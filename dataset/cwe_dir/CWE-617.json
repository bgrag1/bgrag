[
    {
        "cve_id": "CVE-2022-33069",
        "func_name": "ethereum/solidity/SMTEncoder::identifierToVariable",
        "description": "Ethereum Solidity v0.8.14 contains an assertion failure via SMTEncoder::indexOrMemberAssignment() at SMTEncoder.cpp.",
        "git_url": "https://github.com/ethereum/solidity/commit/07870d031894505132843555652f88f4cdf45874",
        "commit_title": "Fix internal error in assignment chains that also assign to fully qualified state variables (, for example), where the contract expression is a tuble.",
        "commit_text": "",
        "func_before": "VariableDeclaration const* SMTEncoder::identifierToVariable(Expression const& _expr) const\n{\n\t// We do not use `expressionToDeclaration` here because we are not interested in\n\t// struct.field, for example.\n\tif (auto const* identifier = dynamic_cast<Identifier const*>(&_expr))\n\t\tif (auto const* varDecl = dynamic_cast<VariableDeclaration const*>(identifier->annotation().referencedDeclaration))\n\t\t{\n\t\t\tsolAssert(m_context.knownVariable(*varDecl), \"\");\n\t\t\treturn varDecl;\n\t\t}\n\t// But we are interested in \"contract.var\", because that is the same as just \"var\".\n\tif (auto const* memberAccess = dynamic_cast<MemberAccess const*>(&_expr))\n\t\tif (dynamic_cast<ContractDefinition const*>(expressionToDeclaration(memberAccess->expression())))\n\t\t\tif (auto const* varDecl = dynamic_cast<VariableDeclaration const*>(memberAccess->annotation().referencedDeclaration))\n\t\t\t{\n\t\t\t\tsolAssert(m_context.knownVariable(*varDecl), \"\");\n\t\t\t\treturn varDecl;\n\t\t\t}\n\n\treturn nullptr;\n}",
        "func": "VariableDeclaration const* SMTEncoder::identifierToVariable(Expression const& _expr) const\n{\n\t// We do not use `expressionToDeclaration` here because we are not interested in\n\t// struct.field, for example.\n\tif (auto const* identifier = dynamic_cast<Identifier const*>(&_expr))\n\t\tif (auto const* varDecl = dynamic_cast<VariableDeclaration const*>(identifier->annotation().referencedDeclaration))\n\t\t{\n\t\t\tsolAssert(m_context.knownVariable(*varDecl), \"\");\n\t\t\treturn varDecl;\n\t\t}\n\t// But we are interested in \"contract.var\", because that is the same as just \"var\".\n\tif (auto const* memberAccess = dynamic_cast<MemberAccess const*>(&_expr))\n\t\tif (dynamic_cast<ContractDefinition const*>(expressionToDeclaration(\n\t\t\t*cleanExpression(memberAccess->expression())\n\t\t)))\n\t\t\tif (auto const* varDecl = dynamic_cast<VariableDeclaration const*>(memberAccess->annotation().referencedDeclaration))\n\t\t\t{\n\t\t\t\tsolAssert(m_context.knownVariable(*varDecl), \"\");\n\t\t\t\treturn varDecl;\n\t\t\t}\n\n\treturn nullptr;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,9 @@\n \t\t}\n \t// But we are interested in \"contract.var\", because that is the same as just \"var\".\n \tif (auto const* memberAccess = dynamic_cast<MemberAccess const*>(&_expr))\n-\t\tif (dynamic_cast<ContractDefinition const*>(expressionToDeclaration(memberAccess->expression())))\n+\t\tif (dynamic_cast<ContractDefinition const*>(expressionToDeclaration(\n+\t\t\t*cleanExpression(memberAccess->expression())\n+\t\t)))\n \t\t\tif (auto const* varDecl = dynamic_cast<VariableDeclaration const*>(memberAccess->annotation().referencedDeclaration))\n \t\t\t{\n \t\t\t\tsolAssert(m_context.knownVariable(*varDecl), \"\");",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (dynamic_cast<ContractDefinition const*>(expressionToDeclaration(memberAccess->expression())))"
            ],
            "added_lines": [
                "\t\tif (dynamic_cast<ContractDefinition const*>(expressionToDeclaration(",
                "\t\t\t*cleanExpression(memberAccess->expression())",
                "\t\t)))"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-12312",
        "func_name": "libreswan/send_v2N_spi_response_from_state",
        "description": "In Libreswan 3.27 an assertion failure can lead to a pluto IKE daemon restart. An attacker can trigger a NULL pointer dereference by initiating an IKEv2 IKE_SA_INIT exchange, followed by a bogus INFORMATIONAL exchange instead of the normallly expected IKE_AUTH exchange. This affects send_v2N_spi_response_from_state() in programs/pluto/ikev2_send.c that will then trigger a NULL pointer dereference leading to a restart of libreswan.",
        "git_url": "https://github.com/libreswan/libreswan/commit/7142d2c37d58cf024595a7549f0fb0d3946682f8",
        "commit_title": "IKEv2: Do not attempt to encrypt a reply without established IKE SA",
        "commit_text": " This is https://github.com/libreswan/libreswan/issues/246 ",
        "func_before": "void send_v2N_spi_response_from_state(struct ike_sa *ike,\n\t\t\t\t      struct msg_digest *md,\n\t\t\t\t      enum ikev2_sec_proto_id protoid,\n\t\t\t\t      ipsec_spi_t *spi,\n\t\t\t\t      v2_notification_t ntype,\n\t\t\t\t      const chunk_t *ndata /* optional */)\n{\n\tpassert(v2_msg_role(md) == MESSAGE_REQUEST); /* always responding */\n\tconst char *const notify_name = enum_short_name(&ikev2_notify_names, ntype);\n\n\tenum isakmp_xchg_types exchange_type = md->hdr.isa_xchg;\n\tconst char *const exchange_name = enum_short_name(&ikev2_exchange_names, exchange_type);\n\n\tipstr_buf b;\n\tlibreswan_log(\"responding to %s message (ID %u) from %s:%u with encrypted notification %s\",\n\t\t      exchange_name, md->hdr.isa_msgid,\n\t\t      sensitive_ipstr(&ike->sa.st_remoteaddr, &b),\n\t\t      ike->sa.st_remoteport,\n\t\t      notify_name);\n\n\t/*\n\t * For encrypted messages, the EXCHANGE TYPE can't be SA_INIT.\n\t */\n\tswitch (exchange_type) {\n\tcase ISAKMP_v2_IKE_SA_INIT:\n\t\tPEXPECT_LOG(\"exchange type %s invalid for encrypted notification\",\n\t\t\t    exchange_name);\n\t\treturn;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tuint8_t buf[MIN_OUTPUT_UDP_SIZE];\n\tpb_stream reply = open_out_pbs(\"encrypted notification\",\n\t\t\t\t       buf, sizeof(buf));\n\n\tpb_stream rbody = open_v2_message(&reply, ike,\n\t\t\t\t\t  md /* response */,\n\t\t\t\t\t  exchange_type);\n\tif (!pbs_ok(&rbody)) {\n\t\tlibreswan_log(\"error initializing hdr for encrypted notification\");\n\t\treturn;\n\t}\n\n\tv2SK_payload_t sk = open_v2SK_payload(&rbody, ike);\n\tif (!pbs_ok(&sk.pbs)) {\n\t\treturn;\n\t}\n\n\t/* actual data */\n\n\t/*\n\t * 3.10.  Notify Payload: Of the notifications defined in this\n\t * document, the SPI is included only with INVALID_SELECTORS,\n\t * REKEY_SA, and CHILD_SA_NOT_FOUND.\n\t*/\n\tswitch (ntype) {\n\tcase v2N_INVALID_SELECTORS:\n\t\t/*\n\t\t * MAY be sent in an IKE INFORMATIONAL exchange when a\n\t\t * node receives an ESP or AH packet whose selectors\n\t\t * do not match those of the SA on which it was\n\t\t * delivered (and that caused the packet to be\n\t\t * dropped).  The Notification Data contains the start\n\t\t * of the offending packet (as in ICMP messages) and\n\t\t * the SPI field of the notification is set to match\n\t\t * the SPI of the Child SA.\n\t\t*/\n\t\tPEXPECT_LOG(\"trying to send unimplemented %s notification\",\n\t\t\t    notify_name);\n\t\treturn;\n\tcase v2N_REKEY_SA:\n\t\tPEXPECT_LOG(\"%s notification cannot be part of a response\",\n\t\t\t    notify_name);\n\t\treturn;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tpb_stream n_pbs;\n\tif (!emit_v2Nsa_pl(ntype, protoid, spi, &sk.pbs, &n_pbs) ||\n\t    (ndata != NULL && !out_chunk(*ndata, &n_pbs, \"Notify data\"))) {\n\t\treturn;\n\t}\n\tclose_output_pbs(&n_pbs);\n\n\tif (!close_v2SK_payload(&sk)) {\n\t\treturn;\n\t}\n\tclose_output_pbs(&rbody);\n\tclose_output_pbs(&reply);\n\n\tstf_status ret = encrypt_v2SK_payload(&sk);\n\tif (ret != STF_OK) {\n\t\tlibreswan_log(\"error encrypting notify message\");\n\t\treturn;\n\t}\n\n\t/*\n\t * The notification is piggybacked on the existing parent\n\t * state.  This notification is fire-and-forget (not a proper\n\t * exchange, one with retrying).  So we need not preserve the\n\t * packet we are sending.\n\t *\n\t * XXX: this sounds wrong!  Integrity has been established so\n\t * the outgoing packet should be retained and message counters\n\t * updated.  If ST is going to be 'deleted', then, wouldn't it\n\t * be better to have it linger a little so it can handle\n\t * duplicates cleanly.\n\t */\n\tsend_chunk_using_state(&ike->sa, \"v2 notify\", same_out_pbs_as_chunk(&reply));\n\tpstat(ikev2_sent_notifies_e, ntype);\n}",
        "func": "void send_v2N_spi_response_from_state(struct ike_sa *ike,\n\t\t\t\t      struct msg_digest *md,\n\t\t\t\t      enum ikev2_sec_proto_id protoid,\n\t\t\t\t      ipsec_spi_t *spi,\n\t\t\t\t      v2_notification_t ntype,\n\t\t\t\t      const chunk_t *ndata /* optional */)\n{\n\tpassert(v2_msg_role(md) == MESSAGE_REQUEST); /* always responding */\n\tconst char *const notify_name = enum_short_name(&ikev2_notify_names, ntype);\n\n\tenum isakmp_xchg_types exchange_type = md->hdr.isa_xchg;\n\tconst char *const exchange_name = enum_short_name(&ikev2_exchange_names, exchange_type);\n\n\tif (!IS_IKE_SA_ESTABLISHED(md->st)) { /* XXX Andrew? how to dig into ike_sa ike ? */\n\t\tloglog(RC_LOG_SERIOUS, \"unable to respond to exchange type %s message with encrypted notification because there is no established IKE SA\",\n\t\t\texchange_name);\n\t\treturn;\n\t}\n\t/*\n\t * For encrypted messages, the EXCHANGE TYPE can't be SA_INIT.\n\t * And the IKE SA must have been established\n\t */\n\tswitch (exchange_type) {\n\tcase ISAKMP_v2_IKE_SA_INIT:\n\tcase ISAKMP_v2_IKE_AUTH:\n\t\tloglog(RC_LOG_SERIOUS, \"exchange type %s invalid for encrypted notification\",\n\t\t\t    exchange_name);\n\t\treturn;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tipstr_buf b;\n\tlibreswan_log(\"responding to %s message (ID %u) from %s:%u with encrypted notification %s\",\n\t\t      exchange_name, md->hdr.isa_msgid,\n\t\t      sensitive_ipstr(&ike->sa.st_remoteaddr, &b),\n\t\t      ike->sa.st_remoteport,\n\t\t      notify_name);\n\n\tuint8_t buf[MIN_OUTPUT_UDP_SIZE];\n\tpb_stream reply = open_out_pbs(\"encrypted notification\",\n\t\t\t\t       buf, sizeof(buf));\n\n\tpb_stream rbody = open_v2_message(&reply, ike,\n\t\t\t\t\t  md /* response */,\n\t\t\t\t\t  exchange_type);\n\tif (!pbs_ok(&rbody)) {\n\t\tlibreswan_log(\"error initializing hdr for encrypted notification\");\n\t\treturn;\n\t}\n\n\tv2SK_payload_t sk = open_v2SK_payload(&rbody, ike);\n\tif (!pbs_ok(&sk.pbs)) {\n\t\treturn;\n\t}\n\n\t/* actual data */\n\n\t/*\n\t * 3.10.  Notify Payload: Of the notifications defined in this\n\t * document, the SPI is included only with INVALID_SELECTORS,\n\t * REKEY_SA, and CHILD_SA_NOT_FOUND.\n\t*/\n\tswitch (ntype) {\n\tcase v2N_INVALID_SELECTORS:\n\t\t/*\n\t\t * MAY be sent in an IKE INFORMATIONAL exchange when a\n\t\t * node receives an ESP or AH packet whose selectors\n\t\t * do not match those of the SA on which it was\n\t\t * delivered (and that caused the packet to be\n\t\t * dropped).  The Notification Data contains the start\n\t\t * of the offending packet (as in ICMP messages) and\n\t\t * the SPI field of the notification is set to match\n\t\t * the SPI of the Child SA.\n\t\t*/\n\t\tPEXPECT_LOG(\"trying to send unimplemented %s notification\",\n\t\t\t    notify_name);\n\t\treturn;\n\tcase v2N_REKEY_SA:\n\t\tPEXPECT_LOG(\"%s notification cannot be part of a response\",\n\t\t\t    notify_name);\n\t\treturn;\n\tdefault:\n\t\tbreak;\n\t}\n\n\tpb_stream n_pbs;\n\tif (!emit_v2Nsa_pl(ntype, protoid, spi, &sk.pbs, &n_pbs) ||\n\t    (ndata != NULL && !out_chunk(*ndata, &n_pbs, \"Notify data\"))) {\n\t\treturn;\n\t}\n\tclose_output_pbs(&n_pbs);\n\n\tif (!close_v2SK_payload(&sk)) {\n\t\treturn;\n\t}\n\tclose_output_pbs(&rbody);\n\tclose_output_pbs(&reply);\n\n\tstf_status ret = encrypt_v2SK_payload(&sk);\n\tif (ret != STF_OK) {\n\t\tlibreswan_log(\"error encrypting notify message\");\n\t\treturn;\n\t}\n\n\t/*\n\t * The notification is piggybacked on the existing parent\n\t * state.  This notification is fire-and-forget (not a proper\n\t * exchange, one with retrying).  So we need not preserve the\n\t * packet we are sending.\n\t *\n\t * XXX: this sounds wrong!  Integrity has been established so\n\t * the outgoing packet should be retained and message counters\n\t * updated.  If ST is going to be 'deleted', then, wouldn't it\n\t * be better to have it linger a little so it can handle\n\t * duplicates cleanly.\n\t */\n\tsend_chunk_using_state(&ike->sa, \"v2 notify\", same_out_pbs_as_chunk(&reply));\n\tpstat(ikev2_sent_notifies_e, ntype);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,24 +11,31 @@\n \tenum isakmp_xchg_types exchange_type = md->hdr.isa_xchg;\n \tconst char *const exchange_name = enum_short_name(&ikev2_exchange_names, exchange_type);\n \n+\tif (!IS_IKE_SA_ESTABLISHED(md->st)) { /* XXX Andrew? how to dig into ike_sa ike ? */\n+\t\tloglog(RC_LOG_SERIOUS, \"unable to respond to exchange type %s message with encrypted notification because there is no established IKE SA\",\n+\t\t\texchange_name);\n+\t\treturn;\n+\t}\n+\t/*\n+\t * For encrypted messages, the EXCHANGE TYPE can't be SA_INIT.\n+\t * And the IKE SA must have been established\n+\t */\n+\tswitch (exchange_type) {\n+\tcase ISAKMP_v2_IKE_SA_INIT:\n+\tcase ISAKMP_v2_IKE_AUTH:\n+\t\tloglog(RC_LOG_SERIOUS, \"exchange type %s invalid for encrypted notification\",\n+\t\t\t    exchange_name);\n+\t\treturn;\n+\tdefault:\n+\t\tbreak;\n+\t}\n+\n \tipstr_buf b;\n \tlibreswan_log(\"responding to %s message (ID %u) from %s:%u with encrypted notification %s\",\n \t\t      exchange_name, md->hdr.isa_msgid,\n \t\t      sensitive_ipstr(&ike->sa.st_remoteaddr, &b),\n \t\t      ike->sa.st_remoteport,\n \t\t      notify_name);\n-\n-\t/*\n-\t * For encrypted messages, the EXCHANGE TYPE can't be SA_INIT.\n-\t */\n-\tswitch (exchange_type) {\n-\tcase ISAKMP_v2_IKE_SA_INIT:\n-\t\tPEXPECT_LOG(\"exchange type %s invalid for encrypted notification\",\n-\t\t\t    exchange_name);\n-\t\treturn;\n-\tdefault:\n-\t\tbreak;\n-\t}\n \n \tuint8_t buf[MIN_OUTPUT_UDP_SIZE];\n \tpb_stream reply = open_out_pbs(\"encrypted notification\",",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\t/*",
                "\t * For encrypted messages, the EXCHANGE TYPE can't be SA_INIT.",
                "\t */",
                "\tswitch (exchange_type) {",
                "\tcase ISAKMP_v2_IKE_SA_INIT:",
                "\t\tPEXPECT_LOG(\"exchange type %s invalid for encrypted notification\",",
                "\t\t\t    exchange_name);",
                "\t\treturn;",
                "\tdefault:",
                "\t\tbreak;",
                "\t}"
            ],
            "added_lines": [
                "\tif (!IS_IKE_SA_ESTABLISHED(md->st)) { /* XXX Andrew? how to dig into ike_sa ike ? */",
                "\t\tloglog(RC_LOG_SERIOUS, \"unable to respond to exchange type %s message with encrypted notification because there is no established IKE SA\",",
                "\t\t\texchange_name);",
                "\t\treturn;",
                "\t}",
                "\t/*",
                "\t * For encrypted messages, the EXCHANGE TYPE can't be SA_INIT.",
                "\t * And the IKE SA must have been established",
                "\t */",
                "\tswitch (exchange_type) {",
                "\tcase ISAKMP_v2_IKE_SA_INIT:",
                "\tcase ISAKMP_v2_IKE_AUTH:",
                "\t\tloglog(RC_LOG_SERIOUS, \"exchange type %s invalid for encrypted notification\",",
                "\t\t\t    exchange_name);",
                "\t\treturn;",
                "\tdefault:",
                "\t\tbreak;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13113",
        "func_name": "Exiv2/exiv2/CiffComponent::dataLocation",
        "description": "Exiv2 through 0.27.1 allows an attacker to cause a denial of service (crash due to assertion failure) via an invalid data location in a CRW image file.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/7eeb638f32d9d18f184e8a5d60dda92e53857346",
        "commit_title": "Throw an exception if the data location is invalid.",
        "commit_text": "",
        "func_before": "DataLocId CiffComponent::dataLocation(uint16_t tag)\n    {\n        DataLocId di = invalidDataLocId;\n        switch (tag & 0xc000) {\n        case 0x0000: di = valueData; break;\n        case 0x4000: di = directoryData; break;\n        }\n        return di;\n    }",
        "func": "DataLocId CiffComponent::dataLocation(uint16_t tag)\n    {\n        switch (tag & 0xc000) {\n        case 0x0000: return valueData;\n        case 0x4000: return directoryData;\n        default: throw Error(kerCorruptedMetadata);\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,8 @@\n DataLocId CiffComponent::dataLocation(uint16_t tag)\n     {\n-        DataLocId di = invalidDataLocId;\n         switch (tag & 0xc000) {\n-        case 0x0000: di = valueData; break;\n-        case 0x4000: di = directoryData; break;\n+        case 0x0000: return valueData;\n+        case 0x4000: return directoryData;\n+        default: throw Error(kerCorruptedMetadata);\n         }\n-        return di;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        DataLocId di = invalidDataLocId;",
                "        case 0x0000: di = valueData; break;",
                "        case 0x4000: di = directoryData; break;",
                "        return di;"
            ],
            "added_lines": [
                "        case 0x0000: return valueData;",
                "        case 0x4000: return directoryData;",
                "        default: throw Error(kerCorruptedMetadata);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/start_decoder",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int start_decoder(vorb *f)\n{\n   uint8 header[6], x,y;\n   int len,i,j,k, max_submaps = 0;\n   int longest_floorlist=0;\n\n   // first page, first packet\n\n   if (!start_page(f))                              return FALSE;\n   // validate page flag\n   if (!(f->page_flag & PAGEFLAG_first_page))       return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_last_page)           return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_continued_packet)    return error(f, VORBIS_invalid_first_page);\n   // check for expected packet length\n   if (f->segment_count != 1)                       return error(f, VORBIS_invalid_first_page);\n   if (f->segments[0] != 30) {\n      // check for the Ogg skeleton fishead identifying header to refine our error\n      if (f->segments[0] == 64 &&\n          getn(f, header, 6) &&\n          header[0] == 'f' &&\n          header[1] == 'i' &&\n          header[2] == 's' &&\n          header[3] == 'h' &&\n          header[4] == 'e' &&\n          header[5] == 'a' &&\n          get8(f)   == 'd' &&\n          get8(f)   == '\\0')                        return error(f, VORBIS_ogg_skeleton_not_supported);\n      else\n                                                    return error(f, VORBIS_invalid_first_page);\n   }\n\n   // read packet\n   // check packet header\n   if (get8(f) != VORBIS_packet_id)                 return error(f, VORBIS_invalid_first_page);\n   if (!getn(f, header, 6))                         return error(f, VORBIS_unexpected_eof);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_first_page);\n   // vorbis_version\n   if (get32(f) != 0)                               return error(f, VORBIS_invalid_first_page);\n   f->channels = get8(f); if (!f->channels)         return error(f, VORBIS_invalid_first_page);\n   if (f->channels > STB_VORBIS_MAX_CHANNELS)       return error(f, VORBIS_too_many_channels);\n   f->sample_rate = get32(f); if (!f->sample_rate)  return error(f, VORBIS_invalid_first_page);\n   get32(f); // bitrate_maximum\n   get32(f); // bitrate_nominal\n   get32(f); // bitrate_minimum\n   x = get8(f);\n   {\n      int log0,log1;\n      log0 = x & 15;\n      log1 = x >> 4;\n      f->blocksize_0 = 1 << log0;\n      f->blocksize_1 = 1 << log1;\n      if (log0 < 6 || log0 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log1 < 6 || log1 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log0 > log1)                                 return error(f, VORBIS_invalid_setup);\n   }\n\n   // framing_flag\n   x = get8(f);\n   if (!(x & 1))                                    return error(f, VORBIS_invalid_first_page);\n\n   // second packet!\n   if (!start_page(f))                              return FALSE;\n\n   if (!start_packet(f))                            return FALSE;\n   do {\n      len = next_segment(f);\n      skip(f, len);\n      f->bytes_in_seg = 0;\n   } while (len);\n\n   // third packet!\n   if (!start_packet(f))                            return FALSE;\n\n   #ifndef STB_VORBIS_NO_PUSHDATA_API\n   if (IS_PUSH_MODE(f)) {\n      if (!is_whole_packet_present(f, TRUE)) {\n         // convert error in ogg header to write type\n         if (f->error == VORBIS_invalid_stream)\n            f->error = VORBIS_invalid_setup;\n         return FALSE;\n      }\n   }\n   #endif\n\n   crc32_init(); // always init it, to avoid multithread race conditions\n\n   if (get8_packet(f) != VORBIS_packet_setup)       return error(f, VORBIS_invalid_setup);\n   for (i=0; i < 6; ++i) header[i] = get8_packet(f);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_setup);\n\n   // codebooks\n\n   f->codebook_count = get_bits(f,8) + 1;\n   f->codebooks = (Codebook *) setup_malloc(f, sizeof(*f->codebooks) * f->codebook_count);\n   if (f->codebooks == NULL)                        return error(f, VORBIS_outofmem);\n   memset(f->codebooks, 0, sizeof(*f->codebooks) * f->codebook_count);\n   for (i=0; i < f->codebook_count; ++i) {\n      uint32 *values;\n      int ordered, sorted_count;\n      int total=0;\n      uint8 *lengths;\n      Codebook *c = f->codebooks+i;\n      CHECK(f);\n      x = get_bits(f, 8); if (x != 0x42)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x43)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x56)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8);\n      c->dimensions = (get_bits(f, 8)<<8) + x;\n      x = get_bits(f, 8);\n      y = get_bits(f, 8);\n      c->entries = (get_bits(f, 8)<<16) + (y<<8) + x;\n      ordered = get_bits(f,1);\n      c->sparse = ordered ? 0 : get_bits(f,1);\n\n      if (c->dimensions == 0 && c->entries != 0)    return error(f, VORBIS_invalid_setup);\n\n      if (c->sparse)\n         lengths = (uint8 *) setup_temp_malloc(f, c->entries);\n      else\n         lengths = c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n\n      if (!lengths) return error(f, VORBIS_outofmem);\n\n      if (ordered) {\n         int current_entry = 0;\n         int current_length = get_bits(f,5) + 1;\n         while (current_entry < c->entries) {\n            int limit = c->entries - current_entry;\n            int n = get_bits(f, ilog(limit));\n            if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n            memset(lengths + current_entry, current_length, n);\n            current_entry += n;\n            ++current_length;\n         }\n      } else {\n         for (j=0; j < c->entries; ++j) {\n            int present = c->sparse ? get_bits(f,1) : 1;\n            if (present) {\n               lengths[j] = get_bits(f, 5) + 1;\n               ++total;\n               if (lengths[j] == 32)\n                  return error(f, VORBIS_invalid_setup);\n            } else {\n               lengths[j] = NO_CODE;\n            }\n         }\n      }\n\n      if (c->sparse && total >= c->entries >> 2) {\n         // convert sparse items to non-sparse!\n         if (c->entries > (int) f->setup_temp_memory_required)\n            f->setup_temp_memory_required = c->entries;\n\n         c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n         if (c->codeword_lengths == NULL) return error(f, VORBIS_outofmem);\n         memcpy(c->codeword_lengths, lengths, c->entries);\n         setup_temp_free(f, lengths, c->entries); // note this is only safe if there have been no intervening temp mallocs!\n         lengths = c->codeword_lengths;\n         c->sparse = 0;\n      }\n\n      // compute the size of the sorted tables\n      if (c->sparse) {\n         sorted_count = total;\n      } else {\n         sorted_count = 0;\n         #ifndef STB_VORBIS_NO_HUFFMAN_BINARY_SEARCH\n         for (j=0; j < c->entries; ++j)\n            if (lengths[j] > STB_VORBIS_FAST_HUFFMAN_LENGTH && lengths[j] != NO_CODE)\n               ++sorted_count;\n         #endif\n      }\n\n      c->sorted_entries = sorted_count;\n      values = NULL;\n\n      CHECK(f);\n      if (!c->sparse) {\n         c->codewords = (uint32 *) setup_malloc(f, sizeof(c->codewords[0]) * c->entries);\n         if (!c->codewords)                  return error(f, VORBIS_outofmem);\n      } else {\n         unsigned int size;\n         if (c->sorted_entries) {\n            c->codeword_lengths = (uint8 *) setup_malloc(f, c->sorted_entries);\n            if (!c->codeword_lengths)           return error(f, VORBIS_outofmem);\n            c->codewords = (uint32 *) setup_temp_malloc(f, sizeof(*c->codewords) * c->sorted_entries);\n            if (!c->codewords)                  return error(f, VORBIS_outofmem);\n            values = (uint32 *) setup_temp_malloc(f, sizeof(*values) * c->sorted_entries);\n            if (!values)                        return error(f, VORBIS_outofmem);\n         }\n         size = c->entries + (sizeof(*c->codewords) + sizeof(*values)) * c->sorted_entries;\n         if (size > f->setup_temp_memory_required)\n            f->setup_temp_memory_required = size;\n      }\n\n      if (!compute_codewords(c, lengths, c->entries, values)) {\n         if (c->sparse) setup_temp_free(f, values, 0);\n         return error(f, VORBIS_invalid_setup);\n      }\n\n      if (c->sorted_entries) {\n         // allocate an extra slot for sentinels\n         c->sorted_codewords = (uint32 *) setup_malloc(f, sizeof(*c->sorted_codewords) * (c->sorted_entries+1));\n         if (c->sorted_codewords == NULL) return error(f, VORBIS_outofmem);\n         // allocate an extra slot at the front so that c->sorted_values[-1] is defined\n         // so that we can catch that case without an extra if\n         c->sorted_values    = ( int   *) setup_malloc(f, sizeof(*c->sorted_values   ) * (c->sorted_entries+1));\n         if (c->sorted_values == NULL) return error(f, VORBIS_outofmem);\n         ++c->sorted_values;\n         c->sorted_values[-1] = -1;\n         compute_sorted_huffman(c, lengths, values);\n      }\n\n      if (c->sparse) {\n         setup_temp_free(f, values, sizeof(*values)*c->sorted_entries);\n         setup_temp_free(f, c->codewords, sizeof(*c->codewords)*c->sorted_entries);\n         setup_temp_free(f, lengths, c->entries);\n         c->codewords = NULL;\n      }\n\n      compute_accelerated_huffman(c);\n\n      CHECK(f);\n      c->lookup_type = get_bits(f, 4);\n      if (c->lookup_type > 2) return error(f, VORBIS_invalid_setup);\n      if (c->lookup_type > 0) {\n         uint16 *mults;\n         c->minimum_value = float32_unpack(get_bits(f, 32));\n         c->delta_value = float32_unpack(get_bits(f, 32));\n         c->value_bits = get_bits(f, 4)+1;\n         c->sequence_p = get_bits(f,1);\n         if (c->lookup_type == 1) {\n            c->lookup_values = lookup1_values(c->entries, c->dimensions);\n         } else {\n            c->lookup_values = c->entries * c->dimensions;\n         }\n         if (c->lookup_values == 0) return error(f, VORBIS_invalid_setup);\n         mults = (uint16 *) setup_temp_malloc(f, sizeof(mults[0]) * c->lookup_values);\n         if (mults == NULL) return error(f, VORBIS_outofmem);\n         for (j=0; j < (int) c->lookup_values; ++j) {\n            int q = get_bits(f, c->value_bits);\n            if (q == EOP) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_invalid_setup); }\n            mults[j] = q;\n         }\n\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n         if (c->lookup_type == 1) {\n            int len, sparse = c->sparse;\n            float last=0;\n            // pre-expand the lookup1-style multiplicands, to avoid a divide in the inner loop\n            if (sparse) {\n               if (c->sorted_entries == 0) goto skip;\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->sorted_entries * c->dimensions);\n            } else\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->entries        * c->dimensions);\n            if (c->multiplicands == NULL) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            len = sparse ? c->sorted_entries : c->entries;\n            for (j=0; j < len; ++j) {\n               unsigned int z = sparse ? c->sorted_values[j] : j;\n               unsigned int div=1;\n               for (k=0; k < c->dimensions; ++k) {\n                  int off = (z / div) % c->lookup_values;\n                  float val = mults[off];\n                  val = mults[off]*c->delta_value + c->minimum_value + last;\n                  c->multiplicands[j*c->dimensions + k] = val;\n                  if (c->sequence_p)\n                     last = val;\n                  if (k+1 < c->dimensions) {\n                     if (div > UINT_MAX / (unsigned int) c->lookup_values) {\n                        setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values);\n                        return error(f, VORBIS_invalid_setup);\n                     }\n                     div *= c->lookup_values;\n                  }\n               }\n            }\n            c->lookup_type = 2;\n         }\n         else\n#endif\n         {\n            float last=0;\n            CHECK(f);\n            c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->lookup_values);\n            if (c->multiplicands == NULL) { setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            for (j=0; j < (int) c->lookup_values; ++j) {\n               float val = mults[j] * c->delta_value + c->minimum_value + last;\n               c->multiplicands[j] = val;\n               if (c->sequence_p)\n                  last = val;\n            }\n         }\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n        skip:;\n#endif\n         setup_temp_free(f, mults, sizeof(mults[0])*c->lookup_values);\n\n         CHECK(f);\n      }\n      CHECK(f);\n   }\n\n   // time domain transfers (notused)\n\n   x = get_bits(f, 6) + 1;\n   for (i=0; i < x; ++i) {\n      uint32 z = get_bits(f, 16);\n      if (z != 0) return error(f, VORBIS_invalid_setup);\n   }\n\n   // Floors\n   f->floor_count = get_bits(f, 6)+1;\n   f->floor_config = (Floor *)  setup_malloc(f, f->floor_count * sizeof(*f->floor_config));\n   if (f->floor_config == NULL) return error(f, VORBIS_outofmem);\n   for (i=0; i < f->floor_count; ++i) {\n      f->floor_types[i] = get_bits(f, 16);\n      if (f->floor_types[i] > 1) return error(f, VORBIS_invalid_setup);\n      if (f->floor_types[i] == 0) {\n         Floor0 *g = &f->floor_config[i].floor0;\n         g->order = get_bits(f,8);\n         g->rate = get_bits(f,16);\n         g->bark_map_size = get_bits(f,16);\n         g->amplitude_bits = get_bits(f,6);\n         g->amplitude_offset = get_bits(f,8);\n         g->number_of_books = get_bits(f,4) + 1;\n         for (j=0; j < g->number_of_books; ++j)\n            g->book_list[j] = get_bits(f,8);\n         return error(f, VORBIS_feature_not_supported);\n      } else {\n         stbv__floor_ordering p[31*8+2];\n         Floor1 *g = &f->floor_config[i].floor1;\n         int max_class = -1; \n         g->partitions = get_bits(f, 5);\n         for (j=0; j < g->partitions; ++j) {\n            g->partition_class_list[j] = get_bits(f, 4);\n            if (g->partition_class_list[j] > max_class)\n               max_class = g->partition_class_list[j];\n         }\n         for (j=0; j <= max_class; ++j) {\n            g->class_dimensions[j] = get_bits(f, 3)+1;\n            g->class_subclasses[j] = get_bits(f, 2);\n            if (g->class_subclasses[j]) {\n               g->class_masterbooks[j] = get_bits(f, 8);\n               if (g->class_masterbooks[j] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n            for (k=0; k < 1 << g->class_subclasses[j]; ++k) {\n               g->subclass_books[j][k] = get_bits(f,8)-1;\n               if (g->subclass_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n         }\n         g->floor1_multiplier = get_bits(f,2)+1;\n         g->rangebits = get_bits(f,4);\n         g->Xlist[0] = 0;\n         g->Xlist[1] = 1 << g->rangebits;\n         g->values = 2;\n         for (j=0; j < g->partitions; ++j) {\n            int c = g->partition_class_list[j];\n            for (k=0; k < g->class_dimensions[c]; ++k) {\n               g->Xlist[g->values] = get_bits(f, g->rangebits);\n               ++g->values;\n            }\n         }\n         // precompute the sorting\n         for (j=0; j < g->values; ++j) {\n            p[j].x = g->Xlist[j];\n            p[j].id = j;\n         }\n         qsort(p, g->values, sizeof(p[0]), point_compare);\n         for (j=0; j < g->values; ++j)\n            g->sorted_order[j] = (uint8) p[j].id;\n         // precompute the neighbors\n         for (j=2; j < g->values; ++j) {\n            int low,hi;\n            neighbors(g->Xlist, j, &low,&hi);\n            g->neighbors[j][0] = low;\n            g->neighbors[j][1] = hi;\n         }\n\n         if (g->values > longest_floorlist)\n            longest_floorlist = g->values;\n      }\n   }\n\n   // Residue\n   f->residue_count = get_bits(f, 6)+1;\n   f->residue_config = (Residue *) setup_malloc(f, f->residue_count * sizeof(f->residue_config[0]));\n   if (f->residue_config == NULL) return error(f, VORBIS_outofmem);\n   memset(f->residue_config, 0, f->residue_count * sizeof(f->residue_config[0]));\n   for (i=0; i < f->residue_count; ++i) {\n      uint8 residue_cascade[64];\n      Residue *r = f->residue_config+i;\n      f->residue_types[i] = get_bits(f, 16);\n      if (f->residue_types[i] > 2) return error(f, VORBIS_invalid_setup);\n      r->begin = get_bits(f, 24);\n      r->end = get_bits(f, 24);\n      if (r->end < r->begin) return error(f, VORBIS_invalid_setup);\n      r->part_size = get_bits(f,24)+1;\n      r->classifications = get_bits(f,6)+1;\n      r->classbook = get_bits(f,8);\n      if (r->classbook >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n      for (j=0; j < r->classifications; ++j) {\n         uint8 high_bits=0;\n         uint8 low_bits=get_bits(f,3);\n         if (get_bits(f,1))\n            high_bits = get_bits(f,5);\n         residue_cascade[j] = high_bits*8 + low_bits;\n      }\n      r->residue_books = (short (*)[8]) setup_malloc(f, sizeof(r->residue_books[0]) * r->classifications);\n      if (r->residue_books == NULL) return error(f, VORBIS_outofmem);\n      for (j=0; j < r->classifications; ++j) {\n         for (k=0; k < 8; ++k) {\n            if (residue_cascade[j] & (1 << k)) {\n               r->residue_books[j][k] = get_bits(f, 8);\n               if (r->residue_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            } else {\n               r->residue_books[j][k] = -1;\n            }\n         }\n      }\n      // precompute the classifications[] array to avoid inner-loop mod/divide\n      // call it 'classdata' since we already have r->classifications\n      r->classdata = (uint8 **) setup_malloc(f, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      if (!r->classdata) return error(f, VORBIS_outofmem);\n      memset(r->classdata, 0, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      for (j=0; j < f->codebooks[r->classbook].entries; ++j) {\n         int classwords = f->codebooks[r->classbook].dimensions;\n         int temp = j;\n         r->classdata[j] = (uint8 *) setup_malloc(f, sizeof(r->classdata[j][0]) * classwords);\n         if (r->classdata[j] == NULL) return error(f, VORBIS_outofmem);\n         for (k=classwords-1; k >= 0; --k) {\n            r->classdata[j][k] = temp % r->classifications;\n            temp /= r->classifications;\n         }\n      }\n   }\n\n   f->mapping_count = get_bits(f,6)+1;\n   f->mapping = (Mapping *) setup_malloc(f, f->mapping_count * sizeof(*f->mapping));\n   if (f->mapping == NULL) return error(f, VORBIS_outofmem);\n   memset(f->mapping, 0, f->mapping_count * sizeof(*f->mapping));\n   for (i=0; i < f->mapping_count; ++i) {\n      Mapping *m = f->mapping + i;      \n      int mapping_type = get_bits(f,16);\n      if (mapping_type != 0) return error(f, VORBIS_invalid_setup);\n      m->chan = (MappingChannel *) setup_malloc(f, f->channels * sizeof(*m->chan));\n      if (m->chan == NULL) return error(f, VORBIS_outofmem);\n      if (get_bits(f,1))\n         m->submaps = get_bits(f,4)+1;\n      else\n         m->submaps = 1;\n      if (m->submaps > max_submaps)\n         max_submaps = m->submaps;\n      if (get_bits(f,1)) {\n         m->coupling_steps = get_bits(f,8)+1;\n         for (k=0; k < m->coupling_steps; ++k) {\n            m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n            m->chan[k].angle = get_bits(f, ilog(f->channels-1));\n            if (m->chan[k].magnitude >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].angle     >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].magnitude == m->chan[k].angle)   return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         m->coupling_steps = 0;\n\n      // reserved field\n      if (get_bits(f,2)) return error(f, VORBIS_invalid_setup);\n      if (m->submaps > 1) {\n         for (j=0; j < f->channels; ++j) {\n            m->chan[j].mux = get_bits(f, 4);\n            if (m->chan[j].mux >= m->submaps)                return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         // @SPECIFICATION: this case is missing from the spec\n         for (j=0; j < f->channels; ++j)\n            m->chan[j].mux = 0;\n\n      for (j=0; j < m->submaps; ++j) {\n         get_bits(f,8); // discard\n         m->submap_floor[j] = get_bits(f,8);\n         m->submap_residue[j] = get_bits(f,8);\n         if (m->submap_floor[j] >= f->floor_count)      return error(f, VORBIS_invalid_setup);\n         if (m->submap_residue[j] >= f->residue_count)  return error(f, VORBIS_invalid_setup);\n      }\n   }\n\n   // Modes\n   f->mode_count = get_bits(f, 6)+1;\n   for (i=0; i < f->mode_count; ++i) {\n      Mode *m = f->mode_config+i;\n      m->blockflag = get_bits(f,1);\n      m->windowtype = get_bits(f,16);\n      m->transformtype = get_bits(f,16);\n      m->mapping = get_bits(f,8);\n      if (m->windowtype != 0)                 return error(f, VORBIS_invalid_setup);\n      if (m->transformtype != 0)              return error(f, VORBIS_invalid_setup);\n      if (m->mapping >= f->mapping_count)     return error(f, VORBIS_invalid_setup);\n   }\n\n   flush_packet(f);\n\n   f->previous_length = 0;\n\n   for (i=0; i < f->channels; ++i) {\n      f->channel_buffers[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1);\n      f->previous_window[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      f->finalY[i]          = (int16 *) setup_malloc(f, sizeof(int16) * longest_floorlist);\n      if (f->channel_buffers[i] == NULL || f->previous_window[i] == NULL || f->finalY[i] == NULL) return error(f, VORBIS_outofmem);\n      memset(f->channel_buffers[i], 0, sizeof(float) * f->blocksize_1);\n      #ifdef STB_VORBIS_NO_DEFER_FLOOR\n      f->floor_buffers[i]   = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      if (f->floor_buffers[i] == NULL) return error(f, VORBIS_outofmem);\n      #endif\n   }\n\n   if (!init_blocksize(f, 0, f->blocksize_0)) return FALSE;\n   if (!init_blocksize(f, 1, f->blocksize_1)) return FALSE;\n   f->blocksize[0] = f->blocksize_0;\n   f->blocksize[1] = f->blocksize_1;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (integer_divide_table[1][1]==0)\n      for (i=0; i < DIVTAB_NUMER; ++i)\n         for (j=1; j < DIVTAB_DENOM; ++j)\n            integer_divide_table[i][j] = i / j;\n#endif\n\n   // compute how much temporary memory is needed\n\n   // 1.\n   {\n      uint32 imdct_mem = (f->blocksize_1 * sizeof(float) >> 1);\n      uint32 classify_mem;\n      int i,max_part_read=0;\n      for (i=0; i < f->residue_count; ++i) {\n         Residue *r = f->residue_config + i;\n         unsigned int actual_size = f->blocksize_1 / 2;\n         unsigned int limit_r_begin = r->begin < actual_size ? r->begin : actual_size;\n         unsigned int limit_r_end   = r->end   < actual_size ? r->end   : actual_size;\n         int n_read = limit_r_end - limit_r_begin;\n         int part_read = n_read / r->part_size;\n         if (part_read > max_part_read)\n            max_part_read = part_read;\n      }\n      #ifndef STB_VORBIS_DIVIDES_IN_RESIDUE\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(uint8 *));\n      #else\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(int *));\n      #endif\n\n      // maximum reasonable partition size is f->blocksize_1\n\n      f->temp_memory_required = classify_mem;\n      if (imdct_mem > f->temp_memory_required)\n         f->temp_memory_required = imdct_mem;\n   }\n\n   f->first_decode = TRUE;\n\n   if (f->alloc.alloc_buffer) {\n      assert(f->temp_offset == f->alloc.alloc_buffer_length_in_bytes);\n      // check if there's enough temp memory so we don't error later\n      if (f->setup_offset + sizeof(*f) + f->temp_memory_required > (unsigned) f->temp_offset)\n         return error(f, VORBIS_outofmem);\n   }\n\n   f->first_audio_page_offset = stb_vorbis_get_file_offset(f);\n\n   return TRUE;\n}",
        "func": "static int start_decoder(vorb *f)\n{\n   uint8 header[6], x,y;\n   int len,i,j,k, max_submaps = 0;\n   int longest_floorlist=0;\n\n   // first page, first packet\n\n   if (!start_page(f))                              return FALSE;\n   // validate page flag\n   if (!(f->page_flag & PAGEFLAG_first_page))       return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_last_page)           return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_continued_packet)    return error(f, VORBIS_invalid_first_page);\n   // check for expected packet length\n   if (f->segment_count != 1)                       return error(f, VORBIS_invalid_first_page);\n   if (f->segments[0] != 30) {\n      // check for the Ogg skeleton fishead identifying header to refine our error\n      if (f->segments[0] == 64 &&\n          getn(f, header, 6) &&\n          header[0] == 'f' &&\n          header[1] == 'i' &&\n          header[2] == 's' &&\n          header[3] == 'h' &&\n          header[4] == 'e' &&\n          header[5] == 'a' &&\n          get8(f)   == 'd' &&\n          get8(f)   == '\\0')                        return error(f, VORBIS_ogg_skeleton_not_supported);\n      else\n                                                    return error(f, VORBIS_invalid_first_page);\n   }\n\n   // read packet\n   // check packet header\n   if (get8(f) != VORBIS_packet_id)                 return error(f, VORBIS_invalid_first_page);\n   if (!getn(f, header, 6))                         return error(f, VORBIS_unexpected_eof);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_first_page);\n   // vorbis_version\n   if (get32(f) != 0)                               return error(f, VORBIS_invalid_first_page);\n   f->channels = get8(f); if (!f->channels)         return error(f, VORBIS_invalid_first_page);\n   if (f->channels > STB_VORBIS_MAX_CHANNELS)       return error(f, VORBIS_too_many_channels);\n   f->sample_rate = get32(f); if (!f->sample_rate)  return error(f, VORBIS_invalid_first_page);\n   get32(f); // bitrate_maximum\n   get32(f); // bitrate_nominal\n   get32(f); // bitrate_minimum\n   x = get8(f);\n   {\n      int log0,log1;\n      log0 = x & 15;\n      log1 = x >> 4;\n      f->blocksize_0 = 1 << log0;\n      f->blocksize_1 = 1 << log1;\n      if (log0 < 6 || log0 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log1 < 6 || log1 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log0 > log1)                                 return error(f, VORBIS_invalid_setup);\n   }\n\n   // framing_flag\n   x = get8(f);\n   if (!(x & 1))                                    return error(f, VORBIS_invalid_first_page);\n\n   // second packet!\n   if (!start_page(f))                              return FALSE;\n\n   if (!start_packet(f))                            return FALSE;\n   do {\n      len = next_segment(f);\n      skip(f, len);\n      f->bytes_in_seg = 0;\n   } while (len);\n\n   // third packet!\n   if (!start_packet(f))                            return FALSE;\n\n   #ifndef STB_VORBIS_NO_PUSHDATA_API\n   if (IS_PUSH_MODE(f)) {\n      if (!is_whole_packet_present(f, TRUE)) {\n         // convert error in ogg header to write type\n         if (f->error == VORBIS_invalid_stream)\n            f->error = VORBIS_invalid_setup;\n         return FALSE;\n      }\n   }\n   #endif\n\n   crc32_init(); // always init it, to avoid multithread race conditions\n\n   if (get8_packet(f) != VORBIS_packet_setup)       return error(f, VORBIS_invalid_setup);\n   for (i=0; i < 6; ++i) header[i] = get8_packet(f);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_setup);\n\n   // codebooks\n\n   f->codebook_count = get_bits(f,8) + 1;\n   f->codebooks = (Codebook *) setup_malloc(f, sizeof(*f->codebooks) * f->codebook_count);\n   if (f->codebooks == NULL)                        return error(f, VORBIS_outofmem);\n   memset(f->codebooks, 0, sizeof(*f->codebooks) * f->codebook_count);\n   for (i=0; i < f->codebook_count; ++i) {\n      uint32 *values;\n      int ordered, sorted_count;\n      int total=0;\n      uint8 *lengths;\n      Codebook *c = f->codebooks+i;\n      CHECK(f);\n      x = get_bits(f, 8); if (x != 0x42)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x43)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x56)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8);\n      c->dimensions = (get_bits(f, 8)<<8) + x;\n      x = get_bits(f, 8);\n      y = get_bits(f, 8);\n      c->entries = (get_bits(f, 8)<<16) + (y<<8) + x;\n      ordered = get_bits(f,1);\n      c->sparse = ordered ? 0 : get_bits(f,1);\n\n      if (c->dimensions == 0 && c->entries != 0)    return error(f, VORBIS_invalid_setup);\n\n      if (c->sparse)\n         lengths = (uint8 *) setup_temp_malloc(f, c->entries);\n      else\n         lengths = c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n\n      if (!lengths) return error(f, VORBIS_outofmem);\n\n      if (ordered) {\n         int current_entry = 0;\n         int current_length = get_bits(f,5) + 1;\n         while (current_entry < c->entries) {\n            int limit = c->entries - current_entry;\n            int n = get_bits(f, ilog(limit));\n            if (current_length >= 32) return error(f, VORBIS_invalid_setup);\n            if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n            memset(lengths + current_entry, current_length, n);\n            current_entry += n;\n            ++current_length;\n         }\n      } else {\n         for (j=0; j < c->entries; ++j) {\n            int present = c->sparse ? get_bits(f,1) : 1;\n            if (present) {\n               lengths[j] = get_bits(f, 5) + 1;\n               ++total;\n               if (lengths[j] == 32)\n                  return error(f, VORBIS_invalid_setup);\n            } else {\n               lengths[j] = NO_CODE;\n            }\n         }\n      }\n\n      if (c->sparse && total >= c->entries >> 2) {\n         // convert sparse items to non-sparse!\n         if (c->entries > (int) f->setup_temp_memory_required)\n            f->setup_temp_memory_required = c->entries;\n\n         c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n         if (c->codeword_lengths == NULL) return error(f, VORBIS_outofmem);\n         memcpy(c->codeword_lengths, lengths, c->entries);\n         setup_temp_free(f, lengths, c->entries); // note this is only safe if there have been no intervening temp mallocs!\n         lengths = c->codeword_lengths;\n         c->sparse = 0;\n      }\n\n      // compute the size of the sorted tables\n      if (c->sparse) {\n         sorted_count = total;\n      } else {\n         sorted_count = 0;\n         #ifndef STB_VORBIS_NO_HUFFMAN_BINARY_SEARCH\n         for (j=0; j < c->entries; ++j)\n            if (lengths[j] > STB_VORBIS_FAST_HUFFMAN_LENGTH && lengths[j] != NO_CODE)\n               ++sorted_count;\n         #endif\n      }\n\n      c->sorted_entries = sorted_count;\n      values = NULL;\n\n      CHECK(f);\n      if (!c->sparse) {\n         c->codewords = (uint32 *) setup_malloc(f, sizeof(c->codewords[0]) * c->entries);\n         if (!c->codewords)                  return error(f, VORBIS_outofmem);\n      } else {\n         unsigned int size;\n         if (c->sorted_entries) {\n            c->codeword_lengths = (uint8 *) setup_malloc(f, c->sorted_entries);\n            if (!c->codeword_lengths)           return error(f, VORBIS_outofmem);\n            c->codewords = (uint32 *) setup_temp_malloc(f, sizeof(*c->codewords) * c->sorted_entries);\n            if (!c->codewords)                  return error(f, VORBIS_outofmem);\n            values = (uint32 *) setup_temp_malloc(f, sizeof(*values) * c->sorted_entries);\n            if (!values)                        return error(f, VORBIS_outofmem);\n         }\n         size = c->entries + (sizeof(*c->codewords) + sizeof(*values)) * c->sorted_entries;\n         if (size > f->setup_temp_memory_required)\n            f->setup_temp_memory_required = size;\n      }\n\n      if (!compute_codewords(c, lengths, c->entries, values)) {\n         if (c->sparse) setup_temp_free(f, values, 0);\n         return error(f, VORBIS_invalid_setup);\n      }\n\n      if (c->sorted_entries) {\n         // allocate an extra slot for sentinels\n         c->sorted_codewords = (uint32 *) setup_malloc(f, sizeof(*c->sorted_codewords) * (c->sorted_entries+1));\n         if (c->sorted_codewords == NULL) return error(f, VORBIS_outofmem);\n         // allocate an extra slot at the front so that c->sorted_values[-1] is defined\n         // so that we can catch that case without an extra if\n         c->sorted_values    = ( int   *) setup_malloc(f, sizeof(*c->sorted_values   ) * (c->sorted_entries+1));\n         if (c->sorted_values == NULL) return error(f, VORBIS_outofmem);\n         ++c->sorted_values;\n         c->sorted_values[-1] = -1;\n         compute_sorted_huffman(c, lengths, values);\n      }\n\n      if (c->sparse) {\n         setup_temp_free(f, values, sizeof(*values)*c->sorted_entries);\n         setup_temp_free(f, c->codewords, sizeof(*c->codewords)*c->sorted_entries);\n         setup_temp_free(f, lengths, c->entries);\n         c->codewords = NULL;\n      }\n\n      compute_accelerated_huffman(c);\n\n      CHECK(f);\n      c->lookup_type = get_bits(f, 4);\n      if (c->lookup_type > 2) return error(f, VORBIS_invalid_setup);\n      if (c->lookup_type > 0) {\n         uint16 *mults;\n         c->minimum_value = float32_unpack(get_bits(f, 32));\n         c->delta_value = float32_unpack(get_bits(f, 32));\n         c->value_bits = get_bits(f, 4)+1;\n         c->sequence_p = get_bits(f,1);\n         if (c->lookup_type == 1) {\n            int values = lookup1_values(c->entries, c->dimensions);\n            if (values < 0) return error(f, VORBIS_invalid_setup);\n            c->lookup_values = (uint32) values;\n         } else {\n            c->lookup_values = c->entries * c->dimensions;\n         }\n         if (c->lookup_values == 0) return error(f, VORBIS_invalid_setup);\n         mults = (uint16 *) setup_temp_malloc(f, sizeof(mults[0]) * c->lookup_values);\n         if (mults == NULL) return error(f, VORBIS_outofmem);\n         for (j=0; j < (int) c->lookup_values; ++j) {\n            int q = get_bits(f, c->value_bits);\n            if (q == EOP) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_invalid_setup); }\n            mults[j] = q;\n         }\n\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n         if (c->lookup_type == 1) {\n            int len, sparse = c->sparse;\n            float last=0;\n            // pre-expand the lookup1-style multiplicands, to avoid a divide in the inner loop\n            if (sparse) {\n               if (c->sorted_entries == 0) goto skip;\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->sorted_entries * c->dimensions);\n            } else\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->entries        * c->dimensions);\n            if (c->multiplicands == NULL) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            len = sparse ? c->sorted_entries : c->entries;\n            for (j=0; j < len; ++j) {\n               unsigned int z = sparse ? c->sorted_values[j] : j;\n               unsigned int div=1;\n               for (k=0; k < c->dimensions; ++k) {\n                  int off = (z / div) % c->lookup_values;\n                  float val = mults[off];\n                  val = mults[off]*c->delta_value + c->minimum_value + last;\n                  c->multiplicands[j*c->dimensions + k] = val;\n                  if (c->sequence_p)\n                     last = val;\n                  if (k+1 < c->dimensions) {\n                     if (div > UINT_MAX / (unsigned int) c->lookup_values) {\n                        setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values);\n                        return error(f, VORBIS_invalid_setup);\n                     }\n                     div *= c->lookup_values;\n                  }\n               }\n            }\n            c->lookup_type = 2;\n         }\n         else\n#endif\n         {\n            float last=0;\n            CHECK(f);\n            c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->lookup_values);\n            if (c->multiplicands == NULL) { setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            for (j=0; j < (int) c->lookup_values; ++j) {\n               float val = mults[j] * c->delta_value + c->minimum_value + last;\n               c->multiplicands[j] = val;\n               if (c->sequence_p)\n                  last = val;\n            }\n         }\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n        skip:;\n#endif\n         setup_temp_free(f, mults, sizeof(mults[0])*c->lookup_values);\n\n         CHECK(f);\n      }\n      CHECK(f);\n   }\n\n   // time domain transfers (notused)\n\n   x = get_bits(f, 6) + 1;\n   for (i=0; i < x; ++i) {\n      uint32 z = get_bits(f, 16);\n      if (z != 0) return error(f, VORBIS_invalid_setup);\n   }\n\n   // Floors\n   f->floor_count = get_bits(f, 6)+1;\n   f->floor_config = (Floor *)  setup_malloc(f, f->floor_count * sizeof(*f->floor_config));\n   if (f->floor_config == NULL) return error(f, VORBIS_outofmem);\n   for (i=0; i < f->floor_count; ++i) {\n      f->floor_types[i] = get_bits(f, 16);\n      if (f->floor_types[i] > 1) return error(f, VORBIS_invalid_setup);\n      if (f->floor_types[i] == 0) {\n         Floor0 *g = &f->floor_config[i].floor0;\n         g->order = get_bits(f,8);\n         g->rate = get_bits(f,16);\n         g->bark_map_size = get_bits(f,16);\n         g->amplitude_bits = get_bits(f,6);\n         g->amplitude_offset = get_bits(f,8);\n         g->number_of_books = get_bits(f,4) + 1;\n         for (j=0; j < g->number_of_books; ++j)\n            g->book_list[j] = get_bits(f,8);\n         return error(f, VORBIS_feature_not_supported);\n      } else {\n         stbv__floor_ordering p[31*8+2];\n         Floor1 *g = &f->floor_config[i].floor1;\n         int max_class = -1; \n         g->partitions = get_bits(f, 5);\n         for (j=0; j < g->partitions; ++j) {\n            g->partition_class_list[j] = get_bits(f, 4);\n            if (g->partition_class_list[j] > max_class)\n               max_class = g->partition_class_list[j];\n         }\n         for (j=0; j <= max_class; ++j) {\n            g->class_dimensions[j] = get_bits(f, 3)+1;\n            g->class_subclasses[j] = get_bits(f, 2);\n            if (g->class_subclasses[j]) {\n               g->class_masterbooks[j] = get_bits(f, 8);\n               if (g->class_masterbooks[j] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n            for (k=0; k < 1 << g->class_subclasses[j]; ++k) {\n               g->subclass_books[j][k] = get_bits(f,8)-1;\n               if (g->subclass_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n         }\n         g->floor1_multiplier = get_bits(f,2)+1;\n         g->rangebits = get_bits(f,4);\n         g->Xlist[0] = 0;\n         g->Xlist[1] = 1 << g->rangebits;\n         g->values = 2;\n         for (j=0; j < g->partitions; ++j) {\n            int c = g->partition_class_list[j];\n            for (k=0; k < g->class_dimensions[c]; ++k) {\n               g->Xlist[g->values] = get_bits(f, g->rangebits);\n               ++g->values;\n            }\n         }\n         // precompute the sorting\n         for (j=0; j < g->values; ++j) {\n            p[j].x = g->Xlist[j];\n            p[j].id = j;\n         }\n         qsort(p, g->values, sizeof(p[0]), point_compare);\n         for (j=0; j < g->values-1; ++j)\n            if (p[j].x == p[j+1].x)\n               return error(f, VORBIS_invalid_setup);\n         for (j=0; j < g->values; ++j)\n            g->sorted_order[j] = (uint8) p[j].id;\n         // precompute the neighbors\n         for (j=2; j < g->values; ++j) {\n            int low,hi;\n            neighbors(g->Xlist, j, &low,&hi);\n            g->neighbors[j][0] = low;\n            g->neighbors[j][1] = hi;\n         }\n\n         if (g->values > longest_floorlist)\n            longest_floorlist = g->values;\n      }\n   }\n\n   // Residue\n   f->residue_count = get_bits(f, 6)+1;\n   f->residue_config = (Residue *) setup_malloc(f, f->residue_count * sizeof(f->residue_config[0]));\n   if (f->residue_config == NULL) return error(f, VORBIS_outofmem);\n   memset(f->residue_config, 0, f->residue_count * sizeof(f->residue_config[0]));\n   for (i=0; i < f->residue_count; ++i) {\n      uint8 residue_cascade[64];\n      Residue *r = f->residue_config+i;\n      f->residue_types[i] = get_bits(f, 16);\n      if (f->residue_types[i] > 2) return error(f, VORBIS_invalid_setup);\n      r->begin = get_bits(f, 24);\n      r->end = get_bits(f, 24);\n      if (r->end < r->begin) return error(f, VORBIS_invalid_setup);\n      r->part_size = get_bits(f,24)+1;\n      r->classifications = get_bits(f,6)+1;\n      r->classbook = get_bits(f,8);\n      if (r->classbook >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n      for (j=0; j < r->classifications; ++j) {\n         uint8 high_bits=0;\n         uint8 low_bits=get_bits(f,3);\n         if (get_bits(f,1))\n            high_bits = get_bits(f,5);\n         residue_cascade[j] = high_bits*8 + low_bits;\n      }\n      r->residue_books = (short (*)[8]) setup_malloc(f, sizeof(r->residue_books[0]) * r->classifications);\n      if (r->residue_books == NULL) return error(f, VORBIS_outofmem);\n      for (j=0; j < r->classifications; ++j) {\n         for (k=0; k < 8; ++k) {\n            if (residue_cascade[j] & (1 << k)) {\n               r->residue_books[j][k] = get_bits(f, 8);\n               if (r->residue_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            } else {\n               r->residue_books[j][k] = -1;\n            }\n         }\n      }\n      // precompute the classifications[] array to avoid inner-loop mod/divide\n      // call it 'classdata' since we already have r->classifications\n      r->classdata = (uint8 **) setup_malloc(f, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      if (!r->classdata) return error(f, VORBIS_outofmem);\n      memset(r->classdata, 0, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      for (j=0; j < f->codebooks[r->classbook].entries; ++j) {\n         int classwords = f->codebooks[r->classbook].dimensions;\n         int temp = j;\n         r->classdata[j] = (uint8 *) setup_malloc(f, sizeof(r->classdata[j][0]) * classwords);\n         if (r->classdata[j] == NULL) return error(f, VORBIS_outofmem);\n         for (k=classwords-1; k >= 0; --k) {\n            r->classdata[j][k] = temp % r->classifications;\n            temp /= r->classifications;\n         }\n      }\n   }\n\n   f->mapping_count = get_bits(f,6)+1;\n   f->mapping = (Mapping *) setup_malloc(f, f->mapping_count * sizeof(*f->mapping));\n   if (f->mapping == NULL) return error(f, VORBIS_outofmem);\n   memset(f->mapping, 0, f->mapping_count * sizeof(*f->mapping));\n   for (i=0; i < f->mapping_count; ++i) {\n      Mapping *m = f->mapping + i;      \n      int mapping_type = get_bits(f,16);\n      if (mapping_type != 0) return error(f, VORBIS_invalid_setup);\n      m->chan = (MappingChannel *) setup_malloc(f, f->channels * sizeof(*m->chan));\n      if (m->chan == NULL) return error(f, VORBIS_outofmem);\n      if (get_bits(f,1))\n         m->submaps = get_bits(f,4)+1;\n      else\n         m->submaps = 1;\n      if (m->submaps > max_submaps)\n         max_submaps = m->submaps;\n      if (get_bits(f,1)) {\n         m->coupling_steps = get_bits(f,8)+1;\n         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);\n         for (k=0; k < m->coupling_steps; ++k) {\n            m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n            m->chan[k].angle = get_bits(f, ilog(f->channels-1));\n            if (m->chan[k].magnitude >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].angle     >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].magnitude == m->chan[k].angle)   return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         m->coupling_steps = 0;\n\n      // reserved field\n      if (get_bits(f,2)) return error(f, VORBIS_invalid_setup);\n      if (m->submaps > 1) {\n         for (j=0; j < f->channels; ++j) {\n            m->chan[j].mux = get_bits(f, 4);\n            if (m->chan[j].mux >= m->submaps)                return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         // @SPECIFICATION: this case is missing from the spec\n         for (j=0; j < f->channels; ++j)\n            m->chan[j].mux = 0;\n\n      for (j=0; j < m->submaps; ++j) {\n         get_bits(f,8); // discard\n         m->submap_floor[j] = get_bits(f,8);\n         m->submap_residue[j] = get_bits(f,8);\n         if (m->submap_floor[j] >= f->floor_count)      return error(f, VORBIS_invalid_setup);\n         if (m->submap_residue[j] >= f->residue_count)  return error(f, VORBIS_invalid_setup);\n      }\n   }\n\n   // Modes\n   f->mode_count = get_bits(f, 6)+1;\n   for (i=0; i < f->mode_count; ++i) {\n      Mode *m = f->mode_config+i;\n      m->blockflag = get_bits(f,1);\n      m->windowtype = get_bits(f,16);\n      m->transformtype = get_bits(f,16);\n      m->mapping = get_bits(f,8);\n      if (m->windowtype != 0)                 return error(f, VORBIS_invalid_setup);\n      if (m->transformtype != 0)              return error(f, VORBIS_invalid_setup);\n      if (m->mapping >= f->mapping_count)     return error(f, VORBIS_invalid_setup);\n   }\n\n   flush_packet(f);\n\n   f->previous_length = 0;\n\n   for (i=0; i < f->channels; ++i) {\n      f->channel_buffers[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1);\n      f->previous_window[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      f->finalY[i]          = (int16 *) setup_malloc(f, sizeof(int16) * longest_floorlist);\n      if (f->channel_buffers[i] == NULL || f->previous_window[i] == NULL || f->finalY[i] == NULL) return error(f, VORBIS_outofmem);\n      memset(f->channel_buffers[i], 0, sizeof(float) * f->blocksize_1);\n      #ifdef STB_VORBIS_NO_DEFER_FLOOR\n      f->floor_buffers[i]   = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      if (f->floor_buffers[i] == NULL) return error(f, VORBIS_outofmem);\n      #endif\n   }\n\n   if (!init_blocksize(f, 0, f->blocksize_0)) return FALSE;\n   if (!init_blocksize(f, 1, f->blocksize_1)) return FALSE;\n   f->blocksize[0] = f->blocksize_0;\n   f->blocksize[1] = f->blocksize_1;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (integer_divide_table[1][1]==0)\n      for (i=0; i < DIVTAB_NUMER; ++i)\n         for (j=1; j < DIVTAB_DENOM; ++j)\n            integer_divide_table[i][j] = i / j;\n#endif\n\n   // compute how much temporary memory is needed\n\n   // 1.\n   {\n      uint32 imdct_mem = (f->blocksize_1 * sizeof(float) >> 1);\n      uint32 classify_mem;\n      int i,max_part_read=0;\n      for (i=0; i < f->residue_count; ++i) {\n         Residue *r = f->residue_config + i;\n         unsigned int actual_size = f->blocksize_1 / 2;\n         unsigned int limit_r_begin = r->begin < actual_size ? r->begin : actual_size;\n         unsigned int limit_r_end   = r->end   < actual_size ? r->end   : actual_size;\n         int n_read = limit_r_end - limit_r_begin;\n         int part_read = n_read / r->part_size;\n         if (part_read > max_part_read)\n            max_part_read = part_read;\n      }\n      #ifndef STB_VORBIS_DIVIDES_IN_RESIDUE\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(uint8 *));\n      #else\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(int *));\n      #endif\n\n      // maximum reasonable partition size is f->blocksize_1\n\n      f->temp_memory_required = classify_mem;\n      if (imdct_mem > f->temp_memory_required)\n         f->temp_memory_required = imdct_mem;\n   }\n\n   f->first_decode = TRUE;\n\n   if (f->alloc.alloc_buffer) {\n      assert(f->temp_offset == f->alloc.alloc_buffer_length_in_bytes);\n      // check if there's enough temp memory so we don't error later\n      if (f->setup_offset + sizeof(*f) + f->temp_memory_required > (unsigned) f->temp_offset)\n         return error(f, VORBIS_outofmem);\n   }\n\n   f->first_audio_page_offset = stb_vorbis_get_file_offset(f);\n\n   return TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -127,6 +127,7 @@\n          while (current_entry < c->entries) {\n             int limit = c->entries - current_entry;\n             int n = get_bits(f, ilog(limit));\n+            if (current_length >= 32) return error(f, VORBIS_invalid_setup);\n             if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n             memset(lengths + current_entry, current_length, n);\n             current_entry += n;\n@@ -230,7 +231,9 @@\n          c->value_bits = get_bits(f, 4)+1;\n          c->sequence_p = get_bits(f,1);\n          if (c->lookup_type == 1) {\n-            c->lookup_values = lookup1_values(c->entries, c->dimensions);\n+            int values = lookup1_values(c->entries, c->dimensions);\n+            if (values < 0) return error(f, VORBIS_invalid_setup);\n+            c->lookup_values = (uint32) values;\n          } else {\n             c->lookup_values = c->entries * c->dimensions;\n          }\n@@ -366,6 +369,9 @@\n             p[j].id = j;\n          }\n          qsort(p, g->values, sizeof(p[0]), point_compare);\n+         for (j=0; j < g->values-1; ++j)\n+            if (p[j].x == p[j+1].x)\n+               return error(f, VORBIS_invalid_setup);\n          for (j=0; j < g->values; ++j)\n             g->sorted_order[j] = (uint8) p[j].id;\n          // precompute the neighbors\n@@ -452,6 +458,7 @@\n          max_submaps = m->submaps;\n       if (get_bits(f,1)) {\n          m->coupling_steps = get_bits(f,8)+1;\n+         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);\n          for (k=0; k < m->coupling_steps; ++k) {\n             m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n             m->chan[k].angle = get_bits(f, ilog(f->channels-1));",
        "diff_line_info": {
            "deleted_lines": [
                "            c->lookup_values = lookup1_values(c->entries, c->dimensions);"
            ],
            "added_lines": [
                "            if (current_length >= 32) return error(f, VORBIS_invalid_setup);",
                "            int values = lookup1_values(c->entries, c->dimensions);",
                "            if (values < 0) return error(f, VORBIS_invalid_setup);",
                "            c->lookup_values = (uint32) values;",
                "         for (j=0; j < g->values-1; ++j)",
                "            if (p[j].x == p[j+1].x)",
                "               return error(f, VORBIS_invalid_setup);",
                "         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/lookup1_values",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int lookup1_values(int entries, int dim)\n{\n   int r = (int) floor(exp((float) log((float) entries) / dim));\n   if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n      ++r;                                              // floor() to avoid _ftol() when non-CRT\n   assert(pow((float) r+1, dim) > entries);\n   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above\n   return r;\n}",
        "func": "static int lookup1_values(int entries, int dim)\n{\n   int r = (int) floor(exp((float) log((float) entries) / dim));\n   if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n      ++r;                                              // floor() to avoid _ftol() when non-CRT\n   if (pow((float) r+1, dim) <= entries)\n      return -1;\n   if ((int) floor(pow((float) r, dim)) > entries)\n      return -1;\n   return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,9 @@\n    int r = (int) floor(exp((float) log((float) entries) / dim));\n    if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n       ++r;                                              // floor() to avoid _ftol() when non-CRT\n-   assert(pow((float) r+1, dim) > entries);\n-   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above\n+   if (pow((float) r+1, dim) <= entries)\n+      return -1;\n+   if ((int) floor(pow((float) r, dim)) > entries)\n+      return -1;\n    return r;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "   assert(pow((float) r+1, dim) > entries);",
                "   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above"
            ],
            "added_lines": [
                "   if (pow((float) r+1, dim) <= entries)",
                "      return -1;",
                "   if ((int) floor(pow((float) r, dim)) > entries)",
                "      return -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/vorbis_finish_frame",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int vorbis_finish_frame(stb_vorbis *f, int len, int left, int right)\n{\n   int prev,i,j;\n   // we use right&left (the start of the right- and left-window sin()-regions)\n   // to determine how much to return, rather than inferring from the rules\n   // (same result, clearer code); 'left' indicates where our sin() window\n   // starts, therefore where the previous window's right edge starts, and\n   // therefore where to start mixing from the previous buffer. 'right'\n   // indicates where our sin() ending-window starts, therefore that's where\n   // we start saving, and where our returned-data ends.\n\n   // mixin from previous window\n   if (f->previous_length) {\n      int i,j, n = f->previous_length;\n      float *w = get_window(f, n);\n      for (i=0; i < f->channels; ++i) {\n         for (j=0; j < n; ++j)\n            f->channel_buffers[i][left+j] =\n               f->channel_buffers[i][left+j]*w[    j] +\n               f->previous_window[i][     j]*w[n-1-j];\n      }\n   }\n\n   prev = f->previous_length;\n\n   // last half of this data becomes previous window\n   f->previous_length = len - right;\n\n   // @OPTIMIZE: could avoid this copy by double-buffering the\n   // output (flipping previous_window with channel_buffers), but\n   // then previous_window would have to be 2x as large, and\n   // channel_buffers couldn't be temp mem (although they're NOT\n   // currently temp mem, they could be (unless we want to level\n   // performance by spreading out the computation))\n   for (i=0; i < f->channels; ++i)\n      for (j=0; right+j < len; ++j)\n         f->previous_window[i][j] = f->channel_buffers[i][right+j];\n\n   if (!prev)\n      // there was no previous packet, so this data isn't valid...\n      // this isn't entirely true, only the would-have-overlapped data\n      // isn't valid, but this seems to be what the spec requires\n      return 0;\n\n   // truncate a short frame\n   if (len < right) right = len;\n\n   f->samples_output += right-left;\n\n   return right - left;\n}",
        "func": "static int vorbis_finish_frame(stb_vorbis *f, int len, int left, int right)\n{\n   int prev,i,j;\n   // we use right&left (the start of the right- and left-window sin()-regions)\n   // to determine how much to return, rather than inferring from the rules\n   // (same result, clearer code); 'left' indicates where our sin() window\n   // starts, therefore where the previous window's right edge starts, and\n   // therefore where to start mixing from the previous buffer. 'right'\n   // indicates where our sin() ending-window starts, therefore that's where\n   // we start saving, and where our returned-data ends.\n\n   // mixin from previous window\n   if (f->previous_length) {\n      int i,j, n = f->previous_length;\n      float *w = get_window(f, n);\n      if (w == NULL) return 0;\n      for (i=0; i < f->channels; ++i) {\n         for (j=0; j < n; ++j)\n            f->channel_buffers[i][left+j] =\n               f->channel_buffers[i][left+j]*w[    j] +\n               f->previous_window[i][     j]*w[n-1-j];\n      }\n   }\n\n   prev = f->previous_length;\n\n   // last half of this data becomes previous window\n   f->previous_length = len - right;\n\n   // @OPTIMIZE: could avoid this copy by double-buffering the\n   // output (flipping previous_window with channel_buffers), but\n   // then previous_window would have to be 2x as large, and\n   // channel_buffers couldn't be temp mem (although they're NOT\n   // currently temp mem, they could be (unless we want to level\n   // performance by spreading out the computation))\n   for (i=0; i < f->channels; ++i)\n      for (j=0; right+j < len; ++j)\n         f->previous_window[i][j] = f->channel_buffers[i][right+j];\n\n   if (!prev)\n      // there was no previous packet, so this data isn't valid...\n      // this isn't entirely true, only the would-have-overlapped data\n      // isn't valid, but this seems to be what the spec requires\n      return 0;\n\n   // truncate a short frame\n   if (len < right) right = len;\n\n   f->samples_output += right-left;\n\n   return right - left;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n    if (f->previous_length) {\n       int i,j, n = f->previous_length;\n       float *w = get_window(f, n);\n+      if (w == NULL) return 0;\n       for (i=0; i < f->channels; ++i) {\n          for (j=0; j < n; ++j)\n             f->channel_buffers[i][left+j] =",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if (w == NULL) return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/get_window",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static float *get_window(vorb *f, int len)\n{\n   len <<= 1;\n   if (len == f->blocksize_0) return f->window[0];\n   if (len == f->blocksize_1) return f->window[1];\n   assert(0);\n   return NULL;\n}",
        "func": "static float *get_window(vorb *f, int len)\n{\n   len <<= 1;\n   if (len == f->blocksize_0) return f->window[0];\n   if (len == f->blocksize_1) return f->window[1];\n   return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,5 @@\n    len <<= 1;\n    if (len == f->blocksize_0) return f->window[0];\n    if (len == f->blocksize_1) return f->window[1];\n-   assert(0);\n    return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "   assert(0);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/draw_line",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static __forceinline void draw_line(float *output, int x0, int y0, int x1, int y1, int n)\n{\n   int dy = y1 - y0;\n   int adx = x1 - x0;\n   int ady = abs(dy);\n   int base;\n   int x=x0,y=y0;\n   int err = 0;\n   int sy;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (adx < DIVTAB_DENOM && ady < DIVTAB_NUMER) {\n      if (dy < 0) {\n         base = -integer_divide_table[ady][adx];\n         sy = base-1;\n      } else {\n         base =  integer_divide_table[ady][adx];\n         sy = base+1;\n      }\n   } else {\n      base = dy / adx;\n      if (dy < 0)\n         sy = base - 1;\n      else\n         sy = base+1;\n   }\n#else\n   base = dy / adx;\n   if (dy < 0)\n      sy = base - 1;\n   else\n      sy = base+1;\n#endif\n   ady -= abs(base) * adx;\n   if (x1 > n) x1 = n;\n   if (x < x1) {\n      LINE_OP(output[x], inverse_db_table[y]);\n      for (++x; x < x1; ++x) {\n         err += ady;\n         if (err >= adx) {\n            err -= adx;\n            y += sy;\n         } else\n            y += base;\n         LINE_OP(output[x], inverse_db_table[y]);\n      }\n   }\n}",
        "func": "static __forceinline void draw_line(float *output, int x0, int y0, int x1, int y1, int n)\n{\n   int dy = y1 - y0;\n   int adx = x1 - x0;\n   int ady = abs(dy);\n   int base;\n   int x=x0,y=y0;\n   int err = 0;\n   int sy;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (adx < DIVTAB_DENOM && ady < DIVTAB_NUMER) {\n      if (dy < 0) {\n         base = -integer_divide_table[ady][adx];\n         sy = base-1;\n      } else {\n         base =  integer_divide_table[ady][adx];\n         sy = base+1;\n      }\n   } else {\n      base = dy / adx;\n      if (dy < 0)\n         sy = base - 1;\n      else\n         sy = base+1;\n   }\n#else\n   base = dy / adx;\n   if (dy < 0)\n      sy = base - 1;\n   else\n      sy = base+1;\n#endif\n   ady -= abs(base) * adx;\n   if (x1 > n) x1 = n;\n   if (x < x1) {\n      LINE_OP(output[x], inverse_db_table[y&255]);\n      for (++x; x < x1; ++x) {\n         err += ady;\n         if (err >= adx) {\n            err -= adx;\n            y += sy;\n         } else\n            y += base;\n         LINE_OP(output[x], inverse_db_table[y&255]);\n      }\n   }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,7 +34,7 @@\n    ady -= abs(base) * adx;\n    if (x1 > n) x1 = n;\n    if (x < x1) {\n-      LINE_OP(output[x], inverse_db_table[y]);\n+      LINE_OP(output[x], inverse_db_table[y&255]);\n       for (++x; x < x1; ++x) {\n          err += ady;\n          if (err >= adx) {\n@@ -42,7 +42,7 @@\n             y += sy;\n          } else\n             y += base;\n-         LINE_OP(output[x], inverse_db_table[y]);\n+         LINE_OP(output[x], inverse_db_table[y&255]);\n       }\n    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      LINE_OP(output[x], inverse_db_table[y]);",
                "         LINE_OP(output[x], inverse_db_table[y]);"
            ],
            "added_lines": [
                "      LINE_OP(output[x], inverse_db_table[y&255]);",
                "         LINE_OP(output[x], inverse_db_table[y&255]);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46504",
        "func_name": "pcmacdon/jsish/jsiEvalSubscript",
        "description": "There is an Assertion 'vp != resPtr' failed at jsiEval.c in Jsish v3.5.0.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/48b86dbeb287dca8e5451cb6d6a60e98156c5c8b",
        "commit_title": "Fixes #51",
        "commit_text": " FossilOrigin-Name: ddb4e585955ade541e0a96228fa0f301fe141a81374aef03bd4636396c2efceb",
        "func_before": "static Jsi_RC jsiEvalSubscript(Jsi_Interp *interp, Jsi_Value *src, Jsi_Value *idx, jsi_OpCode *ip,  jsi_OpCode *end,\n    Jsi_Value *currentScope)\n{\n    Jsi_RC rc = JSI_OK;\n    Jsi_String *str = jsi_ValueString(src);\n    // A string index \"abc\"[1]\n    if (str && Jsi_ValueIsNumber(interp, idx)) {\n        int bLen, cLen;\n        char bbuf[10], *cp = Jsi_ValueString(interp, src, &bLen);\n        int n = (int)idx->d.num;\n        cLen = bLen;\n#if JSI__UTF8\n        if (str->flags&JSI_IS_UTF || !(str->flags&JSI_UTF_CHECKED)) {\n            cLen = Jsi_NumUtfChars(cp, bLen);\n            str->flags |= JSI_UTF_CHECKED;\n            if (cLen != bLen)\n                str->flags |= JSI_IS_UTF;\n        }\n#endif\n        if (n<0 || n>=cLen) {\n            Jsi_ValueMakeUndef(interp, &src);\n        } else {\n            if (cLen != bLen)\n                Jsi_UtfGetIndex(cp, n, bbuf);\n            else {\n                bbuf[0] = cp[n];\n                bbuf[1] = 0;\n            }\n            Jsi_ValueMakeStringDup(interp, &src, bbuf);\n        }\n        return rc;\n    }\n\n    uint flags = (uintptr_t)ip->data, right_val = flags&1; // isident=flags&2;\n    bool ro = src->f.bits.readonly;\n    Jsi_Obj *obj = (src->vt==JSI_VT_OBJECT && src->d.obj->ot == JSI_OT_OBJECT?src->d.obj:NULL);\n    int bsc = (src->vt==JSI_VT_OBJECT && src->d.obj->ot == JSI_OT_NUMBER); // Previous bad subscript.\n\n    if (bsc == 0 && interp->lastSubscriptFail && interp->lastSubscriptFail->vt != JSI_VT_UNDEF)\n        Jsi_ValueReset(interp, &interp->lastSubscriptFail);\n    rc = Jsi_ValueToObject(interp, src);\n    if (rc != JSI_OK)\n        return rc;\n    Jsi_Value res = VALINIT, \n        *resPtr = &res,\n        *vp = jsi_ValueSubscript(interp, src, idx, &resPtr, right_val);\n    if (!vp && bsc == 0) {\n        /* eg. so we can list available commands for  \"db.xx()\" */\n        if (idx->vt == JSI_VT_STRING)\n            interp->lastSubscriptFailStr = idx->d.s.str;\n        Jsi_ValueDup2(interp, &interp->lastSubscriptFail, src);\n    }\n    if (!vp) {\n        Jsi_ValueMakeUndef(interp, &src);\n        if (obj && obj->freeze && obj->freezeReadCheck) {\n            const char *keyStr = Jsi_ValueToString(interp, idx, NULL);\n            if (!jsi_isDebugKey(keyStr))\n                rc = Jsi_LogError(\"object freeze: read undefined \\\"%s\\\"\", keyStr);\n        }\n    }\n    else {\n        Jsi_IncrRefCount(interp, vp);\n        if (right_val || vp->f.bits.readonly) {\n            if (vp == resPtr && (res.vt == JSI_VT_OBJECT || res.vt == JSI_VT_STRING))  // TODO:*** Undo using ValueCopy. ***\n                Jsi_ValueMove(interp, src, vp);\n            else\n                Jsi_ValueCopy(interp, src, vp);\n        } else {\n            assert(vp != resPtr);\n            res.vt = JSI_VT_VARIABLE;\n            res.d.lval = vp;\n            if (ro)\n                vp->f.bits.readonly = 1;\n            Jsi_ValueCopy(interp, src, resPtr);\n        }\n        Jsi_DecrRefCount(interp, vp);\n    }\n    return rc;\n}",
        "func": "static Jsi_RC jsiEvalSubscript(Jsi_Interp *interp, Jsi_Value *src, Jsi_Value *idx, jsi_OpCode *ip,  jsi_OpCode *end,\n    Jsi_Value *currentScope)\n{\n    Jsi_RC rc = JSI_OK;\n    Jsi_String *str = jsi_ValueString(src);\n    // A string index \"abc\"[1]\n    if (str && Jsi_ValueIsNumber(interp, idx)) {\n        int bLen, cLen;\n        char bbuf[10], *cp = Jsi_ValueString(interp, src, &bLen);\n        int n = (int)idx->d.num;\n        cLen = bLen;\n#if JSI__UTF8\n        if (str->flags&JSI_IS_UTF || !(str->flags&JSI_UTF_CHECKED)) {\n            cLen = Jsi_NumUtfChars(cp, bLen);\n            str->flags |= JSI_UTF_CHECKED;\n            if (cLen != bLen)\n                str->flags |= JSI_IS_UTF;\n        }\n#endif\n        if (n<0 || n>=cLen) {\n            Jsi_ValueMakeUndef(interp, &src);\n        } else {\n            if (cLen != bLen)\n                Jsi_UtfGetIndex(cp, n, bbuf);\n            else {\n                bbuf[0] = cp[n];\n                bbuf[1] = 0;\n            }\n            Jsi_ValueMakeStringDup(interp, &src, bbuf);\n        }\n        return rc;\n    }\n\n    uint flags = (uintptr_t)ip->data, right_val = flags&1; // isident=flags&2;\n    bool ro = src->f.bits.readonly;\n    Jsi_Obj *obj = (src->vt==JSI_VT_OBJECT && src->d.obj->ot == JSI_OT_OBJECT?src->d.obj:NULL);\n    int bsc = (src->vt==JSI_VT_OBJECT && src->d.obj->ot == JSI_OT_NUMBER); // Previous bad subscript.\n\n    if (bsc == 0 && interp->lastSubscriptFail && interp->lastSubscriptFail->vt != JSI_VT_UNDEF)\n        Jsi_ValueReset(interp, &interp->lastSubscriptFail);\n    rc = Jsi_ValueToObject(interp, src);\n    if (rc != JSI_OK)\n        return rc;\n    Jsi_Value res = VALINIT, \n        *resPtr = &res,\n        *vp = jsi_ValueSubscript(interp, src, idx, &resPtr, right_val);\n    if (!vp && bsc == 0) {\n        /* eg. so we can list available commands for  \"db.xx()\" */\n        if (idx->vt == JSI_VT_STRING)\n            interp->lastSubscriptFailStr = idx->d.s.str;\n        Jsi_ValueDup2(interp, &interp->lastSubscriptFail, src);\n    }\n    if (!vp) {\n        Jsi_ValueMakeUndef(interp, &src);\n        if (obj && obj->freeze && obj->freezeReadCheck) {\n            const char *keyStr = Jsi_ValueToString(interp, idx, NULL);\n            if (!jsi_isDebugKey(keyStr))\n                rc = Jsi_LogError(\"object freeze: read undefined \\\"%s\\\"\", keyStr);\n        }\n    }\n    else {\n        Jsi_IncrRefCount(interp, vp);\n        if (right_val || vp->f.bits.readonly) {\n            if (vp == resPtr && (res.vt == JSI_VT_OBJECT || res.vt == JSI_VT_STRING))  // TODO:*** Undo using ValueCopy. ***\n                Jsi_ValueMove(interp, src, vp);\n            else\n                Jsi_ValueCopy(interp, src, vp);\n        } else {\n            if (vp == resPtr)\n              return Jsi_LogError(\"bad eval\");\n            res.vt = JSI_VT_VARIABLE;\n            res.d.lval = vp;\n            if (ro)\n                vp->f.bits.readonly = 1;\n            Jsi_ValueCopy(interp, src, resPtr);\n        }\n        Jsi_DecrRefCount(interp, vp);\n    }\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -66,7 +66,8 @@\n             else\n                 Jsi_ValueCopy(interp, src, vp);\n         } else {\n-            assert(vp != resPtr);\n+            if (vp == resPtr)\n+              return Jsi_LogError(\"bad eval\");\n             res.vt = JSI_VT_VARIABLE;\n             res.d.lval = vp;\n             if (ro)",
        "diff_line_info": {
            "deleted_lines": [
                "            assert(vp != resPtr);"
            ],
            "added_lines": [
                "            if (vp == resPtr)",
                "              return Jsi_LogError(\"bad eval\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46506",
        "func_name": "pcmacdon/jsish/Jsi_ValueToNumberInt",
        "description": "There is an Assertion 'v->d.lval != v' failed at src/jsiValue.c in Jsish v3.5.0.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/c8eae8318fac1498e02755ebaa9a433461d0cd64",
        "commit_title": "Fixes #52",
        "commit_text": " FossilOrigin-Name: a2f9eec3e383af808f2e06992ad1715d414710afab378267a18db86d99894137",
        "func_before": "Jsi_Number Jsi_ValueToNumberInt(Jsi_Interp *interp, Jsi_Value *v, int isInt)\n{\n    char *endPtr = NULL, *sptr;\n    Jsi_Number a = 0;\n    switch(v->vt) {\n        case JSI_VT_BOOL:\n            a = (Jsi_Number)(v->d.val ? 1.0: 0);\n            break;\n        case JSI_VT_NULL:\n            a = 0;\n            break;\n        case JSI_VT_OBJECT: {\n            Jsi_Obj *obj = v->d.obj;\n            switch(obj->ot) {\n                case JSI_OT_BOOL:\n                    a = (Jsi_Number)(obj->d.val ? 1.0: 0);\n                    break;\n                case JSI_OT_NUMBER:\n                    a = obj->d.num;\n                    break;\n                case JSI_OT_STRING:\n                    sptr = obj->d.s.str;\n                    goto donum;\n                    break;\n                default:\n                    a = 0;\n                break;\n            }\n            break;\n        }\n        case JSI_VT_UNDEF:\n            a = Jsi_NumberNaN();\n            break;\n        case JSI_VT_NUMBER:\n            a = v->d.num;\n            break;\n        case JSI_VT_STRING:\n            sptr = v->d.s.str;\ndonum:\n            if (!isInt) {\n                a = strtod(sptr, &endPtr);\n                if (endPtr && *endPtr) {\n                    a = interp->NaNValue->d.num;\n                }\n            } else {\n                a = (Jsi_Number)strtol(sptr, &endPtr, 0);\n                if (!isdigit(*sptr))\n                    a = interp->NaNValue->d.num;\n            }\n            break;\n        default:\n            Jsi_LogBug(\"Convert a unknown type: 0x%x to number\", v->vt);\n            break;\n    }\n    if (isInt && Jsi_NumberIsNormal(a))\n        a = (Jsi_Number)((int64_t)(a));\n    return a;\n}",
        "func": "Jsi_RC Jsi_ValueToNumberInt(Jsi_Interp *interp, Jsi_Value *v, int isInt, Jsi_Number *nPtr)\n{\n    char *endPtr = NULL, *sptr;\n    Jsi_Number a = 0;\n    switch(v->vt) {\n        case JSI_VT_BOOL:\n            a = (Jsi_Number)(v->d.val ? 1.0: 0);\n            break;\n        case JSI_VT_NULL:\n            a = 0;\n            break;\n        case JSI_VT_OBJECT: {\n            Jsi_Obj *obj = v->d.obj;\n            switch(obj->ot) {\n                case JSI_OT_BOOL:\n                    a = (Jsi_Number)(obj->d.val ? 1.0: 0);\n                    break;\n                case JSI_OT_NUMBER:\n                    a = obj->d.num;\n                    break;\n                case JSI_OT_STRING:\n                    sptr = obj->d.s.str;\n                    goto donum;\n                    break;\n                default:\n                    a = 0;\n                break;\n            }\n            break;\n        }\n        case JSI_VT_UNDEF:\n            a = Jsi_NumberNaN();\n            break;\n        case JSI_VT_NUMBER:\n            a = v->d.num;\n            break;\n        case JSI_VT_STRING:\n            sptr = v->d.s.str;\ndonum:\n            if (!isInt) {\n                a = strtod(sptr, &endPtr);\n                if (endPtr && *endPtr) {\n                    a = interp->NaNValue->d.num;\n                }\n            } else {\n                a = (Jsi_Number)strtol(sptr, &endPtr, 0);\n                if (!isdigit(*sptr))\n                    a = interp->NaNValue->d.num;\n            }\n            break;\n        default:\n            return Jsi_LogError(\"Convert a unknown type: 0x%x to number\", v->vt);\n    }\n    if (isInt && Jsi_NumberIsNormal(a))\n        a = (Jsi_Number)((int64_t)(a));\n    *nPtr = a;\n    return JSI_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-Jsi_Number Jsi_ValueToNumberInt(Jsi_Interp *interp, Jsi_Value *v, int isInt)\n+Jsi_RC Jsi_ValueToNumberInt(Jsi_Interp *interp, Jsi_Value *v, int isInt, Jsi_Number *nPtr)\n {\n     char *endPtr = NULL, *sptr;\n     Jsi_Number a = 0;\n@@ -49,10 +49,10 @@\n             }\n             break;\n         default:\n-            Jsi_LogBug(\"Convert a unknown type: 0x%x to number\", v->vt);\n-            break;\n+            return Jsi_LogError(\"Convert a unknown type: 0x%x to number\", v->vt);\n     }\n     if (isInt && Jsi_NumberIsNormal(a))\n         a = (Jsi_Number)((int64_t)(a));\n-    return a;\n+    *nPtr = a;\n+    return JSI_OK;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "Jsi_Number Jsi_ValueToNumberInt(Jsi_Interp *interp, Jsi_Value *v, int isInt)",
                "            Jsi_LogBug(\"Convert a unknown type: 0x%x to number\", v->vt);",
                "            break;",
                "    return a;"
            ],
            "added_lines": [
                "Jsi_RC Jsi_ValueToNumberInt(Jsi_Interp *interp, Jsi_Value *v, int isInt, Jsi_Number *nPtr)",
                "            return Jsi_LogError(\"Convert a unknown type: 0x%x to number\", v->vt);",
                "    *nPtr = a;",
                "    return JSI_OK;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46506",
        "func_name": "pcmacdon/jsish/Jsi_ValueToNumber",
        "description": "There is an Assertion 'v->d.lval != v' failed at src/jsiValue.c in Jsish v3.5.0.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/c8eae8318fac1498e02755ebaa9a433461d0cd64",
        "commit_title": "Fixes #52",
        "commit_text": " FossilOrigin-Name: a2f9eec3e383af808f2e06992ad1715d414710afab378267a18db86d99894137",
        "func_before": "Jsi_RC Jsi_ValueToNumber(Jsi_Interp *interp, Jsi_Value *v)\n{\n    if (v->vt == JSI_VT_NUMBER) return JSI_OK;\n    Jsi_Number a = Jsi_ValueToNumberInt(interp, v, 0);\n    Jsi_ValueReset(interp, &v);\n    Jsi_ValueMakeNumber(interp, &v, a);\n    return JSI_OK;\n}",
        "func": "Jsi_RC Jsi_ValueToNumber(Jsi_Interp *interp, Jsi_Value *v)\n{\n    if (v->vt == JSI_VT_NUMBER) return JSI_OK;\n    Jsi_Number a;\n    if (Jsi_ValueToNumberInt(interp, v, 0, &a) != JSI_OK)\n      return JSI_ERROR;\n    Jsi_ValueReset(interp, &v);\n    Jsi_ValueMakeNumber(interp, &v, a);\n    return JSI_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,9 @@\n Jsi_RC Jsi_ValueToNumber(Jsi_Interp *interp, Jsi_Value *v)\n {\n     if (v->vt == JSI_VT_NUMBER) return JSI_OK;\n-    Jsi_Number a = Jsi_ValueToNumberInt(interp, v, 0);\n+    Jsi_Number a;\n+    if (Jsi_ValueToNumberInt(interp, v, 0, &a) != JSI_OK)\n+      return JSI_ERROR;\n     Jsi_ValueReset(interp, &v);\n     Jsi_ValueMakeNumber(interp, &v, a);\n     return JSI_OK;",
        "diff_line_info": {
            "deleted_lines": [
                "    Jsi_Number a = Jsi_ValueToNumberInt(interp, v, 0);"
            ],
            "added_lines": [
                "    Jsi_Number a;",
                "    if (Jsi_ValueToNumberInt(interp, v, 0, &a) != JSI_OK)",
                "      return JSI_ERROR;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46506",
        "func_name": "pcmacdon/jsish/Jsi_ValueCmp",
        "description": "There is an Assertion 'v->d.lval != v' failed at src/jsiValue.c in Jsish v3.5.0.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/c8eae8318fac1498e02755ebaa9a433461d0cd64",
        "commit_title": "Fixes #52",
        "commit_text": " FossilOrigin-Name: a2f9eec3e383af808f2e06992ad1715d414710afab378267a18db86d99894137",
        "func_before": "int Jsi_ValueCmp(Jsi_Interp *interp, Jsi_Value *v1, Jsi_Value* v2, int flags)\n{\n    DECL_VALINIT(res1);\n    DECL_VALINIT(res2);\n    int r = 1;\n    int nocase = (flags&JSI_SORT_NOCASE), dict = ((flags & JSI_SORT_DICT));\n    if (v1 == v2)\n        return 1;\n    if (v1->vt != v2->vt) {\n        jsi_ValueToPrimitiveRes(interp, v1, &res1);\n        jsi_ValueToPrimitiveRes(interp, v2, &res2);\n        v1 = &res1;\n        v2 = &res2;\n    }\n    if (v1->vt != v2->vt) {\n        if ((flags&JSI_CMP_EXACT))\n            return 1;\n        if ((v1->vt == JSI_VT_UNDEF || v1->vt == JSI_VT_NULL) && \n            (v2->vt == JSI_VT_UNDEF || v2->vt == JSI_VT_NULL)) {\n            r = 0;\n        } else {\n            Jsi_Number n1, n2;\n            n1 = Jsi_ValueToNumberInt(interp, v1, 0);\n            n2 = Jsi_ValueToNumberInt(interp, v2, 0);\n            r = (n2 - n1);\n        }\n    } else {\n        switch (v1->vt) {\n            case JSI_VT_NUMBER:\n                if (v2->d.num == v1->d.num) return 0;\n                r = (v2->d.num < v1->d.num ? -1 : 1);\n                break;\n            case JSI_VT_BOOL:\n                r = (v2->d.val - v1->d.val);\n                break;\n            case JSI_VT_STRING:\n                r = (Jsi_StrcmpDict(v2->d.s.str, v1->d.s.str, nocase, dict));\n                break;\n            case JSI_VT_OBJECT:\n                /* TODO: refer to objects joined to each other */\n                if (v2->vt != JSI_VT_OBJECT)\n                    r = 1;\n                else if (v1->d.obj->ot == JSI_OT_STRING && v2->d.obj->ot == JSI_OT_STRING)\n                    r = (Jsi_StrcmpDict(v2->d.obj->d.s.str, v1->d.obj->d.s.str, nocase, dict));\n                else\n                    r = (v2->d.obj - v1->d.obj);\n                break;\n            case JSI_VT_UNDEF:\n            case JSI_VT_NULL:\n                r = 0;\n                break;\n            default:\n                Jsi_LogBug(\"Unexpected value type\");\n        }\n    }\n    return r;\n}",
        "func": "int Jsi_ValueCmp(Jsi_Interp *interp, Jsi_Value *v1, Jsi_Value* v2, int flags)\n{\n    DECL_VALINIT(res1);\n    DECL_VALINIT(res2);\n    int r = 1;\n    int nocase = (flags&JSI_SORT_NOCASE), dict = ((flags & JSI_SORT_DICT));\n    if (v1 == v2)\n        return 1;\n    if (v1->vt != v2->vt) {\n        jsi_ValueToPrimitiveRes(interp, v1, &res1);\n        jsi_ValueToPrimitiveRes(interp, v2, &res2);\n        v1 = &res1;\n        v2 = &res2;\n    }\n    if (v1->vt != v2->vt) {\n        if ((flags&JSI_CMP_EXACT))\n            return 1;\n        if ((v1->vt == JSI_VT_UNDEF || v1->vt == JSI_VT_NULL) && \n            (v2->vt == JSI_VT_UNDEF || v2->vt == JSI_VT_NULL)) {\n            r = 0;\n        } else {\n            Jsi_Number n1, n2;\n            Jsi_ValueToNumberInt(interp, v1, 0, &n1);\n            Jsi_ValueToNumberInt(interp, v2, 0, &n2);\n            r = (n2 - n1);\n        }\n    } else {\n        switch (v1->vt) {\n            case JSI_VT_NUMBER:\n                if (v2->d.num == v1->d.num) return 0;\n                r = (v2->d.num < v1->d.num ? -1 : 1);\n                break;\n            case JSI_VT_BOOL:\n                r = (v2->d.val - v1->d.val);\n                break;\n            case JSI_VT_STRING:\n                r = (Jsi_StrcmpDict(v2->d.s.str, v1->d.s.str, nocase, dict));\n                break;\n            case JSI_VT_OBJECT:\n                /* TODO: refer to objects joined to each other */\n                if (v2->vt != JSI_VT_OBJECT)\n                    r = 1;\n                else if (v1->d.obj->ot == JSI_OT_STRING && v2->d.obj->ot == JSI_OT_STRING)\n                    r = (Jsi_StrcmpDict(v2->d.obj->d.s.str, v1->d.obj->d.s.str, nocase, dict));\n                else\n                    r = (v2->d.obj - v1->d.obj);\n                break;\n            case JSI_VT_UNDEF:\n            case JSI_VT_NULL:\n                r = 0;\n                break;\n            default:\n                Jsi_LogBug(\"Unexpected value type\");\n        }\n    }\n    return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,8 +20,8 @@\n             r = 0;\n         } else {\n             Jsi_Number n1, n2;\n-            n1 = Jsi_ValueToNumberInt(interp, v1, 0);\n-            n2 = Jsi_ValueToNumberInt(interp, v2, 0);\n+            Jsi_ValueToNumberInt(interp, v1, 0, &n1);\n+            Jsi_ValueToNumberInt(interp, v2, 0, &n2);\n             r = (n2 - n1);\n         }\n     } else {",
        "diff_line_info": {
            "deleted_lines": [
                "            n1 = Jsi_ValueToNumberInt(interp, v1, 0);",
                "            n2 = Jsi_ValueToNumberInt(interp, v2, 0);"
            ],
            "added_lines": [
                "            Jsi_ValueToNumberInt(interp, v1, 0, &n1);",
                "            Jsi_ValueToNumberInt(interp, v2, 0, &n2);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46506",
        "func_name": "pcmacdon/jsish/jsi_ValueToOInt32",
        "description": "There is an Assertion 'v->d.lval != v' failed at src/jsiValue.c in Jsish v3.5.0.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/c8eae8318fac1498e02755ebaa9a433461d0cd64",
        "commit_title": "Fixes #52",
        "commit_text": " FossilOrigin-Name: a2f9eec3e383af808f2e06992ad1715d414710afab378267a18db86d99894137",
        "func_before": "int jsi_ValueToOInt32(Jsi_Interp *interp, Jsi_Value *v)\n{\n    Jsi_Number a = Jsi_ValueToNumberInt(interp, v, 1);\n    Jsi_ValueReset(interp,&v);\n    Jsi_ValueMakeNumber(interp, &v, a);\n    return (int)a;\n}",
        "func": "int jsi_ValueToOInt32(Jsi_Interp *interp, Jsi_Value *v)\n{\n    Jsi_Number a;\n    if (Jsi_ValueToNumberInt(interp, v, 1, &a) != JSI_OK)\n      return JSI_ERROR;\n    Jsi_ValueReset(interp,&v);\n    Jsi_ValueMakeNumber(interp, &v, a);\n    return (int)a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n int jsi_ValueToOInt32(Jsi_Interp *interp, Jsi_Value *v)\n {\n-    Jsi_Number a = Jsi_ValueToNumberInt(interp, v, 1);\n+    Jsi_Number a;\n+    if (Jsi_ValueToNumberInt(interp, v, 1, &a) != JSI_OK)\n+      return JSI_ERROR;\n     Jsi_ValueReset(interp,&v);\n     Jsi_ValueMakeNumber(interp, &v, a);\n     return (int)a;",
        "diff_line_info": {
            "deleted_lines": [
                "    Jsi_Number a = Jsi_ValueToNumberInt(interp, v, 1);"
            ],
            "added_lines": [
                "    Jsi_Number a;",
                "    if (Jsi_ValueToNumberInt(interp, v, 1, &a) != JSI_OK)",
                "      return JSI_ERROR;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46506",
        "func_name": "pcmacdon/jsish/parseIntCmd",
        "description": "There is an Assertion 'v->d.lval != v' failed at src/jsiValue.c in Jsish v3.5.0.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/c8eae8318fac1498e02755ebaa9a433461d0cd64",
        "commit_title": "Fixes #52",
        "commit_text": " FossilOrigin-Name: a2f9eec3e383af808f2e06992ad1715d414710afab378267a18db86d99894137",
        "func_before": "static Jsi_RC parseIntCmd(Jsi_Interp *interp, Jsi_Value *args, Jsi_Value *_this,\n    Jsi_Value **ret, Jsi_Func *funcPtr)\n{\n    Jsi_Wide w = 0;\n    Jsi_Number d = 0;\n\n    Jsi_Value *v = Jsi_ValueArrayIndex(interp, args, 0);\n    Jsi_Value *bv = Jsi_ValueArrayIndex(interp, args, 1);\n    if (!v)\n        return JSI_ERROR;\n    char *eptr, *str = Jsi_ValueString(interp, v, NULL);\n    int base = 0;\n    if (!str) {\n        if (Jsi_ValueIsNumber(interp, v))\n            Jsi_GetNumberFromValue(interp, v, &d);\n        else\n            goto nanval;\n    }\n    else if (str[0] == '0' && str[1] == 'x')\n        d = (Jsi_Number)strtoll(str, &eptr, 16);\n    else if (str[0] == '0' && !bv)\n        d = (Jsi_Number)strtoll(str, &eptr, 8);\n    else if (base == 0 && !bv)\n        d = Jsi_ValueToNumberInt(interp, v, 1);\n    else {\n        if (str == NULL || JSI_OK != Jsi_GetIntFromValue(interp, bv, &base) || base<2 || base>36)\n            return JSI_ERROR;\n        d = (Jsi_Number)strtoll(str, &eptr, base);\n    }\n    if (Jsi_NumberIsNaN(d) || (Jsi_NumberIsFinite(d)==0 && Jsi_GetDoubleFromValue(interp, v, &d) != JSI_OK))\nnanval:\n        Jsi_ValueDup2(interp, ret, interp->NaNValue);\n    else {\n        w = (Jsi_Wide)d;\n        Jsi_ValueMakeNumber(interp, ret, (Jsi_Number)w);\n    }\n    return JSI_OK;\n}",
        "func": "static Jsi_RC parseIntCmd(Jsi_Interp *interp, Jsi_Value *args, Jsi_Value *_this,\n    Jsi_Value **ret, Jsi_Func *funcPtr)\n{\n    Jsi_Wide w = 0;\n    Jsi_Number d = 0;\n\n    Jsi_Value *v = Jsi_ValueArrayIndex(interp, args, 0);\n    Jsi_Value *bv = Jsi_ValueArrayIndex(interp, args, 1);\n    if (!v)\n        return JSI_ERROR;\n    char *eptr, *str = Jsi_ValueString(interp, v, NULL);\n    int base = 0;\n    if (!str) {\n        if (Jsi_ValueIsNumber(interp, v))\n            Jsi_GetNumberFromValue(interp, v, &d);\n        else\n            goto nanval;\n    }\n    else if (str[0] == '0' && str[1] == 'x')\n        d = (Jsi_Number)strtoll(str, &eptr, 16);\n    else if (str[0] == '0' && !bv)\n        d = (Jsi_Number)strtoll(str, &eptr, 8);\n    else if (base == 0 && !bv) {\n        if (Jsi_ValueToNumberInt(interp, v, 1, &d) != JSI_OK)\n          return JSI_ERROR;\n    } else {\n        if (str == NULL || JSI_OK != Jsi_GetIntFromValue(interp, bv, &base) || base<2 || base>36)\n            return JSI_ERROR;\n        d = (Jsi_Number)strtoll(str, &eptr, base);\n    }\n    if (Jsi_NumberIsNaN(d) || (Jsi_NumberIsFinite(d)==0 && Jsi_GetDoubleFromValue(interp, v, &d) != JSI_OK))\nnanval:\n        Jsi_ValueDup2(interp, ret, interp->NaNValue);\n    else {\n        w = (Jsi_Wide)d;\n        Jsi_ValueMakeNumber(interp, ret, (Jsi_Number)w);\n    }\n    return JSI_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,9 +20,10 @@\n         d = (Jsi_Number)strtoll(str, &eptr, 16);\n     else if (str[0] == '0' && !bv)\n         d = (Jsi_Number)strtoll(str, &eptr, 8);\n-    else if (base == 0 && !bv)\n-        d = Jsi_ValueToNumberInt(interp, v, 1);\n-    else {\n+    else if (base == 0 && !bv) {\n+        if (Jsi_ValueToNumberInt(interp, v, 1, &d) != JSI_OK)\n+          return JSI_ERROR;\n+    } else {\n         if (str == NULL || JSI_OK != Jsi_GetIntFromValue(interp, bv, &base) || base<2 || base>36)\n             return JSI_ERROR;\n         d = (Jsi_Number)strtoll(str, &eptr, base);",
        "diff_line_info": {
            "deleted_lines": [
                "    else if (base == 0 && !bv)",
                "        d = Jsi_ValueToNumberInt(interp, v, 1);",
                "    else {"
            ],
            "added_lines": [
                "    else if (base == 0 && !bv) {",
                "        if (Jsi_ValueToNumberInt(interp, v, 1, &d) != JSI_OK)",
                "          return JSI_ERROR;",
                "    } else {"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46506",
        "func_name": "pcmacdon/jsish/Jsi_GetIntFromValueBase",
        "description": "There is an Assertion 'v->d.lval != v' failed at src/jsiValue.c in Jsish v3.5.0.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/c8eae8318fac1498e02755ebaa9a433461d0cd64",
        "commit_title": "Fixes #52",
        "commit_text": " FossilOrigin-Name: a2f9eec3e383af808f2e06992ad1715d414710afab378267a18db86d99894137",
        "func_before": "Jsi_RC Jsi_GetIntFromValueBase(Jsi_Interp* interp, Jsi_Value *value, int *n, int base, int flags)\n{\n    int noMsg = (flags & JSI_NO_ERRMSG);\n    /* TODO: inefficient to convert to double then back. */\n    if (!value)\n        return JSI_ERROR;\n    Jsi_Number d = Jsi_ValueToNumberInt(interp, value, 1);\n    if (!Jsi_NumberIsFinite(d))\n    {\n        if (!noMsg)\n            Jsi_LogError(\"invalid number\");\n        return JSI_ERROR;\n    }\n    Jsi_ValueReset(interp,&value);\n    Jsi_ValueMakeNumber(interp, &value, d);\n    *n = (int)d;\n    return JSI_OK;\n}",
        "func": "Jsi_RC Jsi_GetIntFromValueBase(Jsi_Interp* interp, Jsi_Value *value, int *n, int base, int flags)\n{\n    int noMsg = (flags & JSI_NO_ERRMSG);\n    /* TODO: inefficient to convert to double then back. */\n    if (!value)\n        return JSI_ERROR;\n    Jsi_Number d;\n    if (Jsi_ValueToNumberInt(interp, value, 1, &d) != JSI_OK)\n      return JSI_ERROR;\n    if (!Jsi_NumberIsFinite(d))\n    {\n        if (!noMsg)\n            Jsi_LogError(\"invalid number\");\n        return JSI_ERROR;\n    }\n    Jsi_ValueReset(interp,&value);\n    Jsi_ValueMakeNumber(interp, &value, d);\n    *n = (int)d;\n    return JSI_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,9 @@\n     /* TODO: inefficient to convert to double then back. */\n     if (!value)\n         return JSI_ERROR;\n-    Jsi_Number d = Jsi_ValueToNumberInt(interp, value, 1);\n+    Jsi_Number d;\n+    if (Jsi_ValueToNumberInt(interp, value, 1, &d) != JSI_OK)\n+      return JSI_ERROR;\n     if (!Jsi_NumberIsFinite(d))\n     {\n         if (!noMsg)",
        "diff_line_info": {
            "deleted_lines": [
                "    Jsi_Number d = Jsi_ValueToNumberInt(interp, value, 1);"
            ],
            "added_lines": [
                "    Jsi_Number d;",
                "    if (Jsi_ValueToNumberInt(interp, value, 1, &d) != JSI_OK)",
                "      return JSI_ERROR;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23564",
        "func_name": "tensorflow/ResourceHandle::FromProto",
        "description": "Tensorflow is an Open Source Machine Learning Framework. When decoding a resource handle tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/14fea662350e7c26eb5fe1be2ac31704e5682ee6",
        "commit_title": "Prevent `CHECK`-fail when decoding resource handles from proto",
        "commit_text": " In certain scenarios, the proto might contain tensors that have too many elements (overflow). This is a `CHECK`-fail in general, but we should prevent this, given how many CVEs caused by that we have received this year (a large fraction of 200).  PiperOrigin-RevId: 408049766",
        "func_before": "void ResourceHandle::FromProto(const ResourceHandleProto& proto) {\n  set_device(proto.device());\n  set_container(proto.container());\n  set_name(proto.name());\n  set_hash_code(proto.hash_code());\n  set_maybe_type_name(proto.maybe_type_name());\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes;\n  for (const auto& dtype_and_shape : proto.dtypes_and_shapes()) {\n    DataType dtype = dtype_and_shape.dtype();\n    PartialTensorShape shape(dtype_and_shape.shape());\n    dtypes_and_shapes.push_back(DtypeAndPartialTensorShape{dtype, shape});\n  }\n  dtypes_and_shapes_ = std::move(dtypes_and_shapes);\n}",
        "func": "Status ResourceHandle::FromProto(const ResourceHandleProto& proto) {\n  set_device(proto.device());\n  set_container(proto.container());\n  set_name(proto.name());\n  set_hash_code(proto.hash_code());\n  set_maybe_type_name(proto.maybe_type_name());\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes;\n  for (const auto& dtype_and_shape : proto.dtypes_and_shapes()) {\n    DataType dtype = dtype_and_shape.dtype();\n    PartialTensorShape shape;\n    Status s = PartialTensorShape::BuildPartialTensorShape(\n        dtype_and_shape.shape(), &shape);\n    if (!s.ok()) {\n      return s;\n    }\n    dtypes_and_shapes.push_back(DtypeAndPartialTensorShape{dtype, shape});\n  }\n  dtypes_and_shapes_ = std::move(dtypes_and_shapes);\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void ResourceHandle::FromProto(const ResourceHandleProto& proto) {\n+Status ResourceHandle::FromProto(const ResourceHandleProto& proto) {\n   set_device(proto.device());\n   set_container(proto.container());\n   set_name(proto.name());\n@@ -7,8 +7,14 @@\n   std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes;\n   for (const auto& dtype_and_shape : proto.dtypes_and_shapes()) {\n     DataType dtype = dtype_and_shape.dtype();\n-    PartialTensorShape shape(dtype_and_shape.shape());\n+    PartialTensorShape shape;\n+    Status s = PartialTensorShape::BuildPartialTensorShape(\n+        dtype_and_shape.shape(), &shape);\n+    if (!s.ok()) {\n+      return s;\n+    }\n     dtypes_and_shapes.push_back(DtypeAndPartialTensorShape{dtype, shape});\n   }\n   dtypes_and_shapes_ = std::move(dtypes_and_shapes);\n+  return Status::OK();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void ResourceHandle::FromProto(const ResourceHandleProto& proto) {",
                "    PartialTensorShape shape(dtype_and_shape.shape());"
            ],
            "added_lines": [
                "Status ResourceHandle::FromProto(const ResourceHandleProto& proto) {",
                "    PartialTensorShape shape;",
                "    Status s = PartialTensorShape::BuildPartialTensorShape(",
                "        dtype_and_shape.shape(), &shape);",
                "    if (!s.ok()) {",
                "      return s;",
                "    }",
                "  return Status::OK();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23564",
        "func_name": "tensorflow/ResourceHandle::ParseFromString",
        "description": "Tensorflow is an Open Source Machine Learning Framework. When decoding a resource handle tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/14fea662350e7c26eb5fe1be2ac31704e5682ee6",
        "commit_title": "Prevent `CHECK`-fail when decoding resource handles from proto",
        "commit_text": " In certain scenarios, the proto might contain tensors that have too many elements (overflow). This is a `CHECK`-fail in general, but we should prevent this, given how many CVEs caused by that we have received this year (a large fraction of 200).  PiperOrigin-RevId: 408049766",
        "func_before": "bool ResourceHandle::ParseFromString(const string& s) {\n  ResourceHandleProto proto;\n  const bool status = proto.ParseFromString(s);\n  if (status) FromProto(proto);\n  return status;\n}",
        "func": "bool ResourceHandle::ParseFromString(const string& s) {\n  ResourceHandleProto proto;\n  return proto.ParseFromString(s) && FromProto(proto).ok();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,4 @@\n bool ResourceHandle::ParseFromString(const string& s) {\n   ResourceHandleProto proto;\n-  const bool status = proto.ParseFromString(s);\n-  if (status) FromProto(proto);\n-  return status;\n+  return proto.ParseFromString(s) && FromProto(proto).ok();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  const bool status = proto.ParseFromString(s);",
                "  if (status) FromProto(proto);",
                "  return status;"
            ],
            "added_lines": [
                "  return proto.ParseFromString(s) && FromProto(proto).ok();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23564",
        "func_name": "tensorflow/DecodeResourceHandleList",
        "description": "Tensorflow is an Open Source Machine Learning Framework. When decoding a resource handle tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/14fea662350e7c26eb5fe1be2ac31704e5682ee6",
        "commit_title": "Prevent `CHECK`-fail when decoding resource handles from proto",
        "commit_text": " In certain scenarios, the proto might contain tensors that have too many elements (overflow). This is a `CHECK`-fail in general, but we should prevent this, given how many CVEs caused by that we have received this year (a large fraction of 200).  PiperOrigin-RevId: 408049766",
        "func_before": "bool DecodeResourceHandleList(std::unique_ptr<port::StringListDecoder> d,\n                              ResourceHandle* ps, int64_t n) {\n  std::vector<uint32> sizes(n);\n  if (!d->ReadSizes(&sizes)) return false;\n\n  ResourceHandleProto proto;\n  for (int i = 0; i < n; ++i) {\n    if (!proto.ParseFromArray(d->Data(sizes[i]), sizes[i])) {\n      return false;\n    }\n    ps[i].FromProto(proto);\n  }\n  return true;\n}",
        "func": "bool DecodeResourceHandleList(std::unique_ptr<port::StringListDecoder> d,\n                              ResourceHandle* ps, int64_t n) {\n  std::vector<uint32> sizes(n);\n  if (!d->ReadSizes(&sizes)) return false;\n\n  ResourceHandleProto proto;\n  for (int i = 0; i < n; ++i) {\n    if (!proto.ParseFromArray(d->Data(sizes[i]), sizes[i])) {\n      return false;\n    }\n    if (!ps[i].FromProto(proto).ok()) {\n      return false;\n    }\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,9 @@\n     if (!proto.ParseFromArray(d->Data(sizes[i]), sizes[i])) {\n       return false;\n     }\n-    ps[i].FromProto(proto);\n+    if (!ps[i].FromProto(proto).ok()) {\n+      return false;\n+    }\n   }\n   return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    ps[i].FromProto(proto);"
            ],
            "added_lines": [
                "    if (!ps[i].FromProto(proto).ok()) {",
                "      return false;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23564",
        "func_name": "tensorflow/ResourceHandle::ResourceHandle",
        "description": "Tensorflow is an Open Source Machine Learning Framework. When decoding a resource handle tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/14fea662350e7c26eb5fe1be2ac31704e5682ee6",
        "commit_title": "Prevent `CHECK`-fail when decoding resource handles from proto",
        "commit_text": " In certain scenarios, the proto might contain tensors that have too many elements (overflow). This is a `CHECK`-fail in general, but we should prevent this, given how many CVEs caused by that we have received this year (a large fraction of 200).  PiperOrigin-RevId: 408049766",
        "func_before": "ResourceHandle::ResourceHandle(const ResourceHandleProto& proto) {\n  FromProto(proto);\n}",
        "func": "ResourceHandle::ResourceHandle(const ResourceHandleProto& proto) {\n  TF_CHECK_OK(FromProto(proto));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,3 +1,3 @@\n ResourceHandle::ResourceHandle(const ResourceHandleProto& proto) {\n-  FromProto(proto);\n+  TF_CHECK_OK(FromProto(proto));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  FromProto(proto);"
            ],
            "added_lines": [
                "  TF_CHECK_OK(FromProto(proto));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23565",
        "func_name": "tensorflow/RepeatedAttrDefEqual",
        "description": "Tensorflow is an Open Source Machine Learning Framework. An attacker can trigger denial of service via assertion failure by altering a `SavedModel` on disk such that `AttrDef`s of some operation are duplicated. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c2b31ff2d3151acb230edc3f5b1832d2c713a9e0",
        "commit_title": "Remove a `DCHECK`-fail, log an error instead.",
        "commit_text": " `DCHECK` in debug mode results in crashes. TensorFlow has had multiple vulnerabilities due to this.  Outside of debug mode, `DCHECK` is a no-op.  A better alternative is to report an error to the log buffer and continue. This should happen both in debug mode and in prod mode.  PiperOrigin-RevId: 408375925",
        "func_before": "bool RepeatedAttrDefEqual(\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a1,\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n  std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n  for (const OpDef::AttrDef& def : a1) {\n    DCHECK(a1_set.find(def.name()) == a1_set.end())\n        << \"AttrDef names must be unique, but '\" << def.name()\n        << \"' appears more than once\";\n    a1_set[def.name()] = &def;\n  }\n  for (const OpDef::AttrDef& def : a2) {\n    auto iter = a1_set.find(def.name());\n    if (iter == a1_set.end()) return false;\n    if (!AttrDefEqual(*iter->second, def)) return false;\n    a1_set.erase(iter);\n  }\n  if (!a1_set.empty()) return false;\n  return true;\n}",
        "func": "bool RepeatedAttrDefEqual(\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a1,\n    const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n  std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n  for (const OpDef::AttrDef& def : a1) {\n    if (a1_set.find(def.name()) != a1_set.end()) {\n      LOG(ERROR) << \"AttrDef names must be unique, but '\" << def.name()\n                 << \"' appears more than once\";\n    }\n    a1_set[def.name()] = &def;\n  }\n  for (const OpDef::AttrDef& def : a2) {\n    auto iter = a1_set.find(def.name());\n    if (iter == a1_set.end()) return false;\n    if (!AttrDefEqual(*iter->second, def)) return false;\n    a1_set.erase(iter);\n  }\n  if (!a1_set.empty()) return false;\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,9 +3,10 @@\n     const protobuf::RepeatedPtrField<OpDef::AttrDef>& a2) {\n   std::unordered_map<string, const OpDef::AttrDef*> a1_set;\n   for (const OpDef::AttrDef& def : a1) {\n-    DCHECK(a1_set.find(def.name()) == a1_set.end())\n-        << \"AttrDef names must be unique, but '\" << def.name()\n-        << \"' appears more than once\";\n+    if (a1_set.find(def.name()) != a1_set.end()) {\n+      LOG(ERROR) << \"AttrDef names must be unique, but '\" << def.name()\n+                 << \"' appears more than once\";\n+    }\n     a1_set[def.name()] = &def;\n   }\n   for (const OpDef::AttrDef& def : a2) {",
        "diff_line_info": {
            "deleted_lines": [
                "    DCHECK(a1_set.find(def.name()) == a1_set.end())",
                "        << \"AttrDef names must be unique, but '\" << def.name()",
                "        << \"' appears more than once\";"
            ],
            "added_lines": [
                "    if (a1_set.find(def.name()) != a1_set.end()) {",
                "      LOG(ERROR) << \"AttrDef names must be unique, but '\" << def.name()",
                "                 << \"' appears more than once\";",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23570",
        "func_name": "tensorflow/SpecializeType",
        "description": "Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, TensorFlow might do a null-dereference if attributes of some mutable arguments to some operations are missing from the proto. This is guarded by a `DCHECK`. However, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the dereferencing of the null pointer, whereas in the second case it results in a crash due to the assertion failure. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8a513cec4bec15961fbfdedcaa5376522980455c",
        "commit_title": "Prevent null dereference read in `SpecializeType()`",
        "commit_text": " For some adversarial protos, the attribute for a key might not exist.  PiperOrigin-RevId: 408382090",
        "func_before": "StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n                                     const OpDef& op_def) {\n  FullTypeDef ft;\n  ft.set_type_id(TFT_PRODUCT);\n\n  for (int i = 0; i < op_def.output_arg_size(); i++) {\n    auto* t = ft.add_args();\n\n    *t = op_def.output_arg(i).experimental_full_type();\n\n    // Resolve dependent types. The convention for op registrations is to use\n    // attributes as type variables.\n    // See https://www.tensorflow.org/guide/create_op#type_polymorphism.\n    // Once the op signature can be defined entirely in FullType, this\n    // convention can be deprecated.\n    //\n    // Note: While this code performs some basic verifications, it generally\n    // assumes consistent op defs and attributes. If more complete\n    // verifications are needed, they should be done by separately, and in a\n    // way that can be reused for type inference.\n    for (int j = 0; j < t->args_size(); j++) {\n      auto* arg = t->mutable_args(i);\n      if (arg->type_id() == TFT_VAR) {\n        const auto* attr = attrs.Find(arg->s());\n        DCHECK(attr != nullptr);\n        if (attr->value_case() == AttrValue::kList) {\n          const auto& attr_list = attr->list();\n          arg->set_type_id(TFT_PRODUCT);\n          for (int i = 0; i < attr_list.type_size(); i++) {\n            map_dtype_to_tensor(attr_list.type(i), arg->add_args());\n          }\n\n        } else if (attr->value_case() == AttrValue::kType) {\n          map_dtype_to_tensor(attr->type(), arg);\n\n        } else {\n          return Status(error::UNIMPLEMENTED,\n                        absl::StrCat(\"unknown attribute type\",\n                                     attrs.DebugString(), \" key=\", arg->s()));\n        }\n\n        arg->clear_s();\n      }\n    }\n  }\n\n  return ft;\n}",
        "func": "StatusOr<FullTypeDef> SpecializeType(const AttrSlice& attrs,\n                                     const OpDef& op_def) {\n  FullTypeDef ft;\n  ft.set_type_id(TFT_PRODUCT);\n\n  for (int i = 0; i < op_def.output_arg_size(); i++) {\n    auto* t = ft.add_args();\n\n    *t = op_def.output_arg(i).experimental_full_type();\n\n    // Resolve dependent types. The convention for op registrations is to use\n    // attributes as type variables.\n    // See https://www.tensorflow.org/guide/create_op#type_polymorphism.\n    // Once the op signature can be defined entirely in FullType, this\n    // convention can be deprecated.\n    //\n    // Note: While this code performs some basic verifications, it generally\n    // assumes consistent op defs and attributes. If more complete\n    // verifications are needed, they should be done by separately, and in a\n    // way that can be reused for type inference.\n    for (int j = 0; j < t->args_size(); j++) {\n      auto* arg = t->mutable_args(i);\n      if (arg->type_id() == TFT_VAR) {\n        const auto* attr = attrs.Find(arg->s());\n        if (attr == nullptr) {\n          return Status(\n              error::INVALID_ARGUMENT,\n              absl::StrCat(\"Could not find an attribute for key \", arg->s()));\n        }\n        if (attr->value_case() == AttrValue::kList) {\n          const auto& attr_list = attr->list();\n          arg->set_type_id(TFT_PRODUCT);\n          for (int i = 0; i < attr_list.type_size(); i++) {\n            map_dtype_to_tensor(attr_list.type(i), arg->add_args());\n          }\n\n        } else if (attr->value_case() == AttrValue::kType) {\n          map_dtype_to_tensor(attr->type(), arg);\n\n        } else {\n          return Status(error::UNIMPLEMENTED,\n                        absl::StrCat(\"unknown attribute type\",\n                                     attrs.DebugString(), \" key=\", arg->s()));\n        }\n\n        arg->clear_s();\n      }\n    }\n  }\n\n  return ft;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,7 +22,11 @@\n       auto* arg = t->mutable_args(i);\n       if (arg->type_id() == TFT_VAR) {\n         const auto* attr = attrs.Find(arg->s());\n-        DCHECK(attr != nullptr);\n+        if (attr == nullptr) {\n+          return Status(\n+              error::INVALID_ARGUMENT,\n+              absl::StrCat(\"Could not find an attribute for key \", arg->s()));\n+        }\n         if (attr->value_case() == AttrValue::kList) {\n           const auto& attr_list = attr->list();\n           arg->set_type_id(TFT_PRODUCT);",
        "diff_line_info": {
            "deleted_lines": [
                "        DCHECK(attr != nullptr);"
            ],
            "added_lines": [
                "        if (attr == nullptr) {",
                "          return Status(",
                "              error::INVALID_ARGUMENT,",
                "              absl::StrCat(\"Could not find an attribute for key \", arg->s()));",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23571",
        "func_name": "tensorflow/Tensor::FromProto",
        "description": "Tensorflow is an Open Source Machine Learning Framework. When decoding a tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments, if the tensors have an invalid `dtype` and 0 elements or an invalid shape. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/5b491cd5e41ad63735161cec9c2a568172c8b6a3",
        "commit_title": "Validate `proto.dtype()` before calling `set_dtype()`.",
        "commit_text": " This prevents a `DCHECK`-fail when the proto contains an invalid dtype for a tensor shape with 0 elements or for an incomplete tensor shape.  PiperOrigin-RevId: 408369083",
        "func_before": "bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}",
        "func": "bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  } else {\n    // Handle the case of empty tensors (N = 0) or tensors with incomplete shape\n    // (N = -1). All other values of `shape.num_elements()` should be invalid by\n    // construction.\n    // Here, we just need to validate that the `proto.dtype()` value is valid.\n    bool dtype_error = false;\n    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,\n                       dtype_error = true);\n    if (dtype_error) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,6 +16,15 @@\n                          dtype_error = true, dtype_error = true);\n     }\n     if (dtype_error || p == nullptr) return false;\n+  } else {\n+    // Handle the case of empty tensors (N = 0) or tensors with incomplete shape\n+    // (N = -1). All other values of `shape.num_elements()` should be invalid by\n+    // construction.\n+    // Here, we just need to validate that the `proto.dtype()` value is valid.\n+    bool dtype_error = false;\n+    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,\n+                       dtype_error = true);\n+    if (dtype_error) return false;\n   }\n   shape_ = shape;\n   set_dtype(proto.dtype());",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  } else {",
                "    // Handle the case of empty tensors (N = 0) or tensors with incomplete shape",
                "    // (N = -1). All other values of `shape.num_elements()` should be invalid by",
                "    // construction.",
                "    // Here, we just need to validate that the `proto.dtype()` value is valid.",
                "    bool dtype_error = false;",
                "    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,",
                "                       dtype_error = true);",
                "    if (dtype_error) return false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23572",
        "func_name": "tensorflow/InferenceContext::PreInputInit",
        "description": "Tensorflow is an Open Source Machine Learning Framework. Under certain scenarios, TensorFlow can fail to specialize a type during shape inference. This case is covered by the `DCHECK` function however, `DCHECK` is a no-op in production builds and an assertion failure in debug builds. In the first case execution proceeds to the `ValueOrDie` line. This results in an assertion failure as `ret` contains an error `Status`, not a value. In the second case we also get a crash due to the assertion failure. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, and TensorFlow 2.6.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/cb164786dc891ea11d3a900e90367c339305dc7b",
        "commit_title": "Properly handle the case where `SpecializeType()` returns an error `Status`.",
        "commit_text": " If the error case in `SpecializeType()` is reached, then we would get a crash when trying to access the value of an errorenous `StatusOr` object  PiperOrigin-RevId: 408380069",
        "func_before": "void InferenceContext::PreInputInit(\n    const OpDef& op_def, const std::vector<const Tensor*>& input_tensors,\n    const std::vector<ShapeHandle>& input_tensors_as_shapes) {\n  // TODO(mdan): This is also done at graph construction. Run only here instead?\n  const auto ret = full_type::SpecializeType(attrs_, op_def);\n  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\n  ret_types_ = ret.ValueOrDie();\n\n  input_tensors_ = input_tensors;\n  input_tensors_as_shapes_ = input_tensors_as_shapes;\n\n  construction_status_ =\n      NameRangesForNode(attrs_, op_def, &input_name_map_, &output_name_map_);\n  if (!construction_status_.ok()) return;\n\n  int num_outputs = 0;\n  for (const auto& e : output_name_map_) {\n    num_outputs = std::max(num_outputs, e.second.second);\n  }\n  outputs_.assign(num_outputs, nullptr);\n  output_handle_shapes_and_types_.resize(num_outputs);\n}",
        "func": "void InferenceContext::PreInputInit(\n    const OpDef& op_def, const std::vector<const Tensor*>& input_tensors,\n    const std::vector<ShapeHandle>& input_tensors_as_shapes) {\n  // TODO(mdan): This is also done at graph construction. Run only here instead?\n  const auto ret = full_type::SpecializeType(attrs_, op_def);\n  if (!ret.status().ok()) {\n    construction_status_ = ret.status();\n    return;\n  }\n  ret_types_ = ret.ValueOrDie();\n\n  input_tensors_ = input_tensors;\n  input_tensors_as_shapes_ = input_tensors_as_shapes;\n\n  construction_status_ =\n      NameRangesForNode(attrs_, op_def, &input_name_map_, &output_name_map_);\n  if (!construction_status_.ok()) return;\n\n  int num_outputs = 0;\n  for (const auto& e : output_name_map_) {\n    num_outputs = std::max(num_outputs, e.second.second);\n  }\n  outputs_.assign(num_outputs, nullptr);\n  output_handle_shapes_and_types_.resize(num_outputs);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,10 @@\n     const std::vector<ShapeHandle>& input_tensors_as_shapes) {\n   // TODO(mdan): This is also done at graph construction. Run only here instead?\n   const auto ret = full_type::SpecializeType(attrs_, op_def);\n-  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();\n+  if (!ret.status().ok()) {\n+    construction_status_ = ret.status();\n+    return;\n+  }\n   ret_types_ = ret.ValueOrDie();\n \n   input_tensors_ = input_tensors;",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK(ret.status().ok()) << \"while instantiating types: \" << ret.status();"
            ],
            "added_lines": [
                "  if (!ret.status().ok()) {",
                "    construction_status_ = ret.status();",
                "    return;",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23579",
        "func_name": "tensorflow/DependencyOptimizer::SafeToRemoveIdentity",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `SafeToRemoveIdentity` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/92dba16749fae36c246bec3f9ba474d9ddeb7662",
        "commit_title": "Prevent a null-pointer dereference / `CHECK`-fail in grappler.",
        "commit_text": " PiperOrigin-RevId: 409187354",
        "func_before": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n\n  if (node.input_size() < 1) {\n    // Node lacks input, is invalid\n    return false;\n  }\n\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  CHECK(input != nullptr) << \"node = \" << node.name()\n                          << \" input = \" << node.input(0);\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}",
        "func": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n\n  if (node.input_size() < 1) {\n    // Node lacks input, is invalid\n    return false;\n  }\n\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  if (input == nullptr) {\n    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\n    return false;\n  }\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,8 +17,10 @@\n   }\n \n   const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n-  CHECK(input != nullptr) << \"node = \" << node.name()\n-                          << \" input = \" << node.input(0);\n+  if (input == nullptr) {\n+    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\n+    return false;\n+  }\n   // Don't remove Identity nodes corresponding to Variable reads or following\n   // Recv.\n   if (IsVariable(*input) || IsRecv(*input)) {",
        "diff_line_info": {
            "deleted_lines": [
                "  CHECK(input != nullptr) << \"node = \" << node.name()",
                "                          << \" input = \" << node.input(0);"
            ],
            "added_lines": [
                "  if (input == nullptr) {",
                "    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);",
                "    return false;",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23581",
        "func_name": "tensorflow/CreateConstantTensorAttrValue",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1fb27733f943295d874417630edd3b38b34ce082",
        "commit_title": "Remove `CHECK`-fails from `IsSimplifiableReshape`",
        "commit_text": " PiperOrigin-RevId: 409164987",
        "func_before": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  CHECK_LE(2, node.input_size());\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  CHECK_EQ(1, outputs.size());\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "func": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -557,7 +557,11 @@\n   if (!IsReshape(node)) {\n     return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n   }\n-  CHECK_LE(2, node.input_size());\n+  if (2 > node.input_size()) {\n+    return errors::Internal(\"Node \", node.name(),\n+                            \" must have at most 2 inputs but has \",\n+                            node.input_size());\n+  }\n   const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n   if (!IsReallyConstant(*new_shape)) {\n     return errors::Internal(\"Node \", node.name(), \" has shape \",\n@@ -575,7 +579,11 @@\n   if (!s.ok()) {\n     return errors::Internal(\"Could not evaluate node \", node.name());\n   }\n-  CHECK_EQ(1, outputs.size());\n+  if (outputs.size() != 1) {\n+    return errors::Internal(\"Node \", node.name(),\n+                            \" must have exactly 1 output but has \",\n+                            outputs.size());\n+  }\n \n   const std::vector<OpInfo::TensorProperties>& props =\n       properties.GetInputProperties(node.name());",
        "diff_line_info": {
            "deleted_lines": [
                "  CHECK_LE(2, node.input_size());",
                "  CHECK_EQ(1, outputs.size());"
            ],
            "added_lines": [
                "  if (2 > node.input_size()) {",
                "    return errors::Internal(\"Node \", node.name(),",
                "                            \" must have at most 2 inputs but has \",",
                "                            node.input_size());",
                "  }",
                "  if (outputs.size() != 1) {",
                "    return errors::Internal(\"Node \", node.name(),",
                "                            \" must have exactly 1 output but has \",",
                "                            outputs.size());",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23581",
        "func_name": "tensorflow/CreateConstantTensorAttrValue",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/240655511cd3e701155f944a972db71b6c0b1bb6",
        "commit_title": "Eliminate `CHECK`-fails from `IsSimplifiableReshape` via `MakeShape(<invalid shape>)`",
        "commit_text": " PiperOrigin-RevId: 409166738",
        "func_before": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "func": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -609,14 +609,16 @@\n       int32_t dim = outputs[0]->flat<int32>()(i);\n       shp.push_back(dim);\n     }\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n+    if (!s.ok()) return s;\n   } else {\n     std::vector<int64_t> shp;\n     for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n       int64_t dim = outputs[0]->flat<int64_t>()(i);\n       shp.push_back(dim);\n     }\n-    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n+    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n+    if (!s.ok()) return s;\n   }\n \n   if (!shape.IsCompatibleWith(new_dims)) {",
        "diff_line_info": {
            "deleted_lines": [
                "    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));",
                "    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));"
            ],
            "added_lines": [
                "    s = TensorShapeUtils::MakeShape(shp, &new_dims);",
                "    if (!s.ok()) return s;",
                "    s = TensorShapeUtils::MakeShape(shp, &new_dims);",
                "    if (!s.ok()) return s;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23581",
        "func_name": "tensorflow/CreateConstantTensorAttrValue",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ebc1a2ffe5a7573d905e99bd0ee3568ee07c12c1",
        "commit_title": "Make `IsSimplifiableReshape` return `Status` instead of `bool`.",
        "commit_text": " This is to allow remove `CHECK`-fails in subsequent commits.  PiperOrigin-RevId: 409160987",
        "func_before": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nbool ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return false;\n  }\n  CHECK_LE(2, node.input_size());\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return false;\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return false;\n  }\n  CHECK_EQ(1, outputs.size());\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return false;\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return false;\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return false;\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  return shape.IsCompatibleWith(new_dims);\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "func": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  CHECK_LE(2, node.input_size());\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  CHECK_EQ(1, outputs.size());\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -552,15 +552,17 @@\n   return Status::OK();\n }\n \n-bool ConstantFolding::IsSimplifiableReshape(\n+Status ConstantFolding::IsSimplifiableReshape(\n     const NodeDef& node, const GraphProperties& properties) const {\n   if (!IsReshape(node)) {\n-    return false;\n+    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n   }\n   CHECK_LE(2, node.input_size());\n   const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n   if (!IsReallyConstant(*new_shape)) {\n-    return false;\n+    return errors::Internal(\"Node \", node.name(), \" has shape \",\n+                            new_shape->DebugString(),\n+                            \" which is not a constant\");\n   }\n   TensorVector outputs;\n   auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n@@ -571,22 +573,25 @@\n \n   Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n   if (!s.ok()) {\n-    return false;\n+    return errors::Internal(\"Could not evaluate node \", node.name());\n   }\n   CHECK_EQ(1, outputs.size());\n \n   const std::vector<OpInfo::TensorProperties>& props =\n       properties.GetInputProperties(node.name());\n   if (props.empty()) {\n-    return false;\n+    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n   }\n   const OpInfo::TensorProperties& prop = props[0];\n   if (prop.dtype() == DT_INVALID) {\n-    return false;\n+    return errors::Internal(\"Node \", node.name(), \" has property \",\n+                            prop.DebugString(), \" with invalid dtype\");\n   }\n   const PartialTensorShape shape(prop.shape());\n   if (!shape.IsFullyDefined()) {\n-    return false;\n+    return errors::Internal(\"Node \", node.name(), \" has property \",\n+                            prop.DebugString(), \" with shape \",\n+                            shape.DebugString(), \" which is not fully defined\");\n   }\n \n   PartialTensorShape new_dims;\n@@ -606,7 +611,12 @@\n     TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n   }\n \n-  return shape.IsCompatibleWith(new_dims);\n+  if (!shape.IsCompatibleWith(new_dims)) {\n+    return errors::Internal(\"Expected shape \", shape.DebugString(),\n+                            \"to be compatible with \", new_dims.DebugString());\n+  }\n+\n+  return Status::OK();\n }\n \n #define IS_VALUE_CASE(DTYPE, VALUE)                   \\",
        "diff_line_info": {
            "deleted_lines": [
                "bool ConstantFolding::IsSimplifiableReshape(",
                "    return false;",
                "    return false;",
                "    return false;",
                "    return false;",
                "    return false;",
                "    return false;",
                "  return shape.IsCompatibleWith(new_dims);"
            ],
            "added_lines": [
                "Status ConstantFolding::IsSimplifiableReshape(",
                "    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");",
                "    return errors::Internal(\"Node \", node.name(), \" has shape \",",
                "                            new_shape->DebugString(),",
                "                            \" which is not a constant\");",
                "    return errors::Internal(\"Could not evaluate node \", node.name());",
                "    return errors::Internal(\"Node \", node.name(), \" has no properties\");",
                "    return errors::Internal(\"Node \", node.name(), \" has property \",",
                "                            prop.DebugString(), \" with invalid dtype\");",
                "    return errors::Internal(\"Node \", node.name(), \" has property \",",
                "                            prop.DebugString(), \" with shape \",",
                "                            shape.DebugString(), \" which is not fully defined\");",
                "  if (!shape.IsCompatibleWith(new_dims)) {",
                "    return errors::Internal(\"Expected shape \", shape.DebugString(),",
                "                            \"to be compatible with \", new_dims.DebugString());",
                "  }",
                "",
                "  return Status::OK();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23581",
        "func_name": "tensorflow/ConstantFolding::SimplifyReshape",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The Grappler optimizer in TensorFlow can be used to cause a denial of service by altering a `SavedModel` such that `IsSimplifiableReshape` would trigger `CHECK` failures. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ebc1a2ffe5a7573d905e99bd0ee3568ee07c12c1",
        "commit_title": "Make `IsSimplifiableReshape` return `Status` instead of `bool`.",
        "commit_text": " This is to allow remove `CHECK`-fails in subsequent commits.  PiperOrigin-RevId: 409160987",
        "func_before": "bool ConstantFolding::SimplifyReshape(const GraphProperties& properties,\n                                      bool use_shape_info, NodeDef* node) {\n  if (!use_shape_info || node->attr().count(\"T\") == 0 ||\n      !IsSimplifiableReshape(*node, properties)) {\n    return false;\n  }\n  DataType output_type = node->attr().at(\"T\").type();\n  node->set_op(\"Identity\");\n  EraseRegularNodeAttributes(node);\n  (*node->mutable_attr())[\"T\"].set_type(output_type);\n  *node->mutable_input(1) = AsControlDependency(node->input(1));\n  return true;\n}",
        "func": "bool ConstantFolding::SimplifyReshape(const GraphProperties& properties,\n                                      bool use_shape_info, NodeDef* node) {\n  if (!use_shape_info || node->attr().count(\"T\") == 0 ||\n      !IsSimplifiableReshape(*node, properties).ok()) {\n    return false;\n  }\n  DataType output_type = node->attr().at(\"T\").type();\n  node->set_op(\"Identity\");\n  EraseRegularNodeAttributes(node);\n  (*node->mutable_attr())[\"T\"].set_type(output_type);\n  *node->mutable_input(1) = AsControlDependency(node->input(1));\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n bool ConstantFolding::SimplifyReshape(const GraphProperties& properties,\n                                       bool use_shape_info, NodeDef* node) {\n   if (!use_shape_info || node->attr().count(\"T\") == 0 ||\n-      !IsSimplifiableReshape(*node, properties)) {\n+      !IsSimplifiableReshape(*node, properties).ok()) {\n     return false;\n   }\n   DataType output_type = node->attr().at(\"T\").type();",
        "diff_line_info": {
            "deleted_lines": [
                "      !IsSimplifiableReshape(*node, properties)) {"
            ],
            "added_lines": [
                "      !IsSimplifiableReshape(*node, properties).ok()) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23582",
        "func_name": "tensorflow/TensorByteSize",
        "description": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that `TensorByteSize` would trigger `CHECK` failures. `TensorShape` constructor throws a `CHECK`-fail if shape is partial or has a number of elements that would overflow the size of an `int`. The `PartialTensorShape` constructor instead does not cause a `CHECK`-abort if the shape is partial, which is exactly what this function needs to be able to return `-1`. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c2426bba00a01de6913738df8fa78e0215fcce02",
        "commit_title": "Use `PartialTensorShape` instead of `TensorShape`.",
        "commit_text": " `TensorShape` constructor throws a CHECK-fail if shape is partial/overflows which the other doesn't. We are only determining the number of elements in the shape and partial shape should be used as it returns negative number when needed.  PiperOrigin-RevId: 409205384",
        "func_before": "int64_t TensorByteSize(const TensorProto& t) {\n  // num_elements returns -1 if shape is not fully defined.\n  int64_t num_elems = TensorShape(t.tensor_shape()).num_elements();\n  return num_elems < 0 ? -1 : num_elems * DataTypeSize(t.dtype());\n}",
        "func": "int64_t TensorByteSize(const TensorProto& t) {\n  // num_elements returns -1 if shape is not fully defined.\n  int64_t num_elems = PartialTensorShape(t.tensor_shape()).num_elements();\n  return num_elems < 0 ? -1 : num_elems * DataTypeSize(t.dtype());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int64_t TensorByteSize(const TensorProto& t) {\n   // num_elements returns -1 if shape is not fully defined.\n-  int64_t num_elems = TensorShape(t.tensor_shape()).num_elements();\n+  int64_t num_elems = PartialTensorShape(t.tensor_shape()).num_elements();\n   return num_elems < 0 ? -1 : num_elems * DataTypeSize(t.dtype());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  int64_t num_elems = TensorShape(t.tensor_shape()).num_elements();"
            ],
            "added_lines": [
                "  int64_t num_elems = PartialTensorShape(t.tensor_shape()).num_elements();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23586",
        "func_name": "tensorflow/BuildInputArgIndex",
        "description": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3d89911481ba6ebe8c88c1c0b595412121e6c645",
        "commit_title": "Eliminate `CHECK`-fail from `function.cc`.",
        "commit_text": " PiperOrigin-RevId: 409414744",
        "func_before": "Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    CHECK_GE(dtypes.size(), size_t{1});\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "func": "Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,9 @@\n     DataTypeVector dtypes;\n     TF_RETURN_IF_ERROR(\n         ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n-    CHECK_GE(dtypes.size(), size_t{1});\n+    if (dtypes.size() < size_t{1}) {\n+      return errors::Internal(\"Expected a list of at least one dtype\");\n+    }\n     int arg_index = result_.nodes.size();\n     TF_RETURN_IF_ERROR(\n         AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));",
        "diff_line_info": {
            "deleted_lines": [
                "    CHECK_GE(dtypes.size(), size_t{1});"
            ],
            "added_lines": [
                "    if (dtypes.size() < size_t{1}) {",
                "      return errors::Internal(\"Expected a list of at least one dtype\");",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23586",
        "func_name": "tensorflow/BuildInputArgIndex",
        "description": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that assertions in `function.cc` would be falsified and crash the Python interpreter. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/dcc21c7bc972b10b6fb95c2fb0f4ab5a59680ec2",
        "commit_title": "Eliminate debug `CHECK`-fail from `function.cc`",
        "commit_text": " PiperOrigin-RevId: 409416119",
        "func_before": "Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "func": "Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      if (arg_index != result_.nodes.size()) {\n        return errors::Internal(\n            \"Expected arg_index to be equal to the number of nodes in result.\",\n            \" Got \", arg_index, \" and \", result_.nodes.size());\n      }\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,11 @@\n     for (size_t i = 0; i < dtypes.size(); ++i) {\n       TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                  {true, arg_index, 0, false, {dtypes[i]}}));\n-      DCHECK_EQ(arg_index, result_.nodes.size());\n+      if (arg_index != result_.nodes.size()) {\n+        return errors::Internal(\n+            \"Expected arg_index to be equal to the number of nodes in result.\",\n+            \" Got \", arg_index, \" and \", result_.nodes.size());\n+      }\n       string name = arg_def.name();\n       if (dtypes.size() > 1) {\n         strings::StrAppend(&name, \"_\", i);",
        "diff_line_info": {
            "deleted_lines": [
                "      DCHECK_EQ(arg_index, result_.nodes.size());"
            ],
            "added_lines": [
                "      if (arg_index != result_.nodes.size()) {",
                "        return errors::Internal(",
                "            \"Expected arg_index to be equal to the number of nodes in result.\",",
                "            \" Got \", arg_index, \" and \", result_.nodes.size());",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23588",
        "func_name": "tensorflow/CreateConstantTensorAttrValue",
        "description": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that Grappler optimizer would attempt to build a tensor using a reference `dtype`. This would result in a crash due to a `CHECK`-fail in the `Tensor` constructor as reference types are not allowed. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/6b5adc0877de832b2a7c189532dbbbc64622eeb6",
        "commit_title": "Prevent `CHECK`-fail when building reference tensor.",
        "commit_text": " The tensor constructor does not allow reference dtypes, as these should not show up explicitly. However, when passed these invalid types instead of building an invalid object the constructor crashes via a `CHECK`-fail. We have a static builder that properly handles this case but is not applicable given current usage.  Instead, before calling the constructor, we can check that the dtype is not a reference type and return an error otherwise, given that the dtype is user controlled so malicious users can trigger denial of service.  PiperOrigin-RevId: 409662503",
        "func_before": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "func": "Status CreateConstantTensorAttrValue(DataType type, double value,\n                                     const TensorShapeProto& shape,\n                                     AttrValue* attr_tensor) {\n  TensorProto* t = attr_tensor->mutable_tensor();\n  t->set_dtype(type);\n  *t->mutable_tensor_shape() = shape;\n  switch (type) {\n    case DT_HALF:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<Eigen::half>(value)));\n      break;\n    case DT_BFLOAT16:\n      t->add_half_val(\n          Eigen::numext::bit_cast<uint16>(static_cast<bfloat16>(value)));\n      break;\n      SET_TENSOR_VAL_CASE(DT_FLOAT, float, float);\n      SET_TENSOR_VAL_CASE(DT_DOUBLE, double, double);\n      SET_TENSOR_VAL_CASE(DT_INT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_UINT64, int64_t, int64);\n      SET_TENSOR_VAL_CASE(DT_INT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_INT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_UINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT32, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT16, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);\n      SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);\n    default:\n      return errors::InvalidArgument(\n          \"Unsupported type in CreateConstantTensorAttrValue: \",\n          DataTypeString(type));\n  }\n  return Status::OK();\n}\n\n#undef SET_TENSOR_CAL_CASE\n\nDataType GetDataTypeFromNodeOrProps(const NodeDef& node,\n                                    const GraphProperties& properties) {\n  DataType dtype = DT_INVALID;\n  if (node.attr().count(\"T\") == 1) {\n    dtype = node.attr().at(\"T\").type();\n  } else if (node.attr().count(\"dtype\") == 1) {\n    dtype = node.attr().at(\"dtype\").type();\n  } else if (IsLogicalOr(node) || IsLogicalAnd(node)) {\n    dtype = DT_BOOL;\n  } else {\n    auto output_props = properties.GetOutputProperties(node.name());\n    if (!output_props.empty()) {\n      dtype = output_props[0].dtype();\n    }\n  }\n  return dtype;\n}\n\n// Checks whether the shape of the const input of the Mul op is valid to perform\n// the MulConvPushDown optimization.\nbool IsValidConstShapeForMulConvPushDown(\n    const string& data_format, const TensorShapeProto& filter_shape,\n    const TensorShapeProto& mul_const_input_shape) {\n  // If the const is a scalar, or it has fewer or same number of dimensions\n  // than the filter and it only has single element, the optimization should\n  // work.\n  if (mul_const_input_shape.dim_size() <=\n          static_cast<int>(data_format.size()) &&\n      TensorShape(mul_const_input_shape).num_elements() == 1) {\n    return true;\n  }\n\n  // Otherwise, check the eligibility according to data format.\n  if (data_format == \"NHWC\" || data_format == \"NDHWC\") {\n    TensorShapeProto new_filter_shape;\n    if (!ShapeAfterBroadcast(filter_shape, mul_const_input_shape,\n                             &new_filter_shape)) {\n      return false;\n    }\n    if (!ShapesSymbolicallyEqual(filter_shape, new_filter_shape)) {\n      return false;\n    }\n    // Only the last dimension could be larger than one, since broadcasting over\n    // the last dimension (the output channel) will result in invalid filter.\n    for (int i = 0; i < mul_const_input_shape.dim_size() - 1; ++i) {\n      if (mul_const_input_shape.dim(i).size() > 1) return false;\n    }\n    return true;\n  } else if (data_format == \"NCHW\" || data_format == \"NCDHW\") {\n    // TODO(laigd): support NCHW and NCDHW (b/111214513).\n    return false;\n  }\n  return false;\n}\n\n}  // namespace\n\n// static\nStatus ConstantFolding::CreateNodeDef(const string& name,\n                                      const TensorValue& tensor, NodeDef* node,\n                                      size_t original_size) {\n  node->set_name(name);\n  node->set_op(\"Const\");\n\n  AttrValue attr_type;\n  attr_type.set_type(tensor->dtype());\n  node->mutable_attr()->insert({\"dtype\", attr_type});\n\n  AttrValue attr_tensor;\n  TensorProto* t = attr_tensor.mutable_tensor();\n  bool optimized = false;\n  size_t encoded_size;\n  // Use the packed representation whenever possible to avoid generating large\n  // graphdefs. Moreover, avoid repeating the last values if they're equal.\n  if (tensor->NumElements() > 4) {\n#define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\\n  {                                                                            \\\n    const auto* val_ptr = tensor->flat<TYPE>().data();                         \\\n    auto last = *val_ptr;                                                      \\\n    int64_t last_index = 0;                                                    \\\n    for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\\n      TYPE cur = *val_ptr++;                                                   \\\n      if (PackedValuesNotEqual(cur, last)) {                                   \\\n        last = cur;                                                            \\\n        last_index = i;                                                        \\\n      }                                                                        \\\n    }                                                                          \\\n    encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\\n    if (encoded_size < kint32max) {                                            \\\n      optimized = true;                                                        \\\n      t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\\n      const auto* src_ptr = tensor->flat<TYPE>().data();                       \\\n      auto* dst_ptr =                                                          \\\n          t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\\n      std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\\n    }                                                                          \\\n  }                                                                            \\\n  break\n\n    switch (tensor->dtype()) {\n      case DT_FLOAT:\n        POPULATE_TENSOR_PROTO(tensor, t, float, float);\n      case DT_DOUBLE:\n        POPULATE_TENSOR_PROTO(tensor, t, double, double);\n      case DT_INT64:\n        POPULATE_TENSOR_PROTO(tensor, t, int64_t, int64);\n      case DT_UINT64:\n        POPULATE_TENSOR_PROTO(tensor, t, uint64, uint64);\n      case DT_INT32:\n        POPULATE_TENSOR_PROTO(tensor, t, int32_t, int);\n      case DT_UINT32:\n        POPULATE_TENSOR_PROTO(tensor, t, uint32, uint32);\n      case DT_INT16:\n        POPULATE_TENSOR_PROTO(tensor, t, int16_t, int);\n      case DT_UINT16:\n        POPULATE_TENSOR_PROTO(tensor, t, uint16, int);\n      case DT_INT8:\n        POPULATE_TENSOR_PROTO(tensor, t, int8_t, int);\n      case DT_UINT8:\n        POPULATE_TENSOR_PROTO(tensor, t, uint8, int);\n      case DT_BOOL:\n        POPULATE_TENSOR_PROTO(tensor, t, bool, bool);\n      default:\n        /* Do nothing. */\n        break;\n    }\n  }\n  if (optimized) {\n    // Also specify type and shape.\n    t->set_dtype(tensor->dtype());\n    tensor->shape().AsProto(t->mutable_tensor_shape());\n  } else {\n    // DT_HALF, DT_BFLOAT16, DT_QINT32, DT_QINT16, DT_QUINT16, DT_QINT8,\n    // DT_QUINT8\n    tensor->AsProtoTensorContent(t);\n    encoded_size = t->tensor_content().size();\n  }\n  node->mutable_attr()->insert({\"value\", attr_tensor});\n\n  if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {\n    return errors::InvalidArgument(\n        strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",\n                        encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::EvaluateNode(const NodeDef& node,\n                                     const TensorVector& inputs,\n                                     TensorVector* output) const {\n  return ::tensorflow::grappler::EvaluateNode(node, inputs, cpu_device_,\n                                              resource_mgr_.get(), output);\n}\n\nStatus ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldMergeNode(NodeDef* node, GraphDef* output_graph) {\n  // Merge nodes are special, in the sense that they execute as soon as one of\n  // their input is ready. We can therefore fold a merge node iff it has at\n  // least one constant input without control dependency.\n  // We still need to ensure that the nodes in the fanin of the merge node are\n  // scheduled. We'll therefore add a control dependency from the merge node\n  // to the folded constant. We end up with:\n  //  * the merge node and its inputs are preserved as is\n  //  * a new constant node C1, driven by the merge node through a control\n  //  dependency, initialized to the value of the folded input\n  //  * a new constant node C2, driven by the merge node through a control\n  //  dependency, initialized to the index of the folded input\n  //  * the fanout of the merge nodes is rewired to be driven by either C1 or\n  //  C2.\n  for (int input_index = 0; input_index < node->input_size(); ++input_index) {\n    const auto& input = node->input(input_index);\n    if (IsControlInput(input)) {\n      // Try the next input.\n      continue;\n    }\n    NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      continue;\n    }\n    bool valid_input = true;\n    for (const string& fanin_of_input : input_node->input()) {\n      if (IsControlInput(fanin_of_input)) {\n        valid_input = false;\n        break;\n      }\n    }\n    if (!valid_input) {\n      // Try the next input\n      continue;\n    }\n\n    string const_out_name = OptimizedNodeName(*node, \"_const\");\n    string const_index_name = OptimizedNodeName(*node, \"_index\");\n    if (node_map_->GetNode(const_out_name) ||\n        node_map_->GetNode(const_index_name)) {\n      // Intended name already exists.\n      return errors::AlreadyExists(\n          strings::StrCat(const_out_name, \" or \", const_index_name,\n                          \" already present in the graph\"));\n    }\n\n    NodeDef* const_out = output_graph->add_node();\n    *const_out = *input_node;\n    const_out->set_name(const_out_name);\n    const_out->set_device(node->device());\n    *const_out->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_out->name(), const_out);\n    node_map_->AddOutput(node->name(), const_out->name());\n\n    NodeDef* const_index = output_graph->add_node();\n    const_index->set_op(\"Const\");\n    Tensor index(DT_INT32, TensorShape({}));\n    index.flat<int32>()(0) = input_index;\n    (*const_index->mutable_attr())[\"dtype\"].set_type(DT_INT32);\n    index.AsProtoTensorContent(\n        (*const_index->mutable_attr())[\"value\"].mutable_tensor());\n    const_index->set_name(const_index_name);\n    const_index->set_device(node->device());\n    *const_index->add_input() = AsControlDependency(*node);\n    node_map_->AddNode(const_index->name(), const_index);\n    node_map_->AddOutput(node->name(), const_index->name());\n\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port == 0) {\n            *output->mutable_input(i) = const_out->name();\n            node_map_->AddOutput(const_out->name(), output->name());\n          } else if (port == 1) {\n            *output->mutable_input(i) = const_index->name();\n            node_map_->AddOutput(const_index->name(), output->name());\n          } else {\n            // This is a control dependency (or an invalid edge since the\n            // merge node has only 2 outputs): preserve them.\n          }\n        }\n      }\n    }\n    return Status::OK();\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldNode(NodeDef* node, GraphDef* output_graph,\n                                 bool* result_too_large) {\n  *result_too_large = false;\n  if (IsMerge(*node)) {\n    return FoldMergeNode(node, output_graph);\n  }\n\n  std::vector<NodeDef> const_nodes;\n  TF_RETURN_IF_ERROR(\n      EvaluateOneFoldable(*node, &const_nodes, result_too_large));\n  VLOG(2) << \"Folded node: \" << SummarizeNodeDef(*node);\n\n  NodeDef* constant_output = nullptr;\n  for (int i = 0, end = const_nodes.size(); i < end; i++) {\n    NodeDef* const_node = &const_nodes[i];\n    VLOG(3) << \"Generated constant node: \" << SummarizeNodeDef(*const_node);\n    if (const_node->name().empty()) {\n      // Dead output: we can't create a constant to encode its value, so we'll\n      // just skip it. We'll preserve the edges that originate from that\n      // output below to preserve the overall behavior of the graph wrt dead\n      // edges.\n      continue;\n    }\n\n    // Returns `true` iff `const_node` already has control input named `input`.\n    const auto is_duplicate_control_input = [&](const string& input) -> bool {\n      auto it = absl::c_find(const_node->input(), input);\n      return it != const_node->input().end();\n    };\n\n    // Forward control dependencies.\n    for (const string& input : node->input()) {\n      // Forward control dependencies from folded node.\n      if (IsControlInput(input)) {\n        if (!is_duplicate_control_input(input)) {\n          *const_node->add_input() = input;\n        }\n      }\n\n      // Forward control dependencies from constant inputs to folded node.\n      if (!IsControlInput(input)) {\n        NodeDef* input_node = node_map_->GetNode(input);\n        for (const string& fanin_of_input : input_node->input()) {\n          if (!is_duplicate_control_input(fanin_of_input)) {\n            *const_node->add_input() = fanin_of_input;\n          }\n        }\n      }\n    }\n\n    // We rewrite the existing node if it only has a single output, and\n    // create new nodes otherwise.\n    if (const_nodes.size() == 1) {\n      node->set_op(\"Const\");\n      // Note we need to clear the inputs in NodeMap before we clear the inputs\n      // in the node, otherwise NodeMap would see empty inputs and effectively\n      // does nothing.\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n      *node->mutable_input() = const_node->input();\n      for (const auto& input : node->input()) {\n        node_map_->AddOutput(NodeName(input), node->name());\n      }\n      *node->mutable_attr() = const_node->attr();\n      break;\n    } else {\n      if (node_map_->GetNode(const_node->name())) {\n        // Intended name already exists.\n        return errors::AlreadyExists(strings::StrCat(\n            const_node->name(), \" already present in the graph\"));\n      }\n      NodeDef* added_node = output_graph->add_node();\n      *added_node = *const_node;\n      added_node->set_device(node->device());\n      node_map_->AddNode(added_node->name(), added_node);\n      for (const auto& input : added_node->input()) {\n        node_map_->AddOutput(NodeName(input), added_node->name());\n      }\n      // All the constant nodes encoding output values have the same control\n      // dependencies (since these are the control dependencies of the node\n      // we're trying to fold). Record one such constant node.\n      constant_output = added_node;\n    }\n  }\n\n  if (const_nodes.size() > 1) {\n    // We make a copy because we mutate the nodes.\n    auto outputs = node_map_->GetOutputs(node->name());\n    for (NodeDef* output : outputs) {\n      for (int i = 0; i < output->input_size(); i++) {\n        int port;\n        string node_name = ParseNodeName(output->input(i), &port);\n        if (node_name == node->name()) {\n          if (port < 0) {\n            // Propagate control dependencies if possible. If not, we'll just\n            // preserve the existing control dependencies.\n            if (constant_output != nullptr) {\n              node_map_->UpdateInput(node_name, NodeName(output->input(i)),\n                                     constant_output->name());\n              *output->mutable_input(i) = AsControlDependency(*constant_output);\n            }\n          } else if (port < static_cast<int>(const_nodes.size()) &&\n                     !const_nodes[port].name().empty()) {\n            // Replace alive outputs with the corresponding constant.\n            node_map_->UpdateInput(output->name(), NodeName(output->input(i)),\n                                   const_nodes[port].name());\n            *output->mutable_input(i) = const_nodes[port].name();\n          } else {\n            // Leave this edge alone.\n            VLOG(3) << \"Preserving edge from \" << node->name() << \":\" << port\n                    << \"[\" << node->op() << \"] to \" << output->name() << \":\"\n                    << i << \"[\" << output->op() << \"]\";\n          }\n        }\n      }\n    }\n    outputs = node_map_->GetOutputs(node->name());\n    if (outputs.empty() && has_fetch_ &&\n        nodes_to_preserve_.find(node->name()) == nodes_to_preserve_.end()) {\n      node_map_->RemoveInputs(node->name());\n      node->clear_input();\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::FoldGraph(\n    const GraphProperties& properties, GraphDef* optimized_graph,\n    absl::flat_hash_set<string>* nodes_to_not_simplify) {\n  // We build a new optimized_graph by inserting the folded nodes into it, then\n  // copy other nodes that might be needed at the end of this function.\n  absl::flat_hash_set<string> processed_nodes;\n  std::deque<NodeDef*> queue;\n  for (int i = 0; i < graph_->node_size(); i++) {\n    const NodeDef& node = graph_->node(i);\n    if (IsFoldable(node, &properties) &&\n        !nodes_to_not_simplify->count(node.name())) {\n      queue.push_back(graph_->mutable_node(i));\n    }\n  }\n  while (!queue.empty()) {\n    NodeDef* node = queue.front();\n    queue.pop_front();\n    if (processed_nodes.count(node->name())) {\n      continue;\n    }\n    // We need to record a copy of output nodes before FoldNode() modifies it.\n    // We also need to ensure that the fanout is sorted deterministically.\n    std::vector<NodeDef*> fanout =\n        node_map_->GetOutputsOrderedByNodeName(node->name());\n    bool result_too_large = false;\n    Status s = FoldNode(node, optimized_graph, &result_too_large);\n    processed_nodes.insert(node->name());\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to fold node \" << node->DebugString()\n              << \"\\nError message: \" << s;\n      if (result_too_large) {\n        nodes_to_not_simplify->emplace(node->name());\n      }\n    } else {\n      for (auto& fanout_node : fanout) {\n        if (IsFoldable(*fanout_node, &properties) &&\n            !nodes_to_not_simplify->count(fanout_node->name())) {\n          queue.push_back(fanout_node);\n        }\n      }\n    }\n  }\n\n  // Delete the newly created nodes that don't feed anything.\n  std::vector<int> nodes_to_delete;\n  for (int i = 0; i < optimized_graph->node_size(); i++) {\n    const auto& fanout = node_map_->GetOutputs(optimized_graph->node(i).name());\n    if (fanout.empty()) nodes_to_delete.push_back(i);\n  }\n  EraseNodesFromGraph(std::move(nodes_to_delete), optimized_graph);\n\n  for (int i = 0; i < graph_->node_size(); ++i) {\n    NodeDef* node = graph_->mutable_node(i);\n    // If no fetch nodes is provided, we conservatively\n    // move all nodes in the original graph to the output, in case users need\n    // to fetch their values.\n    const auto& fanout = node_map_->GetOutputs(node->name());\n    if (!fanout.empty() || !has_fetch_ ||\n        nodes_to_preserve_.find(node->name()) != nodes_to_preserve_.end()) {\n      *(optimized_graph->add_node()) = std::move(*node);\n    }\n  }\n  return Status::OK();\n}\n\nStatus ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}\n\n#define IS_VALUE_CASE(DTYPE, VALUE)                   \\\n  case DTYPE:                                         \\\n    return AllValuesAre<EnumToDataType<DTYPE>::Type>( \\\n        node.attr().at(\"value\").tensor(), EnumToDataType<DTYPE>::Type(VALUE))\n\n#define IS_ONES_CASE(TYPE) IS_VALUE_CASE(TYPE, 1)\n#define IS_ZEROS_CASE(TYPE) IS_VALUE_CASE(TYPE, 0)\n\nbool ConstantFolding::IsOnes(const NodeDef& node) const {\n  if (feed_nodes_.find(node.name()) != feed_nodes_.end()) {\n    return false;\n  }\n  if (IsOnesLike(node)) return true;\n  if (IsZerosLike(node)) return false;\n  if (node.op() == \"Fill\") {\n    NodeDef* values = node_map_->GetNode(NodeName(node.input(1)));\n    return values != nullptr && IsOnes(*values);\n  }\n  if (node.op() != \"Const\") return false;\n  if (node.attr().count(\"dtype\") == 0) return false;\n  const auto dtype = node.attr().at(\"dtype\").type();\n  switch (dtype) {\n    IS_ONES_CASE(DT_BOOL);\n    IS_ONES_CASE(DT_HALF);\n    IS_ONES_CASE(DT_BFLOAT16);\n    IS_ONES_CASE(DT_FLOAT);\n    IS_ONES_CASE(DT_DOUBLE);\n    IS_ONES_CASE(DT_COMPLEX64);\n    IS_ONES_CASE(DT_COMPLEX128);\n    IS_ONES_CASE(DT_UINT8);\n    IS_ONES_CASE(DT_INT8);\n    IS_ONES_CASE(DT_UINT16);\n    IS_ONES_CASE(DT_INT16);\n    IS_ONES_CASE(DT_INT32);\n    IS_ONES_CASE(DT_INT64);\n    IS_ONES_CASE(DT_QINT32);\n    IS_ONES_CASE(DT_QINT16);\n    IS_ONES_CASE(DT_QUINT16);\n    IS_ONES_CASE(DT_QINT8);\n    IS_ONES_CASE(DT_QUINT8);\n    default:\n      VLOG(1) << \"Unsupported type \" << DataTypeString(dtype);\n      return false;\n  }\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -231,6 +231,11 @@\n                           input_tensor.ToString(),\n                           \" has a dtype of DT_INVALID.\"));\n     }\n+    if (IsRefType(raw_val.dtype())) {\n+      return errors::InvalidArgument(\n+          \"Not allowed to construct a tensor with reference dtype, got \",\n+          DataTypeString(raw_val.dtype()));\n+    }\n     Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n     if (!value->FromProto(raw_val)) {\n       delete (value);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (IsRefType(raw_val.dtype())) {",
                "      return errors::InvalidArgument(",
                "          \"Not allowed to construct a tensor with reference dtype, got \",",
                "          DataTypeString(raw_val.dtype()));",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-22901",
        "func_name": "jerryscript-project/jerryscript/lexer_expect_object_literal_id",
        "description": "There is an Assertion in 'context_p->next_scanner_info_p->type == SCANNER_TYPE_FUNCTION' failed at parser_parse_function_arguments in /js/js-parser.c of JerryScript commit a6ab5e9.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/5e1fdd1d1e75105b43392b4bb3996099cdc50f3d",
        "commit_title": "Fix class static block opening brace parsing",
        "commit_text": " The next character should not be consumed after finding the static block opening brace. This patch fixes #4916.  JerryScript-DCO-1.0-Signed-off-by: Martin Negyokru negyokru@inf.u-szeged.hu",
        "func_before": "void\nlexer_expect_object_literal_id (parser_context_t *context_p, /**< context */\n                                uint32_t ident_opts) /**< lexer_obj_ident_opts_t option bits */\n{\n  lexer_skip_spaces (context_p);\n\n  if (context_p->source_p >= context_p->source_end_p)\n  {\n    parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n  }\n\n  context_p->token.keyword_type = LEXER_EOS;\n  context_p->token.line = context_p->line;\n  context_p->token.column = context_p->column;\n  bool create_literal_object = false;\n\n  JERRY_ASSERT ((ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER) || !(ident_opts & LEXER_OBJ_IDENT_CLASS_NO_STATIC));\n\n#if JERRY_FUNCTION_TO_STRING\n  if (ident_opts & LEXER_OBJ_IDENT_SET_FUNCTION_START)\n  {\n    context_p->function_start_p = context_p->source_p;\n  }\n#endif /* JERRY_FUNCTION_TO_STRING */\n\n  if (lexer_parse_identifier (context_p, LEXER_PARSE_NO_OPTS))\n  {\n    if (!(ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN)))\n    {\n      lexer_skip_spaces (context_p);\n      context_p->token.flags = (uint8_t) (context_p->token.flags | LEXER_NO_SKIP_SPACES);\n\n      if (context_p->source_p < context_p->source_end_p\n#if JERRY_ESNEXT\n          && context_p->source_p[0] != LIT_CHAR_COMMA && context_p->source_p[0] != LIT_CHAR_RIGHT_BRACE\n          && context_p->source_p[0] != LIT_CHAR_LEFT_PAREN && context_p->source_p[0] != LIT_CHAR_SEMICOLON\n          && context_p->source_p[0] != LIT_CHAR_EQUALS\n#endif /* JERRY_ESNEXT */\n          && context_p->source_p[0] != LIT_CHAR_COLON)\n      {\n        if (lexer_compare_literal_to_string (context_p, \"get\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_GETTER;\n          return;\n        }\n\n        if (lexer_compare_literal_to_string (context_p, \"set\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_SETTER;\n          return;\n        }\n\n#if JERRY_ESNEXT\n        if (lexer_compare_literal_to_string (context_p, \"async\", 5))\n        {\n          context_p->token.type = LEXER_KEYW_ASYNC;\n          return;\n        }\n\n        if (ident_opts & LEXER_OBJ_IDENT_CLASS_NO_STATIC)\n        {\n          if (lexer_compare_literal_to_string (context_p, \"static\", 6))\n          {\n            context_p->token.type = LEXER_KEYW_STATIC;\n          }\n          return;\n        }\n#endif /* JERRY_ESNEXT */\n      }\n    }\n\n    create_literal_object = true;\n  }\n#if JERRY_ESNEXT\n  else if (ident_opts & LEXER_OBJ_IDENT_CLASS_PRIVATE)\n  {\n    parser_raise_error (context_p, PARSER_ERR_INVALID_CHARACTER);\n  }\n#endif /* JERRY_ESNEXT */\n  else\n  {\n    switch (context_p->source_p[0])\n    {\n      case LIT_CHAR_DOUBLE_QUOTE:\n      case LIT_CHAR_SINGLE_QUOTE:\n      {\n        lexer_parse_string (context_p, LEXER_STRING_NO_OPTS);\n        create_literal_object = true;\n        break;\n      }\n#if JERRY_ESNEXT\n      case LIT_CHAR_LEFT_SQUARE:\n      {\n#if JERRY_FUNCTION_TO_STRING\n        const uint8_t *function_start_p = context_p->function_start_p;\n#endif /* JERRY_FUNCTION_TO_STRING */\n\n        lexer_consume_next_character (context_p);\n\n        lexer_next_token (context_p);\n        parser_parse_expression (context_p, PARSE_EXPR_NO_COMMA);\n\n        if (context_p->token.type != LEXER_RIGHT_SQUARE)\n        {\n          parser_raise_error (context_p, PARSER_ERR_RIGHT_SQUARE_EXPECTED);\n        }\n\n#if JERRY_FUNCTION_TO_STRING\n        context_p->function_start_p = function_start_p;\n#endif /* JERRY_FUNCTION_TO_STRING */\n        return;\n      }\n      case LIT_CHAR_ASTERISK:\n      {\n        if (ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN))\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_MULTIPLY;\n        lexer_consume_next_character (context_p);\n        return;\n      }\n      case LIT_CHAR_HASHMARK:\n      {\n        if (ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER)\n        {\n          context_p->token.type = LEXER_HASHMARK;\n          return;\n        }\n\n        break;\n      }\n#endif /* JERRY_ESNEXT */\n      case LIT_CHAR_LEFT_BRACE:\n      {\n        if (ident_opts & (LEXER_OBJ_IDENT_CLASS_NO_STATIC | LEXER_OBJ_IDENT_CLASS_PRIVATE))\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_LEFT_BRACE;\n        lexer_consume_next_character (context_p);\n        return;\n      }\n      case LIT_CHAR_RIGHT_BRACE:\n      {\n        if (ident_opts & LEXER_OBJ_IDENT_ONLY_IDENTIFIERS)\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_RIGHT_BRACE;\n        lexer_consume_next_character (context_p);\n        return;\n      }\n#if JERRY_ESNEXT\n      case LIT_CHAR_DOT:\n      {\n        if (!(context_p->source_p + 1 >= context_p->source_end_p || lit_char_is_decimal_digit (context_p->source_p[1])))\n        {\n          if ((ident_opts & ((uint32_t) ~(LEXER_OBJ_IDENT_OBJECT_PATTERN | LEXER_OBJ_IDENT_SET_FUNCTION_START)))\n              || context_p->source_p + 2 >= context_p->source_end_p || context_p->source_p[1] != LIT_CHAR_DOT\n              || context_p->source_p[2] != LIT_CHAR_DOT)\n          {\n            break;\n          }\n\n          context_p->token.type = LEXER_THREE_DOTS;\n          context_p->token.flags &= (uint8_t) ~LEXER_NO_SKIP_SPACES;\n          PARSER_PLUS_EQUAL_LC (context_p->column, 3);\n          context_p->source_p += 3;\n          return;\n        }\n        /* FALLTHRU */\n      }\n#endif /* JERRY_ESNEXT */\n      default:\n      {\n        const uint8_t *char_p = context_p->source_p;\n\n        if (char_p[0] == LIT_CHAR_DOT)\n        {\n          char_p++;\n        }\n\n        if (char_p < context_p->source_end_p && char_p[0] >= LIT_CHAR_0 && char_p[0] <= LIT_CHAR_9)\n        {\n          lexer_parse_number (context_p);\n\n          if (!(ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER))\n          {\n            lexer_construct_number_object (context_p, false, false);\n          }\n          return;\n        }\n        break;\n      }\n    }\n  }\n\n  if (create_literal_object)\n  {\n#if JERRY_ESNEXT\n    if (ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER)\n    {\n      return;\n    }\n\n    if (ident_opts & LEXER_OBJ_IDENT_CLASS_PRIVATE)\n    {\n      parser_resolve_private_identifier (context_p);\n      return;\n    }\n#endif /* JERRY_ESNEXT */\n\n    lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n    return;\n  }\n\n  parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n}",
        "func": "void\nlexer_expect_object_literal_id (parser_context_t *context_p, /**< context */\n                                uint32_t ident_opts) /**< lexer_obj_ident_opts_t option bits */\n{\n  lexer_skip_spaces (context_p);\n\n  if (context_p->source_p >= context_p->source_end_p)\n  {\n    parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n  }\n\n  context_p->token.keyword_type = LEXER_EOS;\n  context_p->token.line = context_p->line;\n  context_p->token.column = context_p->column;\n  bool create_literal_object = false;\n\n  JERRY_ASSERT ((ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER) || !(ident_opts & LEXER_OBJ_IDENT_CLASS_NO_STATIC));\n\n#if JERRY_FUNCTION_TO_STRING\n  if (ident_opts & LEXER_OBJ_IDENT_SET_FUNCTION_START)\n  {\n    context_p->function_start_p = context_p->source_p;\n  }\n#endif /* JERRY_FUNCTION_TO_STRING */\n\n  if (lexer_parse_identifier (context_p, LEXER_PARSE_NO_OPTS))\n  {\n    if (!(ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN)))\n    {\n      lexer_skip_spaces (context_p);\n      context_p->token.flags = (uint8_t) (context_p->token.flags | LEXER_NO_SKIP_SPACES);\n\n      if (context_p->source_p < context_p->source_end_p\n#if JERRY_ESNEXT\n          && context_p->source_p[0] != LIT_CHAR_COMMA && context_p->source_p[0] != LIT_CHAR_RIGHT_BRACE\n          && context_p->source_p[0] != LIT_CHAR_LEFT_PAREN && context_p->source_p[0] != LIT_CHAR_SEMICOLON\n          && context_p->source_p[0] != LIT_CHAR_EQUALS\n#endif /* JERRY_ESNEXT */\n          && context_p->source_p[0] != LIT_CHAR_COLON)\n      {\n        if (lexer_compare_literal_to_string (context_p, \"get\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_GETTER;\n          return;\n        }\n\n        if (lexer_compare_literal_to_string (context_p, \"set\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_SETTER;\n          return;\n        }\n\n#if JERRY_ESNEXT\n        if (lexer_compare_literal_to_string (context_p, \"async\", 5))\n        {\n          context_p->token.type = LEXER_KEYW_ASYNC;\n          return;\n        }\n\n        if (ident_opts & LEXER_OBJ_IDENT_CLASS_NO_STATIC)\n        {\n          if (lexer_compare_literal_to_string (context_p, \"static\", 6))\n          {\n            context_p->token.type = LEXER_KEYW_STATIC;\n          }\n          return;\n        }\n#endif /* JERRY_ESNEXT */\n      }\n    }\n\n    create_literal_object = true;\n  }\n#if JERRY_ESNEXT\n  else if (ident_opts & LEXER_OBJ_IDENT_CLASS_PRIVATE)\n  {\n    parser_raise_error (context_p, PARSER_ERR_INVALID_CHARACTER);\n  }\n#endif /* JERRY_ESNEXT */\n  else\n  {\n    switch (context_p->source_p[0])\n    {\n      case LIT_CHAR_DOUBLE_QUOTE:\n      case LIT_CHAR_SINGLE_QUOTE:\n      {\n        lexer_parse_string (context_p, LEXER_STRING_NO_OPTS);\n        create_literal_object = true;\n        break;\n      }\n#if JERRY_ESNEXT\n      case LIT_CHAR_LEFT_SQUARE:\n      {\n#if JERRY_FUNCTION_TO_STRING\n        const uint8_t *function_start_p = context_p->function_start_p;\n#endif /* JERRY_FUNCTION_TO_STRING */\n\n        lexer_consume_next_character (context_p);\n\n        lexer_next_token (context_p);\n        parser_parse_expression (context_p, PARSE_EXPR_NO_COMMA);\n\n        if (context_p->token.type != LEXER_RIGHT_SQUARE)\n        {\n          parser_raise_error (context_p, PARSER_ERR_RIGHT_SQUARE_EXPECTED);\n        }\n\n#if JERRY_FUNCTION_TO_STRING\n        context_p->function_start_p = function_start_p;\n#endif /* JERRY_FUNCTION_TO_STRING */\n        return;\n      }\n      case LIT_CHAR_ASTERISK:\n      {\n        if (ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN))\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_MULTIPLY;\n        lexer_consume_next_character (context_p);\n        return;\n      }\n      case LIT_CHAR_HASHMARK:\n      {\n        if (ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER)\n        {\n          context_p->token.type = LEXER_HASHMARK;\n          return;\n        }\n\n        break;\n      }\n#endif /* JERRY_ESNEXT */\n      case LIT_CHAR_LEFT_BRACE:\n      {\n        const uint32_t static_block_flags =\n          (LEXER_OBJ_IDENT_CLASS_NO_STATIC | LEXER_OBJ_IDENT_CLASS_PRIVATE | LEXER_OBJ_IDENT_CLASS_IDENTIFIER);\n\n        if ((ident_opts & static_block_flags) == LEXER_OBJ_IDENT_CLASS_IDENTIFIER)\n        {\n          context_p->token.type = LEXER_LEFT_BRACE;\n          lexer_consume_next_character (context_p);\n          return;\n        }\n\n        break;\n      }\n      case LIT_CHAR_RIGHT_BRACE:\n      {\n        if (ident_opts & LEXER_OBJ_IDENT_ONLY_IDENTIFIERS)\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_RIGHT_BRACE;\n        lexer_consume_next_character (context_p);\n        return;\n      }\n#if JERRY_ESNEXT\n      case LIT_CHAR_DOT:\n      {\n        if (!(context_p->source_p + 1 >= context_p->source_end_p || lit_char_is_decimal_digit (context_p->source_p[1])))\n        {\n          if ((ident_opts & ((uint32_t) ~(LEXER_OBJ_IDENT_OBJECT_PATTERN | LEXER_OBJ_IDENT_SET_FUNCTION_START)))\n              || context_p->source_p + 2 >= context_p->source_end_p || context_p->source_p[1] != LIT_CHAR_DOT\n              || context_p->source_p[2] != LIT_CHAR_DOT)\n          {\n            break;\n          }\n\n          context_p->token.type = LEXER_THREE_DOTS;\n          context_p->token.flags &= (uint8_t) ~LEXER_NO_SKIP_SPACES;\n          PARSER_PLUS_EQUAL_LC (context_p->column, 3);\n          context_p->source_p += 3;\n          return;\n        }\n        /* FALLTHRU */\n      }\n#endif /* JERRY_ESNEXT */\n      default:\n      {\n        const uint8_t *char_p = context_p->source_p;\n\n        if (char_p[0] == LIT_CHAR_DOT)\n        {\n          char_p++;\n        }\n\n        if (char_p < context_p->source_end_p && char_p[0] >= LIT_CHAR_0 && char_p[0] <= LIT_CHAR_9)\n        {\n          lexer_parse_number (context_p);\n\n          if (!(ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER))\n          {\n            lexer_construct_number_object (context_p, false, false);\n          }\n          return;\n        }\n        break;\n      }\n    }\n  }\n\n  if (create_literal_object)\n  {\n#if JERRY_ESNEXT\n    if (ident_opts & LEXER_OBJ_IDENT_CLASS_IDENTIFIER)\n    {\n      return;\n    }\n\n    if (ident_opts & LEXER_OBJ_IDENT_CLASS_PRIVATE)\n    {\n      parser_resolve_private_identifier (context_p);\n      return;\n    }\n#endif /* JERRY_ESNEXT */\n\n    lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n    return;\n  }\n\n  parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -134,14 +134,17 @@\n #endif /* JERRY_ESNEXT */\n       case LIT_CHAR_LEFT_BRACE:\n       {\n-        if (ident_opts & (LEXER_OBJ_IDENT_CLASS_NO_STATIC | LEXER_OBJ_IDENT_CLASS_PRIVATE))\n-        {\n-          break;\n-        }\n-\n-        context_p->token.type = LEXER_LEFT_BRACE;\n-        lexer_consume_next_character (context_p);\n-        return;\n+        const uint32_t static_block_flags =\n+          (LEXER_OBJ_IDENT_CLASS_NO_STATIC | LEXER_OBJ_IDENT_CLASS_PRIVATE | LEXER_OBJ_IDENT_CLASS_IDENTIFIER);\n+\n+        if ((ident_opts & static_block_flags) == LEXER_OBJ_IDENT_CLASS_IDENTIFIER)\n+        {\n+          context_p->token.type = LEXER_LEFT_BRACE;\n+          lexer_consume_next_character (context_p);\n+          return;\n+        }\n+\n+        break;\n       }\n       case LIT_CHAR_RIGHT_BRACE:\n       {",
        "diff_line_info": {
            "deleted_lines": [
                "        if (ident_opts & (LEXER_OBJ_IDENT_CLASS_NO_STATIC | LEXER_OBJ_IDENT_CLASS_PRIVATE))",
                "        {",
                "          break;",
                "        }",
                "",
                "        context_p->token.type = LEXER_LEFT_BRACE;",
                "        lexer_consume_next_character (context_p);",
                "        return;"
            ],
            "added_lines": [
                "        const uint32_t static_block_flags =",
                "          (LEXER_OBJ_IDENT_CLASS_NO_STATIC | LEXER_OBJ_IDENT_CLASS_PRIVATE | LEXER_OBJ_IDENT_CLASS_IDENTIFIER);",
                "",
                "        if ((ident_opts & static_block_flags) == LEXER_OBJ_IDENT_CLASS_IDENTIFIER)",
                "        {",
                "          context_p->token.type = LEXER_LEFT_BRACE;",
                "          lexer_consume_next_character (context_p);",
                "          return;",
                "        }",
                "",
                "        break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-34967",
        "func_name": "MonetDB/rel_order_by_column_exp",
        "description": "The assertion `stmt->Dbc->FirstStmt' failed in MonetDB Database Server v11.43.13.",
        "git_url": "https://github.com/MonetDB/MonetDB/commit/d189f931497f2f700e05952b677f549266565862",
        "commit_title": "handle single rows in rel_order_by_column_exp.",
        "commit_text": "make sys.star (virtual function) return single row column, for row results. Solves broken query in issue #7306",
        "func_before": "static sql_exp *\nrel_order_by_column_exp(sql_query *query, sql_rel **R, symbol *column_r, int needs_distinct, int f)\n{\n\tmvc *sql = query->sql;\n\tsql_rel *r = *R, *p = NULL;\n\tsql_exp *e = NULL, *found = NULL;\n\texp_kind ek = {type_value, card_column, FALSE};\n\n\tif (!r)\n\t\treturn e;\n\n\tif (is_simple_project(r->op) && is_processed(r)) {\n\t\tp = r;\n\t\tr = r->l;\n\t}\n\n\te = rel_value_exp(query, &r, column_r, f, ek);\n\n\tif (r && !p)\n\t\t*R = r;\n\telse if (r)\n\t\tp->l = r;\n\tif (e && p) {\n\t\tif (is_project(p->op) && (found = exps_any_match(p->exps, e))) { /* if one of the projections matches, return a reference to it */\n\t\t\te = exp_ref(sql, found);\n\t\t} else {\n\t\t\tif (needs_distinct)\n\t\t\t\treturn sql_error(sql, 02, SQLSTATE(42000) \"SELECT: with DISTINCT ORDER BY expressions must appear in select list\");\n\t\t\te = rel_project_add_exp(sql, p, e);\n\t\t\tfor (node *n = p->exps->h ; n ; n = n->next) {\n\t\t\t\tsql_exp *ee = n->data;\n\n\t\t\t\tif (ee->card > r->card) {\n\t\t\t\t\tif (exp_name(ee) && !has_label(ee))\n\t\t\t\t\t\treturn sql_error(sql, ERR_GROUPBY, SQLSTATE(42000) \"SELECT: cannot use non GROUP BY column '%s' in query results without an aggregate function\", exp_name(ee));\n\t\t\t\t\treturn sql_error(sql, ERR_GROUPBY, SQLSTATE(42000) \"SELECT: cannot use non GROUP BY column in query results without an aggregate function\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn e;\n\t}\n\tif (e && r && is_project(r->op)) {\n\t\tsql_exp *found = exps_find_exp(r->exps, e);\n\n\t\tif (!found) {\n\t\t\tif (needs_distinct)\n\t\t\t\treturn sql_error(sql, 02, SQLSTATE(42000) \"SELECT: with DISTINCT ORDER BY expressions must appear in select list\");\n\t\t\tappend(r->exps, e);\n\t\t} else {\n\t\t\te = found;\n\t\t}\n\t\te = exp_ref(sql, e);\n\t}\n\treturn e;\n}",
        "func": "static sql_exp *\nrel_order_by_column_exp(sql_query *query, sql_rel **R, symbol *column_r, int needs_distinct, int f)\n{\n\tmvc *sql = query->sql;\n\tsql_rel *r = *R, *p = NULL;\n\tsql_exp *e = NULL, *found = NULL;\n\texp_kind ek = {type_value, card_column, FALSE};\n\n\tif (!r)\n\t\treturn e;\n\n\tif (is_simple_project(r->op) && r->l && is_processed(r)) {\n\t\tp = r;\n\t\tr = r->l;\n\t}\n\n\te = rel_value_exp(query, &r, column_r, f, ek);\n\n\tif (r && !p)\n\t\t*R = r;\n\telse if (r)\n\t\tp->l = r;\n\tif (e && p) {\n\t\tif (is_project(p->op) && (found = exps_any_match(p->exps, e))) { /* if one of the projections matches, return a reference to it */\n\t\t\te = exp_ref(sql, found);\n\t\t} else {\n\t\t\tif (needs_distinct)\n\t\t\t\treturn sql_error(sql, 02, SQLSTATE(42000) \"SELECT: with DISTINCT ORDER BY expressions must appear in select list\");\n\t\t\te = rel_project_add_exp(sql, p, e);\n\t\t\tfor (node *n = p->exps->h ; n ; n = n->next) {\n\t\t\t\tsql_exp *ee = n->data;\n\n\t\t\t\tif (ee->card > r->card) {\n\t\t\t\t\tif (exp_name(ee) && !has_label(ee))\n\t\t\t\t\t\treturn sql_error(sql, ERR_GROUPBY, SQLSTATE(42000) \"SELECT: cannot use non GROUP BY column '%s' in query results without an aggregate function\", exp_name(ee));\n\t\t\t\t\treturn sql_error(sql, ERR_GROUPBY, SQLSTATE(42000) \"SELECT: cannot use non GROUP BY column in query results without an aggregate function\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn e;\n\t}\n\tif (e && r && is_project(r->op)) {\n\t\tsql_exp *found = exps_find_exp(r->exps, e);\n\n\t\tif (!found) {\n\t\t\tif (needs_distinct)\n\t\t\t\treturn sql_error(sql, 02, SQLSTATE(42000) \"SELECT: with DISTINCT ORDER BY expressions must appear in select list\");\n\t\t\tappend(r->exps, e);\n\t\t} else {\n\t\t\te = found;\n\t\t}\n\t\te = exp_ref(sql, e);\n\t}\n\treturn e;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \tif (!r)\n \t\treturn e;\n \n-\tif (is_simple_project(r->op) && is_processed(r)) {\n+\tif (is_simple_project(r->op) && r->l && is_processed(r)) {\n \t\tp = r;\n \t\tr = r->l;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (is_simple_project(r->op) && is_processed(r)) {"
            ],
            "added_lines": [
                "\tif (is_simple_project(r->op) && r->l && is_processed(r)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-34967",
        "func_name": "MonetDB/exp_bin",
        "description": "The assertion `stmt->Dbc->FirstStmt' failed in MonetDB Database Server v11.43.13.",
        "git_url": "https://github.com/MonetDB/MonetDB/commit/d189f931497f2f700e05952b677f549266565862",
        "commit_title": "handle single rows in rel_order_by_column_exp.",
        "commit_text": "make sys.star (virtual function) return single row column, for row results. Solves broken query in issue #7306",
        "func_before": "stmt *\nexp_bin(backend *be, sql_exp *e, stmt *left, stmt *right, stmt *grp, stmt *ext, stmt *cnt, stmt *sel, int depth, int reduce, int push)\n{\n\tmvc *sql = be->mvc;\n\tstmt *s = NULL;\n\n \tif (mvc_highwater(sql))\n\t\treturn sql_error(be->mvc, 10, SQLSTATE(42000) \"Query too complex: running out of stack space\");\n\n\tif (!e) {\n\t\tassert(0);\n\t\treturn NULL;\n\t}\n\n\tswitch(e->type) {\n\tcase e_psm:\n\t\tif (e->flag & PSM_SET) {\n\t\t\tstmt *r = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tif(!r)\n\t\t\t\treturn NULL;\n\t\t\tif (e->card <= CARD_ATOM && r->nrcols > 0) /* single value, get result from bat */\n\t\t\t\tr = stmt_fetch(be, r);\n\t\t\treturn stmt_assign(be, exp_relname(e), exp_name(e), r, GET_PSM_LEVEL(e->flag));\n\t\t} else if (e->flag & PSM_VAR) {\n\t\t\tif (e->f)\n\t\t\t\treturn stmt_vars(be, exp_name(e), e->f, 1, GET_PSM_LEVEL(e->flag));\n\t\t\telse\n\t\t\t\treturn stmt_var(be, exp_relname(e), exp_name(e), &e->tpe, 1, GET_PSM_LEVEL(e->flag));\n\t\t} else if (e->flag & PSM_RETURN) {\n\t\t\tsql_exp *l = e->l;\n\t\t\tstmt *r = exp_bin(be, l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\n\t\t\tif (!r)\n\t\t\t\treturn NULL;\n\t\t\t/* handle table returning functions */\n\t\t\tif (l->type == e_psm && l->flag & PSM_REL) {\n\t\t\t\tstmt *lst = r->op1;\n\t\t\t\tif (r->type == st_table && lst->nrcols == 0 && lst->key && e->card > CARD_ATOM) {\n\t\t\t\t\tnode *n;\n\t\t\t\t\tlist *l = sa_list(sql->sa);\n\n\t\t\t\t\tfor(n=lst->op4.lval->h; n; n = n->next)\n\t\t\t\t\t\tlist_append(l, const_column(be, (stmt*)n->data));\n\t\t\t\t\tr = stmt_list(be, l);\n\t\t\t\t} else if (r->type == st_table && e->card == CARD_ATOM) { /* fetch value */\n\t\t\t\t\tr = lst->op4.lval->h->data;\n\t\t\t\t\tif (!r->aggr) /* if the cardinality is atom, no fetch call needed */\n\t\t\t\t\t\tr = stmt_fetch(be, r);\n\t\t\t\t}\n\t\t\t\tif (r->type == st_list)\n\t\t\t\t\tr = stmt_table(be, r, 1);\n\t\t\t}\n\t\t\treturn stmt_return(be, r, GET_PSM_LEVEL(e->flag));\n\t\t} else if (e->flag & PSM_WHILE) {\n\t\t\t/* while is a if - block true with leave statement\n\t \t\t * needed because the condition needs to be inside this outer block */\n\t\t\tstmt *ifstmt = stmt_cond(be, stmt_bool(be, 1), NULL, 0, 0);\n\t\t\tstmt *cond = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tstmt *wstmt;\n\n\t\t\tif(!cond)\n\t\t\t\treturn NULL;\n\t\t\twstmt = stmt_cond(be, cond, ifstmt, 1, 0);\n\n\t\t\tif (!exp_list(be, e->r, left, right, grp, ext, cnt, sel))\n\t\t\t\treturn NULL;\n\t\t\t(void)stmt_control_end(be, wstmt);\n\t\t\treturn stmt_control_end(be, ifstmt);\n\t\t} else if (e->flag & PSM_IF) {\n\t\t\tstmt *cond = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tstmt *ifstmt, *res;\n\n\t\t\tif(!cond)\n\t\t\t\treturn NULL;\n\t\t\tifstmt = stmt_cond(be, cond, NULL, 0, 0);\n\t\t\tif (!exp_list(be, e->r, left, right, grp, ext, cnt, sel))\n\t\t\t\treturn NULL;\n\t\t\tres = stmt_control_end(be, ifstmt);\n\t\t\tif (e->f) {\n\t\t\t\tstmt *elsestmt = stmt_cond(be, cond, NULL, 0, 1);\n\n\t\t\t\tif (!exp_list(be, e->f, left, right, grp, ext, cnt, sel))\n\t\t\t\t\treturn NULL;\n\t\t\t\tres = stmt_control_end(be, elsestmt);\n\t\t\t}\n\t\t\treturn res;\n\t\t} else if (e->flag & PSM_REL) {\n\t\t\tsql_rel *rel = e->l;\n\t\t\tstmt *r = rel_bin(be, rel);\n\n\t\t\tif (!r)\n\t\t\t\treturn NULL;\n\t\t\tif (is_modify(rel->op) || is_ddl(rel->op))\n\t\t\t\treturn r;\n\t\t\treturn stmt_table(be, r, 1);\n\t\t} else if (e->flag & PSM_EXCEPTION) {\n\t\t\tstmt *cond = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tif (!cond)\n\t\t\t\treturn NULL;\n\t\t\tif (cond->nrcols)\n\t\t\t\tcond = stmt_fetch(be, cond);\n\t\t\treturn stmt_exception(be, cond, (const char *) e->r, 0);\n\t\t}\n\t\tbreak;\n\tcase e_atom: {\n\t\tif (e->l) { \t\t\t/* literals */\n\t\t\ts = stmt_atom(be, e->l);\n\t\t} else if (e->r) { \t\t/* parameters and declared variables */\n\t\t\tsql_var_name *vname = (sql_var_name*) e->r;\n\t\t\tassert(vname->name);\n\t\t\ts = stmt_var(be, vname->sname ? sa_strdup(sql->sa, vname->sname) : NULL, sa_strdup(sql->sa, vname->name), e->tpe.type?&e->tpe:NULL, 0, e->flag);\n\t\t} else if (e->f) { \t\t/* values */\n\t\t\ts = value_list(be, e->f, left, sel);\n\t\t} else { \t\t\t/* arguments */\n\t\t\ts = stmt_varnr(be, e->flag, e->tpe.type?&e->tpe:NULL);\n\t\t}\n\t}\tbreak;\n\tcase e_convert: {\n\t\t/* if input is type any NULL or column of nulls, change type */\n\t\tlist *tps = e->r;\n\t\tsql_subtype *from = tps->h->data;\n\t\tsql_subtype *to = tps->h->next->data;\n\t\tstmt *l;\n\n\t\tif (from->type->localtype == 0) {\n\t\t\tl = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tif (l)\n\t\t\t\tl = stmt_atom(be, atom_general(sql->sa, to, NULL));\n\t\t} else {\n\t\t\tl = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t}\n\t\tif (!l)\n\t\t\treturn NULL;\n\t\ts = stmt_convert(be, l, (!push&&l->nrcols==0)?NULL:sel, from, to);\n\t} \tbreak;\n\tcase e_func: {\n\t\tnode *en;\n\t\tlist *l = sa_list(sql->sa), *exps = e->l;\n\t\tsql_subfunc *f = e->f;\n\t\tstmt *rows = NULL;\n\t\tconst char *mod, *fimp;\n\n\t\t/* attempt to instantiate MAL functions now, so we can know if we can push candidate lists */\n\t\tif (f->func->lang == FUNC_LANG_MAL && backend_create_mal_func(be->mvc, f->func) < 0)\n\t\t\treturn NULL;\n\t\tmod = sql_func_mod(f->func);\n\t\tfimp = backend_function_imp(be, f->func);\n\n\t\tif (f->func->side_effect && left && left->nrcols > 0 && f->func->type != F_LOADER && exps_card(exps) < CARD_MULTI) {\n\t\t\trows = bin_find_smallest_column(be, left);\n\t\t}\n\t\tassert(!e->r);\n\t\tif (strcmp(mod, \"\") == 0 && strcmp(fimp, \"\") == 0) {\n\t\t\tif (strcmp(f->func->base.name, \"star\") == 0)\n\t\t\t\treturn left->op4.lval->h->data;\n\t\t\tif (strcmp(f->func->base.name, \"case\") == 0)\n\t\t\t\treturn exp2bin_case(be, e, left, right, sel, depth);\n\t\t\tif (strcmp(f->func->base.name, \"casewhen\") == 0)\n\t\t\t\treturn exp2bin_casewhen(be, e, left, right, sel, depth);\n\t\t\tif (strcmp(f->func->base.name, \"coalesce\") == 0)\n\t\t\t\treturn exp2bin_coalesce(be, e, left, right, sel, depth);\n\t\t}\n\t\tif (!list_empty(exps)) {\n\t\t\tunsigned nrcols = 0;\n\t\t\tint push_cands = can_push_cands(sel, mod, fimp);\n\n\t\t\tassert(list_length(exps) == list_length(f->func->ops) || f->func->type == F_ANALYTIC || f->func->type == F_LOADER || f->func->vararg || f->func->varres);\n\t\t\tfor (en = exps->h; en; en = en->next) {\n\t\t\t\tsql_exp *e = en->data;\n\t\t\t\tstmt *es = exp_bin(be, e, left, right, grp, ext, cnt, (push_cands)?sel:NULL, depth+1, 0, push);\n\n\t\t\t\tif (!es)\n\t\t\t\t\treturn NULL;\n\t\t\t\t/*if (rows && en == exps->h && f->func->type != F_LOADER)\n\t\t\t\t\tes = stmt_const(be, rows, es);*/\n\t\t\t\telse if (f->func->type == F_ANALYTIC && es->nrcols == 0) {\n\t\t\t\t\tif (en == exps->h && left->nrcols)\n\t\t\t\t\t\tes = stmt_const(be, bin_find_smallest_column(be, left), es); /* ensure the first argument is a column */\n\t\t\t\t\tif (!f->func->s && !strcmp(f->func->base.name, \"window_bound\")\n\t\t\t\t\t\t&& exps->h->next && list_length(f->func->ops) == 6 && en == exps->h->next && left->nrcols)\n\t\t\t\t\t\tes = stmt_const(be, bin_find_smallest_column(be, left), es);\n\t\t\t\t}\n\t\t\t\tif (es->nrcols > nrcols)\n\t\t\t\t\tnrcols = es->nrcols;\n\t\t\t\tlist_append(l, es);\n\t\t\t}\n\t\t}\n\t\tif (!(s = stmt_Nop(be, stmt_list(be, l), sel, f, rows)))\n\t\t\treturn NULL;\n\t} \tbreak;\n\tcase e_aggr: {\n\t\tlist *attr = e->l;\n\t\tstmt *as = NULL;\n\t\tsql_subfunc *a = e->f;\n\n\t\tassert(sel == NULL);\n\t\tif (attr && attr->h) {\n\t\t\tnode *en;\n\t\t\tlist *l = sa_list(sql->sa);\n\n\t\t\tfor (en = attr->h; en; en = en->next) {\n\t\t\t\tsql_exp *at = en->data;\n\n\t\t\t\tas = exp_bin(be, at, left, right, NULL, NULL, NULL, sel, depth+1, 0, push);\n\n\t\t\t\tif (as && as->nrcols <= 0 && left)\n\t\t\t\t\tas = stmt_const(be, bin_find_smallest_column(be, left), as);\n\t\t\t\tif (en == attr->h && !en->next && exp_aggr_is_count(e))\n\t\t\t\t\tas = exp_count_no_nil_arg(e, ext, at, as);\n\t\t\t\t/* insert single value into a column */\n\t\t\t\tif (as && as->nrcols <= 0 && !left)\n\t\t\t\t\tas = const_column(be, as);\n\n\t\t\t\tif (!as)\n\t\t\t\t\treturn NULL;\n\t\t\t\tappend(l, as);\n\t\t\t}\n\t\t\tif (need_distinct(e) && (grp || list_length(l) > 1)){\n\t\t\t\tlist *nl = sa_list(sql->sa);\n\t\t\t\tstmt *ngrp = grp;\n\t\t\t\tstmt *next = ext;\n\t\t\t\tstmt *ncnt = cnt;\n\t\t\t\tfor (en = l->h; en; en = en->next) {\n\t\t\t\t\tstmt *as = en->data;\n\t\t\t\t\tstmt *g = stmt_group(be, as, ngrp, next, ncnt, 1);\n\t\t\t\t\tngrp = stmt_result(be, g, 0);\n\t\t\t\t\tnext = stmt_result(be, g, 1);\n\t\t\t\t\tncnt = stmt_result(be, g, 2);\n\t\t\t\t}\n\t\t\t\tfor (en = l->h; en; en = en->next) {\n\t\t\t\t\tstmt *as = en->data;\n\t\t\t\t\tappend(nl, stmt_project(be, next, as));\n\t\t\t\t}\n\t\t\t\tif (grp)\n\t\t\t\t\tgrp = stmt_project(be, next, grp);\n\t\t\t\tl = nl;\n\t\t\t} else if (need_distinct(e)) {\n\t\t\t\tstmt *a = l->h->data;\n\t\t\t\tstmt *u = stmt_unique(be, a);\n\t\t\t\tl = sa_list(sql->sa);\n\t\t\t\tappend(l, stmt_project(be, u, a));\n\t\t\t}\n\t\t\tas = stmt_list(be, l);\n\t\t} else {\n\t\t\t/* count(*) may need the default group (relation) and\n\t\t\t   and/or an attribute to count */\n\t\t\tif (grp) {\n\t\t\t\tas = grp;\n\t\t\t} else if (left) {\n\t\t\t\tas = bin_find_smallest_column(be, left);\n\t\t\t\tas = exp_count_no_nil_arg(e, ext, NULL, as);\n\t\t\t} else {\n\t\t\t\t/* create dummy single value in a column */\n\t\t\t\tas = stmt_atom_lng(be, 0);\n\t\t\t\tas = const_column(be, as);\n\t\t\t}\n\t\t}\n\t\ts = stmt_aggr(be, as, grp, ext, a, 1, need_no_nil(e) /* ignore nil*/, !zero_if_empty(e) );\n\t\tif (find_prop(e->p, PROP_COUNT)) /* propagate count == 0 ipv NULL in outer joins */\n\t\t\ts->flag |= OUTER_ZERO;\n\t} \tbreak;\n\tcase e_column: {\n\t\tif (right) /* check relation names */\n\t\t\ts = bin_find_column(be, right, e->l, e->r);\n\t\tif (!s && left)\n\t\t\ts = bin_find_column(be, left, e->l, e->r);\n\t\tif (s && grp)\n\t\t\ts = stmt_project(be, ext, s);\n\t\tif (!s && right) {\n\t\t\tTRC_CRITICAL(SQL_EXECUTION, \"Could not find %s.%s\\n\", (char*)e->l, (char*)e->r);\n\t\t\tprint_stmtlist(sql->sa, left);\n\t\t\tprint_stmtlist(sql->sa, right);\n\t\t\tif (!s) {\n\t\t\t\tTRC_ERROR(SQL_EXECUTION, \"Query: '%s'\\n\", be->client->query);\n\t\t\t}\n\t\t\tassert(s);\n\t\t\treturn NULL;\n\t\t}\n\t}\tbreak;\n\tcase e_cmp: {\n\t\tstmt *l = NULL, *r = NULL, *r2 = NULL;\n\t\tint swapped = 0, is_select = 0, oldvtop, oldstop, oldvid;\n\t\tsql_exp *re = e->r, *re2 = e->f;\n\n\t\t/* general predicate, select and join */\n\t\tif (e->flag == cmp_filter) {\n\t\t\tlist *args;\n\t\t\tlist *ops;\n\t\t\tnode *n;\n\t\t\tint first = 1;\n\n\t\t\tops = sa_list(sql->sa);\n\t\t\targs = e->l;\n\t\t\tfor( n = args->h; n; n = n->next ) {\n\t\t\t\toldvtop = be->mb->vtop;\n\t\t\t\toldstop = be->mb->stop;\n\t\t\t\toldvid = be->mb->vid;\n\t\t\t\ts = NULL;\n\t\t\t\tif (!swapped)\n\t\t\t\t\ts = exp_bin(be, n->data, left, NULL, grp, ext, cnt, NULL, depth+1, 0, push);\n\t\t\t\tif (!s && (first || swapped)) {\n\t\t\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n\t\t\t\t\ts = exp_bin(be, n->data, right, NULL, grp, ext, cnt, NULL, depth+1, 0, push);\n\t\t\t\t\tswapped = 1;\n\t\t\t\t}\n\t\t\t\tif (!s)\n\t\t\t\t\treturn s;\n\t\t\t\tif (s->nrcols == 0 && first)\n\t\t\t\t\ts = stmt_const(be, bin_find_smallest_column(be, swapped?right:left), s);\n\t\t\t\tlist_append(ops, s);\n\t\t\t\tfirst = 0;\n\t\t\t}\n\t\t\tl = stmt_list(be, ops);\n\t\t\tops = sa_list(sql->sa);\n\t\t\targs = e->r;\n\t\t\tfor( n = args->h; n; n = n->next ) {\n\t\t\t\ts = exp_bin(be, n->data, (swapped || !right)?left:right, NULL, grp, ext, cnt, NULL, depth+1, 0, push);\n\t\t\t\tif (!s)\n\t\t\t\t\treturn s;\n\t\t\t\tlist_append(ops, s);\n\t\t\t}\n\t\t\tr = stmt_list(be, ops);\n\n\t\t\tif (left && right && (exps_card(e->r) != CARD_ATOM || !exps_are_atoms(e->r))) {\n\t\t\t\tsql_subfunc *f = e->f;\n\t\t\t\tfor (node *n = l->op4.lval->h ; n ; n = n->next)\n\t\t\t\t\tn->data = column(be, n->data);\n\t\t\t\tfor (node *n = r->op4.lval->h ; n ; n = n->next)\n\t\t\t\t\tn->data = column(be, n->data);\n\t\t\t\treturn stmt_genjoin(be, l, r, f, is_anti(e), swapped);\n\t\t\t}\n\t\t\tassert(!swapped);\n\t\t\ts = stmt_genselect(be, l, r, e->f, sel, is_anti(e));\n\t\t\treturn s;\n\t\t}\n\t\tif (e->flag == cmp_in || e->flag == cmp_notin)\n\t\t\treturn handle_in_exps(be, e->l, e->r, left, right, grp, ext, cnt, sel, (e->flag == cmp_in), depth, reduce, push);\n\t\tif (e->flag == cmp_or && (!right || right->nrcols == 1))\n\t\t\treturn exp_bin_or(be, e, left, right, grp, ext, cnt, sel, depth, reduce, push);\n\t\tif (e->flag == cmp_or && right) {  /* join */\n\t\t\tassert(0);\n\t\t}\n\n\t\t/* mark use of join indices */\n\t\tif (right && find_prop(e->p, PROP_JOINIDX) != NULL)\n\t\t\tbe->join_idx++;\n\n\t\toldvtop = be->mb->vtop;\n\t\toldstop = be->mb->stop;\n\t\toldvid = be->mb->vid;\n\t\tif (!l) {\n\t\t\tl = exp_bin(be, e->l, left, (!reduce)?right:NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tswapped = 0;\n\t\t}\n\t\tif (!l && right) {\n\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n \t\t\tl = exp_bin(be, e->l, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tswapped = 1;\n\t\t}\n\n\t\toldvtop = be->mb->vtop;\n\t\toldstop = be->mb->stop;\n\t\toldvid = be->mb->vid;\n\t\tif (swapped || !right || !reduce)\n \t\t\tr = exp_bin(be, re, left, (!reduce)?right:NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\telse\n \t\t\tr = exp_bin(be, re, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\tif (!r && !swapped) {\n\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n \t\t\tr = exp_bin(be, re, left, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tis_select = 1;\n\t\t}\n\t\tif (!r && swapped) {\n\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n \t\t\tr = exp_bin(be, re, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tis_select = 1;\n\t\t}\n\t\tif (re2 && (swapped || !right || !reduce))\n \t\t\tr2 = exp_bin(be, re2, left, (!reduce)?right:NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\telse if (re2)\n \t\t\tr2 = exp_bin(be, re2, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\n\t\tif (!l || !r || (re2 && !r2))\n\t\t\treturn NULL;\n\n\t\t(void)is_select;\n\t\tif (reduce && left && right) {\n\t\t\tif (l->nrcols == 0)\n\t\t\t\tl = stmt_const(be, bin_find_smallest_column(be, swapped?right:left), l);\n\t\t\tif (r->nrcols == 0)\n\t\t\t\tr = stmt_const(be, bin_find_smallest_column(be, swapped?left:right), r);\n\t\t\tif (r2 && r2->nrcols == 0)\n\t\t\t\tr2 = stmt_const(be, bin_find_smallest_column(be, swapped?left:right), r2);\n\t\t\tif (r2) {\n\t\t\t\ts = stmt_join2(be, l, r, r2, (comp_type)e->flag, is_anti(e), is_symmetric(e), swapped);\n\t\t\t} else if (swapped) {\n\t\t\t\ts = stmt_join(be, r, l, is_anti(e), swap_compare((comp_type)e->flag), 0, is_semantics(e), false);\n\t\t\t} else {\n\t\t\t\ts = stmt_join(be, l, r, is_anti(e), (comp_type)e->flag, 0, is_semantics(e), false);\n\t\t\t}\n\t\t} else {\n\t\t\tif (r2) { /* handle all cases in stmt_uselect, reducing, non reducing, scalar etc */\n\t\t\t\tif (l->nrcols == 0 && ((sel && sel->nrcols > 0) || r->nrcols > 0 || r2->nrcols > 0 || reduce))\n\t\t\t\t\tl = left ? stmt_const(be, bin_find_smallest_column(be, left), l) : column(be, l);\n\t\t\t\ts = stmt_uselect2(be, l, r, r2, (comp_type)e->flag, sel, is_anti(e), is_symmetric(e), reduce);\n\t\t\t} else {\n\t\t\t\t/* value compare or select */\n\t\t\t\tif ((!reduce || (l->nrcols == 0 && r->nrcols == 0)) && (e->flag == mark_in || e->flag == mark_notin)) {\n\t\t\t\t\tint in_flag = e->flag==mark_in?1:0;\n\t\t\t\t\tif (is_anti(e))\n\t\t\t\t\t\tin_flag = !in_flag;\n\t\t\t\t\tsql_subfunc *f = sql_bind_func(sql, \"sys\", in_flag?\"=\":\"<>\", tail_type(l), tail_type(l), F_FUNC, true);\n\t\t\t\t\tassert(f);\n\t\t\t\t\ts = stmt_binop(be, l, r, sel, f);\n\t\t\t\t\tif (l->cand)\n\t\t\t\t\t\ts->cand = l->cand;\n\t\t\t\t\tif (r->cand)\n\t\t\t\t\t\ts->cand = r->cand;\n\t\t\t\t} else if (!reduce || (l->nrcols == 0 && r->nrcols == 0)) {\n\t\t\t\t\tsql_subfunc *f = sql_bind_func(sql, \"sys\", compare_func((comp_type)e->flag, is_anti(e)),\n\t\t\t\t\t\t\t\t\t\t\t\t   tail_type(l), tail_type(l), F_FUNC, true);\n\t\t\t\t\tassert(f);\n\t\t\t\t\tif (is_semantics(e)) {\n\t\t\t\t\t\tif (exp_is_null(e->l) && exp_is_null(e->r)) {\n\t\t\t\t\t\t\ts = stmt_bool(be, !is_anti(e));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlist *args = sa_list(sql->sa);\n\t\t\t\t\t\t\t/* add nil semantics bit */\n\t\t\t\t\t\t\tlist_append(args, l);\n\t\t\t\t\t\t\tlist_append(args, r);\n\t\t\t\t\t\t\tlist_append(args, stmt_bool(be, 1));\n\t\t\t\t\t\t\ts = stmt_Nop(be, stmt_list(be, args), sel, f, NULL);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts = stmt_binop(be, l, r, sel, f);\n\t\t\t\t\t}\n\t\t\t\t\tif (l->cand)\n\t\t\t\t\t\ts->cand = l->cand;\n\t\t\t\t\tif (r->cand)\n\t\t\t\t\t\ts->cand = r->cand;\n\t\t\t\t} else {\n\t\t\t\t\t/* this can still be a join (as relational algebra and single value subquery results still means joins */\n\t\t\t\t\ts = stmt_uselect(be, l, r, (comp_type)e->flag, sel, is_anti(e), is_semantics(e));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t }\tbreak;\n\tdefault:\n\t\t;\n\t}\n\treturn s;\n}",
        "func": "stmt *\nexp_bin(backend *be, sql_exp *e, stmt *left, stmt *right, stmt *grp, stmt *ext, stmt *cnt, stmt *sel, int depth, int reduce, int push)\n{\n\tmvc *sql = be->mvc;\n\tstmt *s = NULL;\n\n \tif (mvc_highwater(sql))\n\t\treturn sql_error(be->mvc, 10, SQLSTATE(42000) \"Query too complex: running out of stack space\");\n\n\tif (!e) {\n\t\tassert(0);\n\t\treturn NULL;\n\t}\n\n\tswitch(e->type) {\n\tcase e_psm:\n\t\tif (e->flag & PSM_SET) {\n\t\t\tstmt *r = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tif(!r)\n\t\t\t\treturn NULL;\n\t\t\tif (e->card <= CARD_ATOM && r->nrcols > 0) /* single value, get result from bat */\n\t\t\t\tr = stmt_fetch(be, r);\n\t\t\treturn stmt_assign(be, exp_relname(e), exp_name(e), r, GET_PSM_LEVEL(e->flag));\n\t\t} else if (e->flag & PSM_VAR) {\n\t\t\tif (e->f)\n\t\t\t\treturn stmt_vars(be, exp_name(e), e->f, 1, GET_PSM_LEVEL(e->flag));\n\t\t\telse\n\t\t\t\treturn stmt_var(be, exp_relname(e), exp_name(e), &e->tpe, 1, GET_PSM_LEVEL(e->flag));\n\t\t} else if (e->flag & PSM_RETURN) {\n\t\t\tsql_exp *l = e->l;\n\t\t\tstmt *r = exp_bin(be, l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\n\t\t\tif (!r)\n\t\t\t\treturn NULL;\n\t\t\t/* handle table returning functions */\n\t\t\tif (l->type == e_psm && l->flag & PSM_REL) {\n\t\t\t\tstmt *lst = r->op1;\n\t\t\t\tif (r->type == st_table && lst->nrcols == 0 && lst->key && e->card > CARD_ATOM) {\n\t\t\t\t\tnode *n;\n\t\t\t\t\tlist *l = sa_list(sql->sa);\n\n\t\t\t\t\tfor(n=lst->op4.lval->h; n; n = n->next)\n\t\t\t\t\t\tlist_append(l, const_column(be, (stmt*)n->data));\n\t\t\t\t\tr = stmt_list(be, l);\n\t\t\t\t} else if (r->type == st_table && e->card == CARD_ATOM) { /* fetch value */\n\t\t\t\t\tr = lst->op4.lval->h->data;\n\t\t\t\t\tif (!r->aggr) /* if the cardinality is atom, no fetch call needed */\n\t\t\t\t\t\tr = stmt_fetch(be, r);\n\t\t\t\t}\n\t\t\t\tif (r->type == st_list)\n\t\t\t\t\tr = stmt_table(be, r, 1);\n\t\t\t}\n\t\t\treturn stmt_return(be, r, GET_PSM_LEVEL(e->flag));\n\t\t} else if (e->flag & PSM_WHILE) {\n\t\t\t/* while is a if - block true with leave statement\n\t \t\t * needed because the condition needs to be inside this outer block */\n\t\t\tstmt *ifstmt = stmt_cond(be, stmt_bool(be, 1), NULL, 0, 0);\n\t\t\tstmt *cond = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tstmt *wstmt;\n\n\t\t\tif(!cond)\n\t\t\t\treturn NULL;\n\t\t\twstmt = stmt_cond(be, cond, ifstmt, 1, 0);\n\n\t\t\tif (!exp_list(be, e->r, left, right, grp, ext, cnt, sel))\n\t\t\t\treturn NULL;\n\t\t\t(void)stmt_control_end(be, wstmt);\n\t\t\treturn stmt_control_end(be, ifstmt);\n\t\t} else if (e->flag & PSM_IF) {\n\t\t\tstmt *cond = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tstmt *ifstmt, *res;\n\n\t\t\tif(!cond)\n\t\t\t\treturn NULL;\n\t\t\tifstmt = stmt_cond(be, cond, NULL, 0, 0);\n\t\t\tif (!exp_list(be, e->r, left, right, grp, ext, cnt, sel))\n\t\t\t\treturn NULL;\n\t\t\tres = stmt_control_end(be, ifstmt);\n\t\t\tif (e->f) {\n\t\t\t\tstmt *elsestmt = stmt_cond(be, cond, NULL, 0, 1);\n\n\t\t\t\tif (!exp_list(be, e->f, left, right, grp, ext, cnt, sel))\n\t\t\t\t\treturn NULL;\n\t\t\t\tres = stmt_control_end(be, elsestmt);\n\t\t\t}\n\t\t\treturn res;\n\t\t} else if (e->flag & PSM_REL) {\n\t\t\tsql_rel *rel = e->l;\n\t\t\tstmt *r = rel_bin(be, rel);\n\n\t\t\tif (!r)\n\t\t\t\treturn NULL;\n\t\t\tif (is_modify(rel->op) || is_ddl(rel->op))\n\t\t\t\treturn r;\n\t\t\treturn stmt_table(be, r, 1);\n\t\t} else if (e->flag & PSM_EXCEPTION) {\n\t\t\tstmt *cond = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, 0, 0, push);\n\t\t\tif (!cond)\n\t\t\t\treturn NULL;\n\t\t\tif (cond->nrcols)\n\t\t\t\tcond = stmt_fetch(be, cond);\n\t\t\treturn stmt_exception(be, cond, (const char *) e->r, 0);\n\t\t}\n\t\tbreak;\n\tcase e_atom: {\n\t\tif (e->l) { \t\t\t/* literals */\n\t\t\ts = stmt_atom(be, e->l);\n\t\t} else if (e->r) { \t\t/* parameters and declared variables */\n\t\t\tsql_var_name *vname = (sql_var_name*) e->r;\n\t\t\tassert(vname->name);\n\t\t\ts = stmt_var(be, vname->sname ? sa_strdup(sql->sa, vname->sname) : NULL, sa_strdup(sql->sa, vname->name), e->tpe.type?&e->tpe:NULL, 0, e->flag);\n\t\t} else if (e->f) { \t\t/* values */\n\t\t\ts = value_list(be, e->f, left, sel);\n\t\t} else { \t\t\t/* arguments */\n\t\t\ts = stmt_varnr(be, e->flag, e->tpe.type?&e->tpe:NULL);\n\t\t}\n\t}\tbreak;\n\tcase e_convert: {\n\t\t/* if input is type any NULL or column of nulls, change type */\n\t\tlist *tps = e->r;\n\t\tsql_subtype *from = tps->h->data;\n\t\tsql_subtype *to = tps->h->next->data;\n\t\tstmt *l;\n\n\t\tif (from->type->localtype == 0) {\n\t\t\tl = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tif (l)\n\t\t\t\tl = stmt_atom(be, atom_general(sql->sa, to, NULL));\n\t\t} else {\n\t\t\tl = exp_bin(be, e->l, left, right, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t}\n\t\tif (!l)\n\t\t\treturn NULL;\n\t\ts = stmt_convert(be, l, (!push&&l->nrcols==0)?NULL:sel, from, to);\n\t} \tbreak;\n\tcase e_func: {\n\t\tnode *en;\n\t\tlist *l = sa_list(sql->sa), *exps = e->l;\n\t\tsql_subfunc *f = e->f;\n\t\tstmt *rows = NULL;\n\t\tconst char *mod, *fimp;\n\n\t\t/* attempt to instantiate MAL functions now, so we can know if we can push candidate lists */\n\t\tif (f->func->lang == FUNC_LANG_MAL && backend_create_mal_func(be->mvc, f->func) < 0)\n\t\t\treturn NULL;\n\t\tmod = sql_func_mod(f->func);\n\t\tfimp = backend_function_imp(be, f->func);\n\n\t\tif (f->func->side_effect && left && left->nrcols > 0 && f->func->type != F_LOADER && exps_card(exps) < CARD_MULTI) {\n\t\t\trows = bin_find_smallest_column(be, left);\n\t\t}\n\t\tassert(!e->r);\n\t\tif (strcmp(mod, \"\") == 0 && strcmp(fimp, \"\") == 0) {\n\t\t\tif (strcmp(f->func->base.name, \"star\") == 0) {\n\t\t\t\tif (!left)\n\t\t\t\t\treturn const_column(be, stmt_bool(be, 1));\n\t\t\t\treturn left->op4.lval->h->data;\n\t\t\t} if (strcmp(f->func->base.name, \"case\") == 0)\n\t\t\t\treturn exp2bin_case(be, e, left, right, sel, depth);\n\t\t\tif (strcmp(f->func->base.name, \"casewhen\") == 0)\n\t\t\t\treturn exp2bin_casewhen(be, e, left, right, sel, depth);\n\t\t\tif (strcmp(f->func->base.name, \"coalesce\") == 0)\n\t\t\t\treturn exp2bin_coalesce(be, e, left, right, sel, depth);\n\t\t}\n\t\tif (!list_empty(exps)) {\n\t\t\tunsigned nrcols = 0;\n\t\t\tint push_cands = can_push_cands(sel, mod, fimp);\n\n\t\t\tassert(list_length(exps) == list_length(f->func->ops) || f->func->type == F_ANALYTIC || f->func->type == F_LOADER || f->func->vararg || f->func->varres);\n\t\t\tfor (en = exps->h; en; en = en->next) {\n\t\t\t\tsql_exp *e = en->data;\n\t\t\t\tstmt *es = exp_bin(be, e, left, right, grp, ext, cnt, (push_cands)?sel:NULL, depth+1, 0, push);\n\n\t\t\t\tif (!es)\n\t\t\t\t\treturn NULL;\n\t\t\t\t/*if (rows && en == exps->h && f->func->type != F_LOADER)\n\t\t\t\t\tes = stmt_const(be, rows, es);*/\n\t\t\t\telse if (f->func->type == F_ANALYTIC && es->nrcols == 0) {\n\t\t\t\t\tif (en == exps->h && left->nrcols)\n\t\t\t\t\t\tes = stmt_const(be, bin_find_smallest_column(be, left), es); /* ensure the first argument is a column */\n\t\t\t\t\tif (!f->func->s && !strcmp(f->func->base.name, \"window_bound\")\n\t\t\t\t\t\t&& exps->h->next && list_length(f->func->ops) == 6 && en == exps->h->next && left->nrcols)\n\t\t\t\t\t\tes = stmt_const(be, bin_find_smallest_column(be, left), es);\n\t\t\t\t}\n\t\t\t\tif (es->nrcols > nrcols)\n\t\t\t\t\tnrcols = es->nrcols;\n\t\t\t\tlist_append(l, es);\n\t\t\t}\n\t\t}\n\t\tif (!(s = stmt_Nop(be, stmt_list(be, l), sel, f, rows)))\n\t\t\treturn NULL;\n\t} \tbreak;\n\tcase e_aggr: {\n\t\tlist *attr = e->l;\n\t\tstmt *as = NULL;\n\t\tsql_subfunc *a = e->f;\n\n\t\tassert(sel == NULL);\n\t\tif (attr && attr->h) {\n\t\t\tnode *en;\n\t\t\tlist *l = sa_list(sql->sa);\n\n\t\t\tfor (en = attr->h; en; en = en->next) {\n\t\t\t\tsql_exp *at = en->data;\n\n\t\t\t\tas = exp_bin(be, at, left, right, NULL, NULL, NULL, sel, depth+1, 0, push);\n\n\t\t\t\tif (as && as->nrcols <= 0 && left)\n\t\t\t\t\tas = stmt_const(be, bin_find_smallest_column(be, left), as);\n\t\t\t\tif (en == attr->h && !en->next && exp_aggr_is_count(e))\n\t\t\t\t\tas = exp_count_no_nil_arg(e, ext, at, as);\n\t\t\t\t/* insert single value into a column */\n\t\t\t\tif (as && as->nrcols <= 0 && !left)\n\t\t\t\t\tas = const_column(be, as);\n\n\t\t\t\tif (!as)\n\t\t\t\t\treturn NULL;\n\t\t\t\tappend(l, as);\n\t\t\t}\n\t\t\tif (need_distinct(e) && (grp || list_length(l) > 1)){\n\t\t\t\tlist *nl = sa_list(sql->sa);\n\t\t\t\tstmt *ngrp = grp;\n\t\t\t\tstmt *next = ext;\n\t\t\t\tstmt *ncnt = cnt;\n\t\t\t\tfor (en = l->h; en; en = en->next) {\n\t\t\t\t\tstmt *as = en->data;\n\t\t\t\t\tstmt *g = stmt_group(be, as, ngrp, next, ncnt, 1);\n\t\t\t\t\tngrp = stmt_result(be, g, 0);\n\t\t\t\t\tnext = stmt_result(be, g, 1);\n\t\t\t\t\tncnt = stmt_result(be, g, 2);\n\t\t\t\t}\n\t\t\t\tfor (en = l->h; en; en = en->next) {\n\t\t\t\t\tstmt *as = en->data;\n\t\t\t\t\tappend(nl, stmt_project(be, next, as));\n\t\t\t\t}\n\t\t\t\tif (grp)\n\t\t\t\t\tgrp = stmt_project(be, next, grp);\n\t\t\t\tl = nl;\n\t\t\t} else if (need_distinct(e)) {\n\t\t\t\tstmt *a = l->h->data;\n\t\t\t\tstmt *u = stmt_unique(be, a);\n\t\t\t\tl = sa_list(sql->sa);\n\t\t\t\tappend(l, stmt_project(be, u, a));\n\t\t\t}\n\t\t\tas = stmt_list(be, l);\n\t\t} else {\n\t\t\t/* count(*) may need the default group (relation) and\n\t\t\t   and/or an attribute to count */\n\t\t\tif (grp) {\n\t\t\t\tas = grp;\n\t\t\t} else if (left) {\n\t\t\t\tas = bin_find_smallest_column(be, left);\n\t\t\t\tas = exp_count_no_nil_arg(e, ext, NULL, as);\n\t\t\t} else {\n\t\t\t\t/* create dummy single value in a column */\n\t\t\t\tas = stmt_atom_lng(be, 0);\n\t\t\t\tas = const_column(be, as);\n\t\t\t}\n\t\t}\n\t\ts = stmt_aggr(be, as, grp, ext, a, 1, need_no_nil(e) /* ignore nil*/, !zero_if_empty(e) );\n\t\tif (find_prop(e->p, PROP_COUNT)) /* propagate count == 0 ipv NULL in outer joins */\n\t\t\ts->flag |= OUTER_ZERO;\n\t} \tbreak;\n\tcase e_column: {\n\t\tif (right) /* check relation names */\n\t\t\ts = bin_find_column(be, right, e->l, e->r);\n\t\tif (!s && left)\n\t\t\ts = bin_find_column(be, left, e->l, e->r);\n\t\tif (s && grp)\n\t\t\ts = stmt_project(be, ext, s);\n\t\tif (!s && right) {\n\t\t\tTRC_CRITICAL(SQL_EXECUTION, \"Could not find %s.%s\\n\", (char*)e->l, (char*)e->r);\n\t\t\tprint_stmtlist(sql->sa, left);\n\t\t\tprint_stmtlist(sql->sa, right);\n\t\t\tif (!s) {\n\t\t\t\tTRC_ERROR(SQL_EXECUTION, \"Query: '%s'\\n\", be->client->query);\n\t\t\t}\n\t\t\tassert(s);\n\t\t\treturn NULL;\n\t\t}\n\t}\tbreak;\n\tcase e_cmp: {\n\t\tstmt *l = NULL, *r = NULL, *r2 = NULL;\n\t\tint swapped = 0, is_select = 0, oldvtop, oldstop, oldvid;\n\t\tsql_exp *re = e->r, *re2 = e->f;\n\n\t\t/* general predicate, select and join */\n\t\tif (e->flag == cmp_filter) {\n\t\t\tlist *args;\n\t\t\tlist *ops;\n\t\t\tnode *n;\n\t\t\tint first = 1;\n\n\t\t\tops = sa_list(sql->sa);\n\t\t\targs = e->l;\n\t\t\tfor( n = args->h; n; n = n->next ) {\n\t\t\t\toldvtop = be->mb->vtop;\n\t\t\t\toldstop = be->mb->stop;\n\t\t\t\toldvid = be->mb->vid;\n\t\t\t\ts = NULL;\n\t\t\t\tif (!swapped)\n\t\t\t\t\ts = exp_bin(be, n->data, left, NULL, grp, ext, cnt, NULL, depth+1, 0, push);\n\t\t\t\tif (!s && (first || swapped)) {\n\t\t\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n\t\t\t\t\ts = exp_bin(be, n->data, right, NULL, grp, ext, cnt, NULL, depth+1, 0, push);\n\t\t\t\t\tswapped = 1;\n\t\t\t\t}\n\t\t\t\tif (!s)\n\t\t\t\t\treturn s;\n\t\t\t\tif (s->nrcols == 0 && first)\n\t\t\t\t\ts = stmt_const(be, bin_find_smallest_column(be, swapped?right:left), s);\n\t\t\t\tlist_append(ops, s);\n\t\t\t\tfirst = 0;\n\t\t\t}\n\t\t\tl = stmt_list(be, ops);\n\t\t\tops = sa_list(sql->sa);\n\t\t\targs = e->r;\n\t\t\tfor( n = args->h; n; n = n->next ) {\n\t\t\t\ts = exp_bin(be, n->data, (swapped || !right)?left:right, NULL, grp, ext, cnt, NULL, depth+1, 0, push);\n\t\t\t\tif (!s)\n\t\t\t\t\treturn s;\n\t\t\t\tlist_append(ops, s);\n\t\t\t}\n\t\t\tr = stmt_list(be, ops);\n\n\t\t\tif (left && right && (exps_card(e->r) != CARD_ATOM || !exps_are_atoms(e->r))) {\n\t\t\t\tsql_subfunc *f = e->f;\n\t\t\t\tfor (node *n = l->op4.lval->h ; n ; n = n->next)\n\t\t\t\t\tn->data = column(be, n->data);\n\t\t\t\tfor (node *n = r->op4.lval->h ; n ; n = n->next)\n\t\t\t\t\tn->data = column(be, n->data);\n\t\t\t\treturn stmt_genjoin(be, l, r, f, is_anti(e), swapped);\n\t\t\t}\n\t\t\tassert(!swapped);\n\t\t\ts = stmt_genselect(be, l, r, e->f, sel, is_anti(e));\n\t\t\treturn s;\n\t\t}\n\t\tif (e->flag == cmp_in || e->flag == cmp_notin)\n\t\t\treturn handle_in_exps(be, e->l, e->r, left, right, grp, ext, cnt, sel, (e->flag == cmp_in), depth, reduce, push);\n\t\tif (e->flag == cmp_or && (!right || right->nrcols == 1))\n\t\t\treturn exp_bin_or(be, e, left, right, grp, ext, cnt, sel, depth, reduce, push);\n\t\tif (e->flag == cmp_or && right) {  /* join */\n\t\t\tassert(0);\n\t\t}\n\n\t\t/* mark use of join indices */\n\t\tif (right && find_prop(e->p, PROP_JOINIDX) != NULL)\n\t\t\tbe->join_idx++;\n\n\t\toldvtop = be->mb->vtop;\n\t\toldstop = be->mb->stop;\n\t\toldvid = be->mb->vid;\n\t\tif (!l) {\n\t\t\tl = exp_bin(be, e->l, left, (!reduce)?right:NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tswapped = 0;\n\t\t}\n\t\tif (!l && right) {\n\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n \t\t\tl = exp_bin(be, e->l, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tswapped = 1;\n\t\t}\n\n\t\toldvtop = be->mb->vtop;\n\t\toldstop = be->mb->stop;\n\t\toldvid = be->mb->vid;\n\t\tif (swapped || !right || !reduce)\n \t\t\tr = exp_bin(be, re, left, (!reduce)?right:NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\telse\n \t\t\tr = exp_bin(be, re, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\tif (!r && !swapped) {\n\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n \t\t\tr = exp_bin(be, re, left, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tis_select = 1;\n\t\t}\n\t\tif (!r && swapped) {\n\t\t\tclean_mal_statements(be, oldstop, oldvtop, oldvid);\n \t\t\tr = exp_bin(be, re, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\t\tis_select = 1;\n\t\t}\n\t\tif (re2 && (swapped || !right || !reduce))\n \t\t\tr2 = exp_bin(be, re2, left, (!reduce)?right:NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\t\telse if (re2)\n \t\t\tr2 = exp_bin(be, re2, right, NULL, grp, ext, cnt, sel, depth+1, 0, push);\n\n\t\tif (!l || !r || (re2 && !r2))\n\t\t\treturn NULL;\n\n\t\t(void)is_select;\n\t\tif (reduce && left && right) {\n\t\t\tif (l->nrcols == 0)\n\t\t\t\tl = stmt_const(be, bin_find_smallest_column(be, swapped?right:left), l);\n\t\t\tif (r->nrcols == 0)\n\t\t\t\tr = stmt_const(be, bin_find_smallest_column(be, swapped?left:right), r);\n\t\t\tif (r2 && r2->nrcols == 0)\n\t\t\t\tr2 = stmt_const(be, bin_find_smallest_column(be, swapped?left:right), r2);\n\t\t\tif (r2) {\n\t\t\t\ts = stmt_join2(be, l, r, r2, (comp_type)e->flag, is_anti(e), is_symmetric(e), swapped);\n\t\t\t} else if (swapped) {\n\t\t\t\ts = stmt_join(be, r, l, is_anti(e), swap_compare((comp_type)e->flag), 0, is_semantics(e), false);\n\t\t\t} else {\n\t\t\t\ts = stmt_join(be, l, r, is_anti(e), (comp_type)e->flag, 0, is_semantics(e), false);\n\t\t\t}\n\t\t} else {\n\t\t\tif (r2) { /* handle all cases in stmt_uselect, reducing, non reducing, scalar etc */\n\t\t\t\tif (l->nrcols == 0 && ((sel && sel->nrcols > 0) || r->nrcols > 0 || r2->nrcols > 0 || reduce))\n\t\t\t\t\tl = left ? stmt_const(be, bin_find_smallest_column(be, left), l) : column(be, l);\n\t\t\t\ts = stmt_uselect2(be, l, r, r2, (comp_type)e->flag, sel, is_anti(e), is_symmetric(e), reduce);\n\t\t\t} else {\n\t\t\t\t/* value compare or select */\n\t\t\t\tif ((!reduce || (l->nrcols == 0 && r->nrcols == 0)) && (e->flag == mark_in || e->flag == mark_notin)) {\n\t\t\t\t\tint in_flag = e->flag==mark_in?1:0;\n\t\t\t\t\tif (is_anti(e))\n\t\t\t\t\t\tin_flag = !in_flag;\n\t\t\t\t\tsql_subfunc *f = sql_bind_func(sql, \"sys\", in_flag?\"=\":\"<>\", tail_type(l), tail_type(l), F_FUNC, true);\n\t\t\t\t\tassert(f);\n\t\t\t\t\ts = stmt_binop(be, l, r, sel, f);\n\t\t\t\t\tif (l->cand)\n\t\t\t\t\t\ts->cand = l->cand;\n\t\t\t\t\tif (r->cand)\n\t\t\t\t\t\ts->cand = r->cand;\n\t\t\t\t} else if (!reduce || (l->nrcols == 0 && r->nrcols == 0)) {\n\t\t\t\t\tsql_subfunc *f = sql_bind_func(sql, \"sys\", compare_func((comp_type)e->flag, is_anti(e)),\n\t\t\t\t\t\t\t\t\t\t\t\t   tail_type(l), tail_type(l), F_FUNC, true);\n\t\t\t\t\tassert(f);\n\t\t\t\t\tif (is_semantics(e)) {\n\t\t\t\t\t\tif (exp_is_null(e->l) && exp_is_null(e->r)) {\n\t\t\t\t\t\t\ts = stmt_bool(be, !is_anti(e));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlist *args = sa_list(sql->sa);\n\t\t\t\t\t\t\t/* add nil semantics bit */\n\t\t\t\t\t\t\tlist_append(args, l);\n\t\t\t\t\t\t\tlist_append(args, r);\n\t\t\t\t\t\t\tlist_append(args, stmt_bool(be, 1));\n\t\t\t\t\t\t\ts = stmt_Nop(be, stmt_list(be, args), sel, f, NULL);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\ts = stmt_binop(be, l, r, sel, f);\n\t\t\t\t\t}\n\t\t\t\t\tif (l->cand)\n\t\t\t\t\t\ts->cand = l->cand;\n\t\t\t\t\tif (r->cand)\n\t\t\t\t\t\ts->cand = r->cand;\n\t\t\t\t} else {\n\t\t\t\t\t/* this can still be a join (as relational algebra and single value subquery results still means joins */\n\t\t\t\t\ts = stmt_uselect(be, l, r, (comp_type)e->flag, sel, is_anti(e), is_semantics(e));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t }\tbreak;\n\tdefault:\n\t\t;\n\t}\n\treturn s;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -151,9 +151,11 @@\n \t\t}\n \t\tassert(!e->r);\n \t\tif (strcmp(mod, \"\") == 0 && strcmp(fimp, \"\") == 0) {\n-\t\t\tif (strcmp(f->func->base.name, \"star\") == 0)\n+\t\t\tif (strcmp(f->func->base.name, \"star\") == 0) {\n+\t\t\t\tif (!left)\n+\t\t\t\t\treturn const_column(be, stmt_bool(be, 1));\n \t\t\t\treturn left->op4.lval->h->data;\n-\t\t\tif (strcmp(f->func->base.name, \"case\") == 0)\n+\t\t\t} if (strcmp(f->func->base.name, \"case\") == 0)\n \t\t\t\treturn exp2bin_case(be, e, left, right, sel, depth);\n \t\t\tif (strcmp(f->func->base.name, \"casewhen\") == 0)\n \t\t\t\treturn exp2bin_casewhen(be, e, left, right, sel, depth);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (strcmp(f->func->base.name, \"star\") == 0)",
                "\t\t\tif (strcmp(f->func->base.name, \"case\") == 0)"
            ],
            "added_lines": [
                "\t\t\tif (strcmp(f->func->base.name, \"star\") == 0) {",
                "\t\t\t\tif (!left)",
                "\t\t\t\t\treturn const_column(be, stmt_bool(be, 1));",
                "\t\t\t} if (strcmp(f->func->base.name, \"case\") == 0)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-34967",
        "func_name": "MonetDB/newODBCStmt",
        "description": "The assertion `stmt->Dbc->FirstStmt' failed in MonetDB Database Server v11.43.13.",
        "git_url": "https://github.com/MonetDB/MonetDB/commit/8c363ad2fd11017bd4a24a22afa0fa84cc25e25a",
        "commit_title": "Fix destruction of new ODBC statement handle if initialization failed.",
        "commit_text": "This fixes the ODBC part of bug #7306.",
        "func_before": "ODBCStmt *\nnewODBCStmt(ODBCDbc *dbc)\n{\n\tODBCStmt *stmt = (ODBCStmt *) malloc(sizeof(ODBCStmt));\n\n\tassert(dbc);\n\tassert(dbc->mid);\n\n\tif (stmt == NULL) {\n\t\t/* Memory allocation error */\n\t\taddDbcError(dbc, \"HY001\", NULL, 0);\n\t\treturn NULL;\n\t}\n\n\t*stmt = (ODBCStmt) {\n\t\t.Dbc = dbc,\n\t\t.Error = NULL,\n\t\t.RetrievedErrors = 0,\n\n\t\t.State = INITED,\n\t\t.hdl = mapi_new_handle(dbc->mid),\n\t\t.currentRow = 0,\n\t\t.startRow = 0,\n\t\t.rowSetSize = 0,\n\t\t.queryid = -1,\n\t\t.nparams = 0,\n\t\t.querytype = -1,\n\t\t.rowcount = 0,\n\n\t\t.qtimeout = dbc->qtimeout, /* inherit query timeout */\n\n\t\t.cursorType = SQL_CURSOR_FORWARD_ONLY,\n\t\t.cursorScrollable = SQL_NONSCROLLABLE,\n\t\t.retrieveData = SQL_RD_ON,\n\t\t.noScan = SQL_NOSCAN_OFF,\n\n\t\t.ApplRowDescr = newODBCDesc(dbc),\n\t\t.ApplParamDescr = newODBCDesc(dbc),\n\t\t.ImplRowDescr = newODBCDesc(dbc),\n\t\t.ImplParamDescr = newODBCDesc(dbc),\n\n\t\t.Type = ODBC_STMT_MAGIC_NR,\t/* set it valid */\n\t};\n\n\tif (stmt->hdl == NULL) {\n\t\t/* Memory allocation error */\n\t\taddDbcError(dbc, \"HY001\", NULL, 0);\n\t\tdestroyODBCStmt(stmt);\n\t\treturn NULL;\n\t}\n\tif (stmt->ApplRowDescr == NULL || stmt->ApplParamDescr == NULL ||\n\t    stmt->ImplRowDescr == NULL || stmt->ImplParamDescr == NULL) {\n\t\tdestroyODBCStmt(stmt);\n\t\treturn NULL;\n\t}\n\n\tstmt->ApplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->ApplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->ImplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->ImplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->ImplRowDescr->Stmt = stmt;\n\tstmt->ImplParamDescr->Stmt = stmt;\n\tstmt->AutoApplRowDescr = stmt->ApplRowDescr;\n\tstmt->AutoApplParamDescr = stmt->ApplParamDescr;\n\n\t/* add this stmt to the administrative linked stmt list */\n\tstmt->next = dbc->FirstStmt,\n\tdbc->FirstStmt = stmt;\n\n\treturn stmt;\n}",
        "func": "ODBCStmt *\nnewODBCStmt(ODBCDbc *dbc)\n{\n\tODBCStmt *stmt = (ODBCStmt *) malloc(sizeof(ODBCStmt));\n\n\tassert(dbc);\n\tassert(dbc->mid);\n\n\tif (stmt == NULL) {\n\t\t/* Memory allocation error */\n\t\taddDbcError(dbc, \"HY001\", NULL, 0);\n\t\treturn NULL;\n\t}\n\n\t*stmt = (ODBCStmt) {\n\t\t.Dbc = dbc,\n\t\t.Error = NULL,\n\t\t.RetrievedErrors = 0,\n\n\t\t.State = INITED,\n\t\t.hdl = mapi_new_handle(dbc->mid),\n\t\t.currentRow = 0,\n\t\t.startRow = 0,\n\t\t.rowSetSize = 0,\n\t\t.queryid = -1,\n\t\t.nparams = 0,\n\t\t.querytype = -1,\n\t\t.rowcount = 0,\n\n\t\t.qtimeout = dbc->qtimeout, /* inherit query timeout */\n\n\t\t.cursorType = SQL_CURSOR_FORWARD_ONLY,\n\t\t.cursorScrollable = SQL_NONSCROLLABLE,\n\t\t.retrieveData = SQL_RD_ON,\n\t\t.noScan = SQL_NOSCAN_OFF,\n\n\t\t.AutoApplRowDescr = newODBCDesc(dbc),\n\t\t.AutoApplParamDescr = newODBCDesc(dbc),\n\t\t.ImplRowDescr = newODBCDesc(dbc),\n\t\t.ImplParamDescr = newODBCDesc(dbc),\n\n\t\t.Type = ODBC_STMT_MAGIC_NR,\t/* set it valid */\n\t};\n\n\tif (stmt->hdl == NULL) {\n\t\t/* Memory allocation error */\n\t\taddDbcError(dbc, \"HY001\", NULL, 0);\n\t\tdestroyODBCStmt(stmt);\n\t\treturn NULL;\n\t}\n\tif (stmt->AutoApplRowDescr == NULL || stmt->AutoApplParamDescr == NULL ||\n\t    stmt->ImplRowDescr == NULL || stmt->ImplParamDescr == NULL) {\n\t\tdestroyODBCStmt(stmt);\n\t\treturn NULL;\n\t}\n\n\tstmt->AutoApplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->AutoApplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->ImplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->ImplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n\tstmt->ImplRowDescr->Stmt = stmt;\n\tstmt->ImplParamDescr->Stmt = stmt;\n\tstmt->ApplRowDescr = stmt->AutoApplRowDescr;\n\tstmt->ApplParamDescr = stmt->AutoApplParamDescr;\n\n\t/* add this stmt to the administrative linked stmt list */\n\tstmt->next = dbc->FirstStmt,\n\tdbc->FirstStmt = stmt;\n\n\treturn stmt;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,8 +34,8 @@\n \t\t.retrieveData = SQL_RD_ON,\n \t\t.noScan = SQL_NOSCAN_OFF,\n \n-\t\t.ApplRowDescr = newODBCDesc(dbc),\n-\t\t.ApplParamDescr = newODBCDesc(dbc),\n+\t\t.AutoApplRowDescr = newODBCDesc(dbc),\n+\t\t.AutoApplParamDescr = newODBCDesc(dbc),\n \t\t.ImplRowDescr = newODBCDesc(dbc),\n \t\t.ImplParamDescr = newODBCDesc(dbc),\n \n@@ -48,20 +48,20 @@\n \t\tdestroyODBCStmt(stmt);\n \t\treturn NULL;\n \t}\n-\tif (stmt->ApplRowDescr == NULL || stmt->ApplParamDescr == NULL ||\n+\tif (stmt->AutoApplRowDescr == NULL || stmt->AutoApplParamDescr == NULL ||\n \t    stmt->ImplRowDescr == NULL || stmt->ImplParamDescr == NULL) {\n \t\tdestroyODBCStmt(stmt);\n \t\treturn NULL;\n \t}\n \n-\tstmt->ApplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n-\tstmt->ApplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n+\tstmt->AutoApplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n+\tstmt->AutoApplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n \tstmt->ImplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n \tstmt->ImplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;\n \tstmt->ImplRowDescr->Stmt = stmt;\n \tstmt->ImplParamDescr->Stmt = stmt;\n-\tstmt->AutoApplRowDescr = stmt->ApplRowDescr;\n-\tstmt->AutoApplParamDescr = stmt->ApplParamDescr;\n+\tstmt->ApplRowDescr = stmt->AutoApplRowDescr;\n+\tstmt->ApplParamDescr = stmt->AutoApplParamDescr;\n \n \t/* add this stmt to the administrative linked stmt list */\n \tstmt->next = dbc->FirstStmt,",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t.ApplRowDescr = newODBCDesc(dbc),",
                "\t\t.ApplParamDescr = newODBCDesc(dbc),",
                "\tif (stmt->ApplRowDescr == NULL || stmt->ApplParamDescr == NULL ||",
                "\tstmt->ApplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;",
                "\tstmt->ApplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;",
                "\tstmt->AutoApplRowDescr = stmt->ApplRowDescr;",
                "\tstmt->AutoApplParamDescr = stmt->ApplParamDescr;"
            ],
            "added_lines": [
                "\t\t.AutoApplRowDescr = newODBCDesc(dbc),",
                "\t\t.AutoApplParamDescr = newODBCDesc(dbc),",
                "\tif (stmt->AutoApplRowDescr == NULL || stmt->AutoApplParamDescr == NULL ||",
                "\tstmt->AutoApplRowDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;",
                "\tstmt->AutoApplParamDescr->sql_desc_alloc_type = SQL_DESC_ALLOC_AUTO;",
                "\tstmt->ApplRowDescr = stmt->AutoApplRowDescr;",
                "\tstmt->ApplParamDescr = stmt->AutoApplParamDescr;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-34967",
        "func_name": "MonetDB/destroyODBCStmt",
        "description": "The assertion `stmt->Dbc->FirstStmt' failed in MonetDB Database Server v11.43.13.",
        "git_url": "https://github.com/MonetDB/MonetDB/commit/8c363ad2fd11017bd4a24a22afa0fa84cc25e25a",
        "commit_title": "Fix destruction of new ODBC statement handle if initialization failed.",
        "commit_text": "This fixes the ODBC part of bug #7306.",
        "func_before": "void\ndestroyODBCStmt(ODBCStmt *stmt)\n{\n\tODBCStmt **stmtp;\n\n\tassert(isValidStmt(stmt));\n\n\t/* first set this object to invalid */\n\tstmt->Type = 0;\n\n\t/* remove this stmt from the dbc */\n\tassert(stmt->Dbc);\n\tassert(stmt->Dbc->FirstStmt);\n\n\t/* search for stmt in linked list */\n\tstmtp = &stmt->Dbc->FirstStmt;\n\n\twhile (*stmtp && *stmtp != stmt)\n\t\tstmtp = &(*stmtp)->next;\n\t/* stmtp points to location in list where stmt is found */\n\n\tassert(*stmtp == stmt);\t/* we must have found it */\n\n\t/* now remove it from the linked list */\n\t*stmtp = stmt->next;\n\n\t/* cleanup own managed data */\n\tdeleteODBCErrorList(&stmt->Error);\n\n\tdestroyODBCDesc(stmt->ImplParamDescr);\n\tdestroyODBCDesc(stmt->ImplRowDescr);\n\tdestroyODBCDesc(stmt->AutoApplParamDescr);\n\tdestroyODBCDesc(stmt->AutoApplRowDescr);\n\n\tif (stmt->hdl)\n\t\tmapi_close_handle(stmt->hdl);\n\n\tfree(stmt);\n}",
        "func": "void\ndestroyODBCStmt(ODBCStmt *stmt)\n{\n\tODBCStmt **stmtp;\n\n\tassert(isValidStmt(stmt));\n\n\t/* first set this object to invalid */\n\tstmt->Type = 0;\n\n\t/* remove this stmt from the dbc */\n\tassert(stmt->Dbc);\n\n\t/* search for stmt in linked list */\n\tstmtp = &stmt->Dbc->FirstStmt;\n\n\twhile (*stmtp && *stmtp != stmt)\n\t\tstmtp = &(*stmtp)->next;\n\t/* stmtp points to location in list where stmt is found, or\n\t * *stmtp is NULL in case it wasn't there (presumably not added\n\t * yet) */\n\n\tif (*stmtp) {\n\t\t/* now remove it from the linked list */\n\t\t*stmtp = stmt->next;\n\t}\n\n\t/* cleanup own managed data */\n\tdeleteODBCErrorList(&stmt->Error);\n\n\tdestroyODBCDesc(stmt->ImplParamDescr);\n\tdestroyODBCDesc(stmt->ImplRowDescr);\n\tdestroyODBCDesc(stmt->AutoApplParamDescr);\n\tdestroyODBCDesc(stmt->AutoApplRowDescr);\n\n\tif (stmt->hdl)\n\t\tmapi_close_handle(stmt->hdl);\n\n\tfree(stmt);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,19 +10,20 @@\n \n \t/* remove this stmt from the dbc */\n \tassert(stmt->Dbc);\n-\tassert(stmt->Dbc->FirstStmt);\n \n \t/* search for stmt in linked list */\n \tstmtp = &stmt->Dbc->FirstStmt;\n \n \twhile (*stmtp && *stmtp != stmt)\n \t\tstmtp = &(*stmtp)->next;\n-\t/* stmtp points to location in list where stmt is found */\n+\t/* stmtp points to location in list where stmt is found, or\n+\t * *stmtp is NULL in case it wasn't there (presumably not added\n+\t * yet) */\n \n-\tassert(*stmtp == stmt);\t/* we must have found it */\n-\n-\t/* now remove it from the linked list */\n-\t*stmtp = stmt->next;\n+\tif (*stmtp) {\n+\t\t/* now remove it from the linked list */\n+\t\t*stmtp = stmt->next;\n+\t}\n \n \t/* cleanup own managed data */\n \tdeleteODBCErrorList(&stmt->Error);",
        "diff_line_info": {
            "deleted_lines": [
                "\tassert(stmt->Dbc->FirstStmt);",
                "\t/* stmtp points to location in list where stmt is found */",
                "\tassert(*stmtp == stmt);\t/* we must have found it */",
                "",
                "\t/* now remove it from the linked list */",
                "\t*stmtp = stmt->next;"
            ],
            "added_lines": [
                "\t/* stmtp points to location in list where stmt is found, or",
                "\t * *stmtp is NULL in case it wasn't there (presumably not added",
                "\t * yet) */",
                "\tif (*stmtp) {",
                "\t\t/* now remove it from the linked list */",
                "\t\t*stmtp = stmt->next;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38496",
        "func_name": "lief-project/LIEF/Binary::shift",
        "description": "LIEF commit 365a16a was discovered to contain a reachable assertion abort via the component BinaryStream.hpp.",
        "git_url": "https://github.com/lief-project/LIEF/commit/4937a24a0bd6a4eefdc2a10e0bde37445d87c065",
        "commit_title": "Fix #765",
        "commit_text": "",
        "func_before": "void Binary::shift(size_t value) {\n  Header& header = this->header();\n\n  // Offset of the load commands table\n  const uint64_t loadcommands_start = is64_ ? sizeof(details::mach_header_64) :\n                                              sizeof(details::mach_header);\n\n  // +------------------------+ <---------- __TEXT.start\n  // |      Mach-O Header     |\n  // +------------------------+ <===== loadcommands_start\n  // |                        |\n  // | Load Command Table     |\n  // |                        |\n  // +------------------------+ <===== loadcommands_end\n  // |************************|\n  // |************************| Assembly code\n  // |************************|\n  // +------------------------+ <---------- __TEXT.end\n  const uint64_t loadcommands_end = loadcommands_start + header.sizeof_cmds();\n\n  // Segment that wraps this load command table\n  SegmentCommand* load_cmd_segment = segment_from_offset(loadcommands_end);\n  if (load_cmd_segment == nullptr) {\n    LIEF_WARN(\"Can't find segment associated with last load command\");\n    return;\n  }\n  LIEF_DEBUG(\"LC Table wrapped by {} / End offset: 0x{:x} (size: {:x})\",\n             load_cmd_segment->name(), loadcommands_end, load_cmd_segment->data_.size());\n  load_cmd_segment->content_insert(loadcommands_end, value);\n\n  // 1. Shift all commands\n  // =====================\n  for (std::unique_ptr<LoadCommand>& cmd : commands_) {\n    if (cmd->command_offset() >= loadcommands_end) {\n      cmd->command_offset(cmd->command_offset() + value);\n    }\n  }\n\n  shift_command(value, loadcommands_end);\n\n  // Shift Segment and sections\n  // ==========================\n  for (SegmentCommand* segment : segments_) {\n    // Extend the virtual size of the segment containing our shift\n    if (segment->file_offset() <= loadcommands_end &&\n        loadcommands_end < (segment->file_offset() + segment->file_size()))\n    {\n      LIEF_DEBUG(\"Extending '{}' by {:x}\", segment->name(), value);\n      segment->virtual_size(segment->virtual_size() + value);\n      segment->file_size(segment->file_size() + value);\n\n      for (const std::unique_ptr<Section>& section : segment->sections_) {\n        if (section->offset() >= loadcommands_end) {\n          section->offset(section->offset() + value);\n          section->virtual_address(section->virtual_address() + value);\n        }\n      }\n    } else {\n      if (segment->file_offset() >= loadcommands_end) {\n        segment->file_offset(segment->file_offset() + value);\n        segment->virtual_address(segment->virtual_address() + value);\n      }\n\n      for (const std::unique_ptr<Section>& section : segment->sections_) {\n        if (section->offset() >= loadcommands_end) {\n          section->offset(section->offset() + value);\n          section->virtual_address(section->virtual_address() + value);\n        }\n\n        if (section->type() == MACHO_SECTION_TYPES::S_ZEROFILL) {\n          section->virtual_address(section->virtual_address() + value);\n        }\n      }\n    }\n  }\n  refresh_seg_offset();\n}",
        "func": "ok_error_t Binary::shift(size_t value) {\n  Header& header = this->header();\n\n  // Offset of the load commands table\n  const uint64_t loadcommands_start = is64_ ? sizeof(details::mach_header_64) :\n                                              sizeof(details::mach_header);\n\n  // +------------------------+ <---------- __TEXT.start\n  // |      Mach-O Header     |\n  // +------------------------+ <===== loadcommands_start\n  // |                        |\n  // | Load Command Table     |\n  // |                        |\n  // +------------------------+ <===== loadcommands_end\n  // |************************|\n  // |************************| Assembly code\n  // |************************|\n  // +------------------------+ <---------- __TEXT.end\n  const uint64_t loadcommands_end = loadcommands_start + header.sizeof_cmds();\n\n  // Segment that wraps this load command table\n  SegmentCommand* load_cmd_segment = segment_from_offset(loadcommands_end);\n  if (load_cmd_segment == nullptr) {\n    LIEF_WARN(\"Can't find segment associated with last load command\");\n    return make_error_code(lief_errors::file_format_error);\n  }\n  LIEF_DEBUG(\"LC Table wrapped by {} / End offset: 0x{:x} (size: {:x})\",\n             load_cmd_segment->name(), loadcommands_end, load_cmd_segment->data_.size());\n  load_cmd_segment->content_insert(loadcommands_end, value);\n\n  // 1. Shift all commands\n  // =====================\n  for (std::unique_ptr<LoadCommand>& cmd : commands_) {\n    if (cmd->command_offset() >= loadcommands_end) {\n      cmd->command_offset(cmd->command_offset() + value);\n    }\n  }\n\n  shift_command(value, loadcommands_end);\n\n  // Shift Segment and sections\n  // ==========================\n  for (SegmentCommand* segment : segments_) {\n    // Extend the virtual size of the segment containing our shift\n    if (segment->file_offset() <= loadcommands_end &&\n        loadcommands_end < (segment->file_offset() + segment->file_size()))\n    {\n      LIEF_DEBUG(\"Extending '{}' by {:x}\", segment->name(), value);\n      segment->virtual_size(segment->virtual_size() + value);\n      segment->file_size(segment->file_size() + value);\n\n      for (const std::unique_ptr<Section>& section : segment->sections_) {\n        if (section->offset() >= loadcommands_end) {\n          section->offset(section->offset() + value);\n          section->virtual_address(section->virtual_address() + value);\n        }\n      }\n    } else {\n      if (segment->file_offset() >= loadcommands_end) {\n        segment->file_offset(segment->file_offset() + value);\n        segment->virtual_address(segment->virtual_address() + value);\n      }\n\n      for (const std::unique_ptr<Section>& section : segment->sections_) {\n        if (section->offset() >= loadcommands_end) {\n          section->offset(section->offset() + value);\n          section->virtual_address(section->virtual_address() + value);\n        }\n\n        if (section->type() == MACHO_SECTION_TYPES::S_ZEROFILL) {\n          section->virtual_address(section->virtual_address() + value);\n        }\n      }\n    }\n  }\n  refresh_seg_offset();\n  return ok();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void Binary::shift(size_t value) {\n+ok_error_t Binary::shift(size_t value) {\n   Header& header = this->header();\n \n   // Offset of the load commands table\n@@ -22,7 +22,7 @@\n   SegmentCommand* load_cmd_segment = segment_from_offset(loadcommands_end);\n   if (load_cmd_segment == nullptr) {\n     LIEF_WARN(\"Can't find segment associated with last load command\");\n-    return;\n+    return make_error_code(lief_errors::file_format_error);\n   }\n   LIEF_DEBUG(\"LC Table wrapped by {} / End offset: 0x{:x} (size: {:x})\",\n              load_cmd_segment->name(), loadcommands_end, load_cmd_segment->data_.size());\n@@ -74,4 +74,5 @@\n     }\n   }\n   refresh_seg_offset();\n+  return ok();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void Binary::shift(size_t value) {",
                "    return;"
            ],
            "added_lines": [
                "ok_error_t Binary::shift(size_t value) {",
                "    return make_error_code(lief_errors::file_format_error);",
                "  return ok();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38496",
        "func_name": "lief-project/LIEF/Binary::add",
        "description": "LIEF commit 365a16a was discovered to contain a reachable assertion abort via the component BinaryStream.hpp.",
        "git_url": "https://github.com/lief-project/LIEF/commit/4937a24a0bd6a4eefdc2a10e0bde37445d87c065",
        "commit_title": "Fix #765",
        "commit_text": "",
        "func_before": "LoadCommand* Binary::add(const LoadCommand& command) {\n  static constexpr uint32_t shift_value = 0x4000;\n  const int32_t size_aligned = align(command.size(), pointer_size());\n\n  // Check there is enough spaces between the load command table\n  // and the raw content\n  if (available_command_space_ < size_aligned) {\n    shift(shift_value);\n    available_command_space_ += shift_value;\n    return add(command);\n  }\n\n  available_command_space_ -= size_aligned;\n\n  Header& header = this->header();\n\n  // Get border of the load command table\n  const uint64_t loadcommands_start = is64_ ? sizeof(details::mach_header_64) :\n                                              sizeof(details::mach_header);\n  const uint64_t loadcommands_end = loadcommands_start + header.sizeof_cmds();\n\n  // Update the Header according to the command that will be added\n  header.sizeof_cmds(header.sizeof_cmds() + size_aligned);\n  header.nb_cmds(header.nb_cmds() + 1);\n\n  // Get the segment handling the LC table\n  SegmentCommand* load_cmd_segment = segment_from_offset(loadcommands_end);\n  if (load_cmd_segment == nullptr) {\n    LIEF_WARN(\"Can't get the last load command\");\n    return nullptr;\n  }\n\n  span<const uint8_t> content_ref = load_cmd_segment->content();\n  std::vector<uint8_t> content = {std::begin(content_ref), std::end(content_ref)};\n\n  // Copy the command data\n  std::copy(std::begin(command.data()), std::end(command.data()),\n            std::begin(content) + loadcommands_end);\n\n  load_cmd_segment->content(std::move(content));\n\n  // Add the command in the Binary\n  std::unique_ptr<LoadCommand> copy(command.clone());\n  copy->command_offset(loadcommands_end);\n\n\n  // Update cache\n  if (DylibCommand::classof(copy.get())) {\n    libraries_.push_back(copy->as<DylibCommand>());\n  }\n\n  if (SegmentCommand::classof(copy.get())) {\n    add_cached_segment(*copy->as<SegmentCommand>());\n  }\n  LoadCommand* ptr = copy.get();\n  commands_.push_back(std::move(copy));\n  return ptr;\n}",
        "func": "LoadCommand* Binary::add(const LoadCommand& command) {\n  static constexpr uint32_t shift_value = 0x4000;\n  const int32_t size_aligned = align(command.size(), pointer_size());\n\n  // Check there is enough spaces between the load command table\n  // and the raw content\n  if (available_command_space_ < size_aligned) {\n    if (!shift(shift_value)) {\n      return nullptr;\n    }\n    available_command_space_ += shift_value;\n    return add(command);\n  }\n\n  available_command_space_ -= size_aligned;\n\n  Header& header = this->header();\n\n  // Get border of the load command table\n  const uint64_t loadcommands_start = is64_ ? sizeof(details::mach_header_64) :\n                                              sizeof(details::mach_header);\n  const uint64_t loadcommands_end = loadcommands_start + header.sizeof_cmds();\n\n  // Update the Header according to the command that will be added\n  header.sizeof_cmds(header.sizeof_cmds() + size_aligned);\n  header.nb_cmds(header.nb_cmds() + 1);\n\n  // Get the segment handling the LC table\n  SegmentCommand* load_cmd_segment = segment_from_offset(loadcommands_end);\n  if (load_cmd_segment == nullptr) {\n    LIEF_WARN(\"Can't get the last load command\");\n    return nullptr;\n  }\n\n  span<const uint8_t> content_ref = load_cmd_segment->content();\n  std::vector<uint8_t> content = {std::begin(content_ref), std::end(content_ref)};\n\n  // Copy the command data\n  std::copy(std::begin(command.data()), std::end(command.data()),\n            std::begin(content) + loadcommands_end);\n\n  load_cmd_segment->content(std::move(content));\n\n  // Add the command in the Binary\n  std::unique_ptr<LoadCommand> copy(command.clone());\n  copy->command_offset(loadcommands_end);\n\n\n  // Update cache\n  if (DylibCommand::classof(copy.get())) {\n    libraries_.push_back(copy->as<DylibCommand>());\n  }\n\n  if (SegmentCommand::classof(copy.get())) {\n    add_cached_segment(*copy->as<SegmentCommand>());\n  }\n  LoadCommand* ptr = copy.get();\n  commands_.push_back(std::move(copy));\n  return ptr;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,9 @@\n   // Check there is enough spaces between the load command table\n   // and the raw content\n   if (available_command_space_ < size_aligned) {\n-    shift(shift_value);\n+    if (!shift(shift_value)) {\n+      return nullptr;\n+    }\n     available_command_space_ += shift_value;\n     return add(command);\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "    shift(shift_value);"
            ],
            "added_lines": [
                "    if (!shift(shift_value)) {",
                "      return nullptr;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38496",
        "func_name": "lief-project/LIEF/peek_data",
        "description": "LIEF commit 365a16a was discovered to contain a reachable assertion abort via the component BinaryStream.hpp.",
        "git_url": "https://github.com/lief-project/LIEF/commit/4937a24a0bd6a4eefdc2a10e0bde37445d87c065",
        "commit_title": "Fix #765",
        "commit_text": "",
        "func_before": "virtual inline ok_error_t peek_data(std::vector<uint8_t>& container,\n                                      uint64_t offset, uint64_t size)\n  {\n\n    if (size == 0) {\n      return ok();\n    }\n    // Even though offset + size < ... => offset < ...\n    // the addition could overflow so it's worth checking both\n    const bool read_ok = offset <= this->size() && (offset + size) <= this->size();\n    if (!read_ok) {\n      return make_error_code(lief_errors::read_error);\n    }\n    container.resize(size);\n    if (peek_in(container.data(), offset, size)) {\n      return ok();\n    }\n    return make_error_code(lief_errors::read_error);\n  }",
        "func": "virtual inline ok_error_t peek_data(std::vector<uint8_t>& container,\n                                      uint64_t offset, uint64_t size)\n  {\n\n    if (size == 0) {\n      return ok();\n    }\n    // Even though offset + size < ... => offset < ...\n    // the addition could overflow so it's worth checking both\n    const bool read_ok = offset <= this->size() && (offset + size) <= this->size()\n                                                /* Check for an overflow */\n                                                && (static_cast<int64_t>(offset) >= 0 && static_cast<int64_t>(size) >= 0)\n                                                && (static_cast<int64_t>(offset + size) >= 0);\n    if (!read_ok) {\n      return make_error_code(lief_errors::read_error);\n    }\n    container.resize(size);\n    if (peek_in(container.data(), offset, size)) {\n      return ok();\n    }\n    return make_error_code(lief_errors::read_error);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,10 @@\n     }\n     // Even though offset + size < ... => offset < ...\n     // the addition could overflow so it's worth checking both\n-    const bool read_ok = offset <= this->size() && (offset + size) <= this->size();\n+    const bool read_ok = offset <= this->size() && (offset + size) <= this->size()\n+                                                /* Check for an overflow */\n+                                                && (static_cast<int64_t>(offset) >= 0 && static_cast<int64_t>(size) >= 0)\n+                                                && (static_cast<int64_t>(offset + size) >= 0);\n     if (!read_ok) {\n       return make_error_code(lief_errors::read_error);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    const bool read_ok = offset <= this->size() && (offset + size) <= this->size();"
            ],
            "added_lines": [
                "    const bool read_ok = offset <= this->size() && (offset + size) <= this->size()",
                "                                                /* Check for an overflow */",
                "                                                && (static_cast<int64_t>(offset) >= 0 && static_cast<int64_t>(size) >= 0)",
                "                                                && (static_cast<int64_t>(offset + size) >= 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35934",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. The implementation of tf.reshape op in TensorFlow is vulnerable to a denial of service via CHECK-failure (assertion failure) caused by overflowing the number of elements in a tensor. This issue has been patched in GitHub commit 61f0f9b94df8c0411f0ad0ecc2fec2d3f3c33555. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/61f0f9b94df8c0411f0ad0ecc2fec2d3f3c33555",
        "commit_title": "Fix failed check in tf.reshape.",
        "commit_text": " Passing in too many dimensions causes an assertion failure and a crash. Check input as a precondition and fail gracefully.  PiperOrigin-RevId: 449893553",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& sizes = context->input(1);\n    // Preliminary validation of sizes.\n    OP_REQUIRES(\n        context,\n        (TensorShapeUtils::IsVector(sizes.shape()) ||\n         // TODO(rmlarsen): Disallow legacy use of scalars to represent shape.\n         TensorShapeUtils::IsScalar(sizes.shape())),\n        errors::InvalidArgument(\"sizes input must be 1-D, not \",\n                                sizes.shape().DebugString()));\n\n    // Compute the output shape.  Determine product of specified\n    // dimensions, and find the index of the unspecified one.\n    TensorShape shape;\n    int64_t product = 1;\n    int unknown_index = -1;\n    bool sizes_has_zero_dim;\n    switch (sizes.dtype()) {\n      case DT_INT32:\n        OP_REQUIRES_OK(context,\n                       ValidateSizes<int32>(sizes, &product, &unknown_index,\n                                            &shape, &sizes_has_zero_dim));\n        break;\n      case DT_INT64:\n        OP_REQUIRES_OK(context,\n                       ValidateSizes<int64_t>(sizes, &product, &unknown_index,\n                                              &shape, &sizes_has_zero_dim));\n        break;\n      default:\n        context->CtxFailure(errors::InvalidArgument(\n            \"desired shape must be a DT_INT32 or DT_INT64 vector, not a \",\n            DataTypeString(sizes.dtype())));\n        return;\n    }\n    if (unknown_index != -1) {\n      int64_t input_num_elements = 1;\n      bool input_has_zero_dim = false;\n      for (int dim = 0; dim < input.dims(); dim++) {\n        // For zero dimension, we don't count it into `input_num_elements`\n        // unless `sizes` has no zero dimension, so we are still able to\n        // infer shapes for other dimensions.\n        if (input.dim_size(dim) > 0 || !sizes_has_zero_dim) {\n          input_num_elements *= input.dim_size(dim);\n        } else {\n          input_has_zero_dim = true;\n        }\n      }\n\n      const int64_t missing = input_num_elements / product;\n      if (!input_has_zero_dim) {\n        OP_REQUIRES(\n            context, product * missing == input_num_elements,\n            errors::InvalidArgument(\n                \"Input to reshape is a tensor with \", input_num_elements,\n                \" values, but the requested shape requires a multiple of \",\n                product));\n      }\n      shape.set_dim(unknown_index, missing);\n    }\n    OP_REQUIRES(context, shape.num_elements() == input.NumElements(),\n                errors::InvalidArgument(\"Input to reshape is a tensor with \",\n                                        input.NumElements(),\n                                        \" values, but the requested shape has \",\n                                        shape.num_elements()));\n\n    // Actually produce the reshaped output.\n    Tensor output(input.dtype());\n    CHECK(output.CopyFrom(input, shape));\n    context->set_output(0, output);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& sizes = context->input(1);\n    // Preliminary validation of sizes.\n    OP_REQUIRES(\n        context,\n        (TensorShapeUtils::IsVector(sizes.shape()) ||\n         // TODO(rmlarsen): Disallow legacy use of scalars to represent shape.\n         TensorShapeUtils::IsScalar(sizes.shape())),\n        errors::InvalidArgument(\"sizes input must be 1-D, not \",\n                                sizes.shape().DebugString()));\n    OP_REQUIRES(\n        context, sizes.NumElements() < TensorShape::MaxDimensions(),\n        errors::InvalidArgument(\"too many dimensions: must be < \",\n                                TensorShape::MaxDimensions(), \", but received \",\n                                sizes.NumElements()));\n\n    // Compute the output shape.  Determine product of specified\n    // dimensions, and find the index of the unspecified one.\n    TensorShape shape;\n    int64_t product = 1;\n    int unknown_index = -1;\n    bool sizes_has_zero_dim;\n    switch (sizes.dtype()) {\n      case DT_INT32:\n        OP_REQUIRES_OK(context,\n                       ValidateSizes<int32>(sizes, &product, &unknown_index,\n                                            &shape, &sizes_has_zero_dim));\n        break;\n      case DT_INT64:\n        OP_REQUIRES_OK(context,\n                       ValidateSizes<int64_t>(sizes, &product, &unknown_index,\n                                              &shape, &sizes_has_zero_dim));\n        break;\n      default:\n        context->CtxFailure(errors::InvalidArgument(\n            \"desired shape must be a DT_INT32 or DT_INT64 vector, not a \",\n            DataTypeString(sizes.dtype())));\n        return;\n    }\n    if (unknown_index != -1) {\n      int64_t input_num_elements = 1;\n      bool input_has_zero_dim = false;\n      for (int dim = 0; dim < input.dims(); dim++) {\n        // For zero dimension, we don't count it into `input_num_elements`\n        // unless `sizes` has no zero dimension, so we are still able to\n        // infer shapes for other dimensions.\n        if (input.dim_size(dim) > 0 || !sizes_has_zero_dim) {\n          input_num_elements *= input.dim_size(dim);\n        } else {\n          input_has_zero_dim = true;\n        }\n      }\n\n      const int64_t missing = input_num_elements / product;\n      if (!input_has_zero_dim) {\n        OP_REQUIRES(\n            context, product * missing == input_num_elements,\n            errors::InvalidArgument(\n                \"Input to reshape is a tensor with \", input_num_elements,\n                \" values, but the requested shape requires a multiple of \",\n                product));\n      }\n      shape.set_dim(unknown_index, missing);\n    }\n    OP_REQUIRES(context, shape.num_elements() == input.NumElements(),\n                errors::InvalidArgument(\"Input to reshape is a tensor with \",\n                                        input.NumElements(),\n                                        \" values, but the requested shape has \",\n                                        shape.num_elements()));\n\n    // Actually produce the reshaped output.\n    Tensor output(input.dtype());\n    CHECK(output.CopyFrom(input, shape));\n    context->set_output(0, output);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,11 @@\n          TensorShapeUtils::IsScalar(sizes.shape())),\n         errors::InvalidArgument(\"sizes input must be 1-D, not \",\n                                 sizes.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, sizes.NumElements() < TensorShape::MaxDimensions(),\n+        errors::InvalidArgument(\"too many dimensions: must be < \",\n+                                TensorShape::MaxDimensions(), \", but received \",\n+                                sizes.NumElements()));\n \n     // Compute the output shape.  Determine product of specified\n     // dimensions, and find the index of the unspecified one.",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, sizes.NumElements() < TensorShape::MaxDimensions(),",
                "        errors::InvalidArgument(\"too many dimensions: must be < \",",
                "                                TensorShape::MaxDimensions(), \", but received \",",
                "                                sizes.NumElements()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35935",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. The implementation of SobolSampleOp is vulnerable to a denial of service via CHECK-failure (assertion failure) caused by assuming `input(0)`, `input(1)`, and `input(2)` to be scalar. This issue has been patched in GitHub commit c65c67f88ad770662e8f191269a907bf2b94b1bf. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c65c67f88ad770662e8f191269a907bf2b94b1bf",
        "commit_title": "Fix `CHECK`-fail due to passing invalid tensors in `SobolOp`.",
        "commit_text": " PiperOrigin-RevId: 460794378",
        "func_before": "void Compute(OpKernelContext* context) override {\n    int32_t dim = context->input(0).scalar<int32_t>()();\n    int32_t num_results = context->input(1).scalar<int32_t>()();\n    int32_t skip = context->input(2).scalar<int32_t>()();\n\n    OP_REQUIRES(context, dim >= 1,\n                errors::InvalidArgument(\"dim must be at least one\"));\n    OP_REQUIRES(context, dim <= sobol_data::kMaxSobolDim,\n                errors::InvalidArgument(\"dim must be at most \",\n                                        sobol_data::kMaxSobolDim));\n    OP_REQUIRES(context, num_results >= 1,\n                errors::InvalidArgument(\"num_results must be at least one\"));\n    OP_REQUIRES(context, skip >= 0,\n                errors::InvalidArgument(\"skip must be non-negative\"));\n    OP_REQUIRES(context,\n                num_results < std::numeric_limits<int32_t>::max() - skip,\n                errors::InvalidArgument(\"num_results+skip must be less than \",\n                                        std::numeric_limits<int32_t>::max()));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\n                       0, TensorShape({num_results, dim}), &output));\n    auto output_flat = output->flat<T>();\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n    int num_threads = worker_threads.num_threads;\n    int block_size = std::max(\n        kMinBlockSize, static_cast<int>(std::ceil(\n                           static_cast<float>(num_results) / num_threads)));\n    worker_threads.workers->TransformRangeConcurrently(\n        block_size, num_results /* total */,\n        [&dim, &skip, &output_flat](const int start, const int end) {\n          CalculateSobolSample<T>(dim, end - start /* num_results */, skip,\n                                  start, output_flat);\n        });\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n                errors::InvalidArgument(\"dim must be a scalar\"));\n    int32_t dim = context->input(0).scalar<int32_t>()();\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n                errors::InvalidArgument(\"num_results must be a scalar\"));\n    int32_t num_results = context->input(1).scalar<int32_t>()();\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n                errors::InvalidArgument(\"skip must be a scalar\"));\n    int32_t skip = context->input(2).scalar<int32_t>()();\n\n    OP_REQUIRES(context, dim >= 1,\n                errors::InvalidArgument(\"dim must be at least one\"));\n    OP_REQUIRES(context, dim <= sobol_data::kMaxSobolDim,\n                errors::InvalidArgument(\"dim must be at most \",\n                                        sobol_data::kMaxSobolDim));\n    OP_REQUIRES(context, num_results >= 1,\n                errors::InvalidArgument(\"num_results must be at least one\"));\n    OP_REQUIRES(context, skip >= 0,\n                errors::InvalidArgument(\"skip must be non-negative\"));\n    OP_REQUIRES(context,\n                num_results < std::numeric_limits<int32_t>::max() - skip,\n                errors::InvalidArgument(\"num_results+skip must be less than \",\n                                        std::numeric_limits<int32_t>::max()));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\n                       0, TensorShape({num_results, dim}), &output));\n    auto output_flat = output->flat<T>();\n    const DeviceBase::CpuWorkerThreads& worker_threads =\n        *(context->device()->tensorflow_cpu_worker_threads());\n    int num_threads = worker_threads.num_threads;\n    int block_size = std::max(\n        kMinBlockSize, static_cast<int>(std::ceil(\n                           static_cast<float>(num_results) / num_threads)));\n    worker_threads.workers->TransformRangeConcurrently(\n        block_size, num_results /* total */,\n        [&dim, &skip, &output_flat](const int start, const int end) {\n          CalculateSobolSample<T>(dim, end - start /* num_results */, skip,\n                                  start, output_flat);\n        });\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,12 @@\n void Compute(OpKernelContext* context) override {\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"dim must be a scalar\"));\n     int32_t dim = context->input(0).scalar<int32_t>()();\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"num_results must be a scalar\"));\n     int32_t num_results = context->input(1).scalar<int32_t>()();\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),\n+                errors::InvalidArgument(\"skip must be a scalar\"));\n     int32_t skip = context->input(2).scalar<int32_t>()();\n \n     OP_REQUIRES(context, dim >= 1,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),",
                "                errors::InvalidArgument(\"dim must be a scalar\"));",
                "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),",
                "                errors::InvalidArgument(\"num_results must be a scalar\"));",
                "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(context->input(0).shape()),",
                "                errors::InvalidArgument(\"skip must be a scalar\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35941",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. The `AvgPoolOp` function takes an argument `ksize` that must be positive but is not checked. A negative `ksize` can trigger a `CHECK` failure and crash the program. We have patched the issue in GitHub commit 3a6ac52664c6c095aa2b114e742b0aa17fdce78f. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds to this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3a6ac52664c6c095aa2b114e742b0aa17fdce78f",
        "commit_title": "Fix security vulnerability with AvgPoolGrad",
        "commit_text": " PiperOrigin-RevId: 461724457",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in_shape = context->input(0);\n    const Tensor& out_backprop = context->input(1);\n    // For avgpooling, tensor_in_shape should have 1 dimension, and 4 elements.\n    OP_REQUIRES(\n        context,\n        tensor_in_shape.dims() == 1 && tensor_in_shape.NumElements() == 4,\n        errors::InvalidArgument(\"out_backprop must be 1-dimensional and 4 \"\n                                \"elements\"));\n    // For avgpooling, out_backprop should have 4 dimensions.\n    OP_REQUIRES(context, out_backprop.dims() == 4,\n                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n    TensorShape output_shape;\n    auto shape_vec = tensor_in_shape.vec<int32>();\n    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n      output_shape.AddDim(shape_vec(i));\n    }\n    if (output_shape.num_elements() == 0) {\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, output_shape, &output));\n      return;\n    }\n\n#if CUDNN_VERSION >= 7300\n    DnnPoolingGradOp<T>::Compute(context, se::dnn::PoolingMode::kAverage,\n                                 ksize_, stride_, padding_,\n                                 /*explicit_paddings=*/{}, data_format_,\n                                 nullptr, nullptr, out_backprop, output_shape,\n                                 /*propagate_nans=*/false);\n#else\n    if (data_format_ == FORMAT_NHWC) {\n      const int64 out_backprop_batch = out_backprop.dim_size(0);\n      const int64 out_backprop_rows = out_backprop.dim_size(1);\n      const int64 out_backprop_cols = out_backprop.dim_size(2);\n      const int64 out_backprop_depth = out_backprop.dim_size(3);\n\n      const int64 in_rows = output_shape.dim_size(1);\n      const int64 in_cols = output_shape.dim_size(2);\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, output_shape, &output));\n\n      const int window_rows = ksize_[1];\n      const int window_cols = ksize_[2];\n      const int depth_window = ksize_[3];\n\n      const int row_stride = stride_[1];\n      const int col_stride = stride_[2];\n\n      // We (will) use different code for spatial pooling and\n      // non-spatial pooling.\n      //\n      // Spatial pooling is when depth_window = 1\n      OP_REQUIRES(context, depth_window == 1,\n                  errors::Unimplemented(\"Non-spatial pooling is not \"\n                                        \"yet supported. Volunteers? :)\"));\n\n      int64 out_height, out_width, pad_rows, pad_cols;\n      OP_REQUIRES_OK(context,\n                     GetWindowedOutputSize(in_rows, window_rows, row_stride,\n                                           padding_, &out_height, &pad_rows));\n      OP_REQUIRES_OK(context,\n                     GetWindowedOutputSize(in_cols, window_cols, col_stride,\n                                           padding_, &out_width, &pad_cols));\n\n      RunAvePoolBackwardNHWC<T>(out_backprop.flat<T>().data(),  // top_diff\n                                out_backprop_batch,             // num\n                                in_rows,                        // height\n                                in_cols,                        // width\n                                out_backprop_depth,             // channels\n                                out_backprop_rows,              // pooled_height\n                                out_backprop_cols,              // pooled_width\n                                window_rows,                    // kernel_h\n                                window_cols,                    // kernel_w\n                                row_stride,                     // stride_h\n                                col_stride,                     // stride_w\n                                pad_rows,                       // pad_t\n                                pad_cols,                       // pad_l\n                                output->flat<T>().data(),       // bottom_diff\n                                context->eigen_gpu_device());   // d\n    } else {\n      DnnPoolingGradOp<T>::Compute(context, se::dnn::PoolingMode::kAverage,\n                                   ksize_, stride_, padding_,\n                                   /*explicit_paddings=*/{}, data_format_,\n                                   nullptr, nullptr, out_backprop, output_shape,\n                                   /*propagate_nans=*/false);\n    }\n#endif  // CUDNN_VERSION >= 7300\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in_shape = context->input(0);\n    const Tensor& out_backprop = context->input(1);\n    // For avgpooling, tensor_in_shape should have 1 dimension, and 4 elements.\n    OP_REQUIRES(\n        context,\n        tensor_in_shape.dims() == 1 && tensor_in_shape.NumElements() == 4,\n        errors::InvalidArgument(\"out_backprop must be 1-dimensional and 4 \"\n                                \"elements\"));\n    // For avgpooling, out_backprop should have 4 dimensions.\n    OP_REQUIRES(context, out_backprop.dims() == 4,\n                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n    TensorShape output_shape;\n    auto shape_vec = tensor_in_shape.vec<int32>();\n    for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n    }\n    if (output_shape.num_elements() == 0) {\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, output_shape, &output));\n      return;\n    }\n\n#if CUDNN_VERSION >= 7300\n    DnnPoolingGradOp<T>::Compute(context, se::dnn::PoolingMode::kAverage,\n                                 ksize_, stride_, padding_,\n                                 /*explicit_paddings=*/{}, data_format_,\n                                 nullptr, nullptr, out_backprop, output_shape,\n                                 /*propagate_nans=*/false);\n#else\n    if (data_format_ == FORMAT_NHWC) {\n      const int64 out_backprop_batch = out_backprop.dim_size(0);\n      const int64 out_backprop_rows = out_backprop.dim_size(1);\n      const int64 out_backprop_cols = out_backprop.dim_size(2);\n      const int64 out_backprop_depth = out_backprop.dim_size(3);\n\n      const int64 in_rows = output_shape.dim_size(1);\n      const int64 in_cols = output_shape.dim_size(2);\n      Tensor* output = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, output_shape, &output));\n\n      const int window_rows = ksize_[1];\n      const int window_cols = ksize_[2];\n      const int depth_window = ksize_[3];\n\n      const int row_stride = stride_[1];\n      const int col_stride = stride_[2];\n\n      // We (will) use different code for spatial pooling and\n      // non-spatial pooling.\n      //\n      // Spatial pooling is when depth_window = 1\n      OP_REQUIRES(context, depth_window == 1,\n                  errors::Unimplemented(\"Non-spatial pooling is not \"\n                                        \"yet supported. Volunteers? :)\"));\n\n      int64 out_height, out_width, pad_rows, pad_cols;\n      OP_REQUIRES_OK(context,\n                     GetWindowedOutputSize(in_rows, window_rows, row_stride,\n                                           padding_, &out_height, &pad_rows));\n      OP_REQUIRES_OK(context,\n                     GetWindowedOutputSize(in_cols, window_cols, col_stride,\n                                           padding_, &out_width, &pad_cols));\n\n      RunAvePoolBackwardNHWC<T>(out_backprop.flat<T>().data(),  // top_diff\n                                out_backprop_batch,             // num\n                                in_rows,                        // height\n                                in_cols,                        // width\n                                out_backprop_depth,             // channels\n                                out_backprop_rows,              // pooled_height\n                                out_backprop_cols,              // pooled_width\n                                window_rows,                    // kernel_h\n                                window_cols,                    // kernel_w\n                                row_stride,                     // stride_h\n                                col_stride,                     // stride_w\n                                pad_rows,                       // pad_t\n                                pad_cols,                       // pad_l\n                                output->flat<T>().data(),       // bottom_diff\n                                context->eigen_gpu_device());   // d\n    } else {\n      DnnPoolingGradOp<T>::Compute(context, se::dnn::PoolingMode::kAverage,\n                                   ksize_, stride_, padding_,\n                                   /*explicit_paddings=*/{}, data_format_,\n                                   nullptr, nullptr, out_backprop, output_shape,\n                                   /*propagate_nans=*/false);\n    }\n#endif  // CUDNN_VERSION >= 7300\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n     TensorShape output_shape;\n     auto shape_vec = tensor_in_shape.vec<int32>();\n     for (int64_t i = 0; i < tensor_in_shape.NumElements(); ++i) {\n-      output_shape.AddDim(shape_vec(i));\n+      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));\n     }\n     if (output_shape.num_elements() == 0) {\n       Tensor* output = nullptr;",
        "diff_line_info": {
            "deleted_lines": [
                "      output_shape.AddDim(shape_vec(i));"
            ],
            "added_lines": [
                "      OP_REQUIRES_OK(context, output_shape.AddDimWithStatus(shape_vec(i)));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35952",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. The `UnbatchGradOp` function takes an argument `id` that is assumed to be a scalar. A nonscalar `id` can trigger a `CHECK` failure and crash the program. It also requires its argument `batch_index` to contain three times the number of elements as indicated in its `batch_index.dim_size(0)`. An incorrect `batch_index` can trigger a `CHECK` failure and crash the program. We have patched the issue in GitHub commit 5f945fc6409a3c1e90d6970c9292f805f6e6ddf2. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/5f945fc6409a3c1e90d6970c9292f805f6e6ddf2",
        "commit_title": "Fix security vulnerability with UnbatchGradKernel",
        "commit_text": " PiperOrigin-RevId: 460992964",
        "func_before": "Status Compute(OpKernelContext* context,\n                 const AsyncOpKernel::DoneCallback& done) {\n    const Tensor& data_t = context->input(0);\n    const Tensor& batch_index_t = context->input(1);\n    const Tensor& grad_t = context->input(2);\n\n    mutex_lock ml(mu_);\n\n    const int64_t batch_key = context->input(3).scalar<int64_t>()();\n    // Mark our tensor as available.\n    if (!available_tensors_.emplace(batch_key, grad_t).second) {\n      return errors::InvalidArgument(\"Two runs with the same batch key.\");\n    }\n\n    // Check whether we have a valid input tensor and, if so, create its\n    // dispatch logic.\n    if (data_t.NumElements() > 0) {\n      if (batch_index_t.NumElements() == 0) {\n        return errors::InvalidArgument(\n            \"batch_index is empty while the tensor isn't.\");\n      }\n      std::unordered_set<int64_t> missing_tensors;\n      const auto batch_index =\n          batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});\n      for (int i = 0; i < batch_index_t.dim_size(0); ++i) {\n        const int64_t batch_key = batch_index(i, 0);\n        if (available_tensors_.find(batch_key) == available_tensors_.end()) {\n          missing_tensors.emplace(batch_key);\n        }\n      }\n      if (missing_tensors.empty()) {\n        return OutputBatch(context, done);\n      }\n      if (!available_batches_\n               .emplace(batch_key, Batch{missing_tensors, context, done})\n               .second) {\n        return errors::InvalidArgument(\n            \"Batch key with valid batch used twice.\");\n      }\n      for (const int64_t i : missing_tensors) {\n        if (!desired_tensor_to_batch_map_.emplace(i, batch_key).second) {\n          return errors::InvalidArgument(\n              \"Missing tensor wanted by more than one batch.\");\n        }\n      }\n    } else {\n      // If we don't have a valid input tensor we can output an empty tensor and\n      // call our done closure.\n      TensorShape output_shape(grad_t.shape());\n      output_shape.set_dim(0, 0);\n      Tensor* output = nullptr;\n      TF_RETURN_IF_ERROR(context->allocate_output(0, output_shape, &output));\n      done();\n    }\n\n    // Search to see whether our tensor is desired by any existing batch.\n    auto desire_it = desired_tensor_to_batch_map_.find(batch_key);\n    if (desire_it != desired_tensor_to_batch_map_.end()) {\n      // Mark our tensor as no longer missing.\n      auto batch_it = available_batches_.find(desire_it->second);\n      desired_tensor_to_batch_map_.erase(desire_it);\n      if (batch_it == available_batches_.end()) {\n        return errors::InvalidArgument(\"Batch no longer exists.\");\n      }\n      batch_it->second.missing_tensors.erase(batch_key);\n      // If all tensors are available we should concatenate them and dispatch\n      // the batch.\n      if (batch_it->second.missing_tensors.empty()) {\n        TF_RETURN_IF_ERROR(\n            OutputBatch(batch_it->second.context, batch_it->second.done));\n        available_batches_.erase(batch_it);\n      }\n    }\n    return OkStatus();\n  }",
        "func": "Status Compute(OpKernelContext* context,\n                 const AsyncOpKernel::DoneCallback& done) {\n    const Tensor& data_t = context->input(0);\n    const Tensor& batch_index_t = context->input(1);\n    const Tensor& grad_t = context->input(2);\n    const Tensor& batch_key_t = context->input(3);\n\n    mutex_lock ml(mu_);\n    if (batch_key_t.NumElements() != 1) {\n      return errors::InvalidArgument(\"Expected `id` to be scalar. Received \",\n                                     batch_key_t.DebugString());\n    }\n\n    const int64_t batch_key = context->input(3).scalar<int64_t>()();\n    // Mark our tensor as available.\n    if (!available_tensors_.emplace(batch_key, grad_t).second) {\n      return errors::InvalidArgument(\"Two runs with the same batch key.\");\n    }\n\n    // Check whether we have a valid input tensor and, if so, create its\n    // dispatch logic.\n    if (data_t.NumElements() > 0) {\n      if (batch_index_t.NumElements() == 0) {\n        return errors::InvalidArgument(\n            \"batch_index is empty while the tensor isn't.\");\n      }\n      std::unordered_set<int64_t> missing_tensors;\n      if (batch_index_t.NumElements() != batch_index_t.dim_size(0) * 3) {\n        return errors::InvalidArgument(\n            \"batch_index should contain \", batch_index_t.dim_size(0) * 3,\n            \" elements. Received \", batch_index_t.NumElements());\n      }\n      const auto batch_index =\n          batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});\n      for (int i = 0; i < batch_index_t.dim_size(0); ++i) {\n        const int64_t batch_key = batch_index(i, 0);\n        if (available_tensors_.find(batch_key) == available_tensors_.end()) {\n          missing_tensors.emplace(batch_key);\n        }\n      }\n      if (missing_tensors.empty()) {\n        return OutputBatch(context, done);\n      }\n      if (!available_batches_\n               .emplace(batch_key, Batch{missing_tensors, context, done})\n               .second) {\n        return errors::InvalidArgument(\n            \"Batch key with valid batch used twice.\");\n      }\n      for (const int64_t i : missing_tensors) {\n        if (!desired_tensor_to_batch_map_.emplace(i, batch_key).second) {\n          return errors::InvalidArgument(\n              \"Missing tensor wanted by more than one batch.\");\n        }\n      }\n    } else {\n      // If we don't have a valid input tensor we can output an empty tensor and\n      // call our done closure.\n      TensorShape output_shape(grad_t.shape());\n      output_shape.set_dim(0, 0);\n      Tensor* output = nullptr;\n      TF_RETURN_IF_ERROR(context->allocate_output(0, output_shape, &output));\n      done();\n    }\n\n    // Search to see whether our tensor is desired by any existing batch.\n    auto desire_it = desired_tensor_to_batch_map_.find(batch_key);\n    if (desire_it != desired_tensor_to_batch_map_.end()) {\n      // Mark our tensor as no longer missing.\n      auto batch_it = available_batches_.find(desire_it->second);\n      desired_tensor_to_batch_map_.erase(desire_it);\n      if (batch_it == available_batches_.end()) {\n        return errors::InvalidArgument(\"Batch no longer exists.\");\n      }\n      batch_it->second.missing_tensors.erase(batch_key);\n      // If all tensors are available we should concatenate them and dispatch\n      // the batch.\n      if (batch_it->second.missing_tensors.empty()) {\n        TF_RETURN_IF_ERROR(\n            OutputBatch(batch_it->second.context, batch_it->second.done));\n        available_batches_.erase(batch_it);\n      }\n    }\n    return OkStatus();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,13 @@\n     const Tensor& data_t = context->input(0);\n     const Tensor& batch_index_t = context->input(1);\n     const Tensor& grad_t = context->input(2);\n+    const Tensor& batch_key_t = context->input(3);\n \n     mutex_lock ml(mu_);\n+    if (batch_key_t.NumElements() != 1) {\n+      return errors::InvalidArgument(\"Expected `id` to be scalar. Received \",\n+                                     batch_key_t.DebugString());\n+    }\n \n     const int64_t batch_key = context->input(3).scalar<int64_t>()();\n     // Mark our tensor as available.\n@@ -20,6 +25,11 @@\n             \"batch_index is empty while the tensor isn't.\");\n       }\n       std::unordered_set<int64_t> missing_tensors;\n+      if (batch_index_t.NumElements() != batch_index_t.dim_size(0) * 3) {\n+        return errors::InvalidArgument(\n+            \"batch_index should contain \", batch_index_t.dim_size(0) * 3,\n+            \" elements. Received \", batch_index_t.NumElements());\n+      }\n       const auto batch_index =\n           batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});\n       for (int i = 0; i < batch_index_t.dim_size(0); ++i) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    const Tensor& batch_key_t = context->input(3);",
                "    if (batch_key_t.NumElements() != 1) {",
                "      return errors::InvalidArgument(\"Expected `id` to be scalar. Received \",",
                "                                     batch_key_t.DebugString());",
                "    }",
                "      if (batch_index_t.NumElements() != batch_index_t.dim_size(0) * 3) {",
                "        return errors::InvalidArgument(",
                "            \"batch_index should contain \", batch_index_t.dim_size(0) * 3,",
                "            \" elements. Received \", batch_index_t.NumElements());",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35959",
        "func_name": "tensorflow/XlaOpKernelContext::ConstantInputAsShape",
        "description": "TensorFlow is an open source platform for machine learning. The implementation of `AvgPool3DGradOp` does not fully validate the input `orig_input_shape`. This results in an overflow that results in a `CHECK` failure which can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 9178ac9d6389bdc54638ab913ea0e419234d14eb. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/9178ac9d6389bdc54638ab913ea0e419234d14eb",
        "commit_title": "Fix security vulnerability with AvgPool3DGrad.",
        "commit_text": " PiperOrigin-RevId: 461244371",
        "func_before": "Status XlaOpKernelContext::ConstantInputAsShape(int index, TensorShape* shape,\n                                                xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  std::vector<int64_t> dims;\n  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n  *shape = TensorShape(dims);\n  return OkStatus();\n}",
        "func": "Status XlaOpKernelContext::ConstantInputAsShape(int index, TensorShape* shape,\n                                                xla::ValueInferenceMode mode) {\n  xla::Literal literal;\n  TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n  std::vector<int64_t> dims;\n  TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n\n  int64_t num_elements = 1;\n  for (auto i = dims.begin(); i != dims.end(); ++i) {\n    num_elements = MultiplyWithoutOverflow(num_elements, *i);\n    if (num_elements < 0)\n      return errors::InvalidArgument(\n          \"The total elements specified by orig_input_shape is too large.\",\n          \"Encountered overflow after multiplying\", *i,\n          \", result: \", num_elements);\n  }\n  *shape = TensorShape(dims);\n  return OkStatus();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,16 @@\n   TF_RETURN_IF_ERROR(ConstantInput(index, &literal, mode));\n   std::vector<int64_t> dims;\n   TF_RETURN_IF_ERROR(LiteralToInt64Vector(literal, &dims));\n+\n+  int64_t num_elements = 1;\n+  for (auto i = dims.begin(); i != dims.end(); ++i) {\n+    num_elements = MultiplyWithoutOverflow(num_elements, *i);\n+    if (num_elements < 0)\n+      return errors::InvalidArgument(\n+          \"The total elements specified by orig_input_shape is too large.\",\n+          \"Encountered overflow after multiplying\", *i,\n+          \", result: \", num_elements);\n+  }\n   *shape = TensorShape(dims);\n   return OkStatus();\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  int64_t num_elements = 1;",
                "  for (auto i = dims.begin(); i != dims.end(); ++i) {",
                "    num_elements = MultiplyWithoutOverflow(num_elements, *i);",
                "    if (num_elements < 0)",
                "      return errors::InvalidArgument(",
                "          \"The total elements specified by orig_input_shape is too large.\",",
                "          \"Encountered overflow after multiplying\", *i,",
                "          \", result: \", num_elements);",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35963",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. The implementation of `FractionalAvgPoolGrad` does not fully validate the input `orig_input_tensor_shape`. This results in an overflow that results in a `CHECK` failure which can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 03a659d7be9a1154fdf5eeac221e5950fec07dad. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/03a659d7be9a1154fdf5eeac221e5950fec07dad",
        "commit_title": "Fix security vulnerability with FractionalAvgPoolGrad",
        "commit_text": " PiperOrigin-RevId: 462292194",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Here's the basic idea:\n    // Batch and depth dimension are independent from row and col dimension. And\n    // because FractionalAvgPool currently only support pooling along row and\n    // col, we can basically think of this 4D tensor backpropagation as\n    // operation of a series of 2D planes.\n    //\n    // For each element of a 'slice' (2D plane) of output_backprop, we need to\n    // figure out its contributors when doing FractionalAvgPool operation. This\n    // can be done based on row_pooling_sequence, col_pooling_seq and\n    // overlapping.\n    // Once we figure out the original contributors, we just need to evenly\n    // divide the value of this element among these contributors.\n    //\n    // Internally, we divide the out_backprop tensor and store it in a temporary\n    // tensor of double type. And cast it to the corresponding type.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenDoubleMatrixMap;\n\n    // Grab the inputs.\n    const Tensor& orig_input_tensor_shape = context->input(0);\n    OP_REQUIRES(context,\n                orig_input_tensor_shape.dims() == 1 &&\n                    orig_input_tensor_shape.NumElements() == 4,\n                errors::InvalidArgument(\"original input tensor shape must be\"\n                                        \"1-dimensional and 4 elements\"));\n    const Tensor& out_backprop = context->input(1);\n    const Tensor& row_seq_tensor = context->input(2);\n    const Tensor& col_seq_tensor = context->input(3);\n\n    const int64_t out_batch = out_backprop.dim_size(0);\n    const int64_t out_rows = out_backprop.dim_size(1);\n    const int64_t out_cols = out_backprop.dim_size(2);\n    const int64_t out_depth = out_backprop.dim_size(3);\n\n    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", row_seq_tensor must have at least \",\n                                        out_rows + 1, \" elements, but got \",\n                                        row_seq_tensor.NumElements()));\n    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", col_seq_tensor must have at least \",\n                                        out_cols + 1, \" elements, but got \",\n                                        col_seq_tensor.NumElements()));\n\n    auto row_seq_tensor_flat = row_seq_tensor.flat<int64_t>();\n    auto col_seq_tensor_flat = col_seq_tensor.flat<int64_t>();\n    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64_t>();\n\n    const int64_t in_batch = orig_input_tensor_shape_flat(0);\n    const int64_t in_rows = orig_input_tensor_shape_flat(1);\n    const int64_t in_cols = orig_input_tensor_shape_flat(2);\n    const int64_t in_depth = orig_input_tensor_shape_flat(3);\n    OP_REQUIRES(\n        context, in_batch != 0,\n        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_rows != 0,\n        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_cols != 0,\n        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_depth != 0,\n        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n\n    constexpr int tensor_in_and_out_dims = 4;\n    // Transform orig_input_tensor_shape into TensorShape\n    TensorShape in_shape;\n    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {\n      in_shape.AddDim(orig_input_tensor_shape_flat(i));\n    }\n\n    // Create intermediate in_backprop.\n    Tensor in_backprop_tensor_temp;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {0}, DataTypeToEnum<double>::v(), in_shape,\n                                &in_backprop_tensor_temp));\n    in_backprop_tensor_temp.flat<double>().setZero();\n    // Transform 4D tensor to 2D matrix.\n    EigenDoubleMatrixMap in_backprop_tensor_temp_mat(\n        in_backprop_tensor_temp.flat<double>().data(), in_depth,\n        in_cols * in_rows * in_batch);\n    ConstEigenMatrixMap out_backprop_mat(out_backprop.flat<T>().data(),\n                                         out_depth,\n                                         out_cols * out_rows * out_batch);\n    // Loop through each element of out_backprop and evenly distribute the\n    // element to the corresponding pooling cell.\n    const int64_t in_max_row_index = in_rows - 1;\n    const int64_t in_max_col_index = in_cols - 1;\n    for (int64_t b = 0; b < out_batch; ++b) {\n      for (int64_t r = 0; r < out_rows; ++r) {\n        const int64_t in_row_start = row_seq_tensor_flat(r);\n\n        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                          : row_seq_tensor_flat(r + 1) - 1;\n        in_row_end = std::min(in_row_end, in_max_row_index);\n        OP_REQUIRES(context, in_row_start >= 0 && in_row_end >= 0,\n                    errors::InvalidArgument(\n                        \"Row sequence tensor values must not be negative, got \",\n                        row_seq_tensor_flat));\n\n        for (int64_t c = 0; c < out_cols; ++c) {\n          const int64_t in_col_start = col_seq_tensor_flat(c);\n          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                            : col_seq_tensor_flat(c + 1) - 1;\n          in_col_end = std::min(in_col_end, in_max_col_index);\n\n          OP_REQUIRES(\n              context, in_col_start >= 0 && in_col_end >= 0,\n              errors::InvalidArgument(\n                  \"Column sequence tensor values must not be negative, got \",\n                  col_seq_tensor_flat));\n          const int64_t num_elements_in_pooling_cell =\n              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n          const int64_t out_index = (b * out_rows + r) * out_cols + c;\n          // Now we can evenly distribute out_backprop(b, h, w, *) to\n          // in_backprop(b, hs:he, ws:we, *).\n          for (int64_t in_r = in_row_start; in_r <= in_row_end; ++in_r) {\n            for (int64_t in_c = in_col_start; in_c <= in_col_end; ++in_c) {\n              const int64_t in_index = (b * in_rows + in_r) * in_cols + in_c;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < out_depth; ++d) {\n                const double out_backprop_element = static_cast<double>(\n                    out_backprop_mat.coeffRef(d, out_index));\n                double& in_backprop_ref =\n                    in_backprop_tensor_temp_mat.coeffRef(d, in_index);\n                in_backprop_ref +=\n                    out_backprop_element / num_elements_in_pooling_cell;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Depending on the type, cast double to type T.\n    Tensor* in_backprop_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, in_shape, &in_backprop_tensor));\n    auto in_backprop_tensor_flat = in_backprop_tensor->flat<T>();\n    auto in_backprop_tensor_temp_flat = in_backprop_tensor_temp.flat<double>();\n    for (int64_t i = 0; i < in_backprop_tensor_flat.size(); ++i) {\n      in_backprop_tensor_flat(i) =\n          static_cast<T>(in_backprop_tensor_temp_flat(i));\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Here's the basic idea:\n    // Batch and depth dimension are independent from row and col dimension. And\n    // because FractionalAvgPool currently only support pooling along row and\n    // col, we can basically think of this 4D tensor backpropagation as\n    // operation of a series of 2D planes.\n    //\n    // For each element of a 'slice' (2D plane) of output_backprop, we need to\n    // figure out its contributors when doing FractionalAvgPool operation. This\n    // can be done based on row_pooling_sequence, col_pooling_seq and\n    // overlapping.\n    // Once we figure out the original contributors, we just need to evenly\n    // divide the value of this element among these contributors.\n    //\n    // Internally, we divide the out_backprop tensor and store it in a temporary\n    // tensor of double type. And cast it to the corresponding type.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<double, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenDoubleMatrixMap;\n\n    // Grab the inputs.\n    const Tensor& orig_input_tensor_shape = context->input(0);\n    OP_REQUIRES(context,\n                orig_input_tensor_shape.dims() == 1 &&\n                    orig_input_tensor_shape.NumElements() == 4,\n                errors::InvalidArgument(\"original input tensor shape must be\"\n                                        \"1-dimensional and 4 elements\"));\n    int64_t num_elements = 1;\n    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {\n      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,\n                  errors::InvalidArgument(\n                      \"orig_input_tensor_shape must be positive, got: \",\n                      orig_input_tensor_shape.dim_size(i)));\n      num_elements = MultiplyWithoutOverflow(\n          num_elements, orig_input_tensor_shape.dim_size(i));\n      OP_REQUIRES(\n          context, num_elements > 0,\n          errors::InvalidArgument(\n              \"The total elements specified by orig_input_tensor_shape\",\n              \" is too large. Encountered overflow after multiplying \",\n              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));\n    }\n\n    const Tensor& out_backprop = context->input(1);\n    OP_REQUIRES(context, out_backprop.dims() == 4,\n                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n    for (int i = 0; i < out_backprop.dims(); i++) {\n      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,\n                  errors::InvalidArgument(\n                      \"out_backprop must be positive for all dimension, got:\",\n                      out_backprop.dim_size(i)));\n    }\n\n    const Tensor& row_seq_tensor = context->input(2);\n    const Tensor& col_seq_tensor = context->input(3);\n\n    const int64_t out_batch = out_backprop.dim_size(0);\n    const int64_t out_rows = out_backprop.dim_size(1);\n    const int64_t out_cols = out_backprop.dim_size(2);\n    const int64_t out_depth = out_backprop.dim_size(3);\n\n    OP_REQUIRES(context, row_seq_tensor.NumElements() > out_rows,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", row_seq_tensor must have at least \",\n                                        out_rows + 1, \" elements, but got \",\n                                        row_seq_tensor.NumElements()));\n    OP_REQUIRES(context, col_seq_tensor.NumElements() > out_cols,\n                errors::InvalidArgument(\"Given out_backprop shape \",\n                                        out_backprop.shape().DebugString(),\n                                        \", col_seq_tensor must have at least \",\n                                        out_cols + 1, \" elements, but got \",\n                                        col_seq_tensor.NumElements()));\n\n    auto row_seq_tensor_flat = row_seq_tensor.flat<int64_t>();\n    auto col_seq_tensor_flat = col_seq_tensor.flat<int64_t>();\n    auto orig_input_tensor_shape_flat = orig_input_tensor_shape.flat<int64_t>();\n\n    const int64_t in_batch = orig_input_tensor_shape_flat(0);\n    const int64_t in_rows = orig_input_tensor_shape_flat(1);\n    const int64_t in_cols = orig_input_tensor_shape_flat(2);\n    const int64_t in_depth = orig_input_tensor_shape_flat(3);\n    OP_REQUIRES(\n        context, in_batch != 0,\n        errors::InvalidArgument(\"Batch dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_rows != 0,\n        errors::InvalidArgument(\"Rows dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_cols != 0,\n        errors::InvalidArgument(\"Columns dimension of input must not be 0\"));\n    OP_REQUIRES(\n        context, in_depth != 0,\n        errors::InvalidArgument(\"Depth dimension of input must not be 0\"));\n\n    constexpr int tensor_in_and_out_dims = 4;\n    // Transform orig_input_tensor_shape into TensorShape\n    TensorShape in_shape;\n    for (auto i = 0; i < tensor_in_and_out_dims; ++i) {\n      in_shape.AddDim(orig_input_tensor_shape_flat(i));\n    }\n\n    // Create intermediate in_backprop.\n    Tensor in_backprop_tensor_temp;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {0}, DataTypeToEnum<double>::v(), in_shape,\n                                &in_backprop_tensor_temp));\n    in_backprop_tensor_temp.flat<double>().setZero();\n    // Transform 4D tensor to 2D matrix.\n    EigenDoubleMatrixMap in_backprop_tensor_temp_mat(\n        in_backprop_tensor_temp.flat<double>().data(), in_depth,\n        in_cols * in_rows * in_batch);\n    ConstEigenMatrixMap out_backprop_mat(out_backprop.flat<T>().data(),\n                                         out_depth,\n                                         out_cols * out_rows * out_batch);\n    // Loop through each element of out_backprop and evenly distribute the\n    // element to the corresponding pooling cell.\n    const int64_t in_max_row_index = in_rows - 1;\n    const int64_t in_max_col_index = in_cols - 1;\n    for (int64_t b = 0; b < out_batch; ++b) {\n      for (int64_t r = 0; r < out_rows; ++r) {\n        const int64_t in_row_start = row_seq_tensor_flat(r);\n\n        int64_t in_row_end = overlapping_ ? row_seq_tensor_flat(r + 1)\n                                          : row_seq_tensor_flat(r + 1) - 1;\n        in_row_end = std::min(in_row_end, in_max_row_index);\n        OP_REQUIRES(context, in_row_start >= 0 && in_row_end >= 0,\n                    errors::InvalidArgument(\n                        \"Row sequence tensor values must not be negative, got \",\n                        row_seq_tensor_flat));\n\n        for (int64_t c = 0; c < out_cols; ++c) {\n          const int64_t in_col_start = col_seq_tensor_flat(c);\n          int64_t in_col_end = overlapping_ ? col_seq_tensor_flat(c + 1)\n                                            : col_seq_tensor_flat(c + 1) - 1;\n          in_col_end = std::min(in_col_end, in_max_col_index);\n\n          OP_REQUIRES(\n              context, in_col_start >= 0 && in_col_end >= 0,\n              errors::InvalidArgument(\n                  \"Column sequence tensor values must not be negative, got \",\n                  col_seq_tensor_flat));\n          const int64_t num_elements_in_pooling_cell =\n              (in_row_end - in_row_start + 1) * (in_col_end - in_col_start + 1);\n          const int64_t out_index = (b * out_rows + r) * out_cols + c;\n          // Now we can evenly distribute out_backprop(b, h, w, *) to\n          // in_backprop(b, hs:he, ws:we, *).\n          for (int64_t in_r = in_row_start; in_r <= in_row_end; ++in_r) {\n            for (int64_t in_c = in_col_start; in_c <= in_col_end; ++in_c) {\n              const int64_t in_index = (b * in_rows + in_r) * in_cols + in_c;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < out_depth; ++d) {\n                const double out_backprop_element = static_cast<double>(\n                    out_backprop_mat.coeffRef(d, out_index));\n                double& in_backprop_ref =\n                    in_backprop_tensor_temp_mat.coeffRef(d, in_index);\n                in_backprop_ref +=\n                    out_backprop_element / num_elements_in_pooling_cell;\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Depending on the type, cast double to type T.\n    Tensor* in_backprop_tensor = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, in_shape, &in_backprop_tensor));\n    auto in_backprop_tensor_flat = in_backprop_tensor->flat<T>();\n    auto in_backprop_tensor_temp_flat = in_backprop_tensor_temp.flat<double>();\n    for (int64_t i = 0; i < in_backprop_tensor_flat.size(); ++i) {\n      in_backprop_tensor_flat(i) =\n          static_cast<T>(in_backprop_tensor_temp_flat(i));\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,7 +26,32 @@\n                     orig_input_tensor_shape.NumElements() == 4,\n                 errors::InvalidArgument(\"original input tensor shape must be\"\n                                         \"1-dimensional and 4 elements\"));\n+    int64_t num_elements = 1;\n+    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {\n+      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"orig_input_tensor_shape must be positive, got: \",\n+                      orig_input_tensor_shape.dim_size(i)));\n+      num_elements = MultiplyWithoutOverflow(\n+          num_elements, orig_input_tensor_shape.dim_size(i));\n+      OP_REQUIRES(\n+          context, num_elements > 0,\n+          errors::InvalidArgument(\n+              \"The total elements specified by orig_input_tensor_shape\",\n+              \" is too large. Encountered overflow after multiplying \",\n+              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));\n+    }\n+\n     const Tensor& out_backprop = context->input(1);\n+    OP_REQUIRES(context, out_backprop.dims() == 4,\n+                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));\n+    for (int i = 0; i < out_backprop.dims(); i++) {\n+      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,\n+                  errors::InvalidArgument(\n+                      \"out_backprop must be positive for all dimension, got:\",\n+                      out_backprop.dim_size(i)));\n+    }\n+\n     const Tensor& row_seq_tensor = context->input(2);\n     const Tensor& col_seq_tensor = context->input(3);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    int64_t num_elements = 1;",
                "    for (int i = 0; i < orig_input_tensor_shape.dims(); i++) {",
                "      OP_REQUIRES(context, orig_input_tensor_shape.dim_size(i) > 0,",
                "                  errors::InvalidArgument(",
                "                      \"orig_input_tensor_shape must be positive, got: \",",
                "                      orig_input_tensor_shape.dim_size(i)));",
                "      num_elements = MultiplyWithoutOverflow(",
                "          num_elements, orig_input_tensor_shape.dim_size(i));",
                "      OP_REQUIRES(",
                "          context, num_elements > 0,",
                "          errors::InvalidArgument(",
                "              \"The total elements specified by orig_input_tensor_shape\",",
                "              \" is too large. Encountered overflow after multiplying \",",
                "              orig_input_tensor_shape.dim_size(i), \", result: \", num_elements));",
                "    }",
                "",
                "    OP_REQUIRES(context, out_backprop.dims() == 4,",
                "                errors::InvalidArgument(\"out_backprop must be 4-dimensional\"));",
                "    for (int i = 0; i < out_backprop.dims(); i++) {",
                "      OP_REQUIRES(context, out_backprop.dim_size(i) > 0,",
                "                  errors::InvalidArgument(",
                "                      \"out_backprop must be positive for all dimension, got:\",",
                "                      out_backprop.dim_size(i)));",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35969",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. The implementation of `Conv2DBackpropInput` requires `input_sizes` to be 4-dimensional. Otherwise, it gives a `CHECK` failure which can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 50156d547b9a1da0144d7babe665cf690305b33c. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/50156d547b9a1da0144d7babe665cf690305b33c",
        "commit_title": "Add security vulnerability test for raw_ops.Conv2DBackpropInput",
        "commit_text": " PiperOrigin-RevId: 463395218",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input_sizes = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n\n    TensorShape input_shape;\n    OP_REQUIRES_OK(context,\n                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n                                                   out_backprop.shape(),\n                                                   data_format_, &input_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(context,\n                   ConvBackpropComputeDimensionsV2(\n                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,\n                       input_shape, filter.shape(), out_backprop.shape(),\n                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,\n                       explicit_paddings_, data_format_, &dims));\n\n    OP_REQUIRES(context, dims.in_depth == filter.shape().dim_size(2),\n                errors::InvalidArgument(\n                    \"Gradients for grouped convolutions are not \"\n                    \"supported on CPU. Please file a feature request if you \"\n                    \"run into this issue. Computed input depth \",\n                    dims.in_depth, \" doesn't match filter input depth \",\n                    filter.shape().dim_size(2)));\n    OP_REQUIRES(\n        context, dims.out_depth == filter.shape().dim_size(3),\n        errors::InvalidArgument(\"Computed output depth \", dims.out_depth,\n                                \" doesn't match filter output depth \",\n                                filter.shape().dim_size(3)));\n\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_shape, &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input_shape.num_elements() == 0) {\n      return;\n    }\n\n    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n    if (out_backprop.NumElements() == 0) {\n      functor::SetZeroFunctor<Device, T> set_zero;\n      set_zero(context->eigen_device<Device>(),\n               in_backprop->template flat<T>());\n      return;\n    }\n\n// TODO(ezhulenev): Remove custom kernel and move XSMM support to\n// LaunchConv2DBackpropInputOp functor.\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardInputConvolution<Device, T>()(\n              context, context->eigen_device<Device>(),\n              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),\n              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#else\n    int64_t pad_top, pad_bottom;\n    int64_t pad_left, pad_right;\n#endif\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // TODO(andydavis) Get L2/L3 cache sizes from device.\n    const size_t l2_cache_size = 256LL << 10;\n    const size_t l3_cache_size = 30LL << 20;\n\n    // Use L3 cache size as target working set size.\n    const size_t target_working_set_size = l3_cache_size / sizeof(T);\n\n    // Calculate size of matrices involved in MatMul: C = A x B.\n    const size_t size_A = output_image_size * dims.out_depth;\n\n    const size_t size_B = filter_total_size * dims.out_depth;\n\n    const size_t size_C = output_image_size * filter_total_size;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Calculate per-thread work unit size.\n    const size_t thread_work_unit_size =\n        work_unit_size / worker_threads.num_threads;\n\n    // Set minimum per-thread work unit size to size of L2 cache.\n    const size_t min_thread_work_unit_size = l2_cache_size / sizeof(T);\n\n    // Use parallel tensor contractions if there is no batching, or if the\n    // minimum per-thread work unit size threshold has been exceeded.\n    // Otherwise, revert to multiple single-threaded matmul ops running in\n    // parallel to keep all threads busy.\n    // TODO(andydavis) Explore alternatives to branching the code in this way\n    // (i.e. run multiple, parallel tensor contractions in another thread pool).\n    const bool use_parallel_contraction =\n        dims.batch_size == 1 ||\n        thread_work_unit_size >= min_thread_work_unit_size;\n\n    OP_REQUIRES(\n        context, work_unit_size > 0,\n        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n                                \"must all have at least 1 element\"));\n\n    const size_t shard_size =\n        use_parallel_contraction\n            ? 1\n            : (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64_t>(shard_size),\n                                    static_cast<int64_t>(output_image_size),\n                                    static_cast<int64_t>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* filter_data = filter.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n\n    auto in_backprop_flat = in_backprop->template flat<T>();\n    T* input_backprop_data = in_backprop_flat.data();\n    in_backprop_flat.device(context->eigen_device<Device>()) =\n        in_backprop_flat.constant(T(0));\n\n    if (use_parallel_contraction) {\n      typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          TensorMap;\n      typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          ConstTensorMap;\n\n      // Initialize contraction dims (we need to transpose 'B' below).\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n      contract_dims[0].first = 1;\n      contract_dims[0].second = 1;\n\n      for (int image_id = 0; image_id < dims.batch_size; ++image_id) {\n        // Compute gradient into col_buffer.\n        TensorMap C(col_buffer_data, output_image_size, filter_total_size);\n\n        ConstTensorMap A(out_backprop_data + output_offset * image_id,\n                         output_image_size, dims.out_depth);\n        ConstTensorMap B(filter_data, filter_total_size, dims.out_depth);\n\n        C.device(context->eigen_cpu_device()) = A.contract(B, contract_dims);\n\n        Col2im<T>(\n            col_buffer_data, dims.in_depth, dims.spatial_dims[0].input_size,\n            dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n            pad_right, dims.spatial_dims[0].stride, dims.spatial_dims[1].stride,\n            input_backprop_data);\n\n        input_backprop_data += input_offset;\n      }\n    } else {\n      for (int image_id = 0; image_id < dims.batch_size;\n           image_id += shard_size) {\n        const int shard_limit =\n            std::min(static_cast<int>(shard_size),\n                     static_cast<int>(dims.batch_size) - image_id);\n\n        auto shard = [&context, &dims, &pad_top, &pad_left, &pad_bottom,\n                      &pad_right, &output_image_size, &filter_total_size,\n                      &input_backprop_data, &col_buffer_data,\n                      &out_backprop_data, &filter_data, &input_offset,\n                      &output_offset, &size_C](int64_t start, int64_t limit) {\n          for (int shard_id = start; shard_id < limit; ++shard_id) {\n            T* im2col_buf = col_buffer_data + shard_id * size_C;\n            T* input_data = input_backprop_data + shard_id * input_offset;\n            const T* out_data = out_backprop_data + shard_id * output_offset;\n\n            Conv2DCustomBackpropInputMatMulFunctor<T>()(\n                context, out_data, filter_data, filter_total_size,\n                output_image_size, dims.out_depth, im2col_buf);\n\n            Col2im<T>(im2col_buf, dims.in_depth,\n                      dims.spatial_dims[0].input_size,\n                      dims.spatial_dims[1].input_size,\n                      dims.spatial_dims[0].filter_size,\n                      dims.spatial_dims[1].filter_size, pad_top, pad_left,\n                      pad_bottom, pad_right, dims.spatial_dims[0].stride,\n                      dims.spatial_dims[1].stride, input_data);\n          }\n        };\n        Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n              work_unit_size, shard);\n\n        input_backprop_data += input_offset * shard_limit;\n        out_backprop_data += output_offset * shard_limit;\n      }\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input_sizes = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    OP_REQUIRES(\n        context, out_backprop.dims() == 4,\n        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n                                out_backprop.dims()));\n\n    TensorShape input_shape;\n    OP_REQUIRES_OK(context,\n                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n                                                   out_backprop.shape(),\n                                                   data_format_, &input_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(context,\n                   ConvBackpropComputeDimensionsV2(\n                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,\n                       input_shape, filter.shape(), out_backprop.shape(),\n                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,\n                       explicit_paddings_, data_format_, &dims));\n\n    OP_REQUIRES(context, dims.in_depth == filter.shape().dim_size(2),\n                errors::InvalidArgument(\n                    \"Gradients for grouped convolutions are not \"\n                    \"supported on CPU. Please file a feature request if you \"\n                    \"run into this issue. Computed input depth \",\n                    dims.in_depth, \" doesn't match filter input depth \",\n                    filter.shape().dim_size(2)));\n    OP_REQUIRES(\n        context, dims.out_depth == filter.shape().dim_size(3),\n        errors::InvalidArgument(\"Computed output depth \", dims.out_depth,\n                                \" doesn't match filter output depth \",\n                                filter.shape().dim_size(3)));\n\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_shape, &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input_shape.num_elements() == 0) {\n      return;\n    }\n\n    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n    if (out_backprop.NumElements() == 0) {\n      functor::SetZeroFunctor<Device, T> set_zero;\n      set_zero(context->eigen_device<Device>(),\n               in_backprop->template flat<T>());\n      return;\n    }\n\n// TODO(ezhulenev): Remove custom kernel and move XSMM support to\n// LaunchConv2DBackpropInputOp functor.\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardInputConvolution<Device, T>()(\n              context, context->eigen_device<Device>(),\n              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),\n              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#else\n    int64_t pad_top, pad_bottom;\n    int64_t pad_left, pad_right;\n#endif\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // TODO(andydavis) Get L2/L3 cache sizes from device.\n    const size_t l2_cache_size = 256LL << 10;\n    const size_t l3_cache_size = 30LL << 20;\n\n    // Use L3 cache size as target working set size.\n    const size_t target_working_set_size = l3_cache_size / sizeof(T);\n\n    // Calculate size of matrices involved in MatMul: C = A x B.\n    const size_t size_A = output_image_size * dims.out_depth;\n\n    const size_t size_B = filter_total_size * dims.out_depth;\n\n    const size_t size_C = output_image_size * filter_total_size;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Calculate per-thread work unit size.\n    const size_t thread_work_unit_size =\n        work_unit_size / worker_threads.num_threads;\n\n    // Set minimum per-thread work unit size to size of L2 cache.\n    const size_t min_thread_work_unit_size = l2_cache_size / sizeof(T);\n\n    // Use parallel tensor contractions if there is no batching, or if the\n    // minimum per-thread work unit size threshold has been exceeded.\n    // Otherwise, revert to multiple single-threaded matmul ops running in\n    // parallel to keep all threads busy.\n    // TODO(andydavis) Explore alternatives to branching the code in this way\n    // (i.e. run multiple, parallel tensor contractions in another thread pool).\n    const bool use_parallel_contraction =\n        dims.batch_size == 1 ||\n        thread_work_unit_size >= min_thread_work_unit_size;\n\n    OP_REQUIRES(\n        context, work_unit_size > 0,\n        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n                                \"must all have at least 1 element\"));\n\n    const size_t shard_size =\n        use_parallel_contraction\n            ? 1\n            : (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64_t>(shard_size),\n                                    static_cast<int64_t>(output_image_size),\n                                    static_cast<int64_t>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* filter_data = filter.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n\n    auto in_backprop_flat = in_backprop->template flat<T>();\n    T* input_backprop_data = in_backprop_flat.data();\n    in_backprop_flat.device(context->eigen_device<Device>()) =\n        in_backprop_flat.constant(T(0));\n\n    if (use_parallel_contraction) {\n      typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          TensorMap;\n      typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          ConstTensorMap;\n\n      // Initialize contraction dims (we need to transpose 'B' below).\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n      contract_dims[0].first = 1;\n      contract_dims[0].second = 1;\n\n      for (int image_id = 0; image_id < dims.batch_size; ++image_id) {\n        // Compute gradient into col_buffer.\n        TensorMap C(col_buffer_data, output_image_size, filter_total_size);\n\n        ConstTensorMap A(out_backprop_data + output_offset * image_id,\n                         output_image_size, dims.out_depth);\n        ConstTensorMap B(filter_data, filter_total_size, dims.out_depth);\n\n        C.device(context->eigen_cpu_device()) = A.contract(B, contract_dims);\n\n        Col2im<T>(\n            col_buffer_data, dims.in_depth, dims.spatial_dims[0].input_size,\n            dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n            pad_right, dims.spatial_dims[0].stride, dims.spatial_dims[1].stride,\n            input_backprop_data);\n\n        input_backprop_data += input_offset;\n      }\n    } else {\n      for (int image_id = 0; image_id < dims.batch_size;\n           image_id += shard_size) {\n        const int shard_limit =\n            std::min(static_cast<int>(shard_size),\n                     static_cast<int>(dims.batch_size) - image_id);\n\n        auto shard = [&context, &dims, &pad_top, &pad_left, &pad_bottom,\n                      &pad_right, &output_image_size, &filter_total_size,\n                      &input_backprop_data, &col_buffer_data,\n                      &out_backprop_data, &filter_data, &input_offset,\n                      &output_offset, &size_C](int64_t start, int64_t limit) {\n          for (int shard_id = start; shard_id < limit; ++shard_id) {\n            T* im2col_buf = col_buffer_data + shard_id * size_C;\n            T* input_data = input_backprop_data + shard_id * input_offset;\n            const T* out_data = out_backprop_data + shard_id * output_offset;\n\n            Conv2DCustomBackpropInputMatMulFunctor<T>()(\n                context, out_data, filter_data, filter_total_size,\n                output_image_size, dims.out_depth, im2col_buf);\n\n            Col2im<T>(im2col_buf, dims.in_depth,\n                      dims.spatial_dims[0].input_size,\n                      dims.spatial_dims[1].input_size,\n                      dims.spatial_dims[0].filter_size,\n                      dims.spatial_dims[1].filter_size, pad_top, pad_left,\n                      pad_bottom, pad_right, dims.spatial_dims[0].stride,\n                      dims.spatial_dims[1].stride, input_data);\n          }\n        };\n        Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n              work_unit_size, shard);\n\n        input_backprop_data += input_offset * shard_limit;\n        out_backprop_data += output_offset * shard_limit;\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,10 @@\n     const Tensor& input_sizes = context->input(0);\n     const Tensor& filter = context->input(1);\n     const Tensor& out_backprop = context->input(2);\n+    OP_REQUIRES(\n+        context, out_backprop.dims() == 4,\n+        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",\n+                                out_backprop.dims()));\n \n     TensorShape input_shape;\n     OP_REQUIRES_OK(context,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, out_backprop.dims() == 4,",
                "        errors::InvalidArgument(\"input_sizes must be 4-dimensional, got: \",",
                "                                out_backprop.dims()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35970",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. If `QuantizedInstanceNorm` is given `x_min` or `x_max` tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 785d67a78a1d533759fcd2f5e8d6ef778de849e0. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/785d67a78a1d533759fcd2f5e8d6ef778de849e0",
        "commit_title": "Fix quantize ops input validation issues.",
        "commit_text": " The majority of these are just missing checks on min/max.  PiperOrigin-RevId: 461800665",
        "func_before": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const float input_min_float = ctx->input(1).flat<float>()(0);\n    const float input_max_float = ctx->input(2).flat<float>()(0);\n    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));\n\n    OP_REQUIRES(\n        ctx, requested_output_min_float <= 0.0f,\n        errors::InvalidArgument(\"requested_output_min must be <= 0, but got \",\n                                requested_output_min_float));\n    OP_REQUIRES(\n        ctx, requested_output_max_float >= requested_output_min_float,\n        errors::InvalidArgument(\n            \"requested_output_max must be >= requested_output_min, but got \",\n            requested_output_max_float, \" and \", requested_output_min_float));\n\n    auto input_array = input.flat<T1>();\n\n#if 0\n    // This is the reference, non-eigen implementation:\n    auto output_array = output->flat<T2>();\n    RequantizeManyInNewRange<T1, T2>(\n        input_array.data(), input_array.size(),\n        input_min_float, input_max_float,\n        requested_output_min_float, requested_output_max_float,\n        output_array.data());\n#endif\n\n    if (input_array.size() > 0) {\n      if (meta::IsSupportedAndEnabled() && std::is_same<T1, qint32>() &&\n          std::is_same<T2, quint8>()) {\n        auto input_i32_array = input.flat<qint32>();\n        meta::Requantize(ctx, input_i32_array.data(), input_i32_array.size(),\n                         input_min_float, input_max_float,\n                         requested_output_min_float, requested_output_max_float,\n                         output->flat<quint8>().data());\n      } else {\n        RequantizeManyInNewRangeUsingEigen<T1, T2>(\n            ctx->eigen_device<CPUDevice>(), input, input_min_float,\n            input_max_float, requested_output_min_float,\n            requested_output_max_float, output);\n      }\n    }\n\n    output_min->flat<float>().setConstant(requested_output_min_float);\n    output_max->flat<float>().setConstant(requested_output_max_float);\n  }",
        "func": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n\n    const Tensor& input_min = ctx->input(1);\n    const Tensor& input_max = ctx->input(2);\n    const Tensor& requested_output_min = ctx->input(3);\n    const Tensor& requested_output_max = ctx->input(4);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n                                input_min.dims()));\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n                                input_max.dims()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n                errors::InvalidArgument(\n                    \"`requested_output_min` must be rank 0 but is rank \",\n                    requested_output_min.dims()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n                errors::InvalidArgument(\n                    \"`requested_output_max` must be rank 0 but is rank \",\n                    requested_output_max.dims()));\n\n    const float input_min_float = input_min.flat<float>()(0);\n    const float input_max_float = input_max.flat<float>()(0);\n    const float requested_output_min_float =\n        requested_output_min.flat<float>()(0);\n    const float requested_output_max_float =\n        requested_output_max.flat<float>()(0);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(1, TensorShape({}), &output_min));\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(2, TensorShape({}), &output_max));\n\n    OP_REQUIRES(\n        ctx, requested_output_min_float <= 0.0f,\n        errors::InvalidArgument(\"requested_output_min must be <= 0, but got \",\n                                requested_output_min_float));\n    OP_REQUIRES(\n        ctx, requested_output_max_float >= requested_output_min_float,\n        errors::InvalidArgument(\n            \"requested_output_max must be >= requested_output_min, but got \",\n            requested_output_max_float, \" and \", requested_output_min_float));\n\n    auto input_array = input.flat<T1>();\n\n#if 0\n    // This is the reference, non-eigen implementation:\n    auto output_array = output->flat<T2>();\n    RequantizeManyInNewRange<T1, T2>(\n        input_array.data(), input_array.size(),\n        input_min_float, input_max_float,\n        requested_output_min_float, requested_output_max_float,\n        output_array.data());\n#endif\n\n    if (input_array.size() > 0) {\n      if (meta::IsSupportedAndEnabled() && std::is_same<T1, qint32>() &&\n          std::is_same<T2, quint8>()) {\n        auto input_i32_array = input.flat<qint32>();\n        meta::Requantize(ctx, input_i32_array.data(), input_i32_array.size(),\n                         input_min_float, input_max_float,\n                         requested_output_min_float, requested_output_max_float,\n                         output->flat<quint8>().data());\n      } else {\n        RequantizeManyInNewRangeUsingEigen<T1, T2>(\n            ctx->eigen_device<CPUDevice>(), input, input_min_float,\n            input_max_float, requested_output_min_float,\n            requested_output_max_float, output);\n      }\n    }\n\n    output_min->flat<float>().setConstant(requested_output_min_float);\n    output_max->flat<float>().setConstant(requested_output_max_float);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,33 @@\n void Compute(OpKernelContext* ctx) override {\n     const Tensor& input = ctx->input(0);\n-    const float input_min_float = ctx->input(1).flat<float>()(0);\n-    const float input_max_float = ctx->input(2).flat<float>()(0);\n-    const float requested_output_min_float = ctx->input(3).flat<float>()(0);\n-    const float requested_output_max_float = ctx->input(4).flat<float>()(0);\n+\n+    const Tensor& input_min = ctx->input(1);\n+    const Tensor& input_max = ctx->input(2);\n+    const Tensor& requested_output_min = ctx->input(3);\n+    const Tensor& requested_output_max = ctx->input(4);\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_min.shape()),\n+        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",\n+                                input_min.dims()));\n+    OP_REQUIRES(\n+        ctx, TensorShapeUtils::IsScalar(input_max.shape()),\n+        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",\n+                                input_max.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_min` must be rank 0 but is rank \",\n+                    requested_output_min.dims()));\n+    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),\n+                errors::InvalidArgument(\n+                    \"`requested_output_max` must be rank 0 but is rank \",\n+                    requested_output_max.dims()));\n+\n+    const float input_min_float = input_min.flat<float>()(0);\n+    const float input_max_float = input_max.flat<float>()(0);\n+    const float requested_output_min_float =\n+        requested_output_min.flat<float>()(0);\n+    const float requested_output_max_float =\n+        requested_output_max.flat<float>()(0);\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
        "diff_line_info": {
            "deleted_lines": [
                "    const float input_min_float = ctx->input(1).flat<float>()(0);",
                "    const float input_max_float = ctx->input(2).flat<float>()(0);",
                "    const float requested_output_min_float = ctx->input(3).flat<float>()(0);",
                "    const float requested_output_max_float = ctx->input(4).flat<float>()(0);"
            ],
            "added_lines": [
                "",
                "    const Tensor& input_min = ctx->input(1);",
                "    const Tensor& input_max = ctx->input(2);",
                "    const Tensor& requested_output_min = ctx->input(3);",
                "    const Tensor& requested_output_max = ctx->input(4);",
                "    OP_REQUIRES(",
                "        ctx, TensorShapeUtils::IsScalar(input_min.shape()),",
                "        errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",",
                "                                input_min.dims()));",
                "    OP_REQUIRES(",
                "        ctx, TensorShapeUtils::IsScalar(input_max.shape()),",
                "        errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",",
                "                                input_max.dims()));",
                "    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),",
                "                errors::InvalidArgument(",
                "                    \"`requested_output_min` must be rank 0 but is rank \",",
                "                    requested_output_min.dims()));",
                "    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),",
                "                errors::InvalidArgument(",
                "                    \"`requested_output_max` must be rank 0 but is rank \",",
                "                    requested_output_max.dims()));",
                "",
                "    const float input_min_float = input_min.flat<float>()(0);",
                "    const float input_max_float = input_max.flat<float>()(0);",
                "    const float requested_output_min_float =",
                "        requested_output_min.flat<float>()(0);",
                "    const float requested_output_max_float =",
                "        requested_output_max.flat<float>()(0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35970",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. If `QuantizedInstanceNorm` is given `x_min` or `x_max` tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 785d67a78a1d533759fcd2f5e8d6ef778de849e0. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/785d67a78a1d533759fcd2f5e8d6ef778de849e0",
        "commit_title": "Fix quantize ops input validation issues.",
        "commit_text": " The majority of these are just missing checks on min/max.  PiperOrigin-RevId: 461800665",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n\n    float input_min = context->input(1).flat<float>()(0);\n    float input_max = context->input(2).flat<float>()(0);\n    float input_scale = (input_max - input_min) / 255.0f;\n\n    OP_REQUIRES(context, input_min < input_max,\n                errors::InvalidArgument(\n                    \"input_min must be less than input_max : \", input_min,\n                    \" >= \", input_max));\n\n    auto input_tensor = input.tensor<quint8, 4>();\n    auto N = input_tensor.dimension(0);\n    auto H = input_tensor.dimension(1);\n    auto W = input_tensor.dimension(2);\n    auto C = input_tensor.dimension(3);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));\n\n    typedef TTypes<float>::Tensor::Index Index;\n\n    const Eigen::IndexList<Eigen::type2index<1>, Eigen::type2index<2>>\n        reduction_indices;\n    Eigen::IndexList<Eigen::type2index<1>, Index, Index, Eigen::type2index<1>>\n        broadcast_spec;\n    broadcast_spec.set(1, H);\n    broadcast_spec.set(2, W);\n    Eigen::IndexList<Index, Eigen::type2index<1>, Eigen::type2index<1>, Index>\n        expand_spec;\n    expand_spec.set(0, N);\n    expand_spec.set(3, C);\n\n    Eigen::Tensor<float, 2, Eigen::RowMajor> float_mean(N, C);\n    Eigen::Tensor<float, 2, Eigen::RowMajor> float_variance(N, C);\n\n#ifdef USE_NEON\n    if (N == 1 && (C % 16 == 0)) {\n      VLOG(2) << \"Calling optimized\";\n      ColMeanAndVariance(reinterpret_cast<const uint8_t*>(input_tensor.data()),\n                         H * W, C, float_mean.data(), float_variance.data());\n\n      float minimum = given_y_min_, maximum = given_y_max_;\n      if (!output_range_given_) {\n        MinAndMax(reinterpret_cast<const uint8_t*>(input_tensor.data()), H * W,\n                  C, float_mean.data(), float_variance.data(),\n                  variance_epsilon_, &minimum, &maximum);\n      }\n\n      if (maximum - minimum < min_separation_) {\n        maximum = minimum + min_separation_;\n      }\n\n      InstanceNorm(reinterpret_cast<const uint8_t*>(input_tensor.data()), H * W,\n                   C, float_mean.data(), float_variance.data(),\n                   variance_epsilon_, minimum, maximum,\n                   reinterpret_cast<uint8_t*>(output->flat<quint8>().data()));\n      output_min->scalar<float>()() = minimum;\n      output_max->scalar<float>()() = maximum;\n    } else  // NOLINT(readability/braces)\n#endif\n    {\n      VLOG(2) << \"Calling unoptimized\";\n      float_mean = input_tensor.cast<float>().reduce(\n          reduction_indices, Eigen::internal::MeanReducer<float>());\n\n      float_variance =\n          (input_scale *\n           ((input_tensor.cast<float>() -\n             float_mean.reshape(expand_spec).broadcast(broadcast_spec))))\n              .square()\n              .reduce(reduction_indices, Eigen::internal::MeanReducer<float>());\n\n      Eigen::Tensor<float, 4, Eigen::RowMajor> instance_normed =\n          input_scale *\n          (input_tensor.cast<float>() -\n           float_mean.reshape(expand_spec).broadcast(broadcast_spec)) *\n          (float_variance + variance_epsilon_)\n              .rsqrt()\n              .reshape(expand_spec)\n              .broadcast(broadcast_spec);\n\n      Eigen::Tensor<float, 0, Eigen::RowMajor> normed_min;\n      Eigen::Tensor<float, 0, Eigen::RowMajor> normed_max;\n\n      if (!output_range_given_) {\n        normed_min = instance_normed.minimum();\n        normed_max = instance_normed.maximum();\n      } else {\n        normed_min() = given_y_min_;\n        normed_max() = given_y_max_;\n      }\n\n      if (normed_max() - normed_min() < min_separation_) {\n        normed_max() = normed_min() + min_separation_;\n      }\n\n      FloatToQuantizedStruct<quint8> output_f2q(normed_min(), normed_max());\n      auto instance_normed_quantized =\n          QUANTIZE_WITH_EIGEN(instance_normed, output_f2q, quint8);\n\n      output->tensor<quint8, 4>().device(\n          context->template eigen_device<CPUDevice>()) =\n          instance_normed_quantized;\n      output_min->flat<float>()(0) = normed_min();\n      output_max->flat<float>()(0) = normed_max();\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n\n    const Tensor& x_min = context->input(1);\n    const Tensor& x_max = context->input(2);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),\n                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",\n                                        x_min.dims()));\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),\n                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",\n                                        x_max.dims()));\n    float input_min = x_min.scalar<float>()();\n    float input_max = x_max.scalar<float>()();\n    float input_scale = (input_max - input_min) / 255.0f;\n\n    OP_REQUIRES(context, input_min < input_max,\n                errors::InvalidArgument(\n                    \"input_min must be less than input_max : \", input_min,\n                    \" >= \", input_max));\n\n    auto input_tensor = input.tensor<quint8, 4>();\n    auto N = input_tensor.dimension(0);\n    auto H = input_tensor.dimension(1);\n    auto W = input_tensor.dimension(2);\n    auto C = input_tensor.dimension(3);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));\n\n    typedef TTypes<float>::Tensor::Index Index;\n\n    const Eigen::IndexList<Eigen::type2index<1>, Eigen::type2index<2>>\n        reduction_indices;\n    Eigen::IndexList<Eigen::type2index<1>, Index, Index, Eigen::type2index<1>>\n        broadcast_spec;\n    broadcast_spec.set(1, H);\n    broadcast_spec.set(2, W);\n    Eigen::IndexList<Index, Eigen::type2index<1>, Eigen::type2index<1>, Index>\n        expand_spec;\n    expand_spec.set(0, N);\n    expand_spec.set(3, C);\n\n    Eigen::Tensor<float, 2, Eigen::RowMajor> float_mean(N, C);\n    Eigen::Tensor<float, 2, Eigen::RowMajor> float_variance(N, C);\n\n#ifdef USE_NEON\n    if (N == 1 && (C % 16 == 0)) {\n      VLOG(2) << \"Calling optimized\";\n      ColMeanAndVariance(reinterpret_cast<const uint8_t*>(input_tensor.data()),\n                         H * W, C, float_mean.data(), float_variance.data());\n\n      float minimum = given_y_min_, maximum = given_y_max_;\n      if (!output_range_given_) {\n        MinAndMax(reinterpret_cast<const uint8_t*>(input_tensor.data()), H * W,\n                  C, float_mean.data(), float_variance.data(),\n                  variance_epsilon_, &minimum, &maximum);\n      }\n\n      if (maximum - minimum < min_separation_) {\n        maximum = minimum + min_separation_;\n      }\n\n      InstanceNorm(reinterpret_cast<const uint8_t*>(input_tensor.data()), H * W,\n                   C, float_mean.data(), float_variance.data(),\n                   variance_epsilon_, minimum, maximum,\n                   reinterpret_cast<uint8_t*>(output->flat<quint8>().data()));\n      output_min->scalar<float>()() = minimum;\n      output_max->scalar<float>()() = maximum;\n    } else  // NOLINT(readability/braces)\n#endif\n    {\n      VLOG(2) << \"Calling unoptimized\";\n      float_mean = input_tensor.cast<float>().reduce(\n          reduction_indices, Eigen::internal::MeanReducer<float>());\n\n      float_variance =\n          (input_scale *\n           ((input_tensor.cast<float>() -\n             float_mean.reshape(expand_spec).broadcast(broadcast_spec))))\n              .square()\n              .reduce(reduction_indices, Eigen::internal::MeanReducer<float>());\n\n      Eigen::Tensor<float, 4, Eigen::RowMajor> instance_normed =\n          input_scale *\n          (input_tensor.cast<float>() -\n           float_mean.reshape(expand_spec).broadcast(broadcast_spec)) *\n          (float_variance + variance_epsilon_)\n              .rsqrt()\n              .reshape(expand_spec)\n              .broadcast(broadcast_spec);\n\n      Eigen::Tensor<float, 0, Eigen::RowMajor> normed_min;\n      Eigen::Tensor<float, 0, Eigen::RowMajor> normed_max;\n\n      if (!output_range_given_) {\n        normed_min = instance_normed.minimum();\n        normed_max = instance_normed.maximum();\n      } else {\n        normed_min() = given_y_min_;\n        normed_max() = given_y_max_;\n      }\n\n      if (normed_max() - normed_min() < min_separation_) {\n        normed_max() = normed_min() + min_separation_;\n      }\n\n      FloatToQuantizedStruct<quint8> output_f2q(normed_min(), normed_max());\n      auto instance_normed_quantized =\n          QUANTIZE_WITH_EIGEN(instance_normed, output_f2q, quint8);\n\n      output->tensor<quint8, 4>().device(\n          context->template eigen_device<CPUDevice>()) =\n          instance_normed_quantized;\n      output_min->flat<float>()(0) = normed_min();\n      output_max->flat<float>()(0) = normed_max();\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,16 @@\n void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n \n-    float input_min = context->input(1).flat<float>()(0);\n-    float input_max = context->input(2).flat<float>()(0);\n+    const Tensor& x_min = context->input(1);\n+    const Tensor& x_max = context->input(2);\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),\n+                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",\n+                                        x_min.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),\n+                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",\n+                                        x_max.dims()));\n+    float input_min = x_min.scalar<float>()();\n+    float input_max = x_max.scalar<float>()();\n     float input_scale = (input_max - input_min) / 255.0f;\n \n     OP_REQUIRES(context, input_min < input_max,",
        "diff_line_info": {
            "deleted_lines": [
                "    float input_min = context->input(1).flat<float>()(0);",
                "    float input_max = context->input(2).flat<float>()(0);"
            ],
            "added_lines": [
                "    const Tensor& x_min = context->input(1);",
                "    const Tensor& x_max = context->input(2);",
                "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),",
                "                errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",",
                "                                        x_min.dims()));",
                "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),",
                "                errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",",
                "                                        x_max.dims()));",
                "    float input_min = x_min.scalar<float>()();",
                "    float input_max = x_max.scalar<float>()();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35970",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. If `QuantizedInstanceNorm` is given `x_min` or `x_max` tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 785d67a78a1d533759fcd2f5e8d6ef778de849e0. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/785d67a78a1d533759fcd2f5e8d6ef778de849e0",
        "commit_title": "Fix quantize ops input validation issues.",
        "commit_text": " The majority of these are just missing checks on min/max.  PiperOrigin-RevId: 461800665",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& bias = context->input(1);\n    const float input_min = context->input(2).flat<float>()(0);\n    const float input_max = context->input(3).flat<float>()(0);\n    const float bias_min = context->input(4).flat<float>()(0);\n    const float bias_max = context->input(5).flat<float>()(0);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n                                        input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(bias.shape()),\n                errors::InvalidArgument(\"Biases must be 1D: \",\n                                        bias.shape().DebugString()));\n    const auto last_dim = input.shape().dims() - 1;\n    OP_REQUIRES(\n        context, bias.shape().dim_size(0) == input.shape().dim_size(last_dim),\n        errors::InvalidArgument(\n            \"Must provide as many biases as the last dimension \"\n            \"of the input tensor: \",\n            bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n    OP_REQUIRES(context, bias.NumElements() > 0,\n                errors::InvalidArgument(\"Must provide at least 1 bias\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n\n    float total_min;\n    float total_max;\n\n    if (meta::IsSupportedAndEnabled() && std::is_same<T1, quint8>() &&\n        std::is_same<T2, quint8>() && std::is_same<T3, qint32>()) {\n      auto input_ui8_array = input.flat<quint8>();\n      auto bias_ui8_array = bias.flat<quint8>();\n      GetOutputMinAndMaxForQuantizedAdd(input_min, input_max, bias_min,\n                                        bias_max, &total_min, &total_max);\n      meta::QuantizedBiasAdd(context, input_ui8_array.data(),\n                             input_ui8_array.size(), bias_ui8_array.data(),\n                             bias_ui8_array.size(), input_min, input_max,\n                             bias_min, bias_max, total_min, total_max,\n                             output->flat<qint32>().data());\n    } else {\n      QuantizedAddUsingEigen<T1, T2, T3>(\n          context->template eigen_device<CPUDevice>(), input, input_min,\n          input_max, bias, bias_min, bias_max, output, &total_min, &total_max);\n    }\n\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n    output_min->flat<float>()(0) = total_min;\n\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));\n    output_max->flat<float>()(0) = total_max;\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& bias = context->input(1);\n\n    const Tensor& min_input = context->input(2);\n    const Tensor& max_input = context->input(3);\n    const Tensor& min_bias = context->input(4);\n    const Tensor& max_bias = context->input(5);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(min_input.shape()),\n        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n                                min_input.dims()));\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsScalar(max_input.shape()),\n        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n                                max_input.dims()));\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),\n                errors::InvalidArgument(\n                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),\n                errors::InvalidArgument(\n                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));\n\n    const float input_min = min_input.flat<float>()(0);\n    const float input_max = max_input.flat<float>()(0);\n    const float bias_min = min_bias.flat<float>()(0);\n    const float bias_max = max_bias.flat<float>()(0);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n                                        input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(bias.shape()),\n                errors::InvalidArgument(\"Biases must be 1D: \",\n                                        bias.shape().DebugString()));\n    const auto last_dim = input.shape().dims() - 1;\n    OP_REQUIRES(\n        context, bias.shape().dim_size(0) == input.shape().dim_size(last_dim),\n        errors::InvalidArgument(\n            \"Must provide as many biases as the last dimension \"\n            \"of the input tensor: \",\n            bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n    OP_REQUIRES(context, bias.NumElements() > 0,\n                errors::InvalidArgument(\"Must provide at least 1 bias\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n\n    float total_min;\n    float total_max;\n\n    if (meta::IsSupportedAndEnabled() && std::is_same<T1, quint8>() &&\n        std::is_same<T2, quint8>() && std::is_same<T3, qint32>()) {\n      auto input_ui8_array = input.flat<quint8>();\n      auto bias_ui8_array = bias.flat<quint8>();\n      GetOutputMinAndMaxForQuantizedAdd(input_min, input_max, bias_min,\n                                        bias_max, &total_min, &total_max);\n      meta::QuantizedBiasAdd(context, input_ui8_array.data(),\n                             input_ui8_array.size(), bias_ui8_array.data(),\n                             bias_ui8_array.size(), input_min, input_max,\n                             bias_min, bias_max, total_min, total_max,\n                             output->flat<qint32>().data());\n    } else {\n      QuantizedAddUsingEigen<T1, T2, T3>(\n          context->template eigen_device<CPUDevice>(), input, input_min,\n          input_max, bias, bias_min, bias_max, output, &total_min, &total_max);\n    }\n\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n    output_min->flat<float>()(0) = total_min;\n\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));\n    output_max->flat<float>()(0) = total_max;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,30 @@\n void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n     const Tensor& bias = context->input(1);\n-    const float input_min = context->input(2).flat<float>()(0);\n-    const float input_max = context->input(3).flat<float>()(0);\n-    const float bias_min = context->input(4).flat<float>()(0);\n-    const float bias_max = context->input(5).flat<float>()(0);\n+\n+    const Tensor& min_input = context->input(2);\n+    const Tensor& max_input = context->input(3);\n+    const Tensor& min_bias = context->input(4);\n+    const Tensor& max_bias = context->input(5);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(min_input.shape()),\n+        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",\n+                                min_input.dims()));\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsScalar(max_input.shape()),\n+        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",\n+                                max_input.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),\n+                errors::InvalidArgument(\n+                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));\n+\n+    const float input_min = min_input.flat<float>()(0);\n+    const float input_max = max_input.flat<float>()(0);\n+    const float bias_min = min_bias.flat<float>()(0);\n+    const float bias_max = max_bias.flat<float>()(0);\n \n     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",",
        "diff_line_info": {
            "deleted_lines": [
                "    const float input_min = context->input(2).flat<float>()(0);",
                "    const float input_max = context->input(3).flat<float>()(0);",
                "    const float bias_min = context->input(4).flat<float>()(0);",
                "    const float bias_max = context->input(5).flat<float>()(0);"
            ],
            "added_lines": [
                "",
                "    const Tensor& min_input = context->input(2);",
                "    const Tensor& max_input = context->input(3);",
                "    const Tensor& min_bias = context->input(4);",
                "    const Tensor& max_bias = context->input(5);",
                "    OP_REQUIRES(",
                "        context, TensorShapeUtils::IsScalar(min_input.shape()),",
                "        errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
                "                                min_input.dims()));",
                "    OP_REQUIRES(",
                "        context, TensorShapeUtils::IsScalar(max_input.shape()),",
                "        errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
                "                                max_input.dims()));",
                "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),",
                "                errors::InvalidArgument(",
                "                    \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));",
                "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),",
                "                errors::InvalidArgument(",
                "                    \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));",
                "",
                "    const float input_min = min_input.flat<float>()(0);",
                "    const float input_max = max_input.flat<float>()(0);",
                "    const float bias_min = min_bias.flat<float>()(0);",
                "    const float bias_max = max_bias.flat<float>()(0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35981",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. `FractionalMaxPoolGrad` validates its inputs with `CHECK` failures instead of with returning errors. If it gets incorrectly sized inputs, the `CHECK` failure can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 8741e57d163a079db05a7107a7609af70931def4. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8741e57d163a079db05a7107a7609af70931def4",
        "commit_title": "Fix security vulnerability with FractionalMaxPoolGrad",
        "commit_text": " PiperOrigin-RevId: 461722693",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // There are two steps when calculating gradient for FractionalMaxPool.\n    // 1) Walk through the process of calculating fractional pooling given\n    //    pooling region; however, in the process, keep track of where the max\n    //    element comes from. (arg_max)\n    // 2) Populate the value of out_backprop to where arg_max indicates. If\n    //    we support overlapping, it is likely to have multiple out_backprop[i]\n    //    propagates back to the same arg_max value.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<int64, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenIndexMatrixMap;\n\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    const Tensor& height_seq_tensor = context->input(3);\n    const Tensor& width_seq_tensor = context->input(4);\n\n    // Just to make it similar to FractionalMaxPoolOp.\n    constexpr int tensor_in_and_out_dims = 4;\n    OP_REQUIRES(\n        context, tensor_in.dims() == tensor_in_and_out_dims,\n        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\n                                tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n                errors::InvalidArgument(\"orig_input must not be empty, got \",\n                                        tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\n                errors::InvalidArgument(\n                    \"orig_output should be a tensor of rank 4, got \",\n                    tensor_out.DebugString()));\n    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                errors::InvalidArgument(\"orig_output must not be empty, got \",\n                                        tensor_out.DebugString()));\n    std::vector<int64_t> input_size(tensor_in_and_out_dims);\n    std::vector<int64_t> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n    }\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      output_size[i] = tensor_out.dim_size(i);\n    }\n\n    // ---------\n    // Step 1\n    // ---------\n    Tensor tensor_out_dup;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {1}, DataTypeToEnum<T>::v(), tensor_out.shape(),\n                                &tensor_out_dup));\n    Tensor tensor_out_arg_max;\n    OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<int64_t>::v(),\n                                                   tensor_out.shape(),\n                                                   &tensor_out_arg_max));\n    // Find arg_max for each tensor_out\n    ConstEigenMatrixMap tensor_in_mat(\n        tensor_in.flat<T>().data(), input_size[3],\n        input_size[2] * input_size[1] * input_size[0]);\n    EigenMatrixMap tensor_out_dup_mat(\n        tensor_out_dup.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    EigenIndexMatrixMap tensor_out_arg_max_mat(\n        tensor_out_arg_max.flat<int64_t>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n\n    tensor_out_arg_max.flat<int64_t>().setConstant(kInvalidMaxPoolingIndex);\n    // Initializes the duplicate output tensor with MIN<T>.\n    tensor_out_dup.flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto height_seq_tensor_flat = height_seq_tensor.flat<int64_t>();\n    auto width_seq_tensor_flat = width_seq_tensor.flat<int64_t>();\n\n    // Now walk through the process of fractional max pooling again.\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64_t height_max = input_size[1] - 1;\n    const int64_t width_max = input_size[2] - 1;\n    for (int64_t b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64_t hs = 0; hs < height_seq_tensor.dim_size(0) - 1; ++hs) {\n        // height start and end.\n        const int64_t height_start = height_seq_tensor_flat(hs);\n        int64_t height_end = overlapping_ ? height_seq_tensor_flat(hs + 1)\n                                          : height_seq_tensor_flat(hs + 1) - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64_t ws = 0; ws < width_seq_tensor.dim_size(0) - 1; ++ws) {\n          const int64_t out_index =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64_t width_start = width_seq_tensor_flat(ws);\n          int64_t width_end = overlapping_ ? width_seq_tensor_flat(ws + 1)\n                                           : width_seq_tensor_flat(ws + 1) - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64_t h = height_start; h <= height_end; ++h) {\n            for (int64_t w = width_start; w <= width_end; ++w) {\n              const int64_t in_index =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < input_size[3]; ++d) {\n                const T& input_ref = tensor_in_mat.coeffRef(d, in_index);\n                T& output_ref = tensor_out_dup_mat.coeffRef(d, out_index);\n                int64_t& out_arg_max_ref =\n                    tensor_out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  int input_offset = in_index * input_size[3] + d;\n                  out_arg_max_ref = input_offset;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Check tensor_out_dup is the same as tensor_out.\n    ConstEigenMatrixMap tensor_out_mat(\n        tensor_out.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    const int64_t num_reshaped_cols =\n        output_size[2] * output_size[1] * output_size[0];\n    for (int64_t i = 0; i < num_reshaped_cols; ++i) {\n      for (int64_t j = 0; j < output_size[3]; ++j) {\n        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));\n      }\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, tensor_in.shape(), &output));\n    output->flat<T>().setZero();\n\n    auto out_backprop_flat = out_backprop.flat<T>();\n    auto input_backprop_flat = output->flat<T>();\n    auto out_arg_max_flat = tensor_out_arg_max.flat<int64_t>();\n    int num_total_outputs = out_backprop_flat.size();\n    int num_total_inputs = input_backprop_flat.size();\n\n    for (int index = 0; index < num_total_outputs; ++index) {\n      int input_backprop_index = out_arg_max_flat(index);\n      // According to maxpooling_op.cc, the performance impact below is small.\n      CHECK(input_backprop_index >= 0 &&\n            input_backprop_index < num_total_inputs)\n          << \"Invalid input backprop index: \" << input_backprop_index << \", \"\n          << num_total_inputs;\n      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // There are two steps when calculating gradient for FractionalMaxPool.\n    // 1) Walk through the process of calculating fractional pooling given\n    //    pooling region; however, in the process, keep track of where the max\n    //    element comes from. (arg_max)\n    // 2) Populate the value of out_backprop to where arg_max indicates. If\n    //    we support overlapping, it is likely to have multiple out_backprop[i]\n    //    propagates back to the same arg_max value.\n    typedef Eigen::Map<const Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        ConstEigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenMatrixMap;\n    typedef Eigen::Map<Eigen::Matrix<int64, Eigen::Dynamic, Eigen::Dynamic>>\n        EigenIndexMatrixMap;\n\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& tensor_out = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    const Tensor& height_seq_tensor = context->input(3);\n    const Tensor& width_seq_tensor = context->input(4);\n\n    // Just to make it similar to FractionalMaxPoolOp.\n    constexpr int tensor_in_and_out_dims = 4;\n    OP_REQUIRES(\n        context, tensor_in.dims() == tensor_in_and_out_dims,\n        errors::InvalidArgument(\"orig_input should be a tensor of rank 4, got \",\n                                tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_in.NumElements() > 0,\n                errors::InvalidArgument(\"orig_input must not be empty, got \",\n                                        tensor_in.DebugString()));\n    OP_REQUIRES(context, tensor_out.dims() == tensor_in_and_out_dims,\n                errors::InvalidArgument(\n                    \"orig_output should be a tensor of rank 4, got \",\n                    tensor_out.DebugString()));\n    OP_REQUIRES(context, tensor_out.NumElements() > 0,\n                errors::InvalidArgument(\"orig_output must not be empty, got \",\n                                        tensor_out.DebugString()));\n    std::vector<int64_t> input_size(tensor_in_and_out_dims);\n    std::vector<int64_t> output_size(tensor_in_and_out_dims);\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      input_size[i] = tensor_in.dim_size(i);\n    }\n    for (int i = 0; i < tensor_in_and_out_dims; ++i) {\n      output_size[i] = tensor_out.dim_size(i);\n    }\n\n    // ---------\n    // Step 1\n    // ---------\n    Tensor tensor_out_dup;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_temp(\n                                {1}, DataTypeToEnum<T>::v(), tensor_out.shape(),\n                                &tensor_out_dup));\n    Tensor tensor_out_arg_max;\n    OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<int64_t>::v(),\n                                                   tensor_out.shape(),\n                                                   &tensor_out_arg_max));\n    // Find arg_max for each tensor_out\n    ConstEigenMatrixMap tensor_in_mat(\n        tensor_in.flat<T>().data(), input_size[3],\n        input_size[2] * input_size[1] * input_size[0]);\n    EigenMatrixMap tensor_out_dup_mat(\n        tensor_out_dup.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    EigenIndexMatrixMap tensor_out_arg_max_mat(\n        tensor_out_arg_max.flat<int64_t>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n\n    tensor_out_arg_max.flat<int64_t>().setConstant(kInvalidMaxPoolingIndex);\n    // Initializes the duplicate output tensor with MIN<T>.\n    tensor_out_dup.flat<T>().setConstant(Eigen::NumTraits<T>::lowest());\n\n    auto height_seq_tensor_flat = height_seq_tensor.flat<int64_t>();\n    auto width_seq_tensor_flat = width_seq_tensor.flat<int64_t>();\n\n    // Now walk through the process of fractional max pooling again.\n    // For both input and output,\n    // 0: batch\n    // 1: height / row\n    // 2: width / col\n    // 3: depth / channel\n    const int64_t height_max = input_size[1] - 1;\n    const int64_t width_max = input_size[2] - 1;\n    for (int64_t b = 0; b < input_size[0]; ++b) {\n      // height sequence.\n      for (int64_t hs = 0; hs < height_seq_tensor.dim_size(0) - 1; ++hs) {\n        // height start and end.\n        const int64_t height_start = height_seq_tensor_flat(hs);\n        int64_t height_end = overlapping_ ? height_seq_tensor_flat(hs + 1)\n                                          : height_seq_tensor_flat(hs + 1) - 1;\n        height_end = std::min(height_end, height_max);\n\n        // width sequence.\n        for (int64_t ws = 0; ws < width_seq_tensor.dim_size(0) - 1; ++ws) {\n          const int64_t out_index =\n              (b * output_size[1] + hs) * output_size[2] + ws;\n          // width start and end.\n          const int64_t width_start = width_seq_tensor_flat(ws);\n          int64_t width_end = overlapping_ ? width_seq_tensor_flat(ws + 1)\n                                           : width_seq_tensor_flat(ws + 1) - 1;\n          width_end = std::min(width_end, width_max);\n          for (int64_t h = height_start; h <= height_end; ++h) {\n            for (int64_t w = width_start; w <= width_end; ++w) {\n              const int64_t in_index =\n                  (b * input_size[1] + h) * input_size[2] + w;\n              // Walk through each channel (depth).\n              for (int64_t d = 0; d < input_size[3]; ++d) {\n                const T& input_ref = tensor_in_mat.coeffRef(d, in_index);\n                T& output_ref = tensor_out_dup_mat.coeffRef(d, out_index);\n                int64_t& out_arg_max_ref =\n                    tensor_out_arg_max_mat.coeffRef(d, out_index);\n                if (output_ref < input_ref ||\n                    out_arg_max_ref == kInvalidMaxPoolingIndex) {\n                  output_ref = input_ref;\n                  int input_offset = in_index * input_size[3] + d;\n                  out_arg_max_ref = input_offset;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    // Check tensor_out_dup is the same as tensor_out.\n    ConstEigenMatrixMap tensor_out_mat(\n        tensor_out.flat<T>().data(), output_size[3],\n        output_size[2] * output_size[1] * output_size[0]);\n    const int64_t num_reshaped_cols =\n        output_size[2] * output_size[1] * output_size[0];\n    for (int64_t i = 0; i < num_reshaped_cols; ++i) {\n      for (int64_t j = 0; j < output_size[3]; ++j) {\n        OP_REQUIRES(context, tensor_out_dup_mat(j, i) == tensor_out_mat(j, i),\n                    errors::InvalidArgument(\n                        \"tensor_out_dup is not the same as tensor_out\"));\n      }\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, tensor_in.shape(), &output));\n    output->flat<T>().setZero();\n\n    auto out_backprop_flat = out_backprop.flat<T>();\n    auto input_backprop_flat = output->flat<T>();\n    auto out_arg_max_flat = tensor_out_arg_max.flat<int64_t>();\n    int num_total_outputs = out_backprop_flat.size();\n    int num_total_inputs = input_backprop_flat.size();\n\n    for (int index = 0; index < num_total_outputs; ++index) {\n      int input_backprop_index = out_arg_max_flat(index);\n      OP_REQUIRES(\n          context,\n          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,\n          errors::InvalidArgument(\n              \"Invalid input backprop index: \", input_backprop_index, \", \",\n              num_total_inputs));\n      input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -130,7 +130,9 @@\n         output_size[2] * output_size[1] * output_size[0];\n     for (int64_t i = 0; i < num_reshaped_cols; ++i) {\n       for (int64_t j = 0; j < output_size[3]; ++j) {\n-        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));\n+        OP_REQUIRES(context, tensor_out_dup_mat(j, i) == tensor_out_mat(j, i),\n+                    errors::InvalidArgument(\n+                        \"tensor_out_dup is not the same as tensor_out\"));\n       }\n     }\n \n@@ -147,11 +149,12 @@\n \n     for (int index = 0; index < num_total_outputs; ++index) {\n       int input_backprop_index = out_arg_max_flat(index);\n-      // According to maxpooling_op.cc, the performance impact below is small.\n-      CHECK(input_backprop_index >= 0 &&\n-            input_backprop_index < num_total_inputs)\n-          << \"Invalid input backprop index: \" << input_backprop_index << \", \"\n-          << num_total_inputs;\n+      OP_REQUIRES(\n+          context,\n+          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,\n+          errors::InvalidArgument(\n+              \"Invalid input backprop index: \", input_backprop_index, \", \",\n+              num_total_inputs));\n       input_backprop_flat(input_backprop_index) += out_backprop_flat(index);\n     }\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "        DCHECK_EQ(tensor_out_dup_mat(j, i), tensor_out_mat(j, i));",
                "      // According to maxpooling_op.cc, the performance impact below is small.",
                "      CHECK(input_backprop_index >= 0 &&",
                "            input_backprop_index < num_total_inputs)",
                "          << \"Invalid input backprop index: \" << input_backprop_index << \", \"",
                "          << num_total_inputs;"
            ],
            "added_lines": [
                "        OP_REQUIRES(context, tensor_out_dup_mat(j, i) == tensor_out_mat(j, i),",
                "                    errors::InvalidArgument(",
                "                        \"tensor_out_dup is not the same as tensor_out\"));",
                "      OP_REQUIRES(",
                "          context,",
                "          input_backprop_index >= 0 && input_backprop_index < num_total_inputs,",
                "          errors::InvalidArgument(",
                "              \"Invalid input backprop index: \", input_backprop_index, \", \",",
                "              num_total_inputs));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35983",
        "func_name": "tensorflow/TensorSliceWriter::SaveData",
        "description": "TensorFlow is an open source platform for machine learning. If `Save` or `SaveSlices` is run over tensors of an unsupported `dtype`, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4",
        "commit_title": "Fix tf.raw_ops.SaveSlices vulnerability with unsupported dtypes.",
        "commit_text": " Check that given dtype is supported and emit a descriptive error if not.  PiperOrigin-RevId: 461660795",
        "func_before": "Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                   SavedSlice* ss) {\n  size_t size_bound =\n      ss->ByteSize() + kTensorProtoHeaderBytes +\n      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);\n  if (size_bound > kMaxMessageBytes) {\n    return errors::InvalidArgument(\n        \"Tensor slice is too large to serialize (conservative estimate: \",\n        size_bound, \" bytes)\");\n  }\n  Fill(data, num_elements, ss->mutable_data());\n  DCHECK_GE(ss->ByteSize(), 0);\n  DCHECK_LE(ss->ByteSize(), size_bound);\n  return OkStatus();\n}",
        "func": "Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                   SavedSlice* ss) {\n  size_t max_bytes_per_element =\n      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);\n  if (max_bytes_per_element == 0) {\n    return errors::InvalidArgument(\n        \"Tensor slice serialization not implemented for dtype \",\n        DataTypeToEnum<T>::value);\n  }\n  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n                      (max_bytes_per_element * num_elements);\n  if (size_bound > kMaxMessageBytes) {\n    return errors::InvalidArgument(\n        \"Tensor slice is too large to serialize (conservative estimate: \",\n        size_bound, \" bytes)\");\n  }\n  Fill(data, num_elements, ss->mutable_data());\n  DCHECK_GE(ss->ByteSize(), 0);\n  DCHECK_LE(ss->ByteSize(), size_bound);\n  return OkStatus();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,14 @@\n Status TensorSliceWriter::SaveData(const T* data, int64_t num_elements,\n                                    SavedSlice* ss) {\n-  size_t size_bound =\n-      ss->ByteSize() + kTensorProtoHeaderBytes +\n-      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);\n+  size_t max_bytes_per_element =\n+      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);\n+  if (max_bytes_per_element == 0) {\n+    return errors::InvalidArgument(\n+        \"Tensor slice serialization not implemented for dtype \",\n+        DataTypeToEnum<T>::value);\n+  }\n+  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +\n+                      (max_bytes_per_element * num_elements);\n   if (size_bound > kMaxMessageBytes) {\n     return errors::InvalidArgument(\n         \"Tensor slice is too large to serialize (conservative estimate: \",",
        "diff_line_info": {
            "deleted_lines": [
                "  size_t size_bound =",
                "      ss->ByteSize() + kTensorProtoHeaderBytes +",
                "      (MaxBytesPerElement(DataTypeToEnum<T>::value) * num_elements);"
            ],
            "added_lines": [
                "  size_t max_bytes_per_element =",
                "      MaxBytesPerElementOrZero(DataTypeToEnum<T>::value);",
                "  if (max_bytes_per_element == 0) {",
                "    return errors::InvalidArgument(",
                "        \"Tensor slice serialization not implemented for dtype \",",
                "        DataTypeToEnum<T>::value);",
                "  }",
                "  size_t size_bound = ss->ByteSize() + kTensorProtoHeaderBytes +",
                "                      (max_bytes_per_element * num_elements);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35983",
        "func_name": "tensorflow/TensorSliceWriter::MaxBytesPerElement",
        "description": "TensorFlow is an open source platform for machine learning. If `Save` or `SaveSlices` is run over tensors of an unsupported `dtype`, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/5dd7b86b84a864b834c6fa3d7f9f51c87efa99d4",
        "commit_title": "Fix tf.raw_ops.SaveSlices vulnerability with unsupported dtypes.",
        "commit_text": " Check that given dtype is supported and emit a descriptive error if not.  PiperOrigin-RevId: 461660795",
        "func_before": "size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n  switch (dt) {\n    case DT_FLOAT:\n      return 4;\n    case DT_DOUBLE:\n      return 8;\n    case DT_INT32:\n      return 10;\n    case DT_UINT8:\n      return 2;\n    case DT_INT16:\n      return 10;\n    case DT_INT8:\n      return 10;\n    case DT_COMPLEX64:\n      return 8;\n    case DT_INT64:\n      return 10;\n    case DT_BOOL:\n      return 1;\n    case DT_QINT8:\n      return 10;\n    case DT_QUINT8:\n      return 2;\n    case DT_QINT32:\n      return 10;\n    case DT_QINT16:\n      return 10;\n    case DT_QUINT16:\n      return 3;\n    case DT_UINT16:\n      return 3;\n    case DT_COMPLEX128:\n      return 16;\n    case DT_HALF:\n      return 3;\n    case DT_INVALID:\n    case DT_STRING:\n    case DT_BFLOAT16:\n    default:\n      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n  }\n  return 0;\n}",
        "func": "size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n  size_t max_bytes_per_element =\n      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n  if (max_bytes_per_element == 0) {\n    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n  }\n  return max_bytes_per_element;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,44 +1,8 @@\n size_t TensorSliceWriter::MaxBytesPerElement(DataType dt) {\n-  switch (dt) {\n-    case DT_FLOAT:\n-      return 4;\n-    case DT_DOUBLE:\n-      return 8;\n-    case DT_INT32:\n-      return 10;\n-    case DT_UINT8:\n-      return 2;\n-    case DT_INT16:\n-      return 10;\n-    case DT_INT8:\n-      return 10;\n-    case DT_COMPLEX64:\n-      return 8;\n-    case DT_INT64:\n-      return 10;\n-    case DT_BOOL:\n-      return 1;\n-    case DT_QINT8:\n-      return 10;\n-    case DT_QUINT8:\n-      return 2;\n-    case DT_QINT32:\n-      return 10;\n-    case DT_QINT16:\n-      return 10;\n-    case DT_QUINT16:\n-      return 3;\n-    case DT_UINT16:\n-      return 3;\n-    case DT_COMPLEX128:\n-      return 16;\n-    case DT_HALF:\n-      return 3;\n-    case DT_INVALID:\n-    case DT_STRING:\n-    case DT_BFLOAT16:\n-    default:\n-      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n+  size_t max_bytes_per_element =\n+      TensorSliceWriter::MaxBytesPerElementOrZero(dt);\n+  if (max_bytes_per_element == 0) {\n+    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;\n   }\n-  return 0;\n+  return max_bytes_per_element;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  switch (dt) {",
                "    case DT_FLOAT:",
                "      return 4;",
                "    case DT_DOUBLE:",
                "      return 8;",
                "    case DT_INT32:",
                "      return 10;",
                "    case DT_UINT8:",
                "      return 2;",
                "    case DT_INT16:",
                "      return 10;",
                "    case DT_INT8:",
                "      return 10;",
                "    case DT_COMPLEX64:",
                "      return 8;",
                "    case DT_INT64:",
                "      return 10;",
                "    case DT_BOOL:",
                "      return 1;",
                "    case DT_QINT8:",
                "      return 10;",
                "    case DT_QUINT8:",
                "      return 2;",
                "    case DT_QINT32:",
                "      return 10;",
                "    case DT_QINT16:",
                "      return 10;",
                "    case DT_QUINT16:",
                "      return 3;",
                "    case DT_UINT16:",
                "      return 3;",
                "    case DT_COMPLEX128:",
                "      return 16;",
                "    case DT_HALF:",
                "      return 3;",
                "    case DT_INVALID:",
                "    case DT_STRING:",
                "    case DT_BFLOAT16:",
                "    default:",
                "      LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;",
                "  return 0;"
            ],
            "added_lines": [
                "  size_t max_bytes_per_element =",
                "      TensorSliceWriter::MaxBytesPerElementOrZero(dt);",
                "  if (max_bytes_per_element == 0) {",
                "    LOG(FATAL) << \"MaxBytesPerElement not implemented for dtype: \" << dt;",
                "  return max_bytes_per_element;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35985",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. If `LRNGrad` is given an `output_image` input tensor that is not 4-D, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit bd90b3efab4ec958b228cd7cfe9125be1c0cf255. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/bd90b3efab4ec958b228cd7cfe9125be1c0cf255",
        "commit_title": "Fix security vulnerability with LRNGradOp",
        "commit_text": " PiperOrigin-RevId: 460738938",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& in_grads = context->input(0);\n    const Tensor& in_image = context->input(1);\n    const Tensor& out_image = context->input(2);\n\n    OP_REQUIRES(context, in_grads.dims() == 4 && in_image.dims() == 4,\n                errors::InvalidArgument(\"inputs must be 4-dimensional\"));\n    const int64_t batch = in_grads.dim_size(0);\n    const int64_t rows = in_grads.dim_size(1);\n    const int64_t cols = in_grads.dim_size(2);\n    const int64_t depth = in_grads.dim_size(3);\n    OP_REQUIRES(\n        context,\n        in_image.dim_size(0) == batch && in_image.dim_size(1) == rows &&\n            in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&\n            out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&\n            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,\n        errors::InvalidArgument(\n            \"input_grads, input_image, and out_image should have the same \"\n            \"shape\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\n                       0, TensorShape({batch, rows, cols, depth}), &output));\n\n    LaunchLRNGrad<Device, T> launcher(depth_radius_, bias_, alpha_, beta_);\n    launcher.launch(context, this, in_grads, in_image, out_image, output);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& in_grads = context->input(0);\n    const Tensor& in_image = context->input(1);\n    const Tensor& out_image = context->input(2);\n\n    OP_REQUIRES(context, in_grads.dims() == 4 && in_image.dims() == 4,\n                errors::InvalidArgument(\"inputs must be 4-dimensional\"));\n    const int64_t batch = in_grads.dim_size(0);\n    const int64_t rows = in_grads.dim_size(1);\n    const int64_t cols = in_grads.dim_size(2);\n    const int64_t depth = in_grads.dim_size(3);\n    OP_REQUIRES(\n        context,\n        in_image.dim_size(0) == batch && in_image.dim_size(1) == rows &&\n            in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&\n            out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&\n            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&\n            out_image.dims() == 4,\n        errors::InvalidArgument(\n            \"input_grads, input_image, and out_image should have the same \"\n            \"shape\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\n                       0, TensorShape({batch, rows, cols, depth}), &output));\n\n    LaunchLRNGrad<Device, T> launcher(depth_radius_, bias_, alpha_, beta_);\n    launcher.launch(context, this, in_grads, in_image, out_image, output);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,8 @@\n         in_image.dim_size(0) == batch && in_image.dim_size(1) == rows &&\n             in_image.dim_size(2) == cols && in_image.dim_size(3) == depth &&\n             out_image.dim_size(0) == batch && out_image.dim_size(1) == rows &&\n-            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,\n+            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&\n+            out_image.dims() == 4,\n         errors::InvalidArgument(\n             \"input_grads, input_image, and out_image should have the same \"\n             \"shape\"));",
        "diff_line_info": {
            "deleted_lines": [
                "            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth,"
            ],
            "added_lines": [
                "            out_image.dim_size(2) == cols && out_image.dim_size(3) == depth &&",
                "            out_image.dims() == 4,"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35987",
        "func_name": "tensorflow/Compile",
        "description": "TensorFlow is an open source platform for machine learning. `DenseBincount` assumes its input tensor `weights` to either have the same shape as its input tensor `input` or to be length-0. A different `weights` shape will trigger a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit bf4c14353c2328636a18bfad1e151052c81d5f43. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/bf4c14353c2328636a18bfad1e151052c81d5f43",
        "commit_title": "Fix security vulnerability with DenseBincountOp",
        "commit_text": " PiperOrigin-RevId: 460826735",
        "func_before": "void Compile(XlaOpKernelContext* ctx) override {\n    int64_t output_size;\n    xla::XlaOp output_size_param = ctx->Input(\"size\");\n    StatusOr<xla::Shape> output_shape_or =\n        ctx->builder()->GetShape(output_size_param);\n    OP_REQUIRES_OK(ctx, output_shape_or.status());\n    auto output_shape_param = output_shape_or.ValueOrDie();\n    auto output_rank = output_shape_param.rank();\n    OP_REQUIRES(ctx, output_rank == 0,\n                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                        output_rank));\n    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntScalar(\"size\", &output_size));\n    OP_REQUIRES(ctx, output_size >= 0,\n                errors::InvalidArgument(\"size (\", output_size,\n                                        \") must be non-negative\"));\n    xla::XlaOp idx, updates, output;\n    xla::XlaOp input = ctx->Input(0);\n    auto input_xla_type = ctx->input_xla_type(0);\n    xla::PrimitiveType dtype = ctx->InputXlaType(\"weights\");\n    auto zero = xla::Zero(ctx->builder(), dtype);\n    auto one = xla::One(ctx->builder(), dtype);\n    StatusOr<xla::Shape> input_shape_or = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape_or.status());\n    auto input_shape = input_shape_or.ValueOrDie();\n    auto size = input_shape.dimensions(0);\n\n    if (!size) {\n      output = xla::Broadcast(zero, {output_size});\n      ctx->SetOutput(0, output);\n      return;\n    }\n    auto rank = input_shape.rank();\n\n    OP_REQUIRES(ctx, rank <= 2,\n                errors::InvalidArgument(\n                    \"Shape must be at most rank 2 but is rank \", rank));\n\n    xla::XlaOp weights = ctx->Input(2);\n    StatusOr<xla::Shape> weights_shape_or = ctx->builder()->GetShape(weights);\n    OP_REQUIRES_OK(ctx, weights_shape_or.status());\n\n    auto weights_shape = weights_shape_or.ValueOrDie();\n    auto weights_size = weights_shape.dimensions(0);\n    bool has_weights = false;\n    if (weights_size) {\n      has_weights = true;\n    }\n    xla::Shape output_shape = xla::ShapeUtil::MakeShape(dtype, {output_size});\n    xla::ScatterDimensionNumbers scatter_dnums;\n    scatter_dnums.set_index_vector_dim(1);\n    scatter_dnums.add_inserted_window_dims(0);\n    scatter_dnums.add_scatter_dims_to_operand_dims(0);\n\n    if (rank == 2) {\n      output_shape = xla::ShapeUtil::MakeShape(dtype, {size, output_size});\n      scatter_dnums.add_inserted_window_dims(1);\n      scatter_dnums.add_scatter_dims_to_operand_dims(1);\n      auto i_shape =\n          xla::ShapeUtil::MakeShape(input_xla_type, {input_shape.dimensions()});\n      auto i = xla::Iota(ctx->builder(), i_shape, 0);\n      i = xla::Reshape(\n          i, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      auto j = xla::Reshape(\n          input, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      std::vector<xla::XlaOp> iotas_to_concat;\n      iotas_to_concat.push_back(i);\n      iotas_to_concat.push_back(j);\n      idx = xla::ConcatInDim(ctx->builder(), iotas_to_concat, 1);\n      updates = xla::Broadcast(\n          one, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n      output = xla::Broadcast(\n          zero, {output_shape.dimensions(0), output_shape.dimensions(1)});\n      if (has_weights && !binary_output_) {\n        weights = xla::Reshape(\n            weights, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n        updates = weights;\n      }\n    } else {\n      input = xla::Reshape(input, {size, 1});\n      idx = xla::Reshape(input, {size, 1});\n      updates = xla::Broadcast(one, {size});\n      output = xla::Broadcast(zero, {output_size});\n      if (has_weights && !binary_output_) {\n        updates = weights;\n      }\n    }\n\n    xla::XlaComputation assn_computation = [&] {\n      std::unique_ptr<xla::XlaBuilder> subb =\n          ctx->builder()->CreateSubBuilder(\"scatter_bincount\");\n      xla::Shape param_shape = xla::ShapeUtil::MakeShape(dtype, {});\n      auto p0 = xla::Parameter(subb.get(), 0, param_shape, \"p0\");\n      auto p1 = xla::Parameter(subb.get(), 1, param_shape, \"p1\");\n      if (!binary_output_) {\n        xla::Add(p0, p1);\n      }\n      return subb->BuildAndNoteError();\n    }();\n    output = xla::Scatter(output, idx, updates, assn_computation, scatter_dnums,\n                          false, false);\n    ctx->SetOutput(0, output);\n  }",
        "func": "void Compile(XlaOpKernelContext* ctx) override {\n    int64_t output_size;\n    xla::XlaOp output_size_param = ctx->Input(\"size\");\n    StatusOr<xla::Shape> output_shape_or =\n        ctx->builder()->GetShape(output_size_param);\n    OP_REQUIRES_OK(ctx, output_shape_or.status());\n    auto output_shape_param = output_shape_or.ValueOrDie();\n    auto output_rank = output_shape_param.rank();\n    OP_REQUIRES(ctx, output_rank == 0,\n                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                        output_rank));\n    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntScalar(\"size\", &output_size));\n    OP_REQUIRES(ctx, output_size >= 0,\n                errors::InvalidArgument(\"size (\", output_size,\n                                        \") must be non-negative\"));\n    xla::XlaOp idx, updates, output;\n    xla::XlaOp input = ctx->Input(0);\n    auto input_xla_type = ctx->input_xla_type(0);\n    xla::PrimitiveType dtype = ctx->InputXlaType(\"weights\");\n    auto zero = xla::Zero(ctx->builder(), dtype);\n    auto one = xla::One(ctx->builder(), dtype);\n    StatusOr<xla::Shape> input_shape_or = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape_or.status());\n    auto input_shape = input_shape_or.ValueOrDie();\n    auto size = input_shape.dimensions(0);\n\n    if (!size) {\n      output = xla::Broadcast(zero, {output_size});\n      ctx->SetOutput(0, output);\n      return;\n    }\n    auto rank = input_shape.rank();\n\n    OP_REQUIRES(ctx, rank <= 2,\n                errors::InvalidArgument(\n                    \"Shape must be at most rank 2 but is rank \", rank));\n\n    xla::XlaOp weights = ctx->Input(2);\n    StatusOr<xla::Shape> weights_shape_or = ctx->builder()->GetShape(weights);\n    OP_REQUIRES_OK(ctx, weights_shape_or.status());\n\n    auto weights_shape = weights_shape_or.ValueOrDie();\n    OP_REQUIRES(ctx,\n                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n                                                              input_shape) ||\n                    (weights_shape.dimensions_size() > 0 &&\n                     weights_shape.dimensions(0) == 0),\n                errors::InvalidArgument(\n                    \"`weights` must be the same shape as `arr` or a length-0 \"\n                    \"`Tensor`, in which case it acts as all weights equal to \"\n                    \"1. Received \",\n                    weights_shape.DebugString()));\n\n    auto weights_size = weights_shape.dimensions(0);\n    bool has_weights = false;\n    if (weights_size) {\n      has_weights = true;\n    }\n    xla::Shape output_shape = xla::ShapeUtil::MakeShape(dtype, {output_size});\n    xla::ScatterDimensionNumbers scatter_dnums;\n    scatter_dnums.set_index_vector_dim(1);\n    scatter_dnums.add_inserted_window_dims(0);\n    scatter_dnums.add_scatter_dims_to_operand_dims(0);\n\n    if (rank == 2) {\n      output_shape = xla::ShapeUtil::MakeShape(dtype, {size, output_size});\n      scatter_dnums.add_inserted_window_dims(1);\n      scatter_dnums.add_scatter_dims_to_operand_dims(1);\n      auto i_shape =\n          xla::ShapeUtil::MakeShape(input_xla_type, {input_shape.dimensions()});\n      auto i = xla::Iota(ctx->builder(), i_shape, 0);\n      i = xla::Reshape(\n          i, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      auto j = xla::Reshape(\n          input, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      std::vector<xla::XlaOp> iotas_to_concat;\n      iotas_to_concat.push_back(i);\n      iotas_to_concat.push_back(j);\n      idx = xla::ConcatInDim(ctx->builder(), iotas_to_concat, 1);\n      updates = xla::Broadcast(\n          one, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n      output = xla::Broadcast(\n          zero, {output_shape.dimensions(0), output_shape.dimensions(1)});\n      if (has_weights && !binary_output_) {\n        weights = xla::Reshape(\n            weights, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n        updates = weights;\n      }\n    } else {\n      input = xla::Reshape(input, {size, 1});\n      idx = xla::Reshape(input, {size, 1});\n      updates = xla::Broadcast(one, {size});\n      output = xla::Broadcast(zero, {output_size});\n      if (has_weights && !binary_output_) {\n        updates = weights;\n      }\n    }\n\n    xla::XlaComputation assn_computation = [&] {\n      std::unique_ptr<xla::XlaBuilder> subb =\n          ctx->builder()->CreateSubBuilder(\"scatter_bincount\");\n      xla::Shape param_shape = xla::ShapeUtil::MakeShape(dtype, {});\n      auto p0 = xla::Parameter(subb.get(), 0, param_shape, \"p0\");\n      auto p1 = xla::Parameter(subb.get(), 1, param_shape, \"p1\");\n      if (!binary_output_) {\n        xla::Add(p0, p1);\n      }\n      return subb->BuildAndNoteError();\n    }();\n    output = xla::Scatter(output, idx, updates, assn_computation, scatter_dnums,\n                          false, false);\n    ctx->SetOutput(0, output);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -40,6 +40,17 @@\n     OP_REQUIRES_OK(ctx, weights_shape_or.status());\n \n     auto weights_shape = weights_shape_or.ValueOrDie();\n+    OP_REQUIRES(ctx,\n+                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n+                                                              input_shape) ||\n+                    (weights_shape.dimensions_size() > 0 &&\n+                     weights_shape.dimensions(0) == 0),\n+                errors::InvalidArgument(\n+                    \"`weights` must be the same shape as `arr` or a length-0 \"\n+                    \"`Tensor`, in which case it acts as all weights equal to \"\n+                    \"1. Received \",\n+                    weights_shape.DebugString()));\n+\n     auto weights_size = weights_shape.dimensions(0);\n     bool has_weights = false;\n     if (weights_size) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(ctx,",
                "                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,",
                "                                                              input_shape) ||",
                "                    (weights_shape.dimensions_size() > 0 &&",
                "                     weights_shape.dimensions(0) == 0),",
                "                errors::InvalidArgument(",
                "                    \"`weights` must be the same shape as `arr` or a length-0 \"",
                "                    \"`Tensor`, in which case it acts as all weights equal to \"",
                "                    \"1. Received \",",
                "                    weights_shape.DebugString()));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35987",
        "func_name": "tensorflow/Compile",
        "description": "TensorFlow is an open source platform for machine learning. `DenseBincount` assumes its input tensor `weights` to either have the same shape as its input tensor `input` or to be length-0. A different `weights` shape will trigger a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit bf4c14353c2328636a18bfad1e151052c81d5f43. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/bf4c14353c2328636a18bfad1e151052c81d5f43",
        "commit_title": "Fix security vulnerability with DenseBincountOp",
        "commit_text": " PiperOrigin-RevId: 460826735",
        "func_before": "void Compile(XlaOpKernelContext* ctx) override {\n    int64_t output_size;\n    xla::XlaOp output_size_param = ctx->Input(\"size\");\n    StatusOr<xla::Shape> output_shape_or =\n        ctx->builder()->GetShape(output_size_param);\n    OP_REQUIRES_OK(ctx, output_shape_or.status());\n    auto output_shape_param = output_shape_or.ValueOrDie();\n    auto output_rank = output_shape_param.rank();\n    OP_REQUIRES(ctx, output_rank == 0,\n                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                        output_rank));\n    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntScalar(\"size\", &output_size));\n    OP_REQUIRES(ctx, output_size >= 0,\n                errors::InvalidArgument(\"size (\", output_size,\n                                        \") must be non-negative\"));\n    xla::XlaOp idx, updates, output;\n    xla::XlaOp input = ctx->Input(0);\n    auto input_xla_type = ctx->input_xla_type(0);\n    xla::PrimitiveType dtype = ctx->InputXlaType(\"weights\");\n    auto zero = xla::Zero(ctx->builder(), dtype);\n    auto one = xla::One(ctx->builder(), dtype);\n    StatusOr<xla::Shape> input_shape_or = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape_or.status());\n    auto input_shape = input_shape_or.ValueOrDie();\n    auto size = input_shape.dimensions(0);\n\n    if (!size) {\n      output = xla::Broadcast(zero, {output_size});\n      ctx->SetOutput(0, output);\n      return;\n    }\n    auto rank = input_shape.rank();\n\n    OP_REQUIRES(ctx, rank <= 2,\n                errors::InvalidArgument(\n                    \"Shape must be at most rank 2 but is rank \", rank));\n\n    xla::XlaOp weights = ctx->Input(2);\n    StatusOr<xla::Shape> weights_shape_or = ctx->builder()->GetShape(weights);\n    OP_REQUIRES_OK(ctx, weights_shape_or.status());\n\n    auto weights_shape = weights_shape_or.ValueOrDie();\n    auto weights_size = weights_shape.dimensions(0);\n    bool has_weights = false;\n    if (weights_size) {\n      has_weights = true;\n    }\n    xla::Shape output_shape = xla::ShapeUtil::MakeShape(dtype, {output_size});\n    xla::ScatterDimensionNumbers scatter_dnums;\n    scatter_dnums.set_index_vector_dim(1);\n    scatter_dnums.add_inserted_window_dims(0);\n    scatter_dnums.add_scatter_dims_to_operand_dims(0);\n\n    if (rank == 2) {\n      output_shape = xla::ShapeUtil::MakeShape(dtype, {size, output_size});\n      scatter_dnums.add_inserted_window_dims(1);\n      scatter_dnums.add_scatter_dims_to_operand_dims(1);\n      auto i_shape =\n          xla::ShapeUtil::MakeShape(input_xla_type, {input_shape.dimensions()});\n      auto i = xla::Iota(ctx->builder(), i_shape, 0);\n      i = xla::Reshape(\n          i, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      auto j = xla::Reshape(\n          input, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      std::vector<xla::XlaOp> iotas_to_concat;\n      iotas_to_concat.push_back(i);\n      iotas_to_concat.push_back(j);\n      idx = xla::ConcatInDim(ctx->builder(), iotas_to_concat, 1);\n      updates = xla::Broadcast(\n          one, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n      output = xla::Broadcast(\n          zero, {output_shape.dimensions(0), output_shape.dimensions(1)});\n      if (has_weights && !binary_output_) {\n        weights = xla::Reshape(\n            weights, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n        updates = weights;\n      }\n    } else {\n      input = xla::Reshape(input, {size, 1});\n      idx = xla::Reshape(input, {size, 1});\n      updates = xla::Broadcast(one, {size});\n      output = xla::Broadcast(zero, {output_size});\n      if (has_weights && !binary_output_) {\n        updates = weights;\n      }\n    }\n\n    xla::XlaComputation assn_computation = [&] {\n      std::unique_ptr<xla::XlaBuilder> subb =\n          ctx->builder()->CreateSubBuilder(\"scatter_bincount\");\n      xla::Shape param_shape = xla::ShapeUtil::MakeShape(dtype, {});\n      auto p0 = xla::Parameter(subb.get(), 0, param_shape, \"p0\");\n      auto p1 = xla::Parameter(subb.get(), 1, param_shape, \"p1\");\n      if (!binary_output_) {\n        xla::Add(p0, p1);\n      }\n      return subb->BuildAndNoteError();\n    }();\n    output = xla::Scatter(output, idx, updates, assn_computation, scatter_dnums,\n                          false, false);\n    ctx->SetOutput(0, output);\n  }",
        "func": "void Compile(XlaOpKernelContext* ctx) override {\n    int64_t output_size;\n    xla::XlaOp output_size_param = ctx->Input(\"size\");\n    StatusOr<xla::Shape> output_shape_or =\n        ctx->builder()->GetShape(output_size_param);\n    OP_REQUIRES_OK(ctx, output_shape_or.status());\n    auto output_shape_param = output_shape_or.ValueOrDie();\n    auto output_rank = output_shape_param.rank();\n    OP_REQUIRES(ctx, output_rank == 0,\n                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                        output_rank));\n    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntScalar(\"size\", &output_size));\n    OP_REQUIRES(ctx, output_size >= 0,\n                errors::InvalidArgument(\"size (\", output_size,\n                                        \") must be non-negative\"));\n    xla::XlaOp idx, updates, output;\n    xla::XlaOp input = ctx->Input(0);\n    auto input_xla_type = ctx->input_xla_type(0);\n    xla::PrimitiveType dtype = ctx->InputXlaType(\"weights\");\n    auto zero = xla::Zero(ctx->builder(), dtype);\n    auto one = xla::One(ctx->builder(), dtype);\n    StatusOr<xla::Shape> input_shape_or = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape_or.status());\n    auto input_shape = input_shape_or.ValueOrDie();\n    auto size = input_shape.dimensions(0);\n\n    if (!size) {\n      output = xla::Broadcast(zero, {output_size});\n      ctx->SetOutput(0, output);\n      return;\n    }\n    auto rank = input_shape.rank();\n\n    OP_REQUIRES(ctx, rank <= 2,\n                errors::InvalidArgument(\n                    \"Shape must be at most rank 2 but is rank \", rank));\n\n    xla::XlaOp weights = ctx->Input(2);\n    StatusOr<xla::Shape> weights_shape_or = ctx->builder()->GetShape(weights);\n    OP_REQUIRES_OK(ctx, weights_shape_or.status());\n\n    auto weights_shape = weights_shape_or.ValueOrDie();\n    OP_REQUIRES(ctx,\n                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n                                                              input_shape) ||\n                    (weights_shape.dimensions_size() > 0 &&\n                     weights_shape.dimensions(0) == 0),\n                errors::InvalidArgument(\n                    \"`weights` must be the same shape as `arr` or a length-0 \"\n                    \"`Tensor`, in which case it acts as all weights equal to \"\n                    \"1. Received \",\n                    weights_shape.DebugString()));\n\n    auto weights_size = weights_shape.dimensions(0);\n    bool has_weights = false;\n    if (weights_size) {\n      has_weights = true;\n    }\n    xla::Shape output_shape = xla::ShapeUtil::MakeShape(dtype, {output_size});\n    xla::ScatterDimensionNumbers scatter_dnums;\n    scatter_dnums.set_index_vector_dim(1);\n    scatter_dnums.add_inserted_window_dims(0);\n    scatter_dnums.add_scatter_dims_to_operand_dims(0);\n\n    if (rank == 2) {\n      output_shape = xla::ShapeUtil::MakeShape(dtype, {size, output_size});\n      scatter_dnums.add_inserted_window_dims(1);\n      scatter_dnums.add_scatter_dims_to_operand_dims(1);\n      auto i_shape =\n          xla::ShapeUtil::MakeShape(input_xla_type, {input_shape.dimensions()});\n      auto i = xla::Iota(ctx->builder(), i_shape, 0);\n      i = xla::Reshape(\n          i, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      auto j = xla::Reshape(\n          input, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      std::vector<xla::XlaOp> iotas_to_concat;\n      iotas_to_concat.push_back(i);\n      iotas_to_concat.push_back(j);\n      idx = xla::ConcatInDim(ctx->builder(), iotas_to_concat, 1);\n      updates = xla::Broadcast(\n          one, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n      output = xla::Broadcast(\n          zero, {output_shape.dimensions(0), output_shape.dimensions(1)});\n      if (has_weights && !binary_output_) {\n        weights = xla::Reshape(\n            weights, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n        updates = weights;\n      }\n    } else {\n      input = xla::Reshape(input, {size, 1});\n      idx = xla::Reshape(input, {size, 1});\n      updates = xla::Broadcast(one, {size});\n      output = xla::Broadcast(zero, {output_size});\n      if (has_weights && !binary_output_) {\n        updates = weights;\n      }\n    }\n\n    xla::XlaComputation assn_computation = [&] {\n      std::unique_ptr<xla::XlaBuilder> subb =\n          ctx->builder()->CreateSubBuilder(\"scatter_bincount\");\n      xla::Shape param_shape = xla::ShapeUtil::MakeShape(dtype, {});\n      auto p0 = xla::Parameter(subb.get(), 0, param_shape, \"p0\");\n      auto p1 = xla::Parameter(subb.get(), 1, param_shape, \"p1\");\n      if (!binary_output_) {\n        xla::Add(p0, p1);\n      }\n      return subb->BuildAndNoteError();\n    }();\n    output = xla::Scatter(output, idx, updates, assn_computation, scatter_dnums,\n                          false, false);\n    ctx->SetOutput(0, output);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -40,6 +40,17 @@\n     OP_REQUIRES_OK(ctx, weights_shape_or.status());\n \n     auto weights_shape = weights_shape_or.ValueOrDie();\n+    OP_REQUIRES(ctx,\n+                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n+                                                              input_shape) ||\n+                    (weights_shape.dimensions_size() > 0 &&\n+                     weights_shape.dimensions(0) == 0),\n+                errors::InvalidArgument(\n+                    \"`weights` must be the same shape as `arr` or a length-0 \"\n+                    \"`Tensor`, in which case it acts as all weights equal to \"\n+                    \"1. Received \",\n+                    weights_shape.DebugString()));\n+\n     auto weights_size = weights_shape.dimensions(0);\n     bool has_weights = false;\n     if (weights_size) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(ctx,",
                "                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,",
                "                                                              input_shape) ||",
                "                    (weights_shape.dimensions_size() > 0 &&",
                "                     weights_shape.dimensions(0) == 0),",
                "                errors::InvalidArgument(",
                "                    \"`weights` must be the same shape as `arr` or a length-0 \"",
                "                    \"`Tensor`, in which case it acts as all weights equal to \"",
                "                    \"1. Received \",",
                "                    weights_shape.DebugString()));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35988",
        "func_name": "tensorflow/ComputeAsync",
        "description": "TensorFlow is an open source platform for machine learning. When `tf.linalg.matrix_rank` receives an empty input `a`, the GPU kernel gives a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit c55b476aa0e0bd4ee99d0f3ad18d9d706cd1260a. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c55b476aa0e0bd4ee99d0f3ad18d9d706cd1260a",
        "commit_title": "Fix empty batch issue in svd.",
        "commit_text": " If there are zero batches, the GPU kernel previously failed with a `work_element_count > 0` check failure.  In the zero batch case, there is no output, so simply return.  PiperOrigin-RevId: 462210670",
        "func_before": "void ComputeAsync(OpKernelContext* context, DoneCallback done) final {\n    const Tensor& input = context->input(0);\n    const int ndims = input.dims();\n\n    // Validate inputs.\n    OP_REQUIRES_ASYNC(\n        context, ndims >= 2,\n        errors::InvalidArgument(\"Input must have rank >= 2, got \", ndims),\n        done);\n\n    const int64 m = input.dim_size(ndims - 2);\n    const int64 n = input.dim_size(ndims - 1);\n    const int64 p = std::min(m, n);\n\n    // output tensors.\n    Tensor* outputU = NULL;\n    Tensor* outputS = NULL;\n    Tensor* outputV = NULL;\n\n    // compute  shapes\n    TensorShape shapeRaw = input.shape();\n    shapeRaw.RemoveLastDims(2);\n    TensorShape shapeS = shapeRaw;\n    TensorShape shapeU = shapeRaw;\n    TensorShape shapeV = shapeRaw;\n    shapeS.AddDim(p);\n    if (compute_uv_) {\n      if (full_matrices_) {\n        shapeU.AddDim(m);\n        shapeU.AddDim(m);\n        shapeV.AddDim(n);\n        shapeV.AddDim(n);\n      } else {\n        shapeU.AddDim(m);\n        shapeU.AddDim(p);\n        shapeV.AddDim(n);\n        shapeV.AddDim(p);\n      }\n    } else {\n      shapeU = TensorShape({0});\n      shapeV = TensorShape({0});\n    }\n\n    // allocate output\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(0, shapeS, &outputS),\n                         done);\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(1, shapeU, &outputU),\n                         done);\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(2, shapeV, &outputV),\n                         done);\n\n    if (n == 0 || m == 0) {\n      if (n == m || !compute_uv_ || !full_matrices_) {\n        // S, U, and V are all empty. Nothing to do.\n        done();\n        return;\n      }\n      auto device = context->eigen_device<GPUDevice>();\n      functor::EyeFunctor<GPUDevice, Scalar> eye;\n      if (m > 0) {\n        // Return a full canonical basis for the column space.\n        auto outputU_reshaped = outputU->flat_inner_dims<Scalar, 3>();\n        eye(device, outputU_reshaped);\n      } else if (n > 0) {\n        // Return a full canonical basis for the row space.\n        auto outputV_reshaped = outputV->flat_inner_dims<Scalar, 3>();\n        eye(device, outputV_reshaped);\n      }\n      done();\n      return;\n    }\n\n    // call implementations\n    if (m >= n) {\n      PerformSVD_MgeqN(context, done, m, n, p, input, outputS, outputU,\n                       outputV);\n    } else {\n      PerformSVD_MlessN(context, done, m, n, p, input, outputS, outputU,\n                        outputV);\n    }\n  }",
        "func": "void ComputeAsync(OpKernelContext* context, DoneCallback done) final {\n    const Tensor& input = context->input(0);\n    const int ndims = input.dims();\n\n    // Validate inputs.\n    OP_REQUIRES_ASYNC(\n        context, ndims >= 2,\n        errors::InvalidArgument(\"Input must have rank >= 2, got \", ndims),\n        done);\n\n    const int64 m = input.dim_size(ndims - 2);\n    const int64 n = input.dim_size(ndims - 1);\n    const int64 p = std::min(m, n);\n\n    // output tensors.\n    Tensor* outputU = NULL;\n    Tensor* outputS = NULL;\n    Tensor* outputV = NULL;\n\n    // compute  shapes\n    TensorShape shapeRaw = input.shape();\n    shapeRaw.RemoveLastDims(2);\n    TensorShape shapeS = shapeRaw;\n    TensorShape shapeU = shapeRaw;\n    TensorShape shapeV = shapeRaw;\n    shapeS.AddDim(p);\n    if (compute_uv_) {\n      if (full_matrices_) {\n        shapeU.AddDim(m);\n        shapeU.AddDim(m);\n        shapeV.AddDim(n);\n        shapeV.AddDim(n);\n      } else {\n        shapeU.AddDim(m);\n        shapeU.AddDim(p);\n        shapeV.AddDim(n);\n        shapeV.AddDim(p);\n      }\n    } else {\n      shapeU = TensorShape({0});\n      shapeV = TensorShape({0});\n    }\n\n    // allocate output\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(0, shapeS, &outputS),\n                         done);\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(1, shapeU, &outputU),\n                         done);\n    OP_REQUIRES_OK_ASYNC(context, context->allocate_output(2, shapeV, &outputV),\n                         done);\n\n    // If there are zero batches, we are done.\n    if (shapeRaw.num_elements() == 0) {\n      done();\n      return;\n    }\n\n    if (n == 0 || m == 0) {\n      if (n == m || !compute_uv_ || !full_matrices_) {\n        // S, U, and V are all empty. Nothing to do.\n        done();\n        return;\n      }\n      auto device = context->eigen_device<GPUDevice>();\n      functor::EyeFunctor<GPUDevice, Scalar> eye;\n      if (m > 0) {\n        // Return a full canonical basis for the column space.\n        auto outputU_reshaped = outputU->flat_inner_dims<Scalar, 3>();\n        eye(device, outputU_reshaped);\n      } else if (n > 0) {\n        // Return a full canonical basis for the row space.\n        auto outputV_reshaped = outputV->flat_inner_dims<Scalar, 3>();\n        eye(device, outputV_reshaped);\n      }\n      done();\n      return;\n    }\n\n    // call implementations\n    if (m >= n) {\n      PerformSVD_MgeqN(context, done, m, n, p, input, outputS, outputU,\n                       outputV);\n    } else {\n      PerformSVD_MlessN(context, done, m, n, p, input, outputS, outputU,\n                        outputV);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -49,6 +49,12 @@\n     OP_REQUIRES_OK_ASYNC(context, context->allocate_output(2, shapeV, &outputV),\n                          done);\n \n+    // If there are zero batches, we are done.\n+    if (shapeRaw.num_elements() == 0) {\n+      done();\n+      return;\n+    }\n+\n     if (n == 0 || m == 0) {\n       if (n == m || !compute_uv_ || !full_matrices_) {\n         // S, U, and V are all empty. Nothing to do.",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // If there are zero batches, we are done.",
                "    if (shapeRaw.num_elements() == 0) {",
                "      done();",
                "      return;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35990",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient` receives input `min` or `max` of rank other than 1, it gives a `CHECK` fail that can trigger a denial of service attack. We have patched the issue in GitHub commit f3cf67ac5705f4f04721d15e485e192bb319feed. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range.There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f3cf67ac5705f4f04721d15e485e192bb319feed",
        "commit_title": "Add IsScalar / IsVector (rank) checks to input min/max tensors for FakeQuantWithMinMaxVarsPerChannelGradientOp and FakeQuantWithMinMaxVarsGradientOp.",
        "commit_text": " PiperOrigin-RevId: 462542629",
        "func_before": "void Compute(OpKernelContext* context) override {\n    CHECK_EQ(4, context->num_inputs());\n    const Tensor& gradient = context->input(0);\n    const Tensor& input = context->input(1);\n    OP_REQUIRES(context, input.IsSameSize(gradient),\n                InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n    const Tensor& min = context->input(2);\n    OP_REQUIRES(context, min.dim_size(0) == depth,\n                InvalidArgument(\"min has incorrect size, expected \", depth,\n                                \" was \", min.dim_size(0)));\n    const Tensor& max = context->input(3);\n    OP_REQUIRES(context, max.dim_size(0) == depth,\n                InvalidArgument(\"max has incorrect size, expected \", depth,\n                                \" was \", max.dim_size(0)));\n\n    Tensor* grad_wrt_input;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &grad_wrt_input));\n\n    TensorShape min_max_shape({input.dim_size(input.dims() - 1)});\n    Tensor* grad_wrt_min;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(1, min_max_shape, &grad_wrt_min));\n\n    Tensor* grad_wrt_max;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(2, min_max_shape, &grad_wrt_max));\n\n    FakeQuantWithMinMaxVarsPerChannelGradientFunctor<Device> functor;\n    functor(\n        context->eigen_device<Device>(), gradient.flat_inner_dims<float, 2>(),\n        input.flat_inner_dims<float, 2>(), min.vec<float>(), max.vec<float>(),\n        quant_min_, quant_max_, grad_wrt_input->flat_inner_dims<float, 2>(),\n        grad_wrt_min->vec<float>(), grad_wrt_max->vec<float>());\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    CHECK_EQ(4, context->num_inputs());\n    const Tensor& gradient = context->input(0);\n    const Tensor& input = context->input(1);\n    OP_REQUIRES(context, input.IsSameSize(gradient),\n                InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n    const Tensor& min = context->input(2);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(min.shape()),\n        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n    OP_REQUIRES(context, min.dim_size(0) == depth,\n                InvalidArgument(\"min has incorrect size, expected \", depth,\n                                \" was \", min.dim_size(0)));\n    const Tensor& max = context->input(3);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(max.shape()),\n        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n    OP_REQUIRES(context, max.dim_size(0) == depth,\n                InvalidArgument(\"max has incorrect size, expected \", depth,\n                                \" was \", max.dim_size(0)));\n\n    Tensor* grad_wrt_input;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &grad_wrt_input));\n\n    TensorShape min_max_shape({input.dim_size(input.dims() - 1)});\n    Tensor* grad_wrt_min;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(1, min_max_shape, &grad_wrt_min));\n\n    Tensor* grad_wrt_max;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(2, min_max_shape, &grad_wrt_max));\n\n    FakeQuantWithMinMaxVarsPerChannelGradientFunctor<Device> functor;\n    functor(\n        context->eigen_device<Device>(), gradient.flat_inner_dims<float, 2>(),\n        input.flat_inner_dims<float, 2>(), min.vec<float>(), max.vec<float>(),\n        quant_min_, quant_max_, grad_wrt_input->flat_inner_dims<float, 2>(),\n        grad_wrt_min->vec<float>(), grad_wrt_max->vec<float>());\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,10 +6,16 @@\n                 InvalidArgument(\"gradient and input must be the same size\"));\n     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.\n     const Tensor& min = context->input(2);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(min.shape()),\n+        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));\n     OP_REQUIRES(context, min.dim_size(0) == depth,\n                 InvalidArgument(\"min has incorrect size, expected \", depth,\n                                 \" was \", min.dim_size(0)));\n     const Tensor& max = context->input(3);\n+    OP_REQUIRES(\n+        context, TensorShapeUtils::IsVector(max.shape()),\n+        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));\n     OP_REQUIRES(context, max.dim_size(0) == depth,\n                 InvalidArgument(\"max has incorrect size, expected \", depth,\n                                 \" was \", max.dim_size(0)));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, TensorShapeUtils::IsVector(min.shape()),",
                "        InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
                "    OP_REQUIRES(",
                "        context, TensorShapeUtils::IsVector(max.shape()),",
                "        InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36026",
        "func_name": "tensorflow/QuantizeAndDequantizeV2Op",
        "description": "TensorFlow is an open source platform for machine learning. If `QuantizeAndDequantizeV3` is given a nonscalar `num_bits` input tensor, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit f3f9cb38ecfe5a8a703f2c4a8fead434ef291713. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f3f9cb38ecfe5a8a703f2c4a8fead434ef291713",
        "commit_title": "Validate the rank and number of elements of the `num_bits` tensor for QuantizeAndDequantizeV3.",
        "commit_text": " QuantizeAndDequantizeV3Op, which accepts `num_bits` as a tensor, has a precondition that it should be rank <= 1 and the number of elements should be 1. This change adds a validation for the Compute() method for this condition.  PiperOrigin-RevId: 463755293",
        "func_before": "explicit QuantizeAndDequantizeV2Op(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                        \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n\n    string round_mode_string;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));\n    OP_REQUIRES(\n        ctx,\n        (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),\n        errors::InvalidArgument(\"Round mode string must be \"\n                                \"'HALF_UP' or \"\n                                \"'HALF_TO_EVEN', is '\" +\n                                round_mode_string + \"'\"));\n    if (round_mode_string == \"HALF_UP\") {\n      round_mode_ = ROUND_HALF_UP;\n    } else if (round_mode_string == \"HALF_TO_EVEN\") {\n      round_mode_ = ROUND_HALF_TO_EVEN;\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"narrow_range\", &narrow_range_));\n  }",
        "func": "explicit QuantizeAndDequantizeV2Op(OpKernelConstruction* ctx)\n      : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n\n    string round_mode_string;\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));\n    OP_REQUIRES(\n        ctx,\n        (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),\n        InvalidArgument(\"Round mode string must be \"\n                        \"'HALF_UP' or \"\n                        \"'HALF_TO_EVEN', is '\" +\n                        round_mode_string + \"'\"));\n    if (round_mode_string == \"HALF_UP\") {\n      round_mode_ = ROUND_HALF_UP;\n    } else if (round_mode_string == \"HALF_TO_EVEN\") {\n      round_mode_ = ROUND_HALF_TO_EVEN;\n    }\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"narrow_range\", &narrow_range_));\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,8 +4,8 @@\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n \n     string round_mode_string;\n@@ -13,10 +13,10 @@\n     OP_REQUIRES(\n         ctx,\n         (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),\n-        errors::InvalidArgument(\"Round mode string must be \"\n-                                \"'HALF_UP' or \"\n-                                \"'HALF_TO_EVEN', is '\" +\n-                                round_mode_string + \"'\"));\n+        InvalidArgument(\"Round mode string must be \"\n+                        \"'HALF_UP' or \"\n+                        \"'HALF_TO_EVEN', is '\" +\n+                        round_mode_string + \"'\"));\n     if (round_mode_string == \"HALF_UP\") {\n       round_mode_ = ROUND_HALF_UP;\n     } else if (round_mode_string == \"HALF_TO_EVEN\") {",
        "diff_line_info": {
            "deleted_lines": [
                "                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
                "                                        \" with signed_input_ \", signed_input_));",
                "        errors::InvalidArgument(\"Round mode string must be \"",
                "                                \"'HALF_UP' or \"",
                "                                \"'HALF_TO_EVEN', is '\" +",
                "                                round_mode_string + \"'\"));"
            ],
            "added_lines": [
                "                InvalidArgument(\"num_bits is out of range: \", num_bits_,",
                "                                \" with signed_input_ \", signed_input_));",
                "        InvalidArgument(\"Round mode string must be \"",
                "                        \"'HALF_UP' or \"",
                "                        \"'HALF_TO_EVEN', is '\" +",
                "                        round_mode_string + \"'\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36026",
        "func_name": "tensorflow/QuantizeAndDequantizeOp",
        "description": "TensorFlow is an open source platform for machine learning. If `QuantizeAndDequantizeV3` is given a nonscalar `num_bits` input tensor, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit f3f9cb38ecfe5a8a703f2c4a8fead434ef291713. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f3f9cb38ecfe5a8a703f2c4a8fead434ef291713",
        "commit_title": "Validate the rank and number of elements of the `num_bits` tensor for QuantizeAndDequantizeV3.",
        "commit_text": " QuantizeAndDequantizeV3Op, which accepts `num_bits` as a tensor, has a precondition that it should be rank <= 1 and the number of elements should be 1. This change adds a validation for the Compute() method for this condition.  PiperOrigin-RevId: 463755293",
        "func_before": "explicit QuantizeAndDequantizeOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                        \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));\n    if (range_given_) {\n      OP_REQUIRES(\n          ctx, input_min_ <= input_max_,\n          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,\n                                  \" > input_max \", input_max_));\n    }\n  }",
        "func": "explicit QuantizeAndDequantizeOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n    OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                \" with signed_input_ \", signed_input_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));\n    OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));\n    if (range_given_) {\n      OP_REQUIRES(ctx, input_min_ <= input_max_,\n                  InvalidArgument(\"Invalid range: input_min \", input_min_,\n                                  \" > input_max \", input_max_));\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,15 +2,14 @@\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));\n     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n-                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n-                                        \" with signed_input_ \", signed_input_));\n+                InvalidArgument(\"num_bits is out of range: \", num_bits_,\n+                                \" with signed_input_ \", signed_input_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));\n     if (range_given_) {\n-      OP_REQUIRES(\n-          ctx, input_min_ <= input_max_,\n-          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,\n+      OP_REQUIRES(ctx, input_min_ <= input_max_,\n+                  InvalidArgument(\"Invalid range: input_min \", input_min_,\n                                   \" > input_max \", input_max_));\n     }\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "                errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
                "                                        \" with signed_input_ \", signed_input_));",
                "      OP_REQUIRES(",
                "          ctx, input_min_ <= input_max_,",
                "          errors::InvalidArgument(\"Invalid range: input_min \", input_min_,"
            ],
            "added_lines": [
                "                InvalidArgument(\"num_bits is out of range: \", num_bits_,",
                "                                \" with signed_input_ \", signed_input_));",
                "      OP_REQUIRES(ctx, input_min_ <= input_max_,",
                "                  InvalidArgument(\"Invalid range: input_min \", input_min_,"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35993",
        "func_name": "tensorflow/SparseTensorFromContext",
        "description": "TensorFlow is an open source platform for machine learning. When `SetSize` receives an input `set_shape` that is not a 1D tensor, it gives a `CHECK` fails that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit cf70b79d2662c0d3c6af74583641e345fc939467. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/cf70b79d2662c0d3c6af74583641e345fc939467",
        "commit_title": "Fix tf.raw_ops.SetSize vulnerability with invalid input arg specifying shape.",
        "commit_text": " Check that given input is a 1D tensor, as required.  PiperOrigin-RevId: 460740463",
        "func_before": "Status SparseTensorFromContext(OpKernelContext* ctx, const int32_t base_index,\n                               const bool validate_indices,\n                               sparse::SparseTensor* tensor) {\n  // Assume row-major order.\n  TensorShape shape;\n  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(\n      ctx->input(base_index + 2).vec<int64_t>(), &shape));\n  CheckRankAtLeast2(ctx, shape);\n  std::vector<int64_t> order(shape.dims());\n  std::iota(order.begin(), order.end(), 0);\n\n  Status status = sparse::SparseTensor::Create(\n      ctx->input(base_index), ctx->input(base_index + 1), shape, order, tensor);\n\n  if (!validate_indices || !status.ok()) return status;\n  return tensor->IndicesValid();\n}",
        "func": "Status SparseTensorFromContext(OpKernelContext* ctx, const int32_t base_index,\n                               const bool validate_indices,\n                               sparse::SparseTensor* tensor) {\n  // Assume row-major order.\n  TensorShape shape;\n  const Tensor& shape_tensor = ctx->input(base_index + 2);\n  if (shape_tensor.dims() != 1) {\n    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");\n  }\n  TF_RETURN_IF_ERROR(\n      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));\n  CheckRankAtLeast2(ctx, shape);\n  std::vector<int64_t> order(shape.dims());\n  std::iota(order.begin(), order.end(), 0);\n\n  Status status = sparse::SparseTensor::Create(\n      ctx->input(base_index), ctx->input(base_index + 1), shape, order, tensor);\n\n  if (!validate_indices || !status.ok()) return status;\n  return tensor->IndicesValid();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,12 @@\n                                sparse::SparseTensor* tensor) {\n   // Assume row-major order.\n   TensorShape shape;\n-  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(\n-      ctx->input(base_index + 2).vec<int64_t>(), &shape));\n+  const Tensor& shape_tensor = ctx->input(base_index + 2);\n+  if (shape_tensor.dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");\n+  }\n+  TF_RETURN_IF_ERROR(\n+      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));\n   CheckRankAtLeast2(ctx, shape);\n   std::vector<int64_t> order(shape.dims());\n   std::iota(order.begin(), order.end(), 0);",
        "diff_line_info": {
            "deleted_lines": [
                "  TF_RETURN_IF_ERROR(TensorShape::BuildTensorShape(",
                "      ctx->input(base_index + 2).vec<int64_t>(), &shape));"
            ],
            "added_lines": [
                "  const Tensor& shape_tensor = ctx->input(base_index + 2);",
                "  if (shape_tensor.dims() != 1) {",
                "    return errors::InvalidArgument(\"Shape must be a 1D tensor.\");",
                "  }",
                "  TF_RETURN_IF_ERROR(",
                "      TensorShape::BuildTensorShape(shape_tensor.vec<int64_t>(), &shape));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35995",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `AudioSummaryV2` receives an input `sample_rate` with more than one element, it gives a `CHECK` fails that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit bf6b45244992e2ee543c258e519489659c99fb7f. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/bf6b45244992e2ee543c258e519489659c99fb7f",
        "commit_title": "Fix tf.raw_ops.AudioSummaryV2 vulnerability with invalid `sample_rate`.",
        "commit_text": " Check that `sample_rate` has the required shape.  PiperOrigin-RevId: 460819553",
        "func_before": "void Compute(OpKernelContext* c) override {\n    const Tensor& tag = c->input(0);\n    const Tensor& tensor = c->input(1);\n    OP_REQUIRES(c, TensorShapeUtils::IsScalar(tag.shape()),\n                errors::InvalidArgument(\"Tag must be a scalar\"));\n    OP_REQUIRES(c, tensor.dims() >= 2 && tensor.dims() <= 3,\n                errors::InvalidArgument(\"Tensor must be 3-D or 2-D, got: \",\n                                        tensor.shape().DebugString()));\n    const string& base_tag = tag.scalar<tstring>()();\n\n    float sample_rate = sample_rate_attr_;\n    if (!has_sample_rate_attr_) {\n      const Tensor& sample_rate_tensor = c->input(2);\n      sample_rate = sample_rate_tensor.scalar<float>()();\n    }\n    OP_REQUIRES(c, sample_rate > 0.0f,\n                errors::InvalidArgument(\"sample_rate must be > 0\"));\n\n    const int batch_size = tensor.dim_size(0);\n    const int64_t length_frames = tensor.dim_size(1);\n    const int64_t num_channels =\n        tensor.dims() == 2 ? 1 : tensor.dim_size(tensor.dims() - 1);\n\n    Summary s;\n    const int N = std::min<int>(max_outputs_, batch_size);\n    for (int i = 0; i < N; ++i) {\n      Summary::Value* v = s.add_value();\n      if (max_outputs_ > 1) {\n        v->set_tag(strings::StrCat(base_tag, \"/audio/\", i));\n      } else {\n        v->set_tag(strings::StrCat(base_tag, \"/audio\"));\n      }\n\n      Summary::Audio* sa = v->mutable_audio();\n      sa->set_sample_rate(sample_rate);\n      sa->set_num_channels(num_channels);\n      sa->set_length_frames(length_frames);\n      sa->set_content_type(\"audio/wav\");\n\n      auto values =\n          tensor.shaped<float, 3>({batch_size, length_frames, num_channels});\n      const float* data =\n          tensor.NumElements() == 0 ? nullptr : &values(i, 0, 0);\n\n      size_t sample_rate_truncated = lrintf(sample_rate);\n      if (sample_rate_truncated == 0) {\n        sample_rate_truncated = 1;\n      }\n      OP_REQUIRES_OK(c, wav::EncodeAudioAsS16LEWav(\n                            data, sample_rate_truncated, num_channels,\n                            length_frames, sa->mutable_encoded_audio_string()));\n    }\n\n    Tensor* summary_tensor = nullptr;\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape({}), &summary_tensor));\n    CHECK(SerializeToTString(s, &summary_tensor->scalar<tstring>()()));\n  }",
        "func": "void Compute(OpKernelContext* c) override {\n    const Tensor& tag = c->input(0);\n    const Tensor& tensor = c->input(1);\n    OP_REQUIRES(c, TensorShapeUtils::IsScalar(tag.shape()),\n                errors::InvalidArgument(\"Tag must be a scalar\"));\n    OP_REQUIRES(c, tensor.dims() >= 2 && tensor.dims() <= 3,\n                errors::InvalidArgument(\"Tensor must be 3-D or 2-D, got: \",\n                                        tensor.shape().DebugString()));\n    const string& base_tag = tag.scalar<tstring>()();\n\n    float sample_rate = sample_rate_attr_;\n    if (!has_sample_rate_attr_) {\n      const Tensor& sample_rate_tensor = c->input(2);\n      OP_REQUIRES(c,\n                  sample_rate_tensor.IsAligned() &&\n                      sample_rate_tensor.NumElements() == 1,\n                  errors::InvalidArgument(\n                      \"sample_rate must be rank-0 or contain a single value\"));\n      sample_rate = sample_rate_tensor.scalar<float>()();\n    }\n    OP_REQUIRES(c, sample_rate > 0.0f,\n                errors::InvalidArgument(\"sample_rate must be > 0\"));\n\n    const int batch_size = tensor.dim_size(0);\n    const int64_t length_frames = tensor.dim_size(1);\n    const int64_t num_channels =\n        tensor.dims() == 2 ? 1 : tensor.dim_size(tensor.dims() - 1);\n\n    Summary s;\n    const int N = std::min<int>(max_outputs_, batch_size);\n    for (int i = 0; i < N; ++i) {\n      Summary::Value* v = s.add_value();\n      if (max_outputs_ > 1) {\n        v->set_tag(strings::StrCat(base_tag, \"/audio/\", i));\n      } else {\n        v->set_tag(strings::StrCat(base_tag, \"/audio\"));\n      }\n\n      Summary::Audio* sa = v->mutable_audio();\n      sa->set_sample_rate(sample_rate);\n      sa->set_num_channels(num_channels);\n      sa->set_length_frames(length_frames);\n      sa->set_content_type(\"audio/wav\");\n\n      auto values =\n          tensor.shaped<float, 3>({batch_size, length_frames, num_channels});\n      const float* data =\n          tensor.NumElements() == 0 ? nullptr : &values(i, 0, 0);\n\n      size_t sample_rate_truncated = lrintf(sample_rate);\n      if (sample_rate_truncated == 0) {\n        sample_rate_truncated = 1;\n      }\n      OP_REQUIRES_OK(c, wav::EncodeAudioAsS16LEWav(\n                            data, sample_rate_truncated, num_channels,\n                            length_frames, sa->mutable_encoded_audio_string()));\n    }\n\n    Tensor* summary_tensor = nullptr;\n    OP_REQUIRES_OK(c, c->allocate_output(0, TensorShape({}), &summary_tensor));\n    CHECK(SerializeToTString(s, &summary_tensor->scalar<tstring>()()));\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,11 @@\n     float sample_rate = sample_rate_attr_;\n     if (!has_sample_rate_attr_) {\n       const Tensor& sample_rate_tensor = c->input(2);\n+      OP_REQUIRES(c,\n+                  sample_rate_tensor.IsAligned() &&\n+                      sample_rate_tensor.NumElements() == 1,\n+                  errors::InvalidArgument(\n+                      \"sample_rate must be rank-0 or contain a single value\"));\n       sample_rate = sample_rate_tensor.scalar<float>()();\n     }\n     OP_REQUIRES(c, sample_rate > 0.0f,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      OP_REQUIRES(c,",
                "                  sample_rate_tensor.IsAligned() &&",
                "                      sample_rate_tensor.NumElements() == 1,",
                "                  errors::InvalidArgument(",
                "                      \"sample_rate must be rank-0 or contain a single value\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35998",
        "func_name": "tensorflow/TensorShapeFromTensor",
        "description": "TensorFlow is an open source platform for machine learning. If `EmptyTensorList` receives an input `element_shape` with more than one dimension, it gives a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit c8ba76d48567aed347508e0552a257641931024d. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c8ba76d48567aed347508e0552a257641931024d",
        "commit_title": "Fix tf.raw_ops.EmptyTensorList vulnerability with invalid `element_shape`.",
        "commit_text": " Check that given `element_shape` is valid. Add graph/eager unit tests. Graph mode was already ok but eager mode was not.  PiperOrigin-RevId: 461906461",
        "func_before": "Status TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n  if (t.shape() == TensorShape({})) {\n    if ((t.dtype() == DT_INT32 && t.scalar<int32>()() == -1) ||\n        (t.dtype() == DT_INT64 && t.scalar<int64_t>()() == -1)) {\n      *out = PartialTensorShape();\n      return OkStatus();\n    }\n    return errors::InvalidArgument(\n        \"The only valid scalar shape tensor is the fully unknown shape \"\n        \"specified as -1.\");\n  }\n  if (t.dtype() == DT_INT32) {\n    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),\n                                                t.NumElements(), out);\n  } else if (t.dtype() == DT_INT64) {\n    return PartialTensorShape::MakePartialShape(t.vec<int64_t>().data(),\n                                                t.NumElements(), out);\n  }\n  return errors::InvalidArgument(\n      \"Expected an int32 or int64 shape tensor; found \",\n      DataTypeString(t.dtype()));\n}",
        "func": "Status TensorShapeFromTensor(const Tensor& t, PartialTensorShape* out) {\n  if (t.shape() == TensorShape({})) {\n    if ((t.dtype() == DT_INT32 && t.scalar<int32>()() == -1) ||\n        (t.dtype() == DT_INT64 && t.scalar<int64_t>()() == -1)) {\n      *out = PartialTensorShape();\n      return OkStatus();\n    }\n    return errors::InvalidArgument(\n        \"The only valid scalar shape tensor is the fully unknown shape \"\n        \"specified as -1.\");\n  } else if (t.shape().dims() != 1) {\n    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",\n                                   t.shape().dims());\n  }\n  if (t.dtype() == DT_INT32) {\n    return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),\n                                                t.NumElements(), out);\n  } else if (t.dtype() == DT_INT64) {\n    return PartialTensorShape::MakePartialShape(t.vec<int64_t>().data(),\n                                                t.NumElements(), out);\n  }\n  return errors::InvalidArgument(\n      \"Expected an int32 or int64 shape tensor; found \",\n      DataTypeString(t.dtype()));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,9 @@\n     return errors::InvalidArgument(\n         \"The only valid scalar shape tensor is the fully unknown shape \"\n         \"specified as -1.\");\n+  } else if (t.shape().dims() != 1) {\n+    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",\n+                                   t.shape().dims());\n   }\n   if (t.dtype() == DT_INT32) {\n     return PartialTensorShape::MakePartialShape(t.vec<int32>().data(),",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  } else if (t.shape().dims() != 1) {",
                "    return errors::InvalidArgument(\"Shape must be at most rank 1 but is rank \",",
                "                                   t.shape().dims());"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35999",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `Conv2DBackpropInput` receives empty `out_backprop` inputs (e.g. `[3, 1, 0, 1]`), the current CPU/GPU kernels `CHECK` fail (one with dnnl, the other with cudnn). This can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 27a65a43cf763897fecfa5cdb5cc653fc5dd0346. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/27a65a43cf763897fecfa5cdb5cc653fc5dd0346",
        "commit_title": "Fix GPU/CPU Conv2DBackpropInputOp check error.",
        "commit_text": " For empty `out_backprop` inputs (e.g. `[3, 1, 0, 1]`), the current CPU/GPU kernels fail (one with dnnl, the other with cudnn). Added a shortcut path to return a zero input.  Note that the XLA test currently fails due to an incorrect result size bug (b/239598470), so it is currently disabled.  PiperOrigin-RevId: 462217998",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input_sizes = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n\n    TensorShape input_shape;\n    OP_REQUIRES_OK(context,\n                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n                                                   out_backprop.shape(),\n                                                   data_format_, &input_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(context,\n                   ConvBackpropComputeDimensionsV2(\n                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,\n                       input_shape, filter.shape(), out_backprop.shape(),\n                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,\n                       explicit_paddings_, data_format_, &dims));\n\n    OP_REQUIRES(context, dims.in_depth == filter.shape().dim_size(2),\n                errors::InvalidArgument(\n                    \"Gradients for grouped convolutions are not \"\n                    \"supported on CPU. Please file a feature request if you \"\n                    \"run into this issue. Computed input depth \",\n                    dims.in_depth, \" doesn't match filter input depth \",\n                    filter.shape().dim_size(2)));\n    OP_REQUIRES(\n        context, dims.out_depth == filter.shape().dim_size(3),\n        errors::InvalidArgument(\"Computed output depth \", dims.out_depth,\n                                \" doesn't match filter output depth \",\n                                filter.shape().dim_size(3)));\n\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_shape, &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input_shape.num_elements() == 0) {\n      return;\n    }\n\n// TODO(ezhulenev): Remove custom kernel and move XSMM support to\n// LaunchConv2DBackpropInputOp functor.\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardInputConvolution<Device, T>()(\n              context, context->eigen_device<Device>(),\n              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),\n              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#else\n    int64_t pad_top, pad_bottom;\n    int64_t pad_left, pad_right;\n#endif\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // TODO(andydavis) Get L2/L3 cache sizes from device.\n    const size_t l2_cache_size = 256LL << 10;\n    const size_t l3_cache_size = 30LL << 20;\n\n    // Use L3 cache size as target working set size.\n    const size_t target_working_set_size = l3_cache_size / sizeof(T);\n\n    // Calculate size of matrices involved in MatMul: C = A x B.\n    const size_t size_A = output_image_size * dims.out_depth;\n\n    const size_t size_B = filter_total_size * dims.out_depth;\n\n    const size_t size_C = output_image_size * filter_total_size;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Calculate per-thread work unit size.\n    const size_t thread_work_unit_size =\n        work_unit_size / worker_threads.num_threads;\n\n    // Set minimum per-thread work unit size to size of L2 cache.\n    const size_t min_thread_work_unit_size = l2_cache_size / sizeof(T);\n\n    // Use parallel tensor contractions if there is no batching, or if the\n    // minimum per-thread work unit size threshold has been exceeded.\n    // Otherwise, revert to multiple single-threaded matmul ops running in\n    // parallel to keep all threads busy.\n    // TODO(andydavis) Explore alternatives to branching the code in this way\n    // (i.e. run multiple, parallel tensor contractions in another thread pool).\n    const bool use_parallel_contraction =\n        dims.batch_size == 1 ||\n        thread_work_unit_size >= min_thread_work_unit_size;\n\n    OP_REQUIRES(\n        context, work_unit_size > 0,\n        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n                                \"must all have at least 1 element\"));\n\n    const size_t shard_size =\n        use_parallel_contraction\n            ? 1\n            : (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64_t>(shard_size),\n                                    static_cast<int64_t>(output_image_size),\n                                    static_cast<int64_t>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* filter_data = filter.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n\n    auto in_backprop_flat = in_backprop->template flat<T>();\n    T* input_backprop_data = in_backprop_flat.data();\n    in_backprop_flat.device(context->eigen_device<Device>()) =\n        in_backprop_flat.constant(T(0));\n\n    if (use_parallel_contraction) {\n      typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          TensorMap;\n      typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          ConstTensorMap;\n\n      // Initialize contraction dims (we need to transpose 'B' below).\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n      contract_dims[0].first = 1;\n      contract_dims[0].second = 1;\n\n      for (int image_id = 0; image_id < dims.batch_size; ++image_id) {\n        // Compute gradient into col_buffer.\n        TensorMap C(col_buffer_data, output_image_size, filter_total_size);\n\n        ConstTensorMap A(out_backprop_data + output_offset * image_id,\n                         output_image_size, dims.out_depth);\n        ConstTensorMap B(filter_data, filter_total_size, dims.out_depth);\n\n        C.device(context->eigen_cpu_device()) = A.contract(B, contract_dims);\n\n        Col2im<T>(\n            col_buffer_data, dims.in_depth, dims.spatial_dims[0].input_size,\n            dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n            pad_right, dims.spatial_dims[0].stride, dims.spatial_dims[1].stride,\n            input_backprop_data);\n\n        input_backprop_data += input_offset;\n      }\n    } else {\n      for (int image_id = 0; image_id < dims.batch_size;\n           image_id += shard_size) {\n        const int shard_limit =\n            std::min(static_cast<int>(shard_size),\n                     static_cast<int>(dims.batch_size) - image_id);\n\n        auto shard = [&context, &dims, &pad_top, &pad_left, &pad_bottom,\n                      &pad_right, &output_image_size, &filter_total_size,\n                      &input_backprop_data, &col_buffer_data,\n                      &out_backprop_data, &filter_data, &input_offset,\n                      &output_offset, &size_C](int64_t start, int64_t limit) {\n          for (int shard_id = start; shard_id < limit; ++shard_id) {\n            T* im2col_buf = col_buffer_data + shard_id * size_C;\n            T* input_data = input_backprop_data + shard_id * input_offset;\n            const T* out_data = out_backprop_data + shard_id * output_offset;\n\n            Conv2DCustomBackpropInputMatMulFunctor<T>()(\n                context, out_data, filter_data, filter_total_size,\n                output_image_size, dims.out_depth, im2col_buf);\n\n            Col2im<T>(im2col_buf, dims.in_depth,\n                      dims.spatial_dims[0].input_size,\n                      dims.spatial_dims[1].input_size,\n                      dims.spatial_dims[0].filter_size,\n                      dims.spatial_dims[1].filter_size, pad_top, pad_left,\n                      pad_bottom, pad_right, dims.spatial_dims[0].stride,\n                      dims.spatial_dims[1].stride, input_data);\n          }\n        };\n        Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n              work_unit_size, shard);\n\n        input_backprop_data += input_offset * shard_limit;\n        out_backprop_data += output_offset * shard_limit;\n      }\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input_sizes = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n\n    TensorShape input_shape;\n    OP_REQUIRES_OK(context,\n                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n                                                   out_backprop.shape(),\n                                                   data_format_, &input_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(context,\n                   ConvBackpropComputeDimensionsV2(\n                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,\n                       input_shape, filter.shape(), out_backprop.shape(),\n                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,\n                       explicit_paddings_, data_format_, &dims));\n\n    OP_REQUIRES(context, dims.in_depth == filter.shape().dim_size(2),\n                errors::InvalidArgument(\n                    \"Gradients for grouped convolutions are not \"\n                    \"supported on CPU. Please file a feature request if you \"\n                    \"run into this issue. Computed input depth \",\n                    dims.in_depth, \" doesn't match filter input depth \",\n                    filter.shape().dim_size(2)));\n    OP_REQUIRES(\n        context, dims.out_depth == filter.shape().dim_size(3),\n        errors::InvalidArgument(\"Computed output depth \", dims.out_depth,\n                                \" doesn't match filter output depth \",\n                                filter.shape().dim_size(3)));\n\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_shape, &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input_shape.num_elements() == 0) {\n      return;\n    }\n\n    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n    if (out_backprop.NumElements() == 0) {\n      functor::SetZeroFunctor<Device, T> set_zero;\n      set_zero(context->eigen_device<Device>(),\n               in_backprop->template flat<T>());\n      return;\n    }\n\n// TODO(ezhulenev): Remove custom kernel and move XSMM support to\n// LaunchConv2DBackpropInputOp functor.\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardInputConvolution<Device, T>()(\n              context, context->eigen_device<Device>(),\n              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),\n              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#else\n    int64_t pad_top, pad_bottom;\n    int64_t pad_left, pad_right;\n#endif\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // TODO(andydavis) Get L2/L3 cache sizes from device.\n    const size_t l2_cache_size = 256LL << 10;\n    const size_t l3_cache_size = 30LL << 20;\n\n    // Use L3 cache size as target working set size.\n    const size_t target_working_set_size = l3_cache_size / sizeof(T);\n\n    // Calculate size of matrices involved in MatMul: C = A x B.\n    const size_t size_A = output_image_size * dims.out_depth;\n\n    const size_t size_B = filter_total_size * dims.out_depth;\n\n    const size_t size_C = output_image_size * filter_total_size;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Calculate per-thread work unit size.\n    const size_t thread_work_unit_size =\n        work_unit_size / worker_threads.num_threads;\n\n    // Set minimum per-thread work unit size to size of L2 cache.\n    const size_t min_thread_work_unit_size = l2_cache_size / sizeof(T);\n\n    // Use parallel tensor contractions if there is no batching, or if the\n    // minimum per-thread work unit size threshold has been exceeded.\n    // Otherwise, revert to multiple single-threaded matmul ops running in\n    // parallel to keep all threads busy.\n    // TODO(andydavis) Explore alternatives to branching the code in this way\n    // (i.e. run multiple, parallel tensor contractions in another thread pool).\n    const bool use_parallel_contraction =\n        dims.batch_size == 1 ||\n        thread_work_unit_size >= min_thread_work_unit_size;\n\n    OP_REQUIRES(\n        context, work_unit_size > 0,\n        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n                                \"must all have at least 1 element\"));\n\n    const size_t shard_size =\n        use_parallel_contraction\n            ? 1\n            : (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64_t>(shard_size),\n                                    static_cast<int64_t>(output_image_size),\n                                    static_cast<int64_t>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* filter_data = filter.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n\n    auto in_backprop_flat = in_backprop->template flat<T>();\n    T* input_backprop_data = in_backprop_flat.data();\n    in_backprop_flat.device(context->eigen_device<Device>()) =\n        in_backprop_flat.constant(T(0));\n\n    if (use_parallel_contraction) {\n      typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          TensorMap;\n      typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          ConstTensorMap;\n\n      // Initialize contraction dims (we need to transpose 'B' below).\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n      contract_dims[0].first = 1;\n      contract_dims[0].second = 1;\n\n      for (int image_id = 0; image_id < dims.batch_size; ++image_id) {\n        // Compute gradient into col_buffer.\n        TensorMap C(col_buffer_data, output_image_size, filter_total_size);\n\n        ConstTensorMap A(out_backprop_data + output_offset * image_id,\n                         output_image_size, dims.out_depth);\n        ConstTensorMap B(filter_data, filter_total_size, dims.out_depth);\n\n        C.device(context->eigen_cpu_device()) = A.contract(B, contract_dims);\n\n        Col2im<T>(\n            col_buffer_data, dims.in_depth, dims.spatial_dims[0].input_size,\n            dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n            pad_right, dims.spatial_dims[0].stride, dims.spatial_dims[1].stride,\n            input_backprop_data);\n\n        input_backprop_data += input_offset;\n      }\n    } else {\n      for (int image_id = 0; image_id < dims.batch_size;\n           image_id += shard_size) {\n        const int shard_limit =\n            std::min(static_cast<int>(shard_size),\n                     static_cast<int>(dims.batch_size) - image_id);\n\n        auto shard = [&context, &dims, &pad_top, &pad_left, &pad_bottom,\n                      &pad_right, &output_image_size, &filter_total_size,\n                      &input_backprop_data, &col_buffer_data,\n                      &out_backprop_data, &filter_data, &input_offset,\n                      &output_offset, &size_C](int64_t start, int64_t limit) {\n          for (int shard_id = start; shard_id < limit; ++shard_id) {\n            T* im2col_buf = col_buffer_data + shard_id * size_C;\n            T* input_data = input_backprop_data + shard_id * input_offset;\n            const T* out_data = out_backprop_data + shard_id * output_offset;\n\n            Conv2DCustomBackpropInputMatMulFunctor<T>()(\n                context, out_data, filter_data, filter_total_size,\n                output_image_size, dims.out_depth, im2col_buf);\n\n            Col2im<T>(im2col_buf, dims.in_depth,\n                      dims.spatial_dims[0].input_size,\n                      dims.spatial_dims[1].input_size,\n                      dims.spatial_dims[0].filter_size,\n                      dims.spatial_dims[1].filter_size, pad_top, pad_left,\n                      pad_bottom, pad_right, dims.spatial_dims[0].stride,\n                      dims.spatial_dims[1].stride, input_data);\n          }\n        };\n        Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n              work_unit_size, shard);\n\n        input_backprop_data += input_offset * shard_limit;\n        out_backprop_data += output_offset * shard_limit;\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -39,6 +39,15 @@\n       return;\n     }\n \n+    // If shapes are valid but `out_backprop` is empty, in_backprop should be\n+    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.\n+    if (out_backprop.NumElements() == 0) {\n+      functor::SetZeroFunctor<Device, T> set_zero;\n+      set_zero(context->eigen_device<Device>(),\n+               in_backprop->template flat<T>());\n+      return;\n+    }\n+\n // TODO(ezhulenev): Remove custom kernel and move XSMM support to\n // LaunchConv2DBackpropInputOp functor.\n #if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // If shapes are valid but `out_backprop` is empty, in_backprop should be",
                "    // set to all zeros.  Otherwise, cudnn/dnnl fail with an empty input.",
                "    if (out_backprop.NumElements() == 0) {",
                "      functor::SetZeroFunctor<Device, T> set_zero;",
                "      set_zero(context->eigen_device<Device>(),",
                "               in_backprop->template flat<T>());",
                "      return;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36001",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `DrawBoundingBoxes` receives an input `boxes` that is not of dtype `float`, it gives a `CHECK` fail that can trigger a denial of service attack. We have patched the issue in GitHub commit da0d65cdc1270038e72157ba35bf74b85d9bda11. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/da0d65cdc1270038e72157ba35bf74b85d9bda11",
        "commit_title": "Fix dtype bug in draw bounding boxes.",
        "commit_text": " Boxes always needs to be type `float`.  PiperOrigin-RevId: 461800676",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& images = context->input(0);\n    const Tensor& boxes = context->input(1);\n    const int64_t depth = images.dim_size(3);\n\n    OP_REQUIRES(context, images.dims() == 4,\n                errors::InvalidArgument(\"The rank of the images should be 4\"));\n    OP_REQUIRES(\n        context, boxes.dims() == 3,\n        errors::InvalidArgument(\"The rank of the boxes tensor should be 3\"));\n    OP_REQUIRES(context, images.dim_size(0) == boxes.dim_size(0),\n                errors::InvalidArgument(\"The batch sizes should be the same\"));\n\n    OP_REQUIRES(\n        context, depth == 4 || depth == 1 || depth == 3,\n        errors::InvalidArgument(\"Channel depth should be either 1 (GRY), \"\n                                \"3 (RGB), or 4 (RGBA)\"));\n\n    OP_REQUIRES(\n        context, boxes.dim_size(2) == 4,\n        errors::InvalidArgument(\n            \"The size of the third dimension of the box must be 4. Received: \",\n            boxes.dim_size(2)));\n\n    const int64_t batch_size = images.dim_size(0);\n    const int64_t height = images.dim_size(1);\n    const int64_t width = images.dim_size(2);\n    std::vector<std::vector<float>> color_table;\n    if (context->num_inputs() == 3) {\n      const Tensor& colors_tensor = context->input(2);\n      OP_REQUIRES(context, colors_tensor.shape().dims() == 2,\n                  errors::InvalidArgument(\"colors must be a 2-D matrix\",\n                                          colors_tensor.shape().DebugString()));\n      OP_REQUIRES(context, colors_tensor.shape().dim_size(1) >= depth,\n                  errors::InvalidArgument(\"colors must have equal or more \",\n                                          \"channels than the image provided: \",\n                                          colors_tensor.shape().DebugString()));\n      if (colors_tensor.NumElements() != 0) {\n        color_table.clear();\n\n        auto colors = colors_tensor.matrix<float>();\n        for (int64_t i = 0; i < colors.dimension(0); i++) {\n          std::vector<float> color_value(depth);\n          for (int64_t j = 0; j < depth; j++) {\n            color_value[j] = colors(i, j);\n          }\n          color_table.emplace_back(color_value);\n        }\n      }\n    }\n    if (color_table.empty()) {\n      color_table = DefaultColorTable(depth);\n    }\n    Tensor* output;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({batch_size, height, width, depth}), &output));\n\n    output->tensor<T, 4>() = images.tensor<T, 4>();\n    auto canvas = output->tensor<T, 4>();\n\n    for (int64_t b = 0; b < batch_size; ++b) {\n      const int64_t num_boxes = boxes.dim_size(1);\n      const auto tboxes = boxes.tensor<T, 3>();\n      for (int64_t bb = 0; bb < num_boxes; ++bb) {\n        int64_t color_index = bb % color_table.size();\n        const int64_t min_box_row =\n            static_cast<float>(tboxes(b, bb, 0)) * (height - 1);\n        const int64_t min_box_row_clamp =\n            std::max<int64_t>(min_box_row, int64_t{0});\n        const int64_t max_box_row =\n            static_cast<float>(tboxes(b, bb, 2)) * (height - 1);\n        const int64_t max_box_row_clamp =\n            std::min<int64_t>(max_box_row, height - 1);\n        const int64_t min_box_col =\n            static_cast<float>(tboxes(b, bb, 1)) * (width - 1);\n        const int64_t min_box_col_clamp =\n            std::max<int64_t>(min_box_col, int64_t{0});\n        const int64_t max_box_col =\n            static_cast<float>(tboxes(b, bb, 3)) * (width - 1);\n        const int64_t max_box_col_clamp =\n            std::min<int64_t>(max_box_col, width - 1);\n\n        if (min_box_row > max_box_row || min_box_col > max_box_col) {\n          LOG(WARNING) << \"Bounding box (\" << min_box_row << \",\" << min_box_col\n                       << \",\" << max_box_row << \",\" << max_box_col\n                       << \") is inverted and will not be drawn.\";\n          continue;\n        }\n        if (min_box_row >= height || max_box_row < 0 || min_box_col >= width ||\n            max_box_col < 0) {\n          LOG(WARNING) << \"Bounding box (\" << min_box_row << \",\" << min_box_col\n                       << \",\" << max_box_row << \",\" << max_box_col\n                       << \") is completely outside the image\"\n                       << \" and will not be drawn.\";\n          continue;\n        }\n\n        // At this point, {min,max}_box_{row,col}_clamp are inside the\n        // image.\n        OP_REQUIRES(\n            context, min_box_row_clamp >= 0,\n            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));\n        OP_REQUIRES(\n            context, max_box_row_clamp >= 0,\n            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));\n        OP_REQUIRES(context, min_box_row_clamp <= height,\n                    errors::InvalidArgument(\n                        \"Min box row clamp is greater than height.\"));\n        OP_REQUIRES(context, max_box_row_clamp <= height,\n                    errors::InvalidArgument(\n                        \"Max box row clamp is greater than height.\"));\n\n        OP_REQUIRES(\n            context, min_box_col_clamp >= 0,\n            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));\n        OP_REQUIRES(\n            context, max_box_col_clamp >= 0,\n            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));\n        OP_REQUIRES(context, min_box_col_clamp <= width,\n                    errors::InvalidArgument(\n                        \"Min box col clamp is greater than width.\"));\n        OP_REQUIRES(context, max_box_col_clamp <= width,\n                    errors::InvalidArgument(\n                        \"Max box col clamp is greater than width.\"));\n\n        // At this point, the min_box_row and min_box_col are either\n        // in the image or above/left of it, and max_box_row and\n        // max_box_col are either in the image or below/right or it.\n\n        OP_REQUIRES(\n            context, min_box_row <= height,\n            errors::InvalidArgument(\"Min box row is greater than height.\"));\n        OP_REQUIRES(context, max_box_row >= 0,\n                    errors::InvalidArgument(\"Max box row is less than 0.\"));\n        OP_REQUIRES(\n            context, min_box_col <= width,\n            errors::InvalidArgument(\"Min box col is greater than width.\"));\n        OP_REQUIRES(context, max_box_col >= 0,\n                    errors::InvalidArgument(\"Max box col is less than 0.\"));\n\n        // Draw top line.\n        if (min_box_row >= 0) {\n          for (int64_t j = min_box_col_clamp; j <= max_box_col_clamp; ++j)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, min_box_row, j, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n        // Draw bottom line.\n        if (max_box_row < height) {\n          for (int64_t j = min_box_col_clamp; j <= max_box_col_clamp; ++j)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, max_box_row, j, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n        // Draw left line.\n        if (min_box_col >= 0) {\n          for (int64_t i = min_box_row_clamp; i <= max_box_row_clamp; ++i)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, i, min_box_col, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n        // Draw right line.\n        if (max_box_col < width) {\n          for (int64_t i = min_box_row_clamp; i <= max_box_row_clamp; ++i)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, i, max_box_col, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n      }\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& images = context->input(0);\n    const Tensor& boxes = context->input(1);\n    const int64_t depth = images.dim_size(3);\n\n    OP_REQUIRES(context, images.dims() == 4,\n                errors::InvalidArgument(\"The rank of the images should be 4\"));\n    OP_REQUIRES(\n        context, boxes.dims() == 3,\n        errors::InvalidArgument(\"The rank of the boxes tensor should be 3\"));\n    OP_REQUIRES(context, images.dim_size(0) == boxes.dim_size(0),\n                errors::InvalidArgument(\"The batch sizes should be the same\"));\n\n    OP_REQUIRES(\n        context, depth == 4 || depth == 1 || depth == 3,\n        errors::InvalidArgument(\"Channel depth should be either 1 (GRY), \"\n                                \"3 (RGB), or 4 (RGBA)\"));\n\n    OP_REQUIRES(\n        context, boxes.dim_size(2) == 4,\n        errors::InvalidArgument(\n            \"The size of the third dimension of the box must be 4. Received: \",\n            boxes.dim_size(2)));\n\n    const int64_t batch_size = images.dim_size(0);\n    const int64_t height = images.dim_size(1);\n    const int64_t width = images.dim_size(2);\n    std::vector<std::vector<float>> color_table;\n    if (context->num_inputs() == 3) {\n      const Tensor& colors_tensor = context->input(2);\n      OP_REQUIRES(context, colors_tensor.shape().dims() == 2,\n                  errors::InvalidArgument(\"colors must be a 2-D matrix\",\n                                          colors_tensor.shape().DebugString()));\n      OP_REQUIRES(context, colors_tensor.shape().dim_size(1) >= depth,\n                  errors::InvalidArgument(\"colors must have equal or more \",\n                                          \"channels than the image provided: \",\n                                          colors_tensor.shape().DebugString()));\n      if (colors_tensor.NumElements() != 0) {\n        color_table.clear();\n\n        auto colors = colors_tensor.matrix<float>();\n        for (int64_t i = 0; i < colors.dimension(0); i++) {\n          std::vector<float> color_value(depth);\n          for (int64_t j = 0; j < depth; j++) {\n            color_value[j] = colors(i, j);\n          }\n          color_table.emplace_back(color_value);\n        }\n      }\n    }\n    if (color_table.empty()) {\n      color_table = DefaultColorTable(depth);\n    }\n    Tensor* output;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({batch_size, height, width, depth}), &output));\n\n    output->tensor<T, 4>() = images.tensor<T, 4>();\n    auto canvas = output->tensor<T, 4>();\n\n    for (int64_t b = 0; b < batch_size; ++b) {\n      const int64_t num_boxes = boxes.dim_size(1);\n      const auto tboxes = boxes.tensor<float, 3>();\n      for (int64_t bb = 0; bb < num_boxes; ++bb) {\n        int64_t color_index = bb % color_table.size();\n        const int64_t min_box_row =\n            static_cast<float>(tboxes(b, bb, 0)) * (height - 1);\n        const int64_t min_box_row_clamp =\n            std::max<int64_t>(min_box_row, int64_t{0});\n        const int64_t max_box_row =\n            static_cast<float>(tboxes(b, bb, 2)) * (height - 1);\n        const int64_t max_box_row_clamp =\n            std::min<int64_t>(max_box_row, height - 1);\n        const int64_t min_box_col =\n            static_cast<float>(tboxes(b, bb, 1)) * (width - 1);\n        const int64_t min_box_col_clamp =\n            std::max<int64_t>(min_box_col, int64_t{0});\n        const int64_t max_box_col =\n            static_cast<float>(tboxes(b, bb, 3)) * (width - 1);\n        const int64_t max_box_col_clamp =\n            std::min<int64_t>(max_box_col, width - 1);\n\n        if (min_box_row > max_box_row || min_box_col > max_box_col) {\n          LOG(WARNING) << \"Bounding box (\" << min_box_row << \",\" << min_box_col\n                       << \",\" << max_box_row << \",\" << max_box_col\n                       << \") is inverted and will not be drawn.\";\n          continue;\n        }\n        if (min_box_row >= height || max_box_row < 0 || min_box_col >= width ||\n            max_box_col < 0) {\n          LOG(WARNING) << \"Bounding box (\" << min_box_row << \",\" << min_box_col\n                       << \",\" << max_box_row << \",\" << max_box_col\n                       << \") is completely outside the image\"\n                       << \" and will not be drawn.\";\n          continue;\n        }\n\n        // At this point, {min,max}_box_{row,col}_clamp are inside the\n        // image.\n        OP_REQUIRES(\n            context, min_box_row_clamp >= 0,\n            errors::InvalidArgument(\"Min box row clamp is less than 0.\"));\n        OP_REQUIRES(\n            context, max_box_row_clamp >= 0,\n            errors::InvalidArgument(\"Max box row clamp is less than 0.\"));\n        OP_REQUIRES(context, min_box_row_clamp <= height,\n                    errors::InvalidArgument(\n                        \"Min box row clamp is greater than height.\"));\n        OP_REQUIRES(context, max_box_row_clamp <= height,\n                    errors::InvalidArgument(\n                        \"Max box row clamp is greater than height.\"));\n\n        OP_REQUIRES(\n            context, min_box_col_clamp >= 0,\n            errors::InvalidArgument(\"Min box col clamp is less than 0.\"));\n        OP_REQUIRES(\n            context, max_box_col_clamp >= 0,\n            errors::InvalidArgument(\"Max box col clamp is less than 0.\"));\n        OP_REQUIRES(context, min_box_col_clamp <= width,\n                    errors::InvalidArgument(\n                        \"Min box col clamp is greater than width.\"));\n        OP_REQUIRES(context, max_box_col_clamp <= width,\n                    errors::InvalidArgument(\n                        \"Max box col clamp is greater than width.\"));\n\n        // At this point, the min_box_row and min_box_col are either\n        // in the image or above/left of it, and max_box_row and\n        // max_box_col are either in the image or below/right or it.\n\n        OP_REQUIRES(\n            context, min_box_row <= height,\n            errors::InvalidArgument(\"Min box row is greater than height.\"));\n        OP_REQUIRES(context, max_box_row >= 0,\n                    errors::InvalidArgument(\"Max box row is less than 0.\"));\n        OP_REQUIRES(\n            context, min_box_col <= width,\n            errors::InvalidArgument(\"Min box col is greater than width.\"));\n        OP_REQUIRES(context, max_box_col >= 0,\n                    errors::InvalidArgument(\"Max box col is less than 0.\"));\n\n        // Draw top line.\n        if (min_box_row >= 0) {\n          for (int64_t j = min_box_col_clamp; j <= max_box_col_clamp; ++j)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, min_box_row, j, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n        // Draw bottom line.\n        if (max_box_row < height) {\n          for (int64_t j = min_box_col_clamp; j <= max_box_col_clamp; ++j)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, max_box_row, j, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n        // Draw left line.\n        if (min_box_col >= 0) {\n          for (int64_t i = min_box_row_clamp; i <= max_box_row_clamp; ++i)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, i, min_box_col, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n        // Draw right line.\n        if (max_box_col < width) {\n          for (int64_t i = min_box_row_clamp; i <= max_box_row_clamp; ++i)\n            for (int64_t c = 0; c < depth; c++) {\n              canvas(b, i, max_box_col, c) =\n                  static_cast<T>(color_table[color_index][c]);\n            }\n        }\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -62,7 +62,7 @@\n \n     for (int64_t b = 0; b < batch_size; ++b) {\n       const int64_t num_boxes = boxes.dim_size(1);\n-      const auto tboxes = boxes.tensor<T, 3>();\n+      const auto tboxes = boxes.tensor<float, 3>();\n       for (int64_t bb = 0; bb < num_boxes; ++bb) {\n         int64_t color_index = bb % color_table.size();\n         const int64_t min_box_row =",
        "diff_line_info": {
            "deleted_lines": [
                "      const auto tboxes = boxes.tensor<T, 3>();"
            ],
            "added_lines": [
                "      const auto tboxes = boxes.tensor<float, 3>();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36002",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `Unbatch` receives a nonscalar input `id`, it gives a `CHECK` fail that can trigger a denial of service attack. We have patched the issue in GitHub commit 4419d10d576adefa36b0e0a9425d2569f7c0189f. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/4419d10d576adefa36b0e0a9425d2569f7c0189f",
        "commit_title": "Fix check failure in Unbatch Op kernel by checking whether input argument is a scalar before trying to extract value.",
        "commit_text": " PiperOrigin-RevId: 461660186",
        "func_before": "Status Compute(OpKernelContext* context, AsyncOpKernel::DoneCallback done) {\n    const Tensor& data_t = context->input(0);\n    const Tensor& batch_index_t = context->input(1);\n\n    if (batch_index_t.shape().dim_size(0) > data_t.shape().dim_size(0)) {\n      return errors::InvalidArgument(\n          \"Wrong shape for index tensor. Expected 0th dimension size to be no \"\n          \"greater than \",\n          data_t.shape().dim_size(0),\n          \"; Got: \", batch_index_t.shape().dim_size(0), \".\");\n    }\n    if (batch_index_t.shape().dim_size(1) != 3) {\n      return errors::InvalidArgument(\n          \"Wrong shape for index tensor. Expected 1st dimension size to be 3 ; \"\n          \"Got: \",\n          batch_index_t.shape().dim_size(1), \".\");\n    }\n\n    const int64_t batch_key = context->input(2).scalar<int64_t>()();\n    const bool nonempty_input = batch_index_t.dim_size(0) > 0;\n\n    // If we have a non-empty tensor, slice it up.\n    // (It is important to do this outside of the critical section below.)\n    // The following variables are populated iff 'nonempty_input==true'.\n    std::vector<int64_t> sizes;\n    std::vector<int64_t> batch_keys;\n    std::vector<Tensor> split_inputs;\n    if (nonempty_input) {\n      auto batch_indices =\n          batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});\n      for (int i = 0; i < batch_index_t.dim_size(0); ++i) {\n        sizes.push_back(batch_indices(i, 2) - batch_indices(i, 1));\n        batch_keys.push_back(batch_indices(i, 0));\n      }\n\n      TF_RETURN_IF_ERROR(Split(context, data_t, sizes, &split_inputs));\n    }\n\n    // Critical section.\n    std::vector<AsyncOpKernel::DoneCallback> done_callbacks_to_call;\n    Status status = [&]() -> Status {\n      mutex_lock ml(mu_);\n\n      // Check to see whether the tensor we want is already ready.\n      auto tensor_it = waiting_tensors_.find(batch_key);\n      if (tensor_it != waiting_tensors_.end()) {\n        context->set_output(0, tensor_it->second.tensor);\n        waiting_tensors_.erase(tensor_it);\n        done_callbacks_to_call.push_back(done);\n        return OkStatus();\n      }\n\n      const uint64 deadline_micros =\n          Env::Default()->NowMicros() + timeout_micros_;\n\n      // Add ourselves to the waitlist for tensors.\n      if (!waiting_callbacks_\n               .emplace(batch_key,\n                        WaitingCallback{deadline_micros, context, done})\n               .second) {\n        return errors::AlreadyExists(\n            \"Multiple session runs with the same batch key.\");\n      }\n\n      // If we have a non-empty tensor, finish the waitlisted runs,\n      // and store any remaining pieces.\n      if (nonempty_input) {\n        for (size_t i = 0; i < batch_keys.size(); ++i) {\n          auto runs_it = waiting_callbacks_.find(batch_keys[i]);\n          if (runs_it != waiting_callbacks_.end()) {\n            runs_it->second.context->set_output(0, split_inputs[i]);\n            done_callbacks_to_call.push_back(runs_it->second.done);\n            waiting_callbacks_.erase(runs_it);\n          } else {\n            // Note: the deadline here is in case we are arriving late and the\n            // kernel that should rendezvous with this tensor has already waited\n            // and timed out.\n            if (!waiting_tensors_\n                     .emplace(batch_keys[i],\n                              WaitingTensor{deadline_micros, split_inputs[i]})\n                     .second) {\n              return errors::AlreadyExists(\n                  \"Multiple tensors returned for same batch key.\");\n            }\n          }\n        }\n      }\n\n      return OkStatus();\n    }();\n\n    for (const AsyncOpKernel::DoneCallback& done_callback :\n         done_callbacks_to_call) {\n      done_callback();\n    }\n\n    return status;\n  }",
        "func": "Status Compute(OpKernelContext* context, AsyncOpKernel::DoneCallback done) {\n    const Tensor& data_t = context->input(0);\n    const Tensor& batch_index_t = context->input(1);\n\n    if (batch_index_t.shape().dim_size(0) > data_t.shape().dim_size(0)) {\n      return errors::InvalidArgument(\n          \"Wrong shape for index tensor. Expected 0th dimension size to be no \"\n          \"greater than \",\n          data_t.shape().dim_size(0),\n          \"; Got: \", batch_index_t.shape().dim_size(0), \".\");\n    }\n    if (batch_index_t.shape().dim_size(1) != 3) {\n      return errors::InvalidArgument(\n          \"Wrong shape for index tensor. Expected 1st dimension size to be 3 ; \"\n          \"Got: \",\n          batch_index_t.shape().dim_size(1), \".\");\n    }\n\n    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {\n      return errors::InvalidArgument(\n          \"Input id should be scalar; \"\n          \"Got: \",\n          context->input(2).DebugString(), \".\");\n    }\n    const int64_t batch_key = context->input(2).scalar<int64_t>()();\n    const bool nonempty_input = batch_index_t.dim_size(0) > 0;\n\n    // If we have a non-empty tensor, slice it up.\n    // (It is important to do this outside of the critical section below.)\n    // The following variables are populated iff 'nonempty_input==true'.\n    std::vector<int64_t> sizes;\n    std::vector<int64_t> batch_keys;\n    std::vector<Tensor> split_inputs;\n    if (nonempty_input) {\n      auto batch_indices =\n          batch_index_t.shaped<int64_t, 2>({batch_index_t.dim_size(0), 3});\n      for (int i = 0; i < batch_index_t.dim_size(0); ++i) {\n        sizes.push_back(batch_indices(i, 2) - batch_indices(i, 1));\n        batch_keys.push_back(batch_indices(i, 0));\n      }\n\n      TF_RETURN_IF_ERROR(Split(context, data_t, sizes, &split_inputs));\n    }\n\n    // Critical section.\n    std::vector<AsyncOpKernel::DoneCallback> done_callbacks_to_call;\n    Status status = [&]() -> Status {\n      mutex_lock ml(mu_);\n\n      // Check to see whether the tensor we want is already ready.\n      auto tensor_it = waiting_tensors_.find(batch_key);\n      if (tensor_it != waiting_tensors_.end()) {\n        context->set_output(0, tensor_it->second.tensor);\n        waiting_tensors_.erase(tensor_it);\n        done_callbacks_to_call.push_back(done);\n        return OkStatus();\n      }\n\n      const uint64 deadline_micros =\n          Env::Default()->NowMicros() + timeout_micros_;\n\n      // Add ourselves to the waitlist for tensors.\n      if (!waiting_callbacks_\n               .emplace(batch_key,\n                        WaitingCallback{deadline_micros, context, done})\n               .second) {\n        return errors::AlreadyExists(\n            \"Multiple session runs with the same batch key.\");\n      }\n\n      // If we have a non-empty tensor, finish the waitlisted runs,\n      // and store any remaining pieces.\n      if (nonempty_input) {\n        for (size_t i = 0; i < batch_keys.size(); ++i) {\n          auto runs_it = waiting_callbacks_.find(batch_keys[i]);\n          if (runs_it != waiting_callbacks_.end()) {\n            runs_it->second.context->set_output(0, split_inputs[i]);\n            done_callbacks_to_call.push_back(runs_it->second.done);\n            waiting_callbacks_.erase(runs_it);\n          } else {\n            // Note: the deadline here is in case we are arriving late and the\n            // kernel that should rendezvous with this tensor has already waited\n            // and timed out.\n            if (!waiting_tensors_\n                     .emplace(batch_keys[i],\n                              WaitingTensor{deadline_micros, split_inputs[i]})\n                     .second) {\n              return errors::AlreadyExists(\n                  \"Multiple tensors returned for same batch key.\");\n            }\n          }\n        }\n      }\n\n      return OkStatus();\n    }();\n\n    for (const AsyncOpKernel::DoneCallback& done_callback :\n         done_callbacks_to_call) {\n      done_callback();\n    }\n\n    return status;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,6 +16,12 @@\n           batch_index_t.shape().dim_size(1), \".\");\n     }\n \n+    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {\n+      return errors::InvalidArgument(\n+          \"Input id should be scalar; \"\n+          \"Got: \",\n+          context->input(2).DebugString(), \".\");\n+    }\n     const int64_t batch_key = context->input(2).scalar<int64_t>()();\n     const bool nonempty_input = batch_index_t.dim_size(0) > 0;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (!TensorShapeUtils::IsScalar(context->input(2).shape())) {",
                "      return errors::InvalidArgument(",
                "          \"Input id should be scalar; \"",
                "          \"Got: \",",
                "          context->input(2).DebugString(), \".\");",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36003",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. When `RandomPoissonV2` receives large input shape and rates, it gives a `CHECK` fail that can trigger a denial of service attack. We have patched the issue in GitHub commit 552bfced6ce4809db5f3ca305f60ff80dd40c5a3. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/552bfced6ce4809db5f3ca305f60ff80dd40c5a3",
        "commit_title": "Fix size check for large input shape and rates.",
        "commit_text": " To address a check failure for exceedingly large output shapes, we need to `AppendShapeWithStatus`.  PiperOrigin-RevId: 462885894",
        "func_before": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& shape_t = ctx->input(0);\n    const Tensor& rate_t = ctx->input(1);\n\n    TensorShape samples_shape;\n    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));\n    const int64_t num_samples = samples_shape.num_elements();\n\n    samples_shape.AppendShape(rate_t.shape());\n    // Allocate output samples.\n    Tensor* samples_t = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n    if (num_samples == 0) return;\n\n    const auto rate_flat = rate_t.flat<T>().data();\n    const int64_t num_rate = rate_t.NumElements();\n    auto samples_flat = samples_t->flat<U>().data();\n    random::PhiloxRandom rng = generator_.ReserveRandomOutputs(\n        num_samples * num_rate, kReservedSamplesPerOutput);\n\n    functor::PoissonFunctor<CPUDevice, T, U>()(\n        ctx, ctx->eigen_device<CPUDevice>(), rate_flat, num_rate, num_samples,\n        rng, samples_flat);\n  }",
        "func": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& shape_t = ctx->input(0);\n    const Tensor& rate_t = ctx->input(1);\n\n    TensorShape samples_shape;\n    OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));\n    const int64_t num_samples = samples_shape.num_elements();\n    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));\n\n    // Allocate output samples.\n    Tensor* samples_t = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));\n    if (num_samples == 0) return;\n\n    const auto rate_flat = rate_t.flat<T>().data();\n    const int64_t num_rate = rate_t.NumElements();\n    auto samples_flat = samples_t->flat<U>().data();\n    random::PhiloxRandom rng = generator_.ReserveRandomOutputs(\n        num_samples * num_rate, kReservedSamplesPerOutput);\n\n    functor::PoissonFunctor<CPUDevice, T, U>()(\n        ctx, ctx->eigen_device<CPUDevice>(), rate_flat, num_rate, num_samples,\n        rng, samples_flat);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,8 +5,8 @@\n     TensorShape samples_shape;\n     OP_REQUIRES_OK(ctx, tensor::MakeShape(shape_t, &samples_shape));\n     const int64_t num_samples = samples_shape.num_elements();\n+    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));\n \n-    samples_shape.AppendShape(rate_t.shape());\n     // Allocate output samples.\n     Tensor* samples_t = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, samples_shape, &samples_t));",
        "diff_line_info": {
            "deleted_lines": [
                "    samples_shape.AppendShape(rate_t.shape());"
            ],
            "added_lines": [
                "    OP_REQUIRES_OK(ctx, samples_shape.AppendShapeWithStatus(rate_t.shape()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36012",
        "func_name": "tensorflow/ImportGenericFunction",
        "description": "TensorFlow is an open source platform for machine learning. When `mlir::tfg::ConvertGenericFunctionToFunctionDef` is given empty function attributes, it crashes. We have patched the issue in GitHub commit ad069af92392efee1418c48ff561fd3070a03d7b. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ad069af92392efee1418c48ff561fd3070a03d7b",
        "commit_title": "[tfg][functiondef_import] Error on empty edge names",
        "commit_text": " Return an error in the generic function importer if an edge name is empty.  PiperOrigin-RevId: 449953062",
        "func_before": "Status ImportGenericFunction(\n    GraphFuncOp func_op, const FunctionDef& func,\n    llvm::StringMap<llvm::StringMap<SmallVector<Value, 1>>>& values_map,\n    OpBuilder& builder) {\n  const OpDef& signature = func.signature();\n  Location unknown_loc = builder.getUnknownLoc();\n  MLIRContext* context = builder.getContext();\n\n  TFGraphDialect* tfgDialect = cast<TFGraphDialect>(func_op->getDialect());\n  NamedAttrList attrs;\n  DictionaryAttr func_attrs = builder.getDictionaryAttr({});\n  if (signature.name().empty())\n    return InvalidArgument(\"generic function without a name\");\n  attrs.append(\"sym_name\", builder.getStringAttr(signature.name()));\n  attrs.append(\"generic\", builder.getUnitAttr());\n  if (!signature.description().empty())\n    attrs.append(\"description\", builder.getStringAttr(signature.description()));\n  if (signature.is_stateful())\n    attrs.append(\"is_stateful\", builder.getUnitAttr());\n  if (signature.control_output_size()) {\n    SmallVector<Attribute> control_outputs;\n    for (const std::string& output : signature.control_output())\n      control_outputs.push_back(builder.getStringAttr(output));\n    attrs.append(\"control_output\", builder.getArrayAttr(control_outputs));\n  }\n  {\n    NamedAttrList attr_defs;\n    for (const OpDef_AttrDef& attr : signature.attr()) {\n      NamedAttrList attr_def;\n      if (attr.name().empty())\n        return InvalidArgument(\"Missing name for function attribute\");\n      if (!attr.type().empty())\n        attr_def.append(builder.getNamedAttr(\n            \"function_type\", builder.getStringAttr(attr.type())));\n      if (attr.has_default_value()) {\n        TF_ASSIGN_OR_RETURN(\n            Attribute attr,\n            ConvertAttributeValue(attr.default_value(), builder, tfgDialect));\n        attr_def.append(builder.getNamedAttr(\"default_value\", attr));\n      }\n      if (!attr.description().empty())\n        attr_def.append(builder.getNamedAttr(\n            \"description\", builder.getStringAttr(attr.description())));\n      if (attr.has_minimum() || attr.minimum())\n        attr_def.append(builder.getNamedAttr(\n            \"minimum\", builder.getI32IntegerAttr(attr.minimum())));\n      if (attr.has_allowed_values()) {\n        TF_ASSIGN_OR_RETURN(\n            Attribute attr,\n            ConvertAttributeValue(attr.allowed_values(), builder, tfgDialect));\n        attr_def.append(builder.getNamedAttr(\"allowed_values\", attr));\n      }\n      attr_defs.append(builder.getNamedAttr(\n          attr.name(), attr_def.getDictionary(builder.getContext())));\n    }\n    if (!attr_defs.empty()) {\n      func_attrs = attr_defs.getDictionary(builder.getContext());\n      attrs.append(\"tfg.func_attrs\", func_attrs);\n    }\n  }\n\n  // The resource_arg_unique_id is a list of `pair<int, int>`, we import it\n  // as two arrays of integer right now.\n  if (func.resource_arg_unique_id_size()) {\n    SmallVector<int32_t> resource_arg_unique_ids_keys;\n    SmallVector<int32_t> resource_arg_unique_ids_values;\n    for (const auto& unique_id : func.resource_arg_unique_id()) {\n      resource_arg_unique_ids_keys.push_back(unique_id.first);\n      resource_arg_unique_ids_values.push_back(unique_id.second);\n    }\n    attrs.append(\"resource_arg_unique_ids_keys\",\n                 builder.getI32TensorAttr(resource_arg_unique_ids_keys));\n    attrs.append(\"resource_arg_unique_ids_values\",\n                 builder.getI32TensorAttr(resource_arg_unique_ids_values));\n  }\n\n  // Import the function attributes with a `tf.` prefix to match the current\n  // infrastructure expectations.\n  for (const auto& namedAttr : func.attr()) {\n    if (namedAttr.first.empty())\n      return InvalidArgument(\"Invalid function attribute name\");\n    const std::string& name = \"tf.\" + namedAttr.first;\n    const AttrValue& tf_attr = namedAttr.second;\n    TF_ASSIGN_OR_RETURN(Attribute attr,\n                        ConvertAttributeValue(tf_attr, builder, tfgDialect));\n    attrs.append(name, attr);\n  }\n  SmallString<8> arg_or_res_attr_name;\n  SmallString<8> sub_arg_attr_name;\n  // Iterate of the input in the signature. Each input will correspond to\n  // potentially multiple arguments because of how the OpDef allows repeated\n  // arguments controlled by `number_attr` for example.\n  // We populate the `arg_names` vector with the name of each input at each\n  // position, and `arg_types` with the matching type.\n  int arg_num = 0;\n  SmallVector<StringRef> arg_names;\n  SmallVector<Type> arg_types;\n  SmallVector<Attribute> args_attrs;\n  SmallVector<Attribute> res_attrs;\n  for (const auto& enumerated_input : llvm::enumerate(signature.input_arg())) {\n    const OpDef::ArgDef& input = enumerated_input.value();\n    TF_ASSIGN_OR_RETURN(NamedAttrList input_attrs,\n                        ConvertArgDefAttributes(input, tfgDialect, builder));\n    auto it = func.arg_attr().find(enumerated_input.index());\n    if (it != func.arg_attr().end()) {\n      NamedAttrList arg_attr;\n      for (const auto& named_attr : it->second.attr()) {\n        TF_ASSIGN_OR_RETURN(\n            Attribute attr,\n            ConvertAttributeValue(named_attr.second, builder, tfgDialect));\n        arg_attr.append(named_attr.first, attr);\n      }\n      input_attrs.append(\"tfg.arg_attrs\",\n                         arg_attr.getDictionary(builder.getContext()));\n    }\n    arg_names.push_back(builder.getStringAttr(input.name()).getValue());\n    arg_types.push_back(OpaqueTensorType::get(context));\n    args_attrs.push_back(input_attrs.getDictionary(context));\n    args_attrs.push_back(NamedAttrList{}.getDictionary(context));\n    arg_num++;\n  }\n  attrs.push_back(\n      builder.getNamedAttr(function_interface_impl::getArgDictAttrName(),\n                           builder.getArrayAttr(args_attrs)));\n\n  // Process the results attributes now.\n  int res_num = 0;\n  for (const OpDef::ArgDef& output : signature.output_arg()) {\n    TF_ASSIGN_OR_RETURN(NamedAttrList output_attrs,\n                        ConvertArgDefAttributes(output, tfgDialect, builder));\n    res_attrs.push_back(output_attrs.getDictionary(context));\n    ++res_num;\n  }\n  // Process the control output metadata and store them as attributes.\n  for (const std::string& output : signature.control_output()) {\n    NamedAttrList output_attrs;\n    output_attrs.append(\"tfg.name\", builder.getStringAttr(output));\n    res_attrs.push_back(output_attrs.getDictionary(context));\n    ++res_num;\n  }\n  attrs.push_back(\n      builder.getNamedAttr(function_interface_impl::getResultDictAttrName(),\n                           builder.getArrayAttr(res_attrs)));\n\n  values_map.clear();\n  Block* body = new Block();\n  func_op.body().push_back(body);\n  Type control_ty = ControlType::get(context);\n  // Create the block arguments and populate the `values_map` with the matching\n  // input names.\n  for (auto type_and_name : llvm::zip(arg_types, arg_names)) {\n    Value arg = body->addArgument(std::get<0>(type_and_name), unknown_loc);\n    llvm::StringMap<SmallVector<Value, 1>>& values =\n        values_map[std::get<1>(type_and_name)];\n    Value ctl = body->addArgument(control_ty, unknown_loc);\n    values[\"\"].push_back(arg);\n    values[\"^\"].push_back(ctl);\n  }\n\n  // Pre-populate the nodes_map with the needed slots for the return.\n  OpBuilder body_builder = OpBuilder::atBlockEnd(body);\n  // We use placeholders during the import to create \"fake\" operations to break\n  // cycles: we need operands to feed to the users.\n  OperationName mlir_placeholder(\"tfg.__mlir_placeholder\", context);\n  Type placeholder_ty = OpaqueTensorType::get(context);\n  ValueMapManager value_manager(values_map, body_builder, mlir_placeholder,\n                                placeholder_ty, control_ty, unknown_loc);\n\n  // Import the function body here, after this we have a function with all\n  // the nodes, and the nodes_map contains the mapping from node_name to actual\n  // MLIR Operations.\n  TF_RETURN_WITH_CONTEXT_IF_ERROR(\n      ImportNodes(value_manager, func.node_def(), body_builder),\n      \" when importing function \", func.signature().name());\n\n  // After the body, the final part is to setup the return. It comes in two\n  // parts: the `ret` field from the FunctionDef for the regular output and the\n  // `control_ret` field for the control output.\n  //\n  // Because `ret` and `control_ret` aren't ordered, there is an indirection to\n  // the FunctionDef signature to retrieve the position of each `ret` and\n  // `control_ret` entry by name. We compute this mapping from the name of an\n  // output to the position in the result array first.\n  res_num = 0;\n  llvm::StringMap<int> output_name_to_position;\n  for (const OpDef::ArgDef& output : signature.output_arg()) {\n    if (output_name_to_position.count(output.name()))\n      return InvalidArgument(\"Duplicated output_arg entry\", output.name());\n    output_name_to_position[output.name()] = res_num;\n    ++res_num;\n  }\n  res_num = 0;\n  llvm::StringMap<int> control_output_to_position;\n  for (const std::string& output : signature.control_output()) {\n    if (control_output_to_position.count(output))\n      return InvalidArgument(\"Duplicated control_output entry\", output);\n    control_output_to_position[output] = res_num;\n    ++res_num;\n  }\n\n  // We pre-allocate the array of operands and populate it using the\n  // `output_name_to_position` and `control_output_to_position` populated\n  // previously.\n  SmallVector<Value> ret_vals(func.ret_size() + func.control_ret_size(),\n                              Value());\n  for (const auto& ret_val : func.ret()) {\n    auto position = output_name_to_position.find(ret_val.first);\n    if (position == output_name_to_position.end())\n      return InvalidArgument(\n          \"Can't import function, returned value references unknown output \"\n          \"argument \",\n          ret_val.first);\n    ret_vals[position->second] =\n        value_manager.GetValueOrCreatePlaceholder(ret_val.second);\n  }\n  for (const auto& ret_val : func.control_ret()) {\n    auto position = control_output_to_position.find(ret_val.first);\n    if (position == control_output_to_position.end())\n      return InvalidArgument(\n          \"Can't import function, returned value references unknown output \"\n          \"argument \",\n          ret_val.first);\n    Value result = value_manager.GetValueOrCreatePlaceholder(\n        (Twine(\"^\") + ret_val.second).str());\n    if (!result.getType().isa<ControlType>())\n      return InvalidArgument(\"failed to map returned value \", ret_val.second,\n                             \", isn't a control output\");\n    ret_vals[func.ret_size() + position->second] = result;\n  }\n  // Check that all the of the return operands have been populated.\n  for (auto& indexed_val : llvm::enumerate(ret_vals)) {\n    if (indexed_val.value()) continue;\n    return InvalidArgument(\n        \"Failed to import function, missing output for position \",\n        indexed_val.index());\n  }\n  MutableArrayRef<Value> operands = ret_vals;\n  ReturnOp ret_op = body_builder.create<ReturnOp>(\n      unknown_loc, operands.slice(0, func.ret_size()),\n      operands.slice(func.ret_size()));\n\n  // Now that we have all the types, set the function signature as the\n  // \"function_type\" attribute.\n  {\n    SmallVector<Type> arg_types_with_ctl;\n    for (Type type : arg_types) {\n      arg_types_with_ctl.push_back(type);\n      arg_types_with_ctl.push_back(control_ty);\n    }\n    attrs.append(\"function_type\",\n                 TypeAttr::get(builder.getFunctionType(\n                     arg_types_with_ctl, ret_op.getOperandTypes())));\n  }\n  func_op->setAttrs(attrs);\n  return Status::OK();\n}",
        "func": "Status ImportGenericFunction(\n    GraphFuncOp func_op, const FunctionDef& func,\n    llvm::StringMap<llvm::StringMap<SmallVector<Value, 1>>>& values_map,\n    OpBuilder& builder) {\n  const OpDef& signature = func.signature();\n  Location unknown_loc = builder.getUnknownLoc();\n  MLIRContext* context = builder.getContext();\n\n  TFGraphDialect* tfgDialect = cast<TFGraphDialect>(func_op->getDialect());\n  NamedAttrList attrs;\n  DictionaryAttr func_attrs = builder.getDictionaryAttr({});\n  if (signature.name().empty())\n    return InvalidArgument(\"generic function without a name\");\n  attrs.append(\"sym_name\", builder.getStringAttr(signature.name()));\n  attrs.append(\"generic\", builder.getUnitAttr());\n  if (!signature.description().empty())\n    attrs.append(\"description\", builder.getStringAttr(signature.description()));\n  if (signature.is_stateful())\n    attrs.append(\"is_stateful\", builder.getUnitAttr());\n  if (signature.control_output_size()) {\n    SmallVector<Attribute> control_outputs;\n    for (const std::string& output : signature.control_output())\n      control_outputs.push_back(builder.getStringAttr(output));\n    attrs.append(\"control_output\", builder.getArrayAttr(control_outputs));\n  }\n  {\n    NamedAttrList attr_defs;\n    for (const OpDef_AttrDef& attr : signature.attr()) {\n      NamedAttrList attr_def;\n      if (attr.name().empty())\n        return InvalidArgument(\"Missing name for function attribute\");\n      if (!attr.type().empty())\n        attr_def.append(builder.getNamedAttr(\n            \"function_type\", builder.getStringAttr(attr.type())));\n      if (attr.has_default_value()) {\n        TF_ASSIGN_OR_RETURN(\n            Attribute attr,\n            ConvertAttributeValue(attr.default_value(), builder, tfgDialect));\n        attr_def.append(builder.getNamedAttr(\"default_value\", attr));\n      }\n      if (!attr.description().empty())\n        attr_def.append(builder.getNamedAttr(\n            \"description\", builder.getStringAttr(attr.description())));\n      if (attr.has_minimum() || attr.minimum())\n        attr_def.append(builder.getNamedAttr(\n            \"minimum\", builder.getI32IntegerAttr(attr.minimum())));\n      if (attr.has_allowed_values()) {\n        TF_ASSIGN_OR_RETURN(\n            Attribute attr,\n            ConvertAttributeValue(attr.allowed_values(), builder, tfgDialect));\n        attr_def.append(builder.getNamedAttr(\"allowed_values\", attr));\n      }\n      attr_defs.append(builder.getNamedAttr(\n          attr.name(), attr_def.getDictionary(builder.getContext())));\n    }\n    if (!attr_defs.empty()) {\n      func_attrs = attr_defs.getDictionary(builder.getContext());\n      attrs.append(\"tfg.func_attrs\", func_attrs);\n    }\n  }\n\n  // The resource_arg_unique_id is a list of `pair<int, int>`, we import it\n  // as two arrays of integer right now.\n  if (func.resource_arg_unique_id_size()) {\n    SmallVector<int32_t> resource_arg_unique_ids_keys;\n    SmallVector<int32_t> resource_arg_unique_ids_values;\n    for (const auto& unique_id : func.resource_arg_unique_id()) {\n      resource_arg_unique_ids_keys.push_back(unique_id.first);\n      resource_arg_unique_ids_values.push_back(unique_id.second);\n    }\n    attrs.append(\"resource_arg_unique_ids_keys\",\n                 builder.getI32TensorAttr(resource_arg_unique_ids_keys));\n    attrs.append(\"resource_arg_unique_ids_values\",\n                 builder.getI32TensorAttr(resource_arg_unique_ids_values));\n  }\n\n  // Import the function attributes with a `tf.` prefix to match the current\n  // infrastructure expectations.\n  for (const auto& namedAttr : func.attr()) {\n    if (namedAttr.first.empty())\n      return InvalidArgument(\"Invalid function attribute name\");\n    const std::string& name = \"tf.\" + namedAttr.first;\n    const AttrValue& tf_attr = namedAttr.second;\n    TF_ASSIGN_OR_RETURN(Attribute attr,\n                        ConvertAttributeValue(tf_attr, builder, tfgDialect));\n    attrs.append(name, attr);\n  }\n  SmallString<8> arg_or_res_attr_name;\n  SmallString<8> sub_arg_attr_name;\n  // Iterate of the input in the signature. Each input will correspond to\n  // potentially multiple arguments because of how the OpDef allows repeated\n  // arguments controlled by `number_attr` for example.\n  // We populate the `arg_names` vector with the name of each input at each\n  // position, and `arg_types` with the matching type.\n  int arg_num = 0;\n  SmallVector<StringRef> arg_names;\n  SmallVector<Type> arg_types;\n  SmallVector<Attribute> args_attrs;\n  SmallVector<Attribute> res_attrs;\n  for (const auto& enumerated_input : llvm::enumerate(signature.input_arg())) {\n    const OpDef::ArgDef& input = enumerated_input.value();\n    TF_ASSIGN_OR_RETURN(NamedAttrList input_attrs,\n                        ConvertArgDefAttributes(input, tfgDialect, builder));\n    auto it = func.arg_attr().find(enumerated_input.index());\n    if (it != func.arg_attr().end()) {\n      NamedAttrList arg_attr;\n      for (const auto& named_attr : it->second.attr()) {\n        TF_ASSIGN_OR_RETURN(\n            Attribute attr,\n            ConvertAttributeValue(named_attr.second, builder, tfgDialect));\n        arg_attr.append(named_attr.first, attr);\n      }\n      input_attrs.append(\"tfg.arg_attrs\",\n                         arg_attr.getDictionary(builder.getContext()));\n    }\n    arg_names.push_back(builder.getStringAttr(input.name()).getValue());\n    arg_types.push_back(OpaqueTensorType::get(context));\n    args_attrs.push_back(input_attrs.getDictionary(context));\n    args_attrs.push_back(NamedAttrList{}.getDictionary(context));\n    arg_num++;\n  }\n  attrs.push_back(\n      builder.getNamedAttr(function_interface_impl::getArgDictAttrName(),\n                           builder.getArrayAttr(args_attrs)));\n\n  // Process the results attributes now.\n  int res_num = 0;\n  for (const OpDef::ArgDef& output : signature.output_arg()) {\n    TF_ASSIGN_OR_RETURN(NamedAttrList output_attrs,\n                        ConvertArgDefAttributes(output, tfgDialect, builder));\n    res_attrs.push_back(output_attrs.getDictionary(context));\n    ++res_num;\n  }\n  // Process the control output metadata and store them as attributes.\n  for (const std::string& output : signature.control_output()) {\n    NamedAttrList output_attrs;\n    output_attrs.append(\"tfg.name\", builder.getStringAttr(output));\n    res_attrs.push_back(output_attrs.getDictionary(context));\n    ++res_num;\n  }\n  attrs.push_back(\n      builder.getNamedAttr(function_interface_impl::getResultDictAttrName(),\n                           builder.getArrayAttr(res_attrs)));\n\n  values_map.clear();\n  Block* body = new Block();\n  func_op.body().push_back(body);\n  Type control_ty = ControlType::get(context);\n  // Create the block arguments and populate the `values_map` with the matching\n  // input names.\n  for (auto type_and_name : llvm::zip(arg_types, arg_names)) {\n    Value arg = body->addArgument(std::get<0>(type_and_name), unknown_loc);\n    llvm::StringMap<SmallVector<Value, 1>>& values =\n        values_map[std::get<1>(type_and_name)];\n    Value ctl = body->addArgument(control_ty, unknown_loc);\n    values[\"\"].push_back(arg);\n    values[\"^\"].push_back(ctl);\n  }\n\n  // Pre-populate the nodes_map with the needed slots for the return.\n  OpBuilder body_builder = OpBuilder::atBlockEnd(body);\n  // We use placeholders during the import to create \"fake\" operations to break\n  // cycles: we need operands to feed to the users.\n  OperationName mlir_placeholder(\"tfg.__mlir_placeholder\", context);\n  Type placeholder_ty = OpaqueTensorType::get(context);\n  ValueMapManager value_manager(values_map, body_builder, mlir_placeholder,\n                                placeholder_ty, control_ty, unknown_loc);\n\n  // Import the function body here, after this we have a function with all\n  // the nodes, and the nodes_map contains the mapping from node_name to actual\n  // MLIR Operations.\n  TF_RETURN_WITH_CONTEXT_IF_ERROR(\n      ImportNodes(value_manager, func.node_def(), body_builder),\n      \" when importing function \", func.signature().name());\n\n  // After the body, the final part is to setup the return. It comes in two\n  // parts: the `ret` field from the FunctionDef for the regular output and the\n  // `control_ret` field for the control output.\n  //\n  // Because `ret` and `control_ret` aren't ordered, there is an indirection to\n  // the FunctionDef signature to retrieve the position of each `ret` and\n  // `control_ret` entry by name. We compute this mapping from the name of an\n  // output to the position in the result array first.\n  res_num = 0;\n  llvm::StringMap<int> output_name_to_position;\n  for (const OpDef::ArgDef& output : signature.output_arg()) {\n    if (output_name_to_position.count(output.name()))\n      return InvalidArgument(\"Duplicated output_arg entry\", output.name());\n    output_name_to_position[output.name()] = res_num;\n    ++res_num;\n  }\n  res_num = 0;\n  llvm::StringMap<int> control_output_to_position;\n  for (const std::string& output : signature.control_output()) {\n    if (control_output_to_position.count(output))\n      return InvalidArgument(\"Duplicated control_output entry\", output);\n    control_output_to_position[output] = res_num;\n    ++res_num;\n  }\n\n  // We pre-allocate the array of operands and populate it using the\n  // `output_name_to_position` and `control_output_to_position` populated\n  // previously.\n  SmallVector<Value> ret_vals(func.ret_size() + func.control_ret_size(),\n                              Value());\n  for (const auto& ret_val : func.ret()) {\n    auto position = output_name_to_position.find(ret_val.first);\n    if (position == output_name_to_position.end()) {\n      return InvalidArgument(\n          \"Can't import function, returned value references unknown output \"\n          \"argument \",\n          ret_val.first);\n    }\n    if (ret_val.second.empty()) {\n      return InvalidArgument(\"Function '\", func.signature().name(),\n                             \"' has empty result name\");\n    }\n    ret_vals[position->second] =\n        value_manager.GetValueOrCreatePlaceholder(ret_val.second);\n  }\n  for (const auto& ret_val : func.control_ret()) {\n    auto position = control_output_to_position.find(ret_val.first);\n    if (position == control_output_to_position.end()) {\n      return InvalidArgument(\n          \"Can't import function, returned value references unknown output \"\n          \"argument \",\n          ret_val.first);\n    }\n    if (ret_val.second.empty()) {\n      return InvalidArgument(\"Function '\", func.signature().name(),\n                             \"' has empty control result name\");\n    }\n    Value result = value_manager.GetValueOrCreatePlaceholder(\n        (Twine(\"^\") + ret_val.second).str());\n    if (!result.getType().isa<ControlType>())\n      return InvalidArgument(\"failed to map returned value \", ret_val.second,\n                             \", isn't a control output\");\n    ret_vals[func.ret_size() + position->second] = result;\n  }\n  // Check that all the of the return operands have been populated.\n  for (auto& indexed_val : llvm::enumerate(ret_vals)) {\n    if (indexed_val.value()) continue;\n    return InvalidArgument(\n        \"Failed to import function, missing output for position \",\n        indexed_val.index());\n  }\n  MutableArrayRef<Value> operands = ret_vals;\n  ReturnOp ret_op = body_builder.create<ReturnOp>(\n      unknown_loc, operands.slice(0, func.ret_size()),\n      operands.slice(func.ret_size()));\n\n  // Now that we have all the types, set the function signature as the\n  // \"function_type\" attribute.\n  {\n    SmallVector<Type> arg_types_with_ctl;\n    for (Type type : arg_types) {\n      arg_types_with_ctl.push_back(type);\n      arg_types_with_ctl.push_back(control_ty);\n    }\n    attrs.append(\"function_type\",\n                 TypeAttr::get(builder.getFunctionType(\n                     arg_types_with_ctl, ret_op.getOperandTypes())));\n  }\n  func_op->setAttrs(attrs);\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -205,21 +205,31 @@\n                               Value());\n   for (const auto& ret_val : func.ret()) {\n     auto position = output_name_to_position.find(ret_val.first);\n-    if (position == output_name_to_position.end())\n+    if (position == output_name_to_position.end()) {\n       return InvalidArgument(\n           \"Can't import function, returned value references unknown output \"\n           \"argument \",\n           ret_val.first);\n+    }\n+    if (ret_val.second.empty()) {\n+      return InvalidArgument(\"Function '\", func.signature().name(),\n+                             \"' has empty result name\");\n+    }\n     ret_vals[position->second] =\n         value_manager.GetValueOrCreatePlaceholder(ret_val.second);\n   }\n   for (const auto& ret_val : func.control_ret()) {\n     auto position = control_output_to_position.find(ret_val.first);\n-    if (position == control_output_to_position.end())\n+    if (position == control_output_to_position.end()) {\n       return InvalidArgument(\n           \"Can't import function, returned value references unknown output \"\n           \"argument \",\n           ret_val.first);\n+    }\n+    if (ret_val.second.empty()) {\n+      return InvalidArgument(\"Function '\", func.signature().name(),\n+                             \"' has empty control result name\");\n+    }\n     Value result = value_manager.GetValueOrCreatePlaceholder(\n         (Twine(\"^\") + ret_val.second).str());\n     if (!result.getType().isa<ControlType>())",
        "diff_line_info": {
            "deleted_lines": [
                "    if (position == output_name_to_position.end())",
                "    if (position == control_output_to_position.end())"
            ],
            "added_lines": [
                "    if (position == output_name_to_position.end()) {",
                "    }",
                "    if (ret_val.second.empty()) {",
                "      return InvalidArgument(\"Function '\", func.signature().name(),",
                "                             \"' has empty result name\");",
                "    }",
                "    if (position == control_output_to_position.end()) {",
                "    }",
                "    if (ret_val.second.empty()) {",
                "      return InvalidArgument(\"Function '\", func.signature().name(),",
                "                             \"' has empty control result name\");",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36012",
        "func_name": "tensorflow/ImportNodes",
        "description": "TensorFlow is an open source platform for machine learning. When `mlir::tfg::ConvertGenericFunctionToFunctionDef` is given empty function attributes, it crashes. We have patched the issue in GitHub commit ad069af92392efee1418c48ff561fd3070a03d7b. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ad069af92392efee1418c48ff561fd3070a03d7b",
        "commit_title": "[tfg][functiondef_import] Error on empty edge names",
        "commit_text": " Return an error in the generic function importer if an edge name is empty.  PiperOrigin-RevId: 449953062",
        "func_before": "Status ImportNodes(ValueMapManager value_manager,\n                   const RepeatedPtrField<NodeDef>& nodes, OpBuilder& builder) {\n  Location unknown_loc = builder.getUnknownLoc();\n  MLIRContext* context = builder.getContext();\n\n  Type placeholder_ty = OpaqueTensorType::get(context);\n  Type control_ty = ControlType::get(context);\n  TFGraphDialect* tfgDialect =\n      cast<TFGraphDialect>(context->getLoadedDialect(\"tfg\"));\n  StringAttr device_attr = tfgDialect->getDeviceAttrIdentifier();\n  StringAttr name_attr = tfgDialect->getNameAttrIdentifier();\n  StringAttr fulltype_attr = tfgDialect->getFullTypeAttrIdentifier();\n  // Process every node and create a matching MLIR operation\n  for (const NodeDef& node : nodes) {\n    DVLOG(1) << \"Processing node \" << node.name() << \"\\n\";\n    if (node.op().empty()) return InvalidArgument(\"empty op type\");\n    OperationState state(unknown_loc, absl::StrCat(\"tfg.\", node.op()));\n    // Fetch the inputs, creating placeholder if an input hasn't been visited.\n    for (const std::string& input : node.input())\n      state.operands.push_back(\n          value_manager.GetValueOrCreatePlaceholder(input));\n    // Retrieve the entry in the nodes_map for this node and infer the result\n    // count from what was inferred during the first traversal above.\n    state.types.push_back(placeholder_ty);\n    state.types.push_back(control_ty);\n    // Handle attributes.\n    for (const auto& namedAttr : node.attr()) {\n      const std::string& name = namedAttr.first;\n      const AttrValue& tf_attr = namedAttr.second;\n      TF_ASSIGN_OR_RETURN(Attribute attr,\n                          ConvertAttributeValue(tf_attr, builder, tfgDialect));\n      state.addAttribute(name, attr);\n    }\n    if (!node.device().empty())\n      state.addAttribute(device_attr, StringAttr::get(context, node.device()));\n    if (!node.name().empty())\n      state.addAttribute(name_attr, StringAttr::get(context, node.name()));\n    if (node.has_experimental_type()) {\n      TF_ASSIGN_OR_RETURN(\n          tf_type::FullTypeAttr type,\n          ConvertAttribute(node.experimental_type(), builder, tfgDialect));\n      state.addAttribute(fulltype_attr, type);\n    }\n\n    Operation* op = builder.create(state);\n\n    StringRef node_name = node.name();\n    {\n      size_t colon_sep = node_name.find_first_of(':');\n      if (colon_sep != StringRef::npos)\n        node_name = node_name.take_front(colon_sep);\n    }\n    TF_RETURN_IF_ERROR(value_manager.DefineOperation(op, node_name));\n  }\n  // We don't expect any placeholder left at this point, fail if any.\n  for (Operation& op : *builder.getInsertionBlock()) {\n    if (op.getName().getStringRef() == \"tfg.__mlir_placeholder\") {\n      return InvalidArgument(absl::StrCat(\n          \"Couldn't import graph: placeholder left \",\n          op.getAttrOfType<StringAttr>(name_attr).getValue().str()));\n    }\n  }\n  return Status::OK();\n}",
        "func": "Status ImportNodes(ValueMapManager value_manager,\n                   const RepeatedPtrField<NodeDef>& nodes, OpBuilder& builder) {\n  Location unknown_loc = builder.getUnknownLoc();\n  MLIRContext* context = builder.getContext();\n\n  Type placeholder_ty = OpaqueTensorType::get(context);\n  Type control_ty = ControlType::get(context);\n  TFGraphDialect* tfgDialect =\n      cast<TFGraphDialect>(context->getLoadedDialect(\"tfg\"));\n  StringAttr device_attr = tfgDialect->getDeviceAttrIdentifier();\n  StringAttr name_attr = tfgDialect->getNameAttrIdentifier();\n  StringAttr fulltype_attr = tfgDialect->getFullTypeAttrIdentifier();\n  // Process every node and create a matching MLIR operation\n  for (const NodeDef& node : nodes) {\n    DVLOG(1) << \"Processing node \" << node.name() << \"\\n\";\n    if (node.op().empty()) return InvalidArgument(\"empty op type\");\n    OperationState state(unknown_loc, absl::StrCat(\"tfg.\", node.op()));\n    // Fetch the inputs, creating placeholder if an input hasn't been visited.\n    for (const std::string& input : node.input()) {\n      if (input.empty())\n        return InvalidArgument(\"Node '\", node.name(), \"' has an empty input\");\n      state.operands.push_back(\n          value_manager.GetValueOrCreatePlaceholder(input));\n    }\n    // Retrieve the entry in the nodes_map for this node and infer the result\n    // count from what was inferred during the first traversal above.\n    state.types.push_back(placeholder_ty);\n    state.types.push_back(control_ty);\n    // Handle attributes.\n    for (const auto& namedAttr : node.attr()) {\n      const std::string& name = namedAttr.first;\n      const AttrValue& tf_attr = namedAttr.second;\n      TF_ASSIGN_OR_RETURN(Attribute attr,\n                          ConvertAttributeValue(tf_attr, builder, tfgDialect));\n      state.addAttribute(name, attr);\n    }\n    if (!node.device().empty())\n      state.addAttribute(device_attr, StringAttr::get(context, node.device()));\n    if (!node.name().empty())\n      state.addAttribute(name_attr, StringAttr::get(context, node.name()));\n    if (node.has_experimental_type()) {\n      TF_ASSIGN_OR_RETURN(\n          tf_type::FullTypeAttr type,\n          ConvertAttribute(node.experimental_type(), builder, tfgDialect));\n      state.addAttribute(fulltype_attr, type);\n    }\n\n    Operation* op = builder.create(state);\n\n    StringRef node_name = node.name();\n    {\n      size_t colon_sep = node_name.find_first_of(':');\n      if (colon_sep != StringRef::npos)\n        node_name = node_name.take_front(colon_sep);\n    }\n    TF_RETURN_IF_ERROR(value_manager.DefineOperation(op, node_name));\n  }\n  // We don't expect any placeholder left at this point, fail if any.\n  for (Operation& op : *builder.getInsertionBlock()) {\n    if (op.getName().getStringRef() == \"tfg.__mlir_placeholder\") {\n      return InvalidArgument(absl::StrCat(\n          \"Couldn't import graph: placeholder left \",\n          op.getAttrOfType<StringAttr>(name_attr).getValue().str()));\n    }\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,9 +16,12 @@\n     if (node.op().empty()) return InvalidArgument(\"empty op type\");\n     OperationState state(unknown_loc, absl::StrCat(\"tfg.\", node.op()));\n     // Fetch the inputs, creating placeholder if an input hasn't been visited.\n-    for (const std::string& input : node.input())\n+    for (const std::string& input : node.input()) {\n+      if (input.empty())\n+        return InvalidArgument(\"Node '\", node.name(), \"' has an empty input\");\n       state.operands.push_back(\n           value_manager.GetValueOrCreatePlaceholder(input));\n+    }\n     // Retrieve the entry in the nodes_map for this node and infer the result\n     // count from what was inferred during the first traversal above.\n     state.types.push_back(placeholder_ty);",
        "diff_line_info": {
            "deleted_lines": [
                "    for (const std::string& input : node.input())"
            ],
            "added_lines": [
                "    for (const std::string& input : node.input()) {",
                "      if (input.empty())",
                "        return InvalidArgument(\"Node '\", node.name(), \"' has an empty input\");",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-36016",
        "func_name": "tensorflow/SubstituteForEach",
        "description": "TensorFlow is an open source platform for machine learning. When `tensorflow::full_type::SubstituteFromAttrs` receives a `FullTypeDef& t` that is not exactly three args, it triggers a `CHECK`-fail instead of returning a status. We have patched the issue in GitHub commit 6104f0d4091c260ce9352f9155f7e9b725eab012. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/6104f0d4091c260ce9352f9155f7e9b725eab012",
        "commit_title": "Strengthen input verification for SpecializeType by replacing DCHECK with explicit test/status return.",
        "commit_text": " PiperOrigin-RevId: 453436708",
        "func_before": "Status SubstituteForEach(AttrMap& attrs, FullTypeDef& t) {\n  DCHECK_EQ(t.args_size(), 3);\n\n  const auto& cont = t.args(0);\n  const auto& tmpl = t.args(1);\n  const auto& t_var = t.args(2);\n\n  StringPiece var_name = t_var.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  FullTypeDef result;\n  result.set_type_id(cont.type_id());\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    FullTypeDef* target = result.add_args();\n    *target = tmpl;\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(attrs, *target), \"while substituting '\", var_name,\n        \"' from\\n\", attr->DebugString(), \"\\ninto \", target->DebugString());\n\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    int tsize = attr_list.type_size();\n    if (tsize == 0) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"unsupported list attribute type\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    AttrValue replacement;\n    attrs[var_name] = &replacement;\n    for (int i = 0; i < tsize; i++) {\n      replacement.set_type(attr_list.type(i));\n      FullTypeDef* target = result.add_args();\n      *target = tmpl;\n      TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *target),\n                                      \"while substituting '\", var_name,\n                                      \"' from\\n\", attr->DebugString(), \"\\n[\", i,\n                                      \"] into\\n\", target->DebugString());\n    }\n    // In case of error, it's ok for the attributes map to remain in an invalid\n    // state.\n    attrs[var_name] = attr;\n\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type\\n\",\n                               attr->DebugString(), \"\\nfor name \", var_name));\n  }\n  t = result;\n  return OkStatus();\n}",
        "func": "Status SubstituteForEach(AttrMap& attrs, FullTypeDef& t) {\n  if (t.args_size() != 3) {\n    return Status(error::INVALID_ARGUMENT,\n                  absl::StrCat(\"illegal FOR_EACH type, expected 3 args, got \",\n                               t.args_size()));\n  }\n\n  const auto& cont = t.args(0);\n  const auto& tmpl = t.args(1);\n  const auto& t_var = t.args(2);\n\n  StringPiece var_name = t_var.s();\n  if (!attrs.contains(var_name)) {\n    return Status(\n        error::INVALID_ARGUMENT,\n        absl::StrCat(\"could not find an attribute for key '\", var_name, \"'\"));\n  }\n  const AttrValue* attr = attrs.at(var_name);\n\n  FullTypeDef result;\n  result.set_type_id(cont.type_id());\n\n  const auto attr_type = attr->value_case();\n  if (attr_type == AttrValue::kType) {\n    FullTypeDef* target = result.add_args();\n    *target = tmpl;\n    TF_RETURN_WITH_CONTEXT_IF_ERROR(\n        SubstituteFromAttrs(attrs, *target), \"while substituting '\", var_name,\n        \"' from\\n\", attr->DebugString(), \"\\ninto \", target->DebugString());\n\n  } else if (attr_type == AttrValue::kList) {\n    const auto& attr_list = attr->list();\n    int tsize = attr_list.type_size();\n    if (tsize == 0) {\n      return Status(error::UNIMPLEMENTED,\n                    absl::StrCat(\"unsupported list attribute type\\n\",\n                                 attr_list.DebugString(), \"\\nkey=\", var_name));\n    }\n    AttrValue replacement;\n    attrs[var_name] = &replacement;\n    for (int i = 0; i < tsize; i++) {\n      replacement.set_type(attr_list.type(i));\n      FullTypeDef* target = result.add_args();\n      *target = tmpl;\n      TF_RETURN_WITH_CONTEXT_IF_ERROR(SubstituteFromAttrs(attrs, *target),\n                                      \"while substituting '\", var_name,\n                                      \"' from\\n\", attr->DebugString(), \"\\n[\", i,\n                                      \"] into\\n\", target->DebugString());\n    }\n    // In case of error, it's ok for the attributes map to remain in an invalid\n    // state.\n    attrs[var_name] = attr;\n\n  } else {\n    return Status(error::UNIMPLEMENTED,\n                  absl::StrCat(\"unsupported attribute type\\n\",\n                               attr->DebugString(), \"\\nfor name \", var_name));\n  }\n  t = result;\n  return OkStatus();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,9 @@\n Status SubstituteForEach(AttrMap& attrs, FullTypeDef& t) {\n-  DCHECK_EQ(t.args_size(), 3);\n+  if (t.args_size() != 3) {\n+    return Status(error::INVALID_ARGUMENT,\n+                  absl::StrCat(\"illegal FOR_EACH type, expected 3 args, got \",\n+                               t.args_size()));\n+  }\n \n   const auto& cont = t.args(0);\n   const auto& tmpl = t.args(1);",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK_EQ(t.args_size(), 3);"
            ],
            "added_lines": [
                "  if (t.args_size() != 3) {",
                "    return Status(error::INVALID_ARGUMENT,",
                "                  absl::StrCat(\"illegal FOR_EACH type, expected 3 args, got \",",
                "                               t.args_size()));",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-12168",
        "func_name": "torvalds/linux/access_pmu_evcntr",
        "description": "The access_pmu_evcntr function in arch/arm64/kvm/sys_regs.c in the Linux kernel before 4.8.11 allows privileged KVM guest OS users to cause a denial of service (assertion failure and host OS crash) by accessing the Performance Monitors Cycle Count Register (PMCCNTR).",
        "git_url": "https://github.com/torvalds/linux/commit/9e3f7a29694049edd728e2400ab57ad7553e5aa9",
        "commit_title": "arm64: KVM: pmu: Fix AArch32 cycle counter access",
        "commit_text": " We're missing the handling code for the cycle counter accessed from a 32bit guest, leading to unexpected results.  Cc: stable@vger.kernel.org # 4.6+",
        "func_before": "static bool access_pmu_evcntr(struct kvm_vcpu *vcpu,\n\t\t\t      struct sys_reg_params *p,\n\t\t\t      const struct sys_reg_desc *r)\n{\n\tu64 idx;\n\n\tif (!kvm_arm_pmu_v3_ready(vcpu))\n\t\treturn trap_raz_wi(vcpu, p, r);\n\n\tif (r->CRn == 9 && r->CRm == 13) {\n\t\tif (r->Op2 == 2) {\n\t\t\t/* PMXEVCNTR_EL0 */\n\t\t\tif (pmu_access_event_counter_el0_disabled(vcpu))\n\t\t\t\treturn false;\n\n\t\t\tidx = vcpu_sys_reg(vcpu, PMSELR_EL0)\n\t\t\t      & ARMV8_PMU_COUNTER_MASK;\n\t\t} else if (r->Op2 == 0) {\n\t\t\t/* PMCCNTR_EL0 */\n\t\t\tif (pmu_access_cycle_counter_el0_disabled(vcpu))\n\t\t\t\treturn false;\n\n\t\t\tidx = ARMV8_PMU_CYCLE_IDX;\n\t\t} else {\n\t\t\tBUG();\n\t\t}\n\t} else if (r->CRn == 14 && (r->CRm & 12) == 8) {\n\t\t/* PMEVCNTRn_EL0 */\n\t\tif (pmu_access_event_counter_el0_disabled(vcpu))\n\t\t\treturn false;\n\n\t\tidx = ((r->CRm & 3) << 3) | (r->Op2 & 7);\n\t} else {\n\t\tBUG();\n\t}\n\n\tif (!pmu_counter_idx_valid(vcpu, idx))\n\t\treturn false;\n\n\tif (p->is_write) {\n\t\tif (pmu_access_el0_disabled(vcpu))\n\t\t\treturn false;\n\n\t\tkvm_pmu_set_counter_value(vcpu, idx, p->regval);\n\t} else {\n\t\tp->regval = kvm_pmu_get_counter_value(vcpu, idx);\n\t}\n\n\treturn true;\n}",
        "func": "static bool access_pmu_evcntr(struct kvm_vcpu *vcpu,\n\t\t\t      struct sys_reg_params *p,\n\t\t\t      const struct sys_reg_desc *r)\n{\n\tu64 idx;\n\n\tif (!kvm_arm_pmu_v3_ready(vcpu))\n\t\treturn trap_raz_wi(vcpu, p, r);\n\n\tif (r->CRn == 9 && r->CRm == 13) {\n\t\tif (r->Op2 == 2) {\n\t\t\t/* PMXEVCNTR_EL0 */\n\t\t\tif (pmu_access_event_counter_el0_disabled(vcpu))\n\t\t\t\treturn false;\n\n\t\t\tidx = vcpu_sys_reg(vcpu, PMSELR_EL0)\n\t\t\t      & ARMV8_PMU_COUNTER_MASK;\n\t\t} else if (r->Op2 == 0) {\n\t\t\t/* PMCCNTR_EL0 */\n\t\t\tif (pmu_access_cycle_counter_el0_disabled(vcpu))\n\t\t\t\treturn false;\n\n\t\t\tidx = ARMV8_PMU_CYCLE_IDX;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t} else if (r->CRn == 0 && r->CRm == 9) {\n\t\t/* PMCCNTR */\n\t\tif (pmu_access_event_counter_el0_disabled(vcpu))\n\t\t\treturn false;\n\n\t\tidx = ARMV8_PMU_CYCLE_IDX;\n\t} else if (r->CRn == 14 && (r->CRm & 12) == 8) {\n\t\t/* PMEVCNTRn_EL0 */\n\t\tif (pmu_access_event_counter_el0_disabled(vcpu))\n\t\t\treturn false;\n\n\t\tidx = ((r->CRm & 3) << 3) | (r->Op2 & 7);\n\t} else {\n\t\treturn false;\n\t}\n\n\tif (!pmu_counter_idx_valid(vcpu, idx))\n\t\treturn false;\n\n\tif (p->is_write) {\n\t\tif (pmu_access_el0_disabled(vcpu))\n\t\t\treturn false;\n\n\t\tkvm_pmu_set_counter_value(vcpu, idx, p->regval);\n\t} else {\n\t\tp->regval = kvm_pmu_get_counter_value(vcpu, idx);\n\t}\n\n\treturn true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,8 +22,14 @@\n \n \t\t\tidx = ARMV8_PMU_CYCLE_IDX;\n \t\t} else {\n-\t\t\tBUG();\n+\t\t\treturn false;\n \t\t}\n+\t} else if (r->CRn == 0 && r->CRm == 9) {\n+\t\t/* PMCCNTR */\n+\t\tif (pmu_access_event_counter_el0_disabled(vcpu))\n+\t\t\treturn false;\n+\n+\t\tidx = ARMV8_PMU_CYCLE_IDX;\n \t} else if (r->CRn == 14 && (r->CRm & 12) == 8) {\n \t\t/* PMEVCNTRn_EL0 */\n \t\tif (pmu_access_event_counter_el0_disabled(vcpu))\n@@ -31,7 +37,7 @@\n \n \t\tidx = ((r->CRm & 3) << 3) | (r->Op2 & 7);\n \t} else {\n-\t\tBUG();\n+\t\treturn false;\n \t}\n \n \tif (!pmu_counter_idx_valid(vcpu, idx))",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tBUG();",
                "\t\tBUG();"
            ],
            "added_lines": [
                "\t\t\treturn false;",
                "\t} else if (r->CRn == 0 && r->CRm == 9) {",
                "\t\t/* PMCCNTR */",
                "\t\tif (pmu_access_event_counter_el0_disabled(vcpu))",
                "\t\t\treturn false;",
                "",
                "\t\tidx = ARMV8_PMU_CYCLE_IDX;",
                "\t\treturn false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-1000252",
        "func_name": "torvalds/linux/kvm_irqfd",
        "description": "The KVM subsystem in the Linux kernel through 4.13.3 allows guest OS users to cause a denial of service (assertion failure, and hypervisor hang or crash) via an out-of bounds guest_irq value, related to arch/x86/kvm/vmx.c and virt/kvm/eventfd.c.",
        "git_url": "https://github.com/torvalds/linux/commit/36ae3c0a36b7456432fedce38ae2f7bd3e01a563",
        "commit_title": "KVM: Don't accept obviously wrong gsi values via KVM_IRQFD",
        "commit_text": " We cannot add routes for gsi values >= KVM_MAX_IRQ_ROUTES -- see kvm_set_irq_routing(). Hence, there is no sense in accepting them via KVM_IRQFD. Prevent them from entering the system in the first place. ",
        "func_before": "int\nkvm_irqfd(struct kvm *kvm, struct kvm_irqfd *args)\n{\n\tif (args->flags & ~(KVM_IRQFD_FLAG_DEASSIGN | KVM_IRQFD_FLAG_RESAMPLE))\n\t\treturn -EINVAL;\n\n\tif (args->flags & KVM_IRQFD_FLAG_DEASSIGN)\n\t\treturn kvm_irqfd_deassign(kvm, args);\n\n\treturn kvm_irqfd_assign(kvm, args);\n}",
        "func": "int\nkvm_irqfd(struct kvm *kvm, struct kvm_irqfd *args)\n{\n\tif (args->flags & ~(KVM_IRQFD_FLAG_DEASSIGN | KVM_IRQFD_FLAG_RESAMPLE))\n\t\treturn -EINVAL;\n\tif (args->gsi >= KVM_MAX_IRQ_ROUTES)\n\t\treturn -EINVAL;\n\n\tif (args->flags & KVM_IRQFD_FLAG_DEASSIGN)\n\t\treturn kvm_irqfd_deassign(kvm, args);\n\n\treturn kvm_irqfd_assign(kvm, args);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,8 @@\n kvm_irqfd(struct kvm *kvm, struct kvm_irqfd *args)\n {\n \tif (args->flags & ~(KVM_IRQFD_FLAG_DEASSIGN | KVM_IRQFD_FLAG_RESAMPLE))\n+\t\treturn -EINVAL;\n+\tif (args->gsi >= KVM_MAX_IRQ_ROUTES)\n \t\treturn -EINVAL;\n \n \tif (args->flags & KVM_IRQFD_FLAG_DEASSIGN)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\treturn -EINVAL;",
                "\tif (args->gsi >= KVM_MAX_IRQ_ROUTES)"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-1000252",
        "func_name": "torvalds/linux/vmx_update_pi_irte",
        "description": "The KVM subsystem in the Linux kernel through 4.13.3 allows guest OS users to cause a denial of service (assertion failure, and hypervisor hang or crash) via an out-of bounds guest_irq value, related to arch/x86/kvm/vmx.c and virt/kvm/eventfd.c.",
        "git_url": "https://github.com/torvalds/linux/commit/3a8b0677fc6180a467e26cc32ce6b0c09a32f9bb",
        "commit_title": "KVM: VMX: Do not BUG() on out-of-bounds guest IRQ",
        "commit_text": " The value of the guest_irq argument to vmx_update_pi_irte() is ultimately coming from a KVM_IRQFD API call. Do not BUG() in vmx_update_pi_irte() if the value is out-of bounds. (Especially, since KVM as a whole seems to hang after that.)  Instead, print a message only once if we find that we don't have a route for a certain IRQ (which can be out-of-bounds or within the array).  This fixes CVE-2017-1000252. ",
        "func_before": "static int vmx_update_pi_irte(struct kvm *kvm, unsigned int host_irq,\n\t\t\t      uint32_t guest_irq, bool set)\n{\n\tstruct kvm_kernel_irq_routing_entry *e;\n\tstruct kvm_irq_routing_table *irq_rt;\n\tstruct kvm_lapic_irq irq;\n\tstruct kvm_vcpu *vcpu;\n\tstruct vcpu_data vcpu_info;\n\tint idx, ret = -EINVAL;\n\n\tif (!kvm_arch_has_assigned_device(kvm) ||\n\t\t!irq_remapping_cap(IRQ_POSTING_CAP) ||\n\t\t!kvm_vcpu_apicv_active(kvm->vcpus[0]))\n\t\treturn 0;\n\n\tidx = srcu_read_lock(&kvm->irq_srcu);\n\tirq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);\n\tBUG_ON(guest_irq >= irq_rt->nr_rt_entries);\n\n\thlist_for_each_entry(e, &irq_rt->map[guest_irq], link) {\n\t\tif (e->type != KVM_IRQ_ROUTING_MSI)\n\t\t\tcontinue;\n\t\t/*\n\t\t * VT-d PI cannot support posting multicast/broadcast\n\t\t * interrupts to a vCPU, we still use interrupt remapping\n\t\t * for these kind of interrupts.\n\t\t *\n\t\t * For lowest-priority interrupts, we only support\n\t\t * those with single CPU as the destination, e.g. user\n\t\t * configures the interrupts via /proc/irq or uses\n\t\t * irqbalance to make the interrupts single-CPU.\n\t\t *\n\t\t * We will support full lowest-priority interrupt later.\n\t\t */\n\n\t\tkvm_set_msi_irq(kvm, e, &irq);\n\t\tif (!kvm_intr_is_single_vcpu(kvm, &irq, &vcpu)) {\n\t\t\t/*\n\t\t\t * Make sure the IRTE is in remapped mode if\n\t\t\t * we don't handle it in posted mode.\n\t\t\t */\n\t\t\tret = irq_set_vcpu_affinity(host_irq, NULL);\n\t\t\tif (ret < 0) {\n\t\t\t\tprintk(KERN_INFO\n\t\t\t\t   \"failed to back to remapped mode, irq: %u\\n\",\n\t\t\t\t   host_irq);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tvcpu_info.pi_desc_addr = __pa(vcpu_to_pi_desc(vcpu));\n\t\tvcpu_info.vector = irq.vector;\n\n\t\ttrace_kvm_pi_irte_update(vcpu->vcpu_id, host_irq, e->gsi,\n\t\t\t\tvcpu_info.vector, vcpu_info.pi_desc_addr, set);\n\n\t\tif (set)\n\t\t\tret = irq_set_vcpu_affinity(host_irq, &vcpu_info);\n\t\telse {\n\t\t\t/* suppress notification event before unposting */\n\t\t\tpi_set_sn(vcpu_to_pi_desc(vcpu));\n\t\t\tret = irq_set_vcpu_affinity(host_irq, NULL);\n\t\t\tpi_clear_sn(vcpu_to_pi_desc(vcpu));\n\t\t}\n\n\t\tif (ret < 0) {\n\t\t\tprintk(KERN_INFO \"%s: failed to update PI IRTE\\n\",\n\t\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = 0;\nout:\n\tsrcu_read_unlock(&kvm->irq_srcu, idx);\n\treturn ret;\n}",
        "func": "static int vmx_update_pi_irte(struct kvm *kvm, unsigned int host_irq,\n\t\t\t      uint32_t guest_irq, bool set)\n{\n\tstruct kvm_kernel_irq_routing_entry *e;\n\tstruct kvm_irq_routing_table *irq_rt;\n\tstruct kvm_lapic_irq irq;\n\tstruct kvm_vcpu *vcpu;\n\tstruct vcpu_data vcpu_info;\n\tint idx, ret = 0;\n\n\tif (!kvm_arch_has_assigned_device(kvm) ||\n\t\t!irq_remapping_cap(IRQ_POSTING_CAP) ||\n\t\t!kvm_vcpu_apicv_active(kvm->vcpus[0]))\n\t\treturn 0;\n\n\tidx = srcu_read_lock(&kvm->irq_srcu);\n\tirq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);\n\tif (guest_irq >= irq_rt->nr_rt_entries ||\n\t    hlist_empty(&irq_rt->map[guest_irq])) {\n\t\tpr_warn_once(\"no route for guest_irq %u/%u (broken user space?)\\n\",\n\t\t\t     guest_irq, irq_rt->nr_rt_entries);\n\t\tgoto out;\n\t}\n\n\thlist_for_each_entry(e, &irq_rt->map[guest_irq], link) {\n\t\tif (e->type != KVM_IRQ_ROUTING_MSI)\n\t\t\tcontinue;\n\t\t/*\n\t\t * VT-d PI cannot support posting multicast/broadcast\n\t\t * interrupts to a vCPU, we still use interrupt remapping\n\t\t * for these kind of interrupts.\n\t\t *\n\t\t * For lowest-priority interrupts, we only support\n\t\t * those with single CPU as the destination, e.g. user\n\t\t * configures the interrupts via /proc/irq or uses\n\t\t * irqbalance to make the interrupts single-CPU.\n\t\t *\n\t\t * We will support full lowest-priority interrupt later.\n\t\t */\n\n\t\tkvm_set_msi_irq(kvm, e, &irq);\n\t\tif (!kvm_intr_is_single_vcpu(kvm, &irq, &vcpu)) {\n\t\t\t/*\n\t\t\t * Make sure the IRTE is in remapped mode if\n\t\t\t * we don't handle it in posted mode.\n\t\t\t */\n\t\t\tret = irq_set_vcpu_affinity(host_irq, NULL);\n\t\t\tif (ret < 0) {\n\t\t\t\tprintk(KERN_INFO\n\t\t\t\t   \"failed to back to remapped mode, irq: %u\\n\",\n\t\t\t\t   host_irq);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tcontinue;\n\t\t}\n\n\t\tvcpu_info.pi_desc_addr = __pa(vcpu_to_pi_desc(vcpu));\n\t\tvcpu_info.vector = irq.vector;\n\n\t\ttrace_kvm_pi_irte_update(vcpu->vcpu_id, host_irq, e->gsi,\n\t\t\t\tvcpu_info.vector, vcpu_info.pi_desc_addr, set);\n\n\t\tif (set)\n\t\t\tret = irq_set_vcpu_affinity(host_irq, &vcpu_info);\n\t\telse {\n\t\t\t/* suppress notification event before unposting */\n\t\t\tpi_set_sn(vcpu_to_pi_desc(vcpu));\n\t\t\tret = irq_set_vcpu_affinity(host_irq, NULL);\n\t\t\tpi_clear_sn(vcpu_to_pi_desc(vcpu));\n\t\t}\n\n\t\tif (ret < 0) {\n\t\t\tprintk(KERN_INFO \"%s: failed to update PI IRTE\\n\",\n\t\t\t\t\t__func__);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tret = 0;\nout:\n\tsrcu_read_unlock(&kvm->irq_srcu, idx);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n \tstruct kvm_lapic_irq irq;\n \tstruct kvm_vcpu *vcpu;\n \tstruct vcpu_data vcpu_info;\n-\tint idx, ret = -EINVAL;\n+\tint idx, ret = 0;\n \n \tif (!kvm_arch_has_assigned_device(kvm) ||\n \t\t!irq_remapping_cap(IRQ_POSTING_CAP) ||\n@@ -15,7 +15,12 @@\n \n \tidx = srcu_read_lock(&kvm->irq_srcu);\n \tirq_rt = srcu_dereference(kvm->irq_routing, &kvm->irq_srcu);\n-\tBUG_ON(guest_irq >= irq_rt->nr_rt_entries);\n+\tif (guest_irq >= irq_rt->nr_rt_entries ||\n+\t    hlist_empty(&irq_rt->map[guest_irq])) {\n+\t\tpr_warn_once(\"no route for guest_irq %u/%u (broken user space?)\\n\",\n+\t\t\t     guest_irq, irq_rt->nr_rt_entries);\n+\t\tgoto out;\n+\t}\n \n \thlist_for_each_entry(e, &irq_rt->map[guest_irq], link) {\n \t\tif (e->type != KVM_IRQ_ROUTING_MSI)",
        "diff_line_info": {
            "deleted_lines": [
                "\tint idx, ret = -EINVAL;",
                "\tBUG_ON(guest_irq >= irq_rt->nr_rt_entries);"
            ],
            "added_lines": [
                "\tint idx, ret = 0;",
                "\tif (guest_irq >= irq_rt->nr_rt_entries ||",
                "\t    hlist_empty(&irq_rt->map[guest_irq])) {",
                "\t\tpr_warn_once(\"no route for guest_irq %u/%u (broken user space?)\\n\",",
                "\t\t\t     guest_irq, irq_rt->nr_rt_entries);",
                "\t\tgoto out;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-20217",
        "func_name": "krb5/s4u_identify_user",
        "description": "A Reachable Assertion issue was discovered in the KDC in MIT Kerberos 5 (aka krb5) before 1.17. If an attacker can obtain a krbtgt ticket using an older encryption type (single-DES, triple-DES, or RC4), the attacker can crash the KDC by making an S4U2Self request.",
        "git_url": "https://github.com/krb5/krb5/commit/5e6d1796106df8ba6bc1973ee0917c170d929086",
        "commit_title": "Ignore password attributes for S4U2Self requests",
        "commit_text": " For consistency with Windows KDCs, allow protocol transition to work even if the password has expired or needs changing.  Also, when looking up an enterprise principal with an AS request, treat ERR_KEY_EXP as confirmation that the client is present in the realm.  [ghudson@mit.edu: added comment in kdc_process_s4u2self_req(); edited commit message]  ticket: 8763 (new) tags: pullup target_version: 1.17",
        "func_before": "static krb5_error_code\ns4u_identify_user(krb5_context context,\n                  krb5_creds *in_creds,\n                  krb5_data *subject_cert,\n                  krb5_principal *canon_user)\n{\n    krb5_error_code code;\n    krb5_preauthtype ptypes[1] = { KRB5_PADATA_S4U_X509_USER };\n    krb5_creds creds;\n    int use_master = 0;\n    krb5_get_init_creds_opt *opts = NULL;\n    krb5_principal_data client;\n    krb5_s4u_userid userid;\n\n    *canon_user = NULL;\n\n    if (in_creds->client == NULL && subject_cert == NULL) {\n        return EINVAL;\n    }\n\n    if (in_creds->client != NULL &&\n        in_creds->client->type != KRB5_NT_ENTERPRISE_PRINCIPAL) {\n        int anonymous;\n\n        anonymous = krb5_principal_compare(context, in_creds->client,\n                                           krb5_anonymous_principal());\n\n        return krb5_copy_principal(context,\n                                   anonymous ? in_creds->server\n                                   : in_creds->client,\n                                   canon_user);\n    }\n\n    memset(&creds, 0, sizeof(creds));\n\n    memset(&userid, 0, sizeof(userid));\n    if (subject_cert != NULL)\n        userid.subject_cert = *subject_cert;\n\n    code = krb5_get_init_creds_opt_alloc(context, &opts);\n    if (code != 0)\n        goto cleanup;\n    krb5_get_init_creds_opt_set_tkt_life(opts, 15);\n    krb5_get_init_creds_opt_set_renew_life(opts, 0);\n    krb5_get_init_creds_opt_set_forwardable(opts, 0);\n    krb5_get_init_creds_opt_set_proxiable(opts, 0);\n    krb5_get_init_creds_opt_set_canonicalize(opts, 1);\n    krb5_get_init_creds_opt_set_preauth_list(opts, ptypes, 1);\n\n    if (in_creds->client != NULL) {\n        client = *in_creds->client;\n        client.realm = in_creds->server->realm;\n    } else {\n        client.magic = KV5M_PRINCIPAL;\n        client.realm = in_creds->server->realm;\n        /* should this be NULL, empty or a fixed string? XXX */\n        client.data = NULL;\n        client.length = 0;\n        client.type = KRB5_NT_ENTERPRISE_PRINCIPAL;\n    }\n\n    code = k5_get_init_creds(context, &creds, &client, NULL, NULL, 0, NULL,\n                             opts, krb5_get_as_key_noop, &userid, &use_master,\n                             NULL);\n    if (code == 0 || code == KRB5_PREAUTH_FAILED) {\n        *canon_user = userid.user;\n        userid.user = NULL;\n        code = 0;\n    }\n\ncleanup:\n    krb5_free_cred_contents(context, &creds);\n    if (opts != NULL)\n        krb5_get_init_creds_opt_free(context, opts);\n    if (userid.user != NULL)\n        krb5_free_principal(context, userid.user);\n\n    return code;\n}",
        "func": "static krb5_error_code\ns4u_identify_user(krb5_context context,\n                  krb5_creds *in_creds,\n                  krb5_data *subject_cert,\n                  krb5_principal *canon_user)\n{\n    krb5_error_code code;\n    krb5_preauthtype ptypes[1] = { KRB5_PADATA_S4U_X509_USER };\n    krb5_creds creds;\n    int use_master = 0;\n    krb5_get_init_creds_opt *opts = NULL;\n    krb5_principal_data client;\n    krb5_s4u_userid userid;\n\n    *canon_user = NULL;\n\n    if (in_creds->client == NULL && subject_cert == NULL) {\n        return EINVAL;\n    }\n\n    if (in_creds->client != NULL &&\n        in_creds->client->type != KRB5_NT_ENTERPRISE_PRINCIPAL) {\n        int anonymous;\n\n        anonymous = krb5_principal_compare(context, in_creds->client,\n                                           krb5_anonymous_principal());\n\n        return krb5_copy_principal(context,\n                                   anonymous ? in_creds->server\n                                   : in_creds->client,\n                                   canon_user);\n    }\n\n    memset(&creds, 0, sizeof(creds));\n\n    memset(&userid, 0, sizeof(userid));\n    if (subject_cert != NULL)\n        userid.subject_cert = *subject_cert;\n\n    code = krb5_get_init_creds_opt_alloc(context, &opts);\n    if (code != 0)\n        goto cleanup;\n    krb5_get_init_creds_opt_set_tkt_life(opts, 15);\n    krb5_get_init_creds_opt_set_renew_life(opts, 0);\n    krb5_get_init_creds_opt_set_forwardable(opts, 0);\n    krb5_get_init_creds_opt_set_proxiable(opts, 0);\n    krb5_get_init_creds_opt_set_canonicalize(opts, 1);\n    krb5_get_init_creds_opt_set_preauth_list(opts, ptypes, 1);\n\n    if (in_creds->client != NULL) {\n        client = *in_creds->client;\n        client.realm = in_creds->server->realm;\n    } else {\n        client.magic = KV5M_PRINCIPAL;\n        client.realm = in_creds->server->realm;\n        /* should this be NULL, empty or a fixed string? XXX */\n        client.data = NULL;\n        client.length = 0;\n        client.type = KRB5_NT_ENTERPRISE_PRINCIPAL;\n    }\n\n    code = k5_get_init_creds(context, &creds, &client, NULL, NULL, 0, NULL,\n                             opts, krb5_get_as_key_noop, &userid, &use_master,\n                             NULL);\n    if (!code || code == KRB5_PREAUTH_FAILED || code == KRB5KDC_ERR_KEY_EXP) {\n        *canon_user = userid.user;\n        userid.user = NULL;\n        code = 0;\n    }\n\ncleanup:\n    krb5_free_cred_contents(context, &creds);\n    if (opts != NULL)\n        krb5_get_init_creds_opt_free(context, opts);\n    if (userid.user != NULL)\n        krb5_free_principal(context, userid.user);\n\n    return code;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -62,7 +62,7 @@\n     code = k5_get_init_creds(context, &creds, &client, NULL, NULL, 0, NULL,\n                              opts, krb5_get_as_key_noop, &userid, &use_master,\n                              NULL);\n-    if (code == 0 || code == KRB5_PREAUTH_FAILED) {\n+    if (!code || code == KRB5_PREAUTH_FAILED || code == KRB5KDC_ERR_KEY_EXP) {\n         *canon_user = userid.user;\n         userid.user = NULL;\n         code = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (code == 0 || code == KRB5_PREAUTH_FAILED) {"
            ],
            "added_lines": [
                "    if (!code || code == KRB5_PREAUTH_FAILED || code == KRB5KDC_ERR_KEY_EXP) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-20217",
        "func_name": "krb5/kdc_process_s4u2self_req",
        "description": "A Reachable Assertion issue was discovered in the KDC in MIT Kerberos 5 (aka krb5) before 1.17. If an attacker can obtain a krbtgt ticket using an older encryption type (single-DES, triple-DES, or RC4), the attacker can crash the KDC by making an S4U2Self request.",
        "git_url": "https://github.com/krb5/krb5/commit/5e6d1796106df8ba6bc1973ee0917c170d929086",
        "commit_title": "Ignore password attributes for S4U2Self requests",
        "commit_text": " For consistency with Windows KDCs, allow protocol transition to work even if the password has expired or needs changing.  Also, when looking up an enterprise principal with an AS request, treat ERR_KEY_EXP as confirmation that the client is present in the realm.  [ghudson@mit.edu: added comment in kdc_process_s4u2self_req(); edited commit message]  ticket: 8763 (new) tags: pullup target_version: 1.17",
        "func_before": "krb5_error_code\nkdc_process_s4u2self_req(kdc_realm_t *kdc_active_realm,\n                         krb5_kdc_req *request,\n                         krb5_const_principal client_princ,\n                         krb5_const_principal header_srv_princ,\n                         krb5_boolean issuing_referral,\n                         const krb5_db_entry *server,\n                         krb5_keyblock *tgs_subkey,\n                         krb5_keyblock *tgs_session,\n                         krb5_timestamp kdc_time,\n                         krb5_pa_s4u_x509_user **s4u_x509_user,\n                         krb5_db_entry **princ_ptr,\n                         const char **status)\n{\n    krb5_error_code             code;\n    krb5_boolean                is_local_tgt;\n    krb5_pa_data                *pa_data;\n    int                         flags;\n    krb5_db_entry               *princ;\n\n    *princ_ptr = NULL;\n\n    pa_data = krb5int_find_pa_data(kdc_context,\n                                   request->padata, KRB5_PADATA_S4U_X509_USER);\n    if (pa_data != NULL) {\n        code = kdc_process_s4u_x509_user(kdc_context,\n                                         request,\n                                         pa_data,\n                                         tgs_subkey,\n                                         tgs_session,\n                                         s4u_x509_user,\n                                         status);\n        if (code != 0)\n            return code;\n    } else {\n        pa_data = krb5int_find_pa_data(kdc_context,\n                                       request->padata, KRB5_PADATA_FOR_USER);\n        if (pa_data != NULL) {\n            code = kdc_process_for_user(kdc_active_realm,\n                                        pa_data,\n                                        tgs_session,\n                                        s4u_x509_user,\n                                        status);\n            if (code != 0)\n                return code;\n        } else\n            return 0;\n    }\n\n    /*\n     * We need to compare the client name in the TGT with the requested\n     * server name. Supporting server name aliases without assuming a\n     * global name service makes this difficult to do.\n     *\n     * The comparison below handles the following cases (note that the\n     * term \"principal name\" below excludes the realm).\n     *\n     * (1) The requested service is a host-based service with two name\n     *     components, in which case we assume the principal name to\n     *     contain sufficient qualifying information. The realm is\n     *     ignored for the purpose of comparison.\n     *\n     * (2) The requested service name is an enterprise principal name:\n     *     the service principal name is compared with the unparsed\n     *     form of the client name (including its realm).\n     *\n     * (3) The requested service is some other name type: an exact\n     *     match is required.\n     *\n     * An alternative would be to look up the server once again with\n     * FLAG_CANONICALIZE | FLAG_CLIENT_REFERRALS_ONLY set, do an exact\n     * match between the returned name and client_princ. However, this\n     * assumes that the client set FLAG_CANONICALIZE when requesting\n     * the TGT and that we have a global name service.\n     */\n    flags = 0;\n    switch (krb5_princ_type(kdc_context, request->server)) {\n    case KRB5_NT_SRV_HST:                   /* (1) */\n        if (krb5_princ_size(kdc_context, request->server) == 2)\n            flags |= KRB5_PRINCIPAL_COMPARE_IGNORE_REALM;\n        break;\n    case KRB5_NT_ENTERPRISE_PRINCIPAL:      /* (2) */\n        flags |= KRB5_PRINCIPAL_COMPARE_ENTERPRISE;\n        break;\n    default:                                /* (3) */\n        break;\n    }\n\n    if (!krb5_principal_compare_flags(kdc_context,\n                                      request->server,\n                                      client_princ,\n                                      flags)) {\n        *status = \"INVALID_S4U2SELF_REQUEST\";\n        return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN; /* match Windows error code */\n    }\n\n    /*\n     * Protocol transition is mutually exclusive with renew/forward/etc\n     * as well as user-to-user and constrained delegation. This check\n     * is also made in validate_as_request().\n     *\n     * We can assert from this check that the header ticket was a TGT, as\n     * that is validated previously in validate_tgs_request().\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KRB5KDC_ERR_BADOPTION;\n    }\n\n    /*\n     * Valid S4U2Self requests can occur in the following combinations:\n     *\n     * (1) local TGT, local user, local server\n     * (2) cross TGT, local user, issuing referral\n     * (3) cross TGT, non-local user, issuing referral\n     * (4) cross TGT, non-local user, local server\n     *\n     * The first case is for a single-realm S4U2Self scenario; the second,\n     * third, and fourth cases are for the initial, intermediate (if any), and\n     * final cross-realm requests in a multi-realm scenario.\n     */\n\n    is_local_tgt = !is_cross_tgs_principal(header_srv_princ);\n    if (is_local_tgt && issuing_referral) {\n        /* The requesting server appears to no longer exist, and we found\n         * a referral instead.  Treat this as a server lookup failure. */\n        *status = \"LOOKING_UP_SERVER\";\n        return KRB5KDC_ERR_S_PRINCIPAL_UNKNOWN;\n    }\n\n    /*\n     * Do not attempt to lookup principals in foreign realms.\n     */\n    if (is_local_principal(kdc_active_realm,\n                           (*s4u_x509_user)->user_id.user)) {\n        krb5_db_entry no_server;\n        krb5_pa_data **e_data = NULL;\n\n        if (!is_local_tgt && !issuing_referral) {\n            /* A local server should not need a cross-realm TGT to impersonate\n             * a local principal. */\n            *status = \"NOT_CROSS_REALM_REQUEST\";\n            return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN; /* match Windows error */\n        }\n\n        code = krb5_db_get_principal(kdc_context,\n                                     (*s4u_x509_user)->user_id.user,\n                                     KRB5_KDB_FLAG_INCLUDE_PAC, &princ);\n        if (code == KRB5_KDB_NOENTRY) {\n            *status = \"UNKNOWN_S4U2SELF_PRINCIPAL\";\n            return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n        } else if (code) {\n            *status = \"LOOKING_UP_S4U2SELF_PRINCIPAL\";\n            return code; /* caller can free for_user */\n        }\n\n        memset(&no_server, 0, sizeof(no_server));\n\n        code = validate_as_request(kdc_active_realm, request, *princ,\n                                   no_server, kdc_time, status, &e_data);\n        if (code) {\n            krb5_db_free_principal(kdc_context, princ);\n            krb5_free_pa_data(kdc_context, e_data);\n            return code;\n        }\n\n        *princ_ptr = princ;\n    } else if (is_local_tgt) {\n        /*\n         * The server is asking to impersonate a principal from another realm,\n         * using a local TGT.  It should instead ask that principal's realm and\n         * follow referrals back to us.\n         */\n        *status = \"S4U2SELF_CLIENT_NOT_OURS\";\n        return KRB5KDC_ERR_POLICY; /* match Windows error */\n    }\n\n    return 0;\n}",
        "func": "krb5_error_code\nkdc_process_s4u2self_req(kdc_realm_t *kdc_active_realm,\n                         krb5_kdc_req *request,\n                         krb5_const_principal client_princ,\n                         krb5_const_principal header_srv_princ,\n                         krb5_boolean issuing_referral,\n                         const krb5_db_entry *server,\n                         krb5_keyblock *tgs_subkey,\n                         krb5_keyblock *tgs_session,\n                         krb5_timestamp kdc_time,\n                         krb5_pa_s4u_x509_user **s4u_x509_user,\n                         krb5_db_entry **princ_ptr,\n                         const char **status)\n{\n    krb5_error_code             code;\n    krb5_boolean                is_local_tgt;\n    krb5_pa_data                *pa_data;\n    int                         flags;\n    krb5_db_entry               *princ;\n\n    *princ_ptr = NULL;\n\n    pa_data = krb5int_find_pa_data(kdc_context,\n                                   request->padata, KRB5_PADATA_S4U_X509_USER);\n    if (pa_data != NULL) {\n        code = kdc_process_s4u_x509_user(kdc_context,\n                                         request,\n                                         pa_data,\n                                         tgs_subkey,\n                                         tgs_session,\n                                         s4u_x509_user,\n                                         status);\n        if (code != 0)\n            return code;\n    } else {\n        pa_data = krb5int_find_pa_data(kdc_context,\n                                       request->padata, KRB5_PADATA_FOR_USER);\n        if (pa_data != NULL) {\n            code = kdc_process_for_user(kdc_active_realm,\n                                        pa_data,\n                                        tgs_session,\n                                        s4u_x509_user,\n                                        status);\n            if (code != 0)\n                return code;\n        } else\n            return 0;\n    }\n\n    /*\n     * We need to compare the client name in the TGT with the requested\n     * server name. Supporting server name aliases without assuming a\n     * global name service makes this difficult to do.\n     *\n     * The comparison below handles the following cases (note that the\n     * term \"principal name\" below excludes the realm).\n     *\n     * (1) The requested service is a host-based service with two name\n     *     components, in which case we assume the principal name to\n     *     contain sufficient qualifying information. The realm is\n     *     ignored for the purpose of comparison.\n     *\n     * (2) The requested service name is an enterprise principal name:\n     *     the service principal name is compared with the unparsed\n     *     form of the client name (including its realm).\n     *\n     * (3) The requested service is some other name type: an exact\n     *     match is required.\n     *\n     * An alternative would be to look up the server once again with\n     * FLAG_CANONICALIZE | FLAG_CLIENT_REFERRALS_ONLY set, do an exact\n     * match between the returned name and client_princ. However, this\n     * assumes that the client set FLAG_CANONICALIZE when requesting\n     * the TGT and that we have a global name service.\n     */\n    flags = 0;\n    switch (krb5_princ_type(kdc_context, request->server)) {\n    case KRB5_NT_SRV_HST:                   /* (1) */\n        if (krb5_princ_size(kdc_context, request->server) == 2)\n            flags |= KRB5_PRINCIPAL_COMPARE_IGNORE_REALM;\n        break;\n    case KRB5_NT_ENTERPRISE_PRINCIPAL:      /* (2) */\n        flags |= KRB5_PRINCIPAL_COMPARE_ENTERPRISE;\n        break;\n    default:                                /* (3) */\n        break;\n    }\n\n    if (!krb5_principal_compare_flags(kdc_context,\n                                      request->server,\n                                      client_princ,\n                                      flags)) {\n        *status = \"INVALID_S4U2SELF_REQUEST\";\n        return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN; /* match Windows error code */\n    }\n\n    /*\n     * Protocol transition is mutually exclusive with renew/forward/etc\n     * as well as user-to-user and constrained delegation. This check\n     * is also made in validate_as_request().\n     *\n     * We can assert from this check that the header ticket was a TGT, as\n     * that is validated previously in validate_tgs_request().\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KRB5KDC_ERR_BADOPTION;\n    }\n\n    /*\n     * Valid S4U2Self requests can occur in the following combinations:\n     *\n     * (1) local TGT, local user, local server\n     * (2) cross TGT, local user, issuing referral\n     * (3) cross TGT, non-local user, issuing referral\n     * (4) cross TGT, non-local user, local server\n     *\n     * The first case is for a single-realm S4U2Self scenario; the second,\n     * third, and fourth cases are for the initial, intermediate (if any), and\n     * final cross-realm requests in a multi-realm scenario.\n     */\n\n    is_local_tgt = !is_cross_tgs_principal(header_srv_princ);\n    if (is_local_tgt && issuing_referral) {\n        /* The requesting server appears to no longer exist, and we found\n         * a referral instead.  Treat this as a server lookup failure. */\n        *status = \"LOOKING_UP_SERVER\";\n        return KRB5KDC_ERR_S_PRINCIPAL_UNKNOWN;\n    }\n\n    /*\n     * Do not attempt to lookup principals in foreign realms.\n     */\n    if (is_local_principal(kdc_active_realm,\n                           (*s4u_x509_user)->user_id.user)) {\n        krb5_db_entry no_server;\n        krb5_pa_data **e_data = NULL;\n\n        if (!is_local_tgt && !issuing_referral) {\n            /* A local server should not need a cross-realm TGT to impersonate\n             * a local principal. */\n            *status = \"NOT_CROSS_REALM_REQUEST\";\n            return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN; /* match Windows error */\n        }\n\n        code = krb5_db_get_principal(kdc_context,\n                                     (*s4u_x509_user)->user_id.user,\n                                     KRB5_KDB_FLAG_INCLUDE_PAC, &princ);\n        if (code == KRB5_KDB_NOENTRY) {\n            *status = \"UNKNOWN_S4U2SELF_PRINCIPAL\";\n            return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n        } else if (code) {\n            *status = \"LOOKING_UP_S4U2SELF_PRINCIPAL\";\n            return code; /* caller can free for_user */\n        }\n\n        memset(&no_server, 0, sizeof(no_server));\n\n        /* Ignore password expiration and needchange attributes (as Windows\n         * does), since S4U2Self is not password authentication. */\n        princ->pw_expiration = 0;\n        clear(princ->attributes, KRB5_KDB_REQUIRES_PWCHANGE);\n\n        code = validate_as_request(kdc_active_realm, request, *princ,\n                                   no_server, kdc_time, status, &e_data);\n        if (code) {\n            krb5_db_free_principal(kdc_context, princ);\n            krb5_free_pa_data(kdc_context, e_data);\n            return code;\n        }\n\n        *princ_ptr = princ;\n    } else if (is_local_tgt) {\n        /*\n         * The server is asking to impersonate a principal from another realm,\n         * using a local TGT.  It should instead ask that principal's realm and\n         * follow referrals back to us.\n         */\n        *status = \"S4U2SELF_CLIENT_NOT_OURS\";\n        return KRB5KDC_ERR_POLICY; /* match Windows error */\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -156,6 +156,11 @@\n \n         memset(&no_server, 0, sizeof(no_server));\n \n+        /* Ignore password expiration and needchange attributes (as Windows\n+         * does), since S4U2Self is not password authentication. */\n+        princ->pw_expiration = 0;\n+        clear(princ->attributes, KRB5_KDB_REQUIRES_PWCHANGE);\n+\n         code = validate_as_request(kdc_active_realm, request, *princ,\n                                    no_server, kdc_time, status, &e_data);\n         if (code) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        /* Ignore password expiration and needchange attributes (as Windows",
                "         * does), since S4U2Self is not password authentication. */",
                "        princ->pw_expiration = 0;",
                "        clear(princ->attributes, KRB5_KDB_REQUIRES_PWCHANGE);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-31294",
        "func_name": "redis/processCommand",
        "description": "Redis before 6cbea7d allows a replica to cause an assertion failure in a primary server by sending a non-administrative command (specifically, a SET command). NOTE: this was fixed for Redis 6.2.x and 7.x in 2021. Versions before 6.2 were not intended to have safety guarantees related to this.",
        "git_url": "https://github.com/redis/redis/commit/6cbea7d29b5285692843bc1c351abba1a7ef326f",
        "commit_title": "Prevent replicas from sending commands that interact with keyspace (#8868)",
        "commit_text": " This solves an issue reported in #8712 in which a replica would bypass\r the client write pause check and cause an assertion due to executing a\r write command during failover.\r \r The fact is that we don't expect replicas to execute any command other\r than maybe REPLCONF and PING, etc. but matching against the ADMIN\r command flag is insufficient, so instead i just block keyspace access\r for now.  (cherry picked from commit 46f4ebbe842620f0976a36741a72482620aa4b48)",
        "func_before": "int processCommand(client *c) {\n    if (!server.lua_timedout) {\n        /* Both EXEC and EVAL call call() directly so there should be\n         * no way in_exec or in_eval or propagate_in_transaction is 1.\n         * That is unless lua_timedout, in which case client may run\n         * some commands. */\n        serverAssert(!server.propagate_in_transaction);\n        serverAssert(!server.in_exec);\n        serverAssert(!server.in_eval);\n    }\n\n    moduleCallCommandFilters(c);\n\n    /* The QUIT command is handled separately. Normal command procs will\n     * go through checking for replication and QUIT will cause trouble\n     * when FORCE_REPLICATION is enabled and would be implemented in\n     * a regular command proc. */\n    if (!strcasecmp(c->argv[0]->ptr,\"quit\")) {\n        addReply(c,shared.ok);\n        c->flags |= CLIENT_CLOSE_AFTER_REPLY;\n        return C_ERR;\n    }\n\n    /* Now lookup the command and check ASAP about trivial error conditions\n     * such as wrong arity, bad command name and so forth. */\n    c->cmd = c->lastcmd = lookupCommand(c->argv[0]->ptr);\n    if (!c->cmd) {\n        sds args = sdsempty();\n        int i;\n        for (i=1; i < c->argc && sdslen(args) < 128; i++)\n            args = sdscatprintf(args, \"`%.*s`, \", 128-(int)sdslen(args), (char*)c->argv[i]->ptr);\n        rejectCommandFormat(c,\"unknown command `%s`, with args beginning with: %s\",\n            (char*)c->argv[0]->ptr, args);\n        sdsfree(args);\n        return C_OK;\n    } else if ((c->cmd->arity > 0 && c->cmd->arity != c->argc) ||\n               (c->argc < -c->cmd->arity)) {\n        rejectCommandFormat(c,\"wrong number of arguments for '%s' command\",\n            c->cmd->name);\n        return C_OK;\n    }\n\n    int is_write_command = (c->cmd->flags & CMD_WRITE) ||\n                           (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_WRITE));\n    int is_denyoom_command = (c->cmd->flags & CMD_DENYOOM) ||\n                             (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_DENYOOM));\n    int is_denystale_command = !(c->cmd->flags & CMD_STALE) ||\n                               (c->cmd->proc == execCommand && (c->mstate.cmd_inv_flags & CMD_STALE));\n    int is_denyloading_command = !(c->cmd->flags & CMD_LOADING) ||\n                                 (c->cmd->proc == execCommand && (c->mstate.cmd_inv_flags & CMD_LOADING));\n    int is_may_replicate_command = (c->cmd->flags & (CMD_WRITE | CMD_MAY_REPLICATE)) ||\n                                   (c->cmd->proc == execCommand && (c->mstate.cmd_flags & (CMD_WRITE | CMD_MAY_REPLICATE)));\n\n    /* Check if the user is authenticated. This check is skipped in case\n     * the default user is flagged as \"nopass\" and is active. */\n    int auth_required = (!(DefaultUser->flags & USER_FLAG_NOPASS) ||\n                          (DefaultUser->flags & USER_FLAG_DISABLED)) &&\n                        !c->authenticated;\n    if (auth_required) {\n        /* AUTH and HELLO and no auth modules are valid even in\n         * non-authenticated state. */\n        if (!(c->cmd->flags & CMD_NO_AUTH)) {\n            rejectCommand(c,shared.noautherr);\n            return C_OK;\n        }\n    }\n\n    /* Check if the user can run this command according to the current\n     * ACLs. */\n    int acl_errpos;\n    int acl_retval = ACLCheckAllPerm(c,&acl_errpos);\n    if (acl_retval != ACL_OK) {\n        addACLLogEntry(c,acl_retval,acl_errpos,NULL);\n        switch (acl_retval) {\n        case ACL_DENIED_CMD:\n            rejectCommandFormat(c,\n                \"-NOPERM this user has no permissions to run \"\n                \"the '%s' command or its subcommand\", c->cmd->name);\n            break;\n        case ACL_DENIED_KEY:\n            rejectCommandFormat(c,\n                \"-NOPERM this user has no permissions to access \"\n                \"one of the keys used as arguments\");\n            break;\n        case ACL_DENIED_CHANNEL:\n            rejectCommandFormat(c,\n                \"-NOPERM this user has no permissions to access \"\n                \"one of the channels used as arguments\");\n            break;\n        default:\n            rejectCommandFormat(c, \"no permission\");\n            break;\n        }\n        return C_OK;\n    }\n\n    /* If cluster is enabled perform the cluster redirection here.\n     * However we don't perform the redirection if:\n     * 1) The sender of this command is our master.\n     * 2) The command has no key arguments. */\n    if (server.cluster_enabled &&\n        !(c->flags & CLIENT_MASTER) &&\n        !(c->flags & CLIENT_LUA &&\n          server.lua_caller->flags & CLIENT_MASTER) &&\n        !(!cmdHasMovableKeys(c->cmd) && c->cmd->firstkey == 0 &&\n          c->cmd->proc != execCommand))\n    {\n        int hashslot;\n        int error_code;\n        clusterNode *n = getNodeByQuery(c,c->cmd,c->argv,c->argc,\n                                        &hashslot,&error_code);\n        if (n == NULL || n != server.cluster->myself) {\n            if (c->cmd->proc == execCommand) {\n                discardTransaction(c);\n            } else {\n                flagTransaction(c);\n            }\n            clusterRedirectClient(c,n,hashslot,error_code);\n            c->cmd->rejected_calls++;\n            return C_OK;\n        }\n    }\n\n    /* Handle the maxmemory directive.\n     *\n     * Note that we do not want to reclaim memory if we are here re-entering\n     * the event loop since there is a busy Lua script running in timeout\n     * condition, to avoid mixing the propagation of scripts with the\n     * propagation of DELs due to eviction. */\n    if (server.maxmemory && !server.lua_timedout) {\n        int out_of_memory = (performEvictions() == EVICT_FAIL);\n        /* performEvictions may flush slave output buffers. This may result\n         * in a slave, that may be the active client, to be freed. */\n        if (server.current_client == NULL) return C_ERR;\n\n        int reject_cmd_on_oom = is_denyoom_command;\n        /* If client is in MULTI/EXEC context, queuing may consume an unlimited\n         * amount of memory, so we want to stop that.\n         * However, we never want to reject DISCARD, or even EXEC (unless it\n         * contains denied commands, in which case is_denyoom_command is already\n         * set. */\n        if (c->flags & CLIENT_MULTI &&\n            c->cmd->proc != execCommand &&\n            c->cmd->proc != discardCommand &&\n            c->cmd->proc != resetCommand) {\n            reject_cmd_on_oom = 1;\n        }\n\n        if (out_of_memory && reject_cmd_on_oom) {\n            rejectCommand(c, shared.oomerr);\n            return C_OK;\n        }\n\n        /* Save out_of_memory result at script start, otherwise if we check OOM\n         * until first write within script, memory used by lua stack and\n         * arguments might interfere. */\n        if (c->cmd->proc == evalCommand || c->cmd->proc == evalShaCommand) {\n            server.lua_oom = out_of_memory;\n        }\n    }\n\n    /* Make sure to use a reasonable amount of memory for client side\n     * caching metadata. */\n    if (server.tracking_clients) trackingLimitUsedSlots();\n\n    /* Don't accept write commands if there are problems persisting on disk\n     * and if this is a master instance. */\n    int deny_write_type = writeCommandsDeniedByDiskError();\n    if (deny_write_type != DISK_ERROR_TYPE_NONE &&\n        server.masterhost == NULL &&\n        (is_write_command ||c->cmd->proc == pingCommand))\n    {\n        if (deny_write_type == DISK_ERROR_TYPE_RDB)\n            rejectCommand(c, shared.bgsaveerr);\n        else\n            rejectCommandFormat(c,\n                \"-MISCONF Errors writing to the AOF file: %s\",\n                strerror(server.aof_last_write_errno));\n        return C_OK;\n    }\n\n    /* Don't accept write commands if there are not enough good slaves and\n     * user configured the min-slaves-to-write option. */\n    if (server.masterhost == NULL &&\n        server.repl_min_slaves_to_write &&\n        server.repl_min_slaves_max_lag &&\n        is_write_command &&\n        server.repl_good_slaves_count < server.repl_min_slaves_to_write)\n    {\n        rejectCommand(c, shared.noreplicaserr);\n        return C_OK;\n    }\n\n    /* Don't accept write commands if this is a read only slave. But\n     * accept write commands if this is our master. */\n    if (server.masterhost && server.repl_slave_ro &&\n        !(c->flags & CLIENT_MASTER) &&\n        is_write_command)\n    {\n        rejectCommand(c, shared.roslaveerr);\n        return C_OK;\n    }\n\n    /* Only allow a subset of commands in the context of Pub/Sub if the\n     * connection is in RESP2 mode. With RESP3 there are no limits. */\n    if ((c->flags & CLIENT_PUBSUB && c->resp == 2) &&\n        c->cmd->proc != pingCommand &&\n        c->cmd->proc != subscribeCommand &&\n        c->cmd->proc != unsubscribeCommand &&\n        c->cmd->proc != psubscribeCommand &&\n        c->cmd->proc != punsubscribeCommand &&\n        c->cmd->proc != resetCommand) {\n        rejectCommandFormat(c,\n            \"Can't execute '%s': only (P)SUBSCRIBE / \"\n            \"(P)UNSUBSCRIBE / PING / QUIT / RESET are allowed in this context\",\n            c->cmd->name);\n        return C_OK;\n    }\n\n    /* Only allow commands with flag \"t\", such as INFO, SLAVEOF and so on,\n     * when slave-serve-stale-data is no and we are a slave with a broken\n     * link with master. */\n    if (server.masterhost && server.repl_state != REPL_STATE_CONNECTED &&\n        server.repl_serve_stale_data == 0 &&\n        is_denystale_command)\n    {\n        rejectCommand(c, shared.masterdownerr);\n        return C_OK;\n    }\n\n    /* Loading DB? Return an error if the command has not the\n     * CMD_LOADING flag. */\n    if (server.loading && is_denyloading_command) {\n        rejectCommand(c, shared.loadingerr);\n        return C_OK;\n    }\n\n    /* Lua script too slow? Only allow a limited number of commands.\n     * Note that we need to allow the transactions commands, otherwise clients\n     * sending a transaction with pipelining without error checking, may have\n     * the MULTI plus a few initial commands refused, then the timeout\n     * condition resolves, and the bottom-half of the transaction gets\n     * executed, see Github PR #7022. */\n    if (server.lua_timedout &&\n          c->cmd->proc != authCommand &&\n          c->cmd->proc != helloCommand &&\n          c->cmd->proc != replconfCommand &&\n          c->cmd->proc != multiCommand &&\n          c->cmd->proc != discardCommand &&\n          c->cmd->proc != watchCommand &&\n          c->cmd->proc != unwatchCommand &&\n\t  c->cmd->proc != resetCommand &&\n        !(c->cmd->proc == shutdownCommand &&\n          c->argc == 2 &&\n          tolower(((char*)c->argv[1]->ptr)[0]) == 'n') &&\n        !(c->cmd->proc == scriptCommand &&\n          c->argc == 2 &&\n          tolower(((char*)c->argv[1]->ptr)[0]) == 'k'))\n    {\n        rejectCommand(c, shared.slowscripterr);\n        return C_OK;\n    }\n\n    /* If the server is paused, block the client until\n     * the pause has ended. Replicas are never paused. */\n    if (!(c->flags & CLIENT_SLAVE) && \n        ((server.client_pause_type == CLIENT_PAUSE_ALL) ||\n        (server.client_pause_type == CLIENT_PAUSE_WRITE && is_may_replicate_command)))\n    {\n        c->bpop.timeout = 0;\n        blockClient(c,BLOCKED_PAUSE);\n        return C_OK;       \n    }\n\n    /* Exec the command */\n    if (c->flags & CLIENT_MULTI &&\n        c->cmd->proc != execCommand && c->cmd->proc != discardCommand &&\n        c->cmd->proc != multiCommand && c->cmd->proc != watchCommand &&\n        c->cmd->proc != resetCommand)\n    {\n        queueMultiCommand(c);\n        addReply(c,shared.queued);\n    } else {\n        call(c,CMD_CALL_FULL);\n        c->woff = server.master_repl_offset;\n        if (listLength(server.ready_keys))\n            handleClientsBlockedOnKeys();\n    }\n\n    return C_OK;\n}",
        "func": "int processCommand(client *c) {\n    if (!server.lua_timedout) {\n        /* Both EXEC and EVAL call call() directly so there should be\n         * no way in_exec or in_eval or propagate_in_transaction is 1.\n         * That is unless lua_timedout, in which case client may run\n         * some commands. */\n        serverAssert(!server.propagate_in_transaction);\n        serverAssert(!server.in_exec);\n        serverAssert(!server.in_eval);\n    }\n\n    moduleCallCommandFilters(c);\n\n    /* The QUIT command is handled separately. Normal command procs will\n     * go through checking for replication and QUIT will cause trouble\n     * when FORCE_REPLICATION is enabled and would be implemented in\n     * a regular command proc. */\n    if (!strcasecmp(c->argv[0]->ptr,\"quit\")) {\n        addReply(c,shared.ok);\n        c->flags |= CLIENT_CLOSE_AFTER_REPLY;\n        return C_ERR;\n    }\n\n    /* Now lookup the command and check ASAP about trivial error conditions\n     * such as wrong arity, bad command name and so forth. */\n    c->cmd = c->lastcmd = lookupCommand(c->argv[0]->ptr);\n    if (!c->cmd) {\n        sds args = sdsempty();\n        int i;\n        for (i=1; i < c->argc && sdslen(args) < 128; i++)\n            args = sdscatprintf(args, \"`%.*s`, \", 128-(int)sdslen(args), (char*)c->argv[i]->ptr);\n        rejectCommandFormat(c,\"unknown command `%s`, with args beginning with: %s\",\n            (char*)c->argv[0]->ptr, args);\n        sdsfree(args);\n        return C_OK;\n    } else if ((c->cmd->arity > 0 && c->cmd->arity != c->argc) ||\n               (c->argc < -c->cmd->arity)) {\n        rejectCommandFormat(c,\"wrong number of arguments for '%s' command\",\n            c->cmd->name);\n        return C_OK;\n    }\n\n    int is_read_command = (c->cmd->flags & CMD_READONLY) ||\n                           (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_READONLY));\n    int is_write_command = (c->cmd->flags & CMD_WRITE) ||\n                           (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_WRITE));\n    int is_denyoom_command = (c->cmd->flags & CMD_DENYOOM) ||\n                             (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_DENYOOM));\n    int is_denystale_command = !(c->cmd->flags & CMD_STALE) ||\n                               (c->cmd->proc == execCommand && (c->mstate.cmd_inv_flags & CMD_STALE));\n    int is_denyloading_command = !(c->cmd->flags & CMD_LOADING) ||\n                                 (c->cmd->proc == execCommand && (c->mstate.cmd_inv_flags & CMD_LOADING));\n    int is_may_replicate_command = (c->cmd->flags & (CMD_WRITE | CMD_MAY_REPLICATE)) ||\n                                   (c->cmd->proc == execCommand && (c->mstate.cmd_flags & (CMD_WRITE | CMD_MAY_REPLICATE)));\n\n    /* Check if the user is authenticated. This check is skipped in case\n     * the default user is flagged as \"nopass\" and is active. */\n    int auth_required = (!(DefaultUser->flags & USER_FLAG_NOPASS) ||\n                          (DefaultUser->flags & USER_FLAG_DISABLED)) &&\n                        !c->authenticated;\n    if (auth_required) {\n        /* AUTH and HELLO and no auth modules are valid even in\n         * non-authenticated state. */\n        if (!(c->cmd->flags & CMD_NO_AUTH)) {\n            rejectCommand(c,shared.noautherr);\n            return C_OK;\n        }\n    }\n\n    /* Check if the user can run this command according to the current\n     * ACLs. */\n    int acl_errpos;\n    int acl_retval = ACLCheckAllPerm(c,&acl_errpos);\n    if (acl_retval != ACL_OK) {\n        addACLLogEntry(c,acl_retval,acl_errpos,NULL);\n        switch (acl_retval) {\n        case ACL_DENIED_CMD:\n            rejectCommandFormat(c,\n                \"-NOPERM this user has no permissions to run \"\n                \"the '%s' command or its subcommand\", c->cmd->name);\n            break;\n        case ACL_DENIED_KEY:\n            rejectCommandFormat(c,\n                \"-NOPERM this user has no permissions to access \"\n                \"one of the keys used as arguments\");\n            break;\n        case ACL_DENIED_CHANNEL:\n            rejectCommandFormat(c,\n                \"-NOPERM this user has no permissions to access \"\n                \"one of the channels used as arguments\");\n            break;\n        default:\n            rejectCommandFormat(c, \"no permission\");\n            break;\n        }\n        return C_OK;\n    }\n\n    /* If cluster is enabled perform the cluster redirection here.\n     * However we don't perform the redirection if:\n     * 1) The sender of this command is our master.\n     * 2) The command has no key arguments. */\n    if (server.cluster_enabled &&\n        !(c->flags & CLIENT_MASTER) &&\n        !(c->flags & CLIENT_LUA &&\n          server.lua_caller->flags & CLIENT_MASTER) &&\n        !(!cmdHasMovableKeys(c->cmd) && c->cmd->firstkey == 0 &&\n          c->cmd->proc != execCommand))\n    {\n        int hashslot;\n        int error_code;\n        clusterNode *n = getNodeByQuery(c,c->cmd,c->argv,c->argc,\n                                        &hashslot,&error_code);\n        if (n == NULL || n != server.cluster->myself) {\n            if (c->cmd->proc == execCommand) {\n                discardTransaction(c);\n            } else {\n                flagTransaction(c);\n            }\n            clusterRedirectClient(c,n,hashslot,error_code);\n            c->cmd->rejected_calls++;\n            return C_OK;\n        }\n    }\n\n    /* Handle the maxmemory directive.\n     *\n     * Note that we do not want to reclaim memory if we are here re-entering\n     * the event loop since there is a busy Lua script running in timeout\n     * condition, to avoid mixing the propagation of scripts with the\n     * propagation of DELs due to eviction. */\n    if (server.maxmemory && !server.lua_timedout) {\n        int out_of_memory = (performEvictions() == EVICT_FAIL);\n        /* performEvictions may flush slave output buffers. This may result\n         * in a slave, that may be the active client, to be freed. */\n        if (server.current_client == NULL) return C_ERR;\n\n        int reject_cmd_on_oom = is_denyoom_command;\n        /* If client is in MULTI/EXEC context, queuing may consume an unlimited\n         * amount of memory, so we want to stop that.\n         * However, we never want to reject DISCARD, or even EXEC (unless it\n         * contains denied commands, in which case is_denyoom_command is already\n         * set. */\n        if (c->flags & CLIENT_MULTI &&\n            c->cmd->proc != execCommand &&\n            c->cmd->proc != discardCommand &&\n            c->cmd->proc != resetCommand) {\n            reject_cmd_on_oom = 1;\n        }\n\n        if (out_of_memory && reject_cmd_on_oom) {\n            rejectCommand(c, shared.oomerr);\n            return C_OK;\n        }\n\n        /* Save out_of_memory result at script start, otherwise if we check OOM\n         * until first write within script, memory used by lua stack and\n         * arguments might interfere. */\n        if (c->cmd->proc == evalCommand || c->cmd->proc == evalShaCommand) {\n            server.lua_oom = out_of_memory;\n        }\n    }\n\n    /* Make sure to use a reasonable amount of memory for client side\n     * caching metadata. */\n    if (server.tracking_clients) trackingLimitUsedSlots();\n\n    /* Don't accept write commands if there are problems persisting on disk\n     * and if this is a master instance. */\n    int deny_write_type = writeCommandsDeniedByDiskError();\n    if (deny_write_type != DISK_ERROR_TYPE_NONE &&\n        server.masterhost == NULL &&\n        (is_write_command ||c->cmd->proc == pingCommand))\n    {\n        if (deny_write_type == DISK_ERROR_TYPE_RDB)\n            rejectCommand(c, shared.bgsaveerr);\n        else\n            rejectCommandFormat(c,\n                \"-MISCONF Errors writing to the AOF file: %s\",\n                strerror(server.aof_last_write_errno));\n        return C_OK;\n    }\n\n    /* Don't accept write commands if there are not enough good slaves and\n     * user configured the min-slaves-to-write option. */\n    if (server.masterhost == NULL &&\n        server.repl_min_slaves_to_write &&\n        server.repl_min_slaves_max_lag &&\n        is_write_command &&\n        server.repl_good_slaves_count < server.repl_min_slaves_to_write)\n    {\n        rejectCommand(c, shared.noreplicaserr);\n        return C_OK;\n    }\n\n    /* Don't accept write commands if this is a read only slave. But\n     * accept write commands if this is our master. */\n    if (server.masterhost && server.repl_slave_ro &&\n        !(c->flags & CLIENT_MASTER) &&\n        is_write_command)\n    {\n        rejectCommand(c, shared.roslaveerr);\n        return C_OK;\n    }\n\n    /* Only allow a subset of commands in the context of Pub/Sub if the\n     * connection is in RESP2 mode. With RESP3 there are no limits. */\n    if ((c->flags & CLIENT_PUBSUB && c->resp == 2) &&\n        c->cmd->proc != pingCommand &&\n        c->cmd->proc != subscribeCommand &&\n        c->cmd->proc != unsubscribeCommand &&\n        c->cmd->proc != psubscribeCommand &&\n        c->cmd->proc != punsubscribeCommand &&\n        c->cmd->proc != resetCommand) {\n        rejectCommandFormat(c,\n            \"Can't execute '%s': only (P)SUBSCRIBE / \"\n            \"(P)UNSUBSCRIBE / PING / QUIT / RESET are allowed in this context\",\n            c->cmd->name);\n        return C_OK;\n    }\n\n    /* Only allow commands with flag \"t\", such as INFO, SLAVEOF and so on,\n     * when slave-serve-stale-data is no and we are a slave with a broken\n     * link with master. */\n    if (server.masterhost && server.repl_state != REPL_STATE_CONNECTED &&\n        server.repl_serve_stale_data == 0 &&\n        is_denystale_command)\n    {\n        rejectCommand(c, shared.masterdownerr);\n        return C_OK;\n    }\n\n    /* Loading DB? Return an error if the command has not the\n     * CMD_LOADING flag. */\n    if (server.loading && is_denyloading_command) {\n        rejectCommand(c, shared.loadingerr);\n        return C_OK;\n    }\n\n    /* Lua script too slow? Only allow a limited number of commands.\n     * Note that we need to allow the transactions commands, otherwise clients\n     * sending a transaction with pipelining without error checking, may have\n     * the MULTI plus a few initial commands refused, then the timeout\n     * condition resolves, and the bottom-half of the transaction gets\n     * executed, see Github PR #7022. */\n    if (server.lua_timedout &&\n          c->cmd->proc != authCommand &&\n          c->cmd->proc != helloCommand &&\n          c->cmd->proc != replconfCommand &&\n          c->cmd->proc != multiCommand &&\n          c->cmd->proc != discardCommand &&\n          c->cmd->proc != watchCommand &&\n          c->cmd->proc != unwatchCommand &&\n          c->cmd->proc != resetCommand &&\n        !(c->cmd->proc == shutdownCommand &&\n          c->argc == 2 &&\n          tolower(((char*)c->argv[1]->ptr)[0]) == 'n') &&\n        !(c->cmd->proc == scriptCommand &&\n          c->argc == 2 &&\n          tolower(((char*)c->argv[1]->ptr)[0]) == 'k'))\n    {\n        rejectCommand(c, shared.slowscripterr);\n        return C_OK;\n    }\n\n    /* Prevent a replica from sending commands that access the keyspace.\n     * The main objective here is to prevent abuse of client pause check\n     * from which replicas are exempt. */\n    if ((c->flags & CLIENT_SLAVE) && (is_may_replicate_command || is_write_command || is_read_command)) {\n        rejectCommandFormat(c, \"Replica can't interract with the keyspace\");\n        return C_OK;\n    }\n\n    /* If the server is paused, block the client until\n     * the pause has ended. Replicas are never paused. */\n    if (!(c->flags & CLIENT_SLAVE) && \n        ((server.client_pause_type == CLIENT_PAUSE_ALL) ||\n        (server.client_pause_type == CLIENT_PAUSE_WRITE && is_may_replicate_command)))\n    {\n        c->bpop.timeout = 0;\n        blockClient(c,BLOCKED_PAUSE);\n        return C_OK;       \n    }\n\n    /* Exec the command */\n    if (c->flags & CLIENT_MULTI &&\n        c->cmd->proc != execCommand && c->cmd->proc != discardCommand &&\n        c->cmd->proc != multiCommand && c->cmd->proc != watchCommand &&\n        c->cmd->proc != resetCommand)\n    {\n        queueMultiCommand(c);\n        addReply(c,shared.queued);\n    } else {\n        call(c,CMD_CALL_FULL);\n        c->woff = server.master_repl_offset;\n        if (listLength(server.ready_keys))\n            handleClientsBlockedOnKeys();\n    }\n\n    return C_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -40,6 +40,8 @@\n         return C_OK;\n     }\n \n+    int is_read_command = (c->cmd->flags & CMD_READONLY) ||\n+                           (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_READONLY));\n     int is_write_command = (c->cmd->flags & CMD_WRITE) ||\n                            (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_WRITE));\n     int is_denyoom_command = (c->cmd->flags & CMD_DENYOOM) ||\n@@ -249,7 +251,7 @@\n           c->cmd->proc != discardCommand &&\n           c->cmd->proc != watchCommand &&\n           c->cmd->proc != unwatchCommand &&\n-\t  c->cmd->proc != resetCommand &&\n+          c->cmd->proc != resetCommand &&\n         !(c->cmd->proc == shutdownCommand &&\n           c->argc == 2 &&\n           tolower(((char*)c->argv[1]->ptr)[0]) == 'n') &&\n@@ -258,6 +260,14 @@\n           tolower(((char*)c->argv[1]->ptr)[0]) == 'k'))\n     {\n         rejectCommand(c, shared.slowscripterr);\n+        return C_OK;\n+    }\n+\n+    /* Prevent a replica from sending commands that access the keyspace.\n+     * The main objective here is to prevent abuse of client pause check\n+     * from which replicas are exempt. */\n+    if ((c->flags & CLIENT_SLAVE) && (is_may_replicate_command || is_write_command || is_read_command)) {\n+        rejectCommandFormat(c, \"Replica can't interract with the keyspace\");\n         return C_OK;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t  c->cmd->proc != resetCommand &&"
            ],
            "added_lines": [
                "    int is_read_command = (c->cmd->flags & CMD_READONLY) ||",
                "                           (c->cmd->proc == execCommand && (c->mstate.cmd_flags & CMD_READONLY));",
                "          c->cmd->proc != resetCommand &&",
                "        return C_OK;",
                "    }",
                "",
                "    /* Prevent a replica from sending commands that access the keyspace.",
                "     * The main objective here is to prevent abuse of client pause check",
                "     * from which replicas are exempt. */",
                "    if ((c->flags & CLIENT_SLAVE) && (is_may_replicate_command || is_write_command || is_read_command)) {",
                "        rejectCommandFormat(c, \"Replica can't interract with the keyspace\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-6461",
        "func_name": "cairo/_cairo_arc_in_direction",
        "description": "An issue was discovered in cairo 1.16.0. There is an assertion problem in the function _cairo_arc_in_direction in the file cairo-arc.c.",
        "git_url": "https://cgit.freedesktop.org/cairo/commit/?id=86d7025af513ac012961cfc6fdee99249342b8e7",
        "commit_title": "Avoid assert when drawing arcs with NaN angles",
        "commit_text": " Closes #352  See merge request cairo/cairo!515",
        "func_before": "static void\n_cairo_arc_in_direction (cairo_t\t  *cr,\n\t\t\t double\t\t   xc,\n\t\t\t double\t\t   yc,\n\t\t\t double\t\t   radius,\n\t\t\t double\t\t   angle_min,\n\t\t\t double\t\t   angle_max,\n\t\t\t cairo_direction_t dir)\n{\n    if (cairo_status (cr))\n        return;\n\n    assert (angle_max >= angle_min);\n\n    if (angle_max - angle_min > 2 * M_PI * MAX_FULL_CIRCLES) {\n\tangle_max = fmod (angle_max - angle_min, 2 * M_PI);\n\tangle_min = fmod (angle_min, 2 * M_PI);\n\tangle_max += angle_min + 2 * M_PI * MAX_FULL_CIRCLES;\n    }\n\n    /* Recurse if drawing arc larger than pi */\n    if (angle_max - angle_min > M_PI) {\n\tdouble angle_mid = angle_min + (angle_max - angle_min) / 2.0;\n\tif (dir == CAIRO_DIRECTION_FORWARD) {\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_min, angle_mid,\n\t\t\t\t     dir);\n\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_mid, angle_max,\n\t\t\t\t     dir);\n\t} else {\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_mid, angle_max,\n\t\t\t\t     dir);\n\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_min, angle_mid,\n\t\t\t\t     dir);\n\t}\n    } else if (angle_max != angle_min) {\n\tcairo_matrix_t ctm;\n\tint i, segments;\n\tdouble step;\n\n\tcairo_get_matrix (cr, &ctm);\n\tsegments = _arc_segments_needed (angle_max - angle_min,\n\t\t\t\t\t radius, &ctm,\n\t\t\t\t\t cairo_get_tolerance (cr));\n\tstep = (angle_max - angle_min) / segments;\n\tsegments -= 1;\n\n\tif (dir == CAIRO_DIRECTION_REVERSE) {\n\t    double t;\n\n\t    t = angle_min;\n\t    angle_min = angle_max;\n\t    angle_max = t;\n\n\t    step = -step;\n\t}\n\n\tcairo_line_to (cr,\n\t\t       xc + radius * cos (angle_min),\n\t\t       yc + radius * sin (angle_min));\n\n\tfor (i = 0; i < segments; i++, angle_min += step) {\n\t    _cairo_arc_segment (cr, xc, yc, radius,\n\t\t\t\tangle_min, angle_min + step);\n\t}\n\n\t_cairo_arc_segment (cr, xc, yc, radius,\n\t\t\t    angle_min, angle_max);\n    } else {\n\tcairo_line_to (cr,\n\t\t       xc + radius * cos (angle_min),\n\t\t       yc + radius * sin (angle_min));\n    }\n}",
        "func": "static void\n_cairo_arc_in_direction (cairo_t\t  *cr,\n\t\t\t double\t\t   xc,\n\t\t\t double\t\t   yc,\n\t\t\t double\t\t   radius,\n\t\t\t double\t\t   angle_min,\n\t\t\t double\t\t   angle_max,\n\t\t\t cairo_direction_t dir)\n{\n    if (cairo_status (cr))\n        return;\n\n    if (! ISFINITE (angle_max) || ! ISFINITE (angle_min))\n        return;\n\n    assert (angle_max >= angle_min);\n\n    if (angle_max - angle_min > 2 * M_PI * MAX_FULL_CIRCLES) {\n\tangle_max = fmod (angle_max - angle_min, 2 * M_PI);\n\tangle_min = fmod (angle_min, 2 * M_PI);\n\tangle_max += angle_min + 2 * M_PI * MAX_FULL_CIRCLES;\n    }\n\n    /* Recurse if drawing arc larger than pi */\n    if (angle_max - angle_min > M_PI) {\n\tdouble angle_mid = angle_min + (angle_max - angle_min) / 2.0;\n\tif (dir == CAIRO_DIRECTION_FORWARD) {\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_min, angle_mid,\n\t\t\t\t     dir);\n\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_mid, angle_max,\n\t\t\t\t     dir);\n\t} else {\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_mid, angle_max,\n\t\t\t\t     dir);\n\n\t    _cairo_arc_in_direction (cr, xc, yc, radius,\n\t\t\t\t     angle_min, angle_mid,\n\t\t\t\t     dir);\n\t}\n    } else if (angle_max != angle_min) {\n\tcairo_matrix_t ctm;\n\tint i, segments;\n\tdouble step;\n\n\tcairo_get_matrix (cr, &ctm);\n\tsegments = _arc_segments_needed (angle_max - angle_min,\n\t\t\t\t\t radius, &ctm,\n\t\t\t\t\t cairo_get_tolerance (cr));\n\tstep = (angle_max - angle_min) / segments;\n\tsegments -= 1;\n\n\tif (dir == CAIRO_DIRECTION_REVERSE) {\n\t    double t;\n\n\t    t = angle_min;\n\t    angle_min = angle_max;\n\t    angle_max = t;\n\n\t    step = -step;\n\t}\n\n\tcairo_line_to (cr,\n\t\t       xc + radius * cos (angle_min),\n\t\t       yc + radius * sin (angle_min));\n\n\tfor (i = 0; i < segments; i++, angle_min += step) {\n\t    _cairo_arc_segment (cr, xc, yc, radius,\n\t\t\t\tangle_min, angle_min + step);\n\t}\n\n\t_cairo_arc_segment (cr, xc, yc, radius,\n\t\t\t    angle_min, angle_max);\n    } else {\n\tcairo_line_to (cr,\n\t\t       xc + radius * cos (angle_min),\n\t\t       yc + radius * sin (angle_min));\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,9 @@\n \t\t\t cairo_direction_t dir)\n {\n     if (cairo_status (cr))\n+        return;\n+\n+    if (! ISFINITE (angle_max) || ! ISFINITE (angle_min))\n         return;\n \n     assert (angle_max >= angle_min);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        return;",
                "",
                "    if (! ISFINITE (angle_max) || ! ISFINITE (angle_min))"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-7662",
        "func_name": "WebAssembly/binaryen/WasmBinaryBuilder::getType",
        "description": "An assertion failure was discovered in wasm::WasmBinaryBuilder::getType() in wasm-binary.cpp in Binaryen 1.38.22. This allows remote attackers to cause a denial of service (failed assertion and crash) via a crafted wasm file.",
        "git_url": "https://github.com/WebAssembly/binaryen/commit/0e5e55053c171b138a0cf5aa8a08de8c7714048f",
        "commit_title": "Show a proper error on an invalid type in binary reading ; fixes #1872 (#1874)",
        "commit_text": "",
        "func_before": "Type WasmBinaryBuilder::getType() {\n  int type = getS32LEB();\n  switch (type) {\n    // None only used for block signatures. TODO: Separate out?\n    case BinaryConsts::EncodedType::Empty: return none;\n    case BinaryConsts::EncodedType::i32: return i32;\n    case BinaryConsts::EncodedType::i64: return i64;\n    case BinaryConsts::EncodedType::f32: return f32;\n    case BinaryConsts::EncodedType::f64: return f64;\n    case BinaryConsts::EncodedType::v128: return v128;\n    case BinaryConsts::EncodedType::AnyFunc:\n    case BinaryConsts::EncodedType::Func:\n      throwError(\"invalid wasm type: \" + std::to_string(type));\n  }\n  WASM_UNREACHABLE();\n}",
        "func": "Type WasmBinaryBuilder::getType() {\n  int type = getS32LEB();\n  switch (type) {\n    // None only used for block signatures. TODO: Separate out?\n    case BinaryConsts::EncodedType::Empty: return none;\n    case BinaryConsts::EncodedType::i32: return i32;\n    case BinaryConsts::EncodedType::i64: return i64;\n    case BinaryConsts::EncodedType::f32: return f32;\n    case BinaryConsts::EncodedType::f64: return f64;\n    case BinaryConsts::EncodedType::v128: return v128;\n    default: {\n      throwError(\"invalid wasm type: \" + std::to_string(type));\n    }\n  }\n  WASM_UNREACHABLE();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,9 +8,9 @@\n     case BinaryConsts::EncodedType::f32: return f32;\n     case BinaryConsts::EncodedType::f64: return f64;\n     case BinaryConsts::EncodedType::v128: return v128;\n-    case BinaryConsts::EncodedType::AnyFunc:\n-    case BinaryConsts::EncodedType::Func:\n+    default: {\n       throwError(\"invalid wasm type: \" + std::to_string(type));\n+    }\n   }\n   WASM_UNREACHABLE();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    case BinaryConsts::EncodedType::AnyFunc:",
                "    case BinaryConsts::EncodedType::Func:"
            ],
            "added_lines": [
                "    default: {",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-10894",
        "func_name": "wireshark/dissect_gssapi_work",
        "description": "In Wireshark 2.4.0 to 2.4.13, 2.6.0 to 2.6.7, and 3.0.0, the GSS-API dissector could crash. This was addressed in epan/dissectors/packet-gssapi.c by ensuring that a valid dissector is called.",
        "git_url": "https://github.com/wireshark/wireshark/commit/b20e5d8aae2580e29c83ddaf0b6b2e640603e4aa",
        "commit_title": "GSS-API: Make sure we call a valid dissector.",
        "commit_text": " Make our unknown dissector handle logic conistent with other parts of the code.  Conflicts: \tepan/dissectors/packet-gssapi.c  Bug: 15613 (cherry picked from commit 8cdc95842687feee32856afba8e7087396082158) (cherry picked from commit ea75daa28bd6bd6911fd14a8b1734004269a18b8)",
        "func_before": "static int\ndissect_gssapi_work(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,\n\t\t    gboolean is_verifier, gssapi_encrypt_info_t* encrypt_info)\n{\n\tproto_item *volatile item;\n\tproto_tree *volatile subtree;\n\tvolatile int return_offset = 0;\n\tgssapi_conv_info_t *volatile gss_info;\n\tgssapi_oid_value *oidvalue;\n\tdissector_handle_t handle;\n\tconversation_t *conversation;\n\ttvbuff_t *oid_tvb;\n\tint len, start_offset, oid_start_offset;\n\tvolatile int offset;\n\tgint8 appclass;\n\tgboolean pc, ind_field;\n\tgint32 tag;\n\tguint32 len1;\n\tconst char *oid;\n\tfragment_head *fd_head=NULL;\n\tgssapi_frag_info_t *fi;\n\ttvbuff_t *volatile gss_tvb=NULL;\n\tasn1_ctx_t asn1_ctx;\n\n\tstart_offset=0;\n\toffset=0;\n\tasn1_ctx_init(&asn1_ctx, ASN1_ENC_BER, TRUE, pinfo);\n\t/*\n\t * We don't know whether the data is encrypted, so say it's\n\t * not, for now.  The subdissector must set gssapi_data_encrypted\n\t * if it is.\n\t */\n\tencrypt_info->gssapi_data_encrypted = FALSE;\n\n\n\t/*\n\t * We need a conversation for later\n\t */\n\tconversation = find_or_create_conversation(pinfo);\n\n\tgss_info = (gssapi_conv_info_t *)conversation_get_proto_data(conversation, proto_gssapi);\n\tif (!gss_info) {\n\t\tgss_info = wmem_new(wmem_file_scope(), gssapi_conv_info_t);\n\t\tgss_info->oid=NULL;\n\t\tgss_info->do_reassembly=FALSE;\n\t\tgss_info->frags=wmem_tree_new(wmem_file_scope());\n\n\t\tconversation_add_proto_data(conversation, proto_gssapi, gss_info);\n\t}\n\n\titem = proto_tree_add_item(\n\t\ttree, proto_gssapi, tvb, offset, -1, ENC_NA);\n\n\tsubtree = proto_item_add_subtree(item, ett_gssapi);\n\n\t/*\n\t * Catch the ReportedBoundsError exception; the stuff we've been\n\t * handed doesn't necessarily run to the end of the packet, it's\n\t * an item inside a packet, so if it happens to be malformed (or\n\t * we, or a dissector we call, has a bug), so that an exception\n\t * is thrown, we want to report the error, but return and let\n\t * our caller dissect the rest of the packet.\n\t *\n\t * If it gets a BoundsError, we can stop, as there's nothing more\n\t * in the packet after our blob to see, so we just re-throw the\n\t * exception.\n\t */\n\tTRY {\n\t\tgss_tvb=tvb;\n\n\n\t\t/* First of all, if it's the first time we see this packet\n\t\t * then check whether we are in the middle of reassembly or not\n\t\t */\n\t\tif( (!pinfo->fd->flags.visited)\n\t\t&&  (gss_info->do_reassembly)\n\t\t&&  (gssapi_reassembly) ){\n\t\t\tfi=(gssapi_frag_info_t *)wmem_tree_lookup32(gss_info->frags, gss_info->first_frame);\n\t\t\tif(!fi){\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\twmem_tree_insert32(gss_info->frags, pinfo->num, fi);\n\t\t\tfd_head=fragment_add(&gssapi_reassembly_table,\n\t\t\t\ttvb, 0, pinfo, fi->first_frame, NULL,\n\t\t\t\tgss_info->frag_offset,\n\t\t\t\ttvb_captured_length(tvb), TRUE);\n\t\t\tgss_info->frag_offset+=tvb_captured_length(tvb);\n\n\t\t\t/* we need more fragments */\n\t\t\tif(!fd_head){\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* this blob is now fully reassembled */\n\t\t\tgss_info->do_reassembly=FALSE;\n\t\t\tfi->reassembled_in=pinfo->num;\n\n\t\t\tgss_tvb=tvb_new_chain(tvb, fd_head->tvb_data);\n\t\t\tadd_new_data_source(pinfo, gss_tvb, \"Reassembled GSSAPI\");\n\t\t}\n\t\t/* We have seen this packet before.\n\t\t * Is this blob part of reassembly or a normal blob ?\n\t\t */\n\t\tif( (pinfo->fd->flags.visited)\n\t\t&&  (gssapi_reassembly) ){\n\t\t\tfi=(gssapi_frag_info_t *)wmem_tree_lookup32(gss_info->frags, pinfo->num);\n\t\t\tif(fi){\n\t\t\t\tfd_head=fragment_get(&gssapi_reassembly_table,\n\t\t\t\t\tpinfo, fi->first_frame, NULL);\n\t\t\t\tif(fd_head && (fd_head->flags&FD_DEFRAGMENTED)){\n\t\t\t\t\tif(pinfo->num==fi->reassembled_in){\n\t\t\t\t\t        proto_item *frag_tree_item;\n\t\t\t\t\t\tgss_tvb=tvb_new_chain(tvb, fd_head->tvb_data);\n\t\t\t\t\t\tadd_new_data_source(pinfo, gss_tvb, \"Reassembled GSSAPI\");\n\t\t\t\t\t\tshow_fragment_tree(fd_head, &gssapi_frag_items, tree, pinfo, tvb, &frag_tree_item);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tproto_item *it;\n\t\t\t\t\t\tit=proto_tree_add_uint(tree, hf_gssapi_reassembled_in, tvb, 0, 0, fi->reassembled_in);\n\t\t\t\t\t        PROTO_ITEM_SET_GENERATED(it);\n\t\t\t\t\t\tgoto done;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* Read header */\n\t\toffset = get_ber_identifier(gss_tvb, offset, &appclass, &pc, &tag);\n\t\toffset = get_ber_length(gss_tvb, offset, &len1, &ind_field);\n\n\n\t\tif (!(appclass == BER_CLASS_APP && pc && tag == 0)) {\n\t\t  /* It could be NTLMSSP, with no OID.  This can happen\n\t\t     for anything that microsoft calls 'Negotiate' or GSS-SPNEGO */\n\t\t\tif ((tvb_captured_length_remaining(gss_tvb, start_offset)>7) && (tvb_strneql(gss_tvb, start_offset, \"NTLMSSP\", 7) == 0)) {\n\t\t\t\treturn_offset = call_dissector(ntlmssp_handle,\n\t\t\t\t\t\t\ttvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t\tpinfo, subtree);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\t/* Maybe it's new NTLMSSP payload */\n\t\t\tif ((tvb_captured_length_remaining(gss_tvb, start_offset)>16) &&\n\t\t\t   ((tvb_memeql(gss_tvb, start_offset, \"\\x01\\x00\\x00\\x00\", 4) == 0))) {\n\t\t\t\treturn_offset = call_dissector(ntlmssp_payload_handle,\n\t\t\t\t\t\t\ttvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t\tpinfo, subtree);\n\t\t\t\tencrypt_info->gssapi_data_encrypted = TRUE;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tif ((tvb_captured_length_remaining(gss_tvb, start_offset)==16) &&\n\t\t\t   ((tvb_memeql(gss_tvb, start_offset, \"\\x01\\x00\\x00\\x00\", 4) == 0))) {\n\t\t\t\tif( is_verifier ) {\n\t\t\t\t\treturn_offset = call_dissector(ntlmssp_verf_handle,\n\t\t\t\t\t\t\t\t\ttvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t\t\t\tpinfo, subtree);\n\t\t\t\t}\n\t\t\t\telse if( encrypt_info->gssapi_encrypted_tvb ) {\n\t\t\t\t\treturn_offset = call_dissector_with_data(ntlmssp_data_only_handle,\n\t\t\t\t\t\t\t\t\ttvb_new_subset_remaining(encrypt_info->gssapi_encrypted_tvb, 0),\n\t\t\t\t\t\t\t\t\tpinfo, subtree, &encrypt_info->gssapi_decrypted_tvb);\n\t\t\t\t\tencrypt_info->gssapi_data_encrypted = TRUE;\n\t\t\t\t}\n\t\t   \t\tgoto done;\n\t\t  \t}\n\n\t\t  /* Maybe it's new GSSKRB5 CFX Wrapping */\n\t\t  if ((tvb_captured_length_remaining(gss_tvb, start_offset)>2) &&\n\t\t      ((tvb_memeql(gss_tvb, start_offset, \"\\04\\x04\", 2) == 0) ||\n\t\t       (tvb_memeql(gss_tvb, start_offset, \"\\05\\x04\", 2) == 0))) {\n\t\t    return_offset = call_dissector_with_data(spnego_krb5_wrap_handle,\n\t\t\t\t\t\t   tvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t   pinfo, subtree, encrypt_info);\n\t\t    goto done;\n\t\t  }\n\n\t\t  /*\n\t\t   * If we do not recognise an Application class,\n\t\t   * then we are probably dealing with an inner context\n\t\t   * token or a wrap token, and we should retrieve the\n\t\t   * gssapi_oid_value pointer from the per-frame data or,\n\t\t   * if there is no per-frame data (as would be the case\n\t\t   * the first time we dissect this frame), from the\n\t\t   * conversation that exists or that we created from\n\t\t   * pinfo (and then make it per-frame data).\n\t\t   * We need to make it per-frame data as there can be\n\t\t   * more than one GSS-API negotiation in a conversation.\n\t\t   *\n\t\t   * Note! We \"cheat\". Since we only need the pointer,\n\t\t   * we store that as the data.  (That's not really\n\t\t   * \"cheating\" - the per-frame data and per-conversation\n\t\t   * data code doesn't care what you supply as a data\n\t\t   * pointer; it just treats it as an opaque pointer, it\n\t\t   * doesn't dereference it or free what it points to.)\n\t\t   */\n\t\t  oidvalue = (gssapi_oid_value *)p_get_proto_data(wmem_file_scope(), pinfo, proto_gssapi, 0);\n\t\t  if (!oidvalue && !pinfo->fd->flags.visited)\n\t\t  {\n\t\t    /* No handle attached to this frame, but it's the first */\n\t\t    /* pass, so it'd be attached to the conversation. */\n\t\t    oidvalue = gss_info->oid;\n\t\t    if (gss_info->oid)\n\t\t      p_add_proto_data(wmem_file_scope(), pinfo, proto_gssapi, 0, gss_info->oid);\n\t\t  }\n\t\t  if (!oidvalue)\n\t\t  {\n\t\t\t  proto_tree_add_expert_format(subtree, pinfo, &ei_gssapi_unknown_header, gss_tvb, start_offset, 0,\n\t\t\t\t\t      \"Unknown header (class=%d, pc=%d, tag=%d)\",\n\t\t\t\t\t      appclass, pc, tag);\n\t\t    return_offset = tvb_captured_length(gss_tvb);\n\t\t    goto done;\n\t\t  } else {\n\t\t    tvbuff_t *oid_tvb_local;\n\n\t\t    oid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);\n\t\t    if (is_verifier)\n\t\t\thandle = oidvalue->wrap_handle;\n\t\t    else\n\t\t\thandle = oidvalue->handle;\n\t\t    len = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);\n\t\t    if (len == 0)\n\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t    else\n\t\t\treturn_offset = start_offset + len;\n\t\t    goto done; /* We are finished here */\n\t\t  }\n\t\t}\n\n\t\t/* Read oid */\n\t\toid_start_offset=offset;\n\t\toffset=dissect_ber_object_identifier_str(FALSE, &asn1_ctx, subtree, gss_tvb, offset, hf_gssapi_oid, &oid);\n\t\toidvalue = gssapi_lookup_oid_str(oid);\n\n\n\t\t/* Check if we need reassembly of this blob.\n\t\t * Only try reassembly for OIDs we recognize\n\t\t * and when we have the entire tvb\n\t\t *\n\t\t * SMB will sometimes split one large GSSAPI blob\n\t\t * across multiple SMB/SessionSetup commands.\n\t\t * While we should look at the uid returned in the response\n\t\t * to the first SessionSetup and use that as a key\n\t\t * instead for simplicity we assume there will not be several\n\t\t * such authentication at once on a single tcp session\n\t\t */\n\t\tif( (!pinfo->fd->flags.visited)\n\t\t&&  (oidvalue)\n\t\t&&  (tvb_captured_length(gss_tvb)==tvb_reported_length(gss_tvb))\n\t\t&&  (len1>(guint32)tvb_captured_length_remaining(gss_tvb, oid_start_offset))\n\t\t&&  (gssapi_reassembly) ){\n\t\t\tfi=wmem_new(wmem_file_scope(), gssapi_frag_info_t);\n\t\t\tfi->first_frame=pinfo->num;\n\t\t\tfi->reassembled_in=0;\n\t\t\twmem_tree_insert32(gss_info->frags, pinfo->num, fi);\n\n\t\t\tfragment_add(&gssapi_reassembly_table,\n\t\t\t\tgss_tvb, 0, pinfo, pinfo->num, NULL,\n\t\t\t\t0, tvb_captured_length(gss_tvb), TRUE);\n\t\t\tfragment_set_tot_len(&gssapi_reassembly_table,\n\t\t\t\tpinfo, pinfo->num, NULL, len1+oid_start_offset);\n\n\t\t\tgss_info->do_reassembly=TRUE;\n\t\t\tgss_info->first_frame=pinfo->num;\n\t\t\tgss_info->frag_offset=tvb_captured_length(gss_tvb);\n\t\t\tgoto done;\n\t\t}\n\n\n\t\t/*\n\t\t * Hand off to subdissector.\n\t\t */\n\n\t\tif ((oidvalue == NULL) ||\n\t\t    !proto_is_protocol_enabled(oidvalue->proto)) {\n\t\t\t/* No dissector for this oid */\n\t\t\tproto_tree_add_item(subtree, hf_gssapi_token_object, gss_tvb, oid_start_offset, -1, ENC_NA);\n\n\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Save a pointer to the data for the OID for the\n\t\t * GSSAPI protocol for this conversation.\n\t\t */\n\n\t\t/*\n\t\t * Now add the proto data ...\n\t\t * but only if it is not already there.\n\t\t */\n\t\tif(!gss_info->oid){\n\t\t  gss_info->oid=oidvalue;\n\t\t}\n\n\t\tif (is_verifier) {\n\t\t\thandle = oidvalue->wrap_handle;\n\t\t\tif (handle != NULL) {\n\t\t\t\toid_tvb = tvb_new_subset_remaining(gss_tvb, offset);\n\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb, pinfo, subtree, encrypt_info);\n\t\t\t\tif (len == 0)\n\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\telse\n\t\t\t\t\treturn_offset = offset + len;\n\t\t\t} else {\n\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_verifier, gss_tvb, offset, -1, ENC_NA);\n\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t}\n\t\t} else {\n\t\t\thandle = oidvalue->handle;\n\t\t\tif (handle != NULL) {\n\t\t\t\toid_tvb = tvb_new_subset_remaining(gss_tvb, offset);\n\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb, pinfo, subtree, encrypt_info);\n\t\t\t\tif (len == 0)\n\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\telse\n\t\t\t\t\treturn_offset = offset + len;\n\t\t\t} else {\n\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_credentials, gss_tvb, offset, -1, ENC_NA);\n\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t}\n\t\t}\n\n\t done:\n\t\t;\n\t}",
        "func": "static int\ndissect_gssapi_work(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree,\n\t\t    gboolean is_verifier, gssapi_encrypt_info_t* encrypt_info)\n{\n\tproto_item *volatile item;\n\tproto_tree *volatile subtree;\n\tvolatile int return_offset = 0;\n\tgssapi_conv_info_t *volatile gss_info;\n\tgssapi_oid_value *oidvalue;\n\tdissector_handle_t handle;\n\tconversation_t *conversation;\n\ttvbuff_t *oid_tvb;\n\tint len, start_offset, oid_start_offset;\n\tvolatile int offset;\n\tgint8 appclass;\n\tgboolean pc, ind_field;\n\tgint32 tag;\n\tguint32 len1;\n\tconst char *oid;\n\tfragment_head *fd_head=NULL;\n\tgssapi_frag_info_t *fi;\n\ttvbuff_t *volatile gss_tvb=NULL;\n\tasn1_ctx_t asn1_ctx;\n\n\tstart_offset=0;\n\toffset=0;\n\tasn1_ctx_init(&asn1_ctx, ASN1_ENC_BER, TRUE, pinfo);\n\t/*\n\t * We don't know whether the data is encrypted, so say it's\n\t * not, for now.  The subdissector must set gssapi_data_encrypted\n\t * if it is.\n\t */\n\tencrypt_info->gssapi_data_encrypted = FALSE;\n\n\n\t/*\n\t * We need a conversation for later\n\t */\n\tconversation = find_or_create_conversation(pinfo);\n\n\tgss_info = (gssapi_conv_info_t *)conversation_get_proto_data(conversation, proto_gssapi);\n\tif (!gss_info) {\n\t\tgss_info = wmem_new(wmem_file_scope(), gssapi_conv_info_t);\n\t\tgss_info->oid=NULL;\n\t\tgss_info->do_reassembly=FALSE;\n\t\tgss_info->frags=wmem_tree_new(wmem_file_scope());\n\n\t\tconversation_add_proto_data(conversation, proto_gssapi, gss_info);\n\t}\n\n\titem = proto_tree_add_item(\n\t\ttree, proto_gssapi, tvb, offset, -1, ENC_NA);\n\n\tsubtree = proto_item_add_subtree(item, ett_gssapi);\n\n\t/*\n\t * Catch the ReportedBoundsError exception; the stuff we've been\n\t * handed doesn't necessarily run to the end of the packet, it's\n\t * an item inside a packet, so if it happens to be malformed (or\n\t * we, or a dissector we call, has a bug), so that an exception\n\t * is thrown, we want to report the error, but return and let\n\t * our caller dissect the rest of the packet.\n\t *\n\t * If it gets a BoundsError, we can stop, as there's nothing more\n\t * in the packet after our blob to see, so we just re-throw the\n\t * exception.\n\t */\n\tTRY {\n\t\tgss_tvb=tvb;\n\n\n\t\t/* First of all, if it's the first time we see this packet\n\t\t * then check whether we are in the middle of reassembly or not\n\t\t */\n\t\tif( (!pinfo->fd->flags.visited)\n\t\t&&  (gss_info->do_reassembly)\n\t\t&&  (gssapi_reassembly) ){\n\t\t\tfi=(gssapi_frag_info_t *)wmem_tree_lookup32(gss_info->frags, gss_info->first_frame);\n\t\t\tif(!fi){\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\twmem_tree_insert32(gss_info->frags, pinfo->num, fi);\n\t\t\tfd_head=fragment_add(&gssapi_reassembly_table,\n\t\t\t\ttvb, 0, pinfo, fi->first_frame, NULL,\n\t\t\t\tgss_info->frag_offset,\n\t\t\t\ttvb_captured_length(tvb), TRUE);\n\t\t\tgss_info->frag_offset+=tvb_captured_length(tvb);\n\n\t\t\t/* we need more fragments */\n\t\t\tif(!fd_head){\n\t\t\t\tgoto done;\n\t\t\t}\n\n\t\t\t/* this blob is now fully reassembled */\n\t\t\tgss_info->do_reassembly=FALSE;\n\t\t\tfi->reassembled_in=pinfo->num;\n\n\t\t\tgss_tvb=tvb_new_chain(tvb, fd_head->tvb_data);\n\t\t\tadd_new_data_source(pinfo, gss_tvb, \"Reassembled GSSAPI\");\n\t\t}\n\t\t/* We have seen this packet before.\n\t\t * Is this blob part of reassembly or a normal blob ?\n\t\t */\n\t\tif( (pinfo->fd->flags.visited)\n\t\t&&  (gssapi_reassembly) ){\n\t\t\tfi=(gssapi_frag_info_t *)wmem_tree_lookup32(gss_info->frags, pinfo->num);\n\t\t\tif(fi){\n\t\t\t\tfd_head=fragment_get(&gssapi_reassembly_table,\n\t\t\t\t\tpinfo, fi->first_frame, NULL);\n\t\t\t\tif(fd_head && (fd_head->flags&FD_DEFRAGMENTED)){\n\t\t\t\t\tif(pinfo->num==fi->reassembled_in){\n\t\t\t\t\t        proto_item *frag_tree_item;\n\t\t\t\t\t\tgss_tvb=tvb_new_chain(tvb, fd_head->tvb_data);\n\t\t\t\t\t\tadd_new_data_source(pinfo, gss_tvb, \"Reassembled GSSAPI\");\n\t\t\t\t\t\tshow_fragment_tree(fd_head, &gssapi_frag_items, tree, pinfo, tvb, &frag_tree_item);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tproto_item *it;\n\t\t\t\t\t\tit=proto_tree_add_uint(tree, hf_gssapi_reassembled_in, tvb, 0, 0, fi->reassembled_in);\n\t\t\t\t\t        PROTO_ITEM_SET_GENERATED(it);\n\t\t\t\t\t\tgoto done;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* Read header */\n\t\toffset = get_ber_identifier(gss_tvb, offset, &appclass, &pc, &tag);\n\t\toffset = get_ber_length(gss_tvb, offset, &len1, &ind_field);\n\n\n\t\tif (!(appclass == BER_CLASS_APP && pc && tag == 0)) {\n\t\t  /* It could be NTLMSSP, with no OID.  This can happen\n\t\t     for anything that microsoft calls 'Negotiate' or GSS-SPNEGO */\n\t\t\tif ((tvb_captured_length_remaining(gss_tvb, start_offset)>7) && (tvb_strneql(gss_tvb, start_offset, \"NTLMSSP\", 7) == 0)) {\n\t\t\t\treturn_offset = call_dissector(ntlmssp_handle,\n\t\t\t\t\t\t\ttvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t\tpinfo, subtree);\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\t/* Maybe it's new NTLMSSP payload */\n\t\t\tif ((tvb_captured_length_remaining(gss_tvb, start_offset)>16) &&\n\t\t\t   ((tvb_memeql(gss_tvb, start_offset, \"\\x01\\x00\\x00\\x00\", 4) == 0))) {\n\t\t\t\treturn_offset = call_dissector(ntlmssp_payload_handle,\n\t\t\t\t\t\t\ttvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t\tpinfo, subtree);\n\t\t\t\tencrypt_info->gssapi_data_encrypted = TRUE;\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tif ((tvb_captured_length_remaining(gss_tvb, start_offset)==16) &&\n\t\t\t   ((tvb_memeql(gss_tvb, start_offset, \"\\x01\\x00\\x00\\x00\", 4) == 0))) {\n\t\t\t\tif( is_verifier ) {\n\t\t\t\t\treturn_offset = call_dissector(ntlmssp_verf_handle,\n\t\t\t\t\t\t\t\t\ttvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t\t\t\tpinfo, subtree);\n\t\t\t\t}\n\t\t\t\telse if( encrypt_info->gssapi_encrypted_tvb ) {\n\t\t\t\t\treturn_offset = call_dissector_with_data(ntlmssp_data_only_handle,\n\t\t\t\t\t\t\t\t\ttvb_new_subset_remaining(encrypt_info->gssapi_encrypted_tvb, 0),\n\t\t\t\t\t\t\t\t\tpinfo, subtree, &encrypt_info->gssapi_decrypted_tvb);\n\t\t\t\t\tencrypt_info->gssapi_data_encrypted = TRUE;\n\t\t\t\t}\n\t\t   \t\tgoto done;\n\t\t  \t}\n\n\t\t  /* Maybe it's new GSSKRB5 CFX Wrapping */\n\t\t  if ((tvb_captured_length_remaining(gss_tvb, start_offset)>2) &&\n\t\t      ((tvb_memeql(gss_tvb, start_offset, \"\\04\\x04\", 2) == 0) ||\n\t\t       (tvb_memeql(gss_tvb, start_offset, \"\\05\\x04\", 2) == 0))) {\n\t\t    return_offset = call_dissector_with_data(spnego_krb5_wrap_handle,\n\t\t\t\t\t\t   tvb_new_subset_remaining(gss_tvb, start_offset),\n\t\t\t\t\t\t   pinfo, subtree, encrypt_info);\n\t\t    goto done;\n\t\t  }\n\n\t\t  /*\n\t\t   * If we do not recognise an Application class,\n\t\t   * then we are probably dealing with an inner context\n\t\t   * token or a wrap token, and we should retrieve the\n\t\t   * gssapi_oid_value pointer from the per-frame data or,\n\t\t   * if there is no per-frame data (as would be the case\n\t\t   * the first time we dissect this frame), from the\n\t\t   * conversation that exists or that we created from\n\t\t   * pinfo (and then make it per-frame data).\n\t\t   * We need to make it per-frame data as there can be\n\t\t   * more than one GSS-API negotiation in a conversation.\n\t\t   *\n\t\t   * Note! We \"cheat\". Since we only need the pointer,\n\t\t   * we store that as the data.  (That's not really\n\t\t   * \"cheating\" - the per-frame data and per-conversation\n\t\t   * data code doesn't care what you supply as a data\n\t\t   * pointer; it just treats it as an opaque pointer, it\n\t\t   * doesn't dereference it or free what it points to.)\n\t\t   */\n\t\t  oidvalue = (gssapi_oid_value *)p_get_proto_data(wmem_file_scope(), pinfo, proto_gssapi, 0);\n\t\t  if (!oidvalue && !pinfo->fd->flags.visited)\n\t\t  {\n\t\t    /* No handle attached to this frame, but it's the first */\n\t\t    /* pass, so it'd be attached to the conversation. */\n\t\t    oidvalue = gss_info->oid;\n\t\t    if (gss_info->oid)\n\t\t      p_add_proto_data(wmem_file_scope(), pinfo, proto_gssapi, 0, gss_info->oid);\n\t\t  }\n\t\t  if (!oidvalue)\n\t\t  {\n\t\t\t  proto_tree_add_expert_format(subtree, pinfo, &ei_gssapi_unknown_header, gss_tvb, start_offset, 0,\n\t\t\t\t\t      \"Unknown header (class=%d, pc=%d, tag=%d)\",\n\t\t\t\t\t      appclass, pc, tag);\n\t\t    return_offset = tvb_captured_length(gss_tvb);\n\t\t    goto done;\n\t\t  } else {\n\t\t\ttvbuff_t *oid_tvb_local;\n\n\t\t\tif (is_verifier) {\n\t\t\t\thandle = oidvalue->wrap_handle;\n\t\t\t\tif (handle != NULL) {\n\t\t\t\t\toid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);\n\t\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);\n\t\t\t\t\tif (len == 0)\n\t\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\t\telse\n\t\t\t\t\t\treturn_offset = start_offset + len;\n\t\t\t\t} else {\n\t\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_verifier, gss_tvb, offset, -1, ENC_NA);\n\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\thandle = oidvalue->handle;\n\t\t\t\tif (handle != NULL) {\n\t\t\t\t\toid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);\n\t\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);\n\t\t\t\t\tif (len == 0)\n\t\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\t\telse\n\t\t\t\t\t\treturn_offset = start_offset + len;\n\t\t\t\t} else {\n\t\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_credentials, gss_tvb, offset, -1, ENC_NA);\n\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\t}\n\t\t\t}\n\t\t\tgoto done; /* We are finished here */\n\t\t  }\n\t\t}\n\n\t\t/* Read oid */\n\t\toid_start_offset=offset;\n\t\toffset=dissect_ber_object_identifier_str(FALSE, &asn1_ctx, subtree, gss_tvb, offset, hf_gssapi_oid, &oid);\n\t\toidvalue = gssapi_lookup_oid_str(oid);\n\n\n\t\t/* Check if we need reassembly of this blob.\n\t\t * Only try reassembly for OIDs we recognize\n\t\t * and when we have the entire tvb\n\t\t *\n\t\t * SMB will sometimes split one large GSSAPI blob\n\t\t * across multiple SMB/SessionSetup commands.\n\t\t * While we should look at the uid returned in the response\n\t\t * to the first SessionSetup and use that as a key\n\t\t * instead for simplicity we assume there will not be several\n\t\t * such authentication at once on a single tcp session\n\t\t */\n\t\tif( (!pinfo->fd->flags.visited)\n\t\t&&  (oidvalue)\n\t\t&&  (tvb_captured_length(gss_tvb)==tvb_reported_length(gss_tvb))\n\t\t&&  (len1>(guint32)tvb_captured_length_remaining(gss_tvb, oid_start_offset))\n\t\t&&  (gssapi_reassembly) ){\n\t\t\tfi=wmem_new(wmem_file_scope(), gssapi_frag_info_t);\n\t\t\tfi->first_frame=pinfo->num;\n\t\t\tfi->reassembled_in=0;\n\t\t\twmem_tree_insert32(gss_info->frags, pinfo->num, fi);\n\n\t\t\tfragment_add(&gssapi_reassembly_table,\n\t\t\t\tgss_tvb, 0, pinfo, pinfo->num, NULL,\n\t\t\t\t0, tvb_captured_length(gss_tvb), TRUE);\n\t\t\tfragment_set_tot_len(&gssapi_reassembly_table,\n\t\t\t\tpinfo, pinfo->num, NULL, len1+oid_start_offset);\n\n\t\t\tgss_info->do_reassembly=TRUE;\n\t\t\tgss_info->first_frame=pinfo->num;\n\t\t\tgss_info->frag_offset=tvb_captured_length(gss_tvb);\n\t\t\tgoto done;\n\t\t}\n\n\n\t\t/*\n\t\t * Hand off to subdissector.\n\t\t */\n\n\t\tif ((oidvalue == NULL) ||\n\t\t    !proto_is_protocol_enabled(oidvalue->proto)) {\n\t\t\t/* No dissector for this oid */\n\t\t\tproto_tree_add_item(subtree, hf_gssapi_token_object, gss_tvb, oid_start_offset, -1, ENC_NA);\n\n\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\tgoto done;\n\t\t}\n\n\t\t/* Save a pointer to the data for the OID for the\n\t\t * GSSAPI protocol for this conversation.\n\t\t */\n\n\t\t/*\n\t\t * Now add the proto data ...\n\t\t * but only if it is not already there.\n\t\t */\n\t\tif(!gss_info->oid){\n\t\t  gss_info->oid=oidvalue;\n\t\t}\n\n\t\tif (is_verifier) {\n\t\t\thandle = oidvalue->wrap_handle;\n\t\t\tif (handle != NULL) {\n\t\t\t\toid_tvb = tvb_new_subset_remaining(gss_tvb, offset);\n\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb, pinfo, subtree, encrypt_info);\n\t\t\t\tif (len == 0)\n\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\telse\n\t\t\t\t\treturn_offset = offset + len;\n\t\t\t} else {\n\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_verifier, gss_tvb, offset, -1, ENC_NA);\n\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t}\n\t\t} else {\n\t\t\thandle = oidvalue->handle;\n\t\t\tif (handle != NULL) {\n\t\t\t\toid_tvb = tvb_new_subset_remaining(gss_tvb, offset);\n\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb, pinfo, subtree, encrypt_info);\n\t\t\t\tif (len == 0)\n\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t\telse\n\t\t\t\t\treturn_offset = offset + len;\n\t\t\t} else {\n\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_credentials, gss_tvb, offset, -1, ENC_NA);\n\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n\t\t\t}\n\t\t}\n\n\t done:\n\t\t;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -208,19 +208,36 @@\n \t\t    return_offset = tvb_captured_length(gss_tvb);\n \t\t    goto done;\n \t\t  } else {\n-\t\t    tvbuff_t *oid_tvb_local;\n-\n-\t\t    oid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);\n-\t\t    if (is_verifier)\n-\t\t\thandle = oidvalue->wrap_handle;\n-\t\t    else\n-\t\t\thandle = oidvalue->handle;\n-\t\t    len = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);\n-\t\t    if (len == 0)\n-\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n-\t\t    else\n-\t\t\treturn_offset = start_offset + len;\n-\t\t    goto done; /* We are finished here */\n+\t\t\ttvbuff_t *oid_tvb_local;\n+\n+\t\t\tif (is_verifier) {\n+\t\t\t\thandle = oidvalue->wrap_handle;\n+\t\t\t\tif (handle != NULL) {\n+\t\t\t\t\toid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);\n+\t\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);\n+\t\t\t\t\tif (len == 0)\n+\t\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n+\t\t\t\t\telse\n+\t\t\t\t\t\treturn_offset = start_offset + len;\n+\t\t\t\t} else {\n+\t\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_verifier, gss_tvb, offset, -1, ENC_NA);\n+\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\thandle = oidvalue->handle;\n+\t\t\t\tif (handle != NULL) {\n+\t\t\t\t\toid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);\n+\t\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);\n+\t\t\t\t\tif (len == 0)\n+\t\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n+\t\t\t\t\telse\n+\t\t\t\t\t\treturn_offset = start_offset + len;\n+\t\t\t\t} else {\n+\t\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_credentials, gss_tvb, offset, -1, ENC_NA);\n+\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tgoto done; /* We are finished here */\n \t\t  }\n \t\t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t    tvbuff_t *oid_tvb_local;",
                "",
                "\t\t    oid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);",
                "\t\t    if (is_verifier)",
                "\t\t\thandle = oidvalue->wrap_handle;",
                "\t\t    else",
                "\t\t\thandle = oidvalue->handle;",
                "\t\t    len = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);",
                "\t\t    if (len == 0)",
                "\t\t\treturn_offset = tvb_captured_length(gss_tvb);",
                "\t\t    else",
                "\t\t\treturn_offset = start_offset + len;",
                "\t\t    goto done; /* We are finished here */"
            ],
            "added_lines": [
                "\t\t\ttvbuff_t *oid_tvb_local;",
                "",
                "\t\t\tif (is_verifier) {",
                "\t\t\t\thandle = oidvalue->wrap_handle;",
                "\t\t\t\tif (handle != NULL) {",
                "\t\t\t\t\toid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);",
                "\t\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);",
                "\t\t\t\t\tif (len == 0)",
                "\t\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);",
                "\t\t\t\t\telse",
                "\t\t\t\t\t\treturn_offset = start_offset + len;",
                "\t\t\t\t} else {",
                "\t\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_verifier, gss_tvb, offset, -1, ENC_NA);",
                "\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);",
                "\t\t\t\t}",
                "\t\t\t} else {",
                "\t\t\t\thandle = oidvalue->handle;",
                "\t\t\t\tif (handle != NULL) {",
                "\t\t\t\t\toid_tvb_local = tvb_new_subset_remaining(gss_tvb, start_offset);",
                "\t\t\t\t\tlen = call_dissector_with_data(handle, oid_tvb_local, pinfo, subtree, encrypt_info);",
                "\t\t\t\t\tif (len == 0)",
                "\t\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);",
                "\t\t\t\t\telse",
                "\t\t\t\t\t\treturn_offset = start_offset + len;",
                "\t\t\t\t} else {",
                "\t\t\t\t\tproto_tree_add_item(subtree, hf_gssapi_auth_credentials, gss_tvb, offset, -1, ENC_NA);",
                "\t\t\t\t\treturn_offset = tvb_captured_length(gss_tvb);",
                "\t\t\t\t}",
                "\t\t\t}",
                "\t\t\tgoto done; /* We are finished here */"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-32815",
        "func_name": "Exiv2/exiv2/packIfdId",
        "description": "Exiv2 is a command-line utility and C++ library for reading, writing, deleting, and modifying the metadata of image files. The assertion failure is triggered when Exiv2 is used to modify the metadata of a crafted image file. An attacker could potentially exploit the vulnerability to cause a denial of service, if they can trick the victim into running Exiv2 on a crafted image file. Note that this bug is only triggered when modifying the metadata, which is a less frequently used Exiv2 operation than reading the metadata. For example, to trigger the bug in the Exiv2 command-line application, you need to add an extra command-line argument such as `fi`. ### Patches The bug is fixed in version v0.27.5. ### References Regression test and bug fix: #1739 ### For more information Please see our [security policy](https://github.com/Exiv2/exiv2/security/policy) for information about Exiv2 security.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/0c17eb33c0a7fad1796ce23b8bbc32067f511aed",
        "commit_title": "Don't crash if s > size.",
        "commit_text": "",
        "func_before": "DataBuf packIfdId(const ExifData& exifData,\n                            IfdId     ifdId,\n                            ByteOrder byteOrder)\n    {\n        const uint16_t size = 1024;\n        DataBuf buf(size);\n        std::memset(buf.pData_, 0x0, buf.size_);\n\n        uint16_t len = 0;\n        const ExifData::const_iterator b = exifData.begin();\n        const ExifData::const_iterator e = exifData.end();\n        for (ExifData::const_iterator i = b; i != e; ++i) {\n            if (i->ifdId() != ifdId) continue;\n            const uint16_t s = i->tag()*2 + static_cast<uint16_t>(i->size());\n            assert(s <= size);\n            if (len < s) len = s;\n            i->copy(buf.pData_ + i->tag()*2, byteOrder);\n        }\n        // Round the size to make it even.\n        buf.size_ = len + len%2;\n        return buf;\n    }",
        "func": "DataBuf packIfdId(const ExifData& exifData,\n                            IfdId     ifdId,\n                            ByteOrder byteOrder)\n    {\n        const uint16_t size = 1024;\n        DataBuf buf(size);\n        std::memset(buf.pData_, 0x0, buf.size_);\n\n        uint16_t len = 0;\n        const ExifData::const_iterator b = exifData.begin();\n        const ExifData::const_iterator e = exifData.end();\n        for (ExifData::const_iterator i = b; i != e; ++i) {\n            if (i->ifdId() != ifdId) continue;\n            const uint16_t s = i->tag()*2 + static_cast<uint16_t>(i->size());\n            if (s <= size) {\n                if (len < s) len = s;\n                i->copy(buf.pData_ + i->tag()*2, byteOrder);\n            }\n        }\n        // Round the size to make it even.\n        buf.size_ = len + len%2;\n        return buf;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,9 +12,10 @@\n         for (ExifData::const_iterator i = b; i != e; ++i) {\n             if (i->ifdId() != ifdId) continue;\n             const uint16_t s = i->tag()*2 + static_cast<uint16_t>(i->size());\n-            assert(s <= size);\n-            if (len < s) len = s;\n-            i->copy(buf.pData_ + i->tag()*2, byteOrder);\n+            if (s <= size) {\n+                if (len < s) len = s;\n+                i->copy(buf.pData_ + i->tag()*2, byteOrder);\n+            }\n         }\n         // Round the size to make it even.\n         buf.size_ = len + len%2;",
        "diff_line_info": {
            "deleted_lines": [
                "            assert(s <= size);",
                "            if (len < s) len = s;",
                "            i->copy(buf.pData_ + i->tag()*2, byteOrder);"
            ],
            "added_lines": [
                "            if (s <= size) {",
                "                if (len < s) len = s;",
                "                i->copy(buf.pData_ + i->tag()*2, byteOrder);",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-32815",
        "func_name": "Exiv2/exiv2/packIfdId",
        "description": "Exiv2 is a command-line utility and C++ library for reading, writing, deleting, and modifying the metadata of image files. The assertion failure is triggered when Exiv2 is used to modify the metadata of a crafted image file. An attacker could potentially exploit the vulnerability to cause a denial of service, if they can trick the victim into running Exiv2 on a crafted image file. Note that this bug is only triggered when modifying the metadata, which is a less frequently used Exiv2 operation than reading the metadata. For example, to trigger the bug in the Exiv2 command-line application, you need to add an extra command-line argument such as `fi`. ### Patches The bug is fixed in version v0.27.5. ### References Regression test and bug fix: #1739 ### For more information Please see our [security policy](https://github.com/Exiv2/exiv2/security/policy) for information about Exiv2 security.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/04466168b87dedff4ec09c09e9c23f2334ba1734",
        "commit_title": "Print message to stderr when EXIV2_DEBUG_MESSAGES is enabled.",
        "commit_text": "",
        "func_before": "DataBuf packIfdId(const ExifData& exifData,\n                            IfdId     ifdId,\n                            ByteOrder byteOrder)\n    {\n        const uint16_t size = 1024;\n        DataBuf buf(size);\n        std::memset(buf.pData_, 0x0, buf.size_);\n\n        uint16_t len = 0;\n        const ExifData::const_iterator b = exifData.begin();\n        const ExifData::const_iterator e = exifData.end();\n        for (ExifData::const_iterator i = b; i != e; ++i) {\n            if (i->ifdId() != ifdId) continue;\n            const uint16_t s = i->tag()*2 + static_cast<uint16_t>(i->size());\n            if (s <= size) {\n                if (len < s) len = s;\n                i->copy(buf.pData_ + i->tag()*2, byteOrder);\n            }\n        }\n        // Round the size to make it even.\n        buf.size_ = len + len%2;\n        return buf;\n    }",
        "func": "DataBuf packIfdId(const ExifData& exifData,\n                            IfdId     ifdId,\n                            ByteOrder byteOrder)\n    {\n        const uint16_t size = 1024;\n        DataBuf buf(size);\n        std::memset(buf.pData_, 0x0, buf.size_);\n\n        uint16_t len = 0;\n        const ExifData::const_iterator b = exifData.begin();\n        const ExifData::const_iterator e = exifData.end();\n        for (ExifData::const_iterator i = b; i != e; ++i) {\n            if (i->ifdId() != ifdId) continue;\n            const uint16_t s = i->tag()*2 + static_cast<uint16_t>(i->size());\n            if (s <= size) {\n                if (len < s) len = s;\n                i->copy(buf.pData_ + i->tag()*2, byteOrder);\n            } else {\n#ifdef EXIV2_DEBUG_MESSAGES\n                std::cerr << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";\n#endif\n            }\n        }\n        // Round the size to make it even.\n        buf.size_ = len + len%2;\n        return buf;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,10 @@\n             if (s <= size) {\n                 if (len < s) len = s;\n                 i->copy(buf.pData_ + i->tag()*2, byteOrder);\n+            } else {\n+#ifdef EXIV2_DEBUG_MESSAGES\n+                std::cerr << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";\n+#endif\n             }\n         }\n         // Round the size to make it even.",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            } else {",
                "#ifdef EXIV2_DEBUG_MESSAGES",
                "                std::cerr << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-32815",
        "func_name": "Exiv2/exiv2/packIfdId",
        "description": "Exiv2 is a command-line utility and C++ library for reading, writing, deleting, and modifying the metadata of image files. The assertion failure is triggered when Exiv2 is used to modify the metadata of a crafted image file. An attacker could potentially exploit the vulnerability to cause a denial of service, if they can trick the victim into running Exiv2 on a crafted image file. Note that this bug is only triggered when modifying the metadata, which is a less frequently used Exiv2 operation than reading the metadata. For example, to trigger the bug in the Exiv2 command-line application, you need to add an extra command-line argument such as `fi`. ### Patches The bug is fixed in version v0.27.5. ### References Regression test and bug fix: #1739 ### For more information Please see our [security policy](https://github.com/Exiv2/exiv2/security/policy) for information about Exiv2 security.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/c79d83f25fdd09218697d482211a61db87ce5333",
        "commit_title": "Better way to print the error message.",
        "commit_text": "",
        "func_before": "DataBuf packIfdId(const ExifData& exifData,\n                            IfdId     ifdId,\n                            ByteOrder byteOrder)\n    {\n        const uint16_t size = 1024;\n        DataBuf buf(size);\n        std::memset(buf.pData_, 0x0, buf.size_);\n\n        uint16_t len = 0;\n        const ExifData::const_iterator b = exifData.begin();\n        const ExifData::const_iterator e = exifData.end();\n        for (ExifData::const_iterator i = b; i != e; ++i) {\n            if (i->ifdId() != ifdId) continue;\n            const uint16_t s = i->tag()*2 + static_cast<uint16_t>(i->size());\n            if (s <= size) {\n                if (len < s) len = s;\n                i->copy(buf.pData_ + i->tag()*2, byteOrder);\n            } else {\n#ifdef EXIV2_DEBUG_MESSAGES\n                std::cerr << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";\n#endif\n            }\n        }\n        // Round the size to make it even.\n        buf.size_ = len + len%2;\n        return buf;\n    }",
        "func": "DataBuf packIfdId(const ExifData& exifData,\n                            IfdId     ifdId,\n                            ByteOrder byteOrder)\n    {\n        const uint16_t size = 1024;\n        DataBuf buf(size);\n        std::memset(buf.pData_, 0x0, buf.size_);\n\n        uint16_t len = 0;\n        const ExifData::const_iterator b = exifData.begin();\n        const ExifData::const_iterator e = exifData.end();\n        for (ExifData::const_iterator i = b; i != e; ++i) {\n            if (i->ifdId() != ifdId) continue;\n            const uint16_t s = i->tag()*2 + static_cast<uint16_t>(i->size());\n            if (s <= size) {\n                if (len < s) len = s;\n                i->copy(buf.pData_ + i->tag()*2, byteOrder);\n            } else {\n                EXV_ERROR << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";\n            }\n        }\n        // Round the size to make it even.\n        buf.size_ = len + len%2;\n        return buf;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,9 +16,7 @@\n                 if (len < s) len = s;\n                 i->copy(buf.pData_ + i->tag()*2, byteOrder);\n             } else {\n-#ifdef EXIV2_DEBUG_MESSAGES\n-                std::cerr << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";\n-#endif\n+                EXV_ERROR << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";\n             }\n         }\n         // Round the size to make it even.",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef EXIV2_DEBUG_MESSAGES",
                "                std::cerr << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";",
                "#endif"
            ],
            "added_lines": [
                "                EXV_ERROR << \"packIfdId out-of-bounds error: s = \" << std::dec << s << \"\\n\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-16818",
        "func_name": "ceph/parse_principal",
        "description": "RADOS Gateway in Ceph 12.1.0 through 12.2.1 allows remote authenticated users to cause a denial of service (assertion failure and application exit) by leveraging \"full\" (not necessarily admin) privileges to post an invalid profile to the admin API, related to rgw/rgw_iam_policy.cc, rgw/rgw_basic_types.h, and rgw/rgw_iam_types.h.",
        "git_url": "https://github.com/ceph/ceph/commit/b3118cabb8060a8cc6a01c4e8264cb18e7b1745a",
        "commit_title": "rgw: Remove assertions in IAM Policy",
        "commit_text": " A couple of them could be triggered by user input. ",
        "func_before": "static optional<Principal> parse_principal(CephContext* cct, TokenID t,\n\t\t\t\t    string&& s) {\n  // Wildcard!\n  if ((t == TokenID::AWS) && (s == \"*\")) {\n    return Principal::wildcard();\n\n    // Do nothing for now.\n  } else if (t == TokenID::CanonicalUser) {\n\n    // AWS ARNs\n  } else if (t == TokenID::AWS) {\n    auto a = ARN::parse(s);\n    if (!a) {\n      if (std::none_of(s.begin(), s.end(),\n\t\t       [](const char& c) {\n\t\t\t return (c == ':') || (c == '/');\n\t\t       })) {\n\t// Since tenants are simply prefixes, there's no really good\n\t// way to see if one exists or not. So we return the thing and\n\t// let them try to match against it.\n\treturn Principal::tenant(std::move(s));\n      }\n    }\n\n    if (a->resource == \"root\") {\n      return Principal::tenant(std::move(a->account));\n    }\n\n    static const char rx_str[] = \"([^/]*)/(.*)\";\n    static const regex rx(rx_str, sizeof(rx_str) - 1,\n\t\t\t  ECMAScript | optimize);\n    smatch match;\n    if (regex_match(a->resource, match, rx)) {\n      ceph_assert(match.size() == 3);\n\n      if (match[1] == \"user\") {\n\treturn Principal::user(std::move(a->account),\n\t\t\t       match[2]);\n      }\n\n      if (match[1] == \"role\") {\n\treturn Principal::role(std::move(a->account),\n\t\t\t       match[2]);\n      }\n    }\n  }\n\n  ldout(cct, 0) << \"Supplied principal is discarded: \" << s << dendl;\n  return boost::none;\n}",
        "func": "static optional<Principal> parse_principal(CephContext* cct, TokenID t,\n\t\t\t\t    string&& s) {\n  // Wildcard!\n  if ((t == TokenID::AWS) && (s == \"*\")) {\n    return Principal::wildcard();\n\n    // Do nothing for now.\n  } else if (t == TokenID::CanonicalUser) {\n\n    // AWS ARNs\n  } else if (t == TokenID::AWS) {\n    auto a = ARN::parse(s);\n    if (!a) {\n      if (std::none_of(s.begin(), s.end(),\n\t\t       [](const char& c) {\n\t\t\t return (c == ':') || (c == '/');\n\t\t       })) {\n\t// Since tenants are simply prefixes, there's no really good\n\t// way to see if one exists or not. So we return the thing and\n\t// let them try to match against it.\n\treturn Principal::tenant(std::move(s));\n      }\n    }\n\n    if (a->resource == \"root\") {\n      return Principal::tenant(std::move(a->account));\n    }\n\n    static const char rx_str[] = \"([^/]*)/(.*)\";\n    static const regex rx(rx_str, sizeof(rx_str) - 1,\n\t\t\t  ECMAScript | optimize);\n    smatch match;\n    if (regex_match(a->resource, match, rx)) {\n      if (match.size() != 3) {\n\treturn boost::none;\n      }\n\n      if (match[1] == \"user\") {\n\treturn Principal::user(std::move(a->account),\n\t\t\t       match[2]);\n      }\n\n      if (match[1] == \"role\") {\n\treturn Principal::role(std::move(a->account),\n\t\t\t       match[2]);\n      }\n    }\n  }\n\n  ldout(cct, 0) << \"Supplied principal is discarded: \" << s << dendl;\n  return boost::none;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,7 +31,9 @@\n \t\t\t  ECMAScript | optimize);\n     smatch match;\n     if (regex_match(a->resource, match, rx)) {\n-      ceph_assert(match.size() == 3);\n+      if (match.size() != 3) {\n+\treturn boost::none;\n+      }\n \n       if (match[1] == \"user\") {\n \treturn Principal::user(std::move(a->account),",
        "diff_line_info": {
            "deleted_lines": [
                "      ceph_assert(match.size() == 3);"
            ],
            "added_lines": [
                "      if (match.size() != 3) {",
                "\treturn boost::none;",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-16818",
        "func_name": "ceph/ParseState::do_string",
        "description": "RADOS Gateway in Ceph 12.1.0 through 12.2.1 allows remote authenticated users to cause a denial of service (assertion failure and application exit) by leveraging \"full\" (not necessarily admin) privileges to post an invalid profile to the admin API, related to rgw/rgw_iam_policy.cc, rgw/rgw_basic_types.h, and rgw/rgw_iam_types.h.",
        "git_url": "https://github.com/ceph/ceph/commit/b3118cabb8060a8cc6a01c4e8264cb18e7b1745a",
        "commit_title": "rgw: Remove assertions in IAM Policy",
        "commit_text": " A couple of them could be triggered by user input. ",
        "func_before": "bool ParseState::do_string(CephContext* cct, const char* s, size_t l) {\n  auto k = pp->tokens.lookup(s, l);\n  Policy& p = pp->policy;\n  bool is_action = false;\n  bool is_validaction = false;\n  Statement* t = p.statements.empty() ? nullptr : &(p.statements.back());\n\n  // Top level!\n  if ((w->id == TokenID::Version) && k &&\n      k->kind == TokenKind::version_key) {\n    p.version = static_cast<Version>(k->specific);\n  } else if (w->id == TokenID::Id) {\n    p.id = string(s, l);\n\n    // Statement\n\n  } else if (w->id == TokenID::Sid) {\n    t->sid.emplace(s, l);\n  } else if ((w->id == TokenID::Effect) &&\n\t     k->kind == TokenKind::effect_key) {\n    t->effect = static_cast<Effect>(k->specific);\n  } else if (w->id == TokenID::Principal && s && *s == '*') {\n    t->princ.emplace(Principal::wildcard());\n  } else if (w->id == TokenID::NotPrincipal && s && *s == '*') {\n    t->noprinc.emplace(Principal::wildcard());\n  } else if ((w->id == TokenID::Action) ||\n\t     (w->id == TokenID::NotAction)) {\n    is_action = true;\n    for (auto& p : actpairs) {\n      if (match_policy({s, l}, p.name, MATCH_POLICY_ACTION)) {\n        is_validaction = true;\n\t(w->id == TokenID::Action ? t->action : t->notaction) |= p.bit;\n      }\n    }\n  } else if (w->id == TokenID::Resource || w->id == TokenID::NotResource) {\n    auto a = ARN::parse({s, l}, true);\n    // You can't specify resources for someone ELSE'S account.\n    if (a && (a->account.empty() || a->account == pp->tenant ||\n\t      a->account == \"*\")) {\n      if (a->account.empty() || a->account == \"*\")\n\ta->account = pp->tenant;\n      (w->id == TokenID::Resource ? t->resource : t->notresource)\n\t.emplace(std::move(*a));\n    }\n    else\n      ldout(cct, 0) << \"Supplied resource is discarded: \" << string(s, l)\n\t\t    << dendl;\n  } else if (w->kind == TokenKind::cond_key) {\n    auto& t = pp->policy.statements.back();\n    t.conditions.back().vals.emplace_back(s, l);\n\n    // Principals\n\n  } else if (w->kind == TokenKind::princ_type) {\n    ceph_assert(pp->s.size() > 1);\n    auto& pri = pp->s[pp->s.size() - 2].w->id == TokenID::Principal ?\n      t->princ : t->noprinc;\n\n    auto o = parse_principal(pp->cct, w->id, string(s, l));\n    if (o)\n      pri.emplace(std::move(*o));\n\n    // Failure\n\n  } else {\n    return false;\n  }\n\n  if (!arraying) {\n    pp->s.pop_back();\n  }\n\n  if (is_action && !is_validaction){\n    return false;\n  }\n\n  return true;\n}",
        "func": "bool ParseState::do_string(CephContext* cct, const char* s, size_t l) {\n  auto k = pp->tokens.lookup(s, l);\n  Policy& p = pp->policy;\n  bool is_action = false;\n  bool is_validaction = false;\n  Statement* t = p.statements.empty() ? nullptr : &(p.statements.back());\n\n  // Top level!\n  if ((w->id == TokenID::Version) && k &&\n      k->kind == TokenKind::version_key) {\n    p.version = static_cast<Version>(k->specific);\n  } else if (w->id == TokenID::Id) {\n    p.id = string(s, l);\n\n    // Statement\n\n  } else if (w->id == TokenID::Sid) {\n    t->sid.emplace(s, l);\n  } else if ((w->id == TokenID::Effect) &&\n\t     k->kind == TokenKind::effect_key) {\n    t->effect = static_cast<Effect>(k->specific);\n  } else if (w->id == TokenID::Principal && s && *s == '*') {\n    t->princ.emplace(Principal::wildcard());\n  } else if (w->id == TokenID::NotPrincipal && s && *s == '*') {\n    t->noprinc.emplace(Principal::wildcard());\n  } else if ((w->id == TokenID::Action) ||\n\t     (w->id == TokenID::NotAction)) {\n    is_action = true;\n    for (auto& p : actpairs) {\n      if (match_policy({s, l}, p.name, MATCH_POLICY_ACTION)) {\n        is_validaction = true;\n\t(w->id == TokenID::Action ? t->action : t->notaction) |= p.bit;\n      }\n    }\n  } else if (w->id == TokenID::Resource || w->id == TokenID::NotResource) {\n    auto a = ARN::parse({s, l}, true);\n    // You can't specify resources for someone ELSE'S account.\n    if (a && (a->account.empty() || a->account == pp->tenant ||\n\t      a->account == \"*\")) {\n      if (a->account.empty() || a->account == \"*\")\n\ta->account = pp->tenant;\n      (w->id == TokenID::Resource ? t->resource : t->notresource)\n\t.emplace(std::move(*a));\n    }\n    else\n      ldout(cct, 0) << \"Supplied resource is discarded: \" << string(s, l)\n\t\t    << dendl;\n  } else if (w->kind == TokenKind::cond_key) {\n    auto& t = pp->policy.statements.back();\n    t.conditions.back().vals.emplace_back(s, l);\n\n    // Principals\n\n  } else if (w->kind == TokenKind::princ_type) {\n    if (pp->s.size() <= 1) {\n      return false;\n    }\n    auto& pri = pp->s[pp->s.size() - 2].w->id == TokenID::Principal ?\n      t->princ : t->noprinc;\n\n    auto o = parse_principal(pp->cct, w->id, string(s, l));\n    if (o)\n      pri.emplace(std::move(*o));\n\n    // Failure\n\n  } else {\n    return false;\n  }\n\n  if (!arraying) {\n    pp->s.pop_back();\n  }\n\n  if (is_action && !is_validaction){\n    return false;\n  }\n\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,7 +52,9 @@\n     // Principals\n \n   } else if (w->kind == TokenKind::princ_type) {\n-    ceph_assert(pp->s.size() > 1);\n+    if (pp->s.size() <= 1) {\n+      return false;\n+    }\n     auto& pri = pp->s[pp->s.size() - 2].w->id == TokenID::Principal ?\n       t->princ : t->noprinc;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    ceph_assert(pp->s.size() > 1);"
            ],
            "added_lines": [
                "    if (pp->s.size() <= 1) {",
                "      return false;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-16818",
        "func_name": "ceph/ARN::parse",
        "description": "RADOS Gateway in Ceph 12.1.0 through 12.2.1 allows remote authenticated users to cause a denial of service (assertion failure and application exit) by leveraging \"full\" (not necessarily admin) privileges to post an invalid profile to the admin API, related to rgw/rgw_iam_policy.cc, rgw/rgw_basic_types.h, and rgw/rgw_iam_types.h.",
        "git_url": "https://github.com/ceph/ceph/commit/b3118cabb8060a8cc6a01c4e8264cb18e7b1745a",
        "commit_title": "rgw: Remove assertions in IAM Policy",
        "commit_text": " A couple of them could be triggered by user input. ",
        "func_before": "optional<ARN> ARN::parse(const string& s, bool wildcards) {\n  static const char str_wild[] = \"arn:([^:]*):([^:]*):([^:]*):([^:]*):([^:]*)\";\n  static const regex rx_wild(str_wild,\n\t\t\t\t    sizeof(str_wild) - 1,\n\t\t\t\t    ECMAScript | optimize);\n  static const char str_no_wild[]\n    = \"arn:([^:*]*):([^:*]*):([^:*]*):([^:*]*):([^:*]*)\";\n  static const regex rx_no_wild(str_no_wild,\n\t\t\t\tsizeof(str_no_wild) - 1,\n\t\t\t\tECMAScript | optimize);\n\n  smatch match;\n\n  if ((s == \"*\") && wildcards) {\n    return ARN(Partition::wildcard, Service::wildcard, \"*\", \"*\", \"*\");\n  } else if (regex_match(s, match, wildcards ? rx_wild : rx_no_wild)) {\n    ceph_assert(match.size() == 6);\n\n    ARN a;\n    {\n      auto p = to_partition(match[1], wildcards);\n      if (!p)\n\treturn none;\n\n      a.partition = *p;\n    }\n    {\n      auto s = to_service(match[2], wildcards);\n      if (!s) {\n\treturn none;\n      }\n      a.service = *s;\n    }\n\n    a.region = match[3];\n    a.account = match[4];\n    a.resource = match[5];\n\n    return a;\n  }\n  return none;\n}",
        "func": "optional<ARN> ARN::parse(const string& s, bool wildcards) {\n  static const char str_wild[] = \"arn:([^:]*):([^:]*):([^:]*):([^:]*):([^:]*)\";\n  static const regex rx_wild(str_wild,\n\t\t\t\t    sizeof(str_wild) - 1,\n\t\t\t\t    ECMAScript | optimize);\n  static const char str_no_wild[]\n    = \"arn:([^:*]*):([^:*]*):([^:*]*):([^:*]*):([^:*]*)\";\n  static const regex rx_no_wild(str_no_wild,\n\t\t\t\tsizeof(str_no_wild) - 1,\n\t\t\t\tECMAScript | optimize);\n\n  smatch match;\n\n  if ((s == \"*\") && wildcards) {\n    return ARN(Partition::wildcard, Service::wildcard, \"*\", \"*\", \"*\");\n  } else if (regex_match(s, match, wildcards ? rx_wild : rx_no_wild)) {\n    if (match.size() != 6) {\n      return boost::none;\n    }\n\n    ARN a;\n    {\n      auto p = to_partition(match[1], wildcards);\n      if (!p)\n\treturn none;\n\n      a.partition = *p;\n    }\n    {\n      auto s = to_service(match[2], wildcards);\n      if (!s) {\n\treturn none;\n      }\n      a.service = *s;\n    }\n\n    a.region = match[3];\n    a.account = match[4];\n    a.resource = match[5];\n\n    return a;\n  }\n  return none;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,9 @@\n   if ((s == \"*\") && wildcards) {\n     return ARN(Partition::wildcard, Service::wildcard, \"*\", \"*\", \"*\");\n   } else if (regex_match(s, match, wildcards ? rx_wild : rx_no_wild)) {\n-    ceph_assert(match.size() == 6);\n+    if (match.size() != 6) {\n+      return boost::none;\n+    }\n \n     ARN a;\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "    ceph_assert(match.size() == 6);"
            ],
            "added_lines": [
                "    if (match.size() != 6) {",
                "      return boost::none;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-16818",
        "func_name": "ceph/operator ==",
        "description": "RADOS Gateway in Ceph 12.1.0 through 12.2.1 allows remote authenticated users to cause a denial of service (assertion failure and application exit) by leveraging \"full\" (not necessarily admin) privileges to post an invalid profile to the admin API, related to rgw/rgw_iam_policy.cc, rgw/rgw_basic_types.h, and rgw/rgw_iam_types.h.",
        "git_url": "https://github.com/ceph/ceph/commit/b3118cabb8060a8cc6a01c4e8264cb18e7b1745a",
        "commit_title": "rgw: Remove assertions in IAM Policy",
        "commit_text": " A couple of them could be triggered by user input. ",
        "func_before": "inline bool operator ==(const MaskedIP& l, const MaskedIP& r) {\n  auto shift = std::max((l.v6 ? 128 : 32) - l.prefix,\n\t\t\t(r.v6 ? 128 : 32) - r.prefix);\n  ceph_assert(shift > 0);\n  return (l.addr >> shift) == (r.addr >> shift);\n}",
        "func": "inline bool operator ==(const MaskedIP& l, const MaskedIP& r) {\n  auto shift = std::max((l.v6 ? 128 : 32) - l.prefix,\n\t\t\t(r.v6 ? 128 : 32) - r.prefix);\n  return (l.addr >> shift) == (r.addr >> shift);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,5 @@\n inline bool operator ==(const MaskedIP& l, const MaskedIP& r) {\n   auto shift = std::max((l.v6 ? 128 : 32) - l.prefix,\n \t\t\t(r.v6 ? 128 : 32) - r.prefix);\n-  ceph_assert(shift > 0);\n   return (l.addr >> shift) == (r.addr >> shift);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  ceph_assert(shift > 0);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/RBaseStream::skip",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/8a76fadaa39b87d740ec3346d9eccb64bde5a6af",
        "commit_title": "imgcodecs: add overflow checks",
        "commit_text": "",
        "func_before": "void  RBaseStream::skip( int bytes )\n{\n    CV_Assert(bytes >= 0);\n    m_current += bytes;\n}",
        "func": "void  RBaseStream::skip( int bytes )\n{\n    CV_Assert(bytes >= 0);\n    uchar* old = m_current;\n    m_current += bytes;\n    CV_Assert(m_current >= old);  // overflow check\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,7 @@\n void  RBaseStream::skip( int bytes )\n {\n     CV_Assert(bytes >= 0);\n+    uchar* old = m_current;\n     m_current += bytes;\n+    CV_Assert(m_current >= old);  // overflow check\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    uchar* old = m_current;",
                "    CV_Assert(m_current >= old);  // overflow check"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/RBaseStream::getPos",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/8a76fadaa39b87d740ec3346d9eccb64bde5a6af",
        "commit_title": "imgcodecs: add overflow checks",
        "commit_text": "",
        "func_before": "int  RBaseStream::getPos()\n{\n    CV_Assert(isOpened());\n    return m_block_pos + (int)(m_current - m_start);\n}",
        "func": "int  RBaseStream::getPos()\n{\n    CV_Assert(isOpened());\n    int pos = validateToInt((m_current - m_start) + m_block_pos);\n    CV_Assert(pos >= m_block_pos); // overflow check\n    CV_Assert(pos >= 0); // overflow check\n    return pos;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n int  RBaseStream::getPos()\n {\n     CV_Assert(isOpened());\n-    return m_block_pos + (int)(m_current - m_start);\n+    int pos = validateToInt((m_current - m_start) + m_block_pos);\n+    CV_Assert(pos >= m_block_pos); // overflow check\n+    CV_Assert(pos >= 0); // overflow check\n+    return pos;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return m_block_pos + (int)(m_current - m_start);"
            ],
            "added_lines": [
                "    int pos = validateToInt((m_current - m_start) + m_block_pos);",
                "    CV_Assert(pos >= m_block_pos); // overflow check",
                "    CV_Assert(pos >= 0); // overflow check",
                "    return pos;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/BmpDecoder::readHeader",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/8a76fadaa39b87d740ec3346d9eccb64bde5a6af",
        "commit_title": "imgcodecs: add overflow checks",
        "commit_text": "",
        "func_before": "bool  BmpDecoder::readHeader()\n{\n    bool result = false;\n    bool iscolor = false;\n\n    if( !m_buf.empty() )\n    {\n        if( !m_strm.open( m_buf ) )\n            return false;\n    }\n    else if( !m_strm.open( m_filename ))\n        return false;\n\n    CV_TRY\n    {\n        m_strm.skip( 10 );\n        m_offset = m_strm.getDWord();\n\n        int  size = m_strm.getDWord();\n\n        if( size >= 36 )\n        {\n            m_width  = m_strm.getDWord();\n            m_height = m_strm.getDWord();\n            m_bpp    = m_strm.getDWord() >> 16;\n            m_rle_code = (BmpCompression)m_strm.getDWord();\n            m_strm.skip(12);\n            int clrused = m_strm.getDWord();\n            m_strm.skip( size - 36 );\n\n            if( m_width > 0 && m_height != 0 &&\n             (((m_bpp == 1 || m_bpp == 4 || m_bpp == 8 ||\n                m_bpp == 24 || m_bpp == 32 ) && m_rle_code == BMP_RGB) ||\n               ((m_bpp == 16 || m_bpp == 32) && (m_rle_code == BMP_RGB || m_rle_code == BMP_BITFIELDS)) ||\n               (m_bpp == 4 && m_rle_code == BMP_RLE4) ||\n               (m_bpp == 8 && m_rle_code == BMP_RLE8)))\n            {\n                iscolor = true;\n                result = true;\n\n                if( m_bpp <= 8 )\n                {\n                    CV_Assert(clrused >= 0 && clrused <= 256);\n                    memset(m_palette, 0, sizeof(m_palette));\n                    m_strm.getBytes(m_palette, (clrused == 0? 1<<m_bpp : clrused)*4 );\n                    iscolor = IsColorPalette( m_palette, m_bpp );\n                }\n                else if( m_bpp == 16 && m_rle_code == BMP_BITFIELDS )\n                {\n                    int redmask = m_strm.getDWord();\n                    int greenmask = m_strm.getDWord();\n                    int bluemask = m_strm.getDWord();\n\n                    if( bluemask == 0x1f && greenmask == 0x3e0 && redmask == 0x7c00 )\n                        m_bpp = 15;\n                    else if( bluemask == 0x1f && greenmask == 0x7e0 && redmask == 0xf800 )\n                        ;\n                    else\n                        result = false;\n                }\n                else if (m_bpp == 32 && m_rle_code == BMP_BITFIELDS)\n                {\n                    // 32bit BMP not require to check something - we can simply allow it to use\n                    ;\n                }\n                else if( m_bpp == 16 && m_rle_code == BMP_RGB )\n                    m_bpp = 15;\n            }\n        }\n        else if( size == 12 )\n        {\n            m_width  = m_strm.getWord();\n            m_height = m_strm.getWord();\n            m_bpp    = m_strm.getDWord() >> 16;\n            m_rle_code = BMP_RGB;\n\n            if( m_width > 0 && m_height != 0 &&\n               (m_bpp == 1 || m_bpp == 4 || m_bpp == 8 ||\n                m_bpp == 24 || m_bpp == 32 ))\n            {\n                if( m_bpp <= 8 )\n                {\n                    uchar buffer[256*3];\n                    int j, clrused = 1 << m_bpp;\n                    m_strm.getBytes( buffer, clrused*3 );\n                    for( j = 0; j < clrused; j++ )\n                    {\n                        m_palette[j].b = buffer[3*j+0];\n                        m_palette[j].g = buffer[3*j+1];\n                        m_palette[j].r = buffer[3*j+2];\n                    }\n                }\n                result = true;\n            }\n        }\n    }",
        "func": "bool  BmpDecoder::readHeader()\n{\n    bool result = false;\n    bool iscolor = false;\n\n    if( !m_buf.empty() )\n    {\n        if( !m_strm.open( m_buf ) )\n            return false;\n    }\n    else if( !m_strm.open( m_filename ))\n        return false;\n\n    CV_TRY\n    {\n        m_strm.skip( 10 );\n        m_offset = m_strm.getDWord();\n\n        int  size = m_strm.getDWord();\n        CV_Assert(size > 0); // overflow, 2Gb limit\n\n        if( size >= 36 )\n        {\n            m_width  = m_strm.getDWord();\n            m_height = m_strm.getDWord();\n            m_bpp    = m_strm.getDWord() >> 16;\n            m_rle_code = (BmpCompression)m_strm.getDWord();\n            m_strm.skip(12);\n            int clrused = m_strm.getDWord();\n            m_strm.skip( size - 36 );\n\n            if( m_width > 0 && m_height != 0 &&\n             (((m_bpp == 1 || m_bpp == 4 || m_bpp == 8 ||\n                m_bpp == 24 || m_bpp == 32 ) && m_rle_code == BMP_RGB) ||\n               ((m_bpp == 16 || m_bpp == 32) && (m_rle_code == BMP_RGB || m_rle_code == BMP_BITFIELDS)) ||\n               (m_bpp == 4 && m_rle_code == BMP_RLE4) ||\n               (m_bpp == 8 && m_rle_code == BMP_RLE8)))\n            {\n                iscolor = true;\n                result = true;\n\n                if( m_bpp <= 8 )\n                {\n                    CV_Assert(clrused >= 0 && clrused <= 256);\n                    memset(m_palette, 0, sizeof(m_palette));\n                    m_strm.getBytes(m_palette, (clrused == 0? 1<<m_bpp : clrused)*4 );\n                    iscolor = IsColorPalette( m_palette, m_bpp );\n                }\n                else if( m_bpp == 16 && m_rle_code == BMP_BITFIELDS )\n                {\n                    int redmask = m_strm.getDWord();\n                    int greenmask = m_strm.getDWord();\n                    int bluemask = m_strm.getDWord();\n\n                    if( bluemask == 0x1f && greenmask == 0x3e0 && redmask == 0x7c00 )\n                        m_bpp = 15;\n                    else if( bluemask == 0x1f && greenmask == 0x7e0 && redmask == 0xf800 )\n                        ;\n                    else\n                        result = false;\n                }\n                else if (m_bpp == 32 && m_rle_code == BMP_BITFIELDS)\n                {\n                    // 32bit BMP not require to check something - we can simply allow it to use\n                    ;\n                }\n                else if( m_bpp == 16 && m_rle_code == BMP_RGB )\n                    m_bpp = 15;\n            }\n        }\n        else if( size == 12 )\n        {\n            m_width  = m_strm.getWord();\n            m_height = m_strm.getWord();\n            m_bpp    = m_strm.getDWord() >> 16;\n            m_rle_code = BMP_RGB;\n\n            if( m_width > 0 && m_height != 0 &&\n               (m_bpp == 1 || m_bpp == 4 || m_bpp == 8 ||\n                m_bpp == 24 || m_bpp == 32 ))\n            {\n                if( m_bpp <= 8 )\n                {\n                    uchar buffer[256*3];\n                    int j, clrused = 1 << m_bpp;\n                    m_strm.getBytes( buffer, clrused*3 );\n                    for( j = 0; j < clrused; j++ )\n                    {\n                        m_palette[j].b = buffer[3*j+0];\n                        m_palette[j].g = buffer[3*j+1];\n                        m_palette[j].r = buffer[3*j+2];\n                    }\n                }\n                result = true;\n            }\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,7 @@\n         m_offset = m_strm.getDWord();\n \n         int  size = m_strm.getDWord();\n+        CV_Assert(size > 0); // overflow, 2Gb limit\n \n         if( size >= 36 )\n         {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        CV_Assert(size > 0); // overflow, 2Gb limit"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/basic_conversion",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "static void\nbasic_conversion (void *src, const struct channel_layout *layout, int src_sampe_size,\n    int src_width, void *target, int target_channels, int target_depth)\n{\n    switch (target_depth) {\n        case CV_8U:\n        {\n            uchar *d = (uchar *)target, *s = (uchar *)src,\n                *end = ((uchar *)src) + src_width;\n            switch (target_channels) {\n                case 1:\n                    for( ; s < end; d += 3, s += src_sampe_size )\n                        d[0] = d[1] = d[2] = s[layout->graychan];\n                    break;\n                case 3:\n                    for( ; s < end; d += 3, s += src_sampe_size ) {\n                        d[0] = s[layout->bchan];\n                        d[1] = s[layout->gchan];\n                        d[2] = s[layout->rchan];\n                    }\n                    break;\n                default:\n                    assert (0);\n            }\n            break;\n        }\n        case CV_16U:\n        {\n            ushort *d = (ushort *)target, *s = (ushort *)src,\n                *end = ((ushort *)src) + src_width;\n            switch (target_channels) {\n                case 1:\n                    for( ; s < end; d += 3, s += src_sampe_size )\n                        d[0] = d[1] = d[2] = s[layout->graychan];\n                    break;\n                case 3:\n                    for( ; s < end; d += 3, s += src_sampe_size ) {\n                        d[0] = s[layout->bchan];\n                        d[1] = s[layout->gchan];\n                        d[2] = s[layout->rchan];\n                    }\n                    break;\n                default:\n                    assert (0);\n            }\n            break;\n        }\n        default:\n            assert (0);\n    }\n}",
        "func": "static void\nbasic_conversion (void *src, const struct channel_layout *layout, int src_sampe_size,\n    int src_width, void *target, int target_channels, int target_depth)\n{\n    switch (target_depth) {\n        case CV_8U:\n        {\n            uchar *d = (uchar *)target, *s = (uchar *)src,\n                *end = ((uchar *)src) + src_width;\n            switch (target_channels) {\n                case 1:\n                    for( ; s < end; d += 3, s += src_sampe_size )\n                        d[0] = d[1] = d[2] = s[layout->graychan];\n                    break;\n                case 3:\n                    for( ; s < end; d += 3, s += src_sampe_size ) {\n                        d[0] = s[layout->bchan];\n                        d[1] = s[layout->gchan];\n                        d[2] = s[layout->rchan];\n                    }\n                    break;\n                default:\n                    CV_Error(Error::StsInternal, \"\");\n            }\n            break;\n        }\n        case CV_16U:\n        {\n            ushort *d = (ushort *)target, *s = (ushort *)src,\n                *end = ((ushort *)src) + src_width;\n            switch (target_channels) {\n                case 1:\n                    for( ; s < end; d += 3, s += src_sampe_size )\n                        d[0] = d[1] = d[2] = s[layout->graychan];\n                    break;\n                case 3:\n                    for( ; s < end; d += 3, s += src_sampe_size ) {\n                        d[0] = s[layout->bchan];\n                        d[1] = s[layout->gchan];\n                        d[2] = s[layout->rchan];\n                    }\n                    break;\n                default:\n                    CV_Error(Error::StsInternal, \"\");\n            }\n            break;\n        }\n        default:\n            CV_Error(Error::StsInternal, \"\");\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,7 @@\n                     }\n                     break;\n                 default:\n-                    assert (0);\n+                    CV_Error(Error::StsInternal, \"\");\n             }\n             break;\n         }\n@@ -41,11 +41,11 @@\n                     }\n                     break;\n                 default:\n-                    assert (0);\n+                    CV_Error(Error::StsInternal, \"\");\n             }\n             break;\n         }\n         default:\n-            assert (0);\n+            CV_Error(Error::StsInternal, \"\");\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "                    assert (0);",
                "                    assert (0);",
                "            assert (0);"
            ],
            "added_lines": [
                "                    CV_Error(Error::StsInternal, \"\");",
                "                    CV_Error(Error::StsInternal, \"\");",
                "            CV_Error(Error::StsInternal, \"\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/PAMEncoder::write",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "bool PAMEncoder::write( const Mat& img, const std::vector<int>& params )\n{\n\n    WLByteStream strm;\n\n    int width = img.cols, height = img.rows;\n    int stride = width*(int)img.elemSize();\n    const uchar* data = img.ptr();\n    const struct pam_format *fmt = NULL;\n    int x, y, tmp, bufsize = 256;\n\n    /* parse save file type */\n    for( size_t i = 0; i < params.size(); i += 2 )\n        if( params[i] == CV_IMWRITE_PAM_TUPLETYPE ) {\n            if ( params[i+1] > CV_IMWRITE_PAM_FORMAT_NULL &&\n                 params[i+1] < (int) PAM_FORMATS_NO)\n                fmt = &formats[params[i+1]];\n        }\n\n    if( m_buf )\n    {\n        if( !strm.open(*m_buf) )\n            return false;\n        m_buf->reserve( alignSize(256 + stride*height, 256));\n    }\n    else if( !strm.open(m_filename) )\n        return false;\n\n    tmp = width * (int)img.elemSize();\n\n    if (bufsize < tmp)\n        bufsize = tmp;\n\n    AutoBuffer<char> _buffer(bufsize);\n    char* buffer = _buffer;\n\n    /* write header */\n    tmp = 0;\n    tmp += sprintf( buffer, \"P7\\n\");\n    tmp += sprintf( buffer + tmp, \"WIDTH %d\\n\", width);\n    tmp += sprintf( buffer + tmp, \"HEIGHT %d\\n\", height);\n    tmp += sprintf( buffer + tmp, \"DEPTH %d\\n\", img.channels());\n    tmp += sprintf( buffer + tmp, \"MAXVAL %d\\n\", (1 << img.elemSize1()*8) - 1);\n    if (fmt)\n        tmp += sprintf( buffer + tmp, \"TUPLTYPE %s\\n\", fmt->name );\n    tmp += sprintf( buffer + tmp, \"ENDHDR\\n\" );\n\n    strm.putBytes( buffer, (int)strlen(buffer) );\n    /* write data */\n    if (img.depth() == CV_8U)\n        strm.putBytes( data, stride*height );\n    else if (img.depth() == CV_16U) {\n        /* fix endianess */\n        if (!isBigEndian()) {\n            for( y = 0; y < height; y++ ) {\n                memcpy( buffer, img.ptr(y), stride );\n                for( x = 0; x < stride; x += 2 )\n                {\n                    uchar v = buffer[x];\n                    buffer[x] = buffer[x + 1];\n                    buffer[x + 1] = v;\n                }\n                strm.putBytes( buffer, stride );\n            }\n        } else\n            strm.putBytes( data, stride*height );\n    } else\n        assert (0);\n\n    strm.close();\n    return true;\n}",
        "func": "bool PAMEncoder::write( const Mat& img, const std::vector<int>& params )\n{\n\n    WLByteStream strm;\n\n    int width = img.cols, height = img.rows;\n    int stride = width*(int)img.elemSize();\n    const uchar* data = img.ptr();\n    const struct pam_format *fmt = NULL;\n    int x, y, tmp, bufsize = 256;\n\n    /* parse save file type */\n    for( size_t i = 0; i < params.size(); i += 2 )\n        if( params[i] == CV_IMWRITE_PAM_TUPLETYPE ) {\n            if ( params[i+1] > CV_IMWRITE_PAM_FORMAT_NULL &&\n                 params[i+1] < (int) PAM_FORMATS_NO)\n                fmt = &formats[params[i+1]];\n        }\n\n    if( m_buf )\n    {\n        if( !strm.open(*m_buf) )\n            return false;\n        m_buf->reserve( alignSize(256 + stride*height, 256));\n    }\n    else if( !strm.open(m_filename) )\n        return false;\n\n    tmp = width * (int)img.elemSize();\n\n    if (bufsize < tmp)\n        bufsize = tmp;\n\n    AutoBuffer<char> _buffer(bufsize);\n    char* buffer = _buffer;\n\n    /* write header */\n    tmp = 0;\n    tmp += sprintf( buffer, \"P7\\n\");\n    tmp += sprintf( buffer + tmp, \"WIDTH %d\\n\", width);\n    tmp += sprintf( buffer + tmp, \"HEIGHT %d\\n\", height);\n    tmp += sprintf( buffer + tmp, \"DEPTH %d\\n\", img.channels());\n    tmp += sprintf( buffer + tmp, \"MAXVAL %d\\n\", (1 << img.elemSize1()*8) - 1);\n    if (fmt)\n        tmp += sprintf( buffer + tmp, \"TUPLTYPE %s\\n\", fmt->name );\n    tmp += sprintf( buffer + tmp, \"ENDHDR\\n\" );\n\n    strm.putBytes( buffer, (int)strlen(buffer) );\n    /* write data */\n    if (img.depth() == CV_8U)\n        strm.putBytes( data, stride*height );\n    else if (img.depth() == CV_16U) {\n        /* fix endianess */\n        if (!isBigEndian()) {\n            for( y = 0; y < height; y++ ) {\n                memcpy( buffer, img.ptr(y), stride );\n                for( x = 0; x < stride; x += 2 )\n                {\n                    uchar v = buffer[x];\n                    buffer[x] = buffer[x + 1];\n                    buffer[x + 1] = v;\n                }\n                strm.putBytes( buffer, stride );\n            }\n        } else\n            strm.putBytes( data, stride*height );\n    } else\n        CV_Error(Error::StsInternal, \"\");\n\n    strm.close();\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -65,7 +65,7 @@\n         } else\n             strm.putBytes( data, stride*height );\n     } else\n-        assert (0);\n+        CV_Error(Error::StsInternal, \"\");\n \n     strm.close();\n     return true;",
        "diff_line_info": {
            "deleted_lines": [
                "        assert (0);"
            ],
            "added_lines": [
                "        CV_Error(Error::StsInternal, \"\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/cvConvertImage",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "CV_IMPL void\ncvConvertImage( const CvArr* srcarr, CvArr* dstarr, int flags )\n{\n    CvMat* temp = 0;\n\n    CV_FUNCNAME( \"cvConvertImage\" );\n\n    __BEGIN__;\n\n    CvMat srcstub, *src;\n    CvMat dststub, *dst;\n    int src_cn, dst_cn, swap_rb = flags & CV_CVTIMG_SWAP_RB;\n\n    CV_CALL( src = cvGetMat( srcarr, &srcstub ));\n    CV_CALL( dst = cvGetMat( dstarr, &dststub ));\n\n    src_cn = CV_MAT_CN( src->type );\n    dst_cn = CV_MAT_CN( dst->type );\n\n    if( src_cn != 1 && src_cn != 3 && src_cn != 4 )\n        CV_ERROR( CV_BadNumChannels, \"Source image must have 1, 3 or 4 channels\" );\n\n    if( CV_MAT_DEPTH( dst->type ) != CV_8U )\n        CV_ERROR( CV_BadDepth, \"Destination image must be 8u\" );\n\n    if( CV_MAT_CN(dst->type) != 1 && CV_MAT_CN(dst->type) != 3 )\n        CV_ERROR( CV_BadNumChannels, \"Destination image must have 1 or 3 channels\" );\n\n    if( !CV_ARE_DEPTHS_EQ( src, dst ))\n    {\n        int src_depth = CV_MAT_DEPTH(src->type);\n        double scale = src_depth <= CV_8S ? 1 : src_depth <= CV_32S ? 1./256 : 255;\n        double shift = src_depth == CV_8S || src_depth == CV_16S ? 128 : 0;\n\n        if( !CV_ARE_CNS_EQ( src, dst ))\n        {\n            temp = cvCreateMat( src->height, src->width,\n                (src->type & CV_MAT_CN_MASK)|(dst->type & CV_MAT_DEPTH_MASK));\n            cvConvertScale( src, temp, scale, shift );\n            src = temp;\n        }\n        else\n        {\n            cvConvertScale( src, dst, scale, shift );\n            src = dst;\n        }\n    }\n\n    if( src_cn != dst_cn || (src_cn == 3 && swap_rb) )\n    {\n        uchar *s = src->data.ptr, *d = dst->data.ptr;\n        int s_step = src->step, d_step = dst->step;\n        int code = src_cn*10 + dst_cn;\n        CvSize size(src->cols, src->rows);\n\n        if( CV_IS_MAT_CONT(src->type & dst->type) )\n        {\n            size.width *= size.height;\n            size.height = 1;\n            s_step = d_step = /*CV_STUB_STEP*/ (1 << 30);\n        }\n\n        switch( code )\n        {\n        case 13:\n            icvCvt_Gray2BGR_8u_C1C3R( s, s_step, d, d_step, size );\n            break;\n        case 31:\n            icvCvt_BGR2Gray_8u_C3C1R( s, s_step, d, d_step, size, swap_rb );\n            break;\n        case 33:\n            assert( swap_rb );\n            icvCvt_RGB2BGR_8u_C3R( s, s_step, d, d_step, size );\n            break;\n        case 41:\n            icvCvt_BGRA2Gray_8u_C4C1R( s, s_step, d, d_step, size, swap_rb );\n            break;\n        case 43:\n            icvCvt_BGRA2BGR_8u_C4C3R( s, s_step, d, d_step, size, swap_rb );\n            break;\n        default:\n            CV_ERROR( CV_StsUnsupportedFormat, \"Unsupported combination of input/output formats\" );\n        }\n        src = dst;\n    }\n\n    if( flags & CV_CVTIMG_FLIP )\n    {\n        CV_CALL( cvFlip( src, dst, 0 ));\n    }\n    else if( src != dst )\n    {\n        CV_CALL( cvCopy( src, dst ));\n    }\n\n    __END__;\n\n    cvReleaseMat( &temp );\n}",
        "func": "CV_IMPL void\ncvConvertImage( const CvArr* srcarr, CvArr* dstarr, int flags )\n{\n    CvMat* temp = 0;\n\n    CV_FUNCNAME( \"cvConvertImage\" );\n\n    __BEGIN__;\n\n    CvMat srcstub, *src;\n    CvMat dststub, *dst;\n    int src_cn, dst_cn, swap_rb = flags & CV_CVTIMG_SWAP_RB;\n\n    CV_CALL( src = cvGetMat( srcarr, &srcstub ));\n    CV_CALL( dst = cvGetMat( dstarr, &dststub ));\n\n    src_cn = CV_MAT_CN( src->type );\n    dst_cn = CV_MAT_CN( dst->type );\n\n    if( src_cn != 1 && src_cn != 3 && src_cn != 4 )\n        CV_ERROR( CV_BadNumChannels, \"Source image must have 1, 3 or 4 channels\" );\n\n    if( CV_MAT_DEPTH( dst->type ) != CV_8U )\n        CV_ERROR( CV_BadDepth, \"Destination image must be 8u\" );\n\n    if( CV_MAT_CN(dst->type) != 1 && CV_MAT_CN(dst->type) != 3 )\n        CV_ERROR( CV_BadNumChannels, \"Destination image must have 1 or 3 channels\" );\n\n    if( !CV_ARE_DEPTHS_EQ( src, dst ))\n    {\n        int src_depth = CV_MAT_DEPTH(src->type);\n        double scale = src_depth <= CV_8S ? 1 : src_depth <= CV_32S ? 1./256 : 255;\n        double shift = src_depth == CV_8S || src_depth == CV_16S ? 128 : 0;\n\n        if( !CV_ARE_CNS_EQ( src, dst ))\n        {\n            temp = cvCreateMat( src->height, src->width,\n                (src->type & CV_MAT_CN_MASK)|(dst->type & CV_MAT_DEPTH_MASK));\n            cvConvertScale( src, temp, scale, shift );\n            src = temp;\n        }\n        else\n        {\n            cvConvertScale( src, dst, scale, shift );\n            src = dst;\n        }\n    }\n\n    if( src_cn != dst_cn || (src_cn == 3 && swap_rb) )\n    {\n        uchar *s = src->data.ptr, *d = dst->data.ptr;\n        int s_step = src->step, d_step = dst->step;\n        int code = src_cn*10 + dst_cn;\n        CvSize size(src->cols, src->rows);\n\n        if( CV_IS_MAT_CONT(src->type & dst->type) )\n        {\n            size.width *= size.height;\n            size.height = 1;\n            s_step = d_step = /*CV_STUB_STEP*/ (1 << 30);\n        }\n\n        switch( code )\n        {\n        case 13:\n            icvCvt_Gray2BGR_8u_C1C3R( s, s_step, d, d_step, size );\n            break;\n        case 31:\n            icvCvt_BGR2Gray_8u_C3C1R( s, s_step, d, d_step, size, swap_rb );\n            break;\n        case 33:\n            CV_Assert(swap_rb);\n            icvCvt_RGB2BGR_8u_C3R( s, s_step, d, d_step, size );\n            break;\n        case 41:\n            icvCvt_BGRA2Gray_8u_C4C1R( s, s_step, d, d_step, size, swap_rb );\n            break;\n        case 43:\n            icvCvt_BGRA2BGR_8u_C4C3R( s, s_step, d, d_step, size, swap_rb );\n            break;\n        default:\n            CV_ERROR( CV_StsUnsupportedFormat, \"Unsupported combination of input/output formats\" );\n        }\n        src = dst;\n    }\n\n    if( flags & CV_CVTIMG_FLIP )\n    {\n        CV_CALL( cvFlip( src, dst, 0 ));\n    }\n    else if( src != dst )\n    {\n        CV_CALL( cvCopy( src, dst ));\n    }\n\n    __END__;\n\n    cvReleaseMat( &temp );\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -69,7 +69,7 @@\n             icvCvt_BGR2Gray_8u_C3C1R( s, s_step, d, d_step, size, swap_rb );\n             break;\n         case 33:\n-            assert( swap_rb );\n+            CV_Assert(swap_rb);\n             icvCvt_RGB2BGR_8u_C3R( s, s_step, d, d_step, size );\n             break;\n         case 41:",
        "diff_line_info": {
            "deleted_lines": [
                "            assert( swap_rb );"
            ],
            "added_lines": [
                "            CV_Assert(swap_rb);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/WBaseStream::getPos",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "int  WBaseStream::getPos()\n{\n    assert( isOpened() );\n    return m_block_pos + (int)(m_current - m_start);\n}",
        "func": "int  WBaseStream::getPos()\n{\n    CV_Assert(isOpened());\n    return m_block_pos + (int)(m_current - m_start);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int  WBaseStream::getPos()\n {\n-    assert( isOpened() );\n+    CV_Assert(isOpened());\n     return m_block_pos + (int)(m_current - m_start);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    assert( isOpened() );"
            ],
            "added_lines": [
                "    CV_Assert(isOpened());"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/WBaseStream::writeBlock",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "void  WBaseStream::writeBlock()\n{\n    int size = (int)(m_current - m_start);\n\n    assert( isOpened() );\n    if( size == 0 )\n        return;\n\n    if( m_buf )\n    {\n        size_t sz = m_buf->size();\n        m_buf->resize( sz + size );\n        memcpy( &(*m_buf)[sz], m_start, size );\n    }\n    else\n    {\n        fwrite( m_start, 1, size, m_file );\n    }\n    m_current = m_start;\n    m_block_pos += size;\n}",
        "func": "void  WBaseStream::writeBlock()\n{\n    int size = (int)(m_current - m_start);\n\n    CV_Assert(isOpened());\n    if( size == 0 )\n        return;\n\n    if( m_buf )\n    {\n        size_t sz = m_buf->size();\n        m_buf->resize( sz + size );\n        memcpy( &(*m_buf)[sz], m_start, size );\n    }\n    else\n    {\n        fwrite( m_start, 1, size, m_file );\n    }\n    m_current = m_start;\n    m_block_pos += size;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n {\n     int size = (int)(m_current - m_start);\n \n-    assert( isOpened() );\n+    CV_Assert(isOpened());\n     if( size == 0 )\n         return;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    assert( isOpened() );"
            ],
            "added_lines": [
                "    CV_Assert(isOpened());"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/RBaseStream::skip",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "void  RBaseStream::skip( int bytes )\n{\n    assert( bytes >= 0 );\n    m_current += bytes;\n}",
        "func": "void  RBaseStream::skip( int bytes )\n{\n    CV_Assert(bytes >= 0);\n    m_current += bytes;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n void  RBaseStream::skip( int bytes )\n {\n-    assert( bytes >= 0 );\n+    CV_Assert(bytes >= 0);\n     m_current += bytes;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    assert( bytes >= 0 );"
            ],
            "added_lines": [
                "    CV_Assert(bytes >= 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/RLByteStream::getBytes",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "int RLByteStream::getBytes( void* buffer, int count )\n{\n    uchar*  data = (uchar*)buffer;\n    int readed = 0;\n    assert( count >= 0 );\n\n    while( count > 0 )\n    {\n        int l;\n\n        for(;;)\n        {\n            l = (int)(m_end - m_current);\n            if( l > count ) l = count;\n            if( l > 0 ) break;\n            readBlock();\n        }\n        memcpy( data, m_current, l );\n        m_current += l;\n        data += l;\n        count -= l;\n        readed += l;\n    }\n    return readed;\n}",
        "func": "int RLByteStream::getBytes( void* buffer, int count )\n{\n    uchar*  data = (uchar*)buffer;\n    int readed = 0;\n    CV_Assert(count >= 0);\n\n    while( count > 0 )\n    {\n        int l;\n\n        for(;;)\n        {\n            l = (int)(m_end - m_current);\n            if( l > count ) l = count;\n            if( l > 0 ) break;\n            readBlock();\n        }\n        memcpy( data, m_current, l );\n        m_current += l;\n        data += l;\n        count -= l;\n        readed += l;\n    }\n    return readed;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n {\n     uchar*  data = (uchar*)buffer;\n     int readed = 0;\n-    assert( count >= 0 );\n+    CV_Assert(count >= 0);\n \n     while( count > 0 )\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "    assert( count >= 0 );"
            ],
            "added_lines": [
                "    CV_Assert(count >= 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/RBaseStream::getPos",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "int  RBaseStream::getPos()\n{\n    assert( isOpened() );\n    return m_block_pos + (int)(m_current - m_start);\n}",
        "func": "int  RBaseStream::getPos()\n{\n    CV_Assert(isOpened());\n    return m_block_pos + (int)(m_current - m_start);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n int  RBaseStream::getPos()\n {\n-    assert( isOpened() );\n+    CV_Assert(isOpened());\n     return m_block_pos + (int)(m_current - m_start);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    assert( isOpened() );"
            ],
            "added_lines": [
                "    CV_Assert(isOpened());"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/WLByteStream::putBytes",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "void WLByteStream::putBytes( const void* buffer, int count )\n{\n    uchar* data = (uchar*)buffer;\n\n    assert( data && m_current && count >= 0 );\n\n    while( count )\n    {\n        int l = (int)(m_end - m_current);\n\n        if( l > count )\n            l = count;\n\n        if( l > 0 )\n        {\n            memcpy( m_current, data, l );\n            m_current += l;\n            data += l;\n            count -= l;\n        }\n        if( m_current == m_end )\n            writeBlock();\n    }\n}",
        "func": "void WLByteStream::putBytes( const void* buffer, int count )\n{\n    uchar* data = (uchar*)buffer;\n\n    CV_Assert(data && m_current && count >= 0);\n\n    while( count )\n    {\n        int l = (int)(m_end - m_current);\n\n        if( l > count )\n            l = count;\n\n        if( l > 0 )\n        {\n            memcpy( m_current, data, l );\n            m_current += l;\n            data += l;\n            count -= l;\n        }\n        if( m_current == m_end )\n            writeBlock();\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n {\n     uchar* data = (uchar*)buffer;\n \n-    assert( data && m_current && count >= 0 );\n+    CV_Assert(data && m_current && count >= 0);\n \n     while( count )\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "    assert( data && m_current && count >= 0 );"
            ],
            "added_lines": [
                "    CV_Assert(data && m_current && count >= 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/RBaseStream::setPos",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "void  RBaseStream::setPos( int pos )\n{\n    assert( isOpened() && pos >= 0 );\n\n    if( !m_file )\n    {\n        m_current = m_start + pos;\n        m_block_pos = 0;\n        return;\n    }\n\n    int offset = pos % m_block_size;\n    m_block_pos = pos - offset;\n    m_current = m_start + offset;\n}",
        "func": "void  RBaseStream::setPos( int pos )\n{\n    CV_Assert(isOpened() && pos >= 0);\n\n    if( !m_file )\n    {\n        m_current = m_start + pos;\n        m_block_pos = 0;\n        return;\n    }\n\n    int offset = pos % m_block_size;\n    m_block_pos = pos - offset;\n    m_current = m_start + offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n void  RBaseStream::setPos( int pos )\n {\n-    assert( isOpened() && pos >= 0 );\n+    CV_Assert(isOpened() && pos >= 0);\n \n     if( !m_file )\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "    assert( isOpened() && pos >= 0 );"
            ],
            "added_lines": [
                "    CV_Assert(isOpened() && pos >= 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/SunRasterDecoder::readData",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "bool  SunRasterDecoder::readData( Mat& img )\n{\n    int color = img.channels() > 1;\n    uchar* data = img.ptr();\n    size_t step = img.step;\n    uchar  gray_palette[256] = {0};\n    bool   result = false;\n    int  src_pitch = ((m_width*m_bpp + 7)/8 + 1) & -2;\n    int  nch = color ? 3 : 1;\n    int  width3 = m_width*nch;\n    int  y;\n\n    if( m_offset < 0 || !m_strm.isOpened())\n        return false;\n\n    AutoBuffer<uchar> _src(src_pitch + 32);\n    uchar* src = _src;\n    AutoBuffer<uchar> _bgr(m_width*3 + 32);\n    uchar* bgr = _bgr;\n\n    if( !color && m_maptype == RMT_EQUAL_RGB )\n        CvtPaletteToGray( m_palette, gray_palette, 1 << m_bpp );\n\n    CV_TRY\n    {\n        m_strm.setPos( m_offset );\n\n        switch( m_bpp )\n        {\n        /************************* 1 BPP ************************/\n        case 1:\n            if( m_type != RAS_BYTE_ENCODED )\n            {\n                for( y = 0; y < m_height; y++, data += step )\n                {\n                    m_strm.getBytes( src, src_pitch );\n                    if( color )\n                        FillColorRow1( data, src, m_width, m_palette );\n                    else\n                        FillGrayRow1( data, src, m_width, gray_palette );\n                }\n                result = true;\n            }\n            else\n            {\n                uchar* line_end = src + (m_width*m_bpp + 7)/8;\n                uchar* tsrc = src;\n                y = 0;\n\n                for(;;)\n                {\n                    int max_count = (int)(line_end - tsrc);\n                    int code = 0, len = 0, len1 = 0;\n\n                    do\n                    {\n                        code = m_strm.getByte();\n                        if( code == 0x80 )\n                        {\n                            len = m_strm.getByte();\n                            if( len != 0 ) break;\n                        }\n                        tsrc[len1] = (uchar)code;\n                    }\n                    while( ++len1 < max_count );\n\n                    tsrc += len1;\n\n                    if( len > 0 ) // encoded mode\n                    {\n                        ++len;\n                        code = m_strm.getByte();\n                        if( len > line_end - tsrc )\n                        {\n                            assert(0);\n                            goto bad_decoding_1bpp;\n                        }\n\n                        memset( tsrc, code, len );\n                        tsrc += len;\n                    }\n\n                    if( tsrc >= line_end )\n                    {\n                        tsrc = src;\n                        if( color )\n                            FillColorRow1( data, src, m_width, m_palette );\n                        else\n                            FillGrayRow1( data, src, m_width, gray_palette );\n                        data += step;\n                        if( ++y >= m_height ) break;\n                    }\n                }\n                result = true;\nbad_decoding_1bpp:\n                ;\n            }\n            break;\n        /************************* 8 BPP ************************/\n        case 8:\n            if( m_type != RAS_BYTE_ENCODED )\n            {\n                for( y = 0; y < m_height; y++, data += step )\n                {\n                    m_strm.getBytes( src, src_pitch );\n                    if( color )\n                        FillColorRow8( data, src, m_width, m_palette );\n                    else\n                        FillGrayRow8( data, src, m_width, gray_palette );\n                }\n                result = true;\n            }\n            else // RLE-encoded\n            {\n                uchar* line_end = data + width3;\n                y = 0;\n\n                for(;;)\n                {\n                    int max_count = (int)(line_end - data);\n                    int code = 0, len = 0, len1;\n                    uchar* tsrc = src;\n\n                    do\n                    {\n                        code = m_strm.getByte();\n                        if( code == 0x80 )\n                        {\n                            len = m_strm.getByte();\n                            if( len != 0 ) break;\n                        }\n                        *tsrc++ = (uchar)code;\n                    }\n                    while( (max_count -= nch) > 0 );\n\n                    len1 = (int)(tsrc - src);\n\n                    if( len1 > 0 )\n                    {\n                        if( color )\n                            FillColorRow8( data, src, len1, m_palette );\n                        else\n                            FillGrayRow8( data, src, len1, gray_palette );\n                        data += len1*nch;\n                    }\n\n                    if( len > 0 ) // encoded mode\n                    {\n                        len = (len + 1)*nch;\n                        code = m_strm.getByte();\n\n                        if( color )\n                            data = FillUniColor( data, line_end, validateToInt(step), width3,\n                                                 y, m_height, len,\n                                                 m_palette[code] );\n                        else\n                            data = FillUniGray( data, line_end, validateToInt(step), width3,\n                                                y, m_height, len,\n                                                gray_palette[code] );\n                        if( y >= m_height )\n                            break;\n                    }\n\n                    if( data == line_end )\n                    {\n                        if( m_strm.getByte() != 0 )\n                            goto bad_decoding_end;\n                        line_end += step;\n                        data = line_end - width3;\n                        if( ++y >= m_height ) break;\n                    }\n                }\n\n                result = true;\nbad_decoding_end:\n                ;\n            }\n            break;\n        /************************* 24 BPP ************************/\n        case 24:\n            for( y = 0; y < m_height; y++, data += step )\n            {\n                m_strm.getBytes( color ? data : bgr, src_pitch );\n\n                if( color )\n                {\n                    if( m_type == RAS_FORMAT_RGB )\n                        icvCvt_RGB2BGR_8u_C3R( data, 0, data, 0, cvSize(m_width,1) );\n                }\n                else\n                {\n                    icvCvt_BGR2Gray_8u_C3C1R( bgr, 0, data, 0, cvSize(m_width,1),\n                                              m_type == RAS_FORMAT_RGB ? 2 : 0 );\n                }\n            }\n            result = true;\n            break;\n        /************************* 32 BPP ************************/\n        case 32:\n            for( y = 0; y < m_height; y++, data += step )\n            {\n                /* hack: a0 b0 g0 r0 a1 b1 g1 r1 ... are written to src + 3,\n                   so when we look at src + 4, we see b0 g0 r0 x b1 g1 g1 x ... */\n                m_strm.getBytes( src + 3, src_pitch );\n\n                if( color )\n                    icvCvt_BGRA2BGR_8u_C4C3R( src + 4, 0, data, 0, cvSize(m_width,1),\n                                              m_type == RAS_FORMAT_RGB ? 2 : 0 );\n                else\n                    icvCvt_BGRA2Gray_8u_C4C1R( src + 4, 0, data, 0, cvSize(m_width,1),\n                                               m_type == RAS_FORMAT_RGB ? 2 : 0 );\n            }\n            result = true;\n            break;\n        default:\n            assert(0);\n        }\n    }",
        "func": "bool  SunRasterDecoder::readData( Mat& img )\n{\n    int color = img.channels() > 1;\n    uchar* data = img.ptr();\n    size_t step = img.step;\n    uchar  gray_palette[256] = {0};\n    bool   result = false;\n    int  src_pitch = ((m_width*m_bpp + 7)/8 + 1) & -2;\n    int  nch = color ? 3 : 1;\n    int  width3 = m_width*nch;\n    int  y;\n\n    if( m_offset < 0 || !m_strm.isOpened())\n        return false;\n\n    AutoBuffer<uchar> _src(src_pitch + 32);\n    uchar* src = _src;\n    AutoBuffer<uchar> _bgr(m_width*3 + 32);\n    uchar* bgr = _bgr;\n\n    if( !color && m_maptype == RMT_EQUAL_RGB )\n        CvtPaletteToGray( m_palette, gray_palette, 1 << m_bpp );\n\n    CV_TRY\n    {\n        m_strm.setPos( m_offset );\n\n        switch( m_bpp )\n        {\n        /************************* 1 BPP ************************/\n        case 1:\n            if( m_type != RAS_BYTE_ENCODED )\n            {\n                for( y = 0; y < m_height; y++, data += step )\n                {\n                    m_strm.getBytes( src, src_pitch );\n                    if( color )\n                        FillColorRow1( data, src, m_width, m_palette );\n                    else\n                        FillGrayRow1( data, src, m_width, gray_palette );\n                }\n                result = true;\n            }\n            else\n            {\n                uchar* line_end = src + (m_width*m_bpp + 7)/8;\n                uchar* tsrc = src;\n                y = 0;\n\n                for(;;)\n                {\n                    int max_count = (int)(line_end - tsrc);\n                    int code = 0, len = 0, len1 = 0;\n\n                    do\n                    {\n                        code = m_strm.getByte();\n                        if( code == 0x80 )\n                        {\n                            len = m_strm.getByte();\n                            if( len != 0 ) break;\n                        }\n                        tsrc[len1] = (uchar)code;\n                    }\n                    while( ++len1 < max_count );\n\n                    tsrc += len1;\n\n                    if( len > 0 ) // encoded mode\n                    {\n                        ++len;\n                        code = m_strm.getByte();\n                        if( len > line_end - tsrc )\n                        {\n                            CV_Error(Error::StsInternal, \"\");\n                            goto bad_decoding_1bpp;\n                        }\n\n                        memset( tsrc, code, len );\n                        tsrc += len;\n                    }\n\n                    if( tsrc >= line_end )\n                    {\n                        tsrc = src;\n                        if( color )\n                            FillColorRow1( data, src, m_width, m_palette );\n                        else\n                            FillGrayRow1( data, src, m_width, gray_palette );\n                        data += step;\n                        if( ++y >= m_height ) break;\n                    }\n                }\n                result = true;\nbad_decoding_1bpp:\n                ;\n            }\n            break;\n        /************************* 8 BPP ************************/\n        case 8:\n            if( m_type != RAS_BYTE_ENCODED )\n            {\n                for( y = 0; y < m_height; y++, data += step )\n                {\n                    m_strm.getBytes( src, src_pitch );\n                    if( color )\n                        FillColorRow8( data, src, m_width, m_palette );\n                    else\n                        FillGrayRow8( data, src, m_width, gray_palette );\n                }\n                result = true;\n            }\n            else // RLE-encoded\n            {\n                uchar* line_end = data + width3;\n                y = 0;\n\n                for(;;)\n                {\n                    int max_count = (int)(line_end - data);\n                    int code = 0, len = 0, len1;\n                    uchar* tsrc = src;\n\n                    do\n                    {\n                        code = m_strm.getByte();\n                        if( code == 0x80 )\n                        {\n                            len = m_strm.getByte();\n                            if( len != 0 ) break;\n                        }\n                        *tsrc++ = (uchar)code;\n                    }\n                    while( (max_count -= nch) > 0 );\n\n                    len1 = (int)(tsrc - src);\n\n                    if( len1 > 0 )\n                    {\n                        if( color )\n                            FillColorRow8( data, src, len1, m_palette );\n                        else\n                            FillGrayRow8( data, src, len1, gray_palette );\n                        data += len1*nch;\n                    }\n\n                    if( len > 0 ) // encoded mode\n                    {\n                        len = (len + 1)*nch;\n                        code = m_strm.getByte();\n\n                        if( color )\n                            data = FillUniColor( data, line_end, validateToInt(step), width3,\n                                                 y, m_height, len,\n                                                 m_palette[code] );\n                        else\n                            data = FillUniGray( data, line_end, validateToInt(step), width3,\n                                                y, m_height, len,\n                                                gray_palette[code] );\n                        if( y >= m_height )\n                            break;\n                    }\n\n                    if( data == line_end )\n                    {\n                        if( m_strm.getByte() != 0 )\n                            goto bad_decoding_end;\n                        line_end += step;\n                        data = line_end - width3;\n                        if( ++y >= m_height ) break;\n                    }\n                }\n\n                result = true;\nbad_decoding_end:\n                ;\n            }\n            break;\n        /************************* 24 BPP ************************/\n        case 24:\n            for( y = 0; y < m_height; y++, data += step )\n            {\n                m_strm.getBytes( color ? data : bgr, src_pitch );\n\n                if( color )\n                {\n                    if( m_type == RAS_FORMAT_RGB )\n                        icvCvt_RGB2BGR_8u_C3R( data, 0, data, 0, cvSize(m_width,1) );\n                }\n                else\n                {\n                    icvCvt_BGR2Gray_8u_C3C1R( bgr, 0, data, 0, cvSize(m_width,1),\n                                              m_type == RAS_FORMAT_RGB ? 2 : 0 );\n                }\n            }\n            result = true;\n            break;\n        /************************* 32 BPP ************************/\n        case 32:\n            for( y = 0; y < m_height; y++, data += step )\n            {\n                /* hack: a0 b0 g0 r0 a1 b1 g1 r1 ... are written to src + 3,\n                   so when we look at src + 4, we see b0 g0 r0 x b1 g1 g1 x ... */\n                m_strm.getBytes( src + 3, src_pitch );\n\n                if( color )\n                    icvCvt_BGRA2BGR_8u_C4C3R( src + 4, 0, data, 0, cvSize(m_width,1),\n                                              m_type == RAS_FORMAT_RGB ? 2 : 0 );\n                else\n                    icvCvt_BGRA2Gray_8u_C4C1R( src + 4, 0, data, 0, cvSize(m_width,1),\n                                               m_type == RAS_FORMAT_RGB ? 2 : 0 );\n            }\n            result = true;\n            break;\n        default:\n            CV_Error(Error::StsInternal, \"\");\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -72,7 +72,7 @@\n                         code = m_strm.getByte();\n                         if( len > line_end - tsrc )\n                         {\n-                            assert(0);\n+                            CV_Error(Error::StsInternal, \"\");\n                             goto bad_decoding_1bpp;\n                         }\n \n@@ -213,6 +213,6 @@\n             result = true;\n             break;\n         default:\n-            assert(0);\n+            CV_Error(Error::StsInternal, \"\");\n         }\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "                            assert(0);",
                "            assert(0);"
            ],
            "added_lines": [
                "                            CV_Error(Error::StsInternal, \"\");",
                "            CV_Error(Error::StsInternal, \"\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5269",
        "func_name": "opencv/SunRasterDecoder::readHeader",
        "description": "In OpenCV 3.3.1, an assertion failure happens in cv::RBaseStream::setPos in modules/imgcodecs/src/bitstrm.cpp because of an incorrect integer cast.",
        "git_url": "https://github.com/opencv/opencv/commit/be5247921da02e58aa42830c81730ef20a23af80",
        "commit_title": "imgcodecs: remove assert() usage",
        "commit_text": "",
        "func_before": "bool  SunRasterDecoder::readHeader()\n{\n    bool result = false;\n\n    if( !m_strm.open( m_filename )) return false;\n\n    CV_TRY\n    {\n        m_strm.skip( 4 );\n        m_width  = m_strm.getDWord();\n        m_height = m_strm.getDWord();\n        m_bpp    = m_strm.getDWord();\n        int palSize = 3*(1 << m_bpp);\n\n        m_strm.skip( 4 );\n        m_encoding = (SunRasType)m_strm.getDWord();\n        m_maptype = (SunRasMapType)m_strm.getDWord();\n        m_maplength = m_strm.getDWord();\n\n        if( m_width > 0 && m_height > 0 &&\n            (m_bpp == 1 || m_bpp == 8 || m_bpp == 24 || m_bpp == 32) &&\n            (m_encoding == RAS_OLD || m_encoding == RAS_STANDARD ||\n             (m_type == RAS_BYTE_ENCODED && m_bpp == 8) || m_type == RAS_FORMAT_RGB) &&\n            ((m_maptype == RMT_NONE && m_maplength == 0) ||\n             (m_maptype == RMT_EQUAL_RGB && m_maplength <= palSize && m_maplength > 0 && m_bpp <= 8)))\n        {\n            memset( m_palette, 0, sizeof(m_palette));\n\n            if( m_maplength != 0 )\n            {\n                uchar buffer[256*3];\n\n                if( m_strm.getBytes( buffer, m_maplength ) == m_maplength )\n                {\n                    int i;\n                    palSize = m_maplength/3;\n\n                    for( i = 0; i < palSize; i++ )\n                    {\n                        m_palette[i].b = buffer[i + 2*palSize];\n                        m_palette[i].g = buffer[i + palSize];\n                        m_palette[i].r = buffer[i];\n                        m_palette[i].a = 0;\n                    }\n\n                    m_type = IsColorPalette( m_palette, m_bpp ) ? CV_8UC3 : CV_8UC1;\n                    m_offset = m_strm.getPos();\n\n                    assert( m_offset == 32 + m_maplength );\n                    result = true;\n                }\n            }\n            else\n            {\n                m_type = m_bpp > 8 ? CV_8UC3 : CV_8UC1;\n\n                if( CV_MAT_CN(m_type) == 1 )\n                    FillGrayPalette( m_palette, m_bpp );\n\n                m_offset = m_strm.getPos();\n\n                assert( m_offset == 32 + m_maplength );\n                result = true;\n            }\n        }\n    }",
        "func": "bool  SunRasterDecoder::readHeader()\n{\n    bool result = false;\n\n    if( !m_strm.open( m_filename )) return false;\n\n    CV_TRY\n    {\n        m_strm.skip( 4 );\n        m_width  = m_strm.getDWord();\n        m_height = m_strm.getDWord();\n        m_bpp    = m_strm.getDWord();\n        int palSize = 3*(1 << m_bpp);\n\n        m_strm.skip( 4 );\n        m_encoding = (SunRasType)m_strm.getDWord();\n        m_maptype = (SunRasMapType)m_strm.getDWord();\n        m_maplength = m_strm.getDWord();\n\n        if( m_width > 0 && m_height > 0 &&\n            (m_bpp == 1 || m_bpp == 8 || m_bpp == 24 || m_bpp == 32) &&\n            (m_encoding == RAS_OLD || m_encoding == RAS_STANDARD ||\n             (m_type == RAS_BYTE_ENCODED && m_bpp == 8) || m_type == RAS_FORMAT_RGB) &&\n            ((m_maptype == RMT_NONE && m_maplength == 0) ||\n             (m_maptype == RMT_EQUAL_RGB && m_maplength <= palSize && m_maplength > 0 && m_bpp <= 8)))\n        {\n            memset( m_palette, 0, sizeof(m_palette));\n\n            if( m_maplength != 0 )\n            {\n                uchar buffer[256*3];\n\n                if( m_strm.getBytes( buffer, m_maplength ) == m_maplength )\n                {\n                    int i;\n                    palSize = m_maplength/3;\n\n                    for( i = 0; i < palSize; i++ )\n                    {\n                        m_palette[i].b = buffer[i + 2*palSize];\n                        m_palette[i].g = buffer[i + palSize];\n                        m_palette[i].r = buffer[i];\n                        m_palette[i].a = 0;\n                    }\n\n                    m_type = IsColorPalette( m_palette, m_bpp ) ? CV_8UC3 : CV_8UC1;\n                    m_offset = m_strm.getPos();\n\n                    CV_Assert(m_offset == 32 + m_maplength);\n                    result = true;\n                }\n            }\n            else\n            {\n                m_type = m_bpp > 8 ? CV_8UC3 : CV_8UC1;\n\n                if( CV_MAT_CN(m_type) == 1 )\n                    FillGrayPalette( m_palette, m_bpp );\n\n                m_offset = m_strm.getPos();\n\n                CV_Assert(m_offset == 32 + m_maplength);\n                result = true;\n            }\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,7 +46,7 @@\n                     m_type = IsColorPalette( m_palette, m_bpp ) ? CV_8UC3 : CV_8UC1;\n                     m_offset = m_strm.getPos();\n \n-                    assert( m_offset == 32 + m_maplength );\n+                    CV_Assert(m_offset == 32 + m_maplength);\n                     result = true;\n                 }\n             }\n@@ -59,7 +59,7 @@\n \n                 m_offset = m_strm.getPos();\n \n-                assert( m_offset == 32 + m_maplength );\n+                CV_Assert(m_offset == 32 + m_maplength);\n                 result = true;\n             }\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "                    assert( m_offset == 32 + m_maplength );",
                "                assert( m_offset == 32 + m_maplength );"
            ],
            "added_lines": [
                "                    CV_Assert(m_offset == 32 + m_maplength);",
                "                CV_Assert(m_offset == 32 + m_maplength);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-45861",
        "func_name": "justdan96/tsMuxer/VvcUnitWithProfile::profile_tier_level",
        "description": "There is an Assertion `num <= INT_BIT' failed at BitStreamReader::skipBits in /bitStream.h:132 of tsMuxer git-c6a0277.",
        "git_url": "https://github.com/justdan96/tsMuxer/commit/5b8fdee725f8b4b2f8c5dd23da6bc1c05ee7a8f9",
        "commit_title": "Update vvc.cpp",
        "commit_text": "",
        "func_before": "void VvcUnitWithProfile::profile_tier_level(bool profileTierPresentFlag, int MaxNumSubLayersMinus1)\n{\n    if (profileTierPresentFlag)\n    {\n        profile_idc = m_reader.getBits(7);\n        bool tier_flag = m_reader.getBit();\n    }\n    level_idc = m_reader.getBits(8);\n    m_reader.skipBits(2);  // ptl_frame_only_constraint_flag, ptl_multilayer_enabled_flag\n\n    if (profileTierPresentFlag)\n    {                           // general_constraints_info()\n        if (m_reader.getBit())  // gci_present_flag\n        {\n            m_reader.skipBits(32);\n            m_reader.skipBits(32);\n            m_reader.skipBits(7);\n            m_reader.skipBits(m_reader.getBits(8));  // gci_reserved_zero_bit[i]\n        }\n        m_reader.skipBits(m_reader.getBitsLeft() % 8);  // gci_alignment_zero_bit\n    }\n    std::vector<int> ptl_sublayer_level_present_flag;\n    ptl_sublayer_level_present_flag.resize(MaxNumSubLayersMinus1);\n\n    for (int i = MaxNumSubLayersMinus1 - 1; i >= 0; i--) ptl_sublayer_level_present_flag[i] = m_reader.getBit();\n\n    m_reader.skipBits(m_reader.getBitsLeft() % 8);  // ptl_reserved_zero_bit\n\n    for (int i = MaxNumSubLayersMinus1 - 1; i >= 0; i--)\n        if (ptl_sublayer_level_present_flag[i])\n            m_reader.skipBits(8);  // sublayer_level_idc[i]\n    if (profileTierPresentFlag)\n    {\n        int ptl_num_sub_profiles = m_reader.getBits(8);\n        for (int i = 0; i < ptl_num_sub_profiles; i++) m_reader.skipBits(32);  // general_sub_profile_idc[i]\n    }\n}",
        "func": "void VvcUnitWithProfile::profile_tier_level(bool profileTierPresentFlag, int MaxNumSubLayersMinus1)\n{\n    if (profileTierPresentFlag)\n    {\n        profile_idc = m_reader.getBits(7);\n        bool tier_flag = m_reader.getBit();\n    }\n    level_idc = m_reader.getBits(8);\n    m_reader.skipBits(2);  // ptl_frame_only_constraint_flag, ptl_multilayer_enabled_flag\n\n    if (profileTierPresentFlag)\n    {                           // general_constraints_info()\n        if (m_reader.getBit())  // gci_present_flag\n        {\n            m_reader.skipBits(32);\n            m_reader.skipBits(32);\n            m_reader.skipBits(7);\n            int gci_num_reserved_bits = m_reader.getBits(8);\n            for (int i = 0; i < gci_num_reserved_bits; i++) m_reader.skipBit();  // gci_reserved_zero_bit[i]\n        }\n        m_reader.skipBits(m_reader.getBitsLeft() % 8);  // gci_alignment_zero_bit\n    }\n    std::vector<int> ptl_sublayer_level_present_flag;\n    ptl_sublayer_level_present_flag.resize(MaxNumSubLayersMinus1);\n\n    for (int i = MaxNumSubLayersMinus1 - 1; i >= 0; i--) ptl_sublayer_level_present_flag[i] = m_reader.getBit();\n\n    m_reader.skipBits(m_reader.getBitsLeft() % 8);  // ptl_reserved_zero_bit\n\n    for (int i = MaxNumSubLayersMinus1 - 1; i >= 0; i--)\n        if (ptl_sublayer_level_present_flag[i])\n            m_reader.skipBits(8);  // sublayer_level_idc[i]\n    if (profileTierPresentFlag)\n    {\n        int ptl_num_sub_profiles = m_reader.getBits(8);\n        for (int i = 0; i < ptl_num_sub_profiles; i++) m_reader.skipBits(32);  // general_sub_profile_idc[i]\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,8 @@\n             m_reader.skipBits(32);\n             m_reader.skipBits(32);\n             m_reader.skipBits(7);\n-            m_reader.skipBits(m_reader.getBits(8));  // gci_reserved_zero_bit[i]\n+            int gci_num_reserved_bits = m_reader.getBits(8);\n+            for (int i = 0; i < gci_num_reserved_bits; i++) m_reader.skipBit();  // gci_reserved_zero_bit[i]\n         }\n         m_reader.skipBits(m_reader.getBitsLeft() % 8);  // gci_alignment_zero_bit\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "            m_reader.skipBits(m_reader.getBits(8));  // gci_reserved_zero_bit[i]"
            ],
            "added_lines": [
                "            int gci_num_reserved_bits = m_reader.getBits(8);",
                "            for (int i = 0; i < gci_num_reserved_bits; i++) m_reader.skipBit();  // gci_reserved_zero_bit[i]"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-0865",
        "func_name": "libtiff/TIFFInitJBIG",
        "description": "Reachable Assertion in tiffcp in libtiff 4.3.0 allows attackers to cause a denial-of-service via a crafted tiff file. For users that compile libtiff from sources, the fix is available with commit 5e180045.",
        "git_url": "https://gitlab.com/libtiff/libtiff/-/commit/a1c933dabd0e1c54a412f3f84ae0aa58115c6067",
        "commit_title": "tif_jbig.c: fix crash when reading a file with multiple IFD in memory-mapped mode and when bit reversal is needed (fixes #385)",
        "commit_text": "",
        "func_before": "int TIFFInitJBIG(TIFF* tif, int scheme)\n{\n        (void)scheme;\n\tassert(scheme == COMPRESSION_JBIG);\n\n\t/*\n\t * These flags are set so the JBIG Codec can control when to reverse\n\t * bits and when not to and to allow the jbig decoder and bit reverser\n\t * to write to memory when necessary.\n\t */\n\ttif->tif_flags |= TIFF_NOBITREV;\n\ttif->tif_flags &= ~TIFF_MAPPED;\n\n\t/* Setup the function pointers for encode, decode, and cleanup. */\n\ttif->tif_setupdecode = JBIGSetupDecode;\n\ttif->tif_decodestrip = JBIGDecode;\n\n\ttif->tif_setupencode = JBIGSetupEncode;\n\ttif->tif_encodestrip = JBIGEncode;\n\n\treturn 1;\n}",
        "func": "int TIFFInitJBIG(TIFF* tif, int scheme)\n{\n        (void)scheme;\n\tassert(scheme == COMPRESSION_JBIG);\n\n\t/*\n\t * These flags are set so the JBIG Codec can control when to reverse\n\t * bits and when not to and to allow the jbig decoder and bit reverser\n\t * to write to memory when necessary.\n\t */\n\ttif->tif_flags |= TIFF_NOBITREV;\n\ttif->tif_flags &= ~TIFF_MAPPED;\n\t/* We may have read from a previous IFD and thus set TIFF_BUFFERMMAP and\n\t * cleared TIFF_MYBUFFER. It is necessary to restore them to their initial\n\t * value to be consistent with the state of a non-memory mapped file.\n\t */\n\tif (tif->tif_flags&TIFF_BUFFERMMAP) {\n\t\ttif->tif_rawdata = NULL;\n\t\ttif->tif_rawdatasize = 0;\n\t\ttif->tif_flags &= ~TIFF_BUFFERMMAP;\n\t\ttif->tif_flags |= TIFF_MYBUFFER;\n\t}\n\n\t/* Setup the function pointers for encode, decode, and cleanup. */\n\ttif->tif_setupdecode = JBIGSetupDecode;\n\ttif->tif_decodestrip = JBIGDecode;\n\n\ttif->tif_setupencode = JBIGSetupEncode;\n\ttif->tif_encodestrip = JBIGEncode;\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,16 @@\n \t */\n \ttif->tif_flags |= TIFF_NOBITREV;\n \ttif->tif_flags &= ~TIFF_MAPPED;\n+\t/* We may have read from a previous IFD and thus set TIFF_BUFFERMMAP and\n+\t * cleared TIFF_MYBUFFER. It is necessary to restore them to their initial\n+\t * value to be consistent with the state of a non-memory mapped file.\n+\t */\n+\tif (tif->tif_flags&TIFF_BUFFERMMAP) {\n+\t\ttif->tif_rawdata = NULL;\n+\t\ttif->tif_rawdatasize = 0;\n+\t\ttif->tif_flags &= ~TIFF_BUFFERMMAP;\n+\t\ttif->tif_flags |= TIFF_MYBUFFER;\n+\t}\n \n \t/* Setup the function pointers for encode, decode, and cleanup. */\n \ttif->tif_setupdecode = JBIGSetupDecode;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* We may have read from a previous IFD and thus set TIFF_BUFFERMMAP and",
                "\t * cleared TIFF_MYBUFFER. It is necessary to restore them to their initial",
                "\t * value to be consistent with the state of a non-memory mapped file.",
                "\t */",
                "\tif (tif->tif_flags&TIFF_BUFFERMMAP) {",
                "\t\ttif->tif_rawdata = NULL;",
                "\t\ttif->tif_rawdatasize = 0;",
                "\t\ttif->tif_flags &= ~TIFF_BUFFERMMAP;",
                "\t\ttif->tif_flags |= TIFF_MYBUFFER;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-27939",
        "func_name": "appneta/tcpreplay/get_layer4_v6",
        "description": "tcprewrite in Tcpreplay 4.4.1 has a reachable assertion in get_layer4_v6 in common/get.c.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/bac620dfbd5b7b3b3602eae29e05afa00765ce19",
        "commit_title": "Bug #717 avoid assertion in get_layer4_v6",
        "commit_text": "",
        "func_before": "void *\nget_layer4_v6(const ipv6_hdr_t *ip6_hdr, const int l3len)\n{\n    struct tcpr_ipv6_ext_hdr_base *next, *exthdr;\n    bool done = false;\n    uint32_t maxlen;\n    uint8_t proto;\n    int min_len;\n\n    assert(ip6_hdr);\n\n    min_len = TCPR_IPV6_H + sizeof(struct tcpr_ipv6_ext_hdr_base);\n    if (l3len < min_len)\n        return NULL;\n\n    /* jump to the end of the IPv6 header */\n    next = (struct tcpr_ipv6_ext_hdr_base *)((u_char *)ip6_hdr + TCPR_IPV6_H);\n    proto = ip6_hdr->ip_nh;\n\n    while (!done) {\n        dbgx(3, \"Processing proto: 0x%hx\", (uint16_t)proto);\n\n        switch (proto) {\n        /* recurse due to v6-in-v6, need to recast next as an IPv6 Header */\n        case TCPR_IPV6_NH_IPV6:\n            dbg(3, \"recursing due to v6-in-v6\");\n            next = get_layer4_v6((ipv6_hdr_t *)next, l3len - min_len);\n            break;\n\n        /* loop again */\n        case TCPR_IPV6_NH_AH:\n        case TCPR_IPV6_NH_ROUTING:\n        case TCPR_IPV6_NH_DESTOPTS:\n        case TCPR_IPV6_NH_HBH:\n            dbgx(3, \"Going deeper due to extension header 0x%02X\", proto);\n            maxlen = l3len - (int)((u_char *)ip6_hdr - (u_char *)next);\n            exthdr = get_ipv6_next(next, maxlen);\n            if (exthdr == NULL) {\n                done = true;\n                break;\n            }\n            proto = exthdr->ip_nh;\n            next = exthdr;\n            break;\n\n        /*\n         * Can't handle.  Unparsable IPv6 fragment/encrypted data\n         */\n        case TCPR_IPV6_NH_FRAGMENT:\n        case TCPR_IPV6_NH_ESP:\n            next = NULL;\n            done = true;\n            break;\n\n        /*\n         * no further processing, either TCP, UDP, ICMP, etc...\n         */\n        default:\n            if (proto != ip6_hdr->ip_nh) {\n                dbgx(3, \"Returning byte offset of this ext header: %u\", \n                        IPV6_EXTLEN_TO_BYTES(next->ip_len));\n                next =  (void *)((u_char *)next + IPV6_EXTLEN_TO_BYTES(next->ip_len));\n            } else {\n                dbgx(3, \"%s\", \"Returning end of IPv6 Header\");\n            }\n\n            done = true;\n        } /* switch */\n    } /* while */\n\n    if (!next || (u_char*)next > (u_char*)ip6_hdr + l3len)\n        return NULL;\n\n    return next;\n}",
        "func": "void *\nget_layer4_v6(const ipv6_hdr_t *ip6_hdr, const int l3len)\n{\n    struct tcpr_ipv6_ext_hdr_base *next, *exthdr;\n    bool done = false;\n    uint32_t maxlen;\n    uint8_t proto;\n    int min_len;\n\n    assert(ip6_hdr);\n\n    min_len = TCPR_IPV6_H + sizeof(struct tcpr_ipv6_ext_hdr_base);\n    if (l3len < min_len)\n        return NULL;\n\n    /* jump to the end of the IPv6 header */\n    next = (struct tcpr_ipv6_ext_hdr_base *)((u_char *)ip6_hdr + TCPR_IPV6_H);\n    proto = ip6_hdr->ip_nh;\n\n    while (!done) {\n        dbgx(3, \"Processing proto: 0x%hx\", (uint16_t)proto);\n\n        switch (proto) {\n        /* recurse due to v6-in-v6, need to recast next as an IPv6 Header */\n        case TCPR_IPV6_NH_IPV6:\n            dbg(3, \"recursing due to v6-in-v6\");\n            next = get_layer4_v6((ipv6_hdr_t *)next, l3len - min_len);\n            if (next == NULL)\n                done = true;\n\n            break;\n\n        /* loop again */\n        case TCPR_IPV6_NH_AH:\n        case TCPR_IPV6_NH_ROUTING:\n        case TCPR_IPV6_NH_DESTOPTS:\n        case TCPR_IPV6_NH_HBH:\n            dbgx(3, \"Going deeper due to extension header 0x%02X\", proto);\n            maxlen = l3len - (int)((u_char *)ip6_hdr - (u_char *)next);\n            exthdr = get_ipv6_next(next, maxlen);\n            if (exthdr == NULL) {\n                done = true;\n                break;\n            }\n            proto = exthdr->ip_nh;\n            next = exthdr;\n            break;\n\n        /*\n         * Can't handle.  Unparsable IPv6 fragment/encrypted data\n         */\n        case TCPR_IPV6_NH_FRAGMENT:\n        case TCPR_IPV6_NH_ESP:\n            next = NULL;\n            done = true;\n            break;\n\n        /*\n         * no further processing, either TCP, UDP, ICMP, etc...\n         */\n        default:\n            if (proto != ip6_hdr->ip_nh) {\n                dbgx(3, \"Returning byte offset of this ext header: %u\", \n                        IPV6_EXTLEN_TO_BYTES(next->ip_len));\n                next =  (void *)((u_char *)next + IPV6_EXTLEN_TO_BYTES(next->ip_len));\n            } else {\n                dbgx(3, \"%s\", \"Returning end of IPv6 Header\");\n            }\n\n            done = true;\n        } /* switch */\n    } /* while */\n\n    if (!next || (u_char*)next > (u_char*)ip6_hdr + l3len)\n        return NULL;\n\n    return next;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,6 +25,9 @@\n         case TCPR_IPV6_NH_IPV6:\n             dbg(3, \"recursing due to v6-in-v6\");\n             next = get_layer4_v6((ipv6_hdr_t *)next, l3len - min_len);\n+            if (next == NULL)\n+                done = true;\n+\n             break;\n \n         /* loop again */",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            if (next == NULL)",
                "                done = true;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-29339",
        "func_name": "gpac/gf_isom_oinf_read_entry",
        "description": "In GPAC 2.1-DEV-rev87-g053aae8-master, function BS_ReadByte() in utils/bitstream.c has a failed assertion, which causes a Denial of Service. This vulnerability was fixed in commit 9ea93a2.",
        "git_url": "https://github.com/gpac/gpac/commit/9ea93a2ec8f555ceed1ee27294cf94822f14f10f",
        "commit_title": "fixed #2165",
        "commit_text": "",
        "func_before": "GF_Err gf_isom_oinf_read_entry(void *entry, GF_BitStream *bs)\n{\n\tGF_OperatingPointsInformation* ptr = (GF_OperatingPointsInformation *)entry;\n\tu32 i, j, count;\n\n\tif (!ptr) return GF_BAD_PARAM;\n\tptr->scalability_mask = gf_bs_read_u16(bs);\n\tgf_bs_read_int(bs, 2);//reserved\n\tcount = gf_bs_read_int(bs, 6);\n\tfor (i = 0; i < count; i++) {\n\t\tLHEVC_ProfileTierLevel *ptl;\n\t\tGF_SAFEALLOC(ptl, LHEVC_ProfileTierLevel);\n\t\tif (!ptl) return GF_OUT_OF_MEM;\n\t\tptl->general_profile_space = gf_bs_read_int(bs, 2);\n\t\tptl->general_tier_flag= gf_bs_read_int(bs, 1);\n\t\tptl->general_profile_idc = gf_bs_read_int(bs, 5);\n\t\tptl->general_profile_compatibility_flags = gf_bs_read_u32(bs);\n\t\tptl->general_constraint_indicator_flags = gf_bs_read_long_int(bs, 48);\n\t\tptl->general_level_idc = gf_bs_read_u8(bs);\n\t\tgf_list_add(ptr->profile_tier_levels, ptl);\n\t}\n\tcount = gf_bs_read_u16(bs);\n\tfor (i = 0; i < count; i++) {\n\t\tLHEVC_OperatingPoint *op;\n\t\tGF_SAFEALLOC(op, LHEVC_OperatingPoint);\n\t\tif (!op) return GF_OUT_OF_MEM;\n\t\top->output_layer_set_idx = gf_bs_read_u16(bs);\n\t\top->max_temporal_id = gf_bs_read_u8(bs);\n\t\top->layer_count = gf_bs_read_u8(bs);\n\t\tif (op->layer_count > GF_ARRAY_LENGTH(op->layers_info)) {\n\t\t\tgf_free(op);\n\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t}\n\t\tfor (j = 0; j < op->layer_count; j++) {\n\t\t\top->layers_info[j].ptl_idx = gf_bs_read_u8(bs);\n\t\t\top->layers_info[j].layer_id = gf_bs_read_int(bs, 6);\n\t\t\top->layers_info[j].is_outputlayer = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\t\t\top->layers_info[j].is_alternate_outputlayer = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\t\t}\n\t\top->minPicWidth = gf_bs_read_u16(bs);\n\t\top->minPicHeight = gf_bs_read_u16(bs);\n\t\top->maxPicWidth = gf_bs_read_u16(bs);\n\t\top->maxPicHeight = gf_bs_read_u16(bs);\n\t\top->maxChromaFormat = gf_bs_read_int(bs, 2);\n\t\top->maxBitDepth = gf_bs_read_int(bs, 3) + 8;\n\t\tgf_bs_read_int(bs, 1);//reserved\n\t\top->frame_rate_info_flag = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\t\top->bit_rate_info_flag = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\t\tif (op->frame_rate_info_flag) {\n\t\t\top->avgFrameRate = gf_bs_read_u16(bs);\n\t\t\tgf_bs_read_int(bs, 6); //reserved\n\t\t\top->constantFrameRate = gf_bs_read_int(bs, 2);\n\t\t}\n\t\tif (op->bit_rate_info_flag) {\n\t\t\top->maxBitRate = gf_bs_read_u32(bs);\n\t\t\top->avgBitRate = gf_bs_read_u32(bs);\n\t\t}\n\t\tgf_list_add(ptr->operating_points, op);\n\t}\n\tcount = gf_bs_read_u8(bs);\n\tfor (i = 0; i < count; i++) {\n\t\tLHEVC_DependentLayer *dep;\n\t\tGF_SAFEALLOC(dep, LHEVC_DependentLayer);\n\t\tif (!dep) return GF_OUT_OF_MEM;\n\t\tdep->dependent_layerID = gf_bs_read_u8(bs);\n\t\tdep->num_layers_dependent_on = gf_bs_read_u8(bs);\n\t\tif (dep->num_layers_dependent_on > GF_ARRAY_LENGTH(dep->dependent_on_layerID)) {\n\t\t\tgf_free(dep);\n\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t}\n\t\tfor (j = 0; j < dep->num_layers_dependent_on; j++)\n\t\t\tdep->dependent_on_layerID[j] = gf_bs_read_u8(bs);\n\t\tfor (j = 0; j < 16; j++) {\n\t\t\tif (ptr->scalability_mask & (1 << j))\n\t\t\t\tdep->dimension_identifier[j] = gf_bs_read_u8(bs);\n\t\t}\n\t\tgf_list_add(ptr->dependency_layers, dep);\n\t}\n\n\treturn GF_OK;\n}",
        "func": "GF_Err gf_isom_oinf_read_entry(void *entry, GF_BitStream *bs)\n{\n\tGF_OperatingPointsInformation* ptr = (GF_OperatingPointsInformation *)entry;\n\tu32 i, j, count;\n\n\tif (!ptr) return GF_BAD_PARAM;\n\tptr->scalability_mask = gf_bs_read_u16(bs);\n\tgf_bs_read_int(bs, 2);//reserved\n\tcount = gf_bs_read_int(bs, 6);\n\tfor (i = 0; i < count; i++) {\n\t\tLHEVC_ProfileTierLevel *ptl;\n\t\tGF_SAFEALLOC(ptl, LHEVC_ProfileTierLevel);\n\t\tif (!ptl) return GF_OUT_OF_MEM;\n\t\tptl->general_profile_space = gf_bs_read_int(bs, 2);\n\t\tptl->general_tier_flag= gf_bs_read_int(bs, 1);\n\t\tptl->general_profile_idc = gf_bs_read_int(bs, 5);\n\t\tptl->general_profile_compatibility_flags = gf_bs_read_u32(bs);\n\t\tptl->general_constraint_indicator_flags = gf_bs_read_long_int(bs, 48);\n\t\tptl->general_level_idc = gf_bs_read_u8(bs);\n\t\tgf_list_add(ptr->profile_tier_levels, ptl);\n\t}\n\tcount = gf_bs_read_u16(bs);\n\tfor (i = 0; i < count; i++) {\n\t\tLHEVC_OperatingPoint *op;\n\t\tGF_SAFEALLOC(op, LHEVC_OperatingPoint);\n\t\tif (!op) return GF_OUT_OF_MEM;\n\t\top->output_layer_set_idx = gf_bs_read_u16(bs);\n\t\top->max_temporal_id = gf_bs_read_u8(bs);\n\t\top->layer_count = gf_bs_read_u8(bs);\n\t\tif (op->layer_count > GF_ARRAY_LENGTH(op->layers_info)) {\n\t\t\tgf_free(op);\n\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t}\n\t\tfor (j = 0; j < op->layer_count; j++) {\n\t\t\top->layers_info[j].ptl_idx = gf_bs_read_u8(bs);\n\t\t\top->layers_info[j].layer_id = gf_bs_read_int(bs, 6);\n\t\t\top->layers_info[j].is_outputlayer = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\t\t\top->layers_info[j].is_alternate_outputlayer = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\n\t\t\tif (gf_bs_is_overflow(bs)) {\n\t\t\t\tgf_free(op);\n\t\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t}\n\t\t}\n\t\top->minPicWidth = gf_bs_read_u16(bs);\n\t\top->minPicHeight = gf_bs_read_u16(bs);\n\t\top->maxPicWidth = gf_bs_read_u16(bs);\n\t\top->maxPicHeight = gf_bs_read_u16(bs);\n\t\top->maxChromaFormat = gf_bs_read_int(bs, 2);\n\t\top->maxBitDepth = gf_bs_read_int(bs, 3) + 8;\n\t\tgf_bs_read_int(bs, 1);//reserved\n\t\top->frame_rate_info_flag = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\t\top->bit_rate_info_flag = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n\t\tif (op->frame_rate_info_flag) {\n\t\t\top->avgFrameRate = gf_bs_read_u16(bs);\n\t\t\tgf_bs_read_int(bs, 6); //reserved\n\t\t\top->constantFrameRate = gf_bs_read_int(bs, 2);\n\t\t}\n\t\tif (op->bit_rate_info_flag) {\n\t\t\top->maxBitRate = gf_bs_read_u32(bs);\n\t\t\top->avgBitRate = gf_bs_read_u32(bs);\n\t\t}\n\t\tif (gf_bs_is_overflow(bs)) {\n\t\t\tgf_free(op);\n\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t}\n\t\tgf_list_add(ptr->operating_points, op);\n\t}\n\tcount = gf_bs_read_u8(bs);\n\tfor (i = 0; i < count; i++) {\n\t\tLHEVC_DependentLayer *dep;\n\t\tGF_SAFEALLOC(dep, LHEVC_DependentLayer);\n\t\tif (!dep) return GF_OUT_OF_MEM;\n\t\tdep->dependent_layerID = gf_bs_read_u8(bs);\n\t\tdep->num_layers_dependent_on = gf_bs_read_u8(bs);\n\t\tif (dep->num_layers_dependent_on > GF_ARRAY_LENGTH(dep->dependent_on_layerID)) {\n\t\t\tgf_free(dep);\n\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t}\n\t\tfor (j = 0; j < dep->num_layers_dependent_on; j++)\n\t\t\tdep->dependent_on_layerID[j] = gf_bs_read_u8(bs);\n\t\tfor (j = 0; j < 16; j++) {\n\t\t\tif (ptr->scalability_mask & (1 << j))\n\t\t\t\tdep->dimension_identifier[j] = gf_bs_read_u8(bs);\n\t\t}\n\t\tif (gf_bs_is_overflow(bs)) {\n\t\t\tgf_free(dep);\n\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t}\n\t\tgf_list_add(ptr->dependency_layers, dep);\n\t}\n\n\treturn GF_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,6 +36,11 @@\n \t\t\top->layers_info[j].layer_id = gf_bs_read_int(bs, 6);\n \t\t\top->layers_info[j].is_outputlayer = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n \t\t\top->layers_info[j].is_alternate_outputlayer = gf_bs_read_int(bs, 1) ? GF_TRUE : GF_FALSE;\n+\n+\t\t\tif (gf_bs_is_overflow(bs)) {\n+\t\t\t\tgf_free(op);\n+\t\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n+\t\t\t}\n \t\t}\n \t\top->minPicWidth = gf_bs_read_u16(bs);\n \t\top->minPicHeight = gf_bs_read_u16(bs);\n@@ -54,6 +59,10 @@\n \t\tif (op->bit_rate_info_flag) {\n \t\t\top->maxBitRate = gf_bs_read_u32(bs);\n \t\t\top->avgBitRate = gf_bs_read_u32(bs);\n+\t\t}\n+\t\tif (gf_bs_is_overflow(bs)) {\n+\t\t\tgf_free(op);\n+\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n \t\t}\n \t\tgf_list_add(ptr->operating_points, op);\n \t}\n@@ -74,6 +83,10 @@\n \t\t\tif (ptr->scalability_mask & (1 << j))\n \t\t\t\tdep->dimension_identifier[j] = gf_bs_read_u8(bs);\n \t\t}\n+\t\tif (gf_bs_is_overflow(bs)) {\n+\t\t\tgf_free(dep);\n+\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n+\t\t}\n \t\tgf_list_add(ptr->dependency_layers, dep);\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t\t\tif (gf_bs_is_overflow(bs)) {",
                "\t\t\t\tgf_free(op);",
                "\t\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;",
                "\t\t\t}",
                "\t\t}",
                "\t\tif (gf_bs_is_overflow(bs)) {",
                "\t\t\tgf_free(op);",
                "\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;",
                "\t\tif (gf_bs_is_overflow(bs)) {",
                "\t\t\tgf_free(dep);",
                "\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-29339",
        "func_name": "gpac/BS_ReadByte",
        "description": "In GPAC 2.1-DEV-rev87-g053aae8-master, function BS_ReadByte() in utils/bitstream.c has a failed assertion, which causes a Denial of Service. This vulnerability was fixed in commit 9ea93a2.",
        "git_url": "https://github.com/gpac/gpac/commit/9ea93a2ec8f555ceed1ee27294cf94822f14f10f",
        "commit_title": "fixed #2165",
        "commit_text": "",
        "func_before": "static u8 BS_ReadByte(GF_BitStream *bs)\n{\n\tBool is_eos;\n\tif (bs->bsmode == GF_BITSTREAM_READ) {\n\t\tu8 res;\n\t\tif (bs->position >= bs->size) {\n\t\t\tif (bs->EndOfStream) bs->EndOfStream(bs->par);\n\t\t\tif (!bs->overflow_state) bs->overflow_state = 1;\n\t\t\treturn 0;\n\t\t}\n\t\tres = bs->original[bs->position++];\n\n\t\tif (bs->remove_emul_prevention_byte) {\n\t\t\tif ((bs->nb_zeros==2) && (res==0x03) && (bs->position<bs->size) && (bs->original[bs->position]<0x04)) {\n\t\t\t\tbs->nb_zeros = 0;\n\t\t\t\tres = bs->original[bs->position++];\n\t\t\t}\n\t\t\tif (!res) bs->nb_zeros++;\n\t\t\telse bs->nb_zeros = 0;\n\t\t}\n\t\treturn res;\n\t}\n\tif (bs->cache_write)\n\t\tbs_flush_write_cache(bs);\n\n\tis_eos = gf_feof(bs->stream);\n\n\t/*we are in FILE mode, test for end of file*/\n\tif (!is_eos || bs->cache_read) {\n\t\tu8 res;\n\t\tBool loc_eos=GF_FALSE;\n\t\tassert(bs->position<=bs->size);\n\t\tbs->position++;\n\n\t\tres = gf_bs_load_byte(bs, &loc_eos);\n\t\tif (loc_eos) goto bs_eof;\n\n\t\tif (bs->remove_emul_prevention_byte) {\n\t\t\tif ((bs->nb_zeros==2) && (res==0x03) && (bs->position<bs->size)) {\n\t\t\t\tu8 next = gf_bs_load_byte(bs, &loc_eos);\n\t\t\t\tif (next < 0x04) {\n\t\t\t\t\tbs->nb_zeros = 0;\n\t\t\t\t\tres = next;\n\t\t\t\t\tbs->position++;\n\t\t\t\t} else {\n\t\t\t\t\tgf_bs_seek(bs, bs->position);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!res) bs->nb_zeros++;\n\t\t\telse bs->nb_zeros = 0;\n\t\t}\n\t\treturn res;\n\t}\n\nbs_eof:\n\tif (bs->EndOfStream) {\n\t\tbs->EndOfStream(bs->par);\n\t\tif (!bs->overflow_state) bs->overflow_state = 1;\n\t} else {\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CORE, (\"[BS] Attempt to overread bitstream\\n\"));\n\t}\n\tassert(bs->position <= 1+bs->size);\n\treturn 0;\n}",
        "func": "static u8 BS_ReadByte(GF_BitStream *bs)\n{\n\tBool is_eos;\n\tif (bs->bsmode == GF_BITSTREAM_READ) {\n\t\tu8 res;\n\t\tif (bs->position >= bs->size) {\n\t\t\tif (bs->EndOfStream) bs->EndOfStream(bs->par);\n\t\t\tif (!bs->overflow_state) bs->overflow_state = 1;\n\t\t\treturn 0;\n\t\t}\n\t\tres = bs->original[bs->position++];\n\n\t\tif (bs->remove_emul_prevention_byte) {\n\t\t\tif ((bs->nb_zeros==2) && (res==0x03) && (bs->position<bs->size) && (bs->original[bs->position]<0x04)) {\n\t\t\t\tbs->nb_zeros = 0;\n\t\t\t\tres = bs->original[bs->position++];\n\t\t\t}\n\t\t\tif (!res) bs->nb_zeros++;\n\t\t\telse bs->nb_zeros = 0;\n\t\t}\n\t\treturn res;\n\t}\n\tif (bs->cache_write)\n\t\tbs_flush_write_cache(bs);\n\n\tis_eos = gf_feof(bs->stream);\n\t//cache not fully read, reset EOS\n\tif (bs->cache_read && (bs->cache_read_pos<bs->cache_read_size))\n\t\tis_eos = GF_FALSE;\n\n\t/*we are in FILE mode, test for end of file*/\n\tif (!is_eos) {\n\t\tu8 res;\n\t\tBool loc_eos=GF_FALSE;\n\t\tassert(bs->position<=bs->size);\n\t\tbs->position++;\n\n\t\tres = gf_bs_load_byte(bs, &loc_eos);\n\t\tif (loc_eos) goto bs_eof;\n\n\t\tif (bs->remove_emul_prevention_byte) {\n\t\t\tif ((bs->nb_zeros==2) && (res==0x03) && (bs->position<bs->size)) {\n\t\t\t\tu8 next = gf_bs_load_byte(bs, &loc_eos);\n\t\t\t\tif (next < 0x04) {\n\t\t\t\t\tbs->nb_zeros = 0;\n\t\t\t\t\tres = next;\n\t\t\t\t\tbs->position++;\n\t\t\t\t} else {\n\t\t\t\t\tgf_bs_seek(bs, bs->position);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!res) bs->nb_zeros++;\n\t\t\telse bs->nb_zeros = 0;\n\t\t}\n\t\treturn res;\n\t}\n\nbs_eof:\n\tif (bs->EndOfStream) {\n\t\tbs->EndOfStream(bs->par);\n\t\tif (!bs->overflow_state) bs->overflow_state = 1;\n\t} else {\n\t\tif (!bs->overflow_state) {\n\t\t\tbs->overflow_state = 1;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CORE, (\"[BS] Attempt to overread bitstream\\n\"));\n\t\t}\n\t}\n\tassert(bs->position <= 1+bs->size);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,9 +24,12 @@\n \t\tbs_flush_write_cache(bs);\n \n \tis_eos = gf_feof(bs->stream);\n+\t//cache not fully read, reset EOS\n+\tif (bs->cache_read && (bs->cache_read_pos<bs->cache_read_size))\n+\t\tis_eos = GF_FALSE;\n \n \t/*we are in FILE mode, test for end of file*/\n-\tif (!is_eos || bs->cache_read) {\n+\tif (!is_eos) {\n \t\tu8 res;\n \t\tBool loc_eos=GF_FALSE;\n \t\tassert(bs->position<=bs->size);\n@@ -57,7 +60,10 @@\n \t\tbs->EndOfStream(bs->par);\n \t\tif (!bs->overflow_state) bs->overflow_state = 1;\n \t} else {\n-\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CORE, (\"[BS] Attempt to overread bitstream\\n\"));\n+\t\tif (!bs->overflow_state) {\n+\t\t\tbs->overflow_state = 1;\n+\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CORE, (\"[BS] Attempt to overread bitstream\\n\"));\n+\t\t}\n \t}\n \tassert(bs->position <= 1+bs->size);\n \treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!is_eos || bs->cache_read) {",
                "\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CORE, (\"[BS] Attempt to overread bitstream\\n\"));"
            ],
            "added_lines": [
                "\t//cache not fully read, reset EOS",
                "\tif (bs->cache_read && (bs->cache_read_pos<bs->cache_read_size))",
                "\t\tis_eos = GF_FALSE;",
                "\tif (!is_eos) {",
                "\t\tif (!bs->overflow_state) {",
                "\t\t\tbs->overflow_state = 1;",
                "\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CORE, (\"[BS] Attempt to overread bitstream\\n\"));",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-31620",
        "func_name": "thorfdbg/libjpeg/Init",
        "description": "In libjpeg before 1.64, BitStream<false>::Get in bitstream.hpp has an assertion failure that may cause denial of service. This is related to out-of-bounds array access during arithmetically coded lossless scan or arithmetically coded sequential scan.",
        "git_url": "https://github.com/thorfdbg/libjpeg/commit/ef4a29a62ab48b8dc235f4af52cfd6319eda9a6a",
        "commit_title": "Added out-of-bounds checks for lossless symbol decoding and AC context",
        "commit_text": "indices. Worked around some gcc warnings. Bumped to 1.64.",
        "func_before": "void Init(bool hi) \n      {\n        for(int i = 0;i < 18;i++) {\n          char string[5] = \"xl00\";\n          string[1] = (hi)?('h'):('l');\n          string[2] = (i / 10) + '0';\n          string[3] = (i % 10) + '0';\n          X[i].Init(string);\n          string[0] = 'm';\n          M[i].Init(string);\n        }\n      }",
        "func": "void Init(bool hi) \n      {\n        for(int i = 0;i < MagnitudeContexts;i++) {\n          char string[5] = \"xl00\";\n          string[1] = (hi)?('h'):('l');\n          string[2] = (i / 10) + '0';\n          string[3] = (i % 10) + '0';\n          X[i].Init(string);\n          string[0] = 'm';\n          M[i].Init(string);\n        }\n      }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n void Init(bool hi) \n       {\n-        for(int i = 0;i < 18;i++) {\n+        for(int i = 0;i < MagnitudeContexts;i++) {\n           char string[5] = \"xl00\";\n           string[1] = (hi)?('h'):('l');\n           string[2] = (i / 10) + '0';",
        "diff_line_info": {
            "deleted_lines": [
                "        for(int i = 0;i < 18;i++) {"
            ],
            "added_lines": [
                "        for(int i = 0;i < MagnitudeContexts;i++) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-31620",
        "func_name": "thorfdbg/libjpeg/RectangleRequest",
        "description": "In libjpeg before 1.64, BitStream<false>::Get in bitstream.hpp has an assertion failure that may cause denial of service. This is related to out-of-bounds array access during arithmetically coded lossless scan or arithmetically coded sequential scan.",
        "git_url": "https://github.com/thorfdbg/libjpeg/commit/ef4a29a62ab48b8dc235f4af52cfd6319eda9a6a",
        "commit_title": "Added out-of-bounds checks for lossless symbol decoding and AC context",
        "commit_text": "indices. Worked around some gcc warnings. Bumped to 1.64.",
        "func_before": "RectangleRequest(const struct RectangleRequest &req)\n    : Explicit()\n  {\n    // Not nice, but this is really faster and simpler\n    memcpy(this,&req,sizeof(struct RectangleRequest));\n    // Not linked in any way if this is new.\n    rr_pNext = NULL;\n  }",
        "func": "RectangleRequest(const struct RectangleRequest &req)\n    : Explicit()\n  {\n    // Not linked in any way if this is new.\n    rr_pNext            = NULL;\n    rr_Request          = req.rr_Request;\n    rr_usFirstComponent = req.rr_usFirstComponent;\n    rr_usLastComponent  = req.rr_usLastComponent;\n    rr_cPriority        = req.rr_cPriority;\n    rr_bIncludeAlpha    = req.rr_bIncludeAlpha;\n    rr_bUpsampling      = req.rr_bUpsampling;\n    rr_bColorTrafo      = req.rr_bColorTrafo;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,13 @@\n RectangleRequest(const struct RectangleRequest &req)\n     : Explicit()\n   {\n-    // Not nice, but this is really faster and simpler\n-    memcpy(this,&req,sizeof(struct RectangleRequest));\n     // Not linked in any way if this is new.\n-    rr_pNext = NULL;\n+    rr_pNext            = NULL;\n+    rr_Request          = req.rr_Request;\n+    rr_usFirstComponent = req.rr_usFirstComponent;\n+    rr_usLastComponent  = req.rr_usLastComponent;\n+    rr_cPriority        = req.rr_cPriority;\n+    rr_bIncludeAlpha    = req.rr_bIncludeAlpha;\n+    rr_bUpsampling      = req.rr_bUpsampling;\n+    rr_bColorTrafo      = req.rr_bColorTrafo;\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "    // Not nice, but this is really faster and simpler",
                "    memcpy(this,&req,sizeof(struct RectangleRequest));",
                "    rr_pNext = NULL;"
            ],
            "added_lines": [
                "    rr_pNext            = NULL;",
                "    rr_Request          = req.rr_Request;",
                "    rr_usFirstComponent = req.rr_usFirstComponent;",
                "    rr_usLastComponent  = req.rr_usLastComponent;",
                "    rr_cPriority        = req.rr_cPriority;",
                "    rr_bIncludeAlpha    = req.rr_bIncludeAlpha;",
                "    rr_bUpsampling      = req.rr_bUpsampling;",
                "    rr_bColorTrafo      = req.rr_bColorTrafo;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-31620",
        "func_name": "thorfdbg/libjpeg/LosslessScan::ParseMCU",
        "description": "In libjpeg before 1.64, BitStream<false>::Get in bitstream.hpp has an assertion failure that may cause denial of service. This is related to out-of-bounds array access during arithmetically coded lossless scan or arithmetically coded sequential scan.",
        "git_url": "https://github.com/thorfdbg/libjpeg/commit/ef4a29a62ab48b8dc235f4af52cfd6319eda9a6a",
        "commit_title": "Added out-of-bounds checks for lossless symbol decoding and AC context",
        "commit_text": "indices. Worked around some gcc warnings. Bumped to 1.64.",
        "func_before": "void LosslessScan::ParseMCU(struct Line **prev,struct Line **top)\n{ \n#if ACCUSOFT_CODE\n  UBYTE i;\n  //\n  // Parse a single MCU, which is now a group of pixels.\n  for(i = 0;i < m_ucCount;i++) {\n    class HuffmanDecoder *dc = m_pDCDecoder[i];\n    struct Line *line = top[i];\n    struct Line *pline= prev[i];\n    UBYTE ym = m_ucMCUHeight[i];\n    class PredictorBase *mcupred = m_pPredict[i];\n    LONG *lp = line->m_pData + m_ulX[i];\n    LONG *pp = (pline)?(pline->m_pData + m_ulX[i]):(NULL);\n    //\n    // Parse MCUwidth * MCUheight coefficients starting at the line top.\n    do {\n      class PredictorBase *pred = mcupred;\n      UBYTE xm = m_ucMCUWidth[i];\n      do {\n        LONG v;\n        UBYTE symbol = dc->Get(&m_Stream);\n        \n        if (symbol == 0) {\n          v = 0;\n        } else if (symbol == 16) {\n          v = -32768;\n        } else {\n          LONG thre = 1L << (symbol - 1);\n          LONG diff = m_Stream.Get(symbol); // get the number of bits \n          if (diff < thre) {\n            diff += (-1L << symbol) + 1;\n          }\n          v = diff;\n        }\n        //\n        // Set the current pixel, do the inverse pointwise transformation.\n        lp[0] = pred->DecodeSample(v,lp,pp);\n        //\n        // One pixel done. Proceed to the next in the MCU. Note that\n        // the lines have been extended such that always a complete MCU is present.\n      } while(--xm && (lp++,pp++,pred = pred->MoveRight(),true));\n      //\n      // Go to the next line.\n    } while(--ym && (pp = line->m_pData + m_ulX[i],line = (line->m_pNext)?(line->m_pNext):(line),\n                     lp = line->m_pData + m_ulX[i],mcupred = mcupred->MoveDown(),true));\n  }\n#else\n  NOREF(prev);\n  NOREF(top);\n#endif\n}",
        "func": "void LosslessScan::ParseMCU(struct Line **prev,struct Line **top)\n{ \n#if ACCUSOFT_CODE\n  UBYTE i;\n  //\n  // Parse a single MCU, which is now a group of pixels.\n  for(i = 0;i < m_ucCount;i++) {\n    class HuffmanDecoder *dc = m_pDCDecoder[i];\n    struct Line *line = top[i];\n    struct Line *pline= prev[i];\n    UBYTE ym = m_ucMCUHeight[i];\n    class PredictorBase *mcupred = m_pPredict[i];\n    LONG *lp = line->m_pData + m_ulX[i];\n    LONG *pp = (pline)?(pline->m_pData + m_ulX[i]):(NULL);\n    //\n    // Parse MCUwidth * MCUheight coefficients starting at the line top.\n    do {\n      class PredictorBase *pred = mcupred;\n      UBYTE xm = m_ucMCUWidth[i];\n      do {\n        LONG v;\n        UBYTE symbol = dc->Get(&m_Stream);\n        \n        if (symbol == 0) {\n          v = 0;\n        } else if (symbol == 16) {\n          v = -32768;\n        } else if (symbol > 16) {\n          JPG_THROW(MALFORMED_STREAM,\"LosslessScan::ParseMCU\",\n                    \"received an out-of-bounds symbol in a lossless JPEG scan\");\n        } else {\n          LONG thre = 1L << (symbol - 1);\n          LONG diff = m_Stream.Get(symbol); // get the number of bits \n          if (diff < thre) {\n            diff += (-1L << symbol) + 1;\n          }\n          v = diff;\n        }\n        //\n        // Set the current pixel, do the inverse pointwise transformation.\n        lp[0] = pred->DecodeSample(v,lp,pp);\n        //\n        // One pixel done. Proceed to the next in the MCU. Note that\n        // the lines have been extended such that always a complete MCU is present.\n      } while(--xm && (lp++,pp++,pred = pred->MoveRight(),true));\n      //\n      // Go to the next line.\n    } while(--ym && (pp = line->m_pData + m_ulX[i],line = (line->m_pNext)?(line->m_pNext):(line),\n                     lp = line->m_pData + m_ulX[i],mcupred = mcupred->MoveDown(),true));\n  }\n#else\n  NOREF(prev);\n  NOREF(top);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,6 +25,9 @@\n           v = 0;\n         } else if (symbol == 16) {\n           v = -32768;\n+        } else if (symbol > 16) {\n+          JPG_THROW(MALFORMED_STREAM,\"LosslessScan::ParseMCU\",\n+                    \"received an out-of-bounds symbol in a lossless JPEG scan\");\n         } else {\n           LONG thre = 1L << (symbol - 1);\n           LONG diff = m_Stream.Get(symbol); // get the number of bits ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        } else if (symbol > 16) {",
                "          JPG_THROW(MALFORMED_STREAM,\"LosslessScan::ParseMCU\",",
                "                    \"received an out-of-bounds symbol in a lossless JPEG scan\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-31620",
        "func_name": "thorfdbg/libjpeg/ACLosslessScan::ParseMCU",
        "description": "In libjpeg before 1.64, BitStream<false>::Get in bitstream.hpp has an assertion failure that may cause denial of service. This is related to out-of-bounds array access during arithmetically coded lossless scan or arithmetically coded sequential scan.",
        "git_url": "https://github.com/thorfdbg/libjpeg/commit/ef4a29a62ab48b8dc235f4af52cfd6319eda9a6a",
        "commit_title": "Added out-of-bounds checks for lossless symbol decoding and AC context",
        "commit_text": "indices. Worked around some gcc warnings. Bumped to 1.64.",
        "func_before": "void ACLosslessScan::ParseMCU(struct Line **prev,struct Line **top)\n{ \n#if ACCUSOFT_CODE\n  UBYTE c;\n  //\n  // Parse a single MCU, which is now a group of pixels.\n  for(c = 0;c < m_ucCount;c++) {\n    struct QMContextSet &contextset = m_Context[m_ucContext[c]];\n    struct Line *line = top[c];\n    struct Line *pline= prev[c];\n    UBYTE ym = m_ucMCUHeight[c];\n    ULONG  x = m_ulX[c];\n    class PredictorBase *mcupred = m_pPredict[c];\n    LONG *lp = line->m_pData + x;\n    LONG *pp = (pline)?(pline->m_pData + x):(NULL);\n    //\n    // Parse MCUwidth * MCUheight coefficients starting at the line top.\n    do {\n      class PredictorBase *pred = mcupred;\n      UBYTE xm = m_ucMCUWidth[c];\n      do {\n        // Decode now the difference between the predicted value and\n        // the real value.\n        LONG v;\n        //\n        // Get the sign coding context.\n        struct QMContextSet::ContextZeroSet &zset = contextset.ClassifySignZero(m_plDa[c][ym-1],m_plDb[c][x],\n                                                                                m_ucSmall[c],m_ucLarge[c]);\n        //\n        if (m_Coder.Get(zset.S0)) {\n          LONG sz   = 0;\n          bool sign = m_Coder.Get(zset.SS); // true for negative.\n          //\n          if (m_Coder.Get((sign)?(zset.SN):(zset.SP))) {\n            struct QMContextSet::MagnitudeSet &mset = contextset.ClassifyMagnitude(m_plDb[c][x],m_ucLarge[c]);\n            int  i = 0;\n            LONG m = 2;\n            //\n            while(m_Coder.Get(mset.X[i])) {\n              m <<= 1;\n              i++;\n            }\n            //\n            m >>= 1;\n            sz  = m;\n            while((m >>= 1)) {\n              if (m_Coder.Get(mset.M[i])) {\n                sz |= m;\n              }\n            }\n          }\n          //\n          if (sign) {\n            v = -sz - 1;\n          } else {\n            v =  sz + 1;\n          }\n        } else {\n          v = 0;\n        }\n        //\n        // Use the prediction to fill in the sample.\n        lp[0] = pred->DecodeSample(v,lp,pp);\n        // Update Da and Db.\n        // Is this a bug? 32768 does not exist, but -32768 does. The streams\n        // seem to use -32768 instead.\n        m_plDb[c][x]    = v;\n        m_plDa[c][ym-1] = v;\n        //\n        // One pixel done. Proceed to the next in the MCU. Note that\n        // the lines have been extended such that always a complete MCU is present.\n      } while(--xm && (lp++,pp++,x++,pred = pred->MoveRight(),true));\n      //\n      // Go to the next line.\n    } while(--ym && (pp = line->m_pData + (x = m_ulX[c]),line = (line->m_pNext)?(line->m_pNext):(line),\n                     lp = line->m_pData + x,mcupred = mcupred->MoveDown(),true));\n  }\n#else\n  NOREF(prev);\n  NOREF(top);\n#endif\n}",
        "func": "void ACLosslessScan::ParseMCU(struct Line **prev,struct Line **top)\n{ \n#if ACCUSOFT_CODE\n  UBYTE c;\n  //\n  // Parse a single MCU, which is now a group of pixels.\n  for(c = 0;c < m_ucCount;c++) {\n    struct QMContextSet &contextset = m_Context[m_ucContext[c]];\n    struct Line *line = top[c];\n    struct Line *pline= prev[c];\n    UBYTE ym = m_ucMCUHeight[c];\n    ULONG  x = m_ulX[c];\n    class PredictorBase *mcupred = m_pPredict[c];\n    LONG *lp = line->m_pData + x;\n    LONG *pp = (pline)?(pline->m_pData + x):(NULL);\n    //\n    // Parse MCUwidth * MCUheight coefficients starting at the line top.\n    do {\n      class PredictorBase *pred = mcupred;\n      UBYTE xm = m_ucMCUWidth[c];\n      do {\n        // Decode now the difference between the predicted value and\n        // the real value.\n        LONG v;\n        //\n        // Get the sign coding context.\n        struct QMContextSet::ContextZeroSet &zset = contextset.ClassifySignZero(m_plDa[c][ym-1],m_plDb[c][x],\n                                                                                m_ucSmall[c],m_ucLarge[c]);\n        //\n        if (m_Coder.Get(zset.S0)) {\n          LONG sz   = 0;\n          bool sign = m_Coder.Get(zset.SS); // true for negative.\n          //\n          if (m_Coder.Get((sign)?(zset.SN):(zset.SP))) {\n            struct QMContextSet::MagnitudeSet &mset = contextset.ClassifyMagnitude(m_plDb[c][x],m_ucLarge[c]);\n            int  i = 0;\n            LONG m = 2;\n            //\n            while(m_Coder.Get(mset.X[i])) {\n              m <<= 1;\n              if (++i >= QMContextSet::MagnitudeSet::MagnitudeContexts)\n                JPG_THROW(MALFORMED_STREAM,\"ACLosslessScan::ParseMCU\",\n                          \"received an out-of-bounds signal while parsing an AC-coded lossless symbol\");\n            }\n            //\n            m >>= 1;\n            sz  = m;\n            while((m >>= 1)) {\n              if (m_Coder.Get(mset.M[i])) {\n                sz |= m;\n              }\n            }\n          }\n          //\n          if (sign) {\n            v = -sz - 1;\n          } else {\n            v =  sz + 1;\n          }\n        } else {\n          v = 0;\n        }\n        //\n        // Use the prediction to fill in the sample.\n        lp[0] = pred->DecodeSample(v,lp,pp);\n        // Update Da and Db.\n        // Is this a bug? 32768 does not exist, but -32768 does. The streams\n        // seem to use -32768 instead.\n        m_plDb[c][x]    = v;\n        m_plDa[c][ym-1] = v;\n        //\n        // One pixel done. Proceed to the next in the MCU. Note that\n        // the lines have been extended such that always a complete MCU is present.\n      } while(--xm && (lp++,pp++,x++,pred = pred->MoveRight(),true));\n      //\n      // Go to the next line.\n    } while(--ym && (pp = line->m_pData + (x = m_ulX[c]),line = (line->m_pNext)?(line->m_pNext):(line),\n                     lp = line->m_pData + x,mcupred = mcupred->MoveDown(),true));\n  }\n#else\n  NOREF(prev);\n  NOREF(top);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,7 +38,9 @@\n             //\n             while(m_Coder.Get(mset.X[i])) {\n               m <<= 1;\n-              i++;\n+              if (++i >= QMContextSet::MagnitudeSet::MagnitudeContexts)\n+                JPG_THROW(MALFORMED_STREAM,\"ACLosslessScan::ParseMCU\",\n+                          \"received an out-of-bounds signal while parsing an AC-coded lossless symbol\");\n             }\n             //\n             m >>= 1;",
        "diff_line_info": {
            "deleted_lines": [
                "              i++;"
            ],
            "added_lines": [
                "              if (++i >= QMContextSet::MagnitudeSet::MagnitudeContexts)",
                "                JPG_THROW(MALFORMED_STREAM,\"ACLosslessScan::ParseMCU\",",
                "                          \"received an out-of-bounds signal while parsing an AC-coded lossless symbol\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-31620",
        "func_name": "thorfdbg/libjpeg/ACSequentialScan::DecodeBlock",
        "description": "In libjpeg before 1.64, BitStream<false>::Get in bitstream.hpp has an assertion failure that may cause denial of service. This is related to out-of-bounds array access during arithmetically coded lossless scan or arithmetically coded sequential scan.",
        "git_url": "https://github.com/thorfdbg/libjpeg/commit/ef4a29a62ab48b8dc235f4af52cfd6319eda9a6a",
        "commit_title": "Added out-of-bounds checks for lossless symbol decoding and AC context",
        "commit_text": "indices. Worked around some gcc warnings. Bumped to 1.64.",
        "func_before": "void ACSequentialScan::DecodeBlock(LONG *block,\n                                   LONG &prevdc,LONG &prevdiff,\n                                   UBYTE small,UBYTE large,UBYTE kx,UBYTE dc,UBYTE ac)\n{\n  // DC coding\n  if (m_ucScanStart == 0 && m_bResidual == false) {\n    LONG diff;\n    struct QMContextSet::DCContextZeroSet &cz = m_Context[dc].Classify(prevdiff,small,large);\n    // Check whether the difference is nonzero.\n    if (m_Coder.Get(cz.S0)) {\n      LONG sz;\n      bool sign = m_Coder.Get(cz.SS); // sign coding, is true for negative.\n      //\n      //\n      // Positive and negative are encoded in different contexts.\n      // Decode the magnitude cathegory.\n      if (m_Coder.Get((sign)?(cz.SN):(cz.SP))) {\n        int  i = 0;\n        LONG m = 2;\n        \n        while(m_Coder.Get(m_Context[dc].DCMagnitude.X[i])) {\n          m <<= 1;\n          i++;\n          if (m == 0) \n            JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                      \"QMDecoder is out of sync\");\n        }\n        //\n        // Get the MSB to decode.\n        m >>= 1;\n        sz  = m;\n        //\n        // Refinement coding of remaining bits.\n        while((m >>= 1)) {\n          if (m_Coder.Get(m_Context[dc].DCMagnitude.M[i])) {\n            sz |= m;\n          }\n        }\n      } else {\n        sz = 0;\n      }\n      //\n      // Done, finally, include the sign and the offset.\n      if (sign) {\n        diff = -sz - 1;\n      } else {\n        diff = sz + 1;\n      }\n    } else {\n      // Difference is zero.\n      diff = 0;\n    }\n\n    prevdiff = diff;\n    if (m_bDifferential) {\n      prevdc   = diff;\n    } else {\n      prevdc  += diff;\n    }\n    block[0] = prevdc << m_ucLowBit; // point transformation\n  }\n\n  if (m_ucScanStop) {\n    // AC coding. No block skipping used here.\n    int k = (m_ucScanStart)?(m_ucScanStart):((m_bResidual)?0:1);\n    //\n    // EOB decoding.\n    while(k <= m_ucScanStop && !m_Coder.Get(m_Context[ac].ACZero[k-1].SE)) {\n      LONG sz;\n      bool sign;\n      //\n      // Not yet EOB. Run coding in S0: Skip over zeros.\n      while(!m_Coder.Get(m_Context[ac].ACZero[k-1].S0)) {\n        k++;\n        if (k > m_ucScanStop)\n          JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                    \"QMDecoder is out of sync\");\n      }\n      //\n      // Now decode the sign of the coefficient.\n      // This happens in the uniform context.\n      sign = m_Coder.Get(m_Context[ac].Uniform);\n      //\n      // Decode the magnitude.\n      if (m_Coder.Get(m_Context[ac].ACZero[k-1].SP)) {\n        // X1 coding, identical to SN and SP.\n        if (m_Coder.Get(m_Context[ac].ACZero[k-1].SP)) {\n          int  i = 0;\n          LONG m = 4;\n          struct QMContextSet::ACContextMagnitudeSet &acm = (k > kx)?(m_Context[ac].ACMagnitudeHigh):(m_Context[ac].ACMagnitudeLow);\n          \n          while(m_Coder.Get(acm.X[i])) {\n            m <<= 1;\n            i++;\n            if (m == 0)\n              JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                        \"QMDecoder is out of sync\");\n          }\n          //\n          // Get the MSB to decode\n          m >>= 1;\n          sz  = m;\n          //\n          // Proceed to refinement.\n          while((m >>= 1)) {\n            if (m_Coder.Get(acm.M[i])) {\n              sz |= m;\n            }\n          }\n        } else {\n          sz = 1;\n        }\n      } else {\n        sz = 0;\n      }\n      //\n      // Done. Finally, include sign and offset.\n      sz++;\n      if (sign) \n        sz = -sz;\n      block[DCT::ScanOrder[k]] = sz << m_ucLowBit;\n      //\n      // Proceed to the next block.\n      k++;\n    }\n  }\n}",
        "func": "void ACSequentialScan::DecodeBlock(LONG *block,\n                                   LONG &prevdc,LONG &prevdiff,\n                                   UBYTE small,UBYTE large,UBYTE kx,UBYTE dc,UBYTE ac)\n{\n  // DC coding\n  if (m_ucScanStart == 0 && m_bResidual == false) {\n    LONG diff;\n    struct QMContextSet::DCContextZeroSet &cz = m_Context[dc].Classify(prevdiff,small,large);\n    // Check whether the difference is nonzero.\n    if (m_Coder.Get(cz.S0)) {\n      LONG sz;\n      bool sign = m_Coder.Get(cz.SS); // sign coding, is true for negative.\n      //\n      //\n      // Positive and negative are encoded in different contexts.\n      // Decode the magnitude cathegory.\n      if (m_Coder.Get((sign)?(cz.SN):(cz.SP))) {\n        int  i = 0;\n        LONG m = 2;\n        \n        while(m_Coder.Get(m_Context[dc].DCMagnitude.X[i])) {\n          m <<= 1;\n          if(++i >= QMContextSet::DCContextMagnitudeSet::MagnitudeContexts)\n            JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                      \"QMDecoder is out of sync\");\n        }\n        //\n        // Get the MSB to decode.\n        m >>= 1;\n        sz  = m;\n        //\n        // Refinement coding of remaining bits.\n        while((m >>= 1)) {\n          if (m_Coder.Get(m_Context[dc].DCMagnitude.M[i])) {\n            sz |= m;\n          }\n        }\n      } else {\n        sz = 0;\n      }\n      //\n      // Done, finally, include the sign and the offset.\n      if (sign) {\n        diff = -sz - 1;\n      } else {\n        diff = sz + 1;\n      }\n    } else {\n      // Difference is zero.\n      diff = 0;\n    }\n\n    prevdiff = diff;\n    if (m_bDifferential) {\n      prevdc   = diff;\n    } else {\n      prevdc  += diff;\n    }\n    block[0] = prevdc << m_ucLowBit; // point transformation\n  }\n\n  if (m_ucScanStop) {\n    // AC coding. No block skipping used here.\n    int k = (m_ucScanStart)?(m_ucScanStart):((m_bResidual)?0:1);\n    //\n    // EOB decoding.\n    while(k <= m_ucScanStop && !m_Coder.Get(m_Context[ac].ACZero[k-1].SE)) {\n      LONG sz;\n      bool sign;\n      //\n      // Not yet EOB. Run coding in S0: Skip over zeros.\n      while(!m_Coder.Get(m_Context[ac].ACZero[k-1].S0)) {\n        k++;\n        if (k > m_ucScanStop)\n          JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                    \"QMDecoder is out of sync\");\n      }\n      //\n      // Now decode the sign of the coefficient.\n      // This happens in the uniform context.\n      sign = m_Coder.Get(m_Context[ac].Uniform);\n      //\n      // Decode the magnitude.\n      if (m_Coder.Get(m_Context[ac].ACZero[k-1].SP)) {\n        // X1 coding, identical to SN and SP.\n        if (m_Coder.Get(m_Context[ac].ACZero[k-1].SP)) {\n          int  i = 0;\n          LONG m = 4;\n          struct QMContextSet::ACContextMagnitudeSet &acm = (k > kx)?(m_Context[ac].ACMagnitudeHigh):(m_Context[ac].ACMagnitudeLow);\n          \n          while(m_Coder.Get(acm.X[i])) {\n            m <<= 1;\n            if(++i >= QMContextSet::ACContextMagnitudeSet::MagnitudeContexts)\n              JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                        \"QMDecoder is out of sync\");\n          }\n          //\n          // Get the MSB to decode\n          m >>= 1;\n          sz  = m;\n          //\n          // Proceed to refinement.\n          while((m >>= 1)) {\n            if (m_Coder.Get(acm.M[i])) {\n              sz |= m;\n            }\n          }\n        } else {\n          sz = 1;\n        }\n      } else {\n        sz = 0;\n      }\n      //\n      // Done. Finally, include sign and offset.\n      sz++;\n      if (sign) \n        sz = -sz;\n      block[DCT::ScanOrder[k]] = sz << m_ucLowBit;\n      //\n      // Proceed to the next block.\n      k++;\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,8 +20,7 @@\n         \n         while(m_Coder.Get(m_Context[dc].DCMagnitude.X[i])) {\n           m <<= 1;\n-          i++;\n-          if (m == 0) \n+          if(++i >= QMContextSet::DCContextMagnitudeSet::MagnitudeContexts)\n             JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                       \"QMDecoder is out of sync\");\n         }\n@@ -91,8 +90,7 @@\n           \n           while(m_Coder.Get(acm.X[i])) {\n             m <<= 1;\n-            i++;\n-            if (m == 0)\n+            if(++i >= QMContextSet::ACContextMagnitudeSet::MagnitudeContexts)\n               JPG_THROW(MALFORMED_STREAM,\"ACSequentialScan::DecodeBlock\",\n                         \"QMDecoder is out of sync\");\n           }",
        "diff_line_info": {
            "deleted_lines": [
                "          i++;",
                "          if (m == 0) ",
                "            i++;",
                "            if (m == 0)"
            ],
            "added_lines": [
                "          if(++i >= QMContextSet::DCContextMagnitudeSet::MagnitudeContexts)",
                "            if(++i >= QMContextSet::ACContextMagnitudeSet::MagnitudeContexts)"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8745",
        "func_name": "qemu/vmxnet3_io_bar0_read",
        "description": "QEMU (aka Quick Emulator) built with a VMWARE VMXNET3 paravirtual NIC emulator support is vulnerable to crash issue. It could occur while reading Interrupt Mask Registers (IMR). A privileged (CAP_SYS_RAWIO) guest user could use this flaw to crash the QEMU process instance resulting in DoS.",
        "git_url": "https://github.com/qemu/qemu/commit/c6048f849c7e3f009786df76206e895a69de032c",
        "commit_title": "vmxnet3: Support reading IMR registers on bar0",
        "commit_text": " Instead of asserting, return the actual IMR register value. This is aligned with what's returned on ESXi. ",
        "func_before": "static uint64_t\nvmxnet3_io_bar0_read(void *opaque, hwaddr addr, unsigned size)\n{\n    if (VMW_IS_MULTIREG_ADDR(addr, VMXNET3_REG_IMR,\n                        VMXNET3_MAX_INTRS, VMXNET3_REG_ALIGN)) {\n        g_assert_not_reached();\n    }\n\n    VMW_CBPRN(\"BAR0 unknown read [%\" PRIx64 \"], size %d\", addr, size);\n    return 0;\n}",
        "func": "static uint64_t\nvmxnet3_io_bar0_read(void *opaque, hwaddr addr, unsigned size)\n{\n    VMXNET3State *s = opaque;\n\n    if (VMW_IS_MULTIREG_ADDR(addr, VMXNET3_REG_IMR,\n                        VMXNET3_MAX_INTRS, VMXNET3_REG_ALIGN)) {\n        int l = VMW_MULTIREG_IDX_BY_ADDR(addr, VMXNET3_REG_IMR,\n                                         VMXNET3_REG_ALIGN);\n        return s->interrupt_states[l].is_masked;\n    }\n\n    VMW_CBPRN(\"BAR0 unknown read [%\" PRIx64 \"], size %d\", addr, size);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,13 @@\n static uint64_t\n vmxnet3_io_bar0_read(void *opaque, hwaddr addr, unsigned size)\n {\n+    VMXNET3State *s = opaque;\n+\n     if (VMW_IS_MULTIREG_ADDR(addr, VMXNET3_REG_IMR,\n                         VMXNET3_MAX_INTRS, VMXNET3_REG_ALIGN)) {\n-        g_assert_not_reached();\n+        int l = VMW_MULTIREG_IDX_BY_ADDR(addr, VMXNET3_REG_IMR,\n+                                         VMXNET3_REG_ALIGN);\n+        return s->interrupt_states[l].is_masked;\n     }\n \n     VMW_CBPRN(\"BAR0 unknown read [%\" PRIx64 \"], size %d\", addr, size);",
        "diff_line_info": {
            "deleted_lines": [
                "        g_assert_not_reached();"
            ],
            "added_lines": [
                "    VMXNET3State *s = opaque;",
                "",
                "        int l = VMW_MULTIREG_IDX_BY_ADDR(addr, VMXNET3_REG_IMR,",
                "                                         VMXNET3_REG_ALIGN);",
                "        return s->interrupt_states[l].is_masked;"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9141",
        "func_name": "ImageMagick/ReadDDSImage",
        "description": "In ImageMagick 7.0.5-7 Q16, a crafted file could trigger an assertion failure in the ResetImageProfileIterator function in MagickCore/profile.c because of missing checks in the ReadDDSImage function in coders/dds.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/0c5b1e430a83ef793a7334bbbee408cf3c628699",
        "commit_title": "Added check to prevent image being 0x0 (reported in #489).",
        "commit_text": "",
        "func_before": "static Image *ReadDDSImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    status,\n    cubemap = MagickFalse,\n    volume = MagickFalse;\n\n  CompressionType\n    compression;\n\n  DDSInfo\n    dds_info;\n  \n  DDSDecoder\n    *decoder;\n  \n  PixelTrait\n    alpha_trait;\n  \n  size_t\n    n,\n    num_images;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  \n  /*\n    Initialize image structure.\n  */\n  if (ReadDDSInfo(image, &dds_info) != MagickTrue) {\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  }\n  \n  if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP)\n    cubemap = MagickTrue;\n  \n  if (dds_info.ddscaps2 & DDSCAPS2_VOLUME && dds_info.depth > 0)\n    volume = MagickTrue;\n  \n  (void) SeekBlob(image, 128, SEEK_SET);\n\n  /*\n    Determine pixel format\n  */\n  if (dds_info.pixelformat.flags & DDPF_RGB)\n    {\n      compression = NoCompression;\n      if (dds_info.pixelformat.flags & DDPF_ALPHAPIXELS)\n        {\n          alpha_trait = BlendPixelTrait;\n          decoder = ReadUncompressedRGBA;\n        }\n      else\n        {\n          alpha_trait = UndefinedPixelTrait;\n          decoder = ReadUncompressedRGB;\n        }\n    }\n  else if (dds_info.pixelformat.flags & DDPF_LUMINANCE)\n   {\n      compression = NoCompression;\n      if (dds_info.pixelformat.flags & DDPF_ALPHAPIXELS)\n        {\n          /* Not sure how to handle this */\n          ThrowReaderException(CorruptImageError, \"ImageTypeNotSupported\");\n        }\n      else\n        {\n          alpha_trait = UndefinedPixelTrait;\n          decoder = ReadUncompressedRGB;\n        }\n    }\n  else if (dds_info.pixelformat.flags & DDPF_FOURCC)\n    {\n      switch (dds_info.pixelformat.fourcc)\n      {\n        case FOURCC_DXT1:\n        {\n          alpha_trait = UndefinedPixelTrait;\n          compression = DXT1Compression;\n          decoder = ReadDXT1;\n          break;\n        }\n        case FOURCC_DXT3:\n        {\n          alpha_trait = BlendPixelTrait;\n          compression = DXT3Compression;\n          decoder = ReadDXT3;\n          break;\n        }\n        case FOURCC_DXT5:\n        {\n          alpha_trait = BlendPixelTrait;\n          compression = DXT5Compression;\n          decoder = ReadDXT5;\n          break;\n        }\n        default:\n        {\n          /* Unknown FOURCC */\n          ThrowReaderException(CorruptImageError, \"ImageTypeNotSupported\");\n        }\n      }\n    }\n  else\n    {\n      /* Neither compressed nor uncompressed... thus unsupported */\n      ThrowReaderException(CorruptImageError, \"ImageTypeNotSupported\");\n    }\n  \n  num_images = 1;\n  if (cubemap)\n    {\n      /*\n        Determine number of faces defined in the cubemap\n      */\n      num_images = 0;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_POSITIVEX) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_NEGATIVEX) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_POSITIVEY) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_NEGATIVEY) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_POSITIVEZ) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_NEGATIVEZ) num_images++;\n    }\n  \n  if (volume)\n    num_images = dds_info.depth;\n  \n  for (n = 0; n < num_images; n++)\n  {\n    if (n != 0)\n      {\n        /* Start a new image */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          return(DestroyImageList(image));\n        image=SyncNextImageInList(image);\n      }\n    \n    image->alpha_trait=alpha_trait;\n    image->compression = compression;\n    image->columns = dds_info.width;\n    image->rows = dds_info.height;\n    image->storage_class = DirectClass;\n    image->endian = LSBEndian;\n    image->depth = 8;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((decoder)(image, &dds_info, exception) != MagickTrue)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n  }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadDDSImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    status,\n    cubemap = MagickFalse,\n    volume = MagickFalse;\n\n  CompressionType\n    compression;\n\n  DDSInfo\n    dds_info;\n  \n  DDSDecoder\n    *decoder;\n  \n  PixelTrait\n    alpha_trait;\n  \n  size_t\n    n,\n    num_images;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  \n  /*\n    Initialize image structure.\n  */\n  if (ReadDDSInfo(image, &dds_info) != MagickTrue)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP)\n    cubemap = MagickTrue;\n\n  if (dds_info.ddscaps2 & DDSCAPS2_VOLUME && dds_info.depth > 0)\n    volume = MagickTrue;\n\n  (void) SeekBlob(image, 128, SEEK_SET);\n\n  /*\n    Determine pixel format\n  */\n  if (dds_info.pixelformat.flags & DDPF_RGB)\n    {\n      compression = NoCompression;\n      if (dds_info.pixelformat.flags & DDPF_ALPHAPIXELS)\n        {\n          alpha_trait = BlendPixelTrait;\n          decoder = ReadUncompressedRGBA;\n        }\n      else\n        {\n          alpha_trait = UndefinedPixelTrait;\n          decoder = ReadUncompressedRGB;\n        }\n    }\n  else if (dds_info.pixelformat.flags & DDPF_LUMINANCE)\n   {\n      compression = NoCompression;\n      if (dds_info.pixelformat.flags & DDPF_ALPHAPIXELS)\n        {\n          /* Not sure how to handle this */\n          ThrowReaderException(CorruptImageError, \"ImageTypeNotSupported\");\n        }\n      else\n        {\n          alpha_trait = UndefinedPixelTrait;\n          decoder = ReadUncompressedRGB;\n        }\n    }\n  else if (dds_info.pixelformat.flags & DDPF_FOURCC)\n    {\n      switch (dds_info.pixelformat.fourcc)\n      {\n        case FOURCC_DXT1:\n        {\n          alpha_trait = UndefinedPixelTrait;\n          compression = DXT1Compression;\n          decoder = ReadDXT1;\n          break;\n        }\n        case FOURCC_DXT3:\n        {\n          alpha_trait = BlendPixelTrait;\n          compression = DXT3Compression;\n          decoder = ReadDXT3;\n          break;\n        }\n        case FOURCC_DXT5:\n        {\n          alpha_trait = BlendPixelTrait;\n          compression = DXT5Compression;\n          decoder = ReadDXT5;\n          break;\n        }\n        default:\n        {\n          /* Unknown FOURCC */\n          ThrowReaderException(CorruptImageError, \"ImageTypeNotSupported\");\n        }\n      }\n    }\n  else\n    {\n      /* Neither compressed nor uncompressed... thus unsupported */\n      ThrowReaderException(CorruptImageError, \"ImageTypeNotSupported\");\n    }\n  \n  num_images = 1;\n  if (cubemap)\n    {\n      /*\n        Determine number of faces defined in the cubemap\n      */\n      num_images = 0;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_POSITIVEX) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_NEGATIVEX) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_POSITIVEY) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_NEGATIVEY) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_POSITIVEZ) num_images++;\n      if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP_NEGATIVEZ) num_images++;\n    }\n  \n  if (volume)\n    num_images = dds_info.depth;\n\n  if (num_images < 1)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  for (n = 0; n < num_images; n++)\n  {\n    if (n != 0)\n      {\n        /* Start a new image */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          return(DestroyImageList(image));\n        image=SyncNextImageInList(image);\n      }\n    \n    image->alpha_trait=alpha_trait;\n    image->compression = compression;\n    image->columns = dds_info.width;\n    image->rows = dds_info.height;\n    image->storage_class = DirectClass;\n    image->endian = LSBEndian;\n    image->depth = 8;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((decoder)(image, &dds_info, exception) != MagickTrue)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n  }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -45,16 +45,15 @@\n   /*\n     Initialize image structure.\n   */\n-  if (ReadDDSInfo(image, &dds_info) != MagickTrue) {\n+  if (ReadDDSInfo(image, &dds_info) != MagickTrue)\n     ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n-  }\n-  \n+\n   if (dds_info.ddscaps2 & DDSCAPS2_CUBEMAP)\n     cubemap = MagickTrue;\n-  \n+\n   if (dds_info.ddscaps2 & DDSCAPS2_VOLUME && dds_info.depth > 0)\n     volume = MagickTrue;\n-  \n+\n   (void) SeekBlob(image, 128, SEEK_SET);\n \n   /*\n@@ -143,7 +142,10 @@\n   \n   if (volume)\n     num_images = dds_info.depth;\n-  \n+\n+  if (num_images < 1)\n+    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n+\n   for (n = 0; n < num_images; n++)\n   {\n     if (n != 0)",
        "diff_line_info": {
            "deleted_lines": [
                "  if (ReadDDSInfo(image, &dds_info) != MagickTrue) {",
                "  }",
                "  ",
                "  ",
                "  ",
                "  "
            ],
            "added_lines": [
                "  if (ReadDDSInfo(image, &dds_info) != MagickTrue)",
                "",
                "",
                "",
                "",
                "  if (num_images < 1)",
                "    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9142",
        "func_name": "ImageMagick/ReadOneJNGImage",
        "description": "In ImageMagick 7.0.5-7 Q16, a crafted file could trigger an assertion failure in the WriteBlob function in MagickCore/blob.c because of missing checks in the ReadOneJNGImage function in coders/png.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/f0232a2a45dfd003c1faf6079497895df3ab0ee1",
        "commit_title": "Fixed incorrect call to WriteBlob reported in #490.",
        "commit_text": "",
        "func_before": "static Image *ReadOneJNGImage(MngInfo *mng_info,\n    const ImageInfo *image_info, ExceptionInfo *exception)\n{\n  Image\n    *alpha_image,\n    *color_image,\n    *image,\n    *jng_image;\n\n  ImageInfo\n    *alpha_image_info,\n    *color_image_info;\n\n  MagickBooleanType\n    logging;\n\n  ssize_t\n    y;\n\n  MagickBooleanType\n    status;\n\n  png_uint_32\n    jng_height,\n    jng_width;\n\n  png_byte\n    jng_color_type,\n    jng_image_sample_depth,\n    jng_image_compression_method,\n    jng_image_interlace_method,\n    jng_alpha_sample_depth,\n    jng_alpha_compression_method,\n    jng_alpha_filter_method,\n    jng_alpha_interlace_method;\n\n  register const Quantum\n    *s;\n\n  register ssize_t\n    i,\n    x;\n\n  register Quantum\n    *q;\n\n  register unsigned char\n    *p;\n\n  unsigned int\n    read_JSEP,\n    reading_idat;\n\n  size_t\n    length;\n\n  jng_alpha_compression_method=0;\n  jng_alpha_sample_depth=8;\n  jng_color_type=0;\n  jng_height=0;\n  jng_width=0;\n  alpha_image=(Image *) NULL;\n  color_image=(Image *) NULL;\n  alpha_image_info=(ImageInfo *) NULL;\n  color_image_info=(ImageInfo *) NULL;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneJNGImage()\");\n\n  image=mng_info->image;\n\n  if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n    {\n      /*\n        Allocate next image structure.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  AcquireNextImage()\");\n\n      AcquireNextImage(image_info,image,exception);\n\n      if (GetNextImageInList(image) == (Image *) NULL)\n        return(DestroyImageList(image));\n\n      image=SyncNextImageInList(image);\n    }\n  mng_info->image=image;\n\n  /*\n    Signature bytes have already been read.\n  */\n\n  read_JSEP=MagickFalse;\n  reading_idat=MagickFalse;\n  for (;;)\n  {\n    char\n      type[MagickPathExtent];\n\n    unsigned char\n      *chunk;\n\n    unsigned int\n      count;\n\n    /*\n      Read a new JNG chunk.\n    */\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n      2*GetBlobSize(image));\n\n    if (status == MagickFalse)\n      break;\n\n    type[0]='\\0';\n    (void) ConcatenateMagickString(type,\"errr\",MagickPathExtent);\n    length=ReadBlobMSBLong(image);\n    count=(unsigned int) ReadBlob(image,4,(unsigned char *) type);\n\n    if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Reading JNG chunk type %c%c%c%c, length: %.20g\",\n        type[0],type[1],type[2],type[3],(double) length);\n\n    if (length > PNG_UINT_31_MAX || count == 0)\n      ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n    p=NULL;\n    chunk=(unsigned char *) NULL;\n\n    if (length != 0)\n      {\n        chunk=(unsigned char *) AcquireQuantumMemory(length,sizeof(*chunk));\n\n        if (chunk == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n        for (i=0; i < (ssize_t) length; i++)\n          chunk[i]=(unsigned char) ReadBlobByte(image);\n\n        p=chunk;\n      }\n\n    (void) ReadBlobMSBLong(image);  /* read crc word */\n\n    if (memcmp(type,mng_JHDR,4) == 0)\n      {\n        if (length == 16)\n          {\n            jng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n              (p[2] << 8) | p[3]);\n            jng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n              (p[6] << 8) | p[7]);\n            if ((jng_width == 0) || (jng_height == 0))\n              ThrowReaderException(CorruptImageError,\n                \"NegativeOrZeroImageSize\");\n            jng_color_type=p[8];\n            jng_image_sample_depth=p[9];\n            jng_image_compression_method=p[10];\n            jng_image_interlace_method=p[11];\n\n            image->interlace=jng_image_interlace_method != 0 ? PNGInterlace :\n              NoInterlace;\n\n            jng_alpha_sample_depth=p[12];\n            jng_alpha_compression_method=p[13];\n            jng_alpha_filter_method=p[14];\n            jng_alpha_interlace_method=p[15];\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    jng_width:      %16lu,    jng_height:     %16lu\\n\"\n                  \"    jng_color_type: %16d,     jng_image_sample_depth: %3d\\n\"\n                  \"    jng_image_compression_method:%3d\",\n                  (unsigned long) jng_width, (unsigned long) jng_height,\n                  jng_color_type, jng_image_sample_depth,\n                  jng_image_compression_method);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    jng_image_interlace_method:  %3d\"\n                  \"    jng_alpha_sample_depth:      %3d\",\n                  jng_image_interlace_method,\n                  jng_alpha_sample_depth);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    jng_alpha_compression_method:%3d\\n\"\n                  \"    jng_alpha_filter_method:     %3d\\n\"\n                  \"    jng_alpha_interlace_method:  %3d\",\n                  jng_alpha_compression_method,\n                  jng_alpha_filter_method,\n                  jng_alpha_interlace_method);\n              }\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n\n    if ((reading_idat == MagickFalse) && (read_JSEP == MagickFalse) &&\n        ((memcmp(type,mng_JDAT,4) == 0) || (memcmp(type,mng_JdAA,4) == 0) ||\n         (memcmp(type,mng_IDAT,4) == 0) || (memcmp(type,mng_JDAA,4) == 0)))\n      {\n        /*\n           o create color_image\n           o open color_blob, attached to color_image\n           o if (color type has alpha)\n               open alpha_blob, attached to alpha_image\n        */\n\n        color_image_info=(ImageInfo *)AcquireMagickMemory(sizeof(ImageInfo));\n\n        if (color_image_info == (ImageInfo *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n        GetImageInfo(color_image_info);\n        color_image=AcquireImage(color_image_info,exception);\n\n        if (color_image == (Image *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Creating color_blob.\");\n\n        (void) AcquireUniqueFilename(color_image->filename);\n        status=OpenBlob(color_image_info,color_image,WriteBinaryBlobMode,\n          exception);\n\n        if (status == MagickFalse)\n          {\n            color_image=DestroyImage(color_image);\n            return(DestroyImageList(image));\n          }\n\n        if ((image_info->ping == MagickFalse) && (jng_color_type >= 12))\n          {\n            alpha_image_info=(ImageInfo *)\n              AcquireMagickMemory(sizeof(ImageInfo));\n\n            if (alpha_image_info == (ImageInfo *) NULL)\n              {\n                color_image=DestroyImage(color_image);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n\n            GetImageInfo(alpha_image_info);\n            alpha_image=AcquireImage(alpha_image_info,exception);\n\n            if (alpha_image == (Image *) NULL)\n              {\n                alpha_image_info=DestroyImageInfo(alpha_image_info);\n                color_image=DestroyImage(color_image);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Creating alpha_blob.\");\n\n            (void) AcquireUniqueFilename(alpha_image->filename);\n            status=OpenBlob(alpha_image_info,alpha_image,WriteBinaryBlobMode,\n              exception);\n\n            if (status == MagickFalse)\n              {\n                alpha_image=DestroyImage(alpha_image);\n                alpha_image_info=DestroyImageInfo(alpha_image_info);\n                color_image=DestroyImage(color_image);\n                return(DestroyImageList(image));\n              }\n\n            if (jng_alpha_compression_method == 0)\n              {\n                unsigned char\n                  data[18];\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Writing IHDR chunk to alpha_blob.\");\n\n                (void) WriteBlob(alpha_image,8,(const unsigned char *)\n                  \"\\211PNG\\r\\n\\032\\n\");\n\n                (void) WriteBlobMSBULong(alpha_image,13L);\n                PNGType(data,mng_IHDR);\n                LogPNGChunk(logging,mng_IHDR,13L);\n                PNGLong(data+4,jng_width);\n                PNGLong(data+8,jng_height);\n                data[12]=jng_alpha_sample_depth;\n                data[13]=0; /* color_type gray */\n                data[14]=0; /* compression method 0 */\n                data[15]=0; /* filter_method 0 */\n                data[16]=0; /* interlace_method 0 */\n                (void) WriteBlob(alpha_image,17,data);\n                (void) WriteBlobMSBULong(alpha_image,crc32(0,data,17));\n              }\n          }\n        reading_idat=MagickTrue;\n      }\n\n    if (memcmp(type,mng_JDAT,4) == 0)\n      {\n        /* Copy chunk to color_image->blob */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Copying JDAT chunk data to color_blob.\");\n\n        (void) WriteBlob(color_image,length,chunk);\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if (memcmp(type,mng_IDAT,4) == 0)\n      {\n        png_byte\n           data[5];\n\n        /* Copy IDAT header and chunk data to alpha_image->blob */\n\n        if (alpha_image != NULL && image_info->ping == MagickFalse)\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Copying IDAT chunk data to alpha_blob.\");\n\n            (void) WriteBlobMSBULong(alpha_image,(size_t) length);\n            PNGType(data,mng_IDAT);\n            LogPNGChunk(logging,mng_IDAT,length);\n            (void) WriteBlob(alpha_image,4,data);\n            (void) WriteBlob(alpha_image,length,chunk);\n            (void) WriteBlobMSBULong(alpha_image,\n              crc32(crc32(0,data,4),chunk,(uInt) length));\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if ((memcmp(type,mng_JDAA,4) == 0) || (memcmp(type,mng_JdAA,4) == 0))\n      {\n        /* Copy chunk data to alpha_image->blob */\n\n        if (alpha_image != NULL && image_info->ping == MagickFalse)\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Copying JDAA chunk data to alpha_blob.\");\n\n            (void) WriteBlob(alpha_image,length,chunk);\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if (memcmp(type,mng_JSEP,4) == 0)\n      {\n        read_JSEP=MagickTrue;\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if (memcmp(type,mng_bKGD,4) == 0)\n      {\n        if (length == 2)\n          {\n            image->background_color.red=ScaleCharToQuantum(p[1]);\n            image->background_color.green=image->background_color.red;\n            image->background_color.blue=image->background_color.red;\n          }\n\n        if (length == 6)\n          {\n            image->background_color.red=ScaleCharToQuantum(p[1]);\n            image->background_color.green=ScaleCharToQuantum(p[3]);\n            image->background_color.blue=ScaleCharToQuantum(p[5]);\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_gAMA,4) == 0)\n      {\n        if (length == 4)\n          image->gamma=((float) mng_get_long(p))*0.00001;\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_cHRM,4) == 0)\n      {\n        if (length == 32)\n          {\n            image->chromaticity.white_point.x=0.00001*mng_get_long(p);\n            image->chromaticity.white_point.y=0.00001*mng_get_long(&p[4]);\n            image->chromaticity.red_primary.x=0.00001*mng_get_long(&p[8]);\n            image->chromaticity.red_primary.y=0.00001*mng_get_long(&p[12]);\n            image->chromaticity.green_primary.x=0.00001*mng_get_long(&p[16]);\n            image->chromaticity.green_primary.y=0.00001*mng_get_long(&p[20]);\n            image->chromaticity.blue_primary.x=0.00001*mng_get_long(&p[24]);\n            image->chromaticity.blue_primary.y=0.00001*mng_get_long(&p[28]);\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_sRGB,4) == 0)\n      {\n        if (length == 1)\n          {\n            image->rendering_intent=\n              Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n            image->gamma=1.000f/2.200f;\n            image->chromaticity.red_primary.x=0.6400f;\n            image->chromaticity.red_primary.y=0.3300f;\n            image->chromaticity.green_primary.x=0.3000f;\n            image->chromaticity.green_primary.y=0.6000f;\n            image->chromaticity.blue_primary.x=0.1500f;\n            image->chromaticity.blue_primary.y=0.0600f;\n            image->chromaticity.white_point.x=0.3127f;\n            image->chromaticity.white_point.y=0.3290f;\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_oFFs,4) == 0)\n      {\n        if (length > 8)\n          {\n            image->page.x=(ssize_t) mng_get_long(p);\n            image->page.y=(ssize_t) mng_get_long(&p[4]);\n\n            if ((int) p[8] != 0)\n              {\n                image->page.x/=10000;\n                image->page.y/=10000;\n              }\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if (memcmp(type,mng_pHYs,4) == 0)\n      {\n        if (length > 8)\n          {\n            image->resolution.x=(double) mng_get_long(p);\n            image->resolution.y=(double) mng_get_long(&p[4]);\n            if ((int) p[8] == PNG_RESOLUTION_METER)\n              {\n                image->units=PixelsPerCentimeterResolution;\n                image->resolution.x=image->resolution.x/100.0f;\n                image->resolution.y=image->resolution.y/100.0f;\n              }\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n#if 0\n    if (memcmp(type,mng_iCCP,4) == 0)\n      {\n        /* To do: */\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n#endif\n\n    if (length != 0)\n      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n    if (memcmp(type,mng_IEND,4))\n      continue;\n\n    break;\n  }\n\n\n  /* IEND found */\n\n  /*\n    Finish up reading image data:\n\n       o read main image from color_blob.\n\n       o close color_blob.\n\n       o if (color_type has alpha)\n            if alpha_encoding is PNG\n               read secondary image from alpha_blob via ReadPNG\n            if alpha_encoding is JPEG\n               read secondary image from alpha_blob via ReadJPEG\n\n       o close alpha_blob.\n\n       o copy intensity of secondary image into\n         alpha samples of main image.\n\n       o destroy the secondary image.\n  */\n\n  if (color_image_info == (ImageInfo *) NULL)\n    {\n      assert(color_image == (Image *) NULL);\n      assert(alpha_image == (Image *) NULL);\n      return(DestroyImageList(image));\n    }\n\n  if (color_image == (Image *) NULL)\n    {\n      assert(alpha_image == (Image *) NULL);\n      return(DestroyImageList(image));\n    }\n\n  (void) SeekBlob(color_image,0,SEEK_SET);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    Reading jng_image from color_blob.\");\n\n  assert(color_image_info != (ImageInfo *) NULL);\n  (void) FormatLocaleString(color_image_info->filename,MagickPathExtent,\"%s\",\n    color_image->filename);\n\n  color_image_info->ping=MagickFalse;   /* To do: avoid this */\n  jng_image=ReadImage(color_image_info,exception);\n\n  (void) RelinquishUniqueFileResource(color_image->filename);\n  color_image=DestroyImage(color_image);\n  color_image_info=DestroyImageInfo(color_image_info);\n\n  if (jng_image == (Image *) NULL)\n    return(DestroyImageList(image));\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    Copying jng_image pixels to main image.\");\n\n  image->rows=jng_height;\n  image->columns=jng_width;\n\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    s=GetVirtualPixels(jng_image,0,y,image->columns,1,exception);\n    q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n    for (x=(ssize_t) image->columns; x != 0; x--)\n    {\n      SetPixelRed(image,GetPixelRed(jng_image,s),q);\n      SetPixelGreen(image,GetPixelGreen(jng_image,s),q);\n      SetPixelBlue(image,GetPixelBlue(jng_image,s),q);\n      q+=GetPixelChannels(image);\n      s+=GetPixelChannels(jng_image);\n    }\n\n    if (SyncAuthenticPixels(image,exception) == MagickFalse)\n      break;\n  }\n\n  jng_image=DestroyImage(jng_image);\n\n  if (image_info->ping == MagickFalse)\n    {\n     if (jng_color_type >= 12)\n       {\n         if (jng_alpha_compression_method == 0)\n           {\n             png_byte\n               data[5];\n             (void) WriteBlobMSBULong(alpha_image,0x00000000L);\n             PNGType(data,mng_IEND);\n             LogPNGChunk(logging,mng_IEND,0L);\n             (void) WriteBlob(alpha_image,4,data);\n             (void) WriteBlobMSBULong(alpha_image,crc32(0,data,4));\n           }\n\n         (void) CloseBlob(alpha_image);\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"    Reading alpha from alpha_blob.\");\n\n         (void) FormatLocaleString(alpha_image_info->filename,MagickPathExtent,\n           \"%s\",alpha_image->filename);\n\n         jng_image=ReadImage(alpha_image_info,exception);\n\n         if (jng_image != (Image *) NULL)\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             s=GetVirtualPixels(jng_image,0,y,image->columns,1,\n               exception);\n             q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (image->alpha_trait != UndefinedPixelTrait)\n               for (x=(ssize_t) image->columns; x != 0; x--)\n               {\n                  SetPixelAlpha(image,GetPixelRed(jng_image,s),q);\n                  q+=GetPixelChannels(image);\n                  s+=GetPixelChannels(jng_image);\n               }\n\n             else\n               for (x=(ssize_t) image->columns; x != 0; x--)\n               {\n                  SetPixelAlpha(image,GetPixelRed(jng_image,s),q);\n                  if (GetPixelAlpha(image,q) != OpaqueAlpha)\n                    image->alpha_trait=BlendPixelTrait;\n                  q+=GetPixelChannels(image);\n                  s+=GetPixelChannels(jng_image);\n               }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n           }\n         (void) RelinquishUniqueFileResource(alpha_image->filename);\n         alpha_image=DestroyImage(alpha_image);\n         alpha_image_info=DestroyImageInfo(alpha_image_info);\n         if (jng_image != (Image *) NULL)\n           jng_image=DestroyImage(jng_image);\n       }\n    }\n\n  /* Read the JNG image.  */\n\n  if (mng_info->mng_type == 0)\n    {\n      mng_info->mng_width=jng_width;\n      mng_info->mng_height=jng_height;\n    }\n\n  if (image->page.width == 0 && image->page.height == 0)\n    {\n      image->page.width=jng_width;\n      image->page.height=jng_height;\n    }\n\n  if (image->page.x == 0 && image->page.y == 0)\n    {\n      image->page.x=mng_info->x_off[mng_info->object_id];\n      image->page.y=mng_info->y_off[mng_info->object_id];\n    }\n\n  else\n    {\n      image->page.y=mng_info->y_off[mng_info->object_id];\n    }\n\n  mng_info->image_found++;\n  status=SetImageProgress(image,LoadImagesTag,2*TellBlob(image),\n    2*GetBlobSize(image));\n\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage()\");\n\n  return(image);\n}",
        "func": "static Image *ReadOneJNGImage(MngInfo *mng_info,\n    const ImageInfo *image_info, ExceptionInfo *exception)\n{\n  Image\n    *alpha_image,\n    *color_image,\n    *image,\n    *jng_image;\n\n  ImageInfo\n    *alpha_image_info,\n    *color_image_info;\n\n  MagickBooleanType\n    logging;\n\n  ssize_t\n    y;\n\n  MagickBooleanType\n    status;\n\n  png_uint_32\n    jng_height,\n    jng_width;\n\n  png_byte\n    jng_color_type,\n    jng_image_sample_depth,\n    jng_image_compression_method,\n    jng_image_interlace_method,\n    jng_alpha_sample_depth,\n    jng_alpha_compression_method,\n    jng_alpha_filter_method,\n    jng_alpha_interlace_method;\n\n  register const Quantum\n    *s;\n\n  register ssize_t\n    i,\n    x;\n\n  register Quantum\n    *q;\n\n  register unsigned char\n    *p;\n\n  unsigned int\n    read_JSEP,\n    reading_idat;\n\n  size_t\n    length;\n\n  jng_alpha_compression_method=0;\n  jng_alpha_sample_depth=8;\n  jng_color_type=0;\n  jng_height=0;\n  jng_width=0;\n  alpha_image=(Image *) NULL;\n  color_image=(Image *) NULL;\n  alpha_image_info=(ImageInfo *) NULL;\n  color_image_info=(ImageInfo *) NULL;\n\n  logging=LogMagickEvent(CoderEvent,GetMagickModule(),\n    \"  Enter ReadOneJNGImage()\");\n\n  image=mng_info->image;\n\n  if (GetAuthenticPixelQueue(image) != (Quantum *) NULL)\n    {\n      /*\n        Allocate next image structure.\n      */\n      if (logging != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n           \"  AcquireNextImage()\");\n\n      AcquireNextImage(image_info,image,exception);\n\n      if (GetNextImageInList(image) == (Image *) NULL)\n        return(DestroyImageList(image));\n\n      image=SyncNextImageInList(image);\n    }\n  mng_info->image=image;\n\n  /*\n    Signature bytes have already been read.\n  */\n\n  read_JSEP=MagickFalse;\n  reading_idat=MagickFalse;\n  for (;;)\n  {\n    char\n      type[MagickPathExtent];\n\n    unsigned char\n      *chunk;\n\n    unsigned int\n      count;\n\n    /*\n      Read a new JNG chunk.\n    */\n    status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n      2*GetBlobSize(image));\n\n    if (status == MagickFalse)\n      break;\n\n    type[0]='\\0';\n    (void) ConcatenateMagickString(type,\"errr\",MagickPathExtent);\n    length=ReadBlobMSBLong(image);\n    count=(unsigned int) ReadBlob(image,4,(unsigned char *) type);\n\n    if (logging != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Reading JNG chunk type %c%c%c%c, length: %.20g\",\n        type[0],type[1],type[2],type[3],(double) length);\n\n    if (length > PNG_UINT_31_MAX || count == 0)\n      ThrowReaderException(CorruptImageError,\"CorruptImage\");\n\n    p=NULL;\n    chunk=(unsigned char *) NULL;\n\n    if (length != 0)\n      {\n        chunk=(unsigned char *) AcquireQuantumMemory(length,sizeof(*chunk));\n\n        if (chunk == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n        for (i=0; i < (ssize_t) length; i++)\n          chunk[i]=(unsigned char) ReadBlobByte(image);\n\n        p=chunk;\n      }\n\n    (void) ReadBlobMSBLong(image);  /* read crc word */\n\n    if (memcmp(type,mng_JHDR,4) == 0)\n      {\n        if (length == 16)\n          {\n            jng_width=(size_t) ((p[0] << 24) | (p[1] << 16) |\n              (p[2] << 8) | p[3]);\n            jng_height=(size_t) ((p[4] << 24) | (p[5] << 16) |\n              (p[6] << 8) | p[7]);\n            if ((jng_width == 0) || (jng_height == 0))\n              ThrowReaderException(CorruptImageError,\n                \"NegativeOrZeroImageSize\");\n            jng_color_type=p[8];\n            jng_image_sample_depth=p[9];\n            jng_image_compression_method=p[10];\n            jng_image_interlace_method=p[11];\n\n            image->interlace=jng_image_interlace_method != 0 ? PNGInterlace :\n              NoInterlace;\n\n            jng_alpha_sample_depth=p[12];\n            jng_alpha_compression_method=p[13];\n            jng_alpha_filter_method=p[14];\n            jng_alpha_interlace_method=p[15];\n\n            if (logging != MagickFalse)\n              {\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    jng_width:      %16lu,    jng_height:     %16lu\\n\"\n                  \"    jng_color_type: %16d,     jng_image_sample_depth: %3d\\n\"\n                  \"    jng_image_compression_method:%3d\",\n                  (unsigned long) jng_width, (unsigned long) jng_height,\n                  jng_color_type, jng_image_sample_depth,\n                  jng_image_compression_method);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    jng_image_interlace_method:  %3d\"\n                  \"    jng_alpha_sample_depth:      %3d\",\n                  jng_image_interlace_method,\n                  jng_alpha_sample_depth);\n\n                (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                  \"    jng_alpha_compression_method:%3d\\n\"\n                  \"    jng_alpha_filter_method:     %3d\\n\"\n                  \"    jng_alpha_interlace_method:  %3d\",\n                  jng_alpha_compression_method,\n                  jng_alpha_filter_method,\n                  jng_alpha_interlace_method);\n              }\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n\n    if ((reading_idat == MagickFalse) && (read_JSEP == MagickFalse) &&\n        ((memcmp(type,mng_JDAT,4) == 0) || (memcmp(type,mng_JdAA,4) == 0) ||\n         (memcmp(type,mng_IDAT,4) == 0) || (memcmp(type,mng_JDAA,4) == 0)))\n      {\n        /*\n           o create color_image\n           o open color_blob, attached to color_image\n           o if (color type has alpha)\n               open alpha_blob, attached to alpha_image\n        */\n\n        color_image_info=(ImageInfo *)AcquireMagickMemory(sizeof(ImageInfo));\n\n        if (color_image_info == (ImageInfo *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n        GetImageInfo(color_image_info);\n        color_image=AcquireImage(color_image_info,exception);\n\n        if (color_image == (Image *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Creating color_blob.\");\n\n        (void) AcquireUniqueFilename(color_image->filename);\n        status=OpenBlob(color_image_info,color_image,WriteBinaryBlobMode,\n          exception);\n\n        if (status == MagickFalse)\n          {\n            color_image=DestroyImage(color_image);\n            return(DestroyImageList(image));\n          }\n\n        if ((image_info->ping == MagickFalse) && (jng_color_type >= 12))\n          {\n            alpha_image_info=(ImageInfo *)\n              AcquireMagickMemory(sizeof(ImageInfo));\n\n            if (alpha_image_info == (ImageInfo *) NULL)\n              {\n                color_image=DestroyImage(color_image);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n\n            GetImageInfo(alpha_image_info);\n            alpha_image=AcquireImage(alpha_image_info,exception);\n\n            if (alpha_image == (Image *) NULL)\n              {\n                alpha_image_info=DestroyImageInfo(alpha_image_info);\n                color_image=DestroyImage(color_image);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Creating alpha_blob.\");\n\n            (void) AcquireUniqueFilename(alpha_image->filename);\n            status=OpenBlob(alpha_image_info,alpha_image,WriteBinaryBlobMode,\n              exception);\n\n            if (status == MagickFalse)\n              {\n                alpha_image=DestroyImage(alpha_image);\n                alpha_image_info=DestroyImageInfo(alpha_image_info);\n                color_image=DestroyImage(color_image);\n                return(DestroyImageList(image));\n              }\n\n            if (jng_alpha_compression_method == 0)\n              {\n                unsigned char\n                  data[18];\n\n                if (logging != MagickFalse)\n                  (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                    \"    Writing IHDR chunk to alpha_blob.\");\n\n                (void) WriteBlob(alpha_image,8,(const unsigned char *)\n                  \"\\211PNG\\r\\n\\032\\n\");\n\n                (void) WriteBlobMSBULong(alpha_image,13L);\n                PNGType(data,mng_IHDR);\n                LogPNGChunk(logging,mng_IHDR,13L);\n                PNGLong(data+4,jng_width);\n                PNGLong(data+8,jng_height);\n                data[12]=jng_alpha_sample_depth;\n                data[13]=0; /* color_type gray */\n                data[14]=0; /* compression method 0 */\n                data[15]=0; /* filter_method 0 */\n                data[16]=0; /* interlace_method 0 */\n                (void) WriteBlob(alpha_image,17,data);\n                (void) WriteBlobMSBULong(alpha_image,crc32(0,data,17));\n              }\n          }\n        reading_idat=MagickTrue;\n      }\n\n    if (memcmp(type,mng_JDAT,4) == 0)\n      {\n        /* Copy chunk to color_image->blob */\n\n        if (logging != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"    Copying JDAT chunk data to color_blob.\");\n\n        if (length != 0)\n          {\n            (void) WriteBlob(color_image,length,chunk);\n            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n          }\n\n        continue;\n      }\n\n    if (memcmp(type,mng_IDAT,4) == 0)\n      {\n        png_byte\n           data[5];\n\n        /* Copy IDAT header and chunk data to alpha_image->blob */\n\n        if (alpha_image != NULL && image_info->ping == MagickFalse)\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Copying IDAT chunk data to alpha_blob.\");\n\n            (void) WriteBlobMSBULong(alpha_image,(size_t) length);\n            PNGType(data,mng_IDAT);\n            LogPNGChunk(logging,mng_IDAT,length);\n            (void) WriteBlob(alpha_image,4,data);\n            (void) WriteBlob(alpha_image,length,chunk);\n            (void) WriteBlobMSBULong(alpha_image,\n              crc32(crc32(0,data,4),chunk,(uInt) length));\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if ((memcmp(type,mng_JDAA,4) == 0) || (memcmp(type,mng_JdAA,4) == 0))\n      {\n        /* Copy chunk data to alpha_image->blob */\n\n        if (alpha_image != NULL && image_info->ping == MagickFalse)\n          {\n            if (logging != MagickFalse)\n              (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n                \"    Copying JDAA chunk data to alpha_blob.\");\n\n            (void) WriteBlob(alpha_image,length,chunk);\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if (memcmp(type,mng_JSEP,4) == 0)\n      {\n        read_JSEP=MagickTrue;\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if (memcmp(type,mng_bKGD,4) == 0)\n      {\n        if (length == 2)\n          {\n            image->background_color.red=ScaleCharToQuantum(p[1]);\n            image->background_color.green=image->background_color.red;\n            image->background_color.blue=image->background_color.red;\n          }\n\n        if (length == 6)\n          {\n            image->background_color.red=ScaleCharToQuantum(p[1]);\n            image->background_color.green=ScaleCharToQuantum(p[3]);\n            image->background_color.blue=ScaleCharToQuantum(p[5]);\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_gAMA,4) == 0)\n      {\n        if (length == 4)\n          image->gamma=((float) mng_get_long(p))*0.00001;\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_cHRM,4) == 0)\n      {\n        if (length == 32)\n          {\n            image->chromaticity.white_point.x=0.00001*mng_get_long(p);\n            image->chromaticity.white_point.y=0.00001*mng_get_long(&p[4]);\n            image->chromaticity.red_primary.x=0.00001*mng_get_long(&p[8]);\n            image->chromaticity.red_primary.y=0.00001*mng_get_long(&p[12]);\n            image->chromaticity.green_primary.x=0.00001*mng_get_long(&p[16]);\n            image->chromaticity.green_primary.y=0.00001*mng_get_long(&p[20]);\n            image->chromaticity.blue_primary.x=0.00001*mng_get_long(&p[24]);\n            image->chromaticity.blue_primary.y=0.00001*mng_get_long(&p[28]);\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_sRGB,4) == 0)\n      {\n        if (length == 1)\n          {\n            image->rendering_intent=\n              Magick_RenderingIntent_from_PNG_RenderingIntent(p[0]);\n            image->gamma=1.000f/2.200f;\n            image->chromaticity.red_primary.x=0.6400f;\n            image->chromaticity.red_primary.y=0.3300f;\n            image->chromaticity.green_primary.x=0.3000f;\n            image->chromaticity.green_primary.y=0.6000f;\n            image->chromaticity.blue_primary.x=0.1500f;\n            image->chromaticity.blue_primary.y=0.0600f;\n            image->chromaticity.white_point.x=0.3127f;\n            image->chromaticity.white_point.y=0.3290f;\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n    if (memcmp(type,mng_oFFs,4) == 0)\n      {\n        if (length > 8)\n          {\n            image->page.x=(ssize_t) mng_get_long(p);\n            image->page.y=(ssize_t) mng_get_long(&p[4]);\n\n            if ((int) p[8] != 0)\n              {\n                image->page.x/=10000;\n                image->page.y/=10000;\n              }\n          }\n\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n\n    if (memcmp(type,mng_pHYs,4) == 0)\n      {\n        if (length > 8)\n          {\n            image->resolution.x=(double) mng_get_long(p);\n            image->resolution.y=(double) mng_get_long(&p[4]);\n            if ((int) p[8] == PNG_RESOLUTION_METER)\n              {\n                image->units=PixelsPerCentimeterResolution;\n                image->resolution.x=image->resolution.x/100.0f;\n                image->resolution.y=image->resolution.y/100.0f;\n              }\n          }\n\n        chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n        continue;\n      }\n\n#if 0\n    if (memcmp(type,mng_iCCP,4) == 0)\n      {\n        /* To do: */\n        if (length != 0)\n          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n        continue;\n      }\n#endif\n\n    if (length != 0)\n      chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n\n    if (memcmp(type,mng_IEND,4))\n      continue;\n\n    break;\n  }\n\n\n  /* IEND found */\n\n  /*\n    Finish up reading image data:\n\n       o read main image from color_blob.\n\n       o close color_blob.\n\n       o if (color_type has alpha)\n            if alpha_encoding is PNG\n               read secondary image from alpha_blob via ReadPNG\n            if alpha_encoding is JPEG\n               read secondary image from alpha_blob via ReadJPEG\n\n       o close alpha_blob.\n\n       o copy intensity of secondary image into\n         alpha samples of main image.\n\n       o destroy the secondary image.\n  */\n\n  if (color_image_info == (ImageInfo *) NULL)\n    {\n      assert(color_image == (Image *) NULL);\n      assert(alpha_image == (Image *) NULL);\n      return(DestroyImageList(image));\n    }\n\n  if (color_image == (Image *) NULL)\n    {\n      assert(alpha_image == (Image *) NULL);\n      return(DestroyImageList(image));\n    }\n\n  (void) SeekBlob(color_image,0,SEEK_SET);\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    Reading jng_image from color_blob.\");\n\n  assert(color_image_info != (ImageInfo *) NULL);\n  (void) FormatLocaleString(color_image_info->filename,MagickPathExtent,\"%s\",\n    color_image->filename);\n\n  color_image_info->ping=MagickFalse;   /* To do: avoid this */\n  jng_image=ReadImage(color_image_info,exception);\n\n  (void) RelinquishUniqueFileResource(color_image->filename);\n  color_image=DestroyImage(color_image);\n  color_image_info=DestroyImageInfo(color_image_info);\n\n  if (jng_image == (Image *) NULL)\n    return(DestroyImageList(image));\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"    Copying jng_image pixels to main image.\");\n\n  image->rows=jng_height;\n  image->columns=jng_width;\n\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    s=GetVirtualPixels(jng_image,0,y,image->columns,1,exception);\n    q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n    for (x=(ssize_t) image->columns; x != 0; x--)\n    {\n      SetPixelRed(image,GetPixelRed(jng_image,s),q);\n      SetPixelGreen(image,GetPixelGreen(jng_image,s),q);\n      SetPixelBlue(image,GetPixelBlue(jng_image,s),q);\n      q+=GetPixelChannels(image);\n      s+=GetPixelChannels(jng_image);\n    }\n\n    if (SyncAuthenticPixels(image,exception) == MagickFalse)\n      break;\n  }\n\n  jng_image=DestroyImage(jng_image);\n\n  if (image_info->ping == MagickFalse)\n    {\n     if (jng_color_type >= 12)\n       {\n         if (jng_alpha_compression_method == 0)\n           {\n             png_byte\n               data[5];\n             (void) WriteBlobMSBULong(alpha_image,0x00000000L);\n             PNGType(data,mng_IEND);\n             LogPNGChunk(logging,mng_IEND,0L);\n             (void) WriteBlob(alpha_image,4,data);\n             (void) WriteBlobMSBULong(alpha_image,crc32(0,data,4));\n           }\n\n         (void) CloseBlob(alpha_image);\n\n         if (logging != MagickFalse)\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"    Reading alpha from alpha_blob.\");\n\n         (void) FormatLocaleString(alpha_image_info->filename,MagickPathExtent,\n           \"%s\",alpha_image->filename);\n\n         jng_image=ReadImage(alpha_image_info,exception);\n\n         if (jng_image != (Image *) NULL)\n           for (y=0; y < (ssize_t) image->rows; y++)\n           {\n             s=GetVirtualPixels(jng_image,0,y,image->columns,1,\n               exception);\n             q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n\n             if (image->alpha_trait != UndefinedPixelTrait)\n               for (x=(ssize_t) image->columns; x != 0; x--)\n               {\n                  SetPixelAlpha(image,GetPixelRed(jng_image,s),q);\n                  q+=GetPixelChannels(image);\n                  s+=GetPixelChannels(jng_image);\n               }\n\n             else\n               for (x=(ssize_t) image->columns; x != 0; x--)\n               {\n                  SetPixelAlpha(image,GetPixelRed(jng_image,s),q);\n                  if (GetPixelAlpha(image,q) != OpaqueAlpha)\n                    image->alpha_trait=BlendPixelTrait;\n                  q+=GetPixelChannels(image);\n                  s+=GetPixelChannels(jng_image);\n               }\n\n             if (SyncAuthenticPixels(image,exception) == MagickFalse)\n               break;\n           }\n         (void) RelinquishUniqueFileResource(alpha_image->filename);\n         alpha_image=DestroyImage(alpha_image);\n         alpha_image_info=DestroyImageInfo(alpha_image_info);\n         if (jng_image != (Image *) NULL)\n           jng_image=DestroyImage(jng_image);\n       }\n    }\n\n  /* Read the JNG image.  */\n\n  if (mng_info->mng_type == 0)\n    {\n      mng_info->mng_width=jng_width;\n      mng_info->mng_height=jng_height;\n    }\n\n  if (image->page.width == 0 && image->page.height == 0)\n    {\n      image->page.width=jng_width;\n      image->page.height=jng_height;\n    }\n\n  if (image->page.x == 0 && image->page.y == 0)\n    {\n      image->page.x=mng_info->x_off[mng_info->object_id];\n      image->page.y=mng_info->y_off[mng_info->object_id];\n    }\n\n  else\n    {\n      image->page.y=mng_info->y_off[mng_info->object_id];\n    }\n\n  mng_info->image_found++;\n  status=SetImageProgress(image,LoadImagesTag,2*TellBlob(image),\n    2*GetBlobSize(image));\n\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n  if (logging != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  exit ReadOneJNGImage()\");\n\n  return(image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -313,10 +313,11 @@\n           (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"    Copying JDAT chunk data to color_blob.\");\n \n-        (void) WriteBlob(color_image,length,chunk);\n-\n         if (length != 0)\n-          chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n+          {\n+            (void) WriteBlob(color_image,length,chunk);\n+            chunk=(unsigned char *) RelinquishMagickMemory(chunk);\n+          }\n \n         continue;\n       }",
        "diff_line_info": {
            "deleted_lines": [
                "        (void) WriteBlob(color_image,length,chunk);",
                "",
                "          chunk=(unsigned char *) RelinquishMagickMemory(chunk);"
            ],
            "added_lines": [
                "          {",
                "            (void) WriteBlob(color_image,length,chunk);",
                "            chunk=(unsigned char *) RelinquishMagickMemory(chunk);",
                "          }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9501",
        "func_name": "ImageMagick/CloneImage",
        "description": "In ImageMagick 7.0.5-7 Q16, an assertion failure was found in the function LockSemaphoreInfo, which allows attackers to cause a denial of service via a crafted file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/01843366d6a7b96e22ad7bb67f3df7d9fd4d5d74",
        "commit_title": "Fixed incorrect call to DestroyImage reported in #491.",
        "commit_text": "",
        "func_before": "MagickExport Image *CloneImage(const Image *image,const size_t columns,\n  const size_t rows,const MagickBooleanType detach,ExceptionInfo *exception)\n{\n  double\n    scale;\n\n  Image\n    *clone_image;\n\n  size_t\n    length;\n\n  /*\n    Clone the image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  if ((image->columns == 0) || (image->rows == 0))\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),CorruptImageError,\n        \"NegativeOrZeroImageSize\",\"`%s'\",image->filename);\n      return((Image *) NULL);\n    }\n  clone_image=(Image *) AcquireMagickMemory(sizeof(*clone_image));\n  if (clone_image == (Image *) NULL)\n    ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n  (void) ResetMagickMemory(clone_image,0,sizeof(*clone_image));\n  clone_image->signature=MagickSignature;\n  clone_image->storage_class=image->storage_class;\n  clone_image->channels=image->channels;\n  clone_image->colorspace=image->colorspace;\n  clone_image->matte=image->matte;\n  clone_image->columns=image->columns;\n  clone_image->rows=image->rows;\n  clone_image->dither=image->dither;\n  if (image->colormap != (PixelPacket *) NULL)\n    {\n      /*\n        Allocate and copy the image colormap.\n      */\n      clone_image->colors=image->colors;\n      length=(size_t) image->colors;\n      clone_image->colormap=(PixelPacket *) AcquireQuantumMemory(length,\n        sizeof(*clone_image->colormap));\n      if (clone_image->colormap == (PixelPacket *) NULL)\n        {\n          clone_image=DestroyImage(clone_image);\n          ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      (void) CopyMagickMemory(clone_image->colormap,image->colormap,length*\n        sizeof(*clone_image->colormap));\n    }\n  (void) CloneImageProfiles(clone_image,image);\n  (void) CloneImageProperties(clone_image,image);\n  (void) CloneImageArtifacts(clone_image,image);\n  GetTimerInfo(&clone_image->timer);\n  InitializeExceptionInfo(&clone_image->exception);\n  InheritException(&clone_image->exception,&image->exception);\n  if (image->ascii85 != (void *) NULL)\n    Ascii85Initialize(clone_image);\n  clone_image->magick_columns=image->magick_columns;\n  clone_image->magick_rows=image->magick_rows;\n  clone_image->type=image->type;\n  (void) CopyMagickString(clone_image->magick_filename,image->magick_filename,\n    MaxTextExtent);\n  (void) CopyMagickString(clone_image->magick,image->magick,MaxTextExtent);\n  (void) CopyMagickString(clone_image->filename,image->filename,MaxTextExtent);\n  clone_image->progress_monitor=image->progress_monitor;\n  clone_image->client_data=image->client_data;\n  clone_image->reference_count=1;\n  clone_image->next=image->next;\n  clone_image->previous=image->previous;\n  clone_image->list=NewImageList();\n  clone_image->clip_mask=NewImageList();\n  clone_image->mask=NewImageList();\n  if (detach == MagickFalse)\n    clone_image->blob=ReferenceBlob(image->blob);\n  else\n    {\n      clone_image->next=NewImageList();\n      clone_image->previous=NewImageList();\n      clone_image->blob=CloneBlobInfo((BlobInfo *) NULL);\n    }\n  clone_image->ping=image->ping;\n  clone_image->debug=IsEventLogging();\n  clone_image->semaphore=AllocateSemaphoreInfo();\n  if ((columns == 0) || (rows == 0))\n    {\n      if (image->montage != (char *) NULL)\n        (void) CloneString(&clone_image->montage,image->montage);\n      if (image->directory != (char *) NULL)\n        (void) CloneString(&clone_image->directory,image->directory);\n      if (image->clip_mask != (Image *) NULL)\n        clone_image->clip_mask=CloneImage(image->clip_mask,0,0,MagickTrue,\n          exception);\n      if (image->mask != (Image *) NULL)\n        clone_image->mask=CloneImage(image->mask,0,0,MagickTrue,exception);\n      clone_image->cache=ReferencePixelCache(image->cache);\n      return(clone_image);\n    }\n  if ((columns == image->columns) && (rows == image->rows))\n    {\n      if (image->clip_mask != (Image *) NULL)\n        clone_image->clip_mask=CloneImage(image->clip_mask,0,0,MagickTrue,\n          exception);\n      if (image->mask != (Image *) NULL)\n        clone_image->mask=CloneImage(image->mask,0,0,MagickTrue,exception);\n    }\n  scale=1.0;\n  if (image->columns != 0)\n    scale=(double) columns/(double) image->columns;\n  clone_image->page.width=(size_t) floor(scale*image->page.width+0.5);\n  clone_image->page.x=(ssize_t) ceil(scale*image->page.x-0.5);\n  clone_image->tile_offset.x=(ssize_t) ceil(scale*image->tile_offset.x-0.5);\n  scale=1.0;\n  if (image->rows != 0)\n    scale=(double) rows/(double) image->rows;\n  clone_image->page.height=(size_t) floor(scale*image->page.height+0.5);\n  clone_image->page.y=(ssize_t) ceil(scale*image->page.y-0.5);\n  clone_image->tile_offset.y=(ssize_t) ceil(scale*image->tile_offset.y-0.5);\n  clone_image->cache=ClonePixelCache(image->cache);\n  if (SetImageExtent(clone_image,columns,rows) == MagickFalse)\n    {\n      InheritException(exception,&clone_image->exception);\n      clone_image=DestroyImage(clone_image);\n    }\n  return(clone_image);\n}",
        "func": "MagickExport Image *CloneImage(const Image *image,const size_t columns,\n  const size_t rows,const MagickBooleanType detach,ExceptionInfo *exception)\n{\n  double\n    scale;\n\n  Image\n    *clone_image;\n\n  size_t\n    length;\n\n  /*\n    Clone the image.\n  */\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  if ((image->columns == 0) || (image->rows == 0))\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),CorruptImageError,\n        \"NegativeOrZeroImageSize\",\"`%s'\",image->filename);\n      return((Image *) NULL);\n    }\n  clone_image=(Image *) AcquireMagickMemory(sizeof(*clone_image));\n  if (clone_image == (Image *) NULL)\n    ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n  (void) ResetMagickMemory(clone_image,0,sizeof(*clone_image));\n  clone_image->signature=MagickSignature;\n  clone_image->storage_class=image->storage_class;\n  clone_image->channels=image->channels;\n  clone_image->colorspace=image->colorspace;\n  clone_image->matte=image->matte;\n  clone_image->columns=image->columns;\n  clone_image->rows=image->rows;\n  clone_image->dither=image->dither;\n  if (image->colormap != (PixelPacket *) NULL)\n    {\n      /*\n        Allocate and copy the image colormap.\n      */\n      clone_image->colors=image->colors;\n      length=(size_t) image->colors;\n      clone_image->colormap=(PixelPacket *) AcquireQuantumMemory(length,\n        sizeof(*clone_image->colormap));\n      if (clone_image->colormap == (PixelPacket *) NULL)\n        {\n          image=(Image *) RelinquishMagickMemory(image);\n          ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      (void) CopyMagickMemory(clone_image->colormap,image->colormap,length*\n        sizeof(*clone_image->colormap));\n    }\n  (void) CloneImageProfiles(clone_image,image);\n  (void) CloneImageProperties(clone_image,image);\n  (void) CloneImageArtifacts(clone_image,image);\n  GetTimerInfo(&clone_image->timer);\n  InitializeExceptionInfo(&clone_image->exception);\n  InheritException(&clone_image->exception,&image->exception);\n  if (image->ascii85 != (void *) NULL)\n    Ascii85Initialize(clone_image);\n  clone_image->magick_columns=image->magick_columns;\n  clone_image->magick_rows=image->magick_rows;\n  clone_image->type=image->type;\n  (void) CopyMagickString(clone_image->magick_filename,image->magick_filename,\n    MaxTextExtent);\n  (void) CopyMagickString(clone_image->magick,image->magick,MaxTextExtent);\n  (void) CopyMagickString(clone_image->filename,image->filename,MaxTextExtent);\n  clone_image->progress_monitor=image->progress_monitor;\n  clone_image->client_data=image->client_data;\n  clone_image->reference_count=1;\n  clone_image->next=image->next;\n  clone_image->previous=image->previous;\n  clone_image->list=NewImageList();\n  clone_image->clip_mask=NewImageList();\n  clone_image->mask=NewImageList();\n  if (detach == MagickFalse)\n    clone_image->blob=ReferenceBlob(image->blob);\n  else\n    {\n      clone_image->next=NewImageList();\n      clone_image->previous=NewImageList();\n      clone_image->blob=CloneBlobInfo((BlobInfo *) NULL);\n    }\n  clone_image->ping=image->ping;\n  clone_image->debug=IsEventLogging();\n  clone_image->semaphore=AllocateSemaphoreInfo();\n  if ((columns == 0) || (rows == 0))\n    {\n      if (image->montage != (char *) NULL)\n        (void) CloneString(&clone_image->montage,image->montage);\n      if (image->directory != (char *) NULL)\n        (void) CloneString(&clone_image->directory,image->directory);\n      if (image->clip_mask != (Image *) NULL)\n        clone_image->clip_mask=CloneImage(image->clip_mask,0,0,MagickTrue,\n          exception);\n      if (image->mask != (Image *) NULL)\n        clone_image->mask=CloneImage(image->mask,0,0,MagickTrue,exception);\n      clone_image->cache=ReferencePixelCache(image->cache);\n      return(clone_image);\n    }\n  if ((columns == image->columns) && (rows == image->rows))\n    {\n      if (image->clip_mask != (Image *) NULL)\n        clone_image->clip_mask=CloneImage(image->clip_mask,0,0,MagickTrue,\n          exception);\n      if (image->mask != (Image *) NULL)\n        clone_image->mask=CloneImage(image->mask,0,0,MagickTrue,exception);\n    }\n  scale=1.0;\n  if (image->columns != 0)\n    scale=(double) columns/(double) image->columns;\n  clone_image->page.width=(size_t) floor(scale*image->page.width+0.5);\n  clone_image->page.x=(ssize_t) ceil(scale*image->page.x-0.5);\n  clone_image->tile_offset.x=(ssize_t) ceil(scale*image->tile_offset.x-0.5);\n  scale=1.0;\n  if (image->rows != 0)\n    scale=(double) rows/(double) image->rows;\n  clone_image->page.height=(size_t) floor(scale*image->page.height+0.5);\n  clone_image->page.y=(ssize_t) ceil(scale*image->page.y-0.5);\n  clone_image->tile_offset.y=(ssize_t) ceil(scale*image->tile_offset.y-0.5);\n  clone_image->cache=ClonePixelCache(image->cache);\n  if (SetImageExtent(clone_image,columns,rows) == MagickFalse)\n    {\n      InheritException(exception,&clone_image->exception);\n      clone_image=DestroyImage(clone_image);\n    }\n  return(clone_image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -48,7 +48,7 @@\n         sizeof(*clone_image->colormap));\n       if (clone_image->colormap == (PixelPacket *) NULL)\n         {\n-          clone_image=DestroyImage(clone_image);\n+          image=(Image *) RelinquishMagickMemory(image);\n           ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n         }\n       (void) CopyMagickMemory(clone_image->colormap,image->colormap,length*",
        "diff_line_info": {
            "deleted_lines": [
                "          clone_image=DestroyImage(clone_image);"
            ],
            "added_lines": [
                "          image=(Image *) RelinquishMagickMemory(image);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-0375",
        "func_name": "torproject/tor/connection_exit_begin_conn",
        "description": "The hidden-service feature in Tor before 0.3.0.8 allows a denial of service (assertion failure and daemon exit) in the relay_send_end_cell_from_edge_ function via a malformed BEGIN cell.",
        "git_url": "https://github.com/torproject/tor/commit/79b59a2dfcb68897ee89d98587d09e55f07e68d7",
        "commit_title": "TROVE-2017-004: Fix assertion failure in relay_send_end_cell_from_edge_",
        "commit_text": " This fixes an assertion failure in relay_send_end_cell_from_edge_() when an origin circuit and a cpath_layer = NULL were passed.  A service rendezvous circuit could do such a thing when a malformed BEGIN cell is received but shouldn't in the first place because the service needs to send an END cell on the circuit for which it can not do without a cpath_layer.  Fixes #22493 ",
        "func_before": "int\nconnection_exit_begin_conn(cell_t *cell, circuit_t *circ)\n{\n  edge_connection_t *n_stream;\n  relay_header_t rh;\n  char *address = NULL;\n  uint16_t port = 0;\n  or_circuit_t *or_circ = NULL;\n  const or_options_t *options = get_options();\n  begin_cell_t bcell;\n  int rv;\n  uint8_t end_reason=0;\n\n  assert_circuit_ok(circ);\n  if (!CIRCUIT_IS_ORIGIN(circ))\n    or_circ = TO_OR_CIRCUIT(circ);\n\n  relay_header_unpack(&rh, cell->payload);\n  if (rh.length > RELAY_PAYLOAD_SIZE)\n    return -END_CIRC_REASON_TORPROTOCOL;\n\n  /* Note: we have to use relay_send_command_from_edge here, not\n   * connection_edge_end or connection_edge_send_command, since those require\n   * that we have a stream connected to a circuit, and we don't connect to a\n   * circuit until we have a pending/successful resolve. */\n\n  if (!server_mode(options) &&\n      circ->purpose != CIRCUIT_PURPOSE_S_REND_JOINED) {\n    log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n           \"Relay begin cell at non-server. Closing.\");\n    relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                  END_STREAM_REASON_EXITPOLICY, NULL);\n    return 0;\n  }\n\n  rv = begin_cell_parse(cell, &bcell, &end_reason);\n  if (rv < -1) {\n    return -END_CIRC_REASON_TORPROTOCOL;\n  } else if (rv == -1) {\n    tor_free(bcell.address);\n    relay_send_end_cell_from_edge(rh.stream_id, circ, end_reason, NULL);\n    return 0;\n  }\n\n  if (! bcell.is_begindir) {\n    /* Steal reference */\n    address = bcell.address;\n    port = bcell.port;\n\n    if (or_circ && or_circ->p_chan) {\n      if (!options->AllowSingleHopExits &&\n           (or_circ->is_first_hop ||\n            (!connection_or_digest_is_known_relay(\n                or_circ->p_chan->identity_digest) &&\n          should_refuse_unknown_exits(options)))) {\n        /* Don't let clients use us as a single-hop proxy, unless the user\n         * has explicitly allowed that in the config. It attracts attackers\n         * and users who'd be better off with, well, single-hop proxies.\n         */\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"Attempt by %s to open a stream %s. Closing.\",\n               safe_str(channel_get_canonical_remote_descr(or_circ->p_chan)),\n               or_circ->is_first_hop ? \"on first hop of circuit\" :\n                                       \"from unknown relay\");\n        relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                      or_circ->is_first_hop ?\n                                        END_STREAM_REASON_TORPROTOCOL :\n                                        END_STREAM_REASON_MISC,\n                                      NULL);\n        tor_free(address);\n        return 0;\n      }\n    }\n  } else if (rh.command == RELAY_COMMAND_BEGIN_DIR) {\n    if (!directory_permits_begindir_requests(options) ||\n        circ->purpose != CIRCUIT_PURPOSE_OR) {\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                    END_STREAM_REASON_NOTDIRECTORY, NULL);\n      return 0;\n    }\n    /* Make sure to get the 'real' address of the previous hop: the\n     * caller might want to know whether the remote IP address has changed,\n     * and we might already have corrected base_.addr[ess] for the relay's\n     * canonical IP address. */\n    if (or_circ && or_circ->p_chan)\n      address = tor_strdup(channel_get_actual_remote_address(or_circ->p_chan));\n    else\n      address = tor_strdup(\"127.0.0.1\");\n    port = 1; /* XXXX This value is never actually used anywhere, and there\n               * isn't \"really\" a connection here.  But we\n               * need to set it to something nonzero. */\n  } else {\n    log_warn(LD_BUG, \"Got an unexpected command %d\", (int)rh.command);\n    relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                  END_STREAM_REASON_INTERNAL, NULL);\n    return 0;\n  }\n\n  if (! options->IPv6Exit) {\n    /* I don't care if you prefer IPv6; I can't give you any. */\n    bcell.flags &= ~BEGIN_FLAG_IPV6_PREFERRED;\n    /* If you don't want IPv4, I can't help. */\n    if (bcell.flags & BEGIN_FLAG_IPV4_NOT_OK) {\n      tor_free(address);\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                    END_STREAM_REASON_EXITPOLICY, NULL);\n      return 0;\n    }\n  }\n\n  log_debug(LD_EXIT,\"Creating new exit connection.\");\n  /* The 'AF_INET' here is temporary; we might need to change it later in\n   * connection_exit_connect(). */\n  n_stream = edge_connection_new(CONN_TYPE_EXIT, AF_INET);\n\n  /* Remember the tunneled request ID in the new edge connection, so that\n   * we can measure download times. */\n  n_stream->dirreq_id = circ->dirreq_id;\n\n  n_stream->base_.purpose = EXIT_PURPOSE_CONNECT;\n  n_stream->begincell_flags = bcell.flags;\n  n_stream->stream_id = rh.stream_id;\n  n_stream->base_.port = port;\n  /* leave n_stream->s at -1, because it's not yet valid */\n  n_stream->package_window = STREAMWINDOW_START;\n  n_stream->deliver_window = STREAMWINDOW_START;\n\n  if (circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED) {\n    origin_circuit_t *origin_circ = TO_ORIGIN_CIRCUIT(circ);\n    log_info(LD_REND,\"begin is for rendezvous. configuring stream.\");\n    n_stream->base_.address = tor_strdup(\"(rendezvous)\");\n    n_stream->base_.state = EXIT_CONN_STATE_CONNECTING;\n    n_stream->rend_data = rend_data_dup(origin_circ->rend_data);\n    tor_assert(connection_edge_is_rendezvous_stream(n_stream));\n    assert_circuit_ok(circ);\n\n    const int r = rend_service_set_connection_addr_port(n_stream, origin_circ);\n    if (r < 0) {\n      log_info(LD_REND,\"Didn't find rendezvous service (port %d)\",\n               n_stream->base_.port);\n      /* Send back reason DONE because we want to make hidden service port\n       * scanning harder thus instead of returning that the exit policy\n       * didn't match, which makes it obvious that the port is closed,\n       * return DONE and kill the circuit. That way, a user (malicious or\n       * not) needs one circuit per bad port unless it matches the policy of\n       * the hidden service. */\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                    END_STREAM_REASON_DONE,\n                                    origin_circ->cpath->prev);\n      connection_free(TO_CONN(n_stream));\n      tor_free(address);\n\n      /* Drop the circuit here since it might be someone deliberately\n       * scanning the hidden service ports. Note that this mitigates port\n       * scanning by adding more work on the attacker side to successfully\n       * scan but does not fully solve it. */\n      if (r < -1)\n        return END_CIRC_AT_ORIGIN;\n      else\n        return 0;\n    }\n    assert_circuit_ok(circ);\n    log_debug(LD_REND,\"Finished assigning addr/port\");\n    n_stream->cpath_layer = origin_circ->cpath->prev; /* link it */\n\n    /* add it into the linked list of p_streams on this circuit */\n    n_stream->next_stream = origin_circ->p_streams;\n    n_stream->on_circuit = circ;\n    origin_circ->p_streams = n_stream;\n    assert_circuit_ok(circ);\n\n    origin_circ->rend_data->nr_streams++;\n\n    connection_exit_connect(n_stream);\n\n    /* For path bias: This circuit was used successfully */\n    pathbias_mark_use_success(origin_circ);\n\n    tor_free(address);\n    return 0;\n  }\n  tor_strlower(address);\n  n_stream->base_.address = address;\n  n_stream->base_.state = EXIT_CONN_STATE_RESOLVEFAILED;\n  /* default to failed, change in dns_resolve if it turns out not to fail */\n\n  if (we_are_hibernating()) {\n    relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                  END_STREAM_REASON_HIBERNATING, NULL);\n    connection_free(TO_CONN(n_stream));\n    return 0;\n  }\n\n  n_stream->on_circuit = circ;\n\n  if (rh.command == RELAY_COMMAND_BEGIN_DIR) {\n    tor_addr_t tmp_addr;\n    tor_assert(or_circ);\n    if (or_circ->p_chan &&\n        channel_get_addr_if_possible(or_circ->p_chan, &tmp_addr)) {\n      tor_addr_copy(&n_stream->base_.addr, &tmp_addr);\n    }\n    return connection_exit_connect_dir(n_stream);\n  }\n\n  log_debug(LD_EXIT,\"about to start the dns_resolve().\");\n\n  /* send it off to the gethostbyname farm */\n  switch (dns_resolve(n_stream)) {\n    case 1: /* resolve worked; now n_stream is attached to circ. */\n      assert_circuit_ok(circ);\n      log_debug(LD_EXIT,\"about to call connection_exit_connect().\");\n      connection_exit_connect(n_stream);\n      return 0;\n    case -1: /* resolve failed */\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                    END_STREAM_REASON_RESOLVEFAILED, NULL);\n      /* n_stream got freed. don't touch it. */\n      break;\n    case 0: /* resolve added to pending list */\n      assert_circuit_ok(circ);\n      break;\n  }\n  return 0;\n}",
        "func": "int\nconnection_exit_begin_conn(cell_t *cell, circuit_t *circ)\n{\n  edge_connection_t *n_stream;\n  relay_header_t rh;\n  char *address = NULL;\n  uint16_t port = 0;\n  or_circuit_t *or_circ = NULL;\n  origin_circuit_t *origin_circ = NULL;\n  crypt_path_t *layer_hint = NULL;\n  const or_options_t *options = get_options();\n  begin_cell_t bcell;\n  int rv;\n  uint8_t end_reason=0;\n\n  assert_circuit_ok(circ);\n  if (!CIRCUIT_IS_ORIGIN(circ)) {\n    or_circ = TO_OR_CIRCUIT(circ);\n  } else {\n    tor_assert(circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED);\n    origin_circ = TO_ORIGIN_CIRCUIT(circ);\n    layer_hint = origin_circ->cpath->prev;\n  }\n\n  relay_header_unpack(&rh, cell->payload);\n  if (rh.length > RELAY_PAYLOAD_SIZE)\n    return -END_CIRC_REASON_TORPROTOCOL;\n\n  /* Note: we have to use relay_send_command_from_edge here, not\n   * connection_edge_end or connection_edge_send_command, since those require\n   * that we have a stream connected to a circuit, and we don't connect to a\n   * circuit until we have a pending/successful resolve. */\n\n  if (!server_mode(options) &&\n      circ->purpose != CIRCUIT_PURPOSE_S_REND_JOINED) {\n    log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n           \"Relay begin cell at non-server. Closing.\");\n    relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                  END_STREAM_REASON_EXITPOLICY, NULL);\n    return 0;\n  }\n\n  rv = begin_cell_parse(cell, &bcell, &end_reason);\n  if (rv < -1) {\n    return -END_CIRC_REASON_TORPROTOCOL;\n  } else if (rv == -1) {\n    tor_free(bcell.address);\n    relay_send_end_cell_from_edge(rh.stream_id, circ, end_reason, layer_hint);\n    return 0;\n  }\n\n  if (! bcell.is_begindir) {\n    /* Steal reference */\n    address = bcell.address;\n    port = bcell.port;\n\n    if (or_circ && or_circ->p_chan) {\n      if (!options->AllowSingleHopExits &&\n           (or_circ->is_first_hop ||\n            (!connection_or_digest_is_known_relay(\n                or_circ->p_chan->identity_digest) &&\n          should_refuse_unknown_exits(options)))) {\n        /* Don't let clients use us as a single-hop proxy, unless the user\n         * has explicitly allowed that in the config. It attracts attackers\n         * and users who'd be better off with, well, single-hop proxies.\n         */\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"Attempt by %s to open a stream %s. Closing.\",\n               safe_str(channel_get_canonical_remote_descr(or_circ->p_chan)),\n               or_circ->is_first_hop ? \"on first hop of circuit\" :\n                                       \"from unknown relay\");\n        relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                      or_circ->is_first_hop ?\n                                        END_STREAM_REASON_TORPROTOCOL :\n                                        END_STREAM_REASON_MISC,\n                                      NULL);\n        tor_free(address);\n        return 0;\n      }\n    }\n  } else if (rh.command == RELAY_COMMAND_BEGIN_DIR) {\n    if (!directory_permits_begindir_requests(options) ||\n        circ->purpose != CIRCUIT_PURPOSE_OR) {\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                  END_STREAM_REASON_NOTDIRECTORY, layer_hint);\n      return 0;\n    }\n    /* Make sure to get the 'real' address of the previous hop: the\n     * caller might want to know whether the remote IP address has changed,\n     * and we might already have corrected base_.addr[ess] for the relay's\n     * canonical IP address. */\n    if (or_circ && or_circ->p_chan)\n      address = tor_strdup(channel_get_actual_remote_address(or_circ->p_chan));\n    else\n      address = tor_strdup(\"127.0.0.1\");\n    port = 1; /* XXXX This value is never actually used anywhere, and there\n               * isn't \"really\" a connection here.  But we\n               * need to set it to something nonzero. */\n  } else {\n    log_warn(LD_BUG, \"Got an unexpected command %d\", (int)rh.command);\n    relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                  END_STREAM_REASON_INTERNAL, layer_hint);\n    return 0;\n  }\n\n  if (! options->IPv6Exit) {\n    /* I don't care if you prefer IPv6; I can't give you any. */\n    bcell.flags &= ~BEGIN_FLAG_IPV6_PREFERRED;\n    /* If you don't want IPv4, I can't help. */\n    if (bcell.flags & BEGIN_FLAG_IPV4_NOT_OK) {\n      tor_free(address);\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                    END_STREAM_REASON_EXITPOLICY, layer_hint);\n      return 0;\n    }\n  }\n\n  log_debug(LD_EXIT,\"Creating new exit connection.\");\n  /* The 'AF_INET' here is temporary; we might need to change it later in\n   * connection_exit_connect(). */\n  n_stream = edge_connection_new(CONN_TYPE_EXIT, AF_INET);\n\n  /* Remember the tunneled request ID in the new edge connection, so that\n   * we can measure download times. */\n  n_stream->dirreq_id = circ->dirreq_id;\n\n  n_stream->base_.purpose = EXIT_PURPOSE_CONNECT;\n  n_stream->begincell_flags = bcell.flags;\n  n_stream->stream_id = rh.stream_id;\n  n_stream->base_.port = port;\n  /* leave n_stream->s at -1, because it's not yet valid */\n  n_stream->package_window = STREAMWINDOW_START;\n  n_stream->deliver_window = STREAMWINDOW_START;\n\n  if (circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED) {\n    tor_assert(origin_circ);\n    log_info(LD_REND,\"begin is for rendezvous. configuring stream.\");\n    n_stream->base_.address = tor_strdup(\"(rendezvous)\");\n    n_stream->base_.state = EXIT_CONN_STATE_CONNECTING;\n    n_stream->rend_data = rend_data_dup(origin_circ->rend_data);\n    tor_assert(connection_edge_is_rendezvous_stream(n_stream));\n    assert_circuit_ok(circ);\n\n    const int r = rend_service_set_connection_addr_port(n_stream, origin_circ);\n    if (r < 0) {\n      log_info(LD_REND,\"Didn't find rendezvous service (port %d)\",\n               n_stream->base_.port);\n      /* Send back reason DONE because we want to make hidden service port\n       * scanning harder thus instead of returning that the exit policy\n       * didn't match, which makes it obvious that the port is closed,\n       * return DONE and kill the circuit. That way, a user (malicious or\n       * not) needs one circuit per bad port unless it matches the policy of\n       * the hidden service. */\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                    END_STREAM_REASON_DONE,\n                                    layer_hint);\n      connection_free(TO_CONN(n_stream));\n      tor_free(address);\n\n      /* Drop the circuit here since it might be someone deliberately\n       * scanning the hidden service ports. Note that this mitigates port\n       * scanning by adding more work on the attacker side to successfully\n       * scan but does not fully solve it. */\n      if (r < -1)\n        return END_CIRC_AT_ORIGIN;\n      else\n        return 0;\n    }\n    assert_circuit_ok(circ);\n    log_debug(LD_REND,\"Finished assigning addr/port\");\n    n_stream->cpath_layer = origin_circ->cpath->prev; /* link it */\n\n    /* add it into the linked list of p_streams on this circuit */\n    n_stream->next_stream = origin_circ->p_streams;\n    n_stream->on_circuit = circ;\n    origin_circ->p_streams = n_stream;\n    assert_circuit_ok(circ);\n\n    origin_circ->rend_data->nr_streams++;\n\n    connection_exit_connect(n_stream);\n\n    /* For path bias: This circuit was used successfully */\n    pathbias_mark_use_success(origin_circ);\n\n    tor_free(address);\n    return 0;\n  }\n  tor_strlower(address);\n  n_stream->base_.address = address;\n  n_stream->base_.state = EXIT_CONN_STATE_RESOLVEFAILED;\n  /* default to failed, change in dns_resolve if it turns out not to fail */\n\n  if (we_are_hibernating()) {\n    relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                  END_STREAM_REASON_HIBERNATING, NULL);\n    connection_free(TO_CONN(n_stream));\n    return 0;\n  }\n\n  n_stream->on_circuit = circ;\n\n  if (rh.command == RELAY_COMMAND_BEGIN_DIR) {\n    tor_addr_t tmp_addr;\n    tor_assert(or_circ);\n    if (or_circ->p_chan &&\n        channel_get_addr_if_possible(or_circ->p_chan, &tmp_addr)) {\n      tor_addr_copy(&n_stream->base_.addr, &tmp_addr);\n    }\n    return connection_exit_connect_dir(n_stream);\n  }\n\n  log_debug(LD_EXIT,\"about to start the dns_resolve().\");\n\n  /* send it off to the gethostbyname farm */\n  switch (dns_resolve(n_stream)) {\n    case 1: /* resolve worked; now n_stream is attached to circ. */\n      assert_circuit_ok(circ);\n      log_debug(LD_EXIT,\"about to call connection_exit_connect().\");\n      connection_exit_connect(n_stream);\n      return 0;\n    case -1: /* resolve failed */\n      relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                    END_STREAM_REASON_RESOLVEFAILED, NULL);\n      /* n_stream got freed. don't touch it. */\n      break;\n    case 0: /* resolve added to pending list */\n      assert_circuit_ok(circ);\n      break;\n  }\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,14 +6,21 @@\n   char *address = NULL;\n   uint16_t port = 0;\n   or_circuit_t *or_circ = NULL;\n+  origin_circuit_t *origin_circ = NULL;\n+  crypt_path_t *layer_hint = NULL;\n   const or_options_t *options = get_options();\n   begin_cell_t bcell;\n   int rv;\n   uint8_t end_reason=0;\n \n   assert_circuit_ok(circ);\n-  if (!CIRCUIT_IS_ORIGIN(circ))\n+  if (!CIRCUIT_IS_ORIGIN(circ)) {\n     or_circ = TO_OR_CIRCUIT(circ);\n+  } else {\n+    tor_assert(circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED);\n+    origin_circ = TO_ORIGIN_CIRCUIT(circ);\n+    layer_hint = origin_circ->cpath->prev;\n+  }\n \n   relay_header_unpack(&rh, cell->payload);\n   if (rh.length > RELAY_PAYLOAD_SIZE)\n@@ -38,7 +45,7 @@\n     return -END_CIRC_REASON_TORPROTOCOL;\n   } else if (rv == -1) {\n     tor_free(bcell.address);\n-    relay_send_end_cell_from_edge(rh.stream_id, circ, end_reason, NULL);\n+    relay_send_end_cell_from_edge(rh.stream_id, circ, end_reason, layer_hint);\n     return 0;\n   }\n \n@@ -75,7 +82,7 @@\n     if (!directory_permits_begindir_requests(options) ||\n         circ->purpose != CIRCUIT_PURPOSE_OR) {\n       relay_send_end_cell_from_edge(rh.stream_id, circ,\n-                                    END_STREAM_REASON_NOTDIRECTORY, NULL);\n+                                  END_STREAM_REASON_NOTDIRECTORY, layer_hint);\n       return 0;\n     }\n     /* Make sure to get the 'real' address of the previous hop: the\n@@ -92,7 +99,7 @@\n   } else {\n     log_warn(LD_BUG, \"Got an unexpected command %d\", (int)rh.command);\n     relay_send_end_cell_from_edge(rh.stream_id, circ,\n-                                  END_STREAM_REASON_INTERNAL, NULL);\n+                                  END_STREAM_REASON_INTERNAL, layer_hint);\n     return 0;\n   }\n \n@@ -103,7 +110,7 @@\n     if (bcell.flags & BEGIN_FLAG_IPV4_NOT_OK) {\n       tor_free(address);\n       relay_send_end_cell_from_edge(rh.stream_id, circ,\n-                                    END_STREAM_REASON_EXITPOLICY, NULL);\n+                                    END_STREAM_REASON_EXITPOLICY, layer_hint);\n       return 0;\n     }\n   }\n@@ -126,7 +133,7 @@\n   n_stream->deliver_window = STREAMWINDOW_START;\n \n   if (circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED) {\n-    origin_circuit_t *origin_circ = TO_ORIGIN_CIRCUIT(circ);\n+    tor_assert(origin_circ);\n     log_info(LD_REND,\"begin is for rendezvous. configuring stream.\");\n     n_stream->base_.address = tor_strdup(\"(rendezvous)\");\n     n_stream->base_.state = EXIT_CONN_STATE_CONNECTING;\n@@ -146,7 +153,7 @@\n        * the hidden service. */\n       relay_send_end_cell_from_edge(rh.stream_id, circ,\n                                     END_STREAM_REASON_DONE,\n-                                    origin_circ->cpath->prev);\n+                                    layer_hint);\n       connection_free(TO_CONN(n_stream));\n       tor_free(address);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "  if (!CIRCUIT_IS_ORIGIN(circ))",
                "    relay_send_end_cell_from_edge(rh.stream_id, circ, end_reason, NULL);",
                "                                    END_STREAM_REASON_NOTDIRECTORY, NULL);",
                "                                  END_STREAM_REASON_INTERNAL, NULL);",
                "                                    END_STREAM_REASON_EXITPOLICY, NULL);",
                "    origin_circuit_t *origin_circ = TO_ORIGIN_CIRCUIT(circ);",
                "                                    origin_circ->cpath->prev);"
            ],
            "added_lines": [
                "  origin_circuit_t *origin_circ = NULL;",
                "  crypt_path_t *layer_hint = NULL;",
                "  if (!CIRCUIT_IS_ORIGIN(circ)) {",
                "  } else {",
                "    tor_assert(circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED);",
                "    origin_circ = TO_ORIGIN_CIRCUIT(circ);",
                "    layer_hint = origin_circ->cpath->prev;",
                "  }",
                "    relay_send_end_cell_from_edge(rh.stream_id, circ, end_reason, layer_hint);",
                "                                  END_STREAM_REASON_NOTDIRECTORY, layer_hint);",
                "                                  END_STREAM_REASON_INTERNAL, layer_hint);",
                "                                    END_STREAM_REASON_EXITPOLICY, layer_hint);",
                "    tor_assert(origin_circ);",
                "                                    layer_hint);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-0376",
        "func_name": "torproject/tor/connection_edge_process_relay_cell",
        "description": "The hidden-service feature in Tor before 0.3.0.8 allows a denial of service (assertion failure and daemon exit) in the connection_edge_process_relay_cell function via a BEGIN_DIR cell on a rendezvous circuit.",
        "git_url": "https://github.com/torproject/tor/commit/56a7c5bc15e0447203a491c1ee37de9939ad1dcd",
        "commit_title": "TROVE-2017-005: Fix assertion failure in connection_edge_process_relay_cell",
        "commit_text": " On an hidden service rendezvous circuit, a BEGIN_DIR could be sent (maliciously) which would trigger a tor_assert() because connection_edge_process_relay_cell() thought that the circuit is an or_circuit_t but is an origin circuit in reality.  Fixes #22494 ",
        "func_before": "static int\nconnection_edge_process_relay_cell(cell_t *cell, circuit_t *circ,\n                                   edge_connection_t *conn,\n                                   crypt_path_t *layer_hint)\n{\n  static int num_seen=0;\n  relay_header_t rh;\n  unsigned domain = layer_hint?LD_APP:LD_EXIT;\n  int reason;\n  int optimistic_data = 0; /* Set to 1 if we receive data on a stream\n                            * that's in the EXIT_CONN_STATE_RESOLVING\n                            * or EXIT_CONN_STATE_CONNECTING states. */\n\n  tor_assert(cell);\n  tor_assert(circ);\n\n  relay_header_unpack(&rh, cell->payload);\n//  log_fn(LOG_DEBUG,\"command %d stream %d\", rh.command, rh.stream_id);\n  num_seen++;\n  log_debug(domain, \"Now seen %d relay cells here (command %d, stream %d).\",\n            num_seen, rh.command, rh.stream_id);\n\n  if (rh.length > RELAY_PAYLOAD_SIZE) {\n    log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n           \"Relay cell length field too long. Closing circuit.\");\n    return - END_CIRC_REASON_TORPROTOCOL;\n  }\n\n  if (rh.stream_id == 0) {\n    switch (rh.command) {\n      case RELAY_COMMAND_BEGIN:\n      case RELAY_COMMAND_CONNECTED:\n      case RELAY_COMMAND_DATA:\n      case RELAY_COMMAND_END:\n      case RELAY_COMMAND_RESOLVE:\n      case RELAY_COMMAND_RESOLVED:\n      case RELAY_COMMAND_BEGIN_DIR:\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL, \"Relay command %d with zero \"\n               \"stream_id. Dropping.\", (int)rh.command);\n        return 0;\n      default:\n        ;\n    }\n  }\n\n  /* either conn is NULL, in which case we've got a control cell, or else\n   * conn points to the recognized stream. */\n\n  if (conn && !connection_state_is_open(TO_CONN(conn))) {\n    if (conn->base_.type == CONN_TYPE_EXIT &&\n        (conn->base_.state == EXIT_CONN_STATE_CONNECTING ||\n         conn->base_.state == EXIT_CONN_STATE_RESOLVING) &&\n        rh.command == RELAY_COMMAND_DATA) {\n      /* Allow DATA cells to be delivered to an exit node in state\n       * EXIT_CONN_STATE_CONNECTING or EXIT_CONN_STATE_RESOLVING.\n       * This speeds up HTTP, for example. */\n      optimistic_data = 1;\n    } else {\n      return connection_edge_process_relay_cell_not_open(\n               &rh, cell, circ, conn, layer_hint);\n    }\n  }\n\n  switch (rh.command) {\n    case RELAY_COMMAND_DROP:\n//      log_info(domain,\"Got a relay-level padding cell. Dropping.\");\n      return 0;\n    case RELAY_COMMAND_BEGIN:\n    case RELAY_COMMAND_BEGIN_DIR:\n      if (layer_hint &&\n          circ->purpose != CIRCUIT_PURPOSE_S_REND_JOINED) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"Relay begin request unsupported at AP. Dropping.\");\n        return 0;\n      }\n      if (circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED &&\n          layer_hint != TO_ORIGIN_CIRCUIT(circ)->cpath->prev) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"Relay begin request to Hidden Service \"\n               \"from intermediary node. Dropping.\");\n        return 0;\n      }\n      if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"Begin cell for known stream. Dropping.\");\n        return 0;\n      }\n      if (rh.command == RELAY_COMMAND_BEGIN_DIR) {\n        /* Assign this circuit and its app-ward OR connection a unique ID,\n         * so that we can measure download times. The local edge and dir\n         * connection will be assigned the same ID when they are created\n         * and linked. */\n        static uint64_t next_id = 0;\n        circ->dirreq_id = ++next_id;\n        TO_OR_CIRCUIT(circ)->p_chan->dirreq_id = circ->dirreq_id;\n      }\n\n      return connection_exit_begin_conn(cell, circ);\n    case RELAY_COMMAND_DATA:\n      ++stats_n_data_cells_received;\n      if (( layer_hint && --layer_hint->deliver_window < 0) ||\n          (!layer_hint && --circ->deliver_window < 0)) {\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"(relay data) circ deliver_window below 0. Killing.\");\n        if (conn) {\n          /* XXXX Do we actually need to do this?  Will killing the circuit\n           * not send an END and mark the stream for close as appropriate? */\n          connection_edge_end(conn, END_STREAM_REASON_TORPROTOCOL);\n          connection_mark_for_close(TO_CONN(conn));\n        }\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n      log_debug(domain,\"circ deliver_window now %d.\", layer_hint ?\n                layer_hint->deliver_window : circ->deliver_window);\n\n      circuit_consider_sending_sendme(circ, layer_hint);\n\n      if (!conn) {\n        log_info(domain,\"data cell dropped, unknown stream (streamid %d).\",\n                 rh.stream_id);\n        return 0;\n      }\n\n      if (--conn->deliver_window < 0) { /* is it below 0 after decrement? */\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"(relay data) conn deliver_window below 0. Killing.\");\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n\n      stats_n_data_bytes_received += rh.length;\n      connection_write_to_buf((char*)(cell->payload + RELAY_HEADER_SIZE),\n                              rh.length, TO_CONN(conn));\n\n      if (!optimistic_data) {\n        /* Only send a SENDME if we're not getting optimistic data; otherwise\n         * a SENDME could arrive before the CONNECTED.\n         */\n        connection_edge_consider_sending_sendme(conn);\n      }\n\n      return 0;\n    case RELAY_COMMAND_END:\n      reason = rh.length > 0 ?\n        get_uint8(cell->payload+RELAY_HEADER_SIZE) : END_STREAM_REASON_MISC;\n      if (!conn) {\n        log_info(domain,\"end cell (%s) dropped, unknown stream.\",\n                 stream_end_reason_to_string(reason));\n        return 0;\n      }\n/* XXX add to this log_fn the exit node's nickname? */\n      log_info(domain,TOR_SOCKET_T_FORMAT\": end cell (%s) for stream %d. \"\n               \"Removing stream.\",\n               conn->base_.s,\n               stream_end_reason_to_string(reason),\n               conn->stream_id);\n      if (conn->base_.type == CONN_TYPE_AP) {\n        entry_connection_t *entry_conn = EDGE_TO_ENTRY_CONN(conn);\n        if (entry_conn->socks_request &&\n            !entry_conn->socks_request->has_finished)\n          log_warn(LD_BUG,\n                   \"open stream hasn't sent socks answer yet? Closing.\");\n      }\n      /* We just *got* an end; no reason to send one. */\n      conn->edge_has_sent_end = 1;\n      if (!conn->end_reason)\n        conn->end_reason = reason | END_STREAM_REASON_FLAG_REMOTE;\n      if (!conn->base_.marked_for_close) {\n        /* only mark it if not already marked. it's possible to\n         * get the 'end' right around when the client hangs up on us. */\n        connection_mark_and_flush(TO_CONN(conn));\n      }\n      return 0;\n    case RELAY_COMMAND_EXTEND:\n    case RELAY_COMMAND_EXTEND2: {\n      static uint64_t total_n_extend=0, total_nonearly=0;\n      total_n_extend++;\n      if (rh.stream_id) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"'extend' cell received for non-zero stream. Dropping.\");\n        return 0;\n      }\n      if (cell->command != CELL_RELAY_EARLY &&\n          !networkstatus_get_param(NULL,\"AllowNonearlyExtend\",0,0,1)) {\n#define EARLY_WARNING_INTERVAL 3600\n        static ratelim_t early_warning_limit =\n          RATELIM_INIT(EARLY_WARNING_INTERVAL);\n        char *m;\n        if (cell->command == CELL_RELAY) {\n          ++total_nonearly;\n          if ((m = rate_limit_log(&early_warning_limit, approx_time()))) {\n            double percentage = ((double)total_nonearly)/total_n_extend;\n            percentage *= 100;\n            log_fn(LOG_PROTOCOL_WARN, domain, \"EXTEND cell received, \"\n                   \"but not via RELAY_EARLY. Dropping.%s\", m);\n            log_fn(LOG_PROTOCOL_WARN, domain, \"  (We have dropped %.02f%% of \"\n                   \"all EXTEND cells for this reason)\", percentage);\n            tor_free(m);\n          }\n        } else {\n          log_fn(LOG_WARN, domain,\n                 \"EXTEND cell received, in a cell with type %d! Dropping.\",\n                 cell->command);\n        }\n        return 0;\n      }\n      return circuit_extend(cell, circ);\n    }\n    case RELAY_COMMAND_EXTENDED:\n    case RELAY_COMMAND_EXTENDED2:\n      if (!layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"'extended' unsupported at non-origin. Dropping.\");\n        return 0;\n      }\n      log_debug(domain,\"Got an extended cell! Yay.\");\n      {\n        extended_cell_t extended_cell;\n        if (extended_cell_parse(&extended_cell, rh.command,\n                        (const uint8_t*)cell->payload+RELAY_HEADER_SIZE,\n                        rh.length)<0) {\n          log_warn(LD_PROTOCOL,\n                   \"Can't parse EXTENDED cell; killing circuit.\");\n          return -END_CIRC_REASON_TORPROTOCOL;\n        }\n        if ((reason = circuit_finish_handshake(TO_ORIGIN_CIRCUIT(circ),\n                                         &extended_cell.created_cell)) < 0) {\n          log_warn(domain,\"circuit_finish_handshake failed.\");\n          return reason;\n        }\n      }\n      if ((reason=circuit_send_next_onion_skin(TO_ORIGIN_CIRCUIT(circ)))<0) {\n        log_info(domain,\"circuit_send_next_onion_skin() failed.\");\n        return reason;\n      }\n      return 0;\n    case RELAY_COMMAND_TRUNCATE:\n      if (layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"'truncate' unsupported at origin. Dropping.\");\n        return 0;\n      }\n      if (circ->n_hop) {\n        if (circ->n_chan)\n          log_warn(LD_BUG, \"n_chan and n_hop set on the same circuit!\");\n        extend_info_free(circ->n_hop);\n        circ->n_hop = NULL;\n        tor_free(circ->n_chan_create_cell);\n        circuit_set_state(circ, CIRCUIT_STATE_OPEN);\n      }\n      if (circ->n_chan) {\n        uint8_t trunc_reason = get_uint8(cell->payload + RELAY_HEADER_SIZE);\n        circuit_clear_cell_queue(circ, circ->n_chan);\n        channel_send_destroy(circ->n_circ_id, circ->n_chan,\n                             trunc_reason);\n        circuit_set_n_circid_chan(circ, 0, NULL);\n      }\n      log_debug(LD_EXIT, \"Processed 'truncate', replying.\");\n      {\n        char payload[1];\n        payload[0] = (char)END_CIRC_REASON_REQUESTED;\n        relay_send_command_from_edge(0, circ, RELAY_COMMAND_TRUNCATED,\n                                     payload, sizeof(payload), NULL);\n      }\n      return 0;\n    case RELAY_COMMAND_TRUNCATED:\n      if (!layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_EXIT,\n               \"'truncated' unsupported at non-origin. Dropping.\");\n        return 0;\n      }\n      circuit_truncated(TO_ORIGIN_CIRCUIT(circ), layer_hint,\n                        get_uint8(cell->payload + RELAY_HEADER_SIZE));\n      return 0;\n    case RELAY_COMMAND_CONNECTED:\n      if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"'connected' unsupported while open. Closing circ.\");\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n      log_info(domain,\n               \"'connected' received, no conn attached anymore. Ignoring.\");\n      return 0;\n    case RELAY_COMMAND_SENDME:\n      if (!rh.stream_id) {\n        if (layer_hint) {\n          if (layer_hint->package_window + CIRCWINDOW_INCREMENT >\n                CIRCWINDOW_START_MAX) {\n            log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n                   \"Unexpected sendme cell from exit relay. \"\n                   \"Closing circ.\");\n            return -END_CIRC_REASON_TORPROTOCOL;\n          }\n          layer_hint->package_window += CIRCWINDOW_INCREMENT;\n          log_debug(LD_APP,\"circ-level sendme at origin, packagewindow %d.\",\n                    layer_hint->package_window);\n          circuit_resume_edge_reading(circ, layer_hint);\n        } else {\n          if (circ->package_window + CIRCWINDOW_INCREMENT >\n                CIRCWINDOW_START_MAX) {\n            log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n                   \"Unexpected sendme cell from client. \"\n                   \"Closing circ (window %d).\",\n                   circ->package_window);\n            return -END_CIRC_REASON_TORPROTOCOL;\n          }\n          circ->package_window += CIRCWINDOW_INCREMENT;\n          log_debug(LD_APP,\n                    \"circ-level sendme at non-origin, packagewindow %d.\",\n                    circ->package_window);\n          circuit_resume_edge_reading(circ, layer_hint);\n        }\n        return 0;\n      }\n      if (!conn) {\n        log_info(domain,\"sendme cell dropped, unknown stream (streamid %d).\",\n                 rh.stream_id);\n        return 0;\n      }\n      conn->package_window += STREAMWINDOW_INCREMENT;\n      log_debug(domain,\"stream-level sendme, packagewindow now %d.\",\n                conn->package_window);\n      if (circuit_queue_streams_are_blocked(circ)) {\n        /* Still waiting for queue to flush; don't touch conn */\n        return 0;\n      }\n      connection_start_reading(TO_CONN(conn));\n      /* handle whatever might still be on the inbuf */\n      if (connection_edge_package_raw_inbuf(conn, 1, NULL) < 0) {\n        /* (We already sent an end cell if possible) */\n        connection_mark_for_close(TO_CONN(conn));\n        return 0;\n      }\n      return 0;\n    case RELAY_COMMAND_RESOLVE:\n      if (layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"resolve request unsupported at AP; dropping.\");\n        return 0;\n      } else if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"resolve request for known stream; dropping.\");\n        return 0;\n      } else if (circ->purpose != CIRCUIT_PURPOSE_OR) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"resolve request on circ with purpose %d; dropping\",\n               circ->purpose);\n        return 0;\n      }\n      connection_exit_begin_resolve(cell, TO_OR_CIRCUIT(circ));\n      return 0;\n    case RELAY_COMMAND_RESOLVED:\n      if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"'resolved' unsupported while open. Closing circ.\");\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n      log_info(domain,\n               \"'resolved' received, no conn attached anymore. Ignoring.\");\n      return 0;\n    case RELAY_COMMAND_ESTABLISH_INTRO:\n    case RELAY_COMMAND_ESTABLISH_RENDEZVOUS:\n    case RELAY_COMMAND_INTRODUCE1:\n    case RELAY_COMMAND_INTRODUCE2:\n    case RELAY_COMMAND_INTRODUCE_ACK:\n    case RELAY_COMMAND_RENDEZVOUS1:\n    case RELAY_COMMAND_RENDEZVOUS2:\n    case RELAY_COMMAND_INTRO_ESTABLISHED:\n    case RELAY_COMMAND_RENDEZVOUS_ESTABLISHED:\n      rend_process_relay_cell(circ, layer_hint,\n                              rh.command, rh.length,\n                              cell->payload+RELAY_HEADER_SIZE);\n      return 0;\n  }\n  log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n         \"Received unknown relay command %d. Perhaps the other side is using \"\n         \"a newer version of Tor? Dropping.\",\n         rh.command);\n  return 0; /* for forward compatibility, don't kill the circuit */\n}",
        "func": "static int\nconnection_edge_process_relay_cell(cell_t *cell, circuit_t *circ,\n                                   edge_connection_t *conn,\n                                   crypt_path_t *layer_hint)\n{\n  static int num_seen=0;\n  relay_header_t rh;\n  unsigned domain = layer_hint?LD_APP:LD_EXIT;\n  int reason;\n  int optimistic_data = 0; /* Set to 1 if we receive data on a stream\n                            * that's in the EXIT_CONN_STATE_RESOLVING\n                            * or EXIT_CONN_STATE_CONNECTING states. */\n\n  tor_assert(cell);\n  tor_assert(circ);\n\n  relay_header_unpack(&rh, cell->payload);\n//  log_fn(LOG_DEBUG,\"command %d stream %d\", rh.command, rh.stream_id);\n  num_seen++;\n  log_debug(domain, \"Now seen %d relay cells here (command %d, stream %d).\",\n            num_seen, rh.command, rh.stream_id);\n\n  if (rh.length > RELAY_PAYLOAD_SIZE) {\n    log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n           \"Relay cell length field too long. Closing circuit.\");\n    return - END_CIRC_REASON_TORPROTOCOL;\n  }\n\n  if (rh.stream_id == 0) {\n    switch (rh.command) {\n      case RELAY_COMMAND_BEGIN:\n      case RELAY_COMMAND_CONNECTED:\n      case RELAY_COMMAND_DATA:\n      case RELAY_COMMAND_END:\n      case RELAY_COMMAND_RESOLVE:\n      case RELAY_COMMAND_RESOLVED:\n      case RELAY_COMMAND_BEGIN_DIR:\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL, \"Relay command %d with zero \"\n               \"stream_id. Dropping.\", (int)rh.command);\n        return 0;\n      default:\n        ;\n    }\n  }\n\n  /* either conn is NULL, in which case we've got a control cell, or else\n   * conn points to the recognized stream. */\n\n  if (conn && !connection_state_is_open(TO_CONN(conn))) {\n    if (conn->base_.type == CONN_TYPE_EXIT &&\n        (conn->base_.state == EXIT_CONN_STATE_CONNECTING ||\n         conn->base_.state == EXIT_CONN_STATE_RESOLVING) &&\n        rh.command == RELAY_COMMAND_DATA) {\n      /* Allow DATA cells to be delivered to an exit node in state\n       * EXIT_CONN_STATE_CONNECTING or EXIT_CONN_STATE_RESOLVING.\n       * This speeds up HTTP, for example. */\n      optimistic_data = 1;\n    } else {\n      return connection_edge_process_relay_cell_not_open(\n               &rh, cell, circ, conn, layer_hint);\n    }\n  }\n\n  switch (rh.command) {\n    case RELAY_COMMAND_DROP:\n//      log_info(domain,\"Got a relay-level padding cell. Dropping.\");\n      return 0;\n    case RELAY_COMMAND_BEGIN:\n    case RELAY_COMMAND_BEGIN_DIR:\n      if (layer_hint &&\n          circ->purpose != CIRCUIT_PURPOSE_S_REND_JOINED) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"Relay begin request unsupported at AP. Dropping.\");\n        return 0;\n      }\n      if (circ->purpose == CIRCUIT_PURPOSE_S_REND_JOINED &&\n          layer_hint != TO_ORIGIN_CIRCUIT(circ)->cpath->prev) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"Relay begin request to Hidden Service \"\n               \"from intermediary node. Dropping.\");\n        return 0;\n      }\n      if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"Begin cell for known stream. Dropping.\");\n        return 0;\n      }\n      if (rh.command == RELAY_COMMAND_BEGIN_DIR &&\n          circ->purpose != CIRCUIT_PURPOSE_S_REND_JOINED) {\n        /* Assign this circuit and its app-ward OR connection a unique ID,\n         * so that we can measure download times. The local edge and dir\n         * connection will be assigned the same ID when they are created\n         * and linked. */\n        static uint64_t next_id = 0;\n        circ->dirreq_id = ++next_id;\n        TO_OR_CIRCUIT(circ)->p_chan->dirreq_id = circ->dirreq_id;\n      }\n\n      return connection_exit_begin_conn(cell, circ);\n    case RELAY_COMMAND_DATA:\n      ++stats_n_data_cells_received;\n      if (( layer_hint && --layer_hint->deliver_window < 0) ||\n          (!layer_hint && --circ->deliver_window < 0)) {\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"(relay data) circ deliver_window below 0. Killing.\");\n        if (conn) {\n          /* XXXX Do we actually need to do this?  Will killing the circuit\n           * not send an END and mark the stream for close as appropriate? */\n          connection_edge_end(conn, END_STREAM_REASON_TORPROTOCOL);\n          connection_mark_for_close(TO_CONN(conn));\n        }\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n      log_debug(domain,\"circ deliver_window now %d.\", layer_hint ?\n                layer_hint->deliver_window : circ->deliver_window);\n\n      circuit_consider_sending_sendme(circ, layer_hint);\n\n      if (!conn) {\n        log_info(domain,\"data cell dropped, unknown stream (streamid %d).\",\n                 rh.stream_id);\n        return 0;\n      }\n\n      if (--conn->deliver_window < 0) { /* is it below 0 after decrement? */\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"(relay data) conn deliver_window below 0. Killing.\");\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n\n      stats_n_data_bytes_received += rh.length;\n      connection_write_to_buf((char*)(cell->payload + RELAY_HEADER_SIZE),\n                              rh.length, TO_CONN(conn));\n\n      if (!optimistic_data) {\n        /* Only send a SENDME if we're not getting optimistic data; otherwise\n         * a SENDME could arrive before the CONNECTED.\n         */\n        connection_edge_consider_sending_sendme(conn);\n      }\n\n      return 0;\n    case RELAY_COMMAND_END:\n      reason = rh.length > 0 ?\n        get_uint8(cell->payload+RELAY_HEADER_SIZE) : END_STREAM_REASON_MISC;\n      if (!conn) {\n        log_info(domain,\"end cell (%s) dropped, unknown stream.\",\n                 stream_end_reason_to_string(reason));\n        return 0;\n      }\n/* XXX add to this log_fn the exit node's nickname? */\n      log_info(domain,TOR_SOCKET_T_FORMAT\": end cell (%s) for stream %d. \"\n               \"Removing stream.\",\n               conn->base_.s,\n               stream_end_reason_to_string(reason),\n               conn->stream_id);\n      if (conn->base_.type == CONN_TYPE_AP) {\n        entry_connection_t *entry_conn = EDGE_TO_ENTRY_CONN(conn);\n        if (entry_conn->socks_request &&\n            !entry_conn->socks_request->has_finished)\n          log_warn(LD_BUG,\n                   \"open stream hasn't sent socks answer yet? Closing.\");\n      }\n      /* We just *got* an end; no reason to send one. */\n      conn->edge_has_sent_end = 1;\n      if (!conn->end_reason)\n        conn->end_reason = reason | END_STREAM_REASON_FLAG_REMOTE;\n      if (!conn->base_.marked_for_close) {\n        /* only mark it if not already marked. it's possible to\n         * get the 'end' right around when the client hangs up on us. */\n        connection_mark_and_flush(TO_CONN(conn));\n      }\n      return 0;\n    case RELAY_COMMAND_EXTEND:\n    case RELAY_COMMAND_EXTEND2: {\n      static uint64_t total_n_extend=0, total_nonearly=0;\n      total_n_extend++;\n      if (rh.stream_id) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"'extend' cell received for non-zero stream. Dropping.\");\n        return 0;\n      }\n      if (cell->command != CELL_RELAY_EARLY &&\n          !networkstatus_get_param(NULL,\"AllowNonearlyExtend\",0,0,1)) {\n#define EARLY_WARNING_INTERVAL 3600\n        static ratelim_t early_warning_limit =\n          RATELIM_INIT(EARLY_WARNING_INTERVAL);\n        char *m;\n        if (cell->command == CELL_RELAY) {\n          ++total_nonearly;\n          if ((m = rate_limit_log(&early_warning_limit, approx_time()))) {\n            double percentage = ((double)total_nonearly)/total_n_extend;\n            percentage *= 100;\n            log_fn(LOG_PROTOCOL_WARN, domain, \"EXTEND cell received, \"\n                   \"but not via RELAY_EARLY. Dropping.%s\", m);\n            log_fn(LOG_PROTOCOL_WARN, domain, \"  (We have dropped %.02f%% of \"\n                   \"all EXTEND cells for this reason)\", percentage);\n            tor_free(m);\n          }\n        } else {\n          log_fn(LOG_WARN, domain,\n                 \"EXTEND cell received, in a cell with type %d! Dropping.\",\n                 cell->command);\n        }\n        return 0;\n      }\n      return circuit_extend(cell, circ);\n    }\n    case RELAY_COMMAND_EXTENDED:\n    case RELAY_COMMAND_EXTENDED2:\n      if (!layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"'extended' unsupported at non-origin. Dropping.\");\n        return 0;\n      }\n      log_debug(domain,\"Got an extended cell! Yay.\");\n      {\n        extended_cell_t extended_cell;\n        if (extended_cell_parse(&extended_cell, rh.command,\n                        (const uint8_t*)cell->payload+RELAY_HEADER_SIZE,\n                        rh.length)<0) {\n          log_warn(LD_PROTOCOL,\n                   \"Can't parse EXTENDED cell; killing circuit.\");\n          return -END_CIRC_REASON_TORPROTOCOL;\n        }\n        if ((reason = circuit_finish_handshake(TO_ORIGIN_CIRCUIT(circ),\n                                         &extended_cell.created_cell)) < 0) {\n          log_warn(domain,\"circuit_finish_handshake failed.\");\n          return reason;\n        }\n      }\n      if ((reason=circuit_send_next_onion_skin(TO_ORIGIN_CIRCUIT(circ)))<0) {\n        log_info(domain,\"circuit_send_next_onion_skin() failed.\");\n        return reason;\n      }\n      return 0;\n    case RELAY_COMMAND_TRUNCATE:\n      if (layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"'truncate' unsupported at origin. Dropping.\");\n        return 0;\n      }\n      if (circ->n_hop) {\n        if (circ->n_chan)\n          log_warn(LD_BUG, \"n_chan and n_hop set on the same circuit!\");\n        extend_info_free(circ->n_hop);\n        circ->n_hop = NULL;\n        tor_free(circ->n_chan_create_cell);\n        circuit_set_state(circ, CIRCUIT_STATE_OPEN);\n      }\n      if (circ->n_chan) {\n        uint8_t trunc_reason = get_uint8(cell->payload + RELAY_HEADER_SIZE);\n        circuit_clear_cell_queue(circ, circ->n_chan);\n        channel_send_destroy(circ->n_circ_id, circ->n_chan,\n                             trunc_reason);\n        circuit_set_n_circid_chan(circ, 0, NULL);\n      }\n      log_debug(LD_EXIT, \"Processed 'truncate', replying.\");\n      {\n        char payload[1];\n        payload[0] = (char)END_CIRC_REASON_REQUESTED;\n        relay_send_command_from_edge(0, circ, RELAY_COMMAND_TRUNCATED,\n                                     payload, sizeof(payload), NULL);\n      }\n      return 0;\n    case RELAY_COMMAND_TRUNCATED:\n      if (!layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_EXIT,\n               \"'truncated' unsupported at non-origin. Dropping.\");\n        return 0;\n      }\n      circuit_truncated(TO_ORIGIN_CIRCUIT(circ), layer_hint,\n                        get_uint8(cell->payload + RELAY_HEADER_SIZE));\n      return 0;\n    case RELAY_COMMAND_CONNECTED:\n      if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n               \"'connected' unsupported while open. Closing circ.\");\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n      log_info(domain,\n               \"'connected' received, no conn attached anymore. Ignoring.\");\n      return 0;\n    case RELAY_COMMAND_SENDME:\n      if (!rh.stream_id) {\n        if (layer_hint) {\n          if (layer_hint->package_window + CIRCWINDOW_INCREMENT >\n                CIRCWINDOW_START_MAX) {\n            log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n                   \"Unexpected sendme cell from exit relay. \"\n                   \"Closing circ.\");\n            return -END_CIRC_REASON_TORPROTOCOL;\n          }\n          layer_hint->package_window += CIRCWINDOW_INCREMENT;\n          log_debug(LD_APP,\"circ-level sendme at origin, packagewindow %d.\",\n                    layer_hint->package_window);\n          circuit_resume_edge_reading(circ, layer_hint);\n        } else {\n          if (circ->package_window + CIRCWINDOW_INCREMENT >\n                CIRCWINDOW_START_MAX) {\n            log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n                   \"Unexpected sendme cell from client. \"\n                   \"Closing circ (window %d).\",\n                   circ->package_window);\n            return -END_CIRC_REASON_TORPROTOCOL;\n          }\n          circ->package_window += CIRCWINDOW_INCREMENT;\n          log_debug(LD_APP,\n                    \"circ-level sendme at non-origin, packagewindow %d.\",\n                    circ->package_window);\n          circuit_resume_edge_reading(circ, layer_hint);\n        }\n        return 0;\n      }\n      if (!conn) {\n        log_info(domain,\"sendme cell dropped, unknown stream (streamid %d).\",\n                 rh.stream_id);\n        return 0;\n      }\n      conn->package_window += STREAMWINDOW_INCREMENT;\n      log_debug(domain,\"stream-level sendme, packagewindow now %d.\",\n                conn->package_window);\n      if (circuit_queue_streams_are_blocked(circ)) {\n        /* Still waiting for queue to flush; don't touch conn */\n        return 0;\n      }\n      connection_start_reading(TO_CONN(conn));\n      /* handle whatever might still be on the inbuf */\n      if (connection_edge_package_raw_inbuf(conn, 1, NULL) < 0) {\n        /* (We already sent an end cell if possible) */\n        connection_mark_for_close(TO_CONN(conn));\n        return 0;\n      }\n      return 0;\n    case RELAY_COMMAND_RESOLVE:\n      if (layer_hint) {\n        log_fn(LOG_PROTOCOL_WARN, LD_APP,\n               \"resolve request unsupported at AP; dropping.\");\n        return 0;\n      } else if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"resolve request for known stream; dropping.\");\n        return 0;\n      } else if (circ->purpose != CIRCUIT_PURPOSE_OR) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"resolve request on circ with purpose %d; dropping\",\n               circ->purpose);\n        return 0;\n      }\n      connection_exit_begin_resolve(cell, TO_OR_CIRCUIT(circ));\n      return 0;\n    case RELAY_COMMAND_RESOLVED:\n      if (conn) {\n        log_fn(LOG_PROTOCOL_WARN, domain,\n               \"'resolved' unsupported while open. Closing circ.\");\n        return -END_CIRC_REASON_TORPROTOCOL;\n      }\n      log_info(domain,\n               \"'resolved' received, no conn attached anymore. Ignoring.\");\n      return 0;\n    case RELAY_COMMAND_ESTABLISH_INTRO:\n    case RELAY_COMMAND_ESTABLISH_RENDEZVOUS:\n    case RELAY_COMMAND_INTRODUCE1:\n    case RELAY_COMMAND_INTRODUCE2:\n    case RELAY_COMMAND_INTRODUCE_ACK:\n    case RELAY_COMMAND_RENDEZVOUS1:\n    case RELAY_COMMAND_RENDEZVOUS2:\n    case RELAY_COMMAND_INTRO_ESTABLISHED:\n    case RELAY_COMMAND_RENDEZVOUS_ESTABLISHED:\n      rend_process_relay_cell(circ, layer_hint,\n                              rh.command, rh.length,\n                              cell->payload+RELAY_HEADER_SIZE);\n      return 0;\n  }\n  log_fn(LOG_PROTOCOL_WARN, LD_PROTOCOL,\n         \"Received unknown relay command %d. Perhaps the other side is using \"\n         \"a newer version of Tor? Dropping.\",\n         rh.command);\n  return 0; /* for forward compatibility, don't kill the circuit */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -85,7 +85,8 @@\n                \"Begin cell for known stream. Dropping.\");\n         return 0;\n       }\n-      if (rh.command == RELAY_COMMAND_BEGIN_DIR) {\n+      if (rh.command == RELAY_COMMAND_BEGIN_DIR &&\n+          circ->purpose != CIRCUIT_PURPOSE_S_REND_JOINED) {\n         /* Assign this circuit and its app-ward OR connection a unique ID,\n          * so that we can measure download times. The local edge and dir\n          * connection will be assigned the same ID when they are created",
        "diff_line_info": {
            "deleted_lines": [
                "      if (rh.command == RELAY_COMMAND_BEGIN_DIR) {"
            ],
            "added_lines": [
                "      if (rh.command == RELAY_COMMAND_BEGIN_DIR &&",
                "          circ->purpose != CIRCUIT_PURPOSE_S_REND_JOINED) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9782",
        "func_name": "jasper-software/jasper/jp2_decode",
        "description": "JasPer 2.0.12 allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) via a crafted image, related to the jp2_decode function in libjasper/jp2/jp2_dec.c.",
        "git_url": "https://github.com/jasper-software/jasper/commit/839b1bcf0450ff036c28e8db40a7abf886e02891",
        "commit_title": "jp2_dec: fix `numchans` mixup",
        "commit_text": " When iterating over `dec->cdef->data.cdef.ents`, we need to use its `numchans` variable, not the one in `jp2_dec_t`.  Fixes CVE-2018-19543 Fixes CVE-2017-9782  Closes https://github.com/jasper-maint/jasper/issues/13 Closes https://github.com/jasper-maint/jasper/issues/18 Closes https://github.com/mdadams/jasper/issues/140 Closes https://github.com/mdadams/jasper/issues/182",
        "func_before": "jas_image_t *jp2_decode(jas_stream_t *in, const char *optstr)\n{\n\tjp2_box_t *box;\n\tint found;\n\tjas_image_t *image;\n\tjp2_dec_t *dec;\n\tbool samedtype;\n\tint dtype;\n\tunsigned int i;\n\tjp2_cmap_t *cmapd;\n\tjp2_pclr_t *pclrd;\n\tjp2_cdef_t *cdefd;\n\tunsigned int channo;\n\tint newcmptno;\n\tint_fast32_t *lutents;\n#if 0\n\tjp2_cdefchan_t *cdefent;\n\tint cmptno;\n#endif\n\tjp2_cmapent_t *cmapent;\n\tjas_icchdr_t icchdr;\n\tjas_iccprof_t *iccprof;\n\n\tdec = 0;\n\tbox = 0;\n\timage = 0;\n\n\tJAS_DBGLOG(100, (\"jp2_decode(%p, \\\"%s\\\")\\n\", in, optstr));\n\n\tif (!(dec = jp2_dec_create())) {\n\t\tgoto error;\n\t}\n\n\t/* Get the first box.  This should be a JP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tjas_eprintf(\"error: cannot get box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_JP) {\n\t\tjas_eprintf(\"error: expecting signature box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->data.jp.magic != JP2_JP_MAGIC) {\n\t\tjas_eprintf(\"incorrect magic number\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get the second box.  This should be a FTYP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_FTYP) {\n\t\tjas_eprintf(\"expecting file type box\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get more boxes... */\n\tfound = 0;\n\twhile ((box = jp2_box_get(in))) {\n\t\tif (jas_getdbglevel() >= 1) {\n\t\t\tjas_eprintf(\"got box type %s\\n\", box->info->name);\n\t\t}\n\t\tswitch (box->type) {\n\t\tcase JP2_BOX_JP2C:\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\tcase JP2_BOX_IHDR:\n\t\t\tif (!dec->ihdr) {\n\t\t\t\tdec->ihdr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_BPCC:\n\t\t\tif (!dec->bpcc) {\n\t\t\t\tdec->bpcc = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CDEF:\n\t\t\tif (!dec->cdef) {\n\t\t\t\tdec->cdef = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_PCLR:\n\t\t\tif (!dec->pclr) {\n\t\t\t\tdec->pclr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CMAP:\n\t\t\tif (!dec->cmap) {\n\t\t\t\tdec->cmap = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_COLR:\n\t\t\tif (!dec->colr) {\n\t\t\t\tdec->colr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (box) {\n\t\t\tjp2_box_destroy(box);\n\t\t\tbox = 0;\n\t\t}\n\t\tif (found) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tjas_eprintf(\"error: no code stream found\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!(dec->image = jpc_decode(in, optstr))) {\n\t\tjas_eprintf(\"error: cannot decode code stream\\n\");\n\t\tgoto error;\n\t}\n\n\t/* An IHDR box must be present. */\n\tif (!dec->ihdr) {\n\t\tjas_eprintf(\"error: missing IHDR box\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Does the number of components indicated in the IHDR box match\n\t  the value specified in the code stream? */\n\tif (dec->ihdr->data.ihdr.numcmpts != JAS_CAST(jas_uint,\n\t  jas_image_numcmpts(dec->image))) {\n\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t}\n\n\t/* At least one component must be present. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Determine if all components have the same data type. */\n\tsamedtype = true;\n\tdtype = jas_image_cmptdtype(dec->image, 0);\n\tfor (i = 1; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tif (jas_image_cmptdtype(dec->image, i) != dtype) {\n\t\t\tsamedtype = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Is the component data type indicated in the IHDR box consistent\n\t  with the data in the code stream? */\n\tif ((samedtype && dec->ihdr->data.ihdr.bpc != JP2_DTYPETOBPC(dtype)) ||\n\t  (!samedtype && dec->ihdr->data.ihdr.bpc != JP2_IHDR_BPCNULL)) {\n\t\tjas_eprintf(\"warning: component data type mismatch\\n\");\n\t}\n\n\t/* Is the compression type supported? */\n\tif (dec->ihdr->data.ihdr.comptype != JP2_IHDR_COMPTYPE) {\n\t\tjas_eprintf(\"error: unsupported compression type\\n\");\n\t\tgoto error;\n\t}\n\n\tif (dec->bpcc) {\n\t\t/* Is the number of components indicated in the BPCC box\n\t\t  consistent with the code stream data? */\n\t\tif (dec->bpcc->data.bpcc.numcmpts != JAS_CAST(jas_uint, jas_image_numcmpts(\n\t\t  dec->image))) {\n\t\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t\t}\n\t\t/* Is the component data type information indicated in the BPCC\n\t\t  box consistent with the code stream data? */\n\t\tif (!samedtype) {\n\t\t\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\t\t\t  ++i) {\n\t\t\t\tif (jas_image_cmptdtype(dec->image, i) !=\n\t\t\t\t  JP2_BPCTODTYPE(dec->bpcc->data.bpcc.bpcs[i])) {\n\t\t\t\t\tjas_eprintf(\"warning: component data type mismatch\\n\");\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tjas_eprintf(\"warning: superfluous BPCC box\\n\");\n\t\t}\n\t}\n\n\t/* A COLR box must be present. */\n\tif (!dec->colr) {\n\t\tjas_eprintf(\"error: no COLR box\\n\");\n\t\tgoto error;\n\t}\n\n\tswitch (dec->colr->data.colr.method) {\n\tcase JP2_COLR_ENUM:\n\t\tjas_image_setclrspc(dec->image, jp2_getcs(&dec->colr->data.colr));\n\t\tbreak;\n\tcase JP2_COLR_ICC:\n\t\ticcprof = jas_iccprof_createfrombuf(dec->colr->data.colr.iccp,\n\t\t  dec->colr->data.colr.iccplen);\n\t\tif (!iccprof) {\n\t\t\tjas_eprintf(\"error: failed to parse ICC profile\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_gethdr(iccprof, &icchdr);\n\t\tjas_eprintf(\"ICC Profile CS %08x\\n\", icchdr.colorspc);\n\t\tjas_image_setclrspc(dec->image, fromiccpcs(icchdr.colorspc));\n\t\tdec->image->cmprof_ = jas_cmprof_createfromiccprof(iccprof);\n\t\tassert(dec->image->cmprof_);\n\t\tjas_iccprof_destroy(iccprof);\n\t\tbreak;\n\t}\n\n\t/* If a CMAP box is present, a PCLR box must also be present. */\n\tif (dec->cmap && !dec->pclr) {\n\t\tjas_eprintf(\"warning: missing PCLR box or superfluous CMAP box\\n\");\n\t\tjp2_box_destroy(dec->cmap);\n\t\tdec->cmap = 0;\n\t}\n\n\t/* If a CMAP box is not present, a PCLR box must not be present. */\n\tif (!dec->cmap && dec->pclr) {\n\t\tjas_eprintf(\"warning: missing CMAP box or superfluous PCLR box\\n\");\n\t\tjp2_box_destroy(dec->pclr);\n\t\tdec->pclr = 0;\n\t}\n\n\t/* Determine the number of channels (which is essentially the number\n\t  of components after any palette mappings have been applied). */\n\tdec->numchans = dec->cmap ? dec->cmap->data.cmap.numchans :\n\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\n\t/* Perform a basic sanity check on the CMAP box if present. */\n\tif (dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\t/* Is the component number reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].cmptno >= JAS_CAST(jas_uint,\n\t\t\t  jas_image_numcmpts(dec->image))) {\n\t\t\t\tjas_eprintf(\"error: invalid component number in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\t/* Is the LUT index reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].pcol >=\n\t\t\t  dec->pclr->data.pclr.numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid CMAP LUT index\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Allocate space for the channel-number to component-number LUT. */\n\tif (!(dec->chantocmptlut = jas_alloc2(dec->numchans,\n\t  sizeof(uint_fast16_t)))) {\n\t\tjas_eprintf(\"error: no memory\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tdec->chantocmptlut[i] = i;\n\t\t}\n\t} else {\n\t\tcmapd = &dec->cmap->data.cmap;\n\t\tpclrd = &dec->pclr->data.pclr;\n\t\tcdefd = &dec->cdef->data.cdef;\n\t\tfor (channo = 0; channo < cmapd->numchans; ++channo) {\n\t\t\tcmapent = &cmapd->ents[channo];\n\t\t\tif (cmapent->map == JP2_CMAP_DIRECT) {\n\t\t\t\tdec->chantocmptlut[channo] = channo;\n\t\t\t} else if (cmapent->map == JP2_CMAP_PALETTE) {\n\t\t\t\tlutents = jas_alloc2(pclrd->numlutents, sizeof(int_fast32_t));\n\t\t\t\tfor (i = 0; i < pclrd->numlutents; ++i) {\n\t\t\t\t\tlutents[i] = pclrd->lutdata[cmapent->pcol + i * pclrd->numchans];\n\t\t\t\t}\n\t\t\t\tnewcmptno = jas_image_numcmpts(dec->image);\n\t\t\t\tjas_image_depalettize(dec->image, cmapent->cmptno,\n\t\t\t\t  pclrd->numlutents, lutents,\n\t\t\t\t  JP2_BPCTODTYPE(pclrd->bpc[cmapent->pcol]), newcmptno);\n\t\t\t\tdec->chantocmptlut[channo] = newcmptno;\n\t\t\t\tjas_free(lutents);\n#if 0\n\t\t\t\tif (dec->cdef) {\n\t\t\t\t\tcdefent = jp2_cdef_lookup(cdefd, channo);\n\t\t\t\t\tif (!cdefent) {\n\t\t\t\t\t\tabort();\n\t\t\t\t\t}\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), cdefent->type, cdefent->assoc));\n\t\t\t\t} else {\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), 0, channo + 1));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Mark all components as being of unknown type. */\n\n\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tjas_image_setcmpttype(dec->image, i, JAS_IMAGE_CT_UNKNOWN);\n\t}\n\n\t/* Determine the type of each component. */\n\tif (dec->cdef) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\t/* Is the channel number reasonable? */\n\t\t\tif (dec->cdef->data.cdef.ents[i].channo >= dec->numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid channel number in CDEF box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tjas_image_setcmpttype(dec->image,\n\t\t\t  dec->chantocmptlut[dec->cdef->data.cdef.ents[i].channo],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image),\n\t\t\t  dec->cdef->data.cdef.ents[i].type,\n\t\t\t  dec->cdef->data.cdef.ents[i].assoc));\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tjas_image_setcmpttype(dec->image, dec->chantocmptlut[i],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image), 0, i + 1));\n\t\t}\n\t}\n\n\t/* Delete any components that are not of interest. */\n\tfor (i = jas_image_numcmpts(dec->image); i > 0; --i) {\n\t\tif (jas_image_cmpttype(dec->image, i - 1) == JAS_IMAGE_CT_UNKNOWN) {\n\t\t\tjas_image_delcmpt(dec->image, i - 1);\n\t\t}\n\t}\n\n\t/* Ensure that some components survived. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n#if 0\njas_eprintf(\"no of components is %d\\n\", jas_image_numcmpts(dec->image));\n#endif\n\n\t/* Prevent the image from being destroyed later. */\n\timage = dec->image;\n\tdec->image = 0;\n\n\tjp2_dec_destroy(dec);\n\n\treturn image;\n\nerror:\n\tif (box) {\n\t\tjp2_box_destroy(box);\n\t}\n\tif (dec) {\n\t\tjp2_dec_destroy(dec);\n\t}\n\treturn 0;\n}",
        "func": "jas_image_t *jp2_decode(jas_stream_t *in, const char *optstr)\n{\n\tjp2_box_t *box;\n\tint found;\n\tjas_image_t *image;\n\tjp2_dec_t *dec;\n\tbool samedtype;\n\tint dtype;\n\tunsigned int i;\n\tjp2_cmap_t *cmapd;\n\tjp2_pclr_t *pclrd;\n\tjp2_cdef_t *cdefd;\n\tunsigned int channo;\n\tint newcmptno;\n\tint_fast32_t *lutents;\n#if 0\n\tjp2_cdefchan_t *cdefent;\n\tint cmptno;\n#endif\n\tjp2_cmapent_t *cmapent;\n\tjas_icchdr_t icchdr;\n\tjas_iccprof_t *iccprof;\n\n\tdec = 0;\n\tbox = 0;\n\timage = 0;\n\n\tJAS_DBGLOG(100, (\"jp2_decode(%p, \\\"%s\\\")\\n\", in, optstr));\n\n\tif (!(dec = jp2_dec_create())) {\n\t\tgoto error;\n\t}\n\n\t/* Get the first box.  This should be a JP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tjas_eprintf(\"error: cannot get box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_JP) {\n\t\tjas_eprintf(\"error: expecting signature box\\n\");\n\t\tgoto error;\n\t}\n\tif (box->data.jp.magic != JP2_JP_MAGIC) {\n\t\tjas_eprintf(\"incorrect magic number\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get the second box.  This should be a FTYP box. */\n\tif (!(box = jp2_box_get(in))) {\n\t\tgoto error;\n\t}\n\tif (box->type != JP2_BOX_FTYP) {\n\t\tjas_eprintf(\"expecting file type box\\n\");\n\t\tgoto error;\n\t}\n\tjp2_box_destroy(box);\n\tbox = 0;\n\n\t/* Get more boxes... */\n\tfound = 0;\n\twhile ((box = jp2_box_get(in))) {\n\t\tif (jas_getdbglevel() >= 1) {\n\t\t\tjas_eprintf(\"got box type %s\\n\", box->info->name);\n\t\t}\n\t\tswitch (box->type) {\n\t\tcase JP2_BOX_JP2C:\n\t\t\tfound = 1;\n\t\t\tbreak;\n\t\tcase JP2_BOX_IHDR:\n\t\t\tif (!dec->ihdr) {\n\t\t\t\tdec->ihdr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_BPCC:\n\t\t\tif (!dec->bpcc) {\n\t\t\t\tdec->bpcc = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CDEF:\n\t\t\tif (!dec->cdef) {\n\t\t\t\tdec->cdef = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_PCLR:\n\t\t\tif (!dec->pclr) {\n\t\t\t\tdec->pclr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_CMAP:\n\t\t\tif (!dec->cmap) {\n\t\t\t\tdec->cmap = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase JP2_BOX_COLR:\n\t\t\tif (!dec->colr) {\n\t\t\t\tdec->colr = box;\n\t\t\t\tbox = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (box) {\n\t\t\tjp2_box_destroy(box);\n\t\t\tbox = 0;\n\t\t}\n\t\tif (found) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\tjas_eprintf(\"error: no code stream found\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!(dec->image = jpc_decode(in, optstr))) {\n\t\tjas_eprintf(\"error: cannot decode code stream\\n\");\n\t\tgoto error;\n\t}\n\n\t/* An IHDR box must be present. */\n\tif (!dec->ihdr) {\n\t\tjas_eprintf(\"error: missing IHDR box\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Does the number of components indicated in the IHDR box match\n\t  the value specified in the code stream? */\n\tif (dec->ihdr->data.ihdr.numcmpts != JAS_CAST(jas_uint,\n\t  jas_image_numcmpts(dec->image))) {\n\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t}\n\n\t/* At least one component must be present. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Determine if all components have the same data type. */\n\tsamedtype = true;\n\tdtype = jas_image_cmptdtype(dec->image, 0);\n\tfor (i = 1; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tif (jas_image_cmptdtype(dec->image, i) != dtype) {\n\t\t\tsamedtype = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/* Is the component data type indicated in the IHDR box consistent\n\t  with the data in the code stream? */\n\tif ((samedtype && dec->ihdr->data.ihdr.bpc != JP2_DTYPETOBPC(dtype)) ||\n\t  (!samedtype && dec->ihdr->data.ihdr.bpc != JP2_IHDR_BPCNULL)) {\n\t\tjas_eprintf(\"warning: component data type mismatch\\n\");\n\t}\n\n\t/* Is the compression type supported? */\n\tif (dec->ihdr->data.ihdr.comptype != JP2_IHDR_COMPTYPE) {\n\t\tjas_eprintf(\"error: unsupported compression type\\n\");\n\t\tgoto error;\n\t}\n\n\tif (dec->bpcc) {\n\t\t/* Is the number of components indicated in the BPCC box\n\t\t  consistent with the code stream data? */\n\t\tif (dec->bpcc->data.bpcc.numcmpts != JAS_CAST(jas_uint, jas_image_numcmpts(\n\t\t  dec->image))) {\n\t\t\tjas_eprintf(\"warning: number of components mismatch\\n\");\n\t\t}\n\t\t/* Is the component data type information indicated in the BPCC\n\t\t  box consistent with the code stream data? */\n\t\tif (!samedtype) {\n\t\t\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\t\t\t  ++i) {\n\t\t\t\tif (jas_image_cmptdtype(dec->image, i) !=\n\t\t\t\t  JP2_BPCTODTYPE(dec->bpcc->data.bpcc.bpcs[i])) {\n\t\t\t\t\tjas_eprintf(\"warning: component data type mismatch\\n\");\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tjas_eprintf(\"warning: superfluous BPCC box\\n\");\n\t\t}\n\t}\n\n\t/* A COLR box must be present. */\n\tif (!dec->colr) {\n\t\tjas_eprintf(\"error: no COLR box\\n\");\n\t\tgoto error;\n\t}\n\n\tswitch (dec->colr->data.colr.method) {\n\tcase JP2_COLR_ENUM:\n\t\tjas_image_setclrspc(dec->image, jp2_getcs(&dec->colr->data.colr));\n\t\tbreak;\n\tcase JP2_COLR_ICC:\n\t\ticcprof = jas_iccprof_createfrombuf(dec->colr->data.colr.iccp,\n\t\t  dec->colr->data.colr.iccplen);\n\t\tif (!iccprof) {\n\t\t\tjas_eprintf(\"error: failed to parse ICC profile\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\tjas_iccprof_gethdr(iccprof, &icchdr);\n\t\tjas_eprintf(\"ICC Profile CS %08x\\n\", icchdr.colorspc);\n\t\tjas_image_setclrspc(dec->image, fromiccpcs(icchdr.colorspc));\n\t\tdec->image->cmprof_ = jas_cmprof_createfromiccprof(iccprof);\n\t\tassert(dec->image->cmprof_);\n\t\tjas_iccprof_destroy(iccprof);\n\t\tbreak;\n\t}\n\n\t/* If a CMAP box is present, a PCLR box must also be present. */\n\tif (dec->cmap && !dec->pclr) {\n\t\tjas_eprintf(\"warning: missing PCLR box or superfluous CMAP box\\n\");\n\t\tjp2_box_destroy(dec->cmap);\n\t\tdec->cmap = 0;\n\t}\n\n\t/* If a CMAP box is not present, a PCLR box must not be present. */\n\tif (!dec->cmap && dec->pclr) {\n\t\tjas_eprintf(\"warning: missing CMAP box or superfluous PCLR box\\n\");\n\t\tjp2_box_destroy(dec->pclr);\n\t\tdec->pclr = 0;\n\t}\n\n\t/* Determine the number of channels (which is essentially the number\n\t  of components after any palette mappings have been applied). */\n\tdec->numchans = dec->cmap ? dec->cmap->data.cmap.numchans :\n\t  JAS_CAST(jas_uint, jas_image_numcmpts(dec->image));\n\n\t/* Perform a basic sanity check on the CMAP box if present. */\n\tif (dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\t/* Is the component number reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].cmptno >= JAS_CAST(jas_uint,\n\t\t\t  jas_image_numcmpts(dec->image))) {\n\t\t\t\tjas_eprintf(\"error: invalid component number in CMAP box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\t/* Is the LUT index reasonable? */\n\t\t\tif (dec->cmap->data.cmap.ents[i].pcol >=\n\t\t\t  dec->pclr->data.pclr.numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid CMAP LUT index\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Allocate space for the channel-number to component-number LUT. */\n\tif (!(dec->chantocmptlut = jas_alloc2(dec->numchans,\n\t  sizeof(uint_fast16_t)))) {\n\t\tjas_eprintf(\"error: no memory\\n\");\n\t\tgoto error;\n\t}\n\n\tif (!dec->cmap) {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tdec->chantocmptlut[i] = i;\n\t\t}\n\t} else {\n\t\tcmapd = &dec->cmap->data.cmap;\n\t\tpclrd = &dec->pclr->data.pclr;\n\t\tcdefd = &dec->cdef->data.cdef;\n\t\tfor (channo = 0; channo < cmapd->numchans; ++channo) {\n\t\t\tcmapent = &cmapd->ents[channo];\n\t\t\tif (cmapent->map == JP2_CMAP_DIRECT) {\n\t\t\t\tdec->chantocmptlut[channo] = channo;\n\t\t\t} else if (cmapent->map == JP2_CMAP_PALETTE) {\n\t\t\t\tlutents = jas_alloc2(pclrd->numlutents, sizeof(int_fast32_t));\n\t\t\t\tfor (i = 0; i < pclrd->numlutents; ++i) {\n\t\t\t\t\tlutents[i] = pclrd->lutdata[cmapent->pcol + i * pclrd->numchans];\n\t\t\t\t}\n\t\t\t\tnewcmptno = jas_image_numcmpts(dec->image);\n\t\t\t\tjas_image_depalettize(dec->image, cmapent->cmptno,\n\t\t\t\t  pclrd->numlutents, lutents,\n\t\t\t\t  JP2_BPCTODTYPE(pclrd->bpc[cmapent->pcol]), newcmptno);\n\t\t\t\tdec->chantocmptlut[channo] = newcmptno;\n\t\t\t\tjas_free(lutents);\n#if 0\n\t\t\t\tif (dec->cdef) {\n\t\t\t\t\tcdefent = jp2_cdef_lookup(cdefd, channo);\n\t\t\t\t\tif (!cdefent) {\n\t\t\t\t\t\tabort();\n\t\t\t\t\t}\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), cdefent->type, cdefent->assoc));\n\t\t\t\t} else {\n\t\t\t\tjas_image_setcmpttype(dec->image, newcmptno, jp2_getct(jas_image_clrspc(dec->image), 0, channo + 1));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t}\n\t}\n\n\t/* Mark all components as being of unknown type. */\n\n\tfor (i = 0; i < JAS_CAST(jas_uint, jas_image_numcmpts(dec->image)); ++i) {\n\t\tjas_image_setcmpttype(dec->image, i, JAS_IMAGE_CT_UNKNOWN);\n\t}\n\n\t/* Determine the type of each component. */\n\tif (dec->cdef) {\n\t\tfor (i = 0; i < dec->cdef->data.cdef.numchans; ++i) {\n\t\t\t/* Is the channel number reasonable? */\n\t\t\tif (dec->cdef->data.cdef.ents[i].channo >= dec->numchans) {\n\t\t\t\tjas_eprintf(\"error: invalid channel number in CDEF box\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tjas_image_setcmpttype(dec->image,\n\t\t\t  dec->chantocmptlut[dec->cdef->data.cdef.ents[i].channo],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image),\n\t\t\t  dec->cdef->data.cdef.ents[i].type,\n\t\t\t  dec->cdef->data.cdef.ents[i].assoc));\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < dec->numchans; ++i) {\n\t\t\tjas_image_setcmpttype(dec->image, dec->chantocmptlut[i],\n\t\t\t  jp2_getct(jas_image_clrspc(dec->image), 0, i + 1));\n\t\t}\n\t}\n\n\t/* Delete any components that are not of interest. */\n\tfor (i = jas_image_numcmpts(dec->image); i > 0; --i) {\n\t\tif (jas_image_cmpttype(dec->image, i - 1) == JAS_IMAGE_CT_UNKNOWN) {\n\t\t\tjas_image_delcmpt(dec->image, i - 1);\n\t\t}\n\t}\n\n\t/* Ensure that some components survived. */\n\tif (!jas_image_numcmpts(dec->image)) {\n\t\tjas_eprintf(\"error: no components\\n\");\n\t\tgoto error;\n\t}\n#if 0\njas_eprintf(\"no of components is %d\\n\", jas_image_numcmpts(dec->image));\n#endif\n\n\t/* Prevent the image from being destroyed later. */\n\timage = dec->image;\n\tdec->image = 0;\n\n\tjp2_dec_destroy(dec);\n\n\treturn image;\n\nerror:\n\tif (box) {\n\t\tjp2_box_destroy(box);\n\t}\n\tif (dec) {\n\t\tjp2_dec_destroy(dec);\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -304,7 +304,7 @@\n \n \t/* Determine the type of each component. */\n \tif (dec->cdef) {\n-\t\tfor (i = 0; i < dec->numchans; ++i) {\n+\t\tfor (i = 0; i < dec->cdef->data.cdef.numchans; ++i) {\n \t\t\t/* Is the channel number reasonable? */\n \t\t\tif (dec->cdef->data.cdef.ents[i].channo >= dec->numchans) {\n \t\t\t\tjas_eprintf(\"error: invalid channel number in CDEF box\\n\");",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tfor (i = 0; i < dec->numchans; ++i) {"
            ],
            "added_lines": [
                "\t\tfor (i = 0; i < dec->cdef->data.cdef.numchans; ++i) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-20056",
        "func_name": "saitoha/libsixel/stbi__shiftsigned",
        "description": "stb_image.h (aka the stb image loader) 2.23, as used in libsixel and other products, has an assertion failure in stbi__shiftsigned.",
        "git_url": "https://github.com/saitoha/libsixel/commit/bab1e603a1842898984e719af101dc34838b37a3",
        "commit_title": "Fix for CVE-2019-20056, assertion failure problem(#126). Thanks to @sleicasper",
        "commit_text": "",
        "func_before": "static int stbi__shiftsigned(int v, int shift, int bits)\n{\n   static unsigned int mul_table[9] = {\n      0,\n      0xff/*0b11111111*/, 0x55/*0b01010101*/, 0x49/*0b01001001*/, 0x11/*0b00010001*/,\n      0x21/*0b00100001*/, 0x41/*0b01000001*/, 0x81/*0b10000001*/, 0x01/*0b00000001*/,\n   };\n   static unsigned int shift_table[9] = {\n      0, 0,0,1,0,2,4,6,0,\n   };\n   if (shift < 0)\n      v <<= -shift;\n   else\n      v >>= shift;\n   STBI_ASSERT(v >= 0 && v < 256);\n   v >>= (8-bits);\n   if (bits < 0 || bits > 8) return (0);  /* error */\n   return (int) ((unsigned) v * mul_table[bits]) >> shift_table[bits];\n}",
        "func": "static int stbi__shiftsigned(int v, int shift, int bits)\n{\n   static unsigned int mul_table[9] = {\n      0,\n      0xff/*0b11111111*/, 0x55/*0b01010101*/, 0x49/*0b01001001*/, 0x11/*0b00010001*/,\n      0x21/*0b00100001*/, 0x41/*0b01000001*/, 0x81/*0b10000001*/, 0x01/*0b00000001*/,\n   };\n   static unsigned int shift_table[9] = {\n      0, 0,0,1,0,2,4,6,0,\n   };\n   if (bits < 0 || bits > 8) return (0);  /* error */\n   if (shift < 0)\n      v <<= -shift;\n   else\n      v >>= shift;\n   if (v >= 0 && v < 256) return (0);\n   v >>= (8-bits);\n   return (int) ((unsigned) v * mul_table[bits]) >> shift_table[bits];\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,12 +8,12 @@\n    static unsigned int shift_table[9] = {\n       0, 0,0,1,0,2,4,6,0,\n    };\n+   if (bits < 0 || bits > 8) return (0);  /* error */\n    if (shift < 0)\n       v <<= -shift;\n    else\n       v >>= shift;\n-   STBI_ASSERT(v >= 0 && v < 256);\n+   if (v >= 0 && v < 256) return (0);\n    v >>= (8-bits);\n-   if (bits < 0 || bits > 8) return (0);  /* error */\n    return (int) ((unsigned) v * mul_table[bits]) >> shift_table[bits];\n }",
        "diff_line_info": {
            "deleted_lines": [
                "   STBI_ASSERT(v >= 0 && v < 256);",
                "   if (bits < 0 || bits > 8) return (0);  /* error */"
            ],
            "added_lines": [
                "   if (bits < 0 || bits > 8) return (0);  /* error */",
                "   if (v >= 0 && v < 256) return (0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-13304",
        "func_name": "ffmpeg/ff_mpeg4_decode_picture_header",
        "description": "In libavcodec in FFmpeg 4.0.1, improper maintenance of the consistency between the context profile field and studio_profile in libavcodec may trigger an assertion failure while converting a crafted AVI file to MPEG4, leading to a denial of service, related to error_resilience.c, h263dec.c, and mpeg4videodec.c.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/bd27a9364ca274ca97f1df6d984e88a0700fb235",
        "commit_title": "avcodec/mpeg4videodec: Remove use of FF_PROFILE_MPEG4_SIMPLE_STUDIO as indicator of studio profile",
        "commit_text": " The profile field is changed by code inside and outside the decoder, its not a reliable indicator of the internal codec state. Maintaining it consistency with studio_profile is messy. Its easier to just avoid it and use only studio_profile  ",
        "func_before": "int ff_mpeg4_decode_picture_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n    unsigned startcode, v;\n    int ret;\n    int vol = 0;\n\n    /* search next start code */\n    align_get_bits(gb);\n\n    // If we have not switched to studio profile than we also did not switch bps\n    // that means something else (like a previous instance) outside set bps which\n    // would be inconsistant with the currect state, thus reset it\n    if (!s->studio_profile && s->avctx->bits_per_raw_sample != 8)\n        s->avctx->bits_per_raw_sample = 0;\n\n    if (s->codec_tag == AV_RL32(\"WV1F\") && show_bits(gb, 24) == 0x575630) {\n        skip_bits(gb, 24);\n        if (get_bits(gb, 8) == 0xF0)\n            goto end;\n    }\n\n    startcode = 0xff;\n    for (;;) {\n        if (get_bits_count(gb) >= gb->size_in_bits) {\n            if (gb->size_in_bits == 8 &&\n                (ctx->divx_version >= 0 || ctx->xvid_build >= 0) || s->codec_tag == AV_RL32(\"QMP4\")) {\n                av_log(s->avctx, AV_LOG_VERBOSE, \"frame skip %d\\n\", gb->size_in_bits);\n                return FRAME_SKIPPED;  // divx bug\n            } else\n                return AVERROR_INVALIDDATA;  // end of stream\n        }\n\n        /* use the bits after the test */\n        v = get_bits(gb, 8);\n        startcode = ((startcode << 8) | v) & 0xffffffff;\n\n        if ((startcode & 0xFFFFFF00) != 0x100)\n            continue;  // no startcode\n\n        if (s->avctx->debug & FF_DEBUG_STARTCODE) {\n            av_log(s->avctx, AV_LOG_DEBUG, \"startcode: %3X \", startcode);\n            if (startcode <= 0x11F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Object Start\");\n            else if (startcode <= 0x12F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Object Layer Start\");\n            else if (startcode <= 0x13F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Reserved\");\n            else if (startcode <= 0x15F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"FGS bp start\");\n            else if (startcode <= 0x1AF)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Reserved\");\n            else if (startcode == 0x1B0)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Visual Object Seq Start\");\n            else if (startcode == 0x1B1)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Visual Object Seq End\");\n            else if (startcode == 0x1B2)\n                av_log(s->avctx, AV_LOG_DEBUG, \"User Data\");\n            else if (startcode == 0x1B3)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Group of VOP start\");\n            else if (startcode == 0x1B4)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Session Error\");\n            else if (startcode == 0x1B5)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Visual Object Start\");\n            else if (startcode == 0x1B6)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Object Plane start\");\n            else if (startcode == 0x1B7)\n                av_log(s->avctx, AV_LOG_DEBUG, \"slice start\");\n            else if (startcode == 0x1B8)\n                av_log(s->avctx, AV_LOG_DEBUG, \"extension start\");\n            else if (startcode == 0x1B9)\n                av_log(s->avctx, AV_LOG_DEBUG, \"fgs start\");\n            else if (startcode == 0x1BA)\n                av_log(s->avctx, AV_LOG_DEBUG, \"FBA Object start\");\n            else if (startcode == 0x1BB)\n                av_log(s->avctx, AV_LOG_DEBUG, \"FBA Object Plane start\");\n            else if (startcode == 0x1BC)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Mesh Object start\");\n            else if (startcode == 0x1BD)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Mesh Object Plane start\");\n            else if (startcode == 0x1BE)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Still Texture Object start\");\n            else if (startcode == 0x1BF)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture Spatial Layer start\");\n            else if (startcode == 0x1C0)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture SNR Layer start\");\n            else if (startcode == 0x1C1)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture Tile start\");\n            else if (startcode == 0x1C2)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture Shape Layer start\");\n            else if (startcode == 0x1C3)\n                av_log(s->avctx, AV_LOG_DEBUG, \"stuffing start\");\n            else if (startcode <= 0x1C5)\n                av_log(s->avctx, AV_LOG_DEBUG, \"reserved\");\n            else if (startcode <= 0x1FF)\n                av_log(s->avctx, AV_LOG_DEBUG, \"System start\");\n            av_log(s->avctx, AV_LOG_DEBUG, \" at %d\\n\", get_bits_count(gb));\n        }\n\n        if (startcode >= 0x120 && startcode <= 0x12F) {\n            if (vol) {\n                av_log(s->avctx, AV_LOG_WARNING, \"Ignoring multiple VOL headers\\n\");\n                continue;\n            }\n            vol++;\n            if ((ret = decode_vol_header(ctx, gb)) < 0)\n                return ret;\n        } else if (startcode == USER_DATA_STARTCODE) {\n            decode_user_data(ctx, gb);\n        } else if (startcode == GOP_STARTCODE) {\n            mpeg4_decode_gop_header(s, gb);\n        } else if (startcode == VOS_STARTCODE) {\n            int profile, level;\n            mpeg4_decode_profile_level(s, gb, &profile, &level);\n            if (profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO &&\n                (level > 0 && level < 9)) {\n                s->studio_profile = 1;\n                next_start_code_studio(gb);\n                extension_and_user_data(s, gb, 0);\n            } else if (s->studio_profile) {\n                avpriv_request_sample(s->avctx, \"Mixes studio and non studio profile\\n\");\n                return AVERROR_PATCHWELCOME;\n            }\n            s->avctx->profile = profile;\n            s->avctx->level   = level;\n        } else if (startcode == VISUAL_OBJ_STARTCODE) {\n            if (s->studio_profile) {\n                if ((ret = decode_studiovisualobject(ctx, gb)) < 0)\n                    return ret;\n            } else\n                mpeg4_decode_visual_object(s, gb);\n        } else if (startcode == VOP_STARTCODE) {\n            break;\n        }\n\n        align_get_bits(gb);\n        startcode = 0xff;\n    }\n\nend:\n    if (s->avctx->flags & AV_CODEC_FLAG_LOW_DELAY)\n        s->low_delay = 1;\n    s->avctx->has_b_frames = !s->low_delay;\n\n    if (s->studio_profile) {\n        av_assert0(s->avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO);\n        if (!s->avctx->bits_per_raw_sample) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Missing VOL header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        return decode_studio_vop_header(ctx, gb);\n    } else\n        return decode_vop_header(ctx, gb);\n}",
        "func": "int ff_mpeg4_decode_picture_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n    unsigned startcode, v;\n    int ret;\n    int vol = 0;\n\n    /* search next start code */\n    align_get_bits(gb);\n\n    // If we have not switched to studio profile than we also did not switch bps\n    // that means something else (like a previous instance) outside set bps which\n    // would be inconsistant with the currect state, thus reset it\n    if (!s->studio_profile && s->avctx->bits_per_raw_sample != 8)\n        s->avctx->bits_per_raw_sample = 0;\n\n    if (s->codec_tag == AV_RL32(\"WV1F\") && show_bits(gb, 24) == 0x575630) {\n        skip_bits(gb, 24);\n        if (get_bits(gb, 8) == 0xF0)\n            goto end;\n    }\n\n    startcode = 0xff;\n    for (;;) {\n        if (get_bits_count(gb) >= gb->size_in_bits) {\n            if (gb->size_in_bits == 8 &&\n                (ctx->divx_version >= 0 || ctx->xvid_build >= 0) || s->codec_tag == AV_RL32(\"QMP4\")) {\n                av_log(s->avctx, AV_LOG_VERBOSE, \"frame skip %d\\n\", gb->size_in_bits);\n                return FRAME_SKIPPED;  // divx bug\n            } else\n                return AVERROR_INVALIDDATA;  // end of stream\n        }\n\n        /* use the bits after the test */\n        v = get_bits(gb, 8);\n        startcode = ((startcode << 8) | v) & 0xffffffff;\n\n        if ((startcode & 0xFFFFFF00) != 0x100)\n            continue;  // no startcode\n\n        if (s->avctx->debug & FF_DEBUG_STARTCODE) {\n            av_log(s->avctx, AV_LOG_DEBUG, \"startcode: %3X \", startcode);\n            if (startcode <= 0x11F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Object Start\");\n            else if (startcode <= 0x12F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Object Layer Start\");\n            else if (startcode <= 0x13F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Reserved\");\n            else if (startcode <= 0x15F)\n                av_log(s->avctx, AV_LOG_DEBUG, \"FGS bp start\");\n            else if (startcode <= 0x1AF)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Reserved\");\n            else if (startcode == 0x1B0)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Visual Object Seq Start\");\n            else if (startcode == 0x1B1)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Visual Object Seq End\");\n            else if (startcode == 0x1B2)\n                av_log(s->avctx, AV_LOG_DEBUG, \"User Data\");\n            else if (startcode == 0x1B3)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Group of VOP start\");\n            else if (startcode == 0x1B4)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Session Error\");\n            else if (startcode == 0x1B5)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Visual Object Start\");\n            else if (startcode == 0x1B6)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Video Object Plane start\");\n            else if (startcode == 0x1B7)\n                av_log(s->avctx, AV_LOG_DEBUG, \"slice start\");\n            else if (startcode == 0x1B8)\n                av_log(s->avctx, AV_LOG_DEBUG, \"extension start\");\n            else if (startcode == 0x1B9)\n                av_log(s->avctx, AV_LOG_DEBUG, \"fgs start\");\n            else if (startcode == 0x1BA)\n                av_log(s->avctx, AV_LOG_DEBUG, \"FBA Object start\");\n            else if (startcode == 0x1BB)\n                av_log(s->avctx, AV_LOG_DEBUG, \"FBA Object Plane start\");\n            else if (startcode == 0x1BC)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Mesh Object start\");\n            else if (startcode == 0x1BD)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Mesh Object Plane start\");\n            else if (startcode == 0x1BE)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Still Texture Object start\");\n            else if (startcode == 0x1BF)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture Spatial Layer start\");\n            else if (startcode == 0x1C0)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture SNR Layer start\");\n            else if (startcode == 0x1C1)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture Tile start\");\n            else if (startcode == 0x1C2)\n                av_log(s->avctx, AV_LOG_DEBUG, \"Texture Shape Layer start\");\n            else if (startcode == 0x1C3)\n                av_log(s->avctx, AV_LOG_DEBUG, \"stuffing start\");\n            else if (startcode <= 0x1C5)\n                av_log(s->avctx, AV_LOG_DEBUG, \"reserved\");\n            else if (startcode <= 0x1FF)\n                av_log(s->avctx, AV_LOG_DEBUG, \"System start\");\n            av_log(s->avctx, AV_LOG_DEBUG, \" at %d\\n\", get_bits_count(gb));\n        }\n\n        if (startcode >= 0x120 && startcode <= 0x12F) {\n            if (vol) {\n                av_log(s->avctx, AV_LOG_WARNING, \"Ignoring multiple VOL headers\\n\");\n                continue;\n            }\n            vol++;\n            if ((ret = decode_vol_header(ctx, gb)) < 0)\n                return ret;\n        } else if (startcode == USER_DATA_STARTCODE) {\n            decode_user_data(ctx, gb);\n        } else if (startcode == GOP_STARTCODE) {\n            mpeg4_decode_gop_header(s, gb);\n        } else if (startcode == VOS_STARTCODE) {\n            int profile, level;\n            mpeg4_decode_profile_level(s, gb, &profile, &level);\n            if (profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO &&\n                (level > 0 && level < 9)) {\n                s->studio_profile = 1;\n                next_start_code_studio(gb);\n                extension_and_user_data(s, gb, 0);\n            } else if (s->studio_profile) {\n                avpriv_request_sample(s->avctx, \"Mixes studio and non studio profile\\n\");\n                return AVERROR_PATCHWELCOME;\n            }\n            s->avctx->profile = profile;\n            s->avctx->level   = level;\n        } else if (startcode == VISUAL_OBJ_STARTCODE) {\n            if (s->studio_profile) {\n                if ((ret = decode_studiovisualobject(ctx, gb)) < 0)\n                    return ret;\n            } else\n                mpeg4_decode_visual_object(s, gb);\n        } else if (startcode == VOP_STARTCODE) {\n            break;\n        }\n\n        align_get_bits(gb);\n        startcode = 0xff;\n    }\n\nend:\n    if (s->avctx->flags & AV_CODEC_FLAG_LOW_DELAY)\n        s->low_delay = 1;\n    s->avctx->has_b_frames = !s->low_delay;\n\n    if (s->studio_profile) {\n        if (!s->avctx->bits_per_raw_sample) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Missing VOL header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        return decode_studio_vop_header(ctx, gb);\n    } else\n        return decode_vop_header(ctx, gb);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -143,7 +143,6 @@\n     s->avctx->has_b_frames = !s->low_delay;\n \n     if (s->studio_profile) {\n-        av_assert0(s->avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO);\n         if (!s->avctx->bits_per_raw_sample) {\n             av_log(s->avctx, AV_LOG_ERROR, \"Missing VOL header\\n\");\n             return AVERROR_INVALIDDATA;",
        "diff_line_info": {
            "deleted_lines": [
                "        av_assert0(s->avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2018-13304",
        "func_name": "ffmpeg/er_supported",
        "description": "In libavcodec in FFmpeg 4.0.1, improper maintenance of the consistency between the context profile field and studio_profile in libavcodec may trigger an assertion failure while converting a crafted AVI file to MPEG4, leading to a denial of service, related to error_resilience.c, h263dec.c, and mpeg4videodec.c.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/bd27a9364ca274ca97f1df6d984e88a0700fb235",
        "commit_title": "avcodec/mpeg4videodec: Remove use of FF_PROFILE_MPEG4_SIMPLE_STUDIO as indicator of studio profile",
        "commit_text": " The profile field is changed by code inside and outside the decoder, its not a reliable indicator of the internal codec state. Maintaining it consistency with studio_profile is messy. Its easier to just avoid it and use only studio_profile  ",
        "func_before": "static int er_supported(ERContext *s)\n{\n    if(s->avctx->hwaccel && s->avctx->hwaccel->decode_slice           ||\n       !s->cur_pic.f                                                  ||\n       s->cur_pic.field_picture                                       ||\n       s->avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO\n    )\n        return 0;\n    return 1;\n}",
        "func": "static int er_supported(ERContext *s)\n{\n    if(s->avctx->hwaccel && s->avctx->hwaccel->decode_slice           ||\n       !s->cur_pic.f                                                  ||\n       s->cur_pic.field_picture\n    )\n        return 0;\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,8 +2,7 @@\n {\n     if(s->avctx->hwaccel && s->avctx->hwaccel->decode_slice           ||\n        !s->cur_pic.f                                                  ||\n-       s->cur_pic.field_picture                                       ||\n-       s->avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO\n+       s->cur_pic.field_picture\n     )\n         return 0;\n     return 1;",
        "diff_line_info": {
            "deleted_lines": [
                "       s->cur_pic.field_picture                                       ||",
                "       s->avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO"
            ],
            "added_lines": [
                "       s->cur_pic.field_picture"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-13304",
        "func_name": "ffmpeg/ff_h263_decode_frame",
        "description": "In libavcodec in FFmpeg 4.0.1, improper maintenance of the consistency between the context profile field and studio_profile in libavcodec may trigger an assertion failure while converting a crafted AVI file to MPEG4, leading to a denial of service, related to error_resilience.c, h263dec.c, and mpeg4videodec.c.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/bd27a9364ca274ca97f1df6d984e88a0700fb235",
        "commit_title": "avcodec/mpeg4videodec: Remove use of FF_PROFILE_MPEG4_SIMPLE_STUDIO as indicator of studio profile",
        "commit_text": " The profile field is changed by code inside and outside the decoder, its not a reliable indicator of the internal codec state. Maintaining it consistency with studio_profile is messy. Its easier to just avoid it and use only studio_profile  ",
        "func_before": "int ff_h263_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                         AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size       = avpkt->size;\n    MpegEncContext *s  = avctx->priv_data;\n    int ret;\n    int slice_ret = 0;\n    AVFrame *pict = data;\n\n    /* no supplementary picture */\n    if (buf_size == 0) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    if (s->avctx->flags & AV_CODEC_FLAG_TRUNCATED) {\n        int next;\n\n        if (CONFIG_MPEG4_DECODER && s->codec_id == AV_CODEC_ID_MPEG4) {\n            next = ff_mpeg4_find_frame_end(&s->parse_context, buf, buf_size);\n        } else if (CONFIG_H263_DECODER && s->codec_id == AV_CODEC_ID_H263) {\n            next = ff_h263_find_frame_end(&s->parse_context, buf, buf_size);\n        } else if (CONFIG_H263P_DECODER && s->codec_id == AV_CODEC_ID_H263P) {\n            next = ff_h263_find_frame_end(&s->parse_context, buf, buf_size);\n        } else {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"this codec does not support truncated bitstreams\\n\");\n            return AVERROR(ENOSYS);\n        }\n\n        if (ff_combine_frame(&s->parse_context, next, (const uint8_t **)&buf,\n                             &buf_size) < 0)\n            return buf_size;\n    }\n\nretry:\n    if (s->divx_packed && s->bitstream_buffer_size) {\n        int i;\n        for(i=0; i < buf_size-3; i++) {\n            if (buf[i]==0 && buf[i+1]==0 && buf[i+2]==1) {\n                if (buf[i+3]==0xB0) {\n                    av_log(s->avctx, AV_LOG_WARNING, \"Discarding excessive bitstream in packed xvid\\n\");\n                    s->bitstream_buffer_size = 0;\n                }\n                break;\n            }\n        }\n    }\n\n    if (s->bitstream_buffer_size && (s->divx_packed || buf_size <= MAX_NVOP_SIZE)) // divx 5.01+/xvid frame reorder\n        ret = init_get_bits8(&s->gb, s->bitstream_buffer,\n                             s->bitstream_buffer_size);\n    else\n        ret = init_get_bits8(&s->gb, buf, buf_size);\n\n    s->bitstream_buffer_size = 0;\n    if (ret < 0)\n        return ret;\n\n    if (!s->context_initialized)\n        // we need the idct permutation for reading a custom matrix\n        ff_mpv_idct_init(s);\n\n    /* let's go :-) */\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version == 5) {\n        ret = ff_wmv2_decode_picture_header(s);\n    } else if (CONFIG_MSMPEG4_DECODER && s->msmpeg4_version) {\n        ret = ff_msmpeg4_decode_picture_header(s);\n    } else if (CONFIG_MPEG4_DECODER && avctx->codec_id == AV_CODEC_ID_MPEG4) {\n        if (s->avctx->extradata_size && s->picture_number == 0) {\n            GetBitContext gb;\n\n            if (init_get_bits8(&gb, s->avctx->extradata, s->avctx->extradata_size) >= 0 )\n                ff_mpeg4_decode_picture_header(avctx->priv_data, &gb);\n        }\n        ret = ff_mpeg4_decode_picture_header(avctx->priv_data, &s->gb);\n    } else if (CONFIG_H263I_DECODER && s->codec_id == AV_CODEC_ID_H263I) {\n        ret = ff_intel_h263_decode_picture_header(s);\n    } else if (CONFIG_FLV_DECODER && s->h263_flv) {\n        ret = ff_flv_decode_picture_header(s);\n    } else {\n        ret = ff_h263_decode_picture_header(s);\n    }\n\n    if (ret < 0 || ret == FRAME_SKIPPED) {\n        if (   s->width  != avctx->coded_width\n            || s->height != avctx->coded_height) {\n                av_log(s->avctx, AV_LOG_WARNING, \"Reverting picture dimensions change due to header decoding failure\\n\");\n                s->width = avctx->coded_width;\n                s->height= avctx->coded_height;\n        }\n    }\n    if (ret == FRAME_SKIPPED)\n        return get_consumed_bytes(s, buf_size);\n\n    /* skip if the header was thrashed */\n    if (ret < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"header damaged\\n\");\n        return ret;\n    }\n\n    if (!s->context_initialized) {\n        avctx->pix_fmt = h263_get_format(avctx);\n        if ((ret = ff_mpv_common_init(s)) < 0)\n            return ret;\n    }\n\n    if (!s->current_picture_ptr || s->current_picture_ptr->f->data[0]) {\n        int i = ff_find_unused_picture(s->avctx, s->picture, 0);\n        if (i < 0)\n            return i;\n        s->current_picture_ptr = &s->picture[i];\n    }\n\n    avctx->has_b_frames = !s->low_delay;\n\n    if (CONFIG_MPEG4_DECODER && avctx->codec_id == AV_CODEC_ID_MPEG4) {\n        if (ff_mpeg4_workaround_bugs(avctx) == 1)\n            goto retry;\n        if (s->studio_profile != (s->idsp.idct == NULL))\n            ff_mpv_idct_init(s);\n    }\n\n    /* After H.263 & MPEG-4 header decode we have the height, width,\n     * and other parameters. So then we could init the picture.\n     * FIXME: By the way H.263 decoder is evolving it should have\n     * an H263EncContext */\n    if (s->width  != avctx->coded_width  ||\n        s->height != avctx->coded_height ||\n        s->context_reinit) {\n        /* H.263 could change picture size any time */\n        s->context_reinit = 0;\n\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n        if (ret < 0)\n            return ret;\n\n        ff_set_sar(avctx, avctx->sample_aspect_ratio);\n\n        if ((ret = ff_mpv_common_frame_size_change(s)))\n            return ret;\n\n        if (avctx->pix_fmt != h263_get_format(avctx)) {\n            av_log(avctx, AV_LOG_ERROR, \"format change not supported\\n\");\n            avctx->pix_fmt = AV_PIX_FMT_NONE;\n            return AVERROR_UNKNOWN;\n        }\n    }\n\n    if (s->codec_id == AV_CODEC_ID_H263  ||\n        s->codec_id == AV_CODEC_ID_H263P ||\n        s->codec_id == AV_CODEC_ID_H263I)\n        s->gob_index = H263_GOB_HEIGHT(s->height);\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr &&\n        (s->pict_type == AV_PICTURE_TYPE_B || s->droppable))\n        return get_consumed_bytes(s, buf_size);\n    if ((avctx->skip_frame >= AVDISCARD_NONREF &&\n         s->pict_type == AV_PICTURE_TYPE_B)    ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY &&\n         s->pict_type != AV_PICTURE_TYPE_I)    ||\n        avctx->skip_frame >= AVDISCARD_ALL)\n        return get_consumed_bytes(s, buf_size);\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            return get_consumed_bytes(s, buf_size);\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if ((!s->no_rounding) || s->pict_type == AV_PICTURE_TYPE_B) {\n        s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n        s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n    } else {\n        s->me.qpel_put = s->qdsp.put_no_rnd_qpel_pixels_tab;\n        s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n    }\n\n    if ((ret = ff_mpv_frame_start(s, avctx)) < 0)\n        return ret;\n\n    if (!s->divx_packed)\n        ff_thread_finish_setup(avctx);\n\n    if (avctx->hwaccel) {\n        ret = avctx->hwaccel->start_frame(avctx, s->gb.buffer,\n                                          s->gb.buffer_end - s->gb.buffer);\n        if (ret < 0 )\n            return ret;\n    }\n\n    ff_mpeg_er_frame_start(s);\n\n    /* the second part of the wmv2 header contains the MB skip bits which\n     * are stored in current_picture->mb_type which is not available before\n     * ff_mpv_frame_start() */\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version == 5) {\n        ret = ff_wmv2_decode_secondary_picture_header(s);\n        if (ret < 0)\n            return ret;\n        if (ret == 1)\n            goto frame_end;\n    }\n\n    /* decode each macroblock */\n    s->mb_x = 0;\n    s->mb_y = 0;\n\n    slice_ret = decode_slice(s);\n    while (s->mb_y < s->mb_height) {\n        if (s->msmpeg4_version) {\n            if (s->slice_height == 0 || s->mb_x != 0 || slice_ret < 0 ||\n                (s->mb_y % s->slice_height) != 0 || get_bits_left(&s->gb) < 0)\n                break;\n        } else {\n            int prev_x = s->mb_x, prev_y = s->mb_y;\n            if (ff_h263_resync(s) < 0)\n                break;\n            if (prev_y * s->mb_width + prev_x < s->mb_y * s->mb_width + s->mb_x)\n                s->er.error_occurred = 1;\n        }\n\n        if (s->msmpeg4_version < 4 && s->h263_pred)\n            ff_mpeg4_clean_buffers(s);\n\n        if (decode_slice(s) < 0)\n            slice_ret = AVERROR_INVALIDDATA;\n    }\n\n    if (s->msmpeg4_version && s->msmpeg4_version < 4 &&\n        s->pict_type == AV_PICTURE_TYPE_I)\n        if (!CONFIG_MSMPEG4_DECODER ||\n            ff_msmpeg4_decode_ext_header(s, buf_size) < 0)\n            s->er.error_status_table[s->mb_num - 1] = ER_MB_ERROR;\n\n    av_assert1(s->bitstream_buffer_size == 0);\nframe_end:\n    ff_er_frame_end(&s->er);\n\n    if (avctx->hwaccel) {\n        ret = avctx->hwaccel->end_frame(avctx);\n        if (ret < 0)\n            return ret;\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (CONFIG_MPEG4_DECODER && avctx->codec_id == AV_CODEC_ID_MPEG4)\n        ff_mpeg4_frame_end(avctx, buf, buf_size);\n\n    if (!s->divx_packed && avctx->hwaccel)\n        ff_thread_finish_setup(avctx);\n\n    av_assert1(s->current_picture.f->pict_type == s->current_picture_ptr->f->pict_type);\n    av_assert1(s->current_picture.f->pict_type == s->pict_type);\n    if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n        if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n            return ret;\n        ff_print_debug_info(s, s->current_picture_ptr, pict);\n        ff_mpv_export_qp_table(s, pict, s->current_picture_ptr, FF_QSCALE_TYPE_MPEG1);\n    } else if (s->last_picture_ptr) {\n        if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n            return ret;\n        ff_print_debug_info(s, s->last_picture_ptr, pict);\n        ff_mpv_export_qp_table(s, pict, s->last_picture_ptr, FF_QSCALE_TYPE_MPEG1);\n    }\n\n    if (s->last_picture_ptr || s->low_delay) {\n        if (   pict->format == AV_PIX_FMT_YUV420P\n            && (s->codec_tag == AV_RL32(\"GEOV\") || s->codec_tag == AV_RL32(\"GEOX\"))) {\n            int x, y, p;\n            av_frame_make_writable(pict);\n            for (p=0; p<3; p++) {\n                int w = AV_CEIL_RSHIFT(pict-> width, !!p);\n                int h = AV_CEIL_RSHIFT(pict->height, !!p);\n                int linesize = pict->linesize[p];\n                for (y=0; y<(h>>1); y++)\n                    for (x=0; x<w; x++)\n                        FFSWAP(int,\n                               pict->data[p][x + y*linesize],\n                               pict->data[p][x + (h-1-y)*linesize]);\n            }\n        }\n        *got_frame = 1;\n    }\n\n    if (slice_ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n        return slice_ret;\n    else\n        return get_consumed_bytes(s, buf_size);\n}",
        "func": "int ff_h263_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                         AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size       = avpkt->size;\n    MpegEncContext *s  = avctx->priv_data;\n    int ret;\n    int slice_ret = 0;\n    AVFrame *pict = data;\n\n    /* no supplementary picture */\n    if (buf_size == 0) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n\n            *got_frame = 1;\n        }\n\n        return 0;\n    }\n\n    if (s->avctx->flags & AV_CODEC_FLAG_TRUNCATED) {\n        int next;\n\n        if (CONFIG_MPEG4_DECODER && s->codec_id == AV_CODEC_ID_MPEG4) {\n            next = ff_mpeg4_find_frame_end(&s->parse_context, buf, buf_size);\n        } else if (CONFIG_H263_DECODER && s->codec_id == AV_CODEC_ID_H263) {\n            next = ff_h263_find_frame_end(&s->parse_context, buf, buf_size);\n        } else if (CONFIG_H263P_DECODER && s->codec_id == AV_CODEC_ID_H263P) {\n            next = ff_h263_find_frame_end(&s->parse_context, buf, buf_size);\n        } else {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"this codec does not support truncated bitstreams\\n\");\n            return AVERROR(ENOSYS);\n        }\n\n        if (ff_combine_frame(&s->parse_context, next, (const uint8_t **)&buf,\n                             &buf_size) < 0)\n            return buf_size;\n    }\n\nretry:\n    if (s->divx_packed && s->bitstream_buffer_size) {\n        int i;\n        for(i=0; i < buf_size-3; i++) {\n            if (buf[i]==0 && buf[i+1]==0 && buf[i+2]==1) {\n                if (buf[i+3]==0xB0) {\n                    av_log(s->avctx, AV_LOG_WARNING, \"Discarding excessive bitstream in packed xvid\\n\");\n                    s->bitstream_buffer_size = 0;\n                }\n                break;\n            }\n        }\n    }\n\n    if (s->bitstream_buffer_size && (s->divx_packed || buf_size <= MAX_NVOP_SIZE)) // divx 5.01+/xvid frame reorder\n        ret = init_get_bits8(&s->gb, s->bitstream_buffer,\n                             s->bitstream_buffer_size);\n    else\n        ret = init_get_bits8(&s->gb, buf, buf_size);\n\n    s->bitstream_buffer_size = 0;\n    if (ret < 0)\n        return ret;\n\n    if (!s->context_initialized)\n        // we need the idct permutation for reading a custom matrix\n        ff_mpv_idct_init(s);\n\n    /* let's go :-) */\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version == 5) {\n        ret = ff_wmv2_decode_picture_header(s);\n    } else if (CONFIG_MSMPEG4_DECODER && s->msmpeg4_version) {\n        ret = ff_msmpeg4_decode_picture_header(s);\n    } else if (CONFIG_MPEG4_DECODER && avctx->codec_id == AV_CODEC_ID_MPEG4) {\n        if (s->avctx->extradata_size && s->picture_number == 0) {\n            GetBitContext gb;\n\n            if (init_get_bits8(&gb, s->avctx->extradata, s->avctx->extradata_size) >= 0 )\n                ff_mpeg4_decode_picture_header(avctx->priv_data, &gb);\n        }\n        ret = ff_mpeg4_decode_picture_header(avctx->priv_data, &s->gb);\n    } else if (CONFIG_H263I_DECODER && s->codec_id == AV_CODEC_ID_H263I) {\n        ret = ff_intel_h263_decode_picture_header(s);\n    } else if (CONFIG_FLV_DECODER && s->h263_flv) {\n        ret = ff_flv_decode_picture_header(s);\n    } else {\n        ret = ff_h263_decode_picture_header(s);\n    }\n\n    if (ret < 0 || ret == FRAME_SKIPPED) {\n        if (   s->width  != avctx->coded_width\n            || s->height != avctx->coded_height) {\n                av_log(s->avctx, AV_LOG_WARNING, \"Reverting picture dimensions change due to header decoding failure\\n\");\n                s->width = avctx->coded_width;\n                s->height= avctx->coded_height;\n        }\n    }\n    if (ret == FRAME_SKIPPED)\n        return get_consumed_bytes(s, buf_size);\n\n    /* skip if the header was thrashed */\n    if (ret < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"header damaged\\n\");\n        return ret;\n    }\n\n    if (!s->context_initialized) {\n        avctx->pix_fmt = h263_get_format(avctx);\n        if ((ret = ff_mpv_common_init(s)) < 0)\n            return ret;\n    }\n\n    if (!s->current_picture_ptr || s->current_picture_ptr->f->data[0]) {\n        int i = ff_find_unused_picture(s->avctx, s->picture, 0);\n        if (i < 0)\n            return i;\n        s->current_picture_ptr = &s->picture[i];\n    }\n\n    avctx->has_b_frames = !s->low_delay;\n\n    if (CONFIG_MPEG4_DECODER && avctx->codec_id == AV_CODEC_ID_MPEG4) {\n        if (ff_mpeg4_workaround_bugs(avctx) == 1)\n            goto retry;\n        if (s->studio_profile != (s->idsp.idct == NULL))\n            ff_mpv_idct_init(s);\n    }\n\n    /* After H.263 & MPEG-4 header decode we have the height, width,\n     * and other parameters. So then we could init the picture.\n     * FIXME: By the way H.263 decoder is evolving it should have\n     * an H263EncContext */\n    if (s->width  != avctx->coded_width  ||\n        s->height != avctx->coded_height ||\n        s->context_reinit) {\n        /* H.263 could change picture size any time */\n        s->context_reinit = 0;\n\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n        if (ret < 0)\n            return ret;\n\n        ff_set_sar(avctx, avctx->sample_aspect_ratio);\n\n        if ((ret = ff_mpv_common_frame_size_change(s)))\n            return ret;\n\n        if (avctx->pix_fmt != h263_get_format(avctx)) {\n            av_log(avctx, AV_LOG_ERROR, \"format change not supported\\n\");\n            avctx->pix_fmt = AV_PIX_FMT_NONE;\n            return AVERROR_UNKNOWN;\n        }\n    }\n\n    if (s->codec_id == AV_CODEC_ID_H263  ||\n        s->codec_id == AV_CODEC_ID_H263P ||\n        s->codec_id == AV_CODEC_ID_H263I)\n        s->gob_index = H263_GOB_HEIGHT(s->height);\n\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr &&\n        (s->pict_type == AV_PICTURE_TYPE_B || s->droppable))\n        return get_consumed_bytes(s, buf_size);\n    if ((avctx->skip_frame >= AVDISCARD_NONREF &&\n         s->pict_type == AV_PICTURE_TYPE_B)    ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY &&\n         s->pict_type != AV_PICTURE_TYPE_I)    ||\n        avctx->skip_frame >= AVDISCARD_ALL)\n        return get_consumed_bytes(s, buf_size);\n\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            return get_consumed_bytes(s, buf_size);\n        else\n            s->next_p_frame_damaged = 0;\n    }\n\n    if ((!s->no_rounding) || s->pict_type == AV_PICTURE_TYPE_B) {\n        s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n        s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n    } else {\n        s->me.qpel_put = s->qdsp.put_no_rnd_qpel_pixels_tab;\n        s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n    }\n\n    if ((ret = ff_mpv_frame_start(s, avctx)) < 0)\n        return ret;\n\n    if (!s->divx_packed)\n        ff_thread_finish_setup(avctx);\n\n    if (avctx->hwaccel) {\n        ret = avctx->hwaccel->start_frame(avctx, s->gb.buffer,\n                                          s->gb.buffer_end - s->gb.buffer);\n        if (ret < 0 )\n            return ret;\n    }\n\n    ff_mpeg_er_frame_start(s);\n\n    /* the second part of the wmv2 header contains the MB skip bits which\n     * are stored in current_picture->mb_type which is not available before\n     * ff_mpv_frame_start() */\n    if (CONFIG_WMV2_DECODER && s->msmpeg4_version == 5) {\n        ret = ff_wmv2_decode_secondary_picture_header(s);\n        if (ret < 0)\n            return ret;\n        if (ret == 1)\n            goto frame_end;\n    }\n\n    /* decode each macroblock */\n    s->mb_x = 0;\n    s->mb_y = 0;\n\n    slice_ret = decode_slice(s);\n    while (s->mb_y < s->mb_height) {\n        if (s->msmpeg4_version) {\n            if (s->slice_height == 0 || s->mb_x != 0 || slice_ret < 0 ||\n                (s->mb_y % s->slice_height) != 0 || get_bits_left(&s->gb) < 0)\n                break;\n        } else {\n            int prev_x = s->mb_x, prev_y = s->mb_y;\n            if (ff_h263_resync(s) < 0)\n                break;\n            if (prev_y * s->mb_width + prev_x < s->mb_y * s->mb_width + s->mb_x)\n                s->er.error_occurred = 1;\n        }\n\n        if (s->msmpeg4_version < 4 && s->h263_pred)\n            ff_mpeg4_clean_buffers(s);\n\n        if (decode_slice(s) < 0)\n            slice_ret = AVERROR_INVALIDDATA;\n    }\n\n    if (s->msmpeg4_version && s->msmpeg4_version < 4 &&\n        s->pict_type == AV_PICTURE_TYPE_I)\n        if (!CONFIG_MSMPEG4_DECODER ||\n            ff_msmpeg4_decode_ext_header(s, buf_size) < 0)\n            s->er.error_status_table[s->mb_num - 1] = ER_MB_ERROR;\n\n    av_assert1(s->bitstream_buffer_size == 0);\nframe_end:\n    if (!s->studio_profile)\n        ff_er_frame_end(&s->er);\n\n    if (avctx->hwaccel) {\n        ret = avctx->hwaccel->end_frame(avctx);\n        if (ret < 0)\n            return ret;\n    }\n\n    ff_mpv_frame_end(s);\n\n    if (CONFIG_MPEG4_DECODER && avctx->codec_id == AV_CODEC_ID_MPEG4)\n        ff_mpeg4_frame_end(avctx, buf, buf_size);\n\n    if (!s->divx_packed && avctx->hwaccel)\n        ff_thread_finish_setup(avctx);\n\n    av_assert1(s->current_picture.f->pict_type == s->current_picture_ptr->f->pict_type);\n    av_assert1(s->current_picture.f->pict_type == s->pict_type);\n    if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n        if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n            return ret;\n        ff_print_debug_info(s, s->current_picture_ptr, pict);\n        ff_mpv_export_qp_table(s, pict, s->current_picture_ptr, FF_QSCALE_TYPE_MPEG1);\n    } else if (s->last_picture_ptr) {\n        if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n            return ret;\n        ff_print_debug_info(s, s->last_picture_ptr, pict);\n        ff_mpv_export_qp_table(s, pict, s->last_picture_ptr, FF_QSCALE_TYPE_MPEG1);\n    }\n\n    if (s->last_picture_ptr || s->low_delay) {\n        if (   pict->format == AV_PIX_FMT_YUV420P\n            && (s->codec_tag == AV_RL32(\"GEOV\") || s->codec_tag == AV_RL32(\"GEOX\"))) {\n            int x, y, p;\n            av_frame_make_writable(pict);\n            for (p=0; p<3; p++) {\n                int w = AV_CEIL_RSHIFT(pict-> width, !!p);\n                int h = AV_CEIL_RSHIFT(pict->height, !!p);\n                int linesize = pict->linesize[p];\n                for (y=0; y<(h>>1); y++)\n                    for (x=0; x<w; x++)\n                        FFSWAP(int,\n                               pict->data[p][x + y*linesize],\n                               pict->data[p][x + (h-1-y)*linesize]);\n            }\n        }\n        *got_frame = 1;\n    }\n\n    if (slice_ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n        return slice_ret;\n    else\n        return get_consumed_bytes(s, buf_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -250,7 +250,8 @@\n \n     av_assert1(s->bitstream_buffer_size == 0);\n frame_end:\n-    ff_er_frame_end(&s->er);\n+    if (!s->studio_profile)\n+        ff_er_frame_end(&s->er);\n \n     if (avctx->hwaccel) {\n         ret = avctx->hwaccel->end_frame(avctx);",
        "diff_line_info": {
            "deleted_lines": [
                "    ff_er_frame_end(&s->er);"
            ],
            "added_lines": [
                "    if (!s->studio_profile)",
                "        ff_er_frame_end(&s->er);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-13304",
        "func_name": "ffmpeg/h263_get_format",
        "description": "In libavcodec in FFmpeg 4.0.1, improper maintenance of the consistency between the context profile field and studio_profile in libavcodec may trigger an assertion failure while converting a crafted AVI file to MPEG4, leading to a denial of service, related to error_resilience.c, h263dec.c, and mpeg4videodec.c.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/bd27a9364ca274ca97f1df6d984e88a0700fb235",
        "commit_title": "avcodec/mpeg4videodec: Remove use of FF_PROFILE_MPEG4_SIMPLE_STUDIO as indicator of studio profile",
        "commit_text": " The profile field is changed by code inside and outside the decoder, its not a reliable indicator of the internal codec state. Maintaining it consistency with studio_profile is messy. Its easier to just avoid it and use only studio_profile  ",
        "func_before": "static enum AVPixelFormat h263_get_format(AVCodecContext *avctx)\n{\n    /* MPEG-4 Studio Profile only, not supported by hardware */\n    if (avctx->bits_per_raw_sample > 8) {\n        av_assert1(avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO);\n        return avctx->pix_fmt;\n    }\n\n    if (avctx->codec->id == AV_CODEC_ID_MSS2)\n        return AV_PIX_FMT_YUV420P;\n\n    if (CONFIG_GRAY && (avctx->flags & AV_CODEC_FLAG_GRAY)) {\n        if (avctx->color_range == AVCOL_RANGE_UNSPECIFIED)\n            avctx->color_range = AVCOL_RANGE_MPEG;\n        return AV_PIX_FMT_GRAY8;\n    }\n\n    return avctx->pix_fmt = ff_get_format(avctx, avctx->codec->pix_fmts);\n}",
        "func": "static enum AVPixelFormat h263_get_format(AVCodecContext *avctx)\n{\n    MpegEncContext *s = avctx->priv_data;\n    /* MPEG-4 Studio Profile only, not supported by hardware */\n    if (avctx->bits_per_raw_sample > 8) {\n        av_assert1(s->studio_profile);\n        return avctx->pix_fmt;\n    }\n\n    if (avctx->codec->id == AV_CODEC_ID_MSS2)\n        return AV_PIX_FMT_YUV420P;\n\n    if (CONFIG_GRAY && (avctx->flags & AV_CODEC_FLAG_GRAY)) {\n        if (avctx->color_range == AVCOL_RANGE_UNSPECIFIED)\n            avctx->color_range = AVCOL_RANGE_MPEG;\n        return AV_PIX_FMT_GRAY8;\n    }\n\n    return avctx->pix_fmt = ff_get_format(avctx, avctx->codec->pix_fmts);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,9 @@\n static enum AVPixelFormat h263_get_format(AVCodecContext *avctx)\n {\n+    MpegEncContext *s = avctx->priv_data;\n     /* MPEG-4 Studio Profile only, not supported by hardware */\n     if (avctx->bits_per_raw_sample > 8) {\n-        av_assert1(avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO);\n+        av_assert1(s->studio_profile);\n         return avctx->pix_fmt;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        av_assert1(avctx->profile == FF_PROFILE_MPEG4_SIMPLE_STUDIO);"
            ],
            "added_lines": [
                "    MpegEncContext *s = avctx->priv_data;",
                "        av_assert1(s->studio_profile);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_wr_syncv",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "ssize_t nbd_wr_syncv(QIOChannel *ioc,\n                     struct iovec *iov,\n                     size_t niov,\n                     size_t length,\n                     bool do_read)\n{\n    ssize_t done = 0;\n    Error *local_err = NULL;\n    struct iovec *local_iov = g_new(struct iovec, niov);\n    struct iovec *local_iov_head = local_iov;\n    unsigned int nlocal_iov = niov;\n\n    nlocal_iov = iov_copy(local_iov, nlocal_iov, iov, niov, 0, length);\n\n    while (nlocal_iov > 0) {\n        ssize_t len;\n        if (do_read) {\n            len = qio_channel_readv(ioc, local_iov, nlocal_iov, &local_err);\n        } else {\n            len = qio_channel_writev(ioc, local_iov, nlocal_iov, &local_err);\n        }\n        if (len == QIO_CHANNEL_ERR_BLOCK) {\n            if (qemu_in_coroutine()) {\n                /* XXX figure out if we can create a variant on\n                 * qio_channel_yield() that works with AIO contexts\n                 * and consider using that in this branch */\n                qemu_coroutine_yield();\n            } else if (done) {\n                /* XXX this is needed by nbd_reply_ready.  */\n                qio_channel_wait(ioc,\n                                 do_read ? G_IO_IN : G_IO_OUT);\n            } else {\n                return -EAGAIN;\n            }\n            continue;\n        }\n        if (len < 0) {\n            TRACE(\"I/O error: %s\", error_get_pretty(local_err));\n            error_free(local_err);\n            /* XXX handle Error objects */\n            done = -EIO;\n            goto cleanup;\n        }\n\n        if (do_read && len == 0) {\n            break;\n        }\n\n        iov_discard_front(&local_iov, &nlocal_iov, len);\n        done += len;\n    }\n\n cleanup:\n    g_free(local_iov_head);\n    return done;\n}",
        "func": "ssize_t nbd_wr_syncv(QIOChannel *ioc,\n                     struct iovec *iov,\n                     size_t niov,\n                     size_t length,\n                     bool do_read)\n{\n    ssize_t done = 0;\n    Error *local_err = NULL;\n    struct iovec *local_iov = g_new(struct iovec, niov);\n    struct iovec *local_iov_head = local_iov;\n    unsigned int nlocal_iov = niov;\n\n    nlocal_iov = iov_copy(local_iov, nlocal_iov, iov, niov, 0, length);\n\n    while (nlocal_iov > 0) {\n        ssize_t len;\n        if (do_read) {\n            len = qio_channel_readv(ioc, local_iov, nlocal_iov, &local_err);\n        } else {\n            len = qio_channel_writev(ioc, local_iov, nlocal_iov, &local_err);\n        }\n        if (len == QIO_CHANNEL_ERR_BLOCK) {\n            if (qemu_in_coroutine()) {\n                qio_channel_yield(ioc, do_read ? G_IO_IN : G_IO_OUT);\n            } else {\n                return -EAGAIN;\n            }\n            continue;\n        }\n        if (len < 0) {\n            TRACE(\"I/O error: %s\", error_get_pretty(local_err));\n            error_free(local_err);\n            /* XXX handle Error objects */\n            done = -EIO;\n            goto cleanup;\n        }\n\n        if (do_read && len == 0) {\n            break;\n        }\n\n        iov_discard_front(&local_iov, &nlocal_iov, len);\n        done += len;\n    }\n\n cleanup:\n    g_free(local_iov_head);\n    return done;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,14 +21,7 @@\n         }\n         if (len == QIO_CHANNEL_ERR_BLOCK) {\n             if (qemu_in_coroutine()) {\n-                /* XXX figure out if we can create a variant on\n-                 * qio_channel_yield() that works with AIO contexts\n-                 * and consider using that in this branch */\n-                qemu_coroutine_yield();\n-            } else if (done) {\n-                /* XXX this is needed by nbd_reply_ready.  */\n-                qio_channel_wait(ioc,\n-                                 do_read ? G_IO_IN : G_IO_OUT);\n+                qio_channel_yield(ioc, do_read ? G_IO_IN : G_IO_OUT);\n             } else {\n                 return -EAGAIN;\n             }",
        "diff_line_info": {
            "deleted_lines": [
                "                /* XXX figure out if we can create a variant on",
                "                 * qio_channel_yield() that works with AIO contexts",
                "                 * and consider using that in this branch */",
                "                qemu_coroutine_yield();",
                "            } else if (done) {",
                "                /* XXX this is needed by nbd_reply_ready.  */",
                "                qio_channel_wait(ioc,",
                "                                 do_read ? G_IO_IN : G_IO_OUT);"
            ],
            "added_lines": [
                "                qio_channel_yield(ioc, do_read ? G_IO_IN : G_IO_OUT);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_request_get",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static NBDRequestData *nbd_request_get(NBDClient *client)\n{\n    NBDRequestData *req;\n\n    assert(client->nb_requests <= MAX_NBD_REQUESTS - 1);\n    client->nb_requests++;\n    nbd_update_can_read(client);\n\n    req = g_new0(NBDRequestData, 1);\n    nbd_client_get(client);\n    req->client = client;\n    return req;\n}",
        "func": "static NBDRequestData *nbd_request_get(NBDClient *client)\n{\n    NBDRequestData *req;\n\n    assert(client->nb_requests <= MAX_NBD_REQUESTS - 1);\n    client->nb_requests++;\n\n    req = g_new0(NBDRequestData, 1);\n    nbd_client_get(client);\n    req->client = client;\n    return req;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,6 @@\n \n     assert(client->nb_requests <= MAX_NBD_REQUESTS - 1);\n     client->nb_requests++;\n-    nbd_update_can_read(client);\n \n     req = g_new0(NBDRequestData, 1);\n     nbd_client_get(client);",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_update_can_read(client);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_co_receive_request",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static ssize_t nbd_co_receive_request(NBDRequestData *req,\n                                      NBDRequest *request)\n{\n    NBDClient *client = req->client;\n    ssize_t rc;\n\n    g_assert(qemu_in_coroutine());\n    client->recv_coroutine = qemu_coroutine_self();\n    nbd_update_can_read(client);\n\n    rc = nbd_receive_request(client->ioc, request);\n    if (rc < 0) {\n        if (rc != -EAGAIN) {\n            rc = -EIO;\n        }\n        goto out;\n    }\n\n    TRACE(\"Decoding type\");\n\n    if (request->type != NBD_CMD_WRITE) {\n        /* No payload, we are ready to read the next request.  */\n        req->complete = true;\n    }\n\n    if (request->type == NBD_CMD_DISC) {\n        /* Special case: we're going to disconnect without a reply,\n         * whether or not flags, from, or len are bogus */\n        TRACE(\"Request type is DISCONNECT\");\n        rc = -EIO;\n        goto out;\n    }\n\n    /* Check for sanity in the parameters, part 1.  Defer as many\n     * checks as possible until after reading any NBD_CMD_WRITE\n     * payload, so we can try and keep the connection alive.  */\n    if ((request->from + request->len) < request->from) {\n        LOG(\"integer overflow detected, you're probably being attacked\");\n        rc = -EINVAL;\n        goto out;\n    }\n\n    if (request->type == NBD_CMD_READ || request->type == NBD_CMD_WRITE) {\n        if (request->len > NBD_MAX_BUFFER_SIZE) {\n            LOG(\"len (%\" PRIu32\" ) is larger than max len (%u)\",\n                request->len, NBD_MAX_BUFFER_SIZE);\n            rc = -EINVAL;\n            goto out;\n        }\n\n        req->data = blk_try_blockalign(client->exp->blk, request->len);\n        if (req->data == NULL) {\n            rc = -ENOMEM;\n            goto out;\n        }\n    }\n    if (request->type == NBD_CMD_WRITE) {\n        TRACE(\"Reading %\" PRIu32 \" byte(s)\", request->len);\n\n        if (read_sync(client->ioc, req->data, request->len) != request->len) {\n            LOG(\"reading from socket failed\");\n            rc = -EIO;\n            goto out;\n        }\n        req->complete = true;\n    }\n\n    /* Sanity checks, part 2. */\n    if (request->from + request->len > client->exp->size) {\n        LOG(\"operation past EOF; From: %\" PRIu64 \", Len: %\" PRIu32\n            \", Size: %\" PRIu64, request->from, request->len,\n            (uint64_t)client->exp->size);\n        rc = request->type == NBD_CMD_WRITE ? -ENOSPC : -EINVAL;\n        goto out;\n    }\n    if (request->flags & ~(NBD_CMD_FLAG_FUA | NBD_CMD_FLAG_NO_HOLE)) {\n        LOG(\"unsupported flags (got 0x%x)\", request->flags);\n        rc = -EINVAL;\n        goto out;\n    }\n    if (request->type != NBD_CMD_WRITE_ZEROES &&\n        (request->flags & NBD_CMD_FLAG_NO_HOLE)) {\n        LOG(\"unexpected flags (got 0x%x)\", request->flags);\n        rc = -EINVAL;\n        goto out;\n    }\n\n    rc = 0;\n\nout:\n    client->recv_coroutine = NULL;\n    nbd_update_can_read(client);\n\n    return rc;\n}",
        "func": "static ssize_t nbd_co_receive_request(NBDRequestData *req,\n                                      NBDRequest *request)\n{\n    NBDClient *client = req->client;\n    ssize_t rc;\n\n    g_assert(qemu_in_coroutine());\n    assert(client->recv_coroutine == qemu_coroutine_self());\n    rc = nbd_receive_request(client->ioc, request);\n    if (rc < 0) {\n        if (rc != -EAGAIN) {\n            rc = -EIO;\n        }\n        goto out;\n    }\n\n    TRACE(\"Decoding type\");\n\n    if (request->type != NBD_CMD_WRITE) {\n        /* No payload, we are ready to read the next request.  */\n        req->complete = true;\n    }\n\n    if (request->type == NBD_CMD_DISC) {\n        /* Special case: we're going to disconnect without a reply,\n         * whether or not flags, from, or len are bogus */\n        TRACE(\"Request type is DISCONNECT\");\n        rc = -EIO;\n        goto out;\n    }\n\n    /* Check for sanity in the parameters, part 1.  Defer as many\n     * checks as possible until after reading any NBD_CMD_WRITE\n     * payload, so we can try and keep the connection alive.  */\n    if ((request->from + request->len) < request->from) {\n        LOG(\"integer overflow detected, you're probably being attacked\");\n        rc = -EINVAL;\n        goto out;\n    }\n\n    if (request->type == NBD_CMD_READ || request->type == NBD_CMD_WRITE) {\n        if (request->len > NBD_MAX_BUFFER_SIZE) {\n            LOG(\"len (%\" PRIu32\" ) is larger than max len (%u)\",\n                request->len, NBD_MAX_BUFFER_SIZE);\n            rc = -EINVAL;\n            goto out;\n        }\n\n        req->data = blk_try_blockalign(client->exp->blk, request->len);\n        if (req->data == NULL) {\n            rc = -ENOMEM;\n            goto out;\n        }\n    }\n    if (request->type == NBD_CMD_WRITE) {\n        TRACE(\"Reading %\" PRIu32 \" byte(s)\", request->len);\n\n        if (read_sync(client->ioc, req->data, request->len) != request->len) {\n            LOG(\"reading from socket failed\");\n            rc = -EIO;\n            goto out;\n        }\n        req->complete = true;\n    }\n\n    /* Sanity checks, part 2. */\n    if (request->from + request->len > client->exp->size) {\n        LOG(\"operation past EOF; From: %\" PRIu64 \", Len: %\" PRIu32\n            \", Size: %\" PRIu64, request->from, request->len,\n            (uint64_t)client->exp->size);\n        rc = request->type == NBD_CMD_WRITE ? -ENOSPC : -EINVAL;\n        goto out;\n    }\n    if (request->flags & ~(NBD_CMD_FLAG_FUA | NBD_CMD_FLAG_NO_HOLE)) {\n        LOG(\"unsupported flags (got 0x%x)\", request->flags);\n        rc = -EINVAL;\n        goto out;\n    }\n    if (request->type != NBD_CMD_WRITE_ZEROES &&\n        (request->flags & NBD_CMD_FLAG_NO_HOLE)) {\n        LOG(\"unexpected flags (got 0x%x)\", request->flags);\n        rc = -EINVAL;\n        goto out;\n    }\n\n    rc = 0;\n\nout:\n    client->recv_coroutine = NULL;\n    nbd_client_receive_next_request(client);\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,9 +5,7 @@\n     ssize_t rc;\n \n     g_assert(qemu_in_coroutine());\n-    client->recv_coroutine = qemu_coroutine_self();\n-    nbd_update_can_read(client);\n-\n+    assert(client->recv_coroutine == qemu_coroutine_self());\n     rc = nbd_receive_request(client->ioc, request);\n     if (rc < 0) {\n         if (rc != -EAGAIN) {\n@@ -89,7 +87,7 @@\n \n out:\n     client->recv_coroutine = NULL;\n-    nbd_update_can_read(client);\n+    nbd_client_receive_next_request(client);\n \n     return rc;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    client->recv_coroutine = qemu_coroutine_self();",
                "    nbd_update_can_read(client);",
                "",
                "    nbd_update_can_read(client);"
            ],
            "added_lines": [
                "    assert(client->recv_coroutine == qemu_coroutine_self());",
                "    nbd_client_receive_next_request(client);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_request_put",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void nbd_request_put(NBDRequestData *req)\n{\n    NBDClient *client = req->client;\n\n    if (req->data) {\n        qemu_vfree(req->data);\n    }\n    g_free(req);\n\n    client->nb_requests--;\n    nbd_update_can_read(client);\n    nbd_client_put(client);\n}",
        "func": "static void nbd_request_put(NBDRequestData *req)\n{\n    NBDClient *client = req->client;\n\n    if (req->data) {\n        qemu_vfree(req->data);\n    }\n    g_free(req);\n\n    client->nb_requests--;\n    nbd_client_receive_next_request(client);\n\n    nbd_client_put(client);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,7 @@\n     g_free(req);\n \n     client->nb_requests--;\n-    nbd_update_can_read(client);\n+    nbd_client_receive_next_request(client);\n+\n     nbd_client_put(client);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_update_can_read(client);"
            ],
            "added_lines": [
                "    nbd_client_receive_next_request(client);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_new",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "void nbd_client_new(NBDExport *exp,\n                    QIOChannelSocket *sioc,\n                    QCryptoTLSCreds *tlscreds,\n                    const char *tlsaclname,\n                    void (*close_fn)(NBDClient *))\n{\n    NBDClient *client;\n    NBDClientNewData *data = g_new(NBDClientNewData, 1);\n\n    client = g_malloc0(sizeof(NBDClient));\n    client->refcount = 1;\n    client->exp = exp;\n    client->tlscreds = tlscreds;\n    if (tlscreds) {\n        object_ref(OBJECT(client->tlscreds));\n    }\n    client->tlsaclname = g_strdup(tlsaclname);\n    client->sioc = sioc;\n    object_ref(OBJECT(client->sioc));\n    client->ioc = QIO_CHANNEL(sioc);\n    object_ref(OBJECT(client->ioc));\n    client->can_read = true;\n    client->close = close_fn;\n\n    data->client = client;\n    data->co = qemu_coroutine_create(nbd_co_client_start, data);\n    qemu_coroutine_enter(data->co);\n}",
        "func": "void nbd_client_new(NBDExport *exp,\n                    QIOChannelSocket *sioc,\n                    QCryptoTLSCreds *tlscreds,\n                    const char *tlsaclname,\n                    void (*close_fn)(NBDClient *))\n{\n    NBDClient *client;\n    NBDClientNewData *data = g_new(NBDClientNewData, 1);\n\n    client = g_malloc0(sizeof(NBDClient));\n    client->refcount = 1;\n    client->exp = exp;\n    client->tlscreds = tlscreds;\n    if (tlscreds) {\n        object_ref(OBJECT(client->tlscreds));\n    }\n    client->tlsaclname = g_strdup(tlsaclname);\n    client->sioc = sioc;\n    object_ref(OBJECT(client->sioc));\n    client->ioc = QIO_CHANNEL(sioc);\n    object_ref(OBJECT(client->ioc));\n    client->close = close_fn;\n\n    data->client = client;\n    data->co = qemu_coroutine_create(nbd_co_client_start, data);\n    qemu_coroutine_enter(data->co);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,7 +19,6 @@\n     object_ref(OBJECT(client->sioc));\n     client->ioc = QIO_CHANNEL(sioc);\n     object_ref(OBJECT(client->ioc));\n-    client->can_read = true;\n     client->close = close_fn;\n \n     data->client = client;",
        "diff_line_info": {
            "deleted_lines": [
                "    client->can_read = true;"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_co_send_reply",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static ssize_t nbd_co_send_reply(NBDRequestData *req, NBDReply *reply,\n                                 int len)\n{\n    NBDClient *client = req->client;\n    ssize_t rc, ret;\n\n    g_assert(qemu_in_coroutine());\n    qemu_co_mutex_lock(&client->send_lock);\n    client->send_coroutine = qemu_coroutine_self();\n    nbd_set_handlers(client);\n\n    if (!len) {\n        rc = nbd_send_reply(client->ioc, reply);\n    } else {\n        qio_channel_set_cork(client->ioc, true);\n        rc = nbd_send_reply(client->ioc, reply);\n        if (rc >= 0) {\n            ret = write_sync(client->ioc, req->data, len);\n            if (ret != len) {\n                rc = -EIO;\n            }\n        }\n        qio_channel_set_cork(client->ioc, false);\n    }\n\n    client->send_coroutine = NULL;\n    nbd_set_handlers(client);\n    qemu_co_mutex_unlock(&client->send_lock);\n    return rc;\n}",
        "func": "static ssize_t nbd_co_send_reply(NBDRequestData *req, NBDReply *reply,\n                                 int len)\n{\n    NBDClient *client = req->client;\n    ssize_t rc, ret;\n\n    g_assert(qemu_in_coroutine());\n    qemu_co_mutex_lock(&client->send_lock);\n    client->send_coroutine = qemu_coroutine_self();\n\n    if (!len) {\n        rc = nbd_send_reply(client->ioc, reply);\n    } else {\n        qio_channel_set_cork(client->ioc, true);\n        rc = nbd_send_reply(client->ioc, reply);\n        if (rc >= 0) {\n            ret = write_sync(client->ioc, req->data, len);\n            if (ret != len) {\n                rc = -EIO;\n            }\n        }\n        qio_channel_set_cork(client->ioc, false);\n    }\n\n    client->send_coroutine = NULL;\n    qemu_co_mutex_unlock(&client->send_lock);\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,6 @@\n     g_assert(qemu_in_coroutine());\n     qemu_co_mutex_lock(&client->send_lock);\n     client->send_coroutine = qemu_coroutine_self();\n-    nbd_set_handlers(client);\n \n     if (!len) {\n         rc = nbd_send_reply(client->ioc, reply);\n@@ -24,7 +23,6 @@\n     }\n \n     client->send_coroutine = NULL;\n-    nbd_set_handlers(client);\n     qemu_co_mutex_unlock(&client->send_lock);\n     return rc;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_set_handlers(client);",
                "    nbd_set_handlers(client);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_trip",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void nbd_trip(void *opaque)\n{\n    NBDClient *client = opaque;\n    NBDExport *exp = client->exp;\n    NBDRequestData *req;\n    NBDRequest request;\n    NBDReply reply;\n    ssize_t ret;\n    int flags;\n\n    TRACE(\"Reading request.\");\n    if (client->closing) {\n        return;\n    }\n\n    req = nbd_request_get(client);\n    ret = nbd_co_receive_request(req, &request);\n    if (ret == -EAGAIN) {\n        goto done;\n    }\n    if (ret == -EIO) {\n        goto out;\n    }\n\n    reply.handle = request.handle;\n    reply.error = 0;\n\n    if (ret < 0) {\n        reply.error = -ret;\n        goto error_reply;\n    }\n\n    if (client->closing) {\n        /*\n         * The client may be closed when we are blocked in\n         * nbd_co_receive_request()\n         */\n        goto done;\n    }\n\n    switch (request.type) {\n    case NBD_CMD_READ:\n        TRACE(\"Request type is READ\");\n\n        /* XXX: NBD Protocol only documents use of FUA with WRITE */\n        if (request.flags & NBD_CMD_FLAG_FUA) {\n            ret = blk_co_flush(exp->blk);\n            if (ret < 0) {\n                LOG(\"flush failed\");\n                reply.error = -ret;\n                goto error_reply;\n            }\n        }\n\n        ret = blk_pread(exp->blk, request.from + exp->dev_offset,\n                        req->data, request.len);\n        if (ret < 0) {\n            LOG(\"reading from file failed\");\n            reply.error = -ret;\n            goto error_reply;\n        }\n\n        TRACE(\"Read %\" PRIu32\" byte(s)\", request.len);\n        if (nbd_co_send_reply(req, &reply, request.len) < 0)\n            goto out;\n        break;\n    case NBD_CMD_WRITE:\n        TRACE(\"Request type is WRITE\");\n\n        if (exp->nbdflags & NBD_FLAG_READ_ONLY) {\n            TRACE(\"Server is read-only, return error\");\n            reply.error = EROFS;\n            goto error_reply;\n        }\n\n        TRACE(\"Writing to device\");\n\n        flags = 0;\n        if (request.flags & NBD_CMD_FLAG_FUA) {\n            flags |= BDRV_REQ_FUA;\n        }\n        ret = blk_pwrite(exp->blk, request.from + exp->dev_offset,\n                         req->data, request.len, flags);\n        if (ret < 0) {\n            LOG(\"writing to file failed\");\n            reply.error = -ret;\n            goto error_reply;\n        }\n\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n\n    case NBD_CMD_WRITE_ZEROES:\n        TRACE(\"Request type is WRITE_ZEROES\");\n\n        if (exp->nbdflags & NBD_FLAG_READ_ONLY) {\n            TRACE(\"Server is read-only, return error\");\n            reply.error = EROFS;\n            goto error_reply;\n        }\n\n        TRACE(\"Writing to device\");\n\n        flags = 0;\n        if (request.flags & NBD_CMD_FLAG_FUA) {\n            flags |= BDRV_REQ_FUA;\n        }\n        if (!(request.flags & NBD_CMD_FLAG_NO_HOLE)) {\n            flags |= BDRV_REQ_MAY_UNMAP;\n        }\n        ret = blk_pwrite_zeroes(exp->blk, request.from + exp->dev_offset,\n                                request.len, flags);\n        if (ret < 0) {\n            LOG(\"writing to file failed\");\n            reply.error = -ret;\n            goto error_reply;\n        }\n\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n\n    case NBD_CMD_DISC:\n        /* unreachable, thanks to special case in nbd_co_receive_request() */\n        abort();\n\n    case NBD_CMD_FLUSH:\n        TRACE(\"Request type is FLUSH\");\n\n        ret = blk_co_flush(exp->blk);\n        if (ret < 0) {\n            LOG(\"flush failed\");\n            reply.error = -ret;\n        }\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n    case NBD_CMD_TRIM:\n        TRACE(\"Request type is TRIM\");\n        ret = blk_co_pdiscard(exp->blk, request.from + exp->dev_offset,\n                              request.len);\n        if (ret < 0) {\n            LOG(\"discard failed\");\n            reply.error = -ret;\n        }\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n    default:\n        LOG(\"invalid request type (%\" PRIu32 \") received\", request.type);\n        reply.error = EINVAL;\n    error_reply:\n        /* We must disconnect after NBD_CMD_WRITE if we did not\n         * read the payload.\n         */\n        if (nbd_co_send_reply(req, &reply, 0) < 0 || !req->complete) {\n            goto out;\n        }\n        break;\n    }\n\n    TRACE(\"Request/Reply complete\");\n\ndone:\n    nbd_request_put(req);\n    return;\n\nout:\n    nbd_request_put(req);\n    client_close(client);\n}",
        "func": "static coroutine_fn void nbd_trip(void *opaque)\n{\n    NBDClient *client = opaque;\n    NBDExport *exp = client->exp;\n    NBDRequestData *req;\n    NBDRequest request = { 0 };    /* GCC thinks it can be used uninitialized */\n    NBDReply reply;\n    ssize_t ret;\n    int flags;\n\n    TRACE(\"Reading request.\");\n    if (client->closing) {\n        nbd_client_put(client);\n        return;\n    }\n\n    req = nbd_request_get(client);\n    ret = nbd_co_receive_request(req, &request);\n    if (ret == -EAGAIN) {\n        goto done;\n    }\n    if (ret == -EIO) {\n        goto out;\n    }\n\n    reply.handle = request.handle;\n    reply.error = 0;\n\n    if (ret < 0) {\n        reply.error = -ret;\n        goto error_reply;\n    }\n\n    if (client->closing) {\n        /*\n         * The client may be closed when we are blocked in\n         * nbd_co_receive_request()\n         */\n        goto done;\n    }\n\n    switch (request.type) {\n    case NBD_CMD_READ:\n        TRACE(\"Request type is READ\");\n\n        /* XXX: NBD Protocol only documents use of FUA with WRITE */\n        if (request.flags & NBD_CMD_FLAG_FUA) {\n            ret = blk_co_flush(exp->blk);\n            if (ret < 0) {\n                LOG(\"flush failed\");\n                reply.error = -ret;\n                goto error_reply;\n            }\n        }\n\n        ret = blk_pread(exp->blk, request.from + exp->dev_offset,\n                        req->data, request.len);\n        if (ret < 0) {\n            LOG(\"reading from file failed\");\n            reply.error = -ret;\n            goto error_reply;\n        }\n\n        TRACE(\"Read %\" PRIu32\" byte(s)\", request.len);\n        if (nbd_co_send_reply(req, &reply, request.len) < 0)\n            goto out;\n        break;\n    case NBD_CMD_WRITE:\n        TRACE(\"Request type is WRITE\");\n\n        if (exp->nbdflags & NBD_FLAG_READ_ONLY) {\n            TRACE(\"Server is read-only, return error\");\n            reply.error = EROFS;\n            goto error_reply;\n        }\n\n        TRACE(\"Writing to device\");\n\n        flags = 0;\n        if (request.flags & NBD_CMD_FLAG_FUA) {\n            flags |= BDRV_REQ_FUA;\n        }\n        ret = blk_pwrite(exp->blk, request.from + exp->dev_offset,\n                         req->data, request.len, flags);\n        if (ret < 0) {\n            LOG(\"writing to file failed\");\n            reply.error = -ret;\n            goto error_reply;\n        }\n\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n\n    case NBD_CMD_WRITE_ZEROES:\n        TRACE(\"Request type is WRITE_ZEROES\");\n\n        if (exp->nbdflags & NBD_FLAG_READ_ONLY) {\n            TRACE(\"Server is read-only, return error\");\n            reply.error = EROFS;\n            goto error_reply;\n        }\n\n        TRACE(\"Writing to device\");\n\n        flags = 0;\n        if (request.flags & NBD_CMD_FLAG_FUA) {\n            flags |= BDRV_REQ_FUA;\n        }\n        if (!(request.flags & NBD_CMD_FLAG_NO_HOLE)) {\n            flags |= BDRV_REQ_MAY_UNMAP;\n        }\n        ret = blk_pwrite_zeroes(exp->blk, request.from + exp->dev_offset,\n                                request.len, flags);\n        if (ret < 0) {\n            LOG(\"writing to file failed\");\n            reply.error = -ret;\n            goto error_reply;\n        }\n\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n\n    case NBD_CMD_DISC:\n        /* unreachable, thanks to special case in nbd_co_receive_request() */\n        abort();\n\n    case NBD_CMD_FLUSH:\n        TRACE(\"Request type is FLUSH\");\n\n        ret = blk_co_flush(exp->blk);\n        if (ret < 0) {\n            LOG(\"flush failed\");\n            reply.error = -ret;\n        }\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n    case NBD_CMD_TRIM:\n        TRACE(\"Request type is TRIM\");\n        ret = blk_co_pdiscard(exp->blk, request.from + exp->dev_offset,\n                              request.len);\n        if (ret < 0) {\n            LOG(\"discard failed\");\n            reply.error = -ret;\n        }\n        if (nbd_co_send_reply(req, &reply, 0) < 0) {\n            goto out;\n        }\n        break;\n    default:\n        LOG(\"invalid request type (%\" PRIu32 \") received\", request.type);\n        reply.error = EINVAL;\n    error_reply:\n        /* We must disconnect after NBD_CMD_WRITE if we did not\n         * read the payload.\n         */\n        if (nbd_co_send_reply(req, &reply, 0) < 0 || !req->complete) {\n            goto out;\n        }\n        break;\n    }\n\n    TRACE(\"Request/Reply complete\");\n\ndone:\n    nbd_request_put(req);\n    nbd_client_put(client);\n    return;\n\nout:\n    nbd_request_put(req);\n    client_close(client);\n    nbd_client_put(client);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,15 +1,16 @@\n-static void nbd_trip(void *opaque)\n+static coroutine_fn void nbd_trip(void *opaque)\n {\n     NBDClient *client = opaque;\n     NBDExport *exp = client->exp;\n     NBDRequestData *req;\n-    NBDRequest request;\n+    NBDRequest request = { 0 };    /* GCC thinks it can be used uninitialized */\n     NBDReply reply;\n     ssize_t ret;\n     int flags;\n \n     TRACE(\"Reading request.\");\n     if (client->closing) {\n+        nbd_client_put(client);\n         return;\n     }\n \n@@ -168,9 +169,11 @@\n \n done:\n     nbd_request_put(req);\n+    nbd_client_put(client);\n     return;\n \n out:\n     nbd_request_put(req);\n     client_close(client);\n+    nbd_client_put(client);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static void nbd_trip(void *opaque)",
                "    NBDRequest request;"
            ],
            "added_lines": [
                "static coroutine_fn void nbd_trip(void *opaque)",
                "    NBDRequest request = { 0 };    /* GCC thinks it can be used uninitialized */",
                "        nbd_client_put(client);",
                "    nbd_client_put(client);",
                "    nbd_client_put(client);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_co_client_start",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static coroutine_fn void nbd_co_client_start(void *opaque)\n{\n    NBDClientNewData *data = opaque;\n    NBDClient *client = data->client;\n    NBDExport *exp = client->exp;\n\n    if (exp) {\n        nbd_export_get(exp);\n    }\n    if (nbd_negotiate(data)) {\n        client_close(client);\n        goto out;\n    }\n    qemu_co_mutex_init(&client->send_lock);\n    nbd_set_handlers(client);\n\n    if (exp) {\n        QTAILQ_INSERT_TAIL(&exp->clients, client, next);\n    }\nout:\n    g_free(data);\n}",
        "func": "static coroutine_fn void nbd_co_client_start(void *opaque)\n{\n    NBDClientNewData *data = opaque;\n    NBDClient *client = data->client;\n    NBDExport *exp = client->exp;\n\n    if (exp) {\n        nbd_export_get(exp);\n    }\n    if (nbd_negotiate(data)) {\n        client_close(client);\n        goto out;\n    }\n    qemu_co_mutex_init(&client->send_lock);\n\n    if (exp) {\n        QTAILQ_INSERT_TAIL(&exp->clients, client, next);\n    }\n\n    nbd_client_receive_next_request(client);\n\nout:\n    g_free(data);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,11 +12,13 @@\n         goto out;\n     }\n     qemu_co_mutex_init(&client->send_lock);\n-    nbd_set_handlers(client);\n \n     if (exp) {\n         QTAILQ_INSERT_TAIL(&exp->clients, client, next);\n     }\n+\n+    nbd_client_receive_next_request(client);\n+\n out:\n     g_free(data);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_set_handlers(client);"
            ],
            "added_lines": [
                "",
                "    nbd_client_receive_next_request(client);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_put",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "void nbd_client_put(NBDClient *client)\n{\n    if (--client->refcount == 0) {\n        /* The last reference should be dropped by client->close,\n         * which is called by client_close.\n         */\n        assert(client->closing);\n\n        nbd_unset_handlers(client);\n        object_unref(OBJECT(client->sioc));\n        object_unref(OBJECT(client->ioc));\n        if (client->tlscreds) {\n            object_unref(OBJECT(client->tlscreds));\n        }\n        g_free(client->tlsaclname);\n        if (client->exp) {\n            QTAILQ_REMOVE(&client->exp->clients, client, next);\n            nbd_export_put(client->exp);\n        }\n        g_free(client);\n    }\n}",
        "func": "void nbd_client_put(NBDClient *client)\n{\n    if (--client->refcount == 0) {\n        /* The last reference should be dropped by client->close,\n         * which is called by client_close.\n         */\n        assert(client->closing);\n\n        qio_channel_detach_aio_context(client->ioc);\n        object_unref(OBJECT(client->sioc));\n        object_unref(OBJECT(client->ioc));\n        if (client->tlscreds) {\n            object_unref(OBJECT(client->tlscreds));\n        }\n        g_free(client->tlsaclname);\n        if (client->exp) {\n            QTAILQ_REMOVE(&client->exp->clients, client, next);\n            nbd_export_put(client->exp);\n        }\n        g_free(client);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n          */\n         assert(client->closing);\n \n-        nbd_unset_handlers(client);\n+        qio_channel_detach_aio_context(client->ioc);\n         object_unref(OBJECT(client->sioc));\n         object_unref(OBJECT(client->ioc));\n         if (client->tlscreds) {",
        "diff_line_info": {
            "deleted_lines": [
                "        nbd_unset_handlers(client);"
            ],
            "added_lines": [
                "        qio_channel_detach_aio_context(client->ioc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/blk_aio_attached",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void blk_aio_attached(AioContext *ctx, void *opaque)\n{\n    NBDExport *exp = opaque;\n    NBDClient *client;\n\n    TRACE(\"Export %s: Attaching clients to AIO context %p\\n\", exp->name, ctx);\n\n    exp->ctx = ctx;\n\n    QTAILQ_FOREACH(client, &exp->clients, next) {\n        nbd_set_handlers(client);\n    }\n}",
        "func": "static void blk_aio_attached(AioContext *ctx, void *opaque)\n{\n    NBDExport *exp = opaque;\n    NBDClient *client;\n\n    TRACE(\"Export %s: Attaching clients to AIO context %p\\n\", exp->name, ctx);\n\n    exp->ctx = ctx;\n\n    QTAILQ_FOREACH(client, &exp->clients, next) {\n        qio_channel_attach_aio_context(client->ioc, ctx);\n        if (client->recv_coroutine) {\n            aio_co_schedule(ctx, client->recv_coroutine);\n        }\n        if (client->send_coroutine) {\n            aio_co_schedule(ctx, client->send_coroutine);\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,12 @@\n     exp->ctx = ctx;\n \n     QTAILQ_FOREACH(client, &exp->clients, next) {\n-        nbd_set_handlers(client);\n+        qio_channel_attach_aio_context(client->ioc, ctx);\n+        if (client->recv_coroutine) {\n+            aio_co_schedule(ctx, client->recv_coroutine);\n+        }\n+        if (client->send_coroutine) {\n+            aio_co_schedule(ctx, client->send_coroutine);\n+        }\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        nbd_set_handlers(client);"
            ],
            "added_lines": [
                "        qio_channel_attach_aio_context(client->ioc, ctx);",
                "        if (client->recv_coroutine) {",
                "            aio_co_schedule(ctx, client->recv_coroutine);",
                "        }",
                "        if (client->send_coroutine) {",
                "            aio_co_schedule(ctx, client->send_coroutine);",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/blk_aio_detach",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void blk_aio_detach(void *opaque)\n{\n    NBDExport *exp = opaque;\n    NBDClient *client;\n\n    TRACE(\"Export %s: Detaching clients from AIO context %p\\n\", exp->name, exp->ctx);\n\n    QTAILQ_FOREACH(client, &exp->clients, next) {\n        nbd_unset_handlers(client);\n    }\n\n    exp->ctx = NULL;\n}",
        "func": "static void blk_aio_detach(void *opaque)\n{\n    NBDExport *exp = opaque;\n    NBDClient *client;\n\n    TRACE(\"Export %s: Detaching clients from AIO context %p\\n\", exp->name, exp->ctx);\n\n    QTAILQ_FOREACH(client, &exp->clients, next) {\n        qio_channel_detach_aio_context(client->ioc);\n    }\n\n    exp->ctx = NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n     TRACE(\"Export %s: Detaching clients from AIO context %p\\n\", exp->name, exp->ctx);\n \n     QTAILQ_FOREACH(client, &exp->clients, next) {\n-        nbd_unset_handlers(client);\n+        qio_channel_detach_aio_context(client->ioc);\n     }\n \n     exp->ctx = NULL;",
        "diff_line_info": {
            "deleted_lines": [
                "        nbd_unset_handlers(client);"
            ],
            "added_lines": [
                "        qio_channel_detach_aio_context(client->ioc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_receive_reply",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "ssize_t nbd_receive_reply(QIOChannel *ioc, NBDReply *reply)\n{\n    uint8_t buf[NBD_REPLY_SIZE];\n    uint32_t magic;\n    ssize_t ret;\n\n    ret = read_sync(ioc, buf, sizeof(buf));\n    if (ret < 0) {\n        return ret;\n    }\n\n    if (ret != sizeof(buf)) {\n        LOG(\"read failed\");\n        return -EINVAL;\n    }\n\n    /* Reply\n       [ 0 ..  3]    magic   (NBD_REPLY_MAGIC)\n       [ 4 ..  7]    error   (0 == no error)\n       [ 7 .. 15]    handle\n     */\n\n    magic = ldl_be_p(buf);\n    reply->error  = ldl_be_p(buf + 4);\n    reply->handle = ldq_be_p(buf + 8);\n\n    reply->error = nbd_errno_to_system_errno(reply->error);\n\n    if (reply->error == ESHUTDOWN) {\n        /* This works even on mingw which lacks a native ESHUTDOWN */\n        LOG(\"server shutting down\");\n        return -EINVAL;\n    }\n    TRACE(\"Got reply: { magic = 0x%\" PRIx32 \", .error = % \" PRId32\n          \", handle = %\" PRIu64\" }\",\n          magic, reply->error, reply->handle);\n\n    if (magic != NBD_REPLY_MAGIC) {\n        LOG(\"invalid magic (got 0x%\" PRIx32 \")\", magic);\n        return -EINVAL;\n    }\n    return 0;\n}",
        "func": "ssize_t nbd_receive_reply(QIOChannel *ioc, NBDReply *reply)\n{\n    uint8_t buf[NBD_REPLY_SIZE];\n    uint32_t magic;\n    ssize_t ret;\n\n    ret = read_sync(ioc, buf, sizeof(buf));\n    if (ret <= 0) {\n        return ret;\n    }\n\n    if (ret != sizeof(buf)) {\n        LOG(\"read failed\");\n        return -EINVAL;\n    }\n\n    /* Reply\n       [ 0 ..  3]    magic   (NBD_REPLY_MAGIC)\n       [ 4 ..  7]    error   (0 == no error)\n       [ 7 .. 15]    handle\n     */\n\n    magic = ldl_be_p(buf);\n    reply->error  = ldl_be_p(buf + 4);\n    reply->handle = ldq_be_p(buf + 8);\n\n    reply->error = nbd_errno_to_system_errno(reply->error);\n\n    if (reply->error == ESHUTDOWN) {\n        /* This works even on mingw which lacks a native ESHUTDOWN */\n        LOG(\"server shutting down\");\n        return -EINVAL;\n    }\n    TRACE(\"Got reply: { magic = 0x%\" PRIx32 \", .error = % \" PRId32\n          \", handle = %\" PRIu64\" }\",\n          magic, reply->error, reply->handle);\n\n    if (magic != NBD_REPLY_MAGIC) {\n        LOG(\"invalid magic (got 0x%\" PRIx32 \")\", magic);\n        return -EINVAL;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n     ssize_t ret;\n \n     ret = read_sync(ioc, buf, sizeof(buf));\n-    if (ret < 0) {\n+    if (ret <= 0) {\n         return ret;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (ret < 0) {"
            ],
            "added_lines": [
                "    if (ret <= 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_coroutine_end",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void nbd_coroutine_end(NBDClientSession *s,\n                              NBDRequest *request)\n{\n    int i = HANDLE_TO_INDEX(s, request->handle);\n    s->recv_coroutine[i] = NULL;\n    if (s->in_flight-- == MAX_NBD_REQUESTS) {\n        qemu_co_queue_next(&s->free_sema);\n    }\n}",
        "func": "static void nbd_coroutine_end(BlockDriverState *bs,\n                              NBDRequest *request)\n{\n    NBDClientSession *s = nbd_get_client_session(bs);\n    int i = HANDLE_TO_INDEX(s, request->handle);\n\n    s->recv_coroutine[i] = NULL;\n    s->in_flight--;\n    qemu_co_queue_next(&s->free_sema);\n\n    /* Kick the read_reply_co to get the next reply.  */\n    if (s->read_reply_co) {\n        aio_co_wake(s->read_reply_co);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,15 @@\n-static void nbd_coroutine_end(NBDClientSession *s,\n+static void nbd_coroutine_end(BlockDriverState *bs,\n                               NBDRequest *request)\n {\n+    NBDClientSession *s = nbd_get_client_session(bs);\n     int i = HANDLE_TO_INDEX(s, request->handle);\n+\n     s->recv_coroutine[i] = NULL;\n-    if (s->in_flight-- == MAX_NBD_REQUESTS) {\n-        qemu_co_queue_next(&s->free_sema);\n+    s->in_flight--;\n+    qemu_co_queue_next(&s->free_sema);\n+\n+    /* Kick the read_reply_co to get the next reply.  */\n+    if (s->read_reply_co) {\n+        aio_co_wake(s->read_reply_co);\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static void nbd_coroutine_end(NBDClientSession *s,",
                "    if (s->in_flight-- == MAX_NBD_REQUESTS) {",
                "        qemu_co_queue_next(&s->free_sema);"
            ],
            "added_lines": [
                "static void nbd_coroutine_end(BlockDriverState *bs,",
                "    NBDClientSession *s = nbd_get_client_session(bs);",
                "",
                "    s->in_flight--;",
                "    qemu_co_queue_next(&s->free_sema);",
                "",
                "    /* Kick the read_reply_co to get the next reply.  */",
                "    if (s->read_reply_co) {",
                "        aio_co_wake(s->read_reply_co);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_co_flush",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "int nbd_client_co_flush(BlockDriverState *bs)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = { .type = NBD_CMD_FLUSH };\n    NBDReply reply;\n    ssize_t ret;\n\n    if (!(client->nbdflags & NBD_FLAG_SEND_FLUSH)) {\n        return 0;\n    }\n\n    request.from = 0;\n    request.len = 0;\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(client, &request);\n    return -reply.error;\n}",
        "func": "int nbd_client_co_flush(BlockDriverState *bs)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = { .type = NBD_CMD_FLUSH };\n    NBDReply reply;\n    ssize_t ret;\n\n    if (!(client->nbdflags & NBD_FLAG_SEND_FLUSH)) {\n        return 0;\n    }\n\n    request.from = 0;\n    request.len = 0;\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(bs, &request);\n    return -reply.error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,6 @@\n     } else {\n         nbd_co_receive_reply(client, &request, &reply, NULL);\n     }\n-    nbd_coroutine_end(client, &request);\n+    nbd_coroutine_end(bs, &request);\n     return -reply.error;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_coroutine_end(client, &request);"
            ],
            "added_lines": [
                "    nbd_coroutine_end(bs, &request);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_co_pwrite_zeroes",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "int nbd_client_co_pwrite_zeroes(BlockDriverState *bs, int64_t offset,\n                                int count, BdrvRequestFlags flags)\n{\n    ssize_t ret;\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_WRITE_ZEROES,\n        .from = offset,\n        .len = count,\n    };\n    NBDReply reply;\n\n    if (!(client->nbdflags & NBD_FLAG_SEND_WRITE_ZEROES)) {\n        return -ENOTSUP;\n    }\n\n    if (flags & BDRV_REQ_FUA) {\n        assert(client->nbdflags & NBD_FLAG_SEND_FUA);\n        request.flags |= NBD_CMD_FLAG_FUA;\n    }\n    if (!(flags & BDRV_REQ_MAY_UNMAP)) {\n        request.flags |= NBD_CMD_FLAG_NO_HOLE;\n    }\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(client, &request);\n    return -reply.error;\n}",
        "func": "int nbd_client_co_pwrite_zeroes(BlockDriverState *bs, int64_t offset,\n                                int count, BdrvRequestFlags flags)\n{\n    ssize_t ret;\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_WRITE_ZEROES,\n        .from = offset,\n        .len = count,\n    };\n    NBDReply reply;\n\n    if (!(client->nbdflags & NBD_FLAG_SEND_WRITE_ZEROES)) {\n        return -ENOTSUP;\n    }\n\n    if (flags & BDRV_REQ_FUA) {\n        assert(client->nbdflags & NBD_FLAG_SEND_FUA);\n        request.flags |= NBD_CMD_FLAG_FUA;\n    }\n    if (!(flags & BDRV_REQ_MAY_UNMAP)) {\n        request.flags |= NBD_CMD_FLAG_NO_HOLE;\n    }\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(bs, &request);\n    return -reply.error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,6 +29,6 @@\n     } else {\n         nbd_co_receive_reply(client, &request, &reply, NULL);\n     }\n-    nbd_coroutine_end(client, &request);\n+    nbd_coroutine_end(bs, &request);\n     return -reply.error;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_coroutine_end(client, &request);"
            ],
            "added_lines": [
                "    nbd_coroutine_end(bs, &request);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_init",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "int nbd_client_init(BlockDriverState *bs,\n                    QIOChannelSocket *sioc,\n                    const char *export,\n                    QCryptoTLSCreds *tlscreds,\n                    const char *hostname,\n                    Error **errp)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    int ret;\n\n    /* NBD handshake */\n    logout(\"session init %s\\n\", export);\n    qio_channel_set_blocking(QIO_CHANNEL(sioc), true, NULL);\n\n    ret = nbd_receive_negotiate(QIO_CHANNEL(sioc), export,\n                                &client->nbdflags,\n                                tlscreds, hostname,\n                                &client->ioc,\n                                &client->size, errp);\n    if (ret < 0) {\n        logout(\"Failed to negotiate with the NBD server\\n\");\n        return ret;\n    }\n    if (client->nbdflags & NBD_FLAG_SEND_FUA) {\n        bs->supported_write_flags = BDRV_REQ_FUA;\n        bs->supported_zero_flags |= BDRV_REQ_FUA;\n    }\n    if (client->nbdflags & NBD_FLAG_SEND_WRITE_ZEROES) {\n        bs->supported_zero_flags |= BDRV_REQ_MAY_UNMAP;\n    }\n\n    qemu_co_mutex_init(&client->send_mutex);\n    qemu_co_queue_init(&client->free_sema);\n    client->sioc = sioc;\n    object_ref(OBJECT(client->sioc));\n\n    if (!client->ioc) {\n        client->ioc = QIO_CHANNEL(sioc);\n        object_ref(OBJECT(client->ioc));\n    }\n\n    /* Now that we're connected, set the socket to be non-blocking and\n     * kick the reply mechanism.  */\n    qio_channel_set_blocking(QIO_CHANNEL(sioc), false, NULL);\n\n    nbd_client_attach_aio_context(bs, bdrv_get_aio_context(bs));\n\n    logout(\"Established connection with NBD server\\n\");\n    return 0;\n}",
        "func": "int nbd_client_init(BlockDriverState *bs,\n                    QIOChannelSocket *sioc,\n                    const char *export,\n                    QCryptoTLSCreds *tlscreds,\n                    const char *hostname,\n                    Error **errp)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    int ret;\n\n    /* NBD handshake */\n    logout(\"session init %s\\n\", export);\n    qio_channel_set_blocking(QIO_CHANNEL(sioc), true, NULL);\n\n    ret = nbd_receive_negotiate(QIO_CHANNEL(sioc), export,\n                                &client->nbdflags,\n                                tlscreds, hostname,\n                                &client->ioc,\n                                &client->size, errp);\n    if (ret < 0) {\n        logout(\"Failed to negotiate with the NBD server\\n\");\n        return ret;\n    }\n    if (client->nbdflags & NBD_FLAG_SEND_FUA) {\n        bs->supported_write_flags = BDRV_REQ_FUA;\n        bs->supported_zero_flags |= BDRV_REQ_FUA;\n    }\n    if (client->nbdflags & NBD_FLAG_SEND_WRITE_ZEROES) {\n        bs->supported_zero_flags |= BDRV_REQ_MAY_UNMAP;\n    }\n\n    qemu_co_mutex_init(&client->send_mutex);\n    qemu_co_queue_init(&client->free_sema);\n    client->sioc = sioc;\n    object_ref(OBJECT(client->sioc));\n\n    if (!client->ioc) {\n        client->ioc = QIO_CHANNEL(sioc);\n        object_ref(OBJECT(client->ioc));\n    }\n\n    /* Now that we're connected, set the socket to be non-blocking and\n     * kick the reply mechanism.  */\n    qio_channel_set_blocking(QIO_CHANNEL(sioc), false, NULL);\n    client->read_reply_co = qemu_coroutine_create(nbd_read_reply_entry, client);\n    nbd_client_attach_aio_context(bs, bdrv_get_aio_context(bs));\n\n    logout(\"Established connection with NBD server\\n\");\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,7 +42,7 @@\n     /* Now that we're connected, set the socket to be non-blocking and\n      * kick the reply mechanism.  */\n     qio_channel_set_blocking(QIO_CHANNEL(sioc), false, NULL);\n-\n+    client->read_reply_co = qemu_coroutine_create(nbd_read_reply_entry, client);\n     nbd_client_attach_aio_context(bs, bdrv_get_aio_context(bs));\n \n     logout(\"Established connection with NBD server\\n\");",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "    client->read_reply_co = qemu_coroutine_create(nbd_read_reply_entry, client);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_co_preadv",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "int nbd_client_co_preadv(BlockDriverState *bs, uint64_t offset,\n                         uint64_t bytes, QEMUIOVector *qiov, int flags)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_READ,\n        .from = offset,\n        .len = bytes,\n    };\n    NBDReply reply;\n    ssize_t ret;\n\n    assert(bytes <= NBD_MAX_BUFFER_SIZE);\n    assert(!flags);\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, qiov);\n    }\n    nbd_coroutine_end(client, &request);\n    return -reply.error;\n}",
        "func": "int nbd_client_co_preadv(BlockDriverState *bs, uint64_t offset,\n                         uint64_t bytes, QEMUIOVector *qiov, int flags)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_READ,\n        .from = offset,\n        .len = bytes,\n    };\n    NBDReply reply;\n    ssize_t ret;\n\n    assert(bytes <= NBD_MAX_BUFFER_SIZE);\n    assert(!flags);\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, qiov);\n    }\n    nbd_coroutine_end(bs, &request);\n    return -reply.error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,6 +20,6 @@\n     } else {\n         nbd_co_receive_reply(client, &request, &reply, qiov);\n     }\n-    nbd_coroutine_end(client, &request);\n+    nbd_coroutine_end(bs, &request);\n     return -reply.error;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_coroutine_end(client, &request);"
            ],
            "added_lines": [
                "    nbd_coroutine_end(bs, &request);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_detach_aio_context",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "void nbd_client_detach_aio_context(BlockDriverState *bs)\n{\n    aio_set_fd_handler(bdrv_get_aio_context(bs),\n                       nbd_get_client_session(bs)->sioc->fd,\n                       false, NULL, NULL, NULL, NULL);\n}",
        "func": "void nbd_client_detach_aio_context(BlockDriverState *bs)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    qio_channel_detach_aio_context(QIO_CHANNEL(client->sioc));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,5 @@\n void nbd_client_detach_aio_context(BlockDriverState *bs)\n {\n-    aio_set_fd_handler(bdrv_get_aio_context(bs),\n-                       nbd_get_client_session(bs)->sioc->fd,\n-                       false, NULL, NULL, NULL, NULL);\n+    NBDClientSession *client = nbd_get_client_session(bs);\n+    qio_channel_detach_aio_context(QIO_CHANNEL(client->sioc));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    aio_set_fd_handler(bdrv_get_aio_context(bs),",
                "                       nbd_get_client_session(bs)->sioc->fd,",
                "                       false, NULL, NULL, NULL, NULL);"
            ],
            "added_lines": [
                "    NBDClientSession *client = nbd_get_client_session(bs);",
                "    qio_channel_detach_aio_context(QIO_CHANNEL(client->sioc));"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_co_pwritev",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "int nbd_client_co_pwritev(BlockDriverState *bs, uint64_t offset,\n                          uint64_t bytes, QEMUIOVector *qiov, int flags)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_WRITE,\n        .from = offset,\n        .len = bytes,\n    };\n    NBDReply reply;\n    ssize_t ret;\n\n    if (flags & BDRV_REQ_FUA) {\n        assert(client->nbdflags & NBD_FLAG_SEND_FUA);\n        request.flags |= NBD_CMD_FLAG_FUA;\n    }\n\n    assert(bytes <= NBD_MAX_BUFFER_SIZE);\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, qiov);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(client, &request);\n    return -reply.error;\n}",
        "func": "int nbd_client_co_pwritev(BlockDriverState *bs, uint64_t offset,\n                          uint64_t bytes, QEMUIOVector *qiov, int flags)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_WRITE,\n        .from = offset,\n        .len = bytes,\n    };\n    NBDReply reply;\n    ssize_t ret;\n\n    if (flags & BDRV_REQ_FUA) {\n        assert(client->nbdflags & NBD_FLAG_SEND_FUA);\n        request.flags |= NBD_CMD_FLAG_FUA;\n    }\n\n    assert(bytes <= NBD_MAX_BUFFER_SIZE);\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, qiov);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(bs, &request);\n    return -reply.error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,6 +24,6 @@\n     } else {\n         nbd_co_receive_reply(client, &request, &reply, NULL);\n     }\n-    nbd_coroutine_end(client, &request);\n+    nbd_coroutine_end(bs, &request);\n     return -reply.error;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_coroutine_end(client, &request);"
            ],
            "added_lines": [
                "    nbd_coroutine_end(bs, &request);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_recv_coroutines_enter_all",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void nbd_recv_coroutines_enter_all(NBDClientSession *s)\n{\n    int i;\n\n    for (i = 0; i < MAX_NBD_REQUESTS; i++) {\n        if (s->recv_coroutine[i]) {\n            qemu_coroutine_enter(s->recv_coroutine[i]);\n        }\n    }\n}",
        "func": "static void nbd_recv_coroutines_enter_all(BlockDriverState *bs)\n{\n    NBDClientSession *s = nbd_get_client_session(bs);\n    int i;\n\n    for (i = 0; i < MAX_NBD_REQUESTS; i++) {\n        if (s->recv_coroutine[i]) {\n            qemu_coroutine_enter(s->recv_coroutine[i]);\n        }\n    }\n    BDRV_POLL_WHILE(bs, s->read_reply_co);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n-static void nbd_recv_coroutines_enter_all(NBDClientSession *s)\n+static void nbd_recv_coroutines_enter_all(BlockDriverState *bs)\n {\n+    NBDClientSession *s = nbd_get_client_session(bs);\n     int i;\n \n     for (i = 0; i < MAX_NBD_REQUESTS; i++) {\n@@ -7,4 +8,5 @@\n             qemu_coroutine_enter(s->recv_coroutine[i]);\n         }\n     }\n+    BDRV_POLL_WHILE(bs, s->read_reply_co);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static void nbd_recv_coroutines_enter_all(NBDClientSession *s)"
            ],
            "added_lines": [
                "static void nbd_recv_coroutines_enter_all(BlockDriverState *bs)",
                "    NBDClientSession *s = nbd_get_client_session(bs);",
                "    BDRV_POLL_WHILE(bs, s->read_reply_co);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_teardown_connection",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void nbd_teardown_connection(BlockDriverState *bs)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n\n    if (!client->ioc) { /* Already closed */\n        return;\n    }\n\n    /* finish any pending coroutines */\n    qio_channel_shutdown(client->ioc,\n                         QIO_CHANNEL_SHUTDOWN_BOTH,\n                         NULL);\n    nbd_recv_coroutines_enter_all(client);\n\n    nbd_client_detach_aio_context(bs);\n    object_unref(OBJECT(client->sioc));\n    client->sioc = NULL;\n    object_unref(OBJECT(client->ioc));\n    client->ioc = NULL;\n}",
        "func": "static void nbd_teardown_connection(BlockDriverState *bs)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n\n    if (!client->ioc) { /* Already closed */\n        return;\n    }\n\n    /* finish any pending coroutines */\n    qio_channel_shutdown(client->ioc,\n                         QIO_CHANNEL_SHUTDOWN_BOTH,\n                         NULL);\n    nbd_recv_coroutines_enter_all(bs);\n\n    nbd_client_detach_aio_context(bs);\n    object_unref(OBJECT(client->sioc));\n    client->sioc = NULL;\n    object_unref(OBJECT(client->ioc));\n    client->ioc = NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n     qio_channel_shutdown(client->ioc,\n                          QIO_CHANNEL_SHUTDOWN_BOTH,\n                          NULL);\n-    nbd_recv_coroutines_enter_all(client);\n+    nbd_recv_coroutines_enter_all(bs);\n \n     nbd_client_detach_aio_context(bs);\n     object_unref(OBJECT(client->sioc));",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_recv_coroutines_enter_all(client);"
            ],
            "added_lines": [
                "    nbd_recv_coroutines_enter_all(bs);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_attach_aio_context",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "void nbd_client_attach_aio_context(BlockDriverState *bs,\n                                   AioContext *new_context)\n{\n    aio_set_fd_handler(new_context, nbd_get_client_session(bs)->sioc->fd,\n                       false, nbd_reply_ready, NULL, NULL, bs);\n}",
        "func": "void nbd_client_attach_aio_context(BlockDriverState *bs,\n                                   AioContext *new_context)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    qio_channel_attach_aio_context(QIO_CHANNEL(client->sioc), new_context);\n    aio_co_schedule(new_context, client->read_reply_co);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n void nbd_client_attach_aio_context(BlockDriverState *bs,\n                                    AioContext *new_context)\n {\n-    aio_set_fd_handler(new_context, nbd_get_client_session(bs)->sioc->fd,\n-                       false, nbd_reply_ready, NULL, NULL, bs);\n+    NBDClientSession *client = nbd_get_client_session(bs);\n+    qio_channel_attach_aio_context(QIO_CHANNEL(client->sioc), new_context);\n+    aio_co_schedule(new_context, client->read_reply_co);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    aio_set_fd_handler(new_context, nbd_get_client_session(bs)->sioc->fd,",
                "                       false, nbd_reply_ready, NULL, NULL, bs);"
            ],
            "added_lines": [
                "    NBDClientSession *client = nbd_get_client_session(bs);",
                "    qio_channel_attach_aio_context(QIO_CHANNEL(client->sioc), new_context);",
                "    aio_co_schedule(new_context, client->read_reply_co);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_co_send_request",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static int nbd_co_send_request(BlockDriverState *bs,\n                               NBDRequest *request,\n                               QEMUIOVector *qiov)\n{\n    NBDClientSession *s = nbd_get_client_session(bs);\n    AioContext *aio_context;\n    int rc, ret, i;\n\n    qemu_co_mutex_lock(&s->send_mutex);\n\n    for (i = 0; i < MAX_NBD_REQUESTS; i++) {\n        if (s->recv_coroutine[i] == NULL) {\n            s->recv_coroutine[i] = qemu_coroutine_self();\n            break;\n        }\n    }\n\n    g_assert(qemu_in_coroutine());\n    assert(i < MAX_NBD_REQUESTS);\n    request->handle = INDEX_TO_HANDLE(s, i);\n\n    if (!s->ioc) {\n        qemu_co_mutex_unlock(&s->send_mutex);\n        return -EPIPE;\n    }\n\n    s->send_coroutine = qemu_coroutine_self();\n    aio_context = bdrv_get_aio_context(bs);\n\n    aio_set_fd_handler(aio_context, s->sioc->fd, false,\n                       nbd_reply_ready, nbd_restart_write, NULL, bs);\n    if (qiov) {\n        qio_channel_set_cork(s->ioc, true);\n        rc = nbd_send_request(s->ioc, request);\n        if (rc >= 0) {\n            ret = nbd_wr_syncv(s->ioc, qiov->iov, qiov->niov, request->len,\n                               false);\n            if (ret != request->len) {\n                rc = -EIO;\n            }\n        }\n        qio_channel_set_cork(s->ioc, false);\n    } else {\n        rc = nbd_send_request(s->ioc, request);\n    }\n    aio_set_fd_handler(aio_context, s->sioc->fd, false,\n                       nbd_reply_ready, NULL, NULL, bs);\n    s->send_coroutine = NULL;\n    qemu_co_mutex_unlock(&s->send_mutex);\n    return rc;\n}",
        "func": "static int nbd_co_send_request(BlockDriverState *bs,\n                               NBDRequest *request,\n                               QEMUIOVector *qiov)\n{\n    NBDClientSession *s = nbd_get_client_session(bs);\n    int rc, ret, i;\n\n    qemu_co_mutex_lock(&s->send_mutex);\n\n    for (i = 0; i < MAX_NBD_REQUESTS; i++) {\n        if (s->recv_coroutine[i] == NULL) {\n            s->recv_coroutine[i] = qemu_coroutine_self();\n            break;\n        }\n    }\n\n    g_assert(qemu_in_coroutine());\n    assert(i < MAX_NBD_REQUESTS);\n    request->handle = INDEX_TO_HANDLE(s, i);\n\n    if (!s->ioc) {\n        qemu_co_mutex_unlock(&s->send_mutex);\n        return -EPIPE;\n    }\n\n    if (qiov) {\n        qio_channel_set_cork(s->ioc, true);\n        rc = nbd_send_request(s->ioc, request);\n        if (rc >= 0) {\n            ret = nbd_wr_syncv(s->ioc, qiov->iov, qiov->niov, request->len,\n                               false);\n            if (ret != request->len) {\n                rc = -EIO;\n            }\n        }\n        qio_channel_set_cork(s->ioc, false);\n    } else {\n        rc = nbd_send_request(s->ioc, request);\n    }\n    qemu_co_mutex_unlock(&s->send_mutex);\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,6 @@\n                                QEMUIOVector *qiov)\n {\n     NBDClientSession *s = nbd_get_client_session(bs);\n-    AioContext *aio_context;\n     int rc, ret, i;\n \n     qemu_co_mutex_lock(&s->send_mutex);\n@@ -24,11 +23,6 @@\n         return -EPIPE;\n     }\n \n-    s->send_coroutine = qemu_coroutine_self();\n-    aio_context = bdrv_get_aio_context(bs);\n-\n-    aio_set_fd_handler(aio_context, s->sioc->fd, false,\n-                       nbd_reply_ready, nbd_restart_write, NULL, bs);\n     if (qiov) {\n         qio_channel_set_cork(s->ioc, true);\n         rc = nbd_send_request(s->ioc, request);\n@@ -43,9 +37,6 @@\n     } else {\n         rc = nbd_send_request(s->ioc, request);\n     }\n-    aio_set_fd_handler(aio_context, s->sioc->fd, false,\n-                       nbd_reply_ready, NULL, NULL, bs);\n-    s->send_coroutine = NULL;\n     qemu_co_mutex_unlock(&s->send_mutex);\n     return rc;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    AioContext *aio_context;",
                "    s->send_coroutine = qemu_coroutine_self();",
                "    aio_context = bdrv_get_aio_context(bs);",
                "",
                "    aio_set_fd_handler(aio_context, s->sioc->fd, false,",
                "                       nbd_reply_ready, nbd_restart_write, NULL, bs);",
                "    aio_set_fd_handler(aio_context, s->sioc->fd, false,",
                "                       nbd_reply_ready, NULL, NULL, bs);",
                "    s->send_coroutine = NULL;"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_co_receive_reply",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "static void nbd_co_receive_reply(NBDClientSession *s,\n                                 NBDRequest *request,\n                                 NBDReply *reply,\n                                 QEMUIOVector *qiov)\n{\n    int ret;\n\n    /* Wait until we're woken up by the read handler.  TODO: perhaps\n     * peek at the next reply and avoid yielding if it's ours?  */\n    qemu_coroutine_yield();\n    *reply = s->reply;\n    if (reply->handle != request->handle ||\n        !s->ioc) {\n        reply->error = EIO;\n    } else {\n        if (qiov && reply->error == 0) {\n            ret = nbd_wr_syncv(s->ioc, qiov->iov, qiov->niov, request->len,\n                               true);\n            if (ret != request->len) {\n                reply->error = EIO;\n            }\n        }\n\n        /* Tell the read handler to read another header.  */\n        s->reply.handle = 0;\n    }\n}",
        "func": "static void nbd_co_receive_reply(NBDClientSession *s,\n                                 NBDRequest *request,\n                                 NBDReply *reply,\n                                 QEMUIOVector *qiov)\n{\n    int ret;\n\n    /* Wait until we're woken up by nbd_read_reply_entry.  */\n    qemu_coroutine_yield();\n    *reply = s->reply;\n    if (reply->handle != request->handle ||\n        !s->ioc) {\n        reply->error = EIO;\n    } else {\n        if (qiov && reply->error == 0) {\n            ret = nbd_wr_syncv(s->ioc, qiov->iov, qiov->niov, request->len,\n                               true);\n            if (ret != request->len) {\n                reply->error = EIO;\n            }\n        }\n\n        /* Tell the read handler to read another header.  */\n        s->reply.handle = 0;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,8 +5,7 @@\n {\n     int ret;\n \n-    /* Wait until we're woken up by the read handler.  TODO: perhaps\n-     * peek at the next reply and avoid yielding if it's ours?  */\n+    /* Wait until we're woken up by nbd_read_reply_entry.  */\n     qemu_coroutine_yield();\n     *reply = s->reply;\n     if (reply->handle != request->handle ||",
        "diff_line_info": {
            "deleted_lines": [
                "    /* Wait until we're woken up by the read handler.  TODO: perhaps",
                "     * peek at the next reply and avoid yielding if it's ours?  */"
            ],
            "added_lines": [
                "    /* Wait until we're woken up by nbd_read_reply_entry.  */"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_client_co_pdiscard",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/ff82911cd3f69f028f2537825c9720ff78bc3f19",
        "commit_title": "nbd: convert to use qio_channel_yield",
        "commit_text": " In the client, read the reply headers from a coroutine, switching the read side between the \"read header\" coroutine and the I/O coroutine that reads the body of the reply.  In the server, if the server can read more requests it will create a new \"read request\" coroutine as soon as a request has been read.  Otherwise, the new coroutine is created in nbd_request_put. ",
        "func_before": "int nbd_client_co_pdiscard(BlockDriverState *bs, int64_t offset, int count)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_TRIM,\n        .from = offset,\n        .len = count,\n    };\n    NBDReply reply;\n    ssize_t ret;\n\n    if (!(client->nbdflags & NBD_FLAG_SEND_TRIM)) {\n        return 0;\n    }\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(client, &request);\n    return -reply.error;\n\n}",
        "func": "int nbd_client_co_pdiscard(BlockDriverState *bs, int64_t offset, int count)\n{\n    NBDClientSession *client = nbd_get_client_session(bs);\n    NBDRequest request = {\n        .type = NBD_CMD_TRIM,\n        .from = offset,\n        .len = count,\n    };\n    NBDReply reply;\n    ssize_t ret;\n\n    if (!(client->nbdflags & NBD_FLAG_SEND_TRIM)) {\n        return 0;\n    }\n\n    nbd_coroutine_start(client, &request);\n    ret = nbd_co_send_request(bs, &request, NULL);\n    if (ret < 0) {\n        reply.error = -ret;\n    } else {\n        nbd_co_receive_reply(client, &request, &reply, NULL);\n    }\n    nbd_coroutine_end(bs, &request);\n    return -reply.error;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,7 @@\n     } else {\n         nbd_co_receive_reply(client, &request, &reply, NULL);\n     }\n-    nbd_coroutine_end(client, &request);\n+    nbd_coroutine_end(bs, &request);\n     return -reply.error;\n \n }",
        "diff_line_info": {
            "deleted_lines": [
                "    nbd_coroutine_end(client, &request);"
            ],
            "added_lines": [
                "    nbd_coroutine_end(bs, &request);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate_options",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static int nbd_negotiate_options(NBDClient *client)\n{\n    uint32_t flags;\n    bool fixedNewstyle = false;\n\n    /* Client sends:\n        [ 0 ..   3]   client flags\n\n        [ 0 ..   7]   NBD_OPTS_MAGIC\n        [ 8 ..  11]   NBD option\n        [12 ..  15]   Data length\n        ...           Rest of request\n\n        [ 0 ..   7]   NBD_OPTS_MAGIC\n        [ 8 ..  11]   Second NBD option\n        [12 ..  15]   Data length\n        ...           Rest of request\n    */\n\n    if (nbd_negotiate_read(client->ioc, &flags, sizeof(flags)) < 0) {\n        LOG(\"read failed\");\n        return -EIO;\n    }\n    TRACE(\"Checking client flags\");\n    be32_to_cpus(&flags);\n    if (flags & NBD_FLAG_C_FIXED_NEWSTYLE) {\n        TRACE(\"Client supports fixed newstyle handshake\");\n        fixedNewstyle = true;\n        flags &= ~NBD_FLAG_C_FIXED_NEWSTYLE;\n    }\n    if (flags & NBD_FLAG_C_NO_ZEROES) {\n        TRACE(\"Client supports no zeroes at handshake end\");\n        client->no_zeroes = true;\n        flags &= ~NBD_FLAG_C_NO_ZEROES;\n    }\n    if (flags != 0) {\n        TRACE(\"Unknown client flags 0x%\" PRIx32 \" received\", flags);\n        return -EIO;\n    }\n\n    while (1) {\n        int ret;\n        uint32_t clientflags, length;\n        uint64_t magic;\n\n        if (nbd_negotiate_read(client->ioc, &magic, sizeof(magic)) < 0) {\n            LOG(\"read failed\");\n            return -EINVAL;\n        }\n        TRACE(\"Checking opts magic\");\n        if (magic != be64_to_cpu(NBD_OPTS_MAGIC)) {\n            LOG(\"Bad magic received\");\n            return -EINVAL;\n        }\n\n        if (nbd_negotiate_read(client->ioc, &clientflags,\n                               sizeof(clientflags)) < 0)\n        {\n            LOG(\"read failed\");\n            return -EINVAL;\n        }\n        clientflags = be32_to_cpu(clientflags);\n\n        if (nbd_negotiate_read(client->ioc, &length, sizeof(length)) < 0) {\n            LOG(\"read failed\");\n            return -EINVAL;\n        }\n        length = be32_to_cpu(length);\n\n        TRACE(\"Checking option 0x%\" PRIx32, clientflags);\n        if (client->tlscreds &&\n            client->ioc == (QIOChannel *)client->sioc) {\n            QIOChannel *tioc;\n            if (!fixedNewstyle) {\n                TRACE(\"Unsupported option 0x%\" PRIx32, clientflags);\n                return -EINVAL;\n            }\n            switch (clientflags) {\n            case NBD_OPT_STARTTLS:\n                tioc = nbd_negotiate_handle_starttls(client, length);\n                if (!tioc) {\n                    return -EIO;\n                }\n                object_unref(OBJECT(client->ioc));\n                client->ioc = QIO_CHANNEL(tioc);\n                break;\n\n            case NBD_OPT_EXPORT_NAME:\n                /* No way to return an error to client, so drop connection */\n                TRACE(\"Option 0x%x not permitted before TLS\", clientflags);\n                return -EINVAL;\n\n            default:\n                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n                    return -EIO;\n                }\n                ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                 NBD_REP_ERR_TLS_REQD,\n                                                 clientflags,\n                                                 \"Option 0x%\" PRIx32\n                                                 \"not permitted before TLS\",\n                                                 clientflags);\n                if (ret < 0) {\n                    return ret;\n                }\n                /* Let the client keep trying, unless they asked to quit */\n                if (clientflags == NBD_OPT_ABORT) {\n                    return -EINVAL;\n                }\n                break;\n            }\n        } else if (fixedNewstyle) {\n            switch (clientflags) {\n            case NBD_OPT_LIST:\n                ret = nbd_negotiate_handle_list(client, length);\n                if (ret < 0) {\n                    return ret;\n                }\n                break;\n\n            case NBD_OPT_ABORT:\n                /* NBD spec says we must try to reply before\n                 * disconnecting, but that we must also tolerate\n                 * guests that don't wait for our reply. */\n                nbd_negotiate_send_rep(client->ioc, NBD_REP_ACK, clientflags);\n                return -EINVAL;\n\n            case NBD_OPT_EXPORT_NAME:\n                return nbd_negotiate_handle_export_name(client, length);\n\n            case NBD_OPT_STARTTLS:\n                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n                    return -EIO;\n                }\n                if (client->tlscreds) {\n                    ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                     NBD_REP_ERR_INVALID,\n                                                     clientflags,\n                                                     \"TLS already enabled\");\n                } else {\n                    ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                     NBD_REP_ERR_POLICY,\n                                                     clientflags,\n                                                     \"TLS not configured\");\n                }\n                if (ret < 0) {\n                    return ret;\n                }\n                break;\n            default:\n                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n                    return -EIO;\n                }\n                ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                 NBD_REP_ERR_UNSUP,\n                                                 clientflags,\n                                                 \"Unsupported option 0x%\"\n                                                 PRIx32,\n                                                 clientflags);\n                if (ret < 0) {\n                    return ret;\n                }\n                break;\n            }\n        } else {\n            /*\n             * If broken new-style we should drop the connection\n             * for anything except NBD_OPT_EXPORT_NAME\n             */\n            switch (clientflags) {\n            case NBD_OPT_EXPORT_NAME:\n                return nbd_negotiate_handle_export_name(client, length);\n\n            default:\n                TRACE(\"Unsupported option 0x%\" PRIx32, clientflags);\n                return -EINVAL;\n            }\n        }\n    }\n}",
        "func": "static int nbd_negotiate_options(NBDClient *client)\n{\n    uint32_t flags;\n    bool fixedNewstyle = false;\n\n    /* Client sends:\n        [ 0 ..   3]   client flags\n\n        [ 0 ..   7]   NBD_OPTS_MAGIC\n        [ 8 ..  11]   NBD option\n        [12 ..  15]   Data length\n        ...           Rest of request\n\n        [ 0 ..   7]   NBD_OPTS_MAGIC\n        [ 8 ..  11]   Second NBD option\n        [12 ..  15]   Data length\n        ...           Rest of request\n    */\n\n    if (nbd_read(client->ioc, &flags, sizeof(flags), NULL) < 0) {\n        LOG(\"read failed\");\n        return -EIO;\n    }\n    TRACE(\"Checking client flags\");\n    be32_to_cpus(&flags);\n    if (flags & NBD_FLAG_C_FIXED_NEWSTYLE) {\n        TRACE(\"Client supports fixed newstyle handshake\");\n        fixedNewstyle = true;\n        flags &= ~NBD_FLAG_C_FIXED_NEWSTYLE;\n    }\n    if (flags & NBD_FLAG_C_NO_ZEROES) {\n        TRACE(\"Client supports no zeroes at handshake end\");\n        client->no_zeroes = true;\n        flags &= ~NBD_FLAG_C_NO_ZEROES;\n    }\n    if (flags != 0) {\n        TRACE(\"Unknown client flags 0x%\" PRIx32 \" received\", flags);\n        return -EIO;\n    }\n\n    while (1) {\n        int ret;\n        uint32_t clientflags, length;\n        uint64_t magic;\n\n        if (nbd_read(client->ioc, &magic, sizeof(magic), NULL) < 0) {\n            LOG(\"read failed\");\n            return -EINVAL;\n        }\n        TRACE(\"Checking opts magic\");\n        if (magic != be64_to_cpu(NBD_OPTS_MAGIC)) {\n            LOG(\"Bad magic received\");\n            return -EINVAL;\n        }\n\n        if (nbd_read(client->ioc, &clientflags,\n                      sizeof(clientflags), NULL) < 0)\n        {\n            LOG(\"read failed\");\n            return -EINVAL;\n        }\n        clientflags = be32_to_cpu(clientflags);\n\n        if (nbd_read(client->ioc, &length, sizeof(length), NULL) < 0) {\n            LOG(\"read failed\");\n            return -EINVAL;\n        }\n        length = be32_to_cpu(length);\n\n        TRACE(\"Checking option 0x%\" PRIx32, clientflags);\n        if (client->tlscreds &&\n            client->ioc == (QIOChannel *)client->sioc) {\n            QIOChannel *tioc;\n            if (!fixedNewstyle) {\n                TRACE(\"Unsupported option 0x%\" PRIx32, clientflags);\n                return -EINVAL;\n            }\n            switch (clientflags) {\n            case NBD_OPT_STARTTLS:\n                tioc = nbd_negotiate_handle_starttls(client, length);\n                if (!tioc) {\n                    return -EIO;\n                }\n                object_unref(OBJECT(client->ioc));\n                client->ioc = QIO_CHANNEL(tioc);\n                break;\n\n            case NBD_OPT_EXPORT_NAME:\n                /* No way to return an error to client, so drop connection */\n                TRACE(\"Option 0x%x not permitted before TLS\", clientflags);\n                return -EINVAL;\n\n            default:\n                if (nbd_drop(client->ioc, length, NULL) < 0) {\n                    return -EIO;\n                }\n                ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                 NBD_REP_ERR_TLS_REQD,\n                                                 clientflags,\n                                                 \"Option 0x%\" PRIx32\n                                                 \"not permitted before TLS\",\n                                                 clientflags);\n                if (ret < 0) {\n                    return ret;\n                }\n                /* Let the client keep trying, unless they asked to quit */\n                if (clientflags == NBD_OPT_ABORT) {\n                    return -EINVAL;\n                }\n                break;\n            }\n        } else if (fixedNewstyle) {\n            switch (clientflags) {\n            case NBD_OPT_LIST:\n                ret = nbd_negotiate_handle_list(client, length);\n                if (ret < 0) {\n                    return ret;\n                }\n                break;\n\n            case NBD_OPT_ABORT:\n                /* NBD spec says we must try to reply before\n                 * disconnecting, but that we must also tolerate\n                 * guests that don't wait for our reply. */\n                nbd_negotiate_send_rep(client->ioc, NBD_REP_ACK, clientflags);\n                return -EINVAL;\n\n            case NBD_OPT_EXPORT_NAME:\n                return nbd_negotiate_handle_export_name(client, length);\n\n            case NBD_OPT_STARTTLS:\n                if (nbd_drop(client->ioc, length, NULL) < 0) {\n                    return -EIO;\n                }\n                if (client->tlscreds) {\n                    ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                     NBD_REP_ERR_INVALID,\n                                                     clientflags,\n                                                     \"TLS already enabled\");\n                } else {\n                    ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                     NBD_REP_ERR_POLICY,\n                                                     clientflags,\n                                                     \"TLS not configured\");\n                }\n                if (ret < 0) {\n                    return ret;\n                }\n                break;\n            default:\n                if (nbd_drop(client->ioc, length, NULL) < 0) {\n                    return -EIO;\n                }\n                ret = nbd_negotiate_send_rep_err(client->ioc,\n                                                 NBD_REP_ERR_UNSUP,\n                                                 clientflags,\n                                                 \"Unsupported option 0x%\"\n                                                 PRIx32,\n                                                 clientflags);\n                if (ret < 0) {\n                    return ret;\n                }\n                break;\n            }\n        } else {\n            /*\n             * If broken new-style we should drop the connection\n             * for anything except NBD_OPT_EXPORT_NAME\n             */\n            switch (clientflags) {\n            case NBD_OPT_EXPORT_NAME:\n                return nbd_negotiate_handle_export_name(client, length);\n\n            default:\n                TRACE(\"Unsupported option 0x%\" PRIx32, clientflags);\n                return -EINVAL;\n            }\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,7 @@\n         ...           Rest of request\n     */\n \n-    if (nbd_negotiate_read(client->ioc, &flags, sizeof(flags)) < 0) {\n+    if (nbd_read(client->ioc, &flags, sizeof(flags), NULL) < 0) {\n         LOG(\"read failed\");\n         return -EIO;\n     }\n@@ -43,7 +43,7 @@\n         uint32_t clientflags, length;\n         uint64_t magic;\n \n-        if (nbd_negotiate_read(client->ioc, &magic, sizeof(magic)) < 0) {\n+        if (nbd_read(client->ioc, &magic, sizeof(magic), NULL) < 0) {\n             LOG(\"read failed\");\n             return -EINVAL;\n         }\n@@ -53,15 +53,15 @@\n             return -EINVAL;\n         }\n \n-        if (nbd_negotiate_read(client->ioc, &clientflags,\n-                               sizeof(clientflags)) < 0)\n+        if (nbd_read(client->ioc, &clientflags,\n+                      sizeof(clientflags), NULL) < 0)\n         {\n             LOG(\"read failed\");\n             return -EINVAL;\n         }\n         clientflags = be32_to_cpu(clientflags);\n \n-        if (nbd_negotiate_read(client->ioc, &length, sizeof(length)) < 0) {\n+        if (nbd_read(client->ioc, &length, sizeof(length), NULL) < 0) {\n             LOG(\"read failed\");\n             return -EINVAL;\n         }\n@@ -91,7 +91,7 @@\n                 return -EINVAL;\n \n             default:\n-                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n+                if (nbd_drop(client->ioc, length, NULL) < 0) {\n                     return -EIO;\n                 }\n                 ret = nbd_negotiate_send_rep_err(client->ioc,\n@@ -129,7 +129,7 @@\n                 return nbd_negotiate_handle_export_name(client, length);\n \n             case NBD_OPT_STARTTLS:\n-                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n+                if (nbd_drop(client->ioc, length, NULL) < 0) {\n                     return -EIO;\n                 }\n                 if (client->tlscreds) {\n@@ -148,7 +148,7 @@\n                 }\n                 break;\n             default:\n-                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n+                if (nbd_drop(client->ioc, length, NULL) < 0) {\n                     return -EIO;\n                 }\n                 ret = nbd_negotiate_send_rep_err(client->ioc,",
        "diff_line_info": {
            "deleted_lines": [
                "    if (nbd_negotiate_read(client->ioc, &flags, sizeof(flags)) < 0) {",
                "        if (nbd_negotiate_read(client->ioc, &magic, sizeof(magic)) < 0) {",
                "        if (nbd_negotiate_read(client->ioc, &clientflags,",
                "                               sizeof(clientflags)) < 0)",
                "        if (nbd_negotiate_read(client->ioc, &length, sizeof(length)) < 0) {",
                "                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {",
                "                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {",
                "                if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {"
            ],
            "added_lines": [
                "    if (nbd_read(client->ioc, &flags, sizeof(flags), NULL) < 0) {",
                "        if (nbd_read(client->ioc, &magic, sizeof(magic), NULL) < 0) {",
                "        if (nbd_read(client->ioc, &clientflags,",
                "                      sizeof(clientflags), NULL) < 0)",
                "        if (nbd_read(client->ioc, &length, sizeof(length), NULL) < 0) {",
                "                if (nbd_drop(client->ioc, length, NULL) < 0) {",
                "                if (nbd_drop(client->ioc, length, NULL) < 0) {",
                "                if (nbd_drop(client->ioc, length, NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate_send_rep_len",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static int nbd_negotiate_send_rep_len(QIOChannel *ioc, uint32_t type,\n                                      uint32_t opt, uint32_t len)\n{\n    uint64_t magic;\n\n    TRACE(\"Reply opt=%\" PRIx32 \" type=%\" PRIx32 \" len=%\" PRIu32,\n          type, opt, len);\n\n    magic = cpu_to_be64(NBD_REP_MAGIC);\n    if (nbd_negotiate_write(ioc, &magic, sizeof(magic)) < 0) {\n        LOG(\"write failed (rep magic)\");\n        return -EINVAL;\n    }\n    opt = cpu_to_be32(opt);\n    if (nbd_negotiate_write(ioc, &opt, sizeof(opt)) < 0) {\n        LOG(\"write failed (rep opt)\");\n        return -EINVAL;\n    }\n    type = cpu_to_be32(type);\n    if (nbd_negotiate_write(ioc, &type, sizeof(type)) < 0) {\n        LOG(\"write failed (rep type)\");\n        return -EINVAL;\n    }\n    len = cpu_to_be32(len);\n    if (nbd_negotiate_write(ioc, &len, sizeof(len)) < 0) {\n        LOG(\"write failed (rep data length)\");\n        return -EINVAL;\n    }\n    return 0;\n}",
        "func": "static int nbd_negotiate_send_rep_len(QIOChannel *ioc, uint32_t type,\n                                      uint32_t opt, uint32_t len)\n{\n    uint64_t magic;\n\n    TRACE(\"Reply opt=%\" PRIx32 \" type=%\" PRIx32 \" len=%\" PRIu32,\n          type, opt, len);\n\n    magic = cpu_to_be64(NBD_REP_MAGIC);\n    if (nbd_write(ioc, &magic, sizeof(magic), NULL) < 0) {\n        LOG(\"write failed (rep magic)\");\n        return -EINVAL;\n    }\n    opt = cpu_to_be32(opt);\n    if (nbd_write(ioc, &opt, sizeof(opt), NULL) < 0) {\n        LOG(\"write failed (rep opt)\");\n        return -EINVAL;\n    }\n    type = cpu_to_be32(type);\n    if (nbd_write(ioc, &type, sizeof(type), NULL) < 0) {\n        LOG(\"write failed (rep type)\");\n        return -EINVAL;\n    }\n    len = cpu_to_be32(len);\n    if (nbd_write(ioc, &len, sizeof(len), NULL) < 0) {\n        LOG(\"write failed (rep data length)\");\n        return -EINVAL;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,22 +7,22 @@\n           type, opt, len);\n \n     magic = cpu_to_be64(NBD_REP_MAGIC);\n-    if (nbd_negotiate_write(ioc, &magic, sizeof(magic)) < 0) {\n+    if (nbd_write(ioc, &magic, sizeof(magic), NULL) < 0) {\n         LOG(\"write failed (rep magic)\");\n         return -EINVAL;\n     }\n     opt = cpu_to_be32(opt);\n-    if (nbd_negotiate_write(ioc, &opt, sizeof(opt)) < 0) {\n+    if (nbd_write(ioc, &opt, sizeof(opt), NULL) < 0) {\n         LOG(\"write failed (rep opt)\");\n         return -EINVAL;\n     }\n     type = cpu_to_be32(type);\n-    if (nbd_negotiate_write(ioc, &type, sizeof(type)) < 0) {\n+    if (nbd_write(ioc, &type, sizeof(type), NULL) < 0) {\n         LOG(\"write failed (rep type)\");\n         return -EINVAL;\n     }\n     len = cpu_to_be32(len);\n-    if (nbd_negotiate_write(ioc, &len, sizeof(len)) < 0) {\n+    if (nbd_write(ioc, &len, sizeof(len), NULL) < 0) {\n         LOG(\"write failed (rep data length)\");\n         return -EINVAL;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (nbd_negotiate_write(ioc, &magic, sizeof(magic)) < 0) {",
                "    if (nbd_negotiate_write(ioc, &opt, sizeof(opt)) < 0) {",
                "    if (nbd_negotiate_write(ioc, &type, sizeof(type)) < 0) {",
                "    if (nbd_negotiate_write(ioc, &len, sizeof(len)) < 0) {"
            ],
            "added_lines": [
                "    if (nbd_write(ioc, &magic, sizeof(magic), NULL) < 0) {",
                "    if (nbd_write(ioc, &opt, sizeof(opt), NULL) < 0) {",
                "    if (nbd_write(ioc, &type, sizeof(type), NULL) < 0) {",
                "    if (nbd_write(ioc, &len, sizeof(len), NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate_handle_export_name",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static int nbd_negotiate_handle_export_name(NBDClient *client, uint32_t length)\n{\n    int rc = -EINVAL;\n    char name[NBD_MAX_NAME_SIZE + 1];\n\n    /* Client sends:\n        [20 ..  xx]   export name (length bytes)\n     */\n    TRACE(\"Checking length\");\n    if (length >= sizeof(name)) {\n        LOG(\"Bad length received\");\n        goto fail;\n    }\n    if (nbd_negotiate_read(client->ioc, name, length) < 0) {\n        LOG(\"read failed\");\n        goto fail;\n    }\n    name[length] = '\\0';\n\n    TRACE(\"Client requested export '%s'\", name);\n\n    client->exp = nbd_export_find(name);\n    if (!client->exp) {\n        LOG(\"export not found\");\n        goto fail;\n    }\n\n    QTAILQ_INSERT_TAIL(&client->exp->clients, client, next);\n    nbd_export_get(client->exp);\n    rc = 0;\nfail:\n    return rc;\n}",
        "func": "static int nbd_negotiate_handle_export_name(NBDClient *client, uint32_t length)\n{\n    int rc = -EINVAL;\n    char name[NBD_MAX_NAME_SIZE + 1];\n\n    /* Client sends:\n        [20 ..  xx]   export name (length bytes)\n     */\n    TRACE(\"Checking length\");\n    if (length >= sizeof(name)) {\n        LOG(\"Bad length received\");\n        goto fail;\n    }\n    if (nbd_read(client->ioc, name, length, NULL) < 0) {\n        LOG(\"read failed\");\n        goto fail;\n    }\n    name[length] = '\\0';\n\n    TRACE(\"Client requested export '%s'\", name);\n\n    client->exp = nbd_export_find(name);\n    if (!client->exp) {\n        LOG(\"export not found\");\n        goto fail;\n    }\n\n    QTAILQ_INSERT_TAIL(&client->exp->clients, client, next);\n    nbd_export_get(client->exp);\n    rc = 0;\nfail:\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n         LOG(\"Bad length received\");\n         goto fail;\n     }\n-    if (nbd_negotiate_read(client->ioc, name, length) < 0) {\n+    if (nbd_read(client->ioc, name, length, NULL) < 0) {\n         LOG(\"read failed\");\n         goto fail;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (nbd_negotiate_read(client->ioc, name, length) < 0) {"
            ],
            "added_lines": [
                "    if (nbd_read(client->ioc, name, length, NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate_handle_list",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static int nbd_negotiate_handle_list(NBDClient *client, uint32_t length)\n{\n    NBDExport *exp;\n\n    if (length) {\n        if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n            return -EIO;\n        }\n        return nbd_negotiate_send_rep_err(client->ioc,\n                                          NBD_REP_ERR_INVALID, NBD_OPT_LIST,\n                                          \"OPT_LIST should not have length\");\n    }\n\n    /* For each export, send a NBD_REP_SERVER reply. */\n    QTAILQ_FOREACH(exp, &exports, next) {\n        if (nbd_negotiate_send_rep_list(client->ioc, exp)) {\n            return -EINVAL;\n        }\n    }\n    /* Finish with a NBD_REP_ACK. */\n    return nbd_negotiate_send_rep(client->ioc, NBD_REP_ACK, NBD_OPT_LIST);\n}",
        "func": "static int nbd_negotiate_handle_list(NBDClient *client, uint32_t length)\n{\n    NBDExport *exp;\n\n    if (length) {\n        if (nbd_drop(client->ioc, length, NULL) < 0) {\n            return -EIO;\n        }\n        return nbd_negotiate_send_rep_err(client->ioc,\n                                          NBD_REP_ERR_INVALID, NBD_OPT_LIST,\n                                          \"OPT_LIST should not have length\");\n    }\n\n    /* For each export, send a NBD_REP_SERVER reply. */\n    QTAILQ_FOREACH(exp, &exports, next) {\n        if (nbd_negotiate_send_rep_list(client->ioc, exp)) {\n            return -EINVAL;\n        }\n    }\n    /* Finish with a NBD_REP_ACK. */\n    return nbd_negotiate_send_rep(client->ioc, NBD_REP_ACK, NBD_OPT_LIST);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n     NBDExport *exp;\n \n     if (length) {\n-        if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {\n+        if (nbd_drop(client->ioc, length, NULL) < 0) {\n             return -EIO;\n         }\n         return nbd_negotiate_send_rep_err(client->ioc,",
        "diff_line_info": {
            "deleted_lines": [
                "        if (nbd_negotiate_drop_sync(client->ioc, length) < 0) {"
            ],
            "added_lines": [
                "        if (nbd_drop(client->ioc, length, NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate_handle_starttls",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static QIOChannel *nbd_negotiate_handle_starttls(NBDClient *client,\n                                                 uint32_t length)\n{\n    QIOChannel *ioc;\n    QIOChannelTLS *tioc;\n    struct NBDTLSHandshakeData data = { 0 };\n\n    TRACE(\"Setting up TLS\");\n    ioc = client->ioc;\n    if (length) {\n        if (nbd_negotiate_drop_sync(ioc, length) < 0) {\n            return NULL;\n        }\n        nbd_negotiate_send_rep_err(ioc, NBD_REP_ERR_INVALID, NBD_OPT_STARTTLS,\n                                   \"OPT_STARTTLS should not have length\");\n        return NULL;\n    }\n\n    if (nbd_negotiate_send_rep(client->ioc, NBD_REP_ACK,\n                               NBD_OPT_STARTTLS) < 0) {\n        return NULL;\n    }\n\n    tioc = qio_channel_tls_new_server(ioc,\n                                      client->tlscreds,\n                                      client->tlsaclname,\n                                      NULL);\n    if (!tioc) {\n        return NULL;\n    }\n\n    qio_channel_set_name(QIO_CHANNEL(tioc), \"nbd-server-tls\");\n    TRACE(\"Starting TLS handshake\");\n    data.loop = g_main_loop_new(g_main_context_default(), FALSE);\n    qio_channel_tls_handshake(tioc,\n                              nbd_tls_handshake,\n                              &data,\n                              NULL);\n\n    if (!data.complete) {\n        g_main_loop_run(data.loop);\n    }\n    g_main_loop_unref(data.loop);\n    if (data.error) {\n        object_unref(OBJECT(tioc));\n        error_free(data.error);\n        return NULL;\n    }\n\n    return QIO_CHANNEL(tioc);\n}",
        "func": "static QIOChannel *nbd_negotiate_handle_starttls(NBDClient *client,\n                                                 uint32_t length)\n{\n    QIOChannel *ioc;\n    QIOChannelTLS *tioc;\n    struct NBDTLSHandshakeData data = { 0 };\n\n    TRACE(\"Setting up TLS\");\n    ioc = client->ioc;\n    if (length) {\n        if (nbd_drop(ioc, length, NULL) < 0) {\n            return NULL;\n        }\n        nbd_negotiate_send_rep_err(ioc, NBD_REP_ERR_INVALID, NBD_OPT_STARTTLS,\n                                   \"OPT_STARTTLS should not have length\");\n        return NULL;\n    }\n\n    if (nbd_negotiate_send_rep(client->ioc, NBD_REP_ACK,\n                               NBD_OPT_STARTTLS) < 0) {\n        return NULL;\n    }\n\n    tioc = qio_channel_tls_new_server(ioc,\n                                      client->tlscreds,\n                                      client->tlsaclname,\n                                      NULL);\n    if (!tioc) {\n        return NULL;\n    }\n\n    qio_channel_set_name(QIO_CHANNEL(tioc), \"nbd-server-tls\");\n    TRACE(\"Starting TLS handshake\");\n    data.loop = g_main_loop_new(g_main_context_default(), FALSE);\n    qio_channel_tls_handshake(tioc,\n                              nbd_tls_handshake,\n                              &data,\n                              NULL);\n\n    if (!data.complete) {\n        g_main_loop_run(data.loop);\n    }\n    g_main_loop_unref(data.loop);\n    if (data.error) {\n        object_unref(OBJECT(tioc));\n        error_free(data.error);\n        return NULL;\n    }\n\n    return QIO_CHANNEL(tioc);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n     TRACE(\"Setting up TLS\");\n     ioc = client->ioc;\n     if (length) {\n-        if (nbd_negotiate_drop_sync(ioc, length) < 0) {\n+        if (nbd_drop(ioc, length, NULL) < 0) {\n             return NULL;\n         }\n         nbd_negotiate_send_rep_err(ioc, NBD_REP_ERR_INVALID, NBD_OPT_STARTTLS,",
        "diff_line_info": {
            "deleted_lines": [
                "        if (nbd_negotiate_drop_sync(ioc, length) < 0) {"
            ],
            "added_lines": [
                "        if (nbd_drop(ioc, length, NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static coroutine_fn int nbd_negotiate(NBDClientNewData *data)\n{\n    NBDClient *client = data->client;\n    char buf[8 + 8 + 8 + 128];\n    int rc;\n    const uint16_t myflags = (NBD_FLAG_HAS_FLAGS | NBD_FLAG_SEND_TRIM |\n                              NBD_FLAG_SEND_FLUSH | NBD_FLAG_SEND_FUA |\n                              NBD_FLAG_SEND_WRITE_ZEROES);\n    bool oldStyle;\n    size_t len;\n\n    /* Old style negotiation header without options\n        [ 0 ..   7]   passwd       (\"NBDMAGIC\")\n        [ 8 ..  15]   magic        (NBD_CLIENT_MAGIC)\n        [16 ..  23]   size\n        [24 ..  25]   server flags (0)\n        [26 ..  27]   export flags\n        [28 .. 151]   reserved     (0)\n\n       New style negotiation header with options\n        [ 0 ..   7]   passwd       (\"NBDMAGIC\")\n        [ 8 ..  15]   magic        (NBD_OPTS_MAGIC)\n        [16 ..  17]   server flags (0)\n        ....options sent....\n        [18 ..  25]   size\n        [26 ..  27]   export flags\n        [28 .. 151]   reserved     (0, omit if no_zeroes)\n     */\n\n    qio_channel_set_blocking(client->ioc, false, NULL);\n    rc = -EINVAL;\n\n    TRACE(\"Beginning negotiation.\");\n    memset(buf, 0, sizeof(buf));\n    memcpy(buf, \"NBDMAGIC\", 8);\n\n    oldStyle = client->exp != NULL && !client->tlscreds;\n    if (oldStyle) {\n        TRACE(\"advertising size %\" PRIu64 \" and flags %x\",\n              client->exp->size, client->exp->nbdflags | myflags);\n        stq_be_p(buf + 8, NBD_CLIENT_MAGIC);\n        stq_be_p(buf + 16, client->exp->size);\n        stw_be_p(buf + 26, client->exp->nbdflags | myflags);\n    } else {\n        stq_be_p(buf + 8, NBD_OPTS_MAGIC);\n        stw_be_p(buf + 16, NBD_FLAG_FIXED_NEWSTYLE | NBD_FLAG_NO_ZEROES);\n    }\n\n    if (oldStyle) {\n        if (client->tlscreds) {\n            TRACE(\"TLS cannot be enabled with oldstyle protocol\");\n            goto fail;\n        }\n        if (nbd_negotiate_write(client->ioc, buf, sizeof(buf)) < 0) {\n            LOG(\"write failed\");\n            goto fail;\n        }\n    } else {\n        if (nbd_negotiate_write(client->ioc, buf, 18) < 0) {\n            LOG(\"write failed\");\n            goto fail;\n        }\n        rc = nbd_negotiate_options(client);\n        if (rc != 0) {\n            LOG(\"option negotiation failed\");\n            goto fail;\n        }\n\n        TRACE(\"advertising size %\" PRIu64 \" and flags %x\",\n              client->exp->size, client->exp->nbdflags | myflags);\n        stq_be_p(buf + 18, client->exp->size);\n        stw_be_p(buf + 26, client->exp->nbdflags | myflags);\n        len = client->no_zeroes ? 10 : sizeof(buf) - 18;\n        if (nbd_negotiate_write(client->ioc, buf + 18, len) < 0) {\n            LOG(\"write failed\");\n            goto fail;\n        }\n    }\n\n    TRACE(\"Negotiation succeeded.\");\n    rc = 0;\nfail:\n    return rc;\n}",
        "func": "static coroutine_fn int nbd_negotiate(NBDClientNewData *data)\n{\n    NBDClient *client = data->client;\n    char buf[8 + 8 + 8 + 128];\n    int rc;\n    const uint16_t myflags = (NBD_FLAG_HAS_FLAGS | NBD_FLAG_SEND_TRIM |\n                              NBD_FLAG_SEND_FLUSH | NBD_FLAG_SEND_FUA |\n                              NBD_FLAG_SEND_WRITE_ZEROES);\n    bool oldStyle;\n    size_t len;\n\n    /* Old style negotiation header without options\n        [ 0 ..   7]   passwd       (\"NBDMAGIC\")\n        [ 8 ..  15]   magic        (NBD_CLIENT_MAGIC)\n        [16 ..  23]   size\n        [24 ..  25]   server flags (0)\n        [26 ..  27]   export flags\n        [28 .. 151]   reserved     (0)\n\n       New style negotiation header with options\n        [ 0 ..   7]   passwd       (\"NBDMAGIC\")\n        [ 8 ..  15]   magic        (NBD_OPTS_MAGIC)\n        [16 ..  17]   server flags (0)\n        ....options sent....\n        [18 ..  25]   size\n        [26 ..  27]   export flags\n        [28 .. 151]   reserved     (0, omit if no_zeroes)\n     */\n\n    qio_channel_set_blocking(client->ioc, false, NULL);\n    rc = -EINVAL;\n\n    TRACE(\"Beginning negotiation.\");\n    memset(buf, 0, sizeof(buf));\n    memcpy(buf, \"NBDMAGIC\", 8);\n\n    oldStyle = client->exp != NULL && !client->tlscreds;\n    if (oldStyle) {\n        TRACE(\"advertising size %\" PRIu64 \" and flags %x\",\n              client->exp->size, client->exp->nbdflags | myflags);\n        stq_be_p(buf + 8, NBD_CLIENT_MAGIC);\n        stq_be_p(buf + 16, client->exp->size);\n        stw_be_p(buf + 26, client->exp->nbdflags | myflags);\n    } else {\n        stq_be_p(buf + 8, NBD_OPTS_MAGIC);\n        stw_be_p(buf + 16, NBD_FLAG_FIXED_NEWSTYLE | NBD_FLAG_NO_ZEROES);\n    }\n\n    if (oldStyle) {\n        if (client->tlscreds) {\n            TRACE(\"TLS cannot be enabled with oldstyle protocol\");\n            goto fail;\n        }\n        if (nbd_write(client->ioc, buf, sizeof(buf), NULL) < 0) {\n            LOG(\"write failed\");\n            goto fail;\n        }\n    } else {\n        if (nbd_write(client->ioc, buf, 18, NULL) < 0) {\n            LOG(\"write failed\");\n            goto fail;\n        }\n        rc = nbd_negotiate_options(client);\n        if (rc != 0) {\n            LOG(\"option negotiation failed\");\n            goto fail;\n        }\n\n        TRACE(\"advertising size %\" PRIu64 \" and flags %x\",\n              client->exp->size, client->exp->nbdflags | myflags);\n        stq_be_p(buf + 18, client->exp->size);\n        stw_be_p(buf + 26, client->exp->nbdflags | myflags);\n        len = client->no_zeroes ? 10 : sizeof(buf) - 18;\n        if (nbd_write(client->ioc, buf + 18, len, NULL) < 0) {\n            LOG(\"write failed\");\n            goto fail;\n        }\n    }\n\n    TRACE(\"Negotiation succeeded.\");\n    rc = 0;\nfail:\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -51,12 +51,12 @@\n             TRACE(\"TLS cannot be enabled with oldstyle protocol\");\n             goto fail;\n         }\n-        if (nbd_negotiate_write(client->ioc, buf, sizeof(buf)) < 0) {\n+        if (nbd_write(client->ioc, buf, sizeof(buf), NULL) < 0) {\n             LOG(\"write failed\");\n             goto fail;\n         }\n     } else {\n-        if (nbd_negotiate_write(client->ioc, buf, 18) < 0) {\n+        if (nbd_write(client->ioc, buf, 18, NULL) < 0) {\n             LOG(\"write failed\");\n             goto fail;\n         }\n@@ -71,7 +71,7 @@\n         stq_be_p(buf + 18, client->exp->size);\n         stw_be_p(buf + 26, client->exp->nbdflags | myflags);\n         len = client->no_zeroes ? 10 : sizeof(buf) - 18;\n-        if (nbd_negotiate_write(client->ioc, buf + 18, len) < 0) {\n+        if (nbd_write(client->ioc, buf + 18, len, NULL) < 0) {\n             LOG(\"write failed\");\n             goto fail;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "        if (nbd_negotiate_write(client->ioc, buf, sizeof(buf)) < 0) {",
                "        if (nbd_negotiate_write(client->ioc, buf, 18) < 0) {",
                "        if (nbd_negotiate_write(client->ioc, buf + 18, len) < 0) {"
            ],
            "added_lines": [
                "        if (nbd_write(client->ioc, buf, sizeof(buf), NULL) < 0) {",
                "        if (nbd_write(client->ioc, buf, 18, NULL) < 0) {",
                "        if (nbd_write(client->ioc, buf + 18, len, NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate_send_rep_list",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static int nbd_negotiate_send_rep_list(QIOChannel *ioc, NBDExport *exp)\n{\n    size_t name_len, desc_len;\n    uint32_t len;\n    const char *name = exp->name ? exp->name : \"\";\n    const char *desc = exp->description ? exp->description : \"\";\n    int rc;\n\n    TRACE(\"Advertising export name '%s' description '%s'\", name, desc);\n    name_len = strlen(name);\n    desc_len = strlen(desc);\n    len = name_len + desc_len + sizeof(len);\n    rc = nbd_negotiate_send_rep_len(ioc, NBD_REP_SERVER, NBD_OPT_LIST, len);\n    if (rc < 0) {\n        return rc;\n    }\n\n    len = cpu_to_be32(name_len);\n    if (nbd_negotiate_write(ioc, &len, sizeof(len)) < 0) {\n        LOG(\"write failed (name length)\");\n        return -EINVAL;\n    }\n    if (nbd_negotiate_write(ioc, name, name_len) < 0) {\n        LOG(\"write failed (name buffer)\");\n        return -EINVAL;\n    }\n    if (nbd_negotiate_write(ioc, desc, desc_len) < 0) {\n        LOG(\"write failed (description buffer)\");\n        return -EINVAL;\n    }\n    return 0;\n}",
        "func": "static int nbd_negotiate_send_rep_list(QIOChannel *ioc, NBDExport *exp)\n{\n    size_t name_len, desc_len;\n    uint32_t len;\n    const char *name = exp->name ? exp->name : \"\";\n    const char *desc = exp->description ? exp->description : \"\";\n    int rc;\n\n    TRACE(\"Advertising export name '%s' description '%s'\", name, desc);\n    name_len = strlen(name);\n    desc_len = strlen(desc);\n    len = name_len + desc_len + sizeof(len);\n    rc = nbd_negotiate_send_rep_len(ioc, NBD_REP_SERVER, NBD_OPT_LIST, len);\n    if (rc < 0) {\n        return rc;\n    }\n\n    len = cpu_to_be32(name_len);\n    if (nbd_write(ioc, &len, sizeof(len), NULL) < 0) {\n        LOG(\"write failed (name length)\");\n        return -EINVAL;\n    }\n    if (nbd_write(ioc, name, name_len, NULL) < 0) {\n        LOG(\"write failed (name buffer)\");\n        return -EINVAL;\n    }\n    if (nbd_write(ioc, desc, desc_len, NULL) < 0) {\n        LOG(\"write failed (description buffer)\");\n        return -EINVAL;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,15 +16,15 @@\n     }\n \n     len = cpu_to_be32(name_len);\n-    if (nbd_negotiate_write(ioc, &len, sizeof(len)) < 0) {\n+    if (nbd_write(ioc, &len, sizeof(len), NULL) < 0) {\n         LOG(\"write failed (name length)\");\n         return -EINVAL;\n     }\n-    if (nbd_negotiate_write(ioc, name, name_len) < 0) {\n+    if (nbd_write(ioc, name, name_len, NULL) < 0) {\n         LOG(\"write failed (name buffer)\");\n         return -EINVAL;\n     }\n-    if (nbd_negotiate_write(ioc, desc, desc_len) < 0) {\n+    if (nbd_write(ioc, desc, desc_len, NULL) < 0) {\n         LOG(\"write failed (description buffer)\");\n         return -EINVAL;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (nbd_negotiate_write(ioc, &len, sizeof(len)) < 0) {",
                "    if (nbd_negotiate_write(ioc, name, name_len) < 0) {",
                "    if (nbd_negotiate_write(ioc, desc, desc_len) < 0) {"
            ],
            "added_lines": [
                "    if (nbd_write(ioc, &len, sizeof(len), NULL) < 0) {",
                "    if (nbd_write(ioc, name, name_len, NULL) < 0) {",
                "    if (nbd_write(ioc, desc, desc_len, NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7539",
        "func_name": "qemu/nbd_negotiate_send_rep_err",
        "description": "An assertion-failure flaw was found in Qemu before 2.10.1, in the Network Block Device (NBD) server's initial connection negotiation, where the I/O coroutine was undefined. This could crash the qemu-nbd server if a client sent unexpected data during connection negotiation. A remote user or process could use this flaw to crash the qemu-nbd server resulting in denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/2b0bbc4f8809c972bad134bc1a2570dbb01dea0b",
        "commit_title": "nbd/server: get rid of nbd_negotiate_read and friends",
        "commit_text": " Functions nbd_negotiate_{read,write,drop_sync} were introduced in 1a6245a5b, when nbd_rwv (was nbd_wr_sync) was working through qemu_co_sendv_recvv (the path is nbd_wr_sync -> qemu_co_{recv/send} -> qemu_co_send_recv -> qemu_co_sendv_recvv), which just yields, without setting any handlers. But starting from ff82911cd nbd_rwv (was nbd_wr_syncv) works through qio_channel_yield() which sets handlers, so watchers are redundant in nbd_negotiate_{read,write,drop_sync}, then, let's just use nbd_{read,write,drop} functions.  Functions nbd_{read,write,drop} has errp parameter, which is unused in this patch. This will be fixed later.  Message-Id: <20170602150150.258222-4-vsementsov@virtuozzo.com>",
        "func_before": "static int GCC_FMT_ATTR(4, 5)\nnbd_negotiate_send_rep_err(QIOChannel *ioc, uint32_t type,\n                           uint32_t opt, const char *fmt, ...)\n{\n    va_list va;\n    char *msg;\n    int ret;\n    size_t len;\n\n    va_start(va, fmt);\n    msg = g_strdup_vprintf(fmt, va);\n    va_end(va);\n    len = strlen(msg);\n    assert(len < 4096);\n    TRACE(\"sending error message \\\"%s\\\"\", msg);\n    ret = nbd_negotiate_send_rep_len(ioc, type, opt, len);\n    if (ret < 0) {\n        goto out;\n    }\n    if (nbd_negotiate_write(ioc, msg, len) < 0) {\n        LOG(\"write failed (error message)\");\n        ret = -EIO;\n    } else {\n        ret = 0;\n    }\nout:\n    g_free(msg);\n    return ret;\n}",
        "func": "static int GCC_FMT_ATTR(4, 5)\nnbd_negotiate_send_rep_err(QIOChannel *ioc, uint32_t type,\n                           uint32_t opt, const char *fmt, ...)\n{\n    va_list va;\n    char *msg;\n    int ret;\n    size_t len;\n\n    va_start(va, fmt);\n    msg = g_strdup_vprintf(fmt, va);\n    va_end(va);\n    len = strlen(msg);\n    assert(len < 4096);\n    TRACE(\"sending error message \\\"%s\\\"\", msg);\n    ret = nbd_negotiate_send_rep_len(ioc, type, opt, len);\n    if (ret < 0) {\n        goto out;\n    }\n    if (nbd_write(ioc, msg, len, NULL) < 0) {\n        LOG(\"write failed (error message)\");\n        ret = -EIO;\n    } else {\n        ret = 0;\n    }\nout:\n    g_free(msg);\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,7 @@\n     if (ret < 0) {\n         goto out;\n     }\n-    if (nbd_negotiate_write(ioc, msg, len) < 0) {\n+    if (nbd_write(ioc, msg, len, NULL) < 0) {\n         LOG(\"write failed (error message)\");\n         ret = -EIO;\n     } else {",
        "diff_line_info": {
            "deleted_lines": [
                "    if (nbd_negotiate_write(ioc, msg, len) < 0) {"
            ],
            "added_lines": [
                "    if (nbd_write(ioc, msg, len, NULL) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-15822",
        "func_name": "ffmpeg/flv_write_packet",
        "description": "The flv_write_packet function in libavformat/flvenc.c in FFmpeg through 2.8 does not check for an empty audio packet, leading to an assertion failure.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/6b67d7f05918f7a1ee8fc6ff21355d7e8736aa10",
        "commit_title": "avformat/flvenc: Check audio packet size",
        "commit_text": " ",
        "func_before": "static int flv_write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    AVIOContext *pb      = s->pb;\n    AVCodecParameters *par = s->streams[pkt->stream_index]->codecpar;\n    FLVContext *flv      = s->priv_data;\n    FLVStreamContext *sc = s->streams[pkt->stream_index]->priv_data;\n    unsigned ts;\n    int size = pkt->size;\n    uint8_t *data = NULL;\n    int flags = -1, flags_size, ret;\n    int64_t cur_offset = avio_tell(pb);\n\n    if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A ||\n        par->codec_id == AV_CODEC_ID_VP6  || par->codec_id == AV_CODEC_ID_AAC)\n        flags_size = 2;\n    else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4)\n        flags_size = 5;\n    else\n        flags_size = 1;\n\n    if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264\n            || par->codec_id == AV_CODEC_ID_MPEG4) {\n        int side_size = 0;\n        uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);\n        if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {\n            av_free(par->extradata);\n            par->extradata = av_mallocz(side_size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (!par->extradata) {\n                par->extradata_size = 0;\n                return AVERROR(ENOMEM);\n            }\n            memcpy(par->extradata, side, side_size);\n            par->extradata_size = side_size;\n            flv_write_codec_header(s, par, pkt->dts);\n        }\n    }\n\n    if (flv->delay == AV_NOPTS_VALUE)\n        flv->delay = -pkt->dts;\n\n    if (pkt->dts < -flv->delay) {\n        av_log(s, AV_LOG_WARNING,\n               \"Packets are not in the proper order with respect to DTS\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    ts = pkt->dts;\n\n    if (s->event_flags & AVSTREAM_EVENT_FLAG_METADATA_UPDATED) {\n        write_metadata(s, ts);\n        s->event_flags &= ~AVSTREAM_EVENT_FLAG_METADATA_UPDATED;\n    }\n\n    avio_write_marker(pb, av_rescale(ts, AV_TIME_BASE, 1000),\n                      pkt->flags & AV_PKT_FLAG_KEY && (flv->video_par ? par->codec_type == AVMEDIA_TYPE_VIDEO : 1) ? AVIO_DATA_MARKER_SYNC_POINT : AVIO_DATA_MARKER_BOUNDARY_POINT);\n\n    switch (par->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        avio_w8(pb, FLV_TAG_TYPE_VIDEO);\n\n        flags = ff_codec_get_tag(flv_video_codec_ids, par->codec_id);\n\n        flags |= pkt->flags & AV_PKT_FLAG_KEY ? FLV_FRAME_KEY : FLV_FRAME_INTER;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        flags = get_audio_flags(s, par);\n\n        av_assert0(size);\n\n        avio_w8(pb, FLV_TAG_TYPE_AUDIO);\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n    case AVMEDIA_TYPE_DATA:\n        avio_w8(pb, FLV_TAG_TYPE_META);\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4) {\n        /* check if extradata looks like mp4 formatted */\n        if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)\n            if ((ret = ff_avc_parse_nal_units_buf(pkt->data, &data, &size)) < 0)\n                return ret;\n    } else if (par->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&\n               (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {\n        if (!s->streams[pkt->stream_index]->nb_frames) {\n        av_log(s, AV_LOG_ERROR, \"Malformed AAC bitstream detected: \"\n               \"use the audio bitstream filter 'aac_adtstoasc' to fix it \"\n               \"('-bsf:a aac_adtstoasc' option with ffmpeg)\\n\");\n        return AVERROR_INVALIDDATA;\n        }\n        av_log(s, AV_LOG_WARNING, \"aac bitstream error\\n\");\n    }\n\n    /* check Speex packet duration */\n    if (par->codec_id == AV_CODEC_ID_SPEEX && ts - sc->last_ts > 160)\n        av_log(s, AV_LOG_WARNING, \"Warning: Speex stream has more than \"\n                                  \"8 frames per packet. Adobe Flash \"\n                                  \"Player cannot handle this!\\n\");\n\n    if (sc->last_ts < ts)\n        sc->last_ts = ts;\n\n    if (size + flags_size >= 1<<24) {\n        av_log(s, AV_LOG_ERROR, \"Too large packet with size %u >= %u\\n\",\n               size + flags_size, 1<<24);\n        return AVERROR(EINVAL);\n    }\n\n    avio_wb24(pb, size + flags_size);\n    put_timestamp(pb, ts);\n    avio_wb24(pb, flv->reserved);\n\n    if (par->codec_type == AVMEDIA_TYPE_DATA ||\n        par->codec_type == AVMEDIA_TYPE_SUBTITLE ) {\n        int data_size;\n        int64_t metadata_size_pos = avio_tell(pb);\n        if (par->codec_id == AV_CODEC_ID_TEXT) {\n            // legacy FFmpeg magic?\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"onTextData\");\n            avio_w8(pb, AMF_DATA_TYPE_MIXEDARRAY);\n            avio_wb32(pb, 2);\n            put_amf_string(pb, \"type\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"Text\");\n            put_amf_string(pb, \"text\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, pkt->data);\n            put_amf_string(pb, \"\");\n            avio_w8(pb, AMF_END_OF_OBJECT);\n        } else {\n            // just pass the metadata through\n            avio_write(pb, data ? data : pkt->data, size);\n        }\n        /* write total size of tag */\n        data_size = avio_tell(pb) - metadata_size_pos;\n        avio_seek(pb, metadata_size_pos - 10, SEEK_SET);\n        avio_wb24(pb, data_size);\n        avio_seek(pb, data_size + 10 - 3, SEEK_CUR);\n        avio_wb32(pb, data_size + 11);\n    } else {\n        av_assert1(flags>=0);\n        avio_w8(pb,flags);\n        if (par->codec_id == AV_CODEC_ID_VP6)\n            avio_w8(pb,0);\n        if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A) {\n            if (par->extradata_size)\n                avio_w8(pb, par->extradata[0]);\n            else\n                avio_w8(pb, ((FFALIGN(par->width,  16) - par->width) << 4) |\n                             (FFALIGN(par->height, 16) - par->height));\n        } else if (par->codec_id == AV_CODEC_ID_AAC)\n            avio_w8(pb, 1); // AAC raw\n        else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4) {\n            avio_w8(pb, 1); // AVC NALU\n            avio_wb24(pb, pkt->pts - pkt->dts);\n        }\n\n        avio_write(pb, data ? data : pkt->data, size);\n\n        avio_wb32(pb, size + flags_size + 11); // previous tag size\n        flv->duration = FFMAX(flv->duration,\n                              pkt->pts + flv->delay + pkt->duration);\n    }\n\n    if (flv->flags & FLV_ADD_KEYFRAME_INDEX) {\n        switch (par->codec_type) {\n            case AVMEDIA_TYPE_VIDEO:\n                flv->videosize += (avio_tell(pb) - cur_offset);\n                flv->lasttimestamp = flv->acurframeindex / flv->framerate;\n                if (pkt->flags & AV_PKT_FLAG_KEY) {\n                    double ts = flv->acurframeindex / flv->framerate;\n                    int64_t pos = cur_offset;\n\n                    flv->lastkeyframetimestamp = flv->acurframeindex / flv->framerate;\n                    flv->lastkeyframelocation = pos;\n                    flv_append_keyframe_info(s, flv, ts, pos);\n                }\n                flv->acurframeindex++;\n                break;\n\n            case AVMEDIA_TYPE_AUDIO:\n                flv->audiosize += (avio_tell(pb) - cur_offset);\n                break;\n\n            default:\n                av_log(s, AV_LOG_WARNING, \"par->codec_type is type = [%d]\\n\", par->codec_type);\n                break;\n        }\n    }\n\n    av_free(data);\n\n    return pb->error;\n}",
        "func": "static int flv_write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    AVIOContext *pb      = s->pb;\n    AVCodecParameters *par = s->streams[pkt->stream_index]->codecpar;\n    FLVContext *flv      = s->priv_data;\n    FLVStreamContext *sc = s->streams[pkt->stream_index]->priv_data;\n    unsigned ts;\n    int size = pkt->size;\n    uint8_t *data = NULL;\n    int flags = -1, flags_size, ret;\n    int64_t cur_offset = avio_tell(pb);\n\n    if (par->codec_type == AVMEDIA_TYPE_AUDIO && !pkt->size) {\n        av_log(s, AV_LOG_WARNING, \"Empty audio Packet\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A ||\n        par->codec_id == AV_CODEC_ID_VP6  || par->codec_id == AV_CODEC_ID_AAC)\n        flags_size = 2;\n    else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4)\n        flags_size = 5;\n    else\n        flags_size = 1;\n\n    if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264\n            || par->codec_id == AV_CODEC_ID_MPEG4) {\n        int side_size = 0;\n        uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);\n        if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {\n            av_free(par->extradata);\n            par->extradata = av_mallocz(side_size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (!par->extradata) {\n                par->extradata_size = 0;\n                return AVERROR(ENOMEM);\n            }\n            memcpy(par->extradata, side, side_size);\n            par->extradata_size = side_size;\n            flv_write_codec_header(s, par, pkt->dts);\n        }\n    }\n\n    if (flv->delay == AV_NOPTS_VALUE)\n        flv->delay = -pkt->dts;\n\n    if (pkt->dts < -flv->delay) {\n        av_log(s, AV_LOG_WARNING,\n               \"Packets are not in the proper order with respect to DTS\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    ts = pkt->dts;\n\n    if (s->event_flags & AVSTREAM_EVENT_FLAG_METADATA_UPDATED) {\n        write_metadata(s, ts);\n        s->event_flags &= ~AVSTREAM_EVENT_FLAG_METADATA_UPDATED;\n    }\n\n    avio_write_marker(pb, av_rescale(ts, AV_TIME_BASE, 1000),\n                      pkt->flags & AV_PKT_FLAG_KEY && (flv->video_par ? par->codec_type == AVMEDIA_TYPE_VIDEO : 1) ? AVIO_DATA_MARKER_SYNC_POINT : AVIO_DATA_MARKER_BOUNDARY_POINT);\n\n    switch (par->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        avio_w8(pb, FLV_TAG_TYPE_VIDEO);\n\n        flags = ff_codec_get_tag(flv_video_codec_ids, par->codec_id);\n\n        flags |= pkt->flags & AV_PKT_FLAG_KEY ? FLV_FRAME_KEY : FLV_FRAME_INTER;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        flags = get_audio_flags(s, par);\n\n        av_assert0(size);\n\n        avio_w8(pb, FLV_TAG_TYPE_AUDIO);\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n    case AVMEDIA_TYPE_DATA:\n        avio_w8(pb, FLV_TAG_TYPE_META);\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4) {\n        /* check if extradata looks like mp4 formatted */\n        if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)\n            if ((ret = ff_avc_parse_nal_units_buf(pkt->data, &data, &size)) < 0)\n                return ret;\n    } else if (par->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&\n               (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {\n        if (!s->streams[pkt->stream_index]->nb_frames) {\n        av_log(s, AV_LOG_ERROR, \"Malformed AAC bitstream detected: \"\n               \"use the audio bitstream filter 'aac_adtstoasc' to fix it \"\n               \"('-bsf:a aac_adtstoasc' option with ffmpeg)\\n\");\n        return AVERROR_INVALIDDATA;\n        }\n        av_log(s, AV_LOG_WARNING, \"aac bitstream error\\n\");\n    }\n\n    /* check Speex packet duration */\n    if (par->codec_id == AV_CODEC_ID_SPEEX && ts - sc->last_ts > 160)\n        av_log(s, AV_LOG_WARNING, \"Warning: Speex stream has more than \"\n                                  \"8 frames per packet. Adobe Flash \"\n                                  \"Player cannot handle this!\\n\");\n\n    if (sc->last_ts < ts)\n        sc->last_ts = ts;\n\n    if (size + flags_size >= 1<<24) {\n        av_log(s, AV_LOG_ERROR, \"Too large packet with size %u >= %u\\n\",\n               size + flags_size, 1<<24);\n        return AVERROR(EINVAL);\n    }\n\n    avio_wb24(pb, size + flags_size);\n    put_timestamp(pb, ts);\n    avio_wb24(pb, flv->reserved);\n\n    if (par->codec_type == AVMEDIA_TYPE_DATA ||\n        par->codec_type == AVMEDIA_TYPE_SUBTITLE ) {\n        int data_size;\n        int64_t metadata_size_pos = avio_tell(pb);\n        if (par->codec_id == AV_CODEC_ID_TEXT) {\n            // legacy FFmpeg magic?\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"onTextData\");\n            avio_w8(pb, AMF_DATA_TYPE_MIXEDARRAY);\n            avio_wb32(pb, 2);\n            put_amf_string(pb, \"type\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"Text\");\n            put_amf_string(pb, \"text\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, pkt->data);\n            put_amf_string(pb, \"\");\n            avio_w8(pb, AMF_END_OF_OBJECT);\n        } else {\n            // just pass the metadata through\n            avio_write(pb, data ? data : pkt->data, size);\n        }\n        /* write total size of tag */\n        data_size = avio_tell(pb) - metadata_size_pos;\n        avio_seek(pb, metadata_size_pos - 10, SEEK_SET);\n        avio_wb24(pb, data_size);\n        avio_seek(pb, data_size + 10 - 3, SEEK_CUR);\n        avio_wb32(pb, data_size + 11);\n    } else {\n        av_assert1(flags>=0);\n        avio_w8(pb,flags);\n        if (par->codec_id == AV_CODEC_ID_VP6)\n            avio_w8(pb,0);\n        if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A) {\n            if (par->extradata_size)\n                avio_w8(pb, par->extradata[0]);\n            else\n                avio_w8(pb, ((FFALIGN(par->width,  16) - par->width) << 4) |\n                             (FFALIGN(par->height, 16) - par->height));\n        } else if (par->codec_id == AV_CODEC_ID_AAC)\n            avio_w8(pb, 1); // AAC raw\n        else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4) {\n            avio_w8(pb, 1); // AVC NALU\n            avio_wb24(pb, pkt->pts - pkt->dts);\n        }\n\n        avio_write(pb, data ? data : pkt->data, size);\n\n        avio_wb32(pb, size + flags_size + 11); // previous tag size\n        flv->duration = FFMAX(flv->duration,\n                              pkt->pts + flv->delay + pkt->duration);\n    }\n\n    if (flv->flags & FLV_ADD_KEYFRAME_INDEX) {\n        switch (par->codec_type) {\n            case AVMEDIA_TYPE_VIDEO:\n                flv->videosize += (avio_tell(pb) - cur_offset);\n                flv->lasttimestamp = flv->acurframeindex / flv->framerate;\n                if (pkt->flags & AV_PKT_FLAG_KEY) {\n                    double ts = flv->acurframeindex / flv->framerate;\n                    int64_t pos = cur_offset;\n\n                    flv->lastkeyframetimestamp = flv->acurframeindex / flv->framerate;\n                    flv->lastkeyframelocation = pos;\n                    flv_append_keyframe_info(s, flv, ts, pos);\n                }\n                flv->acurframeindex++;\n                break;\n\n            case AVMEDIA_TYPE_AUDIO:\n                flv->audiosize += (avio_tell(pb) - cur_offset);\n                break;\n\n            default:\n                av_log(s, AV_LOG_WARNING, \"par->codec_type is type = [%d]\\n\", par->codec_type);\n                break;\n        }\n    }\n\n    av_free(data);\n\n    return pb->error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,11 @@\n     uint8_t *data = NULL;\n     int flags = -1, flags_size, ret;\n     int64_t cur_offset = avio_tell(pb);\n+\n+    if (par->codec_type == AVMEDIA_TYPE_AUDIO && !pkt->size) {\n+        av_log(s, AV_LOG_WARNING, \"Empty audio Packet\\n\");\n+        return AVERROR(EINVAL);\n+    }\n \n     if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A ||\n         par->codec_id == AV_CODEC_ID_VP6  || par->codec_id == AV_CODEC_ID_AAC)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (par->codec_type == AVMEDIA_TYPE_AUDIO && !pkt->size) {",
                "        av_log(s, AV_LOG_WARNING, \"Empty audio Packet\\n\");",
                "        return AVERROR(EINVAL);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-15822",
        "func_name": "ffmpeg/flv_write_packet",
        "description": "The flv_write_packet function in libavformat/flvenc.c in FFmpeg through 2.8 does not check for an empty audio packet, leading to an assertion failure.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/d8ecb335fe4852bbc172c7b79e66944d158b4d92",
        "commit_title": "avformat/flvenc: Check audio packet size",
        "commit_text": "  (cherry picked from commit 6b67d7f05918f7a1ee8fc6ff21355d7e8736aa10)",
        "func_before": "static int flv_write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    AVIOContext *pb      = s->pb;\n    AVCodecContext *enc  = s->streams[pkt->stream_index]->codec;\n    FLVContext *flv      = s->priv_data;\n    FLVStreamContext *sc = s->streams[pkt->stream_index]->priv_data;\n    unsigned ts;\n    int size = pkt->size;\n    uint8_t *data = NULL;\n    int flags = -1, flags_size, ret;\n\n    if (enc->codec_id == AV_CODEC_ID_VP6F || enc->codec_id == AV_CODEC_ID_VP6A ||\n        enc->codec_id == AV_CODEC_ID_VP6  || enc->codec_id == AV_CODEC_ID_AAC)\n        flags_size = 2;\n    else if (enc->codec_id == AV_CODEC_ID_H264 || enc->codec_id == AV_CODEC_ID_MPEG4)\n        flags_size = 5;\n    else\n        flags_size = 1;\n\n    if (flv->delay == AV_NOPTS_VALUE)\n        flv->delay = -pkt->dts;\n\n    if (pkt->dts < -flv->delay) {\n        av_log(s, AV_LOG_WARNING,\n               \"Packets are not in the proper order with respect to DTS\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    ts = pkt->dts + flv->delay; // add delay to force positive dts\n\n    if (s->event_flags & AVSTREAM_EVENT_FLAG_METADATA_UPDATED) {\n        write_metadata(s, ts);\n        s->event_flags &= ~AVSTREAM_EVENT_FLAG_METADATA_UPDATED;\n    }\n\n    switch (enc->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        avio_w8(pb, FLV_TAG_TYPE_VIDEO);\n\n        flags = ff_codec_get_tag(flv_video_codec_ids, enc->codec_id);\n\n        flags |= pkt->flags & AV_PKT_FLAG_KEY ? FLV_FRAME_KEY : FLV_FRAME_INTER;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        flags = get_audio_flags(s, enc);\n\n        av_assert0(size);\n\n        avio_w8(pb, FLV_TAG_TYPE_AUDIO);\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n    case AVMEDIA_TYPE_DATA:\n        avio_w8(pb, FLV_TAG_TYPE_META);\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    if (enc->codec_id == AV_CODEC_ID_H264 || enc->codec_id == AV_CODEC_ID_MPEG4) {\n        /* check if extradata looks like mp4 formatted */\n        if (enc->extradata_size > 0 && *(uint8_t*)enc->extradata != 1)\n            if ((ret = ff_avc_parse_nal_units_buf(pkt->data, &data, &size)) < 0)\n                return ret;\n    } else if (enc->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&\n               (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {\n        if (!s->streams[pkt->stream_index]->nb_frames) {\n        av_log(s, AV_LOG_ERROR, \"Malformed AAC bitstream detected: \"\n               \"use the audio bitstream filter 'aac_adtstoasc' to fix it \"\n               \"('-bsf:a aac_adtstoasc' option with ffmpeg)\\n\");\n        return AVERROR_INVALIDDATA;\n        }\n        av_log(s, AV_LOG_WARNING, \"aac bitstream error\\n\");\n    }\n\n    /* check Speex packet duration */\n    if (enc->codec_id == AV_CODEC_ID_SPEEX && ts - sc->last_ts > 160)\n        av_log(s, AV_LOG_WARNING, \"Warning: Speex stream has more than \"\n                                  \"8 frames per packet. Adobe Flash \"\n                                  \"Player cannot handle this!\\n\");\n\n    if (sc->last_ts < ts)\n        sc->last_ts = ts;\n\n    if (size + flags_size >= 1<<24) {\n        av_log(s, AV_LOG_ERROR, \"Too large packet with size %u >= %u\\n\",\n               size + flags_size, 1<<24);\n        return AVERROR(EINVAL);\n    }\n\n    avio_wb24(pb, size + flags_size);\n    avio_wb24(pb, ts & 0xFFFFFF);\n    avio_w8(pb, (ts >> 24) & 0x7F); // timestamps are 32 bits _signed_\n    avio_wb24(pb, flv->reserved);\n\n    if (enc->codec_type == AVMEDIA_TYPE_DATA ||\n        enc->codec_type == AVMEDIA_TYPE_SUBTITLE ) {\n        int data_size;\n        int64_t metadata_size_pos = avio_tell(pb);\n        if (enc->codec_id == AV_CODEC_ID_TEXT) {\n            // legacy FFmpeg magic?\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"onTextData\");\n            avio_w8(pb, AMF_DATA_TYPE_MIXEDARRAY);\n            avio_wb32(pb, 2);\n            put_amf_string(pb, \"type\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"Text\");\n            put_amf_string(pb, \"text\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, pkt->data);\n            put_amf_string(pb, \"\");\n            avio_w8(pb, AMF_END_OF_OBJECT);\n        } else {\n            // just pass the metadata through\n            avio_write(pb, data ? data : pkt->data, size);\n        }\n        /* write total size of tag */\n        data_size = avio_tell(pb) - metadata_size_pos;\n        avio_seek(pb, metadata_size_pos - 10, SEEK_SET);\n        avio_wb24(pb, data_size);\n        avio_seek(pb, data_size + 10 - 3, SEEK_CUR);\n        avio_wb32(pb, data_size + 11);\n    } else {\n        av_assert1(flags>=0);\n        avio_w8(pb,flags);\n        if (enc->codec_id == AV_CODEC_ID_VP6)\n            avio_w8(pb,0);\n        if (enc->codec_id == AV_CODEC_ID_VP6F || enc->codec_id == AV_CODEC_ID_VP6A) {\n            if (enc->extradata_size)\n                avio_w8(pb, enc->extradata[0]);\n            else\n                avio_w8(pb, ((FFALIGN(enc->width,  16) - enc->width) << 4) |\n                             (FFALIGN(enc->height, 16) - enc->height));\n        } else if (enc->codec_id == AV_CODEC_ID_AAC)\n            avio_w8(pb, 1); // AAC raw\n        else if (enc->codec_id == AV_CODEC_ID_H264 || enc->codec_id == AV_CODEC_ID_MPEG4) {\n            avio_w8(pb, 1); // AVC NALU\n            avio_wb24(pb, pkt->pts - pkt->dts);\n        }\n\n        avio_write(pb, data ? data : pkt->data, size);\n\n        avio_wb32(pb, size + flags_size + 11); // previous tag size\n        flv->duration = FFMAX(flv->duration,\n                              pkt->pts + flv->delay + pkt->duration);\n    }\n\n    av_free(data);\n\n    return pb->error;\n}",
        "func": "static int flv_write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    AVIOContext *pb      = s->pb;\n    AVCodecContext *enc  = s->streams[pkt->stream_index]->codec;\n    FLVContext *flv      = s->priv_data;\n    FLVStreamContext *sc = s->streams[pkt->stream_index]->priv_data;\n    unsigned ts;\n    int size = pkt->size;\n    uint8_t *data = NULL;\n    int flags = -1, flags_size, ret;\n\n    if (enc->codec_type == AVMEDIA_TYPE_AUDIO && !pkt->size) {\n        av_log(s, AV_LOG_WARNING, \"Empty audio Packet\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (enc->codec_id == AV_CODEC_ID_VP6F || enc->codec_id == AV_CODEC_ID_VP6A ||\n        enc->codec_id == AV_CODEC_ID_VP6  || enc->codec_id == AV_CODEC_ID_AAC)\n        flags_size = 2;\n    else if (enc->codec_id == AV_CODEC_ID_H264 || enc->codec_id == AV_CODEC_ID_MPEG4)\n        flags_size = 5;\n    else\n        flags_size = 1;\n\n    if (flv->delay == AV_NOPTS_VALUE)\n        flv->delay = -pkt->dts;\n\n    if (pkt->dts < -flv->delay) {\n        av_log(s, AV_LOG_WARNING,\n               \"Packets are not in the proper order with respect to DTS\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    ts = pkt->dts + flv->delay; // add delay to force positive dts\n\n    if (s->event_flags & AVSTREAM_EVENT_FLAG_METADATA_UPDATED) {\n        write_metadata(s, ts);\n        s->event_flags &= ~AVSTREAM_EVENT_FLAG_METADATA_UPDATED;\n    }\n\n    switch (enc->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        avio_w8(pb, FLV_TAG_TYPE_VIDEO);\n\n        flags = ff_codec_get_tag(flv_video_codec_ids, enc->codec_id);\n\n        flags |= pkt->flags & AV_PKT_FLAG_KEY ? FLV_FRAME_KEY : FLV_FRAME_INTER;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        flags = get_audio_flags(s, enc);\n\n        av_assert0(size);\n\n        avio_w8(pb, FLV_TAG_TYPE_AUDIO);\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n    case AVMEDIA_TYPE_DATA:\n        avio_w8(pb, FLV_TAG_TYPE_META);\n        break;\n    default:\n        return AVERROR(EINVAL);\n    }\n\n    if (enc->codec_id == AV_CODEC_ID_H264 || enc->codec_id == AV_CODEC_ID_MPEG4) {\n        /* check if extradata looks like mp4 formatted */\n        if (enc->extradata_size > 0 && *(uint8_t*)enc->extradata != 1)\n            if ((ret = ff_avc_parse_nal_units_buf(pkt->data, &data, &size)) < 0)\n                return ret;\n    } else if (enc->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&\n               (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {\n        if (!s->streams[pkt->stream_index]->nb_frames) {\n        av_log(s, AV_LOG_ERROR, \"Malformed AAC bitstream detected: \"\n               \"use the audio bitstream filter 'aac_adtstoasc' to fix it \"\n               \"('-bsf:a aac_adtstoasc' option with ffmpeg)\\n\");\n        return AVERROR_INVALIDDATA;\n        }\n        av_log(s, AV_LOG_WARNING, \"aac bitstream error\\n\");\n    }\n\n    /* check Speex packet duration */\n    if (enc->codec_id == AV_CODEC_ID_SPEEX && ts - sc->last_ts > 160)\n        av_log(s, AV_LOG_WARNING, \"Warning: Speex stream has more than \"\n                                  \"8 frames per packet. Adobe Flash \"\n                                  \"Player cannot handle this!\\n\");\n\n    if (sc->last_ts < ts)\n        sc->last_ts = ts;\n\n    if (size + flags_size >= 1<<24) {\n        av_log(s, AV_LOG_ERROR, \"Too large packet with size %u >= %u\\n\",\n               size + flags_size, 1<<24);\n        return AVERROR(EINVAL);\n    }\n\n    avio_wb24(pb, size + flags_size);\n    avio_wb24(pb, ts & 0xFFFFFF);\n    avio_w8(pb, (ts >> 24) & 0x7F); // timestamps are 32 bits _signed_\n    avio_wb24(pb, flv->reserved);\n\n    if (enc->codec_type == AVMEDIA_TYPE_DATA ||\n        enc->codec_type == AVMEDIA_TYPE_SUBTITLE ) {\n        int data_size;\n        int64_t metadata_size_pos = avio_tell(pb);\n        if (enc->codec_id == AV_CODEC_ID_TEXT) {\n            // legacy FFmpeg magic?\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"onTextData\");\n            avio_w8(pb, AMF_DATA_TYPE_MIXEDARRAY);\n            avio_wb32(pb, 2);\n            put_amf_string(pb, \"type\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, \"Text\");\n            put_amf_string(pb, \"text\");\n            avio_w8(pb, AMF_DATA_TYPE_STRING);\n            put_amf_string(pb, pkt->data);\n            put_amf_string(pb, \"\");\n            avio_w8(pb, AMF_END_OF_OBJECT);\n        } else {\n            // just pass the metadata through\n            avio_write(pb, data ? data : pkt->data, size);\n        }\n        /* write total size of tag */\n        data_size = avio_tell(pb) - metadata_size_pos;\n        avio_seek(pb, metadata_size_pos - 10, SEEK_SET);\n        avio_wb24(pb, data_size);\n        avio_seek(pb, data_size + 10 - 3, SEEK_CUR);\n        avio_wb32(pb, data_size + 11);\n    } else {\n        av_assert1(flags>=0);\n        avio_w8(pb,flags);\n        if (enc->codec_id == AV_CODEC_ID_VP6)\n            avio_w8(pb,0);\n        if (enc->codec_id == AV_CODEC_ID_VP6F || enc->codec_id == AV_CODEC_ID_VP6A) {\n            if (enc->extradata_size)\n                avio_w8(pb, enc->extradata[0]);\n            else\n                avio_w8(pb, ((FFALIGN(enc->width,  16) - enc->width) << 4) |\n                             (FFALIGN(enc->height, 16) - enc->height));\n        } else if (enc->codec_id == AV_CODEC_ID_AAC)\n            avio_w8(pb, 1); // AAC raw\n        else if (enc->codec_id == AV_CODEC_ID_H264 || enc->codec_id == AV_CODEC_ID_MPEG4) {\n            avio_w8(pb, 1); // AVC NALU\n            avio_wb24(pb, pkt->pts - pkt->dts);\n        }\n\n        avio_write(pb, data ? data : pkt->data, size);\n\n        avio_wb32(pb, size + flags_size + 11); // previous tag size\n        flv->duration = FFMAX(flv->duration,\n                              pkt->pts + flv->delay + pkt->duration);\n    }\n\n    av_free(data);\n\n    return pb->error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,11 @@\n     int size = pkt->size;\n     uint8_t *data = NULL;\n     int flags = -1, flags_size, ret;\n+\n+    if (enc->codec_type == AVMEDIA_TYPE_AUDIO && !pkt->size) {\n+        av_log(s, AV_LOG_WARNING, \"Empty audio Packet\\n\");\n+        return AVERROR(EINVAL);\n+    }\n \n     if (enc->codec_id == AV_CODEC_ID_VP6F || enc->codec_id == AV_CODEC_ID_VP6A ||\n         enc->codec_id == AV_CODEC_ID_VP6  || enc->codec_id == AV_CODEC_ID_AAC)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (enc->codec_type == AVMEDIA_TYPE_AUDIO && !pkt->size) {",
                "        av_log(s, AV_LOG_WARNING, \"Empty audio Packet\\n\");",
                "        return AVERROR(EINVAL);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-17204",
        "func_name": "openvswitch/ovs/parse_group_prop_ntr_selection_method",
        "description": "An issue was discovered in Open vSwitch (OvS) 2.7.x through 2.7.6, affecting parse_group_prop_ntr_selection_method in lib/ofp-util.c. When decoding a group mod, it validates the group type and command after the whole group mod has been decoded. The OF1.5 decoder, however, tries to use the type and command earlier, when it might still be invalid. This causes an assertion failure (via OVS_NOT_REACHED). ovs-vswitchd does not enable support for OpenFlow 1.5 by default.",
        "git_url": "https://github.com/openvswitch/ovs/commit/4af6da3b275b764b1afe194df6499b33d2bf4cde",
        "commit_title": "ofp-group: Don't assert-fail decoding bad OF1.5 group mod type or command.",
        "commit_text": " When decoding a group mod, the current code validates the group type and command after the whole group mod has been decoded.  The OF1.5 decoder, however, tries to use the type and command earlier, when it might still be invalid.  This caused an assertion failure (via OVS_NOT_REACHED).  This commit fixes the problem.  ovs-vswitchd does not enable support for OpenFlow 1.5 by default.  Reported-at: https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=9249",
        "func_before": "static enum ofperr\nparse_group_prop_ntr_selection_method(struct ofpbuf *payload,\n                                      enum ofp11_group_type group_type,\n                                      enum ofp15_group_mod_command group_cmd,\n                                      struct ofputil_group_props *gp)\n{\n    struct ntr_group_prop_selection_method *prop = payload->data;\n    size_t fields_len, method_len;\n    enum ofperr error;\n\n    switch (group_type) {\n    case OFPGT11_SELECT:\n        break;\n    case OFPGT11_ALL:\n    case OFPGT11_INDIRECT:\n    case OFPGT11_FF:\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method property is \"\n                    \"only allowed for select groups\");\n        return OFPERR_OFPBPC_BAD_VALUE;\n    default:\n        OVS_NOT_REACHED();\n    }\n\n    switch (group_cmd) {\n    case OFPGC15_ADD:\n    case OFPGC15_MODIFY:\n    case OFPGC15_ADD_OR_MOD:\n        break;\n    case OFPGC15_DELETE:\n    case OFPGC15_INSERT_BUCKET:\n    case OFPGC15_REMOVE_BUCKET:\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method property is \"\n                    \"only allowed for add and delete group modifications\");\n        return OFPERR_OFPBPC_BAD_VALUE;\n    default:\n        OVS_NOT_REACHED();\n    }\n\n    if (payload->size < sizeof *prop) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method property \"\n                    \"length %u is not valid\", payload->size);\n        return OFPERR_OFPBPC_BAD_LEN;\n    }\n\n    method_len = strnlen(prop->selection_method, NTR_MAX_SELECTION_METHOD_LEN);\n\n    if (method_len == NTR_MAX_SELECTION_METHOD_LEN) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false,\n                    \"ntr selection method is not null terminated\");\n        return OFPERR_OFPBPC_BAD_VALUE;\n    }\n\n    if (strcmp(\"hash\", prop->selection_method)\n        && strcmp(\"dp_hash\", prop->selection_method)) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false,\n                    \"ntr selection method '%s' is not supported\",\n                    prop->selection_method);\n        return OFPERR_OFPBPC_BAD_VALUE;\n    }\n    /* 'method_len' is now non-zero. */\n\n    strcpy(gp->selection_method, prop->selection_method);\n    gp->selection_method_param = ntohll(prop->selection_method_param);\n\n    ofpbuf_pull(payload, sizeof *prop);\n\n    fields_len = ntohs(prop->length) - sizeof *prop;\n    if (fields_len && strcmp(\"hash\", gp->selection_method)) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method %s \"\n                    \"does not support fields\", gp->selection_method);\n        return OFPERR_OFPBPC_BAD_VALUE;\n    }\n\n    error = oxm_pull_field_array(payload->data, fields_len,\n                                 &gp->fields);\n    if (error) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false,\n                    \"ntr selection method fields are invalid\");\n        return error;\n    }\n\n    return 0;\n}",
        "func": "static enum ofperr\nparse_group_prop_ntr_selection_method(struct ofpbuf *payload,\n                                      enum ofp11_group_type group_type,\n                                      enum ofp15_group_mod_command group_cmd,\n                                      struct ofputil_group_props *gp)\n{\n    struct ntr_group_prop_selection_method *prop = payload->data;\n    size_t fields_len, method_len;\n    enum ofperr error;\n\n    switch (group_type) {\n    case OFPGT11_SELECT:\n        break;\n    case OFPGT11_ALL:\n    case OFPGT11_INDIRECT:\n    case OFPGT11_FF:\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method property is \"\n                    \"only allowed for select groups\");\n        return OFPERR_OFPBPC_BAD_VALUE;\n    default:\n        return OFPERR_OFPGMFC_BAD_TYPE;\n    }\n\n    switch (group_cmd) {\n    case OFPGC15_ADD:\n    case OFPGC15_MODIFY:\n    case OFPGC15_ADD_OR_MOD:\n        break;\n    case OFPGC15_DELETE:\n    case OFPGC15_INSERT_BUCKET:\n    case OFPGC15_REMOVE_BUCKET:\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method property is \"\n                    \"only allowed for add and delete group modifications\");\n        return OFPERR_OFPBPC_BAD_VALUE;\n    default:\n        return OFPERR_OFPGMFC_BAD_COMMAND;\n    }\n\n    if (payload->size < sizeof *prop) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method property \"\n                    \"length %u is not valid\", payload->size);\n        return OFPERR_OFPBPC_BAD_LEN;\n    }\n\n    method_len = strnlen(prop->selection_method, NTR_MAX_SELECTION_METHOD_LEN);\n\n    if (method_len == NTR_MAX_SELECTION_METHOD_LEN) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false,\n                    \"ntr selection method is not null terminated\");\n        return OFPERR_OFPBPC_BAD_VALUE;\n    }\n\n    if (strcmp(\"hash\", prop->selection_method)\n        && strcmp(\"dp_hash\", prop->selection_method)) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false,\n                    \"ntr selection method '%s' is not supported\",\n                    prop->selection_method);\n        return OFPERR_OFPBPC_BAD_VALUE;\n    }\n    /* 'method_len' is now non-zero. */\n\n    strcpy(gp->selection_method, prop->selection_method);\n    gp->selection_method_param = ntohll(prop->selection_method_param);\n\n    ofpbuf_pull(payload, sizeof *prop);\n\n    fields_len = ntohs(prop->length) - sizeof *prop;\n    if (fields_len && strcmp(\"hash\", gp->selection_method)) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false, \"ntr selection method %s \"\n                    \"does not support fields\", gp->selection_method);\n        return OFPERR_OFPBPC_BAD_VALUE;\n    }\n\n    error = oxm_pull_field_array(payload->data, fields_len,\n                                 &gp->fields);\n    if (error) {\n        OFPPROP_LOG(&bad_ofmsg_rl, false,\n                    \"ntr selection method fields are invalid\");\n        return error;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,7 @@\n                     \"only allowed for select groups\");\n         return OFPERR_OFPBPC_BAD_VALUE;\n     default:\n-        OVS_NOT_REACHED();\n+        return OFPERR_OFPGMFC_BAD_TYPE;\n     }\n \n     switch (group_cmd) {\n@@ -33,7 +33,7 @@\n                     \"only allowed for add and delete group modifications\");\n         return OFPERR_OFPBPC_BAD_VALUE;\n     default:\n-        OVS_NOT_REACHED();\n+        return OFPERR_OFPGMFC_BAD_COMMAND;\n     }\n \n     if (payload->size < sizeof *prop) {",
        "diff_line_info": {
            "deleted_lines": [
                "        OVS_NOT_REACHED();",
                "        OVS_NOT_REACHED();"
            ],
            "added_lines": [
                "        return OFPERR_OFPGMFC_BAD_TYPE;",
                "        return OFPERR_OFPGMFC_BAD_COMMAND;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-19963",
        "func_name": "xen-project/xen/hvm_free_ioreq_mfn",
        "description": "An issue was discovered in Xen 4.11 allowing HVM guest OS users to cause a denial of service (host OS crash) or possibly gain host OS privileges because x86 IOREQ server resource accounting (for external emulators) was mishandled.",
        "git_url": "https://github.com/xen-project/xen/commit/f6b6ae78679b363ff670a9c125077c436dabd608",
        "commit_title": "x86/hvm/ioreq: fix page referencing",
        "commit_text": " The code does not take a page reference in hvm_alloc_ioreq_mfn(), only a type reference. This can lead to a situation where a malicious domain with XSM_DM_PRIV can engineer a sequence as follows:  - create IOREQ server: no pages as yet. - acquire resource: page allocated, total 0. - decrease reservation: -1 ref, total -1.  This will cause Xen to hit a BUG_ON() in free_domheap_pages().  This patch fixes the issue by changing the call to get_page_type() in hvm_alloc_ioreq_mfn() to a call to get_page_and_type(). This change in turn requires an extra put_page() in hvm_free_ioreq_mfn() in the case that _PGC_allocated is still set (i.e. a decrease reservation has not occurred) to avoid the page being leaked.  This is part of XSA-276. ",
        "func_before": "static void hvm_free_ioreq_mfn(struct hvm_ioreq_server *s, bool buf)\n{\n    struct hvm_ioreq_page *iorp = buf ? &s->bufioreq : &s->ioreq;\n\n    if ( !iorp->page )\n        return;\n\n    unmap_domain_page_global(iorp->va);\n    iorp->va = NULL;\n\n    put_page_and_type(iorp->page);\n    iorp->page = NULL;\n}",
        "func": "static void hvm_free_ioreq_mfn(struct hvm_ioreq_server *s, bool buf)\n{\n    struct hvm_ioreq_page *iorp = buf ? &s->bufioreq : &s->ioreq;\n    struct page_info *page = iorp->page;\n\n    if ( !page )\n        return;\n\n    iorp->page = NULL;\n\n    unmap_domain_page_global(iorp->va);\n    iorp->va = NULL;\n\n    /*\n     * Check whether we need to clear the allocation reference before\n     * dropping the explicit references taken by get_page_and_type().\n     */\n    if ( test_and_clear_bit(_PGC_allocated, &page->count_info) )\n        put_page(page);\n\n    put_page_and_type(page);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,22 @@\n static void hvm_free_ioreq_mfn(struct hvm_ioreq_server *s, bool buf)\n {\n     struct hvm_ioreq_page *iorp = buf ? &s->bufioreq : &s->ioreq;\n+    struct page_info *page = iorp->page;\n \n-    if ( !iorp->page )\n+    if ( !page )\n         return;\n+\n+    iorp->page = NULL;\n \n     unmap_domain_page_global(iorp->va);\n     iorp->va = NULL;\n \n-    put_page_and_type(iorp->page);\n-    iorp->page = NULL;\n+    /*\n+     * Check whether we need to clear the allocation reference before\n+     * dropping the explicit references taken by get_page_and_type().\n+     */\n+    if ( test_and_clear_bit(_PGC_allocated, &page->count_info) )\n+        put_page(page);\n+\n+    put_page_and_type(page);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( !iorp->page )",
                "    put_page_and_type(iorp->page);",
                "    iorp->page = NULL;"
            ],
            "added_lines": [
                "    struct page_info *page = iorp->page;",
                "    if ( !page )",
                "",
                "    iorp->page = NULL;",
                "    /*",
                "     * Check whether we need to clear the allocation reference before",
                "     * dropping the explicit references taken by get_page_and_type().",
                "     */",
                "    if ( test_and_clear_bit(_PGC_allocated, &page->count_info) )",
                "        put_page(page);",
                "",
                "    put_page_and_type(page);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-19963",
        "func_name": "xen-project/xen/hvm_alloc_ioreq_mfn",
        "description": "An issue was discovered in Xen 4.11 allowing HVM guest OS users to cause a denial of service (host OS crash) or possibly gain host OS privileges because x86 IOREQ server resource accounting (for external emulators) was mishandled.",
        "git_url": "https://github.com/xen-project/xen/commit/f6b6ae78679b363ff670a9c125077c436dabd608",
        "commit_title": "x86/hvm/ioreq: fix page referencing",
        "commit_text": " The code does not take a page reference in hvm_alloc_ioreq_mfn(), only a type reference. This can lead to a situation where a malicious domain with XSM_DM_PRIV can engineer a sequence as follows:  - create IOREQ server: no pages as yet. - acquire resource: page allocated, total 0. - decrease reservation: -1 ref, total -1.  This will cause Xen to hit a BUG_ON() in free_domheap_pages().  This patch fixes the issue by changing the call to get_page_type() in hvm_alloc_ioreq_mfn() to a call to get_page_and_type(). This change in turn requires an extra put_page() in hvm_free_ioreq_mfn() in the case that _PGC_allocated is still set (i.e. a decrease reservation has not occurred) to avoid the page being leaked.  This is part of XSA-276. ",
        "func_before": "static int hvm_alloc_ioreq_mfn(struct hvm_ioreq_server *s, bool buf)\n{\n    struct hvm_ioreq_page *iorp = buf ? &s->bufioreq : &s->ioreq;\n\n    if ( iorp->page )\n    {\n        /*\n         * If a guest frame has already been mapped (which may happen\n         * on demand if hvm_get_ioreq_server_info() is called), then\n         * allocating a page is not permitted.\n         */\n        if ( !gfn_eq(iorp->gfn, INVALID_GFN) )\n            return -EPERM;\n\n        return 0;\n    }\n\n    /*\n     * Allocated IOREQ server pages are assigned to the emulating\n     * domain, not the target domain. This is safe because the emulating\n     * domain cannot be destroyed until the ioreq server is destroyed.\n     * Also we must use MEMF_no_refcount otherwise page allocation\n     * could fail if the emulating domain has already reached its\n     * maximum allocation.\n     */\n    iorp->page = alloc_domheap_page(s->emulator, MEMF_no_refcount);\n\n    if ( !iorp->page )\n        return -ENOMEM;\n\n    if ( !get_page_type(iorp->page, PGT_writable_page) )\n        goto fail1;\n\n    iorp->va = __map_domain_page_global(iorp->page);\n    if ( !iorp->va )\n        goto fail2;\n\n    clear_page(iorp->va);\n    return 0;\n\n fail2:\n    put_page_type(iorp->page);\n\n fail1:\n    put_page(iorp->page);\n    iorp->page = NULL;\n\n    return -ENOMEM;\n}",
        "func": "static int hvm_alloc_ioreq_mfn(struct hvm_ioreq_server *s, bool buf)\n{\n    struct hvm_ioreq_page *iorp = buf ? &s->bufioreq : &s->ioreq;\n    struct page_info *page;\n\n    if ( iorp->page )\n    {\n        /*\n         * If a guest frame has already been mapped (which may happen\n         * on demand if hvm_get_ioreq_server_info() is called), then\n         * allocating a page is not permitted.\n         */\n        if ( !gfn_eq(iorp->gfn, INVALID_GFN) )\n            return -EPERM;\n\n        return 0;\n    }\n\n    /*\n     * Allocated IOREQ server pages are assigned to the emulating\n     * domain, not the target domain. This is safe because the emulating\n     * domain cannot be destroyed until the ioreq server is destroyed.\n     * Also we must use MEMF_no_refcount otherwise page allocation\n     * could fail if the emulating domain has already reached its\n     * maximum allocation.\n     */\n    page = alloc_domheap_page(s->emulator, MEMF_no_refcount);\n\n    if ( !page )\n        return -ENOMEM;\n\n    if ( !get_page_and_type(page, s->emulator, PGT_writable_page) )\n    {\n        /*\n         * The domain can't possibly know about this page yet, so failure\n         * here is a clear indication of something fishy going on.\n         */\n        domain_crash(s->emulator);\n        return -ENODATA;\n    }\n\n    iorp->va = __map_domain_page_global(page);\n    if ( !iorp->va )\n        goto fail;\n\n    iorp->page = page;\n    clear_page(iorp->va);\n    return 0;\n\n fail:\n    if ( test_and_clear_bit(_PGC_allocated, &page->count_info) )\n        put_page(page);\n    put_page_and_type(page);\n\n    return -ENOMEM;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n static int hvm_alloc_ioreq_mfn(struct hvm_ioreq_server *s, bool buf)\n {\n     struct hvm_ioreq_page *iorp = buf ? &s->bufioreq : &s->ioreq;\n+    struct page_info *page;\n \n     if ( iorp->page )\n     {\n@@ -23,27 +24,33 @@\n      * could fail if the emulating domain has already reached its\n      * maximum allocation.\n      */\n-    iorp->page = alloc_domheap_page(s->emulator, MEMF_no_refcount);\n+    page = alloc_domheap_page(s->emulator, MEMF_no_refcount);\n \n-    if ( !iorp->page )\n+    if ( !page )\n         return -ENOMEM;\n \n-    if ( !get_page_type(iorp->page, PGT_writable_page) )\n-        goto fail1;\n+    if ( !get_page_and_type(page, s->emulator, PGT_writable_page) )\n+    {\n+        /*\n+         * The domain can't possibly know about this page yet, so failure\n+         * here is a clear indication of something fishy going on.\n+         */\n+        domain_crash(s->emulator);\n+        return -ENODATA;\n+    }\n \n-    iorp->va = __map_domain_page_global(iorp->page);\n+    iorp->va = __map_domain_page_global(page);\n     if ( !iorp->va )\n-        goto fail2;\n+        goto fail;\n \n+    iorp->page = page;\n     clear_page(iorp->va);\n     return 0;\n \n- fail2:\n-    put_page_type(iorp->page);\n-\n- fail1:\n-    put_page(iorp->page);\n-    iorp->page = NULL;\n+ fail:\n+    if ( test_and_clear_bit(_PGC_allocated, &page->count_info) )\n+        put_page(page);\n+    put_page_and_type(page);\n \n     return -ENOMEM;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    iorp->page = alloc_domheap_page(s->emulator, MEMF_no_refcount);",
                "    if ( !iorp->page )",
                "    if ( !get_page_type(iorp->page, PGT_writable_page) )",
                "        goto fail1;",
                "    iorp->va = __map_domain_page_global(iorp->page);",
                "        goto fail2;",
                " fail2:",
                "    put_page_type(iorp->page);",
                "",
                " fail1:",
                "    put_page(iorp->page);",
                "    iorp->page = NULL;"
            ],
            "added_lines": [
                "    struct page_info *page;",
                "    page = alloc_domheap_page(s->emulator, MEMF_no_refcount);",
                "    if ( !page )",
                "    if ( !get_page_and_type(page, s->emulator, PGT_writable_page) )",
                "    {",
                "        /*",
                "         * The domain can't possibly know about this page yet, so failure",
                "         * here is a clear indication of something fishy going on.",
                "         */",
                "        domain_crash(s->emulator);",
                "        return -ENODATA;",
                "    }",
                "    iorp->va = __map_domain_page_global(page);",
                "        goto fail;",
                "    iorp->page = page;",
                " fail:",
                "    if ( test_and_clear_bit(_PGC_allocated, &page->count_info) )",
                "        put_page(page);",
                "    put_page_and_type(page);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-5986",
        "func_name": "torvalds/linux/sctp_wait_for_sndbuf",
        "description": "Race condition in the sctp_wait_for_sndbuf function in net/sctp/socket.c in the Linux kernel before 4.9.11 allows local users to cause a denial of service (assertion failure and panic) via a multithreaded application that peels off an association in a certain buffer-full state.",
        "git_url": "https://github.com/torvalds/linux/commit/2dcab598484185dea7ec22219c76dcdd59e3cb90",
        "commit_title": "sctp: avoid BUG_ON on sctp_wait_for_sndbuf",
        "commit_text": " Alexander Popov reported that an application may trigger a BUG_ON in sctp_wait_for_sndbuf if the socket tx buffer is full, a thread is waiting on it to queue more data and meanwhile another thread peels off the association being used by the first thread.  This patch replaces the BUG_ON call with a proper error handling. It will return -EPIPE to the original sendmsg call, similarly to what would have been done if the association wasn't found in the first place. ",
        "func_before": "static int sctp_wait_for_sndbuf(struct sctp_association *asoc, long *timeo_p,\n\t\t\t\tsize_t msg_len)\n{\n\tstruct sock *sk = asoc->base.sk;\n\tint err = 0;\n\tlong current_timeo = *timeo_p;\n\tDEFINE_WAIT(wait);\n\n\tpr_debug(\"%s: asoc:%p, timeo:%ld, msg_len:%zu\\n\", __func__, asoc,\n\t\t *timeo_p, msg_len);\n\n\t/* Increment the association's refcnt.  */\n\tsctp_association_hold(asoc);\n\n\t/* Wait on the association specific sndbuf space. */\n\tfor (;;) {\n\t\tprepare_to_wait_exclusive(&asoc->wait, &wait,\n\t\t\t\t\t  TASK_INTERRUPTIBLE);\n\t\tif (!*timeo_p)\n\t\t\tgoto do_nonblock;\n\t\tif (sk->sk_err || asoc->state >= SCTP_STATE_SHUTDOWN_PENDING ||\n\t\t    asoc->base.dead)\n\t\t\tgoto do_error;\n\t\tif (signal_pending(current))\n\t\t\tgoto do_interrupted;\n\t\tif (msg_len <= sctp_wspace(asoc))\n\t\t\tbreak;\n\n\t\t/* Let another process have a go.  Since we are going\n\t\t * to sleep anyway.\n\t\t */\n\t\trelease_sock(sk);\n\t\tcurrent_timeo = schedule_timeout(current_timeo);\n\t\tBUG_ON(sk != asoc->base.sk);\n\t\tlock_sock(sk);\n\n\t\t*timeo_p = current_timeo;\n\t}\n\nout:\n\tfinish_wait(&asoc->wait, &wait);\n\n\t/* Release the association's refcnt.  */\n\tsctp_association_put(asoc);\n\n\treturn err;\n\ndo_error:\n\terr = -EPIPE;\n\tgoto out;\n\ndo_interrupted:\n\terr = sock_intr_errno(*timeo_p);\n\tgoto out;\n\ndo_nonblock:\n\terr = -EAGAIN;\n\tgoto out;\n}",
        "func": "static int sctp_wait_for_sndbuf(struct sctp_association *asoc, long *timeo_p,\n\t\t\t\tsize_t msg_len)\n{\n\tstruct sock *sk = asoc->base.sk;\n\tint err = 0;\n\tlong current_timeo = *timeo_p;\n\tDEFINE_WAIT(wait);\n\n\tpr_debug(\"%s: asoc:%p, timeo:%ld, msg_len:%zu\\n\", __func__, asoc,\n\t\t *timeo_p, msg_len);\n\n\t/* Increment the association's refcnt.  */\n\tsctp_association_hold(asoc);\n\n\t/* Wait on the association specific sndbuf space. */\n\tfor (;;) {\n\t\tprepare_to_wait_exclusive(&asoc->wait, &wait,\n\t\t\t\t\t  TASK_INTERRUPTIBLE);\n\t\tif (!*timeo_p)\n\t\t\tgoto do_nonblock;\n\t\tif (sk->sk_err || asoc->state >= SCTP_STATE_SHUTDOWN_PENDING ||\n\t\t    asoc->base.dead)\n\t\t\tgoto do_error;\n\t\tif (signal_pending(current))\n\t\t\tgoto do_interrupted;\n\t\tif (msg_len <= sctp_wspace(asoc))\n\t\t\tbreak;\n\n\t\t/* Let another process have a go.  Since we are going\n\t\t * to sleep anyway.\n\t\t */\n\t\trelease_sock(sk);\n\t\tcurrent_timeo = schedule_timeout(current_timeo);\n\t\tif (sk != asoc->base.sk)\n\t\t\tgoto do_error;\n\t\tlock_sock(sk);\n\n\t\t*timeo_p = current_timeo;\n\t}\n\nout:\n\tfinish_wait(&asoc->wait, &wait);\n\n\t/* Release the association's refcnt.  */\n\tsctp_association_put(asoc);\n\n\treturn err;\n\ndo_error:\n\terr = -EPIPE;\n\tgoto out;\n\ndo_interrupted:\n\terr = sock_intr_errno(*timeo_p);\n\tgoto out;\n\ndo_nonblock:\n\terr = -EAGAIN;\n\tgoto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,7 +31,8 @@\n \t\t */\n \t\trelease_sock(sk);\n \t\tcurrent_timeo = schedule_timeout(current_timeo);\n-\t\tBUG_ON(sk != asoc->base.sk);\n+\t\tif (sk != asoc->base.sk)\n+\t\t\tgoto do_error;\n \t\tlock_sock(sk);\n \n \t\t*timeo_p = current_timeo;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tBUG_ON(sk != asoc->base.sk);"
            ],
            "added_lines": [
                "\t\tif (sk != asoc->base.sk)",
                "\t\t\tgoto do_error;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29552",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by controlling the values of `num_segments` tensor argument for `UnsortedSegmentJoin`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/a2a607db15c7cd01d754d37e5448d72a13491bdb/tensorflow/core/kernels/unsorted_segment_join_op.cc#L92-L93) assumes that the `num_segments` tensor is a valid scalar. Since the tensor is empty the `CHECK` involved in `.scalar<T>()()` that checks that the number of elements is exactly 1 will be invalidated and this would result in process termination. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/704866eabe03a9aeda044ec91a8d0c83fc1ebdbe",
        "commit_title": "Fix overflow CHECK issue with `tf.raw_ops.UnsortedSegmentJoin`.",
        "commit_text": " PiperOrigin-RevId: 370766155",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const int32 input_dims = input_shape.dims();\n\n    const Tensor& segment_id = context->input(1);\n    const TensorShape& segment_id_shape = segment_id.shape();\n    const int32 segment_dims = segment_id_shape.dims();\n\n    const Tensor& num_segments_tensor = context->input(2);\n    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\n    OP_REQUIRES(context, segment_dims != 0,\n                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n\n    OP_REQUIRES(\n        context, segment_dims <= input_dims,\n        errors::OutOfRange(\"Invalid segment_id rank \", segment_dims,\n                           \" for input with \", input_dims, \" dimension(s)\"));\n    for (auto i = 0; i < segment_dims; i++) {\n      OP_REQUIRES(\n          context, segment_id_shape.dim_size(i) == input_shape.dim_size(i),\n          errors::InvalidArgument(\n              \"Segment dimension is \", segment_id_shape.dim_size(i),\n              \" while input dimension is \", input_dims, \" in rank \", i));\n    }\n\n    // Making output tensor.\n    Tensor* output_tensor = nullptr;\n    TensorShape output_shape =\n        GetOutputShape(input_shape, segment_id_shape, num_segments);\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n\n    // Preparating flat tensors.\n    auto output_flat = output_tensor->flat<tstring>();\n    auto flat_segment_id = segment_id.flat<INDICES_TYPE>();\n    auto flat_input = input.flat<tstring>();\n\n    for (int i = 0; i < flat_segment_id.size(); i++) {\n      OP_REQUIRES(\n          context,\n          ((flat_segment_id(i) < num_segments) && (flat_segment_id(i) >= 0)),\n          errors::InvalidArgument(\n              \"segment_ids are not allowed to exceed num_segments or\"\n              \" to have negative values.\"));\n    }\n\n    int64 big_stride;\n    int64 small_stride;\n    std::tie(big_stride, small_stride) =\n        GetStrides<INDICES_TYPE>(input_shape, segment_id_shape);\n    auto relative_offset_set =\n        GetFlattenedRelativeOffsets<INDICES_TYPE>(small_stride, big_stride);\n    for (auto start_offset = 0; start_offset < big_stride; start_offset++) {\n      for (auto i = 0; i < relative_offset_set.size(); i++) {\n        auto output_index = start_offset + flat_segment_id(i) * big_stride;\n        auto offset = start_offset + relative_offset_set[i];\n        if (output_flat(output_index).length() != 0)\n          output_flat(output_index).append(separator_.c_str());\n        output_flat(output_index).append(flat_input(offset));\n      }\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const int32 input_dims = input_shape.dims();\n\n    const Tensor& segment_id = context->input(1);\n    const TensorShape& segment_id_shape = segment_id.shape();\n    const int32 segment_dims = segment_id_shape.dims();\n\n    const Tensor& num_segments_tensor = context->input(2);\n    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n    auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n\n    OP_REQUIRES(context, segment_dims != 0,\n                errors::InvalidArgument(\"Segment_id cannot have rank 0\"));\n\n    OP_REQUIRES(\n        context, segment_dims <= input_dims,\n        errors::OutOfRange(\"Invalid segment_id rank \", segment_dims,\n                           \" for input with \", input_dims, \" dimension(s)\"));\n    for (auto i = 0; i < segment_dims; i++) {\n      OP_REQUIRES(\n          context, segment_id_shape.dim_size(i) == input_shape.dim_size(i),\n          errors::InvalidArgument(\n              \"Segment dimension is \", segment_id_shape.dim_size(i),\n              \" while input dimension is \", input_dims, \" in rank \", i));\n    }\n\n    // Making output tensor.\n    Tensor* output_tensor = nullptr;\n    TensorShape output_shape =\n        GetOutputShape(input_shape, segment_id_shape, num_segments);\n    OP_REQUIRES_OK(context, context->allocate_output(\"output\", output_shape,\n                                                     &output_tensor));\n\n    // Preparating flat tensors.\n    auto output_flat = output_tensor->flat<tstring>();\n    auto flat_segment_id = segment_id.flat<INDICES_TYPE>();\n    auto flat_input = input.flat<tstring>();\n\n    for (int i = 0; i < flat_segment_id.size(); i++) {\n      OP_REQUIRES(\n          context,\n          ((flat_segment_id(i) < num_segments) && (flat_segment_id(i) >= 0)),\n          errors::InvalidArgument(\n              \"segment_ids are not allowed to exceed num_segments or\"\n              \" to have negative values.\"));\n    }\n\n    int64 big_stride;\n    int64 small_stride;\n    std::tie(big_stride, small_stride) =\n        GetStrides<INDICES_TYPE>(input_shape, segment_id_shape);\n    auto relative_offset_set =\n        GetFlattenedRelativeOffsets<INDICES_TYPE>(small_stride, big_stride);\n    for (auto start_offset = 0; start_offset < big_stride; start_offset++) {\n      for (auto i = 0; i < relative_offset_set.size(); i++) {\n        auto output_index = start_offset + flat_segment_id(i) * big_stride;\n        auto offset = start_offset + relative_offset_set[i];\n        if (output_flat(output_index).length() != 0)\n          output_flat(output_index).append(separator_.c_str());\n        output_flat(output_index).append(flat_input(offset));\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,8 @@\n     const int32 segment_dims = segment_id_shape.dims();\n \n     const Tensor& num_segments_tensor = context->input(2);\n+    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,\n+                errors::InvalidArgument(\"Number of segments cannot be empty.\"));\n     auto num_segments = num_segments_tensor.scalar<NUM_SEGMENTS_TYPE>()();\n \n     OP_REQUIRES(context, segment_dims != 0,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(context, num_segments_tensor.NumElements() != 0,",
                "                errors::InvalidArgument(\"Number of segments cannot be empty.\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29561",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by exploiting a `CHECK`-failure coming from `tf.raw_ops.LoadAndRemapMatrix`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/d94227d43aa125ad8b54115c03cece54f6a1977b/tensorflow/core/kernels/ragged_tensor_to_tensor_op.cc#L219-L222) assumes that the `ckpt_path` is always a valid scalar. However, an attacker can send any other tensor as the first argument of `LoadAndRemapMatrix`. This would cause the rank `CHECK` in `scalar<T>()()` to trigger and terminate the process. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/77dd114513d7796e1e2b8aece214a380af26fbf4",
        "commit_title": "Fix a check fail",
        "commit_text": " PiperOrigin-RevId: 372011072",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Checks what we're remapping and inverts the relevant remapping Tensors to\n    // be maps with key = old ID, value = new ID.\n    std::unordered_map<int64, int64> old_row_to_new_row_map;\n    std::vector<bool> row_id_present;\n    const Tensor* row_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n    const auto row_remapping = row_remapping_t->vec<int64>();\n    OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Size of row_remapping is \", row_remapping.size(),\n                    \" instead of being equal to num_rows=\", num_rows_)));\n    OP_REQUIRES_OK(context, RemapVectorToMap(row_remapping, &row_id_present,\n                                             &old_row_to_new_row_map));\n\n    // Calculates the min/max old row ID that we need to read, to save us from\n    // reading some unnecessary slices of the old tensor.\n    int64 min_old_row = -1;\n    int64 max_old_row = -1;\n    for (int i = 0; i < row_remapping.size(); ++i) {\n      if (min_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) < min_old_row)) {\n        min_old_row = row_remapping(i);\n      }\n      if (max_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) > max_old_row)) {\n        max_old_row = row_remapping(i);\n      }\n    }\n\n    // Processes the remapping for columns.\n    std::unordered_map<int64, int64> old_col_to_new_col_map;\n    std::vector<bool> col_id_present;\n    const Tensor* col_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"col_remapping\", &col_remapping_t));\n    const auto col_remapping = col_remapping_t->vec<int64>();\n    // Note that we always \"remap rows\", even when the row vocabulary does\n    // not change, because partitioning requires a mapping from partitioned\n    // Variables to the full checkpoints we load.\n    const bool remap_cols = col_remapping.size() > 0;\n    if (remap_cols) {\n      OP_REQUIRES(\n          context, col_remapping.size() == num_cols_,\n          errors::InvalidArgument(strings::StrCat(\n              \"Provided col_remapping, but its size is \", col_remapping.size(),\n              \" instead of being equal to num_cols=\", num_cols_)));\n      OP_REQUIRES_OK(context, RemapVectorToMap(col_remapping, &col_id_present,\n                                               &old_col_to_new_col_map));\n    } else {\n      col_id_present.clear();\n      col_id_present.resize(num_cols_, true);\n    }\n\n    // Processes the checkpoint source and the provided Tensor name.\n    const Tensor* ckpt_path_t;\n    OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));\n    const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n    const Tensor* old_tensor_name_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"old_tensor_name\", &old_tensor_name_t));\n    const string& old_tensor_name = old_tensor_name_t->scalar<tstring>()();\n\n    LOG(INFO) << \"Processing checkpoint : \" << ckpt_path;\n    BundleReader reader(context->env(), ckpt_path);\n    OP_REQUIRES_OK(context, reader.status());\n\n    DataType tensor_type;\n    TensorShape tensor_shape;\n    OP_REQUIRES_OK(context, reader.LookupDtypeAndShape(\n                                old_tensor_name, &tensor_type, &tensor_shape));\n    OP_REQUIRES(context, tensor_type == DT_FLOAT,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Tensor \", old_tensor_name, \" has invalid type \",\n                    DataTypeString(tensor_type), \" instead of expected type \",\n                    DataTypeString(DT_FLOAT))));\n    // This op is limited to loading Tensors of rank 2 (matrices).\n    OP_REQUIRES(\n        context, tensor_shape.dims() == 2,\n        errors::InvalidArgument(strings::StrCat(\n            \"Tensor \", old_tensor_name, \" has shape \",\n            tensor_shape.DebugString(), \" of invalid rank \",\n            tensor_shape.dims(), \" instead of expected shape of rank 2.\")));\n\n    if (!remap_cols) {\n      // TODO(weiho): Consider relaxing this restriction to allow partial column\n      // loading (even when no column remapping is specified) if there turns out\n      // to be a use case for it.\n      OP_REQUIRES(context, num_cols_ == tensor_shape.dim_size(1),\n                  errors::InvalidArgument(strings::StrCat(\n                      \"Tensor \", old_tensor_name, \" has shape \",\n                      tensor_shape.DebugString(),\n                      \", where the size of its 2nd dimension is \",\n                      tensor_shape.dim_size(1),\n                      \" instead of being equal to num_cols=\", num_cols_)));\n    }\n\n    // Uses TensorSlice to potentially load the old tensor in chunks in case\n    // memory usage is a concern.\n    std::vector<TensorSlice> tensor_slices;\n    TensorSlice slice(tensor_shape.dims());\n    if (min_old_row >= 0 && max_old_row >= 0) {\n      int64 row_start = min_old_row;\n      // TODO(weiho): Given the list of old row IDs of interest (the keys of\n      // old_row_to_new_row_map), we could also try something smarter to\n      // find some minimal set of covering ranges for the list of old row IDs\n      // such that the size of each range is less than max_rows_in_memory_.\n      while (row_start <= max_old_row) {\n        const int64 slice_length =\n            max_rows_in_memory_ <= 0\n                // If max_rows_in_memory_ <= 0, we just load the entire chunk.\n                ? max_old_row - row_start + 1\n                : std::min(max_rows_in_memory_, max_old_row - row_start + 1);\n        slice.set_start(0, row_start);\n        slice.set_length(0, slice_length);\n        tensor_slices.push_back(slice);\n        row_start += slice_length;\n      }\n    }\n\n    // Allocates the output matrix.\n    Tensor* output_matrix_t = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"output_matrix\",\n                                            TensorShape({num_rows_, num_cols_}),\n                                            &output_matrix_t));\n    auto output_matrix = output_matrix_t->matrix<float>();\n\n    // Iterates through tensor slices and copies over values from the old tensor\n    // to the output matrix.\n    int64 row_index = min_old_row;\n    int64 rows_copied = 0;\n    Tensor loaded_tensor_t;\n    for (const TensorSlice& tensor_slice : tensor_slices) {\n      LOG(INFO) << \"Loading slice \" << tensor_slice.DebugString();\n      TensorShape slice_shape;\n      OP_REQUIRES_OK(context,\n                     tensor_slice.SliceTensorShape(tensor_shape, &slice_shape));\n      // Potentially re-allocates the tensor buffer since the last slice may\n      // have fewer rows than the other slices.\n      if (loaded_tensor_t.shape() != slice_shape) {\n        loaded_tensor_t = Tensor(DT_FLOAT, slice_shape);\n      }\n      OP_REQUIRES_OK(context, reader.LookupSlice(old_tensor_name, tensor_slice,\n                                                 &loaded_tensor_t));\n\n      // Iterates through the old loaded tensor slice row-by-row.\n      for (int row = 0; row < loaded_tensor_t.dim_size(0); ++row, ++row_index) {\n        if (row_index % 500000 == min_old_row) {\n          LOG(INFO) << \"Processing old row \" << row_index;\n        }\n\n        // If the old row ID is not found in old_row_to_new_row_map, continue\n        // to the next row; otherwise, copy it to the output matrix.\n        const int64* new_row_ptr =\n            gtl::FindOrNull(old_row_to_new_row_map, row_index);\n        if (new_row_ptr == nullptr) {\n          continue;\n        }\n        ++rows_copied;\n        const int64 new_row = *new_row_ptr;\n\n        // Copies over the row element-by-element, in case remapping is needed\n        // along the column axis.\n        const auto& loaded_tensor = loaded_tensor_t.matrix<float>();\n        for (int old_col = 0; old_col < loaded_tensor_t.dim_size(1);\n             ++old_col) {\n          int64 new_col = old_col;\n          if (remap_cols) {\n            const int64* new_col_ptr =\n                gtl::FindOrNull(old_col_to_new_col_map, old_col);\n            if (new_col_ptr == nullptr) {\n              // Column remapping is specified, but this column is not found in\n              // old_col_to_new_col_map, so we leave it uninitialized, to be\n              // filled in with initializing_values later.\n              continue;\n            }\n            new_col = *new_col_ptr;\n          }\n\n          OP_REQUIRES(context,\n                      new_row < num_rows_ && new_col < num_cols_ &&\n                          new_row >= 0 && new_col >= 0,\n                      errors::Internal(strings::StrCat(\n                          \"new_row=\", new_row, \" and new_col=\", new_col,\n                          \" should have been less than num_rows_=\", num_rows_,\n                          \" and num_cols_=\", num_cols_,\n                          \" and non-negative. This should never have happened \"\n                          \"if the code were correct. Please file a bug.\")));\n          output_matrix(new_row, new_col) = loaded_tensor(row, old_col);\n        }\n      }\n    }\n    LOG(INFO) << \"Copied \" << rows_copied << \" rows from old matrix (with \"\n              << tensor_shape.dim_size(0) << \" rows) to new matrix (with \"\n              << num_rows_ << \" rows).\";\n\n    // At this point, there are potentially whole rows/columns uninitialized\n    // (corresponding to the indices where row_id_present/col_id_present are\n    // false). We fill this in cell-by-cell using row_id_present and\n    // col_id_present while dequeuing from the initializing_values vector.\n    const Tensor* initializing_values_t;\n    OP_REQUIRES_OK(\n        context, context->input(\"initializing_values\", &initializing_values_t));\n    const auto initializing_values = initializing_values_t->flat<float>();\n    int64 initializing_values_index = 0;\n    for (int i = 0; i < num_rows_; ++i) {\n      for (int j = 0; j < num_cols_; ++j) {\n        if (row_id_present[i] && col_id_present[j]) continue;\n        OP_REQUIRES(\n            context, initializing_values_index < initializing_values.size(),\n            errors::InvalidArgument(\n                \"initializing_values contained \", initializing_values.size(),\n                \" elements, but more missing values remain.\"));\n        output_matrix(i, j) = initializing_values(initializing_values_index);\n        ++initializing_values_index;\n      }\n    }\n\n    // Checks that we used all the given initializing values.\n    OP_REQUIRES(\n        context, initializing_values_index == initializing_values.size(),\n        errors::InvalidArgument(\n            \"initializing_values contained \", initializing_values.size(),\n            \" elements, but only \", initializing_values_index,\n            \" elements were used to fill in missing values.\"));\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Checks what we're remapping and inverts the relevant remapping Tensors to\n    // be maps with key = old ID, value = new ID.\n    std::unordered_map<int64, int64> old_row_to_new_row_map;\n    std::vector<bool> row_id_present;\n    const Tensor* row_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"row_remapping\", &row_remapping_t));\n    const auto row_remapping = row_remapping_t->vec<int64>();\n    OP_REQUIRES(context, row_remapping.size() == num_rows_,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Size of row_remapping is \", row_remapping.size(),\n                    \" instead of being equal to num_rows=\", num_rows_)));\n    OP_REQUIRES_OK(context, RemapVectorToMap(row_remapping, &row_id_present,\n                                             &old_row_to_new_row_map));\n\n    // Calculates the min/max old row ID that we need to read, to save us from\n    // reading some unnecessary slices of the old tensor.\n    int64 min_old_row = -1;\n    int64 max_old_row = -1;\n    for (int i = 0; i < row_remapping.size(); ++i) {\n      if (min_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) < min_old_row)) {\n        min_old_row = row_remapping(i);\n      }\n      if (max_old_row < 0 ||\n          (row_remapping(i) >= 0 && row_remapping(i) > max_old_row)) {\n        max_old_row = row_remapping(i);\n      }\n    }\n\n    // Processes the remapping for columns.\n    std::unordered_map<int64, int64> old_col_to_new_col_map;\n    std::vector<bool> col_id_present;\n    const Tensor* col_remapping_t;\n    OP_REQUIRES_OK(context, context->input(\"col_remapping\", &col_remapping_t));\n    const auto col_remapping = col_remapping_t->vec<int64>();\n    // Note that we always \"remap rows\", even when the row vocabulary does\n    // not change, because partitioning requires a mapping from partitioned\n    // Variables to the full checkpoints we load.\n    const bool remap_cols = col_remapping.size() > 0;\n    if (remap_cols) {\n      OP_REQUIRES(\n          context, col_remapping.size() == num_cols_,\n          errors::InvalidArgument(strings::StrCat(\n              \"Provided col_remapping, but its size is \", col_remapping.size(),\n              \" instead of being equal to num_cols=\", num_cols_)));\n      OP_REQUIRES_OK(context, RemapVectorToMap(col_remapping, &col_id_present,\n                                               &old_col_to_new_col_map));\n    } else {\n      col_id_present.clear();\n      col_id_present.resize(num_cols_, true);\n    }\n\n    // Processes the checkpoint source and the provided Tensor name.\n    const Tensor* ckpt_path_t;\n    OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));\n    OP_REQUIRES(\n        context, ckpt_path_t->NumElements() == 1,\n        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"\n                                \"element, got tensor of shape \",\n                                ckpt_path_t->shape().DebugString()));\n    const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n    const Tensor* old_tensor_name_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"old_tensor_name\", &old_tensor_name_t));\n    const string& old_tensor_name = old_tensor_name_t->scalar<tstring>()();\n\n    LOG(INFO) << \"Processing checkpoint : \" << ckpt_path;\n    BundleReader reader(context->env(), ckpt_path);\n    OP_REQUIRES_OK(context, reader.status());\n\n    DataType tensor_type;\n    TensorShape tensor_shape;\n    OP_REQUIRES_OK(context, reader.LookupDtypeAndShape(\n                                old_tensor_name, &tensor_type, &tensor_shape));\n    OP_REQUIRES(context, tensor_type == DT_FLOAT,\n                errors::InvalidArgument(strings::StrCat(\n                    \"Tensor \", old_tensor_name, \" has invalid type \",\n                    DataTypeString(tensor_type), \" instead of expected type \",\n                    DataTypeString(DT_FLOAT))));\n    // This op is limited to loading Tensors of rank 2 (matrices).\n    OP_REQUIRES(\n        context, tensor_shape.dims() == 2,\n        errors::InvalidArgument(strings::StrCat(\n            \"Tensor \", old_tensor_name, \" has shape \",\n            tensor_shape.DebugString(), \" of invalid rank \",\n            tensor_shape.dims(), \" instead of expected shape of rank 2.\")));\n\n    if (!remap_cols) {\n      // TODO(weiho): Consider relaxing this restriction to allow partial column\n      // loading (even when no column remapping is specified) if there turns out\n      // to be a use case for it.\n      OP_REQUIRES(context, num_cols_ == tensor_shape.dim_size(1),\n                  errors::InvalidArgument(strings::StrCat(\n                      \"Tensor \", old_tensor_name, \" has shape \",\n                      tensor_shape.DebugString(),\n                      \", where the size of its 2nd dimension is \",\n                      tensor_shape.dim_size(1),\n                      \" instead of being equal to num_cols=\", num_cols_)));\n    }\n\n    // Uses TensorSlice to potentially load the old tensor in chunks in case\n    // memory usage is a concern.\n    std::vector<TensorSlice> tensor_slices;\n    TensorSlice slice(tensor_shape.dims());\n    if (min_old_row >= 0 && max_old_row >= 0) {\n      int64 row_start = min_old_row;\n      // TODO(weiho): Given the list of old row IDs of interest (the keys of\n      // old_row_to_new_row_map), we could also try something smarter to\n      // find some minimal set of covering ranges for the list of old row IDs\n      // such that the size of each range is less than max_rows_in_memory_.\n      while (row_start <= max_old_row) {\n        const int64 slice_length =\n            max_rows_in_memory_ <= 0\n                // If max_rows_in_memory_ <= 0, we just load the entire chunk.\n                ? max_old_row - row_start + 1\n                : std::min(max_rows_in_memory_, max_old_row - row_start + 1);\n        slice.set_start(0, row_start);\n        slice.set_length(0, slice_length);\n        tensor_slices.push_back(slice);\n        row_start += slice_length;\n      }\n    }\n\n    // Allocates the output matrix.\n    Tensor* output_matrix_t = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"output_matrix\",\n                                            TensorShape({num_rows_, num_cols_}),\n                                            &output_matrix_t));\n    auto output_matrix = output_matrix_t->matrix<float>();\n\n    // Iterates through tensor slices and copies over values from the old tensor\n    // to the output matrix.\n    int64 row_index = min_old_row;\n    int64 rows_copied = 0;\n    Tensor loaded_tensor_t;\n    for (const TensorSlice& tensor_slice : tensor_slices) {\n      LOG(INFO) << \"Loading slice \" << tensor_slice.DebugString();\n      TensorShape slice_shape;\n      OP_REQUIRES_OK(context,\n                     tensor_slice.SliceTensorShape(tensor_shape, &slice_shape));\n      // Potentially re-allocates the tensor buffer since the last slice may\n      // have fewer rows than the other slices.\n      if (loaded_tensor_t.shape() != slice_shape) {\n        loaded_tensor_t = Tensor(DT_FLOAT, slice_shape);\n      }\n      OP_REQUIRES_OK(context, reader.LookupSlice(old_tensor_name, tensor_slice,\n                                                 &loaded_tensor_t));\n\n      // Iterates through the old loaded tensor slice row-by-row.\n      for (int row = 0; row < loaded_tensor_t.dim_size(0); ++row, ++row_index) {\n        if (row_index % 500000 == min_old_row) {\n          LOG(INFO) << \"Processing old row \" << row_index;\n        }\n\n        // If the old row ID is not found in old_row_to_new_row_map, continue\n        // to the next row; otherwise, copy it to the output matrix.\n        const int64* new_row_ptr =\n            gtl::FindOrNull(old_row_to_new_row_map, row_index);\n        if (new_row_ptr == nullptr) {\n          continue;\n        }\n        ++rows_copied;\n        const int64 new_row = *new_row_ptr;\n\n        // Copies over the row element-by-element, in case remapping is needed\n        // along the column axis.\n        const auto& loaded_tensor = loaded_tensor_t.matrix<float>();\n        for (int old_col = 0; old_col < loaded_tensor_t.dim_size(1);\n             ++old_col) {\n          int64 new_col = old_col;\n          if (remap_cols) {\n            const int64* new_col_ptr =\n                gtl::FindOrNull(old_col_to_new_col_map, old_col);\n            if (new_col_ptr == nullptr) {\n              // Column remapping is specified, but this column is not found in\n              // old_col_to_new_col_map, so we leave it uninitialized, to be\n              // filled in with initializing_values later.\n              continue;\n            }\n            new_col = *new_col_ptr;\n          }\n\n          OP_REQUIRES(context,\n                      new_row < num_rows_ && new_col < num_cols_ &&\n                          new_row >= 0 && new_col >= 0,\n                      errors::Internal(strings::StrCat(\n                          \"new_row=\", new_row, \" and new_col=\", new_col,\n                          \" should have been less than num_rows_=\", num_rows_,\n                          \" and num_cols_=\", num_cols_,\n                          \" and non-negative. This should never have happened \"\n                          \"if the code were correct. Please file a bug.\")));\n          output_matrix(new_row, new_col) = loaded_tensor(row, old_col);\n        }\n      }\n    }\n    LOG(INFO) << \"Copied \" << rows_copied << \" rows from old matrix (with \"\n              << tensor_shape.dim_size(0) << \" rows) to new matrix (with \"\n              << num_rows_ << \" rows).\";\n\n    // At this point, there are potentially whole rows/columns uninitialized\n    // (corresponding to the indices where row_id_present/col_id_present are\n    // false). We fill this in cell-by-cell using row_id_present and\n    // col_id_present while dequeuing from the initializing_values vector.\n    const Tensor* initializing_values_t;\n    OP_REQUIRES_OK(\n        context, context->input(\"initializing_values\", &initializing_values_t));\n    const auto initializing_values = initializing_values_t->flat<float>();\n    int64 initializing_values_index = 0;\n    for (int i = 0; i < num_rows_; ++i) {\n      for (int j = 0; j < num_cols_; ++j) {\n        if (row_id_present[i] && col_id_present[j]) continue;\n        OP_REQUIRES(\n            context, initializing_values_index < initializing_values.size(),\n            errors::InvalidArgument(\n                \"initializing_values contained \", initializing_values.size(),\n                \" elements, but more missing values remain.\"));\n        output_matrix(i, j) = initializing_values(initializing_values_index);\n        ++initializing_values_index;\n      }\n    }\n\n    // Checks that we used all the given initializing values.\n    OP_REQUIRES(\n        context, initializing_values_index == initializing_values.size(),\n        errors::InvalidArgument(\n            \"initializing_values contained \", initializing_values.size(),\n            \" elements, but only \", initializing_values_index,\n            \" elements were used to fill in missing values.\"));\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,6 +54,11 @@\n     // Processes the checkpoint source and the provided Tensor name.\n     const Tensor* ckpt_path_t;\n     OP_REQUIRES_OK(context, context->input(\"ckpt_path\", &ckpt_path_t));\n+    OP_REQUIRES(\n+        context, ckpt_path_t->NumElements() == 1,\n+        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"\n+                                \"element, got tensor of shape \",\n+                                ckpt_path_t->shape().DebugString()));\n     const string& ckpt_path = ckpt_path_t->scalar<tstring>()();\n     const Tensor* old_tensor_name_t;\n     OP_REQUIRES_OK(context,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, ckpt_path_t->NumElements() == 1,",
                "        errors::InvalidArgument(\"The `ckpt_path` tensor must have exactly one \"",
                "                                \"element, got tensor of shape \",",
                "                                ckpt_path_t->shape().DebugString()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29562",
        "func_name": "tensorflow/DoRealBackwardFFT",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by exploiting a `CHECK`-failure coming from the implementation of `tf.raw_ops.IRFFT`. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1c56f53be0b722ca657cbc7df461ed676c8642a2",
        "commit_title": "Fix a check fail in Fast Fourier implementation",
        "commit_text": " PiperOrigin-RevId: 372026629",
        "func_before": "void DoRealBackwardFFT(OpKernelContext* ctx, uint64* fft_shape,\n                         const Tensor& in, Tensor* out) {\n    auto device = ctx->eigen_device<CPUDevice>();\n    // Reconstruct the full FFT and take the inverse.\n    auto input = Tensor(in).flat_inner_dims<ComplexT, FFTRank + 1>();\n    auto output = out->flat_inner_dims<RealT, FFTRank + 1>();\n    const auto input_dims = input.dimensions();\n\n    // Calculate the shape of the temporary tensor for the full FFT and the\n    // region we will slice from input given fft_shape. We slice input to\n    // fft_shape on its inner-most dimensions, except the last (which we\n    // slice to fft_shape[-1] / 2 + 1).\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> input_slice_sizes;\n    input_slice_sizes[0] = input_dims[0];\n    TensorShape full_fft_shape;\n    full_fft_shape.AddDim(input_dims[0]);\n    for (auto i = 1; i <= FFTRank; i++) {\n      input_slice_sizes[i] =\n          i == FFTRank ? fft_shape[i - 1] / 2 + 1 : fft_shape[i - 1];\n      full_fft_shape.AddDim(fft_shape[i - 1]);\n    }\n\n    Tensor temp;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n                                           full_fft_shape, &temp));\n    auto full_fft = temp.flat_inner_dims<ComplexT, FFTRank + 1>();\n\n    // Calculate the starting point and range of the source of\n    // negative frequency part.\n    auto neg_sizes = input_slice_sizes;\n    neg_sizes[FFTRank] = fft_shape[FFTRank - 1] - input_slice_sizes[FFTRank];\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> neg_target_indices;\n    neg_target_indices[FFTRank] = input_slice_sizes[FFTRank];\n\n    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> start_indices;\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> neg_start_indices;\n    neg_start_indices[FFTRank] = 1;\n\n    full_fft.slice(start_indices, input_slice_sizes).device(device) =\n        input.slice(start_indices, input_slice_sizes);\n\n    // First, conduct IFFTs on outer dimensions. We save computation (and\n    // avoid touching uninitialized memory) by slicing full_fft to the\n    // subregion we wrote input to.\n    if (FFTRank > 1) {\n      const auto outer_axes =\n          Eigen::ArrayXi::LinSpaced(FFTRank - 1, 1, FFTRank - 1);\n      full_fft.slice(start_indices, input_slice_sizes).device(device) =\n          full_fft.slice(start_indices, input_slice_sizes)\n              .template fft<Eigen::BothParts, Eigen::FFT_REVERSE>(outer_axes);\n    }\n\n    // Reconstruct the full FFT by appending reversed and conjugated\n    // spectrum as the negative frequency part.\n    Eigen::array<bool, FFTRank + 1> reverse_last_axis;\n    for (auto i = 0; i <= FFTRank; i++) {\n      reverse_last_axis[i] = i == FFTRank;\n    }\n\n    if (neg_sizes[FFTRank] != 0) {\n      full_fft.slice(neg_target_indices, neg_sizes).device(device) =\n          full_fft.slice(neg_start_indices, neg_sizes)\n              .reverse(reverse_last_axis)\n              .conjugate();\n    }\n\n    auto inner_axis = Eigen::array<int, 1>{FFTRank};\n    output.device(device) =\n        full_fft.template fft<Eigen::RealPart, Eigen::FFT_REVERSE>(inner_axis);\n  }",
        "func": "void DoRealBackwardFFT(OpKernelContext* ctx, uint64* fft_shape,\n                         const Tensor& in, Tensor* out) {\n    auto device = ctx->eigen_device<CPUDevice>();\n    // Reconstruct the full FFT and take the inverse.\n    auto input = Tensor(in).flat_inner_dims<ComplexT, FFTRank + 1>();\n    auto output = out->flat_inner_dims<RealT, FFTRank + 1>();\n    const auto input_dims = input.dimensions();\n\n    // Calculate the shape of the temporary tensor for the full FFT and the\n    // region we will slice from input given fft_shape. We slice input to\n    // fft_shape on its inner-most dimensions, except the last (which we\n    // slice to fft_shape[-1] / 2 + 1).\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> input_slice_sizes;\n    input_slice_sizes[0] = input_dims[0];\n    TensorShape full_fft_shape;\n    full_fft_shape.AddDim(input_dims[0]);\n    for (auto i = 1; i <= FFTRank; i++) {\n      input_slice_sizes[i] =\n          i == FFTRank ? fft_shape[i - 1] / 2 + 1 : fft_shape[i - 1];\n      full_fft_shape.AddDim(fft_shape[i - 1]);\n    }\n    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,\n                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n                                        full_fft_shape.DebugString()));\n\n    Tensor temp;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n                                           full_fft_shape, &temp));\n    auto full_fft = temp.flat_inner_dims<ComplexT, FFTRank + 1>();\n\n    // Calculate the starting point and range of the source of\n    // negative frequency part.\n    auto neg_sizes = input_slice_sizes;\n    neg_sizes[FFTRank] = fft_shape[FFTRank - 1] - input_slice_sizes[FFTRank];\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> neg_target_indices;\n    neg_target_indices[FFTRank] = input_slice_sizes[FFTRank];\n\n    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> start_indices;\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> neg_start_indices;\n    neg_start_indices[FFTRank] = 1;\n\n    full_fft.slice(start_indices, input_slice_sizes).device(device) =\n        input.slice(start_indices, input_slice_sizes);\n\n    // First, conduct IFFTs on outer dimensions. We save computation (and\n    // avoid touching uninitialized memory) by slicing full_fft to the\n    // subregion we wrote input to.\n    if (FFTRank > 1) {\n      const auto outer_axes =\n          Eigen::ArrayXi::LinSpaced(FFTRank - 1, 1, FFTRank - 1);\n      full_fft.slice(start_indices, input_slice_sizes).device(device) =\n          full_fft.slice(start_indices, input_slice_sizes)\n              .template fft<Eigen::BothParts, Eigen::FFT_REVERSE>(outer_axes);\n    }\n\n    // Reconstruct the full FFT by appending reversed and conjugated\n    // spectrum as the negative frequency part.\n    Eigen::array<bool, FFTRank + 1> reverse_last_axis;\n    for (auto i = 0; i <= FFTRank; i++) {\n      reverse_last_axis[i] = i == FFTRank;\n    }\n\n    if (neg_sizes[FFTRank] != 0) {\n      full_fft.slice(neg_target_indices, neg_sizes).device(device) =\n          full_fft.slice(neg_start_indices, neg_sizes)\n              .reverse(reverse_last_axis)\n              .conjugate();\n    }\n\n    auto inner_axis = Eigen::array<int, 1>{FFTRank};\n    output.device(device) =\n        full_fft.template fft<Eigen::RealPart, Eigen::FFT_REVERSE>(inner_axis);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,9 @@\n           i == FFTRank ? fft_shape[i - 1] / 2 + 1 : fft_shape[i - 1];\n       full_fft_shape.AddDim(fft_shape[i - 1]);\n     }\n+    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n+                                        full_fft_shape.DebugString()));\n \n     Tensor temp;\n     OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(ctx, full_fft_shape.num_elements() > 0,",
                "                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",",
                "                                        full_fft_shape.DebugString()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29563",
        "func_name": "tensorflow/DoRealForwardFFT",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service by exploiting a `CHECK`-failure coming from the implementation of `tf.raw_ops.RFFT`. Eigen code operating on an empty matrix can trigger on an assertion and will cause program termination. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/31bd5026304677faa8a0b77602c6154171b9aec1",
        "commit_title": "Prevent check fail in FFT",
        "commit_text": " PiperOrigin-RevId: 372031044",
        "func_before": "void DoRealForwardFFT(OpKernelContext* ctx, uint64* fft_shape,\n                        const Tensor& in, Tensor* out) {\n    // Create the axes (which are always trailing).\n    const auto axes = Eigen::ArrayXi::LinSpaced(FFTRank, 1, FFTRank);\n    auto device = ctx->eigen_device<CPUDevice>();\n    auto input = Tensor(in).flat_inner_dims<RealT, FFTRank + 1>();\n    const auto input_dims = input.dimensions();\n\n    // Slice input to fft_shape on its inner-most dimensions.\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> input_slice_sizes;\n    input_slice_sizes[0] = input_dims[0];\n    TensorShape temp_shape{input_dims[0]};\n    for (int i = 1; i <= FFTRank; ++i) {\n      input_slice_sizes[i] = fft_shape[i - 1];\n      temp_shape.AddDim(fft_shape[i - 1]);\n    }\n\n    auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;\n\n    // Compute the full FFT using a temporary tensor.\n    Tensor temp;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n                                           temp_shape, &temp));\n    auto full_fft = temp.flat_inner_dims<ComplexT, FFTRank + 1>();\n    full_fft.device(device) =\n        input.slice(zero_start_indices, input_slice_sizes)\n            .template fft<Eigen::BothParts, Eigen::FFT_FORWARD>(axes);\n\n    // Slice away the negative frequency components.\n    output.device(device) =\n        full_fft.slice(zero_start_indices, output.dimensions());\n  }",
        "func": "void DoRealForwardFFT(OpKernelContext* ctx, uint64* fft_shape,\n                        const Tensor& in, Tensor* out) {\n    // Create the axes (which are always trailing).\n    const auto axes = Eigen::ArrayXi::LinSpaced(FFTRank, 1, FFTRank);\n    auto device = ctx->eigen_device<CPUDevice>();\n    auto input = Tensor(in).flat_inner_dims<RealT, FFTRank + 1>();\n    const auto input_dims = input.dimensions();\n\n    // Slice input to fft_shape on its inner-most dimensions.\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> input_slice_sizes;\n    input_slice_sizes[0] = input_dims[0];\n    TensorShape temp_shape{input_dims[0]};\n    for (int i = 1; i <= FFTRank; ++i) {\n      input_slice_sizes[i] = fft_shape[i - 1];\n      temp_shape.AddDim(fft_shape[i - 1]);\n    }\n    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,\n                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n                                        temp_shape.DebugString()));\n\n    auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;\n\n    // Compute the full FFT using a temporary tensor.\n    Tensor temp;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n                                           temp_shape, &temp));\n    auto full_fft = temp.flat_inner_dims<ComplexT, FFTRank + 1>();\n    full_fft.device(device) =\n        input.slice(zero_start_indices, input_slice_sizes)\n            .template fft<Eigen::BothParts, Eigen::FFT_FORWARD>(axes);\n\n    // Slice away the negative frequency components.\n    output.device(device) =\n        full_fft.slice(zero_start_indices, output.dimensions());\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,6 +14,9 @@\n       input_slice_sizes[i] = fft_shape[i - 1];\n       temp_shape.AddDim(fft_shape[i - 1]);\n     }\n+    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,\n+                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n+                                        temp_shape.DebugString()));\n \n     auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n     const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,",
                "                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",",
                "                                        temp_shape.DebugString()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29567",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.SparseDenseCwiseMul`, an attacker can trigger denial of service via `CHECK`-fails or accesses to outside the bounds of heap allocated data. Since the implementation(https://github.com/tensorflow/tensorflow/blob/38178a2f7a681a7835bb0912702a134bfe3b4d84/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc#L68-L80) only validates the rank of the input arguments but no constraints between dimensions(https://www.tensorflow.org/api_docs/python/tf/raw_ops/SparseDenseCwiseMul), an attacker can abuse them to trigger internal `CHECK` assertions (and cause program termination, denial of service) or to write to memory outside of bounds of heap allocated tensor buffers. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/7ae2af34087fb4b5c8915279efd03da3b81028bc",
        "commit_title": "Fix heap-buffer-overflow issue with `tf.raw_ops.SparseDenseCwiseMul`.",
        "commit_text": " PiperOrigin-RevId: 372054410",
        "func_before": "void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n\n    const auto indices_mat = indices_t->matrix<int64>();\n    const auto shape_vec = shape_t->vec<int64>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64> lhs, ArraySlice<int64> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64 nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "func": "void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64>();\n    const auto shape_vec = shape_t->vec<int64>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64> lhs, ArraySlice<int64> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64 nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,6 +18,11 @@\n                     \"but received shapes: \",\n                     values_t->shape().DebugString(), \" and \",\n                     shape_t->shape().DebugString()));\n+    OP_REQUIRES(\n+        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n+        errors::InvalidArgument(\n+            \"The first dimension of values and indices should match. (\",\n+            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n \n     const auto indices_mat = indices_t->matrix<int64>();\n     const auto shape_vec = shape_t->vec<int64>();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        ctx, values_t->dim_size(0) == indices_t->dim_size(0),",
                "        errors::InvalidArgument(",
                "            \"The first dimension of values and indices should match. (\",",
                "            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/resolve_uses",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static int\nresolve_uses(struct lys_node_uses *uses, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = uses->module->ctx; /* shortcut */\n    struct lys_node *node = NULL, *next, *iter, **refine_nodes = NULL;\n    struct lys_node *node_aux, *parent, *tmp;\n    struct lys_node_leaflist *llist;\n    struct lys_node_leaf *leaf;\n    struct lys_refine *rfn;\n    struct lys_restr *must, **old_must;\n    struct lys_iffeature *iff, **old_iff;\n    int i, j, k, rc;\n    uint8_t size, *old_size;\n    unsigned int usize, usize1, usize2;\n\n    assert(uses->grp);\n\n    /* check that the grouping is resolved (no unresolved uses inside) */\n    assert(!uses->grp->unres_count);\n\n    /* copy the data nodes from grouping into the uses context */\n    LY_TREE_FOR(uses->grp->child, node_aux) {\n        if (node_aux->nodetype & LYS_GROUPING) {\n            /* do not instantiate groupings from groupings */\n            continue;\n        }\n        node = lys_node_dup(uses->module, (struct lys_node *)uses, node_aux, unres, 0);\n        if (!node) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, uses->grp->name, \"uses\");\n            LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"Copying data from grouping failed.\");\n            goto fail;\n        }\n        /* test the name of siblings */\n        LY_TREE_FOR((uses->parent) ? *lys_child(uses->parent, LYS_USES) : lys_main_module(uses->module)->data, tmp) {\n            if (!(tmp->nodetype & (LYS_USES | LYS_GROUPING | LYS_CASE)) && ly_strequal(tmp->name, node_aux->name, 1)) {\n                goto fail;\n            }\n        }\n    }\n\n    /* we managed to copy the grouping, the rest must be possible to resolve */\n\n    if (uses->refine_size) {\n        refine_nodes = malloc(uses->refine_size * sizeof *refine_nodes);\n        LY_CHECK_ERR_GOTO(!refine_nodes, LOGMEM(ctx), fail);\n    }\n\n    /* apply refines */\n    for (i = 0; i < uses->refine_size; i++) {\n        rfn = &uses->refine[i];\n        rc = resolve_descendant_schema_nodeid(rfn->target_name, uses->child,\n                                              LYS_NO_RPC_NOTIF_NODE | LYS_ACTION | LYS_NOTIF,\n                                              0, (const struct lys_node **)&node);\n        if (rc || !node) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, rfn->target_name, \"refine\");\n            goto fail;\n        }\n\n        if (rfn->target_type && !(node->nodetype & rfn->target_type)) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, rfn->target_name, \"refine\");\n            LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"Refine substatements not applicable to the target-node.\");\n            goto fail;\n        }\n        refine_nodes[i] = node;\n\n        /* description on any nodetype */\n        if (rfn->dsc) {\n            lydict_remove(ctx, node->dsc);\n            node->dsc = lydict_insert(ctx, rfn->dsc, 0);\n        }\n\n        /* reference on any nodetype */\n        if (rfn->ref) {\n            lydict_remove(ctx, node->ref);\n            node->ref = lydict_insert(ctx, rfn->ref, 0);\n        }\n\n        /* config on any nodetype,\n         * in case of notification or rpc/action, the config is not applicable (there is no config status) */\n        if ((rfn->flags & LYS_CONFIG_MASK) && (node->flags & LYS_CONFIG_MASK)) {\n            node->flags &= ~LYS_CONFIG_MASK;\n            node->flags |= (rfn->flags & LYS_CONFIG_MASK);\n        }\n\n        /* default value ... */\n        if (rfn->dflt_size) {\n            if (node->nodetype == LYS_LEAF) {\n                /* leaf */\n                leaf = (struct lys_node_leaf *)node;\n\n                /* replace default value */\n                lydict_remove(ctx, leaf->dflt);\n                leaf->dflt = lydict_insert(ctx, rfn->dflt[0], 0);\n\n                /* check the default value */\n                if (unres_schema_add_node(leaf->module, unres, &leaf->type, UNRES_TYPE_DFLT,\n                                          (struct lys_node *)(&leaf->dflt)) == -1) {\n                    goto fail;\n                }\n            } else if (node->nodetype == LYS_LEAFLIST) {\n                /* leaf-list */\n                llist = (struct lys_node_leaflist *)node;\n\n                /* remove complete set of defaults in target */\n                for (j = 0; j < llist->dflt_size; j++) {\n                    lydict_remove(ctx, llist->dflt[j]);\n                }\n                free(llist->dflt);\n\n                /* copy the default set from refine */\n                llist->dflt = malloc(rfn->dflt_size * sizeof *llist->dflt);\n                LY_CHECK_ERR_GOTO(!llist->dflt, LOGMEM(ctx), fail);\n                llist->dflt_size = rfn->dflt_size;\n                for (j = 0; j < llist->dflt_size; j++) {\n                    llist->dflt[j] = lydict_insert(ctx, rfn->dflt[j], 0);\n                }\n\n                /* check default value */\n                for (j = 0; j < llist->dflt_size; j++) {\n                    if (unres_schema_add_node(llist->module, unres, &llist->type, UNRES_TYPE_DFLT,\n                                              (struct lys_node *)(&llist->dflt[j])) == -1) {\n                        goto fail;\n                    }\n                }\n            }\n        }\n\n        /* mandatory on leaf, anyxml or choice */\n        if (rfn->flags & LYS_MAND_MASK) {\n            /* remove current value */\n            node->flags &= ~LYS_MAND_MASK;\n\n            /* set new value */\n            node->flags |= (rfn->flags & LYS_MAND_MASK);\n\n            if (rfn->flags & LYS_MAND_TRUE) {\n                /* check if node has default value */\n                if ((node->nodetype & LYS_LEAF) && ((struct lys_node_leaf *)node)->dflt) {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses,\n                           \"The \\\"mandatory\\\" statement is forbidden on leaf with \\\"default\\\".\");\n                    goto fail;\n                }\n                if ((node->nodetype & LYS_CHOICE) && ((struct lys_node_choice *)node)->dflt) {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses,\n                           \"The \\\"mandatory\\\" statement is forbidden on choices with \\\"default\\\".\");\n                    goto fail;\n                }\n            }\n        }\n\n        /* presence on container */\n        if ((node->nodetype & LYS_CONTAINER) && rfn->mod.presence) {\n            lydict_remove(ctx, ((struct lys_node_container *)node)->presence);\n            ((struct lys_node_container *)node)->presence = lydict_insert(ctx, rfn->mod.presence, 0);\n        }\n\n        /* min/max-elements on list or leaf-list */\n        if (node->nodetype == LYS_LIST) {\n            if (rfn->flags & LYS_RFN_MINSET) {\n                ((struct lys_node_list *)node)->min = rfn->mod.list.min;\n            }\n            if (rfn->flags & LYS_RFN_MAXSET) {\n                ((struct lys_node_list *)node)->max = rfn->mod.list.max;\n            }\n        } else if (node->nodetype == LYS_LEAFLIST) {\n            if (rfn->flags & LYS_RFN_MINSET) {\n                ((struct lys_node_leaflist *)node)->min = rfn->mod.list.min;\n            }\n            if (rfn->flags & LYS_RFN_MAXSET) {\n                ((struct lys_node_leaflist *)node)->max = rfn->mod.list.max;\n            }\n        }\n\n        /* must in leaf, leaf-list, list, container or anyxml */\n        if (rfn->must_size) {\n            switch (node->nodetype) {\n            case LYS_LEAF:\n                old_size = &((struct lys_node_leaf *)node)->must_size;\n                old_must = &((struct lys_node_leaf *)node)->must;\n                break;\n            case LYS_LEAFLIST:\n                old_size = &((struct lys_node_leaflist *)node)->must_size;\n                old_must = &((struct lys_node_leaflist *)node)->must;\n                break;\n            case LYS_LIST:\n                old_size = &((struct lys_node_list *)node)->must_size;\n                old_must = &((struct lys_node_list *)node)->must;\n                break;\n            case LYS_CONTAINER:\n                old_size = &((struct lys_node_container *)node)->must_size;\n                old_must = &((struct lys_node_container *)node)->must;\n                break;\n            case LYS_ANYXML:\n            case LYS_ANYDATA:\n                old_size = &((struct lys_node_anydata *)node)->must_size;\n                old_must = &((struct lys_node_anydata *)node)->must;\n                break;\n            default:\n                LOGINT(ctx);\n                goto fail;\n            }\n\n            size = *old_size + rfn->must_size;\n            must = realloc(*old_must, size * sizeof *rfn->must);\n            LY_CHECK_ERR_GOTO(!must, LOGMEM(ctx), fail);\n            for (k = 0, j = *old_size; k < rfn->must_size; k++, j++) {\n                must[j].ext_size = rfn->must[k].ext_size;\n                lys_ext_dup(ctx, rfn->module, rfn->must[k].ext, rfn->must[k].ext_size, &rfn->must[k], LYEXT_PAR_RESTR,\n                            &must[j].ext, 0, unres);\n                must[j].expr = lydict_insert(ctx, rfn->must[k].expr, 0);\n                must[j].dsc = lydict_insert(ctx, rfn->must[k].dsc, 0);\n                must[j].ref = lydict_insert(ctx, rfn->must[k].ref, 0);\n                must[j].eapptag = lydict_insert(ctx, rfn->must[k].eapptag, 0);\n                must[j].emsg = lydict_insert(ctx, rfn->must[k].emsg, 0);\n                must[j].flags = rfn->must[k].flags;\n            }\n\n            *old_must = must;\n            *old_size = size;\n\n            /* check XPath dependencies again */\n            if (unres_schema_add_node(node->module, unres, node, UNRES_XPATH, NULL) == -1) {\n                goto fail;\n            }\n        }\n\n        /* if-feature in leaf, leaf-list, list, container or anyxml */\n        if (rfn->iffeature_size) {\n            old_size = &node->iffeature_size;\n            old_iff = &node->iffeature;\n\n            size = *old_size + rfn->iffeature_size;\n            iff = realloc(*old_iff, size * sizeof *rfn->iffeature);\n            LY_CHECK_ERR_GOTO(!iff, LOGMEM(ctx), fail);\n            *old_iff = iff;\n\n            for (k = 0, j = *old_size; k < rfn->iffeature_size; k++, j++) {\n                resolve_iffeature_getsizes(&rfn->iffeature[k], &usize1, &usize2);\n                if (usize1) {\n                    /* there is something to duplicate */\n                    /* duplicate compiled expression */\n                    usize = (usize1 / 4) + ((usize1 % 4) ? 1 : 0);\n                    iff[j].expr = malloc(usize * sizeof *iff[j].expr);\n                    LY_CHECK_ERR_GOTO(!iff[j].expr, LOGMEM(ctx), fail);\n                    memcpy(iff[j].expr, rfn->iffeature[k].expr, usize * sizeof *iff[j].expr);\n\n                    /* duplicate list of feature pointers */\n                    iff[j].features = malloc(usize2 * sizeof *iff[k].features);\n                    LY_CHECK_ERR_GOTO(!iff[j].expr, LOGMEM(ctx), fail);\n                    memcpy(iff[j].features, rfn->iffeature[k].features, usize2 * sizeof *iff[j].features);\n\n                    /* duplicate extensions */\n                    iff[j].ext_size = rfn->iffeature[k].ext_size;\n                    lys_ext_dup(ctx, rfn->module, rfn->iffeature[k].ext, rfn->iffeature[k].ext_size,\n                                &rfn->iffeature[k], LYEXT_PAR_IFFEATURE, &iff[j].ext, 0, unres);\n                }\n                (*old_size)++;\n            }\n            assert(*old_size == size);\n        }\n    }\n\n    /* apply augments */\n    for (i = 0; i < uses->augment_size; i++) {\n        rc = resolve_augment(&uses->augment[i], (struct lys_node *)uses, unres);\n        if (rc) {\n            goto fail;\n        }\n    }\n\n    /* check refines */\n    for (i = 0; i < uses->refine_size; i++) {\n        node = refine_nodes[i];\n        rfn = &uses->refine[i];\n\n        /* config on any nodetype */\n        if ((rfn->flags & LYS_CONFIG_MASK) && (node->flags & LYS_CONFIG_MASK)) {\n            for (parent = lys_parent(node); parent && parent->nodetype == LYS_USES; parent = lys_parent(parent));\n            if (parent && parent->nodetype != LYS_GROUPING && (parent->flags & LYS_CONFIG_MASK) &&\n                    ((parent->flags & LYS_CONFIG_MASK) != (rfn->flags & LYS_CONFIG_MASK)) &&\n                    (rfn->flags & LYS_CONFIG_W)) {\n                /* setting config true under config false is prohibited */\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, \"config\", \"refine\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                       \"changing config from 'false' to 'true' is prohibited while \"\n                       \"the target's parent is still config 'false'.\");\n                goto fail;\n            }\n\n            /* inherit config change to the target children */\n            LY_TREE_DFS_BEGIN(node->child, next, iter) {\n                if (rfn->flags & LYS_CONFIG_W) {\n                    if (iter->flags & LYS_CONFIG_SET) {\n                        /* config is set explicitely, go to next sibling */\n                        next = NULL;\n                        goto nextsibling;\n                    }\n                } else { /* LYS_CONFIG_R */\n                    if ((iter->flags & LYS_CONFIG_SET) && (iter->flags & LYS_CONFIG_W)) {\n                        /* error - we would have config data under status data */\n                        LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, \"config\", \"refine\");\n                        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                               \"changing config from 'true' to 'false' is prohibited while the target \"\n                               \"has still a children with explicit config 'true'.\");\n                        goto fail;\n                    }\n                }\n                /* change config */\n                iter->flags &= ~LYS_CONFIG_MASK;\n                iter->flags |= (rfn->flags & LYS_CONFIG_MASK);\n\n                /* select next iter - modified LY_TREE_DFS_END */\n                if (iter->nodetype & (LYS_LEAF | LYS_LEAFLIST | LYS_ANYDATA)) {\n                    next = NULL;\n                } else {\n                    next = iter->child;\n                }\nnextsibling:\n                if (!next) {\n                    /* try siblings */\n                    next = iter->next;\n                }\n                while (!next) {\n                    /* parent is already processed, go to its sibling */\n                    iter = lys_parent(iter);\n\n                    /* no siblings, go back through parents */\n                    if (iter == node) {\n                        /* we are done, no next element to process */\n                        break;\n                    }\n                    next = iter->next;\n                }\n            }\n        }\n\n        /* default value */\n        if (rfn->dflt_size) {\n            if (node->nodetype == LYS_CHOICE) {\n                /* choice */\n                ((struct lys_node_choice *)node)->dflt = resolve_choice_dflt((struct lys_node_choice *)node,\n                                                                             rfn->dflt[0]);\n                if (!((struct lys_node_choice *)node)->dflt) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, rfn->dflt[0], \"default\");\n                    goto fail;\n                }\n                if (lyp_check_mandatory_choice(node)) {\n                    goto fail;\n                }\n            }\n        }\n\n        /* min/max-elements on list or leaf-list */\n        if (node->nodetype == LYS_LIST && ((struct lys_node_list *)node)->max) {\n            if (((struct lys_node_list *)node)->min > ((struct lys_node_list *)node)->max) {\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses, \"Invalid value \\\"%d\\\" of \\\"%s\\\".\", rfn->mod.list.min, \"min-elements\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                goto fail;\n            }\n        } else if (node->nodetype == LYS_LEAFLIST && ((struct lys_node_leaflist *)node)->max) {\n            if (((struct lys_node_leaflist *)node)->min > ((struct lys_node_leaflist *)node)->max) {\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses, \"Invalid value \\\"%d\\\" of \\\"%s\\\".\", rfn->mod.list.min, \"min-elements\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                goto fail;\n            }\n        }\n\n        /* additional checks */\n        /* default value with mandatory/min-elements */\n        if (node->nodetype == LYS_LEAFLIST) {\n            llist = (struct lys_node_leaflist *)node;\n            if (llist->dflt_size && llist->min) {\n                LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, uses, rfn->dflt_size ? \"default\" : \"min-elements\", \"refine\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                       \"The \\\"min-elements\\\" statement with non-zero value is forbidden on leaf-lists with the \\\"default\\\" statement.\");\n                goto fail;\n            }\n        } else if (node->nodetype == LYS_LEAF) {\n            leaf = (struct lys_node_leaf *)node;\n            if (leaf->dflt && (leaf->flags & LYS_MAND_TRUE)) {\n                LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, uses, rfn->dflt_size ? \"default\" : \"mandatory\", \"refine\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                       \"The \\\"mandatory\\\" statement is forbidden on leafs with the \\\"default\\\" statement.\");\n                goto fail;\n            }\n        }\n\n        /* check for mandatory node in default case, first find the closest parent choice to the changed node */\n        if ((rfn->flags & LYS_MAND_TRUE) || rfn->mod.list.min) {\n            for (parent = node->parent;\n                 parent && !(parent->nodetype & (LYS_CHOICE | LYS_GROUPING | LYS_ACTION | LYS_USES));\n                 parent = parent->parent) {\n                if (parent->nodetype == LYS_CONTAINER && ((struct lys_node_container *)parent)->presence) {\n                    /* stop also on presence containers */\n                    break;\n                }\n            }\n            /* and if it is a choice with the default case, check it for presence of a mandatory node in it */\n            if (parent && parent->nodetype == LYS_CHOICE && ((struct lys_node_choice *)parent)->dflt) {\n                if (lyp_check_mandatory_choice(parent)) {\n                    goto fail;\n                }\n            }\n        }\n    }\n    free(refine_nodes);\n\n    /* check list config after all the refines were applied */\n    LY_TREE_DFS_BEGIN((struct lys_node *)uses, next, iter) {\n        if ((iter->nodetype == LYS_LIST) && (iter->flags & LYS_CONFIG_W)\n                && !((struct lys_node_list *)iter)->keys_size) {\n            LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, iter, \"key\", \"list\");\n            goto fail;\n        }\n        LY_TREE_DFS_END((struct lys_node *)uses, next, iter);\n    }\n\n    return EXIT_SUCCESS;\n\nfail:\n    LY_TREE_FOR_SAFE(uses->child, next, iter) {\n        lys_node_free(iter, NULL, 0);\n    }\n    free(refine_nodes);\n    return -1;\n}",
        "func": "static int\nresolve_uses(struct lys_node_uses *uses, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = uses->module->ctx; /* shortcut */\n    struct lys_node *node = NULL, *next, *iter, **refine_nodes = NULL;\n    struct lys_node *node_aux, *parent, *tmp;\n    struct lys_node_leaflist *llist;\n    struct lys_node_leaf *leaf;\n    struct lys_refine *rfn;\n    struct lys_restr *must, **old_must;\n    struct lys_iffeature *iff, **old_iff;\n    int i, j, k, rc;\n    uint8_t size, *old_size;\n    unsigned int usize, usize1, usize2;\n\n    assert(uses->grp);\n\n    /* check that the grouping is resolved (no unresolved uses inside) */\n    assert(!uses->grp->unres_count);\n\n    /* copy the data nodes from grouping into the uses context */\n    LY_TREE_FOR(uses->grp->child, node_aux) {\n        if (node_aux->nodetype & LYS_GROUPING) {\n            /* do not instantiate groupings from groupings */\n            continue;\n        }\n        node = lys_node_dup(uses->module, (struct lys_node *)uses, node_aux, unres, 0);\n        if (!node) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, uses->grp->name, \"uses\");\n            LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"Copying data from grouping failed.\");\n            goto fail;\n        }\n        /* test the name of siblings */\n        LY_TREE_FOR((uses->parent) ? *lys_child(uses->parent, LYS_USES) : lys_main_module(uses->module)->data, tmp) {\n            if (!(tmp->nodetype & (LYS_USES | LYS_GROUPING | LYS_CASE)) && ly_strequal(tmp->name, node_aux->name, 1)) {\n                goto fail;\n            }\n        }\n    }\n\n    /* we managed to copy the grouping, the rest must be possible to resolve */\n\n    if (uses->refine_size) {\n        refine_nodes = malloc(uses->refine_size * sizeof *refine_nodes);\n        LY_CHECK_ERR_GOTO(!refine_nodes, LOGMEM(ctx), fail);\n    }\n\n    /* apply refines */\n    for (i = 0; i < uses->refine_size; i++) {\n        rfn = &uses->refine[i];\n        rc = resolve_descendant_schema_nodeid(rfn->target_name, uses->child,\n                                              LYS_NO_RPC_NOTIF_NODE | LYS_ACTION | LYS_NOTIF,\n                                              0, (const struct lys_node **)&node);\n        if (rc || !node) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, rfn->target_name, \"refine\");\n            goto fail;\n        }\n\n        if (rfn->target_type && !(node->nodetype & rfn->target_type)) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, rfn->target_name, \"refine\");\n            LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"Refine substatements not applicable to the target-node.\");\n            goto fail;\n        }\n        refine_nodes[i] = node;\n\n        /* description on any nodetype */\n        if (rfn->dsc) {\n            lydict_remove(ctx, node->dsc);\n            node->dsc = lydict_insert(ctx, rfn->dsc, 0);\n        }\n\n        /* reference on any nodetype */\n        if (rfn->ref) {\n            lydict_remove(ctx, node->ref);\n            node->ref = lydict_insert(ctx, rfn->ref, 0);\n        }\n\n        /* config on any nodetype,\n         * in case of notification or rpc/action, the config is not applicable (there is no config status) */\n        if ((rfn->flags & LYS_CONFIG_MASK) && (node->flags & LYS_CONFIG_MASK)) {\n            node->flags &= ~LYS_CONFIG_MASK;\n            node->flags |= (rfn->flags & LYS_CONFIG_MASK);\n        }\n\n        /* default value ... */\n        if (rfn->dflt_size) {\n            if (node->nodetype == LYS_LEAF) {\n                /* leaf */\n                leaf = (struct lys_node_leaf *)node;\n\n                /* replace default value */\n                lydict_remove(ctx, leaf->dflt);\n                leaf->dflt = lydict_insert(ctx, rfn->dflt[0], 0);\n\n                /* check the default value */\n                if (unres_schema_add_node(leaf->module, unres, &leaf->type, UNRES_TYPE_DFLT,\n                                          (struct lys_node *)(&leaf->dflt)) == -1) {\n                    goto fail;\n                }\n            } else if (node->nodetype == LYS_LEAFLIST) {\n                /* leaf-list */\n                llist = (struct lys_node_leaflist *)node;\n\n                /* remove complete set of defaults in target */\n                for (j = 0; j < llist->dflt_size; j++) {\n                    lydict_remove(ctx, llist->dflt[j]);\n                }\n                free(llist->dflt);\n\n                /* copy the default set from refine */\n                llist->dflt = malloc(rfn->dflt_size * sizeof *llist->dflt);\n                LY_CHECK_ERR_GOTO(!llist->dflt, LOGMEM(ctx), fail);\n                llist->dflt_size = rfn->dflt_size;\n                for (j = 0; j < llist->dflt_size; j++) {\n                    llist->dflt[j] = lydict_insert(ctx, rfn->dflt[j], 0);\n                }\n\n                /* check default value */\n                for (j = 0; j < llist->dflt_size; j++) {\n                    if (unres_schema_add_node(llist->module, unres, &llist->type, UNRES_TYPE_DFLT,\n                                              (struct lys_node *)(&llist->dflt[j])) == -1) {\n                        goto fail;\n                    }\n                }\n            }\n        }\n\n        /* mandatory on leaf, anyxml or choice */\n        if (rfn->flags & LYS_MAND_MASK) {\n            /* remove current value */\n            node->flags &= ~LYS_MAND_MASK;\n\n            /* set new value */\n            node->flags |= (rfn->flags & LYS_MAND_MASK);\n\n            if (rfn->flags & LYS_MAND_TRUE) {\n                /* check if node has default value */\n                if ((node->nodetype & LYS_LEAF) && ((struct lys_node_leaf *)node)->dflt) {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses,\n                           \"The \\\"mandatory\\\" statement is forbidden on leaf with \\\"default\\\".\");\n                    goto fail;\n                }\n                if ((node->nodetype & LYS_CHOICE) && ((struct lys_node_choice *)node)->dflt) {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses,\n                           \"The \\\"mandatory\\\" statement is forbidden on choices with \\\"default\\\".\");\n                    goto fail;\n                }\n            }\n        }\n\n        /* presence on container */\n        if ((node->nodetype & LYS_CONTAINER) && rfn->mod.presence) {\n            lydict_remove(ctx, ((struct lys_node_container *)node)->presence);\n            ((struct lys_node_container *)node)->presence = lydict_insert(ctx, rfn->mod.presence, 0);\n        }\n\n        /* min/max-elements on list or leaf-list */\n        if (node->nodetype == LYS_LIST) {\n            if (rfn->flags & LYS_RFN_MINSET) {\n                ((struct lys_node_list *)node)->min = rfn->mod.list.min;\n            }\n            if (rfn->flags & LYS_RFN_MAXSET) {\n                ((struct lys_node_list *)node)->max = rfn->mod.list.max;\n            }\n        } else if (node->nodetype == LYS_LEAFLIST) {\n            if (rfn->flags & LYS_RFN_MINSET) {\n                ((struct lys_node_leaflist *)node)->min = rfn->mod.list.min;\n            }\n            if (rfn->flags & LYS_RFN_MAXSET) {\n                ((struct lys_node_leaflist *)node)->max = rfn->mod.list.max;\n            }\n        }\n\n        /* must in leaf, leaf-list, list, container or anyxml */\n        if (rfn->must_size) {\n            switch (node->nodetype) {\n            case LYS_LEAF:\n                old_size = &((struct lys_node_leaf *)node)->must_size;\n                old_must = &((struct lys_node_leaf *)node)->must;\n                break;\n            case LYS_LEAFLIST:\n                old_size = &((struct lys_node_leaflist *)node)->must_size;\n                old_must = &((struct lys_node_leaflist *)node)->must;\n                break;\n            case LYS_LIST:\n                old_size = &((struct lys_node_list *)node)->must_size;\n                old_must = &((struct lys_node_list *)node)->must;\n                break;\n            case LYS_CONTAINER:\n                old_size = &((struct lys_node_container *)node)->must_size;\n                old_must = &((struct lys_node_container *)node)->must;\n                break;\n            case LYS_ANYXML:\n            case LYS_ANYDATA:\n                old_size = &((struct lys_node_anydata *)node)->must_size;\n                old_must = &((struct lys_node_anydata *)node)->must;\n                break;\n            default:\n                LOGINT(ctx);\n                goto fail;\n            }\n\n            size = *old_size + rfn->must_size;\n            must = realloc(*old_must, size * sizeof *rfn->must);\n            LY_CHECK_ERR_GOTO(!must, LOGMEM(ctx), fail);\n            for (k = 0, j = *old_size; k < rfn->must_size; k++, j++) {\n                must[j].ext_size = rfn->must[k].ext_size;\n                lys_ext_dup(ctx, rfn->module, rfn->must[k].ext, rfn->must[k].ext_size, &rfn->must[k], LYEXT_PAR_RESTR,\n                            &must[j].ext, 0, unres);\n                must[j].expr = lydict_insert(ctx, rfn->must[k].expr, 0);\n                must[j].dsc = lydict_insert(ctx, rfn->must[k].dsc, 0);\n                must[j].ref = lydict_insert(ctx, rfn->must[k].ref, 0);\n                must[j].eapptag = lydict_insert(ctx, rfn->must[k].eapptag, 0);\n                must[j].emsg = lydict_insert(ctx, rfn->must[k].emsg, 0);\n                must[j].flags = rfn->must[k].flags;\n            }\n\n            *old_must = must;\n            *old_size = size;\n\n            /* check XPath dependencies again */\n            if (unres_schema_add_node(node->module, unres, node, UNRES_XPATH, NULL) == -1) {\n                goto fail;\n            }\n        }\n\n        /* if-feature in leaf, leaf-list, list, container or anyxml */\n        if (rfn->iffeature_size) {\n            old_size = &node->iffeature_size;\n            old_iff = &node->iffeature;\n\n            size = *old_size + rfn->iffeature_size;\n            iff = realloc(*old_iff, size * sizeof *rfn->iffeature);\n            LY_CHECK_ERR_GOTO(!iff, LOGMEM(ctx), fail);\n            *old_iff = iff;\n\n            for (k = 0, j = *old_size; k < rfn->iffeature_size; k++, j++) {\n                resolve_iffeature_getsizes(&rfn->iffeature[k], &usize1, &usize2);\n                if (usize1) {\n                    /* there is something to duplicate */\n                    /* duplicate compiled expression */\n                    usize = (usize1 / 4) + ((usize1 % 4) ? 1 : 0);\n                    iff[j].expr = malloc(usize * sizeof *iff[j].expr);\n                    LY_CHECK_ERR_GOTO(!iff[j].expr, LOGMEM(ctx), fail);\n                    memcpy(iff[j].expr, rfn->iffeature[k].expr, usize * sizeof *iff[j].expr);\n\n                    /* duplicate list of feature pointers */\n                    iff[j].features = malloc(usize2 * sizeof *iff[k].features);\n                    LY_CHECK_ERR_GOTO(!iff[j].expr, LOGMEM(ctx), fail);\n                    memcpy(iff[j].features, rfn->iffeature[k].features, usize2 * sizeof *iff[j].features);\n\n                    /* duplicate extensions */\n                    iff[j].ext_size = rfn->iffeature[k].ext_size;\n                    lys_ext_dup(ctx, rfn->module, rfn->iffeature[k].ext, rfn->iffeature[k].ext_size,\n                                &rfn->iffeature[k], LYEXT_PAR_IFFEATURE, &iff[j].ext, 0, unres);\n                }\n                (*old_size)++;\n            }\n            assert(*old_size == size);\n        }\n    }\n\n    /* apply augments */\n    for (i = 0; i < uses->augment_size; i++) {\n        rc = resolve_augment(&uses->augment[i], (struct lys_node *)uses, unres);\n        if (rc) {\n            goto fail;\n        }\n    }\n\n    /* check refines */\n    for (i = 0; i < uses->refine_size; i++) {\n        node = refine_nodes[i];\n        rfn = &uses->refine[i];\n\n        /* config on any nodetype */\n        if ((rfn->flags & LYS_CONFIG_MASK) && (node->flags & LYS_CONFIG_MASK)) {\n            for (parent = lys_parent(node); parent && parent->nodetype == LYS_USES; parent = lys_parent(parent));\n            if (parent && parent->nodetype != LYS_GROUPING && (parent->flags & LYS_CONFIG_MASK) &&\n                    ((parent->flags & LYS_CONFIG_MASK) != (rfn->flags & LYS_CONFIG_MASK)) &&\n                    (rfn->flags & LYS_CONFIG_W)) {\n                /* setting config true under config false is prohibited */\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, \"config\", \"refine\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                       \"changing config from 'false' to 'true' is prohibited while \"\n                       \"the target's parent is still config 'false'.\");\n                goto fail;\n            }\n\n            /* inherit config change to the target children */\n            LY_TREE_DFS_BEGIN(node->child, next, iter) {\n                if (rfn->flags & LYS_CONFIG_W) {\n                    if (iter->flags & LYS_CONFIG_SET) {\n                        /* config is set explicitely, go to next sibling */\n                        next = NULL;\n                        goto nextsibling;\n                    }\n                } else { /* LYS_CONFIG_R */\n                    if ((iter->flags & LYS_CONFIG_SET) && (iter->flags & LYS_CONFIG_W)) {\n                        /* error - we would have config data under status data */\n                        LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, \"config\", \"refine\");\n                        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                               \"changing config from 'true' to 'false' is prohibited while the target \"\n                               \"has still a children with explicit config 'true'.\");\n                        goto fail;\n                    }\n                }\n                /* change config */\n                iter->flags &= ~LYS_CONFIG_MASK;\n                iter->flags |= (rfn->flags & LYS_CONFIG_MASK);\n\n                /* select next iter - modified LY_TREE_DFS_END */\n                if (iter->nodetype & (LYS_LEAF | LYS_LEAFLIST | LYS_ANYDATA)) {\n                    next = NULL;\n                } else {\n                    next = iter->child;\n                }\nnextsibling:\n                if (!next) {\n                    /* try siblings */\n                    next = iter->next;\n                }\n                while (!next) {\n                    /* parent is already processed, go to its sibling */\n                    iter = lys_parent(iter);\n\n                    /* no siblings, go back through parents */\n                    if (iter == node) {\n                        /* we are done, no next element to process */\n                        break;\n                    }\n                    next = iter->next;\n                }\n            }\n        }\n\n        /* default value */\n        if (rfn->dflt_size) {\n            if (node->nodetype == LYS_CHOICE) {\n                /* choice */\n                ((struct lys_node_choice *)node)->dflt = resolve_choice_dflt((struct lys_node_choice *)node,\n                                                                             rfn->dflt[0]);\n                if (!((struct lys_node_choice *)node)->dflt) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, uses, rfn->dflt[0], \"default\");\n                    goto fail;\n                }\n                if (lyp_check_mandatory_choice(node)) {\n                    goto fail;\n                }\n            }\n        }\n\n        /* min/max-elements on list or leaf-list */\n        if (node->nodetype == LYS_LIST && ((struct lys_node_list *)node)->max) {\n            if (((struct lys_node_list *)node)->min > ((struct lys_node_list *)node)->max) {\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses, \"Invalid value \\\"%d\\\" of \\\"%s\\\".\", rfn->mod.list.min, \"min-elements\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                goto fail;\n            }\n        } else if (node->nodetype == LYS_LEAFLIST && ((struct lys_node_leaflist *)node)->max) {\n            if (((struct lys_node_leaflist *)node)->min > ((struct lys_node_leaflist *)node)->max) {\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_LYS, uses, \"Invalid value \\\"%d\\\" of \\\"%s\\\".\", rfn->mod.list.min, \"min-elements\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                goto fail;\n            }\n        }\n\n        /* additional checks */\n        /* default value with mandatory/min-elements */\n        if (node->nodetype == LYS_LEAFLIST) {\n            llist = (struct lys_node_leaflist *)node;\n            if (llist->dflt_size && llist->min) {\n                LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, uses, rfn->dflt_size ? \"default\" : \"min-elements\", \"refine\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                       \"The \\\"min-elements\\\" statement with non-zero value is forbidden on leaf-lists with the \\\"default\\\" statement.\");\n                goto fail;\n            }\n        } else if (node->nodetype == LYS_LEAF) {\n            leaf = (struct lys_node_leaf *)node;\n            if (leaf->dflt && (leaf->flags & LYS_MAND_TRUE)) {\n                LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, uses, rfn->dflt_size ? \"default\" : \"mandatory\", \"refine\");\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n                       \"The \\\"mandatory\\\" statement is forbidden on leafs with the \\\"default\\\" statement.\");\n                goto fail;\n            }\n        }\n\n        /* check for mandatory node in default case, first find the closest parent choice to the changed node */\n        if ((rfn->flags & LYS_MAND_TRUE) || rfn->mod.list.min) {\n            for (parent = node->parent;\n                 parent && !(parent->nodetype & (LYS_CHOICE | LYS_GROUPING | LYS_ACTION | LYS_USES));\n                 parent = parent->parent) {\n                if (parent->nodetype == LYS_CONTAINER && ((struct lys_node_container *)parent)->presence) {\n                    /* stop also on presence containers */\n                    break;\n                }\n            }\n            /* and if it is a choice with the default case, check it for presence of a mandatory node in it */\n            if (parent && parent->nodetype == LYS_CHOICE && ((struct lys_node_choice *)parent)->dflt) {\n                if (lyp_check_mandatory_choice(parent)) {\n                    goto fail;\n                }\n            }\n        }\n    }\n    free(refine_nodes);\n\n    /* check list config after all the refines were applied */\n    LY_TREE_DFS_BEGIN((struct lys_node *)uses, next, iter) {\n        if ((iter->nodetype == LYS_LIST) && (iter->flags & LYS_CONFIG_W)\n                && !((struct lys_node_list *)iter)->keys_size) {\n            LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, iter, \"key\", \"list\");\n            goto fail;\n        }\n        LY_TREE_DFS_END((struct lys_node *)uses, next, iter);\n    }\n\n    return EXIT_SUCCESS;\n\nfail:\n    LY_TREE_FOR_SAFE(uses->child, next, iter) {\n        lys_node_free(ctx, iter, NULL, 0);\n    }\n    free(refine_nodes);\n    return -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -419,7 +419,7 @@\n \n fail:\n     LY_TREE_FOR_SAFE(uses->child, next, iter) {\n-        lys_node_free(iter, NULL, 0);\n+        lys_node_free(ctx, iter, NULL, 0);\n     }\n     free(refine_nodes);\n     return -1;",
        "diff_line_info": {
            "deleted_lines": [
                "        lys_node_free(iter, NULL, 0);"
            ],
            "added_lines": [
                "        lys_node_free(ctx, iter, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_anydata",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_anydata(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, LYS_NODE type,\n                 int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval;\n    struct lys_node_anydata *anyxml;\n    struct lyxml_elem *sub, *next;\n    const char *value;\n    int r;\n    int f_mand = 0;\n    int c_must = 0, c_ftrs = 0, c_ext = 0;\n    void *reallocated;\n\n    anyxml = calloc(1, sizeof *anyxml);\n    LY_CHECK_ERR_RETURN(!anyxml, LOGMEM(ctx), NULL);\n\n    anyxml->nodetype = type;\n    anyxml->prev = (struct lys_node *)anyxml;\n    retval = (struct lys_node *)anyxml;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n            (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT), unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"anydata\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"mandatory\")) {\n            if (f_mand) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in leaf is not sufficient, we would allow\n             * multiple mandatory statements with the \"false\" value\n             */\n            f_mand = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"true\")) {\n                anyxml->flags |= LYS_MAND_TRUE;\n            } else if (!strcmp(value, \"false\")) {\n                anyxml->flags |= LYS_MAND_FALSE;\n            } else {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }\n            /* else false is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MANDATORY, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (anyxml->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            anyxml->when = read_yin_when(module, sub, unres);\n            if (!anyxml->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, anyxml->must_size, \"musts\", \"anydata\", error);\n            c_must++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"anydata\", error);\n            c_ftrs++;\n\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n */\n    if (c_must) {\n        anyxml->must = calloc(c_must, sizeof *anyxml->must);\n        LY_CHECK_ERR_GOTO(!anyxml->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        anyxml->iffeature = calloc(c_ftrs, sizeof *anyxml->iffeature);\n        LY_CHECK_ERR_GOTO(!anyxml->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &anyxml->must[anyxml->must_size], unres);\n            anyxml->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &anyxml->iffeature[anyxml->iffeature_size], unres);\n            anyxml->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (anyxml->when || anyxml->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            break;\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_anydata(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, LYS_NODE type,\n                 int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval;\n    struct lys_node_anydata *anyxml;\n    struct lyxml_elem *sub, *next;\n    const char *value;\n    int r;\n    int f_mand = 0;\n    int c_must = 0, c_ftrs = 0, c_ext = 0;\n    void *reallocated;\n\n    anyxml = calloc(1, sizeof *anyxml);\n    LY_CHECK_ERR_RETURN(!anyxml, LOGMEM(ctx), NULL);\n\n    anyxml->nodetype = type;\n    anyxml->prev = (struct lys_node *)anyxml;\n    retval = (struct lys_node *)anyxml;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n            (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT), unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"anydata\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"mandatory\")) {\n            if (f_mand) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in leaf is not sufficient, we would allow\n             * multiple mandatory statements with the \"false\" value\n             */\n            f_mand = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"true\")) {\n                anyxml->flags |= LYS_MAND_TRUE;\n            } else if (!strcmp(value, \"false\")) {\n                anyxml->flags |= LYS_MAND_FALSE;\n            } else {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }\n            /* else false is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MANDATORY, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (anyxml->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            anyxml->when = read_yin_when(module, sub, unres);\n            if (!anyxml->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, anyxml->must_size, \"musts\", \"anydata\", error);\n            c_must++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"anydata\", error);\n            c_ftrs++;\n\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n */\n    if (c_must) {\n        anyxml->must = calloc(c_must, sizeof *anyxml->must);\n        LY_CHECK_ERR_GOTO(!anyxml->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        anyxml->iffeature = calloc(c_ftrs, sizeof *anyxml->iffeature);\n        LY_CHECK_ERR_GOTO(!anyxml->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &anyxml->must[anyxml->must_size], unres);\n            anyxml->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &anyxml->iffeature[anyxml->iffeature_size], unres);\n            anyxml->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (anyxml->when || anyxml->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            break;\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -154,6 +154,6 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_uses",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_uses(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n              int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next;\n    struct lys_node *retval;\n    struct lys_node_uses *uses;\n    const char *value;\n    int c_ref = 0, c_aug = 0, c_ftrs = 0, c_ext = 0;\n    int r;\n    void *reallocated;\n\n    uses = calloc(1, sizeof *uses);\n    LY_CHECK_ERR_RETURN(!uses, LOGMEM(ctx), NULL);\n\n    uses->nodetype = LYS_USES;\n    uses->prev = (struct lys_node *)uses;\n    retval = (struct lys_node *)uses;\n\n    GETVAL(ctx, value, yin, \"name\");\n    uses->name = lydict_insert(ctx, value, 0);\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_MODULE, unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* get other properties of uses */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"uses\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"refine\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ref, uses->refine_size, \"refines\", \"uses\", error);\n            c_ref++;\n        } else if (!strcmp(sub->name, \"augment\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_aug, uses->augment_size, \"augments\", \"uses\", error);\n            c_aug++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"uses\", error);\n            c_ftrs++;\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (uses->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            uses->when = read_yin_when(module, sub, unres);\n            if (!uses->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* process properties with cardinality 0..n */\n    if (c_ref) {\n        uses->refine = calloc(c_ref, sizeof *uses->refine);\n        LY_CHECK_ERR_GOTO(!uses->refine, LOGMEM(ctx), error);\n    }\n    if (c_aug) {\n        uses->augment = calloc(c_aug, sizeof *uses->augment);\n        LY_CHECK_ERR_GOTO(!uses->augment, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        uses->iffeature = calloc(c_ftrs, sizeof *uses->iffeature);\n        LY_CHECK_ERR_GOTO(!uses->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"refine\")) {\n            r = fill_yin_refine(retval, sub, &uses->refine[uses->refine_size], unres);\n            uses->refine_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"augment\")) {\n            r = fill_yin_augment(module, retval, sub, &uses->augment[uses->augment_size], options, unres);\n            uses->augment_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &uses->iffeature[uses->iffeature_size], unres);\n            uses->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    if (unres_schema_add_node(module, unres, uses, UNRES_USES, NULL) == -1) {\n        goto error;\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && uses->when) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_uses(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n              int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next;\n    struct lys_node *retval;\n    struct lys_node_uses *uses;\n    const char *value;\n    int c_ref = 0, c_aug = 0, c_ftrs = 0, c_ext = 0;\n    int r;\n    void *reallocated;\n\n    uses = calloc(1, sizeof *uses);\n    LY_CHECK_ERR_RETURN(!uses, LOGMEM(ctx), NULL);\n\n    uses->nodetype = LYS_USES;\n    uses->prev = (struct lys_node *)uses;\n    retval = (struct lys_node *)uses;\n\n    GETVAL(ctx, value, yin, \"name\");\n    uses->name = lydict_insert(ctx, value, 0);\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_MODULE, unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* get other properties of uses */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"uses\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"refine\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ref, uses->refine_size, \"refines\", \"uses\", error);\n            c_ref++;\n        } else if (!strcmp(sub->name, \"augment\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_aug, uses->augment_size, \"augments\", \"uses\", error);\n            c_aug++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"uses\", error);\n            c_ftrs++;\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (uses->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            uses->when = read_yin_when(module, sub, unres);\n            if (!uses->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* process properties with cardinality 0..n */\n    if (c_ref) {\n        uses->refine = calloc(c_ref, sizeof *uses->refine);\n        LY_CHECK_ERR_GOTO(!uses->refine, LOGMEM(ctx), error);\n    }\n    if (c_aug) {\n        uses->augment = calloc(c_aug, sizeof *uses->augment);\n        LY_CHECK_ERR_GOTO(!uses->augment, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        uses->iffeature = calloc(c_ftrs, sizeof *uses->iffeature);\n        LY_CHECK_ERR_GOTO(!uses->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"refine\")) {\n            r = fill_yin_refine(retval, sub, &uses->refine[uses->refine_size], unres);\n            uses->refine_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"augment\")) {\n            r = fill_yin_augment(module, retval, sub, &uses->augment[uses->augment_size], options, unres);\n            uses->augment_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &uses->iffeature[uses->iffeature_size], unres);\n            uses->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    if (unres_schema_add_node(module, unres, uses, UNRES_USES, NULL) == -1) {\n        goto error;\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && uses->when) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -139,6 +139,6 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_input_output",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_input_output(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n                      int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval = NULL;\n    struct lys_node_inout *inout;\n    int r;\n    int c_tpdf = 0, c_must = 0, c_ext = 0;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    inout = calloc(1, sizeof *inout);\n    LY_CHECK_ERR_RETURN(!inout, LOGMEM(ctx), NULL);\n    inout->prev = (struct lys_node *)inout;\n\n    if (!strcmp(yin->name, \"input\")) {\n        inout->nodetype = LYS_INPUT;\n        inout->name = lydict_insert(ctx, \"input\", 0);\n    } else if (!strcmp(yin->name, \"output\")) {\n        inout->nodetype = LYS_OUTPUT;\n        inout->name = lydict_insert(ctx, \"output\", 0);\n    } else {\n        LOGINT(ctx);\n        free(inout);\n        goto error;\n    }\n\n    retval = (struct lys_node *)inout;\n    retval->module = module;\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* data statements */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (!sub->ns) {\n            /* garbage */\n            lyxml_free(ctx, sub);\n        } else if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\",\n                                          inout->nodetype == LYS_INPUT ? \"input\" : \"output\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, inout->tpdf_size, \"typedefs\",\n                                          inout->nodetype == LYS_INPUT ? \"input\" : \"output\", error);\n            c_tpdf++;\n\n        } else if ((module->version >= 2) && !strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, inout->must_size, \"musts\",\n                                          inout->nodetype == LYS_INPUT ? \"input\" : \"output\", error);\n            c_must++;\n\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    if (!root.child) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"schema-node\", strnodetype(retval->nodetype));\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        inout->tpdf = calloc(c_tpdf, sizeof *inout->tpdf);\n        LY_CHECK_ERR_GOTO(!inout->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        inout->must = calloc(c_must, sizeof *inout->must);\n        LY_CHECK_ERR_GOTO(!inout->must, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        inout->ext = calloc(c_ext, sizeof *inout->ext);\n        LY_CHECK_ERR_GOTO(!inout->ext, LOGMEM(ctx), error);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &inout->must[inout->must_size], unres);\n            inout->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else { /* typedef */\n            r = fill_yin_typedef(module, retval, sub, &inout->tpdf[inout->tpdf_size], unres);\n            inout->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    options |= LYS_PARSE_OPT_CFG_IGNORE;\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && inout->must) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_input_output(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n                      int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval = NULL;\n    struct lys_node_inout *inout;\n    int r;\n    int c_tpdf = 0, c_must = 0, c_ext = 0;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    inout = calloc(1, sizeof *inout);\n    LY_CHECK_ERR_RETURN(!inout, LOGMEM(ctx), NULL);\n    inout->prev = (struct lys_node *)inout;\n\n    if (!strcmp(yin->name, \"input\")) {\n        inout->nodetype = LYS_INPUT;\n        inout->name = lydict_insert(ctx, \"input\", 0);\n    } else if (!strcmp(yin->name, \"output\")) {\n        inout->nodetype = LYS_OUTPUT;\n        inout->name = lydict_insert(ctx, \"output\", 0);\n    } else {\n        LOGINT(ctx);\n        free(inout);\n        goto error;\n    }\n\n    retval = (struct lys_node *)inout;\n    retval->module = module;\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* data statements */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (!sub->ns) {\n            /* garbage */\n            lyxml_free(ctx, sub);\n        } else if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\",\n                                          inout->nodetype == LYS_INPUT ? \"input\" : \"output\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, inout->tpdf_size, \"typedefs\",\n                                          inout->nodetype == LYS_INPUT ? \"input\" : \"output\", error);\n            c_tpdf++;\n\n        } else if ((module->version >= 2) && !strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, inout->must_size, \"musts\",\n                                          inout->nodetype == LYS_INPUT ? \"input\" : \"output\", error);\n            c_must++;\n\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    if (!root.child) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"schema-node\", strnodetype(retval->nodetype));\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        inout->tpdf = calloc(c_tpdf, sizeof *inout->tpdf);\n        LY_CHECK_ERR_GOTO(!inout->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        inout->must = calloc(c_must, sizeof *inout->must);\n        LY_CHECK_ERR_GOTO(!inout->must, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        inout->ext = calloc(c_ext, sizeof *inout->ext);\n        LY_CHECK_ERR_GOTO(!inout->ext, LOGMEM(ctx), error);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &inout->must[inout->must_size], unres);\n            inout->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else { /* typedef */\n            r = fill_yin_typedef(module, retval, sub, &inout->tpdf[inout->tpdf_size], unres);\n            inout->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    options |= LYS_PARSE_OPT_CFG_IGNORE;\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && inout->must) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -166,7 +166,7 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     while (root.child) {\n         lyxml_free(ctx, root.child);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_notif",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_notif(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n               int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_notif *notif;\n    int r;\n    int c_tpdf = 0, c_ftrs = 0, c_must = 0, c_ext = 0;\n    void *reallocated;\n\n    if (parent && (module->version < 2)) {\n        LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, parent, \"notification\");\n        return NULL;\n    }\n\n    memset(&root, 0, sizeof root);\n\n    notif = calloc(1, sizeof *notif);\n    LY_CHECK_ERR_RETURN(!notif, LOGMEM(ctx), NULL);\n\n    notif->nodetype = LYS_NOTIF;\n    notif->prev = (struct lys_node *)notif;\n    retval = (struct lys_node *)notif;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_IDENT | OPT_MODULE, unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process rpc's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"notification\", error);\n            c_ext++;\n            continue;\n\n        /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, notif->tpdf_size, \"typedefs\", \"notification\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"notification\", error);\n            c_ftrs++;\n        } else if ((module->version >= 2) && !strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, notif->must_size, \"musts\", \"notification\", error);\n            c_must++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        notif->tpdf = calloc(c_tpdf, sizeof *notif->tpdf);\n        LY_CHECK_ERR_GOTO(!notif->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        notif->iffeature = calloc(c_ftrs, sizeof *notif->iffeature);\n        LY_CHECK_ERR_GOTO(!notif->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        notif->must = calloc(c_must, sizeof *notif->must);\n        LY_CHECK_ERR_GOTO(!notif->must, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &notif->tpdf[notif->tpdf_size], unres);\n            notif->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &notif->iffeature[notif->iffeature_size], unres);\n            notif->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &notif->must[notif->must_size], unres);\n            notif->must_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    options |= LYS_PARSE_OPT_CFG_IGNORE;\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && notif->must) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_notif(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n               int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_notif *notif;\n    int r;\n    int c_tpdf = 0, c_ftrs = 0, c_must = 0, c_ext = 0;\n    void *reallocated;\n\n    if (parent && (module->version < 2)) {\n        LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, parent, \"notification\");\n        return NULL;\n    }\n\n    memset(&root, 0, sizeof root);\n\n    notif = calloc(1, sizeof *notif);\n    LY_CHECK_ERR_RETURN(!notif, LOGMEM(ctx), NULL);\n\n    notif->nodetype = LYS_NOTIF;\n    notif->prev = (struct lys_node *)notif;\n    retval = (struct lys_node *)notif;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_IDENT | OPT_MODULE, unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process rpc's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"notification\", error);\n            c_ext++;\n            continue;\n\n        /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, notif->tpdf_size, \"typedefs\", \"notification\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"notification\", error);\n            c_ftrs++;\n        } else if ((module->version >= 2) && !strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, notif->must_size, \"musts\", \"notification\", error);\n            c_must++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        notif->tpdf = calloc(c_tpdf, sizeof *notif->tpdf);\n        LY_CHECK_ERR_GOTO(!notif->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        notif->iffeature = calloc(c_ftrs, sizeof *notif->iffeature);\n        LY_CHECK_ERR_GOTO(!notif->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        notif->must = calloc(c_must, sizeof *notif->must);\n        LY_CHECK_ERR_GOTO(!notif->must, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &notif->tpdf[notif->tpdf_size], unres);\n            notif->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &notif->iffeature[notif->iffeature_size], unres);\n            notif->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &notif->must[notif->must_size], unres);\n            notif->must_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    options |= LYS_PARSE_OPT_CFG_IGNORE;\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && notif->must) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -171,7 +171,7 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     while (root.child) {\n         lyxml_free(ctx, root.child);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_choice",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_choice(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                struct unres_schema *unres)\n{\n    struct lyxml_elem *sub, *next, *dflt = NULL;\n    struct ly_ctx *const ctx = module->ctx;\n    struct lys_node *retval, *node = NULL;\n    struct lys_node_choice *choice;\n    const char *value;\n    int f_mand = 0, c_ftrs = 0, c_ext = 0, ret;\n    void *reallocated;\n\n    choice = calloc(1, sizeof *choice);\n    LY_CHECK_ERR_RETURN(!choice, LOGMEM(ctx), NULL);\n\n    choice->nodetype = LYS_CHOICE;\n    choice->prev = (struct lys_node *)choice;\n    retval = (struct lys_node *)choice;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process choice's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"choice\", error);\n            c_ext++;\n            /* keep it for later processing, skip lyxml_free() */\n            continue;\n        } else if (!strcmp(sub->name, \"container\")) {\n            if (!(node = read_yin_container(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            if (!(node = read_yin_leaflist(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            if (!(node = read_yin_leaf(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"list\")) {\n            if (!(node = read_yin_list(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"case\")) {\n            if (!(node = read_yin_case(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            if (!(node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            if (!(node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"default\")) {\n            if (dflt) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_DEFAULT, 0, unres)) {\n                goto error;\n            }\n\n            dflt = sub;\n            lyxml_unlink_elem(ctx, dflt, 0);\n            continue;\n            /* skip lyxml_free() at the end of the loop, the sub node is processed later as dflt */\n\n        } else if (!strcmp(sub->name, \"mandatory\")) {\n            if (f_mand) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in leaf is not sufficient, we would allow\n             * multiple mandatory statements with the \"false\" value\n             */\n            f_mand = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"true\")) {\n                choice->flags |= LYS_MAND_TRUE;\n            } else if (!strcmp(value, \"false\")) {\n                choice->flags |= LYS_MAND_FALSE;\n            } else {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }                   /* else false is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MANDATORY, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (choice->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            choice->when = read_yin_when(module, sub, unres);\n            if (!choice->when) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"choice\", error);\n            c_ftrs++;\n\n            /* skip lyxml_free() at the end of the loop, the sub node is processed later */\n            continue;\n        } else if (module->version >= 2 && !strcmp(sub->name, \"choice\")) {\n            if (!(node = read_yin_choice(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n\n        node = NULL;\n        lyxml_free(ctx, sub);\n    }\n\n    if (c_ftrs) {\n        choice->iffeature = calloc(c_ftrs, sizeof *choice->iffeature);\n        LY_CHECK_ERR_GOTO(!choice->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            ret = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (ret) {\n                goto error;\n            }\n        } else {\n            ret = fill_yin_iffeature(retval, 0, sub, &choice->iffeature[choice->iffeature_size], unres);\n            choice->iffeature_size++;\n            if (ret) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* check - default is prohibited in combination with mandatory */\n    if (dflt && (choice->flags & LYS_MAND_TRUE)) {\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, retval, \"default\", \"choice\");\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"The \\\"default\\\" statement is forbidden on choices with \\\"mandatory\\\".\");\n        goto error;\n    }\n\n    /* link default with the case */\n    if (dflt) {\n        GETVAL(ctx, value, dflt, \"value\");\n        if (unres_schema_add_str(module, unres, choice, UNRES_CHOICE_DFLT, value) == -1) {\n            goto error;\n        }\n        lyxml_free(ctx, dflt);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && choice->when) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lyxml_free(ctx, dflt);\n    lys_node_free(retval, NULL, 0);\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_choice(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                struct unres_schema *unres)\n{\n    struct lyxml_elem *sub, *next, *dflt = NULL;\n    struct ly_ctx *const ctx = module->ctx;\n    struct lys_node *retval, *node = NULL;\n    struct lys_node_choice *choice;\n    const char *value;\n    int f_mand = 0, c_ftrs = 0, c_ext = 0, ret;\n    void *reallocated;\n\n    choice = calloc(1, sizeof *choice);\n    LY_CHECK_ERR_RETURN(!choice, LOGMEM(ctx), NULL);\n\n    choice->nodetype = LYS_CHOICE;\n    choice->prev = (struct lys_node *)choice;\n    retval = (struct lys_node *)choice;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process choice's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"choice\", error);\n            c_ext++;\n            /* keep it for later processing, skip lyxml_free() */\n            continue;\n        } else if (!strcmp(sub->name, \"container\")) {\n            if (!(node = read_yin_container(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            if (!(node = read_yin_leaflist(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            if (!(node = read_yin_leaf(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"list\")) {\n            if (!(node = read_yin_list(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"case\")) {\n            if (!(node = read_yin_case(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            if (!(node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            if (!(node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres))) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"default\")) {\n            if (dflt) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_DEFAULT, 0, unres)) {\n                goto error;\n            }\n\n            dflt = sub;\n            lyxml_unlink_elem(ctx, dflt, 0);\n            continue;\n            /* skip lyxml_free() at the end of the loop, the sub node is processed later as dflt */\n\n        } else if (!strcmp(sub->name, \"mandatory\")) {\n            if (f_mand) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in leaf is not sufficient, we would allow\n             * multiple mandatory statements with the \"false\" value\n             */\n            f_mand = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"true\")) {\n                choice->flags |= LYS_MAND_TRUE;\n            } else if (!strcmp(value, \"false\")) {\n                choice->flags |= LYS_MAND_FALSE;\n            } else {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }                   /* else false is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MANDATORY, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (choice->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            choice->when = read_yin_when(module, sub, unres);\n            if (!choice->when) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"choice\", error);\n            c_ftrs++;\n\n            /* skip lyxml_free() at the end of the loop, the sub node is processed later */\n            continue;\n        } else if (module->version >= 2 && !strcmp(sub->name, \"choice\")) {\n            if (!(node = read_yin_choice(module, retval, sub, options, unres))) {\n                goto error;\n            }\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n\n        node = NULL;\n        lyxml_free(ctx, sub);\n    }\n\n    if (c_ftrs) {\n        choice->iffeature = calloc(c_ftrs, sizeof *choice->iffeature);\n        LY_CHECK_ERR_GOTO(!choice->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            ret = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (ret) {\n                goto error;\n            }\n        } else {\n            ret = fill_yin_iffeature(retval, 0, sub, &choice->iffeature[choice->iffeature_size], unres);\n            choice->iffeature_size++;\n            if (ret) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* check - default is prohibited in combination with mandatory */\n    if (dflt && (choice->flags & LYS_MAND_TRUE)) {\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, retval, \"default\", \"choice\");\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"The \\\"default\\\" statement is forbidden on choices with \\\"mandatory\\\".\");\n        goto error;\n    }\n\n    /* link default with the case */\n    if (dflt) {\n        GETVAL(ctx, value, dflt, \"value\");\n        if (unres_schema_add_str(module, unres, choice, UNRES_CHOICE_DFLT, value) == -1) {\n            goto error;\n        }\n        lyxml_free(ctx, dflt);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && choice->when) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lyxml_free(ctx, dflt);\n    lys_node_free(ctx, retval, NULL, 0);\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -199,6 +199,6 @@\n \n error:\n     lyxml_free(ctx, dflt);\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_grouping",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_grouping(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                  struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_grp *grp;\n    int r;\n    int c_tpdf = 0, c_ext = 0;\n    void *reallocated;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    grp = calloc(1, sizeof *grp);\n    LY_CHECK_ERR_RETURN(!grp, LOGMEM(ctx), NULL);\n\n    grp->nodetype = LYS_GROUPING;\n    grp->prev = (struct lys_node *)grp;\n    retval = (struct lys_node *)grp;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_IDENT | OPT_MODULE , unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"grouping\", error);\n            c_ext++;\n\n        /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\") ||\n                !strcmp(sub->name, \"action\") ||\n                !strcmp(sub->name, \"notification\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, grp->tpdf_size, \"typedefs\", \"grouping\", error);\n            c_tpdf++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        grp->tpdf = calloc(c_tpdf, sizeof *grp->tpdf);\n        LY_CHECK_ERR_GOTO(!grp->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else {\n            /* typedef */\n            r = fill_yin_typedef(module, retval, sub, &grp->tpdf[grp->tpdf_size], unres);\n            grp->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    if (!root.child) {\n        LOGWRN(ctx, \"Grouping \\\"%s\\\" without children.\", retval->name);\n    }\n    options |= LYS_PARSE_OPT_INGRP;\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        } else if (!strcmp(sub->name, \"action\")) {\n            node = read_yin_rpc_action(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"notification\")) {\n            node = read_yin_notif(module, retval, sub, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_grouping(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                  struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_grp *grp;\n    int r;\n    int c_tpdf = 0, c_ext = 0;\n    void *reallocated;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    grp = calloc(1, sizeof *grp);\n    LY_CHECK_ERR_RETURN(!grp, LOGMEM(ctx), NULL);\n\n    grp->nodetype = LYS_GROUPING;\n    grp->prev = (struct lys_node *)grp;\n    retval = (struct lys_node *)grp;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_IDENT | OPT_MODULE , unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"grouping\", error);\n            c_ext++;\n\n        /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\") ||\n                !strcmp(sub->name, \"action\") ||\n                !strcmp(sub->name, \"notification\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, grp->tpdf_size, \"typedefs\", \"grouping\", error);\n            c_tpdf++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        grp->tpdf = calloc(c_tpdf, sizeof *grp->tpdf);\n        LY_CHECK_ERR_GOTO(!grp->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else {\n            /* typedef */\n            r = fill_yin_typedef(module, retval, sub, &grp->tpdf[grp->tpdf_size], unres);\n            grp->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    if (!root.child) {\n        LOGWRN(ctx, \"Grouping \\\"%s\\\" without children.\", retval->name);\n    }\n    options |= LYS_PARSE_OPT_INGRP;\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        } else if (!strcmp(sub->name, \"action\")) {\n            node = read_yin_rpc_action(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"notification\")) {\n            node = read_yin_notif(module, retval, sub, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -135,7 +135,7 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     while (root.child) {\n         lyxml_free(ctx, root.child);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_leaf",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_leaf(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n              struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval;\n    struct lys_node_leaf *leaf;\n    struct lyxml_elem *sub, *next;\n    const char *value;\n    int r, has_type = 0;\n    int c_must = 0, c_ftrs = 0, f_mand = 0, c_ext = 0;\n    void *reallocated;\n\n    leaf = calloc(1, sizeof *leaf);\n    LY_CHECK_ERR_RETURN(!leaf, LOGMEM(ctx), NULL);\n\n    leaf->nodetype = LYS_LEAF;\n    leaf->prev = (struct lys_node *)leaf;\n    retval = (struct lys_node *)leaf;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"leaf\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"type\")) {\n            if (has_type) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* HACK for unres */\n            leaf->type.der = (struct lys_tpdf *)sub;\n            leaf->type.parent = (struct lys_tpdf *)leaf;\n            /* postpone type resolution when if-feature parsing is done since we need\n             * if-feature for check_leafref_features() */\n            has_type = 1;\n        } else if (!strcmp(sub->name, \"default\")) {\n            if (leaf->dflt) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"value\");\n            leaf->dflt = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_DEFAULT, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"units\")) {\n            if (leaf->units) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"name\");\n            leaf->units = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_UNITS, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"mandatory\")) {\n            if (f_mand) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in leaf is not sufficient, we would allow\n             * multiple mandatory statements with the \"false\" value\n             */\n            f_mand = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"true\")) {\n                leaf->flags |= LYS_MAND_TRUE;\n            } else if (!strcmp(value, \"false\")) {\n                leaf->flags |= LYS_MAND_FALSE;\n            } else {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }                   /* else false is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MANDATORY, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (leaf->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            leaf->when = read_yin_when(module, sub, unres);\n            if (!leaf->when) {\n                goto error;\n            }\n\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, leaf->must_size, \"musts\", \"leaf\", error);\n            c_must++;\n            continue;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"musts\", \"leaf\", error);\n            c_ftrs++;\n            continue;\n\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n\n        /* do not free sub, it could have been unlinked and stored in unres */\n    }\n\n    /* check mandatory parameters */\n    if (!has_type) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"type\", yin->name);\n        goto error;\n    }\n    if (leaf->dflt && (leaf->flags & LYS_MAND_TRUE)) {\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, retval, \"mandatory\", \"leaf\");\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n               \"The \\\"mandatory\\\" statement is forbidden on leaf with the \\\"default\\\" statement.\");\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n */\n    if (c_must) {\n        leaf->must = calloc(c_must, sizeof *leaf->must);\n        LY_CHECK_ERR_GOTO(!leaf->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        leaf->iffeature = calloc(c_ftrs, sizeof *leaf->iffeature);\n        LY_CHECK_ERR_GOTO(!leaf->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &leaf->must[leaf->must_size], unres);\n            leaf->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &leaf->iffeature[leaf->iffeature_size], unres);\n            leaf->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* finalize type parsing */\n    if (unres_schema_add_node(module, unres, &leaf->type, UNRES_TYPE_DER, retval) == -1) {\n        leaf->type.der = NULL;\n        goto error;\n    }\n\n    /* check default value (if not defined, there still could be some restrictions\n     * that need to be checked against a default value from a derived type) */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) &&\n            (unres_schema_add_node(module, unres, &leaf->type, UNRES_TYPE_DFLT,\n                                   (struct lys_node *)(&leaf->dflt)) == -1)) {\n        goto error;\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (leaf->when || leaf->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            break;\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_leaf(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n              struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval;\n    struct lys_node_leaf *leaf;\n    struct lyxml_elem *sub, *next;\n    const char *value;\n    int r, has_type = 0;\n    int c_must = 0, c_ftrs = 0, f_mand = 0, c_ext = 0;\n    void *reallocated;\n\n    leaf = calloc(1, sizeof *leaf);\n    LY_CHECK_ERR_RETURN(!leaf, LOGMEM(ctx), NULL);\n\n    leaf->nodetype = LYS_LEAF;\n    leaf->prev = (struct lys_node *)leaf;\n    retval = (struct lys_node *)leaf;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"leaf\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"type\")) {\n            if (has_type) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* HACK for unres */\n            leaf->type.der = (struct lys_tpdf *)sub;\n            leaf->type.parent = (struct lys_tpdf *)leaf;\n            /* postpone type resolution when if-feature parsing is done since we need\n             * if-feature for check_leafref_features() */\n            has_type = 1;\n        } else if (!strcmp(sub->name, \"default\")) {\n            if (leaf->dflt) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"value\");\n            leaf->dflt = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_DEFAULT, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"units\")) {\n            if (leaf->units) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"name\");\n            leaf->units = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_UNITS, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"mandatory\")) {\n            if (f_mand) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in leaf is not sufficient, we would allow\n             * multiple mandatory statements with the \"false\" value\n             */\n            f_mand = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"true\")) {\n                leaf->flags |= LYS_MAND_TRUE;\n            } else if (!strcmp(value, \"false\")) {\n                leaf->flags |= LYS_MAND_FALSE;\n            } else {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }                   /* else false is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MANDATORY, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (leaf->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            leaf->when = read_yin_when(module, sub, unres);\n            if (!leaf->when) {\n                goto error;\n            }\n\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, leaf->must_size, \"musts\", \"leaf\", error);\n            c_must++;\n            continue;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"musts\", \"leaf\", error);\n            c_ftrs++;\n            continue;\n\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n\n        /* do not free sub, it could have been unlinked and stored in unres */\n    }\n\n    /* check mandatory parameters */\n    if (!has_type) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"type\", yin->name);\n        goto error;\n    }\n    if (leaf->dflt && (leaf->flags & LYS_MAND_TRUE)) {\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, retval, \"mandatory\", \"leaf\");\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n               \"The \\\"mandatory\\\" statement is forbidden on leaf with the \\\"default\\\" statement.\");\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n */\n    if (c_must) {\n        leaf->must = calloc(c_must, sizeof *leaf->must);\n        LY_CHECK_ERR_GOTO(!leaf->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        leaf->iffeature = calloc(c_ftrs, sizeof *leaf->iffeature);\n        LY_CHECK_ERR_GOTO(!leaf->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &leaf->must[leaf->must_size], unres);\n            leaf->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &leaf->iffeature[leaf->iffeature_size], unres);\n            leaf->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* finalize type parsing */\n    if (unres_schema_add_node(module, unres, &leaf->type, UNRES_TYPE_DER, retval) == -1) {\n        leaf->type.der = NULL;\n        goto error;\n    }\n\n    /* check default value (if not defined, there still could be some restrictions\n     * that need to be checked against a default value from a derived type) */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) &&\n            (unres_schema_add_node(module, unres, &leaf->type, UNRES_TYPE_DFLT,\n                                   (struct lys_node *)(&leaf->dflt)) == -1)) {\n        goto error;\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (leaf->when || leaf->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            break;\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -215,6 +215,6 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_list",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_list(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n              struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval, *node;\n    struct lys_node_list *list;\n    struct lyxml_elem *sub, *next, root, uniq;\n    int r;\n    int c_tpdf = 0, c_must = 0, c_uniq = 0, c_ftrs = 0, c_ext = 0;\n    int f_ordr = 0, f_max = 0, f_min = 0;\n    const char *value;\n    char *auxs;\n    unsigned long val;\n    void *reallocated;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n    memset(&uniq, 0, sizeof uniq);\n\n    list = calloc(1, sizeof *list);\n    LY_CHECK_ERR_RETURN(!list, LOGMEM(ctx), NULL);\n\n    list->nodetype = LYS_LIST;\n    list->prev = (struct lys_node *)list;\n    retval = (struct lys_node *)list;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process list's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"list\", error);\n            c_ext++;\n            continue;\n\n        /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\") ||\n                !strcmp(sub->name, \"action\") ||\n                !strcmp(sub->name, \"notification\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"key\")) {\n            /* check cardinality 0..1 */\n            if (list->keys_size) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, list->name);\n                goto error;\n            }\n\n            /* count the number of keys */\n            GETVAL(ctx, value, sub, \"value\");\n            list->keys_str = lydict_insert(ctx, value, 0);\n            while ((value = strpbrk(value, \" \\t\\n\"))) {\n                list->keys_size++;\n                while (isspace(*value)) {\n                    value++;\n                }\n            }\n            list->keys_size++;\n            list->keys = calloc(list->keys_size, sizeof *list->keys);\n            LY_CHECK_ERR_GOTO(!list->keys, LOGMEM(ctx), error);\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_KEY, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"unique\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_uniq, list->unique_size, \"uniques\", \"list\", error);\n            c_uniq++;\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &uniq, sub);\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, list->tpdf_size, \"typedefs\", \"list\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, list->must_size, \"musts\", \"list\", error);\n            c_must++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"list\", error);\n            c_ftrs++;\n\n            /* optional stetments */\n        } else if (!strcmp(sub->name, \"ordered-by\")) {\n            if (f_ordr) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in llist is not sufficient, we would\n             * allow multiple ordered-by statements with the \"system\" value\n             */\n            f_ordr = 1;\n\n            if (list->flags & LYS_CONFIG_R) {\n                /* RFC 6020, 7.7.5 - ignore ordering when the list represents\n                 * state data\n                 */\n                lyxml_free(ctx, sub);\n                continue;\n            }\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"user\")) {\n                list->flags |= LYS_USERORDERED;\n            } else if (strcmp(value, \"system\")) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            } /* else system is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_ORDEREDBY, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"min-elements\")) {\n            if (f_min) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_min = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            /* convert it to uint32_t */\n            errno = 0;\n            auxs = NULL;\n            val = strtoul(value, &auxs, 10);\n            if (*auxs || value[0] == '-' || errno || val > UINT32_MAX) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }\n            list->min = (uint32_t) val;\n            if (list->max && (list->min > list->max)) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MIN, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"max-elements\")) {\n            if (f_max) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_max = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            if (!strcmp(value, \"unbounded\")) {\n                list->max = 0;;\n            } else {\n                /* convert it to uint32_t */\n                errno = 0;\n                auxs = NULL;\n                val = strtoul(value, &auxs, 10);\n                if (*auxs || value[0] == '-' || errno || val == 0 || val > UINT32_MAX) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    goto error;\n                }\n                list->max = (uint32_t) val;\n                if (list->min > list->max) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"max-elements\\\" is smaller than \\\"min-elements\\\".\");\n                    goto error;\n                }\n            }\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MAX, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (list->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            list->when = read_yin_when(module, sub, unres);\n            if (!list->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* check - if list is configuration, key statement is mandatory\n     * (but only if we are not in a grouping or augment, then the check is deferred) */\n    for (node = retval; node && !(node->nodetype & (LYS_GROUPING | LYS_AUGMENT | LYS_EXT)); node = node->parent);\n    if (!node && (list->flags & LYS_CONFIG_W) && !list->keys_str) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"key\", \"list\");\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        list->tpdf = calloc(c_tpdf, sizeof *list->tpdf);\n        LY_CHECK_ERR_GOTO(!list->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        list->must = calloc(c_must, sizeof *list->must);\n        LY_CHECK_ERR_GOTO(!list->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        list->iffeature = calloc(c_ftrs, sizeof *list->iffeature);\n        LY_CHECK_ERR_GOTO(!list->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &list->tpdf[list->tpdf_size], unres);\n            list->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &list->iffeature[list->iffeature_size], unres);\n            list->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &list->must[list->must_size], unres);\n            list->must_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        } else if (!strcmp(sub->name, \"action\")) {\n            node = read_yin_rpc_action(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"notification\")) {\n            node = read_yin_notif(module, retval, sub, options, unres);\n        } else {\n            LOGINT(ctx);\n            goto error;\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    if (list->keys_str) {\n        if (unres_schema_add_node(module, unres, list, UNRES_LIST_KEYS, NULL) == -1) {\n            goto error;\n        }\n    } /* else config false list without a key, key_str presence in case of config true is checked earlier */\n\n    /* process unique statements */\n    if (c_uniq) {\n        list->unique = calloc(c_uniq, sizeof *list->unique);\n        LY_CHECK_ERR_GOTO(!list->unique, LOGMEM(ctx), error);\n\n        LY_TREE_FOR_SAFE(uniq.child, next, sub) {\n            r = fill_yin_unique(module, retval, sub, &list->unique[list->unique_size], unres);\n            list->unique_size++;\n            if (r) {\n                goto error;\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub,\n                                     LYEXT_SUBSTMT_UNIQUE, list->unique_size - 1, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        }\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (list->when || list->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            if (retval->ext[r]->flags & LYEXT_OPT_VALID_SUBTREE) {\n                retval->flags |= LYS_VALID_EXT_SUBTREE;\n                break;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n\n    lys_node_free(retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    while (uniq.child) {\n        lyxml_free(ctx, uniq.child);\n    }\n\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_list(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n              struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval, *node;\n    struct lys_node_list *list;\n    struct lyxml_elem *sub, *next, root, uniq;\n    int r;\n    int c_tpdf = 0, c_must = 0, c_uniq = 0, c_ftrs = 0, c_ext = 0;\n    int f_ordr = 0, f_max = 0, f_min = 0;\n    const char *value;\n    char *auxs;\n    unsigned long val;\n    void *reallocated;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n    memset(&uniq, 0, sizeof uniq);\n\n    list = calloc(1, sizeof *list);\n    LY_CHECK_ERR_RETURN(!list, LOGMEM(ctx), NULL);\n\n    list->nodetype = LYS_LIST;\n    list->prev = (struct lys_node *)list;\n    retval = (struct lys_node *)list;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process list's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"list\", error);\n            c_ext++;\n            continue;\n\n        /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\") ||\n                !strcmp(sub->name, \"action\") ||\n                !strcmp(sub->name, \"notification\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"key\")) {\n            /* check cardinality 0..1 */\n            if (list->keys_size) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, list->name);\n                goto error;\n            }\n\n            /* count the number of keys */\n            GETVAL(ctx, value, sub, \"value\");\n            list->keys_str = lydict_insert(ctx, value, 0);\n            while ((value = strpbrk(value, \" \\t\\n\"))) {\n                list->keys_size++;\n                while (isspace(*value)) {\n                    value++;\n                }\n            }\n            list->keys_size++;\n            list->keys = calloc(list->keys_size, sizeof *list->keys);\n            LY_CHECK_ERR_GOTO(!list->keys, LOGMEM(ctx), error);\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_KEY, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"unique\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_uniq, list->unique_size, \"uniques\", \"list\", error);\n            c_uniq++;\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &uniq, sub);\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, list->tpdf_size, \"typedefs\", \"list\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, list->must_size, \"musts\", \"list\", error);\n            c_must++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"list\", error);\n            c_ftrs++;\n\n            /* optional stetments */\n        } else if (!strcmp(sub->name, \"ordered-by\")) {\n            if (f_ordr) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in llist is not sufficient, we would\n             * allow multiple ordered-by statements with the \"system\" value\n             */\n            f_ordr = 1;\n\n            if (list->flags & LYS_CONFIG_R) {\n                /* RFC 6020, 7.7.5 - ignore ordering when the list represents\n                 * state data\n                 */\n                lyxml_free(ctx, sub);\n                continue;\n            }\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"user\")) {\n                list->flags |= LYS_USERORDERED;\n            } else if (strcmp(value, \"system\")) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            } /* else system is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_ORDEREDBY, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"min-elements\")) {\n            if (f_min) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_min = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            /* convert it to uint32_t */\n            errno = 0;\n            auxs = NULL;\n            val = strtoul(value, &auxs, 10);\n            if (*auxs || value[0] == '-' || errno || val > UINT32_MAX) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }\n            list->min = (uint32_t) val;\n            if (list->max && (list->min > list->max)) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MIN, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"max-elements\")) {\n            if (f_max) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_max = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            if (!strcmp(value, \"unbounded\")) {\n                list->max = 0;;\n            } else {\n                /* convert it to uint32_t */\n                errno = 0;\n                auxs = NULL;\n                val = strtoul(value, &auxs, 10);\n                if (*auxs || value[0] == '-' || errno || val == 0 || val > UINT32_MAX) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    goto error;\n                }\n                list->max = (uint32_t) val;\n                if (list->min > list->max) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"max-elements\\\" is smaller than \\\"min-elements\\\".\");\n                    goto error;\n                }\n            }\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MAX, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (list->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            list->when = read_yin_when(module, sub, unres);\n            if (!list->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* check - if list is configuration, key statement is mandatory\n     * (but only if we are not in a grouping or augment, then the check is deferred) */\n    for (node = retval; node && !(node->nodetype & (LYS_GROUPING | LYS_AUGMENT | LYS_EXT)); node = node->parent);\n    if (!node && (list->flags & LYS_CONFIG_W) && !list->keys_str) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"key\", \"list\");\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        list->tpdf = calloc(c_tpdf, sizeof *list->tpdf);\n        LY_CHECK_ERR_GOTO(!list->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        list->must = calloc(c_must, sizeof *list->must);\n        LY_CHECK_ERR_GOTO(!list->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        list->iffeature = calloc(c_ftrs, sizeof *list->iffeature);\n        LY_CHECK_ERR_GOTO(!list->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &list->tpdf[list->tpdf_size], unres);\n            list->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &list->iffeature[list->iffeature_size], unres);\n            list->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &list->must[list->must_size], unres);\n            list->must_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        } else if (!strcmp(sub->name, \"action\")) {\n            node = read_yin_rpc_action(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"notification\")) {\n            node = read_yin_notif(module, retval, sub, options, unres);\n        } else {\n            LOGINT(ctx);\n            goto error;\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    if (list->keys_str) {\n        if (unres_schema_add_node(module, unres, list, UNRES_LIST_KEYS, NULL) == -1) {\n            goto error;\n        }\n    } /* else config false list without a key, key_str presence in case of config true is checked earlier */\n\n    /* process unique statements */\n    if (c_uniq) {\n        list->unique = calloc(c_uniq, sizeof *list->unique);\n        LY_CHECK_ERR_GOTO(!list->unique, LOGMEM(ctx), error);\n\n        LY_TREE_FOR_SAFE(uniq.child, next, sub) {\n            r = fill_yin_unique(module, retval, sub, &list->unique[list->unique_size], unres);\n            list->unique_size++;\n            if (r) {\n                goto error;\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub,\n                                     LYEXT_SUBSTMT_UNIQUE, list->unique_size - 1, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        }\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (list->when || list->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            if (retval->ext[r]->flags & LYEXT_OPT_VALID_SUBTREE) {\n                retval->flags |= LYS_VALID_EXT_SUBTREE;\n                break;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n\n    lys_node_free(ctx, retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    while (uniq.child) {\n        lyxml_free(ctx, uniq.child);\n    }\n\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -366,7 +366,7 @@\n \n error:\n \n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     while (root.child) {\n         lyxml_free(ctx, root.child);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_leaflist",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_leaflist(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                  struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval;\n    struct lys_node_leaflist *llist;\n    struct lyxml_elem *sub, *next;\n    const char *value;\n    char *endptr;\n    unsigned long val;\n    int r, has_type = 0;\n    int c_must = 0, c_ftrs = 0, c_dflt = 0, c_ext = 0;\n    int f_ordr = 0, f_min = 0, f_max = 0;\n    void *reallocated;\n\n    llist = calloc(1, sizeof *llist);\n    LY_CHECK_ERR_RETURN(!llist, LOGMEM(ctx), NULL);\n\n    llist->nodetype = LYS_LEAFLIST;\n    llist->prev = (struct lys_node *)llist;\n    retval = (struct lys_node *)llist;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"leaf-list\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"type\")) {\n            if (has_type) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* HACK for unres */\n            llist->type.der = (struct lys_tpdf *)sub;\n            llist->type.parent = (struct lys_tpdf *)llist;\n            /* postpone type resolution when if-feature parsing is done since we need\n             * if-feature for check_leafref_features() */\n            has_type = 1;\n        } else if (!strcmp(sub->name, \"units\")) {\n            if (llist->units) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"name\");\n            llist->units = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_UNITS, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"ordered-by\")) {\n            if (f_ordr) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in llist is not sufficient, we would\n             * allow multiple ordered-by statements with the \"system\" value\n             */\n            f_ordr = 1;\n\n            if (llist->flags & LYS_CONFIG_R) {\n                /* RFC 6020, 7.7.5 - ignore ordering when the list represents\n                 * state data\n                 */\n                lyxml_free(ctx, sub);\n                continue;\n            }\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"user\")) {\n                llist->flags |= LYS_USERORDERED;\n            } else if (strcmp(value, \"system\")) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            } /* else system is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_ORDEREDBY, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, llist->must_size, \"musts\", \"leaf-list\", error);\n            c_must++;\n            continue;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"leaf-list\", error);\n            c_ftrs++;\n            continue;\n        } else if ((module->version >= 2) && !strcmp(sub->name, \"default\")) {\n            /* read the default's extension instances */\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_DEFAULT, c_dflt, unres)) {\n                goto error;\n            }\n\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_dflt, llist->dflt_size, \"defaults\", \"leaf-list\", error);\n            c_dflt++;\n            continue;\n\n        } else if (!strcmp(sub->name, \"min-elements\")) {\n            if (f_min) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_min = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            /* convert it to uint32_t */\n            errno = 0;\n            endptr = NULL;\n            val = strtoul(value, &endptr, 10);\n            if (*endptr || value[0] == '-' || errno || val > UINT32_MAX) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }\n            llist->min = (uint32_t) val;\n            if (llist->max && (llist->min > llist->max)) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                goto error;\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MIN, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"max-elements\")) {\n            if (f_max) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_max = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            if (!strcmp(value, \"unbounded\")) {\n                llist->max = 0;\n            } else {\n                /* convert it to uint32_t */\n                errno = 0;\n                endptr = NULL;\n                val = strtoul(value, &endptr, 10);\n                if (*endptr || value[0] == '-' || errno || val == 0 || val > UINT32_MAX) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    goto error;\n                }\n                llist->max = (uint32_t) val;\n                if (llist->min > llist->max) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"max-elements\\\" is smaller than \\\"min-elements\\\".\");\n                    goto error;\n                }\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MAX, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (llist->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            llist->when = read_yin_when(module, sub, unres);\n            if (!llist->when) {\n                goto error;\n            }\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n\n        /* do not free sub, it could have been unlinked and stored in unres */\n    }\n\n    /* check constraints */\n    if (!has_type) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"type\", yin->name);\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n */\n    if (c_must) {\n        llist->must = calloc(c_must, sizeof *llist->must);\n        LY_CHECK_ERR_GOTO(!llist->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        llist->iffeature = calloc(c_ftrs, sizeof *llist->iffeature);\n        LY_CHECK_ERR_GOTO(!llist->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_dflt) {\n        llist->dflt = calloc(c_dflt, sizeof *llist->dflt);\n        LY_CHECK_ERR_GOTO(!llist->dflt, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &llist->must[llist->must_size], unres);\n            llist->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &llist->iffeature[llist->iffeature_size], unres);\n            llist->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"default\")) {\n            GETVAL(ctx, value, sub, \"value\");\n\n            /* check for duplicity in case of configuration data,\n             * in case of status data duplicities are allowed */\n            if (llist->flags & LYS_CONFIG_W) {\n                for (r = 0; r < llist->dflt_size; r++) {\n                    if (ly_strequal(llist->dflt[r], value, 1)) {\n                        LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, \"default\");\n                        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"Duplicated default value \\\"%s\\\".\", value);\n                        goto error;\n                    }\n                }\n            }\n            llist->dflt[llist->dflt_size++] = lydict_insert(ctx, value, strlen(value));\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* finalize type parsing */\n    if (unres_schema_add_node(module, unres, &llist->type, UNRES_TYPE_DER, retval) == -1) {\n        llist->type.der = NULL;\n        goto error;\n    }\n\n    if (llist->dflt_size && llist->min) {\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, retval, \"min-elements\", \"leaf-list\");\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n               \"The \\\"min-elements\\\" statement with non-zero value is forbidden on leaf-lists with the \\\"default\\\" statement.\");\n        goto error;\n    }\n\n    /* check default value (if not defined, there still could be some restrictions\n     * that need to be checked against a default value from a derived type) */\n    for (r = 0; r < llist->dflt_size; r++) {\n        if (!(ctx->models.flags & LY_CTX_TRUSTED) &&\n                (unres_schema_add_node(module, unres, &llist->type, UNRES_TYPE_DFLT,\n                                       (struct lys_node *)(&llist->dflt[r])) == -1)) {\n            goto error;\n        }\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (llist->when || llist->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            break;\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_leaflist(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                  struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lys_node *retval;\n    struct lys_node_leaflist *llist;\n    struct lyxml_elem *sub, *next;\n    const char *value;\n    char *endptr;\n    unsigned long val;\n    int r, has_type = 0;\n    int c_must = 0, c_ftrs = 0, c_dflt = 0, c_ext = 0;\n    int f_ordr = 0, f_min = 0, f_max = 0;\n    void *reallocated;\n\n    llist = calloc(1, sizeof *llist);\n    LY_CHECK_ERR_RETURN(!llist, LOGMEM(ctx), NULL);\n\n    llist->nodetype = LYS_LEAFLIST;\n    llist->prev = (struct lys_node *)llist;\n    retval = (struct lys_node *)llist;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"leaf-list\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"type\")) {\n            if (has_type) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* HACK for unres */\n            llist->type.der = (struct lys_tpdf *)sub;\n            llist->type.parent = (struct lys_tpdf *)llist;\n            /* postpone type resolution when if-feature parsing is done since we need\n             * if-feature for check_leafref_features() */\n            has_type = 1;\n        } else if (!strcmp(sub->name, \"units\")) {\n            if (llist->units) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"name\");\n            llist->units = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_UNITS, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"ordered-by\")) {\n            if (f_ordr) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            /* just checking the flags in llist is not sufficient, we would\n             * allow multiple ordered-by statements with the \"system\" value\n             */\n            f_ordr = 1;\n\n            if (llist->flags & LYS_CONFIG_R) {\n                /* RFC 6020, 7.7.5 - ignore ordering when the list represents\n                 * state data\n                 */\n                lyxml_free(ctx, sub);\n                continue;\n            }\n\n            GETVAL(ctx, value, sub, \"value\");\n            if (!strcmp(value, \"user\")) {\n                llist->flags |= LYS_USERORDERED;\n            } else if (strcmp(value, \"system\")) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            } /* else system is the default value, so we can ignore it */\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_ORDEREDBY, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, llist->must_size, \"musts\", \"leaf-list\", error);\n            c_must++;\n            continue;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"leaf-list\", error);\n            c_ftrs++;\n            continue;\n        } else if ((module->version >= 2) && !strcmp(sub->name, \"default\")) {\n            /* read the default's extension instances */\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_DEFAULT, c_dflt, unres)) {\n                goto error;\n            }\n\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_dflt, llist->dflt_size, \"defaults\", \"leaf-list\", error);\n            c_dflt++;\n            continue;\n\n        } else if (!strcmp(sub->name, \"min-elements\")) {\n            if (f_min) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_min = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            /* convert it to uint32_t */\n            errno = 0;\n            endptr = NULL;\n            val = strtoul(value, &endptr, 10);\n            if (*endptr || value[0] == '-' || errno || val > UINT32_MAX) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                goto error;\n            }\n            llist->min = (uint32_t) val;\n            if (llist->max && (llist->min > llist->max)) {\n                LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"min-elements\\\" is bigger than \\\"max-elements\\\".\");\n                goto error;\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MIN, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"max-elements\")) {\n            if (f_max) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            f_max = 1;\n\n            GETVAL(ctx, value, sub, \"value\");\n            while (isspace(value[0])) {\n                value++;\n            }\n\n            if (!strcmp(value, \"unbounded\")) {\n                llist->max = 0;\n            } else {\n                /* convert it to uint32_t */\n                errno = 0;\n                endptr = NULL;\n                val = strtoul(value, &endptr, 10);\n                if (*endptr || value[0] == '-' || errno || val == 0 || val > UINT32_MAX) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    goto error;\n                }\n                llist->max = (uint32_t) val;\n                if (llist->min > llist->max) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, sub->name);\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"\\\"max-elements\\\" is smaller than \\\"min-elements\\\".\");\n                    goto error;\n                }\n            }\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_MAX, 0, unres)) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (llist->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            llist->when = read_yin_when(module, sub, unres);\n            if (!llist->when) {\n                goto error;\n            }\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n\n        /* do not free sub, it could have been unlinked and stored in unres */\n    }\n\n    /* check constraints */\n    if (!has_type) {\n        LOGVAL(ctx, LYE_MISSCHILDSTMT, LY_VLOG_LYS, retval, \"type\", yin->name);\n        goto error;\n    }\n\n    /* middle part - process nodes with cardinality of 0..n */\n    if (c_must) {\n        llist->must = calloc(c_must, sizeof *llist->must);\n        LY_CHECK_ERR_GOTO(!llist->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        llist->iffeature = calloc(c_ftrs, sizeof *llist->iffeature);\n        LY_CHECK_ERR_GOTO(!llist->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_dflt) {\n        llist->dflt = calloc(c_dflt, sizeof *llist->dflt);\n        LY_CHECK_ERR_GOTO(!llist->dflt, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &llist->must[llist->must_size], unres);\n            llist->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &llist->iffeature[llist->iffeature_size], unres);\n            llist->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"default\")) {\n            GETVAL(ctx, value, sub, \"value\");\n\n            /* check for duplicity in case of configuration data,\n             * in case of status data duplicities are allowed */\n            if (llist->flags & LYS_CONFIG_W) {\n                for (r = 0; r < llist->dflt_size; r++) {\n                    if (ly_strequal(llist->dflt[r], value, 1)) {\n                        LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, value, \"default\");\n                        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"Duplicated default value \\\"%s\\\".\", value);\n                        goto error;\n                    }\n                }\n            }\n            llist->dflt[llist->dflt_size++] = lydict_insert(ctx, value, strlen(value));\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* finalize type parsing */\n    if (unres_schema_add_node(module, unres, &llist->type, UNRES_TYPE_DER, retval) == -1) {\n        llist->type.der = NULL;\n        goto error;\n    }\n\n    if (llist->dflt_size && llist->min) {\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, retval, \"min-elements\", \"leaf-list\");\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL,\n               \"The \\\"min-elements\\\" statement with non-zero value is forbidden on leaf-lists with the \\\"default\\\" statement.\");\n        goto error;\n    }\n\n    /* check default value (if not defined, there still could be some restrictions\n     * that need to be checked against a default value from a derived type) */\n    for (r = 0; r < llist->dflt_size; r++) {\n        if (!(ctx->models.flags & LY_CTX_TRUSTED) &&\n                (unres_schema_add_node(module, unres, &llist->type, UNRES_TYPE_DFLT,\n                                       (struct lys_node *)(&llist->dflt[r])) == -1)) {\n            goto error;\n        }\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (llist->when || llist->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            break;\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -307,6 +307,6 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_case",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_case(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n              struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node_case *cs;\n    struct lys_node *retval, *node = NULL;\n    int c_ftrs = 0, c_ext = 0, ret;\n    void *reallocated;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    cs = calloc(1, sizeof *cs);\n    LY_CHECK_ERR_RETURN(!cs, LOGMEM(ctx), NULL);\n    cs->nodetype = LYS_CASE;\n    cs->prev = (struct lys_node *)cs;\n    retval = (struct lys_node *)cs;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | (!(options & LYS_PARSE_OPT_CFG_MASK) ? OPT_CFG_INHERIT : 0), unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process choice's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"case\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\")) {\n\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"case\", error);\n            c_ftrs++;\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (cs->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            cs->when = read_yin_when(module, sub, unres);\n            if (!cs->when) {\n                goto error;\n            }\n\n            lyxml_free(ctx, sub);\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    if (c_ftrs) {\n        cs->iffeature = calloc(c_ftrs, sizeof *cs->iffeature);\n        LY_CHECK_ERR_GOTO(!cs->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            ret = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (ret) {\n                goto error;\n            }\n        } else {\n            /* if-feature */\n            ret = fill_yin_iffeature(retval, 0, sub, &cs->iffeature[cs->iffeature_size], unres);\n            cs->iffeature_size++;\n            if (ret) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && cs->when) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    lys_node_free(retval, NULL, 0);\n\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_case(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n              struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node_case *cs;\n    struct lys_node *retval, *node = NULL;\n    int c_ftrs = 0, c_ext = 0, ret;\n    void *reallocated;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    cs = calloc(1, sizeof *cs);\n    LY_CHECK_ERR_RETURN(!cs, LOGMEM(ctx), NULL);\n    cs->nodetype = LYS_CASE;\n    cs->prev = (struct lys_node *)cs;\n    retval = (struct lys_node *)cs;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | (!(options & LYS_PARSE_OPT_CFG_MASK) ? OPT_CFG_INHERIT : 0), unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process choice's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"case\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\")) {\n\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"case\", error);\n            c_ftrs++;\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (cs->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            cs->when = read_yin_when(module, sub, unres);\n            if (!cs->when) {\n                goto error;\n            }\n\n            lyxml_free(ctx, sub);\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    if (c_ftrs) {\n        cs->iffeature = calloc(c_ftrs, sizeof *cs->iffeature);\n        LY_CHECK_ERR_GOTO(!cs->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            ret = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (ret) {\n                goto error;\n            }\n        } else {\n            /* if-feature */\n            ret = fill_yin_iffeature(retval, 0, sub, &cs->iffeature[cs->iffeature_size], unres);\n            cs->iffeature_size++;\n            if (ret) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && cs->when) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    lys_node_free(ctx, retval, NULL, 0);\n\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -146,7 +146,7 @@\n     while (root.child) {\n         lyxml_free(ctx, root.child);\n     }\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n \n     return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_container",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_container(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                   struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_container *cont;\n    const char *value;\n    void *reallocated;\n    int r;\n    int c_tpdf = 0, c_must = 0, c_ftrs = 0, c_ext = 0;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    cont = calloc(1, sizeof *cont);\n    LY_CHECK_ERR_RETURN(!cont, LOGMEM(ctx), NULL);\n\n    cont->nodetype = LYS_CONTAINER;\n    cont->prev = (struct lys_node *)cont;\n    retval = (struct lys_node *)cont;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process container's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"container\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"presence\")) {\n            if (cont->presence) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"value\");\n            cont->presence = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_PRESENCE, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (cont->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            cont->when = read_yin_when(module, sub, unres);\n            if (!cont->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n\n            /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\") ||\n                !strcmp(sub->name, \"action\") ||\n                !strcmp(sub->name, \"notification\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, cont->tpdf_size, \"typedefs\", \"container\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, cont->must_size, \"musts\", \"container\", error);\n            c_must++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"container\", error);\n            c_ftrs++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        cont->tpdf = calloc(c_tpdf, sizeof *cont->tpdf);\n        LY_CHECK_ERR_GOTO(!cont->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        cont->must = calloc(c_must, sizeof *cont->must);\n        LY_CHECK_ERR_GOTO(!cont->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        cont->iffeature = calloc(c_ftrs, sizeof *cont->iffeature);\n        LY_CHECK_ERR_GOTO(!cont->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &cont->tpdf[cont->tpdf_size], unres);\n            cont->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &cont->must[cont->must_size], unres);\n            cont->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &cont->iffeature[cont->iffeature_size], unres);\n            cont->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        } else if (!strcmp(sub->name, \"action\")) {\n            node = read_yin_rpc_action(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"notification\")) {\n            node = read_yin_notif(module, retval, sub, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (cont->when || cont->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            if (retval->ext[r]->flags & LYEXT_OPT_VALID_SUBTREE) {\n                retval->flags |= LYS_VALID_EXT_SUBTREE;\n                break;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_container(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin, int options,\n                   struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_container *cont;\n    const char *value;\n    void *reallocated;\n    int r;\n    int c_tpdf = 0, c_must = 0, c_ftrs = 0, c_ext = 0;\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    cont = calloc(1, sizeof *cont);\n    LY_CHECK_ERR_RETURN(!cont, LOGMEM(ctx), NULL);\n\n    cont->nodetype = LYS_CONTAINER;\n    cont->prev = (struct lys_node *)cont;\n    retval = (struct lys_node *)cont;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin,\n            OPT_IDENT | OPT_MODULE | ((options & LYS_PARSE_OPT_CFG_IGNORE) ? OPT_CFG_IGNORE :\n                (options & LYS_PARSE_OPT_CFG_NOINHERIT) ? OPT_CFG_PARSE : OPT_CFG_PARSE | OPT_CFG_INHERIT),\n            unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process container's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\", \"container\", error);\n            c_ext++;\n        } else if (!strcmp(sub->name, \"presence\")) {\n            if (cont->presence) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            GETVAL(ctx, value, sub, \"value\");\n            cont->presence = lydict_insert(ctx, value, strlen(value));\n\n            if (lyp_yin_parse_subnode_ext(module, retval, LYEXT_PAR_NODE, sub, LYEXT_SUBSTMT_PRESENCE, 0, unres)) {\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n        } else if (!strcmp(sub->name, \"when\")) {\n            if (cont->when) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n\n            cont->when = read_yin_when(module, sub, unres);\n            if (!cont->when) {\n                lyxml_free(ctx, sub);\n                goto error;\n            }\n            lyxml_free(ctx, sub);\n\n            /* data statements */\n        } else if (!strcmp(sub->name, \"container\") ||\n                !strcmp(sub->name, \"leaf-list\") ||\n                !strcmp(sub->name, \"leaf\") ||\n                !strcmp(sub->name, \"list\") ||\n                !strcmp(sub->name, \"choice\") ||\n                !strcmp(sub->name, \"uses\") ||\n                !strcmp(sub->name, \"grouping\") ||\n                !strcmp(sub->name, \"anyxml\") ||\n                !strcmp(sub->name, \"anydata\") ||\n                !strcmp(sub->name, \"action\") ||\n                !strcmp(sub->name, \"notification\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, cont->tpdf_size, \"typedefs\", \"container\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"must\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_must, cont->must_size, \"musts\", \"container\", error);\n            c_must++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\", \"container\", error);\n            c_ftrs++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        cont->tpdf = calloc(c_tpdf, sizeof *cont->tpdf);\n        LY_CHECK_ERR_GOTO(!cont->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_must) {\n        cont->must = calloc(c_must, sizeof *cont->must);\n        LY_CHECK_ERR_GOTO(!cont->must, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        cont->iffeature = calloc(c_ftrs, sizeof *cont->iffeature);\n        LY_CHECK_ERR_GOTO(!cont->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &cont->tpdf[cont->tpdf_size], unres);\n            cont->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"must\")) {\n            r = fill_yin_must(module, sub, &cont->must[cont->must_size], unres);\n            cont->must_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &cont->iffeature[cont->iffeature_size], unres);\n            cont->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"container\")) {\n            node = read_yin_container(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf-list\")) {\n            node = read_yin_leaflist(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"leaf\")) {\n            node = read_yin_leaf(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"list\")) {\n            node = read_yin_list(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"choice\")) {\n            node = read_yin_choice(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"uses\")) {\n            node = read_yin_uses(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"anyxml\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYXML, options, unres);\n        } else if (!strcmp(sub->name, \"anydata\")) {\n            node = read_yin_anydata(module, retval, sub, LYS_ANYDATA, options, unres);\n        } else if (!strcmp(sub->name, \"action\")) {\n            node = read_yin_rpc_action(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"notification\")) {\n            node = read_yin_notif(module, retval, sub, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    /* check XPath dependencies */\n    if (!(ctx->models.flags & LY_CTX_TRUSTED) && (cont->when || cont->must)) {\n        if (options & LYS_PARSE_OPT_INGRP) {\n            if (lyxp_node_check_syntax(retval)) {\n                goto error;\n            }\n        } else {\n            if (unres_schema_add_node(module, unres, retval, UNRES_XPATH, NULL) == -1) {\n                goto error;\n            }\n        }\n    }\n\n    for (r = 0; r < retval->ext_size; ++r) {\n        /* set flag, which represent LYEXT_OPT_VALID */\n        if (retval->ext[r]->flags & LYEXT_OPT_VALID) {\n            retval->flags |= LYS_VALID_EXT;\n            if (retval->ext[r]->flags & LYEXT_OPT_VALID_SUBTREE) {\n                retval->flags |= LYS_VALID_EXT_SUBTREE;\n                break;\n            }\n        }\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -210,7 +210,7 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     while (root.child) {\n         lyxml_free(ctx, root.child);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/read_yin_rpc_action",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nread_yin_rpc_action(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n                    int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_rpc_action *rpc;\n    int r;\n    int c_tpdf = 0, c_ftrs = 0, c_input = 0, c_output = 0, c_ext = 0;\n    void *reallocated;\n\n    if (!strcmp(yin->name, \"action\") && (module->version < 2)) {\n        LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, parent, \"action\");\n        return NULL;\n    }\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    rpc = calloc(1, sizeof *rpc);\n    LY_CHECK_ERR_RETURN(!rpc, LOGMEM(ctx), NULL);\n\n    rpc->nodetype = (!strcmp(yin->name, \"rpc\") ? LYS_RPC : LYS_ACTION);\n    rpc->prev = (struct lys_node *)rpc;\n    retval = (struct lys_node *)rpc;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_IDENT | OPT_MODULE, unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process rpc's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\",\n                                          rpc->nodetype == LYS_RPC ? \"rpc\" : \"action\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"input\")) {\n            if (c_input) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            c_input++;\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n        } else if (!strcmp(sub->name, \"output\")) {\n            if (c_output) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            c_output++;\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* data statements */\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, rpc->tpdf_size, \"typedefs\",\n                                          rpc->nodetype == LYS_RPC ? \"rpc\" : \"action\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\",\n                                          rpc->nodetype == LYS_RPC ? \"rpc\" : \"action\", error);\n            c_ftrs++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        rpc->tpdf = calloc(c_tpdf, sizeof *rpc->tpdf);\n        LY_CHECK_ERR_GOTO(!rpc->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        rpc->iffeature = calloc(c_ftrs, sizeof *rpc->iffeature);\n        LY_CHECK_ERR_GOTO(!rpc->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &rpc->tpdf[rpc->tpdf_size], unres);\n            rpc->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &rpc->iffeature[rpc->iffeature_size], unres);\n            rpc->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"input\") || !strcmp(sub->name, \"output\")) {\n            node = read_yin_input_output(module, retval, sub, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "func": "static struct lys_node *\nread_yin_rpc_action(struct lys_module *module, struct lys_node *parent, struct lyxml_elem *yin,\n                    int options, struct unres_schema *unres)\n{\n    struct ly_ctx *ctx = module->ctx;\n    struct lyxml_elem *sub, *next, root;\n    struct lys_node *node = NULL;\n    struct lys_node *retval;\n    struct lys_node_rpc_action *rpc;\n    int r;\n    int c_tpdf = 0, c_ftrs = 0, c_input = 0, c_output = 0, c_ext = 0;\n    void *reallocated;\n\n    if (!strcmp(yin->name, \"action\") && (module->version < 2)) {\n        LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, parent, \"action\");\n        return NULL;\n    }\n\n    /* init */\n    memset(&root, 0, sizeof root);\n\n    rpc = calloc(1, sizeof *rpc);\n    LY_CHECK_ERR_RETURN(!rpc, LOGMEM(ctx), NULL);\n\n    rpc->nodetype = (!strcmp(yin->name, \"rpc\") ? LYS_RPC : LYS_ACTION);\n    rpc->prev = (struct lys_node *)rpc;\n    retval = (struct lys_node *)rpc;\n\n    if (read_yin_common(module, parent, retval, LYEXT_PAR_NODE, yin, OPT_IDENT | OPT_MODULE, unres)) {\n        goto error;\n    }\n\n    LOGDBG(LY_LDGYIN, \"parsing %s statement \\\"%s\\\"\", yin->name, retval->name);\n\n    /* insert the node into the schema tree */\n    if (lys_node_addchild(parent, lys_main_module(module), retval, options)) {\n        goto error;\n    }\n\n    /* process rpc's specific children */\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ext, retval->ext_size, \"extensions\",\n                                          rpc->nodetype == LYS_RPC ? \"rpc\" : \"action\", error);\n            c_ext++;\n            continue;\n        } else if (!strcmp(sub->name, \"input\")) {\n            if (c_input) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            c_input++;\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n        } else if (!strcmp(sub->name, \"output\")) {\n            if (c_output) {\n                LOGVAL(ctx, LYE_TOOMANY, LY_VLOG_LYS, retval, sub->name, yin->name);\n                goto error;\n            }\n            c_output++;\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* data statements */\n        } else if (!strcmp(sub->name, \"grouping\")) {\n            lyxml_unlink_elem(ctx, sub, 2);\n            lyxml_add_child(ctx, &root, sub);\n\n            /* array counters */\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_tpdf, rpc->tpdf_size, \"typedefs\",\n                                          rpc->nodetype == LYS_RPC ? \"rpc\" : \"action\", error);\n            c_tpdf++;\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            YIN_CHECK_ARRAY_OVERFLOW_GOTO(ctx, c_ftrs, retval->iffeature_size, \"if-features\",\n                                          rpc->nodetype == LYS_RPC ? \"rpc\" : \"action\", error);\n            c_ftrs++;\n        } else {\n            LOGVAL(ctx, LYE_INSTMT, LY_VLOG_LYS, retval, sub->name);\n            goto error;\n        }\n    }\n\n    /* middle part - process nodes with cardinality of 0..n except the data nodes */\n    if (c_tpdf) {\n        rpc->tpdf = calloc(c_tpdf, sizeof *rpc->tpdf);\n        LY_CHECK_ERR_GOTO(!rpc->tpdf, LOGMEM(ctx), error);\n    }\n    if (c_ftrs) {\n        rpc->iffeature = calloc(c_ftrs, sizeof *rpc->iffeature);\n        LY_CHECK_ERR_GOTO(!rpc->iffeature, LOGMEM(ctx), error);\n    }\n    if (c_ext) {\n        /* some extensions may be already present from the substatements */\n        reallocated = realloc(retval->ext, (c_ext + retval->ext_size) * sizeof *retval->ext);\n        LY_CHECK_ERR_GOTO(!reallocated, LOGMEM(ctx), error);\n        retval->ext = reallocated;\n\n        /* init memory */\n        memset(&retval->ext[retval->ext_size], 0, c_ext * sizeof *retval->ext);\n    }\n\n    LY_TREE_FOR_SAFE(yin->child, next, sub) {\n        if (strcmp(sub->ns->value, LY_NSYIN)) {\n            /* extension */\n            r = lyp_yin_fill_ext(retval, LYEXT_PAR_NODE, 0, 0, module, sub, &retval->ext, &retval->ext_size, unres);\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"typedef\")) {\n            r = fill_yin_typedef(module, retval, sub, &rpc->tpdf[rpc->tpdf_size], unres);\n            rpc->tpdf_size++;\n            if (r) {\n                goto error;\n            }\n        } else if (!strcmp(sub->name, \"if-feature\")) {\n            r = fill_yin_iffeature(retval, 0, sub, &rpc->iffeature[rpc->iffeature_size], unres);\n            rpc->iffeature_size++;\n            if (r) {\n                goto error;\n            }\n        }\n    }\n\n    lyp_reduce_ext_list(&retval->ext, retval->ext_size, c_ext + retval->ext_size);\n\n    /* last part - process data nodes */\n    LY_TREE_FOR_SAFE(root.child, next, sub) {\n        if (!strcmp(sub->name, \"grouping\")) {\n            node = read_yin_grouping(module, retval, sub, options, unres);\n        } else if (!strcmp(sub->name, \"input\") || !strcmp(sub->name, \"output\")) {\n            node = read_yin_input_output(module, retval, sub, options, unres);\n        }\n        if (!node) {\n            goto error;\n        }\n\n        lyxml_free(ctx, sub);\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    while (root.child) {\n        lyxml_free(ctx, root.child);\n    }\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -142,7 +142,7 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     while (root.child) {\n         lyxml_free(ctx, root.child);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/lys_node_addchild",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "int\nlys_node_addchild(struct lys_node *parent, struct lys_module *module, struct lys_node *child, int options)\n{\n    struct ly_ctx *ctx = child->module->ctx;\n    struct lys_node *iter, **pchild, *log_parent;\n    struct lys_node_inout *in, *out;\n    struct lys_node_case *c;\n    struct lys_node_augment *aug;\n    int type, shortcase = 0;\n    void *p;\n    struct lyext_substmt *info = NULL;\n\n    assert(child);\n\n    if (parent) {\n        type = parent->nodetype;\n        module = parent->module;\n        log_parent = parent;\n\n        if (type == LYS_USES) {\n            /* we are adding children to uses -> we must be copying grouping contents into it, so properly check the parent */\n            while (log_parent && (log_parent->nodetype == LYS_USES)) {\n                if (log_parent->nodetype == LYS_AUGMENT) {\n                    aug = (struct lys_node_augment *)log_parent;\n                    if (!aug->target) {\n                        /* unresolved augment, just pass the node type check */\n                        goto skip_nodetype_check;\n                    }\n                    log_parent = aug->target;\n                } else {\n                    log_parent = log_parent->parent;\n                }\n            }\n            if (log_parent) {\n                type = log_parent->nodetype;\n            } else {\n                type = 0;\n            }\n        }\n    } else {\n        assert(module);\n        assert(!(child->nodetype & (LYS_INPUT | LYS_OUTPUT)));\n        type = 0;\n        log_parent = NULL;\n    }\n\n    /* checks */\n    switch (type) {\n    case LYS_CONTAINER:\n    case LYS_LIST:\n    case LYS_GROUPING:\n    case LYS_USES:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_GROUPING | LYS_LEAF |\n                 LYS_LEAFLIST | LYS_LIST | LYS_USES | LYS_ACTION | LYS_NOTIF))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n    case LYS_NOTIF:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_GROUPING | LYS_LEAF |\n                 LYS_LEAFLIST | LYS_LIST | LYS_USES))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_CHOICE:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CASE | LYS_CONTAINER | LYS_LEAF | LYS_LEAFLIST | LYS_LIST | LYS_CHOICE))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"choice\");\n            return EXIT_FAILURE;\n        }\n        if (child->nodetype != LYS_CASE) {\n            shortcase = 1;\n        }\n        break;\n    case LYS_CASE:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_LEAF | LYS_LEAFLIST | LYS_LIST | LYS_USES))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"case\");\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_RPC:\n    case LYS_ACTION:\n        if (!(child->nodetype & (LYS_INPUT | LYS_OUTPUT | LYS_GROUPING))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"rpc\");\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_LEAF:\n    case LYS_LEAFLIST:\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"The \\\"%s\\\" statement cannot have any data substatement.\",\n               strnodetype(log_parent->nodetype));\n        return EXIT_FAILURE;\n    case LYS_AUGMENT:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CASE | LYS_CHOICE | LYS_CONTAINER | LYS_LEAF\n                | LYS_LEAFLIST | LYS_LIST | LYS_USES | LYS_ACTION | LYS_NOTIF))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_UNKNOWN:\n        /* top level */\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_LEAF | LYS_GROUPING\n                | LYS_LEAFLIST | LYS_LIST | LYS_USES | LYS_RPC | LYS_NOTIF | LYS_AUGMENT))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"(sub)module\");\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_EXT:\n        /* plugin-defined */\n        p = lys_ext_complex_get_substmt(lys_snode2stmt(child->nodetype), (struct lys_ext_instance_complex*)log_parent, &info);\n        if (!p) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype),\n                   ((struct lys_ext_instance_complex*)log_parent)->def->name);\n            return EXIT_FAILURE;\n        }\n        /* TODO check cardinality */\n        break;\n    }\n\nskip_nodetype_check:\n    /* check identifier uniqueness */\n    if (!(module->ctx->models.flags & LY_CTX_TRUSTED) && lys_check_id(child, parent, module)) {\n        return EXIT_FAILURE;\n    }\n\n    if (child->parent) {\n        lys_node_unlink(child);\n    }\n\n    if ((child->nodetype & (LYS_INPUT | LYS_OUTPUT)) && parent->nodetype != LYS_EXT) {\n        /* find the implicit input/output node */\n        LY_TREE_FOR(parent->child, iter) {\n            if (iter->nodetype == child->nodetype) {\n                break;\n            }\n        }\n        assert(iter);\n\n        /* switch the old implicit node (iter) with the new one (child) */\n        if (parent->child == iter) {\n            /* first child */\n            parent->child = child;\n        } else {\n            iter->prev->next = child;\n        }\n        child->prev = iter->prev;\n        child->next = iter->next;\n        if (iter->next) {\n            iter->next->prev = child;\n        } else {\n            /* last child */\n            parent->child->prev = child;\n        }\n        child->parent = parent;\n\n        /* isolate the node and free it */\n        iter->next = NULL;\n        iter->prev = iter;\n        iter->parent = NULL;\n        lys_node_free(iter, NULL, 0);\n    } else {\n        if (shortcase) {\n            /* create the implicit case to allow it to serve as a target of the augments,\n             * it won't be printed, but it will be present in the tree */\n            c = calloc(1, sizeof *c);\n            LY_CHECK_ERR_RETURN(!c, LOGMEM(ctx), EXIT_FAILURE);\n            c->name = lydict_insert(module->ctx, child->name, 0);\n            c->flags = LYS_IMPLICIT;\n            if (!(options & (LYS_PARSE_OPT_CFG_IGNORE | LYS_PARSE_OPT_CFG_NOINHERIT))) {\n                /* get config flag from parent */\n                c->flags |= parent->flags & LYS_CONFIG_MASK;\n            }\n            c->module = module;\n            c->nodetype = LYS_CASE;\n            c->prev = (struct lys_node*)c;\n            lys_node_addchild(parent, module, (struct lys_node*)c, options);\n            parent = (struct lys_node*)c;\n        }\n        /* connect the child correctly */\n        if (!parent) {\n            if (module->data) {\n                module->data->prev->next = child;\n                child->prev = module->data->prev;\n                module->data->prev = child;\n            } else {\n                module->data = child;\n            }\n        } else {\n            pchild = lys_child(parent, child->nodetype);\n            assert(pchild);\n\n            child->parent = parent;\n            if (!(*pchild)) {\n                /* the only/first child of the parent */\n                *pchild = child;\n                iter = child;\n            } else {\n                /* add a new child at the end of parent's child list */\n                iter = (*pchild)->prev;\n                iter->next = child;\n                child->prev = iter;\n            }\n            while (iter->next) {\n                iter = iter->next;\n                iter->parent = parent;\n            }\n            (*pchild)->prev = iter;\n        }\n    }\n\n    /* check config value (but ignore them in groupings and augments) */\n    for (iter = parent; iter && !(iter->nodetype & (LYS_GROUPING | LYS_AUGMENT | LYS_EXT)); iter = iter->parent);\n    if (parent && !iter) {\n        for (iter = child; iter && !(iter->nodetype & (LYS_NOTIF | LYS_INPUT | LYS_OUTPUT | LYS_RPC)); iter = iter->parent);\n        if (!iter && (parent->flags & LYS_CONFIG_R) && (child->flags & LYS_CONFIG_W)) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, child, \"true\", \"config\");\n            LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"State nodes cannot have configuration nodes as children.\");\n            return EXIT_FAILURE;\n        }\n    }\n\n    /* propagate information about status data presence */\n    if ((child->nodetype & (LYS_CONTAINER | LYS_CHOICE | LYS_LEAF | LYS_LEAFLIST | LYS_LIST | LYS_ANYDATA)) &&\n            (child->flags & LYS_INCL_STATUS)) {\n        for(iter = parent; iter; iter = lys_parent(iter)) {\n            /* store it only into container or list - the only data inner nodes */\n            if (iter->nodetype & (LYS_CONTAINER | LYS_LIST)) {\n                if (iter->flags & LYS_INCL_STATUS) {\n                    /* done, someone else set it already from here */\n                    break;\n                }\n                /* set flag about including status data */\n                iter->flags |= LYS_INCL_STATUS;\n            }\n        }\n    }\n\n    /* create implicit input/output nodes to have available them as possible target for augment */\n    if (child->nodetype & (LYS_RPC | LYS_ACTION)) {\n        if (child->nodetype == LYS_ACTION) {\n            for (iter = child->parent; iter; iter = lys_parent(iter)) {\n                if ((iter->nodetype & (LYS_RPC | LYS_ACTION | LYS_NOTIF))\n                        || ((iter->nodetype == LYS_LIST) && !((struct lys_node_list *)iter)->keys)) {\n                    LOGVAL(module->ctx, LYE_INPAR, LY_VLOG_LYS, iter, strnodetype(iter->nodetype), \"action\");\n                    return EXIT_FAILURE;\n                }\n            }\n        }\n\n        if (!child->child) {\n            in = calloc(1, sizeof *in);\n            out = calloc(1, sizeof *out);\n            if (!in || !out) {\n                LOGMEM(ctx);\n                free(in);\n                free(out);\n                return EXIT_FAILURE;\n            }\n            in->nodetype = LYS_INPUT;\n            in->name = lydict_insert(child->module->ctx, \"input\", 5);\n            out->nodetype = LYS_OUTPUT;\n            out->name = lydict_insert(child->module->ctx, \"output\", 6);\n            in->module = out->module = child->module;\n            in->parent = out->parent = child;\n            in->flags = out->flags = LYS_IMPLICIT;\n            in->next = (struct lys_node *)out;\n            in->prev = (struct lys_node *)out;\n            out->prev = (struct lys_node *)in;\n            child->child = (struct lys_node *)in;\n        }\n    }\n    return EXIT_SUCCESS;\n}",
        "func": "int\nlys_node_addchild(struct lys_node *parent, struct lys_module *module, struct lys_node *child, int options)\n{\n    struct ly_ctx *ctx = child->module->ctx;\n    struct lys_node *iter, **pchild, *log_parent;\n    struct lys_node_inout *in, *out;\n    struct lys_node_case *c;\n    struct lys_node_augment *aug;\n    int type, shortcase = 0;\n    void *p;\n    struct lyext_substmt *info = NULL;\n\n    assert(child);\n\n    if (parent) {\n        type = parent->nodetype;\n        module = parent->module;\n        log_parent = parent;\n\n        if (type == LYS_USES) {\n            /* we are adding children to uses -> we must be copying grouping contents into it, so properly check the parent */\n            while (log_parent && (log_parent->nodetype == LYS_USES)) {\n                if (log_parent->nodetype == LYS_AUGMENT) {\n                    aug = (struct lys_node_augment *)log_parent;\n                    if (!aug->target) {\n                        /* unresolved augment, just pass the node type check */\n                        goto skip_nodetype_check;\n                    }\n                    log_parent = aug->target;\n                } else {\n                    log_parent = log_parent->parent;\n                }\n            }\n            if (log_parent) {\n                type = log_parent->nodetype;\n            } else {\n                type = 0;\n            }\n        }\n    } else {\n        assert(module);\n        assert(!(child->nodetype & (LYS_INPUT | LYS_OUTPUT)));\n        type = 0;\n        log_parent = NULL;\n    }\n\n    /* checks */\n    switch (type) {\n    case LYS_CONTAINER:\n    case LYS_LIST:\n    case LYS_GROUPING:\n    case LYS_USES:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_GROUPING | LYS_LEAF |\n                 LYS_LEAFLIST | LYS_LIST | LYS_USES | LYS_ACTION | LYS_NOTIF))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n    case LYS_NOTIF:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_GROUPING | LYS_LEAF |\n                 LYS_LEAFLIST | LYS_LIST | LYS_USES))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_CHOICE:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CASE | LYS_CONTAINER | LYS_LEAF | LYS_LEAFLIST | LYS_LIST | LYS_CHOICE))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"choice\");\n            return EXIT_FAILURE;\n        }\n        if (child->nodetype != LYS_CASE) {\n            shortcase = 1;\n        }\n        break;\n    case LYS_CASE:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_LEAF | LYS_LEAFLIST | LYS_LIST | LYS_USES))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"case\");\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_RPC:\n    case LYS_ACTION:\n        if (!(child->nodetype & (LYS_INPUT | LYS_OUTPUT | LYS_GROUPING))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"rpc\");\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_LEAF:\n    case LYS_LEAFLIST:\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n        LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"The \\\"%s\\\" statement cannot have any data substatement.\",\n               strnodetype(log_parent->nodetype));\n        return EXIT_FAILURE;\n    case LYS_AUGMENT:\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CASE | LYS_CHOICE | LYS_CONTAINER | LYS_LEAF\n                | LYS_LEAFLIST | LYS_LIST | LYS_USES | LYS_ACTION | LYS_NOTIF))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), strnodetype(log_parent->nodetype));\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_UNKNOWN:\n        /* top level */\n        if (!(child->nodetype &\n                (LYS_ANYDATA | LYS_CHOICE | LYS_CONTAINER | LYS_LEAF | LYS_GROUPING\n                | LYS_LEAFLIST | LYS_LIST | LYS_USES | LYS_RPC | LYS_NOTIF | LYS_AUGMENT))) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype), \"(sub)module\");\n            return EXIT_FAILURE;\n        }\n        break;\n    case LYS_EXT:\n        /* plugin-defined */\n        p = lys_ext_complex_get_substmt(lys_snode2stmt(child->nodetype), (struct lys_ext_instance_complex*)log_parent, &info);\n        if (!p) {\n            LOGVAL(ctx, LYE_INCHILDSTMT, LY_VLOG_LYS, log_parent, strnodetype(child->nodetype),\n                   ((struct lys_ext_instance_complex*)log_parent)->def->name);\n            return EXIT_FAILURE;\n        }\n        /* TODO check cardinality */\n        break;\n    }\n\nskip_nodetype_check:\n    /* check identifier uniqueness */\n    if (!(module->ctx->models.flags & LY_CTX_TRUSTED) && lys_check_id(child, parent, module)) {\n        return EXIT_FAILURE;\n    }\n\n    if (child->parent) {\n        lys_node_unlink(child);\n    }\n\n    if ((child->nodetype & (LYS_INPUT | LYS_OUTPUT)) && parent->nodetype != LYS_EXT) {\n        /* find the implicit input/output node */\n        LY_TREE_FOR(parent->child, iter) {\n            if (iter->nodetype == child->nodetype) {\n                break;\n            }\n        }\n        assert(iter);\n\n        /* switch the old implicit node (iter) with the new one (child) */\n        if (parent->child == iter) {\n            /* first child */\n            parent->child = child;\n        } else {\n            iter->prev->next = child;\n        }\n        child->prev = iter->prev;\n        child->next = iter->next;\n        if (iter->next) {\n            iter->next->prev = child;\n        } else {\n            /* last child */\n            parent->child->prev = child;\n        }\n        child->parent = parent;\n\n        /* isolate the node and free it */\n        iter->next = NULL;\n        iter->prev = iter;\n        iter->parent = NULL;\n        lys_node_free(ctx, iter, NULL, 0);\n    } else {\n        if (shortcase) {\n            /* create the implicit case to allow it to serve as a target of the augments,\n             * it won't be printed, but it will be present in the tree */\n            c = calloc(1, sizeof *c);\n            LY_CHECK_ERR_RETURN(!c, LOGMEM(ctx), EXIT_FAILURE);\n            c->name = lydict_insert(module->ctx, child->name, 0);\n            c->flags = LYS_IMPLICIT;\n            if (!(options & (LYS_PARSE_OPT_CFG_IGNORE | LYS_PARSE_OPT_CFG_NOINHERIT))) {\n                /* get config flag from parent */\n                c->flags |= parent->flags & LYS_CONFIG_MASK;\n            }\n            c->module = module;\n            c->nodetype = LYS_CASE;\n            c->prev = (struct lys_node*)c;\n            lys_node_addchild(parent, module, (struct lys_node*)c, options);\n            parent = (struct lys_node*)c;\n        }\n        /* connect the child correctly */\n        if (!parent) {\n            if (module->data) {\n                module->data->prev->next = child;\n                child->prev = module->data->prev;\n                module->data->prev = child;\n            } else {\n                module->data = child;\n            }\n        } else {\n            pchild = lys_child(parent, child->nodetype);\n            assert(pchild);\n\n            child->parent = parent;\n            if (!(*pchild)) {\n                /* the only/first child of the parent */\n                *pchild = child;\n                iter = child;\n            } else {\n                /* add a new child at the end of parent's child list */\n                iter = (*pchild)->prev;\n                iter->next = child;\n                child->prev = iter;\n            }\n            while (iter->next) {\n                iter = iter->next;\n                iter->parent = parent;\n            }\n            (*pchild)->prev = iter;\n        }\n    }\n\n    /* check config value (but ignore them in groupings and augments) */\n    for (iter = parent; iter && !(iter->nodetype & (LYS_GROUPING | LYS_AUGMENT | LYS_EXT)); iter = iter->parent);\n    if (parent && !iter) {\n        for (iter = child; iter && !(iter->nodetype & (LYS_NOTIF | LYS_INPUT | LYS_OUTPUT | LYS_RPC)); iter = iter->parent);\n        if (!iter && (parent->flags & LYS_CONFIG_R) && (child->flags & LYS_CONFIG_W)) {\n            LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, child, \"true\", \"config\");\n            LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"State nodes cannot have configuration nodes as children.\");\n            return EXIT_FAILURE;\n        }\n    }\n\n    /* propagate information about status data presence */\n    if ((child->nodetype & (LYS_CONTAINER | LYS_CHOICE | LYS_LEAF | LYS_LEAFLIST | LYS_LIST | LYS_ANYDATA)) &&\n            (child->flags & LYS_INCL_STATUS)) {\n        for(iter = parent; iter; iter = lys_parent(iter)) {\n            /* store it only into container or list - the only data inner nodes */\n            if (iter->nodetype & (LYS_CONTAINER | LYS_LIST)) {\n                if (iter->flags & LYS_INCL_STATUS) {\n                    /* done, someone else set it already from here */\n                    break;\n                }\n                /* set flag about including status data */\n                iter->flags |= LYS_INCL_STATUS;\n            }\n        }\n    }\n\n    /* create implicit input/output nodes to have available them as possible target for augment */\n    if (child->nodetype & (LYS_RPC | LYS_ACTION)) {\n        if (child->nodetype == LYS_ACTION) {\n            for (iter = child->parent; iter; iter = lys_parent(iter)) {\n                if ((iter->nodetype & (LYS_RPC | LYS_ACTION | LYS_NOTIF))\n                        || ((iter->nodetype == LYS_LIST) && !((struct lys_node_list *)iter)->keys)) {\n                    LOGVAL(module->ctx, LYE_INPAR, LY_VLOG_LYS, iter, strnodetype(iter->nodetype), \"action\");\n                    return EXIT_FAILURE;\n                }\n            }\n        }\n\n        if (!child->child) {\n            in = calloc(1, sizeof *in);\n            out = calloc(1, sizeof *out);\n            if (!in || !out) {\n                LOGMEM(ctx);\n                free(in);\n                free(out);\n                return EXIT_FAILURE;\n            }\n            in->nodetype = LYS_INPUT;\n            in->name = lydict_insert(child->module->ctx, \"input\", 5);\n            out->nodetype = LYS_OUTPUT;\n            out->name = lydict_insert(child->module->ctx, \"output\", 6);\n            in->module = out->module = child->module;\n            in->parent = out->parent = child;\n            in->flags = out->flags = LYS_IMPLICIT;\n            in->next = (struct lys_node *)out;\n            in->prev = (struct lys_node *)out;\n            out->prev = (struct lys_node *)in;\n            child->child = (struct lys_node *)in;\n        }\n    }\n    return EXIT_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -168,7 +168,7 @@\n         iter->next = NULL;\n         iter->prev = iter;\n         iter->parent = NULL;\n-        lys_node_free(iter, NULL, 0);\n+        lys_node_free(ctx, iter, NULL, 0);\n     } else {\n         if (shortcase) {\n             /* create the implicit case to allow it to serve as a target of the augments,",
        "diff_line_info": {
            "deleted_lines": [
                "        lys_node_free(iter, NULL, 0);"
            ],
            "added_lines": [
                "        lys_node_free(ctx, iter, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/module_free_common",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static void\nmodule_free_common(struct lys_module *module, void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    struct ly_ctx *ctx;\n    struct lys_node *next, *iter;\n    unsigned int i;\n\n    assert(module->ctx);\n    ctx = module->ctx;\n\n    /* just free the import array, imported modules will stay in the context */\n    for (i = 0; i < module->imp_size; i++) {\n        lydict_remove(ctx, module->imp[i].prefix);\n        lydict_remove(ctx, module->imp[i].dsc);\n        lydict_remove(ctx, module->imp[i].ref);\n        lys_extension_instances_free(ctx, module->imp[i].ext, module->imp[i].ext_size, private_destructor);\n    }\n    free(module->imp);\n\n    /* submodules don't have data tree, the data nodes\n     * are placed in the main module altogether */\n    if (!module->type) {\n        LY_TREE_FOR_SAFE(module->data, next, iter) {\n            lys_node_free(iter, private_destructor, 0);\n        }\n    }\n\n    lydict_remove(ctx, module->dsc);\n    lydict_remove(ctx, module->ref);\n    lydict_remove(ctx, module->org);\n    lydict_remove(ctx, module->contact);\n    lydict_remove(ctx, module->filepath);\n\n    /* revisions */\n    for (i = 0; i < module->rev_size; i++) {\n        lys_extension_instances_free(ctx, module->rev[i].ext, module->rev[i].ext_size, private_destructor);\n        lydict_remove(ctx, module->rev[i].dsc);\n        lydict_remove(ctx, module->rev[i].ref);\n    }\n    free(module->rev);\n\n    /* identities */\n    for (i = 0; i < module->ident_size; i++) {\n        lys_ident_free(ctx, &module->ident[i], private_destructor);\n    }\n    module->ident_size = 0;\n    free(module->ident);\n\n    /* typedefs */\n    for (i = 0; i < module->tpdf_size; i++) {\n        lys_tpdf_free(ctx, &module->tpdf[i], private_destructor);\n    }\n    free(module->tpdf);\n\n    /* extension instances */\n    lys_extension_instances_free(ctx, module->ext, module->ext_size, private_destructor);\n\n    /* augment */\n    for (i = 0; i < module->augment_size; i++) {\n        lys_augment_free(ctx, &module->augment[i], private_destructor);\n    }\n    free(module->augment);\n\n    /* features */\n    for (i = 0; i < module->features_size; i++) {\n        lys_feature_free(ctx, &module->features[i], private_destructor);\n    }\n    free(module->features);\n\n    /* deviations */\n    for (i = 0; i < module->deviation_size; i++) {\n        lys_deviation_free(module, &module->deviation[i], private_destructor);\n    }\n    free(module->deviation);\n\n    /* extensions */\n    for (i = 0; i < module->extensions_size; i++) {\n        lys_extension_free(ctx, &module->extensions[i], private_destructor);\n    }\n    free(module->extensions);\n\n    lydict_remove(ctx, module->name);\n    lydict_remove(ctx, module->prefix);\n}",
        "func": "static void\nmodule_free_common(struct lys_module *module, void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    struct ly_ctx *ctx;\n    struct lys_node *next, *iter;\n    unsigned int i;\n\n    assert(module->ctx);\n    ctx = module->ctx;\n\n    /* just free the import array, imported modules will stay in the context */\n    for (i = 0; i < module->imp_size; i++) {\n        lydict_remove(ctx, module->imp[i].prefix);\n        lydict_remove(ctx, module->imp[i].dsc);\n        lydict_remove(ctx, module->imp[i].ref);\n        lys_extension_instances_free(ctx, module->imp[i].ext, module->imp[i].ext_size, private_destructor);\n    }\n    free(module->imp);\n\n    /* submodules don't have data tree, the data nodes\n     * are placed in the main module altogether */\n    if (!module->type) {\n        LY_TREE_FOR_SAFE(module->data, next, iter) {\n            lys_node_free(ctx, iter, private_destructor, 0);\n        }\n    }\n\n    lydict_remove(ctx, module->dsc);\n    lydict_remove(ctx, module->ref);\n    lydict_remove(ctx, module->org);\n    lydict_remove(ctx, module->contact);\n    lydict_remove(ctx, module->filepath);\n\n    /* revisions */\n    for (i = 0; i < module->rev_size; i++) {\n        lys_extension_instances_free(ctx, module->rev[i].ext, module->rev[i].ext_size, private_destructor);\n        lydict_remove(ctx, module->rev[i].dsc);\n        lydict_remove(ctx, module->rev[i].ref);\n    }\n    free(module->rev);\n\n    /* identities */\n    for (i = 0; i < module->ident_size; i++) {\n        lys_ident_free(ctx, &module->ident[i], private_destructor);\n    }\n    module->ident_size = 0;\n    free(module->ident);\n\n    /* typedefs */\n    for (i = 0; i < module->tpdf_size; i++) {\n        lys_tpdf_free(ctx, &module->tpdf[i], private_destructor);\n    }\n    free(module->tpdf);\n\n    /* extension instances */\n    lys_extension_instances_free(ctx, module->ext, module->ext_size, private_destructor);\n\n    /* augment */\n    for (i = 0; i < module->augment_size; i++) {\n        lys_augment_free(ctx, &module->augment[i], private_destructor);\n    }\n    free(module->augment);\n\n    /* features */\n    for (i = 0; i < module->features_size; i++) {\n        lys_feature_free(ctx, &module->features[i], private_destructor);\n    }\n    free(module->features);\n\n    /* deviations */\n    for (i = 0; i < module->deviation_size; i++) {\n        lys_deviation_free(module, &module->deviation[i], private_destructor);\n    }\n    free(module->deviation);\n\n    /* extensions */\n    for (i = 0; i < module->extensions_size; i++) {\n        lys_extension_free(ctx, &module->extensions[i], private_destructor);\n    }\n    free(module->extensions);\n\n    lydict_remove(ctx, module->name);\n    lydict_remove(ctx, module->prefix);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,7 +21,7 @@\n      * are placed in the main module altogether */\n     if (!module->type) {\n         LY_TREE_FOR_SAFE(module->data, next, iter) {\n-            lys_node_free(iter, private_destructor, 0);\n+            lys_node_free(ctx, iter, private_destructor, 0);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            lys_node_free(iter, private_destructor, 0);"
            ],
            "added_lines": [
                "            lys_node_free(ctx, iter, private_destructor, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/lys_submodule_module_data_free",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "void\nlys_submodule_module_data_free(struct lys_submodule *submodule)\n{\n    struct lys_node *next, *elem;\n\n    /* remove parsed data */\n    LY_TREE_FOR_SAFE(submodule->belongsto->data, next, elem) {\n        if (elem->module == (struct lys_module *)submodule) {\n            lys_node_free(elem, NULL, 0);\n        }\n    }\n}",
        "func": "void\nlys_submodule_module_data_free(struct lys_submodule *submodule)\n{\n    struct lys_node *next, *elem;\n\n    /* remove parsed data */\n    LY_TREE_FOR_SAFE(submodule->belongsto->data, next, elem) {\n        if (elem->module == (struct lys_module *)submodule) {\n            lys_node_free(submodule->ctx, elem, NULL, 0);\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n     /* remove parsed data */\n     LY_TREE_FOR_SAFE(submodule->belongsto->data, next, elem) {\n         if (elem->module == (struct lys_module *)submodule) {\n-            lys_node_free(elem, NULL, 0);\n+            lys_node_free(submodule->ctx, elem, NULL, 0);\n         }\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "            lys_node_free(elem, NULL, 0);"
            ],
            "added_lines": [
                "            lys_node_free(submodule->ctx, elem, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/lys_node_free",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "void\nlys_node_free(struct lys_node *node, void (*private_destructor)(const struct lys_node *node, void *priv), int shallow)\n{\n    struct ly_ctx *ctx;\n    struct lys_node *sub, *next;\n\n    if (!node) {\n        return;\n    }\n\n    assert(node->module);\n    assert(node->module->ctx);\n\n    ctx = node->module->ctx;\n\n    /* remove private object */\n    if (node->priv && private_destructor) {\n        private_destructor(node, node->priv);\n    }\n\n    /* common part */\n    lydict_remove(ctx, node->name);\n    if (!(node->nodetype & (LYS_INPUT | LYS_OUTPUT))) {\n        lys_iffeature_free(ctx, node->iffeature, node->iffeature_size, shallow, private_destructor);\n        lydict_remove(ctx, node->dsc);\n        lydict_remove(ctx, node->ref);\n    }\n\n    if (!shallow && !(node->nodetype & (LYS_LEAF | LYS_LEAFLIST))) {\n        LY_TREE_FOR_SAFE(node->child, next, sub) {\n            lys_node_free(sub, private_destructor, 0);\n        }\n    }\n\n    lys_extension_instances_free(ctx, node->ext, node->ext_size, private_destructor);\n\n    /* specific part */\n    switch (node->nodetype) {\n    case LYS_CONTAINER:\n        lys_container_free(ctx, (struct lys_node_container *)node, private_destructor);\n        break;\n    case LYS_CHOICE:\n        lys_when_free(ctx, ((struct lys_node_choice *)node)->when, private_destructor);\n        break;\n    case LYS_LEAF:\n        lys_leaf_free(ctx, (struct lys_node_leaf *)node, private_destructor);\n        break;\n    case LYS_LEAFLIST:\n        lys_leaflist_free(ctx, (struct lys_node_leaflist *)node, private_destructor);\n        break;\n    case LYS_LIST:\n        lys_list_free(ctx, (struct lys_node_list *)node, private_destructor);\n        break;\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        lys_anydata_free(ctx, (struct lys_node_anydata *)node, private_destructor);\n        break;\n    case LYS_USES:\n        lys_uses_free(ctx, (struct lys_node_uses *)node, private_destructor);\n        break;\n    case LYS_CASE:\n        lys_when_free(ctx, ((struct lys_node_case *)node)->when, private_destructor);\n        break;\n    case LYS_AUGMENT:\n        /* do nothing */\n        break;\n    case LYS_GROUPING:\n        lys_grp_free(ctx, (struct lys_node_grp *)node, private_destructor);\n        break;\n    case LYS_RPC:\n    case LYS_ACTION:\n        lys_rpc_action_free(ctx, (struct lys_node_rpc_action *)node, private_destructor);\n        break;\n    case LYS_NOTIF:\n        lys_notif_free(ctx, (struct lys_node_notif *)node, private_destructor);\n        break;\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n        lys_inout_free(ctx, (struct lys_node_inout *)node, private_destructor);\n        break;\n    case LYS_EXT:\n    case LYS_UNKNOWN:\n        LOGINT(ctx);\n        break;\n    }\n\n    /* again common part */\n    lys_node_unlink(node);\n    free(node);\n}",
        "func": "void\nlys_node_free(struct ly_ctx *ctx, struct lys_node *node,\n              void (*private_destructor)(const struct lys_node *node, void *priv), int shallow)\n{\n    struct lys_node *sub, *next;\n\n    if (!node) {\n        return;\n    }\n\n    /* remove private object */\n    if (node->priv && private_destructor) {\n        private_destructor(node, node->priv);\n    }\n\n    /* common part */\n    lydict_remove(ctx, node->name);\n    if (!(node->nodetype & (LYS_INPUT | LYS_OUTPUT))) {\n        lys_iffeature_free(ctx, node->iffeature, node->iffeature_size, shallow, private_destructor);\n        lydict_remove(ctx, node->dsc);\n        lydict_remove(ctx, node->ref);\n    }\n\n    if (!shallow && !(node->nodetype & (LYS_LEAF | LYS_LEAFLIST))) {\n        LY_TREE_FOR_SAFE(node->child, next, sub) {\n            lys_node_free(ctx, sub, private_destructor, 0);\n        }\n    }\n\n    lys_extension_instances_free(ctx, node->ext, node->ext_size, private_destructor);\n\n    /* specific part */\n    switch (node->nodetype) {\n    case LYS_CONTAINER:\n        lys_container_free(ctx, (struct lys_node_container *)node, private_destructor);\n        break;\n    case LYS_CHOICE:\n        lys_when_free(ctx, ((struct lys_node_choice *)node)->when, private_destructor);\n        break;\n    case LYS_LEAF:\n        lys_leaf_free(ctx, (struct lys_node_leaf *)node, private_destructor);\n        break;\n    case LYS_LEAFLIST:\n        lys_leaflist_free(ctx, (struct lys_node_leaflist *)node, private_destructor);\n        break;\n    case LYS_LIST:\n        lys_list_free(ctx, (struct lys_node_list *)node, private_destructor);\n        break;\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        lys_anydata_free(ctx, (struct lys_node_anydata *)node, private_destructor);\n        break;\n    case LYS_USES:\n        lys_uses_free(ctx, (struct lys_node_uses *)node, private_destructor);\n        break;\n    case LYS_CASE:\n        lys_when_free(ctx, ((struct lys_node_case *)node)->when, private_destructor);\n        break;\n    case LYS_AUGMENT:\n        /* do nothing */\n        break;\n    case LYS_GROUPING:\n        lys_grp_free(ctx, (struct lys_node_grp *)node, private_destructor);\n        break;\n    case LYS_RPC:\n    case LYS_ACTION:\n        lys_rpc_action_free(ctx, (struct lys_node_rpc_action *)node, private_destructor);\n        break;\n    case LYS_NOTIF:\n        lys_notif_free(ctx, (struct lys_node_notif *)node, private_destructor);\n        break;\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n        lys_inout_free(ctx, (struct lys_node_inout *)node, private_destructor);\n        break;\n    case LYS_EXT:\n    case LYS_UNKNOWN:\n        LOGINT(ctx);\n        break;\n    }\n\n    /* again common part */\n    lys_node_unlink(node);\n    free(node);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,17 +1,12 @@\n void\n-lys_node_free(struct lys_node *node, void (*private_destructor)(const struct lys_node *node, void *priv), int shallow)\n+lys_node_free(struct ly_ctx *ctx, struct lys_node *node,\n+              void (*private_destructor)(const struct lys_node *node, void *priv), int shallow)\n {\n-    struct ly_ctx *ctx;\n     struct lys_node *sub, *next;\n \n     if (!node) {\n         return;\n     }\n-\n-    assert(node->module);\n-    assert(node->module->ctx);\n-\n-    ctx = node->module->ctx;\n \n     /* remove private object */\n     if (node->priv && private_destructor) {\n@@ -28,7 +23,7 @@\n \n     if (!shallow && !(node->nodetype & (LYS_LEAF | LYS_LEAFLIST))) {\n         LY_TREE_FOR_SAFE(node->child, next, sub) {\n-            lys_node_free(sub, private_destructor, 0);\n+            lys_node_free(ctx, sub, private_destructor, 0);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "lys_node_free(struct lys_node *node, void (*private_destructor)(const struct lys_node *node, void *priv), int shallow)",
                "    struct ly_ctx *ctx;",
                "",
                "    assert(node->module);",
                "    assert(node->module->ctx);",
                "",
                "    ctx = node->module->ctx;",
                "            lys_node_free(sub, private_destructor, 0);"
            ],
            "added_lines": [
                "lys_node_free(struct ly_ctx *ctx, struct lys_node *node,",
                "              void (*private_destructor)(const struct lys_node *node, void *priv), int shallow)",
                "            lys_node_free(ctx, sub, private_destructor, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/lys_extension_instances_free",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "void\nlys_extension_instances_free(struct ly_ctx *ctx, struct lys_ext_instance **e, unsigned int size,\n                             void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    unsigned int i, j, k;\n    struct lyext_substmt *substmt;\n    void **pp, **start;\n    struct lys_node *siter, *snext;\n\n#define EXTCOMPLEX_FREE_STRUCT(STMT, TYPE, FUNC, FREE, ARGS...)                               \\\n    pp = lys_ext_complex_get_substmt(STMT, (struct lys_ext_instance_complex *)e[i], NULL);    \\\n    if (!pp || !(*pp)) { break; }                                                             \\\n    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) { /* process array */                    \\\n        for (start = pp = *pp; *pp; pp++) {                                                   \\\n            FUNC(ctx, (TYPE *)(*pp), ##ARGS, private_destructor);                             \\\n            if (FREE) { free(*pp); }                                                          \\\n        }                                                                                     \\\n        free(start);                                                                          \\\n    } else { /* single item */                                                                \\\n        FUNC(ctx, (TYPE *)(*pp), ##ARGS, private_destructor);                                 \\\n        if (FREE) { free(*pp); }                                                              \\\n    }\n\n    if (!size || !e) {\n        return;\n    }\n\n    for (i = 0; i < size; i++) {\n        if (!e[i]) {\n            continue;\n        }\n\n        if (e[i]->flags & (LYEXT_OPT_INHERIT)) {\n            /* no free, this is just a shadow copy of the original extension instance */\n        } else {\n            if (e[i]->flags & (LYEXT_OPT_YANG)) {\n                free(e[i]->def);     /* remove name of instance extension */\n                e[i]->def = NULL;\n                yang_free_ext_data((struct yang_ext_substmt *)e[i]->parent); /* remove backup part of yang file */\n            }\n            /* remove private object */\n            if (e[i]->priv && private_destructor) {\n                private_destructor((struct lys_node*)e[i], e[i]->priv);\n            }\n            lys_extension_instances_free(ctx, e[i]->ext, e[i]->ext_size, private_destructor);\n            lydict_remove(ctx, e[i]->arg_value);\n        }\n\n        if (e[i]->def && e[i]->def->plugin && e[i]->def->plugin->type == LYEXT_COMPLEX\n                && ((e[i]->flags & LYEXT_OPT_CONTENT) == 0)) {\n            substmt = ((struct lys_ext_instance_complex *)e[i])->substmt;\n            for (j = 0; substmt[j].stmt; j++) {\n                switch(substmt[j].stmt) {\n                case LY_STMT_DESCRIPTION:\n                case LY_STMT_REFERENCE:\n                case LY_STMT_UNITS:\n                case LY_STMT_ARGUMENT:\n                case LY_STMT_DEFAULT:\n                case LY_STMT_ERRTAG:\n                case LY_STMT_ERRMSG:\n                case LY_STMT_PREFIX:\n                case LY_STMT_NAMESPACE:\n                case LY_STMT_PRESENCE:\n                case LY_STMT_REVISIONDATE:\n                case LY_STMT_KEY:\n                case LY_STMT_BASE:\n                case LY_STMT_BELONGSTO:\n                case LY_STMT_CONTACT:\n                case LY_STMT_ORGANIZATION:\n                case LY_STMT_PATH:\n                    lys_extcomplex_free_str(ctx, (struct lys_ext_instance_complex *)e[i], substmt[j].stmt);\n                    break;\n                case LY_STMT_TYPE:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_TYPE, struct lys_type, lys_type_free, 1);\n                    break;\n                case LY_STMT_TYPEDEF:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_TYPEDEF, struct lys_tpdf, lys_tpdf_free, 1);\n                    break;\n                case LY_STMT_IFFEATURE:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_IFFEATURE, struct lys_iffeature, lys_iffeature_free, 0, 1, 0);\n                    break;\n                case LY_STMT_MAX:\n                case LY_STMT_MIN:\n                case LY_STMT_POSITION:\n                case LY_STMT_VALUE:\n                    pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME && *pp) {\n                        for(k = 0; ((uint32_t**)(*pp))[k]; k++) {\n                            free(((uint32_t**)(*pp))[k]);\n                        }\n                    }\n                    free(*pp);\n                    break;\n                case LY_STMT_DIGITS:\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) {\n                        /* free the array */\n                        pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                        free(*pp);\n                    }\n                    break;\n                case LY_STMT_MODULE:\n                    /* modules are part of the context, so they will be freed there */\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) {\n                        /* free the array */\n                        pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                        free(*pp);\n                    }\n                    break;\n                case LY_STMT_ACTION:\n                case LY_STMT_ANYDATA:\n                case LY_STMT_ANYXML:\n                case LY_STMT_CASE:\n                case LY_STMT_CHOICE:\n                case LY_STMT_CONTAINER:\n                case LY_STMT_GROUPING:\n                case LY_STMT_INPUT:\n                case LY_STMT_LEAF:\n                case LY_STMT_LEAFLIST:\n                case LY_STMT_LIST:\n                case LY_STMT_NOTIFICATION:\n                case LY_STMT_OUTPUT:\n                case LY_STMT_RPC:\n                case LY_STMT_USES:\n                    pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                    LY_TREE_FOR_SAFE((struct lys_node *)(*pp), snext, siter) {\n                        lys_node_free(siter, NULL, 0);\n                    }\n                    *pp = NULL;\n                    break;\n                case LY_STMT_UNIQUE:\n                    pp = lys_ext_complex_get_substmt(LY_STMT_UNIQUE, (struct lys_ext_instance_complex *)e[i], NULL);\n                    if (!pp || !(*pp)) {\n                        break;\n                    }\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) { /* process array */\n                        for (start = pp = *pp; *pp; pp++) {\n                            for (k = 0; k < (*(struct lys_unique**)pp)->expr_size; k++) {\n                                lydict_remove(ctx, (*(struct lys_unique**)pp)->expr[k]);\n                            }\n                            free((*(struct lys_unique**)pp)->expr);\n                            free(*pp);\n                        }\n                        free(start);\n                    } else { /* single item */\n                        for (k = 0; k < (*(struct lys_unique**)pp)->expr_size; k++) {\n                            lydict_remove(ctx, (*(struct lys_unique**)pp)->expr[k]);\n                        }\n                        free((*(struct lys_unique**)pp)->expr);\n                        free(*pp);\n                    }\n                    break;\n                case LY_STMT_LENGTH:\n                case LY_STMT_MUST:\n                case LY_STMT_PATTERN:\n                case LY_STMT_RANGE:\n                    EXTCOMPLEX_FREE_STRUCT(substmt[j].stmt, struct lys_restr, lys_restr_free, 1);\n                    break;\n                case LY_STMT_WHEN:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_WHEN, struct lys_when, lys_when_free, 0);\n                    break;\n                case LY_STMT_REVISION:\n                    pp = lys_ext_complex_get_substmt(LY_STMT_REVISION, (struct lys_ext_instance_complex *)e[i], NULL);\n                    if (!pp || !(*pp)) {\n                        break;\n                    }\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) { /* process array */\n                        for (start = pp = *pp; *pp; pp++) {\n                            lydict_remove(ctx, (*(struct lys_revision**)pp)->dsc);\n                            lydict_remove(ctx, (*(struct lys_revision**)pp)->ref);\n                            lys_extension_instances_free(ctx, (*(struct lys_revision**)pp)->ext,\n                                                         (*(struct lys_revision**)pp)->ext_size, private_destructor);\n                            free(*pp);\n                        }\n                        free(start);\n                    } else { /* single item */\n                        lydict_remove(ctx, (*(struct lys_revision**)pp)->dsc);\n                        lydict_remove(ctx, (*(struct lys_revision**)pp)->ref);\n                        lys_extension_instances_free(ctx, (*(struct lys_revision**)pp)->ext,\n                                                     (*(struct lys_revision**)pp)->ext_size, private_destructor);\n                        free(*pp);\n                    }\n                    break;\n                default:\n                    /* nothing to free */\n                    break;\n                }\n            }\n        }\n\n        free(e[i]);\n    }\n    free(e);\n\n#undef EXTCOMPLEX_FREE_STRUCT\n}",
        "func": "void\nlys_extension_instances_free(struct ly_ctx *ctx, struct lys_ext_instance **e, unsigned int size,\n                             void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    unsigned int i, j, k;\n    struct lyext_substmt *substmt;\n    void **pp, **start;\n    struct lys_node *siter, *snext;\n\n#define EXTCOMPLEX_FREE_STRUCT(STMT, TYPE, FUNC, FREE, ARGS...)                               \\\n    pp = lys_ext_complex_get_substmt(STMT, (struct lys_ext_instance_complex *)e[i], NULL);    \\\n    if (!pp || !(*pp)) { break; }                                                             \\\n    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) { /* process array */                    \\\n        for (start = pp = *pp; *pp; pp++) {                                                   \\\n            FUNC(ctx, (TYPE *)(*pp), ##ARGS, private_destructor);                             \\\n            if (FREE) { free(*pp); }                                                          \\\n        }                                                                                     \\\n        free(start);                                                                          \\\n    } else { /* single item */                                                                \\\n        FUNC(ctx, (TYPE *)(*pp), ##ARGS, private_destructor);                                 \\\n        if (FREE) { free(*pp); }                                                              \\\n    }\n\n    if (!size || !e) {\n        return;\n    }\n\n    for (i = 0; i < size; i++) {\n        if (!e[i]) {\n            continue;\n        }\n\n        if (e[i]->flags & (LYEXT_OPT_INHERIT)) {\n            /* no free, this is just a shadow copy of the original extension instance */\n        } else {\n            if (e[i]->flags & (LYEXT_OPT_YANG)) {\n                free(e[i]->def);     /* remove name of instance extension */\n                e[i]->def = NULL;\n                yang_free_ext_data((struct yang_ext_substmt *)e[i]->parent); /* remove backup part of yang file */\n            }\n            /* remove private object */\n            if (e[i]->priv && private_destructor) {\n                private_destructor((struct lys_node*)e[i], e[i]->priv);\n            }\n            lys_extension_instances_free(ctx, e[i]->ext, e[i]->ext_size, private_destructor);\n            lydict_remove(ctx, e[i]->arg_value);\n        }\n\n        if (e[i]->def && e[i]->def->plugin && e[i]->def->plugin->type == LYEXT_COMPLEX\n                && ((e[i]->flags & LYEXT_OPT_CONTENT) == 0)) {\n            substmt = ((struct lys_ext_instance_complex *)e[i])->substmt;\n            for (j = 0; substmt[j].stmt; j++) {\n                switch(substmt[j].stmt) {\n                case LY_STMT_DESCRIPTION:\n                case LY_STMT_REFERENCE:\n                case LY_STMT_UNITS:\n                case LY_STMT_ARGUMENT:\n                case LY_STMT_DEFAULT:\n                case LY_STMT_ERRTAG:\n                case LY_STMT_ERRMSG:\n                case LY_STMT_PREFIX:\n                case LY_STMT_NAMESPACE:\n                case LY_STMT_PRESENCE:\n                case LY_STMT_REVISIONDATE:\n                case LY_STMT_KEY:\n                case LY_STMT_BASE:\n                case LY_STMT_BELONGSTO:\n                case LY_STMT_CONTACT:\n                case LY_STMT_ORGANIZATION:\n                case LY_STMT_PATH:\n                    lys_extcomplex_free_str(ctx, (struct lys_ext_instance_complex *)e[i], substmt[j].stmt);\n                    break;\n                case LY_STMT_TYPE:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_TYPE, struct lys_type, lys_type_free, 1);\n                    break;\n                case LY_STMT_TYPEDEF:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_TYPEDEF, struct lys_tpdf, lys_tpdf_free, 1);\n                    break;\n                case LY_STMT_IFFEATURE:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_IFFEATURE, struct lys_iffeature, lys_iffeature_free, 0, 1, 0);\n                    break;\n                case LY_STMT_MAX:\n                case LY_STMT_MIN:\n                case LY_STMT_POSITION:\n                case LY_STMT_VALUE:\n                    pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME && *pp) {\n                        for(k = 0; ((uint32_t**)(*pp))[k]; k++) {\n                            free(((uint32_t**)(*pp))[k]);\n                        }\n                    }\n                    free(*pp);\n                    break;\n                case LY_STMT_DIGITS:\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) {\n                        /* free the array */\n                        pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                        free(*pp);\n                    }\n                    break;\n                case LY_STMT_MODULE:\n                    /* modules are part of the context, so they will be freed there */\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) {\n                        /* free the array */\n                        pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                        free(*pp);\n                    }\n                    break;\n                case LY_STMT_ACTION:\n                case LY_STMT_ANYDATA:\n                case LY_STMT_ANYXML:\n                case LY_STMT_CASE:\n                case LY_STMT_CHOICE:\n                case LY_STMT_CONTAINER:\n                case LY_STMT_GROUPING:\n                case LY_STMT_INPUT:\n                case LY_STMT_LEAF:\n                case LY_STMT_LEAFLIST:\n                case LY_STMT_LIST:\n                case LY_STMT_NOTIFICATION:\n                case LY_STMT_OUTPUT:\n                case LY_STMT_RPC:\n                case LY_STMT_USES:\n                    pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                    LY_TREE_FOR_SAFE((struct lys_node *)(*pp), snext, siter) {\n                        lys_node_free(ctx, siter, NULL, 0);\n                    }\n                    *pp = NULL;\n                    break;\n                case LY_STMT_UNIQUE:\n                    pp = lys_ext_complex_get_substmt(LY_STMT_UNIQUE, (struct lys_ext_instance_complex *)e[i], NULL);\n                    if (!pp || !(*pp)) {\n                        break;\n                    }\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) { /* process array */\n                        for (start = pp = *pp; *pp; pp++) {\n                            for (k = 0; k < (*(struct lys_unique**)pp)->expr_size; k++) {\n                                lydict_remove(ctx, (*(struct lys_unique**)pp)->expr[k]);\n                            }\n                            free((*(struct lys_unique**)pp)->expr);\n                            free(*pp);\n                        }\n                        free(start);\n                    } else { /* single item */\n                        for (k = 0; k < (*(struct lys_unique**)pp)->expr_size; k++) {\n                            lydict_remove(ctx, (*(struct lys_unique**)pp)->expr[k]);\n                        }\n                        free((*(struct lys_unique**)pp)->expr);\n                        free(*pp);\n                    }\n                    break;\n                case LY_STMT_LENGTH:\n                case LY_STMT_MUST:\n                case LY_STMT_PATTERN:\n                case LY_STMT_RANGE:\n                    EXTCOMPLEX_FREE_STRUCT(substmt[j].stmt, struct lys_restr, lys_restr_free, 1);\n                    break;\n                case LY_STMT_WHEN:\n                    EXTCOMPLEX_FREE_STRUCT(LY_STMT_WHEN, struct lys_when, lys_when_free, 0);\n                    break;\n                case LY_STMT_REVISION:\n                    pp = lys_ext_complex_get_substmt(LY_STMT_REVISION, (struct lys_ext_instance_complex *)e[i], NULL);\n                    if (!pp || !(*pp)) {\n                        break;\n                    }\n                    if (substmt[j].cardinality >= LY_STMT_CARD_SOME) { /* process array */\n                        for (start = pp = *pp; *pp; pp++) {\n                            lydict_remove(ctx, (*(struct lys_revision**)pp)->dsc);\n                            lydict_remove(ctx, (*(struct lys_revision**)pp)->ref);\n                            lys_extension_instances_free(ctx, (*(struct lys_revision**)pp)->ext,\n                                                         (*(struct lys_revision**)pp)->ext_size, private_destructor);\n                            free(*pp);\n                        }\n                        free(start);\n                    } else { /* single item */\n                        lydict_remove(ctx, (*(struct lys_revision**)pp)->dsc);\n                        lydict_remove(ctx, (*(struct lys_revision**)pp)->ref);\n                        lys_extension_instances_free(ctx, (*(struct lys_revision**)pp)->ext,\n                                                     (*(struct lys_revision**)pp)->ext_size, private_destructor);\n                        free(*pp);\n                    }\n                    break;\n                default:\n                    /* nothing to free */\n                    break;\n                }\n            }\n        }\n\n        free(e[i]);\n    }\n    free(e);\n\n#undef EXTCOMPLEX_FREE_STRUCT\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -123,7 +123,7 @@\n                 case LY_STMT_USES:\n                     pp = (void**)&((struct lys_ext_instance_complex *)e[i])->content[substmt[j].offset];\n                     LY_TREE_FOR_SAFE((struct lys_node *)(*pp), snext, siter) {\n-                        lys_node_free(siter, NULL, 0);\n+                        lys_node_free(ctx, siter, NULL, 0);\n                     }\n                     *pp = NULL;\n                     break;",
        "diff_line_info": {
            "deleted_lines": [
                "                        lys_node_free(siter, NULL, 0);"
            ],
            "added_lines": [
                "                        lys_node_free(ctx, siter, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/lys_augment_free",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static void\nlys_augment_free(struct ly_ctx *ctx, struct lys_node_augment *aug,\n                 void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    struct lys_node *next, *sub;\n\n    /* children from a resolved augment are freed under the target node */\n    if (!aug->target || (aug->flags & LYS_NOTAPPLIED)) {\n        LY_TREE_FOR_SAFE(aug->child, next, sub) {\n            lys_node_free(sub, private_destructor, 0);\n        }\n    }\n\n    lydict_remove(ctx, aug->target_name);\n    lydict_remove(ctx, aug->dsc);\n    lydict_remove(ctx, aug->ref);\n\n    lys_iffeature_free(ctx, aug->iffeature, aug->iffeature_size, 0, private_destructor);\n    lys_extension_instances_free(ctx, aug->ext, aug->ext_size, private_destructor);\n\n    lys_when_free(ctx, aug->when, private_destructor);\n}",
        "func": "static void\nlys_augment_free(struct ly_ctx *ctx, struct lys_node_augment *aug,\n                 void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    struct lys_node *next, *sub;\n\n    /* children from a resolved augment are freed under the target node */\n    if (!aug->target || (aug->flags & LYS_NOTAPPLIED)) {\n        LY_TREE_FOR_SAFE(aug->child, next, sub) {\n            lys_node_free(ctx, sub, private_destructor, 0);\n        }\n    }\n\n    lydict_remove(ctx, aug->target_name);\n    lydict_remove(ctx, aug->dsc);\n    lydict_remove(ctx, aug->ref);\n\n    lys_iffeature_free(ctx, aug->iffeature, aug->iffeature_size, 0, private_destructor);\n    lys_extension_instances_free(ctx, aug->ext, aug->ext_size, private_destructor);\n\n    lys_when_free(ctx, aug->when, private_destructor);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n     /* children from a resolved augment are freed under the target node */\n     if (!aug->target || (aug->flags & LYS_NOTAPPLIED)) {\n         LY_TREE_FOR_SAFE(aug->child, next, sub) {\n-            lys_node_free(sub, private_destructor, 0);\n+            lys_node_free(ctx, sub, private_destructor, 0);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            lys_node_free(sub, private_destructor, 0);"
            ],
            "added_lines": [
                "            lys_node_free(ctx, sub, private_destructor, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/lys_deviation_free",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static void\nlys_deviation_free(struct lys_module *module, struct lys_deviation *dev,\n                   void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    int i, j, k;\n    struct ly_ctx *ctx;\n    struct lys_node *next, *elem;\n\n    ctx = module->ctx;\n\n    lydict_remove(ctx, dev->target_name);\n    lydict_remove(ctx, dev->dsc);\n    lydict_remove(ctx, dev->ref);\n    lys_extension_instances_free(ctx, dev->ext, dev->ext_size, private_destructor);\n\n    if (!dev->deviate) {\n        return;\n    }\n\n    /* it could not be applied because it failed to be applied */\n    if (dev->orig_node) {\n        /* the module was freed, but we only need the context from orig_node, use ours */\n        if (dev->deviate[0].mod == LY_DEVIATE_NO) {\n            /* it's actually a node subtree, we need to update modules on all the nodes :-/ */\n            LY_TREE_DFS_BEGIN(dev->orig_node, next, elem) {\n                elem->module = module;\n\n                LY_TREE_DFS_END(dev->orig_node, next, elem);\n            }\n            lys_node_free(dev->orig_node, NULL, 0);\n        } else {\n            /* it's just a shallow copy, freeing one node */\n            dev->orig_node->module = module;\n            lys_node_free(dev->orig_node, NULL, 1);\n        }\n    }\n\n    for (i = 0; i < dev->deviate_size; i++) {\n        lys_extension_instances_free(ctx, dev->deviate[i].ext, dev->deviate[i].ext_size, private_destructor);\n\n        for (j = 0; j < dev->deviate[i].dflt_size; j++) {\n            lydict_remove(ctx, dev->deviate[i].dflt[j]);\n        }\n        free(dev->deviate[i].dflt);\n\n        lydict_remove(ctx, dev->deviate[i].units);\n\n        if (dev->deviate[i].mod == LY_DEVIATE_DEL) {\n            for (j = 0; j < dev->deviate[i].must_size; j++) {\n                lys_restr_free(ctx, &dev->deviate[i].must[j], private_destructor);\n            }\n            free(dev->deviate[i].must);\n\n            for (j = 0; j < dev->deviate[i].unique_size; j++) {\n                for (k = 0; k < dev->deviate[i].unique[j].expr_size; k++) {\n                    lydict_remove(ctx, dev->deviate[i].unique[j].expr[k]);\n                }\n                free(dev->deviate[i].unique[j].expr);\n            }\n            free(dev->deviate[i].unique);\n        }\n    }\n    free(dev->deviate);\n}",
        "func": "static void\nlys_deviation_free(struct lys_module *module, struct lys_deviation *dev,\n                   void (*private_destructor)(const struct lys_node *node, void *priv))\n{\n    int i, j, k;\n    struct ly_ctx *ctx;\n    struct lys_node *next, *elem;\n\n    ctx = module->ctx;\n\n    lydict_remove(ctx, dev->target_name);\n    lydict_remove(ctx, dev->dsc);\n    lydict_remove(ctx, dev->ref);\n    lys_extension_instances_free(ctx, dev->ext, dev->ext_size, private_destructor);\n\n    if (!dev->deviate) {\n        return;\n    }\n\n    /* it could not be applied because it failed to be applied */\n    if (dev->orig_node) {\n        /* the module was freed, but we only need the context from orig_node, use ours */\n        if (dev->deviate[0].mod == LY_DEVIATE_NO) {\n            /* it's actually a node subtree, we need to update modules on all the nodes :-/ */\n            LY_TREE_DFS_BEGIN(dev->orig_node, next, elem) {\n                elem->module = module;\n\n                LY_TREE_DFS_END(dev->orig_node, next, elem);\n            }\n            lys_node_free(ctx, dev->orig_node, NULL, 0);\n        } else {\n            /* it's just a shallow copy, freeing one node */\n            dev->orig_node->module = module;\n            lys_node_free(ctx, dev->orig_node, NULL, 1);\n        }\n    }\n\n    for (i = 0; i < dev->deviate_size; i++) {\n        lys_extension_instances_free(ctx, dev->deviate[i].ext, dev->deviate[i].ext_size, private_destructor);\n\n        for (j = 0; j < dev->deviate[i].dflt_size; j++) {\n            lydict_remove(ctx, dev->deviate[i].dflt[j]);\n        }\n        free(dev->deviate[i].dflt);\n\n        lydict_remove(ctx, dev->deviate[i].units);\n\n        if (dev->deviate[i].mod == LY_DEVIATE_DEL) {\n            for (j = 0; j < dev->deviate[i].must_size; j++) {\n                lys_restr_free(ctx, &dev->deviate[i].must[j], private_destructor);\n            }\n            free(dev->deviate[i].must);\n\n            for (j = 0; j < dev->deviate[i].unique_size; j++) {\n                for (k = 0; k < dev->deviate[i].unique[j].expr_size; k++) {\n                    lydict_remove(ctx, dev->deviate[i].unique[j].expr[k]);\n                }\n                free(dev->deviate[i].unique[j].expr);\n            }\n            free(dev->deviate[i].unique);\n        }\n    }\n    free(dev->deviate);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,11 +27,11 @@\n \n                 LY_TREE_DFS_END(dev->orig_node, next, elem);\n             }\n-            lys_node_free(dev->orig_node, NULL, 0);\n+            lys_node_free(ctx, dev->orig_node, NULL, 0);\n         } else {\n             /* it's just a shallow copy, freeing one node */\n             dev->orig_node->module = module;\n-            lys_node_free(dev->orig_node, NULL, 1);\n+            lys_node_free(ctx, dev->orig_node, NULL, 1);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            lys_node_free(dev->orig_node, NULL, 0);",
                "            lys_node_free(dev->orig_node, NULL, 1);"
            ],
            "added_lines": [
                "            lys_node_free(ctx, dev->orig_node, NULL, 0);",
                "            lys_node_free(ctx, dev->orig_node, NULL, 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28905",
        "func_name": "CESNET/libyang/lys_node_dup_recursion",
        "description": "In function lys_node_free() in libyang <= v1.0.225, it asserts that the value of node->module can't be NULL. But in some cases, node->module can be null, which triggers a reachable assertion (CWE-617).",
        "git_url": "https://github.com/CESNET/libyang/commit/5ce30801f9ccc372bbe9b7c98bb5324b15fb010a",
        "commit_title": "schema tree BUGFIX freeing nodes with no module set",
        "commit_text": " Context must be passed explicitly for these cases. Fixes #1452",
        "func_before": "static struct lys_node *\nlys_node_dup_recursion(struct lys_module *module, struct lys_node *parent, const struct lys_node *node,\n                       struct unres_schema *unres, int shallow, int finalize)\n{\n    struct lys_node *retval = NULL, *iter, *p;\n    struct ly_ctx *ctx = module->ctx;\n    enum int_log_opts prev_ilo;\n    int i, j, rc;\n    unsigned int size, size1, size2;\n    struct unres_list_uniq *unique_info;\n    uint16_t flags;\n\n    struct lys_node_container *cont = NULL;\n    struct lys_node_container *cont_orig = (struct lys_node_container *)node;\n    struct lys_node_choice *choice = NULL;\n    struct lys_node_choice *choice_orig = (struct lys_node_choice *)node;\n    struct lys_node_leaf *leaf = NULL;\n    struct lys_node_leaf *leaf_orig = (struct lys_node_leaf *)node;\n    struct lys_node_leaflist *llist = NULL;\n    struct lys_node_leaflist *llist_orig = (struct lys_node_leaflist *)node;\n    struct lys_node_list *list = NULL;\n    struct lys_node_list *list_orig = (struct lys_node_list *)node;\n    struct lys_node_anydata *any = NULL;\n    struct lys_node_anydata *any_orig = (struct lys_node_anydata *)node;\n    struct lys_node_uses *uses = NULL;\n    struct lys_node_uses *uses_orig = (struct lys_node_uses *)node;\n    struct lys_node_rpc_action *rpc = NULL;\n    struct lys_node_inout *io = NULL;\n    struct lys_node_notif *ntf = NULL;\n    struct lys_node_case *cs = NULL;\n    struct lys_node_case *cs_orig = (struct lys_node_case *)node;\n\n    /* we cannot just duplicate memory since the strings are stored in\n     * dictionary and we need to update dictionary counters.\n     */\n\n    switch (node->nodetype) {\n    case LYS_CONTAINER:\n        cont = calloc(1, sizeof *cont);\n        retval = (struct lys_node *)cont;\n        break;\n\n    case LYS_CHOICE:\n        choice = calloc(1, sizeof *choice);\n        retval = (struct lys_node *)choice;\n        break;\n\n    case LYS_LEAF:\n        leaf = calloc(1, sizeof *leaf);\n        retval = (struct lys_node *)leaf;\n        break;\n\n    case LYS_LEAFLIST:\n        llist = calloc(1, sizeof *llist);\n        retval = (struct lys_node *)llist;\n        break;\n\n    case LYS_LIST:\n        list = calloc(1, sizeof *list);\n        /* copy keys now so that when adding children, it can be properly checked in this parent */\n        list->keys = calloc(list_orig->keys_size, sizeof *list->keys);\n        LY_CHECK_ERR_GOTO(!list->keys, LOGMEM(ctx), error);\n        list->keys_size = list_orig->keys_size;\n\n        retval = (struct lys_node *)list;\n        break;\n\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        any = calloc(1, sizeof *any);\n        retval = (struct lys_node *)any;\n        break;\n\n    case LYS_USES:\n        uses = calloc(1, sizeof *uses);\n        retval = (struct lys_node *)uses;\n        break;\n\n    case LYS_CASE:\n        cs = calloc(1, sizeof *cs);\n        retval = (struct lys_node *)cs;\n        break;\n\n    case LYS_RPC:\n    case LYS_ACTION:\n        rpc = calloc(1, sizeof *rpc);\n        retval = (struct lys_node *)rpc;\n        break;\n\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n        io = calloc(1, sizeof *io);\n        retval = (struct lys_node *)io;\n        break;\n\n    case LYS_NOTIF:\n        ntf = calloc(1, sizeof *ntf);\n        retval = (struct lys_node *)ntf;\n        break;\n\n    default:\n        LOGINT(ctx);\n        goto error;\n    }\n    LY_CHECK_ERR_RETURN(!retval, LOGMEM(ctx), NULL);\n\n    /*\n     * duplicate generic part of the structure\n     */\n    retval->name = lydict_insert(ctx, node->name, 0);\n    retval->dsc = lydict_insert(ctx, node->dsc, 0);\n    retval->ref = lydict_insert(ctx, node->ref, 0);\n    retval->flags = node->flags;\n\n    retval->module = module;\n    retval->nodetype = node->nodetype;\n\n    retval->prev = retval;\n\n    /* copying unresolved extensions is not supported */\n    if (unres_schema_find(unres, -1, (void *)&node->ext, UNRES_EXT) == -1) {\n        retval->ext_size = node->ext_size;\n        if (lys_ext_dup(ctx, module, node->ext, node->ext_size, retval, LYEXT_PAR_NODE, &retval->ext, shallow, unres)) {\n            goto error;\n        }\n    }\n\n    if (node->iffeature_size) {\n        retval->iffeature_size = node->iffeature_size;\n        retval->iffeature = calloc(retval->iffeature_size, sizeof *retval->iffeature);\n        LY_CHECK_ERR_GOTO(!retval->iffeature, LOGMEM(ctx), error);\n    }\n\n    if (!shallow) {\n        for (i = 0; i < node->iffeature_size; ++i) {\n            resolve_iffeature_getsizes(&node->iffeature[i], &size1, &size2);\n            if (size1) {\n                /* there is something to duplicate */\n\n                /* duplicate compiled expression */\n                size = (size1 / 4) + ((size1 % 4) ? 1 : 0);\n                retval->iffeature[i].expr = malloc(size * sizeof *retval->iffeature[i].expr);\n                LY_CHECK_ERR_GOTO(!retval->iffeature[i].expr, LOGMEM(ctx), error);\n                memcpy(retval->iffeature[i].expr, node->iffeature[i].expr, size * sizeof *retval->iffeature[i].expr);\n\n                /* list of feature pointer must be updated to point to the resulting tree */\n                retval->iffeature[i].features = calloc(size2, sizeof *retval->iffeature[i].features);\n                LY_CHECK_ERR_GOTO(!retval->iffeature[i].features, LOGMEM(ctx); free(retval->iffeature[i].expr), error);\n\n                for (j = 0; (unsigned int)j < size2; j++) {\n                    rc = unres_schema_dup(module, unres, &node->iffeature[i].features[j], UNRES_IFFEAT,\n                                          &retval->iffeature[i].features[j]);\n                    if (rc == EXIT_FAILURE) {\n                        /* feature is resolved in origin, so copy it\n                         * - duplication is used for instantiating groupings\n                         * and if-feature inside grouping is supposed to be\n                         * resolved inside the original grouping, so we want\n                         * to keep pointers to features from the grouping\n                         * context */\n                        retval->iffeature[i].features[j] = node->iffeature[i].features[j];\n                    } else if (rc == -1) {\n                        goto error;\n                    } /* else unres was duplicated */\n                }\n            }\n\n            /* duplicate if-feature's extensions */\n            retval->iffeature[i].ext_size = node->iffeature[i].ext_size;\n            if (lys_ext_dup(ctx, module, node->iffeature[i].ext, node->iffeature[i].ext_size,\n                            &retval->iffeature[i], LYEXT_PAR_IFFEATURE, &retval->iffeature[i].ext, shallow, unres)) {\n                goto error;\n            }\n        }\n\n        /* inherit config flags */\n        p = parent;\n        do {\n            for (iter = p; iter && (iter->nodetype == LYS_USES); iter = iter->parent);\n        } while (iter && iter->nodetype == LYS_AUGMENT && (p = ((struct lys_node_augment *)iter)->target));\n        if (iter) {\n            flags = iter->flags & LYS_CONFIG_MASK;\n        } else {\n            /* default */\n            flags = LYS_CONFIG_W;\n        }\n\n        switch (finalize) {\n        case 1:\n            /* inherit config flags */\n            if (retval->flags & LYS_CONFIG_SET) {\n                /* skip nodes with an explicit config value */\n                if ((flags & LYS_CONFIG_R) && (retval->flags & LYS_CONFIG_W)) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, \"true\", \"config\");\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"State nodes cannot have configuration nodes as children.\");\n                    goto error;\n                }\n                break;\n            }\n\n            if (retval->nodetype != LYS_USES) {\n                retval->flags = (retval->flags & ~LYS_CONFIG_MASK) | flags;\n            }\n\n            /* inherit status */\n            if ((parent->flags & LYS_STATUS_MASK) > (retval->flags & LYS_STATUS_MASK)) {\n                /* but do it only in case the parent has a stonger status */\n                retval->flags &= ~LYS_STATUS_MASK;\n                retval->flags |= (parent->flags & LYS_STATUS_MASK);\n            }\n            break;\n        case 2:\n            /* erase config flags */\n            retval->flags &= ~LYS_CONFIG_MASK;\n            retval->flags &= ~LYS_CONFIG_SET;\n            break;\n        }\n\n        /* connect it to the parent */\n        if (lys_node_addchild(parent, retval->module, retval, 0)) {\n            goto error;\n        }\n\n        /* go recursively */\n        if (!(node->nodetype & (LYS_LEAF | LYS_LEAFLIST))) {\n            LY_TREE_FOR(node->child, iter) {\n                if (iter->nodetype & LYS_GROUPING) {\n                    /* do not instantiate groupings */\n                    continue;\n                }\n                if (!lys_node_dup_recursion(module, retval, iter, unres, 0, finalize)) {\n                    goto error;\n                }\n            }\n        }\n    } else {\n        if (node->iffeature_size) {\n            memcpy(retval->iffeature, node->iffeature, retval->iffeature_size * sizeof *retval->iffeature);\n        }\n    }\n\n    /*\n     * duplicate specific part of the structure\n     */\n    switch (node->nodetype) {\n    case LYS_CONTAINER:\n        if (cont_orig->when) {\n            cont->when = lys_when_dup(module, cont_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!cont->when, error);\n        }\n        cont->presence = lydict_insert(ctx, cont_orig->presence, 0);\n\n        if (cont_orig->must) {\n            cont->must = lys_restr_dup(module, cont_orig->must, cont_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!cont->must, error);\n            cont->must_size = cont_orig->must_size;\n        }\n\n        /* typedefs are not needed in instantiated grouping, nor the deviation's shallow copy */\n\n        break;\n    case LYS_CHOICE:\n        if (choice_orig->when) {\n            choice->when = lys_when_dup(module, choice_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!choice->when, error);\n        }\n\n        if (!shallow) {\n            if (choice_orig->dflt) {\n                rc = lys_get_sibling(choice->child, lys_node_module(retval)->name, 0, choice_orig->dflt->name, 0,\n                                            LYS_ANYDATA | LYS_CASE | LYS_CONTAINER | LYS_LEAF | LYS_LEAFLIST | LYS_LIST,\n                                            (const struct lys_node **)&choice->dflt);\n                if (rc) {\n                    if (rc == EXIT_FAILURE) {\n                        LOGINT(ctx);\n                    }\n                    goto error;\n                }\n            } else {\n                /* useless to check return value, we don't know whether\n                * there really wasn't any default defined or it just hasn't\n                * been resolved, we just hope for the best :)\n                */\n                unres_schema_dup(module, unres, choice_orig, UNRES_CHOICE_DFLT, choice);\n            }\n        } else {\n            choice->dflt = choice_orig->dflt;\n        }\n        break;\n\n    case LYS_LEAF:\n        if (lys_type_dup(module, retval, &(leaf->type), &(leaf_orig->type), lys_ingrouping(retval), shallow, unres)) {\n            goto error;\n        }\n        leaf->units = lydict_insert(module->ctx, leaf_orig->units, 0);\n\n        if (leaf_orig->dflt) {\n            /* transform into JSON format, may not be possible later */\n            ly_ilo_change(NULL, ILO_IGNORE, &prev_ilo, NULL);\n            leaf->dflt = transform_schema2json(lys_main_module(leaf_orig->module), leaf_orig->dflt);\n            ly_ilo_restore(NULL, prev_ilo, NULL, 0);\n            if (!leaf->dflt) {\n                /* invalid identityref format or it was already transformed, so ignore the error here */\n                leaf->dflt = lydict_insert(ctx, leaf_orig->dflt, 0);\n            }\n        }\n\n        if (leaf_orig->must) {\n            leaf->must = lys_restr_dup(module, leaf_orig->must, leaf_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!leaf->must, error);\n            leaf->must_size = leaf_orig->must_size;\n        }\n\n        if (leaf_orig->when) {\n            leaf->when = lys_when_dup(module, leaf_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!leaf->when, error);\n        }\n        break;\n\n    case LYS_LEAFLIST:\n        if (lys_type_dup(module, retval, &(llist->type), &(llist_orig->type), lys_ingrouping(retval), shallow, unres)) {\n            goto error;\n        }\n        llist->units = lydict_insert(module->ctx, llist_orig->units, 0);\n\n        llist->min = llist_orig->min;\n        llist->max = llist_orig->max;\n\n        if (llist_orig->must) {\n            llist->must = lys_restr_dup(module, llist_orig->must, llist_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!llist->must, error);\n            llist->must_size = llist_orig->must_size;\n        }\n\n        if (llist_orig->dflt) {\n            llist->dflt = malloc(llist_orig->dflt_size * sizeof *llist->dflt);\n            LY_CHECK_ERR_GOTO(!llist->dflt, LOGMEM(ctx), error);\n            llist->dflt_size = llist_orig->dflt_size;\n\n            for (i = 0; i < llist->dflt_size; i++) {\n                llist->dflt[i] = lydict_insert(ctx, llist_orig->dflt[i], 0);\n            }\n        }\n\n        if (llist_orig->when) {\n            llist->when = lys_when_dup(module, llist_orig->when, shallow, unres);\n        }\n        break;\n\n    case LYS_LIST:\n        list->min = list_orig->min;\n        list->max = list_orig->max;\n\n        if (list_orig->must) {\n            list->must = lys_restr_dup(module, list_orig->must, list_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!list->must, error);\n            list->must_size = list_orig->must_size;\n        }\n\n        /* typedefs are not needed in instantiated grouping, nor the deviation's shallow copy */\n\n        if (list_orig->keys_size) {\n            /* already done */\n            /*list->keys = calloc(list_orig->keys_size, sizeof *list->keys);\n            LY_CHECK_ERR_GOTO(!list->keys, LOGMEM(ctx), error);\n            list->keys_size = list_orig->keys_size;*/\n            list->keys_str = lydict_insert(ctx, list_orig->keys_str, 0);\n\n            if (!shallow) {\n                if (unres_schema_add_node(module, unres, list, UNRES_LIST_KEYS, NULL) == -1) {\n                    goto error;\n                }\n            } else {\n                memcpy(list->keys, list_orig->keys, list_orig->keys_size * sizeof *list->keys);\n            }\n        }\n\n        if (list_orig->unique) {\n            list->unique = malloc(list_orig->unique_size * sizeof *list->unique);\n            LY_CHECK_ERR_GOTO(!list->unique, LOGMEM(ctx), error);\n            list->unique_size = list_orig->unique_size;\n\n            for (i = 0; i < list->unique_size; ++i) {\n                list->unique[i].expr = malloc(list_orig->unique[i].expr_size * sizeof *list->unique[i].expr);\n                LY_CHECK_ERR_GOTO(!list->unique[i].expr, LOGMEM(ctx), error);\n                list->unique[i].expr_size = list_orig->unique[i].expr_size;\n                for (j = 0; j < list->unique[i].expr_size; j++) {\n                    list->unique[i].expr[j] = lydict_insert(ctx, list_orig->unique[i].expr[j], 0);\n\n                    /* if it stays in unres list, duplicate it also there */\n                    unique_info = malloc(sizeof *unique_info);\n                    LY_CHECK_ERR_GOTO(!unique_info, LOGMEM(ctx), error);\n                    unique_info->list = (struct lys_node *)list;\n                    unique_info->expr = list->unique[i].expr[j];\n                    unique_info->trg_type = &list->unique[i].trg_type;\n                    unres_schema_dup(module, unres, &list_orig, UNRES_LIST_UNIQ, unique_info);\n                }\n            }\n        }\n\n        if (list_orig->when) {\n            list->when = lys_when_dup(module, list_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!list->when, error);\n        }\n        break;\n\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        if (any_orig->must) {\n            any->must = lys_restr_dup(module, any_orig->must, any_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!any->must, error);\n            any->must_size = any_orig->must_size;\n        }\n\n        if (any_orig->when) {\n            any->when = lys_when_dup(module, any_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!any->when, error);\n        }\n        break;\n\n    case LYS_USES:\n        uses->grp = uses_orig->grp;\n\n        if (uses_orig->when) {\n            uses->when = lys_when_dup(module, uses_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!uses->when, error);\n        }\n        /* it is not needed to duplicate refine, nor augment. They are already applied to the uses children */\n        break;\n\n    case LYS_CASE:\n        if (cs_orig->when) {\n            cs->when = lys_when_dup(module, cs_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!cs->when, error);\n        }\n        break;\n\n    case LYS_ACTION:\n    case LYS_RPC:\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n    case LYS_NOTIF:\n        /* typedefs are not needed in instantiated grouping, nor the deviation's shallow copy */\n        break;\n\n    default:\n        /* LY_NODE_AUGMENT */\n        LOGINT(ctx);\n        goto error;\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(retval, NULL, 0);\n    return NULL;\n}",
        "func": "static struct lys_node *\nlys_node_dup_recursion(struct lys_module *module, struct lys_node *parent, const struct lys_node *node,\n                       struct unres_schema *unres, int shallow, int finalize)\n{\n    struct lys_node *retval = NULL, *iter, *p;\n    struct ly_ctx *ctx = module->ctx;\n    enum int_log_opts prev_ilo;\n    int i, j, rc;\n    unsigned int size, size1, size2;\n    struct unres_list_uniq *unique_info;\n    uint16_t flags;\n\n    struct lys_node_container *cont = NULL;\n    struct lys_node_container *cont_orig = (struct lys_node_container *)node;\n    struct lys_node_choice *choice = NULL;\n    struct lys_node_choice *choice_orig = (struct lys_node_choice *)node;\n    struct lys_node_leaf *leaf = NULL;\n    struct lys_node_leaf *leaf_orig = (struct lys_node_leaf *)node;\n    struct lys_node_leaflist *llist = NULL;\n    struct lys_node_leaflist *llist_orig = (struct lys_node_leaflist *)node;\n    struct lys_node_list *list = NULL;\n    struct lys_node_list *list_orig = (struct lys_node_list *)node;\n    struct lys_node_anydata *any = NULL;\n    struct lys_node_anydata *any_orig = (struct lys_node_anydata *)node;\n    struct lys_node_uses *uses = NULL;\n    struct lys_node_uses *uses_orig = (struct lys_node_uses *)node;\n    struct lys_node_rpc_action *rpc = NULL;\n    struct lys_node_inout *io = NULL;\n    struct lys_node_notif *ntf = NULL;\n    struct lys_node_case *cs = NULL;\n    struct lys_node_case *cs_orig = (struct lys_node_case *)node;\n\n    /* we cannot just duplicate memory since the strings are stored in\n     * dictionary and we need to update dictionary counters.\n     */\n\n    switch (node->nodetype) {\n    case LYS_CONTAINER:\n        cont = calloc(1, sizeof *cont);\n        retval = (struct lys_node *)cont;\n        break;\n\n    case LYS_CHOICE:\n        choice = calloc(1, sizeof *choice);\n        retval = (struct lys_node *)choice;\n        break;\n\n    case LYS_LEAF:\n        leaf = calloc(1, sizeof *leaf);\n        retval = (struct lys_node *)leaf;\n        break;\n\n    case LYS_LEAFLIST:\n        llist = calloc(1, sizeof *llist);\n        retval = (struct lys_node *)llist;\n        break;\n\n    case LYS_LIST:\n        list = calloc(1, sizeof *list);\n        /* copy keys now so that when adding children, it can be properly checked in this parent */\n        list->keys = calloc(list_orig->keys_size, sizeof *list->keys);\n        LY_CHECK_ERR_GOTO(!list->keys, LOGMEM(ctx), error);\n        list->keys_size = list_orig->keys_size;\n\n        retval = (struct lys_node *)list;\n        break;\n\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        any = calloc(1, sizeof *any);\n        retval = (struct lys_node *)any;\n        break;\n\n    case LYS_USES:\n        uses = calloc(1, sizeof *uses);\n        retval = (struct lys_node *)uses;\n        break;\n\n    case LYS_CASE:\n        cs = calloc(1, sizeof *cs);\n        retval = (struct lys_node *)cs;\n        break;\n\n    case LYS_RPC:\n    case LYS_ACTION:\n        rpc = calloc(1, sizeof *rpc);\n        retval = (struct lys_node *)rpc;\n        break;\n\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n        io = calloc(1, sizeof *io);\n        retval = (struct lys_node *)io;\n        break;\n\n    case LYS_NOTIF:\n        ntf = calloc(1, sizeof *ntf);\n        retval = (struct lys_node *)ntf;\n        break;\n\n    default:\n        LOGINT(ctx);\n        goto error;\n    }\n    LY_CHECK_ERR_RETURN(!retval, LOGMEM(ctx), NULL);\n\n    /*\n     * duplicate generic part of the structure\n     */\n    retval->name = lydict_insert(ctx, node->name, 0);\n    retval->dsc = lydict_insert(ctx, node->dsc, 0);\n    retval->ref = lydict_insert(ctx, node->ref, 0);\n    retval->flags = node->flags;\n\n    retval->module = module;\n    retval->nodetype = node->nodetype;\n\n    retval->prev = retval;\n\n    /* copying unresolved extensions is not supported */\n    if (unres_schema_find(unres, -1, (void *)&node->ext, UNRES_EXT) == -1) {\n        retval->ext_size = node->ext_size;\n        if (lys_ext_dup(ctx, module, node->ext, node->ext_size, retval, LYEXT_PAR_NODE, &retval->ext, shallow, unres)) {\n            goto error;\n        }\n    }\n\n    if (node->iffeature_size) {\n        retval->iffeature_size = node->iffeature_size;\n        retval->iffeature = calloc(retval->iffeature_size, sizeof *retval->iffeature);\n        LY_CHECK_ERR_GOTO(!retval->iffeature, LOGMEM(ctx), error);\n    }\n\n    if (!shallow) {\n        for (i = 0; i < node->iffeature_size; ++i) {\n            resolve_iffeature_getsizes(&node->iffeature[i], &size1, &size2);\n            if (size1) {\n                /* there is something to duplicate */\n\n                /* duplicate compiled expression */\n                size = (size1 / 4) + ((size1 % 4) ? 1 : 0);\n                retval->iffeature[i].expr = malloc(size * sizeof *retval->iffeature[i].expr);\n                LY_CHECK_ERR_GOTO(!retval->iffeature[i].expr, LOGMEM(ctx), error);\n                memcpy(retval->iffeature[i].expr, node->iffeature[i].expr, size * sizeof *retval->iffeature[i].expr);\n\n                /* list of feature pointer must be updated to point to the resulting tree */\n                retval->iffeature[i].features = calloc(size2, sizeof *retval->iffeature[i].features);\n                LY_CHECK_ERR_GOTO(!retval->iffeature[i].features, LOGMEM(ctx); free(retval->iffeature[i].expr), error);\n\n                for (j = 0; (unsigned int)j < size2; j++) {\n                    rc = unres_schema_dup(module, unres, &node->iffeature[i].features[j], UNRES_IFFEAT,\n                                          &retval->iffeature[i].features[j]);\n                    if (rc == EXIT_FAILURE) {\n                        /* feature is resolved in origin, so copy it\n                         * - duplication is used for instantiating groupings\n                         * and if-feature inside grouping is supposed to be\n                         * resolved inside the original grouping, so we want\n                         * to keep pointers to features from the grouping\n                         * context */\n                        retval->iffeature[i].features[j] = node->iffeature[i].features[j];\n                    } else if (rc == -1) {\n                        goto error;\n                    } /* else unres was duplicated */\n                }\n            }\n\n            /* duplicate if-feature's extensions */\n            retval->iffeature[i].ext_size = node->iffeature[i].ext_size;\n            if (lys_ext_dup(ctx, module, node->iffeature[i].ext, node->iffeature[i].ext_size,\n                            &retval->iffeature[i], LYEXT_PAR_IFFEATURE, &retval->iffeature[i].ext, shallow, unres)) {\n                goto error;\n            }\n        }\n\n        /* inherit config flags */\n        p = parent;\n        do {\n            for (iter = p; iter && (iter->nodetype == LYS_USES); iter = iter->parent);\n        } while (iter && iter->nodetype == LYS_AUGMENT && (p = ((struct lys_node_augment *)iter)->target));\n        if (iter) {\n            flags = iter->flags & LYS_CONFIG_MASK;\n        } else {\n            /* default */\n            flags = LYS_CONFIG_W;\n        }\n\n        switch (finalize) {\n        case 1:\n            /* inherit config flags */\n            if (retval->flags & LYS_CONFIG_SET) {\n                /* skip nodes with an explicit config value */\n                if ((flags & LYS_CONFIG_R) && (retval->flags & LYS_CONFIG_W)) {\n                    LOGVAL(ctx, LYE_INARG, LY_VLOG_LYS, retval, \"true\", \"config\");\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_PREV, NULL, \"State nodes cannot have configuration nodes as children.\");\n                    goto error;\n                }\n                break;\n            }\n\n            if (retval->nodetype != LYS_USES) {\n                retval->flags = (retval->flags & ~LYS_CONFIG_MASK) | flags;\n            }\n\n            /* inherit status */\n            if ((parent->flags & LYS_STATUS_MASK) > (retval->flags & LYS_STATUS_MASK)) {\n                /* but do it only in case the parent has a stonger status */\n                retval->flags &= ~LYS_STATUS_MASK;\n                retval->flags |= (parent->flags & LYS_STATUS_MASK);\n            }\n            break;\n        case 2:\n            /* erase config flags */\n            retval->flags &= ~LYS_CONFIG_MASK;\n            retval->flags &= ~LYS_CONFIG_SET;\n            break;\n        }\n\n        /* connect it to the parent */\n        if (lys_node_addchild(parent, retval->module, retval, 0)) {\n            goto error;\n        }\n\n        /* go recursively */\n        if (!(node->nodetype & (LYS_LEAF | LYS_LEAFLIST))) {\n            LY_TREE_FOR(node->child, iter) {\n                if (iter->nodetype & LYS_GROUPING) {\n                    /* do not instantiate groupings */\n                    continue;\n                }\n                if (!lys_node_dup_recursion(module, retval, iter, unres, 0, finalize)) {\n                    goto error;\n                }\n            }\n        }\n    } else {\n        if (node->iffeature_size) {\n            memcpy(retval->iffeature, node->iffeature, retval->iffeature_size * sizeof *retval->iffeature);\n        }\n    }\n\n    /*\n     * duplicate specific part of the structure\n     */\n    switch (node->nodetype) {\n    case LYS_CONTAINER:\n        if (cont_orig->when) {\n            cont->when = lys_when_dup(module, cont_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!cont->when, error);\n        }\n        cont->presence = lydict_insert(ctx, cont_orig->presence, 0);\n\n        if (cont_orig->must) {\n            cont->must = lys_restr_dup(module, cont_orig->must, cont_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!cont->must, error);\n            cont->must_size = cont_orig->must_size;\n        }\n\n        /* typedefs are not needed in instantiated grouping, nor the deviation's shallow copy */\n\n        break;\n    case LYS_CHOICE:\n        if (choice_orig->when) {\n            choice->when = lys_when_dup(module, choice_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!choice->when, error);\n        }\n\n        if (!shallow) {\n            if (choice_orig->dflt) {\n                rc = lys_get_sibling(choice->child, lys_node_module(retval)->name, 0, choice_orig->dflt->name, 0,\n                                            LYS_ANYDATA | LYS_CASE | LYS_CONTAINER | LYS_LEAF | LYS_LEAFLIST | LYS_LIST,\n                                            (const struct lys_node **)&choice->dflt);\n                if (rc) {\n                    if (rc == EXIT_FAILURE) {\n                        LOGINT(ctx);\n                    }\n                    goto error;\n                }\n            } else {\n                /* useless to check return value, we don't know whether\n                * there really wasn't any default defined or it just hasn't\n                * been resolved, we just hope for the best :)\n                */\n                unres_schema_dup(module, unres, choice_orig, UNRES_CHOICE_DFLT, choice);\n            }\n        } else {\n            choice->dflt = choice_orig->dflt;\n        }\n        break;\n\n    case LYS_LEAF:\n        if (lys_type_dup(module, retval, &(leaf->type), &(leaf_orig->type), lys_ingrouping(retval), shallow, unres)) {\n            goto error;\n        }\n        leaf->units = lydict_insert(module->ctx, leaf_orig->units, 0);\n\n        if (leaf_orig->dflt) {\n            /* transform into JSON format, may not be possible later */\n            ly_ilo_change(NULL, ILO_IGNORE, &prev_ilo, NULL);\n            leaf->dflt = transform_schema2json(lys_main_module(leaf_orig->module), leaf_orig->dflt);\n            ly_ilo_restore(NULL, prev_ilo, NULL, 0);\n            if (!leaf->dflt) {\n                /* invalid identityref format or it was already transformed, so ignore the error here */\n                leaf->dflt = lydict_insert(ctx, leaf_orig->dflt, 0);\n            }\n        }\n\n        if (leaf_orig->must) {\n            leaf->must = lys_restr_dup(module, leaf_orig->must, leaf_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!leaf->must, error);\n            leaf->must_size = leaf_orig->must_size;\n        }\n\n        if (leaf_orig->when) {\n            leaf->when = lys_when_dup(module, leaf_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!leaf->when, error);\n        }\n        break;\n\n    case LYS_LEAFLIST:\n        if (lys_type_dup(module, retval, &(llist->type), &(llist_orig->type), lys_ingrouping(retval), shallow, unres)) {\n            goto error;\n        }\n        llist->units = lydict_insert(module->ctx, llist_orig->units, 0);\n\n        llist->min = llist_orig->min;\n        llist->max = llist_orig->max;\n\n        if (llist_orig->must) {\n            llist->must = lys_restr_dup(module, llist_orig->must, llist_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!llist->must, error);\n            llist->must_size = llist_orig->must_size;\n        }\n\n        if (llist_orig->dflt) {\n            llist->dflt = malloc(llist_orig->dflt_size * sizeof *llist->dflt);\n            LY_CHECK_ERR_GOTO(!llist->dflt, LOGMEM(ctx), error);\n            llist->dflt_size = llist_orig->dflt_size;\n\n            for (i = 0; i < llist->dflt_size; i++) {\n                llist->dflt[i] = lydict_insert(ctx, llist_orig->dflt[i], 0);\n            }\n        }\n\n        if (llist_orig->when) {\n            llist->when = lys_when_dup(module, llist_orig->when, shallow, unres);\n        }\n        break;\n\n    case LYS_LIST:\n        list->min = list_orig->min;\n        list->max = list_orig->max;\n\n        if (list_orig->must) {\n            list->must = lys_restr_dup(module, list_orig->must, list_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!list->must, error);\n            list->must_size = list_orig->must_size;\n        }\n\n        /* typedefs are not needed in instantiated grouping, nor the deviation's shallow copy */\n\n        if (list_orig->keys_size) {\n            /* already done */\n            /*list->keys = calloc(list_orig->keys_size, sizeof *list->keys);\n            LY_CHECK_ERR_GOTO(!list->keys, LOGMEM(ctx), error);\n            list->keys_size = list_orig->keys_size;*/\n            list->keys_str = lydict_insert(ctx, list_orig->keys_str, 0);\n\n            if (!shallow) {\n                if (unres_schema_add_node(module, unres, list, UNRES_LIST_KEYS, NULL) == -1) {\n                    goto error;\n                }\n            } else {\n                memcpy(list->keys, list_orig->keys, list_orig->keys_size * sizeof *list->keys);\n            }\n        }\n\n        if (list_orig->unique) {\n            list->unique = malloc(list_orig->unique_size * sizeof *list->unique);\n            LY_CHECK_ERR_GOTO(!list->unique, LOGMEM(ctx), error);\n            list->unique_size = list_orig->unique_size;\n\n            for (i = 0; i < list->unique_size; ++i) {\n                list->unique[i].expr = malloc(list_orig->unique[i].expr_size * sizeof *list->unique[i].expr);\n                LY_CHECK_ERR_GOTO(!list->unique[i].expr, LOGMEM(ctx), error);\n                list->unique[i].expr_size = list_orig->unique[i].expr_size;\n                for (j = 0; j < list->unique[i].expr_size; j++) {\n                    list->unique[i].expr[j] = lydict_insert(ctx, list_orig->unique[i].expr[j], 0);\n\n                    /* if it stays in unres list, duplicate it also there */\n                    unique_info = malloc(sizeof *unique_info);\n                    LY_CHECK_ERR_GOTO(!unique_info, LOGMEM(ctx), error);\n                    unique_info->list = (struct lys_node *)list;\n                    unique_info->expr = list->unique[i].expr[j];\n                    unique_info->trg_type = &list->unique[i].trg_type;\n                    unres_schema_dup(module, unres, &list_orig, UNRES_LIST_UNIQ, unique_info);\n                }\n            }\n        }\n\n        if (list_orig->when) {\n            list->when = lys_when_dup(module, list_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!list->when, error);\n        }\n        break;\n\n    case LYS_ANYXML:\n    case LYS_ANYDATA:\n        if (any_orig->must) {\n            any->must = lys_restr_dup(module, any_orig->must, any_orig->must_size, shallow, unres);\n            LY_CHECK_GOTO(!any->must, error);\n            any->must_size = any_orig->must_size;\n        }\n\n        if (any_orig->when) {\n            any->when = lys_when_dup(module, any_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!any->when, error);\n        }\n        break;\n\n    case LYS_USES:\n        uses->grp = uses_orig->grp;\n\n        if (uses_orig->when) {\n            uses->when = lys_when_dup(module, uses_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!uses->when, error);\n        }\n        /* it is not needed to duplicate refine, nor augment. They are already applied to the uses children */\n        break;\n\n    case LYS_CASE:\n        if (cs_orig->when) {\n            cs->when = lys_when_dup(module, cs_orig->when, shallow, unres);\n            LY_CHECK_GOTO(!cs->when, error);\n        }\n        break;\n\n    case LYS_ACTION:\n    case LYS_RPC:\n    case LYS_INPUT:\n    case LYS_OUTPUT:\n    case LYS_NOTIF:\n        /* typedefs are not needed in instantiated grouping, nor the deviation's shallow copy */\n        break;\n\n    default:\n        /* LY_NODE_AUGMENT */\n        LOGINT(ctx);\n        goto error;\n    }\n\n    return retval;\n\nerror:\n    lys_node_free(ctx, retval, NULL, 0);\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -451,6 +451,6 @@\n     return retval;\n \n error:\n-    lys_node_free(retval, NULL, 0);\n+    lys_node_free(ctx, retval, NULL, 0);\n     return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    lys_node_free(retval, NULL, 0);"
            ],
            "added_lines": [
                "    lys_node_free(ctx, retval, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-23308",
        "func_name": "jerryscript-project/jerryscript/parser_process_group_expression",
        "description": "There is an Assertion 'context_p->stack_top_uint8 == LEXER_EXPRESSION_START' at js-parser-expr.c:3565 in parser_parse_expression in JerryScript 2.2.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/b5c2323954fde19af568c69bf5db791fc24c64e3",
        "commit_title": "Fix assignment lookahead in parser_process_group_expression",
        "commit_text": " This patch fixes #3815 and fixes #3819.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik frobert@inf.u-szeged.hu",
        "func_before": "static bool\nparser_process_group_expression (parser_context_t *context_p, /**< context */\n                                 size_t *grouping_level_p) /**< grouping level */\n{\n  JERRY_ASSERT (*grouping_level_p >= PARSER_GROUPING_LEVEL_INCREASE);\n  (*grouping_level_p) -= PARSER_GROUPING_LEVEL_INCREASE;\n\n  uint8_t token = context_p->stack_top_uint8;\n\n  if (token == LEXER_COMMA_SEP_LIST)\n  {\n    parser_push_result (context_p);\n    parser_flush_cbc (context_p);\n  }\n\n  parser_stack_pop_uint8 (context_p);\n  lexer_next_token (context_p);\n\n  if (context_p->token.type == LEXER_ASSIGN)\n  {\n    uint32_t flags = 0;\n#if ENABLED (JERRY_ES2015)\n    if (JERRY_UNLIKELY (token == LEXER_LEFT_PAREN))\n    {\n      flags = PARSER_PATTERN_GROUP_EXPR;\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n    parser_append_binary_single_assignment_token (context_p, flags);\n    lexer_next_token (context_p);\n    return true;\n  }\n\n  return false;\n}",
        "func": "static void\nparser_process_group_expression (parser_context_t *context_p, /**< context */\n                                 size_t *grouping_level_p) /**< grouping level */\n{\n  JERRY_ASSERT (*grouping_level_p >= PARSER_GROUPING_LEVEL_INCREASE);\n  (*grouping_level_p) -= PARSER_GROUPING_LEVEL_INCREASE;\n\n  uint8_t token = context_p->stack_top_uint8;\n\n  if (token == LEXER_COMMA_SEP_LIST)\n  {\n    parser_push_result (context_p);\n    parser_flush_cbc (context_p);\n  }\n\n  parser_stack_pop_uint8 (context_p);\n  lexer_next_token (context_p);\n\n#if ENABLED (JERRY_ES2015)\n  /* Lookahead for anonymous function declaration after '=' token when the assignment base is LHS expression\n     with a single indentifier in it. e.g.: (a) = function () {} */\n  if (JERRY_UNLIKELY (context_p->token.type == LEXER_ASSIGN\n                      && PARSER_IS_PUSH_LITERALS_WITH_THIS (context_p->last_cbc_opcode)\n                      && context_p->last_cbc.literal_type == LEXER_IDENT_LITERAL))\n  {\n    parser_stack_push_uint8 (context_p, LEXER_ASSIGN_GROUP_EXPR);\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static bool\n+static void\n parser_process_group_expression (parser_context_t *context_p, /**< context */\n                                  size_t *grouping_level_p) /**< grouping level */\n {\n@@ -16,19 +16,15 @@\n   parser_stack_pop_uint8 (context_p);\n   lexer_next_token (context_p);\n \n-  if (context_p->token.type == LEXER_ASSIGN)\n+#if ENABLED (JERRY_ES2015)\n+  /* Lookahead for anonymous function declaration after '=' token when the assignment base is LHS expression\n+     with a single indentifier in it. e.g.: (a) = function () {} */\n+  if (JERRY_UNLIKELY (context_p->token.type == LEXER_ASSIGN\n+                      && PARSER_IS_PUSH_LITERALS_WITH_THIS (context_p->last_cbc_opcode)\n+                      && context_p->last_cbc.literal_type == LEXER_IDENT_LITERAL))\n   {\n-    uint32_t flags = 0;\n-#if ENABLED (JERRY_ES2015)\n-    if (JERRY_UNLIKELY (token == LEXER_LEFT_PAREN))\n-    {\n-      flags = PARSER_PATTERN_GROUP_EXPR;\n-    }\n+    parser_stack_push_uint8 (context_p, LEXER_ASSIGN_GROUP_EXPR);\n+  }\n #endif /* ENABLED (JERRY_ES2015) */\n-    parser_append_binary_single_assignment_token (context_p, flags);\n-    lexer_next_token (context_p);\n-    return true;\n-  }\n \n-  return false;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static bool",
                "  if (context_p->token.type == LEXER_ASSIGN)",
                "    uint32_t flags = 0;",
                "#if ENABLED (JERRY_ES2015)",
                "    if (JERRY_UNLIKELY (token == LEXER_LEFT_PAREN))",
                "    {",
                "      flags = PARSER_PATTERN_GROUP_EXPR;",
                "    }",
                "    parser_append_binary_single_assignment_token (context_p, flags);",
                "    lexer_next_token (context_p);",
                "    return true;",
                "  }",
                "  return false;"
            ],
            "added_lines": [
                "static void",
                "#if ENABLED (JERRY_ES2015)",
                "  /* Lookahead for anonymous function declaration after '=' token when the assignment base is LHS expression",
                "     with a single indentifier in it. e.g.: (a) = function () {} */",
                "  if (JERRY_UNLIKELY (context_p->token.type == LEXER_ASSIGN",
                "                      && PARSER_IS_PUSH_LITERALS_WITH_THIS (context_p->last_cbc_opcode)",
                "                      && context_p->last_cbc.literal_type == LEXER_IDENT_LITERAL))",
                "    parser_stack_push_uint8 (context_p, LEXER_ASSIGN_GROUP_EXPR);",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-23308",
        "func_name": "jerryscript-project/jerryscript/parser_parse_expression",
        "description": "There is an Assertion 'context_p->stack_top_uint8 == LEXER_EXPRESSION_START' at js-parser-expr.c:3565 in parser_parse_expression in JerryScript 2.2.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/b5c2323954fde19af568c69bf5db791fc24c64e3",
        "commit_title": "Fix assignment lookahead in parser_process_group_expression",
        "commit_text": " This patch fixes #3815 and fixes #3819.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik frobert@inf.u-szeged.hu",
        "func_before": "void\nparser_parse_expression (parser_context_t *context_p, /**< context */\n                         int options) /**< option flags */\n{\n  size_t grouping_level = (options & PARSE_EXPR_LEFT_HAND_SIDE);\n\n  parser_stack_push_uint8 (context_p, LEXER_EXPRESSION_START);\n\n  if (options & PARSE_EXPR_HAS_LITERAL)\n  {\n    JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_LITERAL);\n    goto process_unary_expression;\n  }\n\n  while (true)\n  {\nparse_unary_expression:\n    if (parser_parse_unary_expression (context_p, &grouping_level))\n    {\n      parser_process_binary_opcodes (context_p, 0);\n      break;\n    }\n\n    while (true)\n    {\nprocess_unary_expression:\n      parser_process_unary_expression (context_p, grouping_level);\n\n      if (JERRY_LIKELY (grouping_level != PARSE_EXPR_LEFT_HAND_SIDE))\n      {\n        uint8_t min_prec_treshold = 0;\n\n        if (LEXER_IS_BINARY_OP_TOKEN (context_p->token.type))\n        {\n          min_prec_treshold = parser_binary_precedence_table[context_p->token.type - LEXER_FIRST_BINARY_OP];\n\n#if ENABLED (JERRY_ES2015)\n          /* Check for BINARY_LVALUE tokens + LEXER_LOGICAL_OR + LEXER_LOGICAL_AND + LEXER_EXPONENTIATION */\n          if ((min_prec_treshold == PARSER_RIGHT_TO_LEFT_ORDER_EXPONENTIATION)\n              || (min_prec_treshold <= PARSER_RIGHT_TO_LEFT_ORDER_MAX_PRECEDENCE\n                  && min_prec_treshold != PARSER_RIGHT_TO_LEFT_ORDER_TERNARY_PRECEDENCE))\n          {\n            /* Right-to-left evaluation order. */\n            min_prec_treshold++;\n          }\n#else /* !ENABLED (JERRY_ES2015) */\n          /* Check for BINARY_LVALUE tokens + LEXER_LOGICAL_OR + LEXER_LOGICAL_AND */\n          if (min_prec_treshold <= PARSER_RIGHT_TO_LEFT_ORDER_MAX_PRECEDENCE\n              && min_prec_treshold != PARSER_RIGHT_TO_LEFT_ORDER_TERNARY_PRECEDENCE)\n          {\n            /* Right-to-left evaluation order. */\n            min_prec_treshold++;\n          }\n#endif /* ENABLED (JERRY_ES2015) */\n        }\n\n        parser_process_binary_opcodes (context_p, min_prec_treshold);\n      }\n\n      if (context_p->token.type == LEXER_RIGHT_PAREN\n          && (context_p->stack_top_uint8 == LEXER_LEFT_PAREN\n              || context_p->stack_top_uint8 == LEXER_COMMA_SEP_LIST))\n      {\n        if (parser_process_group_expression (context_p, &grouping_level))\n        {\n          goto parse_unary_expression;\n        }\n        continue;\n      }\n\n      if (JERRY_UNLIKELY (context_p->token.type == LEXER_QUESTION_MARK)\n          && (grouping_level != PARSE_EXPR_LEFT_HAND_SIDE)\n          && parser_process_ternary_expression (context_p, grouping_level))\n      {\n        continue;\n      }\n      break;\n    }\n\n    if (grouping_level == PARSE_EXPR_LEFT_HAND_SIDE)\n    {\n      break;\n    }\n\n    if (JERRY_UNLIKELY (context_p->token.type == LEXER_COMMA)\n        && (!(options & PARSE_EXPR_NO_COMMA) || grouping_level >= PARSER_GROUPING_LEVEL_INCREASE))\n    {\n      parser_process_expression_sequence (context_p);\n      continue;\n    }\n\n    if (LEXER_IS_BINARY_OP_TOKEN (context_p->token.type))\n    {\n      parser_append_binary_token (context_p);\n      lexer_next_token (context_p);\n      continue;\n    }\n    break;\n  }\n\n  if (grouping_level >= PARSER_GROUPING_LEVEL_INCREASE)\n  {\n    parser_raise_error (context_p, PARSER_ERR_RIGHT_PAREN_EXPECTED);\n  }\n\n  JERRY_ASSERT (context_p->stack_top_uint8 == LEXER_EXPRESSION_START);\n  parser_stack_pop_uint8 (context_p);\n\n  if (!(options & PARSE_EXPR_NO_PUSH_RESULT))\n  {\n    parser_push_result (context_p);\n  }\n}",
        "func": "void\nparser_parse_expression (parser_context_t *context_p, /**< context */\n                         int options) /**< option flags */\n{\n  size_t grouping_level = (options & PARSE_EXPR_LEFT_HAND_SIDE);\n\n  parser_stack_push_uint8 (context_p, LEXER_EXPRESSION_START);\n\n  if (options & PARSE_EXPR_HAS_LITERAL)\n  {\n    JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_LITERAL);\n    goto process_unary_expression;\n  }\n\n  while (true)\n  {\n    if (parser_parse_unary_expression (context_p, &grouping_level))\n    {\n      parser_process_binary_opcodes (context_p, 0);\n      break;\n    }\n\n    while (true)\n    {\nprocess_unary_expression:\n      parser_process_unary_expression (context_p, grouping_level);\n\n      if (JERRY_LIKELY (grouping_level != PARSE_EXPR_LEFT_HAND_SIDE))\n      {\n        uint8_t min_prec_treshold = 0;\n\n        if (LEXER_IS_BINARY_OP_TOKEN (context_p->token.type))\n        {\n          min_prec_treshold = parser_binary_precedence_table[context_p->token.type - LEXER_FIRST_BINARY_OP];\n\n#if ENABLED (JERRY_ES2015)\n          /* Check for BINARY_LVALUE tokens + LEXER_LOGICAL_OR + LEXER_LOGICAL_AND + LEXER_EXPONENTIATION */\n          if ((min_prec_treshold == PARSER_RIGHT_TO_LEFT_ORDER_EXPONENTIATION)\n              || (min_prec_treshold <= PARSER_RIGHT_TO_LEFT_ORDER_MAX_PRECEDENCE\n                  && min_prec_treshold != PARSER_RIGHT_TO_LEFT_ORDER_TERNARY_PRECEDENCE))\n          {\n            /* Right-to-left evaluation order. */\n            min_prec_treshold++;\n          }\n#else /* !ENABLED (JERRY_ES2015) */\n          /* Check for BINARY_LVALUE tokens + LEXER_LOGICAL_OR + LEXER_LOGICAL_AND */\n          if (min_prec_treshold <= PARSER_RIGHT_TO_LEFT_ORDER_MAX_PRECEDENCE\n              && min_prec_treshold != PARSER_RIGHT_TO_LEFT_ORDER_TERNARY_PRECEDENCE)\n          {\n            /* Right-to-left evaluation order. */\n            min_prec_treshold++;\n          }\n#endif /* ENABLED (JERRY_ES2015) */\n        }\n\n        parser_process_binary_opcodes (context_p, min_prec_treshold);\n      }\n\n      if (context_p->token.type == LEXER_RIGHT_PAREN\n          && (context_p->stack_top_uint8 == LEXER_LEFT_PAREN\n              || context_p->stack_top_uint8 == LEXER_COMMA_SEP_LIST))\n      {\n        parser_process_group_expression (context_p, &grouping_level);\n        continue;\n      }\n\n      if (JERRY_UNLIKELY (context_p->token.type == LEXER_QUESTION_MARK)\n          && (grouping_level != PARSE_EXPR_LEFT_HAND_SIDE)\n          && parser_process_ternary_expression (context_p, grouping_level))\n      {\n        continue;\n      }\n      break;\n    }\n\n    if (grouping_level == PARSE_EXPR_LEFT_HAND_SIDE)\n    {\n      break;\n    }\n\n    if (JERRY_UNLIKELY (context_p->token.type == LEXER_COMMA)\n        && (!(options & PARSE_EXPR_NO_COMMA) || grouping_level >= PARSER_GROUPING_LEVEL_INCREASE))\n    {\n      parser_process_expression_sequence (context_p);\n      continue;\n    }\n\n    if (LEXER_IS_BINARY_OP_TOKEN (context_p->token.type))\n    {\n      parser_append_binary_token (context_p);\n      lexer_next_token (context_p);\n      continue;\n    }\n    break;\n  }\n\n  if (grouping_level >= PARSER_GROUPING_LEVEL_INCREASE)\n  {\n    parser_raise_error (context_p, PARSER_ERR_RIGHT_PAREN_EXPECTED);\n  }\n\n  JERRY_ASSERT (context_p->stack_top_uint8 == LEXER_EXPRESSION_START);\n  parser_stack_pop_uint8 (context_p);\n\n  if (!(options & PARSE_EXPR_NO_PUSH_RESULT))\n  {\n    parser_push_result (context_p);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,6 @@\n \n   while (true)\n   {\n-parse_unary_expression:\n     if (parser_parse_unary_expression (context_p, &grouping_level))\n     {\n       parser_process_binary_opcodes (context_p, 0);\n@@ -61,10 +60,7 @@\n           && (context_p->stack_top_uint8 == LEXER_LEFT_PAREN\n               || context_p->stack_top_uint8 == LEXER_COMMA_SEP_LIST))\n       {\n-        if (parser_process_group_expression (context_p, &grouping_level))\n-        {\n-          goto parse_unary_expression;\n-        }\n+        parser_process_group_expression (context_p, &grouping_level);\n         continue;\n       }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "parse_unary_expression:",
                "        if (parser_process_group_expression (context_p, &grouping_level))",
                "        {",
                "          goto parse_unary_expression;",
                "        }"
            ],
            "added_lines": [
                "        parser_process_group_expression (context_p, &grouping_level);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-23308",
        "func_name": "jerryscript-project/jerryscript/parser_append_binary_single_assignment_token",
        "description": "There is an Assertion 'context_p->stack_top_uint8 == LEXER_EXPRESSION_START' at js-parser-expr.c:3565 in parser_parse_expression in JerryScript 2.2.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/b5c2323954fde19af568c69bf5db791fc24c64e3",
        "commit_title": "Fix assignment lookahead in parser_process_group_expression",
        "commit_text": " This patch fixes #3815 and fixes #3819.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik frobert@inf.u-szeged.hu",
        "func_before": "static uint8_t\nparser_append_binary_single_assignment_token (parser_context_t *context_p, /**< context */\n                                              uint32_t pattern_flags) /**< pattern flags */\n{\n  JERRY_UNUSED (pattern_flags);\n\n  /* Unlike other tokens, the whole byte code is saved for binary\n   * assignment, since it has multiple forms depending on the\n   * previous instruction. */\n\n  uint8_t assign_opcode = CBC_ASSIGN;\n\n  if (PARSER_IS_PUSH_LITERALS_WITH_THIS (context_p->last_cbc_opcode)\n      && context_p->last_cbc.literal_type == LEXER_IDENT_LITERAL)\n  {\n    parser_check_invalid_assign (context_p);\n\n    uint16_t literal_index;\n\n    switch (context_p->last_cbc_opcode)\n    {\n      case CBC_PUSH_LITERAL:\n      {\n        literal_index = context_p->last_cbc.literal_index;\n        context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n        break;\n      }\n      case CBC_PUSH_TWO_LITERALS:\n      {\n        literal_index = context_p->last_cbc.value;\n        context_p->last_cbc_opcode = CBC_PUSH_LITERAL;\n        break;\n      }\n      case CBC_PUSH_THIS_LITERAL:\n      {\n        literal_index = context_p->last_cbc.literal_index;\n        context_p->last_cbc_opcode = CBC_PUSH_THIS;\n        parser_flush_cbc (context_p);\n        break;\n      }\n      default:\n      {\n        JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_THREE_LITERALS);\n        literal_index = context_p->last_cbc.third_literal_index;\n        context_p->last_cbc_opcode = CBC_PUSH_TWO_LITERALS;\n        break;\n      }\n    }\n\n    assign_opcode = CBC_ASSIGN_SET_IDENT;\n\n#if ENABLED (JERRY_ES2015)\n    if (pattern_flags & PARSER_PATTERN_GROUP_EXPR)\n    {\n      parser_stack_push_uint8 (context_p, LEXER_ASSIGN_GROUP_EXPR);\n    }\n\n    if (!(pattern_flags & (PARSER_PATTERN_LET | PARSER_PATTERN_CONST | PARSER_PATTERN_LOCAL)))\n    {\n      if (scanner_literal_is_const_reg (context_p, literal_index))\n      {\n        parser_stack_push_uint8 (context_p, LEXER_ASSIGN_CONST);\n      }\n    }\n    else if (literal_index < PARSER_REGISTER_START)\n    {\n      assign_opcode = CBC_INIT_LET;\n\n      if (scanner_literal_is_created (context_p, literal_index))\n      {\n        assign_opcode = CBC_ASSIGN_LET_CONST;\n      }\n      else if (pattern_flags & PARSER_PATTERN_CONST)\n      {\n        assign_opcode = CBC_INIT_CONST;\n      }\n      else if (pattern_flags & PARSER_PATTERN_LOCAL)\n      {\n        assign_opcode = CBC_INIT_ARG_OR_CATCH;\n      }\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    parser_stack_push_uint16 (context_p, literal_index);\n    JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_LITERAL, assign_opcode));\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP)\n  {\n    JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP, CBC_ASSIGN));\n    context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP_LITERAL)\n  {\n    if (context_p->last_cbc.literal_type != LEXER_IDENT_LITERAL)\n    {\n      JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP_LITERAL, CBC_ASSIGN_PROP_LITERAL));\n      parser_stack_push_uint16 (context_p, context_p->last_cbc.literal_index);\n      assign_opcode = CBC_ASSIGN_PROP_LITERAL;\n      context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n    }\n    else\n    {\n      context_p->last_cbc_opcode = CBC_PUSH_LITERAL;\n    }\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP_LITERAL_LITERAL)\n  {\n    JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP_LITERAL_LITERAL, CBC_PUSH_TWO_LITERALS));\n    context_p->last_cbc_opcode = CBC_PUSH_TWO_LITERALS;\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP_THIS_LITERAL)\n  {\n    if (context_p->last_cbc.literal_type != LEXER_IDENT_LITERAL)\n    {\n      JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP_THIS_LITERAL, CBC_ASSIGN_PROP_THIS_LITERAL));\n      parser_stack_push_uint16 (context_p, context_p->last_cbc.literal_index);\n      assign_opcode = CBC_ASSIGN_PROP_THIS_LITERAL;\n      context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n    }\n    else\n    {\n      context_p->last_cbc_opcode = CBC_PUSH_THIS_LITERAL;\n    }\n  }\n#if ENABLED (JERRY_ES2015)\n  else if (context_p->last_cbc_opcode == PARSER_TO_EXT_OPCODE (CBC_EXT_PUSH_SUPER_PROP_LITERAL))\n  {\n    context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (CBC_EXT_SUPER_PROP_LITERAL_ASSIGNMENT_REFERENCE);\n    assign_opcode = CBC_ASSIGN_SUPER;\n  }\n  else if (context_p->last_cbc_opcode == PARSER_TO_EXT_OPCODE (CBC_EXT_PUSH_SUPER_PROP))\n  {\n    context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (CBC_EXT_SUPER_PROP_ASSIGNMENT_REFERENCE);\n    assign_opcode = CBC_ASSIGN_SUPER;\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n  else\n  {\n    /* Invalid LeftHandSide expression. */\n#if ENABLED (JERRY_ES2015)\n    parser_check_invalid_new_target (context_p, CBC_ASSIGN);\n#endif /* ENABLED (JERRY_ES2015) */\n\n    parser_emit_cbc_ext (context_p, CBC_EXT_THROW_REFERENCE_ERROR);\n  }\n\n  parser_stack_push_uint8 (context_p, assign_opcode);\n  parser_stack_push_uint8 (context_p, LEXER_ASSIGN);\n\n  return assign_opcode;\n}",
        "func": "static uint8_t\nparser_append_binary_single_assignment_token (parser_context_t *context_p, /**< context */\n                                              uint32_t pattern_flags) /**< pattern flags */\n{\n  JERRY_UNUSED (pattern_flags);\n\n  /* Unlike other tokens, the whole byte code is saved for binary\n   * assignment, since it has multiple forms depending on the\n   * previous instruction. */\n\n  uint8_t assign_opcode = CBC_ASSIGN;\n\n  if (PARSER_IS_PUSH_LITERALS_WITH_THIS (context_p->last_cbc_opcode)\n      && context_p->last_cbc.literal_type == LEXER_IDENT_LITERAL)\n  {\n    parser_check_invalid_assign (context_p);\n\n    uint16_t literal_index;\n\n    switch (context_p->last_cbc_opcode)\n    {\n      case CBC_PUSH_LITERAL:\n      {\n        literal_index = context_p->last_cbc.literal_index;\n        context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n        break;\n      }\n      case CBC_PUSH_TWO_LITERALS:\n      {\n        literal_index = context_p->last_cbc.value;\n        context_p->last_cbc_opcode = CBC_PUSH_LITERAL;\n        break;\n      }\n      case CBC_PUSH_THIS_LITERAL:\n      {\n        literal_index = context_p->last_cbc.literal_index;\n        context_p->last_cbc_opcode = CBC_PUSH_THIS;\n        parser_flush_cbc (context_p);\n        break;\n      }\n      default:\n      {\n        JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_THREE_LITERALS);\n        literal_index = context_p->last_cbc.third_literal_index;\n        context_p->last_cbc_opcode = CBC_PUSH_TWO_LITERALS;\n        break;\n      }\n    }\n\n    assign_opcode = CBC_ASSIGN_SET_IDENT;\n\n#if ENABLED (JERRY_ES2015)\n    if (!(pattern_flags & (PARSER_PATTERN_LET | PARSER_PATTERN_CONST | PARSER_PATTERN_LOCAL)))\n    {\n      if (scanner_literal_is_const_reg (context_p, literal_index))\n      {\n        parser_stack_push_uint8 (context_p, LEXER_ASSIGN_CONST);\n      }\n    }\n    else if (literal_index < PARSER_REGISTER_START)\n    {\n      assign_opcode = CBC_INIT_LET;\n\n      if (scanner_literal_is_created (context_p, literal_index))\n      {\n        assign_opcode = CBC_ASSIGN_LET_CONST;\n      }\n      else if (pattern_flags & PARSER_PATTERN_CONST)\n      {\n        assign_opcode = CBC_INIT_CONST;\n      }\n      else if (pattern_flags & PARSER_PATTERN_LOCAL)\n      {\n        assign_opcode = CBC_INIT_ARG_OR_CATCH;\n      }\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    parser_stack_push_uint16 (context_p, literal_index);\n    JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_LITERAL, assign_opcode));\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP)\n  {\n    JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP, CBC_ASSIGN));\n    context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP_LITERAL)\n  {\n    if (context_p->last_cbc.literal_type != LEXER_IDENT_LITERAL)\n    {\n      JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP_LITERAL, CBC_ASSIGN_PROP_LITERAL));\n      parser_stack_push_uint16 (context_p, context_p->last_cbc.literal_index);\n      assign_opcode = CBC_ASSIGN_PROP_LITERAL;\n      context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n    }\n    else\n    {\n      context_p->last_cbc_opcode = CBC_PUSH_LITERAL;\n    }\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP_LITERAL_LITERAL)\n  {\n    JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP_LITERAL_LITERAL, CBC_PUSH_TWO_LITERALS));\n    context_p->last_cbc_opcode = CBC_PUSH_TWO_LITERALS;\n  }\n  else if (context_p->last_cbc_opcode == CBC_PUSH_PROP_THIS_LITERAL)\n  {\n    if (context_p->last_cbc.literal_type != LEXER_IDENT_LITERAL)\n    {\n      JERRY_ASSERT (CBC_SAME_ARGS (CBC_PUSH_PROP_THIS_LITERAL, CBC_ASSIGN_PROP_THIS_LITERAL));\n      parser_stack_push_uint16 (context_p, context_p->last_cbc.literal_index);\n      assign_opcode = CBC_ASSIGN_PROP_THIS_LITERAL;\n      context_p->last_cbc_opcode = PARSER_CBC_UNAVAILABLE;\n    }\n    else\n    {\n      context_p->last_cbc_opcode = CBC_PUSH_THIS_LITERAL;\n    }\n  }\n#if ENABLED (JERRY_ES2015)\n  else if (context_p->last_cbc_opcode == PARSER_TO_EXT_OPCODE (CBC_EXT_PUSH_SUPER_PROP_LITERAL))\n  {\n    context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (CBC_EXT_SUPER_PROP_LITERAL_ASSIGNMENT_REFERENCE);\n    assign_opcode = CBC_ASSIGN_SUPER;\n  }\n  else if (context_p->last_cbc_opcode == PARSER_TO_EXT_OPCODE (CBC_EXT_PUSH_SUPER_PROP))\n  {\n    context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (CBC_EXT_SUPER_PROP_ASSIGNMENT_REFERENCE);\n    assign_opcode = CBC_ASSIGN_SUPER;\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n  else\n  {\n    /* Invalid LeftHandSide expression. */\n#if ENABLED (JERRY_ES2015)\n    parser_check_invalid_new_target (context_p, CBC_ASSIGN);\n#endif /* ENABLED (JERRY_ES2015) */\n\n    parser_emit_cbc_ext (context_p, CBC_EXT_THROW_REFERENCE_ERROR);\n  }\n\n  parser_stack_push_uint8 (context_p, assign_opcode);\n  parser_stack_push_uint8 (context_p, LEXER_ASSIGN);\n\n  return assign_opcode;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -50,11 +50,6 @@\n     assign_opcode = CBC_ASSIGN_SET_IDENT;\n \n #if ENABLED (JERRY_ES2015)\n-    if (pattern_flags & PARSER_PATTERN_GROUP_EXPR)\n-    {\n-      parser_stack_push_uint8 (context_p, LEXER_ASSIGN_GROUP_EXPR);\n-    }\n-\n     if (!(pattern_flags & (PARSER_PATTERN_LET | PARSER_PATTERN_CONST | PARSER_PATTERN_LOCAL)))\n     {\n       if (scanner_literal_is_const_reg (context_p, literal_index))",
        "diff_line_info": {
            "deleted_lines": [
                "    if (pattern_flags & PARSER_PATTERN_GROUP_EXPR)",
                "    {",
                "      parser_stack_push_uint8 (context_p, LEXER_ASSIGN_GROUP_EXPR);",
                "    }",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2020-23310",
        "func_name": "jerryscript-project/jerryscript/parser_parse_function_statement",
        "description": "There is an Assertion 'context_p->next_scanner_info_p->type == SCANNER_TYPE_FUNCTION' failed at js-parser-statm.c:733 in parser_parse_function_statement in JerryScript 2.2.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/14dd68afa50a82ed7a43d25508d701dcaa631e3e",
        "commit_title": "Fix parsing function statements containing invalid tokens",
        "commit_text": " Fixes #3821.  JerryScript-DCO-1.0-Signed-off-by: Dniel Btyai dbatyai@inf.u-szeged.hu",
        "func_before": "static void\nparser_parse_function_statement (parser_context_t *context_p) /**< context */\n{\n  JERRY_ASSERT (context_p->token.type == LEXER_KEYW_FUNCTION);\n\n#if ENABLED (JERRY_ES2015)\n  if (JERRY_UNLIKELY (parser_statement_flags[context_p->stack_top_uint8] & PARSER_STATM_SINGLE_STATM))\n  {\n    if (context_p->status_flags & PARSER_IS_STRICT)\n    {\n      parser_raise_error (context_p, PARSER_ERR_LEXICAL_SINGLE_STATEMENT);\n    }\n\n    if (context_p->stack_top_uint8 == PARSER_STATEMENT_IF\n        || context_p->stack_top_uint8 == PARSER_STATEMENT_ELSE)\n    {\n      /* There must be a parser error later if this check fails. */\n      if (context_p->next_scanner_info_p->source_p == context_p->source_p)\n      {\n        parser_push_block_context (context_p, true);\n      }\n    }\n    else if (context_p->stack_top_uint8 == PARSER_STATEMENT_LABEL)\n    {\n      parser_stack_iterator_t iterator;\n      parser_stack_iterator_init (context_p, &iterator);\n      parser_stack_iterator_skip (&iterator, sizeof (parser_label_statement_t) + 1);\n\n      while (true)\n      {\n        uint8_t type = parser_stack_iterator_read_uint8 (&iterator);\n\n        if (type == PARSER_STATEMENT_LABEL)\n        {\n          parser_stack_iterator_skip (&iterator, sizeof (parser_label_statement_t) + 1);\n          continue;\n        }\n\n        if (parser_statement_flags[type] & PARSER_STATM_HAS_BLOCK)\n        {\n          break;\n        }\n\n        parser_raise_error (context_p, PARSER_ERR_LABELLED_FUNC_NOT_IN_BLOCK);\n      }\n    }\n    else\n    {\n      parser_raise_error (context_p, PARSER_ERR_LEXICAL_SINGLE_STATEMENT);\n    }\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n#if ENABLED (JERRY_DEBUGGER)\n  parser_line_counter_t debugger_line = context_p->token.line;\n  parser_line_counter_t debugger_column = context_p->token.column;\n#endif /* ENABLED (JERRY_DEBUGGER) */\n\n#if ENABLED (JERRY_ES2015)\n  bool is_generator_function = false;\n\n  if (lexer_consume_generator (context_p))\n  {\n    is_generator_function = true;\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n  lexer_expect_identifier (context_p, LEXER_NEW_IDENT_LITERAL);\n  JERRY_ASSERT (context_p->token.type == LEXER_LITERAL\n                && context_p->token.lit_location.type == LEXER_IDENT_LITERAL);\n\n#if ENABLED (JERRY_ES2015)\n  if (context_p->next_scanner_info_p->source_p == context_p->source_p)\n  {\n    JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED);\n    parser_raise_error (context_p, PARSER_ERR_VARIABLE_REDECLARED);\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n#if ENABLED (JERRY_ES2015_MODULE_SYSTEM)\n  uint16_t function_name_index = context_p->lit_object.index;\n  parser_module_append_export_name (context_p);\n  context_p->status_flags &= (uint32_t) ~(PARSER_MODULE_STORE_IDENT);\n#endif /* ENABLED (JERRY_ES2015_MODULE_SYSTEM) */\n\n  uint32_t status_flags = PARSER_FUNCTION_CLOSURE;\n\n  if (context_p->token.keyword_type >= LEXER_FIRST_NON_STRICT_ARGUMENTS)\n  {\n    status_flags |= PARSER_HAS_NON_STRICT_ARG;\n  }\n\n  JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_FUNCTION);\n\n#if ENABLED (JERRY_ES2015)\n  if (is_generator_function)\n  {\n    status_flags |= PARSER_IS_GENERATOR_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n  }\n\n  if (context_p->next_scanner_info_p->u8_arg & SCANNER_FUNCTION_ASYNC)\n  {\n    status_flags |= PARSER_IS_ASYNC_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n#if ENABLED (JERRY_DEBUGGER)\n  if (JERRY_CONTEXT (debugger_flags) & JERRY_DEBUGGER_CONNECTED)\n  {\n    lexer_literal_t *name_p = context_p->lit_object.literal_p;\n    jerry_debugger_send_string (JERRY_DEBUGGER_FUNCTION_NAME,\n                                JERRY_DEBUGGER_NO_SUBTYPE,\n                                name_p->u.char_p,\n                                name_p->prop.length);\n\n    /* Reset token position for the function. */\n    context_p->token.line = debugger_line;\n    context_p->token.column = debugger_column;\n  }\n#endif /* ENABLED (JERRY_DEBUGGER) */\n\n  JERRY_ASSERT (context_p->scope_stack_top >= 2);\n  parser_scope_stack_t *scope_stack_p = context_p->scope_stack_p + context_p->scope_stack_top - 2;\n\n  uint16_t literal_index = context_p->lit_object.index;\n\n  while (literal_index != scope_stack_p->map_from)\n  {\n    scope_stack_p--;\n\n    JERRY_ASSERT (scope_stack_p >= context_p->scope_stack_p);\n  }\n\n  JERRY_ASSERT (scope_stack_p[1].map_from == PARSER_SCOPE_STACK_FUNC);\n\n#if ENABLED (JERRY_ES2015)\n  if (!(context_p->status_flags & PARSER_IS_STRICT)\n      && (scope_stack_p >= context_p->scope_stack_p + context_p->scope_stack_global_end))\n  {\n    bool copy_value = true;\n\n    parser_scope_stack_t *stack_p = context_p->scope_stack_p;\n\n    while (stack_p < scope_stack_p)\n    {\n      if (literal_index == stack_p->map_from\n          && (stack_p->map_to & PARSER_SCOPE_STACK_NO_FUNCTION_COPY))\n      {\n        copy_value = false;\n        break;\n      }\n      stack_p++;\n    }\n\n    if (copy_value)\n    {\n      stack_p = context_p->scope_stack_p;\n\n      while (stack_p < scope_stack_p)\n      {\n        if (literal_index == stack_p->map_from)\n        {\n          JERRY_ASSERT (!(stack_p->map_to & PARSER_SCOPE_STACK_NO_FUNCTION_COPY));\n\n          uint16_t map_to = scanner_decode_map_to (stack_p);\n          uint16_t opcode = ((map_to >= PARSER_REGISTER_START) ? CBC_ASSIGN_LITERAL_SET_IDENT\n                                                               : CBC_COPY_TO_GLOBAL);\n\n          parser_emit_cbc_literal_value (context_p,\n                                         opcode,\n                                         scanner_decode_map_to (scope_stack_p),\n                                         map_to);\n          break;\n        }\n        stack_p++;\n      }\n\n      parser_flush_cbc (context_p);\n    }\n\n    if (JERRY_UNLIKELY (context_p->stack_top_uint8 == PARSER_STATEMENT_PRIVATE_SCOPE\n                        || context_p->stack_top_uint8 == PARSER_STATEMENT_PRIVATE_CONTEXT))\n    {\n      parser_pop_block_context (context_p);\n    }\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n  lexer_literal_t *literal_p = PARSER_GET_LITERAL ((size_t) scope_stack_p[1].map_to);\n\n  JERRY_ASSERT ((literal_p->type == LEXER_UNUSED_LITERAL || literal_p->type == LEXER_FUNCTION_LITERAL)\n                && literal_p->status_flags == 0);\n\n  ecma_compiled_code_t *compiled_code_p = parser_parse_function (context_p, status_flags);\n\n  if (literal_p->type == LEXER_FUNCTION_LITERAL)\n  {\n    ecma_bytecode_deref (literal_p->u.bytecode_p);\n  }\n\n  literal_p->u.bytecode_p = compiled_code_p;\n  literal_p->type = LEXER_FUNCTION_LITERAL;\n\n#if ENABLED (JERRY_ES2015)\n  parser_compiled_code_set_function_name (context_p, compiled_code_p, function_name_index, 0);\n#endif /* ENABLED (JERRY_ES2015) */\n\n  lexer_next_token (context_p);\n}",
        "func": "static void\nparser_parse_function_statement (parser_context_t *context_p) /**< context */\n{\n  JERRY_ASSERT (context_p->token.type == LEXER_KEYW_FUNCTION);\n\n#if ENABLED (JERRY_ES2015)\n  if (JERRY_UNLIKELY (parser_statement_flags[context_p->stack_top_uint8] & PARSER_STATM_SINGLE_STATM))\n  {\n    if (context_p->status_flags & PARSER_IS_STRICT)\n    {\n      parser_raise_error (context_p, PARSER_ERR_LEXICAL_SINGLE_STATEMENT);\n    }\n\n    if (context_p->stack_top_uint8 == PARSER_STATEMENT_IF\n        || context_p->stack_top_uint8 == PARSER_STATEMENT_ELSE)\n    {\n      /* There must be a parser error later if this check fails. */\n      if (context_p->next_scanner_info_p->source_p == context_p->source_p)\n      {\n        parser_push_block_context (context_p, true);\n      }\n    }\n    else if (context_p->stack_top_uint8 == PARSER_STATEMENT_LABEL)\n    {\n      parser_stack_iterator_t iterator;\n      parser_stack_iterator_init (context_p, &iterator);\n      parser_stack_iterator_skip (&iterator, sizeof (parser_label_statement_t) + 1);\n\n      while (true)\n      {\n        uint8_t type = parser_stack_iterator_read_uint8 (&iterator);\n\n        if (type == PARSER_STATEMENT_LABEL)\n        {\n          parser_stack_iterator_skip (&iterator, sizeof (parser_label_statement_t) + 1);\n          continue;\n        }\n\n        if (parser_statement_flags[type] & PARSER_STATM_HAS_BLOCK)\n        {\n          break;\n        }\n\n        parser_raise_error (context_p, PARSER_ERR_LABELLED_FUNC_NOT_IN_BLOCK);\n      }\n    }\n    else\n    {\n      parser_raise_error (context_p, PARSER_ERR_LEXICAL_SINGLE_STATEMENT);\n    }\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n#if ENABLED (JERRY_DEBUGGER)\n  parser_line_counter_t debugger_line = context_p->token.line;\n  parser_line_counter_t debugger_column = context_p->token.column;\n#endif /* ENABLED (JERRY_DEBUGGER) */\n\n#if ENABLED (JERRY_ES2015)\n  bool is_generator_function = false;\n\n  if (lexer_consume_generator (context_p))\n  {\n    is_generator_function = true;\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n  lexer_expect_identifier (context_p, LEXER_NEW_IDENT_LITERAL);\n  JERRY_ASSERT (context_p->token.type == LEXER_LITERAL\n                && context_p->token.lit_location.type == LEXER_IDENT_LITERAL);\n\n#if ENABLED (JERRY_ES2015)\n  if (context_p->next_scanner_info_p->source_p == context_p->source_p\n      && context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED)\n  {\n    parser_raise_error (context_p, PARSER_ERR_VARIABLE_REDECLARED);\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n#if ENABLED (JERRY_ES2015_MODULE_SYSTEM)\n  uint16_t function_name_index = context_p->lit_object.index;\n  parser_module_append_export_name (context_p);\n  context_p->status_flags &= (uint32_t) ~(PARSER_MODULE_STORE_IDENT);\n#endif /* ENABLED (JERRY_ES2015_MODULE_SYSTEM) */\n\n  uint32_t status_flags = PARSER_FUNCTION_CLOSURE;\n\n  if (context_p->token.keyword_type >= LEXER_FIRST_NON_STRICT_ARGUMENTS)\n  {\n    status_flags |= PARSER_HAS_NON_STRICT_ARG;\n  }\n\n#if ENABLED (JERRY_ES2015)\n  if (is_generator_function)\n  {\n    status_flags |= PARSER_IS_GENERATOR_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n  }\n\n  if (context_p->next_scanner_info_p->u8_arg & SCANNER_FUNCTION_ASYNC)\n  {\n    status_flags |= PARSER_IS_ASYNC_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n#if ENABLED (JERRY_DEBUGGER)\n  if (JERRY_CONTEXT (debugger_flags) & JERRY_DEBUGGER_CONNECTED)\n  {\n    lexer_literal_t *name_p = context_p->lit_object.literal_p;\n    jerry_debugger_send_string (JERRY_DEBUGGER_FUNCTION_NAME,\n                                JERRY_DEBUGGER_NO_SUBTYPE,\n                                name_p->u.char_p,\n                                name_p->prop.length);\n\n    /* Reset token position for the function. */\n    context_p->token.line = debugger_line;\n    context_p->token.column = debugger_column;\n  }\n#endif /* ENABLED (JERRY_DEBUGGER) */\n\n  JERRY_ASSERT (context_p->scope_stack_top >= 2);\n  parser_scope_stack_t *scope_stack_p = context_p->scope_stack_p + context_p->scope_stack_top - 2;\n\n  uint16_t literal_index = context_p->lit_object.index;\n\n  while (literal_index != scope_stack_p->map_from)\n  {\n    scope_stack_p--;\n\n    JERRY_ASSERT (scope_stack_p >= context_p->scope_stack_p);\n  }\n\n  JERRY_ASSERT (scope_stack_p[1].map_from == PARSER_SCOPE_STACK_FUNC);\n\n#if ENABLED (JERRY_ES2015)\n  if (!(context_p->status_flags & PARSER_IS_STRICT)\n      && (scope_stack_p >= context_p->scope_stack_p + context_p->scope_stack_global_end))\n  {\n    bool copy_value = true;\n\n    parser_scope_stack_t *stack_p = context_p->scope_stack_p;\n\n    while (stack_p < scope_stack_p)\n    {\n      if (literal_index == stack_p->map_from\n          && (stack_p->map_to & PARSER_SCOPE_STACK_NO_FUNCTION_COPY))\n      {\n        copy_value = false;\n        break;\n      }\n      stack_p++;\n    }\n\n    if (copy_value)\n    {\n      stack_p = context_p->scope_stack_p;\n\n      while (stack_p < scope_stack_p)\n      {\n        if (literal_index == stack_p->map_from)\n        {\n          JERRY_ASSERT (!(stack_p->map_to & PARSER_SCOPE_STACK_NO_FUNCTION_COPY));\n\n          uint16_t map_to = scanner_decode_map_to (stack_p);\n          uint16_t opcode = ((map_to >= PARSER_REGISTER_START) ? CBC_ASSIGN_LITERAL_SET_IDENT\n                                                               : CBC_COPY_TO_GLOBAL);\n\n          parser_emit_cbc_literal_value (context_p,\n                                         opcode,\n                                         scanner_decode_map_to (scope_stack_p),\n                                         map_to);\n          break;\n        }\n        stack_p++;\n      }\n\n      parser_flush_cbc (context_p);\n    }\n\n    if (JERRY_UNLIKELY (context_p->stack_top_uint8 == PARSER_STATEMENT_PRIVATE_SCOPE\n                        || context_p->stack_top_uint8 == PARSER_STATEMENT_PRIVATE_CONTEXT))\n    {\n      parser_pop_block_context (context_p);\n    }\n  }\n#endif /* ENABLED (JERRY_ES2015) */\n\n  lexer_literal_t *literal_p = PARSER_GET_LITERAL ((size_t) scope_stack_p[1].map_to);\n\n  JERRY_ASSERT ((literal_p->type == LEXER_UNUSED_LITERAL || literal_p->type == LEXER_FUNCTION_LITERAL)\n                && literal_p->status_flags == 0);\n\n  ecma_compiled_code_t *compiled_code_p = parser_parse_function (context_p, status_flags);\n\n  if (literal_p->type == LEXER_FUNCTION_LITERAL)\n  {\n    ecma_bytecode_deref (literal_p->u.bytecode_p);\n  }\n\n  literal_p->u.bytecode_p = compiled_code_p;\n  literal_p->type = LEXER_FUNCTION_LITERAL;\n\n#if ENABLED (JERRY_ES2015)\n  parser_compiled_code_set_function_name (context_p, compiled_code_p, function_name_index, 0);\n#endif /* ENABLED (JERRY_ES2015) */\n\n  lexer_next_token (context_p);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -70,9 +70,9 @@\n                 && context_p->token.lit_location.type == LEXER_IDENT_LITERAL);\n \n #if ENABLED (JERRY_ES2015)\n-  if (context_p->next_scanner_info_p->source_p == context_p->source_p)\n-  {\n-    JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED);\n+  if (context_p->next_scanner_info_p->source_p == context_p->source_p\n+      && context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED)\n+  {\n     parser_raise_error (context_p, PARSER_ERR_VARIABLE_REDECLARED);\n   }\n #endif /* ENABLED (JERRY_ES2015) */\n@@ -89,8 +89,6 @@\n   {\n     status_flags |= PARSER_HAS_NON_STRICT_ARG;\n   }\n-\n-  JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_FUNCTION);\n \n #if ENABLED (JERRY_ES2015)\n   if (is_generator_function)",
        "diff_line_info": {
            "deleted_lines": [
                "  if (context_p->next_scanner_info_p->source_p == context_p->source_p)",
                "  {",
                "    JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED);",
                "",
                "  JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_FUNCTION);"
            ],
            "added_lines": [
                "  if (context_p->next_scanner_info_p->source_p == context_p->source_p",
                "      && context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED)",
                "  {"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-23311",
        "func_name": "jerryscript-project/jerryscript/parser_reparse_as_common_identifier",
        "description": "There is an Assertion 'context_p->token.type == LEXER_RIGHT_BRACE || context_p->token.type == LEXER_ASSIGN || context_p->token.type == LEXER_COMMA' failed at js-parser-expr.c:3230 in parser_parse_object_initializer in JerryScript 2.2.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/3bf4b7c9a4c923e66d5e836b598d17501865dc18",
        "commit_title": "Fix PropertyDefinition parsing in ObjectInitializer",
        "commit_text": " This patch fixes #3822 and fixes #3823 and fixes #3824 and fixes #3825.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik frobert@inf.u-szeged.hu",
        "func_before": "static void\nparser_reparse_as_common_identifier (parser_context_t *context_p, /**< context */\n                                     parser_line_counter_t start_line, /**< start line */\n                                     parser_line_counter_t start_column) /**< start column */\n{\n  context_p->source_p = context_p->token.lit_location.char_p;\n  context_p->line = start_line;\n  context_p->column = start_column;\n\n  lexer_next_token (context_p);\n\n  if (context_p->token.type != LEXER_LITERAL\n      || context_p->token.lit_location.type != LEXER_IDENT_LITERAL)\n  {\n    parser_raise_error (context_p, PARSER_ERR_IDENTIFIER_EXPECTED);\n  }\n\n  lexer_construct_literal_object (context_p,\n                                  &context_p->token.lit_location,\n                                  LEXER_IDENT_LITERAL);\n\n}",
        "func": "static void\nparser_reparse_as_common_identifier (parser_context_t *context_p, /**< context */\n                                     parser_line_counter_t start_line, /**< start line */\n                                     parser_line_counter_t start_column) /**< start column */\n{\n  /* context_p->token.lit_location.char_p is showing the character after the string start,\n     so it is not suitable for reparsing as identifier.\n     e.g.: { 'foo' } */\n  if (context_p->token.lit_location.type != LEXER_IDENT_LITERAL)\n  {\n    parser_raise_error (context_p, PARSER_ERR_IDENTIFIER_EXPECTED);\n  }\n\n  context_p->source_p = context_p->token.lit_location.char_p;\n  context_p->line = start_line;\n  context_p->column = start_column;\n\n  lexer_next_token (context_p);\n\n  if (context_p->token.type != LEXER_LITERAL)\n  {\n    parser_raise_error (context_p, PARSER_ERR_IDENTIFIER_EXPECTED);\n  }\n\n  JERRY_ASSERT (context_p->token.lit_location.type == LEXER_IDENT_LITERAL);\n\n  lexer_construct_literal_object (context_p,\n                                  &context_p->token.lit_location,\n                                  LEXER_IDENT_LITERAL);\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,17 +3,26 @@\n                                      parser_line_counter_t start_line, /**< start line */\n                                      parser_line_counter_t start_column) /**< start column */\n {\n+  /* context_p->token.lit_location.char_p is showing the character after the string start,\n+     so it is not suitable for reparsing as identifier.\n+     e.g.: { 'foo' } */\n+  if (context_p->token.lit_location.type != LEXER_IDENT_LITERAL)\n+  {\n+    parser_raise_error (context_p, PARSER_ERR_IDENTIFIER_EXPECTED);\n+  }\n+\n   context_p->source_p = context_p->token.lit_location.char_p;\n   context_p->line = start_line;\n   context_p->column = start_column;\n \n   lexer_next_token (context_p);\n \n-  if (context_p->token.type != LEXER_LITERAL\n-      || context_p->token.lit_location.type != LEXER_IDENT_LITERAL)\n+  if (context_p->token.type != LEXER_LITERAL)\n   {\n     parser_raise_error (context_p, PARSER_ERR_IDENTIFIER_EXPECTED);\n   }\n+\n+  JERRY_ASSERT (context_p->token.lit_location.type == LEXER_IDENT_LITERAL);\n \n   lexer_construct_literal_object (context_p,\n                                   &context_p->token.lit_location,",
        "diff_line_info": {
            "deleted_lines": [
                "  if (context_p->token.type != LEXER_LITERAL",
                "      || context_p->token.lit_location.type != LEXER_IDENT_LITERAL)"
            ],
            "added_lines": [
                "  /* context_p->token.lit_location.char_p is showing the character after the string start,",
                "     so it is not suitable for reparsing as identifier.",
                "     e.g.: { 'foo' } */",
                "  if (context_p->token.lit_location.type != LEXER_IDENT_LITERAL)",
                "  {",
                "    parser_raise_error (context_p, PARSER_ERR_IDENTIFIER_EXPECTED);",
                "  }",
                "",
                "  if (context_p->token.type != LEXER_LITERAL)",
                "",
                "  JERRY_ASSERT (context_p->token.lit_location.type == LEXER_IDENT_LITERAL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-23322",
        "func_name": "jerryscript-project/jerryscript/lexer_expect_object_literal_id",
        "description": "There is an Assertion in 'context_p->token.type == LEXER_RIGHT_BRACE || context_p->token.type == LEXER_ASSIGN || context_p->token.type == LEXER_COMMA' in parser_parse_object_initializer in JerryScript 2.2.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/16dc78e11f8904406a7c5e4ea036d4661fcbc1ac",
        "commit_title": "Asterisk should be ignored by object initializers.",
        "commit_text": " Fixes #3869  JerryScript-DCO-1.0-Signed-off-by: Zoltan Herczeg zherczeg.u-szeged@partner.samsung.com",
        "func_before": "void\nlexer_expect_object_literal_id (parser_context_t *context_p, /**< context */\n                                uint32_t ident_opts) /**< lexer_obj_ident_opts_t option bits */\n{\n  lexer_skip_spaces (context_p);\n\n  if (context_p->source_p >= context_p->source_end_p)\n  {\n    parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n  }\n\n#if ENABLED (JERRY_ES2015)\n  int is_class_method = ((ident_opts & LEXER_OBJ_IDENT_CLASS_METHOD)\n                         && !(ident_opts & LEXER_OBJ_IDENT_ONLY_IDENTIFIERS)\n                         && (context_p->token.type != LEXER_KEYW_STATIC));\n#endif /* ENABLED (JERRY_ES2015) */\n\n  context_p->token.line = context_p->line;\n  context_p->token.column = context_p->column;\n  bool create_literal_object = false;\n\n  if (lexer_parse_identifier (context_p, LEXER_PARSE_NO_OPTS))\n  {\n    if (!(ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN)))\n    {\n      lexer_skip_spaces (context_p);\n      context_p->token.flags = (uint8_t) (context_p->token.flags | LEXER_NO_SKIP_SPACES);\n\n      if (context_p->source_p < context_p->source_end_p\n#if ENABLED (JERRY_ES2015)\n          && context_p->source_p[0] != LIT_CHAR_COMMA\n          && context_p->source_p[0] != LIT_CHAR_RIGHT_BRACE\n          && context_p->source_p[0] != LIT_CHAR_LEFT_PAREN\n#endif /* ENABLED (JERRY_ES2015) */\n          && context_p->source_p[0] != LIT_CHAR_COLON)\n      {\n        if (lexer_compare_literal_to_string (context_p, \"get\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_GETTER;\n          return;\n        }\n\n        if (lexer_compare_literal_to_string (context_p, \"set\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_SETTER;\n          return;\n        }\n\n#if ENABLED (JERRY_ES2015)\n        if (lexer_compare_literal_to_string (context_p, \"async\", 5))\n        {\n          context_p->token.type = LEXER_KEYW_ASYNC;\n          return;\n        }\n#endif /* ENABLED (JERRY_ES2015) */\n      }\n    }\n\n#if ENABLED (JERRY_ES2015)\n    if (is_class_method && lexer_compare_literal_to_string (context_p, \"static\", 6))\n    {\n      context_p->token.type = LEXER_KEYW_STATIC;\n      return;\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    create_literal_object = true;\n  }\n  else\n  {\n    switch (context_p->source_p[0])\n    {\n      case LIT_CHAR_DOUBLE_QUOTE:\n      case LIT_CHAR_SINGLE_QUOTE:\n      {\n        lexer_parse_string (context_p, LEXER_STRING_NO_OPTS);\n        create_literal_object = true;\n        break;\n      }\n#if ENABLED (JERRY_ES2015)\n      case LIT_CHAR_LEFT_SQUARE:\n      {\n        lexer_consume_next_character (context_p);\n\n        lexer_next_token (context_p);\n        parser_parse_expression (context_p, PARSE_EXPR_NO_COMMA);\n\n        if (context_p->token.type != LEXER_RIGHT_SQUARE)\n        {\n          parser_raise_error (context_p, PARSER_ERR_RIGHT_SQUARE_EXPECTED);\n        }\n        return;\n      }\n      case LIT_CHAR_ASTERISK:\n#endif /* ENABLED (JERRY_ES2015) */\n      case LIT_CHAR_RIGHT_BRACE:\n      {\n        if (ident_opts & LEXER_OBJ_IDENT_ONLY_IDENTIFIERS)\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_RIGHT_BRACE;\n#if ENABLED (JERRY_ES2015)\n        if (context_p->source_p[0] == LIT_CHAR_ASTERISK)\n        {\n          context_p->token.type = LEXER_MULTIPLY;\n        }\n#endif /* ENABLED (JERRY_ES2015) */\n\n        lexer_consume_next_character (context_p);\n        return;\n      }\n      default:\n      {\n        const uint8_t *char_p = context_p->source_p;\n\n        if (char_p[0] == LIT_CHAR_DOT)\n        {\n          char_p++;\n        }\n\n        if (char_p < context_p->source_end_p\n            && char_p[0] >= LIT_CHAR_0\n            && char_p[0] <= LIT_CHAR_9)\n        {\n          lexer_parse_number (context_p);\n          lexer_construct_number_object (context_p, false, false);\n          return;\n        }\n        break;\n      }\n    }\n  }\n\n  if (create_literal_object)\n  {\n#if ENABLED (JERRY_ES2015)\n    if (is_class_method && lexer_compare_literal_to_string (context_p, \"constructor\", 11))\n    {\n      context_p->token.type = LEXER_CLASS_CONSTRUCTOR;\n      context_p->token.flags &= (uint8_t) ~LEXER_NO_SKIP_SPACES;\n      return;\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    lexer_construct_literal_object (context_p,\n                                    &context_p->token.lit_location,\n                                    LEXER_STRING_LITERAL);\n    return;\n  }\n\n  parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n}",
        "func": "void\nlexer_expect_object_literal_id (parser_context_t *context_p, /**< context */\n                                uint32_t ident_opts) /**< lexer_obj_ident_opts_t option bits */\n{\n  lexer_skip_spaces (context_p);\n\n  if (context_p->source_p >= context_p->source_end_p)\n  {\n    parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n  }\n\n#if ENABLED (JERRY_ES2015)\n  int is_class_method = ((ident_opts & LEXER_OBJ_IDENT_CLASS_METHOD)\n                         && !(ident_opts & LEXER_OBJ_IDENT_ONLY_IDENTIFIERS)\n                         && (context_p->token.type != LEXER_KEYW_STATIC));\n#endif /* ENABLED (JERRY_ES2015) */\n\n  context_p->token.line = context_p->line;\n  context_p->token.column = context_p->column;\n  bool create_literal_object = false;\n\n  if (lexer_parse_identifier (context_p, LEXER_PARSE_NO_OPTS))\n  {\n    if (!(ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN)))\n    {\n      lexer_skip_spaces (context_p);\n      context_p->token.flags = (uint8_t) (context_p->token.flags | LEXER_NO_SKIP_SPACES);\n\n      if (context_p->source_p < context_p->source_end_p\n#if ENABLED (JERRY_ES2015)\n          && context_p->source_p[0] != LIT_CHAR_COMMA\n          && context_p->source_p[0] != LIT_CHAR_RIGHT_BRACE\n          && context_p->source_p[0] != LIT_CHAR_LEFT_PAREN\n#endif /* ENABLED (JERRY_ES2015) */\n          && context_p->source_p[0] != LIT_CHAR_COLON)\n      {\n        if (lexer_compare_literal_to_string (context_p, \"get\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_GETTER;\n          return;\n        }\n\n        if (lexer_compare_literal_to_string (context_p, \"set\", 3))\n        {\n          context_p->token.type = LEXER_PROPERTY_SETTER;\n          return;\n        }\n\n#if ENABLED (JERRY_ES2015)\n        if (lexer_compare_literal_to_string (context_p, \"async\", 5))\n        {\n          context_p->token.type = LEXER_KEYW_ASYNC;\n          return;\n        }\n#endif /* ENABLED (JERRY_ES2015) */\n      }\n    }\n\n#if ENABLED (JERRY_ES2015)\n    if (is_class_method && lexer_compare_literal_to_string (context_p, \"static\", 6))\n    {\n      context_p->token.type = LEXER_KEYW_STATIC;\n      return;\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    create_literal_object = true;\n  }\n  else\n  {\n    switch (context_p->source_p[0])\n    {\n      case LIT_CHAR_DOUBLE_QUOTE:\n      case LIT_CHAR_SINGLE_QUOTE:\n      {\n        lexer_parse_string (context_p, LEXER_STRING_NO_OPTS);\n        create_literal_object = true;\n        break;\n      }\n#if ENABLED (JERRY_ES2015)\n      case LIT_CHAR_LEFT_SQUARE:\n      {\n        lexer_consume_next_character (context_p);\n\n        lexer_next_token (context_p);\n        parser_parse_expression (context_p, PARSE_EXPR_NO_COMMA);\n\n        if (context_p->token.type != LEXER_RIGHT_SQUARE)\n        {\n          parser_raise_error (context_p, PARSER_ERR_RIGHT_SQUARE_EXPECTED);\n        }\n        return;\n      }\n      case LIT_CHAR_ASTERISK:\n      {\n        if (ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN))\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_MULTIPLY;\n        lexer_consume_next_character (context_p);\n        return;\n      }\n#endif /* ENABLED (JERRY_ES2015) */\n      case LIT_CHAR_RIGHT_BRACE:\n      {\n        if (ident_opts & LEXER_OBJ_IDENT_ONLY_IDENTIFIERS)\n        {\n          break;\n        }\n\n        context_p->token.type = LEXER_RIGHT_BRACE;\n        lexer_consume_next_character (context_p);\n        return;\n      }\n      default:\n      {\n        const uint8_t *char_p = context_p->source_p;\n\n        if (char_p[0] == LIT_CHAR_DOT)\n        {\n          char_p++;\n        }\n\n        if (char_p < context_p->source_end_p\n            && char_p[0] >= LIT_CHAR_0\n            && char_p[0] <= LIT_CHAR_9)\n        {\n          lexer_parse_number (context_p);\n          lexer_construct_number_object (context_p, false, false);\n          return;\n        }\n        break;\n      }\n    }\n  }\n\n  if (create_literal_object)\n  {\n#if ENABLED (JERRY_ES2015)\n    if (is_class_method && lexer_compare_literal_to_string (context_p, \"constructor\", 11))\n    {\n      context_p->token.type = LEXER_CLASS_CONSTRUCTOR;\n      context_p->token.flags &= (uint8_t) ~LEXER_NO_SKIP_SPACES;\n      return;\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    lexer_construct_literal_object (context_p,\n                                    &context_p->token.lit_location,\n                                    LEXER_STRING_LITERAL);\n    return;\n  }\n\n  parser_raise_error (context_p, PARSER_ERR_PROPERTY_IDENTIFIER_EXPECTED);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -92,6 +92,16 @@\n         return;\n       }\n       case LIT_CHAR_ASTERISK:\n+      {\n+        if (ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN))\n+        {\n+          break;\n+        }\n+\n+        context_p->token.type = LEXER_MULTIPLY;\n+        lexer_consume_next_character (context_p);\n+        return;\n+      }\n #endif /* ENABLED (JERRY_ES2015) */\n       case LIT_CHAR_RIGHT_BRACE:\n       {\n@@ -101,13 +111,6 @@\n         }\n \n         context_p->token.type = LEXER_RIGHT_BRACE;\n-#if ENABLED (JERRY_ES2015)\n-        if (context_p->source_p[0] == LIT_CHAR_ASTERISK)\n-        {\n-          context_p->token.type = LEXER_MULTIPLY;\n-        }\n-#endif /* ENABLED (JERRY_ES2015) */\n-\n         lexer_consume_next_character (context_p);\n         return;\n       }",
        "diff_line_info": {
            "deleted_lines": [
                "#if ENABLED (JERRY_ES2015)",
                "        if (context_p->source_p[0] == LIT_CHAR_ASTERISK)",
                "        {",
                "          context_p->token.type = LEXER_MULTIPLY;",
                "        }",
                "#endif /* ENABLED (JERRY_ES2015) */",
                ""
            ],
            "added_lines": [
                "      {",
                "        if (ident_opts & (LEXER_OBJ_IDENT_ONLY_IDENTIFIERS | LEXER_OBJ_IDENT_OBJECT_PATTERN))",
                "        {",
                "          break;",
                "        }",
                "",
                "        context_p->token.type = LEXER_MULTIPLY;",
                "        lexer_consume_next_character (context_p);",
                "        return;",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41899",
        "func_name": "tensorflow/Examples::Initialize",
        "description": "TensorFlow is an open source platform for machine learning. Inputs `dense_features` or `example_state_data` not of rank 2 will trigger a `CHECK` fail in `SdcaOptimizer`. We have patched the issue in GitHub commit 80ff197d03db2a70c6a111f97dcdacad1b0babfa. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/80ff197d03db2a70c6a111f97dcdacad1b0babfa",
        "commit_title": "Fix SDCA optimizer crash.",
        "commit_text": " Validates size of the dense_features and example state_data_inputs. Other validation already verifies that sizes are otherwise consistent.  This looks to be a v1-only op that isn't used internally at all outside of `contrib`, and no tests.  PiperOrigin-RevId: 478073762",
        "func_before": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n  if (example_labels.size() != num_examples) {\n    return errors::InvalidArgument(\"Expected \", num_examples,\n                                   \" example labels but got \",\n                                   example_labels.size());\n  }\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return OkStatus();\n}",
        "func": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n  if (example_labels.size() != num_examples) {\n    return errors::InvalidArgument(\"Expected \", num_examples,\n                                   \" example labels but got \",\n                                   example_labels.size());\n  }\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n  for (int i = 0; i < dense_features_inputs.size(); ++i) {\n    if (!TensorShapeUtils::IsMatrix(dense_features_inputs[i].shape())) {\n      return errors::InvalidArgument(\"Dense features at index \", i,\n                                     \" must be rank 2 but is rank \",\n                                     dense_features_inputs[i].dims());\n    }\n  }\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return OkStatus();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,6 +56,13 @@\n   OpInputList dense_features_inputs;\n   TF_RETURN_IF_ERROR(\n       context->input_list(\"dense_features\", &dense_features_inputs));\n+  for (int i = 0; i < dense_features_inputs.size(); ++i) {\n+    if (!TensorShapeUtils::IsMatrix(dense_features_inputs[i].shape())) {\n+      return errors::InvalidArgument(\"Dense features at index \", i,\n+                                     \" must be rank 2 but is rank \",\n+                                     dense_features_inputs[i].dims());\n+    }\n+  }\n \n   examples_.clear();\n   examples_.resize(num_examples);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  for (int i = 0; i < dense_features_inputs.size(); ++i) {",
                "    if (!TensorShapeUtils::IsMatrix(dense_features_inputs[i].shape())) {",
                "      return errors::InvalidArgument(\"Dense features at index \", i,",
                "                                     \" must be rank 2 but is rank \",",
                "                                     dense_features_inputs[i].dims());",
                "    }",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41899",
        "func_name": "tensorflow/DoCompute",
        "description": "TensorFlow is an open source platform for machine learning. Inputs `dense_features` or `example_state_data` not of rank 2 will trigger a `CHECK` fail in `SdcaOptimizer`. We have patched the issue in GitHub commit 80ff197d03db2a70c6a111f97dcdacad1b0babfa. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/80ff197d03db2a70c6a111f97dcdacad1b0babfa",
        "commit_title": "Fix SDCA optimizer crash.",
        "commit_text": " Validates size of the dense_features and example state_data_inputs. Other validation already verifies that sizes are otherwise consistent.  This looks to be a v1-only op that isn't used internally at all outside of `contrib`, and no tests.  PiperOrigin-RevId: 478073762",
        "func_before": "void DoCompute(const ComputeOptions& options, OpKernelContext* const context) {\n  ModelWeights model_weights;\n  OP_REQUIRES_OK(context, model_weights.Initialize(context));\n\n  Examples examples;\n  OP_REQUIRES_OK(\n      context,\n      examples.Initialize(context, model_weights, options.num_sparse_features,\n                          options.num_sparse_features_with_values,\n                          options.num_dense_features));\n\n  const Tensor* example_state_data_t;\n  OP_REQUIRES_OK(context,\n                 context->input(\"example_state_data\", &example_state_data_t));\n  TensorShape expected_example_state_shape({examples.num_examples(), 4});\n  OP_REQUIRES(context,\n              example_state_data_t->shape() == expected_example_state_shape,\n              errors::InvalidArgument(\n                  \"Expected shape \", expected_example_state_shape.DebugString(),\n                  \" for example_state_data, got \",\n                  example_state_data_t->shape().DebugString()));\n\n  Tensor mutable_example_state_data_t(*example_state_data_t);\n  auto example_state_data = mutable_example_state_data_t.matrix<float>();\n  OP_REQUIRES_OK(context, context->set_output(\"out_example_state_data\",\n                                              mutable_example_state_data_t));\n\n  if (options.adaptive) {\n    OP_REQUIRES_OK(context,\n                   examples.SampleAdaptiveProbabilities(\n                       options.num_loss_partitions, options.regularizations,\n                       model_weights, example_state_data, options.loss_updater,\n                       /*num_weight_vectors =*/1));\n  } else {\n    examples.RandomShuffle();\n  }\n  struct {\n    mutex mu;\n    Status value TF_GUARDED_BY(mu);\n  } train_step_status;\n  std::atomic<std::int64_t> atomic_index(-1);\n  auto train_step = [&](const int64_t begin, const int64_t end) {\n    // The static_cast here is safe since begin and end can be at most\n    // num_examples which is an int.\n    for (int id = static_cast<int>(begin); id < end; ++id) {\n      const int64_t example_index = examples.sampled_index(++atomic_index);\n      const Example& example = examples.example(example_index);\n      const float dual = example_state_data(example_index, 0);\n      const float example_weight = example.example_weight();\n      float example_label = example.example_label();\n      const Status conversion_status =\n          options.loss_updater->ConvertLabel(&example_label);\n      if (!conversion_status.ok()) {\n        mutex_lock l(train_step_status.mu);\n        train_step_status.value = conversion_status;\n        // Return from this worker thread - the calling thread is\n        // responsible for checking context status and returning on error.\n        return;\n      }\n\n      // Compute wx, example norm weighted by regularization, dual loss,\n      // primal loss.\n      // For binary SDCA, num_weight_vectors should be one.\n      const ExampleStatistics example_statistics =\n          example.ComputeWxAndWeightedExampleNorm(\n              options.num_loss_partitions, model_weights,\n              options.regularizations, 1 /* num_weight_vectors */);\n\n      const double new_dual = options.loss_updater->ComputeUpdatedDual(\n          options.num_loss_partitions, example_label, example_weight, dual,\n          example_statistics.wx[0], example_statistics.normalized_squared_norm);\n\n      // Compute new weights.\n      const double normalized_bounded_dual_delta =\n          (new_dual - dual) * example_weight /\n          options.regularizations.symmetric_l2();\n      model_weights.UpdateDeltaWeights(\n          context->eigen_cpu_device(), example,\n          std::vector<double>{normalized_bounded_dual_delta});\n\n      // Update example data.\n      example_state_data(example_index, 0) = new_dual;\n      example_state_data(example_index, 1) =\n          options.loss_updater->ComputePrimalLoss(\n              example_statistics.prev_wx[0], example_label, example_weight);\n      example_state_data(example_index, 2) =\n          options.loss_updater->ComputeDualLoss(dual, example_label,\n                                                example_weight);\n      example_state_data(example_index, 3) = example_weight;\n    }\n  };\n  // TODO(sibyl-Aix6ihai): Tune this properly based on sparsity of the data,\n  // number of cpus, and cost per example.\n  const int64_t kCostPerUnit = examples.num_features();\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n\n  Shard(worker_threads.num_threads, worker_threads.workers,\n        examples.num_examples(), kCostPerUnit, train_step);\n  mutex_lock l(train_step_status.mu);\n  OP_REQUIRES_OK(context, train_step_status.value);\n}",
        "func": "void DoCompute(const ComputeOptions& options, OpKernelContext* const context) {\n  ModelWeights model_weights;\n  OP_REQUIRES_OK(context, model_weights.Initialize(context));\n\n  Examples examples;\n  OP_REQUIRES_OK(\n      context,\n      examples.Initialize(context, model_weights, options.num_sparse_features,\n                          options.num_sparse_features_with_values,\n                          options.num_dense_features));\n\n  const Tensor* example_state_data_t;\n  OP_REQUIRES_OK(context,\n                 context->input(\"example_state_data\", &example_state_data_t));\n  OP_REQUIRES(\n      context, TensorShapeUtils::IsMatrix(example_state_data_t->shape()),\n      errors::InvalidArgument(\"example_state_data must be rank 2 but is rank \",\n                              example_state_data_t->dims()));\n  TensorShape expected_example_state_shape({examples.num_examples(), 4});\n  OP_REQUIRES(context,\n              example_state_data_t->shape() == expected_example_state_shape,\n              errors::InvalidArgument(\n                  \"Expected shape \", expected_example_state_shape.DebugString(),\n                  \" for example_state_data, got \",\n                  example_state_data_t->shape().DebugString()));\n\n  Tensor mutable_example_state_data_t(*example_state_data_t);\n  auto example_state_data = mutable_example_state_data_t.matrix<float>();\n  OP_REQUIRES_OK(context, context->set_output(\"out_example_state_data\",\n                                              mutable_example_state_data_t));\n\n  if (options.adaptive) {\n    OP_REQUIRES_OK(context,\n                   examples.SampleAdaptiveProbabilities(\n                       options.num_loss_partitions, options.regularizations,\n                       model_weights, example_state_data, options.loss_updater,\n                       /*num_weight_vectors =*/1));\n  } else {\n    examples.RandomShuffle();\n  }\n  struct {\n    mutex mu;\n    Status value TF_GUARDED_BY(mu);\n  } train_step_status;\n  std::atomic<std::int64_t> atomic_index(-1);\n  auto train_step = [&](const int64_t begin, const int64_t end) {\n    // The static_cast here is safe since begin and end can be at most\n    // num_examples which is an int.\n    for (int id = static_cast<int>(begin); id < end; ++id) {\n      const int64_t example_index = examples.sampled_index(++atomic_index);\n      const Example& example = examples.example(example_index);\n      const float dual = example_state_data(example_index, 0);\n      const float example_weight = example.example_weight();\n      float example_label = example.example_label();\n      const Status conversion_status =\n          options.loss_updater->ConvertLabel(&example_label);\n      if (!conversion_status.ok()) {\n        mutex_lock l(train_step_status.mu);\n        train_step_status.value = conversion_status;\n        // Return from this worker thread - the calling thread is\n        // responsible for checking context status and returning on error.\n        return;\n      }\n\n      // Compute wx, example norm weighted by regularization, dual loss,\n      // primal loss.\n      // For binary SDCA, num_weight_vectors should be one.\n      const ExampleStatistics example_statistics =\n          example.ComputeWxAndWeightedExampleNorm(\n              options.num_loss_partitions, model_weights,\n              options.regularizations, 1 /* num_weight_vectors */);\n\n      const double new_dual = options.loss_updater->ComputeUpdatedDual(\n          options.num_loss_partitions, example_label, example_weight, dual,\n          example_statistics.wx[0], example_statistics.normalized_squared_norm);\n\n      // Compute new weights.\n      const double normalized_bounded_dual_delta =\n          (new_dual - dual) * example_weight /\n          options.regularizations.symmetric_l2();\n      model_weights.UpdateDeltaWeights(\n          context->eigen_cpu_device(), example,\n          std::vector<double>{normalized_bounded_dual_delta});\n\n      // Update example data.\n      example_state_data(example_index, 0) = new_dual;\n      example_state_data(example_index, 1) =\n          options.loss_updater->ComputePrimalLoss(\n              example_statistics.prev_wx[0], example_label, example_weight);\n      example_state_data(example_index, 2) =\n          options.loss_updater->ComputeDualLoss(dual, example_label,\n                                                example_weight);\n      example_state_data(example_index, 3) = example_weight;\n    }\n  };\n  // TODO(sibyl-Aix6ihai): Tune this properly based on sparsity of the data,\n  // number of cpus, and cost per example.\n  const int64_t kCostPerUnit = examples.num_features();\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n\n  Shard(worker_threads.num_threads, worker_threads.workers,\n        examples.num_examples(), kCostPerUnit, train_step);\n  mutex_lock l(train_step_status.mu);\n  OP_REQUIRES_OK(context, train_step_status.value);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,10 @@\n   const Tensor* example_state_data_t;\n   OP_REQUIRES_OK(context,\n                  context->input(\"example_state_data\", &example_state_data_t));\n+  OP_REQUIRES(\n+      context, TensorShapeUtils::IsMatrix(example_state_data_t->shape()),\n+      errors::InvalidArgument(\"example_state_data must be rank 2 but is rank \",\n+                              example_state_data_t->dims()));\n   TensorShape expected_example_state_shape({examples.num_examples(), 4});\n   OP_REQUIRES(context,\n               example_state_data_t->shape() == expected_example_state_shape,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  OP_REQUIRES(",
                "      context, TensorShapeUtils::IsMatrix(example_state_data_t->shape()),",
                "      errors::InvalidArgument(\"example_state_data must be rank 2 but is rank \",",
                "                              example_state_data_t->dims()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-41901",
        "func_name": "tensorflow/ExtractVariantFromInput",
        "description": "TensorFlow is an open source platform for machine learning. An input `sparse_matrix` that is not a matrix with a shape with rank 0 will trigger a `CHECK` fail in `tf.raw_ops.SparseMatrixNNZ`. We have patched the issue in GitHub commit f856d02e5322821aad155dad9b3acab1e9f5d693. The fix will be included in TensorFlow 2.11. We will also cherrypick this commit on TensorFlow 2.10.1, 2.9.3, and TensorFlow 2.8.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f856d02e5322821aad155dad9b3acab1e9f5d693",
        "commit_title": "Fix missing sparse matrix crash.",
        "commit_text": " Calling a sparse matrix op with no matrix currently causes a crash.  Here we check and return a non-ok status.  PiperOrigin-RevId: 476379116",
        "func_before": "Status ExtractVariantFromInput(OpKernelContext* ctx, int index,\n                               const T** value) {\n  const Tensor& input_t = ctx->input(index);\n  const Variant& input_variant = input_t.scalar<Variant>()();\n  *value = input_variant.get<T>();\n  if (*value == nullptr) {\n    return errors::InvalidArgument(\"Could not retrieve Variant input \", index);\n  }\n  if (!(*value)->valid()) {\n    return errors::InvalidArgument(\"Variant input \", index, \" is not valid.\");\n  }\n  return OkStatus();\n}",
        "func": "Status ExtractVariantFromInput(OpKernelContext* ctx, int index,\n                               const T** value) {\n  const Tensor& input_t = ctx->input(index);\n  if (!TensorShapeUtils::IsScalar(input_t.shape())) {\n    return errors::InvalidArgument(\n        \"Invalid input matrix: Shape must be rank 0 but is rank \",\n        input_t.dims());\n  }\n  const Variant& input_variant = input_t.scalar<Variant>()();\n  *value = input_variant.get<T>();\n  if (*value == nullptr) {\n    return errors::InvalidArgument(\"Could not retrieve Variant input \", index);\n  }\n  if (!(*value)->valid()) {\n    return errors::InvalidArgument(\"Variant input \", index, \" is not valid.\");\n  }\n  return OkStatus();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,11 @@\n Status ExtractVariantFromInput(OpKernelContext* ctx, int index,\n                                const T** value) {\n   const Tensor& input_t = ctx->input(index);\n+  if (!TensorShapeUtils::IsScalar(input_t.shape())) {\n+    return errors::InvalidArgument(\n+        \"Invalid input matrix: Shape must be rank 0 but is rank \",\n+        input_t.dims());\n+  }\n   const Variant& input_variant = input_t.scalar<Variant>()();\n   *value = input_variant.get<T>();\n   if (*value == nullptr) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (!TensorShapeUtils::IsScalar(input_t.shape())) {",
                "    return errors::InvalidArgument(",
                "        \"Invalid input matrix: Shape must be rank 0 but is rank \",",
                "        input_t.dims());",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-32978",
        "func_name": "thorfdbg/libjpeg/SampleInterleavedLSScan::ParseMCU",
        "description": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "git_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7",
        "commit_title": "Fixed handling of empty JPEG-LS scans.",
        "commit_text": "",
        "func_before": "bool SampleInterleavedLSScan::ParseMCU(void)\n{\n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line[4];\n  UBYTE cx;\n\n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n  assert(lines > 0);\n  assert(m_ucCount < 4);\n\n  //\n  // Fill the line pointers.\n  for(cx = 0;cx < m_ucCount;cx++) {\n    line[cx] = CurrentLine(cx);\n  }\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp[4];\n\n    // Get the line pointers and initialize the internal backup lines.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      lp[cx] = line[cx]->m_pData;\n      StartLine(cx);\n    }\n\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { \n      // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a[4],b[4],c[4],d[4]; // neighbouring values.\n        LONG d1[4],d2[4],d3[4];   // local gradients.\n        bool isrun = true;\n      \n        for(cx = 0;cx < m_ucCount;cx++) {\n          GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n\n          d1[cx]  = d[cx] - b[cx];    // compute local gradients\n          d2[cx]  = b[cx] - c[cx];\n          d3[cx]  = c[cx] - a[cx];\n\n          //\n          // Run mode only if the run condition is met for all components\n          if (isrun && !isRunMode(d1[cx],d2[cx],d3[cx]))\n            isrun = false;\n        }\n        \n        if (isrun) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            // There is one sample per component.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              UpdateContext(cx,a[cx]);\n              // And insert the value into the target line as well.\n              *lp[cx]++ = a[cx] << preshift;\n            }\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample. The rtype is here always zero.\n          if (length) {\n            bool negative; // the sign variable\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            //\n            // Decode the interrupting pixels.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              // Get the neighbourhood.\n              GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n              // The prediction mode is always false, but the sign information\n              // is required.\n              negative = a[cx] > b[cx];\n              // Get the golomb parameter for run interruption coding.\n              k       = GolombParameter(false);\n              // Golomb-decode the error symbol. It is always using the common\n              // run index.\n              merr    = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n              // Inverse the error mapping procedure.\n              errval  = InverseErrorMapping(merr,ErrorMappingOffset(false,merr != 0,k));\n              // Compute the reconstructed value.\n              rx      = Reconstruct(negative,b[cx],errval);\n              // Update so that the next process gets the correct value.\n              UpdateContext(cx,rx);\n              // Fill in the value into the line\n              *lp[cx]++ = rx << preshift;\n              // Update the variables of the run mode.\n              UpdateState(false,errval);\n            }\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          //\n          for(cx = 0;cx < m_ucCount;cx++) {\n            // Quantize the gradients.\n            d1[cx]  = QuantizedGradient(d1[cx]);\n            d2[cx]  = QuantizedGradient(d2[cx]);\n            d3[cx]  = QuantizedGradient(d3[cx]);\n            // Compute the context.\n            ctxt    = Context(negative,d1[cx],d2[cx],d3[cx]); \n            // Compute the predicted value.\n            px      = Predict(a[cx],b[cx],c[cx]);\n            // Correct the prediction.\n            px      = CorrectPrediction(ctxt,negative,px);\n            // Compute the golomb parameter k from the context.\n            k       = GolombParameter(ctxt);\n            // Decode the error symbol.\n            merr    = GolombDecode(k,m_lLimit);\n            // Inverse the error symbol into an error value.\n            errval  = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n            // Update the variables.\n            UpdateState(ctxt,errval);\n            // Compute the reconstructed value.\n            rx      = Reconstruct(negative,px,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(cx,rx);\n            // And insert the value into the target line as well.\n            *lp[cx]++ = rx << preshift;\n          }\n        }\n      } while(--length);\n    } // No error handling here.\n    //\n    // Advance the line pointers.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      EndLine(cx);\n      line[cx] = line[cx]->m_pNext;\n    }\n    //\n  } while(--lines);\n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "func": "bool SampleInterleavedLSScan::ParseMCU(void)\n{\n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line[4];\n  UBYTE cx;\n\n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n\n  if (lines == 0)\n    return false;\n  \n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n  assert(m_ucCount < 4);\n\n  //\n  // Fill the line pointers.\n  for(cx = 0;cx < m_ucCount;cx++) {\n    line[cx] = CurrentLine(cx);\n  }\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp[4];\n\n    // Get the line pointers and initialize the internal backup lines.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      lp[cx] = line[cx]->m_pData;\n      StartLine(cx);\n    }\n\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { \n      // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a[4],b[4],c[4],d[4]; // neighbouring values.\n        LONG d1[4],d2[4],d3[4];   // local gradients.\n        bool isrun = true;\n      \n        for(cx = 0;cx < m_ucCount;cx++) {\n          GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n\n          d1[cx]  = d[cx] - b[cx];    // compute local gradients\n          d2[cx]  = b[cx] - c[cx];\n          d3[cx]  = c[cx] - a[cx];\n\n          //\n          // Run mode only if the run condition is met for all components\n          if (isrun && !isRunMode(d1[cx],d2[cx],d3[cx]))\n            isrun = false;\n        }\n        \n        if (isrun) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            // There is one sample per component.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              UpdateContext(cx,a[cx]);\n              // And insert the value into the target line as well.\n              *lp[cx]++ = a[cx] << preshift;\n            }\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample. The rtype is here always zero.\n          if (length) {\n            bool negative; // the sign variable\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            //\n            // Decode the interrupting pixels.\n            for(cx = 0;cx < m_ucCount;cx++) {\n              // Get the neighbourhood.\n              GetContext(cx,a[cx],b[cx],c[cx],d[cx]);\n              // The prediction mode is always false, but the sign information\n              // is required.\n              negative = a[cx] > b[cx];\n              // Get the golomb parameter for run interruption coding.\n              k       = GolombParameter(false);\n              // Golomb-decode the error symbol. It is always using the common\n              // run index.\n              merr    = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n              // Inverse the error mapping procedure.\n              errval  = InverseErrorMapping(merr,ErrorMappingOffset(false,merr != 0,k));\n              // Compute the reconstructed value.\n              rx      = Reconstruct(negative,b[cx],errval);\n              // Update so that the next process gets the correct value.\n              UpdateContext(cx,rx);\n              // Fill in the value into the line\n              *lp[cx]++ = rx << preshift;\n              // Update the variables of the run mode.\n              UpdateState(false,errval);\n            }\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          //\n          for(cx = 0;cx < m_ucCount;cx++) {\n            // Quantize the gradients.\n            d1[cx]  = QuantizedGradient(d1[cx]);\n            d2[cx]  = QuantizedGradient(d2[cx]);\n            d3[cx]  = QuantizedGradient(d3[cx]);\n            // Compute the context.\n            ctxt    = Context(negative,d1[cx],d2[cx],d3[cx]); \n            // Compute the predicted value.\n            px      = Predict(a[cx],b[cx],c[cx]);\n            // Correct the prediction.\n            px      = CorrectPrediction(ctxt,negative,px);\n            // Compute the golomb parameter k from the context.\n            k       = GolombParameter(ctxt);\n            // Decode the error symbol.\n            merr    = GolombDecode(k,m_lLimit);\n            // Inverse the error symbol into an error value.\n            errval  = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n            // Update the variables.\n            UpdateState(ctxt,errval);\n            // Compute the reconstructed value.\n            rx      = Reconstruct(negative,px,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(cx,rx);\n            // And insert the value into the target line as well.\n            *lp[cx]++ = rx << preshift;\n          }\n        }\n      } while(--length);\n    } // No error handling here.\n    //\n    // Advance the line pointers.\n    for(cx = 0;cx < m_ucCount;cx++) {\n      EndLine(cx);\n      line[cx] = line[cx]->m_pNext;\n    }\n    //\n  } while(--lines);\n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,9 +17,12 @@\n   if (lines > 8) {\n     lines = 8;\n   }\n+\n+  if (lines == 0)\n+    return false;\n+  \n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  assert(lines > 0);\n   assert(m_ucCount < 4);\n \n   //",
        "diff_line_info": {
            "deleted_lines": [
                "  assert(lines > 0);"
            ],
            "added_lines": [
                "",
                "  if (lines == 0)",
                "    return false;",
                "  "
            ]
        }
    },
    {
        "cve_id": "CVE-2022-32978",
        "func_name": "thorfdbg/libjpeg/SingleComponentLSScan::ParseMCU",
        "description": "There is an assertion failure in SingleComponentLSScan::ParseMCU in singlecomponentlsscan.cpp in libjpeg before 1.64 via an empty JPEG-LS scan.",
        "git_url": "https://github.com/thorfdbg/libjpeg/commit/4746b577931e926a49e50de9720a4946de3069a7",
        "commit_title": "Fixed handling of empty JPEG-LS scans.",
        "commit_text": "",
        "func_before": "bool SingleComponentLSScan::ParseMCU(void)\n{ \n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line     = CurrentLine(0);\n  \n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n\n  assert(m_ucCount == 1);\n\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n  \n  assert(lines > 0);\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp    = line->m_pData;\n\n#ifdef DEBUG_LS\n    int xpos    = 0;\n    static int linenumber = 0;\n    printf(\"\\n%4d : \",++linenumber);\n#endif\n     \n    StartLine(0);\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a,b,c,d;   // neighbouring values.\n        LONG d1,d2,d3;  // local gradients.\n      \n        GetContext(0,a,b,c,d);\n        d1  = d - b;    // compute local gradients\n        d2  = b - c;\n        d3  = c - a;\n        \n        if (isRunMode(d1,d2,d3)) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,a);\n            // And insert the value into the target line as well.\n            *lp++ = a << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,a);\n#endif\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample.\n          if (length) {\n            bool negative; // the sign variable\n            bool rtype;    // run interruption type\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            // Get the neighbourhood.\n            GetContext(0,a,b,c,d);\n            // Get the prediction mode.\n            rtype  = InterruptedPredictionMode(negative,a,b);\n            // Get the golomb parameter for run interruption coding.\n            k      = GolombParameter(rtype);\n            // Golomb-decode the error symbol.\n            merr   = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n            // Inverse the error mapping procedure.\n            errval = InverseErrorMapping(merr + rtype,ErrorMappingOffset(rtype,rtype || merr,k));\n            // Compute the reconstructed value.\n            rx     = Reconstruct(negative,rtype?a:b,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,rx);\n            // Fill in the value into the line\n            *lp    = rx << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n            // Update the variables of the run mode.\n            UpdateState(rtype,errval);\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          // Quantize the gradients.\n          d1     = QuantizedGradient(d1);\n          d2     = QuantizedGradient(d2);\n          d3     = QuantizedGradient(d3);\n          // Compute the context.\n          ctxt   = Context(negative,d1,d2,d3); \n          // Compute the predicted value.\n          px     = Predict(a,b,c);\n          // Correct the prediction.\n          px     = CorrectPrediction(ctxt,negative,px);\n          // Compute the golomb parameter k from the context.\n          k      = GolombParameter(ctxt);\n          // Decode the error symbol.\n          merr   = GolombDecode(k,m_lLimit);\n          // Inverse the error symbol into an error value.\n          errval = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n          // Update the variables.\n          UpdateState(ctxt,errval);\n          // Compute the reconstructed value.\n          rx     = Reconstruct(negative,px,errval);\n          // Update so that the next process gets the correct value.\n          UpdateContext(0,rx);\n          // And insert the value into the target line as well.\n          *lp    = rx << preshift;\n#ifdef DEBUG_LS\n          printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n        }\n      } while(++lp,--length);\n    } // No error handling here.\n    EndLine(0);\n    line = line->m_pNext;\n  } while(--lines); \n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "func": "bool SingleComponentLSScan::ParseMCU(void)\n{ \n#if ACCUSOFT_CODE\n  int lines             = m_ulRemaining[0]; // total number of MCU lines processed.\n  UBYTE preshift        = m_ucLowBit + FractionalColorBitsOf();\n  struct Line *line     = CurrentLine(0);\n  \n  //\n  // If a DNL marker is present, the number of remaining lines is zero. Fix it.\n  if (m_pFrame->HeightOf() == 0) {\n    assert(lines == 0);\n    lines = 8;\n  }\n\n  assert(m_ucCount == 1);\n\n  //\n  // A \"MCU\" in respect to the code organization is eight lines.\n  if (lines > 8) {\n    lines = 8;\n  }\n  if (m_pFrame->HeightOf() > 0)\n    m_ulRemaining[0] -= lines;\n\n  if (lines == 0)\n    return false;\n\n  // Loop over lines and columns\n  do {\n    LONG length = m_ulWidth[0];\n    LONG *lp    = line->m_pData;\n\n#ifdef DEBUG_LS\n    int xpos    = 0;\n    static int linenumber = 0;\n    printf(\"\\n%4d : \",++linenumber);\n#endif\n     \n    StartLine(0);\n    if (BeginReadMCU(m_Stream.ByteStreamOf())) { // No error handling strategy. No RST in scans. Bummer!\n      do {\n        LONG a,b,c,d;   // neighbouring values.\n        LONG d1,d2,d3;  // local gradients.\n      \n        GetContext(0,a,b,c,d);\n        d1  = d - b;    // compute local gradients\n        d2  = b - c;\n        d3  = c - a;\n        \n        if (isRunMode(d1,d2,d3)) {\n          LONG run = DecodeRun(length,m_lRunIndex[0]);\n          //\n          // Now fill the data.\n          while(run) {\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,a);\n            // And insert the value into the target line as well.\n            *lp++ = a << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,a);\n#endif\n            run--,length--;\n            // As long as there are pixels on the line.\n          }\n          //\n          // More data on the line? I.e. the run did not cover the full m_lJ samples?\n          // Now decode the run interruption sample.\n          if (length) {\n            bool negative; // the sign variable\n            bool rtype;    // run interruption type\n            LONG errval;   // the prediction error\n            LONG merr;     // the mapped error (symbol)\n            LONG rx;       // the reconstructed value\n            UBYTE k;       // golomb parameter\n            // Get the neighbourhood.\n            GetContext(0,a,b,c,d);\n            // Get the prediction mode.\n            rtype  = InterruptedPredictionMode(negative,a,b);\n            // Get the golomb parameter for run interruption coding.\n            k      = GolombParameter(rtype);\n            // Golomb-decode the error symbol.\n            merr   = GolombDecode(k,m_lLimit - m_lJ[m_lRunIndex[0]] - 1);\n            // Inverse the error mapping procedure.\n            errval = InverseErrorMapping(merr + rtype,ErrorMappingOffset(rtype,rtype || merr,k));\n            // Compute the reconstructed value.\n            rx     = Reconstruct(negative,rtype?a:b,errval);\n            // Update so that the next process gets the correct value.\n            UpdateContext(0,rx);\n            // Fill in the value into the line\n            *lp    = rx << preshift;\n#ifdef DEBUG_LS\n            printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n            // Update the variables of the run mode.\n            UpdateState(rtype,errval);\n            // Update the run index now. This is not part of\n            // EncodeRun because the non-reduced run-index is\n            // required for the golomb coder length limit. \n            if (m_lRunIndex[0] > 0)\n              m_lRunIndex[0]--;\n          } else break; // end of line.\n        } else {\n          UWORD ctxt;\n          bool  negative; // the sign variable.\n          LONG  px;       // the predicted variable.\n          LONG  rx;       // the reconstructed value.\n          LONG  errval;   // the error value.\n          LONG  merr;     // the mapped error value.\n          UBYTE k;        // the Golomb parameter.\n          // Quantize the gradients.\n          d1     = QuantizedGradient(d1);\n          d2     = QuantizedGradient(d2);\n          d3     = QuantizedGradient(d3);\n          // Compute the context.\n          ctxt   = Context(negative,d1,d2,d3); \n          // Compute the predicted value.\n          px     = Predict(a,b,c);\n          // Correct the prediction.\n          px     = CorrectPrediction(ctxt,negative,px);\n          // Compute the golomb parameter k from the context.\n          k      = GolombParameter(ctxt);\n          // Decode the error symbol.\n          merr   = GolombDecode(k,m_lLimit);\n          // Inverse the error symbol into an error value.\n          errval = InverseErrorMapping(merr,ErrorMappingOffset(ctxt,k));\n          // Update the variables.\n          UpdateState(ctxt,errval);\n          // Compute the reconstructed value.\n          rx     = Reconstruct(negative,px,errval);\n          // Update so that the next process gets the correct value.\n          UpdateContext(0,rx);\n          // And insert the value into the target line as well.\n          *lp    = rx << preshift;\n#ifdef DEBUG_LS\n          printf(\"%4d:<%2x> \",xpos++,*lp);\n#endif\n        }\n      } while(++lp,--length);\n    } // No error handling here.\n    EndLine(0);\n    line = line->m_pNext;\n  } while(--lines); \n  //\n  // If this is the last line, gobble up all the\n  // bits from bitstuffing the last byte may have left.\n  // As SkipStuffing is idempotent, we can also do that\n  // all the time.\n  m_Stream.SkipStuffing();\n#endif  \n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,8 +21,9 @@\n   }\n   if (m_pFrame->HeightOf() > 0)\n     m_ulRemaining[0] -= lines;\n-  \n-  assert(lines > 0);\n+\n+  if (lines == 0)\n+    return false;\n \n   // Loop over lines and columns\n   do {",
        "diff_line_info": {
            "deleted_lines": [
                "  ",
                "  assert(lines > 0);"
            ],
            "added_lines": [
                "",
                "  if (lines == 0)",
                "    return false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-27783",
        "func_name": "appneta/tcpreplay/dlt_jnpr_ether_cleanup",
        "description": "An issue found in TCPreplay tcprewrite v.4.4.3 allows a remote attacker to cause a denial of service via the tcpedit_dlt_cleanup function at plugins/dlt_plugins.c.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/e831aad6d48874abab6efa37d4460da2be3ac765",
        "commit_title": "dlt_jnpr_ether_cleanup: check subctx before cleanup",
        "commit_text": "",
        "func_before": "int \ndlt_jnpr_ether_cleanup(tcpeditdlt_t *ctx)\n{\n    tcpeditdlt_plugin_t *plugin;\n    \n    assert(ctx);\n\n    if ((plugin = tcpedit_dlt_getplugin(ctx, dlt_value)) == NULL) {\n        tcpedit_seterr(ctx->tcpedit, \"Unable to cleanup unregistered plugin %s\", dlt_name);\n        return TCPEDIT_ERROR;\n    }\n\n    safe_free(plugin->name);\n    plugin->name = NULL;\n    if (plugin->config != NULL) {\n        /* clean up the en10mb plugin */\n        jnpr_ether_config_t *config;\n\n        config = (jnpr_ether_config_t *)ctx->encoder->config;\n        tcpedit_dlt_cleanup(config->subctx);\n        safe_free(plugin->config);\n        plugin->config = NULL;\n        plugin->config_size = 0;\n    }\n\n    return TCPEDIT_OK; /* success */\n}",
        "func": "int \ndlt_jnpr_ether_cleanup(tcpeditdlt_t *ctx)\n{\n    tcpeditdlt_plugin_t *plugin;\n    \n    assert(ctx);\n\n    if ((plugin = tcpedit_dlt_getplugin(ctx, dlt_value)) == NULL) {\n        tcpedit_seterr(ctx->tcpedit, \"Unable to cleanup unregistered plugin %s\", dlt_name);\n        return TCPEDIT_ERROR;\n    }\n\n    safe_free(plugin->name);\n    plugin->name = NULL;\n    if (plugin->config != NULL) {\n        /* clean up the en10mb plugin */\n        jnpr_ether_config_t *config;\n\n        config = (jnpr_ether_config_t *)ctx->encoder->config;\n        if (config->subctx != NULL)\n            tcpedit_dlt_cleanup(config->subctx);\n        safe_free(plugin->config);\n        plugin->config = NULL;\n        plugin->config_size = 0;\n    }\n\n    return TCPEDIT_OK; /* success */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,8 @@\n         jnpr_ether_config_t *config;\n \n         config = (jnpr_ether_config_t *)ctx->encoder->config;\n-        tcpedit_dlt_cleanup(config->subctx);\n+        if (config->subctx != NULL)\n+            tcpedit_dlt_cleanup(config->subctx);\n         safe_free(plugin->config);\n         plugin->config = NULL;\n         plugin->config_size = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "        tcpedit_dlt_cleanup(config->subctx);"
            ],
            "added_lines": [
                "        if (config->subctx != NULL)",
                "            tcpedit_dlt_cleanup(config->subctx);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-27786",
        "func_name": "appneta/tcpreplay/parse_portmap",
        "description": "An issue found in TCPprep v.4.4.3 allows a remote attacker to cause a denial of service via the macinstring function.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/df18c48812462ea802d639d2477887055666ee58",
        "commit_title": "Add check after call strtok_r",
        "commit_text": "",
        "func_before": "int\nparse_portmap(tcpedit_portmap_t ** portmap, const char *ourstr)\n{\n    tcpedit_portmap_t *portmap_ptr;\n    char *substr, *ourstrcpy, *token = NULL;\n\n    assert(ourstr);\n    ourstrcpy = safe_strdup(ourstr);\n\n    /* first iteration of input */\n    substr = strtok_r(ourstrcpy, \",\", &token);\n\n    if ((*portmap = ports2PORT(substr)) == NULL) {\n        safe_free(ourstrcpy);\n        return 0;\n    }\n\n    portmap_ptr = *portmap;\n\n    /* ports2PORT may return a chain, so find the end of it */\n    while (portmap_ptr->next != NULL)\n        portmap_ptr = portmap_ptr->next;\n\n    while (1) {\n        substr = strtok_r(NULL, \",\", &token);\n        /* if that was the last one, kick out */\n        if (substr == NULL)\n            break;\n\n        /* process next record */\n        portmap_ptr->next = ports2PORT(substr);\n\n        /* ports2PORT may return a chain, so find the end of it */\n        while (portmap_ptr->next != NULL)\n            portmap_ptr = portmap_ptr->next;\n    }\n\n    safe_free(ourstrcpy);\n    return 1;\n}",
        "func": "int\nparse_portmap(tcpedit_portmap_t ** portmap, const char *ourstr)\n{\n    tcpedit_portmap_t *portmap_ptr;\n    char *substr, *ourstrcpy, *token = NULL;\n\n    assert(ourstr);\n    ourstrcpy = safe_strdup(ourstr);\n\n    /* first iteration of input */\n    substr = strtok_r(ourstrcpy, \",\", &token);\n\n    if (substr == NULL || (*portmap = ports2PORT(substr)) == NULL) {\n        safe_free(ourstrcpy);\n        return 0;\n    }\n\n    portmap_ptr = *portmap;\n\n    /* ports2PORT may return a chain, so find the end of it */\n    while (portmap_ptr->next != NULL)\n        portmap_ptr = portmap_ptr->next;\n\n    while (1) {\n        substr = strtok_r(NULL, \",\", &token);\n        /* if that was the last one, kick out */\n        if (substr == NULL)\n            break;\n\n        /* process next record */\n        portmap_ptr->next = ports2PORT(substr);\n\n        /* ports2PORT may return a chain, so find the end of it */\n        while (portmap_ptr->next != NULL)\n            portmap_ptr = portmap_ptr->next;\n    }\n\n    safe_free(ourstrcpy);\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n     /* first iteration of input */\n     substr = strtok_r(ourstrcpy, \",\", &token);\n \n-    if ((*portmap = ports2PORT(substr)) == NULL) {\n+    if (substr == NULL || (*portmap = ports2PORT(substr)) == NULL) {\n         safe_free(ourstrcpy);\n         return 0;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    if ((*portmap = ports2PORT(substr)) == NULL) {"
            ],
            "added_lines": [
                "    if (substr == NULL || (*portmap = ports2PORT(substr)) == NULL) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-27786",
        "func_name": "appneta/tcpreplay/read_hexstring",
        "description": "An issue found in TCPprep v.4.4.3 allows a remote attacker to cause a denial of service via the macinstring function.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/df18c48812462ea802d639d2477887055666ee58",
        "commit_title": "Add check after call strtok_r",
        "commit_text": "",
        "func_before": "int\nread_hexstring(const char *l2string, u_char *hex, const int hexlen)\n{\n    int numbytes = 0;\n    unsigned int value;\n    char *l2byte;\n    u_char databyte;\n    char *token = NULL;\n    char *string;\n\n    string = safe_strdup(l2string);\n\n    if (hexlen <= 0)\n        err(-1, \"Hex buffer must be > 0\");\n\n    memset(hex, '\\0', hexlen);\n\n    /* data is hex, comma separated, byte by byte */\n\n    /* get the first byte */\n    l2byte = strtok_r(string, \",\", &token);\n    sscanf(l2byte, \"%x\", &value);\n    if (value > 0xff)\n        errx(-1, \"Invalid hex string byte: %s\", l2byte);\n    databyte = (u_char) value;\n    memcpy(&hex[numbytes], &databyte, 1);\n\n    /* get remaining bytes */\n    while ((l2byte = strtok_r(NULL, \",\", &token)) != NULL) {\n        numbytes++;\n        if (numbytes + 1 > hexlen) {\n            warn(\"Hex buffer too small for data- skipping data\");\n            goto done;\n        }\n        sscanf(l2byte, \"%x\", &value);\n        if (value > 0xff)\n            errx(-1, \"Invalid hex string byte: %s\", l2byte);\n        databyte = (u_char) value;\n        memcpy(&hex[numbytes], &databyte, 1);\n    }\n\n    numbytes++;\n\ndone:\n    safe_free(string);\n\n    dbgx(1, \"Read %d bytes of hex data\", numbytes);\n    return (numbytes);\n}",
        "func": "int\nread_hexstring(const char *l2string, u_char *hex, const int hexlen)\n{\n    int numbytes = 0;\n    unsigned int value;\n    char *l2byte;\n    u_char databyte;\n    char *token = NULL;\n    char *string;\n\n    string = safe_strdup(l2string);\n\n    if (hexlen <= 0)\n        err(-1, \"Hex buffer must be > 0\");\n\n    memset(hex, '\\0', hexlen);\n\n    /* data is hex, comma separated, byte by byte */\n\n    /* get the first byte */\n    l2byte = strtok_r(string, \",\", &token);\n    if (l2byte == NULL)\n        err(-1, \"Hex buffer must contain something\");\n    sscanf(l2byte, \"%x\", &value);\n    if (value > 0xff)\n        errx(-1, \"Invalid hex string byte: %s\", l2byte);\n    databyte = (u_char) value;\n    memcpy(&hex[numbytes], &databyte, 1);\n\n    /* get remaining bytes */\n    while ((l2byte = strtok_r(NULL, \",\", &token)) != NULL) {\n        numbytes++;\n        if (numbytes + 1 > hexlen) {\n            warn(\"Hex buffer too small for data- skipping data\");\n            goto done;\n        }\n        sscanf(l2byte, \"%x\", &value);\n        if (value > 0xff)\n            errx(-1, \"Invalid hex string byte: %s\", l2byte);\n        databyte = (u_char) value;\n        memcpy(&hex[numbytes], &databyte, 1);\n    }\n\n    numbytes++;\n\ndone:\n    safe_free(string);\n\n    dbgx(1, \"Read %d bytes of hex data\", numbytes);\n    return (numbytes);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,8 @@\n \n     /* get the first byte */\n     l2byte = strtok_r(string, \",\", &token);\n+    if (l2byte == NULL)\n+        err(-1, \"Hex buffer must contain something\");\n     sscanf(l2byte, \"%x\", &value);\n     if (value > 0xff)\n         errx(-1, \"Invalid hex string byte: %s\", l2byte);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (l2byte == NULL)",
                "        err(-1, \"Hex buffer must contain something\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-27786",
        "func_name": "appneta/tcpreplay/macinstring",
        "description": "An issue found in TCPprep v.4.4.3 allows a remote attacker to cause a denial of service via the macinstring function.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/df18c48812462ea802d639d2477887055666ee58",
        "commit_title": "Add check after call strtok_r",
        "commit_text": "",
        "func_before": "tcpr_dir_t\nmacinstring(const char *macstring, const u_char *mac)\n{\n    char *tok = NULL, *tempstr, *ourstring;\n    u_char tempmac[6];\n    int len = 6, ret = TCPR_DIR_S2C;\n    \n    ourstring = safe_strdup(macstring);\n    memset(&tempmac[0], 0, sizeof(tempmac));\n    \n    tempstr = strtok_r(ourstring, \",\", &tok);\n    if (strlen(tempstr)) {\n       mac2hex(tempstr, tempmac, len);\n       if (memcmp(mac, tempmac, len) == 0) {\n           dbgx(3, \"Packet matches: \" MAC_FORMAT \" sending out primary.\\n\", MAC_STR(tempmac));\n           ret = TCPR_DIR_C2S;\n           goto EXIT_MACINSTRING;\n       }\n    } else {\n        goto EXIT_MACINSTRING;\n    }\n\n    while ((tempstr = strtok_r(NULL, \",\", &tok)) != NULL) {\n       mac2hex(tempstr, tempmac, len);\n       if (memcmp(mac, tempmac, len) == 0) {\n           ret = TCPR_DIR_C2S;\n           dbgx(3, \"Packet matches: \" MAC_FORMAT \" sending out primary.\\n\", MAC_STR(tempmac));\n           goto EXIT_MACINSTRING;\n       }\n    }\n\nEXIT_MACINSTRING:\n    safe_free(ourstring);\n#ifdef DEBUG\n    if (ret == TCPR_DIR_S2C)\n       dbg(3, \"Packet doesn't match any MAC addresses sending out secondary.\\n\");\n#endif\n    return ret;\n}",
        "func": "tcpr_dir_t\nmacinstring(const char *macstring, const u_char *mac)\n{\n    char *tok = NULL, *tempstr, *ourstring;\n    u_char tempmac[6];\n    int len = 6, ret = TCPR_DIR_S2C;\n    \n    ourstring = safe_strdup(macstring);\n    memset(&tempmac[0], 0, sizeof(tempmac));\n    \n    tempstr = strtok_r(ourstring, \",\", &tok);\n    if (tempstr != NULL && strlen(tempstr)) {\n       mac2hex(tempstr, tempmac, len);\n       if (memcmp(mac, tempmac, len) == 0) {\n           dbgx(3, \"Packet matches: \" MAC_FORMAT \" sending out primary.\\n\", MAC_STR(tempmac));\n           ret = TCPR_DIR_C2S;\n           goto EXIT_MACINSTRING;\n       }\n    } else {\n        goto EXIT_MACINSTRING;\n    }\n\n    while ((tempstr = strtok_r(NULL, \",\", &tok)) != NULL) {\n       mac2hex(tempstr, tempmac, len);\n       if (memcmp(mac, tempmac, len) == 0) {\n           ret = TCPR_DIR_C2S;\n           dbgx(3, \"Packet matches: \" MAC_FORMAT \" sending out primary.\\n\", MAC_STR(tempmac));\n           goto EXIT_MACINSTRING;\n       }\n    }\n\nEXIT_MACINSTRING:\n    safe_free(ourstring);\n#ifdef DEBUG\n    if (ret == TCPR_DIR_S2C)\n       dbg(3, \"Packet doesn't match any MAC addresses sending out secondary.\\n\");\n#endif\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n     memset(&tempmac[0], 0, sizeof(tempmac));\n     \n     tempstr = strtok_r(ourstring, \",\", &tok);\n-    if (strlen(tempstr)) {\n+    if (tempstr != NULL && strlen(tempstr)) {\n        mac2hex(tempstr, tempmac, len);\n        if (memcmp(mac, tempmac, len) == 0) {\n            dbgx(3, \"Packet matches: \" MAC_FORMAT \" sending out primary.\\n\", MAC_STR(tempmac));",
        "diff_line_info": {
            "deleted_lines": [
                "    if (strlen(tempstr)) {"
            ],
            "added_lines": [
                "    if (tempstr != NULL && strlen(tempstr)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-27786",
        "func_name": "appneta/tcpreplay/parse_list",
        "description": "An issue found in TCPprep v.4.4.3 allows a remote attacker to cause a denial of service via the macinstring function.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/df18c48812462ea802d639d2477887055666ee58",
        "commit_title": "Add check after call strtok_r",
        "commit_text": "",
        "func_before": "int\nparse_list(tcpr_list_t ** listdata, char *ourstr)\n{\n    tcpr_list_t *listcur, *list_ptr;\n    char *this = NULL;\n    char *first, *second;\n    int rcode;\n    regex_t preg;\n    char regex[] = \"^[0-9]+(-[0-9]+)?$\";\n    char *token = NULL;\n    u_int i;\n\n\n    /* compile the regex first */\n    if ((rcode = regcomp(&preg, regex, REG_EXTENDED | REG_NOSUB)) != 0) {\n        char ebuf[EBUF_SIZE];\n        regerror(rcode, &preg, ebuf, sizeof(ebuf));\n        errx(-1, \"Unable to compile regex (%s): %s\", regex, ebuf);\n    }\n\n    /* first iteration */\n    this = strtok_r(ourstr, \",\", &token);\n    first = this;\n    second = NULL;\n\n    /* regex test */\n    if (regexec(&preg, this, 0, NULL, 0) != 0) {\n        warnx(\"Unable to parse: %s\", this);\n        regfree(&preg);\n        return 0;\n    }\n\n    *listdata = new_list();\n    list_ptr = *listdata;\n    listcur = list_ptr;\n\n    for (i = 0; i < strlen(this); i++) {\n        if (this[i] == '-') {\n            this[i] = '\\0';\n            second = &this[i + 1];\n        }\n    }\n\n    list_ptr->min = strtoull(first, NULL, 0);\n    if (second != NULL) {\n        list_ptr->max = strtoull(second, NULL, 0);\n    }\n    else {\n        list_ptr->max = list_ptr->min;\n    }\n\n    while (1) {\n        this = strtok_r(NULL, \",\", &token);\n        if (this == NULL)\n            break;\n\n        first = this;\n        second = NULL;\n\n\n        /* regex test */\n        if (regexec(&preg, this, 0, NULL, 0) != 0) {\n            warnx(\"Unable to parse: %s\", this);\n            regfree(&preg);\n            return 0;\n        }\n\n        listcur->next = new_list();\n        listcur = listcur->next;\n\n        for (i = 0; i < strlen(this); i++) {\n            if (this[i] == '-') {\n                this[i] = '\\0';\n                second = &this[i + 1];\n            }\n        }\n\n        listcur->min = strtoull(first, NULL, 0);\n        if (second != NULL) {\n            listcur->max = strtoull(second, NULL, 0);\n        }\n        else {\n            listcur->max = listcur->min;\n        }\n\n    }\n\n    regfree(&preg);\n\n    return 1;\n}",
        "func": "int\nparse_list(tcpr_list_t ** listdata, char *ourstr)\n{\n    tcpr_list_t *listcur, *list_ptr;\n    char *this = NULL;\n    char *first, *second;\n    int rcode;\n    regex_t preg;\n    char regex[] = \"^[0-9]+(-[0-9]+)?$\";\n    char *token = NULL;\n    u_int i;\n\n\n    /* compile the regex first */\n    if ((rcode = regcomp(&preg, regex, REG_EXTENDED | REG_NOSUB)) != 0) {\n        char ebuf[EBUF_SIZE];\n        regerror(rcode, &preg, ebuf, sizeof(ebuf));\n        errx(-1, \"Unable to compile regex (%s): %s\", regex, ebuf);\n    }\n\n    /* first iteration */\n    this = strtok_r(ourstr, \",\", &token);\n    first = this;\n    second = NULL;\n\n    /* regex test */\n    if (this == NULL || regexec(&preg, this, 0, NULL, 0) != 0) {\n        warnx(\"Unable to parse: %s\", this);\n        regfree(&preg);\n        return 0;\n    }\n\n    *listdata = new_list();\n    list_ptr = *listdata;\n    listcur = list_ptr;\n\n    for (i = 0; i < strlen(this); i++) {\n        if (this[i] == '-') {\n            this[i] = '\\0';\n            second = &this[i + 1];\n        }\n    }\n\n    list_ptr->min = strtoull(first, NULL, 0);\n    if (second != NULL) {\n        list_ptr->max = strtoull(second, NULL, 0);\n    }\n    else {\n        list_ptr->max = list_ptr->min;\n    }\n\n    while (1) {\n        this = strtok_r(NULL, \",\", &token);\n        if (this == NULL)\n            break;\n\n        first = this;\n        second = NULL;\n\n\n        /* regex test */\n        if (regexec(&preg, this, 0, NULL, 0) != 0) {\n            warnx(\"Unable to parse: %s\", this);\n            regfree(&preg);\n            return 0;\n        }\n\n        listcur->next = new_list();\n        listcur = listcur->next;\n\n        for (i = 0; i < strlen(this); i++) {\n            if (this[i] == '-') {\n                this[i] = '\\0';\n                second = &this[i + 1];\n            }\n        }\n\n        listcur->min = strtoull(first, NULL, 0);\n        if (second != NULL) {\n            listcur->max = strtoull(second, NULL, 0);\n        }\n        else {\n            listcur->max = listcur->min;\n        }\n\n    }\n\n    regfree(&preg);\n\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,7 +24,7 @@\n     second = NULL;\n \n     /* regex test */\n-    if (regexec(&preg, this, 0, NULL, 0) != 0) {\n+    if (this == NULL || regexec(&preg, this, 0, NULL, 0) != 0) {\n         warnx(\"Unable to parse: %s\", this);\n         regfree(&preg);\n         return 0;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (regexec(&preg, this, 0, NULL, 0) != 0) {"
            ],
            "added_lines": [
                "    if (this == NULL || regexec(&preg, this, 0, NULL, 0) != 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-27786",
        "func_name": "appneta/tcpreplay/parse_cidr",
        "description": "An issue found in TCPprep v.4.4.3 allows a remote attacker to cause a denial of service via the macinstring function.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/df18c48812462ea802d639d2477887055666ee58",
        "commit_title": "Add check after call strtok_r",
        "commit_text": "",
        "func_before": "int\nparse_cidr(tcpr_cidr_t ** cidrdata, char *cidrin, char *delim)\n{\n    tcpr_cidr_t *cidr_ptr;             /* ptr to current cidr record */\n    char *network;\n    char *token = NULL;\n\n    mask_cidr6(&cidrin, delim);\n\n    /* first iteration of input using strtok */\n    network = strtok_r(cidrin, delim, &token);\n\n    *cidrdata = cidr2cidr(network);\n    cidr_ptr = *cidrdata;\n\n    /* do the same with the rest of the input */\n    while (1) {\n        if (token)\n            mask_cidr6(&token, delim);\n\n        network = strtok_r(NULL, delim, &token);\n        /* if that was the last CIDR, then kickout */\n        if (network == NULL)\n            break;\n\n        /* next record */\n        cidr_ptr->next = cidr2cidr(network);\n        cidr_ptr = cidr_ptr->next;\n    }\n    return 1;\n\n}",
        "func": "int\nparse_cidr(tcpr_cidr_t ** cidrdata, char *cidrin, char *delim)\n{\n    tcpr_cidr_t *cidr_ptr;             /* ptr to current cidr record */\n    char *network;\n    char *token = NULL;\n\n    mask_cidr6(&cidrin, delim);\n\n    /* first iteration of input using strtok */\n    network = strtok_r(cidrin, delim, &token);\n    if (network == NULL)\n        return 0;\n\n    *cidrdata = cidr2cidr(network);\n    cidr_ptr = *cidrdata;\n\n    /* do the same with the rest of the input */\n    while (1) {\n        if (token)\n            mask_cidr6(&token, delim);\n\n        network = strtok_r(NULL, delim, &token);\n        /* if that was the last CIDR, then kickout */\n        if (network == NULL)\n            break;\n\n        /* next record */\n        cidr_ptr->next = cidr2cidr(network);\n        cidr_ptr = cidr_ptr->next;\n    }\n    return 1;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,8 @@\n \n     /* first iteration of input using strtok */\n     network = strtok_r(cidrin, delim, &token);\n+    if (network == NULL)\n+        return 0;\n \n     *cidrdata = cidr2cidr(network);\n     cidr_ptr = *cidrdata;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (network == NULL)",
                "        return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-27786",
        "func_name": "appneta/tcpreplay/parse_endpoints",
        "description": "An issue found in TCPprep v.4.4.3 allows a remote attacker to cause a denial of service via the macinstring function.",
        "git_url": "https://github.com/appneta/tcpreplay/commit/df18c48812462ea802d639d2477887055666ee58",
        "commit_title": "Add check after call strtok_r",
        "commit_text": "",
        "func_before": "int\nparse_endpoints(tcpr_cidrmap_t ** cidrmap1, tcpr_cidrmap_t ** cidrmap2, const char *optarg)\n{\n#define NEWMAP_LEN (INET6_ADDRSTRLEN * 2)\n    char *map = NULL, newmap[NEWMAP_LEN];\n    char *token = NULL;\n    char *string;\n    char *p;\n    int res = 0;\n\n    string = safe_strdup(optarg);\n\n    if (*string == '[') {\n        /* ipv6 mode */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        p = strstr(string, \"]:[\");\n        if (!p)\n            goto done;\n            \n        *p = 0;\n        strlcpy(newmap, \"[::/0]:\", NEWMAP_LEN);\n        strlcat(newmap, string, NEWMAP_LEN);\n        strlcat(newmap, \"]\", NEWMAP_LEN);\n        \n        if (! parse_cidr_map(cidrmap1, newmap))\n            goto done;\n\n        /* do again with the second IP */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        strlcpy(newmap, \"[::/0]:\", NEWMAP_LEN);\n        strlcat(newmap, p + 2, NEWMAP_LEN);\n\n        if (! parse_cidr_map(cidrmap2, newmap))\n            goto done;\n\n    } else {\n        /* ipv4 mode */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        map = strtok_r(string, \":\", &token);\n\n        strlcpy(newmap, \"0.0.0.0/0:\", NEWMAP_LEN);\n        strlcat(newmap, map, NEWMAP_LEN);\n        if (! parse_cidr_map(cidrmap1, newmap))\n            goto done;\n    \n        /* do again with the second IP */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        map = strtok_r(NULL, \":\", &token);\n    \n        strlcpy(newmap, \"0.0.0.0/0:\", NEWMAP_LEN);\n        strlcat(newmap, map, NEWMAP_LEN);\n        if (! parse_cidr_map(cidrmap2, newmap))\n            goto done;\n    }\n    \n    /* success */\n    res = 1;\n\ndone:\n    safe_free(string);\n    return res;\n}",
        "func": "int\nparse_endpoints(tcpr_cidrmap_t ** cidrmap1, tcpr_cidrmap_t ** cidrmap2, const char *optarg)\n{\n#define NEWMAP_LEN (INET6_ADDRSTRLEN * 2)\n    char *map = NULL, newmap[NEWMAP_LEN];\n    char *token = NULL;\n    char *string;\n    char *p;\n    int res = 0;\n\n    string = safe_strdup(optarg);\n\n    if (*string == '[') {\n        /* ipv6 mode */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        p = strstr(string, \"]:[\");\n        if (!p)\n            goto done;\n            \n        *p = 0;\n        strlcpy(newmap, \"[::/0]:\", NEWMAP_LEN);\n        strlcat(newmap, string, NEWMAP_LEN);\n        strlcat(newmap, \"]\", NEWMAP_LEN);\n        \n        if (! parse_cidr_map(cidrmap1, newmap))\n            goto done;\n\n        /* do again with the second IP */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        strlcpy(newmap, \"[::/0]:\", NEWMAP_LEN);\n        strlcat(newmap, p + 2, NEWMAP_LEN);\n\n        if (! parse_cidr_map(cidrmap2, newmap))\n            goto done;\n\n    } else {\n        /* ipv4 mode */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        map = strtok_r(string, \":\", &token);\n        if (map == NULL)\n            goto done;\n\n        strlcpy(newmap, \"0.0.0.0/0:\", NEWMAP_LEN);\n        strlcat(newmap, map, NEWMAP_LEN);\n        if (! parse_cidr_map(cidrmap1, newmap))\n            goto done;\n    \n        /* do again with the second IP */\n        memset(newmap, '\\0', NEWMAP_LEN);\n        map = strtok_r(NULL, \":\", &token);\n    \n        strlcpy(newmap, \"0.0.0.0/0:\", NEWMAP_LEN);\n        strlcat(newmap, map, NEWMAP_LEN);\n        if (! parse_cidr_map(cidrmap2, newmap))\n            goto done;\n    }\n    \n    /* success */\n    res = 1;\n\ndone:\n    safe_free(string);\n    return res;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,6 +37,8 @@\n         /* ipv4 mode */\n         memset(newmap, '\\0', NEWMAP_LEN);\n         map = strtok_r(string, \":\", &token);\n+        if (map == NULL)\n+            goto done;\n \n         strlcpy(newmap, \"0.0.0.0/0:\", NEWMAP_LEN);\n         strlcat(newmap, map, NEWMAP_LEN);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (map == NULL)",
                "            goto done;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-28856",
        "func_name": "redis/hincrbyfloatCommand",
        "description": "Redis is an open source, in-memory database that persists on disk. Authenticated users can use the `HINCRBYFLOAT` command to create an invalid hash field that will crash Redis on access in affected versions. This issue has been addressed in in versions 7.0.11, 6.2.12, and 6.0.19. Users are advised to upgrade. There are no known workarounds for this issue.",
        "git_url": "https://github.com/redis/redis/commit/bc7fe41e5857a0854d524e2a63a028e9394d2a5c",
        "commit_title": "fix hincrbyfloat not to create a key if the new value is invalid (#11149)",
        "commit_text": " Check the validity of the value before performing the create operation,\r prevents new data from being generated even if the request fails to execute.\r \r Co-authored-by: Oran Agra <oran@redislabs.com>\r Co-authored-by: chendianqiang <chendianqiang@meituan.com>\r Co-authored-by: Binbin <binloveplay1314@qq.com>",
        "func_before": "void hincrbyfloatCommand(client *c) {\n    long double value, incr;\n    long long ll;\n    robj *o;\n    sds new;\n    unsigned char *vstr;\n    unsigned int vlen;\n\n    if (getLongDoubleFromObjectOrReply(c,c->argv[3],&incr,NULL) != C_OK) return;\n    if ((o = hashTypeLookupWriteOrCreate(c,c->argv[1])) == NULL) return;\n    if (hashTypeGetValue(o,c->argv[2]->ptr,&vstr,&vlen,&ll) == C_OK) {\n        if (vstr) {\n            if (string2ld((char*)vstr,vlen,&value) == 0) {\n                addReplyError(c,\"hash value is not a float\");\n                return;\n            }\n        } else {\n            value = (long double)ll;\n        }\n    } else {\n        value = 0;\n    }\n\n    value += incr;\n    if (isnan(value) || isinf(value)) {\n        addReplyError(c,\"increment would produce NaN or Infinity\");\n        return;\n    }\n\n    char buf[MAX_LONG_DOUBLE_CHARS];\n    int len = ld2string(buf,sizeof(buf),value,LD_STR_HUMAN);\n    new = sdsnewlen(buf,len);\n    hashTypeSet(o,c->argv[2]->ptr,new,HASH_SET_TAKE_VALUE);\n    addReplyBulkCBuffer(c,buf,len);\n    signalModifiedKey(c,c->db,c->argv[1]);\n    notifyKeyspaceEvent(NOTIFY_HASH,\"hincrbyfloat\",c->argv[1],c->db->id);\n    server.dirty++;\n\n    /* Always replicate HINCRBYFLOAT as an HSET command with the final value\n     * in order to make sure that differences in float precision or formatting\n     * will not create differences in replicas or after an AOF restart. */\n    robj *newobj;\n    newobj = createRawStringObject(buf,len);\n    rewriteClientCommandArgument(c,0,shared.hset);\n    rewriteClientCommandArgument(c,3,newobj);\n    decrRefCount(newobj);\n}",
        "func": "void hincrbyfloatCommand(client *c) {\n    long double value, incr;\n    long long ll;\n    robj *o;\n    sds new;\n    unsigned char *vstr;\n    unsigned int vlen;\n\n    if (getLongDoubleFromObjectOrReply(c,c->argv[3],&incr,NULL) != C_OK) return;\n    if (isnan(incr) || isinf(incr)) {\n        addReplyError(c,\"value is NaN or Infinity\");\n        return;\n    }\n    if ((o = hashTypeLookupWriteOrCreate(c,c->argv[1])) == NULL) return;\n    if (hashTypeGetValue(o,c->argv[2]->ptr,&vstr,&vlen,&ll) == C_OK) {\n        if (vstr) {\n            if (string2ld((char*)vstr,vlen,&value) == 0) {\n                addReplyError(c,\"hash value is not a float\");\n                return;\n            }\n        } else {\n            value = (long double)ll;\n        }\n    } else {\n        value = 0;\n    }\n\n    value += incr;\n    if (isnan(value) || isinf(value)) {\n        addReplyError(c,\"increment would produce NaN or Infinity\");\n        return;\n    }\n\n    char buf[MAX_LONG_DOUBLE_CHARS];\n    int len = ld2string(buf,sizeof(buf),value,LD_STR_HUMAN);\n    new = sdsnewlen(buf,len);\n    hashTypeSet(o,c->argv[2]->ptr,new,HASH_SET_TAKE_VALUE);\n    addReplyBulkCBuffer(c,buf,len);\n    signalModifiedKey(c,c->db,c->argv[1]);\n    notifyKeyspaceEvent(NOTIFY_HASH,\"hincrbyfloat\",c->argv[1],c->db->id);\n    server.dirty++;\n\n    /* Always replicate HINCRBYFLOAT as an HSET command with the final value\n     * in order to make sure that differences in float precision or formatting\n     * will not create differences in replicas or after an AOF restart. */\n    robj *newobj;\n    newobj = createRawStringObject(buf,len);\n    rewriteClientCommandArgument(c,0,shared.hset);\n    rewriteClientCommandArgument(c,3,newobj);\n    decrRefCount(newobj);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,10 @@\n     unsigned int vlen;\n \n     if (getLongDoubleFromObjectOrReply(c,c->argv[3],&incr,NULL) != C_OK) return;\n+    if (isnan(incr) || isinf(incr)) {\n+        addReplyError(c,\"value is NaN or Infinity\");\n+        return;\n+    }\n     if ((o = hashTypeLookupWriteOrCreate(c,c->argv[1])) == NULL) return;\n     if (hashTypeGetValue(o,c->argv[2]->ptr,&vstr,&vlen,&ll) == C_OK) {\n         if (vstr) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (isnan(incr) || isinf(incr)) {",
                "        addReplyError(c,\"value is NaN or Infinity\");",
                "        return;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-23759",
        "func_name": "facebookincubator/fizz/EventHandler<ServerTypes, StateEnum::ExpectingClientHello, Event::ClientHello>::\n    handle",
        "description": "There is a vulnerability in the fizz library prior to v2023.01.30.00 where a CHECK failure can be triggered remotely. This behavior requires the client supported cipher advertisement changing between the original ClientHello and the second ClientHello, crashing the process (impact is limited to denial of service).",
        "git_url": "https://github.com/facebookincubator/fizz/commit/8d3649841597bedfb6986c30431ebad0eb215265",
        "commit_title": "Check HelloRetryRequest cipher consistency earlier.",
        "commit_text": " CVE-2023-23759\r \r Co-authored-by: Facebook Community Bot <6422482+facebook-github-bot@users.noreply.github.com>\r \r Differential Revision: D42508182",
        "func_before": "AsyncActions\nEventHandler<ServerTypes, StateEnum::ExpectingClientHello, Event::ClientHello>::\n    handle(const State& state, Param param) {\n  ClientHello chlo = std::move(*param.asClientHello());\n\n  auto cookieState = getCookieState(chlo, state.context()->getCookieCipher());\n\n  if (state.handshakeContext() && cookieState.has_value()) {\n    throw FizzException(\n        \"cookie after statefull hrr\", AlertDescription::illegal_parameter);\n  }\n\n  ECHStatus echStatus;\n  ECHState echState;\n  std::tie(echStatus, echState) = processECH(cookieState, state, chlo);\n\n  addHandshakeLogging(state, chlo);\n\n  if (state.readRecordLayer()->hasUnparsedHandshakeData()) {\n    throw FizzException(\n        \"data after client hello\", AlertDescription::unexpected_message);\n  }\n\n  auto version =\n      negotiateVersion(chlo, state.context()->getSupportedVersions());\n\n  if (state.version().has_value() &&\n      (!version || *version != *state.version())) {\n    throw FizzException(\n        \"version mismatch with previous negotiation\",\n        AlertDescription::illegal_parameter);\n  }\n\n  if (!version) {\n    if (getExtension<ClientEarlyData>(chlo.extensions)) {\n      throw FizzException(\n          \"supported version mismatch with early data\",\n          AlertDescription::protocol_version);\n    }\n    if (state.context()->getVersionFallbackEnabled()) {\n      AttemptVersionFallback fallback;\n      // Re-encode to put the record layer header back on. This won't\n      // necessarily preserve it byte-for-byte, but it isn't authenticated so\n      // should be ok.\n      fallback.clientHello =\n          PlaintextWriteRecordLayer()\n              .writeInitialClientHello(std::move(*chlo.originalEncoding))\n              .data;\n      return actions(\n          MutateState(&Transition<StateEnum::Error>), std::move(fallback));\n    } else {\n      throw FizzException(\n          \"supported version mismatch\", AlertDescription::protocol_version);\n    }\n  }\n\n  state.writeRecordLayer()->setProtocolVersion(*version);\n\n  validateClientHello(chlo);\n\n  auto cipher = negotiateCipher(chlo, state.context()->getSupportedCiphers());\n\n  verifyCookieState(cookieState, *version, cipher);\n\n  auto resStateResult = getResumptionState(\n      chlo,\n      state.context()->getTicketCipher(),\n      state.context()->getSupportedPskModes());\n\n  auto replayCacheResultFuture = getReplayCacheResult(\n      chlo,\n      state.context()->getAcceptEarlyData(*version),\n      state.context()->getReplayCache());\n\n  auto results =\n      collectAll(resStateResult.futureResState, replayCacheResultFuture);\n\n  using FutureResultType = std::tuple<\n      folly::Try<std::pair<PskType, Optional<ResumptionState>>>,\n      folly::Try<ReplayCacheResult>>;\n  return runOnCallerIfComplete(\n      state.executor(),\n      std::move(results),\n      [&state,\n       chlo = std::move(chlo),\n       cookieState = std::move(cookieState),\n       version = *version,\n       cipher,\n       pskMode = resStateResult.pskMode,\n       echStatus,\n       echState = std::move(echState),\n       obfuscatedAge =\n           resStateResult.obfuscatedAge](FutureResultType result) mutable {\n        auto& resumption = *std::get<0>(result);\n        auto pskType = resumption.first;\n        auto resState = std::move(resumption.second);\n        auto replayCacheResult = *std::get<1>(result);\n\n        if (resState) {\n          if (!validateResumptionState(*resState, *pskMode, version, cipher)) {\n            pskType = PskType::Rejected;\n            pskMode = folly::none;\n            resState = folly::none;\n          }\n        } else {\n          pskMode = folly::none;\n        }\n\n        auto legacySessionId = chlo.legacy_session_id->clone();\n\n        // If we successfully resumed, set the handshake time to the ticket's\n        // handshake time to preserve it across ticket updates. If not, set it\n        // to now.\n        std::chrono::system_clock::time_point handshakeTime;\n        if (resState) {\n          handshakeTime = resState->handshakeTime;\n        } else {\n          handshakeTime = state.context()->getClock().getCurrentTime();\n        }\n\n        std::unique_ptr<KeyScheduler> scheduler;\n        std::unique_ptr<HandshakeContext> handshakeContext;\n        std::tie(scheduler, handshakeContext) = setupSchedulerAndContext(\n            *state.context()->getFactory(),\n            cipher,\n            chlo,\n            resState,\n            cookieState,\n            pskType,\n            std::move(state.handshakeContext()),\n            version);\n\n        if (state.cipher().has_value() && cipher != *state.cipher()) {\n          throw FizzException(\n              \"cipher mismatch with previous negotiation\",\n              AlertDescription::illegal_parameter);\n        }\n\n        auto alpn = negotiateAlpn(chlo, folly::none, *state.context());\n\n        auto clockSkew = getClockSkew(\n            resState,\n            obfuscatedAge,\n            state.context()->getClock().getCurrentTime());\n\n        auto appToken = getAppToken(resState);\n\n        auto earlyDataType = negotiateEarlyDataType(\n            state.context()->getAcceptEarlyData(version),\n            chlo,\n            resState,\n            cipher,\n            state.keyExchangeType(),\n            cookieState,\n            alpn,\n            replayCacheResult,\n            clockSkew,\n            state.context()->getClockSkewTolerance(),\n            state.appTokenValidator());\n\n        std::unique_ptr<EncryptedReadRecordLayer> earlyReadRecordLayer;\n        Buf earlyExporterMaster;\n        folly::Optional<SecretAvailable> earlyReadSecretAvailable;\n        if (earlyDataType == EarlyDataType::Accepted) {\n          auto earlyContext = handshakeContext->getHandshakeContext();\n          auto earlyReadSecret = scheduler->getSecret(\n              EarlySecrets::ClientEarlyTraffic, earlyContext->coalesce());\n          if (!state.context()->getOmitEarlyRecordLayer()) {\n            earlyReadRecordLayer =\n                state.context()->getFactory()->makeEncryptedReadRecordLayer(\n                    EncryptionLevel::EarlyData);\n            earlyReadRecordLayer->setProtocolVersion(version);\n\n            Protocol::setAead(\n                *earlyReadRecordLayer,\n                cipher,\n                folly::range(earlyReadSecret.secret),\n                *state.context()->getFactory(),\n                *scheduler);\n          }\n\n          earlyReadSecretAvailable =\n              SecretAvailable(std::move(earlyReadSecret));\n          earlyExporterMaster = folly::IOBuf::copyBuffer(\n              scheduler\n                  ->getSecret(\n                      EarlySecrets::EarlyExporter, earlyContext->coalesce())\n                  .secret);\n        }\n\n        Optional<NamedGroup> group;\n        KeyExchangeType keyExchangeType;\n        SemiFuture<Optional<AsyncKeyExchange::DoKexResult>> kexResultFuture =\n            folly::none;\n        std::unique_ptr<KeyExchange> kex = nullptr;\n\n        if (!pskMode || *pskMode != PskKeyExchangeMode::psk_ke) {\n          Optional<Buf> clientShare;\n          std::tie(group, clientShare) = negotiateGroup(\n              version, chlo, state.context()->getSupportedGroups());\n          if (!clientShare) {\n            VLOG(8) << \"Did not find key share for \" << toString(*group);\n            if (state.group().has_value() || cookieState) {\n              throw FizzException(\n                  \"key share not found for already negotiated group\",\n                  AlertDescription::illegal_parameter);\n            }\n\n            // If we were otherwise going to accept early data we now need to\n            // reject it. It's a little ugly to change our previous early data\n            // decision, but doing it this way allows us to move the key\n            // schedule forward as we do the key exchange.\n            if (earlyDataType == EarlyDataType::Accepted) {\n              earlyDataType = EarlyDataType::Rejected;\n            }\n\n            message_hash chloHash;\n            chloHash.hash = handshakeContext->getHandshakeContext();\n            handshakeContext =\n                state.context()->getFactory()->makeHandshakeContext(cipher);\n            handshakeContext->appendToTranscript(\n                encodeHandshake(std::move(chloHash)));\n\n            auto hrr = getHelloRetryRequest(\n                version,\n                cipher,\n                *group,\n                legacySessionId ? legacySessionId->clone() : nullptr,\n                *handshakeContext);\n\n            if (echStatus == ECHStatus::Accepted) {\n              // Set up acceptance scheduler\n              auto echScheduler =\n                  state.context()->getFactory()->makeKeyScheduler(cipher);\n              echScheduler->deriveEarlySecret(folly::range(chlo.random));\n              // Add acceptance extension\n              ech::setAcceptConfirmation(\n                  hrr, handshakeContext->clone(), std::move(echScheduler));\n            }\n\n            auto encodedHelloRetryRequest = encodeHandshake(std::move(hrr));\n            handshakeContext->appendToTranscript(encodedHelloRetryRequest);\n\n            WriteToSocket serverFlight;\n            serverFlight.contents.emplace_back(\n                state.writeRecordLayer()->writeHandshake(\n                    std::move(encodedHelloRetryRequest)));\n\n            if (legacySessionId && !legacySessionId->empty()) {\n              TLSContent writeCCS;\n              writeCCS.encryptionLevel = EncryptionLevel::Plaintext;\n              writeCCS.contentType = ContentType::change_cipher_spec;\n              writeCCS.data = folly::IOBuf::wrapBuffer(FakeChangeCipherSpec);\n              serverFlight.contents.emplace_back(std::move(writeCCS));\n            }\n\n            // Create a new record layer in case we need to skip early data.\n            auto newReadRecordLayer =\n                state.context()->getFactory()->makePlaintextReadRecordLayer();\n            newReadRecordLayer->setSkipEncryptedRecords(\n                earlyDataType == EarlyDataType::Rejected);\n\n            return SemiFuture<Actions>(actions(\n                MutateState([handshakeContext = std::move(handshakeContext),\n                             version,\n                             cipher,\n                             group,\n                             earlyDataType,\n                             replayCacheResult,\n                             newReadRecordLayer = std::move(newReadRecordLayer),\n                             echStatus,\n                             echState =\n                                 std::move(echState)](State& newState) mutable {\n                  // Save some information about the current state to be\n                  // validated when we get the second client hello. We don't\n                  // validate that the second client hello matches the first\n                  // as strictly as we could according to the spec however.\n                  newState.handshakeContext() = std::move(handshakeContext);\n                  newState.version() = version;\n                  newState.cipher() = cipher;\n                  newState.group() = group;\n                  newState.keyExchangeType() =\n                      KeyExchangeType::HelloRetryRequest;\n                  newState.earlyDataType() = earlyDataType;\n                  newState.replayCacheResult() = replayCacheResult;\n                  newState.readRecordLayer() = std::move(newReadRecordLayer);\n                  newState.echStatus() = echStatus;\n                  if (echStatus == ECHStatus::Accepted) {\n                    newState.echState() = std::move(echState);\n                  }\n                }),\n                std::move(serverFlight),\n                MutateState(&Transition<StateEnum::ExpectingClientHello>)));\n          }\n\n          if (state.keyExchangeType().has_value()) {\n            keyExchangeType = *state.keyExchangeType();\n          } else {\n            keyExchangeType = KeyExchangeType::OneRtt;\n          }\n\n          // The exceptions in SemiFutures will be processed in\n          // detail::processEvent.\n          kex = state.context()->getFactory()->makeKeyExchange(\n              *group, Factory::KeyExchangeMode::Server);\n          kexResultFuture =\n              doKexFuture(kex.get(), std::move(clientShare.value()));\n        } else {\n          keyExchangeType = KeyExchangeType::None;\n        }\n\n        return runOnCallerIfComplete(\n            state.executor(),\n            std::move(kexResultFuture),\n            [&state,\n             scheduler = std::move(scheduler),\n             handshakeContext = std::move(handshakeContext),\n             cipher,\n             group,\n             echStatus,\n             earlyReadRecordLayer = std::move(earlyReadRecordLayer),\n             earlyReadSecretAvailable = std::move(earlyReadSecretAvailable),\n             earlyExporterMaster = std::move(earlyExporterMaster),\n             pskType,\n             pskMode,\n             version,\n             keyExchangeType,\n             earlyDataType,\n             replayCacheResult,\n             alpn = std::move(alpn),\n             clockSkew,\n             appToken = std::move(appToken),\n             legacySessionId = std::move(legacySessionId),\n             handshakeTime,\n             chlo = std::move(chlo),\n             cookieState = std::move(cookieState),\n             resState = std::move(resState),\n             // Hold kex until the doKexFuture finished.\n             kex = std::move(kex)](\n                Optional<AsyncKeyExchange::DoKexResult> kexResult) mutable {\n              Optional<Buf> serverShare;\n              if (kexResult.hasValue()) {\n                serverShare = std::move(kexResult.value().ourKeyShare);\n                scheduler->deriveHandshakeSecret(\n                    kexResult.value().sharedSecret->coalesce());\n              } else {\n                DCHECK(keyExchangeType == KeyExchangeType::None);\n                scheduler->deriveHandshakeSecret();\n              }\n              std::vector<Extension> additionalExtensions;\n              if (state.extensions()) {\n                additionalExtensions = state.extensions()->getExtensions(chlo);\n              }\n\n              if (state.group().has_value() &&\n                  (!group || *group != *state.group())) {\n                throw FizzException(\n                    \"group mismatch with previous negotiation\",\n                    AlertDescription::illegal_parameter);\n              }\n\n              // Cookies are not required to have already negotiated the group\n              // but if they did it must match (psk_ke is still allowed as we\n              // may not know if we are accepting the psk when sending the\n              // cookie).\n              if (cookieState && cookieState->group && group &&\n                  *group != *cookieState->group) {\n                throw FizzException(\n                    \"group mismatch with cookie\",\n                    AlertDescription::illegal_parameter);\n              }\n\n              auto serverHello = getServerHello(\n                  version,\n                  state.context()->getFactory()->makeRandom(),\n                  cipher,\n                  resState.has_value(),\n                  group,\n                  std::move(serverShare),\n                  legacySessionId ? legacySessionId->clone() : nullptr);\n\n              folly::Optional<std::vector<ech::ECHConfig>> echRetryConfigs;\n              if (echStatus == ECHStatus::Accepted) {\n                // Set up acceptance scheduler\n                auto echScheduler =\n                    state.context()->getFactory()->makeKeyScheduler(cipher);\n                echScheduler->deriveEarlySecret(folly::range(chlo.random));\n                // Add acceptance extension\n                ech::setAcceptConfirmation(\n                    serverHello,\n                    handshakeContext->clone(),\n                    std::move(echScheduler));\n              } else if (echStatus == ECHStatus::Rejected) {\n                auto decrypter = state.context()->getECHDecrypter();\n                echRetryConfigs = decrypter->getRetryConfigs();\n              }\n\n              auto encodedServerHello = encodeHandshake(std::move(serverHello));\n              handshakeContext->appendToTranscript(encodedServerHello);\n\n              // Derive handshake keys.\n              auto handshakeWriteRecordLayer =\n                  state.context()->getFactory()->makeEncryptedWriteRecordLayer(\n                      EncryptionLevel::Handshake);\n              handshakeWriteRecordLayer->setProtocolVersion(version);\n              auto handshakeWriteSecret = scheduler->getSecret(\n                  HandshakeSecrets::ServerHandshakeTraffic,\n                  handshakeContext->getHandshakeContext()->coalesce());\n              Protocol::setAead(\n                  *handshakeWriteRecordLayer,\n                  cipher,\n                  folly::range(handshakeWriteSecret.secret),\n                  *state.context()->getFactory(),\n                  *scheduler);\n\n              auto handshakeReadRecordLayer =\n                  state.context()->getFactory()->makeEncryptedReadRecordLayer(\n                      EncryptionLevel::Handshake);\n              handshakeReadRecordLayer->setProtocolVersion(version);\n              handshakeReadRecordLayer->setSkipFailedDecryption(\n                  earlyDataType == EarlyDataType::Rejected);\n              auto handshakeReadSecret = scheduler->getSecret(\n                  HandshakeSecrets::ClientHandshakeTraffic,\n                  handshakeContext->getHandshakeContext()->coalesce());\n              Protocol::setAead(\n                  *handshakeReadRecordLayer,\n                  cipher,\n                  folly::range(handshakeReadSecret.secret),\n                  *state.context()->getFactory(),\n                  *scheduler);\n              auto clientHandshakeSecret =\n                  folly::IOBuf::copyBuffer(handshakeReadSecret.secret);\n\n              auto encodedEncryptedExt = getEncryptedExt(\n                  *handshakeContext,\n                  alpn,\n                  earlyDataType,\n                  std::move(echRetryConfigs),\n                  std::move(additionalExtensions));\n\n              /*\n               * Determine we are requesting client auth.\n               * If yes, add CertificateRequest to handshake write and\n               * transcript.\n               */\n              bool requestClientAuth = state.context()->getClientAuthMode() !=\n                      ClientAuthMode::None &&\n                  !resState;\n              Optional<Buf> encodedCertRequest;\n              if (requestClientAuth) {\n                encodedCertRequest = getCertificateRequest(\n                    state.context()->getSupportedSigSchemes(),\n                    state.context()->getClientCertVerifier().get(),\n                    *handshakeContext);\n              }\n\n              /*\n               * Set the cert and signature scheme we are using.\n               * If sending new cert, add Certificate to handshake write and\n               * transcript.\n               */\n              Optional<Buf> encodedCertificate;\n              SemiFuture<Optional<Buf>> signature = folly::none;\n              Optional<SignatureScheme> sigScheme;\n              Optional<std::shared_ptr<const Cert>> serverCert;\n              std::shared_ptr<const Cert> clientCert;\n              Optional<CertificateCompressionAlgorithm> certCompressionAlgo;\n              if (!resState) { // TODO or reauth\n                std::shared_ptr<const SelfCert> originalSelfCert;\n                std::tie(originalSelfCert, sigScheme) =\n                    chooseCert(*state.context(), chlo);\n\n                std::tie(encodedCertificate, certCompressionAlgo) =\n                    getCertificate(\n                        originalSelfCert,\n                        *state.context(),\n                        chlo,\n                        *handshakeContext);\n\n                auto toBeSigned = handshakeContext->getHandshakeContext();\n                auto asyncSelfCert =\n                    dynamic_cast<const AsyncSelfCert*>(originalSelfCert.get());\n                if (asyncSelfCert) {\n                  signature = asyncSelfCert->signFuture(\n                      *sigScheme,\n                      CertificateVerifyContext::Server,\n                      std::move(toBeSigned));\n                } else {\n                  signature = folly::makeSemiFuture<Optional<Buf>>(\n                      originalSelfCert->sign(\n                          *sigScheme,\n                          CertificateVerifyContext::Server,\n                          toBeSigned->coalesce()));\n                }\n                serverCert = std::move(originalSelfCert);\n              } else {\n                serverCert = std::move(resState->serverCert);\n                clientCert = std::move(resState->clientCert);\n              }\n\n              auto clientRandom = std::move(chlo.random);\n\n              return runOnCallerIfComplete(\n                  state.executor(),\n                  std::move(signature),\n                  [&state,\n                   scheduler = std::move(scheduler),\n                   handshakeContext = std::move(handshakeContext),\n                   cipher,\n                   clientRandom = std::move(clientRandom),\n                   group,\n                   echStatus,\n                   encodedServerHello = std::move(encodedServerHello),\n                   handshakeWriteRecordLayer =\n                       std::move(handshakeWriteRecordLayer),\n                   handshakeWriteSecret = std::move(handshakeWriteSecret),\n                   handshakeReadRecordLayer =\n                       std::move(handshakeReadRecordLayer),\n                   handshakeReadSecret = std::move(handshakeReadSecret),\n                   earlyReadRecordLayer = std::move(earlyReadRecordLayer),\n                   earlyReadSecretAvailable =\n                       std::move(earlyReadSecretAvailable),\n                   earlyExporterMaster = std::move(earlyExporterMaster),\n                   clientHandshakeSecret = std::move(clientHandshakeSecret),\n                   encodedEncryptedExt = std::move(encodedEncryptedExt),\n                   encodedCertificate = std::move(encodedCertificate),\n                   encodedCertRequest = std::move(encodedCertRequest),\n                   requestClientAuth,\n                   pskType,\n                   pskMode,\n                   sigScheme,\n                   version,\n                   keyExchangeType,\n                   earlyDataType,\n                   replayCacheResult,\n                   serverCert = std::move(serverCert),\n                   clientCert = std::move(clientCert),\n                   alpn = std::move(alpn),\n                   clockSkew,\n                   appToken = std::move(appToken),\n                   legacySessionId = std::move(legacySessionId),\n                   serverCertCompAlgo = certCompressionAlgo,\n                   handshakeTime](Optional<Buf> sig) mutable {\n                    Optional<Buf> encodedCertificateVerify;\n                    if (sig) {\n                      encodedCertificateVerify = getCertificateVerify(\n                          *sigScheme, std::move(*sig), *handshakeContext);\n                    }\n\n                    auto encodedFinished = Protocol::getFinished(\n                        folly::range(handshakeWriteSecret.secret),\n                        *handshakeContext);\n\n                    folly::IOBufQueue combined;\n                    if (encodedCertificate) {\n                      if (encodedCertRequest) {\n                        combined.append(std::move(encodedEncryptedExt));\n                        combined.append(std::move(*encodedCertRequest));\n                        combined.append(std::move(*encodedCertificate));\n                        combined.append(std::move(*encodedCertificateVerify));\n                        combined.append(std::move(encodedFinished));\n                      } else {\n                        combined.append(std::move(encodedEncryptedExt));\n                        combined.append(std::move(*encodedCertificate));\n                        combined.append(std::move(*encodedCertificateVerify));\n                        combined.append(std::move(encodedFinished));\n                      }\n                    } else {\n                      combined.append(std::move(encodedEncryptedExt));\n                      combined.append(std::move(encodedFinished));\n                    }\n\n                    // Some middleboxes appear to break if the first encrypted\n                    // record is larger than ~1300 bytes (likely if it does not\n                    // fit in the first packet).\n                    auto serverEncrypted =\n                        handshakeWriteRecordLayer->writeHandshake(\n                            combined.splitAtMost(1000));\n                    if (!combined.empty()) {\n                      auto splitRecord =\n                          handshakeWriteRecordLayer->writeHandshake(\n                              combined.move());\n                      // Split record must have the same encryption level as the\n                      // main handshake.\n                      DCHECK(\n                          splitRecord.encryptionLevel ==\n                          serverEncrypted.encryptionLevel);\n                      serverEncrypted.data->prependChain(\n                          std::move(splitRecord.data));\n                    }\n\n                    WriteToSocket serverFlight;\n                    serverFlight.contents.emplace_back(\n                        state.writeRecordLayer()->writeHandshake(\n                            std::move(encodedServerHello)));\n                    if (legacySessionId && !legacySessionId->empty()) {\n                      TLSContent ccsWrite;\n                      ccsWrite.encryptionLevel = EncryptionLevel::Plaintext;\n                      ccsWrite.contentType = ContentType::change_cipher_spec;\n                      ccsWrite.data =\n                          folly::IOBuf::wrapBuffer(FakeChangeCipherSpec);\n                      serverFlight.contents.emplace_back(std::move(ccsWrite));\n                    }\n                    serverFlight.contents.emplace_back(\n                        std::move(serverEncrypted));\n\n                    scheduler->deriveMasterSecret();\n                    auto clientFinishedContext =\n                        handshakeContext->getHandshakeContext();\n                    auto exporterMasterVector = scheduler->getSecret(\n                        MasterSecrets::ExporterMaster,\n                        clientFinishedContext->coalesce());\n                    auto exporterMaster = folly::IOBuf::copyBuffer(\n                        folly::range(exporterMasterVector.secret));\n\n                    scheduler->deriveAppTrafficSecrets(\n                        clientFinishedContext->coalesce());\n                    auto appTrafficWriteRecordLayer =\n                        state.context()\n                            ->getFactory()\n                            ->makeEncryptedWriteRecordLayer(\n                                EncryptionLevel::AppTraffic);\n                    appTrafficWriteRecordLayer->setProtocolVersion(version);\n                    auto writeSecret = scheduler->getSecret(\n                        AppTrafficSecrets::ServerAppTraffic);\n                    Protocol::setAead(\n                        *appTrafficWriteRecordLayer,\n                        cipher,\n                        folly::range(writeSecret.secret),\n                        *state.context()->getFactory(),\n                        *scheduler);\n\n                    // If we have previously dealt with early data (before a\n                    // HelloRetryRequest), don't overwrite the previous result.\n                    auto earlyDataTypeSave = state.earlyDataType()\n                        ? *state.earlyDataType()\n                        : earlyDataType;\n\n                    SecretAvailable handshakeReadSecretAvailable(\n                        std::move(handshakeReadSecret));\n                    SecretAvailable handshakeWriteSecretAvailable(\n                        std::move(handshakeWriteSecret));\n                    SecretAvailable appWriteSecretAvailable(\n                        std::move(writeSecret));\n\n                    // Save all the necessary state except for the read record\n                    // layer, which is done separately as it varies if early\n                    // data was accepted.\n                    MutateState saveState(\n                        [appTrafficWriteRecordLayer =\n                             std::move(appTrafficWriteRecordLayer),\n                         handshakeContext = std::move(handshakeContext),\n                         scheduler = std::move(scheduler),\n                         exporterMaster = std::move(exporterMaster),\n                         serverCert = std::move(serverCert),\n                         clientCert = std::move(clientCert),\n                         cipher,\n                         group,\n                         sigScheme,\n                         clientHandshakeSecret =\n                             std::move(clientHandshakeSecret),\n                         pskType,\n                         pskMode,\n                         version,\n                         keyExchangeType,\n                         alpn = std::move(alpn),\n                         earlyDataTypeSave,\n                         replayCacheResult,\n                         clockSkew,\n                         appToken = std::move(appToken),\n                         serverCertCompAlgo,\n                         echStatus,\n                         clientRandom = std::move(clientRandom),\n                         handshakeTime = std::move(handshakeTime)](\n                            State& newState) mutable {\n                          newState.writeRecordLayer() =\n                              std::move(appTrafficWriteRecordLayer);\n                          newState.handshakeContext() =\n                              std::move(handshakeContext);\n                          newState.keyScheduler() = std::move(scheduler);\n                          newState.exporterMasterSecret() =\n                              std::move(exporterMaster);\n                          newState.serverCert() = std::move(*serverCert);\n                          newState.clientCert() = std::move(clientCert);\n                          newState.version() = version;\n                          newState.cipher() = cipher;\n                          newState.group() = group;\n                          newState.sigScheme() = sigScheme;\n                          newState.clientHandshakeSecret() =\n                              std::move(clientHandshakeSecret);\n                          newState.pskType() = pskType;\n                          newState.pskMode() = pskMode;\n                          newState.keyExchangeType() = keyExchangeType;\n                          newState.earlyDataType() = earlyDataTypeSave;\n                          newState.replayCacheResult() = replayCacheResult;\n                          newState.alpn() = std::move(alpn);\n                          newState.clientClockSkew() = clockSkew;\n                          newState.appToken() = std::move(appToken);\n                          newState.serverCertCompAlgo() = serverCertCompAlgo;\n                          newState.handshakeTime() = std::move(handshakeTime);\n                          newState.clientRandom() = std::move(clientRandom);\n                          newState.echStatus() = echStatus;\n                          newState.echState() = folly::none;\n                        });\n\n                    if (earlyDataType == EarlyDataType::Accepted) {\n                      if (state.context()->getOmitEarlyRecordLayer()) {\n                        return actions(\n                            MutateState([handshakeReadRecordLayer = std::move(\n                                             handshakeReadRecordLayer),\n                                         earlyExporterMaster =\n                                             std::move(earlyExporterMaster)](\n                                            State& newState) mutable {\n                              newState.readRecordLayer() =\n                                  std::move(handshakeReadRecordLayer);\n                              newState.earlyExporterMasterSecret() =\n                                  std::move(earlyExporterMaster);\n                            }),\n                            std::move(saveState),\n                            std::move(*earlyReadSecretAvailable),\n                            std::move(handshakeReadSecretAvailable),\n                            std::move(handshakeWriteSecretAvailable),\n                            std::move(appWriteSecretAvailable),\n                            std::move(serverFlight),\n                            MutateState(\n                                &Transition<StateEnum::ExpectingFinished>),\n                            ReportEarlyHandshakeSuccess());\n\n                      } else {\n                        return actions(\n                            MutateState([handshakeReadRecordLayer = std::move(\n                                             handshakeReadRecordLayer),\n                                         earlyReadRecordLayer =\n                                             std::move(earlyReadRecordLayer),\n                                         earlyExporterMaster =\n                                             std::move(earlyExporterMaster)](\n                                            State& newState) mutable {\n                              newState.readRecordLayer() =\n                                  std::move(earlyReadRecordLayer);\n                              newState.handshakeReadRecordLayer() =\n                                  std::move(handshakeReadRecordLayer);\n                              newState.earlyExporterMasterSecret() =\n                                  std::move(earlyExporterMaster);\n                            }),\n                            std::move(saveState),\n                            std::move(*earlyReadSecretAvailable),\n                            std::move(handshakeReadSecretAvailable),\n                            std::move(handshakeWriteSecretAvailable),\n                            std::move(appWriteSecretAvailable),\n                            std::move(serverFlight),\n                            MutateState(\n                                &Transition<StateEnum::AcceptingEarlyData>),\n                            ReportEarlyHandshakeSuccess());\n                      }\n                    } else {\n                      auto transition = requestClientAuth\n                          ? Transition<StateEnum::ExpectingCertificate>\n                          : Transition<StateEnum::ExpectingFinished>;\n                      return actions(\n                          MutateState([handshakeReadRecordLayer =\n                                           std::move(handshakeReadRecordLayer)](\n                                          State& newState) mutable {\n                            newState.readRecordLayer() =\n                                std::move(handshakeReadRecordLayer);\n                          }),\n                          std::move(saveState),\n                          std::move(handshakeReadSecretAvailable),\n                          std::move(handshakeWriteSecretAvailable),\n                          std::move(appWriteSecretAvailable),\n                          std::move(serverFlight),\n                          MutateState(transition));\n                    }\n                  });\n            });\n      });\n}",
        "func": "AsyncActions\nEventHandler<ServerTypes, StateEnum::ExpectingClientHello, Event::ClientHello>::\n    handle(const State& state, Param param) {\n  ClientHello chlo = std::move(*param.asClientHello());\n\n  auto cookieState = getCookieState(chlo, state.context()->getCookieCipher());\n\n  if (state.handshakeContext() && cookieState.has_value()) {\n    throw FizzException(\n        \"cookie after statefull hrr\", AlertDescription::illegal_parameter);\n  }\n\n  ECHStatus echStatus;\n  ECHState echState;\n  std::tie(echStatus, echState) = processECH(cookieState, state, chlo);\n\n  addHandshakeLogging(state, chlo);\n\n  if (state.readRecordLayer()->hasUnparsedHandshakeData()) {\n    throw FizzException(\n        \"data after client hello\", AlertDescription::unexpected_message);\n  }\n\n  auto version =\n      negotiateVersion(chlo, state.context()->getSupportedVersions());\n\n  if (state.version().has_value() &&\n      (!version || *version != *state.version())) {\n    throw FizzException(\n        \"version mismatch with previous negotiation\",\n        AlertDescription::illegal_parameter);\n  }\n\n  if (!version) {\n    if (getExtension<ClientEarlyData>(chlo.extensions)) {\n      throw FizzException(\n          \"supported version mismatch with early data\",\n          AlertDescription::protocol_version);\n    }\n    if (state.context()->getVersionFallbackEnabled()) {\n      AttemptVersionFallback fallback;\n      // Re-encode to put the record layer header back on. This won't\n      // necessarily preserve it byte-for-byte, but it isn't authenticated so\n      // should be ok.\n      fallback.clientHello =\n          PlaintextWriteRecordLayer()\n              .writeInitialClientHello(std::move(*chlo.originalEncoding))\n              .data;\n      return actions(\n          MutateState(&Transition<StateEnum::Error>), std::move(fallback));\n    } else {\n      throw FizzException(\n          \"supported version mismatch\", AlertDescription::protocol_version);\n    }\n  }\n\n  state.writeRecordLayer()->setProtocolVersion(*version);\n\n  validateClientHello(chlo);\n\n  auto cipher = negotiateCipher(chlo, state.context()->getSupportedCiphers());\n\n  if (state.cipher().has_value() && cipher != *state.cipher()) {\n    throw FizzException(\n        \"cipher mismatch with previous negotiation\",\n        AlertDescription::illegal_parameter);\n  }\n\n  verifyCookieState(cookieState, *version, cipher);\n\n  auto resStateResult = getResumptionState(\n      chlo,\n      state.context()->getTicketCipher(),\n      state.context()->getSupportedPskModes());\n\n  auto replayCacheResultFuture = getReplayCacheResult(\n      chlo,\n      state.context()->getAcceptEarlyData(*version),\n      state.context()->getReplayCache());\n\n  auto results =\n      collectAll(resStateResult.futureResState, replayCacheResultFuture);\n\n  using FutureResultType = std::tuple<\n      folly::Try<std::pair<PskType, Optional<ResumptionState>>>,\n      folly::Try<ReplayCacheResult>>;\n  return runOnCallerIfComplete(\n      state.executor(),\n      std::move(results),\n      [&state,\n       chlo = std::move(chlo),\n       cookieState = std::move(cookieState),\n       version = *version,\n       cipher,\n       pskMode = resStateResult.pskMode,\n       echStatus,\n       echState = std::move(echState),\n       obfuscatedAge =\n           resStateResult.obfuscatedAge](FutureResultType result) mutable {\n        auto& resumption = *std::get<0>(result);\n        auto pskType = resumption.first;\n        auto resState = std::move(resumption.second);\n        auto replayCacheResult = *std::get<1>(result);\n\n        if (resState) {\n          if (!validateResumptionState(*resState, *pskMode, version, cipher)) {\n            pskType = PskType::Rejected;\n            pskMode = folly::none;\n            resState = folly::none;\n          }\n        } else {\n          pskMode = folly::none;\n        }\n\n        auto legacySessionId = chlo.legacy_session_id->clone();\n\n        // If we successfully resumed, set the handshake time to the ticket's\n        // handshake time to preserve it across ticket updates. If not, set it\n        // to now.\n        std::chrono::system_clock::time_point handshakeTime;\n        if (resState) {\n          handshakeTime = resState->handshakeTime;\n        } else {\n          handshakeTime = state.context()->getClock().getCurrentTime();\n        }\n\n        std::unique_ptr<KeyScheduler> scheduler;\n        std::unique_ptr<HandshakeContext> handshakeContext;\n        std::tie(scheduler, handshakeContext) = setupSchedulerAndContext(\n            *state.context()->getFactory(),\n            cipher,\n            chlo,\n            resState,\n            cookieState,\n            pskType,\n            std::move(state.handshakeContext()),\n            version);\n\n        auto alpn = negotiateAlpn(chlo, folly::none, *state.context());\n\n        auto clockSkew = getClockSkew(\n            resState,\n            obfuscatedAge,\n            state.context()->getClock().getCurrentTime());\n\n        auto appToken = getAppToken(resState);\n\n        auto earlyDataType = negotiateEarlyDataType(\n            state.context()->getAcceptEarlyData(version),\n            chlo,\n            resState,\n            cipher,\n            state.keyExchangeType(),\n            cookieState,\n            alpn,\n            replayCacheResult,\n            clockSkew,\n            state.context()->getClockSkewTolerance(),\n            state.appTokenValidator());\n\n        std::unique_ptr<EncryptedReadRecordLayer> earlyReadRecordLayer;\n        Buf earlyExporterMaster;\n        folly::Optional<SecretAvailable> earlyReadSecretAvailable;\n        if (earlyDataType == EarlyDataType::Accepted) {\n          auto earlyContext = handshakeContext->getHandshakeContext();\n          auto earlyReadSecret = scheduler->getSecret(\n              EarlySecrets::ClientEarlyTraffic, earlyContext->coalesce());\n          if (!state.context()->getOmitEarlyRecordLayer()) {\n            earlyReadRecordLayer =\n                state.context()->getFactory()->makeEncryptedReadRecordLayer(\n                    EncryptionLevel::EarlyData);\n            earlyReadRecordLayer->setProtocolVersion(version);\n\n            Protocol::setAead(\n                *earlyReadRecordLayer,\n                cipher,\n                folly::range(earlyReadSecret.secret),\n                *state.context()->getFactory(),\n                *scheduler);\n          }\n\n          earlyReadSecretAvailable =\n              SecretAvailable(std::move(earlyReadSecret));\n          earlyExporterMaster = folly::IOBuf::copyBuffer(\n              scheduler\n                  ->getSecret(\n                      EarlySecrets::EarlyExporter, earlyContext->coalesce())\n                  .secret);\n        }\n\n        Optional<NamedGroup> group;\n        KeyExchangeType keyExchangeType;\n        SemiFuture<Optional<AsyncKeyExchange::DoKexResult>> kexResultFuture =\n            folly::none;\n        std::unique_ptr<KeyExchange> kex = nullptr;\n\n        if (!pskMode || *pskMode != PskKeyExchangeMode::psk_ke) {\n          Optional<Buf> clientShare;\n          std::tie(group, clientShare) = negotiateGroup(\n              version, chlo, state.context()->getSupportedGroups());\n          if (!clientShare) {\n            VLOG(8) << \"Did not find key share for \" << toString(*group);\n            if (state.group().has_value() || cookieState) {\n              throw FizzException(\n                  \"key share not found for already negotiated group\",\n                  AlertDescription::illegal_parameter);\n            }\n\n            // If we were otherwise going to accept early data we now need to\n            // reject it. It's a little ugly to change our previous early data\n            // decision, but doing it this way allows us to move the key\n            // schedule forward as we do the key exchange.\n            if (earlyDataType == EarlyDataType::Accepted) {\n              earlyDataType = EarlyDataType::Rejected;\n            }\n\n            message_hash chloHash;\n            chloHash.hash = handshakeContext->getHandshakeContext();\n            handshakeContext =\n                state.context()->getFactory()->makeHandshakeContext(cipher);\n            handshakeContext->appendToTranscript(\n                encodeHandshake(std::move(chloHash)));\n\n            auto hrr = getHelloRetryRequest(\n                version,\n                cipher,\n                *group,\n                legacySessionId ? legacySessionId->clone() : nullptr,\n                *handshakeContext);\n\n            if (echStatus == ECHStatus::Accepted) {\n              // Set up acceptance scheduler\n              auto echScheduler =\n                  state.context()->getFactory()->makeKeyScheduler(cipher);\n              echScheduler->deriveEarlySecret(folly::range(chlo.random));\n              // Add acceptance extension\n              ech::setAcceptConfirmation(\n                  hrr, handshakeContext->clone(), std::move(echScheduler));\n            }\n\n            auto encodedHelloRetryRequest = encodeHandshake(std::move(hrr));\n            handshakeContext->appendToTranscript(encodedHelloRetryRequest);\n\n            WriteToSocket serverFlight;\n            serverFlight.contents.emplace_back(\n                state.writeRecordLayer()->writeHandshake(\n                    std::move(encodedHelloRetryRequest)));\n\n            if (legacySessionId && !legacySessionId->empty()) {\n              TLSContent writeCCS;\n              writeCCS.encryptionLevel = EncryptionLevel::Plaintext;\n              writeCCS.contentType = ContentType::change_cipher_spec;\n              writeCCS.data = folly::IOBuf::wrapBuffer(FakeChangeCipherSpec);\n              serverFlight.contents.emplace_back(std::move(writeCCS));\n            }\n\n            // Create a new record layer in case we need to skip early data.\n            auto newReadRecordLayer =\n                state.context()->getFactory()->makePlaintextReadRecordLayer();\n            newReadRecordLayer->setSkipEncryptedRecords(\n                earlyDataType == EarlyDataType::Rejected);\n\n            return SemiFuture<Actions>(actions(\n                MutateState([handshakeContext = std::move(handshakeContext),\n                             version,\n                             cipher,\n                             group,\n                             earlyDataType,\n                             replayCacheResult,\n                             newReadRecordLayer = std::move(newReadRecordLayer),\n                             echStatus,\n                             echState =\n                                 std::move(echState)](State& newState) mutable {\n                  // Save some information about the current state to be\n                  // validated when we get the second client hello. We don't\n                  // validate that the second client hello matches the first\n                  // as strictly as we could according to the spec however.\n                  newState.handshakeContext() = std::move(handshakeContext);\n                  newState.version() = version;\n                  newState.cipher() = cipher;\n                  newState.group() = group;\n                  newState.keyExchangeType() =\n                      KeyExchangeType::HelloRetryRequest;\n                  newState.earlyDataType() = earlyDataType;\n                  newState.replayCacheResult() = replayCacheResult;\n                  newState.readRecordLayer() = std::move(newReadRecordLayer);\n                  newState.echStatus() = echStatus;\n                  if (echStatus == ECHStatus::Accepted) {\n                    newState.echState() = std::move(echState);\n                  }\n                }),\n                std::move(serverFlight),\n                MutateState(&Transition<StateEnum::ExpectingClientHello>)));\n          }\n\n          if (state.keyExchangeType().has_value()) {\n            keyExchangeType = *state.keyExchangeType();\n          } else {\n            keyExchangeType = KeyExchangeType::OneRtt;\n          }\n\n          // The exceptions in SemiFutures will be processed in\n          // detail::processEvent.\n          kex = state.context()->getFactory()->makeKeyExchange(\n              *group, Factory::KeyExchangeMode::Server);\n          kexResultFuture =\n              doKexFuture(kex.get(), std::move(clientShare.value()));\n        } else {\n          keyExchangeType = KeyExchangeType::None;\n        }\n\n        return runOnCallerIfComplete(\n            state.executor(),\n            std::move(kexResultFuture),\n            [&state,\n             scheduler = std::move(scheduler),\n             handshakeContext = std::move(handshakeContext),\n             cipher,\n             group,\n             echStatus,\n             earlyReadRecordLayer = std::move(earlyReadRecordLayer),\n             earlyReadSecretAvailable = std::move(earlyReadSecretAvailable),\n             earlyExporterMaster = std::move(earlyExporterMaster),\n             pskType,\n             pskMode,\n             version,\n             keyExchangeType,\n             earlyDataType,\n             replayCacheResult,\n             alpn = std::move(alpn),\n             clockSkew,\n             appToken = std::move(appToken),\n             legacySessionId = std::move(legacySessionId),\n             handshakeTime,\n             chlo = std::move(chlo),\n             cookieState = std::move(cookieState),\n             resState = std::move(resState),\n             // Hold kex until the doKexFuture finished.\n             kex = std::move(kex)](\n                Optional<AsyncKeyExchange::DoKexResult> kexResult) mutable {\n              Optional<Buf> serverShare;\n              if (kexResult.hasValue()) {\n                serverShare = std::move(kexResult.value().ourKeyShare);\n                scheduler->deriveHandshakeSecret(\n                    kexResult.value().sharedSecret->coalesce());\n              } else {\n                DCHECK(keyExchangeType == KeyExchangeType::None);\n                scheduler->deriveHandshakeSecret();\n              }\n              std::vector<Extension> additionalExtensions;\n              if (state.extensions()) {\n                additionalExtensions = state.extensions()->getExtensions(chlo);\n              }\n\n              if (state.group().has_value() &&\n                  (!group || *group != *state.group())) {\n                throw FizzException(\n                    \"group mismatch with previous negotiation\",\n                    AlertDescription::illegal_parameter);\n              }\n\n              // Cookies are not required to have already negotiated the group\n              // but if they did it must match (psk_ke is still allowed as we\n              // may not know if we are accepting the psk when sending the\n              // cookie).\n              if (cookieState && cookieState->group && group &&\n                  *group != *cookieState->group) {\n                throw FizzException(\n                    \"group mismatch with cookie\",\n                    AlertDescription::illegal_parameter);\n              }\n\n              auto serverHello = getServerHello(\n                  version,\n                  state.context()->getFactory()->makeRandom(),\n                  cipher,\n                  resState.has_value(),\n                  group,\n                  std::move(serverShare),\n                  legacySessionId ? legacySessionId->clone() : nullptr);\n\n              folly::Optional<std::vector<ech::ECHConfig>> echRetryConfigs;\n              if (echStatus == ECHStatus::Accepted) {\n                // Set up acceptance scheduler\n                auto echScheduler =\n                    state.context()->getFactory()->makeKeyScheduler(cipher);\n                echScheduler->deriveEarlySecret(folly::range(chlo.random));\n                // Add acceptance extension\n                ech::setAcceptConfirmation(\n                    serverHello,\n                    handshakeContext->clone(),\n                    std::move(echScheduler));\n              } else if (echStatus == ECHStatus::Rejected) {\n                auto decrypter = state.context()->getECHDecrypter();\n                echRetryConfigs = decrypter->getRetryConfigs();\n              }\n\n              auto encodedServerHello = encodeHandshake(std::move(serverHello));\n              handshakeContext->appendToTranscript(encodedServerHello);\n\n              // Derive handshake keys.\n              auto handshakeWriteRecordLayer =\n                  state.context()->getFactory()->makeEncryptedWriteRecordLayer(\n                      EncryptionLevel::Handshake);\n              handshakeWriteRecordLayer->setProtocolVersion(version);\n              auto handshakeWriteSecret = scheduler->getSecret(\n                  HandshakeSecrets::ServerHandshakeTraffic,\n                  handshakeContext->getHandshakeContext()->coalesce());\n              Protocol::setAead(\n                  *handshakeWriteRecordLayer,\n                  cipher,\n                  folly::range(handshakeWriteSecret.secret),\n                  *state.context()->getFactory(),\n                  *scheduler);\n\n              auto handshakeReadRecordLayer =\n                  state.context()->getFactory()->makeEncryptedReadRecordLayer(\n                      EncryptionLevel::Handshake);\n              handshakeReadRecordLayer->setProtocolVersion(version);\n              handshakeReadRecordLayer->setSkipFailedDecryption(\n                  earlyDataType == EarlyDataType::Rejected);\n              auto handshakeReadSecret = scheduler->getSecret(\n                  HandshakeSecrets::ClientHandshakeTraffic,\n                  handshakeContext->getHandshakeContext()->coalesce());\n              Protocol::setAead(\n                  *handshakeReadRecordLayer,\n                  cipher,\n                  folly::range(handshakeReadSecret.secret),\n                  *state.context()->getFactory(),\n                  *scheduler);\n              auto clientHandshakeSecret =\n                  folly::IOBuf::copyBuffer(handshakeReadSecret.secret);\n\n              auto encodedEncryptedExt = getEncryptedExt(\n                  *handshakeContext,\n                  alpn,\n                  earlyDataType,\n                  std::move(echRetryConfigs),\n                  std::move(additionalExtensions));\n\n              /*\n               * Determine we are requesting client auth.\n               * If yes, add CertificateRequest to handshake write and\n               * transcript.\n               */\n              bool requestClientAuth = state.context()->getClientAuthMode() !=\n                      ClientAuthMode::None &&\n                  !resState;\n              Optional<Buf> encodedCertRequest;\n              if (requestClientAuth) {\n                encodedCertRequest = getCertificateRequest(\n                    state.context()->getSupportedSigSchemes(),\n                    state.context()->getClientCertVerifier().get(),\n                    *handshakeContext);\n              }\n\n              /*\n               * Set the cert and signature scheme we are using.\n               * If sending new cert, add Certificate to handshake write and\n               * transcript.\n               */\n              Optional<Buf> encodedCertificate;\n              SemiFuture<Optional<Buf>> signature = folly::none;\n              Optional<SignatureScheme> sigScheme;\n              Optional<std::shared_ptr<const Cert>> serverCert;\n              std::shared_ptr<const Cert> clientCert;\n              Optional<CertificateCompressionAlgorithm> certCompressionAlgo;\n              if (!resState) { // TODO or reauth\n                std::shared_ptr<const SelfCert> originalSelfCert;\n                std::tie(originalSelfCert, sigScheme) =\n                    chooseCert(*state.context(), chlo);\n\n                std::tie(encodedCertificate, certCompressionAlgo) =\n                    getCertificate(\n                        originalSelfCert,\n                        *state.context(),\n                        chlo,\n                        *handshakeContext);\n\n                auto toBeSigned = handshakeContext->getHandshakeContext();\n                auto asyncSelfCert =\n                    dynamic_cast<const AsyncSelfCert*>(originalSelfCert.get());\n                if (asyncSelfCert) {\n                  signature = asyncSelfCert->signFuture(\n                      *sigScheme,\n                      CertificateVerifyContext::Server,\n                      std::move(toBeSigned));\n                } else {\n                  signature = folly::makeSemiFuture<Optional<Buf>>(\n                      originalSelfCert->sign(\n                          *sigScheme,\n                          CertificateVerifyContext::Server,\n                          toBeSigned->coalesce()));\n                }\n                serverCert = std::move(originalSelfCert);\n              } else {\n                serverCert = std::move(resState->serverCert);\n                clientCert = std::move(resState->clientCert);\n              }\n\n              auto clientRandom = std::move(chlo.random);\n\n              return runOnCallerIfComplete(\n                  state.executor(),\n                  std::move(signature),\n                  [&state,\n                   scheduler = std::move(scheduler),\n                   handshakeContext = std::move(handshakeContext),\n                   cipher,\n                   clientRandom = std::move(clientRandom),\n                   group,\n                   echStatus,\n                   encodedServerHello = std::move(encodedServerHello),\n                   handshakeWriteRecordLayer =\n                       std::move(handshakeWriteRecordLayer),\n                   handshakeWriteSecret = std::move(handshakeWriteSecret),\n                   handshakeReadRecordLayer =\n                       std::move(handshakeReadRecordLayer),\n                   handshakeReadSecret = std::move(handshakeReadSecret),\n                   earlyReadRecordLayer = std::move(earlyReadRecordLayer),\n                   earlyReadSecretAvailable =\n                       std::move(earlyReadSecretAvailable),\n                   earlyExporterMaster = std::move(earlyExporterMaster),\n                   clientHandshakeSecret = std::move(clientHandshakeSecret),\n                   encodedEncryptedExt = std::move(encodedEncryptedExt),\n                   encodedCertificate = std::move(encodedCertificate),\n                   encodedCertRequest = std::move(encodedCertRequest),\n                   requestClientAuth,\n                   pskType,\n                   pskMode,\n                   sigScheme,\n                   version,\n                   keyExchangeType,\n                   earlyDataType,\n                   replayCacheResult,\n                   serverCert = std::move(serverCert),\n                   clientCert = std::move(clientCert),\n                   alpn = std::move(alpn),\n                   clockSkew,\n                   appToken = std::move(appToken),\n                   legacySessionId = std::move(legacySessionId),\n                   serverCertCompAlgo = certCompressionAlgo,\n                   handshakeTime](Optional<Buf> sig) mutable {\n                    Optional<Buf> encodedCertificateVerify;\n                    if (sig) {\n                      encodedCertificateVerify = getCertificateVerify(\n                          *sigScheme, std::move(*sig), *handshakeContext);\n                    }\n\n                    auto encodedFinished = Protocol::getFinished(\n                        folly::range(handshakeWriteSecret.secret),\n                        *handshakeContext);\n\n                    folly::IOBufQueue combined;\n                    if (encodedCertificate) {\n                      if (encodedCertRequest) {\n                        combined.append(std::move(encodedEncryptedExt));\n                        combined.append(std::move(*encodedCertRequest));\n                        combined.append(std::move(*encodedCertificate));\n                        combined.append(std::move(*encodedCertificateVerify));\n                        combined.append(std::move(encodedFinished));\n                      } else {\n                        combined.append(std::move(encodedEncryptedExt));\n                        combined.append(std::move(*encodedCertificate));\n                        combined.append(std::move(*encodedCertificateVerify));\n                        combined.append(std::move(encodedFinished));\n                      }\n                    } else {\n                      combined.append(std::move(encodedEncryptedExt));\n                      combined.append(std::move(encodedFinished));\n                    }\n\n                    // Some middleboxes appear to break if the first encrypted\n                    // record is larger than ~1300 bytes (likely if it does not\n                    // fit in the first packet).\n                    auto serverEncrypted =\n                        handshakeWriteRecordLayer->writeHandshake(\n                            combined.splitAtMost(1000));\n                    if (!combined.empty()) {\n                      auto splitRecord =\n                          handshakeWriteRecordLayer->writeHandshake(\n                              combined.move());\n                      // Split record must have the same encryption level as the\n                      // main handshake.\n                      DCHECK(\n                          splitRecord.encryptionLevel ==\n                          serverEncrypted.encryptionLevel);\n                      serverEncrypted.data->prependChain(\n                          std::move(splitRecord.data));\n                    }\n\n                    WriteToSocket serverFlight;\n                    serverFlight.contents.emplace_back(\n                        state.writeRecordLayer()->writeHandshake(\n                            std::move(encodedServerHello)));\n                    if (legacySessionId && !legacySessionId->empty()) {\n                      TLSContent ccsWrite;\n                      ccsWrite.encryptionLevel = EncryptionLevel::Plaintext;\n                      ccsWrite.contentType = ContentType::change_cipher_spec;\n                      ccsWrite.data =\n                          folly::IOBuf::wrapBuffer(FakeChangeCipherSpec);\n                      serverFlight.contents.emplace_back(std::move(ccsWrite));\n                    }\n                    serverFlight.contents.emplace_back(\n                        std::move(serverEncrypted));\n\n                    scheduler->deriveMasterSecret();\n                    auto clientFinishedContext =\n                        handshakeContext->getHandshakeContext();\n                    auto exporterMasterVector = scheduler->getSecret(\n                        MasterSecrets::ExporterMaster,\n                        clientFinishedContext->coalesce());\n                    auto exporterMaster = folly::IOBuf::copyBuffer(\n                        folly::range(exporterMasterVector.secret));\n\n                    scheduler->deriveAppTrafficSecrets(\n                        clientFinishedContext->coalesce());\n                    auto appTrafficWriteRecordLayer =\n                        state.context()\n                            ->getFactory()\n                            ->makeEncryptedWriteRecordLayer(\n                                EncryptionLevel::AppTraffic);\n                    appTrafficWriteRecordLayer->setProtocolVersion(version);\n                    auto writeSecret = scheduler->getSecret(\n                        AppTrafficSecrets::ServerAppTraffic);\n                    Protocol::setAead(\n                        *appTrafficWriteRecordLayer,\n                        cipher,\n                        folly::range(writeSecret.secret),\n                        *state.context()->getFactory(),\n                        *scheduler);\n\n                    // If we have previously dealt with early data (before a\n                    // HelloRetryRequest), don't overwrite the previous result.\n                    auto earlyDataTypeSave = state.earlyDataType()\n                        ? *state.earlyDataType()\n                        : earlyDataType;\n\n                    SecretAvailable handshakeReadSecretAvailable(\n                        std::move(handshakeReadSecret));\n                    SecretAvailable handshakeWriteSecretAvailable(\n                        std::move(handshakeWriteSecret));\n                    SecretAvailable appWriteSecretAvailable(\n                        std::move(writeSecret));\n\n                    // Save all the necessary state except for the read record\n                    // layer, which is done separately as it varies if early\n                    // data was accepted.\n                    MutateState saveState(\n                        [appTrafficWriteRecordLayer =\n                             std::move(appTrafficWriteRecordLayer),\n                         handshakeContext = std::move(handshakeContext),\n                         scheduler = std::move(scheduler),\n                         exporterMaster = std::move(exporterMaster),\n                         serverCert = std::move(serverCert),\n                         clientCert = std::move(clientCert),\n                         cipher,\n                         group,\n                         sigScheme,\n                         clientHandshakeSecret =\n                             std::move(clientHandshakeSecret),\n                         pskType,\n                         pskMode,\n                         version,\n                         keyExchangeType,\n                         alpn = std::move(alpn),\n                         earlyDataTypeSave,\n                         replayCacheResult,\n                         clockSkew,\n                         appToken = std::move(appToken),\n                         serverCertCompAlgo,\n                         echStatus,\n                         clientRandom = std::move(clientRandom),\n                         handshakeTime = std::move(handshakeTime)](\n                            State& newState) mutable {\n                          newState.writeRecordLayer() =\n                              std::move(appTrafficWriteRecordLayer);\n                          newState.handshakeContext() =\n                              std::move(handshakeContext);\n                          newState.keyScheduler() = std::move(scheduler);\n                          newState.exporterMasterSecret() =\n                              std::move(exporterMaster);\n                          newState.serverCert() = std::move(*serverCert);\n                          newState.clientCert() = std::move(clientCert);\n                          newState.version() = version;\n                          newState.cipher() = cipher;\n                          newState.group() = group;\n                          newState.sigScheme() = sigScheme;\n                          newState.clientHandshakeSecret() =\n                              std::move(clientHandshakeSecret);\n                          newState.pskType() = pskType;\n                          newState.pskMode() = pskMode;\n                          newState.keyExchangeType() = keyExchangeType;\n                          newState.earlyDataType() = earlyDataTypeSave;\n                          newState.replayCacheResult() = replayCacheResult;\n                          newState.alpn() = std::move(alpn);\n                          newState.clientClockSkew() = clockSkew;\n                          newState.appToken() = std::move(appToken);\n                          newState.serverCertCompAlgo() = serverCertCompAlgo;\n                          newState.handshakeTime() = std::move(handshakeTime);\n                          newState.clientRandom() = std::move(clientRandom);\n                          newState.echStatus() = echStatus;\n                          newState.echState() = folly::none;\n                        });\n\n                    if (earlyDataType == EarlyDataType::Accepted) {\n                      if (state.context()->getOmitEarlyRecordLayer()) {\n                        return actions(\n                            MutateState([handshakeReadRecordLayer = std::move(\n                                             handshakeReadRecordLayer),\n                                         earlyExporterMaster =\n                                             std::move(earlyExporterMaster)](\n                                            State& newState) mutable {\n                              newState.readRecordLayer() =\n                                  std::move(handshakeReadRecordLayer);\n                              newState.earlyExporterMasterSecret() =\n                                  std::move(earlyExporterMaster);\n                            }),\n                            std::move(saveState),\n                            std::move(*earlyReadSecretAvailable),\n                            std::move(handshakeReadSecretAvailable),\n                            std::move(handshakeWriteSecretAvailable),\n                            std::move(appWriteSecretAvailable),\n                            std::move(serverFlight),\n                            MutateState(\n                                &Transition<StateEnum::ExpectingFinished>),\n                            ReportEarlyHandshakeSuccess());\n\n                      } else {\n                        return actions(\n                            MutateState([handshakeReadRecordLayer = std::move(\n                                             handshakeReadRecordLayer),\n                                         earlyReadRecordLayer =\n                                             std::move(earlyReadRecordLayer),\n                                         earlyExporterMaster =\n                                             std::move(earlyExporterMaster)](\n                                            State& newState) mutable {\n                              newState.readRecordLayer() =\n                                  std::move(earlyReadRecordLayer);\n                              newState.handshakeReadRecordLayer() =\n                                  std::move(handshakeReadRecordLayer);\n                              newState.earlyExporterMasterSecret() =\n                                  std::move(earlyExporterMaster);\n                            }),\n                            std::move(saveState),\n                            std::move(*earlyReadSecretAvailable),\n                            std::move(handshakeReadSecretAvailable),\n                            std::move(handshakeWriteSecretAvailable),\n                            std::move(appWriteSecretAvailable),\n                            std::move(serverFlight),\n                            MutateState(\n                                &Transition<StateEnum::AcceptingEarlyData>),\n                            ReportEarlyHandshakeSuccess());\n                      }\n                    } else {\n                      auto transition = requestClientAuth\n                          ? Transition<StateEnum::ExpectingCertificate>\n                          : Transition<StateEnum::ExpectingFinished>;\n                      return actions(\n                          MutateState([handshakeReadRecordLayer =\n                                           std::move(handshakeReadRecordLayer)](\n                                          State& newState) mutable {\n                            newState.readRecordLayer() =\n                                std::move(handshakeReadRecordLayer);\n                          }),\n                          std::move(saveState),\n                          std::move(handshakeReadSecretAvailable),\n                          std::move(handshakeWriteSecretAvailable),\n                          std::move(appWriteSecretAvailable),\n                          std::move(serverFlight),\n                          MutateState(transition));\n                    }\n                  });\n            });\n      });\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -60,6 +60,12 @@\n \n   auto cipher = negotiateCipher(chlo, state.context()->getSupportedCiphers());\n \n+  if (state.cipher().has_value() && cipher != *state.cipher()) {\n+    throw FizzException(\n+        \"cipher mismatch with previous negotiation\",\n+        AlertDescription::illegal_parameter);\n+  }\n+\n   verifyCookieState(cookieState, *version, cipher);\n \n   auto resStateResult = getResumptionState(\n@@ -129,12 +135,6 @@\n             pskType,\n             std::move(state.handshakeContext()),\n             version);\n-\n-        if (state.cipher().has_value() && cipher != *state.cipher()) {\n-          throw FizzException(\n-              \"cipher mismatch with previous negotiation\",\n-              AlertDescription::illegal_parameter);\n-        }\n \n         auto alpn = negotiateAlpn(chlo, folly::none, *state.context());\n ",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "        if (state.cipher().has_value() && cipher != *state.cipher()) {",
                "          throw FizzException(",
                "              \"cipher mismatch with previous negotiation\",",
                "              AlertDescription::illegal_parameter);",
                "        }"
            ],
            "added_lines": [
                "  if (state.cipher().has_value() && cipher != *state.cipher()) {",
                "    throw FizzException(",
                "        \"cipher mismatch with previous negotiation\",",
                "        AlertDescription::illegal_parameter);",
                "  }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-1428",
        "func_name": "grpc/Encode",
        "description": "There exists an vulnerability causing an abort() to be called in gRPC.\nThe following headers cause gRPC's C++ implementation to abort() when called via http2:\n\nte: x (x != trailers)\n\n:scheme: x (x != http, https)\n\ngrpclb_client_stats: x (x == anything)\n\nOn top of sending one of those headers, a later header must be sent that gets the total header size past 8KB. We recommend upgrading past git commit2485fa94bd8a723e5c977d55a3ce10b301b437f8 or v1.53 and above.\n\n",
        "git_url": "https://github.com/grpc/grpc/commit/2485fa94bd8a723e5c977d55a3ce10b301b437f8",
        "commit_title": "[chttp2] Fix fuzzer found bug (#32507)",
        "commit_text": " <!--\r \r If you know who should review your pull request, please assign it to\r that\r person, otherwise the pull request would get assigned randomly.\r \r If your pull request is for a specific language, please add the\r appropriate\r lang label.\r \r -->",
        "func_before": "void Encode(Key, const Value& value) {\n      AddToSummary(Key::key(), Key::Encode(value).size());\n    }",
        "func": "void Encode(Key, const Value& value) {\n      AddToSummary(Key::key(), EncodedSizeOfKey(Key(), value));\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,3 +1,3 @@\n void Encode(Key, const Value& value) {\n-      AddToSummary(Key::key(), Key::Encode(value).size());\n+      AddToSummary(Key::key(), EncodedSizeOfKey(Key(), value));\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "      AddToSummary(Key::key(), Key::Encode(value).size());"
            ],
            "added_lines": [
                "      AddToSummary(Key::key(), EncodedSizeOfKey(Key(), value));"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-1428",
        "func_name": "grpc/ContentTypeMetadata::Encode",
        "description": "There exists an vulnerability causing an abort() to be called in gRPC.\nThe following headers cause gRPC's C++ implementation to abort() when called via http2:\n\nte: x (x != trailers)\n\n:scheme: x (x != http, https)\n\ngrpclb_client_stats: x (x == anything)\n\nOn top of sending one of those headers, a later header must be sent that gets the total header size past 8KB. We recommend upgrading past git commit2485fa94bd8a723e5c977d55a3ce10b301b437f8 or v1.53 and above.\n\n",
        "git_url": "https://github.com/grpc/grpc/commit/2485fa94bd8a723e5c977d55a3ce10b301b437f8",
        "commit_title": "[chttp2] Fix fuzzer found bug (#32507)",
        "commit_text": " <!--\r \r If you know who should review your pull request, please assign it to\r that\r person, otherwise the pull request would get assigned randomly.\r \r If your pull request is for a specific language, please add the\r appropriate\r lang label.\r \r -->",
        "func_before": "StaticSlice ContentTypeMetadata::Encode(ValueType x) {\n  switch (x) {\n    case kEmpty:\n      return StaticSlice::FromStaticString(\"\");\n    case kApplicationGrpc:\n      return StaticSlice::FromStaticString(\"application/grpc\");\n    case kInvalid:\n      return StaticSlice::FromStaticString(\"application/grpc+unknown\");\n  }\n  GPR_UNREACHABLE_CODE(\n      return StaticSlice::FromStaticString(\"unrepresentable value\"));\n}\n\nconst char* ContentTypeMetadata::DisplayValue(ValueType content_type) {\n  switch (content_type) {\n    case ValueType::kApplicationGrpc:\n      return \"application/grpc\";\n    case ValueType::kEmpty:\n      return \"\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nGrpcTimeoutMetadata::MementoType GrpcTimeoutMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  auto timeout = ParseTimeout(value);\n  if (!timeout.has_value()) {\n    on_error(\"invalid value\", value);\n    return Duration::Infinity();\n  }\n  return *timeout;\n}\n\nGrpcTimeoutMetadata::ValueType GrpcTimeoutMetadata::MementoToValue(\n    MementoType timeout) {\n  if (timeout == Duration::Infinity()) {\n    return Timestamp::InfFuture();\n  }\n  return Timestamp::Now() + timeout;\n}\n\nSlice GrpcTimeoutMetadata::Encode(ValueType x) {\n  return Timeout::FromDuration(x - Timestamp::Now()).Encode();\n}\n\nTeMetadata::MementoType TeMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  auto out = kInvalid;\n  if (value == \"trailers\") {\n    out = kTrailers;\n  } else {\n    on_error(\"invalid value\", value);\n  }\n  return out;\n}\n\nconst char* TeMetadata::DisplayValue(ValueType te) {\n  switch (te) {\n    case ValueType::kTrailers:\n      return \"trailers\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nHttpSchemeMetadata::ValueType HttpSchemeMetadata::Parse(\n    absl::string_view value, MetadataParseErrorFn on_error) {\n  if (value == \"http\") {\n    return kHttp;\n  } else if (value == \"https\") {\n    return kHttps;\n  }\n  on_error(\"invalid value\", Slice::FromCopiedBuffer(value));\n  return kInvalid;\n}\n\nStaticSlice HttpSchemeMetadata::Encode(ValueType x) {\n  switch (x) {\n    case kHttp:\n      return StaticSlice::FromStaticString(\"http\");\n    case kHttps:\n      return StaticSlice::FromStaticString(\"https\");\n    default:\n      abort();\n  }\n}\n\nconst char* HttpSchemeMetadata::DisplayValue(ValueType content_type) {\n  switch (content_type) {\n    case kHttp:\n      return \"http\";\n    case kHttps:\n      return \"https\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nHttpMethodMetadata::MementoType HttpMethodMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  auto out = kInvalid;\n  auto value_string = value.as_string_view();\n  if (value_string == \"POST\") {\n    out = kPost;\n  } else if (value_string == \"PUT\") {\n    out = kPut;\n  } else if (value_string == \"GET\") {\n    out = kGet;\n  } else {\n    on_error(\"invalid value\", value);\n  }\n  return out;\n}\n\nStaticSlice HttpMethodMetadata::Encode(ValueType x) {\n  switch (x) {\n    case kPost:\n      return StaticSlice::FromStaticString(\"POST\");\n    case kPut:\n      return StaticSlice::FromStaticString(\"PUT\");\n    case kGet:\n      return StaticSlice::FromStaticString(\"GET\");\n    default:\n      // TODO(ctiller): this should be an abort, we should split up the debug\n      // string generation from the encode string generation so that debug\n      // strings can always succeed and encode strings can crash.\n      return StaticSlice::FromStaticString(\"<<INVALID METHOD>>\");\n  }\n}\n\nconst char* HttpMethodMetadata::DisplayValue(ValueType content_type) {\n  switch (content_type) {\n    case kPost:\n      return \"POST\";\n    case kGet:\n      return \"GET\";\n    case kPut:\n      return \"PUT\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nCompressionAlgorithmBasedMetadata::MementoType\nCompressionAlgorithmBasedMetadata::ParseMemento(Slice value,\n                                                MetadataParseErrorFn on_error) {\n  auto algorithm = ParseCompressionAlgorithm(value.as_string_view());\n  if (!algorithm.has_value()) {\n    on_error(\"invalid value\", value);\n    return GRPC_COMPRESS_NONE;\n  }\n  return *algorithm;\n}\n\nDuration GrpcRetryPushbackMsMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  int64_t out;\n  if (!absl::SimpleAtoi(value.as_string_view(), &out)) {\n    on_error(\"not an integer\", value);\n    return Duration::NegativeInfinity();\n  }\n  return Duration::Milliseconds(out);\n}\n\nSlice LbCostBinMetadata::Encode(const ValueType& x) {\n  auto slice =\n      MutableSlice::CreateUninitialized(sizeof(double) + x.name.length());\n  memcpy(slice.data(), &x.cost, sizeof(double));\n  memcpy(slice.data() + sizeof(double), x.name.data(), x.name.length());\n  return Slice(std::move(slice));\n}\n\nstd::string LbCostBinMetadata::DisplayValue(ValueType x) {\n  return absl::StrCat(x.name, \":\", x.cost);\n}\n\nLbCostBinMetadata::MementoType LbCostBinMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  if (value.length() < sizeof(double)) {\n    on_error(\"too short\", value);\n    return {0, \"\"};\n  }\n  MementoType out;\n  memcpy(&out.cost, value.data(), sizeof(double));\n  out.name =\n      std::string(reinterpret_cast<const char*>(value.data()) + sizeof(double),\n                  value.length() - sizeof(double));\n  return out;\n}\n\nstd::string GrpcStreamNetworkState::DisplayValue(ValueType x) {\n  switch (x) {\n    case kNotSentOnWire:\n      return \"not sent on wire\";\n    case kNotSeenByServer:\n      return \"not seen by server\";\n  }\n  GPR_UNREACHABLE_CODE(return \"unknown value\");\n}\n\nstd::string PeerString::DisplayValue(const ValueType& x) {\n  return std::string(x.as_string_view());\n}\n\nconst std::string& GrpcStatusContext::DisplayValue(const std::string& x) {\n  return x;\n}\n\nstd::string WaitForReady::DisplayValue(ValueType x) {\n  return absl::StrCat(x.value ? \"true\" : \"false\",\n                      x.explicitly_set ? \" (explicit)\" : \"\");\n}\n\n}",
        "func": "StaticSlice ContentTypeMetadata::Encode(ValueType x) {\n  switch (x) {\n    case kEmpty:\n      return StaticSlice::FromStaticString(\"\");\n    case kApplicationGrpc:\n      return StaticSlice::FromStaticString(\"application/grpc\");\n    case kInvalid:\n      return StaticSlice::FromStaticString(\"application/grpc+unknown\");\n  }\n  GPR_UNREACHABLE_CODE(\n      return StaticSlice::FromStaticString(\"unrepresentable value\"));\n}\n\nconst char* ContentTypeMetadata::DisplayValue(ValueType content_type) {\n  switch (content_type) {\n    case ValueType::kApplicationGrpc:\n      return \"application/grpc\";\n    case ValueType::kEmpty:\n      return \"\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nGrpcTimeoutMetadata::MementoType GrpcTimeoutMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  auto timeout = ParseTimeout(value);\n  if (!timeout.has_value()) {\n    on_error(\"invalid value\", value);\n    return Duration::Infinity();\n  }\n  return *timeout;\n}\n\nGrpcTimeoutMetadata::ValueType GrpcTimeoutMetadata::MementoToValue(\n    MementoType timeout) {\n  if (timeout == Duration::Infinity()) {\n    return Timestamp::InfFuture();\n  }\n  return Timestamp::Now() + timeout;\n}\n\nSlice GrpcTimeoutMetadata::Encode(ValueType x) {\n  return Timeout::FromDuration(x - Timestamp::Now()).Encode();\n}\n\nTeMetadata::MementoType TeMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  auto out = kInvalid;\n  if (value == \"trailers\") {\n    out = kTrailers;\n  } else {\n    on_error(\"invalid value\", value);\n  }\n  return out;\n}\n\nconst char* TeMetadata::DisplayValue(ValueType te) {\n  switch (te) {\n    case ValueType::kTrailers:\n      return \"trailers\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nHttpSchemeMetadata::ValueType HttpSchemeMetadata::Parse(\n    absl::string_view value, MetadataParseErrorFn on_error) {\n  if (value == \"http\") {\n    return kHttp;\n  } else if (value == \"https\") {\n    return kHttps;\n  }\n  on_error(\"invalid value\", Slice::FromCopiedBuffer(value));\n  return kInvalid;\n}\n\nStaticSlice HttpSchemeMetadata::Encode(ValueType x) {\n  switch (x) {\n    case kHttp:\n      return StaticSlice::FromStaticString(\"http\");\n    case kHttps:\n      return StaticSlice::FromStaticString(\"https\");\n    default:\n      abort();\n  }\n}\n\nsize_t EncodedSizeOfKey(HttpSchemeMetadata, HttpSchemeMetadata::ValueType x) {\n  switch (x) {\n    case HttpSchemeMetadata::kHttp:\n      return 4;\n    case HttpSchemeMetadata::kHttps:\n      return 5;\n    default:\n      return 0;\n  }\n}\n\nconst char* HttpSchemeMetadata::DisplayValue(ValueType content_type) {\n  switch (content_type) {\n    case kHttp:\n      return \"http\";\n    case kHttps:\n      return \"https\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nHttpMethodMetadata::MementoType HttpMethodMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  auto out = kInvalid;\n  auto value_string = value.as_string_view();\n  if (value_string == \"POST\") {\n    out = kPost;\n  } else if (value_string == \"PUT\") {\n    out = kPut;\n  } else if (value_string == \"GET\") {\n    out = kGet;\n  } else {\n    on_error(\"invalid value\", value);\n  }\n  return out;\n}\n\nStaticSlice HttpMethodMetadata::Encode(ValueType x) {\n  switch (x) {\n    case kPost:\n      return StaticSlice::FromStaticString(\"POST\");\n    case kPut:\n      return StaticSlice::FromStaticString(\"PUT\");\n    case kGet:\n      return StaticSlice::FromStaticString(\"GET\");\n    default:\n      // TODO(ctiller): this should be an abort, we should split up the debug\n      // string generation from the encode string generation so that debug\n      // strings can always succeed and encode strings can crash.\n      return StaticSlice::FromStaticString(\"<<INVALID METHOD>>\");\n  }\n}\n\nconst char* HttpMethodMetadata::DisplayValue(ValueType content_type) {\n  switch (content_type) {\n    case kPost:\n      return \"POST\";\n    case kGet:\n      return \"GET\";\n    case kPut:\n      return \"PUT\";\n    default:\n      return \"<discarded-invalid-value>\";\n  }\n}\n\nCompressionAlgorithmBasedMetadata::MementoType\nCompressionAlgorithmBasedMetadata::ParseMemento(Slice value,\n                                                MetadataParseErrorFn on_error) {\n  auto algorithm = ParseCompressionAlgorithm(value.as_string_view());\n  if (!algorithm.has_value()) {\n    on_error(\"invalid value\", value);\n    return GRPC_COMPRESS_NONE;\n  }\n  return *algorithm;\n}\n\nDuration GrpcRetryPushbackMsMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  int64_t out;\n  if (!absl::SimpleAtoi(value.as_string_view(), &out)) {\n    on_error(\"not an integer\", value);\n    return Duration::NegativeInfinity();\n  }\n  return Duration::Milliseconds(out);\n}\n\nSlice LbCostBinMetadata::Encode(const ValueType& x) {\n  auto slice =\n      MutableSlice::CreateUninitialized(sizeof(double) + x.name.length());\n  memcpy(slice.data(), &x.cost, sizeof(double));\n  memcpy(slice.data() + sizeof(double), x.name.data(), x.name.length());\n  return Slice(std::move(slice));\n}\n\nstd::string LbCostBinMetadata::DisplayValue(ValueType x) {\n  return absl::StrCat(x.name, \":\", x.cost);\n}\n\nLbCostBinMetadata::MementoType LbCostBinMetadata::ParseMemento(\n    Slice value, MetadataParseErrorFn on_error) {\n  if (value.length() < sizeof(double)) {\n    on_error(\"too short\", value);\n    return {0, \"\"};\n  }\n  MementoType out;\n  memcpy(&out.cost, value.data(), sizeof(double));\n  out.name =\n      std::string(reinterpret_cast<const char*>(value.data()) + sizeof(double),\n                  value.length() - sizeof(double));\n  return out;\n}\n\nstd::string GrpcStreamNetworkState::DisplayValue(ValueType x) {\n  switch (x) {\n    case kNotSentOnWire:\n      return \"not sent on wire\";\n    case kNotSeenByServer:\n      return \"not seen by server\";\n  }\n  GPR_UNREACHABLE_CODE(return \"unknown value\");\n}\n\nstd::string PeerString::DisplayValue(const ValueType& x) {\n  return std::string(x.as_string_view());\n}\n\nconst std::string& GrpcStatusContext::DisplayValue(const std::string& x) {\n  return x;\n}\n\nstd::string WaitForReady::DisplayValue(ValueType x) {\n  return absl::StrCat(x.value ? \"true\" : \"false\",\n                      x.explicitly_set ? \" (explicit)\" : \"\");\n}\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -83,6 +83,17 @@\n       return StaticSlice::FromStaticString(\"https\");\n     default:\n       abort();\n+  }\n+}\n+\n+size_t EncodedSizeOfKey(HttpSchemeMetadata, HttpSchemeMetadata::ValueType x) {\n+  switch (x) {\n+    case HttpSchemeMetadata::kHttp:\n+      return 4;\n+    case HttpSchemeMetadata::kHttps:\n+      return 5;\n+    default:\n+      return 0;\n   }\n }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  }",
                "}",
                "",
                "size_t EncodedSizeOfKey(HttpSchemeMetadata, HttpSchemeMetadata::ValueType x) {",
                "  switch (x) {",
                "    case HttpSchemeMetadata::kHttp:",
                "      return 4;",
                "    case HttpSchemeMetadata::kHttps:",
                "      return 5;",
                "    default:",
                "      return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11524",
        "func_name": "ImageMagick/WriteBlob",
        "description": "The WriteBlob function in MagickCore/blob.c in ImageMagick before 6.9.8-10 and 7.x before 7.6.0-0 allows remote attackers to cause a denial of service (assertion failure and application exit) via a crafted file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/500d85b8dabbbc37b38e0136feba49633ce982af",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/506",
        "commit_text": "",
        "func_before": "MagickExport ssize_t WriteBlob(Image *image,const size_t length,\n  const void *data)\n{\n  int\n    c;\n\n  register const unsigned char\n    *p;\n\n  ssize_t\n    count;\n\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  assert(data != (const void *) NULL);\n  assert(image->blob != (BlobInfo *) NULL);\n  assert(image->blob->type != UndefinedStream);\n  if (length == 0)\n    return(0);\n  count=0;\n  p=(const unsigned char *) data;\n  switch (image->blob->type)\n  {\n    case UndefinedStream:\n      break;\n    case StandardStream:\n    case FileStream:\n    case PipeStream:\n    {\n      switch (length)\n      {\n        default:\n        {\n          count=(ssize_t) fwrite((const char *) data,1,length,\n            image->blob->file_info.file);\n          break;\n        }\n        case 4:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 3:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 2:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 1:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 0:\n          break;\n      }\n      break;\n    }\n    case ZipStream:\n    {\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n      switch (length)\n      {\n        default:\n        {\n          count=(ssize_t) gzwrite(image->blob->file_info.gzfile,(void *) data,\n            (unsigned int) length);\n          break;\n        }\n        case 4:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 3:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 2:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 1:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 0:\n          break;\n      }\n#endif\n      break;\n    }\n    case BZipStream:\n    {\n#if defined(MAGICKCORE_BZLIB_DELEGATE)\n      count=(ssize_t) BZ2_bzwrite(image->blob->file_info.bzfile,(void *) data,\n        (int) length);\n#endif\n      break;\n    }\n    case FifoStream:\n    {\n      count=(ssize_t) image->blob->stream(image,data,length);\n      break;\n    }\n    case BlobStream:\n    {\n      register unsigned char\n        *q;\n\n      if ((image->blob->offset+(MagickOffsetType) length) >=\n          (MagickOffsetType) image->blob->extent)\n        {\n          if (image->blob->mapped != MagickFalse)\n            return(0);\n          image->blob->extent+=length+image->blob->quantum;\n          image->blob->quantum<<=1;\n          image->blob->data=(unsigned char *) ResizeQuantumMemory(\n            image->blob->data,image->blob->extent+1,sizeof(*image->blob->data));\n          (void) SyncBlob(image);\n          if (image->blob->data == (unsigned char *) NULL)\n            {\n              (void) DetachBlob(image->blob);\n              return(0);\n            }\n        }\n      q=image->blob->data+image->blob->offset;\n      (void) memcpy(q,p,length);\n      image->blob->offset+=length;\n      if (image->blob->offset >= (MagickOffsetType) image->blob->length)\n        image->blob->length=(size_t) image->blob->offset;\n      count=(ssize_t) length;\n      break;\n    }\n    case CustomStream:\n    {\n      count=image->blob->custom_stream->writer((const unsigned char *) data,\n        length,image->blob->custom_stream->data);\n      break;\n    }\n  }\n  return(count);\n}",
        "func": "MagickExport ssize_t WriteBlob(Image *image,const size_t length,\n  const void *data)\n{\n  int\n    c;\n\n  register const unsigned char\n    *p;\n\n  ssize_t\n    count;\n\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  assert(image->blob != (BlobInfo *) NULL);\n  assert(image->blob->type != UndefinedStream);\n  if (length == 0)\n    return(0);\n  assert(data != (const void *) NULL);\n  count=0;\n  p=(const unsigned char *) data;\n  switch (image->blob->type)\n  {\n    case UndefinedStream:\n      break;\n    case StandardStream:\n    case FileStream:\n    case PipeStream:\n    {\n      switch (length)\n      {\n        default:\n        {\n          count=(ssize_t) fwrite((const char *) data,1,length,\n            image->blob->file_info.file);\n          break;\n        }\n        case 4:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 3:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 2:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 1:\n        {\n          c=putc((int) *p++,image->blob->file_info.file);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 0:\n          break;\n      }\n      break;\n    }\n    case ZipStream:\n    {\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n      switch (length)\n      {\n        default:\n        {\n          count=(ssize_t) gzwrite(image->blob->file_info.gzfile,(void *) data,\n            (unsigned int) length);\n          break;\n        }\n        case 4:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 3:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 2:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 1:\n        {\n          c=gzputc(image->blob->file_info.gzfile,(int) *p++);\n          if (c == EOF)\n            break;\n          count++;\n        }\n        case 0:\n          break;\n      }\n#endif\n      break;\n    }\n    case BZipStream:\n    {\n#if defined(MAGICKCORE_BZLIB_DELEGATE)\n      count=(ssize_t) BZ2_bzwrite(image->blob->file_info.bzfile,(void *) data,\n        (int) length);\n#endif\n      break;\n    }\n    case FifoStream:\n    {\n      count=(ssize_t) image->blob->stream(image,data,length);\n      break;\n    }\n    case BlobStream:\n    {\n      register unsigned char\n        *q;\n\n      if ((image->blob->offset+(MagickOffsetType) length) >=\n          (MagickOffsetType) image->blob->extent)\n        {\n          if (image->blob->mapped != MagickFalse)\n            return(0);\n          image->blob->extent+=length+image->blob->quantum;\n          image->blob->quantum<<=1;\n          image->blob->data=(unsigned char *) ResizeQuantumMemory(\n            image->blob->data,image->blob->extent+1,sizeof(*image->blob->data));\n          (void) SyncBlob(image);\n          if (image->blob->data == (unsigned char *) NULL)\n            {\n              (void) DetachBlob(image->blob);\n              return(0);\n            }\n        }\n      q=image->blob->data+image->blob->offset;\n      (void) memcpy(q,p,length);\n      image->blob->offset+=length;\n      if (image->blob->offset >= (MagickOffsetType) image->blob->length)\n        image->blob->length=(size_t) image->blob->offset;\n      count=(ssize_t) length;\n      break;\n    }\n    case CustomStream:\n    {\n      count=image->blob->custom_stream->writer((const unsigned char *) data,\n        length,image->blob->custom_stream->data);\n      break;\n    }\n  }\n  return(count);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,11 +12,11 @@\n \n   assert(image != (Image *) NULL);\n   assert(image->signature == MagickCoreSignature);\n-  assert(data != (const void *) NULL);\n   assert(image->blob != (BlobInfo *) NULL);\n   assert(image->blob->type != UndefinedStream);\n   if (length == 0)\n     return(0);\n+  assert(data != (const void *) NULL);\n   count=0;\n   p=(const unsigned char *) data;\n   switch (image->blob->type)",
        "diff_line_info": {
            "deleted_lines": [
                "  assert(data != (const void *) NULL);"
            ],
            "added_lines": [
                "  assert(data != (const void *) NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-12434",
        "func_name": "ImageMagick/ReadMATImage",
        "description": "In ImageMagick 7.0.6-1, a missing NULL check vulnerability was found in the function ReadMATImage in coders/mat.c, which allows attackers to cause a denial of service (assertion failure) in DestroyImageInfo in image.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/6767f31cac3eacdc9dc41b3193a73bdd37610375",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/547",
        "commit_text": "",
        "func_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=(ImageInfo *) NULL;\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if(MATLAB_HDR.ObjectSize+filepos > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}",
        "func": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=(ImageInfo *) NULL;\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if(MATLAB_HDR.ObjectSize+filepos > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -461,7 +461,8 @@\n   if (quantum_info != (QuantumInfo *) NULL)\n     quantum_info=DestroyQuantumInfo(quantum_info);\n END_OF_READING:\n-  clone_info=DestroyImageInfo(clone_info);\n+  if (clone_info)\n+    clone_info=DestroyImageInfo(clone_info);\n   CloseBlob(image);\n \n ",
        "diff_line_info": {
            "deleted_lines": [
                "  clone_info=DestroyImageInfo(clone_info);"
            ],
            "added_lines": [
                "  if (clone_info)",
                "    clone_info=DestroyImageInfo(clone_info);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-12670",
        "func_name": "ImageMagick/ReadMATImage",
        "description": "In ImageMagick 7.0.6-3, missing validation was found in coders/mat.c, leading to an assertion failure in the function DestroyImage in MagickCore/image.c, which allows attackers to cause a denial of service.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/ab440f9ea11e0dbefb7a808cbb9441198758b0cb",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/610",
        "commit_text": "",
        "func_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=(ImageInfo *) NULL;\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if ((image != image2) && (image2 != (Image *) NULL))\n    image2=DestroyImage(image2);\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}",
        "func": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=(ImageInfo *) NULL;\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -515,9 +515,10 @@\n     clone_info = NULL;\n   }\n   if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n-  if ((image != image2) && (image2 != (Image *) NULL))\n-    image2=DestroyImage(image2);\n   if(image==NULL)\n     ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n+  else\n+    if ((image != image2) && (image2 != (Image *) NULL))\n+      image2=DestroyImage(image2);\n   return (image);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if ((image != image2) && (image2 != (Image *) NULL))",
                "    image2=DestroyImage(image2);"
            ],
            "added_lines": [
                "  else",
                "    if ((image != image2) && (image2 != (Image *) NULL))",
                "      image2=DestroyImage(image2);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11368",
        "func_name": "krb5/process_tgs_req",
        "description": "In MIT Kerberos 5 (aka krb5) 1.7 and later, an authenticated attacker can cause a KDC assertion failure by sending invalid S4U2Self or S4U2Proxy requests.",
        "git_url": "https://github.com/krb5/krb5/commit/ffb35baac6981f9e8914f8f3bffd37f284b85970",
        "commit_title": "Prevent KDC unset status assertion failures",
        "commit_text": " Assign status values if S4U2Self padata fails to decode, if an S4U2Proxy request uses invalid KDC options, or if an S4U2Proxy request uses an evidence ticket which does not match the canonicalized request server principal name.  Reported by Samuel Cabrero.  If a status value is not assigned during KDC processing, default to \"UNKNOWN_REASON\" rather than failing an assertion.  This change will prevent future denial of service bugs due to similar mistakes, and will allow us to omit assigning status values for unlikely errors such as small memory allocation failures.  CVE-2017-11368:  In MIT krb5 1.7 and later, an authenticated attacker can cause an assertion failure in krb5kdc by sending an invalid S4U2Self or S4U2Proxy request.    CVSSv3 Vector: AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:H/RL:O/RC:C  ticket: 8599 (new) target_version: 1.15-next target_version: 1.14-next tags: pullup",
        "func_before": "krb5_error_code\nprocess_tgs_req(struct server_handle *handle, krb5_data *pkt,\n                const krb5_fulladdr *from, krb5_data **response)\n{\n    krb5_keyblock * subkey = 0;\n    krb5_keyblock *header_key = NULL;\n    krb5_kdc_req *request = 0;\n    krb5_db_entry *server = NULL;\n    krb5_db_entry *stkt_server = NULL;\n    krb5_kdc_rep reply;\n    krb5_enc_kdc_rep_part reply_encpart;\n    krb5_ticket ticket_reply, *header_ticket = 0;\n    int st_idx = 0;\n    krb5_enc_tkt_part enc_tkt_reply;\n    int newtransited = 0;\n    krb5_error_code retval = 0;\n    krb5_keyblock encrypting_key;\n    krb5_timestamp kdc_time, authtime = 0;\n    krb5_keyblock session_key;\n    krb5_keyblock *reply_key = NULL;\n    krb5_key_data  *server_key;\n    krb5_principal cprinc = NULL, sprinc = NULL, altcprinc = NULL;\n    krb5_last_req_entry *nolrarray[2], nolrentry;\n    int errcode;\n    const char        *status = 0;\n    krb5_enc_tkt_part *header_enc_tkt = NULL; /* TGT */\n    krb5_enc_tkt_part *subject_tkt = NULL; /* TGT or evidence ticket */\n    krb5_db_entry *client = NULL, *header_server = NULL;\n    krb5_db_entry *local_tgt, *local_tgt_storage = NULL;\n    krb5_pa_s4u_x509_user *s4u_x509_user = NULL; /* protocol transition request */\n    krb5_authdata **kdc_issued_auth_data = NULL; /* auth data issued by KDC */\n    unsigned int c_flags = 0, s_flags = 0;       /* client/server KDB flags */\n    krb5_boolean is_referral;\n    const char *emsg = NULL;\n    krb5_kvno ticket_kvno = 0;\n    struct kdc_request_state *state = NULL;\n    krb5_pa_data *pa_tgs_req; /*points into request*/\n    krb5_data scratch;\n    krb5_pa_data **e_data = NULL;\n    kdc_realm_t *kdc_active_realm = NULL;\n    krb5_audit_state *au_state = NULL;\n    krb5_data **auth_indicators = NULL;\n\n    memset(&reply, 0, sizeof(reply));\n    memset(&reply_encpart, 0, sizeof(reply_encpart));\n    memset(&ticket_reply, 0, sizeof(ticket_reply));\n    memset(&enc_tkt_reply, 0, sizeof(enc_tkt_reply));\n    session_key.contents = NULL;\n\n    retval = decode_krb5_tgs_req(pkt, &request);\n    if (retval)\n        return retval;\n    /* Save pointer to client-requested service principal, in case of\n     * errors before a successful call to search_sprinc(). */\n    sprinc = request->server;\n\n    if (request->msg_type != KRB5_TGS_REQ) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return KRB5_BADMSGTYPE;\n    }\n\n    /*\n     * setup_server_realm() sets up the global realm-specific data pointer.\n     */\n    kdc_active_realm = setup_server_realm(handle, request->server);\n    if (kdc_active_realm == NULL) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return KRB5KDC_ERR_WRONG_REALM;\n    }\n    errcode = kdc_make_rstate(kdc_active_realm, &state);\n    if (errcode !=0) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return errcode;\n    }\n\n    /* Initialize audit state. */\n    errcode = kau_init_kdc_req(kdc_context, request, from, &au_state);\n    if (errcode) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return errcode;\n    }\n    /* Seed the audit trail with the request ID and basic information. */\n    kau_tgs_req(kdc_context, TRUE, au_state);\n\n    errcode = kdc_process_tgs_req(kdc_active_realm,\n                                  request, from, pkt, &header_ticket,\n                                  &header_server, &header_key, &subkey,\n                                  &pa_tgs_req);\n    if (header_ticket && header_ticket->enc_part2)\n        cprinc = header_ticket->enc_part2->client;\n\n    if (errcode) {\n        status = \"PROCESS_TGS\";\n        goto cleanup;\n    }\n\n    if (!header_ticket) {\n        errcode = KRB5_NO_TKT_SUPPLIED;        /* XXX? */\n        status=\"UNEXPECTED NULL in header_ticket\";\n        goto cleanup;\n    }\n    errcode = kau_make_tkt_id(kdc_context, header_ticket,\n                              &au_state->tkt_in_id);\n    if (errcode) {\n        status = \"GENERATE_TICKET_ID\";\n        goto cleanup;\n    }\n\n    scratch.length = pa_tgs_req->length;\n    scratch.data = (char *) pa_tgs_req->contents;\n    errcode = kdc_find_fast(&request, &scratch, subkey,\n                            header_ticket->enc_part2->session, state, NULL);\n    /* Reset sprinc because kdc_find_fast() can replace request. */\n    sprinc = request->server;\n    if (errcode !=0) {\n        status = \"FIND_FAST\";\n        goto cleanup;\n    }\n\n    errcode = get_local_tgt(kdc_context, &sprinc->realm, header_server,\n                            &local_tgt, &local_tgt_storage);\n    if (errcode) {\n        status = \"GET_LOCAL_TGT\";\n        goto cleanup;\n    }\n\n    /* Ignore (for now) the request modification due to FAST processing. */\n    au_state->request = request;\n\n    /*\n     * Pointer to the encrypted part of the header ticket, which may be\n     * replaced to point to the encrypted part of the evidence ticket\n     * if constrained delegation is used. This simplifies the number of\n     * special cases for constrained delegation.\n     */\n    header_enc_tkt = header_ticket->enc_part2;\n\n    /*\n     * We've already dealt with the AP_REQ authentication, so we can\n     * use header_ticket freely.  The encrypted part (if any) has been\n     * decrypted with the session key.\n     */\n\n    au_state->stage = SRVC_PRINC;\n\n    /* XXX make sure server here has the proper realm...taken from AP_REQ\n       header? */\n\n    setflag(s_flags, KRB5_KDB_FLAG_ALIAS_OK);\n    if (isflagset(request->kdc_options, KDC_OPT_CANONICALIZE)) {\n        setflag(c_flags, KRB5_KDB_FLAG_CANONICALIZE);\n        setflag(s_flags, KRB5_KDB_FLAG_CANONICALIZE);\n    }\n\n    errcode = search_sprinc(kdc_active_realm, request, s_flags, &server,\n                            &status);\n    if (errcode != 0)\n        goto cleanup;\n    sprinc = server->princ;\n\n    /* If we got a cross-realm TGS which is not the requested server, we are\n     * issuing a referral (or alternate TGT, which we treat similarly). */\n    is_referral = is_cross_tgs_principal(server->princ) &&\n        !krb5_principal_compare(kdc_context, request->server, server->princ);\n\n    au_state->stage = VALIDATE_POL;\n\n    if ((errcode = krb5_timeofday(kdc_context, &kdc_time))) {\n        status = \"TIME_OF_DAY\";\n        goto cleanup;\n    }\n\n    if ((retval = validate_tgs_request(kdc_active_realm,\n                                       request, *server, header_ticket,\n                                       kdc_time, &status, &e_data))) {\n        if (!status)\n            status = \"UNKNOWN_REASON\";\n        if (retval == KDC_ERR_POLICY || retval == KDC_ERR_BADOPTION)\n            au_state->violation = PROT_CONSTRAINT;\n        errcode = retval + ERROR_TABLE_BASE_krb5;\n        goto cleanup;\n    }\n\n    if (!is_local_principal(kdc_active_realm, header_enc_tkt->client))\n        setflag(c_flags, KRB5_KDB_FLAG_CROSS_REALM);\n\n    /* Check for protocol transition */\n    errcode = kdc_process_s4u2self_req(kdc_active_realm,\n                                       request,\n                                       header_enc_tkt->client,\n                                       server,\n                                       subkey,\n                                       header_enc_tkt->session,\n                                       kdc_time,\n                                       &s4u_x509_user,\n                                       &client,\n                                       &status);\n    if (s4u_x509_user != NULL || errcode != 0) {\n        if (s4u_x509_user != NULL)\n            au_state->s4u2self_user = s4u_x509_user->user_id.user;\n        if (errcode == KDC_ERR_POLICY || errcode == KDC_ERR_BADOPTION)\n            au_state->violation = PROT_CONSTRAINT;\n        au_state->status = status;\n        kau_s4u2self(kdc_context, errcode ? FALSE : TRUE, au_state);\n        au_state->s4u2self_user = NULL;\n    }\n\n    if (errcode)\n        goto cleanup;\n    if (s4u_x509_user != NULL) {\n        setflag(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION);\n        if (is_referral) {\n            /* The requesting server appears to no longer exist, and we found\n             * a referral instead.  Treat this as a server lookup failure. */\n            errcode = KRB5KDC_ERR_S_PRINCIPAL_UNKNOWN;\n            status = \"LOOKING_UP_SERVER\";\n            goto cleanup;\n        }\n    }\n\n    /* Deal with user-to-user and constrained delegation */\n    errcode = decrypt_2ndtkt(kdc_active_realm, request, c_flags,\n                             &stkt_server, &status);\n    if (errcode)\n        goto cleanup;\n\n    if (isflagset(request->kdc_options, KDC_OPT_CNAME_IN_ADDL_TKT)) {\n        /* Do constrained delegation protocol and authorization checks */\n        errcode = kdc_process_s4u2proxy_req(kdc_active_realm,\n                                            request,\n                                            request->second_ticket[st_idx]->enc_part2,\n                                            stkt_server,\n                                            header_ticket->enc_part2->client,\n                                            request->server,\n                                            &status);\n        if (errcode == KDC_ERR_POLICY || errcode == KDC_ERR_BADOPTION)\n            au_state->violation = PROT_CONSTRAINT;\n        else if (errcode)\n            au_state->violation = LOCAL_POLICY;\n        au_state->status = status;\n        retval = kau_make_tkt_id(kdc_context, request->second_ticket[st_idx],\n                                  &au_state->evid_tkt_id);\n        if (retval) {\n            status = \"GENERATE_TICKET_ID\";\n            errcode = retval;\n            goto cleanup;\n        }\n        kau_s4u2proxy(kdc_context, errcode ? FALSE : TRUE, au_state);\n        if (errcode)\n            goto cleanup;\n\n        setflag(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION);\n\n        assert(krb5_is_tgs_principal(header_ticket->server));\n\n        assert(client == NULL); /* assured by kdc_process_s4u2self_req() */\n        client = stkt_server;\n        stkt_server = NULL;\n    } else if (request->kdc_options & KDC_OPT_ENC_TKT_IN_SKEY) {\n        krb5_db_free_principal(kdc_context, stkt_server);\n        stkt_server = NULL;\n    } else\n        assert(stkt_server == NULL);\n\n    au_state->stage = ISSUE_TKT;\n\n    errcode = gen_session_key(kdc_active_realm, request, server, &session_key,\n                              &status);\n    if (errcode)\n        goto cleanup;\n\n    /*\n     * subject_tkt will refer to the evidence ticket (for constrained\n     * delegation) or the TGT. The distinction from header_enc_tkt is\n     * necessary because the TGS signature only protects some fields:\n     * the others could be forged by a malicious server.\n     */\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION))\n        subject_tkt = request->second_ticket[st_idx]->enc_part2;\n    else\n        subject_tkt = header_enc_tkt;\n    authtime = subject_tkt->times.authtime;\n\n    /* Extract auth indicators from the subject ticket, except for S4U2Proxy\n     * requests (where the client didn't authenticate). */\n    if (s4u_x509_user == NULL) {\n        errcode = get_auth_indicators(kdc_context, subject_tkt, local_tgt,\n                                      &auth_indicators);\n        if (errcode) {\n            status = \"GET_AUTH_INDICATORS\";\n            goto cleanup;\n        }\n    }\n\n    errcode = check_indicators(kdc_context, server, auth_indicators);\n    if (errcode) {\n        status = \"HIGHER_AUTHENTICATION_REQUIRED\";\n        goto cleanup;\n    }\n\n    if (is_referral)\n        ticket_reply.server = server->princ;\n    else\n        ticket_reply.server = request->server; /* XXX careful for realm... */\n\n    enc_tkt_reply.flags = OPTS2FLAGS(request->kdc_options);\n    enc_tkt_reply.flags |= COPY_TKT_FLAGS(header_enc_tkt->flags);\n    enc_tkt_reply.times.starttime = 0;\n\n    if (isflagset(server->attributes, KRB5_KDB_OK_AS_DELEGATE))\n        setflag(enc_tkt_reply.flags, TKT_FLG_OK_AS_DELEGATE);\n\n    /* Indicate support for encrypted padata (RFC 6806). */\n    setflag(enc_tkt_reply.flags, TKT_FLG_ENC_PA_REP);\n\n    /* don't use new addresses unless forwarded, see below */\n\n    enc_tkt_reply.caddrs = header_enc_tkt->caddrs;\n    /* noaddrarray[0] = 0; */\n    reply_encpart.caddrs = 0;/* optional...don't put it in */\n    reply_encpart.enc_padata = NULL;\n\n    /*\n     * It should be noted that local policy may affect the\n     * processing of any of these flags.  For example, some\n     * realms may refuse to issue renewable tickets\n     */\n\n    if (isflagset(request->kdc_options, KDC_OPT_FORWARDABLE)) {\n\n        if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION)) {\n            /*\n             * If S4U2Self principal is not forwardable, then mark ticket as\n             * unforwardable. This behaviour matches Windows, but it is\n             * different to the MIT AS-REQ path, which returns an error\n             * (KDC_ERR_POLICY) if forwardable tickets cannot be issued.\n             *\n             * Consider this block the S4U2Self equivalent to\n             * validate_forwardable().\n             */\n            if (client != NULL &&\n                isflagset(client->attributes, KRB5_KDB_DISALLOW_FORWARDABLE))\n                clear(enc_tkt_reply.flags, TKT_FLG_FORWARDABLE);\n            /*\n             * Forwardable flag is propagated along referral path.\n             */\n            else if (!isflagset(header_enc_tkt->flags, TKT_FLG_FORWARDABLE))\n                clear(enc_tkt_reply.flags, TKT_FLG_FORWARDABLE);\n            /*\n             * OK_TO_AUTH_AS_DELEGATE must be set on the service requesting\n             * S4U2Self in order for forwardable tickets to be returned.\n             */\n            else if (!is_referral &&\n                     !isflagset(server->attributes,\n                                KRB5_KDB_OK_TO_AUTH_AS_DELEGATE))\n                clear(enc_tkt_reply.flags, TKT_FLG_FORWARDABLE);\n        }\n    }\n\n    if (isflagset(request->kdc_options, KDC_OPT_FORWARDED) ||\n        isflagset(request->kdc_options, KDC_OPT_PROXY)) {\n\n        /* include new addresses in ticket & reply */\n\n        enc_tkt_reply.caddrs = request->addresses;\n        reply_encpart.caddrs = request->addresses;\n    }\n    /* We don't currently handle issuing anonymous tickets based on\n     * non-anonymous ones, so just ignore the option. */\n    if (isflagset(request->kdc_options, KDC_OPT_REQUEST_ANONYMOUS) &&\n        !isflagset(header_enc_tkt->flags, TKT_FLG_ANONYMOUS))\n        clear(enc_tkt_reply.flags, TKT_FLG_ANONYMOUS);\n\n    if (isflagset(request->kdc_options, KDC_OPT_POSTDATED)) {\n        setflag(enc_tkt_reply.flags, TKT_FLG_INVALID);\n        enc_tkt_reply.times.starttime = request->from;\n    } else\n        enc_tkt_reply.times.starttime = kdc_time;\n\n    if (isflagset(request->kdc_options, KDC_OPT_VALIDATE)) {\n        assert(isflagset(c_flags, KRB5_KDB_FLAGS_S4U) == 0);\n        /* BEWARE of allocation hanging off of ticket & enc_part2, it belongs\n           to the caller */\n        ticket_reply = *(header_ticket);\n        enc_tkt_reply = *(header_ticket->enc_part2);\n        enc_tkt_reply.authorization_data = NULL;\n        clear(enc_tkt_reply.flags, TKT_FLG_INVALID);\n    }\n\n    if (isflagset(request->kdc_options, KDC_OPT_RENEW)) {\n        krb5_timestamp old_starttime;\n        krb5_deltat old_life;\n\n        assert(isflagset(c_flags, KRB5_KDB_FLAGS_S4U) == 0);\n        /* BEWARE of allocation hanging off of ticket & enc_part2, it belongs\n           to the caller */\n        ticket_reply = *(header_ticket);\n        enc_tkt_reply = *(header_ticket->enc_part2);\n        enc_tkt_reply.authorization_data = NULL;\n\n        old_starttime = enc_tkt_reply.times.starttime ?\n            enc_tkt_reply.times.starttime : enc_tkt_reply.times.authtime;\n        old_life = ts_delta(enc_tkt_reply.times.endtime, old_starttime);\n\n        enc_tkt_reply.times.starttime = kdc_time;\n        enc_tkt_reply.times.endtime =\n            ts_min(header_ticket->enc_part2->times.renew_till,\n                   ts_incr(kdc_time, old_life));\n    } else {\n        /* not a renew request */\n        enc_tkt_reply.times.starttime = kdc_time;\n\n        kdc_get_ticket_endtime(kdc_active_realm, enc_tkt_reply.times.starttime,\n                               header_enc_tkt->times.endtime, request->till,\n                               client, server, &enc_tkt_reply.times.endtime);\n    }\n\n    kdc_get_ticket_renewtime(kdc_active_realm, request, header_enc_tkt, client,\n                             server, &enc_tkt_reply);\n\n    /*\n     * Set authtime to be the same as header or evidence ticket's\n     */\n    enc_tkt_reply.times.authtime = authtime;\n\n    /* starttime is optional, and treated as authtime if not present.\n       so we can nuke it if it matches */\n    if (enc_tkt_reply.times.starttime == enc_tkt_reply.times.authtime)\n        enc_tkt_reply.times.starttime = 0;\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION)) {\n        altcprinc = s4u_x509_user->user_id.user;\n    } else if (isflagset(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION)) {\n        altcprinc = subject_tkt->client;\n    } else {\n        altcprinc = NULL;\n    }\n    if (isflagset(request->kdc_options, KDC_OPT_ENC_TKT_IN_SKEY)) {\n        krb5_enc_tkt_part *t2enc = request->second_ticket[st_idx]->enc_part2;\n        encrypting_key = *(t2enc->session);\n    } else {\n        /*\n         * Find the server key\n         */\n        if ((errcode = krb5_dbe_find_enctype(kdc_context, server,\n                                             -1, /* ignore keytype */\n                                             -1, /* Ignore salttype */\n                                             0,  /* Get highest kvno */\n                                             &server_key))) {\n            status = \"FINDING_SERVER_KEY\";\n            goto cleanup;\n        }\n\n        /*\n         * Convert server.key into a real key\n         * (it may be encrypted in the database)\n         */\n        if ((errcode = krb5_dbe_decrypt_key_data(kdc_context, NULL,\n                                                 server_key, &encrypting_key,\n                                                 NULL))) {\n            status = \"DECRYPT_SERVER_KEY\";\n            goto cleanup;\n        }\n    }\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION)) {\n        /*\n         * Don't allow authorization data to be disabled if constrained\n         * delegation is requested. We don't want to deny the server\n         * the ability to validate that delegation was used.\n         */\n        clear(server->attributes, KRB5_KDB_NO_AUTH_DATA_REQUIRED);\n    }\n    if (isflagset(server->attributes, KRB5_KDB_NO_AUTH_DATA_REQUIRED) == 0) {\n        /*\n         * If we are not doing protocol transition/constrained delegation\n         * try to lookup the client principal so plugins can add additional\n         * authorization information.\n         *\n         * Always validate authorization data for constrained delegation\n         * because we must validate the KDC signatures.\n         */\n        if (!isflagset(c_flags, KRB5_KDB_FLAGS_S4U)) {\n            /* Generate authorization data so we can include it in ticket */\n            setflag(c_flags, KRB5_KDB_FLAG_INCLUDE_PAC);\n            /* Map principals from foreign (possibly non-AD) realms */\n            setflag(c_flags, KRB5_KDB_FLAG_MAP_PRINCIPALS);\n\n            assert(client == NULL); /* should not have been set already */\n\n            errcode = krb5_db_get_principal(kdc_context, subject_tkt->client,\n                                            c_flags, &client);\n        }\n    }\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION) &&\n        !isflagset(c_flags, KRB5_KDB_FLAG_CROSS_REALM))\n        enc_tkt_reply.client = s4u_x509_user->user_id.user;\n    else\n        enc_tkt_reply.client = subject_tkt->client;\n\n    enc_tkt_reply.session = &session_key;\n    enc_tkt_reply.transited.tr_type = KRB5_DOMAIN_X500_COMPRESS;\n    enc_tkt_reply.transited.tr_contents = empty_string; /* equivalent of \"\" */\n\n    /*\n     * Only add the realm of the presented tgt to the transited list if\n     * it is different than the local realm (cross-realm) and it is different\n     * than the realm of the client (since the realm of the client is already\n     * implicitly part of the transited list and should not be explicitly\n     * listed).\n     */\n    /* realm compare is like strcmp, but knows how to deal with these args */\n    if (krb5_realm_compare(kdc_context, header_ticket->server, tgs_server) ||\n        krb5_realm_compare(kdc_context, header_ticket->server,\n                           enc_tkt_reply.client)) {\n        /* tgt issued by local realm or issued by realm of client */\n        enc_tkt_reply.transited = header_enc_tkt->transited;\n    } else {\n        /* tgt issued by some other realm and not the realm of the client */\n        /* assemble new transited field into allocated storage */\n        if (header_enc_tkt->transited.tr_type !=\n            KRB5_DOMAIN_X500_COMPRESS) {\n            status = \"VALIDATE_TRANSIT_TYPE\";\n            errcode = KRB5KDC_ERR_TRTYPE_NOSUPP;\n            goto cleanup;\n        }\n        memset(&enc_tkt_reply.transited, 0, sizeof(enc_tkt_reply.transited));\n        enc_tkt_reply.transited.tr_type = KRB5_DOMAIN_X500_COMPRESS;\n        if ((errcode =\n             add_to_transited(&header_enc_tkt->transited.tr_contents,\n                              &enc_tkt_reply.transited.tr_contents,\n                              header_ticket->server,\n                              enc_tkt_reply.client,\n                              request->server))) {\n            status = \"ADD_TO_TRANSITED_LIST\";\n            goto cleanup;\n        }\n        newtransited = 1;\n    }\n    if (isflagset(c_flags, KRB5_KDB_FLAG_CROSS_REALM)) {\n        errcode = validate_transit_path(kdc_context, header_enc_tkt->client,\n                                        server, header_server);\n        if (errcode) {\n            status = \"NON_TRANSITIVE\";\n            goto cleanup;\n        }\n    }\n    if (!isflagset (request->kdc_options, KDC_OPT_DISABLE_TRANSITED_CHECK)) {\n        errcode = kdc_check_transited_list (kdc_active_realm,\n                                            &enc_tkt_reply.transited.tr_contents,\n                                            krb5_princ_realm (kdc_context, header_enc_tkt->client),\n                                            krb5_princ_realm (kdc_context, request->server));\n        if (errcode == 0) {\n            setflag (enc_tkt_reply.flags, TKT_FLG_TRANSIT_POLICY_CHECKED);\n        } else {\n            log_tgs_badtrans(kdc_context, cprinc, sprinc,\n                             &enc_tkt_reply.transited.tr_contents, errcode);\n        }\n    } else\n        krb5_klog_syslog(LOG_INFO, _(\"not checking transit path\"));\n    if (kdc_active_realm->realm_reject_bad_transit &&\n        !isflagset(enc_tkt_reply.flags, TKT_FLG_TRANSIT_POLICY_CHECKED)) {\n        errcode = KRB5KDC_ERR_POLICY;\n        status = \"BAD_TRANSIT\";\n        au_state->violation = LOCAL_POLICY;\n        goto cleanup;\n    }\n\n    errcode = handle_authdata(kdc_context, c_flags, client, server,\n                              header_server, local_tgt,\n                              subkey != NULL ? subkey :\n                              header_ticket->enc_part2->session,\n                              &encrypting_key, /* U2U or server key */\n                              header_key,\n                              pkt,\n                              request,\n                              s4u_x509_user ?\n                              s4u_x509_user->user_id.user : NULL,\n                              subject_tkt,\n                              auth_indicators,\n                              &enc_tkt_reply);\n    if (errcode) {\n        krb5_klog_syslog(LOG_INFO, _(\"TGS_REQ : handle_authdata (%d)\"),\n                         errcode);\n        status = \"HANDLE_AUTHDATA\";\n        goto cleanup;\n    }\n\n    ticket_reply.enc_part2 = &enc_tkt_reply;\n\n    /*\n     * If we are doing user-to-user authentication, then make sure\n     * that the client for the second ticket matches the request\n     * server, and then encrypt the ticket using the session key of\n     * the second ticket.\n     */\n    if (isflagset(request->kdc_options, KDC_OPT_ENC_TKT_IN_SKEY)) {\n        /*\n         * Make sure the client for the second ticket matches\n         * requested server.\n         */\n        krb5_enc_tkt_part *t2enc = request->second_ticket[st_idx]->enc_part2;\n        krb5_principal client2 = t2enc->client;\n        if (!krb5_principal_compare(kdc_context, request->server, client2)) {\n            altcprinc = client2;\n            errcode = KRB5KDC_ERR_SERVER_NOMATCH;\n            status = \"2ND_TKT_MISMATCH\";\n            au_state->status = status;\n            kau_u2u(kdc_context, FALSE, au_state);\n            goto cleanup;\n        }\n\n        ticket_kvno = 0;\n        ticket_reply.enc_part.enctype = t2enc->session->enctype;\n        kau_u2u(kdc_context, TRUE, au_state);\n        st_idx++;\n    } else {\n        ticket_kvno = server_key->key_data_kvno;\n    }\n\n    errcode = krb5_encrypt_tkt_part(kdc_context, &encrypting_key,\n                                    &ticket_reply);\n    if (!isflagset(request->kdc_options, KDC_OPT_ENC_TKT_IN_SKEY))\n        krb5_free_keyblock_contents(kdc_context, &encrypting_key);\n    if (errcode) {\n        status = \"ENCRYPT_TICKET\";\n        goto cleanup;\n    }\n    ticket_reply.enc_part.kvno = ticket_kvno;\n    /* Start assembling the response */\n    au_state->stage = ENCR_REP;\n    reply.msg_type = KRB5_TGS_REP;\n    if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION) &&\n        krb5int_find_pa_data(kdc_context, request->padata,\n                             KRB5_PADATA_S4U_X509_USER) != NULL) {\n        errcode = kdc_make_s4u2self_rep(kdc_context,\n                                        subkey,\n                                        header_ticket->enc_part2->session,\n                                        s4u_x509_user,\n                                        &reply,\n                                        &reply_encpart);\n        if (errcode) {\n            status = \"MAKE_S4U2SELF_PADATA\";\n            au_state->status = status;\n        }\n        kau_s4u2self(kdc_context, errcode ? FALSE : TRUE, au_state);\n        if (errcode)\n            goto cleanup;\n    }\n\n    reply.client = enc_tkt_reply.client;\n    reply.enc_part.kvno = 0;/* We are using the session key */\n    reply.ticket = &ticket_reply;\n\n    reply_encpart.session = &session_key;\n    reply_encpart.nonce = request->nonce;\n\n    /* copy the time fields */\n    reply_encpart.times = enc_tkt_reply.times;\n\n    nolrentry.lr_type = KRB5_LRQ_NONE;\n    nolrentry.value = 0;\n    nolrentry.magic = 0;\n    nolrarray[0] = &nolrentry;\n    nolrarray[1] = 0;\n    reply_encpart.last_req = nolrarray;        /* not available for TGS reqs */\n    reply_encpart.key_exp = 0;/* ditto */\n    reply_encpart.flags = enc_tkt_reply.flags;\n    reply_encpart.server = ticket_reply.server;\n\n    /* use the session key in the ticket, unless there's a subsession key\n       in the AP_REQ */\n    reply.enc_part.enctype = subkey ? subkey->enctype :\n        header_ticket->enc_part2->session->enctype;\n    errcode  = kdc_fast_response_handle_padata(state, request, &reply,\n                                               subkey ? subkey->enctype : header_ticket->enc_part2->session->enctype);\n    if (errcode !=0 ) {\n        status = \"MAKE_FAST_RESPONSE\";\n        goto cleanup;\n    }\n    errcode =kdc_fast_handle_reply_key(state,\n                                       subkey?subkey:header_ticket->enc_part2->session, &reply_key);\n    if (errcode) {\n        status  = \"MAKE_FAST_REPLY_KEY\";\n        goto cleanup;\n    }\n    errcode = return_enc_padata(kdc_context, pkt, request,\n                                reply_key, server, &reply_encpart,\n                                is_referral &&\n                                isflagset(s_flags,\n                                          KRB5_KDB_FLAG_CANONICALIZE));\n    if (errcode) {\n        status = \"KDC_RETURN_ENC_PADATA\";\n        goto cleanup;\n    }\n\n    errcode = kau_make_tkt_id(kdc_context, &ticket_reply, &au_state->tkt_out_id);\n    if (errcode) {\n        status = \"GENERATE_TICKET_ID\";\n        goto cleanup;\n    }\n\n    if (kdc_fast_hide_client(state))\n        reply.client = (krb5_principal)krb5_anonymous_principal();\n    errcode = krb5_encode_kdc_rep(kdc_context, KRB5_TGS_REP, &reply_encpart,\n                                  subkey ? 1 : 0,\n                                  reply_key,\n                                  &reply, response);\n    if (errcode) {\n        status = \"ENCODE_KDC_REP\";\n    } else {\n        status = \"ISSUE\";\n    }\n\n    memset(ticket_reply.enc_part.ciphertext.data, 0,\n           ticket_reply.enc_part.ciphertext.length);\n    free(ticket_reply.enc_part.ciphertext.data);\n    /* these parts are left on as a courtesy from krb5_encode_kdc_rep so we\n       can use them in raw form if needed.  But, we don't... */\n    memset(reply.enc_part.ciphertext.data, 0,\n           reply.enc_part.ciphertext.length);\n    free(reply.enc_part.ciphertext.data);\n\ncleanup:\n    assert(status != NULL);\n    if (reply_key)\n        krb5_free_keyblock(kdc_context, reply_key);\n    if (errcode)\n        emsg = krb5_get_error_message (kdc_context, errcode);\n\n    au_state->status = status;\n    if (!errcode)\n        au_state->reply = &reply;\n    kau_tgs_req(kdc_context, errcode ? FALSE : TRUE, au_state);\n    kau_free_kdc_req(au_state);\n\n    log_tgs_req(kdc_context, from, request, &reply, cprinc,\n                sprinc, altcprinc, authtime,\n                c_flags, status, errcode, emsg);\n    if (errcode) {\n        krb5_free_error_message (kdc_context, emsg);\n        emsg = NULL;\n    }\n\n    if (errcode) {\n        int got_err = 0;\n        if (status == 0) {\n            status = krb5_get_error_message (kdc_context, errcode);\n            got_err = 1;\n        }\n        errcode -= ERROR_TABLE_BASE_krb5;\n        if (errcode < 0 || errcode > KRB_ERR_MAX)\n            errcode = KRB_ERR_GENERIC;\n\n        retval = prepare_error_tgs(state, request, header_ticket, errcode,\n                                   (server != NULL) ? server->princ : NULL,\n                                   response, status, e_data);\n        if (got_err) {\n            krb5_free_error_message (kdc_context, status);\n            status = 0;\n        }\n    }\n\n    if (header_ticket != NULL)\n        krb5_free_ticket(kdc_context, header_ticket);\n    if (request != NULL)\n        krb5_free_kdc_req(kdc_context, request);\n    if (state)\n        kdc_free_rstate(state);\n    krb5_db_free_principal(kdc_context, server);\n    krb5_db_free_principal(kdc_context, stkt_server);\n    krb5_db_free_principal(kdc_context, header_server);\n    krb5_db_free_principal(kdc_context, client);\n    krb5_db_free_principal(kdc_context, local_tgt_storage);\n    if (session_key.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &session_key);\n    if (newtransited)\n        free(enc_tkt_reply.transited.tr_contents.data);\n    if (s4u_x509_user != NULL)\n        krb5_free_pa_s4u_x509_user(kdc_context, s4u_x509_user);\n    if (kdc_issued_auth_data != NULL)\n        krb5_free_authdata(kdc_context, kdc_issued_auth_data);\n    if (subkey != NULL)\n        krb5_free_keyblock(kdc_context, subkey);\n    if (header_key != NULL)\n        krb5_free_keyblock(kdc_context, header_key);\n    if (reply.padata)\n        krb5_free_pa_data(kdc_context, reply.padata);\n    if (reply_encpart.enc_padata)\n        krb5_free_pa_data(kdc_context, reply_encpart.enc_padata);\n    if (enc_tkt_reply.authorization_data != NULL)\n        krb5_free_authdata(kdc_context, enc_tkt_reply.authorization_data);\n    krb5_free_pa_data(kdc_context, e_data);\n    k5_free_data_ptr_list(auth_indicators);\n\n    return retval;\n}",
        "func": "krb5_error_code\nprocess_tgs_req(struct server_handle *handle, krb5_data *pkt,\n                const krb5_fulladdr *from, krb5_data **response)\n{\n    krb5_keyblock * subkey = 0;\n    krb5_keyblock *header_key = NULL;\n    krb5_kdc_req *request = 0;\n    krb5_db_entry *server = NULL;\n    krb5_db_entry *stkt_server = NULL;\n    krb5_kdc_rep reply;\n    krb5_enc_kdc_rep_part reply_encpart;\n    krb5_ticket ticket_reply, *header_ticket = 0;\n    int st_idx = 0;\n    krb5_enc_tkt_part enc_tkt_reply;\n    int newtransited = 0;\n    krb5_error_code retval = 0;\n    krb5_keyblock encrypting_key;\n    krb5_timestamp kdc_time, authtime = 0;\n    krb5_keyblock session_key;\n    krb5_keyblock *reply_key = NULL;\n    krb5_key_data  *server_key;\n    krb5_principal cprinc = NULL, sprinc = NULL, altcprinc = NULL;\n    krb5_last_req_entry *nolrarray[2], nolrentry;\n    int errcode;\n    const char        *status = 0;\n    krb5_enc_tkt_part *header_enc_tkt = NULL; /* TGT */\n    krb5_enc_tkt_part *subject_tkt = NULL; /* TGT or evidence ticket */\n    krb5_db_entry *client = NULL, *header_server = NULL;\n    krb5_db_entry *local_tgt, *local_tgt_storage = NULL;\n    krb5_pa_s4u_x509_user *s4u_x509_user = NULL; /* protocol transition request */\n    krb5_authdata **kdc_issued_auth_data = NULL; /* auth data issued by KDC */\n    unsigned int c_flags = 0, s_flags = 0;       /* client/server KDB flags */\n    krb5_boolean is_referral;\n    const char *emsg = NULL;\n    krb5_kvno ticket_kvno = 0;\n    struct kdc_request_state *state = NULL;\n    krb5_pa_data *pa_tgs_req; /*points into request*/\n    krb5_data scratch;\n    krb5_pa_data **e_data = NULL;\n    kdc_realm_t *kdc_active_realm = NULL;\n    krb5_audit_state *au_state = NULL;\n    krb5_data **auth_indicators = NULL;\n\n    memset(&reply, 0, sizeof(reply));\n    memset(&reply_encpart, 0, sizeof(reply_encpart));\n    memset(&ticket_reply, 0, sizeof(ticket_reply));\n    memset(&enc_tkt_reply, 0, sizeof(enc_tkt_reply));\n    session_key.contents = NULL;\n\n    retval = decode_krb5_tgs_req(pkt, &request);\n    if (retval)\n        return retval;\n    /* Save pointer to client-requested service principal, in case of\n     * errors before a successful call to search_sprinc(). */\n    sprinc = request->server;\n\n    if (request->msg_type != KRB5_TGS_REQ) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return KRB5_BADMSGTYPE;\n    }\n\n    /*\n     * setup_server_realm() sets up the global realm-specific data pointer.\n     */\n    kdc_active_realm = setup_server_realm(handle, request->server);\n    if (kdc_active_realm == NULL) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return KRB5KDC_ERR_WRONG_REALM;\n    }\n    errcode = kdc_make_rstate(kdc_active_realm, &state);\n    if (errcode !=0) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return errcode;\n    }\n\n    /* Initialize audit state. */\n    errcode = kau_init_kdc_req(kdc_context, request, from, &au_state);\n    if (errcode) {\n        krb5_free_kdc_req(handle->kdc_err_context, request);\n        return errcode;\n    }\n    /* Seed the audit trail with the request ID and basic information. */\n    kau_tgs_req(kdc_context, TRUE, au_state);\n\n    errcode = kdc_process_tgs_req(kdc_active_realm,\n                                  request, from, pkt, &header_ticket,\n                                  &header_server, &header_key, &subkey,\n                                  &pa_tgs_req);\n    if (header_ticket && header_ticket->enc_part2)\n        cprinc = header_ticket->enc_part2->client;\n\n    if (errcode) {\n        status = \"PROCESS_TGS\";\n        goto cleanup;\n    }\n\n    if (!header_ticket) {\n        errcode = KRB5_NO_TKT_SUPPLIED;        /* XXX? */\n        status=\"UNEXPECTED NULL in header_ticket\";\n        goto cleanup;\n    }\n    errcode = kau_make_tkt_id(kdc_context, header_ticket,\n                              &au_state->tkt_in_id);\n    if (errcode) {\n        status = \"GENERATE_TICKET_ID\";\n        goto cleanup;\n    }\n\n    scratch.length = pa_tgs_req->length;\n    scratch.data = (char *) pa_tgs_req->contents;\n    errcode = kdc_find_fast(&request, &scratch, subkey,\n                            header_ticket->enc_part2->session, state, NULL);\n    /* Reset sprinc because kdc_find_fast() can replace request. */\n    sprinc = request->server;\n    if (errcode !=0) {\n        status = \"FIND_FAST\";\n        goto cleanup;\n    }\n\n    errcode = get_local_tgt(kdc_context, &sprinc->realm, header_server,\n                            &local_tgt, &local_tgt_storage);\n    if (errcode) {\n        status = \"GET_LOCAL_TGT\";\n        goto cleanup;\n    }\n\n    /* Ignore (for now) the request modification due to FAST processing. */\n    au_state->request = request;\n\n    /*\n     * Pointer to the encrypted part of the header ticket, which may be\n     * replaced to point to the encrypted part of the evidence ticket\n     * if constrained delegation is used. This simplifies the number of\n     * special cases for constrained delegation.\n     */\n    header_enc_tkt = header_ticket->enc_part2;\n\n    /*\n     * We've already dealt with the AP_REQ authentication, so we can\n     * use header_ticket freely.  The encrypted part (if any) has been\n     * decrypted with the session key.\n     */\n\n    au_state->stage = SRVC_PRINC;\n\n    /* XXX make sure server here has the proper realm...taken from AP_REQ\n       header? */\n\n    setflag(s_flags, KRB5_KDB_FLAG_ALIAS_OK);\n    if (isflagset(request->kdc_options, KDC_OPT_CANONICALIZE)) {\n        setflag(c_flags, KRB5_KDB_FLAG_CANONICALIZE);\n        setflag(s_flags, KRB5_KDB_FLAG_CANONICALIZE);\n    }\n\n    errcode = search_sprinc(kdc_active_realm, request, s_flags, &server,\n                            &status);\n    if (errcode != 0)\n        goto cleanup;\n    sprinc = server->princ;\n\n    /* If we got a cross-realm TGS which is not the requested server, we are\n     * issuing a referral (or alternate TGT, which we treat similarly). */\n    is_referral = is_cross_tgs_principal(server->princ) &&\n        !krb5_principal_compare(kdc_context, request->server, server->princ);\n\n    au_state->stage = VALIDATE_POL;\n\n    if ((errcode = krb5_timeofday(kdc_context, &kdc_time))) {\n        status = \"TIME_OF_DAY\";\n        goto cleanup;\n    }\n\n    if ((retval = validate_tgs_request(kdc_active_realm,\n                                       request, *server, header_ticket,\n                                       kdc_time, &status, &e_data))) {\n        if (!status)\n            status = \"UNKNOWN_REASON\";\n        if (retval == KDC_ERR_POLICY || retval == KDC_ERR_BADOPTION)\n            au_state->violation = PROT_CONSTRAINT;\n        errcode = retval + ERROR_TABLE_BASE_krb5;\n        goto cleanup;\n    }\n\n    if (!is_local_principal(kdc_active_realm, header_enc_tkt->client))\n        setflag(c_flags, KRB5_KDB_FLAG_CROSS_REALM);\n\n    /* Check for protocol transition */\n    errcode = kdc_process_s4u2self_req(kdc_active_realm,\n                                       request,\n                                       header_enc_tkt->client,\n                                       server,\n                                       subkey,\n                                       header_enc_tkt->session,\n                                       kdc_time,\n                                       &s4u_x509_user,\n                                       &client,\n                                       &status);\n    if (s4u_x509_user != NULL || errcode != 0) {\n        if (s4u_x509_user != NULL)\n            au_state->s4u2self_user = s4u_x509_user->user_id.user;\n        if (errcode == KDC_ERR_POLICY || errcode == KDC_ERR_BADOPTION)\n            au_state->violation = PROT_CONSTRAINT;\n        au_state->status = status;\n        kau_s4u2self(kdc_context, errcode ? FALSE : TRUE, au_state);\n        au_state->s4u2self_user = NULL;\n    }\n\n    if (errcode)\n        goto cleanup;\n    if (s4u_x509_user != NULL) {\n        setflag(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION);\n        if (is_referral) {\n            /* The requesting server appears to no longer exist, and we found\n             * a referral instead.  Treat this as a server lookup failure. */\n            errcode = KRB5KDC_ERR_S_PRINCIPAL_UNKNOWN;\n            status = \"LOOKING_UP_SERVER\";\n            goto cleanup;\n        }\n    }\n\n    /* Deal with user-to-user and constrained delegation */\n    errcode = decrypt_2ndtkt(kdc_active_realm, request, c_flags,\n                             &stkt_server, &status);\n    if (errcode)\n        goto cleanup;\n\n    if (isflagset(request->kdc_options, KDC_OPT_CNAME_IN_ADDL_TKT)) {\n        /* Do constrained delegation protocol and authorization checks */\n        errcode = kdc_process_s4u2proxy_req(kdc_active_realm,\n                                            request,\n                                            request->second_ticket[st_idx]->enc_part2,\n                                            stkt_server,\n                                            header_ticket->enc_part2->client,\n                                            request->server,\n                                            &status);\n        if (errcode == KDC_ERR_POLICY || errcode == KDC_ERR_BADOPTION)\n            au_state->violation = PROT_CONSTRAINT;\n        else if (errcode)\n            au_state->violation = LOCAL_POLICY;\n        au_state->status = status;\n        retval = kau_make_tkt_id(kdc_context, request->second_ticket[st_idx],\n                                  &au_state->evid_tkt_id);\n        if (retval) {\n            status = \"GENERATE_TICKET_ID\";\n            errcode = retval;\n            goto cleanup;\n        }\n        kau_s4u2proxy(kdc_context, errcode ? FALSE : TRUE, au_state);\n        if (errcode)\n            goto cleanup;\n\n        setflag(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION);\n\n        assert(krb5_is_tgs_principal(header_ticket->server));\n\n        assert(client == NULL); /* assured by kdc_process_s4u2self_req() */\n        client = stkt_server;\n        stkt_server = NULL;\n    } else if (request->kdc_options & KDC_OPT_ENC_TKT_IN_SKEY) {\n        krb5_db_free_principal(kdc_context, stkt_server);\n        stkt_server = NULL;\n    } else\n        assert(stkt_server == NULL);\n\n    au_state->stage = ISSUE_TKT;\n\n    errcode = gen_session_key(kdc_active_realm, request, server, &session_key,\n                              &status);\n    if (errcode)\n        goto cleanup;\n\n    /*\n     * subject_tkt will refer to the evidence ticket (for constrained\n     * delegation) or the TGT. The distinction from header_enc_tkt is\n     * necessary because the TGS signature only protects some fields:\n     * the others could be forged by a malicious server.\n     */\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION))\n        subject_tkt = request->second_ticket[st_idx]->enc_part2;\n    else\n        subject_tkt = header_enc_tkt;\n    authtime = subject_tkt->times.authtime;\n\n    /* Extract auth indicators from the subject ticket, except for S4U2Proxy\n     * requests (where the client didn't authenticate). */\n    if (s4u_x509_user == NULL) {\n        errcode = get_auth_indicators(kdc_context, subject_tkt, local_tgt,\n                                      &auth_indicators);\n        if (errcode) {\n            status = \"GET_AUTH_INDICATORS\";\n            goto cleanup;\n        }\n    }\n\n    errcode = check_indicators(kdc_context, server, auth_indicators);\n    if (errcode) {\n        status = \"HIGHER_AUTHENTICATION_REQUIRED\";\n        goto cleanup;\n    }\n\n    if (is_referral)\n        ticket_reply.server = server->princ;\n    else\n        ticket_reply.server = request->server; /* XXX careful for realm... */\n\n    enc_tkt_reply.flags = OPTS2FLAGS(request->kdc_options);\n    enc_tkt_reply.flags |= COPY_TKT_FLAGS(header_enc_tkt->flags);\n    enc_tkt_reply.times.starttime = 0;\n\n    if (isflagset(server->attributes, KRB5_KDB_OK_AS_DELEGATE))\n        setflag(enc_tkt_reply.flags, TKT_FLG_OK_AS_DELEGATE);\n\n    /* Indicate support for encrypted padata (RFC 6806). */\n    setflag(enc_tkt_reply.flags, TKT_FLG_ENC_PA_REP);\n\n    /* don't use new addresses unless forwarded, see below */\n\n    enc_tkt_reply.caddrs = header_enc_tkt->caddrs;\n    /* noaddrarray[0] = 0; */\n    reply_encpart.caddrs = 0;/* optional...don't put it in */\n    reply_encpart.enc_padata = NULL;\n\n    /*\n     * It should be noted that local policy may affect the\n     * processing of any of these flags.  For example, some\n     * realms may refuse to issue renewable tickets\n     */\n\n    if (isflagset(request->kdc_options, KDC_OPT_FORWARDABLE)) {\n\n        if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION)) {\n            /*\n             * If S4U2Self principal is not forwardable, then mark ticket as\n             * unforwardable. This behaviour matches Windows, but it is\n             * different to the MIT AS-REQ path, which returns an error\n             * (KDC_ERR_POLICY) if forwardable tickets cannot be issued.\n             *\n             * Consider this block the S4U2Self equivalent to\n             * validate_forwardable().\n             */\n            if (client != NULL &&\n                isflagset(client->attributes, KRB5_KDB_DISALLOW_FORWARDABLE))\n                clear(enc_tkt_reply.flags, TKT_FLG_FORWARDABLE);\n            /*\n             * Forwardable flag is propagated along referral path.\n             */\n            else if (!isflagset(header_enc_tkt->flags, TKT_FLG_FORWARDABLE))\n                clear(enc_tkt_reply.flags, TKT_FLG_FORWARDABLE);\n            /*\n             * OK_TO_AUTH_AS_DELEGATE must be set on the service requesting\n             * S4U2Self in order for forwardable tickets to be returned.\n             */\n            else if (!is_referral &&\n                     !isflagset(server->attributes,\n                                KRB5_KDB_OK_TO_AUTH_AS_DELEGATE))\n                clear(enc_tkt_reply.flags, TKT_FLG_FORWARDABLE);\n        }\n    }\n\n    if (isflagset(request->kdc_options, KDC_OPT_FORWARDED) ||\n        isflagset(request->kdc_options, KDC_OPT_PROXY)) {\n\n        /* include new addresses in ticket & reply */\n\n        enc_tkt_reply.caddrs = request->addresses;\n        reply_encpart.caddrs = request->addresses;\n    }\n    /* We don't currently handle issuing anonymous tickets based on\n     * non-anonymous ones, so just ignore the option. */\n    if (isflagset(request->kdc_options, KDC_OPT_REQUEST_ANONYMOUS) &&\n        !isflagset(header_enc_tkt->flags, TKT_FLG_ANONYMOUS))\n        clear(enc_tkt_reply.flags, TKT_FLG_ANONYMOUS);\n\n    if (isflagset(request->kdc_options, KDC_OPT_POSTDATED)) {\n        setflag(enc_tkt_reply.flags, TKT_FLG_INVALID);\n        enc_tkt_reply.times.starttime = request->from;\n    } else\n        enc_tkt_reply.times.starttime = kdc_time;\n\n    if (isflagset(request->kdc_options, KDC_OPT_VALIDATE)) {\n        assert(isflagset(c_flags, KRB5_KDB_FLAGS_S4U) == 0);\n        /* BEWARE of allocation hanging off of ticket & enc_part2, it belongs\n           to the caller */\n        ticket_reply = *(header_ticket);\n        enc_tkt_reply = *(header_ticket->enc_part2);\n        enc_tkt_reply.authorization_data = NULL;\n        clear(enc_tkt_reply.flags, TKT_FLG_INVALID);\n    }\n\n    if (isflagset(request->kdc_options, KDC_OPT_RENEW)) {\n        krb5_timestamp old_starttime;\n        krb5_deltat old_life;\n\n        assert(isflagset(c_flags, KRB5_KDB_FLAGS_S4U) == 0);\n        /* BEWARE of allocation hanging off of ticket & enc_part2, it belongs\n           to the caller */\n        ticket_reply = *(header_ticket);\n        enc_tkt_reply = *(header_ticket->enc_part2);\n        enc_tkt_reply.authorization_data = NULL;\n\n        old_starttime = enc_tkt_reply.times.starttime ?\n            enc_tkt_reply.times.starttime : enc_tkt_reply.times.authtime;\n        old_life = ts_delta(enc_tkt_reply.times.endtime, old_starttime);\n\n        enc_tkt_reply.times.starttime = kdc_time;\n        enc_tkt_reply.times.endtime =\n            ts_min(header_ticket->enc_part2->times.renew_till,\n                   ts_incr(kdc_time, old_life));\n    } else {\n        /* not a renew request */\n        enc_tkt_reply.times.starttime = kdc_time;\n\n        kdc_get_ticket_endtime(kdc_active_realm, enc_tkt_reply.times.starttime,\n                               header_enc_tkt->times.endtime, request->till,\n                               client, server, &enc_tkt_reply.times.endtime);\n    }\n\n    kdc_get_ticket_renewtime(kdc_active_realm, request, header_enc_tkt, client,\n                             server, &enc_tkt_reply);\n\n    /*\n     * Set authtime to be the same as header or evidence ticket's\n     */\n    enc_tkt_reply.times.authtime = authtime;\n\n    /* starttime is optional, and treated as authtime if not present.\n       so we can nuke it if it matches */\n    if (enc_tkt_reply.times.starttime == enc_tkt_reply.times.authtime)\n        enc_tkt_reply.times.starttime = 0;\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION)) {\n        altcprinc = s4u_x509_user->user_id.user;\n    } else if (isflagset(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION)) {\n        altcprinc = subject_tkt->client;\n    } else {\n        altcprinc = NULL;\n    }\n    if (isflagset(request->kdc_options, KDC_OPT_ENC_TKT_IN_SKEY)) {\n        krb5_enc_tkt_part *t2enc = request->second_ticket[st_idx]->enc_part2;\n        encrypting_key = *(t2enc->session);\n    } else {\n        /*\n         * Find the server key\n         */\n        if ((errcode = krb5_dbe_find_enctype(kdc_context, server,\n                                             -1, /* ignore keytype */\n                                             -1, /* Ignore salttype */\n                                             0,  /* Get highest kvno */\n                                             &server_key))) {\n            status = \"FINDING_SERVER_KEY\";\n            goto cleanup;\n        }\n\n        /*\n         * Convert server.key into a real key\n         * (it may be encrypted in the database)\n         */\n        if ((errcode = krb5_dbe_decrypt_key_data(kdc_context, NULL,\n                                                 server_key, &encrypting_key,\n                                                 NULL))) {\n            status = \"DECRYPT_SERVER_KEY\";\n            goto cleanup;\n        }\n    }\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_CONSTRAINED_DELEGATION)) {\n        /*\n         * Don't allow authorization data to be disabled if constrained\n         * delegation is requested. We don't want to deny the server\n         * the ability to validate that delegation was used.\n         */\n        clear(server->attributes, KRB5_KDB_NO_AUTH_DATA_REQUIRED);\n    }\n    if (isflagset(server->attributes, KRB5_KDB_NO_AUTH_DATA_REQUIRED) == 0) {\n        /*\n         * If we are not doing protocol transition/constrained delegation\n         * try to lookup the client principal so plugins can add additional\n         * authorization information.\n         *\n         * Always validate authorization data for constrained delegation\n         * because we must validate the KDC signatures.\n         */\n        if (!isflagset(c_flags, KRB5_KDB_FLAGS_S4U)) {\n            /* Generate authorization data so we can include it in ticket */\n            setflag(c_flags, KRB5_KDB_FLAG_INCLUDE_PAC);\n            /* Map principals from foreign (possibly non-AD) realms */\n            setflag(c_flags, KRB5_KDB_FLAG_MAP_PRINCIPALS);\n\n            assert(client == NULL); /* should not have been set already */\n\n            errcode = krb5_db_get_principal(kdc_context, subject_tkt->client,\n                                            c_flags, &client);\n        }\n    }\n\n    if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION) &&\n        !isflagset(c_flags, KRB5_KDB_FLAG_CROSS_REALM))\n        enc_tkt_reply.client = s4u_x509_user->user_id.user;\n    else\n        enc_tkt_reply.client = subject_tkt->client;\n\n    enc_tkt_reply.session = &session_key;\n    enc_tkt_reply.transited.tr_type = KRB5_DOMAIN_X500_COMPRESS;\n    enc_tkt_reply.transited.tr_contents = empty_string; /* equivalent of \"\" */\n\n    /*\n     * Only add the realm of the presented tgt to the transited list if\n     * it is different than the local realm (cross-realm) and it is different\n     * than the realm of the client (since the realm of the client is already\n     * implicitly part of the transited list and should not be explicitly\n     * listed).\n     */\n    /* realm compare is like strcmp, but knows how to deal with these args */\n    if (krb5_realm_compare(kdc_context, header_ticket->server, tgs_server) ||\n        krb5_realm_compare(kdc_context, header_ticket->server,\n                           enc_tkt_reply.client)) {\n        /* tgt issued by local realm or issued by realm of client */\n        enc_tkt_reply.transited = header_enc_tkt->transited;\n    } else {\n        /* tgt issued by some other realm and not the realm of the client */\n        /* assemble new transited field into allocated storage */\n        if (header_enc_tkt->transited.tr_type !=\n            KRB5_DOMAIN_X500_COMPRESS) {\n            status = \"VALIDATE_TRANSIT_TYPE\";\n            errcode = KRB5KDC_ERR_TRTYPE_NOSUPP;\n            goto cleanup;\n        }\n        memset(&enc_tkt_reply.transited, 0, sizeof(enc_tkt_reply.transited));\n        enc_tkt_reply.transited.tr_type = KRB5_DOMAIN_X500_COMPRESS;\n        if ((errcode =\n             add_to_transited(&header_enc_tkt->transited.tr_contents,\n                              &enc_tkt_reply.transited.tr_contents,\n                              header_ticket->server,\n                              enc_tkt_reply.client,\n                              request->server))) {\n            status = \"ADD_TO_TRANSITED_LIST\";\n            goto cleanup;\n        }\n        newtransited = 1;\n    }\n    if (isflagset(c_flags, KRB5_KDB_FLAG_CROSS_REALM)) {\n        errcode = validate_transit_path(kdc_context, header_enc_tkt->client,\n                                        server, header_server);\n        if (errcode) {\n            status = \"NON_TRANSITIVE\";\n            goto cleanup;\n        }\n    }\n    if (!isflagset (request->kdc_options, KDC_OPT_DISABLE_TRANSITED_CHECK)) {\n        errcode = kdc_check_transited_list (kdc_active_realm,\n                                            &enc_tkt_reply.transited.tr_contents,\n                                            krb5_princ_realm (kdc_context, header_enc_tkt->client),\n                                            krb5_princ_realm (kdc_context, request->server));\n        if (errcode == 0) {\n            setflag (enc_tkt_reply.flags, TKT_FLG_TRANSIT_POLICY_CHECKED);\n        } else {\n            log_tgs_badtrans(kdc_context, cprinc, sprinc,\n                             &enc_tkt_reply.transited.tr_contents, errcode);\n        }\n    } else\n        krb5_klog_syslog(LOG_INFO, _(\"not checking transit path\"));\n    if (kdc_active_realm->realm_reject_bad_transit &&\n        !isflagset(enc_tkt_reply.flags, TKT_FLG_TRANSIT_POLICY_CHECKED)) {\n        errcode = KRB5KDC_ERR_POLICY;\n        status = \"BAD_TRANSIT\";\n        au_state->violation = LOCAL_POLICY;\n        goto cleanup;\n    }\n\n    errcode = handle_authdata(kdc_context, c_flags, client, server,\n                              header_server, local_tgt,\n                              subkey != NULL ? subkey :\n                              header_ticket->enc_part2->session,\n                              &encrypting_key, /* U2U or server key */\n                              header_key,\n                              pkt,\n                              request,\n                              s4u_x509_user ?\n                              s4u_x509_user->user_id.user : NULL,\n                              subject_tkt,\n                              auth_indicators,\n                              &enc_tkt_reply);\n    if (errcode) {\n        krb5_klog_syslog(LOG_INFO, _(\"TGS_REQ : handle_authdata (%d)\"),\n                         errcode);\n        status = \"HANDLE_AUTHDATA\";\n        goto cleanup;\n    }\n\n    ticket_reply.enc_part2 = &enc_tkt_reply;\n\n    /*\n     * If we are doing user-to-user authentication, then make sure\n     * that the client for the second ticket matches the request\n     * server, and then encrypt the ticket using the session key of\n     * the second ticket.\n     */\n    if (isflagset(request->kdc_options, KDC_OPT_ENC_TKT_IN_SKEY)) {\n        /*\n         * Make sure the client for the second ticket matches\n         * requested server.\n         */\n        krb5_enc_tkt_part *t2enc = request->second_ticket[st_idx]->enc_part2;\n        krb5_principal client2 = t2enc->client;\n        if (!krb5_principal_compare(kdc_context, request->server, client2)) {\n            altcprinc = client2;\n            errcode = KRB5KDC_ERR_SERVER_NOMATCH;\n            status = \"2ND_TKT_MISMATCH\";\n            au_state->status = status;\n            kau_u2u(kdc_context, FALSE, au_state);\n            goto cleanup;\n        }\n\n        ticket_kvno = 0;\n        ticket_reply.enc_part.enctype = t2enc->session->enctype;\n        kau_u2u(kdc_context, TRUE, au_state);\n        st_idx++;\n    } else {\n        ticket_kvno = server_key->key_data_kvno;\n    }\n\n    errcode = krb5_encrypt_tkt_part(kdc_context, &encrypting_key,\n                                    &ticket_reply);\n    if (!isflagset(request->kdc_options, KDC_OPT_ENC_TKT_IN_SKEY))\n        krb5_free_keyblock_contents(kdc_context, &encrypting_key);\n    if (errcode) {\n        status = \"ENCRYPT_TICKET\";\n        goto cleanup;\n    }\n    ticket_reply.enc_part.kvno = ticket_kvno;\n    /* Start assembling the response */\n    au_state->stage = ENCR_REP;\n    reply.msg_type = KRB5_TGS_REP;\n    if (isflagset(c_flags, KRB5_KDB_FLAG_PROTOCOL_TRANSITION) &&\n        krb5int_find_pa_data(kdc_context, request->padata,\n                             KRB5_PADATA_S4U_X509_USER) != NULL) {\n        errcode = kdc_make_s4u2self_rep(kdc_context,\n                                        subkey,\n                                        header_ticket->enc_part2->session,\n                                        s4u_x509_user,\n                                        &reply,\n                                        &reply_encpart);\n        if (errcode) {\n            status = \"MAKE_S4U2SELF_PADATA\";\n            au_state->status = status;\n        }\n        kau_s4u2self(kdc_context, errcode ? FALSE : TRUE, au_state);\n        if (errcode)\n            goto cleanup;\n    }\n\n    reply.client = enc_tkt_reply.client;\n    reply.enc_part.kvno = 0;/* We are using the session key */\n    reply.ticket = &ticket_reply;\n\n    reply_encpart.session = &session_key;\n    reply_encpart.nonce = request->nonce;\n\n    /* copy the time fields */\n    reply_encpart.times = enc_tkt_reply.times;\n\n    nolrentry.lr_type = KRB5_LRQ_NONE;\n    nolrentry.value = 0;\n    nolrentry.magic = 0;\n    nolrarray[0] = &nolrentry;\n    nolrarray[1] = 0;\n    reply_encpart.last_req = nolrarray;        /* not available for TGS reqs */\n    reply_encpart.key_exp = 0;/* ditto */\n    reply_encpart.flags = enc_tkt_reply.flags;\n    reply_encpart.server = ticket_reply.server;\n\n    /* use the session key in the ticket, unless there's a subsession key\n       in the AP_REQ */\n    reply.enc_part.enctype = subkey ? subkey->enctype :\n        header_ticket->enc_part2->session->enctype;\n    errcode  = kdc_fast_response_handle_padata(state, request, &reply,\n                                               subkey ? subkey->enctype : header_ticket->enc_part2->session->enctype);\n    if (errcode !=0 ) {\n        status = \"MAKE_FAST_RESPONSE\";\n        goto cleanup;\n    }\n    errcode =kdc_fast_handle_reply_key(state,\n                                       subkey?subkey:header_ticket->enc_part2->session, &reply_key);\n    if (errcode) {\n        status  = \"MAKE_FAST_REPLY_KEY\";\n        goto cleanup;\n    }\n    errcode = return_enc_padata(kdc_context, pkt, request,\n                                reply_key, server, &reply_encpart,\n                                is_referral &&\n                                isflagset(s_flags,\n                                          KRB5_KDB_FLAG_CANONICALIZE));\n    if (errcode) {\n        status = \"KDC_RETURN_ENC_PADATA\";\n        goto cleanup;\n    }\n\n    errcode = kau_make_tkt_id(kdc_context, &ticket_reply, &au_state->tkt_out_id);\n    if (errcode) {\n        status = \"GENERATE_TICKET_ID\";\n        goto cleanup;\n    }\n\n    if (kdc_fast_hide_client(state))\n        reply.client = (krb5_principal)krb5_anonymous_principal();\n    errcode = krb5_encode_kdc_rep(kdc_context, KRB5_TGS_REP, &reply_encpart,\n                                  subkey ? 1 : 0,\n                                  reply_key,\n                                  &reply, response);\n    if (errcode) {\n        status = \"ENCODE_KDC_REP\";\n    } else {\n        status = \"ISSUE\";\n    }\n\n    memset(ticket_reply.enc_part.ciphertext.data, 0,\n           ticket_reply.enc_part.ciphertext.length);\n    free(ticket_reply.enc_part.ciphertext.data);\n    /* these parts are left on as a courtesy from krb5_encode_kdc_rep so we\n       can use them in raw form if needed.  But, we don't... */\n    memset(reply.enc_part.ciphertext.data, 0,\n           reply.enc_part.ciphertext.length);\n    free(reply.enc_part.ciphertext.data);\n\ncleanup:\n    if (status == NULL)\n        status = \"UNKNOWN_REASON\";\n    if (reply_key)\n        krb5_free_keyblock(kdc_context, reply_key);\n    if (errcode)\n        emsg = krb5_get_error_message (kdc_context, errcode);\n\n    au_state->status = status;\n    if (!errcode)\n        au_state->reply = &reply;\n    kau_tgs_req(kdc_context, errcode ? FALSE : TRUE, au_state);\n    kau_free_kdc_req(au_state);\n\n    log_tgs_req(kdc_context, from, request, &reply, cprinc,\n                sprinc, altcprinc, authtime,\n                c_flags, status, errcode, emsg);\n    if (errcode) {\n        krb5_free_error_message (kdc_context, emsg);\n        emsg = NULL;\n    }\n\n    if (errcode) {\n        int got_err = 0;\n        if (status == 0) {\n            status = krb5_get_error_message (kdc_context, errcode);\n            got_err = 1;\n        }\n        errcode -= ERROR_TABLE_BASE_krb5;\n        if (errcode < 0 || errcode > KRB_ERR_MAX)\n            errcode = KRB_ERR_GENERIC;\n\n        retval = prepare_error_tgs(state, request, header_ticket, errcode,\n                                   (server != NULL) ? server->princ : NULL,\n                                   response, status, e_data);\n        if (got_err) {\n            krb5_free_error_message (kdc_context, status);\n            status = 0;\n        }\n    }\n\n    if (header_ticket != NULL)\n        krb5_free_ticket(kdc_context, header_ticket);\n    if (request != NULL)\n        krb5_free_kdc_req(kdc_context, request);\n    if (state)\n        kdc_free_rstate(state);\n    krb5_db_free_principal(kdc_context, server);\n    krb5_db_free_principal(kdc_context, stkt_server);\n    krb5_db_free_principal(kdc_context, header_server);\n    krb5_db_free_principal(kdc_context, client);\n    krb5_db_free_principal(kdc_context, local_tgt_storage);\n    if (session_key.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &session_key);\n    if (newtransited)\n        free(enc_tkt_reply.transited.tr_contents.data);\n    if (s4u_x509_user != NULL)\n        krb5_free_pa_s4u_x509_user(kdc_context, s4u_x509_user);\n    if (kdc_issued_auth_data != NULL)\n        krb5_free_authdata(kdc_context, kdc_issued_auth_data);\n    if (subkey != NULL)\n        krb5_free_keyblock(kdc_context, subkey);\n    if (header_key != NULL)\n        krb5_free_keyblock(kdc_context, header_key);\n    if (reply.padata)\n        krb5_free_pa_data(kdc_context, reply.padata);\n    if (reply_encpart.enc_padata)\n        krb5_free_pa_data(kdc_context, reply_encpart.enc_padata);\n    if (enc_tkt_reply.authorization_data != NULL)\n        krb5_free_authdata(kdc_context, enc_tkt_reply.authorization_data);\n    krb5_free_pa_data(kdc_context, e_data);\n    k5_free_data_ptr_list(auth_indicators);\n\n    return retval;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -724,7 +724,8 @@\n     free(reply.enc_part.ciphertext.data);\n \n cleanup:\n-    assert(status != NULL);\n+    if (status == NULL)\n+        status = \"UNKNOWN_REASON\";\n     if (reply_key)\n         krb5_free_keyblock(kdc_context, reply_key);\n     if (errcode)",
        "diff_line_info": {
            "deleted_lines": [
                "    assert(status != NULL);"
            ],
            "added_lines": [
                "    if (status == NULL)",
                "        status = \"UNKNOWN_REASON\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11368",
        "func_name": "krb5/finish_process_as_req",
        "description": "In MIT Kerberos 5 (aka krb5) 1.7 and later, an authenticated attacker can cause a KDC assertion failure by sending invalid S4U2Self or S4U2Proxy requests.",
        "git_url": "https://github.com/krb5/krb5/commit/ffb35baac6981f9e8914f8f3bffd37f284b85970",
        "commit_title": "Prevent KDC unset status assertion failures",
        "commit_text": " Assign status values if S4U2Self padata fails to decode, if an S4U2Proxy request uses invalid KDC options, or if an S4U2Proxy request uses an evidence ticket which does not match the canonicalized request server principal name.  Reported by Samuel Cabrero.  If a status value is not assigned during KDC processing, default to \"UNKNOWN_REASON\" rather than failing an assertion.  This change will prevent future denial of service bugs due to similar mistakes, and will allow us to omit assigning status values for unlikely errors such as small memory allocation failures.  CVE-2017-11368:  In MIT krb5 1.7 and later, an authenticated attacker can cause an assertion failure in krb5kdc by sending an invalid S4U2Self or S4U2Proxy request.    CVSSv3 Vector: AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:H/RL:O/RC:C  ticket: 8599 (new) target_version: 1.15-next target_version: 1.14-next tags: pullup",
        "func_before": "static void\nfinish_process_as_req(struct as_req_state *state, krb5_error_code errcode)\n{\n    krb5_key_data *server_key;\n    krb5_keyblock *as_encrypting_key = NULL;\n    krb5_data *response = NULL;\n    const char *emsg = 0;\n    int did_log = 0;\n    loop_respond_fn oldrespond;\n    void *oldarg;\n    kdc_realm_t *kdc_active_realm = state->active_realm;\n    krb5_audit_state *au_state = state->au_state;\n\n    assert(state);\n    oldrespond = state->respond;\n    oldarg = state->arg;\n\n    if (errcode)\n        goto egress;\n\n    au_state->stage = ENCR_REP;\n\n    if ((errcode = validate_forwardable(state->request, *state->client,\n                                        *state->server, state->kdc_time,\n                                        &state->status))) {\n        errcode += ERROR_TABLE_BASE_krb5;\n        goto egress;\n    }\n\n    errcode = check_indicators(kdc_context, state->server,\n                               state->auth_indicators);\n    if (errcode) {\n        state->status = \"HIGHER_AUTHENTICATION_REQUIRED\";\n        goto egress;\n    }\n\n    state->ticket_reply.enc_part2 = &state->enc_tkt_reply;\n\n    /*\n     * Find the server key\n     */\n    if ((errcode = krb5_dbe_find_enctype(kdc_context, state->server,\n                                         -1, /* ignore keytype   */\n                                         -1, /* Ignore salttype  */\n                                         0,  /* Get highest kvno */\n                                         &server_key))) {\n        state->status = \"FINDING_SERVER_KEY\";\n        goto egress;\n    }\n\n    /*\n     * Convert server->key into a real key\n     * (it may be encrypted in the database)\n     *\n     *  server_keyblock is later used to generate auth data signatures\n     */\n    if ((errcode = krb5_dbe_decrypt_key_data(kdc_context, NULL,\n                                             server_key,\n                                             &state->server_keyblock,\n                                             NULL))) {\n        state->status = \"DECRYPT_SERVER_KEY\";\n        goto egress;\n    }\n\n    /* Start assembling the response */\n    state->reply.msg_type = KRB5_AS_REP;\n    state->reply.client = state->enc_tkt_reply.client; /* post canonization */\n    state->reply.ticket = &state->ticket_reply;\n    state->reply_encpart.session = &state->session_key;\n    if ((errcode = fetch_last_req_info(state->client,\n                                       &state->reply_encpart.last_req))) {\n        state->status = \"FETCH_LAST_REQ\";\n        goto egress;\n    }\n    state->reply_encpart.nonce = state->request->nonce;\n    state->reply_encpart.key_exp = get_key_exp(state->client);\n    state->reply_encpart.flags = state->enc_tkt_reply.flags;\n    state->reply_encpart.server = state->ticket_reply.server;\n\n    /* copy the time fields EXCEPT for authtime; it's location\n     *  is used for ktime\n     */\n    state->reply_encpart.times = state->enc_tkt_reply.times;\n    state->reply_encpart.times.authtime = state->authtime = state->kdc_time;\n\n    state->reply_encpart.caddrs = state->enc_tkt_reply.caddrs;\n    state->reply_encpart.enc_padata = NULL;\n\n    /* Fetch the padata info to be returned (do this before\n     *  authdata to handle possible replacement of reply key\n     */\n    errcode = return_padata(kdc_context, &state->rock, state->req_pkt,\n                            state->request, &state->reply,\n                            &state->client_keyblock, &state->pa_context);\n    if (errcode) {\n        state->status = \"KDC_RETURN_PADATA\";\n        goto egress;\n    }\n\n    /* If we didn't find a client long-term key and no preauth mechanism\n     * replaced the reply key, error out now. */\n    if (state->client_keyblock.enctype == ENCTYPE_NULL) {\n        state->status = \"CANT_FIND_CLIENT_KEY\";\n        errcode = KRB5KDC_ERR_ETYPE_NOSUPP;\n        goto egress;\n    }\n\n    errcode = handle_authdata(kdc_context,\n                              state->c_flags,\n                              state->client,\n                              state->server,\n                              NULL,\n                              state->local_tgt,\n                              &state->client_keyblock,\n                              &state->server_keyblock,\n                              NULL,\n                              state->req_pkt,\n                              state->request,\n                              NULL, /* for_user_princ */\n                              NULL, /* enc_tkt_request */\n                              state->auth_indicators,\n                              &state->enc_tkt_reply);\n    if (errcode) {\n        krb5_klog_syslog(LOG_INFO, _(\"AS_REQ : handle_authdata (%d)\"),\n                         errcode);\n        state->status = \"HANDLE_AUTHDATA\";\n        goto egress;\n    }\n\n    errcode = krb5_encrypt_tkt_part(kdc_context, &state->server_keyblock,\n                                    &state->ticket_reply);\n    if (errcode) {\n        state->status = \"ENCRYPT_TICKET\";\n        goto egress;\n    }\n\n    errcode = kau_make_tkt_id(kdc_context, &state->ticket_reply,\n                              &au_state->tkt_out_id);\n    if (errcode) {\n        state->status = \"GENERATE_TICKET_ID\";\n        goto egress;\n    }\n\n    state->ticket_reply.enc_part.kvno = server_key->key_data_kvno;\n    errcode = kdc_fast_response_handle_padata(state->rstate,\n                                              state->request,\n                                              &state->reply,\n                                              state->client_keyblock.enctype);\n    if (errcode) {\n        state->status = \"MAKE_FAST_RESPONSE\";\n        goto egress;\n    }\n\n    /* now encode/encrypt the response */\n\n    state->reply.enc_part.enctype = state->client_keyblock.enctype;\n\n    errcode = kdc_fast_handle_reply_key(state->rstate, &state->client_keyblock,\n                                        &as_encrypting_key);\n    if (errcode) {\n        state->status = \"MAKE_FAST_REPLY_KEY\";\n        goto egress;\n    }\n    errcode = return_enc_padata(kdc_context, state->req_pkt, state->request,\n                                as_encrypting_key, state->server,\n                                &state->reply_encpart, FALSE);\n    if (errcode) {\n        state->status = \"KDC_RETURN_ENC_PADATA\";\n        goto egress;\n    }\n\n    if (kdc_fast_hide_client(state->rstate))\n        state->reply.client = (krb5_principal)krb5_anonymous_principal();\n    errcode = krb5_encode_kdc_rep(kdc_context, KRB5_AS_REP,\n                                  &state->reply_encpart, 0,\n                                  as_encrypting_key,\n                                  &state->reply, &response);\n    if (state->client_key != NULL)\n        state->reply.enc_part.kvno = state->client_key->key_data_kvno;\n    if (errcode) {\n        state->status = \"ENCODE_KDC_REP\";\n        goto egress;\n    }\n\n    /* these parts are left on as a courtesy from krb5_encode_kdc_rep so we\n       can use them in raw form if needed.  But, we don't... */\n    memset(state->reply.enc_part.ciphertext.data, 0,\n           state->reply.enc_part.ciphertext.length);\n    free(state->reply.enc_part.ciphertext.data);\n\n    log_as_req(kdc_context, state->local_addr, state->remote_addr,\n               state->request, &state->reply, state->client, state->cname,\n               state->server, state->sname, state->authtime, 0, 0, 0);\n    did_log = 1;\n\negress:\n    if (errcode != 0)\n        assert (state->status != 0);\n\n    au_state->status = state->status;\n    au_state->reply = &state->reply;\n    kau_as_req(kdc_context,\n              (errcode || state->preauth_err) ? FALSE : TRUE, au_state);\n    kau_free_kdc_req(au_state);\n\n    free_padata_context(kdc_context, state->pa_context);\n    if (as_encrypting_key)\n        krb5_free_keyblock(kdc_context, as_encrypting_key);\n    if (errcode)\n        emsg = krb5_get_error_message(kdc_context, errcode);\n\n    if (state->status) {\n        log_as_req(kdc_context, state->local_addr, state->remote_addr,\n                   state->request, &state->reply, state->client,\n                   state->cname, state->server, state->sname, state->authtime,\n                   state->status, errcode, emsg);\n        did_log = 1;\n    }\n    if (errcode) {\n        if (state->status == 0) {\n            state->status = emsg;\n        }\n        if (errcode != KRB5KDC_ERR_DISCARD) {\n            errcode -= ERROR_TABLE_BASE_krb5;\n            if (errcode < 0 || errcode > KRB_ERR_MAX)\n                errcode = KRB_ERR_GENERIC;\n\n            errcode = prepare_error_as(state->rstate, state->request,\n                                       state->local_tgt, errcode,\n                                       state->e_data, state->typed_e_data,\n                                       ((state->client != NULL) ?\n                                        state->client->princ : NULL),\n                                       &response, state->status);\n            state->status = 0;\n        }\n    }\n\n    if (emsg)\n        krb5_free_error_message(kdc_context, emsg);\n    if (state->enc_tkt_reply.authorization_data != NULL)\n        krb5_free_authdata(kdc_context,\n                           state->enc_tkt_reply.authorization_data);\n    if (state->server_keyblock.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &state->server_keyblock);\n    if (state->client_keyblock.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &state->client_keyblock);\n    if (state->reply.padata != NULL)\n        krb5_free_pa_data(kdc_context, state->reply.padata);\n    if (state->reply_encpart.enc_padata)\n        krb5_free_pa_data(kdc_context, state->reply_encpart.enc_padata);\n\n    if (state->cname != NULL)\n        free(state->cname);\n    if (state->sname != NULL)\n        free(state->sname);\n    krb5_db_free_principal(kdc_context, state->client);\n    krb5_db_free_principal(kdc_context, state->server);\n    krb5_db_free_principal(kdc_context, state->local_tgt_storage);\n    if (state->session_key.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &state->session_key);\n    if (state->ticket_reply.enc_part.ciphertext.data != NULL) {\n        memset(state->ticket_reply.enc_part.ciphertext.data , 0,\n               state->ticket_reply.enc_part.ciphertext.length);\n        free(state->ticket_reply.enc_part.ciphertext.data);\n    }\n\n    krb5_free_pa_data(kdc_context, state->e_data);\n    krb5_free_data(kdc_context, state->inner_body);\n    kdc_free_rstate(state->rstate);\n    krb5_free_kdc_req(kdc_context, state->request);\n    k5_free_data_ptr_list(state->auth_indicators);\n    assert(did_log != 0);\n\n    free(state);\n    (*oldrespond)(oldarg, errcode, response);\n}",
        "func": "static void\nfinish_process_as_req(struct as_req_state *state, krb5_error_code errcode)\n{\n    krb5_key_data *server_key;\n    krb5_keyblock *as_encrypting_key = NULL;\n    krb5_data *response = NULL;\n    const char *emsg = 0;\n    int did_log = 0;\n    loop_respond_fn oldrespond;\n    void *oldarg;\n    kdc_realm_t *kdc_active_realm = state->active_realm;\n    krb5_audit_state *au_state = state->au_state;\n\n    assert(state);\n    oldrespond = state->respond;\n    oldarg = state->arg;\n\n    if (errcode)\n        goto egress;\n\n    au_state->stage = ENCR_REP;\n\n    if ((errcode = validate_forwardable(state->request, *state->client,\n                                        *state->server, state->kdc_time,\n                                        &state->status))) {\n        errcode += ERROR_TABLE_BASE_krb5;\n        goto egress;\n    }\n\n    errcode = check_indicators(kdc_context, state->server,\n                               state->auth_indicators);\n    if (errcode) {\n        state->status = \"HIGHER_AUTHENTICATION_REQUIRED\";\n        goto egress;\n    }\n\n    state->ticket_reply.enc_part2 = &state->enc_tkt_reply;\n\n    /*\n     * Find the server key\n     */\n    if ((errcode = krb5_dbe_find_enctype(kdc_context, state->server,\n                                         -1, /* ignore keytype   */\n                                         -1, /* Ignore salttype  */\n                                         0,  /* Get highest kvno */\n                                         &server_key))) {\n        state->status = \"FINDING_SERVER_KEY\";\n        goto egress;\n    }\n\n    /*\n     * Convert server->key into a real key\n     * (it may be encrypted in the database)\n     *\n     *  server_keyblock is later used to generate auth data signatures\n     */\n    if ((errcode = krb5_dbe_decrypt_key_data(kdc_context, NULL,\n                                             server_key,\n                                             &state->server_keyblock,\n                                             NULL))) {\n        state->status = \"DECRYPT_SERVER_KEY\";\n        goto egress;\n    }\n\n    /* Start assembling the response */\n    state->reply.msg_type = KRB5_AS_REP;\n    state->reply.client = state->enc_tkt_reply.client; /* post canonization */\n    state->reply.ticket = &state->ticket_reply;\n    state->reply_encpart.session = &state->session_key;\n    if ((errcode = fetch_last_req_info(state->client,\n                                       &state->reply_encpart.last_req))) {\n        state->status = \"FETCH_LAST_REQ\";\n        goto egress;\n    }\n    state->reply_encpart.nonce = state->request->nonce;\n    state->reply_encpart.key_exp = get_key_exp(state->client);\n    state->reply_encpart.flags = state->enc_tkt_reply.flags;\n    state->reply_encpart.server = state->ticket_reply.server;\n\n    /* copy the time fields EXCEPT for authtime; it's location\n     *  is used for ktime\n     */\n    state->reply_encpart.times = state->enc_tkt_reply.times;\n    state->reply_encpart.times.authtime = state->authtime = state->kdc_time;\n\n    state->reply_encpart.caddrs = state->enc_tkt_reply.caddrs;\n    state->reply_encpart.enc_padata = NULL;\n\n    /* Fetch the padata info to be returned (do this before\n     *  authdata to handle possible replacement of reply key\n     */\n    errcode = return_padata(kdc_context, &state->rock, state->req_pkt,\n                            state->request, &state->reply,\n                            &state->client_keyblock, &state->pa_context);\n    if (errcode) {\n        state->status = \"KDC_RETURN_PADATA\";\n        goto egress;\n    }\n\n    /* If we didn't find a client long-term key and no preauth mechanism\n     * replaced the reply key, error out now. */\n    if (state->client_keyblock.enctype == ENCTYPE_NULL) {\n        state->status = \"CANT_FIND_CLIENT_KEY\";\n        errcode = KRB5KDC_ERR_ETYPE_NOSUPP;\n        goto egress;\n    }\n\n    errcode = handle_authdata(kdc_context,\n                              state->c_flags,\n                              state->client,\n                              state->server,\n                              NULL,\n                              state->local_tgt,\n                              &state->client_keyblock,\n                              &state->server_keyblock,\n                              NULL,\n                              state->req_pkt,\n                              state->request,\n                              NULL, /* for_user_princ */\n                              NULL, /* enc_tkt_request */\n                              state->auth_indicators,\n                              &state->enc_tkt_reply);\n    if (errcode) {\n        krb5_klog_syslog(LOG_INFO, _(\"AS_REQ : handle_authdata (%d)\"),\n                         errcode);\n        state->status = \"HANDLE_AUTHDATA\";\n        goto egress;\n    }\n\n    errcode = krb5_encrypt_tkt_part(kdc_context, &state->server_keyblock,\n                                    &state->ticket_reply);\n    if (errcode) {\n        state->status = \"ENCRYPT_TICKET\";\n        goto egress;\n    }\n\n    errcode = kau_make_tkt_id(kdc_context, &state->ticket_reply,\n                              &au_state->tkt_out_id);\n    if (errcode) {\n        state->status = \"GENERATE_TICKET_ID\";\n        goto egress;\n    }\n\n    state->ticket_reply.enc_part.kvno = server_key->key_data_kvno;\n    errcode = kdc_fast_response_handle_padata(state->rstate,\n                                              state->request,\n                                              &state->reply,\n                                              state->client_keyblock.enctype);\n    if (errcode) {\n        state->status = \"MAKE_FAST_RESPONSE\";\n        goto egress;\n    }\n\n    /* now encode/encrypt the response */\n\n    state->reply.enc_part.enctype = state->client_keyblock.enctype;\n\n    errcode = kdc_fast_handle_reply_key(state->rstate, &state->client_keyblock,\n                                        &as_encrypting_key);\n    if (errcode) {\n        state->status = \"MAKE_FAST_REPLY_KEY\";\n        goto egress;\n    }\n    errcode = return_enc_padata(kdc_context, state->req_pkt, state->request,\n                                as_encrypting_key, state->server,\n                                &state->reply_encpart, FALSE);\n    if (errcode) {\n        state->status = \"KDC_RETURN_ENC_PADATA\";\n        goto egress;\n    }\n\n    if (kdc_fast_hide_client(state->rstate))\n        state->reply.client = (krb5_principal)krb5_anonymous_principal();\n    errcode = krb5_encode_kdc_rep(kdc_context, KRB5_AS_REP,\n                                  &state->reply_encpart, 0,\n                                  as_encrypting_key,\n                                  &state->reply, &response);\n    if (state->client_key != NULL)\n        state->reply.enc_part.kvno = state->client_key->key_data_kvno;\n    if (errcode) {\n        state->status = \"ENCODE_KDC_REP\";\n        goto egress;\n    }\n\n    /* these parts are left on as a courtesy from krb5_encode_kdc_rep so we\n       can use them in raw form if needed.  But, we don't... */\n    memset(state->reply.enc_part.ciphertext.data, 0,\n           state->reply.enc_part.ciphertext.length);\n    free(state->reply.enc_part.ciphertext.data);\n\n    log_as_req(kdc_context, state->local_addr, state->remote_addr,\n               state->request, &state->reply, state->client, state->cname,\n               state->server, state->sname, state->authtime, 0, 0, 0);\n    did_log = 1;\n\negress:\n    if (errcode != 0 && state->status == NULL)\n        state->status = \"UNKNOWN_REASON\";\n\n    au_state->status = state->status;\n    au_state->reply = &state->reply;\n    kau_as_req(kdc_context,\n              (errcode || state->preauth_err) ? FALSE : TRUE, au_state);\n    kau_free_kdc_req(au_state);\n\n    free_padata_context(kdc_context, state->pa_context);\n    if (as_encrypting_key)\n        krb5_free_keyblock(kdc_context, as_encrypting_key);\n    if (errcode)\n        emsg = krb5_get_error_message(kdc_context, errcode);\n\n    if (state->status) {\n        log_as_req(kdc_context, state->local_addr, state->remote_addr,\n                   state->request, &state->reply, state->client,\n                   state->cname, state->server, state->sname, state->authtime,\n                   state->status, errcode, emsg);\n        did_log = 1;\n    }\n    if (errcode) {\n        if (state->status == 0) {\n            state->status = emsg;\n        }\n        if (errcode != KRB5KDC_ERR_DISCARD) {\n            errcode -= ERROR_TABLE_BASE_krb5;\n            if (errcode < 0 || errcode > KRB_ERR_MAX)\n                errcode = KRB_ERR_GENERIC;\n\n            errcode = prepare_error_as(state->rstate, state->request,\n                                       state->local_tgt, errcode,\n                                       state->e_data, state->typed_e_data,\n                                       ((state->client != NULL) ?\n                                        state->client->princ : NULL),\n                                       &response, state->status);\n            state->status = 0;\n        }\n    }\n\n    if (emsg)\n        krb5_free_error_message(kdc_context, emsg);\n    if (state->enc_tkt_reply.authorization_data != NULL)\n        krb5_free_authdata(kdc_context,\n                           state->enc_tkt_reply.authorization_data);\n    if (state->server_keyblock.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &state->server_keyblock);\n    if (state->client_keyblock.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &state->client_keyblock);\n    if (state->reply.padata != NULL)\n        krb5_free_pa_data(kdc_context, state->reply.padata);\n    if (state->reply_encpart.enc_padata)\n        krb5_free_pa_data(kdc_context, state->reply_encpart.enc_padata);\n\n    if (state->cname != NULL)\n        free(state->cname);\n    if (state->sname != NULL)\n        free(state->sname);\n    krb5_db_free_principal(kdc_context, state->client);\n    krb5_db_free_principal(kdc_context, state->server);\n    krb5_db_free_principal(kdc_context, state->local_tgt_storage);\n    if (state->session_key.contents != NULL)\n        krb5_free_keyblock_contents(kdc_context, &state->session_key);\n    if (state->ticket_reply.enc_part.ciphertext.data != NULL) {\n        memset(state->ticket_reply.enc_part.ciphertext.data , 0,\n               state->ticket_reply.enc_part.ciphertext.length);\n        free(state->ticket_reply.enc_part.ciphertext.data);\n    }\n\n    krb5_free_pa_data(kdc_context, state->e_data);\n    krb5_free_data(kdc_context, state->inner_body);\n    kdc_free_rstate(state->rstate);\n    krb5_free_kdc_req(kdc_context, state->request);\n    k5_free_data_ptr_list(state->auth_indicators);\n    assert(did_log != 0);\n\n    free(state);\n    (*oldrespond)(oldarg, errcode, response);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -194,8 +194,8 @@\n     did_log = 1;\n \n egress:\n-    if (errcode != 0)\n-        assert (state->status != 0);\n+    if (errcode != 0 && state->status == NULL)\n+        state->status = \"UNKNOWN_REASON\";\n \n     au_state->status = state->status;\n     au_state->reply = &state->reply;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (errcode != 0)",
                "        assert (state->status != 0);"
            ],
            "added_lines": [
                "    if (errcode != 0 && state->status == NULL)",
                "        state->status = \"UNKNOWN_REASON\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11368",
        "func_name": "krb5/kdc_process_s4u_x509_user",
        "description": "In MIT Kerberos 5 (aka krb5) 1.7 and later, an authenticated attacker can cause a KDC assertion failure by sending invalid S4U2Self or S4U2Proxy requests.",
        "git_url": "https://github.com/krb5/krb5/commit/ffb35baac6981f9e8914f8f3bffd37f284b85970",
        "commit_title": "Prevent KDC unset status assertion failures",
        "commit_text": " Assign status values if S4U2Self padata fails to decode, if an S4U2Proxy request uses invalid KDC options, or if an S4U2Proxy request uses an evidence ticket which does not match the canonicalized request server principal name.  Reported by Samuel Cabrero.  If a status value is not assigned during KDC processing, default to \"UNKNOWN_REASON\" rather than failing an assertion.  This change will prevent future denial of service bugs due to similar mistakes, and will allow us to omit assigning status values for unlikely errors such as small memory allocation failures.  CVE-2017-11368:  In MIT krb5 1.7 and later, an authenticated attacker can cause an assertion failure in krb5kdc by sending an invalid S4U2Self or S4U2Proxy request.    CVSSv3 Vector: AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:H/RL:O/RC:C  ticket: 8599 (new) target_version: 1.15-next target_version: 1.14-next tags: pullup",
        "func_before": "static krb5_error_code\nkdc_process_s4u_x509_user(krb5_context context,\n                          krb5_kdc_req *request,\n                          krb5_pa_data *pa_data,\n                          krb5_keyblock *tgs_subkey,\n                          krb5_keyblock *tgs_session,\n                          krb5_pa_s4u_x509_user **s4u_x509_user,\n                          const char **status)\n{\n    krb5_error_code             code;\n    krb5_data                   req_data;\n\n    req_data.length = pa_data->length;\n    req_data.data = (char *)pa_data->contents;\n\n    code = decode_krb5_pa_s4u_x509_user(&req_data, s4u_x509_user);\n    if (code)\n        return code;\n\n    code = verify_s4u_x509_user_checksum(context,\n                                         tgs_subkey ? tgs_subkey :\n                                         tgs_session,\n                                         &req_data,\n                                         request->nonce, *s4u_x509_user);\n\n    if (code) {\n        *status = \"INVALID_S4U2SELF_CHECKSUM\";\n        krb5_free_pa_s4u_x509_user(context, *s4u_x509_user);\n        *s4u_x509_user = NULL;\n        return code;\n    }\n\n    if (krb5_princ_size(context, (*s4u_x509_user)->user_id.user) == 0 ||\n        (*s4u_x509_user)->user_id.subject_cert.length != 0) {\n        *status = \"INVALID_S4U2SELF_REQUEST\";\n        krb5_free_pa_s4u_x509_user(context, *s4u_x509_user);\n        *s4u_x509_user = NULL;\n        return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n    }\n\n    return 0;\n}",
        "func": "static krb5_error_code\nkdc_process_s4u_x509_user(krb5_context context,\n                          krb5_kdc_req *request,\n                          krb5_pa_data *pa_data,\n                          krb5_keyblock *tgs_subkey,\n                          krb5_keyblock *tgs_session,\n                          krb5_pa_s4u_x509_user **s4u_x509_user,\n                          const char **status)\n{\n    krb5_error_code             code;\n    krb5_data                   req_data;\n\n    req_data.length = pa_data->length;\n    req_data.data = (char *)pa_data->contents;\n\n    code = decode_krb5_pa_s4u_x509_user(&req_data, s4u_x509_user);\n    if (code) {\n        *status = \"DECODE_PA_S4U_X509_USER\";\n        return code;\n    }\n\n    code = verify_s4u_x509_user_checksum(context,\n                                         tgs_subkey ? tgs_subkey :\n                                         tgs_session,\n                                         &req_data,\n                                         request->nonce, *s4u_x509_user);\n\n    if (code) {\n        *status = \"INVALID_S4U2SELF_CHECKSUM\";\n        krb5_free_pa_s4u_x509_user(context, *s4u_x509_user);\n        *s4u_x509_user = NULL;\n        return code;\n    }\n\n    if (krb5_princ_size(context, (*s4u_x509_user)->user_id.user) == 0 ||\n        (*s4u_x509_user)->user_id.subject_cert.length != 0) {\n        *status = \"INVALID_S4U2SELF_REQUEST\";\n        krb5_free_pa_s4u_x509_user(context, *s4u_x509_user);\n        *s4u_x509_user = NULL;\n        return KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,8 +14,10 @@\n     req_data.data = (char *)pa_data->contents;\n \n     code = decode_krb5_pa_s4u_x509_user(&req_data, s4u_x509_user);\n-    if (code)\n+    if (code) {\n+        *status = \"DECODE_PA_S4U_X509_USER\";\n         return code;\n+    }\n \n     code = verify_s4u_x509_user_checksum(context,\n                                          tgs_subkey ? tgs_subkey :",
        "diff_line_info": {
            "deleted_lines": [
                "    if (code)"
            ],
            "added_lines": [
                "    if (code) {",
                "        *status = \"DECODE_PA_S4U_X509_USER\";",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11368",
        "func_name": "krb5/kdc_process_s4u2proxy_req",
        "description": "In MIT Kerberos 5 (aka krb5) 1.7 and later, an authenticated attacker can cause a KDC assertion failure by sending invalid S4U2Self or S4U2Proxy requests.",
        "git_url": "https://github.com/krb5/krb5/commit/ffb35baac6981f9e8914f8f3bffd37f284b85970",
        "commit_title": "Prevent KDC unset status assertion failures",
        "commit_text": " Assign status values if S4U2Self padata fails to decode, if an S4U2Proxy request uses invalid KDC options, or if an S4U2Proxy request uses an evidence ticket which does not match the canonicalized request server principal name.  Reported by Samuel Cabrero.  If a status value is not assigned during KDC processing, default to \"UNKNOWN_REASON\" rather than failing an assertion.  This change will prevent future denial of service bugs due to similar mistakes, and will allow us to omit assigning status values for unlikely errors such as small memory allocation failures.  CVE-2017-11368:  In MIT krb5 1.7 and later, an authenticated attacker can cause an assertion failure in krb5kdc by sending an invalid S4U2Self or S4U2Proxy request.    CVSSv3 Vector: AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:H/RL:O/RC:C  ticket: 8599 (new) target_version: 1.15-next target_version: 1.14-next tags: pullup",
        "func_before": "krb5_error_code\nkdc_process_s4u2proxy_req(kdc_realm_t *kdc_active_realm,\n                          krb5_kdc_req *request,\n                          const krb5_enc_tkt_part *t2enc,\n                          const krb5_db_entry *server,\n                          krb5_const_principal server_princ,\n                          krb5_const_principal proxy_princ,\n                          const char **status)\n{\n    krb5_error_code errcode;\n\n    /*\n     * Constrained delegation is mutually exclusive with renew/forward/etc.\n     * We can assert from this check that the header ticket was a TGT, as\n     * that is validated previously in validate_tgs_request().\n     */\n    if (request->kdc_options & (NON_TGT_OPTION | KDC_OPT_ENC_TKT_IN_SKEY)) {\n        return KRB5KDC_ERR_BADOPTION;\n    }\n\n    /* Ensure that evidence ticket server matches TGT client */\n    if (!krb5_principal_compare(kdc_context,\n                                server->princ, /* after canon */\n                                server_princ)) {\n        return KRB5KDC_ERR_SERVER_NOMATCH;\n    }\n\n    if (!isflagset(t2enc->flags, TKT_FLG_FORWARDABLE)) {\n        *status = \"EVIDENCE_TKT_NOT_FORWARDABLE\";\n        return KRB5_TKT_NOT_FORWARDABLE;\n    }\n\n    /* Backend policy check */\n    errcode = check_allowed_to_delegate_to(kdc_context,\n                                           t2enc->client,\n                                           server,\n                                           proxy_princ);\n    if (errcode) {\n        *status = \"NOT_ALLOWED_TO_DELEGATE\";\n        return errcode;\n    }\n\n    return 0;\n}",
        "func": "krb5_error_code\nkdc_process_s4u2proxy_req(kdc_realm_t *kdc_active_realm,\n                          krb5_kdc_req *request,\n                          const krb5_enc_tkt_part *t2enc,\n                          const krb5_db_entry *server,\n                          krb5_const_principal server_princ,\n                          krb5_const_principal proxy_princ,\n                          const char **status)\n{\n    krb5_error_code errcode;\n\n    /*\n     * Constrained delegation is mutually exclusive with renew/forward/etc.\n     * We can assert from this check that the header ticket was a TGT, as\n     * that is validated previously in validate_tgs_request().\n     */\n    if (request->kdc_options & (NON_TGT_OPTION | KDC_OPT_ENC_TKT_IN_SKEY)) {\n        *status = \"INVALID_S4U2PROXY_OPTIONS\";\n        return KRB5KDC_ERR_BADOPTION;\n    }\n\n    /* Ensure that evidence ticket server matches TGT client */\n    if (!krb5_principal_compare(kdc_context,\n                                server->princ, /* after canon */\n                                server_princ)) {\n        *status = \"EVIDENCE_TICKET_MISMATCH\";\n        return KRB5KDC_ERR_SERVER_NOMATCH;\n    }\n\n    if (!isflagset(t2enc->flags, TKT_FLG_FORWARDABLE)) {\n        *status = \"EVIDENCE_TKT_NOT_FORWARDABLE\";\n        return KRB5_TKT_NOT_FORWARDABLE;\n    }\n\n    /* Backend policy check */\n    errcode = check_allowed_to_delegate_to(kdc_context,\n                                           t2enc->client,\n                                           server,\n                                           proxy_princ);\n    if (errcode) {\n        *status = \"NOT_ALLOWED_TO_DELEGATE\";\n        return errcode;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,7 @@\n      * that is validated previously in validate_tgs_request().\n      */\n     if (request->kdc_options & (NON_TGT_OPTION | KDC_OPT_ENC_TKT_IN_SKEY)) {\n+        *status = \"INVALID_S4U2PROXY_OPTIONS\";\n         return KRB5KDC_ERR_BADOPTION;\n     }\n \n@@ -22,6 +23,7 @@\n     if (!krb5_principal_compare(kdc_context,\n                                 server->princ, /* after canon */\n                                 server_princ)) {\n+        *status = \"EVIDENCE_TICKET_MISMATCH\";\n         return KRB5KDC_ERR_SERVER_NOMATCH;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        *status = \"INVALID_S4U2PROXY_OPTIONS\";",
                "        *status = \"EVIDENCE_TICKET_MISMATCH\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11368",
        "func_name": "krb5/kdc_process_for_user",
        "description": "In MIT Kerberos 5 (aka krb5) 1.7 and later, an authenticated attacker can cause a KDC assertion failure by sending invalid S4U2Self or S4U2Proxy requests.",
        "git_url": "https://github.com/krb5/krb5/commit/ffb35baac6981f9e8914f8f3bffd37f284b85970",
        "commit_title": "Prevent KDC unset status assertion failures",
        "commit_text": " Assign status values if S4U2Self padata fails to decode, if an S4U2Proxy request uses invalid KDC options, or if an S4U2Proxy request uses an evidence ticket which does not match the canonicalized request server principal name.  Reported by Samuel Cabrero.  If a status value is not assigned during KDC processing, default to \"UNKNOWN_REASON\" rather than failing an assertion.  This change will prevent future denial of service bugs due to similar mistakes, and will allow us to omit assigning status values for unlikely errors such as small memory allocation failures.  CVE-2017-11368:  In MIT krb5 1.7 and later, an authenticated attacker can cause an assertion failure in krb5kdc by sending an invalid S4U2Self or S4U2Proxy request.    CVSSv3 Vector: AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H/E:H/RL:O/RC:C  ticket: 8599 (new) target_version: 1.15-next target_version: 1.14-next tags: pullup",
        "func_before": "static krb5_error_code\nkdc_process_for_user(kdc_realm_t *kdc_active_realm,\n                     krb5_pa_data *pa_data,\n                     krb5_keyblock *tgs_session,\n                     krb5_pa_s4u_x509_user **s4u_x509_user,\n                     const char **status)\n{\n    krb5_error_code             code;\n    krb5_pa_for_user            *for_user;\n    krb5_data                   req_data;\n\n    req_data.length = pa_data->length;\n    req_data.data = (char *)pa_data->contents;\n\n    code = decode_krb5_pa_for_user(&req_data, &for_user);\n    if (code)\n        return code;\n\n    code = verify_for_user_checksum(kdc_context, tgs_session, for_user);\n    if (code) {\n        *status = \"INVALID_S4U2SELF_CHECKSUM\";\n        krb5_free_pa_for_user(kdc_context, for_user);\n        return code;\n    }\n\n    *s4u_x509_user = calloc(1, sizeof(krb5_pa_s4u_x509_user));\n    if (*s4u_x509_user == NULL) {\n        krb5_free_pa_for_user(kdc_context, for_user);\n        return ENOMEM;\n    }\n\n    (*s4u_x509_user)->user_id.user = for_user->user;\n    for_user->user = NULL;\n    krb5_free_pa_for_user(kdc_context, for_user);\n\n    return 0;\n}",
        "func": "static krb5_error_code\nkdc_process_for_user(kdc_realm_t *kdc_active_realm,\n                     krb5_pa_data *pa_data,\n                     krb5_keyblock *tgs_session,\n                     krb5_pa_s4u_x509_user **s4u_x509_user,\n                     const char **status)\n{\n    krb5_error_code             code;\n    krb5_pa_for_user            *for_user;\n    krb5_data                   req_data;\n\n    req_data.length = pa_data->length;\n    req_data.data = (char *)pa_data->contents;\n\n    code = decode_krb5_pa_for_user(&req_data, &for_user);\n    if (code) {\n        *status = \"DECODE_PA_FOR_USER\";\n        return code;\n    }\n\n    code = verify_for_user_checksum(kdc_context, tgs_session, for_user);\n    if (code) {\n        *status = \"INVALID_S4U2SELF_CHECKSUM\";\n        krb5_free_pa_for_user(kdc_context, for_user);\n        return code;\n    }\n\n    *s4u_x509_user = calloc(1, sizeof(krb5_pa_s4u_x509_user));\n    if (*s4u_x509_user == NULL) {\n        krb5_free_pa_for_user(kdc_context, for_user);\n        return ENOMEM;\n    }\n\n    (*s4u_x509_user)->user_id.user = for_user->user;\n    for_user->user = NULL;\n    krb5_free_pa_for_user(kdc_context, for_user);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,8 +13,10 @@\n     req_data.data = (char *)pa_data->contents;\n \n     code = decode_krb5_pa_for_user(&req_data, &for_user);\n-    if (code)\n+    if (code) {\n+        *status = \"DECODE_PA_FOR_USER\";\n         return code;\n+    }\n \n     code = verify_for_user_checksum(kdc_context, tgs_session, for_user);\n     if (code) {",
        "diff_line_info": {
            "deleted_lines": [
                "    if (code)"
            ],
            "added_lines": [
                "    if (code) {",
                "        *status = \"DECODE_PA_FOR_USER\";",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-13658",
        "func_name": "ImageMagick/ReadMATImage",
        "description": "In ImageMagick before 6.9.9-3 and 7.x before 7.0.6-3, there is a missing NULL check in the ReadMATImage function in coders/mat.c, leading to a denial of service (assertion failure and application exit) in the DestroyImageInfo function in MagickCore/image.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/e5c063a1007506ba69e97a35effcdef944421c89",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/598",
        "commit_text": "",
        "func_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=(ImageInfo *) NULL;\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if ((image != image2) && (image2 != (Image *) NULL))\n    image2=DestroyImage(image2);\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}",
        "func": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=(ImageInfo *) NULL;\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if ((image != image2) && (image2 != (Image *) NULL))\n    image2=DestroyImage(image2);\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -89,7 +89,8 @@\n   if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n     {\n MATLAB_KO:\n-      clone_info=DestroyImageInfo(clone_info);\n+      if (clone_info != (ImageInfo *) NULL)\n+        clone_info=DestroyImageInfo(clone_info);\n       ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "      clone_info=DestroyImageInfo(clone_info);"
            ],
            "added_lines": [
                "      if (clone_info != (ImageInfo *) NULL)",
                "        clone_info=DestroyImageInfo(clone_info);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-13673",
        "func_name": "qemu/vga_draw_graphic",
        "description": "The vga display update in mis-calculated the region for the dirty bitmap snapshot in case split screen mode is used causing a denial of service (assertion failure) in the cpu_physical_memory_snapshot_get_dirty function.",
        "git_url": "https://github.com/qemu/qemu/commit/bfc56535f793c557aa754c50213fc5f882e6482d",
        "commit_title": "vga: fix display update region calculation",
        "commit_text": " vga display update mis-calculated the region for the dirty bitmap snapshot in case the scanlines are padded.  This can triggere an assert in cpu_physical_memory_snapshot_get_dirty(). ",
        "func_before": "static void vga_draw_graphic(VGACommonState *s, int full_update)\n{\n    DisplaySurface *surface = qemu_console_surface(s->con);\n    int y1, y, update, linesize, y_start, double_scan, mask, depth;\n    int width, height, shift_control, line_offset, bwidth, bits;\n    ram_addr_t page0, page1;\n    DirtyBitmapSnapshot *snap = NULL;\n    int disp_width, multi_scan, multi_run;\n    uint8_t *d;\n    uint32_t v, addr1, addr;\n    vga_draw_line_func *vga_draw_line = NULL;\n    bool share_surface;\n    pixman_format_code_t format;\n#ifdef HOST_WORDS_BIGENDIAN\n    bool byteswap = !s->big_endian_fb;\n#else\n    bool byteswap = s->big_endian_fb;\n#endif\n\n    full_update |= update_basic_params(s);\n\n    s->get_resolution(s, &width, &height);\n    disp_width = width;\n\n    shift_control = (s->gr[VGA_GFX_MODE] >> 5) & 3;\n    double_scan = (s->cr[VGA_CRTC_MAX_SCAN] >> 7);\n    if (shift_control != 1) {\n        multi_scan = (((s->cr[VGA_CRTC_MAX_SCAN] & 0x1f) + 1) << double_scan)\n            - 1;\n    } else {\n        /* in CGA modes, multi_scan is ignored */\n        /* XXX: is it correct ? */\n        multi_scan = double_scan;\n    }\n    multi_run = multi_scan;\n    if (shift_control != s->shift_control ||\n        double_scan != s->double_scan) {\n        full_update = 1;\n        s->shift_control = shift_control;\n        s->double_scan = double_scan;\n    }\n\n    if (shift_control == 0) {\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            disp_width <<= 1;\n        }\n    } else if (shift_control == 1) {\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            disp_width <<= 1;\n        }\n    }\n\n    depth = s->get_bpp(s);\n\n    /*\n     * Check whether we can share the surface with the backend\n     * or whether we need a shadow surface. We share native\n     * endian surfaces for 15bpp and above and byteswapped\n     * surfaces for 24bpp and above.\n     */\n    format = qemu_default_pixman_format(depth, !byteswap);\n    if (format) {\n        share_surface = dpy_gfx_check_format(s->con, format)\n            && !s->force_shadow;\n    } else {\n        share_surface = false;\n    }\n    if (s->line_offset != s->last_line_offset ||\n        disp_width != s->last_width ||\n        height != s->last_height ||\n        s->last_depth != depth ||\n        s->last_byteswap != byteswap ||\n        share_surface != is_buffer_shared(surface)) {\n        if (share_surface) {\n            surface = qemu_create_displaysurface_from(disp_width,\n                    height, format, s->line_offset,\n                    s->vram_ptr + (s->start_addr * 4));\n            dpy_gfx_replace_surface(s->con, surface);\n        } else {\n            qemu_console_resize(s->con, disp_width, height);\n            surface = qemu_console_surface(s->con);\n        }\n        s->last_scr_width = disp_width;\n        s->last_scr_height = height;\n        s->last_width = disp_width;\n        s->last_height = height;\n        s->last_line_offset = s->line_offset;\n        s->last_depth = depth;\n        s->last_byteswap = byteswap;\n        full_update = 1;\n    } else if (is_buffer_shared(surface) &&\n               (full_update || surface_data(surface) != s->vram_ptr\n                + (s->start_addr * 4))) {\n        pixman_format_code_t format =\n            qemu_default_pixman_format(depth, !byteswap);\n        surface = qemu_create_displaysurface_from(disp_width,\n                height, format, s->line_offset,\n                s->vram_ptr + (s->start_addr * 4));\n        dpy_gfx_replace_surface(s->con, surface);\n    }\n\n    if (shift_control == 0) {\n        full_update |= update_palette16(s);\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            v = VGA_DRAW_LINE4D2;\n        } else {\n            v = VGA_DRAW_LINE4;\n        }\n        bits = 4;\n    } else if (shift_control == 1) {\n        full_update |= update_palette16(s);\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            v = VGA_DRAW_LINE2D2;\n        } else {\n            v = VGA_DRAW_LINE2;\n        }\n        bits = 4;\n    } else {\n        switch(s->get_bpp(s)) {\n        default:\n        case 0:\n            full_update |= update_palette256(s);\n            v = VGA_DRAW_LINE8D2;\n            bits = 4;\n            break;\n        case 8:\n            full_update |= update_palette256(s);\n            v = VGA_DRAW_LINE8;\n            bits = 8;\n            break;\n        case 15:\n            v = s->big_endian_fb ? VGA_DRAW_LINE15_BE : VGA_DRAW_LINE15_LE;\n            bits = 16;\n            break;\n        case 16:\n            v = s->big_endian_fb ? VGA_DRAW_LINE16_BE : VGA_DRAW_LINE16_LE;\n            bits = 16;\n            break;\n        case 24:\n            v = s->big_endian_fb ? VGA_DRAW_LINE24_BE : VGA_DRAW_LINE24_LE;\n            bits = 24;\n            break;\n        case 32:\n            v = s->big_endian_fb ? VGA_DRAW_LINE32_BE : VGA_DRAW_LINE32_LE;\n            bits = 32;\n            break;\n        }\n    }\n    vga_draw_line = vga_draw_line_table[v];\n\n    if (!is_buffer_shared(surface) && s->cursor_invalidate) {\n        s->cursor_invalidate(s);\n    }\n\n    line_offset = s->line_offset;\n#if 0\n    printf(\"w=%d h=%d v=%d line_offset=%d cr[0x09]=0x%02x cr[0x17]=0x%02x linecmp=%d sr[0x01]=0x%02x\\n\",\n           width, height, v, line_offset, s->cr[9], s->cr[VGA_CRTC_MODE],\n           s->line_compare, sr(s, VGA_SEQ_CLOCK_MODE));\n#endif\n    addr1 = (s->start_addr * 4);\n    bwidth = (width * bits + 7) / 8;\n    y_start = -1;\n    d = surface_data(surface);\n    linesize = surface_stride(surface);\n    y1 = 0;\n\n    if (!full_update) {\n        vga_sync_dirty_bitmap(s);\n        snap = memory_region_snapshot_and_clear_dirty(&s->vram, addr1,\n                                                      bwidth * height,\n                                                      DIRTY_MEMORY_VGA);\n    }\n\n    for(y = 0; y < height; y++) {\n        addr = addr1;\n        if (!(s->cr[VGA_CRTC_MODE] & 1)) {\n            int shift;\n            /* CGA compatibility handling */\n            shift = 14 + ((s->cr[VGA_CRTC_MODE] >> 6) & 1);\n            addr = (addr & ~(1 << shift)) | ((y1 & 1) << shift);\n        }\n        if (!(s->cr[VGA_CRTC_MODE] & 2)) {\n            addr = (addr & ~0x8000) | ((y1 & 2) << 14);\n        }\n        update = full_update;\n        page0 = addr;\n        page1 = addr + bwidth - 1;\n        if (full_update) {\n            update = 1;\n        } else {\n            update = memory_region_snapshot_get_dirty(&s->vram, snap,\n                                                      page0, page1 - page0);\n        }\n        /* explicit invalidation for the hardware cursor (cirrus only) */\n        update |= vga_scanline_invalidated(s, y);\n        if (update) {\n            if (y_start < 0)\n                y_start = y;\n            if (!(is_buffer_shared(surface))) {\n                vga_draw_line(s, d, s->vram_ptr + addr, width);\n                if (s->cursor_draw_line)\n                    s->cursor_draw_line(s, d, y);\n            }\n        } else {\n            if (y_start >= 0) {\n                /* flush to display */\n                dpy_gfx_update(s->con, 0, y_start,\n                               disp_width, y - y_start);\n                y_start = -1;\n            }\n        }\n        if (!multi_run) {\n            mask = (s->cr[VGA_CRTC_MODE] & 3) ^ 3;\n            if ((y1 & mask) == mask)\n                addr1 += line_offset;\n            y1++;\n            multi_run = multi_scan;\n        } else {\n            multi_run--;\n        }\n        /* line compare acts on the displayed lines */\n        if (y == s->line_compare)\n            addr1 = 0;\n        d += linesize;\n    }\n    if (y_start >= 0) {\n        /* flush to display */\n        dpy_gfx_update(s->con, 0, y_start,\n                       disp_width, y - y_start);\n    }\n    g_free(snap);\n    memset(s->invalidated_y_table, 0, sizeof(s->invalidated_y_table));\n}",
        "func": "static void vga_draw_graphic(VGACommonState *s, int full_update)\n{\n    DisplaySurface *surface = qemu_console_surface(s->con);\n    int y1, y, update, linesize, y_start, double_scan, mask, depth;\n    int width, height, shift_control, line_offset, bwidth, bits;\n    ram_addr_t page0, page1;\n    DirtyBitmapSnapshot *snap = NULL;\n    int disp_width, multi_scan, multi_run;\n    uint8_t *d;\n    uint32_t v, addr1, addr;\n    vga_draw_line_func *vga_draw_line = NULL;\n    bool share_surface;\n    pixman_format_code_t format;\n#ifdef HOST_WORDS_BIGENDIAN\n    bool byteswap = !s->big_endian_fb;\n#else\n    bool byteswap = s->big_endian_fb;\n#endif\n\n    full_update |= update_basic_params(s);\n\n    s->get_resolution(s, &width, &height);\n    disp_width = width;\n\n    shift_control = (s->gr[VGA_GFX_MODE] >> 5) & 3;\n    double_scan = (s->cr[VGA_CRTC_MAX_SCAN] >> 7);\n    if (shift_control != 1) {\n        multi_scan = (((s->cr[VGA_CRTC_MAX_SCAN] & 0x1f) + 1) << double_scan)\n            - 1;\n    } else {\n        /* in CGA modes, multi_scan is ignored */\n        /* XXX: is it correct ? */\n        multi_scan = double_scan;\n    }\n    multi_run = multi_scan;\n    if (shift_control != s->shift_control ||\n        double_scan != s->double_scan) {\n        full_update = 1;\n        s->shift_control = shift_control;\n        s->double_scan = double_scan;\n    }\n\n    if (shift_control == 0) {\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            disp_width <<= 1;\n        }\n    } else if (shift_control == 1) {\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            disp_width <<= 1;\n        }\n    }\n\n    depth = s->get_bpp(s);\n\n    /*\n     * Check whether we can share the surface with the backend\n     * or whether we need a shadow surface. We share native\n     * endian surfaces for 15bpp and above and byteswapped\n     * surfaces for 24bpp and above.\n     */\n    format = qemu_default_pixman_format(depth, !byteswap);\n    if (format) {\n        share_surface = dpy_gfx_check_format(s->con, format)\n            && !s->force_shadow;\n    } else {\n        share_surface = false;\n    }\n    if (s->line_offset != s->last_line_offset ||\n        disp_width != s->last_width ||\n        height != s->last_height ||\n        s->last_depth != depth ||\n        s->last_byteswap != byteswap ||\n        share_surface != is_buffer_shared(surface)) {\n        if (share_surface) {\n            surface = qemu_create_displaysurface_from(disp_width,\n                    height, format, s->line_offset,\n                    s->vram_ptr + (s->start_addr * 4));\n            dpy_gfx_replace_surface(s->con, surface);\n        } else {\n            qemu_console_resize(s->con, disp_width, height);\n            surface = qemu_console_surface(s->con);\n        }\n        s->last_scr_width = disp_width;\n        s->last_scr_height = height;\n        s->last_width = disp_width;\n        s->last_height = height;\n        s->last_line_offset = s->line_offset;\n        s->last_depth = depth;\n        s->last_byteswap = byteswap;\n        full_update = 1;\n    } else if (is_buffer_shared(surface) &&\n               (full_update || surface_data(surface) != s->vram_ptr\n                + (s->start_addr * 4))) {\n        pixman_format_code_t format =\n            qemu_default_pixman_format(depth, !byteswap);\n        surface = qemu_create_displaysurface_from(disp_width,\n                height, format, s->line_offset,\n                s->vram_ptr + (s->start_addr * 4));\n        dpy_gfx_replace_surface(s->con, surface);\n    }\n\n    if (shift_control == 0) {\n        full_update |= update_palette16(s);\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            v = VGA_DRAW_LINE4D2;\n        } else {\n            v = VGA_DRAW_LINE4;\n        }\n        bits = 4;\n    } else if (shift_control == 1) {\n        full_update |= update_palette16(s);\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            v = VGA_DRAW_LINE2D2;\n        } else {\n            v = VGA_DRAW_LINE2;\n        }\n        bits = 4;\n    } else {\n        switch(s->get_bpp(s)) {\n        default:\n        case 0:\n            full_update |= update_palette256(s);\n            v = VGA_DRAW_LINE8D2;\n            bits = 4;\n            break;\n        case 8:\n            full_update |= update_palette256(s);\n            v = VGA_DRAW_LINE8;\n            bits = 8;\n            break;\n        case 15:\n            v = s->big_endian_fb ? VGA_DRAW_LINE15_BE : VGA_DRAW_LINE15_LE;\n            bits = 16;\n            break;\n        case 16:\n            v = s->big_endian_fb ? VGA_DRAW_LINE16_BE : VGA_DRAW_LINE16_LE;\n            bits = 16;\n            break;\n        case 24:\n            v = s->big_endian_fb ? VGA_DRAW_LINE24_BE : VGA_DRAW_LINE24_LE;\n            bits = 24;\n            break;\n        case 32:\n            v = s->big_endian_fb ? VGA_DRAW_LINE32_BE : VGA_DRAW_LINE32_LE;\n            bits = 32;\n            break;\n        }\n    }\n    vga_draw_line = vga_draw_line_table[v];\n\n    if (!is_buffer_shared(surface) && s->cursor_invalidate) {\n        s->cursor_invalidate(s);\n    }\n\n    line_offset = s->line_offset;\n#if 0\n    printf(\"w=%d h=%d v=%d line_offset=%d cr[0x09]=0x%02x cr[0x17]=0x%02x linecmp=%d sr[0x01]=0x%02x\\n\",\n           width, height, v, line_offset, s->cr[9], s->cr[VGA_CRTC_MODE],\n           s->line_compare, sr(s, VGA_SEQ_CLOCK_MODE));\n#endif\n    addr1 = (s->start_addr * 4);\n    bwidth = (width * bits + 7) / 8;\n    y_start = -1;\n    d = surface_data(surface);\n    linesize = surface_stride(surface);\n    y1 = 0;\n\n    if (!full_update) {\n        vga_sync_dirty_bitmap(s);\n        snap = memory_region_snapshot_and_clear_dirty(&s->vram, addr1,\n                                                      line_offset * height,\n                                                      DIRTY_MEMORY_VGA);\n    }\n\n    for(y = 0; y < height; y++) {\n        addr = addr1;\n        if (!(s->cr[VGA_CRTC_MODE] & 1)) {\n            int shift;\n            /* CGA compatibility handling */\n            shift = 14 + ((s->cr[VGA_CRTC_MODE] >> 6) & 1);\n            addr = (addr & ~(1 << shift)) | ((y1 & 1) << shift);\n        }\n        if (!(s->cr[VGA_CRTC_MODE] & 2)) {\n            addr = (addr & ~0x8000) | ((y1 & 2) << 14);\n        }\n        update = full_update;\n        page0 = addr;\n        page1 = addr + bwidth - 1;\n        if (full_update) {\n            update = 1;\n        } else {\n            update = memory_region_snapshot_get_dirty(&s->vram, snap,\n                                                      page0, page1 - page0);\n        }\n        /* explicit invalidation for the hardware cursor (cirrus only) */\n        update |= vga_scanline_invalidated(s, y);\n        if (update) {\n            if (y_start < 0)\n                y_start = y;\n            if (!(is_buffer_shared(surface))) {\n                vga_draw_line(s, d, s->vram_ptr + addr, width);\n                if (s->cursor_draw_line)\n                    s->cursor_draw_line(s, d, y);\n            }\n        } else {\n            if (y_start >= 0) {\n                /* flush to display */\n                dpy_gfx_update(s->con, 0, y_start,\n                               disp_width, y - y_start);\n                y_start = -1;\n            }\n        }\n        if (!multi_run) {\n            mask = (s->cr[VGA_CRTC_MODE] & 3) ^ 3;\n            if ((y1 & mask) == mask)\n                addr1 += line_offset;\n            y1++;\n            multi_run = multi_scan;\n        } else {\n            multi_run--;\n        }\n        /* line compare acts on the displayed lines */\n        if (y == s->line_compare)\n            addr1 = 0;\n        d += linesize;\n    }\n    if (y_start >= 0) {\n        /* flush to display */\n        dpy_gfx_update(s->con, 0, y_start,\n                       disp_width, y - y_start);\n    }\n    g_free(snap);\n    memset(s->invalidated_y_table, 0, sizeof(s->invalidated_y_table));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -168,7 +168,7 @@\n     if (!full_update) {\n         vga_sync_dirty_bitmap(s);\n         snap = memory_region_snapshot_and_clear_dirty(&s->vram, addr1,\n-                                                      bwidth * height,\n+                                                      line_offset * height,\n                                                       DIRTY_MEMORY_VGA);\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "                                                      bwidth * height,"
            ],
            "added_lines": [
                "                                                      line_offset * height,"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-45290",
        "func_name": "WebAssembly/binaryen/WasmBinaryBuilder::visitRefAs",
        "description": "A Denial of Service vulnerability exits in Binaryen 103 due to an assertion abort in wasm::handle_unreachable.",
        "git_url": "https://github.com/WebAssembly/binaryen/commit/859d8996d68b5d279712172669c216569398ae97",
        "commit_title": "fix",
        "commit_text": "",
        "func_before": "void WasmBinaryBuilder::visitRefAs(RefAs* curr, uint8_t code) {\n  BYN_TRACE(\"zz node: RefAs\\n\");\n  switch (code) {\n    case BinaryConsts::RefAsNonNull:\n      curr->op = RefAsNonNull;\n      break;\n    case BinaryConsts::RefAsFunc:\n      curr->op = RefAsFunc;\n      break;\n    case BinaryConsts::RefAsData:\n      curr->op = RefAsData;\n      break;\n    case BinaryConsts::RefAsI31:\n      curr->op = RefAsI31;\n      break;\n    default:\n      WASM_UNREACHABLE(\"invalid code for ref.as_*\");\n  }\n  curr->value = popNonVoidExpression();\n  curr->finalize();\n}",
        "func": "void WasmBinaryBuilder::visitRefAs(RefAs* curr, uint8_t code) {\n  BYN_TRACE(\"zz node: RefAs\\n\");\n  switch (code) {\n    case BinaryConsts::RefAsNonNull:\n      curr->op = RefAsNonNull;\n      break;\n    case BinaryConsts::RefAsFunc:\n      curr->op = RefAsFunc;\n      break;\n    case BinaryConsts::RefAsData:\n      curr->op = RefAsData;\n      break;\n    case BinaryConsts::RefAsI31:\n      curr->op = RefAsI31;\n      break;\n    default:\n      WASM_UNREACHABLE(\"invalid code for ref.as_*\");\n  }\n  curr->value = popNonVoidExpression();\n  if (!curr->value->type.isRef() && curr->value->type != Type::unreachable) {\n    throwError(\"bad input type for ref.as: \" + curr->value->type.toString());\n  }\n  curr->finalize();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,5 +17,8 @@\n       WASM_UNREACHABLE(\"invalid code for ref.as_*\");\n   }\n   curr->value = popNonVoidExpression();\n+  if (!curr->value->type.isRef() && curr->value->type != Type::unreachable) {\n+    throwError(\"bad input type for ref.as: \" + curr->value->type.toString());\n+  }\n   curr->finalize();\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (!curr->value->type.isRef() && curr->value->type != Type::unreachable) {",
                "    throwError(\"bad input type for ref.as: \" + curr->value->type.toString());",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46054",
        "func_name": "WebAssembly/binaryen/WasmBinaryBuilder::visitRethrow",
        "description": "A Denial of Service vulnerability exists in Binaryen 104 due to an assertion abort in wasm::WasmBinaryBuilder::visitRethrow(wasm::Rethrow*).",
        "git_url": "https://github.com/WebAssembly/binaryen/commit/6f599272c66f65472f5e4c8d759d5bca77e47da6",
        "commit_title": "Turn an assertion on not colliding with an internal name into an error (#4422)",
        "commit_text": " Without this, the result in a build without assertions might be quite\r confusing. See #4410\r \r Also make the internal names more obviously internal names.",
        "func_before": "void WasmBinaryBuilder::visitRethrow(Rethrow* curr) {\n  BYN_TRACE(\"zz node: Rethrow\\n\");\n  curr->target = getExceptionTargetName(getU32LEB());\n  // This special target is valid only for delegates\n  assert(curr->target != DELEGATE_CALLER_TARGET);\n  curr->finalize();\n}",
        "func": "void WasmBinaryBuilder::visitRethrow(Rethrow* curr) {\n  BYN_TRACE(\"zz node: Rethrow\\n\");\n  curr->target = getExceptionTargetName(getU32LEB());\n  // This special target is valid only for delegates\n  if (curr->target == DELEGATE_CALLER_TARGET) {\n    throwError(std::string(\"rethrow target cannot use internal name \") +\n               DELEGATE_CALLER_TARGET.str);\n  }\n  curr->finalize();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,9 @@\n   BYN_TRACE(\"zz node: Rethrow\\n\");\n   curr->target = getExceptionTargetName(getU32LEB());\n   // This special target is valid only for delegates\n-  assert(curr->target != DELEGATE_CALLER_TARGET);\n+  if (curr->target == DELEGATE_CALLER_TARGET) {\n+    throwError(std::string(\"rethrow target cannot use internal name \") +\n+               DELEGATE_CALLER_TARGET.str);\n+  }\n   curr->finalize();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  assert(curr->target != DELEGATE_CALLER_TARGET);"
            ],
            "added_lines": [
                "  if (curr->target == DELEGATE_CALLER_TARGET) {",
                "    throwError(std::string(\"rethrow target cannot use internal name \") +",
                "               DELEGATE_CALLER_TARGET.str);",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46055",
        "func_name": "WebAssembly/binaryen/WasmBinaryBuilder::readImports",
        "description": "A Denial of Service vulnerability exists in Binaryen 104 due to an assertion abort in wasm::WasmBinaryBuilder::visitRethrow(wasm::Rethrow*).",
        "git_url": "https://github.com/WebAssembly/binaryen/commit/1beec37f483505db0c5152be9118b28e45b77316",
        "commit_title": "Add binary format parse check for imported function types (#4423)",
        "commit_text": " Without this we hit an assertion later, which is less clear.\r \r See #4413",
        "func_before": "void WasmBinaryBuilder::readImports() {\n  BYN_TRACE(\"== readImports\\n\");\n  size_t num = getU32LEB();\n  BYN_TRACE(\"num: \" << num << std::endl);\n  Builder builder(wasm);\n  size_t tableCounter = 0;\n  size_t memoryCounter = 0;\n  size_t functionCounter = 0;\n  size_t globalCounter = 0;\n  size_t tagCounter = 0;\n  for (size_t i = 0; i < num; i++) {\n    BYN_TRACE(\"read one\\n\");\n    auto module = getInlineString();\n    auto base = getInlineString();\n    auto kind = (ExternalKind)getU32LEB();\n    // We set a unique prefix for the name based on the kind. This ensures no\n    // collisions between them, which can't occur here (due to the index i) but\n    // could occur later due to the names section.\n    switch (kind) {\n      case ExternalKind::Function: {\n        Name name(std::string(\"fimport$\") + std::to_string(functionCounter++));\n        auto index = getU32LEB();\n        functionTypes.push_back(getTypeByIndex(index));\n        auto curr = builder.makeFunction(name, getTypeByIndex(index), {});\n        curr->module = module;\n        curr->base = base;\n        functionImports.push_back(curr.get());\n        wasm.addFunction(std::move(curr));\n        break;\n      }\n      case ExternalKind::Table: {\n        Name name(std::string(\"timport$\") + std::to_string(tableCounter++));\n        auto table = builder.makeTable(name);\n        table->module = module;\n        table->base = base;\n        table->type = getType();\n\n        bool is_shared;\n        Type indexType;\n        getResizableLimits(table->initial,\n                           table->max,\n                           is_shared,\n                           indexType,\n                           Table::kUnlimitedSize);\n        if (is_shared) {\n          throwError(\"Tables may not be shared\");\n        }\n        if (indexType == Type::i64) {\n          throwError(\"Tables may not be 64-bit\");\n        }\n\n        tableImports.push_back(table.get());\n        wasm.addTable(std::move(table));\n        break;\n      }\n      case ExternalKind::Memory: {\n        Name name(std::string(\"mimport$\") + std::to_string(memoryCounter++));\n        wasm.memory.module = module;\n        wasm.memory.base = base;\n        wasm.memory.name = name;\n        wasm.memory.exists = true;\n        getResizableLimits(wasm.memory.initial,\n                           wasm.memory.max,\n                           wasm.memory.shared,\n                           wasm.memory.indexType,\n                           Memory::kUnlimitedSize);\n        break;\n      }\n      case ExternalKind::Global: {\n        Name name(std::string(\"gimport$\") + std::to_string(globalCounter++));\n        auto type = getConcreteType();\n        auto mutable_ = getU32LEB();\n        auto curr =\n          builder.makeGlobal(name,\n                             type,\n                             nullptr,\n                             mutable_ ? Builder::Mutable : Builder::Immutable);\n        curr->module = module;\n        curr->base = base;\n        globalImports.push_back(curr.get());\n        wasm.addGlobal(std::move(curr));\n        break;\n      }\n      case ExternalKind::Tag: {\n        Name name(std::string(\"eimport$\") + std::to_string(tagCounter++));\n        getInt8(); // Reserved 'attribute' field\n        auto index = getU32LEB();\n        auto curr = builder.makeTag(name, getSignatureByTypeIndex(index));\n        curr->module = module;\n        curr->base = base;\n        wasm.addTag(std::move(curr));\n        break;\n      }\n      default: {\n        throwError(\"bad import kind\");\n      }\n    }\n  }\n}",
        "func": "void WasmBinaryBuilder::readImports() {\n  BYN_TRACE(\"== readImports\\n\");\n  size_t num = getU32LEB();\n  BYN_TRACE(\"num: \" << num << std::endl);\n  Builder builder(wasm);\n  size_t tableCounter = 0;\n  size_t memoryCounter = 0;\n  size_t functionCounter = 0;\n  size_t globalCounter = 0;\n  size_t tagCounter = 0;\n  for (size_t i = 0; i < num; i++) {\n    BYN_TRACE(\"read one\\n\");\n    auto module = getInlineString();\n    auto base = getInlineString();\n    auto kind = (ExternalKind)getU32LEB();\n    // We set a unique prefix for the name based on the kind. This ensures no\n    // collisions between them, which can't occur here (due to the index i) but\n    // could occur later due to the names section.\n    switch (kind) {\n      case ExternalKind::Function: {\n        Name name(std::string(\"fimport$\") + std::to_string(functionCounter++));\n        auto index = getU32LEB();\n        functionTypes.push_back(getTypeByIndex(index));\n        auto type = getTypeByIndex(index);\n        if (!type.isSignature()) {\n          throwError(std::string(\"Imported function \") + module.str + '.' +\n                     base.str +\n                     \"'s type must be a signature. Given: \" + type.toString());\n        }\n        auto curr = builder.makeFunction(name, type, {});\n        curr->module = module;\n        curr->base = base;\n        functionImports.push_back(curr.get());\n        wasm.addFunction(std::move(curr));\n        break;\n      }\n      case ExternalKind::Table: {\n        Name name(std::string(\"timport$\") + std::to_string(tableCounter++));\n        auto table = builder.makeTable(name);\n        table->module = module;\n        table->base = base;\n        table->type = getType();\n\n        bool is_shared;\n        Type indexType;\n        getResizableLimits(table->initial,\n                           table->max,\n                           is_shared,\n                           indexType,\n                           Table::kUnlimitedSize);\n        if (is_shared) {\n          throwError(\"Tables may not be shared\");\n        }\n        if (indexType == Type::i64) {\n          throwError(\"Tables may not be 64-bit\");\n        }\n\n        tableImports.push_back(table.get());\n        wasm.addTable(std::move(table));\n        break;\n      }\n      case ExternalKind::Memory: {\n        Name name(std::string(\"mimport$\") + std::to_string(memoryCounter++));\n        wasm.memory.module = module;\n        wasm.memory.base = base;\n        wasm.memory.name = name;\n        wasm.memory.exists = true;\n        getResizableLimits(wasm.memory.initial,\n                           wasm.memory.max,\n                           wasm.memory.shared,\n                           wasm.memory.indexType,\n                           Memory::kUnlimitedSize);\n        break;\n      }\n      case ExternalKind::Global: {\n        Name name(std::string(\"gimport$\") + std::to_string(globalCounter++));\n        auto type = getConcreteType();\n        auto mutable_ = getU32LEB();\n        auto curr =\n          builder.makeGlobal(name,\n                             type,\n                             nullptr,\n                             mutable_ ? Builder::Mutable : Builder::Immutable);\n        curr->module = module;\n        curr->base = base;\n        globalImports.push_back(curr.get());\n        wasm.addGlobal(std::move(curr));\n        break;\n      }\n      case ExternalKind::Tag: {\n        Name name(std::string(\"eimport$\") + std::to_string(tagCounter++));\n        getInt8(); // Reserved 'attribute' field\n        auto index = getU32LEB();\n        auto curr = builder.makeTag(name, getSignatureByTypeIndex(index));\n        curr->module = module;\n        curr->base = base;\n        wasm.addTag(std::move(curr));\n        break;\n      }\n      default: {\n        throwError(\"bad import kind\");\n      }\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,7 +21,13 @@\n         Name name(std::string(\"fimport$\") + std::to_string(functionCounter++));\n         auto index = getU32LEB();\n         functionTypes.push_back(getTypeByIndex(index));\n-        auto curr = builder.makeFunction(name, getTypeByIndex(index), {});\n+        auto type = getTypeByIndex(index);\n+        if (!type.isSignature()) {\n+          throwError(std::string(\"Imported function \") + module.str + '.' +\n+                     base.str +\n+                     \"'s type must be a signature. Given: \" + type.toString());\n+        }\n+        auto curr = builder.makeFunction(name, type, {});\n         curr->module = module;\n         curr->base = base;\n         functionImports.push_back(curr.get());",
        "diff_line_info": {
            "deleted_lines": [
                "        auto curr = builder.makeFunction(name, getTypeByIndex(index), {});"
            ],
            "added_lines": [
                "        auto type = getTypeByIndex(index);",
                "        if (!type.isSignature()) {",
                "          throwError(std::string(\"Imported function \") + module.str + '.' +",
                "                     base.str +",
                "                     \"'s type must be a signature. Given: \" + type.toString());",
                "        }",
                "        auto curr = builder.makeFunction(name, type, {});"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-36409",
        "func_name": "strukturag/libde265/read_scaling_list",
        "description": "There is an Assertion `scaling_list_pred_matrix_id_delta==1' failed at sps.cc:925 in libde265 v1.0.8 when decoding file, which allows attackers to cause a Denial of Service (DoS) by running the application with a crafted file or possibly have unspecified other impact.",
        "git_url": "https://github.com/strukturag/libde265/commit/64d591a6c70737604ca3f5791736fc462cbe8a3c",
        "commit_title": "fix assertion when reading invalid scaling_list (#300)",
        "commit_text": "",
        "func_before": "de265_error read_scaling_list(bitreader* br, const seq_parameter_set* sps,\n                              scaling_list_data* sclist, bool inPPS)\n{\n  int dc_coeff[4][6];\n\n  for (int sizeId=0;sizeId<4;sizeId++) {\n    //int n = ((sizeId==3) ? 2 : 6);\n    uint8_t scaling_list[6][32*32];\n\n    for (int matrixId=0 ; matrixId<6 ; matrixId += (sizeId==3 ? 3 : 1)) {\n      uint8_t* curr_scaling_list = scaling_list[matrixId];\n      int scaling_list_dc_coef;\n\n      int canonicalMatrixId = matrixId;\n      if (sizeId==3 && matrixId==1) { canonicalMatrixId=3; }\n\n\n      //printf(\"----- matrix %d\\n\",matrixId);\n\n      char scaling_list_pred_mode_flag = get_bits(br,1);\n      if (!scaling_list_pred_mode_flag) {\n        int scaling_list_pred_matrix_id_delta = get_uvlc(br);\n        if (scaling_list_pred_matrix_id_delta == UVLC_ERROR ||\n            scaling_list_pred_matrix_id_delta > matrixId) {\n          return DE265_ERROR_CODED_PARAMETER_OUT_OF_RANGE;\n        }\n\n        //printf(\"scaling_list_pred_matrix_id_delta=%d\\n\", scaling_list_pred_matrix_id_delta);\n\n        dc_coeff[sizeId][matrixId] = 16;\n        scaling_list_dc_coef       = 16;\n\n        if (scaling_list_pred_matrix_id_delta==0) {\n          if (sizeId==0) {\n            memcpy(curr_scaling_list, default_ScalingList_4x4, 16);\n          }\n          else {\n            if (canonicalMatrixId<3)\n              { memcpy(curr_scaling_list, default_ScalingList_8x8_intra,64); }\n            else\n              { memcpy(curr_scaling_list, default_ScalingList_8x8_inter,64); }\n          }\n        }\n        else {\n          // TODO: CHECK: for sizeID=3 and the second matrix, should we have delta=1 or delta=3 ?\n          if (sizeId==3) { assert(scaling_list_pred_matrix_id_delta==1); }\n\n          int mID = matrixId - scaling_list_pred_matrix_id_delta;\n\n          int len = (sizeId == 0 ? 16 : 64);\n          memcpy(curr_scaling_list, scaling_list[mID], len);\n\n          scaling_list_dc_coef       = dc_coeff[sizeId][mID];\n          dc_coeff[sizeId][matrixId] = dc_coeff[sizeId][mID];\n        }\n      }\n      else {\n        int nextCoef=8;\n        int coefNum = (sizeId==0 ? 16 : 64);\n        if (sizeId>1) {\n          scaling_list_dc_coef = get_svlc(br);\n          if (scaling_list_dc_coef < -7 ||\n              scaling_list_dc_coef > 247) {\n            return DE265_ERROR_CODED_PARAMETER_OUT_OF_RANGE;\n          }\n\n          scaling_list_dc_coef += 8;\n          nextCoef=scaling_list_dc_coef;\n          dc_coeff[sizeId][matrixId] = scaling_list_dc_coef;\n        }\n        else {\n          scaling_list_dc_coef = 16;\n        }\n        //printf(\"DC = %d\\n\",scaling_list_dc_coef);\n\n        for (int i=0;i<coefNum;i++) {\n          int scaling_list_delta_coef = get_svlc(br);\n          if (scaling_list_delta_coef < -128 ||\n              scaling_list_delta_coef >  127) {\n            return DE265_ERROR_CODED_PARAMETER_OUT_OF_RANGE;\n          }\n\n          nextCoef = (nextCoef + scaling_list_delta_coef + 256) % 256;\n          curr_scaling_list[i] = nextCoef;\n          //printf(\"curr %d = %d\\n\",i,nextCoef);\n        }\n      }\n\n\n      // --- generate ScalingFactor arrays ---\n\n      switch (sizeId) {\n      case 0:\n        fill_scaling_factor(&sclist->ScalingFactor_Size0[matrixId][0][0], curr_scaling_list, 0);\n        break;\n\n      case 1:\n        fill_scaling_factor(&sclist->ScalingFactor_Size1[matrixId][0][0], curr_scaling_list, 1);\n        break;\n\n      case 2:\n        fill_scaling_factor(&sclist->ScalingFactor_Size2[matrixId][0][0], curr_scaling_list, 2);\n        sclist->ScalingFactor_Size2[matrixId][0][0] = scaling_list_dc_coef;\n        //printf(\"DC coeff: %d\\n\", scaling_list_dc_coef);\n        break;\n\n      case 3:\n        fill_scaling_factor(&sclist->ScalingFactor_Size3[matrixId][0][0], curr_scaling_list, 3);\n        sclist->ScalingFactor_Size3[matrixId][0][0] = scaling_list_dc_coef;\n        //printf(\"DC coeff: %d\\n\", scaling_list_dc_coef);\n        break;\n      }\n    }\n  }\n\n\n  // --- fill 32x32 matrices for chroma\n\n  const position* scan = get_scan_order(3, 0 /* diag */);\n\t\n  for (int matrixId=0;matrixId<6;matrixId++)\n    if (matrixId!=0 && matrixId!=3) {\n      for (int i=0;i<64;i++) {\n\tint x = scan[i].x;\n\tint y = scan[i].y;\n\tint v = sclist->ScalingFactor_Size1[matrixId][y][x];\n\n\tfor (int dy=0;dy<4;dy++)\n\t  for (int dx=0;dx<4;dx++) {\n\t    sclist->ScalingFactor_Size3[matrixId][4*y+dy][4*x+dx] = v;\n\t  }\n      }\n\n      sclist->ScalingFactor_Size3[matrixId][0][0] = sclist->ScalingFactor_Size1[matrixId][0][0];\n    }\n  \n  return DE265_OK;\n}",
        "func": "de265_error read_scaling_list(bitreader* br, const seq_parameter_set* sps,\n                              scaling_list_data* sclist, bool inPPS)\n{\n  int dc_coeff[4][6];\n\n  for (int sizeId=0;sizeId<4;sizeId++) {\n    //int n = ((sizeId==3) ? 2 : 6);\n    uint8_t scaling_list[6][32*32];\n\n    // Note: we use a different matrixId for the second matrix of size 3 (we use '3' instead of '1').\n    for (int matrixId=0 ; matrixId<6 ; matrixId += (sizeId==3 ? 3 : 1)) {\n      uint8_t* curr_scaling_list = scaling_list[matrixId];\n      int scaling_list_dc_coef;\n\n\n      //printf(\"----- matrix %d\\n\",matrixId);\n\n      char scaling_list_pred_mode_flag = get_bits(br,1);\n      if (!scaling_list_pred_mode_flag) {\n        int scaling_list_pred_matrix_id_delta = get_uvlc(br);\n\n\tif (sizeId==3) {\n\t  // adapt to our changed matrixId for size 3\n\t  scaling_list_pred_matrix_id_delta *= 3;\n\t}\n\t\n        if (scaling_list_pred_matrix_id_delta == UVLC_ERROR ||\n            scaling_list_pred_matrix_id_delta > matrixId) {\n          return DE265_ERROR_CODED_PARAMETER_OUT_OF_RANGE;\n        }\n\n        //printf(\"scaling_list_pred_matrix_id_delta=%d\\n\", scaling_list_pred_matrix_id_delta);\n\n        dc_coeff[sizeId][matrixId] = 16;\n        scaling_list_dc_coef       = 16;\n\n        if (scaling_list_pred_matrix_id_delta==0) {\n          if (sizeId==0) {\n            memcpy(curr_scaling_list, default_ScalingList_4x4, 16);\n          }\n          else {\n            if (matrixId<3)\n              { memcpy(curr_scaling_list, default_ScalingList_8x8_intra,64); }\n            else\n              { memcpy(curr_scaling_list, default_ScalingList_8x8_inter,64); }\n          }\n        }\n        else {\n          if (sizeId==3) { assert(scaling_list_pred_matrix_id_delta==3); }\n\n          int mID = matrixId - scaling_list_pred_matrix_id_delta;\n\n          int len = (sizeId == 0 ? 16 : 64);\n          memcpy(curr_scaling_list, scaling_list[mID], len);\n\n          scaling_list_dc_coef       = dc_coeff[sizeId][mID];\n          dc_coeff[sizeId][matrixId] = dc_coeff[sizeId][mID];\n        }\n      }\n      else {\n        int nextCoef=8;\n        int coefNum = (sizeId==0 ? 16 : 64);\n        if (sizeId>1) {\n          scaling_list_dc_coef = get_svlc(br);\n          if (scaling_list_dc_coef < -7 ||\n              scaling_list_dc_coef > 247) {\n            return DE265_ERROR_CODED_PARAMETER_OUT_OF_RANGE;\n          }\n\n          scaling_list_dc_coef += 8;\n          nextCoef=scaling_list_dc_coef;\n          dc_coeff[sizeId][matrixId] = scaling_list_dc_coef;\n        }\n        else {\n          scaling_list_dc_coef = 16;\n        }\n        //printf(\"DC = %d\\n\",scaling_list_dc_coef);\n\n        for (int i=0;i<coefNum;i++) {\n          int scaling_list_delta_coef = get_svlc(br);\n          if (scaling_list_delta_coef < -128 ||\n              scaling_list_delta_coef >  127) {\n            return DE265_ERROR_CODED_PARAMETER_OUT_OF_RANGE;\n          }\n\n          nextCoef = (nextCoef + scaling_list_delta_coef + 256) % 256;\n          curr_scaling_list[i] = nextCoef;\n          //printf(\"curr %d = %d\\n\",i,nextCoef);\n        }\n      }\n\n\n      // --- generate ScalingFactor arrays ---\n\n      switch (sizeId) {\n      case 0:\n        fill_scaling_factor(&sclist->ScalingFactor_Size0[matrixId][0][0], curr_scaling_list, 0);\n        break;\n\n      case 1:\n        fill_scaling_factor(&sclist->ScalingFactor_Size1[matrixId][0][0], curr_scaling_list, 1);\n        break;\n\n      case 2:\n        fill_scaling_factor(&sclist->ScalingFactor_Size2[matrixId][0][0], curr_scaling_list, 2);\n        sclist->ScalingFactor_Size2[matrixId][0][0] = scaling_list_dc_coef;\n        //printf(\"DC coeff: %d\\n\", scaling_list_dc_coef);\n        break;\n\n      case 3:\n        fill_scaling_factor(&sclist->ScalingFactor_Size3[matrixId][0][0], curr_scaling_list, 3);\n        sclist->ScalingFactor_Size3[matrixId][0][0] = scaling_list_dc_coef;\n        //printf(\"DC coeff: %d\\n\", scaling_list_dc_coef);\n        break;\n      }\n    }\n  }\n\n\n  // --- fill 32x32 matrices for chroma\n\n  const position* scan = get_scan_order(3, 0 /* diag */);\n\t\n  for (int matrixId=0;matrixId<6;matrixId++)\n    if (matrixId!=0 && matrixId!=3) {\n      for (int i=0;i<64;i++) {\n\tint x = scan[i].x;\n\tint y = scan[i].y;\n\tint v = sclist->ScalingFactor_Size1[matrixId][y][x];\n\n\tfor (int dy=0;dy<4;dy++)\n\t  for (int dx=0;dx<4;dx++) {\n\t    sclist->ScalingFactor_Size3[matrixId][4*y+dy][4*x+dx] = v;\n\t  }\n      }\n\n      sclist->ScalingFactor_Size3[matrixId][0][0] = sclist->ScalingFactor_Size1[matrixId][0][0];\n    }\n  \n  return DE265_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,12 +7,10 @@\n     //int n = ((sizeId==3) ? 2 : 6);\n     uint8_t scaling_list[6][32*32];\n \n+    // Note: we use a different matrixId for the second matrix of size 3 (we use '3' instead of '1').\n     for (int matrixId=0 ; matrixId<6 ; matrixId += (sizeId==3 ? 3 : 1)) {\n       uint8_t* curr_scaling_list = scaling_list[matrixId];\n       int scaling_list_dc_coef;\n-\n-      int canonicalMatrixId = matrixId;\n-      if (sizeId==3 && matrixId==1) { canonicalMatrixId=3; }\n \n \n       //printf(\"----- matrix %d\\n\",matrixId);\n@@ -20,6 +18,12 @@\n       char scaling_list_pred_mode_flag = get_bits(br,1);\n       if (!scaling_list_pred_mode_flag) {\n         int scaling_list_pred_matrix_id_delta = get_uvlc(br);\n+\n+\tif (sizeId==3) {\n+\t  // adapt to our changed matrixId for size 3\n+\t  scaling_list_pred_matrix_id_delta *= 3;\n+\t}\n+\t\n         if (scaling_list_pred_matrix_id_delta == UVLC_ERROR ||\n             scaling_list_pred_matrix_id_delta > matrixId) {\n           return DE265_ERROR_CODED_PARAMETER_OUT_OF_RANGE;\n@@ -35,15 +39,14 @@\n             memcpy(curr_scaling_list, default_ScalingList_4x4, 16);\n           }\n           else {\n-            if (canonicalMatrixId<3)\n+            if (matrixId<3)\n               { memcpy(curr_scaling_list, default_ScalingList_8x8_intra,64); }\n             else\n               { memcpy(curr_scaling_list, default_ScalingList_8x8_inter,64); }\n           }\n         }\n         else {\n-          // TODO: CHECK: for sizeID=3 and the second matrix, should we have delta=1 or delta=3 ?\n-          if (sizeId==3) { assert(scaling_list_pred_matrix_id_delta==1); }\n+          if (sizeId==3) { assert(scaling_list_pred_matrix_id_delta==3); }\n \n           int mID = matrixId - scaling_list_pred_matrix_id_delta;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "      int canonicalMatrixId = matrixId;",
                "      if (sizeId==3 && matrixId==1) { canonicalMatrixId=3; }",
                "            if (canonicalMatrixId<3)",
                "          // TODO: CHECK: for sizeID=3 and the second matrix, should we have delta=1 or delta=3 ?",
                "          if (sizeId==3) { assert(scaling_list_pred_matrix_id_delta==1); }"
            ],
            "added_lines": [
                "    // Note: we use a different matrixId for the second matrix of size 3 (we use '3' instead of '1').",
                "",
                "\tif (sizeId==3) {",
                "\t  // adapt to our changed matrixId for size 3",
                "\t  scaling_list_pred_matrix_id_delta *= 3;",
                "\t}",
                "\t",
                "            if (matrixId<3)",
                "          if (sizeId==3) { assert(scaling_list_pred_matrix_id_delta==3); }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46337",
        "func_name": "jerryscript-project/jerryscript/parser_resolve_private_identifier",
        "description": "There is an Assertion 'page_p != NULL' failed at /parser/js/js-parser-mem.c(parser_list_get) in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/b5327cfcb37c9217f3c319d8897934a6da97d5ed",
        "commit_title": "Private identifier resolving should always construct new literal object",
        "commit_text": " This patch fixes #4930.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "void\nparser_resolve_private_identifier (parser_context_t *context_p) /**< context */\n{\n  if ((context_p->global_status_flags & ECMA_PARSE_DIRECT_EVAL) && parser_resolve_private_identifier_eval (context_p))\n  {\n    return;\n  }\n\n  parser_private_context_t *context_iter_p = context_p->private_context_p;\n\n  while (context_iter_p)\n  {\n    if (context_iter_p == NULL || !(context_iter_p->opts & SCANNER_PRIVATE_FIELD_ACTIVE))\n    {\n      parser_raise_error (context_p, PARSER_ERR_UNDECLARED_PRIVATE_FIELD);\n    }\n\n    if (!(context_iter_p->opts & SCANNER_SUCCESSFUL_CLASS_SCAN))\n    {\n      return;\n    }\n\n    parser_private_context_t *private_context_p = context_iter_p;\n\n    if (private_context_p == NULL)\n    {\n      parser_raise_error (context_p, PARSER_ERR_UNDECLARED_PRIVATE_FIELD);\n    }\n\n    scanner_class_private_member_t *ident_iter = private_context_p->members_p;\n\n    while (ident_iter)\n    {\n      if (lexer_compare_identifiers (context_p, &context_p->token.lit_location, &ident_iter->loc))\n      {\n        lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n        return;\n      }\n\n      ident_iter = ident_iter->prev_p;\n    }\n\n    context_iter_p = context_iter_p->prev_p;\n  }\n\n  parser_raise_error (context_p, PARSER_ERR_UNDECLARED_PRIVATE_FIELD);\n}",
        "func": "void\nparser_resolve_private_identifier (parser_context_t *context_p) /**< context */\n{\n  if ((context_p->global_status_flags & ECMA_PARSE_DIRECT_EVAL) && parser_resolve_private_identifier_eval (context_p))\n  {\n    return;\n  }\n\n  parser_private_context_t *context_iter_p = context_p->private_context_p;\n\n  while (context_iter_p)\n  {\n    if (context_iter_p == NULL || !(context_iter_p->opts & SCANNER_PRIVATE_FIELD_ACTIVE))\n    {\n      parser_raise_error (context_p, PARSER_ERR_UNDECLARED_PRIVATE_FIELD);\n    }\n\n    if (!(context_iter_p->opts & SCANNER_SUCCESSFUL_CLASS_SCAN))\n    {\n      lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n      return;\n    }\n\n    parser_private_context_t *private_context_p = context_iter_p;\n\n    if (private_context_p == NULL)\n    {\n      parser_raise_error (context_p, PARSER_ERR_UNDECLARED_PRIVATE_FIELD);\n    }\n\n    scanner_class_private_member_t *ident_iter = private_context_p->members_p;\n\n    while (ident_iter)\n    {\n      if (lexer_compare_identifiers (context_p, &context_p->token.lit_location, &ident_iter->loc))\n      {\n        lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n        return;\n      }\n\n      ident_iter = ident_iter->prev_p;\n    }\n\n    context_iter_p = context_iter_p->prev_p;\n  }\n\n  parser_raise_error (context_p, PARSER_ERR_UNDECLARED_PRIVATE_FIELD);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,7 @@\n \n     if (!(context_iter_p->opts & SCANNER_SUCCESSFUL_CLASS_SCAN))\n     {\n+      lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n       return;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46340",
        "func_name": "jerryscript-project/jerryscript/scanner_scan_bracket",
        "description": "There is an Assertion 'context_p->stack_top_uint8 == SCAN_STACK_TRY_STATEMENT || context_p->stack_top_uint8 == SCAN_STACK_CATCH_STATEMENT' failed at /parser/js/js-scanner.c(scanner_scan_statement_end) in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/338bf4ffb4efdfe0e58b63fbbeeb6630b2057c83",
        "commit_title": "Fix scanning bracketed expressions",
        "commit_text": " Scan 'async' literal with different depth of brackets  This patch fixes #4924. This patch fixes #4748.  JerryScript-DCO-1.0-Signed-off-by: Martin Negyokru negyokru@inf.u-szeged.hu",
        "func_before": "void\nscanner_scan_bracket (parser_context_t *context_p, /**< context */\n                      scanner_context_t *scanner_context_p) /**< scanner context */\n{\n  size_t depth = 0;\n#if JERRY_ESNEXT\n  const uint8_t *arrow_source_p;\n  const uint8_t *async_source_p = NULL;\n  scanner_scan_bracket_arrow_type_t arrow_type = SCANNER_SCAN_BRACKET_NO_ARROW;\n#endif /* JERRY_ESNEXT */\n\n  JERRY_ASSERT (context_p->token.type == LEXER_LEFT_PAREN);\n\n  do\n  {\n#if JERRY_ESNEXT\n    arrow_source_p = context_p->source_p;\n#endif /* JERRY_ESNEXT */\n    depth++;\n    lexer_next_token (context_p);\n  } while (context_p->token.type == LEXER_LEFT_PAREN);\n\n  scanner_context_p->mode = SCAN_MODE_PRIMARY_EXPRESSION;\n\n  switch (context_p->token.type)\n  {\n    case LEXER_LITERAL:\n    {\n      if (context_p->token.lit_location.type != LEXER_IDENT_LITERAL)\n      {\n#if JERRY_ESNEXT\n        arrow_source_p = NULL;\n#endif /* JERRY_ESNEXT */\n        break;\n      }\n\n#if JERRY_ESNEXT\n      const uint8_t *source_p = context_p->source_p;\n\n      if (lexer_check_arrow (context_p))\n      {\n        arrow_source_p = source_p;\n        arrow_type = SCANNER_SCAN_BRACKET_SIMPLE_ARROW;\n        break;\n      }\n\n      size_t total_depth = depth;\n#endif /* JERRY_ESNEXT */\n\n      while (depth > 0 && lexer_check_next_character (context_p, LIT_CHAR_RIGHT_PAREN))\n      {\n        lexer_consume_next_character (context_p);\n        depth--;\n      }\n\n      if (context_p->token.keyword_type == LEXER_KEYW_EVAL\n          && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n      {\n#if JERRY_ESNEXT\n        /* A function call cannot be an eval function. */\n        arrow_source_p = NULL;\n        const uint16_t flags = (uint16_t) (SCANNER_LITERAL_POOL_CAN_EVAL | SCANNER_LITERAL_POOL_HAS_SUPER_REFERENCE);\n#else /* !JERRY_ESNEXT */\n        const uint16_t flags = SCANNER_LITERAL_POOL_CAN_EVAL;\n#endif /* JERRY_ESNEXT */\n\n        scanner_context_p->active_literal_pool_p->status_flags |= flags;\n        break;\n      }\n\n#if JERRY_ESNEXT\n      if (total_depth == depth)\n      {\n        if (lexer_check_arrow_param (context_p))\n        {\n          JERRY_ASSERT (depth > 0);\n          depth--;\n          break;\n        }\n\n        if (JERRY_UNLIKELY (lexer_token_is_async (context_p)))\n        {\n          async_source_p = source_p;\n        }\n      }\n      else if (depth == total_depth - 1)\n      {\n        if (lexer_check_arrow (context_p))\n        {\n          arrow_type = SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG;\n          break;\n        }\n\n        if (context_p->stack_top_uint8 == SCAN_STACK_USE_ASYNC)\n        {\n          scanner_add_async_literal (context_p, scanner_context_p);\n        }\n      }\n\n      arrow_source_p = NULL;\n#endif /* JERRY_ESNEXT */\n      break;\n    }\n#if JERRY_ESNEXT\n    case LEXER_THREE_DOTS:\n    case LEXER_LEFT_SQUARE:\n    case LEXER_LEFT_BRACE:\n    case LEXER_RIGHT_PAREN:\n    {\n      JERRY_ASSERT (depth > 0);\n      depth--;\n      break;\n    }\n#endif /* JERRY_ESNEXT */\n    default:\n    {\n#if JERRY_ESNEXT\n      arrow_source_p = NULL;\n#endif /* JERRY_ESNEXT */\n      break;\n    }\n  }\n\n#if JERRY_ESNEXT\n  if (JERRY_UNLIKELY (scanner_context_p->async_source_p != NULL) && (arrow_source_p == NULL || depth > 0))\n  {\n    scanner_context_p->async_source_p = NULL;\n  }\n#endif /* JERRY_ESNEXT */\n\n  while (depth > 0)\n  {\n    parser_stack_push_uint8 (context_p, SCAN_STACK_PAREN_EXPRESSION);\n    depth--;\n  }\n\n#if JERRY_ESNEXT\n  if (arrow_source_p != NULL)\n  {\n    JERRY_ASSERT (async_source_p == NULL);\n\n    if (arrow_type == SCANNER_SCAN_BRACKET_SIMPLE_ARROW)\n    {\n      scanner_scan_simple_arrow (context_p, scanner_context_p, arrow_source_p);\n      return;\n    }\n\n    parser_stack_push_uint8 (context_p, SCAN_STACK_ARROW_ARGUMENTS);\n\n    uint16_t status_flags = 0;\n\n    if (JERRY_UNLIKELY (scanner_context_p->async_source_p != NULL))\n    {\n      status_flags |= SCANNER_LITERAL_POOL_MAY_ASYNC_ARROW;\n      arrow_source_p = scanner_context_p->async_source_p;\n      scanner_context_p->async_source_p = NULL;\n    }\n\n    scanner_literal_pool_t *literal_pool_p;\n    literal_pool_p = scanner_push_literal_pool (context_p, scanner_context_p, status_flags);\n    literal_pool_p->source_p = arrow_source_p;\n\n    if (arrow_type == SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG)\n    {\n      scanner_append_argument (context_p, scanner_context_p);\n      scanner_detect_eval_call (context_p, scanner_context_p);\n\n      context_p->token.type = LEXER_RIGHT_PAREN;\n      scanner_context_p->mode = SCAN_MODE_PRIMARY_EXPRESSION_END;\n    }\n    else if (context_p->token.type == LEXER_RIGHT_PAREN)\n    {\n      scanner_context_p->mode = SCAN_MODE_PRIMARY_EXPRESSION_END;\n    }\n    else\n    {\n      scanner_check_arrow_arg (context_p, scanner_context_p);\n    }\n  }\n  else if (JERRY_UNLIKELY (async_source_p != NULL))\n  {\n    scanner_context_p->async_source_p = async_source_p;\n    scanner_check_async_function (context_p, scanner_context_p);\n  }\n#endif /* JERRY_ESNEXT */\n}",
        "func": "void\nscanner_scan_bracket (parser_context_t *context_p, /**< context */\n                      scanner_context_t *scanner_context_p) /**< scanner context */\n{\n  size_t depth = 0;\n#if JERRY_ESNEXT\n  const uint8_t *arrow_source_p;\n  const uint8_t *async_source_p = NULL;\n  scanner_scan_bracket_arrow_type_t arrow_type = SCANNER_SCAN_BRACKET_NO_ARROW;\n#endif /* JERRY_ESNEXT */\n\n  JERRY_ASSERT (context_p->token.type == LEXER_LEFT_PAREN);\n\n  do\n  {\n#if JERRY_ESNEXT\n    arrow_source_p = context_p->source_p;\n#endif /* JERRY_ESNEXT */\n    depth++;\n    lexer_next_token (context_p);\n  } while (context_p->token.type == LEXER_LEFT_PAREN);\n\n  scanner_context_p->mode = SCAN_MODE_PRIMARY_EXPRESSION;\n\n  switch (context_p->token.type)\n  {\n    case LEXER_LITERAL:\n    {\n      if (context_p->token.lit_location.type != LEXER_IDENT_LITERAL)\n      {\n#if JERRY_ESNEXT\n        arrow_source_p = NULL;\n#endif /* JERRY_ESNEXT */\n        break;\n      }\n\n#if JERRY_ESNEXT\n      const uint8_t *source_p = context_p->source_p;\n\n      if (lexer_check_arrow (context_p))\n      {\n        arrow_source_p = source_p;\n        arrow_type = SCANNER_SCAN_BRACKET_SIMPLE_ARROW;\n        break;\n      }\n\n      size_t total_depth = depth;\n#endif /* JERRY_ESNEXT */\n\n      while (depth > 0 && lexer_check_next_character (context_p, LIT_CHAR_RIGHT_PAREN))\n      {\n        lexer_consume_next_character (context_p);\n        depth--;\n      }\n\n      if (context_p->token.keyword_type == LEXER_KEYW_EVAL\n          && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n      {\n#if JERRY_ESNEXT\n        /* A function call cannot be an eval function. */\n        arrow_source_p = NULL;\n        const uint16_t flags = (uint16_t) (SCANNER_LITERAL_POOL_CAN_EVAL | SCANNER_LITERAL_POOL_HAS_SUPER_REFERENCE);\n#else /* !JERRY_ESNEXT */\n        const uint16_t flags = SCANNER_LITERAL_POOL_CAN_EVAL;\n#endif /* JERRY_ESNEXT */\n\n        scanner_context_p->active_literal_pool_p->status_flags |= flags;\n        break;\n      }\n\n#if JERRY_ESNEXT\n      if (total_depth == depth)\n      {\n        if (lexer_check_arrow_param (context_p))\n        {\n          JERRY_ASSERT (depth > 0);\n          depth--;\n          break;\n        }\n\n        if (JERRY_UNLIKELY (lexer_token_is_async (context_p)))\n        {\n          async_source_p = source_p;\n        }\n      }\n\n      if (depth == total_depth - 1 && lexer_check_arrow (context_p))\n      {\n        arrow_type = SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG;\n        break;\n      }\n\n      if (context_p->stack_top_uint8 == SCAN_STACK_USE_ASYNC)\n      {\n        scanner_add_async_literal (context_p, scanner_context_p);\n      }\n\n      arrow_source_p = NULL;\n#endif /* JERRY_ESNEXT */\n      break;\n    }\n#if JERRY_ESNEXT\n    case LEXER_THREE_DOTS:\n    case LEXER_LEFT_SQUARE:\n    case LEXER_LEFT_BRACE:\n    case LEXER_RIGHT_PAREN:\n    {\n      JERRY_ASSERT (depth > 0);\n      depth--;\n      break;\n    }\n#endif /* JERRY_ESNEXT */\n    default:\n    {\n#if JERRY_ESNEXT\n      arrow_source_p = NULL;\n#endif /* JERRY_ESNEXT */\n      break;\n    }\n  }\n\n#if JERRY_ESNEXT\n  if (JERRY_UNLIKELY (scanner_context_p->async_source_p != NULL) && (arrow_source_p == NULL || depth > 0))\n  {\n    scanner_context_p->async_source_p = NULL;\n  }\n#endif /* JERRY_ESNEXT */\n\n  while (depth > 0)\n  {\n    parser_stack_push_uint8 (context_p, SCAN_STACK_PAREN_EXPRESSION);\n    depth--;\n  }\n\n#if JERRY_ESNEXT\n  if (arrow_source_p != NULL)\n  {\n    JERRY_ASSERT (async_source_p == NULL);\n\n    if (arrow_type == SCANNER_SCAN_BRACKET_SIMPLE_ARROW)\n    {\n      scanner_scan_simple_arrow (context_p, scanner_context_p, arrow_source_p);\n      return;\n    }\n\n    parser_stack_push_uint8 (context_p, SCAN_STACK_ARROW_ARGUMENTS);\n\n    uint16_t status_flags = 0;\n\n    if (JERRY_UNLIKELY (scanner_context_p->async_source_p != NULL))\n    {\n      status_flags |= SCANNER_LITERAL_POOL_MAY_ASYNC_ARROW;\n      arrow_source_p = scanner_context_p->async_source_p;\n      scanner_context_p->async_source_p = NULL;\n    }\n\n    scanner_literal_pool_t *literal_pool_p;\n    literal_pool_p = scanner_push_literal_pool (context_p, scanner_context_p, status_flags);\n    literal_pool_p->source_p = arrow_source_p;\n\n    if (arrow_type == SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG)\n    {\n      scanner_append_argument (context_p, scanner_context_p);\n      scanner_detect_eval_call (context_p, scanner_context_p);\n\n      context_p->token.type = LEXER_RIGHT_PAREN;\n      scanner_context_p->mode = SCAN_MODE_PRIMARY_EXPRESSION_END;\n    }\n    else if (context_p->token.type == LEXER_RIGHT_PAREN)\n    {\n      scanner_context_p->mode = SCAN_MODE_PRIMARY_EXPRESSION_END;\n    }\n    else\n    {\n      scanner_check_arrow_arg (context_p, scanner_context_p);\n    }\n  }\n  else if (JERRY_UNLIKELY (async_source_p != NULL))\n  {\n    scanner_context_p->async_source_p = async_source_p;\n    scanner_check_async_function (context_p, scanner_context_p);\n  }\n#endif /* JERRY_ESNEXT */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -83,18 +83,16 @@\n           async_source_p = source_p;\n         }\n       }\n-      else if (depth == total_depth - 1)\n+\n+      if (depth == total_depth - 1 && lexer_check_arrow (context_p))\n       {\n-        if (lexer_check_arrow (context_p))\n-        {\n-          arrow_type = SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG;\n-          break;\n-        }\n+        arrow_type = SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG;\n+        break;\n+      }\n \n-        if (context_p->stack_top_uint8 == SCAN_STACK_USE_ASYNC)\n-        {\n-          scanner_add_async_literal (context_p, scanner_context_p);\n-        }\n+      if (context_p->stack_top_uint8 == SCAN_STACK_USE_ASYNC)\n+      {\n+        scanner_add_async_literal (context_p, scanner_context_p);\n       }\n \n       arrow_source_p = NULL;",
        "diff_line_info": {
            "deleted_lines": [
                "      else if (depth == total_depth - 1)",
                "        if (lexer_check_arrow (context_p))",
                "        {",
                "          arrow_type = SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG;",
                "          break;",
                "        }",
                "        if (context_p->stack_top_uint8 == SCAN_STACK_USE_ASYNC)",
                "        {",
                "          scanner_add_async_literal (context_p, scanner_context_p);",
                "        }"
            ],
            "added_lines": [
                "",
                "      if (depth == total_depth - 1 && lexer_check_arrow (context_p))",
                "        arrow_type = SCANNER_SCAN_BRACKET_ARROW_WITH_ONE_ARG;",
                "        break;",
                "      }",
                "      if (context_p->stack_top_uint8 == SCAN_STACK_USE_ASYNC)",
                "      {",
                "        scanner_add_async_literal (context_p, scanner_context_p);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46342",
        "func_name": "jerryscript-project/jerryscript/opfunc_find_private_key",
        "description": "There is an Assertion 'ecma_is_lexical_environment (obj_p) || !ecma_op_object_is_fast_array (obj_p)' failed at /jerry-core/ecma/base/ecma-helpers.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/3f13061e45348d354c63f96199c2a9c23325cae0",
        "commit_title": "Fix fast array objects cannot hold private properties",
        "commit_text": " This patch fixes #4934.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "static ecma_property_t *\nopfunc_find_private_key (ecma_object_t *class_object_p, /**< class environment */\n                         ecma_object_t *obj_p, /**< object */\n                         ecma_string_t *search_key_p, /**< key */\n                         ecma_string_t **out_private_key_p) /**< [out] private key */\n{\n  ecma_string_t *internal_string_p = ecma_get_internal_string (LIT_INTERNAL_MAGIC_STRING_CLASS_PRIVATE_ELEMENTS);\n  ecma_property_t *prop_p = ecma_find_named_property (class_object_p, internal_string_p);\n\n  if (prop_p == NULL)\n  {\n    return NULL;\n  }\n\n  ecma_value_t *collection_p = ECMA_GET_INTERNAL_VALUE_POINTER (ecma_value_t, ECMA_PROPERTY_VALUE_PTR (prop_p)->value);\n  ecma_value_t *current_p = collection_p + 1;\n  ecma_value_t *end_p = ecma_compact_collection_end (collection_p);\n\n  while (current_p < end_p)\n  {\n    current_p++; /* skip kind */\n    ecma_string_t *private_key_p = ecma_get_prop_name_from_value (*current_p++);\n    current_p++; /* skip value */\n\n    JERRY_ASSERT (ecma_prop_name_is_symbol (private_key_p));\n\n    ecma_string_t *private_key_desc_p =\n      ecma_get_string_from_value (((ecma_extended_string_t *) private_key_p)->u.symbol_descriptor);\n\n    if (ecma_compare_ecma_strings (private_key_desc_p, search_key_p))\n    {\n      prop_p = ecma_find_named_property (obj_p, private_key_p);\n\n      if (out_private_key_p)\n      {\n        *out_private_key_p = private_key_p;\n      }\n\n      return prop_p;\n    }\n  }\n\n  return NULL;\n}",
        "func": "static ecma_property_t *\nopfunc_find_private_key (ecma_object_t *class_object_p, /**< class environment */\n                         ecma_object_t *obj_p, /**< object */\n                         ecma_string_t *search_key_p, /**< key */\n                         ecma_string_t **out_private_key_p) /**< [out] private key */\n{\n  if (ecma_op_object_is_fast_array (obj_p))\n  {\n    return NULL;\n  }\n\n  ecma_string_t *internal_string_p = ecma_get_internal_string (LIT_INTERNAL_MAGIC_STRING_CLASS_PRIVATE_ELEMENTS);\n  ecma_property_t *prop_p = ecma_find_named_property (class_object_p, internal_string_p);\n\n  if (prop_p == NULL)\n  {\n    return NULL;\n  }\n\n  ecma_value_t *collection_p = ECMA_GET_INTERNAL_VALUE_POINTER (ecma_value_t, ECMA_PROPERTY_VALUE_PTR (prop_p)->value);\n  ecma_value_t *current_p = collection_p + 1;\n  ecma_value_t *end_p = ecma_compact_collection_end (collection_p);\n\n  while (current_p < end_p)\n  {\n    current_p++; /* skip kind */\n    ecma_string_t *private_key_p = ecma_get_prop_name_from_value (*current_p++);\n    current_p++; /* skip value */\n\n    JERRY_ASSERT (ecma_prop_name_is_symbol (private_key_p));\n\n    ecma_string_t *private_key_desc_p =\n      ecma_get_string_from_value (((ecma_extended_string_t *) private_key_p)->u.symbol_descriptor);\n\n    if (ecma_compare_ecma_strings (private_key_desc_p, search_key_p))\n    {\n      prop_p = ecma_find_named_property (obj_p, private_key_p);\n\n      if (out_private_key_p)\n      {\n        *out_private_key_p = private_key_p;\n      }\n\n      return prop_p;\n    }\n  }\n\n  return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,11 @@\n                          ecma_string_t *search_key_p, /**< key */\n                          ecma_string_t **out_private_key_p) /**< [out] private key */\n {\n+  if (ecma_op_object_is_fast_array (obj_p))\n+  {\n+    return NULL;\n+  }\n+\n   ecma_string_t *internal_string_p = ecma_get_internal_string (LIT_INTERNAL_MAGIC_STRING_CLASS_PRIVATE_ELEMENTS);\n   ecma_property_t *prop_p = ecma_find_named_property (class_object_p, internal_string_p);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (ecma_op_object_is_fast_array (obj_p))",
                "  {",
                "    return NULL;",
                "  }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46343",
        "func_name": "jerryscript-project/jerryscript/parser_parse_class_body",
        "description": "There is an Assertion 'context_p->token.type == LEXER_LITERAL' failed at /jerry-core/parser/js/js-parser-expr.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/604eb531b3a6ca266e8a97eef38ea3412eba6c7e",
        "commit_title": "Fix duplicated private identifier lookup",
        "commit_text": " This patch fixes #4921.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "static bool\nparser_parse_class_body (parser_context_t *context_p, /**< context */\n                         parser_class_literal_opts_t opts, /**< class literal parsing options */\n                         uint16_t class_name_index) /**< class literal index */\n{\n  JERRY_ASSERT (context_p->token.type == LEXER_LEFT_BRACE);\n\n  lexer_literal_t *ctor_literal_p = NULL;\n  lexer_literal_t *static_fields_literal_p = NULL;\n\n  if (opts & PARSER_CLASS_LITERAL_CTOR_PRESENT)\n  {\n    ctor_literal_p = lexer_construct_unused_literal (context_p);\n    parser_emit_cbc_literal (context_p, CBC_PUSH_LITERAL, (uint16_t) (context_p->literal_count++));\n  }\n  else if (opts & PARSER_CLASS_LITERAL_HERTIAGE_PRESENT)\n  {\n    parser_emit_cbc_ext (context_p, CBC_EXT_PUSH_IMPLICIT_CONSTRUCTOR_HERITAGE);\n  }\n  else\n  {\n    parser_emit_cbc_ext (context_p, CBC_EXT_PUSH_IMPLICIT_CONSTRUCTOR);\n  }\n\n  if (class_name_index != PARSER_INVALID_LITERAL_INDEX)\n  {\n    parser_emit_cbc_ext_literal (context_p, CBC_EXT_SET_CLASS_NAME, class_name_index);\n  }\n\n  parser_emit_cbc_ext (context_p, CBC_EXT_INIT_CLASS);\n\n  bool is_static = false;\n  bool is_private = false;\n  size_t fields_size = 0;\n  uint32_t computed_field_count = 0;\n\n  while (true)\n  {\n    if (!is_static)\n    {\n      lexer_skip_empty_statements (context_p);\n    }\n\n    uint32_t flags = (LEXER_OBJ_IDENT_CLASS_IDENTIFIER | LEXER_OBJ_IDENT_SET_FUNCTION_START);\n\n    if (!is_static)\n    {\n      flags |= LEXER_OBJ_IDENT_CLASS_NO_STATIC;\n    }\n\n    if (is_private)\n    {\n      flags |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n    }\n\n    lexer_expect_object_literal_id (context_p, flags);\n\n    if (context_p->token.type == LEXER_RIGHT_BRACE)\n    {\n      JERRY_ASSERT (!is_static);\n      break;\n    }\n\n    if (context_p->token.type == LEXER_HASHMARK)\n    {\n      is_private = true;\n      lexer_next_token (context_p);\n      context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n      continue;\n    }\n\n    if (context_p->token.type == LEXER_KEYW_STATIC)\n    {\n      JERRY_ASSERT (!is_static);\n      is_static = true;\n      continue;\n    }\n\n    if (is_private)\n    {\n      parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n    }\n\n    bool is_constructor_literal = context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p);\n\n    if (is_private && is_constructor_literal && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n    {\n      parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n    }\n\n    if (!is_static && is_constructor_literal)\n    {\n      JERRY_ASSERT (!is_static);\n      JERRY_ASSERT (opts & PARSER_CLASS_LITERAL_CTOR_PRESENT);\n      JERRY_ASSERT (ctor_literal_p != NULL);\n\n      if (ctor_literal_p->type == LEXER_FUNCTION_LITERAL)\n      {\n        /* 14.5.1 */\n        parser_raise_error (context_p, PARSER_ERR_MULTIPLE_CLASS_CONSTRUCTORS);\n      }\n\n      uint32_t constructor_status_flags =\n        (PARSER_FUNCTION_CLOSURE | PARSER_ALLOW_SUPER | PARSER_CLASS_CONSTRUCTOR | PARSER_LEXICAL_ENV_NEEDED);\n\n      if (opts & PARSER_CLASS_LITERAL_HERTIAGE_PRESENT)\n      {\n        constructor_status_flags |= PARSER_ALLOW_SUPER_CALL;\n      }\n\n      if (context_p->status_flags & PARSER_INSIDE_WITH)\n      {\n        constructor_status_flags |= PARSER_INSIDE_WITH;\n      }\n\n      parser_flush_cbc (context_p);\n      ecma_compiled_code_t *compiled_code_p = parser_parse_function (context_p, constructor_status_flags);\n      ctor_literal_p->u.bytecode_p = compiled_code_p;\n      ctor_literal_p->type = LEXER_FUNCTION_LITERAL;\n      continue;\n    }\n\n    bool is_computed = false;\n\n    if (context_p->token.type == LEXER_PROPERTY_GETTER || context_p->token.type == LEXER_PROPERTY_SETTER)\n    {\n      uint16_t literal_index, function_literal_index;\n      bool is_getter = (context_p->token.type == LEXER_PROPERTY_GETTER);\n\n      uint32_t accessor_status_flags = PARSER_FUNCTION_CLOSURE | PARSER_ALLOW_SUPER;\n      accessor_status_flags |= (is_getter ? PARSER_IS_PROPERTY_GETTER : PARSER_IS_PROPERTY_SETTER);\n\n      uint8_t ident_opts = LEXER_OBJ_IDENT_ONLY_IDENTIFIERS;\n\n      if (lexer_check_next_character (context_p, LIT_CHAR_HASHMARK))\n      {\n        lexer_next_token (context_p);\n        context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n        ident_opts |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n        is_private = true;\n      }\n\n      lexer_expect_object_literal_id (context_p, ident_opts);\n\n      if (is_private)\n      {\n        parser_check_duplicated_private_field (context_p,\n                                               is_getter ? SCANNER_PRIVATE_FIELD_GETTER : SCANNER_PRIVATE_FIELD_SETTER);\n      }\n\n      literal_index = context_p->lit_object.index;\n\n      if (context_p->token.type == LEXER_RIGHT_SQUARE)\n      {\n        is_computed = true;\n      }\n      else if (is_static && !is_private)\n      {\n        if (LEXER_IS_IDENT_OR_STRING (context_p->token.lit_location.type)\n            && lexer_compare_identifier_to_string (&context_p->token.lit_location, (uint8_t *) \"prototype\", 9))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_STATIC_PROTOTYPE);\n        }\n      }\n      else if (parser_is_constructor_literal (context_p))\n      {\n        JERRY_ASSERT (!is_static || is_private);\n        parser_raise_error (context_p, PARSER_ERR_CLASS_CONSTRUCTOR_AS_ACCESSOR);\n      }\n\n      function_literal_index = lexer_construct_function_object (context_p, accessor_status_flags);\n\n      parser_emit_cbc_literal (context_p, CBC_PUSH_LITERAL, literal_index);\n\n      JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_LITERAL);\n\n      cbc_ext_opcode_t opcode;\n\n      if (is_computed)\n      {\n        context_p->last_cbc.literal_index = function_literal_index;\n\n        if (is_getter)\n        {\n          opcode = is_static ? CBC_EXT_SET_STATIC_COMPUTED_GETTER : CBC_EXT_SET_COMPUTED_GETTER;\n        }\n        else\n        {\n          opcode = is_static ? CBC_EXT_SET_STATIC_COMPUTED_SETTER : CBC_EXT_SET_COMPUTED_SETTER;\n        }\n      }\n      else\n      {\n        context_p->last_cbc.value = function_literal_index;\n\n        if (is_getter)\n        {\n          opcode = is_static ? (is_private ? CBC_EXT_COLLECT_PRIVATE_STATIC_GETTER : CBC_EXT_SET_STATIC_GETTER)\n                             : (is_private ? CBC_EXT_COLLECT_PRIVATE_GETTER : CBC_EXT_SET_GETTER);\n        }\n        else\n        {\n          opcode = is_static ? (is_private ? CBC_EXT_COLLECT_PRIVATE_STATIC_SETTER : CBC_EXT_SET_STATIC_SETTER)\n                             : (is_private ? CBC_EXT_COLLECT_PRIVATE_SETTER : CBC_EXT_SET_SETTER);\n        }\n      }\n\n      if (is_computed)\n      {\n        parser_emit_cbc_ext (context_p,\n                             is_getter ? CBC_EXT_SET_COMPUTED_GETTER_NAME : CBC_EXT_SET_COMPUTED_SETTER_NAME);\n        parser_emit_cbc_ext (context_p, opcode);\n      }\n      else\n      {\n        if (is_private)\n        {\n          accessor_status_flags |= PARSER_PRIVATE_FUNCTION_NAME;\n        }\n        parser_set_function_name (context_p, function_literal_index, literal_index, accessor_status_flags);\n        context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (opcode);\n      }\n\n      is_static = false;\n      is_private = false;\n      continue;\n    }\n\n    uint32_t status_flags = PARSER_FUNCTION_CLOSURE | PARSER_ALLOW_SUPER;\n\n    if (context_p->token.type == LEXER_KEYW_ASYNC)\n    {\n      status_flags |= PARSER_IS_ASYNC_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n\n      uint8_t ident_opts = LEXER_OBJ_IDENT_ONLY_IDENTIFIERS;\n\n      if (lexer_check_next_character (context_p, LIT_CHAR_HASHMARK))\n      {\n        lexer_next_token (context_p);\n        context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n        ident_opts |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n        is_private = true;\n      }\n\n      if (!lexer_consume_generator (context_p))\n      {\n        lexer_expect_object_literal_id (context_p, ident_opts);\n      }\n\n      if (is_private)\n      {\n        if (context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n        }\n\n        parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n      }\n    }\n\n    if (context_p->token.type == LEXER_MULTIPLY)\n    {\n      uint8_t ident_opts = LEXER_OBJ_IDENT_ONLY_IDENTIFIERS;\n\n      if (lexer_check_next_character (context_p, LIT_CHAR_HASHMARK))\n      {\n        lexer_next_token (context_p);\n        context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n        ident_opts |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n        is_private = true;\n      }\n\n      lexer_expect_object_literal_id (context_p, ident_opts);\n\n      status_flags |= PARSER_IS_GENERATOR_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n\n      if (is_private)\n      {\n        if (context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n        }\n\n        parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n      }\n    }\n\n    bool is_static_block = context_p->token.type == LEXER_LEFT_BRACE;\n\n    if (context_p->token.type == LEXER_RIGHT_SQUARE)\n    {\n      is_computed = true;\n    }\n    else if (!is_static_block && LEXER_IS_IDENT_OR_STRING (context_p->token.lit_location.type))\n    {\n      if (is_static && !is_private)\n      {\n        if (lexer_compare_identifier_to_string (&context_p->token.lit_location, (uint8_t *) \"prototype\", 9))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_STATIC_PROTOTYPE);\n        }\n      }\n      else if ((status_flags & (PARSER_IS_ASYNC_FUNCTION | PARSER_IS_GENERATOR_FUNCTION))\n               && lexer_compare_literal_to_string (context_p, \"constructor\", 11))\n      {\n        parser_raise_error (context_p, PARSER_ERR_INVALID_CLASS_CONSTRUCTOR);\n      }\n    }\n\n    if (!(status_flags & (PARSER_IS_ASYNC_FUNCTION | PARSER_IS_GENERATOR_FUNCTION)))\n    {\n      if (is_static_block || !lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n      {\n        /* Class field. */\n        if (fields_size == 0)\n        {\n          parser_stack_push_uint8 (context_p, PARSER_CLASS_FIELD_END);\n        }\n\n        scanner_range_t range;\n        uint8_t class_field_type = is_static ? PARSER_CLASS_FIELD_STATIC : 0;\n\n        if (!is_computed)\n        {\n          if (is_private)\n          {\n            lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n            uint8_t field_opcode = is_static ? CBC_EXT_COLLECT_PRIVATE_STATIC_FIELD : CBC_EXT_COLLECT_PRIVATE_FIELD;\n            parser_emit_cbc_ext_literal_from_token (context_p, field_opcode);\n          }\n\n          if (is_static && !is_static_block && parser_is_constructor_literal (context_p))\n          {\n            parser_raise_error (context_p, PARSER_ERR_ARGUMENT_LIST_EXPECTED);\n          }\n\n          range.start_location.source_p = context_p->token.lit_location.char_p;\n          range.start_location.line = context_p->token.line;\n          range.start_location.column = context_p->token.column;\n          class_field_type |= PARSER_CLASS_FIELD_NORMAL;\n\n          if (context_p->token.lit_location.type == LEXER_STRING_LITERAL)\n          {\n            range.start_location.source_p--;\n          }\n        }\n        else\n        {\n          if (++computed_field_count > ECMA_INTEGER_NUMBER_MAX)\n          {\n            parser_raise_error (context_p, PARSER_ERR_TOO_MANY_CLASS_FIELDS);\n          }\n\n          if (is_static && static_fields_literal_p == NULL)\n          {\n            static_fields_literal_p = lexer_construct_unused_literal (context_p);\n            parser_emit_cbc_ext_literal (context_p,\n                                         CBC_EXT_PUSH_STATIC_COMPUTED_FIELD_FUNC,\n                                         (uint16_t) (context_p->literal_count++));\n          }\n          else\n          {\n            parser_emit_cbc_ext (context_p,\n                                 (is_static ? CBC_EXT_ADD_STATIC_COMPUTED_FIELD : CBC_EXT_ADD_COMPUTED_FIELD));\n          }\n        }\n\n        if (is_static_block)\n        {\n          class_field_type |= PARSER_CLASS_FIELD_STATIC_BLOCK;\n\n          if (context_p->next_scanner_info_p->type != SCANNER_TYPE_CLASS_STATIC_BLOCK_END)\n          {\n            parser_flush_cbc (context_p);\n            parser_parse_class_static_block (context_p);\n          }\n\n          JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_CLASS_STATIC_BLOCK_END);\n\n          scanner_set_location (context_p, &((scanner_location_info_t *) context_p->next_scanner_info_p)->location);\n          scanner_release_next (context_p, sizeof (scanner_location_info_t));\n          JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_FUNCTION);\n          range.start_location.source_p = context_p->next_scanner_info_p->source_p - 1;\n\n          scanner_seek (context_p);\n\n          parser_stack_push (context_p, &range.start_location, sizeof (scanner_location_t));\n          fields_size += sizeof (scanner_location_t);\n\n          lexer_consume_next_character (context_p);\n        }\n        else if (lexer_consume_assign (context_p))\n        {\n          class_field_type |= PARSER_CLASS_FIELD_INITIALIZED;\n\n          if (context_p->next_scanner_info_p->source_p != context_p->source_p)\n          {\n            lexer_next_token (context_p);\n            parser_parse_expression (context_p, PARSE_EXPR_NO_COMMA);\n            parser_raise_error (context_p, PARSER_ERR_SEMICOLON_EXPECTED);\n          }\n\n          if (is_computed)\n          {\n            scanner_get_location (&range.start_location, context_p);\n          }\n\n          JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_CLASS_FIELD_INITIALIZER_END);\n          range.source_end_p = ((scanner_location_info_t *) context_p->next_scanner_info_p)->location.source_p;\n\n          scanner_set_location (context_p, &((scanner_location_info_t *) context_p->next_scanner_info_p)->location);\n          scanner_release_next (context_p, sizeof (scanner_location_info_t));\n          scanner_seek (context_p);\n\n          parser_stack_push (context_p, &range, sizeof (scanner_range_t));\n          fields_size += sizeof (scanner_range_t);\n        }\n        else\n        {\n          if (!(context_p->token.flags & LEXER_WAS_NEWLINE)\n              && !lexer_check_next_characters (context_p, LIT_CHAR_SEMICOLON, LIT_CHAR_RIGHT_BRACE))\n          {\n            lexer_next_token (context_p);\n            parser_raise_error (context_p, PARSER_ERR_SEMICOLON_EXPECTED);\n          }\n\n          if (!is_computed)\n          {\n            parser_stack_push (context_p, &range.start_location, sizeof (scanner_location_t));\n            fields_size += sizeof (scanner_location_t);\n          }\n        }\n\n        parser_stack_push_uint8 (context_p, class_field_type);\n        fields_size++;\n        is_static = false;\n        is_private = false;\n        continue;\n      }\n\n      if (!is_computed)\n      {\n        if (context_p->token.lit_location.type != LEXER_NUMBER_LITERAL)\n        {\n          JERRY_ASSERT (context_p->token.lit_location.type == LEXER_IDENT_LITERAL\n                        || context_p->token.lit_location.type == LEXER_STRING_LITERAL);\n          if (is_private)\n          {\n            parser_resolve_private_identifier (context_p);\n          }\n          else\n          {\n            lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n          }\n        }\n        else\n        {\n          lexer_construct_number_object (context_p, false, false);\n        }\n      }\n    }\n\n    uint16_t literal_index = context_p->lit_object.index;\n    uint16_t function_literal_index = lexer_construct_function_object (context_p, status_flags | PARSER_IS_METHOD);\n\n    parser_emit_cbc_literal (context_p, CBC_PUSH_LITERAL, function_literal_index);\n\n    if (is_computed)\n    {\n      parser_emit_cbc_ext (context_p, CBC_EXT_SET_COMPUTED_FUNCTION_NAME);\n      parser_emit_cbc_ext (context_p, is_static ? CBC_EXT_SET_STATIC_COMPUTED_PROPERTY : CBC_EXT_SET_COMPUTED_PROPERTY);\n      is_static = false;\n      continue;\n    }\n\n    uint32_t function_name_status_flags = 0;\n\n    if (is_private)\n    {\n      function_name_status_flags = PARSER_PRIVATE_FUNCTION_NAME;\n    }\n\n    parser_set_function_name (context_p, function_literal_index, literal_index, function_name_status_flags);\n\n    JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_LITERAL);\n\n    context_p->last_cbc.value = literal_index;\n\n    if (is_static)\n    {\n      context_p->last_cbc_opcode = (is_private ? PARSER_TO_EXT_OPCODE (CBC_EXT_COLLECT_PRIVATE_STATIC_METHOD)\n                                               : PARSER_TO_EXT_OPCODE (CBC_EXT_SET_STATIC_PROPERTY_LITERAL));\n      is_static = false;\n    }\n    else if (is_private)\n    {\n      context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (CBC_EXT_COLLECT_PRIVATE_METHOD);\n    }\n    else\n    {\n      context_p->last_cbc_opcode = CBC_SET_LITERAL_PROPERTY;\n    }\n\n    is_private = false;\n  }\n\n  if (fields_size == 0)\n  {\n    return false;\n  }\n\n  parser_reverse_class_fields (context_p, fields_size);\n\n  /* Since PARSER_IS_ARROW_FUNCTION and PARSER_CLASS_CONSTRUCTOR bits cannot\n   * be set at the same time, this bit combination triggers class field parsing. */\n\n  if (!(context_p->stack_top_uint8 & PARSER_CLASS_FIELD_STATIC))\n  {\n    lexer_literal_t *literal_p = lexer_construct_unused_literal (context_p);\n\n    uint16_t function_literal_index = (uint16_t) (context_p->literal_count++);\n    parser_emit_cbc_ext_literal (context_p, CBC_EXT_SET_FIELD_INIT, function_literal_index);\n    parser_flush_cbc (context_p);\n\n    literal_p->u.bytecode_p = parser_parse_class_fields (context_p);\n    literal_p->type = LEXER_FUNCTION_LITERAL;\n  }\n\n  bool has_static_field = false;\n\n  if (context_p->stack_top_uint8 & PARSER_CLASS_FIELD_STATIC)\n  {\n    if (static_fields_literal_p == NULL)\n    {\n      static_fields_literal_p = lexer_construct_unused_literal (context_p);\n      uint16_t function_literal_index = (uint16_t) (context_p->literal_count++);\n      parser_emit_cbc_ext_literal (context_p, CBC_EXT_PUSH_STATIC_FIELD_FUNC, function_literal_index);\n    }\n\n    parser_flush_cbc (context_p);\n    static_fields_literal_p->u.bytecode_p = parser_parse_class_fields (context_p);\n    static_fields_literal_p->type = LEXER_FUNCTION_LITERAL;\n\n    has_static_field = true;\n  }\n\n  parser_stack_pop_uint8 (context_p);\n  return has_static_field;\n}",
        "func": "static bool\nparser_parse_class_body (parser_context_t *context_p, /**< context */\n                         parser_class_literal_opts_t opts, /**< class literal parsing options */\n                         uint16_t class_name_index) /**< class literal index */\n{\n  JERRY_ASSERT (context_p->token.type == LEXER_LEFT_BRACE);\n\n  lexer_literal_t *ctor_literal_p = NULL;\n  lexer_literal_t *static_fields_literal_p = NULL;\n\n  if (opts & PARSER_CLASS_LITERAL_CTOR_PRESENT)\n  {\n    ctor_literal_p = lexer_construct_unused_literal (context_p);\n    parser_emit_cbc_literal (context_p, CBC_PUSH_LITERAL, (uint16_t) (context_p->literal_count++));\n  }\n  else if (opts & PARSER_CLASS_LITERAL_HERTIAGE_PRESENT)\n  {\n    parser_emit_cbc_ext (context_p, CBC_EXT_PUSH_IMPLICIT_CONSTRUCTOR_HERITAGE);\n  }\n  else\n  {\n    parser_emit_cbc_ext (context_p, CBC_EXT_PUSH_IMPLICIT_CONSTRUCTOR);\n  }\n\n  if (class_name_index != PARSER_INVALID_LITERAL_INDEX)\n  {\n    parser_emit_cbc_ext_literal (context_p, CBC_EXT_SET_CLASS_NAME, class_name_index);\n  }\n\n  parser_emit_cbc_ext (context_p, CBC_EXT_INIT_CLASS);\n\n  bool is_static = false;\n  bool is_private = false;\n  size_t fields_size = 0;\n  uint32_t computed_field_count = 0;\n\n  while (true)\n  {\n    if (!is_static)\n    {\n      lexer_skip_empty_statements (context_p);\n    }\n\n    uint32_t flags = (LEXER_OBJ_IDENT_CLASS_IDENTIFIER | LEXER_OBJ_IDENT_SET_FUNCTION_START);\n\n    if (!is_static)\n    {\n      flags |= LEXER_OBJ_IDENT_CLASS_NO_STATIC;\n    }\n\n    if (is_private)\n    {\n      flags |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n    }\n\n    lexer_expect_object_literal_id (context_p, flags);\n\n    if (context_p->token.type == LEXER_RIGHT_BRACE)\n    {\n      JERRY_ASSERT (!is_static);\n      break;\n    }\n\n    if (context_p->token.type == LEXER_HASHMARK)\n    {\n      is_private = true;\n      lexer_next_token (context_p);\n      context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n      continue;\n    }\n\n    if (context_p->token.type == LEXER_KEYW_STATIC)\n    {\n      JERRY_ASSERT (!is_static);\n      is_static = true;\n      continue;\n    }\n\n    bool is_constructor_literal = false;\n\n    if (context_p->token.type == LEXER_LITERAL)\n    {\n      is_constructor_literal = parser_is_constructor_literal (context_p);\n\n      if (is_private)\n      {\n        if (is_constructor_literal && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n        }\n\n        parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n      }\n    }\n\n    if (!is_static && is_constructor_literal)\n    {\n      JERRY_ASSERT (!is_static);\n      JERRY_ASSERT (opts & PARSER_CLASS_LITERAL_CTOR_PRESENT);\n      JERRY_ASSERT (ctor_literal_p != NULL);\n\n      if (ctor_literal_p->type == LEXER_FUNCTION_LITERAL)\n      {\n        /* 14.5.1 */\n        parser_raise_error (context_p, PARSER_ERR_MULTIPLE_CLASS_CONSTRUCTORS);\n      }\n\n      uint32_t constructor_status_flags =\n        (PARSER_FUNCTION_CLOSURE | PARSER_ALLOW_SUPER | PARSER_CLASS_CONSTRUCTOR | PARSER_LEXICAL_ENV_NEEDED);\n\n      if (opts & PARSER_CLASS_LITERAL_HERTIAGE_PRESENT)\n      {\n        constructor_status_flags |= PARSER_ALLOW_SUPER_CALL;\n      }\n\n      if (context_p->status_flags & PARSER_INSIDE_WITH)\n      {\n        constructor_status_flags |= PARSER_INSIDE_WITH;\n      }\n\n      parser_flush_cbc (context_p);\n      ecma_compiled_code_t *compiled_code_p = parser_parse_function (context_p, constructor_status_flags);\n      ctor_literal_p->u.bytecode_p = compiled_code_p;\n      ctor_literal_p->type = LEXER_FUNCTION_LITERAL;\n      continue;\n    }\n\n    bool is_computed = false;\n\n    if (context_p->token.type == LEXER_PROPERTY_GETTER || context_p->token.type == LEXER_PROPERTY_SETTER)\n    {\n      uint16_t literal_index, function_literal_index;\n      bool is_getter = (context_p->token.type == LEXER_PROPERTY_GETTER);\n\n      uint32_t accessor_status_flags = PARSER_FUNCTION_CLOSURE | PARSER_ALLOW_SUPER;\n      accessor_status_flags |= (is_getter ? PARSER_IS_PROPERTY_GETTER : PARSER_IS_PROPERTY_SETTER);\n\n      uint8_t ident_opts = LEXER_OBJ_IDENT_ONLY_IDENTIFIERS;\n\n      if (lexer_check_next_character (context_p, LIT_CHAR_HASHMARK))\n      {\n        lexer_next_token (context_p);\n        context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n        ident_opts |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n        is_private = true;\n      }\n\n      lexer_expect_object_literal_id (context_p, ident_opts);\n\n      if (is_private)\n      {\n        parser_check_duplicated_private_field (context_p,\n                                               is_getter ? SCANNER_PRIVATE_FIELD_GETTER : SCANNER_PRIVATE_FIELD_SETTER);\n      }\n\n      literal_index = context_p->lit_object.index;\n\n      if (context_p->token.type == LEXER_RIGHT_SQUARE)\n      {\n        is_computed = true;\n      }\n      else if (is_static && !is_private)\n      {\n        if (LEXER_IS_IDENT_OR_STRING (context_p->token.lit_location.type)\n            && lexer_compare_identifier_to_string (&context_p->token.lit_location, (uint8_t *) \"prototype\", 9))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_STATIC_PROTOTYPE);\n        }\n      }\n      else if (parser_is_constructor_literal (context_p))\n      {\n        JERRY_ASSERT (!is_static || is_private);\n        parser_raise_error (context_p, PARSER_ERR_CLASS_CONSTRUCTOR_AS_ACCESSOR);\n      }\n\n      function_literal_index = lexer_construct_function_object (context_p, accessor_status_flags);\n\n      parser_emit_cbc_literal (context_p, CBC_PUSH_LITERAL, literal_index);\n\n      JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_LITERAL);\n\n      cbc_ext_opcode_t opcode;\n\n      if (is_computed)\n      {\n        context_p->last_cbc.literal_index = function_literal_index;\n\n        if (is_getter)\n        {\n          opcode = is_static ? CBC_EXT_SET_STATIC_COMPUTED_GETTER : CBC_EXT_SET_COMPUTED_GETTER;\n        }\n        else\n        {\n          opcode = is_static ? CBC_EXT_SET_STATIC_COMPUTED_SETTER : CBC_EXT_SET_COMPUTED_SETTER;\n        }\n      }\n      else\n      {\n        context_p->last_cbc.value = function_literal_index;\n\n        if (is_getter)\n        {\n          opcode = is_static ? (is_private ? CBC_EXT_COLLECT_PRIVATE_STATIC_GETTER : CBC_EXT_SET_STATIC_GETTER)\n                             : (is_private ? CBC_EXT_COLLECT_PRIVATE_GETTER : CBC_EXT_SET_GETTER);\n        }\n        else\n        {\n          opcode = is_static ? (is_private ? CBC_EXT_COLLECT_PRIVATE_STATIC_SETTER : CBC_EXT_SET_STATIC_SETTER)\n                             : (is_private ? CBC_EXT_COLLECT_PRIVATE_SETTER : CBC_EXT_SET_SETTER);\n        }\n      }\n\n      if (is_computed)\n      {\n        parser_emit_cbc_ext (context_p,\n                             is_getter ? CBC_EXT_SET_COMPUTED_GETTER_NAME : CBC_EXT_SET_COMPUTED_SETTER_NAME);\n        parser_emit_cbc_ext (context_p, opcode);\n      }\n      else\n      {\n        if (is_private)\n        {\n          accessor_status_flags |= PARSER_PRIVATE_FUNCTION_NAME;\n        }\n        parser_set_function_name (context_p, function_literal_index, literal_index, accessor_status_flags);\n        context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (opcode);\n      }\n\n      is_static = false;\n      is_private = false;\n      continue;\n    }\n\n    uint32_t status_flags = PARSER_FUNCTION_CLOSURE | PARSER_ALLOW_SUPER;\n\n    if (context_p->token.type == LEXER_KEYW_ASYNC)\n    {\n      status_flags |= PARSER_IS_ASYNC_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n\n      uint8_t ident_opts = LEXER_OBJ_IDENT_ONLY_IDENTIFIERS;\n\n      if (lexer_check_next_character (context_p, LIT_CHAR_HASHMARK))\n      {\n        lexer_next_token (context_p);\n        context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n        ident_opts |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n        is_private = true;\n      }\n\n      if (!lexer_consume_generator (context_p))\n      {\n        lexer_expect_object_literal_id (context_p, ident_opts);\n      }\n\n      if (is_private && context_p->token.type == LEXER_LITERAL)\n      {\n        if (parser_is_constructor_literal (context_p))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n        }\n\n        parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n      }\n    }\n\n    if (context_p->token.type == LEXER_MULTIPLY)\n    {\n      uint8_t ident_opts = LEXER_OBJ_IDENT_ONLY_IDENTIFIERS;\n\n      if (lexer_check_next_character (context_p, LIT_CHAR_HASHMARK))\n      {\n        lexer_next_token (context_p);\n        context_p->token.flags |= LEXER_NO_SKIP_SPACES;\n        ident_opts |= LEXER_OBJ_IDENT_CLASS_PRIVATE;\n        is_private = true;\n      }\n\n      lexer_expect_object_literal_id (context_p, ident_opts);\n\n      status_flags |= PARSER_IS_GENERATOR_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n\n      if (is_private && context_p->token.type == LEXER_LITERAL)\n      {\n        if (parser_is_constructor_literal (context_p))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n        }\n\n        parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n      }\n    }\n\n    bool is_static_block = context_p->token.type == LEXER_LEFT_BRACE;\n\n    if (context_p->token.type == LEXER_RIGHT_SQUARE)\n    {\n      is_computed = true;\n    }\n    else if (!is_static_block && LEXER_IS_IDENT_OR_STRING (context_p->token.lit_location.type))\n    {\n      if (is_static && !is_private)\n      {\n        if (lexer_compare_identifier_to_string (&context_p->token.lit_location, (uint8_t *) \"prototype\", 9))\n        {\n          parser_raise_error (context_p, PARSER_ERR_CLASS_STATIC_PROTOTYPE);\n        }\n      }\n      else if ((status_flags & (PARSER_IS_ASYNC_FUNCTION | PARSER_IS_GENERATOR_FUNCTION))\n               && lexer_compare_literal_to_string (context_p, \"constructor\", 11))\n      {\n        parser_raise_error (context_p, PARSER_ERR_INVALID_CLASS_CONSTRUCTOR);\n      }\n    }\n\n    if (!(status_flags & (PARSER_IS_ASYNC_FUNCTION | PARSER_IS_GENERATOR_FUNCTION)))\n    {\n      if (is_static_block || !lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n      {\n        /* Class field. */\n        if (fields_size == 0)\n        {\n          parser_stack_push_uint8 (context_p, PARSER_CLASS_FIELD_END);\n        }\n\n        scanner_range_t range;\n        uint8_t class_field_type = is_static ? PARSER_CLASS_FIELD_STATIC : 0;\n\n        if (!is_computed)\n        {\n          if (is_private)\n          {\n            lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n            uint8_t field_opcode = is_static ? CBC_EXT_COLLECT_PRIVATE_STATIC_FIELD : CBC_EXT_COLLECT_PRIVATE_FIELD;\n            parser_emit_cbc_ext_literal_from_token (context_p, field_opcode);\n          }\n\n          if (is_static && !is_static_block && parser_is_constructor_literal (context_p))\n          {\n            parser_raise_error (context_p, PARSER_ERR_ARGUMENT_LIST_EXPECTED);\n          }\n\n          range.start_location.source_p = context_p->token.lit_location.char_p;\n          range.start_location.line = context_p->token.line;\n          range.start_location.column = context_p->token.column;\n          class_field_type |= PARSER_CLASS_FIELD_NORMAL;\n\n          if (context_p->token.lit_location.type == LEXER_STRING_LITERAL)\n          {\n            range.start_location.source_p--;\n          }\n        }\n        else\n        {\n          if (++computed_field_count > ECMA_INTEGER_NUMBER_MAX)\n          {\n            parser_raise_error (context_p, PARSER_ERR_TOO_MANY_CLASS_FIELDS);\n          }\n\n          if (is_static && static_fields_literal_p == NULL)\n          {\n            static_fields_literal_p = lexer_construct_unused_literal (context_p);\n            parser_emit_cbc_ext_literal (context_p,\n                                         CBC_EXT_PUSH_STATIC_COMPUTED_FIELD_FUNC,\n                                         (uint16_t) (context_p->literal_count++));\n          }\n          else\n          {\n            parser_emit_cbc_ext (context_p,\n                                 (is_static ? CBC_EXT_ADD_STATIC_COMPUTED_FIELD : CBC_EXT_ADD_COMPUTED_FIELD));\n          }\n        }\n\n        if (is_static_block)\n        {\n          class_field_type |= PARSER_CLASS_FIELD_STATIC_BLOCK;\n\n          if (context_p->next_scanner_info_p->type != SCANNER_TYPE_CLASS_STATIC_BLOCK_END)\n          {\n            parser_flush_cbc (context_p);\n            parser_parse_class_static_block (context_p);\n          }\n\n          JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_CLASS_STATIC_BLOCK_END);\n\n          scanner_set_location (context_p, &((scanner_location_info_t *) context_p->next_scanner_info_p)->location);\n          scanner_release_next (context_p, sizeof (scanner_location_info_t));\n          JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_FUNCTION);\n          range.start_location.source_p = context_p->next_scanner_info_p->source_p - 1;\n\n          scanner_seek (context_p);\n\n          parser_stack_push (context_p, &range.start_location, sizeof (scanner_location_t));\n          fields_size += sizeof (scanner_location_t);\n\n          lexer_consume_next_character (context_p);\n        }\n        else if (lexer_consume_assign (context_p))\n        {\n          class_field_type |= PARSER_CLASS_FIELD_INITIALIZED;\n\n          if (context_p->next_scanner_info_p->source_p != context_p->source_p)\n          {\n            lexer_next_token (context_p);\n            parser_parse_expression (context_p, PARSE_EXPR_NO_COMMA);\n            parser_raise_error (context_p, PARSER_ERR_SEMICOLON_EXPECTED);\n          }\n\n          if (is_computed)\n          {\n            scanner_get_location (&range.start_location, context_p);\n          }\n\n          JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_CLASS_FIELD_INITIALIZER_END);\n          range.source_end_p = ((scanner_location_info_t *) context_p->next_scanner_info_p)->location.source_p;\n\n          scanner_set_location (context_p, &((scanner_location_info_t *) context_p->next_scanner_info_p)->location);\n          scanner_release_next (context_p, sizeof (scanner_location_info_t));\n          scanner_seek (context_p);\n\n          parser_stack_push (context_p, &range, sizeof (scanner_range_t));\n          fields_size += sizeof (scanner_range_t);\n        }\n        else\n        {\n          if (!(context_p->token.flags & LEXER_WAS_NEWLINE)\n              && !lexer_check_next_characters (context_p, LIT_CHAR_SEMICOLON, LIT_CHAR_RIGHT_BRACE))\n          {\n            lexer_next_token (context_p);\n            parser_raise_error (context_p, PARSER_ERR_SEMICOLON_EXPECTED);\n          }\n\n          if (!is_computed)\n          {\n            parser_stack_push (context_p, &range.start_location, sizeof (scanner_location_t));\n            fields_size += sizeof (scanner_location_t);\n          }\n        }\n\n        parser_stack_push_uint8 (context_p, class_field_type);\n        fields_size++;\n        is_static = false;\n        is_private = false;\n        continue;\n      }\n\n      if (!is_computed)\n      {\n        if (context_p->token.lit_location.type != LEXER_NUMBER_LITERAL)\n        {\n          JERRY_ASSERT (context_p->token.lit_location.type == LEXER_IDENT_LITERAL\n                        || context_p->token.lit_location.type == LEXER_STRING_LITERAL);\n          if (is_private)\n          {\n            parser_resolve_private_identifier (context_p);\n          }\n          else\n          {\n            lexer_construct_literal_object (context_p, &context_p->token.lit_location, LEXER_STRING_LITERAL);\n          }\n        }\n        else\n        {\n          lexer_construct_number_object (context_p, false, false);\n        }\n      }\n    }\n\n    uint16_t literal_index = context_p->lit_object.index;\n    uint16_t function_literal_index = lexer_construct_function_object (context_p, status_flags | PARSER_IS_METHOD);\n\n    parser_emit_cbc_literal (context_p, CBC_PUSH_LITERAL, function_literal_index);\n\n    if (is_computed)\n    {\n      parser_emit_cbc_ext (context_p, CBC_EXT_SET_COMPUTED_FUNCTION_NAME);\n      parser_emit_cbc_ext (context_p, is_static ? CBC_EXT_SET_STATIC_COMPUTED_PROPERTY : CBC_EXT_SET_COMPUTED_PROPERTY);\n      is_static = false;\n      continue;\n    }\n\n    uint32_t function_name_status_flags = 0;\n\n    if (is_private)\n    {\n      function_name_status_flags = PARSER_PRIVATE_FUNCTION_NAME;\n    }\n\n    parser_set_function_name (context_p, function_literal_index, literal_index, function_name_status_flags);\n\n    JERRY_ASSERT (context_p->last_cbc_opcode == CBC_PUSH_LITERAL);\n\n    context_p->last_cbc.value = literal_index;\n\n    if (is_static)\n    {\n      context_p->last_cbc_opcode = (is_private ? PARSER_TO_EXT_OPCODE (CBC_EXT_COLLECT_PRIVATE_STATIC_METHOD)\n                                               : PARSER_TO_EXT_OPCODE (CBC_EXT_SET_STATIC_PROPERTY_LITERAL));\n      is_static = false;\n    }\n    else if (is_private)\n    {\n      context_p->last_cbc_opcode = PARSER_TO_EXT_OPCODE (CBC_EXT_COLLECT_PRIVATE_METHOD);\n    }\n    else\n    {\n      context_p->last_cbc_opcode = CBC_SET_LITERAL_PROPERTY;\n    }\n\n    is_private = false;\n  }\n\n  if (fields_size == 0)\n  {\n    return false;\n  }\n\n  parser_reverse_class_fields (context_p, fields_size);\n\n  /* Since PARSER_IS_ARROW_FUNCTION and PARSER_CLASS_CONSTRUCTOR bits cannot\n   * be set at the same time, this bit combination triggers class field parsing. */\n\n  if (!(context_p->stack_top_uint8 & PARSER_CLASS_FIELD_STATIC))\n  {\n    lexer_literal_t *literal_p = lexer_construct_unused_literal (context_p);\n\n    uint16_t function_literal_index = (uint16_t) (context_p->literal_count++);\n    parser_emit_cbc_ext_literal (context_p, CBC_EXT_SET_FIELD_INIT, function_literal_index);\n    parser_flush_cbc (context_p);\n\n    literal_p->u.bytecode_p = parser_parse_class_fields (context_p);\n    literal_p->type = LEXER_FUNCTION_LITERAL;\n  }\n\n  bool has_static_field = false;\n\n  if (context_p->stack_top_uint8 & PARSER_CLASS_FIELD_STATIC)\n  {\n    if (static_fields_literal_p == NULL)\n    {\n      static_fields_literal_p = lexer_construct_unused_literal (context_p);\n      uint16_t function_literal_index = (uint16_t) (context_p->literal_count++);\n      parser_emit_cbc_ext_literal (context_p, CBC_EXT_PUSH_STATIC_FIELD_FUNC, function_literal_index);\n    }\n\n    parser_flush_cbc (context_p);\n    static_fields_literal_p->u.bytecode_p = parser_parse_class_fields (context_p);\n    static_fields_literal_p->type = LEXER_FUNCTION_LITERAL;\n\n    has_static_field = true;\n  }\n\n  parser_stack_pop_uint8 (context_p);\n  return has_static_field;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -76,16 +76,21 @@\n       continue;\n     }\n \n-    if (is_private)\n-    {\n-      parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n-    }\n-\n-    bool is_constructor_literal = context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p);\n-\n-    if (is_private && is_constructor_literal && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n-    {\n-      parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n+    bool is_constructor_literal = false;\n+\n+    if (context_p->token.type == LEXER_LITERAL)\n+    {\n+      is_constructor_literal = parser_is_constructor_literal (context_p);\n+\n+      if (is_private)\n+      {\n+        if (is_constructor_literal && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))\n+        {\n+          parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n+        }\n+\n+        parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);\n+      }\n     }\n \n     if (!is_static && is_constructor_literal)\n@@ -247,9 +252,9 @@\n         lexer_expect_object_literal_id (context_p, ident_opts);\n       }\n \n-      if (is_private)\n-      {\n-        if (context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p))\n+      if (is_private && context_p->token.type == LEXER_LITERAL)\n+      {\n+        if (parser_is_constructor_literal (context_p))\n         {\n           parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n         }\n@@ -274,9 +279,9 @@\n \n       status_flags |= PARSER_IS_GENERATOR_FUNCTION | PARSER_DISALLOW_AWAIT_YIELD;\n \n-      if (is_private)\n-      {\n-        if (context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p))\n+      if (is_private && context_p->token.type == LEXER_LITERAL)\n+      {\n+        if (parser_is_constructor_literal (context_p))\n         {\n           parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (is_private)",
                "    {",
                "      parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);",
                "    }",
                "",
                "    bool is_constructor_literal = context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p);",
                "",
                "    if (is_private && is_constructor_literal && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))",
                "    {",
                "      parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);",
                "      if (is_private)",
                "      {",
                "        if (context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p))",
                "      if (is_private)",
                "      {",
                "        if (context_p->token.type == LEXER_LITERAL && parser_is_constructor_literal (context_p))"
            ],
            "added_lines": [
                "    bool is_constructor_literal = false;",
                "",
                "    if (context_p->token.type == LEXER_LITERAL)",
                "    {",
                "      is_constructor_literal = parser_is_constructor_literal (context_p);",
                "",
                "      if (is_private)",
                "      {",
                "        if (is_constructor_literal && lexer_check_next_character (context_p, LIT_CHAR_LEFT_PAREN))",
                "        {",
                "          parser_raise_error (context_p, PARSER_ERR_CLASS_PRIVATE_CONSTRUCTOR);",
                "        }",
                "",
                "        parser_check_duplicated_private_field (context_p, SCANNER_PRIVATE_FIELD_PROPERTY_GETTER_SETTER);",
                "      }",
                "      if (is_private && context_p->token.type == LEXER_LITERAL)",
                "      {",
                "        if (parser_is_constructor_literal (context_p))",
                "      if (is_private && context_p->token.type == LEXER_LITERAL)",
                "      {",
                "        if (parser_is_constructor_literal (context_p))"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46344",
        "func_name": "jerryscript-project/jerryscript/parser_parse_object_initializer",
        "description": "There is an Assertion 'flags & PARSER_PATTERN_HAS_REST_ELEMENT' failed at /jerry-core/parser/js/js-parser-expr.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/9a8cf58f2252aa825049e9d2fd5071983c6a20be",
        "commit_title": "Check rest initializer existence after pattern finalization",
        "commit_text": " Since the scanner info is not present for invalid destructuring patterns we can only ensure the existence of the rest element after the pattern is finalized. This patch fixes #4928.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "static void\nparser_parse_object_initializer (parser_context_t *context_p, /**< context */\n                                 parser_pattern_flags_t flags) /**< flags */\n{\n  parser_pattern_end_marker_t end_pos = parser_pattern_get_target (context_p, flags);\n\n  /* 12.14.5.2:  ObjectAssignmentPattern : { } */\n  if (lexer_check_next_character (context_p, LIT_CHAR_RIGHT_BRACE))\n  {\n    parser_emit_cbc_ext (context_p, CBC_EXT_REQUIRE_OBJECT_COERCIBLE);\n    lexer_consume_next_character (context_p);\n    parser_pattern_finalize (context_p, flags, &end_pos);\n    return;\n  }\n\n  cbc_ext_opcode_t context_opcode = CBC_EXT_OBJ_INIT_CONTEXT_CREATE;\n\n  if (flags & PARSER_PATTERN_HAS_REST_ELEMENT)\n  {\n    context_opcode = CBC_EXT_OBJ_INIT_REST_CONTEXT_CREATE;\n  }\n\n  parser_emit_cbc_ext (context_p, context_opcode);\n\n  while (true)\n  {\n    lexer_expect_object_literal_id (context_p, LEXER_OBJ_IDENT_OBJECT_PATTERN);\n\n    uint16_t prop_index = context_p->lit_object.index;\n    parser_line_counter_t start_line = context_p->token.line;\n    parser_line_counter_t start_column = context_p->token.column;\n    uint16_t push_prop_opcode = CBC_EXT_INITIALIZER_PUSH_PROP_LITERAL;\n\n    if (context_p->token.type == LEXER_RIGHT_BRACE)\n    {\n      break;\n    }\n\n    if (context_p->token.type == LEXER_THREE_DOTS)\n    {\n      lexer_next_token (context_p);\n\n      flags |= PARSER_PATTERN_REST_ELEMENT;\n\n      if (parser_pattern_process_assignment (context_p,\n                                             flags,\n                                             CBC_EXT_OBJ_INIT_PUSH_REST,\n                                             PARSER_PATTERN_RHS_NO_LIT,\n                                             LEXER_RIGHT_BRACE))\n      {\n        parser_raise_error (context_p, PARSER_ERR_INVALID_LHS_ASSIGNMENT);\n      }\n\n      if (context_p->token.type != LEXER_RIGHT_BRACE)\n      {\n        parser_raise_error (context_p, PARSER_ERR_RIGHT_BRACE_EXPECTED);\n      }\n\n      /* Checked at the end because there might be syntax errors before. */\n      JERRY_ASSERT (flags & PARSER_PATTERN_HAS_REST_ELEMENT);\n      break;\n    }\n\n    if (context_p->token.type == LEXER_RIGHT_SQUARE)\n    {\n      prop_index = PARSER_PATTERN_RHS_NO_LIT;\n      push_prop_opcode =\n        ((flags & PARSER_PATTERN_HAS_REST_ELEMENT) ? CBC_EXT_INITIALIZER_PUSH_NAME : CBC_EXT_INITIALIZER_PUSH_PROP);\n    }\n    else if (flags & PARSER_PATTERN_HAS_REST_ELEMENT)\n    {\n      push_prop_opcode = CBC_EXT_INITIALIZER_PUSH_NAME_LITERAL;\n    }\n\n    if (context_p->next_scanner_info_p->source_p == context_p->source_p)\n    {\n      JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED);\n      parser_raise_error (context_p, PARSER_ERR_VARIABLE_REDECLARED);\n    }\n\n    lexer_next_token (context_p);\n\n    if (context_p->token.type == LEXER_COLON)\n    {\n      lexer_next_token (context_p);\n      parser_pattern_process_assignment (context_p, flags, push_prop_opcode, prop_index, LEXER_RIGHT_BRACE);\n    }\n    else\n    {\n      if (push_prop_opcode == CBC_EXT_INITIALIZER_PUSH_NAME || push_prop_opcode == CBC_EXT_INITIALIZER_PUSH_PROP)\n      {\n        parser_raise_error (context_p, PARSER_ERR_COLON_EXPECTED);\n      }\n\n      if (context_p->token.type != LEXER_RIGHT_BRACE && context_p->token.type != LEXER_ASSIGN\n          && context_p->token.type != LEXER_COMMA)\n      {\n        parser_raise_error (context_p, PARSER_ERR_OBJECT_ITEM_SEPARATOR_EXPECTED);\n      }\n\n      parser_reparse_as_common_identifier (context_p, start_line, start_column);\n\n      if (flags & PARSER_PATTERN_ARGUMENTS)\n      {\n        if (context_p->lit_object.literal_p->status_flags & LEXER_FLAG_FUNCTION_ARGUMENT)\n        {\n          parser_raise_error (context_p, PARSER_ERR_VARIABLE_REDECLARED);\n        }\n        context_p->lit_object.literal_p->status_flags |= LEXER_FLAG_FUNCTION_ARGUMENT;\n      }\n\n#if JERRY_MODULE_SYSTEM\n      parser_module_append_export_name (context_p);\n#endif /* JERRY_MODULE_SYSTEM */\n\n      parser_emit_cbc_literal_from_token (context_p, CBC_PUSH_LITERAL);\n\n      lexer_next_token (context_p);\n      JERRY_ASSERT (context_p->token.type == LEXER_RIGHT_BRACE || context_p->token.type == LEXER_ASSIGN\n                    || context_p->token.type == LEXER_COMMA);\n\n      parser_pattern_form_assignment (context_p, flags, push_prop_opcode, prop_index, start_line);\n#if JERRY_LINE_INFO\n      parser_line_info_append (context_p, start_line, start_column);\n#endif /* JERRY_LINE_INFO */\n    }\n\n    if (context_p->token.type == LEXER_RIGHT_BRACE)\n    {\n      break;\n    }\n    else if (context_p->token.type != LEXER_COMMA)\n    {\n      parser_raise_error (context_p, PARSER_ERR_OBJECT_ITEM_SEPARATOR_EXPECTED);\n    }\n  }\n\n  if (flags & PARSER_PATTERN_HAS_REST_ELEMENT)\n  {\n    PARSER_MINUS_EQUAL_U16 (context_p->stack_depth,\n                            (PARSER_OBJ_INIT_REST_CONTEXT_STACK_ALLOCATION - PARSER_OBJ_INIT_CONTEXT_STACK_ALLOCATION));\n  }\n\n  parser_emit_cbc_ext (context_p, CBC_EXT_OBJ_INIT_CONTEXT_END);\n\n  parser_pattern_finalize (context_p, flags, &end_pos);\n}",
        "func": "static void\nparser_parse_object_initializer (parser_context_t *context_p, /**< context */\n                                 parser_pattern_flags_t flags) /**< flags */\n{\n  parser_pattern_end_marker_t end_pos = parser_pattern_get_target (context_p, flags);\n\n  /* 12.14.5.2:  ObjectAssignmentPattern : { } */\n  if (lexer_check_next_character (context_p, LIT_CHAR_RIGHT_BRACE))\n  {\n    parser_emit_cbc_ext (context_p, CBC_EXT_REQUIRE_OBJECT_COERCIBLE);\n    lexer_consume_next_character (context_p);\n    parser_pattern_finalize (context_p, flags, &end_pos);\n    return;\n  }\n\n#ifndef JERRY_NDEBUG\n  bool rest_found = false;\n#endif /* !defined(JERRY_NDEBUG) */\n\n  cbc_ext_opcode_t context_opcode = CBC_EXT_OBJ_INIT_CONTEXT_CREATE;\n\n  if (flags & PARSER_PATTERN_HAS_REST_ELEMENT)\n  {\n    context_opcode = CBC_EXT_OBJ_INIT_REST_CONTEXT_CREATE;\n  }\n\n  parser_emit_cbc_ext (context_p, context_opcode);\n\n  while (true)\n  {\n    lexer_expect_object_literal_id (context_p, LEXER_OBJ_IDENT_OBJECT_PATTERN);\n\n    uint16_t prop_index = context_p->lit_object.index;\n    parser_line_counter_t start_line = context_p->token.line;\n    parser_line_counter_t start_column = context_p->token.column;\n    uint16_t push_prop_opcode = CBC_EXT_INITIALIZER_PUSH_PROP_LITERAL;\n\n    if (context_p->token.type == LEXER_RIGHT_BRACE)\n    {\n      break;\n    }\n\n    if (context_p->token.type == LEXER_THREE_DOTS)\n    {\n      lexer_next_token (context_p);\n\n      flags |= PARSER_PATTERN_REST_ELEMENT;\n\n      if (parser_pattern_process_assignment (context_p,\n                                             flags,\n                                             CBC_EXT_OBJ_INIT_PUSH_REST,\n                                             PARSER_PATTERN_RHS_NO_LIT,\n                                             LEXER_RIGHT_BRACE))\n      {\n        parser_raise_error (context_p, PARSER_ERR_INVALID_LHS_ASSIGNMENT);\n      }\n\n      if (context_p->token.type != LEXER_RIGHT_BRACE)\n      {\n        parser_raise_error (context_p, PARSER_ERR_RIGHT_BRACE_EXPECTED);\n      }\n\n#ifndef JERRY_NDEBUG\n      rest_found = true;\n#endif /* !defined(JERRY_NDEBUG) */\n      break;\n    }\n\n    if (context_p->token.type == LEXER_RIGHT_SQUARE)\n    {\n      prop_index = PARSER_PATTERN_RHS_NO_LIT;\n      push_prop_opcode =\n        ((flags & PARSER_PATTERN_HAS_REST_ELEMENT) ? CBC_EXT_INITIALIZER_PUSH_NAME : CBC_EXT_INITIALIZER_PUSH_PROP);\n    }\n    else if (flags & PARSER_PATTERN_HAS_REST_ELEMENT)\n    {\n      push_prop_opcode = CBC_EXT_INITIALIZER_PUSH_NAME_LITERAL;\n    }\n\n    if (context_p->next_scanner_info_p->source_p == context_p->source_p)\n    {\n      JERRY_ASSERT (context_p->next_scanner_info_p->type == SCANNER_TYPE_ERR_REDECLARED);\n      parser_raise_error (context_p, PARSER_ERR_VARIABLE_REDECLARED);\n    }\n\n    lexer_next_token (context_p);\n\n    if (context_p->token.type == LEXER_COLON)\n    {\n      lexer_next_token (context_p);\n      parser_pattern_process_assignment (context_p, flags, push_prop_opcode, prop_index, LEXER_RIGHT_BRACE);\n    }\n    else\n    {\n      if (push_prop_opcode == CBC_EXT_INITIALIZER_PUSH_NAME || push_prop_opcode == CBC_EXT_INITIALIZER_PUSH_PROP)\n      {\n        parser_raise_error (context_p, PARSER_ERR_COLON_EXPECTED);\n      }\n\n      if (context_p->token.type != LEXER_RIGHT_BRACE && context_p->token.type != LEXER_ASSIGN\n          && context_p->token.type != LEXER_COMMA)\n      {\n        parser_raise_error (context_p, PARSER_ERR_OBJECT_ITEM_SEPARATOR_EXPECTED);\n      }\n\n      parser_reparse_as_common_identifier (context_p, start_line, start_column);\n\n      if (flags & PARSER_PATTERN_ARGUMENTS)\n      {\n        if (context_p->lit_object.literal_p->status_flags & LEXER_FLAG_FUNCTION_ARGUMENT)\n        {\n          parser_raise_error (context_p, PARSER_ERR_VARIABLE_REDECLARED);\n        }\n        context_p->lit_object.literal_p->status_flags |= LEXER_FLAG_FUNCTION_ARGUMENT;\n      }\n\n#if JERRY_MODULE_SYSTEM\n      parser_module_append_export_name (context_p);\n#endif /* JERRY_MODULE_SYSTEM */\n\n      parser_emit_cbc_literal_from_token (context_p, CBC_PUSH_LITERAL);\n\n      lexer_next_token (context_p);\n      JERRY_ASSERT (context_p->token.type == LEXER_RIGHT_BRACE || context_p->token.type == LEXER_ASSIGN\n                    || context_p->token.type == LEXER_COMMA);\n\n      parser_pattern_form_assignment (context_p, flags, push_prop_opcode, prop_index, start_line);\n#if JERRY_LINE_INFO\n      parser_line_info_append (context_p, start_line, start_column);\n#endif /* JERRY_LINE_INFO */\n    }\n\n    if (context_p->token.type == LEXER_RIGHT_BRACE)\n    {\n      break;\n    }\n    else if (context_p->token.type != LEXER_COMMA)\n    {\n      parser_raise_error (context_p, PARSER_ERR_OBJECT_ITEM_SEPARATOR_EXPECTED);\n    }\n  }\n\n  if (flags & PARSER_PATTERN_HAS_REST_ELEMENT)\n  {\n    PARSER_MINUS_EQUAL_U16 (context_p->stack_depth,\n                            (PARSER_OBJ_INIT_REST_CONTEXT_STACK_ALLOCATION - PARSER_OBJ_INIT_CONTEXT_STACK_ALLOCATION));\n  }\n\n  parser_emit_cbc_ext (context_p, CBC_EXT_OBJ_INIT_CONTEXT_END);\n\n  parser_pattern_finalize (context_p, flags, &end_pos);\n\n#ifndef JERRY_NDEBUG\n  /* Checked at the end because there might be syntax errors before. */\n  JERRY_ASSERT (!!(flags & PARSER_PATTERN_HAS_REST_ELEMENT) == rest_found);\n#endif /* !defined(JERRY_NDEBUG) */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,10 @@\n     parser_pattern_finalize (context_p, flags, &end_pos);\n     return;\n   }\n+\n+#ifndef JERRY_NDEBUG\n+  bool rest_found = false;\n+#endif /* !defined(JERRY_NDEBUG) */\n \n   cbc_ext_opcode_t context_opcode = CBC_EXT_OBJ_INIT_CONTEXT_CREATE;\n \n@@ -56,8 +60,9 @@\n         parser_raise_error (context_p, PARSER_ERR_RIGHT_BRACE_EXPECTED);\n       }\n \n-      /* Checked at the end because there might be syntax errors before. */\n-      JERRY_ASSERT (flags & PARSER_PATTERN_HAS_REST_ELEMENT);\n+#ifndef JERRY_NDEBUG\n+      rest_found = true;\n+#endif /* !defined(JERRY_NDEBUG) */\n       break;\n     }\n \n@@ -144,4 +149,9 @@\n   parser_emit_cbc_ext (context_p, CBC_EXT_OBJ_INIT_CONTEXT_END);\n \n   parser_pattern_finalize (context_p, flags, &end_pos);\n+\n+#ifndef JERRY_NDEBUG\n+  /* Checked at the end because there might be syntax errors before. */\n+  JERRY_ASSERT (!!(flags & PARSER_PATTERN_HAS_REST_ELEMENT) == rest_found);\n+#endif /* !defined(JERRY_NDEBUG) */\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      /* Checked at the end because there might be syntax errors before. */",
                "      JERRY_ASSERT (flags & PARSER_PATTERN_HAS_REST_ELEMENT);"
            ],
            "added_lines": [
                "",
                "#ifndef JERRY_NDEBUG",
                "  bool rest_found = false;",
                "#endif /* !defined(JERRY_NDEBUG) */",
                "#ifndef JERRY_NDEBUG",
                "      rest_found = true;",
                "#endif /* !defined(JERRY_NDEBUG) */",
                "",
                "#ifndef JERRY_NDEBUG",
                "  /* Checked at the end because there might be syntax errors before. */",
                "  JERRY_ASSERT (!!(flags & PARSER_PATTERN_HAS_REST_ELEMENT) == rest_found);",
                "#endif /* !defined(JERRY_NDEBUG) */"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46345",
        "func_name": "jerryscript-project/jerryscript/lit_convert_cesu8_string_to_utf8_string",
        "description": "There is an Assertion 'cesu8_cursor_p == cesu8_end_p' failed at /jerry-core/lit/lit-strings.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/e54c980de52416e41296545e7f5b210a53b31d12",
        "commit_title": "Fix invalid assertion CESU8-UTF8 buffer copy",
        "commit_text": " The UTF8 buffer size can be smaller then the CESU8 string's size so the UTF8 output is may truncated. Therefore we cannot ensure that the CESU8 buffer is read until the end. This patch fixes #4920.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "lit_utf8_size_t\nlit_convert_cesu8_string_to_utf8_string (const lit_utf8_byte_t *cesu8_string_p, /**< cesu-8 string */\n                                         lit_utf8_size_t cesu8_size, /**< size of cesu-8 string */\n                                         lit_utf8_byte_t *utf8_string_p, /**< destination utf-8 buffer pointer\n                                                                          * (can be NULL if buffer_size == 0) */\n                                         lit_utf8_size_t utf8_size) /**< size of utf-8 buffer */\n{\n  const lit_utf8_byte_t *cesu8_cursor_p = cesu8_string_p;\n  const lit_utf8_byte_t *cesu8_end_p = cesu8_string_p + cesu8_size;\n\n  lit_utf8_byte_t *utf8_cursor_p = utf8_string_p;\n  lit_utf8_byte_t *utf8_end_p = utf8_string_p + utf8_size;\n\n  while (cesu8_cursor_p < cesu8_end_p)\n  {\n    lit_code_point_t cp;\n    lit_utf8_size_t read_size = lit_read_code_point_from_cesu8 (cesu8_cursor_p, cesu8_end_p, &cp);\n    lit_utf8_size_t encoded_size = (cp >= LIT_UTF16_FIRST_SURROGATE_CODE_POINT) ? 4 : read_size;\n\n    if (utf8_cursor_p + encoded_size > utf8_end_p)\n    {\n      break;\n    }\n\n    if (cp >= LIT_UTF16_FIRST_SURROGATE_CODE_POINT)\n    {\n      lit_code_point_to_utf8 (cp, utf8_cursor_p);\n    }\n    else\n    {\n      memcpy (utf8_cursor_p, cesu8_cursor_p, encoded_size);\n    }\n\n    utf8_cursor_p += encoded_size;\n    cesu8_cursor_p += read_size;\n  }\n\n  JERRY_ASSERT (cesu8_cursor_p == cesu8_end_p);\n  JERRY_ASSERT (utf8_cursor_p <= utf8_end_p);\n\n  return (lit_utf8_byte_t) (utf8_cursor_p - utf8_string_p);\n}",
        "func": "lit_utf8_size_t\nlit_convert_cesu8_string_to_utf8_string (const lit_utf8_byte_t *cesu8_string_p, /**< cesu-8 string */\n                                         lit_utf8_size_t cesu8_size, /**< size of cesu-8 string */\n                                         lit_utf8_byte_t *utf8_string_p, /**< destination utf-8 buffer pointer\n                                                                          * (can be NULL if buffer_size == 0) */\n                                         lit_utf8_size_t utf8_size) /**< size of utf-8 buffer */\n{\n  const lit_utf8_byte_t *cesu8_cursor_p = cesu8_string_p;\n  const lit_utf8_byte_t *cesu8_end_p = cesu8_string_p + cesu8_size;\n\n  lit_utf8_byte_t *utf8_cursor_p = utf8_string_p;\n  lit_utf8_byte_t *utf8_end_p = utf8_string_p + utf8_size;\n\n  while (cesu8_cursor_p < cesu8_end_p)\n  {\n    lit_code_point_t cp;\n    lit_utf8_size_t read_size = lit_read_code_point_from_cesu8 (cesu8_cursor_p, cesu8_end_p, &cp);\n    lit_utf8_size_t encoded_size = (cp >= LIT_UTF16_FIRST_SURROGATE_CODE_POINT) ? 4 : read_size;\n\n    if (utf8_cursor_p + encoded_size > utf8_end_p)\n    {\n      break;\n    }\n\n    if (cp >= LIT_UTF16_FIRST_SURROGATE_CODE_POINT)\n    {\n      lit_code_point_to_utf8 (cp, utf8_cursor_p);\n    }\n    else\n    {\n      memcpy (utf8_cursor_p, cesu8_cursor_p, encoded_size);\n    }\n\n    utf8_cursor_p += encoded_size;\n    cesu8_cursor_p += read_size;\n  }\n\n  JERRY_ASSERT (cesu8_cursor_p <= cesu8_end_p);\n  JERRY_ASSERT (utf8_cursor_p <= utf8_end_p);\n\n  return (lit_utf8_byte_t) (utf8_cursor_p - utf8_string_p);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,7 +35,7 @@\n     cesu8_cursor_p += read_size;\n   }\n \n-  JERRY_ASSERT (cesu8_cursor_p == cesu8_end_p);\n+  JERRY_ASSERT (cesu8_cursor_p <= cesu8_end_p);\n   JERRY_ASSERT (utf8_cursor_p <= utf8_end_p);\n \n   return (lit_utf8_byte_t) (utf8_cursor_p - utf8_string_p);",
        "diff_line_info": {
            "deleted_lines": [
                "  JERRY_ASSERT (cesu8_cursor_p == cesu8_end_p);"
            ],
            "added_lines": [
                "  JERRY_ASSERT (cesu8_cursor_p <= cesu8_end_p);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46346",
        "func_name": "jerryscript-project/jerryscript/ecma_builtin_date_prototype_dispatch_set",
        "description": "There is an Assertion 'local_tza == ecma_date_local_time_zone_adjustment (date_value)' failed at /jerry-core/ecma/builtin-objects/ecma-builtin-date-prototype.c(ecma_builtin_date_prototype_dispatch_set):421 in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/3a9bd349c55799db2cbf74e36b68f21617ade4f2",
        "commit_title": "Date.prototype.setYear should invalidate cached tza",
        "commit_text": " This patch fixes #4939 and fixes #4940.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "static ecma_value_t\necma_builtin_date_prototype_dispatch_set (uint16_t builtin_routine_id, /**< built-in wide routine\n                                                                        *   identifier */\n                                          ecma_object_t *object_p, /**< date object */\n                                          const ecma_value_t arguments_list[], /**< list of arguments\n                                                                                *   passed to routine */\n                                          uint32_t arguments_number) /**< length of arguments' list */\n{\n  ecma_number_t converted_number[4];\n  uint32_t conversions = 0;\n\n  /* If the first argument is not specified, it is always converted to NaN. */\n  converted_number[0] = ecma_number_make_nan ();\n\n  switch (builtin_routine_id)\n  {\n#if JERRY_BUILTIN_ANNEXB\n    case ECMA_DATE_PROTOTYPE_SET_YEAR:\n#endif /* JERRY_BUILTIN_ANNEXB */\n    case ECMA_DATE_PROTOTYPE_SET_DATE:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_DATE:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_MILLISECONDS:\n    case ECMA_DATE_PROTOTYPE_SET_MILLISECONDS:\n    {\n      conversions = 1;\n      break;\n    }\n    case ECMA_DATE_PROTOTYPE_SET_MONTH:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_MONTH:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_SECONDS:\n    case ECMA_DATE_PROTOTYPE_SET_SECONDS:\n    {\n      conversions = 2;\n      break;\n    }\n    case ECMA_DATE_PROTOTYPE_SET_FULL_YEAR:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_FULL_YEAR:\n    case ECMA_DATE_PROTOTYPE_SET_MINUTES:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_MINUTES:\n    {\n      conversions = 3;\n      break;\n    }\n    default:\n    {\n      JERRY_ASSERT (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_HOURS\n                    || builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_UTC_HOURS);\n\n      conversions = 4;\n      break;\n    }\n  }\n\n  if (conversions > arguments_number)\n  {\n    conversions = arguments_number;\n  }\n\n  for (uint32_t i = 0; i < conversions; i++)\n  {\n    ecma_value_t value = ecma_op_to_number (arguments_list[i], &converted_number[i]);\n\n    if (ECMA_IS_VALUE_ERROR (value))\n    {\n      return value;\n    }\n  }\n\n#if JERRY_ESNEXT\n  ecma_date_object_t *date_object_p = (ecma_date_object_t *) object_p;\n  ecma_number_t *date_value_p = &date_object_p->date_value;\n#else /* !JERRY_ESNEXT */\n  ecma_extended_object_t *ext_object_p = (ecma_extended_object_t *) object_p;\n  ecma_number_t *date_value_p = ECMA_GET_INTERNAL_VALUE_POINTER (ecma_number_t, ext_object_p->u.cls.u3.date);\n#endif /* JERRY_ESNEXT */\n\n  ecma_number_t date_value = *date_value_p;\n\n  if (!BUILTIN_DATE_FUNCTION_IS_UTC (builtin_routine_id))\n  {\n    ecma_number_t local_tza;\n\n#if JERRY_ESNEXT\n    if (date_object_p->header.u.cls.u1.date_flags & ECMA_DATE_TZA_SET)\n    {\n      local_tza = date_object_p->header.u.cls.u3.tza;\n      JERRY_ASSERT (local_tza == ecma_date_local_time_zone_adjustment (date_value));\n    }\n    else\n#endif /* JERRY_ESNEXT */\n    {\n      local_tza = ecma_date_local_time_zone_adjustment (date_value);\n    }\n\n    date_value += local_tza;\n  }\n\n  ecma_number_t day_part;\n  ecma_number_t time_part;\n\n  if (builtin_routine_id <= ECMA_DATE_PROTOTYPE_SET_UTC_DATE)\n  {\n    if (ecma_number_is_nan (date_value))\n    {\n      if (!ECMA_DATE_PROTOTYPE_IS_SET_YEAR_ROUTINE (builtin_routine_id))\n      {\n        return ecma_make_number_value (date_value);\n      }\n\n      date_value = ECMA_NUMBER_ZERO;\n    }\n\n    time_part = ecma_date_time_in_day_from_time (date_value);\n\n    ecma_number_t year = ecma_date_year_from_time (date_value);\n    ecma_number_t month = ecma_date_month_from_time (date_value);\n    ecma_number_t day = ecma_date_date_from_time (date_value);\n\n    switch (builtin_routine_id)\n    {\n      case ECMA_DATE_PROTOTYPE_SET_FULL_YEAR:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_FULL_YEAR:\n      {\n        year = converted_number[0];\n        if (conversions >= 2)\n        {\n          month = converted_number[1];\n        }\n        if (conversions >= 3)\n        {\n          day = converted_number[2];\n        }\n        break;\n      }\n#if JERRY_BUILTIN_ANNEXB\n      case ECMA_DATE_PROTOTYPE_SET_YEAR:\n      {\n        if (ecma_number_is_nan (converted_number[0]))\n        {\n          *date_value_p = converted_number[0];\n          return ecma_make_number_value (converted_number[0]);\n        }\n\n        year = ecma_number_trunc (converted_number[0]);\n        if (year >= 0 && year <= 99)\n        {\n          year += 1900;\n        }\n        break;\n      }\n#endif /* JERRY_BUILTIN_ANNEXB */\n      case ECMA_DATE_PROTOTYPE_SET_MONTH:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_MONTH:\n      {\n        month = converted_number[0];\n        if (conversions >= 2)\n        {\n          day = converted_number[1];\n        }\n        break;\n      }\n      default:\n      {\n        JERRY_ASSERT (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_DATE\n                      || builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_UTC_DATE);\n\n        day = converted_number[0];\n        break;\n      }\n    }\n\n    day_part = ecma_date_make_day (year, month, day);\n\n#if JERRY_BUILTIN_ANNEXB\n    if (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_YEAR)\n    {\n      if (ecma_number_is_nan (converted_number[0]))\n      {\n        day_part = 0;\n        time_part = converted_number[0];\n      }\n    }\n#endif /* JERRY_BUILTIN_ANNEXB */\n  }\n  else\n  {\n    if (ecma_number_is_nan (date_value))\n    {\n      return ecma_make_number_value (date_value);\n    }\n\n    day_part = ecma_date_day_from_time (date_value) * (ecma_number_t) ECMA_DATE_MS_PER_DAY;\n\n    ecma_number_t hour = ecma_date_hour_from_time (date_value);\n    ecma_number_t min = ecma_date_min_from_time (date_value);\n    ecma_number_t sec = ecma_date_sec_from_time (date_value);\n    ecma_number_t ms = ecma_date_ms_from_time (date_value);\n\n    switch (builtin_routine_id)\n    {\n      case ECMA_DATE_PROTOTYPE_SET_HOURS:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_HOURS:\n      {\n        hour = converted_number[0];\n        if (conversions >= 2)\n        {\n          min = converted_number[1];\n        }\n        if (conversions >= 3)\n        {\n          sec = converted_number[2];\n        }\n        if (conversions >= 4)\n        {\n          ms = converted_number[3];\n        }\n        break;\n      }\n      case ECMA_DATE_PROTOTYPE_SET_MINUTES:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_MINUTES:\n      {\n        min = converted_number[0];\n        if (conversions >= 2)\n        {\n          sec = converted_number[1];\n        }\n        if (conversions >= 3)\n        {\n          ms = converted_number[2];\n        }\n        break;\n      }\n      case ECMA_DATE_PROTOTYPE_SET_UTC_SECONDS:\n      case ECMA_DATE_PROTOTYPE_SET_SECONDS:\n      {\n        sec = converted_number[0];\n        if (conversions >= 2)\n        {\n          ms = converted_number[1];\n        }\n        break;\n      }\n      default:\n      {\n        JERRY_ASSERT (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_UTC_MILLISECONDS\n                      || builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_MILLISECONDS);\n\n        ms = converted_number[0];\n        break;\n      }\n    }\n\n    time_part = ecma_date_make_time (hour, min, sec, ms);\n  }\n\n  bool is_utc = BUILTIN_DATE_FUNCTION_IS_UTC (builtin_routine_id);\n\n  ecma_number_t full_date = ecma_date_make_date (day_part, time_part);\n\n  if (!is_utc)\n  {\n    full_date = ecma_date_utc (full_date);\n  }\n\n  full_date = ecma_date_time_clip (full_date);\n\n  *date_value_p = full_date;\n\n#if JERRY_ESNEXT\n  date_object_p->header.u.cls.u1.date_flags &= (uint8_t) ~ECMA_DATE_TZA_SET;\n#endif /* JERRY_ESNEXT */\n\n  return ecma_make_number_value (full_date);\n}",
        "func": "static ecma_value_t\necma_builtin_date_prototype_dispatch_set (uint16_t builtin_routine_id, /**< built-in wide routine\n                                                                        *   identifier */\n                                          ecma_object_t *object_p, /**< date object */\n                                          const ecma_value_t arguments_list[], /**< list of arguments\n                                                                                *   passed to routine */\n                                          uint32_t arguments_number) /**< length of arguments' list */\n{\n  ecma_number_t converted_number[4];\n  uint32_t conversions = 0;\n\n  /* If the first argument is not specified, it is always converted to NaN. */\n  converted_number[0] = ecma_number_make_nan ();\n\n  switch (builtin_routine_id)\n  {\n#if JERRY_BUILTIN_ANNEXB\n    case ECMA_DATE_PROTOTYPE_SET_YEAR:\n#endif /* JERRY_BUILTIN_ANNEXB */\n    case ECMA_DATE_PROTOTYPE_SET_DATE:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_DATE:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_MILLISECONDS:\n    case ECMA_DATE_PROTOTYPE_SET_MILLISECONDS:\n    {\n      conversions = 1;\n      break;\n    }\n    case ECMA_DATE_PROTOTYPE_SET_MONTH:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_MONTH:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_SECONDS:\n    case ECMA_DATE_PROTOTYPE_SET_SECONDS:\n    {\n      conversions = 2;\n      break;\n    }\n    case ECMA_DATE_PROTOTYPE_SET_FULL_YEAR:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_FULL_YEAR:\n    case ECMA_DATE_PROTOTYPE_SET_MINUTES:\n    case ECMA_DATE_PROTOTYPE_SET_UTC_MINUTES:\n    {\n      conversions = 3;\n      break;\n    }\n    default:\n    {\n      JERRY_ASSERT (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_HOURS\n                    || builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_UTC_HOURS);\n\n      conversions = 4;\n      break;\n    }\n  }\n\n  if (conversions > arguments_number)\n  {\n    conversions = arguments_number;\n  }\n\n  for (uint32_t i = 0; i < conversions; i++)\n  {\n    ecma_value_t value = ecma_op_to_number (arguments_list[i], &converted_number[i]);\n\n    if (ECMA_IS_VALUE_ERROR (value))\n    {\n      return value;\n    }\n  }\n\n#if JERRY_ESNEXT\n  ecma_date_object_t *date_object_p = (ecma_date_object_t *) object_p;\n  ecma_number_t *date_value_p = &date_object_p->date_value;\n#else /* !JERRY_ESNEXT */\n  ecma_extended_object_t *ext_object_p = (ecma_extended_object_t *) object_p;\n  ecma_number_t *date_value_p = ECMA_GET_INTERNAL_VALUE_POINTER (ecma_number_t, ext_object_p->u.cls.u3.date);\n#endif /* JERRY_ESNEXT */\n\n  ecma_number_t date_value = *date_value_p;\n\n  if (!BUILTIN_DATE_FUNCTION_IS_UTC (builtin_routine_id))\n  {\n    ecma_number_t local_tza;\n\n#if JERRY_ESNEXT\n    if (date_object_p->header.u.cls.u1.date_flags & ECMA_DATE_TZA_SET)\n    {\n      local_tza = date_object_p->header.u.cls.u3.tza;\n      JERRY_ASSERT (local_tza == ecma_date_local_time_zone_adjustment (date_value));\n    }\n    else\n#endif /* JERRY_ESNEXT */\n    {\n      local_tza = ecma_date_local_time_zone_adjustment (date_value);\n    }\n\n    date_value += local_tza;\n  }\n\n  ecma_number_t day_part;\n  ecma_number_t time_part;\n\n  if (builtin_routine_id <= ECMA_DATE_PROTOTYPE_SET_UTC_DATE)\n  {\n    if (ecma_number_is_nan (date_value))\n    {\n      if (!ECMA_DATE_PROTOTYPE_IS_SET_YEAR_ROUTINE (builtin_routine_id))\n      {\n        return ecma_make_number_value (date_value);\n      }\n\n      date_value = ECMA_NUMBER_ZERO;\n    }\n\n    time_part = ecma_date_time_in_day_from_time (date_value);\n\n    ecma_number_t year = ecma_date_year_from_time (date_value);\n    ecma_number_t month = ecma_date_month_from_time (date_value);\n    ecma_number_t day = ecma_date_date_from_time (date_value);\n\n    switch (builtin_routine_id)\n    {\n      case ECMA_DATE_PROTOTYPE_SET_FULL_YEAR:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_FULL_YEAR:\n      {\n        year = converted_number[0];\n        if (conversions >= 2)\n        {\n          month = converted_number[1];\n        }\n        if (conversions >= 3)\n        {\n          day = converted_number[2];\n        }\n        break;\n      }\n#if JERRY_BUILTIN_ANNEXB\n      case ECMA_DATE_PROTOTYPE_SET_YEAR:\n      {\n        if (ecma_number_is_nan (converted_number[0]))\n        {\n          *date_value_p = converted_number[0];\n#if JERRY_ESNEXT\n          date_object_p->header.u.cls.u1.date_flags &= (uint8_t) ~ECMA_DATE_TZA_SET;\n#endif /* JERRY_ESNEXT */\n          return ecma_make_number_value (converted_number[0]);\n        }\n\n        year = ecma_number_trunc (converted_number[0]);\n        if (year >= 0 && year <= 99)\n        {\n          year += 1900;\n        }\n        break;\n      }\n#endif /* JERRY_BUILTIN_ANNEXB */\n      case ECMA_DATE_PROTOTYPE_SET_MONTH:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_MONTH:\n      {\n        month = converted_number[0];\n        if (conversions >= 2)\n        {\n          day = converted_number[1];\n        }\n        break;\n      }\n      default:\n      {\n        JERRY_ASSERT (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_DATE\n                      || builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_UTC_DATE);\n\n        day = converted_number[0];\n        break;\n      }\n    }\n\n    day_part = ecma_date_make_day (year, month, day);\n\n#if JERRY_BUILTIN_ANNEXB\n    if (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_YEAR)\n    {\n      if (ecma_number_is_nan (converted_number[0]))\n      {\n        day_part = 0;\n        time_part = converted_number[0];\n      }\n    }\n#endif /* JERRY_BUILTIN_ANNEXB */\n  }\n  else\n  {\n    if (ecma_number_is_nan (date_value))\n    {\n      return ecma_make_number_value (date_value);\n    }\n\n    day_part = ecma_date_day_from_time (date_value) * (ecma_number_t) ECMA_DATE_MS_PER_DAY;\n\n    ecma_number_t hour = ecma_date_hour_from_time (date_value);\n    ecma_number_t min = ecma_date_min_from_time (date_value);\n    ecma_number_t sec = ecma_date_sec_from_time (date_value);\n    ecma_number_t ms = ecma_date_ms_from_time (date_value);\n\n    switch (builtin_routine_id)\n    {\n      case ECMA_DATE_PROTOTYPE_SET_HOURS:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_HOURS:\n      {\n        hour = converted_number[0];\n        if (conversions >= 2)\n        {\n          min = converted_number[1];\n        }\n        if (conversions >= 3)\n        {\n          sec = converted_number[2];\n        }\n        if (conversions >= 4)\n        {\n          ms = converted_number[3];\n        }\n        break;\n      }\n      case ECMA_DATE_PROTOTYPE_SET_MINUTES:\n      case ECMA_DATE_PROTOTYPE_SET_UTC_MINUTES:\n      {\n        min = converted_number[0];\n        if (conversions >= 2)\n        {\n          sec = converted_number[1];\n        }\n        if (conversions >= 3)\n        {\n          ms = converted_number[2];\n        }\n        break;\n      }\n      case ECMA_DATE_PROTOTYPE_SET_UTC_SECONDS:\n      case ECMA_DATE_PROTOTYPE_SET_SECONDS:\n      {\n        sec = converted_number[0];\n        if (conversions >= 2)\n        {\n          ms = converted_number[1];\n        }\n        break;\n      }\n      default:\n      {\n        JERRY_ASSERT (builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_UTC_MILLISECONDS\n                      || builtin_routine_id == ECMA_DATE_PROTOTYPE_SET_MILLISECONDS);\n\n        ms = converted_number[0];\n        break;\n      }\n    }\n\n    time_part = ecma_date_make_time (hour, min, sec, ms);\n  }\n\n  bool is_utc = BUILTIN_DATE_FUNCTION_IS_UTC (builtin_routine_id);\n\n  ecma_number_t full_date = ecma_date_make_date (day_part, time_part);\n\n  if (!is_utc)\n  {\n    full_date = ecma_date_utc (full_date);\n  }\n\n  full_date = ecma_date_time_clip (full_date);\n\n  *date_value_p = full_date;\n\n#if JERRY_ESNEXT\n  date_object_p->header.u.cls.u1.date_flags &= (uint8_t) ~ECMA_DATE_TZA_SET;\n#endif /* JERRY_ESNEXT */\n\n  return ecma_make_number_value (full_date);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -138,6 +138,9 @@\n         if (ecma_number_is_nan (converted_number[0]))\n         {\n           *date_value_p = converted_number[0];\n+#if JERRY_ESNEXT\n+          date_object_p->header.u.cls.u1.date_flags &= (uint8_t) ~ECMA_DATE_TZA_SET;\n+#endif /* JERRY_ESNEXT */\n           return ecma_make_number_value (converted_number[0]);\n         }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#if JERRY_ESNEXT",
                "          date_object_p->header.u.cls.u1.date_flags &= (uint8_t) ~ECMA_DATE_TZA_SET;",
                "#endif /* JERRY_ESNEXT */"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46347",
        "func_name": "jerryscript-project/jerryscript/ecma_object_check_class_name_is_object",
        "description": "There is an Assertion 'ecma_object_check_class_name_is_object (obj_p)' failed at /jerry-core/ecma/operations/ecma-objects.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/b0625e61819e1f5823f16f2463f5def4ab16bdfb",
        "commit_title": "Add missing object types for ecma_object_get_class_name",
        "commit_text": " This patch fixes #4937 and fixes #4938.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "static inline bool\necma_object_check_class_name_is_object (ecma_object_t *obj_p) /**< object */\n{\n#ifndef JERRY_NDEBUG\n  return (ecma_builtin_is_global (obj_p)\n#if JERRY_BUILTIN_TYPEDARRAY\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ARRAYBUFFER_PROTOTYPE)\n#if JERRY_BUILTIN_SHAREDARRAYBUFFER\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SHARED_ARRAYBUFFER_PROTOTYPE)\n#endif /* JERRY_BUILTIN_SHAREDARRAYBUFFER */\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_TYPEDARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_INT8ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT8ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_INT16ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT16ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_INT32ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT32ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_FLOAT32ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT8CLAMPEDARRAY_PROTOTYPE)\n#if JERRY_NUMBER_TYPE_FLOAT64\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_FLOAT64ARRAY_PROTOTYPE)\n#endif /* JERRY_NUMBER_TYPE_FLOAT64 */\n#if JERRY_BUILTIN_BIGINT\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGINT64ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGUINT64ARRAY_PROTOTYPE)\n#endif /* JERRY_BUILTIN_BIGINT */\n#endif /* JERRY_BUILTIN_TYPEDARRAY */\n#if JERRY_ESNEXT\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ARRAY_PROTOTYPE_UNSCOPABLES)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ARRAY_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_STRING_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_REGEXP_STRING_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_EVAL_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_RANGE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_REFERENCE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SYNTAX_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_GENERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_TYPE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_AGGREGATE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_URI_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_DATE_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_REGEXP_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SYMBOL_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ASYNC_FUNCTION_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_PROMISE_PROTOTYPE)\n#endif /* JERRY_ESNEXT */\n#if JERRY_BUILTIN_CONTAINER\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_MAP_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SET_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_WEAKMAP_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_WEAKSET_PROTOTYPE)\n#if JERRY_ESNEXT\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_MAP_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SET_ITERATOR_PROTOTYPE)\n#endif /* JERRY_ESNEXT */\n#endif /* JERRY_BUILTIN_CONTAINER */\n#if JERRY_BUILTIN_WEAKREF\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_WEAKREF_PROTOTYPE)\n#endif /* JERRY_BUILTIN_WEAKREF */\n#if JERRY_BUILTIN_DATAVIEW\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_DATAVIEW_PROTOTYPE)\n#endif /* JERRY_BUILTIN_DATAVIEW */\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_OBJECT_PROTOTYPE));\n#else /* JERRY_NDEBUG */\n  JERRY_UNUSED (obj_p);\n  return true;\n#endif /* !JERRY_NDEBUG */\n}",
        "func": "static inline bool\necma_object_check_class_name_is_object (ecma_object_t *obj_p) /**< object */\n{\n#ifndef JERRY_NDEBUG\n  return (ecma_builtin_is_global (obj_p)\n#if JERRY_BUILTIN_TYPEDARRAY\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ARRAYBUFFER_PROTOTYPE)\n#if JERRY_BUILTIN_SHAREDARRAYBUFFER\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SHARED_ARRAYBUFFER_PROTOTYPE)\n#endif /* JERRY_BUILTIN_SHAREDARRAYBUFFER */\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_TYPEDARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_INT8ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT8ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_INT16ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT16ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_INT32ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT32ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_FLOAT32ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_UINT8CLAMPEDARRAY_PROTOTYPE)\n#if JERRY_NUMBER_TYPE_FLOAT64\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_FLOAT64ARRAY_PROTOTYPE)\n#endif /* JERRY_NUMBER_TYPE_FLOAT64 */\n#if JERRY_BUILTIN_BIGINT\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGINT_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGINT64ARRAY_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGUINT64ARRAY_PROTOTYPE)\n#endif /* JERRY_BUILTIN_BIGINT */\n#endif /* JERRY_BUILTIN_TYPEDARRAY */\n#if JERRY_ESNEXT\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ARRAY_PROTOTYPE_UNSCOPABLES)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ARRAY_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_STRING_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_REGEXP_STRING_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_EVAL_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_RANGE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_REFERENCE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SYNTAX_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_GENERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_TYPE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_AGGREGATE_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_URI_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ERROR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_DATE_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_REGEXP_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SYMBOL_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_ASYNC_FUNCTION_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_PROMISE_PROTOTYPE)\n#endif /* JERRY_ESNEXT */\n#if JERRY_BUILTIN_CONTAINER\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_MAP_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SET_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_WEAKMAP_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_WEAKSET_PROTOTYPE)\n#if JERRY_ESNEXT\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_MAP_ITERATOR_PROTOTYPE)\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_SET_ITERATOR_PROTOTYPE)\n#endif /* JERRY_ESNEXT */\n#endif /* JERRY_BUILTIN_CONTAINER */\n#if JERRY_BUILTIN_WEAKREF\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_WEAKREF_PROTOTYPE)\n#endif /* JERRY_BUILTIN_WEAKREF */\n#if JERRY_BUILTIN_DATAVIEW\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_DATAVIEW_PROTOTYPE)\n#endif /* JERRY_BUILTIN_DATAVIEW */\n          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_OBJECT_PROTOTYPE));\n#else /* JERRY_NDEBUG */\n  JERRY_UNUSED (obj_p);\n  return true;\n#endif /* !JERRY_NDEBUG */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,7 @@\n           || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_FLOAT64ARRAY_PROTOTYPE)\n #endif /* JERRY_NUMBER_TYPE_FLOAT64 */\n #if JERRY_BUILTIN_BIGINT\n+          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGINT_PROTOTYPE)\n           || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGINT64ARRAY_PROTOTYPE)\n           || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGUINT64ARRAY_PROTOTYPE)\n #endif /* JERRY_BUILTIN_BIGINT */",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "          || ecma_builtin_is (obj_p, ECMA_BUILTIN_ID_BIGINT_PROTOTYPE)"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46347",
        "func_name": "jerryscript-project/jerryscript/ecma_object_get_class_name",
        "description": "There is an Assertion 'ecma_object_check_class_name_is_object (obj_p)' failed at /jerry-core/ecma/operations/ecma-objects.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/b0625e61819e1f5823f16f2463f5def4ab16bdfb",
        "commit_title": "Add missing object types for ecma_object_get_class_name",
        "commit_text": " This patch fixes #4937 and fixes #4938.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "lit_magic_string_id_t\necma_object_get_class_name (ecma_object_t *obj_p) /**< object */\n{\n  ecma_object_type_t type = ecma_get_object_type (obj_p);\n\n  switch (type)\n  {\n    case ECMA_OBJECT_TYPE_ARRAY:\n    case ECMA_OBJECT_TYPE_BUILT_IN_ARRAY:\n    {\n      return LIT_MAGIC_STRING_ARRAY_UL;\n    }\n    case ECMA_OBJECT_TYPE_CLASS:\n    case ECMA_OBJECT_TYPE_BUILT_IN_CLASS:\n    {\n      ecma_extended_object_t *ext_object_p = (ecma_extended_object_t *) obj_p;\n\n      switch (ext_object_p->u.cls.type)\n      {\n#if JERRY_BUILTIN_TYPEDARRAY\n        case ECMA_OBJECT_CLASS_TYPEDARRAY:\n        {\n          return ecma_get_typedarray_magic_string_id (ext_object_p->u.cls.u1.typedarray_type);\n        }\n#endif /* JERRY_BUILTIN_TYPEDARRAY */\n#if JERRY_BUILTIN_CONTAINER\n        case ECMA_OBJECT_CLASS_CONTAINER:\n        {\n          return (lit_magic_string_id_t) ext_object_p->u.cls.u2.container_id;\n        }\n#endif /* JERRY_BUILTIN_CONTAINER */\n        default:\n        {\n          break;\n        }\n      }\n\n      JERRY_ASSERT (ext_object_p->u.cls.type < ECMA_OBJECT_CLASS__MAX);\n      JERRY_ASSERT (ecma_class_object_magic_string_id[ext_object_p->u.cls.type] != LIT_MAGIC_STRING__EMPTY);\n\n      return (lit_magic_string_id_t) ecma_class_object_magic_string_id[ext_object_p->u.cls.type];\n    }\n    case ECMA_OBJECT_TYPE_FUNCTION:\n    case ECMA_OBJECT_TYPE_NATIVE_FUNCTION:\n    case ECMA_OBJECT_TYPE_BOUND_FUNCTION:\n    case ECMA_OBJECT_TYPE_BUILT_IN_FUNCTION:\n    {\n      return LIT_MAGIC_STRING_FUNCTION_UL;\n    }\n#if JERRY_BUILTIN_PROXY\n    case ECMA_OBJECT_TYPE_PROXY:\n    {\n      ecma_proxy_object_t *proxy_obj_p = (ecma_proxy_object_t *) obj_p;\n\n      if (!ecma_is_value_null (proxy_obj_p->target) && ecma_is_value_object (proxy_obj_p->target))\n      {\n        ecma_object_t *target_obj_p = ecma_get_object_from_value (proxy_obj_p->target);\n        return ecma_object_get_class_name (target_obj_p);\n      }\n      return LIT_MAGIC_STRING_OBJECT_UL;\n    }\n#endif /* JERRY_BUILTIN_PROXY */\n    case ECMA_OBJECT_TYPE_BUILT_IN_GENERAL:\n    {\n      ecma_extended_object_t *ext_obj_p = (ecma_extended_object_t *) obj_p;\n\n      switch (ext_obj_p->u.built_in.id)\n      {\n#if JERRY_BUILTIN_MATH\n        case ECMA_BUILTIN_ID_MATH:\n        {\n          return LIT_MAGIC_STRING_MATH_UL;\n        }\n#endif /* JERRY_BUILTIN_MATH */\n#if JERRY_BUILTIN_REFLECT\n        case ECMA_BUILTIN_ID_REFLECT:\n        {\n          return LIT_MAGIC_STRING_REFLECT_UL;\n        }\n#endif /* JERRY_BUILTIN_REFLECT */\n#if JERRY_ESNEXT\n        case ECMA_BUILTIN_ID_GENERATOR:\n        {\n          return LIT_MAGIC_STRING_GENERATOR_UL;\n        }\n        case ECMA_BUILTIN_ID_ASYNC_GENERATOR:\n        {\n          return LIT_MAGIC_STRING_ASYNC_GENERATOR_UL;\n        }\n#endif /* JERRY_ESNEXT */\n#if JERRY_BUILTIN_JSON\n        case ECMA_BUILTIN_ID_JSON:\n        {\n          return LIT_MAGIC_STRING_JSON_U;\n        }\n#endif /* JERRY_BUILTIN_JSON */\n#if JERRY_BUILTIN_ATOMICS\n        case ECMA_BUILTIN_ID_ATOMICS:\n        {\n          return LIT_MAGIC_STRING_ATOMICS_U;\n        }\n#endif /* JERRY_BUILTIN_ATOMICS */\n#if !JERRY_ESNEXT\n#if JERRY_BUILTIN_ERRORS\n        case ECMA_BUILTIN_ID_EVAL_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_RANGE_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_REFERENCE_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_SYNTAX_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_TYPE_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_URI_ERROR_PROTOTYPE:\n#endif /* JERRY_BUILTIN_ERRORS */\n        case ECMA_BUILTIN_ID_ERROR_PROTOTYPE:\n        {\n          return LIT_MAGIC_STRING_ERROR_UL;\n        }\n#endif /* !JERRY_ESNEXT */\n        default:\n        {\n          break;\n        }\n      }\n\n      JERRY_ASSERT (ecma_object_check_class_name_is_object (obj_p));\n      return LIT_MAGIC_STRING_OBJECT_UL;\n    }\n    default:\n    {\n      JERRY_ASSERT (type == ECMA_OBJECT_TYPE_GENERAL || type == ECMA_OBJECT_TYPE_PROXY);\n\n      return LIT_MAGIC_STRING_OBJECT_UL;\n    }\n  }\n}",
        "func": "lit_magic_string_id_t\necma_object_get_class_name (ecma_object_t *obj_p) /**< object */\n{\n  ecma_object_type_t type = ecma_get_object_type (obj_p);\n\n  switch (type)\n  {\n    case ECMA_OBJECT_TYPE_ARRAY:\n    case ECMA_OBJECT_TYPE_BUILT_IN_ARRAY:\n    {\n      return LIT_MAGIC_STRING_ARRAY_UL;\n    }\n    case ECMA_OBJECT_TYPE_CLASS:\n    case ECMA_OBJECT_TYPE_BUILT_IN_CLASS:\n    {\n      ecma_extended_object_t *ext_object_p = (ecma_extended_object_t *) obj_p;\n\n      switch (ext_object_p->u.cls.type)\n      {\n#if JERRY_BUILTIN_TYPEDARRAY\n        case ECMA_OBJECT_CLASS_TYPEDARRAY:\n        {\n          return ecma_get_typedarray_magic_string_id (ext_object_p->u.cls.u1.typedarray_type);\n        }\n#endif /* JERRY_BUILTIN_TYPEDARRAY */\n#if JERRY_BUILTIN_CONTAINER\n        case ECMA_OBJECT_CLASS_CONTAINER:\n        {\n          return (lit_magic_string_id_t) ext_object_p->u.cls.u2.container_id;\n        }\n#endif /* JERRY_BUILTIN_CONTAINER */\n        default:\n        {\n          break;\n        }\n      }\n\n      JERRY_ASSERT (ext_object_p->u.cls.type < ECMA_OBJECT_CLASS__MAX);\n      JERRY_ASSERT (ecma_class_object_magic_string_id[ext_object_p->u.cls.type] != LIT_MAGIC_STRING__EMPTY);\n\n      return (lit_magic_string_id_t) ecma_class_object_magic_string_id[ext_object_p->u.cls.type];\n    }\n    case ECMA_OBJECT_TYPE_FUNCTION:\n    case ECMA_OBJECT_TYPE_NATIVE_FUNCTION:\n    case ECMA_OBJECT_TYPE_BOUND_FUNCTION:\n    case ECMA_OBJECT_TYPE_BUILT_IN_FUNCTION:\n    case ECMA_OBJECT_TYPE_CONSTRUCTOR_FUNCTION:\n    {\n      return LIT_MAGIC_STRING_FUNCTION_UL;\n    }\n#if JERRY_BUILTIN_PROXY\n    case ECMA_OBJECT_TYPE_PROXY:\n    {\n      ecma_proxy_object_t *proxy_obj_p = (ecma_proxy_object_t *) obj_p;\n\n      if (!ecma_is_value_null (proxy_obj_p->target) && ecma_is_value_object (proxy_obj_p->target))\n      {\n        ecma_object_t *target_obj_p = ecma_get_object_from_value (proxy_obj_p->target);\n        return ecma_object_get_class_name (target_obj_p);\n      }\n      return LIT_MAGIC_STRING_OBJECT_UL;\n    }\n#endif /* JERRY_BUILTIN_PROXY */\n    case ECMA_OBJECT_TYPE_BUILT_IN_GENERAL:\n    {\n      ecma_extended_object_t *ext_obj_p = (ecma_extended_object_t *) obj_p;\n\n      switch (ext_obj_p->u.built_in.id)\n      {\n#if JERRY_BUILTIN_MATH\n        case ECMA_BUILTIN_ID_MATH:\n        {\n          return LIT_MAGIC_STRING_MATH_UL;\n        }\n#endif /* JERRY_BUILTIN_MATH */\n#if JERRY_BUILTIN_REFLECT\n        case ECMA_BUILTIN_ID_REFLECT:\n        {\n          return LIT_MAGIC_STRING_REFLECT_UL;\n        }\n#endif /* JERRY_BUILTIN_REFLECT */\n#if JERRY_ESNEXT\n        case ECMA_BUILTIN_ID_GENERATOR:\n        {\n          return LIT_MAGIC_STRING_GENERATOR_UL;\n        }\n        case ECMA_BUILTIN_ID_ASYNC_GENERATOR:\n        {\n          return LIT_MAGIC_STRING_ASYNC_GENERATOR_UL;\n        }\n#endif /* JERRY_ESNEXT */\n#if JERRY_BUILTIN_JSON\n        case ECMA_BUILTIN_ID_JSON:\n        {\n          return LIT_MAGIC_STRING_JSON_U;\n        }\n#endif /* JERRY_BUILTIN_JSON */\n#if JERRY_BUILTIN_ATOMICS\n        case ECMA_BUILTIN_ID_ATOMICS:\n        {\n          return LIT_MAGIC_STRING_ATOMICS_U;\n        }\n#endif /* JERRY_BUILTIN_ATOMICS */\n#if !JERRY_ESNEXT\n#if JERRY_BUILTIN_ERRORS\n        case ECMA_BUILTIN_ID_EVAL_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_RANGE_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_REFERENCE_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_SYNTAX_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_TYPE_ERROR_PROTOTYPE:\n        case ECMA_BUILTIN_ID_URI_ERROR_PROTOTYPE:\n#endif /* JERRY_BUILTIN_ERRORS */\n        case ECMA_BUILTIN_ID_ERROR_PROTOTYPE:\n        {\n          return LIT_MAGIC_STRING_ERROR_UL;\n        }\n#endif /* !JERRY_ESNEXT */\n        default:\n        {\n          break;\n        }\n      }\n\n      JERRY_ASSERT (ecma_object_check_class_name_is_object (obj_p));\n      return LIT_MAGIC_STRING_OBJECT_UL;\n    }\n    default:\n    {\n      JERRY_ASSERT (type == ECMA_OBJECT_TYPE_GENERAL || type == ECMA_OBJECT_TYPE_PROXY);\n\n      return LIT_MAGIC_STRING_OBJECT_UL;\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -44,6 +44,7 @@\n     case ECMA_OBJECT_TYPE_NATIVE_FUNCTION:\n     case ECMA_OBJECT_TYPE_BOUND_FUNCTION:\n     case ECMA_OBJECT_TYPE_BUILT_IN_FUNCTION:\n+    case ECMA_OBJECT_TYPE_CONSTRUCTOR_FUNCTION:\n     {\n       return LIT_MAGIC_STRING_FUNCTION_UL;\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    case ECMA_OBJECT_TYPE_CONSTRUCTOR_FUNCTION:"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46348",
        "func_name": "jerryscript-project/jerryscript/ecma_op_ordinary_object_set_prototype_of",
        "description": "There is an Assertion 'ECMA_STRING_IS_REF_EQUALS_TO_ONE (string_p)' failed at /jerry-core/ecma/base/ecma-literal-storage.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/d9b37a22698a15ca3ae7b369822805fd7556538e",
        "commit_title": "Ban setting 'Object.prototype.__proto__' as Proxy to prevent circular referencing",
        "commit_text": "in prototype chain.  This patch fixes #4941  JerryScript-DCO-1.0-Signed-off-by: Martin Negyokru negyokru@inf.u-szeged.hu",
        "func_before": "extern inline ecma_value_t JERRY_ATTR_ALWAYS_INLINE\necma_op_ordinary_object_set_prototype_of (ecma_object_t *obj_p, /**< base object */\n                                          ecma_value_t proto) /**< prototype object */\n{\n  JERRY_ASSERT (!ecma_is_lexical_environment (obj_p));\n  JERRY_ASSERT (!ECMA_OBJECT_IS_PROXY (obj_p));\n\n  /* 1. */\n  JERRY_ASSERT (ecma_is_value_object (proto) || ecma_is_value_null (proto));\n\n  /* 3. */\n  ecma_object_t *current_proto_p = ECMA_GET_POINTER (ecma_object_t, ecma_op_ordinary_object_get_prototype_of (obj_p));\n  ecma_object_t *new_proto_p = ecma_is_value_null (proto) ? NULL : ecma_get_object_from_value (proto);\n\n  /* 4. */\n  if (new_proto_p == current_proto_p)\n  {\n    return ECMA_VALUE_TRUE;\n  }\n\n  /* 2 - 5. */\n  if (!ecma_op_ordinary_object_is_extensible (obj_p))\n  {\n    return ECMA_VALUE_FALSE;\n  }\n\n  /**\n   * When the prototype of a fast array changes, it is required to convert the\n   * array to a \"normal\" array. This ensures that all [[Get]]/[[Set]]/etc.\n   * calls works as expected.\n   */\n  if (ecma_op_object_is_fast_array (obj_p))\n  {\n    ecma_fast_array_convert_to_normal (obj_p);\n  }\n\n  /* 6. */\n  ecma_object_t *iter_p = new_proto_p;\n\n  /* 7 - 8. */\n  while (true)\n  {\n    /* 8.a */\n    if (iter_p == NULL)\n    {\n      break;\n    }\n\n    /* 8.b */\n    if (obj_p == iter_p)\n    {\n      return ECMA_VALUE_FALSE;\n    }\n\n    /* 8.c.i */\n#if JERRY_BUILTIN_PROXY\n    if (ECMA_OBJECT_IS_PROXY (iter_p))\n    {\n      break;\n    }\n#endif /* JERRY_BUILTIN_PROXY */\n\n    /* 8.c.ii */\n    iter_p = ECMA_GET_POINTER (ecma_object_t, ecma_op_ordinary_object_get_prototype_of (iter_p));\n  }\n\n  /* 9. */\n  ECMA_SET_POINTER (obj_p->u2.prototype_cp, new_proto_p);\n\n  /* 10. */\n  return ECMA_VALUE_TRUE;\n}",
        "func": "extern inline ecma_value_t JERRY_ATTR_ALWAYS_INLINE\necma_op_ordinary_object_set_prototype_of (ecma_object_t *obj_p, /**< base object */\n                                          ecma_value_t proto) /**< prototype object */\n{\n  JERRY_ASSERT (!ecma_is_lexical_environment (obj_p));\n  JERRY_ASSERT (!ECMA_OBJECT_IS_PROXY (obj_p));\n\n  /* 1. */\n  JERRY_ASSERT (ecma_is_value_object (proto) || ecma_is_value_null (proto));\n\n  /* 3. */\n  ecma_object_t *current_proto_p = ECMA_GET_POINTER (ecma_object_t, ecma_op_ordinary_object_get_prototype_of (obj_p));\n  ecma_object_t *new_proto_p = ecma_is_value_null (proto) ? NULL : ecma_get_object_from_value (proto);\n\n  /* 4. */\n  if (new_proto_p == current_proto_p)\n  {\n    return ECMA_VALUE_TRUE;\n  }\n\n  /* 2 - 5. */\n  if (!ecma_op_ordinary_object_is_extensible (obj_p))\n  {\n    return ECMA_VALUE_FALSE;\n  }\n\n  /**\n   * When the prototype of a fast array changes, it is required to convert the\n   * array to a \"normal\" array. This ensures that all [[Get]]/[[Set]]/etc.\n   * calls works as expected.\n   */\n  if (ecma_op_object_is_fast_array (obj_p))\n  {\n    ecma_fast_array_convert_to_normal (obj_p);\n  }\n\n  /* 6. */\n  ecma_object_t *iter_p = new_proto_p;\n\n  /* 7 - 8. */\n  while (true)\n  {\n    /* 8.a */\n    if (iter_p == NULL)\n    {\n      break;\n    }\n\n    /* 8.b */\n    if (obj_p == iter_p)\n    {\n      return ECMA_VALUE_FALSE;\n    }\n\n    /* 8.c.i */\n#if JERRY_BUILTIN_PROXY\n    if (ECMA_OBJECT_IS_PROXY (iter_p))\n    {\n      /**\n       * Prevent setting 'Object.prototype.__proto__'\n       * to avoid circular referencing in the prototype chain.\n       */\n      if (obj_p == ecma_builtin_get (ECMA_BUILTIN_ID_OBJECT_PROTOTYPE))\n      {\n        return ECMA_VALUE_FALSE;\n      }\n\n      break;\n    }\n#endif /* JERRY_BUILTIN_PROXY */\n\n    /* 8.c.ii */\n    iter_p = ECMA_GET_POINTER (ecma_object_t, ecma_op_ordinary_object_get_prototype_of (iter_p));\n  }\n\n  /* 9. */\n  ECMA_SET_POINTER (obj_p->u2.prototype_cp, new_proto_p);\n\n  /* 10. */\n  return ECMA_VALUE_TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,6 +56,15 @@\n #if JERRY_BUILTIN_PROXY\n     if (ECMA_OBJECT_IS_PROXY (iter_p))\n     {\n+      /**\n+       * Prevent setting 'Object.prototype.__proto__'\n+       * to avoid circular referencing in the prototype chain.\n+       */\n+      if (obj_p == ecma_builtin_get (ECMA_BUILTIN_ID_OBJECT_PROTOTYPE))\n+      {\n+        return ECMA_VALUE_FALSE;\n+      }\n+\n       break;\n     }\n #endif /* JERRY_BUILTIN_PROXY */",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      /**",
                "       * Prevent setting 'Object.prototype.__proto__'",
                "       * to avoid circular referencing in the prototype chain.",
                "       */",
                "      if (obj_p == ecma_builtin_get (ECMA_BUILTIN_ID_OBJECT_PROTOTYPE))",
                "      {",
                "        return ECMA_VALUE_FALSE;",
                "      }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46350",
        "func_name": "jerryscript-project/jerryscript/opfunc_private_set",
        "description": "There is an Assertion 'ecma_is_value_object (value)' failed at jerryscript/jerry-core/ecma/base/ecma-helpers-value.c in JerryScript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/37d7c953fead2b9ffe168fc6ac38c92b602773d8",
        "commit_title": "Add missing toObject conversion for PrivateSet operation",
        "commit_text": " This patch fixes #4936.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "ecma_value_t\nopfunc_private_set (ecma_value_t base, /**< this object */\n                    ecma_value_t property, /**< property name */\n                    ecma_value_t value) /**< ecma value */\n{\n  ecma_object_t *obj_p = ecma_get_object_from_value (base);\n  ecma_string_t *prop_name_p = ecma_get_string_from_value (property);\n  ecma_string_t *private_key_p = NULL;\n\n  ecma_property_t *prop_p = opfunc_find_private_element (obj_p, prop_name_p, &private_key_p, true);\n\n  if (prop_p == NULL)\n  {\n    return ecma_raise_type_error (ECMA_ERR_CANNOT_WRITE_PRIVATE_MEMBER_TO_AN_OBJECT_WHOSE_CLASS_DID_NOT_DECLARE_IT);\n  }\n\n  if (*prop_p & ECMA_PROPERTY_FLAG_DATA)\n  {\n    JERRY_ASSERT (ecma_prop_name_is_symbol (private_key_p));\n\n    if (private_key_p->u.hash & ECMA_SYMBOL_FLAG_PRIVATE_INSTANCE_METHOD)\n    {\n      return ecma_raise_type_error (ECMA_ERR_PRIVATE_METHOD_IS_NOT_WRITABLE);\n    }\n\n    ecma_value_assign_value (&ECMA_PROPERTY_VALUE_PTR (prop_p)->value, value);\n    return ecma_copy_value (value);\n  }\n\n  ecma_getter_setter_pointers_t *get_set_pair_p = ecma_get_named_accessor_property (ECMA_PROPERTY_VALUE_PTR (prop_p));\n\n  if (get_set_pair_p->setter_cp == JMEM_CP_NULL)\n  {\n    return ecma_raise_type_error (ECMA_ERR_PRIVATE_FIELD_WAS_DEFINED_WITHOUT_A_SETTER);\n  }\n\n  ecma_object_t *setter_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, get_set_pair_p->setter_cp);\n\n  return ecma_op_function_call (setter_p, base, &value, 1);\n}",
        "func": "ecma_value_t\nopfunc_private_set (ecma_value_t base, /**< this object */\n                    ecma_value_t property, /**< property name */\n                    ecma_value_t value) /**< ecma value */\n{\n  ecma_value_t base_obj = ecma_op_to_object (base);\n\n  if (ECMA_IS_VALUE_ERROR (base_obj))\n  {\n    return base_obj;\n  }\n\n  ecma_object_t *obj_p = ecma_get_object_from_value (base_obj);\n  ecma_string_t *prop_name_p = ecma_get_string_from_value (property);\n  ecma_string_t *private_key_p = NULL;\n\n  ecma_property_t *prop_p = opfunc_find_private_element (obj_p, prop_name_p, &private_key_p, true);\n\n  ecma_value_t result;\n\n  if (prop_p == NULL)\n  {\n    result = ecma_raise_type_error (ECMA_ERR_CANNOT_WRITE_PRIVATE_MEMBER_TO_AN_OBJECT_WHOSE_CLASS_DID_NOT_DECLARE_IT);\n  }\n  else if (*prop_p & ECMA_PROPERTY_FLAG_DATA)\n  {\n    JERRY_ASSERT (ecma_prop_name_is_symbol (private_key_p));\n\n    if (private_key_p->u.hash & ECMA_SYMBOL_FLAG_PRIVATE_INSTANCE_METHOD)\n    {\n      result = ecma_raise_type_error (ECMA_ERR_PRIVATE_METHOD_IS_NOT_WRITABLE);\n    }\n    else\n    {\n      ecma_value_assign_value (&ECMA_PROPERTY_VALUE_PTR (prop_p)->value, value);\n      result = ecma_copy_value (value);\n    }\n  }\n  else\n  {\n    ecma_getter_setter_pointers_t *get_set_pair_p = ecma_get_named_accessor_property (ECMA_PROPERTY_VALUE_PTR (prop_p));\n\n    if (get_set_pair_p->setter_cp == JMEM_CP_NULL)\n    {\n      result = ecma_raise_type_error (ECMA_ERR_PRIVATE_FIELD_WAS_DEFINED_WITHOUT_A_SETTER);\n    }\n    else\n    {\n      ecma_object_t *setter_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, get_set_pair_p->setter_cp);\n\n      result = ecma_op_function_call (setter_p, base, &value, 1);\n    }\n  }\n\n  ecma_deref_object (obj_p);\n\n  return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,38 +3,56 @@\n                     ecma_value_t property, /**< property name */\n                     ecma_value_t value) /**< ecma value */\n {\n-  ecma_object_t *obj_p = ecma_get_object_from_value (base);\n+  ecma_value_t base_obj = ecma_op_to_object (base);\n+\n+  if (ECMA_IS_VALUE_ERROR (base_obj))\n+  {\n+    return base_obj;\n+  }\n+\n+  ecma_object_t *obj_p = ecma_get_object_from_value (base_obj);\n   ecma_string_t *prop_name_p = ecma_get_string_from_value (property);\n   ecma_string_t *private_key_p = NULL;\n \n   ecma_property_t *prop_p = opfunc_find_private_element (obj_p, prop_name_p, &private_key_p, true);\n \n+  ecma_value_t result;\n+\n   if (prop_p == NULL)\n   {\n-    return ecma_raise_type_error (ECMA_ERR_CANNOT_WRITE_PRIVATE_MEMBER_TO_AN_OBJECT_WHOSE_CLASS_DID_NOT_DECLARE_IT);\n+    result = ecma_raise_type_error (ECMA_ERR_CANNOT_WRITE_PRIVATE_MEMBER_TO_AN_OBJECT_WHOSE_CLASS_DID_NOT_DECLARE_IT);\n   }\n-\n-  if (*prop_p & ECMA_PROPERTY_FLAG_DATA)\n+  else if (*prop_p & ECMA_PROPERTY_FLAG_DATA)\n   {\n     JERRY_ASSERT (ecma_prop_name_is_symbol (private_key_p));\n \n     if (private_key_p->u.hash & ECMA_SYMBOL_FLAG_PRIVATE_INSTANCE_METHOD)\n     {\n-      return ecma_raise_type_error (ECMA_ERR_PRIVATE_METHOD_IS_NOT_WRITABLE);\n+      result = ecma_raise_type_error (ECMA_ERR_PRIVATE_METHOD_IS_NOT_WRITABLE);\n     }\n+    else\n+    {\n+      ecma_value_assign_value (&ECMA_PROPERTY_VALUE_PTR (prop_p)->value, value);\n+      result = ecma_copy_value (value);\n+    }\n+  }\n+  else\n+  {\n+    ecma_getter_setter_pointers_t *get_set_pair_p = ecma_get_named_accessor_property (ECMA_PROPERTY_VALUE_PTR (prop_p));\n \n-    ecma_value_assign_value (&ECMA_PROPERTY_VALUE_PTR (prop_p)->value, value);\n-    return ecma_copy_value (value);\n+    if (get_set_pair_p->setter_cp == JMEM_CP_NULL)\n+    {\n+      result = ecma_raise_type_error (ECMA_ERR_PRIVATE_FIELD_WAS_DEFINED_WITHOUT_A_SETTER);\n+    }\n+    else\n+    {\n+      ecma_object_t *setter_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, get_set_pair_p->setter_cp);\n+\n+      result = ecma_op_function_call (setter_p, base, &value, 1);\n+    }\n   }\n \n-  ecma_getter_setter_pointers_t *get_set_pair_p = ecma_get_named_accessor_property (ECMA_PROPERTY_VALUE_PTR (prop_p));\n+  ecma_deref_object (obj_p);\n \n-  if (get_set_pair_p->setter_cp == JMEM_CP_NULL)\n-  {\n-    return ecma_raise_type_error (ECMA_ERR_PRIVATE_FIELD_WAS_DEFINED_WITHOUT_A_SETTER);\n-  }\n-\n-  ecma_object_t *setter_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, get_set_pair_p->setter_cp);\n-\n-  return ecma_op_function_call (setter_p, base, &value, 1);\n+  return result;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  ecma_object_t *obj_p = ecma_get_object_from_value (base);",
                "    return ecma_raise_type_error (ECMA_ERR_CANNOT_WRITE_PRIVATE_MEMBER_TO_AN_OBJECT_WHOSE_CLASS_DID_NOT_DECLARE_IT);",
                "",
                "  if (*prop_p & ECMA_PROPERTY_FLAG_DATA)",
                "      return ecma_raise_type_error (ECMA_ERR_PRIVATE_METHOD_IS_NOT_WRITABLE);",
                "    ecma_value_assign_value (&ECMA_PROPERTY_VALUE_PTR (prop_p)->value, value);",
                "    return ecma_copy_value (value);",
                "  ecma_getter_setter_pointers_t *get_set_pair_p = ecma_get_named_accessor_property (ECMA_PROPERTY_VALUE_PTR (prop_p));",
                "  if (get_set_pair_p->setter_cp == JMEM_CP_NULL)",
                "  {",
                "    return ecma_raise_type_error (ECMA_ERR_PRIVATE_FIELD_WAS_DEFINED_WITHOUT_A_SETTER);",
                "  }",
                "",
                "  ecma_object_t *setter_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, get_set_pair_p->setter_cp);",
                "",
                "  return ecma_op_function_call (setter_p, base, &value, 1);"
            ],
            "added_lines": [
                "  ecma_value_t base_obj = ecma_op_to_object (base);",
                "",
                "  if (ECMA_IS_VALUE_ERROR (base_obj))",
                "  {",
                "    return base_obj;",
                "  }",
                "",
                "  ecma_object_t *obj_p = ecma_get_object_from_value (base_obj);",
                "  ecma_value_t result;",
                "",
                "    result = ecma_raise_type_error (ECMA_ERR_CANNOT_WRITE_PRIVATE_MEMBER_TO_AN_OBJECT_WHOSE_CLASS_DID_NOT_DECLARE_IT);",
                "  else if (*prop_p & ECMA_PROPERTY_FLAG_DATA)",
                "      result = ecma_raise_type_error (ECMA_ERR_PRIVATE_METHOD_IS_NOT_WRITABLE);",
                "    else",
                "    {",
                "      ecma_value_assign_value (&ECMA_PROPERTY_VALUE_PTR (prop_p)->value, value);",
                "      result = ecma_copy_value (value);",
                "    }",
                "  }",
                "  else",
                "  {",
                "    ecma_getter_setter_pointers_t *get_set_pair_p = ecma_get_named_accessor_property (ECMA_PROPERTY_VALUE_PTR (prop_p));",
                "    if (get_set_pair_p->setter_cp == JMEM_CP_NULL)",
                "    {",
                "      result = ecma_raise_type_error (ECMA_ERR_PRIVATE_FIELD_WAS_DEFINED_WITHOUT_A_SETTER);",
                "    }",
                "    else",
                "    {",
                "      ecma_object_t *setter_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, get_set_pair_p->setter_cp);",
                "",
                "      result = ecma_op_function_call (setter_p, base, &value, 1);",
                "    }",
                "  ecma_deref_object (obj_p);",
                "  return result;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-22890",
        "func_name": "jerryscript-project/jerryscript/scanner_filter_arguments",
        "description": "There is an Assertion 'arguments_type != SCANNER_ARGUMENTS_PRESENT && arguments_type != SCANNER_ARGUMENTS_PRESENT_NO_REG' failed at /jerry-core/parser/js/js-scanner-util.c in Jerryscript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/3bb042b49153dafb4cb47e8c6c032692a78ba0c7",
        "commit_title": "Prevent arguments object creation if 'arguments' function argument is present",
        "commit_text": " This patch fixes #4847.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "void\nscanner_filter_arguments (parser_context_t *context_p, /**< context */\n                          scanner_context_t *scanner_context_p) /**< scanner context */\n{\n  /* Fast case: check whether all literals are arguments. */\n  scanner_literal_pool_t *literal_pool_p = scanner_context_p->active_literal_pool_p;\n  scanner_literal_pool_t *prev_literal_pool_p = literal_pool_p->prev_p;\n  parser_list_iterator_t literal_iterator;\n  lexer_lit_location_t *literal_p;\n  bool can_eval = (literal_pool_p->status_flags & SCANNER_LITERAL_POOL_CAN_EVAL) != 0;\n  bool has_arguments = (literal_pool_p->status_flags & SCANNER_LITERAL_POOL_NO_ARGUMENTS) == 0;\n\n  JERRY_ASSERT (SCANNER_LITERAL_POOL_MAY_HAVE_ARGUMENTS (literal_pool_p->status_flags));\n\n  if (can_eval)\n  {\n    if (prev_literal_pool_p != NULL)\n    {\n      prev_literal_pool_p->status_flags |= SCANNER_LITERAL_POOL_CAN_EVAL;\n    }\n\n    if (has_arguments)\n    {\n      literal_pool_p->status_flags |= (SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS | SCANNER_LITERAL_POOL_NO_ARGUMENTS);\n    }\n  }\n\n  literal_pool_p->status_flags &= (uint16_t) ~SCANNER_LITERAL_POOL_CAN_EVAL;\n\n  parser_list_iterator_init (&literal_pool_p->literal_pool, &literal_iterator);\n\n  while (true)\n  {\n    literal_p = (lexer_lit_location_t *) parser_list_iterator_next (&literal_iterator);\n\n    if (literal_p == NULL)\n    {\n      return;\n    }\n\n    if (can_eval || (literal_p->type & SCANNER_LITERAL_EARLY_CREATE))\n    {\n      literal_p->type |= SCANNER_LITERAL_NO_REG | SCANNER_LITERAL_EARLY_CREATE;\n    }\n\n    uint8_t type = literal_p->type;\n    const uint8_t mask =\n      (SCANNER_LITERAL_IS_ARG | SCANNER_LITERAL_IS_DESTRUCTURED_ARG | SCANNER_LITERAL_IS_ARROW_DESTRUCTURED_ARG);\n\n    if ((type & mask) != SCANNER_LITERAL_IS_ARG)\n    {\n      break;\n    }\n  }\n\n  /* Destructured args are placed after the other arguments because of register assignments. */\n  bool has_destructured_arg = false;\n  scanner_literal_pool_t *new_literal_pool_p;\n\n  new_literal_pool_p = (scanner_literal_pool_t *) scanner_malloc (context_p, sizeof (scanner_literal_pool_t));\n\n  new_literal_pool_p->prev_p = literal_pool_p;\n  scanner_context_p->active_literal_pool_p = new_literal_pool_p;\n\n  *new_literal_pool_p = *literal_pool_p;\n  parser_list_init (&new_literal_pool_p->literal_pool,\n                    sizeof (lexer_lit_location_t),\n                    (uint32_t) ((128 - sizeof (void *)) / sizeof (lexer_lit_location_t)));\n\n  parser_list_iterator_init (&literal_pool_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_lit_location_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    uint8_t type = literal_p->type;\n\n    if (type & SCANNER_LITERAL_IS_ARG)\n    {\n      if (can_eval || (literal_p->type & SCANNER_LITERAL_EARLY_CREATE))\n      {\n        type |= SCANNER_LITERAL_NO_REG | SCANNER_LITERAL_EARLY_CREATE;\n        literal_p->type = type;\n      }\n\n      if (type & (SCANNER_LITERAL_IS_DESTRUCTURED_ARG | SCANNER_LITERAL_IS_ARROW_DESTRUCTURED_ARG))\n      {\n        has_destructured_arg = true;\n\n        if (type & SCANNER_LITERAL_IS_DESTRUCTURED_ARG)\n        {\n          continue;\n        }\n\n        type &= (uint8_t) ~SCANNER_LITERAL_IS_ARROW_DESTRUCTURED_ARG;\n        type |= SCANNER_LITERAL_IS_DESTRUCTURED_ARG;\n\n        literal_p->type = type;\n        continue;\n      }\n\n      lexer_lit_location_t *new_literal_p;\n      new_literal_p = (lexer_lit_location_t *) parser_list_append (context_p, &new_literal_pool_p->literal_pool);\n      *new_literal_p = *literal_p;\n    }\n    else if (has_arguments && scanner_literal_is_arguments (literal_p))\n    {\n      new_literal_pool_p->status_flags |= SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS;\n\n      if (type & SCANNER_LITERAL_NO_REG)\n      {\n        new_literal_pool_p->status_flags |= SCANNER_LITERAL_POOL_NO_ARGUMENTS;\n      }\n    }\n    else if (prev_literal_pool_p != NULL)\n    {\n      /* Propagate literal to upper level. */\n      lexer_lit_location_t *literal_location_p = scanner_add_custom_literal (context_p, prev_literal_pool_p, literal_p);\n      type |= SCANNER_LITERAL_NO_REG | SCANNER_LITERAL_IS_USED;\n      literal_location_p->type |= type;\n    }\n  }\n\n  if (has_destructured_arg)\n  {\n    parser_list_iterator_init (&literal_pool_p->literal_pool, &literal_iterator);\n\n    while ((literal_p = (lexer_lit_location_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n    {\n      const uint8_t expected_flags = SCANNER_LITERAL_IS_ARG | SCANNER_LITERAL_IS_DESTRUCTURED_ARG;\n\n      if ((literal_p->type & expected_flags) == expected_flags)\n      {\n        lexer_lit_location_t *new_literal_p;\n        new_literal_p = (lexer_lit_location_t *) parser_list_append (context_p, &new_literal_pool_p->literal_pool);\n        *new_literal_p = *literal_p;\n      }\n    }\n  }\n\n  new_literal_pool_p->prev_p = prev_literal_pool_p;\n\n  parser_list_free (&literal_pool_p->literal_pool);\n  scanner_free (literal_pool_p, sizeof (scanner_literal_pool_t));\n}",
        "func": "void\nscanner_filter_arguments (parser_context_t *context_p, /**< context */\n                          scanner_context_t *scanner_context_p) /**< scanner context */\n{\n  /* Fast case: check whether all literals are arguments. */\n  scanner_literal_pool_t *literal_pool_p = scanner_context_p->active_literal_pool_p;\n  scanner_literal_pool_t *prev_literal_pool_p = literal_pool_p->prev_p;\n  parser_list_iterator_t literal_iterator;\n  lexer_lit_location_t *literal_p;\n  bool can_eval = (literal_pool_p->status_flags & SCANNER_LITERAL_POOL_CAN_EVAL) != 0;\n  bool has_arguments = (literal_pool_p->status_flags & SCANNER_LITERAL_POOL_NO_ARGUMENTS) == 0;\n\n  JERRY_ASSERT (SCANNER_LITERAL_POOL_MAY_HAVE_ARGUMENTS (literal_pool_p->status_flags));\n\n  if (can_eval)\n  {\n    if (prev_literal_pool_p != NULL)\n    {\n      prev_literal_pool_p->status_flags |= SCANNER_LITERAL_POOL_CAN_EVAL;\n    }\n\n    if (has_arguments)\n    {\n      /* Force the lexically stored arguments object creation */\n      literal_pool_p->status_flags |= (SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS | SCANNER_LITERAL_POOL_NO_ARGUMENTS);\n    }\n  }\n\n  literal_pool_p->status_flags &= (uint16_t) ~SCANNER_LITERAL_POOL_CAN_EVAL;\n\n  parser_list_iterator_init (&literal_pool_p->literal_pool, &literal_iterator);\n\n  while (true)\n  {\n    literal_p = (lexer_lit_location_t *) parser_list_iterator_next (&literal_iterator);\n\n    if (literal_p == NULL)\n    {\n      return;\n    }\n\n    if (can_eval || (literal_p->type & SCANNER_LITERAL_EARLY_CREATE))\n    {\n      literal_p->type |= SCANNER_LITERAL_NO_REG | SCANNER_LITERAL_EARLY_CREATE;\n    }\n\n    uint8_t type = literal_p->type;\n    const uint8_t mask =\n      (SCANNER_LITERAL_IS_ARG | SCANNER_LITERAL_IS_DESTRUCTURED_ARG | SCANNER_LITERAL_IS_ARROW_DESTRUCTURED_ARG);\n\n    if ((type & mask) != SCANNER_LITERAL_IS_ARG)\n    {\n      break;\n    }\n  }\n\n  /* Destructured args are placed after the other arguments because of register assignments. */\n  bool has_destructured_arg = false;\n  scanner_literal_pool_t *new_literal_pool_p;\n\n  new_literal_pool_p = (scanner_literal_pool_t *) scanner_malloc (context_p, sizeof (scanner_literal_pool_t));\n\n  new_literal_pool_p->prev_p = literal_pool_p;\n  scanner_context_p->active_literal_pool_p = new_literal_pool_p;\n\n  *new_literal_pool_p = *literal_pool_p;\n  parser_list_init (&new_literal_pool_p->literal_pool,\n                    sizeof (lexer_lit_location_t),\n                    (uint32_t) ((128 - sizeof (void *)) / sizeof (lexer_lit_location_t)));\n\n  parser_list_iterator_init (&literal_pool_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_lit_location_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    uint8_t type = literal_p->type;\n\n    if (type & SCANNER_LITERAL_IS_ARG)\n    {\n      if (can_eval || (literal_p->type & SCANNER_LITERAL_EARLY_CREATE))\n      {\n        type |= SCANNER_LITERAL_NO_REG | SCANNER_LITERAL_EARLY_CREATE;\n        literal_p->type = type;\n      }\n\n      if (has_arguments && scanner_literal_is_arguments (literal_p))\n      {\n        /* 'arguments' function argument existence should prevent the arguments object construction */\n        new_literal_pool_p->status_flags =\n          (uint16_t) (new_literal_pool_p->status_flags\n                      & ~(SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS | SCANNER_LITERAL_POOL_NO_ARGUMENTS));\n      }\n\n      if (type & (SCANNER_LITERAL_IS_DESTRUCTURED_ARG | SCANNER_LITERAL_IS_ARROW_DESTRUCTURED_ARG))\n      {\n        has_destructured_arg = true;\n\n        if (type & SCANNER_LITERAL_IS_DESTRUCTURED_ARG)\n        {\n          continue;\n        }\n\n        type &= (uint8_t) ~SCANNER_LITERAL_IS_ARROW_DESTRUCTURED_ARG;\n        type |= SCANNER_LITERAL_IS_DESTRUCTURED_ARG;\n\n        literal_p->type = type;\n        continue;\n      }\n\n      lexer_lit_location_t *new_literal_p;\n      new_literal_p = (lexer_lit_location_t *) parser_list_append (context_p, &new_literal_pool_p->literal_pool);\n      *new_literal_p = *literal_p;\n    }\n    else if (has_arguments && scanner_literal_is_arguments (literal_p))\n    {\n      /* Arguments object is directly referenced from the function arguments */\n      new_literal_pool_p->status_flags |= SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS;\n\n      if (type & SCANNER_LITERAL_NO_REG)\n      {\n        new_literal_pool_p->status_flags |= SCANNER_LITERAL_POOL_NO_ARGUMENTS;\n      }\n    }\n    else if (prev_literal_pool_p != NULL)\n    {\n      /* Propagate literal to upper level. */\n      lexer_lit_location_t *literal_location_p = scanner_add_custom_literal (context_p, prev_literal_pool_p, literal_p);\n      type |= SCANNER_LITERAL_NO_REG | SCANNER_LITERAL_IS_USED;\n      literal_location_p->type |= type;\n    }\n  }\n\n  if (has_destructured_arg)\n  {\n    parser_list_iterator_init (&literal_pool_p->literal_pool, &literal_iterator);\n\n    while ((literal_p = (lexer_lit_location_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n    {\n      const uint8_t expected_flags = SCANNER_LITERAL_IS_ARG | SCANNER_LITERAL_IS_DESTRUCTURED_ARG;\n\n      if ((literal_p->type & expected_flags) == expected_flags)\n      {\n        lexer_lit_location_t *new_literal_p;\n        new_literal_p = (lexer_lit_location_t *) parser_list_append (context_p, &new_literal_pool_p->literal_pool);\n        *new_literal_p = *literal_p;\n      }\n    }\n  }\n\n  new_literal_pool_p->prev_p = prev_literal_pool_p;\n\n  parser_list_free (&literal_pool_p->literal_pool);\n  scanner_free (literal_pool_p, sizeof (scanner_literal_pool_t));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,7 @@\n \n     if (has_arguments)\n     {\n+      /* Force the lexically stored arguments object creation */\n       literal_pool_p->status_flags |= (SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS | SCANNER_LITERAL_POOL_NO_ARGUMENTS);\n     }\n   }\n@@ -81,6 +82,14 @@\n         literal_p->type = type;\n       }\n \n+      if (has_arguments && scanner_literal_is_arguments (literal_p))\n+      {\n+        /* 'arguments' function argument existence should prevent the arguments object construction */\n+        new_literal_pool_p->status_flags =\n+          (uint16_t) (new_literal_pool_p->status_flags\n+                      & ~(SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS | SCANNER_LITERAL_POOL_NO_ARGUMENTS));\n+      }\n+\n       if (type & (SCANNER_LITERAL_IS_DESTRUCTURED_ARG | SCANNER_LITERAL_IS_ARROW_DESTRUCTURED_ARG))\n       {\n         has_destructured_arg = true;\n@@ -103,6 +112,7 @@\n     }\n     else if (has_arguments && scanner_literal_is_arguments (literal_p))\n     {\n+      /* Arguments object is directly referenced from the function arguments */\n       new_literal_pool_p->status_flags |= SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS;\n \n       if (type & SCANNER_LITERAL_NO_REG)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      /* Force the lexically stored arguments object creation */",
                "      if (has_arguments && scanner_literal_is_arguments (literal_p))",
                "      {",
                "        /* 'arguments' function argument existence should prevent the arguments object construction */",
                "        new_literal_pool_p->status_flags =",
                "          (uint16_t) (new_literal_pool_p->status_flags",
                "                      & ~(SCANNER_LITERAL_POOL_ARGUMENTS_IN_ARGS | SCANNER_LITERAL_POOL_NO_ARGUMENTS));",
                "      }",
                "",
                "      /* Arguments object is directly referenced from the function arguments */"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-22892",
        "func_name": "jerryscript-project/jerryscript/opfunc_form_super_reference",
        "description": "There is an Assertion 'ecma_is_value_undefined (value) || ecma_is_value_null (value) || ecma_is_value_boolean (value) || ecma_is_value_number (value) || ecma_is_value_string (value) || ecma_is_value_bigint (value) || ecma_is_value_symbol (value) || ecma_is_value_object (value)' failed at jerry-core/ecma/base/ecma-helpers-value.c in Jerryscripts 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/c6aab480c1e2d968871028aec53c85ac5566b34a",
        "commit_title": "Fix arrow function this binding resolving if environment record is present",
        "commit_text": " This patch fixes #4872 and fixes #4876.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "ecma_value_t\nopfunc_form_super_reference (ecma_value_t **vm_stack_top_p, /**< current vm stack top */\n                             vm_frame_ctx_t *frame_ctx_p, /**< frame context */\n                             ecma_value_t prop_name, /**< property name to resolve */\n                             uint8_t opcode) /**< current cbc opcode */\n{\n  if (CBC_FUNCTION_GET_TYPE (frame_ctx_p->shared_p->bytecode_header_p->status_flags) == CBC_FUNCTION_CONSTRUCTOR)\n  {\n    ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);\n\n    if (!ecma_op_this_binding_is_initialized (environment_record_p))\n    {\n      return ecma_raise_reference_error (ECMA_ERR_CALL_SUPER_CONSTRUCTOR_DERIVED_CLASS_BEFORE_THIS);\n    }\n  }\n\n  ecma_value_t parent = ecma_op_resolve_super_base (frame_ctx_p->lex_env_p);\n\n  if (ECMA_IS_VALUE_ERROR (parent))\n  {\n    return ecma_raise_type_error (ECMA_ERR_INVOKE_NULLABLE_SUPER_METHOD);\n  }\n\n  if (!ecma_op_require_object_coercible (parent))\n  {\n    return ECMA_VALUE_ERROR;\n  }\n\n  ecma_value_t *stack_top_p = *vm_stack_top_p;\n\n  if (opcode >= CBC_EXT_SUPER_PROP_ASSIGNMENT_REFERENCE)\n  {\n    JERRY_ASSERT (opcode == CBC_EXT_SUPER_PROP_ASSIGNMENT_REFERENCE\n                  || opcode == CBC_EXT_SUPER_PROP_LITERAL_ASSIGNMENT_REFERENCE);\n    *stack_top_p++ = parent;\n    *stack_top_p++ = ecma_copy_value (prop_name);\n    *vm_stack_top_p = stack_top_p;\n\n    return ECMA_VALUE_EMPTY;\n  }\n\n  ecma_object_t *parent_p = ecma_get_object_from_value (parent);\n  ecma_string_t *prop_name_p = ecma_op_to_property_key (prop_name);\n\n  if (prop_name_p == NULL)\n  {\n    ecma_deref_object (parent_p);\n    return ECMA_VALUE_ERROR;\n  }\n\n  ecma_value_t result = ecma_op_object_get_with_receiver (parent_p, prop_name_p, frame_ctx_p->this_binding);\n  ecma_deref_ecma_string (prop_name_p);\n  ecma_deref_object (parent_p);\n\n  if (ECMA_IS_VALUE_ERROR (result))\n  {\n    return result;\n  }\n\n  if (opcode == CBC_EXT_SUPER_PROP_LITERAL_REFERENCE || opcode == CBC_EXT_SUPER_PROP_REFERENCE)\n  {\n    *stack_top_p++ = ecma_copy_value (frame_ctx_p->this_binding);\n    *stack_top_p++ = ECMA_VALUE_UNDEFINED;\n  }\n\n  *stack_top_p++ = result;\n  *vm_stack_top_p = stack_top_p;\n\n  return ECMA_VALUE_EMPTY;\n}",
        "func": "ecma_value_t\nopfunc_form_super_reference (ecma_value_t **vm_stack_top_p, /**< current vm stack top */\n                             vm_frame_ctx_t *frame_ctx_p, /**< frame context */\n                             ecma_value_t prop_name, /**< property name to resolve */\n                             uint8_t opcode) /**< current cbc opcode */\n{\n  ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);\n\n  if (environment_record_p && !ecma_op_this_binding_is_initialized (environment_record_p))\n  {\n    return ecma_raise_reference_error (ECMA_ERR_CALL_SUPER_CONSTRUCTOR_DERIVED_CLASS_BEFORE_THIS);\n  }\n\n  ecma_value_t parent = ecma_op_resolve_super_base (frame_ctx_p->lex_env_p);\n\n  if (ECMA_IS_VALUE_ERROR (parent))\n  {\n    return ecma_raise_type_error (ECMA_ERR_INVOKE_NULLABLE_SUPER_METHOD);\n  }\n\n  if (!ecma_op_require_object_coercible (parent))\n  {\n    return ECMA_VALUE_ERROR;\n  }\n\n  ecma_value_t *stack_top_p = *vm_stack_top_p;\n\n  if (opcode >= CBC_EXT_SUPER_PROP_ASSIGNMENT_REFERENCE)\n  {\n    JERRY_ASSERT (opcode == CBC_EXT_SUPER_PROP_ASSIGNMENT_REFERENCE\n                  || opcode == CBC_EXT_SUPER_PROP_LITERAL_ASSIGNMENT_REFERENCE);\n    *stack_top_p++ = parent;\n    *stack_top_p++ = ecma_copy_value (prop_name);\n    *vm_stack_top_p = stack_top_p;\n\n    return ECMA_VALUE_EMPTY;\n  }\n\n  ecma_object_t *parent_p = ecma_get_object_from_value (parent);\n  ecma_string_t *prop_name_p = ecma_op_to_property_key (prop_name);\n\n  if (prop_name_p == NULL)\n  {\n    ecma_deref_object (parent_p);\n    return ECMA_VALUE_ERROR;\n  }\n\n  ecma_value_t result = ecma_op_object_get_with_receiver (parent_p, prop_name_p, frame_ctx_p->this_binding);\n  ecma_deref_ecma_string (prop_name_p);\n  ecma_deref_object (parent_p);\n\n  if (ECMA_IS_VALUE_ERROR (result))\n  {\n    return result;\n  }\n\n  if (opcode == CBC_EXT_SUPER_PROP_LITERAL_REFERENCE || opcode == CBC_EXT_SUPER_PROP_REFERENCE)\n  {\n    *stack_top_p++ = ecma_copy_value (frame_ctx_p->this_binding);\n    *stack_top_p++ = ECMA_VALUE_UNDEFINED;\n  }\n\n  *stack_top_p++ = result;\n  *vm_stack_top_p = stack_top_p;\n\n  return ECMA_VALUE_EMPTY;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,14 +4,11 @@\n                              ecma_value_t prop_name, /**< property name to resolve */\n                              uint8_t opcode) /**< current cbc opcode */\n {\n-  if (CBC_FUNCTION_GET_TYPE (frame_ctx_p->shared_p->bytecode_header_p->status_flags) == CBC_FUNCTION_CONSTRUCTOR)\n+  ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);\n+\n+  if (environment_record_p && !ecma_op_this_binding_is_initialized (environment_record_p))\n   {\n-    ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);\n-\n-    if (!ecma_op_this_binding_is_initialized (environment_record_p))\n-    {\n-      return ecma_raise_reference_error (ECMA_ERR_CALL_SUPER_CONSTRUCTOR_DERIVED_CLASS_BEFORE_THIS);\n-    }\n+    return ecma_raise_reference_error (ECMA_ERR_CALL_SUPER_CONSTRUCTOR_DERIVED_CLASS_BEFORE_THIS);\n   }\n \n   ecma_value_t parent = ecma_op_resolve_super_base (frame_ctx_p->lex_env_p);",
        "diff_line_info": {
            "deleted_lines": [
                "  if (CBC_FUNCTION_GET_TYPE (frame_ctx_p->shared_p->bytecode_header_p->status_flags) == CBC_FUNCTION_CONSTRUCTOR)",
                "    ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);",
                "",
                "    if (!ecma_op_this_binding_is_initialized (environment_record_p))",
                "    {",
                "      return ecma_raise_reference_error (ECMA_ERR_CALL_SUPER_CONSTRUCTOR_DERIVED_CLASS_BEFORE_THIS);",
                "    }"
            ],
            "added_lines": [
                "  ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);",
                "",
                "  if (environment_record_p && !ecma_op_this_binding_is_initialized (environment_record_p))",
                "    return ecma_raise_reference_error (ECMA_ERR_CALL_SUPER_CONSTRUCTOR_DERIVED_CLASS_BEFORE_THIS);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-22892",
        "func_name": "jerryscript-project/jerryscript/ecma_op_function_call_simple",
        "description": "There is an Assertion 'ecma_is_value_undefined (value) || ecma_is_value_null (value) || ecma_is_value_boolean (value) || ecma_is_value_number (value) || ecma_is_value_string (value) || ecma_is_value_bigint (value) || ecma_is_value_symbol (value) || ecma_is_value_object (value)' failed at jerry-core/ecma/base/ecma-helpers-value.c in Jerryscripts 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/c6aab480c1e2d968871028aec53c85ac5566b34a",
        "commit_title": "Fix arrow function this binding resolving if environment record is present",
        "commit_text": " This patch fixes #4872 and fixes #4876.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "static ecma_value_t\necma_op_function_call_simple (ecma_object_t *func_obj_p, /**< Function object */\n                              ecma_value_t this_binding, /**< 'this' argument's value */\n                              const ecma_value_t *arguments_list_p, /**< arguments list */\n                              uint32_t arguments_list_len) /**< length of arguments list */\n{\n  JERRY_ASSERT (ecma_get_object_type (func_obj_p) == ECMA_OBJECT_TYPE_FUNCTION);\n\n  vm_frame_ctx_shared_args_t shared_args;\n  shared_args.header.status_flags = VM_FRAME_CTX_SHARED_HAS_ARG_LIST;\n  shared_args.header.function_object_p = func_obj_p;\n  shared_args.arg_list_p = arguments_list_p;\n  shared_args.arg_list_len = arguments_list_len;\n\n  /* Entering Function Code (ECMA-262 v5, 10.4.3) */\n  ecma_extended_object_t *ext_func_p = (ecma_extended_object_t *) func_obj_p;\n\n  ecma_object_t *scope_p = ECMA_GET_NON_NULL_POINTER_FROM_POINTER_TAG (ecma_object_t, ext_func_p->u.function.scope_cp);\n\n  /* 8. */\n  const ecma_compiled_code_t *bytecode_data_p = ecma_op_function_get_compiled_code (ext_func_p);\n  uint16_t status_flags = bytecode_data_p->status_flags;\n\n  shared_args.header.bytecode_header_p = bytecode_data_p;\n\n#if JERRY_BUILTIN_REALMS\n  ecma_global_object_t *realm_p = ecma_op_function_get_realm (bytecode_data_p);\n#endif /* JERRY_BUILTIN_REALMS */\n\n  /* 5. */\n  if (!(status_flags & CBC_CODE_FLAGS_LEXICAL_ENV_NOT_NEEDED))\n  {\n    shared_args.header.status_flags |= VM_FRAME_CTX_SHARED_FREE_LOCAL_ENV;\n    scope_p = ecma_create_decl_lex_env (scope_p);\n  }\n\n  /* 1. */\n  switch (CBC_FUNCTION_GET_TYPE (status_flags))\n  {\n#if JERRY_ESNEXT\n    case CBC_FUNCTION_CONSTRUCTOR:\n    {\n      return ecma_op_function_call_constructor (&shared_args, scope_p, this_binding);\n    }\n    case CBC_FUNCTION_ARROW:\n    {\n      ecma_arrow_function_t *arrow_func_p = (ecma_arrow_function_t *) func_obj_p;\n\n      if (ecma_is_value_undefined (arrow_func_p->new_target))\n      {\n        JERRY_CONTEXT (current_new_target_p) = NULL;\n      }\n      else\n      {\n        JERRY_CONTEXT (current_new_target_p) = ecma_get_object_from_value (arrow_func_p->new_target);\n      }\n\n      this_binding = arrow_func_p->this_binding;\n      break;\n    }\n\n#endif /* JERRY_ESNEXT */\n    default:\n    {\n#if JERRY_ESNEXT\n      shared_args.header.status_flags |= VM_FRAME_CTX_SHARED_NON_ARROW_FUNC;\n#endif /* JERRY_ESNEXT */\n\n      if (status_flags & CBC_CODE_FLAGS_STRICT_MODE)\n      {\n        break;\n      }\n\n      if (ecma_is_value_undefined (this_binding) || ecma_is_value_null (this_binding))\n      {\n        /* 2. */\n#if JERRY_BUILTIN_REALMS\n        this_binding = realm_p->this_binding;\n#else /* !JERRY_BUILTIN_REALMS */\n        this_binding = ecma_make_object_value (ecma_builtin_get_global ());\n#endif /* JERRY_BUILTIN_REALMS */\n      }\n      else if (!ecma_is_value_object (this_binding))\n      {\n        /* 3., 4. */\n        this_binding = ecma_op_to_object (this_binding);\n        shared_args.header.status_flags |= VM_FRAME_CTX_SHARED_FREE_THIS;\n\n        JERRY_ASSERT (!ECMA_IS_VALUE_ERROR (this_binding));\n      }\n      break;\n    }\n  }\n\n#if JERRY_BUILTIN_REALMS\n  ecma_global_object_t *saved_global_object_p = JERRY_CONTEXT (global_object_p);\n  JERRY_CONTEXT (global_object_p) = realm_p;\n#endif /* JERRY_BUILTIN_REALMS */\n\n  ecma_value_t ret_value = vm_run (&shared_args.header, this_binding, scope_p);\n\n#if JERRY_BUILTIN_REALMS\n  JERRY_CONTEXT (global_object_p) = saved_global_object_p;\n#endif /* JERRY_BUILTIN_REALMS */\n\n  if (JERRY_UNLIKELY (shared_args.header.status_flags & VM_FRAME_CTX_SHARED_FREE_LOCAL_ENV))\n  {\n    ecma_deref_object (scope_p);\n  }\n\n  if (JERRY_UNLIKELY (shared_args.header.status_flags & VM_FRAME_CTX_SHARED_FREE_THIS))\n  {\n    ecma_free_value (this_binding);\n  }\n\n  return ret_value;\n}",
        "func": "static ecma_value_t\necma_op_function_call_simple (ecma_object_t *func_obj_p, /**< Function object */\n                              ecma_value_t this_binding, /**< 'this' argument's value */\n                              const ecma_value_t *arguments_list_p, /**< arguments list */\n                              uint32_t arguments_list_len) /**< length of arguments list */\n{\n  JERRY_ASSERT (ecma_get_object_type (func_obj_p) == ECMA_OBJECT_TYPE_FUNCTION);\n\n  vm_frame_ctx_shared_args_t shared_args;\n  shared_args.header.status_flags = VM_FRAME_CTX_SHARED_HAS_ARG_LIST;\n  shared_args.header.function_object_p = func_obj_p;\n  shared_args.arg_list_p = arguments_list_p;\n  shared_args.arg_list_len = arguments_list_len;\n\n  /* Entering Function Code (ECMA-262 v5, 10.4.3) */\n  ecma_extended_object_t *ext_func_p = (ecma_extended_object_t *) func_obj_p;\n\n  ecma_object_t *scope_p = ECMA_GET_NON_NULL_POINTER_FROM_POINTER_TAG (ecma_object_t, ext_func_p->u.function.scope_cp);\n\n  /* 8. */\n  const ecma_compiled_code_t *bytecode_data_p = ecma_op_function_get_compiled_code (ext_func_p);\n  uint16_t status_flags = bytecode_data_p->status_flags;\n\n  shared_args.header.bytecode_header_p = bytecode_data_p;\n\n#if JERRY_BUILTIN_REALMS\n  ecma_global_object_t *realm_p = ecma_op_function_get_realm (bytecode_data_p);\n#endif /* JERRY_BUILTIN_REALMS */\n\n  /* 5. */\n  if (!(status_flags & CBC_CODE_FLAGS_LEXICAL_ENV_NOT_NEEDED))\n  {\n    shared_args.header.status_flags |= VM_FRAME_CTX_SHARED_FREE_LOCAL_ENV;\n    scope_p = ecma_create_decl_lex_env (scope_p);\n  }\n\n  /* 1. */\n  switch (CBC_FUNCTION_GET_TYPE (status_flags))\n  {\n#if JERRY_ESNEXT\n    case CBC_FUNCTION_CONSTRUCTOR:\n    {\n      return ecma_op_function_call_constructor (&shared_args, scope_p, this_binding);\n    }\n    case CBC_FUNCTION_ARROW:\n    {\n      ecma_arrow_function_t *arrow_func_p = (ecma_arrow_function_t *) func_obj_p;\n\n      if (ecma_is_value_undefined (arrow_func_p->new_target))\n      {\n        JERRY_CONTEXT (current_new_target_p) = NULL;\n      }\n      else\n      {\n        JERRY_CONTEXT (current_new_target_p) = ecma_get_object_from_value (arrow_func_p->new_target);\n      }\n\n      this_binding = arrow_func_p->this_binding;\n\n      if (JERRY_UNLIKELY (this_binding == ECMA_VALUE_UNINITIALIZED))\n      {\n        ecma_environment_record_t *env_record_p = ecma_op_get_environment_record (scope_p);\n        JERRY_ASSERT (env_record_p);\n        this_binding = env_record_p->this_binding;\n      }\n      break;\n    }\n\n#endif /* JERRY_ESNEXT */\n    default:\n    {\n#if JERRY_ESNEXT\n      shared_args.header.status_flags |= VM_FRAME_CTX_SHARED_NON_ARROW_FUNC;\n#endif /* JERRY_ESNEXT */\n\n      if (status_flags & CBC_CODE_FLAGS_STRICT_MODE)\n      {\n        break;\n      }\n\n      if (ecma_is_value_undefined (this_binding) || ecma_is_value_null (this_binding))\n      {\n        /* 2. */\n#if JERRY_BUILTIN_REALMS\n        this_binding = realm_p->this_binding;\n#else /* !JERRY_BUILTIN_REALMS */\n        this_binding = ecma_make_object_value (ecma_builtin_get_global ());\n#endif /* JERRY_BUILTIN_REALMS */\n      }\n      else if (!ecma_is_value_object (this_binding))\n      {\n        /* 3., 4. */\n        this_binding = ecma_op_to_object (this_binding);\n        shared_args.header.status_flags |= VM_FRAME_CTX_SHARED_FREE_THIS;\n\n        JERRY_ASSERT (!ECMA_IS_VALUE_ERROR (this_binding));\n      }\n      break;\n    }\n  }\n\n#if JERRY_BUILTIN_REALMS\n  ecma_global_object_t *saved_global_object_p = JERRY_CONTEXT (global_object_p);\n  JERRY_CONTEXT (global_object_p) = realm_p;\n#endif /* JERRY_BUILTIN_REALMS */\n\n  ecma_value_t ret_value = vm_run (&shared_args.header, this_binding, scope_p);\n\n#if JERRY_BUILTIN_REALMS\n  JERRY_CONTEXT (global_object_p) = saved_global_object_p;\n#endif /* JERRY_BUILTIN_REALMS */\n\n  if (JERRY_UNLIKELY (shared_args.header.status_flags & VM_FRAME_CTX_SHARED_FREE_LOCAL_ENV))\n  {\n    ecma_deref_object (scope_p);\n  }\n\n  if (JERRY_UNLIKELY (shared_args.header.status_flags & VM_FRAME_CTX_SHARED_FREE_THIS))\n  {\n    ecma_free_value (this_binding);\n  }\n\n  return ret_value;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,6 +56,13 @@\n       }\n \n       this_binding = arrow_func_p->this_binding;\n+\n+      if (JERRY_UNLIKELY (this_binding == ECMA_VALUE_UNINITIALIZED))\n+      {\n+        ecma_environment_record_t *env_record_p = ecma_op_get_environment_record (scope_p);\n+        JERRY_ASSERT (env_record_p);\n+        this_binding = env_record_p->this_binding;\n+      }\n       break;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "      if (JERRY_UNLIKELY (this_binding == ECMA_VALUE_UNINITIALIZED))",
                "      {",
                "        ecma_environment_record_t *env_record_p = ecma_op_get_environment_record (scope_p);",
                "        JERRY_ASSERT (env_record_p);",
                "        this_binding = env_record_p->this_binding;",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-22892",
        "func_name": "jerryscript-project/jerryscript/ecma_op_get_environment_record",
        "description": "There is an Assertion 'ecma_is_value_undefined (value) || ecma_is_value_null (value) || ecma_is_value_boolean (value) || ecma_is_value_number (value) || ecma_is_value_string (value) || ecma_is_value_bigint (value) || ecma_is_value_symbol (value) || ecma_is_value_object (value)' failed at jerry-core/ecma/base/ecma-helpers-value.c in Jerryscripts 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/c6aab480c1e2d968871028aec53c85ac5566b34a",
        "commit_title": "Fix arrow function this binding resolving if environment record is present",
        "commit_text": " This patch fixes #4872 and fixes #4876.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "ecma_environment_record_t *\necma_op_get_environment_record (ecma_object_t *lex_env_p) /**< lexical environment */\n{\n  JERRY_ASSERT (lex_env_p != NULL);\n\n  ecma_string_t *property_name_p = ecma_get_internal_string (LIT_INTERNAL_MAGIC_STRING_ENVIRONMENT_RECORD);\n  while (true)\n  {\n    if (ecma_get_lex_env_type (lex_env_p) == ECMA_LEXICAL_ENVIRONMENT_DECLARATIVE)\n    {\n      ecma_property_t *property_p = ecma_find_named_property (lex_env_p, property_name_p);\n\n      if (property_p != NULL)\n      {\n        ecma_property_value_t *property_value_p = ECMA_PROPERTY_VALUE_PTR (property_p);\n        return ECMA_GET_INTERNAL_VALUE_POINTER (ecma_environment_record_t, property_value_p->value);\n      }\n    }\n\n    JERRY_ASSERT (lex_env_p->u2.outer_reference_cp != JMEM_CP_NULL);\n    lex_env_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, lex_env_p->u2.outer_reference_cp);\n  }\n}",
        "func": "ecma_environment_record_t *\necma_op_get_environment_record (ecma_object_t *lex_env_p) /**< lexical environment */\n{\n  JERRY_ASSERT (lex_env_p != NULL);\n\n  ecma_string_t *property_name_p = ecma_get_internal_string (LIT_INTERNAL_MAGIC_STRING_ENVIRONMENT_RECORD);\n  while (true)\n  {\n    if (ecma_get_lex_env_type (lex_env_p) == ECMA_LEXICAL_ENVIRONMENT_DECLARATIVE)\n    {\n      ecma_property_t *property_p = ecma_find_named_property (lex_env_p, property_name_p);\n\n      if (property_p != NULL)\n      {\n        ecma_property_value_t *property_value_p = ECMA_PROPERTY_VALUE_PTR (property_p);\n        return ECMA_GET_INTERNAL_VALUE_POINTER (ecma_environment_record_t, property_value_p->value);\n      }\n    }\n\n    if (lex_env_p->u2.outer_reference_cp == JMEM_CP_NULL)\n    {\n      break;\n    }\n\n    lex_env_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, lex_env_p->u2.outer_reference_cp);\n  }\n\n  return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,13 @@\n       }\n     }\n \n-    JERRY_ASSERT (lex_env_p->u2.outer_reference_cp != JMEM_CP_NULL);\n+    if (lex_env_p->u2.outer_reference_cp == JMEM_CP_NULL)\n+    {\n+      break;\n+    }\n+\n     lex_env_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, lex_env_p->u2.outer_reference_cp);\n   }\n+\n+  return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    JERRY_ASSERT (lex_env_p->u2.outer_reference_cp != JMEM_CP_NULL);"
            ],
            "added_lines": [
                "    if (lex_env_p->u2.outer_reference_cp == JMEM_CP_NULL)",
                "    {",
                "      break;",
                "    }",
                "",
                "",
                "  return NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-22892",
        "func_name": "jerryscript-project/jerryscript/vm_super_call",
        "description": "There is an Assertion 'ecma_is_value_undefined (value) || ecma_is_value_null (value) || ecma_is_value_boolean (value) || ecma_is_value_number (value) || ecma_is_value_string (value) || ecma_is_value_bigint (value) || ecma_is_value_symbol (value) || ecma_is_value_object (value)' failed at jerry-core/ecma/base/ecma-helpers-value.c in Jerryscripts 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/c6aab480c1e2d968871028aec53c85ac5566b34a",
        "commit_title": "Fix arrow function this binding resolving if environment record is present",
        "commit_text": " This patch fixes #4872 and fixes #4876.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "static void\nvm_super_call (vm_frame_ctx_t *frame_ctx_p) /**< frame context */\n{\n  JERRY_ASSERT (frame_ctx_p->call_operation == VM_EXEC_SUPER_CALL);\n  JERRY_ASSERT (frame_ctx_p->byte_code_p[0] == CBC_EXT_OPCODE);\n\n  const uint8_t *byte_code_p = frame_ctx_p->byte_code_p + 3;\n  uint8_t opcode = byte_code_p[-2];\n  uint32_t arguments_list_len;\n\n  bool spread_arguments = opcode >= CBC_EXT_SPREAD_SUPER_CALL;\n\n  ecma_collection_t *collection_p = NULL;\n  ecma_value_t *arguments_p;\n\n  if (spread_arguments)\n  {\n    ecma_value_t collection = *(--frame_ctx_p->stack_top_p);\n    collection_p = ECMA_GET_INTERNAL_VALUE_POINTER (ecma_collection_t, collection);\n    arguments_p = collection_p->buffer_p;\n    arguments_list_len = collection_p->item_count;\n  }\n  else\n  {\n    arguments_list_len = byte_code_p[-1];\n    arguments_p = frame_ctx_p->stack_top_p;\n  }\n\n  ecma_value_t func_value = *(--frame_ctx_p->stack_top_p);\n  ecma_value_t completion_value;\n\n  ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);\n\n  if (!ecma_is_constructor (func_value))\n  {\n    completion_value = ecma_raise_type_error (ECMA_ERR_VALUE_FOR_CLASS_HERITAGE_IS_NOT_A_CONSTRUCTOR);\n  }\n  else\n  {\n    ecma_object_t *func_obj_p = ecma_get_object_from_value (func_value);\n    completion_value =\n      ecma_op_function_construct (func_obj_p, JERRY_CONTEXT (current_new_target_p), arguments_p, arguments_list_len);\n\n    if (!ECMA_IS_VALUE_ERROR (completion_value) && ecma_op_this_binding_is_initialized (environment_record_p))\n    {\n      ecma_free_value (completion_value);\n      completion_value = ecma_raise_reference_error (ECMA_ERR_SUPER_CONSTRUCTOR_MAY_ONLY_BE_CALLED_ONCE);\n    }\n  }\n\n  /* Free registers. */\n  for (uint32_t i = 0; i < arguments_list_len; i++)\n  {\n    ecma_fast_free_value (arguments_p[i]);\n  }\n\n  if (collection_p != NULL)\n  {\n    ecma_collection_destroy (collection_p);\n  }\n\n  if (ecma_is_value_object (completion_value))\n  {\n    ecma_op_bind_this_value (environment_record_p, completion_value);\n    frame_ctx_p->this_binding = completion_value;\n\n    ecma_value_t fields_value = opfunc_init_class_fields (vm_get_class_function (frame_ctx_p), completion_value);\n\n    if (ECMA_IS_VALUE_ERROR (fields_value))\n    {\n      ecma_free_value (completion_value);\n      completion_value = ECMA_VALUE_ERROR;\n    }\n  }\n\n  ecma_free_value (func_value);\n\n  if (JERRY_UNLIKELY (ECMA_IS_VALUE_ERROR (completion_value)))\n  {\n#if JERRY_DEBUGGER\n    JERRY_CONTEXT (debugger_exception_byte_code_p) = frame_ctx_p->byte_code_p;\n#endif /* JERRY_DEBUGGER */\n    frame_ctx_p->byte_code_p = (uint8_t *) vm_error_byte_code_p;\n  }\n  else\n  {\n    frame_ctx_p->byte_code_p = byte_code_p;\n    uint32_t opcode_data = vm_decode_table[(CBC_END + 1) + opcode];\n\n    if (!(opcode_data & (VM_OC_PUT_STACK | VM_OC_PUT_BLOCK)))\n    {\n      ecma_fast_free_value (completion_value);\n    }\n    else if (opcode_data & VM_OC_PUT_STACK)\n    {\n      *frame_ctx_p->stack_top_p++ = completion_value;\n    }\n    else\n    {\n      ecma_fast_free_value (VM_GET_REGISTER (frame_ctx_p, 0));\n      VM_GET_REGISTERS (frame_ctx_p)[0] = completion_value;\n    }\n  }\n}",
        "func": "static void\nvm_super_call (vm_frame_ctx_t *frame_ctx_p) /**< frame context */\n{\n  JERRY_ASSERT (frame_ctx_p->call_operation == VM_EXEC_SUPER_CALL);\n  JERRY_ASSERT (frame_ctx_p->byte_code_p[0] == CBC_EXT_OPCODE);\n\n  const uint8_t *byte_code_p = frame_ctx_p->byte_code_p + 3;\n  uint8_t opcode = byte_code_p[-2];\n  uint32_t arguments_list_len;\n\n  bool spread_arguments = opcode >= CBC_EXT_SPREAD_SUPER_CALL;\n\n  ecma_collection_t *collection_p = NULL;\n  ecma_value_t *arguments_p;\n\n  if (spread_arguments)\n  {\n    ecma_value_t collection = *(--frame_ctx_p->stack_top_p);\n    collection_p = ECMA_GET_INTERNAL_VALUE_POINTER (ecma_collection_t, collection);\n    arguments_p = collection_p->buffer_p;\n    arguments_list_len = collection_p->item_count;\n  }\n  else\n  {\n    arguments_list_len = byte_code_p[-1];\n    arguments_p = frame_ctx_p->stack_top_p;\n  }\n\n  ecma_value_t func_value = *(--frame_ctx_p->stack_top_p);\n  ecma_value_t completion_value;\n\n  ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);\n  JERRY_ASSERT (environment_record_p);\n\n  if (!ecma_is_constructor (func_value))\n  {\n    completion_value = ecma_raise_type_error (ECMA_ERR_VALUE_FOR_CLASS_HERITAGE_IS_NOT_A_CONSTRUCTOR);\n  }\n  else\n  {\n    ecma_object_t *func_obj_p = ecma_get_object_from_value (func_value);\n    completion_value =\n      ecma_op_function_construct (func_obj_p, JERRY_CONTEXT (current_new_target_p), arguments_p, arguments_list_len);\n\n    if (!ECMA_IS_VALUE_ERROR (completion_value) && ecma_op_this_binding_is_initialized (environment_record_p))\n    {\n      ecma_free_value (completion_value);\n      completion_value = ecma_raise_reference_error (ECMA_ERR_SUPER_CONSTRUCTOR_MAY_ONLY_BE_CALLED_ONCE);\n    }\n  }\n\n  /* Free registers. */\n  for (uint32_t i = 0; i < arguments_list_len; i++)\n  {\n    ecma_fast_free_value (arguments_p[i]);\n  }\n\n  if (collection_p != NULL)\n  {\n    ecma_collection_destroy (collection_p);\n  }\n\n  if (ecma_is_value_object (completion_value))\n  {\n    ecma_op_bind_this_value (environment_record_p, completion_value);\n    frame_ctx_p->this_binding = completion_value;\n\n    ecma_value_t fields_value = opfunc_init_class_fields (vm_get_class_function (frame_ctx_p), completion_value);\n\n    if (ECMA_IS_VALUE_ERROR (fields_value))\n    {\n      ecma_free_value (completion_value);\n      completion_value = ECMA_VALUE_ERROR;\n    }\n  }\n\n  ecma_free_value (func_value);\n\n  if (JERRY_UNLIKELY (ECMA_IS_VALUE_ERROR (completion_value)))\n  {\n#if JERRY_DEBUGGER\n    JERRY_CONTEXT (debugger_exception_byte_code_p) = frame_ctx_p->byte_code_p;\n#endif /* JERRY_DEBUGGER */\n    frame_ctx_p->byte_code_p = (uint8_t *) vm_error_byte_code_p;\n  }\n  else\n  {\n    frame_ctx_p->byte_code_p = byte_code_p;\n    uint32_t opcode_data = vm_decode_table[(CBC_END + 1) + opcode];\n\n    if (!(opcode_data & (VM_OC_PUT_STACK | VM_OC_PUT_BLOCK)))\n    {\n      ecma_fast_free_value (completion_value);\n    }\n    else if (opcode_data & VM_OC_PUT_STACK)\n    {\n      *frame_ctx_p->stack_top_p++ = completion_value;\n    }\n    else\n    {\n      ecma_fast_free_value (VM_GET_REGISTER (frame_ctx_p, 0));\n      VM_GET_REGISTERS (frame_ctx_p)[0] = completion_value;\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,6 +30,7 @@\n   ecma_value_t completion_value;\n \n   ecma_environment_record_t *environment_record_p = ecma_op_get_environment_record (frame_ctx_p->lex_env_p);\n+  JERRY_ASSERT (environment_record_p);\n \n   if (!ecma_is_constructor (func_value))\n   {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  JERRY_ASSERT (environment_record_p);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-44994",
        "func_name": "jerryscript-project/jerryscript/ecma_atomic_read_modify_write",
        "description": "There is an Assertion ''JERRY_CONTEXT (jmem_heap_allocated_size) == 0'' failed at /jerry-core/jmem/jmem-heap.c in Jerryscript 3.0.0.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/9adbfb7f515ccd6aee82e66e068dccf8a0f39c4b",
        "commit_title": "Fix memory leak in AtomicModifyWrite",
        "commit_text": " This patch fixes #4894.  JerryScript-DCO-1.0-Signed-off-by: Robert Fancsik robert.fancsik@h-lab.eu",
        "func_before": "ecma_value_t\necma_atomic_read_modify_write (ecma_value_t typedarray, /**< typedArray argument */\n                               ecma_value_t index, /**< index argument */\n                               ecma_value_t value, /**< value argument */\n                               ecma_atomics_op_t op) /**< operation argument */\n{\n  /* 1. */\n  ecma_value_t buffer = ecma_validate_shared_integer_typedarray (typedarray, false);\n\n  if (ECMA_IS_VALUE_ERROR (buffer))\n  {\n    return buffer;\n  }\n\n  /* 2. */\n  ecma_value_t idx = ecma_validate_atomic_access (typedarray, index);\n\n  if (ECMA_IS_VALUE_ERROR (idx))\n  {\n    return idx;\n  }\n\n  /* 3. */\n  ecma_object_t *typedarray_p = ecma_get_object_from_value (typedarray);\n  ecma_typedarray_info_t target_info = ecma_typedarray_get_info (typedarray_p);\n\n  /* 4-5. */\n  ecma_value_t val = ECMA_VALUE_ERROR;\n  ecma_number_t tmp;\n  if (target_info.id == ECMA_BIGINT64_ARRAY || target_info.id == ECMA_BIGUINT64_ARRAY)\n  {\n    val = ecma_bigint_to_bigint (value, true);\n  }\n  else if (!ECMA_IS_VALUE_ERROR (ecma_op_to_integer (value, &tmp)))\n  {\n    val = ecma_make_number_value (tmp);\n  }\n\n  if (ECMA_IS_VALUE_ERROR (val))\n  {\n    return val;\n  }\n\n  /* 6. */\n  uint8_t element_size = target_info.element_size;\n\n  /* 7. */\n  ecma_typedarray_type_t element_type = target_info.id;\n\n  /* 8. */\n  uint32_t offset = target_info.offset;\n\n  /* 9. */\n  uint32_t indexed_position = ecma_number_to_uint32 (idx) * element_size + offset;\n\n  JERRY_UNUSED (indexed_position);\n  JERRY_UNUSED (element_type);\n  JERRY_UNUSED (val);\n  JERRY_UNUSED (buffer);\n  JERRY_UNUSED (op);\n\n  ecma_free_value (val);\n\n  /* 10. */\n  return ecma_make_uint32_value (0);\n}",
        "func": "ecma_value_t\necma_atomic_read_modify_write (ecma_value_t typedarray, /**< typedArray argument */\n                               ecma_value_t index, /**< index argument */\n                               ecma_value_t value, /**< value argument */\n                               ecma_atomics_op_t op) /**< operation argument */\n{\n  /* 1. */\n  ecma_value_t buffer = ecma_validate_shared_integer_typedarray (typedarray, false);\n\n  if (ECMA_IS_VALUE_ERROR (buffer))\n  {\n    return buffer;\n  }\n\n  /* 2. */\n  ecma_value_t idx = ecma_validate_atomic_access (typedarray, index);\n\n  if (ECMA_IS_VALUE_ERROR (idx))\n  {\n    return idx;\n  }\n\n  /* 3. */\n  ecma_object_t *typedarray_p = ecma_get_object_from_value (typedarray);\n  ecma_typedarray_info_t target_info = ecma_typedarray_get_info (typedarray_p);\n\n  /* 4-5. */\n  ecma_value_t val = ECMA_VALUE_ERROR;\n  ecma_number_t tmp;\n  if (target_info.id == ECMA_BIGINT64_ARRAY || target_info.id == ECMA_BIGUINT64_ARRAY)\n  {\n    val = ecma_bigint_to_bigint (value, true);\n  }\n  else if (!ECMA_IS_VALUE_ERROR (ecma_op_to_integer (value, &tmp)))\n  {\n    val = ecma_make_number_value (tmp);\n  }\n\n  if (ECMA_IS_VALUE_ERROR (val))\n  {\n    return val;\n  }\n\n  /* 6. */\n  uint8_t element_size = target_info.element_size;\n\n  /* 7. */\n  ecma_typedarray_type_t element_type = target_info.id;\n\n  /* 8. */\n  uint32_t offset = target_info.offset;\n\n  /* 9. */\n  uint32_t indexed_position = ecma_number_to_uint32 (idx) * element_size + offset;\n\n  ecma_free_value (idx);\n\n  JERRY_UNUSED (indexed_position);\n  JERRY_UNUSED (element_type);\n  JERRY_UNUSED (val);\n  JERRY_UNUSED (buffer);\n  JERRY_UNUSED (op);\n\n  ecma_free_value (val);\n\n  /* 10. */\n  return ecma_make_uint32_value (0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -53,6 +53,8 @@\n   /* 9. */\n   uint32_t indexed_position = ecma_number_to_uint32 (idx) * element_size + offset;\n \n+  ecma_free_value (idx);\n+\n   JERRY_UNUSED (indexed_position);\n   JERRY_UNUSED (element_type);\n   JERRY_UNUSED (val);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  ecma_free_value (idx);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-49286",
        "func_name": "squid-cache/squid/ipcCreate",
        "description": "Squid is a caching proxy for the Web supporting HTTP, HTTPS, FTP, and more. Due to an Incorrect Check of Function Return Value bug Squid is vulnerable to a Denial of Service attack against its Helper process management. This bug is fixed by Squid version 6.5. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
        "git_url": "https://github.com/squid-cache/squid/commit/6014c6648a2a54a4ecb7f952ea1163e0798f9264",
        "commit_title": "Exit without asserting when helper process startup fails (#1543)",
        "commit_text": " ... to dup() after fork() and before execvp().  Assertions are for handling program logic errors. Helper initialization code already handled system call errors correctly (i.e. by exiting the newly created helper process with an error), except for a couple of assert()s that could be triggered by dup(2) failures.  This bug was discovered and detailed by Joshua Rogers at https://megamansec.github.io/Squid-Security-Audit/ipc-assert.html where it was filed as 'Assertion in Squid \"Helper\" Process Creator'.",
        "func_before": "pid_t\nipcCreate(int type, const char *prog, const char *const args[], const char *name, Ip::Address &local_addr, int *rfd, int *wfd, void **hIpc)\n{\n    pid_t pid;\n    Ip::Address ChS;\n    Ip::Address PaS;\n    struct addrinfo *AI = nullptr;\n    int crfd = -1;\n    int prfd = -1;\n    int cwfd = -1;\n    int pwfd = -1;\n    int fd;\n    int t1, t2, t3;\n    int x;\n    int xerrno;\n\n#if USE_POLL && _SQUID_OSF_\n    assert(type != IPC_FIFO);\n#endif\n\n    if (rfd)\n        *rfd = -1;\n\n    if (wfd)\n        *wfd = -1;\n\n    if (hIpc)\n        *hIpc = nullptr;\n\n// NP: no wrapping around d and c usage since we *want* code expansion\n#define IPC_CHECK_FAIL(f,d,c) \\\n    if ((f) < 0) { \\\n        debugs(54, DBG_CRITICAL, \"ERROR: Failed to create helper \" d \" FD: \" << c); \\\n        return ipcCloseAllFD(prfd, pwfd, crfd, cwfd); \\\n    } else void(0)\n\n    if (type == IPC_TCP_SOCKET) {\n        crfd = cwfd = comm_open_listener(SOCK_STREAM,\n                                         0,\n                                         local_addr,\n                                         COMM_NOCLOEXEC,\n                                         name);\n        prfd = pwfd = comm_open(SOCK_STREAM,\n                                0,          /* protocol */\n                                local_addr,\n                                0,          /* blocking */\n                                name);\n        IPC_CHECK_FAIL(crfd, \"child read\", \"TCP \" << local_addr);\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"TCP \" << local_addr);\n    } else if (type == IPC_UDP_SOCKET) {\n        crfd = cwfd = comm_open(SOCK_DGRAM,\n                                0,\n                                local_addr,\n                                COMM_NOCLOEXEC,\n                                name);\n        prfd = pwfd = comm_open(SOCK_DGRAM,\n                                0,\n                                local_addr,\n                                0,\n                                name);\n        IPC_CHECK_FAIL(crfd, \"child read\", \"UDP\" << local_addr);\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"UDP\" << local_addr);\n    } else if (type == IPC_FIFO) {\n        int p2c[2];\n        int c2p[2];\n\n        if (pipe(p2c) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: pipe: \" << xstrerr(xerrno));\n            return -1; // maybe ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n        fd_open(prfd = p2c[0], FD_PIPE, \"IPC FIFO Parent Read\");\n        fd_open(cwfd = p2c[1], FD_PIPE, \"IPC FIFO Child Write\");\n\n        if (pipe(c2p) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: pipe: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n        fd_open(crfd = c2p[0], FD_PIPE, \"IPC FIFO Child Read\");\n        fd_open(pwfd = c2p[1], FD_PIPE, \"IPC FIFO Parent Write\");\n\n        IPC_CHECK_FAIL(crfd, \"child read\", \"FIFO pipe\");\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"FIFO pipe\");\n\n#if HAVE_SOCKETPAIR && defined(AF_UNIX)\n\n    } else if (type == IPC_UNIX_STREAM) {\n        int fds[2];\n        int buflen = 32768;\n\n        if (socketpair(AF_UNIX, SOCK_STREAM, 0, fds) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: socketpair: \" << xstrerr(xerrno));\n            return -1;\n        }\n\n        errno = 0;\n        if (setsockopt(fds[0], SOL_SOCKET, SO_SNDBUF, (void *) &buflen, sizeof(buflen)) == -1)  {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        if (setsockopt(fds[0], SOL_SOCKET, SO_RCVBUF, (void *) &buflen, sizeof(buflen)) == -1) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        if (setsockopt(fds[1], SOL_SOCKET, SO_SNDBUF, (void *) &buflen, sizeof(buflen)) == -1) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        if (setsockopt(fds[1], SOL_SOCKET, SO_RCVBUF, (void *) &buflen, sizeof(buflen)) == -1) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        fd_open(prfd = pwfd = fds[0], FD_PIPE, \"IPC UNIX STREAM Parent\");\n        fd_open(crfd = cwfd = fds[1], FD_PIPE, \"IPC UNIX STREAM Parent\");\n        IPC_CHECK_FAIL(crfd, \"child read\", \"UDS socket\");\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"UDS socket\");\n\n    } else if (type == IPC_UNIX_DGRAM) {\n        int fds[2];\n\n        if (socketpair(AF_UNIX, SOCK_DGRAM, 0, fds) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: socketpair: \" << xstrerr(xerrno));\n            return -1;\n        }\n\n        fd_open(prfd = pwfd = fds[0], FD_PIPE, \"IPC UNIX DGRAM Parent\");\n        fd_open(crfd = cwfd = fds[1], FD_PIPE, \"IPC UNIX DGRAM Parent\");\n\n        IPC_CHECK_FAIL(crfd, \"child read\", \"UDS datagram\");\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"UDS datagram\");\n#endif\n\n    } else {\n        assert(IPC_NONE);\n    }\n\n    debugs(54, 3, \"ipcCreate: prfd FD \" << prfd);\n    debugs(54, 3, \"ipcCreate: pwfd FD \" << pwfd);\n    debugs(54, 3, \"ipcCreate: crfd FD \" << crfd);\n    debugs(54, 3, \"ipcCreate: cwfd FD \" << cwfd);\n\n    if (type == IPC_TCP_SOCKET || type == IPC_UDP_SOCKET) {\n        Ip::Address::InitAddr(AI);\n\n        if (getsockname(pwfd, AI->ai_addr, &AI->ai_addrlen) < 0) {\n            xerrno = errno;\n            Ip::Address::FreeAddr(AI);\n            debugs(54, DBG_CRITICAL, \"ipcCreate: getsockname: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        PaS = *AI;\n\n        debugs(54, 3, \"ipcCreate: FD \" << pwfd << \" sockaddr \" << PaS);\n\n        Ip::Address::FreeAddr(AI);\n\n        Ip::Address::InitAddr(AI);\n\n        if (getsockname(crfd, AI->ai_addr, &AI->ai_addrlen) < 0) {\n            xerrno = errno;\n            Ip::Address::FreeAddr(AI);\n            debugs(54, DBG_CRITICAL, \"ipcCreate: getsockname: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        ChS = *AI;\n\n        Ip::Address::FreeAddr(AI);\n\n        debugs(54, 3, \"ipcCreate: FD \" << crfd << \" sockaddr \" << ChS );\n\n    }\n\n    if (type == IPC_TCP_SOCKET) {\n        if (listen(crfd, 1) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ipcCreate: listen FD \" << crfd << \": \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        debugs(54, 3, \"ipcCreate: FD \" << crfd << \" listening...\");\n    }\n\n    /* flush or else we get dup data if unbuffered_logs is set */\n    logsFlush();\n\n    if ((pid = fork()) < 0) {\n        xerrno = errno;\n        debugs(54, DBG_IMPORTANT, \"ipcCreate: fork: \" << xstrerr(xerrno));\n        return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n    }\n\n    if (pid > 0) {      /* parent */\n        /* close shared socket with child */\n        comm_close(crfd);\n\n        if (cwfd != crfd)\n            comm_close(cwfd);\n\n        cwfd = crfd = -1;\n\n        if (type == IPC_TCP_SOCKET || type == IPC_UDP_SOCKET) {\n            if (comm_connect_addr(pwfd, ChS) == Comm::COMM_ERROR)\n                return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        if (type == IPC_UDP_SOCKET)\n            x = comm_udp_recv(prfd, hello_buf, sizeof(hello_buf)-1, 0);\n        else\n            x = read(prfd, hello_buf, sizeof(hello_buf)-1);\n        xerrno = errno;\n        if (x >= 0)\n            hello_buf[x] = '\\0';\n\n        if (x < 0) {\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: PARENT: hello read test failed\");\n            debugs(54, DBG_CRITICAL, \"--> read: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        } else if (strcmp(hello_buf, hello_string)) {\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: PARENT: hello read test failed\");\n            debugs(54, DBG_CRITICAL, \"--> read returned \" << x);\n            debugs(54, DBG_CRITICAL, \"--> got '\" << rfc1738_escape(hello_buf) << \"'\");\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        commUnsetFdTimeout(prfd);\n        commSetNonBlocking(prfd);\n        commSetNonBlocking(pwfd);\n\n        if (rfd)\n            *rfd = prfd;\n\n        if (wfd)\n            *wfd = pwfd;\n\n        fd_table[prfd].flags.ipc = 1;\n\n        fd_table[pwfd].flags.ipc = 1;\n\n        if (Config.sleep_after_fork)\n            std::this_thread::sleep_for(std::chrono::microseconds(Config.sleep_after_fork));\n\n        return pid;\n    }\n\n    /* child */\n    TheProcessKind = pkHelper;\n    no_suid();          /* give up extra privileges */\n\n    /* close shared socket with parent */\n    close(prfd);\n\n    if (pwfd != prfd)\n        close(pwfd);\n\n    pwfd = prfd = -1;\n\n    if (type == IPC_TCP_SOCKET) {\n        debugs(54, 3, \"ipcCreate: calling accept on FD \" << crfd);\n\n        if ((fd = accept(crfd, nullptr, nullptr)) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: FD \" << crfd << \" accept: \" << xstrerr(xerrno));\n            _exit(1);\n        }\n\n        debugs(54, 3, \"ipcCreate: CHILD accepted new FD \" << fd);\n        close(crfd);\n        cwfd = crfd = fd;\n    } else if (type == IPC_UDP_SOCKET) {\n        if (comm_connect_addr(crfd, PaS) == Comm::COMM_ERROR)\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n    }\n\n    if (type == IPC_UDP_SOCKET) {\n        x = comm_udp_send(cwfd, hello_string, strlen(hello_string) + 1, 0);\n\n        if (x < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"sendto FD \" << cwfd << \": \" << xstrerr(xerrno));\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: CHILD: hello write test failed\");\n            _exit(1);\n        }\n    } else {\n        if (write(cwfd, hello_string, strlen(hello_string) + 1) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"write FD \" << cwfd << \": \" << xstrerr(xerrno));\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: CHILD: hello write test failed\");\n            _exit(1);\n        }\n    }\n\n    PutEnvironment();\n    /*\n     * This double-dup stuff avoids problems when one of\n     *  crfd, cwfd, or debug_log are in the rage 0-2.\n     */\n\n    do {\n        /* First make sure 0-2 is occupied by something. Gets cleaned up later */\n        x = dup(crfd);\n        assert(x > -1);\n    } while (x < 3 && x > -1);\n\n    close(x);\n\n    t1 = dup(crfd);\n\n    t2 = dup(cwfd);\n\n    t3 = dup(fileno(debug_log));\n\n    assert(t1 > 2 && t2 > 2 && t3 > 2);\n\n    close(crfd);\n\n    close(cwfd);\n\n    close(fileno(debug_log));\n\n    dup2(t1, 0);\n\n    dup2(t2, 1);\n\n    dup2(t3, 2);\n\n    close(t1);\n\n    close(t2);\n\n    close(t3);\n\n    /* Make sure all other filedescriptors are closed */\n    for (x = 3; x < SQUID_MAXFD; ++x)\n        close(x);\n\n#if HAVE_SETSID\n    if (opt_no_daemon)\n        setsid();\n#endif\n\n    execvp(prog, (char *const *) args);\n    xerrno = errno;\n\n    ResyncDebugLog(fdopen(2, \"a+\"));\n\n    debugs(54, DBG_CRITICAL, \"ipcCreate: \" << prog << \": \" << xstrerr(xerrno));\n\n    _exit(1);\n\n    return 0;\n}",
        "func": "pid_t\nipcCreate(int type, const char *prog, const char *const args[], const char *name, Ip::Address &local_addr, int *rfd, int *wfd, void **hIpc)\n{\n    pid_t pid;\n    Ip::Address ChS;\n    Ip::Address PaS;\n    struct addrinfo *AI = nullptr;\n    int crfd = -1;\n    int prfd = -1;\n    int cwfd = -1;\n    int pwfd = -1;\n    int fd;\n    int t1, t2, t3;\n    int x;\n    int xerrno;\n\n#if USE_POLL && _SQUID_OSF_\n    assert(type != IPC_FIFO);\n#endif\n\n    if (rfd)\n        *rfd = -1;\n\n    if (wfd)\n        *wfd = -1;\n\n    if (hIpc)\n        *hIpc = nullptr;\n\n// NP: no wrapping around d and c usage since we *want* code expansion\n#define IPC_CHECK_FAIL(f,d,c) \\\n    if ((f) < 0) { \\\n        debugs(54, DBG_CRITICAL, \"ERROR: Failed to create helper \" d \" FD: \" << c); \\\n        return ipcCloseAllFD(prfd, pwfd, crfd, cwfd); \\\n    } else void(0)\n\n    if (type == IPC_TCP_SOCKET) {\n        crfd = cwfd = comm_open_listener(SOCK_STREAM,\n                                         0,\n                                         local_addr,\n                                         COMM_NOCLOEXEC,\n                                         name);\n        prfd = pwfd = comm_open(SOCK_STREAM,\n                                0,          /* protocol */\n                                local_addr,\n                                0,          /* blocking */\n                                name);\n        IPC_CHECK_FAIL(crfd, \"child read\", \"TCP \" << local_addr);\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"TCP \" << local_addr);\n    } else if (type == IPC_UDP_SOCKET) {\n        crfd = cwfd = comm_open(SOCK_DGRAM,\n                                0,\n                                local_addr,\n                                COMM_NOCLOEXEC,\n                                name);\n        prfd = pwfd = comm_open(SOCK_DGRAM,\n                                0,\n                                local_addr,\n                                0,\n                                name);\n        IPC_CHECK_FAIL(crfd, \"child read\", \"UDP\" << local_addr);\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"UDP\" << local_addr);\n    } else if (type == IPC_FIFO) {\n        int p2c[2];\n        int c2p[2];\n\n        if (pipe(p2c) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: pipe: \" << xstrerr(xerrno));\n            return -1; // maybe ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n        fd_open(prfd = p2c[0], FD_PIPE, \"IPC FIFO Parent Read\");\n        fd_open(cwfd = p2c[1], FD_PIPE, \"IPC FIFO Child Write\");\n\n        if (pipe(c2p) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: pipe: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n        fd_open(crfd = c2p[0], FD_PIPE, \"IPC FIFO Child Read\");\n        fd_open(pwfd = c2p[1], FD_PIPE, \"IPC FIFO Parent Write\");\n\n        IPC_CHECK_FAIL(crfd, \"child read\", \"FIFO pipe\");\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"FIFO pipe\");\n\n#if HAVE_SOCKETPAIR && defined(AF_UNIX)\n\n    } else if (type == IPC_UNIX_STREAM) {\n        int fds[2];\n        int buflen = 32768;\n\n        if (socketpair(AF_UNIX, SOCK_STREAM, 0, fds) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: socketpair: \" << xstrerr(xerrno));\n            return -1;\n        }\n\n        errno = 0;\n        if (setsockopt(fds[0], SOL_SOCKET, SO_SNDBUF, (void *) &buflen, sizeof(buflen)) == -1)  {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        if (setsockopt(fds[0], SOL_SOCKET, SO_RCVBUF, (void *) &buflen, sizeof(buflen)) == -1) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        if (setsockopt(fds[1], SOL_SOCKET, SO_SNDBUF, (void *) &buflen, sizeof(buflen)) == -1) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        if (setsockopt(fds[1], SOL_SOCKET, SO_RCVBUF, (void *) &buflen, sizeof(buflen)) == -1) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ERROR: setsockopt failed: \" << xstrerr(xerrno));\n            errno = 0;\n        }\n        fd_open(prfd = pwfd = fds[0], FD_PIPE, \"IPC UNIX STREAM Parent\");\n        fd_open(crfd = cwfd = fds[1], FD_PIPE, \"IPC UNIX STREAM Parent\");\n        IPC_CHECK_FAIL(crfd, \"child read\", \"UDS socket\");\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"UDS socket\");\n\n    } else if (type == IPC_UNIX_DGRAM) {\n        int fds[2];\n\n        if (socketpair(AF_UNIX, SOCK_DGRAM, 0, fds) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: socketpair: \" << xstrerr(xerrno));\n            return -1;\n        }\n\n        fd_open(prfd = pwfd = fds[0], FD_PIPE, \"IPC UNIX DGRAM Parent\");\n        fd_open(crfd = cwfd = fds[1], FD_PIPE, \"IPC UNIX DGRAM Parent\");\n\n        IPC_CHECK_FAIL(crfd, \"child read\", \"UDS datagram\");\n        IPC_CHECK_FAIL(prfd, \"parent read\", \"UDS datagram\");\n#endif\n\n    } else {\n        assert(IPC_NONE);\n    }\n\n    debugs(54, 3, \"ipcCreate: prfd FD \" << prfd);\n    debugs(54, 3, \"ipcCreate: pwfd FD \" << pwfd);\n    debugs(54, 3, \"ipcCreate: crfd FD \" << crfd);\n    debugs(54, 3, \"ipcCreate: cwfd FD \" << cwfd);\n\n    if (type == IPC_TCP_SOCKET || type == IPC_UDP_SOCKET) {\n        Ip::Address::InitAddr(AI);\n\n        if (getsockname(pwfd, AI->ai_addr, &AI->ai_addrlen) < 0) {\n            xerrno = errno;\n            Ip::Address::FreeAddr(AI);\n            debugs(54, DBG_CRITICAL, \"ipcCreate: getsockname: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        PaS = *AI;\n\n        debugs(54, 3, \"ipcCreate: FD \" << pwfd << \" sockaddr \" << PaS);\n\n        Ip::Address::FreeAddr(AI);\n\n        Ip::Address::InitAddr(AI);\n\n        if (getsockname(crfd, AI->ai_addr, &AI->ai_addrlen) < 0) {\n            xerrno = errno;\n            Ip::Address::FreeAddr(AI);\n            debugs(54, DBG_CRITICAL, \"ipcCreate: getsockname: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        ChS = *AI;\n\n        Ip::Address::FreeAddr(AI);\n\n        debugs(54, 3, \"ipcCreate: FD \" << crfd << \" sockaddr \" << ChS );\n\n    }\n\n    if (type == IPC_TCP_SOCKET) {\n        if (listen(crfd, 1) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_IMPORTANT, \"ipcCreate: listen FD \" << crfd << \": \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        debugs(54, 3, \"ipcCreate: FD \" << crfd << \" listening...\");\n    }\n\n    /* flush or else we get dup data if unbuffered_logs is set */\n    logsFlush();\n\n    if ((pid = fork()) < 0) {\n        xerrno = errno;\n        debugs(54, DBG_IMPORTANT, \"ipcCreate: fork: \" << xstrerr(xerrno));\n        return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n    }\n\n    if (pid > 0) {      /* parent */\n        /* close shared socket with child */\n        comm_close(crfd);\n\n        if (cwfd != crfd)\n            comm_close(cwfd);\n\n        cwfd = crfd = -1;\n\n        if (type == IPC_TCP_SOCKET || type == IPC_UDP_SOCKET) {\n            if (comm_connect_addr(pwfd, ChS) == Comm::COMM_ERROR)\n                return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        if (type == IPC_UDP_SOCKET)\n            x = comm_udp_recv(prfd, hello_buf, sizeof(hello_buf)-1, 0);\n        else\n            x = read(prfd, hello_buf, sizeof(hello_buf)-1);\n        xerrno = errno;\n        if (x >= 0)\n            hello_buf[x] = '\\0';\n\n        if (x < 0) {\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: PARENT: hello read test failed\");\n            debugs(54, DBG_CRITICAL, \"--> read: \" << xstrerr(xerrno));\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        } else if (strcmp(hello_buf, hello_string)) {\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: PARENT: hello read test failed\");\n            debugs(54, DBG_CRITICAL, \"--> read returned \" << x);\n            debugs(54, DBG_CRITICAL, \"--> got '\" << rfc1738_escape(hello_buf) << \"'\");\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n        }\n\n        commUnsetFdTimeout(prfd);\n        commSetNonBlocking(prfd);\n        commSetNonBlocking(pwfd);\n\n        if (rfd)\n            *rfd = prfd;\n\n        if (wfd)\n            *wfd = pwfd;\n\n        fd_table[prfd].flags.ipc = 1;\n\n        fd_table[pwfd].flags.ipc = 1;\n\n        if (Config.sleep_after_fork)\n            std::this_thread::sleep_for(std::chrono::microseconds(Config.sleep_after_fork));\n\n        return pid;\n    }\n\n    /* child */\n    TheProcessKind = pkHelper;\n    no_suid();          /* give up extra privileges */\n\n    /* close shared socket with parent */\n    close(prfd);\n\n    if (pwfd != prfd)\n        close(pwfd);\n\n    pwfd = prfd = -1;\n\n    if (type == IPC_TCP_SOCKET) {\n        debugs(54, 3, \"ipcCreate: calling accept on FD \" << crfd);\n\n        if ((fd = accept(crfd, nullptr, nullptr)) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"ipcCreate: FD \" << crfd << \" accept: \" << xstrerr(xerrno));\n            _exit(1);\n        }\n\n        debugs(54, 3, \"ipcCreate: CHILD accepted new FD \" << fd);\n        close(crfd);\n        cwfd = crfd = fd;\n    } else if (type == IPC_UDP_SOCKET) {\n        if (comm_connect_addr(crfd, PaS) == Comm::COMM_ERROR)\n            return ipcCloseAllFD(prfd, pwfd, crfd, cwfd);\n    }\n\n    if (type == IPC_UDP_SOCKET) {\n        x = comm_udp_send(cwfd, hello_string, strlen(hello_string) + 1, 0);\n\n        if (x < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"sendto FD \" << cwfd << \": \" << xstrerr(xerrno));\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: CHILD: hello write test failed\");\n            _exit(1);\n        }\n    } else {\n        if (write(cwfd, hello_string, strlen(hello_string) + 1) < 0) {\n            xerrno = errno;\n            debugs(54, DBG_CRITICAL, \"write FD \" << cwfd << \": \" << xstrerr(xerrno));\n            debugs(54, DBG_CRITICAL, \"ERROR: ipcCreate: CHILD: hello write test failed\");\n            _exit(1);\n        }\n    }\n\n    PutEnvironment();\n\n    // A dup(2) wrapper that reports and exits the process on errors. The\n    // exiting logic is only suitable for this child process context.\n    const auto dupOrExit = [prog,name](const int oldFd) {\n        const auto newFd = dup(oldFd);\n        if (newFd < 0) {\n            const auto savedErrno = errno;\n            debugs(54, DBG_CRITICAL, \"ERROR: Helper process initialization failure: \" << name <<\n                   Debug::Extra << \"helper (CHILD) PID: \" << getpid() <<\n                   Debug::Extra << \"helper program name: \" << prog <<\n                   Debug::Extra << \"dup(2) system call error for FD \" << oldFd << \": \" << xstrerr(savedErrno));\n            _exit(EXIT_FAILURE);\n        }\n        return newFd;\n    };\n\n    /*\n     * This double-dup stuff avoids problems when one of\n     *  crfd, cwfd, or debug_log are in the rage 0-2.\n     */\n\n    do {\n        /* First make sure 0-2 is occupied by something. Gets cleaned up later */\n        x = dupOrExit(crfd);\n    } while (x < 3);\n\n    close(x);\n\n    t1 = dupOrExit(crfd);\n\n    t2 = dupOrExit(cwfd);\n\n    t3 = dupOrExit(fileno(debug_log));\n\n    assert(t1 > 2 && t2 > 2 && t3 > 2);\n\n    close(crfd);\n\n    close(cwfd);\n\n    close(fileno(debug_log));\n\n    dup2(t1, 0);\n\n    dup2(t2, 1);\n\n    dup2(t3, 2);\n\n    close(t1);\n\n    close(t2);\n\n    close(t3);\n\n    /* Make sure all other filedescriptors are closed */\n    for (x = 3; x < SQUID_MAXFD; ++x)\n        close(x);\n\n#if HAVE_SETSID\n    if (opt_no_daemon)\n        setsid();\n#endif\n\n    execvp(prog, (char *const *) args);\n    xerrno = errno;\n\n    ResyncDebugLog(fdopen(2, \"a+\"));\n\n    debugs(54, DBG_CRITICAL, \"ipcCreate: \" << prog << \": \" << xstrerr(xerrno));\n\n    _exit(1);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -299,6 +299,22 @@\n     }\n \n     PutEnvironment();\n+\n+    // A dup(2) wrapper that reports and exits the process on errors. The\n+    // exiting logic is only suitable for this child process context.\n+    const auto dupOrExit = [prog,name](const int oldFd) {\n+        const auto newFd = dup(oldFd);\n+        if (newFd < 0) {\n+            const auto savedErrno = errno;\n+            debugs(54, DBG_CRITICAL, \"ERROR: Helper process initialization failure: \" << name <<\n+                   Debug::Extra << \"helper (CHILD) PID: \" << getpid() <<\n+                   Debug::Extra << \"helper program name: \" << prog <<\n+                   Debug::Extra << \"dup(2) system call error for FD \" << oldFd << \": \" << xstrerr(savedErrno));\n+            _exit(EXIT_FAILURE);\n+        }\n+        return newFd;\n+    };\n+\n     /*\n      * This double-dup stuff avoids problems when one of\n      *  crfd, cwfd, or debug_log are in the rage 0-2.\n@@ -306,17 +322,16 @@\n \n     do {\n         /* First make sure 0-2 is occupied by something. Gets cleaned up later */\n-        x = dup(crfd);\n-        assert(x > -1);\n-    } while (x < 3 && x > -1);\n+        x = dupOrExit(crfd);\n+    } while (x < 3);\n \n     close(x);\n \n-    t1 = dup(crfd);\n-\n-    t2 = dup(cwfd);\n-\n-    t3 = dup(fileno(debug_log));\n+    t1 = dupOrExit(crfd);\n+\n+    t2 = dupOrExit(cwfd);\n+\n+    t3 = dupOrExit(fileno(debug_log));\n \n     assert(t1 > 2 && t2 > 2 && t3 > 2);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        x = dup(crfd);",
                "        assert(x > -1);",
                "    } while (x < 3 && x > -1);",
                "    t1 = dup(crfd);",
                "",
                "    t2 = dup(cwfd);",
                "",
                "    t3 = dup(fileno(debug_log));"
            ],
            "added_lines": [
                "",
                "    // A dup(2) wrapper that reports and exits the process on errors. The",
                "    // exiting logic is only suitable for this child process context.",
                "    const auto dupOrExit = [prog,name](const int oldFd) {",
                "        const auto newFd = dup(oldFd);",
                "        if (newFd < 0) {",
                "            const auto savedErrno = errno;",
                "            debugs(54, DBG_CRITICAL, \"ERROR: Helper process initialization failure: \" << name <<",
                "                   Debug::Extra << \"helper (CHILD) PID: \" << getpid() <<",
                "                   Debug::Extra << \"helper program name: \" << prog <<",
                "                   Debug::Extra << \"dup(2) system call error for FD \" << oldFd << \": \" << xstrerr(savedErrno));",
                "            _exit(EXIT_FAILURE);",
                "        }",
                "        return newFd;",
                "    };",
                "",
                "        x = dupOrExit(crfd);",
                "    } while (x < 3);",
                "    t1 = dupOrExit(crfd);",
                "",
                "    t2 = dupOrExit(cwfd);",
                "",
                "    t3 = dupOrExit(fileno(debug_log));"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8012",
        "func_name": "lldpd/cdp_decode",
        "description": "lldpd before 0.8.0 allows remote attackers to cause a denial of service (assertion failure and daemon crash) via a malformed packet.",
        "git_url": "https://github.com/lldpd/lldpd/commit/793526f8884455f43daecd0a2c46772388417a00",
        "commit_title": "protocols: don't use assert on paths that can be reached",
        "commit_text": " Malformed packets should not make lldpd crash. Ensure we can handle them by not using assert() in this part.",
        "func_before": "int\ncdp_decode(struct lldpd *cfg, char *frame, int s,\n    struct lldpd_hardware *hardware,\n    struct lldpd_chassis **newchassis, struct lldpd_port **newport)\n{\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_port *port;\n\tstruct lldpd_mgmt *mgmt;\n\tstruct in_addr addr;\n#if 0\n\tu_int16_t cksum;\n#endif\n\tu_int8_t *software = NULL, *platform = NULL;\n\tint software_len = 0, platform_len = 0, proto, version, nb, caps;\n\tconst unsigned char cdpaddr[] = CDP_MULTICAST_ADDR;\n#ifdef ENABLE_FDP\n\tconst unsigned char fdpaddr[] = CDP_MULTICAST_ADDR;\n\tint fdp = 0;\n#endif\n\tu_int8_t *pos, *tlv, *pos_address, *pos_next_address;\n\tint length, len_eth, tlv_type, tlv_len, addresses_len, address_len;\n#ifdef ENABLE_DOT1\n\tstruct lldpd_vlan *vlan;\n#endif\n\n\tlog_debug(\"cdp\", \"decode CDP frame received on %s\",\n\t    hardware->h_ifname);\n\n\tif ((chassis = calloc(1, sizeof(struct lldpd_chassis))) == NULL) {\n\t\tlog_warn(\"cdp\", \"failed to allocate remote chassis\");\n\t\treturn -1;\n\t}\n\tTAILQ_INIT(&chassis->c_mgmt);\n\tif ((port = calloc(1, sizeof(struct lldpd_port))) == NULL) {\n\t\tlog_warn(\"cdp\", \"failed to allocate remote port\");\n\t\tfree(chassis);\n\t\treturn -1;\n\t}\n#ifdef ENABLE_DOT1\n\tTAILQ_INIT(&port->p_vlans);\n#endif\n\n\tlength = s;\n\tpos = (u_int8_t*)frame;\n\n\tif (length < 2*ETHER_ADDR_LEN + sizeof(u_int16_t) /* Ethernet */ +\n\t    8 /* LLC */ + 4 /* CDP header */) {\n\t\tlog_warn(\"cdp\", \"too short CDP/FDP frame received on %s\", hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n\tif (PEEK_CMP(cdpaddr, sizeof(cdpaddr)) != 0) {\n#ifdef ENABLE_FDP\n\t\tPEEK_RESTORE((u_int8_t*)frame);\n\t\tif (PEEK_CMP(fdpaddr, sizeof(fdpaddr)) != 0)\n\t\t\tfdp = 1;\n\t\telse {\n#endif\n\t\t\tlog_info(\"cdp\", \"frame not targeted at CDP/FDP multicast address received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n#ifdef ENABLE_FDP\n\t\t}\n#endif\n\t}\n\tPEEK_DISCARD(ETHER_ADDR_LEN);\t/* Don't care of source address */\n\tlen_eth = PEEK_UINT16;\n\tif (len_eth > length) {\n\t\tlog_warnx(\"cdp\", \"incorrect 802.3 frame size reported on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tPEEK_DISCARD(6);\t/* Skip beginning of LLC */\n\tproto = PEEK_UINT16;\n\tif (proto != LLC_PID_CDP) {\n\t\tif ((proto != LLC_PID_DRIP) &&\n\t\t    (proto != LLC_PID_PAGP) &&\n\t\t    (proto != LLC_PID_PVSTP) &&\n\t\t    (proto != LLC_PID_UDLD) &&\n\t\t    (proto != LLC_PID_VTP) &&\n\t\t    (proto != LLC_PID_DTP) &&\n\t\t    (proto != LLC_PID_STP))\n\t\t\tlog_debug(\"cdp\", \"incorrect LLC protocol ID received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n#if 0\n\t/* Check checksum */\n\tcksum = frame_checksum(pos, len_eth - 8,\n#ifdef ENABLE_FDP\n\t    !fdp\t\t/* fdp = 0 -> cisco checksum */\n#else\n\t    1\t\t\t/* cisco checksum */\n#endif\n\t\t);\n\tif (cksum != 0) {\n\t\tlog_info(\"cdp\", \"incorrect CDP/FDP checksum for frame received on %s (%d)\",\n\t\t\t  hardware->h_ifname, cksum);\n\t\tgoto malformed;\n\t}\n#endif\n\n\t/* Check version */\n\tversion = PEEK_UINT8;\n\tif ((version != 1) && (version != 2)) {\n\t\tlog_warnx(\"cdp\", \"incorrect CDP/FDP version (%d) for frame received on %s\",\n\t\t    version, hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tchassis->c_ttl = PEEK_UINT8; /* TTL */\n\tPEEK_DISCARD_UINT16;\t     /* Checksum, already checked */\n\n\twhile (length) {\n\t\tif (length < 4) {\n\t\t\tlog_warnx(\"cdp\", \"CDP/FDP TLV header is too large for \"\n\t\t\t    \"frame received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\ttlv_type = PEEK_UINT16;\n\t\ttlv_len = PEEK_UINT16 - 4;\n\t\t(void)PEEK_SAVE(tlv);\n\t\tif ((tlv_len < 0) || (length < tlv_len)) {\n\t\t\tlog_warnx(\"cdp\", \"incorrect size in CDP/FDP TLV header for frame \"\n\t\t\t    \"received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\tswitch (tlv_type) {\n\t\tcase CDP_TLV_CHASSIS:\n\t\t\tif ((chassis->c_name = (char *)calloc(1, tlv_len + 1)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis name\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(chassis->c_name, tlv_len);\n\t\t\tchassis->c_id_subtype = LLDP_CHASSISID_SUBTYPE_LOCAL;\n\t\t\tif ((chassis->c_id =  (char *)malloc(tlv_len)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis ID\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tmemcpy(chassis->c_id, chassis->c_name, tlv_len);\n\t\t\tchassis->c_id_len = tlv_len;\n\t\t\tbreak;\n\t\tcase CDP_TLV_ADDRESSES:\n\t\t\tCHECK_TLV_SIZE(4, \"Address\");\n\t\t\taddresses_len = tlv_len - 4;\n\t\t\tfor (nb = PEEK_UINT32; nb > 0; nb--) {\n\t\t\t\t(void)PEEK_SAVE(pos_address);\n\t\t\t\t/* We first try to get the real length of the packet */\n\t\t\t\tif (addresses_len < 2) {\n\t\t\t\t\tlog_warn(\"cdp\", \"too short address subframe \"\n\t\t\t\t\t\t  \"received on %s\",\n\t\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tPEEK_DISCARD_UINT8; addresses_len--;\n\t\t\t\taddress_len = PEEK_UINT8; addresses_len--;\n\t\t\t\tif (addresses_len < address_len + 2) {\n\t\t\t\t\tlog_warn(\"cdp\", \"too short address subframe \"\n\t\t\t\t\t\t  \"received on %s\",\n\t\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tPEEK_DISCARD(address_len);\n\t\t\t\taddresses_len -= address_len;\n\t\t\t\taddress_len = PEEK_UINT16; addresses_len -= 2;\n\t\t\t\tif (addresses_len < address_len) {\n\t\t\t\t\tlog_warn(\"cdp\", \"too short address subframe \"\n\t\t\t\t\t\t  \"received on %s\",\n\t\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tPEEK_DISCARD(address_len);\n\t\t\t\t(void)PEEK_SAVE(pos_next_address);\n\t\t\t\t/* Next, we go back and try to extract\n\t\t\t\t   IPv4 address */\n\t\t\t\tPEEK_RESTORE(pos_address);\n\t\t\t\tif ((PEEK_UINT8 == 1) && (PEEK_UINT8 == 1) &&\n\t\t\t\t    (PEEK_UINT8 == CDP_ADDRESS_PROTO_IP) &&\n\t\t\t\t    (PEEK_UINT16 == sizeof(struct in_addr))) {\n\t\t\t\t\t\tPEEK_BYTES(&addr, sizeof(struct in_addr));\n\t\t\t\t\t\tmgmt = lldpd_alloc_mgmt(LLDPD_AF_IPV4, &addr, \n\t\t\t\t\t\t\t\t\tsizeof(struct in_addr), 0);\n\t\t\t\t\t\tif (mgmt == NULL) {\n\t\t\t\t\t\t\tassert(errno == ENOMEM);\n\t\t\t\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for management address\");\n\t\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);\n\t\t\t\t}\n\t\t\t\t/* Go to the end of the address */\n\t\t\t\tPEEK_RESTORE(pos_next_address);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CDP_TLV_PORT:\n\t\t\tif (tlv_len == 0) {\n\t\t\t\tlog_warn(\"cd[\", \"too short port description received\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tif ((port->p_descr = (char *)calloc(1, tlv_len + 1)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for port description\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(port->p_descr, tlv_len);\n\t\t\tport->p_id_subtype = LLDP_PORTID_SUBTYPE_IFNAME;\n\t\t\tif ((port->p_id =  (char *)calloc(1, tlv_len)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for port ID\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tmemcpy(port->p_id, port->p_descr, tlv_len);\n\t\t\tport->p_id_len = tlv_len;\n\t\t\tbreak;\n\t\tcase CDP_TLV_CAPABILITIES:\n#ifdef ENABLE_FDP\n\t\t\tif (fdp) {\n\t\t\t\t/* Capabilities are string with FDP */\n\t\t\t\tif (!strncmp(\"Router\", (char*)pos, tlv_len))\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_ROUTER;\n\t\t\t\telse if (!strncmp(\"Switch\", (char*)pos, tlv_len))\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_BRIDGE;\n\t\t\t\telse if (!strncmp(\"Bridge\", (char*)pos, tlv_len))\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_REPEATER;\n\t\t\t\telse\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_STATION;\n\t\t\t\tchassis->c_cap_available = chassis->c_cap_enabled;\n\t\t\t\tbreak;\n\t\t\t}\n#endif\n\t\t\tCHECK_TLV_SIZE(4, \"Capabilities\");\n\t\t\tcaps = PEEK_UINT32;\n\t\t\tif (caps & CDP_CAP_ROUTER)\n\t\t\t\tchassis->c_cap_enabled |= LLDP_CAP_ROUTER;\n\t\t\tif (caps & 0x0e)\n\t\t\t\tchassis->c_cap_enabled |= LLDP_CAP_BRIDGE;\n\t\t\tif (chassis->c_cap_enabled == 0)\n\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_STATION;\n\t\t\tchassis->c_cap_available = chassis->c_cap_enabled;\n\t\t\tbreak;\n\t\tcase CDP_TLV_SOFTWARE:\n\t\t\tsoftware_len = tlv_len;\n\t\t\t(void)PEEK_SAVE(software);\n\t\t\tbreak;\n\t\tcase CDP_TLV_PLATFORM:\n\t\t\tplatform_len = tlv_len;\n\t\t\t(void)PEEK_SAVE(platform);\n\t\t\tbreak;\n#ifdef ENABLE_DOT1\n\t\tcase CDP_TLV_NATIVEVLAN:\n\t\t\tCHECK_TLV_SIZE(2, \"Native VLAN\");\n\t\t\tif ((vlan = (struct lldpd_vlan *)calloc(1,\n\t\t\t\tsizeof(struct lldpd_vlan))) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to alloc vlan \"\n\t\t\t\t\t  \"structure for \"\n\t\t\t\t\t  \"tlv received on %s\",\n\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tvlan->v_vid = port->p_pvid = PEEK_UINT16;\n\t\t\tif (asprintf(&vlan->v_name, \"VLAN #%d\", vlan->v_vid) == -1) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to alloc VLAN name for \"\n\t\t\t\t\t  \"TLV received on %s\",\n\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\tfree(vlan);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tTAILQ_INSERT_TAIL(&port->p_vlans,\n\t\t\t\t\t  vlan, v_entries);\n\t\t\tbreak;\n#endif\n\t\tdefault:\n\t\t\tlog_debug(\"cdp\", \"unknown CDP/FDP TLV type (%d) received on %s\",\n\t\t\t    ntohs(tlv_type), hardware->h_ifname);\n\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t}\n\t\tPEEK_DISCARD(tlv + tlv_len - pos);\n\t}\n\tif (!software && platform) {\n\t\tif ((chassis->c_descr = (char *)calloc(1,\n\t\t\t    platform_len + 1)) == NULL) {\n\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis description\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tmemcpy(chassis->c_descr, platform, platform_len);\n\t} else if (software && !platform) {\n\t\tif ((chassis->c_descr = (char *)calloc(1,\n\t\t\t    software_len + 1)) == NULL) {\n\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis description\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tmemcpy(chassis->c_descr, software, software_len);\n\t} else if (software && platform) {\n#define CONCAT_PLATFORM \" running on\\n\"\n\t\tif ((chassis->c_descr = (char *)calloc(1,\n\t\t\t    software_len + platform_len +\n\t\t\t    strlen(CONCAT_PLATFORM) + 1)) == NULL) {\n\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis description\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tmemcpy(chassis->c_descr, platform, platform_len);\n\t\tmemcpy(chassis->c_descr + platform_len,\n\t\t    CONCAT_PLATFORM, strlen(CONCAT_PLATFORM));\n\t\tmemcpy(chassis->c_descr + platform_len + strlen(CONCAT_PLATFORM),\n\t\t    software, software_len);\n\t}\n\tif ((chassis->c_id == NULL) ||\n\t    (port->p_id == NULL) ||\n\t    (chassis->c_name == NULL) ||\n\t    (chassis->c_descr == NULL) ||\n\t    (port->p_descr == NULL) ||\n\t    (chassis->c_ttl == 0) ||\n\t    (chassis->c_cap_enabled == 0)) {\n\t\tlog_warnx(\"cdp\", \"some mandatory CDP/FDP tlv are missing for frame received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\t*newchassis = chassis;\n\t*newport = port;\n\treturn 1;\n\nmalformed:\n\tlldpd_chassis_cleanup(chassis, 1);\n\tlldpd_port_cleanup(port, 1);\n\tfree(port);\n\treturn -1;\n}",
        "func": "int\ncdp_decode(struct lldpd *cfg, char *frame, int s,\n    struct lldpd_hardware *hardware,\n    struct lldpd_chassis **newchassis, struct lldpd_port **newport)\n{\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_port *port;\n\tstruct lldpd_mgmt *mgmt;\n\tstruct in_addr addr;\n#if 0\n\tu_int16_t cksum;\n#endif\n\tu_int8_t *software = NULL, *platform = NULL;\n\tint software_len = 0, platform_len = 0, proto, version, nb, caps;\n\tconst unsigned char cdpaddr[] = CDP_MULTICAST_ADDR;\n#ifdef ENABLE_FDP\n\tconst unsigned char fdpaddr[] = CDP_MULTICAST_ADDR;\n\tint fdp = 0;\n#endif\n\tu_int8_t *pos, *tlv, *pos_address, *pos_next_address;\n\tint length, len_eth, tlv_type, tlv_len, addresses_len, address_len;\n#ifdef ENABLE_DOT1\n\tstruct lldpd_vlan *vlan;\n#endif\n\n\tlog_debug(\"cdp\", \"decode CDP frame received on %s\",\n\t    hardware->h_ifname);\n\n\tif ((chassis = calloc(1, sizeof(struct lldpd_chassis))) == NULL) {\n\t\tlog_warn(\"cdp\", \"failed to allocate remote chassis\");\n\t\treturn -1;\n\t}\n\tTAILQ_INIT(&chassis->c_mgmt);\n\tif ((port = calloc(1, sizeof(struct lldpd_port))) == NULL) {\n\t\tlog_warn(\"cdp\", \"failed to allocate remote port\");\n\t\tfree(chassis);\n\t\treturn -1;\n\t}\n#ifdef ENABLE_DOT1\n\tTAILQ_INIT(&port->p_vlans);\n#endif\n\n\tlength = s;\n\tpos = (u_int8_t*)frame;\n\n\tif (length < 2*ETHER_ADDR_LEN + sizeof(u_int16_t) /* Ethernet */ +\n\t    8 /* LLC */ + 4 /* CDP header */) {\n\t\tlog_warn(\"cdp\", \"too short CDP/FDP frame received on %s\", hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n\tif (PEEK_CMP(cdpaddr, sizeof(cdpaddr)) != 0) {\n#ifdef ENABLE_FDP\n\t\tPEEK_RESTORE((u_int8_t*)frame);\n\t\tif (PEEK_CMP(fdpaddr, sizeof(fdpaddr)) != 0)\n\t\t\tfdp = 1;\n\t\telse {\n#endif\n\t\t\tlog_info(\"cdp\", \"frame not targeted at CDP/FDP multicast address received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n#ifdef ENABLE_FDP\n\t\t}\n#endif\n\t}\n\tPEEK_DISCARD(ETHER_ADDR_LEN);\t/* Don't care of source address */\n\tlen_eth = PEEK_UINT16;\n\tif (len_eth > length) {\n\t\tlog_warnx(\"cdp\", \"incorrect 802.3 frame size reported on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tPEEK_DISCARD(6);\t/* Skip beginning of LLC */\n\tproto = PEEK_UINT16;\n\tif (proto != LLC_PID_CDP) {\n\t\tif ((proto != LLC_PID_DRIP) &&\n\t\t    (proto != LLC_PID_PAGP) &&\n\t\t    (proto != LLC_PID_PVSTP) &&\n\t\t    (proto != LLC_PID_UDLD) &&\n\t\t    (proto != LLC_PID_VTP) &&\n\t\t    (proto != LLC_PID_DTP) &&\n\t\t    (proto != LLC_PID_STP))\n\t\t\tlog_debug(\"cdp\", \"incorrect LLC protocol ID received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n#if 0\n\t/* Check checksum */\n\tcksum = frame_checksum(pos, len_eth - 8,\n#ifdef ENABLE_FDP\n\t    !fdp\t\t/* fdp = 0 -> cisco checksum */\n#else\n\t    1\t\t\t/* cisco checksum */\n#endif\n\t\t);\n\tif (cksum != 0) {\n\t\tlog_info(\"cdp\", \"incorrect CDP/FDP checksum for frame received on %s (%d)\",\n\t\t\t  hardware->h_ifname, cksum);\n\t\tgoto malformed;\n\t}\n#endif\n\n\t/* Check version */\n\tversion = PEEK_UINT8;\n\tif ((version != 1) && (version != 2)) {\n\t\tlog_warnx(\"cdp\", \"incorrect CDP/FDP version (%d) for frame received on %s\",\n\t\t    version, hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tchassis->c_ttl = PEEK_UINT8; /* TTL */\n\tPEEK_DISCARD_UINT16;\t     /* Checksum, already checked */\n\n\twhile (length) {\n\t\tif (length < 4) {\n\t\t\tlog_warnx(\"cdp\", \"CDP/FDP TLV header is too large for \"\n\t\t\t    \"frame received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\ttlv_type = PEEK_UINT16;\n\t\ttlv_len = PEEK_UINT16 - 4;\n\t\t(void)PEEK_SAVE(tlv);\n\t\tif ((tlv_len < 0) || (length < tlv_len)) {\n\t\t\tlog_warnx(\"cdp\", \"incorrect size in CDP/FDP TLV header for frame \"\n\t\t\t    \"received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\tswitch (tlv_type) {\n\t\tcase CDP_TLV_CHASSIS:\n\t\t\tif ((chassis->c_name = (char *)calloc(1, tlv_len + 1)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis name\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(chassis->c_name, tlv_len);\n\t\t\tchassis->c_id_subtype = LLDP_CHASSISID_SUBTYPE_LOCAL;\n\t\t\tif ((chassis->c_id =  (char *)malloc(tlv_len)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis ID\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tmemcpy(chassis->c_id, chassis->c_name, tlv_len);\n\t\t\tchassis->c_id_len = tlv_len;\n\t\t\tbreak;\n\t\tcase CDP_TLV_ADDRESSES:\n\t\t\tCHECK_TLV_SIZE(4, \"Address\");\n\t\t\taddresses_len = tlv_len - 4;\n\t\t\tfor (nb = PEEK_UINT32; nb > 0; nb--) {\n\t\t\t\t(void)PEEK_SAVE(pos_address);\n\t\t\t\t/* We first try to get the real length of the packet */\n\t\t\t\tif (addresses_len < 2) {\n\t\t\t\t\tlog_warn(\"cdp\", \"too short address subframe \"\n\t\t\t\t\t\t  \"received on %s\",\n\t\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tPEEK_DISCARD_UINT8; addresses_len--;\n\t\t\t\taddress_len = PEEK_UINT8; addresses_len--;\n\t\t\t\tif (addresses_len < address_len + 2) {\n\t\t\t\t\tlog_warn(\"cdp\", \"too short address subframe \"\n\t\t\t\t\t\t  \"received on %s\",\n\t\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tPEEK_DISCARD(address_len);\n\t\t\t\taddresses_len -= address_len;\n\t\t\t\taddress_len = PEEK_UINT16; addresses_len -= 2;\n\t\t\t\tif (addresses_len < address_len) {\n\t\t\t\t\tlog_warn(\"cdp\", \"too short address subframe \"\n\t\t\t\t\t\t  \"received on %s\",\n\t\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tPEEK_DISCARD(address_len);\n\t\t\t\t(void)PEEK_SAVE(pos_next_address);\n\t\t\t\t/* Next, we go back and try to extract\n\t\t\t\t   IPv4 address */\n\t\t\t\tPEEK_RESTORE(pos_address);\n\t\t\t\tif ((PEEK_UINT8 == 1) && (PEEK_UINT8 == 1) &&\n\t\t\t\t    (PEEK_UINT8 == CDP_ADDRESS_PROTO_IP) &&\n\t\t\t\t    (PEEK_UINT16 == sizeof(struct in_addr))) {\n\t\t\t\t\t\tPEEK_BYTES(&addr, sizeof(struct in_addr));\n\t\t\t\t\t\tmgmt = lldpd_alloc_mgmt(LLDPD_AF_IPV4, &addr, \n\t\t\t\t\t\t\t\t\tsizeof(struct in_addr), 0);\n\t\t\t\t\t\tif (mgmt == NULL) {\n\t\t\t\t\t\t\tif (errno == ENOMEM)\n\t\t\t\t\t\t\t\tlog_warn(\"cdp\",\n\t\t\t\t\t\t\t\t    \"unable to allocate memory for management address\");\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\tlog_warn(\"cdp\",\n\t\t\t\t\t\t\t\t    \"too large management address received on %s\",\n\t\t\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);\n\t\t\t\t}\n\t\t\t\t/* Go to the end of the address */\n\t\t\t\tPEEK_RESTORE(pos_next_address);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase CDP_TLV_PORT:\n\t\t\tif (tlv_len == 0) {\n\t\t\t\tlog_warn(\"cd[\", \"too short port description received\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tif ((port->p_descr = (char *)calloc(1, tlv_len + 1)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for port description\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(port->p_descr, tlv_len);\n\t\t\tport->p_id_subtype = LLDP_PORTID_SUBTYPE_IFNAME;\n\t\t\tif ((port->p_id =  (char *)calloc(1, tlv_len)) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for port ID\");\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tmemcpy(port->p_id, port->p_descr, tlv_len);\n\t\t\tport->p_id_len = tlv_len;\n\t\t\tbreak;\n\t\tcase CDP_TLV_CAPABILITIES:\n#ifdef ENABLE_FDP\n\t\t\tif (fdp) {\n\t\t\t\t/* Capabilities are string with FDP */\n\t\t\t\tif (!strncmp(\"Router\", (char*)pos, tlv_len))\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_ROUTER;\n\t\t\t\telse if (!strncmp(\"Switch\", (char*)pos, tlv_len))\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_BRIDGE;\n\t\t\t\telse if (!strncmp(\"Bridge\", (char*)pos, tlv_len))\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_REPEATER;\n\t\t\t\telse\n\t\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_STATION;\n\t\t\t\tchassis->c_cap_available = chassis->c_cap_enabled;\n\t\t\t\tbreak;\n\t\t\t}\n#endif\n\t\t\tCHECK_TLV_SIZE(4, \"Capabilities\");\n\t\t\tcaps = PEEK_UINT32;\n\t\t\tif (caps & CDP_CAP_ROUTER)\n\t\t\t\tchassis->c_cap_enabled |= LLDP_CAP_ROUTER;\n\t\t\tif (caps & 0x0e)\n\t\t\t\tchassis->c_cap_enabled |= LLDP_CAP_BRIDGE;\n\t\t\tif (chassis->c_cap_enabled == 0)\n\t\t\t\tchassis->c_cap_enabled = LLDP_CAP_STATION;\n\t\t\tchassis->c_cap_available = chassis->c_cap_enabled;\n\t\t\tbreak;\n\t\tcase CDP_TLV_SOFTWARE:\n\t\t\tsoftware_len = tlv_len;\n\t\t\t(void)PEEK_SAVE(software);\n\t\t\tbreak;\n\t\tcase CDP_TLV_PLATFORM:\n\t\t\tplatform_len = tlv_len;\n\t\t\t(void)PEEK_SAVE(platform);\n\t\t\tbreak;\n#ifdef ENABLE_DOT1\n\t\tcase CDP_TLV_NATIVEVLAN:\n\t\t\tCHECK_TLV_SIZE(2, \"Native VLAN\");\n\t\t\tif ((vlan = (struct lldpd_vlan *)calloc(1,\n\t\t\t\tsizeof(struct lldpd_vlan))) == NULL) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to alloc vlan \"\n\t\t\t\t\t  \"structure for \"\n\t\t\t\t\t  \"tlv received on %s\",\n\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tvlan->v_vid = port->p_pvid = PEEK_UINT16;\n\t\t\tif (asprintf(&vlan->v_name, \"VLAN #%d\", vlan->v_vid) == -1) {\n\t\t\t\tlog_warn(\"cdp\", \"unable to alloc VLAN name for \"\n\t\t\t\t\t  \"TLV received on %s\",\n\t\t\t\t\t  hardware->h_ifname);\n\t\t\t\tfree(vlan);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tTAILQ_INSERT_TAIL(&port->p_vlans,\n\t\t\t\t\t  vlan, v_entries);\n\t\t\tbreak;\n#endif\n\t\tdefault:\n\t\t\tlog_debug(\"cdp\", \"unknown CDP/FDP TLV type (%d) received on %s\",\n\t\t\t    ntohs(tlv_type), hardware->h_ifname);\n\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t}\n\t\tPEEK_DISCARD(tlv + tlv_len - pos);\n\t}\n\tif (!software && platform) {\n\t\tif ((chassis->c_descr = (char *)calloc(1,\n\t\t\t    platform_len + 1)) == NULL) {\n\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis description\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tmemcpy(chassis->c_descr, platform, platform_len);\n\t} else if (software && !platform) {\n\t\tif ((chassis->c_descr = (char *)calloc(1,\n\t\t\t    software_len + 1)) == NULL) {\n\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis description\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tmemcpy(chassis->c_descr, software, software_len);\n\t} else if (software && platform) {\n#define CONCAT_PLATFORM \" running on\\n\"\n\t\tif ((chassis->c_descr = (char *)calloc(1,\n\t\t\t    software_len + platform_len +\n\t\t\t    strlen(CONCAT_PLATFORM) + 1)) == NULL) {\n\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for chassis description\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tmemcpy(chassis->c_descr, platform, platform_len);\n\t\tmemcpy(chassis->c_descr + platform_len,\n\t\t    CONCAT_PLATFORM, strlen(CONCAT_PLATFORM));\n\t\tmemcpy(chassis->c_descr + platform_len + strlen(CONCAT_PLATFORM),\n\t\t    software, software_len);\n\t}\n\tif ((chassis->c_id == NULL) ||\n\t    (port->p_id == NULL) ||\n\t    (chassis->c_name == NULL) ||\n\t    (chassis->c_descr == NULL) ||\n\t    (port->p_descr == NULL) ||\n\t    (chassis->c_ttl == 0) ||\n\t    (chassis->c_cap_enabled == 0)) {\n\t\tlog_warnx(\"cdp\", \"some mandatory CDP/FDP tlv are missing for frame received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\t*newchassis = chassis;\n\t*newport = port;\n\treturn 1;\n\nmalformed:\n\tlldpd_chassis_cleanup(chassis, 1);\n\tlldpd_port_cleanup(port, 1);\n\tfree(port);\n\treturn -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -183,8 +183,13 @@\n \t\t\t\t\t\tmgmt = lldpd_alloc_mgmt(LLDPD_AF_IPV4, &addr, \n \t\t\t\t\t\t\t\t\tsizeof(struct in_addr), 0);\n \t\t\t\t\t\tif (mgmt == NULL) {\n-\t\t\t\t\t\t\tassert(errno == ENOMEM);\n-\t\t\t\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for management address\");\n+\t\t\t\t\t\t\tif (errno == ENOMEM)\n+\t\t\t\t\t\t\t\tlog_warn(\"cdp\",\n+\t\t\t\t\t\t\t\t    \"unable to allocate memory for management address\");\n+\t\t\t\t\t\t\telse\n+\t\t\t\t\t\t\t\tlog_warn(\"cdp\",\n+\t\t\t\t\t\t\t\t    \"too large management address received on %s\",\n+\t\t\t\t\t\t\t\t    hardware->h_ifname);\n \t\t\t\t\t\t\tgoto malformed;\n \t\t\t\t\t\t}\n \t\t\t\t\t\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\t\t\tassert(errno == ENOMEM);",
                "\t\t\t\t\t\t\tlog_warn(\"cdp\", \"unable to allocate memory for management address\");"
            ],
            "added_lines": [
                "\t\t\t\t\t\t\tif (errno == ENOMEM)",
                "\t\t\t\t\t\t\t\tlog_warn(\"cdp\",",
                "\t\t\t\t\t\t\t\t    \"unable to allocate memory for management address\");",
                "\t\t\t\t\t\t\telse",
                "\t\t\t\t\t\t\t\tlog_warn(\"cdp\",",
                "\t\t\t\t\t\t\t\t    \"too large management address received on %s\",",
                "\t\t\t\t\t\t\t\t    hardware->h_ifname);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8012",
        "func_name": "lldpd/sonmp_decode",
        "description": "lldpd before 0.8.0 allows remote attackers to cause a denial of service (assertion failure and daemon crash) via a malformed packet.",
        "git_url": "https://github.com/lldpd/lldpd/commit/793526f8884455f43daecd0a2c46772388417a00",
        "commit_title": "protocols: don't use assert on paths that can be reached",
        "commit_text": " Malformed packets should not make lldpd crash. Ensure we can handle them by not using assert() in this part.",
        "func_before": "int\nsonmp_decode(struct lldpd *cfg, char *frame, int s,\n    struct lldpd_hardware *hardware,\n    struct lldpd_chassis **newchassis, struct lldpd_port **newport)\n{\n\tconst u_int8_t mcastaddr[] = SONMP_MULTICAST_ADDR;\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_port *port;\n\tstruct lldpd_mgmt *mgmt;\n\tint length, i;\n\tu_int8_t *pos;\n\tu_int8_t seg[3], rchassis;\n\tstruct in_addr address;\n\n\tlog_debug(\"sonmp\", \"decode SONMP PDU from %s\",\n\t    hardware->h_ifname);\n\n\tif ((chassis = calloc(1, sizeof(struct lldpd_chassis))) == NULL) {\n\t\tlog_warn(\"sonmp\", \"failed to allocate remote chassis\");\n\t\treturn -1;\n\t}\n\tTAILQ_INIT(&chassis->c_mgmt);\n\tif ((port = calloc(1, sizeof(struct lldpd_port))) == NULL) {\n\t\tlog_warn(\"sonmp\", \"failed to allocate remote port\");\n\t\tfree(chassis);\n\t\treturn -1;\n\t}\n#ifdef ENABLE_DOT1\n\tTAILQ_INIT(&port->p_vlans);\n#endif\n\n\tlength = s;\n\tpos = (u_int8_t*)frame;\n\tif (length < SONMP_SIZE) {\n\t\tlog_warnx(\"sonmp\", \"too short SONMP frame received on %s\", hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tif (PEEK_CMP(mcastaddr, sizeof(mcastaddr)) != 0)\n\t\t/* There is two multicast address. We just handle only one of\n\t\t * them. */\n\t\tgoto malformed;\n\t/* We skip to LLC PID */\n\tPEEK_DISCARD(ETHER_ADDR_LEN); PEEK_DISCARD_UINT16;\n\tPEEK_DISCARD(6);\n\tif (PEEK_UINT16 != LLC_PID_SONMP_HELLO) {\n\t\tlog_debug(\"sonmp\", \"incorrect LLC protocol ID received for SONMP on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n\tchassis->c_id_subtype = LLDP_CHASSISID_SUBTYPE_ADDR;\n\tif ((chassis->c_id = calloc(1, sizeof(struct in_addr) + 1)) == NULL) {\n\t\tlog_warn(\"sonmp\", \"unable to allocate memory for chassis id on %s\",\n\t\t\thardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tchassis->c_id_len = sizeof(struct in_addr) + 1;\n\tchassis->c_id[0] = 1;\n\tPEEK_BYTES(&address, sizeof(struct in_addr));\n\tmemcpy(chassis->c_id + 1, &address, sizeof(struct in_addr));\n\tif (asprintf(&chassis->c_name, \"%s\", inet_ntoa(address)) == -1) {\n\t\tlog_warnx(\"sonmp\", \"unable to write chassis name for %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tPEEK_BYTES(seg, sizeof(seg));\n\trchassis = PEEK_UINT8;\n\tfor (i=0; sonmp_chassis_types[i].type != 0; i++) {\n\t\tif (sonmp_chassis_types[i].type == rchassis)\n\t\t\tbreak;\n\t}\n\tif (asprintf(&chassis->c_descr, \"%s\",\n\t\tsonmp_chassis_types[i].description) == -1) {\n\t\tlog_warnx(\"sonmp\", \"unable to write chassis description for %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tmgmt = lldpd_alloc_mgmt(LLDPD_AF_IPV4, &address, sizeof(struct in_addr), 0);\n\tif (mgmt == NULL) {\n\t\tassert(errno == ENOMEM);\n\t\tlog_warn(\"sonmp\", \"unable to allocate memory for management address\");\n\t\tgoto malformed;\n\t}\n\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);\n\tchassis->c_ttl = cfg?(cfg->g_config.c_tx_interval * cfg->g_config.c_tx_hold):\n\t    LLDPD_TTL;\n\n\tport->p_id_subtype = LLDP_PORTID_SUBTYPE_LOCAL;\n\tif (asprintf(&port->p_id, \"%02x-%02x-%02x\",\n\t\tseg[0], seg[1], seg[2]) == -1) {\n\t\tlog_warn(\"sonmp\", \"unable to allocate memory for port id on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tport->p_id_len = strlen(port->p_id);\n\n\t/* Port description depend on the number of segments */\n\tif ((seg[0] == 0) && (seg[1] == 0)) {\n\t\tif (asprintf(&port->p_descr, \"port %d\",\n\t\t\tseg[2]) == -1) {\n\t\t\tlog_warnx(\"sonmp\", \"unable to write port description for %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t} else if (seg[0] == 0) {\n\t\tif (asprintf(&port->p_descr, \"port %d/%d\",\n\t\t\tseg[1], seg[2]) == -1) {\n\t\t\tlog_warnx(\"sonmp\", \"unable to write port description for %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t} else {\n\t\tif (asprintf(&port->p_descr, \"port %x:%x:%x\",\n\t\t\tseg[0], seg[1], seg[2]) == -1) {\n\t\t\tlog_warnx(\"sonmp\", \"unable to write port description for %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t}\n\t*newchassis = chassis;\n\t*newport = port;\n\treturn 1;\n\nmalformed:\n\tlldpd_chassis_cleanup(chassis, 1);\n\tlldpd_port_cleanup(port, 1);\n\tfree(port);\n\treturn -1;\n}",
        "func": "int\nsonmp_decode(struct lldpd *cfg, char *frame, int s,\n    struct lldpd_hardware *hardware,\n    struct lldpd_chassis **newchassis, struct lldpd_port **newport)\n{\n\tconst u_int8_t mcastaddr[] = SONMP_MULTICAST_ADDR;\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_port *port;\n\tstruct lldpd_mgmt *mgmt;\n\tint length, i;\n\tu_int8_t *pos;\n\tu_int8_t seg[3], rchassis;\n\tstruct in_addr address;\n\n\tlog_debug(\"sonmp\", \"decode SONMP PDU from %s\",\n\t    hardware->h_ifname);\n\n\tif ((chassis = calloc(1, sizeof(struct lldpd_chassis))) == NULL) {\n\t\tlog_warn(\"sonmp\", \"failed to allocate remote chassis\");\n\t\treturn -1;\n\t}\n\tTAILQ_INIT(&chassis->c_mgmt);\n\tif ((port = calloc(1, sizeof(struct lldpd_port))) == NULL) {\n\t\tlog_warn(\"sonmp\", \"failed to allocate remote port\");\n\t\tfree(chassis);\n\t\treturn -1;\n\t}\n#ifdef ENABLE_DOT1\n\tTAILQ_INIT(&port->p_vlans);\n#endif\n\n\tlength = s;\n\tpos = (u_int8_t*)frame;\n\tif (length < SONMP_SIZE) {\n\t\tlog_warnx(\"sonmp\", \"too short SONMP frame received on %s\", hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tif (PEEK_CMP(mcastaddr, sizeof(mcastaddr)) != 0)\n\t\t/* There is two multicast address. We just handle only one of\n\t\t * them. */\n\t\tgoto malformed;\n\t/* We skip to LLC PID */\n\tPEEK_DISCARD(ETHER_ADDR_LEN); PEEK_DISCARD_UINT16;\n\tPEEK_DISCARD(6);\n\tif (PEEK_UINT16 != LLC_PID_SONMP_HELLO) {\n\t\tlog_debug(\"sonmp\", \"incorrect LLC protocol ID received for SONMP on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n\tchassis->c_id_subtype = LLDP_CHASSISID_SUBTYPE_ADDR;\n\tif ((chassis->c_id = calloc(1, sizeof(struct in_addr) + 1)) == NULL) {\n\t\tlog_warn(\"sonmp\", \"unable to allocate memory for chassis id on %s\",\n\t\t\thardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tchassis->c_id_len = sizeof(struct in_addr) + 1;\n\tchassis->c_id[0] = 1;\n\tPEEK_BYTES(&address, sizeof(struct in_addr));\n\tmemcpy(chassis->c_id + 1, &address, sizeof(struct in_addr));\n\tif (asprintf(&chassis->c_name, \"%s\", inet_ntoa(address)) == -1) {\n\t\tlog_warnx(\"sonmp\", \"unable to write chassis name for %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tPEEK_BYTES(seg, sizeof(seg));\n\trchassis = PEEK_UINT8;\n\tfor (i=0; sonmp_chassis_types[i].type != 0; i++) {\n\t\tif (sonmp_chassis_types[i].type == rchassis)\n\t\t\tbreak;\n\t}\n\tif (asprintf(&chassis->c_descr, \"%s\",\n\t\tsonmp_chassis_types[i].description) == -1) {\n\t\tlog_warnx(\"sonmp\", \"unable to write chassis description for %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tmgmt = lldpd_alloc_mgmt(LLDPD_AF_IPV4, &address, sizeof(struct in_addr), 0);\n\tif (mgmt == NULL) {\n\t\tif (errno == ENOMEM)\n\t\t\tlog_warn(\"sonmp\", \"unable to allocate memory for management address\");\n\t\telse\n\t\t\tlog_warn(\"sonmp\", \"too large management address received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);\n\tchassis->c_ttl = cfg?(cfg->g_config.c_tx_interval * cfg->g_config.c_tx_hold):\n\t    LLDPD_TTL;\n\n\tport->p_id_subtype = LLDP_PORTID_SUBTYPE_LOCAL;\n\tif (asprintf(&port->p_id, \"%02x-%02x-%02x\",\n\t\tseg[0], seg[1], seg[2]) == -1) {\n\t\tlog_warn(\"sonmp\", \"unable to allocate memory for port id on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tport->p_id_len = strlen(port->p_id);\n\n\t/* Port description depend on the number of segments */\n\tif ((seg[0] == 0) && (seg[1] == 0)) {\n\t\tif (asprintf(&port->p_descr, \"port %d\",\n\t\t\tseg[2]) == -1) {\n\t\t\tlog_warnx(\"sonmp\", \"unable to write port description for %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t} else if (seg[0] == 0) {\n\t\tif (asprintf(&port->p_descr, \"port %d/%d\",\n\t\t\tseg[1], seg[2]) == -1) {\n\t\t\tlog_warnx(\"sonmp\", \"unable to write port description for %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t} else {\n\t\tif (asprintf(&port->p_descr, \"port %x:%x:%x\",\n\t\t\tseg[0], seg[1], seg[2]) == -1) {\n\t\t\tlog_warnx(\"sonmp\", \"unable to write port description for %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t}\n\t*newchassis = chassis;\n\t*newport = port;\n\treturn 1;\n\nmalformed:\n\tlldpd_chassis_cleanup(chassis, 1);\n\tlldpd_port_cleanup(port, 1);\n\tfree(port);\n\treturn -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -77,8 +77,11 @@\n \t}\n \tmgmt = lldpd_alloc_mgmt(LLDPD_AF_IPV4, &address, sizeof(struct in_addr), 0);\n \tif (mgmt == NULL) {\n-\t\tassert(errno == ENOMEM);\n-\t\tlog_warn(\"sonmp\", \"unable to allocate memory for management address\");\n+\t\tif (errno == ENOMEM)\n+\t\t\tlog_warn(\"sonmp\", \"unable to allocate memory for management address\");\n+\t\telse\n+\t\t\tlog_warn(\"sonmp\", \"too large management address received on %s\",\n+\t\t\t    hardware->h_ifname);\n \t\tgoto malformed;\n \t}\n \tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tassert(errno == ENOMEM);",
                "\t\tlog_warn(\"sonmp\", \"unable to allocate memory for management address\");"
            ],
            "added_lines": [
                "\t\tif (errno == ENOMEM)",
                "\t\t\tlog_warn(\"sonmp\", \"unable to allocate memory for management address\");",
                "\t\telse",
                "\t\t\tlog_warn(\"sonmp\", \"too large management address received on %s\",",
                "\t\t\t    hardware->h_ifname);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8012",
        "func_name": "lldpd/lldp_decode",
        "description": "lldpd before 0.8.0 allows remote attackers to cause a denial of service (assertion failure and daemon crash) via a malformed packet.",
        "git_url": "https://github.com/lldpd/lldpd/commit/793526f8884455f43daecd0a2c46772388417a00",
        "commit_title": "protocols: don't use assert on paths that can be reached",
        "commit_text": " Malformed packets should not make lldpd crash. Ensure we can handle them by not using assert() in this part.",
        "func_before": "int\nlldp_decode(struct lldpd *cfg, char *frame, int s,\n    struct lldpd_hardware *hardware,\n    struct lldpd_chassis **newchassis, struct lldpd_port **newport)\n{\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_port *port;\n\tconst char lldpaddr[] = LLDP_MULTICAST_ADDR;\n\tconst char dot1[] = LLDP_TLV_ORG_DOT1;\n\tconst char dot3[] = LLDP_TLV_ORG_DOT3;\n\tconst char med[] = LLDP_TLV_ORG_MED;\n\tconst char dcbx[] = LLDP_TLV_ORG_DCBX;\n\tunsigned char orgid[3];\n\tint length, gotend = 0, ttl_received = 0;\n\tint tlv_size, tlv_type, tlv_subtype;\n\tu_int8_t *pos, *tlv;\n\tchar *b;\n#ifdef ENABLE_DOT1\n\tstruct lldpd_vlan *vlan = NULL;\n\tint vlan_len;\n\tstruct lldpd_ppvid *ppvid;\n\tstruct lldpd_pi *pi = NULL;\n#endif\n\tstruct lldpd_mgmt *mgmt;\n\tint af;\n\tu_int8_t addr_str_length, addr_str_buffer[32];\n\tu_int8_t addr_family, addr_length, *addr_ptr, iface_subtype;\n\tu_int32_t iface_number, iface;\n#ifdef ENABLE_CUSTOM\n\tstruct lldpd_custom *custom = NULL;\n#endif\n\n\tlog_debug(\"lldp\", \"receive LLDP PDU on %s\",\n\t    hardware->h_ifname);\n\n\tif ((chassis = calloc(1, sizeof(struct lldpd_chassis))) == NULL) {\n\t\tlog_warn(\"lldp\", \"failed to allocate remote chassis\");\n\t\treturn -1;\n\t}\n\tTAILQ_INIT(&chassis->c_mgmt);\n\tif ((port = calloc(1, sizeof(struct lldpd_port))) == NULL) {\n\t\tlog_warn(\"lldp\", \"failed to allocate remote port\");\n\t\tfree(chassis);\n\t\treturn -1;\n\t}\n#ifdef ENABLE_DOT1\n\tTAILQ_INIT(&port->p_vlans);\n\tTAILQ_INIT(&port->p_ppvids);\n\tTAILQ_INIT(&port->p_pids);\n#endif\n#ifdef ENABLE_CUSTOM\n\tTAILQ_INIT(&port->p_custom_list);\n#endif\n\n\tlength = s;\n\tpos = (u_int8_t*)frame;\n\n\tif (length < 2*ETHER_ADDR_LEN + sizeof(u_int16_t)) {\n\t\tlog_warnx(\"lldp\", \"too short frame received on %s\", hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tif (PEEK_CMP(lldpaddr, ETHER_ADDR_LEN) != 0) {\n\t\tlog_info(\"lldp\", \"frame not targeted at LLDP multicast address received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tPEEK_DISCARD(ETHER_ADDR_LEN);\t/* Skip source address */\n\tif (PEEK_UINT16 != ETHERTYPE_LLDP) {\n\t\tlog_info(\"lldp\", \"non LLDP frame received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n\twhile (length && (!gotend)) {\n\t\tif (length < 2) {\n\t\t\tlog_warnx(\"lldp\", \"tlv header too short received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\ttlv_size = PEEK_UINT16;\n\t\ttlv_type = tlv_size >> 9;\n\t\ttlv_size = tlv_size & 0x1ff;\n\t\t(void)PEEK_SAVE(tlv);\n\t\tif (length < tlv_size) {\n\t\t\tlog_warnx(\"lldp\", \"frame too short for tlv received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\tswitch (tlv_type) {\n\t\tcase LLDP_TLV_END:\n\t\t\tif (tlv_size != 0) {\n\t\t\t\tlog_warnx(\"lldp\", \"lldp end received with size not null on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tif (length)\n\t\t\t\tlog_debug(\"lldp\", \"extra data after lldp end on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\tgotend = 1;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_CHASSIS_ID:\n\t\tcase LLDP_TLV_PORT_ID:\n\t\t\tCHECK_TLV_SIZE(2, \"Port Id\");\n\t\t\ttlv_subtype = PEEK_UINT8;\n\t\t\tif ((tlv_subtype == 0) || (tlv_subtype > 7)) {\n\t\t\t\tlog_warnx(\"lldp\", \"unknown subtype for tlv id received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tif ((b = (char *)calloc(1, tlv_size - 1)) == NULL) {\n\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory for id tlv \"\n\t\t\t\t    \"received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(b, tlv_size - 1);\n\t\t\tif (tlv_type == LLDP_TLV_PORT_ID) {\n\t\t\t\tport->p_id_subtype = tlv_subtype;\n\t\t\t\tport->p_id = b;\n\t\t\t\tport->p_id_len = tlv_size - 1;\n\t\t\t} else {\n\t\t\t\tchassis->c_id_subtype = tlv_subtype;\n\t\t\t\tchassis->c_id = b;\n\t\t\t\tchassis->c_id_len = tlv_size - 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LLDP_TLV_TTL:\n\t\t\tCHECK_TLV_SIZE(2, \"TTL\");\n\t\t\tchassis->c_ttl = PEEK_UINT16;\n\t\t\tttl_received = 1;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_PORT_DESCR:\n\t\tcase LLDP_TLV_SYSTEM_NAME:\n\t\tcase LLDP_TLV_SYSTEM_DESCR:\n\t\t\tif (tlv_size < 1) {\n\t\t\t\tlog_debug(\"lldp\", \"empty tlv received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((b = (char *)calloc(1, tlv_size + 1)) == NULL) {\n\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory for string tlv \"\n\t\t\t\t    \"received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(b, tlv_size);\n\t\t\tif (tlv_type == LLDP_TLV_PORT_DESCR)\n\t\t\t\tport->p_descr = b;\n\t\t\telse if (tlv_type == LLDP_TLV_SYSTEM_NAME)\n\t\t\t\tchassis->c_name = b;\n\t\t\telse chassis->c_descr = b;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_SYSTEM_CAP:\n\t\t\tCHECK_TLV_SIZE(4, \"System capabilities\");\n\t\t\tchassis->c_cap_available = PEEK_UINT16;\n\t\t\tchassis->c_cap_enabled = PEEK_UINT16;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_MGMT_ADDR:\n\t\t\tCHECK_TLV_SIZE(1, \"Management address\");\n\t\t\taddr_str_length = PEEK_UINT8;\n\t\t\tif (addr_str_length > sizeof(addr_str_buffer)) {\n\t\t\t\tlog_warnx(\"lldp\", \"too large management address on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tCHECK_TLV_SIZE(1 + addr_str_length, \"Management address\");\n\t\t\tPEEK_BYTES(addr_str_buffer, addr_str_length);\n\t\t\taddr_length = addr_str_length - 1;\n\t\t\taddr_family = addr_str_buffer[0];\n\t\t\taddr_ptr = &addr_str_buffer[1];\n\t\t\tCHECK_TLV_SIZE(1 + addr_str_length + 5, \"Management address\");\n\t\t\tiface_subtype = PEEK_UINT8;\n\t\t\tiface_number = PEEK_UINT32;\n\n\t\t\taf = lldpd_af_from_lldp_proto(addr_family);\n\t\t\tif (af == LLDPD_AF_UNSPEC)\n\t\t\t\tbreak;\n\t\t\tif (iface_subtype == LLDP_MGMT_IFACE_IFINDEX)\n\t\t\t\tiface = iface_number;\n\t\t\telse\n\t\t\t\tiface = 0;\n\t\t\tmgmt = lldpd_alloc_mgmt(af, addr_ptr, addr_length, iface);\n\t\t\tif (mgmt == NULL) {\n\t\t\t\tassert(errno == ENOMEM);\n\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"\n\t\t\t\t\t\t\t\"for management address\");\n\t\t\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);\n\t\t\tbreak;\n\t\tcase LLDP_TLV_ORG:\n\t\t\tCHECK_TLV_SIZE(1 + (int)sizeof(orgid), \"Organisational\");\n\t\t\tPEEK_BYTES(orgid, sizeof(orgid));\n\t\t\ttlv_subtype = PEEK_UINT8;\n\t\t\tif (memcmp(dot1, orgid, sizeof(orgid)) == 0) {\n#ifndef ENABLE_DOT1\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#else\n\t\t\t\t/* Dot1 */\n\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\tcase LLDP_TLV_DOT1_VLANNAME:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"VLAN\");\n\t\t\t\t\tif ((vlan = (struct lldpd_vlan *)calloc(1,\n\t\t\t\t\t\t    sizeof(struct lldpd_vlan))) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc vlan \"\n\t\t\t\t\t\t    \"structure for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tvlan->v_vid = PEEK_UINT16;\n\t\t\t\t\tvlan_len = PEEK_UINT8;\n\t\t\t\t\tCHECK_TLV_SIZE(7 + vlan_len, \"VLAN\");\n\t\t\t\t\tif ((vlan->v_name =\n\t\t\t\t\t\t(char *)calloc(1, vlan_len + 1)) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc vlan name for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(vlan->v_name, vlan_len);\n\t\t\t\t\tTAILQ_INSERT_TAIL(&port->p_vlans,\n\t\t\t\t\t    vlan, v_entries);\n\t\t\t\t\tvlan = NULL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT1_PVID:\n\t\t\t\t\tCHECK_TLV_SIZE(6, \"PVID\");\n\t\t\t\t\tport->p_pvid = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT1_PPVID:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"PPVID\");\n\t\t\t\t\t/* validation needed */\n\t\t\t\t\t/* PPVID has to be unique if more than\n\t\t\t\t\t   one PPVID TLVs are received  - \n\t\t\t\t\t   discard if duplicate */\n\t\t\t\t\t/* if support bit is not set and \n\t\t\t\t\t   enabled bit is set - PPVID TLV is\n\t\t\t\t\t   considered error  and discarded */\n\t\t\t\t\t/* if PPVID > 4096 - bad and discard */\n\t\t\t\t\tif ((ppvid = (struct lldpd_ppvid *)calloc(1,\n\t\t\t\t\t\t    sizeof(struct lldpd_ppvid))) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc ppvid \"\n\t\t\t\t\t\t    \"structure for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tppvid->p_cap_status = PEEK_UINT8;\n\t\t\t\t\tppvid->p_ppvid = PEEK_UINT16;\t\n\t\t\t\t\tTAILQ_INSERT_TAIL(&port->p_ppvids,\n\t\t\t\t\t    ppvid, p_entries);\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT1_PI:\n\t\t\t\t\t/* validation needed */\n\t\t\t\t\t/* PI has to be unique if more than \n\t\t\t\t\t   one PI TLVs are received  - discard\n\t\t\t\t\t   if duplicate ?? */\n\t\t\t\t\tCHECK_TLV_SIZE(5, \"PI\");\n\t\t\t\t\tif ((pi = (struct lldpd_pi *)calloc(1,\n\t\t\t\t\t\t    sizeof(struct lldpd_pi))) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc PI \"\n\t\t\t\t\t\t    \"structure for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tpi->p_pi_len = PEEK_UINT8;\n\t\t\t\t\tCHECK_TLV_SIZE(5 + pi->p_pi_len, \"PI\");\n\t\t\t\t\tif ((pi->p_pi =\n\t\t\t\t\t\t(char *)calloc(1, pi->p_pi_len)) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc pid name for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(pi->p_pi, pi->p_pi_len);\n\t\t\t\t\tTAILQ_INSERT_TAIL(&port->p_pids,\n\t\t\t\t\t    pi, p_entries);\n\t\t\t\t\tpi = NULL;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t/* Unknown Dot1 TLV, ignore it */\n\t\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t\t}\n#endif\n\t\t\t} else if (memcmp(dot3, orgid, sizeof(orgid)) == 0) {\n#ifndef ENABLE_DOT3\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#else\n\t\t\t\t/* Dot3 */\n\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\tcase LLDP_TLV_DOT3_MAC:\n\t\t\t\t\tCHECK_TLV_SIZE(9, \"MAC/PHY\");\n\t\t\t\t\tport->p_macphy.autoneg_support = PEEK_UINT8;\n\t\t\t\t\tport->p_macphy.autoneg_enabled =\n\t\t\t\t\t    (port->p_macphy.autoneg_support & 0x2) >> 1;\n\t\t\t\t\tport->p_macphy.autoneg_support =\n\t\t\t\t\t    port->p_macphy.autoneg_support & 0x1;\n\t\t\t\t\tport->p_macphy.autoneg_advertised =\n\t\t\t\t\t    PEEK_UINT16;\n\t\t\t\t\tport->p_macphy.mau_type = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT3_LA:\n\t\t\t\t\tCHECK_TLV_SIZE(9, \"Link aggregation\");\n\t\t\t\t\tPEEK_DISCARD_UINT8;\n\t\t\t\t\tport->p_aggregid = PEEK_UINT32;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT3_MFS:\n\t\t\t\t\tCHECK_TLV_SIZE(6, \"MFS\");\n\t\t\t\t\tport->p_mfs = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT3_POWER:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"Power\");\n\t\t\t\t\tport->p_power.devicetype = PEEK_UINT8;\n\t\t\t\t\tport->p_power.supported =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x2) >> 1;\n\t\t\t\t\tport->p_power.enabled =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x4) >> 2;\n\t\t\t\t\tport->p_power.paircontrol =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x8) >> 3;\n\t\t\t\t\tport->p_power.devicetype =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x1)?\n\t\t\t\t\t\tLLDP_DOT3_POWER_PSE:LLDP_DOT3_POWER_PD;\n\t\t\t\t\tport->p_power.pairs = PEEK_UINT8;\n\t\t\t\t\tport->p_power.class = PEEK_UINT8;\n\t\t\t\t\t/* 802.3at? */\n\t\t\t\t\tif (tlv_size >= 12) {\n\t\t\t\t\t\tport->p_power.powertype = PEEK_UINT8;\n\t\t\t\t\t\tport->p_power.source =\n\t\t\t\t\t\t    (port->p_power.powertype & (1<<5 | 1<<4)) >> 4;\n\t\t\t\t\t\tport->p_power.priority =\n\t\t\t\t\t\t    (port->p_power.powertype & (1<<1 | 1<<0));\n\t\t\t\t\t\tport->p_power.powertype =\n\t\t\t\t\t\t    (port->p_power.powertype & (1<<7))?\n\t\t\t\t\t\t    LLDP_DOT3_POWER_8023AT_TYPE1:\n\t\t\t\t\t\t    LLDP_DOT3_POWER_8023AT_TYPE2;\n\t\t\t\t\t\tport->p_power.requested = PEEK_UINT16;\n\t\t\t\t\t\tport->p_power.allocated = PEEK_UINT16;\n\t\t\t\t\t} else\n\t\t\t\t\t\tport->p_power.powertype =\n\t\t\t\t\t\t    LLDP_DOT3_POWER_8023AT_OFF;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t/* Unknown Dot3 TLV, ignore it */\n\t\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t\t}\n#endif\n\t\t\t} else if (memcmp(med, orgid, sizeof(orgid)) == 0) {\n\t\t\t\t/* LLDP-MED */\n#ifndef ENABLE_LLDPMED\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#else\n\t\t\t\tu_int32_t policy;\n\t\t\t\tunsigned loctype;\n\t\t\t\tunsigned power;\n\n\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\tcase LLDP_TLV_MED_CAP:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"LLDP-MED capabilities\");\n\t\t\t\t\tchassis->c_med_cap_available = PEEK_UINT16;\n\t\t\t\t\tchassis->c_med_type = PEEK_UINT8;\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_CAP;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_POLICY:\n\t\t\t\t\tCHECK_TLV_SIZE(8, \"LLDP-MED policy\");\n\t\t\t\t\tpolicy = PEEK_UINT32;\n\t\t\t\t\tif (((policy >> 24) < 1) ||\n\t\t\t\t\t    ((policy >> 24) > LLDP_MED_APPTYPE_LAST)) {\n\t\t\t\t\t\tlog_info(\"lldp\", \"unknown policy field %d \"\n\t\t\t\t\t\t    \"received on %s\",\n\t\t\t\t\t\t    policy,\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].type =\n\t\t\t\t\t    (policy >> 24);\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].unknown =\n\t\t\t\t\t    ((policy & 0x800000) != 0);\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].tagged =\n\t\t\t\t\t    ((policy & 0x400000) != 0);\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].vid =\n\t\t\t\t\t    (policy & 0x001FFE00) >> 9;\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].priority =\n\t\t\t\t\t    (policy & 0x1C0) >> 6;\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].dscp =\n\t\t\t\t\t    policy & 0x3F;\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_POLICY;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_LOCATION:\n\t\t\t\t\tCHECK_TLV_SIZE(5, \"LLDP-MED Location\");\n\t\t\t\t\tloctype = PEEK_UINT8;\n\t\t\t\t\tif ((loctype < 1) ||\n\t\t\t\t\t    (loctype > LLDP_MED_LOCFORMAT_LAST)) {\n\t\t\t\t\t\tlog_info(\"lldp\", \"unknown location type \"\n\t\t\t\t\t\t    \"received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif ((port->p_med_location[loctype - 1].data =\n\t\t\t\t\t\t(char*)malloc(tlv_size - 5)) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"\n\t\t\t\t\t\t    \"for LLDP-MED location for \"\n\t\t\t\t\t\t    \"frame received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(port->p_med_location[loctype - 1].data,\n\t\t\t\t\t    tlv_size - 5);\n\t\t\t\t\tport->p_med_location[loctype - 1].data_len =\n\t\t\t\t\t    tlv_size - 5;\n\t\t\t\t\tport->p_med_location[loctype - 1].format = loctype;\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_LOCATION;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_MDI:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"LLDP-MED PoE-MDI\");\n\t\t\t\t\tpower = PEEK_UINT8;\n\t\t\t\t\tswitch (power & 0xC0) {\n\t\t\t\t\tcase 0x0:\n\t\t\t\t\t\tport->p_med_power.devicetype = LLDP_MED_POW_TYPE_PSE;\n\t\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t\t    LLDP_MED_CAP_MDI_PSE;\n\t\t\t\t\t\tswitch (power & 0x30) {\n\t\t\t\t\t\tcase 0x0:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_UNKNOWN;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x10:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_PRIMARY;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x20:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_BACKUP;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_RESERVED;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 0x40:\n\t\t\t\t\t\tport->p_med_power.devicetype = LLDP_MED_POW_TYPE_PD;\n\t\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t\t    LLDP_MED_CAP_MDI_PD;\n\t\t\t\t\t\tswitch (power & 0x30) {\n\t\t\t\t\t\tcase 0x0:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_UNKNOWN;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x10:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_PSE;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x20:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_LOCAL;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_BOTH;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tport->p_med_power.devicetype =\n\t\t\t\t\t\t    LLDP_MED_POW_TYPE_RESERVED;\n\t\t\t\t\t}\n\t\t\t\t\tif ((power & 0x0F) > LLDP_MED_POW_PRIO_LOW)\n\t\t\t\t\t\tport->p_med_power.priority =\n\t\t\t\t\t\t    LLDP_MED_POW_PRIO_UNKNOWN;\n\t\t\t\t\telse\n\t\t\t\t\t\tport->p_med_power.priority =\n\t\t\t\t\t\t    power & 0x0F;\n\t\t\t\t\tport->p_med_power.val = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_IV_HW:\n\t\t\t\tcase LLDP_TLV_MED_IV_SW:\n\t\t\t\tcase LLDP_TLV_MED_IV_FW:\n\t\t\t\tcase LLDP_TLV_MED_IV_SN:\n\t\t\t\tcase LLDP_TLV_MED_IV_MANUF:\n\t\t\t\tcase LLDP_TLV_MED_IV_MODEL:\n\t\t\t\tcase LLDP_TLV_MED_IV_ASSET:\n\t\t\t\t\tif (tlv_size <= 4)\n\t\t\t\t\t\tb = NULL;\n\t\t\t\t\telse {\n\t\t\t\t\t\tif ((b = (char*)malloc(tlv_size - 3)) ==\n\t\t\t\t\t\t    NULL) {\n\t\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to allocate \"\n\t\t\t\t\t\t\t    \"memory for LLDP-MED \"\n\t\t\t\t\t\t\t    \"inventory for frame \"\n\t\t\t\t\t\t\t    \"received on %s\",\n\t\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tPEEK_BYTES(b, tlv_size - 4);\n\t\t\t\t\t\tb[tlv_size - 4] = '\\0';\n\t\t\t\t\t}\n\t\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\t\tcase LLDP_TLV_MED_IV_HW:\n\t\t\t\t\t\tchassis->c_med_hw = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_FW:\n\t\t\t\t\t\tchassis->c_med_fw = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_SW:\n\t\t\t\t\t\tchassis->c_med_sw = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_SN:\n\t\t\t\t\t\tchassis->c_med_sn = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_MANUF:\n\t\t\t\t\t\tchassis->c_med_manuf = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_MODEL:\n\t\t\t\t\t\tchassis->c_med_model = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_ASSET:\n\t\t\t\t\t\tchassis->c_med_asset = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_IV;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t/* Unknown LLDP MED, ignore it */\n\t\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t\t}\n#endif /* ENABLE_LLDPMED */\n\t\t\t} else if (memcmp(dcbx, orgid, sizeof(orgid)) == 0) {\n\t\t\t\tlog_debug(\"lldp\", \"unsupported DCBX tlv received on %s - ignore\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t} else {\n\t\t\t\tlog_debug(\"lldp\", \"unknown org tlv [%02x:%02x:%02x] received on %s\",\n\t\t\t\t    orgid[0], orgid[1], orgid[2],\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#ifdef ENABLE_CUSTOM\n\t\t\t\tcustom = (struct lldpd_custom*)calloc(1, sizeof(struct lldpd_custom));\n\t\t\t\tif (!custom) {\n\t\t\t\t\tlog_warn(\"lldp\",\n\t\t\t\t\t    \"unable to allocate memory for custom TLV\");\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tcustom->oui_info_len = tlv_size > 4 ? tlv_size - 4 : 0;\n\t\t\t\tmemcpy(custom->oui, orgid, sizeof(custom->oui));\n\t\t\t\tcustom->subtype = tlv_subtype;\n\t\t\t\tif (custom->oui_info_len > 0) {\n\t\t\t\t\tcustom->oui_info = malloc(custom->oui_info_len);\n\t\t\t\t\tif (!custom->oui_info) {\n\t\t\t\t\t\tlog_warn(\"lldp\",\n\t\t\t\t\t\t    \"unable to allocate memory for custom TLV data\");\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(custom->oui_info, custom->oui_info_len);\n\t\t\t\t}\n\t\t\t\tTAILQ_INSERT_TAIL(&port->p_custom_list, custom, next);\n\t\t\t\tcustom = NULL;\n#endif\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog_warnx(\"lldp\", \"unknown tlv (%d) received on %s\",\n\t\t\t    tlv_type, hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\tif (pos > tlv + tlv_size) {\n\t\t\tlog_warnx(\"lldp\", \"BUG: already past TLV!\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tPEEK_DISCARD(tlv + tlv_size - pos);\n\t}\n\n\t/* Some random check */\n\tif ((chassis->c_id == NULL) ||\n\t    (port->p_id == NULL) ||\n\t    (!ttl_received) ||\n\t    (gotend == 0)) {\n\t\tlog_warnx(\"lldp\", \"some mandatory tlv are missing for frame received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\t*newchassis = chassis;\n\t*newport = port;\n\treturn 1;\nmalformed:\n#ifdef ENABLE_CUSTOM\n\tfree(custom);\n#endif\n#ifdef ENABLE_DOT1\n\tfree(vlan);\n\tfree(pi);\n#endif\n\tlldpd_chassis_cleanup(chassis, 1);\n\tlldpd_port_cleanup(port, 1);\n\tfree(port);\n\treturn -1;\n}",
        "func": "int\nlldp_decode(struct lldpd *cfg, char *frame, int s,\n    struct lldpd_hardware *hardware,\n    struct lldpd_chassis **newchassis, struct lldpd_port **newport)\n{\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_port *port;\n\tconst char lldpaddr[] = LLDP_MULTICAST_ADDR;\n\tconst char dot1[] = LLDP_TLV_ORG_DOT1;\n\tconst char dot3[] = LLDP_TLV_ORG_DOT3;\n\tconst char med[] = LLDP_TLV_ORG_MED;\n\tconst char dcbx[] = LLDP_TLV_ORG_DCBX;\n\tunsigned char orgid[3];\n\tint length, gotend = 0, ttl_received = 0;\n\tint tlv_size, tlv_type, tlv_subtype;\n\tu_int8_t *pos, *tlv;\n\tchar *b;\n#ifdef ENABLE_DOT1\n\tstruct lldpd_vlan *vlan = NULL;\n\tint vlan_len;\n\tstruct lldpd_ppvid *ppvid;\n\tstruct lldpd_pi *pi = NULL;\n#endif\n\tstruct lldpd_mgmt *mgmt;\n\tint af;\n\tu_int8_t addr_str_length, addr_str_buffer[32];\n\tu_int8_t addr_family, addr_length, *addr_ptr, iface_subtype;\n\tu_int32_t iface_number, iface;\n#ifdef ENABLE_CUSTOM\n\tstruct lldpd_custom *custom = NULL;\n#endif\n\n\tlog_debug(\"lldp\", \"receive LLDP PDU on %s\",\n\t    hardware->h_ifname);\n\n\tif ((chassis = calloc(1, sizeof(struct lldpd_chassis))) == NULL) {\n\t\tlog_warn(\"lldp\", \"failed to allocate remote chassis\");\n\t\treturn -1;\n\t}\n\tTAILQ_INIT(&chassis->c_mgmt);\n\tif ((port = calloc(1, sizeof(struct lldpd_port))) == NULL) {\n\t\tlog_warn(\"lldp\", \"failed to allocate remote port\");\n\t\tfree(chassis);\n\t\treturn -1;\n\t}\n#ifdef ENABLE_DOT1\n\tTAILQ_INIT(&port->p_vlans);\n\tTAILQ_INIT(&port->p_ppvids);\n\tTAILQ_INIT(&port->p_pids);\n#endif\n#ifdef ENABLE_CUSTOM\n\tTAILQ_INIT(&port->p_custom_list);\n#endif\n\n\tlength = s;\n\tpos = (u_int8_t*)frame;\n\n\tif (length < 2*ETHER_ADDR_LEN + sizeof(u_int16_t)) {\n\t\tlog_warnx(\"lldp\", \"too short frame received on %s\", hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tif (PEEK_CMP(lldpaddr, ETHER_ADDR_LEN) != 0) {\n\t\tlog_info(\"lldp\", \"frame not targeted at LLDP multicast address received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\tPEEK_DISCARD(ETHER_ADDR_LEN);\t/* Skip source address */\n\tif (PEEK_UINT16 != ETHERTYPE_LLDP) {\n\t\tlog_info(\"lldp\", \"non LLDP frame received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\n\twhile (length && (!gotend)) {\n\t\tif (length < 2) {\n\t\t\tlog_warnx(\"lldp\", \"tlv header too short received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\ttlv_size = PEEK_UINT16;\n\t\ttlv_type = tlv_size >> 9;\n\t\ttlv_size = tlv_size & 0x1ff;\n\t\t(void)PEEK_SAVE(tlv);\n\t\tif (length < tlv_size) {\n\t\t\tlog_warnx(\"lldp\", \"frame too short for tlv received on %s\",\n\t\t\t    hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\tswitch (tlv_type) {\n\t\tcase LLDP_TLV_END:\n\t\t\tif (tlv_size != 0) {\n\t\t\t\tlog_warnx(\"lldp\", \"lldp end received with size not null on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tif (length)\n\t\t\t\tlog_debug(\"lldp\", \"extra data after lldp end on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\tgotend = 1;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_CHASSIS_ID:\n\t\tcase LLDP_TLV_PORT_ID:\n\t\t\tCHECK_TLV_SIZE(2, \"Port Id\");\n\t\t\ttlv_subtype = PEEK_UINT8;\n\t\t\tif ((tlv_subtype == 0) || (tlv_subtype > 7)) {\n\t\t\t\tlog_warnx(\"lldp\", \"unknown subtype for tlv id received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tif ((b = (char *)calloc(1, tlv_size - 1)) == NULL) {\n\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory for id tlv \"\n\t\t\t\t    \"received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(b, tlv_size - 1);\n\t\t\tif (tlv_type == LLDP_TLV_PORT_ID) {\n\t\t\t\tport->p_id_subtype = tlv_subtype;\n\t\t\t\tport->p_id = b;\n\t\t\t\tport->p_id_len = tlv_size - 1;\n\t\t\t} else {\n\t\t\t\tchassis->c_id_subtype = tlv_subtype;\n\t\t\t\tchassis->c_id = b;\n\t\t\t\tchassis->c_id_len = tlv_size - 1;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase LLDP_TLV_TTL:\n\t\t\tCHECK_TLV_SIZE(2, \"TTL\");\n\t\t\tchassis->c_ttl = PEEK_UINT16;\n\t\t\tttl_received = 1;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_PORT_DESCR:\n\t\tcase LLDP_TLV_SYSTEM_NAME:\n\t\tcase LLDP_TLV_SYSTEM_DESCR:\n\t\t\tif (tlv_size < 1) {\n\t\t\t\tlog_debug(\"lldp\", \"empty tlv received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif ((b = (char *)calloc(1, tlv_size + 1)) == NULL) {\n\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory for string tlv \"\n\t\t\t\t    \"received on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tPEEK_BYTES(b, tlv_size);\n\t\t\tif (tlv_type == LLDP_TLV_PORT_DESCR)\n\t\t\t\tport->p_descr = b;\n\t\t\telse if (tlv_type == LLDP_TLV_SYSTEM_NAME)\n\t\t\t\tchassis->c_name = b;\n\t\t\telse chassis->c_descr = b;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_SYSTEM_CAP:\n\t\t\tCHECK_TLV_SIZE(4, \"System capabilities\");\n\t\t\tchassis->c_cap_available = PEEK_UINT16;\n\t\t\tchassis->c_cap_enabled = PEEK_UINT16;\n\t\t\tbreak;\n\t\tcase LLDP_TLV_MGMT_ADDR:\n\t\t\tCHECK_TLV_SIZE(1, \"Management address\");\n\t\t\taddr_str_length = PEEK_UINT8;\n\t\t\tif (addr_str_length > sizeof(addr_str_buffer)) {\n\t\t\t\tlog_warnx(\"lldp\", \"too large management address on %s\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tCHECK_TLV_SIZE(1 + addr_str_length, \"Management address\");\n\t\t\tPEEK_BYTES(addr_str_buffer, addr_str_length);\n\t\t\taddr_length = addr_str_length - 1;\n\t\t\taddr_family = addr_str_buffer[0];\n\t\t\taddr_ptr = &addr_str_buffer[1];\n\t\t\tCHECK_TLV_SIZE(1 + addr_str_length + 5, \"Management address\");\n\t\t\tiface_subtype = PEEK_UINT8;\n\t\t\tiface_number = PEEK_UINT32;\n\n\t\t\taf = lldpd_af_from_lldp_proto(addr_family);\n\t\t\tif (af == LLDPD_AF_UNSPEC)\n\t\t\t\tbreak;\n\t\t\tif (iface_subtype == LLDP_MGMT_IFACE_IFINDEX)\n\t\t\t\tiface = iface_number;\n\t\t\telse\n\t\t\t\tiface = 0;\n\t\t\tmgmt = lldpd_alloc_mgmt(af, addr_ptr, addr_length, iface);\n\t\t\tif (mgmt == NULL) {\n\t\t\t\tif (errno == ENOMEM)\n\t\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"\n\t\t\t\t\t    \"for management address\");\n\t\t\t\telse\n\t\t\t\t\tlog_warn(\"lldp\", \"too large management address \"\n\t\t\t\t\t    \"received on %s\", hardware->h_ifname);\n\t\t\t\tgoto malformed;\n\t\t\t}\n\t\t\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);\n\t\t\tbreak;\n\t\tcase LLDP_TLV_ORG:\n\t\t\tCHECK_TLV_SIZE(1 + (int)sizeof(orgid), \"Organisational\");\n\t\t\tPEEK_BYTES(orgid, sizeof(orgid));\n\t\t\ttlv_subtype = PEEK_UINT8;\n\t\t\tif (memcmp(dot1, orgid, sizeof(orgid)) == 0) {\n#ifndef ENABLE_DOT1\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#else\n\t\t\t\t/* Dot1 */\n\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\tcase LLDP_TLV_DOT1_VLANNAME:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"VLAN\");\n\t\t\t\t\tif ((vlan = (struct lldpd_vlan *)calloc(1,\n\t\t\t\t\t\t    sizeof(struct lldpd_vlan))) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc vlan \"\n\t\t\t\t\t\t    \"structure for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tvlan->v_vid = PEEK_UINT16;\n\t\t\t\t\tvlan_len = PEEK_UINT8;\n\t\t\t\t\tCHECK_TLV_SIZE(7 + vlan_len, \"VLAN\");\n\t\t\t\t\tif ((vlan->v_name =\n\t\t\t\t\t\t(char *)calloc(1, vlan_len + 1)) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc vlan name for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(vlan->v_name, vlan_len);\n\t\t\t\t\tTAILQ_INSERT_TAIL(&port->p_vlans,\n\t\t\t\t\t    vlan, v_entries);\n\t\t\t\t\tvlan = NULL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT1_PVID:\n\t\t\t\t\tCHECK_TLV_SIZE(6, \"PVID\");\n\t\t\t\t\tport->p_pvid = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT1_PPVID:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"PPVID\");\n\t\t\t\t\t/* validation needed */\n\t\t\t\t\t/* PPVID has to be unique if more than\n\t\t\t\t\t   one PPVID TLVs are received  - \n\t\t\t\t\t   discard if duplicate */\n\t\t\t\t\t/* if support bit is not set and \n\t\t\t\t\t   enabled bit is set - PPVID TLV is\n\t\t\t\t\t   considered error  and discarded */\n\t\t\t\t\t/* if PPVID > 4096 - bad and discard */\n\t\t\t\t\tif ((ppvid = (struct lldpd_ppvid *)calloc(1,\n\t\t\t\t\t\t    sizeof(struct lldpd_ppvid))) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc ppvid \"\n\t\t\t\t\t\t    \"structure for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tppvid->p_cap_status = PEEK_UINT8;\n\t\t\t\t\tppvid->p_ppvid = PEEK_UINT16;\t\n\t\t\t\t\tTAILQ_INSERT_TAIL(&port->p_ppvids,\n\t\t\t\t\t    ppvid, p_entries);\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT1_PI:\n\t\t\t\t\t/* validation needed */\n\t\t\t\t\t/* PI has to be unique if more than \n\t\t\t\t\t   one PI TLVs are received  - discard\n\t\t\t\t\t   if duplicate ?? */\n\t\t\t\t\tCHECK_TLV_SIZE(5, \"PI\");\n\t\t\t\t\tif ((pi = (struct lldpd_pi *)calloc(1,\n\t\t\t\t\t\t    sizeof(struct lldpd_pi))) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc PI \"\n\t\t\t\t\t\t    \"structure for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tpi->p_pi_len = PEEK_UINT8;\n\t\t\t\t\tCHECK_TLV_SIZE(5 + pi->p_pi_len, \"PI\");\n\t\t\t\t\tif ((pi->p_pi =\n\t\t\t\t\t\t(char *)calloc(1, pi->p_pi_len)) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to alloc pid name for \"\n\t\t\t\t\t\t    \"tlv received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(pi->p_pi, pi->p_pi_len);\n\t\t\t\t\tTAILQ_INSERT_TAIL(&port->p_pids,\n\t\t\t\t\t    pi, p_entries);\n\t\t\t\t\tpi = NULL;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t/* Unknown Dot1 TLV, ignore it */\n\t\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t\t}\n#endif\n\t\t\t} else if (memcmp(dot3, orgid, sizeof(orgid)) == 0) {\n#ifndef ENABLE_DOT3\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#else\n\t\t\t\t/* Dot3 */\n\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\tcase LLDP_TLV_DOT3_MAC:\n\t\t\t\t\tCHECK_TLV_SIZE(9, \"MAC/PHY\");\n\t\t\t\t\tport->p_macphy.autoneg_support = PEEK_UINT8;\n\t\t\t\t\tport->p_macphy.autoneg_enabled =\n\t\t\t\t\t    (port->p_macphy.autoneg_support & 0x2) >> 1;\n\t\t\t\t\tport->p_macphy.autoneg_support =\n\t\t\t\t\t    port->p_macphy.autoneg_support & 0x1;\n\t\t\t\t\tport->p_macphy.autoneg_advertised =\n\t\t\t\t\t    PEEK_UINT16;\n\t\t\t\t\tport->p_macphy.mau_type = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT3_LA:\n\t\t\t\t\tCHECK_TLV_SIZE(9, \"Link aggregation\");\n\t\t\t\t\tPEEK_DISCARD_UINT8;\n\t\t\t\t\tport->p_aggregid = PEEK_UINT32;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT3_MFS:\n\t\t\t\t\tCHECK_TLV_SIZE(6, \"MFS\");\n\t\t\t\t\tport->p_mfs = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_DOT3_POWER:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"Power\");\n\t\t\t\t\tport->p_power.devicetype = PEEK_UINT8;\n\t\t\t\t\tport->p_power.supported =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x2) >> 1;\n\t\t\t\t\tport->p_power.enabled =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x4) >> 2;\n\t\t\t\t\tport->p_power.paircontrol =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x8) >> 3;\n\t\t\t\t\tport->p_power.devicetype =\n\t\t\t\t\t\t(port->p_power.devicetype & 0x1)?\n\t\t\t\t\t\tLLDP_DOT3_POWER_PSE:LLDP_DOT3_POWER_PD;\n\t\t\t\t\tport->p_power.pairs = PEEK_UINT8;\n\t\t\t\t\tport->p_power.class = PEEK_UINT8;\n\t\t\t\t\t/* 802.3at? */\n\t\t\t\t\tif (tlv_size >= 12) {\n\t\t\t\t\t\tport->p_power.powertype = PEEK_UINT8;\n\t\t\t\t\t\tport->p_power.source =\n\t\t\t\t\t\t    (port->p_power.powertype & (1<<5 | 1<<4)) >> 4;\n\t\t\t\t\t\tport->p_power.priority =\n\t\t\t\t\t\t    (port->p_power.powertype & (1<<1 | 1<<0));\n\t\t\t\t\t\tport->p_power.powertype =\n\t\t\t\t\t\t    (port->p_power.powertype & (1<<7))?\n\t\t\t\t\t\t    LLDP_DOT3_POWER_8023AT_TYPE1:\n\t\t\t\t\t\t    LLDP_DOT3_POWER_8023AT_TYPE2;\n\t\t\t\t\t\tport->p_power.requested = PEEK_UINT16;\n\t\t\t\t\t\tport->p_power.allocated = PEEK_UINT16;\n\t\t\t\t\t} else\n\t\t\t\t\t\tport->p_power.powertype =\n\t\t\t\t\t\t    LLDP_DOT3_POWER_8023AT_OFF;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t/* Unknown Dot3 TLV, ignore it */\n\t\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t\t}\n#endif\n\t\t\t} else if (memcmp(med, orgid, sizeof(orgid)) == 0) {\n\t\t\t\t/* LLDP-MED */\n#ifndef ENABLE_LLDPMED\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#else\n\t\t\t\tu_int32_t policy;\n\t\t\t\tunsigned loctype;\n\t\t\t\tunsigned power;\n\n\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\tcase LLDP_TLV_MED_CAP:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"LLDP-MED capabilities\");\n\t\t\t\t\tchassis->c_med_cap_available = PEEK_UINT16;\n\t\t\t\t\tchassis->c_med_type = PEEK_UINT8;\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_CAP;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_POLICY:\n\t\t\t\t\tCHECK_TLV_SIZE(8, \"LLDP-MED policy\");\n\t\t\t\t\tpolicy = PEEK_UINT32;\n\t\t\t\t\tif (((policy >> 24) < 1) ||\n\t\t\t\t\t    ((policy >> 24) > LLDP_MED_APPTYPE_LAST)) {\n\t\t\t\t\t\tlog_info(\"lldp\", \"unknown policy field %d \"\n\t\t\t\t\t\t    \"received on %s\",\n\t\t\t\t\t\t    policy,\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].type =\n\t\t\t\t\t    (policy >> 24);\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].unknown =\n\t\t\t\t\t    ((policy & 0x800000) != 0);\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].tagged =\n\t\t\t\t\t    ((policy & 0x400000) != 0);\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].vid =\n\t\t\t\t\t    (policy & 0x001FFE00) >> 9;\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].priority =\n\t\t\t\t\t    (policy & 0x1C0) >> 6;\n\t\t\t\t\tport->p_med_policy[(policy >> 24) - 1].dscp =\n\t\t\t\t\t    policy & 0x3F;\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_POLICY;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_LOCATION:\n\t\t\t\t\tCHECK_TLV_SIZE(5, \"LLDP-MED Location\");\n\t\t\t\t\tloctype = PEEK_UINT8;\n\t\t\t\t\tif ((loctype < 1) ||\n\t\t\t\t\t    (loctype > LLDP_MED_LOCFORMAT_LAST)) {\n\t\t\t\t\t\tlog_info(\"lldp\", \"unknown location type \"\n\t\t\t\t\t\t    \"received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tif ((port->p_med_location[loctype - 1].data =\n\t\t\t\t\t\t(char*)malloc(tlv_size - 5)) == NULL) {\n\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"\n\t\t\t\t\t\t    \"for LLDP-MED location for \"\n\t\t\t\t\t\t    \"frame received on %s\",\n\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(port->p_med_location[loctype - 1].data,\n\t\t\t\t\t    tlv_size - 5);\n\t\t\t\t\tport->p_med_location[loctype - 1].data_len =\n\t\t\t\t\t    tlv_size - 5;\n\t\t\t\t\tport->p_med_location[loctype - 1].format = loctype;\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_LOCATION;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_MDI:\n\t\t\t\t\tCHECK_TLV_SIZE(7, \"LLDP-MED PoE-MDI\");\n\t\t\t\t\tpower = PEEK_UINT8;\n\t\t\t\t\tswitch (power & 0xC0) {\n\t\t\t\t\tcase 0x0:\n\t\t\t\t\t\tport->p_med_power.devicetype = LLDP_MED_POW_TYPE_PSE;\n\t\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t\t    LLDP_MED_CAP_MDI_PSE;\n\t\t\t\t\t\tswitch (power & 0x30) {\n\t\t\t\t\t\tcase 0x0:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_UNKNOWN;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x10:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_PRIMARY;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x20:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_BACKUP;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_RESERVED;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 0x40:\n\t\t\t\t\t\tport->p_med_power.devicetype = LLDP_MED_POW_TYPE_PD;\n\t\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t\t    LLDP_MED_CAP_MDI_PD;\n\t\t\t\t\t\tswitch (power & 0x30) {\n\t\t\t\t\t\tcase 0x0:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_UNKNOWN;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x10:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_PSE;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 0x20:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_LOCAL;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tport->p_med_power.source =\n\t\t\t\t\t\t\t    LLDP_MED_POW_SOURCE_BOTH;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tport->p_med_power.devicetype =\n\t\t\t\t\t\t    LLDP_MED_POW_TYPE_RESERVED;\n\t\t\t\t\t}\n\t\t\t\t\tif ((power & 0x0F) > LLDP_MED_POW_PRIO_LOW)\n\t\t\t\t\t\tport->p_med_power.priority =\n\t\t\t\t\t\t    LLDP_MED_POW_PRIO_UNKNOWN;\n\t\t\t\t\telse\n\t\t\t\t\t\tport->p_med_power.priority =\n\t\t\t\t\t\t    power & 0x0F;\n\t\t\t\t\tport->p_med_power.val = PEEK_UINT16;\n\t\t\t\t\tbreak;\n\t\t\t\tcase LLDP_TLV_MED_IV_HW:\n\t\t\t\tcase LLDP_TLV_MED_IV_SW:\n\t\t\t\tcase LLDP_TLV_MED_IV_FW:\n\t\t\t\tcase LLDP_TLV_MED_IV_SN:\n\t\t\t\tcase LLDP_TLV_MED_IV_MANUF:\n\t\t\t\tcase LLDP_TLV_MED_IV_MODEL:\n\t\t\t\tcase LLDP_TLV_MED_IV_ASSET:\n\t\t\t\t\tif (tlv_size <= 4)\n\t\t\t\t\t\tb = NULL;\n\t\t\t\t\telse {\n\t\t\t\t\t\tif ((b = (char*)malloc(tlv_size - 3)) ==\n\t\t\t\t\t\t    NULL) {\n\t\t\t\t\t\t\tlog_warn(\"lldp\", \"unable to allocate \"\n\t\t\t\t\t\t\t    \"memory for LLDP-MED \"\n\t\t\t\t\t\t\t    \"inventory for frame \"\n\t\t\t\t\t\t\t    \"received on %s\",\n\t\t\t\t\t\t\t    hardware->h_ifname);\n\t\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tPEEK_BYTES(b, tlv_size - 4);\n\t\t\t\t\t\tb[tlv_size - 4] = '\\0';\n\t\t\t\t\t}\n\t\t\t\t\tswitch (tlv_subtype) {\n\t\t\t\t\tcase LLDP_TLV_MED_IV_HW:\n\t\t\t\t\t\tchassis->c_med_hw = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_FW:\n\t\t\t\t\t\tchassis->c_med_fw = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_SW:\n\t\t\t\t\t\tchassis->c_med_sw = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_SN:\n\t\t\t\t\t\tchassis->c_med_sn = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_MANUF:\n\t\t\t\t\t\tchassis->c_med_manuf = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_MODEL:\n\t\t\t\t\t\tchassis->c_med_model = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase LLDP_TLV_MED_IV_ASSET:\n\t\t\t\t\t\tchassis->c_med_asset = b;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tport->p_med_cap_enabled |=\n\t\t\t\t\t    LLDP_MED_CAP_IV;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t/* Unknown LLDP MED, ignore it */\n\t\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t\t}\n#endif /* ENABLE_LLDPMED */\n\t\t\t} else if (memcmp(dcbx, orgid, sizeof(orgid)) == 0) {\n\t\t\t\tlog_debug(\"lldp\", \"unsupported DCBX tlv received on %s - ignore\",\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n\t\t\t} else {\n\t\t\t\tlog_debug(\"lldp\", \"unknown org tlv [%02x:%02x:%02x] received on %s\",\n\t\t\t\t    orgid[0], orgid[1], orgid[2],\n\t\t\t\t    hardware->h_ifname);\n\t\t\t\thardware->h_rx_unrecognized_cnt++;\n#ifdef ENABLE_CUSTOM\n\t\t\t\tcustom = (struct lldpd_custom*)calloc(1, sizeof(struct lldpd_custom));\n\t\t\t\tif (!custom) {\n\t\t\t\t\tlog_warn(\"lldp\",\n\t\t\t\t\t    \"unable to allocate memory for custom TLV\");\n\t\t\t\t\tgoto malformed;\n\t\t\t\t}\n\t\t\t\tcustom->oui_info_len = tlv_size > 4 ? tlv_size - 4 : 0;\n\t\t\t\tmemcpy(custom->oui, orgid, sizeof(custom->oui));\n\t\t\t\tcustom->subtype = tlv_subtype;\n\t\t\t\tif (custom->oui_info_len > 0) {\n\t\t\t\t\tcustom->oui_info = malloc(custom->oui_info_len);\n\t\t\t\t\tif (!custom->oui_info) {\n\t\t\t\t\t\tlog_warn(\"lldp\",\n\t\t\t\t\t\t    \"unable to allocate memory for custom TLV data\");\n\t\t\t\t\t\tgoto malformed;\n\t\t\t\t\t}\n\t\t\t\t\tPEEK_BYTES(custom->oui_info, custom->oui_info_len);\n\t\t\t\t}\n\t\t\t\tTAILQ_INSERT_TAIL(&port->p_custom_list, custom, next);\n\t\t\t\tcustom = NULL;\n#endif\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog_warnx(\"lldp\", \"unknown tlv (%d) received on %s\",\n\t\t\t    tlv_type, hardware->h_ifname);\n\t\t\tgoto malformed;\n\t\t}\n\t\tif (pos > tlv + tlv_size) {\n\t\t\tlog_warnx(\"lldp\", \"BUG: already past TLV!\");\n\t\t\tgoto malformed;\n\t\t}\n\t\tPEEK_DISCARD(tlv + tlv_size - pos);\n\t}\n\n\t/* Some random check */\n\tif ((chassis->c_id == NULL) ||\n\t    (port->p_id == NULL) ||\n\t    (!ttl_received) ||\n\t    (gotend == 0)) {\n\t\tlog_warnx(\"lldp\", \"some mandatory tlv are missing for frame received on %s\",\n\t\t    hardware->h_ifname);\n\t\tgoto malformed;\n\t}\n\t*newchassis = chassis;\n\t*newport = port;\n\treturn 1;\nmalformed:\n#ifdef ENABLE_CUSTOM\n\tfree(custom);\n#endif\n#ifdef ENABLE_DOT1\n\tfree(vlan);\n\tfree(pi);\n#endif\n\tlldpd_chassis_cleanup(chassis, 1);\n\tlldpd_port_cleanup(port, 1);\n\tfree(port);\n\treturn -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -181,10 +181,13 @@\n \t\t\t\tiface = 0;\n \t\t\tmgmt = lldpd_alloc_mgmt(af, addr_ptr, addr_length, iface);\n \t\t\tif (mgmt == NULL) {\n-\t\t\t\tassert(errno == ENOMEM);\n-\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"\n-\t\t\t\t\t\t\t\"for management address\");\n-\t\t\t\t\t\tgoto malformed;\n+\t\t\t\tif (errno == ENOMEM)\n+\t\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"\n+\t\t\t\t\t    \"for management address\");\n+\t\t\t\telse\n+\t\t\t\t\tlog_warn(\"lldp\", \"too large management address \"\n+\t\t\t\t\t    \"received on %s\", hardware->h_ifname);\n+\t\t\t\tgoto malformed;\n \t\t\t}\n \t\t\tTAILQ_INSERT_TAIL(&chassis->c_mgmt, mgmt, m_entries);\n \t\t\tbreak;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tassert(errno == ENOMEM);",
                "\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"",
                "\t\t\t\t\t\t\t\"for management address\");",
                "\t\t\t\t\t\tgoto malformed;"
            ],
            "added_lines": [
                "\t\t\t\tif (errno == ENOMEM)",
                "\t\t\t\t\tlog_warn(\"lldp\", \"unable to allocate memory \"",
                "\t\t\t\t\t    \"for management address\");",
                "\t\t\t\telse",
                "\t\t\t\t\tlog_warn(\"lldp\", \"too large management address \"",
                "\t\t\t\t\t    \"received on %s\", hardware->h_ifname);",
                "\t\t\t\tgoto malformed;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8012",
        "func_name": "lldpd/_lldp_send",
        "description": "lldpd before 0.8.0 allows remote attackers to cause a denial of service (assertion failure and daemon crash) via a malformed packet.",
        "git_url": "https://github.com/lldpd/lldpd/commit/793526f8884455f43daecd0a2c46772388417a00",
        "commit_title": "protocols: don't use assert on paths that can be reached",
        "commit_text": " Malformed packets should not make lldpd crash. Ensure we can handle them by not using assert() in this part.",
        "func_before": "static int _lldp_send(struct lldpd *global,\n    struct lldpd_hardware *hardware,\n    u_int8_t c_id_subtype,\n    char *c_id,\n    int c_id_len,\n    u_int8_t p_id_subtype,\n    char *p_id,\n    int p_id_len,\n    int shutdown)\n{\n\tstruct lldpd_port *port;\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_frame *frame;\n\tint length;\n\tu_int8_t *packet, *pos, *tlv;\n\tstruct lldpd_mgmt *mgmt;\n\tint proto;\n\n\tu_int8_t mcastaddr[] = LLDP_MULTICAST_ADDR;\n#ifdef ENABLE_DOT1\n\tconst u_int8_t dot1[] = LLDP_TLV_ORG_DOT1;\n\tstruct lldpd_vlan *vlan;\n\tstruct lldpd_ppvid *ppvid;\n\tstruct lldpd_pi *pi;\n#endif\n#ifdef ENABLE_DOT3\n\tconst u_int8_t dot3[] = LLDP_TLV_ORG_DOT3;\n#endif\n#ifdef ENABLE_LLDPMED\n\tint i;\n\tconst u_int8_t med[] = LLDP_TLV_ORG_MED;\n#endif\n#ifdef ENABLE_CUSTOM\n\tstruct lldpd_custom *custom;\n#endif\n\tport = &hardware->h_lport;\n\tchassis = port->p_chassis;\n\tlength = hardware->h_mtu;\n\tif ((packet = (u_int8_t*)calloc(1, length)) == NULL)\n\t\treturn ENOMEM;\n\tpos = packet;\n\n\t/* Ethernet header */\n\tif (!(\n\t      /* LLDP multicast address */\n\t      POKE_BYTES(mcastaddr, sizeof(mcastaddr)) &&\n\t      /* Source MAC address */\n\t      POKE_BYTES(&hardware->h_lladdr, ETHER_ADDR_LEN) &&\n\t      /* LLDP frame */\n\t      POKE_UINT16(ETHERTYPE_LLDP)))\n\t\tgoto toobig;\n\n\t/* Chassis ID */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_CHASSIS_ID) &&\n\t      POKE_UINT8(c_id_subtype) &&\n\t      POKE_BYTES(c_id, c_id_len) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* Port ID */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_PORT_ID) &&\n\t      POKE_UINT8(p_id_subtype) &&\n\t      POKE_BYTES(p_id, p_id_len) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* Time to live */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_TTL) &&\n\t      POKE_UINT16(shutdown?0:chassis->c_ttl) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\tif (shutdown)\n\t\tgoto end;\n\n\t/* System name */\n\tif (chassis->c_name && *chassis->c_name != '\\0') {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_SYSTEM_NAME) &&\n\t\t\t    POKE_BYTES(chassis->c_name, strlen(chassis->c_name)) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* System description (skip it if empty) */\n\tif (chassis->c_descr && *chassis->c_descr != '\\0') {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_SYSTEM_DESCR) &&\n\t\t\t    POKE_BYTES(chassis->c_descr, strlen(chassis->c_descr)) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* System capabilities */\n\tif (global->g_config.c_cap_advertise && chassis->c_cap_available) {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_SYSTEM_CAP) &&\n\t\t\t    POKE_UINT16(chassis->c_cap_available) &&\n\t\t\t    POKE_UINT16(chassis->c_cap_enabled) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* Management addresses */\n\tTAILQ_FOREACH(mgmt, &chassis->c_mgmt, m_entries) {\n\t\tproto = lldpd_af_to_lldp_proto(mgmt->m_family);\n\t\tassert(proto != LLDP_MGMT_ADDR_NONE);\n\t\tif (!(\n\t\t\t  POKE_START_LLDP_TLV(LLDP_TLV_MGMT_ADDR) &&\n\t\t\t  /* Size of the address, including its type */\n\t\t\t  POKE_UINT8(mgmt->m_addrsize + 1) &&\n\t\t\t  POKE_UINT8(proto) &&\n\t\t\t  POKE_BYTES(&mgmt->m_addr, mgmt->m_addrsize)))\n\t\t\tgoto toobig;\n\n\t\t/* Interface port type, OID */\n\t\tif (mgmt->m_iface == 0) {\n\t\t\tif (!(\n\t\t\t\t  /* We don't know the management interface */\n\t\t\t\t  POKE_UINT8(LLDP_MGMT_IFACE_UNKNOWN) &&\n\t\t\t\t  POKE_UINT32(0)))\n\t\t\t\tgoto toobig;\n\t\t} else {\n\t\t\tif (!(\n\t\t\t\t  /* We have the index of the management interface */\n\t\t\t\t  POKE_UINT8(LLDP_MGMT_IFACE_IFINDEX) &&\n\t\t\t\t  POKE_UINT32(mgmt->m_iface)))\n\t\t\t\tgoto toobig;\n\t\t}\n\t\tif (!(\n\t\t\t  /* We don't provide an OID for management */\n\t\t\t  POKE_UINT8(0) &&\n\t\t\t  POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* Port description */\n\tif (port->p_descr && *port->p_descr != '\\0') {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_PORT_DESCR) &&\n\t\t\t    POKE_BYTES(port->p_descr, strlen(port->p_descr)) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n#ifdef ENABLE_DOT1\n\t/* Port VLAN ID */\n\tif(port->p_pvid != 0) {\n\t\tif (!(\n\t\t    POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t    POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t    POKE_UINT8(LLDP_TLV_DOT1_PVID) &&\n\t\t    POKE_UINT16(port->p_pvid) &&\n\t\t    POKE_END_LLDP_TLV)) {\n\t\t    goto toobig;\n\t\t}\n\t}\n\t/* Port and Protocol VLAN IDs */\n\tTAILQ_FOREACH(ppvid, &port->p_ppvids, p_entries) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT1_PPVID) &&\n\t\t      POKE_UINT8(ppvid->p_cap_status) &&\n\t\t      POKE_UINT16(ppvid->p_ppvid) &&\n\t\t      POKE_END_LLDP_TLV)) {\n\t\t\tgoto toobig;\n\t\t}\n\t}\n\t/* VLANs */\n\tTAILQ_FOREACH(vlan, &port->p_vlans, v_entries) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT1_VLANNAME) &&\n\t\t      POKE_UINT16(vlan->v_vid) &&\n\t\t      POKE_UINT8(strlen(vlan->v_name)) &&\n\t\t      POKE_BYTES(vlan->v_name, strlen(vlan->v_name)) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\t/* Protocol Identities */\n\tTAILQ_FOREACH(pi, &port->p_pids, p_entries) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT1_PI) &&\n\t\t      POKE_UINT8(pi->p_pi_len) &&\n\t\t      POKE_BYTES(pi->p_pi, pi->p_pi_len) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n#endif\n\n#ifdef ENABLE_DOT3\n\t/* Aggregation status */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t      POKE_UINT8(LLDP_TLV_DOT3_LA) &&\n\t      /* Bit 0 = capability ; Bit 1 = status */\n\t      POKE_UINT8((port->p_aggregid) ? 3:1) &&\n\t      POKE_UINT32(port->p_aggregid) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* MAC/PHY */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t      POKE_UINT8(LLDP_TLV_DOT3_MAC) &&\n\t      POKE_UINT8(port->p_macphy.autoneg_support |\n\t\t\t (port->p_macphy.autoneg_enabled << 1)) &&\n\t      POKE_UINT16(port->p_macphy.autoneg_advertised) &&\n\t      POKE_UINT16(port->p_macphy.mau_type) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* MFS */\n\tif (port->p_mfs) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT3_MFS) &&\n\t\t      POKE_UINT16(port->p_mfs) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\t/* Power */\n\tif (port->p_power.devicetype) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT3_POWER) &&\n\t\t      POKE_UINT8((\n\t\t\t\t  (((2 - port->p_power.devicetype)    %(1<< 1))<<0) |\n\t\t\t\t  (( port->p_power.supported          %(1<< 1))<<1) |\n\t\t\t\t  (( port->p_power.enabled            %(1<< 1))<<2) |\n\t\t\t\t  (( port->p_power.paircontrol        %(1<< 1))<<3))) &&\n\t\t      POKE_UINT8(port->p_power.pairs) &&\n\t\t      POKE_UINT8(port->p_power.class)))\n\t\t\tgoto toobig;\n\t\t/* 802.3at */\n\t\tif (port->p_power.powertype != LLDP_DOT3_POWER_8023AT_OFF) {\n\t\t\tif (!(\n\t\t\t      POKE_UINT8((\n\t\t\t\t\t  (((port->p_power.powertype ==\n\t\t\t\t\t      LLDP_DOT3_POWER_8023AT_TYPE1)?1:0) << 7) |\n\t\t\t\t\t   (((port->p_power.devicetype ==\n\t\t\t\t\t      LLDP_DOT3_POWER_PSE)?0:1) << 6) |\n\t\t\t\t\t   ((port->p_power.source   %(1<< 2))<<4) |\n\t\t\t\t\t   ((port->p_power.priority %(1<< 2))<<0))) &&\n\t\t\t      POKE_UINT16(port->p_power.requested) &&\n\t\t\t      POKE_UINT16(port->p_power.allocated)))\n\t\t\t\tgoto toobig;\n\t\t}\n\t\tif (!(POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n#endif\n\n#ifdef ENABLE_LLDPMED\n\tif (port->p_med_cap_enabled) {\n\t\t/* LLDP-MED cap */\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t      POKE_UINT8(LLDP_TLV_MED_CAP) &&\n\t\t      POKE_UINT16(chassis->c_med_cap_available) &&\n\t\t      POKE_UINT8(chassis->c_med_type) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\n\t\t/* LLDP-MED inventory */\n#define LLDP_INVENTORY(value, subtype)\t\t\t\t\t\\\n\t\tif (value) {\t\t\t\t\t\t\\\n\t\t    if (!(\t\t\t\t\t\t\\\n\t\t\t  POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\t\t\\\n\t\t\t  POKE_BYTES(med, sizeof(med)) &&\t\t\\\n\t\t\t  POKE_UINT8(subtype) &&\t\t\t\\\n\t\t\t  POKE_BYTES(value,\t\t\t\t\\\n\t\t\t\t(strlen(value)>32)?32:strlen(value)) &&\t\\\n\t\t\t  POKE_END_LLDP_TLV))\t\t\t\t\\\n\t\t\t    goto toobig;\t\t\t\t\\\n\t\t}\n\n\t\tif (port->p_med_cap_enabled & LLDP_MED_CAP_IV) {\n\t\t\tLLDP_INVENTORY(chassis->c_med_hw,\n\t\t\t    LLDP_TLV_MED_IV_HW);\n\t\t\tLLDP_INVENTORY(chassis->c_med_fw,\n\t\t\t    LLDP_TLV_MED_IV_FW);\n\t\t\tLLDP_INVENTORY(chassis->c_med_sw,\n\t\t\t    LLDP_TLV_MED_IV_SW);\n\t\t\tLLDP_INVENTORY(chassis->c_med_sn,\n\t\t\t    LLDP_TLV_MED_IV_SN);\n\t\t\tLLDP_INVENTORY(chassis->c_med_manuf,\n\t\t\t    LLDP_TLV_MED_IV_MANUF);\n\t\t\tLLDP_INVENTORY(chassis->c_med_model,\n\t\t\t    LLDP_TLV_MED_IV_MODEL);\n\t\t\tLLDP_INVENTORY(chassis->c_med_asset,\n\t\t\t    LLDP_TLV_MED_IV_ASSET);\n\t\t}\n\n\t\t/* LLDP-MED location */\n\t\tfor (i = 0; i < LLDP_MED_LOCFORMAT_LAST; i++) {\n\t\t\tif (port->p_med_location[i].format == i + 1) {\n\t\t\t\tif (!(\n\t\t\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t\t\t      POKE_UINT8(LLDP_TLV_MED_LOCATION) &&\n\t\t\t\t      POKE_UINT8(port->p_med_location[i].format) &&\n\t\t\t\t      POKE_BYTES(port->p_med_location[i].data,\n\t\t\t\t\t  port->p_med_location[i].data_len) &&\n\t\t\t\t      POKE_END_LLDP_TLV))\n\t\t\t\t\tgoto toobig;\n\t\t\t}\n\t\t}\n\n\t\t/* LLDP-MED network policy */\n\t\tfor (i = 0; i < LLDP_MED_APPTYPE_LAST; i++) {\n\t\t\tif (port->p_med_policy[i].type == i + 1) {\n\t\t\t\tif (!(\n\t\t\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t\t\t      POKE_UINT8(LLDP_TLV_MED_POLICY) &&\n\t\t\t\t      POKE_UINT32((\n\t\t\t\t\t((port->p_med_policy[i].type     %(1<< 8))<<24) |\n\t\t\t\t\t((port->p_med_policy[i].unknown  %(1<< 1))<<23) |\n\t\t\t\t\t((port->p_med_policy[i].tagged   %(1<< 1))<<22) |\n\t\t\t\t      /*((0                              %(1<< 1))<<21) |*/\n\t\t\t\t\t((port->p_med_policy[i].vid      %(1<<12))<< 9) |\n\t\t\t\t\t((port->p_med_policy[i].priority %(1<< 3))<< 6) |\n\t\t\t\t\t((port->p_med_policy[i].dscp     %(1<< 6))<< 0) )) &&\n\t\t\t\t      POKE_END_LLDP_TLV))\n\t\t\t\t\tgoto toobig;\n\t\t\t}\n\t\t}\n\n\t\t/* LLDP-MED POE-MDI */\n\t\tif ((port->p_med_power.devicetype == LLDP_MED_POW_TYPE_PSE) ||\n\t\t    (port->p_med_power.devicetype == LLDP_MED_POW_TYPE_PD)) {\n\t\t\tint devicetype = 0, source = 0;\n\t\t\tif (!(\n\t\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t\t      POKE_UINT8(LLDP_TLV_MED_MDI)))\n\t\t\t\tgoto toobig;\n\t\t\tswitch (port->p_med_power.devicetype) {\n\t\t\tcase LLDP_MED_POW_TYPE_PSE:\n\t\t\t\tdevicetype = 0;\n\t\t\t\tswitch (port->p_med_power.source) {\n\t\t\t\tcase LLDP_MED_POW_SOURCE_PRIMARY: source = 1; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_BACKUP: source = 2; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_RESERVED: source = 3; break;\n\t\t\t\tdefault: source = 0; break;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase LLDP_MED_POW_TYPE_PD:\n\t\t\t\tdevicetype = 1;\n\t\t\t\tswitch (port->p_med_power.source) {\n\t\t\t\tcase LLDP_MED_POW_SOURCE_PSE: source = 1; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_LOCAL: source = 2; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_BOTH: source = 3; break;\n\t\t\t\tdefault: source = 0; break;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!(\n\t\t\t      POKE_UINT8((\n\t\t\t\t((devicetype                   %(1<< 2))<<6) |\n\t\t\t\t((source                       %(1<< 2))<<4) |\n\t\t\t\t((port->p_med_power.priority   %(1<< 4))<<0) )) &&\n\t\t\t      POKE_UINT16(port->p_med_power.val) &&\n\t\t\t      POKE_END_LLDP_TLV))\n\t\t\t\tgoto toobig;\n\t\t}\n\t}\n#endif\n\n#ifdef ENABLE_CUSTOM\n\tTAILQ_FOREACH(custom, &port->p_custom_list, next) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(custom->oui, sizeof(custom->oui)) &&\n\t\t      POKE_UINT8(custom->subtype) &&\n\t\t      POKE_BYTES(custom->oui_info, custom->oui_info_len) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n#endif\n\nend:\n\t/* END */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_END) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\tif (interfaces_send_helper(global, hardware,\n\t\t(char *)packet, pos - packet) == -1) {\n\t\tlog_warn(\"lldp\", \"unable to send packet on real device for %s\",\n\t\t    hardware->h_ifname);\n\t\tfree(packet);\n\t\treturn ENETDOWN;\n\t}\n\n\thardware->h_tx_cnt++;\n\n\t/* We assume that LLDP frame is the reference */\n\tif (!shutdown && (frame = (struct lldpd_frame*)malloc(\n\t\t\tsizeof(int) + pos - packet)) != NULL) {\n\t\tframe->size = pos - packet;\n\t\tmemcpy(&frame->frame, packet, frame->size);\n\t\tif ((hardware->h_lport.p_lastframe == NULL) ||\n\t\t    (hardware->h_lport.p_lastframe->size != frame->size) ||\n\t\t    (memcmp(hardware->h_lport.p_lastframe->frame, frame->frame,\n\t\t\tframe->size) != 0)) {\n\t\t\tfree(hardware->h_lport.p_lastframe);\n\t\t\thardware->h_lport.p_lastframe = frame;\n\t\t\thardware->h_lport.p_lastchange = time(NULL);\n\t\t} else free(frame);\n\t}\n\n\tfree(packet);\n\treturn 0;\n\ntoobig:\n\tfree(packet);\n\treturn E2BIG;\n}",
        "func": "static int _lldp_send(struct lldpd *global,\n    struct lldpd_hardware *hardware,\n    u_int8_t c_id_subtype,\n    char *c_id,\n    int c_id_len,\n    u_int8_t p_id_subtype,\n    char *p_id,\n    int p_id_len,\n    int shutdown)\n{\n\tstruct lldpd_port *port;\n\tstruct lldpd_chassis *chassis;\n\tstruct lldpd_frame *frame;\n\tint length;\n\tu_int8_t *packet, *pos, *tlv;\n\tstruct lldpd_mgmt *mgmt;\n\tint proto;\n\n\tu_int8_t mcastaddr[] = LLDP_MULTICAST_ADDR;\n#ifdef ENABLE_DOT1\n\tconst u_int8_t dot1[] = LLDP_TLV_ORG_DOT1;\n\tstruct lldpd_vlan *vlan;\n\tstruct lldpd_ppvid *ppvid;\n\tstruct lldpd_pi *pi;\n#endif\n#ifdef ENABLE_DOT3\n\tconst u_int8_t dot3[] = LLDP_TLV_ORG_DOT3;\n#endif\n#ifdef ENABLE_LLDPMED\n\tint i;\n\tconst u_int8_t med[] = LLDP_TLV_ORG_MED;\n#endif\n#ifdef ENABLE_CUSTOM\n\tstruct lldpd_custom *custom;\n#endif\n\tport = &hardware->h_lport;\n\tchassis = port->p_chassis;\n\tlength = hardware->h_mtu;\n\tif ((packet = (u_int8_t*)calloc(1, length)) == NULL)\n\t\treturn ENOMEM;\n\tpos = packet;\n\n\t/* Ethernet header */\n\tif (!(\n\t      /* LLDP multicast address */\n\t      POKE_BYTES(mcastaddr, sizeof(mcastaddr)) &&\n\t      /* Source MAC address */\n\t      POKE_BYTES(&hardware->h_lladdr, ETHER_ADDR_LEN) &&\n\t      /* LLDP frame */\n\t      POKE_UINT16(ETHERTYPE_LLDP)))\n\t\tgoto toobig;\n\n\t/* Chassis ID */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_CHASSIS_ID) &&\n\t      POKE_UINT8(c_id_subtype) &&\n\t      POKE_BYTES(c_id, c_id_len) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* Port ID */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_PORT_ID) &&\n\t      POKE_UINT8(p_id_subtype) &&\n\t      POKE_BYTES(p_id, p_id_len) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* Time to live */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_TTL) &&\n\t      POKE_UINT16(shutdown?0:chassis->c_ttl) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\tif (shutdown)\n\t\tgoto end;\n\n\t/* System name */\n\tif (chassis->c_name && *chassis->c_name != '\\0') {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_SYSTEM_NAME) &&\n\t\t\t    POKE_BYTES(chassis->c_name, strlen(chassis->c_name)) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* System description (skip it if empty) */\n\tif (chassis->c_descr && *chassis->c_descr != '\\0') {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_SYSTEM_DESCR) &&\n\t\t\t    POKE_BYTES(chassis->c_descr, strlen(chassis->c_descr)) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* System capabilities */\n\tif (global->g_config.c_cap_advertise && chassis->c_cap_available) {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_SYSTEM_CAP) &&\n\t\t\t    POKE_UINT16(chassis->c_cap_available) &&\n\t\t\t    POKE_UINT16(chassis->c_cap_enabled) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* Management addresses */\n\tTAILQ_FOREACH(mgmt, &chassis->c_mgmt, m_entries) {\n\t\tproto = lldpd_af_to_lldp_proto(mgmt->m_family);\n\t\tif (proto == LLDP_MGMT_ADDR_NONE) continue;\n\t\tif (!(\n\t\t\t  POKE_START_LLDP_TLV(LLDP_TLV_MGMT_ADDR) &&\n\t\t\t  /* Size of the address, including its type */\n\t\t\t  POKE_UINT8(mgmt->m_addrsize + 1) &&\n\t\t\t  POKE_UINT8(proto) &&\n\t\t\t  POKE_BYTES(&mgmt->m_addr, mgmt->m_addrsize)))\n\t\t\tgoto toobig;\n\n\t\t/* Interface port type, OID */\n\t\tif (mgmt->m_iface == 0) {\n\t\t\tif (!(\n\t\t\t\t  /* We don't know the management interface */\n\t\t\t\t  POKE_UINT8(LLDP_MGMT_IFACE_UNKNOWN) &&\n\t\t\t\t  POKE_UINT32(0)))\n\t\t\t\tgoto toobig;\n\t\t} else {\n\t\t\tif (!(\n\t\t\t\t  /* We have the index of the management interface */\n\t\t\t\t  POKE_UINT8(LLDP_MGMT_IFACE_IFINDEX) &&\n\t\t\t\t  POKE_UINT32(mgmt->m_iface)))\n\t\t\t\tgoto toobig;\n\t\t}\n\t\tif (!(\n\t\t\t  /* We don't provide an OID for management */\n\t\t\t  POKE_UINT8(0) &&\n\t\t\t  POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n\t/* Port description */\n\tif (port->p_descr && *port->p_descr != '\\0') {\n\t\tif (!(\n\t\t\t    POKE_START_LLDP_TLV(LLDP_TLV_PORT_DESCR) &&\n\t\t\t    POKE_BYTES(port->p_descr, strlen(port->p_descr)) &&\n\t\t\t    POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\n#ifdef ENABLE_DOT1\n\t/* Port VLAN ID */\n\tif(port->p_pvid != 0) {\n\t\tif (!(\n\t\t    POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t    POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t    POKE_UINT8(LLDP_TLV_DOT1_PVID) &&\n\t\t    POKE_UINT16(port->p_pvid) &&\n\t\t    POKE_END_LLDP_TLV)) {\n\t\t    goto toobig;\n\t\t}\n\t}\n\t/* Port and Protocol VLAN IDs */\n\tTAILQ_FOREACH(ppvid, &port->p_ppvids, p_entries) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT1_PPVID) &&\n\t\t      POKE_UINT8(ppvid->p_cap_status) &&\n\t\t      POKE_UINT16(ppvid->p_ppvid) &&\n\t\t      POKE_END_LLDP_TLV)) {\n\t\t\tgoto toobig;\n\t\t}\n\t}\n\t/* VLANs */\n\tTAILQ_FOREACH(vlan, &port->p_vlans, v_entries) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT1_VLANNAME) &&\n\t\t      POKE_UINT16(vlan->v_vid) &&\n\t\t      POKE_UINT8(strlen(vlan->v_name)) &&\n\t\t      POKE_BYTES(vlan->v_name, strlen(vlan->v_name)) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\t/* Protocol Identities */\n\tTAILQ_FOREACH(pi, &port->p_pids, p_entries) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot1, sizeof(dot1)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT1_PI) &&\n\t\t      POKE_UINT8(pi->p_pi_len) &&\n\t\t      POKE_BYTES(pi->p_pi, pi->p_pi_len) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n#endif\n\n#ifdef ENABLE_DOT3\n\t/* Aggregation status */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t      POKE_UINT8(LLDP_TLV_DOT3_LA) &&\n\t      /* Bit 0 = capability ; Bit 1 = status */\n\t      POKE_UINT8((port->p_aggregid) ? 3:1) &&\n\t      POKE_UINT32(port->p_aggregid) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* MAC/PHY */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t      POKE_UINT8(LLDP_TLV_DOT3_MAC) &&\n\t      POKE_UINT8(port->p_macphy.autoneg_support |\n\t\t\t (port->p_macphy.autoneg_enabled << 1)) &&\n\t      POKE_UINT16(port->p_macphy.autoneg_advertised) &&\n\t      POKE_UINT16(port->p_macphy.mau_type) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\t/* MFS */\n\tif (port->p_mfs) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT3_MFS) &&\n\t\t      POKE_UINT16(port->p_mfs) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n\t/* Power */\n\tif (port->p_power.devicetype) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(dot3, sizeof(dot3)) &&\n\t\t      POKE_UINT8(LLDP_TLV_DOT3_POWER) &&\n\t\t      POKE_UINT8((\n\t\t\t\t  (((2 - port->p_power.devicetype)    %(1<< 1))<<0) |\n\t\t\t\t  (( port->p_power.supported          %(1<< 1))<<1) |\n\t\t\t\t  (( port->p_power.enabled            %(1<< 1))<<2) |\n\t\t\t\t  (( port->p_power.paircontrol        %(1<< 1))<<3))) &&\n\t\t      POKE_UINT8(port->p_power.pairs) &&\n\t\t      POKE_UINT8(port->p_power.class)))\n\t\t\tgoto toobig;\n\t\t/* 802.3at */\n\t\tif (port->p_power.powertype != LLDP_DOT3_POWER_8023AT_OFF) {\n\t\t\tif (!(\n\t\t\t      POKE_UINT8((\n\t\t\t\t\t  (((port->p_power.powertype ==\n\t\t\t\t\t      LLDP_DOT3_POWER_8023AT_TYPE1)?1:0) << 7) |\n\t\t\t\t\t   (((port->p_power.devicetype ==\n\t\t\t\t\t      LLDP_DOT3_POWER_PSE)?0:1) << 6) |\n\t\t\t\t\t   ((port->p_power.source   %(1<< 2))<<4) |\n\t\t\t\t\t   ((port->p_power.priority %(1<< 2))<<0))) &&\n\t\t\t      POKE_UINT16(port->p_power.requested) &&\n\t\t\t      POKE_UINT16(port->p_power.allocated)))\n\t\t\t\tgoto toobig;\n\t\t}\n\t\tif (!(POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n#endif\n\n#ifdef ENABLE_LLDPMED\n\tif (port->p_med_cap_enabled) {\n\t\t/* LLDP-MED cap */\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t      POKE_UINT8(LLDP_TLV_MED_CAP) &&\n\t\t      POKE_UINT16(chassis->c_med_cap_available) &&\n\t\t      POKE_UINT8(chassis->c_med_type) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\n\t\t/* LLDP-MED inventory */\n#define LLDP_INVENTORY(value, subtype)\t\t\t\t\t\\\n\t\tif (value) {\t\t\t\t\t\t\\\n\t\t    if (!(\t\t\t\t\t\t\\\n\t\t\t  POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\t\t\\\n\t\t\t  POKE_BYTES(med, sizeof(med)) &&\t\t\\\n\t\t\t  POKE_UINT8(subtype) &&\t\t\t\\\n\t\t\t  POKE_BYTES(value,\t\t\t\t\\\n\t\t\t\t(strlen(value)>32)?32:strlen(value)) &&\t\\\n\t\t\t  POKE_END_LLDP_TLV))\t\t\t\t\\\n\t\t\t    goto toobig;\t\t\t\t\\\n\t\t}\n\n\t\tif (port->p_med_cap_enabled & LLDP_MED_CAP_IV) {\n\t\t\tLLDP_INVENTORY(chassis->c_med_hw,\n\t\t\t    LLDP_TLV_MED_IV_HW);\n\t\t\tLLDP_INVENTORY(chassis->c_med_fw,\n\t\t\t    LLDP_TLV_MED_IV_FW);\n\t\t\tLLDP_INVENTORY(chassis->c_med_sw,\n\t\t\t    LLDP_TLV_MED_IV_SW);\n\t\t\tLLDP_INVENTORY(chassis->c_med_sn,\n\t\t\t    LLDP_TLV_MED_IV_SN);\n\t\t\tLLDP_INVENTORY(chassis->c_med_manuf,\n\t\t\t    LLDP_TLV_MED_IV_MANUF);\n\t\t\tLLDP_INVENTORY(chassis->c_med_model,\n\t\t\t    LLDP_TLV_MED_IV_MODEL);\n\t\t\tLLDP_INVENTORY(chassis->c_med_asset,\n\t\t\t    LLDP_TLV_MED_IV_ASSET);\n\t\t}\n\n\t\t/* LLDP-MED location */\n\t\tfor (i = 0; i < LLDP_MED_LOCFORMAT_LAST; i++) {\n\t\t\tif (port->p_med_location[i].format == i + 1) {\n\t\t\t\tif (!(\n\t\t\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t\t\t      POKE_UINT8(LLDP_TLV_MED_LOCATION) &&\n\t\t\t\t      POKE_UINT8(port->p_med_location[i].format) &&\n\t\t\t\t      POKE_BYTES(port->p_med_location[i].data,\n\t\t\t\t\t  port->p_med_location[i].data_len) &&\n\t\t\t\t      POKE_END_LLDP_TLV))\n\t\t\t\t\tgoto toobig;\n\t\t\t}\n\t\t}\n\n\t\t/* LLDP-MED network policy */\n\t\tfor (i = 0; i < LLDP_MED_APPTYPE_LAST; i++) {\n\t\t\tif (port->p_med_policy[i].type == i + 1) {\n\t\t\t\tif (!(\n\t\t\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t\t\t      POKE_UINT8(LLDP_TLV_MED_POLICY) &&\n\t\t\t\t      POKE_UINT32((\n\t\t\t\t\t((port->p_med_policy[i].type     %(1<< 8))<<24) |\n\t\t\t\t\t((port->p_med_policy[i].unknown  %(1<< 1))<<23) |\n\t\t\t\t\t((port->p_med_policy[i].tagged   %(1<< 1))<<22) |\n\t\t\t\t      /*((0                              %(1<< 1))<<21) |*/\n\t\t\t\t\t((port->p_med_policy[i].vid      %(1<<12))<< 9) |\n\t\t\t\t\t((port->p_med_policy[i].priority %(1<< 3))<< 6) |\n\t\t\t\t\t((port->p_med_policy[i].dscp     %(1<< 6))<< 0) )) &&\n\t\t\t\t      POKE_END_LLDP_TLV))\n\t\t\t\t\tgoto toobig;\n\t\t\t}\n\t\t}\n\n\t\t/* LLDP-MED POE-MDI */\n\t\tif ((port->p_med_power.devicetype == LLDP_MED_POW_TYPE_PSE) ||\n\t\t    (port->p_med_power.devicetype == LLDP_MED_POW_TYPE_PD)) {\n\t\t\tint devicetype = 0, source = 0;\n\t\t\tif (!(\n\t\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t\t      POKE_BYTES(med, sizeof(med)) &&\n\t\t\t      POKE_UINT8(LLDP_TLV_MED_MDI)))\n\t\t\t\tgoto toobig;\n\t\t\tswitch (port->p_med_power.devicetype) {\n\t\t\tcase LLDP_MED_POW_TYPE_PSE:\n\t\t\t\tdevicetype = 0;\n\t\t\t\tswitch (port->p_med_power.source) {\n\t\t\t\tcase LLDP_MED_POW_SOURCE_PRIMARY: source = 1; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_BACKUP: source = 2; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_RESERVED: source = 3; break;\n\t\t\t\tdefault: source = 0; break;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase LLDP_MED_POW_TYPE_PD:\n\t\t\t\tdevicetype = 1;\n\t\t\t\tswitch (port->p_med_power.source) {\n\t\t\t\tcase LLDP_MED_POW_SOURCE_PSE: source = 1; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_LOCAL: source = 2; break;\n\t\t\t\tcase LLDP_MED_POW_SOURCE_BOTH: source = 3; break;\n\t\t\t\tdefault: source = 0; break;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!(\n\t\t\t      POKE_UINT8((\n\t\t\t\t((devicetype                   %(1<< 2))<<6) |\n\t\t\t\t((source                       %(1<< 2))<<4) |\n\t\t\t\t((port->p_med_power.priority   %(1<< 4))<<0) )) &&\n\t\t\t      POKE_UINT16(port->p_med_power.val) &&\n\t\t\t      POKE_END_LLDP_TLV))\n\t\t\t\tgoto toobig;\n\t\t}\n\t}\n#endif\n\n#ifdef ENABLE_CUSTOM\n\tTAILQ_FOREACH(custom, &port->p_custom_list, next) {\n\t\tif (!(\n\t\t      POKE_START_LLDP_TLV(LLDP_TLV_ORG) &&\n\t\t      POKE_BYTES(custom->oui, sizeof(custom->oui)) &&\n\t\t      POKE_UINT8(custom->subtype) &&\n\t\t      POKE_BYTES(custom->oui_info, custom->oui_info_len) &&\n\t\t      POKE_END_LLDP_TLV))\n\t\t\tgoto toobig;\n\t}\n#endif\n\nend:\n\t/* END */\n\tif (!(\n\t      POKE_START_LLDP_TLV(LLDP_TLV_END) &&\n\t      POKE_END_LLDP_TLV))\n\t\tgoto toobig;\n\n\tif (interfaces_send_helper(global, hardware,\n\t\t(char *)packet, pos - packet) == -1) {\n\t\tlog_warn(\"lldp\", \"unable to send packet on real device for %s\",\n\t\t    hardware->h_ifname);\n\t\tfree(packet);\n\t\treturn ENETDOWN;\n\t}\n\n\thardware->h_tx_cnt++;\n\n\t/* We assume that LLDP frame is the reference */\n\tif (!shutdown && (frame = (struct lldpd_frame*)malloc(\n\t\t\tsizeof(int) + pos - packet)) != NULL) {\n\t\tframe->size = pos - packet;\n\t\tmemcpy(&frame->frame, packet, frame->size);\n\t\tif ((hardware->h_lport.p_lastframe == NULL) ||\n\t\t    (hardware->h_lport.p_lastframe->size != frame->size) ||\n\t\t    (memcmp(hardware->h_lport.p_lastframe->frame, frame->frame,\n\t\t\tframe->size) != 0)) {\n\t\t\tfree(hardware->h_lport.p_lastframe);\n\t\t\thardware->h_lport.p_lastframe = frame;\n\t\t\thardware->h_lport.p_lastchange = time(NULL);\n\t\t} else free(frame);\n\t}\n\n\tfree(packet);\n\treturn 0;\n\ntoobig:\n\tfree(packet);\n\treturn E2BIG;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -107,7 +107,7 @@\n \t/* Management addresses */\n \tTAILQ_FOREACH(mgmt, &chassis->c_mgmt, m_entries) {\n \t\tproto = lldpd_af_to_lldp_proto(mgmt->m_family);\n-\t\tassert(proto != LLDP_MGMT_ADDR_NONE);\n+\t\tif (proto == LLDP_MGMT_ADDR_NONE) continue;\n \t\tif (!(\n \t\t\t  POKE_START_LLDP_TLV(LLDP_TLV_MGMT_ADDR) &&\n \t\t\t  /* Size of the address, including its type */",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tassert(proto != LLDP_MGMT_ADDR_NONE);"
            ],
            "added_lines": [
                "\t\tif (proto == LLDP_MGMT_ADDR_NONE) continue;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8012",
        "func_name": "lldpd/lldpd_alloc_mgmt",
        "description": "lldpd before 0.8.0 allows remote attackers to cause a denial of service (assertion failure and daemon crash) via a malformed packet.",
        "git_url": "https://github.com/lldpd/lldpd/commit/793526f8884455f43daecd0a2c46772388417a00",
        "commit_title": "protocols: don't use assert on paths that can be reached",
        "commit_text": " Malformed packets should not make lldpd crash. Ensure we can handle them by not using assert() in this part.",
        "func_before": "struct lldpd_mgmt *\nlldpd_alloc_mgmt(int family, void *addrptr, size_t addrsize, u_int32_t iface)\n{\n\tstruct lldpd_mgmt *mgmt;\n\n\tlog_debug(\"alloc\", \"allocate a new management address (family: %d)\", family);\n\n\tif (family <= LLDPD_AF_UNSPEC || family >= LLDPD_AF_LAST) {\n\t\terrno = EAFNOSUPPORT;\n\t\treturn NULL;\n\t}\n\tif (addrsize > LLDPD_MGMT_MAXADDRSIZE) {\n\t\terrno = EOVERFLOW;\n\t\treturn NULL;\n\t}\n\tmgmt = calloc(1, sizeof(struct lldpd_mgmt));\n\tif (mgmt == NULL) {\n\t\terrno = ENOMEM;\n\t\treturn NULL;\n\t}\n\tmgmt->m_family = family;\n\tassert(addrsize <= LLDPD_MGMT_MAXADDRSIZE);\n\tmemcpy(&mgmt->m_addr, addrptr, addrsize);\n\tmgmt->m_addrsize = addrsize;\n\tmgmt->m_iface = iface;\n\treturn mgmt;\n}",
        "func": "struct lldpd_mgmt *\nlldpd_alloc_mgmt(int family, void *addrptr, size_t addrsize, u_int32_t iface)\n{\n\tstruct lldpd_mgmt *mgmt;\n\n\tlog_debug(\"alloc\", \"allocate a new management address (family: %d)\", family);\n\n\tif (family <= LLDPD_AF_UNSPEC || family >= LLDPD_AF_LAST) {\n\t\terrno = EAFNOSUPPORT;\n\t\treturn NULL;\n\t}\n\tif (addrsize > LLDPD_MGMT_MAXADDRSIZE) {\n\t\terrno = EOVERFLOW;\n\t\treturn NULL;\n\t}\n\tmgmt = calloc(1, sizeof(struct lldpd_mgmt));\n\tif (mgmt == NULL) {\n\t\terrno = ENOMEM;\n\t\treturn NULL;\n\t}\n\tmgmt->m_family = family;\n\tmemcpy(&mgmt->m_addr, addrptr, addrsize);\n\tmgmt->m_addrsize = addrsize;\n\tmgmt->m_iface = iface;\n\treturn mgmt;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,7 +19,6 @@\n \t\treturn NULL;\n \t}\n \tmgmt->m_family = family;\n-\tassert(addrsize <= LLDPD_MGMT_MAXADDRSIZE);\n \tmemcpy(&mgmt->m_addr, addrptr, addrsize);\n \tmgmt->m_addrsize = addrsize;\n \tmgmt->m_iface = iface;",
        "diff_line_info": {
            "deleted_lines": [
                "\tassert(addrsize <= LLDPD_MGMT_MAXADDRSIZE);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2020-15194",
        "func_name": "tensorflow/Compute",
        "description": "In Tensorflow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1, the `SparseFillEmptyRowsGrad` implementation has incomplete validation of the shapes of its arguments. Although `reverse_index_map_t` and `grad_values_t` are accessed in a similar pattern, only `reverse_index_map_t` is validated to be of proper shape. Hence, malicious users can pass a bad `grad_values_t` to trigger an assertion failure in `vec`, causing denial of service in serving installations. The issue is patched in commit 390611e0d45c5793c7066110af37c8514e6a6c54, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.\"",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/390611e0d45c5793c7066110af37c8514e6a6c54",
        "commit_title": "Fix heap buffer overflow in `tf.raw_ops.SparseFillEmptyRowsGrad`.",
        "commit_text": " Also add tests as they were lacking  PiperOrigin-RevId: 332566071",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor* reverse_index_map_t;\n    const Tensor* grad_values_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"reverse_index_map\", &reverse_index_map_t));\n    OP_REQUIRES_OK(context, context->input(\"grad_values\", &grad_values_t));\n\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(reverse_index_map_t->shape()),\n        errors::InvalidArgument(\"reverse_index_map must be a vector, saw: \",\n                                reverse_index_map_t->shape().DebugString()));\n\n    const auto reverse_index_map = reverse_index_map_t->vec<int64>();\n    const auto grad_values = grad_values_t->vec<T>();\n\n    const int64 N = reverse_index_map_t->shape().dim_size(0);\n    const int64 N_full = grad_values_t->shape().dim_size(0);\n\n    Tensor* d_values_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"d_values\", TensorShape({N}), &d_values_t));\n    auto d_values = d_values_t->vec<T>();\n    Tensor* d_default_value_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"d_default_value\", TensorShape({}),\n                                            &d_default_value_t));\n    T& d_default_value = d_default_value_t->scalar<T>()();\n    d_default_value = T();\n\n    Tensor visited_t;\n    OP_REQUIRES_OK(context, context->allocate_temp(\n                                DT_BOOL, TensorShape({N_full}), &visited_t));\n    auto visited = visited_t.vec<bool>();\n    visited.device(d) = visited.constant(false);\n\n    for (int i = 0; i < N; ++i) {\n      // Locate the index of the output of the forward prop associated\n      // with this location in the input of the forward prop.  Copy\n      // the gradient into it.  Mark it as visited.\n      d_values(i) = grad_values(reverse_index_map(i));\n      visited(reverse_index_map(i)) = true;\n    }\n    for (int j = 0; j < N_full; ++j) {\n      // The default value gradient gets the accumulated remainder of\n      // the backprop values (since the default value was used to fill\n      // in these slots in the forward calculation).\n      if (!visited(j)) {\n        d_default_value += grad_values(j);\n      }\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor* reverse_index_map_t;\n    const Tensor* grad_values_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"reverse_index_map\", &reverse_index_map_t));\n    OP_REQUIRES_OK(context, context->input(\"grad_values\", &grad_values_t));\n\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(reverse_index_map_t->shape()),\n        errors::InvalidArgument(\"reverse_index_map must be a vector, saw: \",\n                                reverse_index_map_t->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(grad_values_t->shape()),\n                errors::InvalidArgument(\"grad_values must be a vector, saw: \",\n                                        grad_values_t->shape().DebugString()));\n\n    const auto reverse_index_map = reverse_index_map_t->vec<int64>();\n    const auto grad_values = grad_values_t->vec<T>();\n\n    const int64 N = reverse_index_map_t->shape().dim_size(0);\n    const int64 N_full = grad_values_t->shape().dim_size(0);\n\n    Tensor* d_values_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"d_values\", TensorShape({N}), &d_values_t));\n    auto d_values = d_values_t->vec<T>();\n    Tensor* d_default_value_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"d_default_value\", TensorShape({}),\n                                            &d_default_value_t));\n    T& d_default_value = d_default_value_t->scalar<T>()();\n    d_default_value = T();\n\n    Tensor visited_t;\n    OP_REQUIRES_OK(context, context->allocate_temp(\n                                DT_BOOL, TensorShape({N_full}), &visited_t));\n    auto visited = visited_t.vec<bool>();\n    visited.device(d) = visited.constant(false);\n\n    for (int i = 0; i < N; ++i) {\n      // Locate the index of the output of the forward prop associated\n      // with this location in the input of the forward prop.  Copy\n      // the gradient into it.  Mark it as visited.\n      int64 reverse_index = reverse_index_map(i);\n      OP_REQUIRES(\n          context, 0 <= reverse_index && reverse_index < N_full,\n          errors::InvalidArgument(\"Elements in reverse index must be in [0, \",\n                                  N_full, \") but got \", reverse_index));\n      d_values(i) = grad_values(reverse_index);\n      visited(reverse_index) = true;\n    }\n    for (int j = 0; j < N_full; ++j) {\n      // The default value gradient gets the accumulated remainder of\n      // the backprop values (since the default value was used to fill\n      // in these slots in the forward calculation).\n      if (!visited(j)) {\n        d_default_value += grad_values(j);\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,9 @@\n         context, TensorShapeUtils::IsVector(reverse_index_map_t->shape()),\n         errors::InvalidArgument(\"reverse_index_map must be a vector, saw: \",\n                                 reverse_index_map_t->shape().DebugString()));\n+    OP_REQUIRES(context, TensorShapeUtils::IsVector(grad_values_t->shape()),\n+                errors::InvalidArgument(\"grad_values must be a vector, saw: \",\n+                                        grad_values_t->shape().DebugString()));\n \n     const auto reverse_index_map = reverse_index_map_t->vec<int64>();\n     const auto grad_values = grad_values_t->vec<T>();\n@@ -39,8 +42,13 @@\n       // Locate the index of the output of the forward prop associated\n       // with this location in the input of the forward prop.  Copy\n       // the gradient into it.  Mark it as visited.\n-      d_values(i) = grad_values(reverse_index_map(i));\n-      visited(reverse_index_map(i)) = true;\n+      int64 reverse_index = reverse_index_map(i);\n+      OP_REQUIRES(\n+          context, 0 <= reverse_index && reverse_index < N_full,\n+          errors::InvalidArgument(\"Elements in reverse index must be in [0, \",\n+                                  N_full, \") but got \", reverse_index));\n+      d_values(i) = grad_values(reverse_index);\n+      visited(reverse_index) = true;\n     }\n     for (int j = 0; j < N_full; ++j) {\n       // The default value gradient gets the accumulated remainder of",
        "diff_line_info": {
            "deleted_lines": [
                "      d_values(i) = grad_values(reverse_index_map(i));",
                "      visited(reverse_index_map(i)) = true;"
            ],
            "added_lines": [
                "    OP_REQUIRES(context, TensorShapeUtils::IsVector(grad_values_t->shape()),",
                "                errors::InvalidArgument(\"grad_values must be a vector, saw: \",",
                "                                        grad_values_t->shape().DebugString()));",
                "      int64 reverse_index = reverse_index_map(i);",
                "      OP_REQUIRES(",
                "          context, 0 <= reverse_index && reverse_index < N_full,",
                "          errors::InvalidArgument(\"Elements in reverse index must be in [0, \",",
                "                                  N_full, \") but got \", reverse_index));",
                "      d_values(i) = grad_values(reverse_index);",
                "      visited(reverse_index) = true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-15196",
        "func_name": "tensorflow/Compute",
        "description": "In Tensorflow version 2.3.0, the `SparseCountSparseOutput` and `RaggedCountSparseOutput` implementations don't validate that the `weights` tensor has the same shape as the data. The check exists for `DenseCountSparseOutput`, where both tensors are fully specified. In the sparse and ragged count weights are still accessed in parallel with the data. But, since there is no validation, a user passing fewer weights than the values for the tensors can generate a read from outside the bounds of the heap buffer allocated for the weights. The issue is patched in commit 3cbb917b4714766030b28eba9fb41bb97ce9ee02 and is released in TensorFlow version 2.3.1.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3cbb917b4714766030b28eba9fb41bb97ce9ee02",
        "commit_title": "Fix multiple vulnerabilities in `tf.raw_ops.*CountSparseOutput`.",
        "commit_text": " Also add tests for these API points, both for the happy paths and for the vulnerable ones.  PiperOrigin-RevId: 332563222",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& splits = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& weights = context->input(2);\n    bool use_weights = weights.NumElements() > 0;\n    bool is_1d = false;\n\n    const auto splits_values = splits.flat<int64>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n    int num_batches = splits.NumElements() - 1;\n    int num_values = values.NumElements();\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n    T max_value = 0;\n    int batch_idx = 0;\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits_values(batch_idx)) {\n        batch_idx++;\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch_idx - 1][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch_idx - 1][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch_idx - 1][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& splits = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& weights = context->input(2);\n    bool use_weights = weights.NumElements() > 0;\n    bool is_1d = false;\n\n    if (use_weights) {\n      OP_REQUIRES(\n          context, weights.shape() == values.shape(),\n          errors::InvalidArgument(\n              \"Weights and values must have the same shape. Weight shape: \",\n              weights.shape().DebugString(),\n              \"; values shape: \", values.shape().DebugString()));\n    }\n\n    const auto splits_values = splits.flat<int64>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n    int num_batches = splits.NumElements() - 1;\n    int num_values = values.NumElements();\n\n    OP_REQUIRES(\n        context, num_batches > 0,\n        errors::InvalidArgument(\n            \"Must provide at least 2 elements for the splits argument\"));\n    OP_REQUIRES(context, splits_values(0) == 0,\n                errors::InvalidArgument(\"Splits must start with 0, not with \",\n                                        splits_values(0)));\n    OP_REQUIRES(context, splits_values(num_batches) == num_values,\n                errors::InvalidArgument(\n                    \"Splits must end with the number of values, got \",\n                    splits_values(num_batches), \" instead of \", num_values));\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n    T max_value = 0;\n    int batch_idx = 0;\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits_values(batch_idx)) {\n        batch_idx++;\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch_idx - 1][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch_idx - 1][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch_idx - 1][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,11 +5,32 @@\n     bool use_weights = weights.NumElements() > 0;\n     bool is_1d = false;\n \n+    if (use_weights) {\n+      OP_REQUIRES(\n+          context, weights.shape() == values.shape(),\n+          errors::InvalidArgument(\n+              \"Weights and values must have the same shape. Weight shape: \",\n+              weights.shape().DebugString(),\n+              \"; values shape: \", values.shape().DebugString()));\n+    }\n+\n     const auto splits_values = splits.flat<int64>();\n     const auto values_values = values.flat<T>();\n     const auto weight_values = weights.flat<W>();\n     int num_batches = splits.NumElements() - 1;\n     int num_values = values.NumElements();\n+\n+    OP_REQUIRES(\n+        context, num_batches > 0,\n+        errors::InvalidArgument(\n+            \"Must provide at least 2 elements for the splits argument\"));\n+    OP_REQUIRES(context, splits_values(0) == 0,\n+                errors::InvalidArgument(\"Splits must start with 0, not with \",\n+                                        splits_values(0)));\n+    OP_REQUIRES(context, splits_values(num_batches) == num_values,\n+                errors::InvalidArgument(\n+                    \"Splits must end with the number of values, got \",\n+                    splits_values(num_batches), \" instead of \", num_values));\n \n     auto per_batch_counts = BatchedMap<W>(num_batches);\n     T max_value = 0;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (use_weights) {",
                "      OP_REQUIRES(",
                "          context, weights.shape() == values.shape(),",
                "          errors::InvalidArgument(",
                "              \"Weights and values must have the same shape. Weight shape: \",",
                "              weights.shape().DebugString(),",
                "              \"; values shape: \", values.shape().DebugString()));",
                "    }",
                "",
                "",
                "    OP_REQUIRES(",
                "        context, num_batches > 0,",
                "        errors::InvalidArgument(",
                "            \"Must provide at least 2 elements for the splits argument\"));",
                "    OP_REQUIRES(context, splits_values(0) == 0,",
                "                errors::InvalidArgument(\"Splits must start with 0, not with \",",
                "                                        splits_values(0)));",
                "    OP_REQUIRES(context, splits_values(num_batches) == num_values,",
                "                errors::InvalidArgument(",
                "                    \"Splits must end with the number of values, got \",",
                "                    splits_values(num_batches), \" instead of \", num_values));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27638",
        "func_name": "neocturne/fastd/handle_socket_receive_known",
        "description": "receive.c in fastd before v21 allows denial of service (assertion failure) when receiving packets with an invalid type code.",
        "git_url": "https://github.com/neocturne/fastd/commit/737925113363b6130879729cdff9ccc46c33eaea",
        "commit_title": "receive: fix buffer leak when receiving invalid packets",
        "commit_text": " For fastd versions before v20, this was just a memory leak (which could still be used for DoS, as it's remotely triggerable). With the new buffer management of fastd v20, this will trigger an assertion failure instead as soon as the buffer pool is empty.",
        "func_before": "static inline void handle_socket_receive_known(\n\tfastd_socket_t *sock, const fastd_peer_address_t *local_addr, const fastd_peer_address_t *remote_addr,\n\tfastd_peer_t *peer, fastd_buffer_t *buffer) {\n\tif (!fastd_peer_may_connect(peer)) {\n\t\tfastd_buffer_free(buffer);\n\t\treturn;\n\t}\n\n\tconst uint8_t *packet_type = buffer->data;\n\n\tswitch (*packet_type) {\n\tcase PACKET_DATA:\n\t\tif (!fastd_peer_is_established(peer) || !fastd_peer_address_equal(&peer->local_address, local_addr)) {\n\t\t\tfastd_buffer_free(buffer);\n\n\t\t\tif (!backoff_unknown(remote_addr)) {\n\t\t\t\tpr_debug(\"unexpectedly received payload data from %P[%I]\", peer, remote_addr);\n\t\t\t\tconf.protocol->handshake_init(sock, local_addr, remote_addr, NULL);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\tconf.protocol->handle_recv(peer, buffer);\n\t\tbreak;\n\n\tcase PACKET_HANDSHAKE:\n\t\tfastd_handshake_handle(sock, local_addr, remote_addr, peer, buffer);\n\t}\n}",
        "func": "static inline void handle_socket_receive_known(\n\tfastd_socket_t *sock, const fastd_peer_address_t *local_addr, const fastd_peer_address_t *remote_addr,\n\tfastd_peer_t *peer, fastd_buffer_t *buffer) {\n\tif (!fastd_peer_may_connect(peer)) {\n\t\tfastd_buffer_free(buffer);\n\t\treturn;\n\t}\n\n\tconst uint8_t *packet_type = buffer->data;\n\n\tswitch (*packet_type) {\n\tcase PACKET_DATA:\n\t\tif (!fastd_peer_is_established(peer) || !fastd_peer_address_equal(&peer->local_address, local_addr)) {\n\t\t\tfastd_buffer_free(buffer);\n\n\t\t\tif (!backoff_unknown(remote_addr)) {\n\t\t\t\tpr_debug(\"unexpectedly received payload data from %P[%I]\", peer, remote_addr);\n\t\t\t\tconf.protocol->handshake_init(sock, local_addr, remote_addr, NULL);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\tconf.protocol->handle_recv(peer, buffer);\n\t\tbreak;\n\n\tcase PACKET_HANDSHAKE:\n\t\tfastd_handshake_handle(sock, local_addr, remote_addr, peer, buffer);\n\t\tbreak;\n\n\tdefault:\n\t\tfastd_buffer_free(buffer);\n\t\tpr_debug(\"received packet with invalid type from %P[%I]\", peer, remote_addr);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,5 +25,10 @@\n \n \tcase PACKET_HANDSHAKE:\n \t\tfastd_handshake_handle(sock, local_addr, remote_addr, peer, buffer);\n+\t\tbreak;\n+\n+\tdefault:\n+\t\tfastd_buffer_free(buffer);\n+\t\tpr_debug(\"received packet with invalid type from %P[%I]\", peer, remote_addr);\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tbreak;",
                "",
                "\tdefault:",
                "\t\tfastd_buffer_free(buffer);",
                "\t\tpr_debug(\"received packet with invalid type from %P[%I]\", peer, remote_addr);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27638",
        "func_name": "neocturne/fastd/handle_socket_receive_unknown",
        "description": "receive.c in fastd before v21 allows denial of service (assertion failure) when receiving packets with an invalid type code.",
        "git_url": "https://github.com/neocturne/fastd/commit/737925113363b6130879729cdff9ccc46c33eaea",
        "commit_title": "receive: fix buffer leak when receiving invalid packets",
        "commit_text": " For fastd versions before v20, this was just a memory leak (which could still be used for DoS, as it's remotely triggerable). With the new buffer management of fastd v20, this will trigger an assertion failure instead as soon as the buffer pool is empty.",
        "func_before": "static inline void handle_socket_receive_unknown(\n\tfastd_socket_t *sock, const fastd_peer_address_t *local_addr, const fastd_peer_address_t *remote_addr,\n\tfastd_buffer_t *buffer) {\n\tconst uint8_t *packet_type = buffer->data;\n\n\tswitch (*packet_type) {\n\tcase PACKET_DATA:\n\t\tfastd_buffer_free(buffer);\n\n\t\tif (!backoff_unknown(remote_addr)) {\n\t\t\tpr_debug(\"unexpectedly received payload data from unknown address %I\", remote_addr);\n\t\t\tconf.protocol->handshake_init(sock, local_addr, remote_addr, NULL);\n\t\t}\n\t\tbreak;\n\n\tcase PACKET_HANDSHAKE:\n\t\tfastd_handshake_handle(sock, local_addr, remote_addr, NULL, buffer);\n\t}\n}",
        "func": "static inline void handle_socket_receive_unknown(\n\tfastd_socket_t *sock, const fastd_peer_address_t *local_addr, const fastd_peer_address_t *remote_addr,\n\tfastd_buffer_t *buffer) {\n\tconst uint8_t *packet_type = buffer->data;\n\n\tswitch (*packet_type) {\n\tcase PACKET_DATA:\n\t\tfastd_buffer_free(buffer);\n\n\t\tif (!backoff_unknown(remote_addr)) {\n\t\t\tpr_debug(\"unexpectedly received payload data from unknown address %I\", remote_addr);\n\t\t\tconf.protocol->handshake_init(sock, local_addr, remote_addr, NULL);\n\t\t}\n\t\tbreak;\n\n\tcase PACKET_HANDSHAKE:\n\t\tfastd_handshake_handle(sock, local_addr, remote_addr, NULL, buffer);\n\t\tbreak;\n\n\tdefault:\n\t\tfastd_buffer_free(buffer);\n\t\tpr_debug(\"received packet with invalid type from unknown address %I\", remote_addr);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,5 +15,10 @@\n \n \tcase PACKET_HANDSHAKE:\n \t\tfastd_handshake_handle(sock, local_addr, remote_addr, NULL, buffer);\n+\t\tbreak;\n+\n+\tdefault:\n+\t\tfastd_buffer_free(buffer);\n+\t\tpr_debug(\"received packet with invalid type from unknown address %I\", remote_addr);\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tbreak;",
                "",
                "\tdefault:",
                "\t\tfastd_buffer_free(buffer);",
                "\t\tpr_debug(\"received packet with invalid type from unknown address %I\", remote_addr);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-20286",
        "func_name": "nbdkit/libnbd/nbd_unlocked_opt_info",
        "description": "A flaw was found in libnbd 1.7.3. An assertion failure in nbd_unlocked_opt_go in ilb/opt.c may lead to denial of service.",
        "git_url": "https://gitlab.com/nbdkit/libnbd/-/commit/fb4440de9cc76e9c14bd3ddf3333e78621f40ad0",
        "commit_title": "opt_go: Tolerate unplanned server death",
        "commit_text": " While debugging some experimental nbdkit code that was triggering an assertion failure in nbdkit, I noticed a secondary failure of nbdsh also dying from an assertion:  libnbd: debug: nbdsh: nbd_opt_go: transition: NEWSTYLE.OPT_GO.SEND -> DEAD libnbd: debug: nbdsh: nbd_opt_go: option queued, ignoring state machine failure nbdsh: opt.c:86: nbd_unlocked_opt_go: Assertion `nbd_internal_is_state_negotiating (get_next_state (h))' failed.  Although my trigger was from non-production nbdkit code, libnbd should never die from an assertion failure merely because a server disappeared at the wrong moment during an incomplete reply to NBD_OPT_GO or NBD_OPT_INFO.  If this is assigned a CVE, a followup patch will add mention of it in docs/libnbd-security.pod.  ",
        "func_before": "int\nnbd_unlocked_opt_info (struct nbd_handle *h)\n{\n  int err;\n  nbd_completion_callback c = { .callback = go_complete, .user_data = &err };\n  int r = nbd_unlocked_aio_opt_info (h, &c);\n\n  if (r == -1)\n    return r;\n\n  r = wait_for_option (h);\n  if (r == 0 && err) {\n    assert (nbd_internal_is_state_negotiating (get_next_state (h)));\n    set_error (err, \"server replied with error to opt_info request\");\n    return -1;\n  }\n  return r;\n}",
        "func": "int\nnbd_unlocked_opt_info (struct nbd_handle *h)\n{\n  int err;\n  nbd_completion_callback c = { .callback = go_complete, .user_data = &err };\n  int r = nbd_unlocked_aio_opt_info (h, &c);\n\n  if (r == -1)\n    return r;\n\n  r = wait_for_option (h);\n  if (r == 0 && err) {\n    assert (nbd_internal_is_state_negotiating (get_next_state (h)) ||\n            nbd_internal_is_state_dead (get_next_state (h)));\n    set_error (err, \"server replied with error to opt_info request\");\n    return -1;\n  }\n  return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,8 @@\n \n   r = wait_for_option (h);\n   if (r == 0 && err) {\n-    assert (nbd_internal_is_state_negotiating (get_next_state (h)));\n+    assert (nbd_internal_is_state_negotiating (get_next_state (h)) ||\n+            nbd_internal_is_state_dead (get_next_state (h)));\n     set_error (err, \"server replied with error to opt_info request\");\n     return -1;\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "    assert (nbd_internal_is_state_negotiating (get_next_state (h)));"
            ],
            "added_lines": [
                "    assert (nbd_internal_is_state_negotiating (get_next_state (h)) ||",
                "            nbd_internal_is_state_dead (get_next_state (h)));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-20286",
        "func_name": "nbdkit/libnbd/nbd_unlocked_opt_go",
        "description": "A flaw was found in libnbd 1.7.3. An assertion failure in nbd_unlocked_opt_go in ilb/opt.c may lead to denial of service.",
        "git_url": "https://gitlab.com/nbdkit/libnbd/-/commit/fb4440de9cc76e9c14bd3ddf3333e78621f40ad0",
        "commit_title": "opt_go: Tolerate unplanned server death",
        "commit_text": " While debugging some experimental nbdkit code that was triggering an assertion failure in nbdkit, I noticed a secondary failure of nbdsh also dying from an assertion:  libnbd: debug: nbdsh: nbd_opt_go: transition: NEWSTYLE.OPT_GO.SEND -> DEAD libnbd: debug: nbdsh: nbd_opt_go: option queued, ignoring state machine failure nbdsh: opt.c:86: nbd_unlocked_opt_go: Assertion `nbd_internal_is_state_negotiating (get_next_state (h))' failed.  Although my trigger was from non-production nbdkit code, libnbd should never die from an assertion failure merely because a server disappeared at the wrong moment during an incomplete reply to NBD_OPT_GO or NBD_OPT_INFO.  If this is assigned a CVE, a followup patch will add mention of it in docs/libnbd-security.pod.  ",
        "func_before": "int\nnbd_unlocked_opt_go (struct nbd_handle *h)\n{\n  int err;\n  nbd_completion_callback c = { .callback = go_complete, .user_data = &err };\n  int r = nbd_unlocked_aio_opt_go (h, &c);\n\n  if (r == -1)\n    return r;\n\n  r = wait_for_option (h);\n  if (r == 0 && err) {\n    assert (nbd_internal_is_state_negotiating (get_next_state (h)));\n    set_error (err, \"server replied with error to opt_go request\");\n    return -1;\n  }\n  if (r == 0)\n    assert (nbd_internal_is_state_ready (get_next_state (h)));\n  return r;\n}",
        "func": "int\nnbd_unlocked_opt_go (struct nbd_handle *h)\n{\n  int err;\n  nbd_completion_callback c = { .callback = go_complete, .user_data = &err };\n  int r = nbd_unlocked_aio_opt_go (h, &c);\n\n  if (r == -1)\n    return r;\n\n  r = wait_for_option (h);\n  if (r == 0 && err) {\n    assert (nbd_internal_is_state_negotiating (get_next_state (h)) ||\n            nbd_internal_is_state_dead (get_next_state (h)));\n    set_error (err, \"server replied with error to opt_go request\");\n    return -1;\n  }\n  if (r == 0)\n    assert (nbd_internal_is_state_ready (get_next_state (h)));\n  return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,8 @@\n \n   r = wait_for_option (h);\n   if (r == 0 && err) {\n-    assert (nbd_internal_is_state_negotiating (get_next_state (h)));\n+    assert (nbd_internal_is_state_negotiating (get_next_state (h)) ||\n+            nbd_internal_is_state_dead (get_next_state (h)));\n     set_error (err, \"server replied with error to opt_go request\");\n     return -1;\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "    assert (nbd_internal_is_state_negotiating (get_next_state (h)));"
            ],
            "added_lines": [
                "    assert (nbd_internal_is_state_negotiating (get_next_state (h)) ||",
                "            nbd_internal_is_state_dead (get_next_state (h)));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-24029",
        "func_name": "facebook/mvfst/updateHandshakeState",
        "description": "A packet of death scenario is possible in mvfst via a specially crafted message during a QUIC session, which causes a crash via a failed assertion. Per QUIC specification, this particular message should be treated as a connection error. This issue affects mvfst versions prior to commit a67083ff4b8dcbb7ee2839da6338032030d712b0 and proxygen versions prior to v2021.03.15.00.",
        "git_url": "https://github.com/facebook/mvfst/commit/a67083ff4b8dcbb7ee2839da6338032030d712b0",
        "commit_title": "Close connection if we derive an extra 1-rtt write cipher",
        "commit_text": " Summary: Fixes CVE-2021-24029  Reviewed By: mjoras, lnicco  Differential Revision: D26613890  fbshipit-source-id: 19bb2be2c731808144e1a074ece313fba11f1945",
        "func_before": "void updateHandshakeState(QuicServerConnectionState& conn) {\n  // Zero RTT read cipher is available after chlo is processed with the\n  // condition that early data attempt is accepted.\n  auto handshakeLayer = conn.serverHandshakeLayer;\n  auto zeroRttReadCipher = handshakeLayer->getZeroRttReadCipher();\n  auto zeroRttHeaderCipher = handshakeLayer->getZeroRttReadHeaderCipher();\n  // One RTT write cipher is available at Fizz layer after chlo is processed.\n  // However, the cipher is only exported to QUIC if early data attempt is\n  // accepted. Otherwise, the cipher will be available after cfin is\n  // processed.\n  auto oneRttWriteCipher = handshakeLayer->getOneRttWriteCipher();\n  // One RTT read cipher is available after cfin is processed.\n  auto oneRttReadCipher = handshakeLayer->getOneRttReadCipher();\n\n  auto oneRttWriteHeaderCipher = handshakeLayer->getOneRttWriteHeaderCipher();\n  auto oneRttReadHeaderCipher = handshakeLayer->getOneRttReadHeaderCipher();\n\n  if (zeroRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedZeroRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 0-rtt read cipher\");\n    conn.readCodec->setZeroRttReadCipher(std::move(zeroRttReadCipher));\n  }\n  if (zeroRttHeaderCipher) {\n    conn.readCodec->setZeroRttHeaderCipher(std::move(zeroRttHeaderCipher));\n  }\n  if (oneRttWriteHeaderCipher) {\n    conn.oneRttWriteHeaderCipher = std::move(oneRttWriteHeaderCipher);\n  }\n  if (oneRttReadHeaderCipher) {\n    conn.readCodec->setOneRttHeaderCipher(std::move(oneRttReadHeaderCipher));\n  }\n\n  if (oneRttWriteCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n    CHECK(!conn.oneRttWriteCipher.get());\n    conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n\n    updatePacingOnKeyEstablished(conn);\n\n    // We negotiate the transport parameters whenever we have the 1-RTT write\n    // keys available.\n    auto clientParams = handshakeLayer->getClientTransportParams();\n    if (!clientParams) {\n      throw QuicTransportException(\n          \"No client transport params\",\n          TransportErrorCode::TRANSPORT_PARAMETER_ERROR);\n    }\n    processClientInitialParams(conn, std::move(*clientParams));\n  }\n  if (oneRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt read cipher\");\n    // Clear limit because CFIN is received at this point\n    conn.writableBytesLimit = folly::none;\n    conn.readCodec->setOneRttReadCipher(std::move(oneRttReadCipher));\n  }\n  auto handshakeReadCipher = handshakeLayer->getHandshakeReadCipher();\n  auto handshakeReadHeaderCipher =\n      handshakeLayer->getHandshakeReadHeaderCipher();\n  if (handshakeReadCipher) {\n    CHECK(handshakeReadHeaderCipher);\n    conn.readCodec->setHandshakeReadCipher(std::move(handshakeReadCipher));\n    conn.readCodec->setHandshakeHeaderCipher(\n        std::move(handshakeReadHeaderCipher));\n  }\n  if (handshakeLayer->isHandshakeDone()) {\n    CHECK(conn.oneRttWriteCipher);\n    if (conn.version != QuicVersion::MVFST_D24 && !conn.sentHandshakeDone) {\n      sendSimpleFrame(conn, HandshakeDoneFrame());\n      conn.sentHandshakeDone = true;\n    }\n  }\n}",
        "func": "void updateHandshakeState(QuicServerConnectionState& conn) {\n  // Zero RTT read cipher is available after chlo is processed with the\n  // condition that early data attempt is accepted.\n  auto handshakeLayer = conn.serverHandshakeLayer;\n  auto zeroRttReadCipher = handshakeLayer->getZeroRttReadCipher();\n  auto zeroRttHeaderCipher = handshakeLayer->getZeroRttReadHeaderCipher();\n  // One RTT write cipher is available at Fizz layer after chlo is processed.\n  // However, the cipher is only exported to QUIC if early data attempt is\n  // accepted. Otherwise, the cipher will be available after cfin is\n  // processed.\n  auto oneRttWriteCipher = handshakeLayer->getOneRttWriteCipher();\n  // One RTT read cipher is available after cfin is processed.\n  auto oneRttReadCipher = handshakeLayer->getOneRttReadCipher();\n\n  auto oneRttWriteHeaderCipher = handshakeLayer->getOneRttWriteHeaderCipher();\n  auto oneRttReadHeaderCipher = handshakeLayer->getOneRttReadHeaderCipher();\n\n  if (zeroRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedZeroRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 0-rtt read cipher\");\n    conn.readCodec->setZeroRttReadCipher(std::move(zeroRttReadCipher));\n  }\n  if (zeroRttHeaderCipher) {\n    conn.readCodec->setZeroRttHeaderCipher(std::move(zeroRttHeaderCipher));\n  }\n  if (oneRttWriteHeaderCipher) {\n    conn.oneRttWriteHeaderCipher = std::move(oneRttWriteHeaderCipher);\n  }\n  if (oneRttReadHeaderCipher) {\n    conn.readCodec->setOneRttHeaderCipher(std::move(oneRttReadHeaderCipher));\n  }\n\n  if (oneRttWriteCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n    if (conn.oneRttWriteCipher) {\n      throw QuicTransportException(\n          \"Duplicate 1-rtt write cipher\", TransportErrorCode::CRYPTO_ERROR);\n    }\n    conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n\n    updatePacingOnKeyEstablished(conn);\n\n    // We negotiate the transport parameters whenever we have the 1-RTT write\n    // keys available.\n    auto clientParams = handshakeLayer->getClientTransportParams();\n    if (!clientParams) {\n      throw QuicTransportException(\n          \"No client transport params\",\n          TransportErrorCode::TRANSPORT_PARAMETER_ERROR);\n    }\n    processClientInitialParams(conn, std::move(*clientParams));\n  }\n  if (oneRttReadCipher) {\n    if (conn.qLogger) {\n      conn.qLogger->addTransportStateUpdate(kDerivedOneRttReadCipher);\n    }\n    QUIC_TRACE(fst_trace, conn, \"derived 1-rtt read cipher\");\n    // Clear limit because CFIN is received at this point\n    conn.writableBytesLimit = folly::none;\n    conn.readCodec->setOneRttReadCipher(std::move(oneRttReadCipher));\n  }\n  auto handshakeReadCipher = handshakeLayer->getHandshakeReadCipher();\n  auto handshakeReadHeaderCipher =\n      handshakeLayer->getHandshakeReadHeaderCipher();\n  if (handshakeReadCipher) {\n    CHECK(handshakeReadHeaderCipher);\n    conn.readCodec->setHandshakeReadCipher(std::move(handshakeReadCipher));\n    conn.readCodec->setHandshakeHeaderCipher(\n        std::move(handshakeReadHeaderCipher));\n  }\n  if (handshakeLayer->isHandshakeDone()) {\n    CHECK(conn.oneRttWriteCipher);\n    if (conn.version != QuicVersion::MVFST_D24 && !conn.sentHandshakeDone) {\n      sendSimpleFrame(conn, HandshakeDoneFrame());\n      conn.sentHandshakeDone = true;\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,7 +37,10 @@\n       conn.qLogger->addTransportStateUpdate(kDerivedOneRttWriteCipher);\n     }\n     QUIC_TRACE(fst_trace, conn, \"derived 1-rtt write cipher\");\n-    CHECK(!conn.oneRttWriteCipher.get());\n+    if (conn.oneRttWriteCipher) {\n+      throw QuicTransportException(\n+          \"Duplicate 1-rtt write cipher\", TransportErrorCode::CRYPTO_ERROR);\n+    }\n     conn.oneRttWriteCipher = std::move(oneRttWriteCipher);\n \n     updatePacingOnKeyEstablished(conn);",
        "diff_line_info": {
            "deleted_lines": [
                "    CHECK(!conn.oneRttWriteCipher.get());"
            ],
            "added_lines": [
                "    if (conn.oneRttWriteCipher) {",
                "      throw QuicTransportException(",
                "          \"Duplicate 1-rtt write cipher\", TransportErrorCode::CRYPTO_ERROR);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-39949",
        "func_name": "eProsima/Fast-DDS/MessageReceiver::proc_Submsg_Heartbeat",
        "description": "eprosima Fast DDS is a C++ implementation of the Data Distribution Service standard of the Object Management Group. Prior to versions 2.9.1 and 2.6.5, improper validation of sequence numbers may lead to remotely reachable assertion failure. This can remotely crash any Fast-DDS process. Versions 2.9.1 and 2.6.5 contain a patch for this issue.",
        "git_url": "https://github.com/eProsima/Fast-DDS/commit/4382b5dfd02a42ba5d1a25038c78079c24a05638",
        "commit_title": "fix typo",
        "commit_text": "",
        "func_before": "bool MessageReceiver::proc_Submsg_Heartbeat(\n        CDRMessage_t* msg,\n        SubmessageHeader_t* smh) const\n{\n    eprosima::shared_lock<eprosima::shared_mutex> guard(mtx_);\n\n    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n    bool finalFlag = (smh->flags & BIT(1)) != 0;\n    bool livelinessFlag = (smh->flags & BIT(2)) != 0;\n    //Assign message endianness\n    if (endiannessFlag)\n    {\n        msg->msg_endian = LITTLEEND;\n    }\n    else\n    {\n        msg->msg_endian = BIGEND;\n    }\n\n    GUID_t readerGUID;\n    GUID_t writerGUID;\n    readerGUID.guidPrefix = dest_guid_prefix_;\n    CDRMessage::readEntityId(msg, &readerGUID.entityId);\n    writerGUID.guidPrefix = source_guid_prefix_;\n    CDRMessage::readEntityId(msg, &writerGUID.entityId);\n    SequenceNumber_t firstSN;\n    SequenceNumber_t lastSN;\n    CDRMessage::readSequenceNumber(msg, &firstSN);\n    CDRMessage::readSequenceNumber(msg, &lastSN);\n\n    SequenceNumber_t zeroSN;\n    if (fisrtSN <= zeroSN)\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \" <= 0), ignoring\");\n        return false;\n    }\n    if (lastSN < firstSN && lastSN != firstSN - 1)\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \") - (\" <<\n                lastSN << \"), ignoring\");\n        return false;\n    }\n    uint32_t HBCount;\n    if (!CDRMessage::readUInt32(msg, &HBCount))\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Unable to read heartbeat count from heartbeat message\");\n        return false;\n    }\n\n    //Look for the correct reader and writers:\n    findAllReaders(readerGUID.entityId,\n            [&writerGUID, &HBCount, &firstSN, &lastSN, finalFlag, livelinessFlag](RTPSReader* reader)\n            {\n                reader->processHeartbeatMsg(writerGUID, HBCount, firstSN, lastSN, finalFlag, livelinessFlag);\n            });\n\n    return true;\n}",
        "func": "bool MessageReceiver::proc_Submsg_Heartbeat(\n        CDRMessage_t* msg,\n        SubmessageHeader_t* smh) const\n{\n    eprosima::shared_lock<eprosima::shared_mutex> guard(mtx_);\n\n    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n    bool finalFlag = (smh->flags & BIT(1)) != 0;\n    bool livelinessFlag = (smh->flags & BIT(2)) != 0;\n    //Assign message endianness\n    if (endiannessFlag)\n    {\n        msg->msg_endian = LITTLEEND;\n    }\n    else\n    {\n        msg->msg_endian = BIGEND;\n    }\n\n    GUID_t readerGUID;\n    GUID_t writerGUID;\n    readerGUID.guidPrefix = dest_guid_prefix_;\n    CDRMessage::readEntityId(msg, &readerGUID.entityId);\n    writerGUID.guidPrefix = source_guid_prefix_;\n    CDRMessage::readEntityId(msg, &writerGUID.entityId);\n    SequenceNumber_t firstSN;\n    SequenceNumber_t lastSN;\n    CDRMessage::readSequenceNumber(msg, &firstSN);\n    CDRMessage::readSequenceNumber(msg, &lastSN);\n\n    SequenceNumber_t zeroSN;\n    if (firstSN <= zeroSN)\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \" <= 0), ignoring\");\n        return false;\n    }\n    if (lastSN < firstSN && lastSN != firstSN - 1)\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \") - (\" <<\n                lastSN << \"), ignoring\");\n        return false;\n    }\n    uint32_t HBCount;\n    if (!CDRMessage::readUInt32(msg, &HBCount))\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Unable to read heartbeat count from heartbeat message\");\n        return false;\n    }\n\n    //Look for the correct reader and writers:\n    findAllReaders(readerGUID.entityId,\n            [&writerGUID, &HBCount, &firstSN, &lastSN, finalFlag, livelinessFlag](RTPSReader* reader)\n            {\n                reader->processHeartbeatMsg(writerGUID, HBCount, firstSN, lastSN, finalFlag, livelinessFlag);\n            });\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,7 +29,7 @@\n     CDRMessage::readSequenceNumber(msg, &lastSN);\n \n     SequenceNumber_t zeroSN;\n-    if (fisrtSN <= zeroSN)\n+    if (firstSN <= zeroSN)\n     {\n         EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \" <= 0), ignoring\");\n         return false;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (fisrtSN <= zeroSN)"
            ],
            "added_lines": [
                "    if (firstSN <= zeroSN)"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-39949",
        "func_name": "eProsima/Fast-DDS/MessageReceiver::proc_Submsg_Heartbeat",
        "description": "eprosima Fast DDS is a C++ implementation of the Data Distribution Service standard of the Object Management Group. Prior to versions 2.9.1 and 2.6.5, improper validation of sequence numbers may lead to remotely reachable assertion failure. This can remotely crash any Fast-DDS process. Versions 2.9.1 and 2.6.5 contain a patch for this issue.",
        "git_url": "https://github.com/eProsima/Fast-DDS/commit/60c15edf9e5ddf813d3ea25fa3ef2ccdae4e11a6",
        "commit_title": "Implement a validity check for firstSN",
        "commit_text": " Following 8.3.8.6.3 of DDS-RTPS 2.5. This fixes issue #3236. ",
        "func_before": "bool MessageReceiver::proc_Submsg_Heartbeat(\n        CDRMessage_t* msg,\n        SubmessageHeader_t* smh) const\n{\n    eprosima::shared_lock<eprosima::shared_mutex> guard(mtx_);\n\n    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n    bool finalFlag = (smh->flags & BIT(1)) != 0;\n    bool livelinessFlag = (smh->flags & BIT(2)) != 0;\n    //Assign message endianness\n    if (endiannessFlag)\n    {\n        msg->msg_endian = LITTLEEND;\n    }\n    else\n    {\n        msg->msg_endian = BIGEND;\n    }\n\n    GUID_t readerGUID;\n    GUID_t writerGUID;\n    readerGUID.guidPrefix = dest_guid_prefix_;\n    CDRMessage::readEntityId(msg, &readerGUID.entityId);\n    writerGUID.guidPrefix = source_guid_prefix_;\n    CDRMessage::readEntityId(msg, &writerGUID.entityId);\n    SequenceNumber_t firstSN;\n    SequenceNumber_t lastSN;\n    CDRMessage::readSequenceNumber(msg, &firstSN);\n    CDRMessage::readSequenceNumber(msg, &lastSN);\n    if (lastSN < firstSN && lastSN != firstSN - 1)\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \") - (\" <<\n                lastSN << \"), ignoring\");\n        return false;\n    }\n    uint32_t HBCount;\n    if (!CDRMessage::readUInt32(msg, &HBCount))\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Unable to read heartbeat count from heartbeat message\");\n        return false;\n    }\n\n    //Look for the correct reader and writers:\n    findAllReaders(readerGUID.entityId,\n            [&writerGUID, &HBCount, &firstSN, &lastSN, finalFlag, livelinessFlag](RTPSReader* reader)\n            {\n                reader->processHeartbeatMsg(writerGUID, HBCount, firstSN, lastSN, finalFlag, livelinessFlag);\n            });\n\n    return true;\n}",
        "func": "bool MessageReceiver::proc_Submsg_Heartbeat(\n        CDRMessage_t* msg,\n        SubmessageHeader_t* smh) const\n{\n    eprosima::shared_lock<eprosima::shared_mutex> guard(mtx_);\n\n    bool endiannessFlag = (smh->flags & BIT(0)) != 0;\n    bool finalFlag = (smh->flags & BIT(1)) != 0;\n    bool livelinessFlag = (smh->flags & BIT(2)) != 0;\n    //Assign message endianness\n    if (endiannessFlag)\n    {\n        msg->msg_endian = LITTLEEND;\n    }\n    else\n    {\n        msg->msg_endian = BIGEND;\n    }\n\n    GUID_t readerGUID;\n    GUID_t writerGUID;\n    readerGUID.guidPrefix = dest_guid_prefix_;\n    CDRMessage::readEntityId(msg, &readerGUID.entityId);\n    writerGUID.guidPrefix = source_guid_prefix_;\n    CDRMessage::readEntityId(msg, &writerGUID.entityId);\n    SequenceNumber_t firstSN;\n    SequenceNumber_t lastSN;\n    CDRMessage::readSequenceNumber(msg, &firstSN);\n    CDRMessage::readSequenceNumber(msg, &lastSN);\n\n    SequenceNumber_t zeroSN;\n    if (fisrtSN <= zeroSN)\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \" <= 0), ignoring\");\n        return false;\n    }\n    if (lastSN < firstSN && lastSN != firstSN - 1)\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \") - (\" <<\n                lastSN << \"), ignoring\");\n        return false;\n    }\n    uint32_t HBCount;\n    if (!CDRMessage::readUInt32(msg, &HBCount))\n    {\n        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Unable to read heartbeat count from heartbeat message\");\n        return false;\n    }\n\n    //Look for the correct reader and writers:\n    findAllReaders(readerGUID.entityId,\n            [&writerGUID, &HBCount, &firstSN, &lastSN, finalFlag, livelinessFlag](RTPSReader* reader)\n            {\n                reader->processHeartbeatMsg(writerGUID, HBCount, firstSN, lastSN, finalFlag, livelinessFlag);\n            });\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,6 +27,13 @@\n     SequenceNumber_t lastSN;\n     CDRMessage::readSequenceNumber(msg, &firstSN);\n     CDRMessage::readSequenceNumber(msg, &lastSN);\n+\n+    SequenceNumber_t zeroSN;\n+    if (fisrtSN <= zeroSN)\n+    {\n+        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \" <= 0), ignoring\");\n+        return false;\n+    }\n     if (lastSN < firstSN && lastSN != firstSN - 1)\n     {\n         EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \") - (\" <<",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    SequenceNumber_t zeroSN;",
                "    if (fisrtSN <= zeroSN)",
                "    {",
                "        EPROSIMA_LOG_WARNING(RTPS_MSG_IN, IDSTRING \"Invalid Heartbeat received (\" << firstSN << \" <= 0), ignoring\");",
                "        return false;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-37051",
        "func_name": "poppler/main",
        "description": "An issue was discovered in Poppler 22.07.0. There is a reachable abort which leads to denial of service because the main function in pdfunite.cc lacks a stream check before saving an embedded file.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=4631115647c1e4f0482ffe0491c2f38d2231337b",
        "commit_title": "Issue #1276",
        "commit_text": "",
        "func_before": "int main(int argc, char *argv[])\n///////////////////////////////////////////////////////////////////////////\n// Merge PDF files given by arguments 1 to argc-2 and write the result\n// to the file specified by argument argc-1.\n///////////////////////////////////////////////////////////////////////////\n{\n    int objectsCount = 0;\n    unsigned int numOffset = 0;\n    std::vector<Object> pages;\n    std::vector<unsigned int> offsets;\n    XRef *yRef, *countRef;\n    FILE *f;\n    OutStream *outStr;\n    int i;\n    int j, rootNum;\n    std::vector<PDFDoc *> docs;\n    int majorVersion = 0;\n    int minorVersion = 0;\n    char *fileName = argv[argc - 1];\n\n    const bool ok = parseArgs(argDesc, &argc, argv);\n    if (!ok || argc < 3 || printVersion || printHelp) {\n        fprintf(stderr, \"pdfunite version %s\\n\", PACKAGE_VERSION);\n        fprintf(stderr, \"%s\\n\", popplerCopyright);\n        fprintf(stderr, \"%s\\n\", xpdfCopyright);\n        if (!printVersion) {\n            printUsage(\"pdfunite\", \"<PDF-sourcefile-1>..<PDF-sourcefile-n> <PDF-destfile>\", argDesc);\n        }\n        if (printVersion || printHelp) {\n            return 0;\n        }\n        return 99;\n    }\n    globalParams = std::make_unique<GlobalParams>();\n\n    for (i = 1; i < argc - 1; i++) {\n        PDFDoc *doc = new PDFDoc(std::make_unique<GooString>(argv[i]));\n        if (doc->isOk() && !doc->isEncrypted() && doc->getXRef()->getCatalog().isDict()) {\n            docs.push_back(doc);\n            if (doc->getPDFMajorVersion() > majorVersion) {\n                majorVersion = doc->getPDFMajorVersion();\n                minorVersion = doc->getPDFMinorVersion();\n            } else if (doc->getPDFMajorVersion() == majorVersion) {\n                if (doc->getPDFMinorVersion() > minorVersion) {\n                    minorVersion = doc->getPDFMinorVersion();\n                }\n            }\n        } else if (doc->isOk()) {\n            if (doc->isEncrypted()) {\n                error(errUnimplemented, -1, \"Could not merge encrypted files ('{0:s}')\", argv[i]);\n                return -1;\n            } else if (!doc->getXRef()->getCatalog().isDict()) {\n                error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary ('{0:s}')\", argv[i]);\n                return -1;\n            }\n        } else {\n            error(errSyntaxError, -1, \"Could not merge damaged documents ('{0:s}')\", argv[i]);\n            return -1;\n        }\n    }\n\n    if (!(f = fopen(fileName, \"wb\"))) {\n        error(errIO, -1, \"Could not open file '{0:s}'\", fileName);\n        return -1;\n    }\n    outStr = new FileOutStream(f, 0);\n\n    yRef = new XRef();\n    countRef = new XRef();\n    yRef->add(0, 65535, 0, false);\n    PDFDoc::writeHeader(outStr, majorVersion, minorVersion);\n\n    // handle OutputIntents, AcroForm, OCProperties & Names\n    Object intents;\n    Object names;\n    Object afObj;\n    Object ocObj;\n    if (docs.size() >= 1) {\n        Object catObj = docs[0]->getXRef()->getCatalog();\n        Dict *catDict = catObj.getDict();\n        intents = catDict->lookup(\"OutputIntents\");\n        afObj = catDict->lookupNF(\"AcroForm\").copy();\n        Ref *refPage = docs[0]->getCatalog()->getPageRef(1);\n        if (!afObj.isNull() && refPage) {\n            docs[0]->markAcroForm(&afObj, yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        ocObj = catDict->lookupNF(\"OCProperties\").copy();\n        if (!ocObj.isNull() && ocObj.isDict() && refPage) {\n            docs[0]->markPageObjects(ocObj.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        names = catDict->lookup(\"Names\");\n        if (!names.isNull() && names.isDict() && refPage) {\n            docs[0]->markPageObjects(names.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (i = 1; i < (int)docs.size(); i++) {\n                Object pagecatObj = docs[i]->getXRef()->getCatalog();\n                Dict *pagecatDict = pagecatObj.getDict();\n                Object pageintents = pagecatDict->lookup(\"OutputIntents\");\n                if (pageintents.isArray() && pageintents.arrayGetLength() > 0) {\n                    for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                        Object intent = intents.arrayGet(j, 0);\n                        if (intent.isDict()) {\n                            Object idf = intent.dictLookup(\"OutputConditionIdentifier\");\n                            if (idf.isString()) {\n                                const GooString *gidf = idf.getString();\n                                bool removeIntent = true;\n                                for (int k = 0; k < pageintents.arrayGetLength(); k++) {\n                                    Object pgintent = pageintents.arrayGet(k, 0);\n                                    if (pgintent.isDict()) {\n                                        Object pgidf = pgintent.dictLookup(\"OutputConditionIdentifier\");\n                                        if (pgidf.isString()) {\n                                            const GooString *gpgidf = pgidf.getString();\n                                            if (gpgidf->cmp(gidf) == 0) {\n                                                removeIntent = false;\n                                                break;\n                                            }\n                                        }\n                                    }\n                                }\n                                if (removeIntent) {\n                                    intents.arrayRemove(j);\n                                    error(errSyntaxWarning, -1, \"Output intent {0:s} missing in pdf {1:s}, removed\", gidf->c_str(), docs[i]->getFileName()->c_str());\n                                }\n                            } else {\n                                intents.arrayRemove(j);\n                                error(errSyntaxWarning, -1, \"Invalid output intent dict, missing required OutputConditionIdentifier\");\n                            }\n                        } else {\n                            intents.arrayRemove(j);\n                        }\n                    }\n                } else {\n                    error(errSyntaxWarning, -1, \"Output intents differs, remove them all\");\n                    break;\n                }\n            }\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                Object intent = intents.arrayGet(j, 0);\n                if (intent.isDict()) {\n                    docs[0]->markPageObjects(intent.getDict(), yRef, countRef, numOffset, 0, 0);\n                } else {\n                    intents.arrayRemove(j);\n                }\n            }\n        }\n    }\n\n    for (i = 0; i < (int)docs.size(); i++) {\n        for (j = 1; j <= docs[i]->getNumPages(); j++) {\n            if (!docs[i]->getCatalog()->getPage(j)) {\n                continue;\n            }\n\n            const PDFRectangle *cropBox = nullptr;\n            if (docs[i]->getCatalog()->getPage(j)->isCropped()) {\n                cropBox = docs[i]->getCatalog()->getPage(j)->getCropBox();\n            }\n            docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox);\n            Ref *refPage = docs[i]->getCatalog()->getPageRef(j);\n            Object page = docs[i]->getXRef()->fetch(*refPage);\n            Dict *pageDict = page.getDict();\n            Object *resDict = docs[i]->getCatalog()->getPage(j)->getResourceDictObject();\n            if (resDict->isDict()) {\n                pageDict->set(\"Resources\", resDict->copy());\n            }\n            pages.push_back(std::move(page));\n            offsets.push_back(numOffset);\n            docs[i]->markPageObjects(pageDict, yRef, countRef, numOffset, refPage->num, refPage->num);\n            Object annotsObj = pageDict->lookupNF(\"Annots\").copy();\n            if (!annotsObj.isNull()) {\n                docs[i]->markAnnotations(&annotsObj, yRef, countRef, numOffset, refPage->num, refPage->num);\n            }\n        }\n        Object pageCatObj = docs[i]->getXRef()->getCatalog();\n        Dict *pageCatDict = pageCatObj.getDict();\n        Object pageNames = pageCatDict->lookup(\"Names\");\n        if (!pageNames.isNull() && pageNames.isDict()) {\n            if (!names.isDict()) {\n                names = Object(new Dict(yRef));\n            }\n            doMergeNameDict(docs[i], yRef, countRef, 0, 0, names.getDict(), pageNames.getDict(), numOffset);\n        }\n        Object pageForm = pageCatDict->lookup(\"AcroForm\");\n        if (i > 0 && !pageForm.isNull() && pageForm.isDict()) {\n            if (afObj.isNull()) {\n                afObj = pageCatDict->lookupNF(\"AcroForm\").copy();\n            } else if (afObj.isDict()) {\n                doMergeFormDict(afObj.getDict(), pageForm.getDict(), numOffset);\n            }\n        }\n        objectsCount += docs[i]->writePageObjects(outStr, yRef, numOffset, true);\n        numOffset = yRef->getNumObjects() + 1;\n    }\n\n    rootNum = yRef->getNumObjects() + 1;\n    yRef->add(rootNum, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum);\n    outStr->printf(\"<< /Type /Catalog /Pages %d 0 R\", rootNum + 1);\n    // insert OutputIntents\n    if (intents.isArray() && intents.arrayGetLength() > 0) {\n        outStr->printf(\" /OutputIntents [\");\n        for (j = 0; j < intents.arrayGetLength(); j++) {\n            Object intent = intents.arrayGet(j, 0);\n            if (intent.isDict()) {\n                PDFDoc::writeObject(&intent, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\"]\");\n    }\n    // insert AcroForm\n    if (!afObj.isNull()) {\n        outStr->printf(\" /AcroForm \");\n        PDFDoc::writeObject(&afObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert OCProperties\n    if (!ocObj.isNull() && ocObj.isDict()) {\n        outStr->printf(\" /OCProperties \");\n        PDFDoc::writeObject(&ocObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert Names\n    if (!names.isNull() && names.isDict()) {\n        outStr->printf(\" /Names \");\n        PDFDoc::writeObject(&names, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    outStr->printf(\">>\\nendobj\\n\");\n    objectsCount++;\n\n    yRef->add(rootNum + 1, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 1);\n    outStr->printf(\"<< /Type /Pages /Kids [\");\n    for (j = 0; j < (int)pages.size(); j++) {\n        outStr->printf(\" %d 0 R\", rootNum + j + 2);\n    }\n    outStr->printf(\" ] /Count %zd >>\\nendobj\\n\", pages.size());\n    objectsCount++;\n\n    for (i = 0; i < (int)pages.size(); i++) {\n        yRef->add(rootNum + i + 2, 0, outStr->getPos(), true);\n        outStr->printf(\"%d 0 obj\\n\", rootNum + i + 2);\n        outStr->printf(\"<< \");\n        Dict *pageDict = pages[i].getDict();\n        for (j = 0; j < pageDict->getLength(); j++) {\n            if (j > 0) {\n                outStr->printf(\" \");\n            }\n            const char *key = pageDict->getKey(j);\n            Object value = pageDict->getValNF(j).copy();\n            if (strcmp(key, \"Parent\") == 0) {\n                outStr->printf(\"/Parent %d 0 R\", rootNum + 1);\n            } else {\n                outStr->printf(\"/%s \", key);\n                PDFDoc::writeObject(&value, outStr, yRef, offsets[i], nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\" >>\\nendobj\\n\");\n        objectsCount++;\n    }\n    Goffset uxrefOffset = outStr->getPos();\n    Ref ref;\n    ref.num = rootNum;\n    ref.gen = 0;\n    Object trailerDict = PDFDoc::createTrailerDict(objectsCount, false, 0, &ref, yRef, fileName, outStr->getPos());\n    PDFDoc::writeXRefTableTrailer(std::move(trailerDict), yRef, true, // write all entries according to ISO 32000-1, 7.5.4 Cross-Reference Table: \"For a file that has never been incrementally updated, the cross-reference section shall\n                                                                      // contain only one subsection, whose object numbering begins at 0.\"\n                                  uxrefOffset, outStr, yRef);\n\n    outStr->close();\n    delete outStr;\n    fclose(f);\n    delete yRef;\n    delete countRef;\n    for (i = 0; i < (int)docs.size(); i++) {\n        delete docs[i];\n    }\n    return 0;\n}",
        "func": "int main(int argc, char *argv[])\n///////////////////////////////////////////////////////////////////////////\n// Merge PDF files given by arguments 1 to argc-2 and write the result\n// to the file specified by argument argc-1.\n///////////////////////////////////////////////////////////////////////////\n{\n    int objectsCount = 0;\n    unsigned int numOffset = 0;\n    std::vector<Object> pages;\n    std::vector<unsigned int> offsets;\n    XRef *yRef, *countRef;\n    FILE *f;\n    OutStream *outStr;\n    int i;\n    int j, rootNum;\n    std::vector<PDFDoc *> docs;\n    int majorVersion = 0;\n    int minorVersion = 0;\n    char *fileName = argv[argc - 1];\n\n    const bool ok = parseArgs(argDesc, &argc, argv);\n    if (!ok || argc < 3 || printVersion || printHelp) {\n        fprintf(stderr, \"pdfunite version %s\\n\", PACKAGE_VERSION);\n        fprintf(stderr, \"%s\\n\", popplerCopyright);\n        fprintf(stderr, \"%s\\n\", xpdfCopyright);\n        if (!printVersion) {\n            printUsage(\"pdfunite\", \"<PDF-sourcefile-1>..<PDF-sourcefile-n> <PDF-destfile>\", argDesc);\n        }\n        if (printVersion || printHelp) {\n            return 0;\n        }\n        return 99;\n    }\n    globalParams = std::make_unique<GlobalParams>();\n\n    for (i = 1; i < argc - 1; i++) {\n        PDFDoc *doc = new PDFDoc(std::make_unique<GooString>(argv[i]));\n        if (doc->isOk() && !doc->isEncrypted() && doc->getXRef()->getCatalog().isDict()) {\n            docs.push_back(doc);\n            if (doc->getPDFMajorVersion() > majorVersion) {\n                majorVersion = doc->getPDFMajorVersion();\n                minorVersion = doc->getPDFMinorVersion();\n            } else if (doc->getPDFMajorVersion() == majorVersion) {\n                if (doc->getPDFMinorVersion() > minorVersion) {\n                    minorVersion = doc->getPDFMinorVersion();\n                }\n            }\n        } else if (doc->isOk()) {\n            if (doc->isEncrypted()) {\n                error(errUnimplemented, -1, \"Could not merge encrypted files ('{0:s}')\", argv[i]);\n                return -1;\n            } else if (!doc->getXRef()->getCatalog().isDict()) {\n                error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary ('{0:s}')\", argv[i]);\n                return -1;\n            }\n        } else {\n            error(errSyntaxError, -1, \"Could not merge damaged documents ('{0:s}')\", argv[i]);\n            return -1;\n        }\n    }\n\n    if (!(f = fopen(fileName, \"wb\"))) {\n        error(errIO, -1, \"Could not open file '{0:s}'\", fileName);\n        return -1;\n    }\n    outStr = new FileOutStream(f, 0);\n\n    yRef = new XRef();\n    countRef = new XRef();\n    yRef->add(0, 65535, 0, false);\n    PDFDoc::writeHeader(outStr, majorVersion, minorVersion);\n\n    // handle OutputIntents, AcroForm, OCProperties & Names\n    Object intents;\n    Object names;\n    Object afObj;\n    Object ocObj;\n    if (docs.size() >= 1) {\n        Object catObj = docs[0]->getXRef()->getCatalog();\n        if(!catObj.isDict()){\n            fclose(f);\n            delete yRef;\n            delete countRef;\n            delete outStr;\n            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n            return -1;\n        }\n        Dict *catDict = catObj.getDict();\n        intents = catDict->lookup(\"OutputIntents\");\n        afObj = catDict->lookupNF(\"AcroForm\").copy();\n        Ref *refPage = docs[0]->getCatalog()->getPageRef(1);\n        if (!afObj.isNull() && refPage) {\n            docs[0]->markAcroForm(&afObj, yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        ocObj = catDict->lookupNF(\"OCProperties\").copy();\n        if (!ocObj.isNull() && ocObj.isDict() && refPage) {\n            docs[0]->markPageObjects(ocObj.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        names = catDict->lookup(\"Names\");\n        if (!names.isNull() && names.isDict() && refPage) {\n            docs[0]->markPageObjects(names.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (i = 1; i < (int)docs.size(); i++) {\n                Object pagecatObj = docs[i]->getXRef()->getCatalog();\n                Dict *pagecatDict = pagecatObj.getDict();\n                Object pageintents = pagecatDict->lookup(\"OutputIntents\");\n                if (pageintents.isArray() && pageintents.arrayGetLength() > 0) {\n                    for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                        Object intent = intents.arrayGet(j, 0);\n                        if (intent.isDict()) {\n                            Object idf = intent.dictLookup(\"OutputConditionIdentifier\");\n                            if (idf.isString()) {\n                                const GooString *gidf = idf.getString();\n                                bool removeIntent = true;\n                                for (int k = 0; k < pageintents.arrayGetLength(); k++) {\n                                    Object pgintent = pageintents.arrayGet(k, 0);\n                                    if (pgintent.isDict()) {\n                                        Object pgidf = pgintent.dictLookup(\"OutputConditionIdentifier\");\n                                        if (pgidf.isString()) {\n                                            const GooString *gpgidf = pgidf.getString();\n                                            if (gpgidf->cmp(gidf) == 0) {\n                                                removeIntent = false;\n                                                break;\n                                            }\n                                        }\n                                    }\n                                }\n                                if (removeIntent) {\n                                    intents.arrayRemove(j);\n                                    error(errSyntaxWarning, -1, \"Output intent {0:s} missing in pdf {1:s}, removed\", gidf->c_str(), docs[i]->getFileName()->c_str());\n                                }\n                            } else {\n                                intents.arrayRemove(j);\n                                error(errSyntaxWarning, -1, \"Invalid output intent dict, missing required OutputConditionIdentifier\");\n                            }\n                        } else {\n                            intents.arrayRemove(j);\n                        }\n                    }\n                } else {\n                    error(errSyntaxWarning, -1, \"Output intents differs, remove them all\");\n                    break;\n                }\n            }\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                Object intent = intents.arrayGet(j, 0);\n                if (intent.isDict()) {\n                    docs[0]->markPageObjects(intent.getDict(), yRef, countRef, numOffset, 0, 0);\n                } else {\n                    intents.arrayRemove(j);\n                }\n            }\n        }\n    }\n\n    for (i = 0; i < (int)docs.size(); i++) {\n        for (j = 1; j <= docs[i]->getNumPages(); j++) {\n            if (!docs[i]->getCatalog()->getPage(j)) {\n                continue;\n            }\n\n            const PDFRectangle *cropBox = nullptr;\n            if (docs[i]->getCatalog()->getPage(j)->isCropped()) {\n                cropBox = docs[i]->getCatalog()->getPage(j)->getCropBox();\n            }\n            docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox);\n            Ref *refPage = docs[i]->getCatalog()->getPageRef(j);\n            Object page = docs[i]->getXRef()->fetch(*refPage);\n            Dict *pageDict = page.getDict();\n            Object *resDict = docs[i]->getCatalog()->getPage(j)->getResourceDictObject();\n            if (resDict->isDict()) {\n                pageDict->set(\"Resources\", resDict->copy());\n            }\n            pages.push_back(std::move(page));\n            offsets.push_back(numOffset);\n            docs[i]->markPageObjects(pageDict, yRef, countRef, numOffset, refPage->num, refPage->num);\n            Object annotsObj = pageDict->lookupNF(\"Annots\").copy();\n            if (!annotsObj.isNull()) {\n                docs[i]->markAnnotations(&annotsObj, yRef, countRef, numOffset, refPage->num, refPage->num);\n            }\n        }\n        Object pageCatObj = docs[i]->getXRef()->getCatalog();\n        if(!pageCatObj.isDict()){\n            fclose(f);\n            delete yRef;\n            delete countRef;\n            delete outStr;\n            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n            return -1;\n        }\n        Dict *pageCatDict = pageCatObj.getDict();\n        Object pageNames = pageCatDict->lookup(\"Names\");\n        if (!pageNames.isNull() && pageNames.isDict()) {\n            if (!names.isDict()) {\n                names = Object(new Dict(yRef));\n            }\n            doMergeNameDict(docs[i], yRef, countRef, 0, 0, names.getDict(), pageNames.getDict(), numOffset);\n        }\n        Object pageForm = pageCatDict->lookup(\"AcroForm\");\n        if (i > 0 && !pageForm.isNull() && pageForm.isDict()) {\n            if (afObj.isNull()) {\n                afObj = pageCatDict->lookupNF(\"AcroForm\").copy();\n            } else if (afObj.isDict()) {\n                doMergeFormDict(afObj.getDict(), pageForm.getDict(), numOffset);\n            }\n        }\n        objectsCount += docs[i]->writePageObjects(outStr, yRef, numOffset, true);\n        numOffset = yRef->getNumObjects() + 1;\n    }\n\n    rootNum = yRef->getNumObjects() + 1;\n    yRef->add(rootNum, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum);\n    outStr->printf(\"<< /Type /Catalog /Pages %d 0 R\", rootNum + 1);\n    // insert OutputIntents\n    if (intents.isArray() && intents.arrayGetLength() > 0) {\n        outStr->printf(\" /OutputIntents [\");\n        for (j = 0; j < intents.arrayGetLength(); j++) {\n            Object intent = intents.arrayGet(j, 0);\n            if (intent.isDict()) {\n                PDFDoc::writeObject(&intent, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\"]\");\n    }\n    // insert AcroForm\n    if (!afObj.isNull()) {\n        outStr->printf(\" /AcroForm \");\n        PDFDoc::writeObject(&afObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert OCProperties\n    if (!ocObj.isNull() && ocObj.isDict()) {\n        outStr->printf(\" /OCProperties \");\n        PDFDoc::writeObject(&ocObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert Names\n    if (!names.isNull() && names.isDict()) {\n        outStr->printf(\" /Names \");\n        PDFDoc::writeObject(&names, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    outStr->printf(\">>\\nendobj\\n\");\n    objectsCount++;\n\n    yRef->add(rootNum + 1, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 1);\n    outStr->printf(\"<< /Type /Pages /Kids [\");\n    for (j = 0; j < (int)pages.size(); j++) {\n        outStr->printf(\" %d 0 R\", rootNum + j + 2);\n    }\n    outStr->printf(\" ] /Count %zd >>\\nendobj\\n\", pages.size());\n    objectsCount++;\n\n    for (i = 0; i < (int)pages.size(); i++) {\n        yRef->add(rootNum + i + 2, 0, outStr->getPos(), true);\n        outStr->printf(\"%d 0 obj\\n\", rootNum + i + 2);\n        outStr->printf(\"<< \");\n        Dict *pageDict = pages[i].getDict();\n        for (j = 0; j < pageDict->getLength(); j++) {\n            if (j > 0) {\n                outStr->printf(\" \");\n            }\n            const char *key = pageDict->getKey(j);\n            Object value = pageDict->getValNF(j).copy();\n            if (strcmp(key, \"Parent\") == 0) {\n                outStr->printf(\"/Parent %d 0 R\", rootNum + 1);\n            } else {\n                outStr->printf(\"/%s \", key);\n                PDFDoc::writeObject(&value, outStr, yRef, offsets[i], nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\" >>\\nendobj\\n\");\n        objectsCount++;\n    }\n    Goffset uxrefOffset = outStr->getPos();\n    Ref ref;\n    ref.num = rootNum;\n    ref.gen = 0;\n    Object trailerDict = PDFDoc::createTrailerDict(objectsCount, false, 0, &ref, yRef, fileName, outStr->getPos());\n    PDFDoc::writeXRefTableTrailer(std::move(trailerDict), yRef, true, // write all entries according to ISO 32000-1, 7.5.4 Cross-Reference Table: \"For a file that has never been incrementally updated, the cross-reference section shall\n                                                                      // contain only one subsection, whose object numbering begins at 0.\"\n                                  uxrefOffset, outStr, yRef);\n\n    outStr->close();\n    delete outStr;\n    fclose(f);\n    delete yRef;\n    delete countRef;\n    for (i = 0; i < (int)docs.size(); i++) {\n        delete docs[i];\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -77,6 +77,14 @@\n     Object ocObj;\n     if (docs.size() >= 1) {\n         Object catObj = docs[0]->getXRef()->getCatalog();\n+        if(!catObj.isDict()){\n+            fclose(f);\n+            delete yRef;\n+            delete countRef;\n+            delete outStr;\n+            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n+            return -1;\n+        }\n         Dict *catDict = catObj.getDict();\n         intents = catDict->lookup(\"OutputIntents\");\n         afObj = catDict->lookupNF(\"AcroForm\").copy();\n@@ -175,6 +183,14 @@\n             }\n         }\n         Object pageCatObj = docs[i]->getXRef()->getCatalog();\n+        if(!pageCatObj.isDict()){\n+            fclose(f);\n+            delete yRef;\n+            delete countRef;\n+            delete outStr;\n+            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n+            return -1;\n+        }\n         Dict *pageCatDict = pageCatObj.getDict();\n         Object pageNames = pageCatDict->lookup(\"Names\");\n         if (!pageNames.isNull() && pageNames.isDict()) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if(!catObj.isDict()){",
                "            fclose(f);",
                "            delete yRef;",
                "            delete countRef;",
                "            delete outStr;",
                "            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");",
                "            return -1;",
                "        }",
                "        if(!pageCatObj.isDict()){",
                "            fclose(f);",
                "            delete yRef;",
                "            delete countRef;",
                "            delete outStr;",
                "            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");",
                "            return -1;",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-37052",
        "func_name": "poppler/PDFDoc::markDictionnary",
        "description": "A reachable Object::getString assertion in Poppler 22.07.0 allows attackers to cause a denial of service due to a failure in markObject.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=8677500399fc2548fa816b619580c2c07915a98c",
        "commit_title": "Fixes #1278",
        "commit_text": "",
        "func_before": "void PDFDoc::markDictionnary(Dict *dict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n{\n    bool deleteSet = false;\n    if (!alreadyMarkedDicts) {\n        alreadyMarkedDicts = new std::set<Dict *>;\n        deleteSet = true;\n    }\n\n    if (alreadyMarkedDicts->find(dict) != alreadyMarkedDicts->end()) {\n        error(errSyntaxWarning, -1, \"PDFDoc::markDictionnary: Found recursive dicts\");\n        if (deleteSet) {\n            delete alreadyMarkedDicts;\n        }\n        return;\n    } else {\n        alreadyMarkedDicts->insert(dict);\n    }\n\n    for (int i = 0; i < dict->getLength(); i++) {\n        const char *key = dict->getKey(i);\n        if (strcmp(key, \"Annots\") != 0) {\n            Object obj1 = dict->getValNF(i).copy();\n            markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n        } else {\n            Object annotsObj = dict->getValNF(i).copy();\n            if (!annotsObj.isNull()) {\n                markAnnotations(&annotsObj, xRef, countRef, 0, oldRefNum, newRefNum, alreadyMarkedDicts);\n            }\n        }\n    }\n\n    if (deleteSet) {\n        delete alreadyMarkedDicts;\n    }\n}",
        "func": "bool PDFDoc::markDictionnary(Dict *dict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n{\n    bool deleteSet = false;\n    if (!alreadyMarkedDicts) {\n        alreadyMarkedDicts = new std::set<Dict *>;\n        deleteSet = true;\n    }\n\n    if (alreadyMarkedDicts->find(dict) != alreadyMarkedDicts->end()) {\n        error(errSyntaxWarning, -1, \"PDFDoc::markDictionnary: Found recursive dicts\");\n        if (deleteSet) {\n            delete alreadyMarkedDicts;\n        }\n        return true;\n    } else {\n        alreadyMarkedDicts->insert(dict);\n    }\n\n    for (int i = 0; i < dict->getLength(); i++) {\n        const char *key = dict->getKey(i);\n        if (strcmp(key, \"Annots\") != 0) {\n            Object obj1 = dict->getValNF(i).copy();\n            const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n            if (unlikely(!success)) {\n                return false;\n            }\n        } else {\n            Object annotsObj = dict->getValNF(i).copy();\n            if (!annotsObj.isNull()) {\n                markAnnotations(&annotsObj, xRef, countRef, 0, oldRefNum, newRefNum, alreadyMarkedDicts);\n            }\n        }\n    }\n\n    if (deleteSet) {\n        delete alreadyMarkedDicts;\n    }\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void PDFDoc::markDictionnary(Dict *dict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n+bool PDFDoc::markDictionnary(Dict *dict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n {\n     bool deleteSet = false;\n     if (!alreadyMarkedDicts) {\n@@ -11,7 +11,7 @@\n         if (deleteSet) {\n             delete alreadyMarkedDicts;\n         }\n-        return;\n+        return true;\n     } else {\n         alreadyMarkedDicts->insert(dict);\n     }\n@@ -20,7 +20,10 @@\n         const char *key = dict->getKey(i);\n         if (strcmp(key, \"Annots\") != 0) {\n             Object obj1 = dict->getValNF(i).copy();\n-            markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+            const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+            if (unlikely(!success)) {\n+                return false;\n+            }\n         } else {\n             Object annotsObj = dict->getValNF(i).copy();\n             if (!annotsObj.isNull()) {\n@@ -32,4 +35,6 @@\n     if (deleteSet) {\n         delete alreadyMarkedDicts;\n     }\n+\n+    return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void PDFDoc::markDictionnary(Dict *dict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)",
                "        return;",
                "            markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);"
            ],
            "added_lines": [
                "bool PDFDoc::markDictionnary(Dict *dict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)",
                "        return true;",
                "            const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "            if (unlikely(!success)) {",
                "                return false;",
                "            }",
                "",
                "    return true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-37052",
        "func_name": "poppler/PDFDoc::markObject",
        "description": "A reachable Object::getString assertion in Poppler 22.07.0 allows attackers to cause a denial of service due to a failure in markObject.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=8677500399fc2548fa816b619580c2c07915a98c",
        "commit_title": "Fixes #1278",
        "commit_text": "",
        "func_before": "void PDFDoc::markObject(Object *obj, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n{\n    Array *array;\n\n    switch (obj->getType()) {\n    case objArray:\n        array = obj->getArray();\n        for (int i = 0; i < array->getLength(); i++) {\n            Object obj1 = array->getNF(i).copy();\n            markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n        }\n        break;\n    case objDict:\n        markDictionnary(obj->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n        break;\n    case objStream: {\n        Stream *stream = obj->getStream();\n        markDictionnary(stream->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n    } break;\n    case objRef: {\n        if (obj->getRef().num + (int)numOffset >= xRef->getNumObjects() || xRef->getEntry(obj->getRef().num + numOffset)->type == xrefEntryFree) {\n            if (getXRef()->getEntry(obj->getRef().num)->type == xrefEntryFree) {\n                return; // already marked as free => should be replaced\n            }\n            xRef->add(obj->getRef().num + numOffset, obj->getRef().gen, 0, true);\n            if (getXRef()->getEntry(obj->getRef().num)->type == xrefEntryCompressed) {\n                xRef->getEntry(obj->getRef().num + numOffset)->type = xrefEntryCompressed;\n            }\n        }\n        if (obj->getRef().num + (int)numOffset >= countRef->getNumObjects() || countRef->getEntry(obj->getRef().num + numOffset)->type == xrefEntryFree) {\n            countRef->add(obj->getRef().num + numOffset, 1, 0, true);\n        } else {\n            XRefEntry *entry = countRef->getEntry(obj->getRef().num + numOffset);\n            entry->gen++;\n            if (entry->gen > 9) {\n                break;\n            }\n        }\n        Object obj1 = getXRef()->fetch(obj->getRef());\n        markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum);\n    } break;\n    default:\n        break;\n    }\n}",
        "func": "bool PDFDoc::markObject(Object *obj, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n{\n    Array *array;\n\n    switch (obj->getType()) {\n    case objArray:\n        array = obj->getArray();\n        for (int i = 0; i < array->getLength(); i++) {\n            Object obj1 = array->getNF(i).copy();\n            const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n            if (unlikely(!success)) {\n                return false;\n            }\n        }\n        break;\n    case objDict: {\n        const bool success = markDictionnary(obj->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n        if (unlikely(!success)) {\n            return false;\n        }\n    } break;\n    case objStream: {\n        Stream *stream = obj->getStream();\n        const bool success = markDictionnary(stream->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n        if (unlikely(!success)) {\n            return false;\n        }\n    } break;\n    case objRef: {\n        if (obj->getRef().num + (int)numOffset >= xRef->getNumObjects() || xRef->getEntry(obj->getRef().num + numOffset)->type == xrefEntryFree) {\n            if (getXRef()->getEntry(obj->getRef().num)->type == xrefEntryFree) {\n                return true; // already marked as free => should be replaced\n            }\n            const bool success = xRef->add(obj->getRef().num + numOffset, obj->getRef().gen, 0, true);\n            if (unlikely(!success)) {\n                return false;\n            }\n            if (getXRef()->getEntry(obj->getRef().num)->type == xrefEntryCompressed) {\n                xRef->getEntry(obj->getRef().num + numOffset)->type = xrefEntryCompressed;\n            }\n        }\n        if (obj->getRef().num + (int)numOffset >= countRef->getNumObjects() || countRef->getEntry(obj->getRef().num + numOffset)->type == xrefEntryFree) {\n            countRef->add(obj->getRef().num + numOffset, 1, 0, true);\n        } else {\n            XRefEntry *entry = countRef->getEntry(obj->getRef().num + numOffset);\n            entry->gen++;\n            if (entry->gen > 9) {\n                break;\n            }\n        }\n        Object obj1 = getXRef()->fetch(obj->getRef());\n        const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum);\n        if (unlikely(!success)) {\n            return false;\n        }\n    } break;\n    default:\n        break;\n    }\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void PDFDoc::markObject(Object *obj, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n+bool PDFDoc::markObject(Object *obj, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n {\n     Array *array;\n \n@@ -7,22 +7,34 @@\n         array = obj->getArray();\n         for (int i = 0; i < array->getLength(); i++) {\n             Object obj1 = array->getNF(i).copy();\n-            markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+            const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+            if (unlikely(!success)) {\n+                return false;\n+            }\n         }\n         break;\n-    case objDict:\n-        markDictionnary(obj->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n-        break;\n+    case objDict: {\n+        const bool success = markDictionnary(obj->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+        if (unlikely(!success)) {\n+            return false;\n+        }\n+    } break;\n     case objStream: {\n         Stream *stream = obj->getStream();\n-        markDictionnary(stream->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+        const bool success = markDictionnary(stream->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+        if (unlikely(!success)) {\n+            return false;\n+        }\n     } break;\n     case objRef: {\n         if (obj->getRef().num + (int)numOffset >= xRef->getNumObjects() || xRef->getEntry(obj->getRef().num + numOffset)->type == xrefEntryFree) {\n             if (getXRef()->getEntry(obj->getRef().num)->type == xrefEntryFree) {\n-                return; // already marked as free => should be replaced\n+                return true; // already marked as free => should be replaced\n             }\n-            xRef->add(obj->getRef().num + numOffset, obj->getRef().gen, 0, true);\n+            const bool success = xRef->add(obj->getRef().num + numOffset, obj->getRef().gen, 0, true);\n+            if (unlikely(!success)) {\n+                return false;\n+            }\n             if (getXRef()->getEntry(obj->getRef().num)->type == xrefEntryCompressed) {\n                 xRef->getEntry(obj->getRef().num + numOffset)->type = xrefEntryCompressed;\n             }\n@@ -37,9 +49,14 @@\n             }\n         }\n         Object obj1 = getXRef()->fetch(obj->getRef());\n-        markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum);\n+        const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum);\n+        if (unlikely(!success)) {\n+            return false;\n+        }\n     } break;\n     default:\n         break;\n     }\n+\n+    return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void PDFDoc::markObject(Object *obj, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)",
                "            markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "    case objDict:",
                "        markDictionnary(obj->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "        break;",
                "        markDictionnary(stream->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "                return; // already marked as free => should be replaced",
                "            xRef->add(obj->getRef().num + numOffset, obj->getRef().gen, 0, true);",
                "        markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum);"
            ],
            "added_lines": [
                "bool PDFDoc::markObject(Object *obj, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)",
                "            const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "            if (unlikely(!success)) {",
                "                return false;",
                "            }",
                "    case objDict: {",
                "        const bool success = markDictionnary(obj->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "        if (unlikely(!success)) {",
                "            return false;",
                "        }",
                "    } break;",
                "        const bool success = markDictionnary(stream->getDict(), xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "        if (unlikely(!success)) {",
                "            return false;",
                "        }",
                "                return true; // already marked as free => should be replaced",
                "            const bool success = xRef->add(obj->getRef().num + numOffset, obj->getRef().gen, 0, true);",
                "            if (unlikely(!success)) {",
                "                return false;",
                "            }",
                "        const bool success = markObject(&obj1, xRef, countRef, numOffset, oldRefNum, newRefNum);",
                "        if (unlikely(!success)) {",
                "            return false;",
                "        }",
                "",
                "    return true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-37052",
        "func_name": "poppler/PDFDoc::savePageAs",
        "description": "A reachable Object::getString assertion in Poppler 22.07.0 allows attackers to cause a denial of service due to a failure in markObject.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=8677500399fc2548fa816b619580c2c07915a98c",
        "commit_title": "Fixes #1278",
        "commit_text": "",
        "func_before": "int PDFDoc::savePageAs(const GooString &name, int pageNo)\n{\n    FILE *f;\n    OutStream *outStr;\n    XRef *yRef, *countRef;\n\n    if (file && file->modificationTimeChangedSinceOpen()) {\n        return errFileChangedSinceOpen;\n    }\n\n    int rootNum = getXRef()->getNumObjects() + 1;\n\n    // Make sure that special flags are set, because we are going to read\n    // all objects, including Unencrypted ones.\n    xref->scanSpecialFlags();\n\n    unsigned char *fileKey;\n    CryptAlgorithm encAlgorithm;\n    int keyLength;\n    xref->getEncryptionParameters(&fileKey, &encAlgorithm, &keyLength);\n\n    if (pageNo < 1 || pageNo > getNumPages() || !getCatalog()->getPage(pageNo)) {\n        error(errInternal, -1, \"Illegal pageNo: {0:d}({1:d})\", pageNo, getNumPages());\n        return errOpenFile;\n    }\n    const PDFRectangle *cropBox = nullptr;\n    if (getCatalog()->getPage(pageNo)->isCropped()) {\n        cropBox = getCatalog()->getPage(pageNo)->getCropBox();\n    }\n    replacePageDict(pageNo, getCatalog()->getPage(pageNo)->getRotate(), getCatalog()->getPage(pageNo)->getMediaBox(), cropBox);\n    Ref *refPage = getCatalog()->getPageRef(pageNo);\n    Object page = getXRef()->fetch(*refPage);\n\n    if (!(f = openFile(name.c_str(), \"wb\"))) {\n        error(errIO, -1, \"Couldn't open file '{0:t}'\", &name);\n        return errOpenFile;\n    }\n    outStr = new FileOutStream(f, 0);\n\n    yRef = new XRef(getXRef()->getTrailerDict());\n\n    if (secHdlr != nullptr && !secHdlr->isUnencrypted()) {\n        yRef->setEncryption(secHdlr->getPermissionFlags(), secHdlr->getOwnerPasswordOk(), fileKey, keyLength, secHdlr->getEncVersion(), secHdlr->getEncRevision(), encAlgorithm);\n    }\n    countRef = new XRef();\n    Object *trailerObj = getXRef()->getTrailerDict();\n    if (trailerObj->isDict()) {\n        markPageObjects(trailerObj->getDict(), yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    yRef->add(0, 65535, 0, false);\n    writeHeader(outStr, getPDFMajorVersion(), getPDFMinorVersion());\n\n    // get and mark info dict\n    Object infoObj = getXRef()->getDocInfo();\n    if (infoObj.isDict()) {\n        Dict *infoDict = infoObj.getDict();\n        markPageObjects(infoDict, yRef, countRef, 0, refPage->num, rootNum + 2);\n        if (trailerObj->isDict()) {\n            Dict *trailerDict = trailerObj->getDict();\n            const Object &ref = trailerDict->lookupNF(\"Info\");\n            if (ref.isRef()) {\n                yRef->add(ref.getRef(), 0, true);\n                if (getXRef()->getEntry(ref.getRef().num)->type == xrefEntryCompressed) {\n                    yRef->getEntry(ref.getRef().num)->type = xrefEntryCompressed;\n                }\n            }\n        }\n    }\n\n    // get and mark output intents etc.\n    Object catObj = getXRef()->getCatalog();\n    if (!catObj.isDict()) {\n        fclose(f);\n        delete yRef;\n        delete countRef;\n        delete outStr;\n        error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary\");\n        return errOpenFile;\n    }\n    Dict *catDict = catObj.getDict();\n    Object pagesObj = catDict->lookup(\"Pages\");\n    Object afObj = catDict->lookupNF(\"AcroForm\").copy();\n    if (!afObj.isNull()) {\n        markAcroForm(&afObj, yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    Dict *pagesDict = pagesObj.getDict();\n    Object resourcesObj = pagesDict->lookup(\"Resources\");\n    if (resourcesObj.isDict()) {\n        markPageObjects(resourcesObj.getDict(), yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    markPageObjects(catDict, yRef, countRef, 0, refPage->num, rootNum + 2);\n\n    Dict *pageDict = page.getDict();\n    if (resourcesObj.isNull() && !pageDict->hasKey(\"Resources\")) {\n        Object *resourceDictObject = getCatalog()->getPage(pageNo)->getResourceDictObject();\n        if (resourceDictObject->isDict()) {\n            resourcesObj = resourceDictObject->copy();\n            markPageObjects(resourcesObj.getDict(), yRef, countRef, 0, refPage->num, rootNum + 2);\n        }\n    }\n    markPageObjects(pageDict, yRef, countRef, 0, refPage->num, rootNum + 2);\n    Object annotsObj = pageDict->lookupNF(\"Annots\").copy();\n    if (!annotsObj.isNull()) {\n        markAnnotations(&annotsObj, yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    yRef->markUnencrypted();\n    writePageObjects(outStr, yRef, 0);\n\n    yRef->add(rootNum, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum);\n    outStr->printf(\"<< /Type /Catalog /Pages %d 0 R\", rootNum + 1);\n    for (int j = 0; j < catDict->getLength(); j++) {\n        const char *key = catDict->getKey(j);\n        if (strcmp(key, \"Type\") != 0 && strcmp(key, \"Catalog\") != 0 && strcmp(key, \"Pages\") != 0) {\n            if (j > 0) {\n                outStr->printf(\" \");\n            }\n            Object value = catDict->getValNF(j).copy();\n            outStr->printf(\"/%s \", key);\n            writeObject(&value, outStr, getXRef(), 0, nullptr, cryptRC4, 0, 0, 0);\n        }\n    }\n    outStr->printf(\">>\\nendobj\\n\");\n\n    yRef->add(rootNum + 1, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 1);\n    outStr->printf(\"<< /Type /Pages /Kids [ %d 0 R ] /Count 1 \", rootNum + 2);\n    if (resourcesObj.isDict()) {\n        outStr->printf(\"/Resources \");\n        writeObject(&resourcesObj, outStr, getXRef(), 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    outStr->printf(\">>\\n\");\n    outStr->printf(\"endobj\\n\");\n\n    yRef->add(rootNum + 2, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 2);\n    outStr->printf(\"<< \");\n    for (int n = 0; n < pageDict->getLength(); n++) {\n        if (n > 0) {\n            outStr->printf(\" \");\n        }\n        const char *key = pageDict->getKey(n);\n        Object value = pageDict->getValNF(n).copy();\n        if (strcmp(key, \"Parent\") == 0) {\n            outStr->printf(\"/Parent %d 0 R\", rootNum + 1);\n        } else {\n            outStr->printf(\"/%s \", key);\n            writeObject(&value, outStr, getXRef(), 0, nullptr, cryptRC4, 0, 0, 0);\n        }\n    }\n    outStr->printf(\" >>\\nendobj\\n\");\n\n    Goffset uxrefOffset = outStr->getPos();\n    Ref ref;\n    ref.num = rootNum;\n    ref.gen = 0;\n    Object trailerDict = createTrailerDict(rootNum + 3, false, 0, &ref, getXRef(), name.c_str(), uxrefOffset);\n    writeXRefTableTrailer(std::move(trailerDict), yRef, false /* do not write unnecessary entries */, uxrefOffset, outStr, getXRef());\n\n    outStr->close();\n    fclose(f);\n    delete yRef;\n    delete countRef;\n    delete outStr;\n\n    return errNone;\n}",
        "func": "int PDFDoc::savePageAs(const GooString &name, int pageNo)\n{\n    FILE *f;\n    OutStream *outStr;\n    XRef *yRef, *countRef;\n\n    if (file && file->modificationTimeChangedSinceOpen()) {\n        return errFileChangedSinceOpen;\n    }\n\n    int rootNum = getXRef()->getNumObjects() + 1;\n\n    // Make sure that special flags are set, because we are going to read\n    // all objects, including Unencrypted ones.\n    xref->scanSpecialFlags();\n\n    unsigned char *fileKey;\n    CryptAlgorithm encAlgorithm;\n    int keyLength;\n    xref->getEncryptionParameters(&fileKey, &encAlgorithm, &keyLength);\n\n    if (pageNo < 1 || pageNo > getNumPages() || !getCatalog()->getPage(pageNo)) {\n        error(errInternal, -1, \"Illegal pageNo: {0:d}({1:d})\", pageNo, getNumPages());\n        return errOpenFile;\n    }\n    const PDFRectangle *cropBox = nullptr;\n    if (getCatalog()->getPage(pageNo)->isCropped()) {\n        cropBox = getCatalog()->getPage(pageNo)->getCropBox();\n    }\n    replacePageDict(pageNo, getCatalog()->getPage(pageNo)->getRotate(), getCatalog()->getPage(pageNo)->getMediaBox(), cropBox);\n    Ref *refPage = getCatalog()->getPageRef(pageNo);\n    Object page = getXRef()->fetch(*refPage);\n\n    if (!(f = openFile(name.c_str(), \"wb\"))) {\n        error(errIO, -1, \"Couldn't open file '{0:t}'\", &name);\n        return errOpenFile;\n    }\n    outStr = new FileOutStream(f, 0);\n\n    yRef = new XRef(getXRef()->getTrailerDict());\n\n    if (secHdlr != nullptr && !secHdlr->isUnencrypted()) {\n        yRef->setEncryption(secHdlr->getPermissionFlags(), secHdlr->getOwnerPasswordOk(), fileKey, keyLength, secHdlr->getEncVersion(), secHdlr->getEncRevision(), encAlgorithm);\n    }\n    countRef = new XRef();\n    Object *trailerObj = getXRef()->getTrailerDict();\n    if (trailerObj->isDict()) {\n        markPageObjects(trailerObj->getDict(), yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    yRef->add(0, 65535, 0, false);\n    writeHeader(outStr, getPDFMajorVersion(), getPDFMinorVersion());\n\n    // get and mark info dict\n    Object infoObj = getXRef()->getDocInfo();\n    if (infoObj.isDict()) {\n        Dict *infoDict = infoObj.getDict();\n        markPageObjects(infoDict, yRef, countRef, 0, refPage->num, rootNum + 2);\n        if (trailerObj->isDict()) {\n            Dict *trailerDict = trailerObj->getDict();\n            const Object &ref = trailerDict->lookupNF(\"Info\");\n            if (ref.isRef()) {\n                yRef->add(ref.getRef(), 0, true);\n                if (getXRef()->getEntry(ref.getRef().num)->type == xrefEntryCompressed) {\n                    yRef->getEntry(ref.getRef().num)->type = xrefEntryCompressed;\n                }\n            }\n        }\n    }\n\n    // get and mark output intents etc.\n    Object catObj = getXRef()->getCatalog();\n    if (!catObj.isDict()) {\n        fclose(f);\n        delete yRef;\n        delete countRef;\n        delete outStr;\n        error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary\");\n        return errOpenFile;\n    }\n    Dict *catDict = catObj.getDict();\n    Object pagesObj = catDict->lookup(\"Pages\");\n    Object afObj = catDict->lookupNF(\"AcroForm\").copy();\n    if (!afObj.isNull()) {\n        markAcroForm(&afObj, yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    Dict *pagesDict = pagesObj.getDict();\n    Object resourcesObj = pagesDict->lookup(\"Resources\");\n    if (resourcesObj.isDict()) {\n        markPageObjects(resourcesObj.getDict(), yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    if (!markPageObjects(catDict, yRef, countRef, 0, refPage->num, rootNum + 2)) {\n        fclose(f);\n        delete yRef;\n        delete countRef;\n        delete outStr;\n        error(errSyntaxError, -1, \"markPageObjects failed\");\n        return errDamaged;\n    }\n\n    Dict *pageDict = page.getDict();\n    if (resourcesObj.isNull() && !pageDict->hasKey(\"Resources\")) {\n        Object *resourceDictObject = getCatalog()->getPage(pageNo)->getResourceDictObject();\n        if (resourceDictObject->isDict()) {\n            resourcesObj = resourceDictObject->copy();\n            markPageObjects(resourcesObj.getDict(), yRef, countRef, 0, refPage->num, rootNum + 2);\n        }\n    }\n    markPageObjects(pageDict, yRef, countRef, 0, refPage->num, rootNum + 2);\n    Object annotsObj = pageDict->lookupNF(\"Annots\").copy();\n    if (!annotsObj.isNull()) {\n        markAnnotations(&annotsObj, yRef, countRef, 0, refPage->num, rootNum + 2);\n    }\n    yRef->markUnencrypted();\n    writePageObjects(outStr, yRef, 0);\n\n    yRef->add(rootNum, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum);\n    outStr->printf(\"<< /Type /Catalog /Pages %d 0 R\", rootNum + 1);\n    for (int j = 0; j < catDict->getLength(); j++) {\n        const char *key = catDict->getKey(j);\n        if (strcmp(key, \"Type\") != 0 && strcmp(key, \"Catalog\") != 0 && strcmp(key, \"Pages\") != 0) {\n            if (j > 0) {\n                outStr->printf(\" \");\n            }\n            Object value = catDict->getValNF(j).copy();\n            outStr->printf(\"/%s \", key);\n            writeObject(&value, outStr, getXRef(), 0, nullptr, cryptRC4, 0, 0, 0);\n        }\n    }\n    outStr->printf(\">>\\nendobj\\n\");\n\n    yRef->add(rootNum + 1, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 1);\n    outStr->printf(\"<< /Type /Pages /Kids [ %d 0 R ] /Count 1 \", rootNum + 2);\n    if (resourcesObj.isDict()) {\n        outStr->printf(\"/Resources \");\n        writeObject(&resourcesObj, outStr, getXRef(), 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    outStr->printf(\">>\\n\");\n    outStr->printf(\"endobj\\n\");\n\n    yRef->add(rootNum + 2, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 2);\n    outStr->printf(\"<< \");\n    for (int n = 0; n < pageDict->getLength(); n++) {\n        if (n > 0) {\n            outStr->printf(\" \");\n        }\n        const char *key = pageDict->getKey(n);\n        Object value = pageDict->getValNF(n).copy();\n        if (strcmp(key, \"Parent\") == 0) {\n            outStr->printf(\"/Parent %d 0 R\", rootNum + 1);\n        } else {\n            outStr->printf(\"/%s \", key);\n            writeObject(&value, outStr, getXRef(), 0, nullptr, cryptRC4, 0, 0, 0);\n        }\n    }\n    outStr->printf(\" >>\\nendobj\\n\");\n\n    Goffset uxrefOffset = outStr->getPos();\n    Ref ref;\n    ref.num = rootNum;\n    ref.gen = 0;\n    Object trailerDict = createTrailerDict(rootNum + 3, false, 0, &ref, getXRef(), name.c_str(), uxrefOffset);\n    writeXRefTableTrailer(std::move(trailerDict), yRef, false /* do not write unnecessary entries */, uxrefOffset, outStr, getXRef());\n\n    outStr->close();\n    fclose(f);\n    delete yRef;\n    delete countRef;\n    delete outStr;\n\n    return errNone;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -88,7 +88,14 @@\n     if (resourcesObj.isDict()) {\n         markPageObjects(resourcesObj.getDict(), yRef, countRef, 0, refPage->num, rootNum + 2);\n     }\n-    markPageObjects(catDict, yRef, countRef, 0, refPage->num, rootNum + 2);\n+    if (!markPageObjects(catDict, yRef, countRef, 0, refPage->num, rootNum + 2)) {\n+        fclose(f);\n+        delete yRef;\n+        delete countRef;\n+        delete outStr;\n+        error(errSyntaxError, -1, \"markPageObjects failed\");\n+        return errDamaged;\n+    }\n \n     Dict *pageDict = page.getDict();\n     if (resourcesObj.isNull() && !pageDict->hasKey(\"Resources\")) {",
        "diff_line_info": {
            "deleted_lines": [
                "    markPageObjects(catDict, yRef, countRef, 0, refPage->num, rootNum + 2);"
            ],
            "added_lines": [
                "    if (!markPageObjects(catDict, yRef, countRef, 0, refPage->num, rootNum + 2)) {",
                "        fclose(f);",
                "        delete yRef;",
                "        delete countRef;",
                "        delete outStr;",
                "        error(errSyntaxError, -1, \"markPageObjects failed\");",
                "        return errDamaged;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-37052",
        "func_name": "poppler/PDFDoc::markPageObjects",
        "description": "A reachable Object::getString assertion in Poppler 22.07.0 allows attackers to cause a denial of service due to a failure in markObject.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=8677500399fc2548fa816b619580c2c07915a98c",
        "commit_title": "Fixes #1278",
        "commit_text": "",
        "func_before": "void PDFDoc::markPageObjects(Dict *pageDict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n{\n    pageDict->remove(\"OpenAction\");\n    pageDict->remove(\"Outlines\");\n    pageDict->remove(\"StructTreeRoot\");\n\n    for (int n = 0; n < pageDict->getLength(); n++) {\n        const char *key = pageDict->getKey(n);\n        Object value = pageDict->getValNF(n).copy();\n        if (strcmp(key, \"Parent\") != 0 && strcmp(key, \"Pages\") != 0 && strcmp(key, \"AcroForm\") != 0 && strcmp(key, \"Annots\") != 0 && strcmp(key, \"P\") != 0 && strcmp(key, \"Root\") != 0) {\n            markObject(&value, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n        }\n    }\n}",
        "func": "bool PDFDoc::markPageObjects(Dict *pageDict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n{\n    pageDict->remove(\"OpenAction\");\n    pageDict->remove(\"Outlines\");\n    pageDict->remove(\"StructTreeRoot\");\n\n    for (int n = 0; n < pageDict->getLength(); n++) {\n        const char *key = pageDict->getKey(n);\n        Object value = pageDict->getValNF(n).copy();\n        if (strcmp(key, \"Parent\") != 0 && strcmp(key, \"Pages\") != 0 && strcmp(key, \"AcroForm\") != 0 && strcmp(key, \"Annots\") != 0 && strcmp(key, \"P\") != 0 && strcmp(key, \"Root\") != 0) {\n            const bool success = markObject(&value, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n            if (unlikely(!success)) {\n                return false;\n            }\n        }\n    }\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-void PDFDoc::markPageObjects(Dict *pageDict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n+bool PDFDoc::markPageObjects(Dict *pageDict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)\n {\n     pageDict->remove(\"OpenAction\");\n     pageDict->remove(\"Outlines\");\n@@ -8,7 +8,11 @@\n         const char *key = pageDict->getKey(n);\n         Object value = pageDict->getValNF(n).copy();\n         if (strcmp(key, \"Parent\") != 0 && strcmp(key, \"Pages\") != 0 && strcmp(key, \"AcroForm\") != 0 && strcmp(key, \"Annots\") != 0 && strcmp(key, \"P\") != 0 && strcmp(key, \"Root\") != 0) {\n-            markObject(&value, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+            const bool success = markObject(&value, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);\n+            if (unlikely(!success)) {\n+                return false;\n+            }\n         }\n     }\n+    return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void PDFDoc::markPageObjects(Dict *pageDict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)",
                "            markObject(&value, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);"
            ],
            "added_lines": [
                "bool PDFDoc::markPageObjects(Dict *pageDict, XRef *xRef, XRef *countRef, unsigned int numOffset, int oldRefNum, int newRefNum, std::set<Dict *> *alreadyMarkedDicts)",
                "            const bool success = markObject(&value, xRef, countRef, numOffset, oldRefNum, newRefNum, alreadyMarkedDicts);",
                "            if (unlikely(!success)) {",
                "                return false;",
                "            }",
                "    return true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-37052",
        "func_name": "poppler/XRef::add",
        "description": "A reachable Object::getString assertion in Poppler 22.07.0 allows attackers to cause a denial of service due to a failure in markObject.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=8677500399fc2548fa816b619580c2c07915a98c",
        "commit_title": "Fixes #1278",
        "commit_text": "",
        "func_before": "void XRef::add(int num, int gen, Goffset offs, bool used)\n{\n    xrefLocker();\n    if (num >= size) {\n        if (num >= capacity) {\n            entries = (XRefEntry *)greallocn(entries, num + 1, sizeof(XRefEntry));\n            capacity = num + 1;\n        }\n        for (int i = size; i < num + 1; ++i) {\n            entries[i].offset = -1;\n            entries[i].type = xrefEntryFree;\n            new (&entries[i].obj) Object(objNull);\n            entries[i].flags = 0;\n            entries[i].gen = 0;\n        }\n        size = num + 1;\n    }\n    XRefEntry *e = getEntry(num);\n    e->gen = gen;\n    e->obj.setToNull();\n    e->flags = 0;\n    if (used) {\n        e->type = xrefEntryUncompressed;\n        e->offset = offs;\n    } else {\n        e->type = xrefEntryFree;\n        e->offset = 0;\n    }\n}",
        "func": "bool XRef::add(int num, int gen, Goffset offs, bool used)\n{\n    xrefLocker();\n    if (num >= size) {\n        if (num >= capacity) {\n            entries = (XRefEntry *)greallocn_checkoverflow(entries, num + 1, sizeof(XRefEntry));\n            if (unlikely(entries == nullptr)) {\n                size = 0;\n                capacity = 0;\n                return false;\n            }\n\n            capacity = num + 1;\n        }\n        for (int i = size; i < num + 1; ++i) {\n            entries[i].offset = -1;\n            entries[i].type = xrefEntryFree;\n            new (&entries[i].obj) Object(objNull);\n            entries[i].flags = 0;\n            entries[i].gen = 0;\n        }\n        size = num + 1;\n    }\n    XRefEntry *e = getEntry(num);\n    e->gen = gen;\n    e->obj.setToNull();\n    e->flags = 0;\n    if (used) {\n        e->type = xrefEntryUncompressed;\n        e->offset = offs;\n    } else {\n        e->type = xrefEntryFree;\n        e->offset = 0;\n    }\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,15 @@\n-void XRef::add(int num, int gen, Goffset offs, bool used)\n+bool XRef::add(int num, int gen, Goffset offs, bool used)\n {\n     xrefLocker();\n     if (num >= size) {\n         if (num >= capacity) {\n-            entries = (XRefEntry *)greallocn(entries, num + 1, sizeof(XRefEntry));\n+            entries = (XRefEntry *)greallocn_checkoverflow(entries, num + 1, sizeof(XRefEntry));\n+            if (unlikely(entries == nullptr)) {\n+                size = 0;\n+                capacity = 0;\n+                return false;\n+            }\n+\n             capacity = num + 1;\n         }\n         for (int i = size; i < num + 1; ++i) {\n@@ -26,4 +32,5 @@\n         e->type = xrefEntryFree;\n         e->offset = 0;\n     }\n+    return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void XRef::add(int num, int gen, Goffset offs, bool used)",
                "            entries = (XRefEntry *)greallocn(entries, num + 1, sizeof(XRefEntry));"
            ],
            "added_lines": [
                "bool XRef::add(int num, int gen, Goffset offs, bool used)",
                "            entries = (XRefEntry *)greallocn_checkoverflow(entries, num + 1, sizeof(XRefEntry));",
                "            if (unlikely(entries == nullptr)) {",
                "                size = 0;",
                "                capacity = 0;",
                "                return false;",
                "            }",
                "",
                "    return true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38349",
        "func_name": "poppler/PDFDoc::replacePageDict",
        "description": "An issue was discovered in Poppler 22.08.0. There is a reachable assertion in Object.h, will lead to denial of service because PDFDoc::replacePageDict in PDFDoc.cc lacks a stream check before saving an embedded file.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=4564a002bcb6094cc460bc0d5ddff9423fe6dd28",
        "commit_title": "",
        "commit_text": "",
        "func_before": "void PDFDoc::replacePageDict(int pageNo, int rotate, const PDFRectangle *mediaBox, const PDFRectangle *cropBox)\n{\n    Ref *refPage = getCatalog()->getPageRef(pageNo);\n    Object page = getXRef()->fetch(*refPage);\n    Dict *pageDict = page.getDict();\n    pageDict->remove(\"MediaBoxssdf\");\n    pageDict->remove(\"MediaBox\");\n    pageDict->remove(\"CropBox\");\n    pageDict->remove(\"ArtBox\");\n    pageDict->remove(\"BleedBox\");\n    pageDict->remove(\"TrimBox\");\n    pageDict->remove(\"Rotate\");\n    Array *mediaBoxArray = new Array(getXRef());\n    mediaBoxArray->add(Object(mediaBox->x1));\n    mediaBoxArray->add(Object(mediaBox->y1));\n    mediaBoxArray->add(Object(mediaBox->x2));\n    mediaBoxArray->add(Object(mediaBox->y2));\n    Object mediaBoxObject(mediaBoxArray);\n    Object trimBoxObject = mediaBoxObject.copy();\n    pageDict->add(\"MediaBox\", std::move(mediaBoxObject));\n    if (cropBox != nullptr) {\n        Array *cropBoxArray = new Array(getXRef());\n        cropBoxArray->add(Object(cropBox->x1));\n        cropBoxArray->add(Object(cropBox->y1));\n        cropBoxArray->add(Object(cropBox->x2));\n        cropBoxArray->add(Object(cropBox->y2));\n        Object cropBoxObject(cropBoxArray);\n        trimBoxObject = cropBoxObject.copy();\n        pageDict->add(\"CropBox\", std::move(cropBoxObject));\n    }\n    pageDict->add(\"TrimBox\", std::move(trimBoxObject));\n    pageDict->add(\"Rotate\", Object(rotate));\n    getXRef()->setModifiedObject(&page, *refPage);\n}",
        "func": "bool PDFDoc::replacePageDict(int pageNo, int rotate, const PDFRectangle *mediaBox, const PDFRectangle *cropBox)\n{\n    Ref *refPage = getCatalog()->getPageRef(pageNo);\n    Object page = getXRef()->fetch(*refPage);\n    if (!page.isDict()) {\n        return false;\n    }\n    Dict *pageDict = page.getDict();\n    pageDict->remove(\"MediaBoxssdf\");\n    pageDict->remove(\"MediaBox\");\n    pageDict->remove(\"CropBox\");\n    pageDict->remove(\"ArtBox\");\n    pageDict->remove(\"BleedBox\");\n    pageDict->remove(\"TrimBox\");\n    pageDict->remove(\"Rotate\");\n    Array *mediaBoxArray = new Array(getXRef());\n    mediaBoxArray->add(Object(mediaBox->x1));\n    mediaBoxArray->add(Object(mediaBox->y1));\n    mediaBoxArray->add(Object(mediaBox->x2));\n    mediaBoxArray->add(Object(mediaBox->y2));\n    Object mediaBoxObject(mediaBoxArray);\n    Object trimBoxObject = mediaBoxObject.copy();\n    pageDict->add(\"MediaBox\", std::move(mediaBoxObject));\n    if (cropBox != nullptr) {\n        Array *cropBoxArray = new Array(getXRef());\n        cropBoxArray->add(Object(cropBox->x1));\n        cropBoxArray->add(Object(cropBox->y1));\n        cropBoxArray->add(Object(cropBox->x2));\n        cropBoxArray->add(Object(cropBox->y2));\n        Object cropBoxObject(cropBoxArray);\n        trimBoxObject = cropBoxObject.copy();\n        pageDict->add(\"CropBox\", std::move(cropBoxObject));\n    }\n    pageDict->add(\"TrimBox\", std::move(trimBoxObject));\n    pageDict->add(\"Rotate\", Object(rotate));\n    getXRef()->setModifiedObject(&page, *refPage);\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,10 @@\n-void PDFDoc::replacePageDict(int pageNo, int rotate, const PDFRectangle *mediaBox, const PDFRectangle *cropBox)\n+bool PDFDoc::replacePageDict(int pageNo, int rotate, const PDFRectangle *mediaBox, const PDFRectangle *cropBox)\n {\n     Ref *refPage = getCatalog()->getPageRef(pageNo);\n     Object page = getXRef()->fetch(*refPage);\n+    if (!page.isDict()) {\n+        return false;\n+    }\n     Dict *pageDict = page.getDict();\n     pageDict->remove(\"MediaBoxssdf\");\n     pageDict->remove(\"MediaBox\");\n@@ -31,4 +34,5 @@\n     pageDict->add(\"TrimBox\", std::move(trimBoxObject));\n     pageDict->add(\"Rotate\", Object(rotate));\n     getXRef()->setModifiedObject(&page, *refPage);\n+    return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "void PDFDoc::replacePageDict(int pageNo, int rotate, const PDFRectangle *mediaBox, const PDFRectangle *cropBox)"
            ],
            "added_lines": [
                "bool PDFDoc::replacePageDict(int pageNo, int rotate, const PDFRectangle *mediaBox, const PDFRectangle *cropBox)",
                "    if (!page.isDict()) {",
                "        return false;",
                "    }",
                "    return true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38349",
        "func_name": "poppler/main",
        "description": "An issue was discovered in Poppler 22.08.0. There is a reachable assertion in Object.h, will lead to denial of service because PDFDoc::replacePageDict in PDFDoc.cc lacks a stream check before saving an embedded file.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=4564a002bcb6094cc460bc0d5ddff9423fe6dd28",
        "commit_title": "",
        "commit_text": "",
        "func_before": "int main(int argc, char *argv[])\n///////////////////////////////////////////////////////////////////////////\n// Merge PDF files given by arguments 1 to argc-2 and write the result\n// to the file specified by argument argc-1.\n///////////////////////////////////////////////////////////////////////////\n{\n    int objectsCount = 0;\n    unsigned int numOffset = 0;\n    std::vector<Object> pages;\n    std::vector<unsigned int> offsets;\n    XRef *yRef, *countRef;\n    FILE *f;\n    OutStream *outStr;\n    int i;\n    int j, rootNum;\n    std::vector<PDFDoc *> docs;\n    int majorVersion = 0;\n    int minorVersion = 0;\n    char *fileName = argv[argc - 1];\n\n    const bool ok = parseArgs(argDesc, &argc, argv);\n    if (!ok || argc < 3 || printVersion || printHelp) {\n        fprintf(stderr, \"pdfunite version %s\\n\", PACKAGE_VERSION);\n        fprintf(stderr, \"%s\\n\", popplerCopyright);\n        fprintf(stderr, \"%s\\n\", xpdfCopyright);\n        if (!printVersion) {\n            printUsage(\"pdfunite\", \"<PDF-sourcefile-1>..<PDF-sourcefile-n> <PDF-destfile>\", argDesc);\n        }\n        if (printVersion || printHelp) {\n            return 0;\n        }\n        return 99;\n    }\n    globalParams = std::make_unique<GlobalParams>();\n\n    for (i = 1; i < argc - 1; i++) {\n        PDFDoc *doc = new PDFDoc(std::make_unique<GooString>(argv[i]));\n        if (doc->isOk() && !doc->isEncrypted() && doc->getXRef()->getCatalog().isDict()) {\n            docs.push_back(doc);\n            if (doc->getPDFMajorVersion() > majorVersion) {\n                majorVersion = doc->getPDFMajorVersion();\n                minorVersion = doc->getPDFMinorVersion();\n            } else if (doc->getPDFMajorVersion() == majorVersion) {\n                if (doc->getPDFMinorVersion() > minorVersion) {\n                    minorVersion = doc->getPDFMinorVersion();\n                }\n            }\n        } else if (doc->isOk()) {\n            if (doc->isEncrypted()) {\n                error(errUnimplemented, -1, \"Could not merge encrypted files ('{0:s}')\", argv[i]);\n                return -1;\n            } else if (!doc->getXRef()->getCatalog().isDict()) {\n                error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary ('{0:s}')\", argv[i]);\n                return -1;\n            }\n        } else {\n            error(errSyntaxError, -1, \"Could not merge damaged documents ('{0:s}')\", argv[i]);\n            return -1;\n        }\n    }\n\n    if (!(f = fopen(fileName, \"wb\"))) {\n        error(errIO, -1, \"Could not open file '{0:s}'\", fileName);\n        return -1;\n    }\n    outStr = new FileOutStream(f, 0);\n\n    yRef = new XRef();\n    countRef = new XRef();\n    yRef->add(0, 65535, 0, false);\n    PDFDoc::writeHeader(outStr, majorVersion, minorVersion);\n\n    // handle OutputIntents, AcroForm, OCProperties & Names\n    Object intents;\n    Object names;\n    Object afObj;\n    Object ocObj;\n    if (docs.size() >= 1) {\n        Object catObj = docs[0]->getXRef()->getCatalog();\n        if (!catObj.isDict()) {\n            fclose(f);\n            delete yRef;\n            delete countRef;\n            delete outStr;\n            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n            return -1;\n        }\n        Dict *catDict = catObj.getDict();\n        intents = catDict->lookup(\"OutputIntents\");\n        afObj = catDict->lookupNF(\"AcroForm\").copy();\n        Ref *refPage = docs[0]->getCatalog()->getPageRef(1);\n        if (!afObj.isNull() && refPage) {\n            docs[0]->markAcroForm(&afObj, yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        ocObj = catDict->lookupNF(\"OCProperties\").copy();\n        if (!ocObj.isNull() && ocObj.isDict() && refPage) {\n            docs[0]->markPageObjects(ocObj.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        names = catDict->lookup(\"Names\");\n        if (!names.isNull() && names.isDict() && refPage) {\n            docs[0]->markPageObjects(names.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (i = 1; i < (int)docs.size(); i++) {\n                Object pagecatObj = docs[i]->getXRef()->getCatalog();\n                Dict *pagecatDict = pagecatObj.getDict();\n                Object pageintents = pagecatDict->lookup(\"OutputIntents\");\n                if (pageintents.isArray() && pageintents.arrayGetLength() > 0) {\n                    for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                        Object intent = intents.arrayGet(j, 0);\n                        if (intent.isDict()) {\n                            Object idf = intent.dictLookup(\"OutputConditionIdentifier\");\n                            if (idf.isString()) {\n                                const GooString *gidf = idf.getString();\n                                bool removeIntent = true;\n                                for (int k = 0; k < pageintents.arrayGetLength(); k++) {\n                                    Object pgintent = pageintents.arrayGet(k, 0);\n                                    if (pgintent.isDict()) {\n                                        Object pgidf = pgintent.dictLookup(\"OutputConditionIdentifier\");\n                                        if (pgidf.isString()) {\n                                            const GooString *gpgidf = pgidf.getString();\n                                            if (gpgidf->cmp(gidf) == 0) {\n                                                removeIntent = false;\n                                                break;\n                                            }\n                                        }\n                                    }\n                                }\n                                if (removeIntent) {\n                                    intents.arrayRemove(j);\n                                    error(errSyntaxWarning, -1, \"Output intent {0:s} missing in pdf {1:s}, removed\", gidf->c_str(), docs[i]->getFileName()->c_str());\n                                }\n                            } else {\n                                intents.arrayRemove(j);\n                                error(errSyntaxWarning, -1, \"Invalid output intent dict, missing required OutputConditionIdentifier\");\n                            }\n                        } else {\n                            intents.arrayRemove(j);\n                        }\n                    }\n                } else {\n                    error(errSyntaxWarning, -1, \"Output intents differs, remove them all\");\n                    break;\n                }\n            }\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                Object intent = intents.arrayGet(j, 0);\n                if (intent.isDict()) {\n                    docs[0]->markPageObjects(intent.getDict(), yRef, countRef, numOffset, 0, 0);\n                } else {\n                    intents.arrayRemove(j);\n                }\n            }\n        }\n    }\n\n    for (i = 0; i < (int)docs.size(); i++) {\n        for (j = 1; j <= docs[i]->getNumPages(); j++) {\n            if (!docs[i]->getCatalog()->getPage(j)) {\n                continue;\n            }\n\n            const PDFRectangle *cropBox = nullptr;\n            if (docs[i]->getCatalog()->getPage(j)->isCropped()) {\n                cropBox = docs[i]->getCatalog()->getPage(j)->getCropBox();\n            }\n            docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox);\n            Ref *refPage = docs[i]->getCatalog()->getPageRef(j);\n            Object page = docs[i]->getXRef()->fetch(*refPage);\n            Dict *pageDict = page.getDict();\n            Object *resDict = docs[i]->getCatalog()->getPage(j)->getResourceDictObject();\n            if (resDict->isDict()) {\n                pageDict->set(\"Resources\", resDict->copy());\n            }\n            pages.push_back(std::move(page));\n            offsets.push_back(numOffset);\n            docs[i]->markPageObjects(pageDict, yRef, countRef, numOffset, refPage->num, refPage->num);\n            Object annotsObj = pageDict->lookupNF(\"Annots\").copy();\n            if (!annotsObj.isNull()) {\n                docs[i]->markAnnotations(&annotsObj, yRef, countRef, numOffset, refPage->num, refPage->num);\n            }\n        }\n        Object pageCatObj = docs[i]->getXRef()->getCatalog();\n        if (!pageCatObj.isDict()) {\n            fclose(f);\n            delete yRef;\n            delete countRef;\n            delete outStr;\n            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n            return -1;\n        }\n        Dict *pageCatDict = pageCatObj.getDict();\n        Object pageNames = pageCatDict->lookup(\"Names\");\n        if (!pageNames.isNull() && pageNames.isDict()) {\n            if (!names.isDict()) {\n                names = Object(new Dict(yRef));\n            }\n            doMergeNameDict(docs[i], yRef, countRef, 0, 0, names.getDict(), pageNames.getDict(), numOffset);\n        }\n        Object pageForm = pageCatDict->lookup(\"AcroForm\");\n        if (i > 0 && !pageForm.isNull() && pageForm.isDict()) {\n            if (afObj.isNull()) {\n                afObj = pageCatDict->lookupNF(\"AcroForm\").copy();\n            } else if (afObj.isDict()) {\n                doMergeFormDict(afObj.getDict(), pageForm.getDict(), numOffset);\n            }\n        }\n        objectsCount += docs[i]->writePageObjects(outStr, yRef, numOffset, true);\n        numOffset = yRef->getNumObjects() + 1;\n    }\n\n    rootNum = yRef->getNumObjects() + 1;\n    yRef->add(rootNum, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum);\n    outStr->printf(\"<< /Type /Catalog /Pages %d 0 R\", rootNum + 1);\n    // insert OutputIntents\n    if (intents.isArray() && intents.arrayGetLength() > 0) {\n        outStr->printf(\" /OutputIntents [\");\n        for (j = 0; j < intents.arrayGetLength(); j++) {\n            Object intent = intents.arrayGet(j, 0);\n            if (intent.isDict()) {\n                PDFDoc::writeObject(&intent, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\"]\");\n    }\n    // insert AcroForm\n    if (!afObj.isNull()) {\n        outStr->printf(\" /AcroForm \");\n        PDFDoc::writeObject(&afObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert OCProperties\n    if (!ocObj.isNull() && ocObj.isDict()) {\n        outStr->printf(\" /OCProperties \");\n        PDFDoc::writeObject(&ocObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert Names\n    if (!names.isNull() && names.isDict()) {\n        outStr->printf(\" /Names \");\n        PDFDoc::writeObject(&names, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    outStr->printf(\">>\\nendobj\\n\");\n    objectsCount++;\n\n    yRef->add(rootNum + 1, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 1);\n    outStr->printf(\"<< /Type /Pages /Kids [\");\n    for (j = 0; j < (int)pages.size(); j++) {\n        outStr->printf(\" %d 0 R\", rootNum + j + 2);\n    }\n    outStr->printf(\" ] /Count %zd >>\\nendobj\\n\", pages.size());\n    objectsCount++;\n\n    for (i = 0; i < (int)pages.size(); i++) {\n        yRef->add(rootNum + i + 2, 0, outStr->getPos(), true);\n        outStr->printf(\"%d 0 obj\\n\", rootNum + i + 2);\n        outStr->printf(\"<< \");\n        Dict *pageDict = pages[i].getDict();\n        for (j = 0; j < pageDict->getLength(); j++) {\n            if (j > 0) {\n                outStr->printf(\" \");\n            }\n            const char *key = pageDict->getKey(j);\n            Object value = pageDict->getValNF(j).copy();\n            if (strcmp(key, \"Parent\") == 0) {\n                outStr->printf(\"/Parent %d 0 R\", rootNum + 1);\n            } else {\n                outStr->printf(\"/%s \", key);\n                PDFDoc::writeObject(&value, outStr, yRef, offsets[i], nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\" >>\\nendobj\\n\");\n        objectsCount++;\n    }\n    Goffset uxrefOffset = outStr->getPos();\n    Ref ref;\n    ref.num = rootNum;\n    ref.gen = 0;\n    Object trailerDict = PDFDoc::createTrailerDict(objectsCount, false, 0, &ref, yRef, fileName, outStr->getPos());\n    PDFDoc::writeXRefTableTrailer(std::move(trailerDict), yRef, true, // write all entries according to ISO 32000-1, 7.5.4 Cross-Reference Table: \"For a file that has never been incrementally updated, the cross-reference section shall\n                                                                      // contain only one subsection, whose object numbering begins at 0.\"\n                                  uxrefOffset, outStr, yRef);\n\n    outStr->close();\n    delete outStr;\n    fclose(f);\n    delete yRef;\n    delete countRef;\n    for (i = 0; i < (int)docs.size(); i++) {\n        delete docs[i];\n    }\n    return 0;\n}",
        "func": "int main(int argc, char *argv[])\n///////////////////////////////////////////////////////////////////////////\n// Merge PDF files given by arguments 1 to argc-2 and write the result\n// to the file specified by argument argc-1.\n///////////////////////////////////////////////////////////////////////////\n{\n    int objectsCount = 0;\n    unsigned int numOffset = 0;\n    std::vector<Object> pages;\n    std::vector<unsigned int> offsets;\n    XRef *yRef, *countRef;\n    FILE *f;\n    OutStream *outStr;\n    int i;\n    int j, rootNum;\n    std::vector<PDFDoc *> docs;\n    int majorVersion = 0;\n    int minorVersion = 0;\n    char *fileName = argv[argc - 1];\n\n    const bool ok = parseArgs(argDesc, &argc, argv);\n    if (!ok || argc < 3 || printVersion || printHelp) {\n        fprintf(stderr, \"pdfunite version %s\\n\", PACKAGE_VERSION);\n        fprintf(stderr, \"%s\\n\", popplerCopyright);\n        fprintf(stderr, \"%s\\n\", xpdfCopyright);\n        if (!printVersion) {\n            printUsage(\"pdfunite\", \"<PDF-sourcefile-1>..<PDF-sourcefile-n> <PDF-destfile>\", argDesc);\n        }\n        if (printVersion || printHelp) {\n            return 0;\n        }\n        return 99;\n    }\n    globalParams = std::make_unique<GlobalParams>();\n\n    for (i = 1; i < argc - 1; i++) {\n        PDFDoc *doc = new PDFDoc(std::make_unique<GooString>(argv[i]));\n        if (doc->isOk() && !doc->isEncrypted() && doc->getXRef()->getCatalog().isDict()) {\n            docs.push_back(doc);\n            if (doc->getPDFMajorVersion() > majorVersion) {\n                majorVersion = doc->getPDFMajorVersion();\n                minorVersion = doc->getPDFMinorVersion();\n            } else if (doc->getPDFMajorVersion() == majorVersion) {\n                if (doc->getPDFMinorVersion() > minorVersion) {\n                    minorVersion = doc->getPDFMinorVersion();\n                }\n            }\n        } else if (doc->isOk()) {\n            if (doc->isEncrypted()) {\n                error(errUnimplemented, -1, \"Could not merge encrypted files ('{0:s}')\", argv[i]);\n                return -1;\n            } else if (!doc->getXRef()->getCatalog().isDict()) {\n                error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary ('{0:s}')\", argv[i]);\n                return -1;\n            }\n        } else {\n            error(errSyntaxError, -1, \"Could not merge damaged documents ('{0:s}')\", argv[i]);\n            return -1;\n        }\n    }\n\n    if (!(f = fopen(fileName, \"wb\"))) {\n        error(errIO, -1, \"Could not open file '{0:s}'\", fileName);\n        return -1;\n    }\n    outStr = new FileOutStream(f, 0);\n\n    yRef = new XRef();\n    countRef = new XRef();\n    yRef->add(0, 65535, 0, false);\n    PDFDoc::writeHeader(outStr, majorVersion, minorVersion);\n\n    // handle OutputIntents, AcroForm, OCProperties & Names\n    Object intents;\n    Object names;\n    Object afObj;\n    Object ocObj;\n    if (docs.size() >= 1) {\n        Object catObj = docs[0]->getXRef()->getCatalog();\n        if (!catObj.isDict()) {\n            fclose(f);\n            delete yRef;\n            delete countRef;\n            delete outStr;\n            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n            return -1;\n        }\n        Dict *catDict = catObj.getDict();\n        intents = catDict->lookup(\"OutputIntents\");\n        afObj = catDict->lookupNF(\"AcroForm\").copy();\n        Ref *refPage = docs[0]->getCatalog()->getPageRef(1);\n        if (!afObj.isNull() && refPage) {\n            docs[0]->markAcroForm(&afObj, yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        ocObj = catDict->lookupNF(\"OCProperties\").copy();\n        if (!ocObj.isNull() && ocObj.isDict() && refPage) {\n            docs[0]->markPageObjects(ocObj.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        names = catDict->lookup(\"Names\");\n        if (!names.isNull() && names.isDict() && refPage) {\n            docs[0]->markPageObjects(names.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (i = 1; i < (int)docs.size(); i++) {\n                Object pagecatObj = docs[i]->getXRef()->getCatalog();\n                Dict *pagecatDict = pagecatObj.getDict();\n                Object pageintents = pagecatDict->lookup(\"OutputIntents\");\n                if (pageintents.isArray() && pageintents.arrayGetLength() > 0) {\n                    for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                        Object intent = intents.arrayGet(j, 0);\n                        if (intent.isDict()) {\n                            Object idf = intent.dictLookup(\"OutputConditionIdentifier\");\n                            if (idf.isString()) {\n                                const GooString *gidf = idf.getString();\n                                bool removeIntent = true;\n                                for (int k = 0; k < pageintents.arrayGetLength(); k++) {\n                                    Object pgintent = pageintents.arrayGet(k, 0);\n                                    if (pgintent.isDict()) {\n                                        Object pgidf = pgintent.dictLookup(\"OutputConditionIdentifier\");\n                                        if (pgidf.isString()) {\n                                            const GooString *gpgidf = pgidf.getString();\n                                            if (gpgidf->cmp(gidf) == 0) {\n                                                removeIntent = false;\n                                                break;\n                                            }\n                                        }\n                                    }\n                                }\n                                if (removeIntent) {\n                                    intents.arrayRemove(j);\n                                    error(errSyntaxWarning, -1, \"Output intent {0:s} missing in pdf {1:s}, removed\", gidf->c_str(), docs[i]->getFileName()->c_str());\n                                }\n                            } else {\n                                intents.arrayRemove(j);\n                                error(errSyntaxWarning, -1, \"Invalid output intent dict, missing required OutputConditionIdentifier\");\n                            }\n                        } else {\n                            intents.arrayRemove(j);\n                        }\n                    }\n                } else {\n                    error(errSyntaxWarning, -1, \"Output intents differs, remove them all\");\n                    break;\n                }\n            }\n        }\n        if (intents.isArray() && intents.arrayGetLength() > 0) {\n            for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n                Object intent = intents.arrayGet(j, 0);\n                if (intent.isDict()) {\n                    docs[0]->markPageObjects(intent.getDict(), yRef, countRef, numOffset, 0, 0);\n                } else {\n                    intents.arrayRemove(j);\n                }\n            }\n        }\n    }\n\n    for (i = 0; i < (int)docs.size(); i++) {\n        for (j = 1; j <= docs[i]->getNumPages(); j++) {\n            if (!docs[i]->getCatalog()->getPage(j)) {\n                continue;\n            }\n\n            const PDFRectangle *cropBox = nullptr;\n            if (docs[i]->getCatalog()->getPage(j)->isCropped()) {\n                cropBox = docs[i]->getCatalog()->getPage(j)->getCropBox();\n            }\n            if (!docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox)) {\n                fclose(f);\n                delete yRef;\n                delete countRef;\n                delete outStr;\n                error(errSyntaxError, -1, \"PDFDoc::replacePageDict failed.\");\n                return -1;\n            }\n            Ref *refPage = docs[i]->getCatalog()->getPageRef(j);\n            Object page = docs[i]->getXRef()->fetch(*refPage);\n            Dict *pageDict = page.getDict();\n            Object *resDict = docs[i]->getCatalog()->getPage(j)->getResourceDictObject();\n            if (resDict->isDict()) {\n                pageDict->set(\"Resources\", resDict->copy());\n            }\n            pages.push_back(std::move(page));\n            offsets.push_back(numOffset);\n            docs[i]->markPageObjects(pageDict, yRef, countRef, numOffset, refPage->num, refPage->num);\n            Object annotsObj = pageDict->lookupNF(\"Annots\").copy();\n            if (!annotsObj.isNull()) {\n                docs[i]->markAnnotations(&annotsObj, yRef, countRef, numOffset, refPage->num, refPage->num);\n            }\n        }\n        Object pageCatObj = docs[i]->getXRef()->getCatalog();\n        if (!pageCatObj.isDict()) {\n            fclose(f);\n            delete yRef;\n            delete countRef;\n            delete outStr;\n            error(errSyntaxError, -1, \"XRef's Catalog is not a dictionary.\");\n            return -1;\n        }\n        Dict *pageCatDict = pageCatObj.getDict();\n        Object pageNames = pageCatDict->lookup(\"Names\");\n        if (!pageNames.isNull() && pageNames.isDict()) {\n            if (!names.isDict()) {\n                names = Object(new Dict(yRef));\n            }\n            doMergeNameDict(docs[i], yRef, countRef, 0, 0, names.getDict(), pageNames.getDict(), numOffset);\n        }\n        Object pageForm = pageCatDict->lookup(\"AcroForm\");\n        if (i > 0 && !pageForm.isNull() && pageForm.isDict()) {\n            if (afObj.isNull()) {\n                afObj = pageCatDict->lookupNF(\"AcroForm\").copy();\n            } else if (afObj.isDict()) {\n                doMergeFormDict(afObj.getDict(), pageForm.getDict(), numOffset);\n            }\n        }\n        objectsCount += docs[i]->writePageObjects(outStr, yRef, numOffset, true);\n        numOffset = yRef->getNumObjects() + 1;\n    }\n\n    rootNum = yRef->getNumObjects() + 1;\n    yRef->add(rootNum, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum);\n    outStr->printf(\"<< /Type /Catalog /Pages %d 0 R\", rootNum + 1);\n    // insert OutputIntents\n    if (intents.isArray() && intents.arrayGetLength() > 0) {\n        outStr->printf(\" /OutputIntents [\");\n        for (j = 0; j < intents.arrayGetLength(); j++) {\n            Object intent = intents.arrayGet(j, 0);\n            if (intent.isDict()) {\n                PDFDoc::writeObject(&intent, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\"]\");\n    }\n    // insert AcroForm\n    if (!afObj.isNull()) {\n        outStr->printf(\" /AcroForm \");\n        PDFDoc::writeObject(&afObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert OCProperties\n    if (!ocObj.isNull() && ocObj.isDict()) {\n        outStr->printf(\" /OCProperties \");\n        PDFDoc::writeObject(&ocObj, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    // insert Names\n    if (!names.isNull() && names.isDict()) {\n        outStr->printf(\" /Names \");\n        PDFDoc::writeObject(&names, outStr, yRef, 0, nullptr, cryptRC4, 0, 0, 0);\n    }\n    outStr->printf(\">>\\nendobj\\n\");\n    objectsCount++;\n\n    yRef->add(rootNum + 1, 0, outStr->getPos(), true);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + 1);\n    outStr->printf(\"<< /Type /Pages /Kids [\");\n    for (j = 0; j < (int)pages.size(); j++) {\n        outStr->printf(\" %d 0 R\", rootNum + j + 2);\n    }\n    outStr->printf(\" ] /Count %zd >>\\nendobj\\n\", pages.size());\n    objectsCount++;\n\n    for (i = 0; i < (int)pages.size(); i++) {\n        yRef->add(rootNum + i + 2, 0, outStr->getPos(), true);\n        outStr->printf(\"%d 0 obj\\n\", rootNum + i + 2);\n        outStr->printf(\"<< \");\n        Dict *pageDict = pages[i].getDict();\n        for (j = 0; j < pageDict->getLength(); j++) {\n            if (j > 0) {\n                outStr->printf(\" \");\n            }\n            const char *key = pageDict->getKey(j);\n            Object value = pageDict->getValNF(j).copy();\n            if (strcmp(key, \"Parent\") == 0) {\n                outStr->printf(\"/Parent %d 0 R\", rootNum + 1);\n            } else {\n                outStr->printf(\"/%s \", key);\n                PDFDoc::writeObject(&value, outStr, yRef, offsets[i], nullptr, cryptRC4, 0, 0, 0);\n            }\n        }\n        outStr->printf(\" >>\\nendobj\\n\");\n        objectsCount++;\n    }\n    Goffset uxrefOffset = outStr->getPos();\n    Ref ref;\n    ref.num = rootNum;\n    ref.gen = 0;\n    Object trailerDict = PDFDoc::createTrailerDict(objectsCount, false, 0, &ref, yRef, fileName, outStr->getPos());\n    PDFDoc::writeXRefTableTrailer(std::move(trailerDict), yRef, true, // write all entries according to ISO 32000-1, 7.5.4 Cross-Reference Table: \"For a file that has never been incrementally updated, the cross-reference section shall\n                                                                      // contain only one subsection, whose object numbering begins at 0.\"\n                                  uxrefOffset, outStr, yRef);\n\n    outStr->close();\n    delete outStr;\n    fclose(f);\n    delete yRef;\n    delete countRef;\n    for (i = 0; i < (int)docs.size(); i++) {\n        delete docs[i];\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -166,7 +166,14 @@\n             if (docs[i]->getCatalog()->getPage(j)->isCropped()) {\n                 cropBox = docs[i]->getCatalog()->getPage(j)->getCropBox();\n             }\n-            docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox);\n+            if (!docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox)) {\n+                fclose(f);\n+                delete yRef;\n+                delete countRef;\n+                delete outStr;\n+                error(errSyntaxError, -1, \"PDFDoc::replacePageDict failed.\");\n+                return -1;\n+            }\n             Ref *refPage = docs[i]->getCatalog()->getPageRef(j);\n             Object page = docs[i]->getXRef()->fetch(*refPage);\n             Dict *pageDict = page.getDict();",
        "diff_line_info": {
            "deleted_lines": [
                "            docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox);"
            ],
            "added_lines": [
                "            if (!docs[i]->replacePageDict(j, docs[i]->getCatalog()->getPage(j)->getRotate(), docs[i]->getCatalog()->getPage(j)->getMediaBox(), cropBox)) {",
                "                fclose(f);",
                "                delete yRef;",
                "                delete countRef;",
                "                delete outStr;",
                "                error(errSyntaxError, -1, \"PDFDoc::replacePageDict failed.\");",
                "                return -1;",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-47516",
        "func_name": "davehorton/sofia-sip/tport_tsend",
        "description": "An issue was discovered in the libsofia-sip fork in drachtio-server before 0.8.20. It allows remote attackers to cause a denial of service (daemon crash) via a crafted UDP message that leads to a failure of the libsofia-sip-ua/tport/tport.c self assertion.",
        "git_url": "https://github.com/davehorton/sofia-sip/commit/13b2a135287caa2d67ac6cd5155626821e25b377",
        "commit_title": "remove assert that can reasonably be expected to happen",
        "commit_text": "",
        "func_before": "tport_t *tport_tsend(tport_t *self,\n\t\t     msg_t *msg,\n\t\t     tp_name_t const *_tpn,\n\t\t     tag_type_t tag, tag_value_t value, ...)\n{\n  ta_list ta;\n  tagi_t const *t;\n  int reuse, sdwn_after, close_after, resolved = 0, fresh;\n  unsigned mtu;\n  su_addrinfo_t *ai;\n  tport_primary_t *primary;\n  tp_name_t tpn[1];\n  struct sigcomp_compartment *cc;\n\n  assert(self);\n\n  if (!self || !msg || !_tpn) {\n    msg_set_errno(msg, EINVAL);\n    return NULL;\n  }\n\n  *tpn = *_tpn;\n\n  SU_DEBUG_7((\"tport_tsend(%p) tpn = \" TPN_FORMAT \"\\n\",\n\t      (void *)self, TPN_ARGS(tpn)));\n\n  if (tport_is_master(self)) {\n    primary = (tport_primary_t *)tport_primary_by_name(self, tpn);\n    if (!primary) {\n      msg_set_errno(msg, EPROTONOSUPPORT);\n      return NULL;\n    }\n  }\n  else {\n    primary = self->tp_pri;\n  }\n\n  ta_start(ta, tag, value);\n\n  reuse = primary->pri_primary->tp_reusable && self->tp_reusable;\n  fresh = 0;\n  sdwn_after = 0;\n  close_after = 0;\n  mtu = 0;\n  cc = NULL;\n\n  /* tl_gets() is a bit too slow here... */\n  for (t = ta_args(ta); t; t = tl_next(t)) {\n    tag_type_t tt = t->t_tag;\n\n    if (tptag_reuse == tt)\n      reuse = t->t_value != 0;\n    else if (tptag_mtu == tt)\n      mtu = t->t_value;\n    else if (tptag_sdwn_after == tt)\n      sdwn_after = t->t_value != 0;\n    else if (tptag_close_after == tt)\n      close_after = t->t_value != 0;\n    else if (tptag_fresh == tt)\n      fresh = t->t_value != 0;\n    else if (tptag_compartment == tt)\n      cc = (struct sigcomp_compartment *)t->t_value;\n  }\n\n  ta_end(ta);\n\n  fresh = fresh || !reuse;\n\n  ai = msg_addrinfo(msg);\n\n  ai->ai_flags = 0;\n\n  tpn->tpn_comp = tport_canonize_comp(tpn->tpn_comp);\n  if (tpn->tpn_comp) {\n    ai->ai_flags |= TP_AI_COMPRESSED;\n    SU_DEBUG_9((\"%s: compressed msg(%p) with %s\\n\",\n\t\t__func__, (void *)msg, tpn->tpn_comp));\n  }\n\n  if (!tpn->tpn_comp || cc == NONE)\n    cc = NULL;\n\n  if (sdwn_after)\n    ai->ai_flags |= TP_AI_SHUTDOWN;\n  if (close_after)\n    ai->ai_flags |= TP_AI_CLOSE;\n\n  if (fresh) {\n    /* Select a primary protocol, make a fresh connection */\n    self = primary->pri_primary;\n  }\n  else if (tport_is_secondary(self) && tport_is_clear_to_send(self)) {\n\t/* self = self; */\n\t;\n  }\n  /*\n   * Try to find an already open connection to the destination,\n   * or get a primary protocol\n   */\n  \n  else {\n    /* If primary, resolve the destination address, store it in the msg */\n    if (tport_resolve(primary->pri_primary, msg, tpn) < 0) {\n      return NULL;\n    }\n    resolved = 1;\n\n\n    // DCH: iterate through all primaries\n    tport_t* secondary = NULL ;\n    tport_t* tp = tport_primaries( self ) ;\n    if (tp) {\n      do {\n        secondary = tport_by_addrinfo((tport_primary_t *)tp, msg_addrinfo(msg), tpn);\n        if (secondary) break;\n      } while(NULL != (tp = tport_next(tp)));\n    }\n\n    if( secondary ) {\n      self = secondary ;\n    }\n    else {\n      self = primary->pri_primary;      \n    }\n  }\n\n  if (tport_is_primary(self)) {\n    /* If primary, resolve the destination address, store it in the msg */\n    if (!resolved && tport_resolve(self, msg, tpn) < 0) {\n      return NULL;\n    }\n\n    if (tport_is_connection_oriented(self)\n\t|| self->tp_params->tpp_conn_orient) {\n#if 0 && HAVE_UPNP /* We do not want to use UPnP with secondary transports! */\n      if (upnp_register_upnp_client(1) != 0) {\n\tupnp_check_for_nat();\n      }\n#endif\n\n      tpn->tpn_proto = self->tp_protoname;\n\n      if (!cc)\n\ttpn->tpn_comp = NULL;\n\n      /* Create a secondary transport which is connected to the destination */\n      self = tport_connect(primary, msg_addrinfo(msg), tpn);\n\n#if 0 && HAVE_UPNP /* We do not want to use UPnP with secondary transports! */\n      upnp_deregister_upnp_client(0, 0);\n#endif\n\n      if (!self) {\n\tmsg_set_errno(msg, su_errno());\n        SU_DEBUG_9((\"tport_socket failed in tsend\\n\" VA_NONE));\n\treturn NULL;\n      }\n\n      if (cc)\n\ttport_sigcomp_assign(self, cc);\n    }\n  }\n  else if (tport_is_secondary(self)) {\n    cc = tport_sigcomp_assign_if_needed(self, cc);\n  }\n\n  if (cc == NULL)\n    tpn->tpn_comp = NULL;\n\n  if (tport_is_secondary(self)) {\n    /* Set the peer address to msg */\n    tport_peer_address(self, msg);\n    if (sdwn_after || close_after)\n      self->tp_reusable = 0;\n  }\n\n  if (self->tp_pri->pri_vtable->vtp_prepare\n      ? self->tp_pri->pri_vtable->vtp_prepare(self, msg, tpn, cc, mtu) < 0\n      : tport_prepare_and_send(self, msg, tpn, cc, mtu) < 0)\n    return NULL;\n  else\n    return self;\n}",
        "func": "tport_t *tport_tsend(tport_t *self,\n\t\t     msg_t *msg,\n\t\t     tp_name_t const *_tpn,\n\t\t     tag_type_t tag, tag_value_t value, ...)\n{\n  ta_list ta;\n  tagi_t const *t;\n  int reuse, sdwn_after, close_after, resolved = 0, fresh;\n  unsigned mtu;\n  su_addrinfo_t *ai;\n  tport_primary_t *primary;\n  tp_name_t tpn[1];\n  struct sigcomp_compartment *cc;\n\n  if (!self || !msg || !_tpn) {\n    msg_set_errno(msg, EINVAL);\n    return NULL;\n  }\n\n  *tpn = *_tpn;\n\n  SU_DEBUG_7((\"tport_tsend(%p) tpn = \" TPN_FORMAT \"\\n\",\n\t      (void *)self, TPN_ARGS(tpn)));\n\n  if (tport_is_master(self)) {\n    primary = (tport_primary_t *)tport_primary_by_name(self, tpn);\n    if (!primary) {\n      msg_set_errno(msg, EPROTONOSUPPORT);\n      return NULL;\n    }\n  }\n  else {\n    primary = self->tp_pri;\n  }\n\n  ta_start(ta, tag, value);\n\n  reuse = primary->pri_primary->tp_reusable && self->tp_reusable;\n  fresh = 0;\n  sdwn_after = 0;\n  close_after = 0;\n  mtu = 0;\n  cc = NULL;\n\n  /* tl_gets() is a bit too slow here... */\n  for (t = ta_args(ta); t; t = tl_next(t)) {\n    tag_type_t tt = t->t_tag;\n\n    if (tptag_reuse == tt)\n      reuse = t->t_value != 0;\n    else if (tptag_mtu == tt)\n      mtu = t->t_value;\n    else if (tptag_sdwn_after == tt)\n      sdwn_after = t->t_value != 0;\n    else if (tptag_close_after == tt)\n      close_after = t->t_value != 0;\n    else if (tptag_fresh == tt)\n      fresh = t->t_value != 0;\n    else if (tptag_compartment == tt)\n      cc = (struct sigcomp_compartment *)t->t_value;\n  }\n\n  ta_end(ta);\n\n  fresh = fresh || !reuse;\n\n  ai = msg_addrinfo(msg);\n\n  ai->ai_flags = 0;\n\n  tpn->tpn_comp = tport_canonize_comp(tpn->tpn_comp);\n  if (tpn->tpn_comp) {\n    ai->ai_flags |= TP_AI_COMPRESSED;\n    SU_DEBUG_9((\"%s: compressed msg(%p) with %s\\n\",\n\t\t__func__, (void *)msg, tpn->tpn_comp));\n  }\n\n  if (!tpn->tpn_comp || cc == NONE)\n    cc = NULL;\n\n  if (sdwn_after)\n    ai->ai_flags |= TP_AI_SHUTDOWN;\n  if (close_after)\n    ai->ai_flags |= TP_AI_CLOSE;\n\n  if (fresh) {\n    /* Select a primary protocol, make a fresh connection */\n    self = primary->pri_primary;\n  }\n  else if (tport_is_secondary(self) && tport_is_clear_to_send(self)) {\n\t/* self = self; */\n\t;\n  }\n  /*\n   * Try to find an already open connection to the destination,\n   * or get a primary protocol\n   */\n  \n  else {\n    /* If primary, resolve the destination address, store it in the msg */\n    if (tport_resolve(primary->pri_primary, msg, tpn) < 0) {\n      return NULL;\n    }\n    resolved = 1;\n\n\n    // DCH: iterate through all primaries\n    tport_t* secondary = NULL ;\n    tport_t* tp = tport_primaries( self ) ;\n    if (tp) {\n      do {\n        secondary = tport_by_addrinfo((tport_primary_t *)tp, msg_addrinfo(msg), tpn);\n        if (secondary) break;\n      } while(NULL != (tp = tport_next(tp)));\n    }\n\n    if( secondary ) {\n      self = secondary ;\n    }\n    else {\n      self = primary->pri_primary;      \n    }\n  }\n\n  if (tport_is_primary(self)) {\n    /* If primary, resolve the destination address, store it in the msg */\n    if (!resolved && tport_resolve(self, msg, tpn) < 0) {\n      return NULL;\n    }\n\n    if (tport_is_connection_oriented(self)\n\t|| self->tp_params->tpp_conn_orient) {\n#if 0 && HAVE_UPNP /* We do not want to use UPnP with secondary transports! */\n      if (upnp_register_upnp_client(1) != 0) {\n\tupnp_check_for_nat();\n      }\n#endif\n\n      tpn->tpn_proto = self->tp_protoname;\n\n      if (!cc)\n\ttpn->tpn_comp = NULL;\n\n      /* Create a secondary transport which is connected to the destination */\n      self = tport_connect(primary, msg_addrinfo(msg), tpn);\n\n#if 0 && HAVE_UPNP /* We do not want to use UPnP with secondary transports! */\n      upnp_deregister_upnp_client(0, 0);\n#endif\n\n      if (!self) {\n\tmsg_set_errno(msg, su_errno());\n        SU_DEBUG_9((\"tport_socket failed in tsend\\n\" VA_NONE));\n\treturn NULL;\n      }\n\n      if (cc)\n\ttport_sigcomp_assign(self, cc);\n    }\n  }\n  else if (tport_is_secondary(self)) {\n    cc = tport_sigcomp_assign_if_needed(self, cc);\n  }\n\n  if (cc == NULL)\n    tpn->tpn_comp = NULL;\n\n  if (tport_is_secondary(self)) {\n    /* Set the peer address to msg */\n    tport_peer_address(self, msg);\n    if (sdwn_after || close_after)\n      self->tp_reusable = 0;\n  }\n\n  if (self->tp_pri->pri_vtable->vtp_prepare\n      ? self->tp_pri->pri_vtable->vtp_prepare(self, msg, tpn, cc, mtu) < 0\n      : tport_prepare_and_send(self, msg, tpn, cc, mtu) < 0)\n    return NULL;\n  else\n    return self;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,8 +11,6 @@\n   tport_primary_t *primary;\n   tp_name_t tpn[1];\n   struct sigcomp_compartment *cc;\n-\n-  assert(self);\n \n   if (!self || !msg || !_tpn) {\n     msg_set_errno(msg, EINVAL);",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "  assert(self);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2018-12504",
        "func_name": "syoyo/tinyexr/ComputeChannelLayout",
        "description": "tinyexr 0.9.5 has an assertion failure in ComputeChannelLayout in tinyexr.h.",
        "git_url": "https://github.com/syoyo/tinyexr/commit/5d3505a67ffe2e003ae907e31ec7bddad19537dd",
        "commit_title": "Turn assert() into error. Fixes #82",
        "commit_text": "",
        "func_before": "static void ComputeChannelLayout(std::vector<size_t> *channel_offset_list,\n                                 int *pixel_data_size, size_t *channel_offset,\n                                 int num_channels,\n                                 const EXRChannelInfo *channels) {\n  channel_offset_list->resize(static_cast<size_t>(num_channels));\n\n  (*pixel_data_size) = 0;\n  (*channel_offset) = 0;\n\n  for (size_t c = 0; c < static_cast<size_t>(num_channels); c++) {\n    (*channel_offset_list)[c] = (*channel_offset);\n    if (channels[c].pixel_type == TINYEXR_PIXELTYPE_HALF) {\n      (*pixel_data_size) += sizeof(unsigned short);\n      (*channel_offset) += sizeof(unsigned short);\n    } else if (channels[c].pixel_type == TINYEXR_PIXELTYPE_FLOAT) {\n      (*pixel_data_size) += sizeof(float);\n      (*channel_offset) += sizeof(float);\n    } else if (channels[c].pixel_type == TINYEXR_PIXELTYPE_UINT) {\n      (*pixel_data_size) += sizeof(unsigned int);\n      (*channel_offset) += sizeof(unsigned int);\n    } else {\n      assert(0);\n    }\n  }\n}",
        "func": "static bool ComputeChannelLayout(std::vector<size_t> *channel_offset_list,\n                                 int *pixel_data_size, size_t *channel_offset,\n                                 int num_channels,\n                                 const EXRChannelInfo *channels) {\n  channel_offset_list->resize(static_cast<size_t>(num_channels));\n\n  (*pixel_data_size) = 0;\n  (*channel_offset) = 0;\n\n  for (size_t c = 0; c < static_cast<size_t>(num_channels); c++) {\n    (*channel_offset_list)[c] = (*channel_offset);\n    if (channels[c].pixel_type == TINYEXR_PIXELTYPE_HALF) {\n      (*pixel_data_size) += sizeof(unsigned short);\n      (*channel_offset) += sizeof(unsigned short);\n    } else if (channels[c].pixel_type == TINYEXR_PIXELTYPE_FLOAT) {\n      (*pixel_data_size) += sizeof(float);\n      (*channel_offset) += sizeof(float);\n    } else if (channels[c].pixel_type == TINYEXR_PIXELTYPE_UINT) {\n      (*pixel_data_size) += sizeof(unsigned int);\n      (*channel_offset) += sizeof(unsigned int);\n    } else {\n      // ???\n      return false;\n    }\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-static void ComputeChannelLayout(std::vector<size_t> *channel_offset_list,\n+static bool ComputeChannelLayout(std::vector<size_t> *channel_offset_list,\n                                  int *pixel_data_size, size_t *channel_offset,\n                                  int num_channels,\n                                  const EXRChannelInfo *channels) {\n@@ -19,7 +19,9 @@\n       (*pixel_data_size) += sizeof(unsigned int);\n       (*channel_offset) += sizeof(unsigned int);\n     } else {\n-      assert(0);\n+      // ???\n+      return false;\n     }\n   }\n+  return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static void ComputeChannelLayout(std::vector<size_t> *channel_offset_list,",
                "      assert(0);"
            ],
            "added_lines": [
                "static bool ComputeChannelLayout(std::vector<size_t> *channel_offset_list,",
                "      // ???",
                "      return false;",
                "  return true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-12504",
        "func_name": "syoyo/tinyexr/LoadEXR",
        "description": "tinyexr 0.9.5 has an assertion failure in ComputeChannelLayout in tinyexr.h.",
        "git_url": "https://github.com/syoyo/tinyexr/commit/5d3505a67ffe2e003ae907e31ec7bddad19537dd",
        "commit_title": "Turn assert() into error. Fixes #82",
        "commit_text": "",
        "func_before": "int LoadEXR(float **out_rgba, int *width, int *height, const char *filename,\n            const char **err) {\n  if (out_rgba == NULL) {\n    tinyexr::SetErrorMessage(\"Invalid argument for LoadEXR()\", err);\n    return TINYEXR_ERROR_INVALID_ARGUMENT;\n  }\n\n  EXRVersion exr_version;\n  EXRImage exr_image;\n  EXRHeader exr_header;\n  InitEXRHeader(&exr_header);\n  InitEXRImage(&exr_image);\n\n  {\n    int ret = ParseEXRVersionFromFile(&exr_version, filename);\n    if (ret != TINYEXR_SUCCESS) {\n      return ret;\n    }\n\n    if (exr_version.multipart || exr_version.non_image) {\n      tinyexr::SetErrorMessage(\"Loading multipart or DeepImage is not supported  in LoadEXR() API\", err);\n      return TINYEXR_ERROR_INVALID_DATA;  // @fixme.\n    }\n  }\n\n  {\n    int ret = ParseEXRHeaderFromFile(&exr_header, &exr_version, filename, err);\n    if (ret != TINYEXR_SUCCESS) {\n      FreeEXRHeader(&exr_header);\n      return ret;\n    }\n  }\n\n  // Read HALF channel as FLOAT.\n  for (int i = 0; i < exr_header.num_channels; i++) {\n    if (exr_header.pixel_types[i] == TINYEXR_PIXELTYPE_HALF) {\n      exr_header.requested_pixel_types[i] = TINYEXR_PIXELTYPE_FLOAT;\n    }\n  }\n\n  {\n    int ret = LoadEXRImageFromFile(&exr_image, &exr_header, filename, err);\n    if (ret != TINYEXR_SUCCESS) {\n      return ret;\n    }\n  }\n\n  // RGBA\n  int idxR = -1;\n  int idxG = -1;\n  int idxB = -1;\n  int idxA = -1;\n  for (int c = 0; c < exr_header.num_channels; c++) {\n    if (strcmp(exr_header.channels[c].name, \"R\") == 0) {\n      idxR = c;\n    } else if (strcmp(exr_header.channels[c].name, \"G\") == 0) {\n      idxG = c;\n    } else if (strcmp(exr_header.channels[c].name, \"B\") == 0) {\n      idxB = c;\n    } else if (strcmp(exr_header.channels[c].name, \"A\") == 0) {\n      idxA = c;\n    }\n  }\n\n  if ((idxA == 0) && (idxR == -1) && (idxG == -1) && (idxB == -1)) {\n    // Alpha channel only.\n\n    if (exr_header.tiled) {\n      // todo.implement this\n    }\n    (*out_rgba) = reinterpret_cast<float *>(\n        malloc(4 * sizeof(float) * static_cast<size_t>(exr_image.width) *\n               static_cast<size_t>(exr_image.height)));\n    for (int i = 0; i < exr_image.width * exr_image.height; i++) {\n      const float val = reinterpret_cast<float **>(exr_image.images)[0][i];\n      (*out_rgba)[4 * i + 0] = val;\n      (*out_rgba)[4 * i + 1] = val;\n      (*out_rgba)[4 * i + 2] = val;\n      (*out_rgba)[4 * i + 3] = val;\n    }\n  } else {\n    // Assume RGB(A)\n\n    if (idxR == -1) {\n      tinyexr::SetErrorMessage(\"R channel not found\", err);\n\n      // @todo { free exr_image }\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    if (idxG == -1) {\n      tinyexr::SetErrorMessage(\"G channel not found\", err);\n      // @todo { free exr_image }\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    if (idxB == -1) {\n      tinyexr::SetErrorMessage(\"B channel not found\", err);\n      // @todo { free exr_image }\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    (*out_rgba) = reinterpret_cast<float *>(\n        malloc(4 * sizeof(float) * static_cast<size_t>(exr_image.width) *\n               static_cast<size_t>(exr_image.height)));\n    if (exr_header.tiled) {\n      for (int it = 0; it < exr_image.num_tiles; it++) {\n        for (int j = 0; j < exr_header.tile_size_y; j++)\n          for (int i = 0; i < exr_header.tile_size_x; i++) {\n            const int ii =\n                exr_image.tiles[it].offset_x * exr_header.tile_size_x + i;\n            const int jj =\n                exr_image.tiles[it].offset_y * exr_header.tile_size_y + j;\n            const int idx = ii + jj * exr_image.width;\n\n            // out of region check.\n            if (ii >= exr_image.width) {\n              continue;\n            }\n            if (jj >= exr_image.height) {\n              continue;\n            }\n            const int srcIdx = i + j * exr_header.tile_size_x;\n            unsigned char **src = exr_image.tiles[it].images;\n            (*out_rgba)[4 * idx + 0] =\n                reinterpret_cast<float **>(src)[idxR][srcIdx];\n            (*out_rgba)[4 * idx + 1] =\n                reinterpret_cast<float **>(src)[idxG][srcIdx];\n            (*out_rgba)[4 * idx + 2] =\n                reinterpret_cast<float **>(src)[idxB][srcIdx];\n            if (idxA != -1) {\n              (*out_rgba)[4 * idx + 3] =\n                  reinterpret_cast<float **>(src)[idxA][srcIdx];\n            } else {\n              (*out_rgba)[4 * idx + 3] = 1.0;\n            }\n          }\n      }\n    } else {\n      for (int i = 0; i < exr_image.width * exr_image.height; i++) {\n        (*out_rgba)[4 * i + 0] =\n            reinterpret_cast<float **>(exr_image.images)[idxR][i];\n        (*out_rgba)[4 * i + 1] =\n            reinterpret_cast<float **>(exr_image.images)[idxG][i];\n        (*out_rgba)[4 * i + 2] =\n            reinterpret_cast<float **>(exr_image.images)[idxB][i];\n        if (idxA != -1) {\n          (*out_rgba)[4 * i + 3] =\n              reinterpret_cast<float **>(exr_image.images)[idxA][i];\n        } else {\n          (*out_rgba)[4 * i + 3] = 1.0;\n        }\n      }\n    }\n  }\n\n  (*width) = exr_image.width;\n  (*height) = exr_image.height;\n\n  FreeEXRHeader(&exr_header);\n  FreeEXRImage(&exr_image);\n\n  return TINYEXR_SUCCESS;\n}",
        "func": "int LoadEXR(float **out_rgba, int *width, int *height, const char *filename,\n            const char **err) {\n  if (out_rgba == NULL) {\n    tinyexr::SetErrorMessage(\"Invalid argument for LoadEXR()\", err);\n    return TINYEXR_ERROR_INVALID_ARGUMENT;\n  }\n\n  EXRVersion exr_version;\n  EXRImage exr_image;\n  EXRHeader exr_header;\n  InitEXRHeader(&exr_header);\n  InitEXRImage(&exr_image);\n\n  {\n    int ret = ParseEXRVersionFromFile(&exr_version, filename);\n    if (ret != TINYEXR_SUCCESS) {\n      return ret;\n    }\n\n    if (exr_version.multipart || exr_version.non_image) {\n      tinyexr::SetErrorMessage(\"Loading multipart or DeepImage is not supported  in LoadEXR() API\", err);\n      return TINYEXR_ERROR_INVALID_DATA;  // @fixme.\n    }\n  }\n\n  {\n    int ret = ParseEXRHeaderFromFile(&exr_header, &exr_version, filename, err);\n    if (ret != TINYEXR_SUCCESS) {\n      FreeEXRHeader(&exr_header);\n      return ret;\n    }\n  }\n\n  // Read HALF channel as FLOAT.\n  for (int i = 0; i < exr_header.num_channels; i++) {\n    if (exr_header.pixel_types[i] == TINYEXR_PIXELTYPE_HALF) {\n      exr_header.requested_pixel_types[i] = TINYEXR_PIXELTYPE_FLOAT;\n    }\n  }\n\n  {\n    int ret = LoadEXRImageFromFile(&exr_image, &exr_header, filename, err);\n    if (ret != TINYEXR_SUCCESS) {\n      FreeEXRHeader(&exr_header);\n      return ret;\n    }\n  }\n\n  // RGBA\n  int idxR = -1;\n  int idxG = -1;\n  int idxB = -1;\n  int idxA = -1;\n  for (int c = 0; c < exr_header.num_channels; c++) {\n    if (strcmp(exr_header.channels[c].name, \"R\") == 0) {\n      idxR = c;\n    } else if (strcmp(exr_header.channels[c].name, \"G\") == 0) {\n      idxG = c;\n    } else if (strcmp(exr_header.channels[c].name, \"B\") == 0) {\n      idxB = c;\n    } else if (strcmp(exr_header.channels[c].name, \"A\") == 0) {\n      idxA = c;\n    }\n  }\n\n  if ((idxA == 0) && (idxR == -1) && (idxG == -1) && (idxB == -1)) {\n    // Alpha channel only.\n\n    if (exr_header.tiled) {\n      // todo.implement this\n    }\n    (*out_rgba) = reinterpret_cast<float *>(\n        malloc(4 * sizeof(float) * static_cast<size_t>(exr_image.width) *\n               static_cast<size_t>(exr_image.height)));\n    for (int i = 0; i < exr_image.width * exr_image.height; i++) {\n      const float val = reinterpret_cast<float **>(exr_image.images)[0][i];\n      (*out_rgba)[4 * i + 0] = val;\n      (*out_rgba)[4 * i + 1] = val;\n      (*out_rgba)[4 * i + 2] = val;\n      (*out_rgba)[4 * i + 3] = val;\n    }\n  } else {\n    // Assume RGB(A)\n\n    if (idxR == -1) {\n      tinyexr::SetErrorMessage(\"R channel not found\", err);\n\n      // @todo { free exr_image }\n      FreeEXRHeader(&exr_header);\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    if (idxG == -1) {\n      tinyexr::SetErrorMessage(\"G channel not found\", err);\n      // @todo { free exr_image }\n      FreeEXRHeader(&exr_header);\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    if (idxB == -1) {\n      tinyexr::SetErrorMessage(\"B channel not found\", err);\n      // @todo { free exr_image }\n      FreeEXRHeader(&exr_header);\n      return TINYEXR_ERROR_INVALID_DATA;\n    }\n\n    (*out_rgba) = reinterpret_cast<float *>(\n        malloc(4 * sizeof(float) * static_cast<size_t>(exr_image.width) *\n               static_cast<size_t>(exr_image.height)));\n    if (exr_header.tiled) {\n      for (int it = 0; it < exr_image.num_tiles; it++) {\n        for (int j = 0; j < exr_header.tile_size_y; j++)\n          for (int i = 0; i < exr_header.tile_size_x; i++) {\n            const int ii =\n                exr_image.tiles[it].offset_x * exr_header.tile_size_x + i;\n            const int jj =\n                exr_image.tiles[it].offset_y * exr_header.tile_size_y + j;\n            const int idx = ii + jj * exr_image.width;\n\n            // out of region check.\n            if (ii >= exr_image.width) {\n              continue;\n            }\n            if (jj >= exr_image.height) {\n              continue;\n            }\n            const int srcIdx = i + j * exr_header.tile_size_x;\n            unsigned char **src = exr_image.tiles[it].images;\n            (*out_rgba)[4 * idx + 0] =\n                reinterpret_cast<float **>(src)[idxR][srcIdx];\n            (*out_rgba)[4 * idx + 1] =\n                reinterpret_cast<float **>(src)[idxG][srcIdx];\n            (*out_rgba)[4 * idx + 2] =\n                reinterpret_cast<float **>(src)[idxB][srcIdx];\n            if (idxA != -1) {\n              (*out_rgba)[4 * idx + 3] =\n                  reinterpret_cast<float **>(src)[idxA][srcIdx];\n            } else {\n              (*out_rgba)[4 * idx + 3] = 1.0;\n            }\n          }\n      }\n    } else {\n      for (int i = 0; i < exr_image.width * exr_image.height; i++) {\n        (*out_rgba)[4 * i + 0] =\n            reinterpret_cast<float **>(exr_image.images)[idxR][i];\n        (*out_rgba)[4 * i + 1] =\n            reinterpret_cast<float **>(exr_image.images)[idxG][i];\n        (*out_rgba)[4 * i + 2] =\n            reinterpret_cast<float **>(exr_image.images)[idxB][i];\n        if (idxA != -1) {\n          (*out_rgba)[4 * i + 3] =\n              reinterpret_cast<float **>(exr_image.images)[idxA][i];\n        } else {\n          (*out_rgba)[4 * i + 3] = 1.0;\n        }\n      }\n    }\n  }\n\n  (*width) = exr_image.width;\n  (*height) = exr_image.height;\n\n  FreeEXRHeader(&exr_header);\n  FreeEXRImage(&exr_image);\n\n  return TINYEXR_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -41,6 +41,7 @@\n   {\n     int ret = LoadEXRImageFromFile(&exr_image, &exr_header, filename, err);\n     if (ret != TINYEXR_SUCCESS) {\n+      FreeEXRHeader(&exr_header);\n       return ret;\n     }\n   }\n@@ -85,18 +86,21 @@\n       tinyexr::SetErrorMessage(\"R channel not found\", err);\n \n       // @todo { free exr_image }\n+      FreeEXRHeader(&exr_header);\n       return TINYEXR_ERROR_INVALID_DATA;\n     }\n \n     if (idxG == -1) {\n       tinyexr::SetErrorMessage(\"G channel not found\", err);\n       // @todo { free exr_image }\n+      FreeEXRHeader(&exr_header);\n       return TINYEXR_ERROR_INVALID_DATA;\n     }\n \n     if (idxB == -1) {\n       tinyexr::SetErrorMessage(\"B channel not found\", err);\n       // @todo { free exr_image }\n+      FreeEXRHeader(&exr_header);\n       return TINYEXR_ERROR_INVALID_DATA;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      FreeEXRHeader(&exr_header);",
                "      FreeEXRHeader(&exr_header);",
                "      FreeEXRHeader(&exr_header);",
                "      FreeEXRHeader(&exr_header);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-12504",
        "func_name": "syoyo/tinyexr/DecodeChunk",
        "description": "tinyexr 0.9.5 has an assertion failure in ComputeChannelLayout in tinyexr.h.",
        "git_url": "https://github.com/syoyo/tinyexr/commit/5d3505a67ffe2e003ae907e31ec7bddad19537dd",
        "commit_title": "Turn assert() into error. Fixes #82",
        "commit_text": "",
        "func_before": "static int DecodeChunk(EXRImage *exr_image, const EXRHeader *exr_header,\n                       const std::vector<tinyexr::tinyexr_uint64> &offsets,\n                       const unsigned char *head, const size_t size) {\n  int num_channels = exr_header->num_channels;\n\n  int num_scanline_blocks = 1;\n  if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZIP) {\n    num_scanline_blocks = 16;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_PIZ) {\n    num_scanline_blocks = 32;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZFP) {\n    num_scanline_blocks = 16;\n  }\n\n  int data_width = exr_header->data_window[2] - exr_header->data_window[0] + 1;\n  int data_height = exr_header->data_window[3] - exr_header->data_window[1] + 1;\n\n  size_t num_blocks = offsets.size();\n\n  std::vector<size_t> channel_offset_list;\n  int pixel_data_size = 0;\n  size_t channel_offset = 0;\n  tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,\n                                &channel_offset, num_channels,\n                                exr_header->channels);\n\n  bool invalid_data = false;  // TODO(LTE): Use atomic lock for MT safety.\n\n  if (exr_header->tiled) {\n    size_t num_tiles = offsets.size();  // = # of blocks\n\n    exr_image->tiles = static_cast<EXRTile *>(\n        calloc(sizeof(EXRTile), static_cast<size_t>(num_tiles)));\n\n    for (size_t tile_idx = 0; tile_idx < num_tiles; tile_idx++) {\n      // Allocate memory for each tile.\n      exr_image->tiles[tile_idx].images = tinyexr::AllocateImage(\n          num_channels, exr_header->channels, exr_header->requested_pixel_types,\n          exr_header->tile_size_x, exr_header->tile_size_y);\n\n      // 16 byte: tile coordinates\n      // 4 byte : data size\n      // ~      : data(uncompressed or compressed)\n      if (offsets[tile_idx] + sizeof(int) * 5 > size) {\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      size_t data_size = size_t(size - (offsets[tile_idx] + sizeof(int) * 5));\n      const unsigned char *data_ptr =\n          reinterpret_cast<const unsigned char *>(head + offsets[tile_idx]);\n\n      int tile_coordinates[4];\n      memcpy(tile_coordinates, data_ptr, sizeof(int) * 4);\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[0]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[1]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[2]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[3]));\n\n      // @todo{ LoD }\n      if (tile_coordinates[2] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n      if (tile_coordinates[3] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n\n      int data_len;\n      memcpy(&data_len, data_ptr + 16,\n             sizeof(int));  // 16 = sizeof(tile_coordinates)\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n      if (data_len < 4 || size_t(data_len) > data_size) {\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      // Move to data addr: 20 = 16 + 4;\n      data_ptr += 20;\n\n      tinyexr::DecodeTiledPixelData(\n          exr_image->tiles[tile_idx].images,\n          &(exr_image->tiles[tile_idx].width),\n          &(exr_image->tiles[tile_idx].height),\n          exr_header->requested_pixel_types, data_ptr,\n          static_cast<size_t>(data_len), exr_header->compression_type,\n          exr_header->line_order, data_width, data_height, tile_coordinates[0],\n          tile_coordinates[1], exr_header->tile_size_x, exr_header->tile_size_y,\n          static_cast<size_t>(pixel_data_size),\n          static_cast<size_t>(exr_header->num_custom_attributes),\n          exr_header->custom_attributes,\n          static_cast<size_t>(exr_header->num_channels), exr_header->channels,\n          channel_offset_list);\n\n      exr_image->tiles[tile_idx].offset_x = tile_coordinates[0];\n      exr_image->tiles[tile_idx].offset_y = tile_coordinates[1];\n      exr_image->tiles[tile_idx].level_x = tile_coordinates[2];\n      exr_image->tiles[tile_idx].level_y = tile_coordinates[3];\n\n      exr_image->num_tiles = static_cast<int>(num_tiles);\n    }\n  } else {  // scanline format\n\n    exr_image->images = tinyexr::AllocateImage(\n        num_channels, exr_header->channels, exr_header->requested_pixel_types,\n        data_width, data_height);\n\n#ifdef _OPENMP\n#pragma omp parallel for\n#endif\n    for (int y = 0; y < static_cast<int>(num_blocks); y++) {\n      size_t y_idx = static_cast<size_t>(y);\n\n      if (offsets[y_idx] + sizeof(int) * 2 > size) {\n        invalid_data = true;\n      } else {\n        // 4 byte: scan line\n        // 4 byte: data size\n        // ~     : pixel data(uncompressed or compressed)\n        size_t data_size = size_t(size - (offsets[y_idx] + sizeof(int) * 2));\n        const unsigned char *data_ptr =\n            reinterpret_cast<const unsigned char *>(head + offsets[y_idx]);\n\n        int line_no;\n        memcpy(&line_no, data_ptr, sizeof(int));\n        int data_len;\n        memcpy(&data_len, data_ptr + 4, sizeof(int));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&line_no));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n        if (size_t(data_len) > data_size) {\n          invalid_data = true;\n        } else {\n          int end_line_no = (std::min)(line_no + num_scanline_blocks,\n                                       (exr_header->data_window[3] + 1));\n\n          int num_lines = end_line_no - line_no;\n          // assert(num_lines > 0);\n\n          if (num_lines <= 0) {\n            invalid_data = true;\n          } else {\n            // Move to data addr: 8 = 4 + 4;\n            data_ptr += 8;\n\n            // Adjust line_no with data_window.bmin.y\n            line_no -= exr_header->data_window[1];\n\n            if (line_no < 0) {\n              invalid_data = true;\n            } else {\n              if (!tinyexr::DecodePixelData(\n                      exr_image->images, exr_header->requested_pixel_types,\n                      data_ptr, static_cast<size_t>(data_len),\n                      exr_header->compression_type, exr_header->line_order,\n                      data_width, data_height, data_width, y, line_no,\n                      num_lines, static_cast<size_t>(pixel_data_size),\n                      static_cast<size_t>(exr_header->num_custom_attributes),\n                      exr_header->custom_attributes,\n                      static_cast<size_t>(exr_header->num_channels),\n                      exr_header->channels, channel_offset_list)) {\n                invalid_data = true;\n              }\n            }\n          }\n        }\n      }\n    }  // omp parallel\n  }\n\n  if (invalid_data) {\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  // Overwrite `pixel_type` with `requested_pixel_type`.\n  {\n    for (int c = 0; c < exr_header->num_channels; c++) {\n      exr_header->pixel_types[c] = exr_header->requested_pixel_types[c];\n    }\n  }\n\n  {\n    exr_image->num_channels = num_channels;\n\n    exr_image->width = data_width;\n    exr_image->height = data_height;\n  }\n\n  return TINYEXR_SUCCESS;\n}",
        "func": "static int DecodeChunk(EXRImage *exr_image, const EXRHeader *exr_header,\n                       const std::vector<tinyexr::tinyexr_uint64> &offsets,\n                       const unsigned char *head, const size_t size) {\n  int num_channels = exr_header->num_channels;\n\n  int num_scanline_blocks = 1;\n  if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZIP) {\n    num_scanline_blocks = 16;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_PIZ) {\n    num_scanline_blocks = 32;\n  } else if (exr_header->compression_type == TINYEXR_COMPRESSIONTYPE_ZFP) {\n    num_scanline_blocks = 16;\n  }\n\n  int data_width = exr_header->data_window[2] - exr_header->data_window[0] + 1;\n  int data_height = exr_header->data_window[3] - exr_header->data_window[1] + 1;\n\n  size_t num_blocks = offsets.size();\n\n  std::vector<size_t> channel_offset_list;\n  int pixel_data_size = 0;\n  size_t channel_offset = 0;\n  if (!tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,\n                                &channel_offset, num_channels,\n                                exr_header->channels)) {\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  bool invalid_data = false;  // TODO(LTE): Use atomic lock for MT safety.\n\n  if (exr_header->tiled) {\n    size_t num_tiles = offsets.size();  // = # of blocks\n\n    exr_image->tiles = static_cast<EXRTile *>(\n        calloc(sizeof(EXRTile), static_cast<size_t>(num_tiles)));\n\n    for (size_t tile_idx = 0; tile_idx < num_tiles; tile_idx++) {\n      // Allocate memory for each tile.\n      exr_image->tiles[tile_idx].images = tinyexr::AllocateImage(\n          num_channels, exr_header->channels, exr_header->requested_pixel_types,\n          exr_header->tile_size_x, exr_header->tile_size_y);\n\n      // 16 byte: tile coordinates\n      // 4 byte : data size\n      // ~      : data(uncompressed or compressed)\n      if (offsets[tile_idx] + sizeof(int) * 5 > size) {\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      size_t data_size = size_t(size - (offsets[tile_idx] + sizeof(int) * 5));\n      const unsigned char *data_ptr =\n          reinterpret_cast<const unsigned char *>(head + offsets[tile_idx]);\n\n      int tile_coordinates[4];\n      memcpy(tile_coordinates, data_ptr, sizeof(int) * 4);\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[0]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[1]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[2]));\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&tile_coordinates[3]));\n\n      // @todo{ LoD }\n      if (tile_coordinates[2] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n      if (tile_coordinates[3] != 0) {\n        return TINYEXR_ERROR_UNSUPPORTED_FEATURE;\n      }\n\n      int data_len;\n      memcpy(&data_len, data_ptr + 16,\n             sizeof(int));  // 16 = sizeof(tile_coordinates)\n      tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n      if (data_len < 4 || size_t(data_len) > data_size) {\n        return TINYEXR_ERROR_INVALID_DATA;\n      }\n\n      // Move to data addr: 20 = 16 + 4;\n      data_ptr += 20;\n\n      tinyexr::DecodeTiledPixelData(\n          exr_image->tiles[tile_idx].images,\n          &(exr_image->tiles[tile_idx].width),\n          &(exr_image->tiles[tile_idx].height),\n          exr_header->requested_pixel_types, data_ptr,\n          static_cast<size_t>(data_len), exr_header->compression_type,\n          exr_header->line_order, data_width, data_height, tile_coordinates[0],\n          tile_coordinates[1], exr_header->tile_size_x, exr_header->tile_size_y,\n          static_cast<size_t>(pixel_data_size),\n          static_cast<size_t>(exr_header->num_custom_attributes),\n          exr_header->custom_attributes,\n          static_cast<size_t>(exr_header->num_channels), exr_header->channels,\n          channel_offset_list);\n\n      exr_image->tiles[tile_idx].offset_x = tile_coordinates[0];\n      exr_image->tiles[tile_idx].offset_y = tile_coordinates[1];\n      exr_image->tiles[tile_idx].level_x = tile_coordinates[2];\n      exr_image->tiles[tile_idx].level_y = tile_coordinates[3];\n\n      exr_image->num_tiles = static_cast<int>(num_tiles);\n    }\n  } else {  // scanline format\n\n    exr_image->images = tinyexr::AllocateImage(\n        num_channels, exr_header->channels, exr_header->requested_pixel_types,\n        data_width, data_height);\n\n#ifdef _OPENMP\n#pragma omp parallel for\n#endif\n    for (int y = 0; y < static_cast<int>(num_blocks); y++) {\n      size_t y_idx = static_cast<size_t>(y);\n\n      if (offsets[y_idx] + sizeof(int) * 2 > size) {\n        invalid_data = true;\n      } else {\n        // 4 byte: scan line\n        // 4 byte: data size\n        // ~     : pixel data(uncompressed or compressed)\n        size_t data_size = size_t(size - (offsets[y_idx] + sizeof(int) * 2));\n        const unsigned char *data_ptr =\n            reinterpret_cast<const unsigned char *>(head + offsets[y_idx]);\n\n        int line_no;\n        memcpy(&line_no, data_ptr, sizeof(int));\n        int data_len;\n        memcpy(&data_len, data_ptr + 4, sizeof(int));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&line_no));\n        tinyexr::swap4(reinterpret_cast<unsigned int *>(&data_len));\n\n        if (size_t(data_len) > data_size) {\n          invalid_data = true;\n        } else {\n          int end_line_no = (std::min)(line_no + num_scanline_blocks,\n                                       (exr_header->data_window[3] + 1));\n\n          int num_lines = end_line_no - line_no;\n          // assert(num_lines > 0);\n\n          if (num_lines <= 0) {\n            invalid_data = true;\n          } else {\n            // Move to data addr: 8 = 4 + 4;\n            data_ptr += 8;\n\n            // Adjust line_no with data_window.bmin.y\n            line_no -= exr_header->data_window[1];\n\n            if (line_no < 0) {\n              invalid_data = true;\n            } else {\n              if (!tinyexr::DecodePixelData(\n                      exr_image->images, exr_header->requested_pixel_types,\n                      data_ptr, static_cast<size_t>(data_len),\n                      exr_header->compression_type, exr_header->line_order,\n                      data_width, data_height, data_width, y, line_no,\n                      num_lines, static_cast<size_t>(pixel_data_size),\n                      static_cast<size_t>(exr_header->num_custom_attributes),\n                      exr_header->custom_attributes,\n                      static_cast<size_t>(exr_header->num_channels),\n                      exr_header->channels, channel_offset_list)) {\n                invalid_data = true;\n              }\n            }\n          }\n        }\n      }\n    }  // omp parallel\n  }\n\n  if (invalid_data) {\n    return TINYEXR_ERROR_INVALID_DATA;\n  }\n\n  // Overwrite `pixel_type` with `requested_pixel_type`.\n  {\n    for (int c = 0; c < exr_header->num_channels; c++) {\n      exr_header->pixel_types[c] = exr_header->requested_pixel_types[c];\n    }\n  }\n\n  {\n    exr_image->num_channels = num_channels;\n\n    exr_image->width = data_width;\n    exr_image->height = data_height;\n  }\n\n  return TINYEXR_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,9 +20,11 @@\n   std::vector<size_t> channel_offset_list;\n   int pixel_data_size = 0;\n   size_t channel_offset = 0;\n-  tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,\n+  if (!tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,\n                                 &channel_offset, num_channels,\n-                                exr_header->channels);\n+                                exr_header->channels)) {\n+    return TINYEXR_ERROR_INVALID_DATA;\n+  }\n \n   bool invalid_data = false;  // TODO(LTE): Use atomic lock for MT safety.\n ",
        "diff_line_info": {
            "deleted_lines": [
                "  tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,",
                "                                exr_header->channels);"
            ],
            "added_lines": [
                "  if (!tinyexr::ComputeChannelLayout(&channel_offset_list, &pixel_data_size,",
                "                                exr_header->channels)) {",
                "    return TINYEXR_ERROR_INVALID_DATA;",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46784",
        "func_name": "squid-cache/squid/gopherToHTML",
        "description": "In Squid 3.x through 3.5.28, 4.x through 4.17, and 5.x before 5.6, due to improper buffer management, a Denial of Service can occur when processing long Gopher server responses.",
        "git_url": "https://github.com/squid-cache/squid/commit/5e2ea2b13bd98f53e29964ca26bb0d602a8a12b9",
        "commit_title": "Improve handling of Gopher responses (#1022)",
        "commit_text": "",
        "func_before": "static void\ngopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    String outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n            gopherState->overflowed = true; // may already be true\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    case GOPHER_WWW:\n                        icon_url = mimeGetIconURL(\"internal-link\");\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, escaped_selector, rfc1738_escape_part(host),\n                                     *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                     port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                     icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else if (gtype == GOPHER_WWW) {\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                    outbuf.append(tmpbuf);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n                }\n\n                outbuf.append(tmpbuf);\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    outbuf.append(tmpbuf);\n                    break;\n                }\n\n                }\n            }\n\n            break;\n            }           /* HTML_CSO_RESULT */\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.size() > 0) {\n        entry->append(outbuf.rawBuf(), outbuf.size());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    outbuf.clean();\n    return;\n}",
        "func": "static void\ngopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    SBuf outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n            gopherState->overflowed = true; // may already be true\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    case GOPHER_WWW:\n                        icon_url = mimeGetIconURL(\"internal-link\");\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, escaped_selector, rfc1738_escape_part(host),\n                                     *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                     port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        outbuf.appendf(\"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                     icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else if (gtype == GOPHER_WWW) {\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    outbuf.appendf(\"%s\\n\", html_quote(result));\n                }\n\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    break;\n                }\n\n                }\n            }\n\n            break;\n            }           /* HTML_CSO_RESULT */\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.length() > 0) {\n        entry->append(outbuf.rawContent(), outbuf.length());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,6 @@\n     char *lpos = NULL;\n     char *tline = NULL;\n     LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n-    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n     char *name = NULL;\n     char *selector = NULL;\n     char *host = NULL;\n@@ -15,7 +14,6 @@\n     char gtype;\n     StoreEntry *entry = NULL;\n \n-    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n     memset(line, '\\0', TEMP_BUF_SIZE);\n \n     entry = gopherState->entry;\n@@ -50,7 +48,7 @@\n         return;\n     }\n \n-    String outbuf;\n+    SBuf outbuf;\n \n     if (!gopherState->HTML_header_added) {\n         if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n@@ -222,37 +220,34 @@\n                         break;\n                     }\n \n-                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n-\n                     if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                         if (strlen(escaped_selector) != 0)\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                      icon_url, escaped_selector, rfc1738_escape_part(host),\n                                      *port ? \":\" : \"\", port, html_quote(name));\n                         else\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                      icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                      port, html_quote(name));\n \n                     } else if (gtype == GOPHER_INFO) {\n-                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n+                        outbuf.appendf(\"\\t%s\\n\", html_quote(name));\n                     } else {\n                         if (strncmp(selector, \"GET /\", 5) == 0) {\n                             /* WWW link */\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                      icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                         } else if (gtype == GOPHER_WWW) {\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                      icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                         } else {\n                             /* Standard link */\n-                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n+                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                      icon_url, host, gtype, escaped_selector, html_quote(name));\n                         }\n                     }\n \n                     safe_free(escaped_selector);\n-                    outbuf.append(tmpbuf);\n                 } else {\n                     memset(line, '\\0', TEMP_BUF_SIZE);\n                     continue;\n@@ -285,13 +280,12 @@\n                     break;\n \n                 if (gopherState->cso_recno != recno) {\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n+                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                     gopherState->cso_recno = recno;\n                 } else {\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n-                }\n-\n-                outbuf.append(tmpbuf);\n+                    outbuf.appendf(\"%s\\n\", html_quote(result));\n+                }\n+\n                 break;\n             } else {\n                 int code;\n@@ -319,8 +313,7 @@\n \n                 case 502: { /* Too Many Matches */\n                     /* Print the message the server returns */\n-                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n-                    outbuf.append(tmpbuf);\n+                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                     break;\n                 }\n \n@@ -336,12 +329,11 @@\n \n     }               /* while loop */\n \n-    if (outbuf.size() > 0) {\n-        entry->append(outbuf.rawBuf(), outbuf.size());\n+    if (outbuf.length() > 0) {\n+        entry->append(outbuf.rawContent(), outbuf.length());\n         /* now let start sending stuff to client */\n         entry->flush();\n     }\n \n-    outbuf.clean();\n     return;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);",
                "    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);",
                "    String outbuf;",
                "                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);",
                "",
                "                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",",
                "                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",",
                "                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));",
                "                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",",
                "                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",",
                "                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",",
                "                    outbuf.append(tmpbuf);",
                "                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));",
                "                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));",
                "                }",
                "",
                "                outbuf.append(tmpbuf);",
                "                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));",
                "                    outbuf.append(tmpbuf);",
                "    if (outbuf.size() > 0) {",
                "        entry->append(outbuf.rawBuf(), outbuf.size());",
                "    outbuf.clean();"
            ],
            "added_lines": [
                "    SBuf outbuf;",
                "                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",",
                "                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",",
                "                        outbuf.appendf(\"\\t%s\\n\", html_quote(name));",
                "                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",",
                "                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",",
                "                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",",
                "                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));",
                "                    outbuf.appendf(\"%s\\n\", html_quote(result));",
                "                }",
                "",
                "                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));",
                "    if (outbuf.length() > 0) {",
                "        entry->append(outbuf.rawContent(), outbuf.length());"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13622",
        "func_name": "jerryscript-project/jerryscript/ecma_op_object_get_property_names",
        "description": "JerryScript 2.2.0 allows attackers to cause a denial of service (assertion failure) because a property key query for a Proxy object returns unintended data.",
        "git_url": "https://github.com/jerryscript-project/jerryscript/commit/2ac4c4a4c52f81a5c9a3eb33215f325b778f8b94",
        "commit_title": "Improve property key query for Proxy objects",
        "commit_text": " Property key query for Proxy objects always returned all keys even if no symbols were requested symbols were present in the resulting array.  JerryScript-DCO-1.0-Signed-off-by: Peter Gal pgal.usz@partner.samsung.com",
        "func_before": "ecma_collection_t *\necma_op_object_get_property_names (ecma_object_t *obj_p, /**< object */\n                                   uint32_t opts) /**< any combination of ecma_list_properties_options_t values  */\n{\n  JERRY_ASSERT (obj_p != NULL\n                && !ecma_is_lexical_environment (obj_p));\n\n#if ENABLED (JERRY_ES2015_BUILTIN_PROXY)\n  if (ECMA_OBJECT_IS_PROXY (obj_p))\n  {\n    return ecma_proxy_object_own_property_keys (obj_p);\n  }\n#endif /* ENABLED (JERRY_ES2015_BUILTIN_PROXY) */\n\n  if (ecma_op_object_is_fast_array (obj_p))\n  {\n    return ecma_fast_array_get_property_names (obj_p, opts);\n  }\n\n  ecma_collection_t *ret_p = ecma_new_collection ();\n  ecma_collection_t *skipped_non_enumerable_p = ecma_new_collection ();\n\n  const bool is_enumerable_only = (opts & ECMA_LIST_ENUMERABLE) != 0;\n  const bool is_array_indices_only = (opts & ECMA_LIST_ARRAY_INDICES) != 0;\n  const bool is_with_prototype_chain = (opts & ECMA_LIST_PROTOTYPE) != 0;\n#if ENABLED (JERRY_ES2015)\n  const bool is_symbols = (opts & ECMA_LIST_SYMBOLS) != 0;\n  const bool is_symbols_only = (opts & ECMA_LIST_SYMBOLS_ONLY) != 0;\n#endif /* ENABLED (JERRY_ES2015) */\n\n  const size_t bitmap_row_size = sizeof (uint32_t) * JERRY_BITSINBYTE;\n  const size_t names_hashes_bitmap_size = ECMA_OBJECT_HASH_BITMAP_SIZE / bitmap_row_size;\n  JERRY_VLA (uint32_t, names_hashes_bitmap, names_hashes_bitmap_size);\n\n  memset (names_hashes_bitmap, 0, names_hashes_bitmap_size * sizeof (names_hashes_bitmap[0]));\n\n  while (true)\n  {\n    const ecma_object_type_t type = ecma_get_object_type (obj_p);\n    const bool obj_is_builtin = ecma_get_object_is_builtin (obj_p);\n    ecma_length_t string_named_properties_count = 0;\n    ecma_length_t array_index_named_properties_count = 0;\n#if ENABLED (JERRY_ES2015)\n    ecma_length_t symbol_named_properties_count = 0;\n#endif /* ENABLED (JERRY_ES2015) */\n    ecma_collection_t *prop_names_p = ecma_new_collection ();\n\n#if ENABLED (JERRY_ES2015)\n    if (JERRY_LIKELY (!is_symbols_only))\n    {\n#endif /* ENABLED (JERRY_ES2015) */\n\n      if (obj_is_builtin)\n      {\n        if (type == ECMA_OBJECT_TYPE_FUNCTION && ecma_builtin_function_is_routine (obj_p))\n        {\n          ecma_builtin_routine_list_lazy_property_names (obj_p,\n                                                          opts,\n                                                          prop_names_p,\n                                                          skipped_non_enumerable_p);\n        }\n        else\n        {\n          ecma_builtin_list_lazy_property_names (obj_p,\n                                                 opts,\n                                                 prop_names_p,\n                                                 skipped_non_enumerable_p);\n        }\n      }\n      else\n      {\n        switch (type)\n        {\n          case ECMA_OBJECT_TYPE_PSEUDO_ARRAY:\n          {\n  #if ENABLED (JERRY_ES2015_BUILTIN_TYPEDARRAY)\n            if (ecma_object_is_typedarray (obj_p))\n            {\n              ecma_op_typedarray_list_lazy_property_names (obj_p, prop_names_p);\n            }\n  #endif /* ENABLED (JERRY_ES2015_BUILTIN_TYPEDARRAY) */\n            break;\n          }\n          case ECMA_OBJECT_TYPE_FUNCTION:\n          {\n            if (!is_array_indices_only)\n            {\n              ecma_op_function_list_lazy_property_names (obj_p,\n                                                         opts,\n                                                         prop_names_p,\n                                                         skipped_non_enumerable_p);\n            }\n            break;\n          }\n          case ECMA_OBJECT_TYPE_EXTERNAL_FUNCTION:\n          {\n            if (!is_array_indices_only)\n            {\n              ecma_op_external_function_list_lazy_property_names (obj_p,\n                                                                  opts,\n                                                                  prop_names_p,\n                                                                  skipped_non_enumerable_p);\n            }\n            break;\n          }\n          case ECMA_OBJECT_TYPE_BOUND_FUNCTION:\n          {\n            if (!is_array_indices_only)\n            {\n              ecma_op_bound_function_list_lazy_property_names (obj_p,\n                                                               opts,\n                                                               prop_names_p,\n                                                               skipped_non_enumerable_p);\n            }\n            break;\n          }\n          case ECMA_OBJECT_TYPE_CLASS:\n          {\n            ecma_extended_object_t *ext_object_p = (ecma_extended_object_t *) obj_p;\n\n            if (ext_object_p->u.class_prop.class_id == LIT_MAGIC_STRING_STRING_UL)\n            {\n              ecma_op_string_list_lazy_property_names (obj_p,\n                                                       opts,\n                                                       prop_names_p,\n                                                       skipped_non_enumerable_p);\n            }\n\n            break;\n          }\n          case ECMA_OBJECT_TYPE_ARRAY:\n          {\n            ecma_op_array_list_lazy_property_names (obj_p,\n                                                    opts,\n                                                    prop_names_p,\n                                                    skipped_non_enumerable_p);\n            break;\n          }\n          default:\n          {\n            JERRY_ASSERT (type == ECMA_OBJECT_TYPE_GENERAL);\n\n            break;\n          }\n        }\n      }\n#if ENABLED (JERRY_ES2015)\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    ecma_value_t *buffer_p = prop_names_p->buffer_p;\n    uint32_t lazy_prop_name_count = prop_names_p->item_count;\n\n    const size_t own_names_hashes_bitmap_size = ECMA_OBJECT_HASH_BITMAP_SIZE / bitmap_row_size;\n    JERRY_VLA (uint32_t, own_names_hashes_bitmap, own_names_hashes_bitmap_size);\n    memset (own_names_hashes_bitmap, 0, own_names_hashes_bitmap_size * sizeof (own_names_hashes_bitmap[0]));\n\n    for (uint32_t i = 0; i < prop_names_p->item_count; i++)\n    {\n      ecma_string_t *name_p = ecma_get_string_from_value (buffer_p[i]);\n\n      if (ecma_string_get_array_index (name_p) != ECMA_STRING_NOT_ARRAY_INDEX)\n      {\n        array_index_named_properties_count++;\n      }\n#if ENABLED (JERRY_ES2015)\n      else if (ecma_prop_name_is_symbol (name_p))\n      {\n        symbol_named_properties_count++;\n      }\n#endif /* ENABLED (JERRY_ES2015) */\n      else\n      {\n        string_named_properties_count++;\n      }\n\n#if ENABLED (JERRY_ES2015)\n      /* Symbols are never lazy listed */\n      JERRY_ASSERT (!ecma_prop_name_is_symbol (name_p));\n#endif /* ENABLED (JERRY_ES2015) */\n\n      uint8_t hash = (uint8_t) ecma_string_hash (name_p);\n      uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n      uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n      if ((own_names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) == 0)\n      {\n        own_names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n      }\n    }\n\n    jmem_cpointer_t prop_iter_cp = obj_p->u1.property_list_cp;\n\n    if (ecma_op_object_is_fast_array (obj_p) && prop_iter_cp != JMEM_CP_NULL)\n    {\n      ecma_extended_object_t *ext_obj_p = (ecma_extended_object_t *) obj_p;\n\n      uint32_t length = ext_obj_p->u.array.length;\n      array_index_named_properties_count = length - ecma_fast_array_get_hole_count (obj_p);\n\n      ecma_value_t *values_p = ECMA_GET_NON_NULL_POINTER (ecma_value_t, prop_iter_cp);\n\n      for (uint32_t i = 0; i < length; i++)\n      {\n        if (ecma_is_value_array_hole (values_p[i]))\n        {\n          continue;\n        }\n\n        ecma_string_t *index_str_p = ecma_new_ecma_string_from_uint32 (i);\n\n        uint8_t hash = (uint8_t) ecma_string_hash (index_str_p);\n        uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n        uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n        bool is_add = true;\n\n        if ((own_names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) != 0)\n        {\n          buffer_p = prop_names_p->buffer_p;\n\n          for (uint32_t j = 0; j < prop_names_p->item_count; j++)\n          {\n            ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n            if (ecma_compare_ecma_strings (index_str_p, current_name_p))\n            {\n              is_add = false;\n              break;\n            }\n          }\n        }\n\n        if (is_add)\n        {\n          own_names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n\n          ecma_collection_push_back (prop_names_p, ecma_make_string_value (index_str_p));\n        }\n      }\n    }\n    else\n    {\n#if ENABLED (JERRY_PROPRETY_HASHMAP)\n      if (prop_iter_cp != JMEM_CP_NULL)\n      {\n        ecma_property_header_t *prop_iter_p = ECMA_GET_NON_NULL_POINTER (ecma_property_header_t, prop_iter_cp);\n\n        if (prop_iter_p->types[0] == ECMA_PROPERTY_TYPE_HASHMAP)\n        {\n          prop_iter_cp = prop_iter_p->next_property_cp;\n        }\n      }\n  #endif /* ENABLED (JERRY_PROPRETY_HASHMAP) */\n\n      while (prop_iter_cp != JMEM_CP_NULL)\n      {\n        ecma_property_header_t *prop_iter_p = ECMA_GET_NON_NULL_POINTER (ecma_property_header_t, prop_iter_cp);\n        JERRY_ASSERT (ECMA_PROPERTY_IS_PROPERTY_PAIR (prop_iter_p));\n\n        for (int i = 0; i < ECMA_PROPERTY_PAIR_ITEM_COUNT; i++)\n        {\n          ecma_property_t *property_p = prop_iter_p->types + i;\n\n          if (ECMA_PROPERTY_GET_TYPE (*property_p) == ECMA_PROPERTY_TYPE_NAMEDDATA\n              || ECMA_PROPERTY_GET_TYPE (*property_p) == ECMA_PROPERTY_TYPE_NAMEDACCESSOR)\n          {\n            ecma_property_pair_t *prop_pair_p = (ecma_property_pair_t *) prop_iter_p;\n\n            if (ECMA_PROPERTY_GET_NAME_TYPE (*property_p) == ECMA_DIRECT_STRING_MAGIC\n                && prop_pair_p->names_cp[i] >= LIT_NON_INTERNAL_MAGIC_STRING__COUNT\n                && prop_pair_p->names_cp[i] < LIT_MAGIC_STRING__COUNT)\n            {\n              /* Internal properties are never enumerated. */\n              continue;\n            }\n\n            ecma_string_t *name_p = ecma_string_from_property_name (*property_p,\n                                                                    prop_pair_p->names_cp[i]);\n\n            if (!(is_enumerable_only && !ecma_is_property_enumerable (*property_p)))\n            {\n  #if ENABLED (JERRY_ES2015)\n              /* We skip the current property in the following cases:\n                 1. We don't want to list symbols (is_symbols and is_symbols_only are false)\n                    and the current property is a symbol.\n                 2. We only want to list symbols (is_symbols_only is true) and the current\n                    property is NOT a symbol. */\n              bool is_symbol = ecma_prop_name_is_symbol (name_p);\n              if ((!(is_symbols || is_symbols_only) && is_symbol) || (is_symbols_only && !is_symbol))\n              {\n                ecma_deref_ecma_string (name_p);\n                continue;\n              }\n  #endif /* ENABLED (JERRY_ES2015) */\n\n              uint8_t hash = (uint8_t) ecma_string_hash (name_p);\n              uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n              uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n              bool is_add = true;\n\n              if ((own_names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) != 0)\n              {\n                buffer_p = prop_names_p->buffer_p;\n\n                for (uint32_t j = 0; j < prop_names_p->item_count; j++)\n                {\n                  ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n                  if (ecma_compare_ecma_strings (name_p, current_name_p))\n                  {\n                    is_add = false;\n                    break;\n                  }\n                }\n              }\n\n              if (is_add)\n              {\n                if (ecma_string_get_array_index (name_p) != ECMA_STRING_NOT_ARRAY_INDEX)\n                {\n                  /* The name is a valid array index. */\n                  array_index_named_properties_count++;\n                }\n                else if (!is_array_indices_only)\n                {\n  #if ENABLED (JERRY_ES2015)\n                  if (ecma_prop_name_is_symbol (name_p))\n                  {\n                    symbol_named_properties_count++;\n                  }\n                  else\n                  {\n  #endif /* ENABLED (JERRY_ES2015) */\n                    string_named_properties_count++;\n  #if ENABLED (JERRY_ES2015)\n                  }\n  #endif /* ENABLED (JERRY_ES2015) */\n                }\n                else\n                {\n                  ecma_deref_ecma_string (name_p);\n                  continue;\n                }\n\n                own_names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n\n                ecma_collection_push_back (prop_names_p, ecma_make_prop_name_value (name_p));\n              }\n              else\n              {\n                ecma_deref_ecma_string (name_p);\n              }\n            }\n            else\n            {\n              JERRY_ASSERT (is_enumerable_only && !ecma_is_property_enumerable (*property_p));\n\n              ecma_collection_push_back (skipped_non_enumerable_p, ecma_make_prop_name_value (name_p));\n            }\n          }\n        }\n\n        prop_iter_cp = prop_iter_p->next_property_cp;\n      }\n    }\n\n    ecma_length_t all_properties_count = array_index_named_properties_count + string_named_properties_count;\n\n#if ENABLED (JERRY_ES2015)\n    all_properties_count += symbol_named_properties_count;\n#endif /* ENABLED (JERRY_ES2015) */\n\n    /* Second pass: collecting property names into an array. */\n    JMEM_DEFINE_LOCAL_ARRAY (names_p, all_properties_count, ecma_string_t *);\n\n    ecma_string_t **string_names_p = names_p + array_index_named_properties_count;\n#if ENABLED (JERRY_ES2015)\n    ecma_string_t **symbol_names_p = string_names_p + string_named_properties_count;\n#endif /* ENABLED (JERRY_ES2015) */\n\n    uint32_t array_index_name_pos = 0;\n    uint32_t string_name_pos = string_named_properties_count;\n    uint32_t lazy_string_name_pos = 0;\n#if ENABLED (JERRY_ES2015)\n    uint32_t symbol_name_pos = symbol_named_properties_count;\n#endif /* ENABLED (JERRY_ES2015) */\n\n    buffer_p = prop_names_p->buffer_p;\n\n    for (uint32_t i = 0; i < prop_names_p->item_count; i++)\n    {\n      ecma_string_t *name_p = ecma_get_prop_name_from_value (buffer_p[i]);\n      ecma_ref_ecma_string (name_p);\n\n      uint32_t index = ecma_string_get_array_index (name_p);\n\n      if (index != ECMA_STRING_NOT_ARRAY_INDEX)\n      {\n        JERRY_ASSERT (array_index_name_pos < array_index_named_properties_count);\n\n        uint32_t insertion_pos = 0;\n        while (insertion_pos < array_index_name_pos\n               && index > ecma_string_get_array_index (names_p[insertion_pos]))\n        {\n          insertion_pos++;\n        }\n\n        if (insertion_pos == array_index_name_pos)\n        {\n          names_p[array_index_name_pos++] = name_p;\n        }\n        else\n        {\n          JERRY_ASSERT (insertion_pos < array_index_name_pos);\n          JERRY_ASSERT (index <= ecma_string_get_array_index (names_p[insertion_pos]));\n\n          uint32_t move_pos = array_index_name_pos++;\n\n          while (move_pos > insertion_pos)\n          {\n            names_p[move_pos] = names_p[move_pos - 1u];\n\n            move_pos--;\n          }\n\n          names_p[insertion_pos] = name_p;\n        }\n      }\n#if ENABLED (JERRY_ES2015)\n      else if (ecma_prop_name_is_symbol (name_p))\n      {\n        // Put in the symbols in reverse order.\n        JERRY_ASSERT (symbol_name_pos > 0);\n        JERRY_ASSERT (symbol_name_pos <= symbol_named_properties_count);\n\n        symbol_names_p[--symbol_name_pos] = name_p;\n      }\n#endif /* ENABLED (JERRY_ES2015) */\n      else\n      {\n        // Put in the strings in reverse order.\n        JERRY_ASSERT (string_name_pos > 0);\n        JERRY_ASSERT (string_name_pos <= string_named_properties_count);\n\n        if (i < lazy_prop_name_count)\n        {\n          string_names_p[lazy_string_name_pos++] = name_p;\n        }\n        else\n        {\n          string_names_p[--string_name_pos] = name_p;\n        }\n      }\n    }\n\n    JERRY_ASSERT (array_index_name_pos == array_index_named_properties_count);\n    JERRY_ASSERT (string_name_pos - lazy_string_name_pos == 0);\n#if ENABLED (JERRY_ES2015)\n    JERRY_ASSERT (symbol_name_pos == 0);\n#endif /* ENABLED (JERRY_ES2015) */\n\n    ecma_collection_free (prop_names_p);\n\n    /* Third pass:\n     *   embedding own property names of current object of prototype chain to aggregate property names collection */\n    for (uint32_t i = 0; i < all_properties_count; i++)\n    {\n      bool is_append = true;\n\n      ecma_string_t *name_p = names_p[i];\n\n      uint8_t hash = (uint8_t) ecma_string_hash (name_p);\n      uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n      uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n      if ((names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) == 0)\n      {\n        /* This hash has not been used before (for non-skipped). */\n        names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n      }\n      else\n      {\n        /* Name with same hash has already occured. */\n        buffer_p = ret_p->buffer_p;\n\n        for (uint32_t j = 0; j < ret_p->item_count; j++)\n        {\n          ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n          if (ecma_compare_ecma_strings (name_p, current_name_p))\n          {\n            is_append = false;\n            break;\n          }\n        }\n      }\n\n      if (is_append)\n      {\n        buffer_p = skipped_non_enumerable_p->buffer_p;\n\n        for (uint32_t j = 0; j < skipped_non_enumerable_p->item_count; j++)\n        {\n          ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n          if (ecma_compare_ecma_strings (name_p, current_name_p))\n          {\n            is_append = false;\n            break;\n          }\n        }\n      }\n\n      if (is_append)\n      {\n        JERRY_ASSERT ((names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) != 0);\n\n        ecma_collection_push_back (ret_p, ecma_make_prop_name_value (name_p));\n      }\n      else\n      {\n        ecma_deref_ecma_string (name_p);\n      }\n\n    }\n\n    JMEM_FINALIZE_LOCAL_ARRAY (names_p);\n\n    if (!is_with_prototype_chain || obj_p->u2.prototype_cp == JMEM_CP_NULL)\n    {\n      break;\n    }\n\n    obj_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, obj_p->u2.prototype_cp);\n  }\n\n  ecma_collection_free (skipped_non_enumerable_p);\n\n  return ret_p;\n}",
        "func": "ecma_collection_t *\necma_op_object_get_property_names (ecma_object_t *obj_p, /**< object */\n                                   uint32_t opts) /**< any combination of ecma_list_properties_options_t values  */\n{\n  JERRY_ASSERT (obj_p != NULL\n                && !ecma_is_lexical_environment (obj_p));\n\n#if ENABLED (JERRY_ES2015_BUILTIN_PROXY)\n  if (ECMA_OBJECT_IS_PROXY (obj_p))\n  {\n    /* Integrated a part of ECMA 262 v6 7.3.21 EnumerableOwnNames operation. */\n    ecma_collection_t *proxy_keys = ecma_proxy_object_own_property_keys (obj_p);\n    if (JERRY_UNLIKELY (proxy_keys == NULL))\n    {\n      return proxy_keys;\n    }\n    ecma_collection_t *return_keys = ecma_new_collection ();\n\n    /* Move valid elements to the output collection */\n    for (uint32_t i = 0; i < proxy_keys->item_count; i++)\n    {\n      ecma_value_t entry = proxy_keys->buffer_p[i];\n      ecma_string_t *prop_name_p = ecma_get_prop_name_from_value (entry);\n      bool prop_is_symbol = ecma_prop_name_is_symbol (prop_name_p);\n\n      if (prop_is_symbol && ((opts & (ECMA_LIST_SYMBOLS | ECMA_LIST_SYMBOLS_ONLY)) != 0))\n      {\n        ecma_collection_push_back (return_keys, entry);\n      }\n      else if (!prop_is_symbol && (opts & ECMA_LIST_SYMBOLS_ONLY) == 0)\n      {\n        ecma_collection_push_back (return_keys, entry);\n      }\n      else\n      {\n        ecma_free_value (entry);\n      }\n    }\n\n    ecma_collection_destroy (proxy_keys);\n    return return_keys;\n  }\n#endif /* ENABLED (JERRY_ES2015_BUILTIN_PROXY) */\n\n  if (ecma_op_object_is_fast_array (obj_p))\n  {\n    return ecma_fast_array_get_property_names (obj_p, opts);\n  }\n\n  ecma_collection_t *ret_p = ecma_new_collection ();\n  ecma_collection_t *skipped_non_enumerable_p = ecma_new_collection ();\n\n  const bool is_enumerable_only = (opts & ECMA_LIST_ENUMERABLE) != 0;\n  const bool is_array_indices_only = (opts & ECMA_LIST_ARRAY_INDICES) != 0;\n  const bool is_with_prototype_chain = (opts & ECMA_LIST_PROTOTYPE) != 0;\n#if ENABLED (JERRY_ES2015)\n  const bool is_symbols = (opts & ECMA_LIST_SYMBOLS) != 0;\n  const bool is_symbols_only = (opts & ECMA_LIST_SYMBOLS_ONLY) != 0;\n#endif /* ENABLED (JERRY_ES2015) */\n\n  const size_t bitmap_row_size = sizeof (uint32_t) * JERRY_BITSINBYTE;\n  const size_t names_hashes_bitmap_size = ECMA_OBJECT_HASH_BITMAP_SIZE / bitmap_row_size;\n  JERRY_VLA (uint32_t, names_hashes_bitmap, names_hashes_bitmap_size);\n\n  memset (names_hashes_bitmap, 0, names_hashes_bitmap_size * sizeof (names_hashes_bitmap[0]));\n\n  while (true)\n  {\n    const ecma_object_type_t type = ecma_get_object_type (obj_p);\n    const bool obj_is_builtin = ecma_get_object_is_builtin (obj_p);\n    ecma_length_t string_named_properties_count = 0;\n    ecma_length_t array_index_named_properties_count = 0;\n#if ENABLED (JERRY_ES2015)\n    ecma_length_t symbol_named_properties_count = 0;\n#endif /* ENABLED (JERRY_ES2015) */\n    ecma_collection_t *prop_names_p = ecma_new_collection ();\n\n#if ENABLED (JERRY_ES2015)\n    if (JERRY_LIKELY (!is_symbols_only))\n    {\n#endif /* ENABLED (JERRY_ES2015) */\n\n      if (obj_is_builtin)\n      {\n        if (type == ECMA_OBJECT_TYPE_FUNCTION && ecma_builtin_function_is_routine (obj_p))\n        {\n          ecma_builtin_routine_list_lazy_property_names (obj_p,\n                                                          opts,\n                                                          prop_names_p,\n                                                          skipped_non_enumerable_p);\n        }\n        else\n        {\n          ecma_builtin_list_lazy_property_names (obj_p,\n                                                 opts,\n                                                 prop_names_p,\n                                                 skipped_non_enumerable_p);\n        }\n      }\n      else\n      {\n        switch (type)\n        {\n          case ECMA_OBJECT_TYPE_PSEUDO_ARRAY:\n          {\n  #if ENABLED (JERRY_ES2015_BUILTIN_TYPEDARRAY)\n            if (ecma_object_is_typedarray (obj_p))\n            {\n              ecma_op_typedarray_list_lazy_property_names (obj_p, prop_names_p);\n            }\n  #endif /* ENABLED (JERRY_ES2015_BUILTIN_TYPEDARRAY) */\n            break;\n          }\n          case ECMA_OBJECT_TYPE_FUNCTION:\n          {\n            if (!is_array_indices_only)\n            {\n              ecma_op_function_list_lazy_property_names (obj_p,\n                                                         opts,\n                                                         prop_names_p,\n                                                         skipped_non_enumerable_p);\n            }\n            break;\n          }\n          case ECMA_OBJECT_TYPE_EXTERNAL_FUNCTION:\n          {\n            if (!is_array_indices_only)\n            {\n              ecma_op_external_function_list_lazy_property_names (obj_p,\n                                                                  opts,\n                                                                  prop_names_p,\n                                                                  skipped_non_enumerable_p);\n            }\n            break;\n          }\n          case ECMA_OBJECT_TYPE_BOUND_FUNCTION:\n          {\n            if (!is_array_indices_only)\n            {\n              ecma_op_bound_function_list_lazy_property_names (obj_p,\n                                                               opts,\n                                                               prop_names_p,\n                                                               skipped_non_enumerable_p);\n            }\n            break;\n          }\n          case ECMA_OBJECT_TYPE_CLASS:\n          {\n            ecma_extended_object_t *ext_object_p = (ecma_extended_object_t *) obj_p;\n\n            if (ext_object_p->u.class_prop.class_id == LIT_MAGIC_STRING_STRING_UL)\n            {\n              ecma_op_string_list_lazy_property_names (obj_p,\n                                                       opts,\n                                                       prop_names_p,\n                                                       skipped_non_enumerable_p);\n            }\n\n            break;\n          }\n          case ECMA_OBJECT_TYPE_ARRAY:\n          {\n            ecma_op_array_list_lazy_property_names (obj_p,\n                                                    opts,\n                                                    prop_names_p,\n                                                    skipped_non_enumerable_p);\n            break;\n          }\n          default:\n          {\n            JERRY_ASSERT (type == ECMA_OBJECT_TYPE_GENERAL);\n\n            break;\n          }\n        }\n      }\n#if ENABLED (JERRY_ES2015)\n    }\n#endif /* ENABLED (JERRY_ES2015) */\n\n    ecma_value_t *buffer_p = prop_names_p->buffer_p;\n    uint32_t lazy_prop_name_count = prop_names_p->item_count;\n\n    const size_t own_names_hashes_bitmap_size = ECMA_OBJECT_HASH_BITMAP_SIZE / bitmap_row_size;\n    JERRY_VLA (uint32_t, own_names_hashes_bitmap, own_names_hashes_bitmap_size);\n    memset (own_names_hashes_bitmap, 0, own_names_hashes_bitmap_size * sizeof (own_names_hashes_bitmap[0]));\n\n    for (uint32_t i = 0; i < prop_names_p->item_count; i++)\n    {\n      ecma_string_t *name_p = ecma_get_string_from_value (buffer_p[i]);\n\n      if (ecma_string_get_array_index (name_p) != ECMA_STRING_NOT_ARRAY_INDEX)\n      {\n        array_index_named_properties_count++;\n      }\n#if ENABLED (JERRY_ES2015)\n      else if (ecma_prop_name_is_symbol (name_p))\n      {\n        symbol_named_properties_count++;\n      }\n#endif /* ENABLED (JERRY_ES2015) */\n      else\n      {\n        string_named_properties_count++;\n      }\n\n#if ENABLED (JERRY_ES2015)\n      /* Symbols are never lazy listed */\n      JERRY_ASSERT (!ecma_prop_name_is_symbol (name_p));\n#endif /* ENABLED (JERRY_ES2015) */\n\n      uint8_t hash = (uint8_t) ecma_string_hash (name_p);\n      uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n      uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n      if ((own_names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) == 0)\n      {\n        own_names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n      }\n    }\n\n    jmem_cpointer_t prop_iter_cp = obj_p->u1.property_list_cp;\n\n    if (ecma_op_object_is_fast_array (obj_p) && prop_iter_cp != JMEM_CP_NULL)\n    {\n      ecma_extended_object_t *ext_obj_p = (ecma_extended_object_t *) obj_p;\n\n      uint32_t length = ext_obj_p->u.array.length;\n      array_index_named_properties_count = length - ecma_fast_array_get_hole_count (obj_p);\n\n      ecma_value_t *values_p = ECMA_GET_NON_NULL_POINTER (ecma_value_t, prop_iter_cp);\n\n      for (uint32_t i = 0; i < length; i++)\n      {\n        if (ecma_is_value_array_hole (values_p[i]))\n        {\n          continue;\n        }\n\n        ecma_string_t *index_str_p = ecma_new_ecma_string_from_uint32 (i);\n\n        uint8_t hash = (uint8_t) ecma_string_hash (index_str_p);\n        uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n        uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n        bool is_add = true;\n\n        if ((own_names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) != 0)\n        {\n          buffer_p = prop_names_p->buffer_p;\n\n          for (uint32_t j = 0; j < prop_names_p->item_count; j++)\n          {\n            ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n            if (ecma_compare_ecma_strings (index_str_p, current_name_p))\n            {\n              is_add = false;\n              break;\n            }\n          }\n        }\n\n        if (is_add)\n        {\n          own_names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n\n          ecma_collection_push_back (prop_names_p, ecma_make_string_value (index_str_p));\n        }\n      }\n    }\n    else\n    {\n#if ENABLED (JERRY_PROPRETY_HASHMAP)\n      if (prop_iter_cp != JMEM_CP_NULL)\n      {\n        ecma_property_header_t *prop_iter_p = ECMA_GET_NON_NULL_POINTER (ecma_property_header_t, prop_iter_cp);\n\n        if (prop_iter_p->types[0] == ECMA_PROPERTY_TYPE_HASHMAP)\n        {\n          prop_iter_cp = prop_iter_p->next_property_cp;\n        }\n      }\n  #endif /* ENABLED (JERRY_PROPRETY_HASHMAP) */\n\n      while (prop_iter_cp != JMEM_CP_NULL)\n      {\n        ecma_property_header_t *prop_iter_p = ECMA_GET_NON_NULL_POINTER (ecma_property_header_t, prop_iter_cp);\n        JERRY_ASSERT (ECMA_PROPERTY_IS_PROPERTY_PAIR (prop_iter_p));\n\n        for (int i = 0; i < ECMA_PROPERTY_PAIR_ITEM_COUNT; i++)\n        {\n          ecma_property_t *property_p = prop_iter_p->types + i;\n\n          if (ECMA_PROPERTY_GET_TYPE (*property_p) == ECMA_PROPERTY_TYPE_NAMEDDATA\n              || ECMA_PROPERTY_GET_TYPE (*property_p) == ECMA_PROPERTY_TYPE_NAMEDACCESSOR)\n          {\n            ecma_property_pair_t *prop_pair_p = (ecma_property_pair_t *) prop_iter_p;\n\n            if (ECMA_PROPERTY_GET_NAME_TYPE (*property_p) == ECMA_DIRECT_STRING_MAGIC\n                && prop_pair_p->names_cp[i] >= LIT_NON_INTERNAL_MAGIC_STRING__COUNT\n                && prop_pair_p->names_cp[i] < LIT_MAGIC_STRING__COUNT)\n            {\n              /* Internal properties are never enumerated. */\n              continue;\n            }\n\n            ecma_string_t *name_p = ecma_string_from_property_name (*property_p,\n                                                                    prop_pair_p->names_cp[i]);\n\n            if (!(is_enumerable_only && !ecma_is_property_enumerable (*property_p)))\n            {\n  #if ENABLED (JERRY_ES2015)\n              /* We skip the current property in the following cases:\n                 1. We don't want to list symbols (is_symbols and is_symbols_only are false)\n                    and the current property is a symbol.\n                 2. We only want to list symbols (is_symbols_only is true) and the current\n                    property is NOT a symbol. */\n              bool is_symbol = ecma_prop_name_is_symbol (name_p);\n              if ((!(is_symbols || is_symbols_only) && is_symbol) || (is_symbols_only && !is_symbol))\n              {\n                ecma_deref_ecma_string (name_p);\n                continue;\n              }\n  #endif /* ENABLED (JERRY_ES2015) */\n\n              uint8_t hash = (uint8_t) ecma_string_hash (name_p);\n              uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n              uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n              bool is_add = true;\n\n              if ((own_names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) != 0)\n              {\n                buffer_p = prop_names_p->buffer_p;\n\n                for (uint32_t j = 0; j < prop_names_p->item_count; j++)\n                {\n                  ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n                  if (ecma_compare_ecma_strings (name_p, current_name_p))\n                  {\n                    is_add = false;\n                    break;\n                  }\n                }\n              }\n\n              if (is_add)\n              {\n                if (ecma_string_get_array_index (name_p) != ECMA_STRING_NOT_ARRAY_INDEX)\n                {\n                  /* The name is a valid array index. */\n                  array_index_named_properties_count++;\n                }\n                else if (!is_array_indices_only)\n                {\n  #if ENABLED (JERRY_ES2015)\n                  if (ecma_prop_name_is_symbol (name_p))\n                  {\n                    symbol_named_properties_count++;\n                  }\n                  else\n                  {\n  #endif /* ENABLED (JERRY_ES2015) */\n                    string_named_properties_count++;\n  #if ENABLED (JERRY_ES2015)\n                  }\n  #endif /* ENABLED (JERRY_ES2015) */\n                }\n                else\n                {\n                  ecma_deref_ecma_string (name_p);\n                  continue;\n                }\n\n                own_names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n\n                ecma_collection_push_back (prop_names_p, ecma_make_prop_name_value (name_p));\n              }\n              else\n              {\n                ecma_deref_ecma_string (name_p);\n              }\n            }\n            else\n            {\n              JERRY_ASSERT (is_enumerable_only && !ecma_is_property_enumerable (*property_p));\n\n              ecma_collection_push_back (skipped_non_enumerable_p, ecma_make_prop_name_value (name_p));\n            }\n          }\n        }\n\n        prop_iter_cp = prop_iter_p->next_property_cp;\n      }\n    }\n\n    ecma_length_t all_properties_count = array_index_named_properties_count + string_named_properties_count;\n\n#if ENABLED (JERRY_ES2015)\n    all_properties_count += symbol_named_properties_count;\n#endif /* ENABLED (JERRY_ES2015) */\n\n    /* Second pass: collecting property names into an array. */\n    JMEM_DEFINE_LOCAL_ARRAY (names_p, all_properties_count, ecma_string_t *);\n\n    ecma_string_t **string_names_p = names_p + array_index_named_properties_count;\n#if ENABLED (JERRY_ES2015)\n    ecma_string_t **symbol_names_p = string_names_p + string_named_properties_count;\n#endif /* ENABLED (JERRY_ES2015) */\n\n    uint32_t array_index_name_pos = 0;\n    uint32_t string_name_pos = string_named_properties_count;\n    uint32_t lazy_string_name_pos = 0;\n#if ENABLED (JERRY_ES2015)\n    uint32_t symbol_name_pos = symbol_named_properties_count;\n#endif /* ENABLED (JERRY_ES2015) */\n\n    buffer_p = prop_names_p->buffer_p;\n\n    for (uint32_t i = 0; i < prop_names_p->item_count; i++)\n    {\n      ecma_string_t *name_p = ecma_get_prop_name_from_value (buffer_p[i]);\n      ecma_ref_ecma_string (name_p);\n\n      uint32_t index = ecma_string_get_array_index (name_p);\n\n      if (index != ECMA_STRING_NOT_ARRAY_INDEX)\n      {\n        JERRY_ASSERT (array_index_name_pos < array_index_named_properties_count);\n\n        uint32_t insertion_pos = 0;\n        while (insertion_pos < array_index_name_pos\n               && index > ecma_string_get_array_index (names_p[insertion_pos]))\n        {\n          insertion_pos++;\n        }\n\n        if (insertion_pos == array_index_name_pos)\n        {\n          names_p[array_index_name_pos++] = name_p;\n        }\n        else\n        {\n          JERRY_ASSERT (insertion_pos < array_index_name_pos);\n          JERRY_ASSERT (index <= ecma_string_get_array_index (names_p[insertion_pos]));\n\n          uint32_t move_pos = array_index_name_pos++;\n\n          while (move_pos > insertion_pos)\n          {\n            names_p[move_pos] = names_p[move_pos - 1u];\n\n            move_pos--;\n          }\n\n          names_p[insertion_pos] = name_p;\n        }\n      }\n#if ENABLED (JERRY_ES2015)\n      else if (ecma_prop_name_is_symbol (name_p))\n      {\n        // Put in the symbols in reverse order.\n        JERRY_ASSERT (symbol_name_pos > 0);\n        JERRY_ASSERT (symbol_name_pos <= symbol_named_properties_count);\n\n        symbol_names_p[--symbol_name_pos] = name_p;\n      }\n#endif /* ENABLED (JERRY_ES2015) */\n      else\n      {\n        // Put in the strings in reverse order.\n        JERRY_ASSERT (string_name_pos > 0);\n        JERRY_ASSERT (string_name_pos <= string_named_properties_count);\n\n        if (i < lazy_prop_name_count)\n        {\n          string_names_p[lazy_string_name_pos++] = name_p;\n        }\n        else\n        {\n          string_names_p[--string_name_pos] = name_p;\n        }\n      }\n    }\n\n    JERRY_ASSERT (array_index_name_pos == array_index_named_properties_count);\n    JERRY_ASSERT (string_name_pos - lazy_string_name_pos == 0);\n#if ENABLED (JERRY_ES2015)\n    JERRY_ASSERT (symbol_name_pos == 0);\n#endif /* ENABLED (JERRY_ES2015) */\n\n    ecma_collection_free (prop_names_p);\n\n    /* Third pass:\n     *   embedding own property names of current object of prototype chain to aggregate property names collection */\n    for (uint32_t i = 0; i < all_properties_count; i++)\n    {\n      bool is_append = true;\n\n      ecma_string_t *name_p = names_p[i];\n\n      uint8_t hash = (uint8_t) ecma_string_hash (name_p);\n      uint32_t bitmap_row = (uint32_t) (hash / bitmap_row_size);\n      uint32_t bitmap_column = (uint32_t) (hash % bitmap_row_size);\n\n      if ((names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) == 0)\n      {\n        /* This hash has not been used before (for non-skipped). */\n        names_hashes_bitmap[bitmap_row] |= (1u << bitmap_column);\n      }\n      else\n      {\n        /* Name with same hash has already occured. */\n        buffer_p = ret_p->buffer_p;\n\n        for (uint32_t j = 0; j < ret_p->item_count; j++)\n        {\n          ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n          if (ecma_compare_ecma_strings (name_p, current_name_p))\n          {\n            is_append = false;\n            break;\n          }\n        }\n      }\n\n      if (is_append)\n      {\n        buffer_p = skipped_non_enumerable_p->buffer_p;\n\n        for (uint32_t j = 0; j < skipped_non_enumerable_p->item_count; j++)\n        {\n          ecma_string_t *current_name_p = ecma_get_prop_name_from_value (buffer_p[j]);\n\n          if (ecma_compare_ecma_strings (name_p, current_name_p))\n          {\n            is_append = false;\n            break;\n          }\n        }\n      }\n\n      if (is_append)\n      {\n        JERRY_ASSERT ((names_hashes_bitmap[bitmap_row] & (1u << bitmap_column)) != 0);\n\n        ecma_collection_push_back (ret_p, ecma_make_prop_name_value (name_p));\n      }\n      else\n      {\n        ecma_deref_ecma_string (name_p);\n      }\n\n    }\n\n    JMEM_FINALIZE_LOCAL_ARRAY (names_p);\n\n    if (!is_with_prototype_chain || obj_p->u2.prototype_cp == JMEM_CP_NULL)\n    {\n      break;\n    }\n\n    obj_p = ECMA_GET_NON_NULL_POINTER (ecma_object_t, obj_p->u2.prototype_cp);\n  }\n\n  ecma_collection_free (skipped_non_enumerable_p);\n\n  return ret_p;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,37 @@\n #if ENABLED (JERRY_ES2015_BUILTIN_PROXY)\n   if (ECMA_OBJECT_IS_PROXY (obj_p))\n   {\n-    return ecma_proxy_object_own_property_keys (obj_p);\n+    /* Integrated a part of ECMA 262 v6 7.3.21 EnumerableOwnNames operation. */\n+    ecma_collection_t *proxy_keys = ecma_proxy_object_own_property_keys (obj_p);\n+    if (JERRY_UNLIKELY (proxy_keys == NULL))\n+    {\n+      return proxy_keys;\n+    }\n+    ecma_collection_t *return_keys = ecma_new_collection ();\n+\n+    /* Move valid elements to the output collection */\n+    for (uint32_t i = 0; i < proxy_keys->item_count; i++)\n+    {\n+      ecma_value_t entry = proxy_keys->buffer_p[i];\n+      ecma_string_t *prop_name_p = ecma_get_prop_name_from_value (entry);\n+      bool prop_is_symbol = ecma_prop_name_is_symbol (prop_name_p);\n+\n+      if (prop_is_symbol && ((opts & (ECMA_LIST_SYMBOLS | ECMA_LIST_SYMBOLS_ONLY)) != 0))\n+      {\n+        ecma_collection_push_back (return_keys, entry);\n+      }\n+      else if (!prop_is_symbol && (opts & ECMA_LIST_SYMBOLS_ONLY) == 0)\n+      {\n+        ecma_collection_push_back (return_keys, entry);\n+      }\n+      else\n+      {\n+        ecma_free_value (entry);\n+      }\n+    }\n+\n+    ecma_collection_destroy (proxy_keys);\n+    return return_keys;\n   }\n #endif /* ENABLED (JERRY_ES2015_BUILTIN_PROXY) */\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    return ecma_proxy_object_own_property_keys (obj_p);"
            ],
            "added_lines": [
                "    /* Integrated a part of ECMA 262 v6 7.3.21 EnumerableOwnNames operation. */",
                "    ecma_collection_t *proxy_keys = ecma_proxy_object_own_property_keys (obj_p);",
                "    if (JERRY_UNLIKELY (proxy_keys == NULL))",
                "    {",
                "      return proxy_keys;",
                "    }",
                "    ecma_collection_t *return_keys = ecma_new_collection ();",
                "",
                "    /* Move valid elements to the output collection */",
                "    for (uint32_t i = 0; i < proxy_keys->item_count; i++)",
                "    {",
                "      ecma_value_t entry = proxy_keys->buffer_p[i];",
                "      ecma_string_t *prop_name_p = ecma_get_prop_name_from_value (entry);",
                "      bool prop_is_symbol = ecma_prop_name_is_symbol (prop_name_p);",
                "",
                "      if (prop_is_symbol && ((opts & (ECMA_LIST_SYMBOLS | ECMA_LIST_SYMBOLS_ONLY)) != 0))",
                "      {",
                "        ecma_collection_push_back (return_keys, entry);",
                "      }",
                "      else if (!prop_is_symbol && (opts & ECMA_LIST_SYMBOLS_ONLY) == 0)",
                "      {",
                "        ecma_collection_push_back (return_keys, entry);",
                "      }",
                "      else",
                "      {",
                "        ecma_free_value (entry);",
                "      }",
                "    }",
                "",
                "    ecma_collection_destroy (proxy_keys);",
                "    return return_keys;"
            ]
        }
    }
]