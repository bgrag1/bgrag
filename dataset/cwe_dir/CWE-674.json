[
    {
        "cve_id": "CVE-2019-12295",
        "func_name": "wireshark/dissector_try_heuristic",
        "description": "In Wireshark 3.0.0 to 3.0.1, 2.6.0 to 2.6.8, and 2.4.0 to 2.4.14, the dissection engine could crash. This was addressed in epan/packet.c by restricting the number of layers and consequently limiting recursion.",
        "git_url": "https://github.com/wireshark/wireshark/commit/7b6e197da4c497e229ed3ebf6952bae5c426a820",
        "commit_title": "Add dissection recursion checks.",
        "commit_text": " Enforce a maximum layer limit in call_dissector_work and dissector_try_heuristic.  Bug: 15778 (cherry picked from commit be9bdfda02a2498c6f65122d80e3a8b4235dc7f5)",
        "func_before": "gboolean\ndissector_try_heuristic(heur_dissector_list_t sub_dissectors, tvbuff_t *tvb,\n\t\t\tpacket_info *pinfo, proto_tree *tree, heur_dtbl_entry_t **heur_dtbl_entry, void *data)\n{\n\tgboolean           status;\n\tconst char        *saved_curr_proto;\n\tconst char        *saved_heur_list_name;\n\tGSList            *entry;\n\tguint16            saved_can_desegment;\n\tguint              saved_layers_len = 0;\n\theur_dtbl_entry_t *hdtbl_entry;\n\tint                proto_id;\n\n\t/* can_desegment is set to 2 by anyone which offers this api/service.\n\t   then everytime a subdissector is called it is decremented by one.\n\t   thus only the subdissector immediately ontop of whoever offers this\n\t   service can use it.\n\t   We save the current value of \"can_desegment\" for the\n\t   benefit of TCP proxying dissectors such as SOCKS, so they\n\t   can restore it and allow the dissectors they call to use\n\t   the desegmentation service.\n\t*/\n\tsaved_can_desegment        = pinfo->can_desegment;\n\tpinfo->saved_can_desegment = saved_can_desegment;\n\tpinfo->can_desegment       = saved_can_desegment-(saved_can_desegment>0);\n\n\tstatus      = FALSE;\n\tsaved_curr_proto = pinfo->current_proto;\n\tsaved_heur_list_name = pinfo->heur_list_name;\n\n\tsaved_layers_len = wmem_list_count(pinfo->layers);\n\t*heur_dtbl_entry = NULL;\n\n\tfor (entry = sub_dissectors->dissectors; entry != NULL;\n\t    entry = g_slist_next(entry)) {\n\t\t/* XXX - why set this now and above? */\n\t\tpinfo->can_desegment = saved_can_desegment-(saved_can_desegment>0);\n\t\thdtbl_entry = (heur_dtbl_entry_t *)entry->data;\n\n\t\tif (hdtbl_entry->protocol != NULL &&\n\t\t\t(!proto_is_protocol_enabled(hdtbl_entry->protocol)||(hdtbl_entry->enabled==FALSE))) {\n\t\t\t/*\n\t\t\t * No - don't try this dissector.\n\t\t\t */\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (hdtbl_entry->protocol != NULL) {\n\t\t\tproto_id = proto_get_id(hdtbl_entry->protocol);\n\t\t\t/* do NOT change this behavior - wslua uses the protocol short name set here in order\n\t\t\t   to determine which Lua-based heurisitc dissector to call */\n\t\t\tpinfo->current_proto =\n\t\t\t\tproto_get_protocol_short_name(hdtbl_entry->protocol);\n\n\t\t\t/*\n\t\t\t * Add the protocol name to the layers; we'll remove it\n\t\t\t * if the dissector fails.\n\t\t\t */\n\t\t\twmem_list_append(pinfo->layers, GINT_TO_POINTER(proto_id));\n\t\t}\n\n\t\tpinfo->heur_list_name = hdtbl_entry->list_name;\n\n\t\tif ((hdtbl_entry->dissector)(tvb, pinfo, tree, data)) {\n\t\t\t*heur_dtbl_entry = hdtbl_entry;\n\t\t\tstatus = TRUE;\n\t\t\tbreak;\n\t\t} else {\n\t\t\t/*\n\t\t\t * That dissector didn't accept the packet, so\n\t\t\t * remove its protocol's name from the list\n\t\t\t * of protocols.\n\t\t\t */\n\t\t\twhile (wmem_list_count(pinfo->layers) > saved_layers_len) {\n\t\t\t\twmem_list_remove_frame(pinfo->layers, wmem_list_tail(pinfo->layers));\n\t\t\t}\n\t\t}\n\t}\n\n\tpinfo->current_proto = saved_curr_proto;\n\tpinfo->heur_list_name = saved_heur_list_name;\n\tpinfo->can_desegment = saved_can_desegment;\n\treturn status;\n}",
        "func": "gboolean\ndissector_try_heuristic(heur_dissector_list_t sub_dissectors, tvbuff_t *tvb,\n\t\t\tpacket_info *pinfo, proto_tree *tree, heur_dtbl_entry_t **heur_dtbl_entry, void *data)\n{\n\tgboolean           status;\n\tconst char        *saved_curr_proto;\n\tconst char        *saved_heur_list_name;\n\tGSList            *entry;\n\tguint16            saved_can_desegment;\n\tguint              saved_layers_len = 0;\n\theur_dtbl_entry_t *hdtbl_entry;\n\tint                proto_id;\n\n\t/* can_desegment is set to 2 by anyone which offers this api/service.\n\t   then everytime a subdissector is called it is decremented by one.\n\t   thus only the subdissector immediately ontop of whoever offers this\n\t   service can use it.\n\t   We save the current value of \"can_desegment\" for the\n\t   benefit of TCP proxying dissectors such as SOCKS, so they\n\t   can restore it and allow the dissectors they call to use\n\t   the desegmentation service.\n\t*/\n\tsaved_can_desegment        = pinfo->can_desegment;\n\tpinfo->saved_can_desegment = saved_can_desegment;\n\tpinfo->can_desegment       = saved_can_desegment-(saved_can_desegment>0);\n\n\tstatus      = FALSE;\n\tsaved_curr_proto = pinfo->current_proto;\n\tsaved_heur_list_name = pinfo->heur_list_name;\n\n\tsaved_layers_len = wmem_list_count(pinfo->layers);\n\t*heur_dtbl_entry = NULL;\n\n\tDISSECTOR_ASSERT(saved_layers_len < PINFO_LAYER_MAX_RECURSION_DEPTH);\n\n\tfor (entry = sub_dissectors->dissectors; entry != NULL;\n\t    entry = g_slist_next(entry)) {\n\t\t/* XXX - why set this now and above? */\n\t\tpinfo->can_desegment = saved_can_desegment-(saved_can_desegment>0);\n\t\thdtbl_entry = (heur_dtbl_entry_t *)entry->data;\n\n\t\tif (hdtbl_entry->protocol != NULL &&\n\t\t\t(!proto_is_protocol_enabled(hdtbl_entry->protocol)||(hdtbl_entry->enabled==FALSE))) {\n\t\t\t/*\n\t\t\t * No - don't try this dissector.\n\t\t\t */\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (hdtbl_entry->protocol != NULL) {\n\t\t\tproto_id = proto_get_id(hdtbl_entry->protocol);\n\t\t\t/* do NOT change this behavior - wslua uses the protocol short name set here in order\n\t\t\t   to determine which Lua-based heurisitc dissector to call */\n\t\t\tpinfo->current_proto =\n\t\t\t\tproto_get_protocol_short_name(hdtbl_entry->protocol);\n\n\t\t\t/*\n\t\t\t * Add the protocol name to the layers; we'll remove it\n\t\t\t * if the dissector fails.\n\t\t\t */\n\t\t\twmem_list_append(pinfo->layers, GINT_TO_POINTER(proto_id));\n\t\t}\n\n\t\tpinfo->heur_list_name = hdtbl_entry->list_name;\n\n\t\tif ((hdtbl_entry->dissector)(tvb, pinfo, tree, data)) {\n\t\t\t*heur_dtbl_entry = hdtbl_entry;\n\t\t\tstatus = TRUE;\n\t\t\tbreak;\n\t\t} else {\n\t\t\t/*\n\t\t\t * That dissector didn't accept the packet, so\n\t\t\t * remove its protocol's name from the list\n\t\t\t * of protocols.\n\t\t\t */\n\t\t\twhile (wmem_list_count(pinfo->layers) > saved_layers_len) {\n\t\t\t\twmem_list_remove_frame(pinfo->layers, wmem_list_tail(pinfo->layers));\n\t\t\t}\n\t\t}\n\t}\n\n\tpinfo->current_proto = saved_curr_proto;\n\tpinfo->heur_list_name = saved_heur_list_name;\n\tpinfo->can_desegment = saved_can_desegment;\n\treturn status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -30,6 +30,8 @@\n \n \tsaved_layers_len = wmem_list_count(pinfo->layers);\n \t*heur_dtbl_entry = NULL;\n+\n+\tDISSECTOR_ASSERT(saved_layers_len < PINFO_LAYER_MAX_RECURSION_DEPTH);\n \n \tfor (entry = sub_dissectors->dissectors; entry != NULL;\n \t    entry = g_slist_next(entry)) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tDISSECTOR_ASSERT(saved_layers_len < PINFO_LAYER_MAX_RECURSION_DEPTH);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-12295",
        "func_name": "wireshark/call_dissector_work",
        "description": "In Wireshark 3.0.0 to 3.0.1, 2.6.0 to 2.6.8, and 2.4.0 to 2.4.14, the dissection engine could crash. This was addressed in epan/packet.c by restricting the number of layers and consequently limiting recursion.",
        "git_url": "https://github.com/wireshark/wireshark/commit/7b6e197da4c497e229ed3ebf6952bae5c426a820",
        "commit_title": "Add dissection recursion checks.",
        "commit_text": " Enforce a maximum layer limit in call_dissector_work and dissector_try_heuristic.  Bug: 15778 (cherry picked from commit be9bdfda02a2498c6f65122d80e3a8b4235dc7f5)",
        "func_before": "static int\ncall_dissector_work(dissector_handle_t handle, tvbuff_t *tvb, packet_info *pinfo_arg,\n\t\t    proto_tree *tree, gboolean add_proto_name, void *data)\n{\n \tpacket_info *pinfo = pinfo_arg;\n\tconst char  *saved_proto;\n\tguint16      saved_can_desegment;\n\tint          len;\n\tguint        saved_layers_len = 0;\n\n\tif (handle->protocol != NULL &&\n\t    !proto_is_protocol_enabled(handle->protocol)) {\n\t\t/*\n\t\t * The protocol isn't enabled.\n\t\t */\n\t\treturn 0;\n\t}\n\n\tsaved_proto = pinfo->current_proto;\n\tsaved_can_desegment = pinfo->can_desegment;\n\tsaved_layers_len = wmem_list_count(pinfo->layers);\n\n\t/*\n\t * can_desegment is set to 2 by anyone which offers the\n\t * desegmentation api/service.\n\t * Then everytime a subdissector is called it is decremented\n\t * by one.\n\t * Thus only the subdissector immediately on top of whoever\n\t * offers this service can use it.\n\t * We save the current value of \"can_desegment\" for the\n\t * benefit of TCP proxying dissectors such as SOCKS, so they\n\t * can restore it and allow the dissectors they call to use\n\t * the desegmentation service.\n\t */\n\tpinfo->saved_can_desegment = saved_can_desegment;\n\tpinfo->can_desegment = saved_can_desegment-(saved_can_desegment>0);\n\tif ((handle->protocol != NULL) && (!proto_is_pino(handle->protocol))) {\n\t\tpinfo->current_proto =\n\t\t\tproto_get_protocol_short_name(handle->protocol);\n\n\t\t/*\n\t\t * Add the protocol name to the layers\n\t\t * if not told not to. Asn2wrs generated dissectors may be added multiple times otherwise.\n\t\t */\n\t\tif (add_proto_name) {\n\t\t\tpinfo->curr_layer_num++;\n\t\t\twmem_list_append(pinfo->layers, GINT_TO_POINTER(proto_get_id(handle->protocol)));\n\t\t}\n\t}\n\n\tif (pinfo->flags.in_error_pkt) {\n\t\tlen = call_dissector_work_error(handle, tvb, pinfo, tree, data);\n\t} else {\n\t\t/*\n \t\t * Just call the subdissector.\n \t\t */\n\t\tlen = call_dissector_through_handle(handle, tvb, pinfo, tree, data);\n\t}\n\tif (len == 0) {\n\t\t/*\n \t\t * That dissector didn't accept the packet, so\n \t\t * remove its protocol's name from the list\n \t\t * of protocols.\n\t\t */\n\t\twhile (wmem_list_count(pinfo->layers) > saved_layers_len) {\n\t\t\twmem_list_remove_frame(pinfo->layers, wmem_list_tail(pinfo->layers));\n\t\t}\n \t}\n \tpinfo->current_proto = saved_proto;\n \tpinfo->can_desegment = saved_can_desegment;\n\treturn len;\n}",
        "func": "static int\ncall_dissector_work(dissector_handle_t handle, tvbuff_t *tvb, packet_info *pinfo_arg,\n\t\t    proto_tree *tree, gboolean add_proto_name, void *data)\n{\n \tpacket_info *pinfo = pinfo_arg;\n\tconst char  *saved_proto;\n\tguint16      saved_can_desegment;\n\tint          len;\n\tguint        saved_layers_len = 0;\n\n\tif (handle->protocol != NULL &&\n\t    !proto_is_protocol_enabled(handle->protocol)) {\n\t\t/*\n\t\t * The protocol isn't enabled.\n\t\t */\n\t\treturn 0;\n\t}\n\n\tsaved_proto = pinfo->current_proto;\n\tsaved_can_desegment = pinfo->can_desegment;\n\tsaved_layers_len = wmem_list_count(pinfo->layers);\n\tDISSECTOR_ASSERT(saved_layers_len < PINFO_LAYER_MAX_RECURSION_DEPTH);\n\n\t/*\n\t * can_desegment is set to 2 by anyone which offers the\n\t * desegmentation api/service.\n\t * Then everytime a subdissector is called it is decremented\n\t * by one.\n\t * Thus only the subdissector immediately on top of whoever\n\t * offers this service can use it.\n\t * We save the current value of \"can_desegment\" for the\n\t * benefit of TCP proxying dissectors such as SOCKS, so they\n\t * can restore it and allow the dissectors they call to use\n\t * the desegmentation service.\n\t */\n\tpinfo->saved_can_desegment = saved_can_desegment;\n\tpinfo->can_desegment = saved_can_desegment-(saved_can_desegment>0);\n\tif ((handle->protocol != NULL) && (!proto_is_pino(handle->protocol))) {\n\t\tpinfo->current_proto =\n\t\t\tproto_get_protocol_short_name(handle->protocol);\n\n\t\t/*\n\t\t * Add the protocol name to the layers\n\t\t * if not told not to. Asn2wrs generated dissectors may be added multiple times otherwise.\n\t\t */\n\t\tif (add_proto_name) {\n\t\t\tpinfo->curr_layer_num++;\n\t\t\twmem_list_append(pinfo->layers, GINT_TO_POINTER(proto_get_id(handle->protocol)));\n\t\t}\n\t}\n\n\tif (pinfo->flags.in_error_pkt) {\n\t\tlen = call_dissector_work_error(handle, tvb, pinfo, tree, data);\n\t} else {\n\t\t/*\n \t\t * Just call the subdissector.\n \t\t */\n\t\tlen = call_dissector_through_handle(handle, tvb, pinfo, tree, data);\n\t}\n\tif (len == 0) {\n\t\t/*\n \t\t * That dissector didn't accept the packet, so\n \t\t * remove its protocol's name from the list\n \t\t * of protocols.\n\t\t */\n\t\twhile (wmem_list_count(pinfo->layers) > saved_layers_len) {\n\t\t\twmem_list_remove_frame(pinfo->layers, wmem_list_tail(pinfo->layers));\n\t\t}\n \t}\n \tpinfo->current_proto = saved_proto;\n \tpinfo->can_desegment = saved_can_desegment;\n\treturn len;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,7 @@\n \tsaved_proto = pinfo->current_proto;\n \tsaved_can_desegment = pinfo->can_desegment;\n \tsaved_layers_len = wmem_list_count(pinfo->layers);\n+\tDISSECTOR_ASSERT(saved_layers_len < PINFO_LAYER_MAX_RECURSION_DEPTH);\n \n \t/*\n \t * can_desegment is set to 2 by anyone which offers the",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tDISSECTOR_ASSERT(saved_layers_len < PINFO_LAYER_MAX_RECURSION_DEPTH);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-16163",
        "func_name": "kkos/oniguruma/parse_exp",
        "description": "Oniguruma before 6.9.3 allows Stack Exhaustion in regcomp.c because of recursion in regparse.c.",
        "git_url": "https://github.com/kkos/oniguruma/commit/4097828d7cc87589864fecf452f2cd46c5f37180",
        "commit_title": "fix #147: Stack Exhaustion Problem caused by some parsing functions in regcomp.c making recursive calls to themselves.",
        "commit_text": "",
        "func_before": "static int\nparse_exp(Node** np, PToken* tok, int term, UChar** src, UChar* end,\n          ScanEnv* env, int group_head)\n{\n  int r, len, group = 0;\n  Node* qn;\n  Node** tp;\n\n  *np = NULL;\n  if (tok->type == (enum TokenSyms )term)\n    goto end_of_token;\n\n  switch (tok->type) {\n  case TK_ALT:\n  case TK_EOT:\n  end_of_token:\n    *np = node_new_empty();\n    CHECK_NULL_RETURN_MEMERR(*np);\n    return tok->type;\n  break;\n\n  case TK_SUBEXP_OPEN:\n    r = parse_bag(np, tok, TK_SUBEXP_CLOSE, src, end, env);\n    if (r < 0) return r;\n    if (r == 1) { /* group */\n      if (group_head == 0)\n        group = 1;\n      else {\n        Node* target = *np;\n        *np = node_new_group(target);\n        if (IS_NULL(*np)) {\n          onig_node_free(target);\n          return ONIGERR_MEMORY;\n        }\n        group = 2;\n      }\n    }\n    else if (r == 2) { /* option only */\n      Node* target;\n      OnigOptionType prev = env->options;\n\n      env->options = BAG_(*np)->o.options;\n      r = fetch_token(tok, src, end, env);\n      if (r < 0) return r;\n      r = parse_subexp(&target, tok, term, src, end, env, 0);\n      env->options = prev;\n      if (r < 0) {\n        onig_node_free(target);\n        return r;\n      }\n      NODE_BODY(*np) = target;\n      return tok->type;\n    }\n    break;\n\n  case TK_SUBEXP_CLOSE:\n    if (! IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_UNMATCHED_CLOSE_SUBEXP))\n      return ONIGERR_UNMATCHED_CLOSE_PARENTHESIS;\n\n    if (tok->escaped) goto tk_raw_byte;\n    else goto tk_byte;\n    break;\n\n  case TK_STRING:\n  tk_byte:\n    {\n      *np = node_new_str(tok->backp, *src);\n      CHECK_NULL_RETURN_MEMERR(*np);\n\n      while (1) {\n        r = fetch_token(tok, src, end, env);\n        if (r < 0) return r;\n        if (r != TK_STRING) break;\n\n        r = onig_node_str_cat(*np, tok->backp, *src);\n        if (r < 0) return r;\n      }\n\n    string_end:\n      tp = np;\n      goto repeat;\n    }\n    break;\n\n  case TK_RAW_BYTE:\n  tk_raw_byte:\n    {\n      *np = node_new_str_raw_char((UChar )tok->u.c);\n      CHECK_NULL_RETURN_MEMERR(*np);\n      len = 1;\n      while (1) {\n        if (len >= ONIGENC_MBC_MINLEN(env->enc)) {\n          if (len == enclen(env->enc, STR_(*np)->s)) {\n            r = fetch_token(tok, src, end, env);\n            goto tk_raw_byte_end;\n          }\n        }\n\n        r = fetch_token(tok, src, end, env);\n        if (r < 0) return r;\n        if (r != TK_RAW_BYTE)\n          return ONIGERR_TOO_SHORT_MULTI_BYTE_STRING;\n\n        r = node_str_cat_char(*np, (UChar )tok->u.c);\n        if (r < 0) return r;\n\n        len++;\n      }\n\n    tk_raw_byte_end:\n      if (! ONIGENC_IS_VALID_MBC_STRING(env->enc, STR_(*np)->s, STR_(*np)->end))\n        return ONIGERR_INVALID_WIDE_CHAR_VALUE;\n\n      NODE_STRING_CLEAR_RAW(*np);\n      goto string_end;\n    }\n    break;\n\n  case TK_CODE_POINT:\n    {\n      UChar buf[ONIGENC_CODE_TO_MBC_MAXLEN];\n      len = ONIGENC_CODE_TO_MBC(env->enc, tok->u.code, buf);\n      if (len < 0) return len;\n#ifdef NUMBERED_CHAR_IS_NOT_CASE_AMBIG\n      *np = node_new_str_raw(buf, buf + len);\n#else\n      *np = node_new_str(buf, buf + len);\n#endif\n      CHECK_NULL_RETURN_MEMERR(*np);\n    }\n    break;\n\n  case TK_QUOTE_OPEN:\n    {\n      OnigCodePoint end_op[2];\n      UChar *qstart, *qend, *nextp;\n\n      end_op[0] = (OnigCodePoint )MC_ESC(env->syntax);\n      end_op[1] = (OnigCodePoint )'E';\n      qstart = *src;\n      qend = find_str_position(end_op, 2, qstart, end, &nextp, env->enc);\n      if (IS_NULL(qend)) {\n        nextp = qend = end;\n      }\n      *np = node_new_str(qstart, qend);\n      CHECK_NULL_RETURN_MEMERR(*np);\n      *src = nextp;\n    }\n    break;\n\n  case TK_CHAR_TYPE:\n    {\n      switch (tok->u.prop.ctype) {\n      case ONIGENC_CTYPE_WORD:\n        *np = node_new_ctype(tok->u.prop.ctype, tok->u.prop.not, env->options);\n        CHECK_NULL_RETURN_MEMERR(*np);\n        break;\n\n      case ONIGENC_CTYPE_SPACE:\n      case ONIGENC_CTYPE_DIGIT:\n      case ONIGENC_CTYPE_XDIGIT:\n        {\n          CClassNode* cc;\n\n          *np = node_new_cclass();\n          CHECK_NULL_RETURN_MEMERR(*np);\n          cc = CCLASS_(*np);\n          add_ctype_to_cc(cc, tok->u.prop.ctype, 0, env);\n          if (tok->u.prop.not != 0) NCCLASS_SET_NOT(cc);\n        }\n        break;\n\n      default:\n        return ONIGERR_PARSER_BUG;\n        break;\n      }\n    }\n    break;\n\n  case TK_CHAR_PROPERTY:\n    r = parse_char_property(np, tok, src, end, env);\n    if (r != 0) return r;\n    break;\n\n  case TK_CC_OPEN:\n    {\n      CClassNode* cc;\n\n      r = parse_char_class(np, tok, src, end, env);\n      if (r != 0) return r;\n\n      cc = CCLASS_(*np);\n      if (IS_IGNORECASE(env->options)) {\n        IApplyCaseFoldArg iarg;\n\n        iarg.env      = env;\n        iarg.cc       = cc;\n        iarg.alt_root = NULL_NODE;\n        iarg.ptail    = &(iarg.alt_root);\n\n        r = ONIGENC_APPLY_ALL_CASE_FOLD(env->enc, env->case_fold_flag,\n                                        i_apply_case_fold, &iarg);\n        if (r != 0) {\n          onig_node_free(iarg.alt_root);\n          return r;\n        }\n        if (IS_NOT_NULL(iarg.alt_root)) {\n          Node* work = onig_node_new_alt(*np, iarg.alt_root);\n          if (IS_NULL(work)) {\n            onig_node_free(iarg.alt_root);\n            return ONIGERR_MEMORY;\n          }\n          *np = work;\n        }\n      }\n    }\n    break;\n\n  case TK_ANYCHAR:\n    *np = node_new_anychar();\n    CHECK_NULL_RETURN_MEMERR(*np);\n    break;\n\n  case TK_ANYCHAR_ANYTIME:\n    *np = node_new_anychar();\n    CHECK_NULL_RETURN_MEMERR(*np);\n    qn = node_new_quantifier(0, INFINITE_REPEAT, 0);\n    CHECK_NULL_RETURN_MEMERR(qn);\n    NODE_BODY(qn) = *np;\n    *np = qn;\n    break;\n\n  case TK_BACKREF:\n    len = tok->u.backref.num;\n    *np = node_new_backref(len,\n                  (len > 1 ? tok->u.backref.refs : &(tok->u.backref.ref1)),\n                  tok->u.backref.by_name,\n#ifdef USE_BACKREF_WITH_LEVEL\n                           tok->u.backref.exist_level,\n                           tok->u.backref.level,\n#endif\n                           env);\n    CHECK_NULL_RETURN_MEMERR(*np);\n    break;\n\n#ifdef USE_CALL\n  case TK_CALL:\n    {\n      int gnum = tok->u.call.gnum;\n\n      *np = node_new_call(tok->u.call.name, tok->u.call.name_end,\n                          gnum, tok->u.call.by_number);\n      CHECK_NULL_RETURN_MEMERR(*np);\n      env->num_call++;\n      if (tok->u.call.by_number != 0 && gnum == 0) {\n        env->has_call_zero = 1;\n      }\n    }\n    break;\n#endif\n\n  case TK_ANCHOR:\n    {\n      int ascii_mode =\n        IS_WORD_ASCII(env->options) && IS_WORD_ANCHOR_TYPE(tok->u.anchor) ? 1 : 0;\n      *np = onig_node_new_anchor(tok->u.anchor, ascii_mode);\n      CHECK_NULL_RETURN_MEMERR(*np);\n    }\n    break;\n\n  case TK_REPEAT:\n  case TK_INTERVAL:\n    if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_CONTEXT_INDEP_REPEAT_OPS)) {\n      if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_CONTEXT_INVALID_REPEAT_OPS))\n        return ONIGERR_TARGET_OF_REPEAT_OPERATOR_NOT_SPECIFIED;\n      else {\n        *np = node_new_empty();\n        CHECK_NULL_RETURN_MEMERR(*np);\n      }\n    }\n    else {\n      goto tk_byte;\n    }\n    break;\n\n  case TK_KEEP:\n    r = node_new_keep(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_GENERAL_NEWLINE:\n    r = node_new_general_newline(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_NO_NEWLINE:\n    r = node_new_no_newline(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_TRUE_ANYCHAR:\n    r = node_new_true_anychar(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_TEXT_SEGMENT:\n    r = make_text_segment(np, env);\n    if (r < 0) return r;\n    break;\n\n  default:\n    return ONIGERR_PARSER_BUG;\n    break;\n  }\n\n  {\n    tp = np;\n\n  re_entry:\n    r = fetch_token(tok, src, end, env);\n    if (r < 0) return r;\n\n  repeat:\n    if (r == TK_REPEAT || r == TK_INTERVAL) {\n      Node* target;\n\n      if (is_invalid_quantifier_target(*tp))\n        return ONIGERR_TARGET_OF_REPEAT_OPERATOR_INVALID;\n\n      qn = node_new_quantifier(tok->u.repeat.lower, tok->u.repeat.upper,\n                               r == TK_INTERVAL);\n      CHECK_NULL_RETURN_MEMERR(qn);\n      QUANT_(qn)->greedy = tok->u.repeat.greedy;\n      if (group == 2) {\n        target = node_drop_group(*tp);\n        *tp = NULL_NODE;\n      }\n      else {\n        target = *tp;\n      }\n      r = set_quantifier(qn, target, group, env);\n      if (r < 0) {\n        onig_node_free(qn);\n        return r;\n      }\n\n      if (tok->u.repeat.possessive != 0) {\n        Node* en;\n        en = node_new_bag(BAG_STOP_BACKTRACK);\n        if (IS_NULL(en)) {\n          onig_node_free(qn);\n          return ONIGERR_MEMORY;\n        }\n        NODE_BODY(en) = qn;\n        qn = en;\n      }\n\n      if (r == 0) {\n        *tp = qn;\n      }\n      else if (r == 1) { /* x{1,1} ==> x */\n        onig_node_free(qn);\n        *tp = target;\n      }\n      else if (r == 2) { /* split case: /abc+/ */\n        Node *tmp;\n\n        *tp = node_new_list(*tp, NULL);\n        if (IS_NULL(*tp)) {\n          onig_node_free(qn);\n          return ONIGERR_MEMORY;\n        }\n        tmp = NODE_CDR(*tp) = node_new_list(qn, NULL);\n        if (IS_NULL(tmp)) {\n          onig_node_free(qn);\n          return ONIGERR_MEMORY;\n        }\n        tp = &(NODE_CAR(tmp));\n      }\n      group = 0;\n      goto re_entry;\n    }\n  }\n\n  return r;\n}",
        "func": "static int\nparse_exp(Node** np, PToken* tok, int term, UChar** src, UChar* end,\n          ScanEnv* env, int group_head)\n{\n  int r, len, group;\n  Node* qn;\n  Node** tp;\n  unsigned int parse_depth;\n\n  group = 0;\n  *np = NULL;\n  if (tok->type == (enum TokenSyms )term)\n    goto end_of_token;\n\n  parse_depth = env->parse_depth;\n\n  switch (tok->type) {\n  case TK_ALT:\n  case TK_EOT:\n  end_of_token:\n    *np = node_new_empty();\n    CHECK_NULL_RETURN_MEMERR(*np);\n    return tok->type;\n  break;\n\n  case TK_SUBEXP_OPEN:\n    r = parse_bag(np, tok, TK_SUBEXP_CLOSE, src, end, env);\n    if (r < 0) return r;\n    if (r == 1) { /* group */\n      if (group_head == 0)\n        group = 1;\n      else {\n        Node* target = *np;\n        *np = node_new_group(target);\n        if (IS_NULL(*np)) {\n          onig_node_free(target);\n          return ONIGERR_MEMORY;\n        }\n        group = 2;\n      }\n    }\n    else if (r == 2) { /* option only */\n      Node* target;\n      OnigOptionType prev = env->options;\n\n      env->options = BAG_(*np)->o.options;\n      r = fetch_token(tok, src, end, env);\n      if (r < 0) return r;\n      r = parse_subexp(&target, tok, term, src, end, env, 0);\n      env->options = prev;\n      if (r < 0) {\n        onig_node_free(target);\n        return r;\n      }\n      NODE_BODY(*np) = target;\n      return tok->type;\n    }\n    break;\n\n  case TK_SUBEXP_CLOSE:\n    if (! IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_UNMATCHED_CLOSE_SUBEXP))\n      return ONIGERR_UNMATCHED_CLOSE_PARENTHESIS;\n\n    if (tok->escaped) goto tk_raw_byte;\n    else goto tk_byte;\n    break;\n\n  case TK_STRING:\n  tk_byte:\n    {\n      *np = node_new_str(tok->backp, *src);\n      CHECK_NULL_RETURN_MEMERR(*np);\n\n      while (1) {\n        r = fetch_token(tok, src, end, env);\n        if (r < 0) return r;\n        if (r != TK_STRING) break;\n\n        r = onig_node_str_cat(*np, tok->backp, *src);\n        if (r < 0) return r;\n      }\n\n    string_end:\n      tp = np;\n      goto repeat;\n    }\n    break;\n\n  case TK_RAW_BYTE:\n  tk_raw_byte:\n    {\n      *np = node_new_str_raw_char((UChar )tok->u.c);\n      CHECK_NULL_RETURN_MEMERR(*np);\n      len = 1;\n      while (1) {\n        if (len >= ONIGENC_MBC_MINLEN(env->enc)) {\n          if (len == enclen(env->enc, STR_(*np)->s)) {\n            r = fetch_token(tok, src, end, env);\n            goto tk_raw_byte_end;\n          }\n        }\n\n        r = fetch_token(tok, src, end, env);\n        if (r < 0) return r;\n        if (r != TK_RAW_BYTE)\n          return ONIGERR_TOO_SHORT_MULTI_BYTE_STRING;\n\n        r = node_str_cat_char(*np, (UChar )tok->u.c);\n        if (r < 0) return r;\n\n        len++;\n      }\n\n    tk_raw_byte_end:\n      if (! ONIGENC_IS_VALID_MBC_STRING(env->enc, STR_(*np)->s, STR_(*np)->end))\n        return ONIGERR_INVALID_WIDE_CHAR_VALUE;\n\n      NODE_STRING_CLEAR_RAW(*np);\n      goto string_end;\n    }\n    break;\n\n  case TK_CODE_POINT:\n    {\n      UChar buf[ONIGENC_CODE_TO_MBC_MAXLEN];\n      len = ONIGENC_CODE_TO_MBC(env->enc, tok->u.code, buf);\n      if (len < 0) return len;\n#ifdef NUMBERED_CHAR_IS_NOT_CASE_AMBIG\n      *np = node_new_str_raw(buf, buf + len);\n#else\n      *np = node_new_str(buf, buf + len);\n#endif\n      CHECK_NULL_RETURN_MEMERR(*np);\n    }\n    break;\n\n  case TK_QUOTE_OPEN:\n    {\n      OnigCodePoint end_op[2];\n      UChar *qstart, *qend, *nextp;\n\n      end_op[0] = (OnigCodePoint )MC_ESC(env->syntax);\n      end_op[1] = (OnigCodePoint )'E';\n      qstart = *src;\n      qend = find_str_position(end_op, 2, qstart, end, &nextp, env->enc);\n      if (IS_NULL(qend)) {\n        nextp = qend = end;\n      }\n      *np = node_new_str(qstart, qend);\n      CHECK_NULL_RETURN_MEMERR(*np);\n      *src = nextp;\n    }\n    break;\n\n  case TK_CHAR_TYPE:\n    {\n      switch (tok->u.prop.ctype) {\n      case ONIGENC_CTYPE_WORD:\n        *np = node_new_ctype(tok->u.prop.ctype, tok->u.prop.not, env->options);\n        CHECK_NULL_RETURN_MEMERR(*np);\n        break;\n\n      case ONIGENC_CTYPE_SPACE:\n      case ONIGENC_CTYPE_DIGIT:\n      case ONIGENC_CTYPE_XDIGIT:\n        {\n          CClassNode* cc;\n\n          *np = node_new_cclass();\n          CHECK_NULL_RETURN_MEMERR(*np);\n          cc = CCLASS_(*np);\n          add_ctype_to_cc(cc, tok->u.prop.ctype, 0, env);\n          if (tok->u.prop.not != 0) NCCLASS_SET_NOT(cc);\n        }\n        break;\n\n      default:\n        return ONIGERR_PARSER_BUG;\n        break;\n      }\n    }\n    break;\n\n  case TK_CHAR_PROPERTY:\n    r = parse_char_property(np, tok, src, end, env);\n    if (r != 0) return r;\n    break;\n\n  case TK_CC_OPEN:\n    {\n      CClassNode* cc;\n\n      r = parse_char_class(np, tok, src, end, env);\n      if (r != 0) return r;\n\n      cc = CCLASS_(*np);\n      if (IS_IGNORECASE(env->options)) {\n        IApplyCaseFoldArg iarg;\n\n        iarg.env      = env;\n        iarg.cc       = cc;\n        iarg.alt_root = NULL_NODE;\n        iarg.ptail    = &(iarg.alt_root);\n\n        r = ONIGENC_APPLY_ALL_CASE_FOLD(env->enc, env->case_fold_flag,\n                                        i_apply_case_fold, &iarg);\n        if (r != 0) {\n          onig_node_free(iarg.alt_root);\n          return r;\n        }\n        if (IS_NOT_NULL(iarg.alt_root)) {\n          Node* work = onig_node_new_alt(*np, iarg.alt_root);\n          if (IS_NULL(work)) {\n            onig_node_free(iarg.alt_root);\n            return ONIGERR_MEMORY;\n          }\n          *np = work;\n        }\n      }\n    }\n    break;\n\n  case TK_ANYCHAR:\n    *np = node_new_anychar();\n    CHECK_NULL_RETURN_MEMERR(*np);\n    break;\n\n  case TK_ANYCHAR_ANYTIME:\n    *np = node_new_anychar();\n    CHECK_NULL_RETURN_MEMERR(*np);\n    qn = node_new_quantifier(0, INFINITE_REPEAT, 0);\n    CHECK_NULL_RETURN_MEMERR(qn);\n    NODE_BODY(qn) = *np;\n    *np = qn;\n    break;\n\n  case TK_BACKREF:\n    len = tok->u.backref.num;\n    *np = node_new_backref(len,\n                  (len > 1 ? tok->u.backref.refs : &(tok->u.backref.ref1)),\n                  tok->u.backref.by_name,\n#ifdef USE_BACKREF_WITH_LEVEL\n                           tok->u.backref.exist_level,\n                           tok->u.backref.level,\n#endif\n                           env);\n    CHECK_NULL_RETURN_MEMERR(*np);\n    break;\n\n#ifdef USE_CALL\n  case TK_CALL:\n    {\n      int gnum = tok->u.call.gnum;\n\n      *np = node_new_call(tok->u.call.name, tok->u.call.name_end,\n                          gnum, tok->u.call.by_number);\n      CHECK_NULL_RETURN_MEMERR(*np);\n      env->num_call++;\n      if (tok->u.call.by_number != 0 && gnum == 0) {\n        env->has_call_zero = 1;\n      }\n    }\n    break;\n#endif\n\n  case TK_ANCHOR:\n    {\n      int ascii_mode =\n        IS_WORD_ASCII(env->options) && IS_WORD_ANCHOR_TYPE(tok->u.anchor) ? 1 : 0;\n      *np = onig_node_new_anchor(tok->u.anchor, ascii_mode);\n      CHECK_NULL_RETURN_MEMERR(*np);\n    }\n    break;\n\n  case TK_REPEAT:\n  case TK_INTERVAL:\n    if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_CONTEXT_INDEP_REPEAT_OPS)) {\n      if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_CONTEXT_INVALID_REPEAT_OPS))\n        return ONIGERR_TARGET_OF_REPEAT_OPERATOR_NOT_SPECIFIED;\n      else {\n        *np = node_new_empty();\n        CHECK_NULL_RETURN_MEMERR(*np);\n      }\n    }\n    else {\n      goto tk_byte;\n    }\n    break;\n\n  case TK_KEEP:\n    r = node_new_keep(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_GENERAL_NEWLINE:\n    r = node_new_general_newline(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_NO_NEWLINE:\n    r = node_new_no_newline(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_TRUE_ANYCHAR:\n    r = node_new_true_anychar(np, env);\n    if (r < 0) return r;\n    break;\n\n  case TK_TEXT_SEGMENT:\n    r = make_text_segment(np, env);\n    if (r < 0) return r;\n    break;\n\n  default:\n    return ONIGERR_PARSER_BUG;\n    break;\n  }\n\n  {\n    tp = np;\n\n  re_entry:\n    r = fetch_token(tok, src, end, env);\n    if (r < 0) return r;\n\n  repeat:\n    if (r == TK_REPEAT || r == TK_INTERVAL) {\n      Node* target;\n\n      if (is_invalid_quantifier_target(*tp))\n        return ONIGERR_TARGET_OF_REPEAT_OPERATOR_INVALID;\n\n      parse_depth++;\n      if (parse_depth > ParseDepthLimit)\n        return ONIGERR_PARSE_DEPTH_LIMIT_OVER;\n\n      qn = node_new_quantifier(tok->u.repeat.lower, tok->u.repeat.upper,\n                               r == TK_INTERVAL);\n      CHECK_NULL_RETURN_MEMERR(qn);\n      QUANT_(qn)->greedy = tok->u.repeat.greedy;\n      if (group == 2) {\n        target = node_drop_group(*tp);\n        *tp = NULL_NODE;\n      }\n      else {\n        target = *tp;\n      }\n      r = set_quantifier(qn, target, group, env);\n      if (r < 0) {\n        onig_node_free(qn);\n        return r;\n      }\n\n      if (tok->u.repeat.possessive != 0) {\n        Node* en;\n        en = node_new_bag(BAG_STOP_BACKTRACK);\n        if (IS_NULL(en)) {\n          onig_node_free(qn);\n          return ONIGERR_MEMORY;\n        }\n        NODE_BODY(en) = qn;\n        qn = en;\n      }\n\n      if (r == 0) {\n        *tp = qn;\n      }\n      else if (r == 1) { /* x{1,1} ==> x */\n        onig_node_free(qn);\n        *tp = target;\n      }\n      else if (r == 2) { /* split case: /abc+/ */\n        Node *tmp;\n\n        *tp = node_new_list(*tp, NULL);\n        if (IS_NULL(*tp)) {\n          onig_node_free(qn);\n          return ONIGERR_MEMORY;\n        }\n        tmp = NODE_CDR(*tp) = node_new_list(qn, NULL);\n        if (IS_NULL(tmp)) {\n          onig_node_free(qn);\n          return ONIGERR_MEMORY;\n        }\n        tp = &(NODE_CAR(tmp));\n      }\n      group = 0;\n      goto re_entry;\n    }\n  }\n\n  return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,13 +2,17 @@\n parse_exp(Node** np, PToken* tok, int term, UChar** src, UChar* end,\n           ScanEnv* env, int group_head)\n {\n-  int r, len, group = 0;\n+  int r, len, group;\n   Node* qn;\n   Node** tp;\n-\n+  unsigned int parse_depth;\n+\n+  group = 0;\n   *np = NULL;\n   if (tok->type == (enum TokenSyms )term)\n     goto end_of_token;\n+\n+  parse_depth = env->parse_depth;\n \n   switch (tok->type) {\n   case TK_ALT:\n@@ -327,6 +331,10 @@\n       if (is_invalid_quantifier_target(*tp))\n         return ONIGERR_TARGET_OF_REPEAT_OPERATOR_INVALID;\n \n+      parse_depth++;\n+      if (parse_depth > ParseDepthLimit)\n+        return ONIGERR_PARSE_DEPTH_LIMIT_OVER;\n+\n       qn = node_new_quantifier(tok->u.repeat.lower, tok->u.repeat.upper,\n                                r == TK_INTERVAL);\n       CHECK_NULL_RETURN_MEMERR(qn);",
        "diff_line_info": {
            "deleted_lines": [
                "  int r, len, group = 0;",
                ""
            ],
            "added_lines": [
                "  int r, len, group;",
                "  unsigned int parse_depth;",
                "",
                "  group = 0;",
                "",
                "  parse_depth = env->parse_depth;",
                "      parse_depth++;",
                "      if (parse_depth > ParseDepthLimit)",
                "        return ONIGERR_PARSE_DEPTH_LIMIT_OVER;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-16163",
        "func_name": "kkos/oniguruma/parse_char_class",
        "description": "Oniguruma before 6.9.3 allows Stack Exhaustion in regcomp.c because of recursion in regparse.c.",
        "git_url": "https://github.com/kkos/oniguruma/commit/4097828d7cc87589864fecf452f2cd46c5f37180",
        "commit_title": "fix #147: Stack Exhaustion Problem caused by some parsing functions in regcomp.c making recursive calls to themselves.",
        "commit_text": "",
        "func_before": "static int\nparse_char_class(Node** np, PToken* tok, UChar** src, UChar* end, ScanEnv* env)\n{\n  int r, neg, len, fetched, and_start;\n  OnigCodePoint v, vs;\n  UChar *p;\n  Node* node;\n  CClassNode *cc, *prev_cc;\n  CClassNode work_cc;\n\n  enum CCSTATE state;\n  enum CCVALTYPE val_type, in_type;\n  int val_israw, in_israw;\n\n  *np = NULL_NODE;\n  env->parse_depth++;\n  if (env->parse_depth > ParseDepthLimit)\n    return ONIGERR_PARSE_DEPTH_LIMIT_OVER;\n  prev_cc = (CClassNode* )NULL;\n  r = fetch_token_in_cc(tok, src, end, env);\n  if (r == TK_CHAR && tok->u.c == '^' && tok->escaped == 0) {\n    neg = 1;\n    r = fetch_token_in_cc(tok, src, end, env);\n  }\n  else {\n    neg = 0;\n  }\n\n  if (r < 0) return r;\n  if (r == TK_CC_CLOSE) {\n    if (! code_exist_check((OnigCodePoint )']',\n                           *src, env->pattern_end, 1, env))\n      return ONIGERR_EMPTY_CHAR_CLASS;\n\n    CC_ESC_WARN(env, (UChar* )\"]\");\n    r = tok->type = TK_CHAR;  /* allow []...] */\n  }\n\n  *np = node = node_new_cclass();\n  CHECK_NULL_RETURN_MEMERR(node);\n  cc = CCLASS_(node);\n\n  and_start = 0;\n  state = CCS_START;\n  p = *src;\n  while (r != TK_CC_CLOSE) {\n    fetched = 0;\n    switch (r) {\n    case TK_CHAR:\n    any_char_in:\n      len = ONIGENC_CODE_TO_MBCLEN(env->enc, tok->u.c);\n      if (len > 1) {\n        in_type = CCV_CODE_POINT;\n      }\n      else if (len < 0) {\n        r = len;\n        goto err;\n      }\n      else {\n        /* sb_char: */\n        in_type = CCV_SB;\n      }\n      v = (OnigCodePoint )tok->u.c;\n      in_israw = 0;\n      goto val_entry2;\n      break;\n\n    case TK_RAW_BYTE:\n      /* tok->base != 0 : octal or hexadec. */\n      if (! ONIGENC_IS_SINGLEBYTE(env->enc) && tok->base != 0) {\n        int i, j;\n        UChar buf[ONIGENC_CODE_TO_MBC_MAXLEN];\n        UChar* bufe = buf + ONIGENC_CODE_TO_MBC_MAXLEN;\n        UChar* psave = p;\n        int base = tok->base;\n\n        buf[0] = tok->u.c;\n        for (i = 1; i < ONIGENC_MBC_MAXLEN(env->enc); i++) {\n          r = fetch_token_in_cc(tok, &p, end, env);\n          if (r < 0) goto err;\n          if (r != TK_RAW_BYTE || tok->base != base) {\n            fetched = 1;\n            break;\n          }\n          buf[i] = tok->u.c;\n        }\n\n        if (i < ONIGENC_MBC_MINLEN(env->enc)) {\n          r = ONIGERR_TOO_SHORT_MULTI_BYTE_STRING;\n          goto err;\n        }\n\n        /* clear buf tail */\n        for (j = i; j < ONIGENC_CODE_TO_MBC_MAXLEN; j++) buf[j] = '\\0';\n\n        len = enclen(env->enc, buf);\n        if (i < len) {\n          r = ONIGERR_TOO_SHORT_MULTI_BYTE_STRING;\n          goto err;\n        }\n        else if (i > len) { /* fetch back */\n          p = psave;\n          for (i = 1; i < len; i++) {\n            r = fetch_token_in_cc(tok, &p, end, env);\n          }\n          fetched = 0;\n        }\n\n        if (i == 1) {\n          v = (OnigCodePoint )buf[0];\n          goto raw_single;\n        }\n        else {\n          v = ONIGENC_MBC_TO_CODE(env->enc, buf, bufe);\n          in_type = CCV_CODE_POINT;\n        }\n      }\n      else {\n        v = (OnigCodePoint )tok->u.c;\n      raw_single:\n        in_type = CCV_SB;\n      }\n      in_israw = 1;\n      goto val_entry2;\n      break;\n\n    case TK_CODE_POINT:\n      v = tok->u.code;\n      in_israw = 1;\n    val_entry:\n      len = ONIGENC_CODE_TO_MBCLEN(env->enc, v);\n      if (len < 0) {\n        r = len;\n        goto err;\n      }\n      in_type = (len == 1 ? CCV_SB : CCV_CODE_POINT);\n    val_entry2:\n      r = next_state_val(cc, &vs, v, &val_israw, in_israw, in_type, &val_type,\n                         &state, env);\n      if (r != 0) goto err;\n      break;\n\n    case TK_POSIX_BRACKET_OPEN:\n      r = parse_posix_bracket(cc, &p, end, env);\n      if (r < 0) goto err;\n      if (r == 1) {  /* is not POSIX bracket */\n        CC_ESC_WARN(env, (UChar* )\"[\");\n        p = tok->backp;\n        v = (OnigCodePoint )tok->u.c;\n        in_israw = 0;\n        goto val_entry;\n      }\n      goto next_class;\n      break;\n\n    case TK_CHAR_TYPE:\n      r = add_ctype_to_cc(cc, tok->u.prop.ctype, tok->u.prop.not, env);\n      if (r != 0) goto err;\n\n    next_class:\n      r = next_state_class(cc, &vs, &val_type, &state, env);\n      if (r != 0) goto err;\n      break;\n\n    case TK_CHAR_PROPERTY:\n      {\n        int ctype = fetch_char_property_to_ctype(&p, end, env);\n        if (ctype < 0) {\n          r = ctype;\n          goto err;\n        }\n        r = add_ctype_to_cc(cc, ctype, tok->u.prop.not, env);\n        if (r != 0) goto err;\n        goto next_class;\n      }\n      break;\n\n    case TK_CC_RANGE:\n      if (state == CCS_VALUE) {\n        r = fetch_token_in_cc(tok, &p, end, env);\n        if (r < 0) goto err;\n        fetched = 1;\n        if (r == TK_CC_CLOSE) { /* allow [x-] */\n        range_end_val:\n          v = (OnigCodePoint )'-';\n          in_israw = 0;\n          goto val_entry;\n        }\n        else if (r == TK_CC_AND) {\n          CC_ESC_WARN(env, (UChar* )\"-\");\n          goto range_end_val;\n        }\n\n        if (val_type == CCV_CLASS) {\n          r = ONIGERR_UNMATCHED_RANGE_SPECIFIER_IN_CHAR_CLASS;\n          goto err;\n        }\n\n        state = CCS_RANGE;\n      }\n      else if (state == CCS_START) {\n        /* [-xa] is allowed */\n        v = (OnigCodePoint )tok->u.c;\n        in_israw = 0;\n\n        r = fetch_token_in_cc(tok, &p, end, env);\n        if (r < 0) goto err;\n        fetched = 1;\n        /* [--x] or [a&&-x] is warned. */\n        if (r == TK_CC_RANGE || and_start != 0)\n          CC_ESC_WARN(env, (UChar* )\"-\");\n\n        goto val_entry;\n      }\n      else if (state == CCS_RANGE) {\n        CC_ESC_WARN(env, (UChar* )\"-\");\n        goto any_char_in;  /* [!--x] is allowed */\n      }\n      else { /* CCS_COMPLETE */\n        r = fetch_token_in_cc(tok, &p, end, env);\n        if (r < 0) goto err;\n        fetched = 1;\n        if (r == TK_CC_CLOSE) goto range_end_val; /* allow [a-b-] */\n        else if (r == TK_CC_AND) {\n          CC_ESC_WARN(env, (UChar* )\"-\");\n          goto range_end_val;\n        }\n\n        if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_DOUBLE_RANGE_OP_IN_CC)) {\n          CC_ESC_WARN(env, (UChar* )\"-\");\n          goto range_end_val;   /* [0-9-a] is allowed as [0-9\\-a] */\n        }\n        r = ONIGERR_UNMATCHED_RANGE_SPECIFIER_IN_CHAR_CLASS;\n        goto err;\n      }\n      break;\n\n    case TK_CC_CC_OPEN: /* [ */\n      {\n        Node *anode;\n        CClassNode* acc;\n\n        r = parse_char_class(&anode, tok, &p, end, env);\n        if (r != 0) {\n          onig_node_free(anode);\n          goto cc_open_err;\n        }\n        acc = CCLASS_(anode);\n        r = or_cclass(cc, acc, env->enc);\n        onig_node_free(anode);\n\n      cc_open_err:\n        if (r != 0) goto err;\n      }\n      break;\n\n    case TK_CC_AND: /* && */\n      {\n        if (state == CCS_VALUE) {\n          r = next_state_val(cc, &vs, 0, &val_israw, 0, val_type,\n                             &val_type, &state, env);\n          if (r != 0) goto err;\n        }\n        /* initialize local variables */\n        and_start = 1;\n        state = CCS_START;\n\n        if (IS_NOT_NULL(prev_cc)) {\n          r = and_cclass(prev_cc, cc, env->enc);\n          if (r != 0) goto err;\n          bbuf_free(cc->mbuf);\n        }\n        else {\n          prev_cc = cc;\n          cc = &work_cc;\n        }\n        initialize_cclass(cc);\n      }\n      break;\n\n    case TK_EOT:\n      r = ONIGERR_PREMATURE_END_OF_CHAR_CLASS;\n      goto err;\n      break;\n    default:\n      r = ONIGERR_PARSER_BUG;\n      goto err;\n      break;\n    }\n\n    if (fetched)\n      r = tok->type;\n    else {\n      r = fetch_token_in_cc(tok, &p, end, env);\n      if (r < 0) goto err;\n    }\n  }\n\n  if (state == CCS_VALUE) {\n    r = next_state_val(cc, &vs, 0, &val_israw, 0, val_type,\n                       &val_type, &state, env);\n    if (r != 0) goto err;\n  }\n\n  if (IS_NOT_NULL(prev_cc)) {\n    r = and_cclass(prev_cc, cc, env->enc);\n    if (r != 0) goto err;\n    bbuf_free(cc->mbuf);\n    cc = prev_cc;\n  }\n\n  if (neg != 0)\n    NCCLASS_SET_NOT(cc);\n  else\n    NCCLASS_CLEAR_NOT(cc);\n  if (IS_NCCLASS_NOT(cc) &&\n      IS_SYNTAX_BV(env->syntax, ONIG_SYN_NOT_NEWLINE_IN_NEGATIVE_CC)) {\n    int is_empty = (IS_NULL(cc->mbuf) ? 1 : 0);\n    if (is_empty != 0)\n      BITSET_IS_EMPTY(cc->bs, is_empty);\n\n    if (is_empty == 0) {\n#define NEWLINE_CODE    0x0a\n\n      if (ONIGENC_IS_CODE_NEWLINE(env->enc, NEWLINE_CODE)) {\n        if (ONIGENC_CODE_TO_MBCLEN(env->enc, NEWLINE_CODE) == 1)\n          BITSET_SET_BIT(cc->bs, NEWLINE_CODE);\n        else\n          add_code_range(&(cc->mbuf), env, NEWLINE_CODE, NEWLINE_CODE);\n      }\n    }\n  }\n  *src = p;\n  env->parse_depth--;\n  return 0;\n\n err:\n  if (cc != CCLASS_(*np))\n    bbuf_free(cc->mbuf);\n  return r;\n}",
        "func": "static int\nparse_char_class(Node** np, PToken* tok, UChar** src, UChar* end, ScanEnv* env)\n{\n  int r, neg, len, fetched, and_start;\n  OnigCodePoint v, vs;\n  UChar *p;\n  Node* node;\n  CClassNode *cc, *prev_cc;\n  CClassNode work_cc;\n\n  enum CCSTATE state;\n  enum CCVALTYPE val_type, in_type;\n  int val_israw, in_israw;\n\n  *np = NULL_NODE;\n  env->parse_depth++;\n  if (env->parse_depth > ParseDepthLimit)\n    return ONIGERR_PARSE_DEPTH_LIMIT_OVER;\n\n  prev_cc = (CClassNode* )NULL;\n  r = fetch_token_in_cc(tok, src, end, env);\n  if (r == TK_CHAR && tok->u.c == '^' && tok->escaped == 0) {\n    neg = 1;\n    r = fetch_token_in_cc(tok, src, end, env);\n  }\n  else {\n    neg = 0;\n  }\n\n  if (r < 0) return r;\n  if (r == TK_CC_CLOSE) {\n    if (! code_exist_check((OnigCodePoint )']',\n                           *src, env->pattern_end, 1, env))\n      return ONIGERR_EMPTY_CHAR_CLASS;\n\n    CC_ESC_WARN(env, (UChar* )\"]\");\n    r = tok->type = TK_CHAR;  /* allow []...] */\n  }\n\n  *np = node = node_new_cclass();\n  CHECK_NULL_RETURN_MEMERR(node);\n  cc = CCLASS_(node);\n\n  and_start = 0;\n  state = CCS_START;\n  p = *src;\n  while (r != TK_CC_CLOSE) {\n    fetched = 0;\n    switch (r) {\n    case TK_CHAR:\n    any_char_in:\n      len = ONIGENC_CODE_TO_MBCLEN(env->enc, tok->u.c);\n      if (len > 1) {\n        in_type = CCV_CODE_POINT;\n      }\n      else if (len < 0) {\n        r = len;\n        goto err;\n      }\n      else {\n        /* sb_char: */\n        in_type = CCV_SB;\n      }\n      v = (OnigCodePoint )tok->u.c;\n      in_israw = 0;\n      goto val_entry2;\n      break;\n\n    case TK_RAW_BYTE:\n      /* tok->base != 0 : octal or hexadec. */\n      if (! ONIGENC_IS_SINGLEBYTE(env->enc) && tok->base != 0) {\n        int i, j;\n        UChar buf[ONIGENC_CODE_TO_MBC_MAXLEN];\n        UChar* bufe = buf + ONIGENC_CODE_TO_MBC_MAXLEN;\n        UChar* psave = p;\n        int base = tok->base;\n\n        buf[0] = tok->u.c;\n        for (i = 1; i < ONIGENC_MBC_MAXLEN(env->enc); i++) {\n          r = fetch_token_in_cc(tok, &p, end, env);\n          if (r < 0) goto err;\n          if (r != TK_RAW_BYTE || tok->base != base) {\n            fetched = 1;\n            break;\n          }\n          buf[i] = tok->u.c;\n        }\n\n        if (i < ONIGENC_MBC_MINLEN(env->enc)) {\n          r = ONIGERR_TOO_SHORT_MULTI_BYTE_STRING;\n          goto err;\n        }\n\n        /* clear buf tail */\n        for (j = i; j < ONIGENC_CODE_TO_MBC_MAXLEN; j++) buf[j] = '\\0';\n\n        len = enclen(env->enc, buf);\n        if (i < len) {\n          r = ONIGERR_TOO_SHORT_MULTI_BYTE_STRING;\n          goto err;\n        }\n        else if (i > len) { /* fetch back */\n          p = psave;\n          for (i = 1; i < len; i++) {\n            r = fetch_token_in_cc(tok, &p, end, env);\n          }\n          fetched = 0;\n        }\n\n        if (i == 1) {\n          v = (OnigCodePoint )buf[0];\n          goto raw_single;\n        }\n        else {\n          v = ONIGENC_MBC_TO_CODE(env->enc, buf, bufe);\n          in_type = CCV_CODE_POINT;\n        }\n      }\n      else {\n        v = (OnigCodePoint )tok->u.c;\n      raw_single:\n        in_type = CCV_SB;\n      }\n      in_israw = 1;\n      goto val_entry2;\n      break;\n\n    case TK_CODE_POINT:\n      v = tok->u.code;\n      in_israw = 1;\n    val_entry:\n      len = ONIGENC_CODE_TO_MBCLEN(env->enc, v);\n      if (len < 0) {\n        r = len;\n        goto err;\n      }\n      in_type = (len == 1 ? CCV_SB : CCV_CODE_POINT);\n    val_entry2:\n      r = next_state_val(cc, &vs, v, &val_israw, in_israw, in_type, &val_type,\n                         &state, env);\n      if (r != 0) goto err;\n      break;\n\n    case TK_POSIX_BRACKET_OPEN:\n      r = parse_posix_bracket(cc, &p, end, env);\n      if (r < 0) goto err;\n      if (r == 1) {  /* is not POSIX bracket */\n        CC_ESC_WARN(env, (UChar* )\"[\");\n        p = tok->backp;\n        v = (OnigCodePoint )tok->u.c;\n        in_israw = 0;\n        goto val_entry;\n      }\n      goto next_class;\n      break;\n\n    case TK_CHAR_TYPE:\n      r = add_ctype_to_cc(cc, tok->u.prop.ctype, tok->u.prop.not, env);\n      if (r != 0) goto err;\n\n    next_class:\n      r = next_state_class(cc, &vs, &val_type, &state, env);\n      if (r != 0) goto err;\n      break;\n\n    case TK_CHAR_PROPERTY:\n      {\n        int ctype = fetch_char_property_to_ctype(&p, end, env);\n        if (ctype < 0) {\n          r = ctype;\n          goto err;\n        }\n        r = add_ctype_to_cc(cc, ctype, tok->u.prop.not, env);\n        if (r != 0) goto err;\n        goto next_class;\n      }\n      break;\n\n    case TK_CC_RANGE:\n      if (state == CCS_VALUE) {\n        r = fetch_token_in_cc(tok, &p, end, env);\n        if (r < 0) goto err;\n        fetched = 1;\n        if (r == TK_CC_CLOSE) { /* allow [x-] */\n        range_end_val:\n          v = (OnigCodePoint )'-';\n          in_israw = 0;\n          goto val_entry;\n        }\n        else if (r == TK_CC_AND) {\n          CC_ESC_WARN(env, (UChar* )\"-\");\n          goto range_end_val;\n        }\n\n        if (val_type == CCV_CLASS) {\n          r = ONIGERR_UNMATCHED_RANGE_SPECIFIER_IN_CHAR_CLASS;\n          goto err;\n        }\n\n        state = CCS_RANGE;\n      }\n      else if (state == CCS_START) {\n        /* [-xa] is allowed */\n        v = (OnigCodePoint )tok->u.c;\n        in_israw = 0;\n\n        r = fetch_token_in_cc(tok, &p, end, env);\n        if (r < 0) goto err;\n        fetched = 1;\n        /* [--x] or [a&&-x] is warned. */\n        if (r == TK_CC_RANGE || and_start != 0)\n          CC_ESC_WARN(env, (UChar* )\"-\");\n\n        goto val_entry;\n      }\n      else if (state == CCS_RANGE) {\n        CC_ESC_WARN(env, (UChar* )\"-\");\n        goto any_char_in;  /* [!--x] is allowed */\n      }\n      else { /* CCS_COMPLETE */\n        r = fetch_token_in_cc(tok, &p, end, env);\n        if (r < 0) goto err;\n        fetched = 1;\n        if (r == TK_CC_CLOSE) goto range_end_val; /* allow [a-b-] */\n        else if (r == TK_CC_AND) {\n          CC_ESC_WARN(env, (UChar* )\"-\");\n          goto range_end_val;\n        }\n\n        if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_DOUBLE_RANGE_OP_IN_CC)) {\n          CC_ESC_WARN(env, (UChar* )\"-\");\n          goto range_end_val;   /* [0-9-a] is allowed as [0-9\\-a] */\n        }\n        r = ONIGERR_UNMATCHED_RANGE_SPECIFIER_IN_CHAR_CLASS;\n        goto err;\n      }\n      break;\n\n    case TK_CC_CC_OPEN: /* [ */\n      {\n        Node *anode;\n        CClassNode* acc;\n\n        r = parse_char_class(&anode, tok, &p, end, env);\n        if (r != 0) {\n          onig_node_free(anode);\n          goto cc_open_err;\n        }\n        acc = CCLASS_(anode);\n        r = or_cclass(cc, acc, env->enc);\n        onig_node_free(anode);\n\n      cc_open_err:\n        if (r != 0) goto err;\n      }\n      break;\n\n    case TK_CC_AND: /* && */\n      {\n        if (state == CCS_VALUE) {\n          r = next_state_val(cc, &vs, 0, &val_israw, 0, val_type,\n                             &val_type, &state, env);\n          if (r != 0) goto err;\n        }\n        /* initialize local variables */\n        and_start = 1;\n        state = CCS_START;\n\n        if (IS_NOT_NULL(prev_cc)) {\n          r = and_cclass(prev_cc, cc, env->enc);\n          if (r != 0) goto err;\n          bbuf_free(cc->mbuf);\n        }\n        else {\n          prev_cc = cc;\n          cc = &work_cc;\n        }\n        initialize_cclass(cc);\n      }\n      break;\n\n    case TK_EOT:\n      r = ONIGERR_PREMATURE_END_OF_CHAR_CLASS;\n      goto err;\n      break;\n    default:\n      r = ONIGERR_PARSER_BUG;\n      goto err;\n      break;\n    }\n\n    if (fetched)\n      r = tok->type;\n    else {\n      r = fetch_token_in_cc(tok, &p, end, env);\n      if (r < 0) goto err;\n    }\n  }\n\n  if (state == CCS_VALUE) {\n    r = next_state_val(cc, &vs, 0, &val_israw, 0, val_type,\n                       &val_type, &state, env);\n    if (r != 0) goto err;\n  }\n\n  if (IS_NOT_NULL(prev_cc)) {\n    r = and_cclass(prev_cc, cc, env->enc);\n    if (r != 0) goto err;\n    bbuf_free(cc->mbuf);\n    cc = prev_cc;\n  }\n\n  if (neg != 0)\n    NCCLASS_SET_NOT(cc);\n  else\n    NCCLASS_CLEAR_NOT(cc);\n  if (IS_NCCLASS_NOT(cc) &&\n      IS_SYNTAX_BV(env->syntax, ONIG_SYN_NOT_NEWLINE_IN_NEGATIVE_CC)) {\n    int is_empty = (IS_NULL(cc->mbuf) ? 1 : 0);\n    if (is_empty != 0)\n      BITSET_IS_EMPTY(cc->bs, is_empty);\n\n    if (is_empty == 0) {\n#define NEWLINE_CODE    0x0a\n\n      if (ONIGENC_IS_CODE_NEWLINE(env->enc, NEWLINE_CODE)) {\n        if (ONIGENC_CODE_TO_MBCLEN(env->enc, NEWLINE_CODE) == 1)\n          BITSET_SET_BIT(cc->bs, NEWLINE_CODE);\n        else\n          add_code_range(&(cc->mbuf), env, NEWLINE_CODE, NEWLINE_CODE);\n      }\n    }\n  }\n  *src = p;\n  env->parse_depth--;\n  return 0;\n\n err:\n  if (cc != CCLASS_(*np))\n    bbuf_free(cc->mbuf);\n  return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,6 +16,7 @@\n   env->parse_depth++;\n   if (env->parse_depth > ParseDepthLimit)\n     return ONIGERR_PARSE_DEPTH_LIMIT_OVER;\n+\n   prev_cc = (CClassNode* )NULL;\n   r = fetch_token_in_cc(tok, src, end, env);\n   if (r == TK_CHAR && tok->u.c == '^' && tok->escaped == 0) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2018-16300",
        "func_name": "the-tcpdump-group/tcpdump/bgp_update_print",
        "description": "The BGP parser in tcpdump before 4.9.3 allows stack consumption in print-bgp.c:bgp_attr_print() because of unlimited recursion.",
        "git_url": "https://github.com/the-tcpdump-group/tcpdump/commit/af2cf04a9394c1a56227c2289ae8da262828294a",
        "commit_title": "(for 4.9.3) CVE-2018-16300/BGP: prevent stack exhaustion",
        "commit_text": " Enforce a limit on how many times bgp_attr_print() can recurse.  This fixes a stack exhaustion discovered by Include Security working under the Mozilla SOS program in 2018 by means of code audit.",
        "func_before": "static void\nbgp_update_print(netdissect_options *ndo,\n                 const u_char *dat, int length)\n{\n\tstruct bgp bgp;\n\tconst u_char *p;\n\tint withdrawn_routes_len;\n\tint len;\n\tint i;\n\n\tND_TCHECK2(dat[0], BGP_SIZE);\n\tif (length < BGP_SIZE)\n\t\tgoto trunc;\n\tmemcpy(&bgp, dat, BGP_SIZE);\n\tp = dat + BGP_SIZE;\t/*XXX*/\n\tlength -= BGP_SIZE;\n\n\t/* Unfeasible routes */\n\tND_TCHECK2(p[0], 2);\n\tif (length < 2)\n\t\tgoto trunc;\n\twithdrawn_routes_len = EXTRACT_16BITS(p);\n\tp += 2;\n\tlength -= 2;\n\tif (withdrawn_routes_len) {\n\t\t/*\n\t\t * Without keeping state from the original NLRI message,\n\t\t * it's not possible to tell if this a v4 or v6 route,\n\t\t * so only try to decode it if we're not v6 enabled.\n\t         */\n\t\tND_TCHECK2(p[0], withdrawn_routes_len);\n\t\tif (length < withdrawn_routes_len)\n\t\t\tgoto trunc;\n\t\tND_PRINT((ndo, \"\\n\\t  Withdrawn routes: %d bytes\", withdrawn_routes_len));\n\t\tp += withdrawn_routes_len;\n\t\tlength -= withdrawn_routes_len;\n\t}\n\n\tND_TCHECK2(p[0], 2);\n\tif (length < 2)\n\t\tgoto trunc;\n\tlen = EXTRACT_16BITS(p);\n\tp += 2;\n\tlength -= 2;\n\n        if (withdrawn_routes_len == 0 && len == 0 && length == 0) {\n            /* No withdrawn routes, no path attributes, no NLRI */\n            ND_PRINT((ndo, \"\\n\\t  End-of-Rib Marker (empty NLRI)\"));\n            return;\n        }\n\n\tif (len) {\n\t\t/* do something more useful!*/\n\t\twhile (len) {\n\t\t\tint aflags, atype, alenlen, alen;\n\n\t\t\tND_TCHECK2(p[0], 2);\n\t\t\tif (len < 2)\n\t\t\t    goto trunc;\n\t\t\tif (length < 2)\n\t\t\t    goto trunc;\n\t\t\taflags = *p;\n\t\t\tatype = *(p + 1);\n\t\t\tp += 2;\n\t\t\tlen -= 2;\n\t\t\tlength -= 2;\n\t\t\talenlen = bgp_attr_lenlen(aflags, p);\n\t\t\tND_TCHECK2(p[0], alenlen);\n\t\t\tif (len < alenlen)\n\t\t\t    goto trunc;\n\t\t\tif (length < alenlen)\n\t\t\t    goto trunc;\n\t\t\talen = bgp_attr_len(aflags, p);\n\t\t\tp += alenlen;\n\t\t\tlen -= alenlen;\n\t\t\tlength -= alenlen;\n\n\t\t\tND_PRINT((ndo, \"\\n\\t  %s (%u), length: %u\",\n                              tok2str(bgp_attr_values, \"Unknown Attribute\",\n\t\t\t\t\t atype),\n                              atype,\n                              alen));\n\n\t\t\tif (aflags) {\n\t\t\t\tND_PRINT((ndo, \", Flags [%s%s%s%s\",\n\t\t\t\t\taflags & 0x80 ? \"O\" : \"\",\n\t\t\t\t\taflags & 0x40 ? \"T\" : \"\",\n\t\t\t\t\taflags & 0x20 ? \"P\" : \"\",\n\t\t\t\t\taflags & 0x10 ? \"E\" : \"\"));\n\t\t\t\tif (aflags & 0xf)\n\t\t\t\t\tND_PRINT((ndo, \"+%x\", aflags & 0xf));\n\t\t\t\tND_PRINT((ndo, \"]: \"));\n\t\t\t}\n\t\t\tif (len < alen)\n\t\t\t\tgoto trunc;\n\t\t\tif (length < alen)\n\t\t\t\tgoto trunc;\n\t\t\tif (!bgp_attr_print(ndo, atype, p, alen))\n\t\t\t\tgoto trunc;\n\t\t\tp += alen;\n\t\t\tlen -= alen;\n\t\t\tlength -= alen;\n\t\t}\n\t}\n\n\tif (length) {\n\t\t/*\n\t\t * XXX - what if they're using the \"Advertisement of\n\t\t * Multiple Paths in BGP\" feature:\n\t\t *\n\t\t * https://datatracker.ietf.org/doc/draft-ietf-idr-add-paths/\n\t\t *\n\t\t * http://tools.ietf.org/html/draft-ietf-idr-add-paths-06\n\t\t */\n\t\tND_PRINT((ndo, \"\\n\\t  Updated routes:\"));\n\t\twhile (length) {\n\t\t\tchar buf[MAXHOSTNAMELEN + 100];\n\t\t\ti = decode_prefix4(ndo, p, length, buf, sizeof(buf));\n\t\t\tif (i == -1) {\n\t\t\t\tND_PRINT((ndo, \"\\n\\t    (illegal prefix length)\"));\n\t\t\t\tbreak;\n\t\t\t} else if (i == -2)\n\t\t\t\tgoto trunc;\n\t\t\telse if (i == -3)\n\t\t\t\tgoto trunc; /* bytes left, but not enough */\n\t\t\telse {\n\t\t\t\tND_PRINT((ndo, \"\\n\\t    %s\", buf));\n\t\t\t\tp += i;\n\t\t\t\tlength -= i;\n\t\t\t}\n\t\t}\n\t}\n\treturn;\ntrunc:\n\tND_PRINT((ndo, \"%s\", tstr));\n}",
        "func": "static void\nbgp_update_print(netdissect_options *ndo,\n                 const u_char *dat, int length)\n{\n\tstruct bgp bgp;\n\tconst u_char *p;\n\tint withdrawn_routes_len;\n\tint len;\n\tint i;\n\n\tND_TCHECK2(dat[0], BGP_SIZE);\n\tif (length < BGP_SIZE)\n\t\tgoto trunc;\n\tmemcpy(&bgp, dat, BGP_SIZE);\n\tp = dat + BGP_SIZE;\t/*XXX*/\n\tlength -= BGP_SIZE;\n\n\t/* Unfeasible routes */\n\tND_TCHECK2(p[0], 2);\n\tif (length < 2)\n\t\tgoto trunc;\n\twithdrawn_routes_len = EXTRACT_16BITS(p);\n\tp += 2;\n\tlength -= 2;\n\tif (withdrawn_routes_len) {\n\t\t/*\n\t\t * Without keeping state from the original NLRI message,\n\t\t * it's not possible to tell if this a v4 or v6 route,\n\t\t * so only try to decode it if we're not v6 enabled.\n\t         */\n\t\tND_TCHECK2(p[0], withdrawn_routes_len);\n\t\tif (length < withdrawn_routes_len)\n\t\t\tgoto trunc;\n\t\tND_PRINT((ndo, \"\\n\\t  Withdrawn routes: %d bytes\", withdrawn_routes_len));\n\t\tp += withdrawn_routes_len;\n\t\tlength -= withdrawn_routes_len;\n\t}\n\n\tND_TCHECK2(p[0], 2);\n\tif (length < 2)\n\t\tgoto trunc;\n\tlen = EXTRACT_16BITS(p);\n\tp += 2;\n\tlength -= 2;\n\n        if (withdrawn_routes_len == 0 && len == 0 && length == 0) {\n            /* No withdrawn routes, no path attributes, no NLRI */\n            ND_PRINT((ndo, \"\\n\\t  End-of-Rib Marker (empty NLRI)\"));\n            return;\n        }\n\n\tif (len) {\n\t\t/* do something more useful!*/\n\t\twhile (len) {\n\t\t\tint aflags, atype, alenlen, alen;\n\n\t\t\tND_TCHECK2(p[0], 2);\n\t\t\tif (len < 2)\n\t\t\t    goto trunc;\n\t\t\tif (length < 2)\n\t\t\t    goto trunc;\n\t\t\taflags = *p;\n\t\t\tatype = *(p + 1);\n\t\t\tp += 2;\n\t\t\tlen -= 2;\n\t\t\tlength -= 2;\n\t\t\talenlen = bgp_attr_lenlen(aflags, p);\n\t\t\tND_TCHECK2(p[0], alenlen);\n\t\t\tif (len < alenlen)\n\t\t\t    goto trunc;\n\t\t\tif (length < alenlen)\n\t\t\t    goto trunc;\n\t\t\talen = bgp_attr_len(aflags, p);\n\t\t\tp += alenlen;\n\t\t\tlen -= alenlen;\n\t\t\tlength -= alenlen;\n\n\t\t\tND_PRINT((ndo, \"\\n\\t  %s (%u), length: %u\",\n                              tok2str(bgp_attr_values, \"Unknown Attribute\",\n\t\t\t\t\t atype),\n                              atype,\n                              alen));\n\n\t\t\tif (aflags) {\n\t\t\t\tND_PRINT((ndo, \", Flags [%s%s%s%s\",\n\t\t\t\t\taflags & 0x80 ? \"O\" : \"\",\n\t\t\t\t\taflags & 0x40 ? \"T\" : \"\",\n\t\t\t\t\taflags & 0x20 ? \"P\" : \"\",\n\t\t\t\t\taflags & 0x10 ? \"E\" : \"\"));\n\t\t\t\tif (aflags & 0xf)\n\t\t\t\t\tND_PRINT((ndo, \"+%x\", aflags & 0xf));\n\t\t\t\tND_PRINT((ndo, \"]: \"));\n\t\t\t}\n\t\t\tif (len < alen)\n\t\t\t\tgoto trunc;\n\t\t\tif (length < alen)\n\t\t\t\tgoto trunc;\n\t\t\tif (!bgp_attr_print(ndo, atype, p, alen, 0))\n\t\t\t\tgoto trunc;\n\t\t\tp += alen;\n\t\t\tlen -= alen;\n\t\t\tlength -= alen;\n\t\t}\n\t}\n\n\tif (length) {\n\t\t/*\n\t\t * XXX - what if they're using the \"Advertisement of\n\t\t * Multiple Paths in BGP\" feature:\n\t\t *\n\t\t * https://datatracker.ietf.org/doc/draft-ietf-idr-add-paths/\n\t\t *\n\t\t * http://tools.ietf.org/html/draft-ietf-idr-add-paths-06\n\t\t */\n\t\tND_PRINT((ndo, \"\\n\\t  Updated routes:\"));\n\t\twhile (length) {\n\t\t\tchar buf[MAXHOSTNAMELEN + 100];\n\t\t\ti = decode_prefix4(ndo, p, length, buf, sizeof(buf));\n\t\t\tif (i == -1) {\n\t\t\t\tND_PRINT((ndo, \"\\n\\t    (illegal prefix length)\"));\n\t\t\t\tbreak;\n\t\t\t} else if (i == -2)\n\t\t\t\tgoto trunc;\n\t\t\telse if (i == -3)\n\t\t\t\tgoto trunc; /* bytes left, but not enough */\n\t\t\telse {\n\t\t\t\tND_PRINT((ndo, \"\\n\\t    %s\", buf));\n\t\t\t\tp += i;\n\t\t\t\tlength -= i;\n\t\t\t}\n\t\t}\n\t}\n\treturn;\ntrunc:\n\tND_PRINT((ndo, \"%s\", tstr));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -95,7 +95,7 @@\n \t\t\t\tgoto trunc;\n \t\t\tif (length < alen)\n \t\t\t\tgoto trunc;\n-\t\t\tif (!bgp_attr_print(ndo, atype, p, alen))\n+\t\t\tif (!bgp_attr_print(ndo, atype, p, alen, 0))\n \t\t\t\tgoto trunc;\n \t\t\tp += alen;\n \t\t\tlen -= alen;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (!bgp_attr_print(ndo, atype, p, alen))"
            ],
            "added_lines": [
                "\t\t\tif (!bgp_attr_print(ndo, atype, p, alen, 0))"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-16452",
        "func_name": "the-tcpdump-group/tcpdump/smb_fdata",
        "description": "The SMB parser in tcpdump before 4.9.3 has stack exhaustion in smbutil.c:smb_fdata() via recursion.",
        "git_url": "https://github.com/the-tcpdump-group/tcpdump/commit/24182d959f661327525a20d9a94c98a8ec016778",
        "commit_title": "(for 4.9.3) CVE-2018-16452/SMB: prevent stack exhaustion",
        "commit_text": " Enforce a limit on how many times smb_fdata() can recurse.  This fixes a stack exhaustion discovered by Include Security working under the Mozilla SOS program in 2018 by means of code audit.",
        "func_before": "const u_char *\nsmb_fdata(netdissect_options *ndo,\n          const u_char *buf, const char *fmt, const u_char *maxbuf,\n          int unicodestr)\n{\n    static int depth = 0;\n    char s[128];\n    char *p;\n\n    while (*fmt) {\n\tswitch (*fmt) {\n\tcase '*':\n\t    fmt++;\n\t    while (buf < maxbuf) {\n\t\tconst u_char *buf2;\n\t\tdepth++;\n\t\tbuf2 = smb_fdata(ndo, buf, fmt, maxbuf, unicodestr);\n\t\tdepth--;\n\t\tif (buf2 == NULL)\n\t\t    return(NULL);\n\t\tif (buf2 == buf)\n\t\t    return(buf);\n\t\tbuf = buf2;\n\t    }\n\t    return(buf);\n\n\tcase '|':\n\t    fmt++;\n\t    if (buf >= maxbuf)\n\t\treturn(buf);\n\t    break;\n\n\tcase '%':\n\t    fmt++;\n\t    buf = maxbuf;\n\t    break;\n\n\tcase '#':\n\t    fmt++;\n\t    return(buf);\n\t    break;\n\n\tcase '[':\n\t    fmt++;\n\t    if (buf >= maxbuf)\n\t\treturn(buf);\n\t    memset(s, 0, sizeof(s));\n\t    p = strchr(fmt, ']');\n\t    if ((size_t)(p - fmt + 1) > sizeof(s)) {\n\t\t/* overrun */\n\t\treturn(buf);\n\t    }\n\t    strncpy(s, fmt, p - fmt);\n\t    s[p - fmt] = '\\0';\n\t    fmt = p + 1;\n\t    buf = smb_fdata1(ndo, buf, s, maxbuf, unicodestr);\n\t    if (buf == NULL)\n\t\treturn(NULL);\n\t    break;\n\n\tdefault:\n\t    ND_PRINT((ndo, \"%c\", *fmt));\n\t    fmt++;\n\t    break;\n\t}\n    }\n    if (!depth && buf < maxbuf) {\n\tsize_t len = PTR_DIFF(maxbuf, buf);\n\tND_PRINT((ndo, \"Data: (%lu bytes)\\n\", (unsigned long)len));\n\tsmb_print_data(ndo, buf, len);\n\treturn(buf + len);\n    }\n    return(buf);\n}",
        "func": "const u_char *\nsmb_fdata(netdissect_options *ndo,\n          const u_char *buf, const char *fmt, const u_char *maxbuf,\n          int unicodestr)\n{\n    static int depth = 0;\n    char s[128];\n    char *p;\n\n    while (*fmt) {\n\tswitch (*fmt) {\n\tcase '*':\n\t    fmt++;\n\t    while (buf < maxbuf) {\n\t\tconst u_char *buf2;\n\t\tdepth++;\n\t\t/* Not sure how this relates with the protocol specification,\n\t\t * but in order to avoid stack exhaustion recurse at most that\n\t\t * many levels.\n\t\t */\n\t\tif (depth == 10)\n\t\t\tND_PRINT((ndo, \"(too many nested levels, not recursing)\"));\n\t\telse\n\t\t\tbuf2 = smb_fdata(ndo, buf, fmt, maxbuf, unicodestr);\n\t\tdepth--;\n\t\tif (buf2 == NULL)\n\t\t    return(NULL);\n\t\tif (buf2 == buf)\n\t\t    return(buf);\n\t\tbuf = buf2;\n\t    }\n\t    return(buf);\n\n\tcase '|':\n\t    fmt++;\n\t    if (buf >= maxbuf)\n\t\treturn(buf);\n\t    break;\n\n\tcase '%':\n\t    fmt++;\n\t    buf = maxbuf;\n\t    break;\n\n\tcase '#':\n\t    fmt++;\n\t    return(buf);\n\t    break;\n\n\tcase '[':\n\t    fmt++;\n\t    if (buf >= maxbuf)\n\t\treturn(buf);\n\t    memset(s, 0, sizeof(s));\n\t    p = strchr(fmt, ']');\n\t    if ((size_t)(p - fmt + 1) > sizeof(s)) {\n\t\t/* overrun */\n\t\treturn(buf);\n\t    }\n\t    strncpy(s, fmt, p - fmt);\n\t    s[p - fmt] = '\\0';\n\t    fmt = p + 1;\n\t    buf = smb_fdata1(ndo, buf, s, maxbuf, unicodestr);\n\t    if (buf == NULL)\n\t\treturn(NULL);\n\t    break;\n\n\tdefault:\n\t    ND_PRINT((ndo, \"%c\", *fmt));\n\t    fmt++;\n\t    break;\n\t}\n    }\n    if (!depth && buf < maxbuf) {\n\tsize_t len = PTR_DIFF(maxbuf, buf);\n\tND_PRINT((ndo, \"Data: (%lu bytes)\\n\", (unsigned long)len));\n\tsmb_print_data(ndo, buf, len);\n\treturn(buf + len);\n    }\n    return(buf);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,14 @@\n \t    while (buf < maxbuf) {\n \t\tconst u_char *buf2;\n \t\tdepth++;\n-\t\tbuf2 = smb_fdata(ndo, buf, fmt, maxbuf, unicodestr);\n+\t\t/* Not sure how this relates with the protocol specification,\n+\t\t * but in order to avoid stack exhaustion recurse at most that\n+\t\t * many levels.\n+\t\t */\n+\t\tif (depth == 10)\n+\t\t\tND_PRINT((ndo, \"(too many nested levels, not recursing)\"));\n+\t\telse\n+\t\t\tbuf2 = smb_fdata(ndo, buf, fmt, maxbuf, unicodestr);\n \t\tdepth--;\n \t\tif (buf2 == NULL)\n \t\t    return(NULL);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tbuf2 = smb_fdata(ndo, buf, fmt, maxbuf, unicodestr);"
            ],
            "added_lines": [
                "\t\t/* Not sure how this relates with the protocol specification,",
                "\t\t * but in order to avoid stack exhaustion recurse at most that",
                "\t\t * many levels.",
                "\t\t */",
                "\t\tif (depth == 10)",
                "\t\t\tND_PRINT((ndo, \"(too many nested levels, not recursing)\"));",
                "\t\telse",
                "\t\t\tbuf2 = smb_fdata(ndo, buf, fmt, maxbuf, unicodestr);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46505",
        "func_name": "pcmacdon/jsish/jsi_FuncMake",
        "description": "Jsish v3.5.0 was discovered to contain a stack overflow via /usr/lib/x86_64-linux-gnu/libasan.so.4+0x5b1e5.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/619df528295ef564592a898d58b560c3f3176e21",
        "commit_title": "Fixes #53",
        "commit_text": " FossilOrigin-Name: 82b73736b7e8564290aefb236f94c390a5284066f41d8c05d3646f6c0f1b99c4",
        "func_before": "Jsi_Func *jsi_FuncMake(jsi_Pstate *pstate, Jsi_ScopeStrs *args, Jsi_OpCodes *ops,\n    jsi_Pline* line, const char *name, int flags)\n{\n    Jsi_Interp *interp = pstate->interp;\n    Jsi_ScopeStrs *localvar = jsi_ScopeGetVarlist(pstate);\n    Jsi_Func *f = jsi_FuncNew(interp);\n    jsi_Lexer *l = pstate->lexer;\n    f->isArrow = flags&1;\n    if (f->isArrow && interp->noES6) {\n        Jsi_LogError(\"es6 feature: arrow function '%s'\", name);\n        pstate->err_count++;\n    }\n    f->isSet = flags&2;\n    f->isGet = flags&4;\n    f->type = FC_NORMAL;\n    f->opcodes = ops;\n    f->argnames = args;\n    f->localnames = localvar;\n    f->bodyline = *line;\n    f->retType = (Jsi_otype)args->retType;\n    if (l->ltype == LT_STRING)\n        f->bodyStr = l->d.str;\n    f->endPos = l->cur;\n    f->startPos = -1; // Have to get these from newline count.\n    if (f->retType & JSI_TT_UNDEFINED)\n        Jsi_LogWarn(\"invalid use of 'undefined' in a return type: %s\", name?name:\"\");\n    \n    pstate->argType = 0;\n    if (localvar && args && (!interp->noCheck)) {\n        int i, j;\n        for (i=0; i<args->count; i++) {\n            for (j=0; j<args->count; j++) {\n                if (i != j && !Jsi_Strcmp(args->args[i].name, args->args[j].name)) {\n                        if (line)\n                            interp->parseLine = line;\n                        Jsi_LogError(\"function %s():  duplicate parameter name '%s'\", name?name:\"\", args->args[i].name);\n                        if (line)\n                            interp->parseLine = NULL;\n                        pstate->err_count++;\n                }\n            }\n            for (j=0; j<localvar->count; j++) {\n                if (!Jsi_Strcmp(localvar->args[j].name, args->args[i].name)) {\n                        if (line)\n                            interp->parseLine = line;\n                        Jsi_LogError(\"function %s():  parameter name conflicts with local '%s'\", name?name:\"\", localvar->args[j].name);\n                        if (line)\n                            interp->parseLine = NULL;\n                        pstate->err_count++;\n                }\n            }\n        }\n    }\n    if (name) {\n        if ((name[0] == 'a' && !Jsi_Strcmp(name,\"assert\"))\n            || (name[0] == 'L' && (!Jsi_Strcmp(name,\"LogDebug\") || !Jsi_Strcmp(name,\"LogTrace\") || !Jsi_Strcmp(name,\"LogTest\")))) {\n                if (line)\n                    interp->parseLine = line;\n                Jsi_LogError(\"invalid redefine of builtin: %s\", name);\n                if (line)\n                    interp->parseLine = NULL;\n                pstate->err_count++;\n        }\n        f->name = Jsi_KeyAdd(interp, name);\n        if (!interp->noCheck) {\n            \n            if (f->retType && !(f->retType&JSI_TT_VOID) && ops && ops->code_len && ops->codes[ops->code_len-1].op != OP_RET) {\n                if (line)\n                    interp->parseLine = line;\n                Jsi_LogWarn(\"missing return at end of function '%s'\", name);\n                if (line)\n                    interp->parseLine = NULL;\n                //if (interp->typeCheck.error)\n                 //   pstate->err_count++;\n            }\n             \n            Jsi_Func *fo = (Jsi_Func*)Jsi_HashGet(interp->staticFuncsTbl, (void*)name, 0);\n            \n            // Forward declaration signature compare (indicated by an empty body).\n            if (interp->typeCheck.funcdecl && fo && fo->opcodes && fo->opcodes->code_len == 1 && fo->opcodes->codes->op == OP_NOP) {\n                if (!jsi_FuncSigsMatch(pstate, f, fo)) {\n                    if (line)\n                        interp->parseLine = line;\n                    Jsi_LogWarn(\"possible signature mismatch for function '%s' at %.120s:%d\", name, fo->filePtr->fileName, fo->bodyline.first_line);\n                    if (line)\n                        interp->parseLine = NULL;\n                    jsi_TypeMismatch(interp);\n                }\n                //printf(\"OLD: %s\\n\", name);\n            }\n            Jsi_HashSet(interp->staticFuncsTbl, name, f);\n        }\n    }\n    return f;\n}",
        "func": "Jsi_Func *jsi_FuncMake(jsi_Pstate *pstate, Jsi_ScopeStrs *args, Jsi_OpCodes *ops,\n    jsi_Pline* line, const char *name, int flags)\n{\n    Jsi_Interp *interp = pstate->interp;\n    Jsi_ScopeStrs *localvar = jsi_ScopeGetVarlist(pstate);\n    Jsi_Func *f = jsi_FuncNew(interp);\n    jsi_Lexer *l = pstate->lexer;\n    f->isArrow = flags&1;\n    if (f->isArrow && interp->noES6) {\n        Jsi_LogError(\"es6 feature: arrow function '%s'\", name);\n        pstate->err_count++;\n    }\n    f->isSet = flags&2;\n    f->isGet = flags&4;\n    f->type = FC_NORMAL;\n    f->opcodes = ops;\n    f->argnames = args;\n    f->localnames = localvar;\n    f->bodyline = *line;\n    f->retType = (Jsi_otype)args->retType;\n    if (l->ltype == LT_STRING)\n        f->bodyStr = l->d.str;\n    f->endPos = l->cur;\n    f->startPos = -1; // Have to get these from newline count.\n    if (f->retType & JSI_TT_UNDEFINED)\n        Jsi_LogWarn(\"invalid use of 'undefined' in a return type: %s\", name?name:\"\");\n    \n    pstate->argType = 0;\n    if (localvar && args && (!interp->noCheck)) {\n        int i, j;\n        for (i=0; i<args->count; i++) {\n            char *anam = args->args[i].name;\n            if (Jsi_IsReserved(interp, anam, 0)) {\n                if (line)\n                    interp->parseLine = line;\n                Jsi_LogError(\"function %s():  reserved parameter name '%s'\", name?name:\"\", anam);\n                if (line)\n                    interp->parseLine = NULL;\n                pstate->err_count++;\n                break;\n            }\n            for (j=0; j<args->count; j++) {\n                if (i != j && !Jsi_Strcmp(anam, args->args[j].name)) {\n                    if (line)\n                        interp->parseLine = line;\n                    Jsi_LogError(\"function %s():  duplicate parameter name '%s'\", name?name:\"\", anam);\n                    if (line)\n                        interp->parseLine = NULL;\n                    pstate->err_count++;\n                }\n            }\n            for (j=0; j<localvar->count; j++) {\n                if (!Jsi_Strcmp(localvar->args[j].name, args->args[i].name)) {\n                    if (line)\n                        interp->parseLine = line;\n                    Jsi_LogError(\"function %s():  parameter name conflicts with local '%s'\", name?name:\"\", localvar->args[j].name);\n                    if (line)\n                        interp->parseLine = NULL;\n                    pstate->err_count++;\n                }\n            }\n        }\n    }\n    if (name) {\n        if ((name[0] == 'a' && !Jsi_Strcmp(name,\"assert\"))\n            || (name[0] == 'L' && (!Jsi_Strcmp(name,\"LogDebug\") || !Jsi_Strcmp(name,\"LogTrace\") || !Jsi_Strcmp(name,\"LogTest\")))) {\n                if (line)\n                    interp->parseLine = line;\n                Jsi_LogError(\"invalid redefine of builtin: %s\", name);\n                if (line)\n                    interp->parseLine = NULL;\n                pstate->err_count++;\n        }\n        f->name = Jsi_KeyAdd(interp, name);\n        if (!interp->noCheck) {\n            \n            if (f->retType && !(f->retType&JSI_TT_VOID) && ops && ops->code_len && ops->codes[ops->code_len-1].op != OP_RET) {\n                if (line)\n                    interp->parseLine = line;\n                Jsi_LogWarn(\"missing return at end of function '%s'\", name);\n                if (line)\n                    interp->parseLine = NULL;\n                //if (interp->typeCheck.error)\n                 //   pstate->err_count++;\n            }\n             \n            Jsi_Func *fo = (Jsi_Func*)Jsi_HashGet(interp->staticFuncsTbl, (void*)name, 0);\n            \n            // Forward declaration signature compare (indicated by an empty body).\n            if (interp->typeCheck.funcdecl && fo && fo->opcodes && fo->opcodes->code_len == 1 && fo->opcodes->codes->op == OP_NOP) {\n                if (!jsi_FuncSigsMatch(pstate, f, fo)) {\n                    if (line)\n                        interp->parseLine = line;\n                    Jsi_LogWarn(\"possible signature mismatch for function '%s' at %.120s:%d\", name, fo->filePtr->fileName, fo->bodyline.first_line);\n                    if (line)\n                        interp->parseLine = NULL;\n                    jsi_TypeMismatch(interp);\n                }\n                //printf(\"OLD: %s\\n\", name);\n            }\n            Jsi_HashSet(interp->staticFuncsTbl, name, f);\n        }\n    }\n    return f;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,24 +29,34 @@\n     if (localvar && args && (!interp->noCheck)) {\n         int i, j;\n         for (i=0; i<args->count; i++) {\n+            char *anam = args->args[i].name;\n+            if (Jsi_IsReserved(interp, anam, 0)) {\n+                if (line)\n+                    interp->parseLine = line;\n+                Jsi_LogError(\"function %s():  reserved parameter name '%s'\", name?name:\"\", anam);\n+                if (line)\n+                    interp->parseLine = NULL;\n+                pstate->err_count++;\n+                break;\n+            }\n             for (j=0; j<args->count; j++) {\n-                if (i != j && !Jsi_Strcmp(args->args[i].name, args->args[j].name)) {\n-                        if (line)\n-                            interp->parseLine = line;\n-                        Jsi_LogError(\"function %s():  duplicate parameter name '%s'\", name?name:\"\", args->args[i].name);\n-                        if (line)\n-                            interp->parseLine = NULL;\n-                        pstate->err_count++;\n+                if (i != j && !Jsi_Strcmp(anam, args->args[j].name)) {\n+                    if (line)\n+                        interp->parseLine = line;\n+                    Jsi_LogError(\"function %s():  duplicate parameter name '%s'\", name?name:\"\", anam);\n+                    if (line)\n+                        interp->parseLine = NULL;\n+                    pstate->err_count++;\n                 }\n             }\n             for (j=0; j<localvar->count; j++) {\n                 if (!Jsi_Strcmp(localvar->args[j].name, args->args[i].name)) {\n-                        if (line)\n-                            interp->parseLine = line;\n-                        Jsi_LogError(\"function %s():  parameter name conflicts with local '%s'\", name?name:\"\", localvar->args[j].name);\n-                        if (line)\n-                            interp->parseLine = NULL;\n-                        pstate->err_count++;\n+                    if (line)\n+                        interp->parseLine = line;\n+                    Jsi_LogError(\"function %s():  parameter name conflicts with local '%s'\", name?name:\"\", localvar->args[j].name);\n+                    if (line)\n+                        interp->parseLine = NULL;\n+                    pstate->err_count++;\n                 }\n             }\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "                if (i != j && !Jsi_Strcmp(args->args[i].name, args->args[j].name)) {",
                "                        if (line)",
                "                            interp->parseLine = line;",
                "                        Jsi_LogError(\"function %s():  duplicate parameter name '%s'\", name?name:\"\", args->args[i].name);",
                "                        if (line)",
                "                            interp->parseLine = NULL;",
                "                        pstate->err_count++;",
                "                        if (line)",
                "                            interp->parseLine = line;",
                "                        Jsi_LogError(\"function %s():  parameter name conflicts with local '%s'\", name?name:\"\", localvar->args[j].name);",
                "                        if (line)",
                "                            interp->parseLine = NULL;",
                "                        pstate->err_count++;"
            ],
            "added_lines": [
                "            char *anam = args->args[i].name;",
                "            if (Jsi_IsReserved(interp, anam, 0)) {",
                "                if (line)",
                "                    interp->parseLine = line;",
                "                Jsi_LogError(\"function %s():  reserved parameter name '%s'\", name?name:\"\", anam);",
                "                if (line)",
                "                    interp->parseLine = NULL;",
                "                pstate->err_count++;",
                "                break;",
                "            }",
                "                if (i != j && !Jsi_Strcmp(anam, args->args[j].name)) {",
                "                    if (line)",
                "                        interp->parseLine = line;",
                "                    Jsi_LogError(\"function %s():  duplicate parameter name '%s'\", name?name:\"\", anam);",
                "                    if (line)",
                "                        interp->parseLine = NULL;",
                "                    pstate->err_count++;",
                "                    if (line)",
                "                        interp->parseLine = line;",
                "                    Jsi_LogError(\"function %s():  parameter name conflicts with local '%s'\", name?name:\"\", localvar->args[j].name);",
                "                    if (line)",
                "                        interp->parseLine = NULL;",
                "                    pstate->err_count++;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46505",
        "func_name": "pcmacdon/jsish/jsi_InitLexer",
        "description": "Jsish v3.5.0 was discovered to contain a stack overflow via /usr/lib/x86_64-linux-gnu/libasan.so.4+0x5b1e5.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/619df528295ef564592a898d58b560c3f3176e21",
        "commit_title": "Fixes #53",
        "commit_text": " FossilOrigin-Name: 82b73736b7e8564290aefb236f94c390a5284066f41d8c05d3646f6c0f1b99c4",
        "func_before": "Jsi_RC jsi_InitLexer(Jsi_Interp *interp, int release)\n{\n    static struct st_kw {\n        const char *name;\n        uintptr_t value;\n    } keywords[] = {\n        { \"if\", IF },\n        { \"else\", ELSE },\n        { \"for\", FOR },\n        { \"in\", IN },\n        { \"while\", WHILE },\n        { \"do\", DO },\n        { \"continue\", CONTINUE },\n        { \"switch\", SWITCH },\n        { \"case\", CASE },\n        { \"default\", DEFAULT },\n        { \"break\", BREAK },\n        { \"function\", FUNC },\n        { \"return\", RETURN },\n        { \"var\", LOCAL },\n        { \"let\", LOCALLET },\n        { \"const\", LOCALCONST },\n        { \"of\", OF },\n        { \"new\", NEW },\n        { \"delete\", DELETE },\n        { \"try\", TRY },\n        { \"catch\", CATCH },\n        { \"throw\", THROW },\n        { \"finally\", FINALLY },\n        { \"with\", WITH },\n        { \"undefined\", UNDEF },\n        { \"true\", _TRUE },\n        { \"false\", _FALSE },\n        { \"this\", _THIS },\n        { \"arguments\", ARGUMENTS },\n        { \"void\", VOID },\n        { \"typeof\", TYPEOF },\n        { \"instanceof\", INSTANCEOF },\n        { \"string\", TYPESTRING },\n        { \"number\", TYPENUMBER },\n        { \"regexp\", TYPEREGEXP },\n        { \"any\", TYPEANY },\n        { \"userobj\", TYPEUSEROBJ },\n        { \"iterobj\", TYPEITEROBJ },\n        { \"object\", TYPEOBJECT },\n        { \"boolean\", TYPEBOOLEAN },\n        { \"array\", TYPEARRAY },\n        { \"null\", TYPENULL },\n        { \"export\", EXPORT },\n        { \"set\", OBJSET },\n        { \"get\", OBJGET },\n        { \"...\", ELLIPSIS },\n        { \"debugger\", __DEBUG }\n    };\n    uint i;\n    Jsi_HashEntry *hPtr;\n    if (release) return JSI_OK;\n    if (!interp->lexkeyTbl->numEntries) {\n        bool isNew;\n        for (i = 0; i < sizeof(keywords) / sizeof(struct st_kw); ++i) {\n            hPtr = Jsi_HashEntryNew(interp->lexkeyTbl, keywords[i].name, &isNew);\n            assert(hPtr);\n            if (hPtr)\n                Jsi_HashValueSet(hPtr, (void*)keywords[i].value);\n        }\n    }\n    return JSI_OK;\n}",
        "func": "Jsi_RC jsi_InitLexer(Jsi_Interp *interp, int release)\n{\n    static struct st_kw {\n        const char *name;\n        uintptr_t value;\n    } keywords[] = {\n        { \"if\", IF },\n        { \"else\", ELSE },\n        { \"for\", FOR },\n        { \"in\", IN },\n        { \"while\", WHILE },\n        { \"do\", DO },\n        { \"continue\", CONTINUE },\n        { \"switch\", SWITCH },\n        { \"case\", CASE },\n        { \"default\", DEFAULT },\n        { \"break\", BREAK },\n        { \"function\", FUNC },\n        { \"return\", RETURN },\n        { \"var\", LOCAL },\n        { \"let\", LOCALLET },\n        { \"const\", LOCALCONST },\n        { \"of\", OF },\n        { \"new\", NEW },\n        { \"delete\", DELETE },\n        { \"try\", TRY },\n        { \"catch\", CATCH },\n        { \"throw\", THROW },\n        { \"finally\", FINALLY },\n        { \"with\", WITH },\n        { \"undefined\", UNDEF },\n        { \"true\", _TRUE },\n        { \"false\", _FALSE },\n        { \"this\", _THIS },\n        { \"arguments\", ARGUMENTS },\n        { \"void\", VOID },\n        { \"typeof\", TYPEOF },\n        { \"instanceof\", INSTANCEOF },\n        { \"string\", TYPESTRING },\n        { \"number\", TYPENUMBER },\n        { \"regexp\", TYPEREGEXP },\n        { \"any\", TYPEANY },\n        { \"userobj\", TYPEUSEROBJ },\n        { \"iterobj\", TYPEITEROBJ },\n        { \"object\", TYPEOBJECT },\n        { \"boolean\", TYPEBOOLEAN },\n        { \"array\", TYPEARRAY },\n        { \"null\", TYPENULL },\n        { \"export\", EXPORT },\n        { \"set\", OBJSET },\n        { \"get\", OBJGET },\n        { \"...\", ELLIPSIS },\n        { \"debugger\", __DEBUG },\n        { \"Array\", 0 },\n        { \"Boolean\", 0 },\n        { \"Channel\", 0 },\n        { \"Event\", 0 },\n        { \"File\", 0 },\n        { \"Function\", 0 },\n        { \"Info\", 0 },\n        { \"Interp\", 0 },\n        { \"JSON\", 0 },\n        { \"Math\", 0 },\n        { \"MySql\", 0 },\n        { \"Number\", 0 },\n        { \"Object\", 0 },\n        { \"RegExp\", 0 },\n        { \"Signal\", 0 },\n        { \"Socket\", 0 },\n        { \"Sqlite\", 0 },\n        { \"String\", 0 },\n        { \"System\", 0 },\n        { \"Util\", 0 },\n        { \"Vfs\", 0 },\n        { \"WebSocket\", 0 },\n        { \"Zvfs\", 0 },\n        { \"JSON\", 0 },\n        { \"console\", 0 },\n\n    };\n    uint i;\n    Jsi_HashEntry *hPtr;\n    if (release) return JSI_OK;\n    if (!interp->lexkeyTbl->numEntries) {\n        bool isNew;\n        for (i = 0; i < sizeof(keywords) / sizeof(struct st_kw) && keywords[i].name; ++i) {\n            hPtr = Jsi_HashEntryNew(interp->lexkeyTbl, keywords[i].name, &isNew);\n            assert(hPtr);\n            if (hPtr)\n                Jsi_HashValueSet(hPtr, (void*)keywords[i].value);\n        }\n    }\n    return JSI_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -50,14 +50,40 @@\n         { \"set\", OBJSET },\n         { \"get\", OBJGET },\n         { \"...\", ELLIPSIS },\n-        { \"debugger\", __DEBUG }\n+        { \"debugger\", __DEBUG },\n+        { \"Array\", 0 },\n+        { \"Boolean\", 0 },\n+        { \"Channel\", 0 },\n+        { \"Event\", 0 },\n+        { \"File\", 0 },\n+        { \"Function\", 0 },\n+        { \"Info\", 0 },\n+        { \"Interp\", 0 },\n+        { \"JSON\", 0 },\n+        { \"Math\", 0 },\n+        { \"MySql\", 0 },\n+        { \"Number\", 0 },\n+        { \"Object\", 0 },\n+        { \"RegExp\", 0 },\n+        { \"Signal\", 0 },\n+        { \"Socket\", 0 },\n+        { \"Sqlite\", 0 },\n+        { \"String\", 0 },\n+        { \"System\", 0 },\n+        { \"Util\", 0 },\n+        { \"Vfs\", 0 },\n+        { \"WebSocket\", 0 },\n+        { \"Zvfs\", 0 },\n+        { \"JSON\", 0 },\n+        { \"console\", 0 },\n+\n     };\n     uint i;\n     Jsi_HashEntry *hPtr;\n     if (release) return JSI_OK;\n     if (!interp->lexkeyTbl->numEntries) {\n         bool isNew;\n-        for (i = 0; i < sizeof(keywords) / sizeof(struct st_kw); ++i) {\n+        for (i = 0; i < sizeof(keywords) / sizeof(struct st_kw) && keywords[i].name; ++i) {\n             hPtr = Jsi_HashEntryNew(interp->lexkeyTbl, keywords[i].name, &isNew);\n             assert(hPtr);\n             if (hPtr)",
        "diff_line_info": {
            "deleted_lines": [
                "        { \"debugger\", __DEBUG }",
                "        for (i = 0; i < sizeof(keywords) / sizeof(struct st_kw); ++i) {"
            ],
            "added_lines": [
                "        { \"debugger\", __DEBUG },",
                "        { \"Array\", 0 },",
                "        { \"Boolean\", 0 },",
                "        { \"Channel\", 0 },",
                "        { \"Event\", 0 },",
                "        { \"File\", 0 },",
                "        { \"Function\", 0 },",
                "        { \"Info\", 0 },",
                "        { \"Interp\", 0 },",
                "        { \"JSON\", 0 },",
                "        { \"Math\", 0 },",
                "        { \"MySql\", 0 },",
                "        { \"Number\", 0 },",
                "        { \"Object\", 0 },",
                "        { \"RegExp\", 0 },",
                "        { \"Signal\", 0 },",
                "        { \"Socket\", 0 },",
                "        { \"Sqlite\", 0 },",
                "        { \"String\", 0 },",
                "        { \"System\", 0 },",
                "        { \"Util\", 0 },",
                "        { \"Vfs\", 0 },",
                "        { \"WebSocket\", 0 },",
                "        { \"Zvfs\", 0 },",
                "        { \"JSON\", 0 },",
                "        { \"console\", 0 },",
                "",
                "        for (i = 0; i < sizeof(keywords) / sizeof(struct st_kw) && keywords[i].name; ++i) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-46507",
        "func_name": "pcmacdon/jsish/Jsi_ValueToString",
        "description": "Jsish v3.5.0 was discovered to contain a stack overflow via Jsi_LogMsg at src/jsiUtils.c.",
        "git_url": "https://github.com/pcmacdon/jsish/commit/b99d9eac3d01d3f9ea8959aed092168c0aadd448",
        "commit_title": "Fixes #54",
        "commit_text": " FossilOrigin-Name: e8cfa1f794ef05c67d00ebb5575c08f3987e71709bca5072cf2a7924870ae0e5",
        "func_before": "const char* Jsi_ValueToString(Jsi_Interp *interp, Jsi_Value *v, int *lenPtr)\n{\n    Jsi_Number d;\n    const char *ntxt = \"undefined\";\n    int kflag = 1;\n    int isKey = 0;\n    char *key = NULL;\n    if (!v)\n        goto done;\n    if (lenPtr) *lenPtr = 0;\n    char unibuf[JSI_MAX_NUMBER_STRING*2];\n    switch(v->vt) {\n        case JSI_VT_STRING:\n            ntxt = v->d.s.str;\n            goto done;\n        case JSI_VT_UNDEF:\n            break;\n        case JSI_VT_BOOL:\n            ntxt = v->d.val ? \"true\":\"false\";\n            break;\n        case JSI_VT_NULL:\n            ntxt = \"null\";\n            break;\n        case JSI_VT_NUMBER: {\n            d = v->d.num;\nfmtnum:\n            if (Jsi_NumberIsInteger(d)) {\n                Jsi_NumberItoA10((Jsi_Wide)d, unibuf, sizeof(unibuf));\n                kflag = 0;\n                ntxt = unibuf;\n            } else if (Jsi_NumberIsNormal(d)) {\n                Jsi_NumberDtoA(interp, d, unibuf, sizeof(unibuf), 0);\n                kflag = 0;\n                ntxt = unibuf;\n            } else if (Jsi_NumberIsNaN(v->d.num)) {\n                ntxt = \"NaN\";\n            } else {\n                int s = Jsi_NumberIsInfinity(d);\n                if (s > 0) ntxt = \"Infinity\";\n                else if (s < 0) ntxt = \"-Infinity\";\n                else Jsi_LogBug(\"Ieee function got problem\");\n            }\n            break;\n        }\n        case JSI_VT_OBJECT: {\n            Jsi_Obj *obj = v->d.obj;\n            switch(obj->ot) {\n                case JSI_OT_STRING:\n                    ntxt = obj->d.s.str;\n                    goto done;\n                case JSI_OT_BOOL:\n                    ntxt = obj->d.val ? \"true\":\"false\";\n                    break;\n                case JSI_OT_NUMBER:\n                    d = obj->d.num;\n                    goto fmtnum;\n                    break;\n                default:\n                    ntxt = \"[object Object]\";\n                    break;\n            }\n            break;\n        }\n        default:\n            Jsi_LogBug(\"Convert a unknown type: 0x%x to string\", v->vt);\n            break;\n    }\n    Jsi_ValueReset(interp, &v);\n    if (!kflag) {\n        Jsi_ValueMakeStringDup(interp, &v, ntxt);\n        return Jsi_ValueString(interp, v, lenPtr);\n    }\n    \n    key = jsi_KeyFind(interp, ntxt, 0, &isKey);\n    if (key)\n        Jsi_ValueMakeStringKey(interp, &v, key);\n    else\n        Jsi_ValueMakeString(interp, &v, ntxt);\n    ntxt = v->d.s.str;\n    \ndone:\n    if (lenPtr) *lenPtr = Jsi_Strlen(ntxt);\n    return ntxt;\n}",
        "func": "const char* Jsi_ValueToString(Jsi_Interp *interp, Jsi_Value *v, int *lenPtr)\n{\n    Jsi_Number d;\n    const char *ntxt = \"undefined\";\n    int kflag = 1;\n    int isKey = 0;\n    char *key = NULL;\n    if (!v)\n        goto done;\n    if (lenPtr) *lenPtr = 0;\n    char unibuf[JSI_MAX_NUMBER_STRING*2];\n    switch(v->vt) {\n        case JSI_VT_STRING:\n            ntxt = v->d.s.str;\n            goto done;\n        case JSI_VT_UNDEF:\n            break;\n        case JSI_VT_BOOL:\n            ntxt = v->d.val ? \"true\":\"false\";\n            break;\n        case JSI_VT_NULL:\n            ntxt = \"null\";\n            break;\n        case JSI_VT_NUMBER: {\n            d = v->d.num;\nfmtnum:\n            if (Jsi_NumberIsInteger(d)) {\n                Jsi_NumberItoA10((Jsi_Wide)d, unibuf, sizeof(unibuf));\n                kflag = 0;\n                ntxt = unibuf;\n            } else if (Jsi_NumberIsNormal(d)) {\n                Jsi_NumberDtoA(interp, d, unibuf, sizeof(unibuf), 0);\n                kflag = 0;\n                ntxt = unibuf;\n            } else if (Jsi_NumberIsNaN(v->d.num)) {\n                ntxt = \"NaN\";\n            } else {\n                int s = Jsi_NumberIsInfinity(d);\n                if (s > 0) ntxt = \"Infinity\";\n                else if (s < 0) ntxt = \"-Infinity\";\n                else if (!interp->logMsgDepth) Jsi_LogBug(\"Ieee function got problem\");\n            }\n            break;\n        }\n        case JSI_VT_OBJECT: {\n            Jsi_Obj *obj = v->d.obj;\n            switch(obj->ot) {\n                case JSI_OT_STRING:\n                    ntxt = obj->d.s.str;\n                    goto done;\n                case JSI_OT_BOOL:\n                    ntxt = obj->d.val ? \"true\":\"false\";\n                    break;\n                case JSI_OT_NUMBER:\n                    d = obj->d.num;\n                    goto fmtnum;\n                    break;\n                default:\n                    ntxt = \"[object Object]\";\n                    break;\n            }\n            break;\n        }\n        default:\n            if (!interp->logMsgDepth) Jsi_LogBug(\"Convert a unknown type: 0x%x to string\", v->vt);\n            break;\n    }\n    Jsi_ValueReset(interp, &v);\n    if (!kflag) {\n        Jsi_ValueMakeStringDup(interp, &v, ntxt);\n        return Jsi_ValueString(interp, v, lenPtr);\n    }\n    \n    key = jsi_KeyFind(interp, ntxt, 0, &isKey);\n    if (key)\n        Jsi_ValueMakeStringKey(interp, &v, key);\n    else\n        Jsi_ValueMakeString(interp, &v, ntxt);\n    ntxt = v->d.s.str;\n    \ndone:\n    if (lenPtr) *lenPtr = Jsi_Strlen(ntxt);\n    return ntxt;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,7 +38,7 @@\n                 int s = Jsi_NumberIsInfinity(d);\n                 if (s > 0) ntxt = \"Infinity\";\n                 else if (s < 0) ntxt = \"-Infinity\";\n-                else Jsi_LogBug(\"Ieee function got problem\");\n+                else if (!interp->logMsgDepth) Jsi_LogBug(\"Ieee function got problem\");\n             }\n             break;\n         }\n@@ -62,7 +62,7 @@\n             break;\n         }\n         default:\n-            Jsi_LogBug(\"Convert a unknown type: 0x%x to string\", v->vt);\n+            if (!interp->logMsgDepth) Jsi_LogBug(\"Convert a unknown type: 0x%x to string\", v->vt);\n             break;\n     }\n     Jsi_ValueReset(interp, &v);",
        "diff_line_info": {
            "deleted_lines": [
                "                else Jsi_LogBug(\"Ieee function got problem\");",
                "            Jsi_LogBug(\"Convert a unknown type: 0x%x to string\", v->vt);"
            ],
            "added_lines": [
                "                else if (!interp->logMsgDepth) Jsi_LogBug(\"Ieee function got problem\");",
                "            if (!interp->logMsgDepth) Jsi_LogBug(\"Convert a unknown type: 0x%x to string\", v->vt);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23591",
        "func_name": "tensorflow/ValidateSavedTensors",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The `GraphDef` format in TensorFlow does not allow self recursive functions. The runtime assumes that this invariant is satisfied. However, a `GraphDef` containing a fragment such as the following can be consumed when loading a `SavedModel`. This would result in a stack overflow during execution as resolving each `NodeDef` means resolving the function itself and its nodes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/448a16182065bd08a202d9057dd8ca541e67996c",
        "commit_title": "Prevent stack overflow when FunctionLib in GraphDef has a self-recursive function.",
        "commit_text": " It is likely that no recursivity is supported, but we should handle this separately.  PiperOrigin-RevId: 414860329",
        "func_before": "static Status ValidateSavedTensors(const GraphDef& graph_def) {\n  for (const auto& node : graph_def.node()) {\n    TF_RETURN_IF_ERROR(ValidateNode(node));\n  }\n\n  if (graph_def.has_library()) {\n    const FunctionDefLibrary& library = graph_def.library();\n    for (const auto& function : library.function()) {\n      for (const auto& node : function.node_def()) {\n        TF_RETURN_IF_ERROR(ValidateNode(node));\n      }\n    }\n  }\n\n  return Status::OK();\n}",
        "func": "static Status ValidateSavedTensors(const GraphDef& graph_def) {\n  for (const auto& node : graph_def.node()) {\n    TF_RETURN_IF_ERROR(ValidateNode(node));\n  }\n\n  if (graph_def.has_library()) {\n    const FunctionDefLibrary& library = graph_def.library();\n    for (const auto& function : library.function()) {\n      for (const auto& node : function.node_def()) {\n        TF_RETURN_IF_ERROR(ValidateNode(node));\n      }\n\n      // Also check that there is no recursivity in the library\n      // TODO(mihaimaruseac): Do more than self-recursivity\n      TF_RETURN_IF_ERROR(ValidateFunctionNotRecursive(function));\n    }\n  }\n\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,10 @@\n       for (const auto& node : function.node_def()) {\n         TF_RETURN_IF_ERROR(ValidateNode(node));\n       }\n+\n+      // Also check that there is no recursivity in the library\n+      // TODO(mihaimaruseac): Do more than self-recursivity\n+      TF_RETURN_IF_ERROR(ValidateFunctionNotRecursive(function));\n     }\n   }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "      // Also check that there is no recursivity in the library",
                "      // TODO(mihaimaruseac): Do more than self-recursivity",
                "      TF_RETURN_IF_ERROR(ValidateFunctionNotRecursive(function));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-25313",
        "func_name": "libexpat/build_model",
        "description": "In Expat (aka libexpat) before 2.4.5, an attacker can trigger stack exhaustion in build_model via a large nesting depth in the DTD element.",
        "git_url": "https://github.com/libexpat/libexpat/commit/9b4ce651b26557f16103c3a366c91934ecd439ab",
        "commit_title": "Prevent stack exhaustion in build_model",
        "commit_text": " It is possible to trigger stack exhaustion in build_model function if depth of nested children in DTD element is large enough. This happens because build_node is a recursively called function within build_model.  The code has been adjusted to run iteratively. It uses the already allocated heap space as temporary stack (growing from top to bottom).  Output is identical to recursive version. No new fields in data structures were added, i.e. it keeps full API and ABI compatibility. Instead the numchildren variable is used to temporarily keep the index of items (uint vs int).  Documentation and readability improvements kindly added by Sebastian.  Proof of Concept:  1. Compile poc binary which parses XML file line by line  ``` cat > poc.c << EOF  #include <err.h>  #include <expat.h>  #include <stdio.h>   XML_Parser parser;   static void XMLCALL  dummy_element_decl_handler(void *userData, const XML_Char *name,                             XML_Content *model) {    XML_FreeContentModel(parser, model);  }   int main(int argc, char *argv[]) {    FILE *fp;    char *p = NULL;    size_t s = 0;    ssize_t l;    if (argc != 2)      errx(1, \"usage: poc poc.xml\");    if ((parser = XML_ParserCreate(NULL)) == NULL)      errx(1, \"XML_ParserCreate\");    XML_SetElementDeclHandler(parser, dummy_element_decl_handler);    if ((fp = fopen(argv[1], \"r\")) == NULL)      err(1, \"fopen\");    while ((l = getline(&p, &s, fp)) > 0)      if (XML_Parse(parser, p, (int)l, XML_FALSE) != XML_STATUS_OK)        errx(1, \"XML_Parse\");    XML_ParserFree(parser);    free(p);    fclose(fp);    return 0;  } EOF cc -std=c11 -D_POSIX_C_SOURCE=200809L -lexpat -o poc poc.c ```  2. Create XML file with a lot of nested groups in DTD element  ``` cat > poc.xml.zst.b64 << EOF KLUv/aQkACAAPAEA+DwhRE9DVFlQRSB1d3UgWwo8IUVMRU1FTlQgdXd1CigBAHv/58AJAgAQKAIA ECgCABAoAgAQKAIAECgCABAoAgAQKHwAAChvd28KKQIA2/8gV24XBAIAECkCABApAgAQKQIAECkC ABApAgAQKQIAEClVAAAgPl0+CgEA4A4I2VwwnQ== EOF base64 -d poc.xml.zst.b64 | zstd -d > poc.xml ```  3. Run Proof of Concept  ``` ./poc poc.xml ```  Co-authored-by: Sebastian Pipping <sebastian@pipping.org>",
        "func_before": "static XML_Content *\nbuild_model(XML_Parser parser) {\n  DTD *const dtd = parser->m_dtd; /* save one level of indirection */\n  XML_Content *ret;\n  XML_Content *cpos;\n  XML_Char *str;\n\n  /* Detect and prevent integer overflow.\n   * The preprocessor guard addresses the \"always false\" warning\n   * from -Wtype-limits on platforms where\n   * sizeof(unsigned int) < sizeof(size_t), e.g. on x86_64. */\n#if UINT_MAX >= SIZE_MAX\n  if (dtd->scaffCount > (size_t)(-1) / sizeof(XML_Content)) {\n    return NULL;\n  }\n  if (dtd->contentStringLen > (size_t)(-1) / sizeof(XML_Char)) {\n    return NULL;\n  }\n#endif\n  if (dtd->scaffCount * sizeof(XML_Content)\n      > (size_t)(-1) - dtd->contentStringLen * sizeof(XML_Char)) {\n    return NULL;\n  }\n\n  const size_t allocsize = (dtd->scaffCount * sizeof(XML_Content)\n                            + (dtd->contentStringLen * sizeof(XML_Char)));\n\n  ret = (XML_Content *)MALLOC(parser, allocsize);\n  if (! ret)\n    return NULL;\n\n  str = (XML_Char *)(&ret[dtd->scaffCount]);\n  cpos = &ret[1];\n\n  build_node(parser, 0, ret, &cpos, &str);\n  return ret;\n}",
        "func": "static XML_Content *\nbuild_model(XML_Parser parser) {\n  /* Function build_model transforms the existing parser->m_dtd->scaffold\n   * array of CONTENT_SCAFFOLD tree nodes into a new array of\n   * XML_Content tree nodes followed by a gapless list of zero-terminated\n   * strings. */\n  DTD *const dtd = parser->m_dtd; /* save one level of indirection */\n  XML_Content *ret;\n  XML_Char *str; /* the current string writing location */\n\n  /* Detect and prevent integer overflow.\n   * The preprocessor guard addresses the \"always false\" warning\n   * from -Wtype-limits on platforms where\n   * sizeof(unsigned int) < sizeof(size_t), e.g. on x86_64. */\n#if UINT_MAX >= SIZE_MAX\n  if (dtd->scaffCount > (size_t)(-1) / sizeof(XML_Content)) {\n    return NULL;\n  }\n  if (dtd->contentStringLen > (size_t)(-1) / sizeof(XML_Char)) {\n    return NULL;\n  }\n#endif\n  if (dtd->scaffCount * sizeof(XML_Content)\n      > (size_t)(-1) - dtd->contentStringLen * sizeof(XML_Char)) {\n    return NULL;\n  }\n\n  const size_t allocsize = (dtd->scaffCount * sizeof(XML_Content)\n                            + (dtd->contentStringLen * sizeof(XML_Char)));\n\n  ret = (XML_Content *)MALLOC(parser, allocsize);\n  if (! ret)\n    return NULL;\n\n  /* What follows is an iterative implementation (of what was previously done\n   * recursively in a dedicated function called \"build_node\".  The old recursive\n   * build_node could be forced into stack exhaustion from input as small as a\n   * few megabyte, and so that was a security issue.  Hence, a function call\n   * stack is avoided now by resolving recursion.)\n   *\n   * The iterative approach works as follows:\n   *\n   * - We use space in the target array for building a temporary stack structure\n   *   while that space is still unused.\n   *   The stack grows from the array's end downwards and the \"actual data\"\n   *   grows from the start upwards, sequentially.\n   *   (Because stack grows downwards, pushing onto the stack is a decrement\n   *   while popping off the stack is an increment.)\n   *\n   * - A stack element appears as a regular XML_Content node on the outside,\n   *   but only uses a single field -- numchildren -- to store the source\n   *   tree node array index.  These are the breadcrumbs leading the way back\n   *   during pre-order (node first) depth-first traversal.\n   *\n   * - The reason we know the stack will never grow into (or overlap with)\n   *   the area with data of value at the start of the array is because\n   *   the overall number of elements to process matches the size of the array,\n   *   and the sum of fully processed nodes and yet-to-be processed nodes\n   *   on the stack, cannot be more than the total number of nodes.\n   *   It is possible for the top of the stack and the about-to-write node\n   *   to meet, but that is safe because we get the source index out\n   *   before doing any writes on that node.\n   */\n  XML_Content *dest = ret; /* tree node writing location, moves upwards */\n  XML_Content *const destLimit = &ret[dtd->scaffCount];\n  XML_Content *const stackBottom = &ret[dtd->scaffCount];\n  XML_Content *stackTop = stackBottom; /* i.e. stack is initially empty */\n  str = (XML_Char *)&ret[dtd->scaffCount];\n\n  /* Push source tree root node index onto the stack */\n  (--stackTop)->numchildren = 0;\n\n  for (; dest < destLimit; dest++) {\n    /* Pop source tree node index off the stack */\n    const int src_node = (int)(stackTop++)->numchildren;\n\n    /* Convert item */\n    dest->type = dtd->scaffold[src_node].type;\n    dest->quant = dtd->scaffold[src_node].quant;\n    if (dest->type == XML_CTYPE_NAME) {\n      const XML_Char *src;\n      dest->name = str;\n      src = dtd->scaffold[src_node].name;\n      for (;;) {\n        *str++ = *src;\n        if (! *src)\n          break;\n        src++;\n      }\n      dest->numchildren = 0;\n      dest->children = NULL;\n    } else {\n      unsigned int i;\n      int cn;\n      dest->name = NULL;\n      dest->numchildren = dtd->scaffold[src_node].childcnt;\n      dest->children = &dest[1];\n\n      /* Push children to the stack\n       * in a way where the first child ends up at the top of the\n       * (downwards growing) stack, in order to be processed first. */\n      stackTop -= dest->numchildren;\n      for (i = 0, cn = dtd->scaffold[src_node].firstchild;\n           i < dest->numchildren; i++, cn = dtd->scaffold[cn].nextsib) {\n        (stackTop + i)->numchildren = (unsigned int)cn;\n      }\n    }\n  }\n\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,12 @@\n static XML_Content *\n build_model(XML_Parser parser) {\n+  /* Function build_model transforms the existing parser->m_dtd->scaffold\n+   * array of CONTENT_SCAFFOLD tree nodes into a new array of\n+   * XML_Content tree nodes followed by a gapless list of zero-terminated\n+   * strings. */\n   DTD *const dtd = parser->m_dtd; /* save one level of indirection */\n   XML_Content *ret;\n-  XML_Content *cpos;\n-  XML_Char *str;\n+  XML_Char *str; /* the current string writing location */\n \n   /* Detect and prevent integer overflow.\n    * The preprocessor guard addresses the \"always false\" warning\n@@ -29,9 +32,80 @@\n   if (! ret)\n     return NULL;\n \n-  str = (XML_Char *)(&ret[dtd->scaffCount]);\n-  cpos = &ret[1];\n+  /* What follows is an iterative implementation (of what was previously done\n+   * recursively in a dedicated function called \"build_node\".  The old recursive\n+   * build_node could be forced into stack exhaustion from input as small as a\n+   * few megabyte, and so that was a security issue.  Hence, a function call\n+   * stack is avoided now by resolving recursion.)\n+   *\n+   * The iterative approach works as follows:\n+   *\n+   * - We use space in the target array for building a temporary stack structure\n+   *   while that space is still unused.\n+   *   The stack grows from the array's end downwards and the \"actual data\"\n+   *   grows from the start upwards, sequentially.\n+   *   (Because stack grows downwards, pushing onto the stack is a decrement\n+   *   while popping off the stack is an increment.)\n+   *\n+   * - A stack element appears as a regular XML_Content node on the outside,\n+   *   but only uses a single field -- numchildren -- to store the source\n+   *   tree node array index.  These are the breadcrumbs leading the way back\n+   *   during pre-order (node first) depth-first traversal.\n+   *\n+   * - The reason we know the stack will never grow into (or overlap with)\n+   *   the area with data of value at the start of the array is because\n+   *   the overall number of elements to process matches the size of the array,\n+   *   and the sum of fully processed nodes and yet-to-be processed nodes\n+   *   on the stack, cannot be more than the total number of nodes.\n+   *   It is possible for the top of the stack and the about-to-write node\n+   *   to meet, but that is safe because we get the source index out\n+   *   before doing any writes on that node.\n+   */\n+  XML_Content *dest = ret; /* tree node writing location, moves upwards */\n+  XML_Content *const destLimit = &ret[dtd->scaffCount];\n+  XML_Content *const stackBottom = &ret[dtd->scaffCount];\n+  XML_Content *stackTop = stackBottom; /* i.e. stack is initially empty */\n+  str = (XML_Char *)&ret[dtd->scaffCount];\n \n-  build_node(parser, 0, ret, &cpos, &str);\n+  /* Push source tree root node index onto the stack */\n+  (--stackTop)->numchildren = 0;\n+\n+  for (; dest < destLimit; dest++) {\n+    /* Pop source tree node index off the stack */\n+    const int src_node = (int)(stackTop++)->numchildren;\n+\n+    /* Convert item */\n+    dest->type = dtd->scaffold[src_node].type;\n+    dest->quant = dtd->scaffold[src_node].quant;\n+    if (dest->type == XML_CTYPE_NAME) {\n+      const XML_Char *src;\n+      dest->name = str;\n+      src = dtd->scaffold[src_node].name;\n+      for (;;) {\n+        *str++ = *src;\n+        if (! *src)\n+          break;\n+        src++;\n+      }\n+      dest->numchildren = 0;\n+      dest->children = NULL;\n+    } else {\n+      unsigned int i;\n+      int cn;\n+      dest->name = NULL;\n+      dest->numchildren = dtd->scaffold[src_node].childcnt;\n+      dest->children = &dest[1];\n+\n+      /* Push children to the stack\n+       * in a way where the first child ends up at the top of the\n+       * (downwards growing) stack, in order to be processed first. */\n+      stackTop -= dest->numchildren;\n+      for (i = 0, cn = dtd->scaffold[src_node].firstchild;\n+           i < dest->numchildren; i++, cn = dtd->scaffold[cn].nextsib) {\n+        (stackTop + i)->numchildren = (unsigned int)cn;\n+      }\n+    }\n+  }\n+\n   return ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  XML_Content *cpos;",
                "  XML_Char *str;",
                "  str = (XML_Char *)(&ret[dtd->scaffCount]);",
                "  cpos = &ret[1];",
                "  build_node(parser, 0, ret, &cpos, &str);"
            ],
            "added_lines": [
                "  /* Function build_model transforms the existing parser->m_dtd->scaffold",
                "   * array of CONTENT_SCAFFOLD tree nodes into a new array of",
                "   * XML_Content tree nodes followed by a gapless list of zero-terminated",
                "   * strings. */",
                "  XML_Char *str; /* the current string writing location */",
                "  /* What follows is an iterative implementation (of what was previously done",
                "   * recursively in a dedicated function called \"build_node\".  The old recursive",
                "   * build_node could be forced into stack exhaustion from input as small as a",
                "   * few megabyte, and so that was a security issue.  Hence, a function call",
                "   * stack is avoided now by resolving recursion.)",
                "   *",
                "   * The iterative approach works as follows:",
                "   *",
                "   * - We use space in the target array for building a temporary stack structure",
                "   *   while that space is still unused.",
                "   *   The stack grows from the array's end downwards and the \"actual data\"",
                "   *   grows from the start upwards, sequentially.",
                "   *   (Because stack grows downwards, pushing onto the stack is a decrement",
                "   *   while popping off the stack is an increment.)",
                "   *",
                "   * - A stack element appears as a regular XML_Content node on the outside,",
                "   *   but only uses a single field -- numchildren -- to store the source",
                "   *   tree node array index.  These are the breadcrumbs leading the way back",
                "   *   during pre-order (node first) depth-first traversal.",
                "   *",
                "   * - The reason we know the stack will never grow into (or overlap with)",
                "   *   the area with data of value at the start of the array is because",
                "   *   the overall number of elements to process matches the size of the array,",
                "   *   and the sum of fully processed nodes and yet-to-be processed nodes",
                "   *   on the stack, cannot be more than the total number of nodes.",
                "   *   It is possible for the top of the stack and the about-to-write node",
                "   *   to meet, but that is safe because we get the source index out",
                "   *   before doing any writes on that node.",
                "   */",
                "  XML_Content *dest = ret; /* tree node writing location, moves upwards */",
                "  XML_Content *const destLimit = &ret[dtd->scaffCount];",
                "  XML_Content *const stackBottom = &ret[dtd->scaffCount];",
                "  XML_Content *stackTop = stackBottom; /* i.e. stack is initially empty */",
                "  str = (XML_Char *)&ret[dtd->scaffCount];",
                "  /* Push source tree root node index onto the stack */",
                "  (--stackTop)->numchildren = 0;",
                "",
                "  for (; dest < destLimit; dest++) {",
                "    /* Pop source tree node index off the stack */",
                "    const int src_node = (int)(stackTop++)->numchildren;",
                "",
                "    /* Convert item */",
                "    dest->type = dtd->scaffold[src_node].type;",
                "    dest->quant = dtd->scaffold[src_node].quant;",
                "    if (dest->type == XML_CTYPE_NAME) {",
                "      const XML_Char *src;",
                "      dest->name = str;",
                "      src = dtd->scaffold[src_node].name;",
                "      for (;;) {",
                "        *str++ = *src;",
                "        if (! *src)",
                "          break;",
                "        src++;",
                "      }",
                "      dest->numchildren = 0;",
                "      dest->children = NULL;",
                "    } else {",
                "      unsigned int i;",
                "      int cn;",
                "      dest->name = NULL;",
                "      dest->numchildren = dtd->scaffold[src_node].childcnt;",
                "      dest->children = &dest[1];",
                "",
                "      /* Push children to the stack",
                "       * in a way where the first child ends up at the top of the",
                "       * (downwards growing) stack, in order to be processed first. */",
                "      stackTop -= dest->numchildren;",
                "      for (i = 0, cn = dtd->scaffold[src_node].firstchild;",
                "           i < dest->numchildren; i++, cn = dtd->scaffold[cn].nextsib) {",
                "        (stackTop + i)->numchildren = (unsigned int)cn;",
                "      }",
                "    }",
                "  }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3222",
        "func_name": "gpac/SFScript_Parse",
        "description": "Uncontrolled Recursion in GitHub repository gpac/gpac prior to 2.1.0-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4e7736d7ec7bf64026daa611da951993bb42fdaf",
        "commit_title": "fixed #2238",
        "commit_text": "",
        "func_before": "GF_Err SFScript_Parse(GF_BifsDecoder *codec, SFScript *script_field, GF_BitStream *bs, GF_Node *n)\n{\n\tGF_Err e;\n\tu32 i, count, nbBits;\n\tchar *ptr;\n\tScriptParser parser;\n\te = GF_OK;\n\tif (gf_node_get_tag(n) != TAG_MPEG4_Script) return GF_NON_COMPLIANT_BITSTREAM;\n\n\tparser.codec = codec;\n\tparser.script = n;\n\tparser.bs = bs;\n\tparser.length = 500;\n\tparser.string = (char *) gf_malloc(sizeof(char)* parser.length);\n\tparser.string[0] = 0;\n\tparser.identifiers = gf_list_new();\n\tparser.new_line = (char *) (codec->dec_memory_mode ? \"\\n\" : NULL);\n\tparser.indent = 0;\n\n\t//first parse fields\n\n\tif (gf_bs_read_int(bs, 1)) {\n\t\t//endFlag\n\t\twhile (!gf_bs_read_int(bs, 1)) {\n\t\t\te = ParseScriptField(&parser);\n\t\t\tif (e) goto exit;\n\t\t}\n\t} else {\n\t\tnbBits = gf_bs_read_int(bs, 4);\n\t\tcount = gf_bs_read_int(bs, nbBits);\n\t\tfor (i=0; i<count; i++) {\n\t\t\te = ParseScriptField(&parser);\n\t\t\tif (e) goto exit;\n\t\t}\n\t}\n\t//reserevd\n\tgf_bs_read_int(bs, 1);\n\t//then parse\n\tSFS_AddString(&parser, \"javascript:\");\n\tSFS_AddString(&parser, parser.new_line);\n\n\t//hasFunction\n\twhile (gf_bs_read_int(bs, 1)) {\n\t\tSFS_AddString(&parser, \"function \");\n\t\tSFS_Identifier(&parser);\n\t\tSFS_Arguments(&parser, GF_FALSE);\n\t\tSFS_Space(&parser);\n\t\tSFS_StatementBlock(&parser, GF_TRUE);\n\t\tSFS_Line(&parser);\n\t}\n\n\tSFS_Line(&parser);\n\n\tif (script_field->script_text) gf_free(script_field->script_text);\n\tscript_field->script_text = (char *) gf_strdup(parser.string);\n\nexit:\n\t//clean up\n\twhile (gf_list_count(parser.identifiers)) {\n\t\tptr = (char *)gf_list_get(parser.identifiers, 0);\n\t\tgf_free(ptr);\n\t\tgf_list_rem(parser.identifiers, 0);\n\t}\n\tgf_list_del(parser.identifiers);\n\tif (parser.string) gf_free(parser.string);\n\treturn e;\n}",
        "func": "GF_Err SFScript_Parse(GF_BifsDecoder *codec, SFScript *script_field, GF_BitStream *bs, GF_Node *n)\n{\n\tGF_Err e;\n\tu32 i, count, nbBits;\n\tchar *ptr;\n\tScriptParser parser;\n\te = GF_OK;\n\tif (gf_node_get_tag(n) != TAG_MPEG4_Script) return GF_NON_COMPLIANT_BITSTREAM;\n\n\tmemset(&parser, 0, sizeof(ScriptParser));\n\tparser.codec = codec;\n\tparser.script = n;\n\tparser.bs = bs;\n\tparser.length = 500;\n\tparser.string = (char *) gf_malloc(sizeof(char)* parser.length);\n\tparser.string[0] = 0;\n\tparser.identifiers = gf_list_new();\n\tparser.new_line = (char *) (codec->dec_memory_mode ? \"\\n\" : NULL);\n\tparser.indent = 0;\n\n\t//first parse fields\n\n\tif (gf_bs_read_int(bs, 1)) {\n\t\t//endFlag\n\t\twhile (!gf_bs_read_int(bs, 1)) {\n\t\t\te = ParseScriptField(&parser);\n\t\t\tif (e) goto exit;\n\t\t}\n\t} else {\n\t\tnbBits = gf_bs_read_int(bs, 4);\n\t\tcount = gf_bs_read_int(bs, nbBits);\n\t\tfor (i=0; i<count; i++) {\n\t\t\te = ParseScriptField(&parser);\n\t\t\tif (e) goto exit;\n\t\t}\n\t}\n\t//reserevd\n\tgf_bs_read_int(bs, 1);\n\t//then parse\n\tSFS_AddString(&parser, \"javascript:\");\n\tSFS_AddString(&parser, parser.new_line);\n\n\t//hasFunction\n\twhile (gf_bs_read_int(bs, 1)) {\n\t\tSFS_AddString(&parser, \"function \");\n\t\tSFS_Identifier(&parser);\n\t\tSFS_Arguments(&parser, GF_FALSE);\n\t\tSFS_Space(&parser);\n\t\tSFS_StatementBlock(&parser, GF_TRUE);\n\t\tSFS_Line(&parser);\n\t\tif (codec->LastError) {\n\t\t\te = codec->LastError;\n\t\t\tgoto exit;\n\t\t}\n\t}\n\n\tSFS_Line(&parser);\n\n\tif (script_field->script_text) gf_free(script_field->script_text);\n\tscript_field->script_text = (char *) gf_strdup(parser.string);\n\nexit:\n\t//clean up\n\twhile (gf_list_count(parser.identifiers)) {\n\t\tptr = (char *)gf_list_get(parser.identifiers, 0);\n\t\tgf_free(ptr);\n\t\tgf_list_rem(parser.identifiers, 0);\n\t}\n\tgf_list_del(parser.identifiers);\n\tif (parser.string) gf_free(parser.string);\n\treturn e;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n \te = GF_OK;\n \tif (gf_node_get_tag(n) != TAG_MPEG4_Script) return GF_NON_COMPLIANT_BITSTREAM;\n \n+\tmemset(&parser, 0, sizeof(ScriptParser));\n \tparser.codec = codec;\n \tparser.script = n;\n \tparser.bs = bs;\n@@ -47,6 +48,10 @@\n \t\tSFS_Space(&parser);\n \t\tSFS_StatementBlock(&parser, GF_TRUE);\n \t\tSFS_Line(&parser);\n+\t\tif (codec->LastError) {\n+\t\t\te = codec->LastError;\n+\t\t\tgoto exit;\n+\t\t}\n \t}\n \n \tSFS_Line(&parser);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tmemset(&parser, 0, sizeof(ScriptParser));",
                "\t\tif (codec->LastError) {",
                "\t\t\te = codec->LastError;",
                "\t\t\tgoto exit;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3222",
        "func_name": "gpac/SFS_ArrayDeref",
        "description": "Uncontrolled Recursion in GitHub repository gpac/gpac prior to 2.1.0-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4e7736d7ec7bf64026daa611da951993bb42fdaf",
        "commit_title": "fixed #2238",
        "commit_text": "",
        "func_before": "void SFS_ArrayDeref(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tSFS_AddString(parser, \"[\");\n\tSFS_CompoundExpression(parser);\n\tSFS_AddString(parser, \"]\");\n}",
        "func": "void SFS_ArrayDeref(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tif (parser->codec->LastError) return;\n\tSFS_AddString(parser, \"[\");\n\tSFS_CompoundExpression(parser);\n\tSFS_AddString(parser, \"]\");\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n {\n \tif (parser->codec->LastError) return;\n \tSFS_Expression(parser);\n+\tif (parser->codec->LastError) return;\n \tSFS_AddString(parser, \"[\");\n \tSFS_CompoundExpression(parser);\n \tSFS_AddString(parser, \"]\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (parser->codec->LastError) return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3222",
        "func_name": "gpac/SFS_ObjectMethodCall",
        "description": "Uncontrolled Recursion in GitHub repository gpac/gpac prior to 2.1.0-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4e7736d7ec7bf64026daa611da951993bb42fdaf",
        "commit_title": "fixed #2238",
        "commit_text": "",
        "func_before": "void SFS_ObjectMethodCall(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tSFS_AddString(parser, \".\");\n\tSFS_Identifier(parser);\n\tSFS_AddString(parser, \"(\");\n\tSFS_Params(parser);\n\tSFS_AddString(parser, \")\");\n}",
        "func": "void SFS_ObjectMethodCall(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tif (parser->codec->LastError) return;\n\tSFS_AddString(parser, \".\");\n\tSFS_Identifier(parser);\n\tSFS_AddString(parser, \"(\");\n\tSFS_Params(parser);\n\tSFS_AddString(parser, \")\");\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n {\n \tif (parser->codec->LastError) return;\n \tSFS_Expression(parser);\n+\tif (parser->codec->LastError) return;\n \tSFS_AddString(parser, \".\");\n \tSFS_Identifier(parser);\n \tSFS_AddString(parser, \"(\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (parser->codec->LastError) return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3222",
        "func_name": "gpac/SFS_ObjectMemberAccess",
        "description": "Uncontrolled Recursion in GitHub repository gpac/gpac prior to 2.1.0-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4e7736d7ec7bf64026daa611da951993bb42fdaf",
        "commit_title": "fixed #2238",
        "commit_text": "",
        "func_before": "void SFS_ObjectMemberAccess(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tSFS_AddString(parser, \".\");\n\tSFS_Identifier(parser);\n}",
        "func": "void SFS_ObjectMemberAccess(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tif (parser->codec->LastError) return;\n\tSFS_AddString(parser, \".\");\n\tSFS_Identifier(parser);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n {\n \tif (parser->codec->LastError) return;\n \tSFS_Expression(parser);\n+\tif (parser->codec->LastError) return;\n \tSFS_AddString(parser, \".\");\n \tSFS_Identifier(parser);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (parser->codec->LastError) return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3222",
        "func_name": "gpac/SFS_Expression",
        "description": "Uncontrolled Recursion in GitHub repository gpac/gpac prior to 2.1.0-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4e7736d7ec7bf64026daa611da951993bb42fdaf",
        "commit_title": "fixed #2238",
        "commit_text": "",
        "func_before": "void SFS_Expression(ScriptParser *parser)\n{\n\tu32 val = gf_bs_read_int(parser->bs, NUMBITS_EXPR_TYPE);\n\tif (parser->codec->LastError) return;\n\n\tswitch(val) {\n\tcase ET_CURVED_EXPR:\n\t\tSFS_AddString(parser, \"(\");\n\t\tSFS_CompoundExpression(parser);\n\t\tSFS_AddString(parser, \")\");\n\t\tbreak;\n\tcase ET_NEGATIVE:\n\t\tSFS_AddString(parser, \"-\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_NOT:\n\t\tSFS_AddString(parser, \"!\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_ONESCOMP:\n\t\tSFS_AddString(parser, \"~\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_INCREMENT:\n\t\tSFS_AddString(parser, \"++\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_DECREMENT:\n\t\tSFS_AddString(parser, \"--\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_POST_INCREMENT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"++\");\n\t\tbreak;\n\tcase ET_POST_DECREMENT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"--\");\n\t\tbreak;\n\tcase ET_CONDTEST:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \" ? \");\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \" : \");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_STRING:\n\t\tSFS_AddString(parser, \"'\");\n\t\tSFS_GetString(parser);\n\t\tSFS_AddString(parser, \"'\");\n\t\tbreak;\n\tcase ET_NUMBER:\n\t\tSFS_GetNumber(parser);\n\t\tbreak;\n\tcase ET_IDENTIFIER:\n\t\tSFS_Identifier(parser);\n\t\tbreak;\n\tcase ET_FUNCTION_CALL:\n\t\tSFS_FunctionCall(parser);\n\t\tbreak;\n\tcase ET_NEW:\n\t\tSFS_NewObject(parser);\n\t\tbreak;\n\tcase ET_OBJECT_MEMBER_ACCESS:\n\t\tSFS_ObjectMemberAccess(parser);\n\t\tbreak;\n\tcase ET_OBJECT_METHOD_CALL:\n\t\tSFS_ObjectMethodCall(parser);\n\t\tbreak;\n\tcase ET_ARRAY_DEREFERENCE:\n\t\tSFS_ArrayDeref(parser);\n\t\tbreak;\n\n\tcase ET_MULTIPLY:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"*\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_DIVIDE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"/\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MOD:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"%\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_PLUS:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"+\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MINUS:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"-\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LSHIFT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<<\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFTFILL:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>>\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_AND:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"&\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_XOR:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"^\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_OR:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"|\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_GT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_GE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_EQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"==\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_NE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"!=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LAND:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"&&\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LOR:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"||\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_ASSIGN:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_PLUSEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"+=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MINUSEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"-=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MULTIPLYEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"*=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_DIVIDEEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"/=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MODEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"%=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LSHIFTEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<<=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFTEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFTFILLEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>>=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_ANDEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"&=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_XOREQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"^=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_OREQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"|=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_BOOLEAN:\n\t\tSFS_GetBoolean(parser);\n\t\tbreak;\n\tcase ET_VAR:\n\t\tSFS_AddString(parser, \"var \");\n\t\tSFS_Arguments(parser, GF_TRUE);\n\t\tbreak;\n\tcase ET_FUNCTION_ASSIGN:\n\t\tSFS_AddString(parser, \"function \");\n\t\tSFS_Arguments(parser, GF_FALSE);\n\t\tSFS_StatementBlock(parser, GF_TRUE);\n\t\tbreak;\n\tdefault:\n\t\tparser->codec->LastError = GF_NON_COMPLIANT_BITSTREAM;\n\t\tbreak;\n\t}\n}",
        "func": "void SFS_Expression(ScriptParser *parser)\n{\n\tu32 val = gf_bs_read_int(parser->bs, NUMBITS_EXPR_TYPE);\n\tif (parser->codec->LastError) return;\n\n\t//limit max expression stack size\n\tparser->expr_stack_size++;\n\tif (parser->expr_stack_size>MAX_EXPR_STACK) {\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODEC, (\"[BIFS] Max stack size %d reached for expressions, not supported\\n\", MAX_EXPR_STACK))\n\t\tparser->codec->LastError = GF_NON_COMPLIANT_BITSTREAM;\n\t\treturn;\n\t}\n\n\tswitch(val) {\n\tcase ET_CURVED_EXPR:\n\t\tSFS_AddString(parser, \"(\");\n\t\tSFS_CompoundExpression(parser);\n\t\tSFS_AddString(parser, \")\");\n\t\tbreak;\n\tcase ET_NEGATIVE:\n\t\tSFS_AddString(parser, \"-\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_NOT:\n\t\tSFS_AddString(parser, \"!\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_ONESCOMP:\n\t\tSFS_AddString(parser, \"~\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_INCREMENT:\n\t\tSFS_AddString(parser, \"++\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_DECREMENT:\n\t\tSFS_AddString(parser, \"--\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_POST_INCREMENT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"++\");\n\t\tbreak;\n\tcase ET_POST_DECREMENT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"--\");\n\t\tbreak;\n\tcase ET_CONDTEST:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \" ? \");\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \" : \");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_STRING:\n\t\tSFS_AddString(parser, \"'\");\n\t\tSFS_GetString(parser);\n\t\tSFS_AddString(parser, \"'\");\n\t\tbreak;\n\tcase ET_NUMBER:\n\t\tSFS_GetNumber(parser);\n\t\tbreak;\n\tcase ET_IDENTIFIER:\n\t\tSFS_Identifier(parser);\n\t\tbreak;\n\tcase ET_FUNCTION_CALL:\n\t\tSFS_FunctionCall(parser);\n\t\tbreak;\n\tcase ET_NEW:\n\t\tSFS_NewObject(parser);\n\t\tbreak;\n\tcase ET_OBJECT_MEMBER_ACCESS:\n\t\tSFS_ObjectMemberAccess(parser);\n\t\tbreak;\n\tcase ET_OBJECT_METHOD_CALL:\n\t\tSFS_ObjectMethodCall(parser);\n\t\tbreak;\n\tcase ET_ARRAY_DEREFERENCE:\n\t\tSFS_ArrayDeref(parser);\n\t\tbreak;\n\n\tcase ET_MULTIPLY:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"*\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_DIVIDE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"/\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MOD:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"%\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_PLUS:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"+\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MINUS:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"-\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LSHIFT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<<\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFTFILL:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>>\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_AND:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"&\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_XOR:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"^\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_OR:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"|\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_GT:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_GE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_EQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"==\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_NE:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"!=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LAND:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"&&\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LOR:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"||\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_ASSIGN:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_PLUSEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"+=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MINUSEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"-=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MULTIPLYEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"*=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_DIVIDEEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"/=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_MODEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"%=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_LSHIFTEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"<<=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFTEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_RSHIFTFILLEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \">>>=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_ANDEQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"&=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_XOREQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"^=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_OREQ:\n\t\tSFS_Expression(parser);\n\t\tSFS_AddString(parser, \"|=\");\n\t\tSFS_Expression(parser);\n\t\tbreak;\n\tcase ET_BOOLEAN:\n\t\tSFS_GetBoolean(parser);\n\t\tbreak;\n\tcase ET_VAR:\n\t\tSFS_AddString(parser, \"var \");\n\t\tSFS_Arguments(parser, GF_TRUE);\n\t\tbreak;\n\tcase ET_FUNCTION_ASSIGN:\n\t\tSFS_AddString(parser, \"function \");\n\t\tSFS_Arguments(parser, GF_FALSE);\n\t\tSFS_StatementBlock(parser, GF_TRUE);\n\t\tbreak;\n\tdefault:\n\t\tparser->codec->LastError = GF_NON_COMPLIANT_BITSTREAM;\n\t\tbreak;\n\t}\n\tparser->expr_stack_size--;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,14 @@\n {\n \tu32 val = gf_bs_read_int(parser->bs, NUMBITS_EXPR_TYPE);\n \tif (parser->codec->LastError) return;\n+\n+\t//limit max expression stack size\n+\tparser->expr_stack_size++;\n+\tif (parser->expr_stack_size>MAX_EXPR_STACK) {\n+\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODEC, (\"[BIFS] Max stack size %d reached for expressions, not supported\\n\", MAX_EXPR_STACK))\n+\t\tparser->codec->LastError = GF_NON_COMPLIANT_BITSTREAM;\n+\t\treturn;\n+\t}\n \n \tswitch(val) {\n \tcase ET_CURVED_EXPR:\n@@ -242,4 +250,5 @@\n \t\tparser->codec->LastError = GF_NON_COMPLIANT_BITSTREAM;\n \t\tbreak;\n \t}\n+\tparser->expr_stack_size--;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t//limit max expression stack size",
                "\tparser->expr_stack_size++;",
                "\tif (parser->expr_stack_size>MAX_EXPR_STACK) {",
                "\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CODEC, (\"[BIFS] Max stack size %d reached for expressions, not supported\\n\", MAX_EXPR_STACK))",
                "\t\tparser->codec->LastError = GF_NON_COMPLIANT_BITSTREAM;",
                "\t\treturn;",
                "\t}",
                "\tparser->expr_stack_size--;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3222",
        "func_name": "gpac/SFS_CompoundExpression",
        "description": "Uncontrolled Recursion in GitHub repository gpac/gpac prior to 2.1.0-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4e7736d7ec7bf64026daa611da951993bb42fdaf",
        "commit_title": "fixed #2238",
        "commit_text": "",
        "func_before": "void SFS_CompoundExpression(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tif (! gf_bs_read_int(parser->bs, 1)) return;\n\tSFS_AddString(parser, \",\");\n\tSFS_CompoundExpression(parser);\n}",
        "func": "void SFS_CompoundExpression(ScriptParser *parser)\n{\n\tif (parser->codec->LastError) return;\n\tSFS_Expression(parser);\n\tif (! gf_bs_read_int(parser->bs, 1)) return;\n\tif (parser->codec->LastError) return;\n\tSFS_AddString(parser, \",\");\n\tSFS_CompoundExpression(parser);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,7 @@\n \tif (parser->codec->LastError) return;\n \tSFS_Expression(parser);\n \tif (! gf_bs_read_int(parser->bs, 1)) return;\n+\tif (parser->codec->LastError) return;\n \tSFS_AddString(parser, \",\");\n \tSFS_CompoundExpression(parser);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (parser->codec->LastError) return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3222",
        "func_name": "gpac/SFS_Params",
        "description": "Uncontrolled Recursion in GitHub repository gpac/gpac prior to 2.1.0-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4e7736d7ec7bf64026daa611da951993bb42fdaf",
        "commit_title": "fixed #2238",
        "commit_text": "",
        "func_before": "void SFS_Params(ScriptParser *parser)\n{\n\tu32 val;\n\tif (parser->codec->LastError) return;\n\tval = gf_bs_read_int(parser->bs, 1);\n\twhile (val) {\n\t\tSFS_Expression(parser);\n\t\tval = gf_bs_read_int(parser->bs, 1);\n\t\tif(val) SFS_AddString(parser, \",\");\n\t}\n}",
        "func": "void SFS_Params(ScriptParser *parser)\n{\n\tu32 val;\n\tif (parser->codec->LastError) return;\n\tval = gf_bs_read_int(parser->bs, 1);\n\twhile (val) {\n\t\tSFS_Expression(parser);\n\t\tif (parser->codec->LastError) return;\n\t\tval = gf_bs_read_int(parser->bs, 1);\n\t\tif(val) SFS_AddString(parser, \",\");\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n \tval = gf_bs_read_int(parser->bs, 1);\n \twhile (val) {\n \t\tSFS_Expression(parser);\n+\t\tif (parser->codec->LastError) return;\n \t\tval = gf_bs_read_int(parser->bs, 1);\n \t\tif(val) SFS_AddString(parser, \",\");\n \t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (parser->codec->LastError) return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-25219",
        "func_name": "libproxy/recvline",
        "description": "url::recvline in url.cpp in libproxy 0.4.x through 0.4.15 allows a remote HTTP server to trigger uncontrolled recursion via a response composed of an infinite stream that lacks a newline character. This leads to stack exhaustion.",
        "git_url": "https://github.com/libproxy/libproxy/commit/a83dae404feac517695c23ff43ce1e116e2bfbe0",
        "commit_title": "Rewrite url::recvline to be nonrecursive",
        "commit_text": " This function processes network input. It's semi-trusted, because the PAC ought to be trusted. But we still shouldn't allow it to control how far we recurse. A malicious PAC can cause us to overflow the stack by sending a sufficiently-long line without any '\\n' character.  Also, this function failed to properly handle EINTR, so let's fix that too, for good measure.  Fixes #134",
        "func_before": "static inline string recvline(int fd) {\n\t// Read a character.\n\t// If we don't get a character, return empty string.\n\t// If we are at the end of the line, return empty string.\n\tchar c = '\\0';\n\t\n\tif (recv(fd, &c, 1, 0) != 1 || c == '\\n')\n\t\treturn \"\";\n\n\treturn string(1, c) + recvline(fd);\n}",
        "func": "static string recvline(int fd) {\n\tstring line;\n\tint ret;\n\n\t// Reserve arbitrary amount of space to avoid small memory reallocations.\n\tline.reserve(128);\n\n\tdo {\n\t\tchar c;\n\t\tret = recv(fd, &c, 1, 0);\n\t\tif (ret == 1) {\n\t\t\tif (c == '\\n')\n\t\t\t\treturn line;\n\t\t\tline += c;\n\t\t}\n\t} while (ret == 1 || (ret == -1 && errno == EINTR));\n\n\treturn line;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,19 @@\n-static inline string recvline(int fd) {\n-\t// Read a character.\n-\t// If we don't get a character, return empty string.\n-\t// If we are at the end of the line, return empty string.\n-\tchar c = '\\0';\n-\t\n-\tif (recv(fd, &c, 1, 0) != 1 || c == '\\n')\n-\t\treturn \"\";\n+static string recvline(int fd) {\n+\tstring line;\n+\tint ret;\n \n-\treturn string(1, c) + recvline(fd);\n+\t// Reserve arbitrary amount of space to avoid small memory reallocations.\n+\tline.reserve(128);\n+\n+\tdo {\n+\t\tchar c;\n+\t\tret = recv(fd, &c, 1, 0);\n+\t\tif (ret == 1) {\n+\t\t\tif (c == '\\n')\n+\t\t\t\treturn line;\n+\t\t\tline += c;\n+\t\t}\n+\t} while (ret == 1 || (ret == -1 && errno == EINTR));\n+\n+\treturn line;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static inline string recvline(int fd) {",
                "\t// Read a character.",
                "\t// If we don't get a character, return empty string.",
                "\t// If we are at the end of the line, return empty string.",
                "\tchar c = '\\0';",
                "\t",
                "\tif (recv(fd, &c, 1, 0) != 1 || c == '\\n')",
                "\t\treturn \"\";",
                "\treturn string(1, c) + recvline(fd);"
            ],
            "added_lines": [
                "static string recvline(int fd) {",
                "\tstring line;",
                "\tint ret;",
                "\t// Reserve arbitrary amount of space to avoid small memory reallocations.",
                "\tline.reserve(128);",
                "",
                "\tdo {",
                "\t\tchar c;",
                "\t\tret = recv(fd, &c, 1, 0);",
                "\t\tif (ret == 1) {",
                "\t\t\tif (c == '\\n')",
                "\t\t\t\treturn line;",
                "\t\t\tline += c;",
                "\t\t}",
                "\t} while (ret == 1 || (ret == -1 && errno == EINTR));",
                "",
                "\treturn line;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-9144",
        "func_name": "Exiv2/exiv2/printIFD",
        "description": "An issue was discovered in Exiv2 0.27. There is infinite recursion at BigTiffImage::printIFD in the file bigtiffimage.cpp. This can be triggered by a crafted file. It allows an attacker to cause Denial of Service (Segmentation fault) or possibly have unspecified other impact.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/134e062b664e52a0f1e5223ea8c5d2495de2f31e",
        "commit_title": "Fix issue 712.",
        "commit_text": "",
        "func_before": "void printIFD(std::ostream& out, PrintStructureOption option, uint64_t dir_offset, int depth)\n                {\n                    BasicIo& io = Image::io();\n\n                    depth++;\n                    bool bFirst  = true;\n\n                    // buffer\n                    bool bPrint = true;\n\n                    do\n                    {\n                        // Read top of directory\n                        io.seek(static_cast<int64>(dir_offset), BasicIo::beg);\n\n                        const uint64_t entries = readData(header_.format() == Header::StandardTiff? 2: 8);\n                        const bool tooBig = entries > 500;\n\n                        if ( bFirst && bPrint )\n                        {\n                            out << Internal::indent(depth) << \"STRUCTURE OF BIGTIFF FILE \" << io.path() << std::endl;\n                            if (tooBig)\n                                out << Internal::indent(depth) << \"entries = \" << entries << std::endl;\n                        }\n\n                        if (tooBig)\n                            break;\n\n                        // Read the dictionary\n                        for ( uint64_t i = 0; i < entries; i ++ )\n                        {\n                            if ( bFirst && bPrint )\n                                out << Internal::indent(depth)\n                                    << \" address |    tag                           |     \"\n                                    << \" type |    count |    offset | value\\n\";\n\n                            bFirst = false;\n\n                            const uint16_t tag   = (uint16_t) readData(2);\n                            const uint16_t type  = (uint16_t) readData(2);\n                            const uint64_t count = readData(dataSize_);\n                            const DataBuf  data  = io.read(dataSize_);        // Read data as raw value. what should be done about it will be decided depending on type\n\n                            std::string sp = \"\" ; // output spacer\n\n                            //prepare to print the value\n                            // TODO: figure out what's going on with kount\n                            const uint64_t kount  = isStringType(type)? (count > 32 ? 32 : count) // restrict long arrays\n                                                            : count > 5              ? 5\n                                                            : count\n                                                            ;\n                            const uint32_t pad    = isStringType(type) ? 1 : 0;\n                            const uint32_t size   = isStringType(type) ? 1\n                                                  : is2ByteType(type)  ? 2\n                                                  : is4ByteType(type)  ? 4\n                                                  : is8ByteType(type)  ? 8\n                                                  : 1;\n\n                            // #55 and #56 memory allocation crash test/data/POC8\n\n                            // size * count > std::numeric_limits<uint64_t>::max()\n                            // =>\n                            // size > std::numeric_limits<uint64_t>::max() / count\n                            // (don't perform that check when count == 0 => will cause a division by zero exception)\n                            if (count != 0) {\n                                if (size > std::numeric_limits<uint64_t>::max() / count) {\n                                    throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n                                }\n                            }\n                                                             // more than we can handle\n\n                            if (size * count > std::numeric_limits<uint64_t>::max() - pad)\n                                throw Error(kerInvalidMalloc);             // again more than 2^64\n\n                            const uint64_t allocate = size*count + pad;\n                            if ( allocate > io.size() ) {\n                                throw Error(kerInvalidMalloc);\n                            }\n\n                            DataBuf buf(static_cast<long>(allocate));\n\n                            const uint64_t offset = header_.format() == Header::StandardTiff?\n                                    byteSwap4(data, 0, doSwap_):\n                                    byteSwap8(data, 0, doSwap_);\n\n                            // big data? Use 'data' as pointer to real data\n                            const bool usePointer = (size_t) count*size > (size_t) dataSize_;\n\n                            if ( usePointer )                          // read into buffer\n                            {\n                                size_t   restore = io.tell();          // save\n                                io.seek(static_cast<int64>(offset), BasicIo::beg);         // position\n                                io.read(buf.pData_, (long) count * size);     // read\n                                io.seek(restore, BasicIo::beg);        // restore\n                            }\n                            else  // use 'data' as data :)\n                                std::memcpy(buf.pData_, data.pData_, (size_t) count * size);     // copy data\n\n                            if ( bPrint )\n                            {\n                                const uint64_t entrySize = header_.format() == Header::StandardTiff? 12: 20;\n                                const uint64_t address = dir_offset + 2 + i * entrySize;\n\n                                out << Internal::indent(depth)\n                                    << Internal::stringFormat(\"%8u | %#06x %-25s |%10s |%9u |\",\n                                        static_cast<size_t>(address), tag, tagName(tag).c_str(), typeName(type), count)\n                                    <<(usePointer ? Internal::stringFormat(\"%10u | \",(size_t)offset)\n                                                  : Internal::stringFormat(\"%10s | \",\"\"))\n                                    ;\n                                if ( isShortType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap2(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap4(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap8(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isRationalType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        uint32_t a = byteSwap4(buf, k*size+0, doSwap_);\n                                        uint32_t b = byteSwap4(buf, k*size+4, doSwap_);\n                                        out << sp << a << \"/\" << b;\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isStringType(type) )\n                                    out << sp << Internal::binaryToString(makeSlice(buf, 0, static_cast<size_t>(kount)));\n\n                                sp = kount == count ? \"\" : \" ...\";\n                                out << sp << std::endl;\n\n                                if ( option == kpsRecursive &&\n                                        (tag == 0x8769 /* ExifTag */ || tag == 0x014a/*SubIFDs*/ || type == tiffIfd || type == tiffIfd8) )\n                                {\n                                    for ( size_t k = 0 ; k < count ; k++ )\n                                    {\n                                        const size_t restore = io.tell();\n                                        const uint64_t ifdOffset = type == tiffIfd8?\n                                            byteSwap8(buf, k*size, doSwap_):\n                                            byteSwap4(buf, k*size, doSwap_);\n\n                                        printIFD(out, option, ifdOffset, depth);\n                                        io.seek(restore, BasicIo::beg);\n                                    }\n                                }\n                                else if ( option == kpsRecursive && tag == 0x83bb /* IPTCNAA */ )\n                                {\n                                    if (Safe::add(count, offset) > io.size()) {\n                                        throw Error(kerCorruptedMetadata);\n                                    }\n\n                                    const size_t restore = io.tell();\n                                    io.seek(static_cast<int64>(offset), BasicIo::beg);  // position\n                                    std::vector<byte> bytes(static_cast<size_t>(count)) ;  // allocate memory\n                                    // TODO: once we have C++11 use bytes.data()\n                                    const size_t read_bytes = io.read(&bytes[0], static_cast<long>(count));\n                                    io.seek(restore, BasicIo::beg);\n                                    // TODO: once we have C++11 use bytes.data()\n                                    IptcData::printStructure(out, makeSliceUntil(&bytes[0], read_bytes), depth);\n\n                                }\n                                else if ( option == kpsRecursive && tag == 0x927c /* MakerNote */ && count > 10)\n                                {\n                                    size_t   restore = io.tell();  // save\n\n                                    long jump= 10           ;\n                                    byte     bytes[20]          ;\n                                    const char* chars = (const char*) &bytes[0] ;\n                                    io.seek(static_cast<int64>(dir_offset), BasicIo::beg);  // position\n                                    io.read(bytes,jump    )     ;  // read\n                                    bytes[jump]=0               ;\n                                    if ( ::strcmp(\"Nikon\",chars) == 0 )\n                                    {\n                                      // tag is an embedded tiff\n                                      std::vector<byte> nikon_bytes(static_cast<size_t>(count - jump));\n\n                                      io.read(&nikon_bytes.at(0), (long)nikon_bytes.size());\n                                      MemIo memIo(&nikon_bytes.at(0), (long)count - jump); // create a file\n                                      std::cerr << \"Nikon makernote\" << std::endl;\n                                      // printTiffStructure(memIo,out,option,depth);\n                                      // TODO: fix it\n                                    }\n                                    else\n                                    {\n                                        // tag is an IFD\n                                        io.seek(0, BasicIo::beg);  // position\n                                        std::cerr << \"makernote\" << std::endl;\n                                        printIFD(out,option,offset,depth);\n                                    }\n\n                                    io.seek(restore,BasicIo::beg); // restore\n                                }\n                            }\n                        }\n\n                        const uint64_t nextDirOffset = readData(dataSize_);\n\n                        dir_offset = tooBig ? 0 : nextDirOffset;\n                        out.flush();\n                    } while (dir_offset != 0);\n\n                    if ( bPrint )\n                        out << Internal::indent(depth) << \"END \" << io.path() << std::endl;\n                }",
        "func": "void printIFD(std::ostream& out, PrintStructureOption option, uint64_t dir_offset, int depth)\n                {\n                    BasicIo& io = Image::io();\n\n                    // Fix for https://github.com/Exiv2/exiv2/issues/712\n                    // A malicious file can cause a very deep recursion, leading to\n                    // stack exhaustion.\n                    if (depth > 200) {\n                      out << Internal::indent(depth) << \"Maximum indentation depth exceeded.\" << std::endl;\n                      return;\n                    }\n\n                    depth++;\n                    bool bFirst  = true;\n\n                    // buffer\n                    bool bPrint = true;\n\n                    do\n                    {\n                        // Read top of directory\n                        io.seek(static_cast<int64>(dir_offset), BasicIo::beg);\n\n                        const uint64_t entries = readData(header_.format() == Header::StandardTiff? 2: 8);\n                        const bool tooBig = entries > 500;\n\n                        if ( bFirst && bPrint )\n                        {\n                            out << Internal::indent(depth) << \"STRUCTURE OF BIGTIFF FILE \" << io.path() << std::endl;\n                            if (tooBig)\n                                out << Internal::indent(depth) << \"entries = \" << entries << std::endl;\n                        }\n\n                        if (tooBig)\n                            break;\n\n                        // Read the dictionary\n                        for ( uint64_t i = 0; i < entries; i ++ )\n                        {\n                            if ( bFirst && bPrint )\n                                out << Internal::indent(depth)\n                                    << \" address |    tag                           |     \"\n                                    << \" type |    count |    offset | value\\n\";\n\n                            bFirst = false;\n\n                            const uint16_t tag   = (uint16_t) readData(2);\n                            const uint16_t type  = (uint16_t) readData(2);\n                            const uint64_t count = readData(dataSize_);\n                            const DataBuf  data  = io.read(dataSize_);        // Read data as raw value. what should be done about it will be decided depending on type\n\n                            std::string sp = \"\" ; // output spacer\n\n                            //prepare to print the value\n                            // TODO: figure out what's going on with kount\n                            const uint64_t kount  = isStringType(type)? (count > 32 ? 32 : count) // restrict long arrays\n                                                            : count > 5              ? 5\n                                                            : count\n                                                            ;\n                            const uint32_t pad    = isStringType(type) ? 1 : 0;\n                            const uint32_t size   = isStringType(type) ? 1\n                                                  : is2ByteType(type)  ? 2\n                                                  : is4ByteType(type)  ? 4\n                                                  : is8ByteType(type)  ? 8\n                                                  : 1;\n\n                            // #55 and #56 memory allocation crash test/data/POC8\n\n                            // size * count > std::numeric_limits<uint64_t>::max()\n                            // =>\n                            // size > std::numeric_limits<uint64_t>::max() / count\n                            // (don't perform that check when count == 0 => will cause a division by zero exception)\n                            if (count != 0) {\n                                if (size > std::numeric_limits<uint64_t>::max() / count) {\n                                    throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n                                }\n                            }\n                                                             // more than we can handle\n\n                            if (size * count > std::numeric_limits<uint64_t>::max() - pad)\n                                throw Error(kerInvalidMalloc);             // again more than 2^64\n\n                            const uint64_t allocate = size*count + pad;\n                            if ( allocate > io.size() ) {\n                                throw Error(kerInvalidMalloc);\n                            }\n\n                            DataBuf buf(static_cast<long>(allocate));\n\n                            const uint64_t offset = header_.format() == Header::StandardTiff?\n                                    byteSwap4(data, 0, doSwap_):\n                                    byteSwap8(data, 0, doSwap_);\n\n                            // big data? Use 'data' as pointer to real data\n                            const bool usePointer = (size_t) count*size > (size_t) dataSize_;\n\n                            if ( usePointer )                          // read into buffer\n                            {\n                                size_t   restore = io.tell();          // save\n                                io.seek(static_cast<int64>(offset), BasicIo::beg);         // position\n                                io.read(buf.pData_, (long) count * size);     // read\n                                io.seek(restore, BasicIo::beg);        // restore\n                            }\n                            else  // use 'data' as data :)\n                                std::memcpy(buf.pData_, data.pData_, (size_t) count * size);     // copy data\n\n                            if ( bPrint )\n                            {\n                                const uint64_t entrySize = header_.format() == Header::StandardTiff? 12: 20;\n                                const uint64_t address = dir_offset + 2 + i * entrySize;\n\n                                out << Internal::indent(depth)\n                                    << Internal::stringFormat(\"%8u | %#06x %-25s |%10s |%9u |\",\n                                        static_cast<size_t>(address), tag, tagName(tag).c_str(), typeName(type), count)\n                                    <<(usePointer ? Internal::stringFormat(\"%10u | \",(size_t)offset)\n                                                  : Internal::stringFormat(\"%10s | \",\"\"))\n                                    ;\n                                if ( isShortType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap2(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap4(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap8(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isRationalType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        uint32_t a = byteSwap4(buf, k*size+0, doSwap_);\n                                        uint32_t b = byteSwap4(buf, k*size+4, doSwap_);\n                                        out << sp << a << \"/\" << b;\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isStringType(type) )\n                                    out << sp << Internal::binaryToString(makeSlice(buf, 0, static_cast<size_t>(kount)));\n\n                                sp = kount == count ? \"\" : \" ...\";\n                                out << sp << std::endl;\n\n                                if ( option == kpsRecursive &&\n                                        (tag == 0x8769 /* ExifTag */ || tag == 0x014a/*SubIFDs*/ || type == tiffIfd || type == tiffIfd8) )\n                                {\n                                    for ( size_t k = 0 ; k < count ; k++ )\n                                    {\n                                        const size_t restore = io.tell();\n                                        const uint64_t ifdOffset = type == tiffIfd8?\n                                            byteSwap8(buf, k*size, doSwap_):\n                                            byteSwap4(buf, k*size, doSwap_);\n\n                                        printIFD(out, option, ifdOffset, depth);\n                                        io.seek(restore, BasicIo::beg);\n                                    }\n                                }\n                                else if ( option == kpsRecursive && tag == 0x83bb /* IPTCNAA */ )\n                                {\n                                    if (Safe::add(count, offset) > io.size()) {\n                                        throw Error(kerCorruptedMetadata);\n                                    }\n\n                                    const size_t restore = io.tell();\n                                    io.seek(static_cast<int64>(offset), BasicIo::beg);  // position\n                                    std::vector<byte> bytes(static_cast<size_t>(count)) ;  // allocate memory\n                                    // TODO: once we have C++11 use bytes.data()\n                                    const size_t read_bytes = io.read(&bytes[0], static_cast<long>(count));\n                                    io.seek(restore, BasicIo::beg);\n                                    // TODO: once we have C++11 use bytes.data()\n                                    IptcData::printStructure(out, makeSliceUntil(&bytes[0], read_bytes), depth);\n\n                                }\n                                else if ( option == kpsRecursive && tag == 0x927c /* MakerNote */ && count > 10)\n                                {\n                                    size_t   restore = io.tell();  // save\n\n                                    long jump= 10           ;\n                                    byte     bytes[20]          ;\n                                    const char* chars = (const char*) &bytes[0] ;\n                                    io.seek(static_cast<int64>(dir_offset), BasicIo::beg);  // position\n                                    io.read(bytes,jump    )     ;  // read\n                                    bytes[jump]=0               ;\n                                    if ( ::strcmp(\"Nikon\",chars) == 0 )\n                                    {\n                                      // tag is an embedded tiff\n                                      std::vector<byte> nikon_bytes(static_cast<size_t>(count - jump));\n\n                                      io.read(&nikon_bytes.at(0), (long)nikon_bytes.size());\n                                      MemIo memIo(&nikon_bytes.at(0), (long)count - jump); // create a file\n                                      std::cerr << \"Nikon makernote\" << std::endl;\n                                      // printTiffStructure(memIo,out,option,depth);\n                                      // TODO: fix it\n                                    }\n                                    else\n                                    {\n                                        // tag is an IFD\n                                        io.seek(0, BasicIo::beg);  // position\n                                        std::cerr << \"makernote\" << std::endl;\n                                        printIFD(out,option,offset,depth);\n                                    }\n\n                                    io.seek(restore,BasicIo::beg); // restore\n                                }\n                            }\n                        }\n\n                        const uint64_t nextDirOffset = readData(dataSize_);\n\n                        dir_offset = tooBig ? 0 : nextDirOffset;\n                        out.flush();\n                    } while (dir_offset != 0);\n\n                    if ( bPrint )\n                        out << Internal::indent(depth) << \"END \" << io.path() << std::endl;\n                }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,14 @@\n void printIFD(std::ostream& out, PrintStructureOption option, uint64_t dir_offset, int depth)\n                 {\n                     BasicIo& io = Image::io();\n+\n+                    // Fix for https://github.com/Exiv2/exiv2/issues/712\n+                    // A malicious file can cause a very deep recursion, leading to\n+                    // stack exhaustion.\n+                    if (depth > 200) {\n+                      out << Internal::indent(depth) << \"Maximum indentation depth exceeded.\" << std::endl;\n+                      return;\n+                    }\n \n                     depth++;\n                     bool bFirst  = true;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "                    // Fix for https://github.com/Exiv2/exiv2/issues/712",
                "                    // A malicious file can cause a very deep recursion, leading to",
                "                    // stack exhaustion.",
                "                    if (depth > 200) {",
                "                      out << Internal::indent(depth) << \"Maximum indentation depth exceeded.\" << std::endl;",
                "                      return;",
                "                    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-9144",
        "func_name": "Exiv2/exiv2/printIFD",
        "description": "An issue was discovered in Exiv2 0.27. There is infinite recursion at BigTiffImage::printIFD in the file bigtiffimage.cpp. This can be triggered by a crafted file. It allows an attacker to cause Denial of Service (Segmentation fault) or possibly have unspecified other impact.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/a6765cf18b9bf9d79486946ecec8ef0e2de1ab7b",
        "commit_title": "Add comment to explain choice of cut-off value.",
        "commit_text": "",
        "func_before": "void printIFD(std::ostream& out, PrintStructureOption option, uint64_t dir_offset, int depth)\n                {\n                    BasicIo& io = Image::io();\n\n                    // Fix for https://github.com/Exiv2/exiv2/issues/712\n                    // A malicious file can cause a very deep recursion, leading to\n                    // stack exhaustion.\n                    if (depth > 200) {\n                      out << Internal::indent(depth) << \"Maximum indentation depth exceeded.\" << std::endl;\n                      return;\n                    }\n\n                    depth++;\n                    bool bFirst  = true;\n\n                    // buffer\n                    bool bPrint = true;\n\n                    do\n                    {\n                        // Read top of directory\n                        io.seek(static_cast<int64>(dir_offset), BasicIo::beg);\n\n                        const uint64_t entries = readData(header_.format() == Header::StandardTiff? 2: 8);\n                        const bool tooBig = entries > 500;\n\n                        if ( bFirst && bPrint )\n                        {\n                            out << Internal::indent(depth) << \"STRUCTURE OF BIGTIFF FILE \" << io.path() << std::endl;\n                            if (tooBig)\n                                out << Internal::indent(depth) << \"entries = \" << entries << std::endl;\n                        }\n\n                        if (tooBig)\n                            break;\n\n                        // Read the dictionary\n                        for ( uint64_t i = 0; i < entries; i ++ )\n                        {\n                            if ( bFirst && bPrint )\n                                out << Internal::indent(depth)\n                                    << \" address |    tag                           |     \"\n                                    << \" type |    count |    offset | value\\n\";\n\n                            bFirst = false;\n\n                            const uint16_t tag   = (uint16_t) readData(2);\n                            const uint16_t type  = (uint16_t) readData(2);\n                            const uint64_t count = readData(dataSize_);\n                            const DataBuf  data  = io.read(dataSize_);        // Read data as raw value. what should be done about it will be decided depending on type\n\n                            std::string sp = \"\" ; // output spacer\n\n                            //prepare to print the value\n                            // TODO: figure out what's going on with kount\n                            const uint64_t kount  = isStringType(type)? (count > 32 ? 32 : count) // restrict long arrays\n                                                            : count > 5              ? 5\n                                                            : count\n                                                            ;\n                            const uint32_t pad    = isStringType(type) ? 1 : 0;\n                            const uint32_t size   = isStringType(type) ? 1\n                                                  : is2ByteType(type)  ? 2\n                                                  : is4ByteType(type)  ? 4\n                                                  : is8ByteType(type)  ? 8\n                                                  : 1;\n\n                            // #55 and #56 memory allocation crash test/data/POC8\n\n                            // size * count > std::numeric_limits<uint64_t>::max()\n                            // =>\n                            // size > std::numeric_limits<uint64_t>::max() / count\n                            // (don't perform that check when count == 0 => will cause a division by zero exception)\n                            if (count != 0) {\n                                if (size > std::numeric_limits<uint64_t>::max() / count) {\n                                    throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n                                }\n                            }\n                                                             // more than we can handle\n\n                            if (size * count > std::numeric_limits<uint64_t>::max() - pad)\n                                throw Error(kerInvalidMalloc);             // again more than 2^64\n\n                            const uint64_t allocate = size*count + pad;\n                            if ( allocate > io.size() ) {\n                                throw Error(kerInvalidMalloc);\n                            }\n\n                            DataBuf buf(static_cast<long>(allocate));\n\n                            const uint64_t offset = header_.format() == Header::StandardTiff?\n                                    byteSwap4(data, 0, doSwap_):\n                                    byteSwap8(data, 0, doSwap_);\n\n                            // big data? Use 'data' as pointer to real data\n                            const bool usePointer = (size_t) count*size > (size_t) dataSize_;\n\n                            if ( usePointer )                          // read into buffer\n                            {\n                                size_t   restore = io.tell();          // save\n                                io.seek(static_cast<int64>(offset), BasicIo::beg);         // position\n                                io.read(buf.pData_, (long) count * size);     // read\n                                io.seek(restore, BasicIo::beg);        // restore\n                            }\n                            else  // use 'data' as data :)\n                                std::memcpy(buf.pData_, data.pData_, (size_t) count * size);     // copy data\n\n                            if ( bPrint )\n                            {\n                                const uint64_t entrySize = header_.format() == Header::StandardTiff? 12: 20;\n                                const uint64_t address = dir_offset + 2 + i * entrySize;\n\n                                out << Internal::indent(depth)\n                                    << Internal::stringFormat(\"%8u | %#06x %-25s |%10s |%9u |\",\n                                        static_cast<size_t>(address), tag, tagName(tag).c_str(), typeName(type), count)\n                                    <<(usePointer ? Internal::stringFormat(\"%10u | \",(size_t)offset)\n                                                  : Internal::stringFormat(\"%10s | \",\"\"))\n                                    ;\n                                if ( isShortType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap2(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap4(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap8(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isRationalType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        uint32_t a = byteSwap4(buf, k*size+0, doSwap_);\n                                        uint32_t b = byteSwap4(buf, k*size+4, doSwap_);\n                                        out << sp << a << \"/\" << b;\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isStringType(type) )\n                                    out << sp << Internal::binaryToString(makeSlice(buf, 0, static_cast<size_t>(kount)));\n\n                                sp = kount == count ? \"\" : \" ...\";\n                                out << sp << std::endl;\n\n                                if ( option == kpsRecursive &&\n                                        (tag == 0x8769 /* ExifTag */ || tag == 0x014a/*SubIFDs*/ || type == tiffIfd || type == tiffIfd8) )\n                                {\n                                    for ( size_t k = 0 ; k < count ; k++ )\n                                    {\n                                        const size_t restore = io.tell();\n                                        const uint64_t ifdOffset = type == tiffIfd8?\n                                            byteSwap8(buf, k*size, doSwap_):\n                                            byteSwap4(buf, k*size, doSwap_);\n\n                                        printIFD(out, option, ifdOffset, depth);\n                                        io.seek(restore, BasicIo::beg);\n                                    }\n                                }\n                                else if ( option == kpsRecursive && tag == 0x83bb /* IPTCNAA */ )\n                                {\n                                    if (Safe::add(count, offset) > io.size()) {\n                                        throw Error(kerCorruptedMetadata);\n                                    }\n\n                                    const size_t restore = io.tell();\n                                    io.seek(static_cast<int64>(offset), BasicIo::beg);  // position\n                                    std::vector<byte> bytes(static_cast<size_t>(count)) ;  // allocate memory\n                                    // TODO: once we have C++11 use bytes.data()\n                                    const size_t read_bytes = io.read(&bytes[0], static_cast<long>(count));\n                                    io.seek(restore, BasicIo::beg);\n                                    // TODO: once we have C++11 use bytes.data()\n                                    IptcData::printStructure(out, makeSliceUntil(&bytes[0], read_bytes), depth);\n\n                                }\n                                else if ( option == kpsRecursive && tag == 0x927c /* MakerNote */ && count > 10)\n                                {\n                                    size_t   restore = io.tell();  // save\n\n                                    long jump= 10           ;\n                                    byte     bytes[20]          ;\n                                    const char* chars = (const char*) &bytes[0] ;\n                                    io.seek(static_cast<int64>(dir_offset), BasicIo::beg);  // position\n                                    io.read(bytes,jump    )     ;  // read\n                                    bytes[jump]=0               ;\n                                    if ( ::strcmp(\"Nikon\",chars) == 0 )\n                                    {\n                                      // tag is an embedded tiff\n                                      std::vector<byte> nikon_bytes(static_cast<size_t>(count - jump));\n\n                                      io.read(&nikon_bytes.at(0), (long)nikon_bytes.size());\n                                      MemIo memIo(&nikon_bytes.at(0), (long)count - jump); // create a file\n                                      std::cerr << \"Nikon makernote\" << std::endl;\n                                      // printTiffStructure(memIo,out,option,depth);\n                                      // TODO: fix it\n                                    }\n                                    else\n                                    {\n                                        // tag is an IFD\n                                        io.seek(0, BasicIo::beg);  // position\n                                        std::cerr << \"makernote\" << std::endl;\n                                        printIFD(out,option,offset,depth);\n                                    }\n\n                                    io.seek(restore,BasicIo::beg); // restore\n                                }\n                            }\n                        }\n\n                        const uint64_t nextDirOffset = readData(dataSize_);\n\n                        dir_offset = tooBig ? 0 : nextDirOffset;\n                        out.flush();\n                    } while (dir_offset != 0);\n\n                    if ( bPrint )\n                        out << Internal::indent(depth) << \"END \" << io.path() << std::endl;\n                }",
        "func": "void printIFD(std::ostream& out, PrintStructureOption option, uint64_t dir_offset, int depth)\n                {\n                    BasicIo& io = Image::io();\n\n                    // Fix for https://github.com/Exiv2/exiv2/issues/712\n                    // A malicious file can cause a very deep recursion, leading to\n                    // stack exhaustion.\n                    // Note: 200 is an arbitrarily chosen cut-off value. The value\n                    // of depth determines the amount of indentation inserted by the\n                    // pretty-printer. The output starts to become unreadable as\n                    // soon as the indentation exceeds 80 characters or so. That's\n                    // why 200 ought to be a reasonable cut-off.\n                    if (depth > 200) {\n                      out << Internal::indent(depth) << \"Maximum indentation depth exceeded.\" << std::endl;\n                      return;\n                    }\n\n                    depth++;\n                    bool bFirst  = true;\n\n                    // buffer\n                    bool bPrint = true;\n\n                    do\n                    {\n                        // Read top of directory\n                        io.seek(static_cast<int64>(dir_offset), BasicIo::beg);\n\n                        const uint64_t entries = readData(header_.format() == Header::StandardTiff? 2: 8);\n                        const bool tooBig = entries > 500;\n\n                        if ( bFirst && bPrint )\n                        {\n                            out << Internal::indent(depth) << \"STRUCTURE OF BIGTIFF FILE \" << io.path() << std::endl;\n                            if (tooBig)\n                                out << Internal::indent(depth) << \"entries = \" << entries << std::endl;\n                        }\n\n                        if (tooBig)\n                            break;\n\n                        // Read the dictionary\n                        for ( uint64_t i = 0; i < entries; i ++ )\n                        {\n                            if ( bFirst && bPrint )\n                                out << Internal::indent(depth)\n                                    << \" address |    tag                           |     \"\n                                    << \" type |    count |    offset | value\\n\";\n\n                            bFirst = false;\n\n                            const uint16_t tag   = (uint16_t) readData(2);\n                            const uint16_t type  = (uint16_t) readData(2);\n                            const uint64_t count = readData(dataSize_);\n                            const DataBuf  data  = io.read(dataSize_);        // Read data as raw value. what should be done about it will be decided depending on type\n\n                            std::string sp = \"\" ; // output spacer\n\n                            //prepare to print the value\n                            // TODO: figure out what's going on with kount\n                            const uint64_t kount  = isStringType(type)? (count > 32 ? 32 : count) // restrict long arrays\n                                                            : count > 5              ? 5\n                                                            : count\n                                                            ;\n                            const uint32_t pad    = isStringType(type) ? 1 : 0;\n                            const uint32_t size   = isStringType(type) ? 1\n                                                  : is2ByteType(type)  ? 2\n                                                  : is4ByteType(type)  ? 4\n                                                  : is8ByteType(type)  ? 8\n                                                  : 1;\n\n                            // #55 and #56 memory allocation crash test/data/POC8\n\n                            // size * count > std::numeric_limits<uint64_t>::max()\n                            // =>\n                            // size > std::numeric_limits<uint64_t>::max() / count\n                            // (don't perform that check when count == 0 => will cause a division by zero exception)\n                            if (count != 0) {\n                                if (size > std::numeric_limits<uint64_t>::max() / count) {\n                                    throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n                                }\n                            }\n                                                             // more than we can handle\n\n                            if (size * count > std::numeric_limits<uint64_t>::max() - pad)\n                                throw Error(kerInvalidMalloc);             // again more than 2^64\n\n                            const uint64_t allocate = size*count + pad;\n                            if ( allocate > io.size() ) {\n                                throw Error(kerInvalidMalloc);\n                            }\n\n                            DataBuf buf(static_cast<long>(allocate));\n\n                            const uint64_t offset = header_.format() == Header::StandardTiff?\n                                    byteSwap4(data, 0, doSwap_):\n                                    byteSwap8(data, 0, doSwap_);\n\n                            // big data? Use 'data' as pointer to real data\n                            const bool usePointer = (size_t) count*size > (size_t) dataSize_;\n\n                            if ( usePointer )                          // read into buffer\n                            {\n                                size_t   restore = io.tell();          // save\n                                io.seek(static_cast<int64>(offset), BasicIo::beg);         // position\n                                io.read(buf.pData_, (long) count * size);     // read\n                                io.seek(restore, BasicIo::beg);        // restore\n                            }\n                            else  // use 'data' as data :)\n                                std::memcpy(buf.pData_, data.pData_, (size_t) count * size);     // copy data\n\n                            if ( bPrint )\n                            {\n                                const uint64_t entrySize = header_.format() == Header::StandardTiff? 12: 20;\n                                const uint64_t address = dir_offset + 2 + i * entrySize;\n\n                                out << Internal::indent(depth)\n                                    << Internal::stringFormat(\"%8u | %#06x %-25s |%10s |%9u |\",\n                                        static_cast<size_t>(address), tag, tagName(tag).c_str(), typeName(type), count)\n                                    <<(usePointer ? Internal::stringFormat(\"%10u | \",(size_t)offset)\n                                                  : Internal::stringFormat(\"%10s | \",\"\"))\n                                    ;\n                                if ( isShortType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap2(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap4(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap8(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isRationalType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        uint32_t a = byteSwap4(buf, k*size+0, doSwap_);\n                                        uint32_t b = byteSwap4(buf, k*size+4, doSwap_);\n                                        out << sp << a << \"/\" << b;\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isStringType(type) )\n                                    out << sp << Internal::binaryToString(makeSlice(buf, 0, static_cast<size_t>(kount)));\n\n                                sp = kount == count ? \"\" : \" ...\";\n                                out << sp << std::endl;\n\n                                if ( option == kpsRecursive &&\n                                        (tag == 0x8769 /* ExifTag */ || tag == 0x014a/*SubIFDs*/ || type == tiffIfd || type == tiffIfd8) )\n                                {\n                                    for ( size_t k = 0 ; k < count ; k++ )\n                                    {\n                                        const size_t restore = io.tell();\n                                        const uint64_t ifdOffset = type == tiffIfd8?\n                                            byteSwap8(buf, k*size, doSwap_):\n                                            byteSwap4(buf, k*size, doSwap_);\n\n                                        printIFD(out, option, ifdOffset, depth);\n                                        io.seek(restore, BasicIo::beg);\n                                    }\n                                }\n                                else if ( option == kpsRecursive && tag == 0x83bb /* IPTCNAA */ )\n                                {\n                                    if (Safe::add(count, offset) > io.size()) {\n                                        throw Error(kerCorruptedMetadata);\n                                    }\n\n                                    const size_t restore = io.tell();\n                                    io.seek(static_cast<int64>(offset), BasicIo::beg);  // position\n                                    std::vector<byte> bytes(static_cast<size_t>(count)) ;  // allocate memory\n                                    // TODO: once we have C++11 use bytes.data()\n                                    const size_t read_bytes = io.read(&bytes[0], static_cast<long>(count));\n                                    io.seek(restore, BasicIo::beg);\n                                    // TODO: once we have C++11 use bytes.data()\n                                    IptcData::printStructure(out, makeSliceUntil(&bytes[0], read_bytes), depth);\n\n                                }\n                                else if ( option == kpsRecursive && tag == 0x927c /* MakerNote */ && count > 10)\n                                {\n                                    size_t   restore = io.tell();  // save\n\n                                    long jump= 10           ;\n                                    byte     bytes[20]          ;\n                                    const char* chars = (const char*) &bytes[0] ;\n                                    io.seek(static_cast<int64>(dir_offset), BasicIo::beg);  // position\n                                    io.read(bytes,jump    )     ;  // read\n                                    bytes[jump]=0               ;\n                                    if ( ::strcmp(\"Nikon\",chars) == 0 )\n                                    {\n                                      // tag is an embedded tiff\n                                      std::vector<byte> nikon_bytes(static_cast<size_t>(count - jump));\n\n                                      io.read(&nikon_bytes.at(0), (long)nikon_bytes.size());\n                                      MemIo memIo(&nikon_bytes.at(0), (long)count - jump); // create a file\n                                      std::cerr << \"Nikon makernote\" << std::endl;\n                                      // printTiffStructure(memIo,out,option,depth);\n                                      // TODO: fix it\n                                    }\n                                    else\n                                    {\n                                        // tag is an IFD\n                                        io.seek(0, BasicIo::beg);  // position\n                                        std::cerr << \"makernote\" << std::endl;\n                                        printIFD(out,option,offset,depth);\n                                    }\n\n                                    io.seek(restore,BasicIo::beg); // restore\n                                }\n                            }\n                        }\n\n                        const uint64_t nextDirOffset = readData(dataSize_);\n\n                        dir_offset = tooBig ? 0 : nextDirOffset;\n                        out.flush();\n                    } while (dir_offset != 0);\n\n                    if ( bPrint )\n                        out << Internal::indent(depth) << \"END \" << io.path() << std::endl;\n                }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,11 @@\n                     // Fix for https://github.com/Exiv2/exiv2/issues/712\n                     // A malicious file can cause a very deep recursion, leading to\n                     // stack exhaustion.\n+                    // Note: 200 is an arbitrarily chosen cut-off value. The value\n+                    // of depth determines the amount of indentation inserted by the\n+                    // pretty-printer. The output starts to become unreadable as\n+                    // soon as the indentation exceeds 80 characters or so. That's\n+                    // why 200 ought to be a reasonable cut-off.\n                     if (depth > 200) {\n                       out << Internal::indent(depth) << \"Maximum indentation depth exceeded.\" << std::endl;\n                       return;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "                    // Note: 200 is an arbitrarily chosen cut-off value. The value",
                "                    // of depth determines the amount of indentation inserted by the",
                "                    // pretty-printer. The output starts to become unreadable as",
                "                    // soon as the indentation exceeds 80 characters or so. That's",
                "                    // why 200 ought to be a reasonable cut-off."
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11024",
        "func_name": "saitoha/libsixel/pnm_get_line",
        "description": "The load_pnm function in frompnm.c in libsixel.a in libsixel 1.8.2 has infinite recursion.",
        "git_url": "https://github.com/saitoha/libsixel/commit/b418f351f348d8273282f3fec6425b6b4e1d91da",
        "commit_title": "Fix for infinite recursive loop problem in load_pnm() (#85),",
        "commit_text": "Thanks to @Loginsoft-Research",
        "func_before": "static unsigned char *\npnm_get_line(unsigned char *p, unsigned char *end, unsigned char *line)\n{\n    int n;\n\n    do {\n        for (n = 0 ; p < end && *p >= ' '; p++) {\n            if (n < 255) {\n                line[n++] = *p;\n            }\n        }\n\n        if (p < end && *p == '\\n') {\n            p++;\n        }\n\n        line[n] = '\\0';\n\n    } while (line[0] == '#');\n\n    return p;\n}",
        "func": "static unsigned char *\npnm_get_line(unsigned char *p, unsigned char *end, unsigned char *line)\n{\n    int n;\n\n    do {\n        /* read the line */\n        for (n = 0 ; p < end && *p >= ' '; p++) {\n            if (n < 255) {\n                line[n++] = *p;\n            }\n        }\n\n        /* skip invald characters */\n        if (p < end && *p < ' ') {\n            p++;\n        }\n\n        line[n] = '\\0';\n\n    } while (line[0] == '#');\n\n    return p;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,13 +4,15 @@\n     int n;\n \n     do {\n+        /* read the line */\n         for (n = 0 ; p < end && *p >= ' '; p++) {\n             if (n < 255) {\n                 line[n++] = *p;\n             }\n         }\n \n-        if (p < end && *p == '\\n') {\n+        /* skip invald characters */\n+        if (p < end && *p < ' ') {\n             p++;\n         }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        if (p < end && *p == '\\n') {"
            ],
            "added_lines": [
                "        /* read the line */",
                "        /* skip invald characters */",
                "        if (p < end && *p < ' ') {"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11026",
        "func_name": "poppler/FontInfoScanner::scanFonts",
        "description": "FontInfoScanner::scanFonts in FontInfo.cc in Poppler 0.75.0 has infinite recursion, leading to a call to the error function in Error.cc.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=8051f678b3b43326e5fdfd7c03f39de21059f426",
        "commit_title": "Fixes #752",
        "commit_text": "",
        "func_before": "void FontInfoScanner::scanFonts(XRef *xrefA, Dict *resDict, std::vector<FontInfo*> *fontsList) {\n  GfxFontDict *gfxFontDict;\n  GfxFont *font;\n\n  // scan the fonts in this resource dictionary\n  gfxFontDict = nullptr;\n  const Object &fontObj = resDict->lookupNF(\"Font\");\n  if (fontObj.isRef()) {\n    Object obj2 = fontObj.fetch(xrefA);\n    if (obj2.isDict()) {\n      Ref r = fontObj.getRef();\n      gfxFontDict = new GfxFontDict(xrefA, &r, obj2.getDict());\n    }\n  } else if (fontObj.isDict()) {\n    gfxFontDict = new GfxFontDict(xrefA, nullptr, fontObj.getDict());\n  }\n  if (gfxFontDict) {\n    for (int i = 0; i < gfxFontDict->getNumFonts(); ++i) {\n      if ((font = gfxFontDict->getFont(i))) {\n        Ref fontRef = *font->getID();\n\n        // add this font to the list if not already found\n        if (fonts.find(fontRef.num) == fonts.end()) {\n\t  fontsList->push_back(new FontInfo(font, xrefA));\n          fonts.insert(fontRef.num);\n        }\n      }\n    }\n    delete gfxFontDict;\n  }\n\n  // recursively scan any resource dictionaries in objects in this\n  // resource dictionary\n  const char *resTypes[] = { \"XObject\", \"Pattern\" };\n  for (unsigned int resType = 0; resType < sizeof(resTypes) / sizeof(resTypes[0]); ++resType) {\n    Object objDict = resDict->lookup(resTypes[resType]);\n    if (objDict.isDict()) {\n      for (int i = 0; i < objDict.dictGetLength(); ++i) {\n        const Object &dictObjI = objDict.dictGetValNF(i);\n        if (dictObjI.isRef()) {\n          // check for an already-seen object\n          const Ref r = dictObjI.getRef();\n          if (visitedObjects.find(r.num) != visitedObjects.end()) {\n            continue;\n          }\n\n          visitedObjects.insert(r.num);\n        }\n\n        Object obj2 = dictObjI.fetch(xrefA);\n        if (obj2.isStream()) {\n          Object resObj = obj2.streamGetDict()->lookup(\"Resources\");\n          if (resObj.isDict() && resObj.getDict() != resDict) {\n            scanFonts(xrefA, resObj.getDict(), fontsList);\n          }\n        }\n      }\n    }\n  }\n}",
        "func": "void FontInfoScanner::scanFonts(XRef *xrefA, Dict *resDict, std::vector<FontInfo*> *fontsList) {\n  GfxFontDict *gfxFontDict;\n  GfxFont *font;\n\n  // scan the fonts in this resource dictionary\n  gfxFontDict = nullptr;\n  const Object &fontObj = resDict->lookupNF(\"Font\");\n  if (fontObj.isRef()) {\n    Object obj2 = fontObj.fetch(xrefA);\n    if (obj2.isDict()) {\n      Ref r = fontObj.getRef();\n      gfxFontDict = new GfxFontDict(xrefA, &r, obj2.getDict());\n    }\n  } else if (fontObj.isDict()) {\n    gfxFontDict = new GfxFontDict(xrefA, nullptr, fontObj.getDict());\n  }\n  if (gfxFontDict) {\n    for (int i = 0; i < gfxFontDict->getNumFonts(); ++i) {\n      if ((font = gfxFontDict->getFont(i))) {\n        Ref fontRef = *font->getID();\n\n        // add this font to the list if not already found\n        if (fonts.find(fontRef.num) == fonts.end()) {\n\t  fontsList->push_back(new FontInfo(font, xrefA));\n          fonts.insert(fontRef.num);\n        }\n      }\n    }\n    delete gfxFontDict;\n  }\n\n  // recursively scan any resource dictionaries in objects in this\n  // resource dictionary\n  const char *resTypes[] = { \"XObject\", \"Pattern\" };\n  for (unsigned int resType = 0; resType < sizeof(resTypes) / sizeof(resTypes[0]); ++resType) {\n    Object objDict = resDict->lookup(resTypes[resType]);\n    if (objDict.isDict()) {\n      for (int i = 0; i < objDict.dictGetLength(); ++i) {\n        const Object &dictObjI = objDict.dictGetValNF(i);\n        if (dictObjI.isRef()) {\n          // check for an already-seen object\n          const Ref r = dictObjI.getRef();\n          if (visitedObjects.find(r.num) != visitedObjects.end()) {\n            continue;\n          }\n\n          visitedObjects.insert(r.num);\n        }\n\n        Object obj2 = dictObjI.fetch(xrefA);\n        if (obj2.isStream()) {\n          Ref resourcesRef;\n          const Object resObj = obj2.streamGetDict()->lookup(\"Resources\", &resourcesRef);\n\n          if (resourcesRef != Ref::INVALID()) {\n            if (visitedObjects.find(resourcesRef.num) != visitedObjects.end()) {\n              continue;\n            }\n\n            visitedObjects.insert(resourcesRef.num);\n          }\n\n          if (resObj.isDict() && resObj.getDict() != resDict) {\n            scanFonts(xrefA, resObj.getDict(), fontsList);\n          }\n        }\n      }\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -49,7 +49,17 @@\n \n         Object obj2 = dictObjI.fetch(xrefA);\n         if (obj2.isStream()) {\n-          Object resObj = obj2.streamGetDict()->lookup(\"Resources\");\n+          Ref resourcesRef;\n+          const Object resObj = obj2.streamGetDict()->lookup(\"Resources\", &resourcesRef);\n+\n+          if (resourcesRef != Ref::INVALID()) {\n+            if (visitedObjects.find(resourcesRef.num) != visitedObjects.end()) {\n+              continue;\n+            }\n+\n+            visitedObjects.insert(resourcesRef.num);\n+          }\n+\n           if (resObj.isDict() && resObj.getDict() != resDict) {\n             scanFonts(xrefA, resObj.getDict(), fontsList);\n           }",
        "diff_line_info": {
            "deleted_lines": [
                "          Object resObj = obj2.streamGetDict()->lookup(\"Resources\");"
            ],
            "added_lines": [
                "          Ref resourcesRef;",
                "          const Object resObj = obj2.streamGetDict()->lookup(\"Resources\", &resourcesRef);",
                "",
                "          if (resourcesRef != Ref::INVALID()) {",
                "            if (visitedObjects.find(resourcesRef.num) != visitedObjects.end()) {",
                "              continue;",
                "            }",
                "",
                "            visitedObjects.insert(resourcesRef.num);",
                "          }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11413",
        "func_name": "ccxvii/mujs/js_RegExp_prototype_exec",
        "description": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "git_url": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "commit_title": "Bug 700937: Limit recursion in regexp matcher.",
        "commit_text": " Also handle negative return code as an error in the JS bindings.",
        "func_before": "void js_RegExp_prototype_exec(js_State *J, js_Regexp *re, const char *text)\n{\n\tint i;\n\tint opts;\n\tResub m;\n\n\topts = 0;\n\tif (re->flags & JS_REGEXP_G) {\n\t\tif (re->last > strlen(text)) {\n\t\t\tre->last = 0;\n\t\t\tjs_pushnull(J);\n\t\t\treturn;\n\t\t}\n\t\tif (re->last > 0) {\n\t\t\ttext += re->last;\n\t\t\topts |= REG_NOTBOL;\n\t\t}\n\t}\n\n\tif (!js_regexec(re->prog, text, &m, opts)) {\n\t\tjs_newarray(J);\n\t\tjs_pushstring(J, text);\n\t\tjs_setproperty(J, -2, \"input\");\n\t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n\t\tjs_setproperty(J, -2, \"index\");\n\t\tfor (i = 0; i < m.nsub; ++i) {\n\t\t\tjs_pushlstring(J, m.sub[i].sp, m.sub[i].ep - m.sub[i].sp);\n\t\t\tjs_setindex(J, -2, i);\n\t\t}\n\t\tif (re->flags & JS_REGEXP_G)\n\t\t\tre->last = re->last + (m.sub[0].ep - text);\n\t\treturn;\n\t}\n\n\tif (re->flags & JS_REGEXP_G)\n\t\tre->last = 0;\n\n\tjs_pushnull(J);\n}",
        "func": "void js_RegExp_prototype_exec(js_State *J, js_Regexp *re, const char *text)\n{\n\tint result;\n\tint i;\n\tint opts;\n\tResub m;\n\n\topts = 0;\n\tif (re->flags & JS_REGEXP_G) {\n\t\tif (re->last > strlen(text)) {\n\t\t\tre->last = 0;\n\t\t\tjs_pushnull(J);\n\t\t\treturn;\n\t\t}\n\t\tif (re->last > 0) {\n\t\t\ttext += re->last;\n\t\t\topts |= REG_NOTBOL;\n\t\t}\n\t}\n\n\tresult = js_regexec(re->prog, text, &m, opts);\n\tif (result < 0)\n\t\tjs_error(J, \"regexec failed\");\n\tif (result == 0) {\n\t\tjs_newarray(J);\n\t\tjs_pushstring(J, text);\n\t\tjs_setproperty(J, -2, \"input\");\n\t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n\t\tjs_setproperty(J, -2, \"index\");\n\t\tfor (i = 0; i < m.nsub; ++i) {\n\t\t\tjs_pushlstring(J, m.sub[i].sp, m.sub[i].ep - m.sub[i].sp);\n\t\t\tjs_setindex(J, -2, i);\n\t\t}\n\t\tif (re->flags & JS_REGEXP_G)\n\t\t\tre->last = re->last + (m.sub[0].ep - text);\n\t\treturn;\n\t}\n\n\tif (re->flags & JS_REGEXP_G)\n\t\tre->last = 0;\n\n\tjs_pushnull(J);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n void js_RegExp_prototype_exec(js_State *J, js_Regexp *re, const char *text)\n {\n+\tint result;\n \tint i;\n \tint opts;\n \tResub m;\n@@ -17,7 +18,10 @@\n \t\t}\n \t}\n \n-\tif (!js_regexec(re->prog, text, &m, opts)) {\n+\tresult = js_regexec(re->prog, text, &m, opts);\n+\tif (result < 0)\n+\t\tjs_error(J, \"regexec failed\");\n+\tif (result == 0) {\n \t\tjs_newarray(J);\n \t\tjs_pushstring(J, text);\n \t\tjs_setproperty(J, -2, \"input\");",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!js_regexec(re->prog, text, &m, opts)) {"
            ],
            "added_lines": [
                "\tint result;",
                "\tresult = js_regexec(re->prog, text, &m, opts);",
                "\tif (result < 0)",
                "\t\tjs_error(J, \"regexec failed\");",
                "\tif (result == 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11413",
        "func_name": "ccxvii/mujs/Sp_match",
        "description": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "git_url": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "commit_title": "Bug 700937: Limit recursion in regexp matcher.",
        "commit_text": " Also handle negative return code as an error in the JS bindings.",
        "func_before": "static void Sp_match(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint len;\n\tconst char *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n\n\tre = js_toregexp(J, -1);\n\tif (!(re->flags & JS_REGEXP_G)) {\n\t\tjs_RegExp_prototype_exec(J, re, text);\n\t\treturn;\n\t}\n\n\tre->last = 0;\n\n\tjs_newarray(J);\n\n\tlen = 0;\n\ta = text;\n\te = text + strlen(text);\n\twhile (a <= e) {\n\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n\t\t\tbreak;\n\n\t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\tjs_pushlstring(J, b, c - b);\n\t\tjs_setindex(J, -2, len++);\n\n\t\ta = c;\n\t\tif (c - b == 0)\n\t\t\t++a;\n\t}\n\n\tif (len == 0) {\n\t\tjs_pop(J, 1);\n\t\tjs_pushnull(J);\n\t}\n}",
        "func": "static void Sp_match(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint len;\n\tconst char *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n\n\tre = js_toregexp(J, -1);\n\tif (!(re->flags & JS_REGEXP_G)) {\n\t\tjs_RegExp_prototype_exec(J, re, text);\n\t\treturn;\n\t}\n\n\tre->last = 0;\n\n\tjs_newarray(J);\n\n\tlen = 0;\n\ta = text;\n\te = text + strlen(text);\n\twhile (a <= e) {\n\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n\t\t\tbreak;\n\n\t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\tjs_pushlstring(J, b, c - b);\n\t\tjs_setindex(J, -2, len++);\n\n\t\ta = c;\n\t\tif (c - b == 0)\n\t\t\t++a;\n\t}\n\n\tif (len == 0) {\n\t\tjs_pop(J, 1);\n\t\tjs_pushnull(J);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,7 +29,7 @@\n \ta = text;\n \te = text + strlen(text);\n \twhile (a <= e) {\n-\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n+\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n \t\t\tbreak;\n \n \t\tb = m.sub[0].sp;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))"
            ],
            "added_lines": [
                "\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11413",
        "func_name": "ccxvii/mujs/Sp_replace_regexp",
        "description": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "git_url": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "commit_title": "Bug 700937: Limit recursion in regexp matcher.",
        "commit_text": " Also handle negative return code as an error in the JS bindings.",
        "func_before": "static void Sp_replace_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *source, *s, *r;\n\tjs_Buffer *sb = NULL;\n\tint n, x;\n\tResub m;\n\n\tsource = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\n\tif (js_regexec(re->prog, source, &m, 0)) {\n\t\tjs_copy(J, 0);\n\t\treturn;\n\t}\n\n\tre->last = 0;\n\nloop:\n\ts = m.sub[0].sp;\n\tn = m.sub[0].ep - m.sub[0].sp;\n\n\tif (js_iscallable(J, 2)) {\n\t\tjs_copy(J, 2);\n\t\tjs_pushundefined(J);\n\t\tfor (x = 0; m.sub[x].sp; ++x) /* arg 0..x: substring and subexps that matched */\n\t\t\tjs_pushlstring(J, m.sub[x].sp, m.sub[x].ep - m.sub[x].sp);\n\t\tjs_pushnumber(J, s - source); /* arg x+2: offset within search string */\n\t\tjs_copy(J, 0); /* arg x+3: search string */\n\t\tjs_call(J, 2 + x);\n\t\tr = js_tostring(J, -1);\n\t\tjs_putm(J, &sb, source, s);\n\t\tjs_puts(J, &sb, r);\n\t\tjs_pop(J, 1);\n\t} else {\n\t\tr = js_tostring(J, 2);\n\t\tjs_putm(J, &sb, source, s);\n\t\twhile (*r) {\n\t\t\tif (*r == '$') {\n\t\t\t\tswitch (*(++r)) {\n\t\t\t\tcase 0: --r; /* end of string; back up */\n\t\t\t\t/* fallthrough */\n\t\t\t\tcase '$': js_putc(J, &sb, '$'); break;\n\t\t\t\tcase '`': js_putm(J, &sb, source, s); break;\n\t\t\t\tcase '\\'': js_puts(J, &sb, s + n); break;\n\t\t\t\tcase '&':\n\t\t\t\t\tjs_putm(J, &sb, s, s + n);\n\t\t\t\t\tbreak;\n\t\t\t\tcase '0': case '1': case '2': case '3': case '4':\n\t\t\t\tcase '5': case '6': case '7': case '8': case '9':\n\t\t\t\t\tx = *r - '0';\n\t\t\t\t\tif (r[1] >= '0' && r[1] <= '9')\n\t\t\t\t\t\tx = x * 10 + *(++r) - '0';\n\t\t\t\t\tif (x > 0 && x < m.nsub) {\n\t\t\t\t\t\tjs_putm(J, &sb, m.sub[x].sp, m.sub[x].ep);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\t\tif (x > 10) {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x / 10);\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x % 10);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\tjs_putc(J, &sb, *r);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t++r;\n\t\t\t} else {\n\t\t\t\tjs_putc(J, &sb, *r++);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (re->flags & JS_REGEXP_G) {\n\t\tsource = m.sub[0].ep;\n\t\tif (n == 0) {\n\t\t\tif (*source)\n\t\t\t\tjs_putc(J, &sb, *source++);\n\t\t\telse\n\t\t\t\tgoto end;\n\t\t}\n\t\tif (!js_regexec(re->prog, source, &m, REG_NOTBOL))\n\t\t\tgoto loop;\n\t}\n\nend:\n\tjs_puts(J, &sb, s + n);\n\tjs_putc(J, &sb, 0);\n\n\tif (js_try(J)) {\n\t\tjs_free(J, sb);\n\t\tjs_throw(J);\n\t}\n\tjs_pushstring(J, sb ? sb->s : \"\");\n\tjs_endtry(J);\n\tjs_free(J, sb);\n}",
        "func": "static void Sp_replace_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *source, *s, *r;\n\tjs_Buffer *sb = NULL;\n\tint n, x;\n\tResub m;\n\n\tsource = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\n\tif (js_doregexec(J, re->prog, source, &m, 0)) {\n\t\tjs_copy(J, 0);\n\t\treturn;\n\t}\n\n\tre->last = 0;\n\nloop:\n\ts = m.sub[0].sp;\n\tn = m.sub[0].ep - m.sub[0].sp;\n\n\tif (js_iscallable(J, 2)) {\n\t\tjs_copy(J, 2);\n\t\tjs_pushundefined(J);\n\t\tfor (x = 0; m.sub[x].sp; ++x) /* arg 0..x: substring and subexps that matched */\n\t\t\tjs_pushlstring(J, m.sub[x].sp, m.sub[x].ep - m.sub[x].sp);\n\t\tjs_pushnumber(J, s - source); /* arg x+2: offset within search string */\n\t\tjs_copy(J, 0); /* arg x+3: search string */\n\t\tjs_call(J, 2 + x);\n\t\tr = js_tostring(J, -1);\n\t\tjs_putm(J, &sb, source, s);\n\t\tjs_puts(J, &sb, r);\n\t\tjs_pop(J, 1);\n\t} else {\n\t\tr = js_tostring(J, 2);\n\t\tjs_putm(J, &sb, source, s);\n\t\twhile (*r) {\n\t\t\tif (*r == '$') {\n\t\t\t\tswitch (*(++r)) {\n\t\t\t\tcase 0: --r; /* end of string; back up */\n\t\t\t\t/* fallthrough */\n\t\t\t\tcase '$': js_putc(J, &sb, '$'); break;\n\t\t\t\tcase '`': js_putm(J, &sb, source, s); break;\n\t\t\t\tcase '\\'': js_puts(J, &sb, s + n); break;\n\t\t\t\tcase '&':\n\t\t\t\t\tjs_putm(J, &sb, s, s + n);\n\t\t\t\t\tbreak;\n\t\t\t\tcase '0': case '1': case '2': case '3': case '4':\n\t\t\t\tcase '5': case '6': case '7': case '8': case '9':\n\t\t\t\t\tx = *r - '0';\n\t\t\t\t\tif (r[1] >= '0' && r[1] <= '9')\n\t\t\t\t\t\tx = x * 10 + *(++r) - '0';\n\t\t\t\t\tif (x > 0 && x < m.nsub) {\n\t\t\t\t\t\tjs_putm(J, &sb, m.sub[x].sp, m.sub[x].ep);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\t\tif (x > 10) {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x / 10);\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x % 10);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tjs_putc(J, &sb, '0' + x);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tjs_putc(J, &sb, '$');\n\t\t\t\t\tjs_putc(J, &sb, *r);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t++r;\n\t\t\t} else {\n\t\t\t\tjs_putc(J, &sb, *r++);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (re->flags & JS_REGEXP_G) {\n\t\tsource = m.sub[0].ep;\n\t\tif (n == 0) {\n\t\t\tif (*source)\n\t\t\t\tjs_putc(J, &sb, *source++);\n\t\t\telse\n\t\t\t\tgoto end;\n\t\t}\n\t\tif (!js_doregexec(J, re->prog, source, &m, REG_NOTBOL))\n\t\t\tgoto loop;\n\t}\n\nend:\n\tjs_puts(J, &sb, s + n);\n\tjs_putc(J, &sb, 0);\n\n\tif (js_try(J)) {\n\t\tjs_free(J, sb);\n\t\tjs_throw(J);\n\t}\n\tjs_pushstring(J, sb ? sb->s : \"\");\n\tjs_endtry(J);\n\tjs_free(J, sb);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \tsource = checkstring(J, 0);\n \tre = js_toregexp(J, 1);\n \n-\tif (js_regexec(re->prog, source, &m, 0)) {\n+\tif (js_doregexec(J, re->prog, source, &m, 0)) {\n \t\tjs_copy(J, 0);\n \t\treturn;\n \t}\n@@ -83,7 +83,7 @@\n \t\t\telse\n \t\t\t\tgoto end;\n \t\t}\n-\t\tif (!js_regexec(re->prog, source, &m, REG_NOTBOL))\n+\t\tif (!js_doregexec(J, re->prog, source, &m, REG_NOTBOL))\n \t\t\tgoto loop;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (js_regexec(re->prog, source, &m, 0)) {",
                "\t\tif (!js_regexec(re->prog, source, &m, REG_NOTBOL))"
            ],
            "added_lines": [
                "\tif (js_doregexec(J, re->prog, source, &m, 0)) {",
                "\t\tif (!js_doregexec(J, re->prog, source, &m, REG_NOTBOL))"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11413",
        "func_name": "ccxvii/mujs/Sp_split_regexp",
        "description": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "git_url": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "commit_title": "Bug 700937: Limit recursion in regexp matcher.",
        "commit_text": " Also handle negative return code as an error in the JS bindings.",
        "func_before": "static void Sp_split_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint limit, len, k;\n\tconst char *p, *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\tlimit = js_isdefined(J, 2) ? js_tointeger(J, 2) : 1 << 30;\n\n\tjs_newarray(J);\n\tlen = 0;\n\n\te = text + strlen(text);\n\n\t/* splitting the empty string */\n\tif (e == text) {\n\t\tif (js_regexec(re->prog, text, &m, 0)) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushliteral(J, \"\");\n\t\t\tjs_setindex(J, -2, 0);\n\t\t}\n\t\treturn;\n\t}\n\n\tp = a = text;\n\twhile (a < e) {\n\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n\t\t\tbreak; /* no match */\n\n\t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\t/* empty string at end of last match */\n\t\tif (b == p) {\n\t\t\t++a;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (len == limit) return;\n\t\tjs_pushlstring(J, p, b - p);\n\t\tjs_setindex(J, -2, len++);\n\n\t\tfor (k = 1; k < m.nsub; ++k) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushlstring(J, m.sub[k].sp, m.sub[k].ep - m.sub[k].sp);\n\t\t\tjs_setindex(J, -2, len++);\n\t\t}\n\n\t\ta = p = c;\n\t}\n\n\tif (len == limit) return;\n\tjs_pushstring(J, p);\n\tjs_setindex(J, -2, len);\n}",
        "func": "static void Sp_split_regexp(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tint limit, len, k;\n\tconst char *p, *a, *b, *c, *e;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\tre = js_toregexp(J, 1);\n\tlimit = js_isdefined(J, 2) ? js_tointeger(J, 2) : 1 << 30;\n\n\tjs_newarray(J);\n\tlen = 0;\n\n\te = text + strlen(text);\n\n\t/* splitting the empty string */\n\tif (e == text) {\n\t\tif (js_doregexec(J, re->prog, text, &m, 0)) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushliteral(J, \"\");\n\t\t\tjs_setindex(J, -2, 0);\n\t\t}\n\t\treturn;\n\t}\n\n\tp = a = text;\n\twhile (a < e) {\n\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n\t\t\tbreak; /* no match */\n\n\t\tb = m.sub[0].sp;\n\t\tc = m.sub[0].ep;\n\n\t\t/* empty string at end of last match */\n\t\tif (b == p) {\n\t\t\t++a;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (len == limit) return;\n\t\tjs_pushlstring(J, p, b - p);\n\t\tjs_setindex(J, -2, len++);\n\n\t\tfor (k = 1; k < m.nsub; ++k) {\n\t\t\tif (len == limit) return;\n\t\t\tjs_pushlstring(J, m.sub[k].sp, m.sub[k].ep - m.sub[k].sp);\n\t\t\tjs_setindex(J, -2, len++);\n\t\t}\n\n\t\ta = p = c;\n\t}\n\n\tif (len == limit) return;\n\tjs_pushstring(J, p);\n\tjs_setindex(J, -2, len);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,7 @@\n \n \t/* splitting the empty string */\n \tif (e == text) {\n-\t\tif (js_regexec(re->prog, text, &m, 0)) {\n+\t\tif (js_doregexec(J, re->prog, text, &m, 0)) {\n \t\t\tif (len == limit) return;\n \t\t\tjs_pushliteral(J, \"\");\n \t\t\tjs_setindex(J, -2, 0);\n@@ -27,7 +27,7 @@\n \n \tp = a = text;\n \twhile (a < e) {\n-\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n+\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))\n \t\t\tbreak; /* no match */\n \n \t\tb = m.sub[0].sp;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (js_regexec(re->prog, text, &m, 0)) {",
                "\t\tif (js_regexec(re->prog, a, &m, a > text ? REG_NOTBOL : 0))"
            ],
            "added_lines": [
                "\t\tif (js_doregexec(J, re->prog, text, &m, 0)) {",
                "\t\tif (js_doregexec(J, re->prog, a, &m, a > text ? REG_NOTBOL : 0))"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11413",
        "func_name": "ccxvii/mujs/Sp_search",
        "description": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "git_url": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "commit_title": "Bug 700937: Limit recursion in regexp matcher.",
        "commit_text": " Also handle negative return code as an error in the JS bindings.",
        "func_before": "static void Sp_search(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n\n\tre = js_toregexp(J, -1);\n\n\tif (!js_regexec(re->prog, text, &m, 0))\n\t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n\telse\n\t\tjs_pushnumber(J, -1);\n}",
        "func": "static void Sp_search(js_State *J)\n{\n\tjs_Regexp *re;\n\tconst char *text;\n\tResub m;\n\n\ttext = checkstring(J, 0);\n\n\tif (js_isregexp(J, 1))\n\t\tjs_copy(J, 1);\n\telse if (js_isundefined(J, 1))\n\t\tjs_newregexp(J, \"\", 0);\n\telse\n\t\tjs_newregexp(J, js_tostring(J, 1), 0);\n\n\tre = js_toregexp(J, -1);\n\n\tif (!js_doregexec(J, re->prog, text, &m, 0))\n\t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n\telse\n\t\tjs_pushnumber(J, -1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,7 @@\n \n \tre = js_toregexp(J, -1);\n \n-\tif (!js_regexec(re->prog, text, &m, 0))\n+\tif (!js_doregexec(J, re->prog, text, &m, 0))\n \t\tjs_pushnumber(J, js_utfptrtoidx(text, m.sub[0].sp));\n \telse\n \t\tjs_pushnumber(J, -1);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!js_regexec(re->prog, text, &m, 0))"
            ],
            "added_lines": [
                "\tif (!js_doregexec(J, re->prog, text, &m, 0))"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11413",
        "func_name": "ccxvii/mujs/regexec",
        "description": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "git_url": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "commit_title": "Bug 700937: Limit recursion in regexp matcher.",
        "commit_text": " Also handle negative return code as an error in the JS bindings.",
        "func_before": "int regexec(Reprog *prog, const char *sp, Resub *sub, int eflags)\n{\n\tResub scratch;\n\tint i;\n\n\tif (!sub)\n\t\tsub = &scratch;\n\n\tsub->nsub = prog->nsub;\n\tfor (i = 0; i < MAXSUB; ++i)\n\t\tsub->sub[i].sp = sub->sub[i].ep = NULL;\n\n\treturn !match(prog->start, sp, sp, prog->flags | eflags, sub);\n}",
        "func": "int regexec(Reprog *prog, const char *sp, Resub *sub, int eflags)\n{\n\tResub scratch;\n\tint i;\n\n\tif (!sub)\n\t\tsub = &scratch;\n\n\tsub->nsub = prog->nsub;\n\tfor (i = 0; i < MAXSUB; ++i)\n\t\tsub->sub[i].sp = sub->sub[i].ep = NULL;\n\n\treturn match(prog->start, sp, sp, prog->flags | eflags, sub, 0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,5 +10,5 @@\n \tfor (i = 0; i < MAXSUB; ++i)\n \t\tsub->sub[i].sp = sub->sub[i].ep = NULL;\n \n-\treturn !match(prog->start, sp, sp, prog->flags | eflags, sub);\n+\treturn match(prog->start, sp, sp, prog->flags | eflags, sub, 0);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn !match(prog->start, sp, sp, prog->flags | eflags, sub);"
            ],
            "added_lines": [
                "\treturn match(prog->start, sp, sp, prog->flags | eflags, sub, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11413",
        "func_name": "ccxvii/mujs/match",
        "description": "An issue was discovered in Artifex MuJS 1.0.5. It has unlimited recursion because the match function in regexp.c lacks a depth check.",
        "git_url": "https://github.com/ccxvii/mujs/commit/00d4606c3baf813b7b1c176823b2729bf51002a2",
        "commit_title": "Bug 700937: Limit recursion in regexp matcher.",
        "commit_text": " Also handle negative return code as an error in the JS bindings.",
        "func_before": "static int match(Reinst *pc, const char *sp, const char *bol, int flags, Resub *out)\n{\n\tResub scratch;\n\tint i;\n\tRune c;\n\n\tfor (;;) {\n\t\tswitch (pc->opcode) {\n\t\tcase I_END:\n\t\t\treturn 1;\n\t\tcase I_JUMP:\n\t\t\tpc = pc->x;\n\t\t\tbreak;\n\t\tcase I_SPLIT:\n\t\t\tscratch = *out;\n\t\t\tif (match(pc->x, sp, bol, flags, &scratch)) {\n\t\t\t\t*out = scratch;\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tpc = pc->y;\n\t\t\tbreak;\n\n\t\tcase I_PLA:\n\t\t\tif (!match(pc->x, sp, bol, flags, out))\n\t\t\t\treturn 0;\n\t\t\tpc = pc->y;\n\t\t\tbreak;\n\t\tcase I_NLA:\n\t\t\tscratch = *out;\n\t\t\tif (match(pc->x, sp, bol, flags, &scratch))\n\t\t\t\treturn 0;\n\t\t\tpc = pc->y;\n\t\t\tbreak;\n\n\t\tcase I_ANYNL:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 0;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_ANY:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 0;\n\t\t\tif (isnewline(c))\n\t\t\t\treturn 0;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_CHAR:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 0;\n\t\t\tif (flags & REG_ICASE)\n\t\t\t\tc = canon(c);\n\t\t\tif (c != pc->c)\n\t\t\t\treturn 0;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_CCLASS:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 0;\n\t\t\tif (flags & REG_ICASE) {\n\t\t\t\tif (!incclasscanon(pc->cc, canon(c)))\n\t\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\tif (!incclass(pc->cc, c))\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_NCCLASS:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 0;\n\t\t\tif (flags & REG_ICASE) {\n\t\t\t\tif (incclasscanon(pc->cc, canon(c)))\n\t\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\tif (incclass(pc->cc, c))\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_REF:\n\t\t\ti = out->sub[pc->n].ep - out->sub[pc->n].sp;\n\t\t\tif (flags & REG_ICASE) {\n\t\t\t\tif (strncmpcanon(sp, out->sub[pc->n].sp, i))\n\t\t\t\t\treturn 0;\n\t\t\t} else {\n\t\t\t\tif (strncmp(sp, out->sub[pc->n].sp, i))\n\t\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif (i > 0)\n\t\t\t\tsp += i;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\n\t\tcase I_BOL:\n\t\t\tif (sp == bol && !(flags & REG_NOTBOL)) {\n\t\t\t\tpc = pc + 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (flags & REG_NEWLINE) {\n\t\t\t\tif (sp > bol && isnewline(sp[-1])) {\n\t\t\t\t\tpc = pc + 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 0;\n\t\tcase I_EOL:\n\t\t\tif (*sp == 0) {\n\t\t\t\tpc = pc + 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (flags & REG_NEWLINE) {\n\t\t\t\tif (isnewline(*sp)) {\n\t\t\t\t\tpc = pc + 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 0;\n\t\tcase I_WORD:\n\t\t\ti = sp > bol && iswordchar(sp[-1]);\n\t\t\ti ^= iswordchar(sp[0]);\n\t\t\tif (!i)\n\t\t\t\treturn 0;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_NWORD:\n\t\t\ti = sp > bol && iswordchar(sp[-1]);\n\t\t\ti ^= iswordchar(sp[0]);\n\t\t\tif (i)\n\t\t\t\treturn 0;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\n\t\tcase I_LPAR:\n\t\t\tout->sub[pc->n].sp = sp;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_RPAR:\n\t\t\tout->sub[pc->n].ep = sp;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn 0;\n\t\t}\n\t}\n}",
        "func": "static int match(Reinst *pc, const char *sp, const char *bol, int flags, Resub *out, int depth)\n{\n\tResub scratch;\n\tint result;\n\tint i;\n\tRune c;\n\n\t/* stack overflow */\n\tif (depth > MAXREC)\n\t\treturn -1;\n\n\tfor (;;) {\n\t\tswitch (pc->opcode) {\n\t\tcase I_END:\n\t\t\treturn 0;\n\t\tcase I_JUMP:\n\t\t\tpc = pc->x;\n\t\t\tbreak;\n\t\tcase I_SPLIT:\n\t\t\tscratch = *out;\n\t\t\tresult = match(pc->x, sp, bol, flags, &scratch, depth+1);\n\t\t\tif (result == -1)\n\t\t\t\treturn -1;\n\t\t\tif (result == 0) {\n\t\t\t\t*out = scratch;\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tpc = pc->y;\n\t\t\tbreak;\n\n\t\tcase I_PLA:\n\t\t\tresult = match(pc->x, sp, bol, flags, out, depth+1);\n\t\t\tif (result == -1)\n\t\t\t\treturn -1;\n\t\t\tif (result == 1)\n\t\t\t\treturn 1;\n\t\t\tpc = pc->y;\n\t\t\tbreak;\n\t\tcase I_NLA:\n\t\t\tscratch = *out;\n\t\t\tresult = match(pc->x, sp, bol, flags, &scratch, depth+1);\n\t\t\tif (result == -1)\n\t\t\t\treturn -1;\n\t\t\tif (result == 0)\n\t\t\t\treturn 1;\n\t\t\tpc = pc->y;\n\t\t\tbreak;\n\n\t\tcase I_ANYNL:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 1;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_ANY:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 1;\n\t\t\tif (isnewline(c))\n\t\t\t\treturn 1;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_CHAR:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 1;\n\t\t\tif (flags & REG_ICASE)\n\t\t\t\tc = canon(c);\n\t\t\tif (c != pc->c)\n\t\t\t\treturn 1;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_CCLASS:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 1;\n\t\t\tif (flags & REG_ICASE) {\n\t\t\t\tif (!incclasscanon(pc->cc, canon(c)))\n\t\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\tif (!incclass(pc->cc, c))\n\t\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_NCCLASS:\n\t\t\tsp += chartorune(&c, sp);\n\t\t\tif (c == 0)\n\t\t\t\treturn 1;\n\t\t\tif (flags & REG_ICASE) {\n\t\t\t\tif (incclasscanon(pc->cc, canon(c)))\n\t\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\tif (incclass(pc->cc, c))\n\t\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_REF:\n\t\t\ti = out->sub[pc->n].ep - out->sub[pc->n].sp;\n\t\t\tif (flags & REG_ICASE) {\n\t\t\t\tif (strncmpcanon(sp, out->sub[pc->n].sp, i))\n\t\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\tif (strncmp(sp, out->sub[pc->n].sp, i))\n\t\t\t\t\treturn 1;\n\t\t\t}\n\t\t\tif (i > 0)\n\t\t\t\tsp += i;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\n\t\tcase I_BOL:\n\t\t\tif (sp == bol && !(flags & REG_NOTBOL)) {\n\t\t\t\tpc = pc + 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (flags & REG_NEWLINE) {\n\t\t\t\tif (sp > bol && isnewline(sp[-1])) {\n\t\t\t\t\tpc = pc + 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 1;\n\t\tcase I_EOL:\n\t\t\tif (*sp == 0) {\n\t\t\t\tpc = pc + 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (flags & REG_NEWLINE) {\n\t\t\t\tif (isnewline(*sp)) {\n\t\t\t\t\tpc = pc + 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 1;\n\t\tcase I_WORD:\n\t\t\ti = sp > bol && iswordchar(sp[-1]);\n\t\t\ti ^= iswordchar(sp[0]);\n\t\t\tif (!i)\n\t\t\t\treturn 1;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_NWORD:\n\t\t\ti = sp > bol && iswordchar(sp[-1]);\n\t\t\ti ^= iswordchar(sp[0]);\n\t\t\tif (i)\n\t\t\t\treturn 1;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\n\t\tcase I_LPAR:\n\t\t\tout->sub[pc->n].sp = sp;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tcase I_RPAR:\n\t\t\tout->sub[pc->n].ep = sp;\n\t\t\tpc = pc + 1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn 1;\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,84 +1,98 @@\n-static int match(Reinst *pc, const char *sp, const char *bol, int flags, Resub *out)\n+static int match(Reinst *pc, const char *sp, const char *bol, int flags, Resub *out, int depth)\n {\n \tResub scratch;\n+\tint result;\n \tint i;\n \tRune c;\n+\n+\t/* stack overflow */\n+\tif (depth > MAXREC)\n+\t\treturn -1;\n \n \tfor (;;) {\n \t\tswitch (pc->opcode) {\n \t\tcase I_END:\n-\t\t\treturn 1;\n+\t\t\treturn 0;\n \t\tcase I_JUMP:\n \t\t\tpc = pc->x;\n \t\t\tbreak;\n \t\tcase I_SPLIT:\n \t\t\tscratch = *out;\n-\t\t\tif (match(pc->x, sp, bol, flags, &scratch)) {\n+\t\t\tresult = match(pc->x, sp, bol, flags, &scratch, depth+1);\n+\t\t\tif (result == -1)\n+\t\t\t\treturn -1;\n+\t\t\tif (result == 0) {\n \t\t\t\t*out = scratch;\n-\t\t\t\treturn 1;\n+\t\t\t\treturn 0;\n \t\t\t}\n \t\t\tpc = pc->y;\n \t\t\tbreak;\n \n \t\tcase I_PLA:\n-\t\t\tif (!match(pc->x, sp, bol, flags, out))\n-\t\t\t\treturn 0;\n+\t\t\tresult = match(pc->x, sp, bol, flags, out, depth+1);\n+\t\t\tif (result == -1)\n+\t\t\t\treturn -1;\n+\t\t\tif (result == 1)\n+\t\t\t\treturn 1;\n \t\t\tpc = pc->y;\n \t\t\tbreak;\n \t\tcase I_NLA:\n \t\t\tscratch = *out;\n-\t\t\tif (match(pc->x, sp, bol, flags, &scratch))\n-\t\t\t\treturn 0;\n+\t\t\tresult = match(pc->x, sp, bol, flags, &scratch, depth+1);\n+\t\t\tif (result == -1)\n+\t\t\t\treturn -1;\n+\t\t\tif (result == 0)\n+\t\t\t\treturn 1;\n \t\t\tpc = pc->y;\n \t\t\tbreak;\n \n \t\tcase I_ANYNL:\n \t\t\tsp += chartorune(&c, sp);\n \t\t\tif (c == 0)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n \t\tcase I_ANY:\n \t\t\tsp += chartorune(&c, sp);\n \t\t\tif (c == 0)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tif (isnewline(c))\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n \t\tcase I_CHAR:\n \t\t\tsp += chartorune(&c, sp);\n \t\t\tif (c == 0)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tif (flags & REG_ICASE)\n \t\t\t\tc = canon(c);\n \t\t\tif (c != pc->c)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n \t\tcase I_CCLASS:\n \t\t\tsp += chartorune(&c, sp);\n \t\t\tif (c == 0)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tif (flags & REG_ICASE) {\n \t\t\t\tif (!incclasscanon(pc->cc, canon(c)))\n-\t\t\t\t\treturn 0;\n+\t\t\t\t\treturn 1;\n \t\t\t} else {\n \t\t\t\tif (!incclass(pc->cc, c))\n-\t\t\t\t\treturn 0;\n+\t\t\t\t\treturn 1;\n \t\t\t}\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n \t\tcase I_NCCLASS:\n \t\t\tsp += chartorune(&c, sp);\n \t\t\tif (c == 0)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tif (flags & REG_ICASE) {\n \t\t\t\tif (incclasscanon(pc->cc, canon(c)))\n-\t\t\t\t\treturn 0;\n+\t\t\t\t\treturn 1;\n \t\t\t} else {\n \t\t\t\tif (incclass(pc->cc, c))\n-\t\t\t\t\treturn 0;\n+\t\t\t\t\treturn 1;\n \t\t\t}\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n@@ -86,10 +100,10 @@\n \t\t\ti = out->sub[pc->n].ep - out->sub[pc->n].sp;\n \t\t\tif (flags & REG_ICASE) {\n \t\t\t\tif (strncmpcanon(sp, out->sub[pc->n].sp, i))\n-\t\t\t\t\treturn 0;\n+\t\t\t\t\treturn 1;\n \t\t\t} else {\n \t\t\t\tif (strncmp(sp, out->sub[pc->n].sp, i))\n-\t\t\t\t\treturn 0;\n+\t\t\t\t\treturn 1;\n \t\t\t}\n \t\t\tif (i > 0)\n \t\t\t\tsp += i;\n@@ -107,7 +121,7 @@\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n-\t\t\treturn 0;\n+\t\t\treturn 1;\n \t\tcase I_EOL:\n \t\t\tif (*sp == 0) {\n \t\t\t\tpc = pc + 1;\n@@ -119,19 +133,19 @@\n \t\t\t\t\tbreak;\n \t\t\t\t}\n \t\t\t}\n-\t\t\treturn 0;\n+\t\t\treturn 1;\n \t\tcase I_WORD:\n \t\t\ti = sp > bol && iswordchar(sp[-1]);\n \t\t\ti ^= iswordchar(sp[0]);\n \t\t\tif (!i)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n \t\tcase I_NWORD:\n \t\t\ti = sp > bol && iswordchar(sp[-1]);\n \t\t\ti ^= iswordchar(sp[0]);\n \t\t\tif (i)\n-\t\t\t\treturn 0;\n+\t\t\t\treturn 1;\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n \n@@ -144,7 +158,7 @@\n \t\t\tpc = pc + 1;\n \t\t\tbreak;\n \t\tdefault:\n-\t\t\treturn 0;\n+\t\t\treturn 1;\n \t\t}\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static int match(Reinst *pc, const char *sp, const char *bol, int flags, Resub *out)",
                "\t\t\treturn 1;",
                "\t\t\tif (match(pc->x, sp, bol, flags, &scratch)) {",
                "\t\t\t\treturn 1;",
                "\t\t\tif (!match(pc->x, sp, bol, flags, out))",
                "\t\t\t\treturn 0;",
                "\t\t\tif (match(pc->x, sp, bol, flags, &scratch))",
                "\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\t\treturn 0;",
                "\t\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\t\treturn 0;",
                "\t\t\t\t\treturn 0;",
                "\t\t\t\t\treturn 0;",
                "\t\t\t\t\treturn 0;",
                "\t\t\treturn 0;",
                "\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\t\treturn 0;",
                "\t\t\treturn 0;"
            ],
            "added_lines": [
                "static int match(Reinst *pc, const char *sp, const char *bol, int flags, Resub *out, int depth)",
                "\tint result;",
                "",
                "\t/* stack overflow */",
                "\tif (depth > MAXREC)",
                "\t\treturn -1;",
                "\t\t\treturn 0;",
                "\t\t\tresult = match(pc->x, sp, bol, flags, &scratch, depth+1);",
                "\t\t\tif (result == -1)",
                "\t\t\t\treturn -1;",
                "\t\t\tif (result == 0) {",
                "\t\t\t\treturn 0;",
                "\t\t\tresult = match(pc->x, sp, bol, flags, out, depth+1);",
                "\t\t\tif (result == -1)",
                "\t\t\t\treturn -1;",
                "\t\t\tif (result == 1)",
                "\t\t\t\treturn 1;",
                "\t\t\tresult = match(pc->x, sp, bol, flags, &scratch, depth+1);",
                "\t\t\tif (result == -1)",
                "\t\t\t\treturn -1;",
                "\t\t\tif (result == 0)",
                "\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\t\treturn 1;",
                "\t\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\t\treturn 1;",
                "\t\t\t\t\treturn 1;",
                "\t\t\t\t\treturn 1;",
                "\t\t\t\t\treturn 1;",
                "\t\t\treturn 1;",
                "\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\t\treturn 1;",
                "\t\t\treturn 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-20821",
        "func_name": "sass/libsass/Parser::parse_css_variable_value",
        "description": "The parsing component in LibSass through 3.5.5 allows attackers to cause a denial-of-service (uncontrolled recursion in Sass::Parser::parse_css_variable_value in parser.cpp).",
        "git_url": "https://github.com/sass/libsass/commit/c9987a4206ee444bc09a3be7a690a506dfc37636",
        "commit_title": "Make `parse_css_variable_value` non-recursive",
        "commit_text": " Fixes #2658 stack overflow",
        "func_before": "String_Schema_Obj Parser::parse_css_variable_value(bool top_level)\n  {\n    String_Schema_Obj schema = SASS_MEMORY_NEW(String_Schema, pstate);\n    String_Schema_Obj tok;\n    if (!(tok = parse_css_variable_value_token(top_level))) {\n      return {};\n    }\n\n    schema->concat(tok);\n    while ((tok = parse_css_variable_value_token(top_level))) {\n      schema->concat(tok);\n    }\n\n    return schema.detach();\n  }",
        "func": "String_Schema_Obj Parser::parse_css_variable_value()\n  {\n    String_Schema_Obj schema = SASS_MEMORY_NEW(String_Schema, pstate);\n    std::vector<char> brackets;\n    while (true) {\n      if (\n        (brackets.empty() && lex< css_variable_top_level_value >(false)) ||\n        (!brackets.empty() && lex< css_variable_value >(false))\n      ) {\n        Token str(lexed);\n        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, str));\n      } else if (Expression_Obj tok = lex_interpolation()) {\n        if (String_Schema* s = Cast<String_Schema>(tok)) {\n          if (s->empty()) break;\n          schema->concat(s);\n        } else {\n          schema->append(tok);\n        }\n      } else if (lex< quoted_string >()) {\n        Expression_Obj tok = parse_string();\n        if (tok.isNull()) break;\n        if (String_Schema* s = Cast<String_Schema>(tok)) {\n          if (s->empty()) break;\n          schema->concat(s);\n        } else {\n          schema->append(tok);\n        }\n      } else if (lex< alternatives< exactly<'('>, exactly<'['>, exactly<'{'> > >()) {\n        const char opening_bracket = *(position - 1);\n        brackets.push_back(opening_bracket);\n        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, std::string(1, opening_bracket)));\n      } else if (const char *match = peek< alternatives< exactly<')'>, exactly<']'>, exactly<'}'> > >()) {\n        if (brackets.empty()) break;\n        const char closing_bracket = *(match - 1);\n        if (brackets.back() != Util::opening_bracket_for(closing_bracket)) {\n          std::string message = \": expected \\\"\";\n          message += Util::closing_bracket_for(brackets.back());\n          message += \"\\\", was \";\n          css_error(\"Invalid CSS\", \" after \", message);\n        }\n        lex< alternatives< exactly<')'>, exactly<']'>, exactly<'}'> > >();\n        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, std::string(1, closing_bracket)));\n        brackets.pop_back();\n      } else {\n        break;\n      }\n    }\n\n    if (!brackets.empty()) {\n      std::string message = \": expected \\\"\";\n      message += Util::closing_bracket_for(brackets.back());\n      message += \"\\\", was \";\n      css_error(\"Invalid CSS\", \" after \", message);\n    }\n\n    if (schema->empty()) return {};\n    return schema.detach();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,15 +1,58 @@\n-String_Schema_Obj Parser::parse_css_variable_value(bool top_level)\n+String_Schema_Obj Parser::parse_css_variable_value()\n   {\n     String_Schema_Obj schema = SASS_MEMORY_NEW(String_Schema, pstate);\n-    String_Schema_Obj tok;\n-    if (!(tok = parse_css_variable_value_token(top_level))) {\n-      return {};\n+    std::vector<char> brackets;\n+    while (true) {\n+      if (\n+        (brackets.empty() && lex< css_variable_top_level_value >(false)) ||\n+        (!brackets.empty() && lex< css_variable_value >(false))\n+      ) {\n+        Token str(lexed);\n+        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, str));\n+      } else if (Expression_Obj tok = lex_interpolation()) {\n+        if (String_Schema* s = Cast<String_Schema>(tok)) {\n+          if (s->empty()) break;\n+          schema->concat(s);\n+        } else {\n+          schema->append(tok);\n+        }\n+      } else if (lex< quoted_string >()) {\n+        Expression_Obj tok = parse_string();\n+        if (tok.isNull()) break;\n+        if (String_Schema* s = Cast<String_Schema>(tok)) {\n+          if (s->empty()) break;\n+          schema->concat(s);\n+        } else {\n+          schema->append(tok);\n+        }\n+      } else if (lex< alternatives< exactly<'('>, exactly<'['>, exactly<'{'> > >()) {\n+        const char opening_bracket = *(position - 1);\n+        brackets.push_back(opening_bracket);\n+        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, std::string(1, opening_bracket)));\n+      } else if (const char *match = peek< alternatives< exactly<')'>, exactly<']'>, exactly<'}'> > >()) {\n+        if (brackets.empty()) break;\n+        const char closing_bracket = *(match - 1);\n+        if (brackets.back() != Util::opening_bracket_for(closing_bracket)) {\n+          std::string message = \": expected \\\"\";\n+          message += Util::closing_bracket_for(brackets.back());\n+          message += \"\\\", was \";\n+          css_error(\"Invalid CSS\", \" after \", message);\n+        }\n+        lex< alternatives< exactly<')'>, exactly<']'>, exactly<'}'> > >();\n+        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, std::string(1, closing_bracket)));\n+        brackets.pop_back();\n+      } else {\n+        break;\n+      }\n     }\n \n-    schema->concat(tok);\n-    while ((tok = parse_css_variable_value_token(top_level))) {\n-      schema->concat(tok);\n+    if (!brackets.empty()) {\n+      std::string message = \": expected \\\"\";\n+      message += Util::closing_bracket_for(brackets.back());\n+      message += \"\\\", was \";\n+      css_error(\"Invalid CSS\", \" after \", message);\n     }\n \n+    if (schema->empty()) return {};\n     return schema.detach();\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "String_Schema_Obj Parser::parse_css_variable_value(bool top_level)",
                "    String_Schema_Obj tok;",
                "    if (!(tok = parse_css_variable_value_token(top_level))) {",
                "      return {};",
                "    schema->concat(tok);",
                "    while ((tok = parse_css_variable_value_token(top_level))) {",
                "      schema->concat(tok);"
            ],
            "added_lines": [
                "String_Schema_Obj Parser::parse_css_variable_value()",
                "    std::vector<char> brackets;",
                "    while (true) {",
                "      if (",
                "        (brackets.empty() && lex< css_variable_top_level_value >(false)) ||",
                "        (!brackets.empty() && lex< css_variable_value >(false))",
                "      ) {",
                "        Token str(lexed);",
                "        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, str));",
                "      } else if (Expression_Obj tok = lex_interpolation()) {",
                "        if (String_Schema* s = Cast<String_Schema>(tok)) {",
                "          if (s->empty()) break;",
                "          schema->concat(s);",
                "        } else {",
                "          schema->append(tok);",
                "        }",
                "      } else if (lex< quoted_string >()) {",
                "        Expression_Obj tok = parse_string();",
                "        if (tok.isNull()) break;",
                "        if (String_Schema* s = Cast<String_Schema>(tok)) {",
                "          if (s->empty()) break;",
                "          schema->concat(s);",
                "        } else {",
                "          schema->append(tok);",
                "        }",
                "      } else if (lex< alternatives< exactly<'('>, exactly<'['>, exactly<'{'> > >()) {",
                "        const char opening_bracket = *(position - 1);",
                "        brackets.push_back(opening_bracket);",
                "        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, std::string(1, opening_bracket)));",
                "      } else if (const char *match = peek< alternatives< exactly<')'>, exactly<']'>, exactly<'}'> > >()) {",
                "        if (brackets.empty()) break;",
                "        const char closing_bracket = *(match - 1);",
                "        if (brackets.back() != Util::opening_bracket_for(closing_bracket)) {",
                "          std::string message = \": expected \\\"\";",
                "          message += Util::closing_bracket_for(brackets.back());",
                "          message += \"\\\", was \";",
                "          css_error(\"Invalid CSS\", \" after \", message);",
                "        }",
                "        lex< alternatives< exactly<')'>, exactly<']'>, exactly<'}'> > >();",
                "        schema->append(SASS_MEMORY_NEW(String_Constant, pstate, std::string(1, closing_bracket)));",
                "        brackets.pop_back();",
                "      } else {",
                "        break;",
                "      }",
                "    if (!brackets.empty()) {",
                "      std::string message = \": expected \\\"\";",
                "      message += Util::closing_bracket_for(brackets.back());",
                "      message += \"\\\", was \";",
                "      css_error(\"Invalid CSS\", \" after \", message);",
                "    if (schema->empty()) return {};"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/callexp",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *callexp(js_State *J)\n{\n\tjs_Ast *a = newexp(J);\nloop:\n\tif (jsP_accept(J, '.')) { a = EXP2(MEMBER, a, identifiername(J)); goto loop; }\n\tif (jsP_accept(J, '[')) { a = EXP2(INDEX, a, expression(J, 0)); jsP_expect(J, ']'); goto loop; }\n\tif (jsP_accept(J, '(')) { a = EXP2(CALL, a, arguments(J)); jsP_expect(J, ')'); goto loop; }\n\treturn a;\n}",
        "func": "static js_Ast *callexp(js_State *J)\n{\n\tjs_Ast *a = newexp(J);\n\tSAVEREC();\nloop:\n\tINCREC();\n\tif (jsP_accept(J, '.')) { a = EXP2(MEMBER, a, identifiername(J)); goto loop; }\n\tif (jsP_accept(J, '[')) { a = EXP2(INDEX, a, expression(J, 0)); jsP_expect(J, ']'); goto loop; }\n\tif (jsP_accept(J, '(')) { a = EXP2(CALL, a, arguments(J)); jsP_expect(J, ')'); goto loop; }\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,12 @@\n static js_Ast *callexp(js_State *J)\n {\n \tjs_Ast *a = newexp(J);\n+\tSAVEREC();\n loop:\n+\tINCREC();\n \tif (jsP_accept(J, '.')) { a = EXP2(MEMBER, a, identifiername(J)); goto loop; }\n \tif (jsP_accept(J, '[')) { a = EXP2(INDEX, a, expression(J, 0)); jsP_expect(J, ']'); goto loop; }\n \tif (jsP_accept(J, '(')) { a = EXP2(CALL, a, arguments(J)); jsP_expect(J, ')'); goto loop; }\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tSAVEREC();",
                "\tINCREC();",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/equality",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *equality(js_State *J, int notin)\n{\n\tjs_Ast *a = relational(J, notin);\nloop:\n\tif (jsP_accept(J, TK_EQ)) { a = EXP2(EQ, a, relational(J, notin)); goto loop; }\n\tif (jsP_accept(J, TK_NE)) { a = EXP2(NE, a, relational(J, notin)); goto loop; }\n\tif (jsP_accept(J, TK_STRICTEQ)) { a = EXP2(STRICTEQ, a, relational(J, notin)); goto loop; }\n\tif (jsP_accept(J, TK_STRICTNE)) { a = EXP2(STRICTNE, a, relational(J, notin)); goto loop; }\n\treturn a;\n}",
        "func": "static js_Ast *equality(js_State *J, int notin)\n{\n\tjs_Ast *a = relational(J, notin);\n\tSAVEREC();\nloop:\n\tINCREC();\n\tif (jsP_accept(J, TK_EQ)) { a = EXP2(EQ, a, relational(J, notin)); goto loop; }\n\tif (jsP_accept(J, TK_NE)) { a = EXP2(NE, a, relational(J, notin)); goto loop; }\n\tif (jsP_accept(J, TK_STRICTEQ)) { a = EXP2(STRICTEQ, a, relational(J, notin)); goto loop; }\n\tif (jsP_accept(J, TK_STRICTNE)) { a = EXP2(STRICTNE, a, relational(J, notin)); goto loop; }\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,13 @@\n static js_Ast *equality(js_State *J, int notin)\n {\n \tjs_Ast *a = relational(J, notin);\n+\tSAVEREC();\n loop:\n+\tINCREC();\n \tif (jsP_accept(J, TK_EQ)) { a = EXP2(EQ, a, relational(J, notin)); goto loop; }\n \tif (jsP_accept(J, TK_NE)) { a = EXP2(NE, a, relational(J, notin)); goto loop; }\n \tif (jsP_accept(J, TK_STRICTEQ)) { a = EXP2(STRICTEQ, a, relational(J, notin)); goto loop; }\n \tif (jsP_accept(J, TK_STRICTNE)) { a = EXP2(STRICTNE, a, relational(J, notin)); goto loop; }\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tSAVEREC();",
                "\tINCREC();",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/conditional",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *conditional(js_State *J, int notin)\n{\n\tjs_Ast *a, *b, *c;\n\ta = logor(J, notin);\n\tif (jsP_accept(J, '?')) {\n\t\tb = assignment(J, 0);\n\t\tjsP_expect(J, ':');\n\t\tc = assignment(J, notin);\n\t\treturn EXP3(COND, a, b, c);\n\t}\n\treturn a;\n}",
        "func": "static js_Ast *conditional(js_State *J, int notin)\n{\n\tjs_Ast *a = logor(J, notin);\n\tif (jsP_accept(J, '?')) {\n\t\tjs_Ast *b, *c;\n\t\tINCREC();\n\t\tb = assignment(J, 0);\n\t\tjsP_expect(J, ':');\n\t\tc = assignment(J, notin);\n\t\tDECREC();\n\t\treturn EXP3(COND, a, b, c);\n\t}\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,13 @@\n static js_Ast *conditional(js_State *J, int notin)\n {\n-\tjs_Ast *a, *b, *c;\n-\ta = logor(J, notin);\n+\tjs_Ast *a = logor(J, notin);\n \tif (jsP_accept(J, '?')) {\n+\t\tjs_Ast *b, *c;\n+\t\tINCREC();\n \t\tb = assignment(J, 0);\n \t\tjsP_expect(J, ':');\n \t\tc = assignment(J, notin);\n+\t\tDECREC();\n \t\treturn EXP3(COND, a, b, c);\n \t}\n \treturn a;",
        "diff_line_info": {
            "deleted_lines": [
                "\tjs_Ast *a, *b, *c;",
                "\ta = logor(J, notin);"
            ],
            "added_lines": [
                "\tjs_Ast *a = logor(J, notin);",
                "\t\tjs_Ast *b, *c;",
                "\t\tINCREC();",
                "\t\tDECREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/multiplicative",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *multiplicative(js_State *J)\n{\n\tjs_Ast *a = unary(J);\nloop:\n\tif (jsP_accept(J, '*')) { a = EXP2(MUL, a, unary(J)); goto loop; }\n\tif (jsP_accept(J, '/')) { a = EXP2(DIV, a, unary(J)); goto loop; }\n\tif (jsP_accept(J, '%')) { a = EXP2(MOD, a, unary(J)); goto loop; }\n\treturn a;\n}",
        "func": "static js_Ast *multiplicative(js_State *J)\n{\n\tjs_Ast *a = unary(J);\n\tSAVEREC();\nloop:\n\tINCREC();\n\tif (jsP_accept(J, '*')) { a = EXP2(MUL, a, unary(J)); goto loop; }\n\tif (jsP_accept(J, '/')) { a = EXP2(DIV, a, unary(J)); goto loop; }\n\tif (jsP_accept(J, '%')) { a = EXP2(MOD, a, unary(J)); goto loop; }\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,12 @@\n static js_Ast *multiplicative(js_State *J)\n {\n \tjs_Ast *a = unary(J);\n+\tSAVEREC();\n loop:\n+\tINCREC();\n \tif (jsP_accept(J, '*')) { a = EXP2(MUL, a, unary(J)); goto loop; }\n \tif (jsP_accept(J, '/')) { a = EXP2(DIV, a, unary(J)); goto loop; }\n \tif (jsP_accept(J, '%')) { a = EXP2(MOD, a, unary(J)); goto loop; }\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tSAVEREC();",
                "\tINCREC();",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/relational",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *relational(js_State *J, int notin)\n{\n\tjs_Ast *a = shift(J);\nloop:\n\tif (jsP_accept(J, '<')) { a = EXP2(LT, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, '>')) { a = EXP2(GT, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, TK_LE)) { a = EXP2(LE, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, TK_GE)) { a = EXP2(GE, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, TK_INSTANCEOF)) { a = EXP2(INSTANCEOF, a, shift(J)); goto loop; }\n\tif (!notin && jsP_accept(J, TK_IN)) { a = EXP2(IN, a, shift(J)); goto loop; }\n\treturn a;\n}",
        "func": "static js_Ast *relational(js_State *J, int notin)\n{\n\tjs_Ast *a = shift(J);\n\tSAVEREC();\nloop:\n\tINCREC();\n\tif (jsP_accept(J, '<')) { a = EXP2(LT, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, '>')) { a = EXP2(GT, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, TK_LE)) { a = EXP2(LE, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, TK_GE)) { a = EXP2(GE, a, shift(J)); goto loop; }\n\tif (jsP_accept(J, TK_INSTANCEOF)) { a = EXP2(INSTANCEOF, a, shift(J)); goto loop; }\n\tif (!notin && jsP_accept(J, TK_IN)) { a = EXP2(IN, a, shift(J)); goto loop; }\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,12 +1,15 @@\n static js_Ast *relational(js_State *J, int notin)\n {\n \tjs_Ast *a = shift(J);\n+\tSAVEREC();\n loop:\n+\tINCREC();\n \tif (jsP_accept(J, '<')) { a = EXP2(LT, a, shift(J)); goto loop; }\n \tif (jsP_accept(J, '>')) { a = EXP2(GT, a, shift(J)); goto loop; }\n \tif (jsP_accept(J, TK_LE)) { a = EXP2(LE, a, shift(J)); goto loop; }\n \tif (jsP_accept(J, TK_GE)) { a = EXP2(GE, a, shift(J)); goto loop; }\n \tif (jsP_accept(J, TK_INSTANCEOF)) { a = EXP2(INSTANCEOF, a, shift(J)); goto loop; }\n \tif (!notin && jsP_accept(J, TK_IN)) { a = EXP2(IN, a, shift(J)); goto loop; }\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tSAVEREC();",
                "\tINCREC();",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/bitxor",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *bitxor(js_State *J, int notin)\n{\n\tjs_Ast *a = bitand(J, notin);\n\twhile (jsP_accept(J, '^'))\n\t\ta = EXP2(BITXOR, a, bitand(J, notin));\n\treturn a;\n}",
        "func": "static js_Ast *bitxor(js_State *J, int notin)\n{\n\tjs_Ast *a = bitand(J, notin);\n\tSAVEREC();\n\twhile (jsP_accept(J, '^')) {\n\t\tINCREC();\n\t\ta = EXP2(BITXOR, a, bitand(J, notin));\n\t}\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,11 @@\n static js_Ast *bitxor(js_State *J, int notin)\n {\n \tjs_Ast *a = bitand(J, notin);\n-\twhile (jsP_accept(J, '^'))\n+\tSAVEREC();\n+\twhile (jsP_accept(J, '^')) {\n+\t\tINCREC();\n \t\ta = EXP2(BITXOR, a, bitand(J, notin));\n+\t}\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\twhile (jsP_accept(J, '^'))"
            ],
            "added_lines": [
                "\tSAVEREC();",
                "\twhile (jsP_accept(J, '^')) {",
                "\t\tINCREC();",
                "\t}",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/assignment",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *assignment(js_State *J, int notin)\n{\n\tjs_Ast *a;\n\tINCREC();\n\ta = conditional(J, notin);\n\tif (jsP_accept(J, '=')) a = EXP2(ASS, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_MUL_ASS)) a = EXP2(ASS_MUL, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_DIV_ASS)) a = EXP2(ASS_DIV, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_MOD_ASS)) a = EXP2(ASS_MOD, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_ADD_ASS)) a = EXP2(ASS_ADD, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_SUB_ASS)) a = EXP2(ASS_SUB, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_SHL_ASS)) a = EXP2(ASS_SHL, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_SHR_ASS)) a = EXP2(ASS_SHR, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_USHR_ASS)) a = EXP2(ASS_USHR, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_AND_ASS)) a = EXP2(ASS_BITAND, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_XOR_ASS)) a = EXP2(ASS_BITXOR, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_OR_ASS)) a = EXP2(ASS_BITOR, a, assignment(J, notin));\n\tDECREC();\n\treturn a;\n}",
        "func": "static js_Ast *assignment(js_State *J, int notin)\n{\n\tjs_Ast *a = conditional(J, notin);\n\tINCREC();\n\tif (jsP_accept(J, '=')) a = EXP2(ASS, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_MUL_ASS)) a = EXP2(ASS_MUL, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_DIV_ASS)) a = EXP2(ASS_DIV, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_MOD_ASS)) a = EXP2(ASS_MOD, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_ADD_ASS)) a = EXP2(ASS_ADD, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_SUB_ASS)) a = EXP2(ASS_SUB, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_SHL_ASS)) a = EXP2(ASS_SHL, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_SHR_ASS)) a = EXP2(ASS_SHR, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_USHR_ASS)) a = EXP2(ASS_USHR, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_AND_ASS)) a = EXP2(ASS_BITAND, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_XOR_ASS)) a = EXP2(ASS_BITXOR, a, assignment(J, notin));\n\telse if (jsP_accept(J, TK_OR_ASS)) a = EXP2(ASS_BITOR, a, assignment(J, notin));\n\tDECREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,7 @@\n static js_Ast *assignment(js_State *J, int notin)\n {\n-\tjs_Ast *a;\n+\tjs_Ast *a = conditional(J, notin);\n \tINCREC();\n-\ta = conditional(J, notin);\n \tif (jsP_accept(J, '=')) a = EXP2(ASS, a, assignment(J, notin));\n \telse if (jsP_accept(J, TK_MUL_ASS)) a = EXP2(ASS_MUL, a, assignment(J, notin));\n \telse if (jsP_accept(J, TK_DIV_ASS)) a = EXP2(ASS_DIV, a, assignment(J, notin));",
        "diff_line_info": {
            "deleted_lines": [
                "\tjs_Ast *a;",
                "\ta = conditional(J, notin);"
            ],
            "added_lines": [
                "\tjs_Ast *a = conditional(J, notin);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/logand",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *logand(js_State *J, int notin)\n{\n\tjs_Ast *a = bitor(J, notin);\n\tif (jsP_accept(J, TK_AND))\n\t\ta = EXP2(LOGAND, a, logand(J, notin));\n\treturn a;\n}",
        "func": "static js_Ast *logand(js_State *J, int notin)\n{\n\tjs_Ast *a = bitor(J, notin);\n\tif (jsP_accept(J, TK_AND)) {\n\t\tINCREC();\n\t\ta = EXP2(LOGAND, a, logand(J, notin));\n\t\tDECREC();\n\t}\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,10 @@\n static js_Ast *logand(js_State *J, int notin)\n {\n \tjs_Ast *a = bitor(J, notin);\n-\tif (jsP_accept(J, TK_AND))\n+\tif (jsP_accept(J, TK_AND)) {\n+\t\tINCREC();\n \t\ta = EXP2(LOGAND, a, logand(J, notin));\n+\t\tDECREC();\n+\t}\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (jsP_accept(J, TK_AND))"
            ],
            "added_lines": [
                "\tif (jsP_accept(J, TK_AND)) {",
                "\t\tINCREC();",
                "\t\tDECREC();",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/expression",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *expression(js_State *J, int notin)\n{\n\tjs_Ast *a;\n\tINCREC();\n\ta = assignment(J, notin);\n\twhile (jsP_accept(J, ','))\n\t\ta = EXP2(COMMA, a, assignment(J, notin));\n\tDECREC();\n\treturn a;\n}",
        "func": "static js_Ast *expression(js_State *J, int notin)\n{\n\tjs_Ast *a = assignment(J, notin);\n\tSAVEREC();\n\twhile (jsP_accept(J, ',')) {\n\t\tINCREC();\n\t\ta = EXP2(COMMA, a, assignment(J, notin));\n\t}\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,11 @@\n static js_Ast *expression(js_State *J, int notin)\n {\n-\tjs_Ast *a;\n-\tINCREC();\n-\ta = assignment(J, notin);\n-\twhile (jsP_accept(J, ','))\n+\tjs_Ast *a = assignment(J, notin);\n+\tSAVEREC();\n+\twhile (jsP_accept(J, ',')) {\n+\t\tINCREC();\n \t\ta = EXP2(COMMA, a, assignment(J, notin));\n-\tDECREC();\n+\t}\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tjs_Ast *a;",
                "\tINCREC();",
                "\ta = assignment(J, notin);",
                "\twhile (jsP_accept(J, ','))",
                "\tDECREC();"
            ],
            "added_lines": [
                "\tjs_Ast *a = assignment(J, notin);",
                "\tSAVEREC();",
                "\twhile (jsP_accept(J, ',')) {",
                "\t\tINCREC();",
                "\t}",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/shift",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *shift(js_State *J)\n{\n\tjs_Ast *a = additive(J);\nloop:\n\tif (jsP_accept(J, TK_SHL)) { a = EXP2(SHL, a, additive(J)); goto loop; }\n\tif (jsP_accept(J, TK_SHR)) { a = EXP2(SHR, a, additive(J)); goto loop; }\n\tif (jsP_accept(J, TK_USHR)) { a = EXP2(USHR, a, additive(J)); goto loop; }\n\treturn a;\n}",
        "func": "static js_Ast *shift(js_State *J)\n{\n\tjs_Ast *a = additive(J);\n\tSAVEREC();\nloop:\n\tINCREC();\n\tif (jsP_accept(J, TK_SHL)) { a = EXP2(SHL, a, additive(J)); goto loop; }\n\tif (jsP_accept(J, TK_SHR)) { a = EXP2(SHR, a, additive(J)); goto loop; }\n\tif (jsP_accept(J, TK_USHR)) { a = EXP2(USHR, a, additive(J)); goto loop; }\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,12 @@\n static js_Ast *shift(js_State *J)\n {\n \tjs_Ast *a = additive(J);\n+\tSAVEREC();\n loop:\n+\tINCREC();\n \tif (jsP_accept(J, TK_SHL)) { a = EXP2(SHL, a, additive(J)); goto loop; }\n \tif (jsP_accept(J, TK_SHR)) { a = EXP2(SHR, a, additive(J)); goto loop; }\n \tif (jsP_accept(J, TK_USHR)) { a = EXP2(USHR, a, additive(J)); goto loop; }\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tSAVEREC();",
                "\tINCREC();",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/additive",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *additive(js_State *J)\n{\n\tjs_Ast *a = multiplicative(J);\nloop:\n\tif (jsP_accept(J, '+')) { a = EXP2(ADD, a, multiplicative(J)); goto loop; }\n\tif (jsP_accept(J, '-')) { a = EXP2(SUB, a, multiplicative(J)); goto loop; }\n\treturn a;\n}",
        "func": "static js_Ast *additive(js_State *J)\n{\n\tjs_Ast *a = multiplicative(J);\n\tSAVEREC();\nloop:\n\tINCREC();\n\tif (jsP_accept(J, '+')) { a = EXP2(ADD, a, multiplicative(J)); goto loop; }\n\tif (jsP_accept(J, '-')) { a = EXP2(SUB, a, multiplicative(J)); goto loop; }\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,11 @@\n static js_Ast *additive(js_State *J)\n {\n \tjs_Ast *a = multiplicative(J);\n+\tSAVEREC();\n loop:\n+\tINCREC();\n \tif (jsP_accept(J, '+')) { a = EXP2(ADD, a, multiplicative(J)); goto loop; }\n \tif (jsP_accept(J, '-')) { a = EXP2(SUB, a, multiplicative(J)); goto loop; }\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tSAVEREC();",
                "\tINCREC();",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/logor",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *logor(js_State *J, int notin)\n{\n\tjs_Ast *a = logand(J, notin);\n\tif (jsP_accept(J, TK_OR))\n\t\ta = EXP2(LOGOR, a, logor(J, notin));\n\treturn a;\n}",
        "func": "static js_Ast *logor(js_State *J, int notin)\n{\n\tjs_Ast *a = logand(J, notin);\n\tif (jsP_accept(J, TK_OR)) {\n\t\tINCREC();\n\t\ta = EXP2(LOGOR, a, logor(J, notin));\n\t\tDECREC();\n\t}\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,10 @@\n static js_Ast *logor(js_State *J, int notin)\n {\n \tjs_Ast *a = logand(J, notin);\n-\tif (jsP_accept(J, TK_OR))\n+\tif (jsP_accept(J, TK_OR)) {\n+\t\tINCREC();\n \t\ta = EXP2(LOGOR, a, logor(J, notin));\n+\t\tDECREC();\n+\t}\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (jsP_accept(J, TK_OR))"
            ],
            "added_lines": [
                "\tif (jsP_accept(J, TK_OR)) {",
                "\t\tINCREC();",
                "\t\tDECREC();",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/bitor",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *bitor(js_State *J, int notin)\n{\n\tjs_Ast *a = bitxor(J, notin);\n\twhile (jsP_accept(J, '|'))\n\t\ta = EXP2(BITOR, a, bitxor(J, notin));\n\treturn a;\n}",
        "func": "static js_Ast *bitor(js_State *J, int notin)\n{\n\tjs_Ast *a = bitxor(J, notin);\n\tSAVEREC();\n\twhile (jsP_accept(J, '|')) {\n\t\tINCREC();\n\t\ta = EXP2(BITOR, a, bitxor(J, notin));\n\t}\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,11 @@\n static js_Ast *bitor(js_State *J, int notin)\n {\n \tjs_Ast *a = bitxor(J, notin);\n-\twhile (jsP_accept(J, '|'))\n+\tSAVEREC();\n+\twhile (jsP_accept(J, '|')) {\n+\t\tINCREC();\n \t\ta = EXP2(BITOR, a, bitxor(J, notin));\n+\t}\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\twhile (jsP_accept(J, '|'))"
            ],
            "added_lines": [
                "\tSAVEREC();",
                "\twhile (jsP_accept(J, '|')) {",
                "\t\tINCREC();",
                "\t}",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/bitand",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *bitand(js_State *J, int notin)\n{\n\tjs_Ast *a = equality(J, notin);\n\twhile (jsP_accept(J, '&'))\n\t\ta = EXP2(BITAND, a, equality(J, notin));\n\treturn a;\n}",
        "func": "static js_Ast *bitand(js_State *J, int notin)\n{\n\tjs_Ast *a = equality(J, notin);\n\tSAVEREC();\n\twhile (jsP_accept(J, '&')) {\n\t\tINCREC();\n\t\ta = EXP2(BITAND, a, equality(J, notin));\n\t}\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,11 @@\n static js_Ast *bitand(js_State *J, int notin)\n {\n \tjs_Ast *a = equality(J, notin);\n-\twhile (jsP_accept(J, '&'))\n+\tSAVEREC();\n+\twhile (jsP_accept(J, '&')) {\n+\t\tINCREC();\n \t\ta = EXP2(BITAND, a, equality(J, notin));\n+\t}\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\twhile (jsP_accept(J, '&'))"
            ],
            "added_lines": [
                "\tSAVEREC();",
                "\twhile (jsP_accept(J, '&')) {",
                "\t\tINCREC();",
                "\t}",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5759",
        "func_name": "ArtifexSoftware/mujs/memberexp",
        "description": "jsparse.c in Artifex MuJS through 1.0.2 does not properly maintain the AST depth for binary expressions, which allows remote attackers to cause a denial of service (excessive recursion) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/mujs/commit/4d45a96e57fbabf00a7378b337d0ddcace6f38c1",
        "commit_title": "Guard binary expressions from too much recursion.",
        "commit_text": "",
        "func_before": "static js_Ast *memberexp(js_State *J)\n{\n\tjs_Ast *a;\n\tINCREC();\n\ta = newexp(J);\nloop:\n\tif (jsP_accept(J, '.')) { a = EXP2(MEMBER, a, identifiername(J)); goto loop; }\n\tif (jsP_accept(J, '[')) { a = EXP2(INDEX, a, expression(J, 0)); jsP_expect(J, ']'); goto loop; }\n\tDECREC();\n\treturn a;\n}",
        "func": "static js_Ast *memberexp(js_State *J)\n{\n\tjs_Ast *a = newexp(J);\n\tSAVEREC();\nloop:\n\tINCREC();\n\tif (jsP_accept(J, '.')) { a = EXP2(MEMBER, a, identifiername(J)); goto loop; }\n\tif (jsP_accept(J, '[')) { a = EXP2(INDEX, a, expression(J, 0)); jsP_expect(J, ']'); goto loop; }\n\tPOPREC();\n\treturn a;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,11 @@\n static js_Ast *memberexp(js_State *J)\n {\n-\tjs_Ast *a;\n+\tjs_Ast *a = newexp(J);\n+\tSAVEREC();\n+loop:\n \tINCREC();\n-\ta = newexp(J);\n-loop:\n \tif (jsP_accept(J, '.')) { a = EXP2(MEMBER, a, identifiername(J)); goto loop; }\n \tif (jsP_accept(J, '[')) { a = EXP2(INDEX, a, expression(J, 0)); jsP_expect(J, ']'); goto loop; }\n-\tDECREC();\n+\tPOPREC();\n \treturn a;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tjs_Ast *a;",
                "\ta = newexp(J);",
                "loop:",
                "\tDECREC();"
            ],
            "added_lines": [
                "\tjs_Ast *a = newexp(J);",
                "\tSAVEREC();",
                "loop:",
                "\tPOPREC();"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-6544",
        "func_name": "ArtifexSoftware/mupdf/pdf_open_raw_filter",
        "description": "pdf_load_obj_stm in pdf/pdf-xref.c in Artifex MuPDF 1.12.0 could reference the object stream recursively and therefore run out of error stack, which allows remote attackers to cause a denial of service via a crafted PDF document.",
        "git_url": "https://github.com/ArtifexSoftware/mupdf/commit/26527eef77b3e51c2258c8e40845bfbc015e405d",
        "commit_title": "Bug 698830: Don't drop unkept stream if running out of error stack.",
        "commit_text": " Under normal conditions where fz_keep_stream() is called inside fz_try() we may call fz_drop_stream() in fz_catch() upon exceptions. The issue comes when fz_keep_stream() has not yet been called but is dropped in fz_catch(). This happens in the PDF from the bug when fz_try() runs out of exception stack, and next the code in fz_catch() runs, dropping the caller's reference to the filter chain stream!  The simplest way of fixing this it to always keep the filter chain stream before fz_try() is called. That way fz_catch() may drop the stream whether an exception has occurred or if the fz_try() ran out of exception stack.",
        "func_before": "static fz_stream *\npdf_open_raw_filter(fz_context *ctx, fz_stream *chain, pdf_document *doc, pdf_obj *stmobj, int num, int *orig_num, int *orig_gen, int64_t offset)\n{\n\tpdf_xref_entry *x = NULL;\n\tfz_stream *chain2;\n\tint hascrypt;\n\tint len;\n\n\tif (num > 0 && num < pdf_xref_len(ctx, doc))\n\t{\n\t\tx = pdf_get_xref_entry(ctx, doc, num);\n\t\t*orig_num = x->num;\n\t\t*orig_gen = x->gen;\n\t\tif (x->stm_buf)\n\t\t\treturn fz_open_buffer(ctx, x->stm_buf);\n\t}\n\telse\n\t{\n\t\t/* We only end up here when called from pdf_open_stream_with_offset to parse new format XRef sections. */\n\t\t/* New style XRef sections must have generation number 0. */\n\t\t*orig_num = num;\n\t\t*orig_gen = 0;\n\t}\n\n\tfz_var(chain);\n\n\tfz_try(ctx)\n\t{\n\t\tlen = pdf_to_int(ctx, pdf_dict_get(ctx, stmobj, PDF_NAME_Length));\n\n\t\t/* don't close chain when we close this filter */\n\t\tchain2 = fz_keep_stream(ctx, chain);\n\t\tchain = NULL;\n\t\tchain = fz_open_null(ctx, chain2, len, offset);\n\n\t\thascrypt = pdf_stream_has_crypt(ctx, stmobj);\n\t\tif (doc->crypt && !hascrypt)\n\t\t{\n\t\t\tchain2 = chain;\n\t\t\tchain = NULL;\n\t\t\tchain = pdf_open_crypt(ctx, chain2, doc->crypt, *orig_num, *orig_gen);\n\t\t}\n\t}\n\tfz_catch(ctx)\n\t{\n\t\tfz_drop_stream(ctx, chain);\n\t\tfz_rethrow(ctx);\n\t}\n\n\treturn chain;\n}",
        "func": "static fz_stream *\npdf_open_raw_filter(fz_context *ctx, fz_stream *chain, pdf_document *doc, pdf_obj *stmobj, int num, int *orig_num, int *orig_gen, int64_t offset)\n{\n\tpdf_xref_entry *x = NULL;\n\tfz_stream *chain2;\n\tint hascrypt;\n\tint len;\n\n\tif (num > 0 && num < pdf_xref_len(ctx, doc))\n\t{\n\t\tx = pdf_get_xref_entry(ctx, doc, num);\n\t\t*orig_num = x->num;\n\t\t*orig_gen = x->gen;\n\t\tif (x->stm_buf)\n\t\t\treturn fz_open_buffer(ctx, x->stm_buf);\n\t}\n\telse\n\t{\n\t\t/* We only end up here when called from pdf_open_stream_with_offset to parse new format XRef sections. */\n\t\t/* New style XRef sections must have generation number 0. */\n\t\t*orig_num = num;\n\t\t*orig_gen = 0;\n\t}\n\n\tchain = fz_keep_stream(ctx, chain);\n\n\tfz_try(ctx)\n\t{\n\t\tlen = pdf_to_int(ctx, pdf_dict_get(ctx, stmobj, PDF_NAME_Length));\n\n\t\tchain2 = chain;\n\t\tchain = NULL;\n\t\tchain = fz_open_null(ctx, chain2, len, offset);\n\n\t\thascrypt = pdf_stream_has_crypt(ctx, stmobj);\n\t\tif (doc->crypt && !hascrypt)\n\t\t{\n\t\t\tchain2 = chain;\n\t\t\tchain = NULL;\n\t\t\tchain = pdf_open_crypt(ctx, chain2, doc->crypt, *orig_num, *orig_gen);\n\t\t}\n\t}\n\tfz_catch(ctx)\n\t{\n\t\tfz_drop_stream(ctx, chain);\n\t\tfz_rethrow(ctx);\n\t}\n\n\treturn chain;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,14 +22,13 @@\n \t\t*orig_gen = 0;\n \t}\n \n-\tfz_var(chain);\n+\tchain = fz_keep_stream(ctx, chain);\n \n \tfz_try(ctx)\n \t{\n \t\tlen = pdf_to_int(ctx, pdf_dict_get(ctx, stmobj, PDF_NAME_Length));\n \n-\t\t/* don't close chain when we close this filter */\n-\t\tchain2 = fz_keep_stream(ctx, chain);\n+\t\tchain2 = chain;\n \t\tchain = NULL;\n \t\tchain = fz_open_null(ctx, chain2, len, offset);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tfz_var(chain);",
                "\t\t/* don't close chain when we close this filter */",
                "\t\tchain2 = fz_keep_stream(ctx, chain);"
            ],
            "added_lines": [
                "\tchain = fz_keep_stream(ctx, chain);",
                "\t\tchain2 = chain;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-6544",
        "func_name": "ArtifexSoftware/mupdf/pdf_load_obj_stm",
        "description": "pdf_load_obj_stm in pdf/pdf-xref.c in Artifex MuPDF 1.12.0 could reference the object stream recursively and therefore run out of error stack, which allows remote attackers to cause a denial of service via a crafted PDF document.",
        "git_url": "https://github.com/ArtifexSoftware/mupdf/commit/b03def134988da8c800adac1a38a41a1f09a1d89",
        "commit_title": "Bug 698830: Avoid recursion when loading object streams objects.",
        "commit_text": " If there were indirect references in the object stream dictionary and one of those indirect references referred to an object inside the object stream itself, mupdf would previously enter recursion only bounded by the exception stack. After this commit the object stream is checked if it is marked immediately after being loaded. If it is marked then we terminate the recursion at this point, if it is not marked then mark it and attempt to load the desired object within. We also take care to unmark the stream object when done or upon exception.",
        "func_before": "static pdf_xref_entry *\npdf_load_obj_stm(fz_context *ctx, pdf_document *doc, int num, pdf_lexbuf *buf, int target)\n{\n\tfz_stream *stm = NULL;\n\tpdf_obj *objstm = NULL;\n\tint *numbuf = NULL;\n\tint64_t *ofsbuf = NULL;\n\n\tpdf_obj *obj;\n\tint64_t first;\n\tint count;\n\tint i;\n\tpdf_token tok;\n\tpdf_xref_entry *ret_entry = NULL;\n\n\tfz_var(numbuf);\n\tfz_var(ofsbuf);\n\tfz_var(objstm);\n\tfz_var(stm);\n\n\tfz_try(ctx)\n\t{\n\t\tobjstm = pdf_load_object(ctx, doc, num);\n\n\t\tcount = pdf_to_int(ctx, pdf_dict_get(ctx, objstm, PDF_NAME_N));\n\t\tfirst = pdf_to_int(ctx, pdf_dict_get(ctx, objstm, PDF_NAME_First));\n\n\t\tif (count < 0)\n\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"negative number of objects in object stream\");\n\t\tif (first < 0)\n\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"first object in object stream resides outside stream\");\n\n\t\tnumbuf = fz_calloc(ctx, count, sizeof(*numbuf));\n\t\tofsbuf = fz_calloc(ctx, count, sizeof(*ofsbuf));\n\n\t\tstm = pdf_open_stream_number(ctx, doc, num);\n\t\tfor (i = 0; i < count; i++)\n\t\t{\n\t\t\ttok = pdf_lex(ctx, stm, buf);\n\t\t\tif (tok != PDF_TOK_INT)\n\t\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"corrupt object stream (%d 0 R)\", num);\n\t\t\tnumbuf[i] = buf->i;\n\n\t\t\ttok = pdf_lex(ctx, stm, buf);\n\t\t\tif (tok != PDF_TOK_INT)\n\t\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"corrupt object stream (%d 0 R)\", num);\n\t\t\tofsbuf[i] = buf->i;\n\t\t}\n\n\t\tfz_seek(ctx, stm, first, SEEK_SET);\n\n\t\tfor (i = 0; i < count; i++)\n\t\t{\n\t\t\tint xref_len = pdf_xref_len(ctx, doc);\n\t\t\tpdf_xref_entry *entry;\n\t\t\tfz_seek(ctx, stm, first + ofsbuf[i], SEEK_SET);\n\n\t\t\tobj = pdf_parse_stm_obj(ctx, doc, stm, buf);\n\n\t\t\tif (numbuf[i] <= 0 || numbuf[i] >= xref_len)\n\t\t\t{\n\t\t\t\tpdf_drop_obj(ctx, obj);\n\t\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"object id (%d 0 R) out of range (0..%d)\", numbuf[i], xref_len - 1);\n\t\t\t}\n\n\t\t\tentry = pdf_get_xref_entry(ctx, doc, numbuf[i]);\n\n\t\t\tpdf_set_obj_parent(ctx, obj, numbuf[i]);\n\n\t\t\tif (entry->type == 'o' && entry->ofs == num)\n\t\t\t{\n\t\t\t\t/* If we already have an entry for this object,\n\t\t\t\t * we'd like to drop it and use the new one -\n\t\t\t\t * but this means that anyone currently holding\n\t\t\t\t * a pointer to the old one will be left with a\n\t\t\t\t * stale pointer. Instead, we drop the new one\n\t\t\t\t * and trust that the old one is correct. */\n\t\t\t\tif (entry->obj)\n\t\t\t\t{\n\t\t\t\t\tif (pdf_objcmp(ctx, entry->obj, obj))\n\t\t\t\t\t\tfz_warn(ctx, \"Encountered new definition for object %d - keeping the original one\", numbuf[i]);\n\t\t\t\t\tpdf_drop_obj(ctx, obj);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tentry->obj = obj;\n\t\t\t\t\tfz_drop_buffer(ctx, entry->stm_buf);\n\t\t\t\t\tentry->stm_buf = NULL;\n\t\t\t\t}\n\t\t\t\tif (numbuf[i] == target)\n\t\t\t\t\tret_entry = entry;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tpdf_drop_obj(ctx, obj);\n\t\t\t}\n\t\t}\n\t}\n\tfz_always(ctx)\n\t{\n\t\tfz_drop_stream(ctx, stm);\n\t\tfz_free(ctx, ofsbuf);\n\t\tfz_free(ctx, numbuf);\n\t\tpdf_drop_obj(ctx, objstm);\n\t}\n\tfz_catch(ctx)\n\t{\n\t\tfz_rethrow(ctx);\n\t}\n\treturn ret_entry;\n}",
        "func": "static pdf_xref_entry *\npdf_load_obj_stm(fz_context *ctx, pdf_document *doc, int num, pdf_lexbuf *buf, int target)\n{\n\tfz_stream *stm = NULL;\n\tpdf_obj *objstm = NULL;\n\tint *numbuf = NULL;\n\tint64_t *ofsbuf = NULL;\n\n\tpdf_obj *obj;\n\tint64_t first;\n\tint count;\n\tint i;\n\tpdf_token tok;\n\tpdf_xref_entry *ret_entry = NULL;\n\n\tfz_var(numbuf);\n\tfz_var(ofsbuf);\n\tfz_var(objstm);\n\tfz_var(stm);\n\n\tfz_try(ctx)\n\t{\n\t\tobjstm = pdf_load_object(ctx, doc, num);\n\n\t\tif (pdf_obj_marked(ctx, objstm))\n\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"recursive object stream lookup\");\n\t}\n\tfz_catch(ctx)\n\t{\n\t\tpdf_drop_obj(ctx, objstm);\n\t\tfz_rethrow(ctx);\n\t}\n\n\tfz_try(ctx)\n\t{\n\t\tpdf_mark_obj(ctx, objstm);\n\n\t\tcount = pdf_to_int(ctx, pdf_dict_get(ctx, objstm, PDF_NAME_N));\n\t\tfirst = pdf_to_int(ctx, pdf_dict_get(ctx, objstm, PDF_NAME_First));\n\n\t\tif (count < 0)\n\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"negative number of objects in object stream\");\n\t\tif (first < 0)\n\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"first object in object stream resides outside stream\");\n\n\t\tnumbuf = fz_calloc(ctx, count, sizeof(*numbuf));\n\t\tofsbuf = fz_calloc(ctx, count, sizeof(*ofsbuf));\n\n\t\tstm = pdf_open_stream_number(ctx, doc, num);\n\t\tfor (i = 0; i < count; i++)\n\t\t{\n\t\t\ttok = pdf_lex(ctx, stm, buf);\n\t\t\tif (tok != PDF_TOK_INT)\n\t\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"corrupt object stream (%d 0 R)\", num);\n\t\t\tnumbuf[i] = buf->i;\n\n\t\t\ttok = pdf_lex(ctx, stm, buf);\n\t\t\tif (tok != PDF_TOK_INT)\n\t\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"corrupt object stream (%d 0 R)\", num);\n\t\t\tofsbuf[i] = buf->i;\n\t\t}\n\n\t\tfz_seek(ctx, stm, first, SEEK_SET);\n\n\t\tfor (i = 0; i < count; i++)\n\t\t{\n\t\t\tint xref_len = pdf_xref_len(ctx, doc);\n\t\t\tpdf_xref_entry *entry;\n\t\t\tfz_seek(ctx, stm, first + ofsbuf[i], SEEK_SET);\n\n\t\t\tobj = pdf_parse_stm_obj(ctx, doc, stm, buf);\n\n\t\t\tif (numbuf[i] <= 0 || numbuf[i] >= xref_len)\n\t\t\t{\n\t\t\t\tpdf_drop_obj(ctx, obj);\n\t\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"object id (%d 0 R) out of range (0..%d)\", numbuf[i], xref_len - 1);\n\t\t\t}\n\n\t\t\tentry = pdf_get_xref_entry(ctx, doc, numbuf[i]);\n\n\t\t\tpdf_set_obj_parent(ctx, obj, numbuf[i]);\n\n\t\t\tif (entry->type == 'o' && entry->ofs == num)\n\t\t\t{\n\t\t\t\t/* If we already have an entry for this object,\n\t\t\t\t * we'd like to drop it and use the new one -\n\t\t\t\t * but this means that anyone currently holding\n\t\t\t\t * a pointer to the old one will be left with a\n\t\t\t\t * stale pointer. Instead, we drop the new one\n\t\t\t\t * and trust that the old one is correct. */\n\t\t\t\tif (entry->obj)\n\t\t\t\t{\n\t\t\t\t\tif (pdf_objcmp(ctx, entry->obj, obj))\n\t\t\t\t\t\tfz_warn(ctx, \"Encountered new definition for object %d - keeping the original one\", numbuf[i]);\n\t\t\t\t\tpdf_drop_obj(ctx, obj);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tentry->obj = obj;\n\t\t\t\t\tfz_drop_buffer(ctx, entry->stm_buf);\n\t\t\t\t\tentry->stm_buf = NULL;\n\t\t\t\t}\n\t\t\t\tif (numbuf[i] == target)\n\t\t\t\t\tret_entry = entry;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tpdf_drop_obj(ctx, obj);\n\t\t\t}\n\t\t}\n\t}\n\tfz_always(ctx)\n\t{\n\t\tfz_drop_stream(ctx, stm);\n\t\tfz_free(ctx, ofsbuf);\n\t\tfz_free(ctx, numbuf);\n\t\tpdf_unmark_obj(ctx, objstm);\n\t\tpdf_drop_obj(ctx, objstm);\n\t}\n\tfz_catch(ctx)\n\t{\n\t\tfz_rethrow(ctx);\n\t}\n\treturn ret_entry;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,19 @@\n \tfz_try(ctx)\n \t{\n \t\tobjstm = pdf_load_object(ctx, doc, num);\n+\n+\t\tif (pdf_obj_marked(ctx, objstm))\n+\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"recursive object stream lookup\");\n+\t}\n+\tfz_catch(ctx)\n+\t{\n+\t\tpdf_drop_obj(ctx, objstm);\n+\t\tfz_rethrow(ctx);\n+\t}\n+\n+\tfz_try(ctx)\n+\t{\n+\t\tpdf_mark_obj(ctx, objstm);\n \n \t\tcount = pdf_to_int(ctx, pdf_dict_get(ctx, objstm, PDF_NAME_N));\n \t\tfirst = pdf_to_int(ctx, pdf_dict_get(ctx, objstm, PDF_NAME_First));\n@@ -101,6 +114,7 @@\n \t\tfz_drop_stream(ctx, stm);\n \t\tfz_free(ctx, ofsbuf);\n \t\tfz_free(ctx, numbuf);\n+\t\tpdf_unmark_obj(ctx, objstm);\n \t\tpdf_drop_obj(ctx, objstm);\n \t}\n \tfz_catch(ctx)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t\tif (pdf_obj_marked(ctx, objstm))",
                "\t\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"recursive object stream lookup\");",
                "\t}",
                "\tfz_catch(ctx)",
                "\t{",
                "\t\tpdf_drop_obj(ctx, objstm);",
                "\t\tfz_rethrow(ctx);",
                "\t}",
                "",
                "\tfz_try(ctx)",
                "\t{",
                "\t\tpdf_mark_obj(ctx, objstm);",
                "\t\tpdf_unmark_obj(ctx, objstm);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-47662",
        "func_name": "gpac/gf_isom_nalu_sample_rewrite",
        "description": "GPAC MP4Box 2.1-DEV-rev649-ga8f438d20 has a segment fault (/stack overflow) due to infinite recursion in Media_GetSample isomedia/media.c:662",
        "git_url": "https://github.com/gpac/gpac/commit/080a62728ccd251a7f20eaac3fda21b0716e3c9b",
        "commit_title": "fixed #2359",
        "commit_text": "",
        "func_before": "GF_Err gf_isom_nalu_sample_rewrite(GF_MediaBox *mdia, GF_ISOSample *sample, u32 sampleNumber, GF_MPEGVisualSampleEntryBox *entry)\n{\n\tBool is_hevc = GF_FALSE;\n\t//if only one sync given in the sample sync table, insert sps/pps/vps before cra/bla in hevc\n//\tBool check_cra_bla = (mdia->information->sampleTable->SyncSample && mdia->information->sampleTable->SyncSample->nb_entries>1) ? 0 : 1;\n\tBool check_cra_bla = GF_TRUE;\n\tBool insert_nalu_delim = GF_TRUE;\n\tBool force_sei_inspect = GF_FALSE;\n\tGF_Err e = GF_OK;\n\tGF_BitStream *sei_suffix_bs = NULL;\n\tBool ps_transfered = GF_FALSE;\n\tu32 nal_size, nal_unit_size_field, extractor_mode;\n\tBool rewrite_ps, rewrite_start_codes, insert_vdrd_code;\n\tu8 nal_type;\n\tu32 nal_hdr, sabt_ref, i, track_num;\n\tu32 temporal_id = 0;\n\tGF_ISOFile *file = mdia->mediaTrack->moov->mov;\n\tGF_TrackReferenceTypeBox *scal = NULL;\n\n\tTrack_FindRef(mdia->mediaTrack, GF_ISOM_REF_SCAL, &scal);\n\n\trewrite_ps = (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_INBAND_PS_FLAG) ? GF_TRUE : GF_FALSE;\n\trewrite_start_codes = (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_ANNEXB_FLAG) ? GF_TRUE : GF_FALSE;\n\tinsert_vdrd_code = (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_VDRD_FLAG) ? GF_TRUE : GF_FALSE;\n\tif (!entry->svc_config && !entry->mvc_config && !entry->lhvc_config) insert_vdrd_code = GF_FALSE;\n\textractor_mode = mdia->mediaTrack->extractor_mode&0x0000FFFF;\n\n\tif (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_TILE_ONLY) {\n\t\tinsert_nalu_delim = GF_FALSE;\n\t}\n\n\ttrack_num = 1 + gf_list_find(mdia->mediaTrack->moov->trackList, mdia->mediaTrack);\n\n\tif ( (extractor_mode != GF_ISOM_NALU_EXTRACT_INSPECT) && !(mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_TILE_ONLY) ) {\n\t\tu32 ref_track, di;\n\t\t//aggregate all sabt samples with the same DTS\n\t\tif (entry->lhvc_config && !entry->hevc_config && !(mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_LAYER_ONLY)) {\n\t\t\tif (gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_SCAL) <= 0) {\n\t\t\t\t//FIXME - for now we only support two layers (base + enh) in implicit\n\t\t\t\tif ( gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_BASE) >= 1) {\n\t\t\t\t\tGF_ISOSample *base_samp;\n\t\t\t\t\tgf_isom_get_reference(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_BASE, 1, &ref_track);\n\t\t\t\t\tswitch (gf_isom_get_media_subtype(mdia->mediaTrack->moov->mov , ref_track, 1)) {\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HVC1:\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HVC2:\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HEV1:\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HEV2:\n\n\t\t\t\t\t\tif (!mdia->extracted_samp) {\n\t\t\t\t\t\t\tmdia->extracted_samp = gf_isom_sample_new();\n\t\t\t\t\t\t\tif (!mdia->extracted_samp) return GF_OUT_OF_MEM;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tbase_samp = gf_isom_get_sample_ex(mdia->mediaTrack->moov->mov, ref_track, sampleNumber + mdia->mediaTrack->sample_count_at_seg_start, &di, mdia->extracted_samp, NULL);\n\t\t\t\t\t\tif (base_samp && base_samp->data) {\n\t\t\t\t\t\t\tif (!sample->alloc_size || (sample->alloc_size<sample->dataLength+base_samp->dataLength) ) {\n\t\t\t\t\t\t\t\tsample->data = gf_realloc(sample->data, sample->dataLength+base_samp->dataLength);\n\t\t\t\t\t\t\t\tif (sample->alloc_size) sample->alloc_size = sample->dataLength+base_samp->dataLength;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmemmove(sample->data + base_samp->dataLength, sample->data , sample->dataLength);\n\t\t\t\t\t\t\tmemcpy(sample->data, base_samp->data, base_samp->dataLength);\n\t\t\t\t\t\t\tsample->dataLength += base_samp->dataLength;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tTrack_FindRef(mdia->mediaTrack, GF_ISOM_REF_BASE, &scal);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tsabt_ref = gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_SABT);\n\t\tif ((s32) sabt_ref > 0) {\n\t\t\tforce_sei_inspect = GF_TRUE;\n\t\t\tfor (i=0; i<sabt_ref; i++) {\n\t\t\t\tGF_ISOSample *tile_samp;\n\t\t\t\tgf_isom_get_reference(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_SABT, i+1, &ref_track);\n\n\t\t\t\tif (!mdia->extracted_samp) {\n\t\t\t\t\tmdia->extracted_samp = gf_isom_sample_new();\n\t\t\t\t\tif (!mdia->extracted_samp) return GF_OUT_OF_MEM;\n\t\t\t\t}\n\n\t\t\t\ttile_samp = gf_isom_get_sample_ex(mdia->mediaTrack->moov->mov, ref_track, sampleNumber + mdia->mediaTrack->sample_count_at_seg_start, &di, mdia->extracted_samp, NULL);\n\t\t\t\tif (tile_samp  && tile_samp ->data) {\n\t\t\t\t\tif (!sample->alloc_size || (sample->alloc_size<sample->dataLength+tile_samp->dataLength) ) {\n\t\t\t\t\t\tsample->data = gf_realloc(sample->data, sample->dataLength+tile_samp->dataLength);\n\t\t\t\t\t\tif (sample->alloc_size) sample->alloc_size = sample->dataLength+tile_samp->dataLength;\n\t\t\t\t\t}\n\t\t\t\t\tmemcpy(sample->data + sample->dataLength, tile_samp->data, tile_samp->dataLength);\n\t\t\t\t\tsample->dataLength += tile_samp->dataLength;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif ( gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_TBAS) >= 1) {\n\t\tu32 ref_track;\n\t\tu32 idx = gf_list_find(mdia->information->sampleTable->SampleDescription->child_boxes, entry);\n\t\tGF_TrackBox *tbas;\n\t\tgf_isom_get_reference(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_TBAS, 1, &ref_track);\n\t\ttbas = (GF_TrackBox *)gf_list_get(mdia->mediaTrack->moov->trackList, ref_track-1);\n\t\tentry = gf_list_get(tbas->Media->information->sampleTable->SampleDescription->child_boxes, idx);\n\t}\n\n\n\tif (sample->IsRAP < SAP_TYPE_2) {\n\t\tif (mdia->information->sampleTable->no_sync_found || (!sample->IsRAP && check_cra_bla) ) {\n\t\t\tsample->IsRAP = is_sample_idr(mdia, sample, entry);\n\t\t}\n\t}\n\tif (!sample->IsRAP)\n\t\trewrite_ps = GF_FALSE;\n\n\tif (extractor_mode != GF_ISOM_NALU_EXTRACT_LAYER_ONLY)\n\t\tinsert_vdrd_code = GF_FALSE;\n\n\tif (!entry) return GF_BAD_PARAM;\n\n\t//this is a compatible HEVC, don't insert VDRD, insert NALU delim\n\tif (entry->lhvc_config && entry->hevc_config)\n\t\tinsert_vdrd_code = GF_FALSE;\n\n\tif (extractor_mode == GF_ISOM_NALU_EXTRACT_INSPECT) {\n\t\tif (!rewrite_ps && !rewrite_start_codes)\n\t\t\treturn GF_OK;\n\t}\n\n\tnal_unit_size_field = 0;\n\t/*if svc rewrite*/\n\tif (entry->svc_config && entry->svc_config->config)\n\t\tnal_unit_size_field = entry->svc_config->config->nal_unit_size;\n\t/*if mvc rewrite*/\n\tif (entry->mvc_config && entry->mvc_config->config)\n\t\tnal_unit_size_field = entry->mvc_config->config->nal_unit_size;\n\n\t/*if lhvc rewrite*/\n\telse if (entry->lhvc_config && entry->lhvc_config->config)  {\n\t\tis_hevc = GF_TRUE;\n\t\tnal_unit_size_field = entry->lhvc_config->config->nal_unit_size;\n\t}\n\n\t/*otherwise do nothing*/\n\telse if (!rewrite_ps && !rewrite_start_codes && !scal && !force_sei_inspect) {\n\t\treturn GF_OK;\n\t}\n\n\tif (!nal_unit_size_field) {\n\t\tif (entry->avc_config && entry->avc_config->config)\n\t\t\tnal_unit_size_field = entry->avc_config->config->nal_unit_size;\n\t\telse if (entry->lhvc_config && entry->lhvc_config->config) {\n\t\t\tnal_unit_size_field = entry->lhvc_config->config->nal_unit_size;\n\t\t\tis_hevc = GF_TRUE;\n\t\t}\n\t\telse if (entry->hevc_config && entry->hevc_config->config) {\n\t\t\tnal_unit_size_field = entry->hevc_config->config->nal_unit_size;\n\t\t\tis_hevc = GF_TRUE;\n\t\t}\n\t}\n\n\tif (!nal_unit_size_field) return GF_ISOM_INVALID_FILE;\n\n\t//setup PS rewriter\n\tif (!mdia->nalu_ps_bs)\n\t\tmdia->nalu_ps_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\tgf_bs_seek(mdia->nalu_ps_bs, 0);\n\n\t//setup sample reader\n\tif (mdia->in_sample_buffer_alloc<sample->dataLength) {\n\t\tmdia->in_sample_buffer_alloc = sample->dataLength;\n\t\tmdia->in_sample_buffer = gf_realloc(mdia->in_sample_buffer, sample->dataLength);\n\t}\n\tmemcpy(mdia->in_sample_buffer, sample->data, sample->dataLength);\n\n\tif (!mdia->nalu_parser) {\n\t\tmdia->nalu_parser = gf_bs_new(mdia->in_sample_buffer, sample->dataLength, GF_BITSTREAM_READ);\n\t\tif (!mdia->nalu_parser && sample->data) return GF_ISOM_INVALID_FILE;\n\t} else {\n\t\te = gf_bs_reassign_buffer(mdia->nalu_parser, mdia->in_sample_buffer, sample->dataLength);\n\t\tif (e) return e;\n\t}\n\t//setup output\n\tif (!mdia->nalu_out_bs) {\n\t\tu8 *output;\n\t\tu32 outSize;\n\t\tmdia->nalu_out_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\tgf_bs_get_content(mdia->nalu_out_bs, &output, &outSize);\n\t}\n\n\tgf_bs_reassign_buffer(mdia->nalu_out_bs, sample->data, sample->alloc_size ? sample->alloc_size : sample->dataLength);\n\n\t/*rewrite start code with NALU delim*/\n\tif (rewrite_start_codes) {\n\n\t\t//we are SVC, don't write NALU delim, only insert VDRD NALU\n\t\tif (insert_vdrd_code) {\n\t\t\tif (is_hevc) {\n\t\t\t\t//spec is not clear here, we don't insert an NALU AU delimiter before the layer starts since it breaks openHEVC\n//\t\t\t\tinsert_nalu_delim=0;\n\t\t\t} else {\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 1, 32);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, GF_AVC_NALU_VDRD , 8);\n\t\t\t\tinsert_nalu_delim=0;\n\t\t\t}\n\t\t}\n\n\t\t//AVC/HEVC base, insert NALU delim\n\t\tif (insert_nalu_delim) {\n\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 1, 32);\n\t\t\tif (is_hevc) {\n#ifndef GPAC_DISABLE_HEVC\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 0, 1);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, GF_HEVC_NALU_ACCESS_UNIT, 6);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, insert_vdrd_code ? 1 : 0, 6); //we should pick the layerID of the following nalus ...\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 1, 3); //nuh_temporal_id_plus1 - cannot be 0, we use 1 by default, and overwrite it if needed at the end\n\n\t\t\t\t/*pic-type - by default we signal all slice types possible*/\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 2, 3);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 0, 5);\n#endif\n\t\t\t} else {\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, (sample->data[0] & 0x60) | GF_AVC_NALU_ACCESS_UNIT, 8);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 0xF0 , 8); /*7 \"all supported NALUs\" (=111) + rbsp trailing (10000)*/;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (rewrite_ps) {\n\t\tBool has_vps = GF_FALSE;\n\t\t//in inspect mode or single-layer mode just use the xPS from this layer\n\t\tif (extractor_mode == GF_ISOM_NALU_EXTRACT_DEFAULT) {\n\t\t\tif (scal) {\n\t\t\t\tfor (i=0; i<scal->trackIDCount; i++) {\n\t\t\t\t\tGF_TrackBox *a_track = GetTrackbyID(mdia->mediaTrack->moov, scal->trackIDs[i]);\n\t\t\t\t\tGF_MPEGVisualSampleEntryBox *an_entry = NULL;\n\t\t\t\t\tif (a_track && a_track->Media && a_track->Media->information && a_track->Media->information->sampleTable && a_track->Media->information->sampleTable->SampleDescription)\n\t\t\t\t\t\tan_entry = (GF_MPEGVisualSampleEntryBox*)gf_list_get(a_track->Media->information->sampleTable->SampleDescription->child_boxes, 0);\n\n\t\t\t\t\tif (an_entry)\n\t\t\t\t\t\tnalu_merge_ps(mdia->nalu_ps_bs, rewrite_start_codes, nal_unit_size_field, an_entry, is_hevc, &has_vps);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tnalu_merge_ps(mdia->nalu_ps_bs, rewrite_start_codes, nal_unit_size_field, entry, is_hevc, &has_vps);\n\n\n\t\tif (is_hevc) {\n\t\t\t/*little optimization if we are not asked to start codes: copy over the sample*/\n\t\t\tif (!rewrite_start_codes && !entry->lhvc_config && !scal) {\n\t\t\t\tif (! ps_transfered) {\n\t\t\t\t\tnal_type = (sample->data[nal_unit_size_field] & 0x7E) >> 1;\n\t\t\t\t\t//temp fix - if we detect xPS in the beginning of the sample do NOT copy the ps bitstream\n\t\t\t\t\t//this is not correct since we are not sure whether they are the same xPS or not, but it crashes openHEVC ...\n\t\t\t\t\tswitch (nal_type) {\n#ifndef GPAC_DISABLE_HEVC\n\t\t\t\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\t\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\t\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\t\t\t\tbreak;\n#endif\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->in_sample_buffer, sample->dataLength);\n\t\t\t\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n\n\t\t\t\treturn GF_OK;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tps_transfered = GF_TRUE;\n\t}\n\n\t/*little optimization if we are not asked to rewrite extractors or start codes: copy over the sample*/\n\tif (!scal && !rewrite_start_codes && !rewrite_ps && !force_sei_inspect) {\n\t\tif (! ps_transfered)\n\t\t{\n\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t}\n\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->in_sample_buffer, sample->dataLength);\n\t\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n\t\treturn GF_OK;\n\t}\n\n\tif (!mdia->tmp_nal_copy_buffer) {\n\t\tmdia->tmp_nal_copy_buffer = gf_malloc(sizeof(char) * 4096);\n\t\tmdia->tmp_nal_copy_buffer_alloc = 4096;\n\t}\n\n\n\twhile (gf_bs_available(mdia->nalu_parser)) {\n\t\tnal_size = gf_bs_read_int(mdia->nalu_parser, 8*nal_unit_size_field);\n\t\tif (gf_bs_get_position(mdia->nalu_parser) + nal_size > sample->dataLength) {\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CODING, (\"Sample %u (size %u) rewrite: corrupted NAL Unit (size %u)\\n\", sampleNumber, sample->dataLength, nal_size));\n\t\t\tgoto exit;\n\t\t}\n\t\tif (nal_size > mdia->tmp_nal_copy_buffer_alloc) {\n\t\t\tmdia->tmp_nal_copy_buffer_alloc = nal_size;\n\t\t\tmdia->tmp_nal_copy_buffer = (char*) gf_realloc(mdia->tmp_nal_copy_buffer, sizeof(char)*nal_size);\n\t\t}\n\t\tif (is_hevc) {\n\t\t\tnal_hdr = gf_bs_read_u16(mdia->nalu_parser);\n\t\t\tnal_type = (nal_hdr&0x7E00) >> 9;\n\t\t} else {\n\t\t\tnal_hdr = gf_bs_read_u8(mdia->nalu_parser);\n\t\t\tnal_type = nal_hdr & 0x1F;\n\t\t}\n\n\t\tif (is_hevc) {\n#ifndef GPAC_DISABLE_HEVC\n\t\t\tGF_BitStream *write_to_bs = mdia->nalu_out_bs;\n#endif\n\n\t\t\tif (!ps_transfered) {\n\t\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t\t\tps_transfered = GF_TRUE;\n\t\t\t}\n\n#ifndef GPAC_DISABLE_HEVC\n\t\t\tswitch (nal_type) {\n\t\t\t/*we already wrote AU delim, and we trash aggregators*/\n\t\t\tcase GF_HEVC_NALU_ACCESS_UNIT:\n\t\t\tcase GF_HEVC_NALU_FF_AGGREGATOR:\n\t\t\t\tgf_bs_skip_bytes(mdia->nalu_parser, nal_size-2);\n\t\t\t\tcontinue;\n\n\t\t\t//extractor\n\t\t\tcase GF_HEVC_NALU_FF_EXTRACTOR:\n\t\t\t\te = process_extractor(file, mdia, sampleNumber, sample->DTS, nal_size, nal_hdr, nal_unit_size_field, GF_TRUE, rewrite_ps, rewrite_start_codes, extractor_mode);\n\t\t\t\tif (e) goto exit;\n\t\t\t\tbreak;\n\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_R:\n\t\t\t\tif (temporal_id < (nal_hdr & 0x7))\n\t\t\t\t\ttemporal_id = (nal_hdr & 0x7);\n\t\t\t\t/*rewrite nal*/\n\t\t\t\tgf_bs_read_data(mdia->nalu_parser, mdia->tmp_nal_copy_buffer, nal_size-2);\n\t\t\t\tif (rewrite_start_codes)\n\t\t\t\t\tgf_bs_write_u32(mdia->nalu_out_bs, 1);\n\t\t\t\telse\n\t\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, nal_size, 8*nal_unit_size_field);\n\n\t\t\t\tgf_bs_write_u16(mdia->nalu_out_bs, nal_hdr);\n\t\t\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->tmp_nal_copy_buffer, nal_size-2);\n\t\t\t\tbreak;\n\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_CRA:\n\t\t\t\t//insert xPS before CRA/BLA\n\t\t\t\tif (check_cra_bla && !sample->IsRAP) {\n\t\t\t\t\tsample->IsRAP = sap_type_from_nal_type(nal_type);\n\t\t\t\t\tif (sei_suffix_bs) gf_bs_del(sei_suffix_bs);\n\t\t\t\t\treturn gf_isom_nalu_sample_rewrite(mdia, sample, sampleNumber, entry);\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\t/*rewrite nal*/\n\t\t\t\tif (nal_size<2) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Invalid nal size %d in sample %d\\n\", nal_type, sampleNumber));\n\t\t\t\t\te = GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t\t\tgoto exit;\n\t\t\t\t}\n\n\t\t\t\tgf_bs_read_data(mdia->nalu_parser, mdia->tmp_nal_copy_buffer, nal_size-2);\n\n\t\t\t\tif (nal_type==GF_HEVC_NALU_SEI_SUFFIX) {\n\t\t\t\t\tif (!sei_suffix_bs) sei_suffix_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\t\t\twrite_to_bs = sei_suffix_bs;\n\t\t\t\t}\n\n\t\t\t\tif (rewrite_start_codes)\n\t\t\t\t\tgf_bs_write_u32(write_to_bs, 1);\n\t\t\t\telse\n\t\t\t\t\tgf_bs_write_int(write_to_bs, nal_size, 8*nal_unit_size_field);\n\n\t\t\t\tgf_bs_write_u16(write_to_bs, nal_hdr);\n\t\t\t\tgf_bs_write_data(write_to_bs, mdia->tmp_nal_copy_buffer, nal_size-2);\n\t\t\t}\n#endif\n\n\t\t\t//done with HEVC\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch(nal_type) {\n\t\tcase GF_AVC_NALU_ACCESS_UNIT:\n\t\tcase GF_AVC_NALU_FF_AGGREGATOR:\n\t\t\t/*we already wrote this stuff, and we trash aggregators*/\n\t\t\tgf_bs_skip_bytes(mdia->nalu_parser, nal_size-1);\n\t\t\tcontinue;\n\t\t//extractor\n\t\tcase GF_AVC_NALU_FF_EXTRACTOR:\n\t\t\te = process_extractor(file, mdia, sampleNumber, sample->DTS, nal_size, nal_hdr, nal_unit_size_field, GF_FALSE, rewrite_ps, rewrite_start_codes, extractor_mode);\n\t\t\tif (e) goto exit;\n\t\t\tbreak;\n//\t\t\tcase GF_AVC_NALU_SEI:\n\t\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\tcase GF_AVC_NALU_PIC_PARAM:\n\t\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\t\t// we will rewrite the sps/pps if and only if there is no sps/pps in bistream\n\t\t\tif (!ps_transfered) {\n\t\t\t\tps_transfered = GF_TRUE;\n\t\t\t}\n\t\tdefault:\n\t\t\tif (!ps_transfered) {\n\t\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t\t\tps_transfered = GF_TRUE;\n\t\t\t}\n\t\t\tgf_bs_read_data(mdia->nalu_parser, mdia->tmp_nal_copy_buffer, nal_size-1);\n\t\t\tif (rewrite_start_codes)\n\t\t\t\tgf_bs_write_u32(mdia->nalu_out_bs, 1);\n\t\t\telse\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, nal_size, 8*nal_unit_size_field);\n\n\t\t\tgf_bs_write_u8(mdia->nalu_out_bs, nal_hdr);\n\t\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->tmp_nal_copy_buffer, nal_size-1);\n\t\t}\n\t}\n\n\tif (sei_suffix_bs) {\n\t\tgf_bs_transfer(mdia->nalu_out_bs, sei_suffix_bs, GF_FALSE);\n\t}\n\t/*done*/\n\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n\n\t/*rewrite temporal ID of AU Ddelim NALU (first one)*/\n\tif (rewrite_start_codes && is_hevc && temporal_id) {\n\t\tsample->data[6] = (sample->data[6] & 0xF8) | (temporal_id+1);\n\t}\n\n\nexit:\n\tif (sei_suffix_bs)\n\t\tgf_bs_del(sei_suffix_bs);\n\n\treturn e;\n}",
        "func": "GF_Err gf_isom_nalu_sample_rewrite(GF_MediaBox *mdia, GF_ISOSample *sample, u32 sampleNumber, GF_MPEGVisualSampleEntryBox *entry)\n{\n\tBool is_hevc = GF_FALSE;\n\t//if only one sync given in the sample sync table, insert sps/pps/vps before cra/bla in hevc\n//\tBool check_cra_bla = (mdia->information->sampleTable->SyncSample && mdia->information->sampleTable->SyncSample->nb_entries>1) ? 0 : 1;\n\tBool check_cra_bla = GF_TRUE;\n\tBool insert_nalu_delim = GF_TRUE;\n\tBool force_sei_inspect = GF_FALSE;\n\tGF_Err e = GF_OK;\n\tGF_BitStream *sei_suffix_bs = NULL;\n\tBool ps_transfered = GF_FALSE;\n\tu32 nal_size, nal_unit_size_field, extractor_mode;\n\tBool rewrite_ps, rewrite_start_codes, insert_vdrd_code;\n\tu8 nal_type;\n\tu32 nal_hdr, sabt_ref, i, track_num;\n\tu32 temporal_id = 0;\n\tGF_ISOFile *file = mdia->mediaTrack->moov->mov;\n\tGF_TrackReferenceTypeBox *scal = NULL;\n\n\tif (mdia->in_nalu_rewrite)\n\t\treturn GF_ISOM_INVALID_FILE;\n\tmdia->in_nalu_rewrite = GF_TRUE;\n\n\tTrack_FindRef(mdia->mediaTrack, GF_ISOM_REF_SCAL, &scal);\n\n\trewrite_ps = (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_INBAND_PS_FLAG) ? GF_TRUE : GF_FALSE;\n\trewrite_start_codes = (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_ANNEXB_FLAG) ? GF_TRUE : GF_FALSE;\n\tinsert_vdrd_code = (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_VDRD_FLAG) ? GF_TRUE : GF_FALSE;\n\tif (!entry->svc_config && !entry->mvc_config && !entry->lhvc_config) insert_vdrd_code = GF_FALSE;\n\textractor_mode = mdia->mediaTrack->extractor_mode&0x0000FFFF;\n\n\tif (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_TILE_ONLY) {\n\t\tinsert_nalu_delim = GF_FALSE;\n\t}\n\n\ttrack_num = 1 + gf_list_find(mdia->mediaTrack->moov->trackList, mdia->mediaTrack);\n\n\tif ( (extractor_mode != GF_ISOM_NALU_EXTRACT_INSPECT) && !(mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_TILE_ONLY) ) {\n\t\tu32 ref_track, di;\n\t\t//aggregate all sabt samples with the same DTS\n\t\tif (entry->lhvc_config && !entry->hevc_config && !(mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_LAYER_ONLY)) {\n\t\t\tif (gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_SCAL) <= 0) {\n\t\t\t\t//FIXME - for now we only support two layers (base + enh) in implicit\n\t\t\t\tif ( gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_BASE) >= 1) {\n\t\t\t\t\tGF_ISOSample *base_samp;\n\t\t\t\t\tgf_isom_get_reference(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_BASE, 1, &ref_track);\n\t\t\t\t\tswitch (gf_isom_get_media_subtype(mdia->mediaTrack->moov->mov , ref_track, 1)) {\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HVC1:\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HVC2:\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HEV1:\n\t\t\t\t\tcase GF_ISOM_SUBTYPE_HEV2:\n\n\t\t\t\t\t\tif (!mdia->extracted_samp) {\n\t\t\t\t\t\t\tmdia->extracted_samp = gf_isom_sample_new();\n\t\t\t\t\t\t\tif (!mdia->extracted_samp) {\n\t\t\t\t\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\t\t\t\t\t\t\t\treturn GF_OUT_OF_MEM;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tbase_samp = gf_isom_get_sample_ex(mdia->mediaTrack->moov->mov, ref_track, sampleNumber + mdia->mediaTrack->sample_count_at_seg_start, &di, mdia->extracted_samp, NULL);\n\t\t\t\t\t\t//base sample may be null (track split)\n\t\t\t\t\t\tif (base_samp && base_samp->data) {\n\t\t\t\t\t\t\tif (!sample->alloc_size || (sample->alloc_size<sample->dataLength+base_samp->dataLength) ) {\n\t\t\t\t\t\t\t\tsample->data = gf_realloc(sample->data, sample->dataLength+base_samp->dataLength);\n\t\t\t\t\t\t\t\tif (sample->alloc_size) sample->alloc_size = sample->dataLength+base_samp->dataLength;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tmemmove(sample->data + base_samp->dataLength, sample->data , sample->dataLength);\n\t\t\t\t\t\t\tmemcpy(sample->data, base_samp->data, base_samp->dataLength);\n\t\t\t\t\t\t\tsample->dataLength += base_samp->dataLength;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tTrack_FindRef(mdia->mediaTrack, GF_ISOM_REF_BASE, &scal);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tsabt_ref = gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_SABT);\n\t\tif ((s32) sabt_ref > 0) {\n\t\t\tforce_sei_inspect = GF_TRUE;\n\t\t\tfor (i=0; i<sabt_ref; i++) {\n\t\t\t\tGF_ISOSample *tile_samp;\n\t\t\t\tgf_isom_get_reference(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_SABT, i+1, &ref_track);\n\n\t\t\t\tif (!mdia->extracted_samp) {\n\t\t\t\t\tmdia->extracted_samp = gf_isom_sample_new();\n\t\t\t\t\tif (!mdia->extracted_samp) {\n\t\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\t\t\t\t\treturn GF_OUT_OF_MEM;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\ttile_samp = gf_isom_get_sample_ex(mdia->mediaTrack->moov->mov, ref_track, sampleNumber + mdia->mediaTrack->sample_count_at_seg_start, &di, mdia->extracted_samp, NULL);\n\t\t\t\t//tile sample may be NULL (removal of tracks, ...)\n\t\t\t\tif (tile_samp  && tile_samp ->data) {\n\t\t\t\t\tif (!sample->alloc_size || (sample->alloc_size<sample->dataLength+tile_samp->dataLength) ) {\n\t\t\t\t\t\tsample->data = gf_realloc(sample->data, sample->dataLength+tile_samp->dataLength);\n\t\t\t\t\t\tif (sample->alloc_size) sample->alloc_size = sample->dataLength+tile_samp->dataLength;\n\t\t\t\t\t}\n\t\t\t\t\tmemcpy(sample->data + sample->dataLength, tile_samp->data, tile_samp->dataLength);\n\t\t\t\t\tsample->dataLength += tile_samp->dataLength;\n\t\t\t\t}\n \t\t\t}\n\t\t}\n\t}\n\n\tif ( gf_isom_get_reference_count(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_TBAS) >= 1) {\n\t\tu32 ref_track;\n\t\tu32 idx = gf_list_find(mdia->information->sampleTable->SampleDescription->child_boxes, entry);\n\t\tGF_TrackBox *tbas;\n\t\tgf_isom_get_reference(mdia->mediaTrack->moov->mov, track_num, GF_ISOM_REF_TBAS, 1, &ref_track);\n\t\ttbas = (GF_TrackBox *)gf_list_get(mdia->mediaTrack->moov->trackList, ref_track-1);\n\t\tentry = gf_list_get(tbas->Media->information->sampleTable->SampleDescription->child_boxes, idx);\n\t}\n\n\n\tif (sample->IsRAP < SAP_TYPE_2) {\n\t\tif (mdia->information->sampleTable->no_sync_found || (!sample->IsRAP && check_cra_bla) ) {\n\t\t\tsample->IsRAP = is_sample_idr(mdia, sample, entry);\n\t\t}\n\t}\n\tif (!sample->IsRAP)\n\t\trewrite_ps = GF_FALSE;\n\n\tif (extractor_mode != GF_ISOM_NALU_EXTRACT_LAYER_ONLY)\n\t\tinsert_vdrd_code = GF_FALSE;\n\n\tif (!entry) {\n\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\treturn GF_BAD_PARAM;\n\t}\n\t//this is a compatible HEVC, don't insert VDRD, insert NALU delim\n\tif (entry->lhvc_config && entry->hevc_config)\n\t\tinsert_vdrd_code = GF_FALSE;\n\n\tif (extractor_mode == GF_ISOM_NALU_EXTRACT_INSPECT) {\n\t\tif (!rewrite_ps && !rewrite_start_codes) {\n\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\t\treturn GF_OK;\n\t\t}\n\t}\n\n\tnal_unit_size_field = 0;\n\t/*if svc rewrite*/\n\tif (entry->svc_config && entry->svc_config->config)\n\t\tnal_unit_size_field = entry->svc_config->config->nal_unit_size;\n\t/*if mvc rewrite*/\n\tif (entry->mvc_config && entry->mvc_config->config)\n\t\tnal_unit_size_field = entry->mvc_config->config->nal_unit_size;\n\n\t/*if lhvc rewrite*/\n\telse if (entry->lhvc_config && entry->lhvc_config->config)  {\n\t\tis_hevc = GF_TRUE;\n\t\tnal_unit_size_field = entry->lhvc_config->config->nal_unit_size;\n\t}\n\n\t/*otherwise do nothing*/\n\telse if (!rewrite_ps && !rewrite_start_codes && !scal && !force_sei_inspect) {\n\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\treturn GF_OK;\n\t}\n\n\tif (!nal_unit_size_field) {\n\t\tif (entry->avc_config && entry->avc_config->config)\n\t\t\tnal_unit_size_field = entry->avc_config->config->nal_unit_size;\n\t\telse if (entry->lhvc_config && entry->lhvc_config->config) {\n\t\t\tnal_unit_size_field = entry->lhvc_config->config->nal_unit_size;\n\t\t\tis_hevc = GF_TRUE;\n\t\t}\n\t\telse if (entry->hevc_config && entry->hevc_config->config) {\n\t\t\tnal_unit_size_field = entry->hevc_config->config->nal_unit_size;\n\t\t\tis_hevc = GF_TRUE;\n\t\t}\n\t}\n\n\tif (!nal_unit_size_field) {\n\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\treturn GF_ISOM_INVALID_FILE;\n\t}\n\t//setup PS rewriter\n\tif (!mdia->nalu_ps_bs)\n\t\tmdia->nalu_ps_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\tgf_bs_seek(mdia->nalu_ps_bs, 0);\n\n\t//setup sample reader\n\tif (mdia->in_sample_buffer_alloc<sample->dataLength) {\n\t\tmdia->in_sample_buffer_alloc = sample->dataLength;\n\t\tmdia->in_sample_buffer = gf_realloc(mdia->in_sample_buffer, sample->dataLength);\n\t}\n\tmemcpy(mdia->in_sample_buffer, sample->data, sample->dataLength);\n\n\tif (!mdia->nalu_parser) {\n\t\tmdia->nalu_parser = gf_bs_new(mdia->in_sample_buffer, sample->dataLength, GF_BITSTREAM_READ);\n\t\tif (!mdia->nalu_parser && sample->data) {\n\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\t\treturn GF_ISOM_INVALID_FILE;\n\t\t}\n\t} else {\n\t\te = gf_bs_reassign_buffer(mdia->nalu_parser, mdia->in_sample_buffer, sample->dataLength);\n\t\tif (e) {\n\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\t\treturn e;\n\t\t}\n\t}\n\t//setup output\n\tif (!mdia->nalu_out_bs) {\n\t\tu8 *output;\n\t\tu32 outSize;\n\t\tmdia->nalu_out_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\tgf_bs_get_content(mdia->nalu_out_bs, &output, &outSize);\n\t}\n\n\tgf_bs_reassign_buffer(mdia->nalu_out_bs, sample->data, sample->alloc_size ? sample->alloc_size : sample->dataLength);\n\n\t/*rewrite start code with NALU delim*/\n\tif (rewrite_start_codes) {\n\n\t\t//we are SVC, don't write NALU delim, only insert VDRD NALU\n\t\tif (insert_vdrd_code) {\n\t\t\tif (is_hevc) {\n\t\t\t\t//spec is not clear here, we don't insert an NALU AU delimiter before the layer starts since it breaks openHEVC\n//\t\t\t\tinsert_nalu_delim=0;\n\t\t\t} else {\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 1, 32);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, GF_AVC_NALU_VDRD , 8);\n\t\t\t\tinsert_nalu_delim=0;\n\t\t\t}\n\t\t}\n\n\t\t//AVC/HEVC base, insert NALU delim\n\t\tif (insert_nalu_delim) {\n\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 1, 32);\n\t\t\tif (is_hevc) {\n#ifndef GPAC_DISABLE_HEVC\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 0, 1);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, GF_HEVC_NALU_ACCESS_UNIT, 6);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, insert_vdrd_code ? 1 : 0, 6); //we should pick the layerID of the following nalus ...\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 1, 3); //nuh_temporal_id_plus1 - cannot be 0, we use 1 by default, and overwrite it if needed at the end\n\n\t\t\t\t/*pic-type - by default we signal all slice types possible*/\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 2, 3);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 0, 5);\n#endif\n\t\t\t} else {\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, (sample->data[0] & 0x60) | GF_AVC_NALU_ACCESS_UNIT, 8);\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, 0xF0 , 8); /*7 \"all supported NALUs\" (=111) + rbsp trailing (10000)*/;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (rewrite_ps) {\n\t\tBool has_vps = GF_FALSE;\n\t\t//in inspect mode or single-layer mode just use the xPS from this layer\n\t\tif (extractor_mode == GF_ISOM_NALU_EXTRACT_DEFAULT) {\n\t\t\tif (scal) {\n\t\t\t\tfor (i=0; i<scal->trackIDCount; i++) {\n\t\t\t\t\tGF_TrackBox *a_track = GetTrackbyID(mdia->mediaTrack->moov, scal->trackIDs[i]);\n\t\t\t\t\tGF_MPEGVisualSampleEntryBox *an_entry = NULL;\n\t\t\t\t\tif (a_track && a_track->Media && a_track->Media->information && a_track->Media->information->sampleTable && a_track->Media->information->sampleTable->SampleDescription)\n\t\t\t\t\t\tan_entry = (GF_MPEGVisualSampleEntryBox*)gf_list_get(a_track->Media->information->sampleTable->SampleDescription->child_boxes, 0);\n\n\t\t\t\t\tif (an_entry)\n\t\t\t\t\t\tnalu_merge_ps(mdia->nalu_ps_bs, rewrite_start_codes, nal_unit_size_field, an_entry, is_hevc, &has_vps);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tnalu_merge_ps(mdia->nalu_ps_bs, rewrite_start_codes, nal_unit_size_field, entry, is_hevc, &has_vps);\n\n\n\t\tif (is_hevc) {\n\t\t\t/*little optimization if we are not asked to start codes: copy over the sample*/\n\t\t\tif (!rewrite_start_codes && !entry->lhvc_config && !scal) {\n\t\t\t\tif (! ps_transfered) {\n\t\t\t\t\tnal_type = (sample->data[nal_unit_size_field] & 0x7E) >> 1;\n\t\t\t\t\t//temp fix - if we detect xPS in the beginning of the sample do NOT copy the ps bitstream\n\t\t\t\t\t//this is not correct since we are not sure whether they are the same xPS or not, but it crashes openHEVC ...\n\t\t\t\t\tswitch (nal_type) {\n#ifndef GPAC_DISABLE_HEVC\n\t\t\t\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\t\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\t\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\t\t\t\tbreak;\n#endif\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->in_sample_buffer, sample->dataLength);\n\t\t\t\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\t\t\treturn GF_OK;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tps_transfered = GF_TRUE;\n\t}\n\n\t/*little optimization if we are not asked to rewrite extractors or start codes: copy over the sample*/\n\tif (!scal && !rewrite_start_codes && !rewrite_ps && !force_sei_inspect) {\n\t\tif (! ps_transfered)\n\t\t{\n\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t}\n\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->in_sample_buffer, sample->dataLength);\n\t\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\treturn GF_OK;\n\t}\n\n\tif (!mdia->tmp_nal_copy_buffer) {\n\t\tmdia->tmp_nal_copy_buffer = gf_malloc(sizeof(char) * 4096);\n\t\tmdia->tmp_nal_copy_buffer_alloc = 4096;\n\t}\n\n\n\twhile (gf_bs_available(mdia->nalu_parser)) {\n\t\tnal_size = gf_bs_read_int(mdia->nalu_parser, 8*nal_unit_size_field);\n\t\tif (gf_bs_get_position(mdia->nalu_parser) + nal_size > sample->dataLength) {\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CODING, (\"Sample %u (size %u) rewrite: corrupted NAL Unit (size %u)\\n\", sampleNumber, sample->dataLength, nal_size));\n\t\t\tgoto exit;\n\t\t}\n\t\tif (nal_size > mdia->tmp_nal_copy_buffer_alloc) {\n\t\t\tmdia->tmp_nal_copy_buffer_alloc = nal_size;\n\t\t\tmdia->tmp_nal_copy_buffer = (char*) gf_realloc(mdia->tmp_nal_copy_buffer, sizeof(char)*nal_size);\n\t\t}\n\t\tif (is_hevc) {\n\t\t\tnal_hdr = gf_bs_read_u16(mdia->nalu_parser);\n\t\t\tnal_type = (nal_hdr&0x7E00) >> 9;\n\t\t} else {\n\t\t\tnal_hdr = gf_bs_read_u8(mdia->nalu_parser);\n\t\t\tnal_type = nal_hdr & 0x1F;\n\t\t}\n\n\t\tif (is_hevc) {\n#ifndef GPAC_DISABLE_HEVC\n\t\t\tGF_BitStream *write_to_bs = mdia->nalu_out_bs;\n#endif\n\n\t\t\tif (!ps_transfered) {\n\t\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t\t\tps_transfered = GF_TRUE;\n\t\t\t}\n\n#ifndef GPAC_DISABLE_HEVC\n\t\t\tswitch (nal_type) {\n\t\t\t/*we already wrote AU delim, and we trash aggregators*/\n\t\t\tcase GF_HEVC_NALU_ACCESS_UNIT:\n\t\t\tcase GF_HEVC_NALU_FF_AGGREGATOR:\n\t\t\t\tgf_bs_skip_bytes(mdia->nalu_parser, nal_size-2);\n\t\t\t\tcontinue;\n\n\t\t\t//extractor\n\t\t\tcase GF_HEVC_NALU_FF_EXTRACTOR:\n\t\t\t\te = process_extractor(file, mdia, sampleNumber, sample->DTS, nal_size, nal_hdr, nal_unit_size_field, GF_TRUE, rewrite_ps, rewrite_start_codes, extractor_mode);\n\t\t\t\tif (e) goto exit;\n\t\t\t\tbreak;\n\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_R:\n\t\t\t\tif (temporal_id < (nal_hdr & 0x7))\n\t\t\t\t\ttemporal_id = (nal_hdr & 0x7);\n\t\t\t\t/*rewrite nal*/\n\t\t\t\tgf_bs_read_data(mdia->nalu_parser, mdia->tmp_nal_copy_buffer, nal_size-2);\n\t\t\t\tif (rewrite_start_codes)\n\t\t\t\t\tgf_bs_write_u32(mdia->nalu_out_bs, 1);\n\t\t\t\telse\n\t\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, nal_size, 8*nal_unit_size_field);\n\n\t\t\t\tgf_bs_write_u16(mdia->nalu_out_bs, nal_hdr);\n\t\t\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->tmp_nal_copy_buffer, nal_size-2);\n\t\t\t\tbreak;\n\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_CRA:\n\t\t\t\t//insert xPS before CRA/BLA\n\t\t\t\tif (check_cra_bla && !sample->IsRAP) {\n\t\t\t\t\tsample->IsRAP = sap_type_from_nal_type(nal_type);\n\t\t\t\t\tif (sei_suffix_bs) gf_bs_del(sei_suffix_bs);\n\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n\t\t\t\t\treturn gf_isom_nalu_sample_rewrite(mdia, sample, sampleNumber, entry);\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\t/*rewrite nal*/\n\t\t\t\tif (nal_size<2) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Invalid nal size %d in sample %d\\n\", nal_type, sampleNumber));\n\t\t\t\t\te = GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t\t\tgoto exit;\n\t\t\t\t}\n\n\t\t\t\tgf_bs_read_data(mdia->nalu_parser, mdia->tmp_nal_copy_buffer, nal_size-2);\n\n\t\t\t\tif (nal_type==GF_HEVC_NALU_SEI_SUFFIX) {\n\t\t\t\t\tif (!sei_suffix_bs) sei_suffix_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\t\t\twrite_to_bs = sei_suffix_bs;\n\t\t\t\t}\n\n\t\t\t\tif (rewrite_start_codes)\n\t\t\t\t\tgf_bs_write_u32(write_to_bs, 1);\n\t\t\t\telse\n\t\t\t\t\tgf_bs_write_int(write_to_bs, nal_size, 8*nal_unit_size_field);\n\n\t\t\t\tgf_bs_write_u16(write_to_bs, nal_hdr);\n\t\t\t\tgf_bs_write_data(write_to_bs, mdia->tmp_nal_copy_buffer, nal_size-2);\n\t\t\t}\n#endif\n\n\t\t\t//done with HEVC\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch(nal_type) {\n\t\tcase GF_AVC_NALU_ACCESS_UNIT:\n\t\tcase GF_AVC_NALU_FF_AGGREGATOR:\n\t\t\t/*we already wrote this stuff, and we trash aggregators*/\n\t\t\tgf_bs_skip_bytes(mdia->nalu_parser, nal_size-1);\n\t\t\tcontinue;\n\t\t//extractor\n\t\tcase GF_AVC_NALU_FF_EXTRACTOR:\n\t\t\te = process_extractor(file, mdia, sampleNumber, sample->DTS, nal_size, nal_hdr, nal_unit_size_field, GF_FALSE, rewrite_ps, rewrite_start_codes, extractor_mode);\n\t\t\tif (e) goto exit;\n\t\t\tbreak;\n//\t\t\tcase GF_AVC_NALU_SEI:\n\t\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\tcase GF_AVC_NALU_PIC_PARAM:\n\t\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\t\t// we will rewrite the sps/pps if and only if there is no sps/pps in bistream\n\t\t\tif (!ps_transfered) {\n\t\t\t\tps_transfered = GF_TRUE;\n\t\t\t}\n\t\tdefault:\n\t\t\tif (!ps_transfered) {\n\t\t\t\tgf_bs_transfer(mdia->nalu_out_bs, mdia->nalu_ps_bs, GF_TRUE);\n\t\t\t\tps_transfered = GF_TRUE;\n\t\t\t}\n\t\t\tgf_bs_read_data(mdia->nalu_parser, mdia->tmp_nal_copy_buffer, nal_size-1);\n\t\t\tif (rewrite_start_codes)\n\t\t\t\tgf_bs_write_u32(mdia->nalu_out_bs, 1);\n\t\t\telse\n\t\t\t\tgf_bs_write_int(mdia->nalu_out_bs, nal_size, 8*nal_unit_size_field);\n\n\t\t\tgf_bs_write_u8(mdia->nalu_out_bs, nal_hdr);\n\t\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->tmp_nal_copy_buffer, nal_size-1);\n\t\t}\n\t}\n\n\tif (sei_suffix_bs) {\n\t\tgf_bs_transfer(mdia->nalu_out_bs, sei_suffix_bs, GF_FALSE);\n\t}\n\t/*done*/\n\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n\n\t/*rewrite temporal ID of AU Ddelim NALU (first one)*/\n\tif (rewrite_start_codes && is_hevc && temporal_id) {\n\t\tsample->data[6] = (sample->data[6] & 0xF8) | (temporal_id+1);\n\t}\n\n\nexit:\n\tif (sei_suffix_bs)\n\t\tgf_bs_del(sei_suffix_bs);\n\n\tmdia->in_nalu_rewrite = GF_FALSE;\n\treturn e;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,10 @@\n \tGF_ISOFile *file = mdia->mediaTrack->moov->mov;\n \tGF_TrackReferenceTypeBox *scal = NULL;\n \n+\tif (mdia->in_nalu_rewrite)\n+\t\treturn GF_ISOM_INVALID_FILE;\n+\tmdia->in_nalu_rewrite = GF_TRUE;\n+\n \tTrack_FindRef(mdia->mediaTrack, GF_ISOM_REF_SCAL, &scal);\n \n \trewrite_ps = (mdia->mediaTrack->extractor_mode & GF_ISOM_NALU_EXTRACT_INBAND_PS_FLAG) ? GF_TRUE : GF_FALSE;\n@@ -48,10 +52,14 @@\n \n \t\t\t\t\t\tif (!mdia->extracted_samp) {\n \t\t\t\t\t\t\tmdia->extracted_samp = gf_isom_sample_new();\n-\t\t\t\t\t\t\tif (!mdia->extracted_samp) return GF_OUT_OF_MEM;\n+\t\t\t\t\t\t\tif (!mdia->extracted_samp) {\n+\t\t\t\t\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n+\t\t\t\t\t\t\t\t\treturn GF_OUT_OF_MEM;\n+\t\t\t\t\t\t\t}\n \t\t\t\t\t\t}\n \n \t\t\t\t\t\tbase_samp = gf_isom_get_sample_ex(mdia->mediaTrack->moov->mov, ref_track, sampleNumber + mdia->mediaTrack->sample_count_at_seg_start, &di, mdia->extracted_samp, NULL);\n+\t\t\t\t\t\t//base sample may be null (track split)\n \t\t\t\t\t\tif (base_samp && base_samp->data) {\n \t\t\t\t\t\t\tif (!sample->alloc_size || (sample->alloc_size<sample->dataLength+base_samp->dataLength) ) {\n \t\t\t\t\t\t\t\tsample->data = gf_realloc(sample->data, sample->dataLength+base_samp->dataLength);\n@@ -77,10 +85,14 @@\n \n \t\t\t\tif (!mdia->extracted_samp) {\n \t\t\t\t\tmdia->extracted_samp = gf_isom_sample_new();\n-\t\t\t\t\tif (!mdia->extracted_samp) return GF_OUT_OF_MEM;\n+\t\t\t\t\tif (!mdia->extracted_samp) {\n+\t\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n+\t\t\t\t\t\treturn GF_OUT_OF_MEM;\n+\t\t\t\t\t}\n \t\t\t\t}\n \n \t\t\t\ttile_samp = gf_isom_get_sample_ex(mdia->mediaTrack->moov->mov, ref_track, sampleNumber + mdia->mediaTrack->sample_count_at_seg_start, &di, mdia->extracted_samp, NULL);\n+\t\t\t\t//tile sample may be NULL (removal of tracks, ...)\n \t\t\t\tif (tile_samp  && tile_samp ->data) {\n \t\t\t\t\tif (!sample->alloc_size || (sample->alloc_size<sample->dataLength+tile_samp->dataLength) ) {\n \t\t\t\t\t\tsample->data = gf_realloc(sample->data, sample->dataLength+tile_samp->dataLength);\n@@ -89,7 +101,7 @@\n \t\t\t\t\tmemcpy(sample->data + sample->dataLength, tile_samp->data, tile_samp->dataLength);\n \t\t\t\t\tsample->dataLength += tile_samp->dataLength;\n \t\t\t\t}\n-\t\t\t}\n+ \t\t\t}\n \t\t}\n \t}\n \n@@ -114,15 +126,19 @@\n \tif (extractor_mode != GF_ISOM_NALU_EXTRACT_LAYER_ONLY)\n \t\tinsert_vdrd_code = GF_FALSE;\n \n-\tif (!entry) return GF_BAD_PARAM;\n-\n+\tif (!entry) {\n+\t\tmdia->in_nalu_rewrite = GF_FALSE;\n+\t\treturn GF_BAD_PARAM;\n+\t}\n \t//this is a compatible HEVC, don't insert VDRD, insert NALU delim\n \tif (entry->lhvc_config && entry->hevc_config)\n \t\tinsert_vdrd_code = GF_FALSE;\n \n \tif (extractor_mode == GF_ISOM_NALU_EXTRACT_INSPECT) {\n-\t\tif (!rewrite_ps && !rewrite_start_codes)\n+\t\tif (!rewrite_ps && !rewrite_start_codes) {\n+\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n \t\t\treturn GF_OK;\n+\t\t}\n \t}\n \n \tnal_unit_size_field = 0;\n@@ -141,6 +157,7 @@\n \n \t/*otherwise do nothing*/\n \telse if (!rewrite_ps && !rewrite_start_codes && !scal && !force_sei_inspect) {\n+\t\tmdia->in_nalu_rewrite = GF_FALSE;\n \t\treturn GF_OK;\n \t}\n \n@@ -157,8 +174,10 @@\n \t\t}\n \t}\n \n-\tif (!nal_unit_size_field) return GF_ISOM_INVALID_FILE;\n-\n+\tif (!nal_unit_size_field) {\n+\t\tmdia->in_nalu_rewrite = GF_FALSE;\n+\t\treturn GF_ISOM_INVALID_FILE;\n+\t}\n \t//setup PS rewriter\n \tif (!mdia->nalu_ps_bs)\n \t\tmdia->nalu_ps_bs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n@@ -173,10 +192,16 @@\n \n \tif (!mdia->nalu_parser) {\n \t\tmdia->nalu_parser = gf_bs_new(mdia->in_sample_buffer, sample->dataLength, GF_BITSTREAM_READ);\n-\t\tif (!mdia->nalu_parser && sample->data) return GF_ISOM_INVALID_FILE;\n+\t\tif (!mdia->nalu_parser && sample->data) {\n+\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n+\t\t\treturn GF_ISOM_INVALID_FILE;\n+\t\t}\n \t} else {\n \t\te = gf_bs_reassign_buffer(mdia->nalu_parser, mdia->in_sample_buffer, sample->dataLength);\n-\t\tif (e) return e;\n+\t\tif (e) {\n+\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n+\t\t\treturn e;\n+\t\t}\n \t}\n \t//setup output\n \tif (!mdia->nalu_out_bs) {\n@@ -264,7 +289,7 @@\n \t\t\t\t}\n \t\t\t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->in_sample_buffer, sample->dataLength);\n \t\t\t\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n-\n+\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n \t\t\t\treturn GF_OK;\n \t\t\t}\n \t\t}\n@@ -280,6 +305,7 @@\n \t\t}\n \t\tgf_bs_write_data(mdia->nalu_out_bs, mdia->in_sample_buffer, sample->dataLength);\n \t\tgf_bs_get_content_no_truncate(mdia->nalu_out_bs, &sample->data, &sample->dataLength, &sample->alloc_size);\n+\t\tmdia->in_nalu_rewrite = GF_FALSE;\n \t\treturn GF_OK;\n \t}\n \n@@ -358,6 +384,7 @@\n \t\t\t\tif (check_cra_bla && !sample->IsRAP) {\n \t\t\t\t\tsample->IsRAP = sap_type_from_nal_type(nal_type);\n \t\t\t\t\tif (sei_suffix_bs) gf_bs_del(sei_suffix_bs);\n+\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;\n \t\t\t\t\treturn gf_isom_nalu_sample_rewrite(mdia, sample, sampleNumber, entry);\n \t\t\t\t}\n \t\t\tdefault:\n@@ -441,5 +468,6 @@\n \tif (sei_suffix_bs)\n \t\tgf_bs_del(sei_suffix_bs);\n \n+\tmdia->in_nalu_rewrite = GF_FALSE;\n \treturn e;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\t\t\tif (!mdia->extracted_samp) return GF_OUT_OF_MEM;",
                "\t\t\t\t\tif (!mdia->extracted_samp) return GF_OUT_OF_MEM;",
                "\t\t\t}",
                "\tif (!entry) return GF_BAD_PARAM;",
                "",
                "\t\tif (!rewrite_ps && !rewrite_start_codes)",
                "\tif (!nal_unit_size_field) return GF_ISOM_INVALID_FILE;",
                "",
                "\t\tif (!mdia->nalu_parser && sample->data) return GF_ISOM_INVALID_FILE;",
                "\t\tif (e) return e;",
                ""
            ],
            "added_lines": [
                "\tif (mdia->in_nalu_rewrite)",
                "\t\treturn GF_ISOM_INVALID_FILE;",
                "\tmdia->in_nalu_rewrite = GF_TRUE;",
                "",
                "\t\t\t\t\t\t\tif (!mdia->extracted_samp) {",
                "\t\t\t\t\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\t\t\t\t\t\t\t\treturn GF_OUT_OF_MEM;",
                "\t\t\t\t\t\t\t}",
                "\t\t\t\t\t\t//base sample may be null (track split)",
                "\t\t\t\t\tif (!mdia->extracted_samp) {",
                "\t\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\t\t\t\t\treturn GF_OUT_OF_MEM;",
                "\t\t\t\t\t}",
                "\t\t\t\t//tile sample may be NULL (removal of tracks, ...)",
                " \t\t\t}",
                "\tif (!entry) {",
                "\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\treturn GF_BAD_PARAM;",
                "\t}",
                "\t\tif (!rewrite_ps && !rewrite_start_codes) {",
                "\t\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\t}",
                "\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\tif (!nal_unit_size_field) {",
                "\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\treturn GF_ISOM_INVALID_FILE;",
                "\t}",
                "\t\tif (!mdia->nalu_parser && sample->data) {",
                "\t\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\t\treturn GF_ISOM_INVALID_FILE;",
                "\t\t}",
                "\t\tif (e) {",
                "\t\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\t\treturn e;",
                "\t\t}",
                "\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\t\t\t\t\tmdia->in_nalu_rewrite = GF_FALSE;",
                "\tmdia->in_nalu_rewrite = GF_FALSE;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-47662",
        "func_name": "gpac/gf_media_split_hevc_tiles",
        "description": "GPAC MP4Box 2.1-DEV-rev649-ga8f438d20 has a segment fault (/stack overflow) due to infinite recursion in Media_GetSample isomedia/media.c:662",
        "git_url": "https://github.com/gpac/gpac/commit/080a62728ccd251a7f20eaac3fda21b0716e3c9b",
        "commit_title": "fixed #2359",
        "commit_text": "",
        "func_before": "GF_EXPORT\nGF_Err gf_media_split_hevc_tiles(GF_ISOFile *file, u32 signal_mode)\n{\n#if defined(GPAC_DISABLE_HEVC) || defined(GPAC_DISABLE_AV_PARSERS)\n\treturn GF_NOT_SUPPORTED;\n#else\n\tu32 i, j, cur_tile, count, stype, track, nb_tiles, di, nalu_size_length, tx, ty, tw, th;\n\ts32 pps_idx=-1, sps_idx=-1, ret;\n\tGF_Err e = GF_OK;\n\tHEVCState hevc;\n\tHEVCTileImport *tiles;\n\tGF_HEVCConfig *hvcc;\n\tBool filter_disabled=GF_TRUE;\n\n\ttrack = 0;\n\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\tstype = gf_isom_get_media_subtype(file, i+1, 1);\n\t\tswitch (stype) {\n\t\tcase GF_ISOM_SUBTYPE_HVC1:\n\t\tcase GF_ISOM_SUBTYPE_HEV1:\n\t\tcase GF_ISOM_SUBTYPE_HVC2:\n\t\tcase GF_ISOM_SUBTYPE_HEV2:\n\n\t\t\tif (track) return GF_NOT_SUPPORTED;\n\t\t\ttrack = i+1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!track) return GF_NOT_SUPPORTED;\n\n\thvcc = gf_isom_hevc_config_get(file, track, 1);\n\tnalu_size_length = hvcc->nal_unit_size;\n\n\tmemset(&hevc, 0, sizeof(HEVCState));\n\n\tcount = gf_list_count(hvcc->param_array);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParamArray *ar = gf_list_get(hvcc->param_array, i);\n\t\tfor (j=0; j < gf_list_count(ar->nalus); j++) {\n\t\t\tGF_NALUFFParam *sl = gf_list_get(ar->nalus, j);\n\t\t\tif (!sl) continue;\n\t\t\tswitch (ar->type) {\n\t\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\t\tpps_idx = gf_hevc_read_pps(sl->data, sl->size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\t\tsps_idx = gf_hevc_read_sps(sl->data, sl->size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\t\tgf_hevc_read_vps(sl->data, sl->size, &hevc);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tgf_isom_hevc_set_tile_config(file, track, 1, hvcc, GF_TRUE);\n\tgf_odf_hevc_cfg_del(hvcc);\n\n\t//if params sets are inband, get first sps/pps\n\ti=0;\n\twhile ((pps_idx==-1) || (sps_idx==-1)) {\n\t\tGF_ISOSample *sample = gf_isom_get_sample(file, track, i+1, &di);\n\t\tchar *data = sample->data;\n\t\tu32 size = sample->dataLength;\n\n\t\twhile (size) {\n\t\t\tu8 temporal_id, layer_id;\n\t\t\tu8 nal_type = 0;\n\t\t\tu32 nalu_size = 0;\n\n\t\t\tfor (j=0; j<nalu_size_length; j++) {\n\t\t\t\tnalu_size = (nalu_size<<8) + data[j];\n\t\t\t}\n\t\t\tgf_hevc_parse_nalu(data + nalu_size_length, nalu_size, &hevc, &nal_type, &temporal_id, &layer_id);\n\n\t\t\tswitch (nal_type) {\n\t\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\t\tpps_idx = gf_hevc_read_pps((char *) data+nalu_size_length, nalu_size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\t\tsps_idx = gf_hevc_read_sps((char *) data+nalu_size_length, nalu_size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\t\tgf_hevc_read_vps((char *) data+nalu_size_length, nalu_size, &hevc);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdata += nalu_size + nalu_size_length;\n\t\t\tsize -= nalu_size + nalu_size_length;\n\t\t}\n\t\tgf_isom_sample_del(&sample);\n\t}\n\n\tif (pps_idx==-1) return GF_BAD_PARAM;\n\tif (sps_idx==-1) return GF_BAD_PARAM;\n\n\tif (hevc.pps[pps_idx].loop_filter_across_tiles_enabled_flag)\n\t\tfilter_disabled=GF_FALSE;\n\n\tif (! hevc.pps[pps_idx].tiles_enabled_flag) {\n\t\thevc_add_trif(file, track, gf_isom_get_track_id(file, track), GF_TRUE, 1, filter_disabled, 0, 0, hevc.sps[pps_idx].width, hevc.sps[pps_idx].height, GF_TRUE);\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_MEDIA, (\"[HEVC Tiles] Tiles not enabled, signal only single tile full picture\\n\"));\n\t\treturn GF_OK;\n\t}\n\n\tnb_tiles = hevc.pps[pps_idx].num_tile_columns * hevc.pps[pps_idx].num_tile_rows;\n\ttiles = gf_malloc(sizeof(HEVCTileImport) * nb_tiles);\n\tif (!tiles) return GF_OUT_OF_MEM;\n\tmemset(tiles, 0, sizeof(HEVCTileImport) * nb_tiles);\n\n\tfor (i=0; i<nb_tiles; i++) {\n\t\tif (! signal_mode) {\n\t\t\t//first clone tracks\n\t\t\te = gf_isom_clone_track(file, track, file, 0, &tiles[i].track );\n\t\t\tif (e) goto err_exit;\n\t\t\ttiles[i].track_id = gf_isom_get_track_id(file, tiles[i].track);\n\t\t\tgf_isom_hevc_set_tile_config(file, tiles[i].track, 1, NULL, GF_FALSE);\n\n\t\t\t// setup track references from tile track to base\n\t\t\tgf_isom_set_track_reference(file, tiles[i].track, GF_ISOM_REF_TBAS, gf_isom_get_track_id(file, track) );\n\t\t} else {\n\t\t\ttiles[i].track_id = gf_isom_get_track_id(file, track) + i+1;\n\t\t}\n\t\ttiles[i].all_intra = GF_TRUE;\n\t}\n\n\tcount = gf_isom_get_sample_count(file, track);\n\tfor (i=0; i<count; i++) {\n\t\tu8 *data;\n\t\tu32 size, nb_nalus=0, nb_nal_entries=0, last_tile_group=(u32) -1;\n\t\tGF_BitStream *bs=NULL;\n\t\tGF_ISOSample *sample = gf_isom_get_sample(file, track, i+1, &di);\n\n\t\tdata = (u8 *) sample->data;\n\t\tsize = sample->dataLength;\n\t\tif (!signal_mode) {\n\t\t\tbs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\tsample->data = NULL;\n\t\t\tsample->dataLength = 0;\n\n\t\t\tfor (j=0; j<nb_tiles; j++) {\n\t\t\t\ttiles[j].data_offset = 0;\n\t\t\t\ttiles[j].sample_data = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\t}\n\t\t} else {\n\t\t\tfor (j=0; j<nb_tiles; j++) {\n\t\t\t\ttiles[j].nb_nalus_in_sample = 0;\n\t\t\t}\n\t\t\tbs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\t//write start of nalm group\n\t\t\tgf_bs_write_int(bs, 0, 6);//reserved\n\t\t\tgf_bs_write_int(bs, 0, 1);//large_size\n\t\t\tgf_bs_write_int(bs, (signal_mode==2) ? 1 : 0, 1);//rle\n\t\t\tgf_bs_write_u8(bs, 0);//entry_count - will be set at the end\n\t\t}\n\n\n\t\tsample->data = (char *) data;\n\n\t\twhile (size) {\n\t\t\tu8 temporal_id, layer_id;\n\t\t\tu8 nal_type = 0;\n\t\t\tu32 nalu_size = 0;\n\t\t\tfor (j=0; j<nalu_size_length; j++) {\n\t\t\t\tnalu_size = (nalu_size<<8) + data[j];\n\t\t\t}\n\t\t\tret = gf_hevc_parse_nalu(data + nalu_size_length, nalu_size, &hevc, &nal_type, &temporal_id, &layer_id);\n\n\t\t\t//error parsing NAL, set nal to fallback to regular import\n\t\t\tif (ret<0) nal_type = GF_HEVC_NALU_VID_PARAM;\n\n\t\t\tswitch (nal_type) {\n\t\t\tcase GF_HEVC_NALU_SLICE_TRAIL_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_TRAIL_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_CRA:\n\t\t\tcase GF_HEVC_NALU_SLICE_RADL_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_RADL_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_RASL_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_RASL_N:\n\t\t\t\ttx = ty = tw = th = 0;\n\t\t\t\tcur_tile = hevc_get_tile_id(&hevc, &tx, &ty, &tw, &th);\n\t\t\t\tif (cur_tile>=nb_tiles) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[HEVC Tiles] Tile index %d is greater than number of tiles %d in PPS\\n\", cur_tile, nb_tiles));\n\t\t\t\t\te = GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t\t}\n\t\t\t\tif (e)\n\t\t\t\t\tgoto err_exit;\n\n\t\t\t\ttiles[cur_tile].tx = tx;\n\t\t\t\ttiles[cur_tile].ty = ty;\n\t\t\t\ttiles[cur_tile].tw = tw;\n\t\t\t\ttiles[cur_tile].th = th;\n\t\t\t\tif (hevc.s_info.slice_type != GF_HEVC_SLICE_TYPE_I) {\n\t\t\t\t\ttiles[cur_tile].all_intra = 0;\n\t\t\t\t}\n\n\t\t\t\tif (signal_mode) {\n\t\t\t\t\tnb_nalus++;\n\t\t\t\t\ttiles[cur_tile].nb_nalus_in_sample++;\n\t\t\t\t\tif (signal_mode==1) {\n\t\t\t\t\t\tgf_bs_write_u16(bs, tiles[cur_tile].track_id);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t} else if (last_tile_group != tiles[cur_tile].track_id) {\n\t\t\t\t\t\tlast_tile_group = tiles[cur_tile].track_id;\n\t\t\t\t\t\tgf_bs_write_u8(bs, nb_nalus);\n\t\t\t\t\t\tgf_bs_write_u16(bs, tiles[cur_tile].track_id);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tgf_bs_write_data(tiles[cur_tile].sample_data, (char *) data, nalu_size + nalu_size_length);\n\n\t\t\t\t\tif (! gf_isom_has_track_reference(file, track, GF_ISOM_REF_SABT, tiles[cur_tile].track_id)) {\n\t\t\t\t\t\tgf_isom_set_track_reference(file, track, GF_ISOM_REF_SABT, tiles[cur_tile].track_id);\n\t\t\t\t\t}\n\t\t\t\t\ttiles[cur_tile].data_offset += nalu_size + nalu_size_length;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif (! signal_mode) {\n\t\t\t\t\tgf_bs_write_data(bs, (char *) data, nalu_size + nalu_size_length);\n\t\t\t\t} else {\n\t\t\t\t\tnb_nalus++;\n\t\t\t\t\tif (signal_mode==1) {\n\t\t\t\t\t\tgf_bs_write_u16(bs, 0);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t} else if (last_tile_group != 0) {\n\t\t\t\t\t\tlast_tile_group = 0;\n\t\t\t\t\t\tgf_bs_write_u8(bs, nb_nalus);\n\t\t\t\t\t\tgf_bs_write_u16(bs, 0);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdata += nalu_size + nalu_size_length;\n\t\t\tsize -= nalu_size + nalu_size_length;\n\t\t}\n\n\t\tif (! signal_mode) {\n\t\t\tgf_free(sample->data);\n\t\t\tgf_bs_get_content(bs, &sample->data, &sample->dataLength);\n\t\t\tgf_bs_del(bs);\n\n\t\t\te = gf_isom_update_sample(file, track, i+1, sample, 1);\n\t\t\tif (e) goto err_exit;\n\n\t\t\tgf_free(sample->data);\n\t\t\tsample->data = NULL;\n\n\t\t\tfor (j=0; j<nb_tiles; j++) {\n\t\t\t\tsample->dataLength = 0;\n\t\t\t\tgf_bs_get_content(tiles[j].sample_data, &sample->data, &sample->dataLength);\n\t\t\t\tif (!sample->data)\n\t\t\t\t\tcontinue;\n\n\t\t\t\te = gf_isom_add_sample(file, tiles[j].track, 1, sample);\n\t\t\t\tif (e) goto err_exit;\n\t\t\t\ttiles[j].sample_count ++;\n\n\t\t\t\tgf_bs_del(tiles[j].sample_data);\n\t\t\t\ttiles[j].sample_data = NULL;\n\t\t\t\tgf_free(sample->data);\n\t\t\t\tsample->data = NULL;\n\n\t\t\t\te = gf_isom_copy_sample_info(file, tiles[j].track, file, track, i+1);\n\t\t\t\tif (e) goto err_exit;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 sdesc;\n\t\t\tdata=NULL;\n\t\t\tsize=0;\n\t\t\tgf_bs_get_content(bs, &data, &size);\n\t\t\tgf_bs_del(bs);\n\t\t\tdata[1] = nb_nal_entries;\n\n\t\t\te = gf_isom_add_sample_group_info(file, track, GF_ISOM_SAMPLE_GROUP_NALM, data, size, 0, &sdesc);\n\t\t\tif (e) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[ISOBMF] Error defining NALM group description entry\\n\" ));\n\t\t\t} else {\n\t\t\t\te = gf_isom_add_sample_info(file, track, i+1, GF_ISOM_SAMPLE_GROUP_NALM, sdesc, GF_ISOM_SAMPLE_GROUP_TRIF);\n\t\t\t\tif (e) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[ISOBMF] Error associating NALM group description to sample\\n\" ));\n\t\t\t\t}\n\t\t\t}\n\t\t\tgf_free(data);\n\t\t\tif (e) goto err_exit;\n\t\t}\n\n\t\tgf_isom_sample_del(&sample);\n\n\t}\n\n\n\tfor (i=0; i<nb_tiles; i++) {\n\t\tu32 width, height;\n\t\ts32 translation_x, translation_y;\n\t\ts16 layer;\n\n\t\tif (! signal_mode) {\n\t\t\ttiles[i].track = gf_isom_get_track_by_id(file, tiles[i].track_id);\n\t\t\tif (!tiles[i].sample_count) {\n\t\t\t\tgf_isom_remove_track(file, tiles[i].track);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\thevc_add_trif(file, tiles[i].track, tiles[i].track_id, GF_FALSE, (tiles[i].all_intra) ? 2 : 1, filter_disabled, tiles[i].tx, tiles[i].ty, tiles[i].tw, tiles[i].th, GF_TRUE);\n\t\t\tgf_isom_set_visual_info(file, tiles[i].track, 1, tiles[i].tw, tiles[i].th);\n\n\t\t\tgf_isom_get_track_layout_info(file, track, &width, &height, &translation_x, &translation_y, &layer);\n\t\t\tgf_isom_set_track_layout_info(file, tiles[i].track, width<<16, height<<16, translation_x, translation_y, layer);\n\t\t} else {\n\t\t\thevc_add_trif(file, track, tiles[i].track_id, GF_FALSE, (tiles[i].all_intra) ? 2 : 1, filter_disabled, tiles[i].tx, tiles[i].ty, tiles[i].tw, tiles[i].th, GF_FALSE);\n\t\t}\n\n\t}\n\n\nerr_exit:\n\tgf_free(tiles);\n\tif (e) {\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[ISOBMF] Could not split HEVC tiles into tracks: %s\\n\", gf_error_to_string(e) ));\n\t}\n\treturn e;\n#endif\n}",
        "func": "GF_EXPORT\nGF_Err gf_media_split_hevc_tiles(GF_ISOFile *file, u32 signal_mode)\n{\n#if defined(GPAC_DISABLE_HEVC) || defined(GPAC_DISABLE_AV_PARSERS)\n\treturn GF_NOT_SUPPORTED;\n#else\n\tu32 i, j, cur_tile, count, stype, track, nb_tiles, di, nalu_size_length, tx, ty, tw, th;\n\ts32 pps_idx=-1, sps_idx=-1, ret;\n\tGF_Err e = GF_OK;\n\tHEVCState hevc;\n\tHEVCTileImport *tiles;\n\tGF_HEVCConfig *hvcc;\n\tBool filter_disabled=GF_TRUE;\n\n\ttrack = 0;\n\tfor (i=0; i<gf_isom_get_track_count(file); i++) {\n\t\tstype = gf_isom_get_media_subtype(file, i+1, 1);\n\t\tswitch (stype) {\n\t\tcase GF_ISOM_SUBTYPE_HVC1:\n\t\tcase GF_ISOM_SUBTYPE_HEV1:\n\t\tcase GF_ISOM_SUBTYPE_HVC2:\n\t\tcase GF_ISOM_SUBTYPE_HEV2:\n\n\t\t\tif (track) return GF_NOT_SUPPORTED;\n\t\t\ttrack = i+1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!track) return GF_NOT_SUPPORTED;\n\n\thvcc = gf_isom_hevc_config_get(file, track, 1);\n\tnalu_size_length = hvcc->nal_unit_size;\n\n\tmemset(&hevc, 0, sizeof(HEVCState));\n\n\tcount = gf_list_count(hvcc->param_array);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParamArray *ar = gf_list_get(hvcc->param_array, i);\n\t\tfor (j=0; j < gf_list_count(ar->nalus); j++) {\n\t\t\tGF_NALUFFParam *sl = gf_list_get(ar->nalus, j);\n\t\t\tif (!sl) continue;\n\t\t\tswitch (ar->type) {\n\t\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\t\tpps_idx = gf_hevc_read_pps(sl->data, sl->size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\t\tsps_idx = gf_hevc_read_sps(sl->data, sl->size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\t\tgf_hevc_read_vps(sl->data, sl->size, &hevc);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tgf_isom_hevc_set_tile_config(file, track, 1, hvcc, GF_TRUE);\n\tgf_odf_hevc_cfg_del(hvcc);\n\n\t//if params sets are inband, get first sps/pps\n\ti=0;\n\twhile ((pps_idx==-1) || (sps_idx==-1)) {\n\t\tGF_ISOSample *sample = gf_isom_get_sample(file, track, i+1, &di);\n\t\tchar *data = sample->data;\n\t\tu32 size = sample->dataLength;\n\n\t\twhile (size) {\n\t\t\tu8 temporal_id, layer_id;\n\t\t\tu8 nal_type = 0;\n\t\t\tu32 nalu_size = 0;\n\n\t\t\tfor (j=0; j<nalu_size_length; j++) {\n\t\t\t\tnalu_size = (nalu_size<<8) + data[j];\n\t\t\t}\n\t\t\tgf_hevc_parse_nalu(data + nalu_size_length, nalu_size, &hevc, &nal_type, &temporal_id, &layer_id);\n\n\t\t\tswitch (nal_type) {\n\t\t\tcase GF_HEVC_NALU_PIC_PARAM:\n\t\t\t\tpps_idx = gf_hevc_read_pps((char *) data+nalu_size_length, nalu_size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_SEQ_PARAM:\n\t\t\t\tsps_idx = gf_hevc_read_sps((char *) data+nalu_size_length, nalu_size, &hevc);\n\t\t\t\tbreak;\n\t\t\tcase GF_HEVC_NALU_VID_PARAM:\n\t\t\t\tgf_hevc_read_vps((char *) data+nalu_size_length, nalu_size, &hevc);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdata += nalu_size + nalu_size_length;\n\t\t\tsize -= nalu_size + nalu_size_length;\n\t\t}\n\t\tgf_isom_sample_del(&sample);\n\t}\n\n\tif (pps_idx==-1) return GF_BAD_PARAM;\n\tif (sps_idx==-1) return GF_BAD_PARAM;\n\n\tif (hevc.pps[pps_idx].loop_filter_across_tiles_enabled_flag)\n\t\tfilter_disabled=GF_FALSE;\n\n\tif (! hevc.pps[pps_idx].tiles_enabled_flag) {\n\t\thevc_add_trif(file, track, gf_isom_get_track_id(file, track), GF_TRUE, 1, filter_disabled, 0, 0, hevc.sps[pps_idx].width, hevc.sps[pps_idx].height, GF_TRUE);\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_MEDIA, (\"[HEVC Tiles] Tiles not enabled, signal only single tile full picture\\n\"));\n\t\treturn GF_OK;\n\t}\n\n\tnb_tiles = hevc.pps[pps_idx].num_tile_columns * hevc.pps[pps_idx].num_tile_rows;\n\ttiles = gf_malloc(sizeof(HEVCTileImport) * nb_tiles);\n\tif (!tiles) return GF_OUT_OF_MEM;\n\tmemset(tiles, 0, sizeof(HEVCTileImport) * nb_tiles);\n\n\tfor (i=0; i<nb_tiles; i++) {\n\t\tif (! signal_mode) {\n\t\t\t//first clone tracks\n\t\t\te = gf_isom_clone_track(file, track, file, 0, &tiles[i].track );\n\t\t\tif (e) goto err_exit;\n\t\t\ttiles[i].track_id = gf_isom_get_track_id(file, tiles[i].track);\n\t\t\tgf_isom_hevc_set_tile_config(file, tiles[i].track, 1, NULL, GF_FALSE);\n\n\t\t\t// setup track references from tile track to base\n\t\t\tgf_isom_set_track_reference(file, tiles[i].track, GF_ISOM_REF_TBAS, gf_isom_get_track_id(file, track) );\n\t\t} else {\n\t\t\ttiles[i].track_id = gf_isom_get_track_id(file, track) + i+1;\n\t\t}\n\t\ttiles[i].all_intra = GF_TRUE;\n\t}\n\n\tcount = gf_isom_get_sample_count(file, track);\n\tfor (i=0; i<count; i++) {\n\t\tu8 *data;\n\t\tu32 size, nb_nalus=0, nb_nal_entries=0, last_tile_group=(u32) -1;\n\t\tGF_BitStream *bs=NULL;\n\t\tGF_ISOSample *sample = gf_isom_get_sample(file, track, i+1, &di);\n\t\tif (!sample) {\n\t\t\te = gf_isom_last_error(file);\n\t\t\tgoto err_exit;\n\t\t}\n\n\t\tdata = (u8 *) sample->data;\n\t\tsize = sample->dataLength;\n\t\tif (!signal_mode) {\n\t\t\tbs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\tsample->data = NULL;\n\t\t\tsample->dataLength = 0;\n\n\t\t\tfor (j=0; j<nb_tiles; j++) {\n\t\t\t\ttiles[j].data_offset = 0;\n\t\t\t\ttiles[j].sample_data = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\t}\n\t\t} else {\n\t\t\tfor (j=0; j<nb_tiles; j++) {\n\t\t\t\ttiles[j].nb_nalus_in_sample = 0;\n\t\t\t}\n\t\t\tbs = gf_bs_new(NULL, 0, GF_BITSTREAM_WRITE);\n\t\t\t//write start of nalm group\n\t\t\tgf_bs_write_int(bs, 0, 6);//reserved\n\t\t\tgf_bs_write_int(bs, 0, 1);//large_size\n\t\t\tgf_bs_write_int(bs, (signal_mode==2) ? 1 : 0, 1);//rle\n\t\t\tgf_bs_write_u8(bs, 0);//entry_count - will be set at the end\n\t\t}\n\n\n\t\tsample->data = (char *) data;\n\n\t\twhile (size) {\n\t\t\tu8 temporal_id, layer_id;\n\t\t\tu8 nal_type = 0;\n\t\t\tu32 nalu_size = 0;\n\t\t\tfor (j=0; j<nalu_size_length; j++) {\n\t\t\t\tnalu_size = (nalu_size<<8) + data[j];\n\t\t\t}\n\t\t\tret = gf_hevc_parse_nalu(data + nalu_size_length, nalu_size, &hevc, &nal_type, &temporal_id, &layer_id);\n\n\t\t\t//error parsing NAL, set nal to fallback to regular import\n\t\t\tif (ret<0) nal_type = GF_HEVC_NALU_VID_PARAM;\n\n\t\t\tswitch (nal_type) {\n\t\t\tcase GF_HEVC_NALU_SLICE_TRAIL_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_TRAIL_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_TSA_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_STSA_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_BLA_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_W_DLP:\n\t\t\tcase GF_HEVC_NALU_SLICE_IDR_N_LP:\n\t\t\tcase GF_HEVC_NALU_SLICE_CRA:\n\t\t\tcase GF_HEVC_NALU_SLICE_RADL_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_RADL_N:\n\t\t\tcase GF_HEVC_NALU_SLICE_RASL_R:\n\t\t\tcase GF_HEVC_NALU_SLICE_RASL_N:\n\t\t\t\ttx = ty = tw = th = 0;\n\t\t\t\tcur_tile = hevc_get_tile_id(&hevc, &tx, &ty, &tw, &th);\n\t\t\t\tif (cur_tile>=nb_tiles) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[HEVC Tiles] Tile index %d is greater than number of tiles %d in PPS\\n\", cur_tile, nb_tiles));\n\t\t\t\t\te = GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t\t}\n\t\t\t\tif (e)\n\t\t\t\t\tgoto err_exit;\n\n\t\t\t\ttiles[cur_tile].tx = tx;\n\t\t\t\ttiles[cur_tile].ty = ty;\n\t\t\t\ttiles[cur_tile].tw = tw;\n\t\t\t\ttiles[cur_tile].th = th;\n\t\t\t\tif (hevc.s_info.slice_type != GF_HEVC_SLICE_TYPE_I) {\n\t\t\t\t\ttiles[cur_tile].all_intra = 0;\n\t\t\t\t}\n\n\t\t\t\tif (signal_mode) {\n\t\t\t\t\tnb_nalus++;\n\t\t\t\t\ttiles[cur_tile].nb_nalus_in_sample++;\n\t\t\t\t\tif (signal_mode==1) {\n\t\t\t\t\t\tgf_bs_write_u16(bs, tiles[cur_tile].track_id);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t} else if (last_tile_group != tiles[cur_tile].track_id) {\n\t\t\t\t\t\tlast_tile_group = tiles[cur_tile].track_id;\n\t\t\t\t\t\tgf_bs_write_u8(bs, nb_nalus);\n\t\t\t\t\t\tgf_bs_write_u16(bs, tiles[cur_tile].track_id);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tgf_bs_write_data(tiles[cur_tile].sample_data, (char *) data, nalu_size + nalu_size_length);\n\n\t\t\t\t\tif (! gf_isom_has_track_reference(file, track, GF_ISOM_REF_SABT, tiles[cur_tile].track_id)) {\n\t\t\t\t\t\tgf_isom_set_track_reference(file, track, GF_ISOM_REF_SABT, tiles[cur_tile].track_id);\n\t\t\t\t\t}\n\t\t\t\t\ttiles[cur_tile].data_offset += nalu_size + nalu_size_length;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tif (! signal_mode) {\n\t\t\t\t\tgf_bs_write_data(bs, (char *) data, nalu_size + nalu_size_length);\n\t\t\t\t} else {\n\t\t\t\t\tnb_nalus++;\n\t\t\t\t\tif (signal_mode==1) {\n\t\t\t\t\t\tgf_bs_write_u16(bs, 0);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t} else if (last_tile_group != 0) {\n\t\t\t\t\t\tlast_tile_group = 0;\n\t\t\t\t\t\tgf_bs_write_u8(bs, nb_nalus);\n\t\t\t\t\t\tgf_bs_write_u16(bs, 0);\n\t\t\t\t\t\tnb_nal_entries++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdata += nalu_size + nalu_size_length;\n\t\t\tsize -= nalu_size + nalu_size_length;\n\t\t}\n\n\t\tif (! signal_mode) {\n\t\t\tgf_free(sample->data);\n\t\t\tgf_bs_get_content(bs, &sample->data, &sample->dataLength);\n\t\t\tgf_bs_del(bs);\n\n\t\t\te = gf_isom_update_sample(file, track, i+1, sample, 1);\n\t\t\tif (e) goto err_exit;\n\n\t\t\tgf_free(sample->data);\n\t\t\tsample->data = NULL;\n\n\t\t\tfor (j=0; j<nb_tiles; j++) {\n\t\t\t\tsample->dataLength = 0;\n\t\t\t\tgf_bs_get_content(tiles[j].sample_data, &sample->data, &sample->dataLength);\n\t\t\t\tif (!sample->data)\n\t\t\t\t\tcontinue;\n\n\t\t\t\te = gf_isom_add_sample(file, tiles[j].track, 1, sample);\n\t\t\t\tif (e) goto err_exit;\n\t\t\t\ttiles[j].sample_count ++;\n\n\t\t\t\tgf_bs_del(tiles[j].sample_data);\n\t\t\t\ttiles[j].sample_data = NULL;\n\t\t\t\tgf_free(sample->data);\n\t\t\t\tsample->data = NULL;\n\n\t\t\t\te = gf_isom_copy_sample_info(file, tiles[j].track, file, track, i+1);\n\t\t\t\tif (e) goto err_exit;\n\t\t\t}\n\t\t} else {\n\t\t\tu32 sdesc;\n\t\t\tdata=NULL;\n\t\t\tsize=0;\n\t\t\tgf_bs_get_content(bs, &data, &size);\n\t\t\tgf_bs_del(bs);\n\t\t\tdata[1] = nb_nal_entries;\n\n\t\t\te = gf_isom_add_sample_group_info(file, track, GF_ISOM_SAMPLE_GROUP_NALM, data, size, 0, &sdesc);\n\t\t\tif (e) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[ISOBMF] Error defining NALM group description entry\\n\" ));\n\t\t\t} else {\n\t\t\t\te = gf_isom_add_sample_info(file, track, i+1, GF_ISOM_SAMPLE_GROUP_NALM, sdesc, GF_ISOM_SAMPLE_GROUP_TRIF);\n\t\t\t\tif (e) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[ISOBMF] Error associating NALM group description to sample\\n\" ));\n\t\t\t\t}\n\t\t\t}\n\t\t\tgf_free(data);\n\t\t\tif (e) goto err_exit;\n\t\t}\n\n\t\tgf_isom_sample_del(&sample);\n\n\t}\n\n\n\tfor (i=0; i<nb_tiles; i++) {\n\t\tu32 width, height;\n\t\ts32 translation_x, translation_y;\n\t\ts16 layer;\n\n\t\tif (! signal_mode) {\n\t\t\ttiles[i].track = gf_isom_get_track_by_id(file, tiles[i].track_id);\n\t\t\tif (!tiles[i].sample_count) {\n\t\t\t\tgf_isom_remove_track(file, tiles[i].track);\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\thevc_add_trif(file, tiles[i].track, tiles[i].track_id, GF_FALSE, (tiles[i].all_intra) ? 2 : 1, filter_disabled, tiles[i].tx, tiles[i].ty, tiles[i].tw, tiles[i].th, GF_TRUE);\n\t\t\tgf_isom_set_visual_info(file, tiles[i].track, 1, tiles[i].tw, tiles[i].th);\n\n\t\t\tgf_isom_get_track_layout_info(file, track, &width, &height, &translation_x, &translation_y, &layer);\n\t\t\tgf_isom_set_track_layout_info(file, tiles[i].track, width<<16, height<<16, translation_x, translation_y, layer);\n\t\t} else {\n\t\t\thevc_add_trif(file, track, tiles[i].track_id, GF_FALSE, (tiles[i].all_intra) ? 2 : 1, filter_disabled, tiles[i].tx, tiles[i].ty, tiles[i].tw, tiles[i].th, GF_FALSE);\n\t\t}\n\n\t}\n\n\nerr_exit:\n\tgf_free(tiles);\n\tif (e) {\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[ISOBMF] Could not split HEVC tiles into tracks: %s\\n\", gf_error_to_string(e) ));\n\t}\n\treturn e;\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -130,6 +130,10 @@\n \t\tu32 size, nb_nalus=0, nb_nal_entries=0, last_tile_group=(u32) -1;\n \t\tGF_BitStream *bs=NULL;\n \t\tGF_ISOSample *sample = gf_isom_get_sample(file, track, i+1, &di);\n+\t\tif (!sample) {\n+\t\t\te = gf_isom_last_error(file);\n+\t\t\tgoto err_exit;\n+\t\t}\n \n \t\tdata = (u8 *) sample->data;\n \t\tsize = sample->dataLength;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (!sample) {",
                "\t\t\te = gf_isom_last_error(file);",
                "\t\t\tgoto err_exit;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23606",
        "func_name": "envoyproxy/envoy/ConnPoolImplBase::onConnectionEvent",
        "description": "Envoy is an open source edge and service proxy, designed for cloud-native applications. When a cluster is deleted via Cluster Discovery Service (CDS) all idle connections established to endpoints in that cluster are disconnected. A recursion was introduced in the procedure of disconnecting idle connections that can lead to stack exhaustion and abnormal process termination when a cluster has a large number of idle connections. This infinite recursion causes Envoy to crash. Users are advised to upgrade.",
        "git_url": "https://github.com/envoyproxy/envoy/commit/4b6dd3b53cd5c6d4d4df378a2fc62c1707522b31",
        "commit_title": "CVE-2022-23606",
        "commit_text": " Avoid closing other connections to prevent deep recursion when a large number of idle connections are closed at the start of a pool drain, when a connection is closed. ",
        "func_before": "void ConnPoolImplBase::onConnectionEvent(ActiveClient& client, absl::string_view failure_reason,\n                                         Network::ConnectionEvent event) {\n  if (client.state() == ActiveClient::State::CONNECTING) {\n    ASSERT(connecting_stream_capacity_ >= client.effectiveConcurrentStreamLimit());\n    connecting_stream_capacity_ -= client.effectiveConcurrentStreamLimit();\n  }\n\n  if (client.connect_timer_) {\n    client.connect_timer_->disableTimer();\n    client.connect_timer_.reset();\n  }\n\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    state_.decrConnectingAndConnectedStreamCapacity(client.currentUnusedCapacity());\n    // Make sure that onStreamClosed won't double count.\n    client.remaining_streams_ = 0;\n    // The client died.\n    ENVOY_CONN_LOG(debug, \"client disconnected, failure reason: {}\", client, failure_reason);\n\n    Envoy::Upstream::reportUpstreamCxDestroy(host_, event);\n    const bool incomplete_stream = client.closingWithIncompleteStream();\n    if (incomplete_stream) {\n      Envoy::Upstream::reportUpstreamCxDestroyActiveRequest(host_, event);\n    }\n\n    if (client.state() == ActiveClient::State::CONNECTING) {\n      host_->cluster().stats().upstream_cx_connect_fail_.inc();\n      host_->stats().cx_connect_fail_.inc();\n\n      ConnectionPool::PoolFailureReason reason;\n      if (client.timed_out_) {\n        reason = ConnectionPool::PoolFailureReason::Timeout;\n      } else if (event == Network::ConnectionEvent::RemoteClose) {\n        reason = ConnectionPool::PoolFailureReason::RemoteConnectionFailure;\n      } else {\n        reason = ConnectionPool::PoolFailureReason::LocalConnectionFailure;\n      }\n\n      // Raw connect failures should never happen under normal circumstances. If we have an upstream\n      // that is behaving badly, streams can get stuck here in the pending state. If we see a\n      // connect failure, we purge all pending streams so that calling code can determine what to\n      // do with the stream.\n      // NOTE: We move the existing pending streams to a temporary list. This is done so that\n      //       if retry logic submits a new stream to the pool, we don't fail it inline.\n      purgePendingStreams(client.real_host_description_, failure_reason, reason);\n      // See if we should preconnect based on active connections.\n      if (!is_draining_for_deletion_) {\n        tryCreateNewConnections();\n      }\n    }\n\n    // We need to release our resourceManager() resources before checking below for\n    // whether we can create a new connection. Normally this would happen when\n    // client's destructor runs, but this object needs to be deferredDelete'd(), so\n    // this forces part of its cleanup to happen now.\n    client.releaseResources();\n\n    // Again, since we know this object is going to be deferredDelete'd(), we take\n    // this opportunity to disable and reset the connection duration timer so that\n    // it doesn't trigger while on the deferred delete list. In theory it is safe\n    // to handle the CLOSED state in onConnectionDurationTimeout, but we handle\n    // it here for simplicity and safety anyway.\n    if (client.connection_duration_timer_) {\n      client.connection_duration_timer_->disableTimer();\n      client.connection_duration_timer_.reset();\n    }\n\n    dispatcher_.deferredDelete(client.removeFromList(owningList(client.state())));\n\n    checkForIdleAndCloseIdleConnsIfDraining();\n\n    client.setState(ActiveClient::State::CLOSED);\n\n    // If we have pending streams and we just lost a connection we should make a new one.\n    if (!pending_streams_.empty()) {\n      tryCreateNewConnections();\n    }\n  } else if (event == Network::ConnectionEvent::Connected) {\n    client.conn_connect_ms_->complete();\n    client.conn_connect_ms_.reset();\n    ASSERT(client.state() == ActiveClient::State::CONNECTING);\n    bool streams_available = client.currentUnusedCapacity() > 0;\n    transitionActiveClientState(client, streams_available ? ActiveClient::State::READY\n                                                          : ActiveClient::State::BUSY);\n\n    // Now that the active client is ready, set up a timer for max connection duration.\n    const absl::optional<std::chrono::milliseconds> max_connection_duration =\n        client.parent_.host()->cluster().maxConnectionDuration();\n    if (max_connection_duration.has_value()) {\n      client.connection_duration_timer_ = client.parent_.dispatcher().createTimer(\n          [&client]() { client.onConnectionDurationTimeout(); });\n      client.connection_duration_timer_->enableTimer(max_connection_duration.value());\n    }\n\n    // At this point, for the mixed ALPN pool, the client may be deleted. Do not\n    // refer to client after this point.\n    onConnected(client);\n    if (streams_available) {\n      onUpstreamReady();\n    }\n    checkForIdleAndCloseIdleConnsIfDraining();\n  }\n}",
        "func": "void ConnPoolImplBase::onConnectionEvent(ActiveClient& client, absl::string_view failure_reason,\n                                         Network::ConnectionEvent event) {\n  if (client.state() == ActiveClient::State::CONNECTING) {\n    ASSERT(connecting_stream_capacity_ >= client.effectiveConcurrentStreamLimit());\n    connecting_stream_capacity_ -= client.effectiveConcurrentStreamLimit();\n  }\n\n  if (client.connect_timer_) {\n    client.connect_timer_->disableTimer();\n    client.connect_timer_.reset();\n  }\n\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    state_.decrConnectingAndConnectedStreamCapacity(client.currentUnusedCapacity());\n    // Make sure that onStreamClosed won't double count.\n    client.remaining_streams_ = 0;\n    // The client died.\n    ENVOY_CONN_LOG(debug, \"client disconnected, failure reason: {}\", client, failure_reason);\n\n    Envoy::Upstream::reportUpstreamCxDestroy(host_, event);\n    const bool incomplete_stream = client.closingWithIncompleteStream();\n    if (incomplete_stream) {\n      Envoy::Upstream::reportUpstreamCxDestroyActiveRequest(host_, event);\n    }\n\n    if (client.state() == ActiveClient::State::CONNECTING) {\n      host_->cluster().stats().upstream_cx_connect_fail_.inc();\n      host_->stats().cx_connect_fail_.inc();\n\n      ConnectionPool::PoolFailureReason reason;\n      if (client.timed_out_) {\n        reason = ConnectionPool::PoolFailureReason::Timeout;\n      } else if (event == Network::ConnectionEvent::RemoteClose) {\n        reason = ConnectionPool::PoolFailureReason::RemoteConnectionFailure;\n      } else {\n        reason = ConnectionPool::PoolFailureReason::LocalConnectionFailure;\n      }\n\n      // Raw connect failures should never happen under normal circumstances. If we have an upstream\n      // that is behaving badly, streams can get stuck here in the pending state. If we see a\n      // connect failure, we purge all pending streams so that calling code can determine what to\n      // do with the stream.\n      // NOTE: We move the existing pending streams to a temporary list. This is done so that\n      //       if retry logic submits a new stream to the pool, we don't fail it inline.\n      purgePendingStreams(client.real_host_description_, failure_reason, reason);\n      // See if we should preconnect based on active connections.\n      if (!is_draining_for_deletion_) {\n        tryCreateNewConnections();\n      }\n    }\n\n    // We need to release our resourceManager() resources before checking below for\n    // whether we can create a new connection. Normally this would happen when\n    // client's destructor runs, but this object needs to be deferredDelete'd(), so\n    // this forces part of its cleanup to happen now.\n    client.releaseResources();\n\n    // Again, since we know this object is going to be deferredDelete'd(), we take\n    // this opportunity to disable and reset the connection duration timer so that\n    // it doesn't trigger while on the deferred delete list. In theory it is safe\n    // to handle the CLOSED state in onConnectionDurationTimeout, but we handle\n    // it here for simplicity and safety anyway.\n    if (client.connection_duration_timer_) {\n      client.connection_duration_timer_->disableTimer();\n      client.connection_duration_timer_.reset();\n    }\n\n    dispatcher_.deferredDelete(client.removeFromList(owningList(client.state())));\n\n    // Check if the pool transitioned to idle state after removing closed client\n    // from one of the client tracking lists.\n    // There is no need to check if other connections are idle in a draining pool\n    // because the pool will close all idle connection when it is starting to\n    // drain.\n    // Trying to close other connections here can lead to deep recursion when\n    // a large number idle connections are closed at the start of pool drain.\n    // See CdsIntegrationTest.CdsClusterDownWithLotsOfIdleConnections for an example.\n    checkForIdleAndNotify();\n\n    client.setState(ActiveClient::State::CLOSED);\n\n    // If we have pending streams and we just lost a connection we should make a new one.\n    if (!pending_streams_.empty()) {\n      tryCreateNewConnections();\n    }\n  } else if (event == Network::ConnectionEvent::Connected) {\n    client.conn_connect_ms_->complete();\n    client.conn_connect_ms_.reset();\n    ASSERT(client.state() == ActiveClient::State::CONNECTING);\n    bool streams_available = client.currentUnusedCapacity() > 0;\n    transitionActiveClientState(client, streams_available ? ActiveClient::State::READY\n                                                          : ActiveClient::State::BUSY);\n\n    // Now that the active client is ready, set up a timer for max connection duration.\n    const absl::optional<std::chrono::milliseconds> max_connection_duration =\n        client.parent_.host()->cluster().maxConnectionDuration();\n    if (max_connection_duration.has_value()) {\n      client.connection_duration_timer_ = client.parent_.dispatcher().createTimer(\n          [&client]() { client.onConnectionDurationTimeout(); });\n      client.connection_duration_timer_->enableTimer(max_connection_duration.value());\n    }\n\n    // At this point, for the mixed ALPN pool, the client may be deleted. Do not\n    // refer to client after this point.\n    onConnected(client);\n    if (streams_available) {\n      onUpstreamReady();\n    }\n    checkForIdleAndCloseIdleConnsIfDraining();\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -68,7 +68,15 @@\n \n     dispatcher_.deferredDelete(client.removeFromList(owningList(client.state())));\n \n-    checkForIdleAndCloseIdleConnsIfDraining();\n+    // Check if the pool transitioned to idle state after removing closed client\n+    // from one of the client tracking lists.\n+    // There is no need to check if other connections are idle in a draining pool\n+    // because the pool will close all idle connection when it is starting to\n+    // drain.\n+    // Trying to close other connections here can lead to deep recursion when\n+    // a large number idle connections are closed at the start of pool drain.\n+    // See CdsIntegrationTest.CdsClusterDownWithLotsOfIdleConnections for an example.\n+    checkForIdleAndNotify();\n \n     client.setState(ActiveClient::State::CLOSED);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    checkForIdleAndCloseIdleConnsIfDraining();"
            ],
            "added_lines": [
                "    // Check if the pool transitioned to idle state after removing closed client",
                "    // from one of the client tracking lists.",
                "    // There is no need to check if other connections are idle in a draining pool",
                "    // because the pool will close all idle connection when it is starting to",
                "    // drain.",
                "    // Trying to close other connections here can lead to deep recursion when",
                "    // a large number idle connections are closed at the start of pool drain.",
                "    // See CdsIntegrationTest.CdsClusterDownWithLotsOfIdleConnections for an example.",
                "    checkForIdleAndNotify();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23606",
        "func_name": "envoyproxy/envoy/ConnPoolImplBase::closeIdleConnectionsForDrainingPool",
        "description": "Envoy is an open source edge and service proxy, designed for cloud-native applications. When a cluster is deleted via Cluster Discovery Service (CDS) all idle connections established to endpoints in that cluster are disconnected. A recursion was introduced in the procedure of disconnecting idle connections that can lead to stack exhaustion and abnormal process termination when a cluster has a large number of idle connections. This infinite recursion causes Envoy to crash. Users are advised to upgrade.",
        "git_url": "https://github.com/envoyproxy/envoy/commit/4b6dd3b53cd5c6d4d4df378a2fc62c1707522b31",
        "commit_title": "CVE-2022-23606",
        "commit_text": " Avoid closing other connections to prevent deep recursion when a large number of idle connections are closed at the start of a pool drain, when a connection is closed. ",
        "func_before": "void ConnPoolImplBase::closeIdleConnectionsForDrainingPool() {\n  // Create a separate list of elements to close to avoid mutate-while-iterating problems.\n  std::list<ActiveClient*> to_close;\n\n  for (auto& client : ready_clients_) {\n    if (client->numActiveStreams() == 0) {\n      to_close.push_back(client.get());\n    }\n  }\n\n  if (pending_streams_.empty()) {\n    for (auto& client : connecting_clients_) {\n      to_close.push_back(client.get());\n    }\n  }\n\n  for (auto& entry : to_close) {\n    ENVOY_LOG_EVENT(debug, \"closing_idle_client\", \"closing idle client {} for cluster {}\",\n                    entry->id(), host_->cluster().name());\n    entry->close();\n  }\n}",
        "func": "void ConnPoolImplBase::closeIdleConnectionsForDrainingPool() {\n  Common::AutoDebugRecursionChecker assert_not_in(recursion_checker_);\n\n  // Create a separate list of elements to close to avoid mutate-while-iterating problems.\n  std::list<ActiveClient*> to_close;\n\n  for (auto& client : ready_clients_) {\n    if (client->numActiveStreams() == 0) {\n      to_close.push_back(client.get());\n    }\n  }\n\n  if (pending_streams_.empty()) {\n    for (auto& client : connecting_clients_) {\n      to_close.push_back(client.get());\n    }\n  }\n\n  for (auto& entry : to_close) {\n    ENVOY_LOG_EVENT(debug, \"closing_idle_client\", \"closing idle client {} for cluster {}\",\n                    entry->id(), host_->cluster().name());\n    entry->close();\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,6 @@\n void ConnPoolImplBase::closeIdleConnectionsForDrainingPool() {\n+  Common::AutoDebugRecursionChecker assert_not_in(recursion_checker_);\n+\n   // Create a separate list of elements to close to avoid mutate-while-iterating problems.\n   std::list<ActiveClient*> to_close;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  Common::AutoDebugRecursionChecker assert_not_in(recursion_checker_);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23606",
        "func_name": "envoyproxy/envoy/ConnPoolImplBase::checkForIdleAndCloseIdleConnsIfDraining",
        "description": "Envoy is an open source edge and service proxy, designed for cloud-native applications. When a cluster is deleted via Cluster Discovery Service (CDS) all idle connections established to endpoints in that cluster are disconnected. A recursion was introduced in the procedure of disconnecting idle connections that can lead to stack exhaustion and abnormal process termination when a cluster has a large number of idle connections. This infinite recursion causes Envoy to crash. Users are advised to upgrade.",
        "git_url": "https://github.com/envoyproxy/envoy/commit/4b6dd3b53cd5c6d4d4df378a2fc62c1707522b31",
        "commit_title": "CVE-2022-23606",
        "commit_text": " Avoid closing other connections to prevent deep recursion when a large number of idle connections are closed at the start of a pool drain, when a connection is closed. ",
        "func_before": "void ConnPoolImplBase::checkForIdleAndCloseIdleConnsIfDraining() {\n  if (is_draining_for_deletion_) {\n    closeIdleConnectionsForDrainingPool();\n  }\n\n  if (isIdleImpl()) {\n    ENVOY_LOG(debug, \"invoking idle callbacks - is_draining_for_deletion_={}\",\n              is_draining_for_deletion_);\n    for (const Instance::IdleCb& cb : idle_callbacks_) {\n      cb();\n    }\n  }\n}",
        "func": "void ConnPoolImplBase::checkForIdleAndCloseIdleConnsIfDraining() {\n  if (is_draining_for_deletion_) {\n    closeIdleConnectionsForDrainingPool();\n  }\n\n  checkForIdleAndNotify();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,11 +3,5 @@\n     closeIdleConnectionsForDrainingPool();\n   }\n \n-  if (isIdleImpl()) {\n-    ENVOY_LOG(debug, \"invoking idle callbacks - is_draining_for_deletion_={}\",\n-              is_draining_for_deletion_);\n-    for (const Instance::IdleCb& cb : idle_callbacks_) {\n-      cb();\n-    }\n-  }\n+  checkForIdleAndNotify();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (isIdleImpl()) {",
                "    ENVOY_LOG(debug, \"invoking idle callbacks - is_draining_for_deletion_={}\",",
                "              is_draining_for_deletion_);",
                "    for (const Instance::IdleCb& cb : idle_callbacks_) {",
                "      cb();",
                "    }",
                "  }"
            ],
            "added_lines": [
                "  checkForIdleAndNotify();"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-30974",
        "func_name": "ccxvii/mujs/count",
        "description": "compile in regexp.c in Artifex MuJS through 1.2.0 results in stack consumption because of unlimited recursion, a different issue than CVE-2019-11413.",
        "git_url": "https://github.com/ccxvii/mujs/commit/160ae29578054dc09fd91e5401ef040d52797e61",
        "commit_title": "Issue #162: Check stack overflow during regexp compilation.",
        "commit_text": " Only bother checking during the first compilation pass that counts the size of the program.",
        "func_before": "static int count(struct cstate *g, Renode *node)\n{\n\tint min, max, n;\n\tif (!node) return 0;\n\tswitch (node->type) {\n\tdefault: return 1;\n\tcase P_CAT: return count(g, node->x) + count(g, node->y);\n\tcase P_ALT: return count(g, node->x) + count(g, node->y) + 2;\n\tcase P_REP:\n\t\tmin = node->m;\n\t\tmax = node->n;\n\t\tif (min == max) n = count(g, node->x) * min;\n\t\telse if (max < REPINF) n = count(g, node->x) * max + (max - min);\n\t\telse n = count(g, node->x) * (min + 1) + 2;\n\t\tif (n < 0 || n > REG_MAXPROG) die(g, \"program too large\");\n\t\treturn n;\n\tcase P_PAR: return count(g, node->x) + 2;\n\tcase P_PLA: return count(g, node->x) + 2;\n\tcase P_NLA: return count(g, node->x) + 2;\n\t}\n}",
        "func": "static int count(struct cstate *g, Renode *node, int depth)\n{\n\tint min, max, n;\n\tif (!node) return 0;\n\tif (++depth > REG_MAXREC) die(g, \"stack overflow\");\n\tswitch (node->type) {\n\tdefault: return 1;\n\tcase P_CAT: return count(g, node->x, depth) + count(g, node->y, depth);\n\tcase P_ALT: return count(g, node->x, depth) + count(g, node->y, depth) + 2;\n\tcase P_REP:\n\t\tmin = node->m;\n\t\tmax = node->n;\n\t\tif (min == max) n = count(g, node->x, depth) * min;\n\t\telse if (max < REPINF) n = count(g, node->x, depth) * max + (max - min);\n\t\telse n = count(g, node->x, depth) * (min + 1) + 2;\n\t\tif (n < 0 || n > REG_MAXPROG) die(g, \"program too large\");\n\t\treturn n;\n\tcase P_PAR: return count(g, node->x, depth) + 2;\n\tcase P_PLA: return count(g, node->x, depth) + 2;\n\tcase P_NLA: return count(g, node->x, depth) + 2;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,21 +1,22 @@\n-static int count(struct cstate *g, Renode *node)\n+static int count(struct cstate *g, Renode *node, int depth)\n {\n \tint min, max, n;\n \tif (!node) return 0;\n+\tif (++depth > REG_MAXREC) die(g, \"stack overflow\");\n \tswitch (node->type) {\n \tdefault: return 1;\n-\tcase P_CAT: return count(g, node->x) + count(g, node->y);\n-\tcase P_ALT: return count(g, node->x) + count(g, node->y) + 2;\n+\tcase P_CAT: return count(g, node->x, depth) + count(g, node->y, depth);\n+\tcase P_ALT: return count(g, node->x, depth) + count(g, node->y, depth) + 2;\n \tcase P_REP:\n \t\tmin = node->m;\n \t\tmax = node->n;\n-\t\tif (min == max) n = count(g, node->x) * min;\n-\t\telse if (max < REPINF) n = count(g, node->x) * max + (max - min);\n-\t\telse n = count(g, node->x) * (min + 1) + 2;\n+\t\tif (min == max) n = count(g, node->x, depth) * min;\n+\t\telse if (max < REPINF) n = count(g, node->x, depth) * max + (max - min);\n+\t\telse n = count(g, node->x, depth) * (min + 1) + 2;\n \t\tif (n < 0 || n > REG_MAXPROG) die(g, \"program too large\");\n \t\treturn n;\n-\tcase P_PAR: return count(g, node->x) + 2;\n-\tcase P_PLA: return count(g, node->x) + 2;\n-\tcase P_NLA: return count(g, node->x) + 2;\n+\tcase P_PAR: return count(g, node->x, depth) + 2;\n+\tcase P_PLA: return count(g, node->x, depth) + 2;\n+\tcase P_NLA: return count(g, node->x, depth) + 2;\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static int count(struct cstate *g, Renode *node)",
                "\tcase P_CAT: return count(g, node->x) + count(g, node->y);",
                "\tcase P_ALT: return count(g, node->x) + count(g, node->y) + 2;",
                "\t\tif (min == max) n = count(g, node->x) * min;",
                "\t\telse if (max < REPINF) n = count(g, node->x) * max + (max - min);",
                "\t\telse n = count(g, node->x) * (min + 1) + 2;",
                "\tcase P_PAR: return count(g, node->x) + 2;",
                "\tcase P_PLA: return count(g, node->x) + 2;",
                "\tcase P_NLA: return count(g, node->x) + 2;"
            ],
            "added_lines": [
                "static int count(struct cstate *g, Renode *node, int depth)",
                "\tif (++depth > REG_MAXREC) die(g, \"stack overflow\");",
                "\tcase P_CAT: return count(g, node->x, depth) + count(g, node->y, depth);",
                "\tcase P_ALT: return count(g, node->x, depth) + count(g, node->y, depth) + 2;",
                "\t\tif (min == max) n = count(g, node->x, depth) * min;",
                "\t\telse if (max < REPINF) n = count(g, node->x, depth) * max + (max - min);",
                "\t\telse n = count(g, node->x, depth) * (min + 1) + 2;",
                "\tcase P_PAR: return count(g, node->x, depth) + 2;",
                "\tcase P_PLA: return count(g, node->x, depth) + 2;",
                "\tcase P_NLA: return count(g, node->x, depth) + 2;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-30974",
        "func_name": "ccxvii/mujs/regcompx",
        "description": "compile in regexp.c in Artifex MuJS through 1.2.0 results in stack consumption because of unlimited recursion, a different issue than CVE-2019-11413.",
        "git_url": "https://github.com/ccxvii/mujs/commit/160ae29578054dc09fd91e5401ef040d52797e61",
        "commit_title": "Issue #162: Check stack overflow during regexp compilation.",
        "commit_text": " Only bother checking during the first compilation pass that counts the size of the program.",
        "func_before": "Reprog *regcompx(void *(*alloc)(void *ctx, void *p, int n), void *ctx,\n\tconst char *pattern, int cflags, const char **errorp)\n{\n\tstruct cstate g;\n\tRenode *node;\n\tReinst *split, *jump;\n\tint i, n;\n\n\tg.pstart = NULL;\n\tg.prog = NULL;\n\n\tif (setjmp(g.kaboom)) {\n\t\tif (errorp) *errorp = g.error;\n\t\talloc(ctx, g.pstart, 0);\n\t\talloc(ctx, g.prog, 0);\n\t\treturn NULL;\n\t}\n\n\tg.prog = alloc(ctx, NULL, sizeof (Reprog));\n\tif (!g.prog)\n\t\tdie(&g, \"cannot allocate regular expression\");\n\tn = strlen(pattern) * 2;\n\tif (n > REG_MAXPROG)\n\t\tdie(&g, \"program too large\");\n\tif (n > 0) {\n\t\tg.pstart = g.pend = alloc(ctx, NULL, sizeof (Renode) * n);\n\t\tif (!g.pstart)\n\t\t\tdie(&g, \"cannot allocate regular expression parse list\");\n\t}\n\n\tg.source = pattern;\n\tg.ncclass = 0;\n\tg.nsub = 1;\n\tfor (i = 0; i < REG_MAXSUB; ++i)\n\t\tg.sub[i] = 0;\n\n\tg.prog->flags = cflags;\n\n\tnext(&g);\n\tnode = parsealt(&g);\n\tif (g.lookahead == ')')\n\t\tdie(&g, \"unmatched ')'\");\n\tif (g.lookahead != EOF)\n\t\tdie(&g, \"syntax error\");\n\n#ifdef TEST\n\tdumpnode(node);\n\tputchar('\\n');\n#endif\n\n\tn = 6 + count(&g, node);\n\tif (n < 0 || n > REG_MAXPROG)\n\t\tdie(&g, \"program too large\");\n\n\tg.prog->nsub = g.nsub;\n\tg.prog->start = g.prog->end = alloc(ctx, NULL, n * sizeof (Reinst));\n\tif (!g.prog->start)\n\t\tdie(&g, \"cannot allocate regular expression instruction list\");\n\n\tsplit = emit(g.prog, I_SPLIT);\n\tsplit->x = split + 3;\n\tsplit->y = split + 1;\n\temit(g.prog, I_ANYNL);\n\tjump = emit(g.prog, I_JUMP);\n\tjump->x = split;\n\temit(g.prog, I_LPAR);\n\tcompile(g.prog, node);\n\temit(g.prog, I_RPAR);\n\temit(g.prog, I_END);\n\n#ifdef TEST\n\tdumpprog(g.prog);\n#endif\n\n\talloc(ctx, g.pstart, 0);\n\n\tif (errorp) *errorp = NULL;\n\treturn g.prog;\n}",
        "func": "Reprog *regcompx(void *(*alloc)(void *ctx, void *p, int n), void *ctx,\n\tconst char *pattern, int cflags, const char **errorp)\n{\n\tstruct cstate g;\n\tRenode *node;\n\tReinst *split, *jump;\n\tint i, n;\n\n\tg.pstart = NULL;\n\tg.prog = NULL;\n\n\tif (setjmp(g.kaboom)) {\n\t\tif (errorp) *errorp = g.error;\n\t\talloc(ctx, g.pstart, 0);\n\t\talloc(ctx, g.prog, 0);\n\t\treturn NULL;\n\t}\n\n\tg.prog = alloc(ctx, NULL, sizeof (Reprog));\n\tif (!g.prog)\n\t\tdie(&g, \"cannot allocate regular expression\");\n\tn = strlen(pattern) * 2;\n\tif (n > REG_MAXPROG)\n\t\tdie(&g, \"program too large\");\n\tif (n > 0) {\n\t\tg.pstart = g.pend = alloc(ctx, NULL, sizeof (Renode) * n);\n\t\tif (!g.pstart)\n\t\t\tdie(&g, \"cannot allocate regular expression parse list\");\n\t}\n\n\tg.source = pattern;\n\tg.ncclass = 0;\n\tg.nsub = 1;\n\tfor (i = 0; i < REG_MAXSUB; ++i)\n\t\tg.sub[i] = 0;\n\n\tg.prog->flags = cflags;\n\n\tnext(&g);\n\tnode = parsealt(&g);\n\tif (g.lookahead == ')')\n\t\tdie(&g, \"unmatched ')'\");\n\tif (g.lookahead != EOF)\n\t\tdie(&g, \"syntax error\");\n\n#ifdef TEST\n\tdumpnode(node);\n\tputchar('\\n');\n#endif\n\n\tn = 6 + count(&g, node, 0);\n\tif (n < 0 || n > REG_MAXPROG)\n\t\tdie(&g, \"program too large\");\n\n\tg.prog->nsub = g.nsub;\n\tg.prog->start = g.prog->end = alloc(ctx, NULL, n * sizeof (Reinst));\n\tif (!g.prog->start)\n\t\tdie(&g, \"cannot allocate regular expression instruction list\");\n\n\tsplit = emit(g.prog, I_SPLIT);\n\tsplit->x = split + 3;\n\tsplit->y = split + 1;\n\temit(g.prog, I_ANYNL);\n\tjump = emit(g.prog, I_JUMP);\n\tjump->x = split;\n\temit(g.prog, I_LPAR);\n\tcompile(g.prog, node);\n\temit(g.prog, I_RPAR);\n\temit(g.prog, I_END);\n\n#ifdef TEST\n\tdumpprog(g.prog);\n#endif\n\n\talloc(ctx, g.pstart, 0);\n\n\tif (errorp) *errorp = NULL;\n\treturn g.prog;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -48,7 +48,7 @@\n \tputchar('\\n');\n #endif\n \n-\tn = 6 + count(&g, node);\n+\tn = 6 + count(&g, node, 0);\n \tif (n < 0 || n > REG_MAXPROG)\n \t\tdie(&g, \"program too large\");\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tn = 6 + count(&g, node);"
            ],
            "added_lines": [
                "\tn = 6 + count(&g, node, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-30974",
        "func_name": "ccxvii/mujs/jsP_dumpsyntax",
        "description": "compile in regexp.c in Artifex MuJS through 1.2.0 results in stack consumption because of unlimited recursion, a different issue than CVE-2019-11413.",
        "git_url": "https://github.com/ccxvii/mujs/commit/799b62bf065b006e2bcb1c80044eab2b10412ecf",
        "commit_title": "Issue #162: Cope with empty programs in mujs-pp.",
        "commit_text": "",
        "func_before": "void jsP_dumpsyntax(js_State *J, js_Ast *prog, int dominify)\n{\n\tminify = dominify;\n\tif (prog->type == AST_LIST)\n\t\tpstmlist(-1, prog);\n\telse {\n\t\tpstm(0, prog);\n\t\tnl();\n\t}\n\tif (minify > 1)\n\t\tputchar('\\n');\n}",
        "func": "void jsP_dumpsyntax(js_State *J, js_Ast *prog, int dominify)\n{\n\tminify = dominify;\n\tif (prog) {\n\t\tif (prog->type == AST_LIST)\n\t\t\tpstmlist(-1, prog);\n\t\telse {\n\t\t\tpstm(0, prog);\n\t\t\tnl();\n\t\t}\n\t}\n\tif (minify > 1)\n\t\tputchar('\\n');\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,13 @@\n void jsP_dumpsyntax(js_State *J, js_Ast *prog, int dominify)\n {\n \tminify = dominify;\n-\tif (prog->type == AST_LIST)\n-\t\tpstmlist(-1, prog);\n-\telse {\n-\t\tpstm(0, prog);\n-\t\tnl();\n+\tif (prog) {\n+\t\tif (prog->type == AST_LIST)\n+\t\t\tpstmlist(-1, prog);\n+\t\telse {\n+\t\t\tpstm(0, prog);\n+\t\t\tnl();\n+\t\t}\n \t}\n \tif (minify > 1)\n \t\tputchar('\\n');",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (prog->type == AST_LIST)",
                "\t\tpstmlist(-1, prog);",
                "\telse {",
                "\t\tpstm(0, prog);",
                "\t\tnl();"
            ],
            "added_lines": [
                "\tif (prog) {",
                "\t\tif (prog->type == AST_LIST)",
                "\t\t\tpstmlist(-1, prog);",
                "\t\telse {",
                "\t\t\tpstm(0, prog);",
                "\t\t\tnl();",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-30974",
        "func_name": "ccxvii/mujs/jsP_dumplist",
        "description": "compile in regexp.c in Artifex MuJS through 1.2.0 results in stack consumption because of unlimited recursion, a different issue than CVE-2019-11413.",
        "git_url": "https://github.com/ccxvii/mujs/commit/799b62bf065b006e2bcb1c80044eab2b10412ecf",
        "commit_title": "Issue #162: Cope with empty programs in mujs-pp.",
        "commit_text": "",
        "func_before": "void jsP_dumplist(js_State *J, js_Ast *prog)\n{\n\tminify = 0;\n\tif (prog->type == AST_LIST)\n\t\tsblock(0, prog);\n\telse\n\t\tsnode(0, prog);\n\tnl();\n}",
        "func": "void jsP_dumplist(js_State *J, js_Ast *prog)\n{\n\tminify = 0;\n\tif (prog) {\n\t\tif (prog->type == AST_LIST)\n\t\t\tsblock(0, prog);\n\t\telse\n\t\t\tsnode(0, prog);\n\t\tnl();\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,11 @@\n void jsP_dumplist(js_State *J, js_Ast *prog)\n {\n \tminify = 0;\n-\tif (prog->type == AST_LIST)\n-\t\tsblock(0, prog);\n-\telse\n-\t\tsnode(0, prog);\n-\tnl();\n+\tif (prog) {\n+\t\tif (prog->type == AST_LIST)\n+\t\t\tsblock(0, prog);\n+\t\telse\n+\t\t\tsnode(0, prog);\n+\t\tnl();\n+\t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (prog->type == AST_LIST)",
                "\t\tsblock(0, prog);",
                "\telse",
                "\t\tsnode(0, prog);",
                "\tnl();"
            ],
            "added_lines": [
                "\tif (prog) {",
                "\t\tif (prog->type == AST_LIST)",
                "\t\t\tsblock(0, prog);",
                "\t\telse",
                "\t\t\tsnode(0, prog);",
                "\t\tnl();",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9766",
        "func_name": "wireshark/dissect_IPNIO_Write_rqst",
        "description": "In Wireshark 2.2.7, PROFINET IO data with a high recursion depth allows remote attackers to cause a denial of service (stack exhaustion) in the dissect_IODWriteReq function in plugins/profinet/packet-dcerpc-pn-io.c.",
        "git_url": "https://github.com/wireshark/wireshark/commit/d6e888400ba64de3147d1111a4c23edf389b0000",
        "commit_title": "PROFINET IO: define an arbitrary recursion depth limit",
        "commit_text": " Bug: 13811 (cherry picked from commit fbfb87a2439dd18f2318586b8e5a2f6db410ba6a)",
        "func_before": "static int\ndissect_IPNIO_Write_rqst(tvbuff_t *tvb, int offset,\n    packet_info *pinfo, proto_tree *tree, dcerpc_info *di, guint8 *drep)\n{\n    pnio_ar_t *ar = NULL;\n\n    offset = dissect_IPNIO_rqst_header(tvb, offset, pinfo, tree, di, drep);\n\n    offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, &ar);\n\n    if (ar != NULL) {\n        pnio_ar_info(tvb, pinfo, tree, ar);\n    }\n\n    return offset;\n}",
        "func": "static int\ndissect_IPNIO_Write_rqst(tvbuff_t *tvb, int offset,\n    packet_info *pinfo, proto_tree *tree, dcerpc_info *di, guint8 *drep)\n{\n    pnio_ar_t *ar = NULL;\n    guint recursion_count = 0;\n\n    offset = dissect_IPNIO_rqst_header(tvb, offset, pinfo, tree, di, drep);\n\n    offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, &ar, recursion_count);\n\n    if (ar != NULL) {\n        pnio_ar_info(tvb, pinfo, tree, ar);\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,10 +3,11 @@\n     packet_info *pinfo, proto_tree *tree, dcerpc_info *di, guint8 *drep)\n {\n     pnio_ar_t *ar = NULL;\n+    guint recursion_count = 0;\n \n     offset = dissect_IPNIO_rqst_header(tvb, offset, pinfo, tree, di, drep);\n \n-    offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, &ar);\n+    offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, &ar, recursion_count);\n \n     if (ar != NULL) {\n         pnio_ar_info(tvb, pinfo, tree, ar);",
        "diff_line_info": {
            "deleted_lines": [
                "    offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, &ar);"
            ],
            "added_lines": [
                "    guint recursion_count = 0;",
                "    offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, &ar, recursion_count);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9766",
        "func_name": "wireshark/dissect_IODWriteReq",
        "description": "In Wireshark 2.2.7, PROFINET IO data with a high recursion depth allows remote attackers to cause a denial of service (stack exhaustion) in the dissect_IODWriteReq function in plugins/profinet/packet-dcerpc-pn-io.c.",
        "git_url": "https://github.com/wireshark/wireshark/commit/d6e888400ba64de3147d1111a4c23edf389b0000",
        "commit_title": "PROFINET IO: define an arbitrary recursion depth limit",
        "commit_text": " Bug: 13811 (cherry picked from commit fbfb87a2439dd18f2318586b8e5a2f6db410ba6a)",
        "func_before": "static int\ndissect_IODWriteReq(tvbuff_t *tvb, int offset,\n    packet_info *pinfo, proto_tree *tree, guint8 *drep, pnio_ar_t **ar)\n{\n    guint16 u16Index = 0;\n    guint32 u32RecDataLen = 0;\n\n\n    /* IODWriteHeader */\n    offset = dissect_block(tvb, offset, pinfo, tree, drep, &u16Index, &u32RecDataLen, ar);\n\n    /* IODWriteMultipleReq? */\n    if (u16Index == 0xe040) {\n        while (tvb_captured_length_remaining(tvb, offset) > 0) {\n            offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, ar);\n        }\n    } else {\n        tvbuff_t *new_tvb = tvb_new_subset_length(tvb, offset, u32RecDataLen);\n        /* RecordDataWrite */\n        offset += dissect_RecordDataWrite(new_tvb, 0, pinfo, tree, drep, u16Index, u32RecDataLen);\n\n        /* Padding */\n        switch (offset % 4) {\n        case(3):\n            offset += 1;\n            break;\n        case(2):\n            offset += 2;\n            break;\n        case(1):\n            offset += 3;\n            break;\n        }\n    }\n\n    return offset;\n}",
        "func": "static int\ndissect_IODWriteReq(tvbuff_t *tvb, int offset,\n    packet_info *pinfo, proto_tree *tree, guint8 *drep, pnio_ar_t **ar, guint recursion_count)\n{\n    guint16 u16Index = 0;\n    guint32 u32RecDataLen = 0;\n\n    if (++recursion_count >= PN_IO_MAX_RECURSION_DEPTH) {\n        proto_tree_add_expert(tree, pinfo, &ei_pn_io_max_recursion_depth_reached,\n                              tvb, 0, 0);\n        return tvb_captured_length(tvb);\n    }\n\n    /* IODWriteHeader */\n    offset = dissect_block(tvb, offset, pinfo, tree, drep, &u16Index, &u32RecDataLen, ar);\n\n    /* IODWriteMultipleReq? */\n    if (u16Index == 0xe040) {\n        while (tvb_captured_length_remaining(tvb, offset) > 0) {\n            offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, ar, recursion_count++);\n        }\n    } else {\n        tvbuff_t *new_tvb = tvb_new_subset_length(tvb, offset, u32RecDataLen);\n        /* RecordDataWrite */\n        offset += dissect_RecordDataWrite(new_tvb, 0, pinfo, tree, drep, u16Index, u32RecDataLen);\n\n        /* Padding */\n        switch (offset % 4) {\n        case(3):\n            offset += 1;\n            break;\n        case(2):\n            offset += 2;\n            break;\n        case(1):\n            offset += 3;\n            break;\n        }\n    }\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,15 @@\n static int\n dissect_IODWriteReq(tvbuff_t *tvb, int offset,\n-    packet_info *pinfo, proto_tree *tree, guint8 *drep, pnio_ar_t **ar)\n+    packet_info *pinfo, proto_tree *tree, guint8 *drep, pnio_ar_t **ar, guint recursion_count)\n {\n     guint16 u16Index = 0;\n     guint32 u32RecDataLen = 0;\n \n+    if (++recursion_count >= PN_IO_MAX_RECURSION_DEPTH) {\n+        proto_tree_add_expert(tree, pinfo, &ei_pn_io_max_recursion_depth_reached,\n+                              tvb, 0, 0);\n+        return tvb_captured_length(tvb);\n+    }\n \n     /* IODWriteHeader */\n     offset = dissect_block(tvb, offset, pinfo, tree, drep, &u16Index, &u32RecDataLen, ar);\n@@ -12,7 +17,7 @@\n     /* IODWriteMultipleReq? */\n     if (u16Index == 0xe040) {\n         while (tvb_captured_length_remaining(tvb, offset) > 0) {\n-            offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, ar);\n+            offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, ar, recursion_count++);\n         }\n     } else {\n         tvbuff_t *new_tvb = tvb_new_subset_length(tvb, offset, u32RecDataLen);",
        "diff_line_info": {
            "deleted_lines": [
                "    packet_info *pinfo, proto_tree *tree, guint8 *drep, pnio_ar_t **ar)",
                "            offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, ar);"
            ],
            "added_lines": [
                "    packet_info *pinfo, proto_tree *tree, guint8 *drep, pnio_ar_t **ar, guint recursion_count)",
                "    if (++recursion_count >= PN_IO_MAX_RECURSION_DEPTH) {",
                "        proto_tree_add_expert(tree, pinfo, &ei_pn_io_max_recursion_depth_reached,",
                "                              tvb, 0, 0);",
                "        return tvb_captured_length(tvb);",
                "    }",
                "            offset = dissect_IODWriteReq(tvb, offset, pinfo, tree, drep, ar, recursion_count++);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/abi_from_variant_visitor",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d",
        "commit_title": "Add limit to recursion",
        "commit_text": "",
        "func_before": "abi_from_variant_visitor( const variant_object& _vo, T& v, Resolver _resolver )\n         : reflector_verifier_visitor<T>(v)\n         ,_vo(_vo)\n         ,_resolver(_resolver)\n         {}",
        "func": "abi_from_variant_visitor( const variant_object& _vo, T& v, Resolver _resolver, size_t _recursion_depth )\n         : reflector_verifier_visitor<T>(v)\n         ,_vo(_vo)\n         ,_resolver(_resolver)\n         ,_recursion_depth(_recursion_depth)\n         {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n-abi_from_variant_visitor( const variant_object& _vo, T& v, Resolver _resolver )\n+abi_from_variant_visitor( const variant_object& _vo, T& v, Resolver _resolver, size_t _recursion_depth )\n          : reflector_verifier_visitor<T>(v)\n          ,_vo(_vo)\n          ,_resolver(_resolver)\n+         ,_recursion_depth(_recursion_depth)\n          {}",
        "diff_line_info": {
            "deleted_lines": [
                "abi_from_variant_visitor( const variant_object& _vo, T& v, Resolver _resolver )"
            ],
            "added_lines": [
                "abi_from_variant_visitor( const variant_object& _vo, T& v, Resolver _resolver, size_t _recursion_depth )",
                "         ,_recursion_depth(_recursion_depth)"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/abi_to_variant::add",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d",
        "commit_title": "Add limit to recursion",
        "commit_text": "",
        "func_before": "void abi_to_variant::add( mutable_variant_object &mvo, const char* name, const M& v, Resolver resolver ) {\n      mutable_variant_object member_mvo;\n      fc::reflector<M>::visit( impl::abi_to_variant_visitor<M, Resolver>( member_mvo, v, resolver ) );\n      mvo(name, std::move(member_mvo));\n   }",
        "func": "void abi_to_variant::add( mutable_variant_object &mvo, const char* name, const M& v, Resolver resolver, size_t recursion_depth ) {\n      FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n      mutable_variant_object member_mvo;\n      fc::reflector<M>::visit( impl::abi_to_variant_visitor<M, Resolver>( member_mvo, v, resolver, recursion_depth ) );\n      mvo(name, std::move(member_mvo));\n   }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n-void abi_to_variant::add( mutable_variant_object &mvo, const char* name, const M& v, Resolver resolver ) {\n+void abi_to_variant::add( mutable_variant_object &mvo, const char* name, const M& v, Resolver resolver, size_t recursion_depth ) {\n+      FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n       mutable_variant_object member_mvo;\n-      fc::reflector<M>::visit( impl::abi_to_variant_visitor<M, Resolver>( member_mvo, v, resolver ) );\n+      fc::reflector<M>::visit( impl::abi_to_variant_visitor<M, Resolver>( member_mvo, v, resolver, recursion_depth ) );\n       mvo(name, std::move(member_mvo));\n    }",
        "diff_line_info": {
            "deleted_lines": [
                "void abi_to_variant::add( mutable_variant_object &mvo, const char* name, const M& v, Resolver resolver ) {",
                "      fc::reflector<M>::visit( impl::abi_to_variant_visitor<M, Resolver>( member_mvo, v, resolver ) );"
            ],
            "added_lines": [
                "void abi_to_variant::add( mutable_variant_object &mvo, const char* name, const M& v, Resolver resolver, size_t recursion_depth ) {",
                "      FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );",
                "      fc::reflector<M>::visit( impl::abi_to_variant_visitor<M, Resolver>( member_mvo, v, resolver, recursion_depth ) );"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/operator()",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d",
        "commit_title": "Add limit to recursion",
        "commit_text": "",
        "func_before": "void operator()( T& v )const\n         {\n            add(obj_mvo, \"_\", v, resolver);\n         }",
        "func": "void operator()( T& v )const\n         {\n            add(obj_mvo, \"_\", v, resolver, recursion_depth);\n         }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n void operator()( T& v )const\n          {\n-            add(obj_mvo, \"_\", v, resolver);\n+            add(obj_mvo, \"_\", v, resolver, recursion_depth);\n          }",
        "diff_line_info": {
            "deleted_lines": [
                "            add(obj_mvo, \"_\", v, resolver);"
            ],
            "added_lines": [
                "            add(obj_mvo, \"_\", v, resolver, recursion_depth);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/abi_from_variant::extract",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d",
        "commit_title": "Add limit to recursion",
        "commit_text": "",
        "func_before": "void abi_from_variant::extract( const variant& v, M& o, Resolver resolver ) {\n      const variant_object& vo = v.get_object();\n      fc::reflector<M>::visit( abi_from_variant_visitor<M, decltype(resolver)>( vo, o, resolver ) );\n   }",
        "func": "void abi_from_variant::extract( const variant& v, M& o, Resolver resolver, size_t recursion_depth ) {\n      FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n      const variant_object& vo = v.get_object();\n      fc::reflector<M>::visit( abi_from_variant_visitor<M, decltype(resolver)>( vo, o, resolver, recursion_depth ) );\n   }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-void abi_from_variant::extract( const variant& v, M& o, Resolver resolver ) {\n+void abi_from_variant::extract( const variant& v, M& o, Resolver resolver, size_t recursion_depth ) {\n+      FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n       const variant_object& vo = v.get_object();\n-      fc::reflector<M>::visit( abi_from_variant_visitor<M, decltype(resolver)>( vo, o, resolver ) );\n+      fc::reflector<M>::visit( abi_from_variant_visitor<M, decltype(resolver)>( vo, o, resolver, recursion_depth ) );\n    }",
        "diff_line_info": {
            "deleted_lines": [
                "void abi_from_variant::extract( const variant& v, M& o, Resolver resolver ) {",
                "      fc::reflector<M>::visit( abi_from_variant_visitor<M, decltype(resolver)>( vo, o, resolver ) );"
            ],
            "added_lines": [
                "void abi_from_variant::extract( const variant& v, M& o, Resolver resolver, size_t recursion_depth ) {",
                "      FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );",
                "      fc::reflector<M>::visit( abi_from_variant_visitor<M, decltype(resolver)>( vo, o, resolver, recursion_depth ) );"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/operator()",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d",
        "commit_title": "Add limit to recursion",
        "commit_text": "",
        "func_before": "void operator()( const char* name )const\n         {\n            auto itr = _vo.find(name);\n            if( itr != _vo.end() )\n               abi_from_variant::extract( itr->value(), this->obj.*member, _resolver );\n         }",
        "func": "void operator()( const char* name )const\n         {\n            auto itr = _vo.find(name);\n            if( itr != _vo.end() )\n               abi_from_variant::extract( itr->value(), this->obj.*member, _resolver, _recursion_depth );\n         }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,5 @@\n          {\n             auto itr = _vo.find(name);\n             if( itr != _vo.end() )\n-               abi_from_variant::extract( itr->value(), this->obj.*member, _resolver );\n+               abi_from_variant::extract( itr->value(), this->obj.*member, _resolver, _recursion_depth );\n          }",
        "diff_line_info": {
            "deleted_lines": [
                "               abi_from_variant::extract( itr->value(), this->obj.*member, _resolver );"
            ],
            "added_lines": [
                "               abi_from_variant::extract( itr->value(), this->obj.*member, _resolver, _recursion_depth );"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/add_static_variant",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d",
        "commit_title": "Add limit to recursion",
        "commit_text": "",
        "func_before": "add_static_variant( mutable_variant_object& o, Resolver& r)\n               :obj_mvo(o), resolver(r){}",
        "func": "add_static_variant( mutable_variant_object& o, Resolver& r, size_t recursion_depth)\n               :obj_mvo(o), resolver(r), recursion_depth(recursion_depth){}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,2 +1,2 @@\n-add_static_variant( mutable_variant_object& o, Resolver& r)\n-               :obj_mvo(o), resolver(r){}\n+add_static_variant( mutable_variant_object& o, Resolver& r, size_t recursion_depth)\n+               :obj_mvo(o), resolver(r), recursion_depth(recursion_depth){}",
        "diff_line_info": {
            "deleted_lines": [
                "add_static_variant( mutable_variant_object& o, Resolver& r)",
                "               :obj_mvo(o), resolver(r){}"
            ],
            "added_lines": [
                "add_static_variant( mutable_variant_object& o, Resolver& r, size_t recursion_depth)",
                "               :obj_mvo(o), resolver(r), recursion_depth(recursion_depth){}"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/abi_to_variant_visitor",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d",
        "commit_title": "Add limit to recursion",
        "commit_text": "",
        "func_before": "abi_to_variant_visitor( mutable_variant_object& _mvo, const T& _val, Resolver _resolver )\n         :_vo(_mvo)\n         ,_val(_val)\n         ,_resolver(_resolver)\n         {}",
        "func": "abi_to_variant_visitor( mutable_variant_object& _mvo, const T& _val, Resolver _resolver, size_t _recursion_depth )\n         :_vo(_mvo)\n         ,_val(_val)\n         ,_resolver(_resolver)\n         ,_recursion_depth(_recursion_depth)\n         {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n-abi_to_variant_visitor( mutable_variant_object& _mvo, const T& _val, Resolver _resolver )\n+abi_to_variant_visitor( mutable_variant_object& _mvo, const T& _val, Resolver _resolver, size_t _recursion_depth )\n          :_vo(_mvo)\n          ,_val(_val)\n          ,_resolver(_resolver)\n+         ,_recursion_depth(_recursion_depth)\n          {}",
        "diff_line_info": {
            "deleted_lines": [
                "abi_to_variant_visitor( mutable_variant_object& _mvo, const T& _val, Resolver _resolver )"
            ],
            "added_lines": [
                "abi_to_variant_visitor( mutable_variant_object& _mvo, const T& _val, Resolver _resolver, size_t _recursion_depth )",
                "         ,_recursion_depth(_recursion_depth)"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/extract",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cc5722858cc24808f7bd4fa699718eec0240b3a2",
        "commit_title": "Pass recursion_depth to binary_to_variant and variant_to_binary",
        "commit_text": "",
        "func_before": "static void extract( const variant& v, action& act, Resolver resolver, size_t recursion_depth )\n      {\n         FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n         const variant_object& vo = v.get_object();\n         EOS_ASSERT(vo.contains(\"account\"), packed_transaction_type_exception, \"Missing account\");\n         EOS_ASSERT(vo.contains(\"name\"), packed_transaction_type_exception, \"Missing name\");\n         from_variant(vo[\"account\"], act.account);\n         from_variant(vo[\"name\"], act.name);\n\n         if (vo.contains(\"authorization\")) {\n            from_variant(vo[\"authorization\"], act.authorization);\n         }\n\n         bool valid_empty_data = false;\n         if( vo.contains( \"data\" ) ) {\n            const auto& data = vo[\"data\"];\n            if( data.is_string() ) {\n               from_variant(data, act.data);\n               valid_empty_data = act.data.empty();\n            } else if ( data.is_object() ) {\n               auto abi = resolver(act.account);\n               if (abi.valid()) {\n                  auto type = abi->get_action_type(act.name);\n                  if (!type.empty()) {\n                     act.data = std::move( abi->variant_to_binary( type, data ));\n                     valid_empty_data = act.data.empty();\n                  }\n               }\n            }\n         }\n\n         if( !valid_empty_data && act.data.empty() ) {\n            if( vo.contains( \"hex_data\" ) ) {\n               const auto& data = vo[\"hex_data\"];\n               if( data.is_string() ) {\n                  from_variant(data, act.data);\n               }\n            }\n         }\n\n         EOS_ASSERT(valid_empty_data || !act.data.empty(), packed_transaction_type_exception,\n                    \"Failed to deserialize data for ${account}:${name}\", (\"account\", act.account)(\"name\", act.name));\n      }",
        "func": "static void extract( const variant& v, action& act, Resolver resolver, size_t recursion_depth )\n      {\n         FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n         const variant_object& vo = v.get_object();\n         EOS_ASSERT(vo.contains(\"account\"), packed_transaction_type_exception, \"Missing account\");\n         EOS_ASSERT(vo.contains(\"name\"), packed_transaction_type_exception, \"Missing name\");\n         from_variant(vo[\"account\"], act.account);\n         from_variant(vo[\"name\"], act.name);\n\n         if (vo.contains(\"authorization\")) {\n            from_variant(vo[\"authorization\"], act.authorization);\n         }\n\n         bool valid_empty_data = false;\n         if( vo.contains( \"data\" ) ) {\n            const auto& data = vo[\"data\"];\n            if( data.is_string() ) {\n               from_variant(data, act.data);\n               valid_empty_data = act.data.empty();\n            } else if ( data.is_object() ) {\n               auto abi = resolver(act.account);\n               if (abi.valid()) {\n                  auto type = abi->get_action_type(act.name);\n                  if (!type.empty()) {\n                     act.data = std::move( abi->_variant_to_binary( type, data, recursion_depth ));\n                     valid_empty_data = act.data.empty();\n                  }\n               }\n            }\n         }\n\n         if( !valid_empty_data && act.data.empty() ) {\n            if( vo.contains( \"hex_data\" ) ) {\n               const auto& data = vo[\"hex_data\"];\n               if( data.is_string() ) {\n                  from_variant(data, act.data);\n               }\n            }\n         }\n\n         EOS_ASSERT(valid_empty_data || !act.data.empty(), packed_transaction_type_exception,\n                    \"Failed to deserialize data for ${account}:${name}\", (\"account\", act.account)(\"name\", act.name));\n      }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,7 +22,7 @@\n                if (abi.valid()) {\n                   auto type = abi->get_action_type(act.name);\n                   if (!type.empty()) {\n-                     act.data = std::move( abi->variant_to_binary( type, data ));\n+                     act.data = std::move( abi->_variant_to_binary( type, data, recursion_depth ));\n                      valid_empty_data = act.data.empty();\n                   }\n                }",
        "diff_line_info": {
            "deleted_lines": [
                "                     act.data = std::move( abi->variant_to_binary( type, data ));"
            ],
            "added_lines": [
                "                     act.data = std::move( abi->_variant_to_binary( type, data, recursion_depth ));"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1000618",
        "func_name": "EOSIO/eos/add",
        "description": "EOSIO/eos eos version after commit f1545dd0ae2b77580c2236fdb70ae7138d2c7168 contains a stack overflow vulnerability in abi_serializer that can result in attack eos network node. This attack appear to be exploitable via network request. This vulnerability appears to have been fixed in after commit cf7209e703e6d3f7a5413e0cb1fe88a4d8e4b38d .",
        "git_url": "https://github.com/EOSIO/eos/commit/cc5722858cc24808f7bd4fa699718eec0240b3a2",
        "commit_title": "Pass recursion_depth to binary_to_variant and variant_to_binary",
        "commit_text": "",
        "func_before": "static void add(mutable_variant_object &out, const char* name, const action& act, Resolver resolver, size_t recursion_depth) {\n         FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n         mutable_variant_object mvo;\n         mvo(\"account\", act.account);\n         mvo(\"name\", act.name);\n         mvo(\"authorization\", act.authorization);\n\n         auto abi = resolver(act.account);\n         if (abi.valid()) {\n            auto type = abi->get_action_type(act.name);\n            if (!type.empty()) {\n               try {\n                  mvo( \"data\", abi->binary_to_variant( type, act.data ));\n                  mvo(\"hex_data\", act.data);\n               } catch(...) {\n                  // any failure to serialize data, then leave as not serailzed\n                  mvo(\"data\", act.data);\n               }\n            } else {\n               mvo(\"data\", act.data);\n            }\n         } else {\n            mvo(\"data\", act.data);\n         }\n         out(name, std::move(mvo));\n      }",
        "func": "static void add(mutable_variant_object &out, const char* name, const action& act, Resolver resolver, size_t recursion_depth) {\n         FC_ASSERT( ++recursion_depth < abi_serializer::max_recursion_depth, \"recursive definition, max_recursion_depth\" );\n         mutable_variant_object mvo;\n         mvo(\"account\", act.account);\n         mvo(\"name\", act.name);\n         mvo(\"authorization\", act.authorization);\n\n         auto abi = resolver(act.account);\n         if (abi.valid()) {\n            auto type = abi->get_action_type(act.name);\n            if (!type.empty()) {\n               try {\n                  mvo( \"data\", abi->_binary_to_variant( type, act.data, recursion_depth ));\n                  mvo(\"hex_data\", act.data);\n               } catch(...) {\n                  // any failure to serialize data, then leave as not serailzed\n                  mvo(\"data\", act.data);\n               }\n            } else {\n               mvo(\"data\", act.data);\n            }\n         } else {\n            mvo(\"data\", act.data);\n         }\n         out(name, std::move(mvo));\n      }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n             auto type = abi->get_action_type(act.name);\n             if (!type.empty()) {\n                try {\n-                  mvo( \"data\", abi->binary_to_variant( type, act.data ));\n+                  mvo( \"data\", abi->_binary_to_variant( type, act.data, recursion_depth ));\n                   mvo(\"hex_data\", act.data);\n                } catch(...) {\n                   // any failure to serialize data, then leave as not serailzed",
        "diff_line_info": {
            "deleted_lines": [
                "                  mvo( \"data\", abi->binary_to_variant( type, act.data ));"
            ],
            "added_lines": [
                "                  mvo( \"data\", abi->_binary_to_variant( type, act.data, recursion_depth ));"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-16426",
        "func_name": "OpenSC/iasecc_select_file",
        "description": "Endless recursion when handling responses from an IAS-ECC card in iasecc_select_file in libopensc/card-iasecc.c in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to hang or crash the opensc library using programs.",
        "git_url": "https://github.com/OpenSC/OpenSC/commit/03628449b75a93787eb2359412a3980365dda49b",
        "commit_title": "iasecc: fixed unbound recursion",
        "commit_text": "",
        "func_before": "static int\niasecc_select_file(struct sc_card *card, const struct sc_path *path,\n\t\t struct sc_file **file_out)\n{\n\tstruct sc_context *ctx = card->ctx;\n\tstruct sc_path lpath;\n\tint cache_valid = card->cache.valid, df_from_cache = 0;\n\tint rv, ii;\n\n\tLOG_FUNC_CALLED(ctx);\n\tmemcpy(&lpath, path, sizeof(struct sc_path));\n\tif (file_out)\n\t\t*file_out = NULL;\n\n\tsc_log(ctx,\n\t       \"iasecc_select_file(card:%p) path.len %\"SC_FORMAT_LEN_SIZE_T\"u; path.type %i; aid_len %\"SC_FORMAT_LEN_SIZE_T\"u\",\n\t       card, path->len, path->type, path->aid.len);\n\tsc_log(ctx, \"iasecc_select_file() path:%s\", sc_print_path(path));\n\n\tsc_print_cache(card);\n\tif (lpath.len >= 2 && lpath.value[0] == 0x3F && lpath.value[1] == 0x00)   {\n\t\tsc_log(ctx, \"EF.ATR(aid:'%s')\", card->ef_atr ? sc_dump_hex(card->ef_atr->aid.value, card->ef_atr->aid.len) : \"\");\n\n\t\trv = iasecc_select_mf(card, file_out);\n\t\tLOG_TEST_RET(ctx, rv, \"MF selection error\");\n\n\t\tif (lpath.len >= 2 && lpath.value[0] == 0x3F && lpath.value[1] == 0x00)\t   {\n\t\t\tmemmove(&lpath.value[0], &lpath.value[2], lpath.len - 2);\n\t\t\tlpath.len -=  2;\n\t\t}\n\t}\n\n\tif (lpath.aid.len)\t{\n\t\tstruct sc_file *file = NULL;\n\t\tstruct sc_path ppath;\n\n\t\tsc_log(ctx,\n\t\t       \"iasecc_select_file() select parent AID:%p/%\"SC_FORMAT_LEN_SIZE_T\"u\",\n\t\t       lpath.aid.value, lpath.aid.len);\n\t\tsc_log(ctx, \"iasecc_select_file() select parent AID:%s\", sc_dump_hex(lpath.aid.value, lpath.aid.len));\n\t\tmemset(&ppath, 0, sizeof(ppath));\n\t\tmemcpy(ppath.value, lpath.aid.value, lpath.aid.len);\n\t\tppath.len = lpath.aid.len;\n\t\tppath.type = SC_PATH_TYPE_DF_NAME;\n\n\t\tif (card->cache.valid && card->cache.current_df\n\t\t\t\t&& card->cache.current_df->path.len == lpath.aid.len\n\t\t\t\t&& !memcmp(card->cache.current_df->path.value, lpath.aid.value, lpath.aid.len))\n\t\t\tdf_from_cache = 1;\n\n\t\trv = iasecc_select_file(card, &ppath, &file);\n\t\tLOG_TEST_RET(ctx, rv, \"select AID path failed\");\n\n\t\tif (file_out)\n\t\t\t*file_out = file;\n\t\telse\n\t\t   sc_file_free(file);\n\n\t\tif (lpath.type == SC_PATH_TYPE_DF_NAME)\n\t\t\tlpath.type = SC_PATH_TYPE_FROM_CURRENT;\n\t}\n\n\tif (lpath.type == SC_PATH_TYPE_PATH)\n\t\tlpath.type = SC_PATH_TYPE_FROM_CURRENT;\n\n\tif (!lpath.len)\n\t\tLOG_FUNC_RETURN(ctx, SC_SUCCESS);\n\n\tsc_print_cache(card);\n\n\tif (card->cache.valid && card->cache.current_df && lpath.type == SC_PATH_TYPE_DF_NAME\n\t\t\t&& card->cache.current_df->path.len == lpath.len\n\t\t\t&& !memcmp(card->cache.current_df->path.value, lpath.value, lpath.len))   {\n\t\tsc_log(ctx, \"returns current DF path %s\", sc_print_path(&card->cache.current_df->path));\n\t\tif (file_out)   {\n\t\t\tsc_file_free(*file_out);\n\t\t\tsc_file_dup(file_out, card->cache.current_df);\n\t\t}\n\n\t\tsc_print_cache(card);\n\t\tLOG_FUNC_RETURN(ctx, SC_SUCCESS);\n\t}\n\n\tdo   {\n\t\tstruct sc_apdu apdu;\n\t\tstruct sc_file *file = NULL;\n\t\tunsigned char rbuf[SC_MAX_APDU_BUFFER_SIZE];\n\t\tint pathlen = lpath.len;\n\n\t\tsc_format_apdu(card, &apdu, SC_APDU_CASE_4_SHORT, 0xA4, 0x00, 0x00);\n\n\t\tif (card->type != SC_CARD_TYPE_IASECC_GEMALTO\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_OBERTHUR\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_SAGEM\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_AMOS\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_MI\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_MI2)\n\t\t\tLOG_TEST_RET(ctx, SC_ERROR_NOT_SUPPORTED, \"Unsupported card\");\n\n\t\tif (lpath.type == SC_PATH_TYPE_FILE_ID)   {\n\t\t\tapdu.p1 = 0x02;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_OBERTHUR)   {\n\t\t\t\tapdu.p1 = 0x01;\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\t}\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_AMOS)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI2)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_FROM_CURRENT)  {\n\t\t\tapdu.p1 = 0x09;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_OBERTHUR)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_AMOS)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI2)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_PARENT)   {\n\t\t\tapdu.p1 = 0x03;\n\t\t\tpathlen = 0;\n\t\t\tapdu.cse = SC_APDU_CASE_2_SHORT;\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_DF_NAME)   {\n\t\t\tapdu.p1 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_AMOS)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI2)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t}\n\t\telse   {\n\t\t\tsc_log(ctx, \"Invalid PATH type: 0x%X\", lpath.type);\n\t\t\tLOG_TEST_RET(ctx, SC_ERROR_NOT_SUPPORTED, \"iasecc_select_file() invalid PATH type\");\n\t\t}\n\n\t\tfor (ii=0; ii<2; ii++)   {\n\t\t\tapdu.lc = pathlen;\n\t\t\tapdu.data = lpath.value;\n\t\t\tapdu.datalen = pathlen;\n\n\t\t\tapdu.resp = rbuf;\n\t\t\tapdu.resplen = sizeof(rbuf);\n\t\t\tapdu.le = 256;\n\n\t\t\trv = sc_transmit_apdu(card, &apdu);\n\t\t\tLOG_TEST_RET(ctx, rv, \"APDU transmit failed\");\n\t\t\trv = sc_check_sw(card, apdu.sw1, apdu.sw2);\n\t\t\tif (rv == SC_ERROR_INCORRECT_PARAMETERS &&\n\t\t\t\t\tlpath.type == SC_PATH_TYPE_DF_NAME && apdu.p2 == 0x00)   {\n\t\t\t\tapdu.p2 = 0x0C;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (ii)   {\n\t\t\t\t/* 'SELECT AID' do not returned FCP. Try to emulate. */\n\t\t\t\tapdu.resplen = sizeof(rbuf);\n\t\t\t\trv = iasecc_emulate_fcp(ctx, &apdu);\n\t\t\t\tLOG_TEST_RET(ctx, rv, \"Failed to emulate DF FCP\");\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Using of the cached DF and EF can cause problems in the multi-thread environment.\n\t\t * FIXME: introduce config. option that invalidates this cache outside the locked card session,\n\t\t *        (or invent something else)\n\t\t */\n\t\tif (rv == SC_ERROR_FILE_NOT_FOUND && cache_valid && df_from_cache)   {\n\t\t\tsc_invalidate_cache(card);\n\t\t\tsc_log(ctx, \"iasecc_select_file() file not found, retry without cached DF\");\n\t\t\tif (file_out)   {\n\t\t\t\tsc_file_free(*file_out);\n\t\t\t\t*file_out = NULL;\n\t\t\t}\n\t\t\trv = iasecc_select_file(card, path, file_out);\n\t\t\tLOG_FUNC_RETURN(ctx, rv);\n\t\t}\n\n\t\tLOG_TEST_RET(ctx, rv, \"iasecc_select_file() check SW failed\");\n\n\t\tsc_log(ctx,\n\t\t       \"iasecc_select_file() apdu.resp %\"SC_FORMAT_LEN_SIZE_T\"u\",\n\t\t       apdu.resplen);\n\t\tif (apdu.resplen)   {\n\t\t\tsc_log(ctx, \"apdu.resp %02X:%02X:%02X...\", apdu.resp[0], apdu.resp[1], apdu.resp[2]);\n\n\t\t\tswitch (apdu.resp[0]) {\n\t\t\tcase 0x62:\n\t\t\tcase 0x6F:\n\t\t\t\tfile = sc_file_new();\n\t\t\t\tif (file == NULL)\n\t\t\t\t\tLOG_FUNC_RETURN(ctx, SC_ERROR_OUT_OF_MEMORY);\n\t\t\t\tfile->path = lpath;\n\n\t\t\t\trv = iasecc_process_fci(card, file, apdu.resp, apdu.resplen);\n\t\t\t\tif (rv)\n\t\t\t\t\tLOG_FUNC_RETURN(ctx, rv);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tLOG_FUNC_RETURN(ctx, SC_ERROR_UNKNOWN_DATA_RECEIVED);\n\t\t\t}\n\n\t\t\tsc_log(ctx, \"FileType %i\", file->type);\n\t\t\tif (file->type == SC_FILE_TYPE_DF)   {\n\t\t\t\tif (card->cache.valid)\n\t\t\t\t\tsc_file_free(card->cache.current_df);\n\t\t\t\tcard->cache.current_df = NULL;\n\n\n\t\t\t\tif (card->cache.valid)\n\t\t\t\t\tsc_file_free(card->cache.current_ef);\n\t\t\t\tcard->cache.current_ef = NULL;\n\n\t\t\t\tsc_file_dup(&card->cache.current_df, file);\n\t\t\t\tcard->cache.valid = 1;\n\t\t\t}\n\t\t\telse   {\n\t\t\t\tif (card->cache.valid)\n\t\t\t\t\tsc_file_free(card->cache.current_ef);\n\n\t\t\t\tcard->cache.current_ef = NULL;\n\n\t\t\t\tsc_file_dup(&card->cache.current_ef, file);\n\t\t\t}\n\n\t\t\tif (file_out)   {\n\t\t\t\tsc_file_free(*file_out);\n\t\t\t\t*file_out = file;\n\t\t\t}\n\t\t\telse   {\n\t\t\t\tsc_file_free(file);\n\t\t\t}\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_DF_NAME)   {\n\t\t\tsc_file_free(card->cache.current_df);\n\t\t\tcard->cache.current_df = NULL;\n\n\t\t\tsc_file_free(card->cache.current_ef);\n\t\t\tcard->cache.current_ef = NULL;\n\n\t\t\tcard->cache.valid = 1;\n\t\t}\n\t} while(0);\n\n\tsc_print_cache(card);\n\tLOG_FUNC_RETURN(ctx, SC_SUCCESS);\n}",
        "func": "static int\niasecc_select_file(struct sc_card *card, const struct sc_path *path,\n\t\t struct sc_file **file_out)\n{\n\tstruct sc_context *ctx = card->ctx;\n\tstruct sc_path lpath;\n\tint cache_valid = card->cache.valid, df_from_cache = 0;\n\tint rv, ii;\n\n\tLOG_FUNC_CALLED(ctx);\n\tmemcpy(&lpath, path, sizeof(struct sc_path));\n\tif (file_out)\n\t\t*file_out = NULL;\n\n\tsc_log(ctx,\n\t       \"iasecc_select_file(card:%p) path.len %\"SC_FORMAT_LEN_SIZE_T\"u; path.type %i; aid_len %\"SC_FORMAT_LEN_SIZE_T\"u\",\n\t       card, path->len, path->type, path->aid.len);\n\tsc_log(ctx, \"iasecc_select_file() path:%s\", sc_print_path(path));\n\n\tsc_print_cache(card);\n\tif (path->type != SC_PATH_TYPE_DF_NAME\n\t\t\t&& lpath.len >= 2\n\t\t\t&& lpath.value[0] == 0x3F && lpath.value[1] == 0x00)   {\n\t\tsc_log(ctx, \"EF.ATR(aid:'%s')\", card->ef_atr ? sc_dump_hex(card->ef_atr->aid.value, card->ef_atr->aid.len) : \"\");\n\n\t\trv = iasecc_select_mf(card, file_out);\n\t\tLOG_TEST_RET(ctx, rv, \"MF selection error\");\n\n\t\tmemmove(&lpath.value[0], &lpath.value[2], lpath.len - 2);\n\t\tlpath.len -=  2;\n\t}\n\n\tif (lpath.aid.len)\t{\n\t\tstruct sc_file *file = NULL;\n\t\tstruct sc_path ppath;\n\n\t\tsc_log(ctx,\n\t\t       \"iasecc_select_file() select parent AID:%p/%\"SC_FORMAT_LEN_SIZE_T\"u\",\n\t\t       lpath.aid.value, lpath.aid.len);\n\t\tsc_log(ctx, \"iasecc_select_file() select parent AID:%s\", sc_dump_hex(lpath.aid.value, lpath.aid.len));\n\t\tmemset(&ppath, 0, sizeof(ppath));\n\t\tmemcpy(ppath.value, lpath.aid.value, lpath.aid.len);\n\t\tppath.len = lpath.aid.len;\n\t\tppath.type = SC_PATH_TYPE_DF_NAME;\n\n\t\tif (card->cache.valid && card->cache.current_df\n\t\t\t\t&& card->cache.current_df->path.len == lpath.aid.len\n\t\t\t\t&& !memcmp(card->cache.current_df->path.value, lpath.aid.value, lpath.aid.len))\n\t\t\tdf_from_cache = 1;\n\n\t\trv = iasecc_select_file(card, &ppath, &file);\n\t\tLOG_TEST_RET(ctx, rv, \"select AID path failed\");\n\n\t\tif (file_out)\n\t\t\t*file_out = file;\n\t\telse\n\t\t   sc_file_free(file);\n\n\t\tif (lpath.type == SC_PATH_TYPE_DF_NAME)\n\t\t\tlpath.type = SC_PATH_TYPE_FROM_CURRENT;\n\t}\n\n\tif (lpath.type == SC_PATH_TYPE_PATH)\n\t\tlpath.type = SC_PATH_TYPE_FROM_CURRENT;\n\n\tif (!lpath.len)\n\t\tLOG_FUNC_RETURN(ctx, SC_SUCCESS);\n\n\tsc_print_cache(card);\n\n\tif (card->cache.valid && card->cache.current_df && lpath.type == SC_PATH_TYPE_DF_NAME\n\t\t\t&& card->cache.current_df->path.len == lpath.len\n\t\t\t&& !memcmp(card->cache.current_df->path.value, lpath.value, lpath.len))   {\n\t\tsc_log(ctx, \"returns current DF path %s\", sc_print_path(&card->cache.current_df->path));\n\t\tif (file_out)   {\n\t\t\tsc_file_free(*file_out);\n\t\t\tsc_file_dup(file_out, card->cache.current_df);\n\t\t}\n\n\t\tsc_print_cache(card);\n\t\tLOG_FUNC_RETURN(ctx, SC_SUCCESS);\n\t}\n\n\tdo   {\n\t\tstruct sc_apdu apdu;\n\t\tstruct sc_file *file = NULL;\n\t\tunsigned char rbuf[SC_MAX_APDU_BUFFER_SIZE];\n\t\tint pathlen = lpath.len;\n\n\t\tsc_format_apdu(card, &apdu, SC_APDU_CASE_4_SHORT, 0xA4, 0x00, 0x00);\n\n\t\tif (card->type != SC_CARD_TYPE_IASECC_GEMALTO\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_OBERTHUR\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_SAGEM\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_AMOS\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_MI\n\t\t\t\t&& card->type != SC_CARD_TYPE_IASECC_MI2)\n\t\t\tLOG_TEST_RET(ctx, SC_ERROR_NOT_SUPPORTED, \"Unsupported card\");\n\n\t\tif (lpath.type == SC_PATH_TYPE_FILE_ID)   {\n\t\t\tapdu.p1 = 0x02;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_OBERTHUR)   {\n\t\t\t\tapdu.p1 = 0x01;\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\t}\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_AMOS)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI2)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_FROM_CURRENT)  {\n\t\t\tapdu.p1 = 0x09;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_OBERTHUR)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_AMOS)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI2)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_PARENT)   {\n\t\t\tapdu.p1 = 0x03;\n\t\t\tpathlen = 0;\n\t\t\tapdu.cse = SC_APDU_CASE_2_SHORT;\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_DF_NAME)   {\n\t\t\tapdu.p1 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_AMOS)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t\tif (card->type == SC_CARD_TYPE_IASECC_MI2)\n\t\t\t\tapdu.p2 = 0x04;\n\t\t}\n\t\telse   {\n\t\t\tsc_log(ctx, \"Invalid PATH type: 0x%X\", lpath.type);\n\t\t\tLOG_TEST_RET(ctx, SC_ERROR_NOT_SUPPORTED, \"iasecc_select_file() invalid PATH type\");\n\t\t}\n\n\t\tfor (ii=0; ii<2; ii++)   {\n\t\t\tapdu.lc = pathlen;\n\t\t\tapdu.data = lpath.value;\n\t\t\tapdu.datalen = pathlen;\n\n\t\t\tapdu.resp = rbuf;\n\t\t\tapdu.resplen = sizeof(rbuf);\n\t\t\tapdu.le = 256;\n\n\t\t\trv = sc_transmit_apdu(card, &apdu);\n\t\t\tLOG_TEST_RET(ctx, rv, \"APDU transmit failed\");\n\t\t\trv = sc_check_sw(card, apdu.sw1, apdu.sw2);\n\t\t\tif (rv == SC_ERROR_INCORRECT_PARAMETERS &&\n\t\t\t\t\tlpath.type == SC_PATH_TYPE_DF_NAME && apdu.p2 == 0x00)   {\n\t\t\t\tapdu.p2 = 0x0C;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (ii)   {\n\t\t\t\t/* 'SELECT AID' do not returned FCP. Try to emulate. */\n\t\t\t\tapdu.resplen = sizeof(rbuf);\n\t\t\t\trv = iasecc_emulate_fcp(ctx, &apdu);\n\t\t\t\tLOG_TEST_RET(ctx, rv, \"Failed to emulate DF FCP\");\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Using of the cached DF and EF can cause problems in the multi-thread environment.\n\t\t * FIXME: introduce config. option that invalidates this cache outside the locked card session,\n\t\t *        (or invent something else)\n\t\t */\n\t\tif (rv == SC_ERROR_FILE_NOT_FOUND && cache_valid && df_from_cache)   {\n\t\t\tsc_invalidate_cache(card);\n\t\t\tsc_log(ctx, \"iasecc_select_file() file not found, retry without cached DF\");\n\t\t\tif (file_out)   {\n\t\t\t\tsc_file_free(*file_out);\n\t\t\t\t*file_out = NULL;\n\t\t\t}\n\t\t\trv = iasecc_select_file(card, path, file_out);\n\t\t\tLOG_FUNC_RETURN(ctx, rv);\n\t\t}\n\n\t\tLOG_TEST_RET(ctx, rv, \"iasecc_select_file() check SW failed\");\n\n\t\tsc_log(ctx,\n\t\t       \"iasecc_select_file() apdu.resp %\"SC_FORMAT_LEN_SIZE_T\"u\",\n\t\t       apdu.resplen);\n\t\tif (apdu.resplen)   {\n\t\t\tsc_log(ctx, \"apdu.resp %02X:%02X:%02X...\", apdu.resp[0], apdu.resp[1], apdu.resp[2]);\n\n\t\t\tswitch (apdu.resp[0]) {\n\t\t\tcase 0x62:\n\t\t\tcase 0x6F:\n\t\t\t\tfile = sc_file_new();\n\t\t\t\tif (file == NULL)\n\t\t\t\t\tLOG_FUNC_RETURN(ctx, SC_ERROR_OUT_OF_MEMORY);\n\t\t\t\tfile->path = lpath;\n\n\t\t\t\trv = iasecc_process_fci(card, file, apdu.resp, apdu.resplen);\n\t\t\t\tif (rv)\n\t\t\t\t\tLOG_FUNC_RETURN(ctx, rv);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tLOG_FUNC_RETURN(ctx, SC_ERROR_UNKNOWN_DATA_RECEIVED);\n\t\t\t}\n\n\t\t\tsc_log(ctx, \"FileType %i\", file->type);\n\t\t\tif (file->type == SC_FILE_TYPE_DF)   {\n\t\t\t\tif (card->cache.valid)\n\t\t\t\t\tsc_file_free(card->cache.current_df);\n\t\t\t\tcard->cache.current_df = NULL;\n\n\n\t\t\t\tif (card->cache.valid)\n\t\t\t\t\tsc_file_free(card->cache.current_ef);\n\t\t\t\tcard->cache.current_ef = NULL;\n\n\t\t\t\tsc_file_dup(&card->cache.current_df, file);\n\t\t\t\tcard->cache.valid = 1;\n\t\t\t}\n\t\t\telse   {\n\t\t\t\tif (card->cache.valid)\n\t\t\t\t\tsc_file_free(card->cache.current_ef);\n\n\t\t\t\tcard->cache.current_ef = NULL;\n\n\t\t\t\tsc_file_dup(&card->cache.current_ef, file);\n\t\t\t}\n\n\t\t\tif (file_out)   {\n\t\t\t\tsc_file_free(*file_out);\n\t\t\t\t*file_out = file;\n\t\t\t}\n\t\t\telse   {\n\t\t\t\tsc_file_free(file);\n\t\t\t}\n\t\t}\n\t\telse if (lpath.type == SC_PATH_TYPE_DF_NAME)   {\n\t\t\tsc_file_free(card->cache.current_df);\n\t\t\tcard->cache.current_df = NULL;\n\n\t\t\tsc_file_free(card->cache.current_ef);\n\t\t\tcard->cache.current_ef = NULL;\n\n\t\t\tcard->cache.valid = 1;\n\t\t}\n\t} while(0);\n\n\tsc_print_cache(card);\n\tLOG_FUNC_RETURN(ctx, SC_SUCCESS);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,16 +18,16 @@\n \tsc_log(ctx, \"iasecc_select_file() path:%s\", sc_print_path(path));\n \n \tsc_print_cache(card);\n-\tif (lpath.len >= 2 && lpath.value[0] == 0x3F && lpath.value[1] == 0x00)   {\n+\tif (path->type != SC_PATH_TYPE_DF_NAME\n+\t\t\t&& lpath.len >= 2\n+\t\t\t&& lpath.value[0] == 0x3F && lpath.value[1] == 0x00)   {\n \t\tsc_log(ctx, \"EF.ATR(aid:'%s')\", card->ef_atr ? sc_dump_hex(card->ef_atr->aid.value, card->ef_atr->aid.len) : \"\");\n \n \t\trv = iasecc_select_mf(card, file_out);\n \t\tLOG_TEST_RET(ctx, rv, \"MF selection error\");\n \n-\t\tif (lpath.len >= 2 && lpath.value[0] == 0x3F && lpath.value[1] == 0x00)\t   {\n-\t\t\tmemmove(&lpath.value[0], &lpath.value[2], lpath.len - 2);\n-\t\t\tlpath.len -=  2;\n-\t\t}\n+\t\tmemmove(&lpath.value[0], &lpath.value[2], lpath.len - 2);\n+\t\tlpath.len -=  2;\n \t}\n \n \tif (lpath.aid.len)\t{",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (lpath.len >= 2 && lpath.value[0] == 0x3F && lpath.value[1] == 0x00)   {",
                "\t\tif (lpath.len >= 2 && lpath.value[0] == 0x3F && lpath.value[1] == 0x00)\t   {",
                "\t\t\tmemmove(&lpath.value[0], &lpath.value[2], lpath.len - 2);",
                "\t\t\tlpath.len -=  2;",
                "\t\t}"
            ],
            "added_lines": [
                "\tif (path->type != SC_PATH_TYPE_DF_NAME",
                "\t\t\t&& lpath.len >= 2",
                "\t\t\t&& lpath.value[0] == 0x3F && lpath.value[1] == 0x00)   {",
                "\t\tmemmove(&lpath.value[0], &lpath.value[2], lpath.len - 2);",
                "\t\tlpath.len -=  2;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-31794",
        "func_name": "ArtifexSoftware/mupdf/gatherresourceinfo",
        "description": "MuPDF v1.21.1 was discovered to contain an infinite recursion in the component pdf_mark_list_push. This vulnerability allows attackers to cause a Denial of Service (DoS) via a crafted PDF file.",
        "git_url": "https://github.com/ArtifexSoftware/mupdf/commit/c0015401693b58e2deb5d75c39f27bc1216e47c6",
        "commit_title": "Bug 706506: Fix infinite recursion in mutool info.",
        "commit_text": " 2 separate problems here.  Firstly, pdf_mark_list_push fails to copy the pushed data from local_list to the newly malloced block when we first move from local storage to malloced storage.  (Also, while we are here, there is no point in storing 0 entries in the list as they will never be checked!)  Secondly, while gatherresourceinfo is supposed to be called with indirected objects, it can (as is the case with the given fuzzed file) be called with direct references. These don't put anything sane in the cycle checker.  Thus by using (legal) indirections from (say) the Font resource entry back to something that contains the original resource entry, we can get cycles that we don't detect.  Fix this by pushing such entries onto the mark list.",
        "func_before": "static void\ngatherresourceinfo(fz_context *ctx, pdf_mark_list *mark_list, globals *glo, int page, pdf_obj *obj, int show)\n{\n\tpdf_obj *rsrc;\n\tpdf_obj *pageref;\n\tpdf_obj *font;\n\tpdf_obj *xobj;\n\tpdf_obj *shade;\n\tpdf_obj *pattern;\n\tint i;\n\n\t/* stop on cyclic resource dependencies */\n\tif (pdf_mark_list_push(ctx, mark_list, obj))\n\t\treturn;\n\n\trsrc = pdf_dict_get(ctx, obj, PDF_NAME(Resources));\n\n\tpageref = pdf_lookup_page_obj(ctx, glo->doc, page-1);\n\tif (!pageref)\n\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"cannot retrieve info from page %d\", page);\n\n\tfont = pdf_dict_get(ctx, rsrc, PDF_NAME(Font));\n\tif (show & FONTS && font)\n\t{\n\t\tint n;\n\n\t\tgatherfonts(ctx, glo, page, pageref, font);\n\t\tn = pdf_dict_len(ctx, font);\n\t\tfor (i = 0; i < n; i++)\n\t\t{\n\t\t\tgatherresourceinfo(ctx, mark_list, glo, page, pdf_dict_get_val(ctx, font, i), show);\n\t\t}\n\t}\n\n\txobj = pdf_dict_get(ctx, rsrc, PDF_NAME(XObject));\n\tif (show & (IMAGES|XOBJS) && xobj)\n\t{\n\t\tint n;\n\n\t\tif (show & IMAGES)\n\t\t\tgatherimages(ctx, glo, page, pageref, xobj);\n\t\tif (show & XOBJS)\n\t\t{\n\t\t\tgatherforms(ctx, glo, page, pageref, xobj);\n\t\t\tgatherpsobjs(ctx, glo, page, pageref, xobj);\n\t\t}\n\t\tn = pdf_dict_len(ctx, xobj);\n\t\tfor (i = 0; i < n; i++)\n\t\t{\n\t\t\tgatherresourceinfo(ctx, mark_list, glo, page, pdf_dict_get_val(ctx, xobj, i), show);\n\t\t}\n\t}\n\n\tshade = pdf_dict_get(ctx, rsrc, PDF_NAME(Shading));\n\tif (show & SHADINGS && shade)\n\t\tgathershadings(ctx, glo, page, pageref, shade);\n\n\tpattern = pdf_dict_get(ctx, rsrc, PDF_NAME(Pattern));\n\tif (show & PATTERNS && pattern)\n\t{\n\t\tint n;\n\t\tgatherpatterns(ctx, glo, page, pageref, pattern);\n\t\tn = pdf_dict_len(ctx, pattern);\n\t\tfor (i = 0; i < n; i++)\n\t\t{\n\t\t\tgatherresourceinfo(ctx, mark_list, glo, page, pdf_dict_get_val(ctx, pattern, i), show);\n\t\t}\n\t}\n}",
        "func": "static void\ngatherresourceinfo(fz_context *ctx, pdf_mark_list *mark_list, globals *glo, int page, pdf_obj *obj, int show)\n{\n\tpdf_obj *rsrc;\n\tpdf_obj *pageref;\n\tpdf_obj *font;\n\tpdf_obj *xobj;\n\tpdf_obj *shade;\n\tpdf_obj *pattern;\n\tint i;\n\n\t/* stop on cyclic resource dependencies */\n\tif (pdf_mark_list_push(ctx, mark_list, obj))\n\t\treturn;\n\n\trsrc = pdf_dict_get(ctx, obj, PDF_NAME(Resources));\n\n\tpageref = pdf_lookup_page_obj(ctx, glo->doc, page-1);\n\tif (!pageref)\n\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"cannot retrieve info from page %d\", page);\n\n\tfont = pdf_dict_get(ctx, rsrc, PDF_NAME(Font));\n\tif (show & FONTS && font && !pdf_mark_list_push(ctx, mark_list, font))\n\t{\n\t\tint n;\n\n\t\tgatherfonts(ctx, glo, page, pageref, font);\n\t\tn = pdf_dict_len(ctx, font);\n\t\tfor (i = 0; i < n; i++)\n\t\t{\n\t\t\tgatherresourceinfo(ctx, mark_list, glo, page, pdf_dict_get_val(ctx, font, i), show);\n\t\t}\n\t}\n\n\txobj = pdf_dict_get(ctx, rsrc, PDF_NAME(XObject));\n\tif (show & (IMAGES|XOBJS) && xobj && !pdf_mark_list_push(ctx, mark_list, xobj))\n\t{\n\t\tint n;\n\n\t\tif (show & IMAGES)\n\t\t\tgatherimages(ctx, glo, page, pageref, xobj);\n\t\tif (show & XOBJS)\n\t\t{\n\t\t\tgatherforms(ctx, glo, page, pageref, xobj);\n\t\t\tgatherpsobjs(ctx, glo, page, pageref, xobj);\n\t\t}\n\t\tn = pdf_dict_len(ctx, xobj);\n\t\tfor (i = 0; i < n; i++)\n\t\t{\n\t\t\tgatherresourceinfo(ctx, mark_list, glo, page, pdf_dict_get_val(ctx, xobj, i), show);\n\t\t}\n\t}\n\n\tshade = pdf_dict_get(ctx, rsrc, PDF_NAME(Shading));\n\tif (show & SHADINGS && shade && !pdf_mark_list_push(ctx, mark_list, shade))\n\t\tgathershadings(ctx, glo, page, pageref, shade);\n\n\tpattern = pdf_dict_get(ctx, rsrc, PDF_NAME(Pattern));\n\tif (show & PATTERNS && pattern && !pdf_mark_list_push(ctx, mark_list, pattern))\n\t{\n\t\tint n;\n\t\tgatherpatterns(ctx, glo, page, pageref, pattern);\n\t\tn = pdf_dict_len(ctx, pattern);\n\t\tfor (i = 0; i < n; i++)\n\t\t{\n\t\t\tgatherresourceinfo(ctx, mark_list, glo, page, pdf_dict_get_val(ctx, pattern, i), show);\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,7 @@\n \t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"cannot retrieve info from page %d\", page);\n \n \tfont = pdf_dict_get(ctx, rsrc, PDF_NAME(Font));\n-\tif (show & FONTS && font)\n+\tif (show & FONTS && font && !pdf_mark_list_push(ctx, mark_list, font))\n \t{\n \t\tint n;\n \n@@ -33,7 +33,7 @@\n \t}\n \n \txobj = pdf_dict_get(ctx, rsrc, PDF_NAME(XObject));\n-\tif (show & (IMAGES|XOBJS) && xobj)\n+\tif (show & (IMAGES|XOBJS) && xobj && !pdf_mark_list_push(ctx, mark_list, xobj))\n \t{\n \t\tint n;\n \n@@ -52,11 +52,11 @@\n \t}\n \n \tshade = pdf_dict_get(ctx, rsrc, PDF_NAME(Shading));\n-\tif (show & SHADINGS && shade)\n+\tif (show & SHADINGS && shade && !pdf_mark_list_push(ctx, mark_list, shade))\n \t\tgathershadings(ctx, glo, page, pageref, shade);\n \n \tpattern = pdf_dict_get(ctx, rsrc, PDF_NAME(Pattern));\n-\tif (show & PATTERNS && pattern)\n+\tif (show & PATTERNS && pattern && !pdf_mark_list_push(ctx, mark_list, pattern))\n \t{\n \t\tint n;\n \t\tgatherpatterns(ctx, glo, page, pageref, pattern);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (show & FONTS && font)",
                "\tif (show & (IMAGES|XOBJS) && xobj)",
                "\tif (show & SHADINGS && shade)",
                "\tif (show & PATTERNS && pattern)"
            ],
            "added_lines": [
                "\tif (show & FONTS && font && !pdf_mark_list_push(ctx, mark_list, font))",
                "\tif (show & (IMAGES|XOBJS) && xobj && !pdf_mark_list_push(ctx, mark_list, xobj))",
                "\tif (show & SHADINGS && shade && !pdf_mark_list_push(ctx, mark_list, shade))",
                "\tif (show & PATTERNS && pattern && !pdf_mark_list_push(ctx, mark_list, pattern))"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-31794",
        "func_name": "ArtifexSoftware/mupdf/pdf_mark_list_push",
        "description": "MuPDF v1.21.1 was discovered to contain an infinite recursion in the component pdf_mark_list_push. This vulnerability allows attackers to cause a Denial of Service (DoS) via a crafted PDF file.",
        "git_url": "https://github.com/ArtifexSoftware/mupdf/commit/c0015401693b58e2deb5d75c39f27bc1216e47c6",
        "commit_title": "Bug 706506: Fix infinite recursion in mutool info.",
        "commit_text": " 2 separate problems here.  Firstly, pdf_mark_list_push fails to copy the pushed data from local_list to the newly malloced block when we first move from local storage to malloced storage.  (Also, while we are here, there is no point in storing 0 entries in the list as they will never be checked!)  Secondly, while gatherresourceinfo is supposed to be called with indirected objects, it can (as is the case with the given fuzzed file) be called with direct references. These don't put anything sane in the cycle checker.  Thus by using (legal) indirections from (say) the Font resource entry back to something that contains the original resource entry, we can get cycles that we don't detect.  Fix this by pushing such entries onto the mark list.",
        "func_before": "int\npdf_mark_list_push(fz_context *ctx, pdf_mark_list *marks, pdf_obj *obj)\n{\n\tint num = pdf_to_num(ctx, obj);\n\tint i;\n\n\tif (num > 0)\n\t{\n\t\t/* Note: this is slow, if the mark list is expected to be big use pdf_mark_bits instead! */\n\t\tfor (i = 0; i < marks->len; ++i)\n\t\t\tif (marks->list[i] == num)\n\t\t\t\treturn 1;\n\t}\n\n\tif (marks->len == marks->max)\n\t{\n\t\tint newsize = marks->max << 1;\n\t\tif (marks->list == marks->local_list)\n\t\t\tmarks->list = fz_malloc_array(ctx, newsize, int);\n\t\telse\n\t\t\tmarks->list = fz_realloc_array(ctx, marks->list, newsize, int);\n\t\tmarks->max = newsize;\n\t}\n\n\tmarks->list[marks->len++] = num;\n\treturn 0;\n}",
        "func": "int\npdf_mark_list_push(fz_context *ctx, pdf_mark_list *marks, pdf_obj *obj)\n{\n\tint num = pdf_to_num(ctx, obj);\n\tint i;\n\n\t/* If object is not an indirection, then no record to store, or check. */\n\tif (num == 0)\n\t\treturn 0;\n\n\t/* Note: this is slow, if the mark list is expected to be big use pdf_mark_bits instead! */\n\tfor (i = 0; i < marks->len; ++i)\n\t\tif (marks->list[i] == num)\n\t\t\treturn 1;\n\n\tif (marks->len == marks->max)\n\t{\n\t\tint newsize = marks->max << 1;\n\t\tif (marks->list == marks->local_list)\n\t\t{\n\t\t\tmarks->list = fz_malloc_array(ctx, newsize, int);\n\t\t\tmemcpy(marks->list, marks->local_list, sizeof(marks->local_list));\n\t\t}\n\t\telse\n\t\t\tmarks->list = fz_realloc_array(ctx, marks->list, newsize, int);\n\t\tmarks->max = newsize;\n\t}\n\n\tmarks->list[marks->len++] = num;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,19 +4,23 @@\n \tint num = pdf_to_num(ctx, obj);\n \tint i;\n \n-\tif (num > 0)\n-\t{\n-\t\t/* Note: this is slow, if the mark list is expected to be big use pdf_mark_bits instead! */\n-\t\tfor (i = 0; i < marks->len; ++i)\n-\t\t\tif (marks->list[i] == num)\n-\t\t\t\treturn 1;\n-\t}\n+\t/* If object is not an indirection, then no record to store, or check. */\n+\tif (num == 0)\n+\t\treturn 0;\n+\n+\t/* Note: this is slow, if the mark list is expected to be big use pdf_mark_bits instead! */\n+\tfor (i = 0; i < marks->len; ++i)\n+\t\tif (marks->list[i] == num)\n+\t\t\treturn 1;\n \n \tif (marks->len == marks->max)\n \t{\n \t\tint newsize = marks->max << 1;\n \t\tif (marks->list == marks->local_list)\n+\t\t{\n \t\t\tmarks->list = fz_malloc_array(ctx, newsize, int);\n+\t\t\tmemcpy(marks->list, marks->local_list, sizeof(marks->local_list));\n+\t\t}\n \t\telse\n \t\t\tmarks->list = fz_realloc_array(ctx, marks->list, newsize, int);\n \t\tmarks->max = newsize;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (num > 0)",
                "\t{",
                "\t\t/* Note: this is slow, if the mark list is expected to be big use pdf_mark_bits instead! */",
                "\t\tfor (i = 0; i < marks->len; ++i)",
                "\t\t\tif (marks->list[i] == num)",
                "\t\t\t\treturn 1;",
                "\t}"
            ],
            "added_lines": [
                "\t/* If object is not an indirection, then no record to store, or check. */",
                "\tif (num == 0)",
                "\t\treturn 0;",
                "",
                "\t/* Note: this is slow, if the mark list is expected to be big use pdf_mark_bits instead! */",
                "\tfor (i = 0; i < marks->len; ++i)",
                "\t\tif (marks->list[i] == num)",
                "\t\t\treturn 1;",
                "\t\t{",
                "\t\t\tmemcpy(marks->list, marks->local_list, sizeof(marks->local_list));",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29591",
        "func_name": "tensorflow/Subgraph::AllocateTensors",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. TFlite graphs must not have loops between nodes. However, this condition was not checked and an attacker could craft models that would result in infinite loop during evaluation. In certain cases, the infinite loop would be replaced by stack overflow due to too many recursive calls. For example, the `While` implementation(https://github.com/tensorflow/tensorflow/blob/106d8f4fb89335a2c52d7c895b7a7485465ca8d9/tensorflow/lite/kernels/while.cc) could be tricked into a scneario where both the body and the loop subgraphs are the same. Evaluating one of the subgraphs means calling the `Eval` function for the other and this quickly exhaust all stack space. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range. Please consult our security guide(https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c6173f5fe66cdbab74f4f869311fe6aae2ba35f4",
        "commit_title": "TFLite: Error out when the graph has a recurion.",
        "commit_text": " Recursion is currently unsupported.  PiperOrigin-RevId: 371708957",
        "func_before": "TfLiteStatus Subgraph::AllocateTensors() {\n  TFLITE_SCOPED_TAGGED_DEFAULT_PROFILE(profiler_.get(), \"AllocateTensors\");\n  if (!consistent_) {\n    ReportError(\"AllocateTensors() called on inconsistent model.\");\n    return kTfLiteError;\n  }\n\n  // Restore delegation state if applicable.\n  TF_LITE_ENSURE_STATUS(RedoAllDelegates());\n\n  // Explicit (re)allocation is necessary if nodes have been changed or tensors\n  // have been resized. For inputs marked as dynamic, we can't short-circuit the\n  // allocation as the client may have done the resize manually.\n  if (state_ != kStateUninvokable &&\n      !HasDynamicTensorImpl(context_, inputs())) {\n    if (memory_planner_ && !memory_planner_->HasNonPersistentMemory()) {\n      // If the only change was the release of non-persistent memory via\n      // ReleaseNonPersistentMemory(), just re-allocate it. For any other type\n      // of memory-planning change (for eg, ResizeInputTensor), the state would\n      // be kStateUninvokable.\n      memory_planner_->AcquireNonPersistentMemory();\n    }\n    return kTfLiteOk;\n  }\n\n  next_execution_plan_index_to_prepare_ = 0;\n  next_execution_plan_index_to_plan_allocation_ = 0;\n  next_original_execution_plan_index_to_prepare_ = 0;\n  if (memory_planner_) {\n    TF_LITE_ENSURE_STATUS(memory_planner_->ResetAllocations());\n  }\n\n  TF_LITE_ENSURE_STATUS(PrepareOpsAndTensors());\n\n  state_ = kStateInvokable;\n\n  // Reset the variable tensors to zero after (re)allocating the tensors.\n  // Developers shouldn't rely on the side effect of this function to reset\n  // variable tensors. They should call `ResetVariableTensors` directly\n  // instead.\n  ResetVariableTensors();\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Subgraph::AllocateTensors() {\n  TFLITE_SCOPED_TAGGED_DEFAULT_PROFILE(profiler_.get(), \"AllocateTensors\");\n\n  if (!consistent_) {\n    ReportError(\"AllocateTensors() called on inconsistent model.\");\n    return kTfLiteError;\n  }\n\n  // Restore delegation state if applicable.\n  TF_LITE_ENSURE_STATUS(RedoAllDelegates());\n\n  // Explicit (re)allocation is necessary if nodes have been changed or tensors\n  // have been resized. For inputs marked as dynamic, we can't short-circuit the\n  // allocation as the client may have done the resize manually.\n  if (state_ != kStateUninvokable &&\n      !HasDynamicTensorImpl(context_, inputs())) {\n    if (memory_planner_ && !memory_planner_->HasNonPersistentMemory()) {\n      // If the only change was the release of non-persistent memory via\n      // ReleaseNonPersistentMemory(), just re-allocate it. For any other type\n      // of memory-planning change (for eg, ResizeInputTensor), the state would\n      // be kStateUninvokable.\n      memory_planner_->AcquireNonPersistentMemory();\n    }\n    return kTfLiteOk;\n  }\n\n  // Note `AllocateTensors` sometimes calls itself recursively above\n  // for delegates. Therefore only the logic below need to be guarded\n  // by `SubgraphGuard`.\n  SubgraphGuard guard(&context_, &is_subgraph_in_use_);\n  TF_LITE_ENSURE_OK(&context_, guard.status());\n\n  next_execution_plan_index_to_prepare_ = 0;\n  next_execution_plan_index_to_plan_allocation_ = 0;\n  next_original_execution_plan_index_to_prepare_ = 0;\n  if (memory_planner_) {\n    TF_LITE_ENSURE_STATUS(memory_planner_->ResetAllocations());\n  }\n\n  TF_LITE_ENSURE_STATUS(PrepareOpsAndTensors());\n\n  state_ = kStateInvokable;\n\n  // Reset the variable tensors to zero after (re)allocating the tensors.\n  // Developers shouldn't rely on the side effect of this function to reset\n  // variable tensors. They should call `ResetVariableTensors` directly\n  // instead.\n  ResetVariableTensors();\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n TfLiteStatus Subgraph::AllocateTensors() {\n   TFLITE_SCOPED_TAGGED_DEFAULT_PROFILE(profiler_.get(), \"AllocateTensors\");\n+\n   if (!consistent_) {\n     ReportError(\"AllocateTensors() called on inconsistent model.\");\n     return kTfLiteError;\n@@ -23,6 +24,12 @@\n     return kTfLiteOk;\n   }\n \n+  // Note `AllocateTensors` sometimes calls itself recursively above\n+  // for delegates. Therefore only the logic below need to be guarded\n+  // by `SubgraphGuard`.\n+  SubgraphGuard guard(&context_, &is_subgraph_in_use_);\n+  TF_LITE_ENSURE_OK(&context_, guard.status());\n+\n   next_execution_plan_index_to_prepare_ = 0;\n   next_execution_plan_index_to_plan_allocation_ = 0;\n   next_original_execution_plan_index_to_prepare_ = 0;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  // Note `AllocateTensors` sometimes calls itself recursively above",
                "  // for delegates. Therefore only the logic below need to be guarded",
                "  // by `SubgraphGuard`.",
                "  SubgraphGuard guard(&context_, &is_subgraph_in_use_);",
                "  TF_LITE_ENSURE_OK(&context_, guard.status());",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29591",
        "func_name": "tensorflow/Subgraph::Invoke",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. TFlite graphs must not have loops between nodes. However, this condition was not checked and an attacker could craft models that would result in infinite loop during evaluation. In certain cases, the infinite loop would be replaced by stack overflow due to too many recursive calls. For example, the `While` implementation(https://github.com/tensorflow/tensorflow/blob/106d8f4fb89335a2c52d7c895b7a7485465ca8d9/tensorflow/lite/kernels/while.cc) could be tricked into a scneario where both the body and the loop subgraphs are the same. Evaluating one of the subgraphs means calling the `Eval` function for the other and this quickly exhaust all stack space. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range. Please consult our security guide(https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c6173f5fe66cdbab74f4f869311fe6aae2ba35f4",
        "commit_title": "TFLite: Error out when the graph has a recurion.",
        "commit_text": " Recursion is currently unsupported.  PiperOrigin-RevId: 371708957",
        "func_before": "TfLiteStatus Subgraph::Invoke() {\n  if (!consistent_) {\n    ReportError(\"Invoke called on model that is not consistent.\");\n    return kTfLiteError;\n  }\n\n  TfLiteStatus status = kTfLiteOk;\n  if (state_ == kStateUninvokable) {\n    ReportError(\"Invoke called on model that is not ready.\");\n    return kTfLiteError;\n  } else if (memory_planner_ && !memory_planner_->HasNonPersistentMemory()) {\n    ReportError(\"Non-persistent memory is not available.\");\n    return kTfLiteError;\n  }\n  TFLITE_SCOPED_TAGGED_DEFAULT_PROFILE(profiler_.get(), \"Invoke\");\n\n  // Invocations are always done in node order.\n  // Note that calling Invoke repeatedly will cause the original memory plan to\n  // be reused, unless either ResizeInputTensor() or AllocateTensors() has been\n  // called.\n  for (int execution_plan_index = 0;\n       execution_plan_index < execution_plan_.size(); execution_plan_index++) {\n    if (execution_plan_index == next_execution_plan_index_to_prepare_) {\n      TF_LITE_ENSURE_STATUS(PrepareOpsAndTensors());\n      TF_LITE_ENSURE(&context_, next_execution_plan_index_to_prepare_ >=\n                                    execution_plan_index);\n    }\n    int node_index = execution_plan_[execution_plan_index];\n    TfLiteNode& node = nodes_and_registration_[node_index].first;\n    const TfLiteRegistration& registration =\n        nodes_and_registration_[node_index].second;\n\n    const char* op_name = nullptr;\n    if (profiler_) op_name = GetTFLiteOpName(registration);\n    TFLITE_SCOPED_TAGGED_OPERATOR_PROFILE(profiler_.get(), op_name, node_index);\n\n    for (int i = 0; i < node.inputs->size; ++i) {\n      int tensor_index = node.inputs->data[i];\n      if (tensor_index == kTfLiteOptionalTensor) {\n        continue;\n      }\n      TfLiteTensor* tensor = &tensors_[tensor_index];\n      if (tensor->delegate && tensor->delegate != node.delegate &&\n          tensor->data_is_stale) {\n        TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));\n      }\n      if (tensor->data.raw == nullptr && tensor->bytes > 0) {\n        if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1 &&\n            tensor->dims->size != 1) {\n          // In general, having a tensor here with no buffer will be an error.\n          // However, for the reshape operator, the second input tensor is\n          // sometimes only used for the shape, not for the data. Thus, null\n          // buffer is ok in this situation.\n          // The situation where null buffer is not ok for reshape operator is\n          // only when there are 2 inputs given to the node and the one\n          // corresponding to the shape (i == 1) is a vector that contains all\n          // dimensions. See `GetOutputShape()` function in\n          // `tensorflow/lite/kernels/reshape.cc`\n          continue;\n        } else {\n          // In all other cases, we need to return an error as otherwise we will\n          // trigger a null pointer dereference (likely).\n          ReportError(\"Input tensor %d lacks data\", tensor_index);\n          return kTfLiteError;\n        }\n      }\n    }\n\n    if (check_cancelled_func_ != nullptr &&\n        check_cancelled_func_(cancellation_data_)) {\n      ReportError(\"Client requested cancel during Invoke()\");\n      return kTfLiteError;\n    }\n\n    EnsureTensorsVectorCapacity();\n    tensor_resized_since_op_invoke_ = false;\n    if (OpInvoke(registration, &node) != kTfLiteOk) {\n      return ReportOpError(&context_, node, registration, node_index,\n                           \"failed to invoke\");\n    }\n\n    // Force execution prep for downstream ops if the latest op triggered the\n    // resize of a dynamic tensor.\n    if (tensor_resized_since_op_invoke_ &&\n        HasDynamicTensor(context_, node.outputs)) {\n      next_execution_plan_index_to_prepare_ = execution_plan_index + 1;\n\n      // This happens when an intermediate dynamic tensor is resized.\n      // We don't have to prepare all the ops, but we need to recompute\n      // the allocation plan.\n      if (next_execution_plan_index_to_plan_allocation_ >\n          next_execution_plan_index_to_prepare_) {\n        next_execution_plan_index_to_plan_allocation_ =\n            next_execution_plan_index_to_prepare_;\n        if (memory_planner_) {\n          TF_LITE_ENSURE_STATUS(memory_planner_->ResetAllocationsAfter(\n              next_execution_plan_index_to_plan_allocation_ - 1));\n        }\n      }\n    }\n  }\n\n  return status;\n}",
        "func": "TfLiteStatus Subgraph::Invoke() {\n  SubgraphGuard guard(&context_, &is_subgraph_in_use_);\n  TF_LITE_ENSURE_OK(&context_, guard.status());\n\n  if (!consistent_) {\n    ReportError(\"Invoke called on model that is not consistent.\");\n    return kTfLiteError;\n  }\n\n  TfLiteStatus status = kTfLiteOk;\n  if (state_ == kStateUninvokable) {\n    ReportError(\"Invoke called on model that is not ready.\");\n    return kTfLiteError;\n  } else if (memory_planner_ && !memory_planner_->HasNonPersistentMemory()) {\n    ReportError(\"Non-persistent memory is not available.\");\n    return kTfLiteError;\n  }\n  TFLITE_SCOPED_TAGGED_DEFAULT_PROFILE(profiler_.get(), \"Invoke\");\n\n  // Invocations are always done in node order.\n  // Note that calling Invoke repeatedly will cause the original memory plan to\n  // be reused, unless either ResizeInputTensor() or AllocateTensors() has been\n  // called.\n  for (int execution_plan_index = 0;\n       execution_plan_index < execution_plan_.size(); execution_plan_index++) {\n    if (execution_plan_index == next_execution_plan_index_to_prepare_) {\n      TF_LITE_ENSURE_STATUS(PrepareOpsAndTensors());\n      TF_LITE_ENSURE(&context_, next_execution_plan_index_to_prepare_ >=\n                                    execution_plan_index);\n    }\n    int node_index = execution_plan_[execution_plan_index];\n    TfLiteNode& node = nodes_and_registration_[node_index].first;\n    const TfLiteRegistration& registration =\n        nodes_and_registration_[node_index].second;\n\n    const char* op_name = nullptr;\n    if (profiler_) op_name = GetTFLiteOpName(registration);\n    TFLITE_SCOPED_TAGGED_OPERATOR_PROFILE(profiler_.get(), op_name, node_index);\n\n    for (int i = 0; i < node.inputs->size; ++i) {\n      int tensor_index = node.inputs->data[i];\n      if (tensor_index == kTfLiteOptionalTensor) {\n        continue;\n      }\n      TfLiteTensor* tensor = &tensors_[tensor_index];\n      if (tensor->delegate && tensor->delegate != node.delegate &&\n          tensor->data_is_stale) {\n        TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));\n      }\n      if (tensor->data.raw == nullptr && tensor->bytes > 0) {\n        if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1 &&\n            tensor->dims->size != 1) {\n          // In general, having a tensor here with no buffer will be an error.\n          // However, for the reshape operator, the second input tensor is\n          // sometimes only used for the shape, not for the data. Thus, null\n          // buffer is ok in this situation.\n          // The situation where null buffer is not ok for reshape operator is\n          // only when there are 2 inputs given to the node and the one\n          // corresponding to the shape (i == 1) is a vector that contains all\n          // dimensions. See `GetOutputShape()` function in\n          // `tensorflow/lite/kernels/reshape.cc`\n          continue;\n        } else {\n          // In all other cases, we need to return an error as otherwise we will\n          // trigger a null pointer dereference (likely).\n          ReportError(\"Input tensor %d lacks data\", tensor_index);\n          return kTfLiteError;\n        }\n      }\n    }\n\n    if (check_cancelled_func_ != nullptr &&\n        check_cancelled_func_(cancellation_data_)) {\n      ReportError(\"Client requested cancel during Invoke()\");\n      return kTfLiteError;\n    }\n\n    EnsureTensorsVectorCapacity();\n    tensor_resized_since_op_invoke_ = false;\n    if (OpInvoke(registration, &node) != kTfLiteOk) {\n      return ReportOpError(&context_, node, registration, node_index,\n                           \"failed to invoke\");\n    }\n\n    // Force execution prep for downstream ops if the latest op triggered the\n    // resize of a dynamic tensor.\n    if (tensor_resized_since_op_invoke_ &&\n        HasDynamicTensor(context_, node.outputs)) {\n      next_execution_plan_index_to_prepare_ = execution_plan_index + 1;\n\n      // This happens when an intermediate dynamic tensor is resized.\n      // We don't have to prepare all the ops, but we need to recompute\n      // the allocation plan.\n      if (next_execution_plan_index_to_plan_allocation_ >\n          next_execution_plan_index_to_prepare_) {\n        next_execution_plan_index_to_plan_allocation_ =\n            next_execution_plan_index_to_prepare_;\n        if (memory_planner_) {\n          TF_LITE_ENSURE_STATUS(memory_planner_->ResetAllocationsAfter(\n              next_execution_plan_index_to_plan_allocation_ - 1));\n        }\n      }\n    }\n  }\n\n  return status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,7 @@\n TfLiteStatus Subgraph::Invoke() {\n+  SubgraphGuard guard(&context_, &is_subgraph_in_use_);\n+  TF_LITE_ENSURE_OK(&context_, guard.status());\n+\n   if (!consistent_) {\n     ReportError(\"Invoke called on model that is not consistent.\");\n     return kTfLiteError;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  SubgraphGuard guard(&context_, &is_subgraph_in_use_);",
                "  TF_LITE_ENSURE_OK(&context_, guard.status());",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29591",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. TFlite graphs must not have loops between nodes. However, this condition was not checked and an attacker could craft models that would result in infinite loop during evaluation. In certain cases, the infinite loop would be replaced by stack overflow due to too many recursive calls. For example, the `While` implementation(https://github.com/tensorflow/tensorflow/blob/106d8f4fb89335a2c52d7c895b7a7485465ca8d9/tensorflow/lite/kernels/while.cc) could be tricked into a scneario where both the body and the loop subgraphs are the same. Evaluating one of the subgraphs means calling the `Eval` function for the other and this quickly exhaust all stack space. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range. Please consult our security guide(https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c6173f5fe66cdbab74f4f869311fe6aae2ba35f4",
        "commit_title": "TFLite: Error out when the graph has a recurion.",
        "commit_text": " Recursion is currently unsupported.  PiperOrigin-RevId: 371708957",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int num_inputs = node->inputs->size;\n  // The number of outputs should be the same as number of inputs.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, num_inputs);\n\n  // Check subgraph indices and get subgraphs.\n  Subgraph* this_subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n  auto* subgraphs = this_subgraph->GetSubgraphs();\n  TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\n  TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\n  TF_LITE_ENSURE(context,\n                 op_data->cond_subgraph_index != op_data->body_subgraph_index);\n\n  Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\n  Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();\n\n  // Check input & output count of the condition subgraph.\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->outputs().size(), 1);\n\n  // Check input & output count of the body subgraph.\n  TF_LITE_ENSURE_EQ(context, body_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, body_subgraph->outputs().size(), num_inputs);\n\n  // Prepare and check the condition subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   cond_subgraph, cond_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, cond_subgraph->AllocateTensors());\n  TfLiteTensor* cond_output =\n      cond_subgraph->tensor(cond_subgraph->outputs()[0]);\n  // This should rarely happens. In most cases the output is static with shape\n  // [1]. However theoretically intermediate tensors in the cond subgraph\n  // can be dynamic.\n  if (IsDynamicTensor(cond_output)) {\n    op_data->cond_has_dynamic_output_tensors = true;\n  } else {\n    TF_LITE_ENSURE_STATUS(CheckCondOutput(context, cond_output));\n  }\n\n  // Prepare and check the body subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   body_subgraph, body_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, body_subgraph->AllocateTensors());\n  if (body_subgraph->HasDynamicTensors()) {\n    op_data->body_has_dynamic_output_tensors = true;\n  } else {\n    for (int i = 0; i < num_inputs; ++i) {\n      TfLiteTensor* body_input =\n          body_subgraph->tensor(body_subgraph->inputs()[i]);\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TF_LITE_ENSURE_TYPES_EQ(context, body_input->type, body_output->type);\n\n      TF_LITE_ENSURE(context, !IsDynamicTensor(body_output));\n      if (!TfLiteIntArrayEqual(body_input->dims, body_output->dims)) {\n        // If the output shape of the body subgraph is static w.r.t. a fixed\n        // input size, but it's different from input size, it's still considered\n        // dynamic. For example: If a subgraph keeps padding its input with a\n        // fixed padding, the output shape is static w.r.t the input shape and\n        // padding, but running it in a loop will keep bloating the tensor.\n        op_data->body_has_dynamic_output_tensors = true;\n        break;\n      }\n    }\n  }\n  for (int i = 0; i < num_inputs; ++i) {\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    if (op_data->body_has_dynamic_output_tensors) {\n      SetTensorToDynamic(output);\n    } else {\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TfLiteIntArray* output_size = TfLiteIntArrayCopy(body_output->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, output, output_size));\n    }\n  }\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int num_inputs = node->inputs->size;\n  // The number of outputs should be the same as number of inputs.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, num_inputs);\n\n  // Check subgraph indices and get subgraphs.\n  Subgraph* this_subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n  auto* subgraphs = this_subgraph->GetSubgraphs();\n  TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\n  TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\n\n  Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\n  Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();\n\n  // Check input & output count of the condition subgraph.\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->outputs().size(), 1);\n\n  // Check input & output count of the body subgraph.\n  TF_LITE_ENSURE_EQ(context, body_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, body_subgraph->outputs().size(), num_inputs);\n\n  // Prepare and check the condition subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   cond_subgraph, cond_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, cond_subgraph->AllocateTensors());\n  TfLiteTensor* cond_output =\n      cond_subgraph->tensor(cond_subgraph->outputs()[0]);\n  // This should rarely happens. In most cases the output is static with shape\n  // [1]. However theoretically intermediate tensors in the cond subgraph\n  // can be dynamic.\n  if (IsDynamicTensor(cond_output)) {\n    op_data->cond_has_dynamic_output_tensors = true;\n  } else {\n    TF_LITE_ENSURE_STATUS(CheckCondOutput(context, cond_output));\n  }\n\n  // Prepare and check the body subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   body_subgraph, body_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, body_subgraph->AllocateTensors());\n  if (body_subgraph->HasDynamicTensors()) {\n    op_data->body_has_dynamic_output_tensors = true;\n  } else {\n    for (int i = 0; i < num_inputs; ++i) {\n      TfLiteTensor* body_input =\n          body_subgraph->tensor(body_subgraph->inputs()[i]);\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TF_LITE_ENSURE_TYPES_EQ(context, body_input->type, body_output->type);\n\n      TF_LITE_ENSURE(context, !IsDynamicTensor(body_output));\n      if (!TfLiteIntArrayEqual(body_input->dims, body_output->dims)) {\n        // If the output shape of the body subgraph is static w.r.t. a fixed\n        // input size, but it's different from input size, it's still considered\n        // dynamic. For example: If a subgraph keeps padding its input with a\n        // fixed padding, the output shape is static w.r.t the input shape and\n        // padding, but running it in a loop will keep bloating the tensor.\n        op_data->body_has_dynamic_output_tensors = true;\n        break;\n      }\n    }\n  }\n  for (int i = 0; i < num_inputs; ++i) {\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    if (op_data->body_has_dynamic_output_tensors) {\n      SetTensorToDynamic(output);\n    } else {\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TfLiteIntArray* output_size = TfLiteIntArrayCopy(body_output->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, output, output_size));\n    }\n  }\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,8 +9,6 @@\n   auto* subgraphs = this_subgraph->GetSubgraphs();\n   TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\n   TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\n-  TF_LITE_ENSURE(context,\n-                 op_data->cond_subgraph_index != op_data->body_subgraph_index);\n \n   Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\n   Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();",
        "diff_line_info": {
            "deleted_lines": [
                "  TF_LITE_ENSURE(context,",
                "                 op_data->cond_subgraph_index != op_data->body_subgraph_index);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2021-29591",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. TFlite graphs must not have loops between nodes. However, this condition was not checked and an attacker could craft models that would result in infinite loop during evaluation. In certain cases, the infinite loop would be replaced by stack overflow due to too many recursive calls. For example, the `While` implementation(https://github.com/tensorflow/tensorflow/blob/106d8f4fb89335a2c52d7c895b7a7485465ca8d9/tensorflow/lite/kernels/while.cc) could be tricked into a scneario where both the body and the loop subgraphs are the same. Evaluating one of the subgraphs means calling the `Eval` function for the other and this quickly exhaust all stack space. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range. Please consult our security guide(https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md) for more information regarding the security model and how to contact us with issues and questions.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/9c1dc920d8ffb4893d6c9d27d1f039607b326743",
        "commit_title": "Prevent infinite loop/stack overflow in TFLite `while` op.",
        "commit_text": " PiperOrigin-RevId: 370800333",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int num_inputs = node->inputs->size;\n  // The number of outputs should be the same as number of inputs.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, num_inputs);\n\n  // Check subgraph indices and get subgraphs.\n  Subgraph* this_subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n  auto* subgraphs = this_subgraph->GetSubgraphs();\n  TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\n  TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\n\n  Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\n  Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();\n\n  // Check input & output count of the condition subgraph.\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->outputs().size(), 1);\n\n  // Check input & output count of the body subgraph.\n  TF_LITE_ENSURE_EQ(context, body_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, body_subgraph->outputs().size(), num_inputs);\n\n  // Prepare and check the condition subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   cond_subgraph, cond_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, cond_subgraph->AllocateTensors());\n  TfLiteTensor* cond_output =\n      cond_subgraph->tensor(cond_subgraph->outputs()[0]);\n  // This should rarely happens. In most cases the output is static with shape\n  // [1]. However theoretically intermediate tensors in the cond subgraph\n  // can be dynamic.\n  if (IsDynamicTensor(cond_output)) {\n    op_data->cond_has_dynamic_output_tensors = true;\n  } else {\n    TF_LITE_ENSURE_STATUS(CheckCondOutput(context, cond_output));\n  }\n\n  // Prepare and check the body subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   body_subgraph, body_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, body_subgraph->AllocateTensors());\n  if (body_subgraph->HasDynamicTensors()) {\n    op_data->body_has_dynamic_output_tensors = true;\n  } else {\n    for (int i = 0; i < num_inputs; ++i) {\n      TfLiteTensor* body_input =\n          body_subgraph->tensor(body_subgraph->inputs()[i]);\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TF_LITE_ENSURE_TYPES_EQ(context, body_input->type, body_output->type);\n\n      TF_LITE_ENSURE(context, !IsDynamicTensor(body_output));\n      if (!TfLiteIntArrayEqual(body_input->dims, body_output->dims)) {\n        // If the output shape of the body subgraph is static w.r.t. a fixed\n        // input size, but it's different from input size, it's still considered\n        // dynamic. For example: If a subgraph keeps padding its input with a\n        // fixed padding, the output shape is static w.r.t the input shape and\n        // padding, but running it in a loop will keep bloating the tensor.\n        op_data->body_has_dynamic_output_tensors = true;\n        break;\n      }\n    }\n  }\n  for (int i = 0; i < num_inputs; ++i) {\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    if (op_data->body_has_dynamic_output_tensors) {\n      SetTensorToDynamic(output);\n    } else {\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TfLiteIntArray* output_size = TfLiteIntArrayCopy(body_output->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, output, output_size));\n    }\n  }\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int num_inputs = node->inputs->size;\n  // The number of outputs should be the same as number of inputs.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, num_inputs);\n\n  // Check subgraph indices and get subgraphs.\n  Subgraph* this_subgraph = reinterpret_cast<Subgraph*>(context->impl_);\n  auto* subgraphs = this_subgraph->GetSubgraphs();\n  TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\n  TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\n  TF_LITE_ENSURE(context,\n                 op_data->cond_subgraph_index != op_data->body_subgraph_index);\n\n  Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\n  Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();\n\n  // Check input & output count of the condition subgraph.\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, cond_subgraph->outputs().size(), 1);\n\n  // Check input & output count of the body subgraph.\n  TF_LITE_ENSURE_EQ(context, body_subgraph->inputs().size(), num_inputs);\n  TF_LITE_ENSURE_EQ(context, body_subgraph->outputs().size(), num_inputs);\n\n  // Prepare and check the condition subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   cond_subgraph, cond_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, cond_subgraph->AllocateTensors());\n  TfLiteTensor* cond_output =\n      cond_subgraph->tensor(cond_subgraph->outputs()[0]);\n  // This should rarely happens. In most cases the output is static with shape\n  // [1]. However theoretically intermediate tensors in the cond subgraph\n  // can be dynamic.\n  if (IsDynamicTensor(cond_output)) {\n    op_data->cond_has_dynamic_output_tensors = true;\n  } else {\n    TF_LITE_ENSURE_STATUS(CheckCondOutput(context, cond_output));\n  }\n\n  // Prepare and check the body subgraph.\n  TF_LITE_ENSURE_OK(\n      context, CopyTensorsShapeAndType(\n                   context, this_subgraph, TfLiteIntArrayView(node->inputs),\n                   body_subgraph, body_subgraph->inputs(), true));\n  TF_LITE_ENSURE_OK(context, body_subgraph->AllocateTensors());\n  if (body_subgraph->HasDynamicTensors()) {\n    op_data->body_has_dynamic_output_tensors = true;\n  } else {\n    for (int i = 0; i < num_inputs; ++i) {\n      TfLiteTensor* body_input =\n          body_subgraph->tensor(body_subgraph->inputs()[i]);\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TF_LITE_ENSURE_TYPES_EQ(context, body_input->type, body_output->type);\n\n      TF_LITE_ENSURE(context, !IsDynamicTensor(body_output));\n      if (!TfLiteIntArrayEqual(body_input->dims, body_output->dims)) {\n        // If the output shape of the body subgraph is static w.r.t. a fixed\n        // input size, but it's different from input size, it's still considered\n        // dynamic. For example: If a subgraph keeps padding its input with a\n        // fixed padding, the output shape is static w.r.t the input shape and\n        // padding, but running it in a loop will keep bloating the tensor.\n        op_data->body_has_dynamic_output_tensors = true;\n        break;\n      }\n    }\n  }\n  for (int i = 0; i < num_inputs; ++i) {\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    if (op_data->body_has_dynamic_output_tensors) {\n      SetTensorToDynamic(output);\n    } else {\n      TfLiteTensor* body_output =\n          body_subgraph->tensor(body_subgraph->outputs()[i]);\n      TfLiteIntArray* output_size = TfLiteIntArrayCopy(body_output->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, output, output_size));\n    }\n  }\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,8 @@\n   auto* subgraphs = this_subgraph->GetSubgraphs();\n   TF_LITE_ENSURE(context, op_data->cond_subgraph_index < subgraphs->size());\n   TF_LITE_ENSURE(context, op_data->body_subgraph_index < subgraphs->size());\n+  TF_LITE_ENSURE(context,\n+                 op_data->cond_subgraph_index != op_data->body_subgraph_index);\n \n   Subgraph* cond_subgraph = (*subgraphs)[op_data->cond_subgraph_index].get();\n   Subgraph* body_subgraph = (*subgraphs)[op_data->body_subgraph_index].get();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context,",
                "                 op_data->cond_subgraph_index != op_data->body_subgraph_index);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29615",
        "func_name": "tensorflow/ParseAttrValue",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of `ParseAttrValue`(https://github.com/tensorflow/tensorflow/blob/c22d88d6ff33031aa113e48aa3fc9aa74ed79595/tensorflow/core/framework/attr_value_util.cc#L397-L453) can be tricked into stack overflow due to recursion by giving in a specially crafted input. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/e07e1c3d26492c06f078c7e5bf2d138043e199c1",
        "commit_title": "Prevent memory overflow in ParseAttrValue from nested tensors.",
        "commit_text": " PiperOrigin-RevId: 370108442",
        "func_before": "bool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\n  // Parse type.\n  string field_name;\n  bool is_list = absl::ConsumePrefix(&type, \"list(\");\n  if (absl::ConsumePrefix(&type, \"string\")) {\n    field_name = \"s\";\n  } else if (absl::ConsumePrefix(&type, \"int\")) {\n    field_name = \"i\";\n  } else if (absl::ConsumePrefix(&type, \"float\")) {\n    field_name = \"f\";\n  } else if (absl::ConsumePrefix(&type, \"bool\")) {\n    field_name = \"b\";\n  } else if (absl::ConsumePrefix(&type, \"type\")) {\n    field_name = \"type\";\n  } else if (absl::ConsumePrefix(&type, \"shape\")) {\n    field_name = \"shape\";\n  } else if (absl::ConsumePrefix(&type, \"tensor\")) {\n    field_name = \"tensor\";\n  } else if (absl::ConsumePrefix(&type, \"func\")) {\n    field_name = \"func\";\n  } else if (absl::ConsumePrefix(&type, \"placeholder\")) {\n    field_name = \"placeholder\";\n  } else {\n    return false;\n  }\n  if (is_list && !absl::ConsumePrefix(&type, \")\")) {\n    return false;\n  }\n\n  // Construct a valid text proto message to parse.\n  string to_parse;\n  if (is_list) {\n    // TextFormat parser considers \"i: 7\" to be the same as \"i: [7]\",\n    // but we only want to allow list values with [].\n    StringPiece cleaned = text;\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    str_util::RemoveTrailingWhitespace(&cleaned);\n    if (cleaned.size() < 2 || cleaned[0] != '[' ||\n        cleaned[cleaned.size() - 1] != ']') {\n      return false;\n    }\n    cleaned.remove_prefix(1);\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    if (cleaned.size() == 1) {\n      // User wrote \"[]\", so return empty list without invoking the TextFormat\n      // parse which returns an error for \"i: []\".\n      out->Clear();\n      out->mutable_list();\n      return true;\n    }\n    to_parse = strings::StrCat(\"list { \", field_name, \": \", text, \" }\");\n  } else {\n    to_parse = strings::StrCat(field_name, \": \", text);\n  }\n\n  return ProtoParseFromString(to_parse, out);\n}",
        "func": "bool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\n  // Parse type.\n  string field_name;\n  bool is_list = absl::ConsumePrefix(&type, \"list(\");\n  if (absl::ConsumePrefix(&type, \"string\")) {\n    field_name = \"s\";\n  } else if (absl::ConsumePrefix(&type, \"int\")) {\n    field_name = \"i\";\n  } else if (absl::ConsumePrefix(&type, \"float\")) {\n    field_name = \"f\";\n  } else if (absl::ConsumePrefix(&type, \"bool\")) {\n    field_name = \"b\";\n  } else if (absl::ConsumePrefix(&type, \"type\")) {\n    field_name = \"type\";\n  } else if (absl::ConsumePrefix(&type, \"shape\")) {\n    field_name = \"shape\";\n  } else if (absl::ConsumePrefix(&type, \"tensor\")) {\n    field_name = \"tensor\";\n  } else if (absl::ConsumePrefix(&type, \"func\")) {\n    field_name = \"func\";\n  } else if (absl::ConsumePrefix(&type, \"placeholder\")) {\n    field_name = \"placeholder\";\n  } else {\n    return false;\n  }\n  if (is_list && !absl::ConsumePrefix(&type, \")\")) {\n    return false;\n  }\n\n  // Construct a valid text proto message to parse.\n  string to_parse;\n  if (is_list) {\n    // TextFormat parser considers \"i: 7\" to be the same as \"i: [7]\",\n    // but we only want to allow list values with [].\n    StringPiece cleaned = text;\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    str_util::RemoveTrailingWhitespace(&cleaned);\n    if (cleaned.size() < 2 || cleaned[0] != '[' ||\n        cleaned[cleaned.size() - 1] != ']') {\n      return false;\n    }\n    cleaned.remove_prefix(1);\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    if (cleaned.size() == 1) {\n      // User wrote \"[]\", so return empty list without invoking the TextFormat\n      // parse which returns an error for \"i: []\".\n      out->Clear();\n      out->mutable_list();\n      return true;\n    }\n    to_parse = strings::StrCat(\"list { \", field_name, \": \", text, \" }\");\n  } else {\n    to_parse = strings::StrCat(field_name, \": \", text);\n  }\n  if (field_name == \"tensor\") {\n    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,\n                                                    to_parse)) {\n      return false;\n    }\n  }\n  return ProtoParseFromString(to_parse, out);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,6 +52,11 @@\n   } else {\n     to_parse = strings::StrCat(field_name, \": \", text);\n   }\n-\n+  if (field_name == \"tensor\") {\n+    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,\n+                                                    to_parse)) {\n+      return false;\n+    }\n+  }\n   return ProtoParseFromString(to_parse, out);\n }",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "  if (field_name == \"tensor\") {",
                "    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,",
                "                                                    to_parse)) {",
                "      return false;",
                "    }",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28903",
        "func_name": "CESNET/libyang/lyxml_parse_elem",
        "description": "A stack overflow in libyang <= v1.0.225 can cause a denial of service through function lyxml_parse_mem(). lyxml_parse_elem() function will be called recursively, which will consume stack space and lead to crash.",
        "git_url": "https://github.com/CESNET/libyang/commit/298b30ea4ebee137226acf9bb38678bd82704582",
        "commit_title": "common FEATURE add a hard limit for recursion",
        "commit_text": " Fixes #1453",
        "func_before": "struct lyxml_elem *\nlyxml_parse_elem(struct ly_ctx *ctx, const char *data, unsigned int *len, struct lyxml_elem *parent, int options)\n{\n    const char *c = data, *start, *e;\n    const char *lws;    /* leading white space for handling mixed content */\n    int uc;\n    char *str;\n    char *prefix = NULL;\n    unsigned int prefix_len = 0;\n    struct lyxml_elem *elem = NULL, *child;\n    struct lyxml_attr *attr;\n    unsigned int size;\n    int nons_flag = 0, closed_flag = 0;\n\n    *len = 0;\n\n    if (*c != '<') {\n        return NULL;\n    }\n\n    /* locate element name */\n    c++;\n    e = c;\n\n    uc = lyxml_getutf8(ctx, e, &size);\n    if (!is_xmlnamestartchar(uc)) {\n        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_NONE, NULL, \"NameStartChar of the element\");\n        return NULL;\n    }\n    e += size;\n    uc = lyxml_getutf8(ctx, e, &size);\n    while (is_xmlnamechar(uc)) {\n        if (*e == ':') {\n            if (prefix_len) {\n                LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_NONE, NULL, \"element name, multiple colons found\");\n                goto error;\n            }\n            /* element in a namespace */\n            start = e + 1;\n\n            /* look for the prefix in namespaces */\n            prefix_len = e - c;\n            LY_CHECK_ERR_GOTO(prefix, LOGVAL(ctx, LYE_XML_INCHAR, LY_VLOG_NONE, NULL, e), error);\n            prefix = malloc((prefix_len + 1) * sizeof *prefix);\n            LY_CHECK_ERR_GOTO(!prefix, LOGMEM(ctx), error);\n            memcpy(prefix, c, prefix_len);\n            prefix[prefix_len] = '\\0';\n            c = start;\n        }\n        e += size;\n        uc = lyxml_getutf8(ctx, e, &size);\n    }\n    if (!*e) {\n        LOGVAL(ctx, LYE_EOF, LY_VLOG_NONE, NULL);\n        free(prefix);\n        return NULL;\n    }\n\n    /* allocate element structure */\n    elem = calloc(1, sizeof *elem);\n    LY_CHECK_ERR_RETURN(!elem, free(prefix); LOGMEM(ctx), NULL);\n\n    elem->next = NULL;\n    elem->prev = elem;\n    if (parent) {\n        lyxml_add_child(ctx, parent, elem);\n    }\n\n    /* store the name into the element structure */\n    elem->name = lydict_insert(ctx, c, e - c);\n    c = e;\n\nprocess:\n    ign_xmlws(c);\n    if (!strncmp(\"/>\", c, 2)) {\n        /* we are done, it was EmptyElemTag */\n        c += 2;\n        elem->content = lydict_insert(ctx, \"\", 0);\n        closed_flag = 1;\n    } else if (*c == '>') {\n        /* process element content */\n        c++;\n        lws = NULL;\n\n        while (*c) {\n            if (!strncmp(c, \"</\", 2)) {\n                if (lws && !elem->child) {\n                    /* leading white spaces were actually content */\n                    goto store_content;\n                }\n\n                /* Etag */\n                c += 2;\n                /* get name and check it */\n                e = c;\n                uc = lyxml_getutf8(ctx, e, &size);\n                if (!is_xmlnamestartchar(uc)) {\n                    LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_XML, elem, \"NameStartChar of the element\");\n                    goto error;\n                }\n                e += size;\n                uc = lyxml_getutf8(ctx, e, &size);\n                while (is_xmlnamechar(uc)) {\n                    if (*e == ':') {\n                        /* element in a namespace */\n                        start = e + 1;\n\n                        /* look for the prefix in namespaces */\n                        if (!prefix || memcmp(prefix, c, e - c)) {\n                            LOGVAL(ctx, LYE_SPEC, LY_VLOG_XML, elem,\n                                   \"Invalid (different namespaces) opening (%s) and closing element tags.\", elem->name);\n                            goto error;\n                        }\n                        c = start;\n                    }\n                    e += size;\n                    uc = lyxml_getutf8(ctx, e, &size);\n                }\n                if (!*e) {\n                    LOGVAL(ctx, LYE_EOF, LY_VLOG_NONE, NULL);\n                    goto error;\n                }\n\n                /* check that it corresponds to opening tag */\n                size = e - c;\n                str = malloc((size + 1) * sizeof *str);\n                LY_CHECK_ERR_GOTO(!str, LOGMEM(ctx), error);\n                memcpy(str, c, e - c);\n                str[e - c] = '\\0';\n                if (size != strlen(elem->name) || memcmp(str, elem->name, size)) {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_XML, elem,\n                           \"Invalid (mixed names) opening (%s) and closing (%s) element tags.\", elem->name, str);\n                    free(str);\n                    goto error;\n                }\n                free(str);\n                c = e;\n\n                ign_xmlws(c);\n                if (*c != '>') {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_XML, elem, \"Data after closing element tag \\\"%s\\\".\", elem->name);\n                    goto error;\n                }\n                c++;\n                if (!(elem->flags & LYXML_ELEM_MIXED) && !elem->content) {\n                    /* there was no content, but we don't want NULL (only if mixed content) */\n                    elem->content = lydict_insert(ctx, \"\", 0);\n                }\n                closed_flag = 1;\n                break;\n\n            } else if (!strncmp(c, \"<?\", 2)) {\n                if (lws) {\n                    /* leading white spaces were only formatting */\n                    lws = NULL;\n                }\n                /* PI - ignore it */\n                c += 2;\n                if (parse_ignore(ctx, c, \"?>\", &size)) {\n                    goto error;\n                }\n                c += size;\n            } else if (!strncmp(c, \"<!--\", 4)) {\n                if (lws) {\n                    /* leading white spaces were only formatting */\n                    lws = NULL;\n                }\n                /* Comment - ignore it */\n                c += 4;\n                if (parse_ignore(ctx, c, \"-->\", &size)) {\n                    goto error;\n                }\n                c += size;\n            } else if (!strncmp(c, \"<![CDATA[\", 9)) {\n                /* CDSect */\n                goto store_content;\n            } else if (*c == '<') {\n                if (lws) {\n                    if (elem->flags & LYXML_ELEM_MIXED) {\n                        /* we have a mixed content */\n                        goto store_content;\n                    } else {\n                        /* leading white spaces were only formatting */\n                        lws = NULL;\n                    }\n                }\n                if (elem->content) {\n                    /* we have a mixed content */\n                    if (options & LYXML_PARSE_NOMIXEDCONTENT) {\n                        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_XML, elem, \"XML element with mixed content\");\n                        goto error;\n                    }\n                    child = calloc(1, sizeof *child);\n                    LY_CHECK_ERR_GOTO(!child, LOGMEM(ctx), error);\n                    child->content = elem->content;\n                    elem->content = NULL;\n                    lyxml_add_child(ctx, elem, child);\n                    elem->flags |= LYXML_ELEM_MIXED;\n                }\n                child = lyxml_parse_elem(ctx, c, &size, elem, options);\n                if (!child) {\n                    goto error;\n                }\n                c += size;      /* move after processed child element */\n            } else if (is_xmlws(*c)) {\n                lws = c;\n                ign_xmlws(c);\n            } else {\nstore_content:\n                /* store text content */\n                if (lws) {\n                    /* process content including the leading white spaces */\n                    c = lws;\n                    lws = NULL;\n                }\n                str = parse_text(ctx, c, '<', &size);\n                if (!str && !size) {\n                    goto error;\n                }\n                elem->content = lydict_insert_zc(ctx, str);\n                c += size;      /* move after processed text content */\n\n                if (elem->child) {\n                    /* we have a mixed content */\n                    if (options & LYXML_PARSE_NOMIXEDCONTENT) {\n                        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_XML, elem, \"XML element with mixed content\");\n                        goto error;\n                    }\n                    child = calloc(1, sizeof *child);\n                    LY_CHECK_ERR_GOTO(!child, LOGMEM(ctx), error);\n                    child->content = elem->content;\n                    elem->content = NULL;\n                    lyxml_add_child(ctx, elem, child);\n                    elem->flags |= LYXML_ELEM_MIXED;\n                }\n            }\n        }\n    } else {\n        /* process attribute */\n        attr = parse_attr(ctx, c, &size, elem);\n        if (!attr) {\n            goto error;\n        }\n        c += size;              /* move after processed attribute */\n\n        /* check namespace */\n        if (attr->type == LYXML_ATTR_NS) {\n            if ((!prefix || !prefix[0]) && !attr->name) {\n                if (attr->value) {\n                    /* default prefix */\n                    elem->ns = (struct lyxml_ns *)attr;\n                } else {\n                    /* xmlns=\"\" -> no namespace */\n                    nons_flag = 1;\n                }\n            } else if (prefix && prefix[0] && attr->name && !strncmp(attr->name, prefix, prefix_len + 1)) {\n                /* matching namespace with prefix */\n                elem->ns = (struct lyxml_ns *)attr;\n            }\n        }\n\n        /* go back to finish element processing */\n        goto process;\n    }\n\n    *len = c - data;\n\n    if (!closed_flag) {\n        LOGVAL(ctx, LYE_XML_MISS, LY_VLOG_XML, elem, \"closing element tag\", elem->name);\n        goto error;\n    }\n\n    /* resolve all attribute prefixes */\n    LY_TREE_FOR(elem->attr, attr) {\n        if (attr->type == LYXML_ATTR_STD_UNRES) {\n            str = (char *)attr->ns;\n            attr->ns = lyxml_get_ns(elem, str);\n            free(str);\n            attr->type = LYXML_ATTR_STD;\n        }\n    }\n\n    if (!elem->ns && !nons_flag && parent) {\n        elem->ns = lyxml_get_ns(parent, prefix_len ? prefix : NULL);\n    }\n    free(prefix);\n    return elem;\n\nerror:\n    lyxml_free(ctx, elem);\n    free(prefix);\n    return NULL;\n}",
        "func": "struct lyxml_elem *\nlyxml_parse_elem(struct ly_ctx *ctx, const char *data, unsigned int *len, struct lyxml_elem *parent, int options,\n                 int bt_count)\n{\n    const char *c = data, *start, *e;\n    const char *lws;    /* leading white space for handling mixed content */\n    int uc;\n    char *str;\n    char *prefix = NULL;\n    unsigned int prefix_len = 0;\n    struct lyxml_elem *elem = NULL, *child;\n    struct lyxml_attr *attr;\n    unsigned int size;\n    int nons_flag = 0, closed_flag = 0;\n\n    *len = 0;\n\n    if (bt_count > LY_RECURSION_LIMIT) {\n        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_NONE, NULL, \"Recursion limit %d reached\", LY_RECURSION_LIMIT);\n        return NULL;\n    }\n\n    if (*c != '<') {\n        return NULL;\n    }\n\n    /* locate element name */\n    c++;\n    e = c;\n\n    uc = lyxml_getutf8(ctx, e, &size);\n    if (!is_xmlnamestartchar(uc)) {\n        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_NONE, NULL, \"NameStartChar of the element\");\n        return NULL;\n    }\n    e += size;\n    uc = lyxml_getutf8(ctx, e, &size);\n    while (is_xmlnamechar(uc)) {\n        if (*e == ':') {\n            if (prefix_len) {\n                LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_NONE, NULL, \"element name, multiple colons found\");\n                goto error;\n            }\n            /* element in a namespace */\n            start = e + 1;\n\n            /* look for the prefix in namespaces */\n            prefix_len = e - c;\n            LY_CHECK_ERR_GOTO(prefix, LOGVAL(ctx, LYE_XML_INCHAR, LY_VLOG_NONE, NULL, e), error);\n            prefix = malloc((prefix_len + 1) * sizeof *prefix);\n            LY_CHECK_ERR_GOTO(!prefix, LOGMEM(ctx), error);\n            memcpy(prefix, c, prefix_len);\n            prefix[prefix_len] = '\\0';\n            c = start;\n        }\n        e += size;\n        uc = lyxml_getutf8(ctx, e, &size);\n    }\n    if (!*e) {\n        LOGVAL(ctx, LYE_EOF, LY_VLOG_NONE, NULL);\n        free(prefix);\n        return NULL;\n    }\n\n    /* allocate element structure */\n    elem = calloc(1, sizeof *elem);\n    LY_CHECK_ERR_RETURN(!elem, free(prefix); LOGMEM(ctx), NULL);\n\n    elem->next = NULL;\n    elem->prev = elem;\n    if (parent) {\n        lyxml_add_child(ctx, parent, elem);\n    }\n\n    /* store the name into the element structure */\n    elem->name = lydict_insert(ctx, c, e - c);\n    c = e;\n\nprocess:\n    ign_xmlws(c);\n    if (!strncmp(\"/>\", c, 2)) {\n        /* we are done, it was EmptyElemTag */\n        c += 2;\n        elem->content = lydict_insert(ctx, \"\", 0);\n        closed_flag = 1;\n    } else if (*c == '>') {\n        /* process element content */\n        c++;\n        lws = NULL;\n\n        while (*c) {\n            if (!strncmp(c, \"</\", 2)) {\n                if (lws && !elem->child) {\n                    /* leading white spaces were actually content */\n                    goto store_content;\n                }\n\n                /* Etag */\n                c += 2;\n                /* get name and check it */\n                e = c;\n                uc = lyxml_getutf8(ctx, e, &size);\n                if (!is_xmlnamestartchar(uc)) {\n                    LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_XML, elem, \"NameStartChar of the element\");\n                    goto error;\n                }\n                e += size;\n                uc = lyxml_getutf8(ctx, e, &size);\n                while (is_xmlnamechar(uc)) {\n                    if (*e == ':') {\n                        /* element in a namespace */\n                        start = e + 1;\n\n                        /* look for the prefix in namespaces */\n                        if (!prefix || memcmp(prefix, c, e - c)) {\n                            LOGVAL(ctx, LYE_SPEC, LY_VLOG_XML, elem,\n                                   \"Invalid (different namespaces) opening (%s) and closing element tags.\", elem->name);\n                            goto error;\n                        }\n                        c = start;\n                    }\n                    e += size;\n                    uc = lyxml_getutf8(ctx, e, &size);\n                }\n                if (!*e) {\n                    LOGVAL(ctx, LYE_EOF, LY_VLOG_NONE, NULL);\n                    goto error;\n                }\n\n                /* check that it corresponds to opening tag */\n                size = e - c;\n                str = malloc((size + 1) * sizeof *str);\n                LY_CHECK_ERR_GOTO(!str, LOGMEM(ctx), error);\n                memcpy(str, c, e - c);\n                str[e - c] = '\\0';\n                if (size != strlen(elem->name) || memcmp(str, elem->name, size)) {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_XML, elem,\n                           \"Invalid (mixed names) opening (%s) and closing (%s) element tags.\", elem->name, str);\n                    free(str);\n                    goto error;\n                }\n                free(str);\n                c = e;\n\n                ign_xmlws(c);\n                if (*c != '>') {\n                    LOGVAL(ctx, LYE_SPEC, LY_VLOG_XML, elem, \"Data after closing element tag \\\"%s\\\".\", elem->name);\n                    goto error;\n                }\n                c++;\n                if (!(elem->flags & LYXML_ELEM_MIXED) && !elem->content) {\n                    /* there was no content, but we don't want NULL (only if mixed content) */\n                    elem->content = lydict_insert(ctx, \"\", 0);\n                }\n                closed_flag = 1;\n                break;\n\n            } else if (!strncmp(c, \"<?\", 2)) {\n                if (lws) {\n                    /* leading white spaces were only formatting */\n                    lws = NULL;\n                }\n                /* PI - ignore it */\n                c += 2;\n                if (parse_ignore(ctx, c, \"?>\", &size)) {\n                    goto error;\n                }\n                c += size;\n            } else if (!strncmp(c, \"<!--\", 4)) {\n                if (lws) {\n                    /* leading white spaces were only formatting */\n                    lws = NULL;\n                }\n                /* Comment - ignore it */\n                c += 4;\n                if (parse_ignore(ctx, c, \"-->\", &size)) {\n                    goto error;\n                }\n                c += size;\n            } else if (!strncmp(c, \"<![CDATA[\", 9)) {\n                /* CDSect */\n                goto store_content;\n            } else if (*c == '<') {\n                if (lws) {\n                    if (elem->flags & LYXML_ELEM_MIXED) {\n                        /* we have a mixed content */\n                        goto store_content;\n                    } else {\n                        /* leading white spaces were only formatting */\n                        lws = NULL;\n                    }\n                }\n                if (elem->content) {\n                    /* we have a mixed content */\n                    if (options & LYXML_PARSE_NOMIXEDCONTENT) {\n                        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_XML, elem, \"XML element with mixed content\");\n                        goto error;\n                    }\n                    child = calloc(1, sizeof *child);\n                    LY_CHECK_ERR_GOTO(!child, LOGMEM(ctx), error);\n                    child->content = elem->content;\n                    elem->content = NULL;\n                    lyxml_add_child(ctx, elem, child);\n                    elem->flags |= LYXML_ELEM_MIXED;\n                }\n                child = lyxml_parse_elem(ctx, c, &size, elem, options, bt_count + 1);\n                if (!child) {\n                    goto error;\n                }\n                c += size;      /* move after processed child element */\n            } else if (is_xmlws(*c)) {\n                lws = c;\n                ign_xmlws(c);\n            } else {\nstore_content:\n                /* store text content */\n                if (lws) {\n                    /* process content including the leading white spaces */\n                    c = lws;\n                    lws = NULL;\n                }\n                str = parse_text(ctx, c, '<', &size);\n                if (!str && !size) {\n                    goto error;\n                }\n                elem->content = lydict_insert_zc(ctx, str);\n                c += size;      /* move after processed text content */\n\n                if (elem->child) {\n                    /* we have a mixed content */\n                    if (options & LYXML_PARSE_NOMIXEDCONTENT) {\n                        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_XML, elem, \"XML element with mixed content\");\n                        goto error;\n                    }\n                    child = calloc(1, sizeof *child);\n                    LY_CHECK_ERR_GOTO(!child, LOGMEM(ctx), error);\n                    child->content = elem->content;\n                    elem->content = NULL;\n                    lyxml_add_child(ctx, elem, child);\n                    elem->flags |= LYXML_ELEM_MIXED;\n                }\n            }\n        }\n    } else {\n        /* process attribute */\n        attr = parse_attr(ctx, c, &size, elem);\n        if (!attr) {\n            goto error;\n        }\n        c += size;              /* move after processed attribute */\n\n        /* check namespace */\n        if (attr->type == LYXML_ATTR_NS) {\n            if ((!prefix || !prefix[0]) && !attr->name) {\n                if (attr->value) {\n                    /* default prefix */\n                    elem->ns = (struct lyxml_ns *)attr;\n                } else {\n                    /* xmlns=\"\" -> no namespace */\n                    nons_flag = 1;\n                }\n            } else if (prefix && prefix[0] && attr->name && !strncmp(attr->name, prefix, prefix_len + 1)) {\n                /* matching namespace with prefix */\n                elem->ns = (struct lyxml_ns *)attr;\n            }\n        }\n\n        /* go back to finish element processing */\n        goto process;\n    }\n\n    *len = c - data;\n\n    if (!closed_flag) {\n        LOGVAL(ctx, LYE_XML_MISS, LY_VLOG_XML, elem, \"closing element tag\", elem->name);\n        goto error;\n    }\n\n    /* resolve all attribute prefixes */\n    LY_TREE_FOR(elem->attr, attr) {\n        if (attr->type == LYXML_ATTR_STD_UNRES) {\n            str = (char *)attr->ns;\n            attr->ns = lyxml_get_ns(elem, str);\n            free(str);\n            attr->type = LYXML_ATTR_STD;\n        }\n    }\n\n    if (!elem->ns && !nons_flag && parent) {\n        elem->ns = lyxml_get_ns(parent, prefix_len ? prefix : NULL);\n    }\n    free(prefix);\n    return elem;\n\nerror:\n    lyxml_free(ctx, elem);\n    free(prefix);\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n struct lyxml_elem *\n-lyxml_parse_elem(struct ly_ctx *ctx, const char *data, unsigned int *len, struct lyxml_elem *parent, int options)\n+lyxml_parse_elem(struct ly_ctx *ctx, const char *data, unsigned int *len, struct lyxml_elem *parent, int options,\n+                 int bt_count)\n {\n     const char *c = data, *start, *e;\n     const char *lws;    /* leading white space for handling mixed content */\n@@ -14,6 +15,11 @@\n \n     *len = 0;\n \n+    if (bt_count > LY_RECURSION_LIMIT) {\n+        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_NONE, NULL, \"Recursion limit %d reached\", LY_RECURSION_LIMIT);\n+        return NULL;\n+    }\n+\n     if (*c != '<') {\n         return NULL;\n     }\n@@ -197,7 +203,7 @@\n                     lyxml_add_child(ctx, elem, child);\n                     elem->flags |= LYXML_ELEM_MIXED;\n                 }\n-                child = lyxml_parse_elem(ctx, c, &size, elem, options);\n+                child = lyxml_parse_elem(ctx, c, &size, elem, options, bt_count + 1);\n                 if (!child) {\n                     goto error;\n                 }",
        "diff_line_info": {
            "deleted_lines": [
                "lyxml_parse_elem(struct ly_ctx *ctx, const char *data, unsigned int *len, struct lyxml_elem *parent, int options)",
                "                child = lyxml_parse_elem(ctx, c, &size, elem, options);"
            ],
            "added_lines": [
                "lyxml_parse_elem(struct ly_ctx *ctx, const char *data, unsigned int *len, struct lyxml_elem *parent, int options,",
                "                 int bt_count)",
                "    if (bt_count > LY_RECURSION_LIMIT) {",
                "        LOGVAL(ctx, LYE_XML_INVAL, LY_VLOG_NONE, NULL, \"Recursion limit %d reached\", LY_RECURSION_LIMIT);",
                "        return NULL;",
                "    }",
                "",
                "                child = lyxml_parse_elem(ctx, c, &size, elem, options, bt_count + 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28903",
        "func_name": "CESNET/libyang/lyxml_parse_mem",
        "description": "A stack overflow in libyang <= v1.0.225 can cause a denial of service through function lyxml_parse_mem(). lyxml_parse_elem() function will be called recursively, which will consume stack space and lead to crash.",
        "git_url": "https://github.com/CESNET/libyang/commit/298b30ea4ebee137226acf9bb38678bd82704582",
        "commit_title": "common FEATURE add a hard limit for recursion",
        "commit_text": " Fixes #1453",
        "func_before": "lyxml_elem *\nlyxml_parse_mem(struct ly_ctx *ctx, const char *data, int options)\n{\n    FUN_IN;\n\n    const char *c = data;\n    unsigned int len;\n    struct lyxml_elem *root, *first = NULL, *next;\n\n    if (!ctx) {\n        LOGARG;\n        return NULL;\n    }\n\n    if (!data) {\n        /* nothing to parse */\n        return NULL;\n    }\n\nrepeat:\n    /* process document */\n    while (1) {\n        if (!*c) {\n            /* eof */\n            return first;\n        } else if (is_xmlws(*c)) {\n            /* skip whitespaces */\n            ign_xmlws(c);\n        } else if (!strncmp(c, \"<?\", 2)) {\n            /* XMLDecl or PI - ignore it */\n            c += 2;\n            if (parse_ignore(ctx, c, \"?>\", &len)) {\n                goto error;\n            }\n            c += len;\n        } else if (!strncmp(c, \"<!--\", 4)) {\n            /* Comment - ignore it */\n            c += 2;\n            if (parse_ignore(ctx, c, \"-->\", &len)) {\n                goto error;\n            }\n            c += len;\n        } else if (!strncmp(c, \"<!\", 2)) {\n            /* DOCTYPE */\n            /* TODO - standalone ignore counting < and > */\n            LOGERR(ctx, LY_EINVAL, \"DOCTYPE not supported in XML documents.\");\n            goto error;\n        } else if (*c == '<') {\n            /* element - process it in next loop to strictly follow XML\n             * format\n             */\n            break;\n        } else {\n            LOGVAL(ctx, LYE_XML_INCHAR, LY_VLOG_NONE, NULL, c);\n            goto error;\n        }\n    }\n\n    root = lyxml_parse_elem(ctx, c, &len, NULL, options);\n    if (!root) {\n        goto error;\n    } else if (!first) {\n        first = root;\n    } else {\n        first->prev->next = root;\n        root->prev = first->prev;\n        first->prev = root;\n    }\n    c += len;\n\n    /* ignore the rest of document where can be comments, PIs and whitespaces,\n     * note that we are not detecting syntax errors in these parts\n     */\n    ign_xmlws(c);\n    if (*c) {\n        if (options & LYXML_PARSE_MULTIROOT) {\n            goto repeat;\n        } else {\n            LOGWRN(ctx, \"There are some not parsed data:\\n%s\", c);\n        }\n    }\n\n    return first;\n\nerror:\n    LY_TREE_FOR_SAFE(first, next, root) {\n        lyxml_free(ctx, root);\n    }\n    return NULL;\n}",
        "func": "lyxml_elem *\nlyxml_parse_mem(struct ly_ctx *ctx, const char *data, int options)\n{\n    FUN_IN;\n\n    const char *c = data;\n    unsigned int len;\n    struct lyxml_elem *root, *first = NULL, *next;\n\n    if (!ctx) {\n        LOGARG;\n        return NULL;\n    }\n\n    if (!data) {\n        /* nothing to parse */\n        return NULL;\n    }\n\nrepeat:\n    /* process document */\n    while (1) {\n        if (!*c) {\n            /* eof */\n            return first;\n        } else if (is_xmlws(*c)) {\n            /* skip whitespaces */\n            ign_xmlws(c);\n        } else if (!strncmp(c, \"<?\", 2)) {\n            /* XMLDecl or PI - ignore it */\n            c += 2;\n            if (parse_ignore(ctx, c, \"?>\", &len)) {\n                goto error;\n            }\n            c += len;\n        } else if (!strncmp(c, \"<!--\", 4)) {\n            /* Comment - ignore it */\n            c += 2;\n            if (parse_ignore(ctx, c, \"-->\", &len)) {\n                goto error;\n            }\n            c += len;\n        } else if (!strncmp(c, \"<!\", 2)) {\n            /* DOCTYPE */\n            /* TODO - standalone ignore counting < and > */\n            LOGERR(ctx, LY_EINVAL, \"DOCTYPE not supported in XML documents.\");\n            goto error;\n        } else if (*c == '<') {\n            /* element - process it in next loop to strictly follow XML\n             * format\n             */\n            break;\n        } else {\n            LOGVAL(ctx, LYE_XML_INCHAR, LY_VLOG_NONE, NULL, c);\n            goto error;\n        }\n    }\n\n    root = lyxml_parse_elem(ctx, c, &len, NULL, options, 0);\n    if (!root) {\n        goto error;\n    } else if (!first) {\n        first = root;\n    } else {\n        first->prev->next = root;\n        root->prev = first->prev;\n        first->prev = root;\n    }\n    c += len;\n\n    /* ignore the rest of document where can be comments, PIs and whitespaces,\n     * note that we are not detecting syntax errors in these parts\n     */\n    ign_xmlws(c);\n    if (*c) {\n        if (options & LYXML_PARSE_MULTIROOT) {\n            goto repeat;\n        } else {\n            LOGWRN(ctx, \"There are some not parsed data:\\n%s\", c);\n        }\n    }\n\n    return first;\n\nerror:\n    LY_TREE_FOR_SAFE(first, next, root) {\n        lyxml_free(ctx, root);\n    }\n    return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,7 +56,7 @@\n         }\n     }\n \n-    root = lyxml_parse_elem(ctx, c, &len, NULL, options);\n+    root = lyxml_parse_elem(ctx, c, &len, NULL, options, 0);\n     if (!root) {\n         goto error;\n     } else if (!first) {",
        "diff_line_info": {
            "deleted_lines": [
                "    root = lyxml_parse_elem(ctx, c, &len, NULL, options);"
            ],
            "added_lines": [
                "    root = lyxml_parse_elem(ctx, c, &len, NULL, options, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-36691",
        "func_name": "torvalds/linux/__nla_parse",
        "description": "An issue was discovered in the Linux kernel before 5.8. lib/nlattr.c allows attackers to cause a denial of service (unbounded recursion) via a nested Netlink policy with a back reference.",
        "git_url": "https://github.com/torvalds/linux/commit/7690aa1cdf7c4565ad6b013b324c28b685505e24",
        "commit_title": "netlink: limit recursion depth in policy validation",
        "commit_text": " Now that we have nested policies, we can theoretically recurse forever parsing attributes if a (sub-)policy refers back to a higher level one. This is a situation that has happened in nl80211, and we've avoided it there by not linking it.  Add some code to netlink parsing to limit recursion depth. ",
        "func_before": "int __nla_parse(struct nlattr **tb, int maxtype,\n\t\tconst struct nlattr *head, int len,\n\t\tconst struct nla_policy *policy, unsigned int validate,\n\t\tstruct netlink_ext_ack *extack)\n{\n\treturn __nla_validate_parse(head, len, maxtype, policy, validate,\n\t\t\t\t    extack, tb);\n}",
        "func": "int __nla_parse(struct nlattr **tb, int maxtype,\n\t\tconst struct nlattr *head, int len,\n\t\tconst struct nla_policy *policy, unsigned int validate,\n\t\tstruct netlink_ext_ack *extack)\n{\n\treturn __nla_validate_parse(head, len, maxtype, policy, validate,\n\t\t\t\t    extack, tb, 0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,5 +4,5 @@\n \t\tstruct netlink_ext_ack *extack)\n {\n \treturn __nla_validate_parse(head, len, maxtype, policy, validate,\n-\t\t\t\t    extack, tb);\n+\t\t\t\t    extack, tb, 0);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t    extack, tb);"
            ],
            "added_lines": [
                "\t\t\t\t    extack, tb, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-36691",
        "func_name": "torvalds/linux/nla_validate_array",
        "description": "An issue was discovered in the Linux kernel before 5.8. lib/nlattr.c allows attackers to cause a denial of service (unbounded recursion) via a nested Netlink policy with a back reference.",
        "git_url": "https://github.com/torvalds/linux/commit/7690aa1cdf7c4565ad6b013b324c28b685505e24",
        "commit_title": "netlink: limit recursion depth in policy validation",
        "commit_text": " Now that we have nested policies, we can theoretically recurse forever parsing attributes if a (sub-)policy refers back to a higher level one. This is a situation that has happened in nl80211, and we've avoided it there by not linking it.  Add some code to netlink parsing to limit recursion depth. ",
        "func_before": "static int nla_validate_array(const struct nlattr *head, int len, int maxtype,\n\t\t\t      const struct nla_policy *policy,\n\t\t\t      struct netlink_ext_ack *extack,\n\t\t\t      unsigned int validate)\n{\n\tconst struct nlattr *entry;\n\tint rem;\n\n\tnla_for_each_attr(entry, head, len, rem) {\n\t\tint ret;\n\n\t\tif (nla_len(entry) == 0)\n\t\t\tcontinue;\n\n\t\tif (nla_len(entry) < NLA_HDRLEN) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, entry,\n\t\t\t\t\t    \"Array element too short\");\n\t\t\treturn -ERANGE;\n\t\t}\n\n\t\tret = __nla_validate(nla_data(entry), nla_len(entry),\n\t\t\t\t     maxtype, policy, validate, extack);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "func": "static int nla_validate_array(const struct nlattr *head, int len, int maxtype,\n\t\t\t      const struct nla_policy *policy,\n\t\t\t      struct netlink_ext_ack *extack,\n\t\t\t      unsigned int validate, unsigned int depth)\n{\n\tconst struct nlattr *entry;\n\tint rem;\n\n\tnla_for_each_attr(entry, head, len, rem) {\n\t\tint ret;\n\n\t\tif (nla_len(entry) == 0)\n\t\t\tcontinue;\n\n\t\tif (nla_len(entry) < NLA_HDRLEN) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, entry,\n\t\t\t\t\t    \"Array element too short\");\n\t\t\treturn -ERANGE;\n\t\t}\n\n\t\tret = __nla_validate_parse(nla_data(entry), nla_len(entry),\n\t\t\t\t\t   maxtype, policy, validate, extack,\n\t\t\t\t\t   NULL, depth + 1);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static int nla_validate_array(const struct nlattr *head, int len, int maxtype,\n \t\t\t      const struct nla_policy *policy,\n \t\t\t      struct netlink_ext_ack *extack,\n-\t\t\t      unsigned int validate)\n+\t\t\t      unsigned int validate, unsigned int depth)\n {\n \tconst struct nlattr *entry;\n \tint rem;\n@@ -18,8 +18,9 @@\n \t\t\treturn -ERANGE;\n \t\t}\n \n-\t\tret = __nla_validate(nla_data(entry), nla_len(entry),\n-\t\t\t\t     maxtype, policy, validate, extack);\n+\t\tret = __nla_validate_parse(nla_data(entry), nla_len(entry),\n+\t\t\t\t\t   maxtype, policy, validate, extack,\n+\t\t\t\t\t   NULL, depth + 1);\n \t\tif (ret < 0)\n \t\t\treturn ret;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t      unsigned int validate)",
                "\t\tret = __nla_validate(nla_data(entry), nla_len(entry),",
                "\t\t\t\t     maxtype, policy, validate, extack);"
            ],
            "added_lines": [
                "\t\t\t      unsigned int validate, unsigned int depth)",
                "\t\tret = __nla_validate_parse(nla_data(entry), nla_len(entry),",
                "\t\t\t\t\t   maxtype, policy, validate, extack,",
                "\t\t\t\t\t   NULL, depth + 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-36691",
        "func_name": "torvalds/linux/validate_nla",
        "description": "An issue was discovered in the Linux kernel before 5.8. lib/nlattr.c allows attackers to cause a denial of service (unbounded recursion) via a nested Netlink policy with a back reference.",
        "git_url": "https://github.com/torvalds/linux/commit/7690aa1cdf7c4565ad6b013b324c28b685505e24",
        "commit_title": "netlink: limit recursion depth in policy validation",
        "commit_text": " Now that we have nested policies, we can theoretically recurse forever parsing attributes if a (sub-)policy refers back to a higher level one. This is a situation that has happened in nl80211, and we've avoided it there by not linking it.  Add some code to netlink parsing to limit recursion depth. ",
        "func_before": "static int validate_nla(const struct nlattr *nla, int maxtype,\n\t\t\tconst struct nla_policy *policy, unsigned int validate,\n\t\t\tstruct netlink_ext_ack *extack)\n{\n\tu16 strict_start_type = policy[0].strict_start_type;\n\tconst struct nla_policy *pt;\n\tint minlen = 0, attrlen = nla_len(nla), type = nla_type(nla);\n\tint err = -ERANGE;\n\n\tif (strict_start_type && type >= strict_start_type)\n\t\tvalidate |= NL_VALIDATE_STRICT;\n\n\tif (type <= 0 || type > maxtype)\n\t\treturn 0;\n\n\tpt = &policy[type];\n\n\tBUG_ON(pt->type > NLA_TYPE_MAX);\n\n\tif ((nla_attr_len[pt->type] && attrlen != nla_attr_len[pt->type]) ||\n\t    (pt->type == NLA_EXACT_LEN_WARN && attrlen != pt->len)) {\n\t\tpr_warn_ratelimited(\"netlink: '%s': attribute type %d has an invalid length.\\n\",\n\t\t\t\t    current->comm, type);\n\t\tif (validate & NL_VALIDATE_STRICT_ATTRS) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"invalid attribute length\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (validate & NL_VALIDATE_NESTED) {\n\t\tif ((pt->type == NLA_NESTED || pt->type == NLA_NESTED_ARRAY) &&\n\t\t    !(nla->nla_type & NLA_F_NESTED)) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"NLA_F_NESTED is missing\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (pt->type != NLA_NESTED && pt->type != NLA_NESTED_ARRAY &&\n\t\t    pt->type != NLA_UNSPEC && (nla->nla_type & NLA_F_NESTED)) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"NLA_F_NESTED not expected\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tswitch (pt->type) {\n\tcase NLA_EXACT_LEN:\n\t\tif (attrlen != pt->len)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_REJECT:\n\t\tif (extack && pt->reject_message) {\n\t\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\t\textack->_msg = pt->reject_message;\n\t\t\treturn -EINVAL;\n\t\t}\n\t\terr = -EINVAL;\n\t\tgoto out_err;\n\n\tcase NLA_FLAG:\n\t\tif (attrlen > 0)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_BITFIELD32:\n\t\tif (attrlen != sizeof(struct nla_bitfield32))\n\t\t\tgoto out_err;\n\n\t\terr = validate_nla_bitfield32(nla, pt->bitfield32_valid);\n\t\tif (err)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_NUL_STRING:\n\t\tif (pt->len)\n\t\t\tminlen = min_t(int, attrlen, pt->len + 1);\n\t\telse\n\t\t\tminlen = attrlen;\n\n\t\tif (!minlen || memchr(nla_data(nla), '\\0', minlen) == NULL) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t\t/* fall through */\n\n\tcase NLA_STRING:\n\t\tif (attrlen < 1)\n\t\t\tgoto out_err;\n\n\t\tif (pt->len) {\n\t\t\tchar *buf = nla_data(nla);\n\n\t\t\tif (buf[attrlen - 1] == '\\0')\n\t\t\t\tattrlen--;\n\n\t\t\tif (attrlen > pt->len)\n\t\t\t\tgoto out_err;\n\t\t}\n\t\tbreak;\n\n\tcase NLA_BINARY:\n\t\tif (pt->len && attrlen > pt->len)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_NESTED:\n\t\t/* a nested attributes is allowed to be empty; if its not,\n\t\t * it must have a size of at least NLA_HDRLEN.\n\t\t */\n\t\tif (attrlen == 0)\n\t\t\tbreak;\n\t\tif (attrlen < NLA_HDRLEN)\n\t\t\tgoto out_err;\n\t\tif (pt->nested_policy) {\n\t\t\terr = __nla_validate(nla_data(nla), nla_len(nla), pt->len,\n\t\t\t\t\t     pt->nested_policy, validate,\n\t\t\t\t\t     extack);\n\t\t\tif (err < 0) {\n\t\t\t\t/*\n\t\t\t\t * return directly to preserve the inner\n\t\t\t\t * error message/attribute pointer\n\t\t\t\t */\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase NLA_NESTED_ARRAY:\n\t\t/* a nested array attribute is allowed to be empty; if its not,\n\t\t * it must have a size of at least NLA_HDRLEN.\n\t\t */\n\t\tif (attrlen == 0)\n\t\t\tbreak;\n\t\tif (attrlen < NLA_HDRLEN)\n\t\t\tgoto out_err;\n\t\tif (pt->nested_policy) {\n\t\t\tint err;\n\n\t\t\terr = nla_validate_array(nla_data(nla), nla_len(nla),\n\t\t\t\t\t\t pt->len, pt->nested_policy,\n\t\t\t\t\t\t extack, validate);\n\t\t\tif (err < 0) {\n\t\t\t\t/*\n\t\t\t\t * return directly to preserve the inner\n\t\t\t\t * error message/attribute pointer\n\t\t\t\t */\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase NLA_UNSPEC:\n\t\tif (validate & NL_VALIDATE_UNSPEC) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"Unsupported attribute\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t/* fall through */\n\tcase NLA_MIN_LEN:\n\t\tif (attrlen < pt->len)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tdefault:\n\t\tif (pt->len)\n\t\t\tminlen = pt->len;\n\t\telse\n\t\t\tminlen = nla_attr_minlen[pt->type];\n\n\t\tif (attrlen < minlen)\n\t\t\tgoto out_err;\n\t}\n\n\t/* further validation */\n\tswitch (pt->validation_type) {\n\tcase NLA_VALIDATE_NONE:\n\t\t/* nothing to do */\n\t\tbreak;\n\tcase NLA_VALIDATE_RANGE:\n\tcase NLA_VALIDATE_MIN:\n\tcase NLA_VALIDATE_MAX:\n\t\terr = nla_validate_int_range(pt, nla, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\tbreak;\n\tcase NLA_VALIDATE_FUNCTION:\n\t\tif (pt->validate) {\n\t\t\terr = pt->validate(nla, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn 0;\nout_err:\n\tNL_SET_ERR_MSG_ATTR(extack, nla, \"Attribute failed policy validation\");\n\treturn err;\n}",
        "func": "static int validate_nla(const struct nlattr *nla, int maxtype,\n\t\t\tconst struct nla_policy *policy, unsigned int validate,\n\t\t\tstruct netlink_ext_ack *extack, unsigned int depth)\n{\n\tu16 strict_start_type = policy[0].strict_start_type;\n\tconst struct nla_policy *pt;\n\tint minlen = 0, attrlen = nla_len(nla), type = nla_type(nla);\n\tint err = -ERANGE;\n\n\tif (strict_start_type && type >= strict_start_type)\n\t\tvalidate |= NL_VALIDATE_STRICT;\n\n\tif (type <= 0 || type > maxtype)\n\t\treturn 0;\n\n\tpt = &policy[type];\n\n\tBUG_ON(pt->type > NLA_TYPE_MAX);\n\n\tif ((nla_attr_len[pt->type] && attrlen != nla_attr_len[pt->type]) ||\n\t    (pt->type == NLA_EXACT_LEN_WARN && attrlen != pt->len)) {\n\t\tpr_warn_ratelimited(\"netlink: '%s': attribute type %d has an invalid length.\\n\",\n\t\t\t\t    current->comm, type);\n\t\tif (validate & NL_VALIDATE_STRICT_ATTRS) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"invalid attribute length\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (validate & NL_VALIDATE_NESTED) {\n\t\tif ((pt->type == NLA_NESTED || pt->type == NLA_NESTED_ARRAY) &&\n\t\t    !(nla->nla_type & NLA_F_NESTED)) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"NLA_F_NESTED is missing\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (pt->type != NLA_NESTED && pt->type != NLA_NESTED_ARRAY &&\n\t\t    pt->type != NLA_UNSPEC && (nla->nla_type & NLA_F_NESTED)) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"NLA_F_NESTED not expected\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tswitch (pt->type) {\n\tcase NLA_EXACT_LEN:\n\t\tif (attrlen != pt->len)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_REJECT:\n\t\tif (extack && pt->reject_message) {\n\t\t\tNL_SET_BAD_ATTR(extack, nla);\n\t\t\textack->_msg = pt->reject_message;\n\t\t\treturn -EINVAL;\n\t\t}\n\t\terr = -EINVAL;\n\t\tgoto out_err;\n\n\tcase NLA_FLAG:\n\t\tif (attrlen > 0)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_BITFIELD32:\n\t\tif (attrlen != sizeof(struct nla_bitfield32))\n\t\t\tgoto out_err;\n\n\t\terr = validate_nla_bitfield32(nla, pt->bitfield32_valid);\n\t\tif (err)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_NUL_STRING:\n\t\tif (pt->len)\n\t\t\tminlen = min_t(int, attrlen, pt->len + 1);\n\t\telse\n\t\t\tminlen = attrlen;\n\n\t\tif (!minlen || memchr(nla_data(nla), '\\0', minlen) == NULL) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out_err;\n\t\t}\n\t\t/* fall through */\n\n\tcase NLA_STRING:\n\t\tif (attrlen < 1)\n\t\t\tgoto out_err;\n\n\t\tif (pt->len) {\n\t\t\tchar *buf = nla_data(nla);\n\n\t\t\tif (buf[attrlen - 1] == '\\0')\n\t\t\t\tattrlen--;\n\n\t\t\tif (attrlen > pt->len)\n\t\t\t\tgoto out_err;\n\t\t}\n\t\tbreak;\n\n\tcase NLA_BINARY:\n\t\tif (pt->len && attrlen > pt->len)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tcase NLA_NESTED:\n\t\t/* a nested attributes is allowed to be empty; if its not,\n\t\t * it must have a size of at least NLA_HDRLEN.\n\t\t */\n\t\tif (attrlen == 0)\n\t\t\tbreak;\n\t\tif (attrlen < NLA_HDRLEN)\n\t\t\tgoto out_err;\n\t\tif (pt->nested_policy) {\n\t\t\terr = __nla_validate_parse(nla_data(nla), nla_len(nla),\n\t\t\t\t\t\t   pt->len, pt->nested_policy,\n\t\t\t\t\t\t   validate, extack, NULL,\n\t\t\t\t\t\t   depth + 1);\n\t\t\tif (err < 0) {\n\t\t\t\t/*\n\t\t\t\t * return directly to preserve the inner\n\t\t\t\t * error message/attribute pointer\n\t\t\t\t */\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase NLA_NESTED_ARRAY:\n\t\t/* a nested array attribute is allowed to be empty; if its not,\n\t\t * it must have a size of at least NLA_HDRLEN.\n\t\t */\n\t\tif (attrlen == 0)\n\t\t\tbreak;\n\t\tif (attrlen < NLA_HDRLEN)\n\t\t\tgoto out_err;\n\t\tif (pt->nested_policy) {\n\t\t\tint err;\n\n\t\t\terr = nla_validate_array(nla_data(nla), nla_len(nla),\n\t\t\t\t\t\t pt->len, pt->nested_policy,\n\t\t\t\t\t\t extack, validate, depth);\n\t\t\tif (err < 0) {\n\t\t\t\t/*\n\t\t\t\t * return directly to preserve the inner\n\t\t\t\t * error message/attribute pointer\n\t\t\t\t */\n\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n\tcase NLA_UNSPEC:\n\t\tif (validate & NL_VALIDATE_UNSPEC) {\n\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t    \"Unsupported attribute\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t\t/* fall through */\n\tcase NLA_MIN_LEN:\n\t\tif (attrlen < pt->len)\n\t\t\tgoto out_err;\n\t\tbreak;\n\n\tdefault:\n\t\tif (pt->len)\n\t\t\tminlen = pt->len;\n\t\telse\n\t\t\tminlen = nla_attr_minlen[pt->type];\n\n\t\tif (attrlen < minlen)\n\t\t\tgoto out_err;\n\t}\n\n\t/* further validation */\n\tswitch (pt->validation_type) {\n\tcase NLA_VALIDATE_NONE:\n\t\t/* nothing to do */\n\t\tbreak;\n\tcase NLA_VALIDATE_RANGE:\n\tcase NLA_VALIDATE_MIN:\n\tcase NLA_VALIDATE_MAX:\n\t\terr = nla_validate_int_range(pt, nla, extack);\n\t\tif (err)\n\t\t\treturn err;\n\t\tbreak;\n\tcase NLA_VALIDATE_FUNCTION:\n\t\tif (pt->validate) {\n\t\t\terr = pt->validate(nla, extack);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t}\n\t\tbreak;\n\t}\n\n\treturn 0;\nout_err:\n\tNL_SET_ERR_MSG_ATTR(extack, nla, \"Attribute failed policy validation\");\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static int validate_nla(const struct nlattr *nla, int maxtype,\n \t\t\tconst struct nla_policy *policy, unsigned int validate,\n-\t\t\tstruct netlink_ext_ack *extack)\n+\t\t\tstruct netlink_ext_ack *extack, unsigned int depth)\n {\n \tu16 strict_start_type = policy[0].strict_start_type;\n \tconst struct nla_policy *pt;\n@@ -113,9 +113,10 @@\n \t\tif (attrlen < NLA_HDRLEN)\n \t\t\tgoto out_err;\n \t\tif (pt->nested_policy) {\n-\t\t\terr = __nla_validate(nla_data(nla), nla_len(nla), pt->len,\n-\t\t\t\t\t     pt->nested_policy, validate,\n-\t\t\t\t\t     extack);\n+\t\t\terr = __nla_validate_parse(nla_data(nla), nla_len(nla),\n+\t\t\t\t\t\t   pt->len, pt->nested_policy,\n+\t\t\t\t\t\t   validate, extack, NULL,\n+\t\t\t\t\t\t   depth + 1);\n \t\t\tif (err < 0) {\n \t\t\t\t/*\n \t\t\t\t * return directly to preserve the inner\n@@ -138,7 +139,7 @@\n \n \t\t\terr = nla_validate_array(nla_data(nla), nla_len(nla),\n \t\t\t\t\t\t pt->len, pt->nested_policy,\n-\t\t\t\t\t\t extack, validate);\n+\t\t\t\t\t\t extack, validate, depth);\n \t\t\tif (err < 0) {\n \t\t\t\t/*\n \t\t\t\t * return directly to preserve the inner",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tstruct netlink_ext_ack *extack)",
                "\t\t\terr = __nla_validate(nla_data(nla), nla_len(nla), pt->len,",
                "\t\t\t\t\t     pt->nested_policy, validate,",
                "\t\t\t\t\t     extack);",
                "\t\t\t\t\t\t extack, validate);"
            ],
            "added_lines": [
                "\t\t\tstruct netlink_ext_ack *extack, unsigned int depth)",
                "\t\t\terr = __nla_validate_parse(nla_data(nla), nla_len(nla),",
                "\t\t\t\t\t\t   pt->len, pt->nested_policy,",
                "\t\t\t\t\t\t   validate, extack, NULL,",
                "\t\t\t\t\t\t   depth + 1);",
                "\t\t\t\t\t\t extack, validate, depth);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-36691",
        "func_name": "torvalds/linux/__nla_validate_parse",
        "description": "An issue was discovered in the Linux kernel before 5.8. lib/nlattr.c allows attackers to cause a denial of service (unbounded recursion) via a nested Netlink policy with a back reference.",
        "git_url": "https://github.com/torvalds/linux/commit/7690aa1cdf7c4565ad6b013b324c28b685505e24",
        "commit_title": "netlink: limit recursion depth in policy validation",
        "commit_text": " Now that we have nested policies, we can theoretically recurse forever parsing attributes if a (sub-)policy refers back to a higher level one. This is a situation that has happened in nl80211, and we've avoided it there by not linking it.  Add some code to netlink parsing to limit recursion depth. ",
        "func_before": "static int __nla_validate_parse(const struct nlattr *head, int len, int maxtype,\n\t\t\t\tconst struct nla_policy *policy,\n\t\t\t\tunsigned int validate,\n\t\t\t\tstruct netlink_ext_ack *extack,\n\t\t\t\tstruct nlattr **tb)\n{\n\tconst struct nlattr *nla;\n\tint rem;\n\n\tif (tb)\n\t\tmemset(tb, 0, sizeof(struct nlattr *) * (maxtype + 1));\n\n\tnla_for_each_attr(nla, head, len, rem) {\n\t\tu16 type = nla_type(nla);\n\n\t\tif (type == 0 || type > maxtype) {\n\t\t\tif (validate & NL_VALIDATE_MAXTYPE) {\n\t\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t\t    \"Unknown attribute type\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tif (policy) {\n\t\t\tint err = validate_nla(nla, maxtype, policy,\n\t\t\t\t\t       validate, extack);\n\n\t\t\tif (err < 0)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (tb)\n\t\t\ttb[type] = (struct nlattr *)nla;\n\t}\n\n\tif (unlikely(rem > 0)) {\n\t\tpr_warn_ratelimited(\"netlink: %d bytes leftover after parsing attributes in process `%s'.\\n\",\n\t\t\t\t    rem, current->comm);\n\t\tNL_SET_ERR_MSG(extack, \"bytes leftover after parsing attributes\");\n\t\tif (validate & NL_VALIDATE_TRAILING)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}",
        "func": "static int __nla_validate_parse(const struct nlattr *head, int len, int maxtype,\n\t\t\t\tconst struct nla_policy *policy,\n\t\t\t\tunsigned int validate,\n\t\t\t\tstruct netlink_ext_ack *extack,\n\t\t\t\tstruct nlattr **tb, unsigned int depth)\n{\n\tconst struct nlattr *nla;\n\tint rem;\n\n\tif (depth >= MAX_POLICY_RECURSION_DEPTH) {\n\t\tNL_SET_ERR_MSG(extack,\n\t\t\t       \"allowed policy recursion depth exceeded\");\n\t\treturn -EINVAL;\n\t}\n\n\tif (tb)\n\t\tmemset(tb, 0, sizeof(struct nlattr *) * (maxtype + 1));\n\n\tnla_for_each_attr(nla, head, len, rem) {\n\t\tu16 type = nla_type(nla);\n\n\t\tif (type == 0 || type > maxtype) {\n\t\t\tif (validate & NL_VALIDATE_MAXTYPE) {\n\t\t\t\tNL_SET_ERR_MSG_ATTR(extack, nla,\n\t\t\t\t\t\t    \"Unknown attribute type\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tif (policy) {\n\t\t\tint err = validate_nla(nla, maxtype, policy,\n\t\t\t\t\t       validate, extack, depth);\n\n\t\t\tif (err < 0)\n\t\t\t\treturn err;\n\t\t}\n\n\t\tif (tb)\n\t\t\ttb[type] = (struct nlattr *)nla;\n\t}\n\n\tif (unlikely(rem > 0)) {\n\t\tpr_warn_ratelimited(\"netlink: %d bytes leftover after parsing attributes in process `%s'.\\n\",\n\t\t\t\t    rem, current->comm);\n\t\tNL_SET_ERR_MSG(extack, \"bytes leftover after parsing attributes\");\n\t\tif (validate & NL_VALIDATE_TRAILING)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,10 +2,16 @@\n \t\t\t\tconst struct nla_policy *policy,\n \t\t\t\tunsigned int validate,\n \t\t\t\tstruct netlink_ext_ack *extack,\n-\t\t\t\tstruct nlattr **tb)\n+\t\t\t\tstruct nlattr **tb, unsigned int depth)\n {\n \tconst struct nlattr *nla;\n \tint rem;\n+\n+\tif (depth >= MAX_POLICY_RECURSION_DEPTH) {\n+\t\tNL_SET_ERR_MSG(extack,\n+\t\t\t       \"allowed policy recursion depth exceeded\");\n+\t\treturn -EINVAL;\n+\t}\n \n \tif (tb)\n \t\tmemset(tb, 0, sizeof(struct nlattr *) * (maxtype + 1));\n@@ -23,7 +29,7 @@\n \t\t}\n \t\tif (policy) {\n \t\t\tint err = validate_nla(nla, maxtype, policy,\n-\t\t\t\t\t       validate, extack);\n+\t\t\t\t\t       validate, extack, depth);\n \n \t\t\tif (err < 0)\n \t\t\t\treturn err;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tstruct nlattr **tb)",
                "\t\t\t\t\t       validate, extack);"
            ],
            "added_lines": [
                "\t\t\t\tstruct nlattr **tb, unsigned int depth)",
                "",
                "\tif (depth >= MAX_POLICY_RECURSION_DEPTH) {",
                "\t\tNL_SET_ERR_MSG(extack,",
                "\t\t\t       \"allowed policy recursion depth exceeded\");",
                "\t\treturn -EINVAL;",
                "\t}",
                "\t\t\t\t\t       validate, extack, depth);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-36691",
        "func_name": "torvalds/linux/__nla_validate",
        "description": "An issue was discovered in the Linux kernel before 5.8. lib/nlattr.c allows attackers to cause a denial of service (unbounded recursion) via a nested Netlink policy with a back reference.",
        "git_url": "https://github.com/torvalds/linux/commit/7690aa1cdf7c4565ad6b013b324c28b685505e24",
        "commit_title": "netlink: limit recursion depth in policy validation",
        "commit_text": " Now that we have nested policies, we can theoretically recurse forever parsing attributes if a (sub-)policy refers back to a higher level one. This is a situation that has happened in nl80211, and we've avoided it there by not linking it.  Add some code to netlink parsing to limit recursion depth. ",
        "func_before": "int __nla_validate(const struct nlattr *head, int len, int maxtype,\n\t\t   const struct nla_policy *policy, unsigned int validate,\n\t\t   struct netlink_ext_ack *extack)\n{\n\treturn __nla_validate_parse(head, len, maxtype, policy, validate,\n\t\t\t\t    extack, NULL);\n}",
        "func": "int __nla_validate(const struct nlattr *head, int len, int maxtype,\n\t\t   const struct nla_policy *policy, unsigned int validate,\n\t\t   struct netlink_ext_ack *extack)\n{\n\treturn __nla_validate_parse(head, len, maxtype, policy, validate,\n\t\t\t\t    extack, NULL, 0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,5 @@\n \t\t   struct netlink_ext_ack *extack)\n {\n \treturn __nla_validate_parse(head, len, maxtype, policy, validate,\n-\t\t\t\t    extack, NULL);\n+\t\t\t\t    extack, NULL, 0);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t    extack, NULL);"
            ],
            "added_lines": [
                "\t\t\t\t    extack, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-18853",
        "func_name": "ImageMagick/ReadSVGImage",
        "description": "ImageMagick before 7.0.9-0 allows remote attackers to cause a denial of service because XML_PARSE_HUGE is not properly restricted in coders/svg.c, related to SVG and libxml2.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/ec9c8944af2bfc65c697ca44f93a727a99b405f1",
        "commit_title": "[FG-VD-19-136] ImageMagick Convert SVG MacOS Denial Of Service",
        "commit_text": "",
        "func_before": "static Image *ReadSVGImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    filename[MagickPathExtent];\n\n  FILE\n    *file;\n\n  Image\n    *image,\n    *next;\n\n  int\n    status,\n    unique_file;\n\n  ssize_t\n    n;\n\n  SVGInfo\n    *svg_info;\n\n  unsigned char\n    message[MagickPathExtent];\n\n  xmlSAXHandler\n    sax_modules;\n\n  xmlSAXHandlerPtr\n    sax_handler;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if ((fabs(image->resolution.x) < MagickEpsilon) ||\n      (fabs(image->resolution.y) < MagickEpsilon))\n    {\n      GeometryInfo\n        geometry_info;\n\n      int\n        flags;\n\n      flags=ParseGeometry(SVGDensityGeometry,&geometry_info);\n      image->resolution.x=geometry_info.rho;\n      image->resolution.y=geometry_info.sigma;\n      if ((flags & SigmaValue) == 0)\n        image->resolution.y=image->resolution.x;\n    }\n  if (LocaleCompare(image_info->magick,\"MSVG\") != 0)\n    {\n      Image\n        *svg_image;\n\n      svg_image=RenderSVGImage(image_info,image,exception);\n      if (svg_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          return(svg_image);\n        }\n      {\n#if defined(MAGICKCORE_RSVG_DELEGATE)\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n        cairo_surface_t\n          *cairo_surface;\n\n        cairo_t\n          *cairo_image;\n\n        MagickBooleanType\n          apply_density;\n\n        MemoryInfo\n          *pixel_info;\n\n        register unsigned char\n          *p;\n\n        RsvgDimensionData\n          dimension_info;\n\n        unsigned char\n          *pixels;\n\n#else\n        GdkPixbuf\n          *pixel_buffer;\n\n        register const guchar\n          *p;\n#endif\n\n        GError\n          *error;\n\n        PixelInfo\n          fill_color;\n\n        register ssize_t\n          x;\n\n        register Quantum\n          *q;\n\n        RsvgHandle\n          *svg_handle;\n\n        ssize_t\n          y;\n\n        svg_handle=rsvg_handle_new();\n        if (svg_handle == (RsvgHandle *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        rsvg_handle_set_base_uri(svg_handle,image_info->filename);\n        if ((fabs(image->resolution.x) > MagickEpsilon) &&\n            (fabs(image->resolution.y) > MagickEpsilon))\n          rsvg_handle_set_dpi_x_y(svg_handle,image->resolution.x,\n            image->resolution.y);\n        while ((n=ReadBlob(image,MagickPathExtent-1,message)) != 0)\n        {\n          message[n]='\\0';\n          error=(GError *) NULL;\n          (void) rsvg_handle_write(svg_handle,message,n,&error);\n          if (error != (GError *) NULL)\n            g_error_free(error);\n        }\n        error=(GError *) NULL;\n        rsvg_handle_close(svg_handle,&error);\n        if (error != (GError *) NULL)\n          g_error_free(error);\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n        apply_density=MagickTrue;\n        rsvg_handle_get_dimensions(svg_handle,&dimension_info);\n        if ((image->resolution.x > 0.0) && (image->resolution.y > 0.0))\n          {\n            RsvgDimensionData\n              dpi_dimension_info;\n\n            /*\n              We should not apply the density when the internal 'factor' is 'i'.\n              This can be checked by using the trick below.\n            */\n            rsvg_handle_set_dpi_x_y(svg_handle,image->resolution.x*256,\n              image->resolution.y*256);\n            rsvg_handle_get_dimensions(svg_handle,&dpi_dimension_info);\n            if ((dpi_dimension_info.width != dimension_info.width) ||\n                (dpi_dimension_info.height != dimension_info.height))\n              apply_density=MagickFalse;\n            rsvg_handle_set_dpi_x_y(svg_handle,image->resolution.x,\n              image->resolution.y);\n          }\n        if (image_info->size != (char *) NULL)\n          {\n            (void) GetGeometry(image_info->size,(ssize_t *) NULL,\n              (ssize_t *) NULL,&image->columns,&image->rows);\n            if ((image->columns != 0) || (image->rows != 0))\n              {\n                image->resolution.x=DefaultSVGDensity*image->columns/\n                  dimension_info.width;\n                image->resolution.y=DefaultSVGDensity*image->rows/\n                  dimension_info.height;\n                if (fabs(image->resolution.x) < MagickEpsilon)\n                  image->resolution.x=image->resolution.y;\n                else\n                  if (fabs(image->resolution.y) < MagickEpsilon)\n                    image->resolution.y=image->resolution.x;\n                  else\n                    image->resolution.x=image->resolution.y=MagickMin(\n                      image->resolution.x,image->resolution.y);\n                apply_density=MagickTrue;\n              }\n          }\n        if (apply_density != MagickFalse)\n          {\n            image->columns=image->resolution.x*dimension_info.width/\n              DefaultSVGDensity;\n            image->rows=image->resolution.y*dimension_info.height/\n              DefaultSVGDensity;\n          }\n        else\n          {\n            image->columns=dimension_info.width;\n            image->rows=dimension_info.height;\n          }\n        pixel_info=(MemoryInfo *) NULL;\n#else\n        pixel_buffer=rsvg_handle_get_pixbuf(svg_handle);\n        rsvg_handle_free(svg_handle);\n        image->columns=gdk_pixbuf_get_width(pixel_buffer);\n        image->rows=gdk_pixbuf_get_height(pixel_buffer);\n#endif\n        image->alpha_trait=BlendPixelTrait;\n        if (image_info->ping == MagickFalse)\n          {\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n            size_t\n              stride;\n#endif\n\n            status=SetImageExtent(image,image->columns,image->rows,exception);\n            if (status == MagickFalse)\n              {\n#if !defined(MAGICKCORE_CAIRO_DELEGATE)\n                g_object_unref(G_OBJECT(pixel_buffer));\n#endif\n                g_object_unref(svg_handle);\n                ThrowReaderException(MissingDelegateError,\n                  \"NoDecodeDelegateForThisImageFormat\");\n              }\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n            stride=4*image->columns;\n#if defined(MAGICKCORE_PANGOCAIRO_DELEGATE)\n            stride=(size_t) cairo_format_stride_for_width(CAIRO_FORMAT_ARGB32,\n              (int) image->columns);\n#endif\n            pixel_info=AcquireVirtualMemory(stride,image->rows*sizeof(*pixels));\n            if (pixel_info == (MemoryInfo *) NULL)\n              {\n                g_object_unref(svg_handle);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n            pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n#endif\n            (void) SetImageBackgroundColor(image,exception);\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n            cairo_surface=cairo_image_surface_create_for_data(pixels,\n              CAIRO_FORMAT_ARGB32,(int) image->columns,(int) image->rows,(int)\n              stride);\n            if ((cairo_surface == (cairo_surface_t *) NULL) ||\n                (cairo_surface_status(cairo_surface) != CAIRO_STATUS_SUCCESS))\n              {\n                if (cairo_surface != (cairo_surface_t *) NULL)\n                  cairo_surface_destroy(cairo_surface);\n                pixel_info=RelinquishVirtualMemory(pixel_info);\n                g_object_unref(svg_handle);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n            cairo_image=cairo_create(cairo_surface);\n            cairo_set_operator(cairo_image,CAIRO_OPERATOR_CLEAR);\n            cairo_paint(cairo_image);\n            cairo_set_operator(cairo_image,CAIRO_OPERATOR_OVER);\n            if (apply_density != MagickFalse)\n              cairo_scale(cairo_image,image->resolution.x/DefaultSVGDensity,\n                image->resolution.y/DefaultSVGDensity);\n            rsvg_handle_render_cairo(svg_handle,cairo_image);\n            cairo_destroy(cairo_image);\n            cairo_surface_destroy(cairo_surface);\n            g_object_unref(svg_handle);\n            p=pixels;\n#else\n            p=gdk_pixbuf_get_pixels(pixel_buffer);\n#endif\n            GetPixelInfo(image,&fill_color);\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n                fill_color.blue=ScaleCharToQuantum(*p++);\n                fill_color.green=ScaleCharToQuantum(*p++);\n                fill_color.red=ScaleCharToQuantum(*p++);\n#else\n                fill_color.red=ScaleCharToQuantum(*p++);\n                fill_color.green=ScaleCharToQuantum(*p++);\n                fill_color.blue=ScaleCharToQuantum(*p++);\n#endif\n                fill_color.alpha=ScaleCharToQuantum(*p++);\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n                {\n                  double\n                    gamma;\n\n                  gamma=QuantumScale*fill_color.alpha;\n                  gamma=PerceptibleReciprocal(gamma);\n                  fill_color.blue*=gamma;\n                  fill_color.green*=gamma;\n                  fill_color.red*=gamma;\n                }\n#endif\n                CompositePixelOver(image,&fill_color,fill_color.alpha,q,(double)\n                  GetPixelAlpha(image,q),q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n          }\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n        if (pixel_info != (MemoryInfo *) NULL)\n          pixel_info=RelinquishVirtualMemory(pixel_info);\n#else\n        g_object_unref(G_OBJECT(pixel_buffer));\n#endif\n        (void) CloseBlob(image);\n        for (next=GetFirstImageInList(image); next != (Image *) NULL; )\n        {\n          (void) CopyMagickString(next->filename,image->filename,MaxTextExtent);\n          (void) CopyMagickString(next->magick,image->magick,MaxTextExtent);\n          next=GetNextImageInList(next);\n        }\n        return(GetFirstImageInList(image));\n#endif\n      }\n    }\n  /*\n    Open draw file.\n  */\n  file=(FILE *) NULL;\n  unique_file=AcquireUniqueFileResource(filename);\n  if (unique_file != -1)\n    file=fdopen(unique_file,\"w\");\n  if ((unique_file == -1) || (file == (FILE *) NULL))\n    {\n      (void) CopyMagickString(image->filename,filename,MagickPathExtent);\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Parse SVG file.\n  */\n  svg_info=AcquireSVGInfo();\n  if (svg_info == (SVGInfo *) NULL)\n    {\n      (void) fclose(file);\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  svg_info->file=file;\n  svg_info->exception=exception;\n  svg_info->image=image;\n  svg_info->image_info=image_info;\n  svg_info->bounds.width=image->columns;\n  svg_info->bounds.height=image->rows;\n  svg_info->svgDepth=0;\n  if (image_info->size != (char *) NULL)\n    (void) CloneString(&svg_info->size,image_info->size);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"begin SAX\");\n  xmlInitParser();\n  (void) xmlSubstituteEntitiesDefault(1);\n  (void) memset(&sax_modules,0,sizeof(sax_modules));\n  sax_modules.internalSubset=SVGInternalSubset;\n  sax_modules.isStandalone=SVGIsStandalone;\n  sax_modules.hasInternalSubset=SVGHasInternalSubset;\n  sax_modules.hasExternalSubset=SVGHasExternalSubset;\n  sax_modules.resolveEntity=SVGResolveEntity;\n  sax_modules.getEntity=SVGGetEntity;\n  sax_modules.entityDecl=SVGEntityDeclaration;\n  sax_modules.notationDecl=SVGNotationDeclaration;\n  sax_modules.attributeDecl=SVGAttributeDeclaration;\n  sax_modules.elementDecl=SVGElementDeclaration;\n  sax_modules.unparsedEntityDecl=SVGUnparsedEntityDeclaration;\n  sax_modules.setDocumentLocator=SVGSetDocumentLocator;\n  sax_modules.startDocument=SVGStartDocument;\n  sax_modules.endDocument=SVGEndDocument;\n  sax_modules.startElement=SVGStartElement;\n  sax_modules.endElement=SVGEndElement;\n  sax_modules.reference=SVGReference;\n  sax_modules.characters=SVGCharacters;\n  sax_modules.ignorableWhitespace=SVGIgnorableWhitespace;\n  sax_modules.processingInstruction=SVGProcessingInstructions;\n  sax_modules.comment=SVGComment;\n  sax_modules.warning=SVGWarning;\n  sax_modules.error=SVGError;\n  sax_modules.fatalError=SVGError;\n  sax_modules.getParameterEntity=SVGGetParameterEntity;\n  sax_modules.cdataBlock=SVGCDataBlock;\n  sax_modules.externalSubset=SVGExternalSubset;\n  sax_handler=(&sax_modules);\n  n=ReadBlob(image,MagickPathExtent-1,message);\n  message[n]='\\0';\n  if (n > 0)\n    {\n      svg_info->parser=xmlCreatePushParserCtxt(sax_handler,svg_info,(char *)\n        message,n,image->filename);\n      (void) xmlCtxtUseOptions(svg_info->parser,XML_PARSE_HUGE);\n      while ((n=ReadBlob(image,MagickPathExtent-1,message)) != 0)\n      {\n        message[n]='\\0';\n        status=xmlParseChunk(svg_info->parser,(char *) message,(int) n,0);\n        if (status != 0)\n          break;\n      }\n    }\n  (void) xmlParseChunk(svg_info->parser,(char *) message,0,1);\n  SVGEndDocument(svg_info);\n  xmlFreeParserCtxt(svg_info->parser);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"end SAX\");\n  (void) fclose(file);\n  (void) CloseBlob(image);\n  image->columns=svg_info->width;\n  image->rows=svg_info->height;\n  if (exception->severity >= ErrorException)\n    {\n      svg_info=DestroySVGInfo(svg_info);\n      (void) RelinquishUniqueFileResource(filename);\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if (image_info->ping == MagickFalse)\n    {\n      ImageInfo\n        *read_info;\n\n      /*\n        Draw image.\n      */\n      image=DestroyImage(image);\n      image=(Image *) NULL;\n      read_info=CloneImageInfo(image_info);\n      SetImageInfoBlob(read_info,(void *) NULL,0);\n      (void) FormatLocaleString(read_info->filename,MagickPathExtent,\"mvg:%s\",\n        filename);\n      image=ReadImage(read_info,exception);\n      read_info=DestroyImageInfo(read_info);\n      if (image != (Image *) NULL)\n        (void) CopyMagickString(image->filename,image_info->filename,\n          MagickPathExtent);\n    }\n  /*\n    Relinquish resources.\n  */\n  if (image != (Image *) NULL)\n    {\n      if (svg_info->title != (char *) NULL)\n        (void) SetImageProperty(image,\"svg:title\",svg_info->title,exception);\n      if (svg_info->comment != (char *) NULL)\n        (void) SetImageProperty(image,\"svg:comment\",svg_info->comment,\n          exception);\n    }\n  for (next=GetFirstImageInList(image); next != (Image *) NULL; )\n  {\n    (void) CopyMagickString(next->filename,image->filename,MaxTextExtent);\n    (void) CopyMagickString(next->magick,image->magick,MaxTextExtent);\n    next=GetNextImageInList(next);\n  }\n  svg_info=DestroySVGInfo(svg_info);\n  (void) RelinquishUniqueFileResource(filename);\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadSVGImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  char\n    filename[MagickPathExtent];\n\n  FILE\n    *file;\n\n  Image\n    *image,\n    *next;\n\n  int\n    status,\n    unique_file;\n\n  ssize_t\n    n;\n\n  SVGInfo\n    *svg_info;\n\n  unsigned char\n    message[MagickPathExtent];\n\n  xmlSAXHandler\n    sax_modules;\n\n  xmlSAXHandlerPtr\n    sax_handler;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if ((fabs(image->resolution.x) < MagickEpsilon) ||\n      (fabs(image->resolution.y) < MagickEpsilon))\n    {\n      GeometryInfo\n        geometry_info;\n\n      int\n        flags;\n\n      flags=ParseGeometry(SVGDensityGeometry,&geometry_info);\n      image->resolution.x=geometry_info.rho;\n      image->resolution.y=geometry_info.sigma;\n      if ((flags & SigmaValue) == 0)\n        image->resolution.y=image->resolution.x;\n    }\n  if (LocaleCompare(image_info->magick,\"MSVG\") != 0)\n    {\n      Image\n        *svg_image;\n\n      svg_image=RenderSVGImage(image_info,image,exception);\n      if (svg_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          return(svg_image);\n        }\n      {\n#if defined(MAGICKCORE_RSVG_DELEGATE)\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n        cairo_surface_t\n          *cairo_surface;\n\n        cairo_t\n          *cairo_image;\n\n        MagickBooleanType\n          apply_density;\n\n        MemoryInfo\n          *pixel_info;\n\n        register unsigned char\n          *p;\n\n        RsvgDimensionData\n          dimension_info;\n\n        unsigned char\n          *pixels;\n\n#else\n        GdkPixbuf\n          *pixel_buffer;\n\n        register const guchar\n          *p;\n#endif\n\n        GError\n          *error;\n\n        PixelInfo\n          fill_color;\n\n        register ssize_t\n          x;\n\n        register Quantum\n          *q;\n\n        RsvgHandle\n          *svg_handle;\n\n        ssize_t\n          y;\n\n        svg_handle=rsvg_handle_new();\n        if (svg_handle == (RsvgHandle *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        rsvg_handle_set_base_uri(svg_handle,image_info->filename);\n        if ((fabs(image->resolution.x) > MagickEpsilon) &&\n            (fabs(image->resolution.y) > MagickEpsilon))\n          rsvg_handle_set_dpi_x_y(svg_handle,image->resolution.x,\n            image->resolution.y);\n        while ((n=ReadBlob(image,MagickPathExtent-1,message)) != 0)\n        {\n          message[n]='\\0';\n          error=(GError *) NULL;\n          (void) rsvg_handle_write(svg_handle,message,n,&error);\n          if (error != (GError *) NULL)\n            g_error_free(error);\n        }\n        error=(GError *) NULL;\n        rsvg_handle_close(svg_handle,&error);\n        if (error != (GError *) NULL)\n          g_error_free(error);\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n        apply_density=MagickTrue;\n        rsvg_handle_get_dimensions(svg_handle,&dimension_info);\n        if ((image->resolution.x > 0.0) && (image->resolution.y > 0.0))\n          {\n            RsvgDimensionData\n              dpi_dimension_info;\n\n            /*\n              We should not apply the density when the internal 'factor' is 'i'.\n              This can be checked by using the trick below.\n            */\n            rsvg_handle_set_dpi_x_y(svg_handle,image->resolution.x*256,\n              image->resolution.y*256);\n            rsvg_handle_get_dimensions(svg_handle,&dpi_dimension_info);\n            if ((dpi_dimension_info.width != dimension_info.width) ||\n                (dpi_dimension_info.height != dimension_info.height))\n              apply_density=MagickFalse;\n            rsvg_handle_set_dpi_x_y(svg_handle,image->resolution.x,\n              image->resolution.y);\n          }\n        if (image_info->size != (char *) NULL)\n          {\n            (void) GetGeometry(image_info->size,(ssize_t *) NULL,\n              (ssize_t *) NULL,&image->columns,&image->rows);\n            if ((image->columns != 0) || (image->rows != 0))\n              {\n                image->resolution.x=DefaultSVGDensity*image->columns/\n                  dimension_info.width;\n                image->resolution.y=DefaultSVGDensity*image->rows/\n                  dimension_info.height;\n                if (fabs(image->resolution.x) < MagickEpsilon)\n                  image->resolution.x=image->resolution.y;\n                else\n                  if (fabs(image->resolution.y) < MagickEpsilon)\n                    image->resolution.y=image->resolution.x;\n                  else\n                    image->resolution.x=image->resolution.y=MagickMin(\n                      image->resolution.x,image->resolution.y);\n                apply_density=MagickTrue;\n              }\n          }\n        if (apply_density != MagickFalse)\n          {\n            image->columns=image->resolution.x*dimension_info.width/\n              DefaultSVGDensity;\n            image->rows=image->resolution.y*dimension_info.height/\n              DefaultSVGDensity;\n          }\n        else\n          {\n            image->columns=dimension_info.width;\n            image->rows=dimension_info.height;\n          }\n        pixel_info=(MemoryInfo *) NULL;\n#else\n        pixel_buffer=rsvg_handle_get_pixbuf(svg_handle);\n        rsvg_handle_free(svg_handle);\n        image->columns=gdk_pixbuf_get_width(pixel_buffer);\n        image->rows=gdk_pixbuf_get_height(pixel_buffer);\n#endif\n        image->alpha_trait=BlendPixelTrait;\n        if (image_info->ping == MagickFalse)\n          {\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n            size_t\n              stride;\n#endif\n\n            status=SetImageExtent(image,image->columns,image->rows,exception);\n            if (status == MagickFalse)\n              {\n#if !defined(MAGICKCORE_CAIRO_DELEGATE)\n                g_object_unref(G_OBJECT(pixel_buffer));\n#endif\n                g_object_unref(svg_handle);\n                ThrowReaderException(MissingDelegateError,\n                  \"NoDecodeDelegateForThisImageFormat\");\n              }\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n            stride=4*image->columns;\n#if defined(MAGICKCORE_PANGOCAIRO_DELEGATE)\n            stride=(size_t) cairo_format_stride_for_width(CAIRO_FORMAT_ARGB32,\n              (int) image->columns);\n#endif\n            pixel_info=AcquireVirtualMemory(stride,image->rows*sizeof(*pixels));\n            if (pixel_info == (MemoryInfo *) NULL)\n              {\n                g_object_unref(svg_handle);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n            pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n#endif\n            (void) SetImageBackgroundColor(image,exception);\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n            cairo_surface=cairo_image_surface_create_for_data(pixels,\n              CAIRO_FORMAT_ARGB32,(int) image->columns,(int) image->rows,(int)\n              stride);\n            if ((cairo_surface == (cairo_surface_t *) NULL) ||\n                (cairo_surface_status(cairo_surface) != CAIRO_STATUS_SUCCESS))\n              {\n                if (cairo_surface != (cairo_surface_t *) NULL)\n                  cairo_surface_destroy(cairo_surface);\n                pixel_info=RelinquishVirtualMemory(pixel_info);\n                g_object_unref(svg_handle);\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              }\n            cairo_image=cairo_create(cairo_surface);\n            cairo_set_operator(cairo_image,CAIRO_OPERATOR_CLEAR);\n            cairo_paint(cairo_image);\n            cairo_set_operator(cairo_image,CAIRO_OPERATOR_OVER);\n            if (apply_density != MagickFalse)\n              cairo_scale(cairo_image,image->resolution.x/DefaultSVGDensity,\n                image->resolution.y/DefaultSVGDensity);\n            rsvg_handle_render_cairo(svg_handle,cairo_image);\n            cairo_destroy(cairo_image);\n            cairo_surface_destroy(cairo_surface);\n            g_object_unref(svg_handle);\n            p=pixels;\n#else\n            p=gdk_pixbuf_get_pixels(pixel_buffer);\n#endif\n            GetPixelInfo(image,&fill_color);\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=GetAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n                fill_color.blue=ScaleCharToQuantum(*p++);\n                fill_color.green=ScaleCharToQuantum(*p++);\n                fill_color.red=ScaleCharToQuantum(*p++);\n#else\n                fill_color.red=ScaleCharToQuantum(*p++);\n                fill_color.green=ScaleCharToQuantum(*p++);\n                fill_color.blue=ScaleCharToQuantum(*p++);\n#endif\n                fill_color.alpha=ScaleCharToQuantum(*p++);\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n                {\n                  double\n                    gamma;\n\n                  gamma=QuantumScale*fill_color.alpha;\n                  gamma=PerceptibleReciprocal(gamma);\n                  fill_color.blue*=gamma;\n                  fill_color.green*=gamma;\n                  fill_color.red*=gamma;\n                }\n#endif\n                CompositePixelOver(image,&fill_color,fill_color.alpha,q,(double)\n                  GetPixelAlpha(image,q),q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n          }\n#if defined(MAGICKCORE_CAIRO_DELEGATE)\n        if (pixel_info != (MemoryInfo *) NULL)\n          pixel_info=RelinquishVirtualMemory(pixel_info);\n#else\n        g_object_unref(G_OBJECT(pixel_buffer));\n#endif\n        (void) CloseBlob(image);\n        for (next=GetFirstImageInList(image); next != (Image *) NULL; )\n        {\n          (void) CopyMagickString(next->filename,image->filename,MaxTextExtent);\n          (void) CopyMagickString(next->magick,image->magick,MaxTextExtent);\n          next=GetNextImageInList(next);\n        }\n        return(GetFirstImageInList(image));\n#endif\n      }\n    }\n  /*\n    Open draw file.\n  */\n  file=(FILE *) NULL;\n  unique_file=AcquireUniqueFileResource(filename);\n  if (unique_file != -1)\n    file=fdopen(unique_file,\"w\");\n  if ((unique_file == -1) || (file == (FILE *) NULL))\n    {\n      (void) CopyMagickString(image->filename,filename,MagickPathExtent);\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Parse SVG file.\n  */\n  svg_info=AcquireSVGInfo();\n  if (svg_info == (SVGInfo *) NULL)\n    {\n      (void) fclose(file);\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  svg_info->file=file;\n  svg_info->exception=exception;\n  svg_info->image=image;\n  svg_info->image_info=image_info;\n  svg_info->bounds.width=image->columns;\n  svg_info->bounds.height=image->rows;\n  svg_info->svgDepth=0;\n  if (image_info->size != (char *) NULL)\n    (void) CloneString(&svg_info->size,image_info->size);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"begin SAX\");\n  xmlInitParser();\n  (void) xmlSubstituteEntitiesDefault(1);\n  (void) memset(&sax_modules,0,sizeof(sax_modules));\n  sax_modules.internalSubset=SVGInternalSubset;\n  sax_modules.isStandalone=SVGIsStandalone;\n  sax_modules.hasInternalSubset=SVGHasInternalSubset;\n  sax_modules.hasExternalSubset=SVGHasExternalSubset;\n  sax_modules.resolveEntity=SVGResolveEntity;\n  sax_modules.getEntity=SVGGetEntity;\n  sax_modules.entityDecl=SVGEntityDeclaration;\n  sax_modules.notationDecl=SVGNotationDeclaration;\n  sax_modules.attributeDecl=SVGAttributeDeclaration;\n  sax_modules.elementDecl=SVGElementDeclaration;\n  sax_modules.unparsedEntityDecl=SVGUnparsedEntityDeclaration;\n  sax_modules.setDocumentLocator=SVGSetDocumentLocator;\n  sax_modules.startDocument=SVGStartDocument;\n  sax_modules.endDocument=SVGEndDocument;\n  sax_modules.startElement=SVGStartElement;\n  sax_modules.endElement=SVGEndElement;\n  sax_modules.reference=SVGReference;\n  sax_modules.characters=SVGCharacters;\n  sax_modules.ignorableWhitespace=SVGIgnorableWhitespace;\n  sax_modules.processingInstruction=SVGProcessingInstructions;\n  sax_modules.comment=SVGComment;\n  sax_modules.warning=SVGWarning;\n  sax_modules.error=SVGError;\n  sax_modules.fatalError=SVGError;\n  sax_modules.getParameterEntity=SVGGetParameterEntity;\n  sax_modules.cdataBlock=SVGCDataBlock;\n  sax_modules.externalSubset=SVGExternalSubset;\n  sax_handler=(&sax_modules);\n  n=ReadBlob(image,MagickPathExtent-1,message);\n  message[n]='\\0';\n  if (n > 0)\n    {\n      const char\n        *value;\n\n      svg_info->parser=xmlCreatePushParserCtxt(sax_handler,svg_info,(char *)\n        message,n,image->filename);\n      value=GetImageOption(image_info,\"svg:xml-parse-huge\");\n      if ((value != (char *) NULL) && (IsStringTrue(value) != MagickFalse))\n        (void) xmlCtxtUseOptions(svg_info->parser,XML_PARSE_HUGE);\n      while ((n=ReadBlob(image,MagickPathExtent-1,message)) != 0)\n      {\n        message[n]='\\0';\n        status=xmlParseChunk(svg_info->parser,(char *) message,(int) n,0);\n        if (status != 0)\n          break;\n      }\n    }\n  (void) xmlParseChunk(svg_info->parser,(char *) message,0,1);\n  SVGEndDocument(svg_info);\n  xmlFreeParserCtxt(svg_info->parser);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"end SAX\");\n  (void) fclose(file);\n  (void) CloseBlob(image);\n  image->columns=svg_info->width;\n  image->rows=svg_info->height;\n  if (exception->severity >= ErrorException)\n    {\n      svg_info=DestroySVGInfo(svg_info);\n      (void) RelinquishUniqueFileResource(filename);\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if (image_info->ping == MagickFalse)\n    {\n      ImageInfo\n        *read_info;\n\n      /*\n        Draw image.\n      */\n      image=DestroyImage(image);\n      image=(Image *) NULL;\n      read_info=CloneImageInfo(image_info);\n      SetImageInfoBlob(read_info,(void *) NULL,0);\n      (void) FormatLocaleString(read_info->filename,MagickPathExtent,\"mvg:%s\",\n        filename);\n      image=ReadImage(read_info,exception);\n      read_info=DestroyImageInfo(read_info);\n      if (image != (Image *) NULL)\n        (void) CopyMagickString(image->filename,image_info->filename,\n          MagickPathExtent);\n    }\n  /*\n    Relinquish resources.\n  */\n  if (image != (Image *) NULL)\n    {\n      if (svg_info->title != (char *) NULL)\n        (void) SetImageProperty(image,\"svg:title\",svg_info->title,exception);\n      if (svg_info->comment != (char *) NULL)\n        (void) SetImageProperty(image,\"svg:comment\",svg_info->comment,\n          exception);\n    }\n  for (next=GetFirstImageInList(image); next != (Image *) NULL; )\n  {\n    (void) CopyMagickString(next->filename,image->filename,MaxTextExtent);\n    (void) CopyMagickString(next->magick,image->magick,MaxTextExtent);\n    next=GetNextImageInList(next);\n  }\n  svg_info=DestroySVGInfo(svg_info);\n  (void) RelinquishUniqueFileResource(filename);\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -398,9 +398,14 @@\n   message[n]='\\0';\n   if (n > 0)\n     {\n+      const char\n+        *value;\n+\n       svg_info->parser=xmlCreatePushParserCtxt(sax_handler,svg_info,(char *)\n         message,n,image->filename);\n-      (void) xmlCtxtUseOptions(svg_info->parser,XML_PARSE_HUGE);\n+      value=GetImageOption(image_info,\"svg:xml-parse-huge\");\n+      if ((value != (char *) NULL) && (IsStringTrue(value) != MagickFalse))\n+        (void) xmlCtxtUseOptions(svg_info->parser,XML_PARSE_HUGE);\n       while ((n=ReadBlob(image,MagickPathExtent-1,message)) != 0)\n       {\n         message[n]='\\0';",
        "diff_line_info": {
            "deleted_lines": [
                "      (void) xmlCtxtUseOptions(svg_info->parser,XML_PARSE_HUGE);"
            ],
            "added_lines": [
                "      const char",
                "        *value;",
                "",
                "      value=GetImageOption(image_info,\"svg:xml-parse-huge\");",
                "      if ((value != (char *) NULL) && (IsStringTrue(value) != MagickFalse))",
                "        (void) xmlCtxtUseOptions(svg_info->parser,XML_PARSE_HUGE);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11937",
        "func_name": "facebook/mcrouter/readStructEnd",
        "description": "In Mcrouter prior to v0.41.0, a large struct input provided to the Carbon protocol reader could result in stack exhaustion and denial of service.",
        "git_url": "https://github.com/facebook/mcrouter/commit/97e033b3bb0cb16b61bf49f0dc7f311a3e0edd1b",
        "commit_title": "Attempt to make CarbonProtocolReader::skip tail recursive",
        "commit_text": " Reviewed By: edenzik  Differential Revision: D17967570  fbshipit-source-id: fdc32e190a521349c7c8f4d6081902fa18eb0284",
        "func_before": "void readStructEnd() {\n    lastFieldId_ = nestedStructFieldIds_.back();\n    nestedStructFieldIds_.pop_back();\n  }",
        "func": "void readStructEnd() {\n    if (!nestedStructFieldIds_.empty()) {\n      lastFieldId_ = nestedStructFieldIds_.back();\n      nestedStructFieldIds_.pop_back();\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,6 @@\n void readStructEnd() {\n-    lastFieldId_ = nestedStructFieldIds_.back();\n-    nestedStructFieldIds_.pop_back();\n+    if (!nestedStructFieldIds_.empty()) {\n+      lastFieldId_ = nestedStructFieldIds_.back();\n+      nestedStructFieldIds_.pop_back();\n+    }\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "    lastFieldId_ = nestedStructFieldIds_.back();",
                "    nestedStructFieldIds_.pop_back();"
            ],
            "added_lines": [
                "    if (!nestedStructFieldIds_.empty()) {",
                "      lastFieldId_ = nestedStructFieldIds_.back();",
                "      nestedStructFieldIds_.pop_back();",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11937",
        "func_name": "facebook/mcrouter/CarbonProtocolReader::skip",
        "description": "In Mcrouter prior to v0.41.0, a large struct input provided to the Carbon protocol reader could result in stack exhaustion and denial of service.",
        "git_url": "https://github.com/facebook/mcrouter/commit/97e033b3bb0cb16b61bf49f0dc7f311a3e0edd1b",
        "commit_title": "Attempt to make CarbonProtocolReader::skip tail recursive",
        "commit_text": " Reviewed By: edenzik  Differential Revision: D17967570  fbshipit-source-id: fdc32e190a521349c7c8f4d6081902fa18eb0284",
        "func_before": "void CarbonProtocolReader::skip(const FieldType ft) {\n  switch (ft) {\n    case FieldType::True:\n    case FieldType::False: {\n      break;\n    }\n    case FieldType::Int8: {\n      readRaw<int8_t>();\n      break;\n    }\n    case FieldType::Int16: {\n      readRaw<int16_t>();\n      break;\n    }\n    case FieldType::Int32: {\n      readRaw<int32_t>();\n      break;\n    }\n    case FieldType::Int64: {\n      readRaw<int64_t>();\n      break;\n    }\n    case FieldType::Double: {\n      readRaw<double>();\n      break;\n    }\n    case FieldType::Float: {\n      readRaw<float>();\n      break;\n    }\n    case FieldType::Binary: {\n      readRaw<std::string>();\n      break;\n    }\n    case FieldType::List: {\n      skipLinearContainer();\n      break;\n    }\n    case FieldType::Struct: {\n      readStructBegin();\n      while (true) {\n        const auto fieldType = readFieldHeader().first;\n        if (fieldType == FieldType::Stop) {\n          break;\n        }\n        skip(fieldType);\n      }\n      readStructEnd();\n      break;\n    }\n    case FieldType::Set: {\n      skipLinearContainer();\n      break;\n    }\n    case FieldType::Map: {\n      skipKVContainer();\n      break;\n    }\n    default: { break; }\n  }\n}",
        "func": "void CarbonProtocolReader::skip(const FieldType ft) {\n  switch (ft) {\n    case FieldType::True:\n    case FieldType::False: {\n      break;\n    }\n    case FieldType::Int8: {\n      readRaw<int8_t>();\n      break;\n    }\n    case FieldType::Int16: {\n      readRaw<int16_t>();\n      break;\n    }\n    case FieldType::Int32: {\n      readRaw<int32_t>();\n      break;\n    }\n    case FieldType::Int64: {\n      readRaw<int64_t>();\n      break;\n    }\n    case FieldType::Double: {\n      readRaw<double>();\n      break;\n    }\n    case FieldType::Float: {\n      readRaw<float>();\n      break;\n    }\n    case FieldType::Binary: {\n      readRaw<std::string>();\n      break;\n    }\n    case FieldType::List: {\n      skipLinearContainer();\n      break;\n    }\n    case FieldType::Struct: {\n      readStructBegin();\n      const auto next = readFieldHeader().first;\n      skip(next);\n      break;\n    }\n    case FieldType::Stop: {\n      readStructEnd();\n      break;\n    }\n    case FieldType::Set: {\n      skipLinearContainer();\n      break;\n    }\n    case FieldType::Map: {\n      skipKVContainer();\n      break;\n    }\n    default: {\n      break;\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,13 +38,11 @@\n     }\n     case FieldType::Struct: {\n       readStructBegin();\n-      while (true) {\n-        const auto fieldType = readFieldHeader().first;\n-        if (fieldType == FieldType::Stop) {\n-          break;\n-        }\n-        skip(fieldType);\n-      }\n+      const auto next = readFieldHeader().first;\n+      skip(next);\n+      break;\n+    }\n+    case FieldType::Stop: {\n       readStructEnd();\n       break;\n     }\n@@ -56,6 +54,8 @@\n       skipKVContainer();\n       break;\n     }\n-    default: { break; }\n+    default: {\n+      break;\n+    }\n   }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      while (true) {",
                "        const auto fieldType = readFieldHeader().first;",
                "        if (fieldType == FieldType::Stop) {",
                "          break;",
                "        }",
                "        skip(fieldType);",
                "      }",
                "    default: { break; }"
            ],
            "added_lines": [
                "      const auto next = readFieldHeader().first;",
                "      skip(next);",
                "      break;",
                "    }",
                "    case FieldType::Stop: {",
                "    default: {",
                "      break;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19645",
        "func_name": "sqlite/renameTableSelectCb",
        "description": "alter.c in SQLite through 3.30.1 allows attackers to trigger infinite recursion via certain types of self-referential views in conjunction with ALTER TABLE statements.",
        "git_url": "https://github.com/sqlite/sqlite/commit/38096961c7cd109110ac21d3ed7dad7e0cb0ae06",
        "commit_title": "Avoid infinite recursion in the ALTER TABLE code when a view contains an unused CTE that references, directly or indirectly, the view itself.",
        "commit_text": " FossilOrigin-Name: 1d2e53a39b87e364685e21de137655b6eee725e4c6d27fc90865072d7c5892b5",
        "func_before": "static int renameTableSelectCb(Walker *pWalker, Select *pSelect){\n  int i;\n  RenameCtx *p = pWalker->u.pRename;\n  SrcList *pSrc = pSelect->pSrc;\n  if( pSrc==0 ){\n    assert( pWalker->pParse->db->mallocFailed );\n    return WRC_Abort;\n  }\n  for(i=0; i<pSrc->nSrc; i++){\n    struct SrcList_item *pItem = &pSrc->a[i];\n    if( pItem->pTab==p->pTab ){\n      renameTokenFind(pWalker->pParse, p, pItem->zName);\n    }\n  }\n  renameWalkWith(pWalker, pSelect);\n\n  return WRC_Continue;\n}",
        "func": "static int renameTableSelectCb(Walker *pWalker, Select *pSelect){\n  int i;\n  RenameCtx *p = pWalker->u.pRename;\n  SrcList *pSrc = pSelect->pSrc;\n  if( pSelect->selFlags & SF_View ) return WRC_Prune;\n  if( pSrc==0 ){\n    assert( pWalker->pParse->db->mallocFailed );\n    return WRC_Abort;\n  }\n  for(i=0; i<pSrc->nSrc; i++){\n    struct SrcList_item *pItem = &pSrc->a[i];\n    if( pItem->pTab==p->pTab ){\n      renameTokenFind(pWalker->pParse, p, pItem->zName);\n    }\n  }\n  renameWalkWith(pWalker, pSelect);\n\n  return WRC_Continue;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n   int i;\n   RenameCtx *p = pWalker->u.pRename;\n   SrcList *pSrc = pSelect->pSrc;\n+  if( pSelect->selFlags & SF_View ) return WRC_Prune;\n   if( pSrc==0 ){\n     assert( pWalker->pParse->db->mallocFailed );\n     return WRC_Abort;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if( pSelect->selFlags & SF_View ) return WRC_Prune;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19645",
        "func_name": "sqlite/renameUnmapSelectCb",
        "description": "alter.c in SQLite through 3.30.1 allows attackers to trigger infinite recursion via certain types of self-referential views in conjunction with ALTER TABLE statements.",
        "git_url": "https://github.com/sqlite/sqlite/commit/38096961c7cd109110ac21d3ed7dad7e0cb0ae06",
        "commit_title": "Avoid infinite recursion in the ALTER TABLE code when a view contains an unused CTE that references, directly or indirectly, the view itself.",
        "commit_text": " FossilOrigin-Name: 1d2e53a39b87e364685e21de137655b6eee725e4c6d27fc90865072d7c5892b5",
        "func_before": "static int renameUnmapSelectCb(Walker *pWalker, Select *p){\n  Parse *pParse = pWalker->pParse;\n  int i;\n  if( pParse->nErr ) return WRC_Abort;\n  if( ALWAYS(p->pEList) ){\n    ExprList *pList = p->pEList;\n    for(i=0; i<pList->nExpr; i++){\n      if( pList->a[i].zName ){\n        sqlite3RenameTokenRemap(pParse, 0, (void*)pList->a[i].zName);\n      }\n    }\n  }\n  if( ALWAYS(p->pSrc) ){  /* Every Select as a SrcList, even if it is empty */\n    SrcList *pSrc = p->pSrc;\n    for(i=0; i<pSrc->nSrc; i++){\n      sqlite3RenameTokenRemap(pParse, 0, (void*)pSrc->a[i].zName);\n    }\n  }\n\n  renameWalkWith(pWalker, p);\n  return WRC_Continue;\n}",
        "func": "static int renameUnmapSelectCb(Walker *pWalker, Select *p){\n  Parse *pParse = pWalker->pParse;\n  int i;\n  if( pParse->nErr ) return WRC_Abort;\n  if( p->selFlags & SF_View ) return WRC_Prune;\n  if( ALWAYS(p->pEList) ){\n    ExprList *pList = p->pEList;\n    for(i=0; i<pList->nExpr; i++){\n      if( pList->a[i].zName ){\n        sqlite3RenameTokenRemap(pParse, 0, (void*)pList->a[i].zName);\n      }\n    }\n  }\n  if( ALWAYS(p->pSrc) ){  /* Every Select as a SrcList, even if it is empty */\n    SrcList *pSrc = p->pSrc;\n    for(i=0; i<pSrc->nSrc; i++){\n      sqlite3RenameTokenRemap(pParse, 0, (void*)pSrc->a[i].zName);\n    }\n  }\n\n  renameWalkWith(pWalker, p);\n  return WRC_Continue;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n   Parse *pParse = pWalker->pParse;\n   int i;\n   if( pParse->nErr ) return WRC_Abort;\n+  if( p->selFlags & SF_View ) return WRC_Prune;\n   if( ALWAYS(p->pEList) ){\n     ExprList *pList = p->pEList;\n     for(i=0; i<pList->nExpr; i++){",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if( p->selFlags & SF_View ) return WRC_Prune;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19645",
        "func_name": "sqlite/renameColumnSelectCb",
        "description": "alter.c in SQLite through 3.30.1 allows attackers to trigger infinite recursion via certain types of self-referential views in conjunction with ALTER TABLE statements.",
        "git_url": "https://github.com/sqlite/sqlite/commit/38096961c7cd109110ac21d3ed7dad7e0cb0ae06",
        "commit_title": "Avoid infinite recursion in the ALTER TABLE code when a view contains an unused CTE that references, directly or indirectly, the view itself.",
        "commit_text": " FossilOrigin-Name: 1d2e53a39b87e364685e21de137655b6eee725e4c6d27fc90865072d7c5892b5",
        "func_before": "static int renameColumnSelectCb(Walker *pWalker, Select *p){\n  renameWalkWith(pWalker, p);\n  return WRC_Continue;\n}",
        "func": "static int renameColumnSelectCb(Walker *pWalker, Select *p){\n  if( p->selFlags & SF_View ) return WRC_Prune;\n  renameWalkWith(pWalker, p);\n  return WRC_Continue;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n static int renameColumnSelectCb(Walker *pWalker, Select *p){\n+  if( p->selFlags & SF_View ) return WRC_Prune;\n   renameWalkWith(pWalker, p);\n   return WRC_Continue;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if( p->selFlags & SF_View ) return WRC_Prune;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19645",
        "func_name": "sqlite/renameColumnFunc",
        "description": "alter.c in SQLite through 3.30.1 allows attackers to trigger infinite recursion via certain types of self-referential views in conjunction with ALTER TABLE statements.",
        "git_url": "https://github.com/sqlite/sqlite/commit/38096961c7cd109110ac21d3ed7dad7e0cb0ae06",
        "commit_title": "Avoid infinite recursion in the ALTER TABLE code when a view contains an unused CTE that references, directly or indirectly, the view itself.",
        "commit_text": " FossilOrigin-Name: 1d2e53a39b87e364685e21de137655b6eee725e4c6d27fc90865072d7c5892b5",
        "func_before": "static void renameColumnFunc(\n  sqlite3_context *context,\n  int NotUsed,\n  sqlite3_value **argv\n){\n  sqlite3 *db = sqlite3_context_db_handle(context);\n  RenameCtx sCtx;\n  const char *zSql = (const char*)sqlite3_value_text(argv[0]);\n  const char *zDb = (const char*)sqlite3_value_text(argv[3]);\n  const char *zTable = (const char*)sqlite3_value_text(argv[4]);\n  int iCol = sqlite3_value_int(argv[5]);\n  const char *zNew = (const char*)sqlite3_value_text(argv[6]);\n  int bQuote = sqlite3_value_int(argv[7]);\n  int bTemp = sqlite3_value_int(argv[8]);\n  const char *zOld;\n  int rc;\n  Parse sParse;\n  Walker sWalker;\n  Index *pIdx;\n  int i;\n  Table *pTab;\n#ifndef SQLITE_OMIT_AUTHORIZATION\n  sqlite3_xauth xAuth = db->xAuth;\n#endif\n\n  UNUSED_PARAMETER(NotUsed);\n  if( zSql==0 ) return;\n  if( zTable==0 ) return;\n  if( zNew==0 ) return;\n  if( iCol<0 ) return;\n  sqlite3BtreeEnterAll(db);\n  pTab = sqlite3FindTable(db, zTable, zDb);\n  if( pTab==0 || iCol>=pTab->nCol ){\n    sqlite3BtreeLeaveAll(db);\n    return;\n  }\n  zOld = pTab->aCol[iCol].zName;\n  memset(&sCtx, 0, sizeof(sCtx));\n  sCtx.iCol = ((iCol==pTab->iPKey) ? -1 : iCol);\n\n#ifndef SQLITE_OMIT_AUTHORIZATION\n  db->xAuth = 0;\n#endif\n  rc = renameParseSql(&sParse, zDb, 0, db, zSql, bTemp);\n\n  /* Find tokens that need to be replaced. */\n  memset(&sWalker, 0, sizeof(Walker));\n  sWalker.pParse = &sParse;\n  sWalker.xExprCallback = renameColumnExprCb;\n  sWalker.xSelectCallback = renameColumnSelectCb;\n  sWalker.u.pRename = &sCtx;\n\n  sCtx.pTab = pTab;\n  if( rc!=SQLITE_OK ) goto renameColumnFunc_done;\n  if( sParse.pNewTable ){\n    Select *pSelect = sParse.pNewTable->pSelect;\n    if( pSelect ){\n      sParse.rc = SQLITE_OK;\n      sqlite3SelectPrep(&sParse, sParse.pNewTable->pSelect, 0);\n      rc = (db->mallocFailed ? SQLITE_NOMEM : sParse.rc);\n      if( rc==SQLITE_OK ){\n        sqlite3WalkSelect(&sWalker, pSelect);\n      }\n      if( rc!=SQLITE_OK ) goto renameColumnFunc_done;\n    }else{\n      /* A regular table */\n      int bFKOnly = sqlite3_stricmp(zTable, sParse.pNewTable->zName);\n      FKey *pFKey;\n      assert( sParse.pNewTable->pSelect==0 );\n      sCtx.pTab = sParse.pNewTable;\n      if( bFKOnly==0 ){\n        renameTokenFind(\n            &sParse, &sCtx, (void*)sParse.pNewTable->aCol[iCol].zName\n        );\n        if( sCtx.iCol<0 ){\n          renameTokenFind(&sParse, &sCtx, (void*)&sParse.pNewTable->iPKey);\n        }\n        sqlite3WalkExprList(&sWalker, sParse.pNewTable->pCheck);\n        for(pIdx=sParse.pNewTable->pIndex; pIdx; pIdx=pIdx->pNext){\n          sqlite3WalkExprList(&sWalker, pIdx->aColExpr);\n        }\n        for(pIdx=sParse.pNewIndex; pIdx; pIdx=pIdx->pNext){\n          sqlite3WalkExprList(&sWalker, pIdx->aColExpr);\n        }\n      }\n#ifndef SQLITE_OMIT_GENERATED_COLUMNS\n      for(i=0; i<sParse.pNewTable->nCol; i++){\n        sqlite3WalkExpr(&sWalker, sParse.pNewTable->aCol[i].pDflt);\n      }\n#endif\n\n      for(pFKey=sParse.pNewTable->pFKey; pFKey; pFKey=pFKey->pNextFrom){\n        for(i=0; i<pFKey->nCol; i++){\n          if( bFKOnly==0 && pFKey->aCol[i].iFrom==iCol ){\n            renameTokenFind(&sParse, &sCtx, (void*)&pFKey->aCol[i]);\n          }\n          if( 0==sqlite3_stricmp(pFKey->zTo, zTable)\n           && 0==sqlite3_stricmp(pFKey->aCol[i].zCol, zOld)\n          ){\n            renameTokenFind(&sParse, &sCtx, (void*)pFKey->aCol[i].zCol);\n          }\n        }\n      }\n    }\n  }else if( sParse.pNewIndex ){\n    sqlite3WalkExprList(&sWalker, sParse.pNewIndex->aColExpr);\n    sqlite3WalkExpr(&sWalker, sParse.pNewIndex->pPartIdxWhere);\n  }else{\n    /* A trigger */\n    TriggerStep *pStep;\n    rc = renameResolveTrigger(&sParse, (bTemp ? 0 : zDb));\n    if( rc!=SQLITE_OK ) goto renameColumnFunc_done;\n\n    for(pStep=sParse.pNewTrigger->step_list; pStep; pStep=pStep->pNext){\n      if( pStep->zTarget ){ \n        Table *pTarget = sqlite3LocateTable(&sParse, 0, pStep->zTarget, zDb);\n        if( pTarget==pTab ){\n          if( pStep->pUpsert ){\n            ExprList *pUpsertSet = pStep->pUpsert->pUpsertSet;\n            renameColumnElistNames(&sParse, &sCtx, pUpsertSet, zOld);\n          }\n          renameColumnIdlistNames(&sParse, &sCtx, pStep->pIdList, zOld);\n          renameColumnElistNames(&sParse, &sCtx, pStep->pExprList, zOld);\n        }\n      }\n    }\n\n\n    /* Find tokens to edit in UPDATE OF clause */\n    if( sParse.pTriggerTab==pTab ){\n      renameColumnIdlistNames(&sParse, &sCtx,sParse.pNewTrigger->pColumns,zOld);\n    }\n\n    /* Find tokens to edit in various expressions and selects */\n    renameWalkTrigger(&sWalker, sParse.pNewTrigger);\n  }\n\n  assert( rc==SQLITE_OK );\n  rc = renameEditSql(context, &sCtx, zSql, zNew, bQuote);\n\nrenameColumnFunc_done:\n  if( rc!=SQLITE_OK ){\n    if( sParse.zErrMsg ){\n      renameColumnParseError(context, 0, argv[1], argv[2], &sParse);\n    }else{\n      sqlite3_result_error_code(context, rc);\n    }\n  }\n\n  renameParseCleanup(&sParse);\n  renameTokenFree(db, sCtx.pList);\n#ifndef SQLITE_OMIT_AUTHORIZATION\n  db->xAuth = xAuth;\n#endif\n  sqlite3BtreeLeaveAll(db);\n}",
        "func": "static void renameColumnFunc(\n  sqlite3_context *context,\n  int NotUsed,\n  sqlite3_value **argv\n){\n  sqlite3 *db = sqlite3_context_db_handle(context);\n  RenameCtx sCtx;\n  const char *zSql = (const char*)sqlite3_value_text(argv[0]);\n  const char *zDb = (const char*)sqlite3_value_text(argv[3]);\n  const char *zTable = (const char*)sqlite3_value_text(argv[4]);\n  int iCol = sqlite3_value_int(argv[5]);\n  const char *zNew = (const char*)sqlite3_value_text(argv[6]);\n  int bQuote = sqlite3_value_int(argv[7]);\n  int bTemp = sqlite3_value_int(argv[8]);\n  const char *zOld;\n  int rc;\n  Parse sParse;\n  Walker sWalker;\n  Index *pIdx;\n  int i;\n  Table *pTab;\n#ifndef SQLITE_OMIT_AUTHORIZATION\n  sqlite3_xauth xAuth = db->xAuth;\n#endif\n\n  UNUSED_PARAMETER(NotUsed);\n  if( zSql==0 ) return;\n  if( zTable==0 ) return;\n  if( zNew==0 ) return;\n  if( iCol<0 ) return;\n  sqlite3BtreeEnterAll(db);\n  pTab = sqlite3FindTable(db, zTable, zDb);\n  if( pTab==0 || iCol>=pTab->nCol ){\n    sqlite3BtreeLeaveAll(db);\n    return;\n  }\n  zOld = pTab->aCol[iCol].zName;\n  memset(&sCtx, 0, sizeof(sCtx));\n  sCtx.iCol = ((iCol==pTab->iPKey) ? -1 : iCol);\n\n#ifndef SQLITE_OMIT_AUTHORIZATION\n  db->xAuth = 0;\n#endif\n  rc = renameParseSql(&sParse, zDb, 0, db, zSql, bTemp);\n\n  /* Find tokens that need to be replaced. */\n  memset(&sWalker, 0, sizeof(Walker));\n  sWalker.pParse = &sParse;\n  sWalker.xExprCallback = renameColumnExprCb;\n  sWalker.xSelectCallback = renameColumnSelectCb;\n  sWalker.u.pRename = &sCtx;\n\n  sCtx.pTab = pTab;\n  if( rc!=SQLITE_OK ) goto renameColumnFunc_done;\n  if( sParse.pNewTable ){\n    Select *pSelect = sParse.pNewTable->pSelect;\n    if( pSelect ){\n      pSelect->selFlags &= ~SF_View;\n      sParse.rc = SQLITE_OK;\n      sqlite3SelectPrep(&sParse, pSelect, 0);\n      rc = (db->mallocFailed ? SQLITE_NOMEM : sParse.rc);\n      if( rc==SQLITE_OK ){\n        sqlite3WalkSelect(&sWalker, pSelect);\n      }\n      if( rc!=SQLITE_OK ) goto renameColumnFunc_done;\n    }else{\n      /* A regular table */\n      int bFKOnly = sqlite3_stricmp(zTable, sParse.pNewTable->zName);\n      FKey *pFKey;\n      assert( sParse.pNewTable->pSelect==0 );\n      sCtx.pTab = sParse.pNewTable;\n      if( bFKOnly==0 ){\n        renameTokenFind(\n            &sParse, &sCtx, (void*)sParse.pNewTable->aCol[iCol].zName\n        );\n        if( sCtx.iCol<0 ){\n          renameTokenFind(&sParse, &sCtx, (void*)&sParse.pNewTable->iPKey);\n        }\n        sqlite3WalkExprList(&sWalker, sParse.pNewTable->pCheck);\n        for(pIdx=sParse.pNewTable->pIndex; pIdx; pIdx=pIdx->pNext){\n          sqlite3WalkExprList(&sWalker, pIdx->aColExpr);\n        }\n        for(pIdx=sParse.pNewIndex; pIdx; pIdx=pIdx->pNext){\n          sqlite3WalkExprList(&sWalker, pIdx->aColExpr);\n        }\n      }\n#ifndef SQLITE_OMIT_GENERATED_COLUMNS\n      for(i=0; i<sParse.pNewTable->nCol; i++){\n        sqlite3WalkExpr(&sWalker, sParse.pNewTable->aCol[i].pDflt);\n      }\n#endif\n\n      for(pFKey=sParse.pNewTable->pFKey; pFKey; pFKey=pFKey->pNextFrom){\n        for(i=0; i<pFKey->nCol; i++){\n          if( bFKOnly==0 && pFKey->aCol[i].iFrom==iCol ){\n            renameTokenFind(&sParse, &sCtx, (void*)&pFKey->aCol[i]);\n          }\n          if( 0==sqlite3_stricmp(pFKey->zTo, zTable)\n           && 0==sqlite3_stricmp(pFKey->aCol[i].zCol, zOld)\n          ){\n            renameTokenFind(&sParse, &sCtx, (void*)pFKey->aCol[i].zCol);\n          }\n        }\n      }\n    }\n  }else if( sParse.pNewIndex ){\n    sqlite3WalkExprList(&sWalker, sParse.pNewIndex->aColExpr);\n    sqlite3WalkExpr(&sWalker, sParse.pNewIndex->pPartIdxWhere);\n  }else{\n    /* A trigger */\n    TriggerStep *pStep;\n    rc = renameResolveTrigger(&sParse, (bTemp ? 0 : zDb));\n    if( rc!=SQLITE_OK ) goto renameColumnFunc_done;\n\n    for(pStep=sParse.pNewTrigger->step_list; pStep; pStep=pStep->pNext){\n      if( pStep->zTarget ){ \n        Table *pTarget = sqlite3LocateTable(&sParse, 0, pStep->zTarget, zDb);\n        if( pTarget==pTab ){\n          if( pStep->pUpsert ){\n            ExprList *pUpsertSet = pStep->pUpsert->pUpsertSet;\n            renameColumnElistNames(&sParse, &sCtx, pUpsertSet, zOld);\n          }\n          renameColumnIdlistNames(&sParse, &sCtx, pStep->pIdList, zOld);\n          renameColumnElistNames(&sParse, &sCtx, pStep->pExprList, zOld);\n        }\n      }\n    }\n\n\n    /* Find tokens to edit in UPDATE OF clause */\n    if( sParse.pTriggerTab==pTab ){\n      renameColumnIdlistNames(&sParse, &sCtx,sParse.pNewTrigger->pColumns,zOld);\n    }\n\n    /* Find tokens to edit in various expressions and selects */\n    renameWalkTrigger(&sWalker, sParse.pNewTrigger);\n  }\n\n  assert( rc==SQLITE_OK );\n  rc = renameEditSql(context, &sCtx, zSql, zNew, bQuote);\n\nrenameColumnFunc_done:\n  if( rc!=SQLITE_OK ){\n    if( sParse.zErrMsg ){\n      renameColumnParseError(context, 0, argv[1], argv[2], &sParse);\n    }else{\n      sqlite3_result_error_code(context, rc);\n    }\n  }\n\n  renameParseCleanup(&sParse);\n  renameTokenFree(db, sCtx.pList);\n#ifndef SQLITE_OMIT_AUTHORIZATION\n  db->xAuth = xAuth;\n#endif\n  sqlite3BtreeLeaveAll(db);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -55,8 +55,9 @@\n   if( sParse.pNewTable ){\n     Select *pSelect = sParse.pNewTable->pSelect;\n     if( pSelect ){\n+      pSelect->selFlags &= ~SF_View;\n       sParse.rc = SQLITE_OK;\n-      sqlite3SelectPrep(&sParse, sParse.pNewTable->pSelect, 0);\n+      sqlite3SelectPrep(&sParse, pSelect, 0);\n       rc = (db->mallocFailed ? SQLITE_NOMEM : sParse.rc);\n       if( rc==SQLITE_OK ){\n         sqlite3WalkSelect(&sWalker, pSelect);",
        "diff_line_info": {
            "deleted_lines": [
                "      sqlite3SelectPrep(&sParse, sParse.pNewTable->pSelect, 0);"
            ],
            "added_lines": [
                "      pSelect->selFlags &= ~SF_View;",
                "      sqlite3SelectPrep(&sParse, pSelect, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19645",
        "func_name": "sqlite/renameTableFunc",
        "description": "alter.c in SQLite through 3.30.1 allows attackers to trigger infinite recursion via certain types of self-referential views in conjunction with ALTER TABLE statements.",
        "git_url": "https://github.com/sqlite/sqlite/commit/38096961c7cd109110ac21d3ed7dad7e0cb0ae06",
        "commit_title": "Avoid infinite recursion in the ALTER TABLE code when a view contains an unused CTE that references, directly or indirectly, the view itself.",
        "commit_text": " FossilOrigin-Name: 1d2e53a39b87e364685e21de137655b6eee725e4c6d27fc90865072d7c5892b5",
        "func_before": "static void renameTableFunc(\n  sqlite3_context *context,\n  int NotUsed,\n  sqlite3_value **argv\n){\n  sqlite3 *db = sqlite3_context_db_handle(context);\n  const char *zDb = (const char*)sqlite3_value_text(argv[0]);\n  const char *zInput = (const char*)sqlite3_value_text(argv[3]);\n  const char *zOld = (const char*)sqlite3_value_text(argv[4]);\n  const char *zNew = (const char*)sqlite3_value_text(argv[5]);\n  int bTemp = sqlite3_value_int(argv[6]);\n  UNUSED_PARAMETER(NotUsed);\n\n  if( zInput && zOld && zNew ){\n    Parse sParse;\n    int rc;\n    int bQuote = 1;\n    RenameCtx sCtx;\n    Walker sWalker;\n\n#ifndef SQLITE_OMIT_AUTHORIZATION\n    sqlite3_xauth xAuth = db->xAuth;\n    db->xAuth = 0;\n#endif\n\n    sqlite3BtreeEnterAll(db);\n\n    memset(&sCtx, 0, sizeof(RenameCtx));\n    sCtx.pTab = sqlite3FindTable(db, zOld, zDb);\n    memset(&sWalker, 0, sizeof(Walker));\n    sWalker.pParse = &sParse;\n    sWalker.xExprCallback = renameTableExprCb;\n    sWalker.xSelectCallback = renameTableSelectCb;\n    sWalker.u.pRename = &sCtx;\n\n    rc = renameParseSql(&sParse, zDb, 1, db, zInput, bTemp);\n\n    if( rc==SQLITE_OK ){\n      int isLegacy = (db->flags & SQLITE_LegacyAlter);\n      if( sParse.pNewTable ){\n        Table *pTab = sParse.pNewTable;\n\n        if( pTab->pSelect ){\n          if( isLegacy==0 ){\n            NameContext sNC;\n            memset(&sNC, 0, sizeof(sNC));\n            sNC.pParse = &sParse;\n\n            sqlite3SelectPrep(&sParse, pTab->pSelect, &sNC);\n            if( sParse.nErr ) rc = sParse.rc;\n            sqlite3WalkSelect(&sWalker, pTab->pSelect);\n          }\n        }else{\n          /* Modify any FK definitions to point to the new table. */\n#ifndef SQLITE_OMIT_FOREIGN_KEY\n          if( isLegacy==0 || (db->flags & SQLITE_ForeignKeys) ){\n            FKey *pFKey;\n            for(pFKey=pTab->pFKey; pFKey; pFKey=pFKey->pNextFrom){\n              if( sqlite3_stricmp(pFKey->zTo, zOld)==0 ){\n                renameTokenFind(&sParse, &sCtx, (void*)pFKey->zTo);\n              }\n            }\n          }\n#endif\n\n          /* If this is the table being altered, fix any table refs in CHECK\n          ** expressions. Also update the name that appears right after the\n          ** \"CREATE [VIRTUAL] TABLE\" bit. */\n          if( sqlite3_stricmp(zOld, pTab->zName)==0 ){\n            sCtx.pTab = pTab;\n            if( isLegacy==0 ){\n              sqlite3WalkExprList(&sWalker, pTab->pCheck);\n            }\n            renameTokenFind(&sParse, &sCtx, pTab->zName);\n          }\n        }\n      }\n\n      else if( sParse.pNewIndex ){\n        renameTokenFind(&sParse, &sCtx, sParse.pNewIndex->zName);\n        if( isLegacy==0 ){\n          sqlite3WalkExpr(&sWalker, sParse.pNewIndex->pPartIdxWhere);\n        }\n      }\n\n#ifndef SQLITE_OMIT_TRIGGER\n      else{\n        Trigger *pTrigger = sParse.pNewTrigger;\n        TriggerStep *pStep;\n        if( 0==sqlite3_stricmp(sParse.pNewTrigger->table, zOld) \n            && sCtx.pTab->pSchema==pTrigger->pTabSchema\n          ){\n          renameTokenFind(&sParse, &sCtx, sParse.pNewTrigger->table);\n        }\n\n        if( isLegacy==0 ){\n          rc = renameResolveTrigger(&sParse, bTemp ? 0 : zDb);\n          if( rc==SQLITE_OK ){\n            renameWalkTrigger(&sWalker, pTrigger);\n            for(pStep=pTrigger->step_list; pStep; pStep=pStep->pNext){\n              if( pStep->zTarget && 0==sqlite3_stricmp(pStep->zTarget, zOld) ){\n                renameTokenFind(&sParse, &sCtx, pStep->zTarget);\n              }\n            }\n          }\n        }\n      }\n#endif\n    }\n\n    if( rc==SQLITE_OK ){\n      rc = renameEditSql(context, &sCtx, zInput, zNew, bQuote);\n    }\n    if( rc!=SQLITE_OK ){\n      if( sParse.zErrMsg ){\n        renameColumnParseError(context, 0, argv[1], argv[2], &sParse);\n      }else{\n        sqlite3_result_error_code(context, rc);\n      }\n    }\n\n    renameParseCleanup(&sParse);\n    renameTokenFree(db, sCtx.pList);\n    sqlite3BtreeLeaveAll(db);\n#ifndef SQLITE_OMIT_AUTHORIZATION\n    db->xAuth = xAuth;\n#endif\n  }\n\n  return;\n}",
        "func": "static void renameTableFunc(\n  sqlite3_context *context,\n  int NotUsed,\n  sqlite3_value **argv\n){\n  sqlite3 *db = sqlite3_context_db_handle(context);\n  const char *zDb = (const char*)sqlite3_value_text(argv[0]);\n  const char *zInput = (const char*)sqlite3_value_text(argv[3]);\n  const char *zOld = (const char*)sqlite3_value_text(argv[4]);\n  const char *zNew = (const char*)sqlite3_value_text(argv[5]);\n  int bTemp = sqlite3_value_int(argv[6]);\n  UNUSED_PARAMETER(NotUsed);\n\n  if( zInput && zOld && zNew ){\n    Parse sParse;\n    int rc;\n    int bQuote = 1;\n    RenameCtx sCtx;\n    Walker sWalker;\n\n#ifndef SQLITE_OMIT_AUTHORIZATION\n    sqlite3_xauth xAuth = db->xAuth;\n    db->xAuth = 0;\n#endif\n\n    sqlite3BtreeEnterAll(db);\n\n    memset(&sCtx, 0, sizeof(RenameCtx));\n    sCtx.pTab = sqlite3FindTable(db, zOld, zDb);\n    memset(&sWalker, 0, sizeof(Walker));\n    sWalker.pParse = &sParse;\n    sWalker.xExprCallback = renameTableExprCb;\n    sWalker.xSelectCallback = renameTableSelectCb;\n    sWalker.u.pRename = &sCtx;\n\n    rc = renameParseSql(&sParse, zDb, 1, db, zInput, bTemp);\n\n    if( rc==SQLITE_OK ){\n      int isLegacy = (db->flags & SQLITE_LegacyAlter);\n      if( sParse.pNewTable ){\n        Table *pTab = sParse.pNewTable;\n\n        if( pTab->pSelect ){\n          if( isLegacy==0 ){\n            Select *pSelect = pTab->pSelect;\n            NameContext sNC;\n            memset(&sNC, 0, sizeof(sNC));\n            sNC.pParse = &sParse;\n\n            assert( pSelect->selFlags & SF_View );\n            pSelect->selFlags &= ~SF_View;\n            sqlite3SelectPrep(&sParse, pTab->pSelect, &sNC);\n            if( sParse.nErr ) rc = sParse.rc;\n            sqlite3WalkSelect(&sWalker, pTab->pSelect);\n          }\n        }else{\n          /* Modify any FK definitions to point to the new table. */\n#ifndef SQLITE_OMIT_FOREIGN_KEY\n          if( isLegacy==0 || (db->flags & SQLITE_ForeignKeys) ){\n            FKey *pFKey;\n            for(pFKey=pTab->pFKey; pFKey; pFKey=pFKey->pNextFrom){\n              if( sqlite3_stricmp(pFKey->zTo, zOld)==0 ){\n                renameTokenFind(&sParse, &sCtx, (void*)pFKey->zTo);\n              }\n            }\n          }\n#endif\n\n          /* If this is the table being altered, fix any table refs in CHECK\n          ** expressions. Also update the name that appears right after the\n          ** \"CREATE [VIRTUAL] TABLE\" bit. */\n          if( sqlite3_stricmp(zOld, pTab->zName)==0 ){\n            sCtx.pTab = pTab;\n            if( isLegacy==0 ){\n              sqlite3WalkExprList(&sWalker, pTab->pCheck);\n            }\n            renameTokenFind(&sParse, &sCtx, pTab->zName);\n          }\n        }\n      }\n\n      else if( sParse.pNewIndex ){\n        renameTokenFind(&sParse, &sCtx, sParse.pNewIndex->zName);\n        if( isLegacy==0 ){\n          sqlite3WalkExpr(&sWalker, sParse.pNewIndex->pPartIdxWhere);\n        }\n      }\n\n#ifndef SQLITE_OMIT_TRIGGER\n      else{\n        Trigger *pTrigger = sParse.pNewTrigger;\n        TriggerStep *pStep;\n        if( 0==sqlite3_stricmp(sParse.pNewTrigger->table, zOld) \n            && sCtx.pTab->pSchema==pTrigger->pTabSchema\n          ){\n          renameTokenFind(&sParse, &sCtx, sParse.pNewTrigger->table);\n        }\n\n        if( isLegacy==0 ){\n          rc = renameResolveTrigger(&sParse, bTemp ? 0 : zDb);\n          if( rc==SQLITE_OK ){\n            renameWalkTrigger(&sWalker, pTrigger);\n            for(pStep=pTrigger->step_list; pStep; pStep=pStep->pNext){\n              if( pStep->zTarget && 0==sqlite3_stricmp(pStep->zTarget, zOld) ){\n                renameTokenFind(&sParse, &sCtx, pStep->zTarget);\n              }\n            }\n          }\n        }\n      }\n#endif\n    }\n\n    if( rc==SQLITE_OK ){\n      rc = renameEditSql(context, &sCtx, zInput, zNew, bQuote);\n    }\n    if( rc!=SQLITE_OK ){\n      if( sParse.zErrMsg ){\n        renameColumnParseError(context, 0, argv[1], argv[2], &sParse);\n      }else{\n        sqlite3_result_error_code(context, rc);\n      }\n    }\n\n    renameParseCleanup(&sParse);\n    renameTokenFree(db, sCtx.pList);\n    sqlite3BtreeLeaveAll(db);\n#ifndef SQLITE_OMIT_AUTHORIZATION\n    db->xAuth = xAuth;\n#endif\n  }\n\n  return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,10 +42,13 @@\n \n         if( pTab->pSelect ){\n           if( isLegacy==0 ){\n+            Select *pSelect = pTab->pSelect;\n             NameContext sNC;\n             memset(&sNC, 0, sizeof(sNC));\n             sNC.pParse = &sParse;\n \n+            assert( pSelect->selFlags & SF_View );\n+            pSelect->selFlags &= ~SF_View;\n             sqlite3SelectPrep(&sParse, pTab->pSelect, &sNC);\n             if( sParse.nErr ) rc = sParse.rc;\n             sqlite3WalkSelect(&sWalker, pTab->pSelect);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            Select *pSelect = pTab->pSelect;",
                "            assert( pSelect->selFlags & SF_View );",
                "            pSelect->selFlags &= ~SF_View;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19645",
        "func_name": "sqlite/sqlite3CreateView",
        "description": "alter.c in SQLite through 3.30.1 allows attackers to trigger infinite recursion via certain types of self-referential views in conjunction with ALTER TABLE statements.",
        "git_url": "https://github.com/sqlite/sqlite/commit/38096961c7cd109110ac21d3ed7dad7e0cb0ae06",
        "commit_title": "Avoid infinite recursion in the ALTER TABLE code when a view contains an unused CTE that references, directly or indirectly, the view itself.",
        "commit_text": " FossilOrigin-Name: 1d2e53a39b87e364685e21de137655b6eee725e4c6d27fc90865072d7c5892b5",
        "func_before": "void sqlite3CreateView(\n  Parse *pParse,     /* The parsing context */\n  Token *pBegin,     /* The CREATE token that begins the statement */\n  Token *pName1,     /* The token that holds the name of the view */\n  Token *pName2,     /* The token that holds the name of the view */\n  ExprList *pCNames, /* Optional list of view column names */\n  Select *pSelect,   /* A SELECT statement that will become the new view */\n  int isTemp,        /* TRUE for a TEMPORARY view */\n  int noErr          /* Suppress error messages if VIEW already exists */\n){\n  Table *p;\n  int n;\n  const char *z;\n  Token sEnd;\n  DbFixer sFix;\n  Token *pName = 0;\n  int iDb;\n  sqlite3 *db = pParse->db;\n\n  if( pParse->nVar>0 ){\n    sqlite3ErrorMsg(pParse, \"parameters are not allowed in views\");\n    goto create_view_fail;\n  }\n  sqlite3StartTable(pParse, pName1, pName2, isTemp, 1, 0, noErr);\n  p = pParse->pNewTable;\n  if( p==0 || pParse->nErr ) goto create_view_fail;\n  sqlite3TwoPartName(pParse, pName1, pName2, &pName);\n  iDb = sqlite3SchemaToIndex(db, p->pSchema);\n  sqlite3FixInit(&sFix, pParse, iDb, \"view\", pName);\n  if( sqlite3FixSelect(&sFix, pSelect) ) goto create_view_fail;\n\n  /* Make a copy of the entire SELECT statement that defines the view.\n  ** This will force all the Expr.token.z values to be dynamically\n  ** allocated rather than point to the input string - which means that\n  ** they will persist after the current sqlite3_exec() call returns.\n  */\n  if( IN_RENAME_OBJECT ){\n    p->pSelect = pSelect;\n    pSelect = 0;\n  }else{\n    p->pSelect = sqlite3SelectDup(db, pSelect, EXPRDUP_REDUCE);\n  }\n  p->pCheck = sqlite3ExprListDup(db, pCNames, EXPRDUP_REDUCE);\n  if( db->mallocFailed ) goto create_view_fail;\n\n  /* Locate the end of the CREATE VIEW statement.  Make sEnd point to\n  ** the end.\n  */\n  sEnd = pParse->sLastToken;\n  assert( sEnd.z[0]!=0 || sEnd.n==0 );\n  if( sEnd.z[0]!=';' ){\n    sEnd.z += sEnd.n;\n  }\n  sEnd.n = 0;\n  n = (int)(sEnd.z - pBegin->z);\n  assert( n>0 );\n  z = pBegin->z;\n  while( sqlite3Isspace(z[n-1]) ){ n--; }\n  sEnd.z = &z[n-1];\n  sEnd.n = 1;\n\n  /* Use sqlite3EndTable() to add the view to the SQLITE_MASTER table */\n  sqlite3EndTable(pParse, 0, &sEnd, 0, 0);\n\ncreate_view_fail:\n  sqlite3SelectDelete(db, pSelect);\n  if( IN_RENAME_OBJECT ){\n    sqlite3RenameExprlistUnmap(pParse, pCNames);\n  }\n  sqlite3ExprListDelete(db, pCNames);\n  return;\n}",
        "func": "void sqlite3CreateView(\n  Parse *pParse,     /* The parsing context */\n  Token *pBegin,     /* The CREATE token that begins the statement */\n  Token *pName1,     /* The token that holds the name of the view */\n  Token *pName2,     /* The token that holds the name of the view */\n  ExprList *pCNames, /* Optional list of view column names */\n  Select *pSelect,   /* A SELECT statement that will become the new view */\n  int isTemp,        /* TRUE for a TEMPORARY view */\n  int noErr          /* Suppress error messages if VIEW already exists */\n){\n  Table *p;\n  int n;\n  const char *z;\n  Token sEnd;\n  DbFixer sFix;\n  Token *pName = 0;\n  int iDb;\n  sqlite3 *db = pParse->db;\n\n  if( pParse->nVar>0 ){\n    sqlite3ErrorMsg(pParse, \"parameters are not allowed in views\");\n    goto create_view_fail;\n  }\n  sqlite3StartTable(pParse, pName1, pName2, isTemp, 1, 0, noErr);\n  p = pParse->pNewTable;\n  if( p==0 || pParse->nErr ) goto create_view_fail;\n  sqlite3TwoPartName(pParse, pName1, pName2, &pName);\n  iDb = sqlite3SchemaToIndex(db, p->pSchema);\n  sqlite3FixInit(&sFix, pParse, iDb, \"view\", pName);\n  if( sqlite3FixSelect(&sFix, pSelect) ) goto create_view_fail;\n\n  /* Make a copy of the entire SELECT statement that defines the view.\n  ** This will force all the Expr.token.z values to be dynamically\n  ** allocated rather than point to the input string - which means that\n  ** they will persist after the current sqlite3_exec() call returns.\n  */\n  pSelect->selFlags |= SF_View;\n  if( IN_RENAME_OBJECT ){\n    p->pSelect = pSelect;\n    pSelect = 0;\n  }else{\n    p->pSelect = sqlite3SelectDup(db, pSelect, EXPRDUP_REDUCE);\n  }\n  p->pCheck = sqlite3ExprListDup(db, pCNames, EXPRDUP_REDUCE);\n  if( db->mallocFailed ) goto create_view_fail;\n\n  /* Locate the end of the CREATE VIEW statement.  Make sEnd point to\n  ** the end.\n  */\n  sEnd = pParse->sLastToken;\n  assert( sEnd.z[0]!=0 || sEnd.n==0 );\n  if( sEnd.z[0]!=';' ){\n    sEnd.z += sEnd.n;\n  }\n  sEnd.n = 0;\n  n = (int)(sEnd.z - pBegin->z);\n  assert( n>0 );\n  z = pBegin->z;\n  while( sqlite3Isspace(z[n-1]) ){ n--; }\n  sEnd.z = &z[n-1];\n  sEnd.n = 1;\n\n  /* Use sqlite3EndTable() to add the view to the SQLITE_MASTER table */\n  sqlite3EndTable(pParse, 0, &sEnd, 0, 0);\n\ncreate_view_fail:\n  sqlite3SelectDelete(db, pSelect);\n  if( IN_RENAME_OBJECT ){\n    sqlite3RenameExprlistUnmap(pParse, pCNames);\n  }\n  sqlite3ExprListDelete(db, pCNames);\n  return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,6 +34,7 @@\n   ** allocated rather than point to the input string - which means that\n   ** they will persist after the current sqlite3_exec() call returns.\n   */\n+  pSelect->selFlags |= SF_View;\n   if( IN_RENAME_OBJECT ){\n     p->pSelect = pSelect;\n     pSelect = 0;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  pSelect->selFlags |= SF_View;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-39929",
        "func_name": "wireshark/dissect_bencoded_list",
        "description": "Uncontrolled Recursion in the Bluetooth DHT dissector in Wireshark 3.4.0 to 3.4.9 and 3.2.0 to 3.2.17 allows denial of service via packet injection or crafted capture file",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/ed98abe2080053403f1881a8b2df1905a3ccdf2e",
        "commit_title": "BT-DHT: Exit a loop.",
        "commit_text": " Always make sure our offset advances in dissect_bencoded_list. Fixes #17651. ",
        "func_before": "static int\ndissect_bencoded_list(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset, const char *label  )\n{\n  proto_item *ti;\n  proto_tree *sub_tree;\n  guint       one_byte;\n  const char *result;\n\n  ti = proto_tree_add_none_format( tree, hf_bencoded_list, tvb, offset, 0, \"%s: list...\", label );\n  sub_tree = proto_item_add_subtree( ti, ett_bencoded_list);\n\n  /* skip the 'l' */\n  offset += 1;\n  while( (one_byte=tvb_get_guint8(tvb,offset)) != 'e' )\n  {\n    switch( one_byte )\n    {\n    /* a integer */\n    case 'i':\n      offset = dissect_bencoded_int( tvb, pinfo, sub_tree, offset, &result, \"Integer\" );\n      break;\n    /* a sub-list */\n    case 'l':\n      offset = dissect_bencoded_list( tvb, pinfo, sub_tree, offset, \"Sub-list\" );\n      break;\n    /* a dictionary */\n    case 'd':\n      offset = dissect_bencoded_dict( tvb, pinfo, sub_tree, offset, \"Sub-dict\" );\n      break;\n    /* a string */\n    default:\n      offset = dissect_bencoded_string( tvb, pinfo, sub_tree, offset, &result, FALSE, \"String\" );\n      if (offset == 0)\n      {\n        proto_tree_add_expert(sub_tree, pinfo, &ei_int_string, tvb, offset, -1);\n        /* if offset is not going on, there is no chance to exit the loop, then return*/\n        return 0;\n      }\n      break;\n    }\n  }\n  proto_tree_add_item(sub_tree, hf_bencoded_list_terminator, tvb, offset, 1, ENC_ASCII|ENC_NA);\n  offset += 1;\n  return offset;\n}",
        "func": "static int\ndissect_bencoded_list(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset, const char *label  )\n{\n  proto_item *ti;\n  proto_tree *sub_tree;\n  guint       one_byte;\n  const char *result;\n\n  ti = proto_tree_add_none_format( tree, hf_bencoded_list, tvb, offset, 0, \"%s: list...\", label );\n  sub_tree = proto_item_add_subtree( ti, ett_bencoded_list);\n\n  /* skip the 'l' */\n  offset += 1;\n  while( (one_byte=tvb_get_guint8(tvb,offset)) != 'e' )\n  {\n    guint start_offset = offset;\n    switch( one_byte )\n    {\n    /* a integer */\n    case 'i':\n      offset = dissect_bencoded_int( tvb, pinfo, sub_tree, offset, &result, \"Integer\" );\n      break;\n    /* a sub-list */\n    case 'l':\n      offset = dissect_bencoded_list( tvb, pinfo, sub_tree, offset, \"Sub-list\" );\n      break;\n    /* a dictionary */\n    case 'd':\n      offset = dissect_bencoded_dict( tvb, pinfo, sub_tree, offset, \"Sub-dict\" );\n      break;\n    /* a string */\n    default:\n      offset = dissect_bencoded_string( tvb, pinfo, sub_tree, offset, &result, FALSE, \"String\" );\n      break;\n    }\n    if (offset <= start_offset)\n    {\n      proto_tree_add_expert(sub_tree, pinfo, &ei_int_string, tvb, offset, -1);\n      /* if offset is not going on, there is no chance to exit the loop, then return*/\n      return 0;\n    }\n  }\n  proto_tree_add_item(sub_tree, hf_bencoded_list_terminator, tvb, offset, 1, ENC_ASCII|ENC_NA);\n  offset += 1;\n  return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n   offset += 1;\n   while( (one_byte=tvb_get_guint8(tvb,offset)) != 'e' )\n   {\n+    guint start_offset = offset;\n     switch( one_byte )\n     {\n     /* a integer */\n@@ -30,13 +31,13 @@\n     /* a string */\n     default:\n       offset = dissect_bencoded_string( tvb, pinfo, sub_tree, offset, &result, FALSE, \"String\" );\n-      if (offset == 0)\n-      {\n-        proto_tree_add_expert(sub_tree, pinfo, &ei_int_string, tvb, offset, -1);\n-        /* if offset is not going on, there is no chance to exit the loop, then return*/\n-        return 0;\n-      }\n       break;\n+    }\n+    if (offset <= start_offset)\n+    {\n+      proto_tree_add_expert(sub_tree, pinfo, &ei_int_string, tvb, offset, -1);\n+      /* if offset is not going on, there is no chance to exit the loop, then return*/\n+      return 0;\n     }\n   }\n   proto_tree_add_item(sub_tree, hf_bencoded_list_terminator, tvb, offset, 1, ENC_ASCII|ENC_NA);",
        "diff_line_info": {
            "deleted_lines": [
                "      if (offset == 0)",
                "      {",
                "        proto_tree_add_expert(sub_tree, pinfo, &ei_int_string, tvb, offset, -1);",
                "        /* if offset is not going on, there is no chance to exit the loop, then return*/",
                "        return 0;",
                "      }"
            ],
            "added_lines": [
                "    guint start_offset = offset;",
                "    }",
                "    if (offset <= start_offset)",
                "    {",
                "      proto_tree_add_expert(sub_tree, pinfo, &ei_int_string, tvb, offset, -1);",
                "      /* if offset is not going on, there is no chance to exit the loop, then return*/",
                "      return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2024-0208",
        "func_name": "wireshark/dissect_readreg_ack",
        "description": "GVCP dissector crash in Wireshark 4.2.0, 4.0.0 to 4.0.11, and 3.6.0 to 3.6.19 allows denial of service via packet injection or crafted capture file",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/a8586fde3a6512466afb2a660538ef3fe712076b",
        "commit_title": "gvcp: Don't try to add a NULL string to a column",
        "commit_text": " This was caught as an invalid argument by g_strlcpy before 4.2, but it was never a good idea.  Fix #19496 ",
        "func_before": "static void dissect_readreg_ack(proto_tree *gvcp_telegram_tree, tvbuff_t *tvb, packet_info *pinfo, gint startoffset, gint length, gvcp_conv_info_t *gvcp_info, gvcp_transaction_t *gvcp_trans)\n{\n\tguint i;\n\tgboolean is_custom_register = FALSE;\n\tconst gchar* address_string = NULL;\n\tguint num_registers;\n\tgint offset;\n\tgboolean valid_trans = FALSE;\n\tguint addr_list_size = 0;\n\n\toffset = startoffset;\n\tnum_registers = length / 4;\n\n\tif (gvcp_trans && gvcp_trans->addr_list)\n\t{\n\t\tvalid_trans = TRUE;\n\t\taddr_list_size = wmem_array_get_count(gvcp_trans->addr_list);\n\t}\n\n\tif (num_registers > 1)\n\t{\n\t\tcol_append_fstr(pinfo->cinfo, COL_INFO, \"[Multiple ReadReg Ack]\");\n\t}\n\telse\n\t{\n\t\tif (valid_trans)\n\t\t{\n\t\t\tif (addr_list_size > 0)\n\t\t\t{\n\t\t\t\taddress_string = get_register_name_from_address(*((guint32*)wmem_array_index(gvcp_trans->addr_list, 0)), pinfo->pool, gvcp_info, &is_custom_register);\n\t\t\t}\n\n\t\t\tif (num_registers)\n\t\t\t{\n\t\t\t\tcol_append_fstr(pinfo->cinfo, COL_INFO, \"%s Value=0x%08X\", address_string, tvb_get_ntohl(tvb, offset));\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tcol_append_str(pinfo->cinfo, COL_INFO, address_string);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (gvcp_telegram_tree != NULL)\n\t{\n\t\t/* Subtree initialization for Payload Data: READREG_ACK */\n\t\tif (num_registers > 1)\n\t\t{\n\t\t\tgvcp_telegram_tree = proto_tree_add_subtree(gvcp_telegram_tree, tvb, offset, length,\n\t\t\t\t\t\t\t\t\t\t\t\tett_gvcp_payload_ack, NULL, \"Register Value List\");\n\t\t}\n\n\t\tfor (i = 0; i < num_registers; i++)\n\t\t{\n\t\t\tguint32 curr_register = 0;\n\n\t\t\tif (valid_trans && i < addr_list_size)\n\t\t\t{\n\t\t\t\tgint stream_channel_count = 0;\n\t\t\t\tcurr_register = *((guint32*)wmem_array_index(gvcp_trans->addr_list, i));\n\t\t\t\taddress_string = get_register_name_from_address(curr_register, pinfo->pool, gvcp_info, &is_custom_register);\n\t\t\t\tfor (; stream_channel_count < GVCP_MAX_STREAM_CHANNEL_COUNT; stream_channel_count++)\n\t\t\t\t{\n\t\t\t\t\tif (curr_register == (guint32)GVCP_SC_EXTENDED_BOOTSTRAP_ADDRESS(stream_channel_count))\n\t\t\t\t\t{\n\t\t\t\t\t\tgvcp_info->extended_bootstrap_address[stream_channel_count] = tvb_get_ntohl(tvb, offset);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (!is_custom_register) /* bootstrap register */\n\t\t\t\t{\n\t\t\t\t\tguint32 extended_bootstrap_address_offset = 0;\n\t\t\t\t\tif (is_extended_bootstrap_address(gvcp_info, curr_register, &extended_bootstrap_address_offset))\n\t\t\t\t\t{\n\t\t\t\t\t\tproto_tree_add_uint_format_value(gvcp_telegram_tree, hf_gvcp_readregcmd_extended_bootstrap_register, tvb, offset, 4, curr_register, \"%s (0x%08X)\", address_string, curr_register);\n\t\t\t\t\t\tdissect_extended_bootstrap_register(curr_register - extended_bootstrap_address_offset, gvcp_telegram_tree, tvb, offset, length);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tproto_tree_add_uint(gvcp_telegram_tree, hf_gvcp_readregcmd_bootstrap_register, tvb, 0, 4, curr_register);\n\t\t\t\t\t\tdissect_register(curr_register, gvcp_telegram_tree, tvb, offset, length);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tproto_tree_add_uint_format_value(gvcp_telegram_tree, hf_gvcp_custom_read_register_addr, tvb, offset, 4, curr_register, \"%s (0x%08X)\", address_string, curr_register);\n\t\t\t\t\tproto_tree_add_item(gvcp_telegram_tree, hf_gvcp_custom_read_register_value, tvb, offset, 4, ENC_BIG_ENDIAN);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tproto_tree_add_item(gvcp_telegram_tree, hf_gvcp_custom_register_value, tvb, offset, 4, ENC_BIG_ENDIAN);\n\t\t\t}\n\n\t\t\toffset += 4;\n\t\t}\n\t}\n}",
        "func": "static void dissect_readreg_ack(proto_tree *gvcp_telegram_tree, tvbuff_t *tvb, packet_info *pinfo, gint startoffset, gint length, gvcp_conv_info_t *gvcp_info, gvcp_transaction_t *gvcp_trans)\n{\n\tguint i;\n\tgboolean is_custom_register = FALSE;\n\tconst gchar* address_string = NULL;\n\tguint num_registers;\n\tgint offset;\n\tgboolean valid_trans = FALSE;\n\tguint addr_list_size = 0;\n\n\toffset = startoffset;\n\tnum_registers = length / 4;\n\n\tif (gvcp_trans && gvcp_trans->addr_list)\n\t{\n\t\tvalid_trans = TRUE;\n\t\taddr_list_size = wmem_array_get_count(gvcp_trans->addr_list);\n\t}\n\n\tif (num_registers > 1)\n\t{\n\t\tcol_append_fstr(pinfo->cinfo, COL_INFO, \"[Multiple ReadReg Ack]\");\n\t}\n\telse\n\t{\n\t\tif (valid_trans)\n\t\t{\n\t\t\tif (addr_list_size > 0)\n\t\t\t{\n\t\t\t\taddress_string = get_register_name_from_address(*((guint32*)wmem_array_index(gvcp_trans->addr_list, 0)), pinfo->pool, gvcp_info, &is_custom_register);\n\t\t\t\tcol_append_str(pinfo->cinfo, COL_INFO, address_string);\n\t\t\t}\n\n\t\t\tif (num_registers)\n\t\t\t{\n\t\t\t\tcol_append_sep_fstr(pinfo->cinfo, COL_INFO, \" \", \"Value=0x%08X\", tvb_get_ntohl(tvb, offset));\n\t\t\t}\n\t\t}\n\t}\n\n\tif (gvcp_telegram_tree != NULL)\n\t{\n\t\t/* Subtree initialization for Payload Data: READREG_ACK */\n\t\tif (num_registers > 1)\n\t\t{\n\t\t\tgvcp_telegram_tree = proto_tree_add_subtree(gvcp_telegram_tree, tvb, offset, length,\n\t\t\t\t\t\t\t\t\t\t\t\tett_gvcp_payload_ack, NULL, \"Register Value List\");\n\t\t}\n\n\t\tfor (i = 0; i < num_registers; i++)\n\t\t{\n\t\t\tguint32 curr_register = 0;\n\n\t\t\tif (valid_trans && i < addr_list_size)\n\t\t\t{\n\t\t\t\tgint stream_channel_count = 0;\n\t\t\t\tcurr_register = *((guint32*)wmem_array_index(gvcp_trans->addr_list, i));\n\t\t\t\taddress_string = get_register_name_from_address(curr_register, pinfo->pool, gvcp_info, &is_custom_register);\n\t\t\t\tfor (; stream_channel_count < GVCP_MAX_STREAM_CHANNEL_COUNT; stream_channel_count++)\n\t\t\t\t{\n\t\t\t\t\tif (curr_register == (guint32)GVCP_SC_EXTENDED_BOOTSTRAP_ADDRESS(stream_channel_count))\n\t\t\t\t\t{\n\t\t\t\t\t\tgvcp_info->extended_bootstrap_address[stream_channel_count] = tvb_get_ntohl(tvb, offset);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (!is_custom_register) /* bootstrap register */\n\t\t\t\t{\n\t\t\t\t\tguint32 extended_bootstrap_address_offset = 0;\n\t\t\t\t\tif (is_extended_bootstrap_address(gvcp_info, curr_register, &extended_bootstrap_address_offset))\n\t\t\t\t\t{\n\t\t\t\t\t\tproto_tree_add_uint_format_value(gvcp_telegram_tree, hf_gvcp_readregcmd_extended_bootstrap_register, tvb, offset, 4, curr_register, \"%s (0x%08X)\", address_string, curr_register);\n\t\t\t\t\t\tdissect_extended_bootstrap_register(curr_register - extended_bootstrap_address_offset, gvcp_telegram_tree, tvb, offset, length);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\tproto_tree_add_uint(gvcp_telegram_tree, hf_gvcp_readregcmd_bootstrap_register, tvb, 0, 4, curr_register);\n\t\t\t\t\t\tdissect_register(curr_register, gvcp_telegram_tree, tvb, offset, length);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tproto_tree_add_uint_format_value(gvcp_telegram_tree, hf_gvcp_custom_read_register_addr, tvb, offset, 4, curr_register, \"%s (0x%08X)\", address_string, curr_register);\n\t\t\t\t\tproto_tree_add_item(gvcp_telegram_tree, hf_gvcp_custom_read_register_value, tvb, offset, 4, ENC_BIG_ENDIAN);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tproto_tree_add_item(gvcp_telegram_tree, hf_gvcp_custom_register_value, tvb, offset, 4, ENC_BIG_ENDIAN);\n\t\t\t}\n\n\t\t\toffset += 4;\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,15 +28,12 @@\n \t\t\tif (addr_list_size > 0)\n \t\t\t{\n \t\t\t\taddress_string = get_register_name_from_address(*((guint32*)wmem_array_index(gvcp_trans->addr_list, 0)), pinfo->pool, gvcp_info, &is_custom_register);\n+\t\t\t\tcol_append_str(pinfo->cinfo, COL_INFO, address_string);\n \t\t\t}\n \n \t\t\tif (num_registers)\n \t\t\t{\n-\t\t\t\tcol_append_fstr(pinfo->cinfo, COL_INFO, \"%s Value=0x%08X\", address_string, tvb_get_ntohl(tvb, offset));\n-\t\t\t}\n-\t\t\telse\n-\t\t\t{\n-\t\t\t\tcol_append_str(pinfo->cinfo, COL_INFO, address_string);\n+\t\t\t\tcol_append_sep_fstr(pinfo->cinfo, COL_INFO, \" \", \"Value=0x%08X\", tvb_get_ntohl(tvb, offset));\n \t\t\t}\n \t\t}\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tcol_append_fstr(pinfo->cinfo, COL_INFO, \"%s Value=0x%08X\", address_string, tvb_get_ntohl(tvb, offset));",
                "\t\t\t}",
                "\t\t\telse",
                "\t\t\t{",
                "\t\t\t\tcol_append_str(pinfo->cinfo, COL_INFO, address_string);"
            ],
            "added_lines": [
                "\t\t\t\tcol_append_str(pinfo->cinfo, COL_INFO, address_string);",
                "\t\t\t\tcol_append_sep_fstr(pinfo->cinfo, COL_INFO, \" \", \"Value=0x%08X\", tvb_get_ntohl(tvb, offset));"
            ]
        }
    },
    {
        "cve_id": "CVE-2024-0210",
        "func_name": "wireshark/proto_register_zbee_tlv",
        "description": "Zigbee TLV dissector crash in Wireshark 4.2.0 allows denial of service via packet injection or crafted capture file",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/98a8a9787bd9a6b15684f32f4cb760f0072f1b87",
        "commit_title": "ZigBee TLV: Add a recursion check",
        "commit_text": " Blind attempt at fixing #19504. ",
        "func_before": "void proto_register_zbee_tlv(void)\n{\n    /* NCP protocol headers */\n    static hf_register_info hf[] = {\n        { &hf_zbee_tlv_relay_msg_type,\n        { \"Type\", \"zbee_tlv.relay.type\", FT_UINT8, BASE_HEX, VALS(zbee_aps_relay_tlvs), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_relay_msg_length,\n        { \"Length\", \"zbee_tlv.relay.length\", FT_UINT8, BASE_DEC, NULL, 0x0,  NULL, HFILL }},\n\n        { &hf_zbee_tlv_relay_msg_joiner_ieee,\n        { \"Joiner IEEE\",        \"zbee_tlv.relay.joiner_ieee\", FT_EUI64, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_global_type,\n          { \"Type\",        \"zbee_tlv.type_global\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_global_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_key_update_req_rsp,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_key_update_req_rsp), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_key_negotiation_req_rsp,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_key_negotiation_req_rsp), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_get_auth_level_rsp,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_get_auth_level_rsp), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_clear_all_bindings_req,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_clear_all_bindings_req), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_security_get_auth_token,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_security_get_auth_token), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_security_get_auth_level,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_security_get_auth_level), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_security_decommission,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_security_decommission), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_beacon_survey,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_beacon_survey), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_rsp_beacon_survey,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_rsp_beacon_survey), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_challenge,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_challenge), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_rsp_challenge,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_rsp_challenge), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_rsp_set_configuration,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_rsp_set_configuration), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_type,\n          { \"Unknown Type\", \"zbee_tlv.type\", FT_UINT8, BASE_HEX,\n            NULL, 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_length,\n          { \"Length\",      \"zbee_tlv.length\", FT_UINT8, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_value,\n          { \"Value\",       \"zbee_tlv.value\", FT_BYTES, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_count,\n          { \"Count\",       \"zbee_tlv.count\", FT_UINT8, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_status_count,\n            { \"TLV Status Count\",           \"zbee_tlv.tlv_status_count\", FT_UINT8, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_id,\n            { \"TLV Type ID\",                \"zbee_tlv.tlv_type_id\", FT_UINT8, BASE_HEX, VALS(zbee_tlv_global_types), 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_proc_status,\n            { \"TLV Processing Status\",      \"zbee_tlv.tlv_proc_status\", FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_manufacturer_specific,\n          { \"ZigBee Manufacturer ID\", \"zbee_tlv.manufacturer_specific\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods,\n          { \"Supported Key Negotiation Methods\", \"zbee_tlv.supported_key_negotiation_methods\", FT_UINT8, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods_key_request,\n          { \"Key Request (ZigBee 3.0)\",             \"zbee_tlv.supported_key_negotiation_methods.key_request\", FT_BOOLEAN, 8, NULL,\n            ZBEE_TLV_SUPPORTED_KEY_NEGOTIATION_METHODS_KEY_REQUEST, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods_ecdhe_using_curve25519_aes_mmo128,\n          { \"ECDHE using Curve25519 with Hash AES-MMO-128\", \"zbee_tlv.supported_key_negotiation_methods.ecdhe_using_curve25519_aes_mmo128\", FT_BOOLEAN, 8, NULL,\n            ZBEE_TLV_SUPPORTED_KEY_NEGOTIATION_METHODS_ANONYMOUS_ECDHE_USING_CURVE25519_AES_MMO128, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods_ecdhe_using_curve25519_sha256,\n          { \"ECDHE using Curve25519 with Hash SHA-256\", \"zbee_tlv.supported_key_negotiation_methods.ecdhe_using_curve25519_sha256\", FT_BOOLEAN, 8, NULL,\n            ZBEE_TLV_SUPPORTED_KEY_NEGOTIATION_METHODS_ANONYMOUS_ECDHE_USING_CURVE25519_SHA256, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_secrets,\n          { \"Supported Pre-shared Secrets Bitmask\", \"zbee_tlv.supported_secrets\", FT_UINT8, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_auth_token,\n          { \"Symmetric Authentication Token\", \"zbee_tlv.supported_secrets.auth_token\", FT_BOOLEAN, 8, NULL,\n            0x1, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_ic,\n          { \"128-bit pre-configured link-key from install code\", \"zbee_tlv.supported_secrets.ic\", FT_BOOLEAN, 8, NULL,\n            0x2, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_passcode_pake,\n          { \"Variable-length pass code for PAKE protocols\", \"zbee_tlv.supported_secrets.passcode_pake\", FT_BOOLEAN, 8, NULL,\n            0x4, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_basic_access_key,\n          { \"Basic Access Key\", \"zbee_tlv.supported_secrets.basic_key\", FT_BOOLEAN, 8, NULL,\n            0x8, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_admin_access_key,\n          { \"Administrative Access Key\", \"zbee_tlv.supported_secrets.admin_key\", FT_BOOLEAN, 8, NULL,\n            0x10, NULL, HFILL }},\n\n        { &hf_zbee_tlv_panid_conflict_cnt,\n          { \"PAN ID Conflict Count\", \"zbee_tlv.panid_conflict_cnt\", FT_UINT16, BASE_DEC, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_next_pan_id,\n          { \"Next PAN ID Change\", \"zbee_tlv.next_pan_id\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_next_channel_change,\n          { \"Next Channel Change\", \"zbee_tlv.next_channel\", FT_UINT32, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_passphrase,\n          { \"128-bit Symmetric Passphrase\", \"zbee_tlv.passphrase\", FT_BYTES, BASE_NONE, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_challenge_value,\n          { \"Challenge Value\", \"zbee_tlv.challenge_val\", FT_BYTES, BASE_NONE, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_aps_frame_counter,\n          { \"APS Frame Counter\", \"zbee_tlv.aps_frame_cnt\", FT_UINT32, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_challenge_counter,\n          { \"Challenge Counter\", \"zbee_tlv.challenge_cnt\", FT_UINT32, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param,\n          { \"Configuration Parameters\", \"zbee_tlv.configuration_parameters\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param_restricted_mode,\n          { \"apsZdoRestrictedMode\", \"zbee_tlv.conf_param.restricted_mode\", FT_UINT16, BASE_DEC, NULL,\n            0x1, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param_link_key_enc,\n          { \"requireLinkKeyEncryptionForApsTransportKey\", \"zbee_tlv.conf_param.req_link_key_enc\", FT_UINT16, BASE_DEC, NULL,\n            0x2, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param_leave_req_allowed,\n          { \"nwkLeaveRequestAllowed\", \"zbee_tlv.conf_param.leave_req_allowed\", FT_UINT16, BASE_DEC, NULL,\n            0x4, NULL, HFILL }},\n\n        { &hf_zbee_tlv_dev_cap_ext_capability_information,\n          { \"Capability Information\", \"zbee_tlv.dev_cap_ext_cap_info\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_dev_cap_ext_zbdirect_virt_device,\n          { \"Zigbee Direct Virtual Device\", \"zbee_tlv.dev_cap_ext.zbdirect_virt_dev\", FT_UINT16, BASE_DEC, NULL,\n            0x1, NULL, HFILL }},\n\n        { &hf_zbee_tlv_lqa,\n          { \"LQA\", \"zbee_tlv.lqa\", FT_UINT8, BASE_HEX, NULL, 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information,\n          { \"Router Information\", \"zbee_tlv.router_information\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_hub_connectivity,\n          { \"Hub Connectivity\",   \"zbee_tlv.router_information.hub_connectivity\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_HUB_CONNECTIVITY, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_uptime,\n          { \"Uptime\",             \"zbee_tlv.router_information.uptime\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_UPTIME, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_pref_parent,\n          { \"Preferred parent\",        \"zbee_tlv.router_information.pref_parent\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_PREF_PARENT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_battery_backup,\n          { \"Battery Backup\",     \"zbee_tlv.router_information.battery\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_BATTERY_BACKUP, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_enhanced_beacon_request_support,\n          { \"Enhanced Beacon Request Support\", \"zbee_tlv.router_information.enhanced_beacon\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_ENHANCED_BEACON_REQUEST_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_mac_data_poll_keepalive_support,\n          { \"MAC Data Poll Keepalive Support\", \"zbee_tlv.router_information.mac_data_poll_keepalive\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_MAC_DATA_POLL_KEEPALIVE_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_end_device_keepalive_support,\n          { \"End Device Keepalive Support\", \"zbee_tlv.router_information.end_dev_keepalive\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_END_DEVICE_KEEPALIVE_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_power_negotiation_support,\n          { \"Power Negotiation Support\", \"zbee_tlv.router_information.power_negotiation\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_POWER_NEGOTIATION_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_node_id,\n          { \"Node ID\", \"zbee_tlv.node_id\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_frag_opt,\n          { \"Fragmentation Options\", \"zbee_tlv.frag_opt\", FT_UINT8, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_max_reassembled_buf_size,\n          { \"Maximum Reassembled Input Buffer Size\", \"zbee_tlv.max_buf_size\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_selected_key_negotiation_method,\n          { \"Selected Key Negotiation Method\", \"zbee_tlv.selected_key_negotiation_method\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_selected_key_negotiation_method), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_selected_pre_shared_secret,\n          { \"Selected Pre Shared Secret\", \"zbee_tlv.selected_pre_shared_secret\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_selected_pre_shared_secret), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_device_eui64,\n          { \"Device EUI64\", \"zbee_tlv.device_eui64\", FT_EUI64, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_public_point,\n          { \"Public Point\", \"zbee_tlv.public_point\", FT_BYTES, BASE_NONE, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_global_tlv_id,\n          { \"TLV Type ID\", \"zbee_tlv.global_tlv_id\", FT_UINT8, BASE_HEX, VALS(zbee_tlv_global_types), 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_ieee_addr,\n          { \"IEEE Addr\", \"zbee_tlv.ieee_addr\", FT_EUI64, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_mic64,\n          { \"MIC\", \"zbee_tlv.mic64\", FT_UINT64, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_initial_join_method,\n          { \"Initial Join Method\",        \"zbee_tlv.init_method\", FT_UINT8, BASE_HEX,\n            VALS(zbee_initial_join_methods), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_active_lk_type,\n          { \"Active link key type\",        \"zbee_tlv.lk_type\", FT_UINT8, BASE_HEX,\n            VALS(zbee_active_lk_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_zbd_comm_tlv,\n            { \"ZBD Commissioning Service TLV Type ID\", \"zbee_tlv.zbd.comm_tlv_id\", FT_UINT8, BASE_HEX,\n              VALS(zbee_tlv_zbd_comm_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_zbd_comm_mj_cmd_tlv,\n            { \"ZBD Manage Joiners TLV Type ID\", \"zbee_tlv.zbd.comm_mj_tlv_id\", FT_UINT8, BASE_HEX,\n              VALS(zbee_tlv_zbd_comm_mj_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_zbd_secur_tlv,\n            { \"ZBD Manage Joiners TLV Type ID\", \"zbee_tlv.zbd.comm_mj_tlv_id\", FT_UINT8, BASE_HEX,\n              VALS(zbee_tlv_zbd_secur_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_tunneling_npdu,\n            { \"NPDU\", \"zbee_tlv.zbd.npdu\", FT_NONE, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_zbd_tunneling_npdu_msg_tlv,\n            { \"NPDU Message TLV\", \"zbee_tlv.zbd.tlv.tunneling.npdu_msg\", FT_NONE, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_ext_pan_id,\n            { \"Extended PAN ID\", \"zbee_tlv.zbd.comm.ext_pan_id\", FT_BYTES, SEP_COLON,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_short_pan_id,\n            { \"Short PAN ID\", \"zbee_tlv.zbd.comm.short_pan_id\", FT_UINT16, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_channel_mask,\n            { \"Network Channels\", \"zbee_tlv.zbd.comm.nwk_channel_mask\", FT_UINT32, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_channel_page,\n            { \"Channel Page\", \"zbee_tlv.zbd.comm.nwk_channel_page\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_channel_page_count,\n            { \"Channel Page Count\", \"zbee_tlv.zbd.comm.nwk_channel_page_count\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_nwk_key,\n            { \"Network key\", \"zbee_tlv.zbd.comm.nwk_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key,\n            { \"Link key\", \"zbee_tlv.zbd.comm.link_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_dev_type,\n            { \"Device type\", \"zbee_tlv.zbd.comm.dev_type\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_dev_type_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_nwk_addr,\n            { \"Network address\", \"zbee_tlv.zbd.comm.nwk_addr\", FT_UINT16, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_join_method,\n            { \"Join method\", \"zbee_tlv.zbd.comm.join_method\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_join_method_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_tc_addr,\n            { \"TC address\", \"zbee_tlv.zbd.comm.tc_addr\", FT_UINT64, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_nwk_upd_id,\n            { \"Network update ID\", \"zbee_tlv.zbd.comm.nwk_upd_id\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_key_seq_num,\n            { \"Network active key sequence number\", \"zbee_tlv.zbd.comm.nwk_key_seq_num\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_adm_key,\n            { \"Admin key\", \"zbee_tlv.zbd.comm.admin_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_status_code_domain,\n            { \"Domain\", \"zbee_tlv.zbd.comm.status_code_domain\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_status_code_domain_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_status_code_value,\n            { \"Code\", \"zbee_tlv.zbd.comm.status_code_value\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_mj_prov_lnk_key,\n            { \"Manage Joiners Provisional Link key\", \"zbee_tlv.zbd.comm.manage_joiners_prov_lnk_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_mj_ieee_addr,\n            { \"Manage Joiners IEEE Address\", \"zbee_tlv.zbd.comm.manage_joiners_ieee_addr\", FT_UINT64, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_mj_cmd,\n            { \"Manage Joiners command\", \"zbee_tlv.zbd.comm.manage_joiners_cmd\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_mj_cmd_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_flags,\n            { \"NPDU Flags\", \"zbee_tlv.zbd.tunneling.npdu_flags\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_flags_security,\n            { \"Security Enabled\", \"zbee_tlv.zbd.tunneling.npdu_flags.security\", FT_BOOLEAN, 8,\n                NULL, 0b00000001, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_flags_reserved,\n            { \"Reserved\", \"zbee_tlv.zbd.tunneling.npdu_flags.reserved\", FT_UINT8, BASE_DEC,\n                NULL, 0b11111110, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_length,\n            { \"NPDU Length\", \"zbee_tlv.zbd.tunneling.npdu_length\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_selected_key_method,\n            { \"Selected Key Negotiation Method\", \"zbee_tlv.zbd.secur.key_method\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_key_method_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_selected_psk_secret,\n            { \"Selected PSK Secret\", \"zbee_tlv.zbd.secur.psk_secret\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_psk_secret_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_nwk_key_seq_num,\n            { \"Network Key Sequence Number\", \"zbee_tlv.zbd.secur.nwk_key_seq_num\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_mac_tag,\n            { \"MAC Tag\", \"zbee_tlv.zbd.secur.mac_tag\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key_flags,\n            { \"Link Key\", \"zbee_tlv.zbd.comm.join.link_key\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key_flags_unique,\n            { \"Unique\", \"zbee_tlv.zbd.comm.join.link_key.unique\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_lnk_key_unique_str), ZBEE_TLV_LINK_KEY_UNIQUE, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key_flags_provisional,\n            { \"Provisional\", \"zbee_tlv.zbd.comm.join.link_key.provisional\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_lnk_key_provisional_str), ZBEE_TLV_LINK_KEY_PROVISIONAL, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_network_status_map,\n            { \"Network Status Map\", \"zbee_tlv.zbd.comm.status_map\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_network_status_map_joined_status,\n            { \"Joined\", \"zbee_tlv.zbd.comm.status_map.joined_status\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_joined_status_str), ZBEE_TLV_STATUS_MAP_JOINED_STATUS, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_network_status_map_open_status,\n            { \"Open/Closed\", \"zbee_tlv.zbd.comm.status_map.open_status\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_nwk_state_str), ZBEE_TLV_STATUS_MAP_OPEN_STATUS, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_network_status_map_network_type,\n            { \"Network Type\", \"zbee_tlv.zbd.comm.status_map.network_type\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_nwk_type_str), ZBEE_TLV_STATUS_MAP_NETWORK_TYPE, NULL, HFILL }\n        },\n    };\n\n    /* Protocol subtrees */\n    static gint *ett[] =\n        {\n            &ett_zbee_aps_tlv,\n            &ett_zbee_aps_relay,\n            &ett_zbee_tlv,\n            &ett_zbee_tlv_supported_key_negotiation_methods,\n            &ett_zbee_tlv_supported_secrets,\n            &ett_zbee_tlv_router_information,\n            &ett_zbee_tlv_configuration_param,\n            &ett_zbee_tlv_capability_information,\n            &ett_zbee_tlv_zbd_tunneling_npdu,\n            &ett_zbee_tlv_zbd_tunneling_npdu_flags,\n            &ett_zbee_tlv_link_key_flags,\n            &ett_zbee_tlv_network_status_map\n        };\n\n    proto_zbee_tlv = proto_register_protocol(\"Zigbee TLV\", \"ZB TLV\", \"zbee_tlv\");\n\n    proto_register_field_array(proto_zbee_tlv, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n\n    register_dissector(\"zbee_tlv\", dissect_zbee_tlv_default, proto_zbee_tlv);\n    zbee_nwk_handle = find_dissector(\"zbee_nwk\");\n}",
        "func": "void proto_register_zbee_tlv(void)\n{\n    /* NCP protocol headers */\n    static hf_register_info hf[] = {\n        { &hf_zbee_tlv_relay_msg_type,\n        { \"Type\", \"zbee_tlv.relay.type\", FT_UINT8, BASE_HEX, VALS(zbee_aps_relay_tlvs), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_relay_msg_length,\n        { \"Length\", \"zbee_tlv.relay.length\", FT_UINT8, BASE_DEC, NULL, 0x0,  NULL, HFILL }},\n\n        { &hf_zbee_tlv_relay_msg_joiner_ieee,\n        { \"Joiner IEEE\",        \"zbee_tlv.relay.joiner_ieee\", FT_EUI64, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_global_type,\n          { \"Type\",        \"zbee_tlv.type_global\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_global_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_key_update_req_rsp,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_key_update_req_rsp), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_key_negotiation_req_rsp,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_key_negotiation_req_rsp), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_get_auth_level_rsp,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_get_auth_level_rsp), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_clear_all_bindings_req,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_clear_all_bindings_req), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_security_get_auth_token,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_security_get_auth_token), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_security_get_auth_level,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_security_get_auth_level), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_security_decommission,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_security_decommission), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_beacon_survey,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_beacon_survey), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_rsp_beacon_survey,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_rsp_beacon_survey), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_req_challenge,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_req_challenge), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_rsp_challenge,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_rsp_challenge), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_rsp_set_configuration,\n          { \"Type\",        \"zbee_tlv.type_local\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_local_types_rsp_set_configuration), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_type,\n          { \"Unknown Type\", \"zbee_tlv.type\", FT_UINT8, BASE_HEX,\n            NULL, 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_length,\n          { \"Length\",      \"zbee_tlv.length\", FT_UINT8, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_value,\n          { \"Value\",       \"zbee_tlv.value\", FT_BYTES, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_count,\n          { \"Count\",       \"zbee_tlv.count\", FT_UINT8, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_status_count,\n            { \"TLV Status Count\",           \"zbee_tlv.tlv_status_count\", FT_UINT8, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_type_id,\n            { \"TLV Type ID\",                \"zbee_tlv.tlv_type_id\", FT_UINT8, BASE_HEX, VALS(zbee_tlv_global_types), 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_proc_status,\n            { \"TLV Processing Status\",      \"zbee_tlv.tlv_proc_status\", FT_UINT8, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_manufacturer_specific,\n          { \"ZigBee Manufacturer ID\", \"zbee_tlv.manufacturer_specific\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods,\n          { \"Supported Key Negotiation Methods\", \"zbee_tlv.supported_key_negotiation_methods\", FT_UINT8, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods_key_request,\n          { \"Key Request (ZigBee 3.0)\",             \"zbee_tlv.supported_key_negotiation_methods.key_request\", FT_BOOLEAN, 8, NULL,\n            ZBEE_TLV_SUPPORTED_KEY_NEGOTIATION_METHODS_KEY_REQUEST, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods_ecdhe_using_curve25519_aes_mmo128,\n          { \"ECDHE using Curve25519 with Hash AES-MMO-128\", \"zbee_tlv.supported_key_negotiation_methods.ecdhe_using_curve25519_aes_mmo128\", FT_BOOLEAN, 8, NULL,\n            ZBEE_TLV_SUPPORTED_KEY_NEGOTIATION_METHODS_ANONYMOUS_ECDHE_USING_CURVE25519_AES_MMO128, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_key_negotiation_methods_ecdhe_using_curve25519_sha256,\n          { \"ECDHE using Curve25519 with Hash SHA-256\", \"zbee_tlv.supported_key_negotiation_methods.ecdhe_using_curve25519_sha256\", FT_BOOLEAN, 8, NULL,\n            ZBEE_TLV_SUPPORTED_KEY_NEGOTIATION_METHODS_ANONYMOUS_ECDHE_USING_CURVE25519_SHA256, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_secrets,\n          { \"Supported Pre-shared Secrets Bitmask\", \"zbee_tlv.supported_secrets\", FT_UINT8, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_auth_token,\n          { \"Symmetric Authentication Token\", \"zbee_tlv.supported_secrets.auth_token\", FT_BOOLEAN, 8, NULL,\n            0x1, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_ic,\n          { \"128-bit pre-configured link-key from install code\", \"zbee_tlv.supported_secrets.ic\", FT_BOOLEAN, 8, NULL,\n            0x2, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_passcode_pake,\n          { \"Variable-length pass code for PAKE protocols\", \"zbee_tlv.supported_secrets.passcode_pake\", FT_BOOLEAN, 8, NULL,\n            0x4, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_basic_access_key,\n          { \"Basic Access Key\", \"zbee_tlv.supported_secrets.basic_key\", FT_BOOLEAN, 8, NULL,\n            0x8, NULL, HFILL }},\n\n        { &hf_zbee_tlv_supported_preshared_secrets_admin_access_key,\n          { \"Administrative Access Key\", \"zbee_tlv.supported_secrets.admin_key\", FT_BOOLEAN, 8, NULL,\n            0x10, NULL, HFILL }},\n\n        { &hf_zbee_tlv_panid_conflict_cnt,\n          { \"PAN ID Conflict Count\", \"zbee_tlv.panid_conflict_cnt\", FT_UINT16, BASE_DEC, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_next_pan_id,\n          { \"Next PAN ID Change\", \"zbee_tlv.next_pan_id\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_next_channel_change,\n          { \"Next Channel Change\", \"zbee_tlv.next_channel\", FT_UINT32, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_passphrase,\n          { \"128-bit Symmetric Passphrase\", \"zbee_tlv.passphrase\", FT_BYTES, BASE_NONE, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_challenge_value,\n          { \"Challenge Value\", \"zbee_tlv.challenge_val\", FT_BYTES, BASE_NONE, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_aps_frame_counter,\n          { \"APS Frame Counter\", \"zbee_tlv.aps_frame_cnt\", FT_UINT32, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_challenge_counter,\n          { \"Challenge Counter\", \"zbee_tlv.challenge_cnt\", FT_UINT32, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param,\n          { \"Configuration Parameters\", \"zbee_tlv.configuration_parameters\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param_restricted_mode,\n          { \"apsZdoRestrictedMode\", \"zbee_tlv.conf_param.restricted_mode\", FT_UINT16, BASE_DEC, NULL,\n            0x1, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param_link_key_enc,\n          { \"requireLinkKeyEncryptionForApsTransportKey\", \"zbee_tlv.conf_param.req_link_key_enc\", FT_UINT16, BASE_DEC, NULL,\n            0x2, NULL, HFILL }},\n\n        { &hf_zbee_tlv_configuration_param_leave_req_allowed,\n          { \"nwkLeaveRequestAllowed\", \"zbee_tlv.conf_param.leave_req_allowed\", FT_UINT16, BASE_DEC, NULL,\n            0x4, NULL, HFILL }},\n\n        { &hf_zbee_tlv_dev_cap_ext_capability_information,\n          { \"Capability Information\", \"zbee_tlv.dev_cap_ext_cap_info\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_dev_cap_ext_zbdirect_virt_device,\n          { \"Zigbee Direct Virtual Device\", \"zbee_tlv.dev_cap_ext.zbdirect_virt_dev\", FT_UINT16, BASE_DEC, NULL,\n            0x1, NULL, HFILL }},\n\n        { &hf_zbee_tlv_lqa,\n          { \"LQA\", \"zbee_tlv.lqa\", FT_UINT8, BASE_HEX, NULL, 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information,\n          { \"Router Information\", \"zbee_tlv.router_information\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_hub_connectivity,\n          { \"Hub Connectivity\",   \"zbee_tlv.router_information.hub_connectivity\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_HUB_CONNECTIVITY, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_uptime,\n          { \"Uptime\",             \"zbee_tlv.router_information.uptime\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_UPTIME, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_pref_parent,\n          { \"Preferred parent\",        \"zbee_tlv.router_information.pref_parent\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_PREF_PARENT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_battery_backup,\n          { \"Battery Backup\",     \"zbee_tlv.router_information.battery\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_BATTERY_BACKUP, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_enhanced_beacon_request_support,\n          { \"Enhanced Beacon Request Support\", \"zbee_tlv.router_information.enhanced_beacon\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_ENHANCED_BEACON_REQUEST_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_mac_data_poll_keepalive_support,\n          { \"MAC Data Poll Keepalive Support\", \"zbee_tlv.router_information.mac_data_poll_keepalive\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_MAC_DATA_POLL_KEEPALIVE_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_end_device_keepalive_support,\n          { \"End Device Keepalive Support\", \"zbee_tlv.router_information.end_dev_keepalive\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_END_DEVICE_KEEPALIVE_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_router_information_power_negotiation_support,\n          { \"Power Negotiation Support\", \"zbee_tlv.router_information.power_negotiation\", FT_BOOLEAN, 16, NULL,\n              ZBEE_TLV_ROUTER_INFORMATION_POWER_NEGOTIATION_SUPPORT, NULL, HFILL }},\n\n        { &hf_zbee_tlv_node_id,\n          { \"Node ID\", \"zbee_tlv.node_id\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_frag_opt,\n          { \"Fragmentation Options\", \"zbee_tlv.frag_opt\", FT_UINT8, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_max_reassembled_buf_size,\n          { \"Maximum Reassembled Input Buffer Size\", \"zbee_tlv.max_buf_size\", FT_UINT16, BASE_HEX, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_selected_key_negotiation_method,\n          { \"Selected Key Negotiation Method\", \"zbee_tlv.selected_key_negotiation_method\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_selected_key_negotiation_method), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_selected_pre_shared_secret,\n          { \"Selected Pre Shared Secret\", \"zbee_tlv.selected_pre_shared_secret\", FT_UINT8, BASE_HEX,\n            VALS(zbee_tlv_selected_pre_shared_secret), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_device_eui64,\n          { \"Device EUI64\", \"zbee_tlv.device_eui64\", FT_EUI64, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_public_point,\n          { \"Public Point\", \"zbee_tlv.public_point\", FT_BYTES, BASE_NONE, NULL,\n            0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_global_tlv_id,\n          { \"TLV Type ID\", \"zbee_tlv.global_tlv_id\", FT_UINT8, BASE_HEX, VALS(zbee_tlv_global_types), 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_ieee_addr,\n          { \"IEEE Addr\", \"zbee_tlv.ieee_addr\", FT_EUI64, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_mic64,\n          { \"MIC\", \"zbee_tlv.mic64\", FT_UINT64, BASE_HEX, NULL, 0x0,\n            NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_initial_join_method,\n          { \"Initial Join Method\",        \"zbee_tlv.init_method\", FT_UINT8, BASE_HEX,\n            VALS(zbee_initial_join_methods), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_active_lk_type,\n          { \"Active link key type\",        \"zbee_tlv.lk_type\", FT_UINT8, BASE_HEX,\n            VALS(zbee_active_lk_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_zbd_comm_tlv,\n            { \"ZBD Commissioning Service TLV Type ID\", \"zbee_tlv.zbd.comm_tlv_id\", FT_UINT8, BASE_HEX,\n              VALS(zbee_tlv_zbd_comm_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_zbd_comm_mj_cmd_tlv,\n            { \"ZBD Manage Joiners TLV Type ID\", \"zbee_tlv.zbd.comm_mj_tlv_id\", FT_UINT8, BASE_HEX,\n              VALS(zbee_tlv_zbd_comm_mj_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_zbd_secur_tlv,\n            { \"ZBD Manage Joiners TLV Type ID\", \"zbee_tlv.zbd.comm_mj_tlv_id\", FT_UINT8, BASE_HEX,\n              VALS(zbee_tlv_zbd_secur_types), 0x0, NULL, HFILL }},\n\n        { &hf_zbee_tlv_local_tunneling_npdu,\n            { \"NPDU\", \"zbee_tlv.zbd.npdu\", FT_NONE, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_zbd_tunneling_npdu_msg_tlv,\n            { \"NPDU Message TLV\", \"zbee_tlv.zbd.tlv.tunneling.npdu_msg\", FT_NONE, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_ext_pan_id,\n            { \"Extended PAN ID\", \"zbee_tlv.zbd.comm.ext_pan_id\", FT_BYTES, SEP_COLON,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_short_pan_id,\n            { \"Short PAN ID\", \"zbee_tlv.zbd.comm.short_pan_id\", FT_UINT16, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_channel_mask,\n            { \"Network Channels\", \"zbee_tlv.zbd.comm.nwk_channel_mask\", FT_UINT32, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_channel_page,\n            { \"Channel Page\", \"zbee_tlv.zbd.comm.nwk_channel_page\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_channel_page_count,\n            { \"Channel Page Count\", \"zbee_tlv.zbd.comm.nwk_channel_page_count\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_nwk_key,\n            { \"Network key\", \"zbee_tlv.zbd.comm.nwk_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key,\n            { \"Link key\", \"zbee_tlv.zbd.comm.link_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_dev_type,\n            { \"Device type\", \"zbee_tlv.zbd.comm.dev_type\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_dev_type_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_nwk_addr,\n            { \"Network address\", \"zbee_tlv.zbd.comm.nwk_addr\", FT_UINT16, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_join_method,\n            { \"Join method\", \"zbee_tlv.zbd.comm.join_method\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_join_method_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_tc_addr,\n            { \"TC address\", \"zbee_tlv.zbd.comm.tc_addr\", FT_UINT64, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_nwk_upd_id,\n            { \"Network update ID\", \"zbee_tlv.zbd.comm.nwk_upd_id\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_key_seq_num,\n            { \"Network active key sequence number\", \"zbee_tlv.zbd.comm.nwk_key_seq_num\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_adm_key,\n            { \"Admin key\", \"zbee_tlv.zbd.comm.admin_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_status_code_domain,\n            { \"Domain\", \"zbee_tlv.zbd.comm.status_code_domain\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_status_code_domain_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_status_code_value,\n            { \"Code\", \"zbee_tlv.zbd.comm.status_code_value\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_mj_prov_lnk_key,\n            { \"Manage Joiners Provisional Link key\", \"zbee_tlv.zbd.comm.manage_joiners_prov_lnk_key\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_mj_ieee_addr,\n            { \"Manage Joiners IEEE Address\", \"zbee_tlv.zbd.comm.manage_joiners_ieee_addr\", FT_UINT64, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_mj_cmd,\n            { \"Manage Joiners command\", \"zbee_tlv.zbd.comm.manage_joiners_cmd\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_mj_cmd_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_flags,\n            { \"NPDU Flags\", \"zbee_tlv.zbd.tunneling.npdu_flags\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_flags_security,\n            { \"Security Enabled\", \"zbee_tlv.zbd.tunneling.npdu_flags.security\", FT_BOOLEAN, 8,\n                NULL, 0b00000001, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_flags_reserved,\n            { \"Reserved\", \"zbee_tlv.zbd.tunneling.npdu_flags.reserved\", FT_UINT8, BASE_DEC,\n                NULL, 0b11111110, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_tunneling_npdu_length,\n            { \"NPDU Length\", \"zbee_tlv.zbd.tunneling.npdu_length\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_selected_key_method,\n            { \"Selected Key Negotiation Method\", \"zbee_tlv.zbd.secur.key_method\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_key_method_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_selected_psk_secret,\n            { \"Selected PSK Secret\", \"zbee_tlv.zbd.secur.psk_secret\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_psk_secret_str), 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_nwk_key_seq_num,\n            { \"Network Key Sequence Number\", \"zbee_tlv.zbd.secur.nwk_key_seq_num\", FT_UINT8, BASE_DEC,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_mac_tag,\n            { \"MAC Tag\", \"zbee_tlv.zbd.secur.mac_tag\", FT_BYTES, BASE_NONE,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key_flags,\n            { \"Link Key\", \"zbee_tlv.zbd.comm.join.link_key\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key_flags_unique,\n            { \"Unique\", \"zbee_tlv.zbd.comm.join.link_key.unique\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_lnk_key_unique_str), ZBEE_TLV_LINK_KEY_UNIQUE, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_link_key_flags_provisional,\n            { \"Provisional\", \"zbee_tlv.zbd.comm.join.link_key.provisional\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_lnk_key_provisional_str), ZBEE_TLV_LINK_KEY_PROVISIONAL, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_network_status_map,\n            { \"Network Status Map\", \"zbee_tlv.zbd.comm.status_map\", FT_UINT8, BASE_HEX,\n                NULL, 0x0, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_network_status_map_joined_status,\n            { \"Joined\", \"zbee_tlv.zbd.comm.status_map.joined_status\", FT_UINT8, BASE_HEX,\n                VALS(zbee_tlv_local_types_joined_status_str), ZBEE_TLV_STATUS_MAP_JOINED_STATUS, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_local_comm_network_status_map_open_status,\n            { \"Open/Closed\", \"zbee_tlv.zbd.comm.status_map.open_status\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_nwk_state_str), ZBEE_TLV_STATUS_MAP_OPEN_STATUS, NULL, HFILL }\n        },\n        { &hf_zbee_tlv_network_status_map_network_type,\n            { \"Network Type\", \"zbee_tlv.zbd.comm.status_map.network_type\", FT_UINT8, BASE_DEC,\n                VALS(zbee_tlv_local_types_nwk_type_str), ZBEE_TLV_STATUS_MAP_NETWORK_TYPE, NULL, HFILL }\n        },\n    };\n\n    /* Protocol subtrees */\n    static gint *ett[] =\n        {\n            &ett_zbee_aps_tlv,\n            &ett_zbee_aps_relay,\n            &ett_zbee_tlv,\n            &ett_zbee_tlv_supported_key_negotiation_methods,\n            &ett_zbee_tlv_supported_secrets,\n            &ett_zbee_tlv_router_information,\n            &ett_zbee_tlv_configuration_param,\n            &ett_zbee_tlv_capability_information,\n            &ett_zbee_tlv_zbd_tunneling_npdu,\n            &ett_zbee_tlv_zbd_tunneling_npdu_flags,\n            &ett_zbee_tlv_link_key_flags,\n            &ett_zbee_tlv_network_status_map\n        };\n\n    static ei_register_info ei[] = {\n        { &ei_zbee_tlv_max_recursion_depth_reached, { \"zbee_tlv.max_recursion_depth_reached\",\n            PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached - stop decoding\", EXPFILL }}\n    };\n\n    proto_zbee_tlv = proto_register_protocol(\"Zigbee TLV\", \"ZB TLV\", \"zbee_tlv\");\n\n    proto_register_field_array(proto_zbee_tlv, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n\n    expert_module_t* expert_zbee_tlv = expert_register_protocol(proto_zbee_tlv);\n    expert_register_field_array(expert_zbee_tlv, ei, array_length(ei));\n\n    register_dissector(\"zbee_tlv\", dissect_zbee_tlv_default, proto_zbee_tlv);\n    zbee_nwk_handle = find_dissector(\"zbee_nwk\");\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -450,10 +450,18 @@\n             &ett_zbee_tlv_network_status_map\n         };\n \n+    static ei_register_info ei[] = {\n+        { &ei_zbee_tlv_max_recursion_depth_reached, { \"zbee_tlv.max_recursion_depth_reached\",\n+            PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached - stop decoding\", EXPFILL }}\n+    };\n+\n     proto_zbee_tlv = proto_register_protocol(\"Zigbee TLV\", \"ZB TLV\", \"zbee_tlv\");\n \n     proto_register_field_array(proto_zbee_tlv, hf, array_length(hf));\n     proto_register_subtree_array(ett, array_length(ett));\n+\n+    expert_module_t* expert_zbee_tlv = expert_register_protocol(proto_zbee_tlv);\n+    expert_register_field_array(expert_zbee_tlv, ei, array_length(ei));\n \n     register_dissector(\"zbee_tlv\", dissect_zbee_tlv_default, proto_zbee_tlv);\n     zbee_nwk_handle = find_dissector(\"zbee_nwk\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    static ei_register_info ei[] = {",
                "        { &ei_zbee_tlv_max_recursion_depth_reached, { \"zbee_tlv.max_recursion_depth_reached\",",
                "            PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached - stop decoding\", EXPFILL }}",
                "    };",
                "",
                "",
                "    expert_module_t* expert_zbee_tlv = expert_register_protocol(proto_zbee_tlv);",
                "    expert_register_field_array(expert_zbee_tlv, ei, array_length(ei));"
            ]
        }
    },
    {
        "cve_id": "CVE-2024-0210",
        "func_name": "wireshark/dissect_zbee_tlvs",
        "description": "Zigbee TLV dissector crash in Wireshark 4.2.0 allows denial of service via packet injection or crafted capture file",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/98a8a9787bd9a6b15684f32f4cb760f0072f1b87",
        "commit_title": "ZigBee TLV: Add a recursion check",
        "commit_text": " Blind attempt at fixing #19504. ",
        "func_before": "guint\ndissect_zbee_tlvs(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, guint offset, void *data, guint8 source_type, guint cmd_id)\n{\n    proto_tree  *subtree;\n    guint8       length;\n\n    while (tvb_bytes_exist(tvb, offset, ZBEE_TLV_HEADER_LENGTH)) {\n        length = tvb_get_guint8(tvb, offset + 1) + 1;\n        subtree = proto_tree_add_subtree(tree, tvb, offset, ZBEE_TLV_HEADER_LENGTH + length, ett_zbee_tlv, NULL, \"TLV\");\n        offset = dissect_zbee_tlv(tvb, pinfo, subtree, offset, data, source_type, cmd_id);\n    }\n\n    return offset;\n}",
        "func": "guint\ndissect_zbee_tlvs(tvbuff_t *tvb, packet_info *pinfo _U_, proto_tree *tree, guint offset, void *data, guint8 source_type, guint cmd_id)\n{\n    proto_tree  *subtree;\n    guint8       length;\n    unsigned     recursion_depth = p_get_proto_depth(pinfo, proto_zbee_tlv);\n\n   if (++recursion_depth >= ZBEE_TLV_MAX_RECURSION_DEPTH) {\n      proto_tree_add_expert(tree, pinfo, &ei_zbee_tlv_max_recursion_depth_reached, tvb, 0, 0);\n      return tvb_reported_length_remaining(tvb, offset);\n   }\n\n   p_set_proto_depth(pinfo, proto_zbee_tlv, recursion_depth);\n\n    while (tvb_bytes_exist(tvb, offset, ZBEE_TLV_HEADER_LENGTH)) {\n        length = tvb_get_guint8(tvb, offset + 1) + 1;\n        subtree = proto_tree_add_subtree(tree, tvb, offset, ZBEE_TLV_HEADER_LENGTH + length, ett_zbee_tlv, NULL, \"TLV\");\n        offset = dissect_zbee_tlv(tvb, pinfo, subtree, offset, data, source_type, cmd_id);\n    }\n\n    recursion_depth = p_get_proto_depth(pinfo, proto_zbee_tlv);\n    p_set_proto_depth(pinfo, proto_zbee_tlv, recursion_depth - 1);\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,14 @@\n {\n     proto_tree  *subtree;\n     guint8       length;\n+    unsigned     recursion_depth = p_get_proto_depth(pinfo, proto_zbee_tlv);\n+\n+   if (++recursion_depth >= ZBEE_TLV_MAX_RECURSION_DEPTH) {\n+      proto_tree_add_expert(tree, pinfo, &ei_zbee_tlv_max_recursion_depth_reached, tvb, 0, 0);\n+      return tvb_reported_length_remaining(tvb, offset);\n+   }\n+\n+   p_set_proto_depth(pinfo, proto_zbee_tlv, recursion_depth);\n \n     while (tvb_bytes_exist(tvb, offset, ZBEE_TLV_HEADER_LENGTH)) {\n         length = tvb_get_guint8(tvb, offset + 1) + 1;\n@@ -10,5 +18,8 @@\n         offset = dissect_zbee_tlv(tvb, pinfo, subtree, offset, data, source_type, cmd_id);\n     }\n \n+    recursion_depth = p_get_proto_depth(pinfo, proto_zbee_tlv);\n+    p_set_proto_depth(pinfo, proto_zbee_tlv, recursion_depth - 1);\n+\n     return offset;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    unsigned     recursion_depth = p_get_proto_depth(pinfo, proto_zbee_tlv);",
                "",
                "   if (++recursion_depth >= ZBEE_TLV_MAX_RECURSION_DEPTH) {",
                "      proto_tree_add_expert(tree, pinfo, &ei_zbee_tlv_max_recursion_depth_reached, tvb, 0, 0);",
                "      return tvb_reported_length_remaining(tvb, offset);",
                "   }",
                "",
                "   p_set_proto_depth(pinfo, proto_zbee_tlv, recursion_depth);",
                "    recursion_depth = p_get_proto_depth(pinfo, proto_zbee_tlv);",
                "    p_set_proto_depth(pinfo, proto_zbee_tlv, recursion_depth - 1);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-20395",
        "func_name": "CESNET/libyang/resolve_superior_type",
        "description": "A stack consumption issue is present in libyang before v1.0-r1 due to the self-referential union type containing leafrefs. Applications that use libyang to parse untrusted input yang files may crash.",
        "git_url": "https://github.com/CESNET/libyang/commit/4e610ccd87a2ba9413819777d508f71163fcc237",
        "commit_title": "resovle BUGFIX handle cyclic typedefs with unions",
        "commit_text": " Fixes #724",
        "func_before": "int\nresolve_superior_type(const char *name, const char *mod_name, const struct lys_module *module,\n                      const struct lys_node *parent, struct lys_tpdf **ret)\n{\n    int i, j;\n    struct lys_tpdf *tpdf, *match;\n    int tpdf_size;\n\n    if (!mod_name) {\n        /* no prefix, try built-in types */\n        for (i = 1; i < LY_DATA_TYPE_COUNT; i++) {\n            if (!strcmp(ly_types[i]->name, name)) {\n                if (ret) {\n                    *ret = ly_types[i];\n                }\n                return EXIT_SUCCESS;\n            }\n        }\n    } else {\n        if (!strcmp(mod_name, module->name)) {\n            /* prefix refers to the current module, ignore it */\n            mod_name = NULL;\n        }\n    }\n\n    if (!mod_name && parent) {\n        /* search in local typedefs */\n        while (parent) {\n            switch (parent->nodetype) {\n            case LYS_CONTAINER:\n                tpdf_size = ((struct lys_node_container *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_container *)parent)->tpdf;\n                break;\n\n            case LYS_LIST:\n                tpdf_size = ((struct lys_node_list *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_list *)parent)->tpdf;\n                break;\n\n            case LYS_GROUPING:\n                tpdf_size = ((struct lys_node_grp *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_grp *)parent)->tpdf;\n                break;\n\n            case LYS_RPC:\n            case LYS_ACTION:\n                tpdf_size = ((struct lys_node_rpc_action *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_rpc_action *)parent)->tpdf;\n                break;\n\n            case LYS_NOTIF:\n                tpdf_size = ((struct lys_node_notif *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_notif *)parent)->tpdf;\n                break;\n\n            case LYS_INPUT:\n            case LYS_OUTPUT:\n                tpdf_size = ((struct lys_node_inout *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_inout *)parent)->tpdf;\n                break;\n\n            default:\n                parent = lys_parent(parent);\n                continue;\n            }\n\n            for (i = 0; i < tpdf_size; i++) {\n                if (!strcmp(tpdf[i].name, name) && tpdf[i].type.base > 0) {\n                    match = &tpdf[i];\n                    goto check_leafref;\n                }\n            }\n\n            parent = lys_parent(parent);\n        }\n    } else {\n        /* get module where to search */\n        module = lyp_get_module(module, NULL, 0, mod_name, 0, 0);\n        if (!module) {\n            return -1;\n        }\n    }\n\n    /* search in top level typedefs */\n    for (i = 0; i < module->tpdf_size; i++) {\n        if (!strcmp(module->tpdf[i].name, name) && module->tpdf[i].type.base > 0) {\n            match = &module->tpdf[i];\n            goto check_leafref;\n        }\n    }\n\n    /* search in submodules */\n    for (i = 0; i < module->inc_size && module->inc[i].submodule; i++) {\n        for (j = 0; j < module->inc[i].submodule->tpdf_size; j++) {\n            if (!strcmp(module->inc[i].submodule->tpdf[j].name, name) && module->inc[i].submodule->tpdf[j].type.base > 0) {\n                match = &module->inc[i].submodule->tpdf[j];\n                goto check_leafref;\n            }\n        }\n    }\n\n    return EXIT_FAILURE;\n\ncheck_leafref:\n    if (ret) {\n        *ret = match;\n    }\n    if (match->type.base == LY_TYPE_LEAFREF) {\n        while (!match->type.info.lref.path) {\n            match = match->type.der;\n            assert(match);\n        }\n    }\n    return EXIT_SUCCESS;\n}",
        "func": "int\nresolve_superior_type(const char *name, const char *mod_name, const struct lys_module *module,\n                      const struct lys_node *parent, struct lys_tpdf **ret)\n{\n    int i, j;\n    struct lys_tpdf *tpdf, *match;\n    int tpdf_size;\n\n    if (!mod_name) {\n        /* no prefix, try built-in types */\n        for (i = 1; i < LY_DATA_TYPE_COUNT; i++) {\n            if (!strcmp(ly_types[i]->name, name)) {\n                if (ret) {\n                    *ret = ly_types[i];\n                }\n                return EXIT_SUCCESS;\n            }\n        }\n    } else {\n        if (!strcmp(mod_name, module->name)) {\n            /* prefix refers to the current module, ignore it */\n            mod_name = NULL;\n        }\n    }\n\n    if (!mod_name && parent) {\n        /* search in local typedefs */\n        while (parent) {\n            switch (parent->nodetype) {\n            case LYS_CONTAINER:\n                tpdf_size = ((struct lys_node_container *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_container *)parent)->tpdf;\n                break;\n\n            case LYS_LIST:\n                tpdf_size = ((struct lys_node_list *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_list *)parent)->tpdf;\n                break;\n\n            case LYS_GROUPING:\n                tpdf_size = ((struct lys_node_grp *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_grp *)parent)->tpdf;\n                break;\n\n            case LYS_RPC:\n            case LYS_ACTION:\n                tpdf_size = ((struct lys_node_rpc_action *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_rpc_action *)parent)->tpdf;\n                break;\n\n            case LYS_NOTIF:\n                tpdf_size = ((struct lys_node_notif *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_notif *)parent)->tpdf;\n                break;\n\n            case LYS_INPUT:\n            case LYS_OUTPUT:\n                tpdf_size = ((struct lys_node_inout *)parent)->tpdf_size;\n                tpdf = ((struct lys_node_inout *)parent)->tpdf;\n                break;\n\n            default:\n                parent = lys_parent(parent);\n                continue;\n            }\n\n            for (i = 0; i < tpdf_size; i++) {\n                if (!strcmp(tpdf[i].name, name)) {\n                    match = &tpdf[i];\n                    goto check_typedef;\n                }\n            }\n\n            parent = lys_parent(parent);\n        }\n    } else {\n        /* get module where to search */\n        module = lyp_get_module(module, NULL, 0, mod_name, 0, 0);\n        if (!module) {\n            return -1;\n        }\n    }\n\n    /* search in top level typedefs */\n    for (i = 0; i < module->tpdf_size; i++) {\n        if (!strcmp(module->tpdf[i].name, name)) {\n            match = &module->tpdf[i];\n            goto check_typedef;\n        }\n    }\n\n    /* search in submodules */\n    for (i = 0; i < module->inc_size && module->inc[i].submodule; i++) {\n        for (j = 0; j < module->inc[i].submodule->tpdf_size; j++) {\n            if (!strcmp(module->inc[i].submodule->tpdf[j].name, name)) {\n                match = &module->inc[i].submodule->tpdf[j];\n                goto check_typedef;\n            }\n        }\n    }\n\n    return EXIT_FAILURE;\n\ncheck_typedef:\n    if (resolve_superior_type_check(&match->type)) {\n        return EXIT_FAILURE;\n    }\n\n    if (ret) {\n        *ret = match;\n    }\n    return EXIT_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -65,9 +65,9 @@\n             }\n \n             for (i = 0; i < tpdf_size; i++) {\n-                if (!strcmp(tpdf[i].name, name) && tpdf[i].type.base > 0) {\n+                if (!strcmp(tpdf[i].name, name)) {\n                     match = &tpdf[i];\n-                    goto check_leafref;\n+                    goto check_typedef;\n                 }\n             }\n \n@@ -83,33 +83,31 @@\n \n     /* search in top level typedefs */\n     for (i = 0; i < module->tpdf_size; i++) {\n-        if (!strcmp(module->tpdf[i].name, name) && module->tpdf[i].type.base > 0) {\n+        if (!strcmp(module->tpdf[i].name, name)) {\n             match = &module->tpdf[i];\n-            goto check_leafref;\n+            goto check_typedef;\n         }\n     }\n \n     /* search in submodules */\n     for (i = 0; i < module->inc_size && module->inc[i].submodule; i++) {\n         for (j = 0; j < module->inc[i].submodule->tpdf_size; j++) {\n-            if (!strcmp(module->inc[i].submodule->tpdf[j].name, name) && module->inc[i].submodule->tpdf[j].type.base > 0) {\n+            if (!strcmp(module->inc[i].submodule->tpdf[j].name, name)) {\n                 match = &module->inc[i].submodule->tpdf[j];\n-                goto check_leafref;\n+                goto check_typedef;\n             }\n         }\n     }\n \n     return EXIT_FAILURE;\n \n-check_leafref:\n+check_typedef:\n+    if (resolve_superior_type_check(&match->type)) {\n+        return EXIT_FAILURE;\n+    }\n+\n     if (ret) {\n         *ret = match;\n     }\n-    if (match->type.base == LY_TYPE_LEAFREF) {\n-        while (!match->type.info.lref.path) {\n-            match = match->type.der;\n-            assert(match);\n-        }\n-    }\n     return EXIT_SUCCESS;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "                if (!strcmp(tpdf[i].name, name) && tpdf[i].type.base > 0) {",
                "                    goto check_leafref;",
                "        if (!strcmp(module->tpdf[i].name, name) && module->tpdf[i].type.base > 0) {",
                "            goto check_leafref;",
                "            if (!strcmp(module->inc[i].submodule->tpdf[j].name, name) && module->inc[i].submodule->tpdf[j].type.base > 0) {",
                "                goto check_leafref;",
                "check_leafref:",
                "    if (match->type.base == LY_TYPE_LEAFREF) {",
                "        while (!match->type.info.lref.path) {",
                "            match = match->type.der;",
                "            assert(match);",
                "        }",
                "    }"
            ],
            "added_lines": [
                "                if (!strcmp(tpdf[i].name, name)) {",
                "                    goto check_typedef;",
                "        if (!strcmp(module->tpdf[i].name, name)) {",
                "            goto check_typedef;",
                "            if (!strcmp(module->inc[i].submodule->tpdf[j].name, name)) {",
                "                goto check_typedef;",
                "check_typedef:",
                "    if (resolve_superior_type_check(&match->type)) {",
                "        return EXIT_FAILURE;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2020-28196",
        "func_name": "krb5/get_tag",
        "description": "MIT Kerberos 5 (aka krb5) before 1.17.2 and 1.18.x before 1.18.3 allows unbounded recursion via an ASN.1-encoded Kerberos message because the lib/krb5/asn.1/asn1_encode.c support for BER indefinite lengths lacks a recursion limit.",
        "git_url": "https://github.com/krb5/krb5/commit/57415dda6cf04e73ffc3723be518eddfae599bfd",
        "commit_title": "Add recursion limit for ASN.1 indefinite lengths",
        "commit_text": " The libkrb5 ASN.1 decoder supports BER indefinite lengths.  It computes the tag length using recursion; the lack of a recursion limit allows an attacker to overrun the stack and cause the process to crash.  Reported by Demi Obenour.  CVE-2020-28196:  In MIT krb5 releases 1.11 and later, an unauthenticated attacker can cause a denial of service for any client or server to which it can send an ASN.1-encoded Kerberos message of sufficient length.  ticket: 8959 (new) tags: pullup target_version: 1.18-next target_version: 1.17-next",
        "func_before": "static krb5_error_code\nget_tag(const uint8_t *asn1, size_t len, taginfo *tag_out,\n        const uint8_t **contents_out, size_t *clen_out,\n        const uint8_t **remainder_out, size_t *rlen_out)\n{\n    krb5_error_code ret;\n    uint8_t o;\n    const uint8_t *c, *p, *tag_start = asn1;\n    size_t clen, llen, i;\n    taginfo t;\n\n    *contents_out = *remainder_out = NULL;\n    *clen_out = *rlen_out = 0;\n    if (len == 0)\n        return ASN1_OVERRUN;\n    o = *asn1++;\n    len--;\n    tag_out->asn1class = o & 0xC0;\n    tag_out->construction = o & 0x20;\n    if ((o & 0x1F) != 0x1F) {\n        tag_out->tagnum = o & 0x1F;\n    } else {\n        tag_out->tagnum = 0;\n        do {\n            if (len == 0)\n                return ASN1_OVERRUN;\n            o = *asn1++;\n            len--;\n            tag_out->tagnum = (tag_out->tagnum << 7) | (o & 0x7F);\n        } while (o & 0x80);\n    }\n\n    if (len == 0)\n        return ASN1_OVERRUN;\n    o = *asn1++;\n    len--;\n\n    if (o == 0x80) {\n        /* Indefinite form (should not be present in DER, but we accept it). */\n        if (tag_out->construction != CONSTRUCTED)\n            return ASN1_MISMATCH_INDEF;\n        p = asn1;\n        while (!(len >= 2 && p[0] == 0 && p[1] == 0)) {\n            ret = get_tag(p, len, &t, &c, &clen, &p, &len);\n            if (ret)\n                return ret;\n        }\n        tag_out->tag_end_len = 2;\n        *contents_out = asn1;\n        *clen_out = p - asn1;\n        *remainder_out = p + 2;\n        *rlen_out = len - 2;\n    } else if ((o & 0x80) == 0) {\n        /* Short form (first octet gives content length). */\n        if (o > len)\n            return ASN1_OVERRUN;\n        tag_out->tag_end_len = 0;\n        *contents_out = asn1;\n        *clen_out = o;\n        *remainder_out = asn1 + *clen_out;\n        *rlen_out = len - (*remainder_out - asn1);\n    } else {\n        /* Long form (first octet gives number of base-256 length octets). */\n        llen = o & 0x7F;\n        if (llen > len)\n            return ASN1_OVERRUN;\n        if (llen > sizeof(*clen_out))\n            return ASN1_OVERFLOW;\n        for (i = 0, clen = 0; i < llen; i++)\n            clen = (clen << 8) | asn1[i];\n        if (clen > len - llen)\n            return ASN1_OVERRUN;\n        tag_out->tag_end_len = 0;\n        *contents_out = asn1 + llen;\n        *clen_out = clen;\n        *remainder_out = *contents_out + clen;\n        *rlen_out = len - (*remainder_out - asn1);\n    }\n    tag_out->tag_len = *contents_out - tag_start;\n    return 0;\n}",
        "func": "static krb5_error_code\nget_tag(const uint8_t *asn1, size_t len, taginfo *tag_out,\n        const uint8_t **contents_out, size_t *clen_out,\n        const uint8_t **remainder_out, size_t *rlen_out, int recursion)\n{\n    krb5_error_code ret;\n    uint8_t o;\n    const uint8_t *c, *p, *tag_start = asn1;\n    size_t clen, llen, i;\n    taginfo t;\n\n    *contents_out = *remainder_out = NULL;\n    *clen_out = *rlen_out = 0;\n    if (len == 0)\n        return ASN1_OVERRUN;\n    o = *asn1++;\n    len--;\n    tag_out->asn1class = o & 0xC0;\n    tag_out->construction = o & 0x20;\n    if ((o & 0x1F) != 0x1F) {\n        tag_out->tagnum = o & 0x1F;\n    } else {\n        tag_out->tagnum = 0;\n        do {\n            if (len == 0)\n                return ASN1_OVERRUN;\n            o = *asn1++;\n            len--;\n            tag_out->tagnum = (tag_out->tagnum << 7) | (o & 0x7F);\n        } while (o & 0x80);\n    }\n\n    if (len == 0)\n        return ASN1_OVERRUN;\n    o = *asn1++;\n    len--;\n\n    if (o == 0x80) {\n        /* Indefinite form (should not be present in DER, but we accept it). */\n        if (tag_out->construction != CONSTRUCTED)\n            return ASN1_MISMATCH_INDEF;\n        if (recursion >= 32)\n            return ASN1_OVERFLOW;\n        p = asn1;\n        while (!(len >= 2 && p[0] == 0 && p[1] == 0)) {\n            ret = get_tag(p, len, &t, &c, &clen, &p, &len, recursion + 1);\n            if (ret)\n                return ret;\n        }\n        tag_out->tag_end_len = 2;\n        *contents_out = asn1;\n        *clen_out = p - asn1;\n        *remainder_out = p + 2;\n        *rlen_out = len - 2;\n    } else if ((o & 0x80) == 0) {\n        /* Short form (first octet gives content length). */\n        if (o > len)\n            return ASN1_OVERRUN;\n        tag_out->tag_end_len = 0;\n        *contents_out = asn1;\n        *clen_out = o;\n        *remainder_out = asn1 + *clen_out;\n        *rlen_out = len - (*remainder_out - asn1);\n    } else {\n        /* Long form (first octet gives number of base-256 length octets). */\n        llen = o & 0x7F;\n        if (llen > len)\n            return ASN1_OVERRUN;\n        if (llen > sizeof(*clen_out))\n            return ASN1_OVERFLOW;\n        for (i = 0, clen = 0; i < llen; i++)\n            clen = (clen << 8) | asn1[i];\n        if (clen > len - llen)\n            return ASN1_OVERRUN;\n        tag_out->tag_end_len = 0;\n        *contents_out = asn1 + llen;\n        *clen_out = clen;\n        *remainder_out = *contents_out + clen;\n        *rlen_out = len - (*remainder_out - asn1);\n    }\n    tag_out->tag_len = *contents_out - tag_start;\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static krb5_error_code\n get_tag(const uint8_t *asn1, size_t len, taginfo *tag_out,\n         const uint8_t **contents_out, size_t *clen_out,\n-        const uint8_t **remainder_out, size_t *rlen_out)\n+        const uint8_t **remainder_out, size_t *rlen_out, int recursion)\n {\n     krb5_error_code ret;\n     uint8_t o;\n@@ -39,9 +39,11 @@\n         /* Indefinite form (should not be present in DER, but we accept it). */\n         if (tag_out->construction != CONSTRUCTED)\n             return ASN1_MISMATCH_INDEF;\n+        if (recursion >= 32)\n+            return ASN1_OVERFLOW;\n         p = asn1;\n         while (!(len >= 2 && p[0] == 0 && p[1] == 0)) {\n-            ret = get_tag(p, len, &t, &c, &clen, &p, &len);\n+            ret = get_tag(p, len, &t, &c, &clen, &p, &len, recursion + 1);\n             if (ret)\n                 return ret;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "        const uint8_t **remainder_out, size_t *rlen_out)",
                "            ret = get_tag(p, len, &t, &c, &clen, &p, &len);"
            ],
            "added_lines": [
                "        const uint8_t **remainder_out, size_t *rlen_out, int recursion)",
                "        if (recursion >= 32)",
                "            return ASN1_OVERFLOW;",
                "            ret = get_tag(p, len, &t, &c, &clen, &p, &len, recursion + 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-28196",
        "func_name": "krb5/k5_asn1_full_decode",
        "description": "MIT Kerberos 5 (aka krb5) before 1.17.2 and 1.18.x before 1.18.3 allows unbounded recursion via an ASN.1-encoded Kerberos message because the lib/krb5/asn.1/asn1_encode.c support for BER indefinite lengths lacks a recursion limit.",
        "git_url": "https://github.com/krb5/krb5/commit/57415dda6cf04e73ffc3723be518eddfae599bfd",
        "commit_title": "Add recursion limit for ASN.1 indefinite lengths",
        "commit_text": " The libkrb5 ASN.1 decoder supports BER indefinite lengths.  It computes the tag length using recursion; the lack of a recursion limit allows an attacker to overrun the stack and cause the process to crash.  Reported by Demi Obenour.  CVE-2020-28196:  In MIT krb5 releases 1.11 and later, an unauthenticated attacker can cause a denial of service for any client or server to which it can send an ASN.1-encoded Kerberos message of sufficient length.  ticket: 8959 (new) tags: pullup target_version: 1.18-next target_version: 1.17-next",
        "func_before": "krb5_error_code\nk5_asn1_full_decode(const krb5_data *code, const struct atype_info *a,\n                    void **retrep)\n{\n    krb5_error_code ret;\n    const uint8_t *contents, *remainder;\n    size_t clen, rlen;\n    taginfo t;\n\n    *retrep = NULL;\n    ret = get_tag((uint8_t *)code->data, code->length, &t, &contents,\n                  &clen, &remainder, &rlen);\n    if (ret)\n        return ret;\n    /* rlen should be 0, but we don't check it (and due to padding in\n     * non-length-preserving enctypes, it will sometimes be nonzero). */\n    if (!check_atype_tag(a, &t))\n        return ASN1_BAD_ID;\n    return decode_atype_to_ptr(&t, contents, clen, a, retrep);\n}",
        "func": "krb5_error_code\nk5_asn1_full_decode(const krb5_data *code, const struct atype_info *a,\n                    void **retrep)\n{\n    krb5_error_code ret;\n    const uint8_t *contents, *remainder;\n    size_t clen, rlen;\n    taginfo t;\n\n    *retrep = NULL;\n    ret = get_tag((uint8_t *)code->data, code->length, &t, &contents,\n                  &clen, &remainder, &rlen, 0);\n    if (ret)\n        return ret;\n    /* rlen should be 0, but we don't check it (and due to padding in\n     * non-length-preserving enctypes, it will sometimes be nonzero). */\n    if (!check_atype_tag(a, &t))\n        return ASN1_BAD_ID;\n    return decode_atype_to_ptr(&t, contents, clen, a, retrep);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \n     *retrep = NULL;\n     ret = get_tag((uint8_t *)code->data, code->length, &t, &contents,\n-                  &clen, &remainder, &rlen);\n+                  &clen, &remainder, &rlen, 0);\n     if (ret)\n         return ret;\n     /* rlen should be 0, but we don't check it (and due to padding in",
        "diff_line_info": {
            "deleted_lines": [
                "                  &clen, &remainder, &rlen);"
            ],
            "added_lines": [
                "                  &clen, &remainder, &rlen, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-28196",
        "func_name": "krb5/decode_sequence_of",
        "description": "MIT Kerberos 5 (aka krb5) before 1.17.2 and 1.18.x before 1.18.3 allows unbounded recursion via an ASN.1-encoded Kerberos message because the lib/krb5/asn.1/asn1_encode.c support for BER indefinite lengths lacks a recursion limit.",
        "git_url": "https://github.com/krb5/krb5/commit/57415dda6cf04e73ffc3723be518eddfae599bfd",
        "commit_title": "Add recursion limit for ASN.1 indefinite lengths",
        "commit_text": " The libkrb5 ASN.1 decoder supports BER indefinite lengths.  It computes the tag length using recursion; the lack of a recursion limit allows an attacker to overrun the stack and cause the process to crash.  Reported by Demi Obenour.  CVE-2020-28196:  In MIT krb5 releases 1.11 and later, an unauthenticated attacker can cause a denial of service for any client or server to which it can send an ASN.1-encoded Kerberos message of sufficient length.  ticket: 8959 (new) tags: pullup target_version: 1.18-next target_version: 1.17-next",
        "func_before": "static krb5_error_code\ndecode_sequence_of(const uint8_t *asn1, size_t len,\n                   const struct atype_info *elemtype, void **seq_out,\n                   size_t *count_out)\n{\n    krb5_error_code ret;\n    void *seq = NULL, *elem, *newseq;\n    const uint8_t *contents;\n    size_t clen, count = 0;\n    taginfo t;\n\n    *seq_out = NULL;\n    *count_out = 0;\n    while (len > 0) {\n        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len);\n        if (ret)\n            goto error;\n        if (!check_atype_tag(elemtype, &t)) {\n            ret = ASN1_BAD_ID;\n            goto error;\n        }\n        newseq = realloc(seq, (count + 1) * elemtype->size);\n        if (newseq == NULL) {\n            ret = ENOMEM;\n            goto error;\n        }\n        seq = newseq;\n        elem = (char *)seq + count * elemtype->size;\n        memset(elem, 0, elemtype->size);\n        ret = decode_atype(&t, contents, clen, elemtype, elem);\n        if (ret)\n            goto error;\n        count++;\n    }\n    *seq_out = seq;\n    *count_out = count;\n    return 0;\n\nerror:\n    free_sequence_of(elemtype, seq, count);\n    free(seq);\n    return ret;\n}",
        "func": "static krb5_error_code\ndecode_sequence_of(const uint8_t *asn1, size_t len,\n                   const struct atype_info *elemtype, void **seq_out,\n                   size_t *count_out)\n{\n    krb5_error_code ret;\n    void *seq = NULL, *elem, *newseq;\n    const uint8_t *contents;\n    size_t clen, count = 0;\n    taginfo t;\n\n    *seq_out = NULL;\n    *count_out = 0;\n    while (len > 0) {\n        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len, 0);\n        if (ret)\n            goto error;\n        if (!check_atype_tag(elemtype, &t)) {\n            ret = ASN1_BAD_ID;\n            goto error;\n        }\n        newseq = realloc(seq, (count + 1) * elemtype->size);\n        if (newseq == NULL) {\n            ret = ENOMEM;\n            goto error;\n        }\n        seq = newseq;\n        elem = (char *)seq + count * elemtype->size;\n        memset(elem, 0, elemtype->size);\n        ret = decode_atype(&t, contents, clen, elemtype, elem);\n        if (ret)\n            goto error;\n        count++;\n    }\n    *seq_out = seq;\n    *count_out = count;\n    return 0;\n\nerror:\n    free_sequence_of(elemtype, seq, count);\n    free(seq);\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n     *seq_out = NULL;\n     *count_out = 0;\n     while (len > 0) {\n-        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len);\n+        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len, 0);\n         if (ret)\n             goto error;\n         if (!check_atype_tag(elemtype, &t)) {",
        "diff_line_info": {
            "deleted_lines": [
                "        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len);"
            ],
            "added_lines": [
                "        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-28196",
        "func_name": "krb5/split_der",
        "description": "MIT Kerberos 5 (aka krb5) before 1.17.2 and 1.18.x before 1.18.3 allows unbounded recursion via an ASN.1-encoded Kerberos message because the lib/krb5/asn.1/asn1_encode.c support for BER indefinite lengths lacks a recursion limit.",
        "git_url": "https://github.com/krb5/krb5/commit/57415dda6cf04e73ffc3723be518eddfae599bfd",
        "commit_title": "Add recursion limit for ASN.1 indefinite lengths",
        "commit_text": " The libkrb5 ASN.1 decoder supports BER indefinite lengths.  It computes the tag length using recursion; the lack of a recursion limit allows an attacker to overrun the stack and cause the process to crash.  Reported by Demi Obenour.  CVE-2020-28196:  In MIT krb5 releases 1.11 and later, an unauthenticated attacker can cause a denial of service for any client or server to which it can send an ASN.1-encoded Kerberos message of sufficient length.  ticket: 8959 (new) tags: pullup target_version: 1.18-next target_version: 1.17-next",
        "func_before": "static krb5_error_code\nsplit_der(asn1buf *buf, uint8_t *const *der, size_t len, taginfo *tag_out)\n{\n    krb5_error_code ret;\n    const uint8_t *contents, *remainder;\n    size_t clen, rlen;\n\n    ret = get_tag(*der, len, tag_out, &contents, &clen, &remainder, &rlen);\n    if (ret)\n        return ret;\n    if (rlen != 0)\n        return ASN1_BAD_LENGTH;\n    insert_bytes(buf, contents, clen);\n    return 0;\n}",
        "func": "static krb5_error_code\nsplit_der(asn1buf *buf, uint8_t *const *der, size_t len, taginfo *tag_out)\n{\n    krb5_error_code ret;\n    const uint8_t *contents, *remainder;\n    size_t clen, rlen;\n\n    ret = get_tag(*der, len, tag_out, &contents, &clen, &remainder, &rlen, 0);\n    if (ret)\n        return ret;\n    if (rlen != 0)\n        return ASN1_BAD_LENGTH;\n    insert_bytes(buf, contents, clen);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n     const uint8_t *contents, *remainder;\n     size_t clen, rlen;\n \n-    ret = get_tag(*der, len, tag_out, &contents, &clen, &remainder, &rlen);\n+    ret = get_tag(*der, len, tag_out, &contents, &clen, &remainder, &rlen, 0);\n     if (ret)\n         return ret;\n     if (rlen != 0)",
        "diff_line_info": {
            "deleted_lines": [
                "    ret = get_tag(*der, len, tag_out, &contents, &clen, &remainder, &rlen);"
            ],
            "added_lines": [
                "    ret = get_tag(*der, len, tag_out, &contents, &clen, &remainder, &rlen, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-28196",
        "func_name": "krb5/decode_sequence",
        "description": "MIT Kerberos 5 (aka krb5) before 1.17.2 and 1.18.x before 1.18.3 allows unbounded recursion via an ASN.1-encoded Kerberos message because the lib/krb5/asn.1/asn1_encode.c support for BER indefinite lengths lacks a recursion limit.",
        "git_url": "https://github.com/krb5/krb5/commit/57415dda6cf04e73ffc3723be518eddfae599bfd",
        "commit_title": "Add recursion limit for ASN.1 indefinite lengths",
        "commit_text": " The libkrb5 ASN.1 decoder supports BER indefinite lengths.  It computes the tag length using recursion; the lack of a recursion limit allows an attacker to overrun the stack and cause the process to crash.  Reported by Demi Obenour.  CVE-2020-28196:  In MIT krb5 releases 1.11 and later, an unauthenticated attacker can cause a denial of service for any client or server to which it can send an ASN.1-encoded Kerberos message of sufficient length.  ticket: 8959 (new) tags: pullup target_version: 1.18-next target_version: 1.17-next",
        "func_before": "static krb5_error_code\ndecode_sequence(const uint8_t *asn1, size_t len, const struct seq_info *seq,\n                void *val)\n{\n    krb5_error_code ret;\n    const uint8_t *contents;\n    size_t i, j, clen;\n    taginfo t;\n\n    assert(seq->n_fields > 0);\n    for (i = 0; i < seq->n_fields; i++) {\n        if (len == 0)\n            break;\n        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len);\n        if (ret)\n            goto error;\n        /*\n         * Find the applicable sequence field.  This logic is a little\n         * oversimplified; we could match an element to an optional extensible\n         * choice or optional stored-DER type when we ought to match a\n         * subsequent non-optional field.  But it's unwise and (hopefully) very\n         * rare for ASN.1 modules to require such precision.\n         */\n        for (; i < seq->n_fields; i++) {\n            if (check_atype_tag(seq->fields[i], &t))\n                break;\n            ret = omit_atype(seq->fields[i], val);\n            if (ret)\n                goto error;\n        }\n        /* We currently model all sequences as extensible.  We should consider\n         * changing this before making the encoder visible to plugins. */\n        if (i == seq->n_fields)\n            break;\n        ret = decode_atype(&t, contents, clen, seq->fields[i], val);\n        if (ret)\n            goto error;\n    }\n    /* Initialize any fields in the C object which were not accounted for in\n     * the sequence.  Error out if any of them aren't optional. */\n    for (; i < seq->n_fields; i++) {\n        ret = omit_atype(seq->fields[i], val);\n        if (ret)\n            goto error;\n    }\n    return 0;\n\nerror:\n    /* Free what we've decoded so far.  Free pointers in a second pass in\n     * case multiple fields refer to the same pointer. */\n    for (j = 0; j < i; j++)\n        free_atype(seq->fields[j], val);\n    for (j = 0; j < i; j++)\n        free_atype_ptr(seq->fields[j], val);\n    return ret;\n}",
        "func": "static krb5_error_code\ndecode_sequence(const uint8_t *asn1, size_t len, const struct seq_info *seq,\n                void *val)\n{\n    krb5_error_code ret;\n    const uint8_t *contents;\n    size_t i, j, clen;\n    taginfo t;\n\n    assert(seq->n_fields > 0);\n    for (i = 0; i < seq->n_fields; i++) {\n        if (len == 0)\n            break;\n        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len, 0);\n        if (ret)\n            goto error;\n        /*\n         * Find the applicable sequence field.  This logic is a little\n         * oversimplified; we could match an element to an optional extensible\n         * choice or optional stored-DER type when we ought to match a\n         * subsequent non-optional field.  But it's unwise and (hopefully) very\n         * rare for ASN.1 modules to require such precision.\n         */\n        for (; i < seq->n_fields; i++) {\n            if (check_atype_tag(seq->fields[i], &t))\n                break;\n            ret = omit_atype(seq->fields[i], val);\n            if (ret)\n                goto error;\n        }\n        /* We currently model all sequences as extensible.  We should consider\n         * changing this before making the encoder visible to plugins. */\n        if (i == seq->n_fields)\n            break;\n        ret = decode_atype(&t, contents, clen, seq->fields[i], val);\n        if (ret)\n            goto error;\n    }\n    /* Initialize any fields in the C object which were not accounted for in\n     * the sequence.  Error out if any of them aren't optional. */\n    for (; i < seq->n_fields; i++) {\n        ret = omit_atype(seq->fields[i], val);\n        if (ret)\n            goto error;\n    }\n    return 0;\n\nerror:\n    /* Free what we've decoded so far.  Free pointers in a second pass in\n     * case multiple fields refer to the same pointer. */\n    for (j = 0; j < i; j++)\n        free_atype(seq->fields[j], val);\n    for (j = 0; j < i; j++)\n        free_atype_ptr(seq->fields[j], val);\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n     for (i = 0; i < seq->n_fields; i++) {\n         if (len == 0)\n             break;\n-        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len);\n+        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len, 0);\n         if (ret)\n             goto error;\n         /*",
        "diff_line_info": {
            "deleted_lines": [
                "        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len);"
            ],
            "added_lines": [
                "        ret = get_tag(asn1, len, &t, &contents, &clen, &asn1, &len, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-28196",
        "func_name": "krb5/decode_atype",
        "description": "MIT Kerberos 5 (aka krb5) before 1.17.2 and 1.18.x before 1.18.3 allows unbounded recursion via an ASN.1-encoded Kerberos message because the lib/krb5/asn.1/asn1_encode.c support for BER indefinite lengths lacks a recursion limit.",
        "git_url": "https://github.com/krb5/krb5/commit/57415dda6cf04e73ffc3723be518eddfae599bfd",
        "commit_title": "Add recursion limit for ASN.1 indefinite lengths",
        "commit_text": " The libkrb5 ASN.1 decoder supports BER indefinite lengths.  It computes the tag length using recursion; the lack of a recursion limit allows an attacker to overrun the stack and cause the process to crash.  Reported by Demi Obenour.  CVE-2020-28196:  In MIT krb5 releases 1.11 and later, an unauthenticated attacker can cause a denial of service for any client or server to which it can send an ASN.1-encoded Kerberos message of sufficient length.  ticket: 8959 (new) tags: pullup target_version: 1.18-next target_version: 1.17-next",
        "func_before": "static krb5_error_code\ndecode_atype(const taginfo *t, const uint8_t *asn1, size_t len,\n             const struct atype_info *a, void *val)\n{\n    krb5_error_code ret;\n\n    switch (a->type) {\n    case atype_fn: {\n        const struct fn_info *fn = a->tinfo;\n        assert(fn->dec != NULL);\n        return fn->dec(t, asn1, len, val);\n    }\n    case atype_sequence:\n        return decode_sequence(asn1, len, a->tinfo, val);\n    case atype_ptr: {\n        const struct ptr_info *ptrinfo = a->tinfo;\n        void *ptr = LOADPTR(val, ptrinfo);\n        assert(ptrinfo->basetype != NULL);\n        if (ptr != NULL) {\n            /* Container was already allocated by a previous sequence field. */\n            return decode_atype(t, asn1, len, ptrinfo->basetype, ptr);\n        } else {\n            ret = decode_atype_to_ptr(t, asn1, len, ptrinfo->basetype, &ptr);\n            if (ret)\n                return ret;\n            STOREPTR(ptr, ptrinfo, val);\n            break;\n        }\n    }\n    case atype_offset: {\n        const struct offset_info *off = a->tinfo;\n        assert(off->basetype != NULL);\n        return decode_atype(t, asn1, len, off->basetype,\n                            (char *)val + off->dataoff);\n    }\n    case atype_optional: {\n        const struct optional_info *opt = a->tinfo;\n        return decode_atype(t, asn1, len, opt->basetype, val);\n    }\n    case atype_counted: {\n        const struct counted_info *counted = a->tinfo;\n        void *dataptr = (char *)val + counted->dataoff;\n        size_t count;\n        assert(counted->basetype != NULL);\n        ret = decode_cntype(t, asn1, len, counted->basetype, dataptr, &count);\n        if (ret)\n            return ret;\n        return store_count(count, counted, val);\n    }\n    case atype_tagged_thing: {\n        const struct tagged_info *tag = a->tinfo;\n        taginfo inner_tag;\n        const taginfo *tp = t;\n        const uint8_t *rem;\n        size_t rlen;\n        if (!tag->implicit) {\n            ret = get_tag(asn1, len, &inner_tag, &asn1, &len, &rem, &rlen);\n            if (ret)\n                return ret;\n            /* Note: we don't check rlen (it should be 0). */\n            tp = &inner_tag;\n            if (!check_atype_tag(tag->basetype, tp))\n                return ASN1_BAD_ID;\n        }\n        return decode_atype(tp, asn1, len, tag->basetype, val);\n    }\n    case atype_bool: {\n        intmax_t intval;\n        ret = k5_asn1_decode_bool(asn1, len, &intval);\n        if (ret)\n            return ret;\n        return store_int(intval, a->size, val);\n    }\n    case atype_int: {\n        intmax_t intval;\n        ret = k5_asn1_decode_int(asn1, len, &intval);\n        if (ret)\n            return ret;\n        return store_int(intval, a->size, val);\n    }\n    case atype_uint: {\n        uintmax_t intval;\n        ret = k5_asn1_decode_uint(asn1, len, &intval);\n        if (ret)\n            return ret;\n        return store_uint(intval, a->size, val);\n    }\n    case atype_int_immediate: {\n        const struct immediate_info *imm = a->tinfo;\n        intmax_t intval;\n        ret = k5_asn1_decode_int(asn1, len, &intval);\n        if (ret)\n            return ret;\n        if (intval != imm->val && imm->err != 0)\n            return imm->err;\n        break;\n    }\n    default:\n        /* Null-terminated sequence types are handled in decode_atype_to_ptr,\n         * since they create variable-sized objects. */\n        assert(a->type != atype_nullterm_sequence_of);\n        assert(a->type != atype_nonempty_nullterm_sequence_of);\n        assert(a->type > atype_min);\n        assert(a->type < atype_max);\n        abort();\n    }\n    return 0;\n}",
        "func": "static krb5_error_code\ndecode_atype(const taginfo *t, const uint8_t *asn1, size_t len,\n             const struct atype_info *a, void *val)\n{\n    krb5_error_code ret;\n\n    switch (a->type) {\n    case atype_fn: {\n        const struct fn_info *fn = a->tinfo;\n        assert(fn->dec != NULL);\n        return fn->dec(t, asn1, len, val);\n    }\n    case atype_sequence:\n        return decode_sequence(asn1, len, a->tinfo, val);\n    case atype_ptr: {\n        const struct ptr_info *ptrinfo = a->tinfo;\n        void *ptr = LOADPTR(val, ptrinfo);\n        assert(ptrinfo->basetype != NULL);\n        if (ptr != NULL) {\n            /* Container was already allocated by a previous sequence field. */\n            return decode_atype(t, asn1, len, ptrinfo->basetype, ptr);\n        } else {\n            ret = decode_atype_to_ptr(t, asn1, len, ptrinfo->basetype, &ptr);\n            if (ret)\n                return ret;\n            STOREPTR(ptr, ptrinfo, val);\n            break;\n        }\n    }\n    case atype_offset: {\n        const struct offset_info *off = a->tinfo;\n        assert(off->basetype != NULL);\n        return decode_atype(t, asn1, len, off->basetype,\n                            (char *)val + off->dataoff);\n    }\n    case atype_optional: {\n        const struct optional_info *opt = a->tinfo;\n        return decode_atype(t, asn1, len, opt->basetype, val);\n    }\n    case atype_counted: {\n        const struct counted_info *counted = a->tinfo;\n        void *dataptr = (char *)val + counted->dataoff;\n        size_t count;\n        assert(counted->basetype != NULL);\n        ret = decode_cntype(t, asn1, len, counted->basetype, dataptr, &count);\n        if (ret)\n            return ret;\n        return store_count(count, counted, val);\n    }\n    case atype_tagged_thing: {\n        const struct tagged_info *tag = a->tinfo;\n        taginfo inner_tag;\n        const taginfo *tp = t;\n        const uint8_t *rem;\n        size_t rlen;\n        if (!tag->implicit) {\n            ret = get_tag(asn1, len, &inner_tag, &asn1, &len, &rem, &rlen, 0);\n            if (ret)\n                return ret;\n            /* Note: we don't check rlen (it should be 0). */\n            tp = &inner_tag;\n            if (!check_atype_tag(tag->basetype, tp))\n                return ASN1_BAD_ID;\n        }\n        return decode_atype(tp, asn1, len, tag->basetype, val);\n    }\n    case atype_bool: {\n        intmax_t intval;\n        ret = k5_asn1_decode_bool(asn1, len, &intval);\n        if (ret)\n            return ret;\n        return store_int(intval, a->size, val);\n    }\n    case atype_int: {\n        intmax_t intval;\n        ret = k5_asn1_decode_int(asn1, len, &intval);\n        if (ret)\n            return ret;\n        return store_int(intval, a->size, val);\n    }\n    case atype_uint: {\n        uintmax_t intval;\n        ret = k5_asn1_decode_uint(asn1, len, &intval);\n        if (ret)\n            return ret;\n        return store_uint(intval, a->size, val);\n    }\n    case atype_int_immediate: {\n        const struct immediate_info *imm = a->tinfo;\n        intmax_t intval;\n        ret = k5_asn1_decode_int(asn1, len, &intval);\n        if (ret)\n            return ret;\n        if (intval != imm->val && imm->err != 0)\n            return imm->err;\n        break;\n    }\n    default:\n        /* Null-terminated sequence types are handled in decode_atype_to_ptr,\n         * since they create variable-sized objects. */\n        assert(a->type != atype_nullterm_sequence_of);\n        assert(a->type != atype_nonempty_nullterm_sequence_of);\n        assert(a->type > atype_min);\n        assert(a->type < atype_max);\n        abort();\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,7 +54,7 @@\n         const uint8_t *rem;\n         size_t rlen;\n         if (!tag->implicit) {\n-            ret = get_tag(asn1, len, &inner_tag, &asn1, &len, &rem, &rlen);\n+            ret = get_tag(asn1, len, &inner_tag, &asn1, &len, &rem, &rlen, 0);\n             if (ret)\n                 return ret;\n             /* Note: we don't check rlen (it should be 0). */",
        "diff_line_info": {
            "deleted_lines": [
                "            ret = get_tag(asn1, len, &inner_tag, &asn1, &len, &rem, &rlen);"
            ],
            "added_lines": [
                "            ret = get_tag(asn1, len, &inner_tag, &asn1, &len, &rem, &rlen, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/FBUnserializer<V>::unserializeList",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "inline typename V::VectorType FBUnserializer<V>::unserializeList() {\n  p_ += CODE_SIZE;\n\n  // the list size is written so we can reserve it in the vector\n  // in future. Skip past it for now.\n  unserializeInt64();\n\n  typename V::VectorType ret = V::createVector();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    V::vectorAppend(ret, unserializeThing());\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n  return ret;\n}",
        "func": "inline typename V::VectorType FBUnserializer<V>::unserializeList(size_t depth) {\n  p_ += CODE_SIZE;\n\n  // the list size is written so we can reserve it in the vector\n  // in future. Skip past it for now.\n  unserializeInt64();\n\n  typename V::VectorType ret = V::createVector();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    V::vectorAppend(ret, unserializeThing(depth + 1));\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-inline typename V::VectorType FBUnserializer<V>::unserializeList() {\n+inline typename V::VectorType FBUnserializer<V>::unserializeList(size_t depth) {\n   p_ += CODE_SIZE;\n \n   // the list size is written so we can reserve it in the vector\n@@ -9,7 +9,7 @@\n \n   size_t code = nextCode();\n   while (code != FB_SERIALIZE_STOP) {\n-    V::vectorAppend(ret, unserializeThing());\n+    V::vectorAppend(ret, unserializeThing(depth + 1));\n     code = nextCode();\n   }\n   p_ += CODE_SIZE;",
        "diff_line_info": {
            "deleted_lines": [
                "inline typename V::VectorType FBUnserializer<V>::unserializeList() {",
                "    V::vectorAppend(ret, unserializeThing());"
            ],
            "added_lines": [
                "inline typename V::VectorType FBUnserializer<V>::unserializeList(size_t depth) {",
                "    V::vectorAppend(ret, unserializeThing(depth + 1));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/FBUnserializer<V>::unserializeSet",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "inline typename V::SetType FBUnserializer<V>::unserializeSet() {\n  p_ += CODE_SIZE;\n\n  // the set size is written so we can reserve it in the set\n  // in future. Skip past it for now.\n  unserializeInt64();\n\n  typename V::SetType ret = V::createSet();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    V::setAppend(ret, unserializeThing());\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n  return ret;\n}",
        "func": "inline typename V::SetType FBUnserializer<V>::unserializeSet(size_t depth) {\n  p_ += CODE_SIZE;\n\n  // the set size is written so we can reserve it in the set\n  // in future. Skip past it for now.\n  unserializeInt64();\n\n  typename V::SetType ret = V::createSet();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    V::setAppend(ret, unserializeThing(depth + 1));\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-inline typename V::SetType FBUnserializer<V>::unserializeSet() {\n+inline typename V::SetType FBUnserializer<V>::unserializeSet(size_t depth) {\n   p_ += CODE_SIZE;\n \n   // the set size is written so we can reserve it in the set\n@@ -9,7 +9,7 @@\n \n   size_t code = nextCode();\n   while (code != FB_SERIALIZE_STOP) {\n-    V::setAppend(ret, unserializeThing());\n+    V::setAppend(ret, unserializeThing(depth + 1));\n     code = nextCode();\n   }\n   p_ += CODE_SIZE;",
        "diff_line_info": {
            "deleted_lines": [
                "inline typename V::SetType FBUnserializer<V>::unserializeSet() {",
                "    V::setAppend(ret, unserializeThing());"
            ],
            "added_lines": [
                "inline typename V::SetType FBUnserializer<V>::unserializeSet(size_t depth) {",
                "    V::setAppend(ret, unserializeThing(depth + 1));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/FBUnserializer<V>::unserializeThing",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "inline typename V::VariantType FBUnserializer<V>::unserializeThing() {\n  size_t code = nextCode();\n\n  switch (code) {\n    case FB_SERIALIZE_BYTE:\n    case FB_SERIALIZE_I16:\n    case FB_SERIALIZE_I32:\n    case FB_SERIALIZE_I64:\n      return V::fromInt64(unserializeInt64());\n    case FB_SERIALIZE_VARCHAR:\n    case FB_SERIALIZE_STRING:\n      return V::fromString(unserializeString());\n    case FB_SERIALIZE_STRUCT:\n      return V::fromMap(unserializeMap());\n    case FB_SERIALIZE_NULL:\n      ++p_;\n      return V::createNull();\n    case FB_SERIALIZE_DOUBLE:\n      return V::fromDouble(unserializeDouble());\n    case FB_SERIALIZE_BOOLEAN:\n      return V::fromBool(unserializeBoolean());\n    case FB_SERIALIZE_VECTOR:\n      return V::fromVector(unserializeVector());\n    case FB_SERIALIZE_LIST:\n      return V::fromVector(unserializeList());\n    case FB_SERIALIZE_SET:\n      return V::fromSet(unserializeSet());\n    default:\n      throw UnserializeError(\"Invalid code: \" + folly::to<std::string>(code)\n                             + \" at location \" + folly::to<std::string>(p_));\n  }\n}",
        "func": "inline typename V::VariantType\nFBUnserializer<V>::unserializeThing(size_t depth) {\n  if (UNLIKELY(depth > 1024)) {\n    throw UnserializeError(\"depth > 1024\");\n  }\n\n  size_t code = nextCode();\n\n  switch (code) {\n    case FB_SERIALIZE_BYTE:\n    case FB_SERIALIZE_I16:\n    case FB_SERIALIZE_I32:\n    case FB_SERIALIZE_I64:\n      return V::fromInt64(unserializeInt64());\n    case FB_SERIALIZE_VARCHAR:\n    case FB_SERIALIZE_STRING:\n      return V::fromString(unserializeString());\n    case FB_SERIALIZE_STRUCT:\n      return V::fromMap(unserializeMap(depth));\n    case FB_SERIALIZE_NULL:\n      ++p_;\n      return V::createNull();\n    case FB_SERIALIZE_DOUBLE:\n      return V::fromDouble(unserializeDouble());\n    case FB_SERIALIZE_BOOLEAN:\n      return V::fromBool(unserializeBoolean());\n    case FB_SERIALIZE_VECTOR:\n      return V::fromVector(unserializeVector(depth));\n    case FB_SERIALIZE_LIST:\n      return V::fromVector(unserializeList(depth));\n    case FB_SERIALIZE_SET:\n      return V::fromSet(unserializeSet(depth));\n    default:\n      throw UnserializeError(\"Invalid code: \" + folly::to<std::string>(code)\n                             + \" at location \" + folly::to<std::string>(p_));\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,9 @@\n-inline typename V::VariantType FBUnserializer<V>::unserializeThing() {\n+inline typename V::VariantType\n+FBUnserializer<V>::unserializeThing(size_t depth) {\n+  if (UNLIKELY(depth > 1024)) {\n+    throw UnserializeError(\"depth > 1024\");\n+  }\n+\n   size_t code = nextCode();\n \n   switch (code) {\n@@ -11,7 +16,7 @@\n     case FB_SERIALIZE_STRING:\n       return V::fromString(unserializeString());\n     case FB_SERIALIZE_STRUCT:\n-      return V::fromMap(unserializeMap());\n+      return V::fromMap(unserializeMap(depth));\n     case FB_SERIALIZE_NULL:\n       ++p_;\n       return V::createNull();\n@@ -20,11 +25,11 @@\n     case FB_SERIALIZE_BOOLEAN:\n       return V::fromBool(unserializeBoolean());\n     case FB_SERIALIZE_VECTOR:\n-      return V::fromVector(unserializeVector());\n+      return V::fromVector(unserializeVector(depth));\n     case FB_SERIALIZE_LIST:\n-      return V::fromVector(unserializeList());\n+      return V::fromVector(unserializeList(depth));\n     case FB_SERIALIZE_SET:\n-      return V::fromSet(unserializeSet());\n+      return V::fromSet(unserializeSet(depth));\n     default:\n       throw UnserializeError(\"Invalid code: \" + folly::to<std::string>(code)\n                              + \" at location \" + folly::to<std::string>(p_));",
        "diff_line_info": {
            "deleted_lines": [
                "inline typename V::VariantType FBUnserializer<V>::unserializeThing() {",
                "      return V::fromMap(unserializeMap());",
                "      return V::fromVector(unserializeVector());",
                "      return V::fromVector(unserializeList());",
                "      return V::fromSet(unserializeSet());"
            ],
            "added_lines": [
                "inline typename V::VariantType",
                "FBUnserializer<V>::unserializeThing(size_t depth) {",
                "  if (UNLIKELY(depth > 1024)) {",
                "    throw UnserializeError(\"depth > 1024\");",
                "  }",
                "",
                "      return V::fromMap(unserializeMap(depth));",
                "      return V::fromVector(unserializeVector(depth));",
                "      return V::fromVector(unserializeList(depth));",
                "      return V::fromSet(unserializeSet(depth));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/FBUnserializer<V>::unserializeMap",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "inline typename V::MapType FBUnserializer<V>::unserializeMap() {\n  p_ += CODE_SIZE;\n\n  typename V::MapType ret = V::createMap();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    switch (code) {\n      case FB_SERIALIZE_VARCHAR:\n      case FB_SERIALIZE_STRING:\n        {\n          auto key = unserializeString();\n          auto value = unserializeThing();\n          V::mapSet(ret, std::move(key), std::move(value));\n        }\n        break;\n      default:\n        {\n          auto key = unserializeInt64();\n          auto value = unserializeThing();\n          V::mapSet(ret, std::move(key), std::move(value));\n        }\n    }\n\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n\n  return ret;\n}",
        "func": "inline typename V::MapType FBUnserializer<V>::unserializeMap(size_t depth) {\n  p_ += CODE_SIZE;\n\n  typename V::MapType ret = V::createMap();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    switch (code) {\n      case FB_SERIALIZE_VARCHAR:\n      case FB_SERIALIZE_STRING:\n        {\n          auto key = unserializeString();\n          auto value = unserializeThing(depth + 1);\n          V::mapSet(ret, std::move(key), std::move(value));\n        }\n        break;\n      default:\n        {\n          auto key = unserializeInt64();\n          auto value = unserializeThing(depth + 1);\n          V::mapSet(ret, std::move(key), std::move(value));\n        }\n    }\n\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-inline typename V::MapType FBUnserializer<V>::unserializeMap() {\n+inline typename V::MapType FBUnserializer<V>::unserializeMap(size_t depth) {\n   p_ += CODE_SIZE;\n \n   typename V::MapType ret = V::createMap();\n@@ -10,14 +10,14 @@\n       case FB_SERIALIZE_STRING:\n         {\n           auto key = unserializeString();\n-          auto value = unserializeThing();\n+          auto value = unserializeThing(depth + 1);\n           V::mapSet(ret, std::move(key), std::move(value));\n         }\n         break;\n       default:\n         {\n           auto key = unserializeInt64();\n-          auto value = unserializeThing();\n+          auto value = unserializeThing(depth + 1);\n           V::mapSet(ret, std::move(key), std::move(value));\n         }\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "inline typename V::MapType FBUnserializer<V>::unserializeMap() {",
                "          auto value = unserializeThing();",
                "          auto value = unserializeThing();"
            ],
            "added_lines": [
                "inline typename V::MapType FBUnserializer<V>::unserializeMap(size_t depth) {",
                "          auto value = unserializeThing(depth + 1);",
                "          auto value = unserializeThing(depth + 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/FBUnserializer<V>::unserializeVector",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "inline typename V::VectorType FBUnserializer<V>::unserializeVector() {\n  p_ += CODE_SIZE;\n\n  typename V::VectorType ret = V::createVector();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    V::vectorAppend(ret, unserializeThing());\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n  return ret;\n}",
        "func": "inline typename V::VectorType\nFBUnserializer<V>::unserializeVector(size_t depth) {\n  p_ += CODE_SIZE;\n\n  typename V::VectorType ret = V::createVector();\n\n  size_t code = nextCode();\n  while (code != FB_SERIALIZE_STOP) {\n    V::vectorAppend(ret, unserializeThing(depth + 1));\n    code = nextCode();\n  }\n  p_ += CODE_SIZE;\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,12 @@\n-inline typename V::VectorType FBUnserializer<V>::unserializeVector() {\n+inline typename V::VectorType\n+FBUnserializer<V>::unserializeVector(size_t depth) {\n   p_ += CODE_SIZE;\n \n   typename V::VectorType ret = V::createVector();\n \n   size_t code = nextCode();\n   while (code != FB_SERIALIZE_STOP) {\n-    V::vectorAppend(ret, unserializeThing());\n+    V::vectorAppend(ret, unserializeThing(depth + 1));\n     code = nextCode();\n   }\n   p_ += CODE_SIZE;",
        "diff_line_info": {
            "deleted_lines": [
                "inline typename V::VectorType FBUnserializer<V>::unserializeVector() {",
                "    V::vectorAppend(ret, unserializeThing());"
            ],
            "added_lines": [
                "inline typename V::VectorType",
                "FBUnserializer<V>::unserializeVector(size_t depth) {",
                "    V::vectorAppend(ret, unserializeThing(depth + 1));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/FBUnserializer<V>::unserialize",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "inline typename V::VariantType FBUnserializer<V>::unserialize(\n  folly::StringPiece serialized) {\n\n  FBUnserializer<V> unserializer(serialized);\n  return unserializer.unserializeThing();\n}",
        "func": "inline typename V::VariantType FBUnserializer<V>::unserialize(\n  folly::StringPiece serialized) {\n\n  FBUnserializer<V> unserializer(serialized);\n  return unserializer.unserializeThing(0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,5 @@\n   folly::StringPiece serialized) {\n \n   FBUnserializer<V> unserializer(serialized);\n-  return unserializer.unserializeThing();\n+  return unserializer.unserializeThing(0);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  return unserializer.unserializeThing();"
            ],
            "added_lines": [
                "  return unserializer.unserializeThing(0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/setAppend",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "static void setAppend(SetType& set, const VariantType& v) {\n    auto value_type = type(v);\n    if (value_type != HPHP::serialize::Type::INT64 &&\n        value_type != HPHP::serialize::Type::STRING) {\n      throw HPHP::serialize::UnserializeError(\n          \"Unsupported keyset element of type \" +\n          folly::to<std::string>(value_type));\n    }\n    set.append(v);\n  }",
        "func": "static void setAppend(SetType& set, const VariantType& v) {\n    if (!v.isInteger() && !v.isString()) {\n      throw HPHP::serialize::UnserializeError(\n        \"Keysets can only contain integers or strings\"\n      );\n    }\n    set.append(v);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,8 @@\n static void setAppend(SetType& set, const VariantType& v) {\n-    auto value_type = type(v);\n-    if (value_type != HPHP::serialize::Type::INT64 &&\n-        value_type != HPHP::serialize::Type::STRING) {\n+    if (!v.isInteger() && !v.isString()) {\n       throw HPHP::serialize::UnserializeError(\n-          \"Unsupported keyset element of type \" +\n-          folly::to<std::string>(value_type));\n+        \"Keysets can only contain integers or strings\"\n+      );\n     }\n     set.append(v);\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "    auto value_type = type(v);",
                "    if (value_type != HPHP::serialize::Type::INT64 &&",
                "        value_type != HPHP::serialize::Type::STRING) {",
                "          \"Unsupported keyset element of type \" +",
                "          folly::to<std::string>(value_type));"
            ],
            "added_lines": [
                "    if (!v.isInteger() && !v.isString()) {",
                "        \"Keysets can only contain integers or strings\"",
                "      );"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/fb_compact_unserialize_from_buffer",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "int fb_compact_unserialize_from_buffer(\n  Variant& out, const char* buf, int n, int& p) {\n\n  CHECK_ENOUGH(1, p, n);\n  int code = (unsigned char)buf[p];\n  if ((code & ~kCodeMask) != kCodePrefix ||\n      (code & kCodeMask) == FB_CS_INT16 ||\n      (code & kCodeMask) == FB_CS_INT32 ||\n      (code & kCodeMask) == FB_CS_INT64) {\n\n    int64_t val;\n    int err = fb_compact_unserialize_int64_from_buffer(val, buf, n, p);\n    if (err) {\n      return err;\n    }\n    out = (int64_t)val;\n    return 0;\n  }\n  p += 1;\n  code &= kCodeMask;\n  switch (code) {\n    case FB_CS_NULL:\n      out = uninit_null();\n      break;\n\n    case FB_CS_TRUE:\n      out = true;\n      break;\n\n    case FB_CS_FALSE:\n      out = false;\n      break;\n\n    case FB_CS_DOUBLE:\n    {\n      CHECK_ENOUGH(8, p, n);\n      double d = *reinterpret_cast<const double*>(buf + p);\n      p += 8;\n      out = d;\n      break;\n    }\n\n    case FB_CS_STRING_0:\n    {\n      out = s_empty;\n      break;\n    }\n\n    case FB_CS_STRING_1:\n    case FB_CS_STRING_N:\n    {\n      int64_t len = 1;\n      if (code == FB_CS_STRING_N) {\n        int err = fb_compact_unserialize_int64_from_buffer(len, buf, n, p);\n        if (err) {\n          return err;\n        }\n      }\n\n    CHECK_ENOUGH(len, p, n);\n      out = Variant::attach(StringData::Make(buf + p, len, CopyString));\n      p += len;\n      break;\n    }\n\n    case FB_CS_VECTOR:\n    {\n      Array arr = Array::CreateVArray();\n      while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n        Variant value;\n        int err = fb_compact_unserialize_from_buffer(value, buf, n, p);\n        if (err) {\n          return err;\n        }\n        arr.append(value);\n      }\n\n      // Consume STOP\n      CHECK_ENOUGH(1, p, n);\n      p += 1;\n\n      out = arr;\n      break;\n    }\n\n    case FB_CS_LIST_MAP:\n    {\n      Array arr = Array::CreateDArray();\n      int64_t i = 0;\n      while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n        if (buf[p] == (char)(kCodePrefix | FB_CS_SKIP)) {\n          ++i;\n          ++p;\n        } else {\n          Variant value;\n          int err = fb_compact_unserialize_from_buffer(value, buf, n, p);\n          if (err) {\n            return err;\n          }\n          arr.set(i++, value);\n        }\n      }\n\n      // Consume STOP\n      CHECK_ENOUGH(1, p, n);\n      p += 1;\n\n      out = arr;\n      break;\n    }\n\n    case FB_CS_MAP:\n    {\n      Array arr = Array::CreateDArray();\n      while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n        Variant key;\n        int err = fb_compact_unserialize_from_buffer(key, buf, n, p);\n        if (err) {\n          return err;\n        }\n        Variant value;\n        err = fb_compact_unserialize_from_buffer(value, buf, n, p);\n        if (err) {\n          return err;\n        }\n        if (key.getType() == KindOfInt64) {\n          arr.set(key.toInt64(), value);\n        } else if (key.getType() == KindOfString ||\n                   key.getType() == KindOfPersistentString) {\n          mapSetAndConvertStaticKeys(\n            arr, key.asStrRef().get(), std::move(value));\n        } else {\n          return FB_UNSERIALIZE_UNEXPECTED_ARRAY_KEY_TYPE;\n        }\n      }\n\n      // Consume STOP\n      CHECK_ENOUGH(1, p, n);\n      p += 1;\n\n      out = arr;\n      break;\n    }\n\n    default:\n      return FB_UNSERIALIZE_UNRECOGNIZED_OBJECT_TYPE;\n  }\n\n  return 0;\n}",
        "func": "int fb_compact_unserialize_from_buffer(\n    Variant& out, const char* buf, int n, int& p, size_t depth) {\n  if (UNLIKELY(depth > 1024)) {\n    return FB_UNSERIALIZE_MAX_DEPTH_EXCEEDED;\n  }\n\n  CHECK_ENOUGH(1, p, n);\n  int code = (unsigned char)buf[p];\n  if ((code & ~kCodeMask) != kCodePrefix ||\n      (code & kCodeMask) == FB_CS_INT16 ||\n      (code & kCodeMask) == FB_CS_INT32 ||\n      (code & kCodeMask) == FB_CS_INT64) {\n\n    int64_t val;\n    int err = fb_compact_unserialize_int64_from_buffer(val, buf, n, p);\n    if (err) {\n      return err;\n    }\n    out = (int64_t)val;\n    return 0;\n  }\n  p += 1;\n  code &= kCodeMask;\n  switch (code) {\n    case FB_CS_NULL:\n      out = uninit_null();\n      break;\n\n    case FB_CS_TRUE:\n      out = true;\n      break;\n\n    case FB_CS_FALSE:\n      out = false;\n      break;\n\n    case FB_CS_DOUBLE:\n    {\n      CHECK_ENOUGH(8, p, n);\n      double d = *reinterpret_cast<const double*>(buf + p);\n      p += 8;\n      out = d;\n      break;\n    }\n\n    case FB_CS_STRING_0:\n    {\n      out = s_empty;\n      break;\n    }\n\n    case FB_CS_STRING_1:\n    case FB_CS_STRING_N:\n    {\n      int64_t len = 1;\n      if (code == FB_CS_STRING_N) {\n        int err = fb_compact_unserialize_int64_from_buffer(len, buf, n, p);\n        if (err) {\n          return err;\n        }\n      }\n\n    CHECK_ENOUGH(len, p, n);\n      out = Variant::attach(StringData::Make(buf + p, len, CopyString));\n      p += len;\n      break;\n    }\n\n    case FB_CS_VECTOR:\n    {\n      Array arr = Array::CreateVArray();\n      while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n        Variant value;\n        int err =\n          fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);\n        if (err) {\n          return err;\n        }\n        arr.append(value);\n      }\n\n      // Consume STOP\n      CHECK_ENOUGH(1, p, n);\n      p += 1;\n\n      out = arr;\n      break;\n    }\n\n    case FB_CS_LIST_MAP:\n    {\n      Array arr = Array::CreateDArray();\n      int64_t i = 0;\n      while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n        if (buf[p] == (char)(kCodePrefix | FB_CS_SKIP)) {\n          ++i;\n          ++p;\n        } else {\n          Variant value;\n          int err =\n            fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);\n          if (err) {\n            return err;\n          }\n          arr.set(i++, value);\n        }\n      }\n\n      // Consume STOP\n      CHECK_ENOUGH(1, p, n);\n      p += 1;\n\n      out = arr;\n      break;\n    }\n\n    case FB_CS_MAP:\n    {\n      Array arr = Array::CreateDArray();\n      while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n        Variant key;\n        int err = fb_compact_unserialize_from_buffer(key, buf, n, p, depth + 1);\n        if (err) {\n          return err;\n        }\n        Variant value;\n        err = fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);\n        if (err) {\n          return err;\n        }\n        if (key.getType() == KindOfInt64) {\n          arr.set(key.toInt64(), value);\n        } else if (key.getType() == KindOfString ||\n                   key.getType() == KindOfPersistentString) {\n          mapSetAndConvertStaticKeys(\n            arr, key.asStrRef().get(), std::move(value));\n        } else {\n          return FB_UNSERIALIZE_UNEXPECTED_ARRAY_KEY_TYPE;\n        }\n      }\n\n      // Consume STOP\n      CHECK_ENOUGH(1, p, n);\n      p += 1;\n\n      out = arr;\n      break;\n    }\n\n    default:\n      return FB_UNSERIALIZE_UNRECOGNIZED_OBJECT_TYPE;\n  }\n\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n int fb_compact_unserialize_from_buffer(\n-  Variant& out, const char* buf, int n, int& p) {\n+    Variant& out, const char* buf, int n, int& p, size_t depth) {\n+  if (UNLIKELY(depth > 1024)) {\n+    return FB_UNSERIALIZE_MAX_DEPTH_EXCEEDED;\n+  }\n \n   CHECK_ENOUGH(1, p, n);\n   int code = (unsigned char)buf[p];\n@@ -68,7 +71,8 @@\n       Array arr = Array::CreateVArray();\n       while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n         Variant value;\n-        int err = fb_compact_unserialize_from_buffer(value, buf, n, p);\n+        int err =\n+          fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);\n         if (err) {\n           return err;\n         }\n@@ -93,7 +97,8 @@\n           ++p;\n         } else {\n           Variant value;\n-          int err = fb_compact_unserialize_from_buffer(value, buf, n, p);\n+          int err =\n+            fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);\n           if (err) {\n             return err;\n           }\n@@ -114,12 +119,12 @@\n       Array arr = Array::CreateDArray();\n       while (p < n && buf[p] != (char)(kCodePrefix | FB_CS_STOP)) {\n         Variant key;\n-        int err = fb_compact_unserialize_from_buffer(key, buf, n, p);\n+        int err = fb_compact_unserialize_from_buffer(key, buf, n, p, depth + 1);\n         if (err) {\n           return err;\n         }\n         Variant value;\n-        err = fb_compact_unserialize_from_buffer(value, buf, n, p);\n+        err = fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);\n         if (err) {\n           return err;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "  Variant& out, const char* buf, int n, int& p) {",
                "        int err = fb_compact_unserialize_from_buffer(value, buf, n, p);",
                "          int err = fb_compact_unserialize_from_buffer(value, buf, n, p);",
                "        int err = fb_compact_unserialize_from_buffer(key, buf, n, p);",
                "        err = fb_compact_unserialize_from_buffer(value, buf, n, p);"
            ],
            "added_lines": [
                "    Variant& out, const char* buf, int n, int& p, size_t depth) {",
                "  if (UNLIKELY(depth > 1024)) {",
                "    return FB_UNSERIALIZE_MAX_DEPTH_EXCEEDED;",
                "  }",
                "        int err =",
                "          fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);",
                "          int err =",
                "            fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);",
                "        int err = fb_compact_unserialize_from_buffer(key, buf, n, p, depth + 1);",
                "        err = fb_compact_unserialize_from_buffer(value, buf, n, p, depth + 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/moduleInit",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "void moduleInit() override {\n    HHVM_RC_BOOL_SAME(HHVM_FACEBOOK);\n    HHVM_RC_BOOL(HHVM_ONE_BIT_REFCOUNT, one_bit_refcount);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_NONSTRING_VALUE);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNEXPECTED_END);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNRECOGNIZED_OBJECT_TYPE);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNEXPECTED_ARRAY_KEY_TYPE);\n\n    HHVM_RC_INT(FB_SERIALIZE_HACK_ARRAYS, k_FB_SERIALIZE_HACK_ARRAYS);\n    HHVM_RC_INT(FB_SERIALIZE_VARRAY_DARRAY, k_FB_SERIALIZE_VARRAY_DARRAY);\n    HHVM_RC_INT(FB_SERIALIZE_HACK_ARRAYS_AND_KEYSETS,\n                k_FB_SERIALIZE_HACK_ARRAYS_AND_KEYSETS);\n\n    HHVM_FE(fb_serialize);\n    HHVM_FE(fb_unserialize);\n    HHVM_FE(fb_compact_serialize);\n    HHVM_FE(fb_compact_unserialize);\n    HHVM_FE(fb_utf8ize);\n    HHVM_FE(fb_utf8_strlen);\n    HHVM_FE(fb_utf8_strlen_deprecated);\n    HHVM_FE(fb_utf8_substr);\n    HHVM_FE(fb_intercept);\n    HHVM_FE(fb_intercept2);\n    HHVM_FE(fb_rename_function);\n    HHVM_FE(fb_get_code_coverage);\n    HHVM_FE(fb_enable_code_coverage);\n    HHVM_FE(fb_disable_code_coverage);\n    HHVM_FE(fb_output_compression);\n    HHVM_FE(fb_set_exit_callback);\n    HHVM_FE(fb_get_last_flush_size);\n    HHVM_FE(fb_lazy_lstat);\n    HHVM_FE(fb_lazy_realpath);\n\n    HHVM_FALIAS(HH\\\\disable_code_coverage_with_frequency,\n                HH_disable_code_coverage_with_frequency);\n    HHVM_FALIAS(HH\\\\non_crypto_md5_upper, HH_non_crypto_md5_upper);\n    HHVM_FALIAS(HH\\\\non_crypto_md5_lower, HH_non_crypto_md5_lower);\n    HHVM_FALIAS(HH\\\\int_mul_overflow, HH_int_mul_overflow);\n    HHVM_FALIAS(HH\\\\int_mul_add_overflow, HH_int_mul_add_overflow);\n\n    loadSystemlib();\n  }",
        "func": "void moduleInit() override {\n    HHVM_RC_BOOL_SAME(HHVM_FACEBOOK);\n    HHVM_RC_BOOL(HHVM_ONE_BIT_REFCOUNT, one_bit_refcount);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_NONSTRING_VALUE);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNEXPECTED_END);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNRECOGNIZED_OBJECT_TYPE);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNEXPECTED_ARRAY_KEY_TYPE);\n    HHVM_RC_INT_SAME(FB_UNSERIALIZE_MAX_DEPTH_EXCEEDED);\n\n    HHVM_RC_INT(FB_SERIALIZE_HACK_ARRAYS, k_FB_SERIALIZE_HACK_ARRAYS);\n    HHVM_RC_INT(FB_SERIALIZE_VARRAY_DARRAY, k_FB_SERIALIZE_VARRAY_DARRAY);\n    HHVM_RC_INT(FB_SERIALIZE_HACK_ARRAYS_AND_KEYSETS,\n                k_FB_SERIALIZE_HACK_ARRAYS_AND_KEYSETS);\n\n    HHVM_FE(fb_serialize);\n    HHVM_FE(fb_unserialize);\n    HHVM_FE(fb_compact_serialize);\n    HHVM_FE(fb_compact_unserialize);\n    HHVM_FE(fb_utf8ize);\n    HHVM_FE(fb_utf8_strlen);\n    HHVM_FE(fb_utf8_strlen_deprecated);\n    HHVM_FE(fb_utf8_substr);\n    HHVM_FE(fb_intercept);\n    HHVM_FE(fb_intercept2);\n    HHVM_FE(fb_rename_function);\n    HHVM_FE(fb_get_code_coverage);\n    HHVM_FE(fb_enable_code_coverage);\n    HHVM_FE(fb_disable_code_coverage);\n    HHVM_FE(fb_output_compression);\n    HHVM_FE(fb_set_exit_callback);\n    HHVM_FE(fb_get_last_flush_size);\n    HHVM_FE(fb_lazy_lstat);\n    HHVM_FE(fb_lazy_realpath);\n\n    HHVM_FALIAS(HH\\\\disable_code_coverage_with_frequency,\n                HH_disable_code_coverage_with_frequency);\n    HHVM_FALIAS(HH\\\\non_crypto_md5_upper, HH_non_crypto_md5_upper);\n    HHVM_FALIAS(HH\\\\non_crypto_md5_lower, HH_non_crypto_md5_lower);\n    HHVM_FALIAS(HH\\\\int_mul_overflow, HH_int_mul_overflow);\n    HHVM_FALIAS(HH\\\\int_mul_add_overflow, HH_int_mul_add_overflow);\n\n    loadSystemlib();\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n     HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNEXPECTED_END);\n     HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNRECOGNIZED_OBJECT_TYPE);\n     HHVM_RC_INT_SAME(FB_UNSERIALIZE_UNEXPECTED_ARRAY_KEY_TYPE);\n+    HHVM_RC_INT_SAME(FB_UNSERIALIZE_MAX_DEPTH_EXCEEDED);\n \n     HHVM_RC_INT(FB_SERIALIZE_HACK_ARRAYS, k_FB_SERIALIZE_HACK_ARRAYS);\n     HHVM_RC_INT(FB_SERIALIZE_VARRAY_DARRAY, k_FB_SERIALIZE_VARRAY_DARRAY);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    HHVM_RC_INT_SAME(FB_UNSERIALIZE_MAX_DEPTH_EXCEEDED);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-1898",
        "func_name": "facebook/hhvm/fb_compact_unserialize",
        "description": "The fb_unserialize function did not impose a depth limit for nested deserialization. That meant a maliciously constructed string could cause deserialization to recurse, leading to stack exhaustion. This issue affected HHVM prior to v4.32.3, between versions 4.33.0 and 4.56.0, 4.57.0, 4.58.0, 4.58.1, 4.59.0, 4.60.0, 4.61.0, 4.62.0.",
        "git_url": "https://github.com/facebook/hhvm/commit/1746dfb11fc0048366f34669e74318b8278a684c",
        "commit_title": "CVE-2020-1898",
        "commit_text": " Don't allow for unlimited nesting in FBUnserialize or fb_compact_unserialize",
        "func_before": "Variant fb_compact_unserialize(const char* str, int len,\n                               bool& success,\n                               Variant& errcode) {\n\n  Variant ret;\n  int p = 0;\n  int err = fb_compact_unserialize_from_buffer(ret, str, len, p);\n  if (err) {\n    success = false;\n    errcode = err;\n    return false;\n  }\n  success = true;\n  errcode = init_null();\n  return ret;\n}",
        "func": "Variant fb_compact_unserialize(const char* str, int len,\n                               bool& success,\n                               Variant& errcode) {\n\n  Variant ret;\n  int p = 0;\n  int err = fb_compact_unserialize_from_buffer(ret, str, len, p, 0);\n  if (err) {\n    success = false;\n    errcode = err;\n    return false;\n  }\n  success = true;\n  errcode = init_null();\n  return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \n   Variant ret;\n   int p = 0;\n-  int err = fb_compact_unserialize_from_buffer(ret, str, len, p);\n+  int err = fb_compact_unserialize_from_buffer(ret, str, len, p, 0);\n   if (err) {\n     success = false;\n     errcode = err;",
        "diff_line_info": {
            "deleted_lines": [
                "  int err = fb_compact_unserialize_from_buffer(ret, str, len, p);"
            ],
            "added_lines": [
                "  int err = fb_compact_unserialize_from_buffer(ret, str, len, p, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-23804",
        "func_name": "poppler/XRef::readXRefTable",
        "description": "Uncontrolled Recursion in pdfinfo, and pdftops in poppler 0.89.0 allows remote attackers to cause a denial of service via crafted input.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=ec8a43c8df29fdd6f1228276160898ccd9401c92",
        "commit_title": "The file is not malformed per se, it just has a huge XRefStm chain",
        "commit_text": "and we end up exhausting the stack space trying to parse them all.  Having more than 4096 XRefStm seems like won't really happen on real life so break the flow at that point  Fixes #936 ",
        "func_before": "bool XRef::readXRefTable(Parser *parser, Goffset *pos, std::vector<Goffset> *followedXRefStm, std::vector<int> *xrefStreamObjsNum)\n{\n    XRefEntry entry;\n    bool more;\n    Object obj, obj2;\n    Goffset pos2;\n    int first, n;\n\n    while (true) {\n        obj = parser->getObj(true);\n        if (obj.isCmd(\"trailer\")) {\n            break;\n        }\n        if (!obj.isInt()) {\n            goto err0;\n        }\n        first = obj.getInt();\n        obj = parser->getObj(true);\n        if (!obj.isInt()) {\n            goto err0;\n        }\n        n = obj.getInt();\n        if (first < 0 || n < 0 || first > INT_MAX - n) {\n            goto err0;\n        }\n        if (first + n > size) {\n            if (resize(first + n) != first + n) {\n                error(errSyntaxError, -1, \"Invalid 'obj' parameters'\");\n                goto err0;\n            }\n        }\n        for (int i = first; i < first + n; ++i) {\n            obj = parser->getObj(true);\n            if (obj.isInt()) {\n                entry.offset = obj.getInt();\n            } else if (obj.isInt64()) {\n                entry.offset = obj.getInt64();\n            } else {\n                goto err0;\n            }\n            obj = parser->getObj(true);\n            if (!obj.isInt()) {\n                goto err0;\n            }\n            entry.gen = obj.getInt();\n            entry.flags = 0;\n            obj = parser->getObj(true);\n            if (obj.isCmd(\"n\")) {\n                entry.type = xrefEntryUncompressed;\n            } else if (obj.isCmd(\"f\")) {\n                entry.type = xrefEntryFree;\n            } else {\n                goto err0;\n            }\n            if (entries[i].offset == -1) {\n                entries[i].offset = entry.offset;\n                entries[i].gen = entry.gen;\n                entries[i].type = entry.type;\n                entries[i].flags = entry.flags;\n                entries[i].obj.setToNull();\n\n                // PDF files of patents from the IBM Intellectual Property\n                // Network have a bug: the xref table claims to start at 1\n                // instead of 0.\n                if (i == 1 && first == 1 && entries[1].offset == 0 && entries[1].gen == 65535 && entries[1].type == xrefEntryFree) {\n                    i = first = 0;\n                    entries[0].offset = 0;\n                    entries[0].gen = 65535;\n                    entries[0].type = xrefEntryFree;\n                    entries[0].flags = entries[1].flags;\n                    entries[0].obj = std::move(entries[1].obj);\n\n                    entries[1].offset = -1;\n                    entries[1].obj.setToNull();\n                }\n            }\n        }\n    }\n\n    // read the trailer dictionary\n    obj = parser->getObj();\n    if (!obj.isDict()) {\n        goto err0;\n    }\n\n    // get the 'Prev' pointer\n    obj2 = obj.getDict()->lookupNF(\"Prev\").copy();\n    if (obj2.isInt() || obj2.isInt64()) {\n        if (obj2.isInt())\n            pos2 = obj2.getInt();\n        else\n            pos2 = obj2.getInt64();\n        if (pos2 != *pos) {\n            *pos = pos2;\n            more = true;\n        } else {\n            error(errSyntaxWarning, -1, \"Infinite loop in xref table\");\n            more = false;\n        }\n    } else if (obj2.isRef()) {\n        // certain buggy PDF generators generate \"/Prev NNN 0 R\" instead\n        // of \"/Prev NNN\"\n        pos2 = (unsigned int)obj2.getRefNum();\n        if (pos2 != *pos) {\n            *pos = pos2;\n            more = true;\n        } else {\n            error(errSyntaxWarning, -1, \"Infinite loop in xref table\");\n            more = false;\n        }\n    } else {\n        more = false;\n    }\n\n    // save the first trailer dictionary\n    if (trailerDict.isNone()) {\n        trailerDict = obj.copy();\n    }\n\n    // check for an 'XRefStm' key\n    obj2 = obj.getDict()->lookup(\"XRefStm\");\n    if (obj2.isInt() || obj2.isInt64()) {\n        if (obj2.isInt())\n            pos2 = obj2.getInt();\n        else\n            pos2 = obj2.getInt64();\n        for (size_t i = 0; ok == true && i < followedXRefStm->size(); ++i) {\n            if (followedXRefStm->at(i) == pos2) {\n                ok = false;\n            }\n        }\n        if (ok) {\n            followedXRefStm->push_back(pos2);\n            readXRef(&pos2, followedXRefStm, xrefStreamObjsNum);\n        }\n        if (!ok) {\n            goto err0;\n        }\n    }\n\n    return more;\n\nerr0:\n    ok = false;\n    return false;\n}",
        "func": "bool XRef::readXRefTable(Parser *parser, Goffset *pos, std::vector<Goffset> *followedXRefStm, std::vector<int> *xrefStreamObjsNum)\n{\n    XRefEntry entry;\n    bool more;\n    Object obj, obj2;\n    Goffset pos2;\n    int first, n;\n\n    while (true) {\n        obj = parser->getObj(true);\n        if (obj.isCmd(\"trailer\")) {\n            break;\n        }\n        if (!obj.isInt()) {\n            goto err0;\n        }\n        first = obj.getInt();\n        obj = parser->getObj(true);\n        if (!obj.isInt()) {\n            goto err0;\n        }\n        n = obj.getInt();\n        if (first < 0 || n < 0 || first > INT_MAX - n) {\n            goto err0;\n        }\n        if (first + n > size) {\n            if (resize(first + n) != first + n) {\n                error(errSyntaxError, -1, \"Invalid 'obj' parameters'\");\n                goto err0;\n            }\n        }\n        for (int i = first; i < first + n; ++i) {\n            obj = parser->getObj(true);\n            if (obj.isInt()) {\n                entry.offset = obj.getInt();\n            } else if (obj.isInt64()) {\n                entry.offset = obj.getInt64();\n            } else {\n                goto err0;\n            }\n            obj = parser->getObj(true);\n            if (!obj.isInt()) {\n                goto err0;\n            }\n            entry.gen = obj.getInt();\n            entry.flags = 0;\n            obj = parser->getObj(true);\n            if (obj.isCmd(\"n\")) {\n                entry.type = xrefEntryUncompressed;\n            } else if (obj.isCmd(\"f\")) {\n                entry.type = xrefEntryFree;\n            } else {\n                goto err0;\n            }\n            if (entries[i].offset == -1) {\n                entries[i].offset = entry.offset;\n                entries[i].gen = entry.gen;\n                entries[i].type = entry.type;\n                entries[i].flags = entry.flags;\n                entries[i].obj.setToNull();\n\n                // PDF files of patents from the IBM Intellectual Property\n                // Network have a bug: the xref table claims to start at 1\n                // instead of 0.\n                if (i == 1 && first == 1 && entries[1].offset == 0 && entries[1].gen == 65535 && entries[1].type == xrefEntryFree) {\n                    i = first = 0;\n                    entries[0].offset = 0;\n                    entries[0].gen = 65535;\n                    entries[0].type = xrefEntryFree;\n                    entries[0].flags = entries[1].flags;\n                    entries[0].obj = std::move(entries[1].obj);\n\n                    entries[1].offset = -1;\n                    entries[1].obj.setToNull();\n                }\n            }\n        }\n    }\n\n    // read the trailer dictionary\n    obj = parser->getObj();\n    if (!obj.isDict()) {\n        goto err0;\n    }\n\n    // get the 'Prev' pointer\n    obj2 = obj.getDict()->lookupNF(\"Prev\").copy();\n    if (obj2.isInt() || obj2.isInt64()) {\n        if (obj2.isInt())\n            pos2 = obj2.getInt();\n        else\n            pos2 = obj2.getInt64();\n        if (pos2 != *pos) {\n            *pos = pos2;\n            more = true;\n        } else {\n            error(errSyntaxWarning, -1, \"Infinite loop in xref table\");\n            more = false;\n        }\n    } else if (obj2.isRef()) {\n        // certain buggy PDF generators generate \"/Prev NNN 0 R\" instead\n        // of \"/Prev NNN\"\n        pos2 = (unsigned int)obj2.getRefNum();\n        if (pos2 != *pos) {\n            *pos = pos2;\n            more = true;\n        } else {\n            error(errSyntaxWarning, -1, \"Infinite loop in xref table\");\n            more = false;\n        }\n    } else {\n        more = false;\n    }\n\n    // save the first trailer dictionary\n    if (trailerDict.isNone()) {\n        trailerDict = obj.copy();\n    }\n\n    // check for an 'XRefStm' key\n    obj2 = obj.getDict()->lookup(\"XRefStm\");\n    if (obj2.isInt() || obj2.isInt64()) {\n        if (obj2.isInt())\n            pos2 = obj2.getInt();\n        else\n            pos2 = obj2.getInt64();\n        for (size_t i = 0; ok == true && i < followedXRefStm->size(); ++i) {\n            if (followedXRefStm->at(i) == pos2) {\n                ok = false;\n            }\n        }\n        // Arbitrary limit because otherwise we exhaust the stack\n        // calling readXRef + readXRefTable\n        if (followedXRefStm->size() > 4096) {\n            error(errSyntaxError, -1, \"File has more than 4096 XRefStm, aborting\");\n            ok = false;\n        }\n        if (ok) {\n            followedXRefStm->push_back(pos2);\n            readXRef(&pos2, followedXRefStm, xrefStreamObjsNum);\n        }\n        if (!ok) {\n            goto err0;\n        }\n    }\n\n    return more;\n\nerr0:\n    ok = false;\n    return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -129,6 +129,12 @@\n                 ok = false;\n             }\n         }\n+        // Arbitrary limit because otherwise we exhaust the stack\n+        // calling readXRef + readXRefTable\n+        if (followedXRefStm->size() > 4096) {\n+            error(errSyntaxError, -1, \"File has more than 4096 XRefStm, aborting\");\n+            ok = false;\n+        }\n         if (ok) {\n             followedXRefStm->push_back(pos2);\n             readXRef(&pos2, followedXRefStm, xrefStreamObjsNum);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        // Arbitrary limit because otherwise we exhaust the stack",
                "        // calling readXRef + readXRefTable",
                "        if (followedXRefStm->size() > 4096) {",
                "            error(errSyntaxError, -1, \"File has more than 4096 XRefStm, aborting\");",
                "            ok = false;",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4512",
        "func_name": "wireshark/dissect_cbor_byte_string",
        "description": "CBOR dissector crash in Wireshark 4.0.0 to 4.0.6 allows denial of service via packet injection or crafted capture file",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/76719d21eb1aff3ae8d2d4536d9dc118107631b4",
        "commit_title": "CBOR: Add a recursion check",
        "commit_text": " Fixes #19144 ",
        "func_before": "static gboolean\ndissect_cbor_byte_string(tvbuff_t *tvb, packet_info *pinfo, proto_tree *cbor_tree, gint *offset, guint8 type_minor)\n{\n\tguint64  length;\n\tgint     eof_type;\n\tproto_tree *subtree;\n\tproto_item *item;\n\n\titem = proto_tree_add_item(cbor_tree, hf_cbor_item_byte_string, tvb, *offset, -1, ENC_NA);\n\tsubtree = proto_item_add_subtree(item, ett_cbor_byte_string);\n\n\tproto_tree_add_item(subtree, hf_cbor_item_major_type, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\tif (type_minor <= 0x17) {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length5, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t\tlength = type_minor;\n\t} else {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length_size, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t}\n\t*offset += 1;\n\n\tswitch (type_minor) {\n\tcase 0x18:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 1, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 1;\n\t\tbreak;\n\tcase 0x19:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 2, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 2;\n\t\tbreak;\n\tcase 0x1a:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 4, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 4;\n\t\tbreak;\n\tcase 0x1b:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 8, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 8;\n\t\tbreak;\n\tcase 0x1f:\n\t\tproto_item_append_text(item, \": (indefinite length)\");\n\t\titem = proto_tree_add_item(subtree, hf_cbor_type_byte_string_indef, tvb, *offset, 1, ENC_NA);\n\t\tsubtree = proto_item_add_subtree(item, ett_cbor_byte_string_indef);\n\t\twhile (1) {\n\t\t\teof_type = tvb_get_guint8(tvb, *offset);\n\t\t\tif (eof_type == 0xff) {\n\t\t\t\tdissect_cbor_float_simple_data(tvb, pinfo, subtree, offset, 0x1f);\n\t\t\t\tproto_item_set_end(item, tvb, *offset);\n\t\t\t\treturn TRUE;\n\t\t\t}\n\n\t\t\tif (((eof_type & 0xe0) >> 5) != CBOR_TYPE_BYTE_STRING) {\n\t\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_element,\n\t\t\t\t\t\"invalid element %i, expected byte string\", (eof_type & 0xe0) >> 5);\n\t\t\t\treturn FALSE;\n\t\t\t}\n\n\t\t\tif (!dissect_cbor_byte_string(tvb, pinfo, subtree, offset, eof_type & 0x1f)) {\n\t\t\t\treturn FALSE;\n\t\t\t}\n\t\t}\n\t\tDISSECTOR_ASSERT_NOT_REACHED();\n\t\treturn FALSE;\n\tdefault:\n\t\tif (type_minor > 0x17) {\n\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_minor_type,\n\t\t\t\t\t\"invalid minor type %i in byte string\", type_minor);\n\t\t\treturn FALSE;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (length > G_MAXINT32 || *offset + (gint)length < *offset) {\n\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_too_long_length,\n\t\t\t\"the length (%\" PRIu64 \") of the byte string too long\", length);\n\t\treturn FALSE;\n\t}\n\n\tproto_tree_add_item(subtree, hf_cbor_type_byte_string, tvb, *offset, (gint)length, ENC_BIG_ENDIAN|ENC_NA);\n\t*offset += (gint)length;\n\n\tproto_item_append_text(item, \": (%\" PRIu64 \" byte%s)\", length, plurality(length, \"\", \"s\"));\n\tproto_item_set_end(item, tvb, *offset);\n\n\treturn TRUE;\n}",
        "func": "static gboolean\ndissect_cbor_byte_string(tvbuff_t *tvb, packet_info *pinfo, proto_tree *cbor_tree, gint *offset, guint8 type_minor)\n{\n\tguint64  length;\n\tgint     eof_type;\n\tproto_tree *subtree;\n\tproto_item *item;\n\n\titem = proto_tree_add_item(cbor_tree, hf_cbor_item_byte_string, tvb, *offset, -1, ENC_NA);\n\tsubtree = proto_item_add_subtree(item, ett_cbor_byte_string);\n\n\tproto_tree_add_item(subtree, hf_cbor_item_major_type, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\tif (type_minor <= 0x17) {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length5, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t\tlength = type_minor;\n\t} else {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length_size, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t}\n\t*offset += 1;\n\n\tswitch (type_minor) {\n\tcase 0x18:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 1, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 1;\n\t\tbreak;\n\tcase 0x19:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 2, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 2;\n\t\tbreak;\n\tcase 0x1a:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 4, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 4;\n\t\tbreak;\n\tcase 0x1b:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 8, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 8;\n\t\tbreak;\n\tcase 0x1f:\n\t\tproto_item_append_text(item, \": (indefinite length)\");\n\t\titem = proto_tree_add_item(subtree, hf_cbor_type_byte_string_indef, tvb, *offset, 1, ENC_NA);\n\t\tsubtree = proto_item_add_subtree(item, ett_cbor_byte_string_indef);\n\t\twhile (1) {\n\t\t\teof_type = tvb_get_guint8(tvb, *offset);\n\t\t\tif (eof_type == 0xff) {\n\t\t\t\tdissect_cbor_float_simple_data(tvb, pinfo, subtree, offset, 0x1f);\n\t\t\t\tproto_item_set_end(item, tvb, *offset);\n\t\t\t\treturn TRUE;\n\t\t\t}\n\n\t\t\tif (((eof_type & 0xe0) >> 5) != CBOR_TYPE_BYTE_STRING) {\n\t\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_element,\n\t\t\t\t\t\"invalid element %i, expected byte string\", (eof_type & 0xe0) >> 5);\n\t\t\t\treturn FALSE;\n\t\t\t}\n\n\t\t\tunsigned recursion_depth = p_get_proto_depth(pinfo, proto_cbor);\n\t\t\tif (++recursion_depth >= CBOR_MAX_RECURSION_DEPTH) {\n\t\t\t\tproto_tree_add_expert(subtree, pinfo, &ei_cbor_max_recursion_depth_reached, tvb, 0, 0);\n\t\t\t\treturn FALSE;\n\t\t\t}\n\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth);\n\n\t\t\tgboolean recursed = dissect_cbor_byte_string(tvb, pinfo, subtree, offset, eof_type & 0x1f);\n\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth - 1);\n\n\t\t\tif (!recursed) {\n\t\t\t\treturn FALSE;\n\t\t\t}\n\t\t}\n\t\tDISSECTOR_ASSERT_NOT_REACHED();\n\t\treturn FALSE;\n\tdefault:\n\t\tif (type_minor > 0x17) {\n\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_minor_type,\n\t\t\t\t\t\"invalid minor type %i in byte string\", type_minor);\n\t\t\treturn FALSE;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (length > G_MAXINT32 || *offset + (gint)length < *offset) {\n\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_too_long_length,\n\t\t\t\"the length (%\" PRIu64 \") of the byte string too long\", length);\n\t\treturn FALSE;\n\t}\n\n\tproto_tree_add_item(subtree, hf_cbor_type_byte_string, tvb, *offset, (gint)length, ENC_BIG_ENDIAN|ENC_NA);\n\t*offset += (gint)length;\n\n\tproto_item_append_text(item, \": (%\" PRIu64 \" byte%s)\", length, plurality(length, \"\", \"s\"));\n\tproto_item_set_end(item, tvb, *offset);\n\n\treturn TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -53,7 +53,17 @@\n \t\t\t\treturn FALSE;\n \t\t\t}\n \n-\t\t\tif (!dissect_cbor_byte_string(tvb, pinfo, subtree, offset, eof_type & 0x1f)) {\n+\t\t\tunsigned recursion_depth = p_get_proto_depth(pinfo, proto_cbor);\n+\t\t\tif (++recursion_depth >= CBOR_MAX_RECURSION_DEPTH) {\n+\t\t\t\tproto_tree_add_expert(subtree, pinfo, &ei_cbor_max_recursion_depth_reached, tvb, 0, 0);\n+\t\t\t\treturn FALSE;\n+\t\t\t}\n+\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth);\n+\n+\t\t\tgboolean recursed = dissect_cbor_byte_string(tvb, pinfo, subtree, offset, eof_type & 0x1f);\n+\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth - 1);\n+\n+\t\t\tif (!recursed) {\n \t\t\t\treturn FALSE;\n \t\t\t}\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (!dissect_cbor_byte_string(tvb, pinfo, subtree, offset, eof_type & 0x1f)) {"
            ],
            "added_lines": [
                "\t\t\tunsigned recursion_depth = p_get_proto_depth(pinfo, proto_cbor);",
                "\t\t\tif (++recursion_depth >= CBOR_MAX_RECURSION_DEPTH) {",
                "\t\t\t\tproto_tree_add_expert(subtree, pinfo, &ei_cbor_max_recursion_depth_reached, tvb, 0, 0);",
                "\t\t\t\treturn FALSE;",
                "\t\t\t}",
                "\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth);",
                "",
                "\t\t\tgboolean recursed = dissect_cbor_byte_string(tvb, pinfo, subtree, offset, eof_type & 0x1f);",
                "\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth - 1);",
                "",
                "\t\t\tif (!recursed) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4512",
        "func_name": "wireshark/dissect_cbor_text_string",
        "description": "CBOR dissector crash in Wireshark 4.0.0 to 4.0.6 allows denial of service via packet injection or crafted capture file",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/76719d21eb1aff3ae8d2d4536d9dc118107631b4",
        "commit_title": "CBOR: Add a recursion check",
        "commit_text": " Fixes #19144 ",
        "func_before": "static gboolean\ndissect_cbor_text_string(tvbuff_t *tvb, packet_info *pinfo, proto_tree *cbor_tree, gint *offset, guint8 type_minor)\n{\n\tconst guint8 *value = NULL;\n\tguint64  length = 0;\n\tgint     eof_type;\n\tproto_tree *subtree;\n\tproto_item *item;\n\n\titem = proto_tree_add_item(cbor_tree, hf_cbor_item_text_string, tvb, *offset, -1, ENC_NA);\n\tsubtree = proto_item_add_subtree(item, ett_cbor_text_string);\n\n\tproto_tree_add_item(subtree, hf_cbor_item_major_type, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\tif (type_minor <= 0x17) {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length5, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t\tlength = type_minor;\n\t} else {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length_size, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t}\n\t*offset += 1;\n\n\tswitch (type_minor) {\n\tcase 0x18:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 1, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 1;\n\t\tbreak;\n\tcase 0x19:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 2, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 2;\n\t\tbreak;\n\tcase 0x1a:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 4, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 4;\n\t\tbreak;\n\tcase 0x1b:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 8, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 8;\n\t\tbreak;\n\tcase 0x1f:\n\t\tproto_item_append_text(item, \": (indefinite length)\");\n\t\titem = proto_tree_add_item(subtree, hf_cbor_type_text_string_indef, tvb, *offset, 1, ENC_NA);\n\t\tsubtree = proto_item_add_subtree(item, ett_cbor_text_string_indef);\n\t\twhile (1) {\n\t\t\teof_type = tvb_get_guint8(tvb, *offset);\n\t\t\tif (eof_type == 0xff) {\n\t\t\t\tdissect_cbor_float_simple_data(tvb, pinfo, subtree, offset, 0x1f);\n\t\t\t\tproto_item_set_end(item, tvb, *offset);\n\t\t\t\treturn TRUE;\n\t\t\t}\n\n\t\t\tif (((eof_type & 0xe0) >> 5) != CBOR_TYPE_TEXT_STRING) {\n\t\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_element,\n\t\t\t\t\t\"invalid element %i, expected text string\", (eof_type & 0xe0) >> 5);\n\t\t\t\treturn FALSE;\n\t\t\t}\n\n\t\t\tif (!dissect_cbor_text_string(tvb, pinfo, subtree, offset, eof_type & 0x1f)) {\n\t\t\t\treturn FALSE;\n\t\t\t}\n\t\t}\n\t\tDISSECTOR_ASSERT_NOT_REACHED();\n\t\treturn FALSE;\n\tdefault:\n\t\tif (type_minor > 0x17) {\n\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_minor_type,\n\t\t\t\t\t\"invalid minor type %i in text string\", type_minor);\n\t\t\treturn FALSE;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (length > G_MAXINT32 || *offset + (gint)length < *offset) {\n\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_too_long_length,\n\t\t\t\"the length (%\" PRIu64 \") of the text string too long\", length);\n\t\treturn FALSE;\n\t}\n\n\tproto_tree_add_item_ret_string(subtree, hf_cbor_type_text_string, tvb, *offset, (gint)length, ENC_BIG_ENDIAN|ENC_UTF_8, pinfo->pool, &value);\n\t*offset += (gint)length;\n\n\tproto_item_append_text(item, \": %s\", value);\n\tproto_item_set_end(item, tvb, *offset);\n\n\treturn TRUE;\n}",
        "func": "static gboolean\ndissect_cbor_text_string(tvbuff_t *tvb, packet_info *pinfo, proto_tree *cbor_tree, gint *offset, guint8 type_minor)\n{\n\tconst guint8 *value = NULL;\n\tguint64  length = 0;\n\tgint     eof_type;\n\tproto_tree *subtree;\n\tproto_item *item;\n\n\titem = proto_tree_add_item(cbor_tree, hf_cbor_item_text_string, tvb, *offset, -1, ENC_NA);\n\tsubtree = proto_item_add_subtree(item, ett_cbor_text_string);\n\n\tproto_tree_add_item(subtree, hf_cbor_item_major_type, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\tif (type_minor <= 0x17) {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length5, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t\tlength = type_minor;\n\t} else {\n\t\tproto_tree_add_item(subtree, hf_cbor_item_length_size, tvb, *offset, 1, ENC_BIG_ENDIAN);\n\t}\n\t*offset += 1;\n\n\tswitch (type_minor) {\n\tcase 0x18:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 1, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 1;\n\t\tbreak;\n\tcase 0x19:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 2, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 2;\n\t\tbreak;\n\tcase 0x1a:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 4, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 4;\n\t\tbreak;\n\tcase 0x1b:\n\t\tproto_tree_add_item_ret_uint64(subtree, hf_cbor_item_length, tvb, *offset, 8, ENC_BIG_ENDIAN, &length);\n\t\t*offset += 8;\n\t\tbreak;\n\tcase 0x1f:\n\t\tproto_item_append_text(item, \": (indefinite length)\");\n\t\titem = proto_tree_add_item(subtree, hf_cbor_type_text_string_indef, tvb, *offset, 1, ENC_NA);\n\t\tsubtree = proto_item_add_subtree(item, ett_cbor_text_string_indef);\n\t\twhile (1) {\n\t\t\teof_type = tvb_get_guint8(tvb, *offset);\n\t\t\tif (eof_type == 0xff) {\n\t\t\t\tdissect_cbor_float_simple_data(tvb, pinfo, subtree, offset, 0x1f);\n\t\t\t\tproto_item_set_end(item, tvb, *offset);\n\t\t\t\treturn TRUE;\n\t\t\t}\n\n\t\t\tif (((eof_type & 0xe0) >> 5) != CBOR_TYPE_TEXT_STRING) {\n\t\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_element,\n\t\t\t\t\t\"invalid element %i, expected text string\", (eof_type & 0xe0) >> 5);\n\t\t\t\treturn FALSE;\n\t\t\t}\n\n\t\t\tunsigned recursion_depth = p_get_proto_depth(pinfo, proto_cbor);\n\t\t\tif (++recursion_depth >= CBOR_MAX_RECURSION_DEPTH) {\n\t\t\t\tproto_tree_add_expert(subtree, pinfo, &ei_cbor_max_recursion_depth_reached, tvb, 0, 0);\n\t\t\t\treturn FALSE;\n\t\t\t}\n\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth);\n\n\t\t\tgboolean recursed = dissect_cbor_text_string(tvb, pinfo, subtree, offset, eof_type & 0x1f);\n\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth - 1);\n\n\t\t\tif (!recursed) {\n\t\t\t\treturn FALSE;\n\t\t\t}\n\t\t}\n\t\tDISSECTOR_ASSERT_NOT_REACHED();\n\t\treturn FALSE;\n\tdefault:\n\t\tif (type_minor > 0x17) {\n\t\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_invalid_minor_type,\n\t\t\t\t\t\"invalid minor type %i in text string\", type_minor);\n\t\t\treturn FALSE;\n\t\t}\n\t\tbreak;\n\t}\n\n\tif (length > G_MAXINT32 || *offset + (gint)length < *offset) {\n\t\texpert_add_info_format(pinfo, subtree, &ei_cbor_too_long_length,\n\t\t\t\"the length (%\" PRIu64 \") of the text string too long\", length);\n\t\treturn FALSE;\n\t}\n\n\tproto_tree_add_item_ret_string(subtree, hf_cbor_type_text_string, tvb, *offset, (gint)length, ENC_BIG_ENDIAN|ENC_UTF_8, pinfo->pool, &value);\n\t*offset += (gint)length;\n\n\tproto_item_append_text(item, \": %s\", value);\n\tproto_item_set_end(item, tvb, *offset);\n\n\treturn TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,7 +54,17 @@\n \t\t\t\treturn FALSE;\n \t\t\t}\n \n-\t\t\tif (!dissect_cbor_text_string(tvb, pinfo, subtree, offset, eof_type & 0x1f)) {\n+\t\t\tunsigned recursion_depth = p_get_proto_depth(pinfo, proto_cbor);\n+\t\t\tif (++recursion_depth >= CBOR_MAX_RECURSION_DEPTH) {\n+\t\t\t\tproto_tree_add_expert(subtree, pinfo, &ei_cbor_max_recursion_depth_reached, tvb, 0, 0);\n+\t\t\t\treturn FALSE;\n+\t\t\t}\n+\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth);\n+\n+\t\t\tgboolean recursed = dissect_cbor_text_string(tvb, pinfo, subtree, offset, eof_type & 0x1f);\n+\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth - 1);\n+\n+\t\t\tif (!recursed) {\n \t\t\t\treturn FALSE;\n \t\t\t}\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (!dissect_cbor_text_string(tvb, pinfo, subtree, offset, eof_type & 0x1f)) {"
            ],
            "added_lines": [
                "\t\t\tunsigned recursion_depth = p_get_proto_depth(pinfo, proto_cbor);",
                "\t\t\tif (++recursion_depth >= CBOR_MAX_RECURSION_DEPTH) {",
                "\t\t\t\tproto_tree_add_expert(subtree, pinfo, &ei_cbor_max_recursion_depth_reached, tvb, 0, 0);",
                "\t\t\t\treturn FALSE;",
                "\t\t\t}",
                "\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth);",
                "",
                "\t\t\tgboolean recursed = dissect_cbor_text_string(tvb, pinfo, subtree, offset, eof_type & 0x1f);",
                "\t\t\tp_set_proto_depth(pinfo, proto_cbor, recursion_depth - 1);",
                "",
                "\t\t\tif (!recursed) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4512",
        "func_name": "wireshark/proto_register_cbor",
        "description": "CBOR dissector crash in Wireshark 4.0.0 to 4.0.6 allows denial of service via packet injection or crafted capture file",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/76719d21eb1aff3ae8d2d4536d9dc118107631b4",
        "commit_title": "CBOR: Add a recursion check",
        "commit_text": " Fixes #19144 ",
        "func_before": "void\nproto_register_cbor(void)\n{\n\tstatic hf_register_info hf[] = {\n\t\t{ &hf_cbor_item_major_type,\n\t\t  { \"Major Type\", \"cbor.item.major_type\",\n\t\t    FT_UINT8, BASE_DEC, VALS(major_type_vals), 0xe0,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_integer_size,\n\t\t  { \"Size\", \"cbor.item.size\",\n\t\t    FT_UINT8, BASE_DEC, VALS(integer_size_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_length_size,\n\t\t  { \"Size\", \"cbor.item.size\",\n\t\t    FT_UINT8, BASE_DEC, VALS(length_size_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_length5,\n\t\t  { \"Length\", \"cbor.item.length5\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_length,\n\t\t  { \"Length\", \"cbor.item.length\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_items5,\n\t\t  { \"Items\", \"cbor.item.items5\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_items,\n\t\t  { \"Items\", \"cbor.item.items\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_pairs5,\n\t\t  { \"Pairs\", \"cbor.item.pairs\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_pairs,\n\t\t  { \"Pairs\", \"cbor.item.pairs\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_float_simple_type,\n\t\t  { \"Type\", \"cbor.item.float_simple_type\",\n\t\t    FT_UINT8, BASE_DEC, VALS(float_simple_type_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_unsigned_integer,\n\t\t  { \"Unsigned Integer\", \"cbor.item.unsigned_integer\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_negative_integer,\n\t\t  { \"Negative Integer\", \"cbor.item.negative_integer\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_text_string,\n\t\t  { \"Text String\", \"cbor.item.textstring\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_byte_string,\n\t\t  { \"Byte String\", \"cbor.item.bytestring\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_array,\n\t\t  { \"Array\", \"cbor.item.array\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_map,\n\t\t  { \"Map\", \"cbor.item.map\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_tag,\n\t\t  { \"Tag\", \"cbor.item.tag\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_float_simple,\n\t\t  { \"Floating-point or Simple\", \"cbor.item.float_or_simple\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_uint5,\n\t\t  { \"Unsigned Integer\", \"cbor.type.uint\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_uint,\n\t\t  { \"Unsigned Integer\", \"cbor.type.uint\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_nint,\n\t\t  { \"Negative Integer\", \"cbor.type.nint\",\n\t\t    FT_INT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_byte_string,\n\t\t  { \"Byte String\", \"cbor.type.bytestring\",\n\t\t    FT_BYTES, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_byte_string_indef,\n\t\t  { \"Byte String (indefinite length)\", \"cbor.type.bytestring.indef\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x0,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_text_string,\n\t\t  { \"Text String\", \"cbor.type.textstring\",\n\t\t    FT_STRING, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_text_string_indef,\n\t\t  { \"Text String (indefinite length)\", \"cbor.type.textstring.indef\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x0,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_tag5,\n\t\t  { \"Tag\", \"cbor.type.tag\",\n\t\t    FT_UINT8, BASE_DEC, VALS(tag32_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_tag,\n\t\t  { \"Tag\", \"cbor.type.tag\",\n\t\t    FT_UINT64, BASE_DEC|BASE_VAL64_STRING, VALS64(tag64_vals), 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_simple_data5,\n\t\t  { \"Simple data\", \"cbor.type.simple_data\",\n\t\t    FT_UINT8, BASE_DEC, VALS(vals_simple_data), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_simple_data8,\n\t\t  { \"Simple data\", \"cbor.type.simple_data\",\n\t\t    FT_UINT8, BASE_DEC, VALS(vals_simple_data), 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_float16,\n\t\t  { \"Float 16 Bit\", \"cbor.type.float16\",\n\t\t    FT_FLOAT, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_float32,\n\t\t  { \"Float 32 Bit\", \"cbor.type.float32\",\n\t\t    FT_FLOAT, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_float64,\n\t\t  { \"Float 64 Bit\", \"cbor.type.float64\",\n\t\t    FT_DOUBLE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t};\n\n\tstatic gint *ett[] = {\n\t\t&ett_cbor,\n\t\t&ett_cbor_type,\n\t\t&ett_cbor_unsigned_integer,\n\t\t&ett_cbor_negative_integer,\n\t\t&ett_cbor_byte_string,\n\t\t&ett_cbor_byte_string_indef,\n\t\t&ett_cbor_text_string,\n\t\t&ett_cbor_text_string_indef,\n\t\t&ett_cbor_array,\n\t\t&ett_cbor_map,\n\t\t&ett_cbor_tag,\n\t\t&ett_cbor_float_simple\n\t};\n\n\tstatic ei_register_info ei[] = {\n\t\t{ &ei_cbor_invalid_minor_type,\n\t\t  { \"cbor.invalid_minor_type\", PI_MALFORMED, PI_WARN, \"Invalid minor type\", EXPFILL }},\n\t\t{ &ei_cbor_invalid_element,\n\t\t  { \"cbor.invalid_element\", PI_MALFORMED, PI_WARN, \"Invalid element\", EXPFILL }},\n\t\t{ &ei_cbor_too_long_length,\n\t\t  { \"cbor.too_long_length\", PI_MALFORMED, PI_WARN, \"Too long length\", EXPFILL }},\n\t};\n\n\texpert_module_t *expert_cbor;\n\n\tproto_cbor = proto_register_protocol(\"Concise Binary Object Representation\", \"CBOR\", \"cbor\");\n\tproto_register_field_array(proto_cbor, hf, array_length(hf));\n\tproto_register_subtree_array(ett, array_length(ett));\n\texpert_cbor = expert_register_protocol(proto_cbor);\n\texpert_register_field_array(expert_cbor, ei, array_length(ei));\n\n\tcbor_handle = register_dissector(\"cbor\", dissect_cbor, proto_cbor);\n\tcborseq_handle = register_dissector(\"cborseq\", dissect_cborseq, proto_cbor);\n}",
        "func": "void\nproto_register_cbor(void)\n{\n\tstatic hf_register_info hf[] = {\n\t\t{ &hf_cbor_item_major_type,\n\t\t  { \"Major Type\", \"cbor.item.major_type\",\n\t\t    FT_UINT8, BASE_DEC, VALS(major_type_vals), 0xe0,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_integer_size,\n\t\t  { \"Size\", \"cbor.item.size\",\n\t\t    FT_UINT8, BASE_DEC, VALS(integer_size_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_length_size,\n\t\t  { \"Size\", \"cbor.item.size\",\n\t\t    FT_UINT8, BASE_DEC, VALS(length_size_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_length5,\n\t\t  { \"Length\", \"cbor.item.length5\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_length,\n\t\t  { \"Length\", \"cbor.item.length\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_items5,\n\t\t  { \"Items\", \"cbor.item.items5\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_items,\n\t\t  { \"Items\", \"cbor.item.items\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_pairs5,\n\t\t  { \"Pairs\", \"cbor.item.pairs\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_pairs,\n\t\t  { \"Pairs\", \"cbor.item.pairs\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_float_simple_type,\n\t\t  { \"Type\", \"cbor.item.float_simple_type\",\n\t\t    FT_UINT8, BASE_DEC, VALS(float_simple_type_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_unsigned_integer,\n\t\t  { \"Unsigned Integer\", \"cbor.item.unsigned_integer\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_negative_integer,\n\t\t  { \"Negative Integer\", \"cbor.item.negative_integer\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_text_string,\n\t\t  { \"Text String\", \"cbor.item.textstring\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_byte_string,\n\t\t  { \"Byte String\", \"cbor.item.bytestring\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_array,\n\t\t  { \"Array\", \"cbor.item.array\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_map,\n\t\t  { \"Map\", \"cbor.item.map\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_tag,\n\t\t  { \"Tag\", \"cbor.item.tag\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_item_float_simple,\n\t\t  { \"Floating-point or Simple\", \"cbor.item.float_or_simple\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_uint5,\n\t\t  { \"Unsigned Integer\", \"cbor.type.uint\",\n\t\t    FT_UINT8, BASE_DEC, NULL, 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_uint,\n\t\t  { \"Unsigned Integer\", \"cbor.type.uint\",\n\t\t    FT_UINT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_nint,\n\t\t  { \"Negative Integer\", \"cbor.type.nint\",\n\t\t    FT_INT64, BASE_DEC, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_byte_string,\n\t\t  { \"Byte String\", \"cbor.type.bytestring\",\n\t\t    FT_BYTES, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_byte_string_indef,\n\t\t  { \"Byte String (indefinite length)\", \"cbor.type.bytestring.indef\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x0,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_text_string,\n\t\t  { \"Text String\", \"cbor.type.textstring\",\n\t\t    FT_STRING, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_text_string_indef,\n\t\t  { \"Text String (indefinite length)\", \"cbor.type.textstring.indef\",\n\t\t    FT_NONE, BASE_NONE, NULL, 0x0,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_tag5,\n\t\t  { \"Tag\", \"cbor.type.tag\",\n\t\t    FT_UINT8, BASE_DEC, VALS(tag32_vals), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_tag,\n\t\t  { \"Tag\", \"cbor.type.tag\",\n\t\t    FT_UINT64, BASE_DEC|BASE_VAL64_STRING, VALS64(tag64_vals), 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_simple_data5,\n\t\t  { \"Simple data\", \"cbor.type.simple_data\",\n\t\t    FT_UINT8, BASE_DEC, VALS(vals_simple_data), 0x1f,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_simple_data8,\n\t\t  { \"Simple data\", \"cbor.type.simple_data\",\n\t\t    FT_UINT8, BASE_DEC, VALS(vals_simple_data), 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_float16,\n\t\t  { \"Float 16 Bit\", \"cbor.type.float16\",\n\t\t    FT_FLOAT, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_float32,\n\t\t  { \"Float 32 Bit\", \"cbor.type.float32\",\n\t\t    FT_FLOAT, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t\t{ &hf_cbor_type_float64,\n\t\t  { \"Float 64 Bit\", \"cbor.type.float64\",\n\t\t    FT_DOUBLE, BASE_NONE, NULL, 0x00,\n\t\t    NULL, HFILL }\n\t\t},\n\t};\n\n\tstatic gint *ett[] = {\n\t\t&ett_cbor,\n\t\t&ett_cbor_type,\n\t\t&ett_cbor_unsigned_integer,\n\t\t&ett_cbor_negative_integer,\n\t\t&ett_cbor_byte_string,\n\t\t&ett_cbor_byte_string_indef,\n\t\t&ett_cbor_text_string,\n\t\t&ett_cbor_text_string_indef,\n\t\t&ett_cbor_array,\n\t\t&ett_cbor_map,\n\t\t&ett_cbor_tag,\n\t\t&ett_cbor_float_simple\n\t};\n\n\tstatic ei_register_info ei[] = {\n\t\t{ &ei_cbor_invalid_minor_type,\n\t\t  { \"cbor.invalid_minor_type\", PI_MALFORMED, PI_WARN, \"Invalid minor type\", EXPFILL }},\n\t\t{ &ei_cbor_invalid_element,\n\t\t  { \"cbor.invalid_element\", PI_MALFORMED, PI_WARN, \"Invalid element\", EXPFILL }},\n\t\t{ &ei_cbor_too_long_length,\n\t\t  { \"cbor.too_long_length\", PI_MALFORMED, PI_WARN, \"Too long length\", EXPFILL }},\n\t\t{ &ei_cbor_max_recursion_depth_reached,\n\t\t  { \"cbor.max_recursion_depth_reached\", PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached. Dissection stopped.\", EXPFILL }},\n\t};\n\n\texpert_module_t *expert_cbor;\n\n\tproto_cbor = proto_register_protocol(\"Concise Binary Object Representation\", \"CBOR\", \"cbor\");\n\tproto_register_field_array(proto_cbor, hf, array_length(hf));\n\tproto_register_subtree_array(ett, array_length(ett));\n\texpert_cbor = expert_register_protocol(proto_cbor);\n\texpert_register_field_array(expert_cbor, ei, array_length(ei));\n\n\tcbor_handle = register_dissector(\"cbor\", dissect_cbor, proto_cbor);\n\tcborseq_handle = register_dissector(\"cborseq\", dissect_cborseq, proto_cbor);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -186,6 +186,8 @@\n \t\t  { \"cbor.invalid_element\", PI_MALFORMED, PI_WARN, \"Invalid element\", EXPFILL }},\n \t\t{ &ei_cbor_too_long_length,\n \t\t  { \"cbor.too_long_length\", PI_MALFORMED, PI_WARN, \"Too long length\", EXPFILL }},\n+\t\t{ &ei_cbor_max_recursion_depth_reached,\n+\t\t  { \"cbor.max_recursion_depth_reached\", PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached. Dissection stopped.\", EXPFILL }},\n \t};\n \n \texpert_module_t *expert_cbor;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t{ &ei_cbor_max_recursion_depth_reached,",
                "\t\t  { \"cbor.max_recursion_depth_reached\", PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached. Dissection stopped.\", EXPFILL }},"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-9918",
        "func_name": "qpdf/QPDFObjectHandle::parseInternal",
        "description": "libqpdf.a in QPDF through 8.0.2 mishandles certain \"expected dictionary key but found non-name object\" cases, allowing remote attackers to cause a denial of service (stack exhaustion), related to the QPDFObjectHandle and QPDF_Dictionary classes, because nesting in direct objects is not restricted.",
        "git_url": "https://github.com/qpdf/qpdf/commit/b4d6cf6836ce025ba1811b7bbec52680c7204223",
        "commit_title": "Limit depth of nesting in direct objects (fixes #202)",
        "commit_text": " This fixes CVE-2018-9918.",
        "func_before": "QPDFObjectHandle\nQPDFObjectHandle::parseInternal(PointerHolder<InputSource> input,\n                                std::string const& object_description,\n                                QPDFTokenizer& tokenizer, bool& empty,\n                                StringDecrypter* decrypter, QPDF* context,\n                                bool content_stream)\n{\n    // This method must take care not to resolve any objects. Don't\n    // check the type of any object without first ensuring that it is\n    // a direct object. Otherwise, doing so may have the side effect\n    // of reading the object and changing the file pointer.\n\n    empty = false;\n\n    QPDFObjectHandle object;\n\n    std::vector<std::vector<QPDFObjectHandle> > olist_stack;\n    olist_stack.push_back(std::vector<QPDFObjectHandle>());\n    std::vector<parser_state_e> state_stack;\n    state_stack.push_back(st_top);\n    std::vector<qpdf_offset_t> offset_stack;\n    qpdf_offset_t offset = input->tell();\n    offset_stack.push_back(offset);\n    bool done = false;\n    while (! done)\n    {\n        std::vector<QPDFObjectHandle>& olist = olist_stack.back();\n        parser_state_e state = state_stack.back();\n        offset = offset_stack.back();\n\n\tobject = QPDFObjectHandle();\n\n\tQPDFTokenizer::Token token =\n            tokenizer.readToken(input, object_description, true);\n\n\tswitch (token.getType())\n\t{\n          case QPDFTokenizer::tt_eof:\n            if (! content_stream)\n            {\n                QTC::TC(\"qpdf\", \"QPDFObjectHandle eof in parseInternal\");\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"unexpected EOF\"));\n            }\n            state = st_eof;\n            break;\n\n          case QPDFTokenizer::tt_bad:\n\t    QTC::TC(\"qpdf\", \"QPDFObjectHandle bad token in parse\");\n            warn(context,\n                 QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                         object_description,\n                         input->getLastOffset(),\n                         token.getErrorMessage()));\n            object = newNull();\n\t    break;\n\n\t  case QPDFTokenizer::tt_brace_open:\n\t  case QPDFTokenizer::tt_brace_close:\n\t    QTC::TC(\"qpdf\", \"QPDFObjectHandle bad brace\");\n            warn(context,\n                 QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                         object_description,\n                         input->getLastOffset(),\n                         \"treating unexpected brace token as null\"));\n            object = newNull();\n\t    break;\n\n\t  case QPDFTokenizer::tt_array_close:\n\t    if (state == st_array)\n\t    {\n                state = st_stop;\n\t    }\n\t    else\n\t    {\n\t\tQTC::TC(\"qpdf\", \"QPDFObjectHandle bad array close\");\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"treating unexpected array close token as null\"));\n                object = newNull();\n\t    }\n\t    break;\n\n\t  case QPDFTokenizer::tt_dict_close:\n\t    if (state == st_dictionary)\n\t    {\n                state = st_stop;\n\t    }\n\t    else\n\t    {\n\t\tQTC::TC(\"qpdf\", \"QPDFObjectHandle bad dictionary close\");\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"unexpected dictionary close token\"));\n                object = newNull();\n\t    }\n\t    break;\n\n\t  case QPDFTokenizer::tt_array_open:\n\t  case QPDFTokenizer::tt_dict_open:\n            olist_stack.push_back(std::vector<QPDFObjectHandle>());\n            state = st_start;\n            offset_stack.push_back(input->tell());\n            state_stack.push_back(\n                (token.getType() == QPDFTokenizer::tt_array_open) ?\n                st_array : st_dictionary);\n\t    break;\n\n\t  case QPDFTokenizer::tt_bool:\n\t    object = newBool((token.getValue() == \"true\"));\n\t    break;\n\n\t  case QPDFTokenizer::tt_null:\n\t    object = newNull();\n\t    break;\n\n\t  case QPDFTokenizer::tt_integer:\n\t    object = newInteger(QUtil::string_to_ll(token.getValue().c_str()));\n\t    break;\n\n\t  case QPDFTokenizer::tt_real:\n\t    object = newReal(token.getValue());\n\t    break;\n\n\t  case QPDFTokenizer::tt_name:\n\t    object = newName(token.getValue());\n\t    break;\n\n\t  case QPDFTokenizer::tt_word:\n\t    {\n\t\tstd::string const& value = token.getValue();\n                if (content_stream)\n                {\n                    object = QPDFObjectHandle::newOperator(value);\n                }\n\t\telse if ((value == \"R\") && (state != st_top) &&\n                         (olist.size() >= 2) &&\n                         (! olist.at(olist.size() - 1).isIndirect()) &&\n                         (olist.at(olist.size() - 1).isInteger()) &&\n                         (! olist.at(olist.size() - 2).isIndirect()) &&\n                         (olist.at(olist.size() - 2).isInteger()))\n\t\t{\n                    if (context == 0)\n                    {\n                        QTC::TC(\"qpdf\", \"QPDFObjectHandle indirect without context\");\n                        throw std::logic_error(\n                            \"QPDFObjectHandle::parse called without context\"\n                            \" on an object with indirect references\");\n                    }\n\t\t    // Try to resolve indirect objects\n\t\t    object = newIndirect(\n\t\t\tcontext,\n\t\t\tolist.at(olist.size() - 2).getIntValue(),\n\t\t\tolist.at(olist.size() - 1).getIntValue());\n\t\t    olist.pop_back();\n\t\t    olist.pop_back();\n\t\t}\n\t\telse if ((value == \"endobj\") && (state == st_top))\n\t\t{\n\t\t    // We just saw endobj without having read\n\t\t    // anything.  Treat this as a null and do not move\n\t\t    // the input source's offset.\n\t\t    object = newNull();\n\t\t    input->seek(input->getLastOffset(), SEEK_SET);\n                    empty = true;\n\t\t}\n\t\telse\n\t\t{\n                    QTC::TC(\"qpdf\", \"QPDFObjectHandle treat word as string\");\n                    warn(context,\n                         QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                                 object_description,\n                                 input->getLastOffset(),\n                                 \"unknown token while reading object;\"\n                                 \" treating as string\"));\n                    object = newString(value);\n\t\t}\n\t    }\n\t    break;\n\n\t  case QPDFTokenizer::tt_string:\n\t    {\n\t\tstd::string val = token.getValue();\n                if (decrypter)\n                {\n                    decrypter->decryptString(val);\n                }\n\t\tobject = QPDFObjectHandle::newString(val);\n\t    }\n\n\t    break;\n\n\t  default:\n            warn(context,\n                 QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                         object_description,\n                         input->getLastOffset(),\n                         \"treating unknown token type as null while \"\n                         \"reading object\"));\n            object = newNull();\n\t    break;\n\t}\n\n        if ((! object.isInitialized()) &&\n            (! ((state == st_start) ||\n                (state == st_stop) ||\n                (state == st_eof))))\n        {\n            throw std::logic_error(\n                \"QPDFObjectHandle::parseInternal: \"\n                \"unexpected uninitialized object\");\n            object = newNull();\n        }\n\n        switch (state)\n        {\n          case st_eof:\n            if (state_stack.size() > 1)\n            {\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"parse error while reading object\"));\n            }\n            done = true;\n            // In content stream mode, leave object uninitialized to\n            // indicate EOF\n            if (! content_stream)\n            {\n                object = newNull();\n            }\n            break;\n\n          case st_dictionary:\n          case st_array:\n            setObjectDescriptionFromInput(\n                object, context, object_description, input,\n                input->getLastOffset());\n            olist.push_back(object);\n            break;\n\n          case st_top:\n            done = true;\n            break;\n\n          case st_start:\n            break;\n\n          case st_stop:\n            if ((state_stack.size() < 2) || (olist_stack.size() < 2))\n            {\n                throw std::logic_error(\n                    \"QPDFObjectHandle::parseInternal: st_stop encountered\"\n                    \" with insufficient elements in stack\");\n            }\n            parser_state_e old_state = state_stack.back();\n            state_stack.pop_back();\n            if (old_state == st_array)\n            {\n                object = newArray(olist);\n                setObjectDescriptionFromInput(\n                    object, context, object_description, input, offset);\n            }\n            else if (old_state == st_dictionary)\n            {\n                // Convert list to map. Alternating elements are keys.\n                // Attempt to recover more or less gracefully from\n                // invalid dictionaries.\n                std::set<std::string> names;\n                for (std::vector<QPDFObjectHandle>::iterator iter =\n                         olist.begin();\n                     iter != olist.end(); ++iter)\n                {\n                    if ((! (*iter).isIndirect()) && (*iter).isName())\n                    {\n                        names.insert((*iter).getName());\n                    }\n                }\n\n                std::map<std::string, QPDFObjectHandle> dict;\n                int next_fake_key = 1;\n                for (unsigned int i = 0; i < olist.size(); ++i)\n                {\n                    QPDFObjectHandle key_obj = olist.at(i);\n                    QPDFObjectHandle val;\n                    if (key_obj.isIndirect() || (! key_obj.isName()))\n                    {\n                        bool found_fake = false;\n                        std::string candidate;\n                        while (! found_fake)\n                        {\n                            candidate =\n                                \"/QPDFFake\" +\n                                QUtil::int_to_string(next_fake_key++);\n                            found_fake = (names.count(candidate) == 0);\n                            QTC::TC(\"qpdf\", \"QPDFObjectHandle found fake\",\n                                    (found_fake ? 0 : 1));\n                        }\n                        warn(context,\n                             QPDFExc(\n                                 qpdf_e_damaged_pdf,\n                                 input->getName(), object_description, offset,\n                                 \"expected dictionary key but found\"\n                                 \" non-name object; inserting key \" +\n                                 candidate));\n                        val = key_obj;\n                        key_obj = newName(candidate);\n                    }\n                    else if (i + 1 >= olist.size())\n                    {\n                        QTC::TC(\"qpdf\", \"QPDFObjectHandle no val for last key\");\n                        warn(context,\n                             QPDFExc(\n                                 qpdf_e_damaged_pdf,\n                                 input->getName(), object_description, offset,\n                                 \"dictionary ended prematurely; \"\n                                 \"using null as value for last key\"));\n                        val = newNull();\n                        setObjectDescriptionFromInput(\n                            val, context, object_description, input, offset);\n                    }\n                    else\n                    {\n                        val = olist.at(++i);\n                    }\n                    dict[key_obj.getName()] = val;\n                }\n                object = newDictionary(dict);\n                setObjectDescriptionFromInput(\n                    object, context, object_description, input, offset);\n            }\n            olist_stack.pop_back();\n            offset_stack.pop_back();\n            if (state_stack.back() == st_top)\n            {\n                done = true;\n            }\n            else\n            {\n                olist_stack.back().push_back(object);\n            }\n        }\n    }\n\n    setObjectDescriptionFromInput(\n        object, context, object_description, input, offset);\n    return object;\n}",
        "func": "QPDFObjectHandle\nQPDFObjectHandle::parseInternal(PointerHolder<InputSource> input,\n                                std::string const& object_description,\n                                QPDFTokenizer& tokenizer, bool& empty,\n                                StringDecrypter* decrypter, QPDF* context,\n                                bool content_stream)\n{\n    // This method must take care not to resolve any objects. Don't\n    // check the type of any object without first ensuring that it is\n    // a direct object. Otherwise, doing so may have the side effect\n    // of reading the object and changing the file pointer.\n\n    empty = false;\n\n    QPDFObjectHandle object;\n\n    std::vector<std::vector<QPDFObjectHandle> > olist_stack;\n    olist_stack.push_back(std::vector<QPDFObjectHandle>());\n    std::vector<parser_state_e> state_stack;\n    state_stack.push_back(st_top);\n    std::vector<qpdf_offset_t> offset_stack;\n    qpdf_offset_t offset = input->tell();\n    offset_stack.push_back(offset);\n    bool done = false;\n    while (! done)\n    {\n        std::vector<QPDFObjectHandle>& olist = olist_stack.back();\n        parser_state_e state = state_stack.back();\n        offset = offset_stack.back();\n\n\tobject = QPDFObjectHandle();\n\n\tQPDFTokenizer::Token token =\n            tokenizer.readToken(input, object_description, true);\n\n\tswitch (token.getType())\n\t{\n          case QPDFTokenizer::tt_eof:\n            if (! content_stream)\n            {\n                QTC::TC(\"qpdf\", \"QPDFObjectHandle eof in parseInternal\");\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"unexpected EOF\"));\n            }\n            state = st_eof;\n            break;\n\n          case QPDFTokenizer::tt_bad:\n\t    QTC::TC(\"qpdf\", \"QPDFObjectHandle bad token in parse\");\n            warn(context,\n                 QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                         object_description,\n                         input->getLastOffset(),\n                         token.getErrorMessage()));\n            object = newNull();\n\t    break;\n\n\t  case QPDFTokenizer::tt_brace_open:\n\t  case QPDFTokenizer::tt_brace_close:\n\t    QTC::TC(\"qpdf\", \"QPDFObjectHandle bad brace\");\n            warn(context,\n                 QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                         object_description,\n                         input->getLastOffset(),\n                         \"treating unexpected brace token as null\"));\n            object = newNull();\n\t    break;\n\n\t  case QPDFTokenizer::tt_array_close:\n\t    if (state == st_array)\n\t    {\n                state = st_stop;\n\t    }\n\t    else\n\t    {\n\t\tQTC::TC(\"qpdf\", \"QPDFObjectHandle bad array close\");\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"treating unexpected array close token as null\"));\n                object = newNull();\n\t    }\n\t    break;\n\n\t  case QPDFTokenizer::tt_dict_close:\n\t    if (state == st_dictionary)\n\t    {\n                state = st_stop;\n\t    }\n\t    else\n\t    {\n\t\tQTC::TC(\"qpdf\", \"QPDFObjectHandle bad dictionary close\");\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"unexpected dictionary close token\"));\n                object = newNull();\n\t    }\n\t    break;\n\n\t  case QPDFTokenizer::tt_array_open:\n\t  case QPDFTokenizer::tt_dict_open:\n            if (olist_stack.size() > 500)\n            {\n\t\tQTC::TC(\"qpdf\", \"QPDFObjectHandle too deep\");\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"ignoring excessively deeply nested data structure\"));\n                object = newNull();\n                state = st_top;\n            }\n            else\n            {\n                olist_stack.push_back(std::vector<QPDFObjectHandle>());\n                state = st_start;\n                offset_stack.push_back(input->tell());\n                state_stack.push_back(\n                    (token.getType() == QPDFTokenizer::tt_array_open) ?\n                    st_array : st_dictionary);\n            }\n\t    break;\n\n\t  case QPDFTokenizer::tt_bool:\n\t    object = newBool((token.getValue() == \"true\"));\n\t    break;\n\n\t  case QPDFTokenizer::tt_null:\n\t    object = newNull();\n\t    break;\n\n\t  case QPDFTokenizer::tt_integer:\n\t    object = newInteger(QUtil::string_to_ll(token.getValue().c_str()));\n\t    break;\n\n\t  case QPDFTokenizer::tt_real:\n\t    object = newReal(token.getValue());\n\t    break;\n\n\t  case QPDFTokenizer::tt_name:\n\t    object = newName(token.getValue());\n\t    break;\n\n\t  case QPDFTokenizer::tt_word:\n\t    {\n\t\tstd::string const& value = token.getValue();\n                if (content_stream)\n                {\n                    object = QPDFObjectHandle::newOperator(value);\n                }\n\t\telse if ((value == \"R\") && (state != st_top) &&\n                         (olist.size() >= 2) &&\n                         (! olist.at(olist.size() - 1).isIndirect()) &&\n                         (olist.at(olist.size() - 1).isInteger()) &&\n                         (! olist.at(olist.size() - 2).isIndirect()) &&\n                         (olist.at(olist.size() - 2).isInteger()))\n\t\t{\n                    if (context == 0)\n                    {\n                        QTC::TC(\"qpdf\", \"QPDFObjectHandle indirect without context\");\n                        throw std::logic_error(\n                            \"QPDFObjectHandle::parse called without context\"\n                            \" on an object with indirect references\");\n                    }\n\t\t    // Try to resolve indirect objects\n\t\t    object = newIndirect(\n\t\t\tcontext,\n\t\t\tolist.at(olist.size() - 2).getIntValue(),\n\t\t\tolist.at(olist.size() - 1).getIntValue());\n\t\t    olist.pop_back();\n\t\t    olist.pop_back();\n\t\t}\n\t\telse if ((value == \"endobj\") && (state == st_top))\n\t\t{\n\t\t    // We just saw endobj without having read\n\t\t    // anything.  Treat this as a null and do not move\n\t\t    // the input source's offset.\n\t\t    object = newNull();\n\t\t    input->seek(input->getLastOffset(), SEEK_SET);\n                    empty = true;\n\t\t}\n\t\telse\n\t\t{\n                    QTC::TC(\"qpdf\", \"QPDFObjectHandle treat word as string\");\n                    warn(context,\n                         QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                                 object_description,\n                                 input->getLastOffset(),\n                                 \"unknown token while reading object;\"\n                                 \" treating as string\"));\n                    object = newString(value);\n\t\t}\n\t    }\n\t    break;\n\n\t  case QPDFTokenizer::tt_string:\n\t    {\n\t\tstd::string val = token.getValue();\n                if (decrypter)\n                {\n                    decrypter->decryptString(val);\n                }\n\t\tobject = QPDFObjectHandle::newString(val);\n\t    }\n\n\t    break;\n\n\t  default:\n            warn(context,\n                 QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                         object_description,\n                         input->getLastOffset(),\n                         \"treating unknown token type as null while \"\n                         \"reading object\"));\n            object = newNull();\n\t    break;\n\t}\n\n        if ((! object.isInitialized()) &&\n            (! ((state == st_start) ||\n                (state == st_stop) ||\n                (state == st_eof))))\n        {\n            throw std::logic_error(\n                \"QPDFObjectHandle::parseInternal: \"\n                \"unexpected uninitialized object\");\n            object = newNull();\n        }\n\n        switch (state)\n        {\n          case st_eof:\n            if (state_stack.size() > 1)\n            {\n                warn(context,\n                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n                             object_description,\n                             input->getLastOffset(),\n                             \"parse error while reading object\"));\n            }\n            done = true;\n            // In content stream mode, leave object uninitialized to\n            // indicate EOF\n            if (! content_stream)\n            {\n                object = newNull();\n            }\n            break;\n\n          case st_dictionary:\n          case st_array:\n            setObjectDescriptionFromInput(\n                object, context, object_description, input,\n                input->getLastOffset());\n            olist.push_back(object);\n            break;\n\n          case st_top:\n            done = true;\n            break;\n\n          case st_start:\n            break;\n\n          case st_stop:\n            if ((state_stack.size() < 2) || (olist_stack.size() < 2))\n            {\n                throw std::logic_error(\n                    \"QPDFObjectHandle::parseInternal: st_stop encountered\"\n                    \" with insufficient elements in stack\");\n            }\n            parser_state_e old_state = state_stack.back();\n            state_stack.pop_back();\n            if (old_state == st_array)\n            {\n                object = newArray(olist);\n                setObjectDescriptionFromInput(\n                    object, context, object_description, input, offset);\n            }\n            else if (old_state == st_dictionary)\n            {\n                // Convert list to map. Alternating elements are keys.\n                // Attempt to recover more or less gracefully from\n                // invalid dictionaries.\n                std::set<std::string> names;\n                for (std::vector<QPDFObjectHandle>::iterator iter =\n                         olist.begin();\n                     iter != olist.end(); ++iter)\n                {\n                    if ((! (*iter).isIndirect()) && (*iter).isName())\n                    {\n                        names.insert((*iter).getName());\n                    }\n                }\n\n                std::map<std::string, QPDFObjectHandle> dict;\n                int next_fake_key = 1;\n                for (unsigned int i = 0; i < olist.size(); ++i)\n                {\n                    QPDFObjectHandle key_obj = olist.at(i);\n                    QPDFObjectHandle val;\n                    if (key_obj.isIndirect() || (! key_obj.isName()))\n                    {\n                        bool found_fake = false;\n                        std::string candidate;\n                        while (! found_fake)\n                        {\n                            candidate =\n                                \"/QPDFFake\" +\n                                QUtil::int_to_string(next_fake_key++);\n                            found_fake = (names.count(candidate) == 0);\n                            QTC::TC(\"qpdf\", \"QPDFObjectHandle found fake\",\n                                    (found_fake ? 0 : 1));\n                        }\n                        warn(context,\n                             QPDFExc(\n                                 qpdf_e_damaged_pdf,\n                                 input->getName(), object_description, offset,\n                                 \"expected dictionary key but found\"\n                                 \" non-name object; inserting key \" +\n                                 candidate));\n                        val = key_obj;\n                        key_obj = newName(candidate);\n                    }\n                    else if (i + 1 >= olist.size())\n                    {\n                        QTC::TC(\"qpdf\", \"QPDFObjectHandle no val for last key\");\n                        warn(context,\n                             QPDFExc(\n                                 qpdf_e_damaged_pdf,\n                                 input->getName(), object_description, offset,\n                                 \"dictionary ended prematurely; \"\n                                 \"using null as value for last key\"));\n                        val = newNull();\n                        setObjectDescriptionFromInput(\n                            val, context, object_description, input, offset);\n                    }\n                    else\n                    {\n                        val = olist.at(++i);\n                    }\n                    dict[key_obj.getName()] = val;\n                }\n                object = newDictionary(dict);\n                setObjectDescriptionFromInput(\n                    object, context, object_description, input, offset);\n            }\n            olist_stack.pop_back();\n            offset_stack.pop_back();\n            if (state_stack.back() == st_top)\n            {\n                done = true;\n            }\n            else\n            {\n                olist_stack.back().push_back(object);\n            }\n        }\n    }\n\n    setObjectDescriptionFromInput(\n        object, context, object_description, input, offset);\n    return object;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -105,12 +105,26 @@\n \n \t  case QPDFTokenizer::tt_array_open:\n \t  case QPDFTokenizer::tt_dict_open:\n-            olist_stack.push_back(std::vector<QPDFObjectHandle>());\n-            state = st_start;\n-            offset_stack.push_back(input->tell());\n-            state_stack.push_back(\n-                (token.getType() == QPDFTokenizer::tt_array_open) ?\n-                st_array : st_dictionary);\n+            if (olist_stack.size() > 500)\n+            {\n+\t\tQTC::TC(\"qpdf\", \"QPDFObjectHandle too deep\");\n+                warn(context,\n+                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),\n+                             object_description,\n+                             input->getLastOffset(),\n+                             \"ignoring excessively deeply nested data structure\"));\n+                object = newNull();\n+                state = st_top;\n+            }\n+            else\n+            {\n+                olist_stack.push_back(std::vector<QPDFObjectHandle>());\n+                state = st_start;\n+                offset_stack.push_back(input->tell());\n+                state_stack.push_back(\n+                    (token.getType() == QPDFTokenizer::tt_array_open) ?\n+                    st_array : st_dictionary);\n+            }\n \t    break;\n \n \t  case QPDFTokenizer::tt_bool:",
        "diff_line_info": {
            "deleted_lines": [
                "            olist_stack.push_back(std::vector<QPDFObjectHandle>());",
                "            state = st_start;",
                "            offset_stack.push_back(input->tell());",
                "            state_stack.push_back(",
                "                (token.getType() == QPDFTokenizer::tt_array_open) ?",
                "                st_array : st_dictionary);"
            ],
            "added_lines": [
                "            if (olist_stack.size() > 500)",
                "            {",
                "\t\tQTC::TC(\"qpdf\", \"QPDFObjectHandle too deep\");",
                "                warn(context,",
                "                     QPDFExc(qpdf_e_damaged_pdf, input->getName(),",
                "                             object_description,",
                "                             input->getLastOffset(),",
                "                             \"ignoring excessively deeply nested data structure\"));",
                "                object = newNull();",
                "                state = st_top;",
                "            }",
                "            else",
                "            {",
                "                olist_stack.push_back(std::vector<QPDFObjectHandle>());",
                "                state = st_start;",
                "                offset_stack.push_back(input->tell());",
                "                state_stack.push_back(",
                "                    (token.getType() == QPDFTokenizer::tt_array_open) ?",
                "                    st_array : st_dictionary);",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-11597",
        "func_name": "espruino/Espruino/jspeStatement",
        "description": "Espruino before 1.99 allows attackers to cause a denial of service (application crash) with a user crafted input file via a Buffer Overflow during syntax parsing because of a missing check for stack exhaustion with many '{' characters in jsparse.c.",
        "git_url": "https://github.com/espruino/Espruino/commit/51380baf17241728b6d48cdb84140b931e3e3cc5",
        "commit_title": "Fix stack overflow if interpreting a file full of '{' (fix #1448)",
        "commit_text": "",
        "func_before": "NO_INLINE JsVar *jspeStatement() {\n#ifdef USE_DEBUGGER\n  if (execInfo.execute&EXEC_DEBUGGER_NEXT_LINE &&\n      lex->tk!=';' &&\n      JSP_SHOULD_EXECUTE) {\n    lex->tokenLastStart = jsvStringIteratorGetIndex(&lex->tokenStart.it)-1;\n    jsiDebuggerLoop();\n  }\n#endif\n  if (lex->tk==LEX_ID ||\n      lex->tk==LEX_INT ||\n      lex->tk==LEX_FLOAT ||\n      lex->tk==LEX_STR ||\n      lex->tk==LEX_TEMPLATE_LITERAL ||\n      lex->tk==LEX_REGEX ||\n      lex->tk==LEX_R_NEW ||\n      lex->tk==LEX_R_NULL ||\n      lex->tk==LEX_R_UNDEFINED ||\n      lex->tk==LEX_R_TRUE ||\n      lex->tk==LEX_R_FALSE ||\n      lex->tk==LEX_R_THIS ||\n      lex->tk==LEX_R_DELETE ||\n      lex->tk==LEX_R_TYPEOF ||\n      lex->tk==LEX_R_VOID ||\n      lex->tk==LEX_R_SUPER ||\n      lex->tk==LEX_PLUSPLUS ||\n      lex->tk==LEX_MINUSMINUS ||\n      lex->tk=='!' ||\n      lex->tk=='-' ||\n      lex->tk=='+' ||\n      lex->tk=='~' ||\n      lex->tk=='[' ||\n      lex->tk=='(') {\n    /* Execute a simple statement that only contains basic arithmetic... */\n    return jspeExpression();\n  } else if (lex->tk=='{') {\n    /* A block of code */\n    jspeBlock();\n    return 0;\n  } else if (lex->tk==';') {\n    /* Empty statement - to allow things like ;;; */\n    JSP_ASSERT_MATCH(';');\n    return 0;\n  } else if (lex->tk==LEX_R_VAR ||\n            lex->tk==LEX_R_LET ||\n            lex->tk==LEX_R_CONST) {\n    return jspeStatementVar();\n  } else if (lex->tk==LEX_R_IF) {\n    return jspeStatementIf();\n  } else if (lex->tk==LEX_R_DO) {\n    return jspeStatementDoOrWhile(false);\n  } else if (lex->tk==LEX_R_WHILE) {\n    return jspeStatementDoOrWhile(true);\n  } else if (lex->tk==LEX_R_FOR) {\n    return jspeStatementFor();\n  } else if (lex->tk==LEX_R_TRY) {\n    return jspeStatementTry();\n  } else if (lex->tk==LEX_R_RETURN) {\n    return jspeStatementReturn();\n  } else if (lex->tk==LEX_R_THROW) {\n    return jspeStatementThrow();\n  } else if (lex->tk==LEX_R_FUNCTION) {\n    return jspeStatementFunctionDecl(false/* function */);\n#ifndef SAVE_ON_FLASH\n  } else if (lex->tk==LEX_R_CLASS) {\n      return jspeStatementFunctionDecl(true/* class */);\n#endif\n  } else if (lex->tk==LEX_R_CONTINUE) {\n    JSP_ASSERT_MATCH(LEX_R_CONTINUE);\n    if (JSP_SHOULD_EXECUTE) {\n      if (!(execInfo.execute & EXEC_IN_LOOP))\n        jsExceptionHere(JSET_SYNTAXERROR, \"CONTINUE statement outside of FOR or WHILE loop\");\n      else\n        execInfo.execute = (execInfo.execute & (JsExecFlags)~EXEC_RUN_MASK) | EXEC_CONTINUE;\n    }\n  } else if (lex->tk==LEX_R_BREAK) {\n    JSP_ASSERT_MATCH(LEX_R_BREAK);\n    if (JSP_SHOULD_EXECUTE) {\n      if (!(execInfo.execute & (EXEC_IN_LOOP|EXEC_IN_SWITCH)))\n        jsExceptionHere(JSET_SYNTAXERROR, \"BREAK statement outside of SWITCH, FOR or WHILE loop\");\n      else\n        execInfo.execute = (execInfo.execute & (JsExecFlags)~EXEC_RUN_MASK) | EXEC_BREAK;\n    }\n  } else if (lex->tk==LEX_R_SWITCH) {\n    return jspeStatementSwitch();\n  } else if (lex->tk==LEX_R_DEBUGGER) {\n    JSP_ASSERT_MATCH(LEX_R_DEBUGGER);\n#ifdef USE_DEBUGGER\n    if (JSP_SHOULD_EXECUTE)\n      jsiDebuggerLoop();\n#endif\n  } else JSP_MATCH(LEX_EOF);\n  return 0;\n}",
        "func": "NO_INLINE JsVar *jspeStatement() {\n#ifdef USE_DEBUGGER\n  if (execInfo.execute&EXEC_DEBUGGER_NEXT_LINE &&\n      lex->tk!=';' &&\n      JSP_SHOULD_EXECUTE) {\n    lex->tokenLastStart = jsvStringIteratorGetIndex(&lex->tokenStart.it)-1;\n    jsiDebuggerLoop();\n  }\n#endif\n  if (lex->tk==LEX_ID ||\n      lex->tk==LEX_INT ||\n      lex->tk==LEX_FLOAT ||\n      lex->tk==LEX_STR ||\n      lex->tk==LEX_TEMPLATE_LITERAL ||\n      lex->tk==LEX_REGEX ||\n      lex->tk==LEX_R_NEW ||\n      lex->tk==LEX_R_NULL ||\n      lex->tk==LEX_R_UNDEFINED ||\n      lex->tk==LEX_R_TRUE ||\n      lex->tk==LEX_R_FALSE ||\n      lex->tk==LEX_R_THIS ||\n      lex->tk==LEX_R_DELETE ||\n      lex->tk==LEX_R_TYPEOF ||\n      lex->tk==LEX_R_VOID ||\n      lex->tk==LEX_R_SUPER ||\n      lex->tk==LEX_PLUSPLUS ||\n      lex->tk==LEX_MINUSMINUS ||\n      lex->tk=='!' ||\n      lex->tk=='-' ||\n      lex->tk=='+' ||\n      lex->tk=='~' ||\n      lex->tk=='[' ||\n      lex->tk=='(') {\n    /* Execute a simple statement that only contains basic arithmetic... */\n    return jspeExpression();\n  } else if (lex->tk=='{') {\n    /* A block of code */\n    if (!jspCheckStackPosition()) return 0;\n    jspeBlock();\n    return 0;\n  } else if (lex->tk==';') {\n    /* Empty statement - to allow things like ;;; */\n    JSP_ASSERT_MATCH(';');\n    return 0;\n  } else if (lex->tk==LEX_R_VAR ||\n            lex->tk==LEX_R_LET ||\n            lex->tk==LEX_R_CONST) {\n    return jspeStatementVar();\n  } else if (lex->tk==LEX_R_IF) {\n    return jspeStatementIf();\n  } else if (lex->tk==LEX_R_DO) {\n    return jspeStatementDoOrWhile(false);\n  } else if (lex->tk==LEX_R_WHILE) {\n    return jspeStatementDoOrWhile(true);\n  } else if (lex->tk==LEX_R_FOR) {\n    return jspeStatementFor();\n  } else if (lex->tk==LEX_R_TRY) {\n    return jspeStatementTry();\n  } else if (lex->tk==LEX_R_RETURN) {\n    return jspeStatementReturn();\n  } else if (lex->tk==LEX_R_THROW) {\n    return jspeStatementThrow();\n  } else if (lex->tk==LEX_R_FUNCTION) {\n    return jspeStatementFunctionDecl(false/* function */);\n#ifndef SAVE_ON_FLASH\n  } else if (lex->tk==LEX_R_CLASS) {\n      return jspeStatementFunctionDecl(true/* class */);\n#endif\n  } else if (lex->tk==LEX_R_CONTINUE) {\n    JSP_ASSERT_MATCH(LEX_R_CONTINUE);\n    if (JSP_SHOULD_EXECUTE) {\n      if (!(execInfo.execute & EXEC_IN_LOOP))\n        jsExceptionHere(JSET_SYNTAXERROR, \"CONTINUE statement outside of FOR or WHILE loop\");\n      else\n        execInfo.execute = (execInfo.execute & (JsExecFlags)~EXEC_RUN_MASK) | EXEC_CONTINUE;\n    }\n  } else if (lex->tk==LEX_R_BREAK) {\n    JSP_ASSERT_MATCH(LEX_R_BREAK);\n    if (JSP_SHOULD_EXECUTE) {\n      if (!(execInfo.execute & (EXEC_IN_LOOP|EXEC_IN_SWITCH)))\n        jsExceptionHere(JSET_SYNTAXERROR, \"BREAK statement outside of SWITCH, FOR or WHILE loop\");\n      else\n        execInfo.execute = (execInfo.execute & (JsExecFlags)~EXEC_RUN_MASK) | EXEC_BREAK;\n    }\n  } else if (lex->tk==LEX_R_SWITCH) {\n    return jspeStatementSwitch();\n  } else if (lex->tk==LEX_R_DEBUGGER) {\n    JSP_ASSERT_MATCH(LEX_R_DEBUGGER);\n#ifdef USE_DEBUGGER\n    if (JSP_SHOULD_EXECUTE)\n      jsiDebuggerLoop();\n#endif\n  } else JSP_MATCH(LEX_EOF);\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,6 +35,7 @@\n     return jspeExpression();\n   } else if (lex->tk=='{') {\n     /* A block of code */\n+    if (!jspCheckStackPosition()) return 0;\n     jspeBlock();\n     return 0;\n   } else if (lex->tk==';') {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (!jspCheckStackPosition()) return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-18936",
        "func_name": "jgarzik/univalue/UniValue::read",
        "description": "UniValue::read() in UniValue before 1.0.5 allow attackers to cause a denial of service (the class internal data reaches an inconsistent state) via input data that triggers an error.",
        "git_url": "https://github.com/jgarzik/univalue/commit/07aa635c034f3a2accfe4e20a8148c366bccf5bf",
        "commit_title": "UniValue::read(): Clear internal state upon error",
        "commit_text": " Avoid parsing edge cases that leave the class internal data in an inconsistent state, when the parser encounters an input data error.  This is a rewrite of PR #39 by @awemany.",
        "func_before": "bool UniValue::read(const char *raw, size_t size)\n{\n    clear();\n\n    uint32_t expectMask = 0;\n    std::vector<UniValue*> stack;\n\n    std::string tokenVal;\n    unsigned int consumed;\n    enum jtokentype tok = JTOK_NONE;\n    enum jtokentype last_tok = JTOK_NONE;\n    const char* end = raw + size;\n    do {\n        last_tok = tok;\n\n        tok = getJsonToken(tokenVal, consumed, raw, end);\n        if (tok == JTOK_NONE || tok == JTOK_ERR)\n            return false;\n        raw += consumed;\n\n        bool isValueOpen = jsonTokenIsValue(tok) ||\n            tok == JTOK_OBJ_OPEN || tok == JTOK_ARR_OPEN;\n\n        if (expect(VALUE)) {\n            if (!isValueOpen)\n                return false;\n            clearExpect(VALUE);\n\n        } else if (expect(ARR_VALUE)) {\n            bool isArrValue = isValueOpen || (tok == JTOK_ARR_CLOSE);\n            if (!isArrValue)\n                return false;\n\n            clearExpect(ARR_VALUE);\n\n        } else if (expect(OBJ_NAME)) {\n            bool isObjName = (tok == JTOK_OBJ_CLOSE || tok == JTOK_STRING);\n            if (!isObjName)\n                return false;\n\n        } else if (expect(COLON)) {\n            if (tok != JTOK_COLON)\n                return false;\n            clearExpect(COLON);\n\n        } else if (!expect(COLON) && (tok == JTOK_COLON)) {\n            return false;\n        }\n\n        if (expect(NOT_VALUE)) {\n            if (isValueOpen)\n                return false;\n            clearExpect(NOT_VALUE);\n        }\n\n        switch (tok) {\n\n        case JTOK_OBJ_OPEN:\n        case JTOK_ARR_OPEN: {\n            VType utyp = (tok == JTOK_OBJ_OPEN ? VOBJ : VARR);\n            if (!stack.size()) {\n                if (utyp == VOBJ)\n                    setObject();\n                else\n                    setArray();\n                stack.push_back(this);\n            } else {\n                UniValue tmpVal(utyp);\n                UniValue *top = stack.back();\n                top->values.push_back(tmpVal);\n\n                UniValue *newTop = &(top->values.back());\n                stack.push_back(newTop);\n            }\n\n            if (utyp == VOBJ)\n                setExpect(OBJ_NAME);\n            else\n                setExpect(ARR_VALUE);\n            break;\n            }\n\n        case JTOK_OBJ_CLOSE:\n        case JTOK_ARR_CLOSE: {\n            if (!stack.size() || (last_tok == JTOK_COMMA))\n                return false;\n\n            VType utyp = (tok == JTOK_OBJ_CLOSE ? VOBJ : VARR);\n            UniValue *top = stack.back();\n            if (utyp != top->getType())\n                return false;\n\n            stack.pop_back();\n            clearExpect(OBJ_NAME);\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        case JTOK_COLON: {\n            if (!stack.size())\n                return false;\n\n            UniValue *top = stack.back();\n            if (top->getType() != VOBJ)\n                return false;\n\n            setExpect(VALUE);\n            break;\n            }\n\n        case JTOK_COMMA: {\n            if (!stack.size() ||\n                (last_tok == JTOK_COMMA) || (last_tok == JTOK_ARR_OPEN))\n                return false;\n\n            UniValue *top = stack.back();\n            if (top->getType() == VOBJ)\n                setExpect(OBJ_NAME);\n            else\n                setExpect(ARR_VALUE);\n            break;\n            }\n\n        case JTOK_KW_NULL:\n        case JTOK_KW_TRUE:\n        case JTOK_KW_FALSE: {\n            UniValue tmpVal;\n            switch (tok) {\n            case JTOK_KW_NULL:\n                // do nothing more\n                break;\n            case JTOK_KW_TRUE:\n                tmpVal.setBool(true);\n                break;\n            case JTOK_KW_FALSE:\n                tmpVal.setBool(false);\n                break;\n            default: /* impossible */ break;\n            }\n\n            if (!stack.size()) {\n                *this = tmpVal;\n                break;\n            }\n\n            UniValue *top = stack.back();\n            top->values.push_back(tmpVal);\n\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        case JTOK_NUMBER: {\n            UniValue tmpVal(VNUM, tokenVal);\n            if (!stack.size()) {\n                *this = tmpVal;\n                break;\n            }\n\n            UniValue *top = stack.back();\n            top->values.push_back(tmpVal);\n\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        case JTOK_STRING: {\n            if (expect(OBJ_NAME)) {\n                UniValue *top = stack.back();\n                top->keys.push_back(tokenVal);\n                clearExpect(OBJ_NAME);\n                setExpect(COLON);\n            } else {\n                UniValue tmpVal(VSTR, tokenVal);\n                if (!stack.size()) {\n                    *this = tmpVal;\n                    break;\n                }\n                UniValue *top = stack.back();\n                top->values.push_back(tmpVal);\n            }\n\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        default:\n            return false;\n        }\n    } while (!stack.empty ());\n\n    /* Check that nothing follows the initial construct (parsed above).  */\n    tok = getJsonToken(tokenVal, consumed, raw, end);\n    if (tok != JTOK_NONE)\n        return false;\n\n    return true;\n}",
        "func": "bool UniValue::read(const char *raw, size_t size)\n{\n    clear();\n\n    uint32_t expectMask = 0;\n    std::vector<UniValue*> stack;\n\n    std::string tokenVal;\n    unsigned int consumed;\n    enum jtokentype tok = JTOK_NONE;\n    enum jtokentype last_tok = JTOK_NONE;\n    const char* end = raw + size;\n    do {\n        last_tok = tok;\n\n        tok = getJsonToken(tokenVal, consumed, raw, end);\n        if (tok == JTOK_NONE || tok == JTOK_ERR)\n            goto return_fail;\n        raw += consumed;\n\n        bool isValueOpen = jsonTokenIsValue(tok) ||\n            tok == JTOK_OBJ_OPEN || tok == JTOK_ARR_OPEN;\n\n        if (expect(VALUE)) {\n            if (!isValueOpen)\n                goto return_fail;\n            clearExpect(VALUE);\n\n        } else if (expect(ARR_VALUE)) {\n            bool isArrValue = isValueOpen || (tok == JTOK_ARR_CLOSE);\n            if (!isArrValue)\n                goto return_fail;\n\n            clearExpect(ARR_VALUE);\n\n        } else if (expect(OBJ_NAME)) {\n            bool isObjName = (tok == JTOK_OBJ_CLOSE || tok == JTOK_STRING);\n            if (!isObjName)\n                goto return_fail;\n\n        } else if (expect(COLON)) {\n            if (tok != JTOK_COLON)\n                goto return_fail;\n            clearExpect(COLON);\n\n        } else if (!expect(COLON) && (tok == JTOK_COLON)) {\n            goto return_fail;\n        }\n\n        if (expect(NOT_VALUE)) {\n            if (isValueOpen)\n                goto return_fail;\n            clearExpect(NOT_VALUE);\n        }\n\n        switch (tok) {\n\n        case JTOK_OBJ_OPEN:\n        case JTOK_ARR_OPEN: {\n            VType utyp = (tok == JTOK_OBJ_OPEN ? VOBJ : VARR);\n            if (!stack.size()) {\n                if (utyp == VOBJ)\n                    setObject();\n                else\n                    setArray();\n                stack.push_back(this);\n            } else {\n                UniValue tmpVal(utyp);\n                UniValue *top = stack.back();\n                top->values.push_back(tmpVal);\n\n                UniValue *newTop = &(top->values.back());\n                stack.push_back(newTop);\n            }\n\n            if (utyp == VOBJ)\n                setExpect(OBJ_NAME);\n            else\n                setExpect(ARR_VALUE);\n            break;\n            }\n\n        case JTOK_OBJ_CLOSE:\n        case JTOK_ARR_CLOSE: {\n            if (!stack.size() || (last_tok == JTOK_COMMA))\n                goto return_fail;\n\n            VType utyp = (tok == JTOK_OBJ_CLOSE ? VOBJ : VARR);\n            UniValue *top = stack.back();\n            if (utyp != top->getType())\n                goto return_fail;\n\n            stack.pop_back();\n            clearExpect(OBJ_NAME);\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        case JTOK_COLON: {\n            if (!stack.size())\n                goto return_fail;\n\n            UniValue *top = stack.back();\n            if (top->getType() != VOBJ)\n                goto return_fail;\n\n            setExpect(VALUE);\n            break;\n            }\n\n        case JTOK_COMMA: {\n            if (!stack.size() ||\n                (last_tok == JTOK_COMMA) || (last_tok == JTOK_ARR_OPEN))\n                goto return_fail;\n\n            UniValue *top = stack.back();\n            if (top->getType() == VOBJ)\n                setExpect(OBJ_NAME);\n            else\n                setExpect(ARR_VALUE);\n            break;\n            }\n\n        case JTOK_KW_NULL:\n        case JTOK_KW_TRUE:\n        case JTOK_KW_FALSE: {\n            UniValue tmpVal;\n            switch (tok) {\n            case JTOK_KW_NULL:\n                // do nothing more\n                break;\n            case JTOK_KW_TRUE:\n                tmpVal.setBool(true);\n                break;\n            case JTOK_KW_FALSE:\n                tmpVal.setBool(false);\n                break;\n            default: /* impossible */ break;\n            }\n\n            if (!stack.size()) {\n                *this = tmpVal;\n                break;\n            }\n\n            UniValue *top = stack.back();\n            top->values.push_back(tmpVal);\n\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        case JTOK_NUMBER: {\n            UniValue tmpVal(VNUM, tokenVal);\n            if (!stack.size()) {\n                *this = tmpVal;\n                break;\n            }\n\n            UniValue *top = stack.back();\n            top->values.push_back(tmpVal);\n\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        case JTOK_STRING: {\n            if (expect(OBJ_NAME)) {\n                UniValue *top = stack.back();\n                top->keys.push_back(tokenVal);\n                clearExpect(OBJ_NAME);\n                setExpect(COLON);\n            } else {\n                UniValue tmpVal(VSTR, tokenVal);\n                if (!stack.size()) {\n                    *this = tmpVal;\n                    break;\n                }\n                UniValue *top = stack.back();\n                top->values.push_back(tmpVal);\n            }\n\n            setExpect(NOT_VALUE);\n            break;\n            }\n\n        default:\n            goto return_fail;\n        }\n    } while (!stack.empty ());\n\n    /* Check that nothing follows the initial construct (parsed above).  */\n    tok = getJsonToken(tokenVal, consumed, raw, end);\n    if (tok != JTOK_NONE)\n        goto return_fail;\n\n    return true;\n\nreturn_fail:\n    clear();\n    return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,7 @@\n \n         tok = getJsonToken(tokenVal, consumed, raw, end);\n         if (tok == JTOK_NONE || tok == JTOK_ERR)\n-            return false;\n+            goto return_fail;\n         raw += consumed;\n \n         bool isValueOpen = jsonTokenIsValue(tok) ||\n@@ -23,33 +23,33 @@\n \n         if (expect(VALUE)) {\n             if (!isValueOpen)\n-                return false;\n+                goto return_fail;\n             clearExpect(VALUE);\n \n         } else if (expect(ARR_VALUE)) {\n             bool isArrValue = isValueOpen || (tok == JTOK_ARR_CLOSE);\n             if (!isArrValue)\n-                return false;\n+                goto return_fail;\n \n             clearExpect(ARR_VALUE);\n \n         } else if (expect(OBJ_NAME)) {\n             bool isObjName = (tok == JTOK_OBJ_CLOSE || tok == JTOK_STRING);\n             if (!isObjName)\n-                return false;\n+                goto return_fail;\n \n         } else if (expect(COLON)) {\n             if (tok != JTOK_COLON)\n-                return false;\n+                goto return_fail;\n             clearExpect(COLON);\n \n         } else if (!expect(COLON) && (tok == JTOK_COLON)) {\n-            return false;\n+            goto return_fail;\n         }\n \n         if (expect(NOT_VALUE)) {\n             if (isValueOpen)\n-                return false;\n+                goto return_fail;\n             clearExpect(NOT_VALUE);\n         }\n \n@@ -83,12 +83,12 @@\n         case JTOK_OBJ_CLOSE:\n         case JTOK_ARR_CLOSE: {\n             if (!stack.size() || (last_tok == JTOK_COMMA))\n-                return false;\n+                goto return_fail;\n \n             VType utyp = (tok == JTOK_OBJ_CLOSE ? VOBJ : VARR);\n             UniValue *top = stack.back();\n             if (utyp != top->getType())\n-                return false;\n+                goto return_fail;\n \n             stack.pop_back();\n             clearExpect(OBJ_NAME);\n@@ -98,11 +98,11 @@\n \n         case JTOK_COLON: {\n             if (!stack.size())\n-                return false;\n+                goto return_fail;\n \n             UniValue *top = stack.back();\n             if (top->getType() != VOBJ)\n-                return false;\n+                goto return_fail;\n \n             setExpect(VALUE);\n             break;\n@@ -111,7 +111,7 @@\n         case JTOK_COMMA: {\n             if (!stack.size() ||\n                 (last_tok == JTOK_COMMA) || (last_tok == JTOK_ARR_OPEN))\n-                return false;\n+                goto return_fail;\n \n             UniValue *top = stack.back();\n             if (top->getType() == VOBJ)\n@@ -185,14 +185,18 @@\n             }\n \n         default:\n-            return false;\n+            goto return_fail;\n         }\n     } while (!stack.empty ());\n \n     /* Check that nothing follows the initial construct (parsed above).  */\n     tok = getJsonToken(tokenVal, consumed, raw, end);\n     if (tok != JTOK_NONE)\n-        return false;\n+        goto return_fail;\n \n     return true;\n+\n+return_fail:\n+    clear();\n+    return false;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "            return false;",
                "                return false;",
                "                return false;",
                "                return false;",
                "                return false;",
                "            return false;",
                "                return false;",
                "                return false;",
                "                return false;",
                "                return false;",
                "                return false;",
                "                return false;",
                "            return false;",
                "        return false;"
            ],
            "added_lines": [
                "            goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "            goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "                goto return_fail;",
                "            goto return_fail;",
                "        goto return_fail;",
                "",
                "return_fail:",
                "    clear();",
                "    return false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-11647",
        "func_name": "wireshark/proto_register_bacapp",
        "description": "In Wireshark 3.2.0 to 3.2.2, 3.0.0 to 3.0.9, and 2.6.0 to 2.6.15, the BACapp dissector could crash. This was addressed in epan/dissectors/packet-bacapp.c by limiting the amount of recursion.",
        "git_url": "https://github.com/wireshark/wireshark/commit/6f56fc9496db158218243ea87e3660c874a0bab0",
        "commit_title": "BACapp: Add a nesting / recursion check.",
        "commit_text": " Track our recursion depth in fAbstractSyntaxNType. It calls several functions which in turn call it, which makes it easy to overflow the stack.  Bug: 16474 (cherry picked from commit 15dc2f6bd4c9a674333cbc97260362524d5364de)",
        "func_before": "void\nproto_register_bacapp(void)\n{\n    static hf_register_info hf[] = {\n        { &hf_bacapp_type,\n          { \"APDU Type\",           \"bacapp.type\",\n            FT_UINT8, BASE_DEC, VALS(BACnetTypeName), 0xf0, NULL, HFILL }\n        },\n        { &hf_bacapp_pduflags,\n          { \"PDU Flags\",          \"bacapp.pduflags\",\n            FT_UINT8, BASE_HEX, NULL, 0x0f, NULL, HFILL }\n        },\n        { &hf_bacapp_SEG,\n          { \"Segmented Request\",           \"bacapp.segmented_request\",\n            FT_BOOLEAN, 8, TFS(&segments_follow), 0x08, NULL, HFILL }\n        },\n        { &hf_bacapp_MOR,\n          { \"More Segments\",           \"bacapp.more_segments\",\n            FT_BOOLEAN, 8, TFS(&more_follow), 0x04, \"More Segments Follow\", HFILL }\n        },\n        { &hf_bacapp_SA,\n          { \"SA\",           \"bacapp.SA\",\n            FT_BOOLEAN, 8, TFS(&segmented_accept), 0x02, \"Segmented Response accepted\", HFILL }\n        },\n        { &hf_bacapp_max_adpu_size,\n          { \"Size of Maximum ADPU accepted\",           \"bacapp.max_adpu_size\",\n            FT_UINT8, BASE_DEC, VALS(BACnetMaxAPDULengthAccepted), 0x0f, NULL, HFILL }\n        },\n        { &hf_bacapp_response_segments,\n          { \"Max Response Segments accepted\",           \"bacapp.response_segments\",\n            FT_UINT8, BASE_DEC, VALS(BACnetMaxSegmentsAccepted), 0x70, NULL, HFILL }\n        },\n        { &hf_bacapp_objectType,\n          { \"Object Type\",           \"bacapp.objectType\",\n            FT_UINT32, BASE_DEC, VALS(BACnetObjectType), 0xffc00000, NULL, HFILL }\n        },\n        { &hf_bacapp_instanceNumber,\n          { \"Instance Number\",           \"bacapp.instance_number\",\n            FT_UINT32, BASE_DEC, NULL, 0x003fffff, NULL, HFILL }\n        },\n        { &hf_BACnetPropertyIdentifier,\n          { \"Property Identifier\", \"bacapp.property_identifier\",\n            FT_UINT32, BASE_DEC, VALS(BACnetPropertyIdentifier), 0, NULL, HFILL }\n        },\n        { &hf_BACnetVendorIdentifier,\n          { \"Vendor Identifier\", \"bacapp.vendor_identifier\",\n            FT_UINT16, BASE_DEC|BASE_EXT_STRING, &BACnetVendorIdentifiers_ext, 0, NULL, HFILL }\n        },\n        { &hf_BACnetRestartReason,\n          { \"Restart Reason\", \"bacapp.restart_reason\",\n            FT_UINT8, BASE_DEC, VALS(BACnetRestartReason), 0, NULL, HFILL }\n        },\n        { &hf_bacapp_invoke_id,\n          { \"Invoke ID\",           \"bacapp.invoke_id\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_sequence_number,\n          { \"Sequence Number\",           \"bacapp.sequence_number\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_window_size,\n          { \"Proposed Window Size\",           \"bacapp.window_size\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_service,\n          { \"Service Choice\",           \"bacapp.confirmed_service\",\n            FT_UINT8, BASE_DEC, VALS(BACnetConfirmedServiceChoice), 0x00, NULL, HFILL }\n        },\n        { &hf_bacapp_uservice,\n          { \"Unconfirmed Service Choice\",           \"bacapp.unconfirmed_service\",\n            FT_UINT8, BASE_DEC, VALS(BACnetUnconfirmedServiceChoice), 0x00, NULL, HFILL }\n        },\n        { &hf_bacapp_NAK,\n          { \"NAK\",           \"bacapp.NAK\",\n            FT_BOOLEAN, 8, NULL, 0x02, \"negative ACK\", HFILL }\n        },\n        { &hf_bacapp_SRV,\n          { \"SRV\",           \"bacapp.SRV\",\n            FT_BOOLEAN, 8, NULL, 0x01, \"Server\", HFILL }\n        },\n        { &hf_Device_Instance_Range_Low_Limit,\n          { \"Device Instance Range Low Limit\", \"bacapp.who_is.low_limit\",\n            FT_UINT32, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_Device_Instance_Range_High_Limit,\n          { \"Device Instance Range High Limit\", \"bacapp.who_is.high_limit\",\n            FT_UINT32, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_BACnetRejectReason,\n          { \"Reject Reason\",           \"bacapp.reject_reason\",\n            FT_UINT8, BASE_DEC, VALS(BACnetRejectReason), 0x00, NULL, HFILL }\n        },\n        { &hf_BACnetAbortReason,\n          { \"Abort Reason\",           \"bacapp.abort_reason\",\n            FT_UINT8, BASE_DEC, VALS(BACnetAbortReason), 0x00, NULL, HFILL }\n        },\n        { &hf_BACnetApplicationTagNumber,\n          { \"Application Tag Number\",\n            \"bacapp.application_tag_number\",\n            FT_UINT8, BASE_DEC, VALS(BACnetApplicationTagNumber), 0xF0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetContextTagNumber,\n          { \"Context Tag Number\",\n            \"bacapp.context_tag_number\",\n            FT_UINT8, BASE_DEC, NULL, 0xF0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetExtendedTagNumber,\n          { \"Extended Tag Number\",\n            \"bacapp.extended_tag_number\",\n            FT_UINT8, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetNamedTag,\n          { \"Named Tag\",\n            \"bacapp.named_tag\",\n            FT_UINT8, BASE_DEC, VALS(BACnetTagNames), 0x07,\n            NULL, HFILL }\n        },\n        { &hf_BACnetCharacterSet,\n          { \"String Character Set\",\n            \"bacapp.string_character_set\",\n            FT_UINT8, BASE_DEC, VALS(BACnetCharacterSet), 0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetCodePage,\n          { \"Code Page\",\n            \"bacapp.code_page\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetTagClass,\n          { \"Tag Class\",           \"bacapp.tag_class\",\n            FT_BOOLEAN, 8, TFS(&BACnetTagClass), 0x08, NULL, HFILL }\n        },\n        { &hf_bacapp_tag_lvt,\n          { \"Length Value Type\",\n            \"bacapp.LVT\",\n            FT_UINT8, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_bacapp_tag_ProcessId,\n          { \"ProcessIdentifier\",           \"bacapp.processId\",\n            FT_UINT32, BASE_DEC, NULL, 0, \"Process Identifier\", HFILL }\n        },\n        { &hf_bacapp_tag_IPV4,\n          { \"IPV4\",           \"bacapp.IPV4\",\n            FT_IPv4, BASE_NONE, NULL, 0, \"IP-Address\", HFILL }\n        },\n        { &hf_bacapp_tag_IPV6,\n          { \"IPV6\",           \"bacapp.IPV6\",\n            FT_IPv6, BASE_NONE, NULL, 0, \"IP-Address\", HFILL }\n        },\n        { &hf_bacapp_tag_PORT,\n          { \"Port\",           \"bacapp.Port\",\n            FT_UINT16, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_tag_mac_address_broadcast,\n          { \"MAC-address: broadcast\",           \"bacapp.mac_address_broadcast\",\n            FT_NONE, BASE_NONE, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_reserved_ashrea,\n          { \"reserved for ASHRAE\",           \"bacapp.reserved_ashrea\",\n            FT_BYTES, BASE_NONE, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_unused_bits,\n          { \"Unused bits\",           \"bacapp.unused_bits\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_bit,\n          { \"bit\",           \"bacapp.bit\",\n            FT_BOOLEAN, 8, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_complete_bitstring,\n          { \"Complete bitstring\",           \"bacapp.complete_bitstring\",\n            FT_BYTES, BASE_NONE, NULL, 0, NULL, HFILL }\n        },\n        {&hf_msg_fragments,\n          { \"Message fragments\", \"bacapp.fragments\",\n            FT_NONE, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment,\n          { \"Message fragment\", \"bacapp.fragment\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_overlap,\n          { \"Message fragment overlap\", \"bacapp.fragment.overlap\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_overlap_conflicts,\n          { \"Message fragment overlapping with conflicting data\",\n            \"bacapp.fragment.overlap.conflicts\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_multiple_tails,\n          { \"Message has multiple tail fragments\",\n            \"bacapp.fragment.multiple_tails\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_too_long_fragment,\n          { \"Message fragment too long\", \"bacapp.fragment.too_long_fragment\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_error,\n          { \"Message defragmentation error\", \"bacapp.fragment.error\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_count,\n          { \"Message fragment count\", \"bacapp.fragment.count\",\n            FT_UINT32, BASE_DEC, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_reassembled_in,\n          { \"Reassembled in\", \"bacapp.reassembled.in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_reassembled_length,\n          { \"Reassembled BACapp length\", \"bacapp.reassembled.length\",\n            FT_UINT32, BASE_DEC, NULL, 0x00, NULL, HFILL } }\n    };\n    static gint *ett[] = {\n        &ett_bacapp,\n        &ett_bacapp_control,\n        &ett_bacapp_tag,\n        &ett_bacapp_list,\n        &ett_bacapp_value,\n        &ett_msg_fragment,\n        &ett_msg_fragments\n\n    };\n\n    static ei_register_info ei[] = {\n        { &ei_bacapp_bad_length, { \"bacapp.bad_length\", PI_MALFORMED, PI_ERROR, \"Wrong length indicated\", EXPFILL }},\n        { &ei_bacapp_bad_tag, { \"bacapp.bad_tag\", PI_MALFORMED, PI_ERROR, \"Wrong tag found\", EXPFILL }},\n        { &ei_bacapp_opening_tag, { \"bacapp.bad_opening_tag\", PI_MALFORMED, PI_ERROR, \"Expected Opening Tag!\", EXPFILL }},\n    };\n\n    expert_module_t* expert_bacapp;\n\n    proto_bacapp = proto_register_protocol(\"Building Automation and Control Network APDU\",\n                                           \"BACapp\", \"bacapp\");\n\n    proto_register_field_array(proto_bacapp, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n    expert_bacapp = expert_register_protocol(proto_bacapp);\n    expert_register_field_array(expert_bacapp, ei, array_length(ei));\n    register_dissector(\"bacapp\", dissect_bacapp, proto_bacapp);\n\n    reassembly_table_register(&msg_reassembly_table,\n                          &addresses_reassembly_table_functions);\n\n    bacapp_dissector_table = register_dissector_table(\"bacapp.vendor_identifier\",\n                                                      \"BACapp Vendor Identifier\", proto_bacapp,\n                                                      FT_UINT8, BASE_HEX);\n\n    /* Register BACnet Statistic trees */\n    register_bacapp_stat_trees();\n    bacapp_tap = register_tap(\"bacapp\"); /* BACnet statistics tap */\n}",
        "func": "void\nproto_register_bacapp(void)\n{\n    static hf_register_info hf[] = {\n        { &hf_bacapp_type,\n          { \"APDU Type\",           \"bacapp.type\",\n            FT_UINT8, BASE_DEC, VALS(BACnetTypeName), 0xf0, NULL, HFILL }\n        },\n        { &hf_bacapp_pduflags,\n          { \"PDU Flags\",          \"bacapp.pduflags\",\n            FT_UINT8, BASE_HEX, NULL, 0x0f, NULL, HFILL }\n        },\n        { &hf_bacapp_SEG,\n          { \"Segmented Request\",           \"bacapp.segmented_request\",\n            FT_BOOLEAN, 8, TFS(&segments_follow), 0x08, NULL, HFILL }\n        },\n        { &hf_bacapp_MOR,\n          { \"More Segments\",           \"bacapp.more_segments\",\n            FT_BOOLEAN, 8, TFS(&more_follow), 0x04, \"More Segments Follow\", HFILL }\n        },\n        { &hf_bacapp_SA,\n          { \"SA\",           \"bacapp.SA\",\n            FT_BOOLEAN, 8, TFS(&segmented_accept), 0x02, \"Segmented Response accepted\", HFILL }\n        },\n        { &hf_bacapp_max_adpu_size,\n          { \"Size of Maximum ADPU accepted\",           \"bacapp.max_adpu_size\",\n            FT_UINT8, BASE_DEC, VALS(BACnetMaxAPDULengthAccepted), 0x0f, NULL, HFILL }\n        },\n        { &hf_bacapp_response_segments,\n          { \"Max Response Segments accepted\",           \"bacapp.response_segments\",\n            FT_UINT8, BASE_DEC, VALS(BACnetMaxSegmentsAccepted), 0x70, NULL, HFILL }\n        },\n        { &hf_bacapp_objectType,\n          { \"Object Type\",           \"bacapp.objectType\",\n            FT_UINT32, BASE_DEC, VALS(BACnetObjectType), 0xffc00000, NULL, HFILL }\n        },\n        { &hf_bacapp_instanceNumber,\n          { \"Instance Number\",           \"bacapp.instance_number\",\n            FT_UINT32, BASE_DEC, NULL, 0x003fffff, NULL, HFILL }\n        },\n        { &hf_BACnetPropertyIdentifier,\n          { \"Property Identifier\", \"bacapp.property_identifier\",\n            FT_UINT32, BASE_DEC, VALS(BACnetPropertyIdentifier), 0, NULL, HFILL }\n        },\n        { &hf_BACnetVendorIdentifier,\n          { \"Vendor Identifier\", \"bacapp.vendor_identifier\",\n            FT_UINT16, BASE_DEC|BASE_EXT_STRING, &BACnetVendorIdentifiers_ext, 0, NULL, HFILL }\n        },\n        { &hf_BACnetRestartReason,\n          { \"Restart Reason\", \"bacapp.restart_reason\",\n            FT_UINT8, BASE_DEC, VALS(BACnetRestartReason), 0, NULL, HFILL }\n        },\n        { &hf_bacapp_invoke_id,\n          { \"Invoke ID\",           \"bacapp.invoke_id\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_sequence_number,\n          { \"Sequence Number\",           \"bacapp.sequence_number\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_window_size,\n          { \"Proposed Window Size\",           \"bacapp.window_size\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_service,\n          { \"Service Choice\",           \"bacapp.confirmed_service\",\n            FT_UINT8, BASE_DEC, VALS(BACnetConfirmedServiceChoice), 0x00, NULL, HFILL }\n        },\n        { &hf_bacapp_uservice,\n          { \"Unconfirmed Service Choice\",           \"bacapp.unconfirmed_service\",\n            FT_UINT8, BASE_DEC, VALS(BACnetUnconfirmedServiceChoice), 0x00, NULL, HFILL }\n        },\n        { &hf_bacapp_NAK,\n          { \"NAK\",           \"bacapp.NAK\",\n            FT_BOOLEAN, 8, NULL, 0x02, \"negative ACK\", HFILL }\n        },\n        { &hf_bacapp_SRV,\n          { \"SRV\",           \"bacapp.SRV\",\n            FT_BOOLEAN, 8, NULL, 0x01, \"Server\", HFILL }\n        },\n        { &hf_Device_Instance_Range_Low_Limit,\n          { \"Device Instance Range Low Limit\", \"bacapp.who_is.low_limit\",\n            FT_UINT32, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_Device_Instance_Range_High_Limit,\n          { \"Device Instance Range High Limit\", \"bacapp.who_is.high_limit\",\n            FT_UINT32, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_BACnetRejectReason,\n          { \"Reject Reason\",           \"bacapp.reject_reason\",\n            FT_UINT8, BASE_DEC, VALS(BACnetRejectReason), 0x00, NULL, HFILL }\n        },\n        { &hf_BACnetAbortReason,\n          { \"Abort Reason\",           \"bacapp.abort_reason\",\n            FT_UINT8, BASE_DEC, VALS(BACnetAbortReason), 0x00, NULL, HFILL }\n        },\n        { &hf_BACnetApplicationTagNumber,\n          { \"Application Tag Number\",\n            \"bacapp.application_tag_number\",\n            FT_UINT8, BASE_DEC, VALS(BACnetApplicationTagNumber), 0xF0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetContextTagNumber,\n          { \"Context Tag Number\",\n            \"bacapp.context_tag_number\",\n            FT_UINT8, BASE_DEC, NULL, 0xF0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetExtendedTagNumber,\n          { \"Extended Tag Number\",\n            \"bacapp.extended_tag_number\",\n            FT_UINT8, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetNamedTag,\n          { \"Named Tag\",\n            \"bacapp.named_tag\",\n            FT_UINT8, BASE_DEC, VALS(BACnetTagNames), 0x07,\n            NULL, HFILL }\n        },\n        { &hf_BACnetCharacterSet,\n          { \"String Character Set\",\n            \"bacapp.string_character_set\",\n            FT_UINT8, BASE_DEC, VALS(BACnetCharacterSet), 0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetCodePage,\n          { \"Code Page\",\n            \"bacapp.code_page\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_BACnetTagClass,\n          { \"Tag Class\",           \"bacapp.tag_class\",\n            FT_BOOLEAN, 8, TFS(&BACnetTagClass), 0x08, NULL, HFILL }\n        },\n        { &hf_bacapp_tag_lvt,\n          { \"Length Value Type\",\n            \"bacapp.LVT\",\n            FT_UINT8, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_bacapp_tag_ProcessId,\n          { \"ProcessIdentifier\",           \"bacapp.processId\",\n            FT_UINT32, BASE_DEC, NULL, 0, \"Process Identifier\", HFILL }\n        },\n        { &hf_bacapp_tag_IPV4,\n          { \"IPV4\",           \"bacapp.IPV4\",\n            FT_IPv4, BASE_NONE, NULL, 0, \"IP-Address\", HFILL }\n        },\n        { &hf_bacapp_tag_IPV6,\n          { \"IPV6\",           \"bacapp.IPV6\",\n            FT_IPv6, BASE_NONE, NULL, 0, \"IP-Address\", HFILL }\n        },\n        { &hf_bacapp_tag_PORT,\n          { \"Port\",           \"bacapp.Port\",\n            FT_UINT16, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_tag_mac_address_broadcast,\n          { \"MAC-address: broadcast\",           \"bacapp.mac_address_broadcast\",\n            FT_NONE, BASE_NONE, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_reserved_ashrea,\n          { \"reserved for ASHRAE\",           \"bacapp.reserved_ashrea\",\n            FT_BYTES, BASE_NONE, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_unused_bits,\n          { \"Unused bits\",           \"bacapp.unused_bits\",\n            FT_UINT8, BASE_DEC, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_bit,\n          { \"bit\",           \"bacapp.bit\",\n            FT_BOOLEAN, 8, NULL, 0, NULL, HFILL }\n        },\n        { &hf_bacapp_complete_bitstring,\n          { \"Complete bitstring\",           \"bacapp.complete_bitstring\",\n            FT_BYTES, BASE_NONE, NULL, 0, NULL, HFILL }\n        },\n        {&hf_msg_fragments,\n          { \"Message fragments\", \"bacapp.fragments\",\n            FT_NONE, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment,\n          { \"Message fragment\", \"bacapp.fragment\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_overlap,\n          { \"Message fragment overlap\", \"bacapp.fragment.overlap\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_overlap_conflicts,\n          { \"Message fragment overlapping with conflicting data\",\n            \"bacapp.fragment.overlap.conflicts\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_multiple_tails,\n          { \"Message has multiple tail fragments\",\n            \"bacapp.fragment.multiple_tails\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_too_long_fragment,\n          { \"Message fragment too long\", \"bacapp.fragment.too_long_fragment\",\n            FT_BOOLEAN, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_error,\n          { \"Message defragmentation error\", \"bacapp.fragment.error\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_fragment_count,\n          { \"Message fragment count\", \"bacapp.fragment.count\",\n            FT_UINT32, BASE_DEC, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_reassembled_in,\n          { \"Reassembled in\", \"bacapp.reassembled.in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x00, NULL, HFILL } },\n        {&hf_msg_reassembled_length,\n          { \"Reassembled BACapp length\", \"bacapp.reassembled.length\",\n            FT_UINT32, BASE_DEC, NULL, 0x00, NULL, HFILL } }\n    };\n    static gint *ett[] = {\n        &ett_bacapp,\n        &ett_bacapp_control,\n        &ett_bacapp_tag,\n        &ett_bacapp_list,\n        &ett_bacapp_value,\n        &ett_msg_fragment,\n        &ett_msg_fragments\n\n    };\n\n    static ei_register_info ei[] = {\n        { &ei_bacapp_bad_length, { \"bacapp.bad_length\", PI_MALFORMED, PI_ERROR, \"Wrong length indicated\", EXPFILL }},\n        { &ei_bacapp_bad_tag, { \"bacapp.bad_tag\", PI_MALFORMED, PI_ERROR, \"Wrong tag found\", EXPFILL }},\n        { &ei_bacapp_opening_tag, { \"bacapp.bad_opening_tag\", PI_MALFORMED, PI_ERROR, \"Expected Opening Tag!\", EXPFILL }},\n        { &ei_bacapp_max_recursion_depth_reached, { \"bacapp.max_recursion_depth_reached\",\n            PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached. Dissection stopped.\", EXPFILL }}\n    };\n\n    expert_module_t* expert_bacapp;\n\n    proto_bacapp = proto_register_protocol(\"Building Automation and Control Network APDU\",\n                                           \"BACapp\", \"bacapp\");\n\n    proto_register_field_array(proto_bacapp, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n    expert_bacapp = expert_register_protocol(proto_bacapp);\n    expert_register_field_array(expert_bacapp, ei, array_length(ei));\n    register_dissector(\"bacapp\", dissect_bacapp, proto_bacapp);\n\n    reassembly_table_register(&msg_reassembly_table,\n                          &addresses_reassembly_table_functions);\n\n    bacapp_dissector_table = register_dissector_table(\"bacapp.vendor_identifier\",\n                                                      \"BACapp Vendor Identifier\", proto_bacapp,\n                                                      FT_UINT8, BASE_HEX);\n\n    /* Register BACnet Statistic trees */\n    register_bacapp_stat_trees();\n    bacapp_tap = register_tap(\"bacapp\"); /* BACnet statistics tap */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -224,6 +224,8 @@\n         { &ei_bacapp_bad_length, { \"bacapp.bad_length\", PI_MALFORMED, PI_ERROR, \"Wrong length indicated\", EXPFILL }},\n         { &ei_bacapp_bad_tag, { \"bacapp.bad_tag\", PI_MALFORMED, PI_ERROR, \"Wrong tag found\", EXPFILL }},\n         { &ei_bacapp_opening_tag, { \"bacapp.bad_opening_tag\", PI_MALFORMED, PI_ERROR, \"Expected Opening Tag!\", EXPFILL }},\n+        { &ei_bacapp_max_recursion_depth_reached, { \"bacapp.max_recursion_depth_reached\",\n+            PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached. Dissection stopped.\", EXPFILL }}\n     };\n \n     expert_module_t* expert_bacapp;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        { &ei_bacapp_max_recursion_depth_reached, { \"bacapp.max_recursion_depth_reached\",",
                "            PI_PROTOCOL, PI_WARN, \"Maximum allowed recursion depth reached. Dissection stopped.\", EXPFILL }}"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-11647",
        "func_name": "wireshark/dissect_bacapp",
        "description": "In Wireshark 3.2.0 to 3.2.2, 3.0.0 to 3.0.9, and 2.6.0 to 2.6.15, the BACapp dissector could crash. This was addressed in epan/dissectors/packet-bacapp.c by limiting the amount of recursion.",
        "git_url": "https://github.com/wireshark/wireshark/commit/6f56fc9496db158218243ea87e3660c874a0bab0",
        "commit_title": "BACapp: Add a nesting / recursion check.",
        "commit_text": " Track our recursion depth in fAbstractSyntaxNType. It calls several functions which in turn call it, which makes it easy to overflow the stack.  Bug: 16474 (cherry picked from commit 15dc2f6bd4c9a674333cbc97260362524d5364de)",
        "func_before": "static int\ndissect_bacapp(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, void* data _U_)\n{\n    guint8      flag, bacapp_type;\n    guint       save_fragmented  = FALSE, data_offset = 0, /*bacapp_apdu_size,*/ fragment = FALSE;\n    tvbuff_t   *new_tvb          = NULL;\n    guint       offset           = 0;\n    guint8      bacapp_seqno     = 0;\n    guint8      bacapp_service, bacapp_reason/*, bacapp_prop_win_size*/;\n    guint8      bacapp_invoke_id = 0;\n    proto_item *ti;\n    proto_tree *bacapp_tree      = NULL;\n\n    gint        svc = 0;\n    proto_item *tt  = 0;\n    gint8       ack = 0;\n\n    /* Strings for BACnet Statistics */\n    const gchar errstr[]       = \"ERROR: \";\n    const gchar rejstr[]       = \"REJECTED: \";\n    const gchar abortstr[]     = \"ABORTED: \";\n    const gchar sackstr[]      = \" (SimpleAck)\";\n    const gchar cackstr[]      = \" (ComplexAck)\";\n    const gchar uconfsreqstr[] = \" (Unconfirmed Service Request)\";\n    const gchar confsreqstr[]  = \" (Confirmed Service Request)\";\n\n    col_set_str(pinfo->cinfo, COL_PROTOCOL, \"BACnet-APDU\");\n    col_clear(pinfo->cinfo, COL_INFO);\n\n    flag = tvb_get_guint8(tvb, 0);\n    bacapp_type = (flag >> 4) & 0x0f;\n\n    /* show some descriptive text in the INFO column */\n    col_add_fstr(pinfo->cinfo, COL_INFO, \"%-16s\",\n        val_to_str_const(bacapp_type, BACnetTypeName, \"# unknown APDU #\"));\n\n    bacinfo.service_type = NULL;\n    bacinfo.invoke_id = NULL;\n    bacinfo.instance_ident = NULL;\n    bacinfo.object_ident = NULL;\n\n    switch (bacapp_type) {\n    case BACAPP_TYPE_CONFIRMED_SERVICE_REQUEST:\n        /* segmented messages have 2 additional bytes */\n        if (flag & BACAPP_SEGMENTED_REQUEST) {\n            fragment = TRUE;\n            ack = 0;\n            /* bacapp_apdu_size = fGetMaxAPDUSize(tvb_get_guint8(tvb, offset + 1)); */ /* has 16 values, reserved are 50 Bytes */\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 2);\n            bacapp_seqno = tvb_get_guint8(tvb, offset + 3);\n            /* bacapp_prop_win_size = tvb_get_guint8(tvb, offset + 4); */\n            bacapp_service = tvb_get_guint8(tvb, offset + 5);\n            data_offset = 6;\n        } else {\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 2);\n            bacapp_service = tvb_get_guint8(tvb, offset + 3);\n        }\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \",\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             confsreqstr, NULL));\n        break;\n    case BACAPP_TYPE_UNCONFIRMED_SERVICE_REQUEST:\n        bacapp_service = tvb_get_guint8(tvb, offset + 1);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s \",\n                        val_to_str_const(bacapp_service,\n                                         BACnetUnconfirmedServiceChoice,\n                                         bacapp_unknown_service_str));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetUnconfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             uconfsreqstr, NULL));\n        break;\n    case BACAPP_TYPE_SIMPLE_ACK:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_service = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(),\n                                                 \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             sackstr, NULL));\n        break;\n    case BACAPP_TYPE_COMPLEX_ACK:\n        /* segmented messages have 2 additional bytes */\n        if (flag & BACAPP_SEGMENTED_REQUEST) {\n            fragment = TRUE;\n            ack = 1;\n            /* bacapp_apdu_size = fGetMaxAPDUSize(0); */ /* has minimum of 50 Bytes */\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n            bacapp_seqno = tvb_get_guint8(tvb, offset + 2);\n            /* bacapp_prop_win_size = tvb_get_guint8(tvb, offset + 3); */\n            bacapp_service = tvb_get_guint8(tvb, offset + 4);\n            data_offset = 5;\n        } else {\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n            bacapp_service = tvb_get_guint8(tvb, offset + 2);\n        }\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             cackstr, NULL));\n        break;\n    case BACAPP_TYPE_SEGMENT_ACK:\n        /* nothing more to add */\n        break;\n    case BACAPP_TYPE_ERROR:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_service = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             errstr,\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             NULL));\n        break;\n    case BACAPP_TYPE_REJECT:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_reason = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_split_str(bacapp_reason,\n                                         64,\n                                         BACnetRejectReason,\n                                         ASHRAE_Reserved_Fmt,\n                                         Vendor_Proprietary_Fmt), bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(), rejstr,\n                                             val_to_split_str(bacapp_reason, 64,\n                                                              BACnetRejectReason,\n                                                              ASHRAE_Reserved_Fmt,\n                                                              Vendor_Proprietary_Fmt),\n                                             NULL));\n        break;\n    case BACAPP_TYPE_ABORT:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_reason = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_split_str(bacapp_reason,\n                                         64,\n                                         BACnetAbortReason,\n                                         ASHRAE_Reserved_Fmt,\n                                         Vendor_Proprietary_Fmt), bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(), abortstr,\n                                             val_to_split_str(bacapp_reason,\n                                                              64,\n                                                              BACnetAbortReason,\n                                                              ASHRAE_Reserved_Fmt,\n                                                              Vendor_Proprietary_Fmt),\n                                             NULL));\n        break;\n        /* UNKNOWN */\n    default:\n        /* nothing more to add */\n        break;\n    }\n\n    save_fragmented = pinfo->fragmented;\n\n    ti = proto_tree_add_item(tree, proto_bacapp, tvb, offset, -1, ENC_NA);\n    bacapp_tree = proto_item_add_subtree(ti, ett_bacapp);\n\n    if (!fragment)\n        do_the_dissection(tvb, pinfo, bacapp_tree);\n    else\n        fStartConfirmed(tvb, pinfo, bacapp_tree, offset, ack, &svc, &tt);\n            /* not resetting the offset so the remaining can be done */\n\n    if (fragment) { /* fragmented */\n        fragment_head *frag_msg;\n\n        pinfo->fragmented = TRUE;\n\n        frag_msg = fragment_add_seq_check(&msg_reassembly_table,\n            tvb, data_offset,\n            pinfo,\n            bacapp_invoke_id,      /* ID for fragments belonging together */\n            NULL,\n            bacapp_seqno,          /* fragment sequence number */\n            tvb_reported_length_remaining(tvb, data_offset), /* fragment length - to the end */\n            flag & BACAPP_MORE_SEGMENTS); /* Last fragment reached? */\n        new_tvb = process_reassembled_data(tvb, data_offset, pinfo,\n                \"Reassembled BACapp\", frag_msg, &msg_frag_items,\n                NULL, tree);\n\n        if (new_tvb) { /* Reassembled */\n            col_append_str(pinfo->cinfo, COL_INFO,\n                           \" (Message Reassembled)\");\n        } else { /* Not last packet of reassembled Short Message */\n            col_append_fstr(pinfo->cinfo, COL_INFO,\n                            \" (Message fragment %u)\", bacapp_seqno);\n        }\n        if (new_tvb) { /* take it all */\n            switch (bacapp_type) {\n            case BACAPP_TYPE_CONFIRMED_SERVICE_REQUEST:\n                fContinueConfirmedRequestPDU(new_tvb, pinfo, bacapp_tree, 0, svc);\n                break;\n            case BACAPP_TYPE_COMPLEX_ACK:\n                fContinueComplexAckPDU(new_tvb, pinfo, bacapp_tree, 0, svc);\n                break;\n            default:\n                /* do nothing */\n                break;\n            }\n        }\n    }\n\n    pinfo->fragmented = save_fragmented;\n\n    /* tapping */\n    tap_queue_packet(bacapp_tap, pinfo, &bacinfo);\n    return tvb_captured_length(tvb);\n}",
        "func": "static int\ndissect_bacapp(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, void* data _U_)\n{\n    guint8      flag, bacapp_type;\n    guint       save_fragmented  = FALSE, data_offset = 0, /*bacapp_apdu_size,*/ fragment = FALSE;\n    tvbuff_t   *new_tvb          = NULL;\n    guint       offset           = 0;\n    guint8      bacapp_seqno     = 0;\n    guint8      bacapp_service, bacapp_reason/*, bacapp_prop_win_size*/;\n    guint8      bacapp_invoke_id = 0;\n    proto_item *ti;\n    proto_tree *bacapp_tree      = NULL;\n\n    gint        svc = 0;\n    proto_item *tt  = 0;\n    gint8       ack = 0;\n\n    /* Strings for BACnet Statistics */\n    const gchar errstr[]       = \"ERROR: \";\n    const gchar rejstr[]       = \"REJECTED: \";\n    const gchar abortstr[]     = \"ABORTED: \";\n    const gchar sackstr[]      = \" (SimpleAck)\";\n    const gchar cackstr[]      = \" (ComplexAck)\";\n    const gchar uconfsreqstr[] = \" (Unconfirmed Service Request)\";\n    const gchar confsreqstr[]  = \" (Confirmed Service Request)\";\n\n    col_set_str(pinfo->cinfo, COL_PROTOCOL, \"BACnet-APDU\");\n    col_clear(pinfo->cinfo, COL_INFO);\n\n    flag = tvb_get_guint8(tvb, 0);\n    bacapp_type = (flag >> 4) & 0x0f;\n\n    /* show some descriptive text in the INFO column */\n    col_add_fstr(pinfo->cinfo, COL_INFO, \"%-16s\",\n        val_to_str_const(bacapp_type, BACnetTypeName, \"# unknown APDU #\"));\n\n    bacinfo.service_type = NULL;\n    bacinfo.invoke_id = NULL;\n    bacinfo.instance_ident = NULL;\n    bacinfo.object_ident = NULL;\n\n    /* Recursion depth */\n    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(0));\n\n    switch (bacapp_type) {\n    case BACAPP_TYPE_CONFIRMED_SERVICE_REQUEST:\n        /* segmented messages have 2 additional bytes */\n        if (flag & BACAPP_SEGMENTED_REQUEST) {\n            fragment = TRUE;\n            ack = 0;\n            /* bacapp_apdu_size = fGetMaxAPDUSize(tvb_get_guint8(tvb, offset + 1)); */ /* has 16 values, reserved are 50 Bytes */\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 2);\n            bacapp_seqno = tvb_get_guint8(tvb, offset + 3);\n            /* bacapp_prop_win_size = tvb_get_guint8(tvb, offset + 4); */\n            bacapp_service = tvb_get_guint8(tvb, offset + 5);\n            data_offset = 6;\n        } else {\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 2);\n            bacapp_service = tvb_get_guint8(tvb, offset + 3);\n        }\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \",\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             confsreqstr, NULL));\n        break;\n    case BACAPP_TYPE_UNCONFIRMED_SERVICE_REQUEST:\n        bacapp_service = tvb_get_guint8(tvb, offset + 1);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s \",\n                        val_to_str_const(bacapp_service,\n                                         BACnetUnconfirmedServiceChoice,\n                                         bacapp_unknown_service_str));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetUnconfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             uconfsreqstr, NULL));\n        break;\n    case BACAPP_TYPE_SIMPLE_ACK:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_service = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(),\n                                                 \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             sackstr, NULL));\n        break;\n    case BACAPP_TYPE_COMPLEX_ACK:\n        /* segmented messages have 2 additional bytes */\n        if (flag & BACAPP_SEGMENTED_REQUEST) {\n            fragment = TRUE;\n            ack = 1;\n            /* bacapp_apdu_size = fGetMaxAPDUSize(0); */ /* has minimum of 50 Bytes */\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n            bacapp_seqno = tvb_get_guint8(tvb, offset + 2);\n            /* bacapp_prop_win_size = tvb_get_guint8(tvb, offset + 3); */\n            bacapp_service = tvb_get_guint8(tvb, offset + 4);\n            data_offset = 5;\n        } else {\n            bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n            bacapp_service = tvb_get_guint8(tvb, offset + 2);\n        }\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             cackstr, NULL));\n        break;\n    case BACAPP_TYPE_SEGMENT_ACK:\n        /* nothing more to add */\n        break;\n    case BACAPP_TYPE_ERROR:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_service = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_str_const(bacapp_service,\n                                         BACnetConfirmedServiceChoice,\n                                         bacapp_unknown_service_str),\n                        bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(),\n                                             errstr,\n                                             val_to_str_const(bacapp_service,\n                                                              BACnetConfirmedServiceChoice,\n                                                              bacapp_unknown_service_str),\n                                             NULL));\n        break;\n    case BACAPP_TYPE_REJECT:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_reason = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_split_str(bacapp_reason,\n                                         64,\n                                         BACnetRejectReason,\n                                         ASHRAE_Reserved_Fmt,\n                                         Vendor_Proprietary_Fmt), bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(), rejstr,\n                                             val_to_split_str(bacapp_reason, 64,\n                                                              BACnetRejectReason,\n                                                              ASHRAE_Reserved_Fmt,\n                                                              Vendor_Proprietary_Fmt),\n                                             NULL));\n        break;\n    case BACAPP_TYPE_ABORT:\n        bacapp_invoke_id = tvb_get_guint8(tvb, offset + 1);\n        bacapp_reason = tvb_get_guint8(tvb, offset + 2);\n        col_append_fstr(pinfo->cinfo, COL_INFO, \"%s[%3u] \", /* \"original-invokeID\" replaced */\n                        val_to_split_str(bacapp_reason,\n                                         64,\n                                         BACnetAbortReason,\n                                         ASHRAE_Reserved_Fmt,\n                                         Vendor_Proprietary_Fmt), bacapp_invoke_id);\n\n        updateBacnetInfoValue(BACINFO_INVOKEID,\n                              wmem_strdup_printf(wmem_packet_scope(), \"Invoke ID: %d\", bacapp_invoke_id));\n\n        updateBacnetInfoValue(BACINFO_SERVICE,\n                              wmem_strconcat(wmem_packet_scope(), abortstr,\n                                             val_to_split_str(bacapp_reason,\n                                                              64,\n                                                              BACnetAbortReason,\n                                                              ASHRAE_Reserved_Fmt,\n                                                              Vendor_Proprietary_Fmt),\n                                             NULL));\n        break;\n        /* UNKNOWN */\n    default:\n        /* nothing more to add */\n        break;\n    }\n\n    save_fragmented = pinfo->fragmented;\n\n    ti = proto_tree_add_item(tree, proto_bacapp, tvb, offset, -1, ENC_NA);\n    bacapp_tree = proto_item_add_subtree(ti, ett_bacapp);\n\n    if (!fragment)\n        do_the_dissection(tvb, pinfo, bacapp_tree);\n    else\n        fStartConfirmed(tvb, pinfo, bacapp_tree, offset, ack, &svc, &tt);\n            /* not resetting the offset so the remaining can be done */\n\n    if (fragment) { /* fragmented */\n        fragment_head *frag_msg;\n\n        pinfo->fragmented = TRUE;\n\n        frag_msg = fragment_add_seq_check(&msg_reassembly_table,\n            tvb, data_offset,\n            pinfo,\n            bacapp_invoke_id,      /* ID for fragments belonging together */\n            NULL,\n            bacapp_seqno,          /* fragment sequence number */\n            tvb_reported_length_remaining(tvb, data_offset), /* fragment length - to the end */\n            flag & BACAPP_MORE_SEGMENTS); /* Last fragment reached? */\n        new_tvb = process_reassembled_data(tvb, data_offset, pinfo,\n                \"Reassembled BACapp\", frag_msg, &msg_frag_items,\n                NULL, tree);\n\n        if (new_tvb) { /* Reassembled */\n            col_append_str(pinfo->cinfo, COL_INFO,\n                           \" (Message Reassembled)\");\n        } else { /* Not last packet of reassembled Short Message */\n            col_append_fstr(pinfo->cinfo, COL_INFO,\n                            \" (Message fragment %u)\", bacapp_seqno);\n        }\n        if (new_tvb) { /* take it all */\n            switch (bacapp_type) {\n            case BACAPP_TYPE_CONFIRMED_SERVICE_REQUEST:\n                fContinueConfirmedRequestPDU(new_tvb, pinfo, bacapp_tree, 0, svc);\n                break;\n            case BACAPP_TYPE_COMPLEX_ACK:\n                fContinueComplexAckPDU(new_tvb, pinfo, bacapp_tree, 0, svc);\n                break;\n            default:\n                /* do nothing */\n                break;\n            }\n        }\n    }\n\n    pinfo->fragmented = save_fragmented;\n\n    /* tapping */\n    tap_queue_packet(bacapp_tap, pinfo, &bacinfo);\n    return tvb_captured_length(tvb);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,6 +38,9 @@\n     bacinfo.invoke_id = NULL;\n     bacinfo.instance_ident = NULL;\n     bacinfo.object_ident = NULL;\n+\n+    /* Recursion depth */\n+    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(0));\n \n     switch (bacapp_type) {\n     case BACAPP_TYPE_CONFIRMED_SERVICE_REQUEST:",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    /* Recursion depth */",
                "    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(0));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-11647",
        "func_name": "wireshark/fAbstractSyntaxNType",
        "description": "In Wireshark 3.2.0 to 3.2.2, 3.0.0 to 3.0.9, and 2.6.0 to 2.6.15, the BACapp dissector could crash. This was addressed in epan/dissectors/packet-bacapp.c by limiting the amount of recursion.",
        "git_url": "https://github.com/wireshark/wireshark/commit/6f56fc9496db158218243ea87e3660c874a0bab0",
        "commit_title": "BACapp: Add a nesting / recursion check.",
        "commit_text": " Track our recursion depth in fAbstractSyntaxNType. It calls several functions which in turn call it, which makes it easy to overflow the stack.  Bug: 16474 (cherry picked from commit 15dc2f6bd4c9a674333cbc97260362524d5364de)",
        "func_before": "static guint\nfAbstractSyntaxNType(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset)\n{\n    guint8  tag_no, tag_info;\n    guint32 lvt;\n    guint   lastoffset = 0, depth = 0;\n    char    ar[256];\n    guint32 save_object_type;\n    gboolean do_default_handling;\n\n    if (propertyIdentifier >= 0) {\n        g_snprintf(ar, sizeof(ar), \"%s: \",\n            val_to_split_str(propertyIdentifier, 512,\n                BACnetPropertyIdentifier,\n                ASHRAE_Reserved_Fmt,\n                Vendor_Proprietary_Fmt));\n    } else {\n        g_snprintf(ar, sizeof(ar), \"Abstract Type: \");\n    }\n    while (tvb_reported_length_remaining(tvb, offset) > 0) {  /* exit loop if nothing happens inside */\n        lastoffset = offset;\n        fTagHeader(tvb, pinfo, offset, &tag_no, &tag_info, &lvt);\n        if (tag_is_closing(tag_info)) { /* closing tag, but not for me */\n            if (depth <= 0) return offset;\n        }\n\n        do_default_handling = FALSE;\n\n        /* Application Tags */\n        switch (propertyIdentifier) {\n        case 0: /* acked-transitions */\n        case 35: /* event-enable */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n            BACnetAcknowledgedTransitions);\n            break;\n        case 2: /* action */\n                /* loop object is application tagged,\n                    command object is context tagged */\n                if (tag_is_context_specific(tag_info)) {\n                    /* BACnetActionList */\n                    offset = fActionList(tvb, pinfo, tree, offset);\n                } else {\n                    /* BACnetAction */\n                    offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                        BACnetAction);\n                }\n                break;\n        case 7: /* alarm-values*/\n            switch (object_type) {\n            case 21: /* life-point */\n            case 22: /* life-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n              break;\n            case 30: /* access-door */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n              break;\n            case 31: /* timer */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerState);\n              break;\n            case 36: /* access-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessZoneOccupancyState);\n              break;\n            case 39: /* bitstring-value */\n            default:\n              if (tag_info) {\n                if (tag_is_opening(tag_info)) {\n                  ++depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else if (tag_is_closing(tag_info)) {\n                  --depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else {\n                  offset = fContextTaggedValue(tvb, pinfo, tree, offset, ar);\n                }\n              }\n              else {\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n              }\n              break;\n            }\n            break;\n        case 37: /* event-type */\n          offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEventType);\n          break;\n        case 39: /* fault-values */\n            switch (object_type) {\n            case 21: /* life-point */\n            case 22: /* life-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n              break;\n            case 30: /* access-door */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n              break;\n            case 31: /* timer */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerState);\n              break;\n            case 36: /* access-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessZoneOccupancyState);\n              break;\n            case 39: /* bitstring-value */\n            default:\n              if (tag_info) {\n                if (tag_is_opening(tag_info)) {\n                  ++depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else if (tag_is_closing(tag_info)) {\n                  --depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else {\n                  offset = fContextTaggedValue(tvb, pinfo, tree, offset, ar);\n                }\n              }\n              else {\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n              }\n              break;\n            }\n            break;\n        case 30: /* BACnetAddressBinding */\n        case 331: /* last-key-server */\n            offset = fAddressBinding(tvb, pinfo, tree, offset);\n            break;\n        case 52: /* limit-enable */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLimitEnable);\n            break;\n        case 54: /* list of object property reference */\n            offset = fLOPR(tvb, pinfo, tree, offset);\n            break;\n        case 55: /* list-of-session-keys */\n            fSessionKey(tvb, pinfo, tree, offset);\n            break;\n        case 79: /* object-type */\n        case 96: /* protocol-object-types-supported */\n            offset = fApplicationTypesEnumeratedSplit(tvb, pinfo, tree, offset, ar,\n                BACnetObjectType, 128);\n            break;\n        case 97: /* Protocol-Services-Supported */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetServicesSupported);\n            break;\n        case 102: /* recipient-list */\n            offset = fDestination(tvb, pinfo, tree, offset);\n            break;\n        case 107: /* segmentation-supported */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetSegmentation);\n            break;\n        case 111: /* Status-Flags */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetStatusFlags);\n            break;\n        case 112: /* System-Status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetDeviceStatus);\n            break;\n        case 117: /* units */\n        case 455: /* car-load-units */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetEngineeringUnits);\n            break;\n        case 87:    /* priority-array -- accessed as a BACnetARRAY */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fPriorityArray(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 38:    /* exception-schedule */\n            if (object_type < 128) {\n                if (propertyArrayIndex == 0) {\n                    /* BACnetARRAY index 0 refers to the length\n                    of the array, not the elements of the array */\n                    offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n                } else {\n                    offset = fSpecialEvent(tvb, pinfo, tree, offset);\n                }\n            }\n            break;\n        case 19:  /* controlled-variable-reference */\n        case 60:  /* manipulated-variable-reference */\n        case 78:  /* object-property-reference */\n        case 181: /* input-reference */\n        case 355: /* event-algorithm-inhibit-reference */\n            offset = fObjectPropertyReference(tvb, pinfo, tree, offset);\n            break;\n        case 132: /* log-device-object-property */\n            offset = fDeviceObjectPropertyReference(tvb, pinfo, tree, offset);\n            break;\n        case 109: /* Setpoint-Reference */\n            /* setpoint-Reference is actually BACnetSetpointReference which is a SEQ of [0] */\n            offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n            offset = fBACnetObjectPropertyReference(tvb, pinfo, tree, offset);\n            offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n            break;\n        case 123:   /* weekly-schedule -- accessed as a BACnetARRAY */\n            if (object_type < 128) {\n                if (propertyArrayIndex == 0) {\n                    /* BACnetARRAY index 0 refers to the length\n                    of the array, not the elements of the array */\n                    offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n                } else {\n                    offset = fWeeklySchedule(tvb, pinfo, tree, offset);\n                }\n            }\n            break;\n        case 127:   /* client COV increment */\n            offset = fClientCOV(tvb, pinfo, tree, offset);\n            break;\n        case 131:  /* log-buffer */\n            if ( object_type == 25 )\n                offset = fEventLogRecord(tvb, pinfo, tree, offset);\n            else if ( object_type == 27 )\n                offset = fLogMultipleRecord(tvb, pinfo, tree, offset);\n            else\n                offset = fLogRecord(tvb, pinfo, tree, offset);\n            break;\n        case 159: /* member-of */\n        case 165: /* zone-members */\n        case 211: /* subordinate-list */\n        case 246: /* access-doors */\n        case 249: /* access-event-credential */\n        case 252: /* accompaniment */\n        case 265: /* credentials */\n        case 266: /* credentials-in-zone */\n        case 277: /* last-credential-added */\n        case 279: /* last-credential-removed */\n        case 286: /* members */\n        case 320: /* zone-from */\n        case 321: /* zone-to */\n        case 461: /* energy-meter-ref */\n        case 491: /* represents */\n            offset = fDeviceObjectReference(tvb, pinfo, tree, offset);\n            break;\n        case 196: /* last-restart-reason */\n            offset = fRestartReason(tvb, pinfo, tree, offset);\n            break;\n        case 212: /* actual-shed-level */\n        case 214: /* expected-shed-level */\n        case 218: /* requested-shed-level */\n            offset = fShedLevel(tvb, pinfo, tree, offset);\n            break;\n        case 152: /* active-cov-subscriptions */\n            offset = fCOVSubscription(tvb, pinfo, tree, offset);\n            break;\n        case 23: /* date-list */\n            offset = fCalendarEntry(tvb, pinfo, tree, offset);\n            break;\n        case 116: /* time-sychronization-recipients */\n        case 206: /* utc-time-synchronization-recipients */\n        case 202: /* restart-notification-recipients */\n            offset = fRecipient(tvb, pinfo, tree, offset);\n            break;\n        case 83: /* event-parameters */\n            offset = fEventParameter(tvb, pinfo, tree, offset);\n            break;\n        case 130: /* event-time-stamp */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fEventTimeStamps(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 197: /* logging-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLoggingType);\n            break;\n        case 36: /* event-state */\n            offset = fApplicationTypesEnumeratedSplit(tvb, pinfo, tree, offset, ar, BACnetEventState, 64);\n            break;\n        case 103: /* reliability */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetReliability);\n            break;\n        case 72: /* notify-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNotifyType);\n            break;\n        case 208: /* node-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNodeType);\n            break;\n        case 231: /* door-status */\n        case 450: /* car-door-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorStatus);\n            break;\n        case 233: /* lock-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLockStatus);\n            break;\n        case 235: /* secured-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorSecuredStatus);\n            break;\n        case 158: /* maintenance-required */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetMaintenance);\n            break;\n        case 92: /* program-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProgramState);\n            break;\n        case 90: /* program-change */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProgramRequest);\n            break;\n        case 100: /* reason-for-halt */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProgramError);\n            break;\n        case 160: /* mode */\n        case 175: /* accepted-modes */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyMode);\n            break;\n        case 163: /* silenced */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetSilencedState);\n            break;\n        case 161: /* operation-expected */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyOperation);\n            break;\n        case 164: /* tracking-value */\n        case 166: /* life-safety-alarm-values */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n            break;\n        case 41: /* file-access-method */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetFileAccessMethod);\n            break;\n        case 185:  /* prescale */\n            offset = fPrescale(tvb, pinfo, tree, offset);\n            break;\n        case 187:  /* scale */\n            offset = fScale(tvb, pinfo, tree, offset);\n            break;\n        case 189: /* update-time */\n            if (object_type == 37)\n                offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            else\n                offset = fDateTime(tvb, pinfo, tree, offset, ar);\n            break;\n        case 184: /* logging-record */\n            offset = fLoggingRecord(tvb, pinfo, tree, offset);\n            break;\n        case 203: /* time-of-device-restart */\n            offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            break;\n        case 226: /* door-alarm-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n            break;\n        case 228: /* door-members */\n            offset = fDoorMembers(tvb, pinfo, tree, offset);\n            break;\n        case 234: /* masked-alarm-values */\n            offset = fSequenceOfEnums(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n            break;\n        case 248: /* access-event-authentication-factor */\n            offset = fAuthenticationFactor(tvb, pinfo, tree, offset);\n            break;\n        case 261: /* authorization-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAuthorizationMode);\n            break;\n        case 53:  /* list-of-group-members */\n            save_object_type = object_type;\n            offset = fListOfGroupMembers(tvb, pinfo, tree, offset);\n            object_type = save_object_type;\n            break;\n        case 296: /* occupancy-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessZoneOccupancyState);\n            break;\n        case 300: /* passback-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessPassbackMode);\n            break;\n        case 303: /* reason-for-disable */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessCredentialDisableReason);\n            break;\n        case 318: /* user-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessUserType);\n            break;\n        case 330: /* key-sets */\n            offset = fSecurityKeySet(tvb, pinfo, tree, offset);\n            break;\n        case 332: /* network-access-security-policies */\n            offset = fNetworkSecurityPolicy(tvb, pinfo, tree, offset);\n            break;\n        case 338: /* backup-and-restore-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetBackupState);\n            break;\n        case 370: /* write-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetWriteStatus);\n            break;\n        case 385: /* transition */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLightingTransition);\n            break;\n        case 288: /* negative-access-rules */\n        case 302: /* positive-access-rules */\n            offset = fAccessRule(tvb, pinfo, tree, offset);\n            break;\n        case 304: /* suppoprted-formats */\n            offset = fAuthenticationFactorFormat(tvb, pinfo, tree, offset);\n            break;\n        case 327: /* base-device-security-policy */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetSecurityLevel);\n            break;\n        case 371: /* property-list */\n            offset = fSequenceOfEnums(tvb, pinfo, tree, offset, ar, BACnetPropertyIdentifier);\n            break;\n        case 358: /* fault-parameters */\n            offset = fFaultParameter(tvb, pinfo, tree, offset);\n            break;\n        case 359: /* fault type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetFaultType);\n            break;\n        case 362: /* subscribed-recipients */\n            offset = fEventNotificationSubscription(tvb, pinfo, tree, offset);\n            break;\n        case 364: /* authorization-exemptions */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAuthorizationExemption);\n            break;\n        case 378: /* in-progress */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLightingInProgress);\n            break;\n        case 380: /* lighting-command */\n            offset = fLightingCommand(tvb, pinfo, tree, offset, ar);\n            break;\n        case 16:  /* change-of-state-time */\n        case 71:  /* modification-date */\n        case 114: /* time-of-active-time-reset */\n        case 115: /* time-of-state-count-reset */\n        case 142: /* start-time */\n        case 143: /* stop-time */\n        case 149: /* maximum-value-time-stamp */\n        case 150: /* minimum-value-time-stamp */\n        case 179: /* count-change-time */\n        case 192: /* value-change-time */\n        case 254: /* activation-time */\n        case 270: /* expiration-time */\n        case 278: /* last-credential-added-time */\n        case 280: /* last-credential-removed-time */\n        case 281: /* last-use-time */\n        case 392: /* time-of-strike-count-reset */\n            offset = fDateTime(tvb, pinfo, tree, offset, ar);\n            break;\n        case 258: /* authentication-policy-list */\n            offset = fAuthenticationPolicy(tvb, pinfo, tree, offset);\n            break;\n        case 395: /* last-state-change */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerTransition);\n            break;\n        case 396: /* state-change-values */\n            offset = fTimerStateChangeValue(tvb, pinfo, tree, offset);\n            break;\n        case 398: /* timer-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerState);\n            break;\n        case 407: /* bacnet-ip-global-address */\n        case 418: /* fd-bbmd-address */\n            offset = fHostNPort(tvb, pinfo, tree, offset, ar);\n            break;\n        case 408: /* bacnet-ip-mode */\n        case 435: /* bacnet-ipv6-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetIpMode);\n            break;\n        case 414: /* bmd-broadcast-distribution-table */\n            offset = fBDTEntry(tvb, pinfo, tree, offset, ar);\n            break;\n        case 415: /* bbmd-foreign-device-table */\n            offset = fFDTEntry(tvb, pinfo, tree, offset, ar);\n            break;\n        case 417: /* command */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNetworkPortCommand);\n            break;\n        case 426: /* network-number-quality */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNetworkNumberQuality);\n            break;\n        case 427: /* network-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNetworkType);\n            break;\n        case 428: /* routing-table */\n            offset = fRouterEntry(tvb, pinfo, tree, offset);\n            break;\n        case 429: /* virtual-mac-address-table */\n            offset = fVMACEntry(tvb, pinfo, tree, offset);\n            break;\n        case 430: /* command-time-array */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            }\n            break;\n        case 432: /* last-command-time */\n            offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            break;\n        case 433: /* value-source */\n            offset = fValueSource(tvb, pinfo, tree, offset);\n            break;\n        case 434: /* value-source-array */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fValueSource(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 447: /* assigned-landing-calls */\n            offset = fAssignedLandingCalls(tvb, pinfo, tree, offset);\n            break;\n        case 448: /* car-assigned-direction */\n        case 457: /* car-moving-direction */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarDirection);\n            break;\n        case 449: /* car-door-command */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarDoorCommand);\n            break;\n        case 453: /* car-drive-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarDriveStatus);\n            break;\n        case 456: /* car-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarMode);\n            break;\n        case 462: /* escalator-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEscalatorMode);\n            break;\n        case 463: /* fault-signals */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                if (object_type == 59) /* lift object */\n                    offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftFault);\n                else\n                    offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEscalatorFault);\n            }\n            break;\n        case 467: /* group-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftGroupMode);\n            break;\n        case 470: /* landing-calls */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fLandingCallStatus(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 471: /* landing-call-control */\n            offset = fLandingCallStatus(tvb, pinfo, tree, offset);\n            break;\n        case 472: /* landing-door-status */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fLandingDoorStatus(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 477: /* \"operation-direction */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEscalatorOperationDirection);\n            break;\n        case 481: /* active-cov-multiple-subscriptions */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fCOVMultipleSubscription(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 482: /* protocol-level */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProtocolLevel);\n            break;\n        case 486: /* tags */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fNameValue(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 487: /* subordinate-node-types */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNodeType);\n            }\n            break;\n        case 488: /* subordinate-tags */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fNameValueCollection(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 489: /* subordinate-relationship */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetRelationship);\n            }\n            break;\n        case 490: /* default-subordinate-relationship */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetRelationship);\n            break;\n\n        case 85:  /* present-value */\n            if ( object_type == 11 )    /* group object handling of present-value */\n            {\n                offset = fReadAccessResult(tvb, pinfo, tree, offset);\n            }\n            else if (object_type == 30)  /* access-door object */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetDoorValue);\n            }\n            else if (object_type == 21)  /* life-point */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n            }\n            else if (object_type == 22)  /* life-zone */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n            }\n            else if (object_type == 53) /* channel object */\n            {\n                offset = fChannelValue(tvb, pinfo, tree, offset, ar);\n            }\n            else if (object_type == 37) /* crederntial-data-input */\n            {\n                offset = fAuthenticationFactor(tvb, pinfo, tree, offset);\n            }\n            else if (object_type == 26) /* global-group */\n            {\n                offset = fPropertyAccessResult(tvb, pinfo, tree, offset);\n            }\n            else if (object_type == 28) /* loac-control */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetShedState);\n            }\n            else\n            {\n                do_default_handling = TRUE;\n            }\n            break;\n        default:\n            do_default_handling = TRUE;\n            break;\n        }\n        if (do_default_handling) {\n            if (tag_info) {\n                if (tag_is_opening(tag_info)) {\n                    ++depth;\n                    offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                } else if (tag_is_closing(tag_info)) {\n                    --depth;\n                    offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                } else {\n                    offset  = fContextTaggedValue(tvb, pinfo, tree, offset, ar);\n                }\n            } else {\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            }\n        }\n        if (offset <= lastoffset) break;     /* nothing happened, exit loop */\n    }\n    return offset;\n}",
        "func": "static guint\nfAbstractSyntaxNType(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset)\n{\n    guint8  tag_no, tag_info;\n    guint32 lvt;\n    guint   lastoffset = 0, depth = 0;\n    char    ar[256];\n    guint32 save_object_type;\n    gboolean do_default_handling;\n\n    if (propertyIdentifier >= 0) {\n        g_snprintf(ar, sizeof(ar), \"%s: \",\n            val_to_split_str(propertyIdentifier, 512,\n                BACnetPropertyIdentifier,\n                ASHRAE_Reserved_Fmt,\n                Vendor_Proprietary_Fmt));\n    } else {\n        g_snprintf(ar, sizeof(ar), \"Abstract Type: \");\n    }\n\n    unsigned recursion_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_bacapp, 0));\n    if (++recursion_depth >= BACAPP_MAX_RECURSION_DEPTH) {\n        proto_tree_add_expert(tree, pinfo, &ei_bacapp_max_recursion_depth_reached, tvb, 0, 0);\n        return offset;\n    }\n    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(recursion_depth));\n\n    while (tvb_reported_length_remaining(tvb, offset) > 0) {  /* exit loop if nothing happens inside */\n        lastoffset = offset;\n        fTagHeader(tvb, pinfo, offset, &tag_no, &tag_info, &lvt);\n        if (tag_is_closing(tag_info)) { /* closing tag, but not for me */\n            if (depth <= 0) return offset;\n        }\n\n        do_default_handling = FALSE;\n\n        /* Application Tags */\n        switch (propertyIdentifier) {\n        case 0: /* acked-transitions */\n        case 35: /* event-enable */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n            BACnetAcknowledgedTransitions);\n            break;\n        case 2: /* action */\n                /* loop object is application tagged,\n                    command object is context tagged */\n                if (tag_is_context_specific(tag_info)) {\n                    /* BACnetActionList */\n                    offset = fActionList(tvb, pinfo, tree, offset);\n                } else {\n                    /* BACnetAction */\n                    offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                        BACnetAction);\n                }\n                break;\n        case 7: /* alarm-values*/\n            switch (object_type) {\n            case 21: /* life-point */\n            case 22: /* life-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n              break;\n            case 30: /* access-door */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n              break;\n            case 31: /* timer */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerState);\n              break;\n            case 36: /* access-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessZoneOccupancyState);\n              break;\n            case 39: /* bitstring-value */\n            default:\n              if (tag_info) {\n                if (tag_is_opening(tag_info)) {\n                  ++depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else if (tag_is_closing(tag_info)) {\n                  --depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else {\n                  offset = fContextTaggedValue(tvb, pinfo, tree, offset, ar);\n                }\n              }\n              else {\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n              }\n              break;\n            }\n            break;\n        case 37: /* event-type */\n          offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEventType);\n          break;\n        case 39: /* fault-values */\n            switch (object_type) {\n            case 21: /* life-point */\n            case 22: /* life-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n              break;\n            case 30: /* access-door */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n              break;\n            case 31: /* timer */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerState);\n              break;\n            case 36: /* access-zone */\n              offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessZoneOccupancyState);\n              break;\n            case 39: /* bitstring-value */\n            default:\n              if (tag_info) {\n                if (tag_is_opening(tag_info)) {\n                  ++depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else if (tag_is_closing(tag_info)) {\n                  --depth;\n                  offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                }\n                else {\n                  offset = fContextTaggedValue(tvb, pinfo, tree, offset, ar);\n                }\n              }\n              else {\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n              }\n              break;\n            }\n            break;\n        case 30: /* BACnetAddressBinding */\n        case 331: /* last-key-server */\n            offset = fAddressBinding(tvb, pinfo, tree, offset);\n            break;\n        case 52: /* limit-enable */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLimitEnable);\n            break;\n        case 54: /* list of object property reference */\n            offset = fLOPR(tvb, pinfo, tree, offset);\n            break;\n        case 55: /* list-of-session-keys */\n            fSessionKey(tvb, pinfo, tree, offset);\n            break;\n        case 79: /* object-type */\n        case 96: /* protocol-object-types-supported */\n            offset = fApplicationTypesEnumeratedSplit(tvb, pinfo, tree, offset, ar,\n                BACnetObjectType, 128);\n            break;\n        case 97: /* Protocol-Services-Supported */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetServicesSupported);\n            break;\n        case 102: /* recipient-list */\n            offset = fDestination(tvb, pinfo, tree, offset);\n            break;\n        case 107: /* segmentation-supported */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetSegmentation);\n            break;\n        case 111: /* Status-Flags */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetStatusFlags);\n            break;\n        case 112: /* System-Status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetDeviceStatus);\n            break;\n        case 117: /* units */\n        case 455: /* car-load-units */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar,\n                BACnetEngineeringUnits);\n            break;\n        case 87:    /* priority-array -- accessed as a BACnetARRAY */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fPriorityArray(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 38:    /* exception-schedule */\n            if (object_type < 128) {\n                if (propertyArrayIndex == 0) {\n                    /* BACnetARRAY index 0 refers to the length\n                    of the array, not the elements of the array */\n                    offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n                } else {\n                    offset = fSpecialEvent(tvb, pinfo, tree, offset);\n                }\n            }\n            break;\n        case 19:  /* controlled-variable-reference */\n        case 60:  /* manipulated-variable-reference */\n        case 78:  /* object-property-reference */\n        case 181: /* input-reference */\n        case 355: /* event-algorithm-inhibit-reference */\n            offset = fObjectPropertyReference(tvb, pinfo, tree, offset);\n            break;\n        case 132: /* log-device-object-property */\n            offset = fDeviceObjectPropertyReference(tvb, pinfo, tree, offset);\n            break;\n        case 109: /* Setpoint-Reference */\n            /* setpoint-Reference is actually BACnetSetpointReference which is a SEQ of [0] */\n            offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n            offset = fBACnetObjectPropertyReference(tvb, pinfo, tree, offset);\n            offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n            break;\n        case 123:   /* weekly-schedule -- accessed as a BACnetARRAY */\n            if (object_type < 128) {\n                if (propertyArrayIndex == 0) {\n                    /* BACnetARRAY index 0 refers to the length\n                    of the array, not the elements of the array */\n                    offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n                } else {\n                    offset = fWeeklySchedule(tvb, pinfo, tree, offset);\n                }\n            }\n            break;\n        case 127:   /* client COV increment */\n            offset = fClientCOV(tvb, pinfo, tree, offset);\n            break;\n        case 131:  /* log-buffer */\n            if ( object_type == 25 )\n                offset = fEventLogRecord(tvb, pinfo, tree, offset);\n            else if ( object_type == 27 )\n                offset = fLogMultipleRecord(tvb, pinfo, tree, offset);\n            else\n                offset = fLogRecord(tvb, pinfo, tree, offset);\n            break;\n        case 159: /* member-of */\n        case 165: /* zone-members */\n        case 211: /* subordinate-list */\n        case 246: /* access-doors */\n        case 249: /* access-event-credential */\n        case 252: /* accompaniment */\n        case 265: /* credentials */\n        case 266: /* credentials-in-zone */\n        case 277: /* last-credential-added */\n        case 279: /* last-credential-removed */\n        case 286: /* members */\n        case 320: /* zone-from */\n        case 321: /* zone-to */\n        case 461: /* energy-meter-ref */\n        case 491: /* represents */\n            offset = fDeviceObjectReference(tvb, pinfo, tree, offset);\n            break;\n        case 196: /* last-restart-reason */\n            offset = fRestartReason(tvb, pinfo, tree, offset);\n            break;\n        case 212: /* actual-shed-level */\n        case 214: /* expected-shed-level */\n        case 218: /* requested-shed-level */\n            offset = fShedLevel(tvb, pinfo, tree, offset);\n            break;\n        case 152: /* active-cov-subscriptions */\n            offset = fCOVSubscription(tvb, pinfo, tree, offset);\n            break;\n        case 23: /* date-list */\n            offset = fCalendarEntry(tvb, pinfo, tree, offset);\n            break;\n        case 116: /* time-sychronization-recipients */\n        case 206: /* utc-time-synchronization-recipients */\n        case 202: /* restart-notification-recipients */\n            offset = fRecipient(tvb, pinfo, tree, offset);\n            break;\n        case 83: /* event-parameters */\n            offset = fEventParameter(tvb, pinfo, tree, offset);\n            break;\n        case 130: /* event-time-stamp */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fEventTimeStamps(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 197: /* logging-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLoggingType);\n            break;\n        case 36: /* event-state */\n            offset = fApplicationTypesEnumeratedSplit(tvb, pinfo, tree, offset, ar, BACnetEventState, 64);\n            break;\n        case 103: /* reliability */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetReliability);\n            break;\n        case 72: /* notify-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNotifyType);\n            break;\n        case 208: /* node-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNodeType);\n            break;\n        case 231: /* door-status */\n        case 450: /* car-door-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorStatus);\n            break;\n        case 233: /* lock-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLockStatus);\n            break;\n        case 235: /* secured-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorSecuredStatus);\n            break;\n        case 158: /* maintenance-required */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetMaintenance);\n            break;\n        case 92: /* program-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProgramState);\n            break;\n        case 90: /* program-change */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProgramRequest);\n            break;\n        case 100: /* reason-for-halt */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProgramError);\n            break;\n        case 160: /* mode */\n        case 175: /* accepted-modes */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyMode);\n            break;\n        case 163: /* silenced */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetSilencedState);\n            break;\n        case 161: /* operation-expected */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyOperation);\n            break;\n        case 164: /* tracking-value */\n        case 166: /* life-safety-alarm-values */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n            break;\n        case 41: /* file-access-method */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetFileAccessMethod);\n            break;\n        case 185:  /* prescale */\n            offset = fPrescale(tvb, pinfo, tree, offset);\n            break;\n        case 187:  /* scale */\n            offset = fScale(tvb, pinfo, tree, offset);\n            break;\n        case 189: /* update-time */\n            if (object_type == 37)\n                offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            else\n                offset = fDateTime(tvb, pinfo, tree, offset, ar);\n            break;\n        case 184: /* logging-record */\n            offset = fLoggingRecord(tvb, pinfo, tree, offset);\n            break;\n        case 203: /* time-of-device-restart */\n            offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            break;\n        case 226: /* door-alarm-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n            break;\n        case 228: /* door-members */\n            offset = fDoorMembers(tvb, pinfo, tree, offset);\n            break;\n        case 234: /* masked-alarm-values */\n            offset = fSequenceOfEnums(tvb, pinfo, tree, offset, ar, BACnetDoorAlarmState);\n            break;\n        case 248: /* access-event-authentication-factor */\n            offset = fAuthenticationFactor(tvb, pinfo, tree, offset);\n            break;\n        case 261: /* authorization-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAuthorizationMode);\n            break;\n        case 53:  /* list-of-group-members */\n            save_object_type = object_type;\n            offset = fListOfGroupMembers(tvb, pinfo, tree, offset);\n            object_type = save_object_type;\n            break;\n        case 296: /* occupancy-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessZoneOccupancyState);\n            break;\n        case 300: /* passback-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessPassbackMode);\n            break;\n        case 303: /* reason-for-disable */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessCredentialDisableReason);\n            break;\n        case 318: /* user-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAccessUserType);\n            break;\n        case 330: /* key-sets */\n            offset = fSecurityKeySet(tvb, pinfo, tree, offset);\n            break;\n        case 332: /* network-access-security-policies */\n            offset = fNetworkSecurityPolicy(tvb, pinfo, tree, offset);\n            break;\n        case 338: /* backup-and-restore-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetBackupState);\n            break;\n        case 370: /* write-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetWriteStatus);\n            break;\n        case 385: /* transition */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLightingTransition);\n            break;\n        case 288: /* negative-access-rules */\n        case 302: /* positive-access-rules */\n            offset = fAccessRule(tvb, pinfo, tree, offset);\n            break;\n        case 304: /* suppoprted-formats */\n            offset = fAuthenticationFactorFormat(tvb, pinfo, tree, offset);\n            break;\n        case 327: /* base-device-security-policy */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetSecurityLevel);\n            break;\n        case 371: /* property-list */\n            offset = fSequenceOfEnums(tvb, pinfo, tree, offset, ar, BACnetPropertyIdentifier);\n            break;\n        case 358: /* fault-parameters */\n            offset = fFaultParameter(tvb, pinfo, tree, offset);\n            break;\n        case 359: /* fault type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetFaultType);\n            break;\n        case 362: /* subscribed-recipients */\n            offset = fEventNotificationSubscription(tvb, pinfo, tree, offset);\n            break;\n        case 364: /* authorization-exemptions */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetAuthorizationExemption);\n            break;\n        case 378: /* in-progress */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLightingInProgress);\n            break;\n        case 380: /* lighting-command */\n            offset = fLightingCommand(tvb, pinfo, tree, offset, ar);\n            break;\n        case 16:  /* change-of-state-time */\n        case 71:  /* modification-date */\n        case 114: /* time-of-active-time-reset */\n        case 115: /* time-of-state-count-reset */\n        case 142: /* start-time */\n        case 143: /* stop-time */\n        case 149: /* maximum-value-time-stamp */\n        case 150: /* minimum-value-time-stamp */\n        case 179: /* count-change-time */\n        case 192: /* value-change-time */\n        case 254: /* activation-time */\n        case 270: /* expiration-time */\n        case 278: /* last-credential-added-time */\n        case 280: /* last-credential-removed-time */\n        case 281: /* last-use-time */\n        case 392: /* time-of-strike-count-reset */\n            offset = fDateTime(tvb, pinfo, tree, offset, ar);\n            break;\n        case 258: /* authentication-policy-list */\n            offset = fAuthenticationPolicy(tvb, pinfo, tree, offset);\n            break;\n        case 395: /* last-state-change */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerTransition);\n            break;\n        case 396: /* state-change-values */\n            offset = fTimerStateChangeValue(tvb, pinfo, tree, offset);\n            break;\n        case 398: /* timer-state */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetTimerState);\n            break;\n        case 407: /* bacnet-ip-global-address */\n        case 418: /* fd-bbmd-address */\n            offset = fHostNPort(tvb, pinfo, tree, offset, ar);\n            break;\n        case 408: /* bacnet-ip-mode */\n        case 435: /* bacnet-ipv6-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetIpMode);\n            break;\n        case 414: /* bmd-broadcast-distribution-table */\n            offset = fBDTEntry(tvb, pinfo, tree, offset, ar);\n            break;\n        case 415: /* bbmd-foreign-device-table */\n            offset = fFDTEntry(tvb, pinfo, tree, offset, ar);\n            break;\n        case 417: /* command */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNetworkPortCommand);\n            break;\n        case 426: /* network-number-quality */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNetworkNumberQuality);\n            break;\n        case 427: /* network-type */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNetworkType);\n            break;\n        case 428: /* routing-table */\n            offset = fRouterEntry(tvb, pinfo, tree, offset);\n            break;\n        case 429: /* virtual-mac-address-table */\n            offset = fVMACEntry(tvb, pinfo, tree, offset);\n            break;\n        case 430: /* command-time-array */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            }\n            break;\n        case 432: /* last-command-time */\n            offset = fTimeStamp(tvb, pinfo, tree, offset, ar);\n            break;\n        case 433: /* value-source */\n            offset = fValueSource(tvb, pinfo, tree, offset);\n            break;\n        case 434: /* value-source-array */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fValueSource(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 447: /* assigned-landing-calls */\n            offset = fAssignedLandingCalls(tvb, pinfo, tree, offset);\n            break;\n        case 448: /* car-assigned-direction */\n        case 457: /* car-moving-direction */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarDirection);\n            break;\n        case 449: /* car-door-command */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarDoorCommand);\n            break;\n        case 453: /* car-drive-status */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarDriveStatus);\n            break;\n        case 456: /* car-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftCarMode);\n            break;\n        case 462: /* escalator-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEscalatorMode);\n            break;\n        case 463: /* fault-signals */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                if (object_type == 59) /* lift object */\n                    offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftFault);\n                else\n                    offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEscalatorFault);\n            }\n            break;\n        case 467: /* group-mode */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetLiftGroupMode);\n            break;\n        case 470: /* landing-calls */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fLandingCallStatus(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 471: /* landing-call-control */\n            offset = fLandingCallStatus(tvb, pinfo, tree, offset);\n            break;\n        case 472: /* landing-door-status */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fLandingDoorStatus(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 477: /* \"operation-direction */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetEscalatorOperationDirection);\n            break;\n        case 481: /* active-cov-multiple-subscriptions */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fCOVMultipleSubscription(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 482: /* protocol-level */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetProtocolLevel);\n            break;\n        case 486: /* tags */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fNameValue(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 487: /* subordinate-node-types */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetNodeType);\n            }\n            break;\n        case 488: /* subordinate-tags */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fNameValueCollection(tvb, pinfo, tree, offset);\n            }\n            break;\n        case 489: /* subordinate-relationship */\n            if (propertyArrayIndex == 0) {\n                /* BACnetARRAY index 0 refers to the length\n                of the array, not the elements of the array */\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            } else {\n                offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetRelationship);\n            }\n            break;\n        case 490: /* default-subordinate-relationship */\n            offset = fApplicationTypesEnumerated(tvb, pinfo, tree, offset, ar, BACnetRelationship);\n            break;\n\n        case 85:  /* present-value */\n            if ( object_type == 11 )    /* group object handling of present-value */\n            {\n                offset = fReadAccessResult(tvb, pinfo, tree, offset);\n            }\n            else if (object_type == 30)  /* access-door object */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetDoorValue);\n            }\n            else if (object_type == 21)  /* life-point */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n            }\n            else if (object_type == 22)  /* life-zone */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetLifeSafetyState);\n            }\n            else if (object_type == 53) /* channel object */\n            {\n                offset = fChannelValue(tvb, pinfo, tree, offset, ar);\n            }\n            else if (object_type == 37) /* crederntial-data-input */\n            {\n                offset = fAuthenticationFactor(tvb, pinfo, tree, offset);\n            }\n            else if (object_type == 26) /* global-group */\n            {\n                offset = fPropertyAccessResult(tvb, pinfo, tree, offset);\n            }\n            else if (object_type == 28) /* loac-control */\n            {\n                offset = fEnumeratedTag(tvb, pinfo, tree, offset, ar, BACnetShedState);\n            }\n            else\n            {\n                do_default_handling = TRUE;\n            }\n            break;\n        default:\n            do_default_handling = TRUE;\n            break;\n        }\n        if (do_default_handling) {\n            if (tag_info) {\n                if (tag_is_opening(tag_info)) {\n                    ++depth;\n                    offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                } else if (tag_is_closing(tag_info)) {\n                    --depth;\n                    offset += fTagHeaderTree(tvb, pinfo, tree, offset, &tag_no, &tag_info, &lvt);\n                } else {\n                    offset  = fContextTaggedValue(tvb, pinfo, tree, offset, ar);\n                }\n            } else {\n                offset = fApplicationTypes(tvb, pinfo, tree, offset, ar);\n            }\n        }\n        if (offset <= lastoffset) break;     /* nothing happened, exit loop */\n    }\n    recursion_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_bacapp, 0));\n    recursion_depth--;\n    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(recursion_depth));\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,14 @@\n     } else {\n         g_snprintf(ar, sizeof(ar), \"Abstract Type: \");\n     }\n+\n+    unsigned recursion_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_bacapp, 0));\n+    if (++recursion_depth >= BACAPP_MAX_RECURSION_DEPTH) {\n+        proto_tree_add_expert(tree, pinfo, &ei_bacapp_max_recursion_depth_reached, tvb, 0, 0);\n+        return offset;\n+    }\n+    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(recursion_depth));\n+\n     while (tvb_reported_length_remaining(tvb, offset) > 0) {  /* exit loop if nothing happens inside */\n         lastoffset = offset;\n         fTagHeader(tvb, pinfo, offset, &tag_no, &tag_info, &lvt);\n@@ -670,5 +678,8 @@\n         }\n         if (offset <= lastoffset) break;     /* nothing happened, exit loop */\n     }\n+    recursion_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_bacapp, 0));\n+    recursion_depth--;\n+    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(recursion_depth));\n     return offset;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    unsigned recursion_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_bacapp, 0));",
                "    if (++recursion_depth >= BACAPP_MAX_RECURSION_DEPTH) {",
                "        proto_tree_add_expert(tree, pinfo, &ei_bacapp_max_recursion_depth_reached, tvb, 0, 0);",
                "        return offset;",
                "    }",
                "    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(recursion_depth));",
                "",
                "    recursion_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_bacapp, 0));",
                "    recursion_depth--;",
                "    p_add_proto_data(pinfo->pool, pinfo, proto_bacapp, 0, GUINT_TO_POINTER(recursion_depth));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13164",
        "func_name": "wireshark/nfs_full_name_snoop",
        "description": "In Wireshark 3.2.0 to 3.2.3, 3.0.0 to 3.0.10, and 2.6.0 to 2.6.16, the NFS dissector could crash. This was addressed in epan/dissectors/packet-nfs.c by preventing excessive recursion, such as for a cycle in the directory graph on a filesystem.",
        "git_url": "https://github.com/wireshark/wireshark/commit/e6e98eab8e5e0bbc982cfdc808f2469d7cab6c5a",
        "commit_title": "NFS: Add filesystem cycle detection.",
        "commit_text": " Detect cycles and large depths when snooping full names.  Bug: 16476 (cherry picked from commit fc6763989c7a7c4e4b0522b12b955e5a285d388a)",
        "func_before": "static void\nnfs_full_name_snoop(nfs_name_snoop_t *nns, int *len, char **name, char **pos)\n{\n\tnfs_name_snoop_t     *parent_nns = NULL;\n\tnfs_name_snoop_key_t  key;\n\n\t/* check if the nns component ends with a '/' else we just allocate\n\t   an extra byte to len to accommodate for it later */\n\tif (nns->name[nns->name_len-1] != '/') {\n\t\t(*len)++;\n\t}\n\n\t(*len) += nns->name_len;\n\n\tif (nns->parent == NULL) {\n\t\t*name = (char *)g_malloc((*len)+1);\n\t\t*pos = *name;\n\n\t\t*pos += g_snprintf(*pos, (*len)+1, \"%s\", nns->name);\n\t\tDISSECTOR_ASSERT((*pos-*name) <= *len);\n\t\treturn;\n\t}\n\n\tkey.key = 0;\n\tkey.fh_length = nns->parent_len;\n\tkey.fh = nns->parent;\n\n\tparent_nns = (nfs_name_snoop_t *)g_hash_table_lookup(nfs_name_snoop_matched, &key);\n\n\tif (parent_nns) {\n\t\tnfs_full_name_snoop(parent_nns, len, name, pos);\n\t\tif (*name) {\n\t\t\t/* make sure components are '/' separated */\n\t\t\t*pos += g_snprintf(*pos, (*len+1) - (gulong)(*pos-*name), \"%s%s\",\n\t\t\t\t\t   ((*pos)[-1] != '/')?\"/\":\"\", nns->name);\n\t\t\tDISSECTOR_ASSERT((*pos-*name) <= *len);\n\t\t}\n\t\treturn;\n\t}\n\n\treturn;\n}",
        "func": "static void\nnfs_full_name_snoop(packet_info *pinfo, nfs_name_snoop_t *nns, int *len, char **name, char **pos)\n{\n\tnfs_name_snoop_t     *parent_nns = NULL;\n\tnfs_name_snoop_key_t  key;\n\n\t/* check if the nns component ends with a '/' else we just allocate\n\t   an extra byte to len to accommodate for it later */\n\tif (nns->name[nns->name_len-1] != '/') {\n\t\t(*len)++;\n\t}\n\n\t(*len) += nns->name_len;\n\n\tif (nns->parent == NULL) {\n\t\t*name = (char *)g_malloc((*len)+1);\n\t\t*pos = *name;\n\n\t\t*pos += g_snprintf(*pos, (*len)+1, \"%s\", nns->name);\n\t\tDISSECTOR_ASSERT((*pos-*name) <= *len);\n\t\treturn;\n\t}\n\n\tkey.key = 0;\n\tkey.fh_length = nns->parent_len;\n\tkey.fh = nns->parent;\n\n\tparent_nns = (nfs_name_snoop_t *)g_hash_table_lookup(nfs_name_snoop_matched, &key);\n\n\tif (parent_nns) {\n\t\tunsigned fs_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_nfs, 0));\n\t\tif (++fs_depth >= NFS_MAX_FS_DEPTH) {\n\t\t\tnns->fs_cycle = TRUE;\n\t\t\treturn;\n\t\t}\n\t\tp_add_proto_data(pinfo->pool, pinfo, proto_nfs, 0, GUINT_TO_POINTER(fs_depth));\n\n\t\tnfs_full_name_snoop(pinfo, parent_nns, len, name, pos);\n\t\tif (*name) {\n\t\t\t/* make sure components are '/' separated */\n\t\t\t*pos += g_snprintf(*pos, (*len+1) - (gulong)(*pos-*name), \"%s%s\",\n\t\t\t\t\t   ((*pos)[-1] != '/')?\"/\":\"\", nns->name);\n\t\t\tDISSECTOR_ASSERT((*pos-*name) <= *len);\n\t\t}\n\t\tfs_depth--;\n\t\tp_add_proto_data(pinfo->pool, pinfo, proto_nfs, 0, GUINT_TO_POINTER(fs_depth));\n\t\treturn;\n\t}\n\n\treturn;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n static void\n-nfs_full_name_snoop(nfs_name_snoop_t *nns, int *len, char **name, char **pos)\n+nfs_full_name_snoop(packet_info *pinfo, nfs_name_snoop_t *nns, int *len, char **name, char **pos)\n {\n \tnfs_name_snoop_t     *parent_nns = NULL;\n \tnfs_name_snoop_key_t  key;\n@@ -28,13 +28,22 @@\n \tparent_nns = (nfs_name_snoop_t *)g_hash_table_lookup(nfs_name_snoop_matched, &key);\n \n \tif (parent_nns) {\n-\t\tnfs_full_name_snoop(parent_nns, len, name, pos);\n+\t\tunsigned fs_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_nfs, 0));\n+\t\tif (++fs_depth >= NFS_MAX_FS_DEPTH) {\n+\t\t\tnns->fs_cycle = TRUE;\n+\t\t\treturn;\n+\t\t}\n+\t\tp_add_proto_data(pinfo->pool, pinfo, proto_nfs, 0, GUINT_TO_POINTER(fs_depth));\n+\n+\t\tnfs_full_name_snoop(pinfo, parent_nns, len, name, pos);\n \t\tif (*name) {\n \t\t\t/* make sure components are '/' separated */\n \t\t\t*pos += g_snprintf(*pos, (*len+1) - (gulong)(*pos-*name), \"%s%s\",\n \t\t\t\t\t   ((*pos)[-1] != '/')?\"/\":\"\", nns->name);\n \t\t\tDISSECTOR_ASSERT((*pos-*name) <= *len);\n \t\t}\n+\t\tfs_depth--;\n+\t\tp_add_proto_data(pinfo->pool, pinfo, proto_nfs, 0, GUINT_TO_POINTER(fs_depth));\n \t\treturn;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "nfs_full_name_snoop(nfs_name_snoop_t *nns, int *len, char **name, char **pos)",
                "\t\tnfs_full_name_snoop(parent_nns, len, name, pos);"
            ],
            "added_lines": [
                "nfs_full_name_snoop(packet_info *pinfo, nfs_name_snoop_t *nns, int *len, char **name, char **pos)",
                "\t\tunsigned fs_depth = GPOINTER_TO_UINT(p_get_proto_data(pinfo->pool, pinfo, proto_nfs, 0));",
                "\t\tif (++fs_depth >= NFS_MAX_FS_DEPTH) {",
                "\t\t\tnns->fs_cycle = TRUE;",
                "\t\t\treturn;",
                "\t\t}",
                "\t\tp_add_proto_data(pinfo->pool, pinfo, proto_nfs, 0, GUINT_TO_POINTER(fs_depth));",
                "",
                "\t\tnfs_full_name_snoop(pinfo, parent_nns, len, name, pos);",
                "\t\tfs_depth--;",
                "\t\tp_add_proto_data(pinfo->pool, pinfo, proto_nfs, 0, GUINT_TO_POINTER(fs_depth));"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-13164",
        "func_name": "wireshark/nfs_name_snoop_fh",
        "description": "In Wireshark 3.2.0 to 3.2.3, 3.0.0 to 3.0.10, and 2.6.0 to 2.6.16, the NFS dissector could crash. This was addressed in epan/dissectors/packet-nfs.c by preventing excessive recursion, such as for a cycle in the directory graph on a filesystem.",
        "git_url": "https://github.com/wireshark/wireshark/commit/e6e98eab8e5e0bbc982cfdc808f2469d7cab6c5a",
        "commit_title": "NFS: Add filesystem cycle detection.",
        "commit_text": " Detect cycles and large depths when snooping full names.  Bug: 16476 (cherry picked from commit fc6763989c7a7c4e4b0522b12b955e5a285d388a)",
        "func_before": "static void\nnfs_name_snoop_fh(packet_info *pinfo, proto_tree *tree, tvbuff_t *tvb, int fh_offset,\n\t\t\t\t  int fh_length, gboolean hidden)\n{\n\tnfs_name_snoop_key_t  key;\n\tnfs_name_snoop_t     *nns = NULL;\n\n\t/* if this is a new packet, see if we can register the mapping */\n\tif (!pinfo->fd->flags.visited) {\n\t\tkey.key = 0;\n\t\tkey.fh_length = fh_length;\n\t\tkey.fh = (const unsigned char *)tvb_get_ptr(tvb, fh_offset, fh_length);\n\n\t\tnns = (nfs_name_snoop_t *)g_hash_table_lookup(nfs_name_snoop_matched, &key);\n\t\tif (nns) {\n\t\t\tguint32 fhlen;\n\t\t\tguint32 *fhdata;\n\t\t\twmem_tree_key_t fhkey[3];\n\n\t\t\tfhlen = nns->fh_length;\n\t\t\t/* align it */\n\t\t\tfhdata = (guint32 *)g_memdup(nns->fh, fhlen);\n\t\t\tfhkey[0].length = 1;\n\t\t\tfhkey[0].key\t= &fhlen;\n\t\t\tfhkey[1].length = fhlen/4;\n\t\t\tfhkey[1].key\t= fhdata;\n\t\t\tfhkey[2].length = 0;\n\t\t\twmem_tree_insert32_array(nfs_name_snoop_known, &fhkey[0], nns);\n\t\t\tg_free(fhdata);\n\n\t\t\tif (nfs_file_name_full_snooping) {\n\t\t\t\tchar *name = NULL, *pos = NULL;\n\t\t\t\tint len = 0;\n\n\t\t\t\tnfs_full_name_snoop(nns, &len, &name, &pos);\n\t\t\t\tif (name) {\n\t\t\t\t\tnns->full_name = name;\n\t\t\t\t\tnns->full_name_len = len;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/* see if we know this mapping */\n\tif (!nns) {\n\t\tguint32 fhlen;\n\t\tguint32 *fhdata;\n\t\twmem_tree_key_t fhkey[3];\n\n\t\tfhlen = fh_length;\n\t\t/* align it */\n\t\tfhdata = (guint32 *)tvb_memdup(wmem_packet_scope(), tvb, fh_offset, fh_length);\n\t\tfhkey[0].length = 1;\n\t\tfhkey[0].key\t= &fhlen;\n\t\tfhkey[1].length = fhlen/4;\n\t\tfhkey[1].key\t= fhdata;\n\t\tfhkey[2].length = 0;\n\n\t\tnns = (nfs_name_snoop_t *)wmem_tree_lookup32_array(nfs_name_snoop_known, &fhkey[0]);\n\t}\n\n\t/* if we know the mapping, print the filename */\n\tif (nns) {\n\t\tproto_item *fh_item = NULL;\n\n\t\tif (hidden) {\n\t\t\tfh_item = proto_tree_add_string(tree, hf_nfs_name, NULL,\n\t\t\t\t0, 0, nns->name);\n\t\t\tPROTO_ITEM_SET_HIDDEN(fh_item);\n\t\t} else {\n\t\t\tfh_item = proto_tree_add_string(tree, hf_nfs_name, tvb,\n\t\t\t\tfh_offset, 0, nns->name);\n\t\t}\n\t\tPROTO_ITEM_SET_GENERATED(fh_item);\n\n\t\tif (nns->full_name) {\n\t\t\tif (hidden) {\n\t\t\t\tfh_item = proto_tree_add_string(tree, hf_nfs_full_name, NULL,\n\t\t\t\t\t0, 0, nns->full_name);\n\t\t\t\tPROTO_ITEM_SET_HIDDEN(fh_item);\n\t\t\t} else {\n\t\t\t\tfh_item = proto_tree_add_string_format_value(tree, hf_nfs_full_name, tvb,\n\t\t\t\t\tfh_offset, 0, nns->full_name, \"%s\", nns->full_name);\n\t\t\t}\n\t\t\tPROTO_ITEM_SET_GENERATED(fh_item);\n\t\t}\n\t}\n}",
        "func": "static void\nnfs_name_snoop_fh(packet_info *pinfo, proto_tree *tree, tvbuff_t *tvb, int fh_offset,\n\t\t\t\t  int fh_length, gboolean hidden)\n{\n\tnfs_name_snoop_key_t  key;\n\tnfs_name_snoop_t     *nns = NULL;\n\n\t/* if this is a new packet, see if we can register the mapping */\n\tif (!pinfo->fd->flags.visited) {\n\t\tkey.key = 0;\n\t\tkey.fh_length = fh_length;\n\t\tkey.fh = (const unsigned char *)tvb_get_ptr(tvb, fh_offset, fh_length);\n\n\t\tnns = (nfs_name_snoop_t *)g_hash_table_lookup(nfs_name_snoop_matched, &key);\n\t\tif (nns) {\n\t\t\tguint32 fhlen;\n\t\t\tguint32 *fhdata;\n\t\t\twmem_tree_key_t fhkey[3];\n\n\t\t\tfhlen = nns->fh_length;\n\t\t\t/* align it */\n\t\t\tfhdata = (guint32 *)g_memdup(nns->fh, fhlen);\n\t\t\tfhkey[0].length = 1;\n\t\t\tfhkey[0].key\t= &fhlen;\n\t\t\tfhkey[1].length = fhlen/4;\n\t\t\tfhkey[1].key\t= fhdata;\n\t\t\tfhkey[2].length = 0;\n\t\t\twmem_tree_insert32_array(nfs_name_snoop_known, &fhkey[0], nns);\n\t\t\tg_free(fhdata);\n\n\t\t\tif (nfs_file_name_full_snooping) {\n\t\t\t\tchar *name = NULL, *pos = NULL;\n\t\t\t\tint len = 0;\n\n\t\t\t\tnfs_full_name_snoop(pinfo, nns, &len, &name, &pos);\n\t\t\t\tif (name) {\n\t\t\t\t\tnns->full_name = name;\n\t\t\t\t\tnns->full_name_len = len;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/* see if we know this mapping */\n\tif (!nns) {\n\t\tguint32 fhlen;\n\t\tguint32 *fhdata;\n\t\twmem_tree_key_t fhkey[3];\n\n\t\tfhlen = fh_length;\n\t\t/* align it */\n\t\tfhdata = (guint32 *)tvb_memdup(wmem_packet_scope(), tvb, fh_offset, fh_length);\n\t\tfhkey[0].length = 1;\n\t\tfhkey[0].key\t= &fhlen;\n\t\tfhkey[1].length = fhlen/4;\n\t\tfhkey[1].key\t= fhdata;\n\t\tfhkey[2].length = 0;\n\n\t\tnns = (nfs_name_snoop_t *)wmem_tree_lookup32_array(nfs_name_snoop_known, &fhkey[0]);\n\t}\n\n\t/* if we know the mapping, print the filename */\n\tif (nns) {\n\t\tproto_item *fh_item = NULL;\n\n\t\tif (hidden) {\n\t\t\tfh_item = proto_tree_add_string(tree, hf_nfs_name, NULL,\n\t\t\t\t0, 0, nns->name);\n\t\t\tPROTO_ITEM_SET_HIDDEN(fh_item);\n\t\t} else {\n\t\t\tfh_item = proto_tree_add_string(tree, hf_nfs_name, tvb,\n\t\t\t\tfh_offset, 0, nns->name);\n\t\t}\n\t\tPROTO_ITEM_SET_GENERATED(fh_item);\n\n\t\tif (nns->full_name) {\n\t\t\tif (hidden) {\n\t\t\t\tfh_item = proto_tree_add_string(tree, hf_nfs_full_name, NULL,\n\t\t\t\t\t0, 0, nns->full_name);\n\t\t\t\tPROTO_ITEM_SET_HIDDEN(fh_item);\n\t\t\t} else {\n\t\t\t\tfh_item = proto_tree_add_string_format_value(tree, hf_nfs_full_name, tvb,\n\t\t\t\t\tfh_offset, 0, nns->full_name, \"%s\", nns->full_name);\n\t\t\t}\n\t\t\tPROTO_ITEM_SET_GENERATED(fh_item);\n\t\t}\n\n\t\tif (nns->fs_cycle) {\n\t\t\tproto_tree_add_expert(tree, pinfo, &ei_nfs_file_system_cycle, tvb, 0, 0);\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,7 +32,7 @@\n \t\t\t\tchar *name = NULL, *pos = NULL;\n \t\t\t\tint len = 0;\n \n-\t\t\t\tnfs_full_name_snoop(nns, &len, &name, &pos);\n+\t\t\t\tnfs_full_name_snoop(pinfo, nns, &len, &name, &pos);\n \t\t\t\tif (name) {\n \t\t\t\t\tnns->full_name = name;\n \t\t\t\t\tnns->full_name_len = len;\n@@ -84,5 +84,9 @@\n \t\t\t}\n \t\t\tPROTO_ITEM_SET_GENERATED(fh_item);\n \t\t}\n+\n+\t\tif (nns->fs_cycle) {\n+\t\t\tproto_tree_add_expert(tree, pinfo, &ei_nfs_file_system_cycle, tvb, 0, 0);\n+\t\t}\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tnfs_full_name_snoop(nns, &len, &name, &pos);"
            ],
            "added_lines": [
                "\t\t\t\tnfs_full_name_snoop(pinfo, nns, &len, &name, &pos);",
                "",
                "\t\tif (nns->fs_cycle) {",
                "\t\t\tproto_tree_add_expert(tree, pinfo, &ei_nfs_file_system_cycle, tvb, 0, 0);",
                "\t\t}"
            ]
        }
    }
]