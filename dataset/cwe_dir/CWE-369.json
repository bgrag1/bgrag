[
    {
        "cve_id": "CVE-2022-2056",
        "func_name": "libtiff/computeInputPixelOffsets",
        "description": "Divide By Zero error in tiffcrop in libtiff 4.4.0 allows attackers to cause a denial-of-service via a crafted tiff file. For users that compile libtiff from sources, the fix is available with commit f3a5e010.",
        "git_url": "https://gitlab.com/libtiff/libtiff/-/commit/ab6e93f10f7df01a43aacd51caa1ef6f61cf0ce5",
        "commit_title": "Fix FPE errors in tiffcrop (#415, #427, and #428)",
        "commit_text": "",
        "func_before": "static int\ncomputeInputPixelOffsets(struct crop_mask *crop, struct image_data *image,\n                         struct offset *off)\n  {\n  double scale;\n  float xres, yres;\n  /* Values for these offsets are in pixels from start of image, not bytes,\n   * and are indexed from zero to width - 1 or length - 1 */\n  uint32_t tmargin, bmargin, lmargin, rmargin;\n  uint32_t startx, endx;   /* offsets of first and last columns to extract */\n  uint32_t starty, endy;   /* offsets of first and last row to extract */\n  uint32_t width, length, crop_width, crop_length;\n  uint32_t i, max_width, max_length, zwidth, zlength, buffsize;\n  uint32_t x1, x2, y1, y2;\n\n  if (image->res_unit != RESUNIT_INCH && image->res_unit != RESUNIT_CENTIMETER)\n    {\n    xres = 1.0;\n    yres = 1.0;\n    }\n  else\n    {\n    if (((image->xres == 0) || (image->yres == 0)) && \n         (crop->res_unit != RESUNIT_NONE) &&\n\t((crop->crop_mode & CROP_REGIONS) || (crop->crop_mode & CROP_MARGINS) ||\n \t (crop->crop_mode & CROP_LENGTH)  || (crop->crop_mode & CROP_WIDTH)))\n      {\n      TIFFError(\"computeInputPixelOffsets\", \"Cannot compute margins or fixed size sections without image resolution\");\n      TIFFError(\"computeInputPixelOffsets\", \"Specify units in pixels and try again\");\n      return (-1);\n      }\n    xres = image->xres;\n    yres = image->yres;\n    }\n\n  /* Translate user units to image units */\n  scale = 1.0;\n  switch (crop->res_unit) {\n    case RESUNIT_CENTIMETER:\n         if (image->res_unit == RESUNIT_INCH)\n\t   scale = 1.0/2.54;\n\t break;\n    case RESUNIT_INCH:\n\t if (image->res_unit == RESUNIT_CENTIMETER)\n\t     scale = 2.54;\n\t break;\n    case RESUNIT_NONE: /* Dimensions in pixels */\n    default:\n    break;\n    }\n\n  if (crop->crop_mode & CROP_REGIONS)\n    {\n    max_width = max_length = 0;\n    for (i = 0; i < crop->regions; i++)\n      {\n      if ((crop->res_unit == RESUNIT_INCH) || (crop->res_unit == RESUNIT_CENTIMETER))\n        {\n\tx1 = (uint32_t) (crop->corners[i].X1 * scale * xres);\n\tx2 = (uint32_t) (crop->corners[i].X2 * scale * xres);\n\ty1 = (uint32_t) (crop->corners[i].Y1 * scale * yres);\n\ty2 = (uint32_t) (crop->corners[i].Y2 * scale * yres);\n        }\n      else\n        {\n\tx1 = (uint32_t) (crop->corners[i].X1);\n\tx2 = (uint32_t) (crop->corners[i].X2);\n\ty1 = (uint32_t) (crop->corners[i].Y1);\n\ty2 = (uint32_t) (crop->corners[i].Y2);\n\t}\n      /* a) Region needs to be within image sizes 0.. width-1; 0..length-1 \n       * b) Corners are expected to be submitted as top-left to bottom-right.\n       *    Therefore, check that and reorder input.\n       * (be aware x,y are already casted to (uint32_t) and avoid (0 - 1) )\n       */\n      uint32_t aux;\n      if (x1 > x2) {\n        aux = x1;\n        x1 = x2;\n        x2 = aux;\n      }\n      if (y1 > y2) {\n        aux = y1;\n        y1 = y2;\n        y2 = aux;\n      }\n      if (x1 > image->width - 1)\n        crop->regionlist[i].x1 = image->width - 1;\n      else if (x1 > 0)\n        crop->regionlist[i].x1 = (uint32_t)(x1 - 1);\n\n      if (x2 > image->width - 1)\n        crop->regionlist[i].x2 = image->width - 1;\n      else if (x2 > 0)\n        crop->regionlist[i].x2 = (uint32_t)(x2 - 1);\n\n      zwidth = crop->regionlist[i].x2 - crop->regionlist[i].x1 + 1;\n\n      if (y1 > image->length - 1)\n        crop->regionlist[i].y1 = image->length - 1;\n      else if (y1 > 0)\n        crop->regionlist[i].y1 = (uint32_t)(y1 - 1);\n\n      if (y2 > image->length - 1)\n        crop->regionlist[i].y2 = image->length - 1;\n      else if (y2 > 0)\n        crop->regionlist[i].y2 = (uint32_t)(y2 - 1);\n\n      zlength = crop->regionlist[i].y2 - crop->regionlist[i].y1 + 1;\n      if (zwidth > max_width)\n        max_width = zwidth;\n      if (zlength > max_length)\n        max_length = zlength;\n\n      buffsize = (uint32_t)\n          (((zwidth * image->bps * image->spp + 7 ) / 8) * (zlength + 1));\n\n      crop->regionlist[i].buffsize = buffsize;\n      crop->bufftotal += buffsize;\n      if (crop->img_mode == COMPOSITE_IMAGES)\n        {\n        switch (crop->edge_ref)\n          {\n          case EDGE_LEFT:\n          case EDGE_RIGHT:\n               crop->combined_length = zlength;\n               crop->combined_width += zwidth;\n               break;\n          case EDGE_BOTTOM:\n          case EDGE_TOP:  /* width from left, length from top */\n          default:\n               crop->combined_width = zwidth;\n               crop->combined_length += zlength;\n\t       break;\n          }\n\t}\n      }\n    return (0);\n    }  /* crop_mode == CROP_REGIONS */\n  \n  /* Convert crop margins into offsets into image\n   * Margins are expressed as pixel rows and columns, not bytes\n   */\n  if (crop->crop_mode & CROP_MARGINS)\n    {\n    if (crop->res_unit != RESUNIT_INCH && crop->res_unit != RESUNIT_CENTIMETER)\n      { /* User has specified pixels as reference unit */\n      tmargin = (uint32_t)(crop->margins[0]);\n      lmargin = (uint32_t)(crop->margins[1]);\n      bmargin = (uint32_t)(crop->margins[2]);\n      rmargin = (uint32_t)(crop->margins[3]);\n      }\n    else\n      { /* inches or centimeters specified */\n      tmargin = (uint32_t)(crop->margins[0] * scale * yres);\n      lmargin = (uint32_t)(crop->margins[1] * scale * xres);\n      bmargin = (uint32_t)(crop->margins[2] * scale * yres);\n      rmargin = (uint32_t)(crop->margins[3] * scale * xres);\n      }\n\n    if ((lmargin + rmargin) > image->width)\n      {\n      TIFFError(\"computeInputPixelOffsets\", \"Combined left and right margins exceed image width\");\n      lmargin = (uint32_t) 0;\n      rmargin = (uint32_t) 0;\n      return (-1);\n      }\n    if ((tmargin + bmargin) > image->length)\n      {\n      TIFFError(\"computeInputPixelOffsets\", \"Combined top and bottom margins exceed image length\"); \n      tmargin = (uint32_t) 0;\n      bmargin = (uint32_t) 0;\n      return (-1);\n      }\n    }  /* crop_mode == CROP_MARGINS */\n  else\n    { /* no margins requested */\n    tmargin = (uint32_t) 0;\n    lmargin = (uint32_t) 0;\n    bmargin = (uint32_t) 0;\n    rmargin = (uint32_t) 0;\n    }\n\n  /* Width, height, and margins are expressed as pixel offsets into image */\n  if (crop->res_unit != RESUNIT_INCH && crop->res_unit != RESUNIT_CENTIMETER)\n    {\n    if (crop->crop_mode & CROP_WIDTH)\n      width = (uint32_t)crop->width;\n    else\n      width = image->width - lmargin - rmargin;\n\n    if (crop->crop_mode & CROP_LENGTH)\n      length  = (uint32_t)crop->length;\n    else\n      length = image->length - tmargin - bmargin;\n    }\n  else\n    {\n    if (crop->crop_mode & CROP_WIDTH)\n      width = (uint32_t)(crop->width * scale * image->xres);\n    else\n      width = image->width - lmargin - rmargin;\n\n    if (crop->crop_mode & CROP_LENGTH)\n      length  = (uint32_t)(crop->length * scale * image->yres);\n    else\n      length = image->length - tmargin - bmargin;\n    }\n\n  off->tmargin = tmargin;\n  off->bmargin = bmargin;\n  off->lmargin = lmargin;\n  off->rmargin = rmargin;\n\n  /* Calculate regions defined by margins, width, and length. \n   * Coordinates expressed as 0 to imagewidth - 1, imagelength - 1,\n   * since they are used to compute offsets into buffers */\n  switch (crop->edge_ref) {\n    case EDGE_BOTTOM:\n         startx = lmargin;\n         if ((startx + width) >= (image->width - rmargin))\n           endx = image->width - rmargin - 1;\n         else\n           endx = startx + width - 1;\n\n         endy = image->length - bmargin - 1;\n         if ((endy - length) <= tmargin)\n           starty = tmargin;\n         else\n           starty = endy - length + 1;\n         break;\n    case EDGE_RIGHT:\n         endx = image->width - rmargin - 1;\n         if ((endx - width) <= lmargin)\n           startx = lmargin;\n         else\n           startx = endx - width + 1;\n\n         starty = tmargin;\n         if ((starty + length) >= (image->length - bmargin))\n           endy = image->length - bmargin - 1;\n         else\n           endy = starty + length - 1;\n         break;\n    case EDGE_TOP:  /* width from left, length from top */\n    case EDGE_LEFT:\n    default:\n         startx = lmargin;\n         if ((startx + width) >= (image->width - rmargin))\n           endx = image->width - rmargin - 1;\n         else\n           endx = startx + width - 1;\n\n         starty = tmargin;\n         if ((starty + length) >= (image->length - bmargin))\n           endy = image->length - bmargin - 1;\n         else\n           endy = starty + length - 1;\n         break;\n    }\n  off->startx = startx;\n  off->starty = starty;\n  off->endx   = endx;\n  off->endy   = endy;\n\n  if (endx + 1 <= startx)\n    {\n    TIFFError(\"computeInputPixelOffsets\", \n               \"Invalid left/right margins and /or image crop width requested\");\n    return (-1);\n    }\n  crop_width  = endx - startx + 1;\n  if (crop_width > image->width)\n    crop_width = image->width;\n\n  if (endy + 1 <= starty)\n    {\n    TIFFError(\"computeInputPixelOffsets\", \n              \"Invalid top/bottom margins and /or image crop length requested\");\n    return (-1);\n    }\n  crop_length = endy - starty + 1;\n  if (crop_length > image->length)\n    crop_length = image->length;\n\n  off->crop_width = crop_width;\n  off->crop_length = crop_length;\n\n  return (0);\n  }",
        "func": "static int\ncomputeInputPixelOffsets(struct crop_mask *crop, struct image_data *image,\n                         struct offset *off)\n  {\n  double scale;\n  float xres, yres;\n  /* Values for these offsets are in pixels from start of image, not bytes,\n   * and are indexed from zero to width - 1 or length - 1 */\n  uint32_t tmargin, bmargin, lmargin, rmargin;\n  uint32_t startx, endx;   /* offsets of first and last columns to extract */\n  uint32_t starty, endy;   /* offsets of first and last row to extract */\n  uint32_t width, length, crop_width, crop_length;\n  uint32_t i, max_width, max_length, zwidth, zlength, buffsize;\n  uint32_t x1, x2, y1, y2;\n\n  if (image->res_unit != RESUNIT_INCH && image->res_unit != RESUNIT_CENTIMETER)\n    {\n    xres = 1.0;\n    yres = 1.0;\n    }\n  else\n    {\n    if (((image->xres == 0) || (image->yres == 0)) && \n         (crop->res_unit != RESUNIT_NONE) &&\n\t((crop->crop_mode & CROP_REGIONS) || (crop->crop_mode & CROP_MARGINS) ||\n \t (crop->crop_mode & CROP_LENGTH)  || (crop->crop_mode & CROP_WIDTH)))\n      {\n      TIFFError(\"computeInputPixelOffsets\", \"Cannot compute margins or fixed size sections without image resolution\");\n      TIFFError(\"computeInputPixelOffsets\", \"Specify units in pixels and try again\");\n      return (-1);\n      }\n    xres = image->xres;\n    yres = image->yres;\n    }\n\n  /* Translate user units to image units */\n  scale = 1.0;\n  switch (crop->res_unit) {\n    case RESUNIT_CENTIMETER:\n         if (image->res_unit == RESUNIT_INCH)\n\t   scale = 1.0/2.54;\n\t break;\n    case RESUNIT_INCH:\n\t if (image->res_unit == RESUNIT_CENTIMETER)\n\t     scale = 2.54;\n\t break;\n    case RESUNIT_NONE: /* Dimensions in pixels */\n    default:\n    break;\n    }\n\n  if (crop->crop_mode & CROP_REGIONS)\n    {\n    max_width = max_length = 0;\n    for (i = 0; i < crop->regions; i++)\n      {\n      if ((crop->res_unit == RESUNIT_INCH) || (crop->res_unit == RESUNIT_CENTIMETER))\n        {\n\tx1 = _TIFFClampDoubleToUInt32(crop->corners[i].X1 * scale * xres);\n\tx2 = _TIFFClampDoubleToUInt32(crop->corners[i].X2 * scale * xres);\n\ty1 = _TIFFClampDoubleToUInt32(crop->corners[i].Y1 * scale * yres);\n\ty2 = _TIFFClampDoubleToUInt32(crop->corners[i].Y2 * scale * yres);\n        }\n      else\n        {\n\tx1 = _TIFFClampDoubleToUInt32(crop->corners[i].X1);\n\tx2 = _TIFFClampDoubleToUInt32(crop->corners[i].X2);\n\ty1 = _TIFFClampDoubleToUInt32(crop->corners[i].Y1);\n\ty2 = _TIFFClampDoubleToUInt32(crop->corners[i].Y2);\n\t}\n      /* a) Region needs to be within image sizes 0.. width-1; 0..length-1 \n       * b) Corners are expected to be submitted as top-left to bottom-right.\n       *    Therefore, check that and reorder input.\n       * (be aware x,y are already casted to (uint32_t) and avoid (0 - 1) )\n       */\n      uint32_t aux;\n      if (x1 > x2) {\n        aux = x1;\n        x1 = x2;\n        x2 = aux;\n      }\n      if (y1 > y2) {\n        aux = y1;\n        y1 = y2;\n        y2 = aux;\n      }\n      if (x1 > image->width - 1)\n        crop->regionlist[i].x1 = image->width - 1;\n      else if (x1 > 0)\n        crop->regionlist[i].x1 = (uint32_t)(x1 - 1);\n\n      if (x2 > image->width - 1)\n        crop->regionlist[i].x2 = image->width - 1;\n      else if (x2 > 0)\n        crop->regionlist[i].x2 = (uint32_t)(x2 - 1);\n\n      zwidth = crop->regionlist[i].x2 - crop->regionlist[i].x1 + 1;\n\n      if (y1 > image->length - 1)\n        crop->regionlist[i].y1 = image->length - 1;\n      else if (y1 > 0)\n        crop->regionlist[i].y1 = (uint32_t)(y1 - 1);\n\n      if (y2 > image->length - 1)\n        crop->regionlist[i].y2 = image->length - 1;\n      else if (y2 > 0)\n        crop->regionlist[i].y2 = (uint32_t)(y2 - 1);\n\n      zlength = crop->regionlist[i].y2 - crop->regionlist[i].y1 + 1;\n      if (zwidth > max_width)\n        max_width = zwidth;\n      if (zlength > max_length)\n        max_length = zlength;\n\n      buffsize = (uint32_t)\n          (((zwidth * image->bps * image->spp + 7 ) / 8) * (zlength + 1));\n\n      crop->regionlist[i].buffsize = buffsize;\n      crop->bufftotal += buffsize;\n      if (crop->img_mode == COMPOSITE_IMAGES)\n        {\n        switch (crop->edge_ref)\n          {\n          case EDGE_LEFT:\n          case EDGE_RIGHT:\n               crop->combined_length = zlength;\n               crop->combined_width += zwidth;\n               break;\n          case EDGE_BOTTOM:\n          case EDGE_TOP:  /* width from left, length from top */\n          default:\n               crop->combined_width = zwidth;\n               crop->combined_length += zlength;\n\t       break;\n          }\n\t}\n      }\n    return (0);\n    }  /* crop_mode == CROP_REGIONS */\n  \n  /* Convert crop margins into offsets into image\n   * Margins are expressed as pixel rows and columns, not bytes\n   */\n  if (crop->crop_mode & CROP_MARGINS)\n    {\n    if (crop->res_unit != RESUNIT_INCH && crop->res_unit != RESUNIT_CENTIMETER)\n      { /* User has specified pixels as reference unit */\n      tmargin = _TIFFClampDoubleToUInt32(crop->margins[0]);\n      lmargin = _TIFFClampDoubleToUInt32(crop->margins[1]);\n      bmargin = _TIFFClampDoubleToUInt32(crop->margins[2]);\n      rmargin = _TIFFClampDoubleToUInt32(crop->margins[3]);\n      }\n    else\n      { /* inches or centimeters specified */\n      tmargin = _TIFFClampDoubleToUInt32(crop->margins[0] * scale * yres);\n      lmargin = _TIFFClampDoubleToUInt32(crop->margins[1] * scale * xres);\n      bmargin = _TIFFClampDoubleToUInt32(crop->margins[2] * scale * yres);\n      rmargin = _TIFFClampDoubleToUInt32(crop->margins[3] * scale * xres);\n      }\n\n    if ((lmargin + rmargin) > image->width)\n      {\n      TIFFError(\"computeInputPixelOffsets\", \"Combined left and right margins exceed image width\");\n      lmargin = (uint32_t) 0;\n      rmargin = (uint32_t) 0;\n      return (-1);\n      }\n    if ((tmargin + bmargin) > image->length)\n      {\n      TIFFError(\"computeInputPixelOffsets\", \"Combined top and bottom margins exceed image length\"); \n      tmargin = (uint32_t) 0;\n      bmargin = (uint32_t) 0;\n      return (-1);\n      }\n    }  /* crop_mode == CROP_MARGINS */\n  else\n    { /* no margins requested */\n    tmargin = (uint32_t) 0;\n    lmargin = (uint32_t) 0;\n    bmargin = (uint32_t) 0;\n    rmargin = (uint32_t) 0;\n    }\n\n  /* Width, height, and margins are expressed as pixel offsets into image */\n  if (crop->res_unit != RESUNIT_INCH && crop->res_unit != RESUNIT_CENTIMETER)\n    {\n    if (crop->crop_mode & CROP_WIDTH)\n      width = _TIFFClampDoubleToUInt32(crop->width);\n    else\n      width = image->width - lmargin - rmargin;\n\n    if (crop->crop_mode & CROP_LENGTH)\n      length  = _TIFFClampDoubleToUInt32(crop->length);\n    else\n      length = image->length - tmargin - bmargin;\n    }\n  else\n    {\n    if (crop->crop_mode & CROP_WIDTH)\n      width = _TIFFClampDoubleToUInt32(crop->width * scale * image->xres);\n    else\n      width = image->width - lmargin - rmargin;\n\n    if (crop->crop_mode & CROP_LENGTH)\n      length  = _TIFFClampDoubleToUInt32(crop->length * scale * image->yres);\n    else\n      length = image->length - tmargin - bmargin;\n    }\n\n  off->tmargin = tmargin;\n  off->bmargin = bmargin;\n  off->lmargin = lmargin;\n  off->rmargin = rmargin;\n\n  /* Calculate regions defined by margins, width, and length. \n   * Coordinates expressed as 0 to imagewidth - 1, imagelength - 1,\n   * since they are used to compute offsets into buffers */\n  switch (crop->edge_ref) {\n    case EDGE_BOTTOM:\n         startx = lmargin;\n         if ((startx + width) >= (image->width - rmargin))\n           endx = image->width - rmargin - 1;\n         else\n           endx = startx + width - 1;\n\n         endy = image->length - bmargin - 1;\n         if ((endy - length) <= tmargin)\n           starty = tmargin;\n         else\n           starty = endy - length + 1;\n         break;\n    case EDGE_RIGHT:\n         endx = image->width - rmargin - 1;\n         if ((endx - width) <= lmargin)\n           startx = lmargin;\n         else\n           startx = endx - width + 1;\n\n         starty = tmargin;\n         if ((starty + length) >= (image->length - bmargin))\n           endy = image->length - bmargin - 1;\n         else\n           endy = starty + length - 1;\n         break;\n    case EDGE_TOP:  /* width from left, length from top */\n    case EDGE_LEFT:\n    default:\n         startx = lmargin;\n         if ((startx + width) >= (image->width - rmargin))\n           endx = image->width - rmargin - 1;\n         else\n           endx = startx + width - 1;\n\n         starty = tmargin;\n         if ((starty + length) >= (image->length - bmargin))\n           endy = image->length - bmargin - 1;\n         else\n           endy = starty + length - 1;\n         break;\n    }\n  off->startx = startx;\n  off->starty = starty;\n  off->endx   = endx;\n  off->endy   = endy;\n\n  if (endx + 1 <= startx)\n    {\n    TIFFError(\"computeInputPixelOffsets\", \n               \"Invalid left/right margins and /or image crop width requested\");\n    return (-1);\n    }\n  crop_width  = endx - startx + 1;\n  if (crop_width > image->width)\n    crop_width = image->width;\n\n  if (endy + 1 <= starty)\n    {\n    TIFFError(\"computeInputPixelOffsets\", \n              \"Invalid top/bottom margins and /or image crop length requested\");\n    return (-1);\n    }\n  crop_length = endy - starty + 1;\n  if (crop_length > image->length)\n    crop_length = image->length;\n\n  off->crop_width = crop_width;\n  off->crop_length = crop_length;\n\n  return (0);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,17 +56,17 @@\n       {\n       if ((crop->res_unit == RESUNIT_INCH) || (crop->res_unit == RESUNIT_CENTIMETER))\n         {\n-\tx1 = (uint32_t) (crop->corners[i].X1 * scale * xres);\n-\tx2 = (uint32_t) (crop->corners[i].X2 * scale * xres);\n-\ty1 = (uint32_t) (crop->corners[i].Y1 * scale * yres);\n-\ty2 = (uint32_t) (crop->corners[i].Y2 * scale * yres);\n+\tx1 = _TIFFClampDoubleToUInt32(crop->corners[i].X1 * scale * xres);\n+\tx2 = _TIFFClampDoubleToUInt32(crop->corners[i].X2 * scale * xres);\n+\ty1 = _TIFFClampDoubleToUInt32(crop->corners[i].Y1 * scale * yres);\n+\ty2 = _TIFFClampDoubleToUInt32(crop->corners[i].Y2 * scale * yres);\n         }\n       else\n         {\n-\tx1 = (uint32_t) (crop->corners[i].X1);\n-\tx2 = (uint32_t) (crop->corners[i].X2);\n-\ty1 = (uint32_t) (crop->corners[i].Y1);\n-\ty2 = (uint32_t) (crop->corners[i].Y2);\n+\tx1 = _TIFFClampDoubleToUInt32(crop->corners[i].X1);\n+\tx2 = _TIFFClampDoubleToUInt32(crop->corners[i].X2);\n+\ty1 = _TIFFClampDoubleToUInt32(crop->corners[i].Y1);\n+\ty2 = _TIFFClampDoubleToUInt32(crop->corners[i].Y2);\n \t}\n       /* a) Region needs to be within image sizes 0.. width-1; 0..length-1 \n        * b) Corners are expected to be submitted as top-left to bottom-right.\n@@ -145,17 +145,17 @@\n     {\n     if (crop->res_unit != RESUNIT_INCH && crop->res_unit != RESUNIT_CENTIMETER)\n       { /* User has specified pixels as reference unit */\n-      tmargin = (uint32_t)(crop->margins[0]);\n-      lmargin = (uint32_t)(crop->margins[1]);\n-      bmargin = (uint32_t)(crop->margins[2]);\n-      rmargin = (uint32_t)(crop->margins[3]);\n+      tmargin = _TIFFClampDoubleToUInt32(crop->margins[0]);\n+      lmargin = _TIFFClampDoubleToUInt32(crop->margins[1]);\n+      bmargin = _TIFFClampDoubleToUInt32(crop->margins[2]);\n+      rmargin = _TIFFClampDoubleToUInt32(crop->margins[3]);\n       }\n     else\n       { /* inches or centimeters specified */\n-      tmargin = (uint32_t)(crop->margins[0] * scale * yres);\n-      lmargin = (uint32_t)(crop->margins[1] * scale * xres);\n-      bmargin = (uint32_t)(crop->margins[2] * scale * yres);\n-      rmargin = (uint32_t)(crop->margins[3] * scale * xres);\n+      tmargin = _TIFFClampDoubleToUInt32(crop->margins[0] * scale * yres);\n+      lmargin = _TIFFClampDoubleToUInt32(crop->margins[1] * scale * xres);\n+      bmargin = _TIFFClampDoubleToUInt32(crop->margins[2] * scale * yres);\n+      rmargin = _TIFFClampDoubleToUInt32(crop->margins[3] * scale * xres);\n       }\n \n     if ((lmargin + rmargin) > image->width)\n@@ -185,24 +185,24 @@\n   if (crop->res_unit != RESUNIT_INCH && crop->res_unit != RESUNIT_CENTIMETER)\n     {\n     if (crop->crop_mode & CROP_WIDTH)\n-      width = (uint32_t)crop->width;\n+      width = _TIFFClampDoubleToUInt32(crop->width);\n     else\n       width = image->width - lmargin - rmargin;\n \n     if (crop->crop_mode & CROP_LENGTH)\n-      length  = (uint32_t)crop->length;\n+      length  = _TIFFClampDoubleToUInt32(crop->length);\n     else\n       length = image->length - tmargin - bmargin;\n     }\n   else\n     {\n     if (crop->crop_mode & CROP_WIDTH)\n-      width = (uint32_t)(crop->width * scale * image->xres);\n+      width = _TIFFClampDoubleToUInt32(crop->width * scale * image->xres);\n     else\n       width = image->width - lmargin - rmargin;\n \n     if (crop->crop_mode & CROP_LENGTH)\n-      length  = (uint32_t)(crop->length * scale * image->yres);\n+      length  = _TIFFClampDoubleToUInt32(crop->length * scale * image->yres);\n     else\n       length = image->length - tmargin - bmargin;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "\tx1 = (uint32_t) (crop->corners[i].X1 * scale * xres);",
                "\tx2 = (uint32_t) (crop->corners[i].X2 * scale * xres);",
                "\ty1 = (uint32_t) (crop->corners[i].Y1 * scale * yres);",
                "\ty2 = (uint32_t) (crop->corners[i].Y2 * scale * yres);",
                "\tx1 = (uint32_t) (crop->corners[i].X1);",
                "\tx2 = (uint32_t) (crop->corners[i].X2);",
                "\ty1 = (uint32_t) (crop->corners[i].Y1);",
                "\ty2 = (uint32_t) (crop->corners[i].Y2);",
                "      tmargin = (uint32_t)(crop->margins[0]);",
                "      lmargin = (uint32_t)(crop->margins[1]);",
                "      bmargin = (uint32_t)(crop->margins[2]);",
                "      rmargin = (uint32_t)(crop->margins[3]);",
                "      tmargin = (uint32_t)(crop->margins[0] * scale * yres);",
                "      lmargin = (uint32_t)(crop->margins[1] * scale * xres);",
                "      bmargin = (uint32_t)(crop->margins[2] * scale * yres);",
                "      rmargin = (uint32_t)(crop->margins[3] * scale * xres);",
                "      width = (uint32_t)crop->width;",
                "      length  = (uint32_t)crop->length;",
                "      width = (uint32_t)(crop->width * scale * image->xres);",
                "      length  = (uint32_t)(crop->length * scale * image->yres);"
            ],
            "added_lines": [
                "\tx1 = _TIFFClampDoubleToUInt32(crop->corners[i].X1 * scale * xres);",
                "\tx2 = _TIFFClampDoubleToUInt32(crop->corners[i].X2 * scale * xres);",
                "\ty1 = _TIFFClampDoubleToUInt32(crop->corners[i].Y1 * scale * yres);",
                "\ty2 = _TIFFClampDoubleToUInt32(crop->corners[i].Y2 * scale * yres);",
                "\tx1 = _TIFFClampDoubleToUInt32(crop->corners[i].X1);",
                "\tx2 = _TIFFClampDoubleToUInt32(crop->corners[i].X2);",
                "\ty1 = _TIFFClampDoubleToUInt32(crop->corners[i].Y1);",
                "\ty2 = _TIFFClampDoubleToUInt32(crop->corners[i].Y2);",
                "      tmargin = _TIFFClampDoubleToUInt32(crop->margins[0]);",
                "      lmargin = _TIFFClampDoubleToUInt32(crop->margins[1]);",
                "      bmargin = _TIFFClampDoubleToUInt32(crop->margins[2]);",
                "      rmargin = _TIFFClampDoubleToUInt32(crop->margins[3]);",
                "      tmargin = _TIFFClampDoubleToUInt32(crop->margins[0] * scale * yres);",
                "      lmargin = _TIFFClampDoubleToUInt32(crop->margins[1] * scale * xres);",
                "      bmargin = _TIFFClampDoubleToUInt32(crop->margins[2] * scale * yres);",
                "      rmargin = _TIFFClampDoubleToUInt32(crop->margins[3] * scale * xres);",
                "      width = _TIFFClampDoubleToUInt32(crop->width);",
                "      length  = _TIFFClampDoubleToUInt32(crop->length);",
                "      width = _TIFFClampDoubleToUInt32(crop->width * scale * image->xres);",
                "      length  = _TIFFClampDoubleToUInt32(crop->length * scale * image->yres);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-2056",
        "func_name": "libtiff/computeOutputPixelOffsets",
        "description": "Divide By Zero error in tiffcrop in libtiff 4.4.0 allows attackers to cause a denial-of-service via a crafted tiff file. For users that compile libtiff from sources, the fix is available with commit f3a5e010.",
        "git_url": "https://gitlab.com/libtiff/libtiff/-/commit/ab6e93f10f7df01a43aacd51caa1ef6f61cf0ce5",
        "commit_title": "Fix FPE errors in tiffcrop (#415, #427, and #428)",
        "commit_text": "",
        "func_before": "static int\ncomputeOutputPixelOffsets (struct crop_mask *crop, struct image_data *image,\n                           struct pagedef *page, struct pageseg *sections,\n                           struct dump_opts* dump)\n  {\n  double scale;\n  double pwidth, plength;          /* Output page width and length in user units*/\n  uint32_t iwidth, ilength;          /* Input image width and length in pixels*/\n  uint32_t owidth, olength;          /* Output image width and length in pixels*/\n  uint32_t orows, ocols;             /* rows and cols for output */\n  uint32_t hmargin, vmargin;         /* Horizontal and vertical margins */\n  uint32_t x1, x2, y1, y2, line_bytes;\n  /* unsigned int orientation; */\n  uint32_t i, j, k;\n \n  scale = 1.0;\n  if (page->res_unit == RESUNIT_NONE)\n    page->res_unit = image->res_unit;\n\n  switch (image->res_unit) {\n    case RESUNIT_CENTIMETER:\n         if (page->res_unit == RESUNIT_INCH)\n\t   scale = 1.0/2.54;\n\t break;\n    case RESUNIT_INCH:\n\t if (page->res_unit == RESUNIT_CENTIMETER)\n\t     scale = 2.54;\n\t break;\n    case RESUNIT_NONE: /* Dimensions in pixels */\n    default:\n    break;\n    }\n\n  /* get width, height, resolutions of input image selection */\n  if (crop->combined_width > 0)\n    iwidth = crop->combined_width;\n  else\n    iwidth = image->width;\n  if (crop->combined_length > 0)\n    ilength = crop->combined_length;\n  else\n    ilength = image->length;\n\n  if (page->hres <= 1.0)\n    page->hres = image->xres;\n  if (page->vres <= 1.0)\n    page->vres = image->yres;\n\n  if ((page->hres < 1.0) || (page->vres < 1.0))\n    {\n    TIFFError(\"computeOutputPixelOffsets\",\n    \"Invalid horizontal or vertical resolution specified or read from input image\");\n    return (1);\n    }\n\n  /* If no page sizes are being specified, we just use the input image size to\n   * calculate maximum margins that can be taken from image.\n   */\n  if (page->width <= 0)\n    pwidth = iwidth;\n  else\n    pwidth = page->width;\n\n  if (page->length <= 0)\n    plength = ilength;\n  else\n    plength = page->length;\n\n  if (dump->debug)\n    {\n    TIFFError(\"\", \"Page size: %s, Vres: %3.2f, Hres: %3.2f, \"\n                   \"Hmargin: %3.2f, Vmargin: %3.2f\",\n\t     page->name, page->vres, page->hres,\n             page->hmargin, page->vmargin);\n    TIFFError(\"\", \"Res_unit: %\"PRIu16\", Scale: %3.2f, Page width: %3.2f, length: %3.2f\",\n           page->res_unit, scale, pwidth, plength);\n    }\n\n  /* compute margins at specified unit and resolution */\n  if (page->mode & PAGE_MODE_MARGINS)\n    {\n    if (page->res_unit == RESUNIT_INCH || page->res_unit == RESUNIT_CENTIMETER)\n      { /* inches or centimeters specified */\n      hmargin = (uint32_t)(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));\n      vmargin = (uint32_t)(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));\n      }\n    else\n      { /* Otherwise user has specified pixels as reference unit */\n      hmargin = (uint32_t)(page->hmargin * scale * ((image->bps + 7) / 8));\n      vmargin = (uint32_t)(page->vmargin * scale * ((image->bps + 7) / 8));\n      }\n\n    if ((hmargin * 2.0) > (pwidth * page->hres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined left and right margins exceed page width\");\n      hmargin = (uint32_t) 0;\n      return (-1);\n      }\n    if ((vmargin * 2.0) > (plength * page->vres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined top and bottom margins exceed page length\"); \n      vmargin = (uint32_t) 0;\n      return (-1);\n      }\n    }\n  else\n    {\n    hmargin = 0;\n    vmargin = 0;\n    }\n\n  if (page->mode & PAGE_MODE_ROWSCOLS )\n    {\n    /* Maybe someday but not for now */\n    if (page->mode & PAGE_MODE_MARGINS)\n      TIFFError(\"computeOutputPixelOffsets\", \n      \"Output margins cannot be specified with rows and columns\"); \n\n    owidth  = TIFFhowmany(iwidth, page->cols);\n    olength = TIFFhowmany(ilength, page->rows);\n    }\n  else\n    {\n    if (page->mode & PAGE_MODE_PAPERSIZE )\n      {\n      owidth  = (uint32_t)((pwidth * page->hres) - (hmargin * 2));\n      olength = (uint32_t)((plength * page->vres) - (vmargin * 2));\n      }\n    else\n      {\n      owidth = (uint32_t)(iwidth - (hmargin * 2 * page->hres));\n      olength = (uint32_t)(ilength - (vmargin * 2 * page->vres));\n      }\n    }\n\n  if (owidth > iwidth)\n    owidth = iwidth;\n  if (olength > ilength)\n    olength = ilength;\n\n  /* Compute the number of pages required for Portrait or Landscape */\n  switch (page->orient)\n    {\n    case ORIENTATION_NONE:\n    case ORIENTATION_PORTRAIT:\n         ocols = TIFFhowmany(iwidth, owidth);\n         orows = TIFFhowmany(ilength, olength);\n         /* orientation = ORIENTATION_PORTRAIT; */\n         break;\n\n    case ORIENTATION_LANDSCAPE:\n         ocols = TIFFhowmany(iwidth, olength);\n         orows = TIFFhowmany(ilength, owidth);\n         x1 = olength;\n         olength = owidth;\n         owidth = x1;\n         /* orientation = ORIENTATION_LANDSCAPE; */\n         break;\n\n    case ORIENTATION_AUTO:\n    default:\n         x1 = TIFFhowmany(iwidth, owidth);\n         x2 = TIFFhowmany(ilength, olength); \n         y1 = TIFFhowmany(iwidth, olength);\n         y2 = TIFFhowmany(ilength, owidth); \n\n         if ( (x1 * x2) < (y1 * y2))\n           { /* Portrait */\n           ocols = x1;\n           orows = x2;\n           /* orientation = ORIENTATION_PORTRAIT; */\n\t   }\n         else\n           { /* Landscape */\n           ocols = y1;\n           orows = y2;\n           x1 = olength;\n           olength = owidth;\n           owidth = x1;\n           /* orientation = ORIENTATION_LANDSCAPE; */\n           }\n    }\n\n  if (ocols < 1)\n    ocols = 1;\n  if (orows < 1)\n    orows = 1;\n\n  /* Always return rows and cols from calcuation above.\n   * (correct values needed external to this function)\n   * Warn, if user input settings has been changed.\n   */\n\n  if ((page->rows > 0) && (page->rows != orows)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n          \"Number of user input section rows down (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->rows, orows);\n  }\n  page->rows = orows;\n  if ((page->cols > 0) && (page->cols != ocols)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n        \"Number of user input section cols across (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->cols, ocols);\n  }\n  page->cols = ocols;\n\n  line_bytes = TIFFhowmany8(owidth * image->spp * image->bps);\n\n  if ((orows * ocols) > MAX_SECTIONS)\n   {\n   TIFFError(\"computeOutputPixelOffsets\",\n\t     \"Rows and Columns exceed maximum sections\\nIncrease resolution or reduce sections\");\n   return (-1);\n   }\n\n  /* build the list of offsets for each output section */\n  for (k = 0, i = 0; i < orows; i++)\n    {\n    y1 = (uint32_t)(olength * i);\n    y2 = (uint32_t)(olength * (i + 1) - 1);\n    if (y2 >= ilength)\n      y2 = ilength - 1;\n    for (j = 0; (j < ocols) && (k < MAX_SECTIONS); j++, k++)\n      {\n      x1 = (uint32_t)(owidth * j);\n      x2 = (uint32_t)(owidth * (j + 1) - 1);\n      if (x2 >= iwidth)\n        x2 = iwidth - 1;\n      sections[k].x1 = x1;\n      sections[k].x2 = x2;\n      sections[k].y1 = y1;\n      sections[k].y2 = y2;\n      sections[k].buffsize = line_bytes * olength;\n      sections[k].position = k + 1;\n      sections[k].total = orows * ocols;\n      } \n    } \n  return (0);\n  }",
        "func": "static int\ncomputeOutputPixelOffsets (struct crop_mask *crop, struct image_data *image,\n                           struct pagedef *page, struct pageseg *sections,\n                           struct dump_opts* dump)\n  {\n  double scale;\n  double pwidth, plength;          /* Output page width and length in user units*/\n  uint32_t iwidth, ilength;          /* Input image width and length in pixels*/\n  uint32_t owidth, olength;          /* Output image width and length in pixels*/\n  uint32_t orows, ocols;             /* rows and cols for output */\n  uint32_t hmargin, vmargin;         /* Horizontal and vertical margins */\n  uint32_t x1, x2, y1, y2, line_bytes;\n  /* unsigned int orientation; */\n  uint32_t i, j, k;\n \n  scale = 1.0;\n  if (page->res_unit == RESUNIT_NONE)\n    page->res_unit = image->res_unit;\n\n  switch (image->res_unit) {\n    case RESUNIT_CENTIMETER:\n         if (page->res_unit == RESUNIT_INCH)\n\t   scale = 1.0/2.54;\n\t break;\n    case RESUNIT_INCH:\n\t if (page->res_unit == RESUNIT_CENTIMETER)\n\t     scale = 2.54;\n\t break;\n    case RESUNIT_NONE: /* Dimensions in pixels */\n    default:\n    break;\n    }\n\n  /* get width, height, resolutions of input image selection */\n  if (crop->combined_width > 0)\n    iwidth = crop->combined_width;\n  else\n    iwidth = image->width;\n  if (crop->combined_length > 0)\n    ilength = crop->combined_length;\n  else\n    ilength = image->length;\n\n  if (page->hres <= 1.0)\n    page->hres = image->xres;\n  if (page->vres <= 1.0)\n    page->vres = image->yres;\n\n  if ((page->hres < 1.0) || (page->vres < 1.0))\n    {\n    TIFFError(\"computeOutputPixelOffsets\",\n    \"Invalid horizontal or vertical resolution specified or read from input image\");\n    return (1);\n    }\n\n  /* If no page sizes are being specified, we just use the input image size to\n   * calculate maximum margins that can be taken from image.\n   */\n  if (page->width <= 0)\n    pwidth = iwidth;\n  else\n    pwidth = page->width;\n\n  if (page->length <= 0)\n    plength = ilength;\n  else\n    plength = page->length;\n\n  if (dump->debug)\n    {\n    TIFFError(\"\", \"Page size: %s, Vres: %3.2f, Hres: %3.2f, \"\n                   \"Hmargin: %3.2f, Vmargin: %3.2f\",\n\t     page->name, page->vres, page->hres,\n             page->hmargin, page->vmargin);\n    TIFFError(\"\", \"Res_unit: %\"PRIu16\", Scale: %3.2f, Page width: %3.2f, length: %3.2f\",\n           page->res_unit, scale, pwidth, plength);\n    }\n\n  /* compute margins at specified unit and resolution */\n  if (page->mode & PAGE_MODE_MARGINS)\n    {\n    if (page->res_unit == RESUNIT_INCH || page->res_unit == RESUNIT_CENTIMETER)\n      { /* inches or centimeters specified */\n      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));\n      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));\n      }\n    else\n      { /* Otherwise user has specified pixels as reference unit */\n      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * ((image->bps + 7) / 8));\n      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * ((image->bps + 7) / 8));\n      }\n\n    if ((hmargin * 2.0) > (pwidth * page->hres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined left and right margins exceed page width\");\n      hmargin = (uint32_t) 0;\n      return (-1);\n      }\n    if ((vmargin * 2.0) > (plength * page->vres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined top and bottom margins exceed page length\"); \n      vmargin = (uint32_t) 0;\n      return (-1);\n      }\n    }\n  else\n    {\n    hmargin = 0;\n    vmargin = 0;\n    }\n\n  if (page->mode & PAGE_MODE_ROWSCOLS )\n    {\n    /* Maybe someday but not for now */\n    if (page->mode & PAGE_MODE_MARGINS)\n      TIFFError(\"computeOutputPixelOffsets\", \n      \"Output margins cannot be specified with rows and columns\"); \n\n    owidth  = TIFFhowmany(iwidth, page->cols);\n    olength = TIFFhowmany(ilength, page->rows);\n    }\n  else\n    {\n    if (page->mode & PAGE_MODE_PAPERSIZE )\n      {\n      owidth  = _TIFFClampDoubleToUInt32((pwidth * page->hres) - (hmargin * 2));\n      olength = _TIFFClampDoubleToUInt32((plength * page->vres) - (vmargin * 2));\n      }\n    else\n      {\n      owidth = _TIFFClampDoubleToUInt32(iwidth - (hmargin * 2 * page->hres));\n      olength = _TIFFClampDoubleToUInt32(ilength - (vmargin * 2 * page->vres));\n      }\n    }\n\n  if (owidth > iwidth)\n    owidth = iwidth;\n  if (olength > ilength)\n    olength = ilength;\n\n  if (owidth == 0 || olength == 0)\n  {\n    TIFFError(\"computeOutputPixelOffsets\", \"Integer overflow when calculating the number of pages\");\n\t  exit(EXIT_FAILURE);\n  }\n\n  /* Compute the number of pages required for Portrait or Landscape */\n  switch (page->orient)\n    {\n    case ORIENTATION_NONE:\n    case ORIENTATION_PORTRAIT:\n         ocols = TIFFhowmany(iwidth, owidth);\n         orows = TIFFhowmany(ilength, olength);\n         /* orientation = ORIENTATION_PORTRAIT; */\n         break;\n\n    case ORIENTATION_LANDSCAPE:\n         ocols = TIFFhowmany(iwidth, olength);\n         orows = TIFFhowmany(ilength, owidth);\n         x1 = olength;\n         olength = owidth;\n         owidth = x1;\n         /* orientation = ORIENTATION_LANDSCAPE; */\n         break;\n\n    case ORIENTATION_AUTO:\n    default:\n         x1 = TIFFhowmany(iwidth, owidth);\n         x2 = TIFFhowmany(ilength, olength); \n         y1 = TIFFhowmany(iwidth, olength);\n         y2 = TIFFhowmany(ilength, owidth); \n\n         if ( (x1 * x2) < (y1 * y2))\n           { /* Portrait */\n           ocols = x1;\n           orows = x2;\n           /* orientation = ORIENTATION_PORTRAIT; */\n\t   }\n         else\n           { /* Landscape */\n           ocols = y1;\n           orows = y2;\n           x1 = olength;\n           olength = owidth;\n           owidth = x1;\n           /* orientation = ORIENTATION_LANDSCAPE; */\n           }\n    }\n\n  if (ocols < 1)\n    ocols = 1;\n  if (orows < 1)\n    orows = 1;\n\n  /* Always return rows and cols from calcuation above.\n   * (correct values needed external to this function)\n   * Warn, if user input settings has been changed.\n   */\n\n  if ((page->rows > 0) && (page->rows != orows)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n          \"Number of user input section rows down (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->rows, orows);\n  }\n  page->rows = orows;\n  if ((page->cols > 0) && (page->cols != ocols)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n        \"Number of user input section cols across (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->cols, ocols);\n  }\n  page->cols = ocols;\n\n  line_bytes = TIFFhowmany8(owidth * image->spp * image->bps);\n\n  if ((orows * ocols) > MAX_SECTIONS)\n   {\n   TIFFError(\"computeOutputPixelOffsets\",\n\t     \"Rows and Columns exceed maximum sections\\nIncrease resolution or reduce sections\");\n   return (-1);\n   }\n\n  /* build the list of offsets for each output section */\n  for (k = 0, i = 0; i < orows; i++)\n    {\n    y1 = (uint32_t)(olength * i);\n    y2 = (uint32_t)(olength * (i + 1) - 1);\n    if (y2 >= ilength)\n      y2 = ilength - 1;\n    for (j = 0; (j < ocols) && (k < MAX_SECTIONS); j++, k++)\n      {\n      x1 = (uint32_t)(owidth * j);\n      x2 = (uint32_t)(owidth * (j + 1) - 1);\n      if (x2 >= iwidth)\n        x2 = iwidth - 1;\n      sections[k].x1 = x1;\n      sections[k].x2 = x2;\n      sections[k].y1 = y1;\n      sections[k].y2 = y2;\n      sections[k].buffsize = line_bytes * olength;\n      sections[k].position = k + 1;\n      sections[k].total = orows * ocols;\n      } \n    } \n  return (0);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -81,13 +81,13 @@\n     {\n     if (page->res_unit == RESUNIT_INCH || page->res_unit == RESUNIT_CENTIMETER)\n       { /* inches or centimeters specified */\n-      hmargin = (uint32_t)(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));\n-      vmargin = (uint32_t)(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));\n+      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));\n+      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));\n       }\n     else\n       { /* Otherwise user has specified pixels as reference unit */\n-      hmargin = (uint32_t)(page->hmargin * scale * ((image->bps + 7) / 8));\n-      vmargin = (uint32_t)(page->vmargin * scale * ((image->bps + 7) / 8));\n+      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * ((image->bps + 7) / 8));\n+      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * ((image->bps + 7) / 8));\n       }\n \n     if ((hmargin * 2.0) > (pwidth * page->hres))\n@@ -125,13 +125,13 @@\n     {\n     if (page->mode & PAGE_MODE_PAPERSIZE )\n       {\n-      owidth  = (uint32_t)((pwidth * page->hres) - (hmargin * 2));\n-      olength = (uint32_t)((plength * page->vres) - (vmargin * 2));\n+      owidth  = _TIFFClampDoubleToUInt32((pwidth * page->hres) - (hmargin * 2));\n+      olength = _TIFFClampDoubleToUInt32((plength * page->vres) - (vmargin * 2));\n       }\n     else\n       {\n-      owidth = (uint32_t)(iwidth - (hmargin * 2 * page->hres));\n-      olength = (uint32_t)(ilength - (vmargin * 2 * page->vres));\n+      owidth = _TIFFClampDoubleToUInt32(iwidth - (hmargin * 2 * page->hres));\n+      olength = _TIFFClampDoubleToUInt32(ilength - (vmargin * 2 * page->vres));\n       }\n     }\n \n@@ -139,6 +139,12 @@\n     owidth = iwidth;\n   if (olength > ilength)\n     olength = ilength;\n+\n+  if (owidth == 0 || olength == 0)\n+  {\n+    TIFFError(\"computeOutputPixelOffsets\", \"Integer overflow when calculating the number of pages\");\n+\t  exit(EXIT_FAILURE);\n+  }\n \n   /* Compute the number of pages required for Portrait or Landscape */\n   switch (page->orient)",
        "diff_line_info": {
            "deleted_lines": [
                "      hmargin = (uint32_t)(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));",
                "      vmargin = (uint32_t)(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));",
                "      hmargin = (uint32_t)(page->hmargin * scale * ((image->bps + 7) / 8));",
                "      vmargin = (uint32_t)(page->vmargin * scale * ((image->bps + 7) / 8));",
                "      owidth  = (uint32_t)((pwidth * page->hres) - (hmargin * 2));",
                "      olength = (uint32_t)((plength * page->vres) - (vmargin * 2));",
                "      owidth = (uint32_t)(iwidth - (hmargin * 2 * page->hres));",
                "      olength = (uint32_t)(ilength - (vmargin * 2 * page->vres));"
            ],
            "added_lines": [
                "      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));",
                "      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));",
                "      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * ((image->bps + 7) / 8));",
                "      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * ((image->bps + 7) / 8));",
                "      owidth  = _TIFFClampDoubleToUInt32((pwidth * page->hres) - (hmargin * 2));",
                "      olength = _TIFFClampDoubleToUInt32((plength * page->vres) - (vmargin * 2));",
                "      owidth = _TIFFClampDoubleToUInt32(iwidth - (hmargin * 2 * page->hres));",
                "      olength = _TIFFClampDoubleToUInt32(ilength - (vmargin * 2 * page->vres));",
                "",
                "  if (owidth == 0 || olength == 0)",
                "  {",
                "    TIFFError(\"computeOutputPixelOffsets\", \"Integer overflow when calculating the number of pages\");",
                "\t  exit(EXIT_FAILURE);",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-2056",
        "func_name": "libtiff/computeOutputPixelOffsets",
        "description": "Divide By Zero error in tiffcrop in libtiff 4.4.0 allows attackers to cause a denial-of-service via a crafted tiff file. For users that compile libtiff from sources, the fix is available with commit f3a5e010.",
        "git_url": "https://gitlab.com/libtiff/libtiff/-/commit/70d09b49ba449efa5e7b1258ef61db1ba1527c5e",
        "commit_title": "fix inconsistent identation",
        "commit_text": "",
        "func_before": "static int\ncomputeOutputPixelOffsets (struct crop_mask *crop, struct image_data *image,\n                           struct pagedef *page, struct pageseg *sections,\n                           struct dump_opts* dump)\n  {\n  double scale;\n  double pwidth, plength;          /* Output page width and length in user units*/\n  uint32_t iwidth, ilength;          /* Input image width and length in pixels*/\n  uint32_t owidth, olength;          /* Output image width and length in pixels*/\n  uint32_t orows, ocols;             /* rows and cols for output */\n  uint32_t hmargin, vmargin;         /* Horizontal and vertical margins */\n  uint32_t x1, x2, y1, y2, line_bytes;\n  /* unsigned int orientation; */\n  uint32_t i, j, k;\n \n  scale = 1.0;\n  if (page->res_unit == RESUNIT_NONE)\n    page->res_unit = image->res_unit;\n\n  switch (image->res_unit) {\n    case RESUNIT_CENTIMETER:\n         if (page->res_unit == RESUNIT_INCH)\n\t   scale = 1.0/2.54;\n\t break;\n    case RESUNIT_INCH:\n\t if (page->res_unit == RESUNIT_CENTIMETER)\n\t     scale = 2.54;\n\t break;\n    case RESUNIT_NONE: /* Dimensions in pixels */\n    default:\n    break;\n    }\n\n  /* get width, height, resolutions of input image selection */\n  if (crop->combined_width > 0)\n    iwidth = crop->combined_width;\n  else\n    iwidth = image->width;\n  if (crop->combined_length > 0)\n    ilength = crop->combined_length;\n  else\n    ilength = image->length;\n\n  if (page->hres <= 1.0)\n    page->hres = image->xres;\n  if (page->vres <= 1.0)\n    page->vres = image->yres;\n\n  if ((page->hres < 1.0) || (page->vres < 1.0))\n    {\n    TIFFError(\"computeOutputPixelOffsets\",\n    \"Invalid horizontal or vertical resolution specified or read from input image\");\n    return (1);\n    }\n\n  /* If no page sizes are being specified, we just use the input image size to\n   * calculate maximum margins that can be taken from image.\n   */\n  if (page->width <= 0)\n    pwidth = iwidth;\n  else\n    pwidth = page->width;\n\n  if (page->length <= 0)\n    plength = ilength;\n  else\n    plength = page->length;\n\n  if (dump->debug)\n    {\n    TIFFError(\"\", \"Page size: %s, Vres: %3.2f, Hres: %3.2f, \"\n                   \"Hmargin: %3.2f, Vmargin: %3.2f\",\n\t     page->name, page->vres, page->hres,\n             page->hmargin, page->vmargin);\n    TIFFError(\"\", \"Res_unit: %\"PRIu16\", Scale: %3.2f, Page width: %3.2f, length: %3.2f\",\n           page->res_unit, scale, pwidth, plength);\n    }\n\n  /* compute margins at specified unit and resolution */\n  if (page->mode & PAGE_MODE_MARGINS)\n    {\n    if (page->res_unit == RESUNIT_INCH || page->res_unit == RESUNIT_CENTIMETER)\n      { /* inches or centimeters specified */\n      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));\n      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));\n      }\n    else\n      { /* Otherwise user has specified pixels as reference unit */\n      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * ((image->bps + 7) / 8));\n      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * ((image->bps + 7) / 8));\n      }\n\n    if ((hmargin * 2.0) > (pwidth * page->hres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined left and right margins exceed page width\");\n      hmargin = (uint32_t) 0;\n      return (-1);\n      }\n    if ((vmargin * 2.0) > (plength * page->vres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined top and bottom margins exceed page length\"); \n      vmargin = (uint32_t) 0;\n      return (-1);\n      }\n    }\n  else\n    {\n    hmargin = 0;\n    vmargin = 0;\n    }\n\n  if (page->mode & PAGE_MODE_ROWSCOLS )\n    {\n    /* Maybe someday but not for now */\n    if (page->mode & PAGE_MODE_MARGINS)\n      TIFFError(\"computeOutputPixelOffsets\", \n      \"Output margins cannot be specified with rows and columns\"); \n\n    owidth  = TIFFhowmany(iwidth, page->cols);\n    olength = TIFFhowmany(ilength, page->rows);\n    }\n  else\n    {\n    if (page->mode & PAGE_MODE_PAPERSIZE )\n      {\n      owidth  = _TIFFClampDoubleToUInt32((pwidth * page->hres) - (hmargin * 2));\n      olength = _TIFFClampDoubleToUInt32((plength * page->vres) - (vmargin * 2));\n      }\n    else\n      {\n      owidth = _TIFFClampDoubleToUInt32(iwidth - (hmargin * 2 * page->hres));\n      olength = _TIFFClampDoubleToUInt32(ilength - (vmargin * 2 * page->vres));\n      }\n    }\n\n  if (owidth > iwidth)\n    owidth = iwidth;\n  if (olength > ilength)\n    olength = ilength;\n\n  if (owidth == 0 || olength == 0)\n  {\n    TIFFError(\"computeOutputPixelOffsets\", \"Integer overflow when calculating the number of pages\");\n\t  exit(EXIT_FAILURE);\n  }\n\n  /* Compute the number of pages required for Portrait or Landscape */\n  switch (page->orient)\n    {\n    case ORIENTATION_NONE:\n    case ORIENTATION_PORTRAIT:\n         ocols = TIFFhowmany(iwidth, owidth);\n         orows = TIFFhowmany(ilength, olength);\n         /* orientation = ORIENTATION_PORTRAIT; */\n         break;\n\n    case ORIENTATION_LANDSCAPE:\n         ocols = TIFFhowmany(iwidth, olength);\n         orows = TIFFhowmany(ilength, owidth);\n         x1 = olength;\n         olength = owidth;\n         owidth = x1;\n         /* orientation = ORIENTATION_LANDSCAPE; */\n         break;\n\n    case ORIENTATION_AUTO:\n    default:\n         x1 = TIFFhowmany(iwidth, owidth);\n         x2 = TIFFhowmany(ilength, olength); \n         y1 = TIFFhowmany(iwidth, olength);\n         y2 = TIFFhowmany(ilength, owidth); \n\n         if ( (x1 * x2) < (y1 * y2))\n           { /* Portrait */\n           ocols = x1;\n           orows = x2;\n           /* orientation = ORIENTATION_PORTRAIT; */\n\t   }\n         else\n           { /* Landscape */\n           ocols = y1;\n           orows = y2;\n           x1 = olength;\n           olength = owidth;\n           owidth = x1;\n           /* orientation = ORIENTATION_LANDSCAPE; */\n           }\n    }\n\n  if (ocols < 1)\n    ocols = 1;\n  if (orows < 1)\n    orows = 1;\n\n  /* Always return rows and cols from calcuation above.\n   * (correct values needed external to this function)\n   * Warn, if user input settings has been changed.\n   */\n\n  if ((page->rows > 0) && (page->rows != orows)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n          \"Number of user input section rows down (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->rows, orows);\n  }\n  page->rows = orows;\n  if ((page->cols > 0) && (page->cols != ocols)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n        \"Number of user input section cols across (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->cols, ocols);\n  }\n  page->cols = ocols;\n\n  line_bytes = TIFFhowmany8(owidth * image->spp * image->bps);\n\n  if ((orows * ocols) > MAX_SECTIONS)\n   {\n   TIFFError(\"computeOutputPixelOffsets\",\n\t     \"Rows and Columns exceed maximum sections\\nIncrease resolution or reduce sections\");\n   return (-1);\n   }\n\n  /* build the list of offsets for each output section */\n  for (k = 0, i = 0; i < orows; i++)\n    {\n    y1 = (uint32_t)(olength * i);\n    y2 = (uint32_t)(olength * (i + 1) - 1);\n    if (y2 >= ilength)\n      y2 = ilength - 1;\n    for (j = 0; (j < ocols) && (k < MAX_SECTIONS); j++, k++)\n      {\n      x1 = (uint32_t)(owidth * j);\n      x2 = (uint32_t)(owidth * (j + 1) - 1);\n      if (x2 >= iwidth)\n        x2 = iwidth - 1;\n      sections[k].x1 = x1;\n      sections[k].x2 = x2;\n      sections[k].y1 = y1;\n      sections[k].y2 = y2;\n      sections[k].buffsize = line_bytes * olength;\n      sections[k].position = k + 1;\n      sections[k].total = orows * ocols;\n      } \n    } \n  return (0);\n  }",
        "func": "static int\ncomputeOutputPixelOffsets (struct crop_mask *crop, struct image_data *image,\n                           struct pagedef *page, struct pageseg *sections,\n                           struct dump_opts* dump)\n  {\n  double scale;\n  double pwidth, plength;          /* Output page width and length in user units*/\n  uint32_t iwidth, ilength;          /* Input image width and length in pixels*/\n  uint32_t owidth, olength;          /* Output image width and length in pixels*/\n  uint32_t orows, ocols;             /* rows and cols for output */\n  uint32_t hmargin, vmargin;         /* Horizontal and vertical margins */\n  uint32_t x1, x2, y1, y2, line_bytes;\n  /* unsigned int orientation; */\n  uint32_t i, j, k;\n \n  scale = 1.0;\n  if (page->res_unit == RESUNIT_NONE)\n    page->res_unit = image->res_unit;\n\n  switch (image->res_unit) {\n    case RESUNIT_CENTIMETER:\n         if (page->res_unit == RESUNIT_INCH)\n\t   scale = 1.0/2.54;\n\t break;\n    case RESUNIT_INCH:\n\t if (page->res_unit == RESUNIT_CENTIMETER)\n\t     scale = 2.54;\n\t break;\n    case RESUNIT_NONE: /* Dimensions in pixels */\n    default:\n    break;\n    }\n\n  /* get width, height, resolutions of input image selection */\n  if (crop->combined_width > 0)\n    iwidth = crop->combined_width;\n  else\n    iwidth = image->width;\n  if (crop->combined_length > 0)\n    ilength = crop->combined_length;\n  else\n    ilength = image->length;\n\n  if (page->hres <= 1.0)\n    page->hres = image->xres;\n  if (page->vres <= 1.0)\n    page->vres = image->yres;\n\n  if ((page->hres < 1.0) || (page->vres < 1.0))\n    {\n    TIFFError(\"computeOutputPixelOffsets\",\n    \"Invalid horizontal or vertical resolution specified or read from input image\");\n    return (1);\n    }\n\n  /* If no page sizes are being specified, we just use the input image size to\n   * calculate maximum margins that can be taken from image.\n   */\n  if (page->width <= 0)\n    pwidth = iwidth;\n  else\n    pwidth = page->width;\n\n  if (page->length <= 0)\n    plength = ilength;\n  else\n    plength = page->length;\n\n  if (dump->debug)\n    {\n    TIFFError(\"\", \"Page size: %s, Vres: %3.2f, Hres: %3.2f, \"\n                   \"Hmargin: %3.2f, Vmargin: %3.2f\",\n\t     page->name, page->vres, page->hres,\n             page->hmargin, page->vmargin);\n    TIFFError(\"\", \"Res_unit: %\"PRIu16\", Scale: %3.2f, Page width: %3.2f, length: %3.2f\",\n           page->res_unit, scale, pwidth, plength);\n    }\n\n  /* compute margins at specified unit and resolution */\n  if (page->mode & PAGE_MODE_MARGINS)\n    {\n    if (page->res_unit == RESUNIT_INCH || page->res_unit == RESUNIT_CENTIMETER)\n      { /* inches or centimeters specified */\n      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * page->hres * ((image->bps + 7) / 8));\n      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * page->vres * ((image->bps + 7) / 8));\n      }\n    else\n      { /* Otherwise user has specified pixels as reference unit */\n      hmargin = _TIFFClampDoubleToUInt32(page->hmargin * scale * ((image->bps + 7) / 8));\n      vmargin = _TIFFClampDoubleToUInt32(page->vmargin * scale * ((image->bps + 7) / 8));\n      }\n\n    if ((hmargin * 2.0) > (pwidth * page->hres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined left and right margins exceed page width\");\n      hmargin = (uint32_t) 0;\n      return (-1);\n      }\n    if ((vmargin * 2.0) > (plength * page->vres))\n      {\n      TIFFError(\"computeOutputPixelOffsets\", \n                \"Combined top and bottom margins exceed page length\"); \n      vmargin = (uint32_t) 0;\n      return (-1);\n      }\n    }\n  else\n    {\n    hmargin = 0;\n    vmargin = 0;\n    }\n\n  if (page->mode & PAGE_MODE_ROWSCOLS )\n    {\n    /* Maybe someday but not for now */\n    if (page->mode & PAGE_MODE_MARGINS)\n      TIFFError(\"computeOutputPixelOffsets\", \n      \"Output margins cannot be specified with rows and columns\"); \n\n    owidth  = TIFFhowmany(iwidth, page->cols);\n    olength = TIFFhowmany(ilength, page->rows);\n    }\n  else\n    {\n    if (page->mode & PAGE_MODE_PAPERSIZE )\n      {\n      owidth  = _TIFFClampDoubleToUInt32((pwidth * page->hres) - (hmargin * 2));\n      olength = _TIFFClampDoubleToUInt32((plength * page->vres) - (vmargin * 2));\n      }\n    else\n      {\n      owidth = _TIFFClampDoubleToUInt32(iwidth - (hmargin * 2 * page->hres));\n      olength = _TIFFClampDoubleToUInt32(ilength - (vmargin * 2 * page->vres));\n      }\n    }\n\n  if (owidth > iwidth)\n    owidth = iwidth;\n  if (olength > ilength)\n    olength = ilength;\n\n  if (owidth == 0 || olength == 0)\n  {\n    TIFFError(\"computeOutputPixelOffsets\", \"Integer overflow when calculating the number of pages\");\n    exit(EXIT_FAILURE);\n  }\n\n  /* Compute the number of pages required for Portrait or Landscape */\n  switch (page->orient)\n    {\n    case ORIENTATION_NONE:\n    case ORIENTATION_PORTRAIT:\n         ocols = TIFFhowmany(iwidth, owidth);\n         orows = TIFFhowmany(ilength, olength);\n         /* orientation = ORIENTATION_PORTRAIT; */\n         break;\n\n    case ORIENTATION_LANDSCAPE:\n         ocols = TIFFhowmany(iwidth, olength);\n         orows = TIFFhowmany(ilength, owidth);\n         x1 = olength;\n         olength = owidth;\n         owidth = x1;\n         /* orientation = ORIENTATION_LANDSCAPE; */\n         break;\n\n    case ORIENTATION_AUTO:\n    default:\n         x1 = TIFFhowmany(iwidth, owidth);\n         x2 = TIFFhowmany(ilength, olength); \n         y1 = TIFFhowmany(iwidth, olength);\n         y2 = TIFFhowmany(ilength, owidth); \n\n         if ( (x1 * x2) < (y1 * y2))\n           { /* Portrait */\n           ocols = x1;\n           orows = x2;\n           /* orientation = ORIENTATION_PORTRAIT; */\n\t   }\n         else\n           { /* Landscape */\n           ocols = y1;\n           orows = y2;\n           x1 = olength;\n           olength = owidth;\n           owidth = x1;\n           /* orientation = ORIENTATION_LANDSCAPE; */\n           }\n    }\n\n  if (ocols < 1)\n    ocols = 1;\n  if (orows < 1)\n    orows = 1;\n\n  /* Always return rows and cols from calcuation above.\n   * (correct values needed external to this function)\n   * Warn, if user input settings has been changed.\n   */\n\n  if ((page->rows > 0) && (page->rows != orows)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n          \"Number of user input section rows down (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->rows, orows);\n  }\n  page->rows = orows;\n  if ((page->cols > 0) && (page->cols != ocols)) {\n    TIFFError(\"computeOutputPixelOffsets\",\n        \"Number of user input section cols across (%\"PRIu32\") was changed to (%\"PRIu32\")\", page->cols, ocols);\n  }\n  page->cols = ocols;\n\n  line_bytes = TIFFhowmany8(owidth * image->spp * image->bps);\n\n  if ((orows * ocols) > MAX_SECTIONS)\n   {\n   TIFFError(\"computeOutputPixelOffsets\",\n\t     \"Rows and Columns exceed maximum sections\\nIncrease resolution or reduce sections\");\n   return (-1);\n   }\n\n  /* build the list of offsets for each output section */\n  for (k = 0, i = 0; i < orows; i++)\n    {\n    y1 = (uint32_t)(olength * i);\n    y2 = (uint32_t)(olength * (i + 1) - 1);\n    if (y2 >= ilength)\n      y2 = ilength - 1;\n    for (j = 0; (j < ocols) && (k < MAX_SECTIONS); j++, k++)\n      {\n      x1 = (uint32_t)(owidth * j);\n      x2 = (uint32_t)(owidth * (j + 1) - 1);\n      if (x2 >= iwidth)\n        x2 = iwidth - 1;\n      sections[k].x1 = x1;\n      sections[k].x2 = x2;\n      sections[k].y1 = y1;\n      sections[k].y2 = y2;\n      sections[k].buffsize = line_bytes * olength;\n      sections[k].position = k + 1;\n      sections[k].total = orows * ocols;\n      } \n    } \n  return (0);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -143,7 +143,7 @@\n   if (owidth == 0 || olength == 0)\n   {\n     TIFFError(\"computeOutputPixelOffsets\", \"Integer overflow when calculating the number of pages\");\n-\t  exit(EXIT_FAILURE);\n+    exit(EXIT_FAILURE);\n   }\n \n   /* Compute the number of pages required for Portrait or Landscape */",
        "diff_line_info": {
            "deleted_lines": [
                "\t  exit(EXIT_FAILURE);"
            ],
            "added_lines": [
                "    exit(EXIT_FAILURE);"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-20845",
        "func_name": "uclouvain/openjpeg/pi_next_pcrl",
        "description": "Division-by-zero vulnerabilities in the functions pi_next_pcrl, pi_next_cprl, and pi_next_rpcl in openmj2/pi.c in OpenJPEG through 2.3.0 allow remote attackers to cause a denial of service (application crash).",
        "git_url": "https://github.com/uclouvain/openjpeg/commit/c5bd64ea146162967c29bd2af0cbb845ba3eaaaf",
        "commit_title": "[MJ2] To avoid divisions by zero / undefined behaviour on shift",
        "commit_text": "",
        "func_before": "static opj_bool pi_next_pcrl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    long index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        int compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                int dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1 << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1 << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : int_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : int_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n            pi->y += pi->dy - (pi->y % pi->dy)) {\n        for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                pi->x += pi->dx - (pi->x % pi->dx)) {\n            for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                comp = &pi->comps[pi->compno];\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < int_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    int levelno;\n                    int trx0, try0;\n                    int trx1, try1;\n                    int rpx, rpy;\n                    int prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = int_ceildiv(pi->tx0, comp->dx << levelno);\n                    try0 = int_ceildiv(pi->ty0, comp->dy << levelno);\n                    trx1 = int_ceildiv(pi->tx1, comp->dx << levelno);\n                    try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n                    if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = int_floordivpow2(int_ceildiv(pi->x, comp->dx << levelno), res->pdx)\n                           - int_floordivpow2(trx0, res->pdx);\n                    prcj = int_floordivpow2(int_ceildiv(pi->y, comp->dy << levelno), res->pdy)\n                           - int_floordivpow2(try0, res->pdy);\n                    pi->precno = prci + prcj * res->pw;\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "func": "static opj_bool pi_next_pcrl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    long index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        int compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                int dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1 << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1 << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : int_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : int_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n            pi->y += pi->dy - (pi->y % pi->dy)) {\n        for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                pi->x += pi->dx - (pi->x % pi->dx)) {\n            for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                comp = &pi->comps[pi->compno];\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < int_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    int levelno;\n                    int trx0, try0;\n                    int trx1, try1;\n                    int rpx, rpy;\n                    int prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = int_ceildiv(pi->tx0, comp->dx << levelno);\n                    try0 = int_ceildiv(pi->ty0, comp->dy << levelno);\n                    trx1 = int_ceildiv(pi->tx1, comp->dx << levelno);\n                    try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n\n                    /* To avoid divisions by zero / undefined behaviour on shift */\n                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n                        continue;\n                    }\n\n                    if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = int_floordivpow2(int_ceildiv(pi->x, comp->dx << levelno), res->pdx)\n                           - int_floordivpow2(trx0, res->pdx);\n                    prcj = int_floordivpow2(int_ceildiv(pi->y, comp->dy << levelno), res->pdy)\n                           - int_floordivpow2(try0, res->pdy);\n                    pi->precno = prci + prcj * res->pw;\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -51,6 +51,13 @@\n                     try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                     rpx = res->pdx + levelno;\n                     rpy = res->pdy + levelno;\n+\n+                    /* To avoid divisions by zero / undefined behaviour on shift */\n+                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n+                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n+                        continue;\n+                    }\n+\n                     if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                             ((try0 << levelno) % (1 << rpy))))) {\n                         continue;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "                    /* To avoid divisions by zero / undefined behaviour on shift */",
                "                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||",
                "                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {",
                "                        continue;",
                "                    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2018-20845",
        "func_name": "uclouvain/openjpeg/pi_next_rpcl",
        "description": "Division-by-zero vulnerabilities in the functions pi_next_pcrl, pi_next_cprl, and pi_next_rpcl in openmj2/pi.c in OpenJPEG through 2.3.0 allow remote attackers to cause a denial of service (application crash).",
        "git_url": "https://github.com/uclouvain/openjpeg/commit/c5bd64ea146162967c29bd2af0cbb845ba3eaaaf",
        "commit_title": "[MJ2] To avoid divisions by zero / undefined behaviour on shift",
        "commit_text": "",
        "func_before": "static opj_bool pi_next_rpcl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    long index = 0;\n\n    if (!pi->first) {\n        goto LABEL_SKIP;\n    } else {\n        int compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                int dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1 << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1 << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : int_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : int_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->resno = pi->poc.resno0; pi->resno < pi->poc.resno1; pi->resno++) {\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += pi->dy - (pi->y % pi->dy)) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += pi->dx - (pi->x % pi->dx)) {\n                for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                    int levelno;\n                    int trx0, try0;\n                    int trx1, try1;\n                    int rpx, rpy;\n                    int prci, prcj;\n                    comp = &pi->comps[pi->compno];\n                    if (pi->resno >= comp->numresolutions) {\n                        continue;\n                    }\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = int_ceildiv(pi->tx0, comp->dx << levelno);\n                    try0 = int_ceildiv(pi->ty0, comp->dy << levelno);\n                    trx1 = int_ceildiv(pi->tx1, comp->dx << levelno);\n                    try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n                    if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = int_floordivpow2(int_ceildiv(pi->x, comp->dx << levelno), res->pdx)\n                           - int_floordivpow2(trx0, res->pdx);\n                    prcj = int_floordivpow2(int_ceildiv(pi->y, comp->dy << levelno), res->pdy)\n                           - int_floordivpow2(try0, res->pdy);\n                    pi->precno = prci + prcj * res->pw;\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "func": "static opj_bool pi_next_rpcl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    long index = 0;\n\n    if (!pi->first) {\n        goto LABEL_SKIP;\n    } else {\n        int compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                int dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1 << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1 << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : int_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : int_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->resno = pi->poc.resno0; pi->resno < pi->poc.resno1; pi->resno++) {\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += pi->dy - (pi->y % pi->dy)) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += pi->dx - (pi->x % pi->dx)) {\n                for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                    int levelno;\n                    int trx0, try0;\n                    int trx1, try1;\n                    int rpx, rpy;\n                    int prci, prcj;\n                    comp = &pi->comps[pi->compno];\n                    if (pi->resno >= comp->numresolutions) {\n                        continue;\n                    }\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = int_ceildiv(pi->tx0, comp->dx << levelno);\n                    try0 = int_ceildiv(pi->ty0, comp->dy << levelno);\n                    trx1 = int_ceildiv(pi->tx1, comp->dx << levelno);\n                    try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n\n                    /* To avoid divisions by zero / undefined behaviour on shift */\n                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n                        continue;\n                    }\n\n                    if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = int_floordivpow2(int_ceildiv(pi->x, comp->dx << levelno), res->pdx)\n                           - int_floordivpow2(trx0, res->pdx);\n                    prcj = int_floordivpow2(int_ceildiv(pi->y, comp->dy << levelno), res->pdy)\n                           - int_floordivpow2(try0, res->pdy);\n                    pi->precno = prci + prcj * res->pw;\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,6 +52,13 @@\n                     try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                     rpx = res->pdx + levelno;\n                     rpy = res->pdy + levelno;\n+\n+                    /* To avoid divisions by zero / undefined behaviour on shift */\n+                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n+                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n+                        continue;\n+                    }\n+\n                     if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                             ((try0 << levelno) % (1 << rpy))))) {\n                         continue;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "                    /* To avoid divisions by zero / undefined behaviour on shift */",
                "                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||",
                "                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {",
                "                        continue;",
                "                    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2018-20845",
        "func_name": "uclouvain/openjpeg/pi_next_cprl",
        "description": "Division-by-zero vulnerabilities in the functions pi_next_pcrl, pi_next_cprl, and pi_next_rpcl in openmj2/pi.c in OpenJPEG through 2.3.0 allow remote attackers to cause a denial of service (application crash).",
        "git_url": "https://github.com/uclouvain/openjpeg/commit/c5bd64ea146162967c29bd2af0cbb845ba3eaaaf",
        "commit_title": "[MJ2] To avoid divisions by zero / undefined behaviour on shift",
        "commit_text": "",
        "func_before": "static opj_bool pi_next_cprl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    long index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        pi->first = 0;\n    }\n\n    for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n        int resno;\n        comp = &pi->comps[pi->compno];\n        pi->dx = 0;\n        pi->dy = 0;\n        for (resno = 0; resno < comp->numresolutions; resno++) {\n            int dx, dy;\n            res = &comp->resolutions[resno];\n            dx = comp->dx * (1 << (res->pdx + comp->numresolutions - 1 - resno));\n            dy = comp->dy * (1 << (res->pdy + comp->numresolutions - 1 - resno));\n            pi->dx = !pi->dx ? dx : int_min(pi->dx, dx);\n            pi->dy = !pi->dy ? dy : int_min(pi->dy, dy);\n        }\n        if (!pi->tp_on) {\n            pi->poc.ty0 = pi->ty0;\n            pi->poc.tx0 = pi->tx0;\n            pi->poc.ty1 = pi->ty1;\n            pi->poc.tx1 = pi->tx1;\n        }\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += pi->dy - (pi->y % pi->dy)) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += pi->dx - (pi->x % pi->dx)) {\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < int_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    int levelno;\n                    int trx0, try0;\n                    int trx1, try1;\n                    int rpx, rpy;\n                    int prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = int_ceildiv(pi->tx0, comp->dx << levelno);\n                    try0 = int_ceildiv(pi->ty0, comp->dy << levelno);\n                    trx1 = int_ceildiv(pi->tx1, comp->dx << levelno);\n                    try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n                    if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = int_floordivpow2(int_ceildiv(pi->x, comp->dx << levelno), res->pdx)\n                           - int_floordivpow2(trx0, res->pdx);\n                    prcj = int_floordivpow2(int_ceildiv(pi->y, comp->dy << levelno), res->pdy)\n                           - int_floordivpow2(try0, res->pdy);\n                    pi->precno = prci + prcj * res->pw;\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "func": "static opj_bool pi_next_cprl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    long index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        pi->first = 0;\n    }\n\n    for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n        int resno;\n        comp = &pi->comps[pi->compno];\n        pi->dx = 0;\n        pi->dy = 0;\n        for (resno = 0; resno < comp->numresolutions; resno++) {\n            int dx, dy;\n            res = &comp->resolutions[resno];\n            dx = comp->dx * (1 << (res->pdx + comp->numresolutions - 1 - resno));\n            dy = comp->dy * (1 << (res->pdy + comp->numresolutions - 1 - resno));\n            pi->dx = !pi->dx ? dx : int_min(pi->dx, dx);\n            pi->dy = !pi->dy ? dy : int_min(pi->dy, dy);\n        }\n        if (!pi->tp_on) {\n            pi->poc.ty0 = pi->ty0;\n            pi->poc.tx0 = pi->tx0;\n            pi->poc.ty1 = pi->ty1;\n            pi->poc.tx1 = pi->tx1;\n        }\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += pi->dy - (pi->y % pi->dy)) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += pi->dx - (pi->x % pi->dx)) {\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < int_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    int levelno;\n                    int trx0, try0;\n                    int trx1, try1;\n                    int rpx, rpy;\n                    int prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = int_ceildiv(pi->tx0, comp->dx << levelno);\n                    try0 = int_ceildiv(pi->ty0, comp->dy << levelno);\n                    trx1 = int_ceildiv(pi->tx1, comp->dx << levelno);\n                    try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n\n                    /* To avoid divisions by zero / undefined behaviour on shift */\n                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n                        continue;\n                    }\n\n                    if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = int_floordivpow2(int_ceildiv(pi->x, comp->dx << levelno), res->pdx)\n                           - int_floordivpow2(trx0, res->pdx);\n                    prcj = int_floordivpow2(int_ceildiv(pi->y, comp->dy << levelno), res->pdy)\n                           - int_floordivpow2(try0, res->pdy);\n                    pi->precno = prci + prcj * res->pw;\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -49,6 +49,13 @@\n                     try1 = int_ceildiv(pi->ty1, comp->dy << levelno);\n                     rpx = res->pdx + levelno;\n                     rpy = res->pdy + levelno;\n+\n+                    /* To avoid divisions by zero / undefined behaviour on shift */\n+                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n+                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n+                        continue;\n+                    }\n+\n                     if (!((pi->y % (comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                             ((try0 << levelno) % (1 << rpy))))) {\n                         continue;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "                    /* To avoid divisions by zero / undefined behaviour on shift */",
                "                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||",
                "                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {",
                "                        continue;",
                "                    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13454",
        "func_name": "ImageMagick/RemoveDuplicateLayers",
        "description": "ImageMagick 7.0.8-54 Q16 allows Division by Zero in RemoveDuplicateLayers in MagickCore/layer.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/1ddcf2e4f28029a888cadef2e757509ef5047ad8",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/1629",
        "commit_text": "",
        "func_before": "MagickExport void RemoveDuplicateLayers(Image **images,\n     ExceptionInfo *exception)\n{\n  register Image\n    *curr,\n    *next;\n\n  RectangleInfo\n    bounds;\n\n  assert((*images) != (const Image *) NULL);\n  assert((*images)->signature == MagickCoreSignature);\n  if ((*images)->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",(*images)->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  curr=GetFirstImageInList(*images);\n  for (; (next=GetNextImageInList(curr)) != (Image *) NULL; curr=next)\n  {\n    if ( curr->columns != next->columns || curr->rows != next->rows\n         || curr->page.x != next->page.x || curr->page.y != next->page.y )\n      continue;\n    bounds=CompareImagesBounds(curr,next,CompareAnyLayer,exception);\n    if ( bounds.x < 0 ) {\n      /*\n        the two images are the same, merge time delays and delete one.\n      */\n      size_t time;\n      time = curr->delay*1000/curr->ticks_per_second;\n      time += next->delay*1000/next->ticks_per_second;\n      next->ticks_per_second = 100L;\n      next->delay = time*curr->ticks_per_second/1000;\n      next->iterations = curr->iterations;\n      *images = curr;\n      (void) DeleteImageFromList(images);\n    }\n  }\n  *images = GetFirstImageInList(*images);\n}",
        "func": "MagickExport void RemoveDuplicateLayers(Image **images,ExceptionInfo *exception)\n{\n  RectangleInfo\n    bounds;\n\n  register Image\n    *image,\n    *next;\n\n  assert((*images) != (const Image *) NULL);\n  assert((*images)->signature == MagickCoreSignature);\n  if ((*images)->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      (*images)->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=GetFirstImageInList(*images);\n  for ( ; (next=GetNextImageInList(image)) != (Image *) NULL; image=next)\n  {\n    if ((image->columns != next->columns) || (image->rows != next->rows) ||\n        (image->page.x != next->page.x) || (image->page.y != next->page.y))\n      continue;\n    bounds=CompareImagesBounds(image,next,CompareAnyLayer,exception);\n    if (bounds.x < 0)\n      {\n        /*\n          Two images are the same, merge time delays and delete one.\n        */\n        size_t\n          time;\n\n        time=1000*image->delay*PerceptibleReciprocal(image->ticks_per_second);\n        time+=1000*next->delay*PerceptibleReciprocal(next->ticks_per_second);\n        next->ticks_per_second=100L;\n        next->delay=time*image->ticks_per_second/1000;\n        next->iterations=image->iterations;\n        *images=image;\n        (void) DeleteImageFromList(images);\n      }\n  }\n  *images=GetFirstImageInList(*images);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,40 +1,42 @@\n-MagickExport void RemoveDuplicateLayers(Image **images,\n-     ExceptionInfo *exception)\n+MagickExport void RemoveDuplicateLayers(Image **images,ExceptionInfo *exception)\n {\n-  register Image\n-    *curr,\n-    *next;\n-\n   RectangleInfo\n     bounds;\n+\n+  register Image\n+    *image,\n+    *next;\n \n   assert((*images) != (const Image *) NULL);\n   assert((*images)->signature == MagickCoreSignature);\n   if ((*images)->debug != MagickFalse)\n-    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",(*images)->filename);\n+    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n+      (*images)->filename);\n   assert(exception != (ExceptionInfo *) NULL);\n   assert(exception->signature == MagickCoreSignature);\n+  image=GetFirstImageInList(*images);\n+  for ( ; (next=GetNextImageInList(image)) != (Image *) NULL; image=next)\n+  {\n+    if ((image->columns != next->columns) || (image->rows != next->rows) ||\n+        (image->page.x != next->page.x) || (image->page.y != next->page.y))\n+      continue;\n+    bounds=CompareImagesBounds(image,next,CompareAnyLayer,exception);\n+    if (bounds.x < 0)\n+      {\n+        /*\n+          Two images are the same, merge time delays and delete one.\n+        */\n+        size_t\n+          time;\n \n-  curr=GetFirstImageInList(*images);\n-  for (; (next=GetNextImageInList(curr)) != (Image *) NULL; curr=next)\n-  {\n-    if ( curr->columns != next->columns || curr->rows != next->rows\n-         || curr->page.x != next->page.x || curr->page.y != next->page.y )\n-      continue;\n-    bounds=CompareImagesBounds(curr,next,CompareAnyLayer,exception);\n-    if ( bounds.x < 0 ) {\n-      /*\n-        the two images are the same, merge time delays and delete one.\n-      */\n-      size_t time;\n-      time = curr->delay*1000/curr->ticks_per_second;\n-      time += next->delay*1000/next->ticks_per_second;\n-      next->ticks_per_second = 100L;\n-      next->delay = time*curr->ticks_per_second/1000;\n-      next->iterations = curr->iterations;\n-      *images = curr;\n-      (void) DeleteImageFromList(images);\n-    }\n+        time=1000*image->delay*PerceptibleReciprocal(image->ticks_per_second);\n+        time+=1000*next->delay*PerceptibleReciprocal(next->ticks_per_second);\n+        next->ticks_per_second=100L;\n+        next->delay=time*image->ticks_per_second/1000;\n+        next->iterations=image->iterations;\n+        *images=image;\n+        (void) DeleteImageFromList(images);\n+      }\n   }\n-  *images = GetFirstImageInList(*images);\n+  *images=GetFirstImageInList(*images);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "MagickExport void RemoveDuplicateLayers(Image **images,",
                "     ExceptionInfo *exception)",
                "  register Image",
                "    *curr,",
                "    *next;",
                "",
                "    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",(*images)->filename);",
                "  curr=GetFirstImageInList(*images);",
                "  for (; (next=GetNextImageInList(curr)) != (Image *) NULL; curr=next)",
                "  {",
                "    if ( curr->columns != next->columns || curr->rows != next->rows",
                "         || curr->page.x != next->page.x || curr->page.y != next->page.y )",
                "      continue;",
                "    bounds=CompareImagesBounds(curr,next,CompareAnyLayer,exception);",
                "    if ( bounds.x < 0 ) {",
                "      /*",
                "        the two images are the same, merge time delays and delete one.",
                "      */",
                "      size_t time;",
                "      time = curr->delay*1000/curr->ticks_per_second;",
                "      time += next->delay*1000/next->ticks_per_second;",
                "      next->ticks_per_second = 100L;",
                "      next->delay = time*curr->ticks_per_second/1000;",
                "      next->iterations = curr->iterations;",
                "      *images = curr;",
                "      (void) DeleteImageFromList(images);",
                "    }",
                "  *images = GetFirstImageInList(*images);"
            ],
            "added_lines": [
                "MagickExport void RemoveDuplicateLayers(Image **images,ExceptionInfo *exception)",
                "",
                "  register Image",
                "    *image,",
                "    *next;",
                "    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",",
                "      (*images)->filename);",
                "  image=GetFirstImageInList(*images);",
                "  for ( ; (next=GetNextImageInList(image)) != (Image *) NULL; image=next)",
                "  {",
                "    if ((image->columns != next->columns) || (image->rows != next->rows) ||",
                "        (image->page.x != next->page.x) || (image->page.y != next->page.y))",
                "      continue;",
                "    bounds=CompareImagesBounds(image,next,CompareAnyLayer,exception);",
                "    if (bounds.x < 0)",
                "      {",
                "        /*",
                "          Two images are the same, merge time delays and delete one.",
                "        */",
                "        size_t",
                "          time;",
                "        time=1000*image->delay*PerceptibleReciprocal(image->ticks_per_second);",
                "        time+=1000*next->delay*PerceptibleReciprocal(next->ticks_per_second);",
                "        next->ticks_per_second=100L;",
                "        next->delay=time*image->ticks_per_second/1000;",
                "        next->iterations=image->iterations;",
                "        *images=image;",
                "        (void) DeleteImageFromList(images);",
                "      }",
                "  *images=GetFirstImageInList(*images);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-1010315",
        "func_name": "dbry/WavPack/ParseDsdiffHeaderConfig",
        "description": "WavPack 5.1 and earlier is affected by: CWE 369: Divide by Zero. The impact is: Divide by zero can lead to sudden crash of a software/service that tries to parse a .wav file. The component is: ParseDsdiffHeaderConfig (dsdiff.c:282). The attack vector is: Maliciously crafted .wav file. The fixed version is: After commit https://github.com/dbry/WavPack/commit/4c0faba32fddbd0745cbfaf1e1aeb3da5d35b9fc.",
        "git_url": "https://github.com/dbry/WavPack/commit/4c0faba32fddbd0745cbfaf1e1aeb3da5d35b9fc",
        "commit_title": "issue #65: make sure DSDIFF files have a valid channel count",
        "commit_text": "",
        "func_before": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk;\n\n            if (dff_chunk_header.ckDataSize < 4 || dff_chunk_header.ckDataSize > 1024) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"got PROP chunk of %d bytes total\", (int) dff_chunk_header.ckDataSize);\n\n            prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels, chansSpecified, chanMask = 0;\n                uint32_t sampleRate;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (dff_chunk_header.ckDataSize > 0 && dff_chunk_header.ckDataSize <= eptr - cptr) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            if (numChannels < chansSpecified || numChannels < 1) {\n                                error_line (\"%s is not a valid .DFF file!\", infilename);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff;\n\n            if (bytes_to_copy < 0 || bytes_to_copy > 4194304) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "func": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk;\n\n            if (dff_chunk_header.ckDataSize < 4 || dff_chunk_header.ckDataSize > 1024) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"got PROP chunk of %d bytes total\", (int) dff_chunk_header.ckDataSize);\n\n            prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels = 0, chansSpecified, chanMask = 0;\n                uint32_t sampleRate;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (dff_chunk_header.ckDataSize > 0 && dff_chunk_header.ckDataSize <= eptr - cptr) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            if (numChannels < chansSpecified || numChannels < 1 || numChannels > 256) {\n                                error_line (\"%s is not a valid .DFF file!\", infilename);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n\n            if (!config->num_channels) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff;\n\n            if (bytes_to_copy < 0 || bytes_to_copy > 4194304) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -101,7 +101,7 @@\n \n             if (!strncmp (prop_chunk, \"SND \", 4)) {\n                 char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n-                uint16_t numChannels, chansSpecified, chanMask = 0;\n+                uint16_t numChannels = 0, chansSpecified, chanMask = 0;\n                 uint32_t sampleRate;\n \n                 while (eptr - cptr >= sizeof (dff_chunk_header)) {\n@@ -125,7 +125,7 @@\n \n                             chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n \n-                            if (numChannels < chansSpecified || numChannels < 1) {\n+                            if (numChannels < chansSpecified || numChannels < 1 || numChannels > 256) {\n                                 error_line (\"%s is not a valid .DFF file!\", infilename);\n                                 free (prop_chunk);\n                                 return WAVPACK_SOFT_ERROR;\n@@ -200,6 +200,12 @@\n             free (prop_chunk);\n         }\n         else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n+\n+            if (!config->num_channels) {\n+                error_line (\"%s is not a valid .DFF file!\", infilename);\n+                return WAVPACK_SOFT_ERROR;\n+            }\n+\n             total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n             break;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "                uint16_t numChannels, chansSpecified, chanMask = 0;",
                "                            if (numChannels < chansSpecified || numChannels < 1) {"
            ],
            "added_lines": [
                "                uint16_t numChannels = 0, chansSpecified, chanMask = 0;",
                "                            if (numChannels < chansSpecified || numChannels < 1 || numChannels > 256) {",
                "",
                "            if (!config->num_channels) {",
                "                error_line (\"%s is not a valid .DFF file!\", infilename);",
                "                return WAVPACK_SOFT_ERROR;",
                "            }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2019-14284",
        "func_name": "torvalds/linux/set_geometry",
        "description": "In the Linux kernel before 5.2.3, drivers/block/floppy.c allows a denial of service by setup_format_params division-by-zero. Two consecutive ioctls can trigger the bug: the first one should set the drive geometry with .sect and .rate values that make F_SECT_PER_TRACK be zero. Next, the floppy format operation should be called. It can be triggered by an unprivileged local user even when a floppy disk has not been inserted. NOTE: QEMU creates the floppy device by default.",
        "git_url": "https://github.com/torvalds/linux/commit/f3554aeb991214cbfafd17d55e2bfddb50282e32",
        "commit_title": "floppy: fix div-by-zero in setup_format_params",
        "commit_text": " This fixes a divide by zero error in the setup_format_params function of the floppy driver.  Two consecutive ioctls can trigger the bug: The first one should set the drive geometry with such .sect and .rate values for the F_SECT_PER_TRACK to become zero.  Next, the floppy format operation should be called.  A floppy disk is not required to be inserted.  An unprivileged user could trigger the bug if the device is accessible.  The patch checks F_SECT_PER_TRACK for a non-zero value in the set_geometry function.  The proper check should involve a reasonable upper limit for the .sect and .rate fields, but it could change the UAPI.  The patch also checks F_SECT_PER_TRACK in the setup_format_params, and cancels the formatting operation in case of zero.  The bug was found by syzkaller. ",
        "func_before": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif (g->sect <= 0 ||\n\t    g->head <= 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}",
        "func": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif (g->sect <= 0 ||\n\t    g->head <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,8 @@\n \t/* sanity checking for parameters. */\n \tif (g->sect <= 0 ||\n \t    g->head <= 0 ||\n+\t    /* check for zero in F_SECT_PER_TRACK */\n+\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n \t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n \t    /* check if reserved bits are set */\n \t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t    /* check for zero in F_SECT_PER_TRACK */",
                "\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-14284",
        "func_name": "torvalds/linux/setup_format_params",
        "description": "In the Linux kernel before 5.2.3, drivers/block/floppy.c allows a denial of service by setup_format_params division-by-zero. Two consecutive ioctls can trigger the bug: the first one should set the drive geometry with .sect and .rate values that make F_SECT_PER_TRACK be zero. Next, the floppy format operation should be called. It can be triggered by an unprivileged local user even when a floppy disk has not been inserted. NOTE: QEMU creates the floppy device by default.",
        "git_url": "https://github.com/torvalds/linux/commit/f3554aeb991214cbfafd17d55e2bfddb50282e32",
        "commit_title": "floppy: fix div-by-zero in setup_format_params",
        "commit_text": " This fixes a divide by zero error in the setup_format_params function of the floppy driver.  Two consecutive ioctls can trigger the bug: The first one should set the drive geometry with such .sect and .rate values for the F_SECT_PER_TRACK to become zero.  Next, the floppy format operation should be called.  A floppy disk is not required to be inserted.  An unprivileged user could trigger the bug if the device is accessible.  The patch checks F_SECT_PER_TRACK for a non-zero value in the set_geometry function.  The proper check should involve a reasonable upper limit for the .sect and .rate fields, but it could change the UAPI.  The patch also checks F_SECT_PER_TRACK in the setup_format_params, and cancels the formatting operation in case of zero.  The bug was found by syzkaller. ",
        "func_before": "static void setup_format_params(int track)\n{\n\tint n;\n\tint il;\n\tint count;\n\tint head_shift;\n\tint track_shift;\n\tstruct fparm {\n\t\tunsigned char track, head, sect, size;\n\t} *here = (struct fparm *)floppy_track_buffer;\n\n\traw_cmd = &default_raw_cmd;\n\traw_cmd->track = track;\n\n\traw_cmd->flags = (FD_RAW_WRITE | FD_RAW_INTR | FD_RAW_SPIN |\n\t\t\t  FD_RAW_NEED_DISK | FD_RAW_NEED_SEEK);\n\traw_cmd->rate = _floppy->rate & 0x43;\n\traw_cmd->cmd_count = NR_F;\n\tCOMMAND = FM_MODE(_floppy, FD_FORMAT);\n\tDR_SELECT = UNIT(current_drive) + PH_HEAD(_floppy, format_req.head);\n\tF_SIZECODE = FD_SIZECODE(_floppy);\n\tF_SECT_PER_TRACK = _floppy->sect << 2 >> F_SIZECODE;\n\tF_GAP = _floppy->fmt_gap;\n\tF_FILL = FD_FILL_BYTE;\n\n\traw_cmd->kernel_data = floppy_track_buffer;\n\traw_cmd->length = 4 * F_SECT_PER_TRACK;\n\n\t/* allow for about 30ms for data transport per track */\n\thead_shift = (F_SECT_PER_TRACK + 5) / 6;\n\n\t/* a ``cylinder'' is two tracks plus a little stepping time */\n\ttrack_shift = 2 * head_shift + 3;\n\n\t/* position of logical sector 1 on this track */\n\tn = (track_shift * format_req.track + head_shift * format_req.head)\n\t    % F_SECT_PER_TRACK;\n\n\t/* determine interleave */\n\til = 1;\n\tif (_floppy->fmt_gap < 0x22)\n\t\til++;\n\n\t/* initialize field */\n\tfor (count = 0; count < F_SECT_PER_TRACK; ++count) {\n\t\there[count].track = format_req.track;\n\t\there[count].head = format_req.head;\n\t\there[count].sect = 0;\n\t\there[count].size = F_SIZECODE;\n\t}\n\t/* place logical sectors */\n\tfor (count = 1; count <= F_SECT_PER_TRACK; ++count) {\n\t\there[n].sect = count;\n\t\tn = (n + il) % F_SECT_PER_TRACK;\n\t\tif (here[n].sect) {\t/* sector busy, find next free sector */\n\t\t\t++n;\n\t\t\tif (n >= F_SECT_PER_TRACK) {\n\t\t\t\tn -= F_SECT_PER_TRACK;\n\t\t\t\twhile (here[n].sect)\n\t\t\t\t\t++n;\n\t\t\t}\n\t\t}\n\t}\n\tif (_floppy->stretch & FD_SECTBASEMASK) {\n\t\tfor (count = 0; count < F_SECT_PER_TRACK; count++)\n\t\t\there[count].sect += FD_SECTBASE(_floppy) - 1;\n\t}\n}",
        "func": "static void setup_format_params(int track)\n{\n\tint n;\n\tint il;\n\tint count;\n\tint head_shift;\n\tint track_shift;\n\tstruct fparm {\n\t\tunsigned char track, head, sect, size;\n\t} *here = (struct fparm *)floppy_track_buffer;\n\n\traw_cmd = &default_raw_cmd;\n\traw_cmd->track = track;\n\n\traw_cmd->flags = (FD_RAW_WRITE | FD_RAW_INTR | FD_RAW_SPIN |\n\t\t\t  FD_RAW_NEED_DISK | FD_RAW_NEED_SEEK);\n\traw_cmd->rate = _floppy->rate & 0x43;\n\traw_cmd->cmd_count = NR_F;\n\tCOMMAND = FM_MODE(_floppy, FD_FORMAT);\n\tDR_SELECT = UNIT(current_drive) + PH_HEAD(_floppy, format_req.head);\n\tF_SIZECODE = FD_SIZECODE(_floppy);\n\tF_SECT_PER_TRACK = _floppy->sect << 2 >> F_SIZECODE;\n\tF_GAP = _floppy->fmt_gap;\n\tF_FILL = FD_FILL_BYTE;\n\n\traw_cmd->kernel_data = floppy_track_buffer;\n\traw_cmd->length = 4 * F_SECT_PER_TRACK;\n\n\tif (!F_SECT_PER_TRACK)\n\t\treturn;\n\n\t/* allow for about 30ms for data transport per track */\n\thead_shift = (F_SECT_PER_TRACK + 5) / 6;\n\n\t/* a ``cylinder'' is two tracks plus a little stepping time */\n\ttrack_shift = 2 * head_shift + 3;\n\n\t/* position of logical sector 1 on this track */\n\tn = (track_shift * format_req.track + head_shift * format_req.head)\n\t    % F_SECT_PER_TRACK;\n\n\t/* determine interleave */\n\til = 1;\n\tif (_floppy->fmt_gap < 0x22)\n\t\til++;\n\n\t/* initialize field */\n\tfor (count = 0; count < F_SECT_PER_TRACK; ++count) {\n\t\there[count].track = format_req.track;\n\t\there[count].head = format_req.head;\n\t\there[count].sect = 0;\n\t\there[count].size = F_SIZECODE;\n\t}\n\t/* place logical sectors */\n\tfor (count = 1; count <= F_SECT_PER_TRACK; ++count) {\n\t\there[n].sect = count;\n\t\tn = (n + il) % F_SECT_PER_TRACK;\n\t\tif (here[n].sect) {\t/* sector busy, find next free sector */\n\t\t\t++n;\n\t\t\tif (n >= F_SECT_PER_TRACK) {\n\t\t\t\tn -= F_SECT_PER_TRACK;\n\t\t\t\twhile (here[n].sect)\n\t\t\t\t\t++n;\n\t\t\t}\n\t\t}\n\t}\n\tif (_floppy->stretch & FD_SECTBASEMASK) {\n\t\tfor (count = 0; count < F_SECT_PER_TRACK; count++)\n\t\t\there[count].sect += FD_SECTBASE(_floppy) - 1;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,6 +25,9 @@\n \n \traw_cmd->kernel_data = floppy_track_buffer;\n \traw_cmd->length = 4 * F_SECT_PER_TRACK;\n+\n+\tif (!F_SECT_PER_TRACK)\n+\t\treturn;\n \n \t/* allow for about 30ms for data transport per track */\n \thead_shift = (F_SECT_PER_TRACK + 5) / 6;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!F_SECT_PER_TRACK)",
                "\t\treturn;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-14494",
        "func_name": "poppler/SplashOutputDev::tilingPatternFill",
        "description": "An issue was discovered in Poppler through 0.78.0. There is a divide-by-zero error in the function SplashOutputDev::tilingPatternFill at SplashOutputDev.cc.",
        "git_url": "https://cgit.freedesktop.org/poppler/poppler/commit/?id=b224e2f5739fe61de9fa69955d016725b2a4b78d",
        "commit_title": "Issue #802",
        "commit_text": "",
        "func_before": "bool SplashOutputDev::tilingPatternFill(GfxState *state, Gfx *gfxA, Catalog *catalog, Object *str,\n\t\t\t\t\tconst double *ptm, int paintType, int /*tilingType*/, Dict *resDict,\n\t\t\t\t\tconst double *mat, const double *bbox,\n\t\t\t\t\tint x0, int y0, int x1, int y1,\n\t\t\t\t\tdouble xStep, double yStep)\n{\n  PDFRectangle box;\n  Gfx *gfx;\n  Splash *formerSplash = splash;\n  SplashBitmap *formerBitmap = bitmap;\n  double width, height;\n  int surface_width, surface_height, result_width, result_height, i;\n  int repeatX, repeatY;\n  SplashCoord matc[6];\n  Matrix m1;\n  const double *ctm;\n  double savedCTM[6];\n  double kx, ky, sx, sy;\n  bool retValue = false;\n\n  width = bbox[2] - bbox[0];\n  height = bbox[3] - bbox[1];\n\n  if (xStep != width || yStep != height)\n    return false;\n\n  // calculate offsets\n  ctm = state->getCTM();\n  for (i = 0; i < 6; ++i) {\n    savedCTM[i] = ctm[i];\n  }\n  state->concatCTM(mat[0], mat[1], mat[2], mat[3], mat[4], mat[5]);\n  state->concatCTM(1, 0, 0, 1, bbox[0], bbox[1]);\n  ctm = state->getCTM();\n  for (i = 0; i < 6; ++i) {\n    if (!std::isfinite(ctm[i])) {\n      state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n      return false;\n    }\n  }\n  matc[4] = x0 * xStep * ctm[0] + y0 * yStep * ctm[2] + ctm[4];\n  matc[5] = x0 * xStep * ctm[1] + y0 * yStep * ctm[3] + ctm[5];\n  if (splashAbs(ctm[1]) > splashAbs(ctm[0])) {\n    kx = -ctm[1];\n    ky = ctm[2] - (ctm[0] * ctm[3]) / ctm[1];\n  } else {\n    kx = ctm[0];\n    ky = ctm[3] - (ctm[1] * ctm[2]) / ctm[0];\n  }\n  result_width = (int) ceil(fabs(kx * width * (x1 - x0)));\n  result_height = (int) ceil(fabs(ky * height * (y1 - y0)));\n  kx = state->getHDPI() / 72.0;\n  ky = state->getVDPI() / 72.0;\n  m1.m[0] = (ptm[0] == 0) ? fabs(ptm[2]) * kx : fabs(ptm[0]) * kx;\n  m1.m[1] = 0;\n  m1.m[2] = 0;\n  m1.m[3] = (ptm[3] == 0) ? fabs(ptm[1]) * ky : fabs(ptm[3]) * ky;\n  m1.m[4] = 0;\n  m1.m[5] = 0;\n  m1.transform(width, height, &kx, &ky);\n  surface_width = (int) ceil (fabs(kx));\n  surface_height = (int) ceil (fabs(ky));\n\n  sx = (double) result_width / (surface_width * (x1 - x0));\n  sy = (double) result_height / (surface_height * (y1 - y0));\n  m1.m[0] *= sx;\n  m1.m[3] *= sy;\n  m1.transform(width, height, &kx, &ky);\n\n  if(fabs(kx) < 1 && fabs(ky) < 1) {\n    kx = std::min<double>(kx, ky);\n    ky = 2 / kx;\n    m1.m[0] *= ky;\n    m1.m[3] *= ky;\n    m1.transform(width, height, &kx, &ky);\n    surface_width = (int) ceil (fabs(kx));\n    surface_height = (int) ceil (fabs(ky));\n    repeatX = x1 - x0;\n    repeatY = y1 - y0;\n  } else {\n    if ((unsigned long) surface_width * surface_height > 0x800000L) {\n      state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n      return false;\n    }\n    while(fabs(kx) > 16384 || fabs(ky) > 16384) {\n      // limit pattern bitmap size\n      m1.m[0] /= 2;\n      m1.m[3] /= 2;\n      m1.transform(width, height, &kx, &ky);\n    }\n    surface_width = (int) ceil (fabs(kx));\n    surface_height = (int) ceil (fabs(ky));\n    // adjust repeat values to completely fill region\n    repeatX = result_width / surface_width;\n    repeatY = result_height / surface_height;\n    if (surface_width * repeatX < result_width)\n      repeatX++;\n    if (surface_height * repeatY < result_height)\n      repeatY++;\n    if (x1 - x0 > repeatX)\n      repeatX = x1 - x0;\n    if (y1 - y0 > repeatY)\n      repeatY = y1 - y0;\n  }\n  // restore CTM and calculate rotate and scale with rounded matrix\n  state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n  state->concatCTM(mat[0], mat[1], mat[2], mat[3], mat[4], mat[5]);\n  state->concatCTM(width * repeatX, 0, 0, height * repeatY, bbox[0], bbox[1]);\n  ctm = state->getCTM();\n  matc[0] = ctm[0];\n  matc[1] = ctm[1];\n  matc[2] = ctm[2];\n  matc[3] = ctm[3];\n\n  if (surface_width == 0 || surface_height == 0 || repeatX * repeatY <= 4) {\n    state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n    return false;\n  }\n  m1.transform(bbox[0], bbox[1], &kx, &ky);\n  m1.m[4] = -kx;\n  m1.m[5] = -ky;\n\n  bitmap = new SplashBitmap(surface_width, surface_height, 1,\n                            (paintType == 1) ? colorMode : splashModeMono8, true);\n  if (bitmap->getDataPtr() == nullptr) {\n    SplashBitmap *tBitmap = bitmap;\n    bitmap = formerBitmap;\n    delete tBitmap;\n    state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n    return false;\n  }\n  splash = new Splash(bitmap, true);\n  if (paintType == 2) {\n    SplashColor clearColor;\n#ifdef SPLASH_CMYK\n    clearColor[0] = (colorMode == splashModeCMYK8 || colorMode == splashModeDeviceN8) ? 0x00 : 0xFF;\n#else\n    clearColor[0] = 0xFF;\n#endif\n    splash->clear(clearColor, 0);\n  } else {\n    splash->clear(paperColor, 0);\n  }\n  splash->setThinLineMode(formerSplash->getThinLineMode());\n  splash->setMinLineWidth(s_minLineWidth);\n\n  box.x1 = bbox[0]; box.y1 = bbox[1];\n  box.x2 = bbox[2]; box.y2 = bbox[3];\n  gfx = new Gfx(doc, this, resDict, &box, nullptr, nullptr, nullptr, gfxA);\n  // set pattern transformation matrix\n  gfx->getState()->setCTM(m1.m[0], m1.m[1], m1.m[2], m1.m[3], m1.m[4], m1.m[5]);\n  updateCTM(gfx->getState(), m1.m[0], m1.m[1], m1.m[2], m1.m[3], m1.m[4], m1.m[5]);\n  gfx->display(str);\n  delete splash;\n  splash = formerSplash;\n  TilingSplashOutBitmap imgData;\n  imgData.bitmap = bitmap;\n  imgData.paintType = paintType;\n  imgData.pattern = splash->getFillPattern();\n  imgData.colorMode = colorMode;\n  imgData.y = 0;\n  imgData.repeatX = repeatX;\n  imgData.repeatY = repeatY;\n  SplashBitmap *tBitmap = bitmap;\n  bitmap = formerBitmap;\n  result_width = tBitmap->getWidth() * imgData.repeatX;\n  result_height = tBitmap->getHeight() * imgData.repeatY;\n\n  if (splashAbs(matc[1]) > splashAbs(matc[0])) {\n    kx = -matc[1];\n    ky = matc[2] - (matc[0] * matc[3]) / matc[1];\n  } else {\n    kx = matc[0];\n    ky = matc[3] - (matc[1] * matc[2]) / matc[0];\n  }\n  kx = result_width / (fabs(kx) + 1);\n  ky = result_height / (fabs(ky) + 1);\n  state->concatCTM(kx, 0, 0, ky, 0, 0);\n  ctm = state->getCTM();\n  matc[0] = ctm[0];\n  matc[1] = ctm[1];\n  matc[2] = ctm[2];\n  matc[3] = ctm[3];\n  bool minorAxisZero = matc[1] == 0 && matc[2] == 0;\n  if (matc[0] > 0 && minorAxisZero && matc[3] > 0) {\n    // draw the tiles\n    for (int y = 0; y < imgData.repeatY; ++y) {\n      for (int x = 0; x < imgData.repeatX; ++x) {\n        x0 = splashFloor(matc[4]) + x * tBitmap->getWidth();\n        y0 = splashFloor(matc[5]) + y * tBitmap->getHeight();\n        splash->blitImage(tBitmap, true, x0, y0);\n      }\n    }\n    retValue = true;\n  } else {\n    retValue = splash->drawImage(&tilingBitmapSrc, nullptr, &imgData, colorMode, true, result_width, result_height, matc, false, true) == splashOk;\n  }\n  delete tBitmap;\n  delete gfx;\n  return retValue;\n}",
        "func": "bool SplashOutputDev::tilingPatternFill(GfxState *state, Gfx *gfxA, Catalog *catalog, Object *str,\n\t\t\t\t\tconst double *ptm, int paintType, int /*tilingType*/, Dict *resDict,\n\t\t\t\t\tconst double *mat, const double *bbox,\n\t\t\t\t\tint x0, int y0, int x1, int y1,\n\t\t\t\t\tdouble xStep, double yStep)\n{\n  PDFRectangle box;\n  Gfx *gfx;\n  Splash *formerSplash = splash;\n  SplashBitmap *formerBitmap = bitmap;\n  double width, height;\n  int surface_width, surface_height, result_width, result_height, i;\n  int repeatX, repeatY;\n  SplashCoord matc[6];\n  Matrix m1;\n  const double *ctm;\n  double savedCTM[6];\n  double kx, ky, sx, sy;\n  bool retValue = false;\n\n  width = bbox[2] - bbox[0];\n  height = bbox[3] - bbox[1];\n\n  if (xStep != width || yStep != height)\n    return false;\n\n  // calculate offsets\n  ctm = state->getCTM();\n  for (i = 0; i < 6; ++i) {\n    savedCTM[i] = ctm[i];\n  }\n  state->concatCTM(mat[0], mat[1], mat[2], mat[3], mat[4], mat[5]);\n  state->concatCTM(1, 0, 0, 1, bbox[0], bbox[1]);\n  ctm = state->getCTM();\n  for (i = 0; i < 6; ++i) {\n    if (!std::isfinite(ctm[i])) {\n      state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n      return false;\n    }\n  }\n  matc[4] = x0 * xStep * ctm[0] + y0 * yStep * ctm[2] + ctm[4];\n  matc[5] = x0 * xStep * ctm[1] + y0 * yStep * ctm[3] + ctm[5];\n  if (splashAbs(ctm[1]) > splashAbs(ctm[0])) {\n    kx = -ctm[1];\n    ky = ctm[2] - (ctm[0] * ctm[3]) / ctm[1];\n  } else {\n    kx = ctm[0];\n    ky = ctm[3] - (ctm[1] * ctm[2]) / ctm[0];\n  }\n  result_width = (int) ceil(fabs(kx * width * (x1 - x0)));\n  result_height = (int) ceil(fabs(ky * height * (y1 - y0)));\n  kx = state->getHDPI() / 72.0;\n  ky = state->getVDPI() / 72.0;\n  m1.m[0] = (ptm[0] == 0) ? fabs(ptm[2]) * kx : fabs(ptm[0]) * kx;\n  m1.m[1] = 0;\n  m1.m[2] = 0;\n  m1.m[3] = (ptm[3] == 0) ? fabs(ptm[1]) * ky : fabs(ptm[3]) * ky;\n  m1.m[4] = 0;\n  m1.m[5] = 0;\n  m1.transform(width, height, &kx, &ky);\n  surface_width = (int) ceil (fabs(kx));\n  surface_height = (int) ceil (fabs(ky));\n\n  sx = (double) result_width / (surface_width * (x1 - x0));\n  sy = (double) result_height / (surface_height * (y1 - y0));\n  m1.m[0] *= sx;\n  m1.m[3] *= sy;\n  m1.transform(width, height, &kx, &ky);\n\n  if(fabs(kx) < 1 && fabs(ky) < 1) {\n    kx = std::min<double>(kx, ky);\n    ky = 2 / kx;\n    m1.m[0] *= ky;\n    m1.m[3] *= ky;\n    m1.transform(width, height, &kx, &ky);\n    surface_width = (int) ceil (fabs(kx));\n    surface_height = (int) ceil (fabs(ky));\n    repeatX = x1 - x0;\n    repeatY = y1 - y0;\n  } else {\n    if ((unsigned long) surface_width * surface_height > 0x800000L) {\n      state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n      return false;\n    }\n    while(fabs(kx) > 16384 || fabs(ky) > 16384) {\n      // limit pattern bitmap size\n      m1.m[0] /= 2;\n      m1.m[3] /= 2;\n      m1.transform(width, height, &kx, &ky);\n    }\n    surface_width = (int) ceil (fabs(kx));\n    surface_height = (int) ceil (fabs(ky));\n    // adjust repeat values to completely fill region\n    if (unlikely(surface_width == 0 || surface_height == 0)) {\n        state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n        return false;\n    }\n    repeatX = result_width / surface_width;\n    repeatY = result_height / surface_height;\n    if (surface_width * repeatX < result_width)\n      repeatX++;\n    if (surface_height * repeatY < result_height)\n      repeatY++;\n    if (x1 - x0 > repeatX)\n      repeatX = x1 - x0;\n    if (y1 - y0 > repeatY)\n      repeatY = y1 - y0;\n  }\n  // restore CTM and calculate rotate and scale with rounded matrix\n  state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n  state->concatCTM(mat[0], mat[1], mat[2], mat[3], mat[4], mat[5]);\n  state->concatCTM(width * repeatX, 0, 0, height * repeatY, bbox[0], bbox[1]);\n  ctm = state->getCTM();\n  matc[0] = ctm[0];\n  matc[1] = ctm[1];\n  matc[2] = ctm[2];\n  matc[3] = ctm[3];\n\n  if (surface_width == 0 || surface_height == 0 || repeatX * repeatY <= 4) {\n    state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n    return false;\n  }\n  m1.transform(bbox[0], bbox[1], &kx, &ky);\n  m1.m[4] = -kx;\n  m1.m[5] = -ky;\n\n  bitmap = new SplashBitmap(surface_width, surface_height, 1,\n                            (paintType == 1) ? colorMode : splashModeMono8, true);\n  if (bitmap->getDataPtr() == nullptr) {\n    SplashBitmap *tBitmap = bitmap;\n    bitmap = formerBitmap;\n    delete tBitmap;\n    state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n    return false;\n  }\n  splash = new Splash(bitmap, true);\n  if (paintType == 2) {\n    SplashColor clearColor;\n#ifdef SPLASH_CMYK\n    clearColor[0] = (colorMode == splashModeCMYK8 || colorMode == splashModeDeviceN8) ? 0x00 : 0xFF;\n#else\n    clearColor[0] = 0xFF;\n#endif\n    splash->clear(clearColor, 0);\n  } else {\n    splash->clear(paperColor, 0);\n  }\n  splash->setThinLineMode(formerSplash->getThinLineMode());\n  splash->setMinLineWidth(s_minLineWidth);\n\n  box.x1 = bbox[0]; box.y1 = bbox[1];\n  box.x2 = bbox[2]; box.y2 = bbox[3];\n  gfx = new Gfx(doc, this, resDict, &box, nullptr, nullptr, nullptr, gfxA);\n  // set pattern transformation matrix\n  gfx->getState()->setCTM(m1.m[0], m1.m[1], m1.m[2], m1.m[3], m1.m[4], m1.m[5]);\n  updateCTM(gfx->getState(), m1.m[0], m1.m[1], m1.m[2], m1.m[3], m1.m[4], m1.m[5]);\n  gfx->display(str);\n  delete splash;\n  splash = formerSplash;\n  TilingSplashOutBitmap imgData;\n  imgData.bitmap = bitmap;\n  imgData.paintType = paintType;\n  imgData.pattern = splash->getFillPattern();\n  imgData.colorMode = colorMode;\n  imgData.y = 0;\n  imgData.repeatX = repeatX;\n  imgData.repeatY = repeatY;\n  SplashBitmap *tBitmap = bitmap;\n  bitmap = formerBitmap;\n  result_width = tBitmap->getWidth() * imgData.repeatX;\n  result_height = tBitmap->getHeight() * imgData.repeatY;\n\n  if (splashAbs(matc[1]) > splashAbs(matc[0])) {\n    kx = -matc[1];\n    ky = matc[2] - (matc[0] * matc[3]) / matc[1];\n  } else {\n    kx = matc[0];\n    ky = matc[3] - (matc[1] * matc[2]) / matc[0];\n  }\n  kx = result_width / (fabs(kx) + 1);\n  ky = result_height / (fabs(ky) + 1);\n  state->concatCTM(kx, 0, 0, ky, 0, 0);\n  ctm = state->getCTM();\n  matc[0] = ctm[0];\n  matc[1] = ctm[1];\n  matc[2] = ctm[2];\n  matc[3] = ctm[3];\n  bool minorAxisZero = matc[1] == 0 && matc[2] == 0;\n  if (matc[0] > 0 && minorAxisZero && matc[3] > 0) {\n    // draw the tiles\n    for (int y = 0; y < imgData.repeatY; ++y) {\n      for (int x = 0; x < imgData.repeatX; ++x) {\n        x0 = splashFloor(matc[4]) + x * tBitmap->getWidth();\n        y0 = splashFloor(matc[5]) + y * tBitmap->getHeight();\n        splash->blitImage(tBitmap, true, x0, y0);\n      }\n    }\n    retValue = true;\n  } else {\n    retValue = splash->drawImage(&tilingBitmapSrc, nullptr, &imgData, colorMode, true, result_width, result_height, matc, false, true) == splashOk;\n  }\n  delete tBitmap;\n  delete gfx;\n  return retValue;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -91,6 +91,10 @@\n     surface_width = (int) ceil (fabs(kx));\n     surface_height = (int) ceil (fabs(ky));\n     // adjust repeat values to completely fill region\n+    if (unlikely(surface_width == 0 || surface_height == 0)) {\n+        state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);\n+        return false;\n+    }\n     repeatX = result_width / surface_width;\n     repeatY = result_height / surface_height;\n     if (surface_width * repeatX < result_width)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (unlikely(surface_width == 0 || surface_height == 0)) {",
                "        state->setCTM(savedCTM[0], savedCTM[1], savedCTM[2], savedCTM[3], savedCTM[4], savedCTM[5]);",
                "        return false;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-14981",
        "func_name": "ImageMagick/ImageMagick6/MeanShiftImage",
        "description": "In ImageMagick 7.x before 7.0.8-41 and 6.x before 6.9.10-41, there is a divide-by-zero vulnerability in the MeanShiftImage function. It allows an attacker to cause a denial of service by sending a crafted file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick6/commit/b522d2d857d2f75b659936b59b0da9df1682c256",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/1552",
        "commit_text": "",
        "func_before": "MagickExport Image *MeanShiftImage(const Image *image,const size_t width,\n  const size_t height,const double color_distance,ExceptionInfo *exception)\n{\n#define MaxMeanShiftIterations  100\n#define MeanShiftImageTag  \"MeanShift/Image\"\n\n  CacheView\n    *image_view,\n    *mean_view,\n    *pixel_view;\n\n  Image\n    *mean_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  mean_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (mean_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(mean_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&mean_image->exception);\n      mean_image=DestroyImage(mean_image);\n      return((Image *) NULL);\n    }\n  status=MagickTrue;\n  progress=0;\n  image_view=AcquireVirtualCacheView(image,exception);\n  pixel_view=AcquireVirtualCacheView(image,exception);\n  mean_view=AcquireAuthenticCacheView(mean_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(status,progress) \\\n    magick_number_threads(mean_image,mean_image,mean_image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) mean_image->rows; y++)\n  {\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,image->columns,1,exception);\n    q=GetCacheViewAuthenticPixels(mean_view,0,y,mean_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    for (x=0; x < (ssize_t) mean_image->columns; x++)\n    {\n      MagickPixelPacket\n        mean_pixel,\n        previous_pixel;\n\n      PointInfo\n        mean_location,\n        previous_location;\n\n      register ssize_t\n        i;\n\n      GetMagickPixelPacket(image,&mean_pixel);\n      SetMagickPixelPacket(image,p,indexes+x,&mean_pixel);\n      mean_location.x=(double) x;\n      mean_location.y=(double) y;\n      for (i=0; i < MaxMeanShiftIterations; i++)\n      {\n        double\n          distance,\n          gamma;\n\n        MagickPixelPacket\n          sum_pixel;\n\n        PointInfo\n          sum_location;\n\n        ssize_t\n          count,\n          v;\n\n        sum_location.x=0.0;\n        sum_location.y=0.0;\n        GetMagickPixelPacket(image,&sum_pixel);\n        previous_location=mean_location;\n        previous_pixel=mean_pixel;\n        count=0;\n        for (v=(-((ssize_t) height/2)); v <= (((ssize_t) height/2)); v++)\n        {\n          ssize_t\n            u;\n\n          for (u=(-((ssize_t) width/2)); u <= (((ssize_t) width/2)); u++)\n          {\n            if ((v*v+u*u) <= (ssize_t) ((width/2)*(height/2)))\n              {\n                PixelPacket\n                  pixel;\n\n                status=GetOneCacheViewVirtualPixel(pixel_view,(ssize_t)\n                  MagickRound(mean_location.x+u),(ssize_t) MagickRound(\n                  mean_location.y+v),&pixel,exception);\n                distance=(mean_pixel.red-pixel.red)*(mean_pixel.red-pixel.red)+\n                  (mean_pixel.green-pixel.green)*(mean_pixel.green-pixel.green)+\n                  (mean_pixel.blue-pixel.blue)*(mean_pixel.blue-pixel.blue);\n                if (distance <= (color_distance*color_distance))\n                  {\n                    sum_location.x+=mean_location.x+u;\n                    sum_location.y+=mean_location.y+v;\n                    sum_pixel.red+=pixel.red;\n                    sum_pixel.green+=pixel.green;\n                    sum_pixel.blue+=pixel.blue;\n                    sum_pixel.opacity+=pixel.opacity;\n                    count++;\n                  }\n              }\n          }\n        }\n        gamma=1.0/count;\n        mean_location.x=gamma*sum_location.x;\n        mean_location.y=gamma*sum_location.y;\n        mean_pixel.red=gamma*sum_pixel.red;\n        mean_pixel.green=gamma*sum_pixel.green;\n        mean_pixel.blue=gamma*sum_pixel.blue;\n        mean_pixel.opacity=gamma*sum_pixel.opacity;\n        distance=(mean_location.x-previous_location.x)*\n          (mean_location.x-previous_location.x)+\n          (mean_location.y-previous_location.y)*\n          (mean_location.y-previous_location.y)+\n          255.0*QuantumScale*(mean_pixel.red-previous_pixel.red)*\n          255.0*QuantumScale*(mean_pixel.red-previous_pixel.red)+\n          255.0*QuantumScale*(mean_pixel.green-previous_pixel.green)*\n          255.0*QuantumScale*(mean_pixel.green-previous_pixel.green)+\n          255.0*QuantumScale*(mean_pixel.blue-previous_pixel.blue)*\n          255.0*QuantumScale*(mean_pixel.blue-previous_pixel.blue);\n        if (distance <= 3.0)\n          break;\n      }\n      q->red=ClampToQuantum(mean_pixel.red);\n      q->green=ClampToQuantum(mean_pixel.green);\n      q->blue=ClampToQuantum(mean_pixel.blue);\n      q->opacity=ClampToQuantum(mean_pixel.opacity);\n      p++;\n      q++;\n    }\n    if (SyncCacheViewAuthenticPixels(mean_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,MeanShiftImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  mean_view=DestroyCacheView(mean_view);\n  pixel_view=DestroyCacheView(pixel_view);\n  image_view=DestroyCacheView(image_view);\n  return(mean_image);\n}",
        "func": "MagickExport Image *MeanShiftImage(const Image *image,const size_t width,\n  const size_t height,const double color_distance,ExceptionInfo *exception)\n{\n#define MaxMeanShiftIterations  100\n#define MeanShiftImageTag  \"MeanShift/Image\"\n\n  CacheView\n    *image_view,\n    *mean_view,\n    *pixel_view;\n\n  Image\n    *mean_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  mean_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (mean_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(mean_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&mean_image->exception);\n      mean_image=DestroyImage(mean_image);\n      return((Image *) NULL);\n    }\n  status=MagickTrue;\n  progress=0;\n  image_view=AcquireVirtualCacheView(image,exception);\n  pixel_view=AcquireVirtualCacheView(image,exception);\n  mean_view=AcquireAuthenticCacheView(mean_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(status,progress) \\\n    magick_number_threads(mean_image,mean_image,mean_image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) mean_image->rows; y++)\n  {\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,0,y,image->columns,1,exception);\n    q=GetCacheViewAuthenticPixels(mean_view,0,y,mean_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    for (x=0; x < (ssize_t) mean_image->columns; x++)\n    {\n      MagickPixelPacket\n        mean_pixel,\n        previous_pixel;\n\n      PointInfo\n        mean_location,\n        previous_location;\n\n      register ssize_t\n        i;\n\n      GetMagickPixelPacket(image,&mean_pixel);\n      SetMagickPixelPacket(image,p,indexes+x,&mean_pixel);\n      mean_location.x=(double) x;\n      mean_location.y=(double) y;\n      for (i=0; i < MaxMeanShiftIterations; i++)\n      {\n        double\n          distance,\n          gamma;\n\n        MagickPixelPacket\n          sum_pixel;\n\n        PointInfo\n          sum_location;\n\n        ssize_t\n          count,\n          v;\n\n        sum_location.x=0.0;\n        sum_location.y=0.0;\n        GetMagickPixelPacket(image,&sum_pixel);\n        previous_location=mean_location;\n        previous_pixel=mean_pixel;\n        count=0;\n        for (v=(-((ssize_t) height/2)); v <= (((ssize_t) height/2)); v++)\n        {\n          ssize_t\n            u;\n\n          for (u=(-((ssize_t) width/2)); u <= (((ssize_t) width/2)); u++)\n          {\n            if ((v*v+u*u) <= (ssize_t) ((width/2)*(height/2)))\n              {\n                PixelPacket\n                  pixel;\n\n                status=GetOneCacheViewVirtualPixel(pixel_view,(ssize_t)\n                  MagickRound(mean_location.x+u),(ssize_t) MagickRound(\n                  mean_location.y+v),&pixel,exception);\n                distance=(mean_pixel.red-pixel.red)*(mean_pixel.red-pixel.red)+\n                  (mean_pixel.green-pixel.green)*(mean_pixel.green-pixel.green)+\n                  (mean_pixel.blue-pixel.blue)*(mean_pixel.blue-pixel.blue);\n                if (distance <= (color_distance*color_distance))\n                  {\n                    sum_location.x+=mean_location.x+u;\n                    sum_location.y+=mean_location.y+v;\n                    sum_pixel.red+=pixel.red;\n                    sum_pixel.green+=pixel.green;\n                    sum_pixel.blue+=pixel.blue;\n                    sum_pixel.opacity+=pixel.opacity;\n                    count++;\n                  }\n              }\n          }\n        }\n        gamma=PerceptibleReciprocal(count);\n        mean_location.x=gamma*sum_location.x;\n        mean_location.y=gamma*sum_location.y;\n        mean_pixel.red=gamma*sum_pixel.red;\n        mean_pixel.green=gamma*sum_pixel.green;\n        mean_pixel.blue=gamma*sum_pixel.blue;\n        mean_pixel.opacity=gamma*sum_pixel.opacity;\n        distance=(mean_location.x-previous_location.x)*\n          (mean_location.x-previous_location.x)+\n          (mean_location.y-previous_location.y)*\n          (mean_location.y-previous_location.y)+\n          255.0*QuantumScale*(mean_pixel.red-previous_pixel.red)*\n          255.0*QuantumScale*(mean_pixel.red-previous_pixel.red)+\n          255.0*QuantumScale*(mean_pixel.green-previous_pixel.green)*\n          255.0*QuantumScale*(mean_pixel.green-previous_pixel.green)+\n          255.0*QuantumScale*(mean_pixel.blue-previous_pixel.blue)*\n          255.0*QuantumScale*(mean_pixel.blue-previous_pixel.blue);\n        if (distance <= 3.0)\n          break;\n      }\n      q->red=ClampToQuantum(mean_pixel.red);\n      q->green=ClampToQuantum(mean_pixel.green);\n      q->blue=ClampToQuantum(mean_pixel.blue);\n      q->opacity=ClampToQuantum(mean_pixel.opacity);\n      p++;\n      q++;\n    }\n    if (SyncCacheViewAuthenticPixels(mean_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,MeanShiftImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  mean_view=DestroyCacheView(mean_view);\n  pixel_view=DestroyCacheView(pixel_view);\n  image_view=DestroyCacheView(image_view);\n  return(mean_image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -140,7 +140,7 @@\n               }\n           }\n         }\n-        gamma=1.0/count;\n+        gamma=PerceptibleReciprocal(count);\n         mean_location.x=gamma*sum_location.x;\n         mean_location.y=gamma*sum_location.y;\n         mean_pixel.red=gamma*sum_pixel.red;",
        "diff_line_info": {
            "deleted_lines": [
                "        gamma=1.0/count;"
            ],
            "added_lines": [
                "        gamma=PerceptibleReciprocal(count);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/start_decoder",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int start_decoder(vorb *f)\n{\n   uint8 header[6], x,y;\n   int len,i,j,k, max_submaps = 0;\n   int longest_floorlist=0;\n\n   // first page, first packet\n\n   if (!start_page(f))                              return FALSE;\n   // validate page flag\n   if (!(f->page_flag & PAGEFLAG_first_page))       return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_last_page)           return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_continued_packet)    return error(f, VORBIS_invalid_first_page);\n   // check for expected packet length\n   if (f->segment_count != 1)                       return error(f, VORBIS_invalid_first_page);\n   if (f->segments[0] != 30) {\n      // check for the Ogg skeleton fishead identifying header to refine our error\n      if (f->segments[0] == 64 &&\n          getn(f, header, 6) &&\n          header[0] == 'f' &&\n          header[1] == 'i' &&\n          header[2] == 's' &&\n          header[3] == 'h' &&\n          header[4] == 'e' &&\n          header[5] == 'a' &&\n          get8(f)   == 'd' &&\n          get8(f)   == '\\0')                        return error(f, VORBIS_ogg_skeleton_not_supported);\n      else\n                                                    return error(f, VORBIS_invalid_first_page);\n   }\n\n   // read packet\n   // check packet header\n   if (get8(f) != VORBIS_packet_id)                 return error(f, VORBIS_invalid_first_page);\n   if (!getn(f, header, 6))                         return error(f, VORBIS_unexpected_eof);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_first_page);\n   // vorbis_version\n   if (get32(f) != 0)                               return error(f, VORBIS_invalid_first_page);\n   f->channels = get8(f); if (!f->channels)         return error(f, VORBIS_invalid_first_page);\n   if (f->channels > STB_VORBIS_MAX_CHANNELS)       return error(f, VORBIS_too_many_channels);\n   f->sample_rate = get32(f); if (!f->sample_rate)  return error(f, VORBIS_invalid_first_page);\n   get32(f); // bitrate_maximum\n   get32(f); // bitrate_nominal\n   get32(f); // bitrate_minimum\n   x = get8(f);\n   {\n      int log0,log1;\n      log0 = x & 15;\n      log1 = x >> 4;\n      f->blocksize_0 = 1 << log0;\n      f->blocksize_1 = 1 << log1;\n      if (log0 < 6 || log0 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log1 < 6 || log1 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log0 > log1)                                 return error(f, VORBIS_invalid_setup);\n   }\n\n   // framing_flag\n   x = get8(f);\n   if (!(x & 1))                                    return error(f, VORBIS_invalid_first_page);\n\n   // second packet!\n   if (!start_page(f))                              return FALSE;\n\n   if (!start_packet(f))                            return FALSE;\n   do {\n      len = next_segment(f);\n      skip(f, len);\n      f->bytes_in_seg = 0;\n   } while (len);\n\n   // third packet!\n   if (!start_packet(f))                            return FALSE;\n\n   #ifndef STB_VORBIS_NO_PUSHDATA_API\n   if (IS_PUSH_MODE(f)) {\n      if (!is_whole_packet_present(f, TRUE)) {\n         // convert error in ogg header to write type\n         if (f->error == VORBIS_invalid_stream)\n            f->error = VORBIS_invalid_setup;\n         return FALSE;\n      }\n   }\n   #endif\n\n   crc32_init(); // always init it, to avoid multithread race conditions\n\n   if (get8_packet(f) != VORBIS_packet_setup)       return error(f, VORBIS_invalid_setup);\n   for (i=0; i < 6; ++i) header[i] = get8_packet(f);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_setup);\n\n   // codebooks\n\n   f->codebook_count = get_bits(f,8) + 1;\n   f->codebooks = (Codebook *) setup_malloc(f, sizeof(*f->codebooks) * f->codebook_count);\n   if (f->codebooks == NULL)                        return error(f, VORBIS_outofmem);\n   memset(f->codebooks, 0, sizeof(*f->codebooks) * f->codebook_count);\n   for (i=0; i < f->codebook_count; ++i) {\n      uint32 *values;\n      int ordered, sorted_count;\n      int total=0;\n      uint8 *lengths;\n      Codebook *c = f->codebooks+i;\n      CHECK(f);\n      x = get_bits(f, 8); if (x != 0x42)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x43)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x56)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8);\n      c->dimensions = (get_bits(f, 8)<<8) + x;\n      x = get_bits(f, 8);\n      y = get_bits(f, 8);\n      c->entries = (get_bits(f, 8)<<16) + (y<<8) + x;\n      ordered = get_bits(f,1);\n      c->sparse = ordered ? 0 : get_bits(f,1);\n\n      if (c->dimensions == 0 && c->entries != 0)    return error(f, VORBIS_invalid_setup);\n\n      if (c->sparse)\n         lengths = (uint8 *) setup_temp_malloc(f, c->entries);\n      else\n         lengths = c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n\n      if (!lengths) return error(f, VORBIS_outofmem);\n\n      if (ordered) {\n         int current_entry = 0;\n         int current_length = get_bits(f,5) + 1;\n         while (current_entry < c->entries) {\n            int limit = c->entries - current_entry;\n            int n = get_bits(f, ilog(limit));\n            if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n            memset(lengths + current_entry, current_length, n);\n            current_entry += n;\n            ++current_length;\n         }\n      } else {\n         for (j=0; j < c->entries; ++j) {\n            int present = c->sparse ? get_bits(f,1) : 1;\n            if (present) {\n               lengths[j] = get_bits(f, 5) + 1;\n               ++total;\n               if (lengths[j] == 32)\n                  return error(f, VORBIS_invalid_setup);\n            } else {\n               lengths[j] = NO_CODE;\n            }\n         }\n      }\n\n      if (c->sparse && total >= c->entries >> 2) {\n         // convert sparse items to non-sparse!\n         if (c->entries > (int) f->setup_temp_memory_required)\n            f->setup_temp_memory_required = c->entries;\n\n         c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n         if (c->codeword_lengths == NULL) return error(f, VORBIS_outofmem);\n         memcpy(c->codeword_lengths, lengths, c->entries);\n         setup_temp_free(f, lengths, c->entries); // note this is only safe if there have been no intervening temp mallocs!\n         lengths = c->codeword_lengths;\n         c->sparse = 0;\n      }\n\n      // compute the size of the sorted tables\n      if (c->sparse) {\n         sorted_count = total;\n      } else {\n         sorted_count = 0;\n         #ifndef STB_VORBIS_NO_HUFFMAN_BINARY_SEARCH\n         for (j=0; j < c->entries; ++j)\n            if (lengths[j] > STB_VORBIS_FAST_HUFFMAN_LENGTH && lengths[j] != NO_CODE)\n               ++sorted_count;\n         #endif\n      }\n\n      c->sorted_entries = sorted_count;\n      values = NULL;\n\n      CHECK(f);\n      if (!c->sparse) {\n         c->codewords = (uint32 *) setup_malloc(f, sizeof(c->codewords[0]) * c->entries);\n         if (!c->codewords)                  return error(f, VORBIS_outofmem);\n      } else {\n         unsigned int size;\n         if (c->sorted_entries) {\n            c->codeword_lengths = (uint8 *) setup_malloc(f, c->sorted_entries);\n            if (!c->codeword_lengths)           return error(f, VORBIS_outofmem);\n            c->codewords = (uint32 *) setup_temp_malloc(f, sizeof(*c->codewords) * c->sorted_entries);\n            if (!c->codewords)                  return error(f, VORBIS_outofmem);\n            values = (uint32 *) setup_temp_malloc(f, sizeof(*values) * c->sorted_entries);\n            if (!values)                        return error(f, VORBIS_outofmem);\n         }\n         size = c->entries + (sizeof(*c->codewords) + sizeof(*values)) * c->sorted_entries;\n         if (size > f->setup_temp_memory_required)\n            f->setup_temp_memory_required = size;\n      }\n\n      if (!compute_codewords(c, lengths, c->entries, values)) {\n         if (c->sparse) setup_temp_free(f, values, 0);\n         return error(f, VORBIS_invalid_setup);\n      }\n\n      if (c->sorted_entries) {\n         // allocate an extra slot for sentinels\n         c->sorted_codewords = (uint32 *) setup_malloc(f, sizeof(*c->sorted_codewords) * (c->sorted_entries+1));\n         if (c->sorted_codewords == NULL) return error(f, VORBIS_outofmem);\n         // allocate an extra slot at the front so that c->sorted_values[-1] is defined\n         // so that we can catch that case without an extra if\n         c->sorted_values    = ( int   *) setup_malloc(f, sizeof(*c->sorted_values   ) * (c->sorted_entries+1));\n         if (c->sorted_values == NULL) return error(f, VORBIS_outofmem);\n         ++c->sorted_values;\n         c->sorted_values[-1] = -1;\n         compute_sorted_huffman(c, lengths, values);\n      }\n\n      if (c->sparse) {\n         setup_temp_free(f, values, sizeof(*values)*c->sorted_entries);\n         setup_temp_free(f, c->codewords, sizeof(*c->codewords)*c->sorted_entries);\n         setup_temp_free(f, lengths, c->entries);\n         c->codewords = NULL;\n      }\n\n      compute_accelerated_huffman(c);\n\n      CHECK(f);\n      c->lookup_type = get_bits(f, 4);\n      if (c->lookup_type > 2) return error(f, VORBIS_invalid_setup);\n      if (c->lookup_type > 0) {\n         uint16 *mults;\n         c->minimum_value = float32_unpack(get_bits(f, 32));\n         c->delta_value = float32_unpack(get_bits(f, 32));\n         c->value_bits = get_bits(f, 4)+1;\n         c->sequence_p = get_bits(f,1);\n         if (c->lookup_type == 1) {\n            c->lookup_values = lookup1_values(c->entries, c->dimensions);\n         } else {\n            c->lookup_values = c->entries * c->dimensions;\n         }\n         if (c->lookup_values == 0) return error(f, VORBIS_invalid_setup);\n         mults = (uint16 *) setup_temp_malloc(f, sizeof(mults[0]) * c->lookup_values);\n         if (mults == NULL) return error(f, VORBIS_outofmem);\n         for (j=0; j < (int) c->lookup_values; ++j) {\n            int q = get_bits(f, c->value_bits);\n            if (q == EOP) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_invalid_setup); }\n            mults[j] = q;\n         }\n\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n         if (c->lookup_type == 1) {\n            int len, sparse = c->sparse;\n            float last=0;\n            // pre-expand the lookup1-style multiplicands, to avoid a divide in the inner loop\n            if (sparse) {\n               if (c->sorted_entries == 0) goto skip;\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->sorted_entries * c->dimensions);\n            } else\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->entries        * c->dimensions);\n            if (c->multiplicands == NULL) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            len = sparse ? c->sorted_entries : c->entries;\n            for (j=0; j < len; ++j) {\n               unsigned int z = sparse ? c->sorted_values[j] : j;\n               unsigned int div=1;\n               for (k=0; k < c->dimensions; ++k) {\n                  int off = (z / div) % c->lookup_values;\n                  float val = mults[off];\n                  val = mults[off]*c->delta_value + c->minimum_value + last;\n                  c->multiplicands[j*c->dimensions + k] = val;\n                  if (c->sequence_p)\n                     last = val;\n                  if (k+1 < c->dimensions) {\n                     if (div > UINT_MAX / (unsigned int) c->lookup_values) {\n                        setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values);\n                        return error(f, VORBIS_invalid_setup);\n                     }\n                     div *= c->lookup_values;\n                  }\n               }\n            }\n            c->lookup_type = 2;\n         }\n         else\n#endif\n         {\n            float last=0;\n            CHECK(f);\n            c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->lookup_values);\n            if (c->multiplicands == NULL) { setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            for (j=0; j < (int) c->lookup_values; ++j) {\n               float val = mults[j] * c->delta_value + c->minimum_value + last;\n               c->multiplicands[j] = val;\n               if (c->sequence_p)\n                  last = val;\n            }\n         }\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n        skip:;\n#endif\n         setup_temp_free(f, mults, sizeof(mults[0])*c->lookup_values);\n\n         CHECK(f);\n      }\n      CHECK(f);\n   }\n\n   // time domain transfers (notused)\n\n   x = get_bits(f, 6) + 1;\n   for (i=0; i < x; ++i) {\n      uint32 z = get_bits(f, 16);\n      if (z != 0) return error(f, VORBIS_invalid_setup);\n   }\n\n   // Floors\n   f->floor_count = get_bits(f, 6)+1;\n   f->floor_config = (Floor *)  setup_malloc(f, f->floor_count * sizeof(*f->floor_config));\n   if (f->floor_config == NULL) return error(f, VORBIS_outofmem);\n   for (i=0; i < f->floor_count; ++i) {\n      f->floor_types[i] = get_bits(f, 16);\n      if (f->floor_types[i] > 1) return error(f, VORBIS_invalid_setup);\n      if (f->floor_types[i] == 0) {\n         Floor0 *g = &f->floor_config[i].floor0;\n         g->order = get_bits(f,8);\n         g->rate = get_bits(f,16);\n         g->bark_map_size = get_bits(f,16);\n         g->amplitude_bits = get_bits(f,6);\n         g->amplitude_offset = get_bits(f,8);\n         g->number_of_books = get_bits(f,4) + 1;\n         for (j=0; j < g->number_of_books; ++j)\n            g->book_list[j] = get_bits(f,8);\n         return error(f, VORBIS_feature_not_supported);\n      } else {\n         stbv__floor_ordering p[31*8+2];\n         Floor1 *g = &f->floor_config[i].floor1;\n         int max_class = -1; \n         g->partitions = get_bits(f, 5);\n         for (j=0; j < g->partitions; ++j) {\n            g->partition_class_list[j] = get_bits(f, 4);\n            if (g->partition_class_list[j] > max_class)\n               max_class = g->partition_class_list[j];\n         }\n         for (j=0; j <= max_class; ++j) {\n            g->class_dimensions[j] = get_bits(f, 3)+1;\n            g->class_subclasses[j] = get_bits(f, 2);\n            if (g->class_subclasses[j]) {\n               g->class_masterbooks[j] = get_bits(f, 8);\n               if (g->class_masterbooks[j] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n            for (k=0; k < 1 << g->class_subclasses[j]; ++k) {\n               g->subclass_books[j][k] = get_bits(f,8)-1;\n               if (g->subclass_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n         }\n         g->floor1_multiplier = get_bits(f,2)+1;\n         g->rangebits = get_bits(f,4);\n         g->Xlist[0] = 0;\n         g->Xlist[1] = 1 << g->rangebits;\n         g->values = 2;\n         for (j=0; j < g->partitions; ++j) {\n            int c = g->partition_class_list[j];\n            for (k=0; k < g->class_dimensions[c]; ++k) {\n               g->Xlist[g->values] = get_bits(f, g->rangebits);\n               ++g->values;\n            }\n         }\n         // precompute the sorting\n         for (j=0; j < g->values; ++j) {\n            p[j].x = g->Xlist[j];\n            p[j].id = j;\n         }\n         qsort(p, g->values, sizeof(p[0]), point_compare);\n         for (j=0; j < g->values; ++j)\n            g->sorted_order[j] = (uint8) p[j].id;\n         // precompute the neighbors\n         for (j=2; j < g->values; ++j) {\n            int low,hi;\n            neighbors(g->Xlist, j, &low,&hi);\n            g->neighbors[j][0] = low;\n            g->neighbors[j][1] = hi;\n         }\n\n         if (g->values > longest_floorlist)\n            longest_floorlist = g->values;\n      }\n   }\n\n   // Residue\n   f->residue_count = get_bits(f, 6)+1;\n   f->residue_config = (Residue *) setup_malloc(f, f->residue_count * sizeof(f->residue_config[0]));\n   if (f->residue_config == NULL) return error(f, VORBIS_outofmem);\n   memset(f->residue_config, 0, f->residue_count * sizeof(f->residue_config[0]));\n   for (i=0; i < f->residue_count; ++i) {\n      uint8 residue_cascade[64];\n      Residue *r = f->residue_config+i;\n      f->residue_types[i] = get_bits(f, 16);\n      if (f->residue_types[i] > 2) return error(f, VORBIS_invalid_setup);\n      r->begin = get_bits(f, 24);\n      r->end = get_bits(f, 24);\n      if (r->end < r->begin) return error(f, VORBIS_invalid_setup);\n      r->part_size = get_bits(f,24)+1;\n      r->classifications = get_bits(f,6)+1;\n      r->classbook = get_bits(f,8);\n      if (r->classbook >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n      for (j=0; j < r->classifications; ++j) {\n         uint8 high_bits=0;\n         uint8 low_bits=get_bits(f,3);\n         if (get_bits(f,1))\n            high_bits = get_bits(f,5);\n         residue_cascade[j] = high_bits*8 + low_bits;\n      }\n      r->residue_books = (short (*)[8]) setup_malloc(f, sizeof(r->residue_books[0]) * r->classifications);\n      if (r->residue_books == NULL) return error(f, VORBIS_outofmem);\n      for (j=0; j < r->classifications; ++j) {\n         for (k=0; k < 8; ++k) {\n            if (residue_cascade[j] & (1 << k)) {\n               r->residue_books[j][k] = get_bits(f, 8);\n               if (r->residue_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            } else {\n               r->residue_books[j][k] = -1;\n            }\n         }\n      }\n      // precompute the classifications[] array to avoid inner-loop mod/divide\n      // call it 'classdata' since we already have r->classifications\n      r->classdata = (uint8 **) setup_malloc(f, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      if (!r->classdata) return error(f, VORBIS_outofmem);\n      memset(r->classdata, 0, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      for (j=0; j < f->codebooks[r->classbook].entries; ++j) {\n         int classwords = f->codebooks[r->classbook].dimensions;\n         int temp = j;\n         r->classdata[j] = (uint8 *) setup_malloc(f, sizeof(r->classdata[j][0]) * classwords);\n         if (r->classdata[j] == NULL) return error(f, VORBIS_outofmem);\n         for (k=classwords-1; k >= 0; --k) {\n            r->classdata[j][k] = temp % r->classifications;\n            temp /= r->classifications;\n         }\n      }\n   }\n\n   f->mapping_count = get_bits(f,6)+1;\n   f->mapping = (Mapping *) setup_malloc(f, f->mapping_count * sizeof(*f->mapping));\n   if (f->mapping == NULL) return error(f, VORBIS_outofmem);\n   memset(f->mapping, 0, f->mapping_count * sizeof(*f->mapping));\n   for (i=0; i < f->mapping_count; ++i) {\n      Mapping *m = f->mapping + i;      \n      int mapping_type = get_bits(f,16);\n      if (mapping_type != 0) return error(f, VORBIS_invalid_setup);\n      m->chan = (MappingChannel *) setup_malloc(f, f->channels * sizeof(*m->chan));\n      if (m->chan == NULL) return error(f, VORBIS_outofmem);\n      if (get_bits(f,1))\n         m->submaps = get_bits(f,4)+1;\n      else\n         m->submaps = 1;\n      if (m->submaps > max_submaps)\n         max_submaps = m->submaps;\n      if (get_bits(f,1)) {\n         m->coupling_steps = get_bits(f,8)+1;\n         for (k=0; k < m->coupling_steps; ++k) {\n            m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n            m->chan[k].angle = get_bits(f, ilog(f->channels-1));\n            if (m->chan[k].magnitude >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].angle     >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].magnitude == m->chan[k].angle)   return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         m->coupling_steps = 0;\n\n      // reserved field\n      if (get_bits(f,2)) return error(f, VORBIS_invalid_setup);\n      if (m->submaps > 1) {\n         for (j=0; j < f->channels; ++j) {\n            m->chan[j].mux = get_bits(f, 4);\n            if (m->chan[j].mux >= m->submaps)                return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         // @SPECIFICATION: this case is missing from the spec\n         for (j=0; j < f->channels; ++j)\n            m->chan[j].mux = 0;\n\n      for (j=0; j < m->submaps; ++j) {\n         get_bits(f,8); // discard\n         m->submap_floor[j] = get_bits(f,8);\n         m->submap_residue[j] = get_bits(f,8);\n         if (m->submap_floor[j] >= f->floor_count)      return error(f, VORBIS_invalid_setup);\n         if (m->submap_residue[j] >= f->residue_count)  return error(f, VORBIS_invalid_setup);\n      }\n   }\n\n   // Modes\n   f->mode_count = get_bits(f, 6)+1;\n   for (i=0; i < f->mode_count; ++i) {\n      Mode *m = f->mode_config+i;\n      m->blockflag = get_bits(f,1);\n      m->windowtype = get_bits(f,16);\n      m->transformtype = get_bits(f,16);\n      m->mapping = get_bits(f,8);\n      if (m->windowtype != 0)                 return error(f, VORBIS_invalid_setup);\n      if (m->transformtype != 0)              return error(f, VORBIS_invalid_setup);\n      if (m->mapping >= f->mapping_count)     return error(f, VORBIS_invalid_setup);\n   }\n\n   flush_packet(f);\n\n   f->previous_length = 0;\n\n   for (i=0; i < f->channels; ++i) {\n      f->channel_buffers[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1);\n      f->previous_window[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      f->finalY[i]          = (int16 *) setup_malloc(f, sizeof(int16) * longest_floorlist);\n      if (f->channel_buffers[i] == NULL || f->previous_window[i] == NULL || f->finalY[i] == NULL) return error(f, VORBIS_outofmem);\n      memset(f->channel_buffers[i], 0, sizeof(float) * f->blocksize_1);\n      #ifdef STB_VORBIS_NO_DEFER_FLOOR\n      f->floor_buffers[i]   = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      if (f->floor_buffers[i] == NULL) return error(f, VORBIS_outofmem);\n      #endif\n   }\n\n   if (!init_blocksize(f, 0, f->blocksize_0)) return FALSE;\n   if (!init_blocksize(f, 1, f->blocksize_1)) return FALSE;\n   f->blocksize[0] = f->blocksize_0;\n   f->blocksize[1] = f->blocksize_1;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (integer_divide_table[1][1]==0)\n      for (i=0; i < DIVTAB_NUMER; ++i)\n         for (j=1; j < DIVTAB_DENOM; ++j)\n            integer_divide_table[i][j] = i / j;\n#endif\n\n   // compute how much temporary memory is needed\n\n   // 1.\n   {\n      uint32 imdct_mem = (f->blocksize_1 * sizeof(float) >> 1);\n      uint32 classify_mem;\n      int i,max_part_read=0;\n      for (i=0; i < f->residue_count; ++i) {\n         Residue *r = f->residue_config + i;\n         unsigned int actual_size = f->blocksize_1 / 2;\n         unsigned int limit_r_begin = r->begin < actual_size ? r->begin : actual_size;\n         unsigned int limit_r_end   = r->end   < actual_size ? r->end   : actual_size;\n         int n_read = limit_r_end - limit_r_begin;\n         int part_read = n_read / r->part_size;\n         if (part_read > max_part_read)\n            max_part_read = part_read;\n      }\n      #ifndef STB_VORBIS_DIVIDES_IN_RESIDUE\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(uint8 *));\n      #else\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(int *));\n      #endif\n\n      // maximum reasonable partition size is f->blocksize_1\n\n      f->temp_memory_required = classify_mem;\n      if (imdct_mem > f->temp_memory_required)\n         f->temp_memory_required = imdct_mem;\n   }\n\n   f->first_decode = TRUE;\n\n   if (f->alloc.alloc_buffer) {\n      assert(f->temp_offset == f->alloc.alloc_buffer_length_in_bytes);\n      // check if there's enough temp memory so we don't error later\n      if (f->setup_offset + sizeof(*f) + f->temp_memory_required > (unsigned) f->temp_offset)\n         return error(f, VORBIS_outofmem);\n   }\n\n   f->first_audio_page_offset = stb_vorbis_get_file_offset(f);\n\n   return TRUE;\n}",
        "func": "static int start_decoder(vorb *f)\n{\n   uint8 header[6], x,y;\n   int len,i,j,k, max_submaps = 0;\n   int longest_floorlist=0;\n\n   // first page, first packet\n\n   if (!start_page(f))                              return FALSE;\n   // validate page flag\n   if (!(f->page_flag & PAGEFLAG_first_page))       return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_last_page)           return error(f, VORBIS_invalid_first_page);\n   if (f->page_flag & PAGEFLAG_continued_packet)    return error(f, VORBIS_invalid_first_page);\n   // check for expected packet length\n   if (f->segment_count != 1)                       return error(f, VORBIS_invalid_first_page);\n   if (f->segments[0] != 30) {\n      // check for the Ogg skeleton fishead identifying header to refine our error\n      if (f->segments[0] == 64 &&\n          getn(f, header, 6) &&\n          header[0] == 'f' &&\n          header[1] == 'i' &&\n          header[2] == 's' &&\n          header[3] == 'h' &&\n          header[4] == 'e' &&\n          header[5] == 'a' &&\n          get8(f)   == 'd' &&\n          get8(f)   == '\\0')                        return error(f, VORBIS_ogg_skeleton_not_supported);\n      else\n                                                    return error(f, VORBIS_invalid_first_page);\n   }\n\n   // read packet\n   // check packet header\n   if (get8(f) != VORBIS_packet_id)                 return error(f, VORBIS_invalid_first_page);\n   if (!getn(f, header, 6))                         return error(f, VORBIS_unexpected_eof);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_first_page);\n   // vorbis_version\n   if (get32(f) != 0)                               return error(f, VORBIS_invalid_first_page);\n   f->channels = get8(f); if (!f->channels)         return error(f, VORBIS_invalid_first_page);\n   if (f->channels > STB_VORBIS_MAX_CHANNELS)       return error(f, VORBIS_too_many_channels);\n   f->sample_rate = get32(f); if (!f->sample_rate)  return error(f, VORBIS_invalid_first_page);\n   get32(f); // bitrate_maximum\n   get32(f); // bitrate_nominal\n   get32(f); // bitrate_minimum\n   x = get8(f);\n   {\n      int log0,log1;\n      log0 = x & 15;\n      log1 = x >> 4;\n      f->blocksize_0 = 1 << log0;\n      f->blocksize_1 = 1 << log1;\n      if (log0 < 6 || log0 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log1 < 6 || log1 > 13)                       return error(f, VORBIS_invalid_setup);\n      if (log0 > log1)                                 return error(f, VORBIS_invalid_setup);\n   }\n\n   // framing_flag\n   x = get8(f);\n   if (!(x & 1))                                    return error(f, VORBIS_invalid_first_page);\n\n   // second packet!\n   if (!start_page(f))                              return FALSE;\n\n   if (!start_packet(f))                            return FALSE;\n   do {\n      len = next_segment(f);\n      skip(f, len);\n      f->bytes_in_seg = 0;\n   } while (len);\n\n   // third packet!\n   if (!start_packet(f))                            return FALSE;\n\n   #ifndef STB_VORBIS_NO_PUSHDATA_API\n   if (IS_PUSH_MODE(f)) {\n      if (!is_whole_packet_present(f, TRUE)) {\n         // convert error in ogg header to write type\n         if (f->error == VORBIS_invalid_stream)\n            f->error = VORBIS_invalid_setup;\n         return FALSE;\n      }\n   }\n   #endif\n\n   crc32_init(); // always init it, to avoid multithread race conditions\n\n   if (get8_packet(f) != VORBIS_packet_setup)       return error(f, VORBIS_invalid_setup);\n   for (i=0; i < 6; ++i) header[i] = get8_packet(f);\n   if (!vorbis_validate(header))                    return error(f, VORBIS_invalid_setup);\n\n   // codebooks\n\n   f->codebook_count = get_bits(f,8) + 1;\n   f->codebooks = (Codebook *) setup_malloc(f, sizeof(*f->codebooks) * f->codebook_count);\n   if (f->codebooks == NULL)                        return error(f, VORBIS_outofmem);\n   memset(f->codebooks, 0, sizeof(*f->codebooks) * f->codebook_count);\n   for (i=0; i < f->codebook_count; ++i) {\n      uint32 *values;\n      int ordered, sorted_count;\n      int total=0;\n      uint8 *lengths;\n      Codebook *c = f->codebooks+i;\n      CHECK(f);\n      x = get_bits(f, 8); if (x != 0x42)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x43)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8); if (x != 0x56)            return error(f, VORBIS_invalid_setup);\n      x = get_bits(f, 8);\n      c->dimensions = (get_bits(f, 8)<<8) + x;\n      x = get_bits(f, 8);\n      y = get_bits(f, 8);\n      c->entries = (get_bits(f, 8)<<16) + (y<<8) + x;\n      ordered = get_bits(f,1);\n      c->sparse = ordered ? 0 : get_bits(f,1);\n\n      if (c->dimensions == 0 && c->entries != 0)    return error(f, VORBIS_invalid_setup);\n\n      if (c->sparse)\n         lengths = (uint8 *) setup_temp_malloc(f, c->entries);\n      else\n         lengths = c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n\n      if (!lengths) return error(f, VORBIS_outofmem);\n\n      if (ordered) {\n         int current_entry = 0;\n         int current_length = get_bits(f,5) + 1;\n         while (current_entry < c->entries) {\n            int limit = c->entries - current_entry;\n            int n = get_bits(f, ilog(limit));\n            if (current_length >= 32) return error(f, VORBIS_invalid_setup);\n            if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n            memset(lengths + current_entry, current_length, n);\n            current_entry += n;\n            ++current_length;\n         }\n      } else {\n         for (j=0; j < c->entries; ++j) {\n            int present = c->sparse ? get_bits(f,1) : 1;\n            if (present) {\n               lengths[j] = get_bits(f, 5) + 1;\n               ++total;\n               if (lengths[j] == 32)\n                  return error(f, VORBIS_invalid_setup);\n            } else {\n               lengths[j] = NO_CODE;\n            }\n         }\n      }\n\n      if (c->sparse && total >= c->entries >> 2) {\n         // convert sparse items to non-sparse!\n         if (c->entries > (int) f->setup_temp_memory_required)\n            f->setup_temp_memory_required = c->entries;\n\n         c->codeword_lengths = (uint8 *) setup_malloc(f, c->entries);\n         if (c->codeword_lengths == NULL) return error(f, VORBIS_outofmem);\n         memcpy(c->codeword_lengths, lengths, c->entries);\n         setup_temp_free(f, lengths, c->entries); // note this is only safe if there have been no intervening temp mallocs!\n         lengths = c->codeword_lengths;\n         c->sparse = 0;\n      }\n\n      // compute the size of the sorted tables\n      if (c->sparse) {\n         sorted_count = total;\n      } else {\n         sorted_count = 0;\n         #ifndef STB_VORBIS_NO_HUFFMAN_BINARY_SEARCH\n         for (j=0; j < c->entries; ++j)\n            if (lengths[j] > STB_VORBIS_FAST_HUFFMAN_LENGTH && lengths[j] != NO_CODE)\n               ++sorted_count;\n         #endif\n      }\n\n      c->sorted_entries = sorted_count;\n      values = NULL;\n\n      CHECK(f);\n      if (!c->sparse) {\n         c->codewords = (uint32 *) setup_malloc(f, sizeof(c->codewords[0]) * c->entries);\n         if (!c->codewords)                  return error(f, VORBIS_outofmem);\n      } else {\n         unsigned int size;\n         if (c->sorted_entries) {\n            c->codeword_lengths = (uint8 *) setup_malloc(f, c->sorted_entries);\n            if (!c->codeword_lengths)           return error(f, VORBIS_outofmem);\n            c->codewords = (uint32 *) setup_temp_malloc(f, sizeof(*c->codewords) * c->sorted_entries);\n            if (!c->codewords)                  return error(f, VORBIS_outofmem);\n            values = (uint32 *) setup_temp_malloc(f, sizeof(*values) * c->sorted_entries);\n            if (!values)                        return error(f, VORBIS_outofmem);\n         }\n         size = c->entries + (sizeof(*c->codewords) + sizeof(*values)) * c->sorted_entries;\n         if (size > f->setup_temp_memory_required)\n            f->setup_temp_memory_required = size;\n      }\n\n      if (!compute_codewords(c, lengths, c->entries, values)) {\n         if (c->sparse) setup_temp_free(f, values, 0);\n         return error(f, VORBIS_invalid_setup);\n      }\n\n      if (c->sorted_entries) {\n         // allocate an extra slot for sentinels\n         c->sorted_codewords = (uint32 *) setup_malloc(f, sizeof(*c->sorted_codewords) * (c->sorted_entries+1));\n         if (c->sorted_codewords == NULL) return error(f, VORBIS_outofmem);\n         // allocate an extra slot at the front so that c->sorted_values[-1] is defined\n         // so that we can catch that case without an extra if\n         c->sorted_values    = ( int   *) setup_malloc(f, sizeof(*c->sorted_values   ) * (c->sorted_entries+1));\n         if (c->sorted_values == NULL) return error(f, VORBIS_outofmem);\n         ++c->sorted_values;\n         c->sorted_values[-1] = -1;\n         compute_sorted_huffman(c, lengths, values);\n      }\n\n      if (c->sparse) {\n         setup_temp_free(f, values, sizeof(*values)*c->sorted_entries);\n         setup_temp_free(f, c->codewords, sizeof(*c->codewords)*c->sorted_entries);\n         setup_temp_free(f, lengths, c->entries);\n         c->codewords = NULL;\n      }\n\n      compute_accelerated_huffman(c);\n\n      CHECK(f);\n      c->lookup_type = get_bits(f, 4);\n      if (c->lookup_type > 2) return error(f, VORBIS_invalid_setup);\n      if (c->lookup_type > 0) {\n         uint16 *mults;\n         c->minimum_value = float32_unpack(get_bits(f, 32));\n         c->delta_value = float32_unpack(get_bits(f, 32));\n         c->value_bits = get_bits(f, 4)+1;\n         c->sequence_p = get_bits(f,1);\n         if (c->lookup_type == 1) {\n            int values = lookup1_values(c->entries, c->dimensions);\n            if (values < 0) return error(f, VORBIS_invalid_setup);\n            c->lookup_values = (uint32) values;\n         } else {\n            c->lookup_values = c->entries * c->dimensions;\n         }\n         if (c->lookup_values == 0) return error(f, VORBIS_invalid_setup);\n         mults = (uint16 *) setup_temp_malloc(f, sizeof(mults[0]) * c->lookup_values);\n         if (mults == NULL) return error(f, VORBIS_outofmem);\n         for (j=0; j < (int) c->lookup_values; ++j) {\n            int q = get_bits(f, c->value_bits);\n            if (q == EOP) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_invalid_setup); }\n            mults[j] = q;\n         }\n\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n         if (c->lookup_type == 1) {\n            int len, sparse = c->sparse;\n            float last=0;\n            // pre-expand the lookup1-style multiplicands, to avoid a divide in the inner loop\n            if (sparse) {\n               if (c->sorted_entries == 0) goto skip;\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->sorted_entries * c->dimensions);\n            } else\n               c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->entries        * c->dimensions);\n            if (c->multiplicands == NULL) { setup_temp_free(f,mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            len = sparse ? c->sorted_entries : c->entries;\n            for (j=0; j < len; ++j) {\n               unsigned int z = sparse ? c->sorted_values[j] : j;\n               unsigned int div=1;\n               for (k=0; k < c->dimensions; ++k) {\n                  int off = (z / div) % c->lookup_values;\n                  float val = mults[off];\n                  val = mults[off]*c->delta_value + c->minimum_value + last;\n                  c->multiplicands[j*c->dimensions + k] = val;\n                  if (c->sequence_p)\n                     last = val;\n                  if (k+1 < c->dimensions) {\n                     if (div > UINT_MAX / (unsigned int) c->lookup_values) {\n                        setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values);\n                        return error(f, VORBIS_invalid_setup);\n                     }\n                     div *= c->lookup_values;\n                  }\n               }\n            }\n            c->lookup_type = 2;\n         }\n         else\n#endif\n         {\n            float last=0;\n            CHECK(f);\n            c->multiplicands = (codetype *) setup_malloc(f, sizeof(c->multiplicands[0]) * c->lookup_values);\n            if (c->multiplicands == NULL) { setup_temp_free(f, mults,sizeof(mults[0])*c->lookup_values); return error(f, VORBIS_outofmem); }\n            for (j=0; j < (int) c->lookup_values; ++j) {\n               float val = mults[j] * c->delta_value + c->minimum_value + last;\n               c->multiplicands[j] = val;\n               if (c->sequence_p)\n                  last = val;\n            }\n         }\n#ifndef STB_VORBIS_DIVIDES_IN_CODEBOOK\n        skip:;\n#endif\n         setup_temp_free(f, mults, sizeof(mults[0])*c->lookup_values);\n\n         CHECK(f);\n      }\n      CHECK(f);\n   }\n\n   // time domain transfers (notused)\n\n   x = get_bits(f, 6) + 1;\n   for (i=0; i < x; ++i) {\n      uint32 z = get_bits(f, 16);\n      if (z != 0) return error(f, VORBIS_invalid_setup);\n   }\n\n   // Floors\n   f->floor_count = get_bits(f, 6)+1;\n   f->floor_config = (Floor *)  setup_malloc(f, f->floor_count * sizeof(*f->floor_config));\n   if (f->floor_config == NULL) return error(f, VORBIS_outofmem);\n   for (i=0; i < f->floor_count; ++i) {\n      f->floor_types[i] = get_bits(f, 16);\n      if (f->floor_types[i] > 1) return error(f, VORBIS_invalid_setup);\n      if (f->floor_types[i] == 0) {\n         Floor0 *g = &f->floor_config[i].floor0;\n         g->order = get_bits(f,8);\n         g->rate = get_bits(f,16);\n         g->bark_map_size = get_bits(f,16);\n         g->amplitude_bits = get_bits(f,6);\n         g->amplitude_offset = get_bits(f,8);\n         g->number_of_books = get_bits(f,4) + 1;\n         for (j=0; j < g->number_of_books; ++j)\n            g->book_list[j] = get_bits(f,8);\n         return error(f, VORBIS_feature_not_supported);\n      } else {\n         stbv__floor_ordering p[31*8+2];\n         Floor1 *g = &f->floor_config[i].floor1;\n         int max_class = -1; \n         g->partitions = get_bits(f, 5);\n         for (j=0; j < g->partitions; ++j) {\n            g->partition_class_list[j] = get_bits(f, 4);\n            if (g->partition_class_list[j] > max_class)\n               max_class = g->partition_class_list[j];\n         }\n         for (j=0; j <= max_class; ++j) {\n            g->class_dimensions[j] = get_bits(f, 3)+1;\n            g->class_subclasses[j] = get_bits(f, 2);\n            if (g->class_subclasses[j]) {\n               g->class_masterbooks[j] = get_bits(f, 8);\n               if (g->class_masterbooks[j] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n            for (k=0; k < 1 << g->class_subclasses[j]; ++k) {\n               g->subclass_books[j][k] = get_bits(f,8)-1;\n               if (g->subclass_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            }\n         }\n         g->floor1_multiplier = get_bits(f,2)+1;\n         g->rangebits = get_bits(f,4);\n         g->Xlist[0] = 0;\n         g->Xlist[1] = 1 << g->rangebits;\n         g->values = 2;\n         for (j=0; j < g->partitions; ++j) {\n            int c = g->partition_class_list[j];\n            for (k=0; k < g->class_dimensions[c]; ++k) {\n               g->Xlist[g->values] = get_bits(f, g->rangebits);\n               ++g->values;\n            }\n         }\n         // precompute the sorting\n         for (j=0; j < g->values; ++j) {\n            p[j].x = g->Xlist[j];\n            p[j].id = j;\n         }\n         qsort(p, g->values, sizeof(p[0]), point_compare);\n         for (j=0; j < g->values-1; ++j)\n            if (p[j].x == p[j+1].x)\n               return error(f, VORBIS_invalid_setup);\n         for (j=0; j < g->values; ++j)\n            g->sorted_order[j] = (uint8) p[j].id;\n         // precompute the neighbors\n         for (j=2; j < g->values; ++j) {\n            int low,hi;\n            neighbors(g->Xlist, j, &low,&hi);\n            g->neighbors[j][0] = low;\n            g->neighbors[j][1] = hi;\n         }\n\n         if (g->values > longest_floorlist)\n            longest_floorlist = g->values;\n      }\n   }\n\n   // Residue\n   f->residue_count = get_bits(f, 6)+1;\n   f->residue_config = (Residue *) setup_malloc(f, f->residue_count * sizeof(f->residue_config[0]));\n   if (f->residue_config == NULL) return error(f, VORBIS_outofmem);\n   memset(f->residue_config, 0, f->residue_count * sizeof(f->residue_config[0]));\n   for (i=0; i < f->residue_count; ++i) {\n      uint8 residue_cascade[64];\n      Residue *r = f->residue_config+i;\n      f->residue_types[i] = get_bits(f, 16);\n      if (f->residue_types[i] > 2) return error(f, VORBIS_invalid_setup);\n      r->begin = get_bits(f, 24);\n      r->end = get_bits(f, 24);\n      if (r->end < r->begin) return error(f, VORBIS_invalid_setup);\n      r->part_size = get_bits(f,24)+1;\n      r->classifications = get_bits(f,6)+1;\n      r->classbook = get_bits(f,8);\n      if (r->classbook >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n      for (j=0; j < r->classifications; ++j) {\n         uint8 high_bits=0;\n         uint8 low_bits=get_bits(f,3);\n         if (get_bits(f,1))\n            high_bits = get_bits(f,5);\n         residue_cascade[j] = high_bits*8 + low_bits;\n      }\n      r->residue_books = (short (*)[8]) setup_malloc(f, sizeof(r->residue_books[0]) * r->classifications);\n      if (r->residue_books == NULL) return error(f, VORBIS_outofmem);\n      for (j=0; j < r->classifications; ++j) {\n         for (k=0; k < 8; ++k) {\n            if (residue_cascade[j] & (1 << k)) {\n               r->residue_books[j][k] = get_bits(f, 8);\n               if (r->residue_books[j][k] >= f->codebook_count) return error(f, VORBIS_invalid_setup);\n            } else {\n               r->residue_books[j][k] = -1;\n            }\n         }\n      }\n      // precompute the classifications[] array to avoid inner-loop mod/divide\n      // call it 'classdata' since we already have r->classifications\n      r->classdata = (uint8 **) setup_malloc(f, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      if (!r->classdata) return error(f, VORBIS_outofmem);\n      memset(r->classdata, 0, sizeof(*r->classdata) * f->codebooks[r->classbook].entries);\n      for (j=0; j < f->codebooks[r->classbook].entries; ++j) {\n         int classwords = f->codebooks[r->classbook].dimensions;\n         int temp = j;\n         r->classdata[j] = (uint8 *) setup_malloc(f, sizeof(r->classdata[j][0]) * classwords);\n         if (r->classdata[j] == NULL) return error(f, VORBIS_outofmem);\n         for (k=classwords-1; k >= 0; --k) {\n            r->classdata[j][k] = temp % r->classifications;\n            temp /= r->classifications;\n         }\n      }\n   }\n\n   f->mapping_count = get_bits(f,6)+1;\n   f->mapping = (Mapping *) setup_malloc(f, f->mapping_count * sizeof(*f->mapping));\n   if (f->mapping == NULL) return error(f, VORBIS_outofmem);\n   memset(f->mapping, 0, f->mapping_count * sizeof(*f->mapping));\n   for (i=0; i < f->mapping_count; ++i) {\n      Mapping *m = f->mapping + i;      \n      int mapping_type = get_bits(f,16);\n      if (mapping_type != 0) return error(f, VORBIS_invalid_setup);\n      m->chan = (MappingChannel *) setup_malloc(f, f->channels * sizeof(*m->chan));\n      if (m->chan == NULL) return error(f, VORBIS_outofmem);\n      if (get_bits(f,1))\n         m->submaps = get_bits(f,4)+1;\n      else\n         m->submaps = 1;\n      if (m->submaps > max_submaps)\n         max_submaps = m->submaps;\n      if (get_bits(f,1)) {\n         m->coupling_steps = get_bits(f,8)+1;\n         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);\n         for (k=0; k < m->coupling_steps; ++k) {\n            m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n            m->chan[k].angle = get_bits(f, ilog(f->channels-1));\n            if (m->chan[k].magnitude >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].angle     >= f->channels)        return error(f, VORBIS_invalid_setup);\n            if (m->chan[k].magnitude == m->chan[k].angle)   return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         m->coupling_steps = 0;\n\n      // reserved field\n      if (get_bits(f,2)) return error(f, VORBIS_invalid_setup);\n      if (m->submaps > 1) {\n         for (j=0; j < f->channels; ++j) {\n            m->chan[j].mux = get_bits(f, 4);\n            if (m->chan[j].mux >= m->submaps)                return error(f, VORBIS_invalid_setup);\n         }\n      } else\n         // @SPECIFICATION: this case is missing from the spec\n         for (j=0; j < f->channels; ++j)\n            m->chan[j].mux = 0;\n\n      for (j=0; j < m->submaps; ++j) {\n         get_bits(f,8); // discard\n         m->submap_floor[j] = get_bits(f,8);\n         m->submap_residue[j] = get_bits(f,8);\n         if (m->submap_floor[j] >= f->floor_count)      return error(f, VORBIS_invalid_setup);\n         if (m->submap_residue[j] >= f->residue_count)  return error(f, VORBIS_invalid_setup);\n      }\n   }\n\n   // Modes\n   f->mode_count = get_bits(f, 6)+1;\n   for (i=0; i < f->mode_count; ++i) {\n      Mode *m = f->mode_config+i;\n      m->blockflag = get_bits(f,1);\n      m->windowtype = get_bits(f,16);\n      m->transformtype = get_bits(f,16);\n      m->mapping = get_bits(f,8);\n      if (m->windowtype != 0)                 return error(f, VORBIS_invalid_setup);\n      if (m->transformtype != 0)              return error(f, VORBIS_invalid_setup);\n      if (m->mapping >= f->mapping_count)     return error(f, VORBIS_invalid_setup);\n   }\n\n   flush_packet(f);\n\n   f->previous_length = 0;\n\n   for (i=0; i < f->channels; ++i) {\n      f->channel_buffers[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1);\n      f->previous_window[i] = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      f->finalY[i]          = (int16 *) setup_malloc(f, sizeof(int16) * longest_floorlist);\n      if (f->channel_buffers[i] == NULL || f->previous_window[i] == NULL || f->finalY[i] == NULL) return error(f, VORBIS_outofmem);\n      memset(f->channel_buffers[i], 0, sizeof(float) * f->blocksize_1);\n      #ifdef STB_VORBIS_NO_DEFER_FLOOR\n      f->floor_buffers[i]   = (float *) setup_malloc(f, sizeof(float) * f->blocksize_1/2);\n      if (f->floor_buffers[i] == NULL) return error(f, VORBIS_outofmem);\n      #endif\n   }\n\n   if (!init_blocksize(f, 0, f->blocksize_0)) return FALSE;\n   if (!init_blocksize(f, 1, f->blocksize_1)) return FALSE;\n   f->blocksize[0] = f->blocksize_0;\n   f->blocksize[1] = f->blocksize_1;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (integer_divide_table[1][1]==0)\n      for (i=0; i < DIVTAB_NUMER; ++i)\n         for (j=1; j < DIVTAB_DENOM; ++j)\n            integer_divide_table[i][j] = i / j;\n#endif\n\n   // compute how much temporary memory is needed\n\n   // 1.\n   {\n      uint32 imdct_mem = (f->blocksize_1 * sizeof(float) >> 1);\n      uint32 classify_mem;\n      int i,max_part_read=0;\n      for (i=0; i < f->residue_count; ++i) {\n         Residue *r = f->residue_config + i;\n         unsigned int actual_size = f->blocksize_1 / 2;\n         unsigned int limit_r_begin = r->begin < actual_size ? r->begin : actual_size;\n         unsigned int limit_r_end   = r->end   < actual_size ? r->end   : actual_size;\n         int n_read = limit_r_end - limit_r_begin;\n         int part_read = n_read / r->part_size;\n         if (part_read > max_part_read)\n            max_part_read = part_read;\n      }\n      #ifndef STB_VORBIS_DIVIDES_IN_RESIDUE\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(uint8 *));\n      #else\n      classify_mem = f->channels * (sizeof(void*) + max_part_read * sizeof(int *));\n      #endif\n\n      // maximum reasonable partition size is f->blocksize_1\n\n      f->temp_memory_required = classify_mem;\n      if (imdct_mem > f->temp_memory_required)\n         f->temp_memory_required = imdct_mem;\n   }\n\n   f->first_decode = TRUE;\n\n   if (f->alloc.alloc_buffer) {\n      assert(f->temp_offset == f->alloc.alloc_buffer_length_in_bytes);\n      // check if there's enough temp memory so we don't error later\n      if (f->setup_offset + sizeof(*f) + f->temp_memory_required > (unsigned) f->temp_offset)\n         return error(f, VORBIS_outofmem);\n   }\n\n   f->first_audio_page_offset = stb_vorbis_get_file_offset(f);\n\n   return TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -127,6 +127,7 @@\n          while (current_entry < c->entries) {\n             int limit = c->entries - current_entry;\n             int n = get_bits(f, ilog(limit));\n+            if (current_length >= 32) return error(f, VORBIS_invalid_setup);\n             if (current_entry + n > (int) c->entries) { return error(f, VORBIS_invalid_setup); }\n             memset(lengths + current_entry, current_length, n);\n             current_entry += n;\n@@ -230,7 +231,9 @@\n          c->value_bits = get_bits(f, 4)+1;\n          c->sequence_p = get_bits(f,1);\n          if (c->lookup_type == 1) {\n-            c->lookup_values = lookup1_values(c->entries, c->dimensions);\n+            int values = lookup1_values(c->entries, c->dimensions);\n+            if (values < 0) return error(f, VORBIS_invalid_setup);\n+            c->lookup_values = (uint32) values;\n          } else {\n             c->lookup_values = c->entries * c->dimensions;\n          }\n@@ -366,6 +369,9 @@\n             p[j].id = j;\n          }\n          qsort(p, g->values, sizeof(p[0]), point_compare);\n+         for (j=0; j < g->values-1; ++j)\n+            if (p[j].x == p[j+1].x)\n+               return error(f, VORBIS_invalid_setup);\n          for (j=0; j < g->values; ++j)\n             g->sorted_order[j] = (uint8) p[j].id;\n          // precompute the neighbors\n@@ -452,6 +458,7 @@\n          max_submaps = m->submaps;\n       if (get_bits(f,1)) {\n          m->coupling_steps = get_bits(f,8)+1;\n+         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);\n          for (k=0; k < m->coupling_steps; ++k) {\n             m->chan[k].magnitude = get_bits(f, ilog(f->channels-1));\n             m->chan[k].angle = get_bits(f, ilog(f->channels-1));",
        "diff_line_info": {
            "deleted_lines": [
                "            c->lookup_values = lookup1_values(c->entries, c->dimensions);"
            ],
            "added_lines": [
                "            if (current_length >= 32) return error(f, VORBIS_invalid_setup);",
                "            int values = lookup1_values(c->entries, c->dimensions);",
                "            if (values < 0) return error(f, VORBIS_invalid_setup);",
                "            c->lookup_values = (uint32) values;",
                "         for (j=0; j < g->values-1; ++j)",
                "            if (p[j].x == p[j+1].x)",
                "               return error(f, VORBIS_invalid_setup);",
                "         if (m->coupling_steps > f->channels) return error(f, VORBIS_invalid_setup);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/lookup1_values",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int lookup1_values(int entries, int dim)\n{\n   int r = (int) floor(exp((float) log((float) entries) / dim));\n   if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n      ++r;                                              // floor() to avoid _ftol() when non-CRT\n   assert(pow((float) r+1, dim) > entries);\n   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above\n   return r;\n}",
        "func": "static int lookup1_values(int entries, int dim)\n{\n   int r = (int) floor(exp((float) log((float) entries) / dim));\n   if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n      ++r;                                              // floor() to avoid _ftol() when non-CRT\n   if (pow((float) r+1, dim) <= entries)\n      return -1;\n   if ((int) floor(pow((float) r, dim)) > entries)\n      return -1;\n   return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,9 @@\n    int r = (int) floor(exp((float) log((float) entries) / dim));\n    if ((int) floor(pow((float) r+1, dim)) <= entries)   // (int) cast for MinGW warning;\n       ++r;                                              // floor() to avoid _ftol() when non-CRT\n-   assert(pow((float) r+1, dim) > entries);\n-   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above\n+   if (pow((float) r+1, dim) <= entries)\n+      return -1;\n+   if ((int) floor(pow((float) r, dim)) > entries)\n+      return -1;\n    return r;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "   assert(pow((float) r+1, dim) > entries);",
                "   assert((int) floor(pow((float) r, dim)) <= entries); // (int),floor() as above"
            ],
            "added_lines": [
                "   if (pow((float) r+1, dim) <= entries)",
                "      return -1;",
                "   if ((int) floor(pow((float) r, dim)) > entries)",
                "      return -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/vorbis_finish_frame",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static int vorbis_finish_frame(stb_vorbis *f, int len, int left, int right)\n{\n   int prev,i,j;\n   // we use right&left (the start of the right- and left-window sin()-regions)\n   // to determine how much to return, rather than inferring from the rules\n   // (same result, clearer code); 'left' indicates where our sin() window\n   // starts, therefore where the previous window's right edge starts, and\n   // therefore where to start mixing from the previous buffer. 'right'\n   // indicates where our sin() ending-window starts, therefore that's where\n   // we start saving, and where our returned-data ends.\n\n   // mixin from previous window\n   if (f->previous_length) {\n      int i,j, n = f->previous_length;\n      float *w = get_window(f, n);\n      for (i=0; i < f->channels; ++i) {\n         for (j=0; j < n; ++j)\n            f->channel_buffers[i][left+j] =\n               f->channel_buffers[i][left+j]*w[    j] +\n               f->previous_window[i][     j]*w[n-1-j];\n      }\n   }\n\n   prev = f->previous_length;\n\n   // last half of this data becomes previous window\n   f->previous_length = len - right;\n\n   // @OPTIMIZE: could avoid this copy by double-buffering the\n   // output (flipping previous_window with channel_buffers), but\n   // then previous_window would have to be 2x as large, and\n   // channel_buffers couldn't be temp mem (although they're NOT\n   // currently temp mem, they could be (unless we want to level\n   // performance by spreading out the computation))\n   for (i=0; i < f->channels; ++i)\n      for (j=0; right+j < len; ++j)\n         f->previous_window[i][j] = f->channel_buffers[i][right+j];\n\n   if (!prev)\n      // there was no previous packet, so this data isn't valid...\n      // this isn't entirely true, only the would-have-overlapped data\n      // isn't valid, but this seems to be what the spec requires\n      return 0;\n\n   // truncate a short frame\n   if (len < right) right = len;\n\n   f->samples_output += right-left;\n\n   return right - left;\n}",
        "func": "static int vorbis_finish_frame(stb_vorbis *f, int len, int left, int right)\n{\n   int prev,i,j;\n   // we use right&left (the start of the right- and left-window sin()-regions)\n   // to determine how much to return, rather than inferring from the rules\n   // (same result, clearer code); 'left' indicates where our sin() window\n   // starts, therefore where the previous window's right edge starts, and\n   // therefore where to start mixing from the previous buffer. 'right'\n   // indicates where our sin() ending-window starts, therefore that's where\n   // we start saving, and where our returned-data ends.\n\n   // mixin from previous window\n   if (f->previous_length) {\n      int i,j, n = f->previous_length;\n      float *w = get_window(f, n);\n      if (w == NULL) return 0;\n      for (i=0; i < f->channels; ++i) {\n         for (j=0; j < n; ++j)\n            f->channel_buffers[i][left+j] =\n               f->channel_buffers[i][left+j]*w[    j] +\n               f->previous_window[i][     j]*w[n-1-j];\n      }\n   }\n\n   prev = f->previous_length;\n\n   // last half of this data becomes previous window\n   f->previous_length = len - right;\n\n   // @OPTIMIZE: could avoid this copy by double-buffering the\n   // output (flipping previous_window with channel_buffers), but\n   // then previous_window would have to be 2x as large, and\n   // channel_buffers couldn't be temp mem (although they're NOT\n   // currently temp mem, they could be (unless we want to level\n   // performance by spreading out the computation))\n   for (i=0; i < f->channels; ++i)\n      for (j=0; right+j < len; ++j)\n         f->previous_window[i][j] = f->channel_buffers[i][right+j];\n\n   if (!prev)\n      // there was no previous packet, so this data isn't valid...\n      // this isn't entirely true, only the would-have-overlapped data\n      // isn't valid, but this seems to be what the spec requires\n      return 0;\n\n   // truncate a short frame\n   if (len < right) right = len;\n\n   f->samples_output += right-left;\n\n   return right - left;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n    if (f->previous_length) {\n       int i,j, n = f->previous_length;\n       float *w = get_window(f, n);\n+      if (w == NULL) return 0;\n       for (i=0; i < f->channels; ++i) {\n          for (j=0; j < n; ++j)\n             f->channel_buffers[i][left+j] =",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if (w == NULL) return 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/get_window",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static float *get_window(vorb *f, int len)\n{\n   len <<= 1;\n   if (len == f->blocksize_0) return f->window[0];\n   if (len == f->blocksize_1) return f->window[1];\n   assert(0);\n   return NULL;\n}",
        "func": "static float *get_window(vorb *f, int len)\n{\n   len <<= 1;\n   if (len == f->blocksize_0) return f->window[0];\n   if (len == f->blocksize_1) return f->window[1];\n   return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,5 @@\n    len <<= 1;\n    if (len == f->blocksize_0) return f->window[0];\n    if (len == f->blocksize_1) return f->window[1];\n-   assert(0);\n    return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "   assert(0);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2019-13217",
        "func_name": "nothings/stb/draw_line",
        "description": "A heap buffer overflow in the start_decoder function in stb_vorbis through 2019-03-04 allows an attacker to cause a denial of service or execute arbitrary code by opening a crafted Ogg Vorbis file.",
        "git_url": "https://github.com/nothings/stb/commit/98fdfc6df88b1e34a736d5e126e6c8139c8de1a6",
        "commit_title": "Fix seven bugs discovered and fixed by ForAllSecure:",
        "commit_text": " CVE-2019-13217: heap buffer overflow in start_decoder() CVE-2019-13218: stack buffer overflow in compute_codewords() CVE-2019-13219: uninitialized memory in vorbis_decode_packet_rest() CVE-2019-13220: out-of-range read in draw_line() CVE-2019-13221: issue with large 1D codebooks in lookup1_values() CVE-2019-13222: unchecked NULL returned by get_window() CVE-2019-13223: division by zero in predict_point()",
        "func_before": "static __forceinline void draw_line(float *output, int x0, int y0, int x1, int y1, int n)\n{\n   int dy = y1 - y0;\n   int adx = x1 - x0;\n   int ady = abs(dy);\n   int base;\n   int x=x0,y=y0;\n   int err = 0;\n   int sy;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (adx < DIVTAB_DENOM && ady < DIVTAB_NUMER) {\n      if (dy < 0) {\n         base = -integer_divide_table[ady][adx];\n         sy = base-1;\n      } else {\n         base =  integer_divide_table[ady][adx];\n         sy = base+1;\n      }\n   } else {\n      base = dy / adx;\n      if (dy < 0)\n         sy = base - 1;\n      else\n         sy = base+1;\n   }\n#else\n   base = dy / adx;\n   if (dy < 0)\n      sy = base - 1;\n   else\n      sy = base+1;\n#endif\n   ady -= abs(base) * adx;\n   if (x1 > n) x1 = n;\n   if (x < x1) {\n      LINE_OP(output[x], inverse_db_table[y]);\n      for (++x; x < x1; ++x) {\n         err += ady;\n         if (err >= adx) {\n            err -= adx;\n            y += sy;\n         } else\n            y += base;\n         LINE_OP(output[x], inverse_db_table[y]);\n      }\n   }\n}",
        "func": "static __forceinline void draw_line(float *output, int x0, int y0, int x1, int y1, int n)\n{\n   int dy = y1 - y0;\n   int adx = x1 - x0;\n   int ady = abs(dy);\n   int base;\n   int x=x0,y=y0;\n   int err = 0;\n   int sy;\n\n#ifdef STB_VORBIS_DIVIDE_TABLE\n   if (adx < DIVTAB_DENOM && ady < DIVTAB_NUMER) {\n      if (dy < 0) {\n         base = -integer_divide_table[ady][adx];\n         sy = base-1;\n      } else {\n         base =  integer_divide_table[ady][adx];\n         sy = base+1;\n      }\n   } else {\n      base = dy / adx;\n      if (dy < 0)\n         sy = base - 1;\n      else\n         sy = base+1;\n   }\n#else\n   base = dy / adx;\n   if (dy < 0)\n      sy = base - 1;\n   else\n      sy = base+1;\n#endif\n   ady -= abs(base) * adx;\n   if (x1 > n) x1 = n;\n   if (x < x1) {\n      LINE_OP(output[x], inverse_db_table[y&255]);\n      for (++x; x < x1; ++x) {\n         err += ady;\n         if (err >= adx) {\n            err -= adx;\n            y += sy;\n         } else\n            y += base;\n         LINE_OP(output[x], inverse_db_table[y&255]);\n      }\n   }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,7 +34,7 @@\n    ady -= abs(base) * adx;\n    if (x1 > n) x1 = n;\n    if (x < x1) {\n-      LINE_OP(output[x], inverse_db_table[y]);\n+      LINE_OP(output[x], inverse_db_table[y&255]);\n       for (++x; x < x1; ++x) {\n          err += ady;\n          if (err >= adx) {\n@@ -42,7 +42,7 @@\n             y += sy;\n          } else\n             y += base;\n-         LINE_OP(output[x], inverse_db_table[y]);\n+         LINE_OP(output[x], inverse_db_table[y&255]);\n       }\n    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      LINE_OP(output[x], inverse_db_table[y]);",
                "         LINE_OP(output[x], inverse_db_table[y]);"
            ],
            "added_lines": [
                "      LINE_OP(output[x], inverse_db_table[y&255]);",
                "         LINE_OP(output[x], inverse_db_table[y&255]);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15939",
        "func_name": "opencv/numPartsWithin",
        "description": "An issue was discovered in OpenCV 4.1.0. There is a divide-by-zero error in cv::HOGDescriptor::getDescriptorSize in modules/objdetect/src/hog.cpp.",
        "git_url": "https://github.com/opencv/opencv/commit/5a497077f109d543ab86dfdf8add1c76c0e47d29",
        "commit_title": "objdetect: add input check in HOG detector",
        "commit_text": "",
        "func_before": "static int numPartsWithin(int size, int part_size, int stride)\n{\n    return (size - part_size + stride) / stride;\n}",
        "func": "static int numPartsWithin(int size, int part_size, int stride)\n{\n    CV_Assert(stride != 0);\n    return (size - part_size + stride) / stride;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n static int numPartsWithin(int size, int part_size, int stride)\n {\n+    CV_Assert(stride != 0);\n     return (size - part_size + stride) / stride;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    CV_Assert(stride != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15939",
        "func_name": "opencv/getBlockHistogramSize",
        "description": "An issue was discovered in OpenCV 4.1.0. There is a divide-by-zero error in cv::HOGDescriptor::getDescriptorSize in modules/objdetect/src/hog.cpp.",
        "git_url": "https://github.com/opencv/opencv/commit/5a497077f109d543ab86dfdf8add1c76c0e47d29",
        "commit_title": "objdetect: add input check in HOG detector",
        "commit_text": "",
        "func_before": "static size_t getBlockHistogramSize(Size block_size, Size cell_size, int nbins)\n{\n    Size cells_per_block = Size(block_size.width / cell_size.width,\n        block_size.height / cell_size.height);\n    return (size_t)(nbins * cells_per_block.area());\n}",
        "func": "static size_t getBlockHistogramSize(Size block_size, Size cell_size, int nbins)\n{\n    CV_Assert(!cell_size.empty());\n    Size cells_per_block = Size(block_size.width / cell_size.width,\n                                block_size.height / cell_size.height);\n    return (size_t)(nbins * cells_per_block.area());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n static size_t getBlockHistogramSize(Size block_size, Size cell_size, int nbins)\n {\n+    CV_Assert(!cell_size.empty());\n     Size cells_per_block = Size(block_size.width / cell_size.width,\n-        block_size.height / cell_size.height);\n+                                block_size.height / cell_size.height);\n     return (size_t)(nbins * cells_per_block.area());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        block_size.height / cell_size.height);"
            ],
            "added_lines": [
                "    CV_Assert(!cell_size.empty());",
                "                                block_size.height / cell_size.height);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15939",
        "func_name": "opencv/HOGDescriptor::read",
        "description": "An issue was discovered in OpenCV 4.1.0. There is a divide-by-zero error in cv::HOGDescriptor::getDescriptorSize in modules/objdetect/src/hog.cpp.",
        "git_url": "https://github.com/opencv/opencv/commit/5a497077f109d543ab86dfdf8add1c76c0e47d29",
        "commit_title": "objdetect: add input check in HOG detector",
        "commit_text": "",
        "func_before": "bool HOGDescriptor::read(FileNode& obj)\n{\n    CV_Assert(!obj[\"winSize\"].empty());\n\n    if( !obj.isMap() )\n        return false;\n    FileNodeIterator it = obj[\"winSize\"].begin();\n    it >> winSize.width >> winSize.height;\n    it = obj[\"blockSize\"].begin();\n    it >> blockSize.width >> blockSize.height;\n    it = obj[\"blockStride\"].begin();\n    it >> blockStride.width >> blockStride.height;\n    it = obj[\"cellSize\"].begin();\n    it >> cellSize.width >> cellSize.height;\n    obj[\"nbins\"] >> nbins;\n    obj[\"derivAperture\"] >> derivAperture;\n    obj[\"winSigma\"] >> winSigma;\n    obj[\"histogramNormType\"] >> histogramNormType;\n    obj[\"L2HysThreshold\"] >> L2HysThreshold;\n    obj[\"gammaCorrection\"] >> gammaCorrection;\n    obj[\"nlevels\"] >> nlevels;\n    if (obj[\"signedGradient\"].empty())\n        signedGradient = false;\n    else\n        obj[\"signedGradient\"] >> signedGradient;\n\n    FileNode vecNode = obj[\"SVMDetector\"];\n    if( vecNode.isSeq() )\n    {\n        std::vector<float> _svmDetector;\n        vecNode >> _svmDetector;\n        setSVMDetector(_svmDetector);\n    }\n    return true;\n}",
        "func": "bool HOGDescriptor::read(FileNode& obj)\n{\n    CV_Assert(!obj[\"winSize\"].empty());\n\n    if( !obj.isMap() )\n        return false;\n    FileNodeIterator it = obj[\"winSize\"].begin();\n    it >> winSize.width >> winSize.height; CV_Assert(!winSize.empty());\n    it = obj[\"blockSize\"].begin();\n    it >> blockSize.width >> blockSize.height; CV_Assert(!blockSize.empty());\n    it = obj[\"blockStride\"].begin();\n    it >> blockStride.width >> blockStride.height; CV_Assert(!blockStride.empty());\n    it = obj[\"cellSize\"].begin();\n    it >> cellSize.width >> cellSize.height; CV_Assert(!cellSize.empty());\n    obj[\"nbins\"] >> nbins; CV_Assert(nbins > 0);\n    obj[\"derivAperture\"] >> derivAperture;\n    obj[\"winSigma\"] >> winSigma;\n    obj[\"histogramNormType\"] >> histogramNormType;\n    obj[\"L2HysThreshold\"] >> L2HysThreshold;\n    obj[\"gammaCorrection\"] >> gammaCorrection;\n    obj[\"nlevels\"] >> nlevels; CV_Assert(nlevels > 0);\n    if (obj[\"signedGradient\"].empty())\n        signedGradient = false;\n    else\n        obj[\"signedGradient\"] >> signedGradient;\n\n    FileNode vecNode = obj[\"SVMDetector\"];\n    if( vecNode.isSeq() )\n    {\n        std::vector<float> _svmDetector;\n        vecNode >> _svmDetector;\n        setSVMDetector(_svmDetector);\n    }\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,20 +5,20 @@\n     if( !obj.isMap() )\n         return false;\n     FileNodeIterator it = obj[\"winSize\"].begin();\n-    it >> winSize.width >> winSize.height;\n+    it >> winSize.width >> winSize.height; CV_Assert(!winSize.empty());\n     it = obj[\"blockSize\"].begin();\n-    it >> blockSize.width >> blockSize.height;\n+    it >> blockSize.width >> blockSize.height; CV_Assert(!blockSize.empty());\n     it = obj[\"blockStride\"].begin();\n-    it >> blockStride.width >> blockStride.height;\n+    it >> blockStride.width >> blockStride.height; CV_Assert(!blockStride.empty());\n     it = obj[\"cellSize\"].begin();\n-    it >> cellSize.width >> cellSize.height;\n-    obj[\"nbins\"] >> nbins;\n+    it >> cellSize.width >> cellSize.height; CV_Assert(!cellSize.empty());\n+    obj[\"nbins\"] >> nbins; CV_Assert(nbins > 0);\n     obj[\"derivAperture\"] >> derivAperture;\n     obj[\"winSigma\"] >> winSigma;\n     obj[\"histogramNormType\"] >> histogramNormType;\n     obj[\"L2HysThreshold\"] >> L2HysThreshold;\n     obj[\"gammaCorrection\"] >> gammaCorrection;\n-    obj[\"nlevels\"] >> nlevels;\n+    obj[\"nlevels\"] >> nlevels; CV_Assert(nlevels > 0);\n     if (obj[\"signedGradient\"].empty())\n         signedGradient = false;\n     else",
        "diff_line_info": {
            "deleted_lines": [
                "    it >> winSize.width >> winSize.height;",
                "    it >> blockSize.width >> blockSize.height;",
                "    it >> blockStride.width >> blockStride.height;",
                "    it >> cellSize.width >> cellSize.height;",
                "    obj[\"nbins\"] >> nbins;",
                "    obj[\"nlevels\"] >> nlevels;"
            ],
            "added_lines": [
                "    it >> winSize.width >> winSize.height; CV_Assert(!winSize.empty());",
                "    it >> blockSize.width >> blockSize.height; CV_Assert(!blockSize.empty());",
                "    it >> blockStride.width >> blockStride.height; CV_Assert(!blockStride.empty());",
                "    it >> cellSize.width >> cellSize.height; CV_Assert(!cellSize.empty());",
                "    obj[\"nbins\"] >> nbins; CV_Assert(nbins > 0);",
                "    obj[\"nlevels\"] >> nlevels; CV_Assert(nlevels > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-15939",
        "func_name": "opencv/HOGDescriptor::getDescriptorSize",
        "description": "An issue was discovered in OpenCV 4.1.0. There is a divide-by-zero error in cv::HOGDescriptor::getDescriptorSize in modules/objdetect/src/hog.cpp.",
        "git_url": "https://github.com/opencv/opencv/commit/5a497077f109d543ab86dfdf8add1c76c0e47d29",
        "commit_title": "objdetect: add input check in HOG detector",
        "commit_text": "",
        "func_before": "size_t HOGDescriptor::getDescriptorSize() const\n{\n    CV_Assert(blockSize.width % cellSize.width == 0 &&\n        blockSize.height % cellSize.height == 0);\n    CV_Assert((winSize.width - blockSize.width) % blockStride.width == 0 &&\n        (winSize.height - blockSize.height) % blockStride.height == 0 );\n\n    return (size_t)nbins*\n        (blockSize.width/cellSize.width)*\n        (blockSize.height/cellSize.height)*\n        ((winSize.width - blockSize.width)/blockStride.width + 1)*\n        ((winSize.height - blockSize.height)/blockStride.height + 1);\n}",
        "func": "size_t HOGDescriptor::getDescriptorSize() const\n{\n    CV_Assert(!cellSize.empty());\n    CV_Assert(!blockStride.empty());\n\n    CV_Assert(blockSize.width % cellSize.width == 0 &&\n        blockSize.height % cellSize.height == 0);\n    CV_Assert((winSize.width - blockSize.width) % blockStride.width == 0 &&\n        (winSize.height - blockSize.height) % blockStride.height == 0 );\n\n    return (size_t)nbins*\n        (blockSize.width/cellSize.width)*\n        (blockSize.height/cellSize.height)*\n        ((winSize.width - blockSize.width)/blockStride.width + 1)*\n        ((winSize.height - blockSize.height)/blockStride.height + 1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n size_t HOGDescriptor::getDescriptorSize() const\n {\n+    CV_Assert(!cellSize.empty());\n+    CV_Assert(!blockStride.empty());\n+\n     CV_Assert(blockSize.width % cellSize.width == 0 &&\n         blockSize.height % cellSize.height == 0);\n     CV_Assert((winSize.width - blockSize.width) % blockStride.width == 0 &&",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    CV_Assert(!cellSize.empty());",
                "    CV_Assert(!blockStride.empty());",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21725",
        "func_name": "tensorflow/OpLevelCostEstimator::PredictMaxPoolGrad",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The estimator for the cost of some convolution operations can be made to execute a division by 0. The function fails to check that the stride argument is strictly positive. Hence, the fix is to add a check for the stride argument to ensure it is valid. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a",
        "commit_title": "Internal change",
        "commit_text": " PiperOrigin-RevId: 411896058",
        "func_before": "Status OpLevelCostEstimator::PredictMaxPoolGrad(const OpContext& op_context,\n                                                NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  // y: op_info.inputs(1)\n  // y_grad: op_info.inputs(2)\n  if (op_info.inputs_size() < 3) {\n    return errors::InvalidArgument(\"MaxPoolGrad op has invalid inputs: \",\n                                   op_info.ShortDebugString());\n  }\n\n  ConvolutionDimensions dims = OpDimensionsFromInputs(\n      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n\n  int64_t ops = 0;\n  if (dims.kx == 1 && dims.ky == 1) {\n    // 1x1 window. No need to know which input was max.\n    ops = dims.batch * dims.ix * dims.iy * dims.iz;\n  } else if (dims.kx <= dims.sx && dims.ky <= dims.sy) {\n    // Non-overlapping window: re-run maxpool, then assign zero or y_grad.\n    ops = dims.batch * dims.iz *\n          (dims.ox * dims.oy * (dims.kx * dims.ky - 1) + dims.ix * dims.iy);\n  } else {\n    // Overlapping window: initialize with zeros, re-run maxpool, then\n    // accumulate y_gad to proper x_grad locations.\n    ops = dims.batch * dims.iz *\n          (dims.ox * dims.oy * (dims.kx * dims.ky - 1) + dims.ix * dims.iy * 2);\n  }\n  node_costs->num_compute_ops = ops;\n\n  // Just read x and y_grad; no need to read y as we assume MaxPoolGrad re-run\n  // MaxPool internally.\n  const int64_t input0_size =\n      CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  const int64_t input2_size =\n      CalculateTensorSize(op_info.inputs(2), &found_unknown_shapes);\n  node_costs->num_input_bytes_accessed = {input0_size, 0, input2_size};\n  // Write x_grad; size equal to x.\n  const int64_t output_size =\n      CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  node_costs->num_output_bytes_accessed = {output_size};\n  node_costs->max_memory = output_size;\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "func": "Status OpLevelCostEstimator::PredictMaxPoolGrad(const OpContext& op_context,\n                                                NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  // y: op_info.inputs(1)\n  // y_grad: op_info.inputs(2)\n  if (op_info.inputs_size() < 3) {\n    return errors::InvalidArgument(\"MaxPoolGrad op has invalid inputs: \",\n                                   op_info.ShortDebugString());\n  }\n\n  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n                                             &found_unknown_shapes));\n\n  int64_t ops = 0;\n  if (dims.kx == 1 && dims.ky == 1) {\n    // 1x1 window. No need to know which input was max.\n    ops = dims.batch * dims.ix * dims.iy * dims.iz;\n  } else if (dims.kx <= dims.sx && dims.ky <= dims.sy) {\n    // Non-overlapping window: re-run maxpool, then assign zero or y_grad.\n    ops = dims.batch * dims.iz *\n          (dims.ox * dims.oy * (dims.kx * dims.ky - 1) + dims.ix * dims.iy);\n  } else {\n    // Overlapping window: initialize with zeros, re-run maxpool, then\n    // accumulate y_gad to proper x_grad locations.\n    ops = dims.batch * dims.iz *\n          (dims.ox * dims.oy * (dims.kx * dims.ky - 1) + dims.ix * dims.iy * 2);\n  }\n  node_costs->num_compute_ops = ops;\n\n  // Just read x and y_grad; no need to read y as we assume MaxPoolGrad re-run\n  // MaxPool internally.\n  const int64_t input0_size =\n      CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  const int64_t input2_size =\n      CalculateTensorSize(op_info.inputs(2), &found_unknown_shapes);\n  node_costs->num_input_bytes_accessed = {input0_size, 0, input2_size};\n  // Write x_grad; size equal to x.\n  const int64_t output_size =\n      CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  node_costs->num_output_bytes_accessed = {output_size};\n  node_costs->max_memory = output_size;\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,8 +10,9 @@\n                                    op_info.ShortDebugString());\n   }\n \n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   int64_t ops = 0;\n   if (dims.kx == 1 && dims.ky == 1) {",
        "diff_line_info": {
            "deleted_lines": [
                "  ConvolutionDimensions dims = OpDimensionsFromInputs(",
                "      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);"
            ],
            "added_lines": [
                "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
                "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
                "                                             &found_unknown_shapes));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21725",
        "func_name": "tensorflow/OpLevelCostEstimator::PredictFusedBatchNormGrad",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The estimator for the cost of some convolution operations can be made to execute a division by 0. The function fails to check that the stride argument is strictly positive. Hence, the fix is to add a check for the stride argument to ensure it is valid. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a",
        "commit_title": "Internal change",
        "commit_text": " PiperOrigin-RevId: 411896058",
        "func_before": "Status OpLevelCostEstimator::PredictFusedBatchNormGrad(\n    const OpContext& op_context, NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // y_backprop: op_info.inputs(0)\n  // x: op_info.inputs(1)\n  // scale: op_info.inputs(2)\n  // mean: op_info.inputs(3)\n  // variance or inverse of variance: op_info.inputs(4)\n  ConvolutionDimensions dims = OpDimensionsFromInputs(\n      op_info.inputs(1).shape(), op_info, &found_unknown_shapes);\n\n  int64_t ops = 0;\n  const auto rsqrt_cost = Eigen::internal::functor_traits<\n      Eigen::internal::scalar_rsqrt_op<float>>::Cost;\n  ops = dims.iz * (dims.batch * dims.ix * dims.iy * 11 + 5 + rsqrt_cost);\n  node_costs->num_compute_ops = ops;\n\n  const int64_t size_nhwc =\n      CalculateTensorSize(op_info.inputs(1), &found_unknown_shapes);\n  const int64_t size_c =\n      CalculateTensorSize(op_info.inputs(2), &found_unknown_shapes);\n  // TODO(dyoon): fix missing memory cost for variance input (size_c) and\n  // yet another read of y_backprop (size_nhwc) internally.\n  node_costs->num_input_bytes_accessed = {size_nhwc, size_nhwc, size_c, size_c};\n  node_costs->num_output_bytes_accessed = {size_nhwc, size_c, size_c};\n  // FusedBatchNormGrad has to read y_backprop internally.\n  node_costs->internal_read_bytes = size_nhwc;\n  node_costs->max_memory = node_costs->num_total_output_bytes();\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "func": "Status OpLevelCostEstimator::PredictFusedBatchNormGrad(\n    const OpContext& op_context, NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // y_backprop: op_info.inputs(0)\n  // x: op_info.inputs(1)\n  // scale: op_info.inputs(2)\n  // mean: op_info.inputs(3)\n  // variance or inverse of variance: op_info.inputs(4)\n  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n                      OpDimensionsFromInputs(op_info.inputs(1).shape(), op_info,\n                                             &found_unknown_shapes));\n\n  int64_t ops = 0;\n  const auto rsqrt_cost = Eigen::internal::functor_traits<\n      Eigen::internal::scalar_rsqrt_op<float>>::Cost;\n  ops = dims.iz * (dims.batch * dims.ix * dims.iy * 11 + 5 + rsqrt_cost);\n  node_costs->num_compute_ops = ops;\n\n  const int64_t size_nhwc =\n      CalculateTensorSize(op_info.inputs(1), &found_unknown_shapes);\n  const int64_t size_c =\n      CalculateTensorSize(op_info.inputs(2), &found_unknown_shapes);\n  // TODO(dyoon): fix missing memory cost for variance input (size_c) and\n  // yet another read of y_backprop (size_nhwc) internally.\n  node_costs->num_input_bytes_accessed = {size_nhwc, size_nhwc, size_c, size_c};\n  node_costs->num_output_bytes_accessed = {size_nhwc, size_c, size_c};\n  // FusedBatchNormGrad has to read y_backprop internally.\n  node_costs->internal_read_bytes = size_nhwc;\n  node_costs->max_memory = node_costs->num_total_output_bytes();\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,8 +7,9 @@\n   // scale: op_info.inputs(2)\n   // mean: op_info.inputs(3)\n   // variance or inverse of variance: op_info.inputs(4)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(1).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(1).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   int64_t ops = 0;\n   const auto rsqrt_cost = Eigen::internal::functor_traits<",
        "diff_line_info": {
            "deleted_lines": [
                "  ConvolutionDimensions dims = OpDimensionsFromInputs(",
                "      op_info.inputs(1).shape(), op_info, &found_unknown_shapes);"
            ],
            "added_lines": [
                "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
                "                      OpDimensionsFromInputs(op_info.inputs(1).shape(), op_info,",
                "                                             &found_unknown_shapes));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21725",
        "func_name": "tensorflow/OpLevelCostEstimator::PredictAvgPool",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The estimator for the cost of some convolution operations can be made to execute a division by 0. The function fails to check that the stride argument is strictly positive. Hence, the fix is to add a check for the stride argument to ensure it is valid. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a",
        "commit_title": "Internal change",
        "commit_text": " PiperOrigin-RevId: 411896058",
        "func_before": "Status OpLevelCostEstimator::PredictAvgPool(const OpContext& op_context,\n                                            NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  ConvolutionDimensions dims = OpDimensionsFromInputs(\n      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n\n  // kx * ky - 1 additions and 1 multiplication per output.\n  int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * dims.kx * dims.ky;\n  node_costs->num_compute_ops = ops;\n\n  int64_t input_size;\n  if (dims.ky >= dims.sy) {\n    input_size = CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  } else {  // dims.ky < dims.sy\n    // vertical stride is larger than vertical kernel; assuming row-major\n    // format, skip unnecessary rows (or read every kx rows per sy rows, as the\n    // others are not used for output).\n    const auto data_size = DataTypeSize(BaseType(op_info.inputs(0).dtype()));\n    input_size = data_size * dims.batch * dims.ix * dims.ky * dims.oy * dims.iz;\n  }\n  node_costs->num_input_bytes_accessed = {input_size};\n\n  const int64_t output_size =\n      CalculateOutputSize(op_info, &found_unknown_shapes);\n  node_costs->num_output_bytes_accessed = {output_size};\n  node_costs->max_memory = output_size;\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "func": "Status OpLevelCostEstimator::PredictAvgPool(const OpContext& op_context,\n                                            NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n                                             &found_unknown_shapes));\n\n  // kx * ky - 1 additions and 1 multiplication per output.\n  int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * dims.kx * dims.ky;\n  node_costs->num_compute_ops = ops;\n\n  int64_t input_size;\n  if (dims.ky >= dims.sy) {\n    input_size = CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  } else {  // dims.ky < dims.sy\n    // vertical stride is larger than vertical kernel; assuming row-major\n    // format, skip unnecessary rows (or read every kx rows per sy rows, as the\n    // others are not used for output).\n    const auto data_size = DataTypeSize(BaseType(op_info.inputs(0).dtype()));\n    input_size = data_size * dims.batch * dims.ix * dims.ky * dims.oy * dims.iz;\n  }\n  node_costs->num_input_bytes_accessed = {input_size};\n\n  const int64_t output_size =\n      CalculateOutputSize(op_info, &found_unknown_shapes);\n  node_costs->num_output_bytes_accessed = {output_size};\n  node_costs->max_memory = output_size;\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,9 @@\n   bool found_unknown_shapes = false;\n   const auto& op_info = op_context.op_info;\n   // x: op_info.inputs(0)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n \n   // kx * ky - 1 additions and 1 multiplication per output.\n   int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * dims.kx * dims.ky;",
        "diff_line_info": {
            "deleted_lines": [
                "  ConvolutionDimensions dims = OpDimensionsFromInputs(",
                "      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);"
            ],
            "added_lines": [
                "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
                "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
                "                                             &found_unknown_shapes));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21725",
        "func_name": "tensorflow/OpLevelCostEstimator::OpDimensionsFromInputs",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The estimator for the cost of some convolution operations can be made to execute a division by 0. The function fails to check that the stride argument is strictly positive. Hence, the fix is to add a check for the stride argument to ensure it is valid. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a",
        "commit_title": "Internal change",
        "commit_text": " PiperOrigin-RevId: 411896058",
        "func_before": "OpLevelCostEstimator::ConvolutionDimensions\nOpLevelCostEstimator::OpDimensionsFromInputs(\n    const TensorShapeProto& original_image_shape, const OpInfo& op_info,\n    bool* found_unknown_shapes) {\n  VLOG(2) << \"op features: \" << op_info.DebugString();\n  VLOG(2) << \"Original image shape: \" << original_image_shape.DebugString();\n  auto image_shape =\n      MaybeGetMinimumShape(original_image_shape, 4, found_unknown_shapes);\n  VLOG(2) << \"Image shape: \" << image_shape.DebugString();\n\n  int x_index, y_index, channel_index;\n  const std::string& data_format = GetDataFormat(op_info);\n  if (data_format == \"NCHW\") {\n    channel_index = 1;\n    y_index = 2;\n    x_index = 3;\n  } else {\n    y_index = 1;\n    x_index = 2;\n    channel_index = 3;\n  }\n  int64_t batch = image_shape.dim(0).size();\n  int64_t ix = image_shape.dim(x_index).size();\n  int64_t iy = image_shape.dim(y_index).size();\n  int64_t iz = image_shape.dim(channel_index).size();\n\n  // Note that FusedBatchNorm doesn't have ksize attr, but GetKernelSize returns\n  // {1, 1, 1, 1} in that case.\n  std::vector<int64_t> ksize = GetKernelSize(op_info);\n  int64_t kx = ksize[x_index];\n  int64_t ky = ksize[y_index];\n  // These ops don't support groupwise operation, therefore kz == iz.\n  int64_t kz = iz;\n\n  std::vector<int64_t> strides = GetStrides(op_info);\n  int64_t sx = strides[x_index];\n  int64_t sy = strides[y_index];\n  const auto padding = GetPadding(op_info);\n\n  int64_t ox = GetOutputSize(ix, kx, sx, padding);\n  int64_t oy = GetOutputSize(iy, ky, sy, padding);\n  int64_t oz = iz;\n\n  OpLevelCostEstimator::ConvolutionDimensions conv_dims = {\n      batch, ix, iy, iz, kx, ky, kz, oz, ox, oy, sx, sy, padding};\n  return conv_dims;\n}",
        "func": "StatusOr<OpLevelCostEstimator::ConvolutionDimensions>\nOpLevelCostEstimator::OpDimensionsFromInputs(\n    const TensorShapeProto& original_image_shape, const OpInfo& op_info,\n    bool* found_unknown_shapes) {\n  VLOG(2) << \"op features: \" << op_info.DebugString();\n  VLOG(2) << \"Original image shape: \" << original_image_shape.DebugString();\n  auto image_shape =\n      MaybeGetMinimumShape(original_image_shape, 4, found_unknown_shapes);\n  VLOG(2) << \"Image shape: \" << image_shape.DebugString();\n\n  int x_index, y_index, channel_index;\n  const std::string& data_format = GetDataFormat(op_info);\n  if (data_format == \"NCHW\") {\n    channel_index = 1;\n    y_index = 2;\n    x_index = 3;\n  } else {\n    y_index = 1;\n    x_index = 2;\n    channel_index = 3;\n  }\n  int64_t batch = image_shape.dim(0).size();\n  int64_t ix = image_shape.dim(x_index).size();\n  int64_t iy = image_shape.dim(y_index).size();\n  int64_t iz = image_shape.dim(channel_index).size();\n\n  // Note that FusedBatchNorm doesn't have ksize attr, but GetKernelSize returns\n  // {1, 1, 1, 1} in that case.\n  std::vector<int64_t> ksize = GetKernelSize(op_info);\n  int64_t kx = ksize[x_index];\n  int64_t ky = ksize[y_index];\n  // These ops don't support groupwise operation, therefore kz == iz.\n  int64_t kz = iz;\n\n  std::vector<int64_t> strides = GetStrides(op_info);\n  int64_t sx = strides[x_index];\n  int64_t sy = strides[y_index];\n  if (sx == 0 || sy == 0) {\n    return errors::InvalidArgument(\n        \"Stride must be > 0 for Height and Width, but got (\", sy, \", \", sx,\n        \")\");\n  }\n  const auto padding = GetPadding(op_info);\n\n  int64_t ox = GetOutputSize(ix, kx, sx, padding);\n  int64_t oy = GetOutputSize(iy, ky, sy, padding);\n  int64_t oz = iz;\n\n  OpLevelCostEstimator::ConvolutionDimensions conv_dims = {\n      batch, ix, iy, iz, kx, ky, kz, oz, ox, oy, sx, sy, padding};\n  return conv_dims;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n-OpLevelCostEstimator::ConvolutionDimensions\n+StatusOr<OpLevelCostEstimator::ConvolutionDimensions>\n OpLevelCostEstimator::OpDimensionsFromInputs(\n     const TensorShapeProto& original_image_shape, const OpInfo& op_info,\n     bool* found_unknown_shapes) {\n@@ -35,6 +35,11 @@\n   std::vector<int64_t> strides = GetStrides(op_info);\n   int64_t sx = strides[x_index];\n   int64_t sy = strides[y_index];\n+  if (sx == 0 || sy == 0) {\n+    return errors::InvalidArgument(\n+        \"Stride must be > 0 for Height and Width, but got (\", sy, \", \", sx,\n+        \")\");\n+  }\n   const auto padding = GetPadding(op_info);\n \n   int64_t ox = GetOutputSize(ix, kx, sx, padding);",
        "diff_line_info": {
            "deleted_lines": [
                "OpLevelCostEstimator::ConvolutionDimensions"
            ],
            "added_lines": [
                "StatusOr<OpLevelCostEstimator::ConvolutionDimensions>",
                "  if (sx == 0 || sy == 0) {",
                "    return errors::InvalidArgument(",
                "        \"Stride must be > 0 for Height and Width, but got (\", sy, \", \", sx,",
                "        \")\");",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21725",
        "func_name": "tensorflow/OpLevelCostEstimator::PredictAvgPoolGrad",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The estimator for the cost of some convolution operations can be made to execute a division by 0. The function fails to check that the stride argument is strictly positive. Hence, the fix is to add a check for the stride argument to ensure it is valid. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a",
        "commit_title": "Internal change",
        "commit_text": " PiperOrigin-RevId: 411896058",
        "func_before": "Status OpLevelCostEstimator::PredictAvgPoolGrad(const OpContext& op_context,\n                                                NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x's shape: op_info.inputs(0)\n  // y_grad: op_info.inputs(1)\n\n  // Extract x_shape from op_info.inputs(0).value() or op_info.outputs(0).\n  bool shape_found = false;\n  TensorShapeProto x_shape;\n  if (op_info.inputs_size() >= 1 && op_info.inputs(0).has_value()) {\n    const TensorProto& value = op_info.inputs(0).value();\n    shape_found = GetTensorShapeProtoFromTensorProto(value, &x_shape);\n  }\n  if (!shape_found && op_info.outputs_size() > 0) {\n    x_shape = op_info.outputs(0).shape();\n    shape_found = true;\n  }\n  if (!shape_found) {\n    // Set the minimum shape that's feasible.\n    x_shape.Clear();\n    for (int i = 0; i < 4; ++i) {\n      x_shape.add_dim()->set_size(1);\n    }\n    found_unknown_shapes = true;\n  }\n\n  ConvolutionDimensions dims =\n      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes);\n\n  int64_t ops = 0;\n  if (dims.kx <= dims.sx && dims.ky <= dims.sy) {\n    // Non-overlapping window.\n    ops = dims.batch * dims.iz * (dims.ix * dims.iy + dims.ox * dims.oy);\n  } else {\n    // Overlapping window.\n    ops = dims.batch * dims.iz *\n          (dims.ix * dims.iy + dims.ox * dims.oy * (dims.kx * dims.ky + 1));\n  }\n  auto s = PredictDefaultNodeCosts(ops, op_context, &found_unknown_shapes,\n                                   node_costs);\n  node_costs->max_memory = node_costs->num_total_output_bytes();\n  return s;\n}",
        "func": "Status OpLevelCostEstimator::PredictAvgPoolGrad(const OpContext& op_context,\n                                                NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x's shape: op_info.inputs(0)\n  // y_grad: op_info.inputs(1)\n\n  // Extract x_shape from op_info.inputs(0).value() or op_info.outputs(0).\n  bool shape_found = false;\n  TensorShapeProto x_shape;\n  if (op_info.inputs_size() >= 1 && op_info.inputs(0).has_value()) {\n    const TensorProto& value = op_info.inputs(0).value();\n    shape_found = GetTensorShapeProtoFromTensorProto(value, &x_shape);\n  }\n  if (!shape_found && op_info.outputs_size() > 0) {\n    x_shape = op_info.outputs(0).shape();\n    shape_found = true;\n  }\n  if (!shape_found) {\n    // Set the minimum shape that's feasible.\n    x_shape.Clear();\n    for (int i = 0; i < 4; ++i) {\n      x_shape.add_dim()->set_size(1);\n    }\n    found_unknown_shapes = true;\n  }\n\n  TF_ASSIGN_OR_RETURN(\n      ConvolutionDimensions dims,\n      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes));\n\n  int64_t ops = 0;\n  if (dims.kx <= dims.sx && dims.ky <= dims.sy) {\n    // Non-overlapping window.\n    ops = dims.batch * dims.iz * (dims.ix * dims.iy + dims.ox * dims.oy);\n  } else {\n    // Overlapping window.\n    ops = dims.batch * dims.iz *\n          (dims.ix * dims.iy + dims.ox * dims.oy * (dims.kx * dims.ky + 1));\n  }\n  auto s = PredictDefaultNodeCosts(ops, op_context, &found_unknown_shapes,\n                                   node_costs);\n  node_costs->max_memory = node_costs->num_total_output_bytes();\n  return s;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,8 +25,9 @@\n     found_unknown_shapes = true;\n   }\n \n-  ConvolutionDimensions dims =\n-      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(\n+      ConvolutionDimensions dims,\n+      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes));\n \n   int64_t ops = 0;\n   if (dims.kx <= dims.sx && dims.ky <= dims.sy) {",
        "diff_line_info": {
            "deleted_lines": [
                "  ConvolutionDimensions dims =",
                "      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes);"
            ],
            "added_lines": [
                "  TF_ASSIGN_OR_RETURN(",
                "      ConvolutionDimensions dims,",
                "      OpDimensionsFromInputs(x_shape, op_info, &found_unknown_shapes));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21725",
        "func_name": "tensorflow/OpLevelCostEstimator::PredictMaxPool",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The estimator for the cost of some convolution operations can be made to execute a division by 0. The function fails to check that the stride argument is strictly positive. Hence, the fix is to add a check for the stride argument to ensure it is valid. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a",
        "commit_title": "Internal change",
        "commit_text": " PiperOrigin-RevId: 411896058",
        "func_before": "Status OpLevelCostEstimator::PredictMaxPool(const OpContext& op_context,\n                                            NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  ConvolutionDimensions dims = OpDimensionsFromInputs(\n      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n  // kx * ky - 1 comparisons per output (kx * xy > 1)\n  // or 1 copy per output (kx * k1 = 1).\n  int per_output_ops = dims.kx * dims.ky == 1 ? 1 : dims.kx * dims.ky - 1;\n  int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * per_output_ops;\n  node_costs->num_compute_ops = ops;\n\n  int64_t input_size = 0;\n  if (dims.ky >= dims.sy) {\n    input_size = CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  } else {  // dims.ky < dims.sy\n    // Vertical stride is larger than vertical kernel; assuming row-major\n    // format, skip unnecessary rows (or read every kx rows per sy rows, as the\n    // others are not used for output).\n    const auto data_size = DataTypeSize(BaseType(op_info.inputs(0).dtype()));\n    input_size = data_size * dims.batch * dims.ix * dims.ky * dims.oy * dims.iz;\n  }\n  node_costs->num_input_bytes_accessed = {input_size};\n  const int64_t output_size =\n      CalculateOutputSize(op_info, &found_unknown_shapes);\n  node_costs->num_output_bytes_accessed = {output_size};\n  node_costs->max_memory = output_size;\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "func": "Status OpLevelCostEstimator::PredictMaxPool(const OpContext& op_context,\n                                            NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n                                             &found_unknown_shapes));\n  // kx * ky - 1 comparisons per output (kx * xy > 1)\n  // or 1 copy per output (kx * k1 = 1).\n  int per_output_ops = dims.kx * dims.ky == 1 ? 1 : dims.kx * dims.ky - 1;\n  int64_t ops = dims.batch * dims.ox * dims.oy * dims.oz * per_output_ops;\n  node_costs->num_compute_ops = ops;\n\n  int64_t input_size = 0;\n  if (dims.ky >= dims.sy) {\n    input_size = CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  } else {  // dims.ky < dims.sy\n    // Vertical stride is larger than vertical kernel; assuming row-major\n    // format, skip unnecessary rows (or read every kx rows per sy rows, as the\n    // others are not used for output).\n    const auto data_size = DataTypeSize(BaseType(op_info.inputs(0).dtype()));\n    input_size = data_size * dims.batch * dims.ix * dims.ky * dims.oy * dims.iz;\n  }\n  node_costs->num_input_bytes_accessed = {input_size};\n  const int64_t output_size =\n      CalculateOutputSize(op_info, &found_unknown_shapes);\n  node_costs->num_output_bytes_accessed = {output_size};\n  node_costs->max_memory = output_size;\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,9 @@\n   bool found_unknown_shapes = false;\n   const auto& op_info = op_context.op_info;\n   // x: op_info.inputs(0)\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n   // kx * ky - 1 comparisons per output (kx * xy > 1)\n   // or 1 copy per output (kx * k1 = 1).\n   int per_output_ops = dims.kx * dims.ky == 1 ? 1 : dims.kx * dims.ky - 1;",
        "diff_line_info": {
            "deleted_lines": [
                "  ConvolutionDimensions dims = OpDimensionsFromInputs(",
                "      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);"
            ],
            "added_lines": [
                "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
                "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
                "                                             &found_unknown_shapes));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21725",
        "func_name": "tensorflow/OpLevelCostEstimator::PredictFusedBatchNorm",
        "description": "Tensorflow is an Open Source Machine Learning Framework. The estimator for the cost of some convolution operations can be made to execute a division by 0. The function fails to check that the stride argument is strictly positive. Hence, the fix is to add a check for the stride argument to ensure it is valid. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3218043d6d3a019756607643cf65574fbfef5d7a",
        "commit_title": "Internal change",
        "commit_text": " PiperOrigin-RevId: 411896058",
        "func_before": "Status OpLevelCostEstimator::PredictFusedBatchNorm(\n    const OpContext& op_context, NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  // scale: op_info.inputs(1)\n  // offset: op_info.inputs(2)\n  // mean: op_info.inputs(3)  --> only for inference\n  // variance: op_info.inputs(4) --> only for inference\n  ConvolutionDimensions dims = OpDimensionsFromInputs(\n      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n  const bool is_training = IsTraining(op_info);\n\n  int64_t ops = 0;\n  const auto rsqrt_cost = Eigen::internal::functor_traits<\n      Eigen::internal::scalar_rsqrt_op<float>>::Cost;\n  if (is_training) {\n    ops = dims.iz * (dims.batch * dims.ix * dims.iy * 4 + 6 + rsqrt_cost);\n  } else {\n    ops = dims.batch * dims.ix * dims.iy * dims.iz * 2;\n  }\n  node_costs->num_compute_ops = ops;\n\n  const int64_t size_nhwc =\n      CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  const int64_t size_c =\n      CalculateTensorSize(op_info.inputs(1), &found_unknown_shapes);\n  if (is_training) {\n    node_costs->num_input_bytes_accessed = {size_nhwc, size_c, size_c};\n    node_costs->num_output_bytes_accessed = {size_nhwc, size_c, size_c, size_c,\n                                             size_c};\n    // FusedBatchNorm in training mode internally re-reads the input tensor:\n    // one for mean/variance, and the 2nd internal read forthe actual scaling.\n    // Assume small intermediate data such as mean / variance (size_c) can be\n    // cached on-chip.\n    node_costs->internal_read_bytes = size_nhwc;\n  } else {\n    node_costs->num_input_bytes_accessed = {size_nhwc, size_c, size_c, size_c,\n                                            size_c};\n    node_costs->num_output_bytes_accessed = {size_nhwc};\n  }\n  node_costs->max_memory = node_costs->num_total_output_bytes();\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "func": "Status OpLevelCostEstimator::PredictFusedBatchNorm(\n    const OpContext& op_context, NodeCosts* node_costs) const {\n  bool found_unknown_shapes = false;\n  const auto& op_info = op_context.op_info;\n  // x: op_info.inputs(0)\n  // scale: op_info.inputs(1)\n  // offset: op_info.inputs(2)\n  // mean: op_info.inputs(3)  --> only for inference\n  // variance: op_info.inputs(4) --> only for inference\n  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n                                             &found_unknown_shapes));\n  const bool is_training = IsTraining(op_info);\n\n  int64_t ops = 0;\n  const auto rsqrt_cost = Eigen::internal::functor_traits<\n      Eigen::internal::scalar_rsqrt_op<float>>::Cost;\n  if (is_training) {\n    ops = dims.iz * (dims.batch * dims.ix * dims.iy * 4 + 6 + rsqrt_cost);\n  } else {\n    ops = dims.batch * dims.ix * dims.iy * dims.iz * 2;\n  }\n  node_costs->num_compute_ops = ops;\n\n  const int64_t size_nhwc =\n      CalculateTensorSize(op_info.inputs(0), &found_unknown_shapes);\n  const int64_t size_c =\n      CalculateTensorSize(op_info.inputs(1), &found_unknown_shapes);\n  if (is_training) {\n    node_costs->num_input_bytes_accessed = {size_nhwc, size_c, size_c};\n    node_costs->num_output_bytes_accessed = {size_nhwc, size_c, size_c, size_c,\n                                             size_c};\n    // FusedBatchNorm in training mode internally re-reads the input tensor:\n    // one for mean/variance, and the 2nd internal read forthe actual scaling.\n    // Assume small intermediate data such as mean / variance (size_c) can be\n    // cached on-chip.\n    node_costs->internal_read_bytes = size_nhwc;\n  } else {\n    node_costs->num_input_bytes_accessed = {size_nhwc, size_c, size_c, size_c,\n                                            size_c};\n    node_costs->num_output_bytes_accessed = {size_nhwc};\n  }\n  node_costs->max_memory = node_costs->num_total_output_bytes();\n\n  if (found_unknown_shapes) {\n    node_costs->inaccurate = true;\n    node_costs->num_nodes_with_unknown_shapes = 1;\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,8 +7,9 @@\n   // offset: op_info.inputs(2)\n   // mean: op_info.inputs(3)  --> only for inference\n   // variance: op_info.inputs(4) --> only for inference\n-  ConvolutionDimensions dims = OpDimensionsFromInputs(\n-      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);\n+  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,\n+                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,\n+                                             &found_unknown_shapes));\n   const bool is_training = IsTraining(op_info);\n \n   int64_t ops = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "  ConvolutionDimensions dims = OpDimensionsFromInputs(",
                "      op_info.inputs(0).shape(), op_info, &found_unknown_shapes);"
            ],
            "added_lines": [
                "  TF_ASSIGN_OR_RETURN(ConvolutionDimensions dims,",
                "                      OpDimensionsFromInputs(op_info.inputs(0).shape(), op_info,",
                "                                             &found_unknown_shapes));"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-21741",
        "func_name": "tensorflow/Prepare",
        "description": "Tensorflow is an Open Source Machine Learning Framework. ### Impact An attacker can craft a TFLite model that would trigger a division by zero in the implementation of depthwise convolutions. The parameters of the convolution can be user controlled and are also used within a division operation to determine the size of the padding that needs to be added before applying the convolution. There is no check before this division that the divisor is strictly positive. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/e5b0eec199c2d03de54fd6a7fd9275692218e2bc",
        "commit_title": "[lite] Add validation check for dilation height/width to be positive integers.",
        "commit_text": " PiperOrigin-RevId: 416429178",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  bool has_bias = NumInputs(node) == 3;\n\n  TF_LITE_ENSURE(context, has_bias || NumInputs(node) == 2);\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kFilterTensor, &filter));\n  const TfLiteTensor* bias = nullptr;\n\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\n\n  const TfLiteType data_type = input->type;\n\n  const TfLiteType filter_type = filter->type;\n  const bool is_hybrid =\n      data_type == kTfLiteFloat32 && filter_type == kTfLiteInt8;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt16);\n  TF_LITE_ENSURE_TYPES_EQ(context, output->type, data_type);\n  if (!is_hybrid) {\n    TF_LITE_ENSURE(context,\n                   filter->type == data_type || data_type == kTfLiteInt16);\n  }\n\n  if (data_type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  // Filter in DepthwiseConv is expected to be [1, H, W, O].\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 0), 1);\n\n  if (has_bias) {\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n    if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else if (data_type == kTfLiteInt16) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, data_type);\n    }\n    TF_LITE_ENSURE_EQ(context, NumDimensions(bias), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 3),\n                      SizeOfDimension(bias, 0));\n  }\n\n  int channels_out = SizeOfDimension(filter, 3);\n  int width = SizeOfDimension(input, 2);\n  int height = SizeOfDimension(input, 1);\n  int filter_width = SizeOfDimension(filter, 2);\n  int filter_height = SizeOfDimension(filter, 1);\n  int batches = SizeOfDimension(input, 0);\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width,\n      params->dilation_height_factor, params->dilation_width_factor, height,\n      width, filter_height, filter_width, padding, &out_height, &out_width);\n\n  // Note that quantized inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training or\n  // calibration.\n  if (data_type != kTfLiteFloat32) {\n    TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                      kTfLiteAffineQuantization);\n    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||\n                             affine_quantization->scale->size == channels_out));\n\n    data->per_channel_output_multiplier.resize(channels_out);\n    data->per_channel_output_shift.resize(channels_out);\n    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(\n        context, input, filter, bias, output, params->activation,\n        &data->output_multiplier, &data->output_shift,\n        &data->output_activation_min, &data->output_activation_max,\n        data->per_channel_output_multiplier.data(),\n        data->per_channel_output_shift.data(), channels_out));\n  }\n\n  if (is_hybrid) {\n    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE_EQ(\n        context, affine_quantization->scale->size,\n        filter->dims->data[affine_quantization->quantized_dimension]);\n\n    int temporaries_count = 0;\n    data->input_quantized_index = temporaries_count;\n    if (data->input_quantized_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_quantized_id));\n    }\n    ++temporaries_count;\n    data->scaling_factors_index = temporaries_count;\n    if (data->scaling_factors_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->scaling_factors_id));\n    }\n    ++temporaries_count;\n    data->input_offset_index = temporaries_count;\n    if (data->input_offset_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_offset_id));\n    }\n    ++temporaries_count;\n\n    TfLiteIntArrayFree(node->temporaries);\n    node->temporaries = TfLiteIntArrayCreate(temporaries_count);\n\n    node->temporaries->data[data->input_quantized_index] =\n        data->input_quantized_id;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->input_quantized_index,\n                                  &input_quantized));\n    input_quantized->type = kTfLiteInt8;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n    node->temporaries->data[data->scaling_factors_index] =\n        data->scaling_factors_id;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n                                  &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    const int batch_size = SizeOfDimension(input, 0);\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n    node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n    TfLiteTensor* input_offsets;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, data->input_offset_index,\n                                       &input_offsets));\n    input_offsets->type = kTfLiteInt32;\n    input_offsets->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n      TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n      input_offsets_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                       input_offsets_size));\n    }\n  }\n\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(4);\n  outputSize->data[0] = batches;\n  outputSize->data[1] = out_height;\n  outputSize->data[2] = out_width;\n  outputSize->data[3] = channels_out;\n  return context->ResizeTensor(context, output, outputSize);\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthwiseConvParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  bool has_bias = NumInputs(node) == 3;\n\n  TF_LITE_ENSURE(context, has_bias || NumInputs(node) == 2);\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kFilterTensor, &filter));\n  const TfLiteTensor* bias = nullptr;\n\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\n  TF_LITE_ENSURE(context, params->dilation_height_factor > 0);\n  TF_LITE_ENSURE(context, params->dilation_width_factor > 0);\n\n  const TfLiteType data_type = input->type;\n\n  const TfLiteType filter_type = filter->type;\n  const bool is_hybrid =\n      data_type == kTfLiteFloat32 && filter_type == kTfLiteInt8;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt16);\n  TF_LITE_ENSURE_TYPES_EQ(context, output->type, data_type);\n  if (!is_hybrid) {\n    TF_LITE_ENSURE(context,\n                   filter->type == data_type || data_type == kTfLiteInt16);\n  }\n\n  if (data_type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  // Filter in DepthwiseConv is expected to be [1, H, W, O].\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 0), 1);\n\n  if (has_bias) {\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kBiasTensor, &bias));\n    if (data_type == kTfLiteUInt8 || data_type == kTfLiteInt8) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else if (data_type == kTfLiteInt16) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, data_type);\n    }\n    TF_LITE_ENSURE_EQ(context, NumDimensions(bias), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(filter, 3),\n                      SizeOfDimension(bias, 0));\n  }\n\n  int channels_out = SizeOfDimension(filter, 3);\n  int width = SizeOfDimension(input, 2);\n  int height = SizeOfDimension(input, 1);\n  int filter_width = SizeOfDimension(filter, 2);\n  int filter_height = SizeOfDimension(filter, 1);\n  int batches = SizeOfDimension(input, 0);\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width,\n      params->dilation_height_factor, params->dilation_width_factor, height,\n      width, filter_height, filter_width, padding, &out_height, &out_width);\n\n  // Note that quantized inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training or\n  // calibration.\n  if (data_type != kTfLiteFloat32) {\n    TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                      kTfLiteAffineQuantization);\n    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||\n                             affine_quantization->scale->size == channels_out));\n\n    data->per_channel_output_multiplier.resize(channels_out);\n    data->per_channel_output_shift.resize(channels_out);\n    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(\n        context, input, filter, bias, output, params->activation,\n        &data->output_multiplier, &data->output_shift,\n        &data->output_activation_min, &data->output_activation_max,\n        data->per_channel_output_multiplier.data(),\n        data->per_channel_output_shift.data(), channels_out));\n  }\n\n  if (is_hybrid) {\n    TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE_EQ(\n        context, affine_quantization->scale->size,\n        filter->dims->data[affine_quantization->quantized_dimension]);\n\n    int temporaries_count = 0;\n    data->input_quantized_index = temporaries_count;\n    if (data->input_quantized_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_quantized_id));\n    }\n    ++temporaries_count;\n    data->scaling_factors_index = temporaries_count;\n    if (data->scaling_factors_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->scaling_factors_id));\n    }\n    ++temporaries_count;\n    data->input_offset_index = temporaries_count;\n    if (data->input_offset_id == kTensorNotAllocated) {\n      TF_LITE_ENSURE_OK(\n          context, context->AddTensors(context, 1, &data->input_offset_id));\n    }\n    ++temporaries_count;\n\n    TfLiteIntArrayFree(node->temporaries);\n    node->temporaries = TfLiteIntArrayCreate(temporaries_count);\n\n    node->temporaries->data[data->input_quantized_index] =\n        data->input_quantized_id;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->input_quantized_index,\n                                  &input_quantized));\n    input_quantized->type = kTfLiteInt8;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n    node->temporaries->data[data->scaling_factors_index] =\n        data->scaling_factors_id;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n                                  &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    const int batch_size = SizeOfDimension(input, 0);\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n    node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n    TfLiteTensor* input_offsets;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, data->input_offset_index,\n                                       &input_offsets));\n    input_offsets->type = kTfLiteInt32;\n    input_offsets->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n      TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n      input_offsets_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                       input_offsets_size));\n    }\n  }\n\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(4);\n  outputSize->data[0] = batches;\n  outputSize->data[1] = out_height;\n  outputSize->data[2] = out_width;\n  outputSize->data[3] = channels_out;\n  return context->ResizeTensor(context, output, outputSize);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,6 +20,8 @@\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 4);\n+  TF_LITE_ENSURE(context, params->dilation_height_factor > 0);\n+  TF_LITE_ENSURE(context, params->dilation_width_factor > 0);\n \n   const TfLiteType data_type = input->type;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, params->dilation_height_factor > 0);",
                "  TF_LITE_ENSURE(context, params->dilation_width_factor > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-23557",
        "func_name": "tensorflow/BiasAndClamp",
        "description": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would trigger a division by zero in `BiasAndClamp` implementation. There is no check that the `bias_size` is non zero. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8c6f391a2282684a25cbfec7687bd5d35261a209",
        "commit_title": "[lite] Add check for bias_size is zero to avoid division by zero. This shouldn't happen for properly converted models. Just safety check",
        "commit_text": " PiperOrigin-RevId: 416383645",
        "func_before": "inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n  // this with the Eigen one-liner:\n  //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n  // This turned out to severely regress performance: +4ms (i.e. 8%) on\n  // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now.\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n#ifdef USE_NEON\n  float* array_ptr = array_data;\n  float* array_end_ptr = array_ptr + array_size;\n  const auto clamp_min_vec = vdupq_n_f32(clamp_min);\n  const auto clamp_max_vec = vdupq_n_f32(clamp_max);\n  for (; array_ptr != array_end_ptr; array_ptr += bias_size) {\n    int i = 0;\n    for (; i <= bias_size - 16; i += 16) {\n      auto b0 = vld1q_f32(bias_data + i);\n      auto b1 = vld1q_f32(bias_data + i + 4);\n      auto b2 = vld1q_f32(bias_data + i + 8);\n      auto b3 = vld1q_f32(bias_data + i + 12);\n      auto a0 = vld1q_f32(array_ptr + i);\n      auto a1 = vld1q_f32(array_ptr + i + 4);\n      auto a2 = vld1q_f32(array_ptr + i + 8);\n      auto a3 = vld1q_f32(array_ptr + i + 12);\n      auto x0 = vaddq_f32(a0, b0);\n      auto x1 = vaddq_f32(a1, b1);\n      auto x2 = vaddq_f32(a2, b2);\n      auto x3 = vaddq_f32(a3, b3);\n      x0 = vmaxq_f32(clamp_min_vec, x0);\n      x1 = vmaxq_f32(clamp_min_vec, x1);\n      x2 = vmaxq_f32(clamp_min_vec, x2);\n      x3 = vmaxq_f32(clamp_min_vec, x3);\n      x0 = vminq_f32(clamp_max_vec, x0);\n      x1 = vminq_f32(clamp_max_vec, x1);\n      x2 = vminq_f32(clamp_max_vec, x2);\n      x3 = vminq_f32(clamp_max_vec, x3);\n      vst1q_f32(array_ptr + i, x0);\n      vst1q_f32(array_ptr + i + 4, x1);\n      vst1q_f32(array_ptr + i + 8, x2);\n      vst1q_f32(array_ptr + i + 12, x3);\n    }\n    for (; i <= bias_size - 4; i += 4) {\n      auto b = vld1q_f32(bias_data + i);\n      auto a = vld1q_f32(array_ptr + i);\n      auto x = vaddq_f32(a, b);\n      x = vmaxq_f32(clamp_min_vec, x);\n      x = vminq_f32(clamp_max_vec, x);\n      vst1q_f32(array_ptr + i, x);\n    }\n    for (; i < bias_size; i++) {\n      array_ptr[i] = ActivationFunctionWithMinMax(array_ptr[i] + bias_data[i],\n                                                  clamp_min, clamp_max);\n    }\n  }\n#else  // not NEON\n  for (int array_offset = 0; array_offset < array_size;\n       array_offset += bias_size) {\n    for (int i = 0; i < bias_size; i++) {\n      array_data[array_offset + i] = ActivationFunctionWithMinMax(\n          array_data[array_offset + i] + bias_data[i], clamp_min, clamp_max);\n    }\n  }\n#endif\n}",
        "func": "inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  if (bias_size == 0) return;\n  // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n  // this with the Eigen one-liner:\n  //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n  // This turned out to severely regress performance: +4ms (i.e. 8%) on\n  // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now.\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n#ifdef USE_NEON\n  float* array_ptr = array_data;\n  float* array_end_ptr = array_ptr + array_size;\n  const auto clamp_min_vec = vdupq_n_f32(clamp_min);\n  const auto clamp_max_vec = vdupq_n_f32(clamp_max);\n  for (; array_ptr != array_end_ptr; array_ptr += bias_size) {\n    int i = 0;\n    for (; i <= bias_size - 16; i += 16) {\n      auto b0 = vld1q_f32(bias_data + i);\n      auto b1 = vld1q_f32(bias_data + i + 4);\n      auto b2 = vld1q_f32(bias_data + i + 8);\n      auto b3 = vld1q_f32(bias_data + i + 12);\n      auto a0 = vld1q_f32(array_ptr + i);\n      auto a1 = vld1q_f32(array_ptr + i + 4);\n      auto a2 = vld1q_f32(array_ptr + i + 8);\n      auto a3 = vld1q_f32(array_ptr + i + 12);\n      auto x0 = vaddq_f32(a0, b0);\n      auto x1 = vaddq_f32(a1, b1);\n      auto x2 = vaddq_f32(a2, b2);\n      auto x3 = vaddq_f32(a3, b3);\n      x0 = vmaxq_f32(clamp_min_vec, x0);\n      x1 = vmaxq_f32(clamp_min_vec, x1);\n      x2 = vmaxq_f32(clamp_min_vec, x2);\n      x3 = vmaxq_f32(clamp_min_vec, x3);\n      x0 = vminq_f32(clamp_max_vec, x0);\n      x1 = vminq_f32(clamp_max_vec, x1);\n      x2 = vminq_f32(clamp_max_vec, x2);\n      x3 = vminq_f32(clamp_max_vec, x3);\n      vst1q_f32(array_ptr + i, x0);\n      vst1q_f32(array_ptr + i + 4, x1);\n      vst1q_f32(array_ptr + i + 8, x2);\n      vst1q_f32(array_ptr + i + 12, x3);\n    }\n    for (; i <= bias_size - 4; i += 4) {\n      auto b = vld1q_f32(bias_data + i);\n      auto a = vld1q_f32(array_ptr + i);\n      auto x = vaddq_f32(a, b);\n      x = vmaxq_f32(clamp_min_vec, x);\n      x = vminq_f32(clamp_max_vec, x);\n      vst1q_f32(array_ptr + i, x);\n    }\n    for (; i < bias_size; i++) {\n      array_ptr[i] = ActivationFunctionWithMinMax(array_ptr[i] + bias_data[i],\n                                                  clamp_min, clamp_max);\n    }\n  }\n#else  // not NEON\n  for (int array_offset = 0; array_offset < array_size;\n       array_offset += bias_size) {\n    for (int i = 0; i < bias_size; i++) {\n      array_data[array_offset + i] = ActivationFunctionWithMinMax(\n          array_data[array_offset + i] + bias_data[i], clamp_min, clamp_max);\n    }\n  }\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                          const float* bias_data, int array_size,\n                          float* array_data) {\n+  if (bias_size == 0) return;\n   // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n   // this with the Eigen one-liner:\n   //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (bias_size == 0) return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27790",
        "func_name": "upx/PackLinuxElf64::invert_pt_dynamic",
        "description": "A floating point exception issue was discovered in UPX in PackLinuxElf64::invert_pt_dynamic() function of p_lx_elf.cpp file. An attacker with a crafted input file could trigger this issue that could cause a crash leading to a denial of service. The highest impact is to Availability.",
        "git_url": "https://github.com/upx/upx/commit/eb90eab6325d009004ffb155e3e33f22d4d3ca26",
        "commit_title": "Detect bogus DT_SYMENT.",
        "commit_text": " https://github.com/upx/upx/issues/331 \tmodified:   p_lx_elf.cpp",
        "func_before": "void\nPackLinuxElf64::invert_pt_dynamic(Elf64_Dyn const *dynp)\n{\n    if (dt_table[Elf64_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf64_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 1+ 0;\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        upx_uint64_t const d_tag = get_te64(&dynp->d_tag);\n        if (d_tag>>32) { // outrageous\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf64_Dyn[%d].d_tag %#lx\", -1+ ndx, (long unsigned)d_tag);\n            throwCantPack(msg);\n        }\n        if (d_tag < DT_NUM) {\n            if (Elf64_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te64(&dynp->d_val)\n               != get_te64(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    (unsigned)d_tag, -1+ dt_table[d_tag], -1+ ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = ndx;\n        }\n        if (Elf64_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf64_Dyn::DT_INIT])          upx_dt_init = Elf64_Dyn::DT_INIT;\n    else if (dt_table[Elf64_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf64_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf64_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf64_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf64_Dyn::DT_STRSZ];\n    if (z_str) {\n        strtab_end = get_te64(&dynp0[-1+ z_str].d_val);\n        if ((u64_t)file_size <= strtab_end) { // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_STRSZ %#x\", strtab_end);\n            throwCantPack(msg);\n        }\n    }\n    // DT_SYMTAB has no designated length.\n    // End it when next area else starts; often DT_STRTAB.  (FIXME)\n    unsigned const x_sym = dt_table[Elf64_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf64_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        upx_uint64_t const v_str = get_te64(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf64_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf64_Sym)\n            : get_te64(&dynp0[-1+ z_sym].d_val);\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf64_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!nbucket\n        || (nbucket>>31) || (file_size/sizeof(unsigned)) <= (2*nbucket)  // FIXME: weak\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < (sizeof(unsigned)*2  // headers\n                + sizeof(*buckets)*nbucket  // buckets\n                + sizeof(*chains) *nbucket  // chains\n           ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n      //unsigned     const *const gashend = &hasharr[n_bucket];  // minimum\n\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        if (!n_bucket || !n_bitmask\n        || (-1+ n_bitmask) & n_bitmask  // not a power of 2\n        || 8*sizeof(upx_uint64_t) <= gnu_shift  // shifted result always == 0\n        || (n_bucket>>30)  // fie on fuzzers\n        || (n_bitmask>>30)\n        || (file_size/sizeof(unsigned)) <= ((sizeof(*bitmask)/sizeof(unsigned))*n_bitmask + 2*n_bucket)  // FIXME: weak\n        // FIXME: next test does work for Android?\n        || ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*n_bucket  // hasharr\n            ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#lx\",\n                n_bucket, n_bitmask, (long unsigned)(v_sym - v_gsh));\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}",
        "func": "void\nPackLinuxElf64::invert_pt_dynamic(Elf64_Dyn const *dynp)\n{\n    if (dt_table[Elf64_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf64_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 1+ 0;\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        upx_uint64_t const d_tag = get_te64(&dynp->d_tag);\n        if (d_tag>>32) { // outrageous\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf64_Dyn[%d].d_tag %#lx\", -1+ ndx, (long unsigned)d_tag);\n            throwCantPack(msg);\n        }\n        if (d_tag < DT_NUM) {\n            if (Elf64_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te64(&dynp->d_val)\n               != get_te64(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    (unsigned)d_tag, -1+ dt_table[d_tag], -1+ ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = ndx;\n        }\n        if (Elf64_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf64_Dyn::DT_INIT])          upx_dt_init = Elf64_Dyn::DT_INIT;\n    else if (dt_table[Elf64_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf64_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf64_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf64_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf64_Dyn::DT_STRSZ];\n    if (z_str) {\n        strtab_end = get_te64(&dynp0[-1+ z_str].d_val);\n        if ((u64_t)file_size <= strtab_end) { // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_STRSZ %#x\", strtab_end);\n            throwCantPack(msg);\n        }\n    }\n    // DT_SYMTAB has no designated length.\n    // End it when next area else starts; often DT_STRTAB.  (FIXME)\n    unsigned const x_sym = dt_table[Elf64_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf64_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        upx_uint64_t const v_str = get_te64(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf64_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf64_Sym)\n            : get_te64(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf64_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf64_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!nbucket\n        || (nbucket>>31) || (file_size/sizeof(unsigned)) <= (2*nbucket)  // FIXME: weak\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < (sizeof(unsigned)*2  // headers\n                + sizeof(*buckets)*nbucket  // buckets\n                + sizeof(*chains) *nbucket  // chains\n           ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n      //unsigned     const *const gashend = &hasharr[n_bucket];  // minimum\n\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        if (!n_bucket || !n_bitmask\n        || (-1+ n_bitmask) & n_bitmask  // not a power of 2\n        || 8*sizeof(upx_uint64_t) <= gnu_shift  // shifted result always == 0\n        || (n_bucket>>30)  // fie on fuzzers\n        || (n_bitmask>>30)\n        || (file_size/sizeof(unsigned)) <= ((sizeof(*bitmask)/sizeof(unsigned))*n_bitmask + 2*n_bucket)  // FIXME: weak\n        // FIXME: next test does work for Android?\n        || ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*n_bucket  // hasharr\n            ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#lx\",\n                n_bucket, n_bitmask, (long unsigned)(v_sym - v_gsh));\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,8 +54,16 @@\n         unsigned const  z_sym = dt_table[Elf64_Dyn::DT_SYMENT];\n         unsigned const sz_sym = !z_sym ? sizeof(Elf64_Sym)\n             : get_te64(&dynp0[-1+ z_sym].d_val);\n+        if (sz_sym < sizeof(Elf64_Sym)) {\n+            char msg[50]; snprintf(msg, sizeof(msg),\n+                \"bad DT_SYMENT %x\", sz_sym);\n+            throwCantPack(msg);\n+        }\n         if (v_sym < v_str) {\n             symnum_end = (v_str - v_sym) / sz_sym;\n+        }\n+        if (symnum_end < 1) {\n+            throwCantPack(\"bad DT_SYMTAB\");\n         }\n     }\n     // DT_HASH often ends at DT_SYMTAB",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (sz_sym < sizeof(Elf64_Sym)) {",
                "            char msg[50]; snprintf(msg, sizeof(msg),",
                "                \"bad DT_SYMENT %x\", sz_sym);",
                "            throwCantPack(msg);",
                "        }",
                "        }",
                "        if (symnum_end < 1) {",
                "            throwCantPack(\"bad DT_SYMTAB\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27790",
        "func_name": "upx/PackLinuxElf32::invert_pt_dynamic",
        "description": "A floating point exception issue was discovered in UPX in PackLinuxElf64::invert_pt_dynamic() function of p_lx_elf.cpp file. An attacker with a crafted input file could trigger this issue that could cause a crash leading to a denial of service. The highest impact is to Availability.",
        "git_url": "https://github.com/upx/upx/commit/eb90eab6325d009004ffb155e3e33f22d4d3ca26",
        "commit_title": "Detect bogus DT_SYMENT.",
        "commit_text": " https://github.com/upx/upx/issues/331 \tmodified:   p_lx_elf.cpp",
        "func_before": "void\nPackLinuxElf32::invert_pt_dynamic(Elf32_Dyn const *dynp)\n{\n    if (dt_table[Elf32_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf32_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 1+ 0;\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        unsigned const d_tag = get_te32(&dynp->d_tag);\n        if (d_tag < DT_NUM) {\n            if (Elf32_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te32(&dynp->d_val)\n               != get_te32(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    d_tag, -1+ dt_table[d_tag], -1+ ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = ndx;\n        }\n        if (Elf32_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf32_Dyn::DT_INIT])          upx_dt_init = Elf32_Dyn::DT_INIT;\n    else if (dt_table[Elf32_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf32_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf32_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf32_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf32_Dyn::DT_STRSZ];\n    if (z_str) {\n        strtab_end = get_te32(&dynp0[-1+ z_str].d_val);\n        if ((u32_t)file_size <= strtab_end) { // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_STRSZ %#x\", strtab_end);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const x_sym = dt_table[Elf32_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf32_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint32_t const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        upx_uint32_t const v_str = get_te32(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf32_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf32_Sym)\n            : get_te32(&dynp0[-1+ z_sym].d_val);\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!nbucket\n        || (nbucket>>31) || (file_size/sizeof(unsigned)) <= (2*nbucket)  // FIXME: weak\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < (sizeof(unsigned)*2  // headers\n                + sizeof(*buckets)*nbucket  // buckets\n                + sizeof(*chains) *nbucket  // chains\n           ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = (unsigned const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n      //unsigned     const *const gashend = &hasharr[n_bucket];  // minimum\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!n_bucket || !n_bitmask\n        || (-1+ n_bitmask) & n_bitmask  // not a power of 2\n        || 8*sizeof(unsigned) <= gnu_shift  // shifted result always == 0\n        || (n_bucket>>30)  // fie on fuzzers\n        || (n_bitmask>>30)\n        || (file_size / sizeof(unsigned)) <= (n_bitmask + 2*n_bucket)  // FIXME: weak\n        // FIXME: next test does work for Android?\n        || ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*n_bucket  // hasharr\n            ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#x\",\n                n_bucket, n_bitmask, v_sym - v_gsh);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}",
        "func": "void\nPackLinuxElf32::invert_pt_dynamic(Elf32_Dyn const *dynp)\n{\n    if (dt_table[Elf32_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf32_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 1+ 0;\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        unsigned const d_tag = get_te32(&dynp->d_tag);\n        if (d_tag < DT_NUM) {\n            if (Elf32_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te32(&dynp->d_val)\n               != get_te32(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    d_tag, -1+ dt_table[d_tag], -1+ ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = ndx;\n        }\n        if (Elf32_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf32_Dyn::DT_INIT])          upx_dt_init = Elf32_Dyn::DT_INIT;\n    else if (dt_table[Elf32_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf32_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf32_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf32_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf32_Dyn::DT_STRSZ];\n    if (z_str) {\n        strtab_end = get_te32(&dynp0[-1+ z_str].d_val);\n        if ((u32_t)file_size <= strtab_end) { // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_STRSZ %#x\", strtab_end);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const x_sym = dt_table[Elf32_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf32_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint32_t const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        upx_uint32_t const v_str = get_te32(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf32_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf32_Sym)\n            : get_te32(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf32_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!nbucket\n        || (nbucket>>31) || (file_size/sizeof(unsigned)) <= (2*nbucket)  // FIXME: weak\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < (sizeof(unsigned)*2  // headers\n                + sizeof(*buckets)*nbucket  // buckets\n                + sizeof(*chains) *nbucket  // chains\n           ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = (unsigned const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n      //unsigned     const *const gashend = &hasharr[n_bucket];  // minimum\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!n_bucket || !n_bitmask\n        || (-1+ n_bitmask) & n_bitmask  // not a power of 2\n        || 8*sizeof(unsigned) <= gnu_shift  // shifted result always == 0\n        || (n_bucket>>30)  // fie on fuzzers\n        || (n_bitmask>>30)\n        || (file_size / sizeof(unsigned)) <= (n_bitmask + 2*n_bucket)  // FIXME: weak\n        // FIXME: next test does work for Android?\n        || ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*n_bucket  // hasharr\n            ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#x\",\n                n_bucket, n_bitmask, v_sym - v_gsh);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -47,8 +47,16 @@\n         unsigned const  z_sym = dt_table[Elf32_Dyn::DT_SYMENT];\n         unsigned const sz_sym = !z_sym ? sizeof(Elf32_Sym)\n             : get_te32(&dynp0[-1+ z_sym].d_val);\n+        if (sz_sym < sizeof(Elf32_Sym)) {\n+            char msg[50]; snprintf(msg, sizeof(msg),\n+                \"bad DT_SYMENT %x\", sz_sym);\n+            throwCantPack(msg);\n+        }\n         if (v_sym < v_str) {\n             symnum_end = (v_str - v_sym) / sz_sym;\n+        }\n+        if (symnum_end < 1) {\n+            throwCantPack(\"bad DT_SYMTAB\");\n         }\n     }\n     // DT_HASH often ends at DT_SYMTAB",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (sz_sym < sizeof(Elf32_Sym)) {",
                "            char msg[50]; snprintf(msg, sizeof(msg),",
                "                \"bad DT_SYMENT %x\", sz_sym);",
                "            throwCantPack(msg);",
                "        }",
                "        }",
                "        if (symnum_end < 1) {",
                "            throwCantPack(\"bad DT_SYMTAB\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27802",
        "func_name": "upx/PackLinuxElf32::elf_lookup",
        "description": "An floating point exception was discovered in the elf_lookup function in p_lx_elf.cpp in UPX 4.0.0 via a crafted Mach-O file.",
        "git_url": "https://github.com/upx/upx/commit/8d1d605b3d8c49bdfe9376454f0196738bed8166",
        "commit_title": "Avoid 0==nbucket",
        "commit_text": " https://github.com/upx/upx/issues/393 \tmodified:   p_lx_elf.cpp",
        "func_before": "Elf32_Sym const *PackLinuxElf32::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        unsigned const m = elf_hash(name) % nbucket;\n        if (!nbucket\n        ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        unsigned si;\n        for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n            char const *const p= get_dynsym_name(si, (unsigned)-1);\n            if (0==strcmp(name, p)) {\n                return &dynsym[si];\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = &gashtab[4];\n        unsigned const *const buckets = &bitmask[n_bitmask];\n        unsigned const *const hasharr = &buckets[n_bucket];\n        if (!n_bucket\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n\n        unsigned const h = gnu_hash(name);\n        unsigned const hbit1 = 037& h;\n        unsigned const hbit2 = 037& (h>>gnu_shift);\n        unsigned const w = get_te32(&bitmask[(n_bitmask -1) & (h>>5)]);\n\n        if (1& (w>>hbit1) & (w>>hbit2)) {\n            unsigned bucket = get_te32(&buckets[h % n_bucket]);\n            if (n_bucket <= bucket) {\n                char msg[80]; snprintf(msg, sizeof(msg),\n                        \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                        n_bucket, h % n_bucket, bucket);\n                throwCantPack(msg);\n            }\n            if (0!=bucket) {\n                Elf32_Sym const *dsp = &dynsym[bucket];\n                unsigned const *hp = &hasharr[bucket - symbias];\n\n                do if (0==((h ^ get_te32(hp))>>1)) {\n                    unsigned st_name = get_te32(&dsp->st_name);\n                    char const *const p = get_str_name(st_name, (unsigned)-1);\n                    if (0==strcmp(name, p)) {\n                        return dsp;\n                    }\n                } while (++dsp,\n                        (char const *)hp < (char const *)&file_image[file_size]\n                    &&  0==(1u& get_te32(hp++)));\n            }\n        }\n    }\n    return 0;\n\n}",
        "func": "Elf32_Sym const *PackLinuxElf32::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        if (!nbucket\n        ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        unsigned const m = elf_hash(name) % nbucket;\n        unsigned si;\n        for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n            char const *const p= get_dynsym_name(si, (unsigned)-1);\n            if (0==strcmp(name, p)) {\n                return &dynsym[si];\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = &gashtab[4];\n        unsigned const *const buckets = &bitmask[n_bitmask];\n        unsigned const *const hasharr = &buckets[n_bucket];\n        if (!n_bucket\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n\n        unsigned const h = gnu_hash(name);\n        unsigned const hbit1 = 037& h;\n        unsigned const hbit2 = 037& (h>>gnu_shift);\n        unsigned const w = get_te32(&bitmask[(n_bitmask -1) & (h>>5)]);\n\n        if (1& (w>>hbit1) & (w>>hbit2)) {\n            unsigned bucket = get_te32(&buckets[h % n_bucket]);\n            if (n_bucket <= bucket) {\n                char msg[80]; snprintf(msg, sizeof(msg),\n                        \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                        n_bucket, h % n_bucket, bucket);\n                throwCantPack(msg);\n            }\n            if (0!=bucket) {\n                Elf32_Sym const *dsp = &dynsym[bucket];\n                unsigned const *hp = &hasharr[bucket - symbias];\n\n                do if (0==((h ^ get_te32(hp))>>1)) {\n                    unsigned st_name = get_te32(&dsp->st_name);\n                    char const *const p = get_str_name(st_name, (unsigned)-1);\n                    if (0==strcmp(name, p)) {\n                        return dsp;\n                    }\n                } while (++dsp,\n                        (char const *)hp < (char const *)&file_image[file_size]\n                    &&  0==(1u& get_te32(hp++)));\n            }\n        }\n    }\n    return 0;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,6 @@\n         unsigned const nbucket = get_te32(&hashtab[0]);\n         unsigned const *const buckets = &hashtab[2];\n         unsigned const *const chains = &buckets[nbucket];\n-        unsigned const m = elf_hash(name) % nbucket;\n         if (!nbucket\n         ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                 <= sizeof(unsigned)*nbucket ) {\n@@ -12,6 +11,7 @@\n                 \"bad nbucket %#x\\n\", nbucket);\n             throwCantPack(msg);\n         }\n+        unsigned const m = elf_hash(name) % nbucket;\n         unsigned si;\n         for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n             char const *const p= get_dynsym_name(si, (unsigned)-1);",
        "diff_line_info": {
            "deleted_lines": [
                "        unsigned const m = elf_hash(name) % nbucket;"
            ],
            "added_lines": [
                "        unsigned const m = elf_hash(name) % nbucket;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27802",
        "func_name": "upx/PackLinuxElf64::elf_lookup",
        "description": "An floating point exception was discovered in the elf_lookup function in p_lx_elf.cpp in UPX 4.0.0 via a crafted Mach-O file.",
        "git_url": "https://github.com/upx/upx/commit/8d1d605b3d8c49bdfe9376454f0196738bed8166",
        "commit_title": "Avoid 0==nbucket",
        "commit_text": " https://github.com/upx/upx/issues/393 \tmodified:   p_lx_elf.cpp",
        "func_before": "Elf64_Sym const *PackLinuxElf64::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        unsigned const m = elf_hash(name) % nbucket;\n        if (!nbucket\n        ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        unsigned si;\n        for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n            char const *const p= get_dynsym_name(si, (unsigned)-1);\n            if (0==strcmp(name, p)) {\n                return &dynsym[si];\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket];\n        if (!n_bucket\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n\n        unsigned const h = gnu_hash(name);\n        unsigned const hbit1 = 077& h;\n        unsigned const hbit2 = 077& (h>>gnu_shift);\n        upx_uint64_t const w = get_te64(&bitmask[(n_bitmask -1) & (h>>6)]);\n\n        if (1& (w>>hbit1) & (w>>hbit2)) {\n            unsigned bucket = get_te32(&buckets[h % n_bucket]);\n            if (n_bucket <= bucket) {\n                char msg[80]; snprintf(msg, sizeof(msg),\n                        \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                        n_bucket, h % n_bucket, bucket);\n                throwCantPack(msg);\n            }\n            if (0!=bucket) {\n                Elf64_Sym const *dsp = &dynsym[bucket];\n                unsigned const *hp = &hasharr[bucket - symbias];\n\n                do if (0==((h ^ get_te32(hp))>>1)) {\n                    unsigned st_name = get_te32(&dsp->st_name);\n                    char const *const p = get_str_name(st_name, (unsigned)-1);\n                    if (0==strcmp(name, p)) {\n                        return dsp;\n                    }\n                } while (++dsp,\n                        (char const *)hp < (char const *)&file_image[file_size]\n                    &&  0==(1u& get_te32(hp++)));\n            }\n        }\n    }\n    return 0;\n\n}",
        "func": "Elf64_Sym const *PackLinuxElf64::elf_lookup(char const *name) const\n{\n    if (hashtab && dynsym && dynstr) {\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket];\n        if (!nbucket\n        ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*nbucket ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad nbucket %#x\\n\", nbucket);\n            throwCantPack(msg);\n        }\n        unsigned const m = elf_hash(name) % nbucket;\n        unsigned si;\n        for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n            char const *const p= get_dynsym_name(si, (unsigned)-1);\n            if (0==strcmp(name, p)) {\n                return &dynsym[si];\n            }\n        }\n    }\n    if (gashtab && dynsym && dynstr) {\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const symbias  = get_te32(&gashtab[1]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket];\n        if (!n_bucket\n        || (void const *)&file_image[file_size] <= (void const *)hasharr) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bucket %#x\\n\", n_bucket);\n            throwCantPack(msg);\n        }\n        if (!n_bitmask\n        || (unsigned)(file_size - ((char const *)bitmask - (char const *)(void const *)file_image))\n                <= sizeof(unsigned)*n_bitmask ) {\n            char msg[80]; snprintf(msg, sizeof(msg),\n                \"bad n_bitmask %#x\\n\", n_bitmask);\n            throwCantPack(msg);\n        }\n\n        unsigned const h = gnu_hash(name);\n        unsigned const hbit1 = 077& h;\n        unsigned const hbit2 = 077& (h>>gnu_shift);\n        upx_uint64_t const w = get_te64(&bitmask[(n_bitmask -1) & (h>>6)]);\n\n        if (1& (w>>hbit1) & (w>>hbit2)) {\n            unsigned bucket = get_te32(&buckets[h % n_bucket]);\n            if (n_bucket <= bucket) {\n                char msg[80]; snprintf(msg, sizeof(msg),\n                        \"bad DT_GNU_HASH n_bucket{%#x} <= buckets[%d]{%#x}\\n\",\n                        n_bucket, h % n_bucket, bucket);\n                throwCantPack(msg);\n            }\n            if (0!=bucket) {\n                Elf64_Sym const *dsp = &dynsym[bucket];\n                unsigned const *hp = &hasharr[bucket - symbias];\n\n                do if (0==((h ^ get_te32(hp))>>1)) {\n                    unsigned st_name = get_te32(&dsp->st_name);\n                    char const *const p = get_str_name(st_name, (unsigned)-1);\n                    if (0==strcmp(name, p)) {\n                        return dsp;\n                    }\n                } while (++dsp,\n                        (char const *)hp < (char const *)&file_image[file_size]\n                    &&  0==(1u& get_te32(hp++)));\n            }\n        }\n    }\n    return 0;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,6 @@\n         unsigned const nbucket = get_te32(&hashtab[0]);\n         unsigned const *const buckets = &hashtab[2];\n         unsigned const *const chains = &buckets[nbucket];\n-        unsigned const m = elf_hash(name) % nbucket;\n         if (!nbucket\n         ||  (unsigned)(file_size - ((char const *)buckets - (char const *)(void const *)file_image))\n                 <= sizeof(unsigned)*nbucket ) {\n@@ -12,6 +11,7 @@\n                 \"bad nbucket %#x\\n\", nbucket);\n             throwCantPack(msg);\n         }\n+        unsigned const m = elf_hash(name) % nbucket;\n         unsigned si;\n         for (si= get_te32(&buckets[m]); 0!=si; si= get_te32(&chains[si])) {\n             char const *const p= get_dynsym_name(si, (unsigned)-1);",
        "diff_line_info": {
            "deleted_lines": [
                "        unsigned const m = elf_hash(name) % nbucket;"
            ],
            "added_lines": [
                "        unsigned const m = elf_hash(name) % nbucket;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-4216",
        "func_name": "ArtifexSoftware/mupdf/initialise_banding",
        "description": "A Floating point exception (division-by-zero) flaw was found in Mupdf for zero width pages in muraster.c. It is fixed in Mupdf-1.20.0-rc1 upstream.",
        "git_url": "https://github.com/ArtifexSoftware/mupdf/commit/22c47acbd52949421f8c7cb46ea1556827d0fcbf",
        "commit_title": "Bug 704834: Fix division by zero for zero width pages in muraster.",
        "commit_text": "",
        "func_before": "static void\ninitialise_banding(fz_context *ctx, render_details *render, int color)\n{\n\tsize_t min_band_mem;\n\tint bpp, h, w, reps;\n\n\trender->colorspace = output_cs;\n\trender->format = output_format;\n#if GREY_FALLBACK != 0\n\tif (color == 0)\n\t{\n\t\tif (render->colorspace == CS_RGB)\n\t\t{\n\t\t\t/* Fallback from PPM to PGM */\n\t\t\trender->colorspace = CS_GRAY;\n\t\t\trender->format = OUT_PGM;\n\t\t}\n\t\telse if (render->colorspace == CS_CMYK)\n\t\t{\n\t\t\trender->colorspace = CS_GRAY;\n\t\t\tif (render->format == OUT_PKM)\n\t\t\t\trender->format = OUT_PBM;\n\t\t\telse\n\t\t\t\trender->format = OUT_PGM;\n\t\t}\n\t}\n#endif\n\n\tswitch (render->colorspace)\n\t{\n\tcase CS_GRAY:\n\t\tbpp = 1;\n\t\tbreak;\n\tcase CS_RGB:\n\t\tbpp = 2;\n\t\tbreak;\n\tdefault:\n\tcase CS_CMYK:\n\t\tbpp = 3;\n\t\tbreak;\n\t}\n\n\tw = render->ibounds.x1 - render->ibounds.x0;\n\tmin_band_mem = (size_t)bpp * w * min_band_height;\n\treps = (int)(max_band_memory / min_band_mem);\n\tif (reps < 1)\n\t\treps = 1;\n\n\t/* Adjust reps to even out the work between threads */\n\tif (render->num_workers > 0)\n\t{\n\t\tint runs, num_bands;\n\t\th = render->ibounds.y1 - render->ibounds.y0;\n\t\tnum_bands = (h + min_band_height - 1) / min_band_height;\n\t\t/* num_bands = number of min_band_height bands */\n\t\truns = (num_bands + reps-1) / reps;\n\t\t/* runs = number of worker runs of reps min_band_height bands */\n\t\truns = ((runs + render->num_workers - 1) / render->num_workers) * render->num_workers;\n\t\t/* runs = number of worker runs rounded up to make use of all our threads */\n\t\treps = (num_bands + runs - 1) / runs;\n\t}\n\n\trender->band_height_multiple = reps;\n\trender->bands_rendered = 0;\n\n\tif (output_format == OUT_PGM || output_format == OUT_PPM)\n\t{\n\t\trender->bander = fz_new_pnm_band_writer(ctx, out);\n\t\trender->n = output_format == OUT_PGM ? 1 : 3;\n\t}\n\telse if (output_format == OUT_PAM)\n\t{\n\t\trender->bander = fz_new_pam_band_writer(ctx, out);\n\t\trender->n = 4;\n\t}\n\telse if (output_format == OUT_PBM)\n\t{\n\t\trender->bander = fz_new_pbm_band_writer(ctx, out);\n\t\trender->n = 1;\n\t}\n\telse if (output_format == OUT_PKM)\n\t{\n\t\trender->bander = fz_new_pkm_band_writer(ctx, out);\n\t\trender->n = 4;\n\t}\n}",
        "func": "static void\ninitialise_banding(fz_context *ctx, render_details *render, int color)\n{\n\tsize_t min_band_mem;\n\tint bpp, h, w, reps;\n\n\trender->colorspace = output_cs;\n\trender->format = output_format;\n#if GREY_FALLBACK != 0\n\tif (color == 0)\n\t{\n\t\tif (render->colorspace == CS_RGB)\n\t\t{\n\t\t\t/* Fallback from PPM to PGM */\n\t\t\trender->colorspace = CS_GRAY;\n\t\t\trender->format = OUT_PGM;\n\t\t}\n\t\telse if (render->colorspace == CS_CMYK)\n\t\t{\n\t\t\trender->colorspace = CS_GRAY;\n\t\t\tif (render->format == OUT_PKM)\n\t\t\t\trender->format = OUT_PBM;\n\t\t\telse\n\t\t\t\trender->format = OUT_PGM;\n\t\t}\n\t}\n#endif\n\n\tswitch (render->colorspace)\n\t{\n\tcase CS_GRAY:\n\t\tbpp = 1;\n\t\tbreak;\n\tcase CS_RGB:\n\t\tbpp = 2;\n\t\tbreak;\n\tdefault:\n\tcase CS_CMYK:\n\t\tbpp = 3;\n\t\tbreak;\n\t}\n\n\tw = render->ibounds.x1 - render->ibounds.x0;\n\tmin_band_mem = (size_t)bpp * w * min_band_height;\n\tif (min_band_mem > 0)\n\t\treps = (int)(max_band_memory / min_band_mem);\n\tif (min_band_mem == 0 || reps < 1)\n\t\treps = 1;\n\n\t/* Adjust reps to even out the work between threads */\n\tif (render->num_workers > 0)\n\t{\n\t\tint runs, num_bands;\n\t\th = render->ibounds.y1 - render->ibounds.y0;\n\t\tnum_bands = (h + min_band_height - 1) / min_band_height;\n\t\t/* num_bands = number of min_band_height bands */\n\t\truns = (num_bands + reps-1) / reps;\n\t\t/* runs = number of worker runs of reps min_band_height bands */\n\t\truns = ((runs + render->num_workers - 1) / render->num_workers) * render->num_workers;\n\t\t/* runs = number of worker runs rounded up to make use of all our threads */\n\t\treps = (num_bands + runs - 1) / runs;\n\t}\n\n\trender->band_height_multiple = reps;\n\trender->bands_rendered = 0;\n\n\tif (output_format == OUT_PGM || output_format == OUT_PPM)\n\t{\n\t\trender->bander = fz_new_pnm_band_writer(ctx, out);\n\t\trender->n = output_format == OUT_PGM ? 1 : 3;\n\t}\n\telse if (output_format == OUT_PAM)\n\t{\n\t\trender->bander = fz_new_pam_band_writer(ctx, out);\n\t\trender->n = 4;\n\t}\n\telse if (output_format == OUT_PBM)\n\t{\n\t\trender->bander = fz_new_pbm_band_writer(ctx, out);\n\t\trender->n = 1;\n\t}\n\telse if (output_format == OUT_PKM)\n\t{\n\t\trender->bander = fz_new_pkm_band_writer(ctx, out);\n\t\trender->n = 4;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,8 +42,9 @@\n \n \tw = render->ibounds.x1 - render->ibounds.x0;\n \tmin_band_mem = (size_t)bpp * w * min_band_height;\n-\treps = (int)(max_band_memory / min_band_mem);\n-\tif (reps < 1)\n+\tif (min_band_mem > 0)\n+\t\treps = (int)(max_band_memory / min_band_mem);\n+\tif (min_band_mem == 0 || reps < 1)\n \t\treps = 1;\n \n \t/* Adjust reps to even out the work between threads */",
        "diff_line_info": {
            "deleted_lines": [
                "\treps = (int)(max_band_memory / min_band_mem);",
                "\tif (reps < 1)"
            ],
            "added_lines": [
                "\tif (min_band_mem > 0)",
                "\t\treps = (int)(max_band_memory / min_band_mem);",
                "\tif (min_band_mem == 0 || reps < 1)"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-3061",
        "func_name": "kernel/git/deller/linux-fbdev/i740fb_check_var",
        "description": "Found Linux Kernel flaw in the i740 driver. The Userspace program could pass any values to the driver through ioctl() interface. The driver doesn't check the value of 'pixclock', so it may cause a divide by zero error.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/deller/linux-fbdev.git/commit/?h=15cf0b82271b1823fb02ab8c377badba614d95d5",
        "commit_title": "The userspace program could pass any values to the driver through",
        "commit_text": "ioctl() interface. If the driver doesn't check the value of 'pixclock', it may cause divide error.  Fix this by checking whether 'pixclock' is zero in the function i740fb_check_var().  The following log reveals it:  divide error: 0000 [#1] PREEMPT SMP KASAN PTI RIP: 0010:i740fb_decode_var drivers/video/fbdev/i740fb.c:444 [inline] RIP: 0010:i740fb_set_par+0x272f/0x3bb0 drivers/video/fbdev/i740fb.c:739 Call Trace:     fb_set_var+0x604/0xeb0 drivers/video/fbdev/core/fbmem.c:1036     do_fb_ioctl+0x234/0x670 drivers/video/fbdev/core/fbmem.c:1112     fb_ioctl+0xdd/0x130 drivers/video/fbdev/core/fbmem.c:1191     vfs_ioctl fs/ioctl.c:51 [inline]     __do_sys_ioctl fs/ioctl.c:874 [inline]  ",
        "func_before": "static int i740fb_check_var(struct fb_var_screeninfo *var, struct fb_info *info)\n{\n\tswitch (var->bits_per_pixel) {\n\tcase 8:\n\t\tvar->red.offset\t= var->green.offset = var->blue.offset = 0;\n\t\tvar->red.length\t= var->green.length = var->blue.length = 8;\n\t\tbreak;\n\tcase 16:\n\t\tswitch (var->green.length) {\n\t\tdefault:\n\t\tcase 5:\n\t\t\tvar->red.offset = 10;\n\t\t\tvar->green.offset = 5;\n\t\t\tvar->blue.offset = 0;\n\t\t\tvar->red.length\t= 5;\n\t\t\tvar->green.length = 5;\n\t\t\tvar->blue.length = 5;\n\t\t\tbreak;\n\t\tcase 6:\n\t\t\tvar->red.offset = 11;\n\t\t\tvar->green.offset = 5;\n\t\t\tvar->blue.offset = 0;\n\t\t\tvar->red.length = var->blue.length = 5;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 24:\n\t\tvar->red.offset = 16;\n\t\tvar->green.offset = 8;\n\t\tvar->blue.offset = 0;\n\t\tvar->red.length\t= var->green.length = var->blue.length = 8;\n\t\tbreak;\n\tcase 32:\n\t\tvar->transp.offset = 24;\n\t\tvar->red.offset = 16;\n\t\tvar->green.offset = 8;\n\t\tvar->blue.offset = 0;\n\t\tvar->transp.length = 8;\n\t\tvar->red.length = var->green.length = var->blue.length = 8;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (var->xres > var->xres_virtual)\n\t\tvar->xres_virtual = var->xres;\n\n\tif (var->yres > var->yres_virtual)\n\t\tvar->yres_virtual = var->yres;\n\n\tif (info->monspecs.hfmax && info->monspecs.vfmax &&\n\t    info->monspecs.dclkmax && fb_validate_mode(var, info) < 0)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "func": "static int i740fb_check_var(struct fb_var_screeninfo *var, struct fb_info *info)\n{\n\tif (!var->pixclock)\n\t\treturn -EINVAL;\n\n\tswitch (var->bits_per_pixel) {\n\tcase 8:\n\t\tvar->red.offset\t= var->green.offset = var->blue.offset = 0;\n\t\tvar->red.length\t= var->green.length = var->blue.length = 8;\n\t\tbreak;\n\tcase 16:\n\t\tswitch (var->green.length) {\n\t\tdefault:\n\t\tcase 5:\n\t\t\tvar->red.offset = 10;\n\t\t\tvar->green.offset = 5;\n\t\t\tvar->blue.offset = 0;\n\t\t\tvar->red.length\t= 5;\n\t\t\tvar->green.length = 5;\n\t\t\tvar->blue.length = 5;\n\t\t\tbreak;\n\t\tcase 6:\n\t\t\tvar->red.offset = 11;\n\t\t\tvar->green.offset = 5;\n\t\t\tvar->blue.offset = 0;\n\t\t\tvar->red.length = var->blue.length = 5;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase 24:\n\t\tvar->red.offset = 16;\n\t\tvar->green.offset = 8;\n\t\tvar->blue.offset = 0;\n\t\tvar->red.length\t= var->green.length = var->blue.length = 8;\n\t\tbreak;\n\tcase 32:\n\t\tvar->transp.offset = 24;\n\t\tvar->red.offset = 16;\n\t\tvar->green.offset = 8;\n\t\tvar->blue.offset = 0;\n\t\tvar->transp.length = 8;\n\t\tvar->red.length = var->green.length = var->blue.length = 8;\n\t\tbreak;\n\tdefault:\n\t\treturn -EINVAL;\n\t}\n\n\tif (var->xres > var->xres_virtual)\n\t\tvar->xres_virtual = var->xres;\n\n\tif (var->yres > var->yres_virtual)\n\t\tvar->yres_virtual = var->yres;\n\n\tif (info->monspecs.hfmax && info->monspecs.vfmax &&\n\t    info->monspecs.dclkmax && fb_validate_mode(var, info) < 0)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n static int i740fb_check_var(struct fb_var_screeninfo *var, struct fb_info *info)\n {\n+\tif (!var->pixclock)\n+\t\treturn -EINVAL;\n+\n \tswitch (var->bits_per_pixel) {\n \tcase 8:\n \t\tvar->red.offset\t= var->green.offset = var->blue.offset = 0;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!var->pixclock)",
                "\t\treturn -EINVAL;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38266",
        "func_name": "DanBloomberg/leptonica/pixBlockconvGrayUnnormalized",
        "description": "An issue in the Leptonica linked library (v1.79.0) allows attackers to cause an arithmetic exception leading to a Denial of Service (DoS) via a crafted JPEG file.",
        "git_url": "https://github.com/DanBloomberg/leptonica/commit/f062b42c0ea8dddebdc6a152fd16152de215d614",
        "commit_title": "Issue 26393: morphapp_fuzzer: Divide-by-zero in blockconvLow",
        "commit_text": "* Removed the code that allowed divide by zero for tiny pix * Ditto for 4 other block convolution functions.",
        "func_before": "PIX *\npixBlockconvGrayUnnormalized(PIX     *pixs,\n                             l_int32  wc,\n                             l_int32  hc)\n{\nl_int32    i, j, w, h, d, wpla, wpld, jmax;\nl_uint32  *linemina, *linemaxa, *lined, *dataa, *datad;\nPIX       *pixsb, *pixacc, *pixd;\n\n    PROCNAME(\"pixBlockconvGrayUnnormalized\");\n\n    if (!pixs)\n        return (PIX *)ERROR_PTR(\"pixs not defined\", procName, NULL);\n    pixGetDimensions(pixs, &w, &h, &d);\n    if (d != 8)\n        return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n    if (wc < 0) wc = 0;\n    if (hc < 0) hc = 0;\n    if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n        wc = L_MIN(wc, (w - 1) / 2);\n        hc = L_MIN(hc, (h - 1) / 2);\n        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n    }\n    if (wc == 0 && hc == 0)   /* no-op */\n        return pixCopy(NULL, pixs);\n\n    if ((pixsb = pixAddMirroredBorder(pixs, wc + 1, wc, hc + 1, hc)) == NULL)\n        return (PIX *)ERROR_PTR(\"pixsb not made\", procName, NULL);\n    pixacc = pixBlockconvAccum(pixsb);\n    pixDestroy(&pixsb);\n    if (!pixacc)\n        return (PIX *)ERROR_PTR(\"pixacc not made\", procName, NULL);\n    if ((pixd = pixCreate(w, h, 32)) == NULL) {\n        pixDestroy(&pixacc);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n\n    wpla = pixGetWpl(pixacc);\n    wpld = pixGetWpl(pixd);\n    datad = pixGetData(pixd);\n    dataa = pixGetData(pixacc);\n    for (i = 0; i < h; i++) {\n        lined = datad + i * wpld;\n        linemina = dataa + i * wpla;\n        linemaxa = dataa + (i + 2 * hc + 1) * wpla;\n        for (j = 0; j < w; j++) {\n            jmax = j + 2 * wc + 1;\n            lined[j] = linemaxa[jmax] - linemaxa[j] -\n                       linemina[jmax] + linemina[j];\n        }\n    }\n\n    pixDestroy(&pixacc);\n    return pixd;\n}",
        "func": "PIX *\npixBlockconvGrayUnnormalized(PIX     *pixs,\n                             l_int32  wc,\n                             l_int32  hc)\n{\nl_int32    i, j, w, h, d, wpla, wpld, jmax;\nl_uint32  *linemina, *linemaxa, *lined, *dataa, *datad;\nPIX       *pixsb, *pixacc, *pixd;\n\n    PROCNAME(\"pixBlockconvGrayUnnormalized\");\n\n    if (!pixs)\n        return (PIX *)ERROR_PTR(\"pixs not defined\", procName, NULL);\n    pixGetDimensions(pixs, &w, &h, &d);\n    if (d != 8)\n        return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n    if (wc <= 0 || hc <= 0)  /* no-op */\n        return pixCopy(NULL, pixs);\n    if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n                procName, w, wc, h, hc);\n        return pixCopy(NULL, pixs);\n    }\n\n    if ((pixsb = pixAddMirroredBorder(pixs, wc + 1, wc, hc + 1, hc)) == NULL)\n        return (PIX *)ERROR_PTR(\"pixsb not made\", procName, NULL);\n    pixacc = pixBlockconvAccum(pixsb);\n    pixDestroy(&pixsb);\n    if (!pixacc)\n        return (PIX *)ERROR_PTR(\"pixacc not made\", procName, NULL);\n    if ((pixd = pixCreate(w, h, 32)) == NULL) {\n        pixDestroy(&pixacc);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n\n    wpla = pixGetWpl(pixacc);\n    wpld = pixGetWpl(pixd);\n    datad = pixGetData(pixd);\n    dataa = pixGetData(pixacc);\n    for (i = 0; i < h; i++) {\n        lined = datad + i * wpld;\n        linemina = dataa + i * wpla;\n        linemaxa = dataa + (i + 2 * hc + 1) * wpla;\n        for (j = 0; j < w; j++) {\n            jmax = j + 2 * wc + 1;\n            lined[j] = linemaxa[jmax] - linemaxa[j] -\n                       linemina[jmax] + linemina[j];\n        }\n    }\n\n    pixDestroy(&pixacc);\n    return pixd;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,16 +14,13 @@\n     pixGetDimensions(pixs, &w, &h, &d);\n     if (d != 8)\n         return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n-    if (wc < 0) wc = 0;\n-    if (hc < 0) hc = 0;\n+    if (wc <= 0 || hc <= 0)  /* no-op */\n+        return pixCopy(NULL, pixs);\n     if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n-        wc = L_MIN(wc, (w - 1) / 2);\n-        hc = L_MIN(hc, (h - 1) / 2);\n-        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n-        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n+        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n+                procName, w, wc, h, hc);\n+        return pixCopy(NULL, pixs);\n     }\n-    if (wc == 0 && hc == 0)   /* no-op */\n-        return pixCopy(NULL, pixs);\n \n     if ((pixsb = pixAddMirroredBorder(pixs, wc + 1, wc, hc + 1, hc)) == NULL)\n         return (PIX *)ERROR_PTR(\"pixsb not made\", procName, NULL);",
        "diff_line_info": {
            "deleted_lines": [
                "    if (wc < 0) wc = 0;",
                "    if (hc < 0) hc = 0;",
                "        wc = L_MIN(wc, (w - 1) / 2);",
                "        hc = L_MIN(hc, (h - 1) / 2);",
                "        L_WARNING(\"kernel too large; reducing!\\n\", procName);",
                "        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);",
                "    if (wc == 0 && hc == 0)   /* no-op */",
                "        return pixCopy(NULL, pixs);"
            ],
            "added_lines": [
                "    if (wc <= 0 || hc <= 0)  /* no-op */",
                "        return pixCopy(NULL, pixs);",
                "        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",",
                "                procName, w, wc, h, hc);",
                "        return pixCopy(NULL, pixs);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38266",
        "func_name": "DanBloomberg/leptonica/pixBlockconvGray",
        "description": "An issue in the Leptonica linked library (v1.79.0) allows attackers to cause an arithmetic exception leading to a Denial of Service (DoS) via a crafted JPEG file.",
        "git_url": "https://github.com/DanBloomberg/leptonica/commit/f062b42c0ea8dddebdc6a152fd16152de215d614",
        "commit_title": "Issue 26393: morphapp_fuzzer: Divide-by-zero in blockconvLow",
        "commit_text": "* Removed the code that allowed divide by zero for tiny pix * Ditto for 4 other block convolution functions.",
        "func_before": "PIX *\npixBlockconvGray(PIX     *pixs,\n                 PIX     *pixacc,\n                 l_int32  wc,\n                 l_int32  hc)\n{\nl_int32    w, h, d, wpl, wpla;\nl_uint32  *datad, *dataa;\nPIX       *pixd, *pixt;\n\n    PROCNAME(\"pixBlockconvGray\");\n\n    if (!pixs)\n        return (PIX *)ERROR_PTR(\"pixs not defined\", procName, NULL);\n    pixGetDimensions(pixs, &w, &h, &d);\n    if (d != 8)\n        return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n    if (wc < 0) wc = 0;\n    if (hc < 0) hc = 0;\n    if (wc == 0 && hc == 0)   /* no-op */\n        return pixCopy(NULL, pixs);\n    if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n        L_WARNING(\"kernel too large; returning a copy\\n\", procName);\n        L_INFO(\"w = %d, wc = %d, h = %d, hc = %d\\n\", procName, w, wc, h, hc);\n        return pixCopy(NULL, pixs);\n    }\n\n    if (pixacc) {\n        if (pixGetDepth(pixacc) == 32) {\n            pixt = pixClone(pixacc);\n        } else {\n            L_WARNING(\"pixacc not 32 bpp; making new one\\n\", procName);\n            if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n                return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n        }\n    } else {\n        if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n            return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n    }\n\n    if ((pixd = pixCreateTemplate(pixs)) == NULL) {\n        pixDestroy(&pixt);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n\n    pixSetPadBits(pixt, 0);\n    wpl = pixGetWpl(pixd);\n    wpla = pixGetWpl(pixt);\n    datad = pixGetData(pixd);\n    dataa = pixGetData(pixt);\n    blockconvLow(datad, w, h, wpl, dataa, wpla, wc, hc);\n\n    pixDestroy(&pixt);\n    return pixd;\n}",
        "func": "PIX *\npixBlockconvGray(PIX     *pixs,\n                 PIX     *pixacc,\n                 l_int32  wc,\n                 l_int32  hc)\n{\nl_int32    w, h, d, wpl, wpla;\nl_uint32  *datad, *dataa;\nPIX       *pixd, *pixt;\n\n    PROCNAME(\"pixBlockconvGray\");\n\n    if (!pixs)\n        return (PIX *)ERROR_PTR(\"pixs not defined\", procName, NULL);\n    pixGetDimensions(pixs, &w, &h, &d);\n    if (d != 8)\n        return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n    if (wc <= 0 || hc <= 0)   /* no-op */\n        return pixCopy(NULL, pixs);\n    if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n                procName, w, wc, h, hc);\n        return pixCopy(NULL, pixs);\n    }\n\n    if (pixacc) {\n        if (pixGetDepth(pixacc) == 32) {\n            pixt = pixClone(pixacc);\n        } else {\n            L_WARNING(\"pixacc not 32 bpp; making new one\\n\", procName);\n            if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n                return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n        }\n    } else {\n        if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n            return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n    }\n\n    if ((pixd = pixCreateTemplate(pixs)) == NULL) {\n        pixDestroy(&pixt);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n\n    pixSetPadBits(pixt, 0);\n    wpl = pixGetWpl(pixd);\n    wpla = pixGetWpl(pixt);\n    datad = pixGetData(pixd);\n    dataa = pixGetData(pixt);\n    blockconvLow(datad, w, h, wpl, dataa, wpla, wc, hc);\n\n    pixDestroy(&pixt);\n    return pixd;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,13 +15,11 @@\n     pixGetDimensions(pixs, &w, &h, &d);\n     if (d != 8)\n         return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n-    if (wc < 0) wc = 0;\n-    if (hc < 0) hc = 0;\n-    if (wc == 0 && hc == 0)   /* no-op */\n+    if (wc <= 0 || hc <= 0)   /* no-op */\n         return pixCopy(NULL, pixs);\n     if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n-        L_WARNING(\"kernel too large; returning a copy\\n\", procName);\n-        L_INFO(\"w = %d, wc = %d, h = %d, hc = %d\\n\", procName, w, wc, h, hc);\n+        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n+                procName, w, wc, h, hc);\n         return pixCopy(NULL, pixs);\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (wc < 0) wc = 0;",
                "    if (hc < 0) hc = 0;",
                "    if (wc == 0 && hc == 0)   /* no-op */",
                "        L_WARNING(\"kernel too large; returning a copy\\n\", procName);",
                "        L_INFO(\"w = %d, wc = %d, h = %d, hc = %d\\n\", procName, w, wc, h, hc);"
            ],
            "added_lines": [
                "    if (wc <= 0 || hc <= 0)   /* no-op */",
                "        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",",
                "                procName, w, wc, h, hc);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38266",
        "func_name": "DanBloomberg/leptonica/pixBlockconvGrayTile",
        "description": "An issue in the Leptonica linked library (v1.79.0) allows attackers to cause an arithmetic exception leading to a Denial of Service (DoS) via a crafted JPEG file.",
        "git_url": "https://github.com/DanBloomberg/leptonica/commit/f062b42c0ea8dddebdc6a152fd16152de215d614",
        "commit_title": "Issue 26393: morphapp_fuzzer: Divide-by-zero in blockconvLow",
        "commit_text": "* Removed the code that allowed divide by zero for tiny pix * Ditto for 4 other block convolution functions.",
        "func_before": "PIX *\npixBlockconvGrayTile(PIX     *pixs,\n                     PIX     *pixacc,\n                     l_int32  wc,\n                     l_int32  hc)\n{\nl_int32    w, h, d, wd, hd, i, j, imin, imax, jmin, jmax, wplt, wpld;\nl_float32  norm;\nl_uint32   val;\nl_uint32  *datat, *datad, *lined, *linemint, *linemaxt;\nPIX       *pixt, *pixd;\n\n    PROCNAME(\"pixBlockconvGrayTile\");\n\n    if (!pixs)\n        return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n    pixGetDimensions(pixs, &w, &h, &d);\n    if (d != 8)\n        return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n    if (wc < 0) wc = 0;\n    if (hc < 0) hc = 0;\n    if (w < 2 * wc + 3 || h < 2 * hc + 3) {\n        wc = L_MAX(0, L_MIN(wc, (w - 3) / 2));\n        hc = L_MAX(0, L_MIN(hc, (h - 3) / 2));\n        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n    }\n    if (wc == 0 && hc == 0)\n        return pixCopy(NULL, pixs);\n    wd = w - 2 * wc;\n    hd = h - 2 * hc;\n\n    if (pixacc) {\n        if (pixGetDepth(pixacc) == 32) {\n            pixt = pixClone(pixacc);\n        } else {\n            L_WARNING(\"pixacc not 32 bpp; making new one\\n\", procName);\n            if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n                return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n        }\n    } else {\n        if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n            return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n    }\n\n    if ((pixd = pixCreateTemplate(pixs)) == NULL) {\n        pixDestroy(&pixt);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n    datat = pixGetData(pixt);\n    wplt = pixGetWpl(pixt);\n    datad = pixGetData(pixd);\n    wpld = pixGetWpl(pixd);\n    norm = 1. / (l_float32)((2 * wc + 1) * (2 * hc + 1));\n\n        /* Do the convolution over the subregion of size (wd - 2, hd - 2),\n         * which exactly corresponds to the size of the subregion that\n         * will be extracted by pixTilingPaintTile().  Note that the\n         * region in which points are computed is not symmetric about\n         * the center of the images; instead the computation in\n         * the accumulator image is shifted up and to the left by 1,\n         * relative to the center, because the 4 accumulator sampling\n         * points are taken at the LL corner of the filter and at 3 other\n         * points that are shifted -wc and -hc to the left and above.  */\n    for (i = hc; i < hc + hd - 2; i++) {\n        imin = L_MAX(i - hc - 1, 0);\n        imax = L_MIN(i + hc, h - 1);\n        lined = datad + i * wpld;\n        linemint = datat + imin * wplt;\n        linemaxt = datat + imax * wplt;\n        for (j = wc; j < wc + wd - 2; j++) {\n            jmin = L_MAX(j - wc - 1, 0);\n            jmax = L_MIN(j + wc, w - 1);\n            val = linemaxt[jmax] - linemaxt[jmin]\n                  + linemint[jmin] - linemint[jmax];\n            val = (l_uint8)(norm * val + 0.5);\n            SET_DATA_BYTE(lined, j, val);\n        }\n    }\n\n    pixDestroy(&pixt);\n    return pixd;\n}",
        "func": "PIX *\npixBlockconvGrayTile(PIX     *pixs,\n                     PIX     *pixacc,\n                     l_int32  wc,\n                     l_int32  hc)\n{\nl_int32    w, h, d, wd, hd, i, j, imin, imax, jmin, jmax, wplt, wpld;\nl_float32  norm;\nl_uint32   val;\nl_uint32  *datat, *datad, *lined, *linemint, *linemaxt;\nPIX       *pixt, *pixd;\n\n    PROCNAME(\"pixBlockconvGrayTile\");\n\n    if (!pixs)\n        return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n    pixGetDimensions(pixs, &w, &h, &d);\n    if (d != 8)\n        return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n    if (wc <= 0 || hc <= 0)  /* no-op */\n        return pixCopy(NULL, pixs);\n    if (w < 2 * wc + 3 || h < 2 * hc + 3) {\n        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n                procName, w, wc, h, hc);\n        return pixCopy(NULL, pixs);\n    }\n    wd = w - 2 * wc;\n    hd = h - 2 * hc;\n\n    if (pixacc) {\n        if (pixGetDepth(pixacc) == 32) {\n            pixt = pixClone(pixacc);\n        } else {\n            L_WARNING(\"pixacc not 32 bpp; making new one\\n\", procName);\n            if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n                return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n        }\n    } else {\n        if ((pixt = pixBlockconvAccum(pixs)) == NULL)\n            return (PIX *)ERROR_PTR(\"pixt not made\", procName, NULL);\n    }\n\n    if ((pixd = pixCreateTemplate(pixs)) == NULL) {\n        pixDestroy(&pixt);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n    datat = pixGetData(pixt);\n    wplt = pixGetWpl(pixt);\n    datad = pixGetData(pixd);\n    wpld = pixGetWpl(pixd);\n    norm = 1. / (l_float32)((2 * wc + 1) * (2 * hc + 1));\n\n        /* Do the convolution over the subregion of size (wd - 2, hd - 2),\n         * which exactly corresponds to the size of the subregion that\n         * will be extracted by pixTilingPaintTile().  Note that the\n         * region in which points are computed is not symmetric about\n         * the center of the images; instead the computation in\n         * the accumulator image is shifted up and to the left by 1,\n         * relative to the center, because the 4 accumulator sampling\n         * points are taken at the LL corner of the filter and at 3 other\n         * points that are shifted -wc and -hc to the left and above.  */\n    for (i = hc; i < hc + hd - 2; i++) {\n        imin = L_MAX(i - hc - 1, 0);\n        imax = L_MIN(i + hc, h - 1);\n        lined = datad + i * wpld;\n        linemint = datat + imin * wplt;\n        linemaxt = datat + imax * wplt;\n        for (j = wc; j < wc + wd - 2; j++) {\n            jmin = L_MAX(j - wc - 1, 0);\n            jmax = L_MIN(j + wc, w - 1);\n            val = linemaxt[jmax] - linemaxt[jmin]\n                  + linemint[jmin] - linemint[jmax];\n            val = (l_uint8)(norm * val + 0.5);\n            SET_DATA_BYTE(lined, j, val);\n        }\n    }\n\n    pixDestroy(&pixt);\n    return pixd;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,16 +17,13 @@\n     pixGetDimensions(pixs, &w, &h, &d);\n     if (d != 8)\n         return (PIX *)ERROR_PTR(\"pixs not 8 bpp\", procName, NULL);\n-    if (wc < 0) wc = 0;\n-    if (hc < 0) hc = 0;\n+    if (wc <= 0 || hc <= 0)  /* no-op */\n+        return pixCopy(NULL, pixs);\n     if (w < 2 * wc + 3 || h < 2 * hc + 3) {\n-        wc = L_MAX(0, L_MIN(wc, (w - 3) / 2));\n-        hc = L_MAX(0, L_MIN(hc, (h - 3) / 2));\n-        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n-        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n+        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n+                procName, w, wc, h, hc);\n+        return pixCopy(NULL, pixs);\n     }\n-    if (wc == 0 && hc == 0)\n-        return pixCopy(NULL, pixs);\n     wd = w - 2 * wc;\n     hd = h - 2 * hc;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (wc < 0) wc = 0;",
                "    if (hc < 0) hc = 0;",
                "        wc = L_MAX(0, L_MIN(wc, (w - 3) / 2));",
                "        hc = L_MAX(0, L_MIN(hc, (h - 3) / 2));",
                "        L_WARNING(\"kernel too large; reducing!\\n\", procName);",
                "        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);",
                "    if (wc == 0 && hc == 0)",
                "        return pixCopy(NULL, pixs);"
            ],
            "added_lines": [
                "    if (wc <= 0 || hc <= 0)  /* no-op */",
                "        return pixCopy(NULL, pixs);",
                "        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",",
                "                procName, w, wc, h, hc);",
                "        return pixCopy(NULL, pixs);"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38266",
        "func_name": "DanBloomberg/leptonica/pixBlockconv",
        "description": "An issue in the Leptonica linked library (v1.79.0) allows attackers to cause an arithmetic exception leading to a Denial of Service (DoS) via a crafted JPEG file.",
        "git_url": "https://github.com/DanBloomberg/leptonica/commit/f062b42c0ea8dddebdc6a152fd16152de215d614",
        "commit_title": "Issue 26393: morphapp_fuzzer: Divide-by-zero in blockconvLow",
        "commit_text": "* Removed the code that allowed divide by zero for tiny pix * Ditto for 4 other block convolution functions.",
        "func_before": "PIX  *\npixBlockconv(PIX     *pix,\n             l_int32  wc,\n             l_int32  hc)\n{\nl_int32  w, h, d;\nPIX     *pixs, *pixd, *pixr, *pixrc, *pixg, *pixgc, *pixb, *pixbc;\n\n    PROCNAME(\"pixBlockconv\");\n\n    if (!pix)\n        return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n    if (wc < 0) wc = 0;\n    if (hc < 0) hc = 0;\n    pixGetDimensions(pix, &w, &h, &d);\n    if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n        wc = L_MIN(wc, (w - 1) / 2);\n        hc = L_MIN(hc, (h - 1) / 2);\n        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n    }\n    if (wc == 0 && hc == 0)   /* no-op */\n        return pixCopy(NULL, pix);\n\n        /* Remove colormap if necessary */\n    if ((d == 2 || d == 4 || d == 8) && pixGetColormap(pix)) {\n        L_WARNING(\"pix has colormap; removing\\n\", procName);\n        pixs = pixRemoveColormap(pix, REMOVE_CMAP_BASED_ON_SRC);\n        d = pixGetDepth(pixs);\n    } else {\n        pixs = pixClone(pix);\n    }\n\n    if (d != 8 && d != 32) {\n        pixDestroy(&pixs);\n        return (PIX *)ERROR_PTR(\"depth not 8 or 32 bpp\", procName, NULL);\n    }\n\n    if (d == 8) {\n        pixd = pixBlockconvGray(pixs, NULL, wc, hc);\n    } else { /* d == 32 */\n        pixr = pixGetRGBComponent(pixs, COLOR_RED);\n        pixrc = pixBlockconvGray(pixr, NULL, wc, hc);\n        pixDestroy(&pixr);\n        pixg = pixGetRGBComponent(pixs, COLOR_GREEN);\n        pixgc = pixBlockconvGray(pixg, NULL, wc, hc);\n        pixDestroy(&pixg);\n        pixb = pixGetRGBComponent(pixs, COLOR_BLUE);\n        pixbc = pixBlockconvGray(pixb, NULL, wc, hc);\n        pixDestroy(&pixb);\n        pixd = pixCreateRGBImage(pixrc, pixgc, pixbc);\n        pixDestroy(&pixrc);\n        pixDestroy(&pixgc);\n        pixDestroy(&pixbc);\n    }\n\n    pixDestroy(&pixs);\n    return pixd;\n}",
        "func": "PIX  *\npixBlockconv(PIX     *pix,\n             l_int32  wc,\n             l_int32  hc)\n{\nl_int32  w, h, d;\nPIX     *pixs, *pixd, *pixr, *pixrc, *pixg, *pixgc, *pixb, *pixbc;\n\n    PROCNAME(\"pixBlockconv\");\n\n    if (!pix)\n        return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n    if (wc <= 0 || hc <= 0)\n        return pixCopy(NULL, pix);\n    pixGetDimensions(pix, &w, &h, &d);\n    if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n                procName, w, wc, h, hc);\n        return pixCopy(NULL, pix);  /* no-op */\n    }\n\n        /* Remove colormap if necessary */\n    if ((d == 2 || d == 4 || d == 8) && pixGetColormap(pix)) {\n        L_WARNING(\"pix has colormap; removing\\n\", procName);\n        pixs = pixRemoveColormap(pix, REMOVE_CMAP_BASED_ON_SRC);\n        d = pixGetDepth(pixs);\n    } else {\n        pixs = pixClone(pix);\n    }\n\n    if (d != 8 && d != 32) {\n        pixDestroy(&pixs);\n        return (PIX *)ERROR_PTR(\"depth not 8 or 32 bpp\", procName, NULL);\n    }\n\n    if (d == 8) {\n        pixd = pixBlockconvGray(pixs, NULL, wc, hc);\n    } else { /* d == 32 */\n        pixr = pixGetRGBComponent(pixs, COLOR_RED);\n        pixrc = pixBlockconvGray(pixr, NULL, wc, hc);\n        pixDestroy(&pixr);\n        pixg = pixGetRGBComponent(pixs, COLOR_GREEN);\n        pixgc = pixBlockconvGray(pixg, NULL, wc, hc);\n        pixDestroy(&pixg);\n        pixb = pixGetRGBComponent(pixs, COLOR_BLUE);\n        pixbc = pixBlockconvGray(pixb, NULL, wc, hc);\n        pixDestroy(&pixb);\n        pixd = pixCreateRGBImage(pixrc, pixgc, pixbc);\n        pixDestroy(&pixrc);\n        pixDestroy(&pixgc);\n        pixDestroy(&pixbc);\n    }\n\n    pixDestroy(&pixs);\n    return pixd;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,17 +10,14 @@\n \n     if (!pix)\n         return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n-    if (wc < 0) wc = 0;\n-    if (hc < 0) hc = 0;\n+    if (wc <= 0 || hc <= 0)\n+        return pixCopy(NULL, pix);\n     pixGetDimensions(pix, &w, &h, &d);\n     if (w < 2 * wc + 1 || h < 2 * hc + 1) {\n-        wc = L_MIN(wc, (w - 1) / 2);\n-        hc = L_MIN(hc, (h - 1) / 2);\n-        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n-        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n+        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n+                procName, w, wc, h, hc);\n+        return pixCopy(NULL, pix);  /* no-op */\n     }\n-    if (wc == 0 && hc == 0)   /* no-op */\n-        return pixCopy(NULL, pix);\n \n         /* Remove colormap if necessary */\n     if ((d == 2 || d == 4 || d == 8) && pixGetColormap(pix)) {",
        "diff_line_info": {
            "deleted_lines": [
                "    if (wc < 0) wc = 0;",
                "    if (hc < 0) hc = 0;",
                "        wc = L_MIN(wc, (w - 1) / 2);",
                "        hc = L_MIN(hc, (h - 1) / 2);",
                "        L_WARNING(\"kernel too large; reducing!\\n\", procName);",
                "        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);",
                "    if (wc == 0 && hc == 0)   /* no-op */",
                "        return pixCopy(NULL, pix);"
            ],
            "added_lines": [
                "    if (wc <= 0 || hc <= 0)",
                "        return pixCopy(NULL, pix);",
                "        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",",
                "                procName, w, wc, h, hc);",
                "        return pixCopy(NULL, pix);  /* no-op */"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-38266",
        "func_name": "DanBloomberg/leptonica/pixBlockconvTiled",
        "description": "An issue in the Leptonica linked library (v1.79.0) allows attackers to cause an arithmetic exception leading to a Denial of Service (DoS) via a crafted JPEG file.",
        "git_url": "https://github.com/DanBloomberg/leptonica/commit/f062b42c0ea8dddebdc6a152fd16152de215d614",
        "commit_title": "Issue 26393: morphapp_fuzzer: Divide-by-zero in blockconvLow",
        "commit_text": "* Removed the code that allowed divide by zero for tiny pix * Ditto for 4 other block convolution functions.",
        "func_before": "PIX *\npixBlockconvTiled(PIX     *pix,\n                  l_int32  wc,\n                  l_int32  hc,\n                  l_int32  nx,\n                  l_int32  ny)\n{\nl_int32     i, j, w, h, d, xrat, yrat;\nPIX        *pixs, *pixd, *pixc, *pixt;\nPIX        *pixr, *pixrc, *pixg, *pixgc, *pixb, *pixbc;\nPIXTILING  *pt;\n\n    PROCNAME(\"pixBlockconvTiled\");\n\n    if (!pix)\n        return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n    if (wc < 0) wc = 0;\n    if (hc < 0) hc = 0;\n    pixGetDimensions(pix, &w, &h, &d);\n    if (w < 2 * wc + 3 || h < 2 * hc + 3) {\n        wc = L_MAX(0, L_MIN(wc, (w - 3) / 2));\n        hc = L_MAX(0, L_MIN(hc, (h - 3) / 2));\n        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n    }\n    if (wc == 0 && hc == 0)   /* no-op */\n        return pixCopy(NULL, pix);\n    if (nx <= 1 && ny <= 1)\n        return pixBlockconv(pix, wc, hc);\n\n        /* Test to see if the tiles are too small.  The required\n         * condition is that the tile dimensions must be at least\n         * (wc + 2) x (hc + 2). */\n    xrat = w / nx;\n    yrat = h / ny;\n    if (xrat < wc + 2) {\n        nx = w / (wc + 2);\n        L_WARNING(\"tile width too small; nx reduced to %d\\n\", procName, nx);\n    }\n    if (yrat < hc + 2) {\n        ny = h / (hc + 2);\n        L_WARNING(\"tile height too small; ny reduced to %d\\n\", procName, ny);\n    }\n\n        /* Remove colormap if necessary */\n    if ((d == 2 || d == 4 || d == 8) && pixGetColormap(pix)) {\n        L_WARNING(\"pix has colormap; removing\\n\", procName);\n        pixs = pixRemoveColormap(pix, REMOVE_CMAP_BASED_ON_SRC);\n        d = pixGetDepth(pixs);\n    } else {\n        pixs = pixClone(pix);\n    }\n\n    if (d != 8 && d != 32) {\n        pixDestroy(&pixs);\n        return (PIX *)ERROR_PTR(\"depth not 8 or 32 bpp\", procName, NULL);\n    }\n\n       /* Note that the overlaps in the width and height that\n        * are added to the tile are (wc + 2) and (hc + 2).\n        * These overlaps are removed by pixTilingPaintTile().\n        * They are larger than the extent of the filter because\n        * although the filter is symmetric with respect to its origin,\n        * the implementation is asymmetric -- see the implementation in\n        * pixBlockconvGrayTile(). */\n    if ((pixd = pixCreateTemplate(pixs)) == NULL) {\n        pixDestroy(&pixs);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n    pt = pixTilingCreate(pixs, nx, ny, 0, 0, wc + 2, hc + 2);\n    for (i = 0; i < ny; i++) {\n        for (j = 0; j < nx; j++) {\n            pixt = pixTilingGetTile(pt, i, j);\n\n                /* Convolve over the tile */\n            if (d == 8) {\n                pixc = pixBlockconvGrayTile(pixt, NULL, wc, hc);\n            } else { /* d == 32 */\n                pixr = pixGetRGBComponent(pixt, COLOR_RED);\n                pixrc = pixBlockconvGrayTile(pixr, NULL, wc, hc);\n                pixDestroy(&pixr);\n                pixg = pixGetRGBComponent(pixt, COLOR_GREEN);\n                pixgc = pixBlockconvGrayTile(pixg, NULL, wc, hc);\n                pixDestroy(&pixg);\n                pixb = pixGetRGBComponent(pixt, COLOR_BLUE);\n                pixbc = pixBlockconvGrayTile(pixb, NULL, wc, hc);\n                pixDestroy(&pixb);\n                pixc = pixCreateRGBImage(pixrc, pixgc, pixbc);\n                pixDestroy(&pixrc);\n                pixDestroy(&pixgc);\n                pixDestroy(&pixbc);\n            }\n\n            pixTilingPaintTile(pixd, i, j, pixc, pt);\n            pixDestroy(&pixt);\n            pixDestroy(&pixc);\n        }\n    }\n\n    pixDestroy(&pixs);\n    pixTilingDestroy(&pt);\n    return pixd;\n}",
        "func": "PIX *\npixBlockconvTiled(PIX     *pix,\n                  l_int32  wc,\n                  l_int32  hc,\n                  l_int32  nx,\n                  l_int32  ny)\n{\nl_int32     i, j, w, h, d, xrat, yrat;\nPIX        *pixs, *pixd, *pixc, *pixt;\nPIX        *pixr, *pixrc, *pixg, *pixgc, *pixb, *pixbc;\nPIXTILING  *pt;\n\n    PROCNAME(\"pixBlockconvTiled\");\n\n    if (!pix)\n        return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n    if (wc <= 0 || hc <= 0)   /* no-op */\n        return pixCopy(NULL, pix);\n    if (nx <= 1 && ny <= 1)\n        return pixBlockconv(pix, wc, hc);\n    pixGetDimensions(pix, &w, &h, &d);\n    if (w < 2 * wc + 3 || h < 2 * hc + 3) {\n        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n                procName, w, wc, h, hc);\n        return pixCopy(NULL, pix);\n    }\n\n        /* Test to see if the tiles are too small.  The required\n         * condition is that the tile dimensions must be at least\n         * (wc + 2) x (hc + 2). */\n    xrat = w / nx;\n    yrat = h / ny;\n    if (xrat < wc + 2) {\n        nx = w / (wc + 2);\n        L_WARNING(\"tile width too small; nx reduced to %d\\n\", procName, nx);\n    }\n    if (yrat < hc + 2) {\n        ny = h / (hc + 2);\n        L_WARNING(\"tile height too small; ny reduced to %d\\n\", procName, ny);\n    }\n\n        /* Remove colormap if necessary */\n    if ((d == 2 || d == 4 || d == 8) && pixGetColormap(pix)) {\n        L_WARNING(\"pix has colormap; removing\\n\", procName);\n        pixs = pixRemoveColormap(pix, REMOVE_CMAP_BASED_ON_SRC);\n        d = pixGetDepth(pixs);\n    } else {\n        pixs = pixClone(pix);\n    }\n\n    if (d != 8 && d != 32) {\n        pixDestroy(&pixs);\n        return (PIX *)ERROR_PTR(\"depth not 8 or 32 bpp\", procName, NULL);\n    }\n\n       /* Note that the overlaps in the width and height that\n        * are added to the tile are (wc + 2) and (hc + 2).\n        * These overlaps are removed by pixTilingPaintTile().\n        * They are larger than the extent of the filter because\n        * although the filter is symmetric with respect to its origin,\n        * the implementation is asymmetric -- see the implementation in\n        * pixBlockconvGrayTile(). */\n    if ((pixd = pixCreateTemplate(pixs)) == NULL) {\n        pixDestroy(&pixs);\n        return (PIX *)ERROR_PTR(\"pixd not made\", procName, NULL);\n    }\n    pt = pixTilingCreate(pixs, nx, ny, 0, 0, wc + 2, hc + 2);\n    for (i = 0; i < ny; i++) {\n        for (j = 0; j < nx; j++) {\n            pixt = pixTilingGetTile(pt, i, j);\n\n                /* Convolve over the tile */\n            if (d == 8) {\n                pixc = pixBlockconvGrayTile(pixt, NULL, wc, hc);\n            } else { /* d == 32 */\n                pixr = pixGetRGBComponent(pixt, COLOR_RED);\n                pixrc = pixBlockconvGrayTile(pixr, NULL, wc, hc);\n                pixDestroy(&pixr);\n                pixg = pixGetRGBComponent(pixt, COLOR_GREEN);\n                pixgc = pixBlockconvGrayTile(pixg, NULL, wc, hc);\n                pixDestroy(&pixg);\n                pixb = pixGetRGBComponent(pixt, COLOR_BLUE);\n                pixbc = pixBlockconvGrayTile(pixb, NULL, wc, hc);\n                pixDestroy(&pixb);\n                pixc = pixCreateRGBImage(pixrc, pixgc, pixbc);\n                pixDestroy(&pixrc);\n                pixDestroy(&pixgc);\n                pixDestroy(&pixbc);\n            }\n\n            pixTilingPaintTile(pixd, i, j, pixc, pt);\n            pixDestroy(&pixt);\n            pixDestroy(&pixc);\n        }\n    }\n\n    pixDestroy(&pixs);\n    pixTilingDestroy(&pt);\n    return pixd;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,19 +14,16 @@\n \n     if (!pix)\n         return (PIX *)ERROR_PTR(\"pix not defined\", procName, NULL);\n-    if (wc < 0) wc = 0;\n-    if (hc < 0) hc = 0;\n-    pixGetDimensions(pix, &w, &h, &d);\n-    if (w < 2 * wc + 3 || h < 2 * hc + 3) {\n-        wc = L_MAX(0, L_MIN(wc, (w - 3) / 2));\n-        hc = L_MAX(0, L_MIN(hc, (h - 3) / 2));\n-        L_WARNING(\"kernel too large; reducing!\\n\", procName);\n-        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);\n-    }\n-    if (wc == 0 && hc == 0)   /* no-op */\n+    if (wc <= 0 || hc <= 0)   /* no-op */\n         return pixCopy(NULL, pix);\n     if (nx <= 1 && ny <= 1)\n         return pixBlockconv(pix, wc, hc);\n+    pixGetDimensions(pix, &w, &h, &d);\n+    if (w < 2 * wc + 3 || h < 2 * hc + 3) {\n+        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",\n+                procName, w, wc, h, hc);\n+        return pixCopy(NULL, pix);\n+    }\n \n         /* Test to see if the tiles are too small.  The required\n          * condition is that the tile dimensions must be at least",
        "diff_line_info": {
            "deleted_lines": [
                "    if (wc < 0) wc = 0;",
                "    if (hc < 0) hc = 0;",
                "    pixGetDimensions(pix, &w, &h, &d);",
                "    if (w < 2 * wc + 3 || h < 2 * hc + 3) {",
                "        wc = L_MAX(0, L_MIN(wc, (w - 3) / 2));",
                "        hc = L_MAX(0, L_MIN(hc, (h - 3) / 2));",
                "        L_WARNING(\"kernel too large; reducing!\\n\", procName);",
                "        L_INFO(\"wc = %d, hc = %d\\n\", procName, wc, hc);",
                "    }",
                "    if (wc == 0 && hc == 0)   /* no-op */"
            ],
            "added_lines": [
                "    if (wc <= 0 || hc <= 0)   /* no-op */",
                "    pixGetDimensions(pix, &w, &h, &d);",
                "    if (w < 2 * wc + 3 || h < 2 * hc + 3) {",
                "        L_ERROR(\"kernel is too large: w = %d, wc = %d, h = %d, hc = %d\\n\",",
                "                procName, w, wc, h, hc);",
                "        return pixCopy(NULL, pix);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-35996",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an open source platform for machine learning. If `Conv2D` is given empty `input` and the `filter` and `padding` sizes are valid, the output is all-zeros. This causes division-by-zero floating point exceptions that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 611d80db29dd7b0cfb755772c69d60ae5bca05f9. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/611d80db29dd7b0cfb755772c69d60ae5bca05f9",
        "commit_title": "Fix conv2d crash when input size is empty.",
        "commit_text": " If the input is empty (so convolution is only applied to padding), and if the filter and padding sizes are still valid, then the output will be all-zeros.  This previously caused a division-by-zero crash in multiple kernels.  PiperOrigin-RevId: 463179650",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Input tensor is of the following dimensions:\n    // [ batch, in_rows, in_cols, in_depth ]\n    const Tensor& input = context->input(0);\n\n    // Input filter is of the following dimensions:\n    // [ filter_rows, filter_cols, in_depth, out_depth]\n    const Tensor& filter = context->input(1);\n\n    Conv2DDimensions dimensions;\n    OP_REQUIRES_OK(context,\n                   ComputeConv2DDimension(params_, input, filter, &dimensions));\n\n    TensorShape out_shape = ShapeFromFormat(\n        params_.data_format, dimensions.batch, dimensions.out_rows,\n        dimensions.out_cols, dimensions.out_depth);\n\n    // Output tensor is of the following dimensions:\n    // [ in_batch, out_rows, out_cols, out_depth ]\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n\n    VLOG(2) << \"Conv2D: in_depth = \" << dimensions.in_depth\n            << \", patch_depth = \" << dimensions.patch_depth\n            << \", input_cols = \" << dimensions.input_cols\n            << \", filter_cols = \" << dimensions.filter_cols\n            << \", input_rows = \" << dimensions.input_rows\n            << \", filter_rows = \" << dimensions.filter_rows\n            << \", stride_rows = \" << dimensions.stride_rows\n            << \", stride_cols = \" << dimensions.stride_cols\n            << \", dilation_rows = \" << dimensions.dilation_rows\n            << \", dilation_cols = \" << dimensions.dilation_cols\n            << \", out_depth = \" << dimensions.out_depth;\n\n    // If there is nothing to compute, return.\n    if (out_shape.num_elements() == 0) {\n      return;\n    }\n\n#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS\n    if (params_.padding != EXPLICIT &&\n        LaunchXsmmConvOp<Device, T>::Run(\n            context, input, filter, dimensions.batch, dimensions.input_rows,\n            dimensions.input_cols, dimensions.in_depth, dimensions.filter_rows,\n            dimensions.filter_cols, dimensions.pad_rows_before,\n            dimensions.pad_cols_before, dimensions.out_rows,\n            dimensions.out_cols, dimensions.out_depth, dimensions.dilation_rows,\n            dimensions.dilation_cols, dimensions.stride_rows,\n            dimensions.stride_cols, output, params_.data_format)) {\n      return;\n    }\n#endif\n\n    if (params_.padding != EXPLICIT &&\n        LaunchDeepConvOp<Device, T>::Run(\n            context, input, filter, dimensions.batch, dimensions.input_rows,\n            dimensions.input_cols, dimensions.in_depth, dimensions.filter_rows,\n            dimensions.filter_cols, dimensions.pad_rows_before,\n            dimensions.pad_cols_before, dimensions.out_rows,\n            dimensions.out_cols, dimensions.out_depth, dimensions.dilation_rows,\n            dimensions.dilation_cols, dimensions.stride_rows,\n            dimensions.stride_cols, output, params_.data_format)) {\n      return;\n    }\n\n    launcher_(context, use_cudnn_, cudnn_use_autotune_, input, filter,\n              dimensions.dilation_rows, dimensions.dilation_cols,\n              dimensions.stride_rows, dimensions.stride_cols, params_.padding,\n              params_.explicit_paddings, output, params_.data_format);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Input tensor is of the following dimensions:\n    // [ batch, in_rows, in_cols, in_depth ]\n    const Tensor& input = context->input(0);\n\n    // Input filter is of the following dimensions:\n    // [ filter_rows, filter_cols, in_depth, out_depth]\n    const Tensor& filter = context->input(1);\n\n    Conv2DDimensions dimensions;\n    OP_REQUIRES_OK(context,\n                   ComputeConv2DDimension(params_, input, filter, &dimensions));\n\n    TensorShape out_shape = ShapeFromFormat(\n        params_.data_format, dimensions.batch, dimensions.out_rows,\n        dimensions.out_cols, dimensions.out_depth);\n\n    // Output tensor is of the following dimensions:\n    // [ in_batch, out_rows, out_cols, out_depth ]\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n\n    VLOG(2) << \"Conv2D: in_depth = \" << dimensions.in_depth\n            << \", patch_depth = \" << dimensions.patch_depth\n            << \", input_cols = \" << dimensions.input_cols\n            << \", filter_cols = \" << dimensions.filter_cols\n            << \", input_rows = \" << dimensions.input_rows\n            << \", filter_rows = \" << dimensions.filter_rows\n            << \", stride_rows = \" << dimensions.stride_rows\n            << \", stride_cols = \" << dimensions.stride_cols\n            << \", dilation_rows = \" << dimensions.dilation_rows\n            << \", dilation_cols = \" << dimensions.dilation_cols\n            << \", out_depth = \" << dimensions.out_depth;\n\n    // If there is nothing to compute, return.\n    if (out_shape.num_elements() == 0) {\n      return;\n    }\n\n    // If the input is empty, result can only be due to padding.\n    if (input.NumElements() == 0) {\n      // Zero-out output and return.\n      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),\n                                           output->template flat<T>());\n\n      return;\n    }\n\n#ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS\n    if (params_.padding != EXPLICIT &&\n        LaunchXsmmConvOp<Device, T>::Run(\n            context, input, filter, dimensions.batch, dimensions.input_rows,\n            dimensions.input_cols, dimensions.in_depth, dimensions.filter_rows,\n            dimensions.filter_cols, dimensions.pad_rows_before,\n            dimensions.pad_cols_before, dimensions.out_rows,\n            dimensions.out_cols, dimensions.out_depth, dimensions.dilation_rows,\n            dimensions.dilation_cols, dimensions.stride_rows,\n            dimensions.stride_cols, output, params_.data_format)) {\n      return;\n    }\n#endif\n\n    if (params_.padding != EXPLICIT &&\n        LaunchDeepConvOp<Device, T>::Run(\n            context, input, filter, dimensions.batch, dimensions.input_rows,\n            dimensions.input_cols, dimensions.in_depth, dimensions.filter_rows,\n            dimensions.filter_cols, dimensions.pad_rows_before,\n            dimensions.pad_cols_before, dimensions.out_rows,\n            dimensions.out_cols, dimensions.out_depth, dimensions.dilation_rows,\n            dimensions.dilation_cols, dimensions.stride_rows,\n            dimensions.stride_cols, output, params_.data_format)) {\n      return;\n    }\n\n    launcher_(context, use_cudnn_, cudnn_use_autotune_, input, filter,\n              dimensions.dilation_rows, dimensions.dilation_cols,\n              dimensions.stride_rows, dimensions.stride_cols, params_.padding,\n              params_.explicit_paddings, output, params_.data_format);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,6 +37,15 @@\n       return;\n     }\n \n+    // If the input is empty, result can only be due to padding.\n+    if (input.NumElements() == 0) {\n+      // Zero-out output and return.\n+      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),\n+                                           output->template flat<T>());\n+\n+      return;\n+    }\n+\n #ifdef TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS\n     if (params_.padding != EXPLICIT &&\n         LaunchXsmmConvOp<Device, T>::Run(",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // If the input is empty, result can only be due to padding.",
                "    if (input.NumElements() == 0) {",
                "      // Zero-out output and return.",
                "      functor::SetZeroFunctor<Device, T>()(context->eigen_device<Device>(),",
                "                                           output->template flat<T>());",
                "",
                "      return;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2017-15025",
        "func_name": "binutils-gdb/decode_line_info",
        "description": "decode_line_info in dwarf2.c in the Binary File Descriptor (BFD) library (aka libbfd), as distributed in GNU Binutils 2.29, allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted ELF file.",
        "git_url": "https://sourceware.org/git/gitweb.cgi?p=binutils-gdb.git;h=d8010d3e75ec7194a4703774090b27486b742d48",
        "commit_title": "",
        "commit_text": "PR22186, divide-by-zero in decode_line_info  \tPR 22186 \t* dwarf2.c (decode_line_info): Fail on lh.line_range of zero \trather than dividing by zero. ",
        "func_before": "static struct line_info_table*\ndecode_line_info (struct comp_unit *unit, struct dwarf2_debug *stash)\n{\n  bfd *abfd = unit->abfd;\n  struct line_info_table* table;\n  bfd_byte *line_ptr;\n  bfd_byte *line_end;\n  struct line_head lh;\n  unsigned int i, bytes_read, offset_size;\n  char *cur_file, *cur_dir;\n  unsigned char op_code, extended_op, adj_opcode;\n  unsigned int exop_len;\n  bfd_size_type amt;\n\n  if (! read_section (abfd, &stash->debug_sections[debug_line],\n\t\t      stash->syms, unit->line_offset,\n\t\t      &stash->dwarf_line_buffer, &stash->dwarf_line_size))\n    return NULL;\n\n  amt = sizeof (struct line_info_table);\n  table = (struct line_info_table *) bfd_alloc (abfd, amt);\n  if (table == NULL)\n    return NULL;\n  table->abfd = abfd;\n  table->comp_dir = unit->comp_dir;\n\n  table->num_files = 0;\n  table->files = NULL;\n\n  table->num_dirs = 0;\n  table->dirs = NULL;\n\n  table->num_sequences = 0;\n  table->sequences = NULL;\n\n  table->lcl_head = NULL;\n\n  if (stash->dwarf_line_size < 16)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Line info section is too small (%Ld)\"),\n\t stash->dwarf_line_size);\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n  line_ptr = stash->dwarf_line_buffer + unit->line_offset;\n  line_end = stash->dwarf_line_buffer + stash->dwarf_line_size;\n\n  /* Read in the prologue.  */\n  lh.total_length = read_4_bytes (abfd, line_ptr, line_end);\n  line_ptr += 4;\n  offset_size = 4;\n  if (lh.total_length == 0xffffffff)\n    {\n      lh.total_length = read_8_bytes (abfd, line_ptr, line_end);\n      line_ptr += 8;\n      offset_size = 8;\n    }\n  else if (lh.total_length == 0 && unit->addr_size == 8)\n    {\n      /* Handle (non-standard) 64-bit DWARF2 formats.  */\n      lh.total_length = read_4_bytes (abfd, line_ptr, line_end);\n      line_ptr += 4;\n      offset_size = 8;\n    }\n\n  if (lh.total_length > (size_t) (line_end - line_ptr))\n    {\n      _bfd_error_handler\n\t/* xgettext: c-format */\n\t(_(\"Dwarf Error: Line info data is bigger (%#Lx)\"\n\t   \" than the space remaining in the section (%#lx)\"),\n\t lh.total_length, (unsigned long) (line_end - line_ptr));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  line_end = line_ptr + lh.total_length;\n\n  lh.version = read_2_bytes (abfd, line_ptr, line_end);\n  if (lh.version < 2 || lh.version > 5)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Unhandled .debug_line version %d.\"), lh.version);\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n  line_ptr += 2;\n\n  if (line_ptr + offset_size + (lh.version >= 5 ? 8 : (lh.version >= 4 ? 6 : 5))\n      >= line_end)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Ran out of room reading prologue\"));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  if (lh.version >= 5)\n    {\n      unsigned int segment_selector_size;\n\n      /* Skip address size.  */\n      read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n\n      segment_selector_size = read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n      if (segment_selector_size != 0)\n\t{\n\t  _bfd_error_handler\n\t    (_(\"Dwarf Error: Line info unsupported segment selector size %u.\"),\n\t     segment_selector_size);\n\t  bfd_set_error (bfd_error_bad_value);\n\t  return NULL;\n\t}\n    }\n\n  if (offset_size == 4)\n    lh.prologue_length = read_4_bytes (abfd, line_ptr, line_end);\n  else\n    lh.prologue_length = read_8_bytes (abfd, line_ptr, line_end);\n  line_ptr += offset_size;\n\n  lh.minimum_instruction_length = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  if (lh.version >= 4)\n    {\n      lh.maximum_ops_per_insn = read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n    }\n  else\n    lh.maximum_ops_per_insn = 1;\n\n  if (lh.maximum_ops_per_insn == 0)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Invalid maximum operations per instruction.\"));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  lh.default_is_stmt = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  lh.line_base = read_1_signed_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  lh.line_range = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  lh.opcode_base = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  if (line_ptr + (lh.opcode_base - 1) >= line_end)\n    {\n      _bfd_error_handler (_(\"Dwarf Error: Ran out of room reading opcodes\"));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  amt = lh.opcode_base * sizeof (unsigned char);\n  lh.standard_opcode_lengths = (unsigned char *) bfd_alloc (abfd, amt);\n\n  lh.standard_opcode_lengths[0] = 1;\n\n  for (i = 1; i < lh.opcode_base; ++i)\n    {\n      lh.standard_opcode_lengths[i] = read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n    }\n\n  if (lh.version >= 5)\n    {\n      /* Read directory table.  */\n      if (!read_formatted_entries (unit, &line_ptr, line_end, table,\n\t\t\t\t   line_info_add_include_dir_stub))\n\tgoto fail;\n\n      /* Read file name table.  */\n      if (!read_formatted_entries (unit, &line_ptr, line_end, table,\n\t\t\t\t   line_info_add_file_name))\n\tgoto fail;\n    }\n  else\n    {\n      /* Read directory table.  */\n      while ((cur_dir = read_string (abfd, line_ptr, line_end, &bytes_read)) != NULL)\n\t{\n\t  line_ptr += bytes_read;\n\n\t  if (!line_info_add_include_dir (table, cur_dir))\n\t    goto fail;\n\t}\n\n      line_ptr += bytes_read;\n\n      /* Read file name table.  */\n      while ((cur_file = read_string (abfd, line_ptr, line_end, &bytes_read)) != NULL)\n\t{\n\t  unsigned int dir, xtime, size;\n\n\t  line_ptr += bytes_read;\n\n\t  dir = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read, FALSE, line_end);\n\t  line_ptr += bytes_read;\n\t  xtime = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read, FALSE, line_end);\n\t  line_ptr += bytes_read;\n\t  size = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read, FALSE, line_end);\n\t  line_ptr += bytes_read;\n\n\t  if (!line_info_add_file_name (table, cur_file, dir, xtime, size))\n\t    goto fail;\n\t}\n\n      line_ptr += bytes_read;\n    }\n\n  /* Read the statement sequences until there's nothing left.  */\n  while (line_ptr < line_end)\n    {\n      /* State machine registers.  */\n      bfd_vma address = 0;\n      unsigned char op_index = 0;\n      char * filename = table->num_files ? concat_filename (table, 1) : NULL;\n      unsigned int line = 1;\n      unsigned int column = 0;\n      unsigned int discriminator = 0;\n      int is_stmt = lh.default_is_stmt;\n      int end_sequence = 0;\n      /* eraxxon@alumni.rice.edu: Against the DWARF2 specs, some\n\t compilers generate address sequences that are wildly out of\n\t order using DW_LNE_set_address (e.g. Intel C++ 6.0 compiler\n\t for ia64-Linux).  Thus, to determine the low and high\n\t address, we must compare on every DW_LNS_copy, etc.  */\n      bfd_vma low_pc  = (bfd_vma) -1;\n      bfd_vma high_pc = 0;\n\n      /* Decode the table.  */\n      while (! end_sequence)\n\t{\n\t  op_code = read_1_byte (abfd, line_ptr, line_end);\n\t  line_ptr += 1;\n\n\t  if (op_code >= lh.opcode_base)\n\t    {\n\t      /* Special operand.  */\n\t      adj_opcode = op_code - lh.opcode_base;\n\t      if (lh.line_range == 0)\n\t\tgoto line_fail;\n\t      if (lh.maximum_ops_per_insn == 1)\n\t\taddress += (adj_opcode / lh.line_range\n\t\t\t    * lh.minimum_instruction_length);\n\t      else\n\t\t{\n\t\t  address += ((op_index + adj_opcode / lh.line_range)\n\t\t\t      / lh.maximum_ops_per_insn\n\t\t\t      * lh.minimum_instruction_length);\n\t\t  op_index = ((op_index + adj_opcode / lh.line_range)\n\t\t\t      % lh.maximum_ops_per_insn);\n\t\t}\n\t      line += lh.line_base + (adj_opcode % lh.line_range);\n\t      /* Append row to matrix using current values.  */\n\t      if (!add_line_info (table, address, op_index, filename,\n\t\t\t\t  line, column, discriminator, 0))\n\t\tgoto line_fail;\n\t      discriminator = 0;\n\t      if (address < low_pc)\n\t\tlow_pc = address;\n\t      if (address > high_pc)\n\t\thigh_pc = address;\n\t    }\n\t  else switch (op_code)\n\t    {\n\t    case DW_LNS_extended_op:\n\t      exop_len = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t\tFALSE, line_end);\n\t      line_ptr += bytes_read;\n\t      extended_op = read_1_byte (abfd, line_ptr, line_end);\n\t      line_ptr += 1;\n\n\t      switch (extended_op)\n\t\t{\n\t\tcase DW_LNE_end_sequence:\n\t\t  end_sequence = 1;\n\t\t  if (!add_line_info (table, address, op_index, filename, line,\n\t\t\t\t      column, discriminator, end_sequence))\n\t\t    goto line_fail;\n\t\t  discriminator = 0;\n\t\t  if (address < low_pc)\n\t\t    low_pc = address;\n\t\t  if (address > high_pc)\n\t\t    high_pc = address;\n\t\t  if (!arange_add (unit, &unit->arange, low_pc, high_pc))\n\t\t    goto line_fail;\n\t\t  break;\n\t\tcase DW_LNE_set_address:\n\t\t  address = read_address (unit, line_ptr, line_end);\n\t\t  op_index = 0;\n\t\t  line_ptr += unit->addr_size;\n\t\t  break;\n\t\tcase DW_LNE_define_file:\n\t\t  cur_file = read_string (abfd, line_ptr, line_end, &bytes_read);\n\t\t  line_ptr += bytes_read;\n\t\t  if ((table->num_files % FILE_ALLOC_CHUNK) == 0)\n\t\t    {\n\t\t      struct fileinfo *tmp;\n\n\t\t      amt = table->num_files + FILE_ALLOC_CHUNK;\n\t\t      amt *= sizeof (struct fileinfo);\n\t\t      tmp = (struct fileinfo *) bfd_realloc (table->files, amt);\n\t\t      if (tmp == NULL)\n\t\t\tgoto line_fail;\n\t\t      table->files = tmp;\n\t\t    }\n\t\t  table->files[table->num_files].name = cur_file;\n\t\t  table->files[table->num_files].dir =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  table->files[table->num_files].time =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  table->files[table->num_files].size =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  table->num_files++;\n\t\t  break;\n\t\tcase DW_LNE_set_discriminator:\n\t\t  discriminator =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  break;\n\t\tcase DW_LNE_HP_source_file_correlation:\n\t\t  line_ptr += exop_len - 1;\n\t\t  break;\n\t\tdefault:\n\t\t  _bfd_error_handler\n\t\t    (_(\"Dwarf Error: mangled line number section.\"));\n\t\t  bfd_set_error (bfd_error_bad_value);\n\t\tline_fail:\n\t\t  if (filename != NULL)\n\t\t    free (filename);\n\t\t  goto fail;\n\t\t}\n\t      break;\n\t    case DW_LNS_copy:\n\t      if (!add_line_info (table, address, op_index,\n\t\t\t\t  filename, line, column, discriminator, 0))\n\t\tgoto line_fail;\n\t      discriminator = 0;\n\t      if (address < low_pc)\n\t\tlow_pc = address;\n\t      if (address > high_pc)\n\t\thigh_pc = address;\n\t      break;\n\t    case DW_LNS_advance_pc:\n\t      if (lh.maximum_ops_per_insn == 1)\n\t\taddress += (lh.minimum_instruction_length\n\t\t\t    * _bfd_safe_read_leb128 (abfd, line_ptr,\n\t\t\t\t\t\t     &bytes_read,\n\t\t\t\t\t\t     FALSE, line_end));\n\t      else\n\t\t{\n\t\t  bfd_vma adjust = _bfd_safe_read_leb128 (abfd, line_ptr,\n\t\t\t\t\t\t\t  &bytes_read,\n\t\t\t\t\t\t\t  FALSE, line_end);\n\t\t  address = ((op_index + adjust) / lh.maximum_ops_per_insn\n\t\t\t     * lh.minimum_instruction_length);\n\t\t  op_index = (op_index + adjust) % lh.maximum_ops_per_insn;\n\t\t}\n\t      line_ptr += bytes_read;\n\t      break;\n\t    case DW_LNS_advance_line:\n\t      line += _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t     TRUE, line_end);\n\t      line_ptr += bytes_read;\n\t      break;\n\t    case DW_LNS_set_file:\n\t      {\n\t\tunsigned int file;\n\n\t\t/* The file and directory tables are 0\n\t\t   based, the references are 1 based.  */\n\t\tfile = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t      FALSE, line_end);\n\t\tline_ptr += bytes_read;\n\t\tif (filename)\n\t\t  free (filename);\n\t\tfilename = concat_filename (table, file);\n\t\tbreak;\n\t      }\n\t    case DW_LNS_set_column:\n\t      column = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t      FALSE, line_end);\n\t      line_ptr += bytes_read;\n\t      break;\n\t    case DW_LNS_negate_stmt:\n\t      is_stmt = (!is_stmt);\n\t      break;\n\t    case DW_LNS_set_basic_block:\n\t      break;\n\t    case DW_LNS_const_add_pc:\n\t      if (lh.maximum_ops_per_insn == 1)\n\t\taddress += (lh.minimum_instruction_length\n\t\t\t    * ((255 - lh.opcode_base) / lh.line_range));\n\t      else\n\t\t{\n\t\t  bfd_vma adjust = ((255 - lh.opcode_base) / lh.line_range);\n\t\t  address += (lh.minimum_instruction_length\n\t\t\t      * ((op_index + adjust)\n\t\t\t\t / lh.maximum_ops_per_insn));\n\t\t  op_index = (op_index + adjust) % lh.maximum_ops_per_insn;\n\t\t}\n\t      break;\n\t    case DW_LNS_fixed_advance_pc:\n\t      address += read_2_bytes (abfd, line_ptr, line_end);\n\t      op_index = 0;\n\t      line_ptr += 2;\n\t      break;\n\t    default:\n\t      /* Unknown standard opcode, ignore it.  */\n\t      for (i = 0; i < lh.standard_opcode_lengths[op_code]; i++)\n\t\t{\n\t\t  (void) _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t\tFALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t}\n\t      break;\n\t    }\n\t}\n\n      if (filename)\n\tfree (filename);\n    }\n\n  if (sort_line_sequences (table))\n    return table;\n\n fail:\n  if (table->sequences != NULL)\n    free (table->sequences);\n  if (table->files != NULL)\n    free (table->files);\n  if (table->dirs != NULL)\n    free (table->dirs);\n  return NULL;\n}",
        "func": "static struct line_info_table*\ndecode_line_info (struct comp_unit *unit, struct dwarf2_debug *stash)\n{\n  bfd *abfd = unit->abfd;\n  struct line_info_table* table;\n  bfd_byte *line_ptr;\n  bfd_byte *line_end;\n  struct line_head lh;\n  unsigned int i, bytes_read, offset_size;\n  char *cur_file, *cur_dir;\n  unsigned char op_code, extended_op, adj_opcode;\n  unsigned int exop_len;\n  bfd_size_type amt;\n\n  if (! read_section (abfd, &stash->debug_sections[debug_line],\n\t\t      stash->syms, unit->line_offset,\n\t\t      &stash->dwarf_line_buffer, &stash->dwarf_line_size))\n    return NULL;\n\n  amt = sizeof (struct line_info_table);\n  table = (struct line_info_table *) bfd_alloc (abfd, amt);\n  if (table == NULL)\n    return NULL;\n  table->abfd = abfd;\n  table->comp_dir = unit->comp_dir;\n\n  table->num_files = 0;\n  table->files = NULL;\n\n  table->num_dirs = 0;\n  table->dirs = NULL;\n\n  table->num_sequences = 0;\n  table->sequences = NULL;\n\n  table->lcl_head = NULL;\n\n  if (stash->dwarf_line_size < 16)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Line info section is too small (%Ld)\"),\n\t stash->dwarf_line_size);\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n  line_ptr = stash->dwarf_line_buffer + unit->line_offset;\n  line_end = stash->dwarf_line_buffer + stash->dwarf_line_size;\n\n  /* Read in the prologue.  */\n  lh.total_length = read_4_bytes (abfd, line_ptr, line_end);\n  line_ptr += 4;\n  offset_size = 4;\n  if (lh.total_length == 0xffffffff)\n    {\n      lh.total_length = read_8_bytes (abfd, line_ptr, line_end);\n      line_ptr += 8;\n      offset_size = 8;\n    }\n  else if (lh.total_length == 0 && unit->addr_size == 8)\n    {\n      /* Handle (non-standard) 64-bit DWARF2 formats.  */\n      lh.total_length = read_4_bytes (abfd, line_ptr, line_end);\n      line_ptr += 4;\n      offset_size = 8;\n    }\n\n  if (lh.total_length > (size_t) (line_end - line_ptr))\n    {\n      _bfd_error_handler\n\t/* xgettext: c-format */\n\t(_(\"Dwarf Error: Line info data is bigger (%#Lx)\"\n\t   \" than the space remaining in the section (%#lx)\"),\n\t lh.total_length, (unsigned long) (line_end - line_ptr));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  line_end = line_ptr + lh.total_length;\n\n  lh.version = read_2_bytes (abfd, line_ptr, line_end);\n  if (lh.version < 2 || lh.version > 5)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Unhandled .debug_line version %d.\"), lh.version);\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n  line_ptr += 2;\n\n  if (line_ptr + offset_size + (lh.version >= 5 ? 8 : (lh.version >= 4 ? 6 : 5))\n      >= line_end)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Ran out of room reading prologue\"));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  if (lh.version >= 5)\n    {\n      unsigned int segment_selector_size;\n\n      /* Skip address size.  */\n      read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n\n      segment_selector_size = read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n      if (segment_selector_size != 0)\n\t{\n\t  _bfd_error_handler\n\t    (_(\"Dwarf Error: Line info unsupported segment selector size %u.\"),\n\t     segment_selector_size);\n\t  bfd_set_error (bfd_error_bad_value);\n\t  return NULL;\n\t}\n    }\n\n  if (offset_size == 4)\n    lh.prologue_length = read_4_bytes (abfd, line_ptr, line_end);\n  else\n    lh.prologue_length = read_8_bytes (abfd, line_ptr, line_end);\n  line_ptr += offset_size;\n\n  lh.minimum_instruction_length = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  if (lh.version >= 4)\n    {\n      lh.maximum_ops_per_insn = read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n    }\n  else\n    lh.maximum_ops_per_insn = 1;\n\n  if (lh.maximum_ops_per_insn == 0)\n    {\n      _bfd_error_handler\n\t(_(\"Dwarf Error: Invalid maximum operations per instruction.\"));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  lh.default_is_stmt = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  lh.line_base = read_1_signed_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  lh.line_range = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  lh.opcode_base = read_1_byte (abfd, line_ptr, line_end);\n  line_ptr += 1;\n\n  if (line_ptr + (lh.opcode_base - 1) >= line_end)\n    {\n      _bfd_error_handler (_(\"Dwarf Error: Ran out of room reading opcodes\"));\n      bfd_set_error (bfd_error_bad_value);\n      return NULL;\n    }\n\n  amt = lh.opcode_base * sizeof (unsigned char);\n  lh.standard_opcode_lengths = (unsigned char *) bfd_alloc (abfd, amt);\n\n  lh.standard_opcode_lengths[0] = 1;\n\n  for (i = 1; i < lh.opcode_base; ++i)\n    {\n      lh.standard_opcode_lengths[i] = read_1_byte (abfd, line_ptr, line_end);\n      line_ptr += 1;\n    }\n\n  if (lh.version >= 5)\n    {\n      /* Read directory table.  */\n      if (!read_formatted_entries (unit, &line_ptr, line_end, table,\n\t\t\t\t   line_info_add_include_dir_stub))\n\tgoto fail;\n\n      /* Read file name table.  */\n      if (!read_formatted_entries (unit, &line_ptr, line_end, table,\n\t\t\t\t   line_info_add_file_name))\n\tgoto fail;\n    }\n  else\n    {\n      /* Read directory table.  */\n      while ((cur_dir = read_string (abfd, line_ptr, line_end, &bytes_read)) != NULL)\n\t{\n\t  line_ptr += bytes_read;\n\n\t  if (!line_info_add_include_dir (table, cur_dir))\n\t    goto fail;\n\t}\n\n      line_ptr += bytes_read;\n\n      /* Read file name table.  */\n      while ((cur_file = read_string (abfd, line_ptr, line_end, &bytes_read)) != NULL)\n\t{\n\t  unsigned int dir, xtime, size;\n\n\t  line_ptr += bytes_read;\n\n\t  dir = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read, FALSE, line_end);\n\t  line_ptr += bytes_read;\n\t  xtime = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read, FALSE, line_end);\n\t  line_ptr += bytes_read;\n\t  size = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read, FALSE, line_end);\n\t  line_ptr += bytes_read;\n\n\t  if (!line_info_add_file_name (table, cur_file, dir, xtime, size))\n\t    goto fail;\n\t}\n\n      line_ptr += bytes_read;\n    }\n\n  /* Read the statement sequences until there's nothing left.  */\n  while (line_ptr < line_end)\n    {\n      /* State machine registers.  */\n      bfd_vma address = 0;\n      unsigned char op_index = 0;\n      char * filename = table->num_files ? concat_filename (table, 1) : NULL;\n      unsigned int line = 1;\n      unsigned int column = 0;\n      unsigned int discriminator = 0;\n      int is_stmt = lh.default_is_stmt;\n      int end_sequence = 0;\n      /* eraxxon@alumni.rice.edu: Against the DWARF2 specs, some\n\t compilers generate address sequences that are wildly out of\n\t order using DW_LNE_set_address (e.g. Intel C++ 6.0 compiler\n\t for ia64-Linux).  Thus, to determine the low and high\n\t address, we must compare on every DW_LNS_copy, etc.  */\n      bfd_vma low_pc  = (bfd_vma) -1;\n      bfd_vma high_pc = 0;\n\n      /* Decode the table.  */\n      while (! end_sequence)\n\t{\n\t  op_code = read_1_byte (abfd, line_ptr, line_end);\n\t  line_ptr += 1;\n\n\t  if (op_code >= lh.opcode_base)\n\t    {\n\t      /* Special operand.  */\n\t      adj_opcode = op_code - lh.opcode_base;\n\t      if (lh.line_range == 0)\n\t\tgoto line_fail;\n\t      if (lh.maximum_ops_per_insn == 1)\n\t\taddress += (adj_opcode / lh.line_range\n\t\t\t    * lh.minimum_instruction_length);\n\t      else\n\t\t{\n\t\t  address += ((op_index + adj_opcode / lh.line_range)\n\t\t\t      / lh.maximum_ops_per_insn\n\t\t\t      * lh.minimum_instruction_length);\n\t\t  op_index = ((op_index + adj_opcode / lh.line_range)\n\t\t\t      % lh.maximum_ops_per_insn);\n\t\t}\n\t      line += lh.line_base + (adj_opcode % lh.line_range);\n\t      /* Append row to matrix using current values.  */\n\t      if (!add_line_info (table, address, op_index, filename,\n\t\t\t\t  line, column, discriminator, 0))\n\t\tgoto line_fail;\n\t      discriminator = 0;\n\t      if (address < low_pc)\n\t\tlow_pc = address;\n\t      if (address > high_pc)\n\t\thigh_pc = address;\n\t    }\n\t  else switch (op_code)\n\t    {\n\t    case DW_LNS_extended_op:\n\t      exop_len = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t\tFALSE, line_end);\n\t      line_ptr += bytes_read;\n\t      extended_op = read_1_byte (abfd, line_ptr, line_end);\n\t      line_ptr += 1;\n\n\t      switch (extended_op)\n\t\t{\n\t\tcase DW_LNE_end_sequence:\n\t\t  end_sequence = 1;\n\t\t  if (!add_line_info (table, address, op_index, filename, line,\n\t\t\t\t      column, discriminator, end_sequence))\n\t\t    goto line_fail;\n\t\t  discriminator = 0;\n\t\t  if (address < low_pc)\n\t\t    low_pc = address;\n\t\t  if (address > high_pc)\n\t\t    high_pc = address;\n\t\t  if (!arange_add (unit, &unit->arange, low_pc, high_pc))\n\t\t    goto line_fail;\n\t\t  break;\n\t\tcase DW_LNE_set_address:\n\t\t  address = read_address (unit, line_ptr, line_end);\n\t\t  op_index = 0;\n\t\t  line_ptr += unit->addr_size;\n\t\t  break;\n\t\tcase DW_LNE_define_file:\n\t\t  cur_file = read_string (abfd, line_ptr, line_end, &bytes_read);\n\t\t  line_ptr += bytes_read;\n\t\t  if ((table->num_files % FILE_ALLOC_CHUNK) == 0)\n\t\t    {\n\t\t      struct fileinfo *tmp;\n\n\t\t      amt = table->num_files + FILE_ALLOC_CHUNK;\n\t\t      amt *= sizeof (struct fileinfo);\n\t\t      tmp = (struct fileinfo *) bfd_realloc (table->files, amt);\n\t\t      if (tmp == NULL)\n\t\t\tgoto line_fail;\n\t\t      table->files = tmp;\n\t\t    }\n\t\t  table->files[table->num_files].name = cur_file;\n\t\t  table->files[table->num_files].dir =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  table->files[table->num_files].time =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  table->files[table->num_files].size =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  table->num_files++;\n\t\t  break;\n\t\tcase DW_LNE_set_discriminator:\n\t\t  discriminator =\n\t\t    _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t   FALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t  break;\n\t\tcase DW_LNE_HP_source_file_correlation:\n\t\t  line_ptr += exop_len - 1;\n\t\t  break;\n\t\tdefault:\n\t\t  _bfd_error_handler\n\t\t    (_(\"Dwarf Error: mangled line number section.\"));\n\t\t  bfd_set_error (bfd_error_bad_value);\n\t\tline_fail:\n\t\t  if (filename != NULL)\n\t\t    free (filename);\n\t\t  goto fail;\n\t\t}\n\t      break;\n\t    case DW_LNS_copy:\n\t      if (!add_line_info (table, address, op_index,\n\t\t\t\t  filename, line, column, discriminator, 0))\n\t\tgoto line_fail;\n\t      discriminator = 0;\n\t      if (address < low_pc)\n\t\tlow_pc = address;\n\t      if (address > high_pc)\n\t\thigh_pc = address;\n\t      break;\n\t    case DW_LNS_advance_pc:\n\t      if (lh.maximum_ops_per_insn == 1)\n\t\taddress += (lh.minimum_instruction_length\n\t\t\t    * _bfd_safe_read_leb128 (abfd, line_ptr,\n\t\t\t\t\t\t     &bytes_read,\n\t\t\t\t\t\t     FALSE, line_end));\n\t      else\n\t\t{\n\t\t  bfd_vma adjust = _bfd_safe_read_leb128 (abfd, line_ptr,\n\t\t\t\t\t\t\t  &bytes_read,\n\t\t\t\t\t\t\t  FALSE, line_end);\n\t\t  address = ((op_index + adjust) / lh.maximum_ops_per_insn\n\t\t\t     * lh.minimum_instruction_length);\n\t\t  op_index = (op_index + adjust) % lh.maximum_ops_per_insn;\n\t\t}\n\t      line_ptr += bytes_read;\n\t      break;\n\t    case DW_LNS_advance_line:\n\t      line += _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t     TRUE, line_end);\n\t      line_ptr += bytes_read;\n\t      break;\n\t    case DW_LNS_set_file:\n\t      {\n\t\tunsigned int file;\n\n\t\t/* The file and directory tables are 0\n\t\t   based, the references are 1 based.  */\n\t\tfile = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t      FALSE, line_end);\n\t\tline_ptr += bytes_read;\n\t\tif (filename)\n\t\t  free (filename);\n\t\tfilename = concat_filename (table, file);\n\t\tbreak;\n\t      }\n\t    case DW_LNS_set_column:\n\t      column = _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t      FALSE, line_end);\n\t      line_ptr += bytes_read;\n\t      break;\n\t    case DW_LNS_negate_stmt:\n\t      is_stmt = (!is_stmt);\n\t      break;\n\t    case DW_LNS_set_basic_block:\n\t      break;\n\t    case DW_LNS_const_add_pc:\n\t      if (lh.line_range == 0)\n\t\tgoto line_fail;\n\t      if (lh.maximum_ops_per_insn == 1)\n\t\taddress += (lh.minimum_instruction_length\n\t\t\t    * ((255 - lh.opcode_base) / lh.line_range));\n\t      else\n\t\t{\n\t\t  bfd_vma adjust = ((255 - lh.opcode_base) / lh.line_range);\n\t\t  address += (lh.minimum_instruction_length\n\t\t\t      * ((op_index + adjust)\n\t\t\t\t / lh.maximum_ops_per_insn));\n\t\t  op_index = (op_index + adjust) % lh.maximum_ops_per_insn;\n\t\t}\n\t      break;\n\t    case DW_LNS_fixed_advance_pc:\n\t      address += read_2_bytes (abfd, line_ptr, line_end);\n\t      op_index = 0;\n\t      line_ptr += 2;\n\t      break;\n\t    default:\n\t      /* Unknown standard opcode, ignore it.  */\n\t      for (i = 0; i < lh.standard_opcode_lengths[op_code]; i++)\n\t\t{\n\t\t  (void) _bfd_safe_read_leb128 (abfd, line_ptr, &bytes_read,\n\t\t\t\t\t\tFALSE, line_end);\n\t\t  line_ptr += bytes_read;\n\t\t}\n\t      break;\n\t    }\n\t}\n\n      if (filename)\n\tfree (filename);\n    }\n\n  if (sort_line_sequences (table))\n    return table;\n\n fail:\n  if (table->sequences != NULL)\n    free (table->sequences);\n  if (table->files != NULL)\n    free (table->files);\n  if (table->dirs != NULL)\n    free (table->dirs);\n  return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -405,6 +405,8 @@\n \t    case DW_LNS_set_basic_block:\n \t      break;\n \t    case DW_LNS_const_add_pc:\n+\t      if (lh.line_range == 0)\n+\t\tgoto line_fail;\n \t      if (lh.maximum_ops_per_insn == 1)\n \t\taddress += (lh.minimum_instruction_length\n \t\t\t    * ((255 - lh.opcode_base) / lh.line_range));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t      if (lh.line_range == 0)",
                "\t\tgoto line_fail;"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-14634",
        "func_name": "libsndfile/double64_init",
        "description": "In libsndfile 1.0.28, a divide-by-zero error exists in the function double64_init() in double64.c, which may lead to DoS when playing a crafted audio file.",
        "git_url": "https://github.com/libsndfile/libsndfile/commit/85c877d5072866aadbe8ed0c3e0590fbb5e16788",
        "commit_title": "double64_init: Check psf->sf.channels against upper bound",
        "commit_text": " This prevents division by zero later in the code.  While the trivial case to catch this (i.e. sf.channels < 1) has already been covered, a crafted file may report a number of channels that is so high (i.e. > INT_MAX/sizeof(double)) that it \"somehow\" gets miscalculated to zero (if this makes sense) in the determination of the blockwidth. Since we only support a limited number of channels anyway, make sure to check here as well.  CVE-2017-14634  Closes: https://github.com/erikd/libsndfile/issues/318",
        "func_before": "int\ndouble64_init\t(SF_PRIVATE *psf)\n{\tstatic int double64_caps ;\n\n\tif (psf->sf.channels < 1)\n\t{\tpsf_log_printf (psf, \"double64_init : internal error : channels = %d\\n\", psf->sf.channels) ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tdouble64_caps = double64_get_capability (psf) ;\n\n\tpsf->blockwidth = sizeof (double) * psf->sf.channels ;\n\n\tif (psf->file.mode == SFM_READ || psf->file.mode == SFM_RDWR)\n\t{\tswitch (psf->endian + double64_caps)\n\t\t{\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\t/* When the CPU is not IEEE compatible. */\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tdefault : break ;\n\t\t\t} ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE || psf->file.mode == SFM_RDWR)\n\t{\tswitch (psf->endian + double64_caps)\n\t\t{\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\t/* When the CPU is not IEEE compatible. */\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tdefault : break ;\n\t\t\t} ;\n\t\t} ;\n\n\tif (psf->filelength > psf->dataoffset)\n\t{\tpsf->datalength = (psf->dataend > 0) ? psf->dataend - psf->dataoffset :\n\t\t\t\t\t\t\tpsf->filelength - psf->dataoffset ;\n\t\t}\n\telse\n\t\tpsf->datalength = 0 ;\n\n\tpsf->sf.frames = psf->datalength / psf->blockwidth ;\n\n\treturn 0 ;\n}",
        "func": "int\ndouble64_init\t(SF_PRIVATE *psf)\n{\tstatic int double64_caps ;\n\n\tif (psf->sf.channels < 1 || psf->sf.channels > SF_MAX_CHANNELS)\n\t{\tpsf_log_printf (psf, \"double64_init : internal error : channels = %d\\n\", psf->sf.channels) ;\n\t\treturn SFE_INTERNAL ;\n\t\t} ;\n\n\tdouble64_caps = double64_get_capability (psf) ;\n\n\tpsf->blockwidth = sizeof (double) * psf->sf.channels ;\n\n\tif (psf->file.mode == SFM_READ || psf->file.mode == SFM_RDWR)\n\t{\tswitch (psf->endian + double64_caps)\n\t\t{\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= host_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= host_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= host_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= host_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\t/* When the CPU is not IEEE compatible. */\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->read_short\t\t= replace_read_d2s ;\n\t\t\t\t\tpsf->read_int\t\t= replace_read_d2i ;\n\t\t\t\t\tpsf->read_float\t\t= replace_read_d2f ;\n\t\t\t\t\tpsf->read_double\t= replace_read_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tdefault : break ;\n\t\t\t} ;\n\t\t} ;\n\n\tif (psf->file.mode == SFM_WRITE || psf->file.mode == SFM_RDWR)\n\t{\tswitch (psf->endian + double64_caps)\n\t\t{\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_CAN_RW_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_CAN_RW_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= host_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= host_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= host_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= host_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\t/* When the CPU is not IEEE compatible. */\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_FALSE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_BIG + DOUBLE_BROKEN_LE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tcase (SF_ENDIAN_LITTLE + DOUBLE_BROKEN_BE) :\n\t\t\t\t\tpsf->data_endswap = SF_TRUE ;\n\t\t\t\t\tpsf->write_short\t= replace_write_s2d ;\n\t\t\t\t\tpsf->write_int\t\t= replace_write_i2d ;\n\t\t\t\t\tpsf->write_float\t= replace_write_f2d ;\n\t\t\t\t\tpsf->write_double\t= replace_write_d ;\n\t\t\t\t\tbreak ;\n\n\t\t\tdefault : break ;\n\t\t\t} ;\n\t\t} ;\n\n\tif (psf->filelength > psf->dataoffset)\n\t{\tpsf->datalength = (psf->dataend > 0) ? psf->dataend - psf->dataoffset :\n\t\t\t\t\t\t\tpsf->filelength - psf->dataoffset ;\n\t\t}\n\telse\n\t\tpsf->datalength = 0 ;\n\n\tpsf->sf.frames = psf->datalength / psf->blockwidth ;\n\n\treturn 0 ;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n double64_init\t(SF_PRIVATE *psf)\n {\tstatic int double64_caps ;\n \n-\tif (psf->sf.channels < 1)\n+\tif (psf->sf.channels < 1 || psf->sf.channels > SF_MAX_CHANNELS)\n \t{\tpsf_log_printf (psf, \"double64_init : internal error : channels = %d\\n\", psf->sf.channels) ;\n \t\treturn SFE_INTERNAL ;\n \t\t} ;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (psf->sf.channels < 1)"
            ],
            "added_lines": [
                "\tif (psf->sf.channels < 1 || psf->sf.channels > SF_MAX_CHANNELS)"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-16299",
        "func_name": "ArtifexSoftware/ghostpdl/md_open",
        "description": "A Division by Zero vulnerability in bj10v_print_page() in contrib/japanese/gdev10v.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.",
        "git_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/4fcbece468706e0e89ed2856729b2ccacbc112be",
        "commit_title": "Avoid some devices dying due to inappropriate resolutions.",
        "commit_text": "",
        "func_before": "static int\nmd_open(gx_device *pdev)\n{\n        static const float md_margins[4] =\n         {\tMD_SIDE_MARGIN, MD_BOTTOM_MARGIN,\n                MD_SIDE_MARGIN, MD_TOP_MARGIN\n         };\n\n        gx_device_set_margins(pdev, md_margins, true);\n        return gdev_prn_open(pdev);\n}",
        "func": "static int\nmd_open(gx_device *pdev)\n{\n    static const float md_margins[4] =\n    {\n        MD_SIDE_MARGIN, MD_BOTTOM_MARGIN,\n        MD_SIDE_MARGIN, MD_TOP_MARGIN\n    };\n\n    if (pdev->HWResolution[0] != 600)\n    {\n        emprintf(pdev->memory, \"device must have an X resolution of 600dpi\\n\");\n        return_error(gs_error_rangecheck);\n    }\n\n    gx_device_set_margins(pdev, md_margins, true);\n    return gdev_prn_open(pdev);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,18 @@\n static int\n md_open(gx_device *pdev)\n {\n-        static const float md_margins[4] =\n-         {\tMD_SIDE_MARGIN, MD_BOTTOM_MARGIN,\n-                MD_SIDE_MARGIN, MD_TOP_MARGIN\n-         };\n+    static const float md_margins[4] =\n+    {\n+        MD_SIDE_MARGIN, MD_BOTTOM_MARGIN,\n+        MD_SIDE_MARGIN, MD_TOP_MARGIN\n+    };\n \n-        gx_device_set_margins(pdev, md_margins, true);\n-        return gdev_prn_open(pdev);\n+    if (pdev->HWResolution[0] != 600)\n+    {\n+        emprintf(pdev->memory, \"device must have an X resolution of 600dpi\\n\");\n+        return_error(gs_error_rangecheck);\n+    }\n+\n+    gx_device_set_margins(pdev, md_margins, true);\n+    return gdev_prn_open(pdev);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        static const float md_margins[4] =",
                "         {\tMD_SIDE_MARGIN, MD_BOTTOM_MARGIN,",
                "                MD_SIDE_MARGIN, MD_TOP_MARGIN",
                "         };",
                "        gx_device_set_margins(pdev, md_margins, true);",
                "        return gdev_prn_open(pdev);"
            ],
            "added_lines": [
                "    static const float md_margins[4] =",
                "    {",
                "        MD_SIDE_MARGIN, MD_BOTTOM_MARGIN,",
                "        MD_SIDE_MARGIN, MD_TOP_MARGIN",
                "    };",
                "    if (pdev->HWResolution[0] != 600)",
                "    {",
                "        emprintf(pdev->memory, \"device must have an X resolution of 600dpi\\n\");",
                "        return_error(gs_error_rangecheck);",
                "    }",
                "",
                "    gx_device_set_margins(pdev, md_margins, true);",
                "    return gdev_prn_open(pdev);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-16299",
        "func_name": "ArtifexSoftware/ghostpdl/bj10v_open",
        "description": "A Division by Zero vulnerability in bj10v_print_page() in contrib/japanese/gdev10v.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.",
        "git_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/4fcbece468706e0e89ed2856729b2ccacbc112be",
        "commit_title": "Avoid some devices dying due to inappropriate resolutions.",
        "commit_text": "",
        "func_before": "static int\nbj10v_open(gx_device * pdev)\n{\n    if (pdev->HWResolution[0] < 180 ||\n        pdev->HWResolution[1] < 180)\n    {\n        emprintf(\"device requires a resolution of at least 180dpi\\n\");\n        return_error(gs_error_rangecheck);\n    }\n    return gdev_prn_open(pdev);\n}",
        "func": "static int\nbj10v_open(gx_device * pdev)\n{\n    if (pdev->HWResolution[0] < 180 ||\n        pdev->HWResolution[1] < 180)\n    {\n        emprintf(pdev->memory, \"device requires a resolution of at least 180dpi\\n\");\n        return_error(gs_error_rangecheck);\n    }\n    return gdev_prn_open(pdev);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n     if (pdev->HWResolution[0] < 180 ||\n         pdev->HWResolution[1] < 180)\n     {\n-        emprintf(\"device requires a resolution of at least 180dpi\\n\");\n+        emprintf(pdev->memory, \"device requires a resolution of at least 180dpi\\n\");\n         return_error(gs_error_rangecheck);\n     }\n     return gdev_prn_open(pdev);",
        "diff_line_info": {
            "deleted_lines": [
                "        emprintf(\"device requires a resolution of at least 180dpi\\n\");"
            ],
            "added_lines": [
                "        emprintf(pdev->memory, \"device requires a resolution of at least 180dpi\\n\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-16310",
        "func_name": "ArtifexSoftware/ghostpdl/dot24_print_page",
        "description": "A division by zero vulnerability in dot24_print_page() in devices/gdevdm24.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted PDF file. This is fixed in v9.51.",
        "git_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/eaba1d97b62831b42c51840cc8ee2bc4576c942e",
        "commit_title": "Bug 701828: make dot24_print_page() return error instead of divide by zero.",
        "commit_text": " Fixes:     ./sanbin/gs -dBATCH -dNOPAUSE -dSAFER -r2 -sOutputFile=tmp -sDEVICE=necp6 ../bug-701828.pdf",
        "func_before": "static int\ndot24_print_page (gx_device_printer *pdev, gp_file *prn_stream, char *init_string, int init_len)\n{\n  int xres = (int)pdev->x_pixels_per_inch;\n  int yres = (int)pdev->y_pixels_per_inch;\n  int x_high = (xres == 360);\n  int y_high = (yres == 360);\n  int bits_per_column = (y_high ? 48 : 24);\n  uint line_size = gdev_prn_raster (pdev);\n  uint in_size = line_size * bits_per_column;\n  byte *in = (byte *) gs_malloc (pdev->memory, in_size, 1, \"dot24_print_page (in)\");\n  uint out_size = ((pdev->width + 7) & -8) * 3;\n  byte *out = (byte *) gs_malloc (pdev->memory, out_size, 1, \"dot24_print_page (out)\");\n  int y_passes = (y_high ? 2 : 1);\n  int dots_per_space = xres / 10;\t/* pica space = 1/10\" */\n  int bytes_per_space = dots_per_space * 3;\n  int skip = 0, lnum = 0, ypass;\n\n  /* Check allocations */\n  if (in == 0 || out == 0)\n    {\n      if (out)\n        gs_free (pdev->memory, (char *) out, out_size, 1, \"dot24_print_page (out)\");\n      if (in)\n        gs_free (pdev->memory, (char *) in, in_size, 1, \"dot24_print_page (in)\");\n      return_error (gs_error_VMerror);\n    }\n\n  /* Initialize the printer and reset the margins. */\n  gp_fwrite (init_string, init_len - 1, sizeof (char), prn_stream);\n  gp_fputc ((int) (pdev->width / pdev->x_pixels_per_inch * 10) + 2,\n         prn_stream);\n\n  /* Print lines of graphics */\n  while (lnum < pdev->height)\n    {\n      byte *inp;\n      byte *in_end;\n      byte *out_end;\n      byte *out_blk;\n      register byte *outp;\n      int lcnt;\n\n      /* Copy 1 scan line and test for all zero. */\n      gdev_prn_copy_scan_lines (pdev, lnum, in, line_size);\n      if (in[0] == 0\n          && !memcmp ((char *) in, (char *) in + 1, line_size - 1))\n        {\n          lnum++;\n          skip += 2 - y_high;\n          continue;\n        }\n\n      /* Vertical tab to the appropriate position. */\n      while ((skip >> 1) > 255)\n        {\n          gp_fputs (\"\\033J\\377\", prn_stream);\n          skip -= 255 * 2;\n        }\n\n      if (skip)\n        {\n          if (skip >> 1)\n            gp_fprintf (prn_stream, \"\\033J%c\", skip >> 1);\n          if (skip & 1)\n            gp_fputc ('\\n', prn_stream);\n        }\n\n      /* Copy the rest of the scan lines. */\n      if (y_high)\n        {\n          inp = in + line_size;\n          for (lcnt = 1; lcnt < 24; lcnt++, inp += line_size)\n            if (!gdev_prn_copy_scan_lines (pdev, lnum + lcnt * 2, inp,\n                                           line_size))\n              {\n                memset (inp, 0, (24 - lcnt) * line_size);\n                break;\n              }\n          inp = in + line_size * 24;\n          for (lcnt = 0; lcnt < 24; lcnt++, inp += line_size)\n            if (!gdev_prn_copy_scan_lines (pdev, lnum + lcnt * 2 + 1, inp,\n                                           line_size))\n              {\n                memset (inp, 0, (24 - lcnt) * line_size);\n                break;\n              }\n        }\n      else\n        {\n          lcnt = 1 + gdev_prn_copy_scan_lines (pdev, lnum + 1, in + line_size,\n                                               in_size - line_size);\n          if (lcnt < 24)\n            /* Pad with lines of zeros. */\n            memset (in + lcnt * line_size, 0, in_size - lcnt * line_size);\n        }\n\n      for (ypass = 0; ypass < y_passes; ypass++)\n        {\n          out_end = out;\n          inp = in;\n          if (ypass)\n            inp += line_size * 24;\n          in_end = inp + line_size;\n\n          for (; inp < in_end; inp++, out_end += 24)\n            {\n              memflip8x8 (inp, line_size, out_end, 3);\n              memflip8x8 (inp + line_size * 8, line_size, out_end + 1, 3);\n              memflip8x8 (inp + line_size * 16, line_size, out_end + 2, 3);\n            }\n          /* Remove trailing 0s. */\n          while (out_end - 3 >= out && out_end[-1] == 0\n                 && out_end[-2] == 0 && out_end[-3] == 0)\n            out_end -= 3;\n\n          for (out_blk = outp = out; outp < out_end;)\n            {\n              /* Skip a run of leading 0s. */\n              /* At least 10 are needed to make tabbing worth it. */\n\n              if (outp[0] == 0 && outp + 12 <= out_end\n                  && outp[1] == 0 && outp[2] == 0\n                  && outp[3] == 0 && outp[4] == 0 && outp[5] == 0\n                  && outp[6] == 0 && outp[7] == 0 && outp[8] == 0\n                  && outp[9] == 0 && outp[10] == 0 && outp[11] == 0)\n                {\n                  byte *zp = outp;\n                  int tpos;\n                  byte *newp;\n                  outp += 12;\n                  while (outp + 3 <= out_end\n                         && outp[0] == 0 && outp[1] == 0 && outp[2] == 0)\n                    outp += 3;\n                  tpos = (outp - out) / bytes_per_space;\n                  newp = out + tpos * bytes_per_space;\n                  if (newp > zp + 10)\n                    {\n                      /* Output preceding bit data. */\n                      /* only false at beginning of line */\n                      if (zp > out_blk)\n                        {\n                          if (x_high)\n                            dot24_improve_bitmap (out_blk, (int) (zp - out_blk));\n                          dot24_output_run (out_blk, (int) (zp - out_blk),\n                                          x_high, prn_stream);\n                        }\n                      /* Tab over to the appropriate position. */\n                      gp_fprintf (prn_stream, \"\\033D%c%c\\t\", tpos, 0);\n                      out_blk = outp = newp;\n                    }\n                }\n              else\n                outp += 3;\n            }\n          if (outp > out_blk)\n            {\n              if (x_high)\n                dot24_improve_bitmap (out_blk, (int) (outp - out_blk));\n              dot24_output_run (out_blk, (int) (outp - out_blk), x_high,\n                              prn_stream);\n            }\n\n          gp_fputc ('\\r', prn_stream);\n          if (ypass < y_passes - 1)\n            gp_fputc ('\\n', prn_stream);\n        }\n      skip = 48 - y_high;\n      lnum += bits_per_column;\n    }\n\n  /* Eject the page and reinitialize the printer */\n  gp_fputs (\"\\f\\033@\", prn_stream);\n  gp_fflush (prn_stream);\n\n  gs_free (pdev->memory, (char *) out, out_size, 1, \"dot24_print_page (out)\");\n  gs_free (pdev->memory, (char *) in, in_size, 1, \"dot24_print_page (in)\");\n\n  return 0;\n}",
        "func": "static int\ndot24_print_page (gx_device_printer *pdev, gp_file *prn_stream, char *init_string, int init_len)\n{\n  int xres;\n  int yres;\n  int x_high;\n  int y_high;\n  int bits_per_column;\n  uint line_size;\n  uint in_size;\n  byte *in;\n  uint out_size;\n  byte *out;\n  int y_passes;\n  int dots_per_space;\n  int bytes_per_space;\n  int skip = 0, lnum = 0, ypass;\n\n  xres = (int)pdev->x_pixels_per_inch;\n  yres = (int)pdev->y_pixels_per_inch;\n  x_high = (xres == 360);\n  y_high = (yres == 360);\n  dots_per_space = xres / 10;       /* pica space = 1/10\" */\n  bytes_per_space = dots_per_space * 3;\n  if (bytes_per_space == 0) {\n    /* We divide by bytes_per_space later on. */\n    return_error(gs_error_rangecheck);\n  }\n  \n  bits_per_column = (y_high ? 48 : 24);\n  line_size = gdev_prn_raster (pdev);\n  in_size = line_size * bits_per_column;\n  in = (byte *) gs_malloc (pdev->memory, in_size, 1, \"dot24_print_page (in)\");\n  out_size = ((pdev->width + 7) & -8) * 3;\n  out = (byte *) gs_malloc (pdev->memory, out_size, 1, \"dot24_print_page (out)\");\n  y_passes = (y_high ? 2 : 1);\n\n  /* Check allocations */\n  if (in == 0 || out == 0)\n    {\n      if (out)\n        gs_free (pdev->memory, (char *) out, out_size, 1, \"dot24_print_page (out)\");\n      if (in)\n        gs_free (pdev->memory, (char *) in, in_size, 1, \"dot24_print_page (in)\");\n      return_error (gs_error_VMerror);\n    }\n\n  /* Initialize the printer and reset the margins. */\n  gp_fwrite (init_string, init_len - 1, sizeof (char), prn_stream);\n  gp_fputc ((int) (pdev->width / pdev->x_pixels_per_inch * 10) + 2,\n         prn_stream);\n\n  /* Print lines of graphics */\n  while (lnum < pdev->height)\n    {\n      byte *inp;\n      byte *in_end;\n      byte *out_end;\n      byte *out_blk;\n      register byte *outp;\n      int lcnt;\n\n      /* Copy 1 scan line and test for all zero. */\n      gdev_prn_copy_scan_lines (pdev, lnum, in, line_size);\n      if (in[0] == 0\n          && !memcmp ((char *) in, (char *) in + 1, line_size - 1))\n        {\n          lnum++;\n          skip += 2 - y_high;\n          continue;\n        }\n\n      /* Vertical tab to the appropriate position. */\n      while ((skip >> 1) > 255)\n        {\n          gp_fputs (\"\\033J\\377\", prn_stream);\n          skip -= 255 * 2;\n        }\n\n      if (skip)\n        {\n          if (skip >> 1)\n            gp_fprintf (prn_stream, \"\\033J%c\", skip >> 1);\n          if (skip & 1)\n            gp_fputc ('\\n', prn_stream);\n        }\n\n      /* Copy the rest of the scan lines. */\n      if (y_high)\n        {\n          inp = in + line_size;\n          for (lcnt = 1; lcnt < 24; lcnt++, inp += line_size)\n            if (!gdev_prn_copy_scan_lines (pdev, lnum + lcnt * 2, inp,\n                                           line_size))\n              {\n                memset (inp, 0, (24 - lcnt) * line_size);\n                break;\n              }\n          inp = in + line_size * 24;\n          for (lcnt = 0; lcnt < 24; lcnt++, inp += line_size)\n            if (!gdev_prn_copy_scan_lines (pdev, lnum + lcnt * 2 + 1, inp,\n                                           line_size))\n              {\n                memset (inp, 0, (24 - lcnt) * line_size);\n                break;\n              }\n        }\n      else\n        {\n          lcnt = 1 + gdev_prn_copy_scan_lines (pdev, lnum + 1, in + line_size,\n                                               in_size - line_size);\n          if (lcnt < 24)\n            /* Pad with lines of zeros. */\n            memset (in + lcnt * line_size, 0, in_size - lcnt * line_size);\n        }\n\n      for (ypass = 0; ypass < y_passes; ypass++)\n        {\n          out_end = out;\n          inp = in;\n          if (ypass)\n            inp += line_size * 24;\n          in_end = inp + line_size;\n\n          for (; inp < in_end; inp++, out_end += 24)\n            {\n              memflip8x8 (inp, line_size, out_end, 3);\n              memflip8x8 (inp + line_size * 8, line_size, out_end + 1, 3);\n              memflip8x8 (inp + line_size * 16, line_size, out_end + 2, 3);\n            }\n          /* Remove trailing 0s. */\n          while (out_end - 3 >= out && out_end[-1] == 0\n                 && out_end[-2] == 0 && out_end[-3] == 0)\n            out_end -= 3;\n\n          for (out_blk = outp = out; outp < out_end;)\n            {\n              /* Skip a run of leading 0s. */\n              /* At least 10 are needed to make tabbing worth it. */\n\n              if (outp[0] == 0 && outp + 12 <= out_end\n                  && outp[1] == 0 && outp[2] == 0\n                  && outp[3] == 0 && outp[4] == 0 && outp[5] == 0\n                  && outp[6] == 0 && outp[7] == 0 && outp[8] == 0\n                  && outp[9] == 0 && outp[10] == 0 && outp[11] == 0)\n                {\n                  byte *zp = outp;\n                  int tpos;\n                  byte *newp;\n                  outp += 12;\n                  while (outp + 3 <= out_end\n                         && outp[0] == 0 && outp[1] == 0 && outp[2] == 0)\n                    outp += 3;\n                  tpos = (outp - out) / bytes_per_space;\n                  newp = out + tpos * bytes_per_space;\n                  if (newp > zp + 10)\n                    {\n                      /* Output preceding bit data. */\n                      /* only false at beginning of line */\n                      if (zp > out_blk)\n                        {\n                          if (x_high)\n                            dot24_improve_bitmap (out_blk, (int) (zp - out_blk));\n                          dot24_output_run (out_blk, (int) (zp - out_blk),\n                                          x_high, prn_stream);\n                        }\n                      /* Tab over to the appropriate position. */\n                      gp_fprintf (prn_stream, \"\\033D%c%c\\t\", tpos, 0);\n                      out_blk = outp = newp;\n                    }\n                }\n              else\n                outp += 3;\n            }\n          if (outp > out_blk)\n            {\n              if (x_high)\n                dot24_improve_bitmap (out_blk, (int) (outp - out_blk));\n              dot24_output_run (out_blk, (int) (outp - out_blk), x_high,\n                              prn_stream);\n            }\n\n          gp_fputc ('\\r', prn_stream);\n          if (ypass < y_passes - 1)\n            gp_fputc ('\\n', prn_stream);\n        }\n      skip = 48 - y_high;\n      lnum += bits_per_column;\n    }\n\n  /* Eject the page and reinitialize the printer */\n  gp_fputs (\"\\f\\033@\", prn_stream);\n  gp_fflush (prn_stream);\n\n  gs_free (pdev->memory, (char *) out, out_size, 1, \"dot24_print_page (out)\");\n  gs_free (pdev->memory, (char *) in, in_size, 1, \"dot24_print_page (in)\");\n\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,20 +1,39 @@\n static int\n dot24_print_page (gx_device_printer *pdev, gp_file *prn_stream, char *init_string, int init_len)\n {\n-  int xres = (int)pdev->x_pixels_per_inch;\n-  int yres = (int)pdev->y_pixels_per_inch;\n-  int x_high = (xres == 360);\n-  int y_high = (yres == 360);\n-  int bits_per_column = (y_high ? 48 : 24);\n-  uint line_size = gdev_prn_raster (pdev);\n-  uint in_size = line_size * bits_per_column;\n-  byte *in = (byte *) gs_malloc (pdev->memory, in_size, 1, \"dot24_print_page (in)\");\n-  uint out_size = ((pdev->width + 7) & -8) * 3;\n-  byte *out = (byte *) gs_malloc (pdev->memory, out_size, 1, \"dot24_print_page (out)\");\n-  int y_passes = (y_high ? 2 : 1);\n-  int dots_per_space = xres / 10;\t/* pica space = 1/10\" */\n-  int bytes_per_space = dots_per_space * 3;\n+  int xres;\n+  int yres;\n+  int x_high;\n+  int y_high;\n+  int bits_per_column;\n+  uint line_size;\n+  uint in_size;\n+  byte *in;\n+  uint out_size;\n+  byte *out;\n+  int y_passes;\n+  int dots_per_space;\n+  int bytes_per_space;\n   int skip = 0, lnum = 0, ypass;\n+\n+  xres = (int)pdev->x_pixels_per_inch;\n+  yres = (int)pdev->y_pixels_per_inch;\n+  x_high = (xres == 360);\n+  y_high = (yres == 360);\n+  dots_per_space = xres / 10;       /* pica space = 1/10\" */\n+  bytes_per_space = dots_per_space * 3;\n+  if (bytes_per_space == 0) {\n+    /* We divide by bytes_per_space later on. */\n+    return_error(gs_error_rangecheck);\n+  }\n+  \n+  bits_per_column = (y_high ? 48 : 24);\n+  line_size = gdev_prn_raster (pdev);\n+  in_size = line_size * bits_per_column;\n+  in = (byte *) gs_malloc (pdev->memory, in_size, 1, \"dot24_print_page (in)\");\n+  out_size = ((pdev->width + 7) & -8) * 3;\n+  out = (byte *) gs_malloc (pdev->memory, out_size, 1, \"dot24_print_page (out)\");\n+  y_passes = (y_high ? 2 : 1);\n \n   /* Check allocations */\n   if (in == 0 || out == 0)",
        "diff_line_info": {
            "deleted_lines": [
                "  int xres = (int)pdev->x_pixels_per_inch;",
                "  int yres = (int)pdev->y_pixels_per_inch;",
                "  int x_high = (xres == 360);",
                "  int y_high = (yres == 360);",
                "  int bits_per_column = (y_high ? 48 : 24);",
                "  uint line_size = gdev_prn_raster (pdev);",
                "  uint in_size = line_size * bits_per_column;",
                "  byte *in = (byte *) gs_malloc (pdev->memory, in_size, 1, \"dot24_print_page (in)\");",
                "  uint out_size = ((pdev->width + 7) & -8) * 3;",
                "  byte *out = (byte *) gs_malloc (pdev->memory, out_size, 1, \"dot24_print_page (out)\");",
                "  int y_passes = (y_high ? 2 : 1);",
                "  int dots_per_space = xres / 10;\t/* pica space = 1/10\" */",
                "  int bytes_per_space = dots_per_space * 3;"
            ],
            "added_lines": [
                "  int xres;",
                "  int yres;",
                "  int x_high;",
                "  int y_high;",
                "  int bits_per_column;",
                "  uint line_size;",
                "  uint in_size;",
                "  byte *in;",
                "  uint out_size;",
                "  byte *out;",
                "  int y_passes;",
                "  int dots_per_space;",
                "  int bytes_per_space;",
                "",
                "  xres = (int)pdev->x_pixels_per_inch;",
                "  yres = (int)pdev->y_pixels_per_inch;",
                "  x_high = (xres == 360);",
                "  y_high = (yres == 360);",
                "  dots_per_space = xres / 10;       /* pica space = 1/10\" */",
                "  bytes_per_space = dots_per_space * 3;",
                "  if (bytes_per_space == 0) {",
                "    /* We divide by bytes_per_space later on. */",
                "    return_error(gs_error_rangecheck);",
                "  }",
                "  ",
                "  bits_per_column = (y_high ? 48 : 24);",
                "  line_size = gdev_prn_raster (pdev);",
                "  in_size = line_size * bits_per_column;",
                "  in = (byte *) gs_malloc (pdev->memory, in_size, 1, \"dot24_print_page (in)\");",
                "  out_size = ((pdev->width + 7) & -8) * 3;",
                "  out = (byte *) gs_malloc (pdev->memory, out_size, 1, \"dot24_print_page (out)\");",
                "  y_passes = (y_high ? 2 : 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-14415",
        "func_name": "qemu/oss_write",
        "description": "oss_write in audio/ossaudio.c in QEMU before 5.0.0 mishandles a buffer position.",
        "git_url": "https://github.com/qemu/qemu/commit/7a4ede0047a8613b0e3b72c9d351038f013dd357",
        "commit_title": "audio/oss: fix buffer pos calculation",
        "commit_text": " Message-Id: <20200120101804.29578-1-kraxel@redhat.com>",
        "func_before": "static size_t oss_write(HWVoiceOut *hw, void *buf, size_t len)\n{\n    OSSVoiceOut *oss = (OSSVoiceOut *) hw;\n    size_t pos;\n\n    if (oss->mmapped) {\n        size_t total_len;\n        len = MIN(len, oss_get_available_bytes(oss));\n\n        total_len = len;\n        while (len) {\n            size_t to_copy = MIN(len, hw->size_emul - hw->pos_emul);\n            memcpy(hw->buf_emul + hw->pos_emul, buf, to_copy);\n\n            hw->pos_emul = (hw->pos_emul + to_copy) % hw->pos_emul;\n            buf += to_copy;\n            len -= to_copy;\n        }\n        return total_len;\n    }\n\n    pos = 0;\n    while (len) {\n        ssize_t bytes_written;\n        void *pcm = advance(buf, pos);\n\n        bytes_written = write(oss->fd, pcm, len);\n        if (bytes_written < 0) {\n            if (errno != EAGAIN) {\n                oss_logerr(errno, \"failed to write %zu bytes\\n\",\n                           len);\n            }\n            return pos;\n        }\n\n        pos += bytes_written;\n        if (bytes_written < len) {\n            break;\n        }\n        len -= bytes_written;\n    }\n    return pos;\n}",
        "func": "static size_t oss_write(HWVoiceOut *hw, void *buf, size_t len)\n{\n    OSSVoiceOut *oss = (OSSVoiceOut *) hw;\n    size_t pos;\n\n    if (oss->mmapped) {\n        size_t total_len;\n        len = MIN(len, oss_get_available_bytes(oss));\n\n        total_len = len;\n        while (len) {\n            size_t to_copy = MIN(len, hw->size_emul - hw->pos_emul);\n            memcpy(hw->buf_emul + hw->pos_emul, buf, to_copy);\n\n            hw->pos_emul = (hw->pos_emul + to_copy) % hw->size_emul;\n            buf += to_copy;\n            len -= to_copy;\n        }\n        return total_len;\n    }\n\n    pos = 0;\n    while (len) {\n        ssize_t bytes_written;\n        void *pcm = advance(buf, pos);\n\n        bytes_written = write(oss->fd, pcm, len);\n        if (bytes_written < 0) {\n            if (errno != EAGAIN) {\n                oss_logerr(errno, \"failed to write %zu bytes\\n\",\n                           len);\n            }\n            return pos;\n        }\n\n        pos += bytes_written;\n        if (bytes_written < len) {\n            break;\n        }\n        len -= bytes_written;\n    }\n    return pos;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n             size_t to_copy = MIN(len, hw->size_emul - hw->pos_emul);\n             memcpy(hw->buf_emul + hw->pos_emul, buf, to_copy);\n \n-            hw->pos_emul = (hw->pos_emul + to_copy) % hw->pos_emul;\n+            hw->pos_emul = (hw->pos_emul + to_copy) % hw->size_emul;\n             buf += to_copy;\n             len -= to_copy;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "            hw->pos_emul = (hw->pos_emul + to_copy) % hw->pos_emul;"
            ],
            "added_lines": [
                "            hw->pos_emul = (hw->pos_emul + to_copy) % hw->size_emul;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-30207",
        "func_name": "xbmc/VideoPlayerCodec::Init",
        "description": "A divide by zero issue discovered in Kodi Home Theater Software 19.5 and earlier allows attackers to cause a denial of service via use of crafted mp3 file.",
        "git_url": "https://github.com/xbmc/xbmc/commit/dbc00c500f4c4830049cc040a61c439c580eea73",
        "commit_title": "VideoPlayerCodec: Stop dividing by zero",
        "commit_text": " When parsing a file failed so that needed fields, in our case frameSize are not available a guess work like with m_channels or m_samplerate does not help. Therefore fail early.",
        "func_before": "bool VideoPlayerCodec::Init(const CFileItem &file, unsigned int filecache)\n{\n  // take precaution if Init()ialized earlier\n  if (m_bInited)\n  {\n    // keep things as is if Init() was done with known strFile\n    if (m_strFileName == file.GetDynPath())\n      return true;\n\n    // got differing filename, so cleanup before starting over\n    DeInit();\n  }\n\n  m_nDecodedLen = 0;\n\n  CFileItem fileitem(file);\n  fileitem.SetMimeType(m_strContentType);\n  fileitem.SetMimeTypeForInternetFile();\n  m_pInputStream = CDVDFactoryInputStream::CreateInputStream(NULL, fileitem);\n  if (!m_pInputStream)\n  {\n    CLog::Log(LOGERROR, \"{}: Error creating input stream for {}\", __FUNCTION__, file.GetDynPath());\n    return false;\n  }\n\n  //! @todo\n  //! convey CFileItem::ContentLookup() into Open()\n  if (!m_pInputStream->Open())\n  {\n    CLog::Log(LOGERROR, \"{}: Error opening file {}\", __FUNCTION__, file.GetDynPath());\n    if (m_pInputStream.use_count() > 1)\n      throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n    m_pInputStream.reset();\n    return false;\n  }\n\n  m_pDemuxer = NULL;\n\n  try\n  {\n    m_pDemuxer = CDVDFactoryDemuxer::CreateDemuxer(m_pInputStream);\n    if (!m_pDemuxer)\n    {\n      if (m_pInputStream.use_count() > 1)\n        throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n      m_pInputStream.reset();\n      CLog::Log(LOGERROR, \"{}: Error creating demuxer\", __FUNCTION__);\n      return false;\n    }\n  }\n  catch(...)\n  {\n    CLog::Log(LOGERROR, \"{}: Exception thrown when opening demuxer\", __FUNCTION__);\n    if (m_pDemuxer)\n    {\n      delete m_pDemuxer;\n      m_pDemuxer = NULL;\n    }\n    return false;\n  }\n\n  CDemuxStream* pStream = NULL;\n  m_nAudioStream = -1;\n  int64_t demuxerId = -1;\n  for (auto stream : m_pDemuxer->GetStreams())\n  {\n    if (stream && stream->type == STREAM_AUDIO)\n    {\n      m_nAudioStream = stream->uniqueId;\n      demuxerId = stream->demuxerId;\n      pStream = stream;\n      break;\n    }\n  }\n\n  if (m_nAudioStream == -1)\n  {\n    CLog::Log(LOGERROR, \"{}: Could not find audio stream\", __FUNCTION__);\n    delete m_pDemuxer;\n    m_pDemuxer = NULL;\n    if (m_pInputStream.use_count() > 1)\n      throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n    m_pInputStream.reset();\n    return false;\n  }\n\n  CDVDStreamInfo hint(*pStream, true);\n\n  CAEStreamInfo::DataType ptStreamTye =\n      GetPassthroughStreamType(hint.codec, hint.samplerate, hint.profile);\n  m_pAudioCodec = CDVDFactoryCodec::CreateAudioCodec(hint, *m_processInfo, true, true, ptStreamTye);\n  if (!m_pAudioCodec)\n  {\n    CLog::Log(LOGERROR, \"{}: Could not create audio codec\", __FUNCTION__);\n    delete m_pDemuxer;\n    m_pDemuxer = NULL;\n    if (m_pInputStream.use_count() > 1)\n      throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n    m_pInputStream.reset();\n    return false;\n  }\n\n  //  Extract ReplayGain info\n  // tagLoaderTagLib.Load will try to determine tag type by file extension, so set fallback by contentType\n  std::string strFallbackFileExtension = \"\";\n  if (m_strContentType == \"audio/aacp\" ||\n      m_strContentType == \"audio/aac\")\n    strFallbackFileExtension = \"m4a\";\n  else if (m_strContentType == \"audio/x-ms-wma\")\n    strFallbackFileExtension = \"wma\";\n  else if (m_strContentType == \"audio/x-ape\" ||\n           m_strContentType == \"audio/ape\")\n    strFallbackFileExtension = \"ape\";\n  CTagLoaderTagLib tagLoaderTagLib;\n  tagLoaderTagLib.Load(file.GetDynPath(), m_tag, strFallbackFileExtension);\n\n  // we have to decode initial data in order to get channels/samplerate\n  // for sanity - we read no more than 10 packets\n  int nErrors = 0;\n  for (int nPacket=0; nPacket < 10 && (m_channels == 0 || m_format.m_sampleRate == 0); nPacket++)\n  {\n    uint8_t dummy[256];\n    size_t nSize = 256;\n    if (ReadPCM(dummy, nSize, &nSize) == READ_ERROR)\n      ++nErrors;\n\n    m_srcFormat = m_pAudioCodec->GetFormat();\n    m_format = m_srcFormat;\n    m_channels = m_srcFormat.m_channelLayout.Count();\n    m_bitsPerSample = CAEUtil::DataFormatToBits(m_srcFormat.m_dataFormat);\n    m_bitsPerCodedSample = static_cast<CDemuxStreamAudio*>(pStream)->iBitsPerSample;\n  }\n  if (nErrors >= 10)\n  {\n    CLog::Log(LOGDEBUG, \"{}: Could not decode data\", __FUNCTION__);\n    return false;\n  }\n\n  // test if seeking is supported\n  m_bCanSeek = false;\n  if (m_pInputStream->Seek(0, SEEK_POSSIBLE))\n  {\n    if (Seek(1))\n    {\n      // rewind stream to beginning\n      Seek(0);\n      m_bCanSeek = true;\n    }\n    else\n    {\n      m_pInputStream->Seek(0, SEEK_SET);\n      if (!m_pDemuxer->Reset())\n        return false;\n    }\n  }\n\n  if (m_channels == 0) // no data - just guess and hope for the best\n  {\n    m_srcFormat.m_channelLayout = CAEChannelInfo(AE_CH_LAYOUT_2_0);\n    m_channels = m_srcFormat.m_channelLayout.Count();\n  }\n\n  if (m_srcFormat.m_sampleRate == 0)\n    m_srcFormat.m_sampleRate = 44100;\n\n  m_TotalTime = m_pDemuxer->GetStreamLength();\n  m_bitRate = m_pAudioCodec->GetBitRate();\n  if (!m_bitRate && m_TotalTime)\n  {\n    m_bitRate = (int)(((m_pInputStream->GetLength()*1000) / m_TotalTime) * 8);\n  }\n  m_CodecName = m_pDemuxer->GetStreamCodecName(demuxerId, m_nAudioStream);\n\n  m_needConvert = false;\n  if (NeedConvert(m_srcFormat.m_dataFormat))\n  {\n    m_needConvert = true;\n    m_pResampler = ActiveAE::CAEResampleFactory::Create();\n\n    SampleConfig dstConfig, srcConfig;\n    dstConfig.channel_layout = CAEUtil::GetAVChannelLayout(m_srcFormat.m_channelLayout);\n    dstConfig.channels = m_channels;\n    dstConfig.sample_rate = m_srcFormat.m_sampleRate;\n    dstConfig.fmt = CAEUtil::GetAVSampleFormat(AE_FMT_FLOAT);\n    dstConfig.bits_per_sample = CAEUtil::DataFormatToUsedBits(AE_FMT_FLOAT);\n    dstConfig.dither_bits = CAEUtil::DataFormatToDitherBits(AE_FMT_FLOAT);\n\n    srcConfig.channel_layout = CAEUtil::GetAVChannelLayout(m_srcFormat.m_channelLayout);\n    srcConfig.channels = m_channels;\n    srcConfig.sample_rate = m_srcFormat.m_sampleRate;\n    srcConfig.fmt = CAEUtil::GetAVSampleFormat(m_srcFormat.m_dataFormat);\n    srcConfig.bits_per_sample = CAEUtil::DataFormatToUsedBits(m_srcFormat.m_dataFormat);\n    srcConfig.dither_bits = CAEUtil::DataFormatToDitherBits(m_srcFormat.m_dataFormat);\n\n    m_pResampler->Init(dstConfig, srcConfig,\n                       false,\n                       false,\n                       M_SQRT1_2,\n                       NULL,\n                       AE_QUALITY_UNKNOWN,\n                       false);\n\n    m_planes = AE_IS_PLANAR(m_srcFormat.m_dataFormat) ? m_channels : 1;\n    m_format = m_srcFormat;\n    m_format.m_dataFormat = AE_FMT_FLOAT;\n    m_bitsPerSample = CAEUtil::DataFormatToBits(m_format.m_dataFormat);\n  }\n\n  m_strFileName = file.GetDynPath();\n  m_bInited = true;\n\n  return true;\n}",
        "func": "bool VideoPlayerCodec::Init(const CFileItem &file, unsigned int filecache)\n{\n  // take precaution if Init()ialized earlier\n  if (m_bInited)\n  {\n    // keep things as is if Init() was done with known strFile\n    if (m_strFileName == file.GetDynPath())\n      return true;\n\n    // got differing filename, so cleanup before starting over\n    DeInit();\n  }\n\n  m_nDecodedLen = 0;\n\n  CFileItem fileitem(file);\n  fileitem.SetMimeType(m_strContentType);\n  fileitem.SetMimeTypeForInternetFile();\n  m_pInputStream = CDVDFactoryInputStream::CreateInputStream(NULL, fileitem);\n  if (!m_pInputStream)\n  {\n    CLog::Log(LOGERROR, \"{}: Error creating input stream for {}\", __FUNCTION__, file.GetDynPath());\n    return false;\n  }\n\n  //! @todo\n  //! convey CFileItem::ContentLookup() into Open()\n  if (!m_pInputStream->Open())\n  {\n    CLog::Log(LOGERROR, \"{}: Error opening file {}\", __FUNCTION__, file.GetDynPath());\n    if (m_pInputStream.use_count() > 1)\n      throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n    m_pInputStream.reset();\n    return false;\n  }\n\n  m_pDemuxer = NULL;\n\n  try\n  {\n    m_pDemuxer = CDVDFactoryDemuxer::CreateDemuxer(m_pInputStream);\n    if (!m_pDemuxer)\n    {\n      if (m_pInputStream.use_count() > 1)\n        throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n      m_pInputStream.reset();\n      CLog::Log(LOGERROR, \"{}: Error creating demuxer\", __FUNCTION__);\n      return false;\n    }\n  }\n  catch(...)\n  {\n    CLog::Log(LOGERROR, \"{}: Exception thrown when opening demuxer\", __FUNCTION__);\n    if (m_pDemuxer)\n    {\n      delete m_pDemuxer;\n      m_pDemuxer = NULL;\n    }\n    return false;\n  }\n\n  CDemuxStream* pStream = NULL;\n  m_nAudioStream = -1;\n  int64_t demuxerId = -1;\n  for (auto stream : m_pDemuxer->GetStreams())\n  {\n    if (stream && stream->type == STREAM_AUDIO)\n    {\n      m_nAudioStream = stream->uniqueId;\n      demuxerId = stream->demuxerId;\n      pStream = stream;\n      break;\n    }\n  }\n\n  if (m_nAudioStream == -1)\n  {\n    CLog::Log(LOGERROR, \"{}: Could not find audio stream\", __FUNCTION__);\n    delete m_pDemuxer;\n    m_pDemuxer = NULL;\n    if (m_pInputStream.use_count() > 1)\n      throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n    m_pInputStream.reset();\n    return false;\n  }\n\n  CDVDStreamInfo hint(*pStream, true);\n\n  CAEStreamInfo::DataType ptStreamTye =\n      GetPassthroughStreamType(hint.codec, hint.samplerate, hint.profile);\n  m_pAudioCodec = CDVDFactoryCodec::CreateAudioCodec(hint, *m_processInfo, true, true, ptStreamTye);\n  if (!m_pAudioCodec)\n  {\n    CLog::Log(LOGERROR, \"{}: Could not create audio codec\", __FUNCTION__);\n    delete m_pDemuxer;\n    m_pDemuxer = NULL;\n    if (m_pInputStream.use_count() > 1)\n      throw std::runtime_error(\"m_pInputStream reference count is greater than 1\");\n    m_pInputStream.reset();\n    return false;\n  }\n\n  //  Extract ReplayGain info\n  // tagLoaderTagLib.Load will try to determine tag type by file extension, so set fallback by contentType\n  std::string strFallbackFileExtension = \"\";\n  if (m_strContentType == \"audio/aacp\" ||\n      m_strContentType == \"audio/aac\")\n    strFallbackFileExtension = \"m4a\";\n  else if (m_strContentType == \"audio/x-ms-wma\")\n    strFallbackFileExtension = \"wma\";\n  else if (m_strContentType == \"audio/x-ape\" ||\n           m_strContentType == \"audio/ape\")\n    strFallbackFileExtension = \"ape\";\n  CTagLoaderTagLib tagLoaderTagLib;\n  tagLoaderTagLib.Load(file.GetDynPath(), m_tag, strFallbackFileExtension);\n\n  // we have to decode initial data in order to get channels/samplerate\n  // for sanity - we read no more than 10 packets\n  int nErrors = 0;\n  for (int nPacket = 0;\n       nPacket < 10 && (m_channels == 0 || m_format.m_sampleRate == 0 || m_format.m_frameSize == 0);\n       nPacket++)\n  {\n    uint8_t dummy[256];\n    size_t nSize = 256;\n    if (ReadPCM(dummy, nSize, &nSize) == READ_ERROR)\n      ++nErrors;\n\n    m_srcFormat = m_pAudioCodec->GetFormat();\n    m_format = m_srcFormat;\n    m_channels = m_srcFormat.m_channelLayout.Count();\n    m_bitsPerSample = CAEUtil::DataFormatToBits(m_srcFormat.m_dataFormat);\n    m_bitsPerCodedSample = static_cast<CDemuxStreamAudio*>(pStream)->iBitsPerSample;\n  }\n  if (nErrors >= 10)\n  {\n    CLog::Log(LOGDEBUG, \"{}: Could not decode data\", __FUNCTION__);\n    return false;\n  }\n\n  // test if seeking is supported\n  m_bCanSeek = false;\n  if (m_pInputStream->Seek(0, SEEK_POSSIBLE))\n  {\n    if (Seek(1))\n    {\n      // rewind stream to beginning\n      Seek(0);\n      m_bCanSeek = true;\n    }\n    else\n    {\n      m_pInputStream->Seek(0, SEEK_SET);\n      if (!m_pDemuxer->Reset())\n        return false;\n    }\n  }\n\n  if (m_channels == 0) // no data - just guess and hope for the best\n  {\n    m_srcFormat.m_channelLayout = CAEChannelInfo(AE_CH_LAYOUT_2_0);\n    m_channels = m_srcFormat.m_channelLayout.Count();\n  }\n\n  if (m_srcFormat.m_sampleRate == 0)\n    m_srcFormat.m_sampleRate = 44100;\n\n  m_TotalTime = m_pDemuxer->GetStreamLength();\n  m_bitRate = m_pAudioCodec->GetBitRate();\n  if (!m_bitRate && m_TotalTime)\n  {\n    m_bitRate = (int)(((m_pInputStream->GetLength()*1000) / m_TotalTime) * 8);\n  }\n  m_CodecName = m_pDemuxer->GetStreamCodecName(demuxerId, m_nAudioStream);\n\n  m_needConvert = false;\n  if (NeedConvert(m_srcFormat.m_dataFormat))\n  {\n    m_needConvert = true;\n    // if we don't know the framesize yet, we will fail when converting\n    if (m_srcFormat.m_frameSize == 0)\n      return false;\n\n    m_pResampler = ActiveAE::CAEResampleFactory::Create();\n\n    SampleConfig dstConfig, srcConfig;\n    dstConfig.channel_layout = CAEUtil::GetAVChannelLayout(m_srcFormat.m_channelLayout);\n    dstConfig.channels = m_channels;\n    dstConfig.sample_rate = m_srcFormat.m_sampleRate;\n    dstConfig.fmt = CAEUtil::GetAVSampleFormat(AE_FMT_FLOAT);\n    dstConfig.bits_per_sample = CAEUtil::DataFormatToUsedBits(AE_FMT_FLOAT);\n    dstConfig.dither_bits = CAEUtil::DataFormatToDitherBits(AE_FMT_FLOAT);\n\n    srcConfig.channel_layout = CAEUtil::GetAVChannelLayout(m_srcFormat.m_channelLayout);\n    srcConfig.channels = m_channels;\n    srcConfig.sample_rate = m_srcFormat.m_sampleRate;\n    srcConfig.fmt = CAEUtil::GetAVSampleFormat(m_srcFormat.m_dataFormat);\n    srcConfig.bits_per_sample = CAEUtil::DataFormatToUsedBits(m_srcFormat.m_dataFormat);\n    srcConfig.dither_bits = CAEUtil::DataFormatToDitherBits(m_srcFormat.m_dataFormat);\n\n    m_pResampler->Init(dstConfig, srcConfig,\n                       false,\n                       false,\n                       M_SQRT1_2,\n                       NULL,\n                       AE_QUALITY_UNKNOWN,\n                       false);\n\n    m_planes = AE_IS_PLANAR(m_srcFormat.m_dataFormat) ? m_channels : 1;\n    m_format = m_srcFormat;\n    m_format.m_dataFormat = AE_FMT_FLOAT;\n    m_bitsPerSample = CAEUtil::DataFormatToBits(m_format.m_dataFormat);\n  }\n\n  m_strFileName = file.GetDynPath();\n  m_bInited = true;\n\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -117,7 +117,9 @@\n   // we have to decode initial data in order to get channels/samplerate\n   // for sanity - we read no more than 10 packets\n   int nErrors = 0;\n-  for (int nPacket=0; nPacket < 10 && (m_channels == 0 || m_format.m_sampleRate == 0); nPacket++)\n+  for (int nPacket = 0;\n+       nPacket < 10 && (m_channels == 0 || m_format.m_sampleRate == 0 || m_format.m_frameSize == 0);\n+       nPacket++)\n   {\n     uint8_t dummy[256];\n     size_t nSize = 256;\n@@ -175,6 +177,10 @@\n   if (NeedConvert(m_srcFormat.m_dataFormat))\n   {\n     m_needConvert = true;\n+    // if we don't know the framesize yet, we will fail when converting\n+    if (m_srcFormat.m_frameSize == 0)\n+      return false;\n+\n     m_pResampler = ActiveAE::CAEResampleFactory::Create();\n \n     SampleConfig dstConfig, srcConfig;",
        "diff_line_info": {
            "deleted_lines": [
                "  for (int nPacket=0; nPacket < 10 && (m_channels == 0 || m_format.m_sampleRate == 0); nPacket++)"
            ],
            "added_lines": [
                "  for (int nPacket = 0;",
                "       nPacket < 10 && (m_channels == 0 || m_format.m_sampleRate == 0 || m_format.m_frameSize == 0);",
                "       nPacket++)",
                "    // if we don't know the framesize yet, we will fail when converting",
                "    if (m_srcFormat.m_frameSize == 0)",
                "      return false;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2017-18360",
        "func_name": "torvalds/linux/change_port_settings",
        "description": "In change_port_settings in drivers/usb/serial/io_ti.c in the Linux kernel before 4.11.3, local users could cause a denial of service by division-by-zero in the serial device layer by trying to set very high baud rates.",
        "git_url": "https://github.com/torvalds/linux/commit/6aeb75e6adfaed16e58780309613a578fe1ee90b",
        "commit_title": "USB: serial: io_ti: fix div-by-zero in set_termios",
        "commit_text": " Fix a division-by-zero in set_termios when debugging is enabled and a high-enough speed has been requested so that the divisor value becomes zero.  Instead of just fixing the offending debug statement, cap the baud rate at the base as a zero divisor value also appears to crash the firmware.  Cc: stable <stable@vger.kernel.org>     # 2.6.12",
        "func_before": "static void change_port_settings(struct tty_struct *tty,\n\t\tstruct edgeport_port *edge_port, struct ktermios *old_termios)\n{\n\tstruct device *dev = &edge_port->port->dev;\n\tstruct ump_uart_config *config;\n\tint baud;\n\tunsigned cflag;\n\tint status;\n\tint port_number = edge_port->port->port_number;\n\n\tconfig = kmalloc (sizeof (*config), GFP_KERNEL);\n\tif (!config) {\n\t\ttty->termios = *old_termios;\n\t\treturn;\n\t}\n\n\tcflag = tty->termios.c_cflag;\n\n\tconfig->wFlags = 0;\n\n\t/* These flags must be set */\n\tconfig->wFlags |= UMP_MASK_UART_FLAGS_RECEIVE_MS_INT;\n\tconfig->wFlags |= UMP_MASK_UART_FLAGS_AUTO_START_ON_ERR;\n\tconfig->bUartMode = (__u8)(edge_port->bUartMode);\n\n\tswitch (cflag & CSIZE) {\n\tcase CS5:\n\t\t    config->bDataBits = UMP_UART_CHAR5BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 5\\n\", __func__);\n\t\t    break;\n\tcase CS6:\n\t\t    config->bDataBits = UMP_UART_CHAR6BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 6\\n\", __func__);\n\t\t    break;\n\tcase CS7:\n\t\t    config->bDataBits = UMP_UART_CHAR7BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 7\\n\", __func__);\n\t\t    break;\n\tdefault:\n\tcase CS8:\n\t\t    config->bDataBits = UMP_UART_CHAR8BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 8\\n\", __func__);\n\t\t\t    break;\n\t}\n\n\tif (cflag & PARENB) {\n\t\tif (cflag & PARODD) {\n\t\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_PARITY;\n\t\t\tconfig->bParity = UMP_UART_ODDPARITY;\n\t\t\tdev_dbg(dev, \"%s - parity = odd\\n\", __func__);\n\t\t} else {\n\t\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_PARITY;\n\t\t\tconfig->bParity = UMP_UART_EVENPARITY;\n\t\t\tdev_dbg(dev, \"%s - parity = even\\n\", __func__);\n\t\t}\n\t} else {\n\t\tconfig->bParity = UMP_UART_NOPARITY;\n\t\tdev_dbg(dev, \"%s - parity = none\\n\", __func__);\n\t}\n\n\tif (cflag & CSTOPB) {\n\t\tconfig->bStopBits = UMP_UART_STOPBIT2;\n\t\tdev_dbg(dev, \"%s - stop bits = 2\\n\", __func__);\n\t} else {\n\t\tconfig->bStopBits = UMP_UART_STOPBIT1;\n\t\tdev_dbg(dev, \"%s - stop bits = 1\\n\", __func__);\n\t}\n\n\t/* figure out the flow control settings */\n\tif (cflag & CRTSCTS) {\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_OUT_X_CTS_FLOW;\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_RTS_FLOW;\n\t\tdev_dbg(dev, \"%s - RTS/CTS is enabled\\n\", __func__);\n\t} else {\n\t\tdev_dbg(dev, \"%s - RTS/CTS is disabled\\n\", __func__);\n\t\trestart_read(edge_port);\n\t}\n\n\t/*\n\t * if we are implementing XON/XOFF, set the start and stop\n\t * character in the device\n\t */\n\tconfig->cXon  = START_CHAR(tty);\n\tconfig->cXoff = STOP_CHAR(tty);\n\n\t/* if we are implementing INBOUND XON/XOFF */\n\tif (I_IXOFF(tty)) {\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_IN_X;\n\t\tdev_dbg(dev, \"%s - INBOUND XON/XOFF is enabled, XON = %2x, XOFF = %2x\\n\",\n\t\t\t__func__, config->cXon, config->cXoff);\n\t} else\n\t\tdev_dbg(dev, \"%s - INBOUND XON/XOFF is disabled\\n\", __func__);\n\n\t/* if we are implementing OUTBOUND XON/XOFF */\n\tif (I_IXON(tty)) {\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_OUT_X;\n\t\tdev_dbg(dev, \"%s - OUTBOUND XON/XOFF is enabled, XON = %2x, XOFF = %2x\\n\",\n\t\t\t__func__, config->cXon, config->cXoff);\n\t} else\n\t\tdev_dbg(dev, \"%s - OUTBOUND XON/XOFF is disabled\\n\", __func__);\n\n\ttty->termios.c_cflag &= ~CMSPAR;\n\n\t/* Round the baud rate */\n\tbaud = tty_get_baud_rate(tty);\n\tif (!baud) {\n\t\t/* pick a default, any default... */\n\t\tbaud = 9600;\n\t} else\n\t\ttty_encode_baud_rate(tty, baud, baud);\n\n\tedge_port->baud_rate = baud;\n\tconfig->wBaudRate = (__u16)((461550L + baud/2) / baud);\n\n\t/* FIXME: Recompute actual baud from divisor here */\n\n\tdev_dbg(dev, \"%s - baud rate = %d, wBaudRate = %d\\n\", __func__, baud, config->wBaudRate);\n\n\tdev_dbg(dev, \"wBaudRate:   %d\\n\", (int)(461550L / config->wBaudRate));\n\tdev_dbg(dev, \"wFlags:    0x%x\\n\", config->wFlags);\n\tdev_dbg(dev, \"bDataBits:   %d\\n\", config->bDataBits);\n\tdev_dbg(dev, \"bParity:     %d\\n\", config->bParity);\n\tdev_dbg(dev, \"bStopBits:   %d\\n\", config->bStopBits);\n\tdev_dbg(dev, \"cXon:        %d\\n\", config->cXon);\n\tdev_dbg(dev, \"cXoff:       %d\\n\", config->cXoff);\n\tdev_dbg(dev, \"bUartMode:   %d\\n\", config->bUartMode);\n\n\t/* move the word values into big endian mode */\n\tcpu_to_be16s(&config->wFlags);\n\tcpu_to_be16s(&config->wBaudRate);\n\n\tstatus = send_cmd(edge_port->port->serial->dev, UMPC_SET_CONFIG,\n\t\t\t\t(__u8)(UMPM_UART1_PORT + port_number),\n\t\t\t\t0, (__u8 *)config, sizeof(*config));\n\tif (status)\n\t\tdev_dbg(dev, \"%s - error %d when trying to write config to device\\n\",\n\t\t\t__func__, status);\n\tkfree(config);\n}",
        "func": "static void change_port_settings(struct tty_struct *tty,\n\t\tstruct edgeport_port *edge_port, struct ktermios *old_termios)\n{\n\tstruct device *dev = &edge_port->port->dev;\n\tstruct ump_uart_config *config;\n\tint baud;\n\tunsigned cflag;\n\tint status;\n\tint port_number = edge_port->port->port_number;\n\n\tconfig = kmalloc (sizeof (*config), GFP_KERNEL);\n\tif (!config) {\n\t\ttty->termios = *old_termios;\n\t\treturn;\n\t}\n\n\tcflag = tty->termios.c_cflag;\n\n\tconfig->wFlags = 0;\n\n\t/* These flags must be set */\n\tconfig->wFlags |= UMP_MASK_UART_FLAGS_RECEIVE_MS_INT;\n\tconfig->wFlags |= UMP_MASK_UART_FLAGS_AUTO_START_ON_ERR;\n\tconfig->bUartMode = (__u8)(edge_port->bUartMode);\n\n\tswitch (cflag & CSIZE) {\n\tcase CS5:\n\t\t    config->bDataBits = UMP_UART_CHAR5BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 5\\n\", __func__);\n\t\t    break;\n\tcase CS6:\n\t\t    config->bDataBits = UMP_UART_CHAR6BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 6\\n\", __func__);\n\t\t    break;\n\tcase CS7:\n\t\t    config->bDataBits = UMP_UART_CHAR7BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 7\\n\", __func__);\n\t\t    break;\n\tdefault:\n\tcase CS8:\n\t\t    config->bDataBits = UMP_UART_CHAR8BITS;\n\t\t    dev_dbg(dev, \"%s - data bits = 8\\n\", __func__);\n\t\t\t    break;\n\t}\n\n\tif (cflag & PARENB) {\n\t\tif (cflag & PARODD) {\n\t\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_PARITY;\n\t\t\tconfig->bParity = UMP_UART_ODDPARITY;\n\t\t\tdev_dbg(dev, \"%s - parity = odd\\n\", __func__);\n\t\t} else {\n\t\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_PARITY;\n\t\t\tconfig->bParity = UMP_UART_EVENPARITY;\n\t\t\tdev_dbg(dev, \"%s - parity = even\\n\", __func__);\n\t\t}\n\t} else {\n\t\tconfig->bParity = UMP_UART_NOPARITY;\n\t\tdev_dbg(dev, \"%s - parity = none\\n\", __func__);\n\t}\n\n\tif (cflag & CSTOPB) {\n\t\tconfig->bStopBits = UMP_UART_STOPBIT2;\n\t\tdev_dbg(dev, \"%s - stop bits = 2\\n\", __func__);\n\t} else {\n\t\tconfig->bStopBits = UMP_UART_STOPBIT1;\n\t\tdev_dbg(dev, \"%s - stop bits = 1\\n\", __func__);\n\t}\n\n\t/* figure out the flow control settings */\n\tif (cflag & CRTSCTS) {\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_OUT_X_CTS_FLOW;\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_RTS_FLOW;\n\t\tdev_dbg(dev, \"%s - RTS/CTS is enabled\\n\", __func__);\n\t} else {\n\t\tdev_dbg(dev, \"%s - RTS/CTS is disabled\\n\", __func__);\n\t\trestart_read(edge_port);\n\t}\n\n\t/*\n\t * if we are implementing XON/XOFF, set the start and stop\n\t * character in the device\n\t */\n\tconfig->cXon  = START_CHAR(tty);\n\tconfig->cXoff = STOP_CHAR(tty);\n\n\t/* if we are implementing INBOUND XON/XOFF */\n\tif (I_IXOFF(tty)) {\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_IN_X;\n\t\tdev_dbg(dev, \"%s - INBOUND XON/XOFF is enabled, XON = %2x, XOFF = %2x\\n\",\n\t\t\t__func__, config->cXon, config->cXoff);\n\t} else\n\t\tdev_dbg(dev, \"%s - INBOUND XON/XOFF is disabled\\n\", __func__);\n\n\t/* if we are implementing OUTBOUND XON/XOFF */\n\tif (I_IXON(tty)) {\n\t\tconfig->wFlags |= UMP_MASK_UART_FLAGS_OUT_X;\n\t\tdev_dbg(dev, \"%s - OUTBOUND XON/XOFF is enabled, XON = %2x, XOFF = %2x\\n\",\n\t\t\t__func__, config->cXon, config->cXoff);\n\t} else\n\t\tdev_dbg(dev, \"%s - OUTBOUND XON/XOFF is disabled\\n\", __func__);\n\n\ttty->termios.c_cflag &= ~CMSPAR;\n\n\t/* Round the baud rate */\n\tbaud = tty_get_baud_rate(tty);\n\tif (!baud) {\n\t\t/* pick a default, any default... */\n\t\tbaud = 9600;\n\t} else {\n\t\t/* Avoid a zero divisor. */\n\t\tbaud = min(baud, 461550);\n\t\ttty_encode_baud_rate(tty, baud, baud);\n\t}\n\n\tedge_port->baud_rate = baud;\n\tconfig->wBaudRate = (__u16)((461550L + baud/2) / baud);\n\n\t/* FIXME: Recompute actual baud from divisor here */\n\n\tdev_dbg(dev, \"%s - baud rate = %d, wBaudRate = %d\\n\", __func__, baud, config->wBaudRate);\n\n\tdev_dbg(dev, \"wBaudRate:   %d\\n\", (int)(461550L / config->wBaudRate));\n\tdev_dbg(dev, \"wFlags:    0x%x\\n\", config->wFlags);\n\tdev_dbg(dev, \"bDataBits:   %d\\n\", config->bDataBits);\n\tdev_dbg(dev, \"bParity:     %d\\n\", config->bParity);\n\tdev_dbg(dev, \"bStopBits:   %d\\n\", config->bStopBits);\n\tdev_dbg(dev, \"cXon:        %d\\n\", config->cXon);\n\tdev_dbg(dev, \"cXoff:       %d\\n\", config->cXoff);\n\tdev_dbg(dev, \"bUartMode:   %d\\n\", config->bUartMode);\n\n\t/* move the word values into big endian mode */\n\tcpu_to_be16s(&config->wFlags);\n\tcpu_to_be16s(&config->wBaudRate);\n\n\tstatus = send_cmd(edge_port->port->serial->dev, UMPC_SET_CONFIG,\n\t\t\t\t(__u8)(UMPM_UART1_PORT + port_number),\n\t\t\t\t0, (__u8 *)config, sizeof(*config));\n\tif (status)\n\t\tdev_dbg(dev, \"%s - error %d when trying to write config to device\\n\",\n\t\t\t__func__, status);\n\tkfree(config);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -106,8 +106,11 @@\n \tif (!baud) {\n \t\t/* pick a default, any default... */\n \t\tbaud = 9600;\n-\t} else\n+\t} else {\n+\t\t/* Avoid a zero divisor. */\n+\t\tbaud = min(baud, 461550);\n \t\ttty_encode_baud_rate(tty, baud, baud);\n+\t}\n \n \tedge_port->baud_rate = baud;\n \tconfig->wBaudRate = (__u16)((461550L + baud/2) / baud);",
        "diff_line_info": {
            "deleted_lines": [
                "\t} else"
            ],
            "added_lines": [
                "\t} else {",
                "\t\t/* Avoid a zero divisor. */",
                "\t\tbaud = min(baud, 461550);",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-11472",
        "func_name": "ImageMagick/ReadXWDImage",
        "description": "ReadXWDImage in coders/xwd.c in the XWD image parsing component of ImageMagick 7.0.8-41 Q16 allows attackers to cause a denial-of-service (divide-by-zero error) by crafting an XWD image file in which the header indicates neither LSB first nor MSB first.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/ab3e2be9b387919ef5c25977c4c054fb9dc089a6",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/1546",
        "commit_text": "",
        "func_before": "static Image *ReadXWDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CheckOverflowException(length,width,height) \\\n  (((height) != 0) && ((length)/((size_t) height) != ((size_t) width)))\n\n  char\n    *comment;\n\n  Image\n    *image;\n\n  int\n    x_status;\n\n  MagickBooleanType\n    authentic_colormap;\n\n  MagickStatusType\n    status;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register size_t\n    pixel;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned long\n    lsb_first;\n\n  XColor\n    *colors;\n\n  XImage\n    *ximage;\n\n  XWDFileHeader\n    header;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read in header information.\n  */\n  count=ReadBlob(image,sz_XWDheader,(unsigned char *) &header);\n  if (count != sz_XWDheader)\n    ThrowReaderException(CorruptImageError,\"UnableToReadImageHeader\");\n  /*\n    Ensure the header byte-order is most-significant byte first.\n  */\n  lsb_first=1;\n  if ((int) (*(char *) &lsb_first) != 0)\n    MSBOrderLong((unsigned char *) &header,sz_XWDheader);\n  /*\n    Check to see if the dump file is in the proper format.\n  */\n  if (header.file_version != XWD_FILE_VERSION)\n    ThrowReaderException(CorruptImageError,\"FileFormatVersionMismatch\");\n  if (header.header_size < sz_XWDheader)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if ((header.bits_per_pixel == 0) || (header.bits_per_pixel > 32))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (((header.bitmap_pad % 8) != 0) || (header.bitmap_pad > 32))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (header.bitmap_unit > 32)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (header.ncolors > 256)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  switch (header.visual_class)\n  {\n    case StaticGray:\n    case GrayScale:\n    case StaticColor:\n    case PseudoColor:\n    case TrueColor:\n    case DirectColor:\n      break;\n    default:\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  }\n  switch (header.pixmap_format)\n  {\n    case XYBitmap:\n    case XYPixmap:\n    case ZPixmap:\n      break;\n    default:\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  }\n  length=(size_t) (header.header_size-sz_XWDheader);\n  comment=(char *) AcquireQuantumMemory(length+1,sizeof(*comment));\n  if (comment == (char *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  count=ReadBlob(image,length,(unsigned char *) comment);\n  comment[length]='\\0';\n  (void) SetImageProperty(image,\"comment\",comment,exception);\n  comment=DestroyString(comment);\n  if (count != (ssize_t) length)\n    ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n  /*\n    Initialize the X image.\n  */\n  ximage=(XImage *) AcquireMagickMemory(sizeof(*ximage));\n  if (ximage == (XImage *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  ximage->depth=(int) header.pixmap_depth;\n  ximage->format=(int) header.pixmap_format;\n  ximage->xoffset=(int) header.xoffset;\n  ximage->data=(char *) NULL;\n  ximage->width=(int) header.pixmap_width;\n  ximage->height=(int) header.pixmap_height;\n  ximage->bitmap_pad=(int) header.bitmap_pad;\n  ximage->bytes_per_line=(int) header.bytes_per_line;\n  ximage->byte_order=(int) header.byte_order;\n  ximage->bitmap_unit=(int) header.bitmap_unit;\n  ximage->bitmap_bit_order=(int) header.bitmap_bit_order;\n  ximage->bits_per_pixel=(int) header.bits_per_pixel;\n  ximage->red_mask=header.red_mask;\n  ximage->green_mask=header.green_mask;\n  ximage->blue_mask=header.blue_mask;\n  if ((ximage->width < 0) || (ximage->height < 0) || (ximage->depth < 0) ||\n      (ximage->format < 0) || (ximage->byte_order < 0) ||\n      (ximage->bitmap_bit_order < 0) || (ximage->bitmap_pad < 0) ||\n      (ximage->bytes_per_line < 0))\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  if ((ximage->width > 65535) || (ximage->height > 65535))\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  if ((ximage->bits_per_pixel > 32) || (ximage->bitmap_unit > 32))\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  x_status=XInitImage(ximage);\n  if (x_status == 0)\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    }\n  /*\n    Read colormap.\n  */\n  authentic_colormap=MagickFalse;\n  colors=(XColor *) NULL;\n  if (header.ncolors != 0)\n    {\n      XWDColor\n        color;\n\n      length=(size_t) header.ncolors;\n      if (length > ((~0UL)/sizeof(*colors)))\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      colors=(XColor *) AcquireQuantumMemory(length,sizeof(*colors));\n      if (colors == (XColor *) NULL)\n        {\n          ximage=(XImage *) RelinquishMagickMemory(ximage);\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      for (i=0; i < (ssize_t) header.ncolors; i++)\n      {\n        count=ReadBlob(image,sz_XWDColor,(unsigned char *) &color);\n        if (count != sz_XWDColor)\n          {\n            colors=(XColor *) RelinquishMagickMemory(colors);\n            ximage=(XImage *) RelinquishMagickMemory(ximage);\n            ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n          }\n        colors[i].pixel=color.pixel;\n        colors[i].red=color.red;\n        colors[i].green=color.green;\n        colors[i].blue=color.blue;\n        colors[i].flags=(char) color.flags;\n        if (color.flags != 0)\n          authentic_colormap=MagickTrue;\n      }\n      /*\n        Ensure the header byte-order is most-significant byte first.\n      */\n      lsb_first=1;\n      if ((int) (*(char *) &lsb_first) != 0)\n        for (i=0; i < (ssize_t) header.ncolors; i++)\n        {\n          MSBOrderLong((unsigned char *) &colors[i].pixel,\n            sizeof(colors[i].pixel));\n          MSBOrderShort((unsigned char *) &colors[i].red,3*\n            sizeof(colors[i].red));\n        }\n    }\n  /*\n    Allocate the pixel buffer.\n  */\n  length=(size_t) ximage->bytes_per_line*ximage->height;\n  if (CheckOverflowException(length,ximage->bytes_per_line,ximage->height))\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  if (ximage->format != ZPixmap)\n    {\n      size_t\n        extent;\n\n      extent=length;\n      length*=ximage->depth;\n      if (CheckOverflowException(length,extent,ximage->depth))\n        {\n          if (header.ncolors != 0)\n            colors=(XColor *) RelinquishMagickMemory(colors);\n          ximage=(XImage *) RelinquishMagickMemory(ximage);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n    }\n  ximage->data=(char *) AcquireQuantumMemory(length,sizeof(*ximage->data));\n  if (ximage->data == (char *) NULL)\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  count=ReadBlob(image,length,(unsigned char *) ximage->data);\n  if (count != (ssize_t) length)\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage->data=DestroyString(ximage->data);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    }\n  /*\n    Convert image to MIFF format.\n  */\n  image->columns=(size_t) ximage->width;\n  image->rows=(size_t) ximage->height;\n  image->depth=8;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage->data=DestroyString(ximage->data);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      return(DestroyImageList(image));\n    }\n  if ((header.ncolors == 0U) || (ximage->red_mask != 0) ||\n      (ximage->green_mask != 0) || (ximage->blue_mask != 0))\n    image->storage_class=DirectClass;\n  else\n    image->storage_class=PseudoClass;\n  image->colors=header.ncolors;\n  if (image_info->ping == MagickFalse)\n    switch (image->storage_class)\n    {\n      case DirectClass:\n      default:\n      {\n        register size_t\n          color;\n\n        size_t\n          blue_mask,\n          blue_shift,\n          green_mask,\n          green_shift,\n          red_mask,\n          red_shift;\n\n        /*\n          Determine shift and mask for red, green, and blue.\n        */\n        red_mask=ximage->red_mask;\n        red_shift=0;\n        while ((red_mask != 0) && ((red_mask & 0x01) == 0))\n        {\n          red_mask>>=1;\n          red_shift++;\n        }\n        green_mask=ximage->green_mask;\n        green_shift=0;\n        while ((green_mask != 0) && ((green_mask & 0x01) == 0))\n        {\n          green_mask>>=1;\n          green_shift++;\n        }\n        blue_mask=ximage->blue_mask;\n        blue_shift=0;\n        while ((blue_mask != 0) && ((blue_mask & 0x01) == 0))\n        {\n          blue_mask>>=1;\n          blue_shift++;\n        }\n        /*\n          Convert X image to DirectClass packets.\n        */\n        if ((image->colors != 0) && (authentic_colormap != MagickFalse))\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              pixel=XGetPixel(ximage,(int) x,(int) y);\n              index=(Quantum) ConstrainColormapIndex(image,(ssize_t) (pixel >>\n                red_shift) & red_mask,exception);\n              SetPixelRed(image,ScaleShortToQuantum(\n                colors[(ssize_t) index].red),q);\n              index=(Quantum) ConstrainColormapIndex(image,(ssize_t) (pixel >>\n                green_shift) & green_mask,exception);\n              SetPixelGreen(image,ScaleShortToQuantum(\n                colors[(ssize_t) index].green),q);\n              index=(Quantum) ConstrainColormapIndex(image,(ssize_t) (pixel >>\n                blue_shift) & blue_mask,exception);\n              SetPixelBlue(image,ScaleShortToQuantum(\n                colors[(ssize_t) index].blue),q);\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n        else\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              pixel=XGetPixel(ximage,(int) x,(int) y);\n              color=(pixel >> red_shift) & red_mask;\n              if (red_mask != 0)\n                color=(color*65535UL)/red_mask;\n              SetPixelRed(image,ScaleShortToQuantum((unsigned short) color),q);\n              color=(pixel >> green_shift) & green_mask;\n              if (green_mask != 0)\n                color=(color*65535UL)/green_mask;\n              SetPixelGreen(image,ScaleShortToQuantum((unsigned short) color),\n                q);\n              color=(pixel >> blue_shift) & blue_mask;\n              if (blue_mask != 0)\n                color=(color*65535UL)/blue_mask;\n              SetPixelBlue(image,ScaleShortToQuantum((unsigned short) color),q);\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n        break;\n      }\n      case PseudoClass:\n      {\n        /*\n          Convert X image to PseudoClass packets.\n        */\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          {\n            if (header.ncolors != 0)\n              colors=(XColor *) RelinquishMagickMemory(colors);\n            ximage->data=DestroyString(ximage->data);\n            ximage=(XImage *) RelinquishMagickMemory(ximage);\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        for (i=0; i < (ssize_t) image->colors; i++)\n        {\n          image->colormap[i].red=(MagickRealType) ScaleShortToQuantum(\n            colors[i].red);\n          image->colormap[i].green=(MagickRealType) ScaleShortToQuantum(\n            colors[i].green);\n          image->colormap[i].blue=(MagickRealType) ScaleShortToQuantum(\n            colors[i].blue);\n        }\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=(Quantum) ConstrainColormapIndex(image,(ssize_t)\n              XGetPixel(ximage,(int) x,(int) y),exception);\n            SetPixelIndex(image,index,q);\n            SetPixelViaPixelInfo(image,image->colormap+(ssize_t) index,q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n            image->rows);\n          if (status == MagickFalse)\n            break;\n        }\n        break;\n      }\n    }\n  /*\n    Free image and colormap.\n  */\n  if (header.ncolors != 0)\n    colors=(XColor *) RelinquishMagickMemory(colors);\n  ximage->data=DestroyString(ximage->data);\n  ximage=(XImage *) RelinquishMagickMemory(ximage);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "func": "static Image *ReadXWDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CheckOverflowException(length,width,height) \\\n  (((height) != 0) && ((length)/((size_t) height) != ((size_t) width)))\n\n  char\n    *comment;\n\n  Image\n    *image;\n\n  int\n    x_status;\n\n  MagickBooleanType\n    authentic_colormap;\n\n  MagickStatusType\n    status;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register size_t\n    pixel;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned long\n    lsb_first;\n\n  XColor\n    *colors;\n\n  XImage\n    *ximage;\n\n  XWDFileHeader\n    header;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read in header information.\n  */\n  count=ReadBlob(image,sz_XWDheader,(unsigned char *) &header);\n  if (count != sz_XWDheader)\n    ThrowReaderException(CorruptImageError,\"UnableToReadImageHeader\");\n  /*\n    Ensure the header byte-order is most-significant byte first.\n  */\n  lsb_first=1;\n  if ((int) (*(char *) &lsb_first) != 0)\n    MSBOrderLong((unsigned char *) &header,sz_XWDheader);\n  /*\n    Check to see if the dump file is in the proper format.\n  */\n  if (header.file_version != XWD_FILE_VERSION)\n    ThrowReaderException(CorruptImageError,\"FileFormatVersionMismatch\");\n  if (header.header_size < sz_XWDheader)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if ((header.bits_per_pixel == 0) || (header.bits_per_pixel > 32))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if ((header.bitmap_bit_order != MSBFirst) &&\n      (header.bitmap_bit_order != LSBFirst))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (((header.bitmap_pad % 8) != 0) || (header.bitmap_pad > 32))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (header.bitmap_unit > 32)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (header.ncolors > 256)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  switch (header.visual_class)\n  {\n    case StaticGray:\n    case GrayScale:\n    case StaticColor:\n    case PseudoColor:\n    case TrueColor:\n    case DirectColor:\n      break;\n    default:\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  }\n  switch (header.pixmap_format)\n  {\n    case XYBitmap:\n    case XYPixmap:\n    case ZPixmap:\n      break;\n    default:\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  }\n  length=(size_t) (header.header_size-sz_XWDheader);\n  comment=(char *) AcquireQuantumMemory(length+1,sizeof(*comment));\n  if (comment == (char *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  count=ReadBlob(image,length,(unsigned char *) comment);\n  comment[length]='\\0';\n  (void) SetImageProperty(image,\"comment\",comment,exception);\n  comment=DestroyString(comment);\n  if (count != (ssize_t) length)\n    ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n  /*\n    Initialize the X image.\n  */\n  ximage=(XImage *) AcquireMagickMemory(sizeof(*ximage));\n  if (ximage == (XImage *) NULL)\n    ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n  ximage->depth=(int) header.pixmap_depth;\n  ximage->format=(int) header.pixmap_format;\n  ximage->xoffset=(int) header.xoffset;\n  ximage->data=(char *) NULL;\n  ximage->width=(int) header.pixmap_width;\n  ximage->height=(int) header.pixmap_height;\n  ximage->bitmap_pad=(int) header.bitmap_pad;\n  ximage->bytes_per_line=(int) header.bytes_per_line;\n  ximage->byte_order=(int) header.byte_order;\n  ximage->bitmap_unit=(int) header.bitmap_unit;\n  ximage->bitmap_bit_order=(int) header.bitmap_bit_order;\n  ximage->bits_per_pixel=(int) header.bits_per_pixel;\n  ximage->red_mask=header.red_mask;\n  ximage->green_mask=header.green_mask;\n  ximage->blue_mask=header.blue_mask;\n  if ((ximage->width < 0) || (ximage->height < 0) || (ximage->depth < 0) ||\n      (ximage->format < 0) || (ximage->byte_order < 0) ||\n      (ximage->bitmap_bit_order < 0) || (ximage->bitmap_pad < 0) ||\n      (ximage->bytes_per_line < 0))\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  if ((ximage->width > 65535) || (ximage->height > 65535))\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  if ((ximage->bits_per_pixel > 32) || (ximage->bitmap_unit > 32))\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  x_status=XInitImage(ximage);\n  if (x_status == 0)\n    {\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    }\n  /*\n    Read colormap.\n  */\n  authentic_colormap=MagickFalse;\n  colors=(XColor *) NULL;\n  if (header.ncolors != 0)\n    {\n      XWDColor\n        color;\n\n      length=(size_t) header.ncolors;\n      if (length > ((~0UL)/sizeof(*colors)))\n        ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n      colors=(XColor *) AcquireQuantumMemory(length,sizeof(*colors));\n      if (colors == (XColor *) NULL)\n        {\n          ximage=(XImage *) RelinquishMagickMemory(ximage);\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        }\n      for (i=0; i < (ssize_t) header.ncolors; i++)\n      {\n        count=ReadBlob(image,sz_XWDColor,(unsigned char *) &color);\n        if (count != sz_XWDColor)\n          {\n            colors=(XColor *) RelinquishMagickMemory(colors);\n            ximage=(XImage *) RelinquishMagickMemory(ximage);\n            ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n          }\n        colors[i].pixel=color.pixel;\n        colors[i].red=color.red;\n        colors[i].green=color.green;\n        colors[i].blue=color.blue;\n        colors[i].flags=(char) color.flags;\n        if (color.flags != 0)\n          authentic_colormap=MagickTrue;\n      }\n      /*\n        Ensure the header byte-order is most-significant byte first.\n      */\n      lsb_first=1;\n      if ((int) (*(char *) &lsb_first) != 0)\n        for (i=0; i < (ssize_t) header.ncolors; i++)\n        {\n          MSBOrderLong((unsigned char *) &colors[i].pixel,\n            sizeof(colors[i].pixel));\n          MSBOrderShort((unsigned char *) &colors[i].red,3*\n            sizeof(colors[i].red));\n        }\n    }\n  /*\n    Allocate the pixel buffer.\n  */\n  length=(size_t) ximage->bytes_per_line*ximage->height;\n  if (CheckOverflowException(length,ximage->bytes_per_line,ximage->height))\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n  if (ximage->format != ZPixmap)\n    {\n      size_t\n        extent;\n\n      extent=length;\n      length*=ximage->depth;\n      if (CheckOverflowException(length,extent,ximage->depth))\n        {\n          if (header.ncolors != 0)\n            colors=(XColor *) RelinquishMagickMemory(colors);\n          ximage=(XImage *) RelinquishMagickMemory(ximage);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n    }\n  ximage->data=(char *) AcquireQuantumMemory(length,sizeof(*ximage->data));\n  if (ximage->data == (char *) NULL)\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  count=ReadBlob(image,length,(unsigned char *) ximage->data);\n  if (count != (ssize_t) length)\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage->data=DestroyString(ximage->data);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    }\n  /*\n    Convert image to MIFF format.\n  */\n  image->columns=(size_t) ximage->width;\n  image->rows=(size_t) ximage->height;\n  image->depth=8;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    {\n      if (header.ncolors != 0)\n        colors=(XColor *) RelinquishMagickMemory(colors);\n      ximage->data=DestroyString(ximage->data);\n      ximage=(XImage *) RelinquishMagickMemory(ximage);\n      return(DestroyImageList(image));\n    }\n  if ((header.ncolors == 0U) || (ximage->red_mask != 0) ||\n      (ximage->green_mask != 0) || (ximage->blue_mask != 0))\n    image->storage_class=DirectClass;\n  else\n    image->storage_class=PseudoClass;\n  image->colors=header.ncolors;\n  if (image_info->ping == MagickFalse)\n    switch (image->storage_class)\n    {\n      case DirectClass:\n      default:\n      {\n        register size_t\n          color;\n\n        size_t\n          blue_mask,\n          blue_shift,\n          green_mask,\n          green_shift,\n          red_mask,\n          red_shift;\n\n        /*\n          Determine shift and mask for red, green, and blue.\n        */\n        red_mask=ximage->red_mask;\n        red_shift=0;\n        while ((red_mask != 0) && ((red_mask & 0x01) == 0))\n        {\n          red_mask>>=1;\n          red_shift++;\n        }\n        green_mask=ximage->green_mask;\n        green_shift=0;\n        while ((green_mask != 0) && ((green_mask & 0x01) == 0))\n        {\n          green_mask>>=1;\n          green_shift++;\n        }\n        blue_mask=ximage->blue_mask;\n        blue_shift=0;\n        while ((blue_mask != 0) && ((blue_mask & 0x01) == 0))\n        {\n          blue_mask>>=1;\n          blue_shift++;\n        }\n        /*\n          Convert X image to DirectClass packets.\n        */\n        if ((image->colors != 0) && (authentic_colormap != MagickFalse))\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              pixel=XGetPixel(ximage,(int) x,(int) y);\n              index=(Quantum) ConstrainColormapIndex(image,(ssize_t) (pixel >>\n                red_shift) & red_mask,exception);\n              SetPixelRed(image,ScaleShortToQuantum(\n                colors[(ssize_t) index].red),q);\n              index=(Quantum) ConstrainColormapIndex(image,(ssize_t) (pixel >>\n                green_shift) & green_mask,exception);\n              SetPixelGreen(image,ScaleShortToQuantum(\n                colors[(ssize_t) index].green),q);\n              index=(Quantum) ConstrainColormapIndex(image,(ssize_t) (pixel >>\n                blue_shift) & blue_mask,exception);\n              SetPixelBlue(image,ScaleShortToQuantum(\n                colors[(ssize_t) index].blue),q);\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n        else\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              pixel=XGetPixel(ximage,(int) x,(int) y);\n              color=(pixel >> red_shift) & red_mask;\n              if (red_mask != 0)\n                color=(color*65535UL)/red_mask;\n              SetPixelRed(image,ScaleShortToQuantum((unsigned short) color),q);\n              color=(pixel >> green_shift) & green_mask;\n              if (green_mask != 0)\n                color=(color*65535UL)/green_mask;\n              SetPixelGreen(image,ScaleShortToQuantum((unsigned short) color),\n                q);\n              color=(pixel >> blue_shift) & blue_mask;\n              if (blue_mask != 0)\n                color=(color*65535UL)/blue_mask;\n              SetPixelBlue(image,ScaleShortToQuantum((unsigned short) color),q);\n              q+=GetPixelChannels(image);\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n        break;\n      }\n      case PseudoClass:\n      {\n        /*\n          Convert X image to PseudoClass packets.\n        */\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          {\n            if (header.ncolors != 0)\n              colors=(XColor *) RelinquishMagickMemory(colors);\n            ximage->data=DestroyString(ximage->data);\n            ximage=(XImage *) RelinquishMagickMemory(ximage);\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        for (i=0; i < (ssize_t) image->colors; i++)\n        {\n          image->colormap[i].red=(MagickRealType) ScaleShortToQuantum(\n            colors[i].red);\n          image->colormap[i].green=(MagickRealType) ScaleShortToQuantum(\n            colors[i].green);\n          image->colormap[i].blue=(MagickRealType) ScaleShortToQuantum(\n            colors[i].blue);\n        }\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=(Quantum) ConstrainColormapIndex(image,(ssize_t)\n              XGetPixel(ximage,(int) x,(int) y),exception);\n            SetPixelIndex(image,index,q);\n            SetPixelViaPixelInfo(image,image->colormap+(ssize_t) index,q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n            image->rows);\n          if (status == MagickFalse)\n            break;\n        }\n        break;\n      }\n    }\n  /*\n    Free image and colormap.\n  */\n  if (header.ncolors != 0)\n    colors=(XColor *) RelinquishMagickMemory(colors);\n  ximage->data=DestroyString(ximage->data);\n  ximage=(XImage *) RelinquishMagickMemory(ximage);\n  if (EOFBlob(image) != MagickFalse)\n    ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n      image->filename);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -89,6 +89,9 @@\n   if (header.header_size < sz_XWDheader)\n     ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n   if ((header.bits_per_pixel == 0) || (header.bits_per_pixel > 32))\n+    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n+  if ((header.bitmap_bit_order != MSBFirst) &&\n+      (header.bitmap_bit_order != LSBFirst))\n     ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n   if (((header.bitmap_pad % 8) != 0) || (header.bitmap_pad > 32))\n     ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");",
                "  if ((header.bitmap_bit_order != MSBFirst) &&",
                "      (header.bitmap_bit_order != LSBFirst))"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-27845",
        "func_name": "jasper-software/jasper/cp_create",
        "description": "A Divide-by-zero vulnerability exists in JasPer Image Coding Toolkit 2.0 in jasper/src/libjasper/jpc/jpc_enc.c",
        "git_url": "https://github.com/jasper-software/jasper/commit/fd564ee3377d9fc2484c657e4f464a3fb9764d31",
        "commit_title": "jpc_enc: validate raw_size, prevent division by zero in cp_create()",
        "commit_text": " Closes https://github.com/mdadams/jasper/issues/194 (part 1)",
        "func_before": "static jpc_enc_cp_t *cp_create(const char *optstr, jas_image_t *image)\n{\n\tjpc_enc_cp_t *cp;\n\tjas_tvparser_t *tvp;\n\tint ret;\n\tint numilyrrates;\n\tdouble *ilyrrates;\n\tint i;\n\tint tagid;\n\tjpc_enc_tcp_t *tcp;\n\tjpc_enc_tccp_t *tccp;\n\tjpc_enc_ccp_t *ccp;\n\tint cmptno;\n\tuint_fast16_t rlvlno;\n\tuint_fast16_t prcwidthexpn;\n\tuint_fast16_t prcheightexpn;\n\tbool enablemct;\n\tuint_fast32_t jp2overhead;\n\tuint_fast16_t lyrno;\n\tuint_fast32_t hsteplcm;\n\tuint_fast32_t vsteplcm;\n\tbool mctvalid;\n\n\ttvp = 0;\n\tcp = 0;\n\tilyrrates = 0;\n\tnumilyrrates = 0;\n\n\tif (!(cp = jas_malloc(sizeof(jpc_enc_cp_t)))) {\n\t\tgoto error;\n\t}\n\n\tprcwidthexpn = 15;\n\tprcheightexpn = 15;\n\tenablemct = true;\n\tjp2overhead = 0;\n\n\tcp->ccps = 0;\n\tcp->debug = 0;\n\tcp->imgareatlx = UINT_FAST32_MAX;\n\tcp->imgareatly = UINT_FAST32_MAX;\n\tcp->refgrdwidth = 0;\n\tcp->refgrdheight = 0;\n\tcp->tilegrdoffx = UINT_FAST32_MAX;\n\tcp->tilegrdoffy = UINT_FAST32_MAX;\n\tcp->tilewidth = 0;\n\tcp->tileheight = 0;\n\tcp->numcmpts = jas_image_numcmpts(image);\n\n\thsteplcm = 1;\n\tvsteplcm = 1;\n\tfor (cmptno = 0; cmptno < jas_image_numcmpts(image); ++cmptno) {\n\t\tif (jas_image_cmptbrx(image, cmptno) + jas_image_cmpthstep(image, cmptno) <=\n\t\t  jas_image_brx(image) || jas_image_cmptbry(image, cmptno) +\n\t\t  jas_image_cmptvstep(image, cmptno) <= jas_image_bry(image)) {\n\t\t\tjas_eprintf(\"unsupported image type\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\t/* Note: We ought to be calculating the LCMs here.  Fix some day. */\n\t\thsteplcm *= jas_image_cmpthstep(image, cmptno);\n\t\tvsteplcm *= jas_image_cmptvstep(image, cmptno);\n\t}\n\n\tif (!(cp->ccps = jas_alloc2(cp->numcmpts, sizeof(jpc_enc_ccp_t)))) {\n\t\tgoto error;\n\t}\n\tfor (cmptno = 0, ccp = cp->ccps; cmptno < JAS_CAST(int, cp->numcmpts); ++cmptno,\n\t  ++ccp) {\n\t\tccp->sampgrdstepx = jas_image_cmpthstep(image, cmptno);\n\t\tccp->sampgrdstepy = jas_image_cmptvstep(image, cmptno);\n\t\t/* XXX - this isn't quite correct for more general image */\n\t\tccp->sampgrdsubstepx = 0;\n\t\tccp->sampgrdsubstepx = 0;\n\t\tccp->prec = jas_image_cmptprec(image, cmptno);\n\t\tccp->sgnd = jas_image_cmptsgnd(image, cmptno);\n\t\tccp->numstepsizes = 0;\n\t\tmemset(ccp->stepsizes, 0, sizeof(ccp->stepsizes));\n\t}\n\n\tcp->rawsize = jas_image_rawsize(image);\n\tcp->totalsize = UINT_FAST32_MAX;\n\n\ttcp = &cp->tcp;\n\ttcp->csty = 0;\n\ttcp->intmode = true;\n\ttcp->prg = JPC_COD_LRCPPRG;\n\ttcp->numlyrs = 1;\n\ttcp->ilyrrates = 0;\n\n\ttccp = &cp->tccp;\n\ttccp->csty = 0;\n\ttccp->maxrlvls = 6;\n\ttccp->cblkwidthexpn = 6;\n\ttccp->cblkheightexpn = 6;\n\ttccp->cblksty = 0;\n\ttccp->numgbits = 2;\n\n\tif (!(tvp = jas_tvparser_create(optstr ? optstr : \"\"))) {\n\t\tgoto error;\n\t}\n\n\twhile (!(ret = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(encopts,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase OPT_DEBUG:\n\t\t\tcp->debug = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_IMGAREAOFFX:\n\t\t\tcp->imgareatlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_IMGAREAOFFY:\n\t\t\tcp->imgareatly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEGRDOFFX:\n\t\t\tcp->tilegrdoffx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEGRDOFFY:\n\t\t\tcp->tilegrdoffy = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEWIDTH:\n\t\t\tcp->tilewidth = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEHEIGHT:\n\t\t\tcp->tileheight = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_PRCWIDTH:\n\t\t\tprcwidthexpn = jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_PRCHEIGHT:\n\t\t\tprcheightexpn = jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_CBLKWIDTH:\n\t\t\ttccp->cblkwidthexpn =\n\t\t\t  jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_CBLKHEIGHT:\n\t\t\ttccp->cblkheightexpn =\n\t\t\t  jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_MODE:\n\t\t\tif ((tagid = jas_taginfo_nonull(jas_taginfos_lookup(modetab,\n\t\t\t  jas_tvparser_getval(tvp)))->id) < 0) {\n\t\t\t\tjas_eprintf(\"ignoring invalid mode %s\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t} else {\n\t\t\t\ttcp->intmode = (tagid == MODE_INT);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase OPT_PRG:\n\t\t\tif ((tagid = jas_taginfo_nonull(jas_taginfos_lookup(prgordtab,\n\t\t\t  jas_tvparser_getval(tvp)))->id) < 0) {\n\t\t\t\tjas_eprintf(\"ignoring invalid progression order %s\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t} else {\n\t\t\t\ttcp->prg = tagid;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase OPT_NOMCT:\n\t\t\tenablemct = false;\n\t\t\tbreak;\n\t\tcase OPT_MAXRLVLS:\n\t\t\ttccp->maxrlvls = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_SOP:\n\t\t\tcp->tcp.csty |= JPC_COD_SOP;\n\t\t\tbreak;\n\t\tcase OPT_EPH:\n\t\t\tcp->tcp.csty |= JPC_COD_EPH;\n\t\t\tbreak;\n\t\tcase OPT_LAZY:\n\t\t\ttccp->cblksty |= JPC_COX_LAZY;\n\t\t\tbreak;\n\t\tcase OPT_TERMALL:\n\t\t\ttccp->cblksty |= JPC_COX_TERMALL;\n\t\t\tbreak;\n\t\tcase OPT_SEGSYM:\n\t\t\ttccp->cblksty |= JPC_COX_SEGSYM;\n\t\t\tbreak;\n\t\tcase OPT_VCAUSAL:\n\t\t\ttccp->cblksty |= JPC_COX_VSC;\n\t\t\tbreak;\n\t\tcase OPT_RESET:\n\t\t\ttccp->cblksty |= JPC_COX_RESET;\n\t\t\tbreak;\n\t\tcase OPT_PTERM:\n\t\t\ttccp->cblksty |= JPC_COX_PTERM;\n\t\t\tbreak;\n\t\tcase OPT_NUMGBITS:\n\t\t\tcp->tccp.numgbits = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_RATE:\n\t\t\tif (ratestrtosize(jas_tvparser_getval(tvp), cp->rawsize,\n\t\t\t  &cp->totalsize)) {\n\t\t\t\tjas_eprintf(\"ignoring bad rate specifier %s\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t}\n\t\t\tbreak;\n\t\tcase OPT_ILYRRATES:\n\t\t\tif (jpc_atoaf(jas_tvparser_getval(tvp), &numilyrrates,\n\t\t\t  &ilyrrates)) {\n\t\t\t\tjas_eprintf(\"warning: invalid intermediate layer rates specifier ignored (%s)\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase OPT_JP2OVERHEAD:\n\t\t\tjp2overhead = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tjas_eprintf(\"warning: ignoring invalid option %s\\n\",\n\t\t\t jas_tvparser_gettag(tvp));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tjas_tvparser_destroy(tvp);\n\ttvp = 0;\n\n\tif (cp->totalsize != UINT_FAST32_MAX) {\n\t\tcp->totalsize = (cp->totalsize > jp2overhead) ?\n\t\t  (cp->totalsize - jp2overhead) : 0;\n\t}\n\n\tif (cp->imgareatlx == UINT_FAST32_MAX) {\n\t\tcp->imgareatlx = 0;\n\t} else {\n\t\tif (hsteplcm != 1) {\n\t\t\tjas_eprintf(\"warning: overriding imgareatlx value\\n\");\n\t\t}\n\t\tcp->imgareatlx *= hsteplcm;\n\t}\n\tif (cp->imgareatly == UINT_FAST32_MAX) {\n\t\tcp->imgareatly = 0;\n\t} else {\n\t\tif (vsteplcm != 1) {\n\t\t\tjas_eprintf(\"warning: overriding imgareatly value\\n\");\n\t\t}\n\t\tcp->imgareatly *= vsteplcm;\n\t}\n\tcp->refgrdwidth = cp->imgareatlx + jas_image_width(image);\n\tcp->refgrdheight = cp->imgareatly + jas_image_height(image);\n\tif (cp->tilegrdoffx == UINT_FAST32_MAX) {\n\t\tcp->tilegrdoffx = cp->imgareatlx;\n\t}\n\tif (cp->tilegrdoffy == UINT_FAST32_MAX) {\n\t\tcp->tilegrdoffy = cp->imgareatly;\n\t}\n\tif (!cp->tilewidth) {\n\t\tcp->tilewidth = cp->refgrdwidth - cp->tilegrdoffx;\n\t}\n\tif (!cp->tileheight) {\n\t\tcp->tileheight = cp->refgrdheight - cp->tilegrdoffy;\n\t}\n\n\tif (cp->numcmpts == 3) {\n\t\tmctvalid = true;\n\t\tfor (cmptno = 0; cmptno < jas_image_numcmpts(image); ++cmptno) {\n\t\t\tif (jas_image_cmptprec(image, cmptno) != jas_image_cmptprec(image, 0) ||\n\t\t\t  jas_image_cmptsgnd(image, cmptno) != jas_image_cmptsgnd(image, 0) ||\n\t\t\t  jas_image_cmptwidth(image, cmptno) != jas_image_cmptwidth(image, 0) ||\n\t\t\t  jas_image_cmptheight(image, cmptno) != jas_image_cmptheight(image, 0)) {\n\t\t\t\tmctvalid = false;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tmctvalid = false;\n\t}\n\tif (mctvalid && enablemct && jas_clrspc_fam(jas_image_clrspc(image)) != JAS_CLRSPC_FAM_RGB) {\n\t\tjas_eprintf(\"warning: color space apparently not RGB\\n\");\n\t}\n\tif (mctvalid && enablemct && jas_clrspc_fam(jas_image_clrspc(image)) == JAS_CLRSPC_FAM_RGB) {\n\t\ttcp->mctid = (tcp->intmode) ? (JPC_MCT_RCT) : (JPC_MCT_ICT);\n\t} else {\n\t\ttcp->mctid = JPC_MCT_NONE;\n\t}\n\ttccp->qmfbid = (tcp->intmode) ? (JPC_COX_RFT) : (JPC_COX_INS);\n\n\tfor (rlvlno = 0; rlvlno < tccp->maxrlvls; ++rlvlno) {\n\t\ttccp->prcwidthexpns[rlvlno] = prcwidthexpn;\n\t\ttccp->prcheightexpns[rlvlno] = prcheightexpn;\n\t}\n\tif (prcwidthexpn != 15 || prcheightexpn != 15) {\n\t\ttccp->csty |= JPC_COX_PRT;\n\t}\n\n\t/* Ensure that the tile width and height is valid. */\n\tif (!cp->tilewidth) {\n\t\tjas_eprintf(\"invalid tile width %lu\\n\", (unsigned long)\n\t\t  cp->tilewidth);\n\t\tgoto error;\n\t}\n\tif (!cp->tileheight) {\n\t\tjas_eprintf(\"invalid tile height %lu\\n\", (unsigned long)\n\t\t  cp->tileheight);\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the tile grid offset is valid. */\n\tif (cp->tilegrdoffx > cp->imgareatlx ||\n\t  cp->tilegrdoffy > cp->imgareatly ||\n\t  cp->tilegrdoffx + cp->tilewidth < cp->imgareatlx ||\n\t  cp->tilegrdoffy + cp->tileheight < cp->imgareatly) {\n\t\tjas_eprintf(\"invalid tile grid offset (%lu, %lu)\\n\",\n\t\t  (unsigned long) cp->tilegrdoffx, (unsigned long)\n\t\t  cp->tilegrdoffy);\n\t\tgoto error;\n\t}\n\n\tcp->numhtiles = JPC_CEILDIV(cp->refgrdwidth - cp->tilegrdoffx,\n\t  cp->tilewidth);\n\tcp->numvtiles = JPC_CEILDIV(cp->refgrdheight - cp->tilegrdoffy,\n\t  cp->tileheight);\n\tcp->numtiles = cp->numhtiles * cp->numvtiles;\n\n\tif (ilyrrates && numilyrrates > 0) {\n\t\ttcp->numlyrs = numilyrrates + 1;\n\t\tif (!(tcp->ilyrrates = jas_alloc2((tcp->numlyrs - 1),\n\t\t  sizeof(jpc_fix_t)))) {\n\t\t\tgoto error;\n\t\t}\n\t\tfor (i = 0; i < JAS_CAST(int, tcp->numlyrs - 1); ++i) {\n\t\t\ttcp->ilyrrates[i] = jpc_dbltofix(ilyrrates[i]);\n\t\t}\n\t}\n\n\t/* Ensure that the integer mode is used in the case of lossless\n\t  coding. */\n\tif (cp->totalsize == UINT_FAST32_MAX && (!cp->tcp.intmode)) {\n\t\tjas_eprintf(\"cannot use real mode for lossless coding\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the precinct width is valid. */\n\tif (prcwidthexpn > 15) {\n\t\tjas_eprintf(\"invalid precinct width\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the precinct height is valid. */\n\tif (prcheightexpn > 15) {\n\t\tjas_eprintf(\"invalid precinct height\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the code block width is valid. */\n\tif (cp->tccp.cblkwidthexpn < 2 || cp->tccp.cblkwidthexpn > 12) {\n\t\tjas_eprintf(\"invalid code block width %d\\n\",\n\t\t  JPC_POW2(cp->tccp.cblkwidthexpn));\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the code block height is valid. */\n\tif (cp->tccp.cblkheightexpn < 2 || cp->tccp.cblkheightexpn > 12) {\n\t\tjas_eprintf(\"invalid code block height %d\\n\",\n\t\t  JPC_POW2(cp->tccp.cblkheightexpn));\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the code block size is not too large. */\n\tif (cp->tccp.cblkwidthexpn + cp->tccp.cblkheightexpn > 12) {\n\t\tjas_eprintf(\"code block size too large\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the number of layers is valid. */\n\tif (cp->tcp.numlyrs > 16384) {\n\t\tjas_eprintf(\"too many layers\\n\");\n\t\tgoto error;\n\t}\n\n\t/* There must be at least one resolution level. */\n\tif (cp->tccp.maxrlvls < 1) {\n\t\tjas_eprintf(\"must be at least one resolution level\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the number of guard bits is valid. */\n\tif (cp->tccp.numgbits > 8) {\n\t\tjas_eprintf(\"invalid number of guard bits\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the rate is within the legal range. */\n\tif (cp->totalsize != UINT_FAST32_MAX && cp->totalsize > cp->rawsize) {\n\t\tjas_eprintf(\"warning: specified rate is unreasonably large (%lu > %lu)\\n\", (unsigned long) cp->totalsize, (unsigned long) cp->rawsize);\n\t}\n\n\t/* Ensure that the intermediate layer rates are valid. */\n\tif (tcp->numlyrs > 1) {\n\t\t/* The intermediate layers rates must increase monotonically. */\n\t\tfor (lyrno = 0; lyrno + 2 < tcp->numlyrs; ++lyrno) {\n\t\t\tif (tcp->ilyrrates[lyrno] >= tcp->ilyrrates[lyrno + 1]) {\n\t\t\t\tjas_eprintf(\"intermediate layer rates must increase monotonically\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t\t/* The intermediate layer rates must be less than the overall rate. */\n\t\tif (cp->totalsize != UINT_FAST32_MAX) {\n\t\t\tfor (lyrno = 0; lyrno < tcp->numlyrs - 1; ++lyrno) {\n\t\t\t\tif (jpc_fixtodbl(tcp->ilyrrates[lyrno]) > ((double) cp->totalsize)\n\t\t\t\t  / cp->rawsize) {\n\t\t\t\t\tjas_eprintf(\"warning: intermediate layer rates must be less than overall rate\\n\");\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ilyrrates) {\n\t\tjas_free(ilyrrates);\n\t}\n\n\treturn cp;\n\nerror:\n\n\tif (ilyrrates) {\n\t\tjas_free(ilyrrates);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\tif (cp) {\n\t\tjpc_enc_cp_destroy(cp);\n\t}\n\treturn 0;\n}",
        "func": "static jpc_enc_cp_t *cp_create(const char *optstr, jas_image_t *image)\n{\n\tjpc_enc_cp_t *cp;\n\tjas_tvparser_t *tvp;\n\tint ret;\n\tint numilyrrates;\n\tdouble *ilyrrates;\n\tint i;\n\tint tagid;\n\tjpc_enc_tcp_t *tcp;\n\tjpc_enc_tccp_t *tccp;\n\tjpc_enc_ccp_t *ccp;\n\tint cmptno;\n\tuint_fast16_t rlvlno;\n\tuint_fast16_t prcwidthexpn;\n\tuint_fast16_t prcheightexpn;\n\tbool enablemct;\n\tuint_fast32_t jp2overhead;\n\tuint_fast16_t lyrno;\n\tuint_fast32_t hsteplcm;\n\tuint_fast32_t vsteplcm;\n\tbool mctvalid;\n\n\ttvp = 0;\n\tcp = 0;\n\tilyrrates = 0;\n\tnumilyrrates = 0;\n\n\tif (!(cp = jas_malloc(sizeof(jpc_enc_cp_t)))) {\n\t\tgoto error;\n\t}\n\n\tprcwidthexpn = 15;\n\tprcheightexpn = 15;\n\tenablemct = true;\n\tjp2overhead = 0;\n\n\tcp->ccps = 0;\n\tcp->debug = 0;\n\tcp->imgareatlx = UINT_FAST32_MAX;\n\tcp->imgareatly = UINT_FAST32_MAX;\n\tcp->refgrdwidth = 0;\n\tcp->refgrdheight = 0;\n\tcp->tilegrdoffx = UINT_FAST32_MAX;\n\tcp->tilegrdoffy = UINT_FAST32_MAX;\n\tcp->tilewidth = 0;\n\tcp->tileheight = 0;\n\tcp->numcmpts = jas_image_numcmpts(image);\n\n\thsteplcm = 1;\n\tvsteplcm = 1;\n\tfor (cmptno = 0; cmptno < jas_image_numcmpts(image); ++cmptno) {\n\t\tif (jas_image_cmptbrx(image, cmptno) + jas_image_cmpthstep(image, cmptno) <=\n\t\t  jas_image_brx(image) || jas_image_cmptbry(image, cmptno) +\n\t\t  jas_image_cmptvstep(image, cmptno) <= jas_image_bry(image)) {\n\t\t\tjas_eprintf(\"unsupported image type\\n\");\n\t\t\tgoto error;\n\t\t}\n\t\t/* Note: We ought to be calculating the LCMs here.  Fix some day. */\n\t\thsteplcm *= jas_image_cmpthstep(image, cmptno);\n\t\tvsteplcm *= jas_image_cmptvstep(image, cmptno);\n\t}\n\n\tif (!(cp->ccps = jas_alloc2(cp->numcmpts, sizeof(jpc_enc_ccp_t)))) {\n\t\tgoto error;\n\t}\n\tfor (cmptno = 0, ccp = cp->ccps; cmptno < JAS_CAST(int, cp->numcmpts); ++cmptno,\n\t  ++ccp) {\n\t\tccp->sampgrdstepx = jas_image_cmpthstep(image, cmptno);\n\t\tccp->sampgrdstepy = jas_image_cmptvstep(image, cmptno);\n\t\t/* XXX - this isn't quite correct for more general image */\n\t\tccp->sampgrdsubstepx = 0;\n\t\tccp->sampgrdsubstepx = 0;\n\t\tccp->prec = jas_image_cmptprec(image, cmptno);\n\t\tccp->sgnd = jas_image_cmptsgnd(image, cmptno);\n\t\tccp->numstepsizes = 0;\n\t\tmemset(ccp->stepsizes, 0, sizeof(ccp->stepsizes));\n\t}\n\n\tcp->rawsize = jas_image_rawsize(image);\n\tif (cp->rawsize == 0) {\n\t\t/* prevent division by zero in cp_create() */\n\t\tgoto error;\n\t}\n\tcp->totalsize = UINT_FAST32_MAX;\n\n\ttcp = &cp->tcp;\n\ttcp->csty = 0;\n\ttcp->intmode = true;\n\ttcp->prg = JPC_COD_LRCPPRG;\n\ttcp->numlyrs = 1;\n\ttcp->ilyrrates = 0;\n\n\ttccp = &cp->tccp;\n\ttccp->csty = 0;\n\ttccp->maxrlvls = 6;\n\ttccp->cblkwidthexpn = 6;\n\ttccp->cblkheightexpn = 6;\n\ttccp->cblksty = 0;\n\ttccp->numgbits = 2;\n\n\tif (!(tvp = jas_tvparser_create(optstr ? optstr : \"\"))) {\n\t\tgoto error;\n\t}\n\n\twhile (!(ret = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(encopts,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase OPT_DEBUG:\n\t\t\tcp->debug = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_IMGAREAOFFX:\n\t\t\tcp->imgareatlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_IMGAREAOFFY:\n\t\t\tcp->imgareatly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEGRDOFFX:\n\t\t\tcp->tilegrdoffx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEGRDOFFY:\n\t\t\tcp->tilegrdoffy = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEWIDTH:\n\t\t\tcp->tilewidth = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_TILEHEIGHT:\n\t\t\tcp->tileheight = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_PRCWIDTH:\n\t\t\tprcwidthexpn = jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_PRCHEIGHT:\n\t\t\tprcheightexpn = jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_CBLKWIDTH:\n\t\t\ttccp->cblkwidthexpn =\n\t\t\t  jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_CBLKHEIGHT:\n\t\t\ttccp->cblkheightexpn =\n\t\t\t  jpc_floorlog2(atoi(jas_tvparser_getval(tvp)));\n\t\t\tbreak;\n\t\tcase OPT_MODE:\n\t\t\tif ((tagid = jas_taginfo_nonull(jas_taginfos_lookup(modetab,\n\t\t\t  jas_tvparser_getval(tvp)))->id) < 0) {\n\t\t\t\tjas_eprintf(\"ignoring invalid mode %s\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t} else {\n\t\t\t\ttcp->intmode = (tagid == MODE_INT);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase OPT_PRG:\n\t\t\tif ((tagid = jas_taginfo_nonull(jas_taginfos_lookup(prgordtab,\n\t\t\t  jas_tvparser_getval(tvp)))->id) < 0) {\n\t\t\t\tjas_eprintf(\"ignoring invalid progression order %s\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t} else {\n\t\t\t\ttcp->prg = tagid;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase OPT_NOMCT:\n\t\t\tenablemct = false;\n\t\t\tbreak;\n\t\tcase OPT_MAXRLVLS:\n\t\t\ttccp->maxrlvls = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_SOP:\n\t\t\tcp->tcp.csty |= JPC_COD_SOP;\n\t\t\tbreak;\n\t\tcase OPT_EPH:\n\t\t\tcp->tcp.csty |= JPC_COD_EPH;\n\t\t\tbreak;\n\t\tcase OPT_LAZY:\n\t\t\ttccp->cblksty |= JPC_COX_LAZY;\n\t\t\tbreak;\n\t\tcase OPT_TERMALL:\n\t\t\ttccp->cblksty |= JPC_COX_TERMALL;\n\t\t\tbreak;\n\t\tcase OPT_SEGSYM:\n\t\t\ttccp->cblksty |= JPC_COX_SEGSYM;\n\t\t\tbreak;\n\t\tcase OPT_VCAUSAL:\n\t\t\ttccp->cblksty |= JPC_COX_VSC;\n\t\t\tbreak;\n\t\tcase OPT_RESET:\n\t\t\ttccp->cblksty |= JPC_COX_RESET;\n\t\t\tbreak;\n\t\tcase OPT_PTERM:\n\t\t\ttccp->cblksty |= JPC_COX_PTERM;\n\t\t\tbreak;\n\t\tcase OPT_NUMGBITS:\n\t\t\tcp->tccp.numgbits = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase OPT_RATE:\n\t\t\tif (ratestrtosize(jas_tvparser_getval(tvp), cp->rawsize,\n\t\t\t  &cp->totalsize)) {\n\t\t\t\tjas_eprintf(\"ignoring bad rate specifier %s\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t}\n\t\t\tbreak;\n\t\tcase OPT_ILYRRATES:\n\t\t\tif (jpc_atoaf(jas_tvparser_getval(tvp), &numilyrrates,\n\t\t\t  &ilyrrates)) {\n\t\t\t\tjas_eprintf(\"warning: invalid intermediate layer rates specifier ignored (%s)\\n\",\n\t\t\t\t  jas_tvparser_getval(tvp));\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase OPT_JP2OVERHEAD:\n\t\t\tjp2overhead = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tjas_eprintf(\"warning: ignoring invalid option %s\\n\",\n\t\t\t jas_tvparser_gettag(tvp));\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tjas_tvparser_destroy(tvp);\n\ttvp = 0;\n\n\tif (cp->totalsize != UINT_FAST32_MAX) {\n\t\tcp->totalsize = (cp->totalsize > jp2overhead) ?\n\t\t  (cp->totalsize - jp2overhead) : 0;\n\t}\n\n\tif (cp->imgareatlx == UINT_FAST32_MAX) {\n\t\tcp->imgareatlx = 0;\n\t} else {\n\t\tif (hsteplcm != 1) {\n\t\t\tjas_eprintf(\"warning: overriding imgareatlx value\\n\");\n\t\t}\n\t\tcp->imgareatlx *= hsteplcm;\n\t}\n\tif (cp->imgareatly == UINT_FAST32_MAX) {\n\t\tcp->imgareatly = 0;\n\t} else {\n\t\tif (vsteplcm != 1) {\n\t\t\tjas_eprintf(\"warning: overriding imgareatly value\\n\");\n\t\t}\n\t\tcp->imgareatly *= vsteplcm;\n\t}\n\tcp->refgrdwidth = cp->imgareatlx + jas_image_width(image);\n\tcp->refgrdheight = cp->imgareatly + jas_image_height(image);\n\tif (cp->tilegrdoffx == UINT_FAST32_MAX) {\n\t\tcp->tilegrdoffx = cp->imgareatlx;\n\t}\n\tif (cp->tilegrdoffy == UINT_FAST32_MAX) {\n\t\tcp->tilegrdoffy = cp->imgareatly;\n\t}\n\tif (!cp->tilewidth) {\n\t\tcp->tilewidth = cp->refgrdwidth - cp->tilegrdoffx;\n\t}\n\tif (!cp->tileheight) {\n\t\tcp->tileheight = cp->refgrdheight - cp->tilegrdoffy;\n\t}\n\n\tif (cp->numcmpts == 3) {\n\t\tmctvalid = true;\n\t\tfor (cmptno = 0; cmptno < jas_image_numcmpts(image); ++cmptno) {\n\t\t\tif (jas_image_cmptprec(image, cmptno) != jas_image_cmptprec(image, 0) ||\n\t\t\t  jas_image_cmptsgnd(image, cmptno) != jas_image_cmptsgnd(image, 0) ||\n\t\t\t  jas_image_cmptwidth(image, cmptno) != jas_image_cmptwidth(image, 0) ||\n\t\t\t  jas_image_cmptheight(image, cmptno) != jas_image_cmptheight(image, 0)) {\n\t\t\t\tmctvalid = false;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tmctvalid = false;\n\t}\n\tif (mctvalid && enablemct && jas_clrspc_fam(jas_image_clrspc(image)) != JAS_CLRSPC_FAM_RGB) {\n\t\tjas_eprintf(\"warning: color space apparently not RGB\\n\");\n\t}\n\tif (mctvalid && enablemct && jas_clrspc_fam(jas_image_clrspc(image)) == JAS_CLRSPC_FAM_RGB) {\n\t\ttcp->mctid = (tcp->intmode) ? (JPC_MCT_RCT) : (JPC_MCT_ICT);\n\t} else {\n\t\ttcp->mctid = JPC_MCT_NONE;\n\t}\n\ttccp->qmfbid = (tcp->intmode) ? (JPC_COX_RFT) : (JPC_COX_INS);\n\n\tfor (rlvlno = 0; rlvlno < tccp->maxrlvls; ++rlvlno) {\n\t\ttccp->prcwidthexpns[rlvlno] = prcwidthexpn;\n\t\ttccp->prcheightexpns[rlvlno] = prcheightexpn;\n\t}\n\tif (prcwidthexpn != 15 || prcheightexpn != 15) {\n\t\ttccp->csty |= JPC_COX_PRT;\n\t}\n\n\t/* Ensure that the tile width and height is valid. */\n\tif (!cp->tilewidth) {\n\t\tjas_eprintf(\"invalid tile width %lu\\n\", (unsigned long)\n\t\t  cp->tilewidth);\n\t\tgoto error;\n\t}\n\tif (!cp->tileheight) {\n\t\tjas_eprintf(\"invalid tile height %lu\\n\", (unsigned long)\n\t\t  cp->tileheight);\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the tile grid offset is valid. */\n\tif (cp->tilegrdoffx > cp->imgareatlx ||\n\t  cp->tilegrdoffy > cp->imgareatly ||\n\t  cp->tilegrdoffx + cp->tilewidth < cp->imgareatlx ||\n\t  cp->tilegrdoffy + cp->tileheight < cp->imgareatly) {\n\t\tjas_eprintf(\"invalid tile grid offset (%lu, %lu)\\n\",\n\t\t  (unsigned long) cp->tilegrdoffx, (unsigned long)\n\t\t  cp->tilegrdoffy);\n\t\tgoto error;\n\t}\n\n\tcp->numhtiles = JPC_CEILDIV(cp->refgrdwidth - cp->tilegrdoffx,\n\t  cp->tilewidth);\n\tcp->numvtiles = JPC_CEILDIV(cp->refgrdheight - cp->tilegrdoffy,\n\t  cp->tileheight);\n\tcp->numtiles = cp->numhtiles * cp->numvtiles;\n\n\tif (ilyrrates && numilyrrates > 0) {\n\t\ttcp->numlyrs = numilyrrates + 1;\n\t\tif (!(tcp->ilyrrates = jas_alloc2((tcp->numlyrs - 1),\n\t\t  sizeof(jpc_fix_t)))) {\n\t\t\tgoto error;\n\t\t}\n\t\tfor (i = 0; i < JAS_CAST(int, tcp->numlyrs - 1); ++i) {\n\t\t\ttcp->ilyrrates[i] = jpc_dbltofix(ilyrrates[i]);\n\t\t}\n\t}\n\n\t/* Ensure that the integer mode is used in the case of lossless\n\t  coding. */\n\tif (cp->totalsize == UINT_FAST32_MAX && (!cp->tcp.intmode)) {\n\t\tjas_eprintf(\"cannot use real mode for lossless coding\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the precinct width is valid. */\n\tif (prcwidthexpn > 15) {\n\t\tjas_eprintf(\"invalid precinct width\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the precinct height is valid. */\n\tif (prcheightexpn > 15) {\n\t\tjas_eprintf(\"invalid precinct height\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the code block width is valid. */\n\tif (cp->tccp.cblkwidthexpn < 2 || cp->tccp.cblkwidthexpn > 12) {\n\t\tjas_eprintf(\"invalid code block width %d\\n\",\n\t\t  JPC_POW2(cp->tccp.cblkwidthexpn));\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the code block height is valid. */\n\tif (cp->tccp.cblkheightexpn < 2 || cp->tccp.cblkheightexpn > 12) {\n\t\tjas_eprintf(\"invalid code block height %d\\n\",\n\t\t  JPC_POW2(cp->tccp.cblkheightexpn));\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the code block size is not too large. */\n\tif (cp->tccp.cblkwidthexpn + cp->tccp.cblkheightexpn > 12) {\n\t\tjas_eprintf(\"code block size too large\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the number of layers is valid. */\n\tif (cp->tcp.numlyrs > 16384) {\n\t\tjas_eprintf(\"too many layers\\n\");\n\t\tgoto error;\n\t}\n\n\t/* There must be at least one resolution level. */\n\tif (cp->tccp.maxrlvls < 1) {\n\t\tjas_eprintf(\"must be at least one resolution level\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the number of guard bits is valid. */\n\tif (cp->tccp.numgbits > 8) {\n\t\tjas_eprintf(\"invalid number of guard bits\\n\");\n\t\tgoto error;\n\t}\n\n\t/* Ensure that the rate is within the legal range. */\n\tif (cp->totalsize != UINT_FAST32_MAX && cp->totalsize > cp->rawsize) {\n\t\tjas_eprintf(\"warning: specified rate is unreasonably large (%lu > %lu)\\n\", (unsigned long) cp->totalsize, (unsigned long) cp->rawsize);\n\t}\n\n\t/* Ensure that the intermediate layer rates are valid. */\n\tif (tcp->numlyrs > 1) {\n\t\t/* The intermediate layers rates must increase monotonically. */\n\t\tfor (lyrno = 0; lyrno + 2 < tcp->numlyrs; ++lyrno) {\n\t\t\tif (tcp->ilyrrates[lyrno] >= tcp->ilyrrates[lyrno + 1]) {\n\t\t\t\tjas_eprintf(\"intermediate layer rates must increase monotonically\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t\t/* The intermediate layer rates must be less than the overall rate. */\n\t\tif (cp->totalsize != UINT_FAST32_MAX) {\n\t\t\tfor (lyrno = 0; lyrno < tcp->numlyrs - 1; ++lyrno) {\n\t\t\t\tif (jpc_fixtodbl(tcp->ilyrrates[lyrno]) > ((double) cp->totalsize)\n\t\t\t\t  / cp->rawsize) {\n\t\t\t\t\tjas_eprintf(\"warning: intermediate layer rates must be less than overall rate\\n\");\n\t\t\t\t\tgoto error;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (ilyrrates) {\n\t\tjas_free(ilyrrates);\n\t}\n\n\treturn cp;\n\nerror:\n\n\tif (ilyrrates) {\n\t\tjas_free(ilyrrates);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\tif (cp) {\n\t\tjpc_enc_cp_destroy(cp);\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -78,6 +78,10 @@\n \t}\n \n \tcp->rawsize = jas_image_rawsize(image);\n+\tif (cp->rawsize == 0) {\n+\t\t/* prevent division by zero in cp_create() */\n+\t\tgoto error;\n+\t}\n \tcp->totalsize = UINT_FAST32_MAX;\n \n \ttcp = &cp->tcp;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (cp->rawsize == 0) {",
                "\t\t/* prevent division by zero in cp_create() */",
                "\t\tgoto error;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-27847",
        "func_name": "libvips/vips_eye_point",
        "description": "Division-By-Zero vulnerability in Libvips 8.10.5 in the function vips_eye_point, eye.c#L83, and function vips_mask_point, mask.c#L85.",
        "git_url": "https://github.com/libvips/libvips/commit/2fb81b8ed6a4a6b2385f3efbb0412f24f80163c4",
        "commit_title": "prevent /0 in eye for width/height 1",
        "commit_text": " see https://github.com/libvips/libvips/issues/1236",
        "func_before": "static float\nvips_eye_point( VipsPoint *point, int x, int y ) \n{\n\tVipsEye *eye = (VipsEye *) point;\n\n\tdouble c = eye->factor * VIPS_PI / (2 * (point->width - 1));\n\tdouble h = ((point->height - 1) * (point->height - 1));\n\n\treturn( y * y * cos( c * x * x ) / h );\n}",
        "func": "static float\nvips_eye_point( VipsPoint *point, int x, int y ) \n{\n\tVipsEye *eye = (VipsEye *) point;\n\n\t/* VIPS_MAX to prevent /0.\n\t */\n\tint max_x = VIPS_MAX( point->width - 1, 1 );\n\tint max_y = VIPS_MAX( point->height - 1, 1 );\n\n\tdouble c = eye->factor * VIPS_PI / (2 * max_x);\n\tdouble h = max_y * max_y;\n\n\treturn( y * y * cos( c * x * x ) / h );\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,13 @@\n {\n \tVipsEye *eye = (VipsEye *) point;\n \n-\tdouble c = eye->factor * VIPS_PI / (2 * (point->width - 1));\n-\tdouble h = ((point->height - 1) * (point->height - 1));\n+\t/* VIPS_MAX to prevent /0.\n+\t */\n+\tint max_x = VIPS_MAX( point->width - 1, 1 );\n+\tint max_y = VIPS_MAX( point->height - 1, 1 );\n+\n+\tdouble c = eye->factor * VIPS_PI / (2 * max_x);\n+\tdouble h = max_y * max_y;\n \n \treturn( y * y * cos( c * x * x ) / h );\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tdouble c = eye->factor * VIPS_PI / (2 * (point->width - 1));",
                "\tdouble h = ((point->height - 1) * (point->height - 1));"
            ],
            "added_lines": [
                "\t/* VIPS_MAX to prevent /0.",
                "\t */",
                "\tint max_x = VIPS_MAX( point->width - 1, 1 );",
                "\tint max_y = VIPS_MAX( point->height - 1, 1 );",
                "",
                "\tdouble c = eye->factor * VIPS_PI / (2 * max_x);",
                "\tdouble h = max_y * max_y;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-27847",
        "func_name": "libvips/vips_mask_point",
        "description": "Division-By-Zero vulnerability in Libvips 8.10.5 in the function vips_eye_point, eye.c#L83, and function vips_mask_point, mask.c#L85.",
        "git_url": "https://github.com/libvips/libvips/commit/65a259a0258b2036b168cdeff6e9db434471225a",
        "commit_title": "prevent /0 in freq mask for very small masks",
        "commit_text": " see https://github.com/libvips/libvips/issues/1236",
        "func_before": "static float\nvips_mask_point( VipsPoint *point, int x, int y )\n{\n\tVipsMask *mask = VIPS_MASK( point ); \n\tVipsMaskClass *class = VIPS_MASK_GET_CLASS( point ); \n\tint half_width = point->width / 2;\n\tint half_height = point->height / 2;\n\n\tdouble result;\n\n\t/* Move centre for an optical transform mask.\n\t */\n\tif( !mask->optical ) {\n\t\tx = (x + half_width) % point->width;\n\t\ty = (y + half_height) % point->height;\n\t}\n\n\tx = x - half_width;\n\ty = y - half_height;\n\n\tif( !mask->nodc && \n\t\tx == 0 &&\n\t\ty == 0 )\n\t\t/* DC component is always 1.\n\t\t */\n\t\tresult = 1.0;\n\telse {\n\t\tdouble dx, dy;\n\n\t\tdx = (double) x / half_width;\n\t\tdy = (double) y / half_height;\n\n\t\tresult = class->point( mask, dx, dy );\n\n\t\t/* Invert filter sense for a highpass filter, or to swap\n\t\t * band-pass for band-reject. \n\t\t */\n\t\tif( mask->reject )\n\t\t\tresult = 1.0 - result;\n\t}\n\n\treturn( result ); \n}",
        "func": "static float\nvips_mask_point( VipsPoint *point, int x, int y )\n{\n\tVipsMask *mask = VIPS_MASK( point ); \n\tVipsMaskClass *class = VIPS_MASK_GET_CLASS( point ); \n\n\t/* VIPS_MAX to prevent /0.\n\t */\n\tint half_width = VIPS_MAX( point->width / 2, 1 );\n\tint half_height = VIPS_MAX( point->height / 2, 1 );\n\n\tdouble result;\n\n\t/* Move centre for an optical transform mask.\n\t */\n\tif( !mask->optical ) {\n\t\tx = (x + half_width) % point->width;\n\t\ty = (y + half_height) % point->height;\n\t}\n\n\tx = x - half_width;\n\ty = y - half_height;\n\n\tif( !mask->nodc && \n\t\tx == 0 &&\n\t\ty == 0 )\n\t\t/* DC component is always 1.\n\t\t */\n\t\tresult = 1.0;\n\telse {\n\t\tdouble dx, dy;\n\n\t\tdx = (double) x / half_width;\n\t\tdy = (double) y / half_height;\n\n\t\tresult = class->point( mask, dx, dy );\n\n\t\t/* Invert filter sense for a highpass filter, or to swap\n\t\t * band-pass for band-reject. \n\t\t */\n\t\tif( mask->reject )\n\t\t\tresult = 1.0 - result;\n\t}\n\n\treturn( result ); \n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,11 @@\n {\n \tVipsMask *mask = VIPS_MASK( point ); \n \tVipsMaskClass *class = VIPS_MASK_GET_CLASS( point ); \n-\tint half_width = point->width / 2;\n-\tint half_height = point->height / 2;\n+\n+\t/* VIPS_MAX to prevent /0.\n+\t */\n+\tint half_width = VIPS_MAX( point->width / 2, 1 );\n+\tint half_height = VIPS_MAX( point->height / 2, 1 );\n \n \tdouble result;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tint half_width = point->width / 2;",
                "\tint half_height = point->height / 2;"
            ],
            "added_lines": [
                "",
                "\t/* VIPS_MAX to prevent /0.",
                "\t */",
                "\tint half_width = VIPS_MAX( point->width / 2, 1 );",
                "\tint half_height = VIPS_MAX( point->height / 2, 1 );"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-34335",
        "func_name": "Exiv2/exiv2/ValueType<URational>::toLong",
        "description": "Exiv2 is a command-line utility and C++ library for reading, writing, deleting, and modifying the metadata of image files. A floating point exception (FPE) due to an integer divide by zero was found in Exiv2 versions v0.27.4 and earlier. The FPE is triggered when Exiv2 is used to print the metadata of a crafted image file. An attacker could potentially exploit the vulnerability to cause a denial of service, if they can trick the victim into running Exiv2 on a crafted image file. Note that this bug is only triggered when printing the interpreted (translated) data, which is a less frequently used Exiv2 operation that requires an extra command line option (`-p t` or `-P t`). The bug is fixed in version v0.27.5.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/2d8d44e47b1500030e5b249bffbaf1e80aa74815",
        "commit_title": "Defensive coding to avoid 0x80000000/0xFFFFFFFF FPE.",
        "commit_text": "",
        "func_before": "inline long ValueType<URational>::toLong(long n) const\n    {\n        ok_ = (value_.at(n).second != 0 && value_.at(n).first < LARGE_INT);\n        if (!ok_) return 0;\n        return value_.at(n).first / value_.at(n).second;\n    }",
        "func": "inline long ValueType<URational>::toLong(long n) const\n    {\n        ok_ = (value_.at(n).second > 0 && value_.at(n).first < LARGE_INT);\n        if (!ok_) return 0;\n        return value_.at(n).first / value_.at(n).second;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n inline long ValueType<URational>::toLong(long n) const\n     {\n-        ok_ = (value_.at(n).second != 0 && value_.at(n).first < LARGE_INT);\n+        ok_ = (value_.at(n).second > 0 && value_.at(n).first < LARGE_INT);\n         if (!ok_) return 0;\n         return value_.at(n).first / value_.at(n).second;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        ok_ = (value_.at(n).second != 0 && value_.at(n).first < LARGE_INT);"
            ],
            "added_lines": [
                "        ok_ = (value_.at(n).second > 0 && value_.at(n).first < LARGE_INT);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-34335",
        "func_name": "Exiv2/exiv2/ValueType<T>::read",
        "description": "Exiv2 is a command-line utility and C++ library for reading, writing, deleting, and modifying the metadata of image files. A floating point exception (FPE) due to an integer divide by zero was found in Exiv2 versions v0.27.4 and earlier. The FPE is triggered when Exiv2 is used to print the metadata of a crafted image file. An attacker could potentially exploit the vulnerability to cause a denial of service, if they can trick the victim into running Exiv2 on a crafted image file. Note that this bug is only triggered when printing the interpreted (translated) data, which is a less frequently used Exiv2 operation that requires an extra command line option (`-p t` or `-P t`). The bug is fixed in version v0.27.5.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/2d8d44e47b1500030e5b249bffbaf1e80aa74815",
        "commit_title": "Defensive coding to avoid 0x80000000/0xFFFFFFFF FPE.",
        "commit_text": "",
        "func_before": "int ValueType<T>::read(const byte* buf, long len, ByteOrder byteOrder)\n    {\n        value_.clear();\n        long ts = TypeInfo::typeSize(typeId());\n        if (ts != 0)\n            if (len % ts != 0) len = (len / ts) * ts;\n        for (long i = 0; i < len; i += ts) {\n            value_.push_back(getValue<T>(buf + i, byteOrder));\n        }\n        return 0;\n    }",
        "func": "int ValueType<T>::read(const byte* buf, long len, ByteOrder byteOrder)\n    {\n        value_.clear();\n        long ts = TypeInfo::typeSize(typeId());\n        if (ts > 0)\n            if (len % ts != 0) len = (len / ts) * ts;\n        for (long i = 0; i < len; i += ts) {\n            value_.push_back(getValue<T>(buf + i, byteOrder));\n        }\n        return 0;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n     {\n         value_.clear();\n         long ts = TypeInfo::typeSize(typeId());\n-        if (ts != 0)\n+        if (ts > 0)\n             if (len % ts != 0) len = (len / ts) * ts;\n         for (long i = 0; i < len; i += ts) {\n             value_.push_back(getValue<T>(buf + i, byteOrder));",
        "diff_line_info": {
            "deleted_lines": [
                "        if (ts != 0)"
            ],
            "added_lines": [
                "        if (ts > 0)"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-34335",
        "func_name": "Exiv2/exiv2/ValueType<Rational>::toLong",
        "description": "Exiv2 is a command-line utility and C++ library for reading, writing, deleting, and modifying the metadata of image files. A floating point exception (FPE) due to an integer divide by zero was found in Exiv2 versions v0.27.4 and earlier. The FPE is triggered when Exiv2 is used to print the metadata of a crafted image file. An attacker could potentially exploit the vulnerability to cause a denial of service, if they can trick the victim into running Exiv2 on a crafted image file. Note that this bug is only triggered when printing the interpreted (translated) data, which is a less frequently used Exiv2 operation that requires an extra command line option (`-p t` or `-P t`). The bug is fixed in version v0.27.5.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/2d8d44e47b1500030e5b249bffbaf1e80aa74815",
        "commit_title": "Defensive coding to avoid 0x80000000/0xFFFFFFFF FPE.",
        "commit_text": "",
        "func_before": "inline long ValueType<Rational>::toLong(long n) const\n    {\n        ok_ = (value_.at(n).second != 0 && INT_MIN < value_.at(n).first && value_.at(n).first < INT_MAX );\n        if (!ok_) return 0;\n        return value_.at(n).first / value_.at(n).second;\n    }",
        "func": "inline long ValueType<Rational>::toLong(long n) const\n    {\n        ok_ = (value_.at(n).second > 0 && INT_MIN < value_.at(n).first && value_.at(n).first < INT_MAX );\n        if (!ok_) return 0;\n        return value_.at(n).first / value_.at(n).second;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n inline long ValueType<Rational>::toLong(long n) const\n     {\n-        ok_ = (value_.at(n).second != 0 && INT_MIN < value_.at(n).first && value_.at(n).first < INT_MAX );\n+        ok_ = (value_.at(n).second > 0 && INT_MIN < value_.at(n).first && value_.at(n).first < INT_MAX );\n         if (!ok_) return 0;\n         return value_.at(n).first / value_.at(n).second;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        ok_ = (value_.at(n).second != 0 && INT_MIN < value_.at(n).first && value_.at(n).first < INT_MAX );"
            ],
            "added_lines": [
                "        ok_ = (value_.at(n).second > 0 && INT_MIN < value_.at(n).first && value_.at(n).first < INT_MAX );"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37636",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseDenseCwiseDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/a1bc56203f21a5a4995311825ffaba7a670d7747/tensorflow/core/kernels/sparse_dense_binary_op_shared.cc#L56) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit d9204be9f49520cdaaeb2541d1dc5187b23f31d9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/d9204be9f49520cdaaeb2541d1dc5187b23f31d9",
        "commit_title": "Disallow division by zero FPE in tf.raw_ops.SparseDenseCwiseDiv",
        "commit_text": " PiperOrigin-RevId: 383959809",
        "func_before": "void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64>();\n    const auto shape_vec = shape_t->vec<int64>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64> lhs, ArraySlice<int64> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64 nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "func": "void Compute(OpKernelContext *ctx) override {\n    const Tensor *indices_t, *values_t, *shape_t, *dense_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_indices\", &indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_values\", &values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"sp_shape\", &shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense\", &dense_t));\n\n    // Validations.\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices_t->shape()),\n                errors::InvalidArgument(\n                    \"Input sp_indices should be a matrix but received shape: \",\n                    indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(values_t->shape()) &&\n                    TensorShapeUtils::IsVector(shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs sp_values and sp_shape should be vectors \"\n                    \"but received shapes: \",\n                    values_t->shape().DebugString(), \" and \",\n                    shape_t->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, values_t->dim_size(0) == indices_t->dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of values and indices should match. (\",\n            values_t->dim_size(0), \" vs. \", indices_t->dim_size(0), \")\"));\n\n    const auto indices_mat = indices_t->matrix<int64>();\n    const auto shape_vec = shape_t->vec<int64>();\n    const auto lhs_dims = BCast::FromShape(TensorShape(shape_vec));\n    const auto rhs_dims = BCast::FromShape(dense_t->shape());\n    BCast b(lhs_dims, rhs_dims, false);  // false for keeping the same num dims.\n\n    // True iff (size(lhs) >= size(rhs)) and all dims in lhs is greater or equal\n    // to dims in rhs (from right to left).\n    auto VecGreaterEq = [](ArraySlice<int64> lhs, ArraySlice<int64> rhs) {\n      if (lhs.size() < rhs.size()) return false;\n      for (size_t i = 0; i < rhs.size(); ++i) {\n        if (lhs[lhs.size() - 1 - i] < rhs[rhs.size() - 1 - i]) return false;\n      }\n      return true;\n    };\n    OP_REQUIRES(ctx, VecGreaterEq(lhs_dims, rhs_dims) && b.IsValid(),\n                errors::InvalidArgument(\n                    \"SparseDenseBinaryOpShared broadcasts dense to sparse \"\n                    \"only; got incompatible shapes: [\",\n                    absl::StrJoin(lhs_dims, \",\"), \"] vs. [\",\n                    absl::StrJoin(rhs_dims, \",\"), \"]\"));\n\n    Tensor *output_values = nullptr;\n    Tensor dense_gathered;\n    const int64 nnz = indices_t->dim_size(0);\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({nnz}), &output_values));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                &dense_gathered));\n    bool op_is_div = false;\n    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n      op_is_div = true;\n    }\n    // Pulls relevant entries from the dense side, with reshape and broadcasting\n    // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n    // up memory.\n    //\n    // We can directly use the sparse indices to look up dense side, because\n    // \"b.y_reshape()\" and \"b.y_bcast()\" are guaranteed to have rank \"ndims\".\n    auto dense_gathered_flat = dense_gathered.flat<T>();\n    const int ndims = lhs_dims.size();\n    switch (ndims) {\n#define CASE(NDIM)                                                             \\\n  case NDIM: {                                                                 \\\n    TensorRef<Eigen::Tensor<const T, NDIM, Eigen::RowMajor>> rhs_ref =         \\\n        dense_t->shaped<T, NDIM>(b.y_reshape())                                \\\n            .broadcast(BCast::ToIndexArray<NDIM>(b.y_bcast()));                \\\n    Eigen::array<Eigen::DenseIndex, NDIM> idx;                                 \\\n    bool indices_valid = true;                                                 \\\n    for (int i = 0; i < nnz; ++i) {                                            \\\n      for (int d = 0; d < NDIM; ++d) {                                         \\\n        idx[d] = internal::SubtleMustCopy(indices_mat(i, d));                  \\\n        if (!FastBoundsCheck(idx[d], rhs_ref.dimension(d))) {                  \\\n          indices_valid = false;                                               \\\n        }                                                                      \\\n      }                                                                        \\\n      OP_REQUIRES(                                                             \\\n          ctx, indices_valid,                                                  \\\n          errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                  \"dense side with broadcasted shape\"));       \\\n      dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n      if (op_is_div) {                                                         \\\n        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n                    errors::InvalidArgument(                                   \\\n                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n                        \"but input dense tensor contains zero \"));             \\\n      }                                                                        \\\n    }                                                                          \\\n    break;                                                                     \\\n  }\n\n      CASE(1);\n      CASE(2);\n      CASE(3);\n      CASE(4);\n      CASE(5);\n      default:\n        OP_REQUIRES(\n            ctx, false,\n            errors::InvalidArgument(\"Only tensors with ranks between 1 and 5 \"\n                                    \"are currently supported.  Tensor rank: \",\n                                    ndims));\n#undef CASE\n    }\n\n    output_values->flat<T>().device(ctx->eigen_device<Device>()) =\n        values_t->flat<T>().binaryExpr(dense_gathered_flat,\n                                       typename Functor::func());\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,7 +54,10 @@\n     OP_REQUIRES_OK(\n         ctx, ctx->allocate_temp(DataTypeToEnum<T>::value, TensorShape({nnz}),\n                                 &dense_gathered));\n-\n+    bool op_is_div = false;\n+    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {\n+      op_is_div = true;\n+    }\n     // Pulls relevant entries from the dense side, with reshape and broadcasting\n     // *of the dense side* taken into account.  Use a TensorRef to avoid blowing\n     // up memory.\n@@ -83,6 +86,12 @@\n           errors::InvalidArgument(\"Provided indices are out-of-bounds w.r.t. \" \\\n                                   \"dense side with broadcasted shape\"));       \\\n       dense_gathered_flat(i) = rhs_ref.coeff(idx);                             \\\n+      if (op_is_div) {                                                         \\\n+        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\\n+                    errors::InvalidArgument(                                   \\\n+                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\\n+                        \"but input dense tensor contains zero \"));             \\\n+      }                                                                        \\\n     }                                                                          \\\n     break;                                                                     \\\n   }",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "    bool op_is_div = false;",
                "    if (absl::StrContains(ctx->op_kernel().type_string_view(), \"Div\")) {",
                "      op_is_div = true;",
                "    }",
                "      if (op_is_div) {                                                         \\",
                "        OP_REQUIRES(ctx, dense_gathered_flat(i) != 0,                          \\",
                "                    errors::InvalidArgument(                                   \\",
                "                        \"SparseDenseCwiseDiv cannot divide by zero,\"           \\",
                "                        \"but input dense tensor contains zero \"));             \\",
                "      }                                                                        \\"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37640",
        "func_name": "tensorflow/ReshapeSparseTensor",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.SparseReshape` can be made to trigger an integral division by 0 exception. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L176-L181) calls the reshaping functor whenever there is at least an index in the input but does not check that shape of the input or the target shape have both a non-zero number of elements. The [reshape functor](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/reshape_util.cc#L40-L78) blindly divides by the dimensions of the target shape. Hence, if this is not checked, code will result in a division by 0. We have patched the issue in GitHub commit 4923de56ec94fff7770df259ab7f2288a74feb41. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1 as this is the other affected version.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/4923de56ec94fff7770df259ab7f2288a74feb41",
        "commit_title": "Don't do any work when reshaping 0 elements sparse tensor.",
        "commit_text": " If reshaping to 0 elements tensor, check that input has no elements. If reshaping no elements input, check that output has no elements.  PiperOrigin-RevId: 388296986",
        "func_before": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}",
        "func": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES(\n        context, dense_size > 0 && product > 0,\n        errors::InvalidArgument(\n            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n            input_shape.DebugString(), \") or output shape (\",\n            output_shape.DebugString(), \") is empty\"));\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -92,6 +92,12 @@\n                                           TensorShape({nnz, output_rank}),\n                                           &result_indices));\n   if (nnz > 0) {\n+    OP_REQUIRES(\n+        context, dense_size > 0 && product > 0,\n+        errors::InvalidArgument(\n+            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n+            input_shape.DebugString(), \") or output shape (\",\n+            output_shape.DebugString(), \") is empty\"));\n     OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                 context, input_shape, output_shape,\n                                 input_indices_in.matrix<int64>(),",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, dense_size > 0 && product > 0,",
                "        errors::InvalidArgument(",
                "            \"Input tensor has \", nnz, \" non zero elements but input shape (\",",
                "            input_shape.DebugString(), \") or output shape (\",",
                "            output_shape.DebugString(), \") is empty\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37642",
        "func_name": "tensorflow/DoCompute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/4aacb30888638da75023e6601149415b39763d76",
        "commit_title": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`",
        "commit_text": " Had to update a test that was broken.  PiperOrigin-RevId: 388516976",
        "func_before": "void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(\n            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n            errors::InvalidArgument(\n                \"The shape of indices (\", indices.shape().DebugString(),\n                \") must be a prefix of the shape of updates (\",\n                updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }",
        "func": "void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    // Prevent division by 0\n    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {\n      OP_REQUIRES(c, ValidateInput<T>(updates),\n                  errors::InvalidArgument(\"updates must not contain 0\"));\n    }\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(\n            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n            errors::InvalidArgument(\n                \"The shape of indices (\", indices.shape().DebugString(),\n                \") must be a prefix of the shape of updates (\",\n                updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,6 +31,12 @@\n                                 DataTypeString(DataTypeToEnum<Index>::v()),\n                                 \" indexing: \", params->dim_size(0), \" > \",\n                                 std::numeric_limits<Index>::max()));\n+\n+    // Prevent division by 0\n+    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {\n+      OP_REQUIRES(c, ValidateInput<T>(updates),\n+                  errors::InvalidArgument(\"updates must not contain 0\"));\n+    }\n \n     if (N > 0) {\n       auto indices_flat = indices.flat<Index>();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    // Prevent division by 0",
                "    if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {",
                "      OP_REQUIRES(c, ValidateInput<T>(updates),",
                "                  errors::InvalidArgument(\"updates must not contain 0\"));",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37653",
        "func_name": "tensorflow/AddBatchOffsets",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can trigger a crash via a floating point exception in `tf.raw_ops.ResourceGather`. The [implementation](https://github.com/tensorflow/tensorflow/blob/f24faa153ad31a4b51578f8181d3aaab77a1ddeb/tensorflow/core/kernels/resource_variable_ops.cc#L725-L731) computes the value of a value, `batch_size`, and then divides by it without checking that this value is not 0. We have patched the issue in GitHub commit ac117ee8a8ea57b73d34665cdf00ef3303bc0b11. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ac117ee8a8ea57b73d34665cdf00ef3303bc0b11",
        "commit_title": "Prevent division by 0 in `resource_variable_ops.cc`",
        "commit_text": " PiperOrigin-RevId: 387939939",
        "func_before": "void AddBatchOffsets(Tensor* indices, const Tensor& params) {\n    int64_t batch_size = 1;  // The size of all batch dimensions.\n    for (int idx = 0; idx < batch_dims_; ++idx) {\n      batch_size *= params.dim_size(idx);\n    }\n\n    auto indices_flat = indices->flat<Index>();\n    int64_t const index_inner_size = indices->NumElements() / batch_size;\n    int64_t const batch_offset = params.dim_size(batch_dims_);\n    for (int64_t batch_idx = 0, dest_idx = 0; batch_idx < batch_size;\n         ++batch_idx) {\n      for (int64_t idx = 0; idx < index_inner_size; ++idx) {\n        indices_flat(dest_idx++) += batch_offset * batch_idx;\n      }\n    }\n  }",
        "func": "void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,\n                       const Tensor& params) {\n    int64_t batch_size = 1;  // The size of all batch dimensions.\n    for (int idx = 0; idx < batch_dims_; ++idx) {\n      batch_size *= params.dim_size(idx);\n    }\n    OP_REQUIRES(\n        ctx, batch_size != 0,\n        errors::InvalidArgument(\n            \"Inner size of indices would result in batch_size of 0 and a \",\n            \"division by 0 in the implementation. This is illegal\"));\n\n    auto indices_flat = indices->flat<Index>();\n    int64_t const index_inner_size = indices->NumElements() / batch_size;\n    int64_t const batch_offset = params.dim_size(batch_dims_);\n    for (int64_t batch_idx = 0, dest_idx = 0; batch_idx < batch_size;\n         ++batch_idx) {\n      for (int64_t idx = 0; idx < index_inner_size; ++idx) {\n        indices_flat(dest_idx++) += batch_offset * batch_idx;\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,14 @@\n-void AddBatchOffsets(Tensor* indices, const Tensor& params) {\n+void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,\n+                       const Tensor& params) {\n     int64_t batch_size = 1;  // The size of all batch dimensions.\n     for (int idx = 0; idx < batch_dims_; ++idx) {\n       batch_size *= params.dim_size(idx);\n     }\n+    OP_REQUIRES(\n+        ctx, batch_size != 0,\n+        errors::InvalidArgument(\n+            \"Inner size of indices would result in batch_size of 0 and a \",\n+            \"division by 0 in the implementation. This is illegal\"));\n \n     auto indices_flat = indices->flat<Index>();\n     int64_t const index_inner_size = indices->NumElements() / batch_size;",
        "diff_line_info": {
            "deleted_lines": [
                "void AddBatchOffsets(Tensor* indices, const Tensor& params) {"
            ],
            "added_lines": [
                "void AddBatchOffsets(OpKernelContext* ctx, Tensor* indices,",
                "                       const Tensor& params) {",
                "    OP_REQUIRES(",
                "        ctx, batch_size != 0,",
                "        errors::InvalidArgument(",
                "            \"Inner size of indices would result in batch_size of 0 and a \",",
                "            \"division by 0 in the implementation. This is illegal\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37675",
        "func_name": "tensorflow/Conv3DShape",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions most implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash. The shape inference [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/framework/common_shape_fns.cc#L577) is missing several validations before doing divisions and modulo operations. We have patched the issue in GitHub commit 8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4",
        "commit_title": "Prevent division by 0 in common shape functions.",
        "commit_text": " PiperOrigin-RevId: 387712197",
        "func_before": "Status Conv3DShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 5, &filter_shape));\n\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the dilation attribute to contain 5 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the stride attribute to contain 5 values, but got: \",\n        strides.size());\n  }\n\n  int32_t stride_planes, stride_rows, stride_cols;\n  int32_t dilation_planes, dilation_rows, dilation_cols;\n  if (s.ok() && data_format == \"NCDHW\") {\n    // Convert input_shape to NDHWC.\n    auto dim = [&](char dimension) {\n      return c->Dim(input_shape, GetTensorDimIndex<3>(FORMAT_NCHW, dimension));\n    };\n    input_shape =\n        c->MakeShape({{dim('N'), dim('0'), dim('1'), dim('2'), dim('C')}});\n    stride_planes = strides[2];\n    stride_rows = strides[3];\n    stride_cols = strides[4];\n    dilation_planes = dilations[2];\n    dilation_cols = dilations[3];\n    dilation_rows = dilations[4];\n  } else {\n    stride_planes = strides[1];\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    dilation_planes = dilations[1];\n    dilation_cols = dilations[2];\n    dilation_rows = dilations[3];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n  DimensionHandle input_depth_dim = c->Dim(input_shape, 4);\n\n  DimensionHandle filter_planes_dim = c->Dim(filter_shape, 0);\n  DimensionHandle filter_rows_dim = c->Dim(filter_shape, 1);\n  DimensionHandle filter_cols_dim = c->Dim(filter_shape, 2);\n  DimensionHandle filter_input_depth_dim = c->Dim(filter_shape, 3);\n  DimensionHandle output_depth_dim = c->Dim(filter_shape, 4);\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n  DimensionHandle output_planes, output_rows, output_cols;\n\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_planes_dim, filter_planes_dim, dilation_planes, stride_planes,\n      padding, -1, -1, &output_planes));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, filter_rows_dim, dilation_rows, stride_rows, padding, -1,\n      -1, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, filter_cols_dim, dilation_cols, stride_cols, padding, -1,\n      -1, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == \"NCDHW\") {\n    output_shape = c->MakeShape({batch_size_dim, output_depth_dim,\n                                 output_planes, output_rows, output_cols});\n  } else {\n    output_shape = c->MakeShape({batch_size_dim, output_planes, output_rows,\n                                 output_cols, output_depth_dim});\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}",
        "func": "Status Conv3DShape(shape_inference::InferenceContext* c) {\n  ShapeHandle input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 5, &input_shape));\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), 5, &filter_shape));\n\n  string data_format;\n  Status s = c->GetAttr(\"data_format\", &data_format);\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the dilation attribute to contain 5 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n  if (strides.size() != 5) {\n    return errors::InvalidArgument(\n        \"Conv3D requires the stride attribute to contain 5 values, but got: \",\n        strides.size());\n  }\n\n  int32_t stride_planes, stride_rows, stride_cols;\n  int32_t dilation_planes, dilation_rows, dilation_cols;\n  if (s.ok() && data_format == \"NCDHW\") {\n    // Convert input_shape to NDHWC.\n    auto dim = [&](char dimension) {\n      return c->Dim(input_shape, GetTensorDimIndex<3>(FORMAT_NCHW, dimension));\n    };\n    input_shape =\n        c->MakeShape({{dim('N'), dim('0'), dim('1'), dim('2'), dim('C')}});\n    stride_planes = strides[2];\n    stride_rows = strides[3];\n    stride_cols = strides[4];\n    dilation_planes = dilations[2];\n    dilation_cols = dilations[3];\n    dilation_rows = dilations[4];\n  } else {\n    stride_planes = strides[1];\n    stride_rows = strides[2];\n    stride_cols = strides[3];\n    dilation_planes = dilations[1];\n    dilation_cols = dilations[2];\n    dilation_rows = dilations[3];\n  }\n\n  DimensionHandle batch_size_dim = c->Dim(input_shape, 0);\n  DimensionHandle in_planes_dim = c->Dim(input_shape, 1);\n  DimensionHandle in_rows_dim = c->Dim(input_shape, 2);\n  DimensionHandle in_cols_dim = c->Dim(input_shape, 3);\n  DimensionHandle input_depth_dim = c->Dim(input_shape, 4);\n\n  DimensionHandle filter_planes_dim = c->Dim(filter_shape, 0);\n  DimensionHandle filter_rows_dim = c->Dim(filter_shape, 1);\n  DimensionHandle filter_cols_dim = c->Dim(filter_shape, 2);\n  DimensionHandle filter_input_depth_dim = c->Dim(filter_shape, 3);\n  DimensionHandle output_depth_dim = c->Dim(filter_shape, 4);\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (filter_input_depth_value == 0)\n      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (num_groups == 0)\n          return errors::InvalidArgument(\"Number of groups must not be 0\");\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n  DimensionHandle output_planes, output_rows, output_cols;\n\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_planes_dim, filter_planes_dim, dilation_planes, stride_planes,\n      padding, -1, -1, &output_planes));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_rows_dim, filter_rows_dim, dilation_rows, stride_rows, padding, -1,\n      -1, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, in_cols_dim, filter_cols_dim, dilation_cols, stride_cols, padding, -1,\n      -1, &output_cols));\n\n  ShapeHandle output_shape;\n  if (data_format == \"NCDHW\") {\n    output_shape = c->MakeShape({batch_size_dim, output_depth_dim,\n                                 output_planes, output_rows, output_cols});\n  } else {\n    output_shape = c->MakeShape({batch_size_dim, output_planes, output_rows,\n                                 output_cols, output_depth_dim});\n  }\n  c->set_output(0, output_shape);\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -65,6 +65,8 @@\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -74,6 +76,8 @@\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (filter_input_depth_value == 0)",
                "      return errors::InvalidArgument(\"Depth of filter must not be 0\");",
                "        if (num_groups == 0)",
                "          return errors::InvalidArgument(\"Number of groups must not be 0\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37675",
        "func_name": "tensorflow/Conv2DShapeImpl",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions most implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash. The shape inference [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/framework/common_shape_fns.cc#L577) is missing several validations before doing divisions and modulo operations. We have patched the issue in GitHub commit 8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4",
        "commit_title": "Prevent division by 0 in common shape functions.",
        "commit_text": " PiperOrigin-RevId: 387712197",
        "func_before": "Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n                       bool supports_explicit_padding) {\n  string data_format_str, filter_format_str;\n  if (!c->GetAttr(\"data_format\", &data_format_str).ok()) {\n    data_format_str = \"NHWC\";\n  }\n  if (!c->GetAttr(\"filter_format\", &filter_format_str).ok()) {\n    filter_format_str = \"HWIO\";\n  }\n\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  FilterTensorFormat filter_format;\n  if (!FilterFormatFromString(filter_format_str, &filter_format)) {\n    return errors::InvalidArgument(\"Invalid filter format string: \",\n                                   filter_format_str);\n  }\n\n  constexpr int num_spatial_dims = 2;\n  const int rank = GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n  ShapeHandle conv_input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &conv_input_shape));\n  TF_RETURN_IF_ERROR(CheckFormatConstraintsOnShape(\n      data_format, conv_input_shape, \"conv_input\", c));\n\n  // The filter rank should match the input (4 for NCHW, 5 for NCHW_VECT_C).\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &filter_shape));\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, filter_shape, \"filter\", c));\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 4) {\n    return errors::InvalidArgument(\n        \"Conv2D requires the dilation attribute to contain 4 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n\n  // strides.size() should be 4 (NCHW) even if the input is 5 (NCHW_VECT_C).\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\"Conv2D on data format \", data_format_str,\n                                   \" requires the stride attribute to contain\"\n                                   \" 4 values, but got: \",\n                                   strides.size());\n  }\n\n  const int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  const int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  const int32_t dilation_rows = GetTensorDim(dilations, data_format, 'H');\n  const int32_t dilation_cols = GetTensorDim(dilations, data_format, 'W');\n\n  DimensionHandle batch_size_dim;\n  DimensionHandle input_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> input_spatial_dims(2);\n  TF_RETURN_IF_ERROR(DimensionsFromShape(\n      conv_input_shape, data_format, &batch_size_dim,\n      absl::MakeSpan(input_spatial_dims), &input_depth_dim, c));\n\n  DimensionHandle output_depth_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'O'));\n  DimensionHandle filter_rows_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'H'));\n  DimensionHandle filter_cols_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'W'));\n  DimensionHandle filter_input_depth_dim;\n  if (filter_format == FORMAT_OIHW_VECT_I) {\n    TF_RETURN_IF_ERROR(c->Multiply(\n        c->Dim(filter_shape,\n               GetFilterDimIndex<num_spatial_dims>(filter_format, 'I')),\n        c->Dim(filter_shape,\n               GetFilterTensorInnerInputChannelsDimIndex(rank, filter_format)),\n        &filter_input_depth_dim));\n  } else {\n    filter_input_depth_dim = c->Dim(\n        filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'I'));\n  }\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status s = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!s.ok() && !errors::IsNotFound(s)) {\n      return s;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    CHECK(padding != Padding::EXPLICIT);  // Crash ok.\n  }\n\n  DimensionHandle output_rows, output_cols;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[0], filter_rows_dim, dilation_rows, stride_rows,\n      padding, pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[1], filter_cols_dim, dilation_cols, stride_cols,\n      padding, pad_cols_before, pad_cols_after, &output_cols));\n\n  absl::optional<DimensionHandle> vect_size;\n  if (data_format == FORMAT_NCHW_VECT_C) {\n    vect_size.emplace(c->Dim(conv_input_shape,\n                             GetTensorInnerFeatureDimIndex(rank, data_format)));\n  }\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(ShapeFromDimensions(\n      batch_size_dim, {output_rows, output_cols}, output_depth_dim, data_format,\n      vect_size, c, &output_shape));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}",
        "func": "Status Conv2DShapeImpl(shape_inference::InferenceContext* c,\n                       bool supports_explicit_padding) {\n  string data_format_str, filter_format_str;\n  if (!c->GetAttr(\"data_format\", &data_format_str).ok()) {\n    data_format_str = \"NHWC\";\n  }\n  if (!c->GetAttr(\"filter_format\", &filter_format_str).ok()) {\n    filter_format_str = \"HWIO\";\n  }\n\n  TensorFormat data_format;\n  if (!FormatFromString(data_format_str, &data_format)) {\n    return errors::InvalidArgument(\"Invalid data format string: \",\n                                   data_format_str);\n  }\n  FilterTensorFormat filter_format;\n  if (!FilterFormatFromString(filter_format_str, &filter_format)) {\n    return errors::InvalidArgument(\"Invalid filter format string: \",\n                                   filter_format_str);\n  }\n\n  constexpr int num_spatial_dims = 2;\n  const int rank = GetTensorDimsFromSpatialDims(num_spatial_dims, data_format);\n  ShapeHandle conv_input_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(0), rank, &conv_input_shape));\n  TF_RETURN_IF_ERROR(CheckFormatConstraintsOnShape(\n      data_format, conv_input_shape, \"conv_input\", c));\n\n  // The filter rank should match the input (4 for NCHW, 5 for NCHW_VECT_C).\n  ShapeHandle filter_shape;\n  TF_RETURN_IF_ERROR(c->WithRank(c->input(1), rank, &filter_shape));\n  TF_RETURN_IF_ERROR(\n      CheckFormatConstraintsOnShape(data_format, filter_shape, \"filter\", c));\n\n  std::vector<int32> dilations;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"dilations\", &dilations));\n\n  if (dilations.size() != 4) {\n    return errors::InvalidArgument(\n        \"Conv2D requires the dilation attribute to contain 4 values, but got: \",\n        dilations.size());\n  }\n\n  std::vector<int32> strides;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"strides\", &strides));\n\n  // strides.size() should be 4 (NCHW) even if the input is 5 (NCHW_VECT_C).\n  if (strides.size() != 4) {\n    return errors::InvalidArgument(\"Conv2D on data format \", data_format_str,\n                                   \" requires the stride attribute to contain\"\n                                   \" 4 values, but got: \",\n                                   strides.size());\n  }\n\n  const int32_t stride_rows = GetTensorDim(strides, data_format, 'H');\n  const int32_t stride_cols = GetTensorDim(strides, data_format, 'W');\n  const int32_t dilation_rows = GetTensorDim(dilations, data_format, 'H');\n  const int32_t dilation_cols = GetTensorDim(dilations, data_format, 'W');\n\n  DimensionHandle batch_size_dim;\n  DimensionHandle input_depth_dim;\n  gtl::InlinedVector<DimensionHandle, 2> input_spatial_dims(2);\n  TF_RETURN_IF_ERROR(DimensionsFromShape(\n      conv_input_shape, data_format, &batch_size_dim,\n      absl::MakeSpan(input_spatial_dims), &input_depth_dim, c));\n\n  DimensionHandle output_depth_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'O'));\n  DimensionHandle filter_rows_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'H'));\n  DimensionHandle filter_cols_dim = c->Dim(\n      filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'W'));\n  DimensionHandle filter_input_depth_dim;\n  if (filter_format == FORMAT_OIHW_VECT_I) {\n    TF_RETURN_IF_ERROR(c->Multiply(\n        c->Dim(filter_shape,\n               GetFilterDimIndex<num_spatial_dims>(filter_format, 'I')),\n        c->Dim(filter_shape,\n               GetFilterTensorInnerInputChannelsDimIndex(rank, filter_format)),\n        &filter_input_depth_dim));\n  } else {\n    filter_input_depth_dim = c->Dim(\n        filter_shape, GetFilterDimIndex<num_spatial_dims>(filter_format, 'I'));\n  }\n\n  // Check that the input tensor and the filter tensor agree on the channel\n  // count.\n  if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n    int64_t input_depth_value = c->Value(input_depth_dim),\n            filter_input_depth_value = c->Value(filter_input_depth_dim);\n    if (filter_input_depth_value == 0)\n      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n    if (input_depth_value % filter_input_depth_value != 0)\n      return errors::InvalidArgument(\n          \"Depth of input (\", input_depth_value,\n          \") is not a multiple of input depth of filter (\",\n          filter_input_depth_value, \")\");\n    if (input_depth_value != filter_input_depth_value) {\n      int64_t num_groups = input_depth_value / filter_input_depth_value;\n      if (c->ValueKnown(output_depth_dim)) {\n        int64_t output_depth_value = c->Value(output_depth_dim);\n        if (num_groups == 0)\n          return errors::InvalidArgument(\"Number of groups must not be 0\");\n        if (output_depth_value % num_groups != 0)\n          return errors::InvalidArgument(\n              \"Depth of output (\", output_depth_value,\n              \") is not a multiple of the number of groups (\", num_groups, \")\");\n      }\n    }\n  }\n\n  Padding padding;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"padding\", &padding));\n\n  std::vector<int64> explicit_paddings;\n  if (supports_explicit_padding) {\n    Status s = c->GetAttr(\"explicit_paddings\", &explicit_paddings);\n    // Use the default value, which is an empty list, if the attribute is not\n    // found. Otherwise return the error to the caller.\n    if (!s.ok() && !errors::IsNotFound(s)) {\n      return s;\n    }\n    TF_RETURN_IF_ERROR(CheckValidPadding(padding, explicit_paddings,\n                                         /*num_dims=*/4, data_format));\n  } else {\n    CHECK(padding != Padding::EXPLICIT);  // Crash ok.\n  }\n\n  DimensionHandle output_rows, output_cols;\n  int64_t pad_rows_before = -1, pad_rows_after = -1;\n  int64_t pad_cols_before = -1, pad_cols_after = -1;\n  if (padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(explicit_paddings, data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[0], filter_rows_dim, dilation_rows, stride_rows,\n      padding, pad_rows_before, pad_rows_after, &output_rows));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeFromDimsV2(\n      c, input_spatial_dims[1], filter_cols_dim, dilation_cols, stride_cols,\n      padding, pad_cols_before, pad_cols_after, &output_cols));\n\n  absl::optional<DimensionHandle> vect_size;\n  if (data_format == FORMAT_NCHW_VECT_C) {\n    vect_size.emplace(c->Dim(conv_input_shape,\n                             GetTensorInnerFeatureDimIndex(rank, data_format)));\n  }\n  ShapeHandle output_shape;\n  TF_RETURN_IF_ERROR(ShapeFromDimensions(\n      batch_size_dim, {output_rows, output_cols}, output_depth_dim, data_format,\n      vect_size, c, &output_shape));\n  c->set_output(0, output_shape);\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -88,6 +88,8 @@\n   if (c->ValueKnown(input_depth_dim) && c->ValueKnown(filter_input_depth_dim)) {\n     int64_t input_depth_value = c->Value(input_depth_dim),\n             filter_input_depth_value = c->Value(filter_input_depth_dim);\n+    if (filter_input_depth_value == 0)\n+      return errors::InvalidArgument(\"Depth of filter must not be 0\");\n     if (input_depth_value % filter_input_depth_value != 0)\n       return errors::InvalidArgument(\n           \"Depth of input (\", input_depth_value,\n@@ -97,6 +99,8 @@\n       int64_t num_groups = input_depth_value / filter_input_depth_value;\n       if (c->ValueKnown(output_depth_dim)) {\n         int64_t output_depth_value = c->Value(output_depth_dim);\n+        if (num_groups == 0)\n+          return errors::InvalidArgument(\"Number of groups must not be 0\");\n         if (output_depth_value % num_groups != 0)\n           return errors::InvalidArgument(\n               \"Depth of output (\", output_depth_value,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (filter_input_depth_value == 0)",
                "      return errors::InvalidArgument(\"Depth of filter must not be 0\");",
                "        if (num_groups == 0)",
                "          return errors::InvalidArgument(\"Number of groups must not be 0\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37675",
        "func_name": "tensorflow/SparseReduceShapeFn",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions most implementations of convolution operators in TensorFlow are affected by a division by 0 vulnerability where an attacker can trigger a denial of service via a crash. The shape inference [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/framework/common_shape_fns.cc#L577) is missing several validations before doing divisions and modulo operations. We have patched the issue in GitHub commit 8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8a793b5d7f59e37ac7f3cd0954a750a2fe76bad4",
        "commit_title": "Prevent division by 0 in common shape functions.",
        "commit_text": " PiperOrigin-RevId: 387712197",
        "func_before": "Status SparseReduceShapeFn(InferenceContext* c) {\n  // Input 0: input_indices\n  // Input 1: input_values\n  // Input 2: input_shape\n  // Input 3: reduction_axes\n  // Attr: keep_dims\n  bool keep_dims = false;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"keep_dims\", &keep_dims));\n\n  const Tensor* shape_tensor = c->input_tensor(2);\n  const Tensor* axes_tensor = c->input_tensor(3);\n  if (shape_tensor != nullptr && axes_tensor != nullptr) {\n    auto shape_vec = shape_tensor->flat<int64>();\n    auto axes_vec = axes_tensor->flat<int32>();\n\n    int64_t ndims = shape_vec.size();\n    absl::flat_hash_set<int64> axes;\n    for (int i = 0; i < axes_vec.size(); i++) {\n      axes.insert((axes_vec(i) + ndims) % ndims);\n    }\n\n    std::vector<DimensionHandle> dims;\n    if (keep_dims) {\n      dims.reserve(ndims);\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        } else {\n          dims.push_back(c->MakeDim(1));\n        }\n      }\n    } else {\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        }\n      }\n    }\n\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  return UnknownShape(c);\n}",
        "func": "Status SparseReduceShapeFn(InferenceContext* c) {\n  // Input 0: input_indices\n  // Input 1: input_values\n  // Input 2: input_shape\n  // Input 3: reduction_axes\n  // Attr: keep_dims\n  bool keep_dims = false;\n  TF_RETURN_IF_ERROR(c->GetAttr(\"keep_dims\", &keep_dims));\n\n  const Tensor* shape_tensor = c->input_tensor(2);\n  const Tensor* axes_tensor = c->input_tensor(3);\n  if (shape_tensor != nullptr && axes_tensor != nullptr) {\n    auto shape_vec = shape_tensor->flat<int64>();\n    auto axes_vec = axes_tensor->flat<int32>();\n\n    int64_t ndims = shape_vec.size();\n    absl::flat_hash_set<int64> axes;\n    if (ndims == 0)\n      return errors::InvalidArgument(\n          \"Number of dims in shape tensor must not be 0\");\n    for (int i = 0; i < axes_vec.size(); i++) {\n      axes.insert((axes_vec(i) + ndims) % ndims);\n    }\n\n    std::vector<DimensionHandle> dims;\n    if (keep_dims) {\n      dims.reserve(ndims);\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        } else {\n          dims.push_back(c->MakeDim(1));\n        }\n      }\n    } else {\n      for (int d = 0; d < ndims; ++d) {\n        if (axes.find(d) == axes.end()) {\n          dims.push_back(c->MakeDim(shape_vec(d)));\n        }\n      }\n    }\n\n    c->set_output(0, c->MakeShape(dims));\n    return Status::OK();\n  }\n  return UnknownShape(c);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,9 @@\n \n     int64_t ndims = shape_vec.size();\n     absl::flat_hash_set<int64> axes;\n+    if (ndims == 0)\n+      return errors::InvalidArgument(\n+          \"Number of dims in shape tensor must not be 0\");\n     for (int i = 0; i < axes_vec.size(); i++) {\n       axes.insert((axes_vec(i) + ndims) % ndims);\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (ndims == 0)",
                "      return errors::InvalidArgument(",
                "          \"Number of dims in shape tensor must not be 0\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37680",
        "func_name": "tensorflow/PrepareImpl",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of fully connected layers in TFLite is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/fully_connected.cc#L226). We have patched the issue in GitHub commit 718721986aa137691ee23f03638867151f74935f. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/718721986aa137691ee23f03638867151f74935f",
        "commit_title": "Prevent division by 0 in `fully_connected.cc`",
        "commit_text": " PiperOrigin-RevId: 385137282",
        "func_before": "TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE(context, node->inputs->size == 2 || node->inputs->size == 3);\n  // Shuffled formats need a workspace to store the shuffled input activations.\n  const int expected_outputs_count =\n      params->weights_format == kTfLiteFullyConnectedWeightsFormatDefault ? 1\n                                                                          : 2;\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, expected_outputs_count);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kWeightsTensor, &filter));\n  const TfLiteTensor* bias =\n      (node->inputs->size == 3)\n          ? GetOptionalInputTensor(context, node, kBiasTensor)\n          : nullptr;\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check proper datatype match among all Input Tensors\n  TF_LITE_ENSURE_STATUS(\n      CheckTypes(context, input, filter, bias, output, params));\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  int input_size = 1;\n  for (int i = 0; i < input->dims->size; i++) {\n    input_size *= input->dims->data[i];\n  }\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);\n  const int batch_size = input_size / filter->dims->data[1];\n  const int num_units = filter->dims->data[0];\n\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));\n  }\n\n  // Note that quantized inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training.\n  if (input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 ||\n      input->type == kTfLiteInt16) {\n    double real_multiplier = 0.0;\n    TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler(\n        context, input, filter, bias, output, &real_multiplier));\n    int exponent;\n    QuantizeMultiplier(real_multiplier, &data->output_multiplier, &exponent);\n    data->output_shift = exponent;\n    TF_LITE_ENSURE_STATUS(CalculateActivationRangeQuantized(\n        context, params->activation, output, &data->output_activation_min,\n        &data->output_activation_max));\n  }\n\n  if (input->type == kTfLiteInt16 && output->type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  // If we have to perform on-the-fly quantization (with quantized weights and\n  // float inputs) first we need to quantize the inputs. Allocate a temporary\n  // buffer to store the intermediate quantized values.\n  // Additionally, we allocate a temporary buffer to store the accumulated\n  // quantized values prior to multiplication by the scaling factor.\n  const bool is_hybrid =\n      (input->type == kTfLiteFloat32 &&\n       (filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8));\n  const bool is_sparse = filter->sparsity != nullptr;\n  if (is_hybrid) {\n    TfLiteIntArrayFree(node->temporaries);\n    data->compute_row_sums = true;\n    if (is_sparse) {\n      node->temporaries = TfLiteIntArrayCreate(6);\n    } else {\n      node->temporaries = TfLiteIntArrayCreate(5);\n    }\n    node->temporaries->data[0] = data->scratch_tensor_index;\n\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,\n                                                &input_quantized));\n    input_quantized->type = filter->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n\n    TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                     input_quantized_size));\n\n    node->temporaries->data[1] = data->scratch_tensor_index + 1;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    node->temporaries->data[2] = data->scratch_tensor_index + 2;\n    TfLiteTensor* accum_scratch;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/2, &accum_scratch));\n    accum_scratch->type = kTfLiteInt32;\n    accum_scratch->allocation_type = kTfLiteArenaRw;\n    int accum_scratch_dims[2] = {num_units, batch_size};\n    if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,\n                                   accum_scratch_dims)) {\n      TfLiteIntArray* accum_size = TfLiteIntArrayCreate(2);\n      accum_size->data[0] = num_units;\n      accum_size->data[1] = batch_size;\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, accum_scratch, accum_size));\n    }\n\n    node->temporaries->data[3] = data->scratch_tensor_index + 3;\n    TfLiteTensor* input_offsets;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/3, &input_offsets));\n    input_offsets->type = kTfLiteInt32;\n    input_offsets->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n      TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n      input_offsets_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                       input_offsets_size));\n    }\n    node->temporaries->data[4] = data->scratch_tensor_index + 4;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/4, &row_sums));\n    row_sums->type = kTfLiteInt32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_units};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n\n    if (is_sparse) {\n      data->ledger_initialized = false;\n      node->temporaries->data[5] = data->scratch_tensor_index + 5;\n      TfLiteTensor* filter_ledger =\n          &context->tensors[node->temporaries->data[5]];\n      auto status =\n          CreateLedgerTensor(filter->sparsity, context, filter_ledger);\n      if (status != kTfLiteOk) return status;\n    }\n  }\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = nullptr;\n  if (params->keep_num_dims) {\n    // When number of dimensions are kept the filter operates along the last\n    // dimensions. In other words, for an input tensor with shape\n    // [batch_size, ..., n_inputs] and a filter of shape [n_inputs, n_units]\n    // this Op produces an output of shape [batch_size, ..., n_units].\n    TF_LITE_ENSURE_EQ(context, input->dims->data[input->dims->size - 1],\n                      SizeOfDimension(filter, 1));\n    output_size_array = TfLiteIntArrayCopy(input->dims);\n    output_size_array->data[output_size_array->size - 1] = num_units;\n  } else {\n    // Otherwise, the output is (potentially flattened to) a 2-D matrix.\n    output_size_array = TfLiteIntArrayCreate(2);\n    output_size_array->data[0] = batch_size;\n    output_size_array->data[1] = num_units;\n  }\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus PrepareImpl(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteFullyConnectedParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE(context, node->inputs->size == 2 || node->inputs->size == 3);\n  // Shuffled formats need a workspace to store the shuffled input activations.\n  const int expected_outputs_count =\n      params->weights_format == kTfLiteFullyConnectedWeightsFormatDefault ? 1\n                                                                          : 2;\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, expected_outputs_count);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kWeightsTensor, &filter));\n  const TfLiteTensor* bias =\n      (node->inputs->size == 3)\n          ? GetOptionalInputTensor(context, node, kBiasTensor)\n          : nullptr;\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check proper datatype match among all Input Tensors\n  TF_LITE_ENSURE_STATUS(\n      CheckTypes(context, input, filter, bias, output, params));\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  int input_size = 1;\n  for (int i = 0; i < input->dims->size; i++) {\n    input_size *= input->dims->data[i];\n  }\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);\n  TF_LITE_ENSURE(context, filter->dims->data[1] != 0);\n  const int batch_size = input_size / filter->dims->data[1];\n  const int num_units = filter->dims->data[0];\n\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));\n  }\n\n  // Note that quantized inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training.\n  if (input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 ||\n      input->type == kTfLiteInt16) {\n    double real_multiplier = 0.0;\n    TF_LITE_ENSURE_STATUS(GetQuantizedConvolutionMultipler(\n        context, input, filter, bias, output, &real_multiplier));\n    int exponent;\n    QuantizeMultiplier(real_multiplier, &data->output_multiplier, &exponent);\n    data->output_shift = exponent;\n    TF_LITE_ENSURE_STATUS(CalculateActivationRangeQuantized(\n        context, params->activation, output, &data->output_activation_min,\n        &data->output_activation_max));\n  }\n\n  if (input->type == kTfLiteInt16 && output->type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  // If we have to perform on-the-fly quantization (with quantized weights and\n  // float inputs) first we need to quantize the inputs. Allocate a temporary\n  // buffer to store the intermediate quantized values.\n  // Additionally, we allocate a temporary buffer to store the accumulated\n  // quantized values prior to multiplication by the scaling factor.\n  const bool is_hybrid =\n      (input->type == kTfLiteFloat32 &&\n       (filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8));\n  const bool is_sparse = filter->sparsity != nullptr;\n  if (is_hybrid) {\n    TfLiteIntArrayFree(node->temporaries);\n    data->compute_row_sums = true;\n    if (is_sparse) {\n      node->temporaries = TfLiteIntArrayCreate(6);\n    } else {\n      node->temporaries = TfLiteIntArrayCreate(5);\n    }\n    node->temporaries->data[0] = data->scratch_tensor_index;\n\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/0,\n                                                &input_quantized));\n    input_quantized->type = filter->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n\n    TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                     input_quantized_size));\n\n    node->temporaries->data[1] = data->scratch_tensor_index + 1;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    node->temporaries->data[2] = data->scratch_tensor_index + 2;\n    TfLiteTensor* accum_scratch;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/2, &accum_scratch));\n    accum_scratch->type = kTfLiteInt32;\n    accum_scratch->allocation_type = kTfLiteArenaRw;\n    int accum_scratch_dims[2] = {num_units, batch_size};\n    if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,\n                                   accum_scratch_dims)) {\n      TfLiteIntArray* accum_size = TfLiteIntArrayCreate(2);\n      accum_size->data[0] = num_units;\n      accum_size->data[1] = batch_size;\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, accum_scratch, accum_size));\n    }\n\n    node->temporaries->data[3] = data->scratch_tensor_index + 3;\n    TfLiteTensor* input_offsets;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/3, &input_offsets));\n    input_offsets->type = kTfLiteInt32;\n    input_offsets->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1, scaling_dims)) {\n      TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n      input_offsets_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                       input_offsets_size));\n    }\n    node->temporaries->data[4] = data->scratch_tensor_index + 4;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/4, &row_sums));\n    row_sums->type = kTfLiteInt32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_units};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n\n    if (is_sparse) {\n      data->ledger_initialized = false;\n      node->temporaries->data[5] = data->scratch_tensor_index + 5;\n      TfLiteTensor* filter_ledger =\n          &context->tensors[node->temporaries->data[5]];\n      auto status =\n          CreateLedgerTensor(filter->sparsity, context, filter_ledger);\n      if (status != kTfLiteOk) return status;\n    }\n  }\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = nullptr;\n  if (params->keep_num_dims) {\n    // When number of dimensions are kept the filter operates along the last\n    // dimensions. In other words, for an input tensor with shape\n    // [batch_size, ..., n_inputs] and a filter of shape [n_inputs, n_units]\n    // this Op produces an output of shape [batch_size, ..., n_units].\n    TF_LITE_ENSURE_EQ(context, input->dims->data[input->dims->size - 1],\n                      SizeOfDimension(filter, 1));\n    output_size_array = TfLiteIntArrayCopy(input->dims);\n    output_size_array->data[output_size_array->size - 1] = num_units;\n  } else {\n    // Otherwise, the output is (potentially flattened to) a 2-D matrix.\n    output_size_array = TfLiteIntArrayCreate(2);\n    output_size_array->data[0] = batch_size;\n    output_size_array->data[1] = num_units;\n  }\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,6 +35,7 @@\n   }\n \n   TF_LITE_ENSURE_EQ(context, NumDimensions(filter), 2);\n+  TF_LITE_ENSURE(context, filter->dims->data[1] != 0);\n   const int batch_size = input_size / filter->dims->data[1];\n   const int num_units = filter->dims->data[0];\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, filter->dims->data[1] != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37668",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause denial of service in applications serving models using `tf.raw_ops.UnravelIndex` by triggering a division by 0. The [implementation](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/core/kernels/unravel_index_op.cc#L36) does not check that the tensor subsumed by `dims` is not empty. Hence, if one element of `dims` is 0, the implementation does a division by 0. We have patched the issue in GitHub commit a776040a5e7ebf76eeb7eb923bf1ae417dd4d233. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/a776040a5e7ebf76eeb7eb923bf1ae417dd4d233",
        "commit_title": "Disallow dims input of 0 in tf.raw_ops.UnravelIndex",
        "commit_text": " PiperOrigin-RevId: 384284198",
        "func_before": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices_tensor = ctx->input(0);\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(indices_tensor.shape()) ||\n                    TensorShapeUtils::IsScalar(indices_tensor.shape()),\n                errors::InvalidArgument(\n                    \"The indices can only be scalar or vector, got \\\"\",\n                    indices_tensor.shape().DebugString(), \"\\\"\"));\n\n    const Tensor& dims_tensor = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(dims_tensor.shape()),\n        errors::InvalidArgument(\"The indices can only be 1-D, got \\\"\",\n                                dims_tensor.shape().DebugString(), \"\\\"\"));\n\n    auto dims = dims_tensor.vec<Tidx>();\n\n    // Chek to make sure indices is not out of boundary\n    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n    Tidx dims_prod = dims_prod_eigen();\n    const Tidx* indices = indices_tensor.flat<Tidx>().data();\n    int64 size = indices_tensor.NumElements();\n    bool check = std::all_of(indices, indices + size,\n                             [&](Tidx index) { return index < dims_prod; });\n    OP_REQUIRES(ctx, check,\n                errors::InvalidArgument(\"index is out of bound as with dims\"));\n\n    Eigen::array<bool, 1> reverse({true});\n\n    Tensor strides_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_tensor));\n\n    auto strides = strides_tensor.vec<Tidx>();\n    strides = dims.reverse(reverse)\n                  .scan(0, Eigen::internal::ProdReducer<Tidx>(), false)\n                  .reverse(reverse);\n\n    Tensor strides_shifted_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_shifted_tensor));\n\n    auto strides_shifted = strides_shifted_tensor.vec<Tidx>();\n    strides_shifted = dims.reverse(reverse)\n                          .scan(0, Eigen::internal::ProdReducer<Tidx>(), true)\n                          .reverse(reverse);\n\n    Tensor* output_tensor = nullptr;\n    if (TensorShapeUtils::IsScalar(indices_tensor.shape())) {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({dims_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->vec<Tidx>();\n\n      output = output.constant(indices_tensor.scalar<Tidx>()());\n      output = output.binaryExpr(strides, mod_op<Tidx>()) / strides_shifted;\n    } else {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0,\n                                    TensorShape({dims_tensor.NumElements(),\n                                                 indices_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->matrix<Tidx>();\n\n      Eigen::array<Eigen::Index, 2> reshape{\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1}};\n      Eigen::array<Eigen::Index, 2> bcast(\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())});\n      Eigen::array<Eigen::Index, 2> indices_reshape{\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())}};\n      Eigen::array<Eigen::Index, 2> indices_bcast(\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1});\n\n      output = indices_tensor.vec<Tidx>()\n                   .reshape(indices_reshape)\n                   .broadcast(indices_bcast);\n      output = output.binaryExpr(strides.reshape(reshape).broadcast(bcast),\n                                 mod_op<Tidx>()) /\n               strides_shifted.reshape(reshape).broadcast(bcast);\n    }\n  }",
        "func": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices_tensor = ctx->input(0);\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(indices_tensor.shape()) ||\n                    TensorShapeUtils::IsScalar(indices_tensor.shape()),\n                errors::InvalidArgument(\n                    \"The indices can only be scalar or vector, got \\\"\",\n                    indices_tensor.shape().DebugString(), \"\\\"\"));\n\n    const Tensor& dims_tensor = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(dims_tensor.shape()),\n        errors::InvalidArgument(\"The indices can only be 1-D, got \\\"\",\n                                dims_tensor.shape().DebugString(), \"\\\"\"));\n\n    auto dims = dims_tensor.vec<Tidx>();\n    // Make sure dims does not contain a zero\n    for (int i = 0; i < dims.size(); i++) {\n      OP_REQUIRES(\n          ctx, dims(i) != 0,\n          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n                                  \"but dims contains zero at index \",\n                                  i));\n    }\n\n    // Chek to make sure indices is not out of boundary\n    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n    Tidx dims_prod = dims_prod_eigen();\n    const Tidx* indices = indices_tensor.flat<Tidx>().data();\n    int64 size = indices_tensor.NumElements();\n    bool check = std::all_of(indices, indices + size,\n                             [&](Tidx index) { return index < dims_prod; });\n    OP_REQUIRES(ctx, check,\n                errors::InvalidArgument(\"index is out of bound as with dims\"));\n\n    Eigen::array<bool, 1> reverse({true});\n\n    Tensor strides_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_tensor));\n\n    auto strides = strides_tensor.vec<Tidx>();\n    strides = dims.reverse(reverse)\n                  .scan(0, Eigen::internal::ProdReducer<Tidx>(), false)\n                  .reverse(reverse);\n\n    Tensor strides_shifted_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_shifted_tensor));\n\n    auto strides_shifted = strides_shifted_tensor.vec<Tidx>();\n    strides_shifted = dims.reverse(reverse)\n                          .scan(0, Eigen::internal::ProdReducer<Tidx>(), true)\n                          .reverse(reverse);\n\n    Tensor* output_tensor = nullptr;\n    if (TensorShapeUtils::IsScalar(indices_tensor.shape())) {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({dims_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->vec<Tidx>();\n\n      output = output.constant(indices_tensor.scalar<Tidx>()());\n      output = output.binaryExpr(strides, mod_op<Tidx>()) / strides_shifted;\n    } else {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0,\n                                    TensorShape({dims_tensor.NumElements(),\n                                                 indices_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->matrix<Tidx>();\n\n      Eigen::array<Eigen::Index, 2> reshape{\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1}};\n      Eigen::array<Eigen::Index, 2> bcast(\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())});\n      Eigen::array<Eigen::Index, 2> indices_reshape{\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())}};\n      Eigen::array<Eigen::Index, 2> indices_bcast(\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1});\n\n      output = indices_tensor.vec<Tidx>()\n                   .reshape(indices_reshape)\n                   .broadcast(indices_bcast);\n      output = output.binaryExpr(strides.reshape(reshape).broadcast(bcast),\n                                 mod_op<Tidx>()) /\n               strides_shifted.reshape(reshape).broadcast(bcast);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,6 +14,14 @@\n                                 dims_tensor.shape().DebugString(), \"\\\"\"));\n \n     auto dims = dims_tensor.vec<Tidx>();\n+    // Make sure dims does not contain a zero\n+    for (int i = 0; i < dims.size(); i++) {\n+      OP_REQUIRES(\n+          ctx, dims(i) != 0,\n+          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n+                                  \"but dims contains zero at index \",\n+                                  i));\n+    }\n \n     // Chek to make sure indices is not out of boundary\n     Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // Make sure dims does not contain a zero",
                "    for (int i = 0; i < dims.size(); i++) {",
                "      OP_REQUIRES(",
                "          ctx, dims(i) != 0,",
                "          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"",
                "                                  \"but dims contains zero at index \",",
                "                                  i));",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37683",
        "func_name": "tensorflow/Eval",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of division in TFLite is [vulnerable to a division by 0 error](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/div.cc). There is no check that the divisor tensor does not contain zero elements. We have patched the issue in GitHub commit 1e206baedf8bef0334cca3eb92bab134ef525a28. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1e206baedf8bef0334cca3eb92bab134ef525a28",
        "commit_title": "Prevent a division by 0 in division ops.",
        "commit_text": " PiperOrigin-RevId: 385223169",
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteDivParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  const TfLiteTensor* input1;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor1, &input1));\n  const TfLiteTensor* input2;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor2, &input2));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n  } else if (output->type == kTfLiteUInt8) {\n    TF_LITE_ENSURE_OK(\n        context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                            input2, output));\n  } else {\n    context->ReportError(\n        context,\n        \"Div only supports FLOAT32, INT32 and quantized UINT8 now, got %d.\",\n        output->type);\n    return kTfLiteError;\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteDivParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  const TfLiteTensor* input1;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor1, &input1));\n  const TfLiteTensor* input2;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kInputTensor2, &input2));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // TODO(b/193904910): This can written with C++ templates\n#define TF_LITE_CHECK_DIV_NON_ZERO(data_type)                       \\\n  const auto* input2_data = GetTensorData<data_type>(input2);       \\\n  const size_t input2_elements = input2->bytes / sizeof(data_type); \\\n  for (size_t i = 0; i < input2_elements; i++) {                    \\\n    TF_LITE_ENSURE(context, input2_data[i] != 0);                   \\\n  }\n\n  if (output->type == kTfLiteFloat32) {\n    // Div by zero seems ok in this case, just like in TF case infinities are\n    // returned. So we don't do a check at this point.\n    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n  } else if (output->type == kTfLiteInt32) {\n    TF_LITE_CHECK_DIV_NON_ZERO(int32_t);\n    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n  } else if (output->type == kTfLiteUInt8) {\n    TF_LITE_CHECK_DIV_NON_ZERO(uint8_t);\n    TF_LITE_ENSURE_OK(\n        context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                            input2, output));\n  } else {\n    context->ReportError(\n        context,\n        \"Div only supports FLOAT32, INT32 and quantized UINT8 now, got %d.\",\n        output->type);\n    return kTfLiteError;\n  }\n#undef TF_LITE_CHECK_DIV_NON_ZERO\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,9 +12,23 @@\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n \n-  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {\n+  // TODO(b/193904910): This can written with C++ templates\n+#define TF_LITE_CHECK_DIV_NON_ZERO(data_type)                       \\\n+  const auto* input2_data = GetTensorData<data_type>(input2);       \\\n+  const size_t input2_elements = input2->bytes / sizeof(data_type); \\\n+  for (size_t i = 0; i < input2_elements; i++) {                    \\\n+    TF_LITE_ENSURE(context, input2_data[i] != 0);                   \\\n+  }\n+\n+  if (output->type == kTfLiteFloat32) {\n+    // Div by zero seems ok in this case, just like in TF case infinities are\n+    // returned. So we don't do a check at this point.\n+    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n+  } else if (output->type == kTfLiteInt32) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(int32_t);\n     EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);\n   } else if (output->type == kTfLiteUInt8) {\n+    TF_LITE_CHECK_DIV_NON_ZERO(uint8_t);\n     TF_LITE_ENSURE_OK(\n         context, EvalQuantized<kernel_type>(context, node, params, data, input1,\n                                             input2, output));\n@@ -25,6 +39,7 @@\n         output->type);\n     return kTfLiteError;\n   }\n+#undef TF_LITE_CHECK_DIV_NON_ZERO\n \n   return kTfLiteOk;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (output->type == kTfLiteFloat32 || output->type == kTfLiteInt32) {"
            ],
            "added_lines": [
                "  // TODO(b/193904910): This can written with C++ templates",
                "#define TF_LITE_CHECK_DIV_NON_ZERO(data_type)                       \\",
                "  const auto* input2_data = GetTensorData<data_type>(input2);       \\",
                "  const size_t input2_elements = input2->bytes / sizeof(data_type); \\",
                "  for (size_t i = 0; i < input2_elements; i++) {                    \\",
                "    TF_LITE_ENSURE(context, input2_data[i] != 0);                   \\",
                "  }",
                "",
                "  if (output->type == kTfLiteFloat32) {",
                "    // Div by zero seems ok in this case, just like in TF case infinities are",
                "    // returned. So we don't do a check at this point.",
                "    EvalDiv<kernel_type>(context, node, params, data, input1, input2, output);",
                "  } else if (output->type == kTfLiteInt32) {",
                "    TF_LITE_CHECK_DIV_NON_ZERO(int32_t);",
                "    TF_LITE_CHECK_DIV_NON_ZERO(uint8_t);",
                "#undef TF_LITE_CHECK_DIV_NON_ZERO"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-37691",
        "func_name": "tensorflow/Resize",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can craft a TFLite model that would trigger a division by zero error in LSH [implementation](https://github.com/tensorflow/tensorflow/blob/149562d49faa709ea80df1d99fc41d005b81082a/tensorflow/lite/kernels/lsh_projection.cc#L118). We have patched the issue in GitHub commit 0575b640091680cfb70f4dd93e70658de43b94f9. The fix will be included in TensorFlow 2.6.0. We will also cherrypick thiscommit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/0575b640091680cfb70f4dd93e70658de43b94f9",
        "commit_title": "Prevent division by 0 in LSH projection.",
        "commit_text": " PiperOrigin-RevId: 387225857",
        "func_before": "TfLiteStatus Resize(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteLSHProjectionParams*>(node->builtin_data);\n  TF_LITE_ENSURE(context, NumInputs(node) == 2 || NumInputs(node) == 3);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* hash;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &hash));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(hash), 2);\n  // Support up to 32 bits.\n  TF_LITE_ENSURE(context, SizeOfDimension(hash, 1) <= 32);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &input));\n  TF_LITE_ENSURE(context, NumDimensions(input) >= 1);\n\n  if (NumInputs(node) == 3) {\n    const TfLiteTensor* weight;\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &weight));\n    TF_LITE_ENSURE_EQ(context, NumDimensions(weight), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(weight, 0),\n                      SizeOfDimension(input, 0));\n  }\n\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n  switch (params->type) {\n    case kTfLiteLshProjectionSparse:\n      outputSize->data[0] = SizeOfDimension(hash, 0);\n      break;\n    case kTfLiteLshProjectionDense:\n      outputSize->data[0] = SizeOfDimension(hash, 0) * SizeOfDimension(hash, 1);\n      break;\n    default:\n      return kTfLiteError;\n  }\n  return context->ResizeTensor(context, output, outputSize);\n}",
        "func": "TfLiteStatus Resize(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteLSHProjectionParams*>(node->builtin_data);\n  TF_LITE_ENSURE(context, NumInputs(node) == 2 || NumInputs(node) == 3);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* hash;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &hash));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(hash), 2);\n  // Support up to 32 bits.\n  TF_LITE_ENSURE(context, SizeOfDimension(hash, 1) <= 32);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &input));\n  TF_LITE_ENSURE(context, NumDimensions(input) >= 1);\n  TF_LITE_ENSURE(context, SizeOfDimension(input, 0) >= 1);\n\n  if (NumInputs(node) == 3) {\n    const TfLiteTensor* weight;\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &weight));\n    TF_LITE_ENSURE_EQ(context, NumDimensions(weight), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(weight, 0),\n                      SizeOfDimension(input, 0));\n  }\n\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n  switch (params->type) {\n    case kTfLiteLshProjectionSparse:\n      outputSize->data[0] = SizeOfDimension(hash, 0);\n      break;\n    case kTfLiteLshProjectionDense:\n      outputSize->data[0] = SizeOfDimension(hash, 0) * SizeOfDimension(hash, 1);\n      break;\n    default:\n      return kTfLiteError;\n  }\n  return context->ResizeTensor(context, output, outputSize);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n   const TfLiteTensor* input;\n   TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &input));\n   TF_LITE_ENSURE(context, NumDimensions(input) >= 1);\n+  TF_LITE_ENSURE(context, SizeOfDimension(input, 0) >= 1);\n \n   if (NumInputs(node) == 3) {\n     const TfLiteTensor* weight;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, SizeOfDimension(input, 0) >= 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-36692",
        "func_name": "libjxl/DecodeImageAPNG",
        "description": "libjxl v0.3.7 is affected by a Divide By Zero in issue in lib/extras/codec_apng.cc jxl::DecodeImageAPNG(). When encoding a malicous APNG file using cjxl, an attacker can trigger a denial of service.",
        "git_url": "https://github.com/libjxl/libjxl/commit/7dfa400ded53919d986c5d3d23446a09e0cf481b",
        "commit_title": "Fix handling of APNG with 0 delay_den (#313)",
        "commit_text": "",
        "func_before": "Status DecodeImageAPNG(Span<const uint8_t> bytes, ThreadPool* pool,\n                       CodecInOut* io) {\n  Reader r;\n  unsigned int id, i, j, w, h, w0, h0, x0, y0;\n  unsigned int delay_num, delay_den, dop, bop, rowbytes, imagesize;\n  unsigned char sig[8];\n  png_structp png_ptr;\n  png_infop info_ptr;\n  CHUNK chunk;\n  CHUNK chunkIHDR;\n  std::vector<CHUNK> chunksInfo;\n  bool isAnimated = false;\n  bool skipFirst = false;\n  bool hasInfo = false;\n  bool all_dispose_bg = true;\n  APNGFrame frameRaw = {};\n\n  r = {bytes.data(), bytes.data() + bytes.size()};\n  // Not an aPNG => not an error\n  unsigned char png_signature[8] = {137, 80, 78, 71, 13, 10, 26, 10};\n  if (r.Read(sig, 8) || memcmp(sig, png_signature, 8) != 0) {\n    return false;\n  }\n  id = read_chunk(&r, &chunkIHDR);\n\n  io->frames.clear();\n  io->dec_pixels = 0;\n  io->metadata.m.SetUintSamples(8);\n  io->metadata.m.SetAlphaBits(8);\n  io->metadata.m.color_encoding =\n      ColorEncoding::SRGB();  // todo: get data from png metadata\n  (void)io->dec_hints.Foreach(\n      [](const std::string& key, const std::string& /*value*/) {\n        JXL_WARNING(\"APNG decoder ignoring %s hint\", key.c_str());\n        return true;\n      });\n\n  bool errorstate = true;\n  if (id == kId_IHDR && chunkIHDR.size == 25) {\n    w0 = w = png_get_uint_32(chunkIHDR.p + 8);\n    h0 = h = png_get_uint_32(chunkIHDR.p + 12);\n\n    if (w > cMaxPNGSize || h > cMaxPNGSize) {\n      return false;\n    }\n\n    x0 = 0;\n    y0 = 0;\n    delay_num = 1;\n    delay_den = 10;\n    dop = 0;\n    bop = 0;\n    rowbytes = w * 4;\n    imagesize = h * rowbytes;\n\n    frameRaw.p = new unsigned char[imagesize];\n    frameRaw.rows = new png_bytep[h * sizeof(png_bytep)];\n    for (j = 0; j < h; j++) frameRaw.rows[j] = frameRaw.p + j * rowbytes;\n\n    if (!processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                          chunkIHDR, chunksInfo)) {\n      bool last_base_was_none = true;\n      while (!r.Eof()) {\n        id = read_chunk(&r, &chunk);\n        if (!id) break;\n        JXL_ASSERT(chunk.p != nullptr);\n\n        if (id == kId_acTL && !hasInfo && !isAnimated) {\n          isAnimated = true;\n          skipFirst = true;\n          io->metadata.m.have_animation = true;\n          io->metadata.m.animation.tps_numerator = 1000;\n        } else if (id == kId_IEND ||\n                   (id == kId_fcTL && (!hasInfo || isAnimated))) {\n          if (hasInfo) {\n            if (!processing_finish(png_ptr, info_ptr)) {\n              ImageBundle bundle(&io->metadata.m);\n              bundle.duration = delay_num * 1000 / delay_den;\n              bundle.origin.x0 = x0;\n              bundle.origin.y0 = y0;\n              // TODO(veluca): this could in principle be implemented.\n              if (last_base_was_none && !all_dispose_bg &&\n                  (x0 != 0 || y0 != 0 || w0 != w || h0 != h || bop != 0)) {\n                return JXL_FAILURE(\n                    \"APNG with dispose-to-0 is not supported for non-full or \"\n                    \"blended frames\");\n              }\n              switch (dop) {\n                case 0:\n                  bundle.use_for_next_frame = true;\n                  last_base_was_none = false;\n                  all_dispose_bg = false;\n                  break;\n                case 2:\n                  bundle.use_for_next_frame = false;\n                  all_dispose_bg = false;\n                  break;\n                default:\n                  bundle.use_for_next_frame = false;\n                  last_base_was_none = true;\n              }\n              bundle.blend = bop != 0;\n              io->dec_pixels += w0 * h0;\n\n              Image3F sub_frame(w0, h0);\n              ImageF sub_frame_alpha(w0, h0);\n              for (size_t y = 0; y < h0; ++y) {\n                float* const JXL_RESTRICT row_r = sub_frame.PlaneRow(0, y);\n                float* const JXL_RESTRICT row_g = sub_frame.PlaneRow(1, y);\n                float* const JXL_RESTRICT row_b = sub_frame.PlaneRow(2, y);\n                float* const JXL_RESTRICT row_alpha = sub_frame_alpha.Row(y);\n                uint8_t* const f = frameRaw.rows[y];\n                for (size_t x = 0; x < w0; ++x) {\n                  if (f[4 * x + 3] == 0) {\n                    row_alpha[x] = 0;\n                    row_r[x] = 0;\n                    row_g[x] = 0;\n                    row_b[x] = 0;\n                    continue;\n                  }\n                  row_r[x] = f[4 * x + 0] * (1.f / 255);\n                  row_g[x] = f[4 * x + 1] * (1.f / 255);\n                  row_b[x] = f[4 * x + 2] * (1.f / 255);\n                  row_alpha[x] = f[4 * x + 3] * (1.f / 255);\n                }\n              }\n              bundle.SetFromImage(std::move(sub_frame), ColorEncoding::SRGB());\n              bundle.SetAlpha(std::move(sub_frame_alpha),\n                              /*alpha_is_premultiplied=*/false);\n              io->frames.push_back(std::move(bundle));\n            } else {\n              delete[] chunk.p;\n              break;\n            }\n          }\n\n          if (id == kId_IEND) {\n            errorstate = false;\n            break;\n          }\n          // At this point the old frame is done. Let's start a new one.\n          w0 = png_get_uint_32(chunk.p + 12);\n          h0 = png_get_uint_32(chunk.p + 16);\n          x0 = png_get_uint_32(chunk.p + 20);\n          y0 = png_get_uint_32(chunk.p + 24);\n          delay_num = png_get_uint_16(chunk.p + 28);\n          delay_den = png_get_uint_16(chunk.p + 30);\n          dop = chunk.p[32];\n          bop = chunk.p[33];\n\n          if (w0 > cMaxPNGSize || h0 > cMaxPNGSize || x0 > cMaxPNGSize ||\n              y0 > cMaxPNGSize || x0 + w0 > w || y0 + h0 > h || dop > 2 ||\n              bop > 1) {\n            delete[] chunk.p;\n            break;\n          }\n\n          if (hasInfo) {\n            memcpy(chunkIHDR.p + 8, chunk.p + 12, 8);\n            if (processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                                 chunkIHDR, chunksInfo)) {\n              delete[] chunk.p;\n              break;\n            }\n          } else\n            skipFirst = false;\n\n          if (io->frames.size() == (skipFirst ? 1 : 0)) {\n            bop = 0;\n            if (dop == 2) dop = 1;\n          }\n        } else if (id == kId_IDAT) {\n          hasInfo = true;\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (id == kId_fdAT && isAnimated) {\n          png_save_uint_32(chunk.p + 4, chunk.size - 16);\n          memcpy(chunk.p + 8, \"IDAT\", 4);\n          if (processing_data(png_ptr, info_ptr, chunk.p + 4, chunk.size - 4)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (!isAbc(chunk.p[4]) || !isAbc(chunk.p[5]) ||\n                   !isAbc(chunk.p[6]) || !isAbc(chunk.p[7])) {\n          delete[] chunk.p;\n          break;\n        } else if (!hasInfo) {\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n          chunksInfo.push_back(chunk);\n          continue;\n        }\n        delete[] chunk.p;\n      }\n    }\n    delete[] frameRaw.rows;\n    delete[] frameRaw.p;\n  }\n\n  for (i = 0; i < chunksInfo.size(); i++) delete[] chunksInfo[i].p;\n\n  chunksInfo.clear();\n  delete[] chunkIHDR.p;\n\n  if (errorstate) return false;\n  SetIntensityTarget(io);\n  return true;\n}",
        "func": "Status DecodeImageAPNG(Span<const uint8_t> bytes, ThreadPool* pool,\n                       CodecInOut* io) {\n  Reader r;\n  unsigned int id, i, j, w, h, w0, h0, x0, y0;\n  unsigned int delay_num, delay_den, dop, bop, rowbytes, imagesize;\n  unsigned char sig[8];\n  png_structp png_ptr;\n  png_infop info_ptr;\n  CHUNK chunk;\n  CHUNK chunkIHDR;\n  std::vector<CHUNK> chunksInfo;\n  bool isAnimated = false;\n  bool skipFirst = false;\n  bool hasInfo = false;\n  bool all_dispose_bg = true;\n  APNGFrame frameRaw = {};\n\n  r = {bytes.data(), bytes.data() + bytes.size()};\n  // Not an aPNG => not an error\n  unsigned char png_signature[8] = {137, 80, 78, 71, 13, 10, 26, 10};\n  if (r.Read(sig, 8) || memcmp(sig, png_signature, 8) != 0) {\n    return false;\n  }\n  id = read_chunk(&r, &chunkIHDR);\n\n  io->frames.clear();\n  io->dec_pixels = 0;\n  io->metadata.m.SetUintSamples(8);\n  io->metadata.m.SetAlphaBits(8);\n  io->metadata.m.color_encoding =\n      ColorEncoding::SRGB();  // todo: get data from png metadata\n  (void)io->dec_hints.Foreach(\n      [](const std::string& key, const std::string& /*value*/) {\n        JXL_WARNING(\"APNG decoder ignoring %s hint\", key.c_str());\n        return true;\n      });\n\n  bool errorstate = true;\n  if (id == kId_IHDR && chunkIHDR.size == 25) {\n    w0 = w = png_get_uint_32(chunkIHDR.p + 8);\n    h0 = h = png_get_uint_32(chunkIHDR.p + 12);\n\n    if (w > cMaxPNGSize || h > cMaxPNGSize) {\n      return false;\n    }\n\n    x0 = 0;\n    y0 = 0;\n    delay_num = 1;\n    delay_den = 10;\n    dop = 0;\n    bop = 0;\n    rowbytes = w * 4;\n    imagesize = h * rowbytes;\n\n    frameRaw.p = new unsigned char[imagesize];\n    frameRaw.rows = new png_bytep[h * sizeof(png_bytep)];\n    for (j = 0; j < h; j++) frameRaw.rows[j] = frameRaw.p + j * rowbytes;\n\n    if (!processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                          chunkIHDR, chunksInfo)) {\n      bool last_base_was_none = true;\n      while (!r.Eof()) {\n        id = read_chunk(&r, &chunk);\n        if (!id) break;\n        JXL_ASSERT(chunk.p != nullptr);\n\n        if (id == kId_acTL && !hasInfo && !isAnimated) {\n          isAnimated = true;\n          skipFirst = true;\n          io->metadata.m.have_animation = true;\n          io->metadata.m.animation.tps_numerator = 1000;\n        } else if (id == kId_IEND ||\n                   (id == kId_fcTL && (!hasInfo || isAnimated))) {\n          if (hasInfo) {\n            if (!processing_finish(png_ptr, info_ptr)) {\n              ImageBundle bundle(&io->metadata.m);\n              bundle.duration = delay_num * 1000 / delay_den;\n              bundle.origin.x0 = x0;\n              bundle.origin.y0 = y0;\n              // TODO(veluca): this could in principle be implemented.\n              if (last_base_was_none && !all_dispose_bg &&\n                  (x0 != 0 || y0 != 0 || w0 != w || h0 != h || bop != 0)) {\n                return JXL_FAILURE(\n                    \"APNG with dispose-to-0 is not supported for non-full or \"\n                    \"blended frames\");\n              }\n              switch (dop) {\n                case 0:\n                  bundle.use_for_next_frame = true;\n                  last_base_was_none = false;\n                  all_dispose_bg = false;\n                  break;\n                case 2:\n                  bundle.use_for_next_frame = false;\n                  all_dispose_bg = false;\n                  break;\n                default:\n                  bundle.use_for_next_frame = false;\n                  last_base_was_none = true;\n              }\n              bundle.blend = bop != 0;\n              io->dec_pixels += w0 * h0;\n\n              Image3F sub_frame(w0, h0);\n              ImageF sub_frame_alpha(w0, h0);\n              for (size_t y = 0; y < h0; ++y) {\n                float* const JXL_RESTRICT row_r = sub_frame.PlaneRow(0, y);\n                float* const JXL_RESTRICT row_g = sub_frame.PlaneRow(1, y);\n                float* const JXL_RESTRICT row_b = sub_frame.PlaneRow(2, y);\n                float* const JXL_RESTRICT row_alpha = sub_frame_alpha.Row(y);\n                uint8_t* const f = frameRaw.rows[y];\n                for (size_t x = 0; x < w0; ++x) {\n                  if (f[4 * x + 3] == 0) {\n                    row_alpha[x] = 0;\n                    row_r[x] = 0;\n                    row_g[x] = 0;\n                    row_b[x] = 0;\n                    continue;\n                  }\n                  row_r[x] = f[4 * x + 0] * (1.f / 255);\n                  row_g[x] = f[4 * x + 1] * (1.f / 255);\n                  row_b[x] = f[4 * x + 2] * (1.f / 255);\n                  row_alpha[x] = f[4 * x + 3] * (1.f / 255);\n                }\n              }\n              bundle.SetFromImage(std::move(sub_frame), ColorEncoding::SRGB());\n              bundle.SetAlpha(std::move(sub_frame_alpha),\n                              /*alpha_is_premultiplied=*/false);\n              io->frames.push_back(std::move(bundle));\n            } else {\n              delete[] chunk.p;\n              break;\n            }\n          }\n\n          if (id == kId_IEND) {\n            errorstate = false;\n            break;\n          }\n          // At this point the old frame is done. Let's start a new one.\n          w0 = png_get_uint_32(chunk.p + 12);\n          h0 = png_get_uint_32(chunk.p + 16);\n          x0 = png_get_uint_32(chunk.p + 20);\n          y0 = png_get_uint_32(chunk.p + 24);\n          delay_num = png_get_uint_16(chunk.p + 28);\n          delay_den = png_get_uint_16(chunk.p + 30);\n          dop = chunk.p[32];\n          bop = chunk.p[33];\n\n          if (!delay_den) delay_den = 100;\n\n          if (w0 > cMaxPNGSize || h0 > cMaxPNGSize || x0 > cMaxPNGSize ||\n              y0 > cMaxPNGSize || x0 + w0 > w || y0 + h0 > h || dop > 2 ||\n              bop > 1) {\n            delete[] chunk.p;\n            break;\n          }\n\n          if (hasInfo) {\n            memcpy(chunkIHDR.p + 8, chunk.p + 12, 8);\n            if (processing_start(png_ptr, info_ptr, (void*)&frameRaw, hasInfo,\n                                 chunkIHDR, chunksInfo)) {\n              delete[] chunk.p;\n              break;\n            }\n          } else\n            skipFirst = false;\n\n          if (io->frames.size() == (skipFirst ? 1 : 0)) {\n            bop = 0;\n            if (dop == 2) dop = 1;\n          }\n        } else if (id == kId_IDAT) {\n          hasInfo = true;\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (id == kId_fdAT && isAnimated) {\n          png_save_uint_32(chunk.p + 4, chunk.size - 16);\n          memcpy(chunk.p + 8, \"IDAT\", 4);\n          if (processing_data(png_ptr, info_ptr, chunk.p + 4, chunk.size - 4)) {\n            delete[] chunk.p;\n            break;\n          }\n        } else if (!isAbc(chunk.p[4]) || !isAbc(chunk.p[5]) ||\n                   !isAbc(chunk.p[6]) || !isAbc(chunk.p[7])) {\n          delete[] chunk.p;\n          break;\n        } else if (!hasInfo) {\n          if (processing_data(png_ptr, info_ptr, chunk.p, chunk.size)) {\n            delete[] chunk.p;\n            break;\n          }\n          chunksInfo.push_back(chunk);\n          continue;\n        }\n        delete[] chunk.p;\n      }\n    }\n    delete[] frameRaw.rows;\n    delete[] frameRaw.p;\n  }\n\n  for (i = 0; i < chunksInfo.size(); i++) delete[] chunksInfo[i].p;\n\n  chunksInfo.clear();\n  delete[] chunkIHDR.p;\n\n  if (errorstate) return false;\n  SetIntensityTarget(io);\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -148,6 +148,8 @@\n           dop = chunk.p[32];\n           bop = chunk.p[33];\n \n+          if (!delay_den) delay_den = 100;\n+\n           if (w0 > cMaxPNGSize || h0 > cMaxPNGSize || x0 > cMaxPNGSize ||\n               y0 > cMaxPNGSize || x0 + w0 > w || y0 + h0 > h || dop > 2 ||\n               bop > 1) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "          if (!delay_den) delay_den = 100;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2020-20892",
        "func_name": "ffmpeg/filter_frame",
        "description": "An issue was discovered in function filter_frame in libavfilter/vf_lenscorrection.c in Ffmpeg 4.2.1, allows attackers to cause a Denial of Service or other unspecified impacts due to a division by zero.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=19587c9332f5be4f6bc6d7b2b8ef3fd21dfeaa01",
        "commit_title": "",
        "commit_text": "avfilter/vf_lenscorrection: fix division by zero  Fixes #8265 ",
        "func_before": "static int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    AVFilterContext *ctx = inlink->dst;\n    AVFilterLink *outlink = ctx->outputs[0];\n    LenscorrectionCtx *rect = (LenscorrectionCtx*)ctx->priv;\n    AVFrame *out = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n    int plane;\n\n    if (!out) {\n        av_frame_free(&in);\n        return AVERROR(ENOMEM);\n    }\n\n    av_frame_copy_props(out, in);\n\n    for (plane = 0; plane < rect->nb_planes; ++plane) {\n        int hsub = plane == 1 || plane == 2 ? rect->hsub : 0;\n        int vsub = plane == 1 || plane == 2 ? rect->vsub : 0;\n        int hdiv = 1 << hsub;\n        int vdiv = 1 << vsub;\n        int w = rect->width / hdiv;\n        int h = rect->height / vdiv;\n        int xcenter = rect->cx * w;\n        int ycenter = rect->cy * h;\n        int k1 = rect->k1 * (1<<24);\n        int k2 = rect->k2 * (1<<24);\n        ThreadData td = {\n            .in = in,\n            .out  = out,\n            .w  = w,\n            .h  = h,\n            .xcenter = xcenter,\n            .ycenter = ycenter,\n            .plane = plane};\n\n        if (!rect->correction[plane]) {\n            int i,j;\n            const int64_t r2inv = (4LL<<60) / (w * w + h * h);\n\n            rect->correction[plane] = av_malloc_array(w, h * sizeof(**rect->correction));\n            if (!rect->correction[plane])\n                return AVERROR(ENOMEM);\n            for (j = 0; j < h; j++) {\n                const int off_y = j - ycenter;\n                const int off_y2 = off_y * off_y;\n                for (i = 0; i < w; i++) {\n                    const int off_x = i - xcenter;\n                    const int64_t r2 = ((off_x * off_x + off_y2) * r2inv + (1LL<<31)) >> 32;\n                    const int64_t r4 = (r2 * r2 + (1<<27)) >> 28;\n                    const int radius_mult = (r2 * k1 + r4 * k2 + (1LL<<27) + (1LL<<52))>>28;\n                    rect->correction[plane][j * w + i] = radius_mult;\n                }\n            }\n        }\n\n        td.correction = rect->correction[plane];\n        ctx->internal->execute(ctx, filter_slice, &td, NULL, FFMIN(h, ff_filter_get_nb_threads(ctx)));\n    }\n\n    av_frame_free(&in);\n    return ff_filter_frame(outlink, out);\n}",
        "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *in)\n{\n    AVFilterContext *ctx = inlink->dst;\n    AVFilterLink *outlink = ctx->outputs[0];\n    LenscorrectionCtx *rect = (LenscorrectionCtx*)ctx->priv;\n    AVFrame *out = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n    int plane;\n\n    if (!out) {\n        av_frame_free(&in);\n        return AVERROR(ENOMEM);\n    }\n\n    av_frame_copy_props(out, in);\n\n    for (plane = 0; plane < rect->nb_planes; ++plane) {\n        int hsub = plane == 1 || plane == 2 ? rect->hsub : 0;\n        int vsub = plane == 1 || plane == 2 ? rect->vsub : 0;\n        int w = AV_CEIL_RSHIFT(rect->width, hsub);\n        int h = AV_CEIL_RSHIFT(rect->height, vsub);\n        int xcenter = rect->cx * w;\n        int ycenter = rect->cy * h;\n        int k1 = rect->k1 * (1<<24);\n        int k2 = rect->k2 * (1<<24);\n        ThreadData td = {\n            .in = in,\n            .out  = out,\n            .w  = w,\n            .h  = h,\n            .xcenter = xcenter,\n            .ycenter = ycenter,\n            .plane = plane};\n\n        if (!rect->correction[plane]) {\n            int i,j;\n            const int64_t r2inv = (4LL<<60) / (w * w + h * h);\n\n            rect->correction[plane] = av_malloc_array(w, h * sizeof(**rect->correction));\n            if (!rect->correction[plane])\n                return AVERROR(ENOMEM);\n            for (j = 0; j < h; j++) {\n                const int off_y = j - ycenter;\n                const int off_y2 = off_y * off_y;\n                for (i = 0; i < w; i++) {\n                    const int off_x = i - xcenter;\n                    const int64_t r2 = ((off_x * off_x + off_y2) * r2inv + (1LL<<31)) >> 32;\n                    const int64_t r4 = (r2 * r2 + (1<<27)) >> 28;\n                    const int radius_mult = (r2 * k1 + r4 * k2 + (1LL<<27) + (1LL<<52))>>28;\n                    rect->correction[plane][j * w + i] = radius_mult;\n                }\n            }\n        }\n\n        td.correction = rect->correction[plane];\n        ctx->internal->execute(ctx, filter_slice, &td, NULL, FFMIN(h, ff_filter_get_nb_threads(ctx)));\n    }\n\n    av_frame_free(&in);\n    return ff_filter_frame(outlink, out);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,10 +16,8 @@\n     for (plane = 0; plane < rect->nb_planes; ++plane) {\n         int hsub = plane == 1 || plane == 2 ? rect->hsub : 0;\n         int vsub = plane == 1 || plane == 2 ? rect->vsub : 0;\n-        int hdiv = 1 << hsub;\n-        int vdiv = 1 << vsub;\n-        int w = rect->width / hdiv;\n-        int h = rect->height / vdiv;\n+        int w = AV_CEIL_RSHIFT(rect->width, hsub);\n+        int h = AV_CEIL_RSHIFT(rect->height, vsub);\n         int xcenter = rect->cx * w;\n         int ycenter = rect->cy * h;\n         int k1 = rect->k1 * (1<<24);",
        "diff_line_info": {
            "deleted_lines": [
                "        int hdiv = 1 << hsub;",
                "        int vdiv = 1 << vsub;",
                "        int w = rect->width / hdiv;",
                "        int h = rect->height / vdiv;"
            ],
            "added_lines": [
                "        int w = AV_CEIL_RSHIFT(rect->width, hsub);",
                "        int h = AV_CEIL_RSHIFT(rect->height, vsub);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-17054",
        "func_name": "aubio/new_aubio_source_avcodec",
        "description": "In aubio 0.4.6, a divide-by-zero error exists in the function new_aubio_source_wavread() in source_wavread.c, which may lead to DoS when playing a crafted audio file.",
        "git_url": "https://github.com/aubio/aubio/commit/06df24787ff37e6f08a870d52e2ed4c62d2caa11",
        "commit_title": "src/io/source_avcodec.c: give up if resampling context failed opening (see #148, closes #187)",
        "commit_text": "",
        "func_before": "aubio_source_avcodec_t * new_aubio_source_avcodec(const char_t * path, uint_t samplerate, uint_t hop_size) {\n  aubio_source_avcodec_t * s = AUBIO_NEW(aubio_source_avcodec_t);\n  AVFormatContext *avFormatCtx = s->avFormatCtx;\n  AVCodecContext *avCodecCtx = s->avCodecCtx;\n  AVFrame *avFrame = s->avFrame;\n  sint_t selected_stream = -1;\n#if FF_API_LAVF_AVCTX\n  AVCodecParameters *codecpar;\n#endif\n  AVCodec *codec;\n  uint_t i;\n  int err;\n  if (path == NULL) {\n    AUBIO_ERR(\"source_avcodec: Aborted opening null path\\n\");\n    goto beach;\n  }\n  if ((sint_t)samplerate < 0) {\n    AUBIO_ERR(\"source_avcodec: Can not open %s with samplerate %d\\n\", path, samplerate);\n    goto beach;\n  }\n  if ((sint_t)hop_size <= 0) {\n    AUBIO_ERR(\"source_avcodec: Can not open %s with hop_size %d\\n\", path, hop_size);\n    goto beach;\n  }\n\n  s->hop_size = hop_size;\n  s->channels = 1;\n\n  if (s->path) AUBIO_FREE(s->path);\n  s->path = AUBIO_ARRAY(char_t, strnlen(path, PATH_MAX) + 1);\n  strncpy(s->path, path, strnlen(path, PATH_MAX) + 1);\n\n  // register all formats and codecs\n  av_register_all();\n\n  if (aubio_source_avcodec_has_network_url(s)) {\n    avformat_network_init();\n  }\n\n  // try opening the file and get some info about it\n  avFormatCtx = NULL;\n  if ( (err = avformat_open_input(&avFormatCtx, s->path, NULL, NULL) ) < 0 ) {\n    char errorstr[256];\n    av_strerror (err, errorstr, sizeof(errorstr));\n    AUBIO_ERR(\"source_avcodec: Failed opening %s (%s)\\n\", s->path, errorstr);\n    goto beach;\n  }\n\n  // try to make sure max_analyze_duration is big enough for most songs\n#if FFMPEG_LIBAVFORMAT_MAX_DUR2\n  avFormatCtx->max_analyze_duration2 *= 100;\n#else\n  avFormatCtx->max_analyze_duration *= 100;\n#endif\n\n  // retrieve stream information\n  if ( (err = avformat_find_stream_info(avFormatCtx, NULL)) < 0 ) {\n    char errorstr[256];\n    av_strerror (err, errorstr, sizeof(errorstr));\n    AUBIO_ERR(\"source_avcodec: Could not find stream information \" \"for %s (%s)\\n\", s->path,\n        errorstr);\n    goto beach;\n  }\n\n  // dump information about file onto standard error\n  //av_dump_format(avFormatCtx, 0, s->path, 0);\n\n  // look for the first audio stream\n  for (i = 0; i < avFormatCtx->nb_streams; i++) {\n#if FF_API_LAVF_AVCTX\n    if (avFormatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n#else\n    if (avFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n#endif\n      if (selected_stream == -1) {\n        selected_stream = i;\n      } else {\n        AUBIO_WRN(\"source_avcodec: More than one audio stream in %s, \"\n            \"taking the first one\\n\", s->path);\n      }\n    }\n  }\n  if (selected_stream == -1) {\n    AUBIO_ERR(\"source_avcodec: No audio stream in %s\\n\", s->path);\n    goto beach;\n  }\n  //AUBIO_DBG(\"Taking stream %d in file %s\\n\", selected_stream, s->path);\n  s->selected_stream = selected_stream;\n\n#if FF_API_LAVF_AVCTX\n  codecpar = avFormatCtx->streams[selected_stream]->codecpar;\n  if (codecpar == NULL) {\n    AUBIO_ERR(\"source_avcodec: Could not find decoder for %s\", s->path);\n    goto beach;\n  }\n  codec = avcodec_find_decoder(codecpar->codec_id);\n\n  /* Allocate a codec context for the decoder */\n  avCodecCtx = avcodec_alloc_context3(codec);\n  if (!avCodecCtx) {\n    AUBIO_ERR(\"source_avcodec: Failed to allocate the %s codec context for path %s\\n\",\n        av_get_media_type_string(AVMEDIA_TYPE_AUDIO), s->path);\n    goto beach;\n  }\n#else\n  avCodecCtx = avFormatCtx->streams[selected_stream]->codec;\n  codec = avcodec_find_decoder(avCodecCtx->codec_id);\n#endif\n  if (codec == NULL) {\n    AUBIO_ERR(\"source_avcodec: Could not find decoder for %s\", s->path);\n    goto beach;\n  }\n\n#if FF_API_LAVF_AVCTX\n  /* Copy codec parameters from input stream to output codec context */\n  if ((err = avcodec_parameters_to_context(avCodecCtx, codecpar)) < 0) {\n    AUBIO_ERR(\"source_avcodec: Failed to copy %s codec parameters to decoder context for %s\\n\",\n       av_get_media_type_string(AVMEDIA_TYPE_AUDIO), s->path);\n    goto beach;\n  }\n#endif\n\n  if ( ( err = avcodec_open2(avCodecCtx, codec, NULL) ) < 0) {\n    char errorstr[256];\n    av_strerror (err, errorstr, sizeof(errorstr));\n    AUBIO_ERR(\"source_avcodec: Could not load codec for %s (%s)\\n\", s->path, errorstr);\n    goto beach;\n  }\n\n  /* get input specs */\n  s->input_samplerate = avCodecCtx->sample_rate;\n  s->input_channels   = avCodecCtx->channels;\n  //AUBIO_DBG(\"input_samplerate: %d\\n\", s->input_samplerate);\n  //AUBIO_DBG(\"input_channels: %d\\n\", s->input_channels);\n\n  if (samplerate == 0) {\n    s->samplerate = s->input_samplerate;\n  } else {\n    s->samplerate = samplerate;\n  }\n\n  if (s->samplerate >  s->input_samplerate) {\n    AUBIO_WRN(\"source_avcodec: upsampling %s from %d to %d\\n\", s->path,\n        s->input_samplerate, s->samplerate);\n  }\n\n  avFrame = av_frame_alloc();\n  if (!avFrame) {\n    AUBIO_ERR(\"source_avcodec: Could not allocate frame for (%s)\\n\", s->path);\n  }\n\n  /* allocate output for avr */\n  s->output = (smpl_t *)av_malloc(AUBIO_AVCODEC_MAX_BUFFER_SIZE * sizeof(smpl_t));\n\n  s->read_samples = 0;\n  s->read_index = 0;\n\n  s->avFormatCtx = avFormatCtx;\n  s->avCodecCtx = avCodecCtx;\n  s->avFrame = avFrame;\n\n  // default to mono output\n  aubio_source_avcodec_reset_resampler(s, 0);\n\n  s->eof = 0;\n  s->multi = 0;\n\n  //av_log_set_level(AV_LOG_QUIET);\n\n  return s;\n\nbeach:\n  //AUBIO_ERR(\"can not read %s at samplerate %dHz with a hop_size of %d\\n\",\n  //    s->path, s->samplerate, s->hop_size);\n  del_aubio_source_avcodec(s);\n  return NULL;\n}",
        "func": "aubio_source_avcodec_t * new_aubio_source_avcodec(const char_t * path, uint_t samplerate, uint_t hop_size) {\n  aubio_source_avcodec_t * s = AUBIO_NEW(aubio_source_avcodec_t);\n  AVFormatContext *avFormatCtx = s->avFormatCtx;\n  AVCodecContext *avCodecCtx = s->avCodecCtx;\n  AVFrame *avFrame = s->avFrame;\n  sint_t selected_stream = -1;\n#if FF_API_LAVF_AVCTX\n  AVCodecParameters *codecpar;\n#endif\n  AVCodec *codec;\n  uint_t i;\n  int err;\n  if (path == NULL) {\n    AUBIO_ERR(\"source_avcodec: Aborted opening null path\\n\");\n    goto beach;\n  }\n  if ((sint_t)samplerate < 0) {\n    AUBIO_ERR(\"source_avcodec: Can not open %s with samplerate %d\\n\", path, samplerate);\n    goto beach;\n  }\n  if ((sint_t)hop_size <= 0) {\n    AUBIO_ERR(\"source_avcodec: Can not open %s with hop_size %d\\n\", path, hop_size);\n    goto beach;\n  }\n\n  s->hop_size = hop_size;\n  s->channels = 1;\n\n  if (s->path) AUBIO_FREE(s->path);\n  s->path = AUBIO_ARRAY(char_t, strnlen(path, PATH_MAX) + 1);\n  strncpy(s->path, path, strnlen(path, PATH_MAX) + 1);\n\n  // register all formats and codecs\n  av_register_all();\n\n  if (aubio_source_avcodec_has_network_url(s)) {\n    avformat_network_init();\n  }\n\n  // try opening the file and get some info about it\n  avFormatCtx = NULL;\n  if ( (err = avformat_open_input(&avFormatCtx, s->path, NULL, NULL) ) < 0 ) {\n    char errorstr[256];\n    av_strerror (err, errorstr, sizeof(errorstr));\n    AUBIO_ERR(\"source_avcodec: Failed opening %s (%s)\\n\", s->path, errorstr);\n    goto beach;\n  }\n\n  // try to make sure max_analyze_duration is big enough for most songs\n#if FFMPEG_LIBAVFORMAT_MAX_DUR2\n  avFormatCtx->max_analyze_duration2 *= 100;\n#else\n  avFormatCtx->max_analyze_duration *= 100;\n#endif\n\n  // retrieve stream information\n  if ( (err = avformat_find_stream_info(avFormatCtx, NULL)) < 0 ) {\n    char errorstr[256];\n    av_strerror (err, errorstr, sizeof(errorstr));\n    AUBIO_ERR(\"source_avcodec: Could not find stream information \" \"for %s (%s)\\n\", s->path,\n        errorstr);\n    goto beach;\n  }\n\n  // dump information about file onto standard error\n  //av_dump_format(avFormatCtx, 0, s->path, 0);\n\n  // look for the first audio stream\n  for (i = 0; i < avFormatCtx->nb_streams; i++) {\n#if FF_API_LAVF_AVCTX\n    if (avFormatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n#else\n    if (avFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n#endif\n      if (selected_stream == -1) {\n        selected_stream = i;\n      } else {\n        AUBIO_WRN(\"source_avcodec: More than one audio stream in %s, \"\n            \"taking the first one\\n\", s->path);\n      }\n    }\n  }\n  if (selected_stream == -1) {\n    AUBIO_ERR(\"source_avcodec: No audio stream in %s\\n\", s->path);\n    goto beach;\n  }\n  //AUBIO_DBG(\"Taking stream %d in file %s\\n\", selected_stream, s->path);\n  s->selected_stream = selected_stream;\n\n#if FF_API_LAVF_AVCTX\n  codecpar = avFormatCtx->streams[selected_stream]->codecpar;\n  if (codecpar == NULL) {\n    AUBIO_ERR(\"source_avcodec: Could not find decoder for %s\", s->path);\n    goto beach;\n  }\n  codec = avcodec_find_decoder(codecpar->codec_id);\n\n  /* Allocate a codec context for the decoder */\n  avCodecCtx = avcodec_alloc_context3(codec);\n  if (!avCodecCtx) {\n    AUBIO_ERR(\"source_avcodec: Failed to allocate the %s codec context for path %s\\n\",\n        av_get_media_type_string(AVMEDIA_TYPE_AUDIO), s->path);\n    goto beach;\n  }\n#else\n  avCodecCtx = avFormatCtx->streams[selected_stream]->codec;\n  codec = avcodec_find_decoder(avCodecCtx->codec_id);\n#endif\n  if (codec == NULL) {\n    AUBIO_ERR(\"source_avcodec: Could not find decoder for %s\", s->path);\n    goto beach;\n  }\n\n#if FF_API_LAVF_AVCTX\n  /* Copy codec parameters from input stream to output codec context */\n  if ((err = avcodec_parameters_to_context(avCodecCtx, codecpar)) < 0) {\n    AUBIO_ERR(\"source_avcodec: Failed to copy %s codec parameters to decoder context for %s\\n\",\n       av_get_media_type_string(AVMEDIA_TYPE_AUDIO), s->path);\n    goto beach;\n  }\n#endif\n\n  if ( ( err = avcodec_open2(avCodecCtx, codec, NULL) ) < 0) {\n    char errorstr[256];\n    av_strerror (err, errorstr, sizeof(errorstr));\n    AUBIO_ERR(\"source_avcodec: Could not load codec for %s (%s)\\n\", s->path, errorstr);\n    goto beach;\n  }\n\n  /* get input specs */\n  s->input_samplerate = avCodecCtx->sample_rate;\n  s->input_channels   = avCodecCtx->channels;\n  //AUBIO_DBG(\"input_samplerate: %d\\n\", s->input_samplerate);\n  //AUBIO_DBG(\"input_channels: %d\\n\", s->input_channels);\n\n  if (samplerate == 0) {\n    s->samplerate = s->input_samplerate;\n  } else {\n    s->samplerate = samplerate;\n  }\n\n  if (s->samplerate >  s->input_samplerate) {\n    AUBIO_WRN(\"source_avcodec: upsampling %s from %d to %d\\n\", s->path,\n        s->input_samplerate, s->samplerate);\n  }\n\n  avFrame = av_frame_alloc();\n  if (!avFrame) {\n    AUBIO_ERR(\"source_avcodec: Could not allocate frame for (%s)\\n\", s->path);\n  }\n\n  /* allocate output for avr */\n  s->output = (smpl_t *)av_malloc(AUBIO_AVCODEC_MAX_BUFFER_SIZE * sizeof(smpl_t));\n\n  s->read_samples = 0;\n  s->read_index = 0;\n\n  s->avFormatCtx = avFormatCtx;\n  s->avCodecCtx = avCodecCtx;\n  s->avFrame = avFrame;\n\n  // default to mono output\n  aubio_source_avcodec_reset_resampler(s, 0);\n\n  if (s->avr == NULL) goto beach;\n\n  s->eof = 0;\n  s->multi = 0;\n\n  //av_log_set_level(AV_LOG_QUIET);\n\n  return s;\n\nbeach:\n  //AUBIO_ERR(\"can not read %s at samplerate %dHz with a hop_size of %d\\n\",\n  //    s->path, s->samplerate, s->hop_size);\n  del_aubio_source_avcodec(s);\n  return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -162,6 +162,8 @@\n   // default to mono output\n   aubio_source_avcodec_reset_resampler(s, 0);\n \n+  if (s->avr == NULL) goto beach;\n+\n   s->eof = 0;\n   s->multi = 0;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (s->avr == NULL) goto beach;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-0512",
        "func_name": "vim/adjust_skipcol",
        "description": "Divide By Zero in GitHub repository vim/vim prior to 9.0.1247.",
        "git_url": "https://github.com/vim/vim/commit/870219c58c0804bdc55419b2e455c06ac715a835",
        "commit_title": "patch 9.0.1247: divide by zero with 'smoothscroll' set and a narrow window",
        "commit_text": " Problem:    Divide by zero with 'smoothscroll' set and a narrow window. Solution:   Bail out when the window is too narrow.",
        "func_before": "void\nadjust_skipcol(void)\n{\n    if (!curwin->w_p_wrap\n\t    || !curwin->w_p_sms\n\t    || curwin->w_cursor.lnum != curwin->w_topline)\n\treturn;\n\n    int\t    width1 = curwin->w_width - curwin_col_off();\n    int\t    width2 = width1 + curwin_col_off2();\n    long    so = get_scrolloff_value();\n    int\t    scrolloff_cols = so == 0 ? 0 : width1 + (so - 1) * width2;\n    int\t    scrolled = FALSE;\n\n    validate_cheight();\n    if (curwin->w_cline_height == curwin->w_height\n\t    // w_cline_height may be capped at w_height, check there aren't\n\t    // actually more lines.\n\t    && plines_win(curwin, curwin->w_cursor.lnum, FALSE)\n\t\t\t\t\t\t\t   <= curwin->w_height)\n    {\n\t// the line just fits in the window, don't scroll\n\treset_skipcol();\n\treturn;\n    }\n\n    validate_virtcol();\n    while (curwin->w_skipcol > 0\n\t\t && curwin->w_virtcol < curwin->w_skipcol + 3 + scrolloff_cols)\n    {\n\t// scroll a screen line down\n\tif (curwin->w_skipcol >= width1 + width2)\n\t    curwin->w_skipcol -= width2;\n\telse\n\t    curwin->w_skipcol -= width1;\n\tredraw_later(UPD_NOT_VALID);\n\tscrolled = TRUE;\n\tvalidate_virtcol();\n    }\n    if (scrolled)\n\treturn;  // don't scroll in the other direction now\n\n    int col = curwin->w_virtcol - curwin->w_skipcol + scrolloff_cols;\n    int row = 0;\n    if (col >= width1)\n    {\n\tcol -= width1;\n\t++row;\n    }\n    if (col > width2)\n    {\n\trow += col / width2;\n\tcol = col % width2;\n    }\n    if (row >= curwin->w_height)\n    {\n\tif (curwin->w_skipcol == 0)\n\t{\n\t    curwin->w_skipcol += width1;\n\t    --row;\n\t}\n\tif (row >= curwin->w_height)\n\t    curwin->w_skipcol += (row - curwin->w_height) * width2;\n\tredraw_later(UPD_NOT_VALID);\n    }\n}",
        "func": "void\nadjust_skipcol(void)\n{\n    if (!curwin->w_p_wrap\n\t    || !curwin->w_p_sms\n\t    || curwin->w_cursor.lnum != curwin->w_topline)\n\treturn;\n\n    int\t    width1 = curwin->w_width - curwin_col_off();\n    if (width1 <= 0)\n\treturn;  // no text will be displayed\n\n    int\t    width2 = width1 + curwin_col_off2();\n    long    so = get_scrolloff_value();\n    int\t    scrolloff_cols = so == 0 ? 0 : width1 + (so - 1) * width2;\n    int\t    scrolled = FALSE;\n\n    validate_cheight();\n    if (curwin->w_cline_height == curwin->w_height\n\t    // w_cline_height may be capped at w_height, check there aren't\n\t    // actually more lines.\n\t    && plines_win(curwin, curwin->w_cursor.lnum, FALSE)\n\t\t\t\t\t\t\t   <= curwin->w_height)\n    {\n\t// the line just fits in the window, don't scroll\n\treset_skipcol();\n\treturn;\n    }\n\n    validate_virtcol();\n    while (curwin->w_skipcol > 0\n\t\t && curwin->w_virtcol < curwin->w_skipcol + 3 + scrolloff_cols)\n    {\n\t// scroll a screen line down\n\tif (curwin->w_skipcol >= width1 + width2)\n\t    curwin->w_skipcol -= width2;\n\telse\n\t    curwin->w_skipcol -= width1;\n\tredraw_later(UPD_NOT_VALID);\n\tscrolled = TRUE;\n\tvalidate_virtcol();\n    }\n    if (scrolled)\n\treturn;  // don't scroll in the other direction now\n\n    int col = curwin->w_virtcol - curwin->w_skipcol + scrolloff_cols;\n    int row = 0;\n    if (col >= width1)\n    {\n\tcol -= width1;\n\t++row;\n    }\n    if (col > width2)\n    {\n\trow += col / width2;\n\tcol = col % width2;\n    }\n    if (row >= curwin->w_height)\n    {\n\tif (curwin->w_skipcol == 0)\n\t{\n\t    curwin->w_skipcol += width1;\n\t    --row;\n\t}\n\tif (row >= curwin->w_height)\n\t    curwin->w_skipcol += (row - curwin->w_height) * width2;\n\tredraw_later(UPD_NOT_VALID);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,9 @@\n \treturn;\n \n     int\t    width1 = curwin->w_width - curwin_col_off();\n+    if (width1 <= 0)\n+\treturn;  // no text will be displayed\n+\n     int\t    width2 = width1 + curwin_col_off2();\n     long    so = get_scrolloff_value();\n     int\t    scrolloff_cols = so == 0 ? 0 : width1 + (so - 1) * width2;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (width1 <= 0)",
                "\treturn;  // no text will be displayed",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-23108",
        "func_name": "colinbourassa/crasm/opdiv",
        "description": "In crasm 1.8-3, invalid input validation, specific files passed to the command line application, can lead to a NULL pointer dereference in the function Xasc.",
        "git_url": "https://github.com/colinbourassa/crasm/commit/c7a4d332b426a25478afd3118f3be5af37972edd",
        "commit_title": "Prevent division by zero.",
        "commit_text": " Under specific test cases, the application could crash with a floating point exception.",
        "func_before": "void opdiv(struct result* presult, struct result* parg)\n{\n  presult->flags |= parg->flags;\n  checktype(presult, L_ABSOLUTE);\n  checktype(parg, L_ABSOLUTE);\n  presult->value /= parg->value;\n}",
        "func": "void opdiv(struct result* presult, struct result* parg)\n{\n  presult->flags |= parg->flags;\n  checktype(presult, L_ABSOLUTE);\n  checktype(parg, L_ABSOLUTE);\n  if (parg->value != 0)\n  {\n    presult->value /= parg->value;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,8 @@\n   presult->flags |= parg->flags;\n   checktype(presult, L_ABSOLUTE);\n   checktype(parg, L_ABSOLUTE);\n-  presult->value /= parg->value;\n+  if (parg->value != 0)\n+  {\n+    presult->value /= parg->value;\n+  }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  presult->value /= parg->value;"
            ],
            "added_lines": [
                "  if (parg->value != 0)",
                "  {",
                "    presult->value /= parg->value;",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-23108",
        "func_name": "colinbourassa/crasm/Xasc",
        "description": "In crasm 1.8-3, invalid input validation, specific files passed to the command line application, can lead to a NULL pointer dereference in the function Xasc.",
        "git_url": "https://github.com/colinbourassa/crasm/commit/1be14c2d38cf74d481754ca595fcaa3e928a87a6",
        "commit_title": "Prevent NULL pointer dereference.",
        "commit_text": " Specific test cases could cause the `oper` character pointer to be NULL, leading to NULL pointer dereference.",
        "func_before": "int Xasc(int modifier, char* label, char* mnemo, char* oper)\n{\n  register char* s;\n  register char r;\n  register char delimiter;\n\n  s = oper;\n  delimiter = *s;\n\n  if (delimiter != '\\'' && delimiter != '\\\"')\n  {\n    error(\"Bad operand syntax\");\n  }\n\n  while ((r = *++s) != delimiter)\n  {\n    if (r == '\\\\')\n    {\n      switch (*++s)\n      {\n      case 't':\n        r = '\\t';\n        break;\n\n      case 'n':\n        r = '\\n';\n        break;\n\n      case 'r':\n        r = '\\r';\n        break;\n\n      case '0':\n        r = 0;\n        break;\n\n      case '\\'':\n      case '\\\"':\n      case '\\\\':\n        r = *s;\n        break;\n\n      default:\n        error(\"Bad \\\\X character\");\n      }\n    }\n\n    insert8(r);\n  }\n\n  if (*++s)\n  {\n    error(\"syntax error\");\n  }\n\n  return 0;\n}",
        "func": "int Xasc(int modifier, char* label, char* mnemo, char* oper)\n{\n\n  if (oper == NULL) {\n    error(\"Need an operand\");\n  }\n\n  register char* s;\n  register char r;\n  register char delimiter;\n\n  s = oper;\n  delimiter = *s;\n\n  if (delimiter != '\\'' && delimiter != '\\\"')\n  {\n    error(\"Bad operand syntax\");\n  }\n\n  while ((r = *++s) != delimiter)\n  {\n    if (r == '\\\\')\n    {\n      switch (*++s)\n      {\n      case 't':\n        r = '\\t';\n        break;\n\n      case 'n':\n        r = '\\n';\n        break;\n\n      case 'r':\n        r = '\\r';\n        break;\n\n      case '0':\n        r = 0;\n        break;\n\n      case '\\'':\n      case '\\\"':\n      case '\\\\':\n        r = *s;\n        break;\n\n      default:\n        error(\"Bad \\\\X character\");\n      }\n    }\n\n    insert8(r);\n  }\n\n  if (*++s)\n  {\n    error(\"syntax error\");\n  }\n\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,10 @@\n int Xasc(int modifier, char* label, char* mnemo, char* oper)\n {\n+\n+  if (oper == NULL) {\n+    error(\"Need an operand\");\n+  }\n+\n   register char* s;\n   register char r;\n   register char delimiter;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  if (oper == NULL) {",
                "    error(\"Need an operand\");",
                "  }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2022-0909",
        "func_name": "libtiff/_TIFFVSetField",
        "description": "Divide By Zero error in tiffcrop in libtiff 4.3.0 allows attackers to cause a denial-of-service via a crafted tiff file. For users that compile libtiff from sources, the fix is available with commit f8d0f9aa.",
        "git_url": "https://gitlab.com/libtiff/libtiff/-/commit/5c663c84f8a83ba790250a0ede847aa255825414",
        "commit_title": "fix FPE in tiffcrop",
        "commit_text": "",
        "func_before": "static int\n_TIFFVSetField(TIFF* tif, uint32_t tag, va_list ap)\n{\n\tstatic const char module[] = \"_TIFFVSetField\";\n\n\tTIFFDirectory* td = &tif->tif_dir;\n\tint status = 1;\n\tuint32_t v32, i, v;\n    double dblval;\n\tchar* s;\n\tconst TIFFField *fip = TIFFFindField(tif, tag, TIFF_ANY);\n\tuint32_t standard_tag = tag;\n\tif( fip == NULL ) /* cannot happen since OkToChangeTag() already checks it */\n\t    return 0;\n\t/*\n\t * We want to force the custom code to be used for custom\n\t * fields even if the tag happens to match a well known \n\t * one - important for reinterpreted handling of standard\n\t * tag values in custom directories (i.e. EXIF) \n\t */\n\tif (fip->field_bit == FIELD_CUSTOM) {\n\t\tstandard_tag = 0;\n\t}\n\n\tswitch (standard_tag) {\n\tcase TIFFTAG_SUBFILETYPE:\n\t\ttd->td_subfiletype = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_IMAGEWIDTH:\n\t\ttd->td_imagewidth = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_IMAGELENGTH:\n\t\ttd->td_imagelength = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_BITSPERSAMPLE:\n\t\ttd->td_bitspersample = (uint16_t) va_arg(ap, uint16_vap);\n\t\t/*\n\t\t * If the data require post-decoding processing to byte-swap\n\t\t * samples, set it up here.  Note that since tags are required\n\t\t * to be ordered, compression code can override this behavior\n\t\t * in the setup method if it wants to roll the post decoding\n\t\t * work in with its normal work.\n\t\t */\n\t\tif (tif->tif_flags & TIFF_SWAB) {\n\t\t\tif (td->td_bitspersample == 8)\n\t\t\t\ttif->tif_postdecode = _TIFFNoPostDecode;\n\t\t\telse if (td->td_bitspersample == 16)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab16BitData;\n\t\t\telse if (td->td_bitspersample == 24)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab24BitData;\n\t\t\telse if (td->td_bitspersample == 32)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab32BitData;\n\t\t\telse if (td->td_bitspersample == 64)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab64BitData;\n\t\t\telse if (td->td_bitspersample == 128) /* two 64's */\n\t\t\t\ttif->tif_postdecode = _TIFFSwab64BitData;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_COMPRESSION:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\t/*\n\t\t * If we're changing the compression scheme, notify the\n\t\t * previous module so that it can cleanup any state it's\n\t\t * setup.\n\t\t */\n\t\tif (TIFFFieldSet(tif, FIELD_COMPRESSION)) {\n\t\t\tif ((uint32_t)td->td_compression == v)\n\t\t\t\tbreak;\n\t\t\t(*tif->tif_cleanup)(tif);\n\t\t\ttif->tif_flags &= ~TIFF_CODERSETUP;\n\t\t}\n\t\t/*\n\t\t * Setup new compression routine state.\n\t\t */\n\t\tif( (status = TIFFSetCompressionScheme(tif, v)) != 0 )\n\t\t    td->td_compression = (uint16_t) v;\n\t\telse\n\t\t    status = 0;\n\t\tbreak;\n\tcase TIFFTAG_PHOTOMETRIC:\n\t\ttd->td_photometric = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_THRESHHOLDING:\n\t\ttd->td_threshholding = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_FILLORDER:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v != FILLORDER_LSB2MSB && v != FILLORDER_MSB2LSB)\n\t\t\tgoto badvalue;\n\t\ttd->td_fillorder = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_ORIENTATION:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v < ORIENTATION_TOPLEFT || ORIENTATION_LEFTBOT < v)\n\t\t\tgoto badvalue;\n\t\telse\n\t\t\ttd->td_orientation = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_SAMPLESPERPIXEL:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v == 0)\n\t\t\tgoto badvalue;\n        if( v != td->td_samplesperpixel )\n        {\n            /* See http://bugzilla.maptools.org/show_bug.cgi?id=2500 */\n            if( td->td_sminsamplevalue != NULL )\n            {\n                TIFFWarningExt(tif->tif_clientdata,module,\n                    \"SamplesPerPixel tag value is changing, \"\n                    \"but SMinSampleValue tag was read with a different value. Canceling it\");\n                TIFFClrFieldBit(tif,FIELD_SMINSAMPLEVALUE);\n                _TIFFfree(td->td_sminsamplevalue);\n                td->td_sminsamplevalue = NULL;\n            }\n            if( td->td_smaxsamplevalue != NULL )\n            {\n                TIFFWarningExt(tif->tif_clientdata,module,\n                    \"SamplesPerPixel tag value is changing, \"\n                    \"but SMaxSampleValue tag was read with a different value. Canceling it\");\n                TIFFClrFieldBit(tif,FIELD_SMAXSAMPLEVALUE);\n                _TIFFfree(td->td_smaxsamplevalue);\n                td->td_smaxsamplevalue = NULL;\n            }\n            /* Test if 3 transfer functions instead of just one are now needed\n               See http://bugzilla.maptools.org/show_bug.cgi?id=2820 */\n            if( td->td_transferfunction[0] != NULL && (v - td->td_extrasamples > 1) &&\n                !(td->td_samplesperpixel - td->td_extrasamples > 1))\n            {\n                    TIFFWarningExt(tif->tif_clientdata,module,\n                        \"SamplesPerPixel tag value is changing, \"\n                        \"but TransferFunction was read with a different value. Canceling it\");\n                    TIFFClrFieldBit(tif,FIELD_TRANSFERFUNCTION);\n                    _TIFFfree(td->td_transferfunction[0]);\n                    td->td_transferfunction[0] = NULL;\n            }\n        }\n\t\ttd->td_samplesperpixel = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_ROWSPERSTRIP:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 == 0)\n\t\t\tgoto badvalue32;\n\t\ttd->td_rowsperstrip = v32;\n\t\tif (!TIFFFieldSet(tif, FIELD_TILEDIMENSIONS)) {\n\t\t\ttd->td_tilelength = v32;\n\t\t\ttd->td_tilewidth = td->td_imagewidth;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_MINSAMPLEVALUE:\n\t\ttd->td_minsamplevalue = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_MAXSAMPLEVALUE:\n\t\ttd->td_maxsamplevalue = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_SMINSAMPLEVALUE:\n\t\tif (tif->tif_flags & TIFF_PERSAMPLE)\n\t\t\t_TIFFsetDoubleArray(&td->td_sminsamplevalue, va_arg(ap, double*), td->td_samplesperpixel);\n\t\telse\n\t\t\tsetDoubleArrayOneValue(&td->td_sminsamplevalue, va_arg(ap, double), td->td_samplesperpixel);\n\t\tbreak;\n\tcase TIFFTAG_SMAXSAMPLEVALUE:\n\t\tif (tif->tif_flags & TIFF_PERSAMPLE)\n\t\t\t_TIFFsetDoubleArray(&td->td_smaxsamplevalue, va_arg(ap, double*), td->td_samplesperpixel);\n\t\telse\n\t\t\tsetDoubleArrayOneValue(&td->td_smaxsamplevalue, va_arg(ap, double), td->td_samplesperpixel);\n\t\tbreak;\n\tcase TIFFTAG_XRESOLUTION:\n        dblval = va_arg(ap, double);\n        if( dblval < 0 )\n            goto badvaluedouble;\n\t\ttd->td_xresolution = _TIFFClampDoubleToFloat( dblval );\n\t\tbreak;\n\tcase TIFFTAG_YRESOLUTION:\n        dblval = va_arg(ap, double);\n        if( dblval < 0 )\n            goto badvaluedouble;\n\t\ttd->td_yresolution = _TIFFClampDoubleToFloat( dblval );\n\t\tbreak;\n\tcase TIFFTAG_PLANARCONFIG:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v != PLANARCONFIG_CONTIG && v != PLANARCONFIG_SEPARATE)\n\t\t\tgoto badvalue;\n\t\ttd->td_planarconfig = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_XPOSITION:\n\t\ttd->td_xposition = _TIFFClampDoubleToFloat( va_arg(ap, double) );\n\t\tbreak;\n\tcase TIFFTAG_YPOSITION:\n\t\ttd->td_yposition = _TIFFClampDoubleToFloat( va_arg(ap, double) );\n\t\tbreak;\n\tcase TIFFTAG_RESOLUTIONUNIT:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v < RESUNIT_NONE || RESUNIT_CENTIMETER < v)\n\t\t\tgoto badvalue;\n\t\ttd->td_resolutionunit = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_PAGENUMBER:\n\t\ttd->td_pagenumber[0] = (uint16_t) va_arg(ap, uint16_vap);\n\t\ttd->td_pagenumber[1] = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_HALFTONEHINTS:\n\t\ttd->td_halftonehints[0] = (uint16_t) va_arg(ap, uint16_vap);\n\t\ttd->td_halftonehints[1] = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_COLORMAP:\n\t\tv32 = (uint32_t)(1L << td->td_bitspersample);\n\t\t_TIFFsetShortArray(&td->td_colormap[0], va_arg(ap, uint16_t*), v32);\n\t\t_TIFFsetShortArray(&td->td_colormap[1], va_arg(ap, uint16_t*), v32);\n\t\t_TIFFsetShortArray(&td->td_colormap[2], va_arg(ap, uint16_t*), v32);\n\t\tbreak;\n\tcase TIFFTAG_EXTRASAMPLES:\n\t\tif (!setExtraSamples(tif, ap, &v))\n\t\t\tgoto badvalue;\n\t\tbreak;\n\tcase TIFFTAG_MATTEING:\n\t\ttd->td_extrasamples =  (((uint16_t) va_arg(ap, uint16_vap)) != 0);\n\t\tif (td->td_extrasamples) {\n\t\t\tuint16_t sv = EXTRASAMPLE_ASSOCALPHA;\n\t\t\t_TIFFsetShortArray(&td->td_sampleinfo, &sv, 1);\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_TILEWIDTH:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 % 16) {\n\t\t\tif (tif->tif_mode != O_RDONLY)\n\t\t\t\tgoto badvalue32;\n\t\t\tTIFFWarningExt(tif->tif_clientdata, tif->tif_name,\n\t\t\t\t\"Nonstandard tile width %\"PRIu32\", convert file\", v32);\n\t\t}\n\t\ttd->td_tilewidth = v32;\n\t\ttif->tif_flags |= TIFF_ISTILED;\n\t\tbreak;\n\tcase TIFFTAG_TILELENGTH:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 % 16) {\n\t\t\tif (tif->tif_mode != O_RDONLY)\n\t\t\t\tgoto badvalue32;\n\t\t\tTIFFWarningExt(tif->tif_clientdata, tif->tif_name,\n\t\t\t    \"Nonstandard tile length %\"PRIu32\", convert file\", v32);\n\t\t}\n\t\ttd->td_tilelength = v32;\n\t\ttif->tif_flags |= TIFF_ISTILED;\n\t\tbreak;\n\tcase TIFFTAG_TILEDEPTH:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 == 0)\n\t\t\tgoto badvalue32;\n\t\ttd->td_tiledepth = v32;\n\t\tbreak;\n\tcase TIFFTAG_DATATYPE:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tswitch (v) {\n\t\tcase DATATYPE_VOID:\tv = SAMPLEFORMAT_VOID;\tbreak;\n\t\tcase DATATYPE_INT:\tv = SAMPLEFORMAT_INT;\tbreak;\n\t\tcase DATATYPE_UINT:\tv = SAMPLEFORMAT_UINT;\tbreak;\n\t\tcase DATATYPE_IEEEFP:\tv = SAMPLEFORMAT_IEEEFP;break;\n\t\tdefault:\t\tgoto badvalue;\n\t\t}\n\t\ttd->td_sampleformat = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_SAMPLEFORMAT:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v < SAMPLEFORMAT_UINT || SAMPLEFORMAT_COMPLEXIEEEFP < v)\n\t\t\tgoto badvalue;\n\t\ttd->td_sampleformat = (uint16_t) v;\n\n\t\t/*  Try to fix up the SWAB function for complex data. */\n\t\tif( td->td_sampleformat == SAMPLEFORMAT_COMPLEXINT\n\t\t    && td->td_bitspersample == 32\n\t\t    && tif->tif_postdecode == _TIFFSwab32BitData )\n\t\t    tif->tif_postdecode = _TIFFSwab16BitData;\n\t\telse if( (td->td_sampleformat == SAMPLEFORMAT_COMPLEXINT\n\t\t\t  || td->td_sampleformat == SAMPLEFORMAT_COMPLEXIEEEFP)\n\t\t\t && td->td_bitspersample == 64\n\t\t\t && tif->tif_postdecode == _TIFFSwab64BitData )\n\t\t    tif->tif_postdecode = _TIFFSwab32BitData;\n\t\tbreak;\n\tcase TIFFTAG_IMAGEDEPTH:\n\t\ttd->td_imagedepth = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_SUBIFD:\n\t\tif ((tif->tif_flags & TIFF_INSUBIFD) == 0) {\n\t\t\ttd->td_nsubifd = (uint16_t) va_arg(ap, uint16_vap);\n\t\t\t_TIFFsetLong8Array(&td->td_subifd, (uint64_t*) va_arg(ap, uint64_t*),\n\t\t\t    (uint32_t) td->td_nsubifd);\n\t\t} else {\n\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t     \"%s: Sorry, cannot nest SubIFDs\",\n\t\t\t\t     tif->tif_name);\n\t\t\tstatus = 0;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_YCBCRPOSITIONING:\n\t\ttd->td_ycbcrpositioning = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_YCBCRSUBSAMPLING:\n\t\ttd->td_ycbcrsubsampling[0] = (uint16_t) va_arg(ap, uint16_vap);\n\t\ttd->td_ycbcrsubsampling[1] = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_TRANSFERFUNCTION:\n\t\tv = (td->td_samplesperpixel - td->td_extrasamples) > 1 ? 3 : 1;\n\t\tfor (i = 0; i < v; i++)\n\t\t\t_TIFFsetShortArray(&td->td_transferfunction[i],\n                               va_arg(ap, uint16_t*), 1U << td->td_bitspersample);\n\t\tbreak;\n\tcase TIFFTAG_REFERENCEBLACKWHITE:\n\t\t/* XXX should check for null range */\n\t\t_TIFFsetFloatArray(&td->td_refblackwhite, va_arg(ap, float*), 6);\n\t\tbreak;\n\tcase TIFFTAG_INKNAMES:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\ts = va_arg(ap, char*);\n\t\tv = checkInkNamesString(tif, v, s);\n\t\tstatus = v > 0;\n\t\tif( v > 0 ) {\n\t\t\t_TIFFsetNString(&td->td_inknames, s, v);\n\t\t\ttd->td_inknameslen = v;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_PERSAMPLE:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif( v == PERSAMPLE_MULTI )\n\t\t\ttif->tif_flags |= TIFF_PERSAMPLE;\n\t\telse\n\t\t\ttif->tif_flags &= ~TIFF_PERSAMPLE;\n\t\tbreak;\n\tdefault: {\n\t\tTIFFTagValue *tv;\n\t\tint tv_size, iCustom;\n\n\t\t/*\n\t\t * This can happen if multiple images are open with different\n\t\t * codecs which have private tags.  The global tag information\n\t\t * table may then have tags that are valid for one file but not\n\t\t * the other. If the client tries to set a tag that is not valid\n\t\t * for the image's codec then we'll arrive here.  This\n\t\t * happens, for example, when tiffcp is used to convert between\n\t\t * compression schemes and codec-specific tags are blindly copied.\n\t\t */\n\t\tif(fip->field_bit != FIELD_CUSTOM) {\n\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t    \"%s: Invalid %stag \\\"%s\\\" (not supported by codec)\",\n\t\t\t    tif->tif_name, isPseudoTag(tag) ? \"pseudo-\" : \"\",\n\t\t\t    fip->field_name);\n\t\t\tstatus = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Find the existing entry for this custom value.\n\t\t */\n\t\ttv = NULL;\n\t\tfor (iCustom = 0; iCustom < td->td_customValueCount; iCustom++) {\n\t\t\tif (td->td_customValues[iCustom].info->field_tag == tag) {\n\t\t\t\ttv = td->td_customValues + iCustom;\n\t\t\t\tif (tv->value != NULL) {\n\t\t\t\t\t_TIFFfree(tv->value);\n\t\t\t\t\ttv->value = NULL;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Grow the custom list if the entry was not found.\n\t\t */\n\t\tif(tv == NULL) {\n\t\t\tTIFFTagValue *new_customValues;\n\n\t\t\ttd->td_customValueCount++;\n\t\t\tnew_customValues = (TIFFTagValue *)\n\t\t\t    _TIFFrealloc(td->td_customValues,\n\t\t\t    sizeof(TIFFTagValue) * td->td_customValueCount);\n\t\t\tif (!new_customValues) {\n\t\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t    \"%s: Failed to allocate space for list of custom values\",\n\t\t\t\t    tif->tif_name);\n\t\t\t\tstatus = 0;\n\t\t\t\tgoto end;\n\t\t\t}\n\n\t\t\ttd->td_customValues = new_customValues;\n\n\t\t\ttv = td->td_customValues + (td->td_customValueCount - 1);\n\t\t\ttv->info = fip;\n\t\t\ttv->value = NULL;\n\t\t\ttv->count = 0;\n\t\t}\n\n\t\t/*\n\t\t * Set custom value ... save a copy of the custom tag value.\n\t\t */\n\t\ttv_size = _TIFFDataSize(fip->field_type);\n\t\t/*--: Rational2Double: For Rationals evaluate \"set_field_type\" to determine internal storage size. */\n\t\tif (fip->field_type == TIFF_RATIONAL || fip->field_type == TIFF_SRATIONAL) {\n\t\t\ttv_size = _TIFFSetGetFieldSize(fip->set_field_type);\n\t\t}\n\t\tif (tv_size == 0) {\n\t\t\tstatus = 0;\n\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t    \"%s: Bad field type %d for \\\"%s\\\"\",\n\t\t\t    tif->tif_name, fip->field_type,\n\t\t\t    fip->field_name);\n\t\t\tgoto end;\n\t\t}\n\n\t\tif (fip->field_type == TIFF_ASCII)\n\t\t{\n\t\t\tuint32_t ma;\n\t\t\tconst char* mb;\n\t\t\tif (fip->field_passcount)\n\t\t\t{\n\t\t\t\tassert(fip->field_writecount==TIFF_VARIABLE2);\n\t\t\t\tma=(uint32_t)va_arg(ap, uint32_t);\n\t\t\t\tmb=(const char*)va_arg(ap,const char*);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tmb=(const char*)va_arg(ap,const char*);\n\t\t\t\tsize_t len = strlen(mb) + 1;\n\t\t\t\tif( len >= 0x80000000U )\n\t\t\t\t{\n\t\t\t\t\tstatus = 0;\n\t\t\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t\t    \"%s: Too long string value for \\\"%s\\\". \"\n\t\t\t\t\t    \"Maximum supported is 2147483647 bytes\",\n\t\t\t\t\t    tif->tif_name,\n\t\t\t\t\t    fip->field_name);\n\t\t\t\t\tgoto end;\n\t\t\t\t}\n\t\t\t\tma=(uint32_t)len;\n\t\t\t}\n\t\t\ttv->count=ma;\n\t\t\tsetByteArray(&tv->value,mb,ma,1);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (fip->field_passcount) {\n\t\t\t\tif (fip->field_writecount == TIFF_VARIABLE2)\n\t\t\t\t\ttv->count = (uint32_t) va_arg(ap, uint32_t);\n\t\t\t\telse\n\t\t\t\t\ttv->count = (int) va_arg(ap, int);\n\t\t\t} else if (fip->field_writecount == TIFF_VARIABLE\n\t\t\t   || fip->field_writecount == TIFF_VARIABLE2)\n\t\t\t\ttv->count = 1;\n\t\t\telse if (fip->field_writecount == TIFF_SPP)\n\t\t\t\ttv->count = td->td_samplesperpixel;\n\t\t\telse\n\t\t\t\ttv->count = fip->field_writecount;\n\n\t\t\tif (tv->count == 0) {\n\t\t\t\tstatus = 0;\n\t\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t\t     \"%s: Null count for \\\"%s\\\" (type \"\n\t\t\t\t\t     \"%d, writecount %d, passcount %d)\",\n\t\t\t\t\t     tif->tif_name,\n\t\t\t\t\t     fip->field_name,\n\t\t\t\t\t     fip->field_type,\n\t\t\t\t\t     fip->field_writecount,\n\t\t\t\t\t     fip->field_passcount);\n\t\t\t\tgoto end;\n\t\t\t}\n\n\t\t\ttv->value = _TIFFCheckMalloc(tif, tv->count, tv_size,\n\t\t\t    \"custom tag binary object\");\n\t\t\tif (!tv->value) {\n\t\t\t\tstatus = 0;\n\t\t\t\tgoto end;\n\t\t\t}\n\n\t\t\tif (fip->field_tag == TIFFTAG_DOTRANGE \n\t\t\t    && strcmp(fip->field_name,\"DotRange\") == 0) {\n\t\t\t\t/* TODO: This is an evil exception and should not have been\n\t\t\t\t   handled this way ... likely best if we move it into\n\t\t\t\t   the directory structure with an explicit field in \n\t\t\t\t   libtiff 4.1 and assign it a FIELD_ value */\n\t\t\t\tuint16_t v2[2];\n\t\t\t\tv2[0] = (uint16_t)va_arg(ap, int);\n\t\t\t\tv2[1] = (uint16_t)va_arg(ap, int);\n\t\t\t\t_TIFFmemcpy(tv->value, &v2, 4);\n\t\t\t}\n\n\t\t\telse if (fip->field_passcount\n\t\t\t\t  || fip->field_writecount == TIFF_VARIABLE\n\t\t\t\t  || fip->field_writecount == TIFF_VARIABLE2\n\t\t\t\t  || fip->field_writecount == TIFF_SPP\n\t\t\t\t  || tv->count > 1) {\n\t\t\t  /*--: Rational2Double: For Rationals tv_size is set above to 4 or 8 according to fip->set_field_type! */\n\t\t\t\t_TIFFmemcpy(tv->value, va_arg(ap, void *),\n\t\t\t\t    tv->count * tv_size);\n\t\t\t} else {\n\t\t\t\tchar *val = (char *)tv->value;\n\t\t\t\tassert( tv->count == 1 );\n\n\t\t\t\tswitch (fip->field_type) {\n\t\t\t\tcase TIFF_BYTE:\n\t\t\t\tcase TIFF_UNDEFINED:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint8_t v2 = (uint8_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SBYTE:\n\t\t\t\t\t{\n\t\t\t\t\t\tint8_t v2 = (int8_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SHORT:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint16_t v2 = (uint16_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SSHORT:\n\t\t\t\t\t{\n\t\t\t\t\t\tint16_t v2 = (int16_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_LONG:\n\t\t\t\tcase TIFF_IFD:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint32_t v2 = va_arg(ap, uint32_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SLONG:\n\t\t\t\t\t{\n\t\t\t\t\t\tint32_t v2 = va_arg(ap, int32_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_LONG8:\n\t\t\t\tcase TIFF_IFD8:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint64_t v2 = va_arg(ap, uint64_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SLONG8:\n\t\t\t\t\t{\n\t\t\t\t\t\tint64_t v2 = va_arg(ap, int64_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_RATIONAL:\n\t\t\t\tcase TIFF_SRATIONAL:\n\t\t\t\t\t/*-- Rational2Double: For Rationals tv_size is set above to 4 or 8 according to fip->set_field_type! */\n\t\t\t\t\t{\n\t\t\t\t\t\tif (tv_size == 8) {\n\t\t\t\t\t\t\tdouble v2 = va_arg(ap, double);\n\t\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t/*-- default should be tv_size == 4 */\n\t\t\t\t\t\t\tfloat v3 = (float)va_arg(ap, double);\n\t\t\t\t\t\t\t_TIFFmemcpy(val, &v3, tv_size);\n\t\t\t\t\t\t\t/*-- ToDo: After Testing, this should be removed and tv_size==4 should be set as default. */\n\t\t\t\t\t\t\tif (tv_size != 4) {\n\t\t\t\t\t\t\t\tTIFFErrorExt(0,\"TIFFLib: _TIFFVSetField()\", \"Rational2Double: .set_field_type in not 4 but %d\", tv_size); \n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_FLOAT:\n\t\t\t\t\t{\n\t\t\t\t\t\tfloat v2 = _TIFFClampDoubleToFloat(va_arg(ap, double));\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_DOUBLE:\n\t\t\t\t\t{\n\t\t\t\t\t\tdouble v2 = va_arg(ap, double);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t_TIFFmemset(val, 0, tv_size);\n\t\t\t\t\tstatus = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t}\n\tif (status) {\n\t\tconst TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n\t\tif (fip2)                \n\t\t\tTIFFSetFieldBit(tif, fip2->field_bit);\n\t\ttif->tif_flags |= TIFF_DIRTYDIRECT;\n\t}\n\nend:\n\tva_end(ap);\n\treturn (status);\nbadvalue:\n        {\n\t\tconst TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t     \"%s: Bad value %\"PRIu32\" for \\\"%s\\\" tag\",\n\t\t     tif->tif_name, v,\n\t\t     fip2 ? fip2->field_name : \"Unknown\");\n\t\tva_end(ap);\n        }\n\treturn (0);\nbadvalue32:\n        {\n\t\tconst TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t     \"%s: Bad value %\"PRIu32\" for \\\"%s\\\" tag\",\n\t\t     tif->tif_name, v32,\n\t\t     fip2 ? fip2->field_name : \"Unknown\");\n\t\tva_end(ap);\n        }\n\treturn (0);\nbadvaluedouble:\n        {\n        const TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n        TIFFErrorExt(tif->tif_clientdata, module,\n             \"%s: Bad value %f for \\\"%s\\\" tag\",\n             tif->tif_name, dblval,\n             fip2 ? fip2->field_name : \"Unknown\");\n        va_end(ap);\n        }\n    return (0);\n}",
        "func": "static int\n_TIFFVSetField(TIFF* tif, uint32_t tag, va_list ap)\n{\n\tstatic const char module[] = \"_TIFFVSetField\";\n\n\tTIFFDirectory* td = &tif->tif_dir;\n\tint status = 1;\n\tuint32_t v32, i, v;\n    double dblval;\n\tchar* s;\n\tconst TIFFField *fip = TIFFFindField(tif, tag, TIFF_ANY);\n\tuint32_t standard_tag = tag;\n\tif( fip == NULL ) /* cannot happen since OkToChangeTag() already checks it */\n\t    return 0;\n\t/*\n\t * We want to force the custom code to be used for custom\n\t * fields even if the tag happens to match a well known \n\t * one - important for reinterpreted handling of standard\n\t * tag values in custom directories (i.e. EXIF) \n\t */\n\tif (fip->field_bit == FIELD_CUSTOM) {\n\t\tstandard_tag = 0;\n\t}\n\n\tswitch (standard_tag) {\n\tcase TIFFTAG_SUBFILETYPE:\n\t\ttd->td_subfiletype = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_IMAGEWIDTH:\n\t\ttd->td_imagewidth = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_IMAGELENGTH:\n\t\ttd->td_imagelength = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_BITSPERSAMPLE:\n\t\ttd->td_bitspersample = (uint16_t) va_arg(ap, uint16_vap);\n\t\t/*\n\t\t * If the data require post-decoding processing to byte-swap\n\t\t * samples, set it up here.  Note that since tags are required\n\t\t * to be ordered, compression code can override this behavior\n\t\t * in the setup method if it wants to roll the post decoding\n\t\t * work in with its normal work.\n\t\t */\n\t\tif (tif->tif_flags & TIFF_SWAB) {\n\t\t\tif (td->td_bitspersample == 8)\n\t\t\t\ttif->tif_postdecode = _TIFFNoPostDecode;\n\t\t\telse if (td->td_bitspersample == 16)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab16BitData;\n\t\t\telse if (td->td_bitspersample == 24)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab24BitData;\n\t\t\telse if (td->td_bitspersample == 32)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab32BitData;\n\t\t\telse if (td->td_bitspersample == 64)\n\t\t\t\ttif->tif_postdecode = _TIFFSwab64BitData;\n\t\t\telse if (td->td_bitspersample == 128) /* two 64's */\n\t\t\t\ttif->tif_postdecode = _TIFFSwab64BitData;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_COMPRESSION:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\t/*\n\t\t * If we're changing the compression scheme, notify the\n\t\t * previous module so that it can cleanup any state it's\n\t\t * setup.\n\t\t */\n\t\tif (TIFFFieldSet(tif, FIELD_COMPRESSION)) {\n\t\t\tif ((uint32_t)td->td_compression == v)\n\t\t\t\tbreak;\n\t\t\t(*tif->tif_cleanup)(tif);\n\t\t\ttif->tif_flags &= ~TIFF_CODERSETUP;\n\t\t}\n\t\t/*\n\t\t * Setup new compression routine state.\n\t\t */\n\t\tif( (status = TIFFSetCompressionScheme(tif, v)) != 0 )\n\t\t    td->td_compression = (uint16_t) v;\n\t\telse\n\t\t    status = 0;\n\t\tbreak;\n\tcase TIFFTAG_PHOTOMETRIC:\n\t\ttd->td_photometric = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_THRESHHOLDING:\n\t\ttd->td_threshholding = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_FILLORDER:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v != FILLORDER_LSB2MSB && v != FILLORDER_MSB2LSB)\n\t\t\tgoto badvalue;\n\t\ttd->td_fillorder = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_ORIENTATION:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v < ORIENTATION_TOPLEFT || ORIENTATION_LEFTBOT < v)\n\t\t\tgoto badvalue;\n\t\telse\n\t\t\ttd->td_orientation = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_SAMPLESPERPIXEL:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v == 0)\n\t\t\tgoto badvalue;\n        if( v != td->td_samplesperpixel )\n        {\n            /* See http://bugzilla.maptools.org/show_bug.cgi?id=2500 */\n            if( td->td_sminsamplevalue != NULL )\n            {\n                TIFFWarningExt(tif->tif_clientdata,module,\n                    \"SamplesPerPixel tag value is changing, \"\n                    \"but SMinSampleValue tag was read with a different value. Canceling it\");\n                TIFFClrFieldBit(tif,FIELD_SMINSAMPLEVALUE);\n                _TIFFfree(td->td_sminsamplevalue);\n                td->td_sminsamplevalue = NULL;\n            }\n            if( td->td_smaxsamplevalue != NULL )\n            {\n                TIFFWarningExt(tif->tif_clientdata,module,\n                    \"SamplesPerPixel tag value is changing, \"\n                    \"but SMaxSampleValue tag was read with a different value. Canceling it\");\n                TIFFClrFieldBit(tif,FIELD_SMAXSAMPLEVALUE);\n                _TIFFfree(td->td_smaxsamplevalue);\n                td->td_smaxsamplevalue = NULL;\n            }\n            /* Test if 3 transfer functions instead of just one are now needed\n               See http://bugzilla.maptools.org/show_bug.cgi?id=2820 */\n            if( td->td_transferfunction[0] != NULL && (v - td->td_extrasamples > 1) &&\n                !(td->td_samplesperpixel - td->td_extrasamples > 1))\n            {\n                    TIFFWarningExt(tif->tif_clientdata,module,\n                        \"SamplesPerPixel tag value is changing, \"\n                        \"but TransferFunction was read with a different value. Canceling it\");\n                    TIFFClrFieldBit(tif,FIELD_TRANSFERFUNCTION);\n                    _TIFFfree(td->td_transferfunction[0]);\n                    td->td_transferfunction[0] = NULL;\n            }\n        }\n\t\ttd->td_samplesperpixel = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_ROWSPERSTRIP:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 == 0)\n\t\t\tgoto badvalue32;\n\t\ttd->td_rowsperstrip = v32;\n\t\tif (!TIFFFieldSet(tif, FIELD_TILEDIMENSIONS)) {\n\t\t\ttd->td_tilelength = v32;\n\t\t\ttd->td_tilewidth = td->td_imagewidth;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_MINSAMPLEVALUE:\n\t\ttd->td_minsamplevalue = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_MAXSAMPLEVALUE:\n\t\ttd->td_maxsamplevalue = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_SMINSAMPLEVALUE:\n\t\tif (tif->tif_flags & TIFF_PERSAMPLE)\n\t\t\t_TIFFsetDoubleArray(&td->td_sminsamplevalue, va_arg(ap, double*), td->td_samplesperpixel);\n\t\telse\n\t\t\tsetDoubleArrayOneValue(&td->td_sminsamplevalue, va_arg(ap, double), td->td_samplesperpixel);\n\t\tbreak;\n\tcase TIFFTAG_SMAXSAMPLEVALUE:\n\t\tif (tif->tif_flags & TIFF_PERSAMPLE)\n\t\t\t_TIFFsetDoubleArray(&td->td_smaxsamplevalue, va_arg(ap, double*), td->td_samplesperpixel);\n\t\telse\n\t\t\tsetDoubleArrayOneValue(&td->td_smaxsamplevalue, va_arg(ap, double), td->td_samplesperpixel);\n\t\tbreak;\n\tcase TIFFTAG_XRESOLUTION:\n        dblval = va_arg(ap, double);\n        if( dblval != dblval || dblval < 0 )\n            goto badvaluedouble;\n\t\ttd->td_xresolution = _TIFFClampDoubleToFloat( dblval );\n\t\tbreak;\n\tcase TIFFTAG_YRESOLUTION:\n        dblval = va_arg(ap, double);\n        if( dblval != dblval || dblval < 0 )\n            goto badvaluedouble;\n\t\ttd->td_yresolution = _TIFFClampDoubleToFloat( dblval );\n\t\tbreak;\n\tcase TIFFTAG_PLANARCONFIG:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v != PLANARCONFIG_CONTIG && v != PLANARCONFIG_SEPARATE)\n\t\t\tgoto badvalue;\n\t\ttd->td_planarconfig = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_XPOSITION:\n\t\ttd->td_xposition = _TIFFClampDoubleToFloat( va_arg(ap, double) );\n\t\tbreak;\n\tcase TIFFTAG_YPOSITION:\n\t\ttd->td_yposition = _TIFFClampDoubleToFloat( va_arg(ap, double) );\n\t\tbreak;\n\tcase TIFFTAG_RESOLUTIONUNIT:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v < RESUNIT_NONE || RESUNIT_CENTIMETER < v)\n\t\t\tgoto badvalue;\n\t\ttd->td_resolutionunit = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_PAGENUMBER:\n\t\ttd->td_pagenumber[0] = (uint16_t) va_arg(ap, uint16_vap);\n\t\ttd->td_pagenumber[1] = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_HALFTONEHINTS:\n\t\ttd->td_halftonehints[0] = (uint16_t) va_arg(ap, uint16_vap);\n\t\ttd->td_halftonehints[1] = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_COLORMAP:\n\t\tv32 = (uint32_t)(1L << td->td_bitspersample);\n\t\t_TIFFsetShortArray(&td->td_colormap[0], va_arg(ap, uint16_t*), v32);\n\t\t_TIFFsetShortArray(&td->td_colormap[1], va_arg(ap, uint16_t*), v32);\n\t\t_TIFFsetShortArray(&td->td_colormap[2], va_arg(ap, uint16_t*), v32);\n\t\tbreak;\n\tcase TIFFTAG_EXTRASAMPLES:\n\t\tif (!setExtraSamples(tif, ap, &v))\n\t\t\tgoto badvalue;\n\t\tbreak;\n\tcase TIFFTAG_MATTEING:\n\t\ttd->td_extrasamples =  (((uint16_t) va_arg(ap, uint16_vap)) != 0);\n\t\tif (td->td_extrasamples) {\n\t\t\tuint16_t sv = EXTRASAMPLE_ASSOCALPHA;\n\t\t\t_TIFFsetShortArray(&td->td_sampleinfo, &sv, 1);\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_TILEWIDTH:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 % 16) {\n\t\t\tif (tif->tif_mode != O_RDONLY)\n\t\t\t\tgoto badvalue32;\n\t\t\tTIFFWarningExt(tif->tif_clientdata, tif->tif_name,\n\t\t\t\t\"Nonstandard tile width %\"PRIu32\", convert file\", v32);\n\t\t}\n\t\ttd->td_tilewidth = v32;\n\t\ttif->tif_flags |= TIFF_ISTILED;\n\t\tbreak;\n\tcase TIFFTAG_TILELENGTH:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 % 16) {\n\t\t\tif (tif->tif_mode != O_RDONLY)\n\t\t\t\tgoto badvalue32;\n\t\t\tTIFFWarningExt(tif->tif_clientdata, tif->tif_name,\n\t\t\t    \"Nonstandard tile length %\"PRIu32\", convert file\", v32);\n\t\t}\n\t\ttd->td_tilelength = v32;\n\t\ttif->tif_flags |= TIFF_ISTILED;\n\t\tbreak;\n\tcase TIFFTAG_TILEDEPTH:\n\t\tv32 = (uint32_t) va_arg(ap, uint32_t);\n\t\tif (v32 == 0)\n\t\t\tgoto badvalue32;\n\t\ttd->td_tiledepth = v32;\n\t\tbreak;\n\tcase TIFFTAG_DATATYPE:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tswitch (v) {\n\t\tcase DATATYPE_VOID:\tv = SAMPLEFORMAT_VOID;\tbreak;\n\t\tcase DATATYPE_INT:\tv = SAMPLEFORMAT_INT;\tbreak;\n\t\tcase DATATYPE_UINT:\tv = SAMPLEFORMAT_UINT;\tbreak;\n\t\tcase DATATYPE_IEEEFP:\tv = SAMPLEFORMAT_IEEEFP;break;\n\t\tdefault:\t\tgoto badvalue;\n\t\t}\n\t\ttd->td_sampleformat = (uint16_t) v;\n\t\tbreak;\n\tcase TIFFTAG_SAMPLEFORMAT:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif (v < SAMPLEFORMAT_UINT || SAMPLEFORMAT_COMPLEXIEEEFP < v)\n\t\t\tgoto badvalue;\n\t\ttd->td_sampleformat = (uint16_t) v;\n\n\t\t/*  Try to fix up the SWAB function for complex data. */\n\t\tif( td->td_sampleformat == SAMPLEFORMAT_COMPLEXINT\n\t\t    && td->td_bitspersample == 32\n\t\t    && tif->tif_postdecode == _TIFFSwab32BitData )\n\t\t    tif->tif_postdecode = _TIFFSwab16BitData;\n\t\telse if( (td->td_sampleformat == SAMPLEFORMAT_COMPLEXINT\n\t\t\t  || td->td_sampleformat == SAMPLEFORMAT_COMPLEXIEEEFP)\n\t\t\t && td->td_bitspersample == 64\n\t\t\t && tif->tif_postdecode == _TIFFSwab64BitData )\n\t\t    tif->tif_postdecode = _TIFFSwab32BitData;\n\t\tbreak;\n\tcase TIFFTAG_IMAGEDEPTH:\n\t\ttd->td_imagedepth = (uint32_t) va_arg(ap, uint32_t);\n\t\tbreak;\n\tcase TIFFTAG_SUBIFD:\n\t\tif ((tif->tif_flags & TIFF_INSUBIFD) == 0) {\n\t\t\ttd->td_nsubifd = (uint16_t) va_arg(ap, uint16_vap);\n\t\t\t_TIFFsetLong8Array(&td->td_subifd, (uint64_t*) va_arg(ap, uint64_t*),\n\t\t\t    (uint32_t) td->td_nsubifd);\n\t\t} else {\n\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t     \"%s: Sorry, cannot nest SubIFDs\",\n\t\t\t\t     tif->tif_name);\n\t\t\tstatus = 0;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_YCBCRPOSITIONING:\n\t\ttd->td_ycbcrpositioning = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_YCBCRSUBSAMPLING:\n\t\ttd->td_ycbcrsubsampling[0] = (uint16_t) va_arg(ap, uint16_vap);\n\t\ttd->td_ycbcrsubsampling[1] = (uint16_t) va_arg(ap, uint16_vap);\n\t\tbreak;\n\tcase TIFFTAG_TRANSFERFUNCTION:\n\t\tv = (td->td_samplesperpixel - td->td_extrasamples) > 1 ? 3 : 1;\n\t\tfor (i = 0; i < v; i++)\n\t\t\t_TIFFsetShortArray(&td->td_transferfunction[i],\n                               va_arg(ap, uint16_t*), 1U << td->td_bitspersample);\n\t\tbreak;\n\tcase TIFFTAG_REFERENCEBLACKWHITE:\n\t\t/* XXX should check for null range */\n\t\t_TIFFsetFloatArray(&td->td_refblackwhite, va_arg(ap, float*), 6);\n\t\tbreak;\n\tcase TIFFTAG_INKNAMES:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\ts = va_arg(ap, char*);\n\t\tv = checkInkNamesString(tif, v, s);\n\t\tstatus = v > 0;\n\t\tif( v > 0 ) {\n\t\t\t_TIFFsetNString(&td->td_inknames, s, v);\n\t\t\ttd->td_inknameslen = v;\n\t\t}\n\t\tbreak;\n\tcase TIFFTAG_PERSAMPLE:\n\t\tv = (uint16_t) va_arg(ap, uint16_vap);\n\t\tif( v == PERSAMPLE_MULTI )\n\t\t\ttif->tif_flags |= TIFF_PERSAMPLE;\n\t\telse\n\t\t\ttif->tif_flags &= ~TIFF_PERSAMPLE;\n\t\tbreak;\n\tdefault: {\n\t\tTIFFTagValue *tv;\n\t\tint tv_size, iCustom;\n\n\t\t/*\n\t\t * This can happen if multiple images are open with different\n\t\t * codecs which have private tags.  The global tag information\n\t\t * table may then have tags that are valid for one file but not\n\t\t * the other. If the client tries to set a tag that is not valid\n\t\t * for the image's codec then we'll arrive here.  This\n\t\t * happens, for example, when tiffcp is used to convert between\n\t\t * compression schemes and codec-specific tags are blindly copied.\n\t\t */\n\t\tif(fip->field_bit != FIELD_CUSTOM) {\n\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t    \"%s: Invalid %stag \\\"%s\\\" (not supported by codec)\",\n\t\t\t    tif->tif_name, isPseudoTag(tag) ? \"pseudo-\" : \"\",\n\t\t\t    fip->field_name);\n\t\t\tstatus = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Find the existing entry for this custom value.\n\t\t */\n\t\ttv = NULL;\n\t\tfor (iCustom = 0; iCustom < td->td_customValueCount; iCustom++) {\n\t\t\tif (td->td_customValues[iCustom].info->field_tag == tag) {\n\t\t\t\ttv = td->td_customValues + iCustom;\n\t\t\t\tif (tv->value != NULL) {\n\t\t\t\t\t_TIFFfree(tv->value);\n\t\t\t\t\ttv->value = NULL;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Grow the custom list if the entry was not found.\n\t\t */\n\t\tif(tv == NULL) {\n\t\t\tTIFFTagValue *new_customValues;\n\n\t\t\ttd->td_customValueCount++;\n\t\t\tnew_customValues = (TIFFTagValue *)\n\t\t\t    _TIFFrealloc(td->td_customValues,\n\t\t\t    sizeof(TIFFTagValue) * td->td_customValueCount);\n\t\t\tif (!new_customValues) {\n\t\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t    \"%s: Failed to allocate space for list of custom values\",\n\t\t\t\t    tif->tif_name);\n\t\t\t\tstatus = 0;\n\t\t\t\tgoto end;\n\t\t\t}\n\n\t\t\ttd->td_customValues = new_customValues;\n\n\t\t\ttv = td->td_customValues + (td->td_customValueCount - 1);\n\t\t\ttv->info = fip;\n\t\t\ttv->value = NULL;\n\t\t\ttv->count = 0;\n\t\t}\n\n\t\t/*\n\t\t * Set custom value ... save a copy of the custom tag value.\n\t\t */\n\t\ttv_size = _TIFFDataSize(fip->field_type);\n\t\t/*--: Rational2Double: For Rationals evaluate \"set_field_type\" to determine internal storage size. */\n\t\tif (fip->field_type == TIFF_RATIONAL || fip->field_type == TIFF_SRATIONAL) {\n\t\t\ttv_size = _TIFFSetGetFieldSize(fip->set_field_type);\n\t\t}\n\t\tif (tv_size == 0) {\n\t\t\tstatus = 0;\n\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t    \"%s: Bad field type %d for \\\"%s\\\"\",\n\t\t\t    tif->tif_name, fip->field_type,\n\t\t\t    fip->field_name);\n\t\t\tgoto end;\n\t\t}\n\n\t\tif (fip->field_type == TIFF_ASCII)\n\t\t{\n\t\t\tuint32_t ma;\n\t\t\tconst char* mb;\n\t\t\tif (fip->field_passcount)\n\t\t\t{\n\t\t\t\tassert(fip->field_writecount==TIFF_VARIABLE2);\n\t\t\t\tma=(uint32_t)va_arg(ap, uint32_t);\n\t\t\t\tmb=(const char*)va_arg(ap,const char*);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tmb=(const char*)va_arg(ap,const char*);\n\t\t\t\tsize_t len = strlen(mb) + 1;\n\t\t\t\tif( len >= 0x80000000U )\n\t\t\t\t{\n\t\t\t\t\tstatus = 0;\n\t\t\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t\t    \"%s: Too long string value for \\\"%s\\\". \"\n\t\t\t\t\t    \"Maximum supported is 2147483647 bytes\",\n\t\t\t\t\t    tif->tif_name,\n\t\t\t\t\t    fip->field_name);\n\t\t\t\t\tgoto end;\n\t\t\t\t}\n\t\t\t\tma=(uint32_t)len;\n\t\t\t}\n\t\t\ttv->count=ma;\n\t\t\tsetByteArray(&tv->value,mb,ma,1);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (fip->field_passcount) {\n\t\t\t\tif (fip->field_writecount == TIFF_VARIABLE2)\n\t\t\t\t\ttv->count = (uint32_t) va_arg(ap, uint32_t);\n\t\t\t\telse\n\t\t\t\t\ttv->count = (int) va_arg(ap, int);\n\t\t\t} else if (fip->field_writecount == TIFF_VARIABLE\n\t\t\t   || fip->field_writecount == TIFF_VARIABLE2)\n\t\t\t\ttv->count = 1;\n\t\t\telse if (fip->field_writecount == TIFF_SPP)\n\t\t\t\ttv->count = td->td_samplesperpixel;\n\t\t\telse\n\t\t\t\ttv->count = fip->field_writecount;\n\n\t\t\tif (tv->count == 0) {\n\t\t\t\tstatus = 0;\n\t\t\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t\t\t\t     \"%s: Null count for \\\"%s\\\" (type \"\n\t\t\t\t\t     \"%d, writecount %d, passcount %d)\",\n\t\t\t\t\t     tif->tif_name,\n\t\t\t\t\t     fip->field_name,\n\t\t\t\t\t     fip->field_type,\n\t\t\t\t\t     fip->field_writecount,\n\t\t\t\t\t     fip->field_passcount);\n\t\t\t\tgoto end;\n\t\t\t}\n\n\t\t\ttv->value = _TIFFCheckMalloc(tif, tv->count, tv_size,\n\t\t\t    \"custom tag binary object\");\n\t\t\tif (!tv->value) {\n\t\t\t\tstatus = 0;\n\t\t\t\tgoto end;\n\t\t\t}\n\n\t\t\tif (fip->field_tag == TIFFTAG_DOTRANGE \n\t\t\t    && strcmp(fip->field_name,\"DotRange\") == 0) {\n\t\t\t\t/* TODO: This is an evil exception and should not have been\n\t\t\t\t   handled this way ... likely best if we move it into\n\t\t\t\t   the directory structure with an explicit field in \n\t\t\t\t   libtiff 4.1 and assign it a FIELD_ value */\n\t\t\t\tuint16_t v2[2];\n\t\t\t\tv2[0] = (uint16_t)va_arg(ap, int);\n\t\t\t\tv2[1] = (uint16_t)va_arg(ap, int);\n\t\t\t\t_TIFFmemcpy(tv->value, &v2, 4);\n\t\t\t}\n\n\t\t\telse if (fip->field_passcount\n\t\t\t\t  || fip->field_writecount == TIFF_VARIABLE\n\t\t\t\t  || fip->field_writecount == TIFF_VARIABLE2\n\t\t\t\t  || fip->field_writecount == TIFF_SPP\n\t\t\t\t  || tv->count > 1) {\n\t\t\t  /*--: Rational2Double: For Rationals tv_size is set above to 4 or 8 according to fip->set_field_type! */\n\t\t\t\t_TIFFmemcpy(tv->value, va_arg(ap, void *),\n\t\t\t\t    tv->count * tv_size);\n\t\t\t} else {\n\t\t\t\tchar *val = (char *)tv->value;\n\t\t\t\tassert( tv->count == 1 );\n\n\t\t\t\tswitch (fip->field_type) {\n\t\t\t\tcase TIFF_BYTE:\n\t\t\t\tcase TIFF_UNDEFINED:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint8_t v2 = (uint8_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SBYTE:\n\t\t\t\t\t{\n\t\t\t\t\t\tint8_t v2 = (int8_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SHORT:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint16_t v2 = (uint16_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SSHORT:\n\t\t\t\t\t{\n\t\t\t\t\t\tint16_t v2 = (int16_t)va_arg(ap, int);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_LONG:\n\t\t\t\tcase TIFF_IFD:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint32_t v2 = va_arg(ap, uint32_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SLONG:\n\t\t\t\t\t{\n\t\t\t\t\t\tint32_t v2 = va_arg(ap, int32_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_LONG8:\n\t\t\t\tcase TIFF_IFD8:\n\t\t\t\t\t{\n\t\t\t\t\t\tuint64_t v2 = va_arg(ap, uint64_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_SLONG8:\n\t\t\t\t\t{\n\t\t\t\t\t\tint64_t v2 = va_arg(ap, int64_t);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_RATIONAL:\n\t\t\t\tcase TIFF_SRATIONAL:\n\t\t\t\t\t/*-- Rational2Double: For Rationals tv_size is set above to 4 or 8 according to fip->set_field_type! */\n\t\t\t\t\t{\n\t\t\t\t\t\tif (tv_size == 8) {\n\t\t\t\t\t\t\tdouble v2 = va_arg(ap, double);\n\t\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t/*-- default should be tv_size == 4 */\n\t\t\t\t\t\t\tfloat v3 = (float)va_arg(ap, double);\n\t\t\t\t\t\t\t_TIFFmemcpy(val, &v3, tv_size);\n\t\t\t\t\t\t\t/*-- ToDo: After Testing, this should be removed and tv_size==4 should be set as default. */\n\t\t\t\t\t\t\tif (tv_size != 4) {\n\t\t\t\t\t\t\t\tTIFFErrorExt(0,\"TIFFLib: _TIFFVSetField()\", \"Rational2Double: .set_field_type in not 4 but %d\", tv_size); \n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_FLOAT:\n\t\t\t\t\t{\n\t\t\t\t\t\tfloat v2 = _TIFFClampDoubleToFloat(va_arg(ap, double));\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase TIFF_DOUBLE:\n\t\t\t\t\t{\n\t\t\t\t\t\tdouble v2 = va_arg(ap, double);\n\t\t\t\t\t\t_TIFFmemcpy(val, &v2, tv_size);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\t_TIFFmemset(val, 0, tv_size);\n\t\t\t\t\tstatus = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t}\n\tif (status) {\n\t\tconst TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n\t\tif (fip2)                \n\t\t\tTIFFSetFieldBit(tif, fip2->field_bit);\n\t\ttif->tif_flags |= TIFF_DIRTYDIRECT;\n\t}\n\nend:\n\tva_end(ap);\n\treturn (status);\nbadvalue:\n        {\n\t\tconst TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t     \"%s: Bad value %\"PRIu32\" for \\\"%s\\\" tag\",\n\t\t     tif->tif_name, v,\n\t\t     fip2 ? fip2->field_name : \"Unknown\");\n\t\tva_end(ap);\n        }\n\treturn (0);\nbadvalue32:\n        {\n\t\tconst TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n\t\tTIFFErrorExt(tif->tif_clientdata, module,\n\t\t     \"%s: Bad value %\"PRIu32\" for \\\"%s\\\" tag\",\n\t\t     tif->tif_name, v32,\n\t\t     fip2 ? fip2->field_name : \"Unknown\");\n\t\tva_end(ap);\n        }\n\treturn (0);\nbadvaluedouble:\n        {\n        const TIFFField* fip2=TIFFFieldWithTag(tif,tag);\n        TIFFErrorExt(tif->tif_clientdata, module,\n             \"%s: Bad value %f for \\\"%s\\\" tag\",\n             tif->tif_name, dblval,\n             fip2 ? fip2->field_name : \"Unknown\");\n        va_end(ap);\n        }\n    return (0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -166,13 +166,13 @@\n \t\tbreak;\n \tcase TIFFTAG_XRESOLUTION:\n         dblval = va_arg(ap, double);\n-        if( dblval < 0 )\n+        if( dblval != dblval || dblval < 0 )\n             goto badvaluedouble;\n \t\ttd->td_xresolution = _TIFFClampDoubleToFloat( dblval );\n \t\tbreak;\n \tcase TIFFTAG_YRESOLUTION:\n         dblval = va_arg(ap, double);\n-        if( dblval < 0 )\n+        if( dblval != dblval || dblval < 0 )\n             goto badvaluedouble;\n \t\ttd->td_yresolution = _TIFFClampDoubleToFloat( dblval );\n \t\tbreak;",
        "diff_line_info": {
            "deleted_lines": [
                "        if( dblval < 0 )",
                "        if( dblval < 0 )"
            ],
            "added_lines": [
                "        if( dblval != dblval || dblval < 0 )",
                "        if( dblval != dblval || dblval < 0 )"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6505",
        "func_name": "wireshark/dissect_pbb_tlvblock",
        "description": "epan/dissectors/packet-packetbb.c in the PacketBB dissector in Wireshark 1.12.x before 1.12.13 and 2.x before 2.0.5 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted packet.",
        "git_url": "https://github.com/wireshark/wireshark/commit/94e97e45cf614c7bb8fe90c23df52910246b2c95",
        "commit_title": "packetbb: Prevent divide by 0.",
        "commit_text": " Bug: 12577",
        "func_before": "static int dissect_pbb_tlvblock(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset,\n    guint maxoffset, gint8 addrCount, guint tlvCat) {\n  guint16 tlvblockLength;\n  guint tlvblockEnd;\n\n  proto_tree *tlvblock_tree = NULL;\n  proto_tree *tlv_tree = NULL;\n  proto_tree *tlv_flags_tree = NULL;\n  proto_tree *tlvValue_tree = NULL;\n\n  proto_item *tlvBlock_item = NULL;\n  proto_item *tlv_item = NULL;\n  proto_item *tlvFlags_item = NULL;\n  proto_item *tlvValue_item = NULL;\n  proto_item *ti = NULL;\n\n  int tlvCount = 0;\n\n  int hf_packetbb_tlv_type = 0;\n  const value_string* tlv_type_vals = NULL;\n\n  if (maxoffset < offset + 2) {\n    proto_tree_add_expert_format(tree, pinfo, &ei_packetbb_error, tvb, offset, maxoffset - offset,\n        \"Not enough octets for minimal tlvblock\");\n    return maxoffset;\n  }\n\n  tlvblockLength = tvb_get_ntohs(tvb, offset);\n\n  tlvblockEnd = offset + 2 + tlvblockLength;\n  if (maxoffset < tlvblockEnd) {\n    proto_tree_add_expert_format(tree, pinfo, &ei_packetbb_error, tvb, offset, maxoffset - offset,\n        \"Not enough octets for tlvblock\");\n    return maxoffset;\n  }\n\n  tlvBlock_item = proto_tree_add_item(tree, hf_packetbb_tlvblock, tvb, offset, tlvblockEnd - offset, ENC_NA);\n  tlvblock_tree = proto_item_add_subtree(tlvBlock_item, ett_packetbb_tlvblock);\n\n  proto_tree_add_item(tlvblock_tree, hf_packetbb_tlvblock_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n\n  offset += 2;\n  while (offset < tlvblockEnd) {\n    guint tlvStart, tlvLength;\n    guint8 tlvType, tlvFlags, tlvExtType, indexStart, indexEnd;\n    guint16 length = 0;\n\n    tlvStart = offset;\n    tlvType = tvb_get_guint8(tvb, offset++);\n    tlvFlags = tvb_get_guint8(tvb, offset++);\n\n    indexStart = 0;\n    indexEnd = addrCount ? (addrCount - 1) : 0;\n    tlvExtType = 0;\n\n    if ((tlvFlags & TLV_HAS_TYPEEXT) != 0) {\n      tlvExtType = tvb_get_guint8(tvb, offset++);\n    }\n\n    if ((tlvFlags & TLV_HAS_SINGLEINDEX) != 0) {\n      indexStart = indexEnd = tvb_get_guint8(tvb, offset++);\n    }\n    else if ((tlvFlags & TLV_HAS_MULTIINDEX) != 0) {\n      indexStart = tvb_get_guint8(tvb, offset++);\n      indexEnd = tvb_get_guint8(tvb, offset++);\n    }\n\n    if ((tlvFlags & TLV_HAS_VALUE) != 0) {\n      if ((tlvFlags & TLV_HAS_EXTLEN) != 0) {\n        length = tvb_get_ntohs(tvb, offset++);\n      }\n      else {\n        length = tvb_get_guint8(tvb, offset++);\n      }\n    }\n\n    tlvLength = offset - tlvStart + length;\n    offset = tlvStart;\n\n    tlv_item = proto_tree_add_item(tlvBlock_item, hf_packetbb_tlv, tvb, tlvStart, tlvLength, ENC_NA);\n    tlv_tree = proto_item_add_subtree(tlv_item, ett_packetbb_tlv[tlvType]);\n\n    /* select possible strings for tlvType */\n    if (tlvCat == TLV_CAT_PACKET) {\n      hf_packetbb_tlv_type = hf_packetbb_pkttlv_type;\n      tlv_type_vals = pkttlv_type_vals;\n    }\n    else if (tlvCat == TLV_CAT_MESSAGE) {\n      hf_packetbb_tlv_type = hf_packetbb_msgtlv_type;\n      tlv_type_vals = msgtlv_type_vals;\n    }\n    else {\n      /* assume TLV_CAT_ADDRESS */\n      hf_packetbb_tlv_type = hf_packetbb_addrtlv_type;\n      tlv_type_vals = addrtlv_type_vals;\n    }\n\n    if ((tlvFlags & TLV_HAS_TYPEEXT) == 0) {\n      proto_item_append_text(tlv_item, \" (%s)\",\n        val_to_str_const(tlvType, tlv_type_vals, \"Unknown type\"));\n    }\n    else {\n      proto_item_append_text(tlv_item, \" (%s / %d)\",\n        val_to_str_const(tlvType, tlv_type_vals, \"Unknown type\"), tlvExtType);\n    }\n\n    /* add type */\n    proto_tree_add_item(tlv_tree, hf_packetbb_tlv_type, tvb, offset++, 1, ENC_BIG_ENDIAN);\n\n    /* add flags */\n    tlvFlags_item = proto_tree_add_item(tlv_tree, hf_packetbb_tlv_flags, tvb, offset, 1, ENC_BIG_ENDIAN);\n    tlv_flags_tree = proto_item_add_subtree(tlvFlags_item, ett_packetbb_tlv_flags);\n\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hastypext, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hassingleindex, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasmultiindex, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasvalue, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasextlen, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasmultivalue, tvb, offset, 1, ENC_BIG_ENDIAN);\n    offset++;\n\n    if ((tlvFlags & TLV_HAS_TYPEEXT) != 0) {\n      /* add ext-type */\n      proto_tree_add_item(tlv_tree, hf_packetbb_tlv_typeext, tvb, offset++, 1, ENC_BIG_ENDIAN);\n    }\n\n    if (addrCount > 0) {\n      /* add index values */\n      if ((tlvFlags & TLV_HAS_SINGLEINDEX) != 0) {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexstart, tvb, offset++, 1, indexStart);\n\n        ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexend, tvb, offset, 0, indexEnd);\n        proto_item_append_text(ti, \" (implicit)\");\n      }\n      else if ((tlvFlags & TLV_HAS_MULTIINDEX) != 0) {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexstart, tvb, offset++, 1, indexStart);\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexend, tvb, offset++, 1, indexEnd);\n      }\n      else {\n        ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexstart, tvb, offset, 0, indexStart);\n        proto_item_append_text(ti, \" (implicit)\");\n\n        ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexend, tvb, offset, 0, indexEnd);\n        proto_item_append_text(ti, \" (implicit)\");\n      }\n    }\n\n    /* add length */\n    if ((tlvFlags & TLV_HAS_VALUE) != 0) {\n      if ((tlvFlags & TLV_HAS_EXTLEN) != 0) {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_length, tvb, offset, 2, length);\n        offset += 2;\n      }\n      else {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_length, tvb, offset++, 1, length);\n      }\n    }\n    else {\n      ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_length, tvb, offset, 0, 0);\n      proto_item_append_text(ti, \" (implicit)\");\n    }\n\n    if (length > 0) {\n      /* add value */\n      tlvValue_item = proto_tree_add_item(tlv_tree, hf_packetbb_tlv_value, tvb, offset, length, ENC_NA);\n\n      if ((tlvFlags & TLV_HAS_MULTIVALUE) == 0) {\n        offset += length;\n      }\n      else {\n        int i;\n        guint8 c = indexEnd - indexStart + 1;\n        tlvValue_tree = proto_item_add_subtree(tlvValue_item, ett_packetbb_tlv_value);\n\n        for (i=indexStart; i<=indexEnd; i++) {\n          proto_tree_add_item(tlvValue_tree, hf_packetbb_tlv_multivalue, tvb, offset, length/c, ENC_NA);\n          offset += (length/c);\n        }\n      }\n    }\n    tlvCount++;\n  }\n\n  proto_item_append_text(tlvBlock_item, \" (%d TLVs)\", tlvCount);\n\n  return offset;\n}",
        "func": "static int dissect_pbb_tlvblock(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree, guint offset,\n    guint maxoffset, gint8 addrCount, guint tlvCat) {\n  guint16 tlvblockLength;\n  guint tlvblockEnd;\n\n  proto_tree *tlvblock_tree = NULL;\n  proto_tree *tlv_tree = NULL;\n  proto_tree *tlv_flags_tree = NULL;\n  proto_tree *tlvValue_tree = NULL;\n\n  proto_item *tlvBlock_item = NULL;\n  proto_item *tlv_item = NULL;\n  proto_item *tlvFlags_item = NULL;\n  proto_item *tlvValue_item = NULL;\n  proto_item *ti = NULL;\n\n  int tlvCount = 0;\n\n  int hf_packetbb_tlv_type = 0;\n  const value_string* tlv_type_vals = NULL;\n\n  if (maxoffset < offset + 2) {\n    proto_tree_add_expert_format(tree, pinfo, &ei_packetbb_error, tvb, offset, maxoffset - offset,\n        \"Not enough octets for minimal tlvblock\");\n    return maxoffset;\n  }\n\n  tlvblockLength = tvb_get_ntohs(tvb, offset);\n\n  tlvblockEnd = offset + 2 + tlvblockLength;\n  if (maxoffset < tlvblockEnd) {\n    proto_tree_add_expert_format(tree, pinfo, &ei_packetbb_error, tvb, offset, maxoffset - offset,\n        \"Not enough octets for tlvblock\");\n    return maxoffset;\n  }\n\n  tlvBlock_item = proto_tree_add_item(tree, hf_packetbb_tlvblock, tvb, offset, tlvblockEnd - offset, ENC_NA);\n  tlvblock_tree = proto_item_add_subtree(tlvBlock_item, ett_packetbb_tlvblock);\n\n  proto_tree_add_item(tlvblock_tree, hf_packetbb_tlvblock_length, tvb, offset, 2, ENC_BIG_ENDIAN);\n\n  offset += 2;\n  while (offset < tlvblockEnd) {\n    guint tlvStart, tlvLength;\n    guint8 tlvType, tlvFlags, tlvExtType, indexStart, indexEnd;\n    guint16 length = 0;\n\n    tlvStart = offset;\n    tlvType = tvb_get_guint8(tvb, offset++);\n    tlvFlags = tvb_get_guint8(tvb, offset++);\n\n    indexStart = 0;\n    indexEnd = addrCount ? (addrCount - 1) : 0;\n    tlvExtType = 0;\n\n    if ((tlvFlags & TLV_HAS_TYPEEXT) != 0) {\n      tlvExtType = tvb_get_guint8(tvb, offset++);\n    }\n\n    if ((tlvFlags & TLV_HAS_SINGLEINDEX) != 0) {\n      indexStart = indexEnd = tvb_get_guint8(tvb, offset++);\n    }\n    else if ((tlvFlags & TLV_HAS_MULTIINDEX) != 0) {\n      indexStart = tvb_get_guint8(tvb, offset++);\n      indexEnd = tvb_get_guint8(tvb, offset++);\n    }\n\n    if ((tlvFlags & TLV_HAS_VALUE) != 0) {\n      if ((tlvFlags & TLV_HAS_EXTLEN) != 0) {\n        length = tvb_get_ntohs(tvb, offset++);\n      }\n      else {\n        length = tvb_get_guint8(tvb, offset++);\n      }\n    }\n\n    tlvLength = offset - tlvStart + length;\n    offset = tlvStart;\n\n    tlv_item = proto_tree_add_item(tlvBlock_item, hf_packetbb_tlv, tvb, tlvStart, tlvLength, ENC_NA);\n    tlv_tree = proto_item_add_subtree(tlv_item, ett_packetbb_tlv[tlvType]);\n\n    /* select possible strings for tlvType */\n    if (tlvCat == TLV_CAT_PACKET) {\n      hf_packetbb_tlv_type = hf_packetbb_pkttlv_type;\n      tlv_type_vals = pkttlv_type_vals;\n    }\n    else if (tlvCat == TLV_CAT_MESSAGE) {\n      hf_packetbb_tlv_type = hf_packetbb_msgtlv_type;\n      tlv_type_vals = msgtlv_type_vals;\n    }\n    else {\n      /* assume TLV_CAT_ADDRESS */\n      hf_packetbb_tlv_type = hf_packetbb_addrtlv_type;\n      tlv_type_vals = addrtlv_type_vals;\n    }\n\n    if ((tlvFlags & TLV_HAS_TYPEEXT) == 0) {\n      proto_item_append_text(tlv_item, \" (%s)\",\n        val_to_str_const(tlvType, tlv_type_vals, \"Unknown type\"));\n    }\n    else {\n      proto_item_append_text(tlv_item, \" (%s / %d)\",\n        val_to_str_const(tlvType, tlv_type_vals, \"Unknown type\"), tlvExtType);\n    }\n\n    /* add type */\n    proto_tree_add_item(tlv_tree, hf_packetbb_tlv_type, tvb, offset++, 1, ENC_BIG_ENDIAN);\n\n    /* add flags */\n    tlvFlags_item = proto_tree_add_item(tlv_tree, hf_packetbb_tlv_flags, tvb, offset, 1, ENC_BIG_ENDIAN);\n    tlv_flags_tree = proto_item_add_subtree(tlvFlags_item, ett_packetbb_tlv_flags);\n\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hastypext, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hassingleindex, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasmultiindex, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasvalue, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasextlen, tvb, offset, 1, ENC_BIG_ENDIAN);\n    proto_tree_add_item(tlv_flags_tree, hf_packetbb_tlv_flags_hasmultivalue, tvb, offset, 1, ENC_BIG_ENDIAN);\n    offset++;\n\n    if ((tlvFlags & TLV_HAS_TYPEEXT) != 0) {\n      /* add ext-type */\n      proto_tree_add_item(tlv_tree, hf_packetbb_tlv_typeext, tvb, offset++, 1, ENC_BIG_ENDIAN);\n    }\n\n    if (addrCount > 0) {\n      /* add index values */\n      if ((tlvFlags & TLV_HAS_SINGLEINDEX) != 0) {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexstart, tvb, offset++, 1, indexStart);\n\n        ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexend, tvb, offset, 0, indexEnd);\n        proto_item_append_text(ti, \" (implicit)\");\n      }\n      else if ((tlvFlags & TLV_HAS_MULTIINDEX) != 0) {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexstart, tvb, offset++, 1, indexStart);\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexend, tvb, offset++, 1, indexEnd);\n      }\n      else {\n        ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexstart, tvb, offset, 0, indexStart);\n        proto_item_append_text(ti, \" (implicit)\");\n\n        ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_indexend, tvb, offset, 0, indexEnd);\n        proto_item_append_text(ti, \" (implicit)\");\n      }\n    }\n\n    /* add length */\n    if ((tlvFlags & TLV_HAS_VALUE) != 0) {\n      if ((tlvFlags & TLV_HAS_EXTLEN) != 0) {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_length, tvb, offset, 2, length);\n        offset += 2;\n      }\n      else {\n        proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_length, tvb, offset++, 1, length);\n      }\n    }\n    else {\n      ti = proto_tree_add_uint(tlv_tree, hf_packetbb_tlv_length, tvb, offset, 0, 0);\n      proto_item_append_text(ti, \" (implicit)\");\n    }\n\n    if (length > 0) {\n      /* add value */\n      tlvValue_item = proto_tree_add_item(tlv_tree, hf_packetbb_tlv_value, tvb, offset, length, ENC_NA);\n\n      if ((tlvFlags & TLV_HAS_MULTIVALUE) == 0) {\n        offset += length;\n      }\n      else {\n        int i;\n        guint c = indexEnd - indexStart + 1;\n        if (c > 0) {\n          tlvValue_tree = proto_item_add_subtree(tlvValue_item, ett_packetbb_tlv_value);\n\n          for (i=indexStart; i<=indexEnd; i++) {\n            proto_tree_add_item(tlvValue_tree, hf_packetbb_tlv_multivalue, tvb, offset, length/c, ENC_NA);\n            offset += (length/c);\n          }\n        }\n      }\n    }\n    tlvCount++;\n  }\n\n  proto_item_append_text(tlvBlock_item, \" (%d TLVs)\", tlvCount);\n\n  return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -169,12 +169,14 @@\n       }\n       else {\n         int i;\n-        guint8 c = indexEnd - indexStart + 1;\n-        tlvValue_tree = proto_item_add_subtree(tlvValue_item, ett_packetbb_tlv_value);\n+        guint c = indexEnd - indexStart + 1;\n+        if (c > 0) {\n+          tlvValue_tree = proto_item_add_subtree(tlvValue_item, ett_packetbb_tlv_value);\n \n-        for (i=indexStart; i<=indexEnd; i++) {\n-          proto_tree_add_item(tlvValue_tree, hf_packetbb_tlv_multivalue, tvb, offset, length/c, ENC_NA);\n-          offset += (length/c);\n+          for (i=indexStart; i<=indexEnd; i++) {\n+            proto_tree_add_item(tlvValue_tree, hf_packetbb_tlv_multivalue, tvb, offset, length/c, ENC_NA);\n+            offset += (length/c);\n+          }\n         }\n       }\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        guint8 c = indexEnd - indexStart + 1;",
                "        tlvValue_tree = proto_item_add_subtree(tlvValue_item, ett_packetbb_tlv_value);",
                "        for (i=indexStart; i<=indexEnd; i++) {",
                "          proto_tree_add_item(tlvValue_tree, hf_packetbb_tlv_multivalue, tvb, offset, length/c, ENC_NA);",
                "          offset += (length/c);"
            ],
            "added_lines": [
                "        guint c = indexEnd - indexStart + 1;",
                "        if (c > 0) {",
                "          tlvValue_tree = proto_item_add_subtree(tlvValue_item, ett_packetbb_tlv_value);",
                "          for (i=indexStart; i<=indexEnd; i++) {",
                "            proto_tree_add_item(tlvValue_tree, hf_packetbb_tlv_multivalue, tvb, offset, length/c, ENC_NA);",
                "            offset += (length/c);",
                "          }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-8669",
        "func_name": "qemu/serial_update_parameters",
        "description": "The serial_update_parameters function in hw/char/serial.c in QEMU (aka Quick Emulator) allows local guest OS administrators to cause a denial of service (divide-by-zero error and QEMU process crash) via vectors involving a value of divider greater than baud base.",
        "git_url": "https://github.com/qemu/qemu/commit/3592fe0c919cf27a81d8e9f9b4f269553418bb01",
        "commit_title": "char: serial: check divider value against baud base",
        "commit_text": " 16550A UART device uses an oscillator to generate frequencies (baud base), which decide communication speed. This speed could be changed by dividing it by a divider. If the divider is greater than the baud base, speed is set to zero, leading to a divide by zero error. Add check to avoid it.  Message-Id: <1476251888-20238-1-git-send-email-ppandit@redhat.com>",
        "func_before": "static void serial_update_parameters(SerialState *s)\n{\n    int speed, parity, data_bits, stop_bits, frame_size;\n    QEMUSerialSetParams ssp;\n\n    if (s->divider == 0)\n        return;\n\n    /* Start bit. */\n    frame_size = 1;\n    if (s->lcr & 0x08) {\n        /* Parity bit. */\n        frame_size++;\n        if (s->lcr & 0x10)\n            parity = 'E';\n        else\n            parity = 'O';\n    } else {\n            parity = 'N';\n    }\n    if (s->lcr & 0x04)\n        stop_bits = 2;\n    else\n        stop_bits = 1;\n\n    data_bits = (s->lcr & 0x03) + 5;\n    frame_size += data_bits + stop_bits;\n    speed = s->baudbase / s->divider;\n    ssp.speed = speed;\n    ssp.parity = parity;\n    ssp.data_bits = data_bits;\n    ssp.stop_bits = stop_bits;\n    s->char_transmit_time =  (NANOSECONDS_PER_SECOND / speed) * frame_size;\n    qemu_chr_fe_ioctl(s->chr, CHR_IOCTL_SERIAL_SET_PARAMS, &ssp);\n\n    DPRINTF(\"speed=%d parity=%c data=%d stop=%d\\n\",\n           speed, parity, data_bits, stop_bits);\n}",
        "func": "static void serial_update_parameters(SerialState *s)\n{\n    int speed, parity, data_bits, stop_bits, frame_size;\n    QEMUSerialSetParams ssp;\n\n    if (s->divider == 0 || s->divider > s->baudbase) {\n        return;\n    }\n\n    /* Start bit. */\n    frame_size = 1;\n    if (s->lcr & 0x08) {\n        /* Parity bit. */\n        frame_size++;\n        if (s->lcr & 0x10)\n            parity = 'E';\n        else\n            parity = 'O';\n    } else {\n            parity = 'N';\n    }\n    if (s->lcr & 0x04)\n        stop_bits = 2;\n    else\n        stop_bits = 1;\n\n    data_bits = (s->lcr & 0x03) + 5;\n    frame_size += data_bits + stop_bits;\n    speed = s->baudbase / s->divider;\n    ssp.speed = speed;\n    ssp.parity = parity;\n    ssp.data_bits = data_bits;\n    ssp.stop_bits = stop_bits;\n    s->char_transmit_time =  (NANOSECONDS_PER_SECOND / speed) * frame_size;\n    qemu_chr_fe_ioctl(s->chr, CHR_IOCTL_SERIAL_SET_PARAMS, &ssp);\n\n    DPRINTF(\"speed=%d parity=%c data=%d stop=%d\\n\",\n           speed, parity, data_bits, stop_bits);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,8 +3,9 @@\n     int speed, parity, data_bits, stop_bits, frame_size;\n     QEMUSerialSetParams ssp;\n \n-    if (s->divider == 0)\n+    if (s->divider == 0 || s->divider > s->baudbase) {\n         return;\n+    }\n \n     /* Start bit. */\n     frame_size = 1;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (s->divider == 0)"
            ],
            "added_lines": [
                "    if (s->divider == 0 || s->divider > s->baudbase) {",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3418",
        "func_name": "xorg/xserver/ProcPutImage",
        "description": "The ProcPutImage function in dix/dispatch.c in X.Org Server (aka xserver and xorg-server) before 1.16.4 allows attackers to cause a denial of service (divide-by-zero and crash) via a zero-height PutImage request.",
        "git_url": "https://cgit.freedesktop.org/xorg/xserver/commit/?id=dc777c346d5d452a53b13b917c45f6a1bad2f20b",
        "commit_title": "The length checking code validates PutImage height and byte width by",
        "commit_text": "making sure that byte-width >= INT32_MAX / height. If height is zero, this generates a divide by zero exception. Allow zero height requests explicitly, bypassing the INT32_MAX check.  ",
        "func_before": "int\nProcPutImage(ClientPtr client)\n{\n    GC *pGC;\n    DrawablePtr pDraw;\n    long length;                /* length of scanline server padded */\n    long lengthProto;           /* length of scanline protocol padded */\n    char *tmpImage;\n\n    REQUEST(xPutImageReq);\n\n    REQUEST_AT_LEAST_SIZE(xPutImageReq);\n    VALIDATE_DRAWABLE_AND_GC(stuff->drawable, pDraw, DixWriteAccess);\n    if (stuff->format == XYBitmap) {\n        if ((stuff->depth != 1) ||\n            (stuff->leftPad >= (unsigned int) screenInfo.bitmapScanlinePad))\n            return BadMatch;\n        length = BitmapBytePad(stuff->width + stuff->leftPad);\n    }\n    else if (stuff->format == XYPixmap) {\n        if ((pDraw->depth != stuff->depth) ||\n            (stuff->leftPad >= (unsigned int) screenInfo.bitmapScanlinePad))\n            return BadMatch;\n        length = BitmapBytePad(stuff->width + stuff->leftPad);\n        length *= stuff->depth;\n    }\n    else if (stuff->format == ZPixmap) {\n        if ((pDraw->depth != stuff->depth) || (stuff->leftPad != 0))\n            return BadMatch;\n        length = PixmapBytePad(stuff->width, stuff->depth);\n    }\n    else {\n        client->errorValue = stuff->format;\n        return BadValue;\n    }\n\n    tmpImage = (char *) &stuff[1];\n    lengthProto = length;\n\n    if (lengthProto >= (INT32_MAX / stuff->height))\n        return BadLength;\n\n    if ((bytes_to_int32(lengthProto * stuff->height) +\n         bytes_to_int32(sizeof(xPutImageReq))) != client->req_len)\n        return BadLength;\n\n    ReformatImage(tmpImage, lengthProto * stuff->height,\n                  stuff->format == ZPixmap ? BitsPerPixel(stuff->depth) : 1,\n                  ClientOrder(client));\n\n    (*pGC->ops->PutImage) (pDraw, pGC, stuff->depth, stuff->dstX, stuff->dstY,\n                           stuff->width, stuff->height,\n                           stuff->leftPad, stuff->format, tmpImage);\n\n    return Success;\n}",
        "func": "int\nProcPutImage(ClientPtr client)\n{\n    GC *pGC;\n    DrawablePtr pDraw;\n    long length;                /* length of scanline server padded */\n    long lengthProto;           /* length of scanline protocol padded */\n    char *tmpImage;\n\n    REQUEST(xPutImageReq);\n\n    REQUEST_AT_LEAST_SIZE(xPutImageReq);\n    VALIDATE_DRAWABLE_AND_GC(stuff->drawable, pDraw, DixWriteAccess);\n    if (stuff->format == XYBitmap) {\n        if ((stuff->depth != 1) ||\n            (stuff->leftPad >= (unsigned int) screenInfo.bitmapScanlinePad))\n            return BadMatch;\n        length = BitmapBytePad(stuff->width + stuff->leftPad);\n    }\n    else if (stuff->format == XYPixmap) {\n        if ((pDraw->depth != stuff->depth) ||\n            (stuff->leftPad >= (unsigned int) screenInfo.bitmapScanlinePad))\n            return BadMatch;\n        length = BitmapBytePad(stuff->width + stuff->leftPad);\n        length *= stuff->depth;\n    }\n    else if (stuff->format == ZPixmap) {\n        if ((pDraw->depth != stuff->depth) || (stuff->leftPad != 0))\n            return BadMatch;\n        length = PixmapBytePad(stuff->width, stuff->depth);\n    }\n    else {\n        client->errorValue = stuff->format;\n        return BadValue;\n    }\n\n    tmpImage = (char *) &stuff[1];\n    lengthProto = length;\n\n    if (stuff->height != 0 && lengthProto >= (INT32_MAX / stuff->height))\n        return BadLength;\n\n    if ((bytes_to_int32(lengthProto * stuff->height) +\n         bytes_to_int32(sizeof(xPutImageReq))) != client->req_len)\n        return BadLength;\n\n    ReformatImage(tmpImage, lengthProto * stuff->height,\n                  stuff->format == ZPixmap ? BitsPerPixel(stuff->depth) : 1,\n                  ClientOrder(client));\n\n    (*pGC->ops->PutImage) (pDraw, pGC, stuff->depth, stuff->dstX, stuff->dstY,\n                           stuff->width, stuff->height,\n                           stuff->leftPad, stuff->format, tmpImage);\n\n    return Success;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,7 +37,7 @@\n     tmpImage = (char *) &stuff[1];\n     lengthProto = length;\n \n-    if (lengthProto >= (INT32_MAX / stuff->height))\n+    if (stuff->height != 0 && lengthProto >= (INT32_MAX / stuff->height))\n         return BadLength;\n \n     if ((bytes_to_int32(lengthProto * stuff->height) +",
        "diff_line_info": {
            "deleted_lines": [
                "    if (lengthProto >= (INT32_MAX / stuff->height))"
            ],
            "added_lines": [
                "    if (stuff->height != 0 && lengthProto >= (INT32_MAX / stuff->height))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9756",
        "func_name": "libsndfile/psf_fwrite",
        "description": "The psf_fwrite function in file_io.c in libsndfile allows attackers to cause a denial of service (divide-by-zero error and application crash) via unspecified vectors related to the headindex variable.",
        "git_url": "https://github.com/libsndfile/libsndfile/commit/725c7dbb95bfaf8b4bb7b04820e3a00cceea9ce6",
        "commit_title": "src/file_io.c : Prevent potential divide-by-zero.",
        "commit_text": " Closes: https://github.com/erikd/libsndfile/issues/92",
        "func_before": "sf_count_t\npsf_fwrite (const void *ptr, sf_count_t bytes, sf_count_t items, SF_PRIVATE *psf)\n{\tsf_count_t total = 0 ;\n\tssize_t\tcount ;\n\n\tif (psf->virtual_io)\n\t\treturn psf->vio.write (ptr, bytes*items, psf->vio_user_data) / bytes ;\n\n\titems *= bytes ;\n\n\t/* Do this check after the multiplication above. */\n\tif (items <= 0)\n\t\treturn 0 ;\n\n\twhile (items > 0)\n\t{\t/* Break the writes down to a sensible size. */\n\t\tcount = (items > SENSIBLE_SIZE) ? SENSIBLE_SIZE : items ;\n\n\t\tcount = write (psf->file.filedes, ((const char*) ptr) + total, count) ;\n\n\t\tif (count == -1)\n\t\t{\tif (errno == EINTR)\n\t\t\t\tcontinue ;\n\n\t\t\tpsf_log_syserr (psf, errno) ;\n\t\t\tbreak ;\n\t\t\t} ;\n\n\t\tif (count == 0)\n\t\t\tbreak ;\n\n\t\ttotal += count ;\n\t\titems -= count ;\n\t\t} ;\n\n\tif (psf->is_pipe)\n\t\tpsf->pipeoffset += total ;\n\n\treturn total / bytes ;\n}",
        "func": "sf_count_t\npsf_fwrite (const void *ptr, sf_count_t bytes, sf_count_t items, SF_PRIVATE *psf)\n{\tsf_count_t total = 0 ;\n\tssize_t\tcount ;\n\n\tif (bytes == 0 || items == 0)\n\t\treturn 0 ;\n\n\tif (psf->virtual_io)\n\t\treturn psf->vio.write (ptr, bytes*items, psf->vio_user_data) / bytes ;\n\n\titems *= bytes ;\n\n\t/* Do this check after the multiplication above. */\n\tif (items <= 0)\n\t\treturn 0 ;\n\n\twhile (items > 0)\n\t{\t/* Break the writes down to a sensible size. */\n\t\tcount = (items > SENSIBLE_SIZE) ? SENSIBLE_SIZE : items ;\n\n\t\tcount = write (psf->file.filedes, ((const char*) ptr) + total, count) ;\n\n\t\tif (count == -1)\n\t\t{\tif (errno == EINTR)\n\t\t\t\tcontinue ;\n\n\t\t\tpsf_log_syserr (psf, errno) ;\n\t\t\tbreak ;\n\t\t\t} ;\n\n\t\tif (count == 0)\n\t\t\tbreak ;\n\n\t\ttotal += count ;\n\t\titems -= count ;\n\t\t} ;\n\n\tif (psf->is_pipe)\n\t\tpsf->pipeoffset += total ;\n\n\treturn total / bytes ;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,9 @@\n psf_fwrite (const void *ptr, sf_count_t bytes, sf_count_t items, SF_PRIVATE *psf)\n {\tsf_count_t total = 0 ;\n \tssize_t\tcount ;\n+\n+\tif (bytes == 0 || items == 0)\n+\t\treturn 0 ;\n \n \tif (psf->virtual_io)\n \t\treturn psf->vio.write (ptr, bytes*items, psf->vio_user_data) / bytes ;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (bytes == 0 || items == 0)",
                "\t\treturn 0 ;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7513",
        "func_name": "torvalds/linux/kvm_vm_ioctl_set_pit",
        "description": "arch/x86/kvm/x86.c in the Linux kernel before 4.4 does not reset the PIT counter values during state restoration, which allows guest OS users to cause a denial of service (divide-by-zero error and host OS crash) via a zero value, related to the kvm_vm_ioctl_set_pit and kvm_vm_ioctl_set_pit2 functions.",
        "git_url": "https://github.com/torvalds/linux/commit/0185604c2d82c560dab2f2933a18f797e74ab5a8",
        "commit_title": "KVM: x86: Reload pit counters for all channels when restoring state",
        "commit_text": " Currently if userspace restores the pit counters with a count of 0 on channels 1 or 2 and the guest attempts to read the count on those channels, then KVM will perform a mod of 0 and crash.  This will ensure that 0 values are converted to 65536 as per the spec.  This is CVE-2015-7513. ",
        "func_before": "static int kvm_vm_ioctl_set_pit(struct kvm *kvm, struct kvm_pit_state *ps)\n{\n\tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n\tmemcpy(&kvm->arch.vpit->pit_state, ps, sizeof(struct kvm_pit_state));\n\tkvm_pit_load_count(kvm, 0, ps->channels[0].count, 0);\n\tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n\treturn 0;\n}",
        "func": "static int kvm_vm_ioctl_set_pit(struct kvm *kvm, struct kvm_pit_state *ps)\n{\n\tint i;\n\tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n\tmemcpy(&kvm->arch.vpit->pit_state, ps, sizeof(struct kvm_pit_state));\n\tfor (i = 0; i < 3; i++)\n\t\tkvm_pit_load_count(kvm, i, ps->channels[i].count, 0);\n\tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,10 @@\n static int kvm_vm_ioctl_set_pit(struct kvm *kvm, struct kvm_pit_state *ps)\n {\n+\tint i;\n \tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n \tmemcpy(&kvm->arch.vpit->pit_state, ps, sizeof(struct kvm_pit_state));\n-\tkvm_pit_load_count(kvm, 0, ps->channels[0].count, 0);\n+\tfor (i = 0; i < 3; i++)\n+\t\tkvm_pit_load_count(kvm, i, ps->channels[i].count, 0);\n \tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tkvm_pit_load_count(kvm, 0, ps->channels[0].count, 0);"
            ],
            "added_lines": [
                "\tint i;",
                "\tfor (i = 0; i < 3; i++)",
                "\t\tkvm_pit_load_count(kvm, i, ps->channels[i].count, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7513",
        "func_name": "torvalds/linux/kvm_vm_ioctl_set_pit2",
        "description": "arch/x86/kvm/x86.c in the Linux kernel before 4.4 does not reset the PIT counter values during state restoration, which allows guest OS users to cause a denial of service (divide-by-zero error and host OS crash) via a zero value, related to the kvm_vm_ioctl_set_pit and kvm_vm_ioctl_set_pit2 functions.",
        "git_url": "https://github.com/torvalds/linux/commit/0185604c2d82c560dab2f2933a18f797e74ab5a8",
        "commit_title": "KVM: x86: Reload pit counters for all channels when restoring state",
        "commit_text": " Currently if userspace restores the pit counters with a count of 0 on channels 1 or 2 and the guest attempts to read the count on those channels, then KVM will perform a mod of 0 and crash.  This will ensure that 0 values are converted to 65536 as per the spec.  This is CVE-2015-7513. ",
        "func_before": "static int kvm_vm_ioctl_set_pit2(struct kvm *kvm, struct kvm_pit_state2 *ps)\n{\n\tint start = 0;\n\tu32 prev_legacy, cur_legacy;\n\tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n\tprev_legacy = kvm->arch.vpit->pit_state.flags & KVM_PIT_FLAGS_HPET_LEGACY;\n\tcur_legacy = ps->flags & KVM_PIT_FLAGS_HPET_LEGACY;\n\tif (!prev_legacy && cur_legacy)\n\t\tstart = 1;\n\tmemcpy(&kvm->arch.vpit->pit_state.channels, &ps->channels,\n\t       sizeof(kvm->arch.vpit->pit_state.channels));\n\tkvm->arch.vpit->pit_state.flags = ps->flags;\n\tkvm_pit_load_count(kvm, 0, kvm->arch.vpit->pit_state.channels[0].count, start);\n\tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n\treturn 0;\n}",
        "func": "static int kvm_vm_ioctl_set_pit2(struct kvm *kvm, struct kvm_pit_state2 *ps)\n{\n\tint start = 0;\n\tint i;\n\tu32 prev_legacy, cur_legacy;\n\tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n\tprev_legacy = kvm->arch.vpit->pit_state.flags & KVM_PIT_FLAGS_HPET_LEGACY;\n\tcur_legacy = ps->flags & KVM_PIT_FLAGS_HPET_LEGACY;\n\tif (!prev_legacy && cur_legacy)\n\t\tstart = 1;\n\tmemcpy(&kvm->arch.vpit->pit_state.channels, &ps->channels,\n\t       sizeof(kvm->arch.vpit->pit_state.channels));\n\tkvm->arch.vpit->pit_state.flags = ps->flags;\n\tfor (i = 0; i < 3; i++)\n\t\tkvm_pit_load_count(kvm, i, kvm->arch.vpit->pit_state.channels[i].count, start);\n\tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n static int kvm_vm_ioctl_set_pit2(struct kvm *kvm, struct kvm_pit_state2 *ps)\n {\n \tint start = 0;\n+\tint i;\n \tu32 prev_legacy, cur_legacy;\n \tmutex_lock(&kvm->arch.vpit->pit_state.lock);\n \tprev_legacy = kvm->arch.vpit->pit_state.flags & KVM_PIT_FLAGS_HPET_LEGACY;\n@@ -10,7 +11,8 @@\n \tmemcpy(&kvm->arch.vpit->pit_state.channels, &ps->channels,\n \t       sizeof(kvm->arch.vpit->pit_state.channels));\n \tkvm->arch.vpit->pit_state.flags = ps->flags;\n-\tkvm_pit_load_count(kvm, 0, kvm->arch.vpit->pit_state.channels[0].count, start);\n+\tfor (i = 0; i < 3; i++)\n+\t\tkvm_pit_load_count(kvm, i, kvm->arch.vpit->pit_state.channels[i].count, start);\n \tmutex_unlock(&kvm->arch.vpit->pit_state.lock);\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tkvm_pit_load_count(kvm, 0, kvm->arch.vpit->pit_state.channels[0].count, start);"
            ],
            "added_lines": [
                "\tint i;",
                "\tfor (i = 0; i < 3; i++)",
                "\t\tkvm_pit_load_count(kvm, i, kvm->arch.vpit->pit_state.channels[i].count, start);"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-4165",
        "func_name": "torvalds/linux/do_tcp_setsockopt",
        "description": "The do_tcp_setsockopt function in net/ipv4/tcp.c in the Linux kernel before 2.6.37-rc2 does not properly restrict TCP_MAXSEG (aka MSS) values, which allows local users to cause a denial of service (OOPS) via a setsockopt call that specifies a small value, leading to a divide-by-zero error or incorrect use of a signed integer.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7a1abd08d52fdeddb3e9a5a33f2f15cc6a5674d2",
        "commit_title": "As noted by Steve Chen, since commit",
        "commit_text": "f5fff5dc8a7a3f395b0525c02ba92c95d42b7390 (\"tcp: advertise MSS requested by user\") we can end up with a situation where tcp_select_initial_window() does a divide by a zero (or even negative) mss value.  The problem is that sometimes we effectively subtract TCPOLEN_TSTAMP_ALIGNED and/or TCPOLEN_MD5SIG_ALIGNED from the mss.  Fix this by increasing the minimum from 8 to 64.  ",
        "func_before": "static int do_tcp_setsockopt(struct sock *sk, int level,\n\t\tint optname, char __user *optval, unsigned int optlen)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tint val;\n\tint err = 0;\n\n\t/* These are data/string values, all the others are ints */\n\tswitch (optname) {\n\tcase TCP_CONGESTION: {\n\t\tchar name[TCP_CA_NAME_MAX];\n\n\t\tif (optlen < 1)\n\t\t\treturn -EINVAL;\n\n\t\tval = strncpy_from_user(name, optval,\n\t\t\t\t\tmin_t(long, TCP_CA_NAME_MAX-1, optlen));\n\t\tif (val < 0)\n\t\t\treturn -EFAULT;\n\t\tname[val] = 0;\n\n\t\tlock_sock(sk);\n\t\terr = tcp_set_congestion_control(sk, name);\n\t\trelease_sock(sk);\n\t\treturn err;\n\t}\n\tcase TCP_COOKIE_TRANSACTIONS: {\n\t\tstruct tcp_cookie_transactions ctd;\n\t\tstruct tcp_cookie_values *cvp = NULL;\n\n\t\tif (sizeof(ctd) > optlen)\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&ctd, optval, sizeof(ctd)))\n\t\t\treturn -EFAULT;\n\n\t\tif (ctd.tcpct_used > sizeof(ctd.tcpct_value) ||\n\t\t    ctd.tcpct_s_data_desired > TCP_MSS_DESIRED)\n\t\t\treturn -EINVAL;\n\n\t\tif (ctd.tcpct_cookie_desired == 0) {\n\t\t\t/* default to global value */\n\t\t} else if ((0x1 & ctd.tcpct_cookie_desired) ||\n\t\t\t   ctd.tcpct_cookie_desired > TCP_COOKIE_MAX ||\n\t\t\t   ctd.tcpct_cookie_desired < TCP_COOKIE_MIN) {\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (TCP_COOKIE_OUT_NEVER & ctd.tcpct_flags) {\n\t\t\t/* Supercedes all other values */\n\t\t\tlock_sock(sk);\n\t\t\tif (tp->cookie_values != NULL) {\n\t\t\t\tkref_put(&tp->cookie_values->kref,\n\t\t\t\t\t tcp_cookie_values_release);\n\t\t\t\ttp->cookie_values = NULL;\n\t\t\t}\n\t\t\ttp->rx_opt.cookie_in_always = 0; /* false */\n\t\t\ttp->rx_opt.cookie_out_never = 1; /* true */\n\t\t\trelease_sock(sk);\n\t\t\treturn err;\n\t\t}\n\n\t\t/* Allocate ancillary memory before locking.\n\t\t */\n\t\tif (ctd.tcpct_used > 0 ||\n\t\t    (tp->cookie_values == NULL &&\n\t\t     (sysctl_tcp_cookie_size > 0 ||\n\t\t      ctd.tcpct_cookie_desired > 0 ||\n\t\t      ctd.tcpct_s_data_desired > 0))) {\n\t\t\tcvp = kzalloc(sizeof(*cvp) + ctd.tcpct_used,\n\t\t\t\t      GFP_KERNEL);\n\t\t\tif (cvp == NULL)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tkref_init(&cvp->kref);\n\t\t}\n\t\tlock_sock(sk);\n\t\ttp->rx_opt.cookie_in_always =\n\t\t\t(TCP_COOKIE_IN_ALWAYS & ctd.tcpct_flags);\n\t\ttp->rx_opt.cookie_out_never = 0; /* false */\n\n\t\tif (tp->cookie_values != NULL) {\n\t\t\tif (cvp != NULL) {\n\t\t\t\t/* Changed values are recorded by a changed\n\t\t\t\t * pointer, ensuring the cookie will differ,\n\t\t\t\t * without separately hashing each value later.\n\t\t\t\t */\n\t\t\t\tkref_put(&tp->cookie_values->kref,\n\t\t\t\t\t tcp_cookie_values_release);\n\t\t\t} else {\n\t\t\t\tcvp = tp->cookie_values;\n\t\t\t}\n\t\t}\n\n\t\tif (cvp != NULL) {\n\t\t\tcvp->cookie_desired = ctd.tcpct_cookie_desired;\n\n\t\t\tif (ctd.tcpct_used > 0) {\n\t\t\t\tmemcpy(cvp->s_data_payload, ctd.tcpct_value,\n\t\t\t\t       ctd.tcpct_used);\n\t\t\t\tcvp->s_data_desired = ctd.tcpct_used;\n\t\t\t\tcvp->s_data_constant = 1; /* true */\n\t\t\t} else {\n\t\t\t\t/* No constant payload data. */\n\t\t\t\tcvp->s_data_desired = ctd.tcpct_s_data_desired;\n\t\t\t\tcvp->s_data_constant = 0; /* false */\n\t\t\t}\n\n\t\t\ttp->cookie_values = cvp;\n\t\t}\n\t\trelease_sock(sk);\n\t\treturn err;\n\t}\n\tdefault:\n\t\t/* fallthru */\n\t\tbreak;\n\t}\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase TCP_MAXSEG:\n\t\t/* Values greater than interface MTU won't take effect. However\n\t\t * at the point when this call is done we typically don't yet\n\t\t * know which interface is going to be used */\n\t\tif (val < 8 || val > MAX_TCP_WINDOW) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\ttp->rx_opt.user_mss = val;\n\t\tbreak;\n\n\tcase TCP_NODELAY:\n\t\tif (val) {\n\t\t\t/* TCP_NODELAY is weaker than TCP_CORK, so that\n\t\t\t * this option on corked socket is remembered, but\n\t\t\t * it is not activated until cork is cleared.\n\t\t\t *\n\t\t\t * However, when TCP_NODELAY is set we make\n\t\t\t * an explicit push, which overrides even TCP_CORK\n\t\t\t * for currently queued segments.\n\t\t\t */\n\t\t\ttp->nonagle |= TCP_NAGLE_OFF|TCP_NAGLE_PUSH;\n\t\t\ttcp_push_pending_frames(sk);\n\t\t} else {\n\t\t\ttp->nonagle &= ~TCP_NAGLE_OFF;\n\t\t}\n\t\tbreak;\n\n\tcase TCP_THIN_LINEAR_TIMEOUTS:\n\t\tif (val < 0 || val > 1)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->thin_lto = val;\n\t\tbreak;\n\n\tcase TCP_THIN_DUPACK:\n\t\tif (val < 0 || val > 1)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->thin_dupack = val;\n\t\tbreak;\n\n\tcase TCP_CORK:\n\t\t/* When set indicates to always queue non-full frames.\n\t\t * Later the user clears this option and we transmit\n\t\t * any pending partial frames in the queue.  This is\n\t\t * meant to be used alongside sendfile() to get properly\n\t\t * filled frames when the user (for example) must write\n\t\t * out headers with a write() call first and then use\n\t\t * sendfile to send out the data parts.\n\t\t *\n\t\t * TCP_CORK can be set together with TCP_NODELAY and it is\n\t\t * stronger than TCP_NODELAY.\n\t\t */\n\t\tif (val) {\n\t\t\ttp->nonagle |= TCP_NAGLE_CORK;\n\t\t} else {\n\t\t\ttp->nonagle &= ~TCP_NAGLE_CORK;\n\t\t\tif (tp->nonagle&TCP_NAGLE_OFF)\n\t\t\t\ttp->nonagle |= TCP_NAGLE_PUSH;\n\t\t\ttcp_push_pending_frames(sk);\n\t\t}\n\t\tbreak;\n\n\tcase TCP_KEEPIDLE:\n\t\tif (val < 1 || val > MAX_TCP_KEEPIDLE)\n\t\t\terr = -EINVAL;\n\t\telse {\n\t\t\ttp->keepalive_time = val * HZ;\n\t\t\tif (sock_flag(sk, SOCK_KEEPOPEN) &&\n\t\t\t    !((1 << sk->sk_state) &\n\t\t\t      (TCPF_CLOSE | TCPF_LISTEN))) {\n\t\t\t\tu32 elapsed = keepalive_time_elapsed(tp);\n\t\t\t\tif (tp->keepalive_time > elapsed)\n\t\t\t\t\telapsed = tp->keepalive_time - elapsed;\n\t\t\t\telse\n\t\t\t\t\telapsed = 0;\n\t\t\t\tinet_csk_reset_keepalive_timer(sk, elapsed);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase TCP_KEEPINTVL:\n\t\tif (val < 1 || val > MAX_TCP_KEEPINTVL)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->keepalive_intvl = val * HZ;\n\t\tbreak;\n\tcase TCP_KEEPCNT:\n\t\tif (val < 1 || val > MAX_TCP_KEEPCNT)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->keepalive_probes = val;\n\t\tbreak;\n\tcase TCP_SYNCNT:\n\t\tif (val < 1 || val > MAX_TCP_SYNCNT)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ticsk->icsk_syn_retries = val;\n\t\tbreak;\n\n\tcase TCP_LINGER2:\n\t\tif (val < 0)\n\t\t\ttp->linger2 = -1;\n\t\telse if (val > sysctl_tcp_fin_timeout / HZ)\n\t\t\ttp->linger2 = 0;\n\t\telse\n\t\t\ttp->linger2 = val * HZ;\n\t\tbreak;\n\n\tcase TCP_DEFER_ACCEPT:\n\t\t/* Translate value in seconds to number of retransmits */\n\t\ticsk->icsk_accept_queue.rskq_defer_accept =\n\t\t\tsecs_to_retrans(val, TCP_TIMEOUT_INIT / HZ,\n\t\t\t\t\tTCP_RTO_MAX / HZ);\n\t\tbreak;\n\n\tcase TCP_WINDOW_CLAMP:\n\t\tif (!val) {\n\t\t\tif (sk->sk_state != TCP_CLOSE) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttp->window_clamp = 0;\n\t\t} else\n\t\t\ttp->window_clamp = val < SOCK_MIN_RCVBUF / 2 ?\n\t\t\t\t\t\tSOCK_MIN_RCVBUF / 2 : val;\n\t\tbreak;\n\n\tcase TCP_QUICKACK:\n\t\tif (!val) {\n\t\t\ticsk->icsk_ack.pingpong = 1;\n\t\t} else {\n\t\t\ticsk->icsk_ack.pingpong = 0;\n\t\t\tif ((1 << sk->sk_state) &\n\t\t\t    (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT) &&\n\t\t\t    inet_csk_ack_scheduled(sk)) {\n\t\t\t\ticsk->icsk_ack.pending |= ICSK_ACK_PUSHED;\n\t\t\t\ttcp_cleanup_rbuf(sk, 1);\n\t\t\t\tif (!(val & 1))\n\t\t\t\t\ticsk->icsk_ack.pingpong = 1;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n#ifdef CONFIG_TCP_MD5SIG\n\tcase TCP_MD5SIG:\n\t\t/* Read the IP->Key mappings from userspace */\n\t\terr = tp->af_specific->md5_parse(sk, optval, optlen);\n\t\tbreak;\n#endif\n\tcase TCP_USER_TIMEOUT:\n\t\t/* Cap the max timeout in ms TCP will retry/retrans\n\t\t * before giving up and aborting (ETIMEDOUT) a connection.\n\t\t */\n\t\ticsk->icsk_user_timeout = msecs_to_jiffies(val);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\n\trelease_sock(sk);\n\treturn err;\n}",
        "func": "static int do_tcp_setsockopt(struct sock *sk, int level,\n\t\tint optname, char __user *optval, unsigned int optlen)\n{\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tint val;\n\tint err = 0;\n\n\t/* These are data/string values, all the others are ints */\n\tswitch (optname) {\n\tcase TCP_CONGESTION: {\n\t\tchar name[TCP_CA_NAME_MAX];\n\n\t\tif (optlen < 1)\n\t\t\treturn -EINVAL;\n\n\t\tval = strncpy_from_user(name, optval,\n\t\t\t\t\tmin_t(long, TCP_CA_NAME_MAX-1, optlen));\n\t\tif (val < 0)\n\t\t\treturn -EFAULT;\n\t\tname[val] = 0;\n\n\t\tlock_sock(sk);\n\t\terr = tcp_set_congestion_control(sk, name);\n\t\trelease_sock(sk);\n\t\treturn err;\n\t}\n\tcase TCP_COOKIE_TRANSACTIONS: {\n\t\tstruct tcp_cookie_transactions ctd;\n\t\tstruct tcp_cookie_values *cvp = NULL;\n\n\t\tif (sizeof(ctd) > optlen)\n\t\t\treturn -EINVAL;\n\t\tif (copy_from_user(&ctd, optval, sizeof(ctd)))\n\t\t\treturn -EFAULT;\n\n\t\tif (ctd.tcpct_used > sizeof(ctd.tcpct_value) ||\n\t\t    ctd.tcpct_s_data_desired > TCP_MSS_DESIRED)\n\t\t\treturn -EINVAL;\n\n\t\tif (ctd.tcpct_cookie_desired == 0) {\n\t\t\t/* default to global value */\n\t\t} else if ((0x1 & ctd.tcpct_cookie_desired) ||\n\t\t\t   ctd.tcpct_cookie_desired > TCP_COOKIE_MAX ||\n\t\t\t   ctd.tcpct_cookie_desired < TCP_COOKIE_MIN) {\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (TCP_COOKIE_OUT_NEVER & ctd.tcpct_flags) {\n\t\t\t/* Supercedes all other values */\n\t\t\tlock_sock(sk);\n\t\t\tif (tp->cookie_values != NULL) {\n\t\t\t\tkref_put(&tp->cookie_values->kref,\n\t\t\t\t\t tcp_cookie_values_release);\n\t\t\t\ttp->cookie_values = NULL;\n\t\t\t}\n\t\t\ttp->rx_opt.cookie_in_always = 0; /* false */\n\t\t\ttp->rx_opt.cookie_out_never = 1; /* true */\n\t\t\trelease_sock(sk);\n\t\t\treturn err;\n\t\t}\n\n\t\t/* Allocate ancillary memory before locking.\n\t\t */\n\t\tif (ctd.tcpct_used > 0 ||\n\t\t    (tp->cookie_values == NULL &&\n\t\t     (sysctl_tcp_cookie_size > 0 ||\n\t\t      ctd.tcpct_cookie_desired > 0 ||\n\t\t      ctd.tcpct_s_data_desired > 0))) {\n\t\t\tcvp = kzalloc(sizeof(*cvp) + ctd.tcpct_used,\n\t\t\t\t      GFP_KERNEL);\n\t\t\tif (cvp == NULL)\n\t\t\t\treturn -ENOMEM;\n\n\t\t\tkref_init(&cvp->kref);\n\t\t}\n\t\tlock_sock(sk);\n\t\ttp->rx_opt.cookie_in_always =\n\t\t\t(TCP_COOKIE_IN_ALWAYS & ctd.tcpct_flags);\n\t\ttp->rx_opt.cookie_out_never = 0; /* false */\n\n\t\tif (tp->cookie_values != NULL) {\n\t\t\tif (cvp != NULL) {\n\t\t\t\t/* Changed values are recorded by a changed\n\t\t\t\t * pointer, ensuring the cookie will differ,\n\t\t\t\t * without separately hashing each value later.\n\t\t\t\t */\n\t\t\t\tkref_put(&tp->cookie_values->kref,\n\t\t\t\t\t tcp_cookie_values_release);\n\t\t\t} else {\n\t\t\t\tcvp = tp->cookie_values;\n\t\t\t}\n\t\t}\n\n\t\tif (cvp != NULL) {\n\t\t\tcvp->cookie_desired = ctd.tcpct_cookie_desired;\n\n\t\t\tif (ctd.tcpct_used > 0) {\n\t\t\t\tmemcpy(cvp->s_data_payload, ctd.tcpct_value,\n\t\t\t\t       ctd.tcpct_used);\n\t\t\t\tcvp->s_data_desired = ctd.tcpct_used;\n\t\t\t\tcvp->s_data_constant = 1; /* true */\n\t\t\t} else {\n\t\t\t\t/* No constant payload data. */\n\t\t\t\tcvp->s_data_desired = ctd.tcpct_s_data_desired;\n\t\t\t\tcvp->s_data_constant = 0; /* false */\n\t\t\t}\n\n\t\t\ttp->cookie_values = cvp;\n\t\t}\n\t\trelease_sock(sk);\n\t\treturn err;\n\t}\n\tdefault:\n\t\t/* fallthru */\n\t\tbreak;\n\t}\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase TCP_MAXSEG:\n\t\t/* Values greater than interface MTU won't take effect. However\n\t\t * at the point when this call is done we typically don't yet\n\t\t * know which interface is going to be used */\n\t\tif (val < 64 || val > MAX_TCP_WINDOW) {\n\t\t\terr = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\ttp->rx_opt.user_mss = val;\n\t\tbreak;\n\n\tcase TCP_NODELAY:\n\t\tif (val) {\n\t\t\t/* TCP_NODELAY is weaker than TCP_CORK, so that\n\t\t\t * this option on corked socket is remembered, but\n\t\t\t * it is not activated until cork is cleared.\n\t\t\t *\n\t\t\t * However, when TCP_NODELAY is set we make\n\t\t\t * an explicit push, which overrides even TCP_CORK\n\t\t\t * for currently queued segments.\n\t\t\t */\n\t\t\ttp->nonagle |= TCP_NAGLE_OFF|TCP_NAGLE_PUSH;\n\t\t\ttcp_push_pending_frames(sk);\n\t\t} else {\n\t\t\ttp->nonagle &= ~TCP_NAGLE_OFF;\n\t\t}\n\t\tbreak;\n\n\tcase TCP_THIN_LINEAR_TIMEOUTS:\n\t\tif (val < 0 || val > 1)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->thin_lto = val;\n\t\tbreak;\n\n\tcase TCP_THIN_DUPACK:\n\t\tif (val < 0 || val > 1)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->thin_dupack = val;\n\t\tbreak;\n\n\tcase TCP_CORK:\n\t\t/* When set indicates to always queue non-full frames.\n\t\t * Later the user clears this option and we transmit\n\t\t * any pending partial frames in the queue.  This is\n\t\t * meant to be used alongside sendfile() to get properly\n\t\t * filled frames when the user (for example) must write\n\t\t * out headers with a write() call first and then use\n\t\t * sendfile to send out the data parts.\n\t\t *\n\t\t * TCP_CORK can be set together with TCP_NODELAY and it is\n\t\t * stronger than TCP_NODELAY.\n\t\t */\n\t\tif (val) {\n\t\t\ttp->nonagle |= TCP_NAGLE_CORK;\n\t\t} else {\n\t\t\ttp->nonagle &= ~TCP_NAGLE_CORK;\n\t\t\tif (tp->nonagle&TCP_NAGLE_OFF)\n\t\t\t\ttp->nonagle |= TCP_NAGLE_PUSH;\n\t\t\ttcp_push_pending_frames(sk);\n\t\t}\n\t\tbreak;\n\n\tcase TCP_KEEPIDLE:\n\t\tif (val < 1 || val > MAX_TCP_KEEPIDLE)\n\t\t\terr = -EINVAL;\n\t\telse {\n\t\t\ttp->keepalive_time = val * HZ;\n\t\t\tif (sock_flag(sk, SOCK_KEEPOPEN) &&\n\t\t\t    !((1 << sk->sk_state) &\n\t\t\t      (TCPF_CLOSE | TCPF_LISTEN))) {\n\t\t\t\tu32 elapsed = keepalive_time_elapsed(tp);\n\t\t\t\tif (tp->keepalive_time > elapsed)\n\t\t\t\t\telapsed = tp->keepalive_time - elapsed;\n\t\t\t\telse\n\t\t\t\t\telapsed = 0;\n\t\t\t\tinet_csk_reset_keepalive_timer(sk, elapsed);\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase TCP_KEEPINTVL:\n\t\tif (val < 1 || val > MAX_TCP_KEEPINTVL)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->keepalive_intvl = val * HZ;\n\t\tbreak;\n\tcase TCP_KEEPCNT:\n\t\tif (val < 1 || val > MAX_TCP_KEEPCNT)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ttp->keepalive_probes = val;\n\t\tbreak;\n\tcase TCP_SYNCNT:\n\t\tif (val < 1 || val > MAX_TCP_SYNCNT)\n\t\t\terr = -EINVAL;\n\t\telse\n\t\t\ticsk->icsk_syn_retries = val;\n\t\tbreak;\n\n\tcase TCP_LINGER2:\n\t\tif (val < 0)\n\t\t\ttp->linger2 = -1;\n\t\telse if (val > sysctl_tcp_fin_timeout / HZ)\n\t\t\ttp->linger2 = 0;\n\t\telse\n\t\t\ttp->linger2 = val * HZ;\n\t\tbreak;\n\n\tcase TCP_DEFER_ACCEPT:\n\t\t/* Translate value in seconds to number of retransmits */\n\t\ticsk->icsk_accept_queue.rskq_defer_accept =\n\t\t\tsecs_to_retrans(val, TCP_TIMEOUT_INIT / HZ,\n\t\t\t\t\tTCP_RTO_MAX / HZ);\n\t\tbreak;\n\n\tcase TCP_WINDOW_CLAMP:\n\t\tif (!val) {\n\t\t\tif (sk->sk_state != TCP_CLOSE) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttp->window_clamp = 0;\n\t\t} else\n\t\t\ttp->window_clamp = val < SOCK_MIN_RCVBUF / 2 ?\n\t\t\t\t\t\tSOCK_MIN_RCVBUF / 2 : val;\n\t\tbreak;\n\n\tcase TCP_QUICKACK:\n\t\tif (!val) {\n\t\t\ticsk->icsk_ack.pingpong = 1;\n\t\t} else {\n\t\t\ticsk->icsk_ack.pingpong = 0;\n\t\t\tif ((1 << sk->sk_state) &\n\t\t\t    (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT) &&\n\t\t\t    inet_csk_ack_scheduled(sk)) {\n\t\t\t\ticsk->icsk_ack.pending |= ICSK_ACK_PUSHED;\n\t\t\t\ttcp_cleanup_rbuf(sk, 1);\n\t\t\t\tif (!(val & 1))\n\t\t\t\t\ticsk->icsk_ack.pingpong = 1;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\n#ifdef CONFIG_TCP_MD5SIG\n\tcase TCP_MD5SIG:\n\t\t/* Read the IP->Key mappings from userspace */\n\t\terr = tp->af_specific->md5_parse(sk, optval, optlen);\n\t\tbreak;\n#endif\n\tcase TCP_USER_TIMEOUT:\n\t\t/* Cap the max timeout in ms TCP will retry/retrans\n\t\t * before giving up and aborting (ETIMEDOUT) a connection.\n\t\t */\n\t\ticsk->icsk_user_timeout = msecs_to_jiffies(val);\n\t\tbreak;\n\tdefault:\n\t\terr = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\n\trelease_sock(sk);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -129,7 +129,7 @@\n \t\t/* Values greater than interface MTU won't take effect. However\n \t\t * at the point when this call is done we typically don't yet\n \t\t * know which interface is going to be used */\n-\t\tif (val < 8 || val > MAX_TCP_WINDOW) {\n+\t\tif (val < 64 || val > MAX_TCP_WINDOW) {\n \t\t\terr = -EINVAL;\n \t\t\tbreak;\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (val < 8 || val > MAX_TCP_WINDOW) {"
            ],
            "added_lines": [
                "\t\tif (val < 64 || val > MAX_TCP_WINDOW) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1012",
        "func_name": "torvalds/linux/ldm_parse_vmdb",
        "description": "The ldm_parse_vmdb function in fs/partitions/ldm.c in the Linux kernel before 2.6.38-rc6-git6 does not validate the VBLK size value in the VMDB structure in an LDM partition table, which allows local users to cause a denial of service (divide-by-zero error and OOPS) via a crafted partition table.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=294f6cf48666825d23c9372ef37631232746e40d",
        "commit_title": "The kernel automatically evaluates partition tables of storage devices.",
        "commit_text": "The code for evaluating LDM partitions (in fs/partitions/ldm.c) contains a bug that causes a kernel oops on certain corrupted LDM partitions.  A kernel subsystem seems to crash, because, after the oops, the kernel no longer recognizes newly connected storage devices.  The patch changes ldm_parse_vmdb() to Validate the value of vblk_size.  Cc: Eugene Teo <eugeneteo@kernel.sg> Cc: Harvey Harrison <harvey.harrison@gmail.com> Cc: <stable@kernel.org> ",
        "func_before": "static bool ldm_parse_vmdb (const u8 *data, struct vmdb *vm)\n{\n\tBUG_ON (!data || !vm);\n\n\tif (MAGIC_VMDB != get_unaligned_be32(data)) {\n\t\tldm_crit (\"Cannot find the VMDB, database may be corrupt.\");\n\t\treturn false;\n\t}\n\n\tvm->ver_major = get_unaligned_be16(data + 0x12);\n\tvm->ver_minor = get_unaligned_be16(data + 0x14);\n\tif ((vm->ver_major != 4) || (vm->ver_minor != 10)) {\n\t\tldm_error (\"Expected VMDB version %d.%d, got %d.%d. \"\n\t\t\t\"Aborting.\", 4, 10, vm->ver_major, vm->ver_minor);\n\t\treturn false;\n\t}\n\n\tvm->vblk_size     = get_unaligned_be32(data + 0x08);\n\tvm->vblk_offset   = get_unaligned_be32(data + 0x0C);\n\tvm->last_vblk_seq = get_unaligned_be32(data + 0x04);\n\n\tldm_debug (\"Parsed VMDB successfully.\");\n\treturn true;\n}",
        "func": "static bool ldm_parse_vmdb (const u8 *data, struct vmdb *vm)\n{\n\tBUG_ON (!data || !vm);\n\n\tif (MAGIC_VMDB != get_unaligned_be32(data)) {\n\t\tldm_crit (\"Cannot find the VMDB, database may be corrupt.\");\n\t\treturn false;\n\t}\n\n\tvm->ver_major = get_unaligned_be16(data + 0x12);\n\tvm->ver_minor = get_unaligned_be16(data + 0x14);\n\tif ((vm->ver_major != 4) || (vm->ver_minor != 10)) {\n\t\tldm_error (\"Expected VMDB version %d.%d, got %d.%d. \"\n\t\t\t\"Aborting.\", 4, 10, vm->ver_major, vm->ver_minor);\n\t\treturn false;\n\t}\n\n\tvm->vblk_size     = get_unaligned_be32(data + 0x08);\n\tif (vm->vblk_size == 0) {\n\t\tldm_error (\"Illegal VBLK size\");\n\t\treturn false;\n\t}\n\n\tvm->vblk_offset   = get_unaligned_be32(data + 0x0C);\n\tvm->last_vblk_seq = get_unaligned_be32(data + 0x04);\n\n\tldm_debug (\"Parsed VMDB successfully.\");\n\treturn true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,6 +16,11 @@\n \t}\n \n \tvm->vblk_size     = get_unaligned_be32(data + 0x08);\n+\tif (vm->vblk_size == 0) {\n+\t\tldm_error (\"Illegal VBLK size\");\n+\t\treturn false;\n+\t}\n+\n \tvm->vblk_offset   = get_unaligned_be32(data + 0x0C);\n \tvm->last_vblk_seq = get_unaligned_be32(data + 0x04);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (vm->vblk_size == 0) {",
                "\t\tldm_error (\"Illegal VBLK size\");",
                "\t\treturn false;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10266",
        "func_name": "vadz/libtiff/TIFFReadEncodedStrip",
        "description": "LibTIFF 4.0.7 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted TIFF image, related to libtiff/tif_read.c:351:22.",
        "git_url": "https://github.com/vadz/libtiff/commit/438274f938e046d33cb0e1230b41da32ffe223e1",
        "commit_title": "* libtiff/tif_read.c, libtiff/tiffiop.h: fix uint32 overflow in",
        "commit_text": "TIFFReadEncodedStrip() that caused an integer division by zero. Reported by Agostino Sarubbo. Fixes http://bugzilla.maptools.org/show_bug.cgi?id=2596",
        "func_before": "tmsize_t\nTIFFReadEncodedStrip(TIFF* tif, uint32 strip, void* buf, tmsize_t size)\n{\n\tstatic const char module[] = \"TIFFReadEncodedStrip\";\n\tTIFFDirectory *td = &tif->tif_dir;\n\tuint32 rowsperstrip;\n\tuint32 stripsperplane;\n\tuint32 stripinplane;\n\tuint16 plane;\n\tuint32 rows;\n\ttmsize_t stripsize;\n\tif (!TIFFCheckRead(tif,0))\n\t\treturn((tmsize_t)(-1));\n\tif (strip>=td->td_nstrips)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata,module,\n\t\t    \"%lu: Strip out of range, max %lu\",(unsigned long)strip,\n\t\t    (unsigned long)td->td_nstrips);\n\t\treturn((tmsize_t)(-1));\n\t}\n\t/*\n\t * Calculate the strip size according to the number of\n\t * rows in the strip (check for truncated last strip on any\n\t * of the separations).\n\t */\n\trowsperstrip=td->td_rowsperstrip;\n\tif (rowsperstrip>td->td_imagelength)\n\t\trowsperstrip=td->td_imagelength;\n\tstripsperplane=((td->td_imagelength+rowsperstrip-1)/rowsperstrip);\n\tstripinplane=(strip%stripsperplane);\n\tplane=(uint16)(strip/stripsperplane);\n\trows=td->td_imagelength-stripinplane*rowsperstrip;\n\tif (rows>rowsperstrip)\n\t\trows=rowsperstrip;\n\tstripsize=TIFFVStripSize(tif,rows);\n\tif (stripsize==0)\n\t\treturn((tmsize_t)(-1));\n\n    /* shortcut to avoid an extra memcpy() */\n    if( td->td_compression == COMPRESSION_NONE &&\n        size!=(tmsize_t)(-1) && size >= stripsize &&\n        !isMapped(tif) &&\n        ((tif->tif_flags&TIFF_NOREADRAW)==0) )\n    {\n        if (TIFFReadRawStrip1(tif, strip, buf, stripsize, module) != stripsize)\n            return ((tmsize_t)(-1));\n\n        if (!isFillOrder(tif, td->td_fillorder) &&\n            (tif->tif_flags & TIFF_NOBITREV) == 0)\n            TIFFReverseBits(buf,stripsize);\n\n        (*tif->tif_postdecode)(tif,buf,stripsize);\n        return (stripsize);\n    }\n\n\tif ((size!=(tmsize_t)(-1))&&(size<stripsize))\n\t\tstripsize=size;\n\tif (!TIFFFillStrip(tif,strip))\n\t\treturn((tmsize_t)(-1));\n\tif ((*tif->tif_decodestrip)(tif,buf,stripsize,plane)<=0)\n\t\treturn((tmsize_t)(-1));\n\t(*tif->tif_postdecode)(tif,buf,stripsize);\n\treturn(stripsize);\n}",
        "func": "tmsize_t\nTIFFReadEncodedStrip(TIFF* tif, uint32 strip, void* buf, tmsize_t size)\n{\n\tstatic const char module[] = \"TIFFReadEncodedStrip\";\n\tTIFFDirectory *td = &tif->tif_dir;\n\tuint32 rowsperstrip;\n\tuint32 stripsperplane;\n\tuint32 stripinplane;\n\tuint16 plane;\n\tuint32 rows;\n\ttmsize_t stripsize;\n\tif (!TIFFCheckRead(tif,0))\n\t\treturn((tmsize_t)(-1));\n\tif (strip>=td->td_nstrips)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata,module,\n\t\t    \"%lu: Strip out of range, max %lu\",(unsigned long)strip,\n\t\t    (unsigned long)td->td_nstrips);\n\t\treturn((tmsize_t)(-1));\n\t}\n\t/*\n\t * Calculate the strip size according to the number of\n\t * rows in the strip (check for truncated last strip on any\n\t * of the separations).\n\t */\n\trowsperstrip=td->td_rowsperstrip;\n\tif (rowsperstrip>td->td_imagelength)\n\t\trowsperstrip=td->td_imagelength;\n\tstripsperplane= TIFFhowmany_32_maxuint_compat(td->td_imagelength, rowsperstrip);\n\tstripinplane=(strip%stripsperplane);\n\tplane=(uint16)(strip/stripsperplane);\n\trows=td->td_imagelength-stripinplane*rowsperstrip;\n\tif (rows>rowsperstrip)\n\t\trows=rowsperstrip;\n\tstripsize=TIFFVStripSize(tif,rows);\n\tif (stripsize==0)\n\t\treturn((tmsize_t)(-1));\n\n    /* shortcut to avoid an extra memcpy() */\n    if( td->td_compression == COMPRESSION_NONE &&\n        size!=(tmsize_t)(-1) && size >= stripsize &&\n        !isMapped(tif) &&\n        ((tif->tif_flags&TIFF_NOREADRAW)==0) )\n    {\n        if (TIFFReadRawStrip1(tif, strip, buf, stripsize, module) != stripsize)\n            return ((tmsize_t)(-1));\n\n        if (!isFillOrder(tif, td->td_fillorder) &&\n            (tif->tif_flags & TIFF_NOBITREV) == 0)\n            TIFFReverseBits(buf,stripsize);\n\n        (*tif->tif_postdecode)(tif,buf,stripsize);\n        return (stripsize);\n    }\n\n\tif ((size!=(tmsize_t)(-1))&&(size<stripsize))\n\t\tstripsize=size;\n\tif (!TIFFFillStrip(tif,strip))\n\t\treturn((tmsize_t)(-1));\n\tif ((*tif->tif_decodestrip)(tif,buf,stripsize,plane)<=0)\n\t\treturn((tmsize_t)(-1));\n\t(*tif->tif_postdecode)(tif,buf,stripsize);\n\treturn(stripsize);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,7 +26,7 @@\n \trowsperstrip=td->td_rowsperstrip;\n \tif (rowsperstrip>td->td_imagelength)\n \t\trowsperstrip=td->td_imagelength;\n-\tstripsperplane=((td->td_imagelength+rowsperstrip-1)/rowsperstrip);\n+\tstripsperplane= TIFFhowmany_32_maxuint_compat(td->td_imagelength, rowsperstrip);\n \tstripinplane=(strip%stripsperplane);\n \tplane=(uint16)(strip/stripsperplane);\n \trows=td->td_imagelength-stripinplane*rowsperstrip;",
        "diff_line_info": {
            "deleted_lines": [
                "\tstripsperplane=((td->td_imagelength+rowsperstrip-1)/rowsperstrip);"
            ],
            "added_lines": [
                "\tstripsperplane= TIFFhowmany_32_maxuint_compat(td->td_imagelength, rowsperstrip);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10267",
        "func_name": "vadz/libtiff/OJPEGPreDecode",
        "description": "LibTIFF 4.0.7 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted TIFF image, related to libtiff/tif_ojpeg.c:816:8.",
        "git_url": "https://github.com/vadz/libtiff/commit/43bc256d8ae44b92d2734a3c5bc73957a4d7c1ec",
        "commit_title": "* libtiff/tif_ojpeg.c: make OJPEGDecode() early exit in case of failure in",
        "commit_text": "OJPEGPreDecode(). This will avoid a divide by zero, and potential other issues. Reported by Agostino Sarubbo. Fixes http://bugzilla.maptools.org/show_bug.cgi?id=2611",
        "func_before": "static int\nOJPEGPreDecode(TIFF* tif, uint16 s)\n{\n\tOJPEGState* sp=(OJPEGState*)tif->tif_data;\n\tuint32 m;\n\tif (sp->subsamplingcorrect_done==0)\n\t\tOJPEGSubsamplingCorrect(tif);\n\tif (sp->readheader_done==0)\n\t{\n\t\tif (OJPEGReadHeaderInfo(tif)==0)\n\t\t\treturn(0);\n\t}\n\tif (sp->sos_end[s].log==0)\n\t{\n\t\tif (OJPEGReadSecondarySos(tif,s)==0)\n\t\t\treturn(0);\n\t}\n\tif isTiled(tif)\n\t\tm=tif->tif_curtile;\n\telse\n\t\tm=tif->tif_curstrip;\n\tif ((sp->writeheader_done!=0) && ((sp->write_cursample!=s) || (sp->write_curstrile>m)))\n\t{\n\t\tif (sp->libjpeg_session_active!=0)\n\t\t\tOJPEGLibjpegSessionAbort(tif);\n\t\tsp->writeheader_done=0;\n\t}\n\tif (sp->writeheader_done==0)\n\t{\n\t\tsp->plane_sample_offset=(uint8)s;\n\t\tsp->write_cursample=s;\n\t\tsp->write_curstrile=s*tif->tif_dir.td_stripsperimage;\n\t\tif ((sp->in_buffer_file_pos_log==0) ||\n\t\t    (sp->in_buffer_file_pos-sp->in_buffer_togo!=sp->sos_end[s].in_buffer_file_pos))\n\t\t{\n\t\t\tsp->in_buffer_source=sp->sos_end[s].in_buffer_source;\n\t\t\tsp->in_buffer_next_strile=sp->sos_end[s].in_buffer_next_strile;\n\t\t\tsp->in_buffer_file_pos=sp->sos_end[s].in_buffer_file_pos;\n\t\t\tsp->in_buffer_file_pos_log=0;\n\t\t\tsp->in_buffer_file_togo=sp->sos_end[s].in_buffer_file_togo;\n\t\t\tsp->in_buffer_togo=0;\n\t\t\tsp->in_buffer_cur=0;\n\t\t}\n\t\tif (OJPEGWriteHeaderInfo(tif)==0)\n\t\t\treturn(0);\n\t}\n\twhile (sp->write_curstrile<m)          \n\t{\n\t\tif (sp->libjpeg_jpeg_query_style==0)\n\t\t{\n\t\t\tif (OJPEGPreDecodeSkipRaw(tif)==0)\n\t\t\t\treturn(0);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (OJPEGPreDecodeSkipScanlines(tif)==0)\n\t\t\t\treturn(0);\n\t\t}\n\t\tsp->write_curstrile++;\n\t}\n\treturn(1);\n}",
        "func": "static int\nOJPEGPreDecode(TIFF* tif, uint16 s)\n{\n\tOJPEGState* sp=(OJPEGState*)tif->tif_data;\n\tuint32 m;\n\tif (sp->subsamplingcorrect_done==0)\n\t\tOJPEGSubsamplingCorrect(tif);\n\tif (sp->readheader_done==0)\n\t{\n\t\tif (OJPEGReadHeaderInfo(tif)==0)\n\t\t\treturn(0);\n\t}\n\tif (sp->sos_end[s].log==0)\n\t{\n\t\tif (OJPEGReadSecondarySos(tif,s)==0)\n\t\t\treturn(0);\n\t}\n\tif isTiled(tif)\n\t\tm=tif->tif_curtile;\n\telse\n\t\tm=tif->tif_curstrip;\n\tif ((sp->writeheader_done!=0) && ((sp->write_cursample!=s) || (sp->write_curstrile>m)))\n\t{\n\t\tif (sp->libjpeg_session_active!=0)\n\t\t\tOJPEGLibjpegSessionAbort(tif);\n\t\tsp->writeheader_done=0;\n\t}\n\tif (sp->writeheader_done==0)\n\t{\n\t\tsp->plane_sample_offset=(uint8)s;\n\t\tsp->write_cursample=s;\n\t\tsp->write_curstrile=s*tif->tif_dir.td_stripsperimage;\n\t\tif ((sp->in_buffer_file_pos_log==0) ||\n\t\t    (sp->in_buffer_file_pos-sp->in_buffer_togo!=sp->sos_end[s].in_buffer_file_pos))\n\t\t{\n\t\t\tsp->in_buffer_source=sp->sos_end[s].in_buffer_source;\n\t\t\tsp->in_buffer_next_strile=sp->sos_end[s].in_buffer_next_strile;\n\t\t\tsp->in_buffer_file_pos=sp->sos_end[s].in_buffer_file_pos;\n\t\t\tsp->in_buffer_file_pos_log=0;\n\t\t\tsp->in_buffer_file_togo=sp->sos_end[s].in_buffer_file_togo;\n\t\t\tsp->in_buffer_togo=0;\n\t\t\tsp->in_buffer_cur=0;\n\t\t}\n\t\tif (OJPEGWriteHeaderInfo(tif)==0)\n\t\t\treturn(0);\n\t}\n\twhile (sp->write_curstrile<m)          \n\t{\n\t\tif (sp->libjpeg_jpeg_query_style==0)\n\t\t{\n\t\t\tif (OJPEGPreDecodeSkipRaw(tif)==0)\n\t\t\t\treturn(0);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (OJPEGPreDecodeSkipScanlines(tif)==0)\n\t\t\t\treturn(0);\n\t\t}\n\t\tsp->write_curstrile++;\n\t}\n\tsp->decoder_ok = 1;\n\treturn(1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -58,5 +58,6 @@\n \t\t}\n \t\tsp->write_curstrile++;\n \t}\n+\tsp->decoder_ok = 1;\n \treturn(1);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tsp->decoder_ok = 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10267",
        "func_name": "vadz/libtiff/OJPEGDecode",
        "description": "LibTIFF 4.0.7 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted TIFF image, related to libtiff/tif_ojpeg.c:816:8.",
        "git_url": "https://github.com/vadz/libtiff/commit/43bc256d8ae44b92d2734a3c5bc73957a4d7c1ec",
        "commit_title": "* libtiff/tif_ojpeg.c: make OJPEGDecode() early exit in case of failure in",
        "commit_text": "OJPEGPreDecode(). This will avoid a divide by zero, and potential other issues. Reported by Agostino Sarubbo. Fixes http://bugzilla.maptools.org/show_bug.cgi?id=2611",
        "func_before": "static int\nOJPEGDecode(TIFF* tif, uint8* buf, tmsize_t cc, uint16 s)\n{\n\tOJPEGState* sp=(OJPEGState*)tif->tif_data;\n\t(void)s;\n\tif (sp->libjpeg_jpeg_query_style==0)\n\t{\n\t\tif (OJPEGDecodeRaw(tif,buf,cc)==0)\n\t\t\treturn(0);\n\t}\n\telse\n\t{\n\t\tif (OJPEGDecodeScanlines(tif,buf,cc)==0)\n\t\t\treturn(0);\n\t}\n\treturn(1);\n}",
        "func": "static int\nOJPEGDecode(TIFF* tif, uint8* buf, tmsize_t cc, uint16 s)\n{\n        static const char module[]=\"OJPEGDecode\";\n\tOJPEGState* sp=(OJPEGState*)tif->tif_data;\n\t(void)s;\n        if( !sp->decoder_ok )\n        {\n            TIFFErrorExt(tif->tif_clientdata,module,\"Cannot decode: decoder not correctly initialized\");\n            return 0;\n        }\n\tif (sp->libjpeg_jpeg_query_style==0)\n\t{\n\t\tif (OJPEGDecodeRaw(tif,buf,cc)==0)\n\t\t\treturn(0);\n\t}\n\telse\n\t{\n\t\tif (OJPEGDecodeScanlines(tif,buf,cc)==0)\n\t\t\treturn(0);\n\t}\n\treturn(1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,14 @@\n static int\n OJPEGDecode(TIFF* tif, uint8* buf, tmsize_t cc, uint16 s)\n {\n+        static const char module[]=\"OJPEGDecode\";\n \tOJPEGState* sp=(OJPEGState*)tif->tif_data;\n \t(void)s;\n+        if( !sp->decoder_ok )\n+        {\n+            TIFFErrorExt(tif->tif_clientdata,module,\"Cannot decode: decoder not correctly initialized\");\n+            return 0;\n+        }\n \tif (sp->libjpeg_jpeg_query_style==0)\n \t{\n \t\tif (OJPEGDecodeRaw(tif,buf,cc)==0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        static const char module[]=\"OJPEGDecode\";",
                "        if( !sp->decoder_ok )",
                "        {",
                "            TIFFErrorExt(tif->tif_clientdata,module,\"Cannot decode: decoder not correctly initialized\");",
                "            return 0;",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10219",
        "func_name": "ArtifexSoftware/ghostpdl/intersect",
        "description": "The intersect function in base/gxfill.c in Artifex Software, Inc. Ghostscript 9.20 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted file.",
        "git_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/4bef1a1d32e29b68855616020dbff574b9cda08f",
        "commit_title": "Bug 697453: Avoid divide by 0 in scan conversion code.",
        "commit_text": " Arithmetic overflow due to extreme values in the scan conversion code can cause a division by 0.  Avoid this with a simple extra check.    dx_old=cf814d81   endp->x_next=b0e859b9   alp->x_next=8069a73a  leads to dx_den = 0",
        "func_before": "static bool\nintersect(active_line *endp, active_line *alp, fixed y, fixed y1, fixed *p_y_new)\n{\n    fixed y_new, dy;\n    fixed dx_old = alp->x_current - endp->x_current;\n    fixed dx_den = dx_old + endp->x_next - alp->x_next;\n\n    if (dx_den <= dx_old)\n        return false; /* Intersection isn't possible. */\n    dy = y1 - y;\n    if_debug3('F', \"[F]cross: dy=%g, dx_old=%g, dx_new=%g\\n\",\n              fixed2float(dy), fixed2float(dx_old),\n              fixed2float(dx_den - dx_old));\n    /* Do the computation in single precision */\n    /* if the values are small enough. */\n    y_new =\n        ((dy | dx_old) < 1L << (size_of(fixed) * 4 - 1) ?\n         dy * dx_old / dx_den :\n         (INCR_EXPR(mq_cross), fixed_mult_quo(dy, dx_old, dx_den)))\n        + y;\n    /* The crossing value doesn't have to be */\n    /* very accurate, but it does have to be */\n    /* greater than y and less than y1. */\n    if_debug3('F', \"[F]cross y=%g, y_new=%g, y1=%g\\n\",\n              fixed2float(y), fixed2float(y_new),\n              fixed2float(y1));\n    if (y_new <= y) {\n        /*\n         * This isn't possible.  Recompute the intersection\n         * accurately.\n         */\n        fixed ys, xs0, xs1, ye, xe0, xe1, dy, dx0, dx1;\n\n        INCR(cross_slow);\n        if (endp->start.y < alp->start.y)\n            ys = alp->start.y,\n                xs0 = AL_X_AT_Y(endp, ys), xs1 = alp->start.x;\n        else\n            ys = endp->start.y,\n                xs0 = endp->start.x, xs1 = AL_X_AT_Y(alp, ys);\n        if (endp->end.y > alp->end.y)\n            ye = alp->end.y,\n                xe0 = AL_X_AT_Y(endp, ye), xe1 = alp->end.x;\n        else\n            ye = endp->end.y,\n                xe0 = endp->end.x, xe1 = AL_X_AT_Y(alp, ye);\n        dy = ye - ys;\n        dx0 = xe0 - xs0;\n        dx1 = xe1 - xs1;\n        /* We need xs0 + cross * dx0 == xs1 + cross * dx1. */\n        if (dx0 == dx1) {\n            /* The two lines are coincident.  Do nothing. */\n            y_new = y1;\n        } else {\n            double cross = (double)(xs0 - xs1) / (dx1 - dx0);\n\n            y_new = (fixed)(ys + cross * dy);\n            if (y_new <= y) {\n                /*\n                 * This can only happen through some kind of\n                 * numeric disaster, but we have to check.\n                 */\n                INCR(cross_low);\n                y_new = y + fixed_epsilon;\n            }\n        }\n    }\n    *p_y_new = y_new;\n    return true;\n}",
        "func": "static bool\nintersect(active_line *endp, active_line *alp, fixed y, fixed y1, fixed *p_y_new)\n{\n    fixed y_new, dy;\n    fixed dx_old = alp->x_current - endp->x_current;\n    fixed dx_den = dx_old + endp->x_next - alp->x_next;\n\n    if (dx_den <= dx_old || dx_den == 0)\n        return false; /* Intersection isn't possible. */\n    dy = y1 - y;\n    if_debug3('F', \"[F]cross: dy=%g, dx_old=%g, dx_new=%g\\n\",\n              fixed2float(dy), fixed2float(dx_old),\n              fixed2float(dx_den - dx_old));\n    /* Do the computation in single precision */\n    /* if the values are small enough. */\n    y_new =\n        (((ufixed)(dy | dx_old)) < (1L << (size_of(fixed) * 4 - 1)) ?\n         dy * dx_old / dx_den :\n         (INCR_EXPR(mq_cross), fixed_mult_quo(dy, dx_old, dx_den)))\n        + y;\n    /* The crossing value doesn't have to be */\n    /* very accurate, but it does have to be */\n    /* greater than y and less than y1. */\n    if_debug3('F', \"[F]cross y=%g, y_new=%g, y1=%g\\n\",\n              fixed2float(y), fixed2float(y_new),\n              fixed2float(y1));\n    if (y_new <= y) {\n        /*\n         * This isn't possible.  Recompute the intersection\n         * accurately.\n         */\n        fixed ys, xs0, xs1, ye, xe0, xe1, dy, dx0, dx1;\n\n        INCR(cross_slow);\n        if (endp->start.y < alp->start.y)\n            ys = alp->start.y,\n                xs0 = AL_X_AT_Y(endp, ys), xs1 = alp->start.x;\n        else\n            ys = endp->start.y,\n                xs0 = endp->start.x, xs1 = AL_X_AT_Y(alp, ys);\n        if (endp->end.y > alp->end.y)\n            ye = alp->end.y,\n                xe0 = AL_X_AT_Y(endp, ye), xe1 = alp->end.x;\n        else\n            ye = endp->end.y,\n                xe0 = endp->end.x, xe1 = AL_X_AT_Y(alp, ye);\n        dy = ye - ys;\n        dx0 = xe0 - xs0;\n        dx1 = xe1 - xs1;\n        /* We need xs0 + cross * dx0 == xs1 + cross * dx1. */\n        if (dx0 == dx1) {\n            /* The two lines are coincident.  Do nothing. */\n            y_new = y1;\n        } else {\n            double cross = (double)(xs0 - xs1) / (dx1 - dx0);\n\n            y_new = (fixed)(ys + cross * dy);\n            if (y_new <= y) {\n                /*\n                 * This can only happen through some kind of\n                 * numeric disaster, but we have to check.\n                 */\n                INCR(cross_low);\n                y_new = y + fixed_epsilon;\n            }\n        }\n    }\n    *p_y_new = y_new;\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n     fixed dx_old = alp->x_current - endp->x_current;\n     fixed dx_den = dx_old + endp->x_next - alp->x_next;\n \n-    if (dx_den <= dx_old)\n+    if (dx_den <= dx_old || dx_den == 0)\n         return false; /* Intersection isn't possible. */\n     dy = y1 - y;\n     if_debug3('F', \"[F]cross: dy=%g, dx_old=%g, dx_new=%g\\n\",\n@@ -14,7 +14,7 @@\n     /* Do the computation in single precision */\n     /* if the values are small enough. */\n     y_new =\n-        ((dy | dx_old) < 1L << (size_of(fixed) * 4 - 1) ?\n+        (((ufixed)(dy | dx_old)) < (1L << (size_of(fixed) * 4 - 1)) ?\n          dy * dx_old / dx_den :\n          (INCR_EXPR(mq_cross), fixed_mult_quo(dy, dx_old, dx_den)))\n         + y;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (dx_den <= dx_old)",
                "        ((dy | dx_old) < 1L << (size_of(fixed) * 4 - 1) ?"
            ],
            "added_lines": [
                "    if (dx_den <= dx_old || dx_den == 0)",
                "        (((ufixed)(dy | dx_old)) < (1L << (size_of(fixed) * 4 - 1)) ?"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7448",
        "func_name": "dropbox/lepton/set_quantization_table",
        "description": "The allocate_channel_framebuffer function in uncompressed_components.hh in Dropbox Lepton 1.2.1 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a malformed JPEG image.",
        "git_url": "https://github.com/dropbox/lepton/commit/7789d99ac156adfd7bbf66e7824bd3e948a74cf7",
        "commit_title": "check divide by zero, fixing #86",
        "commit_text": "",
        "func_before": "static void set_quantization_table(BlockType color, const unsigned short quantization_table[64]) {\n        for (int i = 0; i < 64; ++i) {\n            quantization_table_[(int)color][i] = quantization_table[zigzag[i]];\n        }\n        for (int pixel_row = 0; pixel_row < 8; ++pixel_row) {\n            for (int i = 0; i < 8; ++i) {\n                icos_idct_linear_8192_dequantized((int)color)[pixel_row * 8 + i] = icos_idct_linear_8192_scaled[pixel_row * 8 + i] * quantization_table_[(int)color][i];\n                icos_idct_edge_8192_dequantized_x((int)color)[pixel_row * 8 + i] = icos_base_8192_scaled[i * 8] * quantization_table_[(int)color][i * 8 + pixel_row];\n                icos_idct_edge_8192_dequantized_y((int)color)[pixel_row * 8 + i] = icos_base_8192_scaled[i * 8] * quantization_table_[(int)color][pixel_row * 8 + i];\n            }\n        }\n        static const unsigned short int freqmax[] =\n        {\n            1024, 931, 985, 968, 1020, 968, 1020, 1020,\n            932, 858, 884, 840, 932, 838, 854, 854,\n            985, 884, 871, 875, 985, 878, 871, 854,\n            967, 841, 876, 844, 967, 886, 870, 837,\n            1020, 932, 985, 967, 1020, 969, 1020, 1020,\n            969, 838, 878, 886, 969, 838, 969, 838,\n            1020, 854, 871, 870, 1010, 969, 1020, 1020,\n            1020, 854, 854, 838, 1020, 838, 1020, 838\n        };\n        for (int coord = 0; coord < 64; ++coord) {\n            freqmax_[(int)color][coord] = (freqmax[coord] + quantization_table_[(int)color][coord] - 1)\n                / quantization_table_[(int)color][coord];\n            uint8_t max_len = uint16bit_length(freqmax_[(int)color][coord]);\n            bitlen_freqmax_[(int)color][coord] = max_len;\n            if (max_len > (int)RESIDUAL_NOISE_FLOOR) {\n                min_noise_threshold_[(int)color][coord] = max_len - RESIDUAL_NOISE_FLOOR;\n            }\n        }\n    }",
        "func": "static void set_quantization_table(BlockType color, const unsigned short quantization_table[64]) {\n        for (int i = 0; i < 64; ++i) {\n            quantization_table_[(int)color][i] = quantization_table[zigzag[i]];\n        }\n        for (int pixel_row = 0; pixel_row < 8; ++pixel_row) {\n            for (int i = 0; i < 8; ++i) {\n                icos_idct_linear_8192_dequantized((int)color)[pixel_row * 8 + i] = icos_idct_linear_8192_scaled[pixel_row * 8 + i] * quantization_table_[(int)color][i];\n                icos_idct_edge_8192_dequantized_x((int)color)[pixel_row * 8 + i] = icos_base_8192_scaled[i * 8] * quantization_table_[(int)color][i * 8 + pixel_row];\n                icos_idct_edge_8192_dequantized_y((int)color)[pixel_row * 8 + i] = icos_base_8192_scaled[i * 8] * quantization_table_[(int)color][pixel_row * 8 + i];\n            }\n        }\n        static const unsigned short int freqmax[] =\n        {\n            1024, 931, 985, 968, 1020, 968, 1020, 1020,\n            932, 858, 884, 840, 932, 838, 854, 854,\n            985, 884, 871, 875, 985, 878, 871, 854,\n            967, 841, 876, 844, 967, 886, 870, 837,\n            1020, 932, 985, 967, 1020, 969, 1020, 1020,\n            969, 838, 878, 886, 969, 838, 969, 838,\n            1020, 854, 871, 870, 1010, 969, 1020, 1020,\n            1020, 854, 854, 838, 1020, 838, 1020, 838\n        };\n        for (int coord = 0; coord < 64; ++coord) {\n            freqmax_[(int)color][coord] = (freqmax[coord] + quantization_table_[(int)color][coord] - 1);\n            if (quantization_table_[(int)color][coord]) {\n                freqmax_[(int)color][coord] /= quantization_table_[(int)color][coord];\n            }\n            uint8_t max_len = uint16bit_length(freqmax_[(int)color][coord]);\n            bitlen_freqmax_[(int)color][coord] = max_len;\n            if (max_len > (int)RESIDUAL_NOISE_FLOOR) {\n                min_noise_threshold_[(int)color][coord] = max_len - RESIDUAL_NOISE_FLOOR;\n            }\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,8 +21,10 @@\n             1020, 854, 854, 838, 1020, 838, 1020, 838\n         };\n         for (int coord = 0; coord < 64; ++coord) {\n-            freqmax_[(int)color][coord] = (freqmax[coord] + quantization_table_[(int)color][coord] - 1)\n-                / quantization_table_[(int)color][coord];\n+            freqmax_[(int)color][coord] = (freqmax[coord] + quantization_table_[(int)color][coord] - 1);\n+            if (quantization_table_[(int)color][coord]) {\n+                freqmax_[(int)color][coord] /= quantization_table_[(int)color][coord];\n+            }\n             uint8_t max_len = uint16bit_length(freqmax_[(int)color][coord]);\n             bitlen_freqmax_[(int)color][coord] = max_len;\n             if (max_len > (int)RESIDUAL_NOISE_FLOOR) {",
        "diff_line_info": {
            "deleted_lines": [
                "            freqmax_[(int)color][coord] = (freqmax[coord] + quantization_table_[(int)color][coord] - 1)",
                "                / quantization_table_[(int)color][coord];"
            ],
            "added_lines": [
                "            freqmax_[(int)color][coord] = (freqmax[coord] + quantization_table_[(int)color][coord] - 1);",
                "            if (quantization_table_[(int)color][coord]) {",
                "                freqmax_[(int)color][coord] /= quantization_table_[(int)color][coord];",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7448",
        "func_name": "dropbox/lepton/allocate_channel_framebuffer",
        "description": "The allocate_channel_framebuffer function in uncompressed_components.hh in Dropbox Lepton 1.2.1 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a malformed JPEG image.",
        "git_url": "https://github.com/dropbox/lepton/commit/7789d99ac156adfd7bbf66e7824bd3e948a74cf7",
        "commit_title": "check divide by zero, fixing #86",
        "commit_text": "",
        "func_before": "void allocate_channel_framebuffer(int desired_cmp,\n                                      BlockBasedImageBase<force_memory_optimized> *framebuffer,\n                                      bool memory_optimized=force_memory_optimized) const {\n        uint64_t total_req_blocks = 0;\n        for (int cmp = 0; cmp < (int)header_.size() && cmp < cmpc_; cmp++) {\n            total_req_blocks += header_[cmp].info_.bcv * header_[cmp].info_.bch;\n        }\n        for (int cmp = 0; cmp < (int)header_.size() && cmp < cmpc_; cmp++) {\n            int bc_allocated = header_[cmp].info_.bc;\n            int64_t max_cmp_bc = max_number_of_blocks;\n            max_cmp_bc *= header_[cmp].info_.bcv;\n            max_cmp_bc *= header_[cmp].info_.bch;\n            max_cmp_bc /= total_req_blocks;\n            if (bc_allocated > max_cmp_bc) {\n                bc_allocated = max_cmp_bc - (max_cmp_bc % header_[cmp].info_.bch);\n            }\n            if (cmp == desired_cmp) {\n                framebuffer->init(header_[cmp].info_.bch,\n                                  header_[cmp].info_.bcv,\n                                  bc_allocated,\n                                  memory_optimized);\n                break;\n            }\n        }\n    }",
        "func": "void allocate_channel_framebuffer(int desired_cmp,\n                                      BlockBasedImageBase<force_memory_optimized> *framebuffer,\n                                      bool memory_optimized=force_memory_optimized) const {\n        uint64_t total_req_blocks = 0;\n        for (int cmp = 0; cmp < (int)header_.size() && cmp < cmpc_; cmp++) {\n            total_req_blocks += header_[cmp].info_.bcv * header_[cmp].info_.bch;\n        }\n        for (int cmp = 0; cmp < (int)header_.size() && cmp < cmpc_; cmp++) {\n            int bc_allocated = header_[cmp].info_.bc;\n            int64_t max_cmp_bc = max_number_of_blocks;\n            max_cmp_bc *= header_[cmp].info_.bcv;\n            max_cmp_bc *= header_[cmp].info_.bch;\n            if (total_req_blocks) {\n                max_cmp_bc /= total_req_blocks;\n            }\n            if (bc_allocated > max_cmp_bc) {\n                int rem = 0;\n                if (header_[cmp].info_.bch) {\n                    rem = (max_cmp_bc % header_[cmp].info_.bch);\n                }\n                bc_allocated = max_cmp_bc - rem;\n            }\n            if (cmp == desired_cmp) {\n                framebuffer->init(header_[cmp].info_.bch,\n                                  header_[cmp].info_.bcv,\n                                  bc_allocated,\n                                  memory_optimized);\n                break;\n            }\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,9 +10,15 @@\n             int64_t max_cmp_bc = max_number_of_blocks;\n             max_cmp_bc *= header_[cmp].info_.bcv;\n             max_cmp_bc *= header_[cmp].info_.bch;\n-            max_cmp_bc /= total_req_blocks;\n+            if (total_req_blocks) {\n+                max_cmp_bc /= total_req_blocks;\n+            }\n             if (bc_allocated > max_cmp_bc) {\n-                bc_allocated = max_cmp_bc - (max_cmp_bc % header_[cmp].info_.bch);\n+                int rem = 0;\n+                if (header_[cmp].info_.bch) {\n+                    rem = (max_cmp_bc % header_[cmp].info_.bch);\n+                }\n+                bc_allocated = max_cmp_bc - rem;\n             }\n             if (cmp == desired_cmp) {\n                 framebuffer->init(header_[cmp].info_.bch,",
        "diff_line_info": {
            "deleted_lines": [
                "            max_cmp_bc /= total_req_blocks;",
                "                bc_allocated = max_cmp_bc - (max_cmp_bc % header_[cmp].info_.bch);"
            ],
            "added_lines": [
                "            if (total_req_blocks) {",
                "                max_cmp_bc /= total_req_blocks;",
                "            }",
                "                int rem = 0;",
                "                if (header_[cmp].info_.bch) {",
                "                    rem = (max_cmp_bc % header_[cmp].info_.bch);",
                "                }",
                "                bc_allocated = max_cmp_bc - rem;"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-7962",
        "func_name": "jsummers/imageworsener/iwgif_read_image",
        "description": "The iwgif_read_image function in imagew-gif.c in libimageworsener.a in ImageWorsener 1.3.0 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted file.",
        "git_url": "https://github.com/jsummers/imageworsener/commit/ca3356eb49fee03e2eaf6b6aff826988c1122d93",
        "commit_title": "Fixed a GIF decoding bug (divide by zero)",
        "commit_text": " Fixes issue #15",
        "func_before": "static int iwgif_read_image(struct iwgifrcontext *rctx)\n{\n\tint retval=0;\n\tstruct lzwdeccontext d;\n\tsize_t subblocksize;\n\tint has_local_ct;\n\tint local_ct_size;\n\n\tunsigned int root_codesize;\n\n\t// Read image header information\n\tif(!iwgif_read(rctx,rctx->rbuf,9)) goto done;\n\n\trctx->image_left = (int)iw_get_ui16le(&rctx->rbuf[0]);\n\trctx->image_top = (int)iw_get_ui16le(&rctx->rbuf[2]);\n\t// image_left and _top may be updated in iwgif_init_screen().\n\n\trctx->image_width = (int)iw_get_ui16le(&rctx->rbuf[4]);\n\trctx->image_height = (int)iw_get_ui16le(&rctx->rbuf[6]);\n\n\trctx->interlaced = (int)((rctx->rbuf[8]>>6)&0x01);\n\n\thas_local_ct = (int)((rctx->rbuf[8]>>7)&0x01);\n\tif(has_local_ct) {\n\t\tlocal_ct_size = (int)(rctx->rbuf[8]&0x07);\n\t\trctx->colortable.num_entries = 1<<(1+local_ct_size);\n\t}\n\n\tif(has_local_ct) {\n\t\t// We only support one image, so we don't need to keep both a global and a\n\t\t// local color table. If an image has both, the local table will overwrite\n\t\t// the global one.\n\t\tif(!iwgif_read_color_table(rctx,&rctx->colortable)) goto done;\n\t}\n\n\t// Make the transparent color transparent.\n\tif(rctx->has_transparency) {\n\t    rctx->colortable.entry[rctx->trans_color_index].a = 0;\n\t}\n\n\t// Read LZW code size\n\tif(!iwgif_read(rctx,rctx->rbuf,1)) goto done;\n\troot_codesize = (unsigned int)rctx->rbuf[0];\n\n\t// The spec does not allow the \"minimum code size\" to be less than 2.\n\t// Sizes >=12 are impossible to support.\n\t// There's no reason for the size to be larger than 8, but the spec\n\t// does not seem to forbid it.\n\tif(root_codesize<2 || root_codesize>11) {\n\t\tiw_set_error(rctx->ctx,\"Invalid LZW minimum code size\");\n\t\tgoto done;\n\t}\n\n\t// The creation of the global \"screen\" was deferred until now, to wait until\n\t// we know whether the image has transparency.\n\t// (And if !rctx->include_screen, to wait until we know the size of the image.)\n\tif(!iwgif_init_screen(rctx)) goto done;\n\n\trctx->total_npixels = (size_t)rctx->image_width * (size_t)rctx->image_height;\n\n\tif(!iwgif_make_row_pointers(rctx)) goto done;\n\n\tlzw_init(&d,root_codesize);\n\tlzw_clear(&d);\n\n\twhile(1) {\n\t\t// Read size of next subblock\n\t\tif(!iwgif_read(rctx,rctx->rbuf,1)) goto done;\n\t\tsubblocksize = (size_t)rctx->rbuf[0];\n\t\tif(subblocksize==0) break;\n\n\t\t// Read next subblock\n\t\tif(!iwgif_read(rctx,rctx->rbuf,subblocksize)) goto done;\n\t\tif(!lzw_process_bytes(rctx,&d,rctx->rbuf,subblocksize)) goto done;\n\n\t\tif(d.eoi_flag) break;\n\n\t\t// Stop if we reached the end of the image. We don't care if we've read an\n\t\t// EOI code or not.\n\t\tif(rctx->pixels_set >= rctx->total_npixels) break;\n\t}\n\n\tretval=1;\n\ndone:\n\treturn retval;\n}",
        "func": "static int iwgif_read_image(struct iwgifrcontext *rctx)\n{\n\tint retval=0;\n\tstruct lzwdeccontext d;\n\tsize_t subblocksize;\n\tint has_local_ct;\n\tint local_ct_size;\n\n\tunsigned int root_codesize;\n\n\t// Read image header information\n\tif(!iwgif_read(rctx,rctx->rbuf,9)) goto done;\n\n\trctx->image_left = (int)iw_get_ui16le(&rctx->rbuf[0]);\n\trctx->image_top = (int)iw_get_ui16le(&rctx->rbuf[2]);\n\t// image_left and _top may be updated in iwgif_init_screen().\n\n\trctx->image_width = (int)iw_get_ui16le(&rctx->rbuf[4]);\n\trctx->image_height = (int)iw_get_ui16le(&rctx->rbuf[6]);\n\tif(rctx->image_width<1 || rctx->image_height<1) {\n\t\tiw_set_error(rctx->ctx, \"Invalid image dimensions\");\n\t\tgoto done;\n\t}\n\n\trctx->interlaced = (int)((rctx->rbuf[8]>>6)&0x01);\n\n\thas_local_ct = (int)((rctx->rbuf[8]>>7)&0x01);\n\tif(has_local_ct) {\n\t\tlocal_ct_size = (int)(rctx->rbuf[8]&0x07);\n\t\trctx->colortable.num_entries = 1<<(1+local_ct_size);\n\t}\n\n\tif(has_local_ct) {\n\t\t// We only support one image, so we don't need to keep both a global and a\n\t\t// local color table. If an image has both, the local table will overwrite\n\t\t// the global one.\n\t\tif(!iwgif_read_color_table(rctx,&rctx->colortable)) goto done;\n\t}\n\n\t// Make the transparent color transparent.\n\tif(rctx->has_transparency) {\n\t    rctx->colortable.entry[rctx->trans_color_index].a = 0;\n\t}\n\n\t// Read LZW code size\n\tif(!iwgif_read(rctx,rctx->rbuf,1)) goto done;\n\troot_codesize = (unsigned int)rctx->rbuf[0];\n\n\t// The spec does not allow the \"minimum code size\" to be less than 2.\n\t// Sizes >=12 are impossible to support.\n\t// There's no reason for the size to be larger than 8, but the spec\n\t// does not seem to forbid it.\n\tif(root_codesize<2 || root_codesize>11) {\n\t\tiw_set_error(rctx->ctx,\"Invalid LZW minimum code size\");\n\t\tgoto done;\n\t}\n\n\t// The creation of the global \"screen\" was deferred until now, to wait until\n\t// we know whether the image has transparency.\n\t// (And if !rctx->include_screen, to wait until we know the size of the image.)\n\tif(!iwgif_init_screen(rctx)) goto done;\n\n\trctx->total_npixels = (size_t)rctx->image_width * (size_t)rctx->image_height;\n\n\tif(!iwgif_make_row_pointers(rctx)) goto done;\n\n\tlzw_init(&d,root_codesize);\n\tlzw_clear(&d);\n\n\twhile(1) {\n\t\t// Read size of next subblock\n\t\tif(!iwgif_read(rctx,rctx->rbuf,1)) goto done;\n\t\tsubblocksize = (size_t)rctx->rbuf[0];\n\t\tif(subblocksize==0) break;\n\n\t\t// Read next subblock\n\t\tif(!iwgif_read(rctx,rctx->rbuf,subblocksize)) goto done;\n\t\tif(!lzw_process_bytes(rctx,&d,rctx->rbuf,subblocksize)) goto done;\n\n\t\tif(d.eoi_flag) break;\n\n\t\t// Stop if we reached the end of the image. We don't care if we've read an\n\t\t// EOI code or not.\n\t\tif(rctx->pixels_set >= rctx->total_npixels) break;\n\t}\n\n\tretval=1;\n\ndone:\n\treturn retval;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,10 @@\n \n \trctx->image_width = (int)iw_get_ui16le(&rctx->rbuf[4]);\n \trctx->image_height = (int)iw_get_ui16le(&rctx->rbuf[6]);\n+\tif(rctx->image_width<1 || rctx->image_height<1) {\n+\t\tiw_set_error(rctx->ctx, \"Invalid image dimensions\");\n+\t\tgoto done;\n+\t}\n \n \trctx->interlaced = (int)((rctx->rbuf[8]>>6)&0x01);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif(rctx->image_width<1 || rctx->image_height<1) {",
                "\t\tiw_set_error(rctx->ctx, \"Invalid image dimensions\");",
                "\t\tgoto done;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7530",
        "func_name": "ImageMagick/SetQuantumDepth",
        "description": "The quantum handling code in ImageMagick allows remote attackers to cause a denial of service (divide-by-zero error or out-of-bounds write) via a crafted file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/b5ed738f8060266bf4ae521f7e3ed145aa4498a3",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/110",
        "commit_text": "",
        "func_before": "MagickExport MagickBooleanType SetQuantumDepth(const Image *image,\n  QuantumInfo *quantum_info,const size_t depth)\n{\n  size_t\n    extent,\n    quantum;\n\n  /*\n    Allocate the quantum pixel buffer.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(quantum_info != (QuantumInfo *) NULL);\n  assert(quantum_info->signature == MagickSignature);\n  quantum_info->depth=depth;\n  if (quantum_info->format == FloatingPointQuantumFormat)\n    {\n      if (quantum_info->depth > 32)\n        quantum_info->depth=64;\n      else\n        if (quantum_info->depth > 16)\n          quantum_info->depth=32;\n        else\n          quantum_info->depth=16;\n    }\n  if (quantum_info->pixels != (unsigned char **) NULL)\n    DestroyQuantumPixels(quantum_info);\n  quantum=(quantum_info->pad+6)*(quantum_info->depth+7)/8;\n  extent=image->columns*quantum;\n  if (quantum != (extent/image->columns))\n    return(MagickFalse);\n  return(AcquireQuantumPixels(quantum_info,extent));\n}",
        "func": "MagickExport MagickBooleanType SetQuantumDepth(const Image *image,\n  QuantumInfo *quantum_info,const size_t depth)\n{\n  size_t\n    extent,\n    quantum;\n\n  /*\n    Allocate the quantum pixel buffer.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(quantum_info != (QuantumInfo *) NULL);\n  assert(quantum_info->signature == MagickSignature);\n  quantum_info->depth=depth;\n  if (quantum_info->format == FloatingPointQuantumFormat)\n    {\n      if (quantum_info->depth > 32)\n        quantum_info->depth=64;\n      else\n        if (quantum_info->depth > 16)\n          quantum_info->depth=32;\n        else\n          quantum_info->depth=16;\n    }\n  if (quantum_info->pixels != (unsigned char **) NULL)\n    DestroyQuantumPixels(quantum_info);\n  quantum=(quantum_info->pad+6)*(quantum_info->depth+7)/8;\n  extent=image->columns*quantum;\n  if ((image->columns != 0) && (quantum != (extent/image->columns)))\n    return(MagickFalse);\n  return(AcquireQuantumPixels(quantum_info,extent));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,7 +29,7 @@\n     DestroyQuantumPixels(quantum_info);\n   quantum=(quantum_info->pad+6)*(quantum_info->depth+7)/8;\n   extent=image->columns*quantum;\n-  if (quantum != (extent/image->columns))\n+  if ((image->columns != 0) && (quantum != (extent/image->columns)))\n     return(MagickFalse);\n   return(AcquireQuantumPixels(quantum_info,extent));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (quantum != (extent/image->columns))"
            ],
            "added_lines": [
                "  if ((image->columns != 0) && (quantum != (extent/image->columns)))"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7530",
        "func_name": "ImageMagick/SetQuantumDepth",
        "description": "The quantum handling code in ImageMagick allows remote attackers to cause a denial of service (divide-by-zero error or out-of-bounds write) via a crafted file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/c4e63ad30bc42da691f2b5f82a24516dd6b4dc70",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/105",
        "commit_text": "",
        "func_before": "MagickExport MagickBooleanType SetQuantumDepth(const Image *image,\n  QuantumInfo *quantum_info,const size_t depth)\n{\n  size_t\n    extent,\n    quantum;\n\n  /*\n    Allocate the quantum pixel buffer.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(quantum_info != (QuantumInfo *) NULL);\n  assert(quantum_info->signature == MagickCoreSignature);\n  quantum_info->depth=depth;\n  if (quantum_info->format == FloatingPointQuantumFormat)\n    {\n      if (quantum_info->depth > 32)\n        quantum_info->depth=64;\n      else\n        if (quantum_info->depth > 16)\n          quantum_info->depth=32;\n        else\n          quantum_info->depth=16;\n    }\n  if (quantum_info->pixels != (unsigned char **) NULL)\n    DestroyQuantumPixels(quantum_info);\n  quantum=(quantum_info->pad+6)*(quantum_info->depth+7)/8;\n  extent=image->columns*quantum;\n  if ((image->columns != 0) && (quantum != (extent/image->columns)))\n    return(MagickFalse);\n  return(AcquireQuantumPixels(quantum_info,extent));\n}",
        "func": "MagickExport MagickBooleanType SetQuantumDepth(const Image *image,\n  QuantumInfo *quantum_info,const size_t depth)\n{\n  size_t\n    extent,\n    quantum;\n\n  /*\n    Allocate the quantum pixel buffer.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(quantum_info != (QuantumInfo *) NULL);\n  assert(quantum_info->signature == MagickCoreSignature);\n  quantum_info->depth=depth;\n  if (quantum_info->format == FloatingPointQuantumFormat)\n    {\n      if (quantum_info->depth > 32)\n        quantum_info->depth=64;\n      else\n        if (quantum_info->depth > 16)\n          quantum_info->depth=32;\n        else\n          quantum_info->depth=16;\n    }\n  if (quantum_info->pixels != (unsigned char **) NULL)\n    DestroyQuantumPixels(quantum_info);\n  quantum=(quantum_info->pad+6)*(quantum_info->depth+7)/8;\n  extent=MagickMax(image->columns,image->rows)*quantum;\n  if ((MagickMax(image->columns,image->rows) != 0) &&\n      (quantum != (extent/MagickMax(image->columns,image->rows))))\n    return(MagickFalse);\n  return(AcquireQuantumPixels(quantum_info,extent));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,8 +28,9 @@\n   if (quantum_info->pixels != (unsigned char **) NULL)\n     DestroyQuantumPixels(quantum_info);\n   quantum=(quantum_info->pad+6)*(quantum_info->depth+7)/8;\n-  extent=image->columns*quantum;\n-  if ((image->columns != 0) && (quantum != (extent/image->columns)))\n+  extent=MagickMax(image->columns,image->rows)*quantum;\n+  if ((MagickMax(image->columns,image->rows) != 0) &&\n+      (quantum != (extent/MagickMax(image->columns,image->rows))))\n     return(MagickFalse);\n   return(AcquireQuantumPixels(quantum_info,extent));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  extent=image->columns*quantum;",
                "  if ((image->columns != 0) && (quantum != (extent/image->columns)))"
            ],
            "added_lines": [
                "  extent=MagickMax(image->columns,image->rows)*quantum;",
                "  if ((MagickMax(image->columns,image->rows) != 0) &&",
                "      (quantum != (extent/MagickMax(image->columns,image->rows))))"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7530",
        "func_name": "ImageMagick/GetQuantumExtent",
        "description": "The quantum handling code in ImageMagick allows remote attackers to cause a denial of service (divide-by-zero error or out-of-bounds write) via a crafted file.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/c4e63ad30bc42da691f2b5f82a24516dd6b4dc70",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/105",
        "commit_text": "",
        "func_before": "MagickExport size_t GetQuantumExtent(const Image *image,\n  const QuantumInfo *quantum_info,const QuantumType quantum_type)\n{\n  size_t\n    packet_size;\n\n  assert(quantum_info != (QuantumInfo *) NULL);\n  assert(quantum_info->signature == MagickCoreSignature);\n  packet_size=1;\n  switch (quantum_type)\n  {\n    case GrayAlphaQuantum: packet_size=2; break;\n    case IndexAlphaQuantum: packet_size=2; break;\n    case RGBQuantum: packet_size=3; break;\n    case BGRQuantum: packet_size=3; break;\n    case RGBAQuantum: packet_size=4; break;\n    case RGBOQuantum: packet_size=4; break;\n    case BGRAQuantum: packet_size=4; break;\n    case CMYKQuantum: packet_size=4; break;\n    case CMYKAQuantum: packet_size=5; break;\n    default: break;\n  }\n  if (quantum_info->pack == MagickFalse)\n    return((size_t) (packet_size*image->columns*((quantum_info->depth+7)/8)));\n  return((size_t) ((packet_size*image->columns*quantum_info->depth+7)/8));\n}",
        "func": "MagickExport size_t GetQuantumExtent(const Image *image,\n  const QuantumInfo *quantum_info,const QuantumType quantum_type)\n{\n  size_t\n    extent,\n    packet_size;\n\n  assert(quantum_info != (QuantumInfo *) NULL);\n  assert(quantum_info->signature == MagickCoreSignature);\n  packet_size=1;\n  switch (quantum_type)\n  {\n    case GrayAlphaQuantum: packet_size=2; break;\n    case IndexAlphaQuantum: packet_size=2; break;\n    case RGBQuantum: packet_size=3; break;\n    case BGRQuantum: packet_size=3; break;\n    case RGBAQuantum: packet_size=4; break;\n    case RGBOQuantum: packet_size=4; break;\n    case BGRAQuantum: packet_size=4; break;\n    case CMYKQuantum: packet_size=4; break;\n    case CMYKAQuantum: packet_size=5; break;\n    default: break;\n  }\n  extent=MagickMax(image->columns,image->rows);\n  if (quantum_info->pack == MagickFalse)\n    return((size_t) (packet_size*extent*((quantum_info->depth+7)/8)));\n  return((size_t) ((packet_size*extent*quantum_info->depth+7)/8));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n   const QuantumInfo *quantum_info,const QuantumType quantum_type)\n {\n   size_t\n+    extent,\n     packet_size;\n \n   assert(quantum_info != (QuantumInfo *) NULL);\n@@ -20,7 +21,8 @@\n     case CMYKAQuantum: packet_size=5; break;\n     default: break;\n   }\n+  extent=MagickMax(image->columns,image->rows);\n   if (quantum_info->pack == MagickFalse)\n-    return((size_t) (packet_size*image->columns*((quantum_info->depth+7)/8)));\n-  return((size_t) ((packet_size*image->columns*quantum_info->depth+7)/8));\n+    return((size_t) (packet_size*extent*((quantum_info->depth+7)/8)));\n+  return((size_t) ((packet_size*extent*quantum_info->depth+7)/8));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return((size_t) (packet_size*image->columns*((quantum_info->depth+7)/8)));",
                "  return((size_t) ((packet_size*image->columns*quantum_info->depth+7)/8));"
            ],
            "added_lines": [
                "    extent,",
                "  extent=MagickMax(image->columns,image->rows);",
                "    return((size_t) (packet_size*extent*((quantum_info->depth+7)/8)));",
                "  return((size_t) ((packet_size*extent*quantum_info->depth+7)/8));"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-0603",
        "func_name": "android/NuMediaExtractor::getTotalBitrate",
        "description": "A denial of service vulnerability in libstagefright in Mediaserver could enable an attacker to use a specially crafted file to cause a device hang or reboot. This issue is rated as Moderate because it requires an uncommon device configuration. Product: Android. Versions: 4.4.4, 5.0.2, 5.1.1, 6.0, 6.0.1, 7.0, 7.1.1, 7.1.2. Android ID: A-35763994.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/36b04932bb93cc3269279282686b439a17a89920",
        "commit_title": "Fix integer overflow and divide-by-zero",
        "commit_text": " Bug: 35763994 Test: ran CTS with and without fix (cherry picked from commit 8538a603ef992e75f29336499cb783f3ec19f18c) ",
        "func_before": "bool NuMediaExtractor::getTotalBitrate(int64_t *bitrate) const {\n    if (mTotalBitrate >= 0) {\n        *bitrate = mTotalBitrate;\n        return true;\n    }\n\n    off64_t size;\n    if (mDurationUs >= 0 && mDataSource->getSize(&size) == OK) {\n        *bitrate = size * 8000000ll / mDurationUs;  // in bits/sec\n        return true;\n    }\n\n    return false;\n}",
        "func": "bool NuMediaExtractor::getTotalBitrate(int64_t *bitrate) const {\n    if (mTotalBitrate >= 0) {\n        *bitrate = mTotalBitrate;\n        return true;\n    }\n\n    off64_t size;\n    if (mDurationUs > 0 && mDataSource->getSize(&size) == OK) {\n        *bitrate = size * 8000000ll / mDurationUs;  // in bits/sec\n        return true;\n    }\n\n    return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n     }\n \n     off64_t size;\n-    if (mDurationUs >= 0 && mDataSource->getSize(&size) == OK) {\n+    if (mDurationUs > 0 && mDataSource->getSize(&size) == OK) {\n         *bitrate = size * 8000000ll / mDurationUs;  // in bits/sec\n         return true;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (mDurationUs >= 0 && mDataSource->getSize(&size) == OK) {"
            ],
            "added_lines": [
                "    if (mDurationUs > 0 && mDataSource->getSize(&size) == OK) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-0603",
        "func_name": "android/AMRSource::read",
        "description": "A denial of service vulnerability in libstagefright in Mediaserver could enable an attacker to use a specially crafted file to cause a device hang or reboot. This issue is rated as Moderate because it requires an uncommon device configuration. Product: Android. Versions: 4.4.4, 5.0.2, 5.1.1, 6.0, 6.0.1, 7.0, 7.1.1, 7.1.2. Android ID: A-35763994.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/36b04932bb93cc3269279282686b439a17a89920",
        "commit_title": "Fix integer overflow and divide-by-zero",
        "commit_text": " Bug: 35763994 Test: ran CTS with and without fix (cherry picked from commit 8538a603ef992e75f29336499cb783f3ec19f18c) ",
        "func_before": "status_t AMRSource::read(\n        MediaBuffer **out, const ReadOptions *options) {\n    *out = NULL;\n\n    int64_t seekTimeUs;\n    ReadOptions::SeekMode mode;\n    if (options && options->getSeekTo(&seekTimeUs, &mode)) {\n        size_t size;\n        int64_t seekFrame = seekTimeUs / 20000ll;  // 20ms per frame.\n        mCurrentTimeUs = seekFrame * 20000ll;\n\n        size_t index = seekFrame < 0 ? 0 : seekFrame / 50;\n        if (index >= mOffsetTableLength) {\n            index = mOffsetTableLength - 1;\n        }\n\n        mOffset = mOffsetTable[index] + (mIsWide ? 9 : 6);\n\n        for (size_t i = 0; i< seekFrame - index * 50; i++) {\n            status_t err;\n            if ((err = getFrameSizeByOffset(mDataSource, mOffset,\n                            mIsWide, &size)) != OK) {\n                return err;\n            }\n            mOffset += size;\n        }\n    }\n\n    uint8_t header;\n    ssize_t n = mDataSource->readAt(mOffset, &header, 1);\n\n    if (n < 1) {\n        return ERROR_END_OF_STREAM;\n    }\n\n    if (header & 0x83) {\n        // Padding bits must be 0.\n\n        ALOGE(\"padding bits must be 0, header is 0x%02x\", header);\n\n        return ERROR_MALFORMED;\n    }\n\n    unsigned FT = (header >> 3) & 0x0f;\n\n    size_t frameSize = getFrameSize(mIsWide, FT);\n    if (frameSize == 0) {\n        return ERROR_MALFORMED;\n    }\n\n    MediaBuffer *buffer;\n    status_t err = mGroup->acquire_buffer(&buffer);\n    if (err != OK) {\n        return err;\n    }\n\n    n = mDataSource->readAt(mOffset, buffer->data(), frameSize);\n\n    if (n != (ssize_t)frameSize) {\n        buffer->release();\n        buffer = NULL;\n\n        if (n < 0) {\n            return ERROR_IO;\n        } else {\n            // only partial frame is available, treat it as EOS.\n            mOffset += n;\n            return ERROR_END_OF_STREAM;\n        }\n    }\n\n    buffer->set_range(0, frameSize);\n    buffer->meta_data()->setInt64(kKeyTime, mCurrentTimeUs);\n    buffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);\n\n    mOffset += frameSize;\n    mCurrentTimeUs += 20000;  // Each frame is 20ms\n\n    *out = buffer;\n\n    return OK;\n}",
        "func": "status_t AMRSource::read(\n        MediaBuffer **out, const ReadOptions *options) {\n    *out = NULL;\n\n    int64_t seekTimeUs;\n    ReadOptions::SeekMode mode;\n    if (mOffsetTableLength > 0 && options && options->getSeekTo(&seekTimeUs, &mode)) {\n        size_t size;\n        int64_t seekFrame = seekTimeUs / 20000ll;  // 20ms per frame.\n        mCurrentTimeUs = seekFrame * 20000ll;\n\n        size_t index = seekFrame < 0 ? 0 : seekFrame / 50;\n        if (index >= mOffsetTableLength) {\n            index = mOffsetTableLength - 1;\n        }\n\n        mOffset = mOffsetTable[index] + (mIsWide ? 9 : 6);\n\n        for (size_t i = 0; i< seekFrame - index * 50; i++) {\n            status_t err;\n            if ((err = getFrameSizeByOffset(mDataSource, mOffset,\n                            mIsWide, &size)) != OK) {\n                return err;\n            }\n            mOffset += size;\n        }\n    }\n\n    uint8_t header;\n    ssize_t n = mDataSource->readAt(mOffset, &header, 1);\n\n    if (n < 1) {\n        return ERROR_END_OF_STREAM;\n    }\n\n    if (header & 0x83) {\n        // Padding bits must be 0.\n\n        ALOGE(\"padding bits must be 0, header is 0x%02x\", header);\n\n        return ERROR_MALFORMED;\n    }\n\n    unsigned FT = (header >> 3) & 0x0f;\n\n    size_t frameSize = getFrameSize(mIsWide, FT);\n    if (frameSize == 0) {\n        return ERROR_MALFORMED;\n    }\n\n    MediaBuffer *buffer;\n    status_t err = mGroup->acquire_buffer(&buffer);\n    if (err != OK) {\n        return err;\n    }\n\n    n = mDataSource->readAt(mOffset, buffer->data(), frameSize);\n\n    if (n != (ssize_t)frameSize) {\n        buffer->release();\n        buffer = NULL;\n\n        if (n < 0) {\n            return ERROR_IO;\n        } else {\n            // only partial frame is available, treat it as EOS.\n            mOffset += n;\n            return ERROR_END_OF_STREAM;\n        }\n    }\n\n    buffer->set_range(0, frameSize);\n    buffer->meta_data()->setInt64(kKeyTime, mCurrentTimeUs);\n    buffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);\n\n    mOffset += frameSize;\n    mCurrentTimeUs += 20000;  // Each frame is 20ms\n\n    *out = buffer;\n\n    return OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,7 @@\n \n     int64_t seekTimeUs;\n     ReadOptions::SeekMode mode;\n-    if (options && options->getSeekTo(&seekTimeUs, &mode)) {\n+    if (mOffsetTableLength > 0 && options && options->getSeekTo(&seekTimeUs, &mode)) {\n         size_t size;\n         int64_t seekFrame = seekTimeUs / 20000ll;  // 20ms per frame.\n         mCurrentTimeUs = seekFrame * 20000ll;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (options && options->getSeekTo(&seekTimeUs, &mode)) {"
            ],
            "added_lines": [
                "    if (mOffsetTableLength > 0 && options && options->getSeekTo(&seekTimeUs, &mode)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9201",
        "func_name": "jsummers/imageworsener/iw_get_input_density",
        "description": "imagew-cmd.c:850:46 in libimageworsener.a in ImageWorsener 1.3.1 allows remote attackers to cause a denial of service (divide-by-zero error) via a crafted image, related to imagew-api.c.",
        "git_url": "https://github.com/jsummers/imageworsener/commit/dc49c807926b96e503bd7c0dec35119eecd6c6fe",
        "commit_title": "Double-check that the input image's density is valid",
        "commit_text": " Fixes a bug that could result in division by zero, at least for a JPEG source image. Fixes issues #19, #20",
        "func_before": "IW_IMPL(int) iw_get_input_density(struct iw_context *ctx,\n   double *px, double *py, int *pcode)\n{\n\t*px = 1.0;\n\t*py = 1.0;\n\t*pcode = ctx->img1.density_code;\n\tif(ctx->img1.density_code!=IW_DENSITY_UNKNOWN) {\n\t\t*px = ctx->img1.density_x;\n\t\t*py = ctx->img1.density_y;\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "func": "IW_IMPL(int) iw_get_input_density(struct iw_context *ctx,\n   double *px, double *py, int *pcode)\n{\n\t*px = 1.0;\n\t*py = 1.0;\n\t*pcode = IW_DENSITY_UNKNOWN;\n\n\tif(ctx->img1.density_code==IW_DENSITY_UNKNOWN) {\n\t\treturn 0;\n\t}\n\tif(!iw_is_valid_density(ctx->img1.density_x, ctx->img1.density_y,\n\t\tctx->img1.density_code))\n\t{\n\t\treturn 0;\n\t}\n\t*px = ctx->img1.density_x;\n\t*py = ctx->img1.density_y;\n\t*pcode = ctx->img1.density_code;\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,11 +3,18 @@\n {\n \t*px = 1.0;\n \t*py = 1.0;\n+\t*pcode = IW_DENSITY_UNKNOWN;\n+\n+\tif(ctx->img1.density_code==IW_DENSITY_UNKNOWN) {\n+\t\treturn 0;\n+\t}\n+\tif(!iw_is_valid_density(ctx->img1.density_x, ctx->img1.density_y,\n+\t\tctx->img1.density_code))\n+\t{\n+\t\treturn 0;\n+\t}\n+\t*px = ctx->img1.density_x;\n+\t*py = ctx->img1.density_y;\n \t*pcode = ctx->img1.density_code;\n-\tif(ctx->img1.density_code!=IW_DENSITY_UNKNOWN) {\n-\t\t*px = ctx->img1.density_x;\n-\t\t*py = ctx->img1.density_y;\n-\t\treturn 1;\n-\t}\n-\treturn 0;\n+\treturn 1;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif(ctx->img1.density_code!=IW_DENSITY_UNKNOWN) {",
                "\t\t*px = ctx->img1.density_x;",
                "\t\t*py = ctx->img1.density_y;",
                "\t\treturn 1;",
                "\t}",
                "\treturn 0;"
            ],
            "added_lines": [
                "\t*pcode = IW_DENSITY_UNKNOWN;",
                "",
                "\tif(ctx->img1.density_code==IW_DENSITY_UNKNOWN) {",
                "\t\treturn 0;",
                "\t}",
                "\tif(!iw_is_valid_density(ctx->img1.density_x, ctx->img1.density_y,",
                "\t\tctx->img1.density_code))",
                "\t{",
                "\t\treturn 0;",
                "\t}",
                "\t*px = ctx->img1.density_x;",
                "\t*py = ctx->img1.density_y;",
                "\treturn 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9344",
        "func_name": "wireshark/dissect_connparamrequest",
        "description": "In Wireshark 2.2.0 to 2.2.6 and 2.0.0 to 2.0.12, the Bluetooth L2CAP dissector could divide by zero. This was addressed in epan/dissectors/packet-btl2cap.c by validating an interval value.",
        "git_url": "https://github.com/wireshark/wireshark/commit/6308ae03d82a29a2e3d75e1c325c8a9f6c44dcdf",
        "commit_title": "BT L2CAP: avoid a division by 0",
        "commit_text": " Bug: 13701 (cherry picked from commit d566531ae5874bfd63c2755cba95cd63b7a4a189)",
        "func_before": "static int\ndissect_connparamrequest(tvbuff_t *tvb, int offset, packet_info *pinfo, proto_tree *tree)\n{\n    proto_item *item;\n    guint16 max_interval, slave_latency;\n\n    item = proto_tree_add_item(tree, hf_btl2cap_min_interval, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" (%g msec)\",  tvb_get_letohs(tvb, offset) * 1.25);\n    offset += 2;\n    item = proto_tree_add_item(tree, hf_btl2cap_max_interval, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" (%g msec)\",  tvb_get_letohs(tvb, offset) * 1.25);\n    max_interval = tvb_get_letohs(tvb, offset);\n    offset += 2;\n    item = proto_tree_add_item(tree, hf_btl2cap_slave_latency, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" LL Connection Events\");\n    slave_latency = tvb_get_letohs(tvb, offset);\n\n    if(slave_latency >= 500 || slave_latency > 10.0 * tvb_get_letohs(tvb, offset + 2) / (max_interval *1.25))\n        expert_add_info(pinfo, item, &ei_btl2cap_parameter_mismatch);\n\n    offset += 2;\n    item = proto_tree_add_item(tree, hf_btl2cap_timeout_multiplier, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" (%g sec)\",  tvb_get_letohs(tvb, offset) * 0.01);\n    offset += 2;\n\n    return offset;\n}",
        "func": "static int\ndissect_connparamrequest(tvbuff_t *tvb, int offset, packet_info *pinfo, proto_tree *tree)\n{\n    proto_item *item;\n    guint16 max_interval, slave_latency;\n\n    item = proto_tree_add_item(tree, hf_btl2cap_min_interval, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" (%g msec)\",  tvb_get_letohs(tvb, offset) * 1.25);\n    offset += 2;\n    item = proto_tree_add_item(tree, hf_btl2cap_max_interval, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" (%g msec)\",  tvb_get_letohs(tvb, offset) * 1.25);\n    max_interval = tvb_get_letohs(tvb, offset);\n    offset += 2;\n    item = proto_tree_add_item(tree, hf_btl2cap_slave_latency, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" LL Connection Events\");\n    slave_latency = tvb_get_letohs(tvb, offset);\n\n    if(slave_latency >= 500 || max_interval == 0 ||\n       slave_latency > 10.0 * tvb_get_letohs(tvb, offset + 2) / (max_interval *1.25))\n        expert_add_info(pinfo, item, &ei_btl2cap_parameter_mismatch);\n\n    offset += 2;\n    item = proto_tree_add_item(tree, hf_btl2cap_timeout_multiplier, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    proto_item_append_text(item, \" (%g sec)\",  tvb_get_letohs(tvb, offset) * 0.01);\n    offset += 2;\n\n    return offset;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,8 @@\n     proto_item_append_text(item, \" LL Connection Events\");\n     slave_latency = tvb_get_letohs(tvb, offset);\n \n-    if(slave_latency >= 500 || slave_latency > 10.0 * tvb_get_letohs(tvb, offset + 2) / (max_interval *1.25))\n+    if(slave_latency >= 500 || max_interval == 0 ||\n+       slave_latency > 10.0 * tvb_get_letohs(tvb, offset + 2) / (max_interval *1.25))\n         expert_add_info(pinfo, item, &ei_btl2cap_parameter_mismatch);\n \n     offset += 2;",
        "diff_line_info": {
            "deleted_lines": [
                "    if(slave_latency >= 500 || slave_latency > 10.0 * tvb_get_letohs(tvb, offset + 2) / (max_interval *1.25))"
            ],
            "added_lines": [
                "    if(slave_latency >= 500 || max_interval == 0 ||",
                "       slave_latency > 10.0 * tvb_get_letohs(tvb, offset + 2) / (max_interval *1.25))"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-9344",
        "func_name": "wireshark/proto_register_btl2cap",
        "description": "In Wireshark 2.2.0 to 2.2.6 and 2.0.0 to 2.0.12, the Bluetooth L2CAP dissector could divide by zero. This was addressed in epan/dissectors/packet-btl2cap.c by validating an interval value.",
        "git_url": "https://github.com/wireshark/wireshark/commit/6308ae03d82a29a2e3d75e1c325c8a9f6c44dcdf",
        "commit_title": "BT L2CAP: avoid a division by 0",
        "commit_text": " Bug: 13701 (cherry picked from commit d566531ae5874bfd63c2755cba95cd63b7a4a189)",
        "func_before": "void\nproto_register_btl2cap(void)\n{\n    expert_module_t *expert_btl2cap;\n    /* Setup list of header fields  See Section 1.6.1 for details*/\n    static hf_register_info hf[] = {\n        { &hf_btl2cap_length,\n          { \"Length\",           \"btl2cap.length\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"L2CAP Payload Length\", HFILL }\n        },\n        { &hf_btl2cap_cid,\n          { \"CID\",           \"btl2cap.cid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"L2CAP Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_payload,\n          { \"Payload\",           \"btl2cap.payload\",\n            FT_BYTES, BASE_NONE, NULL, 0x0,\n            \"L2CAP Payload\", HFILL }\n        },\n        { &hf_btl2cap_command,\n          { \"Command\",           \"btl2cap.command\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            \"L2CAP Command\", HFILL }\n        },\n        { &hf_btl2cap_cmd_code,\n          { \"Command Code\",           \"btl2cap.cmd_code\",\n            FT_UINT8, BASE_HEX, VALS(command_code_vals), 0x0,\n            \"L2CAP Command Code\", HFILL }\n        },\n        { &hf_btl2cap_cmd_ident,\n          { \"Command Identifier\",           \"btl2cap.cmd_ident\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            \"L2CAP Command Identifier\", HFILL }\n        },\n        { &hf_btl2cap_cmd_length,\n          { \"Command Length\",           \"btl2cap.cmd_length\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"L2CAP Command Length\", HFILL }\n        },\n        { &hf_btl2cap_cmd_data,\n          { \"Command Data\",           \"btl2cap.cmd_data\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            \"L2CAP Command Data\", HFILL }\n        },\n        { &hf_btl2cap_psm,\n          { \"PSM\",           \"btl2cap.psm\",\n            FT_UINT16, BASE_HEX, VALS(psm_vals), 0x0,\n            \"Protocol/Service Multiplexer\", HFILL }\n        },\n        { &hf_btl2cap_psm_dynamic,\n          { \"Dynamic PSM\",           \"btl2cap.psm\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            \"Dynamic Protocol/Service Multiplexer\", HFILL }\n        },\n        { &hf_btl2cap_scid,\n          { \"Source CID\",           \"btl2cap.scid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"Source Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_dcid,\n          { \"Destination CID\",           \"btl2cap.dcid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"Destination Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_icid,\n          { \"Initiator CID\",           \"btl2cap.icid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"Initiator Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_controller,\n          { \"Controller ID\",           \"btl2cap.ctrl_id\",\n            FT_UINT8, BASE_DEC, VALS(ctrl_id_code_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_dcontroller,\n          { \"Controller ID\",           \"btl2cap.dctrl_id\",\n            FT_UINT8, BASE_DEC, VALS(ctrl_id_code_vals), 0x0,\n            \"Destination Controller ID\", HFILL }\n        },\n        { &hf_btl2cap_result,\n          { \"Result\",           \"btl2cap.result\",\n            FT_UINT16, BASE_HEX, VALS(result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_move_result,\n          { \"Move Result\",           \"btl2cap.move_result\",\n            FT_UINT16, BASE_HEX, VALS(move_result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_move_confirmation_result,\n          { \"Move Result\",           \"btl2cap.move_result\",\n            FT_UINT16, BASE_HEX, VALS(move_result_confirmation_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_status,\n          { \"Status\",           \"btl2cap.status\",\n            FT_UINT16, BASE_HEX, VALS(status_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_rej_reason,\n          { \"Reason\",           \"btl2cap.rej_reason\",\n            FT_UINT16, BASE_HEX, VALS(reason_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_sig_mtu,\n          { \"Maximum Signalling MTU\",           \"btl2cap.sig_mtu\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_mtu,\n          { \"Remote Entity MTU\",           \"btl2cap.info_mtu\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Remote entity acceptable connectionless MTU\", HFILL }\n        },\n        { &hf_btl2cap_info_flowcontrol,\n          { \"Flow Control Mode\",           \"btl2cap.info_flowcontrol\",\n            FT_UINT32, BASE_DEC, NULL, 0x01,\n            \"Flow Control mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_retransmission,\n          { \"Retransmission Mode\",         \"btl2cap.info_retransmission\",\n            FT_UINT32, BASE_DEC, NULL, 0x02,\n            \"Retransmission mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_bidirqos,\n          { \"Bi-Directional QOS\",          \"btl2cap.info_bidirqos\",\n            FT_UINT32, BASE_DEC, NULL, 0x04,\n            \"Bi-Directional QOS support\", HFILL }\n        },\n        { &hf_btl2cap_info_enh_retransmission,\n          { \"Enhanced Retransmission Mode\", \"btl2cap.info_enh_retransmission\",\n            FT_UINT32, BASE_DEC, NULL, 0x08,\n            \"Enhanced Retransmission mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_streaming,\n          { \"Streaming Mode\", \"btl2cap.info_streaming\",\n            FT_UINT32, BASE_DEC, NULL, 0x10,\n            \"Streaming mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_fcs,\n          { \"FCS\", \"btl2cap.info_fcs\",\n            FT_UINT32, BASE_DEC, NULL, 0x20,\n            \"FCS support\", HFILL }\n        },\n        { &hf_btl2cap_info_flow_spec,\n          { \"Extended Flow Specification for BR/EDR\", \"btl2cap.info_flow_spec\",\n            FT_UINT32, BASE_DEC, NULL, 0x40,\n            \"Extended Flow Specification for BR/EDR support\", HFILL }\n        },\n        { &hf_btl2cap_info_fixedchan,\n          { \"Fixed Channels\", \"btl2cap.info_fixedchan\",\n            FT_UINT32, BASE_DEC, NULL, 0x80,\n            \"Fixed Channels support\", HFILL }\n        },\n        { &hf_btl2cap_info_window,\n          { \"Extended Window Size\", \"btl2cap.info_window\",\n            FT_UINT32, BASE_DEC, NULL, 0x0100,\n            \"Extended Window Size support\", HFILL }\n        },\n        { &hf_btl2cap_info_unicast,\n          { \"Unicast Connectionless Data Reception\", \"btl2cap.info_unicast\",\n            FT_UINT32, BASE_DEC, NULL, 0x0200,\n            \"Unicast Connectionless Data Reception support\", HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans,\n          { \"Fixed Channels\", \"btl2cap.info_fixedchans\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_null,\n          { \"Null identifier\", \"btl2cap.info_fixedchans_null\",\n            FT_UINT32, BASE_DEC, NULL, 0x1,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_signal,\n          { \"L2CAP signaling channel\", \"btl2cap.info_fixedchans_signal\",\n            FT_UINT32, BASE_DEC, NULL, 0x2,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_connless,\n          { \"Connectionless reception\", \"btl2cap.info_fixedchans_connless\",\n            FT_UINT32, BASE_DEC, NULL, 0x4,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_amp_man,\n          { \"AMP Manager protocol\", \"btl2cap.info_fixedchans_amp_man\",\n            FT_UINT32, BASE_DEC, NULL, 0x8,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_amp_test,\n          { \"AMP Test Manager\", \"btl2cap.info_fixedchans_amp_test\",\n            FT_UINT32, BASE_DEC, NULL, 0x80000000,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_type,\n          { \"Information Type\",           \"btl2cap.info_type\",\n            FT_UINT16, BASE_HEX, VALS(info_type_vals), 0x0,\n            \"Type of implementation-specific information\", HFILL }\n        },\n        { &hf_btl2cap_info_result,\n          { \"Result\",           \"btl2cap.info_result\",\n            FT_UINT16, BASE_HEX, VALS(info_result_vals), 0x0,\n            \"Information about the success of the request\", HFILL }\n        },\n        { &hf_btl2cap_info_extfeatures,\n          { \"Extended Features\",           \"btl2cap.info_extfeatures\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            \"Extended Features Mask\", HFILL }\n        },\n        { &hf_btl2cap_flags_reserved,\n          { \"Reserved\",           \"btl2cap.flags.reserved\",\n            FT_UINT16, BASE_HEX, NULL, 0xFFFE,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_flags_continuation,\n          { \"Continuation Flag\",           \"btl2cap.flags.continuation\",\n            FT_BOOLEAN, 16, NULL, 0x0001,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_configuration_result,\n          { \"Result\",           \"btl2cap.conf_result\",\n            FT_UINT16, BASE_HEX, VALS(configuration_result_vals), 0x0,\n            \"Configuration Result\", HFILL }\n        },\n        { &hf_btl2cap_option_type,\n          { \"Type\",           \"btl2cap.option_type\",\n            FT_UINT8, BASE_HEX, VALS(option_type_vals), 0x0,\n            \"Type of option\", HFILL }\n        },\n        { &hf_btl2cap_option_length,\n          { \"Length\",           \"btl2cap.option_length\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"Number of octets in option payload\", HFILL }\n        },\n        { &hf_btl2cap_option_mtu,\n          { \"MTU\",           \"btl2cap.option_mtu\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Maximum Transmission Unit\", HFILL }\n        },\n        { &hf_btl2cap_option_flushTO,\n          { \"Flush Timeout (ms)\",           \"btl2cap.option_flushto\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Flush Timeout in milliseconds\", HFILL }\n        },\n        { &hf_btl2cap_option_flush_to_us,\n          { \"Flush Timeout (us)\",           \"btl2cap.option_flushto\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Flush Timeout (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_sdu_size,\n          { \"Maximum SDU Size\",           \"btl2cap.option_sdu_size\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_option_sdu_arrival_time,\n          { \"SDU Inter-arrival Time (us)\",           \"btl2cap.option_sdu_arrival_time\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"SDU Inter-arrival Time (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_identifier,\n          { \"Identifier\",           \"btl2cap.option_ident\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            \"Flow Specification Identifier\", HFILL }\n        },\n        { &hf_btl2cap_option_access_latency,\n          { \"Access Latency (us)\",           \"btl2cap.option_access_latency\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Access Latency (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_flags,\n          { \"Flags\",           \"btl2cap.option_flags\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            \"Flags - must be set to 0 (Reserved for future use)\", HFILL }\n        },\n        { &hf_btl2cap_option_service_type,\n          { \"Service Type\",           \"btl2cap.option_servicetype\",\n            FT_UINT8, BASE_HEX, VALS(option_servicetype_vals), 0x0,\n            \"Level of service required\", HFILL }\n        },\n        { &hf_btl2cap_option_tokenrate,\n          { \"Token Rate (bytes/s)\",           \"btl2cap.option_tokenrate\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Rate at which traffic credits are granted (bytes/s)\", HFILL }\n        },\n        { &hf_btl2cap_option_tokenbucketsize,\n          { \"Token Bucket Size (bytes)\",           \"btl2cap.option_tokenbsize\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Size of the token bucket (bytes)\", HFILL }\n        },\n        { &hf_btl2cap_option_peakbandwidth,\n          { \"Peak Bandwidth (bytes/s)\",           \"btl2cap.option_peakbandwidth\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Limit how fast packets may be sent (bytes/s)\", HFILL }\n        },\n        { &hf_btl2cap_option_latency,\n          { \"Latency (microseconds)\",           \"btl2cap.option_latency\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Maximal acceptable delay (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_delayvariation,\n          { \"Delay Variation (microseconds)\",           \"btl2cap.option_delayvar\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Difference between maximum and minimum delay (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_retransmissionmode,\n          { \"Mode\",                               \"btl2cap.retransmissionmode\",\n            FT_UINT8, BASE_HEX, VALS(option_retransmissionmode_vals), 0x0,\n            \"Retransmission/Flow Control mode\", HFILL }\n        },\n        { &hf_btl2cap_option_txwindow,\n          { \"TxWindow\",                           \"btl2cap.txwindow\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"Retransmission window size\", HFILL }\n        },\n        { &hf_btl2cap_option_maxtransmit,\n          { \"MaxTransmit\",                        \"btl2cap.maxtransmit\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"Maximum I-frame retransmissions\", HFILL }\n        },\n        { &hf_btl2cap_option_retransmittimeout,\n          { \"Retransmit timeout (ms)\",            \"btl2cap.retransmittimeout\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Retransmission timeout (milliseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_monitortimeout,\n          { \"Monitor Timeout (ms)\",               \"btl2cap.monitortimeout\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"S-frame transmission interval (milliseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_mps,\n          { \"MPS\",                                \"btl2cap.mps\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Maximum PDU Payload Size\", HFILL }\n        },\n        { &hf_btl2cap_option_fcs,\n          { \"FCS\",           \"btl2cap.option_fcs\",\n            FT_UINT16, BASE_HEX, VALS(option_fcs_vals), 0x0,\n            \"Frame Check Sequence\", HFILL }\n        },\n        { &hf_btl2cap_option_window,\n          { \"Extended Window Size\",           \"btl2cap.option_window\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_option,\n          { \"Configuration Parameter Option\",           \"btl2cap.conf_param_option\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_control_sar,\n          { \"Segmentation and reassembly\",           \"btl2cap.control_sar\",\n            FT_UINT16, BASE_HEX, VALS(control_sar_vals), 0xC000,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_control_reqseq,\n          { \"ReqSeq\",           \"btl2cap.control_reqseq\",\n            FT_UINT16, BASE_DEC, NULL, 0x3F00,\n            \"Request Sequence Number\", HFILL }\n        },\n        { &hf_btl2cap_control_txseq,\n          { \"TxSeq\",           \"btl2cap.control_txseq\",\n            FT_UINT16, BASE_DEC, NULL, 0x007E,\n            \"Transmitted Sequence Number\", HFILL }\n        },\n        { &hf_btl2cap_control_retransmissiondisable,\n          { \"R\",           \"btl2cap.control_retransmissiondisable\",\n            FT_UINT16, BASE_HEX, NULL, 0x0080,\n            \"Retransmission Disable\", HFILL }\n        },\n        { &hf_btl2cap_control_supervisory,\n          { \"S\",           \"btl2cap.control_supervisory\",\n            FT_UINT16, BASE_HEX, VALS(control_supervisory_vals), 0x000C,\n            \"Supervisory Function\", HFILL }\n        },\n        { &hf_btl2cap_control_type,\n          { \"Frame Type\",           \"btl2cap.control_type\",\n            FT_UINT16, BASE_HEX, VALS(control_type_vals), 0x0001,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_control,\n          { \"Control field\",           \"btl2cap.control\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_fcs,\n          { \"FCS\",           \"btl2cap.fcs\",\n            FT_UINT16, BASE_HEX, NULL, 0,\n            \"Frame Check Sequence\", HFILL }\n        },\n        { &hf_btl2cap_sdulength,\n          { \"SDU Length\",           \"btl2cap.sdulength\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_reassembled_in,\n          { \"This SDU is reassembled in frame\",           \"btl2cap.reassembled_in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0,\n            \"This SDU is reassembled in frame #\", HFILL }\n        },\n        { &hf_btl2cap_continuation_to,\n          { \"This is a continuation to the SDU in frame\",           \"btl2cap.continuation_to\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0,\n            \"This is a continuation to the SDU in frame #\", HFILL }\n        },\n        { &hf_btl2cap_min_interval,\n          { \"Min. Interval\",           \"btl2cap.min_interval\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_max_interval,\n          { \"Max. Interval\",           \"btl2cap.max_interval\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_slave_latency,\n          { \"Slave Latency\",           \"btl2cap.slave_latency\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_timeout_multiplier,\n          { \"Timeout Multiplier\",           \"btl2cap.timeout_multiplier\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_conn_param_result,\n          { \"Move Result\",           \"btl2cap.move_result\",\n            FT_UINT16, BASE_HEX, VALS(conn_param_result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_le_result,\n          { \"LE Result\",           \"btl2cap.le_result\",\n            FT_UINT16, BASE_HEX, VALS(le_result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_credits,\n          { \"Credits\",               \"btl2cap.credits\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"L2CAP Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_initial_credits,\n          { \"Initial Credits\",       \"btl2cap.initial_credits\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"L2CAP Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_le_psm,\n          { \"LE PSM\",           \"btl2cap.le_psm\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(le_psm_rvals), 0x0,\n            \"Protocol/Service Multiplexer\", HFILL }\n        },\n        { &hf_btl2cap_data,\n          { \"Data\",           \"btl2cap.data\",\n            FT_BYTES, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_connect_in_frame,\n            { \"Connect in frame\",                            \"btl2cap.connect_in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_disconnect_in_frame,\n            { \"Disconnect in frame\",                         \"btl2cap.disconnect_in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n    };\n\n    /* Setup protocol subtree array */\n    static gint *ett[] = {\n        &ett_btl2cap,\n        &ett_btl2cap_cmd,\n        &ett_btl2cap_option,\n        &ett_btl2cap_extfeatures,\n        &ett_btl2cap_fixedchans,\n        &ett_btl2cap_control\n    };\n\n    static ei_register_info ei[] = {\n        { &ei_btl2cap_parameter_mismatch, { \"btl2cap.parameter_mismatch\", PI_PROTOCOL, PI_WARN, \"Unexpected frame\", EXPFILL }},\n        { &ei_btl2cap_sdulength_bad, { \"btl2cap.sdulength.bad\", PI_MALFORMED, PI_WARN, \"SDU length bad\", EXPFILL }},\n        { &ei_btl2cap_length_bad, { \"btl2cap.length.bad\", PI_MALFORMED, PI_WARN, \"Length bad\", EXPFILL }},\n        { &ei_btl2cap_unknown_command_code, { \"btl2cap.unknown_command_code\", PI_PROTOCOL, PI_WARN, \"Unknown Command Code\", EXPFILL }},\n    };\n\n    /* Decode As handling */\n    static build_valid_func btl2cap_cid_da_build_value[1] = {btl2cap_cid_value};\n    static decode_as_value_t btl2cap_cid_da_values = {btl2cap_cid_prompt, 1, btl2cap_cid_da_build_value};\n    static decode_as_t btl2cap_cid_da = {\"btl2cap\", \"L2CAP CID\", \"btl2cap.cid\", 1, 0, &btl2cap_cid_da_values, NULL, NULL,\n                                 decode_as_default_populate_list, decode_as_default_reset, decode_as_default_change, NULL};\n\n    static build_valid_func btl2cap_psm_da_build_value[1] = {btl2cap_psm_value};\n    static decode_as_value_t btl2cap_psm_da_values = {btl2cap_psm_prompt, 1, btl2cap_psm_da_build_value};\n    static decode_as_t btl2cap_psm_da = {\"btl2cap\", \"L2CAP PSM\", \"btl2cap.psm\", 1, 0, &btl2cap_psm_da_values, NULL, NULL,\n                                 decode_as_default_populate_list, decode_as_default_reset, decode_as_default_change, NULL};\n\n    /* Register the protocol name and description */\n    proto_btl2cap = proto_register_protocol(\"Bluetooth L2CAP Protocol\", \"BT L2CAP\", \"btl2cap\");\n\n    new_register_dissector(\"btl2cap\", dissect_btl2cap, proto_btl2cap);\n\n    /* subdissector code */\n    l2cap_psm_dissector_table = register_dissector_table(\"btl2cap.psm\",     \"BT L2CAP PSM\",     FT_UINT16, BASE_HEX);\n    l2cap_cid_dissector_table = register_dissector_table(\"btl2cap.cid\",     \"BT L2CAP CID\",     FT_UINT16, BASE_HEX);\n\n    /* Required function calls to register the header fields and subtrees used */\n    proto_register_field_array(proto_btl2cap, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n    expert_btl2cap = expert_register_protocol(proto_btl2cap);\n    expert_register_field_array(expert_btl2cap, ei, array_length(ei));\n\n    cid_to_psm_table     = wmem_tree_new_autoreset(wmem_epan_scope(), wmem_file_scope());\n\n    register_decode_as(&btl2cap_cid_da);\n    register_decode_as(&btl2cap_psm_da);\n}",
        "func": "void\nproto_register_btl2cap(void)\n{\n    expert_module_t *expert_btl2cap;\n    /* Setup list of header fields  See Section 1.6.1 for details*/\n    static hf_register_info hf[] = {\n        { &hf_btl2cap_length,\n          { \"Length\",           \"btl2cap.length\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"L2CAP Payload Length\", HFILL }\n        },\n        { &hf_btl2cap_cid,\n          { \"CID\",           \"btl2cap.cid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"L2CAP Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_payload,\n          { \"Payload\",           \"btl2cap.payload\",\n            FT_BYTES, BASE_NONE, NULL, 0x0,\n            \"L2CAP Payload\", HFILL }\n        },\n        { &hf_btl2cap_command,\n          { \"Command\",           \"btl2cap.command\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            \"L2CAP Command\", HFILL }\n        },\n        { &hf_btl2cap_cmd_code,\n          { \"Command Code\",           \"btl2cap.cmd_code\",\n            FT_UINT8, BASE_HEX, VALS(command_code_vals), 0x0,\n            \"L2CAP Command Code\", HFILL }\n        },\n        { &hf_btl2cap_cmd_ident,\n          { \"Command Identifier\",           \"btl2cap.cmd_ident\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            \"L2CAP Command Identifier\", HFILL }\n        },\n        { &hf_btl2cap_cmd_length,\n          { \"Command Length\",           \"btl2cap.cmd_length\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"L2CAP Command Length\", HFILL }\n        },\n        { &hf_btl2cap_cmd_data,\n          { \"Command Data\",           \"btl2cap.cmd_data\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            \"L2CAP Command Data\", HFILL }\n        },\n        { &hf_btl2cap_psm,\n          { \"PSM\",           \"btl2cap.psm\",\n            FT_UINT16, BASE_HEX, VALS(psm_vals), 0x0,\n            \"Protocol/Service Multiplexer\", HFILL }\n        },\n        { &hf_btl2cap_psm_dynamic,\n          { \"Dynamic PSM\",           \"btl2cap.psm\",\n            FT_UINT16, BASE_HEX, NULL, 0x0,\n            \"Dynamic Protocol/Service Multiplexer\", HFILL }\n        },\n        { &hf_btl2cap_scid,\n          { \"Source CID\",           \"btl2cap.scid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"Source Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_dcid,\n          { \"Destination CID\",           \"btl2cap.dcid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"Destination Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_icid,\n          { \"Initiator CID\",           \"btl2cap.icid\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(cid_rvals), 0x0,\n            \"Initiator Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_controller,\n          { \"Controller ID\",           \"btl2cap.ctrl_id\",\n            FT_UINT8, BASE_DEC, VALS(ctrl_id_code_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_dcontroller,\n          { \"Controller ID\",           \"btl2cap.dctrl_id\",\n            FT_UINT8, BASE_DEC, VALS(ctrl_id_code_vals), 0x0,\n            \"Destination Controller ID\", HFILL }\n        },\n        { &hf_btl2cap_result,\n          { \"Result\",           \"btl2cap.result\",\n            FT_UINT16, BASE_HEX, VALS(result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_move_result,\n          { \"Move Result\",           \"btl2cap.move_result\",\n            FT_UINT16, BASE_HEX, VALS(move_result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_move_confirmation_result,\n          { \"Move Result\",           \"btl2cap.move_result\",\n            FT_UINT16, BASE_HEX, VALS(move_result_confirmation_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_status,\n          { \"Status\",           \"btl2cap.status\",\n            FT_UINT16, BASE_HEX, VALS(status_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_rej_reason,\n          { \"Reason\",           \"btl2cap.rej_reason\",\n            FT_UINT16, BASE_HEX, VALS(reason_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_sig_mtu,\n          { \"Maximum Signalling MTU\",           \"btl2cap.sig_mtu\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_mtu,\n          { \"Remote Entity MTU\",           \"btl2cap.info_mtu\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Remote entity acceptable connectionless MTU\", HFILL }\n        },\n        { &hf_btl2cap_info_flowcontrol,\n          { \"Flow Control Mode\",           \"btl2cap.info_flowcontrol\",\n            FT_UINT32, BASE_DEC, NULL, 0x01,\n            \"Flow Control mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_retransmission,\n          { \"Retransmission Mode\",         \"btl2cap.info_retransmission\",\n            FT_UINT32, BASE_DEC, NULL, 0x02,\n            \"Retransmission mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_bidirqos,\n          { \"Bi-Directional QOS\",          \"btl2cap.info_bidirqos\",\n            FT_UINT32, BASE_DEC, NULL, 0x04,\n            \"Bi-Directional QOS support\", HFILL }\n        },\n        { &hf_btl2cap_info_enh_retransmission,\n          { \"Enhanced Retransmission Mode\", \"btl2cap.info_enh_retransmission\",\n            FT_UINT32, BASE_DEC, NULL, 0x08,\n            \"Enhanced Retransmission mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_streaming,\n          { \"Streaming Mode\", \"btl2cap.info_streaming\",\n            FT_UINT32, BASE_DEC, NULL, 0x10,\n            \"Streaming mode support\", HFILL }\n        },\n        { &hf_btl2cap_info_fcs,\n          { \"FCS\", \"btl2cap.info_fcs\",\n            FT_UINT32, BASE_DEC, NULL, 0x20,\n            \"FCS support\", HFILL }\n        },\n        { &hf_btl2cap_info_flow_spec,\n          { \"Extended Flow Specification for BR/EDR\", \"btl2cap.info_flow_spec\",\n            FT_UINT32, BASE_DEC, NULL, 0x40,\n            \"Extended Flow Specification for BR/EDR support\", HFILL }\n        },\n        { &hf_btl2cap_info_fixedchan,\n          { \"Fixed Channels\", \"btl2cap.info_fixedchan\",\n            FT_UINT32, BASE_DEC, NULL, 0x80,\n            \"Fixed Channels support\", HFILL }\n        },\n        { &hf_btl2cap_info_window,\n          { \"Extended Window Size\", \"btl2cap.info_window\",\n            FT_UINT32, BASE_DEC, NULL, 0x0100,\n            \"Extended Window Size support\", HFILL }\n        },\n        { &hf_btl2cap_info_unicast,\n          { \"Unicast Connectionless Data Reception\", \"btl2cap.info_unicast\",\n            FT_UINT32, BASE_DEC, NULL, 0x0200,\n            \"Unicast Connectionless Data Reception support\", HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans,\n          { \"Fixed Channels\", \"btl2cap.info_fixedchans\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_null,\n          { \"Null identifier\", \"btl2cap.info_fixedchans_null\",\n            FT_UINT32, BASE_DEC, NULL, 0x1,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_signal,\n          { \"L2CAP signaling channel\", \"btl2cap.info_fixedchans_signal\",\n            FT_UINT32, BASE_DEC, NULL, 0x2,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_connless,\n          { \"Connectionless reception\", \"btl2cap.info_fixedchans_connless\",\n            FT_UINT32, BASE_DEC, NULL, 0x4,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_amp_man,\n          { \"AMP Manager protocol\", \"btl2cap.info_fixedchans_amp_man\",\n            FT_UINT32, BASE_DEC, NULL, 0x8,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_fixedchans_amp_test,\n          { \"AMP Test Manager\", \"btl2cap.info_fixedchans_amp_test\",\n            FT_UINT32, BASE_DEC, NULL, 0x80000000,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_info_type,\n          { \"Information Type\",           \"btl2cap.info_type\",\n            FT_UINT16, BASE_HEX, VALS(info_type_vals), 0x0,\n            \"Type of implementation-specific information\", HFILL }\n        },\n        { &hf_btl2cap_info_result,\n          { \"Result\",           \"btl2cap.info_result\",\n            FT_UINT16, BASE_HEX, VALS(info_result_vals), 0x0,\n            \"Information about the success of the request\", HFILL }\n        },\n        { &hf_btl2cap_info_extfeatures,\n          { \"Extended Features\",           \"btl2cap.info_extfeatures\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            \"Extended Features Mask\", HFILL }\n        },\n        { &hf_btl2cap_flags_reserved,\n          { \"Reserved\",           \"btl2cap.flags.reserved\",\n            FT_UINT16, BASE_HEX, NULL, 0xFFFE,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_flags_continuation,\n          { \"Continuation Flag\",           \"btl2cap.flags.continuation\",\n            FT_BOOLEAN, 16, NULL, 0x0001,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_configuration_result,\n          { \"Result\",           \"btl2cap.conf_result\",\n            FT_UINT16, BASE_HEX, VALS(configuration_result_vals), 0x0,\n            \"Configuration Result\", HFILL }\n        },\n        { &hf_btl2cap_option_type,\n          { \"Type\",           \"btl2cap.option_type\",\n            FT_UINT8, BASE_HEX, VALS(option_type_vals), 0x0,\n            \"Type of option\", HFILL }\n        },\n        { &hf_btl2cap_option_length,\n          { \"Length\",           \"btl2cap.option_length\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"Number of octets in option payload\", HFILL }\n        },\n        { &hf_btl2cap_option_mtu,\n          { \"MTU\",           \"btl2cap.option_mtu\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Maximum Transmission Unit\", HFILL }\n        },\n        { &hf_btl2cap_option_flushTO,\n          { \"Flush Timeout (ms)\",           \"btl2cap.option_flushto\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Flush Timeout in milliseconds\", HFILL }\n        },\n        { &hf_btl2cap_option_flush_to_us,\n          { \"Flush Timeout (us)\",           \"btl2cap.option_flushto\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Flush Timeout (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_sdu_size,\n          { \"Maximum SDU Size\",           \"btl2cap.option_sdu_size\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_option_sdu_arrival_time,\n          { \"SDU Inter-arrival Time (us)\",           \"btl2cap.option_sdu_arrival_time\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"SDU Inter-arrival Time (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_identifier,\n          { \"Identifier\",           \"btl2cap.option_ident\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            \"Flow Specification Identifier\", HFILL }\n        },\n        { &hf_btl2cap_option_access_latency,\n          { \"Access Latency (us)\",           \"btl2cap.option_access_latency\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Access Latency (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_flags,\n          { \"Flags\",           \"btl2cap.option_flags\",\n            FT_UINT8, BASE_HEX, NULL, 0x0,\n            \"Flags - must be set to 0 (Reserved for future use)\", HFILL }\n        },\n        { &hf_btl2cap_option_service_type,\n          { \"Service Type\",           \"btl2cap.option_servicetype\",\n            FT_UINT8, BASE_HEX, VALS(option_servicetype_vals), 0x0,\n            \"Level of service required\", HFILL }\n        },\n        { &hf_btl2cap_option_tokenrate,\n          { \"Token Rate (bytes/s)\",           \"btl2cap.option_tokenrate\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Rate at which traffic credits are granted (bytes/s)\", HFILL }\n        },\n        { &hf_btl2cap_option_tokenbucketsize,\n          { \"Token Bucket Size (bytes)\",           \"btl2cap.option_tokenbsize\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Size of the token bucket (bytes)\", HFILL }\n        },\n        { &hf_btl2cap_option_peakbandwidth,\n          { \"Peak Bandwidth (bytes/s)\",           \"btl2cap.option_peakbandwidth\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Limit how fast packets may be sent (bytes/s)\", HFILL }\n        },\n        { &hf_btl2cap_option_latency,\n          { \"Latency (microseconds)\",           \"btl2cap.option_latency\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Maximal acceptable delay (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_delayvariation,\n          { \"Delay Variation (microseconds)\",           \"btl2cap.option_delayvar\",\n            FT_UINT32, BASE_DEC, NULL, 0x0,\n            \"Difference between maximum and minimum delay (microseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_retransmissionmode,\n          { \"Mode\",                               \"btl2cap.retransmissionmode\",\n            FT_UINT8, BASE_HEX, VALS(option_retransmissionmode_vals), 0x0,\n            \"Retransmission/Flow Control mode\", HFILL }\n        },\n        { &hf_btl2cap_option_txwindow,\n          { \"TxWindow\",                           \"btl2cap.txwindow\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"Retransmission window size\", HFILL }\n        },\n        { &hf_btl2cap_option_maxtransmit,\n          { \"MaxTransmit\",                        \"btl2cap.maxtransmit\",\n            FT_UINT8, BASE_DEC, NULL, 0x0,\n            \"Maximum I-frame retransmissions\", HFILL }\n        },\n        { &hf_btl2cap_option_retransmittimeout,\n          { \"Retransmit timeout (ms)\",            \"btl2cap.retransmittimeout\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Retransmission timeout (milliseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_monitortimeout,\n          { \"Monitor Timeout (ms)\",               \"btl2cap.monitortimeout\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"S-frame transmission interval (milliseconds)\", HFILL }\n        },\n        { &hf_btl2cap_option_mps,\n          { \"MPS\",                                \"btl2cap.mps\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"Maximum PDU Payload Size\", HFILL }\n        },\n        { &hf_btl2cap_option_fcs,\n          { \"FCS\",           \"btl2cap.option_fcs\",\n            FT_UINT16, BASE_HEX, VALS(option_fcs_vals), 0x0,\n            \"Frame Check Sequence\", HFILL }\n        },\n        { &hf_btl2cap_option_window,\n          { \"Extended Window Size\",           \"btl2cap.option_window\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_option,\n          { \"Configuration Parameter Option\",           \"btl2cap.conf_param_option\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_control_sar,\n          { \"Segmentation and reassembly\",           \"btl2cap.control_sar\",\n            FT_UINT16, BASE_HEX, VALS(control_sar_vals), 0xC000,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_control_reqseq,\n          { \"ReqSeq\",           \"btl2cap.control_reqseq\",\n            FT_UINT16, BASE_DEC, NULL, 0x3F00,\n            \"Request Sequence Number\", HFILL }\n        },\n        { &hf_btl2cap_control_txseq,\n          { \"TxSeq\",           \"btl2cap.control_txseq\",\n            FT_UINT16, BASE_DEC, NULL, 0x007E,\n            \"Transmitted Sequence Number\", HFILL }\n        },\n        { &hf_btl2cap_control_retransmissiondisable,\n          { \"R\",           \"btl2cap.control_retransmissiondisable\",\n            FT_UINT16, BASE_HEX, NULL, 0x0080,\n            \"Retransmission Disable\", HFILL }\n        },\n        { &hf_btl2cap_control_supervisory,\n          { \"S\",           \"btl2cap.control_supervisory\",\n            FT_UINT16, BASE_HEX, VALS(control_supervisory_vals), 0x000C,\n            \"Supervisory Function\", HFILL }\n        },\n        { &hf_btl2cap_control_type,\n          { \"Frame Type\",           \"btl2cap.control_type\",\n            FT_UINT16, BASE_HEX, VALS(control_type_vals), 0x0001,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_control,\n          { \"Control field\",           \"btl2cap.control\",\n            FT_NONE, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_fcs,\n          { \"FCS\",           \"btl2cap.fcs\",\n            FT_UINT16, BASE_HEX, NULL, 0,\n            \"Frame Check Sequence\", HFILL }\n        },\n        { &hf_btl2cap_sdulength,\n          { \"SDU Length\",           \"btl2cap.sdulength\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_reassembled_in,\n          { \"This SDU is reassembled in frame\",           \"btl2cap.reassembled_in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0,\n            \"This SDU is reassembled in frame #\", HFILL }\n        },\n        { &hf_btl2cap_continuation_to,\n          { \"This is a continuation to the SDU in frame\",           \"btl2cap.continuation_to\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0,\n            \"This is a continuation to the SDU in frame #\", HFILL }\n        },\n        { &hf_btl2cap_min_interval,\n          { \"Min. Interval\",           \"btl2cap.min_interval\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_max_interval,\n          { \"Max. Interval\",           \"btl2cap.max_interval\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_slave_latency,\n          { \"Slave Latency\",           \"btl2cap.slave_latency\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_timeout_multiplier,\n          { \"Timeout Multiplier\",           \"btl2cap.timeout_multiplier\",\n            FT_UINT16, BASE_DEC, NULL, 0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_conn_param_result,\n          { \"Move Result\",           \"btl2cap.move_result\",\n            FT_UINT16, BASE_HEX, VALS(conn_param_result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_le_result,\n          { \"LE Result\",           \"btl2cap.le_result\",\n            FT_UINT16, BASE_HEX, VALS(le_result_vals), 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_credits,\n          { \"Credits\",               \"btl2cap.credits\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"L2CAP Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_initial_credits,\n          { \"Initial Credits\",       \"btl2cap.initial_credits\",\n            FT_UINT16, BASE_DEC, NULL, 0x0,\n            \"L2CAP Channel Identifier\", HFILL }\n        },\n        { &hf_btl2cap_le_psm,\n          { \"LE PSM\",           \"btl2cap.le_psm\",\n            FT_UINT16, BASE_HEX | BASE_RANGE_STRING, RVALS(le_psm_rvals), 0x0,\n            \"Protocol/Service Multiplexer\", HFILL }\n        },\n        { &hf_btl2cap_data,\n          { \"Data\",           \"btl2cap.data\",\n            FT_BYTES, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_connect_in_frame,\n            { \"Connect in frame\",                            \"btl2cap.connect_in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n        { &hf_btl2cap_disconnect_in_frame,\n            { \"Disconnect in frame\",                         \"btl2cap.disconnect_in\",\n            FT_FRAMENUM, BASE_NONE, NULL, 0x0,\n            NULL, HFILL }\n        },\n    };\n\n    /* Setup protocol subtree array */\n    static gint *ett[] = {\n        &ett_btl2cap,\n        &ett_btl2cap_cmd,\n        &ett_btl2cap_option,\n        &ett_btl2cap_extfeatures,\n        &ett_btl2cap_fixedchans,\n        &ett_btl2cap_control\n    };\n\n    static ei_register_info ei[] = {\n        { &ei_btl2cap_parameter_mismatch, { \"btl2cap.parameter_mismatch\", PI_PROTOCOL, PI_WARN, \"Parameter mismatch\", EXPFILL }},\n        { &ei_btl2cap_sdulength_bad, { \"btl2cap.sdulength.bad\", PI_MALFORMED, PI_WARN, \"SDU length bad\", EXPFILL }},\n        { &ei_btl2cap_length_bad, { \"btl2cap.length.bad\", PI_MALFORMED, PI_WARN, \"Length bad\", EXPFILL }},\n        { &ei_btl2cap_unknown_command_code, { \"btl2cap.unknown_command_code\", PI_PROTOCOL, PI_WARN, \"Unknown Command Code\", EXPFILL }},\n    };\n\n    /* Decode As handling */\n    static build_valid_func btl2cap_cid_da_build_value[1] = {btl2cap_cid_value};\n    static decode_as_value_t btl2cap_cid_da_values = {btl2cap_cid_prompt, 1, btl2cap_cid_da_build_value};\n    static decode_as_t btl2cap_cid_da = {\"btl2cap\", \"L2CAP CID\", \"btl2cap.cid\", 1, 0, &btl2cap_cid_da_values, NULL, NULL,\n                                 decode_as_default_populate_list, decode_as_default_reset, decode_as_default_change, NULL};\n\n    static build_valid_func btl2cap_psm_da_build_value[1] = {btl2cap_psm_value};\n    static decode_as_value_t btl2cap_psm_da_values = {btl2cap_psm_prompt, 1, btl2cap_psm_da_build_value};\n    static decode_as_t btl2cap_psm_da = {\"btl2cap\", \"L2CAP PSM\", \"btl2cap.psm\", 1, 0, &btl2cap_psm_da_values, NULL, NULL,\n                                 decode_as_default_populate_list, decode_as_default_reset, decode_as_default_change, NULL};\n\n    /* Register the protocol name and description */\n    proto_btl2cap = proto_register_protocol(\"Bluetooth L2CAP Protocol\", \"BT L2CAP\", \"btl2cap\");\n\n    new_register_dissector(\"btl2cap\", dissect_btl2cap, proto_btl2cap);\n\n    /* subdissector code */\n    l2cap_psm_dissector_table = register_dissector_table(\"btl2cap.psm\",     \"BT L2CAP PSM\",     FT_UINT16, BASE_HEX);\n    l2cap_cid_dissector_table = register_dissector_table(\"btl2cap.cid\",     \"BT L2CAP CID\",     FT_UINT16, BASE_HEX);\n\n    /* Required function calls to register the header fields and subtrees used */\n    proto_register_field_array(proto_btl2cap, hf, array_length(hf));\n    proto_register_subtree_array(ett, array_length(ett));\n    expert_btl2cap = expert_register_protocol(proto_btl2cap);\n    expert_register_field_array(expert_btl2cap, ei, array_length(ei));\n\n    cid_to_psm_table     = wmem_tree_new_autoreset(wmem_epan_scope(), wmem_file_scope());\n\n    register_decode_as(&btl2cap_cid_da);\n    register_decode_as(&btl2cap_psm_da);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -477,7 +477,7 @@\n     };\n \n     static ei_register_info ei[] = {\n-        { &ei_btl2cap_parameter_mismatch, { \"btl2cap.parameter_mismatch\", PI_PROTOCOL, PI_WARN, \"Unexpected frame\", EXPFILL }},\n+        { &ei_btl2cap_parameter_mismatch, { \"btl2cap.parameter_mismatch\", PI_PROTOCOL, PI_WARN, \"Parameter mismatch\", EXPFILL }},\n         { &ei_btl2cap_sdulength_bad, { \"btl2cap.sdulength.bad\", PI_MALFORMED, PI_WARN, \"SDU length bad\", EXPFILL }},\n         { &ei_btl2cap_length_bad, { \"btl2cap.length.bad\", PI_MALFORMED, PI_WARN, \"Length bad\", EXPFILL }},\n         { &ei_btl2cap_unknown_command_code, { \"btl2cap.unknown_command_code\", PI_PROTOCOL, PI_WARN, \"Unknown Command Code\", EXPFILL }},",
        "diff_line_info": {
            "deleted_lines": [
                "        { &ei_btl2cap_parameter_mismatch, { \"btl2cap.parameter_mismatch\", PI_PROTOCOL, PI_WARN, \"Unexpected frame\", EXPFILL }},"
            ],
            "added_lines": [
                "        { &ei_btl2cap_parameter_mismatch, { \"btl2cap.parameter_mismatch\", PI_PROTOCOL, PI_WARN, \"Parameter mismatch\", EXPFILL }},"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-19888",
        "func_name": "rockcarry/ffjpeg/jfif_decode",
        "description": "jfif_decode in jfif.c in ffjpeg through 2019-08-21 has a divide-by-zero error.",
        "git_url": "https://github.com/rockcarry/ffjpeg/commit/d6158811dbb4e97dc1cc9820ed0e846468366658",
        "commit_title": "fix issue #13, by dividing zero without sanity check in jfif.c",
        "commit_text": "",
        "func_before": "int jfif_decode(void *ctxt, BMP *pb)\n{\n    JFIF *jfif    = (JFIF*)ctxt;\n    void *bs      = NULL;\n    int  *ftab[16]= {0};\n    int   dc[4]   = {0};\n    int   mcuw, mcuh, mcuc, mcur, mcui, jw, jh;\n    int   i, j, c, h, v, x, y;\n    int   sfh_max = 0;\n    int   sfv_max = 0;\n    int   yuv_stride[3] = {0};\n    int   yuv_height[3] = {0};\n    int  *yuv_datbuf[3] = {0};\n    int  *idst, *isrc;\n    int  *ysrc, *usrc, *vsrc;\n    BYTE *bdst;\n    int   ret = -1;\n\n    if (!ctxt || !pb) {\n        printf(\"invalid input params !\\n\");\n        return -1;\n    }\n\n    // init dct module\n    init_dct_module();\n\n    //++ init ftab\n    for (i=0; i<16; i++) {\n        if (jfif->pqtab[i]) {\n            ftab[i] = malloc(64 * sizeof(int));\n            if (ftab[i]) {\n                init_idct_ftab(ftab[i], jfif->pqtab[i]);\n            } else {\n                goto done;\n            }\n        }\n    }\n    //-- init ftab\n\n    //++ calculate mcu info\n    for (c=0; c<jfif->comp_num; c++) {\n        if (sfh_max < jfif->comp_info[c].samp_factor_h) {\n            sfh_max = jfif->comp_info[c].samp_factor_h;\n        }\n        if (sfv_max < jfif->comp_info[c].samp_factor_v) {\n            sfv_max = jfif->comp_info[c].samp_factor_v;\n        }\n    }\n    mcuw = sfh_max * 8;\n    mcuh = sfv_max * 8;\n    jw = ALIGN(jfif->width , mcuw);\n    jh = ALIGN(jfif->height, mcuh);\n    mcuc = jw / mcuw;\n    mcur = jh / mcuh;\n    //-- calculate mcu info\n\n    // create yuv buffer for decoding\n    yuv_stride[0] = jw;\n    yuv_stride[1] = jw * jfif->comp_info[1].samp_factor_h / sfh_max;\n    yuv_stride[2] = jw * jfif->comp_info[2].samp_factor_h / sfh_max;\n    yuv_height[0] = jh;\n    yuv_height[1] = jh * jfif->comp_info[1].samp_factor_v / sfv_max;\n    yuv_height[2] = jh * jfif->comp_info[2].samp_factor_v / sfv_max;\n    yuv_datbuf[0] = malloc(yuv_stride[0] * yuv_height[0] * sizeof(int));\n    yuv_datbuf[1] = malloc(yuv_stride[1] * yuv_height[1] * sizeof(int));\n    yuv_datbuf[2] = malloc(yuv_stride[2] * yuv_height[2] * sizeof(int));\n    if (!yuv_datbuf[0] || !yuv_datbuf[1] || !yuv_datbuf[2]) {\n        goto done;\n    }\n\n    // open bit stream\n    bs = bitstr_open(jfif->databuf, \"mem\", jfif->datalen);\n    if (!bs) {\n        printf(\"failed to open bitstr for jfif_decode !\");\n        return -1;\n    }\n\n    // init huffman codec\n    for (i=0; i<16; i++) {\n        if (jfif->phcac[i]) {\n            jfif->phcac[i]->input = bs;\n            huffman_decode_init(jfif->phcac[i]);\n        }\n        if (jfif->phcdc[i]) {\n            jfif->phcdc[i]->input = bs;\n            huffman_decode_init(jfif->phcdc[i]);\n        }\n    }\n\n    for (mcui=0; mcui<mcuc*mcur; mcui++) {\n        for (c=0; c<jfif->comp_num; c++) {\n            for (v=0; v<jfif->comp_info[c].samp_factor_v; v++) {\n                for (h=0; h<jfif->comp_info[c].samp_factor_h; h++) {\n                    HUFCODEC *hcac = jfif->phcac[jfif->comp_info[c].htab_idx_ac];\n                    HUFCODEC *hcdc = jfif->phcdc[jfif->comp_info[c].htab_idx_dc];\n                    int       fidx = jfif->comp_info[c].qtab_idx;\n                    int size, znum, code;\n                    int du[64] = {0};\n\n                    //+ decode dc\n                    size = huffman_decode_step(hcdc) & 0xf;\n                    if (size) {\n                        code = bitstr_get_bits(bs  , size);\n                        code = category_decode(code, size);\n                    }\n                    else {\n                        code = 0;\n                    }\n                    dc[c] += code;\n                    du[0]  = dc[c];\n                    //- decode dc\n\n                    //+ decode ac\n                    for (i=1; i<64; ) {\n                        code = huffman_decode_step(hcac);\n                        if (code <= 0) break;\n                        size = (code >> 0) & 0xf;\n                        znum = (code >> 4) & 0xf;\n                        i   += znum;\n                        code = bitstr_get_bits(bs  , size);\n                        code = category_decode(code, size);\n                        if (i < 64) du[i++] = code;\n                    }\n                    //- decode ac\n\n                    // de-zigzag\n                    zigzag_decode(du);\n\n                    // idct\n                    idct2d8x8(du, ftab[fidx]);\n\n                    // copy du to yuv buffer\n                    x    = ((mcui % mcuc) * mcuw + h * 8) * jfif->comp_info[c].samp_factor_h / sfh_max;\n                    y    = ((mcui / mcuc) * mcuh + v * 8) * jfif->comp_info[c].samp_factor_v / sfv_max;\n                    idst = yuv_datbuf[c] + y * yuv_stride[c] + x;\n                    isrc = du;\n                    for (i=0; i<8; i++) {\n                        memcpy(idst, isrc, 8 * sizeof(int));\n                        idst += yuv_stride[c];\n                        isrc += 8;\n                    }\n                }\n            }\n        }\n    }\n\n    // close huffman codec\n    for (i=0; i<16; i++) {\n        if (jfif->phcac[i]) huffman_decode_done(jfif->phcac[i]);\n        if (jfif->phcdc[i]) huffman_decode_done(jfif->phcdc[i]);\n    }\n\n    // close bit stream\n    bitstr_close(bs);\n\n    // create bitmap, and convert yuv to rgb\n    bmp_create(pb, jfif->width, jfif->height);\n    bdst = (BYTE*)pb->pdata;\n    ysrc = yuv_datbuf[0];\n    for (i=0; i<jfif->height; i++) {\n        int uy = i * jfif->comp_info[1].samp_factor_v / sfv_max;\n        int vy = i * jfif->comp_info[2].samp_factor_v / sfv_max;\n        for (j=0; j<jfif->width; j++) {\n            int ux = j * jfif->comp_info[1].samp_factor_h / sfh_max;\n            int vx = j * jfif->comp_info[2].samp_factor_h / sfh_max;\n            usrc = yuv_datbuf[2] + uy * yuv_stride[2] + ux;\n            vsrc = yuv_datbuf[1] + vy * yuv_stride[1] + vx;\n            yuv_to_rgb(*ysrc, *vsrc, *usrc, bdst + 2, bdst + 1, bdst + 0);\n            bdst += 3;\n            ysrc += 1;\n        }\n        bdst -= jfif->width * 3;\n        bdst += pb->stride;\n        ysrc -= jfif->width * 1;\n        ysrc += yuv_stride[0];\n    }\n\n    // success\n    ret = 0;\n\ndone:\n    if (yuv_datbuf[0]) free(yuv_datbuf[0]);\n    if (yuv_datbuf[1]) free(yuv_datbuf[1]);\n    if (yuv_datbuf[2]) free(yuv_datbuf[2]);\n    //++ free ftab\n    for (i=0; i<16; i++) {\n        if (ftab[i]) {\n            free(ftab[i]);\n        }\n    }\n    //-- free ftab\n    return ret;\n}",
        "func": "int jfif_decode(void *ctxt, BMP *pb)\n{\n    JFIF *jfif    = (JFIF*)ctxt;\n    void *bs      = NULL;\n    int  *ftab[16]= {0};\n    int   dc[4]   = {0};\n    int   mcuw, mcuh, mcuc, mcur, mcui, jw, jh;\n    int   i, j, c, h, v, x, y;\n    int   sfh_max = 0;\n    int   sfv_max = 0;\n    int   yuv_stride[3] = {0};\n    int   yuv_height[3] = {0};\n    int  *yuv_datbuf[3] = {0};\n    int  *idst, *isrc;\n    int  *ysrc, *usrc, *vsrc;\n    BYTE *bdst;\n    int   ret = -1;\n\n    if (!ctxt || !pb) {\n        printf(\"invalid input params !\\n\");\n        return -1;\n    }\n\n    // init dct module\n    init_dct_module();\n\n    //++ init ftab\n    for (i=0; i<16; i++) {\n        if (jfif->pqtab[i]) {\n            ftab[i] = malloc(64 * sizeof(int));\n            if (ftab[i]) {\n                init_idct_ftab(ftab[i], jfif->pqtab[i]);\n            } else {\n                goto done;\n            }\n        }\n    }\n    //-- init ftab\n\n    //++ calculate mcu info\n    for (c=0; c<jfif->comp_num; c++) {\n        if (sfh_max < jfif->comp_info[c].samp_factor_h) {\n            sfh_max = jfif->comp_info[c].samp_factor_h;\n        }\n        if (sfv_max < jfif->comp_info[c].samp_factor_v) {\n            sfv_max = jfif->comp_info[c].samp_factor_v;\n        }\n    }\n    if (!sfh_max) sfh_max = 1;\n    if (!sfv_max) sfv_max = 1;\n    mcuw = sfh_max * 8;\n    mcuh = sfv_max * 8;\n    jw = ALIGN(jfif->width , mcuw);\n    jh = ALIGN(jfif->height, mcuh);\n    mcuc = jw / mcuw;\n    mcur = jh / mcuh;\n    //-- calculate mcu info\n\n    // create yuv buffer for decoding\n    yuv_stride[0] = jw;\n    yuv_stride[1] = jw * jfif->comp_info[1].samp_factor_h / sfh_max;\n    yuv_stride[2] = jw * jfif->comp_info[2].samp_factor_h / sfh_max;\n    yuv_height[0] = jh;\n    yuv_height[1] = jh * jfif->comp_info[1].samp_factor_v / sfv_max;\n    yuv_height[2] = jh * jfif->comp_info[2].samp_factor_v / sfv_max;\n    yuv_datbuf[0] = malloc(yuv_stride[0] * yuv_height[0] * sizeof(int));\n    yuv_datbuf[1] = malloc(yuv_stride[1] * yuv_height[1] * sizeof(int));\n    yuv_datbuf[2] = malloc(yuv_stride[2] * yuv_height[2] * sizeof(int));\n    if (!yuv_datbuf[0] || !yuv_datbuf[1] || !yuv_datbuf[2]) {\n        goto done;\n    }\n\n    // open bit stream\n    bs = bitstr_open(jfif->databuf, \"mem\", jfif->datalen);\n    if (!bs) {\n        printf(\"failed to open bitstr for jfif_decode !\");\n        return -1;\n    }\n\n    // init huffman codec\n    for (i=0; i<16; i++) {\n        if (jfif->phcac[i]) {\n            jfif->phcac[i]->input = bs;\n            huffman_decode_init(jfif->phcac[i]);\n        }\n        if (jfif->phcdc[i]) {\n            jfif->phcdc[i]->input = bs;\n            huffman_decode_init(jfif->phcdc[i]);\n        }\n    }\n\n    for (mcui=0; mcui<mcuc*mcur; mcui++) {\n        for (c=0; c<jfif->comp_num; c++) {\n            for (v=0; v<jfif->comp_info[c].samp_factor_v; v++) {\n                for (h=0; h<jfif->comp_info[c].samp_factor_h; h++) {\n                    HUFCODEC *hcac = jfif->phcac[jfif->comp_info[c].htab_idx_ac];\n                    HUFCODEC *hcdc = jfif->phcdc[jfif->comp_info[c].htab_idx_dc];\n                    int       fidx = jfif->comp_info[c].qtab_idx;\n                    int size, znum, code;\n                    int du[64] = {0};\n\n                    //+ decode dc\n                    size = huffman_decode_step(hcdc) & 0xf;\n                    if (size) {\n                        code = bitstr_get_bits(bs  , size);\n                        code = category_decode(code, size);\n                    }\n                    else {\n                        code = 0;\n                    }\n                    dc[c] += code;\n                    du[0]  = dc[c];\n                    //- decode dc\n\n                    //+ decode ac\n                    for (i=1; i<64; ) {\n                        code = huffman_decode_step(hcac);\n                        if (code <= 0) break;\n                        size = (code >> 0) & 0xf;\n                        znum = (code >> 4) & 0xf;\n                        i   += znum;\n                        code = bitstr_get_bits(bs  , size);\n                        code = category_decode(code, size);\n                        if (i < 64) du[i++] = code;\n                    }\n                    //- decode ac\n\n                    // de-zigzag\n                    zigzag_decode(du);\n\n                    // idct\n                    idct2d8x8(du, ftab[fidx]);\n\n                    // copy du to yuv buffer\n                    x    = ((mcui % mcuc) * mcuw + h * 8) * jfif->comp_info[c].samp_factor_h / sfh_max;\n                    y    = ((mcui / mcuc) * mcuh + v * 8) * jfif->comp_info[c].samp_factor_v / sfv_max;\n                    idst = yuv_datbuf[c] + y * yuv_stride[c] + x;\n                    isrc = du;\n                    for (i=0; i<8; i++) {\n                        memcpy(idst, isrc, 8 * sizeof(int));\n                        idst += yuv_stride[c];\n                        isrc += 8;\n                    }\n                }\n            }\n        }\n    }\n\n    // close huffman codec\n    for (i=0; i<16; i++) {\n        if (jfif->phcac[i]) huffman_decode_done(jfif->phcac[i]);\n        if (jfif->phcdc[i]) huffman_decode_done(jfif->phcdc[i]);\n    }\n\n    // close bit stream\n    bitstr_close(bs);\n\n    // create bitmap, and convert yuv to rgb\n    bmp_create(pb, jfif->width, jfif->height);\n    bdst = (BYTE*)pb->pdata;\n    ysrc = yuv_datbuf[0];\n    for (i=0; i<jfif->height; i++) {\n        int uy = i * jfif->comp_info[1].samp_factor_v / sfv_max;\n        int vy = i * jfif->comp_info[2].samp_factor_v / sfv_max;\n        for (j=0; j<jfif->width; j++) {\n            int ux = j * jfif->comp_info[1].samp_factor_h / sfh_max;\n            int vx = j * jfif->comp_info[2].samp_factor_h / sfh_max;\n            usrc = yuv_datbuf[2] + uy * yuv_stride[2] + ux;\n            vsrc = yuv_datbuf[1] + vy * yuv_stride[1] + vx;\n            yuv_to_rgb(*ysrc, *vsrc, *usrc, bdst + 2, bdst + 1, bdst + 0);\n            bdst += 3;\n            ysrc += 1;\n        }\n        bdst -= jfif->width * 3;\n        bdst += pb->stride;\n        ysrc -= jfif->width * 1;\n        ysrc += yuv_stride[0];\n    }\n\n    // success\n    ret = 0;\n\ndone:\n    if (yuv_datbuf[0]) free(yuv_datbuf[0]);\n    if (yuv_datbuf[1]) free(yuv_datbuf[1]);\n    if (yuv_datbuf[2]) free(yuv_datbuf[2]);\n    //++ free ftab\n    for (i=0; i<16; i++) {\n        if (ftab[i]) {\n            free(ftab[i]);\n        }\n    }\n    //-- free ftab\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,6 +46,8 @@\n             sfv_max = jfif->comp_info[c].samp_factor_v;\n         }\n     }\n+    if (!sfh_max) sfh_max = 1;\n+    if (!sfv_max) sfv_max = 1;\n     mcuw = sfh_max * 8;\n     mcuh = sfv_max * 8;\n     jw = ALIGN(jfif->width , mcuw);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (!sfh_max) sfh_max = 1;",
                "    if (!sfv_max) sfv_max = 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-13097",
        "func_name": "torvalds/linux/f2fs_sanity_check_ckpt",
        "description": "An issue was discovered in fs/f2fs/super.c in the Linux kernel through 4.17.3. There is an out-of-bounds read or a divide-by-zero error for an incorrect user_block_count in a corrupted f2fs image, leading to a denial of service (BUG).",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=9dc956b2c8523aed39d1e6508438be9fea28c8fc",
        "commit_title": "This patch fixs to do sanity check with user_block_count.",
        "commit_text": " - Overview Divide zero in utilization when mount() a corrupted f2fs image  - Reproduce (4.18 upstream kernel)  - Kernel message [  564.099503] F2FS-fs (loop0): invalid crc value [  564.101991] divide error: 0000 [#1] SMP KASAN PTI [  564.103103] CPU: 1 PID: 1298 Comm: f2fs_discard-7: Not tainted 4.18.0-rc1+ #4 [  564.104584] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014 [  564.106624] RIP: 0010:issue_discard_thread+0x248/0x5c0 [  564.107692] Code: ff ff 48 8b bd e8 fe ff ff 41 8b 9d 4c 04 00 00 e8 cd b8 ad ff 41 8b 85 50 04 00 00 31 d2 48 8d 04 80 48 8d 04 80 48 c1 e0 02 <48> f7 f3 83 f8 50 7e 16 41 c7 86 7c ff ff ff 01 00 00 00 41 c7 86 [  564.111686] RSP: 0018:ffff8801f3117dc0 EFLAGS: 00010206 [  564.112775] RAX: 0000000000000384 RBX: 0000000000000000 RCX: ffffffffb88c1e03 [  564.114250] RDX: 0000000000000000 RSI: dffffc0000000000 RDI: ffff8801e3aa4850 [  564.115706] RBP: ffff8801f3117f00 R08: 1ffffffff751a1d0 R09: fffffbfff751a1d0 [  564.117177] R10: 0000000000000001 R11: fffffbfff751a1d0 R12: 00000000fffffffc [  564.118634] R13: ffff8801e3aa4400 R14: ffff8801f3117ed8 R15: ffff8801e2050000 [  564.120094] FS:  0000000000000000(0000) GS:ffff8801f6f00000(0000) knlGS:0000000000000000 [  564.121748] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [  564.122923] CR2: 000000000202b078 CR3: 00000001f11ac000 CR4: 00000000000006e0 [  564.124383] Call Trace: [  564.124924]  ? __issue_discard_cmd+0x480/0x480 [  564.125882]  ? __sched_text_start+0x8/0x8 [  564.126756]  ? __kthread_parkme+0xcb/0x100 [  564.127620]  ? kthread_blkcg+0x70/0x70 [  564.128412]  kthread+0x180/0x1d0 [  564.129105]  ? __issue_discard_cmd+0x480/0x480 [  564.130029]  ? kthread_associate_blkcg+0x150/0x150 [  564.131033]  ret_from_fork+0x35/0x40 [  564.131794] Modules linked in: snd_hda_codec_generic snd_hda_intel snd_hda_codec snd_hwdep snd_hda_core snd_pcm snd_timer snd mac_hid i2c_piix4 soundcore ib_iser rdma_cm iw_cm ib_cm ib_core iscsi_tcp libiscsi_tcp libiscsi scsi_transport_iscsi raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx raid1 raid0 multipath linear 8139too crct10dif_pclmul crc32_pclmul qxl drm_kms_helper syscopyarea aesni_intel sysfillrect sysimgblt fb_sys_fops ttm drm aes_x86_64 crypto_simd cryptd 8139cp glue_helper mii pata_acpi floppy [  564.141798] ---[ end trace 4ce02f25ff7d3df5 ]--- [  564.142773] RIP: 0010:issue_discard_thread+0x248/0x5c0 [  564.143885] Code: ff ff 48 8b bd e8 fe ff ff 41 8b 9d 4c 04 00 00 e8 cd b8 ad ff 41 8b 85 50 04 00 00 31 d2 48 8d 04 80 48 8d 04 80 48 c1 e0 02 <48> f7 f3 83 f8 50 7e 16 41 c7 86 7c ff ff ff 01 00 00 00 41 c7 86 [  564.147776] RSP: 0018:ffff8801f3117dc0 EFLAGS: 00010206 [  564.148856] RAX: 0000000000000384 RBX: 0000000000000000 RCX: ffffffffb88c1e03 [  564.150424] RDX: 0000000000000000 RSI: dffffc0000000000 RDI: ffff8801e3aa4850 [  564.151906] RBP: ffff8801f3117f00 R08: 1ffffffff751a1d0 R09: fffffbfff751a1d0 [  564.153463] R10: 0000000000000001 R11: fffffbfff751a1d0 R12: 00000000fffffffc [  564.154915] R13: ffff8801e3aa4400 R14: ffff8801f3117ed8 R15: ffff8801e2050000 [  564.156405] FS:  0000000000000000(0000) GS:ffff8801f6f00000(0000) knlGS:0000000000000000 [  564.158070] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [  564.159279] CR2: 000000000202b078 CR3: 00000001f11ac000 CR4: 00000000000006e0 [  564.161043] ================================================================== [  564.162587] BUG: KASAN: stack-out-of-bounds in from_kuid_munged+0x1d/0x50 [  564.163994] Read of size 4 at addr ffff8801f3117c84 by task f2fs_discard-7:/1298  [  564.165852] CPU: 1 PID: 1298 Comm: f2fs_discard-7: Tainted: G      D           4.18.0-rc1+ #4 [  564.167593] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014 [  564.169522] Call Trace: [  564.170057]  dump_stack+0x7b/0xb5 [  564.170778]  print_address_description+0x70/0x290 [  564.171765]  kasan_report+0x291/0x390 [  564.172540]  ? from_kuid_munged+0x1d/0x50 [  564.173408]  __asan_load4+0x78/0x80 [  564.174148]  from_kuid_munged+0x1d/0x50 [  564.174962]  do_notify_parent+0x1f5/0x4f0 [  564.175808]  ? send_sigqueue+0x390/0x390 [  564.176639]  ? css_set_move_task+0x152/0x340 [  564.184197]  do_exit+0x1290/0x1390 [  564.184950]  ? __issue_discard_cmd+0x480/0x480 [  564.185884]  ? mm_update_next_owner+0x380/0x380 [  564.186829]  ? __sched_text_start+0x8/0x8 [  564.187672]  ? __kthread_parkme+0xcb/0x100 [  564.188528]  ? kthread_blkcg+0x70/0x70 [  564.189333]  ? kthread+0x180/0x1d0 [  564.190052]  ? __issue_discard_cmd+0x480/0x480 [  564.190983]  rewind_stack_do_exit+0x17/0x20  [  564.192190] The buggy address belongs to the page: [  564.193213] page:ffffea0007cc45c0 count:0 mapcount:0 mapping:0000000000000000 index:0x0 [  564.194856] flags: 0x2ffff0000000000() [  564.195644] raw: 02ffff0000000000 0000000000000000 dead000000000200 0000000000000000 [  564.197247] raw: 0000000000000000 0000000000000000 00000000ffffffff 0000000000000000 [  564.198826] page dumped because: kasan: bad access detected  [  564.200299] Memory state around the buggy address: [  564.201306]  ffff8801f3117b80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 [  564.202779]  ffff8801f3117c00: 00 00 00 00 00 00 00 00 00 00 00 f3 f3 f3 f3 f3 [  564.204252] >ffff8801f3117c80: f3 f3 f3 00 00 00 00 00 00 00 00 00 f1 f1 f1 f1 [  564.205742]                    ^ [  564.206424]  ffff8801f3117d00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 [  564.207908]  ffff8801f3117d80: f3 f3 f3 f3 f3 f3 f3 f3 00 00 00 00 00 00 00 00 [  564.209389] ================================================================== [  564.231795] F2FS-fs (loop0): Mounted with checkpoint version = 2  - Location https://elixir.bootlin.com/linux/v4.18-rc1/source/fs/f2fs/segment.h#L586 \treturn div_u64((u64)valid_user_blocks(sbi) * 100, \t\t\t\t\tsbi->user_block_count); Missing checks on sbi->user_block_count.  ",
        "func_before": "int f2fs_sanity_check_ckpt(struct f2fs_sb_info *sbi)\n{\n\tunsigned int total, fsmeta;\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);\n\tunsigned int ovp_segments, reserved_segments;\n\tunsigned int main_segs, blocks_per_seg;\n\tunsigned int sit_segs, nat_segs;\n\tunsigned int sit_bitmap_size, nat_bitmap_size;\n\tunsigned int log_blocks_per_seg;\n\tint i;\n\n\ttotal = le32_to_cpu(raw_super->segment_count);\n\tfsmeta = le32_to_cpu(raw_super->segment_count_ckpt);\n\tsit_segs = le32_to_cpu(raw_super->segment_count_sit);\n\tfsmeta += sit_segs;\n\tnat_segs = le32_to_cpu(raw_super->segment_count_nat);\n\tfsmeta += nat_segs;\n\tfsmeta += le32_to_cpu(ckpt->rsvd_segment_count);\n\tfsmeta += le32_to_cpu(raw_super->segment_count_ssa);\n\n\tif (unlikely(fsmeta >= total))\n\t\treturn 1;\n\n\tovp_segments = le32_to_cpu(ckpt->overprov_segment_count);\n\treserved_segments = le32_to_cpu(ckpt->rsvd_segment_count);\n\n\tif (unlikely(fsmeta < F2FS_MIN_SEGMENTS ||\n\t\t\tovp_segments == 0 || reserved_segments == 0)) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong layout: check mkfs.f2fs version\");\n\t\treturn 1;\n\t}\n\n\tmain_segs = le32_to_cpu(raw_super->segment_count_main);\n\tblocks_per_seg = sbi->blocks_per_seg;\n\n\tfor (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_node_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_node_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\tfor (i = 0; i < NR_CURSEG_DATA_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_data_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_data_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\n\tsit_bitmap_size = le32_to_cpu(ckpt->sit_ver_bitmap_bytesize);\n\tnat_bitmap_size = le32_to_cpu(ckpt->nat_ver_bitmap_bytesize);\n\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n\n\tif (sit_bitmap_size != ((sit_segs / 2) << log_blocks_per_seg) / 8 ||\n\t\tnat_bitmap_size != ((nat_segs / 2) << log_blocks_per_seg) / 8) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong bitmap size: sit: %u, nat:%u\",\n\t\t\tsit_bitmap_size, nat_bitmap_size);\n\t\treturn 1;\n\t}\n\n\tif (unlikely(f2fs_cp_error(sbi))) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR, \"A bug case: need to run fsck\");\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "func": "int f2fs_sanity_check_ckpt(struct f2fs_sb_info *sbi)\n{\n\tunsigned int total, fsmeta;\n\tstruct f2fs_super_block *raw_super = F2FS_RAW_SUPER(sbi);\n\tstruct f2fs_checkpoint *ckpt = F2FS_CKPT(sbi);\n\tunsigned int ovp_segments, reserved_segments;\n\tunsigned int main_segs, blocks_per_seg;\n\tunsigned int sit_segs, nat_segs;\n\tunsigned int sit_bitmap_size, nat_bitmap_size;\n\tunsigned int log_blocks_per_seg;\n\tunsigned int segment_count_main;\n\tblock_t user_block_count;\n\tint i;\n\n\ttotal = le32_to_cpu(raw_super->segment_count);\n\tfsmeta = le32_to_cpu(raw_super->segment_count_ckpt);\n\tsit_segs = le32_to_cpu(raw_super->segment_count_sit);\n\tfsmeta += sit_segs;\n\tnat_segs = le32_to_cpu(raw_super->segment_count_nat);\n\tfsmeta += nat_segs;\n\tfsmeta += le32_to_cpu(ckpt->rsvd_segment_count);\n\tfsmeta += le32_to_cpu(raw_super->segment_count_ssa);\n\n\tif (unlikely(fsmeta >= total))\n\t\treturn 1;\n\n\tovp_segments = le32_to_cpu(ckpt->overprov_segment_count);\n\treserved_segments = le32_to_cpu(ckpt->rsvd_segment_count);\n\n\tif (unlikely(fsmeta < F2FS_MIN_SEGMENTS ||\n\t\t\tovp_segments == 0 || reserved_segments == 0)) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong layout: check mkfs.f2fs version\");\n\t\treturn 1;\n\t}\n\n\tuser_block_count = le64_to_cpu(ckpt->user_block_count);\n\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);\n\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n\tif (!user_block_count || user_block_count >=\n\t\t\tsegment_count_main << log_blocks_per_seg) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong user_block_count: %u\", user_block_count);\n\t\treturn 1;\n\t}\n\n\tmain_segs = le32_to_cpu(raw_super->segment_count_main);\n\tblocks_per_seg = sbi->blocks_per_seg;\n\n\tfor (i = 0; i < NR_CURSEG_NODE_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_node_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_node_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\tfor (i = 0; i < NR_CURSEG_DATA_TYPE; i++) {\n\t\tif (le32_to_cpu(ckpt->cur_data_segno[i]) >= main_segs ||\n\t\t\tle16_to_cpu(ckpt->cur_data_blkoff[i]) >= blocks_per_seg)\n\t\t\treturn 1;\n\t}\n\n\tsit_bitmap_size = le32_to_cpu(ckpt->sit_ver_bitmap_bytesize);\n\tnat_bitmap_size = le32_to_cpu(ckpt->nat_ver_bitmap_bytesize);\n\n\tif (sit_bitmap_size != ((sit_segs / 2) << log_blocks_per_seg) / 8 ||\n\t\tnat_bitmap_size != ((nat_segs / 2) << log_blocks_per_seg) / 8) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR,\n\t\t\t\"Wrong bitmap size: sit: %u, nat:%u\",\n\t\t\tsit_bitmap_size, nat_bitmap_size);\n\t\treturn 1;\n\t}\n\n\tif (unlikely(f2fs_cp_error(sbi))) {\n\t\tf2fs_msg(sbi->sb, KERN_ERR, \"A bug case: need to run fsck\");\n\t\treturn 1;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,8 @@\n \tunsigned int sit_segs, nat_segs;\n \tunsigned int sit_bitmap_size, nat_bitmap_size;\n \tunsigned int log_blocks_per_seg;\n+\tunsigned int segment_count_main;\n+\tblock_t user_block_count;\n \tint i;\n \n \ttotal = le32_to_cpu(raw_super->segment_count);\n@@ -32,6 +34,16 @@\n \t\treturn 1;\n \t}\n \n+\tuser_block_count = le64_to_cpu(ckpt->user_block_count);\n+\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);\n+\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n+\tif (!user_block_count || user_block_count >=\n+\t\t\tsegment_count_main << log_blocks_per_seg) {\n+\t\tf2fs_msg(sbi->sb, KERN_ERR,\n+\t\t\t\"Wrong user_block_count: %u\", user_block_count);\n+\t\treturn 1;\n+\t}\n+\n \tmain_segs = le32_to_cpu(raw_super->segment_count_main);\n \tblocks_per_seg = sbi->blocks_per_seg;\n \n@@ -48,7 +60,6 @@\n \n \tsit_bitmap_size = le32_to_cpu(ckpt->sit_ver_bitmap_bytesize);\n \tnat_bitmap_size = le32_to_cpu(ckpt->nat_ver_bitmap_bytesize);\n-\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);\n \n \tif (sit_bitmap_size != ((sit_segs / 2) << log_blocks_per_seg) / 8 ||\n \t\tnat_bitmap_size != ((nat_segs / 2) << log_blocks_per_seg) / 8) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);"
            ],
            "added_lines": [
                "\tunsigned int segment_count_main;",
                "\tblock_t user_block_count;",
                "\tuser_block_count = le64_to_cpu(ckpt->user_block_count);",
                "\tsegment_count_main = le32_to_cpu(raw_super->segment_count_main);",
                "\tlog_blocks_per_seg = le32_to_cpu(raw_super->log_blocks_per_seg);",
                "\tif (!user_block_count || user_block_count >=",
                "\t\t\tsegment_count_main << log_blocks_per_seg) {",
                "\t\tf2fs_msg(sbi->sb, KERN_ERR,",
                "\t\t\t\"Wrong user_block_count: %u\", user_block_count);",
                "\t\treturn 1;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2018-13100",
        "func_name": "torvalds/linux/sanity_check_raw_super",
        "description": "An issue was discovered in fs/f2fs/super.c in the Linux kernel through 4.17.3, which does not properly validate secs_per_zone in a corrupted f2fs image, as demonstrated by a divide-by-zero error.",
        "git_url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?h=42bf546c1fe3f3654bdf914e977acbc2b80a5be5",
        "commit_title": "As Wen Xu reported in below link:",
        "commit_text": " https://bugzilla.kernel.org/show_bug.cgi?id=200183  - Overview Divide zero in reset_curseg() when mounting a crafted f2fs image  - Reproduce  - Kernel message [  588.281510] divide error: 0000 [#1] SMP KASAN PTI [  588.282701] CPU: 0 PID: 1293 Comm: mount Not tainted 4.18.0-rc1+ #4 [  588.284000] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014 [  588.286178] RIP: 0010:reset_curseg+0x94/0x1a0 [  588.298166] RSP: 0018:ffff8801e88d7940 EFLAGS: 00010246 [  588.299360] RAX: 0000000000000014 RBX: ffff8801e1d46d00 RCX: ffffffffb88bf60b [  588.300809] RDX: 0000000000000000 RSI: dffffc0000000000 RDI: ffff8801e1d46d64 [  588.305272] R13: 0000000000000000 R14: 0000000000000014 R15: 0000000000000000 [  588.306822] FS:  00007fad85008840(0000) GS:ffff8801f6e00000(0000) knlGS:0000000000000000 [  588.308456] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [  588.309623] CR2: 0000000001705078 CR3: 00000001f30f8000 CR4: 00000000000006f0 [  588.311085] Call Trace: [  588.311637]  f2fs_build_segment_manager+0x103f/0x3410 [  588.316136]  ? f2fs_commit_super+0x1b0/0x1b0 [  588.317031]  ? set_blocksize+0x90/0x140 [  588.319473]  f2fs_mount+0x15/0x20 [  588.320166]  mount_fs+0x60/0x1a0 [  588.320847]  ? alloc_vfsmnt+0x309/0x360 [  588.321647]  vfs_kern_mount+0x6b/0x1a0 [  588.322432]  do_mount+0x34a/0x18c0 [  588.323175]  ? strndup_user+0x46/0x70 [  588.323937]  ? copy_mount_string+0x20/0x20 [  588.324793]  ? memcg_kmem_put_cache+0x1b/0xa0 [  588.325702]  ? kasan_check_write+0x14/0x20 [  588.326562]  ? _copy_from_user+0x6a/0x90 [  588.327375]  ? memdup_user+0x42/0x60 [  588.328118]  ksys_mount+0x83/0xd0 [  588.328808]  __x64_sys_mount+0x67/0x80 [  588.329607]  do_syscall_64+0x78/0x170 [  588.330400]  entry_SYSCALL_64_after_hwframe+0x44/0xa9 [  588.331461] RIP: 0033:0x7fad848e8b9a [  588.336022] RSP: 002b:00007ffd7c5b6be8 EFLAGS: 00000206 ORIG_RAX: 00000000000000a5 [  588.337547] RAX: ffffffffffffffda RBX: 00000000016f8030 RCX: 00007fad848e8b9a [  588.338999] RDX: 00000000016f8210 RSI: 00000000016f9f30 RDI: 0000000001700ec0 [  588.340442] RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000013 [  588.341887] R10: 00000000c0ed0000 R11: 0000000000000206 R12: 0000000001700ec0 [  588.343341] R13: 00000000016f8210 R14: 0000000000000000 R15: 0000000000000003 [  588.354891] ---[ end trace 4ce02f25ff7d3df5 ]--- [  588.355862] RIP: 0010:reset_curseg+0x94/0x1a0 [  588.360742] RSP: 0018:ffff8801e88d7940 EFLAGS: 00010246 [  588.361812] RAX: 0000000000000014 RBX: ffff8801e1d46d00 RCX: ffffffffb88bf60b [  588.363485] RDX: 0000000000000000 RSI: dffffc0000000000 RDI: ffff8801e1d46d64 [  588.365213] RBP: ffff8801e88d7968 R08: ffffed003c32266f R09: ffffed003c32266f [  588.366661] R10: 0000000000000001 R11: ffffed003c32266e R12: ffff8801f0337700 [  588.368110] R13: 0000000000000000 R14: 0000000000000014 R15: 0000000000000000 [  588.370057] FS:  00007fad85008840(0000) GS:ffff8801f6e00000(0000) knlGS:0000000000000000 [  588.372099] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033 [  588.373291] CR2: 0000000001705078 CR3: 00000001f30f8000 CR4: 00000000000006f0  - Location https://elixir.bootlin.com/linux/latest/source/fs/f2fs/segment.c#L2147         curseg->zone = GET_ZONE_FROM_SEG(sbi, curseg->segno);  If secs_per_zone is corrupted due to fuzzing test, it will cause divide zero operation when using GET_ZONE_FROM_SEG macro, so we should do more sanity check with secs_per_zone during mount to avoid this issue.  ",
        "func_before": "static int sanity_check_raw_super(struct f2fs_sb_info *sbi,\n\t\t\t\tstruct buffer_head *bh)\n{\n\tblock_t segment_count, segs_per_sec, secs_per_zone;\n\tblock_t total_sections, blocks_per_seg;\n\tstruct f2fs_super_block *raw_super = (struct f2fs_super_block *)\n\t\t\t\t\t(bh->b_data + F2FS_SUPER_OFFSET);\n\tstruct super_block *sb = sbi->sb;\n\tunsigned int blocksize;\n\n\tif (F2FS_SUPER_MAGIC != le32_to_cpu(raw_super->magic)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Magic Mismatch, valid(0x%x) - read(0x%x)\",\n\t\t\tF2FS_SUPER_MAGIC, le32_to_cpu(raw_super->magic));\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB page cache size */\n\tif (F2FS_BLKSIZE != PAGE_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid page_cache_size (%lu), supports only 4KB\\n\",\n\t\t\tPAGE_SIZE);\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB block size */\n\tblocksize = 1 << le32_to_cpu(raw_super->log_blocksize);\n\tif (blocksize != F2FS_BLKSIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid blocksize (%u), supports only 4KB\\n\",\n\t\t\tblocksize);\n\t\treturn 1;\n\t}\n\n\t/* check log blocks per segment */\n\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid log blocks per segment (%u)\\n\",\n\t\t\tle32_to_cpu(raw_super->log_blocks_per_seg));\n\t\treturn 1;\n\t}\n\n\t/* Currently, support 512/1024/2048/4096 bytes sector size */\n\tif (le32_to_cpu(raw_super->log_sectorsize) >\n\t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n\t\tle32_to_cpu(raw_super->log_sectorsize) <\n\t\t\t\tF2FS_MIN_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO, \"Invalid log sectorsize (%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\tif (le32_to_cpu(raw_super->log_sectors_per_block) +\n\t\tle32_to_cpu(raw_super->log_sectorsize) !=\n\t\t\tF2FS_MAX_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid log sectors per block(%u) log sectorsize(%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectors_per_block),\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\n\tsegment_count = le32_to_cpu(raw_super->segment_count);\n\tsegs_per_sec = le32_to_cpu(raw_super->segs_per_sec);\n\tsecs_per_zone = le32_to_cpu(raw_super->secs_per_zone);\n\ttotal_sections = le32_to_cpu(raw_super->section_count);\n\n\t/* blocks_per_seg should be 512, given the above check */\n\tblocks_per_seg = 1 << le32_to_cpu(raw_super->log_blocks_per_seg);\n\n\tif (segment_count > F2FS_MAX_SEGMENT ||\n\t\t\t\tsegment_count < F2FS_MIN_SEGMENTS) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid segment count (%u)\",\n\t\t\tsegment_count);\n\t\treturn 1;\n\t}\n\n\tif (total_sections > segment_count ||\n\t\t\ttotal_sections < F2FS_MIN_SEGMENTS ||\n\t\t\tsegs_per_sec > segment_count || !segs_per_sec) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid segment/section count (%u, %u x %u)\",\n\t\t\tsegment_count, total_sections, segs_per_sec);\n\t\treturn 1;\n\t}\n\n\tif ((segment_count / segs_per_sec) < total_sections) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Small segment_count (%u < %u * %u)\",\n\t\t\tsegment_count, segs_per_sec, total_sections);\n\t\treturn 1;\n\t}\n\n\tif (segment_count > (le32_to_cpu(raw_super->block_count) >> 9)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Wrong segment_count / block_count (%u > %u)\",\n\t\t\tsegment_count, le32_to_cpu(raw_super->block_count));\n\t\treturn 1;\n\t}\n\n\tif (secs_per_zone > total_sections) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Wrong secs_per_zone (%u > %u)\",\n\t\t\tsecs_per_zone, total_sections);\n\t\treturn 1;\n\t}\n\tif (le32_to_cpu(raw_super->extension_count) > F2FS_MAX_EXTENSION ||\n\t\t\traw_super->hot_ext_count > F2FS_MAX_EXTENSION ||\n\t\t\t(le32_to_cpu(raw_super->extension_count) +\n\t\t\traw_super->hot_ext_count) > F2FS_MAX_EXTENSION) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Corrupted extension count (%u + %u > %u)\",\n\t\t\tle32_to_cpu(raw_super->extension_count),\n\t\t\traw_super->hot_ext_count,\n\t\t\tF2FS_MAX_EXTENSION);\n\t\treturn 1;\n\t}\n\n\tif (le32_to_cpu(raw_super->cp_payload) >\n\t\t\t\t(blocks_per_seg - F2FS_CP_PACKS)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Insane cp_payload (%u > %u)\",\n\t\t\tle32_to_cpu(raw_super->cp_payload),\n\t\t\tblocks_per_seg - F2FS_CP_PACKS);\n\t\treturn 1;\n\t}\n\n\t/* check reserved ino info */\n\tif (le32_to_cpu(raw_super->node_ino) != 1 ||\n\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||\n\t\tle32_to_cpu(raw_super->root_ino) != 3) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",\n\t\t\tle32_to_cpu(raw_super->node_ino),\n\t\t\tle32_to_cpu(raw_super->meta_ino),\n\t\t\tle32_to_cpu(raw_super->root_ino));\n\t\treturn 1;\n\t}\n\n\t/* check CP/SIT/NAT/SSA/MAIN_AREA area boundary */\n\tif (sanity_check_area_boundary(sbi, bh))\n\t\treturn 1;\n\n\treturn 0;\n}",
        "func": "static int sanity_check_raw_super(struct f2fs_sb_info *sbi,\n\t\t\t\tstruct buffer_head *bh)\n{\n\tblock_t segment_count, segs_per_sec, secs_per_zone;\n\tblock_t total_sections, blocks_per_seg;\n\tstruct f2fs_super_block *raw_super = (struct f2fs_super_block *)\n\t\t\t\t\t(bh->b_data + F2FS_SUPER_OFFSET);\n\tstruct super_block *sb = sbi->sb;\n\tunsigned int blocksize;\n\n\tif (F2FS_SUPER_MAGIC != le32_to_cpu(raw_super->magic)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Magic Mismatch, valid(0x%x) - read(0x%x)\",\n\t\t\tF2FS_SUPER_MAGIC, le32_to_cpu(raw_super->magic));\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB page cache size */\n\tif (F2FS_BLKSIZE != PAGE_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid page_cache_size (%lu), supports only 4KB\\n\",\n\t\t\tPAGE_SIZE);\n\t\treturn 1;\n\t}\n\n\t/* Currently, support only 4KB block size */\n\tblocksize = 1 << le32_to_cpu(raw_super->log_blocksize);\n\tif (blocksize != F2FS_BLKSIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid blocksize (%u), supports only 4KB\\n\",\n\t\t\tblocksize);\n\t\treturn 1;\n\t}\n\n\t/* check log blocks per segment */\n\tif (le32_to_cpu(raw_super->log_blocks_per_seg) != 9) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid log blocks per segment (%u)\\n\",\n\t\t\tle32_to_cpu(raw_super->log_blocks_per_seg));\n\t\treturn 1;\n\t}\n\n\t/* Currently, support 512/1024/2048/4096 bytes sector size */\n\tif (le32_to_cpu(raw_super->log_sectorsize) >\n\t\t\t\tF2FS_MAX_LOG_SECTOR_SIZE ||\n\t\tle32_to_cpu(raw_super->log_sectorsize) <\n\t\t\t\tF2FS_MIN_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO, \"Invalid log sectorsize (%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\tif (le32_to_cpu(raw_super->log_sectors_per_block) +\n\t\tle32_to_cpu(raw_super->log_sectorsize) !=\n\t\t\tF2FS_MAX_LOG_SECTOR_SIZE) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid log sectors per block(%u) log sectorsize(%u)\",\n\t\t\tle32_to_cpu(raw_super->log_sectors_per_block),\n\t\t\tle32_to_cpu(raw_super->log_sectorsize));\n\t\treturn 1;\n\t}\n\n\tsegment_count = le32_to_cpu(raw_super->segment_count);\n\tsegs_per_sec = le32_to_cpu(raw_super->segs_per_sec);\n\tsecs_per_zone = le32_to_cpu(raw_super->secs_per_zone);\n\ttotal_sections = le32_to_cpu(raw_super->section_count);\n\n\t/* blocks_per_seg should be 512, given the above check */\n\tblocks_per_seg = 1 << le32_to_cpu(raw_super->log_blocks_per_seg);\n\n\tif (segment_count > F2FS_MAX_SEGMENT ||\n\t\t\t\tsegment_count < F2FS_MIN_SEGMENTS) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid segment count (%u)\",\n\t\t\tsegment_count);\n\t\treturn 1;\n\t}\n\n\tif (total_sections > segment_count ||\n\t\t\ttotal_sections < F2FS_MIN_SEGMENTS ||\n\t\t\tsegs_per_sec > segment_count || !segs_per_sec) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid segment/section count (%u, %u x %u)\",\n\t\t\tsegment_count, total_sections, segs_per_sec);\n\t\treturn 1;\n\t}\n\n\tif ((segment_count / segs_per_sec) < total_sections) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Small segment_count (%u < %u * %u)\",\n\t\t\tsegment_count, segs_per_sec, total_sections);\n\t\treturn 1;\n\t}\n\n\tif (segment_count > (le32_to_cpu(raw_super->block_count) >> 9)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Wrong segment_count / block_count (%u > %u)\",\n\t\t\tsegment_count, le32_to_cpu(raw_super->block_count));\n\t\treturn 1;\n\t}\n\n\tif (secs_per_zone > total_sections || !secs_per_zone) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Wrong secs_per_zone / total_sections (%u, %u)\",\n\t\t\tsecs_per_zone, total_sections);\n\t\treturn 1;\n\t}\n\tif (le32_to_cpu(raw_super->extension_count) > F2FS_MAX_EXTENSION ||\n\t\t\traw_super->hot_ext_count > F2FS_MAX_EXTENSION ||\n\t\t\t(le32_to_cpu(raw_super->extension_count) +\n\t\t\traw_super->hot_ext_count) > F2FS_MAX_EXTENSION) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Corrupted extension count (%u + %u > %u)\",\n\t\t\tle32_to_cpu(raw_super->extension_count),\n\t\t\traw_super->hot_ext_count,\n\t\t\tF2FS_MAX_EXTENSION);\n\t\treturn 1;\n\t}\n\n\tif (le32_to_cpu(raw_super->cp_payload) >\n\t\t\t\t(blocks_per_seg - F2FS_CP_PACKS)) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Insane cp_payload (%u > %u)\",\n\t\t\tle32_to_cpu(raw_super->cp_payload),\n\t\t\tblocks_per_seg - F2FS_CP_PACKS);\n\t\treturn 1;\n\t}\n\n\t/* check reserved ino info */\n\tif (le32_to_cpu(raw_super->node_ino) != 1 ||\n\t\tle32_to_cpu(raw_super->meta_ino) != 2 ||\n\t\tle32_to_cpu(raw_super->root_ino) != 3) {\n\t\tf2fs_msg(sb, KERN_INFO,\n\t\t\t\"Invalid Fs Meta Ino: node(%u) meta(%u) root(%u)\",\n\t\t\tle32_to_cpu(raw_super->node_ino),\n\t\t\tle32_to_cpu(raw_super->meta_ino),\n\t\t\tle32_to_cpu(raw_super->root_ino));\n\t\treturn 1;\n\t}\n\n\t/* check CP/SIT/NAT/SSA/MAIN_AREA area boundary */\n\tif (sanity_check_area_boundary(sbi, bh))\n\t\treturn 1;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -98,9 +98,9 @@\n \t\treturn 1;\n \t}\n \n-\tif (secs_per_zone > total_sections) {\n+\tif (secs_per_zone > total_sections || !secs_per_zone) {\n \t\tf2fs_msg(sb, KERN_INFO,\n-\t\t\t\"Wrong secs_per_zone (%u > %u)\",\n+\t\t\t\"Wrong secs_per_zone / total_sections (%u, %u)\",\n \t\t\tsecs_per_zone, total_sections);\n \t\treturn 1;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (secs_per_zone > total_sections) {",
                "\t\t\t\"Wrong secs_per_zone (%u > %u)\","
            ],
            "added_lines": [
                "\tif (secs_per_zone > total_sections || !secs_per_zone) {",
                "\t\t\t\"Wrong secs_per_zone / total_sections (%u, %u)\","
            ]
        }
    },
    {
        "cve_id": "CVE-2018-13785",
        "func_name": "pnggroup/libpng/png_check_chunk_length",
        "description": "In libpng 1.6.34, a wrong calculation of row_factor in the png_check_chunk_length function (pngrutil.c) may trigger an integer overflow and resultant divide-by-zero while processing a crafted PNG file, leading to a denial of service.",
        "git_url": "https://github.com/pnggroup/libpng/commit/8a05766cb74af05c04c53e6c9d60c13fc4d59bf2",
        "commit_title": "[libpng16] Fix the calculation of row_factor in png_check_chunk_length",
        "commit_text": " (Bug report by Thuan Pham, SourceForge issue #278)",
        "func_before": "void /* PRIVATE */\npng_check_chunk_length(png_const_structrp png_ptr, const png_uint_32 length)\n{\n   png_alloc_size_t limit = PNG_UINT_31_MAX;\n\n# ifdef PNG_SET_USER_LIMITS_SUPPORTED\n   if (png_ptr->user_chunk_malloc_max > 0 &&\n       png_ptr->user_chunk_malloc_max < limit)\n      limit = png_ptr->user_chunk_malloc_max;\n# elif PNG_USER_CHUNK_MALLOC_MAX > 0\n   if (PNG_USER_CHUNK_MALLOC_MAX < limit)\n      limit = PNG_USER_CHUNK_MALLOC_MAX;\n# endif\n   if (png_ptr->chunk_name == png_IDAT)\n   {\n      png_alloc_size_t idat_limit = PNG_UINT_31_MAX;\n      size_t row_factor =\n         (png_ptr->width * png_ptr->channels * (png_ptr->bit_depth > 8? 2: 1)\n          + 1 + (png_ptr->interlaced? 6: 0));\n      if (png_ptr->height > PNG_UINT_32_MAX/row_factor)\n         idat_limit=PNG_UINT_31_MAX;\n      else\n         idat_limit = png_ptr->height * row_factor;\n      row_factor = row_factor > 32566? 32566 : row_factor;\n      idat_limit += 6 + 5*(idat_limit/row_factor+1); /* zlib+deflate overhead */\n      idat_limit=idat_limit < PNG_UINT_31_MAX? idat_limit : PNG_UINT_31_MAX;\n      limit = limit < idat_limit? idat_limit : limit;\n   }\n\n   if (length > limit)\n   {\n      png_debug2(0,\" length = %lu, limit = %lu\",\n         (unsigned long)length,(unsigned long)limit);\n      png_chunk_error(png_ptr, \"chunk data is too large\");\n   }\n}",
        "func": "void /* PRIVATE */\npng_check_chunk_length(png_const_structrp png_ptr, const png_uint_32 length)\n{\n   png_alloc_size_t limit = PNG_UINT_31_MAX;\n\n# ifdef PNG_SET_USER_LIMITS_SUPPORTED\n   if (png_ptr->user_chunk_malloc_max > 0 &&\n       png_ptr->user_chunk_malloc_max < limit)\n      limit = png_ptr->user_chunk_malloc_max;\n# elif PNG_USER_CHUNK_MALLOC_MAX > 0\n   if (PNG_USER_CHUNK_MALLOC_MAX < limit)\n      limit = PNG_USER_CHUNK_MALLOC_MAX;\n# endif\n   if (png_ptr->chunk_name == png_IDAT)\n   {\n      png_alloc_size_t idat_limit = PNG_UINT_31_MAX;\n      size_t row_factor =\n         (size_t)png_ptr->width\n         * (size_t)png_ptr->channels\n         * (png_ptr->bit_depth > 8? 2: 1)\n         + 1\n         + (png_ptr->interlaced? 6: 0);\n      if (png_ptr->height > PNG_UINT_32_MAX/row_factor)\n         idat_limit = PNG_UINT_31_MAX;\n      else\n         idat_limit = png_ptr->height * row_factor;\n      row_factor = row_factor > 32566? 32566 : row_factor;\n      idat_limit += 6 + 5*(idat_limit/row_factor+1); /* zlib+deflate overhead */\n      idat_limit=idat_limit < PNG_UINT_31_MAX? idat_limit : PNG_UINT_31_MAX;\n      limit = limit < idat_limit? idat_limit : limit;\n   }\n\n   if (length > limit)\n   {\n      png_debug2(0,\" length = %lu, limit = %lu\",\n         (unsigned long)length,(unsigned long)limit);\n      png_chunk_error(png_ptr, \"chunk data is too large\");\n   }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,10 +15,13 @@\n    {\n       png_alloc_size_t idat_limit = PNG_UINT_31_MAX;\n       size_t row_factor =\n-         (png_ptr->width * png_ptr->channels * (png_ptr->bit_depth > 8? 2: 1)\n-          + 1 + (png_ptr->interlaced? 6: 0));\n+         (size_t)png_ptr->width\n+         * (size_t)png_ptr->channels\n+         * (png_ptr->bit_depth > 8? 2: 1)\n+         + 1\n+         + (png_ptr->interlaced? 6: 0);\n       if (png_ptr->height > PNG_UINT_32_MAX/row_factor)\n-         idat_limit=PNG_UINT_31_MAX;\n+         idat_limit = PNG_UINT_31_MAX;\n       else\n          idat_limit = png_ptr->height * row_factor;\n       row_factor = row_factor > 32566? 32566 : row_factor;",
        "diff_line_info": {
            "deleted_lines": [
                "         (png_ptr->width * png_ptr->channels * (png_ptr->bit_depth > 8? 2: 1)",
                "          + 1 + (png_ptr->interlaced? 6: 0));",
                "         idat_limit=PNG_UINT_31_MAX;"
            ],
            "added_lines": [
                "         (size_t)png_ptr->width",
                "         * (size_t)png_ptr->channels",
                "         * (png_ptr->bit_depth > 8? 2: 1)",
                "         + 1",
                "         + (png_ptr->interlaced? 6: 0);",
                "         idat_limit = PNG_UINT_31_MAX;"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-14394",
        "func_name": "ffmpeg/ff_mov_write_packet",
        "description": "libavformat/movenc.c in FFmpeg before 4.0.2 allows attackers to cause a denial of service (application crash caused by a divide-by-zero error) with a user crafted Waveform audio file.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/3a2d21bc5f97aa0161db3ae731fc2732be6108b8",
        "commit_title": "avformat/movenc: Check input sample count",
        "commit_text": " ",
        "func_before": "int ff_mov_write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    MOVMuxContext *mov = s->priv_data;\n    AVIOContext *pb = s->pb;\n    MOVTrack *trk = &mov->tracks[pkt->stream_index];\n    AVCodecParameters *par = trk->par;\n    unsigned int samples_in_chunk = 0;\n    int size = pkt->size, ret = 0;\n    uint8_t *reformatted_data = NULL;\n\n    ret = check_pkt(s, pkt);\n    if (ret < 0)\n        return ret;\n\n    if (mov->flags & FF_MOV_FLAG_FRAGMENT) {\n        int ret;\n        if (mov->moov_written || mov->flags & FF_MOV_FLAG_EMPTY_MOOV) {\n            if (mov->frag_interleave && mov->fragments > 0) {\n                if (trk->entry - trk->entries_flushed >= mov->frag_interleave) {\n                    if ((ret = mov_flush_fragment_interleaving(s, trk)) < 0)\n                        return ret;\n                }\n            }\n\n            if (!trk->mdat_buf) {\n                if ((ret = avio_open_dyn_buf(&trk->mdat_buf)) < 0)\n                    return ret;\n            }\n            pb = trk->mdat_buf;\n        } else {\n            if (!mov->mdat_buf) {\n                if ((ret = avio_open_dyn_buf(&mov->mdat_buf)) < 0)\n                    return ret;\n            }\n            pb = mov->mdat_buf;\n        }\n    }\n\n    if (par->codec_id == AV_CODEC_ID_AMR_NB) {\n        /* We must find out how many AMR blocks there are in one packet */\n        static const uint16_t packed_size[16] =\n            {13, 14, 16, 18, 20, 21, 27, 32, 6, 0, 0, 0, 0, 0, 0, 1};\n        int len = 0;\n\n        while (len < size && samples_in_chunk < 100) {\n            len += packed_size[(pkt->data[len] >> 3) & 0x0F];\n            samples_in_chunk++;\n        }\n        if (samples_in_chunk > 1) {\n            av_log(s, AV_LOG_ERROR, \"fatal error, input is not a single packet, implement a AVParser for it\\n\");\n            return -1;\n        }\n    } else if (par->codec_id == AV_CODEC_ID_ADPCM_MS ||\n               par->codec_id == AV_CODEC_ID_ADPCM_IMA_WAV) {\n        samples_in_chunk = trk->par->frame_size;\n    } else if (trk->sample_size)\n        samples_in_chunk = size / trk->sample_size;\n    else\n        samples_in_chunk = 1;\n\n    /* copy extradata if it exists */\n    if (trk->vos_len == 0 && par->extradata_size > 0 &&\n        !TAG_IS_AVCI(trk->tag) &&\n        (par->codec_id != AV_CODEC_ID_DNXHD)) {\n        trk->vos_len  = par->extradata_size;\n        trk->vos_data = av_malloc(trk->vos_len);\n        if (!trk->vos_data) {\n            ret = AVERROR(ENOMEM);\n            goto err;\n        }\n        memcpy(trk->vos_data, par->extradata, trk->vos_len);\n    }\n\n    if (par->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&\n        (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {\n        if (!s->streams[pkt->stream_index]->nb_frames) {\n            av_log(s, AV_LOG_ERROR, \"Malformed AAC bitstream detected: \"\n                   \"use the audio bitstream filter 'aac_adtstoasc' to fix it \"\n                   \"('-bsf:a aac_adtstoasc' option with ffmpeg)\\n\");\n            return -1;\n        }\n        av_log(s, AV_LOG_WARNING, \"aac bitstream error\\n\");\n    }\n    if (par->codec_id == AV_CODEC_ID_H264 && trk->vos_len > 0 && *(uint8_t *)trk->vos_data != 1 && !TAG_IS_AVCI(trk->tag)) {\n        /* from x264 or from bytestream H.264 */\n        /* NAL reformatting needed */\n        if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams) {\n            ff_avc_parse_nal_units_buf(pkt->data, &reformatted_data,\n                                       &size);\n            avio_write(pb, reformatted_data, size);\n        } else {\n            if (trk->cenc.aes_ctr) {\n                size = ff_mov_cenc_avc_parse_nal_units(&trk->cenc, pb, pkt->data, size);\n                if (size < 0) {\n                    ret = size;\n                    goto err;\n                }\n            } else {\n                size = ff_avc_parse_nal_units(pb, pkt->data, pkt->size);\n            }\n        }\n    } else if (par->codec_id == AV_CODEC_ID_HEVC && trk->vos_len > 6 &&\n               (AV_RB24(trk->vos_data) == 1 || AV_RB32(trk->vos_data) == 1)) {\n        /* extradata is Annex B, assume the bitstream is too and convert it */\n        if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams) {\n            ff_hevc_annexb2mp4_buf(pkt->data, &reformatted_data, &size, 0, NULL);\n            avio_write(pb, reformatted_data, size);\n        } else {\n            size = ff_hevc_annexb2mp4(pb, pkt->data, pkt->size, 0, NULL);\n        }\n#if CONFIG_AC3_PARSER\n    } else if (par->codec_id == AV_CODEC_ID_EAC3) {\n        size = handle_eac3(mov, pkt, trk);\n        if (size < 0)\n            return size;\n        else if (!size)\n            goto end;\n        avio_write(pb, pkt->data, size);\n#endif\n    } else {\n        if (trk->cenc.aes_ctr) {\n            if (par->codec_id == AV_CODEC_ID_H264 && par->extradata_size > 4) {\n                int nal_size_length = (par->extradata[4] & 0x3) + 1;\n                ret = ff_mov_cenc_avc_write_nal_units(s, &trk->cenc, nal_size_length, pb, pkt->data, size);\n            } else {\n                ret = ff_mov_cenc_write_packet(&trk->cenc, pb, pkt->data, size);\n            }\n\n            if (ret) {\n                goto err;\n            }\n        } else {\n            avio_write(pb, pkt->data, size);\n        }\n    }\n\n    if ((par->codec_id == AV_CODEC_ID_DNXHD ||\n         par->codec_id == AV_CODEC_ID_AC3) && !trk->vos_len) {\n        /* copy frame to create needed atoms */\n        trk->vos_len  = size;\n        trk->vos_data = av_malloc(size);\n        if (!trk->vos_data) {\n            ret = AVERROR(ENOMEM);\n            goto err;\n        }\n        memcpy(trk->vos_data, pkt->data, size);\n    }\n\n    if (trk->entry >= trk->cluster_capacity) {\n        unsigned new_capacity = 2 * (trk->entry + MOV_INDEX_CLUSTER_SIZE);\n        if (av_reallocp_array(&trk->cluster, new_capacity,\n                              sizeof(*trk->cluster))) {\n            ret = AVERROR(ENOMEM);\n            goto err;\n        }\n        trk->cluster_capacity = new_capacity;\n    }\n\n    trk->cluster[trk->entry].pos              = avio_tell(pb) - size;\n    trk->cluster[trk->entry].samples_in_chunk = samples_in_chunk;\n    trk->cluster[trk->entry].chunkNum         = 0;\n    trk->cluster[trk->entry].size             = size;\n    trk->cluster[trk->entry].entries          = samples_in_chunk;\n    trk->cluster[trk->entry].dts              = pkt->dts;\n    trk->cluster[trk->entry].pts              = pkt->pts;\n    if (!trk->entry && trk->start_dts != AV_NOPTS_VALUE) {\n        if (!trk->frag_discont) {\n            /* First packet of a new fragment. We already wrote the duration\n             * of the last packet of the previous fragment based on track_duration,\n             * which might not exactly match our dts. Therefore adjust the dts\n             * of this packet to be what the previous packets duration implies. */\n            trk->cluster[trk->entry].dts = trk->start_dts + trk->track_duration;\n            /* We also may have written the pts and the corresponding duration\n             * in sidx/tfrf/tfxd tags; make sure the sidx pts and duration match up with\n             * the next fragment. This means the cts of the first sample must\n             * be the same in all fragments, unless end_pts was updated by\n             * the packet causing the fragment to be written. */\n            if ((mov->flags & FF_MOV_FLAG_DASH && !(mov->flags & FF_MOV_FLAG_GLOBAL_SIDX)) ||\n                mov->mode == MODE_ISM)\n                pkt->pts = pkt->dts + trk->end_pts - trk->cluster[trk->entry].dts;\n        } else {\n            /* New fragment, but discontinuous from previous fragments.\n             * Pretend the duration sum of the earlier fragments is\n             * pkt->dts - trk->start_dts. */\n            trk->frag_start = pkt->dts - trk->start_dts;\n            trk->end_pts = AV_NOPTS_VALUE;\n            trk->frag_discont = 0;\n        }\n    }\n\n    if (!trk->entry && trk->start_dts == AV_NOPTS_VALUE && !mov->use_editlist &&\n        s->avoid_negative_ts == AVFMT_AVOID_NEG_TS_MAKE_ZERO) {\n        /* Not using edit lists and shifting the first track to start from zero.\n         * If the other streams start from a later timestamp, we won't be able\n         * to signal the difference in starting time without an edit list.\n         * Thus move the timestamp for this first sample to 0, increasing\n         * its duration instead. */\n        trk->cluster[trk->entry].dts = trk->start_dts = 0;\n    }\n    if (trk->start_dts == AV_NOPTS_VALUE) {\n        trk->start_dts = pkt->dts;\n        if (trk->frag_discont) {\n            if (mov->use_editlist) {\n                /* Pretend the whole stream started at pts=0, with earlier fragments\n                 * already written. If the stream started at pts=0, the duration sum\n                 * of earlier fragments would have been pkt->pts. */\n                trk->frag_start = pkt->pts;\n                trk->start_dts  = pkt->dts - pkt->pts;\n            } else {\n                /* Pretend the whole stream started at dts=0, with earlier fragments\n                 * already written, with a duration summing up to pkt->dts. */\n                trk->frag_start = pkt->dts;\n                trk->start_dts  = 0;\n            }\n            trk->frag_discont = 0;\n        } else if (pkt->dts && mov->moov_written)\n            av_log(s, AV_LOG_WARNING,\n                   \"Track %d starts with a nonzero dts %\"PRId64\", while the moov \"\n                   \"already has been written. Set the delay_moov flag to handle \"\n                   \"this case.\\n\",\n                   pkt->stream_index, pkt->dts);\n    }\n    trk->track_duration = pkt->dts - trk->start_dts + pkt->duration;\n    trk->last_sample_is_subtitle_end = 0;\n\n    if (pkt->pts == AV_NOPTS_VALUE) {\n        av_log(s, AV_LOG_WARNING, \"pts has no value\\n\");\n        pkt->pts = pkt->dts;\n    }\n    if (pkt->dts != pkt->pts)\n        trk->flags |= MOV_TRACK_CTTS;\n    trk->cluster[trk->entry].cts   = pkt->pts - pkt->dts;\n    trk->cluster[trk->entry].flags = 0;\n    if (trk->start_cts == AV_NOPTS_VALUE)\n        trk->start_cts = pkt->pts - pkt->dts;\n    if (trk->end_pts == AV_NOPTS_VALUE)\n        trk->end_pts = trk->cluster[trk->entry].dts +\n                       trk->cluster[trk->entry].cts + pkt->duration;\n    else\n        trk->end_pts = FFMAX(trk->end_pts, trk->cluster[trk->entry].dts +\n                                           trk->cluster[trk->entry].cts +\n                                           pkt->duration);\n\n    if (par->codec_id == AV_CODEC_ID_VC1) {\n        mov_parse_vc1_frame(pkt, trk);\n    } else if (pkt->flags & AV_PKT_FLAG_KEY) {\n        if (mov->mode == MODE_MOV && par->codec_id == AV_CODEC_ID_MPEG2VIDEO &&\n            trk->entry > 0) { // force sync sample for the first key frame\n            mov_parse_mpeg2_frame(pkt, &trk->cluster[trk->entry].flags);\n            if (trk->cluster[trk->entry].flags & MOV_PARTIAL_SYNC_SAMPLE)\n                trk->flags |= MOV_TRACK_STPS;\n        } else {\n            trk->cluster[trk->entry].flags = MOV_SYNC_SAMPLE;\n        }\n        if (trk->cluster[trk->entry].flags & MOV_SYNC_SAMPLE)\n            trk->has_keyframes++;\n    }\n    if (pkt->flags & AV_PKT_FLAG_DISPOSABLE) {\n        trk->cluster[trk->entry].flags |= MOV_DISPOSABLE_SAMPLE;\n        trk->has_disposable++;\n    }\n    trk->entry++;\n    trk->sample_count += samples_in_chunk;\n    mov->mdat_size    += size;\n\n    if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams)\n        ff_mov_add_hinted_packet(s, pkt, trk->hint_track, trk->entry,\n                                 reformatted_data, size);\n\nend:\nerr:\n\n    av_free(reformatted_data);\n    return ret;\n}",
        "func": "int ff_mov_write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    MOVMuxContext *mov = s->priv_data;\n    AVIOContext *pb = s->pb;\n    MOVTrack *trk = &mov->tracks[pkt->stream_index];\n    AVCodecParameters *par = trk->par;\n    unsigned int samples_in_chunk = 0;\n    int size = pkt->size, ret = 0;\n    uint8_t *reformatted_data = NULL;\n\n    ret = check_pkt(s, pkt);\n    if (ret < 0)\n        return ret;\n\n    if (mov->flags & FF_MOV_FLAG_FRAGMENT) {\n        int ret;\n        if (mov->moov_written || mov->flags & FF_MOV_FLAG_EMPTY_MOOV) {\n            if (mov->frag_interleave && mov->fragments > 0) {\n                if (trk->entry - trk->entries_flushed >= mov->frag_interleave) {\n                    if ((ret = mov_flush_fragment_interleaving(s, trk)) < 0)\n                        return ret;\n                }\n            }\n\n            if (!trk->mdat_buf) {\n                if ((ret = avio_open_dyn_buf(&trk->mdat_buf)) < 0)\n                    return ret;\n            }\n            pb = trk->mdat_buf;\n        } else {\n            if (!mov->mdat_buf) {\n                if ((ret = avio_open_dyn_buf(&mov->mdat_buf)) < 0)\n                    return ret;\n            }\n            pb = mov->mdat_buf;\n        }\n    }\n\n    if (par->codec_id == AV_CODEC_ID_AMR_NB) {\n        /* We must find out how many AMR blocks there are in one packet */\n        static const uint16_t packed_size[16] =\n            {13, 14, 16, 18, 20, 21, 27, 32, 6, 0, 0, 0, 0, 0, 0, 1};\n        int len = 0;\n\n        while (len < size && samples_in_chunk < 100) {\n            len += packed_size[(pkt->data[len] >> 3) & 0x0F];\n            samples_in_chunk++;\n        }\n        if (samples_in_chunk > 1) {\n            av_log(s, AV_LOG_ERROR, \"fatal error, input is not a single packet, implement a AVParser for it\\n\");\n            return -1;\n        }\n    } else if (par->codec_id == AV_CODEC_ID_ADPCM_MS ||\n               par->codec_id == AV_CODEC_ID_ADPCM_IMA_WAV) {\n        samples_in_chunk = trk->par->frame_size;\n    } else if (trk->sample_size)\n        samples_in_chunk = size / trk->sample_size;\n    else\n        samples_in_chunk = 1;\n\n    if (samples_in_chunk < 1) {\n        av_log(s, AV_LOG_ERROR, \"fatal error, input packet contains no samples\\n\");\n        return AVERROR_PATCHWELCOME;\n    }\n\n    /* copy extradata if it exists */\n    if (trk->vos_len == 0 && par->extradata_size > 0 &&\n        !TAG_IS_AVCI(trk->tag) &&\n        (par->codec_id != AV_CODEC_ID_DNXHD)) {\n        trk->vos_len  = par->extradata_size;\n        trk->vos_data = av_malloc(trk->vos_len);\n        if (!trk->vos_data) {\n            ret = AVERROR(ENOMEM);\n            goto err;\n        }\n        memcpy(trk->vos_data, par->extradata, trk->vos_len);\n    }\n\n    if (par->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&\n        (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {\n        if (!s->streams[pkt->stream_index]->nb_frames) {\n            av_log(s, AV_LOG_ERROR, \"Malformed AAC bitstream detected: \"\n                   \"use the audio bitstream filter 'aac_adtstoasc' to fix it \"\n                   \"('-bsf:a aac_adtstoasc' option with ffmpeg)\\n\");\n            return -1;\n        }\n        av_log(s, AV_LOG_WARNING, \"aac bitstream error\\n\");\n    }\n    if (par->codec_id == AV_CODEC_ID_H264 && trk->vos_len > 0 && *(uint8_t *)trk->vos_data != 1 && !TAG_IS_AVCI(trk->tag)) {\n        /* from x264 or from bytestream H.264 */\n        /* NAL reformatting needed */\n        if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams) {\n            ff_avc_parse_nal_units_buf(pkt->data, &reformatted_data,\n                                       &size);\n            avio_write(pb, reformatted_data, size);\n        } else {\n            if (trk->cenc.aes_ctr) {\n                size = ff_mov_cenc_avc_parse_nal_units(&trk->cenc, pb, pkt->data, size);\n                if (size < 0) {\n                    ret = size;\n                    goto err;\n                }\n            } else {\n                size = ff_avc_parse_nal_units(pb, pkt->data, pkt->size);\n            }\n        }\n    } else if (par->codec_id == AV_CODEC_ID_HEVC && trk->vos_len > 6 &&\n               (AV_RB24(trk->vos_data) == 1 || AV_RB32(trk->vos_data) == 1)) {\n        /* extradata is Annex B, assume the bitstream is too and convert it */\n        if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams) {\n            ff_hevc_annexb2mp4_buf(pkt->data, &reformatted_data, &size, 0, NULL);\n            avio_write(pb, reformatted_data, size);\n        } else {\n            size = ff_hevc_annexb2mp4(pb, pkt->data, pkt->size, 0, NULL);\n        }\n#if CONFIG_AC3_PARSER\n    } else if (par->codec_id == AV_CODEC_ID_EAC3) {\n        size = handle_eac3(mov, pkt, trk);\n        if (size < 0)\n            return size;\n        else if (!size)\n            goto end;\n        avio_write(pb, pkt->data, size);\n#endif\n    } else {\n        if (trk->cenc.aes_ctr) {\n            if (par->codec_id == AV_CODEC_ID_H264 && par->extradata_size > 4) {\n                int nal_size_length = (par->extradata[4] & 0x3) + 1;\n                ret = ff_mov_cenc_avc_write_nal_units(s, &trk->cenc, nal_size_length, pb, pkt->data, size);\n            } else {\n                ret = ff_mov_cenc_write_packet(&trk->cenc, pb, pkt->data, size);\n            }\n\n            if (ret) {\n                goto err;\n            }\n        } else {\n            avio_write(pb, pkt->data, size);\n        }\n    }\n\n    if ((par->codec_id == AV_CODEC_ID_DNXHD ||\n         par->codec_id == AV_CODEC_ID_AC3) && !trk->vos_len) {\n        /* copy frame to create needed atoms */\n        trk->vos_len  = size;\n        trk->vos_data = av_malloc(size);\n        if (!trk->vos_data) {\n            ret = AVERROR(ENOMEM);\n            goto err;\n        }\n        memcpy(trk->vos_data, pkt->data, size);\n    }\n\n    if (trk->entry >= trk->cluster_capacity) {\n        unsigned new_capacity = 2 * (trk->entry + MOV_INDEX_CLUSTER_SIZE);\n        if (av_reallocp_array(&trk->cluster, new_capacity,\n                              sizeof(*trk->cluster))) {\n            ret = AVERROR(ENOMEM);\n            goto err;\n        }\n        trk->cluster_capacity = new_capacity;\n    }\n\n    trk->cluster[trk->entry].pos              = avio_tell(pb) - size;\n    trk->cluster[trk->entry].samples_in_chunk = samples_in_chunk;\n    trk->cluster[trk->entry].chunkNum         = 0;\n    trk->cluster[trk->entry].size             = size;\n    trk->cluster[trk->entry].entries          = samples_in_chunk;\n    trk->cluster[trk->entry].dts              = pkt->dts;\n    trk->cluster[trk->entry].pts              = pkt->pts;\n    if (!trk->entry && trk->start_dts != AV_NOPTS_VALUE) {\n        if (!trk->frag_discont) {\n            /* First packet of a new fragment. We already wrote the duration\n             * of the last packet of the previous fragment based on track_duration,\n             * which might not exactly match our dts. Therefore adjust the dts\n             * of this packet to be what the previous packets duration implies. */\n            trk->cluster[trk->entry].dts = trk->start_dts + trk->track_duration;\n            /* We also may have written the pts and the corresponding duration\n             * in sidx/tfrf/tfxd tags; make sure the sidx pts and duration match up with\n             * the next fragment. This means the cts of the first sample must\n             * be the same in all fragments, unless end_pts was updated by\n             * the packet causing the fragment to be written. */\n            if ((mov->flags & FF_MOV_FLAG_DASH && !(mov->flags & FF_MOV_FLAG_GLOBAL_SIDX)) ||\n                mov->mode == MODE_ISM)\n                pkt->pts = pkt->dts + trk->end_pts - trk->cluster[trk->entry].dts;\n        } else {\n            /* New fragment, but discontinuous from previous fragments.\n             * Pretend the duration sum of the earlier fragments is\n             * pkt->dts - trk->start_dts. */\n            trk->frag_start = pkt->dts - trk->start_dts;\n            trk->end_pts = AV_NOPTS_VALUE;\n            trk->frag_discont = 0;\n        }\n    }\n\n    if (!trk->entry && trk->start_dts == AV_NOPTS_VALUE && !mov->use_editlist &&\n        s->avoid_negative_ts == AVFMT_AVOID_NEG_TS_MAKE_ZERO) {\n        /* Not using edit lists and shifting the first track to start from zero.\n         * If the other streams start from a later timestamp, we won't be able\n         * to signal the difference in starting time without an edit list.\n         * Thus move the timestamp for this first sample to 0, increasing\n         * its duration instead. */\n        trk->cluster[trk->entry].dts = trk->start_dts = 0;\n    }\n    if (trk->start_dts == AV_NOPTS_VALUE) {\n        trk->start_dts = pkt->dts;\n        if (trk->frag_discont) {\n            if (mov->use_editlist) {\n                /* Pretend the whole stream started at pts=0, with earlier fragments\n                 * already written. If the stream started at pts=0, the duration sum\n                 * of earlier fragments would have been pkt->pts. */\n                trk->frag_start = pkt->pts;\n                trk->start_dts  = pkt->dts - pkt->pts;\n            } else {\n                /* Pretend the whole stream started at dts=0, with earlier fragments\n                 * already written, with a duration summing up to pkt->dts. */\n                trk->frag_start = pkt->dts;\n                trk->start_dts  = 0;\n            }\n            trk->frag_discont = 0;\n        } else if (pkt->dts && mov->moov_written)\n            av_log(s, AV_LOG_WARNING,\n                   \"Track %d starts with a nonzero dts %\"PRId64\", while the moov \"\n                   \"already has been written. Set the delay_moov flag to handle \"\n                   \"this case.\\n\",\n                   pkt->stream_index, pkt->dts);\n    }\n    trk->track_duration = pkt->dts - trk->start_dts + pkt->duration;\n    trk->last_sample_is_subtitle_end = 0;\n\n    if (pkt->pts == AV_NOPTS_VALUE) {\n        av_log(s, AV_LOG_WARNING, \"pts has no value\\n\");\n        pkt->pts = pkt->dts;\n    }\n    if (pkt->dts != pkt->pts)\n        trk->flags |= MOV_TRACK_CTTS;\n    trk->cluster[trk->entry].cts   = pkt->pts - pkt->dts;\n    trk->cluster[trk->entry].flags = 0;\n    if (trk->start_cts == AV_NOPTS_VALUE)\n        trk->start_cts = pkt->pts - pkt->dts;\n    if (trk->end_pts == AV_NOPTS_VALUE)\n        trk->end_pts = trk->cluster[trk->entry].dts +\n                       trk->cluster[trk->entry].cts + pkt->duration;\n    else\n        trk->end_pts = FFMAX(trk->end_pts, trk->cluster[trk->entry].dts +\n                                           trk->cluster[trk->entry].cts +\n                                           pkt->duration);\n\n    if (par->codec_id == AV_CODEC_ID_VC1) {\n        mov_parse_vc1_frame(pkt, trk);\n    } else if (pkt->flags & AV_PKT_FLAG_KEY) {\n        if (mov->mode == MODE_MOV && par->codec_id == AV_CODEC_ID_MPEG2VIDEO &&\n            trk->entry > 0) { // force sync sample for the first key frame\n            mov_parse_mpeg2_frame(pkt, &trk->cluster[trk->entry].flags);\n            if (trk->cluster[trk->entry].flags & MOV_PARTIAL_SYNC_SAMPLE)\n                trk->flags |= MOV_TRACK_STPS;\n        } else {\n            trk->cluster[trk->entry].flags = MOV_SYNC_SAMPLE;\n        }\n        if (trk->cluster[trk->entry].flags & MOV_SYNC_SAMPLE)\n            trk->has_keyframes++;\n    }\n    if (pkt->flags & AV_PKT_FLAG_DISPOSABLE) {\n        trk->cluster[trk->entry].flags |= MOV_DISPOSABLE_SAMPLE;\n        trk->has_disposable++;\n    }\n    trk->entry++;\n    trk->sample_count += samples_in_chunk;\n    mov->mdat_size    += size;\n\n    if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams)\n        ff_mov_add_hinted_packet(s, pkt, trk->hint_track, trk->entry,\n                                 reformatted_data, size);\n\nend:\nerr:\n\n    av_free(reformatted_data);\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -57,6 +57,11 @@\n         samples_in_chunk = size / trk->sample_size;\n     else\n         samples_in_chunk = 1;\n+\n+    if (samples_in_chunk < 1) {\n+        av_log(s, AV_LOG_ERROR, \"fatal error, input packet contains no samples\\n\");\n+        return AVERROR_PATCHWELCOME;\n+    }\n \n     /* copy extradata if it exists */\n     if (trk->vos_len == 0 && par->extradata_size > 0 &&",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (samples_in_chunk < 1) {",
                "        av_log(s, AV_LOG_ERROR, \"fatal error, input packet contains no samples\\n\");",
                "        return AVERROR_PATCHWELCOME;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-14395",
        "func_name": "ffmpeg/mov_write_audio_tag",
        "description": "libavformat/movenc.c in FFmpeg 3.2 and 4.0.2 allows attackers to cause a denial of service (application crash caused by a divide-by-zero error) with a user crafted audio file when converting to the MOV audio format.",
        "git_url": "https://github.com/FFmpeg/FFmpeg/commit/2c0e98a0b478284bdff6d7a4062522605a8beae5",
        "commit_title": "avformat/movenc: Write version 2 of audio atom if channels is not known",
        "commit_text": " The version 1 needs the channel count and would divide by 0  (cherry picked from commit fa19fbcf712a6a6cc5a5cfdc3254a97b9bce6582)",
        "func_before": "static int mov_write_audio_tag(AVFormatContext *s, AVIOContext *pb, MOVMuxContext *mov, MOVTrack *track)\n{\n    int64_t pos = avio_tell(pb);\n    int version = 0;\n    uint32_t tag = track->tag;\n\n    if (track->mode == MODE_MOV) {\n        if (track->timescale > UINT16_MAX) {\n            if (mov_get_lpcm_flags(track->par->codec_id))\n                tag = AV_RL32(\"lpcm\");\n            version = 2;\n        } else if (track->audio_vbr || mov_pcm_le_gt16(track->par->codec_id) ||\n                   mov_pcm_be_gt16(track->par->codec_id) ||\n                   track->par->codec_id == AV_CODEC_ID_ADPCM_MS ||\n                   track->par->codec_id == AV_CODEC_ID_ADPCM_IMA_WAV ||\n                   track->par->codec_id == AV_CODEC_ID_QDM2) {\n            version = 1;\n        }\n    }\n\n    avio_wb32(pb, 0); /* size */\n    if (mov->encryption_scheme != MOV_ENC_NONE) {\n        ffio_wfourcc(pb, \"enca\");\n    } else {\n        avio_wl32(pb, tag); // store it byteswapped\n    }\n    avio_wb32(pb, 0); /* Reserved */\n    avio_wb16(pb, 0); /* Reserved */\n    avio_wb16(pb, 1); /* Data-reference index, XXX  == 1 */\n\n    /* SoundDescription */\n    avio_wb16(pb, version); /* Version */\n    avio_wb16(pb, 0); /* Revision level */\n    avio_wb32(pb, 0); /* Reserved */\n\n    if (version == 2) {\n        avio_wb16(pb, 3);\n        avio_wb16(pb, 16);\n        avio_wb16(pb, 0xfffe);\n        avio_wb16(pb, 0);\n        avio_wb32(pb, 0x00010000);\n        avio_wb32(pb, 72);\n        avio_wb64(pb, av_double2int(track->par->sample_rate));\n        avio_wb32(pb, track->par->channels);\n        avio_wb32(pb, 0x7F000000);\n        avio_wb32(pb, av_get_bits_per_sample(track->par->codec_id));\n        avio_wb32(pb, mov_get_lpcm_flags(track->par->codec_id));\n        avio_wb32(pb, track->sample_size);\n        avio_wb32(pb, get_samples_per_packet(track));\n    } else {\n        if (track->mode == MODE_MOV) {\n            avio_wb16(pb, track->par->channels);\n            if (track->par->codec_id == AV_CODEC_ID_PCM_U8 ||\n                track->par->codec_id == AV_CODEC_ID_PCM_S8)\n                avio_wb16(pb, 8); /* bits per sample */\n            else if (track->par->codec_id == AV_CODEC_ID_ADPCM_G726)\n                avio_wb16(pb, track->par->bits_per_coded_sample);\n            else\n                avio_wb16(pb, 16);\n            avio_wb16(pb, track->audio_vbr ? -2 : 0); /* compression ID */\n        } else { /* reserved for mp4/3gp */\n            avio_wb16(pb, 2);\n            avio_wb16(pb, 16);\n            avio_wb16(pb, 0);\n        }\n\n        avio_wb16(pb, 0); /* packet size (= 0) */\n        avio_wb16(pb, track->par->sample_rate <= UINT16_MAX ?\n                      track->par->sample_rate : 0);\n        avio_wb16(pb, 0); /* Reserved */\n    }\n\n    if (version == 1) { /* SoundDescription V1 extended info */\n        if (mov_pcm_le_gt16(track->par->codec_id) ||\n            mov_pcm_be_gt16(track->par->codec_id))\n            avio_wb32(pb, 1); /*  must be 1 for  uncompressed formats */\n        else\n            avio_wb32(pb, track->par->frame_size); /* Samples per packet */\n        avio_wb32(pb, track->sample_size / track->par->channels); /* Bytes per packet */\n        avio_wb32(pb, track->sample_size); /* Bytes per frame */\n        avio_wb32(pb, 2); /* Bytes per sample */\n    }\n\n    if (track->mode == MODE_MOV &&\n        (track->par->codec_id == AV_CODEC_ID_AAC           ||\n         track->par->codec_id == AV_CODEC_ID_AC3           ||\n         track->par->codec_id == AV_CODEC_ID_EAC3          ||\n         track->par->codec_id == AV_CODEC_ID_AMR_NB        ||\n         track->par->codec_id == AV_CODEC_ID_ALAC          ||\n         track->par->codec_id == AV_CODEC_ID_ADPCM_MS      ||\n         track->par->codec_id == AV_CODEC_ID_ADPCM_IMA_WAV ||\n         track->par->codec_id == AV_CODEC_ID_QDM2          ||\n         (mov_pcm_le_gt16(track->par->codec_id) && version==1) ||\n         (mov_pcm_be_gt16(track->par->codec_id) && version==1)))\n        mov_write_wave_tag(s, pb, track);\n    else if (track->tag == MKTAG('m','p','4','a'))\n        mov_write_esds_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_AMR_NB)\n        mov_write_amr_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_AC3)\n        mov_write_ac3_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_EAC3)\n        mov_write_eac3_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_ALAC)\n        mov_write_extradata_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_WMAPRO)\n        mov_write_wfex_tag(s, pb, track);\n    else if (track->vos_len > 0)\n        mov_write_glbl_tag(pb, track);\n\n    if (track->mode == MODE_MOV && track->par->codec_type == AVMEDIA_TYPE_AUDIO)\n        mov_write_chan_tag(s, pb, track);\n\n    if (mov->encryption_scheme != MOV_ENC_NONE) {\n        ff_mov_cenc_write_sinf_tag(track, pb, mov->encryption_kid);\n    }\n\n    return update_size(pb, pos);\n}",
        "func": "static int mov_write_audio_tag(AVFormatContext *s, AVIOContext *pb, MOVMuxContext *mov, MOVTrack *track)\n{\n    int64_t pos = avio_tell(pb);\n    int version = 0;\n    uint32_t tag = track->tag;\n\n    if (track->mode == MODE_MOV) {\n        if (track->timescale > UINT16_MAX || !track->par->channels) {\n            if (mov_get_lpcm_flags(track->par->codec_id))\n                tag = AV_RL32(\"lpcm\");\n            version = 2;\n        } else if (track->audio_vbr || mov_pcm_le_gt16(track->par->codec_id) ||\n                   mov_pcm_be_gt16(track->par->codec_id) ||\n                   track->par->codec_id == AV_CODEC_ID_ADPCM_MS ||\n                   track->par->codec_id == AV_CODEC_ID_ADPCM_IMA_WAV ||\n                   track->par->codec_id == AV_CODEC_ID_QDM2) {\n            version = 1;\n        }\n    }\n\n    avio_wb32(pb, 0); /* size */\n    if (mov->encryption_scheme != MOV_ENC_NONE) {\n        ffio_wfourcc(pb, \"enca\");\n    } else {\n        avio_wl32(pb, tag); // store it byteswapped\n    }\n    avio_wb32(pb, 0); /* Reserved */\n    avio_wb16(pb, 0); /* Reserved */\n    avio_wb16(pb, 1); /* Data-reference index, XXX  == 1 */\n\n    /* SoundDescription */\n    avio_wb16(pb, version); /* Version */\n    avio_wb16(pb, 0); /* Revision level */\n    avio_wb32(pb, 0); /* Reserved */\n\n    if (version == 2) {\n        avio_wb16(pb, 3);\n        avio_wb16(pb, 16);\n        avio_wb16(pb, 0xfffe);\n        avio_wb16(pb, 0);\n        avio_wb32(pb, 0x00010000);\n        avio_wb32(pb, 72);\n        avio_wb64(pb, av_double2int(track->par->sample_rate));\n        avio_wb32(pb, track->par->channels);\n        avio_wb32(pb, 0x7F000000);\n        avio_wb32(pb, av_get_bits_per_sample(track->par->codec_id));\n        avio_wb32(pb, mov_get_lpcm_flags(track->par->codec_id));\n        avio_wb32(pb, track->sample_size);\n        avio_wb32(pb, get_samples_per_packet(track));\n    } else {\n        if (track->mode == MODE_MOV) {\n            avio_wb16(pb, track->par->channels);\n            if (track->par->codec_id == AV_CODEC_ID_PCM_U8 ||\n                track->par->codec_id == AV_CODEC_ID_PCM_S8)\n                avio_wb16(pb, 8); /* bits per sample */\n            else if (track->par->codec_id == AV_CODEC_ID_ADPCM_G726)\n                avio_wb16(pb, track->par->bits_per_coded_sample);\n            else\n                avio_wb16(pb, 16);\n            avio_wb16(pb, track->audio_vbr ? -2 : 0); /* compression ID */\n        } else { /* reserved for mp4/3gp */\n            avio_wb16(pb, 2);\n            avio_wb16(pb, 16);\n            avio_wb16(pb, 0);\n        }\n\n        avio_wb16(pb, 0); /* packet size (= 0) */\n        avio_wb16(pb, track->par->sample_rate <= UINT16_MAX ?\n                      track->par->sample_rate : 0);\n        avio_wb16(pb, 0); /* Reserved */\n    }\n\n    if (version == 1) { /* SoundDescription V1 extended info */\n        if (mov_pcm_le_gt16(track->par->codec_id) ||\n            mov_pcm_be_gt16(track->par->codec_id))\n            avio_wb32(pb, 1); /*  must be 1 for  uncompressed formats */\n        else\n            avio_wb32(pb, track->par->frame_size); /* Samples per packet */\n        avio_wb32(pb, track->sample_size / track->par->channels); /* Bytes per packet */\n        avio_wb32(pb, track->sample_size); /* Bytes per frame */\n        avio_wb32(pb, 2); /* Bytes per sample */\n    }\n\n    if (track->mode == MODE_MOV &&\n        (track->par->codec_id == AV_CODEC_ID_AAC           ||\n         track->par->codec_id == AV_CODEC_ID_AC3           ||\n         track->par->codec_id == AV_CODEC_ID_EAC3          ||\n         track->par->codec_id == AV_CODEC_ID_AMR_NB        ||\n         track->par->codec_id == AV_CODEC_ID_ALAC          ||\n         track->par->codec_id == AV_CODEC_ID_ADPCM_MS      ||\n         track->par->codec_id == AV_CODEC_ID_ADPCM_IMA_WAV ||\n         track->par->codec_id == AV_CODEC_ID_QDM2          ||\n         (mov_pcm_le_gt16(track->par->codec_id) && version==1) ||\n         (mov_pcm_be_gt16(track->par->codec_id) && version==1)))\n        mov_write_wave_tag(s, pb, track);\n    else if (track->tag == MKTAG('m','p','4','a'))\n        mov_write_esds_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_AMR_NB)\n        mov_write_amr_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_AC3)\n        mov_write_ac3_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_EAC3)\n        mov_write_eac3_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_ALAC)\n        mov_write_extradata_tag(pb, track);\n    else if (track->par->codec_id == AV_CODEC_ID_WMAPRO)\n        mov_write_wfex_tag(s, pb, track);\n    else if (track->vos_len > 0)\n        mov_write_glbl_tag(pb, track);\n\n    if (track->mode == MODE_MOV && track->par->codec_type == AVMEDIA_TYPE_AUDIO)\n        mov_write_chan_tag(s, pb, track);\n\n    if (mov->encryption_scheme != MOV_ENC_NONE) {\n        ff_mov_cenc_write_sinf_tag(track, pb, mov->encryption_kid);\n    }\n\n    return update_size(pb, pos);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n     uint32_t tag = track->tag;\n \n     if (track->mode == MODE_MOV) {\n-        if (track->timescale > UINT16_MAX) {\n+        if (track->timescale > UINT16_MAX || !track->par->channels) {\n             if (mov_get_lpcm_flags(track->par->codec_id))\n                 tag = AV_RL32(\"lpcm\");\n             version = 2;",
        "diff_line_info": {
            "deleted_lines": [
                "        if (track->timescale > UINT16_MAX) {"
            ],
            "added_lines": [
                "        if (track->timescale > UINT16_MAX || !track->par->channels) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-19628",
        "func_name": "wireshark/decode_color_temperature",
        "description": "In Wireshark 2.6.0 to 2.6.4, the ZigBee ZCL dissector could crash. This was addressed in epan/dissectors/packet-zbee-zcl-lighting.c by preventing a divide-by-zero error.",
        "git_url": "https://github.com/wireshark/wireshark/commit/212b18825d9b668cda23d334c48867dfa66b2b36",
        "commit_title": "ZigBee ZCL: Fix a divide-by-zero.",
        "commit_text": " Fix a divide-by-zero in decode_color_temperature.  Bug: 15281 (cherry picked from commit d53ff85d409367ee6538326147c8bb545bd4adb3)",
        "func_before": "static void\ndecode_color_temperature(gchar *s, guint16 value)\n{\n    g_snprintf(s, ITEM_LABEL_LENGTH, \"%d [Mired] (%d [K])\", value, 1000000/value);\n    return;\n}",
        "func": "static void\ndecode_color_temperature(gchar *s, guint16 value)\n{\n    if (value == 0) {\n        g_snprintf(s, ITEM_LABEL_LENGTH, \"%u [Mired]\", value);\n    } else {\n        g_snprintf(s, ITEM_LABEL_LENGTH, \"%u [Mired] (%u [K])\", value, 1000000/value);\n    }\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,10 @@\n static void\n decode_color_temperature(gchar *s, guint16 value)\n {\n-    g_snprintf(s, ITEM_LABEL_LENGTH, \"%d [Mired] (%d [K])\", value, 1000000/value);\n+    if (value == 0) {\n+        g_snprintf(s, ITEM_LABEL_LENGTH, \"%u [Mired]\", value);\n+    } else {\n+        g_snprintf(s, ITEM_LABEL_LENGTH, \"%u [Mired] (%u [K])\", value, 1000000/value);\n+    }\n     return;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    g_snprintf(s, ITEM_LABEL_LENGTH, \"%d [Mired] (%d [K])\", value, 1000000/value);"
            ],
            "added_lines": [
                "    if (value == 0) {",
                "        g_snprintf(s, ITEM_LABEL_LENGTH, \"%u [Mired]\", value);",
                "    } else {",
                "        g_snprintf(s, ITEM_LABEL_LENGTH, \"%u [Mired] (%u [K])\", value, 1000000/value);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5804",
        "func_name": "LibRaw/quicktake_100_load_raw",
        "description": "A type confusion error within the \"identify()\" function (internal/dcraw_common.cpp) in LibRaw versions prior to 0.18.8 can be exploited to trigger a division by zero.",
        "git_url": "https://github.com/LibRaw/LibRaw/commit/9f26ce37f5be86ea11bfc6831366558650b1f6ff",
        "commit_title": "SA81000: LibRaw 0.18.8",
        "commit_text": "",
        "func_before": "void CLASS quicktake_100_load_raw()\n{\n  uchar pixel[484][644];\n  static const short gstep[16] =\n  { -89,-60,-44,-32,-22,-15,-8,-2,2,8,15,22,32,44,60,89 };\n  static const short rstep[6][4] =\n  { {  -3,-1,1,3  }, {  -5,-1,1,5  }, {  -8,-2,2,8  },\n    { -13,-3,3,13 }, { -19,-4,4,19 }, { -28,-6,6,28 } };\n  static const short t_curve[256] =\n  { 0,1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,\n    28,29,30,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,53,\n    54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,74,75,76,77,78,\n    79,80,81,82,83,84,86,88,90,92,94,97,99,101,103,105,107,110,112,114,116,\n    118,120,123,125,127,129,131,134,136,138,140,142,144,147,149,151,153,155,\n    158,160,162,164,166,168,171,173,175,177,179,181,184,186,188,190,192,195,\n    197,199,201,203,205,208,210,212,214,216,218,221,223,226,230,235,239,244,\n    248,252,257,261,265,270,274,278,283,287,291,296,300,305,309,313,318,322,\n    326,331,335,339,344,348,352,357,361,365,370,374,379,383,387,392,396,400,\n    405,409,413,418,422,426,431,435,440,444,448,453,457,461,466,470,474,479,\n    483,487,492,496,500,508,519,531,542,553,564,575,587,598,609,620,631,643,\n    654,665,676,687,698,710,721,732,743,754,766,777,788,799,810,822,833,844,\n    855,866,878,889,900,911,922,933,945,956,967,978,989,1001,1012,1023 };\n  int rb, row, col, sharp, val=0;\n\n  getbits(-1);\n  memset (pixel, 0x80, sizeof pixel);\n  for (row=2; row < height+2; row++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=2+(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row-1][col-1] + 2*pixel[row-1][col+1] +\n\t\tpixel[row][col-2]) >> 2) + gstep[getbits(4)];\n      pixel[row][col] = val = LIM(val,0,255);\n      if (col < 4)\n\tpixel[row][col-2] = pixel[row+1][~row & 1] = val;\n      if (row == 2)\n\tpixel[row-1][col+1] = pixel[row-1][col+3] = val;\n    }\n    pixel[row][col] = val;\n  }\n  for (rb=0; rb < 2; rb++)\n    for (row=2+rb; row < height+2; row+=2)\n    {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      for (col=3-(row & 1); col < width+2; col+=2) {\n\tif (row < 4 || col < 4) sharp = 2;\n\telse {\n\t  val = ABS(pixel[row-2][col] - pixel[row][col-2])\n\t      + ABS(pixel[row-2][col] - pixel[row-2][col-2])\n\t      + ABS(pixel[row][col-2] - pixel[row-2][col-2]);\n\t  sharp = val <  4 ? 0 : val <  8 ? 1 : val < 16 ? 2 :\n\t\t  val < 32 ? 3 : val < 48 ? 4 : 5;\n\t}\n\tval = ((pixel[row-2][col] + pixel[row][col-2]) >> 1)\n\t      + rstep[sharp][getbits(2)];\n\tpixel[row][col] = val = LIM(val,0,255);\n\tif (row < 4) pixel[row-2][col+2] = val;\n\tif (col < 4) pixel[row+2][col-2] = val;\n      }\n    }\n  for (row=2; row < height+2; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=3-(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row][col-1] + (pixel[row][col] << 2) +\n\t      pixel[row][col+1]) >> 1) - 0x100;\n      pixel[row][col] = LIM(val,0,255);\n    }\n  }\n  for (row=0; row < height; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=0; col < width; col++)\n      RAW(row,col) = t_curve[pixel[row+2][col+2]];\n  }\n  maximum = 0x3ff;\n}",
        "func": "void CLASS quicktake_100_load_raw()\n{\n  uchar pixel[484][644];\n  static const short gstep[16] =\n  { -89,-60,-44,-32,-22,-15,-8,-2,2,8,15,22,32,44,60,89 };\n  static const short rstep[6][4] =\n  { {  -3,-1,1,3  }, {  -5,-1,1,5  }, {  -8,-2,2,8  },\n    { -13,-3,3,13 }, { -19,-4,4,19 }, { -28,-6,6,28 } };\n  static const short t_curve[256] =\n  { 0,1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,\n    28,29,30,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,53,\n    54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,74,75,76,77,78,\n    79,80,81,82,83,84,86,88,90,92,94,97,99,101,103,105,107,110,112,114,116,\n    118,120,123,125,127,129,131,134,136,138,140,142,144,147,149,151,153,155,\n    158,160,162,164,166,168,171,173,175,177,179,181,184,186,188,190,192,195,\n    197,199,201,203,205,208,210,212,214,216,218,221,223,226,230,235,239,244,\n    248,252,257,261,265,270,274,278,283,287,291,296,300,305,309,313,318,322,\n    326,331,335,339,344,348,352,357,361,365,370,374,379,383,387,392,396,400,\n    405,409,413,418,422,426,431,435,440,444,448,453,457,461,466,470,474,479,\n    483,487,492,496,500,508,519,531,542,553,564,575,587,598,609,620,631,643,\n    654,665,676,687,698,710,721,732,743,754,766,777,788,799,810,822,833,844,\n    855,866,878,889,900,911,922,933,945,956,967,978,989,1001,1012,1023 };\n  int rb, row, col, sharp, val=0;\n#ifdef LIBRAW_LIBRARY_BUILD\n  if(width>640 || height > 480)\n    throw LIBRAW_EXCEPTION_IO_CORRUPT;\n#endif\n  \n  getbits(-1);\n  memset (pixel, 0x80, sizeof pixel);\n  for (row=2; row < height+2; row++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=2+(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row-1][col-1] + 2*pixel[row-1][col+1] +\n\t\tpixel[row][col-2]) >> 2) + gstep[getbits(4)];\n      pixel[row][col] = val = LIM(val,0,255);\n      if (col < 4)\n\tpixel[row][col-2] = pixel[row+1][~row & 1] = val;\n      if (row == 2)\n\tpixel[row-1][col+1] = pixel[row-1][col+3] = val;\n    }\n    pixel[row][col] = val;\n  }\n  for (rb=0; rb < 2; rb++)\n    for (row=2+rb; row < height+2; row+=2)\n    {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      for (col=3-(row & 1); col < width+2; col+=2) {\n\tif (row < 4 || col < 4) sharp = 2;\n\telse {\n\t  val = ABS(pixel[row-2][col] - pixel[row][col-2])\n\t      + ABS(pixel[row-2][col] - pixel[row-2][col-2])\n\t      + ABS(pixel[row][col-2] - pixel[row-2][col-2]);\n\t  sharp = val <  4 ? 0 : val <  8 ? 1 : val < 16 ? 2 :\n\t\t  val < 32 ? 3 : val < 48 ? 4 : 5;\n\t}\n\tval = ((pixel[row-2][col] + pixel[row][col-2]) >> 1)\n\t      + rstep[sharp][getbits(2)];\n\tpixel[row][col] = val = LIM(val,0,255);\n\tif (row < 4) pixel[row-2][col+2] = val;\n\tif (col < 4) pixel[row+2][col-2] = val;\n      }\n    }\n  for (row=2; row < height+2; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=3-(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row][col-1] + (pixel[row][col] << 2) +\n\t      pixel[row][col+1]) >> 1) - 0x100;\n      pixel[row][col] = LIM(val,0,255);\n    }\n  }\n  for (row=0; row < height; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=0; col < width; col++)\n      RAW(row,col) = t_curve[pixel[row+2][col+2]];\n  }\n  maximum = 0x3ff;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,7 +21,11 @@\n     654,665,676,687,698,710,721,732,743,754,766,777,788,799,810,822,833,844,\n     855,866,878,889,900,911,922,933,945,956,967,978,989,1001,1012,1023 };\n   int rb, row, col, sharp, val=0;\n-\n+#ifdef LIBRAW_LIBRARY_BUILD\n+  if(width>640 || height > 480)\n+    throw LIBRAW_EXCEPTION_IO_CORRUPT;\n+#endif\n+  \n   getbits(-1);\n   memset (pixel, 0x80, sizeof pixel);\n   for (row=2; row < height+2; row++) {",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "#ifdef LIBRAW_LIBRARY_BUILD",
                "  if(width>640 || height > 480)",
                "    throw LIBRAW_EXCEPTION_IO_CORRUPT;",
                "#endif",
                "  "
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5804",
        "func_name": "LibRaw/leaf_hdr_load_raw",
        "description": "A type confusion error within the \"identify()\" function (internal/dcraw_common.cpp) in LibRaw versions prior to 0.18.8 can be exploited to trigger a division by zero.",
        "git_url": "https://github.com/LibRaw/LibRaw/commit/9f26ce37f5be86ea11bfc6831366558650b1f6ff",
        "commit_title": "SA81000: LibRaw 0.18.8",
        "commit_text": "",
        "func_before": "void CLASS leaf_hdr_load_raw()\n{\n  ushort *pixel=0;\n  unsigned tile=0, r, c, row, col;\n\n  if (!filters) {\n    pixel = (ushort *) calloc (raw_width, sizeof *pixel);\n    merror (pixel, \"leaf_hdr_load_raw()\");\n  }\n#ifdef LIBRAW_LIBRARY_BUILD\n  try {\n#endif\n  FORC(tiff_samples)\n    for (r=0; r < raw_height; r++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      if (r % tile_length == 0) {\n\tfseek (ifp, data_offset + 4*tile++, SEEK_SET);\n\tfseek (ifp, get4(), SEEK_SET);\n      }\n      if (filters && c != shot_select) continue;\n      if (filters) pixel = raw_image + r*raw_width;\n      read_shorts (pixel, raw_width);\n      if (!filters && (row = r - top_margin) < height)\n\tfor (col=0; col < width; col++)\n\t  image[row*width+col][c] = pixel[col+left_margin];\n    }\n#ifdef LIBRAW_LIBRARY_BUILD\n  } catch (...) {\n    if(!filters) free(pixel);\n    throw;\n  }\n#endif\n  if (!filters) {\n    maximum = 0xffff;\n    raw_color = 1;\n    free (pixel);\n  }\n}",
        "func": "void CLASS leaf_hdr_load_raw()\n{\n  ushort *pixel=0;\n  unsigned tile=0, r, c, row, col;\n\n  if (!filters) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    if(!image)\n      throw LIBRAW_EXCEPTION_IO_CORRUPT;\n#endif\n    pixel = (ushort *) calloc (raw_width, sizeof *pixel);\n    merror (pixel, \"leaf_hdr_load_raw()\");\n  }\n#ifdef LIBRAW_LIBRARY_BUILD\n  try {\n#endif\n  FORC(tiff_samples)\n    for (r=0; r < raw_height; r++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      if (r % tile_length == 0) {\n\tfseek (ifp, data_offset + 4*tile++, SEEK_SET);\n\tfseek (ifp, get4(), SEEK_SET);\n      }\n      if (filters && c != shot_select) continue;\n      if (filters) pixel = raw_image + r*raw_width;\n      read_shorts (pixel, raw_width);\n      if (!filters && (row = r - top_margin) < height)\n\tfor (col=0; col < width; col++)\n\t  image[row*width+col][c] = pixel[col+left_margin];\n    }\n#ifdef LIBRAW_LIBRARY_BUILD\n  } catch (...) {\n    if(!filters) free(pixel);\n    throw;\n  }\n#endif\n  if (!filters) {\n    maximum = 0xffff;\n    raw_color = 1;\n    free (pixel);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,10 @@\n   unsigned tile=0, r, c, row, col;\n \n   if (!filters) {\n+#ifdef LIBRAW_LIBRARY_BUILD\n+    if(!image)\n+      throw LIBRAW_EXCEPTION_IO_CORRUPT;\n+#endif\n     pixel = (ushort *) calloc (raw_width, sizeof *pixel);\n     merror (pixel, \"leaf_hdr_load_raw()\");\n   }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef LIBRAW_LIBRARY_BUILD",
                "    if(!image)",
                "      throw LIBRAW_EXCEPTION_IO_CORRUPT;",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5804",
        "func_name": "LibRaw/quicktake_100_load_raw",
        "description": "A type confusion error within the \"identify()\" function (internal/dcraw_common.cpp) in LibRaw versions prior to 0.18.8 can be exploited to trigger a division by zero.",
        "git_url": "https://github.com/LibRaw/LibRaw/commit/9f26ce37f5be86ea11bfc6831366558650b1f6ff",
        "commit_title": "SA81000: LibRaw 0.18.8",
        "commit_text": "",
        "func_before": "void CLASS quicktake_100_load_raw()\n{\n  uchar pixel[484][644];\n  static const short gstep[16] =\n  { -89,-60,-44,-32,-22,-15,-8,-2,2,8,15,22,32,44,60,89 };\n  static const short rstep[6][4] =\n  { {  -3,-1,1,3  }, {  -5,-1,1,5  }, {  -8,-2,2,8  },\n    { -13,-3,3,13 }, { -19,-4,4,19 }, { -28,-6,6,28 } };\n  static const short t_curve[256] =\n  { 0,1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,\n    28,29,30,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,53,\n    54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,74,75,76,77,78,\n    79,80,81,82,83,84,86,88,90,92,94,97,99,101,103,105,107,110,112,114,116,\n    118,120,123,125,127,129,131,134,136,138,140,142,144,147,149,151,153,155,\n    158,160,162,164,166,168,171,173,175,177,179,181,184,186,188,190,192,195,\n    197,199,201,203,205,208,210,212,214,216,218,221,223,226,230,235,239,244,\n    248,252,257,261,265,270,274,278,283,287,291,296,300,305,309,313,318,322,\n    326,331,335,339,344,348,352,357,361,365,370,374,379,383,387,392,396,400,\n    405,409,413,418,422,426,431,435,440,444,448,453,457,461,466,470,474,479,\n    483,487,492,496,500,508,519,531,542,553,564,575,587,598,609,620,631,643,\n    654,665,676,687,698,710,721,732,743,754,766,777,788,799,810,822,833,844,\n    855,866,878,889,900,911,922,933,945,956,967,978,989,1001,1012,1023 };\n  int rb, row, col, sharp, val=0;\n\n  getbits(-1);\n  memset (pixel, 0x80, sizeof pixel);\n  for (row=2; row < height+2; row++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=2+(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row-1][col-1] + 2*pixel[row-1][col+1] +\n\t\tpixel[row][col-2]) >> 2) + gstep[getbits(4)];\n      pixel[row][col] = val = LIM(val,0,255);\n      if (col < 4)\n\tpixel[row][col-2] = pixel[row+1][~row & 1] = val;\n      if (row == 2)\n\tpixel[row-1][col+1] = pixel[row-1][col+3] = val;\n    }\n    pixel[row][col] = val;\n  }\n  for (rb=0; rb < 2; rb++)\n    for (row=2+rb; row < height+2; row+=2)\n    {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      for (col=3-(row & 1); col < width+2; col+=2) {\n\tif (row < 4 || col < 4) sharp = 2;\n\telse {\n\t  val = ABS(pixel[row-2][col] - pixel[row][col-2])\n\t      + ABS(pixel[row-2][col] - pixel[row-2][col-2])\n\t      + ABS(pixel[row][col-2] - pixel[row-2][col-2]);\n\t  sharp = val <  4 ? 0 : val <  8 ? 1 : val < 16 ? 2 :\n\t\t  val < 32 ? 3 : val < 48 ? 4 : 5;\n\t}\n\tval = ((pixel[row-2][col] + pixel[row][col-2]) >> 1)\n\t      + rstep[sharp][getbits(2)];\n\tpixel[row][col] = val = LIM(val,0,255);\n\tif (row < 4) pixel[row-2][col+2] = val;\n\tif (col < 4) pixel[row+2][col-2] = val;\n      }\n    }\n  for (row=2; row < height+2; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=3-(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row][col-1] + (pixel[row][col] << 2) +\n\t      pixel[row][col+1]) >> 1) - 0x100;\n      pixel[row][col] = LIM(val,0,255);\n    }\n  }\n  for (row=0; row < height; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=0; col < width; col++)\n      RAW(row,col) = t_curve[pixel[row+2][col+2]];\n  }\n  maximum = 0x3ff;\n}",
        "func": "void CLASS quicktake_100_load_raw()\n{\n  uchar pixel[484][644];\n  static const short gstep[16] =\n  { -89,-60,-44,-32,-22,-15,-8,-2,2,8,15,22,32,44,60,89 };\n  static const short rstep[6][4] =\n  { {  -3,-1,1,3  }, {  -5,-1,1,5  }, {  -8,-2,2,8  },\n    { -13,-3,3,13 }, { -19,-4,4,19 }, { -28,-6,6,28 } };\n  static const short t_curve[256] =\n  { 0,1,2,3,4,5,6,7,8,9,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,\n    28,29,30,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,53,\n    54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,74,75,76,77,78,\n    79,80,81,82,83,84,86,88,90,92,94,97,99,101,103,105,107,110,112,114,116,\n    118,120,123,125,127,129,131,134,136,138,140,142,144,147,149,151,153,155,\n    158,160,162,164,166,168,171,173,175,177,179,181,184,186,188,190,192,195,\n    197,199,201,203,205,208,210,212,214,216,218,221,223,226,230,235,239,244,\n    248,252,257,261,265,270,274,278,283,287,291,296,300,305,309,313,318,322,\n    326,331,335,339,344,348,352,357,361,365,370,374,379,383,387,392,396,400,\n    405,409,413,418,422,426,431,435,440,444,448,453,457,461,466,470,474,479,\n    483,487,492,496,500,508,519,531,542,553,564,575,587,598,609,620,631,643,\n    654,665,676,687,698,710,721,732,743,754,766,777,788,799,810,822,833,844,\n    855,866,878,889,900,911,922,933,945,956,967,978,989,1001,1012,1023 };\n  int rb, row, col, sharp, val=0;\n#ifdef LIBRAW_LIBRARY_BUILD\n  if(width>640 || height > 480)\n    throw LIBRAW_EXCEPTION_IO_CORRUPT;\n#endif\n  \n  getbits(-1);\n  memset (pixel, 0x80, sizeof pixel);\n  for (row=2; row < height+2; row++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=2+(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row-1][col-1] + 2*pixel[row-1][col+1] +\n\t\tpixel[row][col-2]) >> 2) + gstep[getbits(4)];\n      pixel[row][col] = val = LIM(val,0,255);\n      if (col < 4)\n\tpixel[row][col-2] = pixel[row+1][~row & 1] = val;\n      if (row == 2)\n\tpixel[row-1][col+1] = pixel[row-1][col+3] = val;\n    }\n    pixel[row][col] = val;\n  }\n  for (rb=0; rb < 2; rb++)\n    for (row=2+rb; row < height+2; row+=2)\n    {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      for (col=3-(row & 1); col < width+2; col+=2) {\n\tif (row < 4 || col < 4) sharp = 2;\n\telse {\n\t  val = ABS(pixel[row-2][col] - pixel[row][col-2])\n\t      + ABS(pixel[row-2][col] - pixel[row-2][col-2])\n\t      + ABS(pixel[row][col-2] - pixel[row-2][col-2]);\n\t  sharp = val <  4 ? 0 : val <  8 ? 1 : val < 16 ? 2 :\n\t\t  val < 32 ? 3 : val < 48 ? 4 : 5;\n\t}\n\tval = ((pixel[row-2][col] + pixel[row][col-2]) >> 1)\n\t      + rstep[sharp][getbits(2)];\n\tpixel[row][col] = val = LIM(val,0,255);\n\tif (row < 4) pixel[row-2][col+2] = val;\n\tif (col < 4) pixel[row+2][col-2] = val;\n      }\n    }\n  for (row=2; row < height+2; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=3-(row & 1); col < width+2; col+=2) {\n      val = ((pixel[row][col-1] + (pixel[row][col] << 2) +\n\t      pixel[row][col+1]) >> 1) - 0x100;\n      pixel[row][col] = LIM(val,0,255);\n    }\n  }\n  for (row=0; row < height; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col=0; col < width; col++)\n      RAW(row,col) = t_curve[pixel[row+2][col+2]];\n  }\n  maximum = 0x3ff;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,7 +21,11 @@\n     654,665,676,687,698,710,721,732,743,754,766,777,788,799,810,822,833,844,\n     855,866,878,889,900,911,922,933,945,956,967,978,989,1001,1012,1023 };\n   int rb, row, col, sharp, val=0;\n-\n+#ifdef LIBRAW_LIBRARY_BUILD\n+  if(width>640 || height > 480)\n+    throw LIBRAW_EXCEPTION_IO_CORRUPT;\n+#endif\n+  \n   getbits(-1);\n   memset (pixel, 0x80, sizeof pixel);\n   for (row=2; row < height+2; row++) {",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "#ifdef LIBRAW_LIBRARY_BUILD",
                "  if(width>640 || height > 480)",
                "    throw LIBRAW_EXCEPTION_IO_CORRUPT;",
                "#endif",
                "  "
            ]
        }
    },
    {
        "cve_id": "CVE-2018-5804",
        "func_name": "LibRaw/leaf_hdr_load_raw",
        "description": "A type confusion error within the \"identify()\" function (internal/dcraw_common.cpp) in LibRaw versions prior to 0.18.8 can be exploited to trigger a division by zero.",
        "git_url": "https://github.com/LibRaw/LibRaw/commit/9f26ce37f5be86ea11bfc6831366558650b1f6ff",
        "commit_title": "SA81000: LibRaw 0.18.8",
        "commit_text": "",
        "func_before": "void CLASS leaf_hdr_load_raw()\n{\n  ushort *pixel=0;\n  unsigned tile=0, r, c, row, col;\n\n  if (!filters) {\n    pixel = (ushort *) calloc (raw_width, sizeof *pixel);\n    merror (pixel, \"leaf_hdr_load_raw()\");\n  }\n#ifdef LIBRAW_LIBRARY_BUILD\n  try {\n#endif\n  FORC(tiff_samples)\n    for (r=0; r < raw_height; r++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      if (r % tile_length == 0) {\n\tfseek (ifp, data_offset + 4*tile++, SEEK_SET);\n\tfseek (ifp, get4(), SEEK_SET);\n      }\n      if (filters && c != shot_select) continue;\n      if (filters) pixel = raw_image + r*raw_width;\n      read_shorts (pixel, raw_width);\n      if (!filters && (row = r - top_margin) < height)\n\tfor (col=0; col < width; col++)\n\t  image[row*width+col][c] = pixel[col+left_margin];\n    }\n#ifdef LIBRAW_LIBRARY_BUILD\n  } catch (...) {\n    if(!filters) free(pixel);\n    throw;\n  }\n#endif\n  if (!filters) {\n    maximum = 0xffff;\n    raw_color = 1;\n    free (pixel);\n  }\n}",
        "func": "void CLASS leaf_hdr_load_raw()\n{\n  ushort *pixel=0;\n  unsigned tile=0, r, c, row, col;\n\n  if (!filters) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    if(!image)\n      throw LIBRAW_EXCEPTION_IO_CORRUPT;\n#endif\n    pixel = (ushort *) calloc (raw_width, sizeof *pixel);\n    merror (pixel, \"leaf_hdr_load_raw()\");\n  }\n#ifdef LIBRAW_LIBRARY_BUILD\n  try {\n#endif\n  FORC(tiff_samples)\n    for (r=0; r < raw_height; r++) {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n      if (r % tile_length == 0) {\n\tfseek (ifp, data_offset + 4*tile++, SEEK_SET);\n\tfseek (ifp, get4(), SEEK_SET);\n      }\n      if (filters && c != shot_select) continue;\n      if (filters) pixel = raw_image + r*raw_width;\n      read_shorts (pixel, raw_width);\n      if (!filters && (row = r - top_margin) < height)\n\tfor (col=0; col < width; col++)\n\t  image[row*width+col][c] = pixel[col+left_margin];\n    }\n#ifdef LIBRAW_LIBRARY_BUILD\n  } catch (...) {\n    if(!filters) free(pixel);\n    throw;\n  }\n#endif\n  if (!filters) {\n    maximum = 0xffff;\n    raw_color = 1;\n    free (pixel);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,10 @@\n   unsigned tile=0, r, c, row, col;\n \n   if (!filters) {\n+#ifdef LIBRAW_LIBRARY_BUILD\n+    if(!image)\n+      throw LIBRAW_EXCEPTION_IO_CORRUPT;\n+#endif\n     pixel = (ushort *) calloc (raw_width, sizeof *pixel);\n     merror (pixel, \"leaf_hdr_load_raw()\");\n   }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef LIBRAW_LIBRARY_BUILD",
                "    if(!image)",
                "      throw LIBRAW_EXCEPTION_IO_CORRUPT;",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-42467",
        "func_name": "qemu-project/qemu/scsi_disk_emulate_mode_select",
        "description": "QEMU through 8.0.0 could trigger a division by zero in scsi_disk_reset in hw/scsi/scsi-disk.c because scsi_disk_emulate_mode_select does not prevent s->qdev.blocksize from being 256. This stops QEMU and the guest immediately.",
        "git_url": "https://gitlab.com/qemu-project/qemu/-/commit/7cfcc79b0ab800959716738aff9419f53fc68c9c",
        "commit_title": "hw/scsi/scsi-disk: Disallow block sizes smaller than 512 [CVE-2023-42467]",
        "commit_text": " We are doing things like      nb_sectors /= (s->qdev.blocksize / BDRV_SECTOR_SIZE);  in the code here (e.g. in scsi_disk_emulate_mode_sense()), so if the blocksize is smaller than BDRV_SECTOR_SIZE (=512), this crashes with a division by 0 exception. Thus disallow block sizes of 256 bytes to avoid this situation.  Resolves: https://gitlab.com/qemu-project/qemu/-/issues/1813 CVE: 2023-42467 Message-ID: <20230925091854.49198-1-thuth@redhat.com> ",
        "func_before": "static void scsi_disk_emulate_mode_select(SCSIDiskReq *r, uint8_t *inbuf)\n{\n    SCSIDiskState *s = DO_UPCAST(SCSIDiskState, qdev, r->req.dev);\n    uint8_t *p = inbuf;\n    int cmd = r->req.cmd.buf[0];\n    int len = r->req.cmd.xfer;\n    int hdr_len = (cmd == MODE_SELECT ? 4 : 8);\n    int bd_len, bs;\n    int pass;\n\n    if ((r->req.cmd.buf[1] & 0x11) != 0x10) {\n        if (!(s->quirks &\n            (1 << SCSI_DISK_QUIRK_MODE_PAGE_VENDOR_SPECIFIC_APPLE))) {\n            /* We only support PF=1, SP=0.  */\n            goto invalid_field;\n        }\n    }\n\n    if (len < hdr_len) {\n        goto invalid_param_len;\n    }\n\n    bd_len = (cmd == MODE_SELECT ? p[3] : lduw_be_p(&p[6]));\n    len -= hdr_len;\n    p += hdr_len;\n    if (len < bd_len) {\n        goto invalid_param_len;\n    }\n    if (bd_len != 0 && bd_len != 8) {\n        goto invalid_param;\n    }\n\n    /* Allow changing the block size */\n    if (bd_len) {\n        bs = p[5] << 16 | p[6] << 8 | p[7];\n\n        /*\n         * Since the existing code only checks/updates bits 8-15 of the block\n         * size, restrict ourselves to the same requirement for now to ensure\n         * that a block size set by a block descriptor and then read back by\n         * a subsequent SCSI command will be the same\n         */\n        if (bs && !(bs & ~0xff00) && bs != s->qdev.blocksize) {\n            s->qdev.blocksize = bs;\n            trace_scsi_disk_mode_select_set_blocksize(s->qdev.blocksize);\n        }\n    }\n\n    len -= bd_len;\n    p += bd_len;\n\n    /* Ensure no change is made if there is an error!  */\n    for (pass = 0; pass < 2; pass++) {\n        if (mode_select_pages(r, p, len, pass == 1) < 0) {\n            assert(pass == 0);\n            return;\n        }\n    }\n    if (!blk_enable_write_cache(s->qdev.conf.blk)) {\n        /* The request is used as the AIO opaque value, so add a ref.  */\n        scsi_req_ref(&r->req);\n        block_acct_start(blk_get_stats(s->qdev.conf.blk), &r->acct, 0,\n                         BLOCK_ACCT_FLUSH);\n        r->req.aiocb = blk_aio_flush(s->qdev.conf.blk, scsi_aio_complete, r);\n        return;\n    }\n\n    scsi_req_complete(&r->req, GOOD);\n    return;\n\ninvalid_param:\n    scsi_check_condition(r, SENSE_CODE(INVALID_PARAM));\n    return;\n\ninvalid_param_len:\n    scsi_check_condition(r, SENSE_CODE(INVALID_PARAM_LEN));\n    return;\n\ninvalid_field:\n    scsi_check_condition(r, SENSE_CODE(INVALID_FIELD));\n}",
        "func": "static void scsi_disk_emulate_mode_select(SCSIDiskReq *r, uint8_t *inbuf)\n{\n    SCSIDiskState *s = DO_UPCAST(SCSIDiskState, qdev, r->req.dev);\n    uint8_t *p = inbuf;\n    int cmd = r->req.cmd.buf[0];\n    int len = r->req.cmd.xfer;\n    int hdr_len = (cmd == MODE_SELECT ? 4 : 8);\n    int bd_len, bs;\n    int pass;\n\n    if ((r->req.cmd.buf[1] & 0x11) != 0x10) {\n        if (!(s->quirks &\n            (1 << SCSI_DISK_QUIRK_MODE_PAGE_VENDOR_SPECIFIC_APPLE))) {\n            /* We only support PF=1, SP=0.  */\n            goto invalid_field;\n        }\n    }\n\n    if (len < hdr_len) {\n        goto invalid_param_len;\n    }\n\n    bd_len = (cmd == MODE_SELECT ? p[3] : lduw_be_p(&p[6]));\n    len -= hdr_len;\n    p += hdr_len;\n    if (len < bd_len) {\n        goto invalid_param_len;\n    }\n    if (bd_len != 0 && bd_len != 8) {\n        goto invalid_param;\n    }\n\n    /* Allow changing the block size */\n    if (bd_len) {\n        bs = p[5] << 16 | p[6] << 8 | p[7];\n\n        /*\n         * Since the existing code only checks/updates bits 8-15 of the block\n         * size, restrict ourselves to the same requirement for now to ensure\n         * that a block size set by a block descriptor and then read back by\n         * a subsequent SCSI command will be the same. Also disallow a block\n         * size of 256 since we cannot handle anything below BDRV_SECTOR_SIZE.\n         */\n        if (bs && !(bs & ~0xfe00) && bs != s->qdev.blocksize) {\n            s->qdev.blocksize = bs;\n            trace_scsi_disk_mode_select_set_blocksize(s->qdev.blocksize);\n        }\n    }\n\n    len -= bd_len;\n    p += bd_len;\n\n    /* Ensure no change is made if there is an error!  */\n    for (pass = 0; pass < 2; pass++) {\n        if (mode_select_pages(r, p, len, pass == 1) < 0) {\n            assert(pass == 0);\n            return;\n        }\n    }\n    if (!blk_enable_write_cache(s->qdev.conf.blk)) {\n        /* The request is used as the AIO opaque value, so add a ref.  */\n        scsi_req_ref(&r->req);\n        block_acct_start(blk_get_stats(s->qdev.conf.blk), &r->acct, 0,\n                         BLOCK_ACCT_FLUSH);\n        r->req.aiocb = blk_aio_flush(s->qdev.conf.blk, scsi_aio_complete, r);\n        return;\n    }\n\n    scsi_req_complete(&r->req, GOOD);\n    return;\n\ninvalid_param:\n    scsi_check_condition(r, SENSE_CODE(INVALID_PARAM));\n    return;\n\ninvalid_param_len:\n    scsi_check_condition(r, SENSE_CODE(INVALID_PARAM_LEN));\n    return;\n\ninvalid_field:\n    scsi_check_condition(r, SENSE_CODE(INVALID_FIELD));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,9 +38,10 @@\n          * Since the existing code only checks/updates bits 8-15 of the block\n          * size, restrict ourselves to the same requirement for now to ensure\n          * that a block size set by a block descriptor and then read back by\n-         * a subsequent SCSI command will be the same\n+         * a subsequent SCSI command will be the same. Also disallow a block\n+         * size of 256 since we cannot handle anything below BDRV_SECTOR_SIZE.\n          */\n-        if (bs && !(bs & ~0xff00) && bs != s->qdev.blocksize) {\n+        if (bs && !(bs & ~0xfe00) && bs != s->qdev.blocksize) {\n             s->qdev.blocksize = bs;\n             trace_scsi_disk_mode_select_set_blocksize(s->qdev.blocksize);\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "         * a subsequent SCSI command will be the same",
                "        if (bs && !(bs & ~0xff00) && bs != s->qdev.blocksize) {"
            ],
            "added_lines": [
                "         * a subsequent SCSI command will be the same. Also disallow a block",
                "         * size of 256 since we cannot handle anything below BDRV_SECTOR_SIZE.",
                "        if (bs && !(bs & ~0xfe00) && bs != s->qdev.blocksize) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4797",
        "func_name": "uclouvain/openjpeg/opj_tcd_init_tile",
        "description": "Divide-by-zero vulnerability in the opj_tcd_init_tile function in tcd.c in OpenJPEG before 2.1.1 allows remote attackers to cause a denial of service (application crash) via a crafted jp2 file. NOTE: this issue exists because of an incorrect fix for CVE-2014-7947.",
        "git_url": "https://github.com/uclouvain/openjpeg/commit/8f9cc62b3f9a1da9712329ddcedb9750d585505c",
        "commit_title": "Fix division by zero",
        "commit_text": " Fix uclouvain/openjpeg#733",
        "func_before": "static INLINE OPJ_BOOL opj_tcd_init_tile(opj_tcd_t *p_tcd, OPJ_UINT32 p_tile_no, OPJ_BOOL isEncoder, OPJ_FLOAT32 fraction, OPJ_SIZE_T sizeof_block, opj_event_mgr_t* manager)\n{\n\tOPJ_UINT32 (*l_gain_ptr)(OPJ_UINT32) = 00;\n\tOPJ_UINT32 compno, resno, bandno, precno, cblkno;\n\topj_tcp_t * l_tcp = 00;\n\topj_cp_t * l_cp = 00;\n\topj_tcd_tile_t * l_tile = 00;\n\topj_tccp_t *l_tccp = 00;\n\topj_tcd_tilecomp_t *l_tilec = 00;\n\topj_image_comp_t * l_image_comp = 00;\n\topj_tcd_resolution_t *l_res = 00;\n\topj_tcd_band_t *l_band = 00;\n\topj_stepsize_t * l_step_size = 00;\n\topj_tcd_precinct_t *l_current_precinct = 00;\n\topj_image_t *l_image = 00;\n\tOPJ_UINT32 p,q;\n\tOPJ_UINT32 l_level_no;\n\tOPJ_UINT32 l_pdx, l_pdy;\n\tOPJ_UINT32 l_gain;\n\tOPJ_INT32 l_x0b, l_y0b;\n\tOPJ_UINT32 l_tx0, l_ty0;\n\t/* extent of precincts , top left, bottom right**/\n\tOPJ_INT32 l_tl_prc_x_start, l_tl_prc_y_start, l_br_prc_x_end, l_br_prc_y_end;\n\t/* number of precinct for a resolution */\n\tOPJ_UINT32 l_nb_precincts;\n\t/* room needed to store l_nb_precinct precinct for a resolution */\n\tOPJ_UINT32 l_nb_precinct_size;\n\t/* number of code blocks for a precinct*/\n\tOPJ_UINT32 l_nb_code_blocks;\n\t/* room needed to store l_nb_code_blocks code blocks for a precinct*/\n\tOPJ_UINT32 l_nb_code_blocks_size;\n\t/* size of data for a tile */\n\tOPJ_UINT32 l_data_size;\n\t\n\tl_cp = p_tcd->cp;\n\tl_tcp = &(l_cp->tcps[p_tile_no]);\n\tl_tile = p_tcd->tcd_image->tiles;\n\tl_tccp = l_tcp->tccps;\n\tl_tilec = l_tile->comps;\n\tl_image = p_tcd->image;\n\tl_image_comp = p_tcd->image->comps;\n\t\n\tp = p_tile_no % l_cp->tw;       /* tile coordinates */\n\tq = p_tile_no / l_cp->tw;\n\t/*fprintf(stderr, \"Tile coordinate = %d,%d\\n\", p, q);*/\n\t\n\t/* 4 borders of the tile rescale on the image if necessary */\n\tl_tx0 = l_cp->tx0 + p * l_cp->tdx; /* can't be greater than l_image->x1 so won't overflow */\n\tl_tile->x0 = (OPJ_INT32)opj_uint_max(l_tx0, l_image->x0);\n\tl_tile->x1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_tx0, l_cp->tdx), l_image->x1);\n\tl_ty0 = l_cp->ty0 + q * l_cp->tdy; /* can't be greater than l_image->y1 so won't overflow */\n\tl_tile->y0 = (OPJ_INT32)opj_uint_max(l_ty0, l_image->y0);\n\tl_tile->y1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_ty0, l_cp->tdy), l_image->y1);\n\n\t/* testcase 1888.pdf.asan.35.988 */\n\tif (l_tccp->numresolutions == 0) {\n\t\topj_event_msg(manager, EVT_ERROR, \"tiles require at least one resolution\\n\");\n\t\treturn OPJ_FALSE;\n\t}\n\t/*fprintf(stderr, \"Tile border = %d,%d,%d,%d\\n\", l_tile->x0, l_tile->y0,l_tile->x1,l_tile->y1);*/\n\t\n\t/*tile->numcomps = image->numcomps; */\n\tfor (compno = 0; compno < l_tile->numcomps; ++compno) {\n\t\t/*fprintf(stderr, \"compno = %d/%d\\n\", compno, l_tile->numcomps);*/\n\t\tl_image_comp->resno_decoded = 0;\n\t\t/* border of each l_tile component (global) */\n\t\tl_tilec->x0 = opj_int_ceildiv(l_tile->x0, (OPJ_INT32)l_image_comp->dx);\n\t\tl_tilec->y0 = opj_int_ceildiv(l_tile->y0, (OPJ_INT32)l_image_comp->dy);\n\t\tl_tilec->x1 = opj_int_ceildiv(l_tile->x1, (OPJ_INT32)l_image_comp->dx);\n\t\tl_tilec->y1 = opj_int_ceildiv(l_tile->y1, (OPJ_INT32)l_image_comp->dy);\n\t\t/*fprintf(stderr, \"\\tTile compo border = %d,%d,%d,%d\\n\", l_tilec->x0, l_tilec->y0,l_tilec->x1,l_tilec->y1);*/\n\t\t\n\t\t/* compute l_data_size with overflow check */\n\t\tl_data_size = (OPJ_UINT32)(l_tilec->x1 - l_tilec->x0);\n\t\tif ((((OPJ_UINT32)-1) / l_data_size) < (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0)) {\n\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile data\\n\");\n\t\t\treturn OPJ_FALSE;\n\t\t}\n\t\tl_data_size = l_data_size * (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0);\n\t\t\n\t\tif ((((OPJ_UINT32)-1) / (OPJ_UINT32)sizeof(OPJ_UINT32)) < l_data_size) {\n\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile data\\n\");\n\t\t\treturn OPJ_FALSE;\n\t\t}\n\t\tl_data_size = l_data_size * (OPJ_UINT32)sizeof(OPJ_UINT32);\n\t\tl_tilec->numresolutions = l_tccp->numresolutions;\n\t\tif (l_tccp->numresolutions < l_cp->m_specific_param.m_dec.m_reduce) {\n\t\t\tl_tilec->minimum_num_resolutions = 1;\n\t\t}\n\t\telse {\n\t\t\tl_tilec->minimum_num_resolutions = l_tccp->numresolutions - l_cp->m_specific_param.m_dec.m_reduce;\n\t\t}\n\t\t\n\t\tl_tilec->data_size_needed = l_data_size;\n\t\tif (p_tcd->m_is_decoder && !opj_alloc_tile_component_data(l_tilec)) {\n\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile data\\n\");\n\t\t\treturn OPJ_FALSE;\n\t\t}\n\t\t\n\t\tl_data_size = l_tilec->numresolutions * (OPJ_UINT32)sizeof(opj_tcd_resolution_t);\n\t\t\n\t\tif (l_tilec->resolutions == 00) {\n\t\t\tl_tilec->resolutions = (opj_tcd_resolution_t *) opj_malloc(l_data_size);\n\t\t\tif (! l_tilec->resolutions ) {\n\t\t\t\treturn OPJ_FALSE;\n\t\t\t}\n\t\t\t/*fprintf(stderr, \"\\tAllocate resolutions of tilec (opj_tcd_resolution_t): %d\\n\",l_data_size);*/\n\t\t\tl_tilec->resolutions_size = l_data_size;\n\t\t\tmemset(l_tilec->resolutions,0,l_data_size);\n\t\t}\n\t\telse if (l_data_size > l_tilec->resolutions_size) {\n\t\t\topj_tcd_resolution_t* new_resolutions = (opj_tcd_resolution_t *) opj_realloc(l_tilec->resolutions, l_data_size);\n\t\t\tif (! new_resolutions) {\n\t\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile resolutions\\n\");\n\t\t\t\topj_free(l_tilec->resolutions);\n\t\t\t\tl_tilec->resolutions = NULL;\n\t\t\t\tl_tilec->resolutions_size = 0;\n\t\t\t\treturn OPJ_FALSE;\n\t\t\t}\n\t\t\tl_tilec->resolutions = new_resolutions;\n\t\t\t/*fprintf(stderr, \"\\tReallocate data of tilec (int): from %d to %d x OPJ_UINT32\\n\", l_tilec->resolutions_size, l_data_size);*/\n\t\t\tmemset(((OPJ_BYTE*) l_tilec->resolutions)+l_tilec->resolutions_size,0,l_data_size - l_tilec->resolutions_size);\n\t\t\tl_tilec->resolutions_size = l_data_size;\n\t\t}\n\t\t\n\t\tl_level_no = l_tilec->numresolutions;\n\t\tl_res = l_tilec->resolutions;\n\t\tl_step_size = l_tccp->stepsizes;\n\t\tif (l_tccp->qmfbid == 0) {\n\t\t\tl_gain_ptr = &opj_dwt_getgain_real;\n\t\t}\n\t\telse {\n\t\t\tl_gain_ptr  = &opj_dwt_getgain;\n\t\t}\n\t\t/*fprintf(stderr, \"\\tlevel_no=%d\\n\",l_level_no);*/\n\t\t\n\t\tfor (resno = 0; resno < l_tilec->numresolutions; ++resno) {\n\t\t\t/*fprintf(stderr, \"\\t\\tresno = %d/%d\\n\", resno, l_tilec->numresolutions);*/\n\t\t\tOPJ_INT32 tlcbgxstart, tlcbgystart /*, brcbgxend, brcbgyend*/;\n\t\t\tOPJ_UINT32 cbgwidthexpn, cbgheightexpn;\n\t\t\tOPJ_UINT32 cblkwidthexpn, cblkheightexpn;\n\t\t\t\n\t\t\t--l_level_no;\n\t\t\t\n\t\t\t/* border for each resolution level (global) */\n\t\t\tl_res->x0 = opj_int_ceildivpow2(l_tilec->x0, (OPJ_INT32)l_level_no);\n\t\t\tl_res->y0 = opj_int_ceildivpow2(l_tilec->y0, (OPJ_INT32)l_level_no);\n\t\t\tl_res->x1 = opj_int_ceildivpow2(l_tilec->x1, (OPJ_INT32)l_level_no);\n\t\t\tl_res->y1 = opj_int_ceildivpow2(l_tilec->y1, (OPJ_INT32)l_level_no);\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tres_x0= %d, res_y0 =%d, res_x1=%d, res_y1=%d\\n\", l_res->x0, l_res->y0, l_res->x1, l_res->y1);*/\n\t\t\t/* p. 35, table A-23, ISO/IEC FDIS154444-1 : 2000 (18 august 2000) */\n\t\t\tl_pdx = l_tccp->prcw[resno];\n\t\t\tl_pdy = l_tccp->prch[resno];\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tpdx=%d, pdy=%d\\n\", l_pdx, l_pdy);*/\n\t\t\t/* p. 64, B.6, ISO/IEC FDIS15444-1 : 2000 (18 august 2000)  */\n\t\t\tl_tl_prc_x_start = opj_int_floordivpow2(l_res->x0, (OPJ_INT32)l_pdx) << l_pdx;\n\t\t\tl_tl_prc_y_start = opj_int_floordivpow2(l_res->y0, (OPJ_INT32)l_pdy) << l_pdy;\n\t\t\tl_br_prc_x_end = opj_int_ceildivpow2(l_res->x1, (OPJ_INT32)l_pdx) << l_pdx;\n\t\t\tl_br_prc_y_end = opj_int_ceildivpow2(l_res->y1, (OPJ_INT32)l_pdy) << l_pdy;\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tprc_x_start=%d, prc_y_start=%d, br_prc_x_end=%d, br_prc_y_end=%d \\n\", l_tl_prc_x_start, l_tl_prc_y_start, l_br_prc_x_end ,l_br_prc_y_end );*/\n\t\t\t\n\t\t\tl_res->pw = (l_res->x0 == l_res->x1) ? 0 : (OPJ_UINT32)((l_br_prc_x_end - l_tl_prc_x_start) >> l_pdx);\n\t\t\tl_res->ph = (l_res->y0 == l_res->y1) ? 0 : (OPJ_UINT32)((l_br_prc_y_end - l_tl_prc_y_start) >> l_pdy);\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tres_pw=%d, res_ph=%d\\n\", l_res->pw, l_res->ph );*/\n\t\t\t\n\t\t\tl_nb_precincts = l_res->pw * l_res->ph;\n\t\t\tl_nb_precinct_size = l_nb_precincts * (OPJ_UINT32)sizeof(opj_tcd_precinct_t);\n\t\t\tif (resno == 0) {\n\t\t\t\ttlcbgxstart = l_tl_prc_x_start;\n\t\t\t\ttlcbgystart = l_tl_prc_y_start;\n\t\t\t\t/*brcbgxend = l_br_prc_x_end;*/\n\t\t\t\t/* brcbgyend = l_br_prc_y_end;*/\n\t\t\t\tcbgwidthexpn = l_pdx;\n\t\t\t\tcbgheightexpn = l_pdy;\n\t\t\t\tl_res->numbands = 1;\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttlcbgxstart = opj_int_ceildivpow2(l_tl_prc_x_start, 1);\n\t\t\t\ttlcbgystart = opj_int_ceildivpow2(l_tl_prc_y_start, 1);\n\t\t\t\t/*brcbgxend = opj_int_ceildivpow2(l_br_prc_x_end, 1);*/\n\t\t\t\t/*brcbgyend = opj_int_ceildivpow2(l_br_prc_y_end, 1);*/\n\t\t\t\tcbgwidthexpn = l_pdx - 1;\n\t\t\t\tcbgheightexpn = l_pdy - 1;\n\t\t\t\tl_res->numbands = 3;\n\t\t\t}\n\t\t\t\n\t\t\tcblkwidthexpn = opj_uint_min(l_tccp->cblkw, cbgwidthexpn);\n\t\t\tcblkheightexpn = opj_uint_min(l_tccp->cblkh, cbgheightexpn);\n\t\t\tl_band = l_res->bands;\n\t\t\t\n\t\t\tfor (bandno = 0; bandno < l_res->numbands; ++bandno) {\n\t\t\t\tOPJ_INT32 numbps;\n\t\t\t\t/*fprintf(stderr, \"\\t\\t\\tband_no=%d/%d\\n\", bandno, l_res->numbands );*/\n\t\t\t\t\n\t\t\t\tif (resno == 0) {\n\t\t\t\t\tl_band->bandno = 0 ;\n\t\t\t\t\tl_band->x0 = opj_int_ceildivpow2(l_tilec->x0, (OPJ_INT32)l_level_no);\n\t\t\t\t\tl_band->y0 = opj_int_ceildivpow2(l_tilec->y0, (OPJ_INT32)l_level_no);\n\t\t\t\t\tl_band->x1 = opj_int_ceildivpow2(l_tilec->x1, (OPJ_INT32)l_level_no);\n\t\t\t\t\tl_band->y1 = opj_int_ceildivpow2(l_tilec->y1, (OPJ_INT32)l_level_no);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tl_band->bandno = bandno + 1;\n\t\t\t\t\t/* x0b = 1 if bandno = 1 or 3 */\n\t\t\t\t\tl_x0b = l_band->bandno&1;\n\t\t\t\t\t/* y0b = 1 if bandno = 2 or 3 */\n\t\t\t\t\tl_y0b = (OPJ_INT32)((l_band->bandno)>>1);\n\t\t\t\t\t/* l_band border (global) */\n\t\t\t\t\tl_band->x0 = opj_int64_ceildivpow2(l_tilec->x0 - ((OPJ_INT64)l_x0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t\tl_band->y0 = opj_int64_ceildivpow2(l_tilec->y0 - ((OPJ_INT64)l_y0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t\tl_band->x1 = opj_int64_ceildivpow2(l_tilec->x1 - ((OPJ_INT64)l_x0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t\tl_band->y1 = opj_int64_ceildivpow2(l_tilec->y1 - ((OPJ_INT64)l_y0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t/** avoid an if with storing function pointer */\n\t\t\t\tl_gain = (*l_gain_ptr) (l_band->bandno);\n\t\t\t\tnumbps = (OPJ_INT32)(l_image_comp->prec + l_gain);\n\t\t\t\tl_band->stepsize = (OPJ_FLOAT32)(((1.0 + l_step_size->mant / 2048.0) * pow(2.0, (OPJ_INT32) (numbps - l_step_size->expn)))) * fraction;\n\t\t\t\tl_band->numbps = l_step_size->expn + (OPJ_INT32)l_tccp->numgbits - 1;      /* WHY -1 ? */\n\t\t\t\t\n\t\t\t\tif (!l_band->precincts && (l_nb_precincts > 0U)) {\n\t\t\t\t\tl_band->precincts = (opj_tcd_precinct_t *) opj_malloc( /*3 * */ l_nb_precinct_size);\n\t\t\t\t\tif (! l_band->precincts) {\n\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t}\n\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tAllocate precincts of a band (opj_tcd_precinct_t): %d\\n\",l_nb_precinct_size);     */\n\t\t\t\t\tmemset(l_band->precincts,0,l_nb_precinct_size);\n\t\t\t\t\tl_band->precincts_data_size = l_nb_precinct_size;\n\t\t\t\t}\n\t\t\t\telse if (l_band->precincts_data_size < l_nb_precinct_size) {\n\t\t\t\t\t\n\t\t\t\t\topj_tcd_precinct_t * new_precincts = (opj_tcd_precinct_t *) opj_realloc(l_band->precincts,/*3 * */ l_nb_precinct_size);\n\t\t\t\t\tif (! new_precincts) {\n\t\t\t\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory to handle band precints\\n\");\n\t\t\t\t\t\topj_free(l_band->precincts);\n\t\t\t\t\t\tl_band->precincts = NULL;\n\t\t\t\t\t\tl_band->precincts_data_size = 0;\n\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t}\n\t\t\t\t\tl_band->precincts = new_precincts;\n\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tReallocate precincts of a band (opj_tcd_precinct_t): from %d to %d\\n\",l_band->precincts_data_size, l_nb_precinct_size);*/\n\t\t\t\t\tmemset(((OPJ_BYTE *) l_band->precincts) + l_band->precincts_data_size,0,l_nb_precinct_size - l_band->precincts_data_size);\n\t\t\t\t\tl_band->precincts_data_size = l_nb_precinct_size;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tl_current_precinct = l_band->precincts;\n\t\t\t\tfor (precno = 0; precno < l_nb_precincts; ++precno) {\n\t\t\t\t\tOPJ_INT32 tlcblkxstart, tlcblkystart, brcblkxend, brcblkyend;\n\t\t\t\t\tOPJ_INT32 cbgxstart = tlcbgxstart + (OPJ_INT32)(precno % l_res->pw) * (1 << cbgwidthexpn);\n\t\t\t\t\tOPJ_INT32 cbgystart = tlcbgystart + (OPJ_INT32)(precno / l_res->pw) * (1 << cbgheightexpn);\n\t\t\t\t\tOPJ_INT32 cbgxend = cbgxstart + (1 << cbgwidthexpn);\n\t\t\t\t\tOPJ_INT32 cbgyend = cbgystart + (1 << cbgheightexpn);\n\t\t\t\t\t/*fprintf(stderr, \"\\t precno=%d; bandno=%d, resno=%d; compno=%d\\n\", precno, bandno , resno, compno);*/\n\t\t\t\t\t/*fprintf(stderr, \"\\t tlcbgxstart(=%d) + (precno(=%d) percent res->pw(=%d)) * (1 << cbgwidthexpn(=%d)) \\n\",tlcbgxstart,precno,l_res->pw,cbgwidthexpn);*/\n\t\t\t\t\t\n\t\t\t\t\t/* precinct size (global) */\n\t\t\t\t\t/*fprintf(stderr, \"\\t cbgxstart=%d, l_band->x0 = %d \\n\",cbgxstart, l_band->x0);*/\n\t\t\t\t\t\n\t\t\t\t\tl_current_precinct->x0 = opj_int_max(cbgxstart, l_band->x0);\n\t\t\t\t\tl_current_precinct->y0 = opj_int_max(cbgystart, l_band->y0);\n\t\t\t\t\tl_current_precinct->x1 = opj_int_min(cbgxend, l_band->x1);\n\t\t\t\t\tl_current_precinct->y1 = opj_int_min(cbgyend, l_band->y1);\n\t\t\t\t\t/*fprintf(stderr, \"\\t prc_x0=%d; prc_y0=%d, prc_x1=%d; prc_y1=%d\\n\",l_current_precinct->x0, l_current_precinct->y0 ,l_current_precinct->x1, l_current_precinct->y1);*/\n\t\t\t\t\t\n\t\t\t\t\ttlcblkxstart = opj_int_floordivpow2(l_current_precinct->x0, (OPJ_INT32)cblkwidthexpn) << cblkwidthexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t tlcblkxstart =%d\\n\",tlcblkxstart );*/\n\t\t\t\t\ttlcblkystart = opj_int_floordivpow2(l_current_precinct->y0, (OPJ_INT32)cblkheightexpn) << cblkheightexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t tlcblkystart =%d\\n\",tlcblkystart );*/\n\t\t\t\t\tbrcblkxend = opj_int_ceildivpow2(l_current_precinct->x1, (OPJ_INT32)cblkwidthexpn) << cblkwidthexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t brcblkxend =%d\\n\",brcblkxend );*/\n\t\t\t\t\tbrcblkyend = opj_int_ceildivpow2(l_current_precinct->y1, (OPJ_INT32)cblkheightexpn) << cblkheightexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t brcblkyend =%d\\n\",brcblkyend );*/\n\t\t\t\t\tl_current_precinct->cw = (OPJ_UINT32)((brcblkxend - tlcblkxstart) >> cblkwidthexpn);\n\t\t\t\t\tl_current_precinct->ch = (OPJ_UINT32)((brcblkyend - tlcblkystart) >> cblkheightexpn);\n\t\t\t\t\t\n\t\t\t\t\tl_nb_code_blocks = l_current_precinct->cw * l_current_precinct->ch;\n\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\t precinct_cw = %d x recinct_ch = %d\\n\",l_current_precinct->cw, l_current_precinct->ch);      */\n\t\t\t\t\tl_nb_code_blocks_size = l_nb_code_blocks * (OPJ_UINT32)sizeof_block;\n\t\t\t\t\t\n\t\t\t\t\tif (!l_current_precinct->cblks.blocks && (l_nb_code_blocks > 0U)) {\n\t\t\t\t\t\tl_current_precinct->cblks.blocks = opj_malloc(l_nb_code_blocks_size);\n\t\t\t\t\t\tif (! l_current_precinct->cblks.blocks ) {\n\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tAllocate cblks of a precinct (opj_tcd_cblk_dec_t): %d\\n\",l_nb_code_blocks_size);*/\n\t\t\t\t\t\t\n\t\t\t\t\t\tmemset(l_current_precinct->cblks.blocks,0,l_nb_code_blocks_size);\n\t\t\t\t\t\t\n\t\t\t\t\t\tl_current_precinct->block_size = l_nb_code_blocks_size;\n\t\t\t\t\t}\n\t\t\t\t\telse if (l_nb_code_blocks_size > l_current_precinct->block_size) {\n\t\t\t\t\t\tvoid *new_blocks = opj_realloc(l_current_precinct->cblks.blocks, l_nb_code_blocks_size);\n\t\t\t\t\t\tif (! new_blocks) {\n\t\t\t\t\t\t\topj_free(l_current_precinct->cblks.blocks);\n\t\t\t\t\t\t\tl_current_precinct->cblks.blocks = NULL;\n\t\t\t\t\t\t\tl_current_precinct->block_size = 0;\n\t\t\t\t\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for current precinct codeblock element\\n\");\n\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tl_current_precinct->cblks.blocks = new_blocks;\n\t\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tReallocate cblks of a precinct (opj_tcd_cblk_dec_t): from %d to %d\\n\",l_current_precinct->block_size, l_nb_code_blocks_size);     */\n\t\t\t\t\t\t\n\t\t\t\t\t\tmemset(((OPJ_BYTE *) l_current_precinct->cblks.blocks) + l_current_precinct->block_size\n\t\t\t\t\t\t\t\t\t ,0\n\t\t\t\t\t\t\t\t\t ,l_nb_code_blocks_size - l_current_precinct->block_size);\n\t\t\t\t\t\t\n\t\t\t\t\t\tl_current_precinct->block_size = l_nb_code_blocks_size;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (! l_current_precinct->incltree) {\n\t\t\t\t\t\tl_current_precinct->incltree = opj_tgt_create(l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\t\t\t\t\telse{\n\t\t\t\t\t\tl_current_precinct->incltree = opj_tgt_init(l_current_precinct->incltree, l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (! l_current_precinct->incltree)     {\n\t\t\t\t\t\topj_event_msg(manager, EVT_WARNING, \"No incltree created.\\n\");\n\t\t\t\t\t\t/*return OPJ_FALSE;*/\n\t\t\t\t\t}\n\n\t\t\t\t\tif (! l_current_precinct->imsbtree) {\n\t\t\t\t\t\tl_current_precinct->imsbtree = opj_tgt_create(l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tl_current_precinct->imsbtree = opj_tgt_init(l_current_precinct->imsbtree, l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (! l_current_precinct->imsbtree) {\n\t\t\t\t\t\topj_event_msg(manager, EVT_WARNING, \"No imsbtree created.\\n\");\n\t\t\t\t\t\t/*return OPJ_FALSE;*/\n\t\t\t\t\t}\n\n\t\t\t\t\tfor (cblkno = 0; cblkno < l_nb_code_blocks; ++cblkno) {\n\t\t\t\t\t\tOPJ_INT32 cblkxstart = tlcblkxstart + (OPJ_INT32)(cblkno % l_current_precinct->cw) * (1 << cblkwidthexpn);\n\t\t\t\t\t\tOPJ_INT32 cblkystart = tlcblkystart + (OPJ_INT32)(cblkno / l_current_precinct->cw) * (1 << cblkheightexpn);\n\t\t\t\t\t\tOPJ_INT32 cblkxend = cblkxstart + (1 << cblkwidthexpn);\n\t\t\t\t\t\tOPJ_INT32 cblkyend = cblkystart + (1 << cblkheightexpn);\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (isEncoder) {\n\t\t\t\t\t\t\topj_tcd_cblk_enc_t* l_code_block = l_current_precinct->cblks.enc + cblkno;\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (! opj_tcd_code_block_enc_allocate(l_code_block)) {\n\t\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t/* code-block size (global) */\n\t\t\t\t\t\t\tl_code_block->x0 = opj_int_max(cblkxstart, l_current_precinct->x0);\n\t\t\t\t\t\t\tl_code_block->y0 = opj_int_max(cblkystart, l_current_precinct->y0);\n\t\t\t\t\t\t\tl_code_block->x1 = opj_int_min(cblkxend, l_current_precinct->x1);\n\t\t\t\t\t\t\tl_code_block->y1 = opj_int_min(cblkyend, l_current_precinct->y1);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (! opj_tcd_code_block_enc_allocate_data(l_code_block)) {\n\t\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\topj_tcd_cblk_dec_t* l_code_block = l_current_precinct->cblks.dec + cblkno;\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (! opj_tcd_code_block_dec_allocate(l_code_block)) {\n\t\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t/* code-block size (global) */\n\t\t\t\t\t\t\tl_code_block->x0 = opj_int_max(cblkxstart, l_current_precinct->x0);\n\t\t\t\t\t\t\tl_code_block->y0 = opj_int_max(cblkystart, l_current_precinct->y0);\n\t\t\t\t\t\t\tl_code_block->x1 = opj_int_min(cblkxend, l_current_precinct->x1);\n\t\t\t\t\t\t\tl_code_block->y1 = opj_int_min(cblkyend, l_current_precinct->y1);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t++l_current_precinct;\n\t\t\t\t} /* precno */\n\t\t\t\t++l_band;\n\t\t\t\t++l_step_size;\n\t\t\t} /* bandno */\n\t\t\t++l_res;\n\t\t} /* resno */\n\t\t++l_tccp;\n\t\t++l_tilec;\n\t\t++l_image_comp;\n\t} /* compno */\n\treturn OPJ_TRUE;\n}",
        "func": "static INLINE OPJ_BOOL opj_tcd_init_tile(opj_tcd_t *p_tcd, OPJ_UINT32 p_tile_no, OPJ_BOOL isEncoder, OPJ_FLOAT32 fraction, OPJ_SIZE_T sizeof_block, opj_event_mgr_t* manager)\n{\n\tOPJ_UINT32 (*l_gain_ptr)(OPJ_UINT32) = 00;\n\tOPJ_UINT32 compno, resno, bandno, precno, cblkno;\n\topj_tcp_t * l_tcp = 00;\n\topj_cp_t * l_cp = 00;\n\topj_tcd_tile_t * l_tile = 00;\n\topj_tccp_t *l_tccp = 00;\n\topj_tcd_tilecomp_t *l_tilec = 00;\n\topj_image_comp_t * l_image_comp = 00;\n\topj_tcd_resolution_t *l_res = 00;\n\topj_tcd_band_t *l_band = 00;\n\topj_stepsize_t * l_step_size = 00;\n\topj_tcd_precinct_t *l_current_precinct = 00;\n\topj_image_t *l_image = 00;\n\tOPJ_UINT32 p,q;\n\tOPJ_UINT32 l_level_no;\n\tOPJ_UINT32 l_pdx, l_pdy;\n\tOPJ_UINT32 l_gain;\n\tOPJ_INT32 l_x0b, l_y0b;\n\tOPJ_UINT32 l_tx0, l_ty0;\n\t/* extent of precincts , top left, bottom right**/\n\tOPJ_INT32 l_tl_prc_x_start, l_tl_prc_y_start, l_br_prc_x_end, l_br_prc_y_end;\n\t/* number of precinct for a resolution */\n\tOPJ_UINT32 l_nb_precincts;\n\t/* room needed to store l_nb_precinct precinct for a resolution */\n\tOPJ_UINT32 l_nb_precinct_size;\n\t/* number of code blocks for a precinct*/\n\tOPJ_UINT32 l_nb_code_blocks;\n\t/* room needed to store l_nb_code_blocks code blocks for a precinct*/\n\tOPJ_UINT32 l_nb_code_blocks_size;\n\t/* size of data for a tile */\n\tOPJ_UINT32 l_data_size;\n\t\n\tl_cp = p_tcd->cp;\n\tl_tcp = &(l_cp->tcps[p_tile_no]);\n\tl_tile = p_tcd->tcd_image->tiles;\n\tl_tccp = l_tcp->tccps;\n\tl_tilec = l_tile->comps;\n\tl_image = p_tcd->image;\n\tl_image_comp = p_tcd->image->comps;\n\t\n\tp = p_tile_no % l_cp->tw;       /* tile coordinates */\n\tq = p_tile_no / l_cp->tw;\n\t/*fprintf(stderr, \"Tile coordinate = %d,%d\\n\", p, q);*/\n\t\n\t/* 4 borders of the tile rescale on the image if necessary */\n\tl_tx0 = l_cp->tx0 + p * l_cp->tdx; /* can't be greater than l_image->x1 so won't overflow */\n\tl_tile->x0 = (OPJ_INT32)opj_uint_max(l_tx0, l_image->x0);\n\tl_tile->x1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_tx0, l_cp->tdx), l_image->x1);\n\tl_ty0 = l_cp->ty0 + q * l_cp->tdy; /* can't be greater than l_image->y1 so won't overflow */\n\tl_tile->y0 = (OPJ_INT32)opj_uint_max(l_ty0, l_image->y0);\n\tl_tile->y1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_ty0, l_cp->tdy), l_image->y1);\n\n\t/* testcase 1888.pdf.asan.35.988 */\n\tif (l_tccp->numresolutions == 0) {\n\t\topj_event_msg(manager, EVT_ERROR, \"tiles require at least one resolution\\n\");\n\t\treturn OPJ_FALSE;\n\t}\n\t/*fprintf(stderr, \"Tile border = %d,%d,%d,%d\\n\", l_tile->x0, l_tile->y0,l_tile->x1,l_tile->y1);*/\n\t\n\t/*tile->numcomps = image->numcomps; */\n\tfor (compno = 0; compno < l_tile->numcomps; ++compno) {\n\t\t/*fprintf(stderr, \"compno = %d/%d\\n\", compno, l_tile->numcomps);*/\n\t\tl_image_comp->resno_decoded = 0;\n\t\t/* border of each l_tile component (global) */\n\t\tl_tilec->x0 = opj_int_ceildiv(l_tile->x0, (OPJ_INT32)l_image_comp->dx);\n\t\tl_tilec->y0 = opj_int_ceildiv(l_tile->y0, (OPJ_INT32)l_image_comp->dy);\n\t\tl_tilec->x1 = opj_int_ceildiv(l_tile->x1, (OPJ_INT32)l_image_comp->dx);\n\t\tl_tilec->y1 = opj_int_ceildiv(l_tile->y1, (OPJ_INT32)l_image_comp->dy);\n\t\t/*fprintf(stderr, \"\\tTile compo border = %d,%d,%d,%d\\n\", l_tilec->x0, l_tilec->y0,l_tilec->x1,l_tilec->y1);*/\n\t\t\n\t\t/* compute l_data_size with overflow check */\n\t\tl_data_size = (OPJ_UINT32)(l_tilec->x1 - l_tilec->x0);\n\t\t/* issue 733, l_data_size == 0U, probably something wrong should be checked before getting here */\n\t\tif ((l_data_size > 0U) && ((((OPJ_UINT32)-1) / l_data_size) < (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0))) {\n\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile data\\n\");\n\t\t\treturn OPJ_FALSE;\n\t\t}\n\t\tl_data_size = l_data_size * (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0);\n\t\t\n\t\tif ((((OPJ_UINT32)-1) / (OPJ_UINT32)sizeof(OPJ_UINT32)) < l_data_size) {\n\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile data\\n\");\n\t\t\treturn OPJ_FALSE;\n\t\t}\n\t\tl_data_size = l_data_size * (OPJ_UINT32)sizeof(OPJ_UINT32);\n\t\tl_tilec->numresolutions = l_tccp->numresolutions;\n\t\tif (l_tccp->numresolutions < l_cp->m_specific_param.m_dec.m_reduce) {\n\t\t\tl_tilec->minimum_num_resolutions = 1;\n\t\t}\n\t\telse {\n\t\t\tl_tilec->minimum_num_resolutions = l_tccp->numresolutions - l_cp->m_specific_param.m_dec.m_reduce;\n\t\t}\n\t\t\n\t\tl_tilec->data_size_needed = l_data_size;\n\t\tif (p_tcd->m_is_decoder && !opj_alloc_tile_component_data(l_tilec)) {\n\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile data\\n\");\n\t\t\treturn OPJ_FALSE;\n\t\t}\n\t\t\n\t\tl_data_size = l_tilec->numresolutions * (OPJ_UINT32)sizeof(opj_tcd_resolution_t);\n\t\t\n\t\tif (l_tilec->resolutions == 00) {\n\t\t\tl_tilec->resolutions = (opj_tcd_resolution_t *) opj_malloc(l_data_size);\n\t\t\tif (! l_tilec->resolutions ) {\n\t\t\t\treturn OPJ_FALSE;\n\t\t\t}\n\t\t\t/*fprintf(stderr, \"\\tAllocate resolutions of tilec (opj_tcd_resolution_t): %d\\n\",l_data_size);*/\n\t\t\tl_tilec->resolutions_size = l_data_size;\n\t\t\tmemset(l_tilec->resolutions,0,l_data_size);\n\t\t}\n\t\telse if (l_data_size > l_tilec->resolutions_size) {\n\t\t\topj_tcd_resolution_t* new_resolutions = (opj_tcd_resolution_t *) opj_realloc(l_tilec->resolutions, l_data_size);\n\t\t\tif (! new_resolutions) {\n\t\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile resolutions\\n\");\n\t\t\t\topj_free(l_tilec->resolutions);\n\t\t\t\tl_tilec->resolutions = NULL;\n\t\t\t\tl_tilec->resolutions_size = 0;\n\t\t\t\treturn OPJ_FALSE;\n\t\t\t}\n\t\t\tl_tilec->resolutions = new_resolutions;\n\t\t\t/*fprintf(stderr, \"\\tReallocate data of tilec (int): from %d to %d x OPJ_UINT32\\n\", l_tilec->resolutions_size, l_data_size);*/\n\t\t\tmemset(((OPJ_BYTE*) l_tilec->resolutions)+l_tilec->resolutions_size,0,l_data_size - l_tilec->resolutions_size);\n\t\t\tl_tilec->resolutions_size = l_data_size;\n\t\t}\n\t\t\n\t\tl_level_no = l_tilec->numresolutions;\n\t\tl_res = l_tilec->resolutions;\n\t\tl_step_size = l_tccp->stepsizes;\n\t\tif (l_tccp->qmfbid == 0) {\n\t\t\tl_gain_ptr = &opj_dwt_getgain_real;\n\t\t}\n\t\telse {\n\t\t\tl_gain_ptr  = &opj_dwt_getgain;\n\t\t}\n\t\t/*fprintf(stderr, \"\\tlevel_no=%d\\n\",l_level_no);*/\n\t\t\n\t\tfor (resno = 0; resno < l_tilec->numresolutions; ++resno) {\n\t\t\t/*fprintf(stderr, \"\\t\\tresno = %d/%d\\n\", resno, l_tilec->numresolutions);*/\n\t\t\tOPJ_INT32 tlcbgxstart, tlcbgystart /*, brcbgxend, brcbgyend*/;\n\t\t\tOPJ_UINT32 cbgwidthexpn, cbgheightexpn;\n\t\t\tOPJ_UINT32 cblkwidthexpn, cblkheightexpn;\n\t\t\t\n\t\t\t--l_level_no;\n\t\t\t\n\t\t\t/* border for each resolution level (global) */\n\t\t\tl_res->x0 = opj_int_ceildivpow2(l_tilec->x0, (OPJ_INT32)l_level_no);\n\t\t\tl_res->y0 = opj_int_ceildivpow2(l_tilec->y0, (OPJ_INT32)l_level_no);\n\t\t\tl_res->x1 = opj_int_ceildivpow2(l_tilec->x1, (OPJ_INT32)l_level_no);\n\t\t\tl_res->y1 = opj_int_ceildivpow2(l_tilec->y1, (OPJ_INT32)l_level_no);\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tres_x0= %d, res_y0 =%d, res_x1=%d, res_y1=%d\\n\", l_res->x0, l_res->y0, l_res->x1, l_res->y1);*/\n\t\t\t/* p. 35, table A-23, ISO/IEC FDIS154444-1 : 2000 (18 august 2000) */\n\t\t\tl_pdx = l_tccp->prcw[resno];\n\t\t\tl_pdy = l_tccp->prch[resno];\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tpdx=%d, pdy=%d\\n\", l_pdx, l_pdy);*/\n\t\t\t/* p. 64, B.6, ISO/IEC FDIS15444-1 : 2000 (18 august 2000)  */\n\t\t\tl_tl_prc_x_start = opj_int_floordivpow2(l_res->x0, (OPJ_INT32)l_pdx) << l_pdx;\n\t\t\tl_tl_prc_y_start = opj_int_floordivpow2(l_res->y0, (OPJ_INT32)l_pdy) << l_pdy;\n\t\t\tl_br_prc_x_end = opj_int_ceildivpow2(l_res->x1, (OPJ_INT32)l_pdx) << l_pdx;\n\t\t\tl_br_prc_y_end = opj_int_ceildivpow2(l_res->y1, (OPJ_INT32)l_pdy) << l_pdy;\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tprc_x_start=%d, prc_y_start=%d, br_prc_x_end=%d, br_prc_y_end=%d \\n\", l_tl_prc_x_start, l_tl_prc_y_start, l_br_prc_x_end ,l_br_prc_y_end );*/\n\t\t\t\n\t\t\tl_res->pw = (l_res->x0 == l_res->x1) ? 0 : (OPJ_UINT32)((l_br_prc_x_end - l_tl_prc_x_start) >> l_pdx);\n\t\t\tl_res->ph = (l_res->y0 == l_res->y1) ? 0 : (OPJ_UINT32)((l_br_prc_y_end - l_tl_prc_y_start) >> l_pdy);\n\t\t\t/*fprintf(stderr, \"\\t\\t\\tres_pw=%d, res_ph=%d\\n\", l_res->pw, l_res->ph );*/\n\t\t\t\n\t\t\tl_nb_precincts = l_res->pw * l_res->ph;\n\t\t\tl_nb_precinct_size = l_nb_precincts * (OPJ_UINT32)sizeof(opj_tcd_precinct_t);\n\t\t\tif (resno == 0) {\n\t\t\t\ttlcbgxstart = l_tl_prc_x_start;\n\t\t\t\ttlcbgystart = l_tl_prc_y_start;\n\t\t\t\t/*brcbgxend = l_br_prc_x_end;*/\n\t\t\t\t/* brcbgyend = l_br_prc_y_end;*/\n\t\t\t\tcbgwidthexpn = l_pdx;\n\t\t\t\tcbgheightexpn = l_pdy;\n\t\t\t\tl_res->numbands = 1;\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttlcbgxstart = opj_int_ceildivpow2(l_tl_prc_x_start, 1);\n\t\t\t\ttlcbgystart = opj_int_ceildivpow2(l_tl_prc_y_start, 1);\n\t\t\t\t/*brcbgxend = opj_int_ceildivpow2(l_br_prc_x_end, 1);*/\n\t\t\t\t/*brcbgyend = opj_int_ceildivpow2(l_br_prc_y_end, 1);*/\n\t\t\t\tcbgwidthexpn = l_pdx - 1;\n\t\t\t\tcbgheightexpn = l_pdy - 1;\n\t\t\t\tl_res->numbands = 3;\n\t\t\t}\n\t\t\t\n\t\t\tcblkwidthexpn = opj_uint_min(l_tccp->cblkw, cbgwidthexpn);\n\t\t\tcblkheightexpn = opj_uint_min(l_tccp->cblkh, cbgheightexpn);\n\t\t\tl_band = l_res->bands;\n\t\t\t\n\t\t\tfor (bandno = 0; bandno < l_res->numbands; ++bandno) {\n\t\t\t\tOPJ_INT32 numbps;\n\t\t\t\t/*fprintf(stderr, \"\\t\\t\\tband_no=%d/%d\\n\", bandno, l_res->numbands );*/\n\t\t\t\t\n\t\t\t\tif (resno == 0) {\n\t\t\t\t\tl_band->bandno = 0 ;\n\t\t\t\t\tl_band->x0 = opj_int_ceildivpow2(l_tilec->x0, (OPJ_INT32)l_level_no);\n\t\t\t\t\tl_band->y0 = opj_int_ceildivpow2(l_tilec->y0, (OPJ_INT32)l_level_no);\n\t\t\t\t\tl_band->x1 = opj_int_ceildivpow2(l_tilec->x1, (OPJ_INT32)l_level_no);\n\t\t\t\t\tl_band->y1 = opj_int_ceildivpow2(l_tilec->y1, (OPJ_INT32)l_level_no);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tl_band->bandno = bandno + 1;\n\t\t\t\t\t/* x0b = 1 if bandno = 1 or 3 */\n\t\t\t\t\tl_x0b = l_band->bandno&1;\n\t\t\t\t\t/* y0b = 1 if bandno = 2 or 3 */\n\t\t\t\t\tl_y0b = (OPJ_INT32)((l_band->bandno)>>1);\n\t\t\t\t\t/* l_band border (global) */\n\t\t\t\t\tl_band->x0 = opj_int64_ceildivpow2(l_tilec->x0 - ((OPJ_INT64)l_x0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t\tl_band->y0 = opj_int64_ceildivpow2(l_tilec->y0 - ((OPJ_INT64)l_y0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t\tl_band->x1 = opj_int64_ceildivpow2(l_tilec->x1 - ((OPJ_INT64)l_x0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t\tl_band->y1 = opj_int64_ceildivpow2(l_tilec->y1 - ((OPJ_INT64)l_y0b << l_level_no), (OPJ_INT32)(l_level_no + 1));\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t/** avoid an if with storing function pointer */\n\t\t\t\tl_gain = (*l_gain_ptr) (l_band->bandno);\n\t\t\t\tnumbps = (OPJ_INT32)(l_image_comp->prec + l_gain);\n\t\t\t\tl_band->stepsize = (OPJ_FLOAT32)(((1.0 + l_step_size->mant / 2048.0) * pow(2.0, (OPJ_INT32) (numbps - l_step_size->expn)))) * fraction;\n\t\t\t\tl_band->numbps = l_step_size->expn + (OPJ_INT32)l_tccp->numgbits - 1;      /* WHY -1 ? */\n\t\t\t\t\n\t\t\t\tif (!l_band->precincts && (l_nb_precincts > 0U)) {\n\t\t\t\t\tl_band->precincts = (opj_tcd_precinct_t *) opj_malloc( /*3 * */ l_nb_precinct_size);\n\t\t\t\t\tif (! l_band->precincts) {\n\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t}\n\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tAllocate precincts of a band (opj_tcd_precinct_t): %d\\n\",l_nb_precinct_size);     */\n\t\t\t\t\tmemset(l_band->precincts,0,l_nb_precinct_size);\n\t\t\t\t\tl_band->precincts_data_size = l_nb_precinct_size;\n\t\t\t\t}\n\t\t\t\telse if (l_band->precincts_data_size < l_nb_precinct_size) {\n\t\t\t\t\t\n\t\t\t\t\topj_tcd_precinct_t * new_precincts = (opj_tcd_precinct_t *) opj_realloc(l_band->precincts,/*3 * */ l_nb_precinct_size);\n\t\t\t\t\tif (! new_precincts) {\n\t\t\t\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory to handle band precints\\n\");\n\t\t\t\t\t\topj_free(l_band->precincts);\n\t\t\t\t\t\tl_band->precincts = NULL;\n\t\t\t\t\t\tl_band->precincts_data_size = 0;\n\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t}\n\t\t\t\t\tl_band->precincts = new_precincts;\n\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tReallocate precincts of a band (opj_tcd_precinct_t): from %d to %d\\n\",l_band->precincts_data_size, l_nb_precinct_size);*/\n\t\t\t\t\tmemset(((OPJ_BYTE *) l_band->precincts) + l_band->precincts_data_size,0,l_nb_precinct_size - l_band->precincts_data_size);\n\t\t\t\t\tl_band->precincts_data_size = l_nb_precinct_size;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tl_current_precinct = l_band->precincts;\n\t\t\t\tfor (precno = 0; precno < l_nb_precincts; ++precno) {\n\t\t\t\t\tOPJ_INT32 tlcblkxstart, tlcblkystart, brcblkxend, brcblkyend;\n\t\t\t\t\tOPJ_INT32 cbgxstart = tlcbgxstart + (OPJ_INT32)(precno % l_res->pw) * (1 << cbgwidthexpn);\n\t\t\t\t\tOPJ_INT32 cbgystart = tlcbgystart + (OPJ_INT32)(precno / l_res->pw) * (1 << cbgheightexpn);\n\t\t\t\t\tOPJ_INT32 cbgxend = cbgxstart + (1 << cbgwidthexpn);\n\t\t\t\t\tOPJ_INT32 cbgyend = cbgystart + (1 << cbgheightexpn);\n\t\t\t\t\t/*fprintf(stderr, \"\\t precno=%d; bandno=%d, resno=%d; compno=%d\\n\", precno, bandno , resno, compno);*/\n\t\t\t\t\t/*fprintf(stderr, \"\\t tlcbgxstart(=%d) + (precno(=%d) percent res->pw(=%d)) * (1 << cbgwidthexpn(=%d)) \\n\",tlcbgxstart,precno,l_res->pw,cbgwidthexpn);*/\n\t\t\t\t\t\n\t\t\t\t\t/* precinct size (global) */\n\t\t\t\t\t/*fprintf(stderr, \"\\t cbgxstart=%d, l_band->x0 = %d \\n\",cbgxstart, l_band->x0);*/\n\t\t\t\t\t\n\t\t\t\t\tl_current_precinct->x0 = opj_int_max(cbgxstart, l_band->x0);\n\t\t\t\t\tl_current_precinct->y0 = opj_int_max(cbgystart, l_band->y0);\n\t\t\t\t\tl_current_precinct->x1 = opj_int_min(cbgxend, l_band->x1);\n\t\t\t\t\tl_current_precinct->y1 = opj_int_min(cbgyend, l_band->y1);\n\t\t\t\t\t/*fprintf(stderr, \"\\t prc_x0=%d; prc_y0=%d, prc_x1=%d; prc_y1=%d\\n\",l_current_precinct->x0, l_current_precinct->y0 ,l_current_precinct->x1, l_current_precinct->y1);*/\n\t\t\t\t\t\n\t\t\t\t\ttlcblkxstart = opj_int_floordivpow2(l_current_precinct->x0, (OPJ_INT32)cblkwidthexpn) << cblkwidthexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t tlcblkxstart =%d\\n\",tlcblkxstart );*/\n\t\t\t\t\ttlcblkystart = opj_int_floordivpow2(l_current_precinct->y0, (OPJ_INT32)cblkheightexpn) << cblkheightexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t tlcblkystart =%d\\n\",tlcblkystart );*/\n\t\t\t\t\tbrcblkxend = opj_int_ceildivpow2(l_current_precinct->x1, (OPJ_INT32)cblkwidthexpn) << cblkwidthexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t brcblkxend =%d\\n\",brcblkxend );*/\n\t\t\t\t\tbrcblkyend = opj_int_ceildivpow2(l_current_precinct->y1, (OPJ_INT32)cblkheightexpn) << cblkheightexpn;\n\t\t\t\t\t/*fprintf(stderr, \"\\t brcblkyend =%d\\n\",brcblkyend );*/\n\t\t\t\t\tl_current_precinct->cw = (OPJ_UINT32)((brcblkxend - tlcblkxstart) >> cblkwidthexpn);\n\t\t\t\t\tl_current_precinct->ch = (OPJ_UINT32)((brcblkyend - tlcblkystart) >> cblkheightexpn);\n\t\t\t\t\t\n\t\t\t\t\tl_nb_code_blocks = l_current_precinct->cw * l_current_precinct->ch;\n\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\t precinct_cw = %d x recinct_ch = %d\\n\",l_current_precinct->cw, l_current_precinct->ch);      */\n\t\t\t\t\tl_nb_code_blocks_size = l_nb_code_blocks * (OPJ_UINT32)sizeof_block;\n\t\t\t\t\t\n\t\t\t\t\tif (!l_current_precinct->cblks.blocks && (l_nb_code_blocks > 0U)) {\n\t\t\t\t\t\tl_current_precinct->cblks.blocks = opj_malloc(l_nb_code_blocks_size);\n\t\t\t\t\t\tif (! l_current_precinct->cblks.blocks ) {\n\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tAllocate cblks of a precinct (opj_tcd_cblk_dec_t): %d\\n\",l_nb_code_blocks_size);*/\n\t\t\t\t\t\t\n\t\t\t\t\t\tmemset(l_current_precinct->cblks.blocks,0,l_nb_code_blocks_size);\n\t\t\t\t\t\t\n\t\t\t\t\t\tl_current_precinct->block_size = l_nb_code_blocks_size;\n\t\t\t\t\t}\n\t\t\t\t\telse if (l_nb_code_blocks_size > l_current_precinct->block_size) {\n\t\t\t\t\t\tvoid *new_blocks = opj_realloc(l_current_precinct->cblks.blocks, l_nb_code_blocks_size);\n\t\t\t\t\t\tif (! new_blocks) {\n\t\t\t\t\t\t\topj_free(l_current_precinct->cblks.blocks);\n\t\t\t\t\t\t\tl_current_precinct->cblks.blocks = NULL;\n\t\t\t\t\t\t\tl_current_precinct->block_size = 0;\n\t\t\t\t\t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for current precinct codeblock element\\n\");\n\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tl_current_precinct->cblks.blocks = new_blocks;\n\t\t\t\t\t\t/*fprintf(stderr, \"\\t\\t\\t\\tReallocate cblks of a precinct (opj_tcd_cblk_dec_t): from %d to %d\\n\",l_current_precinct->block_size, l_nb_code_blocks_size);     */\n\t\t\t\t\t\t\n\t\t\t\t\t\tmemset(((OPJ_BYTE *) l_current_precinct->cblks.blocks) + l_current_precinct->block_size\n\t\t\t\t\t\t\t\t\t ,0\n\t\t\t\t\t\t\t\t\t ,l_nb_code_blocks_size - l_current_precinct->block_size);\n\t\t\t\t\t\t\n\t\t\t\t\t\tl_current_precinct->block_size = l_nb_code_blocks_size;\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\tif (! l_current_precinct->incltree) {\n\t\t\t\t\t\tl_current_precinct->incltree = opj_tgt_create(l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\t\t\t\t\telse{\n\t\t\t\t\t\tl_current_precinct->incltree = opj_tgt_init(l_current_precinct->incltree, l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (! l_current_precinct->incltree)     {\n\t\t\t\t\t\topj_event_msg(manager, EVT_WARNING, \"No incltree created.\\n\");\n\t\t\t\t\t\t/*return OPJ_FALSE;*/\n\t\t\t\t\t}\n\n\t\t\t\t\tif (! l_current_precinct->imsbtree) {\n\t\t\t\t\t\tl_current_precinct->imsbtree = opj_tgt_create(l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tl_current_precinct->imsbtree = opj_tgt_init(l_current_precinct->imsbtree, l_current_precinct->cw, l_current_precinct->ch, manager);\n\t\t\t\t\t}\n\n\t\t\t\t\tif (! l_current_precinct->imsbtree) {\n\t\t\t\t\t\topj_event_msg(manager, EVT_WARNING, \"No imsbtree created.\\n\");\n\t\t\t\t\t\t/*return OPJ_FALSE;*/\n\t\t\t\t\t}\n\n\t\t\t\t\tfor (cblkno = 0; cblkno < l_nb_code_blocks; ++cblkno) {\n\t\t\t\t\t\tOPJ_INT32 cblkxstart = tlcblkxstart + (OPJ_INT32)(cblkno % l_current_precinct->cw) * (1 << cblkwidthexpn);\n\t\t\t\t\t\tOPJ_INT32 cblkystart = tlcblkystart + (OPJ_INT32)(cblkno / l_current_precinct->cw) * (1 << cblkheightexpn);\n\t\t\t\t\t\tOPJ_INT32 cblkxend = cblkxstart + (1 << cblkwidthexpn);\n\t\t\t\t\t\tOPJ_INT32 cblkyend = cblkystart + (1 << cblkheightexpn);\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (isEncoder) {\n\t\t\t\t\t\t\topj_tcd_cblk_enc_t* l_code_block = l_current_precinct->cblks.enc + cblkno;\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (! opj_tcd_code_block_enc_allocate(l_code_block)) {\n\t\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t/* code-block size (global) */\n\t\t\t\t\t\t\tl_code_block->x0 = opj_int_max(cblkxstart, l_current_precinct->x0);\n\t\t\t\t\t\t\tl_code_block->y0 = opj_int_max(cblkystart, l_current_precinct->y0);\n\t\t\t\t\t\t\tl_code_block->x1 = opj_int_min(cblkxend, l_current_precinct->x1);\n\t\t\t\t\t\t\tl_code_block->y1 = opj_int_min(cblkyend, l_current_precinct->y1);\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (! opj_tcd_code_block_enc_allocate_data(l_code_block)) {\n\t\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\topj_tcd_cblk_dec_t* l_code_block = l_current_precinct->cblks.dec + cblkno;\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (! opj_tcd_code_block_dec_allocate(l_code_block)) {\n\t\t\t\t\t\t\t\treturn OPJ_FALSE;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t/* code-block size (global) */\n\t\t\t\t\t\t\tl_code_block->x0 = opj_int_max(cblkxstart, l_current_precinct->x0);\n\t\t\t\t\t\t\tl_code_block->y0 = opj_int_max(cblkystart, l_current_precinct->y0);\n\t\t\t\t\t\t\tl_code_block->x1 = opj_int_min(cblkxend, l_current_precinct->x1);\n\t\t\t\t\t\t\tl_code_block->y1 = opj_int_min(cblkyend, l_current_precinct->y1);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t++l_current_precinct;\n\t\t\t\t} /* precno */\n\t\t\t\t++l_band;\n\t\t\t\t++l_step_size;\n\t\t\t} /* bandno */\n\t\t\t++l_res;\n\t\t} /* resno */\n\t\t++l_tccp;\n\t\t++l_tilec;\n\t\t++l_image_comp;\n\t} /* compno */\n\treturn OPJ_TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -72,7 +72,8 @@\n \t\t\n \t\t/* compute l_data_size with overflow check */\n \t\tl_data_size = (OPJ_UINT32)(l_tilec->x1 - l_tilec->x0);\n-\t\tif ((((OPJ_UINT32)-1) / l_data_size) < (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0)) {\n+\t\t/* issue 733, l_data_size == 0U, probably something wrong should be checked before getting here */\n+\t\tif ((l_data_size > 0U) && ((((OPJ_UINT32)-1) / l_data_size) < (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0))) {\n \t\t\topj_event_msg(manager, EVT_ERROR, \"Not enough memory for tile data\\n\");\n \t\t\treturn OPJ_FALSE;\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif ((((OPJ_UINT32)-1) / l_data_size) < (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0)) {"
            ],
            "added_lines": [
                "\t\t/* issue 733, l_data_size == 0U, probably something wrong should be checked before getting here */",
                "\t\tif ((l_data_size > 0U) && ((((OPJ_UINT32)-1) / l_data_size) < (OPJ_UINT32)(l_tilec->y1 - l_tilec->y0))) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-8691",
        "func_name": "jasper-software/jasper/jpc_siz_getparms",
        "description": "The jpc_dec_process_siz function in libjasper/jpc/jpc_dec.c in JasPer before 1.900.4 allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted XRsiz value in a BMP image to the imginfo command.",
        "git_url": "https://github.com/jasper-software/jasper/commit/d8c2604cd438c41ec72aff52c16ebd8183068020",
        "commit_title": "Added range check on XRsiz and YRsiz fields of SIZ marker segment.",
        "commit_text": "",
        "func_before": "static int jpc_siz_getparms(jpc_ms_t *ms, jpc_cstate_t *cstate,\n  jas_stream_t *in)\n{\n\tjpc_siz_t *siz = &ms->parms.siz;\n\tunsigned int i;\n\tuint_fast8_t tmp;\n\n\t/* Eliminate compiler warning about unused variables. */\n\tcstate = 0;\n\n\tif (jpc_getuint16(in, &siz->caps) ||\n\t  jpc_getuint32(in, &siz->width) ||\n\t  jpc_getuint32(in, &siz->height) ||\n\t  jpc_getuint32(in, &siz->xoff) ||\n\t  jpc_getuint32(in, &siz->yoff) ||\n\t  jpc_getuint32(in, &siz->tilewidth) ||\n\t  jpc_getuint32(in, &siz->tileheight) ||\n\t  jpc_getuint32(in, &siz->tilexoff) ||\n\t  jpc_getuint32(in, &siz->tileyoff) ||\n\t  jpc_getuint16(in, &siz->numcomps)) {\n\t\treturn -1;\n\t}\n\tif (!siz->width || !siz->height || !siz->tilewidth ||\n\t  !siz->tileheight || !siz->numcomps) {\n\t\treturn -1;\n\t}\n\tif (!(siz->comps = jas_alloc2(siz->numcomps, sizeof(jpc_sizcomp_t)))) {\n\t\treturn -1;\n\t}\n\tfor (i = 0; i < siz->numcomps; ++i) {\n\t\tif (jpc_getuint8(in, &tmp) ||\n\t\t  jpc_getuint8(in, &siz->comps[i].hsamp) ||\n\t\t  jpc_getuint8(in, &siz->comps[i].vsamp)) {\n\t\t\tjas_free(siz->comps);\n\t\t\treturn -1;\n\t\t}\n\t\tsiz->comps[i].sgnd = (tmp >> 7) & 1;\n\t\tsiz->comps[i].prec = (tmp & 0x7f) + 1;\n\t}\n\tif (jas_stream_eof(in)) {\n\t\tjas_free(siz->comps);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "func": "static int jpc_siz_getparms(jpc_ms_t *ms, jpc_cstate_t *cstate,\n  jas_stream_t *in)\n{\n\tjpc_siz_t *siz = &ms->parms.siz;\n\tunsigned int i;\n\tuint_fast8_t tmp;\n\n\t/* Eliminate compiler warning about unused variables. */\n\tcstate = 0;\n\n\tif (jpc_getuint16(in, &siz->caps) ||\n\t  jpc_getuint32(in, &siz->width) ||\n\t  jpc_getuint32(in, &siz->height) ||\n\t  jpc_getuint32(in, &siz->xoff) ||\n\t  jpc_getuint32(in, &siz->yoff) ||\n\t  jpc_getuint32(in, &siz->tilewidth) ||\n\t  jpc_getuint32(in, &siz->tileheight) ||\n\t  jpc_getuint32(in, &siz->tilexoff) ||\n\t  jpc_getuint32(in, &siz->tileyoff) ||\n\t  jpc_getuint16(in, &siz->numcomps)) {\n\t\treturn -1;\n\t}\n\tif (!siz->width || !siz->height || !siz->tilewidth ||\n\t  !siz->tileheight || !siz->numcomps) {\n\t\treturn -1;\n\t}\n\tif (!(siz->comps = jas_alloc2(siz->numcomps, sizeof(jpc_sizcomp_t)))) {\n\t\treturn -1;\n\t}\n\tfor (i = 0; i < siz->numcomps; ++i) {\n\t\tif (jpc_getuint8(in, &tmp) ||\n\t\t  jpc_getuint8(in, &siz->comps[i].hsamp) ||\n\t\t  jpc_getuint8(in, &siz->comps[i].vsamp)) {\n\t\t\tjas_free(siz->comps);\n\t\t\treturn -1;\n\t\t}\n\t\tif (siz->comps[i].hsamp == 0 || siz->comps[i].hsamp > 255) {\n\t\t\tjas_eprintf(\"invalid XRsiz value %d\\n\", siz->comps[i].hsamp);\n\t\t\tjas_free(siz->comps);\n\t\t\treturn -1;\n\t\t}\n\t\tif (siz->comps[i].vsamp == 0 || siz->comps[i].vsamp > 255) {\n\t\t\tjas_eprintf(\"invalid YRsiz value %d\\n\", siz->comps[i].vsamp);\n\t\t\tjas_free(siz->comps);\n\t\t\treturn -1;\n\t\t}\n\t\tsiz->comps[i].sgnd = (tmp >> 7) & 1;\n\t\tsiz->comps[i].prec = (tmp & 0x7f) + 1;\n\t}\n\tif (jas_stream_eof(in)) {\n\t\tjas_free(siz->comps);\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,6 +34,16 @@\n \t\t\tjas_free(siz->comps);\n \t\t\treturn -1;\n \t\t}\n+\t\tif (siz->comps[i].hsamp == 0 || siz->comps[i].hsamp > 255) {\n+\t\t\tjas_eprintf(\"invalid XRsiz value %d\\n\", siz->comps[i].hsamp);\n+\t\t\tjas_free(siz->comps);\n+\t\t\treturn -1;\n+\t\t}\n+\t\tif (siz->comps[i].vsamp == 0 || siz->comps[i].vsamp > 255) {\n+\t\t\tjas_eprintf(\"invalid YRsiz value %d\\n\", siz->comps[i].vsamp);\n+\t\t\tjas_free(siz->comps);\n+\t\t\treturn -1;\n+\t\t}\n \t\tsiz->comps[i].sgnd = (tmp >> 7) & 1;\n \t\tsiz->comps[i].prec = (tmp & 0x7f) + 1;\n \t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (siz->comps[i].hsamp == 0 || siz->comps[i].hsamp > 255) {",
                "\t\t\tjas_eprintf(\"invalid XRsiz value %d\\n\", siz->comps[i].hsamp);",
                "\t\t\tjas_free(siz->comps);",
                "\t\t\treturn -1;",
                "\t\t}",
                "\t\tif (siz->comps[i].vsamp == 0 || siz->comps[i].vsamp > 255) {",
                "\t\t\tjas_eprintf(\"invalid YRsiz value %d\\n\", siz->comps[i].vsamp);",
                "\t\t\tjas_free(siz->comps);",
                "\t\t\treturn -1;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-32613",
        "func_name": "radareorg/radare2/get_none_object",
        "description": "In radare2 through 5.3.0 there is a double free vulnerability in the pyc parse via a crafted file which can lead to DoS.",
        "git_url": "https://github.com/radareorg/radare2/commit/5e16e2d1c9fe245e4c17005d779fde91ec0b9c05",
        "commit_title": "Fix #18666 - uaf in python bin parser",
        "commit_text": "",
        "func_before": "static pyc_object *get_none_object(void) {\n\tpyc_object *ret;\n\n\tret = R_NEW0 (pyc_object);\n\tif (!ret) {\n\t\treturn NULL;\n\t}\n\tret->type = TYPE_NONE;\n\tret->data = strdup (\"None\");\n\tif (!ret->data) {\n\t\tR_FREE (ret);\n\t}\n\treturn ret;\n}",
        "func": "static pyc_object *get_none_object(void) {\n\tpyc_object *ret = R_NEW0 (pyc_object);\n\tif (!ret) {\n\t\treturn NULL;\n\t}\n\tret->type = TYPE_NONE;\n\tret->data = strdup (\"None\");\n\tif (!ret->data) {\n\t\tR_FREE (ret);\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,5 @@\n static pyc_object *get_none_object(void) {\n-\tpyc_object *ret;\n-\n-\tret = R_NEW0 (pyc_object);\n+\tpyc_object *ret = R_NEW0 (pyc_object);\n \tif (!ret) {\n \t\treturn NULL;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tpyc_object *ret;",
                "",
                "\tret = R_NEW0 (pyc_object);"
            ],
            "added_lines": [
                "\tpyc_object *ret = R_NEW0 (pyc_object);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-32613",
        "func_name": "radareorg/radare2/get_object",
        "description": "In radare2 through 5.3.0 there is a double free vulnerability in the pyc parse via a crafted file which can lead to DoS.",
        "git_url": "https://github.com/radareorg/radare2/commit/5e16e2d1c9fe245e4c17005d779fde91ec0b9c05",
        "commit_title": "Fix #18666 - uaf in python bin parser",
        "commit_text": "",
        "func_before": "static pyc_object *get_object(RBuffer *buffer) {\n\tbool error = false;\n\tpyc_object *ret = NULL;\n\tut8 code = get_ut8 (buffer, &error);\n\tut8 flag = code & FLAG_REF;\n\tRListIter *ref_idx = NULL;\n\tut8 type = code & ~FLAG_REF;\n\n\tif (error) {\n\t\treturn NULL;\n\t}\n\n\tif (flag) {\n\t\tret = get_none_object ();\n\t\tif (!ret) {\n\t\t\treturn NULL;\n\t\t}\n\t\tref_idx = r_list_append (refs, ret);\n\t\tif (!ref_idx) {\n\t\t\tfree_object (ret);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tswitch (type) {\n\tcase TYPE_NULL:\n\t\tfree_object (ret);\n\t\treturn NULL;\n\tcase TYPE_TRUE:\n\t\tfree_object (ret);\n\t\treturn get_true_object ();\n\tcase TYPE_FALSE:\n\t\tfree_object (ret);\n\t\treturn get_false_object ();\n\tcase TYPE_NONE:\n\t\tfree_object (ret);\n\t\treturn get_none_object ();\n\tcase TYPE_REF:\n\t\tfree_object (ret);\n\t\treturn get_ref_object (buffer);\n\tcase TYPE_SMALL_TUPLE:\n\t\tret = get_small_tuple_object (buffer);\n\t\tbreak;\n\tcase TYPE_TUPLE:\n\t\tret = get_tuple_object (buffer);\n\t\tbreak;\n\tcase TYPE_STRING:\n\t\tret = get_string_object (buffer);\n\t\tbreak;\n\tcase TYPE_CODE_v0:\n\t\tret = get_code_object (buffer);\n\t\tif (ret) {\n\t\t\tret->type = TYPE_CODE_v0;\n\t\t}\n\t\tbreak;\n\tcase TYPE_CODE_v1:\n\t\tret = get_code_object (buffer);\n\t\tif (ret) {\n\t\t\tret->type = TYPE_CODE_v1;\n\t\t}\n\t\tbreak;\n\tcase TYPE_INT:\n\t\tret = get_int_object (buffer);\n\t\tbreak;\n\tcase TYPE_ASCII_INTERNED:\n\t\tret = get_ascii_interned_object (buffer);\n\t\tbreak;\n\tcase TYPE_SHORT_ASCII:\n\t\tret = get_short_ascii_object (buffer);\n\t\tbreak;\n\tcase TYPE_ASCII:\n\t\tret = get_ascii_object (buffer);\n\t\tbreak;\n\tcase TYPE_SHORT_ASCII_INTERNED:\n\t\tret = get_short_ascii_interned_object (buffer);\n\t\tbreak;\n\tcase TYPE_INT64:\n\t\tret = get_int64_object (buffer);\n\t\tbreak;\n\tcase TYPE_INTERNED:\n\t\tret = get_interned_object (buffer);\n\t\tbreak;\n\tcase TYPE_STRINGREF:\n\t\tret = get_stringref_object (buffer);\n\t\tbreak;\n\tcase TYPE_FLOAT:\n\t\tret = get_float_object (buffer);\n\t\tbreak;\n\tcase TYPE_BINARY_FLOAT:\n\t\tret = get_binary_float_object (buffer);\n\t\tbreak;\n\tcase TYPE_COMPLEX:\n\t\tret = get_complex_object (buffer); // behaviour depends on Python version\n\t\tbreak;\n\tcase TYPE_BINARY_COMPLEX:\n\t\tret = get_binary_complex_object (buffer);\n\t\tbreak;\n\tcase TYPE_LIST:\n\t\tret = get_list_object (buffer);\n\t\tbreak;\n\tcase TYPE_LONG:\n\t\tret = get_long_object (buffer);\n\t\tbreak;\n\tcase TYPE_UNICODE:\n\t\tret = get_unicode_object (buffer);\n\t\tbreak;\n\tcase TYPE_DICT:\n\t\tret = get_dict_object (buffer);\n\t\tbreak;\n\tcase TYPE_FROZENSET:\n\tcase TYPE_SET:\n\t\tret = get_set_object (buffer);\n\t\tbreak;\n\tcase TYPE_STOPITER:\n\tcase TYPE_ELLIPSIS:\n\t\tret = R_NEW0 (pyc_object);\n\t\tbreak;\n\tcase TYPE_UNKNOWN:\n\t\teprintf (\"Get not implemented for type 0x%x\\n\", type);\n\t\tfree_object (ret);\n\t\treturn NULL;\n\tcase 0:\n\t\t// nop\n\t\tbreak;\n\tdefault:\n\t\teprintf (\"Undefined type in get_object (0x%x)\\n\", type);\n\t\tfree_object (ret);\n\t\treturn NULL;\n\t}\n\n\tif (flag && ref_idx) {\n\t\tfree_object (ref_idx->data);\n\t\tref_idx->data = copy_object (ret);\n\t}\n\treturn ret;\n}",
        "func": "static pyc_object *get_object(RBuffer *buffer) {\n\tbool error = false;\n\tpyc_object *ret = NULL;\n\tut8 code = get_ut8 (buffer, &error);\n\tut8 flag = code & FLAG_REF;\n\tRListIter *ref_idx = NULL;\n\tut8 type = code & ~FLAG_REF;\n\n\tif (error) {\n\t\treturn NULL;\n\t}\n\n\tif (flag) {\n\t\tret = get_none_object ();\n\t\tif (!ret) {\n\t\t\treturn NULL;\n\t\t}\n\t\tref_idx = r_list_append (refs, ret);\n\t\tif (!ref_idx) {\n\t\t\tfree_object (ret);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tswitch (type) {\n\tcase TYPE_NULL:\n\t\tfree_object (ret);\n\t\treturn NULL;\n\tcase TYPE_TRUE:\n\t\tfree_object (ret);\n\t\treturn get_true_object ();\n\tcase TYPE_FALSE:\n\t\tfree_object (ret);\n\t\treturn get_false_object ();\n\tcase TYPE_NONE:\n\t\tfree_object (ret);\n\t\treturn get_none_object ();\n\tcase TYPE_REF:\n\t\tfree_object (ret);\n\t\treturn get_ref_object (buffer);\n\tcase TYPE_SMALL_TUPLE:\n\t\tret = get_small_tuple_object (buffer);\n\t\tbreak;\n\tcase TYPE_TUPLE:\n\t\tret = get_tuple_object (buffer);\n\t\tbreak;\n\tcase TYPE_STRING:\n\t\tret = get_string_object (buffer);\n\t\tbreak;\n\tcase TYPE_CODE_v0:\n\t\tret = get_code_object (buffer);\n\t\tif (ret) {\n\t\t\tret->type = TYPE_CODE_v0;\n\t\t}\n\t\tbreak;\n\tcase TYPE_CODE_v1:\n\t\tret = get_code_object (buffer);\n\t\tif (ret) {\n\t\t\tret->type = TYPE_CODE_v1;\n\t\t}\n\t\tbreak;\n\tcase TYPE_INT:\n\t\tret = get_int_object (buffer);\n\t\tbreak;\n\tcase TYPE_ASCII_INTERNED:\n\t\tret = get_ascii_interned_object (buffer);\n\t\tbreak;\n\tcase TYPE_SHORT_ASCII:\n\t\tret = get_short_ascii_object (buffer);\n\t\tbreak;\n\tcase TYPE_ASCII:\n\t\tret = get_ascii_object (buffer);\n\t\tbreak;\n\tcase TYPE_SHORT_ASCII_INTERNED:\n\t\tret = get_short_ascii_interned_object (buffer);\n\t\tbreak;\n\tcase TYPE_INT64:\n\t\tret = get_int64_object (buffer);\n\t\tbreak;\n\tcase TYPE_INTERNED:\n\t\tret = get_interned_object (buffer);\n\t\tbreak;\n\tcase TYPE_STRINGREF:\n\t\tret = get_stringref_object (buffer);\n\t\tbreak;\n\tcase TYPE_FLOAT:\n\t\tret = get_float_object (buffer);\n\t\tbreak;\n\tcase TYPE_BINARY_FLOAT:\n\t\tret = get_binary_float_object (buffer);\n\t\tbreak;\n\tcase TYPE_COMPLEX:\n\t\tret = get_complex_object (buffer); // behaviour depends on Python version\n\t\tbreak;\n\tcase TYPE_BINARY_COMPLEX:\n\t\tret = get_binary_complex_object (buffer);\n\t\tbreak;\n\tcase TYPE_LIST:\n\t\tret = get_list_object (buffer);\n\t\tbreak;\n\tcase TYPE_LONG:\n\t\tret = get_long_object (buffer);\n\t\tbreak;\n\tcase TYPE_UNICODE:\n\t\tret = get_unicode_object (buffer);\n\t\tbreak;\n\tcase TYPE_DICT:\n\t\tret = get_dict_object (buffer);\n\t\tbreak;\n\tcase TYPE_FROZENSET:\n\tcase TYPE_SET:\n\t\tret = get_set_object (buffer);\n\t\tbreak;\n\tcase TYPE_STOPITER:\n\tcase TYPE_ELLIPSIS:\n\t\tret = R_NEW0 (pyc_object);\n\t\tbreak;\n\tcase TYPE_UNKNOWN:\n\t\teprintf (\"Get not implemented for type 0x%x\\n\", type);\n\t\tfree_object (ret);\n\t\treturn NULL;\n\tcase 0:\n\t\t// nop\n\t\tbreak;\n\tdefault:\n\t\teprintf (\"Undefined type in get_object (0x%x)\\n\", type);\n\t\tfree_object (ret);\n\t\treturn NULL;\n\t}\n\n\tif (flag && ref_idx) {\n\t\tif (ref_idx->data != ret) {\n\t\t\tfree_object (ref_idx->data);\n\t\t}\n\t\tref_idx->data = copy_object (ret);\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -129,7 +129,9 @@\n \t}\n \n \tif (flag && ref_idx) {\n-\t\tfree_object (ref_idx->data);\n+\t\tif (ref_idx->data != ret) {\n+\t\t\tfree_object (ref_idx->data);\n+\t\t}\n \t\tref_idx->data = copy_object (ret);\n \t}\n \treturn ret;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tfree_object (ref_idx->data);"
            ],
            "added_lines": [
                "\t\tif (ref_idx->data != ret) {",
                "\t\t\tfree_object (ref_idx->data);",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-32613",
        "func_name": "radareorg/radare2/rebase_buffer",
        "description": "In radare2 through 5.3.0 there is a double free vulnerability in the pyc parse via a crafted file which can lead to DoS.",
        "git_url": "https://github.com/radareorg/radare2/commit/a07dedb804a82bc01c07072861942dd80c6b6d62",
        "commit_title": "Fix #18667 - division by zero in the macho parser ##bin",
        "commit_text": "",
        "func_before": "static void rebase_buffer(struct MACH0_(obj_t) *obj, ut64 off, RIODesc *fd, ut8 *buf, int count) {\n\tif (obj->rebasing_buffer) {\n\t\treturn;\n\t}\n\tobj->rebasing_buffer = true;\n\tut64 eob = off + count;\n\tint i = 0;\n\tfor (; i < obj->nsegs; i++) {\n\t\tif (!obj->chained_starts[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tut64 page_size = obj->chained_starts[i]->page_size;\n\t\tut64 start = obj->segs[i].fileoff;\n\t\tut64 end = start + obj->segs[i].filesize;\n\t\tif (end >= off && start <= eob) {\n\t\t\tut64 page_idx = (R_MAX (start, off) - start) / page_size;\n\t\t\tut64 page_end_idx = (R_MIN (eob, end) - start) / page_size;\n\t\t\tfor (; page_idx <= page_end_idx; page_idx++) {\n\t\t\t\tif (page_idx >= obj->chained_starts[i]->page_count) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tut16 page_start = obj->chained_starts[i]->page_start[page_idx];\n\t\t\t\tif (page_start == DYLD_CHAINED_PTR_START_NONE) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tut64 cursor = start + page_idx * page_size + page_start;\n\t\t\t\twhile (cursor < eob && cursor < end) {\n\t\t\t\t\tut8 tmp[8];\n\t\t\t\t\tif (r_buf_read_at (obj->b, cursor, tmp, 8) != 8) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tut64 raw_ptr = r_read_le64 (tmp);\n\t\t\t\t\tbool is_auth = IS_PTR_AUTH (raw_ptr);\n\t\t\t\t\tbool is_bind = IS_PTR_BIND (raw_ptr);\n\t\t\t\t\tut64 ptr_value = raw_ptr;\n\t\t\t\t\tut64 delta;\n\t\t\t\t\tif (is_auth && is_bind) {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_auth_bind *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_auth_bind *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t} else if (!is_auth && is_bind) {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_bind *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_bind *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t} else if (is_auth && !is_bind) {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_auth_rebase *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_auth_rebase *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t\tptr_value = p->target + obj->baddr;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_rebase *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_rebase *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t\tptr_value = ((ut64)p->high8 << 56) | p->target;\n\t\t\t\t\t}\n\t\t\t\t\tut64 in_buf = cursor - off;\n\t\t\t\t\tif (cursor >= off && cursor <= eob - 8) {\n\t\t\t\t\t\tr_write_le64 (&buf[in_buf], ptr_value);\n\t\t\t\t\t}\n\t\t\t\t\tcursor += delta * 8;\n\t\t\t\t\tif (!delta) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tobj->rebasing_buffer = false;\n}",
        "func": "static void rebase_buffer(struct MACH0_(obj_t) *obj, ut64 off, RIODesc *fd, ut8 *buf, int count) {\n\tif (obj->rebasing_buffer) {\n\t\treturn;\n\t}\n\tobj->rebasing_buffer = true;\n\tut64 eob = off + count;\n\tint i = 0;\n\tfor (; i < obj->nsegs; i++) {\n\t\tif (!obj->chained_starts[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tint page_size = obj->chained_starts[i]->page_size;\n\t\tif (page_size < 1) {\n\t\t\tpage_size = 4096;\n\t\t}\n\t\tut64 start = obj->segs[i].fileoff;\n\t\tut64 end = start + obj->segs[i].filesize;\n\t\tif (end >= off && start <= eob) {\n\t\t\tut64 page_idx = (R_MAX (start, off) - start) / page_size;\n\t\t\tut64 page_end_idx = (R_MIN (eob, end) - start) / page_size;\n\t\t\tfor (; page_idx <= page_end_idx; page_idx++) {\n\t\t\t\tif (page_idx >= obj->chained_starts[i]->page_count) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tut16 page_start = obj->chained_starts[i]->page_start[page_idx];\n\t\t\t\tif (page_start == DYLD_CHAINED_PTR_START_NONE) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tut64 cursor = start + page_idx * page_size + page_start;\n\t\t\t\twhile (cursor < eob && cursor < end) {\n\t\t\t\t\tut8 tmp[8];\n\t\t\t\t\tif (r_buf_read_at (obj->b, cursor, tmp, 8) != 8) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tut64 raw_ptr = r_read_le64 (tmp);\n\t\t\t\t\tbool is_auth = IS_PTR_AUTH (raw_ptr);\n\t\t\t\t\tbool is_bind = IS_PTR_BIND (raw_ptr);\n\t\t\t\t\tut64 ptr_value = raw_ptr;\n\t\t\t\t\tut64 delta;\n\t\t\t\t\tif (is_auth && is_bind) {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_auth_bind *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_auth_bind *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t} else if (!is_auth && is_bind) {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_bind *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_bind *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t} else if (is_auth && !is_bind) {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_auth_rebase *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_auth_rebase *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t\tptr_value = p->target + obj->baddr;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tstruct dyld_chained_ptr_arm64e_rebase *p =\n\t\t\t\t\t\t\t\t(struct dyld_chained_ptr_arm64e_rebase *) &raw_ptr;\n\t\t\t\t\t\tdelta = p->next;\n\t\t\t\t\t\tptr_value = ((ut64)p->high8 << 56) | p->target;\n\t\t\t\t\t}\n\t\t\t\t\tut64 in_buf = cursor - off;\n\t\t\t\t\tif (cursor >= off && cursor <= eob - 8) {\n\t\t\t\t\t\tr_write_le64 (&buf[in_buf], ptr_value);\n\t\t\t\t\t}\n\t\t\t\t\tcursor += delta * 8;\n\t\t\t\t\tif (!delta) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tobj->rebasing_buffer = false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,10 @@\n \t\tif (!obj->chained_starts[i]) {\n \t\t\tcontinue;\n \t\t}\n-\t\tut64 page_size = obj->chained_starts[i]->page_size;\n+\t\tint page_size = obj->chained_starts[i]->page_size;\n+\t\tif (page_size < 1) {\n+\t\t\tpage_size = 4096;\n+\t\t}\n \t\tut64 start = obj->segs[i].fileoff;\n \t\tut64 end = start + obj->segs[i].filesize;\n \t\tif (end >= off && start <= eob) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tut64 page_size = obj->chained_starts[i]->page_size;"
            ],
            "added_lines": [
                "\t\tint page_size = obj->chained_starts[i]->page_size;",
                "\t\tif (page_size < 1) {",
                "\t\t\tpage_size = 4096;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29517",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. A malicious user could trigger a division by 0 in `Conv3D` implementation. The implementation(https://github.com/tensorflow/tensorflow/blob/42033603003965bffac51ae171b51801565e002d/tensorflow/core/kernels/conv_ops_3d.cc#L143-L145) does a modulo operation based on user controlled input. Thus, when `filter` has a 0 as the fifth element, this results in a division by 0. Additionally, if the shape of the two tensors is not valid, an Eigen assertion can be triggered, resulting in a program crash. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/799f835a3dfa00a4d852defa29b15841eea9d64f",
        "commit_title": "Fix 2 issues with `Conv3D`.",
        "commit_text": " We have an issue where the dimensions are not matching and this causes Eigen to crash on an assert.  Then, we have an issue where we accidentally do a division by 0.  PiperOrigin-RevId: 369242785",
        "func_before": "void Compute(OpKernelContext* context) override {\n    // Input tensor is of the following dimensions:\n    // [ batch, in_z, in_y, in_x, in_channels ]\n    const Tensor& input = context->input(0);\n\n    // Input filter is of the following dimensions:\n    // [ filter_z, filter_y, filter_x, in_channels, out_channels]\n    const Tensor& filter = context->input(1);\n\n    // NOTE: The ordering of the spatial dimensions is arbitrary, but has to be\n    // kept consistent between input/filter/output.\n    OP_REQUIRES(context, input.dims() == 5,\n                errors::InvalidArgument(\"input must be 5-dimensional\"));\n    OP_REQUIRES(context, filter.dims() == 5,\n                errors::InvalidArgument(\"filter must be 5-dimensional\"));\n\n    const int64 in_depth = GetTensorDim(input, data_format_, 'C');\n    const int64 in_batch = GetTensorDim(input, data_format_, 'N');\n\n    const int64 filter_depth = filter.dim_size(3);\n    const int64 out_depth = filter.dim_size(4);\n\n    OP_REQUIRES(context, in_depth % filter_depth == 0,\n                errors::InvalidArgument(\n                    \"Input depth must be evenly divisible by filter depth: \",\n                    in_depth, \" vs \", filter_depth));\n\n    // Dimension order for these arrays is: z, y, x.\n    std::array<int64, 3> input_size = {\n        {GetTensorDim(input, data_format_, '0'),\n         GetTensorDim(input, data_format_, '1'),\n         GetTensorDim(input, data_format_, '2')}};\n    std::array<int64, 3> filter_size = {\n        {filter.dim_size(0), filter.dim_size(1), filter.dim_size(2)}};\n    std::array<int64, 3> dilations = {\n        {GetTensorDim(dilation_, data_format_, '0'),\n         GetTensorDim(dilation_, data_format_, '1'),\n         GetTensorDim(dilation_, data_format_, '2')}};\n    std::array<int64, 3> strides = {{GetTensorDim(stride_, data_format_, '0'),\n                                     GetTensorDim(stride_, data_format_, '1'),\n                                     GetTensorDim(stride_, data_format_, '2')}};\n    std::array<int64, 3> out, padding;\n\n    OP_REQUIRES_OK(\n        context, Get3dOutputSizeV2(input_size, filter_size, dilations, strides,\n                                   padding_, &out, &padding));\n    TensorShape out_shape = ShapeFromFormat(\n        data_format_, in_batch, {{out[0], out[1], out[2]}}, out_depth);\n    Tensor* output;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n\n    // Return early if nothing to do.\n    if (out_shape.num_elements() == 0) return;\n\n    LaunchConvOp<Device, T>::launch(context, cudnn_use_autotune_, input, filter,\n                                    dilations, strides, padding_, data_format_,\n                                    output);\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    // Input tensor is of the following dimensions:\n    // [ batch, in_z, in_y, in_x, in_channels ]\n    const Tensor& input = context->input(0);\n\n    // Input filter is of the following dimensions:\n    // [ filter_z, filter_y, filter_x, in_channels, out_channels]\n    const Tensor& filter = context->input(1);\n\n    // NOTE: The ordering of the spatial dimensions is arbitrary, but has to be\n    // kept consistent between input/filter/output.\n    OP_REQUIRES(context, input.dims() == 5,\n                errors::InvalidArgument(\"input must be 5-dimensional\"));\n    OP_REQUIRES(context, filter.dims() == 5,\n                errors::InvalidArgument(\"filter must be 5-dimensional\"));\n\n    const int64 in_depth = GetTensorDim(input, data_format_, 'C');\n    const int64 in_batch = GetTensorDim(input, data_format_, 'N');\n\n    const int64 filter_depth = filter.dim_size(3);\n    const int64 out_depth = filter.dim_size(4);\n\n    OP_REQUIRES(context, filter_depth != 0,\n                errors::InvalidArgument(\"filter_depth must be non-zero\"));\n    OP_REQUIRES(context, in_depth % filter_depth == 0,\n                errors::InvalidArgument(\n                    \"Input depth must be evenly divisible by filter depth: \",\n                    in_depth, \" vs \", filter_depth));\n\n    // Dimension order for these arrays is: z, y, x.\n    std::array<int64, 3> input_size = {\n        {GetTensorDim(input, data_format_, '0'),\n         GetTensorDim(input, data_format_, '1'),\n         GetTensorDim(input, data_format_, '2')}};\n    std::array<int64, 3> filter_size = {\n        {filter.dim_size(0), filter.dim_size(1), filter.dim_size(2)}};\n    std::array<int64, 3> dilations = {\n        {GetTensorDim(dilation_, data_format_, '0'),\n         GetTensorDim(dilation_, data_format_, '1'),\n         GetTensorDim(dilation_, data_format_, '2')}};\n    std::array<int64, 3> strides = {{GetTensorDim(stride_, data_format_, '0'),\n                                     GetTensorDim(stride_, data_format_, '1'),\n                                     GetTensorDim(stride_, data_format_, '2')}};\n    std::array<int64, 3> out, padding;\n\n    OP_REQUIRES_OK(\n        context, Get3dOutputSizeV2(input_size, filter_size, dilations, strides,\n                                   padding_, &out, &padding));\n    TensorShape out_shape = ShapeFromFormat(\n        data_format_, in_batch, {{out[0], out[1], out[2]}}, out_depth);\n    Tensor* output;\n    OP_REQUIRES_OK(context, context->allocate_output(0, out_shape, &output));\n\n    // Return early if nothing to do.\n    if (out_shape.num_elements() == 0) return;\n\n    LaunchConvOp<Device, T>::launch(context, cudnn_use_autotune_, input, filter,\n                                    dilations, strides, padding_, data_format_,\n                                    output);\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,6 +20,8 @@\n     const int64 filter_depth = filter.dim_size(3);\n     const int64 out_depth = filter.dim_size(4);\n \n+    OP_REQUIRES(context, filter_depth != 0,\n+                errors::InvalidArgument(\"filter_depth must be non-zero\"));\n     OP_REQUIRES(context, in_depth % filter_depth == 0,\n                 errors::InvalidArgument(\n                     \"Input depth must be evenly divisible by filter depth: \",",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(context, filter_depth != 0,",
                "                errors::InvalidArgument(\"filter_depth must be non-zero\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29517",
        "func_name": "tensorflow/launch",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. A malicious user could trigger a division by 0 in `Conv3D` implementation. The implementation(https://github.com/tensorflow/tensorflow/blob/42033603003965bffac51ae171b51801565e002d/tensorflow/core/kernels/conv_ops_3d.cc#L143-L145) does a modulo operation based on user controlled input. Thus, when `filter` has a 0 as the fifth element, this results in a division by 0. Additionally, if the shape of the two tensors is not valid, an Eigen assertion can be triggered, resulting in a program crash. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/799f835a3dfa00a4d852defa29b15841eea9d64f",
        "commit_title": "Fix 2 issues with `Conv3D`.",
        "commit_text": " We have an issue where the dimensions are not matching and this causes Eigen to crash on an assert.  Then, we have an issue where we accidentally do a division by 0.  PiperOrigin-RevId: 369242785",
        "func_before": "static void launch(OpKernelContext* context, bool cudnn_use_autotune,\n                     const Tensor& input, const Tensor& filter,\n                     const std::array<int64, 3>& dilations,\n                     const std::array<int64, 3>& strides, const Padding padding,\n                     TensorFormat data_format, Tensor* output) {\n    OP_REQUIRES(context, data_format == FORMAT_NHWC,\n                errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                        \"currently only supports the NHWC \"\n                                        \"tensor format.\"));\n    OP_REQUIRES(context,\n                dilations[0] == 1 && dilations[1] == 1 && dilations[2] == 1,\n                errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                        \"currently only supports dilated rates \"\n                                        \"of 1.\"));\n    functor::CuboidConvolution<CPUDevice, T>()(\n        context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),\n        input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],\n        strides[0], BrainPadding2EigenPadding(padding));\n  }",
        "func": "static void launch(OpKernelContext* context, bool cudnn_use_autotune,\n                     const Tensor& input, const Tensor& filter,\n                     const std::array<int64, 3>& dilations,\n                     const std::array<int64, 3>& strides, const Padding padding,\n                     TensorFormat data_format, Tensor* output) {\n    OP_REQUIRES(context, data_format == FORMAT_NHWC,\n                errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                        \"currently only supports the NHWC \"\n                                        \"tensor format.\"));\n    OP_REQUIRES(context,\n                dilations[0] == 1 && dilations[1] == 1 && dilations[2] == 1,\n                errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                        \"currently only supports dilated rates \"\n                                        \"of 1.\"));\n    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),\n                errors::InvalidArgument(\n                    \"Number of channels in filter (\", filter.dim_size(3),\n                    \") must match last dimension of input (\",\n                    input.dim_size(input.dims() - 1), \")\"));\n    functor::CuboidConvolution<CPUDevice, T>()(\n        context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),\n        input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],\n        strides[0], BrainPadding2EigenPadding(padding));\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,11 @@\n                 errors::InvalidArgument(\"CPU implementation of Conv3D \"\n                                         \"currently only supports dilated rates \"\n                                         \"of 1.\"));\n+    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),\n+                errors::InvalidArgument(\n+                    \"Number of channels in filter (\", filter.dim_size(3),\n+                    \") must match last dimension of input (\",\n+                    input.dim_size(input.dims() - 1), \")\"));\n     functor::CuboidConvolution<CPUDevice, T>()(\n         context->eigen_device<CPUDevice>(), output->tensor<T, 5>(),\n         input.tensor<T, 5>(), filter.tensor<T, 5>(), strides[2], strides[1],",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(context, filter.dim_size(3) == input.dim_size(input.dims() - 1),",
                "                errors::InvalidArgument(",
                "                    \"Number of channels in filter (\", filter.dim_size(3),",
                "                    \") must match last dimension of input (\",",
                "                    input.dim_size(input.dims() - 1), \")\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29524",
        "func_name": "tensorflow/ConvBackpropComputeDimensionsV2",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a division by 0 in `tf.raw_ops.Conv2DBackpropFilter`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/496c2630e51c1a478f095b084329acedb253db6b/tensorflow/core/kernels/conv_grad_shape_utils.cc#L130) does a modulus operation where the divisor is controlled by the caller. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/fca9874a9b42a2134f907d2fb46ab774a831404a",
        "commit_title": "Prevent another division by zero.",
        "commit_text": " PiperOrigin-RevId: 369338598",
        "func_before": "Status ConvBackpropComputeDimensionsV2(\n    StringPiece label, int num_spatial_dims, const TensorShape& input_shape,\n    const TensorShape& filter_shape, const TensorShape& out_backprop_shape,\n    const gtl::ArraySlice<int32>& dilations, const std::vector<int32>& strides,\n    Padding padding, absl::Span<const int64> explicit_paddings,\n    TensorFormat data_format, ConvBackpropDimensions* dims) {\n  // The + 2 in the following line is for the batch and feature dimensions.\n  const int num_dims = num_spatial_dims + 2;\n  if (input_shape.dims() != num_dims) {\n    return errors::InvalidArgument(label, \": input must be \", num_dims,\n                                   \"-dimensional\");\n  }\n  if (filter_shape.dims() != num_dims) {\n    return errors::InvalidArgument(label, \": filter must be \", num_dims,\n                                   \"-dimensional\");\n  }\n  if (out_backprop_shape.dims() != num_dims) {\n    return errors::InvalidArgument(label, \": out_backprop must be \", num_dims,\n                                   \"-dimensional\");\n  }\n  int batch_dim = GetTensorBatchDimIndex(num_dims, data_format);\n  dims->batch_size = input_shape.dim_size(batch_dim);\n  if (dims->batch_size != out_backprop_shape.dim_size(batch_dim)) {\n    return errors::InvalidArgument(\n        label, \": input and out_backprop must have the same batch size.\",\n        \" Input batch: \", dims->batch_size,\n        \", outbackprop batch: \", out_backprop_shape.dim_size(batch_dim),\n        \", batch_dim: \", batch_dim);\n  }\n\n  int feature_dim = GetTensorFeatureDimIndex(num_dims, data_format);\n  dims->in_depth = input_shape.dim_size(feature_dim);\n  // The input and output feature dimensions are the second last and last\n  // dimensions of the filter Tensor.\n  VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"\n          << filter_shape.dim_size(num_dims - 2);\n  if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {\n    return errors::InvalidArgument(\n        label, \": input depth must be evenly divisible by filter depth\");\n  }\n  dims->out_depth = filter_shape.dim_size(num_dims - 1);\n  if (dims->out_depth != out_backprop_shape.dim_size(feature_dim)) {\n    return errors::InvalidArgument(\n        label, \": filter and out_backprop must have the same out_depth\");\n  }\n  dims->spatial_dims.resize(num_spatial_dims);\n  for (int i = 0; i < num_spatial_dims; ++i) {\n    int image_dim = GetTensorSpatialDimIndex(num_dims, data_format, i);\n    int64 padding_before = -1, padding_after = -1;\n    if (padding == EXPLICIT) {\n      padding_before = explicit_paddings[2 * image_dim];\n      padding_after = explicit_paddings[2 * image_dim + 1];\n    }\n    TF_RETURN_IF_ERROR(ConvBackpropExtractAndVerifyDimension(\n        label, input_shape, filter_shape, out_backprop_shape, dilations,\n        strides, padding, padding_before, padding_after, image_dim, i,\n        &dims->spatial_dims[i]));\n  }\n  return Status::OK();\n}",
        "func": "Status ConvBackpropComputeDimensionsV2(\n    StringPiece label, int num_spatial_dims, const TensorShape& input_shape,\n    const TensorShape& filter_shape, const TensorShape& out_backprop_shape,\n    const gtl::ArraySlice<int32>& dilations, const std::vector<int32>& strides,\n    Padding padding, absl::Span<const int64> explicit_paddings,\n    TensorFormat data_format, ConvBackpropDimensions* dims) {\n  // The + 2 in the following line is for the batch and feature dimensions.\n  const int num_dims = num_spatial_dims + 2;\n  if (input_shape.dims() != num_dims) {\n    return errors::InvalidArgument(label, \": input must be \", num_dims,\n                                   \"-dimensional\");\n  }\n  if (filter_shape.dims() != num_dims) {\n    return errors::InvalidArgument(label, \": filter must be \", num_dims,\n                                   \"-dimensional\");\n  }\n  if (out_backprop_shape.dims() != num_dims) {\n    return errors::InvalidArgument(label, \": out_backprop must be \", num_dims,\n                                   \"-dimensional\");\n  }\n  int batch_dim = GetTensorBatchDimIndex(num_dims, data_format);\n  dims->batch_size = input_shape.dim_size(batch_dim);\n  if (dims->batch_size != out_backprop_shape.dim_size(batch_dim)) {\n    return errors::InvalidArgument(\n        label, \": input and out_backprop must have the same batch size.\",\n        \" Input batch: \", dims->batch_size,\n        \", outbackprop batch: \", out_backprop_shape.dim_size(batch_dim),\n        \", batch_dim: \", batch_dim);\n  }\n\n  int feature_dim = GetTensorFeatureDimIndex(num_dims, data_format);\n  dims->in_depth = input_shape.dim_size(feature_dim);\n  // The input and output feature dimensions are the second last and last\n  // dimensions of the filter Tensor.\n  VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"\n          << filter_shape.dim_size(num_dims - 2);\n  if (filter_shape.dim_size(num_dims - 2) <= 0) {\n    return errors ::InvalidArgument(\n        label, \": filter depth must be strictly greated than zero\");\n  }\n  if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {\n    return errors::InvalidArgument(\n        label, \": input depth must be evenly divisible by filter depth\");\n  }\n  dims->out_depth = filter_shape.dim_size(num_dims - 1);\n  if (dims->out_depth != out_backprop_shape.dim_size(feature_dim)) {\n    return errors::InvalidArgument(\n        label, \": filter and out_backprop must have the same out_depth\");\n  }\n  dims->spatial_dims.resize(num_spatial_dims);\n  for (int i = 0; i < num_spatial_dims; ++i) {\n    int image_dim = GetTensorSpatialDimIndex(num_dims, data_format, i);\n    int64 padding_before = -1, padding_after = -1;\n    if (padding == EXPLICIT) {\n      padding_before = explicit_paddings[2 * image_dim];\n      padding_after = explicit_paddings[2 * image_dim + 1];\n    }\n    TF_RETURN_IF_ERROR(ConvBackpropExtractAndVerifyDimension(\n        label, input_shape, filter_shape, out_backprop_shape, dilations,\n        strides, padding, padding_before, padding_after, image_dim, i,\n        &dims->spatial_dims[i]));\n  }\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,6 +34,10 @@\n   // dimensions of the filter Tensor.\n   VLOG(2) << \"input vs filter_in depth \" << dims->in_depth << \" \"\n           << filter_shape.dim_size(num_dims - 2);\n+  if (filter_shape.dim_size(num_dims - 2) <= 0) {\n+    return errors ::InvalidArgument(\n+        label, \": filter depth must be strictly greated than zero\");\n+  }\n   if (dims->in_depth % filter_shape.dim_size(num_dims - 2)) {\n     return errors::InvalidArgument(\n         label, \": input depth must be evenly divisible by filter depth\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (filter_shape.dim_size(num_dims - 2) <= 0) {",
                "    return errors ::InvalidArgument(",
                "        label, \": filter depth must be strictly greated than zero\");",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29525",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a division by 0 in `tf.raw_ops.Conv2DBackpropInput`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/b40060c9f697b044e3107917c797ba052f4506ab/tensorflow/core/kernels/conv_grad_input_ops.h#L625-L655) does a division by a quantity that is controlled by the caller. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/2be2cdf3a123e231b16f766aa0e27d56b4606535",
        "commit_title": "Prevent yet another division by zero",
        "commit_text": " PiperOrigin-RevId: 369343977",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input_sizes = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n\n    TensorShape input_shape;\n    OP_REQUIRES_OK(context,\n                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n                                                   out_backprop.shape(),\n                                                   data_format_, &input_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(context,\n                   ConvBackpropComputeDimensionsV2(\n                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,\n                       input_shape, filter.shape(), out_backprop.shape(),\n                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,\n                       explicit_paddings_, data_format_, &dims));\n\n    OP_REQUIRES(context, dims.in_depth == filter.shape().dim_size(2),\n                errors::InvalidArgument(\"Computed input depth \", dims.in_depth,\n                                        \" doesn't match filter input depth \",\n                                        filter.shape().dim_size(2)));\n    OP_REQUIRES(\n        context, dims.out_depth == filter.shape().dim_size(3),\n        errors::InvalidArgument(\"Computed output depth \", dims.out_depth,\n                                \" doesn't match filter output depth \",\n                                filter.shape().dim_size(3)));\n\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_shape, &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input_shape.num_elements() == 0) {\n      return;\n    }\n\n// TODO(ezhulenev): Remove custom kernel and move XSMM support to\n// LaunchConv2DBackpropInputOp functor.\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardInputConvolution<Device, T>()(\n              context, context->eigen_device<Device>(),\n              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),\n              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#else\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n#endif\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // TODO(andydavis) Get L2/L3 cache sizes from device.\n    const size_t l2_cache_size = 256LL << 10;\n    const size_t l3_cache_size = 30LL << 20;\n\n    // Use L3 cache size as target working set size.\n    const size_t target_working_set_size = l3_cache_size / sizeof(T);\n\n    // Calculate size of matrices involved in MatMul: C = A x B.\n    const size_t size_A = output_image_size * dims.out_depth;\n\n    const size_t size_B = filter_total_size * dims.out_depth;\n\n    const size_t size_C = output_image_size * filter_total_size;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Calculate per-thread work unit size.\n    const size_t thread_work_unit_size =\n        work_unit_size / worker_threads.num_threads;\n\n    // Set minimum per-thread work unit size to size of L2 cache.\n    const size_t min_thread_work_unit_size = l2_cache_size / sizeof(T);\n\n    // Use parallel tensor contractions if there is no batching, or if the\n    // minimum per-thread work unit size threshold has been exceeded.\n    // Otherwise, revert to multiple single-threaded matmul ops running in\n    // parallel to keep all threads busy.\n    // TODO(andydavis) Explore alternatives to branching the code in this way\n    // (i.e. run multiple, parallel tensor contractions in another thread pool).\n    const bool use_parallel_contraction =\n        dims.batch_size == 1 ||\n        thread_work_unit_size >= min_thread_work_unit_size;\n\n    const size_t shard_size =\n        use_parallel_contraction\n            ? 1\n            : (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64>(shard_size),\n                                    static_cast<int64>(output_image_size),\n                                    static_cast<int64>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* filter_data = filter.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n\n    auto in_backprop_flat = in_backprop->template flat<T>();\n    T* input_backprop_data = in_backprop_flat.data();\n    in_backprop_flat.device(context->eigen_device<Device>()) =\n        in_backprop_flat.constant(T(0));\n\n    if (use_parallel_contraction) {\n      typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          TensorMap;\n      typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          ConstTensorMap;\n\n      // Initialize contraction dims (we need to transpose 'B' below).\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n      contract_dims[0].first = 1;\n      contract_dims[0].second = 1;\n\n      for (int image_id = 0; image_id < dims.batch_size; ++image_id) {\n        // Compute gradient into col_buffer.\n        TensorMap C(col_buffer_data, output_image_size, filter_total_size);\n\n        ConstTensorMap A(out_backprop_data + output_offset * image_id,\n                         output_image_size, dims.out_depth);\n        ConstTensorMap B(filter_data, filter_total_size, dims.out_depth);\n\n        C.device(context->eigen_cpu_device()) = A.contract(B, contract_dims);\n\n        Col2im<T>(\n            col_buffer_data, dims.in_depth, dims.spatial_dims[0].input_size,\n            dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n            pad_right, dims.spatial_dims[0].stride, dims.spatial_dims[1].stride,\n            input_backprop_data);\n\n        input_backprop_data += input_offset;\n      }\n    } else {\n      for (int image_id = 0; image_id < dims.batch_size;\n           image_id += shard_size) {\n        const int shard_limit =\n            std::min(static_cast<int>(shard_size),\n                     static_cast<int>(dims.batch_size) - image_id);\n\n        auto shard = [&context, &dims, &pad_top, &pad_left, &pad_bottom,\n                      &pad_right, &output_image_size, &filter_total_size,\n                      &input_backprop_data, &col_buffer_data,\n                      &out_backprop_data, &filter_data, &input_offset,\n                      &output_offset, &size_C](int64 start, int64 limit) {\n          for (int shard_id = start; shard_id < limit; ++shard_id) {\n            T* im2col_buf = col_buffer_data + shard_id * size_C;\n            T* input_data = input_backprop_data + shard_id * input_offset;\n            const T* out_data = out_backprop_data + shard_id * output_offset;\n\n            Conv2DCustomBackpropInputMatMulFunctor<T>()(\n                context, out_data, filter_data, filter_total_size,\n                output_image_size, dims.out_depth, im2col_buf);\n\n            Col2im<T>(im2col_buf, dims.in_depth,\n                      dims.spatial_dims[0].input_size,\n                      dims.spatial_dims[1].input_size,\n                      dims.spatial_dims[0].filter_size,\n                      dims.spatial_dims[1].filter_size, pad_top, pad_left,\n                      pad_bottom, pad_right, dims.spatial_dims[0].stride,\n                      dims.spatial_dims[1].stride, input_data);\n          }\n        };\n        Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n              work_unit_size, shard);\n\n        input_backprop_data += input_offset * shard_limit;\n        out_backprop_data += output_offset * shard_limit;\n      }\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input_sizes = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n\n    TensorShape input_shape;\n    OP_REQUIRES_OK(context,\n                   Conv2DBackpropComputeInputShape(input_sizes, filter.shape(),\n                                                   out_backprop.shape(),\n                                                   data_format_, &input_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(context,\n                   ConvBackpropComputeDimensionsV2(\n                       \"Conv2DCustomBackpropInput\", /*num_spatial_dims=*/2,\n                       input_shape, filter.shape(), out_backprop.shape(),\n                       /*dilations=*/{1, 1, 1, 1}, strides_, padding_,\n                       explicit_paddings_, data_format_, &dims));\n\n    OP_REQUIRES(context, dims.in_depth == filter.shape().dim_size(2),\n                errors::InvalidArgument(\"Computed input depth \", dims.in_depth,\n                                        \" doesn't match filter input depth \",\n                                        filter.shape().dim_size(2)));\n    OP_REQUIRES(\n        context, dims.out_depth == filter.shape().dim_size(3),\n        errors::InvalidArgument(\"Computed output depth \", dims.out_depth,\n                                \" doesn't match filter output depth \",\n                                filter.shape().dim_size(3)));\n\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input_shape, &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input_shape.num_elements() == 0) {\n      return;\n    }\n\n// TODO(ezhulenev): Remove custom kernel and move XSMM support to\n// LaunchConv2DBackpropInputOp functor.\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardInputConvolution<Device, T>()(\n              context, context->eigen_device<Device>(),\n              in_backprop->tensor<T, 4>(), filter.tensor<T, 4>(),\n              out_backprop.tensor<T, 4>(), dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#else\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n#endif\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // TODO(andydavis) Get L2/L3 cache sizes from device.\n    const size_t l2_cache_size = 256LL << 10;\n    const size_t l3_cache_size = 30LL << 20;\n\n    // Use L3 cache size as target working set size.\n    const size_t target_working_set_size = l3_cache_size / sizeof(T);\n\n    // Calculate size of matrices involved in MatMul: C = A x B.\n    const size_t size_A = output_image_size * dims.out_depth;\n\n    const size_t size_B = filter_total_size * dims.out_depth;\n\n    const size_t size_C = output_image_size * filter_total_size;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    // Calculate per-thread work unit size.\n    const size_t thread_work_unit_size =\n        work_unit_size / worker_threads.num_threads;\n\n    // Set minimum per-thread work unit size to size of L2 cache.\n    const size_t min_thread_work_unit_size = l2_cache_size / sizeof(T);\n\n    // Use parallel tensor contractions if there is no batching, or if the\n    // minimum per-thread work unit size threshold has been exceeded.\n    // Otherwise, revert to multiple single-threaded matmul ops running in\n    // parallel to keep all threads busy.\n    // TODO(andydavis) Explore alternatives to branching the code in this way\n    // (i.e. run multiple, parallel tensor contractions in another thread pool).\n    const bool use_parallel_contraction =\n        dims.batch_size == 1 ||\n        thread_work_unit_size >= min_thread_work_unit_size;\n\n    OP_REQUIRES(\n        context, work_unit_size > 0,\n        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n                                \"must all have at least 1 element\"));\n\n    const size_t shard_size =\n        use_parallel_contraction\n            ? 1\n            : (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64>(shard_size),\n                                    static_cast<int64>(output_image_size),\n                                    static_cast<int64>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* filter_data = filter.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n\n    auto in_backprop_flat = in_backprop->template flat<T>();\n    T* input_backprop_data = in_backprop_flat.data();\n    in_backprop_flat.device(context->eigen_device<Device>()) =\n        in_backprop_flat.constant(T(0));\n\n    if (use_parallel_contraction) {\n      typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          TensorMap;\n      typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                               Eigen::Unaligned>\n          ConstTensorMap;\n\n      // Initialize contraction dims (we need to transpose 'B' below).\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n      contract_dims[0].first = 1;\n      contract_dims[0].second = 1;\n\n      for (int image_id = 0; image_id < dims.batch_size; ++image_id) {\n        // Compute gradient into col_buffer.\n        TensorMap C(col_buffer_data, output_image_size, filter_total_size);\n\n        ConstTensorMap A(out_backprop_data + output_offset * image_id,\n                         output_image_size, dims.out_depth);\n        ConstTensorMap B(filter_data, filter_total_size, dims.out_depth);\n\n        C.device(context->eigen_cpu_device()) = A.contract(B, contract_dims);\n\n        Col2im<T>(\n            col_buffer_data, dims.in_depth, dims.spatial_dims[0].input_size,\n            dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n            pad_right, dims.spatial_dims[0].stride, dims.spatial_dims[1].stride,\n            input_backprop_data);\n\n        input_backprop_data += input_offset;\n      }\n    } else {\n      for (int image_id = 0; image_id < dims.batch_size;\n           image_id += shard_size) {\n        const int shard_limit =\n            std::min(static_cast<int>(shard_size),\n                     static_cast<int>(dims.batch_size) - image_id);\n\n        auto shard = [&context, &dims, &pad_top, &pad_left, &pad_bottom,\n                      &pad_right, &output_image_size, &filter_total_size,\n                      &input_backprop_data, &col_buffer_data,\n                      &out_backprop_data, &filter_data, &input_offset,\n                      &output_offset, &size_C](int64 start, int64 limit) {\n          for (int shard_id = start; shard_id < limit; ++shard_id) {\n            T* im2col_buf = col_buffer_data + shard_id * size_C;\n            T* input_data = input_backprop_data + shard_id * input_offset;\n            const T* out_data = out_backprop_data + shard_id * output_offset;\n\n            Conv2DCustomBackpropInputMatMulFunctor<T>()(\n                context, out_data, filter_data, filter_total_size,\n                output_image_size, dims.out_depth, im2col_buf);\n\n            Col2im<T>(im2col_buf, dims.in_depth,\n                      dims.spatial_dims[0].input_size,\n                      dims.spatial_dims[1].input_size,\n                      dims.spatial_dims[0].filter_size,\n                      dims.spatial_dims[1].filter_size, pad_top, pad_left,\n                      pad_bottom, pad_right, dims.spatial_dims[0].stride,\n                      dims.spatial_dims[1].stride, input_data);\n          }\n        };\n        Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n              work_unit_size, shard);\n\n        input_backprop_data += input_offset * shard_limit;\n        out_backprop_data += output_offset * shard_limit;\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -134,6 +134,11 @@\n         dims.batch_size == 1 ||\n         thread_work_unit_size >= min_thread_work_unit_size;\n \n+    OP_REQUIRES(\n+        context, work_unit_size > 0,\n+        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"\n+                                \"must all have at least 1 element\"));\n+\n     const size_t shard_size =\n         use_parallel_contraction\n             ? 1",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, work_unit_size > 0,",
                "        errors::InvalidArgument(\"input, filter_sizes and out_backprop tensors \"",
                "                                \"must all have at least 1 element\"));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29526",
        "func_name": "tensorflow/ComputeConv2DDimension",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a division by 0 in `tf.raw_ops.Conv2D`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/988087bd83f144af14087fe4fecee2d250d93737/tensorflow/core/kernels/conv_ops.cc#L261-L263) does a division by a quantity that is controlled by the caller. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/b12aa1d44352de21d1a6faaf04172d8c2508b42b",
        "commit_title": "Fix one more FPE.",
        "commit_text": " PiperOrigin-RevId: 369346568",
        "func_before": "Status ComputeConv2DDimension(const Conv2DParameters& params,\n                              const Tensor& input, const Tensor& filter,\n                              Conv2DDimensions* dimensions) {\n  // Check that 2D convolution input and filter have exactly 4 dimensions.\n  TF_REQUIRES(input.dims() == 4,\n              errors::InvalidArgument(\"input must be 4-dimensional\",\n                                      input.shape().DebugString()));\n  TF_REQUIRES(filter.dims() == 4,\n              errors::InvalidArgument(\"filter must be 4-dimensional: \",\n                                      filter.shape().DebugString()));\n  for (int i = 0; i < 3; i++) {\n    TF_REQUIRES(\n        FastBoundsCheck(filter.dim_size(i), std::numeric_limits<int>::max()),\n        errors::InvalidArgument(\"filter too large\"));\n  }\n\n  // The last dimension for input is in_depth. Check that it is the same as the\n  // filter's in_depth or it is evenly divisible by filter's in_depth.\n  const int64 in_depth_raw = GetTensorDim(input, params.data_format, 'C');\n  const int64 patch_depth_raw = filter.dim_size(2);\n  TF_REQUIRES(FastBoundsCheck(in_depth_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Input depth too large\"));\n  TF_REQUIRES(FastBoundsCheck(patch_depth_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Patch depth too large\"));\n  const int in_depth = static_cast<int>(in_depth_raw);\n  const int patch_depth = static_cast<int>(patch_depth_raw);\n  TF_REQUIRES(in_depth % patch_depth == 0,\n              errors::InvalidArgument(\n                  \"input depth must be evenly divisible by filter depth: \",\n                  in_depth, \" vs \", patch_depth));\n\n  // The last dimension for filter is out_depth.\n  const int out_depth = static_cast<int>(filter.dim_size(3));\n\n  // The second dimension for input is rows/height.\n  // The first dimension for filter is rows/height.\n  const int64 input_rows_raw = GetTensorDim(input, params.data_format, 'H');\n  TF_REQUIRES(FastBoundsCheck(input_rows_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Input rows too large\"));\n  const int input_rows = static_cast<int>(input_rows_raw);\n  const int filter_rows = static_cast<int>(filter.dim_size(0));\n\n  // The third dimension for input is columns/width.\n  // The second dimension for filter is columns/width.\n  const int64 input_cols_raw = GetTensorDim(input, params.data_format, 'W');\n  TF_REQUIRES(FastBoundsCheck(input_cols_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Input cols too large\"));\n  const int input_cols = static_cast<int>(input_cols_raw);\n  const int filter_cols = static_cast<int>(filter.dim_size(1));\n\n  // The first dimension for input is batch.\n  const int64 batch_raw = GetTensorDim(input, params.data_format, 'N');\n  TF_REQUIRES(FastBoundsCheck(batch_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"batch is too large\"));\n  const int batch = static_cast<int>(batch_raw);\n\n  // Take the stride and dilation from the second and third dimensions only (we\n  // do not support striding or dilation on the batch or depth dimension).\n  const int stride_rows = GetTensorDim(params.strides, params.data_format, 'H');\n  const int stride_cols = GetTensorDim(params.strides, params.data_format, 'W');\n  const int dilation_rows =\n      GetTensorDim(params.dilations, params.data_format, 'H');\n  const int dilation_cols =\n      GetTensorDim(params.dilations, params.data_format, 'W');\n\n  int64 pad_rows_before, pad_rows_after, pad_cols_before, pad_cols_after;\n  if (params.padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(params.explicit_paddings, params.data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(params.explicit_paddings, params.data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n\n  // Compute windowed output sizes for rows and columns.\n  int64 out_rows = 0, out_cols = 0;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerboseV2(\n      input_rows, filter_rows, dilation_rows, stride_rows, params.padding,\n      &out_rows, &pad_rows_before, &pad_rows_after));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerboseV2(\n      input_cols, filter_cols, dilation_cols, stride_cols, params.padding,\n      &out_cols, &pad_cols_before, &pad_cols_after));\n\n  dimensions->batch = batch;\n  dimensions->input_rows = input_rows;\n  dimensions->input_cols = input_cols;\n  dimensions->in_depth = in_depth;\n  dimensions->filter_rows = filter_rows;\n  dimensions->filter_cols = filter_cols;\n  dimensions->patch_depth = patch_depth;\n  dimensions->out_depth = out_depth;\n  dimensions->stride_rows = stride_rows;\n  dimensions->stride_cols = stride_cols;\n  dimensions->dilation_rows = dilation_rows;\n  dimensions->dilation_cols = dilation_cols;\n  dimensions->out_rows = out_rows;\n  dimensions->out_cols = out_cols;\n  dimensions->pad_rows_before = pad_rows_before;\n  dimensions->pad_rows_after = pad_rows_after;\n  dimensions->pad_cols_before = pad_cols_before;\n  dimensions->pad_cols_after = pad_cols_after;\n\n  return Status::OK();\n}",
        "func": "Status ComputeConv2DDimension(const Conv2DParameters& params,\n                              const Tensor& input, const Tensor& filter,\n                              Conv2DDimensions* dimensions) {\n  // Check that 2D convolution input and filter have exactly 4 dimensions.\n  TF_REQUIRES(input.dims() == 4,\n              errors::InvalidArgument(\"input must be 4-dimensional\",\n                                      input.shape().DebugString()));\n  TF_REQUIRES(filter.dims() == 4,\n              errors::InvalidArgument(\"filter must be 4-dimensional: \",\n                                      filter.shape().DebugString()));\n  for (int i = 0; i < 3; i++) {\n    TF_REQUIRES(\n        FastBoundsCheck(filter.dim_size(i), std::numeric_limits<int>::max()),\n        errors::InvalidArgument(\"filter too large\"));\n  }\n\n  // The last dimension for input is in_depth. Check that it is the same as the\n  // filter's in_depth or it is evenly divisible by filter's in_depth.\n  const int64 in_depth_raw = GetTensorDim(input, params.data_format, 'C');\n  const int64 patch_depth_raw = filter.dim_size(2);\n  TF_REQUIRES(FastBoundsCheck(in_depth_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Input depth too large\"));\n  TF_REQUIRES(FastBoundsCheck(patch_depth_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Patch depth too large\"));\n  const int in_depth = static_cast<int>(in_depth_raw);\n  const int patch_depth = static_cast<int>(patch_depth_raw);\n  TF_REQUIRES(patch_depth > 0,\n              errors::InvalidArgument(\n                  \"filter depth must be stricly positive, got \", patch_depth));\n  TF_REQUIRES(in_depth % patch_depth == 0,\n              errors::InvalidArgument(\n                  \"input depth must be evenly divisible by filter depth: \",\n                  in_depth, \" vs \", patch_depth));\n\n  // The last dimension for filter is out_depth.\n  const int out_depth = static_cast<int>(filter.dim_size(3));\n\n  // The second dimension for input is rows/height.\n  // The first dimension for filter is rows/height.\n  const int64 input_rows_raw = GetTensorDim(input, params.data_format, 'H');\n  TF_REQUIRES(FastBoundsCheck(input_rows_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Input rows too large\"));\n  const int input_rows = static_cast<int>(input_rows_raw);\n  const int filter_rows = static_cast<int>(filter.dim_size(0));\n\n  // The third dimension for input is columns/width.\n  // The second dimension for filter is columns/width.\n  const int64 input_cols_raw = GetTensorDim(input, params.data_format, 'W');\n  TF_REQUIRES(FastBoundsCheck(input_cols_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"Input cols too large\"));\n  const int input_cols = static_cast<int>(input_cols_raw);\n  const int filter_cols = static_cast<int>(filter.dim_size(1));\n\n  // The first dimension for input is batch.\n  const int64 batch_raw = GetTensorDim(input, params.data_format, 'N');\n  TF_REQUIRES(FastBoundsCheck(batch_raw, std::numeric_limits<int>::max()),\n              errors::InvalidArgument(\"batch is too large\"));\n  const int batch = static_cast<int>(batch_raw);\n\n  // Take the stride and dilation from the second and third dimensions only (we\n  // do not support striding or dilation on the batch or depth dimension).\n  const int stride_rows = GetTensorDim(params.strides, params.data_format, 'H');\n  const int stride_cols = GetTensorDim(params.strides, params.data_format, 'W');\n  const int dilation_rows =\n      GetTensorDim(params.dilations, params.data_format, 'H');\n  const int dilation_cols =\n      GetTensorDim(params.dilations, params.data_format, 'W');\n\n  int64 pad_rows_before, pad_rows_after, pad_cols_before, pad_cols_after;\n  if (params.padding == Padding::EXPLICIT) {\n    GetExplicitPaddingForDim(params.explicit_paddings, params.data_format, 'H',\n                             &pad_rows_before, &pad_rows_after);\n    GetExplicitPaddingForDim(params.explicit_paddings, params.data_format, 'W',\n                             &pad_cols_before, &pad_cols_after);\n  }\n\n  // Compute windowed output sizes for rows and columns.\n  int64 out_rows = 0, out_cols = 0;\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerboseV2(\n      input_rows, filter_rows, dilation_rows, stride_rows, params.padding,\n      &out_rows, &pad_rows_before, &pad_rows_after));\n  TF_RETURN_IF_ERROR(GetWindowedOutputSizeVerboseV2(\n      input_cols, filter_cols, dilation_cols, stride_cols, params.padding,\n      &out_cols, &pad_cols_before, &pad_cols_after));\n\n  dimensions->batch = batch;\n  dimensions->input_rows = input_rows;\n  dimensions->input_cols = input_cols;\n  dimensions->in_depth = in_depth;\n  dimensions->filter_rows = filter_rows;\n  dimensions->filter_cols = filter_cols;\n  dimensions->patch_depth = patch_depth;\n  dimensions->out_depth = out_depth;\n  dimensions->stride_rows = stride_rows;\n  dimensions->stride_cols = stride_cols;\n  dimensions->dilation_rows = dilation_rows;\n  dimensions->dilation_cols = dilation_cols;\n  dimensions->out_rows = out_rows;\n  dimensions->out_cols = out_cols;\n  dimensions->pad_rows_before = pad_rows_before;\n  dimensions->pad_rows_after = pad_rows_after;\n  dimensions->pad_cols_before = pad_cols_before;\n  dimensions->pad_cols_after = pad_cols_after;\n\n  return Status::OK();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,6 +24,9 @@\n               errors::InvalidArgument(\"Patch depth too large\"));\n   const int in_depth = static_cast<int>(in_depth_raw);\n   const int patch_depth = static_cast<int>(patch_depth_raw);\n+  TF_REQUIRES(patch_depth > 0,\n+              errors::InvalidArgument(\n+                  \"filter depth must be stricly positive, got \", patch_depth));\n   TF_REQUIRES(in_depth % patch_depth == 0,\n               errors::InvalidArgument(\n                   \"input depth must be evenly divisible by filter depth: \",",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_REQUIRES(patch_depth > 0,",
                "              errors::InvalidArgument(",
                "                  \"filter depth must be stricly positive, got \", patch_depth));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29527",
        "func_name": "tensorflow/operator()",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a division by 0 in `tf.raw_ops.QuantizedConv2D`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/00e9a4d67d76703fa1aee33dac582acf317e0e81/tensorflow/core/kernels/quantized_conv_ops.cc#L257-L259) does a division by a quantity that is controlled by the caller. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/cfa91be9863a91d5105a3b4941096044ab32036b",
        "commit_title": "Fix one FPE and remove two CHECK-fails.",
        "commit_text": " PiperOrigin-RevId: 369349640",
        "func_before": "void operator()(OpKernelContext* context, const T1* input_data,\n                  int input_batches, int input_height, int input_width,\n                  int input_depth, int input_offset, const T2* filter_data,\n                  int filter_height, int filter_width, int filter_count,\n                  int filter_offset, int stride, Padding padding,\n                  T3* output_data, int output_height, int output_width,\n                  int output_shift, int output_offset, int output_mult) {\n    if (input_offset < 0) {\n      // Only log the first few occurrences of this warning.\n      static int warning_count = 0;\n      if (warning_count < 10) {\n        ++warning_count;\n        LOG(WARNING)\n            << \"For kernel '\" << context->op_kernel().name() << \"' from input '\"\n            << context->op_kernel().requested_input(0)\n            << \"': Zero is not representable in the quantized range used by the\"\n            << \" input. This means QuantizedConv2d has to fall back to a slow\"\n            << \" implementation, since the border of zero values can't be\"\n            << \" represented easily. You should try to construct graphs that\"\n            << \" avoid this situation.\";\n      }\n      ReferenceConvFunctor<T1, T2, T3> conv_functor;\n      conv_functor(context, input_data, input_batches, input_height,\n                   input_width, input_depth, input_offset, filter_data,\n                   filter_height, filter_width, filter_count, filter_offset,\n                   stride, padding, output_data, output_height, output_width,\n                   output_shift, output_offset, output_mult);\n      return;\n    }\n\n    CHECK_GT(output_width, 0);\n    CHECK_GT(output_height, 0);\n    int filter_left_offset;\n    int filter_top_offset;\n    if (padding == VALID) {\n      filter_left_offset =\n          ((output_width - 1) * stride + filter_width - input_width + 1) / 2;\n      filter_top_offset =\n          ((output_height - 1) * stride + filter_height - input_height + 1) / 2;\n    } else {\n      filter_left_offset =\n          ((output_width - 1) * stride + filter_width - input_width) / 2;\n      filter_top_offset =\n          ((output_height - 1) * stride + filter_height - input_height) / 2;\n    }\n\n    // The im2col buffer has # of patches rows, and # of filters cols.\n    // It's laid out like this, in row major order in memory:\n    //        < filter value count >\n    //   ^   +---------------------+\n    // patch |                     |\n    // count |                     |\n    //   v   +---------------------+\n    // Each patch row contains a filter_width x filter_height patch of the\n    // input, with the depth channel as the most contiguous in memory, followed\n    // by the width, then the height. This is the standard memory order in the\n    // image world if it helps to visualize it.\n    const int filter_value_count = filter_width * filter_height * input_depth;\n    const int64 patches_per_chunk =\n        kMaxChunkSize / (filter_value_count * sizeof(T1));\n    const int64 chunk_value_count =\n        (kMaxChunkSize + (sizeof(T1) - 1)) / sizeof(T1);\n    // TODO(petewarden) - Memory allocation can be very slow on Android. Can we\n    // optimize this by keeping the scratch buffer around?\n    // Because memory allocation is very expensive on mobile platforms, try to\n    // allocate a persistent buffer that will be kept around between calls. We\n    // use TensorFlow's resource management to ensure that the memory will be\n    // released when the session is over.\n    Im2ColBufferResource<T1, chunk_value_count>* im2col_buffer_resource;\n    std::function<Status(Im2ColBufferResource<T1, chunk_value_count>**)>\n        creator = [](Im2ColBufferResource<T1, chunk_value_count>** resource) {\n#ifdef _MSC_VER\n          // MSVC complains about the capture of chunk_value_count which oddly\n          // works fine in conv_ops_using_gemm.cc for example.\n          // Define chunk_value_count inside the lambda for now.\n          const int64 chunk_value_count =\n              (kMaxChunkSize + (sizeof(T1) - 1)) / sizeof(T1);\n#endif\n          *resource = new Im2ColBufferResource<T1, chunk_value_count>();\n          return Status::OK();\n        };\n    OP_REQUIRES_OK(context, context->resource_manager()->LookupOrCreate(\n                                \"Conv2d\", \"im2col_buffer\",\n                                &im2col_buffer_resource, creator));\n    // This means that multiple ops can't be run simultaneously on different\n    // threads, because we have a single shared resource. The platforms this is\n    // aimed at have intra-op parallelism as their focus though, so it shouldn't\n    // be an issue.\n    mutex_lock lock_buffer(im2col_buffer_resource->mu);\n    core::ScopedUnref unref_buffer(im2col_buffer_resource);\n    T1* im2col_buffer = im2col_buffer_resource->data;\n\n    const int64 patch_count = (input_batches * output_height * output_width);\n    const int64 chunk_count =\n        (patch_count + (patches_per_chunk - 1)) / patches_per_chunk;\n\n    for (int64 chunk_index = 0; chunk_index < chunk_count; ++chunk_index) {\n      const int64 patch_index_start = chunk_index * patches_per_chunk;\n      const int64 patch_index_end =\n          std::min(patch_index_start + patches_per_chunk, patch_count);\n      for (int64 patch_index = patch_index_start; patch_index < patch_index_end;\n           ++patch_index) {\n        const int64 batch = patch_index / (output_height * output_width);\n        const int64 out_y = (patch_index / output_width) % output_height;\n        const int64 out_x = patch_index % output_width;\n        const T1* input_batch_start =\n            input_data + (batch * input_height * input_width * input_depth);\n        const int in_y_origin = (out_y * stride) - filter_top_offset;\n        const int in_x_origin = (out_x * stride) - filter_left_offset;\n        const int patch_index_within_chunk = patch_index % patches_per_chunk;\n        T1* im2col_patch_start =\n            im2col_buffer + (patch_index_within_chunk * filter_value_count);\n        for (int filter_y = 0; filter_y < filter_height; ++filter_y) {\n          const int in_y = in_y_origin + filter_y;\n          T1* im2col_row_start =\n              im2col_patch_start + (filter_y * filter_width * input_depth);\n          // If we're off the top or the bottom of the input, fill the\n          // whole row with zeroes.\n          if ((in_y < 0) || (in_y >= input_height)) {\n            // On Android, memset and memcpy are significantly faster than the\n            // more modern std::set and std::copy equivalents.\n            memset(im2col_row_start, input_offset,\n                   (filter_width * input_depth));\n          } else {\n            // What we're doing here is trying to copy and fill the im2col\n            // buffer as efficiently as possible, using functions to set or\n            // duplicate values en masse. We know we don't have to worry about\n            // vertical edges because we dealt with that case above, so we\n            // just need to handle filters that overlap the left or right\n            // edges. Here's what that looks like:\n            //\n            // < left_zero_count > < center_copy_count > < right_zero_count >\n            // +------------------+---------------------+--------------------+\n            // |     (filter)     |       (image)       |      (filter)      |\n            // +------------------+---------------------+--------------------+\n            // in_x_origin        0                 input_width       in_x_end\n            //\n            // In reality it's unlikely that a filter patch will be wider\n            // than an input, but this shows all the edge cases.\n            // We use memset() to set the left and right sections to zeroes\n            // and memcpy() to copy over the input data for the center. These\n            // are preferred to std::fill and std::copy because they're much\n            // faster on Android.\n            const int in_x_end = in_x_origin + filter_width;\n            const int left_zero_count = std::max(0, 0 - in_x_origin);\n            const int right_zero_count = std::max(0, in_x_end - input_width);\n            const int center_copy_count =\n                filter_width - (left_zero_count + right_zero_count);\n            if (left_zero_count > 0) {\n              T1* im2col_left_start = im2col_row_start;\n              memset(im2col_left_start, input_offset,\n                     (left_zero_count * input_depth));\n            }\n            if (center_copy_count > 0) {\n              const T1* input_row_start =\n                  input_batch_start + (in_y * input_width * input_depth) +\n                  (std::max(0, in_x_origin) * input_depth);\n              T1* im2col_center_start =\n                  im2col_row_start + (left_zero_count * input_depth);\n              memcpy(im2col_center_start, input_row_start,\n                     (center_copy_count * input_depth));\n            }\n            if (right_zero_count > 0) {\n              T1* im2col_right_start =\n                  im2col_row_start +\n                  ((left_zero_count + center_copy_count) * input_depth);\n              memset(im2col_right_start, input_offset,\n                     (right_zero_count * input_depth));\n            }\n          }\n        }\n      }\n      // Now we've assembled a set of image patches into a matrix, apply a\n      // GEMM matrix multiply of the patches as rows, times the filter\n      // weights in columns, to get partial results in the output matrix.\n      const int how_many_patches = patch_index_end - patch_index_start;\n      const bool transpose_a = false;\n      const bool transpose_b = false;\n      const bool transpose_c = false;\n      const int m = how_many_patches;\n      const int n = filter_count;\n      const int k = filter_value_count;\n      const int lda = filter_value_count;\n      const int ldb = filter_count;\n      const int ldc = filter_count;\n      T3* chunk_output_data = output_data + (patch_index_start * filter_count);\n\n      if (meta::IsSupportedAndEnabled() && std::is_same<T1, quint8>() &&\n          std::is_same<T2, quint8>() && std::is_same<T3, qint32>() &&\n          (output_offset == 0) && (output_mult == 1) && (output_shift == 0) &&\n          (transpose_c == false) && (k <= 2048)) {\n        meta::QuantizedGemm(context, transpose_a, transpose_b, im2col_buffer,\n                            filter_data, chunk_output_data, m, n, k,\n                            -input_offset, -filter_offset, lda, ldb, ldc);\n      } else if (std::is_same<T1, quint8>() && std::is_same<T2, quint8>() &&\n                 std::is_same<T3, qint32>() && (output_offset == 0) &&\n                 (output_mult == 1) && (output_shift == 0)) {\n        // The gemmlowp optimized library only works for a particular set of\n        // data types, so check if we meet those requirements and fall back to a\n        // slower reference implementation if not.\n        const uint8* im2col_data_as_uint8 = &(im2col_buffer->value);\n        const uint8* filter_data_as_uint8 = &(filter_data->value);\n        int32* output_data_as_int32 = &(chunk_output_data->value);\n        // All of the transpose_* variables are currently compile-time consts,\n        // so we could just hard-code these values too, but that would break if\n        // anybody changed those values in the future (e.g. to match the ability\n        // of MatMul to specify them as attributes). We're using a verbose\n        // approach of deriving the order values from the transpose variables to\n        // be able to catch any changes like that.\n        static const gemmlowp::MapOrder ResultOrder =\n            !transpose_c ? gemmlowp::MapOrder::RowMajor\n                         : gemmlowp::MapOrder::ColMajor;\n        static const gemmlowp::MapOrder LhsOrder =\n            !transpose_a ? gemmlowp::MapOrder::RowMajor\n                         : gemmlowp::MapOrder::ColMajor;\n        static const gemmlowp::MapOrder RhsOrder =\n            !transpose_b ? gemmlowp::MapOrder::RowMajor\n                         : gemmlowp::MapOrder::ColMajor;\n        gemmlowp::MatrixMap<const std::uint8_t, LhsOrder> lhs(\n            im2col_data_as_uint8, m, k, lda);\n        gemmlowp::MatrixMap<const std::uint8_t, RhsOrder> rhs(\n            filter_data_as_uint8, k, n, ldb);\n        gemmlowp::MatrixMap<std::int32_t, ResultOrder> result(\n            output_data_as_int32, m, n, ldc);\n        const std::tuple<> empty_pipeline = {};\n\n        auto& worker_threads =\n            *(context->device()->tensorflow_cpu_worker_threads());\n        TensorflowGemmContext context(worker_threads.num_threads,\n                                      worker_threads.workers);\n        gemmlowp::GemmWithOutputPipeline<std::uint8_t, std::int32_t,\n                                         gemmlowp::DefaultL8R8BitDepthParams>(\n            &context, lhs, rhs, &result, -input_offset, -filter_offset,\n            empty_pipeline);\n        // Since gemmlowp uses assembly to write to the output, msan won't\n        // detect the output buffer as written to, so we mark it manually.\n        TF_ANNOTATE_MEMORY_IS_INITIALIZED(output_data_as_int32,\n                                          m * n * sizeof(int32));\n      } else {\n        ReferenceGemm<T1, T2, T3>(\n            transpose_a, transpose_b, transpose_c, m, n, k, im2col_buffer,\n            input_offset, lda, filter_data, filter_offset, ldb,\n            chunk_output_data, output_shift, output_offset, output_mult, ldc);\n      }\n    }\n  }",
        "func": "void operator()(OpKernelContext* context, const T1* input_data,\n                  int input_batches, int input_height, int input_width,\n                  int input_depth, int input_offset, const T2* filter_data,\n                  int filter_height, int filter_width, int filter_count,\n                  int filter_offset, int stride, Padding padding,\n                  T3* output_data, int output_height, int output_width,\n                  int output_shift, int output_offset, int output_mult) {\n    if (input_offset < 0) {\n      // Only log the first few occurrences of this warning.\n      static int warning_count = 0;\n      if (warning_count < 10) {\n        ++warning_count;\n        LOG(WARNING)\n            << \"For kernel '\" << context->op_kernel().name() << \"' from input '\"\n            << context->op_kernel().requested_input(0)\n            << \"': Zero is not representable in the quantized range used by the\"\n            << \" input. This means QuantizedConv2d has to fall back to a slow\"\n            << \" implementation, since the border of zero values can't be\"\n            << \" represented easily. You should try to construct graphs that\"\n            << \" avoid this situation.\";\n      }\n      ReferenceConvFunctor<T1, T2, T3> conv_functor;\n      conv_functor(context, input_data, input_batches, input_height,\n                   input_width, input_depth, input_offset, filter_data,\n                   filter_height, filter_width, filter_count, filter_offset,\n                   stride, padding, output_data, output_height, output_width,\n                   output_shift, output_offset, output_mult);\n      return;\n    }\n\n    OP_REQUIRES(\n        context, output_width > 0,\n        errors::InvalidArgument(\"output_width must be strictly positive\"));\n    OP_REQUIRES(\n        context, output_height > 0,\n        errors::InvalidArgument(\"output_height must be strictly positive\"));\n    int filter_left_offset;\n    int filter_top_offset;\n    if (padding == VALID) {\n      filter_left_offset =\n          ((output_width - 1) * stride + filter_width - input_width + 1) / 2;\n      filter_top_offset =\n          ((output_height - 1) * stride + filter_height - input_height + 1) / 2;\n    } else {\n      filter_left_offset =\n          ((output_width - 1) * stride + filter_width - input_width) / 2;\n      filter_top_offset =\n          ((output_height - 1) * stride + filter_height - input_height) / 2;\n    }\n\n    // The im2col buffer has # of patches rows, and # of filters cols.\n    // It's laid out like this, in row major order in memory:\n    //        < filter value count >\n    //   ^   +---------------------+\n    // patch |                     |\n    // count |                     |\n    //   v   +---------------------+\n    // Each patch row contains a filter_width x filter_height patch of the\n    // input, with the depth channel as the most contiguous in memory, followed\n    // by the width, then the height. This is the standard memory order in the\n    // image world if it helps to visualize it.\n    const int filter_value_count = filter_width * filter_height * input_depth;\n    OP_REQUIRES(context, filter_value_count > 0,\n                errors::InvalidArgument(\n                    \"filter patch must contain at least one element\"));\n    const int64 patches_per_chunk =\n        kMaxChunkSize / (filter_value_count * sizeof(T1));\n    const int64 chunk_value_count =\n        (kMaxChunkSize + (sizeof(T1) - 1)) / sizeof(T1);\n    // TODO(petewarden) - Memory allocation can be very slow on Android. Can we\n    // optimize this by keeping the scratch buffer around?\n    // Because memory allocation is very expensive on mobile platforms, try to\n    // allocate a persistent buffer that will be kept around between calls. We\n    // use TensorFlow's resource management to ensure that the memory will be\n    // released when the session is over.\n    Im2ColBufferResource<T1, chunk_value_count>* im2col_buffer_resource;\n    std::function<Status(Im2ColBufferResource<T1, chunk_value_count>**)>\n        creator = [](Im2ColBufferResource<T1, chunk_value_count>** resource) {\n#ifdef _MSC_VER\n          // MSVC complains about the capture of chunk_value_count which oddly\n          // works fine in conv_ops_using_gemm.cc for example.\n          // Define chunk_value_count inside the lambda for now.\n          const int64 chunk_value_count =\n              (kMaxChunkSize + (sizeof(T1) - 1)) / sizeof(T1);\n#endif\n          *resource = new Im2ColBufferResource<T1, chunk_value_count>();\n          return Status::OK();\n        };\n    OP_REQUIRES_OK(context, context->resource_manager()->LookupOrCreate(\n                                \"Conv2d\", \"im2col_buffer\",\n                                &im2col_buffer_resource, creator));\n    // This means that multiple ops can't be run simultaneously on different\n    // threads, because we have a single shared resource. The platforms this is\n    // aimed at have intra-op parallelism as their focus though, so it shouldn't\n    // be an issue.\n    mutex_lock lock_buffer(im2col_buffer_resource->mu);\n    core::ScopedUnref unref_buffer(im2col_buffer_resource);\n    T1* im2col_buffer = im2col_buffer_resource->data;\n\n    const int64 patch_count = (input_batches * output_height * output_width);\n    const int64 chunk_count =\n        (patch_count + (patches_per_chunk - 1)) / patches_per_chunk;\n\n    for (int64 chunk_index = 0; chunk_index < chunk_count; ++chunk_index) {\n      const int64 patch_index_start = chunk_index * patches_per_chunk;\n      const int64 patch_index_end =\n          std::min(patch_index_start + patches_per_chunk, patch_count);\n      for (int64 patch_index = patch_index_start; patch_index < patch_index_end;\n           ++patch_index) {\n        const int64 batch = patch_index / (output_height * output_width);\n        const int64 out_y = (patch_index / output_width) % output_height;\n        const int64 out_x = patch_index % output_width;\n        const T1* input_batch_start =\n            input_data + (batch * input_height * input_width * input_depth);\n        const int in_y_origin = (out_y * stride) - filter_top_offset;\n        const int in_x_origin = (out_x * stride) - filter_left_offset;\n        const int patch_index_within_chunk = patch_index % patches_per_chunk;\n        T1* im2col_patch_start =\n            im2col_buffer + (patch_index_within_chunk * filter_value_count);\n        for (int filter_y = 0; filter_y < filter_height; ++filter_y) {\n          const int in_y = in_y_origin + filter_y;\n          T1* im2col_row_start =\n              im2col_patch_start + (filter_y * filter_width * input_depth);\n          // If we're off the top or the bottom of the input, fill the\n          // whole row with zeroes.\n          if ((in_y < 0) || (in_y >= input_height)) {\n            // On Android, memset and memcpy are significantly faster than the\n            // more modern std::set and std::copy equivalents.\n            memset(im2col_row_start, input_offset,\n                   (filter_width * input_depth));\n          } else {\n            // What we're doing here is trying to copy and fill the im2col\n            // buffer as efficiently as possible, using functions to set or\n            // duplicate values en masse. We know we don't have to worry about\n            // vertical edges because we dealt with that case above, so we\n            // just need to handle filters that overlap the left or right\n            // edges. Here's what that looks like:\n            //\n            // < left_zero_count > < center_copy_count > < right_zero_count >\n            // +------------------+---------------------+--------------------+\n            // |     (filter)     |       (image)       |      (filter)      |\n            // +------------------+---------------------+--------------------+\n            // in_x_origin        0                 input_width       in_x_end\n            //\n            // In reality it's unlikely that a filter patch will be wider\n            // than an input, but this shows all the edge cases.\n            // We use memset() to set the left and right sections to zeroes\n            // and memcpy() to copy over the input data for the center. These\n            // are preferred to std::fill and std::copy because they're much\n            // faster on Android.\n            const int in_x_end = in_x_origin + filter_width;\n            const int left_zero_count = std::max(0, 0 - in_x_origin);\n            const int right_zero_count = std::max(0, in_x_end - input_width);\n            const int center_copy_count =\n                filter_width - (left_zero_count + right_zero_count);\n            if (left_zero_count > 0) {\n              T1* im2col_left_start = im2col_row_start;\n              memset(im2col_left_start, input_offset,\n                     (left_zero_count * input_depth));\n            }\n            if (center_copy_count > 0) {\n              const T1* input_row_start =\n                  input_batch_start + (in_y * input_width * input_depth) +\n                  (std::max(0, in_x_origin) * input_depth);\n              T1* im2col_center_start =\n                  im2col_row_start + (left_zero_count * input_depth);\n              memcpy(im2col_center_start, input_row_start,\n                     (center_copy_count * input_depth));\n            }\n            if (right_zero_count > 0) {\n              T1* im2col_right_start =\n                  im2col_row_start +\n                  ((left_zero_count + center_copy_count) * input_depth);\n              memset(im2col_right_start, input_offset,\n                     (right_zero_count * input_depth));\n            }\n          }\n        }\n      }\n      // Now we've assembled a set of image patches into a matrix, apply a\n      // GEMM matrix multiply of the patches as rows, times the filter\n      // weights in columns, to get partial results in the output matrix.\n      const int how_many_patches = patch_index_end - patch_index_start;\n      const bool transpose_a = false;\n      const bool transpose_b = false;\n      const bool transpose_c = false;\n      const int m = how_many_patches;\n      const int n = filter_count;\n      const int k = filter_value_count;\n      const int lda = filter_value_count;\n      const int ldb = filter_count;\n      const int ldc = filter_count;\n      T3* chunk_output_data = output_data + (patch_index_start * filter_count);\n\n      if (meta::IsSupportedAndEnabled() && std::is_same<T1, quint8>() &&\n          std::is_same<T2, quint8>() && std::is_same<T3, qint32>() &&\n          (output_offset == 0) && (output_mult == 1) && (output_shift == 0) &&\n          (transpose_c == false) && (k <= 2048)) {\n        meta::QuantizedGemm(context, transpose_a, transpose_b, im2col_buffer,\n                            filter_data, chunk_output_data, m, n, k,\n                            -input_offset, -filter_offset, lda, ldb, ldc);\n      } else if (std::is_same<T1, quint8>() && std::is_same<T2, quint8>() &&\n                 std::is_same<T3, qint32>() && (output_offset == 0) &&\n                 (output_mult == 1) && (output_shift == 0)) {\n        // The gemmlowp optimized library only works for a particular set of\n        // data types, so check if we meet those requirements and fall back to a\n        // slower reference implementation if not.\n        const uint8* im2col_data_as_uint8 = &(im2col_buffer->value);\n        const uint8* filter_data_as_uint8 = &(filter_data->value);\n        int32* output_data_as_int32 = &(chunk_output_data->value);\n        // All of the transpose_* variables are currently compile-time consts,\n        // so we could just hard-code these values too, but that would break if\n        // anybody changed those values in the future (e.g. to match the ability\n        // of MatMul to specify them as attributes). We're using a verbose\n        // approach of deriving the order values from the transpose variables to\n        // be able to catch any changes like that.\n        static const gemmlowp::MapOrder ResultOrder =\n            !transpose_c ? gemmlowp::MapOrder::RowMajor\n                         : gemmlowp::MapOrder::ColMajor;\n        static const gemmlowp::MapOrder LhsOrder =\n            !transpose_a ? gemmlowp::MapOrder::RowMajor\n                         : gemmlowp::MapOrder::ColMajor;\n        static const gemmlowp::MapOrder RhsOrder =\n            !transpose_b ? gemmlowp::MapOrder::RowMajor\n                         : gemmlowp::MapOrder::ColMajor;\n        gemmlowp::MatrixMap<const std::uint8_t, LhsOrder> lhs(\n            im2col_data_as_uint8, m, k, lda);\n        gemmlowp::MatrixMap<const std::uint8_t, RhsOrder> rhs(\n            filter_data_as_uint8, k, n, ldb);\n        gemmlowp::MatrixMap<std::int32_t, ResultOrder> result(\n            output_data_as_int32, m, n, ldc);\n        const std::tuple<> empty_pipeline = {};\n\n        auto& worker_threads =\n            *(context->device()->tensorflow_cpu_worker_threads());\n        TensorflowGemmContext context(worker_threads.num_threads,\n                                      worker_threads.workers);\n        gemmlowp::GemmWithOutputPipeline<std::uint8_t, std::int32_t,\n                                         gemmlowp::DefaultL8R8BitDepthParams>(\n            &context, lhs, rhs, &result, -input_offset, -filter_offset,\n            empty_pipeline);\n        // Since gemmlowp uses assembly to write to the output, msan won't\n        // detect the output buffer as written to, so we mark it manually.\n        TF_ANNOTATE_MEMORY_IS_INITIALIZED(output_data_as_int32,\n                                          m * n * sizeof(int32));\n      } else {\n        ReferenceGemm<T1, T2, T3>(\n            transpose_a, transpose_b, transpose_c, m, n, k, im2col_buffer,\n            input_offset, lda, filter_data, filter_offset, ldb,\n            chunk_output_data, output_shift, output_offset, output_mult, ldc);\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,8 +28,12 @@\n       return;\n     }\n \n-    CHECK_GT(output_width, 0);\n-    CHECK_GT(output_height, 0);\n+    OP_REQUIRES(\n+        context, output_width > 0,\n+        errors::InvalidArgument(\"output_width must be strictly positive\"));\n+    OP_REQUIRES(\n+        context, output_height > 0,\n+        errors::InvalidArgument(\"output_height must be strictly positive\"));\n     int filter_left_offset;\n     int filter_top_offset;\n     if (padding == VALID) {\n@@ -56,6 +60,9 @@\n     // by the width, then the height. This is the standard memory order in the\n     // image world if it helps to visualize it.\n     const int filter_value_count = filter_width * filter_height * input_depth;\n+    OP_REQUIRES(context, filter_value_count > 0,\n+                errors::InvalidArgument(\n+                    \"filter patch must contain at least one element\"));\n     const int64 patches_per_chunk =\n         kMaxChunkSize / (filter_value_count * sizeof(T1));\n     const int64 chunk_value_count =",
        "diff_line_info": {
            "deleted_lines": [
                "    CHECK_GT(output_width, 0);",
                "    CHECK_GT(output_height, 0);"
            ],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, output_width > 0,",
                "        errors::InvalidArgument(\"output_width must be strictly positive\"));",
                "    OP_REQUIRES(",
                "        context, output_height > 0,",
                "        errors::InvalidArgument(\"output_height must be strictly positive\"));",
                "    OP_REQUIRES(context, filter_value_count > 0,",
                "                errors::InvalidArgument(",
                "                    \"filter patch must contain at least one element\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29528",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger a division by 0 in `tf.raw_ops.QuantizedMul`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/55900e961ed4a23b438392024912154a2c2f5e85/tensorflow/core/kernels/quantized_mul_op.cc#L188-L198) does a division by a quantity that is controlled by the caller. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/a1b11d2fdd1e51bfe18bb1ede804f60abfa92da6",
        "commit_title": "Fix one division by zero",
        "commit_text": " PiperOrigin-RevId: 369474832",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& x = context->input(0);\n    const Tensor& y = context->input(1);\n    const float min_x = context->input(2).flat<float>()(0);\n    const float max_x = context->input(3).flat<float>()(0);\n    const float min_y = context->input(4).flat<float>()(0);\n    const float max_y = context->input(5).flat<float>()(0);\n\n    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n    if (!bcast.IsValid()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",\n          y.shape().DebugString()));\n      return;\n    }\n    Tensor* z;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0, BCast::ToShape(bcast.output_shape()), &z));\n\n    // Make sure that we have valid quantization ranges for the input buffers.\n    // If the difference between the min and max is negative or zero, it makes\n    // it hard to do meaningful intermediate operations on the values.\n    OP_REQUIRES(context, (max_x > min_x),\n                errors::InvalidArgument(\"max_x must be larger than min_a.\"));\n    OP_REQUIRES(context, (max_y > min_y),\n                errors::InvalidArgument(\"max_x must be larger than min_b.\"));\n    const int32 offset_x = FloatToQuantizedUnclamped<T>(0.0f, min_x, max_x);\n    const int32 offset_y = FloatToQuantizedUnclamped<T>(0.0f, min_y, max_y);\n    const T* x_data = x.flat<T>().data();\n    const T* y_data = y.flat<T>().data();\n    Toutput* z_data = z->flat<Toutput>().data();\n\n    const int ndims = bcast.x_reshape().size();\n    if (ndims <= 1) {\n      if (x.NumElements() == 1) {\n        ScalarMultiply<T, Toutput>(context, y_data, offset_y, y.NumElements(),\n                                   x_data[0], offset_x, z_data);\n      } else if (y.NumElements() == 1) {\n        ScalarMultiply<T, Toutput>(context, x_data, offset_x, x.NumElements(),\n                                   y_data[0], offset_y, z_data);\n      } else {\n        VectorMultiply<T, Toutput>(context, x_data, offset_x, y_data, offset_y,\n                                   x.NumElements(), z_data);\n      }\n    } else if (ndims == 2) {\n      const T* vector_data;\n      int64 vector_num_elements;\n      int32 vector_offset;\n      const T* tensor_data;\n      int64 tensor_num_elements;\n      int32 tensor_offset;\n      if (x.NumElements() < y.NumElements()) {\n        vector_data = x_data;\n        vector_num_elements = x.NumElements();\n        vector_offset = offset_x;\n        tensor_data = y_data;\n        tensor_num_elements = y.NumElements();\n        tensor_offset = offset_y;\n      } else {\n        vector_data = y_data;\n        vector_num_elements = y.NumElements();\n        vector_offset = offset_y;\n        tensor_data = x_data;\n        tensor_num_elements = x.NumElements();\n        tensor_offset = offset_x;\n      }\n      VectorTensorMultiply<T, Toutput>(\n          vector_data, vector_offset, vector_num_elements, tensor_data,\n          tensor_offset, tensor_num_elements, z_data);\n    } else {\n      LOG(INFO) << \"ndims=\" << ndims;\n      LOG(INFO) << \"bcast.x_reshape()=\"\n                << TensorShape(bcast.x_reshape()).DebugString();\n      LOG(INFO) << \"bcast.y_reshape()=\"\n                << TensorShape(bcast.y_reshape()).DebugString();\n      LOG(INFO) << \"bcast.x_bcast()=\"\n                << TensorShape(bcast.x_bcast()).DebugString();\n      LOG(INFO) << \"bcast.y_bcast()=\"\n                << TensorShape(bcast.y_bcast()).DebugString();\n\n      context->SetStatus(errors::Unimplemented(\n          \"Broadcast between \", context->input(0).shape().DebugString(),\n          \" and \", context->input(1).shape().DebugString(),\n          \" is not supported yet.\"));\n      return;\n    }\n\n    float min_z_value;\n    float max_z_value;\n    QuantizationRangeForMultiplication<T, T, Toutput>(\n        min_x, max_x, min_y, max_y, &min_z_value, &max_z_value);\n    Tensor* z_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &z_min));\n    z_min->flat<float>()(0) = min_z_value;\n\n    Tensor* z_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &z_max));\n    z_max->flat<float>()(0) = max_z_value;\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& x = context->input(0);\n    const Tensor& y = context->input(1);\n    const float min_x = context->input(2).flat<float>()(0);\n    const float max_x = context->input(3).flat<float>()(0);\n    const float min_y = context->input(4).flat<float>()(0);\n    const float max_y = context->input(5).flat<float>()(0);\n\n    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n    if (!bcast.IsValid()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",\n          y.shape().DebugString()));\n      return;\n    }\n    Tensor* z;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0, BCast::ToShape(bcast.output_shape()), &z));\n\n    // Make sure that we have valid quantization ranges for the input buffers.\n    // If the difference between the min and max is negative or zero, it makes\n    // it hard to do meaningful intermediate operations on the values.\n    OP_REQUIRES(context, (max_x > min_x),\n                errors::InvalidArgument(\"max_x must be larger than min_a.\"));\n    OP_REQUIRES(context, (max_y > min_y),\n                errors::InvalidArgument(\"max_x must be larger than min_b.\"));\n    const int32 offset_x = FloatToQuantizedUnclamped<T>(0.0f, min_x, max_x);\n    const int32 offset_y = FloatToQuantizedUnclamped<T>(0.0f, min_y, max_y);\n    const T* x_data = x.flat<T>().data();\n    const T* y_data = y.flat<T>().data();\n    Toutput* z_data = z->flat<Toutput>().data();\n\n    const int ndims = bcast.x_reshape().size();\n    if (ndims <= 1) {\n      if (x.NumElements() == 1) {\n        ScalarMultiply<T, Toutput>(context, y_data, offset_y, y.NumElements(),\n                                   x_data[0], offset_x, z_data);\n      } else if (y.NumElements() == 1) {\n        ScalarMultiply<T, Toutput>(context, x_data, offset_x, x.NumElements(),\n                                   y_data[0], offset_y, z_data);\n      } else {\n        VectorMultiply<T, Toutput>(context, x_data, offset_x, y_data, offset_y,\n                                   x.NumElements(), z_data);\n      }\n    } else if (ndims == 2) {\n      const T* vector_data;\n      int64 vector_num_elements;\n      int32 vector_offset;\n      const T* tensor_data;\n      int64 tensor_num_elements;\n      int32 tensor_offset;\n      if (x.NumElements() < y.NumElements()) {\n        vector_data = x_data;\n        vector_num_elements = x.NumElements();\n        vector_offset = offset_x;\n        tensor_data = y_data;\n        tensor_num_elements = y.NumElements();\n        tensor_offset = offset_y;\n      } else {\n        vector_data = y_data;\n        vector_num_elements = y.NumElements();\n        vector_offset = offset_y;\n        tensor_data = x_data;\n        tensor_num_elements = x.NumElements();\n        tensor_offset = offset_x;\n      }\n      if (vector_num_elements == 0) {\n        context->SetStatus(\n            errors::InvalidArgument(\"vector must have at least 1 element\"));\n        return;\n      }\n      VectorTensorMultiply<T, Toutput>(\n          vector_data, vector_offset, vector_num_elements, tensor_data,\n          tensor_offset, tensor_num_elements, z_data);\n    } else {\n      LOG(INFO) << \"ndims=\" << ndims;\n      LOG(INFO) << \"bcast.x_reshape()=\"\n                << TensorShape(bcast.x_reshape()).DebugString();\n      LOG(INFO) << \"bcast.y_reshape()=\"\n                << TensorShape(bcast.y_reshape()).DebugString();\n      LOG(INFO) << \"bcast.x_bcast()=\"\n                << TensorShape(bcast.x_bcast()).DebugString();\n      LOG(INFO) << \"bcast.y_bcast()=\"\n                << TensorShape(bcast.y_bcast()).DebugString();\n\n      context->SetStatus(errors::Unimplemented(\n          \"Broadcast between \", context->input(0).shape().DebugString(),\n          \" and \", context->input(1).shape().DebugString(),\n          \" is not supported yet.\"));\n      return;\n    }\n\n    float min_z_value;\n    float max_z_value;\n    QuantizationRangeForMultiplication<T, T, Toutput>(\n        min_x, max_x, min_y, max_y, &min_z_value, &max_z_value);\n    Tensor* z_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &z_min));\n    z_min->flat<float>()(0) = min_z_value;\n\n    Tensor* z_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &z_max));\n    z_max->flat<float>()(0) = max_z_value;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -64,6 +64,11 @@\n         tensor_num_elements = x.NumElements();\n         tensor_offset = offset_x;\n       }\n+      if (vector_num_elements == 0) {\n+        context->SetStatus(\n+            errors::InvalidArgument(\"vector must have at least 1 element\"));\n+        return;\n+      }\n       VectorTensorMultiply<T, Toutput>(\n           vector_data, vector_offset, vector_num_elements, tensor_data,\n           tensor_offset, tensor_num_elements, z_data);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if (vector_num_elements == 0) {",
                "        context->SetStatus(",
                "            errors::InvalidArgument(\"vector must have at least 1 element\"));",
                "        return;",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29538",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a division by zero to occur in `Conv2DBackpropFilter`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/1b0296c3b8dd9bd948f924aa8cd62f87dbb7c3da/tensorflow/core/kernels/conv_grad_filter_ops.cc#L513-L522) computes a divisor based on user provided data (i.e., the shape of the tensors given as arguments). If all shapes are empty then `work_unit_size` is 0. Since there is no check for this case before division, this results in a runtime exception, with potential to be abused for a denial of service. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/c570e2ecfc822941335ad48f6e10df4e21f11c96",
        "commit_title": "Fix issues in Conv2DBackpropFilter.",
        "commit_text": " PiperOrigin-RevId: 369772454",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& filter_sizes = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n        errors::InvalidArgument(\n            \"Conv2DCustomBackpropFilter: filter_sizes input must be 1-dim, \"\n            \"not \",\n            filter_sizes.dims()));\n    TensorShape filter_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                filter_sizes.vec<int32>(), &filter_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(\n        context,\n        ConvBackpropComputeDimensionsV2(\n            \"Conv2DCustomBackpropFilter\", /*num_spatial_dims=*/2, input.shape(),\n            filter_shape, out_backprop.shape(), dilations_, strides_, padding_,\n            explicit_paddings_, data_format_, &dims));\n\n    Tensor* filter_backprop;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, filter_shape, &filter_backprop));\n\n    // If there is nothing to compute, return.\n    if (filter_shape.num_elements() == 0) {\n      return;\n    }\n\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardFilter<Device, T>()(\n              context, context->eigen_device<Device>(), input.tensor<T, 4>(),\n              filter_backprop->tensor<T, 4>(), out_backprop.tensor<T, 4>(),\n              dims.spatial_dims[0].input_size, dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#endif\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // Shard 'batch' images into 'shard_size' groups of images to be fed\n    // into the parallel matmul. Calculate 'shard_size' by dividing the L3 cache\n    // size ('target_working_set_size') by the matmul size of an individual\n    // image ('work_unit_size').\n\n    // TODO(andydavis)\n    // *) Get L3 cache size from device at runtime (30MB is from ivybridge).\n    // *) Consider reducing 'target_working_set_size' if L3 is shared by\n    //    other concurrently running tensorflow ops.\n    const size_t target_working_set_size = (30LL << 20) / sizeof(T);\n\n    const size_t size_A = output_image_size * filter_total_size;\n\n    const size_t size_B = output_image_size * dims.out_depth;\n\n    const size_t size_C = filter_total_size * dims.out_depth;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    const size_t shard_size =\n        (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64>(shard_size),\n                                    static_cast<int64>(output_image_size),\n                                    static_cast<int64>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* input_data = input.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n    T* filter_backprop_data = filter_backprop->template flat<T>().data();\n\n    typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                             Eigen::Unaligned>\n        TensorMap;\n    typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                             Eigen::Unaligned>\n        ConstTensorMap;\n\n    TensorMap C(filter_backprop_data, filter_total_size, dims.out_depth);\n    C.setZero();\n\n    // Initialize contraction dims (we need to transpose 'A' below).\n    Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n    contract_dims[0].first = 0;\n    contract_dims[0].second = 0;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    for (int image_id = 0; image_id < dims.batch_size; image_id += shard_size) {\n      const int shard_limit =\n          std::min(static_cast<int>(shard_size),\n                   static_cast<int>(dims.batch_size) - image_id);\n\n      auto shard = [&input_data, &col_buffer_data, &dims, &pad_top, &pad_left,\n                    &pad_bottom, &pad_right, &input_offset,\n                    &size_A](int64 start, int64 limit) {\n        for (int shard_id = start; shard_id < limit; ++shard_id) {\n          const T* input_data_shard = input_data + shard_id * input_offset;\n          T* col_data_shard = col_buffer_data + shard_id * size_A;\n\n          // When we compute the gradient with respect to the filters, we need\n          // to do im2col to allow gemm-type computation.\n          Im2col<T>(\n              input_data_shard, dims.in_depth, dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n              dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n              pad_right, dims.spatial_dims[0].stride,\n              dims.spatial_dims[1].stride, col_data_shard);\n        }\n      };\n      Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n            size_A, shard);\n\n      ConstTensorMap A(col_buffer_data, output_image_size * shard_limit,\n                       filter_total_size);\n      ConstTensorMap B(out_backprop_data, output_image_size * shard_limit,\n                       dims.out_depth);\n\n      // Gradient with respect to filter.\n      C.device(context->eigen_cpu_device()) += A.contract(B, contract_dims);\n\n      input_data += input_offset * shard_limit;\n      out_backprop_data += output_offset * shard_limit;\n    }\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& filter_sizes = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(filter_sizes.shape()),\n        errors::InvalidArgument(\n            \"Conv2DCustomBackpropFilter: filter_sizes input must be 1-dim, \"\n            \"not \",\n            filter_sizes.dims()));\n    TensorShape filter_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                filter_sizes.vec<int32>(), &filter_shape));\n\n    ConvBackpropDimensions dims;\n    OP_REQUIRES_OK(\n        context,\n        ConvBackpropComputeDimensionsV2(\n            \"Conv2DCustomBackpropFilter\", /*num_spatial_dims=*/2, input.shape(),\n            filter_shape, out_backprop.shape(), dilations_, strides_, padding_,\n            explicit_paddings_, data_format_, &dims));\n\n    Tensor* filter_backprop;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, filter_shape, &filter_backprop));\n\n    // If there is nothing to compute, return.\n    if (filter_shape.num_elements() == 0) {\n      return;\n    }\n\n    int64 pad_top, pad_bottom;\n    int64 pad_left, pad_right;\n    if (padding_ == Padding::EXPLICIT) {\n      pad_top = explicit_paddings_[2];\n      pad_bottom = explicit_paddings_[3];\n      pad_left = explicit_paddings_[4];\n      pad_right = explicit_paddings_[5];\n    }\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[0].input_size, dims.spatial_dims[0].filter_size,\n            dims.spatial_dims[0].stride, padding_,\n            &dims.spatial_dims[0].output_size, &pad_top, &pad_bottom));\n    OP_REQUIRES_OK(\n        context,\n        GetWindowedOutputSizeVerbose(\n            dims.spatial_dims[1].input_size, dims.spatial_dims[1].filter_size,\n            dims.spatial_dims[1].stride, padding_,\n            &dims.spatial_dims[1].output_size, &pad_left, &pad_right));\n#if defined TENSORFLOW_USE_LIBXSMM_CONVOLUTIONS && \\\n    defined TENSORFLOW_USE_LIBXSMM_BACKWARD_CONVOLUTIONS\n    if (pad_left == pad_right && pad_top == pad_bottom) {\n      if (LaunchXsmmBackwardFilter<Device, T>()(\n              context, context->eigen_device<Device>(), input.tensor<T, 4>(),\n              filter_backprop->tensor<T, 4>(), out_backprop.tensor<T, 4>(),\n              dims.spatial_dims[0].input_size, dims.spatial_dims[1].input_size,\n              static_cast<int>(dims.spatial_dims[0].stride),\n              static_cast<int>(dims.spatial_dims[1].stride),\n              static_cast<int>(pad_top), static_cast<int>(pad_left),\n              data_format_)) {\n        return;\n      }\n    }\n#endif\n\n    // The total dimension size of each kernel.\n    const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                  dims.spatial_dims[1].filter_size *\n                                  dims.in_depth;\n    OP_REQUIRES(\n        context,\n        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n        errors::InvalidArgument(\n            \"filter_size does not have enough elements, requested \",\n            filter_total_size * dims.out_depth, \", got \",\n            filter_backprop->NumElements()));\n\n    // The output image size is the spatial size of the output.\n    const int output_image_size =\n        dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n\n    // Shard 'batch' images into 'shard_size' groups of images to be fed\n    // into the parallel matmul. Calculate 'shard_size' by dividing the L3 cache\n    // size ('target_working_set_size') by the matmul size of an individual\n    // image ('work_unit_size').\n\n    // TODO(andydavis)\n    // *) Get L3 cache size from device at runtime (30MB is from ivybridge).\n    // *) Consider reducing 'target_working_set_size' if L3 is shared by\n    //    other concurrently running tensorflow ops.\n    const size_t target_working_set_size = (30LL << 20) / sizeof(T);\n\n    const size_t size_A = output_image_size * filter_total_size;\n\n    const size_t size_B = output_image_size * dims.out_depth;\n\n    const size_t size_C = filter_total_size * dims.out_depth;\n\n    const size_t work_unit_size = size_A + size_B + size_C;\n\n    OP_REQUIRES(\n        context, work_unit_size != 0,\n        errors::InvalidArgument(\n            \"Work size for convolution would be 0, which is not acceptable\"));\n\n    const size_t shard_size =\n        (target_working_set_size + work_unit_size - 1) / work_unit_size;\n\n    Tensor col_buffer;\n    OP_REQUIRES_OK(context,\n                   context->allocate_temp(\n                       DataTypeToEnum<T>::value,\n                       TensorShape({static_cast<int64>(shard_size),\n                                    static_cast<int64>(output_image_size),\n                                    static_cast<int64>(filter_total_size)}),\n                       &col_buffer));\n\n    // The input offset corresponding to a single input image.\n    const int input_offset = dims.spatial_dims[0].input_size *\n                             dims.spatial_dims[1].input_size * dims.in_depth;\n    // The output offset corresponding to a single output image.\n    const int output_offset = dims.spatial_dims[0].output_size *\n                              dims.spatial_dims[1].output_size * dims.out_depth;\n\n    const T* input_data = input.template flat<T>().data();\n    T* col_buffer_data = col_buffer.template flat<T>().data();\n    const T* out_backprop_data = out_backprop.template flat<T>().data();\n    T* filter_backprop_data = filter_backprop->template flat<T>().data();\n\n    typedef Eigen::TensorMap<Eigen::Tensor<T, 2, Eigen::RowMajor>,\n                             Eigen::Unaligned>\n        TensorMap;\n    typedef Eigen::TensorMap<Eigen::Tensor<const T, 2, Eigen::RowMajor>,\n                             Eigen::Unaligned>\n        ConstTensorMap;\n\n    TensorMap C(filter_backprop_data, filter_total_size, dims.out_depth);\n    C.setZero();\n\n    // Initialize contraction dims (we need to transpose 'A' below).\n    Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> contract_dims;\n    contract_dims[0].first = 0;\n    contract_dims[0].second = 0;\n\n    auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n\n    for (int image_id = 0; image_id < dims.batch_size; image_id += shard_size) {\n      const int shard_limit =\n          std::min(static_cast<int>(shard_size),\n                   static_cast<int>(dims.batch_size) - image_id);\n\n      auto shard = [&input_data, &col_buffer_data, &dims, &pad_top, &pad_left,\n                    &pad_bottom, &pad_right, &input_offset,\n                    &size_A](int64 start, int64 limit) {\n        for (int shard_id = start; shard_id < limit; ++shard_id) {\n          const T* input_data_shard = input_data + shard_id * input_offset;\n          T* col_data_shard = col_buffer_data + shard_id * size_A;\n\n          // When we compute the gradient with respect to the filters, we need\n          // to do im2col to allow gemm-type computation.\n          Im2col<T>(\n              input_data_shard, dims.in_depth, dims.spatial_dims[0].input_size,\n              dims.spatial_dims[1].input_size, dims.spatial_dims[0].filter_size,\n              dims.spatial_dims[1].filter_size, pad_top, pad_left, pad_bottom,\n              pad_right, dims.spatial_dims[0].stride,\n              dims.spatial_dims[1].stride, col_data_shard);\n        }\n      };\n      Shard(worker_threads.num_threads, worker_threads.workers, shard_limit,\n            size_A, shard);\n\n      ConstTensorMap A(col_buffer_data, output_image_size * shard_limit,\n                       filter_total_size);\n      ConstTensorMap B(out_backprop_data, output_image_size * shard_limit,\n                       dims.out_depth);\n\n      // Gradient with respect to filter.\n      C.device(context->eigen_cpu_device()) += A.contract(B, contract_dims);\n\n      input_data += input_offset * shard_limit;\n      out_backprop_data += output_offset * shard_limit;\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -69,6 +69,14 @@\n     const int filter_total_size = dims.spatial_dims[0].filter_size *\n                                   dims.spatial_dims[1].filter_size *\n                                   dims.in_depth;\n+    OP_REQUIRES(\n+        context,\n+        filter_total_size * dims.out_depth == filter_backprop->NumElements(),\n+        errors::InvalidArgument(\n+            \"filter_size does not have enough elements, requested \",\n+            filter_total_size * dims.out_depth, \", got \",\n+            filter_backprop->NumElements()));\n+\n     // The output image size is the spatial size of the output.\n     const int output_image_size =\n         dims.spatial_dims[0].output_size * dims.spatial_dims[1].output_size;\n@@ -91,6 +99,11 @@\n     const size_t size_C = filter_total_size * dims.out_depth;\n \n     const size_t work_unit_size = size_A + size_B + size_C;\n+\n+    OP_REQUIRES(\n+        context, work_unit_size != 0,\n+        errors::InvalidArgument(\n+            \"Work size for convolution would be 0, which is not acceptable\"));\n \n     const size_t shard_size =\n         (target_working_set_size + work_unit_size - 1) / work_unit_size;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context,",
                "        filter_total_size * dims.out_depth == filter_backprop->NumElements(),",
                "        errors::InvalidArgument(",
                "            \"filter_size does not have enough elements, requested \",",
                "            filter_total_size * dims.out_depth, \", got \",",
                "            filter_backprop->NumElements()));",
                "",
                "",
                "    OP_REQUIRES(",
                "        context, work_unit_size != 0,",
                "        errors::InvalidArgument(",
                "            \"Work size for convolution would be 0, which is not acceptable\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29546",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can trigger an integer division by zero undefined behavior in `tf.raw_ops.QuantizedBiasAdd`. This is because the implementation of the Eigen kernel(https://github.com/tensorflow/tensorflow/blob/61bca8bd5ba8a68b2d97435ddfafcdf2b85672cd/tensorflow/core/kernels/quantization_utils.h#L812-L849) does a division by the number of elements of the smaller input (based on shape) without checking that this is not zero. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/67784700869470d65d5f2ef20aeb5e97c31673cb",
        "commit_title": "Prevent division by 0 in `QuantizedBiasAdd`.",
        "commit_text": " PiperOrigin-RevId: 370117454",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& bias = context->input(1);\n    const float input_min = context->input(2).flat<float>()(0);\n    const float input_max = context->input(3).flat<float>()(0);\n    const float bias_min = context->input(4).flat<float>()(0);\n    const float bias_max = context->input(5).flat<float>()(0);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n                                        input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(bias.shape()),\n                errors::InvalidArgument(\"Biases must be 1D: \",\n                                        bias.shape().DebugString()));\n    const auto last_dim = input.shape().dims() - 1;\n    OP_REQUIRES(\n        context, bias.shape().dim_size(0) == input.shape().dim_size(last_dim),\n        errors::InvalidArgument(\n            \"Must provide as many biases as the last dimension \"\n            \"of the input tensor: \",\n            bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n\n    float total_min;\n    float total_max;\n\n    if (meta::IsSupportedAndEnabled() && std::is_same<T1, quint8>() &&\n        std::is_same<T2, quint8>() && std::is_same<T3, qint32>()) {\n      auto input_ui8_array = input.flat<quint8>();\n      auto bias_ui8_array = bias.flat<quint8>();\n      GetOutputMinAndMaxForQuantizedAdd(input_min, input_max, bias_min,\n                                        bias_max, &total_min, &total_max);\n      meta::QuantizedBiasAdd(context, input_ui8_array.data(),\n                             input_ui8_array.size(), bias_ui8_array.data(),\n                             bias_ui8_array.size(), input_min, input_max,\n                             bias_min, bias_max, total_min, total_max,\n                             output->flat<qint32>().data());\n    } else {\n      QuantizedAddUsingEigen<T1, T2, T3>(\n          context->template eigen_device<CPUDevice>(), input, input_min,\n          input_max, bias, bias_min, bias_max, output, &total_min, &total_max);\n    }\n\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n    output_min->flat<float>()(0) = total_min;\n\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));\n    output_max->flat<float>()(0) = total_max;\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& bias = context->input(1);\n    const float input_min = context->input(2).flat<float>()(0);\n    const float input_max = context->input(3).flat<float>()(0);\n    const float bias_min = context->input(4).flat<float>()(0);\n    const float bias_max = context->input(5).flat<float>()(0);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),\n                errors::InvalidArgument(\"Input tensor must be at least 2D: \",\n                                        input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(bias.shape()),\n                errors::InvalidArgument(\"Biases must be 1D: \",\n                                        bias.shape().DebugString()));\n    const auto last_dim = input.shape().dims() - 1;\n    OP_REQUIRES(\n        context, bias.shape().dim_size(0) == input.shape().dim_size(last_dim),\n        errors::InvalidArgument(\n            \"Must provide as many biases as the last dimension \"\n            \"of the input tensor: \",\n            bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n    OP_REQUIRES(context, bias.NumElements() > 0,\n                errors::InvalidArgument(\"Must provide at least 1 bias\"));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n\n    float total_min;\n    float total_max;\n\n    if (meta::IsSupportedAndEnabled() && std::is_same<T1, quint8>() &&\n        std::is_same<T2, quint8>() && std::is_same<T3, qint32>()) {\n      auto input_ui8_array = input.flat<quint8>();\n      auto bias_ui8_array = bias.flat<quint8>();\n      GetOutputMinAndMaxForQuantizedAdd(input_min, input_max, bias_min,\n                                        bias_max, &total_min, &total_max);\n      meta::QuantizedBiasAdd(context, input_ui8_array.data(),\n                             input_ui8_array.size(), bias_ui8_array.data(),\n                             bias_ui8_array.size(), input_min, input_max,\n                             bias_min, bias_max, total_min, total_max,\n                             output->flat<qint32>().data());\n    } else {\n      QuantizedAddUsingEigen<T1, T2, T3>(\n          context->template eigen_device<CPUDevice>(), input, input_min,\n          input_max, bias, bias_min, bias_max, output, &total_min, &total_max);\n    }\n\n    Tensor* output_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &output_min));\n    output_min->flat<float>()(0) = total_min;\n\n    Tensor* output_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &output_max));\n    output_max->flat<float>()(0) = total_max;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,8 @@\n             \"Must provide as many biases as the last dimension \"\n             \"of the input tensor: \",\n             bias.shape().DebugString(), \" vs. \", input.shape().DebugString()));\n+    OP_REQUIRES(context, bias.NumElements() > 0,\n+                errors::InvalidArgument(\"Must provide at least 1 bias\"));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(context, bias.NumElements() > 0,",
                "                errors::InvalidArgument(\"Must provide at least 1 bias\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29547",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a segfault and denial of service via accessing data outside of bounds in `tf.raw_ops.QuantizedBatchNormWithGlobalNormalization`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f/tensorflow/core/kernels/quantized_batch_norm_op.cc#L176-L189) assumes the inputs are not empty. If any of these inputs is empty, `.flat<T>()` is an empty buffer, so accessing the element at index 0 is accessing data outside of bounds. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
        "commit_title": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`",
        "commit_text": " PiperOrigin-RevId: 370123451",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const float input_min = context->input(1).flat<float>()(0);\n    const float input_max = context->input(2).flat<float>()(0);\n    const Tensor& mean = context->input(3);\n    const float mean_min = context->input(4).flat<float>()(0);\n    const float mean_max = context->input(5).flat<float>()(0);\n    const Tensor& var = context->input(6);\n    const float var_min = context->input(7).flat<float>()(0);\n    const float var_max = context->input(8).flat<float>()(0);\n    const Tensor& beta = context->input(9);\n    const float beta_min = context->input(10).flat<float>()(0);\n    const float beta_max = context->input(11).flat<float>()(0);\n    const Tensor& gamma = context->input(12);\n    const float gamma_min = context->input(13).flat<float>()(0);\n    const float gamma_max = context->input(14).flat<float>()(0);\n\n    OP_REQUIRES(context, input.dims() == 4,\n                errors::InvalidArgument(\"input must be 4-dimensional\",\n                                        input.shape().DebugString()));\n    OP_REQUIRES(context, mean.dims() == 1,\n                errors::InvalidArgument(\"mean must be 1-dimensional\",\n                                        mean.shape().DebugString()));\n    OP_REQUIRES(context, var.dims() == 1,\n                errors::InvalidArgument(\"var must be 1-dimensional\",\n                                        var.shape().DebugString()));\n    OP_REQUIRES(context, beta.dims() == 1,\n                errors::InvalidArgument(\"beta must be 1-dimensional\",\n                                        beta.shape().DebugString()));\n    OP_REQUIRES(context, gamma.dims() == 1,\n                errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                        gamma.shape().DebugString()));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n    float output_min;\n    float output_max;\n    FixedPointBatchNorm<T1, T2>(input, input_min, input_max, mean, mean_min,\n                                mean_max, var, var_min, var_max, beta, beta_min,\n                                beta_max, gamma, gamma_min, gamma_max,\n                                variance_epsilon_, scale_after_normalization_,\n                                output, &output_min, &output_max);\n\n    Tensor* output_min_tensor = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(1, {}, &output_min_tensor));\n    output_min_tensor->flat<float>()(0) = output_min;\n\n    Tensor* output_max_tensor = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(2, {}, &output_max_tensor));\n    output_max_tensor->flat<float>()(0) = output_max;\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const auto& input_min_tensor = context->input(1);\n    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"input_min must have 1 element\"));\n    const float input_min = input_min_tensor.flat<float>()(0);\n    const auto& input_max_tensor = context->input(2);\n    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"input_max must have 1 element\"));\n    const float input_max = input_max_tensor.flat<float>()(0);\n    const Tensor& mean = context->input(3);\n    const auto& mean_min_tensor = context->input(4);\n    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"mean_min must have 1 element\"));\n    const float mean_min = mean_min_tensor.flat<float>()(0);\n    const auto& mean_max_tensor = context->input(5);\n    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"mean_max must have 1 element\"));\n    const float mean_max = mean_max_tensor.flat<float>()(0);\n    const Tensor& var = context->input(6);\n    const auto& var_min_tensor = context->input(7);\n    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"var_min must have 1 element\"));\n    const float var_min = var_min_tensor.flat<float>()(0);\n    const auto& var_max_tensor = context->input(8);\n    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"var_max must have 1 element\"));\n    const float var_max = var_max_tensor.flat<float>()(0);\n    const Tensor& beta = context->input(9);\n    const auto& beta_min_tensor = context->input(10);\n    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"beta_min must have 1 element\"));\n    const float beta_min = beta_min_tensor.flat<float>()(0);\n    const auto& beta_max_tensor = context->input(11);\n    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"beta_max must have 1 element\"));\n    const float beta_max = beta_max_tensor.flat<float>()(0);\n    const Tensor& gamma = context->input(12);\n    const auto& gamma_min_tensor = context->input(13);\n    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n    const auto& gamma_max_tensor = context->input(14);\n    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n\n    OP_REQUIRES(context, input.dims() == 4,\n                errors::InvalidArgument(\"input must be 4-dimensional\",\n                                        input.shape().DebugString()));\n    OP_REQUIRES(context, mean.dims() == 1,\n                errors::InvalidArgument(\"mean must be 1-dimensional\",\n                                        mean.shape().DebugString()));\n    OP_REQUIRES(context, var.dims() == 1,\n                errors::InvalidArgument(\"var must be 1-dimensional\",\n                                        var.shape().DebugString()));\n    OP_REQUIRES(context, beta.dims() == 1,\n                errors::InvalidArgument(\"beta must be 1-dimensional\",\n                                        beta.shape().DebugString()));\n    OP_REQUIRES(context, gamma.dims() == 1,\n                errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                        gamma.shape().DebugString()));\n    OP_REQUIRES(context, mean.NumElements() > 1,\n                errors::InvalidArgument(\"Must have at least a mean value\",\n                                        gamma.shape().DebugString()));\n    OP_REQUIRES(context, mean.NumElements() > 1,\n                errors::InvalidArgument(\"Must have at least a mean value\"));\n    const auto last_dim = input.shape().dims() - 1;\n    OP_REQUIRES(context,\n                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n                errors::InvalidArgument(\"Must provide as many means as the \"\n                                        \"last dimension of the input tensor: \",\n                                        mean.shape().DebugString(), \" vs. \",\n                                        input.shape().DebugString()));\n    OP_REQUIRES(\n        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Mean and variance tensors must have the same shape: \",\n            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n    OP_REQUIRES(\n        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Mean and beta tensors must have the same shape: \",\n            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n    OP_REQUIRES(\n        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Mean and gamma tensors must have the same shape: \",\n            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &output));\n    float output_min;\n    float output_max;\n    FixedPointBatchNorm<T1, T2>(input, input_min, input_max, mean, mean_min,\n                                mean_max, var, var_min, var_max, beta, beta_min,\n                                beta_max, gamma, gamma_min, gamma_max,\n                                variance_epsilon_, scale_after_normalization_,\n                                output, &output_min, &output_max);\n\n    Tensor* output_min_tensor = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(1, {}, &output_min_tensor));\n    output_min_tensor->flat<float>()(0) = output_min;\n\n    Tensor* output_max_tensor = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(2, {}, &output_max_tensor));\n    output_max_tensor->flat<float>()(0) = output_max;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,19 +1,49 @@\n void Compute(OpKernelContext* context) override {\n     const Tensor& input = context->input(0);\n-    const float input_min = context->input(1).flat<float>()(0);\n-    const float input_max = context->input(2).flat<float>()(0);\n+    const auto& input_min_tensor = context->input(1);\n+    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_min must have 1 element\"));\n+    const float input_min = input_min_tensor.flat<float>()(0);\n+    const auto& input_max_tensor = context->input(2);\n+    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"input_max must have 1 element\"));\n+    const float input_max = input_max_tensor.flat<float>()(0);\n     const Tensor& mean = context->input(3);\n-    const float mean_min = context->input(4).flat<float>()(0);\n-    const float mean_max = context->input(5).flat<float>()(0);\n+    const auto& mean_min_tensor = context->input(4);\n+    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_min must have 1 element\"));\n+    const float mean_min = mean_min_tensor.flat<float>()(0);\n+    const auto& mean_max_tensor = context->input(5);\n+    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"mean_max must have 1 element\"));\n+    const float mean_max = mean_max_tensor.flat<float>()(0);\n     const Tensor& var = context->input(6);\n-    const float var_min = context->input(7).flat<float>()(0);\n-    const float var_max = context->input(8).flat<float>()(0);\n+    const auto& var_min_tensor = context->input(7);\n+    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_min must have 1 element\"));\n+    const float var_min = var_min_tensor.flat<float>()(0);\n+    const auto& var_max_tensor = context->input(8);\n+    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"var_max must have 1 element\"));\n+    const float var_max = var_max_tensor.flat<float>()(0);\n     const Tensor& beta = context->input(9);\n-    const float beta_min = context->input(10).flat<float>()(0);\n-    const float beta_max = context->input(11).flat<float>()(0);\n+    const auto& beta_min_tensor = context->input(10);\n+    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_min must have 1 element\"));\n+    const float beta_min = beta_min_tensor.flat<float>()(0);\n+    const auto& beta_max_tensor = context->input(11);\n+    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"beta_max must have 1 element\"));\n+    const float beta_max = beta_max_tensor.flat<float>()(0);\n     const Tensor& gamma = context->input(12);\n-    const float gamma_min = context->input(13).flat<float>()(0);\n-    const float gamma_max = context->input(14).flat<float>()(0);\n+    const auto& gamma_min_tensor = context->input(13);\n+    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_min must have 1 element\"));\n+    const float gamma_min = gamma_min_tensor.flat<float>()(0);\n+    const auto& gamma_max_tensor = context->input(14);\n+    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,\n+                errors::InvalidArgument(\"gamma_max must have 1 element\"));\n+    const float gamma_max = gamma_max_tensor.flat<float>()(0);\n \n     OP_REQUIRES(context, input.dims() == 4,\n                 errors::InvalidArgument(\"input must be 4-dimensional\",\n@@ -30,6 +60,33 @@\n     OP_REQUIRES(context, gamma.dims() == 1,\n                 errors::InvalidArgument(\"gamma must be 1-dimensional\",\n                                         gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\",\n+                                        gamma.shape().DebugString()));\n+    OP_REQUIRES(context, mean.NumElements() > 1,\n+                errors::InvalidArgument(\"Must have at least a mean value\"));\n+    const auto last_dim = input.shape().dims() - 1;\n+    OP_REQUIRES(context,\n+                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),\n+                errors::InvalidArgument(\"Must provide as many means as the \"\n+                                        \"last dimension of the input tensor: \",\n+                                        mean.shape().DebugString(), \" vs. \",\n+                                        input.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == var.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and variance tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and beta tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));\n+    OP_REQUIRES(\n+        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),\n+        errors::InvalidArgument(\n+            \"Mean and gamma tensors must have the same shape: \",\n+            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));\n \n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,",
        "diff_line_info": {
            "deleted_lines": [
                "    const float input_min = context->input(1).flat<float>()(0);",
                "    const float input_max = context->input(2).flat<float>()(0);",
                "    const float mean_min = context->input(4).flat<float>()(0);",
                "    const float mean_max = context->input(5).flat<float>()(0);",
                "    const float var_min = context->input(7).flat<float>()(0);",
                "    const float var_max = context->input(8).flat<float>()(0);",
                "    const float beta_min = context->input(10).flat<float>()(0);",
                "    const float beta_max = context->input(11).flat<float>()(0);",
                "    const float gamma_min = context->input(13).flat<float>()(0);",
                "    const float gamma_max = context->input(14).flat<float>()(0);"
            ],
            "added_lines": [
                "    const auto& input_min_tensor = context->input(1);",
                "    OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"input_min must have 1 element\"));",
                "    const float input_min = input_min_tensor.flat<float>()(0);",
                "    const auto& input_max_tensor = context->input(2);",
                "    OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"input_max must have 1 element\"));",
                "    const float input_max = input_max_tensor.flat<float>()(0);",
                "    const auto& mean_min_tensor = context->input(4);",
                "    OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"mean_min must have 1 element\"));",
                "    const float mean_min = mean_min_tensor.flat<float>()(0);",
                "    const auto& mean_max_tensor = context->input(5);",
                "    OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"mean_max must have 1 element\"));",
                "    const float mean_max = mean_max_tensor.flat<float>()(0);",
                "    const auto& var_min_tensor = context->input(7);",
                "    OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"var_min must have 1 element\"));",
                "    const float var_min = var_min_tensor.flat<float>()(0);",
                "    const auto& var_max_tensor = context->input(8);",
                "    OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"var_max must have 1 element\"));",
                "    const float var_max = var_max_tensor.flat<float>()(0);",
                "    const auto& beta_min_tensor = context->input(10);",
                "    OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"beta_min must have 1 element\"));",
                "    const float beta_min = beta_min_tensor.flat<float>()(0);",
                "    const auto& beta_max_tensor = context->input(11);",
                "    OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"beta_max must have 1 element\"));",
                "    const float beta_max = beta_max_tensor.flat<float>()(0);",
                "    const auto& gamma_min_tensor = context->input(13);",
                "    OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"gamma_min must have 1 element\"));",
                "    const float gamma_min = gamma_min_tensor.flat<float>()(0);",
                "    const auto& gamma_max_tensor = context->input(14);",
                "    OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
                "                errors::InvalidArgument(\"gamma_max must have 1 element\"));",
                "    const float gamma_max = gamma_max_tensor.flat<float>()(0);",
                "    OP_REQUIRES(context, mean.NumElements() > 1,",
                "                errors::InvalidArgument(\"Must have at least a mean value\",",
                "                                        gamma.shape().DebugString()));",
                "    OP_REQUIRES(context, mean.NumElements() > 1,",
                "                errors::InvalidArgument(\"Must have at least a mean value\"));",
                "    const auto last_dim = input.shape().dims() - 1;",
                "    OP_REQUIRES(context,",
                "                mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
                "                errors::InvalidArgument(\"Must provide as many means as the \"",
                "                                        \"last dimension of the input tensor: \",",
                "                                        mean.shape().DebugString(), \" vs. \",",
                "                                        input.shape().DebugString()));",
                "    OP_REQUIRES(",
                "        context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
                "        errors::InvalidArgument(",
                "            \"Mean and variance tensors must have the same shape: \",",
                "            mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
                "    OP_REQUIRES(",
                "        context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
                "        errors::InvalidArgument(",
                "            \"Mean and beta tensors must have the same shape: \",",
                "            mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
                "    OP_REQUIRES(",
                "        context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
                "        errors::InvalidArgument(",
                "            \"Mean and gamma tensors must have the same shape: \",",
                "            mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29549",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a runtime division by zero error and denial of service in `tf.raw_ops.QuantizedBatchNormWithGlobalNormalization`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/6f26b3f3418201479c264f2a02000880d8df151c/tensorflow/core/kernels/quantized_add_op.cc#L289-L295) computes a modulo operation without validating that the divisor is not zero. Since `vector_num_elements` is determined based on input shapes(https://github.com/tensorflow/tensorflow/blob/6f26b3f3418201479c264f2a02000880d8df151c/tensorflow/core/kernels/quantized_add_op.cc#L522-L544), a user can trigger scenarios where this quantity is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/744009c9e5cc5d0447f0dc39d055f917e1fd9e16",
        "commit_title": "Validate work in `QuantizedAdd`, ensure at least one element.",
        "commit_text": " PiperOrigin-RevId: 370127996",
        "func_before": "void Compute(OpKernelContext* context) override {\n    const Tensor& x = context->input(0);\n    const Tensor& y = context->input(1);\n    const float min_x = context->input(2).flat<float>()(0);\n    const float max_x = context->input(3).flat<float>()(0);\n    const float min_y = context->input(4).flat<float>()(0);\n    const float max_y = context->input(5).flat<float>()(0);\n\n    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n    if (!bcast.IsValid()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",\n          y.shape().DebugString()));\n      return;\n    }\n    Tensor* z;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0, BCast::ToShape(bcast.output_shape()), &z));\n\n    // Make sure that we have valid quantization ranges for the input buffers.\n    // If the difference between the min and max is negative or zero, it makes\n    // it hard to do meaningful intermediate operations on the values.\n    OP_REQUIRES(context, (max_x > min_x),\n                errors::InvalidArgument(\"max_x must be larger than min_x.\"));\n    OP_REQUIRES(context, (max_y > min_y),\n                errors::InvalidArgument(\"max_y must be larger than min_y.\"));\n    const T* x_data = x.flat<T>().data();\n    const T* y_data = y.flat<T>().data();\n    Toutput* z_data = z->flat<Toutput>().data();\n\n    // We want the range of the output to be symmetrical around zero so that\n    // adding zero leaves the result unchanged, and to contain the largest of\n    // the two input values with some room to spare.\n    const float smallest_min = std::min(min_x, min_y);\n    const float largest_max = std::max(max_x, max_y);\n    const float biggest_range =\n        std::max(std::abs(smallest_min), std::abs(largest_max));\n    const float output_range = (biggest_range * (1 << 14));\n    const float min_z_value = -output_range;\n    const float max_z_value = output_range;\n\n    const int ndims = bcast.x_reshape().size();\n    if (ndims <= 1) {\n      if (x.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, y_data, min_y, max_y,\n                                   y.NumElements(), x_data[0], min_x, max_x,\n                                   min_z_value, max_z_value, z_data);\n      } else if (y.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, x_data, min_x, max_x,\n                                   x.NumElements(), y_data[0], min_y, max_y,\n                                   min_z_value, max_z_value, z_data);\n      } else {\n        VectorAddition<T, Toutput>(context, x_data, min_x, max_x, y_data, min_y,\n                                   max_y, x.NumElements(), min_z_value,\n                                   max_z_value, z_data);\n      }\n    } else if (ndims == 2) {\n      const T* vector_data;\n      int64 vector_num_elements;\n      float vector_min;\n      float vector_max;\n      const T* tensor_data;\n      int64 tensor_num_elements;\n      float tensor_min;\n      float tensor_max;\n      if (x.NumElements() < y.NumElements()) {\n        vector_data = x_data;\n        vector_num_elements = x.NumElements();\n        vector_min = min_x;\n        vector_max = max_x;\n        tensor_data = y_data;\n        tensor_num_elements = y.NumElements();\n        tensor_min = min_y;\n        tensor_max = max_y;\n      } else {\n        vector_data = y_data;\n        vector_num_elements = y.NumElements();\n        vector_min = min_y;\n        vector_max = max_y;\n        tensor_data = x_data;\n        tensor_num_elements = x.NumElements();\n        tensor_min = min_x;\n        tensor_max = max_x;\n      }\n      VectorTensorAddition<T, Toutput>(\n          vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\n          tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,\n          z_data);\n    } else {\n      LOG(INFO) << \"ndims=\" << ndims;\n      LOG(INFO) << \"bcast.x_reshape()=\"\n                << TensorShape(bcast.x_reshape()).DebugString();\n      LOG(INFO) << \"bcast.y_reshape()=\"\n                << TensorShape(bcast.y_reshape()).DebugString();\n      LOG(INFO) << \"bcast.x_bcast()=\"\n                << TensorShape(bcast.x_bcast()).DebugString();\n      LOG(INFO) << \"bcast.y_bcast()=\"\n                << TensorShape(bcast.y_bcast()).DebugString();\n\n      context->SetStatus(errors::Unimplemented(\n          \"Broadcast between \", context->input(0).shape().DebugString(),\n          \" and \", context->input(1).shape().DebugString(),\n          \" is not supported yet.\"));\n      return;\n    }\n\n    Tensor* z_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &z_min));\n    z_min->flat<float>()(0) = min_z_value;\n\n    Tensor* z_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &z_max));\n    z_max->flat<float>()(0) = max_z_value;\n  }",
        "func": "void Compute(OpKernelContext* context) override {\n    const Tensor& x = context->input(0);\n    const Tensor& y = context->input(1);\n    const float min_x = context->input(2).flat<float>()(0);\n    const float max_x = context->input(3).flat<float>()(0);\n    const float min_y = context->input(4).flat<float>()(0);\n    const float max_y = context->input(5).flat<float>()(0);\n\n    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n    if (!bcast.IsValid()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",\n          y.shape().DebugString()));\n      return;\n    }\n    Tensor* z;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0, BCast::ToShape(bcast.output_shape()), &z));\n\n    // Make sure that we have valid quantization ranges for the input buffers.\n    // If the difference between the min and max is negative or zero, it makes\n    // it hard to do meaningful intermediate operations on the values.\n    OP_REQUIRES(context, (max_x > min_x),\n                errors::InvalidArgument(\"max_x must be larger than min_x.\"));\n    OP_REQUIRES(context, (max_y > min_y),\n                errors::InvalidArgument(\"max_y must be larger than min_y.\"));\n    const T* x_data = x.flat<T>().data();\n    const T* y_data = y.flat<T>().data();\n    Toutput* z_data = z->flat<Toutput>().data();\n\n    // We want the range of the output to be symmetrical around zero so that\n    // adding zero leaves the result unchanged, and to contain the largest of\n    // the two input values with some room to spare.\n    const float smallest_min = std::min(min_x, min_y);\n    const float largest_max = std::max(max_x, max_y);\n    const float biggest_range =\n        std::max(std::abs(smallest_min), std::abs(largest_max));\n    const float output_range = (biggest_range * (1 << 14));\n    const float min_z_value = -output_range;\n    const float max_z_value = output_range;\n\n    const int ndims = bcast.x_reshape().size();\n    if (ndims <= 1) {\n      if (x.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, y_data, min_y, max_y,\n                                   y.NumElements(), x_data[0], min_x, max_x,\n                                   min_z_value, max_z_value, z_data);\n      } else if (y.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, x_data, min_x, max_x,\n                                   x.NumElements(), y_data[0], min_y, max_y,\n                                   min_z_value, max_z_value, z_data);\n      } else {\n        VectorAddition<T, Toutput>(context, x_data, min_x, max_x, y_data, min_y,\n                                   max_y, x.NumElements(), min_z_value,\n                                   max_z_value, z_data);\n      }\n    } else if (ndims == 2) {\n      const T* vector_data;\n      int64 vector_num_elements;\n      float vector_min;\n      float vector_max;\n      const T* tensor_data;\n      int64 tensor_num_elements;\n      float tensor_min;\n      float tensor_max;\n      if (x.NumElements() < y.NumElements()) {\n        vector_data = x_data;\n        vector_num_elements = x.NumElements();\n        vector_min = min_x;\n        vector_max = max_x;\n        tensor_data = y_data;\n        tensor_num_elements = y.NumElements();\n        tensor_min = min_y;\n        tensor_max = max_y;\n      } else {\n        vector_data = y_data;\n        vector_num_elements = y.NumElements();\n        vector_min = min_y;\n        vector_max = max_y;\n        tensor_data = x_data;\n        tensor_num_elements = x.NumElements();\n        tensor_min = min_x;\n        tensor_max = max_x;\n      }\n      OP_REQUIRES(context, vector_num_elements > 0,\n                  errors::InvalidArgument(\"Must have some elements to add\"));\n      VectorTensorAddition<T, Toutput>(\n          vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\n          tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,\n          z_data);\n    } else {\n      LOG(INFO) << \"ndims=\" << ndims;\n      LOG(INFO) << \"bcast.x_reshape()=\"\n                << TensorShape(bcast.x_reshape()).DebugString();\n      LOG(INFO) << \"bcast.y_reshape()=\"\n                << TensorShape(bcast.y_reshape()).DebugString();\n      LOG(INFO) << \"bcast.x_bcast()=\"\n                << TensorShape(bcast.x_bcast()).DebugString();\n      LOG(INFO) << \"bcast.y_bcast()=\"\n                << TensorShape(bcast.y_bcast()).DebugString();\n\n      context->SetStatus(errors::Unimplemented(\n          \"Broadcast between \", context->input(0).shape().DebugString(),\n          \" and \", context->input(1).shape().DebugString(),\n          \" is not supported yet.\"));\n      return;\n    }\n\n    Tensor* z_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &z_min));\n    z_min->flat<float>()(0) = min_z_value;\n\n    Tensor* z_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &z_max));\n    z_max->flat<float>()(0) = max_z_value;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -82,6 +82,8 @@\n         tensor_min = min_x;\n         tensor_max = max_x;\n       }\n+      OP_REQUIRES(context, vector_num_elements > 0,\n+                  errors::InvalidArgument(\"Must have some elements to add\"));\n       VectorTensorAddition<T, Toutput>(\n           vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\n           tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      OP_REQUIRES(context, vector_num_elements > 0,",
                "                  errors::InvalidArgument(\"Must have some elements to add\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29555",
        "func_name": "tensorflow/operator()",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.FusedBatchNorm`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/828f346274841fa7505f7020e88ca36c22e557ab/tensorflow/core/kernels/fused_batch_norm_op.cc#L295-L297) performs a division based on the last dimension of the `x` tensor. Since this is controlled by the user, an attacker can trigger a denial of service. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/1a2a87229d1d61e23a39373777c056161eb4084d",
        "commit_title": "Fix FPE issue with `tf.raw_ops.FusedBatchNorm`.",
        "commit_text": " PiperOrigin-RevId: 370948185",
        "func_before": "void operator()(OpKernelContext* context, const Tensor& x_input,\n                  const Tensor& scale_input, const Tensor& offset_input,\n                  const Tensor& estimated_mean_input,\n                  const Tensor& estimated_variance_input,\n                  const Tensor* side_input, U epsilon, U exponential_avg_factor,\n                  FusedBatchNormActivationMode activation_mode,\n                  Tensor* y_output, Tensor* batch_mean_output,\n                  Tensor* batch_var_output, Tensor* saved_mean_output,\n                  Tensor* saved_var_output, TensorFormat tensor_format,\n                  bool use_reserved_space) {\n    OP_REQUIRES(context, side_input == nullptr,\n                errors::Internal(\n                    \"The CPU implementation of FusedBatchNorm does not support \"\n                    \"side input.\"));\n    OP_REQUIRES(context,\n                activation_mode == FusedBatchNormActivationMode::kIdentity,\n                errors::Internal(\"The CPU implementation of FusedBatchNorm \"\n                                 \"does not support activations.\"));\n\n    if (use_reserved_space) {\n      Tensor* dummy_reserve_space = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(5, {}, &dummy_reserve_space));\n      // Initialize the memory, to avoid sanitizer alerts.\n      dummy_reserve_space->flat<U>()(0) = U();\n    }\n    Tensor transformed_x;\n    Tensor transformed_y;\n    if (tensor_format == FORMAT_NCHW) {\n      const int64 in_batch = GetTensorDim(x_input, tensor_format, 'N');\n      const int64 in_rows = GetTensorDim(x_input, tensor_format, 'H');\n      const int64 in_cols = GetTensorDim(x_input, tensor_format, 'W');\n      const int64 in_depths = GetTensorDim(x_input, tensor_format, 'C');\n      OP_REQUIRES_OK(context, context->allocate_temp(\n                                  DataTypeToEnum<T>::value,\n                                  ShapeFromFormat(FORMAT_NHWC, in_batch,\n                                                  in_rows, in_cols, in_depths),\n                                  &transformed_x));\n      OP_REQUIRES_OK(context, context->allocate_temp(\n                                  DataTypeToEnum<T>::value,\n                                  ShapeFromFormat(FORMAT_NHWC, in_batch,\n                                                  in_rows, in_cols, in_depths),\n                                  &transformed_y));\n      // Perform NCHW to NHWC\n      std::vector<int32> perm = {0, 2, 3, 1};\n      OP_REQUIRES_OK(\n          context, ::tensorflow::DoTranspose(context->eigen_device<CPUDevice>(),\n                                             x_input, perm, &transformed_x));\n    } else {\n      transformed_x = x_input;\n      transformed_y = *y_output;\n    }\n    typename TTypes<T, 4>::Tensor x(transformed_x.tensor<T, 4>());\n    typename TTypes<U>::ConstVec scale(scale_input.vec<U>());\n    typename TTypes<U>::ConstVec offset(offset_input.vec<U>());\n    typename TTypes<U>::ConstVec estimated_mean(estimated_mean_input.vec<U>());\n    typename TTypes<U>::ConstVec estimated_variance(\n        estimated_variance_input.vec<U>());\n    typename TTypes<T, 4>::Tensor y(transformed_y.tensor<T, 4>());\n    typename TTypes<U>::Vec batch_mean(batch_mean_output->vec<U>());\n    typename TTypes<U>::Vec batch_variance(batch_var_output->vec<U>());\n\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    const int depth = x.dimension(3);\n    const int size = x.size();\n    const int rest_size = size / depth;\n    Eigen::DSizes<Eigen::Index, 2> rest_by_depth(rest_size, depth);\n\n#if !defined(EIGEN_HAS_INDEX_LIST)\n    Eigen::DSizes<Eigen::Index, 2> one_by_depth(1, depth);\n    Eigen::array<int, 1> reduce_dims({0});\n    Eigen::array<int, 2> bcast_spec({rest_size, 1});\n#else\n    Eigen::IndexList<Eigen::type2index<1>, Eigen::Index> one_by_depth;\n    one_by_depth.set(1, depth);\n    Eigen::IndexList<Eigen::Index, Eigen::type2index<1>> bcast_spec;\n    bcast_spec.set(0, rest_size);\n#endif\n\n    auto x_rest_by_depth = x.reshape(rest_by_depth).template cast<U>();\n    auto x_centered =\n        x_rest_by_depth -\n        estimated_mean.reshape(one_by_depth).broadcast(bcast_spec);\n    auto scaling_factor = ((estimated_variance + epsilon).rsqrt() * scale)\n                              .eval()\n                              .reshape(one_by_depth)\n                              .broadcast(bcast_spec);\n    auto x_scaled = x_centered * scaling_factor;\n    auto x_shifted =\n        (x_scaled + offset.reshape(one_by_depth).broadcast(bcast_spec))\n            .template cast<T>();\n\n    y.reshape(rest_by_depth).device(d) = x_shifted;\n    batch_mean.device(d) = estimated_mean;\n    batch_variance.device(d) = estimated_variance;\n\n    if (tensor_format == FORMAT_NCHW) {\n      // Perform NHWC to NCHW\n      const std::vector<int32> perm = {0, 3, 1, 2};\n      const Status s = ::tensorflow::DoTranspose(\n          context->eigen_device<CPUDevice>(), transformed_y, perm, y_output);\n      if (!s.ok()) {\n        context->SetStatus(errors::InvalidArgument(\"Transpose failed: \", s));\n      }\n    }\n  }",
        "func": "void operator()(OpKernelContext* context, const Tensor& x_input,\n                  const Tensor& scale_input, const Tensor& offset_input,\n                  const Tensor& estimated_mean_input,\n                  const Tensor& estimated_variance_input,\n                  const Tensor* side_input, U epsilon, U exponential_avg_factor,\n                  FusedBatchNormActivationMode activation_mode,\n                  Tensor* y_output, Tensor* batch_mean_output,\n                  Tensor* batch_var_output, Tensor* saved_mean_output,\n                  Tensor* saved_var_output, TensorFormat tensor_format,\n                  bool use_reserved_space) {\n    OP_REQUIRES(context, side_input == nullptr,\n                errors::Internal(\n                    \"The CPU implementation of FusedBatchNorm does not support \"\n                    \"side input.\"));\n    OP_REQUIRES(context,\n                activation_mode == FusedBatchNormActivationMode::kIdentity,\n                errors::Internal(\"The CPU implementation of FusedBatchNorm \"\n                                 \"does not support activations.\"));\n\n    if (use_reserved_space) {\n      Tensor* dummy_reserve_space = nullptr;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(5, {}, &dummy_reserve_space));\n      // Initialize the memory, to avoid sanitizer alerts.\n      dummy_reserve_space->flat<U>()(0) = U();\n    }\n    Tensor transformed_x;\n    Tensor transformed_y;\n    if (tensor_format == FORMAT_NCHW) {\n      const int64 in_batch = GetTensorDim(x_input, tensor_format, 'N');\n      const int64 in_rows = GetTensorDim(x_input, tensor_format, 'H');\n      const int64 in_cols = GetTensorDim(x_input, tensor_format, 'W');\n      const int64 in_depths = GetTensorDim(x_input, tensor_format, 'C');\n      OP_REQUIRES_OK(context, context->allocate_temp(\n                                  DataTypeToEnum<T>::value,\n                                  ShapeFromFormat(FORMAT_NHWC, in_batch,\n                                                  in_rows, in_cols, in_depths),\n                                  &transformed_x));\n      OP_REQUIRES_OK(context, context->allocate_temp(\n                                  DataTypeToEnum<T>::value,\n                                  ShapeFromFormat(FORMAT_NHWC, in_batch,\n                                                  in_rows, in_cols, in_depths),\n                                  &transformed_y));\n      // Perform NCHW to NHWC\n      std::vector<int32> perm = {0, 2, 3, 1};\n      OP_REQUIRES_OK(\n          context, ::tensorflow::DoTranspose(context->eigen_device<CPUDevice>(),\n                                             x_input, perm, &transformed_x));\n    } else {\n      transformed_x = x_input;\n      transformed_y = *y_output;\n    }\n    typename TTypes<T, 4>::Tensor x(transformed_x.tensor<T, 4>());\n    typename TTypes<U>::ConstVec scale(scale_input.vec<U>());\n    typename TTypes<U>::ConstVec offset(offset_input.vec<U>());\n    typename TTypes<U>::ConstVec estimated_mean(estimated_mean_input.vec<U>());\n    typename TTypes<U>::ConstVec estimated_variance(\n        estimated_variance_input.vec<U>());\n    typename TTypes<T, 4>::Tensor y(transformed_y.tensor<T, 4>());\n    typename TTypes<U>::Vec batch_mean(batch_mean_output->vec<U>());\n    typename TTypes<U>::Vec batch_variance(batch_var_output->vec<U>());\n\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    const int depth = x.dimension(3);\n    OP_REQUIRES(\n        context, depth != 0,\n        errors::Internal(\"The 4th element in the input shape cannot be 0.\"));\n    const int size = x.size();\n    const int rest_size = size / depth;\n    Eigen::DSizes<Eigen::Index, 2> rest_by_depth(rest_size, depth);\n\n#if !defined(EIGEN_HAS_INDEX_LIST)\n    Eigen::DSizes<Eigen::Index, 2> one_by_depth(1, depth);\n    Eigen::array<int, 1> reduce_dims({0});\n    Eigen::array<int, 2> bcast_spec({rest_size, 1});\n#else\n    Eigen::IndexList<Eigen::type2index<1>, Eigen::Index> one_by_depth;\n    one_by_depth.set(1, depth);\n    Eigen::IndexList<Eigen::Index, Eigen::type2index<1>> bcast_spec;\n    bcast_spec.set(0, rest_size);\n#endif\n\n    auto x_rest_by_depth = x.reshape(rest_by_depth).template cast<U>();\n    auto x_centered =\n        x_rest_by_depth -\n        estimated_mean.reshape(one_by_depth).broadcast(bcast_spec);\n    auto scaling_factor = ((estimated_variance + epsilon).rsqrt() * scale)\n                              .eval()\n                              .reshape(one_by_depth)\n                              .broadcast(bcast_spec);\n    auto x_scaled = x_centered * scaling_factor;\n    auto x_shifted =\n        (x_scaled + offset.reshape(one_by_depth).broadcast(bcast_spec))\n            .template cast<T>();\n\n    y.reshape(rest_by_depth).device(d) = x_shifted;\n    batch_mean.device(d) = estimated_mean;\n    batch_variance.device(d) = estimated_variance;\n\n    if (tensor_format == FORMAT_NCHW) {\n      // Perform NHWC to NCHW\n      const std::vector<int32> perm = {0, 3, 1, 2};\n      const Status s = ::tensorflow::DoTranspose(\n          context->eigen_device<CPUDevice>(), transformed_y, perm, y_output);\n      if (!s.ok()) {\n        context->SetStatus(errors::InvalidArgument(\"Transpose failed: \", s));\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -63,6 +63,9 @@\n     const CPUDevice& d = context->eigen_device<CPUDevice>();\n \n     const int depth = x.dimension(3);\n+    OP_REQUIRES(\n+        context, depth != 0,\n+        errors::Internal(\"The 4th element in the input shape cannot be 0.\"));\n     const int size = x.size();\n     const int rest_size = size / depth;\n     Eigen::DSizes<Eigen::Index, 2> rest_by_depth(rest_size, depth);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    OP_REQUIRES(",
                "        context, depth != 0,",
                "        errors::Internal(\"The 4th element in the input shape cannot be 0.\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29557",
        "func_name": "tensorflow/Compute",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a denial of service via a FPE runtime error in `tf.raw_ops.SparseMatMul`. The division by 0 occurs deep in Eigen code because the `b` tensor is empty. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/7f283ff806b2031f407db64c4d3edcda8fb9f9f5",
        "commit_title": "Fix FPE issue in external Eigen source code issue with `tf.raw_ops.SparseMatMul`.",
        "commit_text": " PiperOrigin-RevId: 370992919",
        "func_before": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& a = ctx->input(0);\n    const Tensor& b = ctx->input(1);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(a.shape()),\n                errors::InvalidArgument(\"a is not a matrix\"));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(b.shape()),\n                errors::InvalidArgument(\"b is not a matrix\"));\n\n    const int m = transpose_a_ ? a.dim_size(1) : a.dim_size(0);\n    const int k = transpose_a_ ? a.dim_size(0) : a.dim_size(1);\n    const int n = transpose_b_ ? b.dim_size(0) : b.dim_size(1);\n    const int k2 = transpose_b_ ? b.dim_size(1) : b.dim_size(0);\n\n    OP_REQUIRES(ctx, k == k2,\n                errors::InvalidArgument(\n                    \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                    \", b: \", b.shape().DebugString()));\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n\n    if (k == 0) {\n      // If the inner dimension k in the matrix multiplication is zero, we fill\n      // the output with zeros.\n      functor::SetZeroFunctor<CPUDevice, float> f;\n      f(ctx->eigen_device<CPUDevice>(), output->flat<float>());\n      return;\n    }\n\n    auto out = output->matrix<float>();\n\n    std::unique_ptr<Tensor> a_float;\n    std::unique_ptr<Tensor> b_float;\n    if (!a_is_sparse_ && !b_is_sparse_) {\n      auto left = &a;\n      auto right = &b;\n      // TODO(agarwal): multi-thread the conversions from bfloat16 to float.\n      if (std::is_same<TL, bfloat16>::value) {\n        a_float.reset(new Tensor(DT_FLOAT, a.shape()));\n        BFloat16ToFloat(a.flat<bfloat16>().data(),\n                        a_float->flat<float>().data(), a.NumElements());\n        left = a_float.get();\n      }\n      if (std::is_same<TR, bfloat16>::value) {\n        b_float.reset(new Tensor(DT_FLOAT, b.shape()));\n        BFloat16ToFloat(b.flat<bfloat16>().data(),\n                        b_float->flat<float>().data(), b.NumElements());\n        right = b_float.get();\n      }\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0].first = transpose_a_ ? 0 : 1;\n      dim_pair[0].second = transpose_b_ ? 1 : 0;\n\n      out.device(ctx->template eigen_device<CPUDevice>()) =\n          left->matrix<float>().contract(right->matrix<float>(), dim_pair);\n      return;\n    }\n\n    auto left = &a;\n    auto right = &b;\n    bool transpose_output = false;\n    bool transpose_a = transpose_a_;\n    bool transpose_b = transpose_b_;\n    if (!a_is_sparse_) {\n      // Swap the order of multiplications using the identity:\n      // A * B = (B' *  A')'.\n      std::swap(left, right);\n      std::swap(transpose_a, transpose_b);\n      transpose_a = !transpose_a;\n      transpose_b = !transpose_b;\n      transpose_output = !transpose_output;\n    }\n\n    std::unique_ptr<Tensor> right_tr;\n    if (transpose_b) {\n      // TODO(agarwal): avoid transposing the matrix here and directly handle\n      // transpose in CreateDenseSlices.\n      right_tr.reset(\n          new Tensor(right->dtype(),\n                     TensorShape({right->dim_size(1), right->dim_size(0)})));\n\n      const auto perm = dsizes_10();\n      if (transpose_output) {\n        right_tr->matrix<TL>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TL>().shuffle(perm);\n      } else {\n        right_tr->matrix<TR>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TR>().shuffle(perm);\n      }\n      right = right_tr.get();\n    }\n\n    if (transpose_output) {\n      DoMatMul<TR, TL>::Compute(&this->cache_tr_, left->matrix<TR>(),\n                                right->matrix<TL>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    } else {\n      DoMatMul<TL, TR>::Compute(&this->cache_nt_, left->matrix<TL>(),\n                                right->matrix<TR>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    }\n  }",
        "func": "void Compute(OpKernelContext* ctx) override {\n    const Tensor& a = ctx->input(0);\n    const Tensor& b = ctx->input(1);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(a.shape()),\n                errors::InvalidArgument(\"a is not a matrix\"));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(b.shape()),\n                errors::InvalidArgument(\"b is not a matrix\"));\n\n    const int m = transpose_a_ ? a.dim_size(1) : a.dim_size(0);\n    const int k = transpose_a_ ? a.dim_size(0) : a.dim_size(1);\n    const int n = transpose_b_ ? b.dim_size(0) : b.dim_size(1);\n    const int k2 = transpose_b_ ? b.dim_size(1) : b.dim_size(0);\n\n    OP_REQUIRES(ctx, k == k2,\n                errors::InvalidArgument(\n                    \"Matrix size incompatible: a: \", a.shape().DebugString(),\n                    \", b: \", b.shape().DebugString()));\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({m, n}), &output));\n\n    if (k == 0) {\n      // If the inner dimension k in the matrix multiplication is zero, we fill\n      // the output with zeros.\n      functor::SetZeroFunctor<CPUDevice, float> f;\n      f(ctx->eigen_device<CPUDevice>(), output->flat<float>());\n      return;\n    }\n\n    auto out = output->matrix<float>();\n\n    std::unique_ptr<Tensor> a_float;\n    std::unique_ptr<Tensor> b_float;\n    if (!a_is_sparse_ && !b_is_sparse_) {\n      auto left = &a;\n      auto right = &b;\n      // TODO(agarwal): multi-thread the conversions from bfloat16 to float.\n      if (std::is_same<TL, bfloat16>::value) {\n        a_float.reset(new Tensor(DT_FLOAT, a.shape()));\n        BFloat16ToFloat(a.flat<bfloat16>().data(),\n                        a_float->flat<float>().data(), a.NumElements());\n        left = a_float.get();\n      }\n      if (std::is_same<TR, bfloat16>::value) {\n        b_float.reset(new Tensor(DT_FLOAT, b.shape()));\n        BFloat16ToFloat(b.flat<bfloat16>().data(),\n                        b_float->flat<float>().data(), b.NumElements());\n        right = b_float.get();\n      }\n      Eigen::array<Eigen::IndexPair<Eigen::DenseIndex>, 1> dim_pair;\n      dim_pair[0].first = transpose_a_ ? 0 : 1;\n      dim_pair[0].second = transpose_b_ ? 1 : 0;\n\n      out.device(ctx->template eigen_device<CPUDevice>()) =\n          left->matrix<float>().contract(right->matrix<float>(), dim_pair);\n      return;\n    }\n\n    auto left = &a;\n    auto right = &b;\n    bool transpose_output = false;\n    bool transpose_a = transpose_a_;\n    bool transpose_b = transpose_b_;\n    if (!a_is_sparse_) {\n      // Swap the order of multiplications using the identity:\n      // A * B = (B' *  A')'.\n      std::swap(left, right);\n      std::swap(transpose_a, transpose_b);\n      transpose_a = !transpose_a;\n      transpose_b = !transpose_b;\n      transpose_output = !transpose_output;\n    }\n\n    std::unique_ptr<Tensor> right_tr;\n    if (transpose_b) {\n      // TODO(agarwal): avoid transposing the matrix here and directly handle\n      // transpose in CreateDenseSlices.\n      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n      right_tr.reset(\n          new Tensor(right->dtype(),\n                     TensorShape({right->dim_size(1), right->dim_size(0)})));\n\n      const auto perm = dsizes_10();\n      if (transpose_output) {\n        right_tr->matrix<TL>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TL>().shuffle(perm);\n      } else {\n        right_tr->matrix<TR>().device(ctx->template eigen_device<CPUDevice>()) =\n            right->matrix<TR>().shuffle(perm);\n      }\n      right = right_tr.get();\n    }\n\n    if (transpose_output) {\n      DoMatMul<TR, TL>::Compute(&this->cache_tr_, left->matrix<TR>(),\n                                right->matrix<TL>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    } else {\n      DoMatMul<TL, TR>::Compute(&this->cache_nt_, left->matrix<TL>(),\n                                right->matrix<TR>(), transpose_a,\n                                ctx->device()->tensorflow_cpu_worker_threads(),\n                                transpose_output, &out);\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -74,6 +74,10 @@\n     if (transpose_b) {\n       // TODO(agarwal): avoid transposing the matrix here and directly handle\n       // transpose in CreateDenseSlices.\n+      OP_REQUIRES(ctx, right->dim_size(0) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n+      OP_REQUIRES(ctx, right->dim_size(1) != 0,\n+                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));\n       right_tr.reset(\n           new Tensor(right->dtype(),\n                      TensorShape({right->dim_size(1), right->dim_size(0)})));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      OP_REQUIRES(ctx, right->dim_size(0) != 0,",
                "                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));",
                "      OP_REQUIRES(ctx, right->dim_size(1) != 0,",
                "                  errors::InvalidArgument(\"b has an entry 0 in it's shape.\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29585",
        "func_name": "tensorflow/ComputeOutSize",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The TFLite computation for size of output after padding, `ComputeOutSize`(https://github.com/tensorflow/tensorflow/blob/0c9692ae7b1671c983569e5d3de5565843d500cf/tensorflow/lite/kernels/padding.h#L43-L55), does not check that the `stride` argument is not 0 before doing the division. Users can craft special models such that `ComputeOutSize` is called with `stride` set to 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/49847ae69a4e1a97ae7f2db5e217c77721e37948",
        "commit_title": "Fix division by zero in TFLite padding.",
        "commit_text": " PiperOrigin-RevId: 370777494",
        "func_before": "inline int ComputeOutSize(TfLitePadding padding, int image_size,\n                          int filter_size, int stride, int dilation_rate = 1) {\n  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;\n  switch (padding) {\n    case kTfLitePaddingSame:\n      return (image_size + stride - 1) / stride;\n    case kTfLitePaddingValid:\n      return (image_size + stride - effective_filter_size) / stride;\n    default:\n      return 0;\n  }\n}",
        "func": "inline int ComputeOutSize(TfLitePadding padding, int image_size,\n                          int filter_size, int stride, int dilation_rate = 1) {\n  int effective_filter_size = (filter_size - 1) * dilation_rate + 1;\n\n  // TODO(b/186448822): This uses 0 since the function has no other way to\n  // report error case\n  if (stride == 0) return 0;\n\n  switch (padding) {\n    case kTfLitePaddingSame:\n      return (image_size + stride - 1) / stride;\n    case kTfLitePaddingValid:\n      return (image_size + stride - effective_filter_size) / stride;\n    default:\n      return 0;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,11 @@\n inline int ComputeOutSize(TfLitePadding padding, int image_size,\n                           int filter_size, int stride, int dilation_rate = 1) {\n   int effective_filter_size = (filter_size - 1) * dilation_rate + 1;\n+\n+  // TODO(b/186448822): This uses 0 since the function has no other way to\n+  // report error case\n+  if (stride == 0) return 0;\n+\n   switch (padding) {\n     case kTfLitePaddingSame:\n       return (image_size + stride - 1) / stride;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  // TODO(b/186448822): This uses 0 since the function has no other way to",
                "  // report error case",
                "  if (stride == 0) return 0;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29586",
        "func_name": "tensorflow/GenericPrepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. Optimized pooling implementations in TFLite fail to check that the stride arguments are not 0 before calling `ComputePaddingHeightWidth`(https://github.com/tensorflow/tensorflow/blob/3f24ccd932546416ec906a02ddd183b48a1d2c83/tensorflow/lite/kernels/pooling.cc#L90). Since users can craft special models which will have `params->stride_{height,width}` be zero, this will result in a division by zero. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/5f7975d09eac0f10ed8a17dbb6f5964977725adc",
        "commit_title": "Prevent another div by 0 in optimized pooling implementations TFLite",
        "commit_text": " PiperOrigin-RevId: 370800091",
        "func_before": "TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  int batches = input->dims->data[0];\n  int height = input->dims->data[1];\n  int width = input->dims->data[2];\n  int channels_out = input->dims->data[3];\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width, 1, 1, height, width,\n      params->filter_height, params->filter_width, padding, &out_height,\n      &out_width);\n\n  if (input->type == kTfLiteUInt8 || input->type == kTfLiteInt8) {\n    if (pool_type == kAverage || pool_type == kMax) {\n      TFLITE_DCHECK_LE(std::abs(input->params.scale - output->params.scale),\n                       1.0e-6);\n      TFLITE_DCHECK_EQ(input->params.zero_point, output->params.zero_point);\n    }\n    if (pool_type == kL2) {\n      // We currently don't have a quantized implementation of L2Pool\n      TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n    }\n  }\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = batches;\n  output_size->data[1] = out_height;\n  output_size->data[2] = out_width;\n  output_size->data[3] = channels_out;\n  return context->ResizeTensor(context, output, output_size);\n}",
        "func": "TfLiteStatus GenericPrepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLitePoolParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  int batches = input->dims->data[0];\n  int height = input->dims->data[1];\n  int width = input->dims->data[2];\n  int channels_out = input->dims->data[3];\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n\n  // Prevent division by 0 in optimized pooling implementations\n  TF_LITE_ENSURE(context, params->stride_height > 0);\n  TF_LITE_ENSURE(context, params->stride_width > 0);\n\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width, 1, 1, height, width,\n      params->filter_height, params->filter_width, padding, &out_height,\n      &out_width);\n\n  if (input->type == kTfLiteUInt8 || input->type == kTfLiteInt8) {\n    if (pool_type == kAverage || pool_type == kMax) {\n      TFLITE_DCHECK_LE(std::abs(input->params.scale - output->params.scale),\n                       1.0e-6);\n      TFLITE_DCHECK_EQ(input->params.zero_point, output->params.zero_point);\n    }\n    if (pool_type == kL2) {\n      // We currently don't have a quantized implementation of L2Pool\n      TF_LITE_ENSURE_TYPES_EQ(context, input->type, kTfLiteFloat32);\n    }\n  }\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = batches;\n  output_size->data[1] = out_height;\n  output_size->data[2] = out_width;\n  output_size->data[3] = channels_out;\n  return context->ResizeTensor(context, output, output_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,10 @@\n   // Matching GetWindowedOutputSize in TensorFlow.\n   auto padding = params->padding;\n   int out_width, out_height;\n+\n+  // Prevent division by 0 in optimized pooling implementations\n+  TF_LITE_ENSURE(context, params->stride_height > 0);\n+  TF_LITE_ENSURE(context, params->stride_width > 0);\n \n   data->padding = ComputePaddingHeightWidth(\n       params->stride_height, params->stride_width, 1, 1, height, width,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  // Prevent division by 0 in optimized pooling implementations",
                "  TF_LITE_ENSURE(context, params->stride_height > 0);",
                "  TF_LITE_ENSURE(context, params->stride_width > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29587",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The `Prepare` step of the `SpaceToDepth` TFLite operator does not check for 0 before division(https://github.com/tensorflow/tensorflow/blob/5f7975d09eac0f10ed8a17dbb6f5964977725adc/tensorflow/lite/kernels/space_to_depth.cc#L63-L67). An attacker can craft a model such that `params->block_size` would be zero. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7",
        "commit_title": "Prevent one more div by 0 in TFLite",
        "commit_text": " PiperOrigin-RevId: 370800114",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteSpaceToDepthParams*>(node->builtin_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n\n  auto data_type = output->type;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt32 ||\n                     data_type == kTfLiteInt64);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  const int block_size = params->block_size;\n  const int input_height = input->dims->data[1];\n  const int input_width = input->dims->data[2];\n  int output_height = input_height / block_size;\n  int output_width = input_width / block_size;\n\n  TF_LITE_ENSURE_EQ(context, input_height, output_height * block_size);\n  TF_LITE_ENSURE_EQ(context, input_width, output_width * block_size);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = input->dims->data[0];\n  output_size->data[1] = output_height;\n  output_size->data[2] = output_width;\n  output_size->data[3] = input->dims->data[3] * block_size * block_size;\n\n  return context->ResizeTensor(context, output, output_size);\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteSpaceToDepthParams*>(node->builtin_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n\n  auto data_type = output->type;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt32 ||\n                     data_type == kTfLiteInt64);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  const int block_size = params->block_size;\n  TF_LITE_ENSURE(context, block_size > 0);\n  const int input_height = input->dims->data[1];\n  const int input_width = input->dims->data[2];\n  int output_height = input_height / block_size;\n  int output_width = input_width / block_size;\n\n  TF_LITE_ENSURE_EQ(context, input_height, output_height * block_size);\n  TF_LITE_ENSURE_EQ(context, input_width, output_width * block_size);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = input->dims->data[0];\n  output_size->data[1] = output_height;\n  output_size->data[2] = output_width;\n  output_size->data[3] = input->dims->data[3] * block_size * block_size;\n\n  return context->ResizeTensor(context, output, output_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,7 @@\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   const int block_size = params->block_size;\n+  TF_LITE_ENSURE(context, block_size > 0);\n   const int input_height = input->dims->data[1];\n   const int input_width = input->dims->data[2];\n   int output_height = input_height / block_size;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, block_size > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29588",
        "func_name": "tensorflow/Eval",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The optimized implementation of the `TransposeConv` TFLite operator is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/internal/optimized/optimized_ops.h#L5221-L5222). An attacker can craft a model such that `stride_{h,w}` values are 0. Code calling this function must validate these arguments. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/801c1c6be5324219689c98e1bd3e0ca365ee834d",
        "commit_title": "Fix another division by 0 in TFLite",
        "commit_text": " PiperOrigin-RevId: 370800181",
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  // Retrieve tensors (All should be allocated by now)\n  const TfLiteTensor* output_shape;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n  const TfLiteTensor* weights;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kWeightsTensor, &weights));\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kDataInputTensor, &input));\n  const TfLiteTensor* bias =\n      (NumInputs(node) == 4)\n          ? GetOptionalInputTensor(context, node, kBiasTensor)\n          : nullptr;\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n  TfLiteTensor* col2im = data->has_col2im\n                             ? GetTemporary(context, node, data->col2im_index)\n                             : nullptr;\n  TfLiteTensor* transposed_weights =\n      data->weights_are_transposed\n          ? GetTemporary(context, node, data->transposed_weights_index)\n          : nullptr;\n  const auto* params =\n      reinterpret_cast<TfLiteTransposeConvParams*>(node->builtin_data);\n\n  // Resize any deferred dynamic tensors\n  if (IsDynamicTensor(output)) {\n    TF_LITE_ENSURE_OK(context, ResizeTensor(context, output_shape, output));\n  }\n  if (data->has_col2im && IsDynamicTensor(col2im)) {\n    TF_LITE_ENSURE_OK(context, ResizeCol2ImTensor(context, output_shape,\n                                                  weights, input, col2im));\n  }\n\n  // Get height and width of the output image.\n  const int width = SizeOfDimension(output, 2);\n  const int height = SizeOfDimension(output, 1);\n  const int filter_width = SizeOfDimension(weights, 2);\n  const int filter_height = SizeOfDimension(weights, 1);\n\n  int unused_output_height, unused_output_width;\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width, 1, 1, height, width,\n      filter_height, filter_width, params->padding, &unused_output_height,\n      &unused_output_width);\n\n  // Currently support float32, uint8, int8, int16.\n  switch (input->type) {\n    case kTfLiteFloat32: {\n      // Only for GenericOptimized path, we use transposed weights.\n      if (data->weights_are_transposed) {\n        if (!IsConstantTensor(weights)) {\n          ResizeAndTransposeWeights(context, weights, transposed_weights);\n        }\n      }\n      EvalFloat<kernel_type>(context, params, data, input, weights, bias,\n                             transposed_weights, col2im, output);\n      break;\n    }\n    case kTfLiteUInt8: {\n      TfLiteTensor* scratch_buffer;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n                                    &scratch_buffer));\n      if (IsDynamicTensor(scratch_buffer)) {\n        TF_LITE_ENSURE_OK(context,\n                          ResizeTensor(context, output_shape, scratch_buffer));\n      }\n      if (data->weights_are_transposed) {\n        if (!IsConstantTensor(weights)) {\n          ResizeAndTransposeWeights(context, weights, transposed_weights);\n        }\n      }\n      EvalQuantized<kernel_type>(context, params, data, input, weights,\n                                 transposed_weights, bias, col2im, output,\n                                 scratch_buffer);\n      break;\n    }\n    case kTfLiteInt8: {\n      TfLiteTensor* scratch_buffer;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n                                    &scratch_buffer));\n      if (IsDynamicTensor(scratch_buffer)) {\n        TF_LITE_ENSURE_OK(context,\n                          ResizeTensor(context, output_shape, scratch_buffer));\n      }\n      if (data->weights_are_transposed && !IsConstantTensor(weights)) {\n        ResizeAndTransposeWeights(context, weights, transposed_weights);\n      }\n      EvalQuantizedPerChannel<kernel_type>(context, params, data, input,\n                                           weights, transposed_weights, bias,\n                                           col2im, output, scratch_buffer);\n      break;\n    }\n    case kTfLiteInt16: {\n      TfLiteTensor* scratch_buffer;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n                                    &scratch_buffer));\n      if (IsDynamicTensor(scratch_buffer)) {\n        TF_LITE_ENSURE_OK(context,\n                          ResizeTensor(context, output_shape, scratch_buffer));\n      }\n      if (data->weights_are_transposed && !IsConstantTensor(weights)) {\n        ResizeAndTransposeWeights(context, weights, transposed_weights);\n      }\n      EvalQuantizedPerChannel16x8(context, params, data, input, weights,\n                                  transposed_weights, bias, col2im, output,\n                                  scratch_buffer);\n      break;\n    }\n    default:\n      context->ReportError(context, \"Type '%s' is not currently supported.\",\n                           TfLiteTypeGetName(input->type));\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  // Retrieve tensors (All should be allocated by now)\n  const TfLiteTensor* output_shape;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kOutputShapeTensor, &output_shape));\n  const TfLiteTensor* weights;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kWeightsTensor, &weights));\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context,\n                    GetInputSafe(context, node, kDataInputTensor, &input));\n  const TfLiteTensor* bias =\n      (NumInputs(node) == 4)\n          ? GetOptionalInputTensor(context, node, kBiasTensor)\n          : nullptr;\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n  TfLiteTensor* col2im = data->has_col2im\n                             ? GetTemporary(context, node, data->col2im_index)\n                             : nullptr;\n  TfLiteTensor* transposed_weights =\n      data->weights_are_transposed\n          ? GetTemporary(context, node, data->transposed_weights_index)\n          : nullptr;\n  const auto* params =\n      reinterpret_cast<TfLiteTransposeConvParams*>(node->builtin_data);\n\n  // Prevent divisions by 0\n  TF_LITE_ENSURE(context, params->stride_height > 0);\n  TF_LITE_ENSURE(context, params->stride_width > 0);\n\n  // Resize any deferred dynamic tensors\n  if (IsDynamicTensor(output)) {\n    TF_LITE_ENSURE_OK(context, ResizeTensor(context, output_shape, output));\n  }\n  if (data->has_col2im && IsDynamicTensor(col2im)) {\n    TF_LITE_ENSURE_OK(context, ResizeCol2ImTensor(context, output_shape,\n                                                  weights, input, col2im));\n  }\n\n  // Get height and width of the output image.\n  const int width = SizeOfDimension(output, 2);\n  const int height = SizeOfDimension(output, 1);\n  const int filter_width = SizeOfDimension(weights, 2);\n  const int filter_height = SizeOfDimension(weights, 1);\n\n  int unused_output_height, unused_output_width;\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width, 1, 1, height, width,\n      filter_height, filter_width, params->padding, &unused_output_height,\n      &unused_output_width);\n\n  // Currently support float32, uint8, int8, int16.\n  switch (input->type) {\n    case kTfLiteFloat32: {\n      // Only for GenericOptimized path, we use transposed weights.\n      if (data->weights_are_transposed) {\n        if (!IsConstantTensor(weights)) {\n          ResizeAndTransposeWeights(context, weights, transposed_weights);\n        }\n      }\n      EvalFloat<kernel_type>(context, params, data, input, weights, bias,\n                             transposed_weights, col2im, output);\n      break;\n    }\n    case kTfLiteUInt8: {\n      TfLiteTensor* scratch_buffer;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n                                    &scratch_buffer));\n      if (IsDynamicTensor(scratch_buffer)) {\n        TF_LITE_ENSURE_OK(context,\n                          ResizeTensor(context, output_shape, scratch_buffer));\n      }\n      if (data->weights_are_transposed) {\n        if (!IsConstantTensor(weights)) {\n          ResizeAndTransposeWeights(context, weights, transposed_weights);\n        }\n      }\n      EvalQuantized<kernel_type>(context, params, data, input, weights,\n                                 transposed_weights, bias, col2im, output,\n                                 scratch_buffer);\n      break;\n    }\n    case kTfLiteInt8: {\n      TfLiteTensor* scratch_buffer;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n                                    &scratch_buffer));\n      if (IsDynamicTensor(scratch_buffer)) {\n        TF_LITE_ENSURE_OK(context,\n                          ResizeTensor(context, output_shape, scratch_buffer));\n      }\n      if (data->weights_are_transposed && !IsConstantTensor(weights)) {\n        ResizeAndTransposeWeights(context, weights, transposed_weights);\n      }\n      EvalQuantizedPerChannel<kernel_type>(context, params, data, input,\n                                           weights, transposed_weights, bias,\n                                           col2im, output, scratch_buffer);\n      break;\n    }\n    case kTfLiteInt16: {\n      TfLiteTensor* scratch_buffer;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->scratch_tensor_index,\n                                    &scratch_buffer));\n      if (IsDynamicTensor(scratch_buffer)) {\n        TF_LITE_ENSURE_OK(context,\n                          ResizeTensor(context, output_shape, scratch_buffer));\n      }\n      if (data->weights_are_transposed && !IsConstantTensor(weights)) {\n        ResizeAndTransposeWeights(context, weights, transposed_weights);\n      }\n      EvalQuantizedPerChannel16x8(context, params, data, input, weights,\n                                  transposed_weights, bias, col2im, output,\n                                  scratch_buffer);\n      break;\n    }\n    default:\n      context->ReportError(context, \"Type '%s' is not currently supported.\",\n                           TfLiteTypeGetName(input->type));\n      return kTfLiteError;\n  }\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,6 +26,10 @@\n           : nullptr;\n   const auto* params =\n       reinterpret_cast<TfLiteTransposeConvParams*>(node->builtin_data);\n+\n+  // Prevent divisions by 0\n+  TF_LITE_ENSURE(context, params->stride_height > 0);\n+  TF_LITE_ENSURE(context, params->stride_width > 0);\n \n   // Resize any deferred dynamic tensors\n   if (IsDynamicTensor(output)) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  // Prevent divisions by 0",
                "  TF_LITE_ENSURE(context, params->stride_height > 0);",
                "  TF_LITE_ENSURE(context, params->stride_width > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29589",
        "func_name": "tensorflow/Eval",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The reference implementation of the `GatherNd` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/internal/reference/reference_ops.h#L966). An attacker can craft a model such that `params` input would be an empty tensor. In turn, `params_shape.Dims(.)` would be zero, in at least one dimension. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/8e45822aa0b9f5df4b4c64f221e64dc930a70a9d",
        "commit_title": "Handle one more division by 0 in TFLite.",
        "commit_text": " PiperOrigin-RevId: 370800140",
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* params;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n  const TfLiteTensor* indices;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  switch (indices->type) {\n    case kTfLiteInt32:\n      return EvalGatherNd<int32_t>(context, params, indices, output);\n    case kTfLiteInt64:\n      return EvalGatherNd<int64_t>(context, params, indices, output);\n    default:\n      context->ReportError(\n          context, \"Indices of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n}",
        "func": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteTensor* params;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kParams, &params));\n  const TfLiteTensor* indices;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kIndices, &indices));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Prevent division by 0 in the helper\n  TF_LITE_ENSURE(context, NumElements(params) > 0);\n\n  switch (indices->type) {\n    case kTfLiteInt32:\n      return EvalGatherNd<int32_t>(context, params, indices, output);\n    case kTfLiteInt64:\n      return EvalGatherNd<int64_t>(context, params, indices, output);\n    default:\n      context->ReportError(\n          context, \"Indices of type '%s' are not supported by gather_nd.\",\n          TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,9 @@\n   TfLiteTensor* output;\n   TF_LITE_ENSURE_OK(context,\n                     GetOutputSafe(context, node, kOutputTensor, &output));\n+\n+  // Prevent division by 0 in the helper\n+  TF_LITE_ENSURE(context, NumElements(params) > 0);\n \n   switch (indices->type) {\n     case kTfLiteInt32:",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  // Prevent division by 0 in the helper",
                "  TF_LITE_ENSURE(context, NumElements(params) > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29593",
        "func_name": "tensorflow/ResizeOutputTensor",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `BatchToSpaceNd` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/b5ed552fe55895aee8bd8b191f744a069957d18d/tensorflow/lite/kernels/batch_to_space_nd.cc#L81-L82). An attacker can craft a model such that one dimension of the `block` input is 0. Hence, the corresponding value in `block_shape` is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/2c74674348a4708ced58ad6eb1b23354df8ee044",
        "commit_title": "Prevent division by 0",
        "commit_text": " PiperOrigin-RevId: 370979352",
        "func_before": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                BatchToSpaceNDContext* op_context) {\n  TfLiteIntArray* input_size = op_context->input->dims;\n  const int* block_shape = GetTensorData<int32>(op_context->block_shape);\n  const int* crops = GetTensorData<int32>(op_context->crops);\n\n  int spatial_dims_num = input_size->size - 2;\n  // Block_shape should be a 1D tensor with dimension [spatial_dims_num].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->block_shape), 1);\n  TF_LITE_ENSURE_EQ(context, op_context->block_shape->dims->data[0],\n                    spatial_dims_num);\n  // Crops should be a 2D tensor with dimension [spatial_dims_num, 2].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->crops), 2);\n  TF_LITE_ENSURE_EQ(context, op_context->crops->dims->data[0],\n                    spatial_dims_num);\n  TF_LITE_ENSURE_EQ(context, op_context->crops->dims->data[1], 2);\n\n  for (int i = 0; i < spatial_dims_num * 2; ++i) {\n    TF_LITE_ENSURE(context, crops[i] >= 0);\n  }\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCopy(input_size);\n  int output_batch_size = input_size->data[0];\n  for (int dim = 0; dim < spatial_dims_num; ++dim) {\n    // Number of batch must be multiple of (block_shape[dim]).\n    TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\n    output_batch_size = output_batch_size / block_shape[dim];\n    output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -\n                                 crops[dim * 2] - crops[dim * 2 + 1];\n  }\n\n  output_size->data[0] = output_batch_size;\n  output_size->data[input_size->size - 1] =\n      input_size->data[input_size->size - 1];\n\n  return context->ResizeTensor(context, op_context->output, output_size);\n}",
        "func": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                BatchToSpaceNDContext* op_context) {\n  TfLiteIntArray* input_size = op_context->input->dims;\n  const int* block_shape = GetTensorData<int32>(op_context->block_shape);\n  const int* crops = GetTensorData<int32>(op_context->crops);\n\n  int spatial_dims_num = input_size->size - 2;\n  // Block_shape should be a 1D tensor with dimension [spatial_dims_num].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->block_shape), 1);\n  TF_LITE_ENSURE_EQ(context, op_context->block_shape->dims->data[0],\n                    spatial_dims_num);\n  // Crops should be a 2D tensor with dimension [spatial_dims_num, 2].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->crops), 2);\n  TF_LITE_ENSURE_EQ(context, op_context->crops->dims->data[0],\n                    spatial_dims_num);\n  TF_LITE_ENSURE_EQ(context, op_context->crops->dims->data[1], 2);\n\n  for (int i = 0; i < spatial_dims_num * 2; ++i) {\n    TF_LITE_ENSURE(context, crops[i] >= 0);\n  }\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCopy(input_size);\n  int output_batch_size = input_size->data[0];\n  for (int dim = 0; dim < spatial_dims_num; ++dim) {\n    // Number of batch must be multiple of (block_shape[dim]).\n    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n    TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\n    output_batch_size = output_batch_size / block_shape[dim];\n    output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -\n                                 crops[dim * 2] - crops[dim * 2 + 1];\n  }\n\n  output_size->data[0] = output_batch_size;\n  output_size->data[input_size->size - 1] =\n      input_size->data[input_size->size - 1];\n\n  return context->ResizeTensor(context, op_context->output, output_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,6 +23,7 @@\n   int output_batch_size = input_size->data[0];\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\n     // Number of batch must be multiple of (block_shape[dim]).\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n     TF_LITE_ENSURE_EQ(context, output_batch_size % block_shape[dim], 0);\n     output_batch_size = output_batch_size / block_shape[dim];\n     output_size->data[dim + 1] = input_size->data[dim + 1] * block_shape[dim] -",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    TF_LITE_ENSURE(context, block_shape[dim] != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29594",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. TFLite's convolution code(https://github.com/tensorflow/tensorflow/blob/09c73bca7d648e961dd05898292d91a8322a9d45/tensorflow/lite/kernels/conv.cc) has multiple division where the divisor is controlled by the user and not checked to be non-zero. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ff489d95a9006be080ad14feb378f2b4dac35552",
        "commit_title": "Prevent division by 0.",
        "commit_text": " PiperOrigin-RevId: 370962554",
        "func_before": "TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n                     TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteConvParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  bool has_bias = node->inputs->size == 3;\n  // Check number of inputs/outputs\n  TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));\n\n  // Check dimensionality of input, filter\n  TF_LITE_ENSURE_EQ(context, input->dims->size, 4);\n  TF_LITE_ENSURE_EQ(context, filter->dims->size, 4);\n  // Check input channels matching filter\n  TF_LITE_ENSURE_EQ(context, input->dims->data[3], filter->dims->data[3]);\n\n  // Check types. (We assume that UINT8 refers to quantized tensors)\n  TfLiteType input_type = input->type;\n  TF_LITE_ENSURE(context,\n                 input_type == kTfLiteFloat32 || input_type == kTfLiteUInt8 ||\n                     input_type == kTfLiteInt8 || input_type == kTfLiteInt16);\n  TF_LITE_ENSURE_TYPES_EQ(context, output->type, input_type);\n\n  if (input_type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  const TfLiteTensor* bias = nullptr;\n\n  // TODO(ahentz): At this point the optimized versions require 'bias'. We can\n  // either change that or document that convolution requires it.\n  TF_LITE_ENSURE(context, has_bias);\n\n  if (has_bias) {\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &bias));\n    if (input_type == kTfLiteUInt8 || input_type == kTfLiteInt8) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else if (input_type == kTfLiteInt16) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, input_type);\n    }\n    TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));\n  }\n\n  const bool is_hybrid =\n      (input->type == kTfLiteFloat32 &&\n       (filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8));\n\n  if (is_hybrid && filter->type == kTfLiteInt8 &&\n      filter->quantization.type == kTfLiteAffineQuantization &&\n      filter->quantization.params &&\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)\n          ->scale &&\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)\n              ->scale->size > 1) {\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    const float scale = affine_quantization->scale->data[0];\n    for (int i = 1; i < affine_quantization->scale->size; i++) {\n      if (affine_quantization->scale->data[i] != scale) {\n        data->is_hybrid_per_channel = true;\n        break;\n      }\n    }\n  }\n\n  // The multi-threaded kernel supports neither dilation nor hybrid kernels, and\n  // is incompatible with mutable input filters that might change between evals.\n  data->supports_multithreaded_kernel =\n      (kernel_type == kMultithreadOptimized) &&\n      (context->recommended_num_threads != 1) && !is_hybrid &&\n      (params->dilation_width_factor == 1) &&\n      (params->dilation_height_factor == 1) &&\n      (filter->allocation_type != kTfLiteArenaRw) && !IsDynamicTensor(filter);\n\n  int channels_in = filter->dims->data[3];\n  int channels_out = filter->dims->data[0];\n  int width = input->dims->data[2];\n  int height = input->dims->data[1];\n  int filter_width = filter->dims->data[2];\n  int filter_height = filter->dims->data[1];\n  int batches = input->dims->data[0];\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width,\n      params->dilation_height_factor, params->dilation_width_factor, height,\n      width, filter_height, filter_width, padding, &out_height, &out_width);\n\n  size_t im2col_type_size;\n  TF_LITE_ENSURE_STATUS(GetSizeOfType(context, input->type, &im2col_type_size));\n  const size_t im2col_bytes = batches * out_height * out_width * channels_in *\n                              filter_height * filter_width * im2col_type_size;\n  TF_LITE_ENSURE_STATUS(AllocateTemporaryTensorsIfRequired(\n      context, node, is_hybrid, data->is_hybrid_per_channel, kernel_type,\n      im2col_bytes));\n\n  TF_LITE_ENSURE(context, has_bias);\n\n  // Note that full fixed-point inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training or\n  // calibration.\n  if (input_type != kTfLiteFloat32) {\n    TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                      kTfLiteAffineQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||\n                             affine_quantization->scale->size == channels_out));\n\n    data->per_channel_output_multiplier.resize(channels_out);\n    data->per_channel_output_shift.resize(channels_out);\n    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(\n        context, input, filter, bias, output, params->activation,\n        &data->output_multiplier, &data->output_shift,\n        &data->output_activation_min, &data->output_activation_max,\n        data->per_channel_output_multiplier.data(),\n        data->per_channel_output_shift.data(), channels_out));\n  }\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = batches;\n  output_size->data[1] = out_height;\n  output_size->data[2] = out_width;\n  output_size->data[3] = channels_out;\n  auto output_status = context->ResizeTensor(context, output, output_size);\n\n  if (output_status != kTfLiteOk) return output_status;\n\n  if (data->need_im2col) {\n    node->temporaries->data[data->im2col_index] = data->im2col_id;\n\n    TfLiteIntArray* im2col_size = TfLiteIntArrayCreate(4);\n\n    int input_depth = input->dims->data[3];\n    im2col_size->data[0] = output_size->data[0];\n    im2col_size->data[1] = output_size->data[1];\n    im2col_size->data[2] = output_size->data[2];\n    im2col_size->data[3] = input_depth * filter_height * filter_width;\n\n    TfLiteTensor* im2col =\n        &context->tensors[node->temporaries->data[data->im2col_index]];\n    im2col->type = input->type;\n    if (is_hybrid) {\n      im2col->type = filter->type;\n    }\n    im2col->allocation_type = kTfLiteArenaRw;\n    auto im2col_status = context->ResizeTensor(context, im2col, im2col_size);\n    if (im2col_status != kTfLiteOk) return im2col_status;\n  }\n\n  if (data->need_hwcn_weights) {\n    node->temporaries->data[data->hwcn_weights_index] = data->hwcn_weights_id;\n    TfLiteIntArray* hwcn_weights_size = TfLiteIntArrayCreate(2);\n\n    // Because we're treating the filter weights as a matrix when we do the\n    // transpose, we allocate the buffer with a two-dimensional shape, where one\n    // dimension is the number of elements in each filter, and the second is the\n    // total number of filters.\n    int input_depth = input->dims->data[3];\n    hwcn_weights_size->data[0] = (filter_height * filter_width * input_depth);\n    hwcn_weights_size->data[1] = channels_out;\n\n    TfLiteTensor* hwcn_weights =\n        &context->tensors[node->temporaries->data[data->hwcn_weights_index]];\n    hwcn_weights->type = input_type;\n    hwcn_weights->allocation_type = kTfLiteArenaRwPersistent;\n\n    auto hwcn_weights_status =\n        context->ResizeTensor(context, hwcn_weights, hwcn_weights_size);\n    if (hwcn_weights_status != kTfLiteOk) return hwcn_weights_status;\n\n    // TODO(petewarden): If Resize() is called when the size hasn't actually\n    // changed, this will do extra redundant work.\n    data->have_weights_been_transposed = false;\n  }\n\n  if (is_hybrid) {\n    node->temporaries->data[data->input_quantized_index] =\n        data->input_quantized_id;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->input_quantized_index,\n                                  &input_quantized));\n    input_quantized->type = kTfLiteInt8;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    node->temporaries->data[data->scaling_factors_index] =\n        data->scaling_factors_id;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n                                  &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    // Only one scale factor per batch is typically necessary. See optimized\n    // implementation for why we need to allocate for the height of the inputs\n    // flattened to 2D.\n    const int height = NumElements(input) / channels_in;\n    int scaling_dims[1] = {height};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = height;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    node->temporaries->data[data->accum_scratch_index] = data->accum_scratch_id;\n    TfLiteTensor* accum_scratch;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, data->accum_scratch_index,\n                                       &accum_scratch));\n    accum_scratch->type = kTfLiteInt32;\n    accum_scratch->allocation_type = kTfLiteArenaRw;\n    const int scratch_width = batches * out_height * out_width;\n    int accum_scratch_dims[2] = {channels_out, scratch_width};\n    if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,\n                                   accum_scratch_dims)) {\n      TfLiteIntArray* accum_scratch_size = TfLiteIntArrayCreate(2);\n      accum_scratch_size->data[0] = channels_out;\n      accum_scratch_size->data[1] = scratch_width;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, accum_scratch,\n                                                       accum_scratch_size));\n    }\n\n    if (data->is_hybrid_per_channel) {\n      const auto* affine_quantization =\n          reinterpret_cast<TfLiteAffineQuantization*>(\n              filter->quantization.params);\n      TF_LITE_ENSURE_EQ(\n          context, affine_quantization->scale->size,\n          filter->dims->data[affine_quantization->quantized_dimension]);\n      node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n      TfLiteTensor* input_offsets;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->input_offset_index,\n                                    &input_offsets));\n      input_offsets->type = kTfLiteInt32;\n      input_offsets->allocation_type = kTfLiteArenaRw;\n      // See above comment for the need to allocate for height of inputs.\n      const int height = NumElements(input) / channels_in;\n      const int input_offset_dims[1] = {height};\n      if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1,\n                                     input_offset_dims)) {\n        TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n        input_offsets_size->data[0] = input_offset_dims[0];\n        TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                         input_offsets_size));\n      }\n      node->temporaries->data[data->row_sums_index] = data->row_sums_id;\n      TfLiteTensor* row_sums;\n      TF_LITE_ENSURE_OK(\n          context,\n          GetTemporarySafe(context, node, data->row_sums_index, &row_sums));\n      row_sums->type = kTfLiteInt32;\n      row_sums->allocation_type = kTfLiteArenaRwPersistent;\n      // See above comment for the need to allocate for height of inputs.\n      const int row_sums_dims[1] = {channels_out};\n      if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n        TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n        row_sums_size->data[0] = row_sums_dims[0];\n        TF_LITE_ENSURE_OK(\n            context, context->ResizeTensor(context, row_sums, row_sums_size));\n      }\n    }\n  }\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Prepare(KernelType kernel_type, TfLiteContext* context,\n                     TfLiteNode* node) {\n  auto* params = reinterpret_cast<TfLiteConvParams*>(node->builtin_data);\n  OpData* data = reinterpret_cast<OpData*>(node->user_data);\n\n  bool has_bias = node->inputs->size == 3;\n  // Check number of inputs/outputs\n  TF_LITE_ENSURE(context, has_bias || node->inputs->size == 2);\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &input));\n  const TfLiteTensor* filter;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &filter));\n\n  // Check dimensionality of input, filter\n  TF_LITE_ENSURE_EQ(context, input->dims->size, 4);\n  TF_LITE_ENSURE_EQ(context, filter->dims->size, 4);\n  // Check input channels matching filter\n  TF_LITE_ENSURE_EQ(context, input->dims->data[3], filter->dims->data[3]);\n\n  // Check types. (We assume that UINT8 refers to quantized tensors)\n  TfLiteType input_type = input->type;\n  TF_LITE_ENSURE(context,\n                 input_type == kTfLiteFloat32 || input_type == kTfLiteUInt8 ||\n                     input_type == kTfLiteInt8 || input_type == kTfLiteInt16);\n  TF_LITE_ENSURE_TYPES_EQ(context, output->type, input_type);\n\n  if (input_type == kTfLiteInt16) {\n    TF_LITE_ENSURE_EQ(context, input->params.zero_point, 0);\n    TF_LITE_ENSURE_EQ(context, output->params.zero_point, 0);\n  }\n\n  const TfLiteTensor* bias = nullptr;\n\n  // TODO(ahentz): At this point the optimized versions require 'bias'. We can\n  // either change that or document that convolution requires it.\n  TF_LITE_ENSURE(context, has_bias);\n\n  if (has_bias) {\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &bias));\n    if (input_type == kTfLiteUInt8 || input_type == kTfLiteInt8) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt32);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else if (input_type == kTfLiteInt16) {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, kTfLiteInt64);\n      TF_LITE_ENSURE_EQ(context, bias->params.zero_point, 0);\n    } else {\n      TF_LITE_ENSURE_TYPES_EQ(context, bias->type, input_type);\n    }\n    TF_LITE_ENSURE_EQ(context, NumElements(bias), SizeOfDimension(filter, 0));\n  }\n\n  const bool is_hybrid =\n      (input->type == kTfLiteFloat32 &&\n       (filter->type == kTfLiteUInt8 || filter->type == kTfLiteInt8));\n\n  if (is_hybrid && filter->type == kTfLiteInt8 &&\n      filter->quantization.type == kTfLiteAffineQuantization &&\n      filter->quantization.params &&\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)\n          ->scale &&\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params)\n              ->scale->size > 1) {\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    const float scale = affine_quantization->scale->data[0];\n    for (int i = 1; i < affine_quantization->scale->size; i++) {\n      if (affine_quantization->scale->data[i] != scale) {\n        data->is_hybrid_per_channel = true;\n        break;\n      }\n    }\n  }\n\n  // The multi-threaded kernel supports neither dilation nor hybrid kernels, and\n  // is incompatible with mutable input filters that might change between evals.\n  data->supports_multithreaded_kernel =\n      (kernel_type == kMultithreadOptimized) &&\n      (context->recommended_num_threads != 1) && !is_hybrid &&\n      (params->dilation_width_factor == 1) &&\n      (params->dilation_height_factor == 1) &&\n      (filter->allocation_type != kTfLiteArenaRw) && !IsDynamicTensor(filter);\n\n  int channels_in = filter->dims->data[3];\n  int channels_out = filter->dims->data[0];\n  int width = input->dims->data[2];\n  int height = input->dims->data[1];\n  int filter_width = filter->dims->data[2];\n  int filter_height = filter->dims->data[1];\n  int batches = input->dims->data[0];\n\n  // Matching GetWindowedOutputSize in TensorFlow.\n  auto padding = params->padding;\n  int out_width, out_height;\n  data->padding = ComputePaddingHeightWidth(\n      params->stride_height, params->stride_width,\n      params->dilation_height_factor, params->dilation_width_factor, height,\n      width, filter_height, filter_width, padding, &out_height, &out_width);\n\n  size_t im2col_type_size;\n  TF_LITE_ENSURE_STATUS(GetSizeOfType(context, input->type, &im2col_type_size));\n  const size_t im2col_bytes = batches * out_height * out_width * channels_in *\n                              filter_height * filter_width * im2col_type_size;\n  TF_LITE_ENSURE_STATUS(AllocateTemporaryTensorsIfRequired(\n      context, node, is_hybrid, data->is_hybrid_per_channel, kernel_type,\n      im2col_bytes));\n\n  TF_LITE_ENSURE(context, has_bias);\n\n  // Note that full fixed-point inference requires that all tensors have their\n  // parameters set. This is usually done during quantized training or\n  // calibration.\n  if (input_type != kTfLiteFloat32) {\n    TF_LITE_ENSURE_EQ(context, filter->quantization.type,\n                      kTfLiteAffineQuantization);\n    const auto* affine_quantization =\n        reinterpret_cast<TfLiteAffineQuantization*>(\n            filter->quantization.params);\n    TF_LITE_ENSURE(context, affine_quantization);\n    TF_LITE_ENSURE(context, affine_quantization->scale);\n    TF_LITE_ENSURE(context, (affine_quantization->scale->size == 1 ||\n                             affine_quantization->scale->size == channels_out));\n\n    data->per_channel_output_multiplier.resize(channels_out);\n    data->per_channel_output_shift.resize(channels_out);\n    TF_LITE_ENSURE_STATUS(tflite::PopulateConvolutionQuantizationParams(\n        context, input, filter, bias, output, params->activation,\n        &data->output_multiplier, &data->output_shift,\n        &data->output_activation_min, &data->output_activation_max,\n        data->per_channel_output_multiplier.data(),\n        data->per_channel_output_shift.data(), channels_out));\n  }\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = batches;\n  output_size->data[1] = out_height;\n  output_size->data[2] = out_width;\n  output_size->data[3] = channels_out;\n  auto output_status = context->ResizeTensor(context, output, output_size);\n\n  if (output_status != kTfLiteOk) return output_status;\n\n  if (data->need_im2col) {\n    node->temporaries->data[data->im2col_index] = data->im2col_id;\n\n    TfLiteIntArray* im2col_size = TfLiteIntArrayCreate(4);\n\n    int input_depth = input->dims->data[3];\n    im2col_size->data[0] = output_size->data[0];\n    im2col_size->data[1] = output_size->data[1];\n    im2col_size->data[2] = output_size->data[2];\n    im2col_size->data[3] = input_depth * filter_height * filter_width;\n\n    TfLiteTensor* im2col =\n        &context->tensors[node->temporaries->data[data->im2col_index]];\n    im2col->type = input->type;\n    if (is_hybrid) {\n      im2col->type = filter->type;\n    }\n    im2col->allocation_type = kTfLiteArenaRw;\n    auto im2col_status = context->ResizeTensor(context, im2col, im2col_size);\n    if (im2col_status != kTfLiteOk) return im2col_status;\n  }\n\n  if (data->need_hwcn_weights) {\n    node->temporaries->data[data->hwcn_weights_index] = data->hwcn_weights_id;\n    TfLiteIntArray* hwcn_weights_size = TfLiteIntArrayCreate(2);\n\n    // Because we're treating the filter weights as a matrix when we do the\n    // transpose, we allocate the buffer with a two-dimensional shape, where one\n    // dimension is the number of elements in each filter, and the second is the\n    // total number of filters.\n    int input_depth = input->dims->data[3];\n    hwcn_weights_size->data[0] = (filter_height * filter_width * input_depth);\n    hwcn_weights_size->data[1] = channels_out;\n\n    TfLiteTensor* hwcn_weights =\n        &context->tensors[node->temporaries->data[data->hwcn_weights_index]];\n    hwcn_weights->type = input_type;\n    hwcn_weights->allocation_type = kTfLiteArenaRwPersistent;\n\n    auto hwcn_weights_status =\n        context->ResizeTensor(context, hwcn_weights, hwcn_weights_size);\n    if (hwcn_weights_status != kTfLiteOk) return hwcn_weights_status;\n\n    // TODO(petewarden): If Resize() is called when the size hasn't actually\n    // changed, this will do extra redundant work.\n    data->have_weights_been_transposed = false;\n  }\n\n  if (is_hybrid) {\n    node->temporaries->data[data->input_quantized_index] =\n        data->input_quantized_id;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->input_quantized_index,\n                                  &input_quantized));\n    input_quantized->type = kTfLiteInt8;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    node->temporaries->data[data->scaling_factors_index] =\n        data->scaling_factors_id;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, data->scaling_factors_index,\n                                  &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    // Only one scale factor per batch is typically necessary. See optimized\n    // implementation for why we need to allocate for the height of the inputs\n    // flattened to 2D.\n    TF_LITE_ENSURE(context, channels_in != 0);\n    const int height = NumElements(input) / channels_in;\n    int scaling_dims[1] = {height};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = height;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    node->temporaries->data[data->accum_scratch_index] = data->accum_scratch_id;\n    TfLiteTensor* accum_scratch;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, data->accum_scratch_index,\n                                       &accum_scratch));\n    accum_scratch->type = kTfLiteInt32;\n    accum_scratch->allocation_type = kTfLiteArenaRw;\n    const int scratch_width = batches * out_height * out_width;\n    int accum_scratch_dims[2] = {channels_out, scratch_width};\n    if (!TfLiteIntArrayEqualsArray(accum_scratch->dims, 2,\n                                   accum_scratch_dims)) {\n      TfLiteIntArray* accum_scratch_size = TfLiteIntArrayCreate(2);\n      accum_scratch_size->data[0] = channels_out;\n      accum_scratch_size->data[1] = scratch_width;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, accum_scratch,\n                                                       accum_scratch_size));\n    }\n\n    if (data->is_hybrid_per_channel) {\n      const auto* affine_quantization =\n          reinterpret_cast<TfLiteAffineQuantization*>(\n              filter->quantization.params);\n      TF_LITE_ENSURE_EQ(\n          context, affine_quantization->scale->size,\n          filter->dims->data[affine_quantization->quantized_dimension]);\n      node->temporaries->data[data->input_offset_index] = data->input_offset_id;\n      TfLiteTensor* input_offsets;\n      TF_LITE_ENSURE_OK(\n          context, GetTemporarySafe(context, node, data->input_offset_index,\n                                    &input_offsets));\n      input_offsets->type = kTfLiteInt32;\n      input_offsets->allocation_type = kTfLiteArenaRw;\n      // See above comment for the need to allocate for height of inputs.\n      TF_LITE_ENSURE(context, channels_in != 0);\n      const int height = NumElements(input) / channels_in;\n      const int input_offset_dims[1] = {height};\n      if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1,\n                                     input_offset_dims)) {\n        TfLiteIntArray* input_offsets_size = TfLiteIntArrayCreate(1);\n        input_offsets_size->data[0] = input_offset_dims[0];\n        TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_offsets,\n                                                         input_offsets_size));\n      }\n      node->temporaries->data[data->row_sums_index] = data->row_sums_id;\n      TfLiteTensor* row_sums;\n      TF_LITE_ENSURE_OK(\n          context,\n          GetTemporarySafe(context, node, data->row_sums_index, &row_sums));\n      row_sums->type = kTfLiteInt32;\n      row_sums->allocation_type = kTfLiteArenaRwPersistent;\n      // See above comment for the need to allocate for height of inputs.\n      const int row_sums_dims[1] = {channels_out};\n      if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n        TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n        row_sums_size->data[0] = row_sums_dims[0];\n        TF_LITE_ENSURE_OK(\n            context, context->ResizeTensor(context, row_sums, row_sums_size));\n      }\n    }\n  }\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -217,6 +217,7 @@\n     // Only one scale factor per batch is typically necessary. See optimized\n     // implementation for why we need to allocate for the height of the inputs\n     // flattened to 2D.\n+    TF_LITE_ENSURE(context, channels_in != 0);\n     const int height = NumElements(input) / channels_in;\n     int scaling_dims[1] = {height};\n     if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n@@ -259,6 +260,7 @@\n       input_offsets->type = kTfLiteInt32;\n       input_offsets->allocation_type = kTfLiteArenaRw;\n       // See above comment for the need to allocate for height of inputs.\n+      TF_LITE_ENSURE(context, channels_in != 0);\n       const int height = NumElements(input) / channels_in;\n       const int input_offset_dims[1] = {height};\n       if (!TfLiteIntArrayEqualsArray(input_offsets->dims, 1,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    TF_LITE_ENSURE(context, channels_in != 0);",
                "      TF_LITE_ENSURE(context, channels_in != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29594",
        "func_name": "tensorflow/EvalHybridPerChannel",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. TFLite's convolution code(https://github.com/tensorflow/tensorflow/blob/09c73bca7d648e961dd05898292d91a8322a9d45/tensorflow/lite/kernels/conv.cc) has multiple division where the divisor is controlled by the user and not checked to be non-zero. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ff489d95a9006be080ad14feb378f2b4dac35552",
        "commit_title": "Prevent division by 0.",
        "commit_text": " PiperOrigin-RevId: 370962554",
        "func_before": "TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n                                  TfLiteConvParams* params, OpData* data,\n                                  const TfLiteTensor* input,\n                                  const TfLiteTensor* filter,\n                                  const TfLiteTensor* bias,\n                                  TfLiteTensor* im2col, TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n\n  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n  const int batch_size = SizeOfDimension(input, 0);\n  TfLiteTensor* quantized_input_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &quantized_input_tensor));\n  int8_t* quantized_input_ptr_batch =\n      GetTensorData<int8_t>(quantized_input_tensor);\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n  TfLiteTensor* input_offset_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_offset_index,\n                                     &input_offset_tensor));\n  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n\n  for (int b = 0; b < batch_size; ++b) {\n    const int offset = b * input_size;\n    tensor_utils::AsymmetricQuantizeFloats(\n        GetTensorData<float>(input) + offset, input_size,\n        quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],\n        &input_offset_ptr[b]);\n  }\n\n  int8_t* im2col_ptr = nullptr;\n  int8_t* filter_ptr = nullptr;\n  if (im2col != nullptr) {\n    im2col_ptr = im2col->data.int8;\n  }\n  filter_ptr = filter->data.int8;\n  const auto* affine_quantization =\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n\n  KernelType effective_kernel_type = kernel_type;\n  // We have to fallback to reference execution path when im2col is needed but\n  // disabled because to-be-allocated temporary im2col tensor is too large.\n  // See b/178743262 for the detailed motivation.\n  if (data->im2col_oversized) {\n    effective_kernel_type = kReference;\n  }\n\n  ConvParams op_params;\n  op_params.padding_type = PaddingType::kSame;\n  op_params.padding_values.width = data->padding.width;\n  op_params.padding_values.height = data->padding.height;\n  op_params.dilation_width_factor = params->dilation_width_factor;\n  op_params.dilation_height_factor = params->dilation_height_factor;\n  op_params.stride_width = params->stride_width;\n  op_params.stride_height = params->stride_height;\n  op_params.float_activation_min = output_activation_min;\n  op_params.float_activation_max = output_activation_max;\n  switch (effective_kernel_type) {\n    case kReference:\n      reference_ops::HybridConvPerChannel(\n          op_params, scaling_factors_ptr, GetTensorShape(input),\n          quantized_input_ptr_batch, GetTensorShape(filter), filter_ptr,\n          GetTensorShape(bias), GetTensorData<float>(bias),\n          GetTensorShape(output), GetTensorData<float>(output),\n          GetTensorShape(im2col), im2col_ptr, affine_quantization->scale->data,\n          input_offset_ptr);\n      break;\n    case kGenericOptimized:\n    case kMultithreadOptimized:\n    case kCblasOptimized: {\n      TfLiteTensor* row_sums;\n      TF_LITE_ENSURE_OK(\n          context,\n          GetTemporarySafe(context, node, data->row_sums_index, &row_sums));\n      TfLiteTensor* scratch;\n      TF_LITE_ENSURE_OK(\n          context,\n          GetTemporarySafe(context, node, data->accum_scratch_index, &scratch));\n      optimized_ops::HybridConvPerChannel(\n          op_params, scaling_factors_ptr, GetTensorShape(input),\n          quantized_input_ptr_batch, GetTensorShape(filter), filter_ptr,\n          GetTensorShape(bias), GetTensorData<float>(bias),\n          GetTensorShape(output), GetTensorData<float>(output),\n          GetTensorShape(im2col), im2col_ptr, affine_quantization->scale->data,\n          input_offset_ptr, GetTensorShape(scratch),\n          GetTensorData<int32>(scratch), GetTensorData<int32_t>(row_sums),\n          &data->compute_hybrid_row_sums,\n          CpuBackendContext::GetFromContext(context));\n      data->compute_hybrid_row_sums = false;\n      break;\n    }\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n                                  TfLiteConvParams* params, OpData* data,\n                                  const TfLiteTensor* input,\n                                  const TfLiteTensor* filter,\n                                  const TfLiteTensor* bias,\n                                  TfLiteTensor* im2col, TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n\n  const int batch_size = SizeOfDimension(input, 0);\n  TF_LITE_ENSURE(context, batch_size != 0);\n  const int input_size = NumElements(input) / batch_size;\n  TfLiteTensor* quantized_input_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &quantized_input_tensor));\n  int8_t* quantized_input_ptr_batch =\n      GetTensorData<int8_t>(quantized_input_tensor);\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n  TfLiteTensor* input_offset_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_offset_index,\n                                     &input_offset_tensor));\n  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n\n  for (int b = 0; b < batch_size; ++b) {\n    const int offset = b * input_size;\n    tensor_utils::AsymmetricQuantizeFloats(\n        GetTensorData<float>(input) + offset, input_size,\n        quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],\n        &input_offset_ptr[b]);\n  }\n\n  int8_t* im2col_ptr = nullptr;\n  int8_t* filter_ptr = nullptr;\n  if (im2col != nullptr) {\n    im2col_ptr = im2col->data.int8;\n  }\n  filter_ptr = filter->data.int8;\n  const auto* affine_quantization =\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n\n  KernelType effective_kernel_type = kernel_type;\n  // We have to fallback to reference execution path when im2col is needed but\n  // disabled because to-be-allocated temporary im2col tensor is too large.\n  // See b/178743262 for the detailed motivation.\n  if (data->im2col_oversized) {\n    effective_kernel_type = kReference;\n  }\n\n  ConvParams op_params;\n  op_params.padding_type = PaddingType::kSame;\n  op_params.padding_values.width = data->padding.width;\n  op_params.padding_values.height = data->padding.height;\n  op_params.dilation_width_factor = params->dilation_width_factor;\n  op_params.dilation_height_factor = params->dilation_height_factor;\n  op_params.stride_width = params->stride_width;\n  op_params.stride_height = params->stride_height;\n  op_params.float_activation_min = output_activation_min;\n  op_params.float_activation_max = output_activation_max;\n  switch (effective_kernel_type) {\n    case kReference:\n      reference_ops::HybridConvPerChannel(\n          op_params, scaling_factors_ptr, GetTensorShape(input),\n          quantized_input_ptr_batch, GetTensorShape(filter), filter_ptr,\n          GetTensorShape(bias), GetTensorData<float>(bias),\n          GetTensorShape(output), GetTensorData<float>(output),\n          GetTensorShape(im2col), im2col_ptr, affine_quantization->scale->data,\n          input_offset_ptr);\n      break;\n    case kGenericOptimized:\n    case kMultithreadOptimized:\n    case kCblasOptimized: {\n      TfLiteTensor* row_sums;\n      TF_LITE_ENSURE_OK(\n          context,\n          GetTemporarySafe(context, node, data->row_sums_index, &row_sums));\n      TfLiteTensor* scratch;\n      TF_LITE_ENSURE_OK(\n          context,\n          GetTemporarySafe(context, node, data->accum_scratch_index, &scratch));\n      optimized_ops::HybridConvPerChannel(\n          op_params, scaling_factors_ptr, GetTensorShape(input),\n          quantized_input_ptr_batch, GetTensorShape(filter), filter_ptr,\n          GetTensorShape(bias), GetTensorData<float>(bias),\n          GetTensorShape(output), GetTensorData<float>(output),\n          GetTensorShape(im2col), im2col_ptr, affine_quantization->scale->data,\n          input_offset_ptr, GetTensorShape(scratch),\n          GetTensorData<int32>(scratch), GetTensorData<int32_t>(row_sums),\n          &data->compute_hybrid_row_sums,\n          CpuBackendContext::GetFromContext(context));\n      data->compute_hybrid_row_sums = false;\n      break;\n    }\n  }\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,8 +8,9 @@\n   CalculateActivationRange(params->activation, &output_activation_min,\n                            &output_activation_max);\n \n-  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n   const int batch_size = SizeOfDimension(input, 0);\n+  TF_LITE_ENSURE(context, batch_size != 0);\n+  const int input_size = NumElements(input) / batch_size;\n   TfLiteTensor* quantized_input_tensor;\n   TF_LITE_ENSURE_OK(context,\n                     GetTemporarySafe(context, node, data->input_quantized_index,",
        "diff_line_info": {
            "deleted_lines": [
                "  const int input_size = NumElements(input) / SizeOfDimension(input, 0);"
            ],
            "added_lines": [
                "  TF_LITE_ENSURE(context, batch_size != 0);",
                "  const int input_size = NumElements(input) / batch_size;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29594",
        "func_name": "tensorflow/EvalHybrid",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. TFLite's convolution code(https://github.com/tensorflow/tensorflow/blob/09c73bca7d648e961dd05898292d91a8322a9d45/tensorflow/lite/kernels/conv.cc) has multiple division where the divisor is controlled by the user and not checked to be non-zero. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/ff489d95a9006be080ad14feb378f2b4dac35552",
        "commit_title": "Prevent division by 0.",
        "commit_text": " PiperOrigin-RevId: 370962554",
        "func_before": "TfLiteStatus EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n                        TfLiteConvParams* params, OpData* data,\n                        const TfLiteTensor* input, const TfLiteTensor* filter,\n                        const TfLiteTensor* bias, TfLiteTensor* im2col,\n                        TfLiteTensor* accum_scratch, TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n\n  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n  const int batch_size = SizeOfDimension(input, 0);\n\n  const float* input_ptr = GetTensorData<float>(input);\n  TfLiteTensor* quantized_input_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &quantized_input_tensor));\n  int8_t* quantized_input_ptr_batch =\n      GetTensorData<int8_t>(quantized_input_tensor);\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n\n  // Per-batch input quantization for higher accuracy.\n  {\n    ruy::profiler::ScopeLabel label(\"ConvHybridQuantizeInputs\");\n    for (int b = 0; b < batch_size; ++b) {\n      float unused_min, unused_max;\n      const int offset = b * input_size;\n      tensor_utils::SymmetricQuantizeFloats(\n          input_ptr + offset, input_size, quantized_input_ptr_batch + offset,\n          &unused_min, &unused_max, &scaling_factors_ptr[b]);\n      scaling_factors_ptr[b] *= filter->params.scale;\n    }\n  }\n\n  switch (kernel_type) {\n    case kReference:\n    case kGenericOptimized:\n    case kMultithreadOptimized:\n    case kCblasOptimized: {\n      // There is only one implementation for hybrid kernel.\n      ConvParams op_params;\n      op_params.padding_type = PaddingType::kSame;\n      op_params.padding_values.width = data->padding.width;\n      op_params.padding_values.height = data->padding.height;\n      op_params.stride_width = params->stride_width;\n      op_params.stride_height = params->stride_height;\n      op_params.dilation_width_factor = params->dilation_width_factor;\n      op_params.dilation_height_factor = params->dilation_height_factor;\n      op_params.float_activation_min = output_activation_min;\n      op_params.float_activation_max = output_activation_max;\n      optimized_ops::HybridConv(\n          op_params, scaling_factors_ptr, GetTensorShape(input),\n          quantized_input_ptr_batch, GetTensorShape(filter),\n          GetTensorData<int8_t>(filter), GetTensorShape(bias),\n          GetTensorData<float>(bias), GetTensorShape(accum_scratch),\n          GetTensorData<int32_t>(accum_scratch), GetTensorShape(output),\n          GetTensorData<float>(output), GetTensorShape(im2col),\n          GetTensorData<int8_t>(im2col),\n          CpuBackendContext::GetFromContext(context));\n      break;\n    }\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus EvalHybrid(TfLiteContext* context, TfLiteNode* node,\n                        TfLiteConvParams* params, OpData* data,\n                        const TfLiteTensor* input, const TfLiteTensor* filter,\n                        const TfLiteTensor* bias, TfLiteTensor* im2col,\n                        TfLiteTensor* accum_scratch, TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n\n  const int batch_size = SizeOfDimension(input, 0);\n  TF_LITE_ENSURE(context, batch_size != 0);\n  const int input_size = NumElements(input) / batch_size;\n\n  const float* input_ptr = GetTensorData<float>(input);\n  TfLiteTensor* quantized_input_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &quantized_input_tensor));\n  int8_t* quantized_input_ptr_batch =\n      GetTensorData<int8_t>(quantized_input_tensor);\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n\n  // Per-batch input quantization for higher accuracy.\n  {\n    ruy::profiler::ScopeLabel label(\"ConvHybridQuantizeInputs\");\n    for (int b = 0; b < batch_size; ++b) {\n      float unused_min, unused_max;\n      const int offset = b * input_size;\n      tensor_utils::SymmetricQuantizeFloats(\n          input_ptr + offset, input_size, quantized_input_ptr_batch + offset,\n          &unused_min, &unused_max, &scaling_factors_ptr[b]);\n      scaling_factors_ptr[b] *= filter->params.scale;\n    }\n  }\n\n  switch (kernel_type) {\n    case kReference:\n    case kGenericOptimized:\n    case kMultithreadOptimized:\n    case kCblasOptimized: {\n      // There is only one implementation for hybrid kernel.\n      ConvParams op_params;\n      op_params.padding_type = PaddingType::kSame;\n      op_params.padding_values.width = data->padding.width;\n      op_params.padding_values.height = data->padding.height;\n      op_params.stride_width = params->stride_width;\n      op_params.stride_height = params->stride_height;\n      op_params.dilation_width_factor = params->dilation_width_factor;\n      op_params.dilation_height_factor = params->dilation_height_factor;\n      op_params.float_activation_min = output_activation_min;\n      op_params.float_activation_max = output_activation_max;\n      optimized_ops::HybridConv(\n          op_params, scaling_factors_ptr, GetTensorShape(input),\n          quantized_input_ptr_batch, GetTensorShape(filter),\n          GetTensorData<int8_t>(filter), GetTensorShape(bias),\n          GetTensorData<float>(bias), GetTensorShape(accum_scratch),\n          GetTensorData<int32_t>(accum_scratch), GetTensorShape(output),\n          GetTensorData<float>(output), GetTensorShape(im2col),\n          GetTensorData<int8_t>(im2col),\n          CpuBackendContext::GetFromContext(context));\n      break;\n    }\n  }\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,8 +7,9 @@\n   CalculateActivationRange(params->activation, &output_activation_min,\n                            &output_activation_max);\n \n-  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n   const int batch_size = SizeOfDimension(input, 0);\n+  TF_LITE_ENSURE(context, batch_size != 0);\n+  const int input_size = NumElements(input) / batch_size;\n \n   const float* input_ptr = GetTensorData<float>(input);\n   TfLiteTensor* quantized_input_tensor;",
        "diff_line_info": {
            "deleted_lines": [
                "  const int input_size = NumElements(input) / SizeOfDimension(input, 0);"
            ],
            "added_lines": [
                "  TF_LITE_ENSURE(context, batch_size != 0);",
                "  const int input_size = NumElements(input) / batch_size;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29595",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `DepthToSpace` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/depth_to_space.cc#L63-L69). An attacker can craft a model such that `params->block_size` is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/106d8f4fb89335a2c52d7c895b7a7485465ca8d9",
        "commit_title": "Prevent division by 0 in TFLite",
        "commit_text": " PiperOrigin-RevId: 370800311",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthToSpaceParams*>(node->builtin_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n\n  auto data_type = output->type;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt32 ||\n                     data_type == kTfLiteInt64);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  const int block_size = params->block_size;\n  const int input_height = input->dims->data[1];\n  const int input_width = input->dims->data[2];\n  const int input_channels = input->dims->data[3];\n  int output_height = input_height * block_size;\n  int output_width = input_width * block_size;\n  int output_channels = input_channels / block_size / block_size;\n\n  TF_LITE_ENSURE_EQ(context, input_height, output_height / block_size);\n  TF_LITE_ENSURE_EQ(context, input_width, output_width / block_size);\n  TF_LITE_ENSURE_EQ(context, input_channels,\n                    output_channels * block_size * block_size);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = input->dims->data[0];\n  output_size->data[1] = output_height;\n  output_size->data[2] = output_width;\n  output_size->data[3] = output_channels;\n\n  return context->ResizeTensor(context, output, output_size);\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthToSpaceParams*>(node->builtin_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n\n  auto data_type = output->type;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt32 ||\n                     data_type == kTfLiteInt64);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  const int block_size = params->block_size;\n  TF_LITE_ENSURE(context, block_size > 0);\n  const int input_height = input->dims->data[1];\n  const int input_width = input->dims->data[2];\n  const int input_channels = input->dims->data[3];\n  int output_height = input_height * block_size;\n  int output_width = input_width * block_size;\n  int output_channels = input_channels / block_size / block_size;\n\n  TF_LITE_ENSURE_EQ(context, input_height, output_height / block_size);\n  TF_LITE_ENSURE_EQ(context, input_width, output_width / block_size);\n  TF_LITE_ENSURE_EQ(context, input_channels,\n                    output_channels * block_size * block_size);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = input->dims->data[0];\n  output_size->data[1] = output_height;\n  output_size->data[2] = output_width;\n  output_size->data[3] = output_channels;\n\n  return context->ResizeTensor(context, output, output_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,7 @@\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   const int block_size = params->block_size;\n+  TF_LITE_ENSURE(context, block_size > 0);\n   const int input_height = input->dims->data[1];\n   const int input_width = input->dims->data[2];\n   const int input_channels = input->dims->data[3];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, block_size > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29595",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `DepthToSpace` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/depth_to_space.cc#L63-L69). An attacker can craft a model such that `params->block_size` is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/106d8f4fb89335a2c52d7c895b7a7485465ca8d9",
        "commit_title": "Prevent division by 0 in TFLite",
        "commit_text": " PiperOrigin-RevId: 370800311",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthToSpaceParams*>(node->builtin_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n\n  auto data_type = output->type;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt32 ||\n                     data_type == kTfLiteInt64);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  const int block_size = params->block_size;\n  const int input_height = input->dims->data[1];\n  const int input_width = input->dims->data[2];\n  const int input_channels = input->dims->data[3];\n  int output_height = input_height * block_size;\n  int output_width = input_width * block_size;\n  int output_channels = input_channels / block_size / block_size;\n\n  TF_LITE_ENSURE_EQ(context, input_height, output_height / block_size);\n  TF_LITE_ENSURE_EQ(context, input_width, output_width / block_size);\n  TF_LITE_ENSURE_EQ(context, input_channels,\n                    output_channels * block_size * block_size);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = input->dims->data[0];\n  output_size->data[1] = output_height;\n  output_size->data[2] = output_width;\n  output_size->data[3] = output_channels;\n\n  return context->ResizeTensor(context, output, output_size);\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteDepthToSpaceParams*>(node->builtin_data);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 1);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  TF_LITE_ENSURE_EQ(context, NumDimensions(input), 4);\n\n  auto data_type = output->type;\n  TF_LITE_ENSURE(context,\n                 data_type == kTfLiteFloat32 || data_type == kTfLiteUInt8 ||\n                     data_type == kTfLiteInt8 || data_type == kTfLiteInt32 ||\n                     data_type == kTfLiteInt64);\n  TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n\n  const int block_size = params->block_size;\n  TF_LITE_ENSURE(context, block_size > 0);\n  const int input_height = input->dims->data[1];\n  const int input_width = input->dims->data[2];\n  const int input_channels = input->dims->data[3];\n  int output_height = input_height * block_size;\n  int output_width = input_width * block_size;\n  int output_channels = input_channels / block_size / block_size;\n\n  TF_LITE_ENSURE_EQ(context, input_height, output_height / block_size);\n  TF_LITE_ENSURE_EQ(context, input_width, output_width / block_size);\n  TF_LITE_ENSURE_EQ(context, input_channels,\n                    output_channels * block_size * block_size);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCreate(4);\n  output_size->data[0] = input->dims->data[0];\n  output_size->data[1] = output_height;\n  output_size->data[2] = output_width;\n  output_size->data[3] = output_channels;\n\n  return context->ResizeTensor(context, output, output_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,7 @@\n   TF_LITE_ENSURE_TYPES_EQ(context, input->type, output->type);\n \n   const int block_size = params->block_size;\n+  TF_LITE_ENSURE(context, block_size > 0);\n   const int input_height = input->dims->data[1];\n   const int input_width = input->dims->data[2];\n   const int input_channels = input->dims->data[3];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, block_size > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29596",
        "func_name": "tensorflow/EvalSimple",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `EmbeddingLookup` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/e4b29809543b250bc9b19678ec4776299dd569ba/tensorflow/lite/kernels/embedding_lookup.cc#L73-L74). An attacker can craft a model such that the first dimension of the `value` input is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/f61c57bd425878be108ec787f4d96390579fb83e",
        "commit_title": "Prevent division by 0",
        "commit_text": " PiperOrigin-RevId: 370966645",
        "func_before": "TfLiteStatus EvalSimple(TfLiteContext* context, TfLiteNode* node,\n                        const TfLiteTensor* lookup, const TfLiteTensor* value,\n                        TfLiteTensor* output) {\n  const int row_size = SizeOfDimension(value, 0);\n  const int row_bytes = value->bytes / row_size;\n\n  char* output_raw = GetTensorData<char>(output);\n  const char* value_raw = GetTensorData<char>(value);\n  const int32_t* lookup_data = GetTensorData<int32_t>(lookup);\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = lookup_data[i];\n    if (idx >= row_size || idx < 0) {\n      context->ReportError(context,\n                           \"Embedding Lookup: index out of bounds. \"\n                           \"Got %d, and bounds are [0, %d]\",\n                           idx, row_size - 1);\n      return kTfLiteError;\n    } else {\n      std::memcpy(output_raw + i * row_bytes, value_raw + idx * row_bytes,\n                  row_bytes);\n    }\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus EvalSimple(TfLiteContext* context, TfLiteNode* node,\n                        const TfLiteTensor* lookup, const TfLiteTensor* value,\n                        TfLiteTensor* output) {\n  const int row_size = SizeOfDimension(value, 0);\n  if (row_size == 0) {\n    // Propagate empty tensor if input is empty\n    return kTfLiteOk;\n  }\n  const int row_bytes = value->bytes / row_size;\n\n  char* output_raw = GetTensorData<char>(output);\n  const char* value_raw = GetTensorData<char>(value);\n  const int32_t* lookup_data = GetTensorData<int32_t>(lookup);\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = lookup_data[i];\n    if (idx >= row_size || idx < 0) {\n      context->ReportError(context,\n                           \"Embedding Lookup: index out of bounds. \"\n                           \"Got %d, and bounds are [0, %d]\",\n                           idx, row_size - 1);\n      return kTfLiteError;\n    } else {\n      std::memcpy(output_raw + i * row_bytes, value_raw + idx * row_bytes,\n                  row_bytes);\n    }\n  }\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,10 @@\n                         const TfLiteTensor* lookup, const TfLiteTensor* value,\n                         TfLiteTensor* output) {\n   const int row_size = SizeOfDimension(value, 0);\n+  if (row_size == 0) {\n+    // Propagate empty tensor if input is empty\n+    return kTfLiteOk;\n+  }\n   const int row_bytes = value->bytes / row_size;\n \n   char* output_raw = GetTensorData<char>(output);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  if (row_size == 0) {",
                "    // Propagate empty tensor if input is empty",
                "    return kTfLiteOk;",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29597",
        "func_name": "tensorflow/ResizeOutputTensor",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `SpaceToBatchNd` TFLite operator is [vulnerable to a division by zero error](https://github.com/tensorflow/tensorflow/blob/412c7d9bb8f8a762c5b266c9e73bfa165f29aac8/tensorflow/lite/kernels/space_to_batch_nd.cc#L82-L83). An attacker can craft a model such that one dimension of the `block` input is 0. Hence, the corresponding value in `block_shape` is 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/6d36ba65577006affb272335b7c1abd829010708",
        "commit_title": "Prevent division by 0",
        "commit_text": " PiperOrigin-RevId: 370984990",
        "func_before": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                SpaceToBatchNDContext* op_context) {\n  TfLiteIntArray* input_size = op_context->input->dims;\n  const int32* block_shape = GetTensorData<int32>(op_context->block_shape);\n  const int32* paddings_data = GetTensorData<int32>(op_context->paddings);\n\n  int spatial_dims_num = input_size->size - 2;\n  // Block_shape should be a 1D tensor with dimension [spatial_dims_num].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->block_shape), 1);\n  TF_LITE_ENSURE_EQ(context, op_context->block_shape->dims->data[0],\n                    spatial_dims_num);\n  // Paddings should be a 2D tensor with dimension [spatial_dims_num, 2].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->paddings), 2);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[0],\n                    spatial_dims_num);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[1], 2);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCopy(input_size);\n\n  // Ensures the input height and width (with padding) is a multiple of block\n  // shape height and width.\n  int output_batch_size = input_size->data[0];\n  for (int dim = 0; dim < spatial_dims_num; ++dim) {\n    int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +\n                          paddings_data[dim * 2 + 1]);\n    TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);\n    output_size->data[dim + 1] = final_dim_size / block_shape[dim];\n    output_batch_size *= block_shape[dim];\n  }\n\n  output_size->data[0] = output_batch_size;\n  output_size->data[input_size->size - 1] =\n      input_size->data[input_size->size - 1];\n\n  return context->ResizeTensor(context, op_context->output, output_size);\n}",
        "func": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                SpaceToBatchNDContext* op_context) {\n  TfLiteIntArray* input_size = op_context->input->dims;\n  const int32* block_shape = GetTensorData<int32>(op_context->block_shape);\n  const int32* paddings_data = GetTensorData<int32>(op_context->paddings);\n\n  int spatial_dims_num = input_size->size - 2;\n  // Block_shape should be a 1D tensor with dimension [spatial_dims_num].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->block_shape), 1);\n  TF_LITE_ENSURE_EQ(context, op_context->block_shape->dims->data[0],\n                    spatial_dims_num);\n  // Paddings should be a 2D tensor with dimension [spatial_dims_num, 2].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->paddings), 2);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[0],\n                    spatial_dims_num);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[1], 2);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCopy(input_size);\n\n  // Ensures the input height and width (with padding) is a multiple of block\n  // shape height and width.\n  int output_batch_size = input_size->data[0];\n  for (int dim = 0; dim < spatial_dims_num; ++dim) {\n    int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +\n                          paddings_data[dim * 2 + 1]);\n    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n    TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);\n    output_size->data[dim + 1] = final_dim_size / block_shape[dim];\n    output_batch_size *= block_shape[dim];\n  }\n\n  output_size->data[0] = output_batch_size;\n  output_size->data[input_size->size - 1] =\n      input_size->data[input_size->size - 1];\n\n  return context->ResizeTensor(context, op_context->output, output_size);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,6 +23,7 @@\n   for (int dim = 0; dim < spatial_dims_num; ++dim) {\n     int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +\n                           paddings_data[dim * 2 + 1]);\n+    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n     TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);\n     output_size->data[dim + 1] = final_dim_size / block_shape[dim];\n     output_batch_size *= block_shape[dim];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    TF_LITE_ENSURE(context, block_shape[dim] != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29598",
        "func_name": "tensorflow/Prepare",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `SVDF` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/7f283ff806b2031f407db64c4d3edcda8fb9f9f5/tensorflow/lite/kernels/svdf.cc#L99-L102). An attacker can craft a model such that `params->rank` would be 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/6841e522a3e7d48706a02e8819836e809f738682",
        "commit_title": "Prevent division by 0",
        "commit_text": " PiperOrigin-RevId: 370995582",
        "func_before": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  const auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int scratch_tensor_index = op_data->scratch_tensor_index;\n\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n\n  TF_LITE_ENSURE(context,\n                 input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  const int rank = params->rank;\n  const int batch_size = input->dims->data[0];\n  const int num_filters = weights_feature->dims->data[0];\n  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n  const int num_units = num_filters / rank;\n  const int memory_size = weights_time->dims->data[1];\n  TF_LITE_ENSURE_EQ(context, input->dims->data[1],\n                    weights_feature->dims->data[1]);\n  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[0], num_filters);\n\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n  }\n\n  const TfLiteTensor* state;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check the shape of input state tensors.\n  TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 0), batch_size);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 1),\n                    memory_size * num_filters);\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n  output_size_array->data[0] = batch_size;\n  output_size_array->data[1] = num_units;\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  // The weights are of consistent type, so it suffices to check one.\n  const bool is_hybrid_op = IsHybridOp(input, weights_feature);\n  const bool is_full_integer = input->type == kTfLiteInt8;\n\n  // Resize scratch.\n  TfLiteIntArrayFree(node->temporaries);\n  if (is_hybrid_op) {\n    node->temporaries = TfLiteIntArrayCreate(6);\n  } else if (is_full_integer) {\n    node->temporaries = TfLiteIntArrayCreate(2);\n  } else {\n    node->temporaries = TfLiteIntArrayCreate(1);\n  }\n  node->temporaries->data[0] = scratch_tensor_index;\n\n  TfLiteIntArray* scratch_size_array = TfLiteIntArrayCreate(2);\n  scratch_size_array->data[0] = batch_size;\n  scratch_size_array->data[1] = num_filters;\n\n  TfLiteTensor* scratch_tensor;\n  TF_LITE_ENSURE_OK(\n      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n\n  // The scratch buffer is of type int32 for full integer svdf and it's of type\n  // float32 for hybrid and float case.\n  if (is_full_integer) {\n    scratch_tensor->type = kTfLiteInt32;\n  } else {\n    scratch_tensor->type = kTfLiteFloat32;\n  }\n  scratch_tensor->allocation_type = kTfLiteArenaRw;\n  TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scratch_tensor,\n                                                   scratch_size_array));\n\n  if (is_hybrid_op) {\n    op_data->compute_row_sums = true;\n    // Tell interpreter to allocate temporary tensors to store quantized values\n    // of input tensors.\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &input_quantized));\n    input_quantized->type = weights_feature->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    // Tell interpreter to allocate temporary tensors to store scaling factors.\n    node->temporaries->data[2] = scratch_tensor_index + 2;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    // Used to store dequantized weights_time matrix for hybrid computation of\n    // matmul(state, weights_time), which occurs in floating point.\n    node->temporaries->data[3] = scratch_tensor_index + 3;\n    TfLiteTensor* float_weights_time;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                &float_weights_time));\n    float_weights_time->type = kTfLiteFloat32;\n    // Persistent so that we can compute the dequantized weights only once.\n    float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n    if (!TfLiteIntArrayEqual(float_weights_time->dims, weights_time->dims)) {\n      TfLiteIntArray* float_weights_time_size =\n          TfLiteIntArrayCopy(weights_time->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, float_weights_time,\n                                              float_weights_time_size));\n    }\n\n    node->temporaries->data[4] = scratch_tensor_index + 4;\n    TfLiteTensor* zero_points;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n    zero_points->type = kTfLiteFloat32;\n    zero_points->allocation_type = kTfLiteArenaRw;\n    int zero_points_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(zero_points->dims, 1, zero_points_dims)) {\n      TfLiteIntArray* zero_points_size = TfLiteIntArrayCreate(1);\n      zero_points_size->data[0] = zero_points_dims[0];\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, zero_points,\n                                                       zero_points_size));\n    }\n\n    node->temporaries->data[5] = scratch_tensor_index + 5;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n    row_sums->type = kTfLiteFloat32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_filters};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n  }\n  if (is_full_integer) {\n    // Allocated one extra tensor.\n    TfLiteIntArray* output_temp_size_array = TfLiteIntArrayCreate(2);\n    output_temp_size_array->data[0] = num_units;\n    output_temp_size_array->data[1] = batch_size;\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* output_temp;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n    output_temp->type = kTfLiteInt32;\n    output_temp->allocation_type = kTfLiteArenaRw;\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n                                                     output_temp_size_array));\n\n    // Calculate effective scales.\n    auto* input_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n    auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_feature->quantization.params);\n    auto* state_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n    auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_time->quantization.params);\n    auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        output->quantization.params);\n    const double effective_scale_1 = input_params->scale->data[0] *\n                                     weights_feature_params->scale->data[0] /\n                                     state_params->scale->data[0];\n    const double effective_scale_2 = state_params->scale->data[0] *\n                                     weight_time_params->scale->data[0] /\n                                     output_params->scale->data[0];\n    QuantizeMultiplier(effective_scale_1, &op_data->effective_scale_1_a,\n                       &op_data->effective_scale_1_b);\n    QuantizeMultiplier(effective_scale_2, &op_data->effective_scale_2_a,\n                       &op_data->effective_scale_2_b);\n  }\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  const auto* params = reinterpret_cast<TfLiteSVDFParams*>(node->builtin_data);\n  OpData* op_data = reinterpret_cast<OpData*>(node->user_data);\n  int scratch_tensor_index = op_data->scratch_tensor_index;\n\n  // Check we have all the inputs and outputs we need.\n  TF_LITE_ENSURE_EQ(context, node->outputs->size, 1);\n  TF_LITE_ENSURE_EQ(context, node->inputs->size, 5);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kInputTensor, &input));\n  const TfLiteTensor* weights_feature;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kWeightsFeatureTensor,\n                                          &weights_feature));\n  const TfLiteTensor* weights_time;\n  TF_LITE_ENSURE_OK(\n      context, GetInputSafe(context, node, kWeightsTimeTensor, &weights_time));\n\n  TF_LITE_ENSURE(context,\n                 input->type == kTfLiteFloat32 || input->type == kTfLiteInt8);\n\n  // Check all the parameters of tensor match within themselves and match the\n  // input configuration.\n  const int rank = params->rank;\n  const int batch_size = input->dims->data[0];\n  const int num_filters = weights_feature->dims->data[0];\n  TF_LITE_ENSURE(context, rank != 0);\n  TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n  const int num_units = num_filters / rank;\n  const int memory_size = weights_time->dims->data[1];\n  TF_LITE_ENSURE_EQ(context, input->dims->data[1],\n                    weights_feature->dims->data[1]);\n  TF_LITE_ENSURE_EQ(context, weights_time->dims->data[0], num_filters);\n\n  const TfLiteTensor* bias = GetOptionalInputTensor(context, node, kBiasTensor);\n  if (bias) {\n    TF_LITE_ENSURE_EQ(context, bias->dims->data[0], num_units);\n  }\n\n  const TfLiteTensor* state;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, kStateTensor, &state));\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context,\n                    GetOutputSafe(context, node, kOutputTensor, &output));\n\n  // Check the shape of input state tensors.\n  TF_LITE_ENSURE_EQ(context, NumDimensions(state), 2);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 0), batch_size);\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(state, 1),\n                    memory_size * num_filters);\n\n  // Resize output.\n  TfLiteIntArray* output_size_array = TfLiteIntArrayCreate(2);\n  output_size_array->data[0] = batch_size;\n  output_size_array->data[1] = num_units;\n  TF_LITE_ENSURE_OK(context,\n                    context->ResizeTensor(context, output, output_size_array));\n\n  // The weights are of consistent type, so it suffices to check one.\n  const bool is_hybrid_op = IsHybridOp(input, weights_feature);\n  const bool is_full_integer = input->type == kTfLiteInt8;\n\n  // Resize scratch.\n  TfLiteIntArrayFree(node->temporaries);\n  if (is_hybrid_op) {\n    node->temporaries = TfLiteIntArrayCreate(6);\n  } else if (is_full_integer) {\n    node->temporaries = TfLiteIntArrayCreate(2);\n  } else {\n    node->temporaries = TfLiteIntArrayCreate(1);\n  }\n  node->temporaries->data[0] = scratch_tensor_index;\n\n  TfLiteIntArray* scratch_size_array = TfLiteIntArrayCreate(2);\n  scratch_size_array->data[0] = batch_size;\n  scratch_size_array->data[1] = num_filters;\n\n  TfLiteTensor* scratch_tensor;\n  TF_LITE_ENSURE_OK(\n      context, GetTemporarySafe(context, node, /*index=*/0, &scratch_tensor));\n\n  // The scratch buffer is of type int32 for full integer svdf and it's of type\n  // float32 for hybrid and float case.\n  if (is_full_integer) {\n    scratch_tensor->type = kTfLiteInt32;\n  } else {\n    scratch_tensor->type = kTfLiteFloat32;\n  }\n  scratch_tensor->allocation_type = kTfLiteArenaRw;\n  TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scratch_tensor,\n                                                   scratch_size_array));\n\n  if (is_hybrid_op) {\n    op_data->compute_row_sums = true;\n    // Tell interpreter to allocate temporary tensors to store quantized values\n    // of input tensors.\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* input_quantized;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/1,\n                                                &input_quantized));\n    input_quantized->type = weights_feature->type;\n    input_quantized->allocation_type = kTfLiteArenaRw;\n    if (!TfLiteIntArrayEqual(input_quantized->dims, input->dims)) {\n      TfLiteIntArray* input_quantized_size = TfLiteIntArrayCopy(input->dims);\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, input_quantized,\n                                                       input_quantized_size));\n    }\n\n    // Tell interpreter to allocate temporary tensors to store scaling factors.\n    node->temporaries->data[2] = scratch_tensor_index + 2;\n    TfLiteTensor* scaling_factors;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/2,\n                                                &scaling_factors));\n    scaling_factors->type = kTfLiteFloat32;\n    scaling_factors->allocation_type = kTfLiteArenaRw;\n    int scaling_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(scaling_factors->dims, 1, scaling_dims)) {\n      TfLiteIntArray* scaling_factors_size = TfLiteIntArrayCreate(1);\n      scaling_factors_size->data[0] = batch_size;\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, scaling_factors,\n                                                       scaling_factors_size));\n    }\n\n    // Used to store dequantized weights_time matrix for hybrid computation of\n    // matmul(state, weights_time), which occurs in floating point.\n    node->temporaries->data[3] = scratch_tensor_index + 3;\n    TfLiteTensor* float_weights_time;\n    TF_LITE_ENSURE_OK(context, GetTemporarySafe(context, node, /*index=*/3,\n                                                &float_weights_time));\n    float_weights_time->type = kTfLiteFloat32;\n    // Persistent so that we can compute the dequantized weights only once.\n    float_weights_time->allocation_type = kTfLiteArenaRwPersistent;\n    if (!TfLiteIntArrayEqual(float_weights_time->dims, weights_time->dims)) {\n      TfLiteIntArray* float_weights_time_size =\n          TfLiteIntArrayCopy(weights_time->dims);\n      TF_LITE_ENSURE_OK(context,\n                        context->ResizeTensor(context, float_weights_time,\n                                              float_weights_time_size));\n    }\n\n    node->temporaries->data[4] = scratch_tensor_index + 4;\n    TfLiteTensor* zero_points;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/4, &zero_points));\n    zero_points->type = kTfLiteFloat32;\n    zero_points->allocation_type = kTfLiteArenaRw;\n    int zero_points_dims[1] = {batch_size};\n    if (!TfLiteIntArrayEqualsArray(zero_points->dims, 1, zero_points_dims)) {\n      TfLiteIntArray* zero_points_size = TfLiteIntArrayCreate(1);\n      zero_points_size->data[0] = zero_points_dims[0];\n      TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, zero_points,\n                                                       zero_points_size));\n    }\n\n    node->temporaries->data[5] = scratch_tensor_index + 5;\n    TfLiteTensor* row_sums;\n    TF_LITE_ENSURE_OK(context,\n                      GetTemporarySafe(context, node, /*index=*/5, &row_sums));\n    row_sums->type = kTfLiteFloat32;\n    row_sums->allocation_type = kTfLiteArenaRwPersistent;\n    int row_sums_dims[1] = {num_filters};\n    if (!TfLiteIntArrayEqualsArray(row_sums->dims, 1, row_sums_dims)) {\n      TfLiteIntArray* row_sums_size = TfLiteIntArrayCreate(1);\n      row_sums_size->data[0] = row_sums_dims[0];\n      TF_LITE_ENSURE_OK(\n          context, context->ResizeTensor(context, row_sums, row_sums_size));\n    }\n  }\n  if (is_full_integer) {\n    // Allocated one extra tensor.\n    TfLiteIntArray* output_temp_size_array = TfLiteIntArrayCreate(2);\n    output_temp_size_array->data[0] = num_units;\n    output_temp_size_array->data[1] = batch_size;\n    node->temporaries->data[1] = scratch_tensor_index + 1;\n    TfLiteTensor* output_temp;\n    TF_LITE_ENSURE_OK(\n        context, GetTemporarySafe(context, node, /*index=*/1, &output_temp));\n    output_temp->type = kTfLiteInt32;\n    output_temp->allocation_type = kTfLiteArenaRw;\n    TF_LITE_ENSURE_OK(context, context->ResizeTensor(context, output_temp,\n                                                     output_temp_size_array));\n\n    // Calculate effective scales.\n    auto* input_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(input->quantization.params);\n    auto* weights_feature_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_feature->quantization.params);\n    auto* state_params =\n        reinterpret_cast<TfLiteAffineQuantization*>(state->quantization.params);\n    auto* weight_time_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        weights_time->quantization.params);\n    auto* output_params = reinterpret_cast<TfLiteAffineQuantization*>(\n        output->quantization.params);\n    const double effective_scale_1 = input_params->scale->data[0] *\n                                     weights_feature_params->scale->data[0] /\n                                     state_params->scale->data[0];\n    const double effective_scale_2 = state_params->scale->data[0] *\n                                     weight_time_params->scale->data[0] /\n                                     output_params->scale->data[0];\n    QuantizeMultiplier(effective_scale_1, &op_data->effective_scale_1_a,\n                       &op_data->effective_scale_1_b);\n    QuantizeMultiplier(effective_scale_2, &op_data->effective_scale_2_a,\n                       &op_data->effective_scale_2_b);\n  }\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,6 +24,7 @@\n   const int rank = params->rank;\n   const int batch_size = input->dims->data[0];\n   const int num_filters = weights_feature->dims->data[0];\n+  TF_LITE_ENSURE(context, rank != 0);\n   TF_LITE_ENSURE_EQ(context, num_filters % rank, 0);\n   const int num_units = num_filters / rank;\n   const int memory_size = weights_time->dims->data[1];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, rank != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29599",
        "func_name": "tensorflow/ResizeOutputTensors",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `Split` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/e2752089ef7ce9bcf3db0ec618ebd23ea119d0c7/tensorflow/lite/kernels/split.cc#L63-L65). An attacker can craft a model such that `num_splits` would be 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/b22786e7e9b7bdb6a56936ff29cc7e9968d7bc1d",
        "commit_title": "Prevent division by 0",
        "commit_text": " PiperOrigin-RevId: 370998952",
        "func_before": "TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n                                 const TfLiteTensor* axis,\n                                 const TfLiteTensor* input, int num_splits) {\n  int axis_value = GetTensorData<int>(axis)[0];\n  if (axis_value < 0) {\n    axis_value += NumDimensions(input);\n  }\n\n  TF_LITE_ENSURE(context, axis_value >= 0);\n  TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n\n  const int input_size = SizeOfDimension(input, axis_value);\n  TF_LITE_ENSURE_MSG(context, input_size % num_splits == 0,\n                     \"Not an even split\");\n  const int slice_size = input_size / num_splits;\n\n  for (int i = 0; i < NumOutputs(node); ++i) {\n    TfLiteIntArray* output_dims = TfLiteIntArrayCopy(input->dims);\n    output_dims->data[axis_value] = slice_size;\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_dims));\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n                                 const TfLiteTensor* axis,\n                                 const TfLiteTensor* input, int num_splits) {\n  int axis_value = GetTensorData<int>(axis)[0];\n  if (axis_value < 0) {\n    axis_value += NumDimensions(input);\n  }\n\n  TF_LITE_ENSURE(context, axis_value >= 0);\n  TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n\n  const int input_size = SizeOfDimension(input, axis_value);\n  TF_LITE_ENSURE(context, num_splits != 0);\n  TF_LITE_ENSURE_MSG(context, input_size % num_splits == 0,\n                     \"Not an even split\");\n  const int slice_size = input_size / num_splits;\n\n  for (int i = 0; i < NumOutputs(node); ++i) {\n    TfLiteIntArray* output_dims = TfLiteIntArrayCopy(input->dims);\n    output_dims->data[axis_value] = slice_size;\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_dims));\n  }\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,7 @@\n   TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n \n   const int input_size = SizeOfDimension(input, axis_value);\n+  TF_LITE_ENSURE(context, num_splits != 0);\n   TF_LITE_ENSURE_MSG(context, input_size % num_splits == 0,\n                      \"Not an even split\");\n   const int slice_size = input_size / num_splits;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, num_splits != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29600",
        "func_name": "tensorflow/OneHotComputeImpl",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `OneHot` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/f61c57bd425878be108ec787f4d96390579fb83e/tensorflow/lite/kernels/one_hot.cc#L68-L72). An attacker can craft a model such that at least one of the dimensions of `indices` would be 0. In turn, the `prefix_dim_size` value would become 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/3ebedd7e345453d68e279cfc3e4072648e5e12e5",
        "commit_title": "Prevent division by 0 in OneHot implementation",
        "commit_text": " If input indices is degenerate, the implementation would do a divide by zero. See https://github.com/tensorflow/tensorflow/blob/745d57df6d5e9bc568666a2a48ed8dd629c27241/tensorflow/lite/kernels/one_hot.cc#L68-L72  PiperOrigin-RevId: 370966870",
        "func_before": "void OneHotComputeImpl(const OneHotContext& op_context) {\n  // prefix_dim_size == # of elements before the axis\n  // depth == # of elements per axis\n  // suffix_dim_size == # of elements after the axis\n  int prefix_dim_size = 1;\n  for (int i = 0; i < op_context.axis; ++i) {\n    prefix_dim_size *= op_context.indices->dims->data[i];\n  }\n  const int suffix_dim_size = NumElements(op_context.indices) / prefix_dim_size;\n  const int depth = *op_context.depth->data.i32;\n\n  const T on_value = *GetTensorData<T>(op_context.on_value);\n  const T off_value = *GetTensorData<T>(op_context.off_value);\n\n  // View the indices as a matrix of size:\n  //     prefix_dim_size x suffix_dim_size\n  // View the output as a matrix of size:\n  //     prefix_dim_size x depth x suffix_dim_size\n  // Then the output is:\n  //     output(i, j, k) == (indices(i, k) == j) ? on : off\n  T* output = GetTensorData<T>(op_context.output);\n  const TI* indices = GetTensorData<TI>(op_context.indices);\n  for (int i = 0; i < prefix_dim_size; ++i) {\n    for (int j = 0; j < depth; ++j) {\n      for (int k = 0; k < suffix_dim_size; ++k, ++output) {\n        *output = static_cast<int>(indices[i * suffix_dim_size + k]) == j\n                      ? on_value\n                      : off_value;\n      }\n    }\n  }\n}",
        "func": "void OneHotComputeImpl(const OneHotContext& op_context) {\n  // prefix_dim_size == # of elements before the axis\n  // depth == # of elements per axis\n  // suffix_dim_size == # of elements after the axis\n  int prefix_dim_size = 1;\n  for (int i = 0; i < op_context.axis; ++i) {\n    prefix_dim_size *= op_context.indices->dims->data[i];\n  }\n  if (prefix_dim_size == 0) {\n    // If indices tensor is degenerate, return a degenerate tensor, just like\n    // TensorFlow does.\n    return;\n  }\n  const int suffix_dim_size = NumElements(op_context.indices) / prefix_dim_size;\n  const int depth = *op_context.depth->data.i32;\n\n  const T on_value = *GetTensorData<T>(op_context.on_value);\n  const T off_value = *GetTensorData<T>(op_context.off_value);\n\n  // View the indices as a matrix of size:\n  //     prefix_dim_size x suffix_dim_size\n  // View the output as a matrix of size:\n  //     prefix_dim_size x depth x suffix_dim_size\n  // Then the output is:\n  //     output(i, j, k) == (indices(i, k) == j) ? on : off\n  T* output = GetTensorData<T>(op_context.output);\n  const TI* indices = GetTensorData<TI>(op_context.indices);\n  for (int i = 0; i < prefix_dim_size; ++i) {\n    for (int j = 0; j < depth; ++j) {\n      for (int k = 0; k < suffix_dim_size; ++k, ++output) {\n        *output = static_cast<int>(indices[i * suffix_dim_size + k]) == j\n                      ? on_value\n                      : off_value;\n      }\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,11 @@\n   int prefix_dim_size = 1;\n   for (int i = 0; i < op_context.axis; ++i) {\n     prefix_dim_size *= op_context.indices->dims->data[i];\n+  }\n+  if (prefix_dim_size == 0) {\n+    // If indices tensor is degenerate, return a degenerate tensor, just like\n+    // TensorFlow does.\n+    return;\n   }\n   const int suffix_dim_size = NumElements(op_context.indices) / prefix_dim_size;\n   const int depth = *op_context.depth->data.i32;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  }",
                "  if (prefix_dim_size == 0) {",
                "    // If indices tensor is degenerate, return a degenerate tensor, just like",
                "    // TensorFlow does.",
                "    return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29602",
        "func_name": "tensorflow/EvalHybridPerChannel",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `DepthwiseConv` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8/tensorflow/lite/kernels/depthwise_conv.cc#L287-L288). An attacker can craft a model such that `input`'s fourth dimension would be 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
        "commit_title": "Prevent divisions by 0",
        "commit_text": " PiperOrigin-RevId: 371003153",
        "func_before": "TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n                                  TfLiteDepthwiseConvParams* params,\n                                  OpData* data, const TfLiteTensor* input,\n                                  const TfLiteTensor* filter,\n                                  const TfLiteTensor* bias,\n                                  TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n  const int batch_size = SizeOfDimension(input, 0);\n  TfLiteTensor* input_quantized;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &input_quantized));\n  int8_t* quantized_input_ptr_batch = input_quantized->data.int8;\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n  TfLiteTensor* input_offset_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_offset_index,\n                                     &input_offset_tensor));\n  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n\n  for (int b = 0; b < batch_size; ++b) {\n    const int offset = b * input_size;\n    tensor_utils::AsymmetricQuantizeFloats(\n        GetTensorData<float>(input) + offset, input_size,\n        quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],\n        &input_offset_ptr[b]);\n  }\n\n  DepthwiseParams op_params;\n  op_params.padding_type = PaddingType::kSame;\n  op_params.padding_values.width = data->padding.width;\n  op_params.padding_values.height = data->padding.height;\n  op_params.stride_width = params->stride_width;\n  op_params.stride_height = params->stride_height;\n  op_params.dilation_width_factor = params->dilation_width_factor;\n  op_params.dilation_height_factor = params->dilation_height_factor;\n  op_params.depth_multiplier = params->depth_multiplier;\n\n  op_params.weights_offset = 0;\n  op_params.float_activation_min = output_activation_min;\n  op_params.float_activation_max = output_activation_max;\n  const auto* affine_quantization =\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n  if (kernel_type == kReference) {\n    reference_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr);\n  } else {\n    optimized_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr, CpuBackendContext::GetFromContext(context));\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus EvalHybridPerChannel(TfLiteContext* context, TfLiteNode* node,\n                                  TfLiteDepthwiseConvParams* params,\n                                  OpData* data, const TfLiteTensor* input,\n                                  const TfLiteTensor* filter,\n                                  const TfLiteTensor* bias,\n                                  TfLiteTensor* output) {\n  float output_activation_min, output_activation_max;\n  CalculateActivationRange(params->activation, &output_activation_min,\n                           &output_activation_max);\n  const int batch_size = SizeOfDimension(input, 0);\n  TF_LITE_ENSURE(context, batch_size != 0);\n  const int input_size = NumElements(input) / batch_size;\n  TfLiteTensor* input_quantized;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_quantized_index,\n                                     &input_quantized));\n  int8_t* quantized_input_ptr_batch = input_quantized->data.int8;\n  TfLiteTensor* scaling_factors_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->scaling_factors_index,\n                                     &scaling_factors_tensor));\n  float* scaling_factors_ptr = GetTensorData<float>(scaling_factors_tensor);\n  TfLiteTensor* input_offset_tensor;\n  TF_LITE_ENSURE_OK(context,\n                    GetTemporarySafe(context, node, data->input_offset_index,\n                                     &input_offset_tensor));\n  int32_t* input_offset_ptr = GetTensorData<int32_t>(input_offset_tensor);\n\n  for (int b = 0; b < batch_size; ++b) {\n    const int offset = b * input_size;\n    tensor_utils::AsymmetricQuantizeFloats(\n        GetTensorData<float>(input) + offset, input_size,\n        quantized_input_ptr_batch + offset, &scaling_factors_ptr[b],\n        &input_offset_ptr[b]);\n  }\n\n  DepthwiseParams op_params;\n  op_params.padding_type = PaddingType::kSame;\n  op_params.padding_values.width = data->padding.width;\n  op_params.padding_values.height = data->padding.height;\n  op_params.stride_width = params->stride_width;\n  op_params.stride_height = params->stride_height;\n  op_params.dilation_width_factor = params->dilation_width_factor;\n  op_params.dilation_height_factor = params->dilation_height_factor;\n  op_params.depth_multiplier = params->depth_multiplier;\n\n  op_params.weights_offset = 0;\n  op_params.float_activation_min = output_activation_min;\n  op_params.float_activation_max = output_activation_max;\n  const auto* affine_quantization =\n      reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);\n  if (kernel_type == kReference) {\n    reference_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr);\n  } else {\n    optimized_integer_ops::DepthwiseConvHybridPerChannel(\n        op_params, scaling_factors_ptr, GetTensorShape(input),\n        quantized_input_ptr_batch, GetTensorShape(filter),\n        GetTensorData<int8>(filter), GetTensorShape(bias),\n        GetTensorData<float>(bias), GetTensorShape(output),\n        GetTensorData<float>(output), affine_quantization->scale->data,\n        input_offset_ptr, CpuBackendContext::GetFromContext(context));\n  }\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,8 +7,9 @@\n   float output_activation_min, output_activation_max;\n   CalculateActivationRange(params->activation, &output_activation_min,\n                            &output_activation_max);\n-  const int input_size = NumElements(input) / SizeOfDimension(input, 0);\n   const int batch_size = SizeOfDimension(input, 0);\n+  TF_LITE_ENSURE(context, batch_size != 0);\n+  const int input_size = NumElements(input) / batch_size;\n   TfLiteTensor* input_quantized;\n   TF_LITE_ENSURE_OK(context,\n                     GetTemporarySafe(context, node, data->input_quantized_index,",
        "diff_line_info": {
            "deleted_lines": [
                "  const int input_size = NumElements(input) / SizeOfDimension(input, 0);"
            ],
            "added_lines": [
                "  TF_LITE_ENSURE(context, batch_size != 0);",
                "  const int input_size = NumElements(input) / batch_size;"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29602",
        "func_name": "tensorflow/ComputeDepthMultiplier",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The implementation of the `DepthwiseConv` TFLite operator is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8/tensorflow/lite/kernels/depthwise_conv.cc#L287-L288). An attacker can craft a model such that `input`'s fourth dimension would be 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/cbda3c6b2dbbd3fbdc482ff8c0170a78ec2e97d0",
        "commit_title": "Prevent divisions by 0",
        "commit_text": " PiperOrigin-RevId: 371003153",
        "func_before": "TfLiteStatus ComputeDepthMultiplier(TfLiteContext* context,\n                                    const TfLiteTensor* input,\n                                    const TfLiteTensor* filter,\n                                    int16* depth_multiplier) {\n  int num_filter_channels = SizeOfDimension(filter, 3);\n  int num_input_channels = SizeOfDimension(input, 3);\n  TF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);\n\n  *depth_multiplier = num_filter_channels / num_input_channels;\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus ComputeDepthMultiplier(TfLiteContext* context,\n                                    const TfLiteTensor* input,\n                                    const TfLiteTensor* filter,\n                                    int16* depth_multiplier) {\n  int num_filter_channels = SizeOfDimension(filter, 3);\n  int num_input_channels = SizeOfDimension(input, 3);\n  TF_LITE_ENSURE(context, num_input_channels != 0);\n  TF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);\n  *depth_multiplier = num_filter_channels / num_input_channels;\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,8 +4,8 @@\n                                     int16* depth_multiplier) {\n   int num_filter_channels = SizeOfDimension(filter, 3);\n   int num_input_channels = SizeOfDimension(input, 3);\n+  TF_LITE_ENSURE(context, num_input_channels != 0);\n   TF_LITE_ENSURE_EQ(context, num_filter_channels % num_input_channels, 0);\n-\n   *depth_multiplier = num_filter_channels / num_input_channels;\n   return kTfLiteOk;\n }",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "  TF_LITE_ENSURE(context, num_input_channels != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-29604",
        "func_name": "tensorflow/Eval",
        "description": "TensorFlow is an end-to-end open source platform for machine learning. The TFLite implementation of hashtable lookup is vulnerable to a division by zero error(https://github.com/tensorflow/tensorflow/blob/1a8e885b864c818198a5b2c0cbbeca5a1e833bc8/tensorflow/lite/kernels/hashtable_lookup.cc#L114-L115) An attacker can craft a model such that `values`'s first dimension would be 0. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
        "git_url": "https://github.com/tensorflow/tensorflow/commit/5117e0851348065ed59c991562c0ec80d9193db2",
        "commit_title": "Prevent a division by 0",
        "commit_text": " PiperOrigin-RevId: 371007407",
        "func_before": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteTensor* hits;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 1, &hits));\n  const TfLiteTensor* lookup;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n  const TfLiteTensor* key;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &key));\n  const TfLiteTensor* value;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\n\n  const int num_rows = SizeOfDimension(value, 0);\n  const int row_bytes = value->bytes / num_rows;\n  void* pointer = nullptr;\n  DynamicBuffer buf;\n\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = -1;\n    pointer = bsearch(&(lookup->data.i32[i]), key->data.i32, num_rows,\n                      sizeof(int32_t), greater);\n    if (pointer != nullptr) {\n      idx = (reinterpret_cast<char*>(pointer) - (key->data.raw)) /\n            sizeof(int32_t);\n    }\n\n    if (idx >= num_rows || idx < 0) {\n      if (output->type == kTfLiteString) {\n        buf.AddString(nullptr, 0);\n      } else {\n        memset(output->data.raw + i * row_bytes, 0, row_bytes);\n      }\n      hits->data.uint8[i] = 0;\n    } else {\n      if (output->type == kTfLiteString) {\n        buf.AddString(GetString(value, idx));\n      } else {\n        memcpy(output->data.raw + i * row_bytes,\n               value->data.raw + idx * row_bytes, row_bytes);\n      }\n      hits->data.uint8[i] = 1;\n    }\n  }\n  if (output->type == kTfLiteString) {\n    buf.WriteToTensorAsVector(output);\n  }\n\n  return kTfLiteOk;\n}",
        "func": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteTensor* hits;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 1, &hits));\n  const TfLiteTensor* lookup;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &lookup));\n  const TfLiteTensor* key;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &key));\n  const TfLiteTensor* value;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\n\n  const int num_rows = SizeOfDimension(value, 0);\n  TF_LITE_ENSURE(context, num_rows != 0);\n  const int row_bytes = value->bytes / num_rows;\n  void* pointer = nullptr;\n  DynamicBuffer buf;\n\n  for (int i = 0; i < SizeOfDimension(lookup, 0); i++) {\n    int idx = -1;\n    pointer = bsearch(&(lookup->data.i32[i]), key->data.i32, num_rows,\n                      sizeof(int32_t), greater);\n    if (pointer != nullptr) {\n      idx = (reinterpret_cast<char*>(pointer) - (key->data.raw)) /\n            sizeof(int32_t);\n    }\n\n    if (idx >= num_rows || idx < 0) {\n      if (output->type == kTfLiteString) {\n        buf.AddString(nullptr, 0);\n      } else {\n        memset(output->data.raw + i * row_bytes, 0, row_bytes);\n      }\n      hits->data.uint8[i] = 0;\n    } else {\n      if (output->type == kTfLiteString) {\n        buf.AddString(GetString(value, idx));\n      } else {\n        memcpy(output->data.raw + i * row_bytes,\n               value->data.raw + idx * row_bytes, row_bytes);\n      }\n      hits->data.uint8[i] = 1;\n    }\n  }\n  if (output->type == kTfLiteString) {\n    buf.WriteToTensorAsVector(output);\n  }\n\n  return kTfLiteOk;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,6 +11,7 @@\n   TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &value));\n \n   const int num_rows = SizeOfDimension(value, 0);\n+  TF_LITE_ENSURE(context, num_rows != 0);\n   const int row_bytes = value->bytes / num_rows;\n   void* pointer = nullptr;\n   DynamicBuffer buf;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  TF_LITE_ENSURE(context, num_rows != 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27661",
        "func_name": "qemu/dwc2_handle_packet",
        "description": "A divide-by-zero issue was found in dwc2_handle_packet in hw/usb/hcd-dwc2.c in the hcd-dwc2 USB host controller emulation of QEMU. A malicious guest could use this flaw to crash the QEMU process on the host, resulting in a denial of service.",
        "git_url": "https://github.com/qemu/qemu/commit/bea2a9e3e00b275dc40cfa09c760c715b8753e03",
        "commit_title": "hw/usb/hcd-dwc2: fix divide-by-zero in dwc2_handle_packet()",
        "commit_text": " Check the value of mps to avoid potential divide-by-zero later in the function. Since HCCHAR_MPS is guest controllable, this prevents a malicious/buggy guest from crashing the QEMU process on the host. ",
        "func_before": "static void dwc2_handle_packet(DWC2State *s, uint32_t devadr, USBDevice *dev,\n                               USBEndpoint *ep, uint32_t index, bool send)\n{\n    DWC2Packet *p;\n    uint32_t hcchar = s->hreg1[index];\n    uint32_t hctsiz = s->hreg1[index + 4];\n    uint32_t hcdma = s->hreg1[index + 5];\n    uint32_t chan, epnum, epdir, eptype, mps, pid, pcnt, len, tlen, intr = 0;\n    uint32_t tpcnt, stsidx, actual = 0;\n    bool do_intr = false, done = false;\n\n    epnum = get_field(hcchar, HCCHAR_EPNUM);\n    epdir = get_bit(hcchar, HCCHAR_EPDIR);\n    eptype = get_field(hcchar, HCCHAR_EPTYPE);\n    mps = get_field(hcchar, HCCHAR_MPS);\n    pid = get_field(hctsiz, TSIZ_SC_MC_PID);\n    pcnt = get_field(hctsiz, TSIZ_PKTCNT);\n    len = get_field(hctsiz, TSIZ_XFERSIZE);\n    if (len > DWC2_MAX_XFER_SIZE) {\n        qemu_log_mask(LOG_GUEST_ERROR,\n                      \"%s: HCTSIZ transfer size too large\\n\", __func__);\n        return;\n    }\n\n    chan = index >> 3;\n    p = &s->packet[chan];\n\n    trace_usb_dwc2_handle_packet(chan, dev, &p->packet, epnum, types[eptype],\n                                 dirs[epdir], mps, len, pcnt);\n\n    if (eptype == USB_ENDPOINT_XFER_CONTROL && pid == TSIZ_SC_MC_PID_SETUP) {\n        pid = USB_TOKEN_SETUP;\n    } else {\n        pid = epdir ? USB_TOKEN_IN : USB_TOKEN_OUT;\n    }\n\n    if (send) {\n        tlen = len;\n        if (p->small) {\n            if (tlen > mps) {\n                tlen = mps;\n            }\n        }\n\n        if (pid != USB_TOKEN_IN) {\n            trace_usb_dwc2_memory_read(hcdma, tlen);\n            if (dma_memory_read(&s->dma_as, hcdma,\n                                s->usb_buf[chan], tlen) != MEMTX_OK) {\n                qemu_log_mask(LOG_GUEST_ERROR, \"%s: dma_memory_read failed\\n\",\n                              __func__);\n            }\n        }\n\n        usb_packet_init(&p->packet);\n        usb_packet_setup(&p->packet, pid, ep, 0, hcdma,\n                         pid != USB_TOKEN_IN, true);\n        usb_packet_addbuf(&p->packet, s->usb_buf[chan], tlen);\n        p->async = DWC2_ASYNC_NONE;\n        usb_handle_packet(dev, &p->packet);\n    } else {\n        tlen = p->len;\n    }\n\n    stsidx = -p->packet.status;\n    assert(stsidx < sizeof(pstatus) / sizeof(*pstatus));\n    actual = p->packet.actual_length;\n    trace_usb_dwc2_packet_status(pstatus[stsidx], actual);\n\nbabble:\n    if (p->packet.status != USB_RET_SUCCESS &&\n            p->packet.status != USB_RET_NAK &&\n            p->packet.status != USB_RET_STALL &&\n            p->packet.status != USB_RET_ASYNC) {\n        trace_usb_dwc2_packet_error(pstatus[stsidx]);\n    }\n\n    if (p->packet.status == USB_RET_ASYNC) {\n        trace_usb_dwc2_async_packet(&p->packet, chan, dev, epnum,\n                                    dirs[epdir], tlen);\n        usb_device_flush_ep_queue(dev, ep);\n        assert(p->async != DWC2_ASYNC_INFLIGHT);\n        p->devadr = devadr;\n        p->epnum = epnum;\n        p->epdir = epdir;\n        p->mps = mps;\n        p->pid = pid;\n        p->index = index;\n        p->pcnt = pcnt;\n        p->len = tlen;\n        p->async = DWC2_ASYNC_INFLIGHT;\n        p->needs_service = false;\n        return;\n    }\n\n    if (p->packet.status == USB_RET_SUCCESS) {\n        if (actual > tlen) {\n            p->packet.status = USB_RET_BABBLE;\n            goto babble;\n        }\n\n        if (pid == USB_TOKEN_IN) {\n            trace_usb_dwc2_memory_write(hcdma, actual);\n            if (dma_memory_write(&s->dma_as, hcdma, s->usb_buf[chan],\n                                 actual) != MEMTX_OK) {\n                qemu_log_mask(LOG_GUEST_ERROR, \"%s: dma_memory_write failed\\n\",\n                              __func__);\n            }\n        }\n\n        tpcnt = actual / mps;\n        if (actual % mps) {\n            tpcnt++;\n            if (pid == USB_TOKEN_IN) {\n                done = true;\n            }\n        }\n\n        pcnt -= tpcnt < pcnt ? tpcnt : pcnt;\n        set_field(&hctsiz, pcnt, TSIZ_PKTCNT);\n        len -= actual < len ? actual : len;\n        set_field(&hctsiz, len, TSIZ_XFERSIZE);\n        s->hreg1[index + 4] = hctsiz;\n        hcdma += actual;\n        s->hreg1[index + 5] = hcdma;\n\n        if (!pcnt || len == 0 || actual == 0) {\n            done = true;\n        }\n    } else {\n        intr |= pintr[stsidx];\n        if (p->packet.status == USB_RET_NAK &&\n            (eptype == USB_ENDPOINT_XFER_CONTROL ||\n             eptype == USB_ENDPOINT_XFER_BULK)) {\n            /*\n             * for ctrl/bulk, automatically retry on NAK,\n             * but send the interrupt anyway\n             */\n            intr &= ~HCINTMSK_RESERVED14_31;\n            s->hreg1[index + 2] |= intr;\n            do_intr = true;\n        } else {\n            intr |= HCINTMSK_CHHLTD;\n            done = true;\n        }\n    }\n\n    usb_packet_cleanup(&p->packet);\n\n    if (done) {\n        hcchar &= ~HCCHAR_CHENA;\n        s->hreg1[index] = hcchar;\n        if (!(intr & HCINTMSK_CHHLTD)) {\n            intr |= HCINTMSK_CHHLTD | HCINTMSK_XFERCOMPL;\n        }\n        intr &= ~HCINTMSK_RESERVED14_31;\n        s->hreg1[index + 2] |= intr;\n        p->needs_service = false;\n        trace_usb_dwc2_packet_done(pstatus[stsidx], actual, len, pcnt);\n        dwc2_update_hc_irq(s, index);\n        return;\n    }\n\n    p->devadr = devadr;\n    p->epnum = epnum;\n    p->epdir = epdir;\n    p->mps = mps;\n    p->pid = pid;\n    p->index = index;\n    p->pcnt = pcnt;\n    p->len = len;\n    p->needs_service = true;\n    trace_usb_dwc2_packet_next(pstatus[stsidx], len, pcnt);\n    if (do_intr) {\n        dwc2_update_hc_irq(s, index);\n    }\n}",
        "func": "static void dwc2_handle_packet(DWC2State *s, uint32_t devadr, USBDevice *dev,\n                               USBEndpoint *ep, uint32_t index, bool send)\n{\n    DWC2Packet *p;\n    uint32_t hcchar = s->hreg1[index];\n    uint32_t hctsiz = s->hreg1[index + 4];\n    uint32_t hcdma = s->hreg1[index + 5];\n    uint32_t chan, epnum, epdir, eptype, mps, pid, pcnt, len, tlen, intr = 0;\n    uint32_t tpcnt, stsidx, actual = 0;\n    bool do_intr = false, done = false;\n\n    epnum = get_field(hcchar, HCCHAR_EPNUM);\n    epdir = get_bit(hcchar, HCCHAR_EPDIR);\n    eptype = get_field(hcchar, HCCHAR_EPTYPE);\n    mps = get_field(hcchar, HCCHAR_MPS);\n    pid = get_field(hctsiz, TSIZ_SC_MC_PID);\n    pcnt = get_field(hctsiz, TSIZ_PKTCNT);\n    len = get_field(hctsiz, TSIZ_XFERSIZE);\n    if (len > DWC2_MAX_XFER_SIZE) {\n        qemu_log_mask(LOG_GUEST_ERROR,\n                      \"%s: HCTSIZ transfer size too large\\n\", __func__);\n        return;\n    }\n\n    chan = index >> 3;\n    p = &s->packet[chan];\n\n    trace_usb_dwc2_handle_packet(chan, dev, &p->packet, epnum, types[eptype],\n                                 dirs[epdir], mps, len, pcnt);\n\n    if (mps == 0) {\n        qemu_log_mask(LOG_GUEST_ERROR,\n                \"%s: Bad HCCHAR_MPS set to zero\\n\", __func__);\n        return;\n    }\n\n    if (eptype == USB_ENDPOINT_XFER_CONTROL && pid == TSIZ_SC_MC_PID_SETUP) {\n        pid = USB_TOKEN_SETUP;\n    } else {\n        pid = epdir ? USB_TOKEN_IN : USB_TOKEN_OUT;\n    }\n\n    if (send) {\n        tlen = len;\n        if (p->small) {\n            if (tlen > mps) {\n                tlen = mps;\n            }\n        }\n\n        if (pid != USB_TOKEN_IN) {\n            trace_usb_dwc2_memory_read(hcdma, tlen);\n            if (dma_memory_read(&s->dma_as, hcdma,\n                                s->usb_buf[chan], tlen) != MEMTX_OK) {\n                qemu_log_mask(LOG_GUEST_ERROR, \"%s: dma_memory_read failed\\n\",\n                              __func__);\n            }\n        }\n\n        usb_packet_init(&p->packet);\n        usb_packet_setup(&p->packet, pid, ep, 0, hcdma,\n                         pid != USB_TOKEN_IN, true);\n        usb_packet_addbuf(&p->packet, s->usb_buf[chan], tlen);\n        p->async = DWC2_ASYNC_NONE;\n        usb_handle_packet(dev, &p->packet);\n    } else {\n        tlen = p->len;\n    }\n\n    stsidx = -p->packet.status;\n    assert(stsidx < sizeof(pstatus) / sizeof(*pstatus));\n    actual = p->packet.actual_length;\n    trace_usb_dwc2_packet_status(pstatus[stsidx], actual);\n\nbabble:\n    if (p->packet.status != USB_RET_SUCCESS &&\n            p->packet.status != USB_RET_NAK &&\n            p->packet.status != USB_RET_STALL &&\n            p->packet.status != USB_RET_ASYNC) {\n        trace_usb_dwc2_packet_error(pstatus[stsidx]);\n    }\n\n    if (p->packet.status == USB_RET_ASYNC) {\n        trace_usb_dwc2_async_packet(&p->packet, chan, dev, epnum,\n                                    dirs[epdir], tlen);\n        usb_device_flush_ep_queue(dev, ep);\n        assert(p->async != DWC2_ASYNC_INFLIGHT);\n        p->devadr = devadr;\n        p->epnum = epnum;\n        p->epdir = epdir;\n        p->mps = mps;\n        p->pid = pid;\n        p->index = index;\n        p->pcnt = pcnt;\n        p->len = tlen;\n        p->async = DWC2_ASYNC_INFLIGHT;\n        p->needs_service = false;\n        return;\n    }\n\n    if (p->packet.status == USB_RET_SUCCESS) {\n        if (actual > tlen) {\n            p->packet.status = USB_RET_BABBLE;\n            goto babble;\n        }\n\n        if (pid == USB_TOKEN_IN) {\n            trace_usb_dwc2_memory_write(hcdma, actual);\n            if (dma_memory_write(&s->dma_as, hcdma, s->usb_buf[chan],\n                                 actual) != MEMTX_OK) {\n                qemu_log_mask(LOG_GUEST_ERROR, \"%s: dma_memory_write failed\\n\",\n                              __func__);\n            }\n        }\n\n        tpcnt = actual / mps;\n        if (actual % mps) {\n            tpcnt++;\n            if (pid == USB_TOKEN_IN) {\n                done = true;\n            }\n        }\n\n        pcnt -= tpcnt < pcnt ? tpcnt : pcnt;\n        set_field(&hctsiz, pcnt, TSIZ_PKTCNT);\n        len -= actual < len ? actual : len;\n        set_field(&hctsiz, len, TSIZ_XFERSIZE);\n        s->hreg1[index + 4] = hctsiz;\n        hcdma += actual;\n        s->hreg1[index + 5] = hcdma;\n\n        if (!pcnt || len == 0 || actual == 0) {\n            done = true;\n        }\n    } else {\n        intr |= pintr[stsidx];\n        if (p->packet.status == USB_RET_NAK &&\n            (eptype == USB_ENDPOINT_XFER_CONTROL ||\n             eptype == USB_ENDPOINT_XFER_BULK)) {\n            /*\n             * for ctrl/bulk, automatically retry on NAK,\n             * but send the interrupt anyway\n             */\n            intr &= ~HCINTMSK_RESERVED14_31;\n            s->hreg1[index + 2] |= intr;\n            do_intr = true;\n        } else {\n            intr |= HCINTMSK_CHHLTD;\n            done = true;\n        }\n    }\n\n    usb_packet_cleanup(&p->packet);\n\n    if (done) {\n        hcchar &= ~HCCHAR_CHENA;\n        s->hreg1[index] = hcchar;\n        if (!(intr & HCINTMSK_CHHLTD)) {\n            intr |= HCINTMSK_CHHLTD | HCINTMSK_XFERCOMPL;\n        }\n        intr &= ~HCINTMSK_RESERVED14_31;\n        s->hreg1[index + 2] |= intr;\n        p->needs_service = false;\n        trace_usb_dwc2_packet_done(pstatus[stsidx], actual, len, pcnt);\n        dwc2_update_hc_irq(s, index);\n        return;\n    }\n\n    p->devadr = devadr;\n    p->epnum = epnum;\n    p->epdir = epdir;\n    p->mps = mps;\n    p->pid = pid;\n    p->index = index;\n    p->pcnt = pcnt;\n    p->len = len;\n    p->needs_service = true;\n    trace_usb_dwc2_packet_next(pstatus[stsidx], len, pcnt);\n    if (do_intr) {\n        dwc2_update_hc_irq(s, index);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,6 +27,12 @@\n \n     trace_usb_dwc2_handle_packet(chan, dev, &p->packet, epnum, types[eptype],\n                                  dirs[epdir], mps, len, pcnt);\n+\n+    if (mps == 0) {\n+        qemu_log_mask(LOG_GUEST_ERROR,\n+                \"%s: Bad HCCHAR_MPS set to zero\\n\", __func__);\n+        return;\n+    }\n \n     if (eptype == USB_ENDPOINT_XFER_CONTROL && pid == TSIZ_SC_MC_PID_SETUP) {\n         pid = USB_TOKEN_SETUP;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (mps == 0) {",
                "        qemu_log_mask(LOG_GUEST_ERROR,",
                "                \"%s: Bad HCCHAR_MPS set to zero\\n\", __func__);",
                "        return;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-34069",
        "func_name": "justdan96/tsMuxer/AC3Codec::decodeDtsHdFrame",
        "description": "Divide-by-zero bug in tsMuxer 2.6.16 allows attackers to cause a Denial of Service (DoS) by running the application with a crafted file.",
        "git_url": "https://github.com/justdan96/tsMuxer/commit/7b616604693387bc501b20f7c89944cb3534e001",
        "commit_title": "[bug] Division by 0",
        "commit_text": " Early return when mh.group1_samplerate (Sample rate of first substream) is 0, to avoid division by 0 error.\r \r Solves issue #417 .",
        "func_before": "bool AC3Codec::decodeDtsHdFrame(uint8_t* buffer, uint8_t* end)\n{\n    if (end - buffer < 21)\n        return false;\n    int ratebits = 0;\n    BitStreamReader reader;\n    reader.setBuffer(buffer + 4, end);\n    if (reader.getBits(24) != HD_SYNC_WORLD) /* Sync words */\n        return false;\n    mh.stream_type = reader.getBits(8);\n\n    mh.subType = MLPHeaderInfo::stUnknown;\n    if (mh.stream_type == 0xbb)\n    {\n        mh.subType = MLPHeaderInfo::stMLP;\n        mh.group1_bits = mlp_quants[reader.getBits(4)];\n        mh.group2_bits = mlp_quants[reader.getBits(4)];\n        ratebits = reader.getBits(4);\n        mh.group1_samplerate = mlp_samplerate(ratebits);\n        mh.group2_samplerate = mlp_samplerate(reader.getBits(4));\n        reader.skipBits(11);\n        mh.channels_mlp = reader.getBits(5);\n        mh.channels = mlp_channels[mh.channels_mlp];\n    }\n    else if (mh.stream_type == 0xba)\n    {\n        mh.subType = MLPHeaderInfo::stTRUEHD;\n        mh.group1_bits = 24;  // TODO: Is this information actually conveyed anywhere?\n        mh.group2_bits = 0;\n        ratebits = reader.getBits(4);\n        mh.group1_samplerate = mlp_samplerate(ratebits);\n        mh.group2_samplerate = 0;\n        reader.skipBits(8);\n        mh.channels_thd_stream1 = reader.getBits(5);\n        reader.skipBits(2);\n        mh.channels_thd_stream2 = reader.getBits(13);\n\n        if (mh.channels_thd_stream2)\n            mh.channels = truehd_channels(mh.channels_thd_stream2);\n        else\n            mh.channels = truehd_channels(mh.channels_thd_stream1);\n    }\n    else\n        return false;\n\n    mh.access_unit_size = 40 << (ratebits & 7);\n    mh.access_unit_size_pow2 = 64 << (ratebits & 7);\n    mh.frame_duration_nano = mh.access_unit_size * 1000000000ll / mh.group1_samplerate;\n\n    reader.skipBits(32);\n    reader.skipBits(16);\n\n    mh.is_vbr = reader.getBit();\n    mh.peak_bitrate = (reader.getBits(15) * mh.group1_samplerate + 8) >> 4;\n    mh.num_substreams = reader.getBits(4);\n    // for (int i = 0; i < 11; ++i)\n    //\treader.skipBits(8);\n    // reader.skipBits(4);\n    // skip_bits_long(gb, 4 + 11 * 8);\n    return true;\n}",
        "func": "bool AC3Codec::decodeDtsHdFrame(uint8_t* buffer, uint8_t* end)\n{\n    if (end - buffer < 21)\n        return false;\n    int ratebits = 0;\n    BitStreamReader reader;\n    reader.setBuffer(buffer + 4, end);\n    if (reader.getBits(24) != HD_SYNC_WORLD) /* Sync words */\n        return false;\n    mh.stream_type = reader.getBits(8);\n\n    mh.subType = MLPHeaderInfo::stUnknown;\n    if (mh.stream_type == 0xbb)\n    {\n        mh.subType = MLPHeaderInfo::stMLP;\n        mh.group1_bits = mlp_quants[reader.getBits(4)];\n        mh.group2_bits = mlp_quants[reader.getBits(4)];\n        ratebits = reader.getBits(4);\n        mh.group1_samplerate = mlp_samplerate(ratebits);\n        if (mh.group1_samplerate == 0)\n            return false;\n        mh.group2_samplerate = mlp_samplerate(reader.getBits(4));\n        reader.skipBits(11);\n        mh.channels_mlp = reader.getBits(5);\n        mh.channels = mlp_channels[mh.channels_mlp];\n    }\n    else if (mh.stream_type == 0xba)\n    {\n        mh.subType = MLPHeaderInfo::stTRUEHD;\n        mh.group1_bits = 24;  // TODO: Is this information actually conveyed anywhere?\n        mh.group2_bits = 0;\n        ratebits = reader.getBits(4);\n        mh.group1_samplerate = mlp_samplerate(ratebits);\n        if (mh.group1_samplerate == 0)\n            return false;\n        mh.group2_samplerate = 0;\n        reader.skipBits(8);\n        mh.channels_thd_stream1 = reader.getBits(5);\n        reader.skipBits(2);\n        mh.channels_thd_stream2 = reader.getBits(13);\n\n        if (mh.channels_thd_stream2)\n            mh.channels = truehd_channels(mh.channels_thd_stream2);\n        else\n            mh.channels = truehd_channels(mh.channels_thd_stream1);\n    }\n    else\n        return false;\n\n    mh.access_unit_size = 40 << (ratebits & 7);\n    mh.access_unit_size_pow2 = 64 << (ratebits & 7);\n    mh.frame_duration_nano = mh.access_unit_size * 1000000000ll / mh.group1_samplerate;\n\n    reader.skipBits(32);\n    reader.skipBits(16);\n\n    mh.is_vbr = reader.getBit();\n    mh.peak_bitrate = (reader.getBits(15) * mh.group1_samplerate + 8) >> 4;\n    mh.num_substreams = reader.getBits(4);\n    // for (int i = 0; i < 11; ++i)\n    //\treader.skipBits(8);\n    // reader.skipBits(4);\n    // skip_bits_long(gb, 4 + 11 * 8);\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,6 +17,8 @@\n         mh.group2_bits = mlp_quants[reader.getBits(4)];\n         ratebits = reader.getBits(4);\n         mh.group1_samplerate = mlp_samplerate(ratebits);\n+        if (mh.group1_samplerate == 0)\n+            return false;\n         mh.group2_samplerate = mlp_samplerate(reader.getBits(4));\n         reader.skipBits(11);\n         mh.channels_mlp = reader.getBits(5);\n@@ -29,6 +31,8 @@\n         mh.group2_bits = 0;\n         ratebits = reader.getBits(4);\n         mh.group1_samplerate = mlp_samplerate(ratebits);\n+        if (mh.group1_samplerate == 0)\n+            return false;\n         mh.group2_samplerate = 0;\n         reader.skipBits(8);\n         mh.channels_thd_stream1 = reader.getBits(5);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (mh.group1_samplerate == 0)",
                "            return false;",
                "        if (mh.group1_samplerate == 0)",
                "            return false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2022-39318",
        "func_name": "FreeRDP/libusb_udev_isoch_transfer",
        "description": "FreeRDP is a free remote desktop protocol library and clients. Affected versions of FreeRDP are missing input validation in `urbdrc` channel. A malicious server can trick a FreeRDP based client to crash with division by zero. This issue has been addressed in version 2.9.0. All users are advised to upgrade. Users unable to upgrade should not use the `/usb` redirection switch.",
        "git_url": "https://github.com/FreeRDP/FreeRDP/commit/80adde17ddc4b596ed1dae0922a0c54ab3d4b8ea",
        "commit_title": "Fixed division by zero in urbdrc",
        "commit_text": " (cherry picked from commit 731f8419d04b481d7160de1f34062d630ed48765)",
        "func_before": "static int libusb_udev_isoch_transfer(IUDEVICE* idev, URBDRC_CHANNEL_CALLBACK* callback,\n                                      UINT32 MessageId, UINT32 RequestId, UINT32 EndpointAddress,\n                                      UINT32 TransferFlags, UINT32 StartFrame, UINT32 ErrorCount,\n                                      BOOL NoAck, const BYTE* packetDescriptorData,\n                                      UINT32 NumberOfPackets, UINT32 BufferSize, const BYTE* Buffer,\n                                      t_isoch_transfer_cb cb, UINT32 Timeout)\n{\n\tUINT32 iso_packet_size;\n\tUDEVICE* pdev = (UDEVICE*)idev;\n\tASYNC_TRANSFER_USER_DATA* user_data;\n\tstruct libusb_transfer* iso_transfer = NULL;\n\tURBDRC_PLUGIN* urbdrc;\n\tsize_t outSize = (NumberOfPackets * 12);\n\tuint32_t streamID = 0x40000000 | RequestId;\n\n\tif (!pdev || !pdev->urbdrc)\n\t\treturn -1;\n\n\turbdrc = pdev->urbdrc;\n\tuser_data = async_transfer_user_data_new(idev, MessageId, 48, BufferSize, Buffer,\n\t                                         outSize + 1024, NoAck, cb, callback);\n\n\tif (!user_data)\n\t\treturn -1;\n\n\tuser_data->ErrorCount = ErrorCount;\n\tuser_data->StartFrame = StartFrame;\n\n\tif (!Buffer)\n\t\tStream_Seek(user_data->data, (NumberOfPackets * 12));\n\n\tiso_packet_size = BufferSize / NumberOfPackets;\n\tiso_transfer = libusb_alloc_transfer(NumberOfPackets);\n\n\tif (iso_transfer == NULL)\n\t{\n\t\tWLog_Print(urbdrc->log, WLOG_ERROR, \"Error: libusb_alloc_transfer.\");\n\t\tasync_transfer_user_data_free(user_data);\n\t\treturn -1;\n\t}\n\n\t/**  process URB_FUNCTION_IOSCH_TRANSFER */\n\tlibusb_fill_iso_transfer(iso_transfer, pdev->libusb_handle, EndpointAddress,\n\t                         Stream_Pointer(user_data->data), BufferSize, NumberOfPackets,\n\t                         func_iso_callback, user_data, Timeout);\n\tset_stream_id_for_buffer(iso_transfer, streamID);\n\tlibusb_set_iso_packet_lengths(iso_transfer, iso_packet_size);\n\n\tif (ArrayList_Add(pdev->request_queue, iso_transfer) < 0)\n\t{\n\t\tWLog_Print(urbdrc->log, WLOG_WARN,\n\t\t           \"Failed to queue iso transfer, streamID %08\" PRIx32 \" already in use!\",\n\t\t           streamID);\n\t\trequest_free(iso_transfer);\n\t\treturn -1;\n\t}\n\treturn libusb_submit_transfer(iso_transfer);\n}",
        "func": "static int libusb_udev_isoch_transfer(IUDEVICE* idev, URBDRC_CHANNEL_CALLBACK* callback,\n                                      UINT32 MessageId, UINT32 RequestId, UINT32 EndpointAddress,\n                                      UINT32 TransferFlags, UINT32 StartFrame, UINT32 ErrorCount,\n                                      BOOL NoAck, const BYTE* packetDescriptorData,\n                                      UINT32 NumberOfPackets, UINT32 BufferSize, const BYTE* Buffer,\n                                      t_isoch_transfer_cb cb, UINT32 Timeout)\n{\n\tUINT32 iso_packet_size;\n\tUDEVICE* pdev = (UDEVICE*)idev;\n\tASYNC_TRANSFER_USER_DATA* user_data;\n\tstruct libusb_transfer* iso_transfer = NULL;\n\tURBDRC_PLUGIN* urbdrc;\n\tsize_t outSize = (NumberOfPackets * 12);\n\tuint32_t streamID = 0x40000000 | RequestId;\n\n\tif (!pdev || !pdev->urbdrc)\n\t\treturn -1;\n\n\turbdrc = pdev->urbdrc;\n\tuser_data = async_transfer_user_data_new(idev, MessageId, 48, BufferSize, Buffer,\n\t                                         outSize + 1024, NoAck, cb, callback);\n\n\tif (!user_data)\n\t\treturn -1;\n\n\tuser_data->ErrorCount = ErrorCount;\n\tuser_data->StartFrame = StartFrame;\n\n\tif (!Buffer)\n\t\tStream_Seek(user_data->data, (NumberOfPackets * 12));\n\n\tif (NumberOfPackets > 0)\n\t{\n\t\tiso_packet_size = BufferSize / NumberOfPackets;\n\t\tiso_transfer = libusb_alloc_transfer((int)NumberOfPackets);\n\t}\n\n\tif (iso_transfer == NULL)\n\t{\n\t\tWLog_Print(urbdrc->log, WLOG_ERROR,\n\t\t           \"Error: libusb_alloc_transfer [NumberOfPackets=%\" PRIu32 \", BufferSize=%\" PRIu32\n\t\t           \" ]\",\n\t\t           NumberOfPackets, BufferSize);\n\t\tasync_transfer_user_data_free(user_data);\n\t\treturn -1;\n\t}\n\n\t/**  process URB_FUNCTION_IOSCH_TRANSFER */\n\tlibusb_fill_iso_transfer(iso_transfer, pdev->libusb_handle, EndpointAddress,\n\t                         Stream_Pointer(user_data->data), BufferSize, NumberOfPackets,\n\t                         func_iso_callback, user_data, Timeout);\n\tset_stream_id_for_buffer(iso_transfer, streamID);\n\tlibusb_set_iso_packet_lengths(iso_transfer, iso_packet_size);\n\n\tif (ArrayList_Add(pdev->request_queue, iso_transfer) < 0)\n\t{\n\t\tWLog_Print(urbdrc->log, WLOG_WARN,\n\t\t           \"Failed to queue iso transfer, streamID %08\" PRIx32 \" already in use!\",\n\t\t           streamID);\n\t\trequest_free(iso_transfer);\n\t\treturn -1;\n\t}\n\treturn libusb_submit_transfer(iso_transfer);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,12 +29,18 @@\n \tif (!Buffer)\n \t\tStream_Seek(user_data->data, (NumberOfPackets * 12));\n \n-\tiso_packet_size = BufferSize / NumberOfPackets;\n-\tiso_transfer = libusb_alloc_transfer(NumberOfPackets);\n+\tif (NumberOfPackets > 0)\n+\t{\n+\t\tiso_packet_size = BufferSize / NumberOfPackets;\n+\t\tiso_transfer = libusb_alloc_transfer((int)NumberOfPackets);\n+\t}\n \n \tif (iso_transfer == NULL)\n \t{\n-\t\tWLog_Print(urbdrc->log, WLOG_ERROR, \"Error: libusb_alloc_transfer.\");\n+\t\tWLog_Print(urbdrc->log, WLOG_ERROR,\n+\t\t           \"Error: libusb_alloc_transfer [NumberOfPackets=%\" PRIu32 \", BufferSize=%\" PRIu32\n+\t\t           \" ]\",\n+\t\t           NumberOfPackets, BufferSize);\n \t\tasync_transfer_user_data_free(user_data);\n \t\treturn -1;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tiso_packet_size = BufferSize / NumberOfPackets;",
                "\tiso_transfer = libusb_alloc_transfer(NumberOfPackets);",
                "\t\tWLog_Print(urbdrc->log, WLOG_ERROR, \"Error: libusb_alloc_transfer.\");"
            ],
            "added_lines": [
                "\tif (NumberOfPackets > 0)",
                "\t{",
                "\t\tiso_packet_size = BufferSize / NumberOfPackets;",
                "\t\tiso_transfer = libusb_alloc_transfer((int)NumberOfPackets);",
                "\t}",
                "\t\tWLog_Print(urbdrc->log, WLOG_ERROR,",
                "\t\t           \"Error: libusb_alloc_transfer [NumberOfPackets=%\" PRIu32 \", BufferSize=%\" PRIu32",
                "\t\t           \" ]\",",
                "\t\t           NumberOfPackets, BufferSize);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-1127",
        "func_name": "vim/scrolldown",
        "description": "Divide By Zero in GitHub repository vim/vim prior to 9.0.1367.",
        "git_url": "https://github.com/vim/vim/commit/e0f869196930ef5f25a0ac41c9215b09c9ce2d3c",
        "commit_title": "patch 9.0.1367: divide by zero in zero-width window",
        "commit_text": " Problem:    Divide by zero in zero-width window. Solution:   Check the width is positive.",
        "func_before": "void\nscrolldown(\n    long\tline_count,\n    int\t\tbyfold UNUSED)\t// TRUE: count a closed fold as one line\n{\n    long\tdone = 0;\t// total # of physical lines done\n    int\t\twrow;\n    int\t\tmoved = FALSE;\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n    int\t\twidth1 = 0;\n    int\t\twidth2 = 0;\n\n    if (do_sms)\n    {\n\twidth1 = curwin->w_width - curwin_col_off();\n\twidth2 = width1 + curwin_col_off2();\n    }\n\n#ifdef FEAT_FOLDING\n    linenr_T\tfirst;\n\n    // Make sure w_topline is at the first of a sequence of folded lines.\n    (void)hasFolding(curwin->w_topline, &curwin->w_topline, NULL);\n#endif\n    validate_cursor();\t\t// w_wrow needs to be valid\n    for (int todo = line_count; todo > 0; --todo)\n    {\n#ifdef FEAT_DIFF\n\tif (curwin->w_topfill < diff_check(curwin, curwin->w_topline)\n\t\t&& curwin->w_topfill < curwin->w_height - 1)\n\t{\n\t    ++curwin->w_topfill;\n\t    ++done;\n\t}\n\telse\n#endif\n\t{\n\t    // break when at the very top\n\t    if (curwin->w_topline == 1\n\t\t\t\t   && (!do_sms || curwin->w_skipcol < width1))\n\t\tbreak;\n\t    if (do_sms && curwin->w_skipcol >= width1)\n\t    {\n\t\t// scroll a screen line down\n\t\tif (curwin->w_skipcol >= width1 + width2)\n\t\t    curwin->w_skipcol -= width2;\n\t\telse\n\t\t    curwin->w_skipcol -= width1;\n\t\tredraw_later(UPD_NOT_VALID);\n\t\t++done;\n\t    }\n\t    else\n\t    {\n\t\t// scroll a text line down\n\t\t--curwin->w_topline;\n\t\tcurwin->w_skipcol = 0;\n#ifdef FEAT_DIFF\n\t\tcurwin->w_topfill = 0;\n#endif\n#ifdef FEAT_FOLDING\n\t\t// A sequence of folded lines only counts for one logical line\n\t\tif (hasFolding(curwin->w_topline, &first, NULL))\n\t\t{\n\t\t    ++done;\n\t\t    if (!byfold)\n\t\t\ttodo -= curwin->w_topline - first - 1;\n\t\t    curwin->w_botline -= curwin->w_topline - first;\n\t\t    curwin->w_topline = first;\n\t\t}\n\t\telse\n#endif\n\t\tif (do_sms)\n\t\t{\n\t\t    int size = win_linetabsize(curwin, curwin->w_topline,\n\t\t\t\t   ml_get(curwin->w_topline), (colnr_T)MAXCOL);\n\t\t    if (size > width1)\n\t\t    {\n\t\t\tcurwin->w_skipcol = width1;\n\t\t\tsize -= width1;\n\t\t\tredraw_later(UPD_NOT_VALID);\n\t\t    }\n\t\t    while (size > width2)\n\t\t    {\n\t\t\tcurwin->w_skipcol += width2;\n\t\t\tsize -= width2;\n\t\t    }\n\t\t    ++done;\n\t\t}\n\t\telse\n\t\t    done += PLINES_NOFILL(curwin->w_topline);\n\t    }\n\t}\n\t--curwin->w_botline;\t\t// approximate w_botline\n\tinvalidate_botline();\n    }\n    curwin->w_wrow += done;\t\t// keep w_wrow updated\n    curwin->w_cline_row += done;\t// keep w_cline_row updated\n\n#ifdef FEAT_DIFF\n    if (curwin->w_cursor.lnum == curwin->w_topline)\n\tcurwin->w_cline_row = 0;\n    check_topfill(curwin, TRUE);\n#endif\n\n    /*\n     * Compute the row number of the last row of the cursor line\n     * and move the cursor onto the displayed part of the window.\n     */\n    wrow = curwin->w_wrow;\n    if (curwin->w_p_wrap && curwin->w_width != 0)\n    {\n\tvalidate_virtcol();\n\tvalidate_cheight();\n\twrow += curwin->w_cline_height - 1 -\n\t    curwin->w_virtcol / curwin->w_width;\n    }\n    while (wrow >= curwin->w_height && curwin->w_cursor.lnum > 1)\n    {\n#ifdef FEAT_FOLDING\n\tif (hasFolding(curwin->w_cursor.lnum, &first, NULL))\n\t{\n\t    --wrow;\n\t    if (first == 1)\n\t\tcurwin->w_cursor.lnum = 1;\n\t    else\n\t\tcurwin->w_cursor.lnum = first - 1;\n\t}\n\telse\n#endif\n\t    wrow -= plines(curwin->w_cursor.lnum--);\n\tcurwin->w_valid &=\n\t      ~(VALID_WROW|VALID_WCOL|VALID_CHEIGHT|VALID_CROW|VALID_VIRTCOL);\n\tmoved = TRUE;\n    }\n    if (moved)\n    {\n#ifdef FEAT_FOLDING\n\t// Move cursor to first line of closed fold.\n\tfoldAdjustCursor();\n#endif\n\tcoladvance(curwin->w_curswant);\n    }\n\n    if (curwin->w_cursor.lnum == curwin->w_topline && do_sms)\n    {\n\tlong\tso = get_scrolloff_value();\n\tint\tscrolloff_cols = so == 0 ? 0 : width1 + (so - 1) * width2;\n\n\t// make sure the cursor is in the visible text\n\tvalidate_virtcol();\n\tint col = curwin->w_virtcol - curwin->w_skipcol + scrolloff_cols;\n\tint row = 0;\n\tif (col >= width1)\n\t{\n\t    col -= width1;\n\t    ++row;\n\t}\n\tif (col > width2)\n\t{\n\t    row += col / width2;\n\t    col = col % width2;\n\t}\n\tif (row >= curwin->w_height)\n\t{\n\t    curwin->w_curswant = curwin->w_virtcol\n\t\t\t\t       - (row - curwin->w_height + 1) * width2;\n\t    coladvance(curwin->w_curswant);\n\t}\n    }\n}",
        "func": "void\nscrolldown(\n    long\tline_count,\n    int\t\tbyfold UNUSED)\t// TRUE: count a closed fold as one line\n{\n    long\tdone = 0;\t// total # of physical lines done\n    int\t\twrow;\n    int\t\tmoved = FALSE;\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n    int\t\twidth1 = 0;\n    int\t\twidth2 = 0;\n\n    if (do_sms)\n    {\n\twidth1 = curwin->w_width - curwin_col_off();\n\twidth2 = width1 + curwin_col_off2();\n    }\n\n#ifdef FEAT_FOLDING\n    linenr_T\tfirst;\n\n    // Make sure w_topline is at the first of a sequence of folded lines.\n    (void)hasFolding(curwin->w_topline, &curwin->w_topline, NULL);\n#endif\n    validate_cursor();\t\t// w_wrow needs to be valid\n    for (int todo = line_count; todo > 0; --todo)\n    {\n#ifdef FEAT_DIFF\n\tif (curwin->w_topfill < diff_check(curwin, curwin->w_topline)\n\t\t&& curwin->w_topfill < curwin->w_height - 1)\n\t{\n\t    ++curwin->w_topfill;\n\t    ++done;\n\t}\n\telse\n#endif\n\t{\n\t    // break when at the very top\n\t    if (curwin->w_topline == 1\n\t\t\t\t   && (!do_sms || curwin->w_skipcol < width1))\n\t\tbreak;\n\t    if (do_sms && curwin->w_skipcol >= width1)\n\t    {\n\t\t// scroll a screen line down\n\t\tif (curwin->w_skipcol >= width1 + width2)\n\t\t    curwin->w_skipcol -= width2;\n\t\telse\n\t\t    curwin->w_skipcol -= width1;\n\t\tredraw_later(UPD_NOT_VALID);\n\t\t++done;\n\t    }\n\t    else\n\t    {\n\t\t// scroll a text line down\n\t\t--curwin->w_topline;\n\t\tcurwin->w_skipcol = 0;\n#ifdef FEAT_DIFF\n\t\tcurwin->w_topfill = 0;\n#endif\n#ifdef FEAT_FOLDING\n\t\t// A sequence of folded lines only counts for one logical line\n\t\tif (hasFolding(curwin->w_topline, &first, NULL))\n\t\t{\n\t\t    ++done;\n\t\t    if (!byfold)\n\t\t\ttodo -= curwin->w_topline - first - 1;\n\t\t    curwin->w_botline -= curwin->w_topline - first;\n\t\t    curwin->w_topline = first;\n\t\t}\n\t\telse\n#endif\n\t\tif (do_sms)\n\t\t{\n\t\t    int size = win_linetabsize(curwin, curwin->w_topline,\n\t\t\t\t   ml_get(curwin->w_topline), (colnr_T)MAXCOL);\n\t\t    if (size > width1)\n\t\t    {\n\t\t\tcurwin->w_skipcol = width1;\n\t\t\tsize -= width1;\n\t\t\tredraw_later(UPD_NOT_VALID);\n\t\t    }\n\t\t    while (size > width2)\n\t\t    {\n\t\t\tcurwin->w_skipcol += width2;\n\t\t\tsize -= width2;\n\t\t    }\n\t\t    ++done;\n\t\t}\n\t\telse\n\t\t    done += PLINES_NOFILL(curwin->w_topline);\n\t    }\n\t}\n\t--curwin->w_botline;\t\t// approximate w_botline\n\tinvalidate_botline();\n    }\n    curwin->w_wrow += done;\t\t// keep w_wrow updated\n    curwin->w_cline_row += done;\t// keep w_cline_row updated\n\n#ifdef FEAT_DIFF\n    if (curwin->w_cursor.lnum == curwin->w_topline)\n\tcurwin->w_cline_row = 0;\n    check_topfill(curwin, TRUE);\n#endif\n\n    /*\n     * Compute the row number of the last row of the cursor line\n     * and move the cursor onto the displayed part of the window.\n     */\n    wrow = curwin->w_wrow;\n    if (curwin->w_p_wrap && curwin->w_width != 0)\n    {\n\tvalidate_virtcol();\n\tvalidate_cheight();\n\twrow += curwin->w_cline_height - 1 -\n\t    curwin->w_virtcol / curwin->w_width;\n    }\n    while (wrow >= curwin->w_height && curwin->w_cursor.lnum > 1)\n    {\n#ifdef FEAT_FOLDING\n\tif (hasFolding(curwin->w_cursor.lnum, &first, NULL))\n\t{\n\t    --wrow;\n\t    if (first == 1)\n\t\tcurwin->w_cursor.lnum = 1;\n\t    else\n\t\tcurwin->w_cursor.lnum = first - 1;\n\t}\n\telse\n#endif\n\t    wrow -= plines(curwin->w_cursor.lnum--);\n\tcurwin->w_valid &=\n\t      ~(VALID_WROW|VALID_WCOL|VALID_CHEIGHT|VALID_CROW|VALID_VIRTCOL);\n\tmoved = TRUE;\n    }\n    if (moved)\n    {\n#ifdef FEAT_FOLDING\n\t// Move cursor to first line of closed fold.\n\tfoldAdjustCursor();\n#endif\n\tcoladvance(curwin->w_curswant);\n    }\n\n    if (curwin->w_cursor.lnum == curwin->w_topline && do_sms)\n    {\n\tlong\tso = get_scrolloff_value();\n\tint\tscrolloff_cols = so == 0 ? 0 : width1 + (so - 1) * width2;\n\n\t// make sure the cursor is in the visible text\n\tvalidate_virtcol();\n\tint col = curwin->w_virtcol - curwin->w_skipcol + scrolloff_cols;\n\tint row = 0;\n\tif (col >= width1)\n\t{\n\t    col -= width1;\n\t    ++row;\n\t}\n\tif (col > width2 && width2 > 0)\n\t{\n\t    row += col / width2;\n\t    col = col % width2;\n\t}\n\tif (row >= curwin->w_height)\n\t{\n\t    curwin->w_curswant = curwin->w_virtcol\n\t\t\t\t       - (row - curwin->w_height + 1) * width2;\n\t    coladvance(curwin->w_curswant);\n\t}\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -155,7 +155,7 @@\n \t    col -= width1;\n \t    ++row;\n \t}\n-\tif (col > width2)\n+\tif (col > width2 && width2 > 0)\n \t{\n \t    row += col / width2;\n \t    col = col % width2;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (col > width2)"
            ],
            "added_lines": [
                "\tif (col > width2 && width2 > 0)"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-31085",
        "func_name": "torvalds/linux/ubi_attach_mtd_dev",
        "description": "An issue was discovered in drivers/mtd/ubi/cdev.c in the Linux kernel 6.2. There is a divide-by-zero error in do_div(sz,mtd->erasesize), used indirectly by ctrl_cdev_ioctl, when mtd->erasesize is 0.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?h=017c73a34a661a861712f7cc1393a123e5b2208c",
        "commit_title": "There exists mtd devices with zero erasesize, which will trigger a",
        "commit_text": "divide-by-zero exception while attaching ubi device. Fix it by refusing attaching if mtd's erasesize is 0.  Link: https://lore.kernel.org/lkml/977347543.226888.1682011999468.JavaMail.zimbra@nod.at/T/ ",
        "func_before": "int ubi_attach_mtd_dev(struct mtd_info *mtd, int ubi_num,\n\t\t       int vid_hdr_offset, int max_beb_per1024, bool disable_fm)\n{\n\tstruct ubi_device *ubi;\n\tint i, err;\n\n\tif (max_beb_per1024 < 0 || max_beb_per1024 > MAX_MTD_UBI_BEB_LIMIT)\n\t\treturn -EINVAL;\n\n\tif (!max_beb_per1024)\n\t\tmax_beb_per1024 = CONFIG_MTD_UBI_BEB_LIMIT;\n\n\t/*\n\t * Check if we already have the same MTD device attached.\n\t *\n\t * Note, this function assumes that UBI devices creations and deletions\n\t * are serialized, so it does not take the &ubi_devices_lock.\n\t */\n\tfor (i = 0; i < UBI_MAX_DEVICES; i++) {\n\t\tubi = ubi_devices[i];\n\t\tif (ubi && mtd->index == ubi->mtd->index) {\n\t\t\tpr_err(\"ubi: mtd%d is already attached to ubi%d\\n\",\n\t\t\t\tmtd->index, i);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\t/*\n\t * Make sure this MTD device is not emulated on top of an UBI volume\n\t * already. Well, generally this recursion works fine, but there are\n\t * different problems like the UBI module takes a reference to itself\n\t * by attaching (and thus, opening) the emulated MTD device. This\n\t * results in inability to unload the module. And in general it makes\n\t * no sense to attach emulated MTD devices, so we prohibit this.\n\t */\n\tif (mtd->type == MTD_UBIVOLUME) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - it is already emulated on top of UBI\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * Both UBI and UBIFS have been designed for SLC NAND and NOR flashes.\n\t * MLC NAND is different and needs special care, otherwise UBI or UBIFS\n\t * will die soon and you will lose all your data.\n\t * Relax this rule if the partition we're attaching to operates in SLC\n\t * mode.\n\t */\n\tif (mtd->type == MTD_MLCNANDFLASH &&\n\t    !(mtd->flags & MTD_SLC_ON_MLC_EMULATION)) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - MLC NAND is not supported\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ubi_num == UBI_DEV_NUM_AUTO) {\n\t\t/* Search for an empty slot in the @ubi_devices array */\n\t\tfor (ubi_num = 0; ubi_num < UBI_MAX_DEVICES; ubi_num++)\n\t\t\tif (!ubi_devices[ubi_num])\n\t\t\t\tbreak;\n\t\tif (ubi_num == UBI_MAX_DEVICES) {\n\t\t\tpr_err(\"ubi: only %d UBI devices may be created\\n\",\n\t\t\t\tUBI_MAX_DEVICES);\n\t\t\treturn -ENFILE;\n\t\t}\n\t} else {\n\t\tif (ubi_num >= UBI_MAX_DEVICES)\n\t\t\treturn -EINVAL;\n\n\t\t/* Make sure ubi_num is not busy */\n\t\tif (ubi_devices[ubi_num]) {\n\t\t\tpr_err(\"ubi: ubi%i already exists\\n\", ubi_num);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tubi = kzalloc(sizeof(struct ubi_device), GFP_KERNEL);\n\tif (!ubi)\n\t\treturn -ENOMEM;\n\n\tdevice_initialize(&ubi->dev);\n\tubi->dev.release = dev_release;\n\tubi->dev.class = &ubi_class;\n\tubi->dev.groups = ubi_dev_groups;\n\tubi->dev.parent = &mtd->dev;\n\n\tubi->mtd = mtd;\n\tubi->ubi_num = ubi_num;\n\tubi->vid_hdr_offset = vid_hdr_offset;\n\tubi->autoresize_vol_id = -1;\n\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\tubi->fm_pool.used = ubi->fm_pool.size = 0;\n\tubi->fm_wl_pool.used = ubi->fm_wl_pool.size = 0;\n\n\t/*\n\t * fm_pool.max_size is 5% of the total number of PEBs but it's also\n\t * between UBI_FM_MAX_POOL_SIZE and UBI_FM_MIN_POOL_SIZE.\n\t */\n\tubi->fm_pool.max_size = min(((int)mtd_div_by_eb(ubi->mtd->size,\n\t\tubi->mtd) / 100) * 5, UBI_FM_MAX_POOL_SIZE);\n\tubi->fm_pool.max_size = max(ubi->fm_pool.max_size,\n\t\tUBI_FM_MIN_POOL_SIZE);\n\n\tubi->fm_wl_pool.max_size = ubi->fm_pool.max_size / 2;\n\tubi->fm_disabled = (!fm_autoconvert || disable_fm) ? 1 : 0;\n\tif (fm_debug)\n\t\tubi_enable_dbg_chk_fastmap(ubi);\n\n\tif (!ubi->fm_disabled && (int)mtd_div_by_eb(ubi->mtd->size, ubi->mtd)\n\t    <= UBI_FM_MAX_START) {\n\t\tubi_err(ubi, \"More than %i PEBs are needed for fastmap, sorry.\",\n\t\t\tUBI_FM_MAX_START);\n\t\tubi->fm_disabled = 1;\n\t}\n\n\tubi_msg(ubi, \"default fastmap pool size: %d\", ubi->fm_pool.max_size);\n\tubi_msg(ubi, \"default fastmap WL pool size: %d\",\n\t\tubi->fm_wl_pool.max_size);\n#else\n\tubi->fm_disabled = 1;\n#endif\n\tmutex_init(&ubi->buf_mutex);\n\tmutex_init(&ubi->ckvol_mutex);\n\tmutex_init(&ubi->device_mutex);\n\tspin_lock_init(&ubi->volumes_lock);\n\tinit_rwsem(&ubi->fm_protect);\n\tinit_rwsem(&ubi->fm_eba_sem);\n\n\tubi_msg(ubi, \"attaching mtd%d\", mtd->index);\n\n\terr = io_init(ubi, max_beb_per1024);\n\tif (err)\n\t\tgoto out_free;\n\n\terr = -ENOMEM;\n\tubi->peb_buf = vmalloc(ubi->peb_size);\n\tif (!ubi->peb_buf)\n\t\tgoto out_free;\n\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\tubi->fm_size = ubi_calc_fm_size(ubi);\n\tubi->fm_buf = vzalloc(ubi->fm_size);\n\tif (!ubi->fm_buf)\n\t\tgoto out_free;\n#endif\n\terr = ubi_attach(ubi, disable_fm ? 1 : 0);\n\tif (err) {\n\t\tubi_err(ubi, \"failed to attach mtd%d, error %d\",\n\t\t\tmtd->index, err);\n\t\tgoto out_free;\n\t}\n\n\tif (ubi->autoresize_vol_id != -1) {\n\t\terr = autoresize(ubi, ubi->autoresize_vol_id);\n\t\tif (err)\n\t\t\tgoto out_detach;\n\t}\n\n\terr = uif_init(ubi);\n\tif (err)\n\t\tgoto out_detach;\n\n\terr = ubi_debugfs_init_dev(ubi);\n\tif (err)\n\t\tgoto out_uif;\n\n\tubi->bgt_thread = kthread_create(ubi_thread, ubi, \"%s\", ubi->bgt_name);\n\tif (IS_ERR(ubi->bgt_thread)) {\n\t\terr = PTR_ERR(ubi->bgt_thread);\n\t\tubi_err(ubi, \"cannot spawn \\\"%s\\\", error %d\",\n\t\t\tubi->bgt_name, err);\n\t\tgoto out_debugfs;\n\t}\n\n\tubi_msg(ubi, \"attached mtd%d (name \\\"%s\\\", size %llu MiB)\",\n\t\tmtd->index, mtd->name, ubi->flash_size >> 20);\n\tubi_msg(ubi, \"PEB size: %d bytes (%d KiB), LEB size: %d bytes\",\n\t\tubi->peb_size, ubi->peb_size >> 10, ubi->leb_size);\n\tubi_msg(ubi, \"min./max. I/O unit sizes: %d/%d, sub-page size %d\",\n\t\tubi->min_io_size, ubi->max_write_size, ubi->hdrs_min_io_size);\n\tubi_msg(ubi, \"VID header offset: %d (aligned %d), data offset: %d\",\n\t\tubi->vid_hdr_offset, ubi->vid_hdr_aloffset, ubi->leb_start);\n\tubi_msg(ubi, \"good PEBs: %d, bad PEBs: %d, corrupted PEBs: %d\",\n\t\tubi->good_peb_count, ubi->bad_peb_count, ubi->corr_peb_count);\n\tubi_msg(ubi, \"user volume: %d, internal volumes: %d, max. volumes count: %d\",\n\t\tubi->vol_count - UBI_INT_VOL_COUNT, UBI_INT_VOL_COUNT,\n\t\tubi->vtbl_slots);\n\tubi_msg(ubi, \"max/mean erase counter: %d/%d, WL threshold: %d, image sequence number: %u\",\n\t\tubi->max_ec, ubi->mean_ec, CONFIG_MTD_UBI_WL_THRESHOLD,\n\t\tubi->image_seq);\n\tubi_msg(ubi, \"available PEBs: %d, total reserved PEBs: %d, PEBs reserved for bad PEB handling: %d\",\n\t\tubi->avail_pebs, ubi->rsvd_pebs, ubi->beb_rsvd_pebs);\n\n\t/*\n\t * The below lock makes sure we do not race with 'ubi_thread()' which\n\t * checks @ubi->thread_enabled. Otherwise we may fail to wake it up.\n\t */\n\tspin_lock(&ubi->wl_lock);\n\tubi->thread_enabled = 1;\n\twake_up_process(ubi->bgt_thread);\n\tspin_unlock(&ubi->wl_lock);\n\n\tubi_devices[ubi_num] = ubi;\n\tubi_notify_all(ubi, UBI_VOLUME_ADDED, NULL);\n\treturn ubi_num;\n\nout_debugfs:\n\tubi_debugfs_exit_dev(ubi);\nout_uif:\n\tuif_close(ubi);\nout_detach:\n\tubi_wl_close(ubi);\n\tubi_free_all_volumes(ubi);\n\tvfree(ubi->vtbl);\nout_free:\n\tvfree(ubi->peb_buf);\n\tvfree(ubi->fm_buf);\n\tput_device(&ubi->dev);\n\treturn err;\n}",
        "func": "int ubi_attach_mtd_dev(struct mtd_info *mtd, int ubi_num,\n\t\t       int vid_hdr_offset, int max_beb_per1024, bool disable_fm)\n{\n\tstruct ubi_device *ubi;\n\tint i, err;\n\n\tif (max_beb_per1024 < 0 || max_beb_per1024 > MAX_MTD_UBI_BEB_LIMIT)\n\t\treturn -EINVAL;\n\n\tif (!max_beb_per1024)\n\t\tmax_beb_per1024 = CONFIG_MTD_UBI_BEB_LIMIT;\n\n\t/*\n\t * Check if we already have the same MTD device attached.\n\t *\n\t * Note, this function assumes that UBI devices creations and deletions\n\t * are serialized, so it does not take the &ubi_devices_lock.\n\t */\n\tfor (i = 0; i < UBI_MAX_DEVICES; i++) {\n\t\tubi = ubi_devices[i];\n\t\tif (ubi && mtd->index == ubi->mtd->index) {\n\t\t\tpr_err(\"ubi: mtd%d is already attached to ubi%d\\n\",\n\t\t\t\tmtd->index, i);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\t/*\n\t * Make sure this MTD device is not emulated on top of an UBI volume\n\t * already. Well, generally this recursion works fine, but there are\n\t * different problems like the UBI module takes a reference to itself\n\t * by attaching (and thus, opening) the emulated MTD device. This\n\t * results in inability to unload the module. And in general it makes\n\t * no sense to attach emulated MTD devices, so we prohibit this.\n\t */\n\tif (mtd->type == MTD_UBIVOLUME) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - it is already emulated on top of UBI\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\t/*\n\t * Both UBI and UBIFS have been designed for SLC NAND and NOR flashes.\n\t * MLC NAND is different and needs special care, otherwise UBI or UBIFS\n\t * will die soon and you will lose all your data.\n\t * Relax this rule if the partition we're attaching to operates in SLC\n\t * mode.\n\t */\n\tif (mtd->type == MTD_MLCNANDFLASH &&\n\t    !(mtd->flags & MTD_SLC_ON_MLC_EMULATION)) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - MLC NAND is not supported\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\t/* UBI cannot work on flashes with zero erasesize. */\n\tif (!mtd->erasesize) {\n\t\tpr_err(\"ubi: refuse attaching mtd%d - zero erasesize flash is not supported\\n\",\n\t\t\tmtd->index);\n\t\treturn -EINVAL;\n\t}\n\n\tif (ubi_num == UBI_DEV_NUM_AUTO) {\n\t\t/* Search for an empty slot in the @ubi_devices array */\n\t\tfor (ubi_num = 0; ubi_num < UBI_MAX_DEVICES; ubi_num++)\n\t\t\tif (!ubi_devices[ubi_num])\n\t\t\t\tbreak;\n\t\tif (ubi_num == UBI_MAX_DEVICES) {\n\t\t\tpr_err(\"ubi: only %d UBI devices may be created\\n\",\n\t\t\t\tUBI_MAX_DEVICES);\n\t\t\treturn -ENFILE;\n\t\t}\n\t} else {\n\t\tif (ubi_num >= UBI_MAX_DEVICES)\n\t\t\treturn -EINVAL;\n\n\t\t/* Make sure ubi_num is not busy */\n\t\tif (ubi_devices[ubi_num]) {\n\t\t\tpr_err(\"ubi: ubi%i already exists\\n\", ubi_num);\n\t\t\treturn -EEXIST;\n\t\t}\n\t}\n\n\tubi = kzalloc(sizeof(struct ubi_device), GFP_KERNEL);\n\tif (!ubi)\n\t\treturn -ENOMEM;\n\n\tdevice_initialize(&ubi->dev);\n\tubi->dev.release = dev_release;\n\tubi->dev.class = &ubi_class;\n\tubi->dev.groups = ubi_dev_groups;\n\tubi->dev.parent = &mtd->dev;\n\n\tubi->mtd = mtd;\n\tubi->ubi_num = ubi_num;\n\tubi->vid_hdr_offset = vid_hdr_offset;\n\tubi->autoresize_vol_id = -1;\n\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\tubi->fm_pool.used = ubi->fm_pool.size = 0;\n\tubi->fm_wl_pool.used = ubi->fm_wl_pool.size = 0;\n\n\t/*\n\t * fm_pool.max_size is 5% of the total number of PEBs but it's also\n\t * between UBI_FM_MAX_POOL_SIZE and UBI_FM_MIN_POOL_SIZE.\n\t */\n\tubi->fm_pool.max_size = min(((int)mtd_div_by_eb(ubi->mtd->size,\n\t\tubi->mtd) / 100) * 5, UBI_FM_MAX_POOL_SIZE);\n\tubi->fm_pool.max_size = max(ubi->fm_pool.max_size,\n\t\tUBI_FM_MIN_POOL_SIZE);\n\n\tubi->fm_wl_pool.max_size = ubi->fm_pool.max_size / 2;\n\tubi->fm_disabled = (!fm_autoconvert || disable_fm) ? 1 : 0;\n\tif (fm_debug)\n\t\tubi_enable_dbg_chk_fastmap(ubi);\n\n\tif (!ubi->fm_disabled && (int)mtd_div_by_eb(ubi->mtd->size, ubi->mtd)\n\t    <= UBI_FM_MAX_START) {\n\t\tubi_err(ubi, \"More than %i PEBs are needed for fastmap, sorry.\",\n\t\t\tUBI_FM_MAX_START);\n\t\tubi->fm_disabled = 1;\n\t}\n\n\tubi_msg(ubi, \"default fastmap pool size: %d\", ubi->fm_pool.max_size);\n\tubi_msg(ubi, \"default fastmap WL pool size: %d\",\n\t\tubi->fm_wl_pool.max_size);\n#else\n\tubi->fm_disabled = 1;\n#endif\n\tmutex_init(&ubi->buf_mutex);\n\tmutex_init(&ubi->ckvol_mutex);\n\tmutex_init(&ubi->device_mutex);\n\tspin_lock_init(&ubi->volumes_lock);\n\tinit_rwsem(&ubi->fm_protect);\n\tinit_rwsem(&ubi->fm_eba_sem);\n\n\tubi_msg(ubi, \"attaching mtd%d\", mtd->index);\n\n\terr = io_init(ubi, max_beb_per1024);\n\tif (err)\n\t\tgoto out_free;\n\n\terr = -ENOMEM;\n\tubi->peb_buf = vmalloc(ubi->peb_size);\n\tif (!ubi->peb_buf)\n\t\tgoto out_free;\n\n#ifdef CONFIG_MTD_UBI_FASTMAP\n\tubi->fm_size = ubi_calc_fm_size(ubi);\n\tubi->fm_buf = vzalloc(ubi->fm_size);\n\tif (!ubi->fm_buf)\n\t\tgoto out_free;\n#endif\n\terr = ubi_attach(ubi, disable_fm ? 1 : 0);\n\tif (err) {\n\t\tubi_err(ubi, \"failed to attach mtd%d, error %d\",\n\t\t\tmtd->index, err);\n\t\tgoto out_free;\n\t}\n\n\tif (ubi->autoresize_vol_id != -1) {\n\t\terr = autoresize(ubi, ubi->autoresize_vol_id);\n\t\tif (err)\n\t\t\tgoto out_detach;\n\t}\n\n\terr = uif_init(ubi);\n\tif (err)\n\t\tgoto out_detach;\n\n\terr = ubi_debugfs_init_dev(ubi);\n\tif (err)\n\t\tgoto out_uif;\n\n\tubi->bgt_thread = kthread_create(ubi_thread, ubi, \"%s\", ubi->bgt_name);\n\tif (IS_ERR(ubi->bgt_thread)) {\n\t\terr = PTR_ERR(ubi->bgt_thread);\n\t\tubi_err(ubi, \"cannot spawn \\\"%s\\\", error %d\",\n\t\t\tubi->bgt_name, err);\n\t\tgoto out_debugfs;\n\t}\n\n\tubi_msg(ubi, \"attached mtd%d (name \\\"%s\\\", size %llu MiB)\",\n\t\tmtd->index, mtd->name, ubi->flash_size >> 20);\n\tubi_msg(ubi, \"PEB size: %d bytes (%d KiB), LEB size: %d bytes\",\n\t\tubi->peb_size, ubi->peb_size >> 10, ubi->leb_size);\n\tubi_msg(ubi, \"min./max. I/O unit sizes: %d/%d, sub-page size %d\",\n\t\tubi->min_io_size, ubi->max_write_size, ubi->hdrs_min_io_size);\n\tubi_msg(ubi, \"VID header offset: %d (aligned %d), data offset: %d\",\n\t\tubi->vid_hdr_offset, ubi->vid_hdr_aloffset, ubi->leb_start);\n\tubi_msg(ubi, \"good PEBs: %d, bad PEBs: %d, corrupted PEBs: %d\",\n\t\tubi->good_peb_count, ubi->bad_peb_count, ubi->corr_peb_count);\n\tubi_msg(ubi, \"user volume: %d, internal volumes: %d, max. volumes count: %d\",\n\t\tubi->vol_count - UBI_INT_VOL_COUNT, UBI_INT_VOL_COUNT,\n\t\tubi->vtbl_slots);\n\tubi_msg(ubi, \"max/mean erase counter: %d/%d, WL threshold: %d, image sequence number: %u\",\n\t\tubi->max_ec, ubi->mean_ec, CONFIG_MTD_UBI_WL_THRESHOLD,\n\t\tubi->image_seq);\n\tubi_msg(ubi, \"available PEBs: %d, total reserved PEBs: %d, PEBs reserved for bad PEB handling: %d\",\n\t\tubi->avail_pebs, ubi->rsvd_pebs, ubi->beb_rsvd_pebs);\n\n\t/*\n\t * The below lock makes sure we do not race with 'ubi_thread()' which\n\t * checks @ubi->thread_enabled. Otherwise we may fail to wake it up.\n\t */\n\tspin_lock(&ubi->wl_lock);\n\tubi->thread_enabled = 1;\n\twake_up_process(ubi->bgt_thread);\n\tspin_unlock(&ubi->wl_lock);\n\n\tubi_devices[ubi_num] = ubi;\n\tubi_notify_all(ubi, UBI_VOLUME_ADDED, NULL);\n\treturn ubi_num;\n\nout_debugfs:\n\tubi_debugfs_exit_dev(ubi);\nout_uif:\n\tuif_close(ubi);\nout_detach:\n\tubi_wl_close(ubi);\n\tubi_free_all_volumes(ubi);\n\tvfree(ubi->vtbl);\nout_free:\n\tvfree(ubi->peb_buf);\n\tvfree(ubi->fm_buf);\n\tput_device(&ubi->dev);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -49,6 +49,13 @@\n \tif (mtd->type == MTD_MLCNANDFLASH &&\n \t    !(mtd->flags & MTD_SLC_ON_MLC_EMULATION)) {\n \t\tpr_err(\"ubi: refuse attaching mtd%d - MLC NAND is not supported\\n\",\n+\t\t\tmtd->index);\n+\t\treturn -EINVAL;\n+\t}\n+\n+\t/* UBI cannot work on flashes with zero erasesize. */\n+\tif (!mtd->erasesize) {\n+\t\tpr_err(\"ubi: refuse attaching mtd%d - zero erasesize flash is not supported\\n\",\n \t\t\tmtd->index);\n \t\treturn -EINVAL;\n \t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\tmtd->index);",
                "\t\treturn -EINVAL;",
                "\t}",
                "",
                "\t/* UBI cannot work on flashes with zero erasesize. */",
                "\tif (!mtd->erasesize) {",
                "\t\tpr_err(\"ubi: refuse attaching mtd%d - zero erasesize flash is not supported\\n\","
            ]
        }
    },
    {
        "cve_id": "CVE-2023-29659",
        "func_name": "strukturag/libheif/Fraction::Fraction",
        "description": "A Segmentation fault caused by a floating point exception exists in libheif 1.15.1 using crafted heif images via the heif::Fraction::round() function in box.cc, which causes a denial of service.",
        "git_url": "https://github.com/strukturag/libheif/commit/e05e15b57a38ec411cb9acb38512a1c36ff62991",
        "commit_title": "do not reduce Fraction accuracy when it would result in a zero denominator (fixes #794)",
        "commit_text": "",
        "func_before": "Fraction::Fraction(int32_t num, int32_t den)\n{\n  // Reduce resolution of fraction until we are in a safe range.\n  // We need this as adding fractions may lead to very large denominators\n  // (e.g. 0x10000 * 0x10000 > 0x100000000 -> overflow, leading to integer 0)\n\n  numerator = num;\n  denominator = den;\n\n  while (denominator > MAX_FRACTION_VALUE || denominator < -MAX_FRACTION_VALUE) {\n    numerator /= 2;\n    denominator /= 2;\n  }\n\n  while (numerator > MAX_FRACTION_VALUE || numerator < -MAX_FRACTION_VALUE) {\n    numerator /= 2;\n    denominator /= 2;\n  }\n}",
        "func": "Fraction::Fraction(int32_t num, int32_t den)\n{\n  // Reduce resolution of fraction until we are in a safe range.\n  // We need this as adding fractions may lead to very large denominators\n  // (e.g. 0x10000 * 0x10000 > 0x100000000 -> overflow, leading to integer 0)\n\n  numerator = num;\n  denominator = den;\n\n  while (denominator > MAX_FRACTION_VALUE || denominator < -MAX_FRACTION_VALUE) {\n    numerator /= 2;\n    denominator /= 2;\n  }\n\n  while (denominator > 1 && (numerator > MAX_FRACTION_VALUE || numerator < -MAX_FRACTION_VALUE)) {\n    numerator /= 2;\n    denominator /= 2;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n     denominator /= 2;\n   }\n \n-  while (numerator > MAX_FRACTION_VALUE || numerator < -MAX_FRACTION_VALUE) {\n+  while (denominator > 1 && (numerator > MAX_FRACTION_VALUE || numerator < -MAX_FRACTION_VALUE)) {\n     numerator /= 2;\n     denominator /= 2;\n   }",
        "diff_line_info": {
            "deleted_lines": [
                "  while (numerator > MAX_FRACTION_VALUE || numerator < -MAX_FRACTION_VALUE) {"
            ],
            "added_lines": [
                "  while (denominator > 1 && (numerator > MAX_FRACTION_VALUE || numerator < -MAX_FRACTION_VALUE)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-2839",
        "func_name": "gpac/naludmx_create_avc_decoder_config",
        "description": "Divide By Zero in GitHub repository gpac/gpac prior to 2.2.2.",
        "git_url": "https://github.com/gpac/gpac/commit/047f96fb39e6bf70cb9f344093f5886e51dce0ac",
        "commit_title": "fixed #2476",
        "commit_text": "",
        "func_before": "Bool naludmx_create_avc_decoder_config(GF_NALUDmxCtx *ctx, u8 **dsi, u32 *dsi_size, u8 **dsi_enh, u32 *dsi_enh_size, u32 *max_width, u32 *max_height, u32 *max_enh_width, u32 *max_enh_height, GF_Fraction *sar)\n{\n\tu32 i, count;\n\tBool first = GF_TRUE;\n\tBool first_svc = GF_TRUE;\n\tGF_AVCConfig *cfg;\n\tGF_AVCConfig *avcc;\n\tGF_AVCConfig *svcc;\n\tu32 max_w, max_h, max_ew, max_eh;\n\n\n\tmax_w = max_h = max_ew = max_eh = 0;\n\tsar->num = sar->den = 0;\n\n\tif (!ctx->analyze && (!gf_list_count(ctx->sps) || !gf_list_count(ctx->pps)))\n\t\treturn GF_FALSE;\n\n\tavcc = gf_odf_avc_cfg_new();\n\tsvcc = gf_odf_avc_cfg_new();\n\tavcc->nal_unit_size = ctx->nal_length;\n\tsvcc->nal_unit_size = ctx->nal_length;\n\n\tctx->is_mvc = GF_FALSE;\n\tcount = gf_list_count(ctx->sps);\n\tfor (i=0; i<count; i++) {\n\t\tBool is_svc = GF_FALSE;\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->sps, i);\n\t\tAVC_SPS *sps = &ctx->avc_state->sps[sl->id];\n\t\tu32 nal_type = sl->data[0] & 0x1F;\n\n\t\tif ((sps->profile_idc == 118) || (sps->profile_idc == 128)) {\n\t\t\tctx->is_mvc = GF_TRUE;\n\t\t}\n\n\t\tif (ctx->explicit) {\n\t\t\tcfg = svcc;\n\t\t} else if (nal_type == GF_AVC_NALU_SVC_SUBSEQ_PARAM) {\n\t\t\tcfg = svcc;\n\t\t\tis_svc = GF_TRUE;\n\t\t} else {\n\t\t\tcfg = avcc;\n\t\t}\n\n\t\tif (first || (is_svc && first_svc) ) {\n\t\t\tcfg->configurationVersion = 1;\n\t\t\tcfg->profile_compatibility = sps->prof_compat;\n\t\t\tcfg->AVCProfileIndication = sps->profile_idc;\n\t\t\tcfg->AVCLevelIndication = sps->level_idc;\n\t\t\tcfg->chroma_format = sps->chroma_format;\n\t\t\tcfg->luma_bit_depth = 8 + sps->luma_bit_depth_m8;\n\t\t\tcfg->chroma_bit_depth = 8 + sps->chroma_bit_depth_m8;\n\t\t\t/*try to patch ?*/\n\t\t\tif (!gf_avcc_use_extensions(cfg->AVCProfileIndication)\n\t\t\t\t&& ((cfg->chroma_format>1) || (cfg->luma_bit_depth>8) || (cfg->chroma_bit_depth>8))\n\t\t\t) {\n\t\t\t\tif ((cfg->luma_bit_depth>8) || (cfg->chroma_bit_depth>8)) {\n\t\t\t\t\tcfg->AVCProfileIndication = 110;\n\t\t\t\t} else {\n\t\t\t\t\tcfg->AVCProfileIndication = (cfg->chroma_format==3) ? 244 : 122;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (sps->vui_parameters_present_flag && sps->vui.par_num && sps->vui.par_den) {\n\t\t\t\tsar->num = sps->vui.par_num;\n\t\t\t\tsar->den = sps->vui.par_den;\n\t\t\t}\n\t\t\tctx->interlaced = sps->frame_mbs_only_flag ? GF_FALSE : GF_TRUE;\n\n\n\t\t\t/*disable frame rate scan, most bitstreams have wrong values there*/\n\t\t\tif (first && (!ctx->fps.num || !ctx->fps.den) && sps->vui.timing_info_present_flag\n\t\t\t\t/*if detected FPS is greater than 1000, assume wrong timing info*/\n\t\t\t\t&& (sps->vui.time_scale <= 1000*sps->vui.num_units_in_tick)\n\t\t\t) {\n\t\t\t\t/*ISO/IEC 14496-10 n11084 Table E-6*/\n\t\t\t\t/* not used :\t\t\t\tu8 DeltaTfiDivisorTable[] = {1,1,1,2,2,2,2,3,3,4,6}; */\n\t\t\t\tu8 DeltaTfiDivisorIdx;\n\t\t\t\tif (!sps->vui.pic_struct_present_flag) {\n\t\t\t\t\tDeltaTfiDivisorIdx = 1 + (1 - ctx->avc_state->s_info.field_pic_flag);\n\t\t\t\t} else {\n\t\t\t\t\tif (!ctx->avc_state->sei.pic_timing.pic_struct)\n\t\t\t\t\t\tDeltaTfiDivisorIdx = 2;\n\t\t\t\t\telse if (ctx->avc_state->sei.pic_timing.pic_struct == 8)\n\t\t\t\t\t\tDeltaTfiDivisorIdx = 6;\n\t\t\t\t\telse\n\t\t\t\t\t\tDeltaTfiDivisorIdx = (ctx->avc_state->sei.pic_timing.pic_struct+1) / 2;\n\t\t\t\t}\n\t\t\t\tif (ctx->notime && sps->vui.time_scale && sps->vui.num_units_in_tick) {\n\t\t\t\t\tctx->cur_fps.num = 2 * sps->vui.time_scale;\n\t\t\t\t\tctx->cur_fps.den = 2 * sps->vui.num_units_in_tick * DeltaTfiDivisorIdx;\n\n\t\t\t\t\tif (!ctx->fps.num && ctx->dts==ctx->fps.den)\n\t\t\t\t\t\tctx->dts = ctx->cur_fps.den;\n\t\t\t\t}\n\t\t\t\tif (! sps->vui.fixed_frame_rate_flag)\n\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_MEDIA, (\"[%s] Possible Variable Frame Rate: VUI \\\"fixed_frame_rate_flag\\\" absent\\n\", ctx->log_name));\n\t\t\t}\n\t\t\tctx->fps = ctx->cur_fps;\n\t\t}\n\t\tfirst = GF_FALSE;\n\t\tif (is_svc) {\n\t\t\tfirst_svc = GF_FALSE;\n\t\t\tif (sps->width > max_ew) max_ew = sps->width;\n\t\t\tif (sps->height > max_eh) max_eh = sps->height;\n\t\t} else {\n\t\t\tif (sps->width > max_w) max_w = sps->width;\n\t\t\tif (sps->height > max_h) max_h = sps->height;\n\t\t}\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->sequenceParameterSets, sl);\n\t}\n\n\tcfg = ctx->explicit ? svcc : avcc;\n\tcount = gf_list_count(ctx->sps_ext);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->sps_ext, i);\n\t\tif (!cfg->sequenceParameterSetExtensions) cfg->sequenceParameterSetExtensions = gf_list_new();\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->sequenceParameterSetExtensions, sl);\n\t}\n\n\tcfg = ctx->explicit ? svcc : avcc;\n\tcount = gf_list_count(ctx->pps);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->pps, i);\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->pictureParameterSets, sl);\n\t}\n\n\tcfg = svcc;\n\tcount = gf_list_count(ctx->pps_svc);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->pps_svc, i);\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->pictureParameterSets, sl);\n\t}\n\n\t*dsi = *dsi_enh = NULL;\n\t*dsi_size = *dsi_enh_size = 0;\n\n\tif (ctx->explicit) {\n\t\tgf_odf_avc_cfg_write(svcc, dsi, dsi_size);\n\t} else {\n\t\tgf_odf_avc_cfg_write(avcc, dsi, dsi_size);\n\t\tif (gf_list_count(svcc->sequenceParameterSets) || svcc->sequenceParameterSetExtensions) {\n\t\t\tgf_odf_avc_cfg_write(svcc, dsi_enh, dsi_enh_size);\n\t\t}\n\t}\n\tgf_list_reset(avcc->sequenceParameterSets);\n\tgf_list_reset(avcc->sequenceParameterSetExtensions);\n\tgf_list_reset(avcc->pictureParameterSets);\n\tgf_list_reset(svcc->sequenceParameterSets);\n\tgf_list_reset(svcc->sequenceParameterSetExtensions);\n\tgf_list_reset(svcc->pictureParameterSets);\n\tgf_odf_avc_cfg_del(avcc);\n\tgf_odf_avc_cfg_del(svcc);\n\t*max_width = max_w;\n\t*max_height = max_h;\n\t*max_enh_width = max_ew;\n\t*max_enh_height = max_eh;\n\treturn GF_TRUE;\n}",
        "func": "Bool naludmx_create_avc_decoder_config(GF_NALUDmxCtx *ctx, u8 **dsi, u32 *dsi_size, u8 **dsi_enh, u32 *dsi_enh_size, u32 *max_width, u32 *max_height, u32 *max_enh_width, u32 *max_enh_height, GF_Fraction *sar)\n{\n\tu32 i, count;\n\tBool first = GF_TRUE;\n\tBool first_svc = GF_TRUE;\n\tGF_AVCConfig *cfg;\n\tGF_AVCConfig *avcc;\n\tGF_AVCConfig *svcc;\n\tu32 max_w, max_h, max_ew, max_eh;\n\n\n\tmax_w = max_h = max_ew = max_eh = 0;\n\tsar->num = sar->den = 0;\n\n\tif (!ctx->analyze && (!gf_list_count(ctx->sps) || !gf_list_count(ctx->pps)))\n\t\treturn GF_FALSE;\n\n\tavcc = gf_odf_avc_cfg_new();\n\tsvcc = gf_odf_avc_cfg_new();\n\tavcc->nal_unit_size = ctx->nal_length;\n\tsvcc->nal_unit_size = ctx->nal_length;\n\n\tctx->is_mvc = GF_FALSE;\n\tcount = gf_list_count(ctx->sps);\n\tfor (i=0; i<count; i++) {\n\t\tBool is_svc = GF_FALSE;\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->sps, i);\n\t\tAVC_SPS *sps = &ctx->avc_state->sps[sl->id];\n\t\tu32 nal_type = sl->data[0] & 0x1F;\n\n\t\tif ((sps->profile_idc == 118) || (sps->profile_idc == 128)) {\n\t\t\tctx->is_mvc = GF_TRUE;\n\t\t}\n\n\t\tif (ctx->explicit) {\n\t\t\tcfg = svcc;\n\t\t} else if (nal_type == GF_AVC_NALU_SVC_SUBSEQ_PARAM) {\n\t\t\tcfg = svcc;\n\t\t\tis_svc = GF_TRUE;\n\t\t} else {\n\t\t\tcfg = avcc;\n\t\t}\n\n\t\tif (first || (is_svc && first_svc) ) {\n\t\t\tcfg->configurationVersion = 1;\n\t\t\tcfg->profile_compatibility = sps->prof_compat;\n\t\t\tcfg->AVCProfileIndication = sps->profile_idc;\n\t\t\tcfg->AVCLevelIndication = sps->level_idc;\n\t\t\tcfg->chroma_format = sps->chroma_format;\n\t\t\tcfg->luma_bit_depth = 8 + sps->luma_bit_depth_m8;\n\t\t\tcfg->chroma_bit_depth = 8 + sps->chroma_bit_depth_m8;\n\t\t\t/*try to patch ?*/\n\t\t\tif (!gf_avcc_use_extensions(cfg->AVCProfileIndication)\n\t\t\t\t&& ((cfg->chroma_format>1) || (cfg->luma_bit_depth>8) || (cfg->chroma_bit_depth>8))\n\t\t\t) {\n\t\t\t\tif ((cfg->luma_bit_depth>8) || (cfg->chroma_bit_depth>8)) {\n\t\t\t\t\tcfg->AVCProfileIndication = 110;\n\t\t\t\t} else {\n\t\t\t\t\tcfg->AVCProfileIndication = (cfg->chroma_format==3) ? 244 : 122;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (sps->vui_parameters_present_flag && sps->vui.par_num && sps->vui.par_den) {\n\t\t\t\tsar->num = sps->vui.par_num;\n\t\t\t\tsar->den = sps->vui.par_den;\n\t\t\t}\n\t\t\tctx->interlaced = sps->frame_mbs_only_flag ? GF_FALSE : GF_TRUE;\n\n\n\t\t\t/*disable frame rate scan, most bitstreams have wrong values there*/\n\t\t\tif (first && (!ctx->fps.num || !ctx->fps.den) && sps->vui.timing_info_present_flag\n\t\t\t\t/*if detected FPS is greater than 1000, assume wrong timing info*/\n\t\t\t\t&& (sps->vui.time_scale <= 1000*sps->vui.num_units_in_tick)\n\t\t\t) {\n\t\t\t\t/*ISO/IEC 14496-10 n11084 Table E-6*/\n\t\t\t\t/* not used :\t\t\t\tu8 DeltaTfiDivisorTable[] = {1,1,1,2,2,2,2,3,3,4,6}; */\n\t\t\t\tu8 DeltaTfiDivisorIdx;\n\t\t\t\tif (!sps->vui.pic_struct_present_flag) {\n\t\t\t\t\tDeltaTfiDivisorIdx = 1 + (1 - ctx->avc_state->s_info.field_pic_flag);\n\t\t\t\t} else {\n\t\t\t\t\tif (!ctx->avc_state->sei.pic_timing.pic_struct)\n\t\t\t\t\t\tDeltaTfiDivisorIdx = 2;\n\t\t\t\t\telse if (ctx->avc_state->sei.pic_timing.pic_struct == 8)\n\t\t\t\t\t\tDeltaTfiDivisorIdx = 6;\n\t\t\t\t\telse\n\t\t\t\t\t\tDeltaTfiDivisorIdx = (ctx->avc_state->sei.pic_timing.pic_struct+1) / 2;\n\t\t\t\t}\n\t\t\t\tif (ctx->notime) {\n\t\t\t\t\tu32 fps_num = 2 * sps->vui.time_scale;\n\t\t\t\t\tu32 fps_den = 2 * sps->vui.num_units_in_tick * DeltaTfiDivisorIdx;\n\t\t\t\t\tif (fps_num && fps_den) {\n\t\t\t\t\t\tctx->cur_fps.num = fps_num;\n\t\t\t\t\t\tctx->cur_fps.den = fps_den;\n\t\t\t\t\t}\n\t\t\t\t\tif (!ctx->fps.num && ctx->dts==ctx->fps.den)\n\t\t\t\t\t\tctx->dts = ctx->cur_fps.den;\n\t\t\t\t}\n\t\t\t\tif (! sps->vui.fixed_frame_rate_flag)\n\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_MEDIA, (\"[%s] Possible Variable Frame Rate: VUI \\\"fixed_frame_rate_flag\\\" absent\\n\", ctx->log_name));\n\t\t\t}\n\t\t\tctx->fps = ctx->cur_fps;\n\t\t}\n\t\tfirst = GF_FALSE;\n\t\tif (is_svc) {\n\t\t\tfirst_svc = GF_FALSE;\n\t\t\tif (sps->width > max_ew) max_ew = sps->width;\n\t\t\tif (sps->height > max_eh) max_eh = sps->height;\n\t\t} else {\n\t\t\tif (sps->width > max_w) max_w = sps->width;\n\t\t\tif (sps->height > max_h) max_h = sps->height;\n\t\t}\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->sequenceParameterSets, sl);\n\t}\n\n\tcfg = ctx->explicit ? svcc : avcc;\n\tcount = gf_list_count(ctx->sps_ext);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->sps_ext, i);\n\t\tif (!cfg->sequenceParameterSetExtensions) cfg->sequenceParameterSetExtensions = gf_list_new();\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->sequenceParameterSetExtensions, sl);\n\t}\n\n\tcfg = ctx->explicit ? svcc : avcc;\n\tcount = gf_list_count(ctx->pps);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->pps, i);\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->pictureParameterSets, sl);\n\t}\n\n\tcfg = svcc;\n\tcount = gf_list_count(ctx->pps_svc);\n\tfor (i=0; i<count; i++) {\n\t\tGF_NALUFFParam *sl = gf_list_get(ctx->pps_svc, i);\n\t\tif (!ctx->analyze)\n\t\t\tgf_list_add(cfg->pictureParameterSets, sl);\n\t}\n\n\t*dsi = *dsi_enh = NULL;\n\t*dsi_size = *dsi_enh_size = 0;\n\n\tif (ctx->explicit) {\n\t\tgf_odf_avc_cfg_write(svcc, dsi, dsi_size);\n\t} else {\n\t\tgf_odf_avc_cfg_write(avcc, dsi, dsi_size);\n\t\tif (gf_list_count(svcc->sequenceParameterSets) || svcc->sequenceParameterSetExtensions) {\n\t\t\tgf_odf_avc_cfg_write(svcc, dsi_enh, dsi_enh_size);\n\t\t}\n\t}\n\tgf_list_reset(avcc->sequenceParameterSets);\n\tgf_list_reset(avcc->sequenceParameterSetExtensions);\n\tgf_list_reset(avcc->pictureParameterSets);\n\tgf_list_reset(svcc->sequenceParameterSets);\n\tgf_list_reset(svcc->sequenceParameterSetExtensions);\n\tgf_list_reset(svcc->pictureParameterSets);\n\tgf_odf_avc_cfg_del(avcc);\n\tgf_odf_avc_cfg_del(svcc);\n\t*max_width = max_w;\n\t*max_height = max_h;\n\t*max_enh_width = max_ew;\n\t*max_enh_height = max_eh;\n\treturn GF_TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -84,10 +84,13 @@\n \t\t\t\t\telse\n \t\t\t\t\t\tDeltaTfiDivisorIdx = (ctx->avc_state->sei.pic_timing.pic_struct+1) / 2;\n \t\t\t\t}\n-\t\t\t\tif (ctx->notime && sps->vui.time_scale && sps->vui.num_units_in_tick) {\n-\t\t\t\t\tctx->cur_fps.num = 2 * sps->vui.time_scale;\n-\t\t\t\t\tctx->cur_fps.den = 2 * sps->vui.num_units_in_tick * DeltaTfiDivisorIdx;\n-\n+\t\t\t\tif (ctx->notime) {\n+\t\t\t\t\tu32 fps_num = 2 * sps->vui.time_scale;\n+\t\t\t\t\tu32 fps_den = 2 * sps->vui.num_units_in_tick * DeltaTfiDivisorIdx;\n+\t\t\t\t\tif (fps_num && fps_den) {\n+\t\t\t\t\t\tctx->cur_fps.num = fps_num;\n+\t\t\t\t\t\tctx->cur_fps.den = fps_den;\n+\t\t\t\t\t}\n \t\t\t\t\tif (!ctx->fps.num && ctx->dts==ctx->fps.den)\n \t\t\t\t\t\tctx->dts = ctx->cur_fps.den;\n \t\t\t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tif (ctx->notime && sps->vui.time_scale && sps->vui.num_units_in_tick) {",
                "\t\t\t\t\tctx->cur_fps.num = 2 * sps->vui.time_scale;",
                "\t\t\t\t\tctx->cur_fps.den = 2 * sps->vui.num_units_in_tick * DeltaTfiDivisorIdx;",
                ""
            ],
            "added_lines": [
                "\t\t\t\tif (ctx->notime) {",
                "\t\t\t\t\tu32 fps_num = 2 * sps->vui.time_scale;",
                "\t\t\t\t\tu32 fps_den = 2 * sps->vui.num_units_in_tick * DeltaTfiDivisorIdx;",
                "\t\t\t\t\tif (fps_num && fps_den) {",
                "\t\t\t\t\t\tctx->cur_fps.num = fps_num;",
                "\t\t\t\t\t\tctx->cur_fps.den = fps_den;",
                "\t\t\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11464",
        "func_name": "GNOME/librsvg/box_blur_line",
        "description": "A SIGFPE is raised in the function box_blur_line of rsvg-filter.c in GNOME librsvg 2.40.17 during an attempted parse of a crafted SVG file, because of incorrect protection against division by zero.",
        "git_url": "https://github.com/GNOME/librsvg/commit/ecf9267a24b2c3c0cd211dbdfa9ef2232511972a",
        "commit_title": "bgo#783835 - Don't divide by zero in box_blur_line() for gaussian blurs",
        "commit_text": " We were making the decision to use box blurs, instead of a true Gaussian kernel, based on the size of *both* x and y dimensions.  Do them individually instead.",
        "func_before": "static void\nbox_blur_line (gint box_width, gint even_offset,\n               guchar *src, guchar *dest,\n               gint len, gint bpp)\n{\n    gint  i;\n    gint  lead;    /* This marks the leading edge of the kernel              */\n    gint  output;  /* This marks the center of the kernel                    */\n    gint  trail;   /* This marks the pixel BEHIND the last 1 in the\n                      kernel; it's the pixel to remove from the accumulator. */\n    gint  *ac;     /* Accumulator for each channel                           */\n\n    ac = g_new0 (gint, bpp);\n\n    /* The algorithm differs for even and odd-sized kernels.\n     * With the output at the center,\n     * If odd, the kernel might look like this: 0011100\n     * If even, the kernel will either be centered on the boundary between\n     * the output and its left neighbor, or on the boundary between the\n     * output and its right neighbor, depending on even_lr.\n     * So it might be 0111100 or 0011110, where output is on the center\n     * of these arrays.\n     */\n    lead = 0;\n\n    if (box_width % 2 != 0) {\n        /* Odd-width kernel */\n        output = lead - (box_width - 1) / 2;\n        trail  = lead - box_width;\n    } else {\n        /* Even-width kernel. */\n        if (even_offset == 1) {\n            /* Right offset */\n            output = lead + 1 - box_width / 2;\n            trail  = lead - box_width;\n        } else if (even_offset == -1) {\n            /* Left offset */\n            output = lead - box_width / 2;\n            trail  = lead - box_width;\n        } else {\n            /* If even_offset isn't 1 or -1, there's some error. */\n            g_assert_not_reached ();\n        }\n    }\n\n    /* Initialize accumulator */\n    for (i = 0; i < bpp; i++)\n        ac[i] = 0;\n\n    /* As the kernel moves across the image, it has a leading edge and a\n     * trailing edge, and the output is in the middle. */\n    while (output < len) {\n        /* The number of pixels that are both in the image and\n         * currently covered by the kernel. This is necessary to\n         * handle edge cases. */\n        guint coverage = (lead < len ? lead : len - 1) - (trail >= 0 ? trail : -1);\n\n#ifdef READABLE_BOXBLUR_CODE\n/* The code here does the same as the code below, but the code below\n * has been optimized by moving the if statements out of the tight for\n * loop, and is harder to understand.\n * Don't use both this code and the code below. */\n        for (i = 0; i < bpp; i++) {\n            /* If the leading edge of the kernel is still on the image,\n             * add the value there to the accumulator. */\n            if (lead < len)\n                ac[i] += src[bpp * lead + i];\n\n            /* If the trailing edge of the kernel is on the image,\n             * subtract the value there from the accumulator. */\n            if (trail >= 0)\n                ac[i] -= src[bpp * trail + i];\n\n            /* Take the averaged value in the accumulator and store\n             * that value in the output. The number of pixels currently\n             * stored in the accumulator can be less than the nominal\n             * width of the kernel because the kernel can go \"over the edge\"\n             * of the image. */\n            if (output >= 0)\n                dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n        }\n#endif\n\n        /* If the leading edge of the kernel is still on the image... */\n        if (lead < len) {\n            if (trail >= 0) {\n                /* If the trailing edge of the kernel is on the image. (Since\n                 * the output is in between the lead and trail, it must be on\n                 * the image. */\n                for (i = 0; i < bpp; i++) {\n                    ac[i] += src[bpp * lead + i];\n                    ac[i] -= src[bpp * trail + i];\n                    dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n                }\n            } else if (output >= 0) {\n                /* If the output is on the image, but the trailing edge isn't yet\n                 * on the image. */\n\n                for (i = 0; i < bpp; i++) {\n                    ac[i] += src[bpp * lead + i];\n                    dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n                }\n            } else {\n                /* If leading edge is on the image, but the output and trailing\n                 * edge aren't yet on the image. */\n                for (i = 0; i < bpp; i++)\n                    ac[i] += src[bpp * lead + i];\n            }\n        } else if (trail >= 0) {\n            /* If the leading edge has gone off the image, but the output and\n             * trailing edge are on the image. (The big loop exits when the\n             * output goes off the image. */\n            for (i = 0; i < bpp; i++) {\n                ac[i] -= src[bpp * trail + i];\n                dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n            }\n        } else if (output >= 0) {\n            /* Leading has gone off the image and trailing isn't yet in it\n             * (small image) */\n            for (i = 0; i < bpp; i++)\n                dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n        }\n\n        lead++;\n        output++;\n        trail++;\n    }\n\n    g_free (ac);\n}",
        "func": "static void\nbox_blur_line (gint box_width, gint even_offset,\n               guchar *src, guchar *dest,\n               gint len, gint bpp)\n{\n    gint  i;\n    gint  lead;    /* This marks the leading edge of the kernel              */\n    gint  output;  /* This marks the center of the kernel                    */\n    gint  trail;   /* This marks the pixel BEHIND the last 1 in the\n                      kernel; it's the pixel to remove from the accumulator. */\n    gint  *ac;     /* Accumulator for each channel                           */\n\n    g_assert (box_width > 0);\n\n    ac = g_new0 (gint, bpp);\n\n    /* The algorithm differs for even and odd-sized kernels.\n     * With the output at the center,\n     * If odd, the kernel might look like this: 0011100\n     * If even, the kernel will either be centered on the boundary between\n     * the output and its left neighbor, or on the boundary between the\n     * output and its right neighbor, depending on even_lr.\n     * So it might be 0111100 or 0011110, where output is on the center\n     * of these arrays.\n     */\n    lead = 0;\n\n    if (box_width % 2 != 0) {\n        /* Odd-width kernel */\n        output = lead - (box_width - 1) / 2;\n        trail  = lead - box_width;\n    } else {\n        /* Even-width kernel. */\n        if (even_offset == 1) {\n            /* Right offset */\n            output = lead + 1 - box_width / 2;\n            trail  = lead - box_width;\n        } else if (even_offset == -1) {\n            /* Left offset */\n            output = lead - box_width / 2;\n            trail  = lead - box_width;\n        } else {\n            /* If even_offset isn't 1 or -1, there's some error. */\n            g_assert_not_reached ();\n        }\n    }\n\n    /* Initialize accumulator */\n    for (i = 0; i < bpp; i++)\n        ac[i] = 0;\n\n    /* As the kernel moves across the image, it has a leading edge and a\n     * trailing edge, and the output is in the middle. */\n    while (output < len) {\n        /* The number of pixels that are both in the image and\n         * currently covered by the kernel. This is necessary to\n         * handle edge cases. */\n        guint coverage = (lead < len ? lead : len - 1) - (trail >= 0 ? trail : -1);\n\n#ifdef READABLE_BOXBLUR_CODE\n/* The code here does the same as the code below, but the code below\n * has been optimized by moving the if statements out of the tight for\n * loop, and is harder to understand.\n * Don't use both this code and the code below. */\n        for (i = 0; i < bpp; i++) {\n            /* If the leading edge of the kernel is still on the image,\n             * add the value there to the accumulator. */\n            if (lead < len)\n                ac[i] += src[bpp * lead + i];\n\n            /* If the trailing edge of the kernel is on the image,\n             * subtract the value there from the accumulator. */\n            if (trail >= 0)\n                ac[i] -= src[bpp * trail + i];\n\n            /* Take the averaged value in the accumulator and store\n             * that value in the output. The number of pixels currently\n             * stored in the accumulator can be less than the nominal\n             * width of the kernel because the kernel can go \"over the edge\"\n             * of the image. */\n            if (output >= 0)\n                dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n        }\n#endif\n\n        /* If the leading edge of the kernel is still on the image... */\n        if (lead < len) {\n            if (trail >= 0) {\n                /* If the trailing edge of the kernel is on the image. (Since\n                 * the output is in between the lead and trail, it must be on\n                 * the image. */\n                for (i = 0; i < bpp; i++) {\n                    ac[i] += src[bpp * lead + i];\n                    ac[i] -= src[bpp * trail + i];\n                    dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n                }\n            } else if (output >= 0) {\n                /* If the output is on the image, but the trailing edge isn't yet\n                 * on the image. */\n\n                for (i = 0; i < bpp; i++) {\n                    ac[i] += src[bpp * lead + i];\n                    dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n                }\n            } else {\n                /* If leading edge is on the image, but the output and trailing\n                 * edge aren't yet on the image. */\n                for (i = 0; i < bpp; i++)\n                    ac[i] += src[bpp * lead + i];\n            }\n        } else if (trail >= 0) {\n            /* If the leading edge has gone off the image, but the output and\n             * trailing edge are on the image. (The big loop exits when the\n             * output goes off the image. */\n            for (i = 0; i < bpp; i++) {\n                ac[i] -= src[bpp * trail + i];\n                dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n            }\n        } else if (output >= 0) {\n            /* Leading has gone off the image and trailing isn't yet in it\n             * (small image) */\n            for (i = 0; i < bpp; i++)\n                dest[bpp * output + i] = (ac[i] + (coverage >> 1)) / coverage;\n        }\n\n        lead++;\n        output++;\n        trail++;\n    }\n\n    g_free (ac);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,8 @@\n     gint  trail;   /* This marks the pixel BEHIND the last 1 in the\n                       kernel; it's the pixel to remove from the accumulator. */\n     gint  *ac;     /* Accumulator for each channel                           */\n+\n+    g_assert (box_width > 0);\n \n     ac = g_new0 (gint, bpp);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    g_assert (box_width > 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-11464",
        "func_name": "GNOME/librsvg/gaussian_blur_surface",
        "description": "A SIGFPE is raised in the function box_blur_line of rsvg-filter.c in GNOME librsvg 2.40.17 during an attempted parse of a crafted SVG file, because of incorrect protection against division by zero.",
        "git_url": "https://github.com/GNOME/librsvg/commit/ecf9267a24b2c3c0cd211dbdfa9ef2232511972a",
        "commit_title": "bgo#783835 - Don't divide by zero in box_blur_line() for gaussian blurs",
        "commit_text": " We were making the decision to use box blurs, instead of a true Gaussian kernel, based on the size of *both* x and y dimensions.  Do them individually instead.",
        "func_before": "static void\ngaussian_blur_surface (cairo_surface_t *in,\n                       cairo_surface_t *out,\n                       gdouble sx,\n                       gdouble sy)\n{\n    gboolean use_box_blur;\n    gint width, height;\n    cairo_format_t in_format, out_format;\n    gint in_stride;\n    gint out_stride;\n    guchar *in_data, *out_data;\n    gint bpp;\n    gboolean out_has_data;\n\n    cairo_surface_flush (in);\n\n    width = cairo_image_surface_get_width (in);\n    height = cairo_image_surface_get_height (in);\n\n    g_assert (width == cairo_image_surface_get_width (out)\n              && height == cairo_image_surface_get_height (out));\n\n    in_format = cairo_image_surface_get_format (in);\n    out_format = cairo_image_surface_get_format (out);\n    g_assert (in_format == out_format);\n    g_assert (in_format == CAIRO_FORMAT_ARGB32\n              || in_format == CAIRO_FORMAT_A8);\n\n    if (in_format == CAIRO_FORMAT_ARGB32)\n        bpp = 4;\n    else if (in_format == CAIRO_FORMAT_A8)\n        bpp = 1;\n    else {\n        g_assert_not_reached ();\n        return;\n    }\n\n    in_stride = cairo_image_surface_get_stride (in);\n    out_stride = cairo_image_surface_get_stride (out);\n\n    in_data = cairo_image_surface_get_data (in);\n    out_data = cairo_image_surface_get_data (out);\n\n    if (sx < 0.0)\n        sx = 0.0;\n\n    if (sy < 0.0)\n        sy = 0.0;\n\n    /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with\n     * clever offsets.\n     */\n    if (sx < 10.0 && sy < 10.0)\n        use_box_blur = FALSE;\n    else\n        use_box_blur = TRUE;\n\n    /* Bail out by just copying? */\n    if ((sx == 0.0 && sy == 0.0)\n        || sx > 1000 || sy > 1000) {\n        cairo_t *cr;\n\n        cr = cairo_create (out);\n        cairo_set_source_surface (cr, in, 0, 0);\n        cairo_paint (cr);\n        cairo_destroy (cr);\n        return;\n    }\n\n    if (sx != 0.0) {\n        gint box_width;\n        gdouble *gaussian_matrix;\n        gint gaussian_matrix_len;\n        int y;\n        guchar *row_buffer = NULL;\n        guchar *row1, *row2;\n\n        if (use_box_blur) {\n            box_width = compute_box_blur_width (sx);\n\n            /* twice the size so we can have \"two\" scratch rows */\n            row_buffer = g_new0 (guchar, width * bpp * 2);\n            row1 = row_buffer;\n            row2 = row_buffer + width * bpp;\n        } else\n            make_gaussian_convolution_matrix (sx, &gaussian_matrix, &gaussian_matrix_len);\n\n        for (y = 0; y < height; y++) {\n            guchar *in_row, *out_row;\n\n            in_row = in_data + in_stride * y;\n            out_row = out_data + out_stride * y;\n\n            if (use_box_blur) {\n                if (box_width % 2 != 0) {\n                    /* Odd-width box blur: repeat 3 times, centered on output pixel */\n\n                    box_blur_line (box_width, 0, in_row, row1,    width, bpp);\n                    box_blur_line (box_width, 0, row1,   row2,    width, bpp);\n                    box_blur_line (box_width, 0, row2,   out_row, width, bpp);\n                } else {\n                    /* Even-width box blur:\n                     * This method is suggested by the specification for SVG.\n                     * One pass with width n, centered between output and right pixel\n                     * One pass with width n, centered between output and left pixel\n                     * One pass with width n+1, centered on output pixel\n                     */\n                    box_blur_line (box_width,     -1, in_row, row1,    width, bpp);\n                    box_blur_line (box_width,      1, row1,   row2,    width, bpp);\n                    box_blur_line (box_width + 1,  0, row2,   out_row, width, bpp);\n                }\n            } else\n                gaussian_blur_line (gaussian_matrix, gaussian_matrix_len, in_row, out_row, width, bpp);\n        }\n\n        if (!use_box_blur)\n            g_free (gaussian_matrix);\n\n        g_free (row_buffer);\n\n        out_has_data = TRUE;\n    } else\n        out_has_data = FALSE;\n\n    if (sy != 0.0) {\n        gint box_height;\n        gdouble *gaussian_matrix = NULL;\n        gint gaussian_matrix_len;\n        guchar *col_buffer;\n        guchar *col1, *col2;\n        int x;\n\n        /* twice the size so we can have the source pixels and the blurred pixels */\n        col_buffer = g_new0 (guchar, height * bpp * 2);\n        col1 = col_buffer;\n        col2 = col_buffer + height * bpp;\n\n        if (use_box_blur) {\n            box_height = compute_box_blur_width (sy);\n        } else\n            make_gaussian_convolution_matrix (sy, &gaussian_matrix, &gaussian_matrix_len);\n\n        for (x = 0; x < width; x++) {\n            if (out_has_data)\n                get_column (col1, out_data, out_stride, bpp, height, x);\n            else\n                get_column (col1, in_data, in_stride, bpp, height, x);\n\n            if (use_box_blur) {\n                if (box_height % 2 != 0) {\n                    /* Odd-width box blur */\n                    box_blur_line (box_height, 0, col1, col2, height, bpp);\n                    box_blur_line (box_height, 0, col2, col1, height, bpp);\n                    box_blur_line (box_height, 0, col1, col2, height, bpp);\n                } else {\n                    /* Even-width box blur */\n                    box_blur_line (box_height,     -1, col1, col2, height, bpp);\n                    box_blur_line (box_height,      1, col2, col1, height, bpp);\n                    box_blur_line (box_height + 1,  0, col1, col2, height, bpp);\n                }\n            } else\n                gaussian_blur_line (gaussian_matrix, gaussian_matrix_len, col1, col2, height, bpp);\n\n            put_column (col2, out_data, out_stride, bpp, height, x);\n        }\n\n        g_free (gaussian_matrix);\n        g_free (col_buffer);\n    }\n\n    cairo_surface_mark_dirty (out);\n}",
        "func": "static void\ngaussian_blur_surface (cairo_surface_t *in,\n                       cairo_surface_t *out,\n                       gdouble sx,\n                       gdouble sy)\n{\n    gint width, height;\n    cairo_format_t in_format, out_format;\n    gint in_stride;\n    gint out_stride;\n    guchar *in_data, *out_data;\n    gint bpp;\n    gboolean out_has_data;\n\n    cairo_surface_flush (in);\n\n    width = cairo_image_surface_get_width (in);\n    height = cairo_image_surface_get_height (in);\n\n    g_assert (width == cairo_image_surface_get_width (out)\n              && height == cairo_image_surface_get_height (out));\n\n    in_format = cairo_image_surface_get_format (in);\n    out_format = cairo_image_surface_get_format (out);\n    g_assert (in_format == out_format);\n    g_assert (in_format == CAIRO_FORMAT_ARGB32\n              || in_format == CAIRO_FORMAT_A8);\n\n    if (in_format == CAIRO_FORMAT_ARGB32)\n        bpp = 4;\n    else if (in_format == CAIRO_FORMAT_A8)\n        bpp = 1;\n    else {\n        g_assert_not_reached ();\n        return;\n    }\n\n    in_stride = cairo_image_surface_get_stride (in);\n    out_stride = cairo_image_surface_get_stride (out);\n\n    in_data = cairo_image_surface_get_data (in);\n    out_data = cairo_image_surface_get_data (out);\n\n    if (sx < 0.0)\n        sx = 0.0;\n\n    if (sy < 0.0)\n        sy = 0.0;\n\n    /* Bail out by just copying? */\n    if ((sx == 0.0 && sy == 0.0)\n        || sx > 1000 || sy > 1000) {\n        cairo_t *cr;\n\n        cr = cairo_create (out);\n        cairo_set_source_surface (cr, in, 0, 0);\n        cairo_paint (cr);\n        cairo_destroy (cr);\n        return;\n    }\n\n    if (sx != 0.0) {\n        gint box_width;\n        gdouble *gaussian_matrix;\n        gint gaussian_matrix_len;\n        int y;\n        guchar *row_buffer = NULL;\n        guchar *row1, *row2;\n        gboolean use_box_blur;\n\n        /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with\n         * clever offsets.\n         */\n        if (sx < 10.0)\n            use_box_blur = FALSE;\n        else\n            use_box_blur = TRUE;\n\n        if (use_box_blur) {\n            box_width = compute_box_blur_width (sx);\n\n            /* twice the size so we can have \"two\" scratch rows */\n            row_buffer = g_new0 (guchar, width * bpp * 2);\n            row1 = row_buffer;\n            row2 = row_buffer + width * bpp;\n        } else\n            make_gaussian_convolution_matrix (sx, &gaussian_matrix, &gaussian_matrix_len);\n\n        for (y = 0; y < height; y++) {\n            guchar *in_row, *out_row;\n\n            in_row = in_data + in_stride * y;\n            out_row = out_data + out_stride * y;\n\n            if (use_box_blur) {\n                if (box_width % 2 != 0) {\n                    /* Odd-width box blur: repeat 3 times, centered on output pixel */\n\n                    box_blur_line (box_width, 0, in_row, row1,    width, bpp);\n                    box_blur_line (box_width, 0, row1,   row2,    width, bpp);\n                    box_blur_line (box_width, 0, row2,   out_row, width, bpp);\n                } else {\n                    /* Even-width box blur:\n                     * This method is suggested by the specification for SVG.\n                     * One pass with width n, centered between output and right pixel\n                     * One pass with width n, centered between output and left pixel\n                     * One pass with width n+1, centered on output pixel\n                     */\n                    box_blur_line (box_width,     -1, in_row, row1,    width, bpp);\n                    box_blur_line (box_width,      1, row1,   row2,    width, bpp);\n                    box_blur_line (box_width + 1,  0, row2,   out_row, width, bpp);\n                }\n            } else\n                gaussian_blur_line (gaussian_matrix, gaussian_matrix_len, in_row, out_row, width, bpp);\n        }\n\n        if (!use_box_blur)\n            g_free (gaussian_matrix);\n\n        g_free (row_buffer);\n\n        out_has_data = TRUE;\n    } else\n        out_has_data = FALSE;\n\n    if (sy != 0.0) {\n        gint box_height;\n        gdouble *gaussian_matrix = NULL;\n        gint gaussian_matrix_len;\n        guchar *col_buffer;\n        guchar *col1, *col2;\n        int x;\n        gboolean use_box_blur;\n\n        /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with\n         * clever offsets.\n         */\n        if (sy < 10.0)\n            use_box_blur = FALSE;\n        else\n            use_box_blur = TRUE;\n\n        /* twice the size so we can have the source pixels and the blurred pixels */\n        col_buffer = g_new0 (guchar, height * bpp * 2);\n        col1 = col_buffer;\n        col2 = col_buffer + height * bpp;\n\n        if (use_box_blur) {\n            box_height = compute_box_blur_width (sy);\n        } else\n            make_gaussian_convolution_matrix (sy, &gaussian_matrix, &gaussian_matrix_len);\n\n        for (x = 0; x < width; x++) {\n            if (out_has_data)\n                get_column (col1, out_data, out_stride, bpp, height, x);\n            else\n                get_column (col1, in_data, in_stride, bpp, height, x);\n\n            if (use_box_blur) {\n                if (box_height % 2 != 0) {\n                    /* Odd-width box blur */\n                    box_blur_line (box_height, 0, col1, col2, height, bpp);\n                    box_blur_line (box_height, 0, col2, col1, height, bpp);\n                    box_blur_line (box_height, 0, col1, col2, height, bpp);\n                } else {\n                    /* Even-width box blur */\n                    box_blur_line (box_height,     -1, col1, col2, height, bpp);\n                    box_blur_line (box_height,      1, col2, col1, height, bpp);\n                    box_blur_line (box_height + 1,  0, col1, col2, height, bpp);\n                }\n            } else\n                gaussian_blur_line (gaussian_matrix, gaussian_matrix_len, col1, col2, height, bpp);\n\n            put_column (col2, out_data, out_stride, bpp, height, x);\n        }\n\n        g_free (gaussian_matrix);\n        g_free (col_buffer);\n    }\n\n    cairo_surface_mark_dirty (out);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,6 @@\n                        gdouble sx,\n                        gdouble sy)\n {\n-    gboolean use_box_blur;\n     gint width, height;\n     cairo_format_t in_format, out_format;\n     gint in_stride;\n@@ -48,14 +47,6 @@\n     if (sy < 0.0)\n         sy = 0.0;\n \n-    /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with\n-     * clever offsets.\n-     */\n-    if (sx < 10.0 && sy < 10.0)\n-        use_box_blur = FALSE;\n-    else\n-        use_box_blur = TRUE;\n-\n     /* Bail out by just copying? */\n     if ((sx == 0.0 && sy == 0.0)\n         || sx > 1000 || sy > 1000) {\n@@ -75,6 +66,15 @@\n         int y;\n         guchar *row_buffer = NULL;\n         guchar *row1, *row2;\n+        gboolean use_box_blur;\n+\n+        /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with\n+         * clever offsets.\n+         */\n+        if (sx < 10.0)\n+            use_box_blur = FALSE;\n+        else\n+            use_box_blur = TRUE;\n \n         if (use_box_blur) {\n             box_width = compute_box_blur_width (sx);\n@@ -130,6 +130,15 @@\n         guchar *col_buffer;\n         guchar *col1, *col2;\n         int x;\n+        gboolean use_box_blur;\n+\n+        /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with\n+         * clever offsets.\n+         */\n+        if (sy < 10.0)\n+            use_box_blur = FALSE;\n+        else\n+            use_box_blur = TRUE;\n \n         /* twice the size so we can have the source pixels and the blurred pixels */\n         col_buffer = g_new0 (guchar, height * bpp * 2);",
        "diff_line_info": {
            "deleted_lines": [
                "    gboolean use_box_blur;",
                "    /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with",
                "     * clever offsets.",
                "     */",
                "    if (sx < 10.0 && sy < 10.0)",
                "        use_box_blur = FALSE;",
                "    else",
                "        use_box_blur = TRUE;",
                ""
            ],
            "added_lines": [
                "        gboolean use_box_blur;",
                "",
                "        /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with",
                "         * clever offsets.",
                "         */",
                "        if (sx < 10.0)",
                "            use_box_blur = FALSE;",
                "        else",
                "            use_box_blur = TRUE;",
                "        gboolean use_box_blur;",
                "",
                "        /* For small radiuses, use a true gaussian kernel; otherwise use three box blurs with",
                "         * clever offsets.",
                "         */",
                "        if (sy < 10.0)",
                "            use_box_blur = FALSE;",
                "        else",
                "            use_box_blur = TRUE;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0142",
        "func_name": "qemu/bochs_open",
        "description": "QEMU, possibly before 2.0.0, allows local users to cause a denial of service (divide-by-zero error and crash) via a zero value in the (1) tracks field to the seek_to_sector function in block/parallels.c or (2) extent_size field in the bochs function in block/bochs.c.",
        "git_url": "https://github.com/qemu/qemu/commit/8e53abbc20d08ae3ec30c2054e1161314ad9501d",
        "commit_title": "bochs: Check extent_size header field (CVE-2014-0142)",
        "commit_text": " This fixes two possible division by zero crashes: In bochs_open() and in seek_to_sector(). ",
        "func_before": "static int bochs_open(BlockDriverState *bs, QDict *options, int flags,\n                      Error **errp)\n{\n    BDRVBochsState *s = bs->opaque;\n    uint32_t i;\n    struct bochs_header bochs;\n    int ret;\n\n    bs->read_only = 1; // no write support yet\n\n    ret = bdrv_pread(bs->file, 0, &bochs, sizeof(bochs));\n    if (ret < 0) {\n        return ret;\n    }\n\n    if (strcmp(bochs.magic, HEADER_MAGIC) ||\n        strcmp(bochs.type, REDOLOG_TYPE) ||\n        strcmp(bochs.subtype, GROWING_TYPE) ||\n\t((le32_to_cpu(bochs.version) != HEADER_VERSION) &&\n\t(le32_to_cpu(bochs.version) != HEADER_V1))) {\n        error_setg(errp, \"Image not in Bochs format\");\n        return -EINVAL;\n    }\n\n    if (le32_to_cpu(bochs.version) == HEADER_V1) {\n        bs->total_sectors = le64_to_cpu(bochs.extra.redolog_v1.disk) / 512;\n    } else {\n        bs->total_sectors = le64_to_cpu(bochs.extra.redolog.disk) / 512;\n    }\n\n    /* Limit to 1M entries to avoid unbounded allocation. This is what is\n     * needed for the largest image that bximage can create (~8 TB). */\n    s->catalog_size = le32_to_cpu(bochs.catalog);\n    if (s->catalog_size > 0x100000) {\n        error_setg(errp, \"Catalog size is too large\");\n        return -EFBIG;\n    }\n\n    s->catalog_bitmap = g_malloc(s->catalog_size * 4);\n\n    ret = bdrv_pread(bs->file, le32_to_cpu(bochs.header), s->catalog_bitmap,\n                     s->catalog_size * 4);\n    if (ret < 0) {\n        goto fail;\n    }\n\n    for (i = 0; i < s->catalog_size; i++)\n\tle32_to_cpus(&s->catalog_bitmap[i]);\n\n    s->data_offset = le32_to_cpu(bochs.header) + (s->catalog_size * 4);\n\n    s->bitmap_blocks = 1 + (le32_to_cpu(bochs.bitmap) - 1) / 512;\n    s->extent_blocks = 1 + (le32_to_cpu(bochs.extent) - 1) / 512;\n\n    s->extent_size = le32_to_cpu(bochs.extent);\n\n    if (s->catalog_size < bs->total_sectors / s->extent_size) {\n        error_setg(errp, \"Catalog size is too small for this disk size\");\n        ret = -EINVAL;\n        goto fail;\n    }\n\n    qemu_co_mutex_init(&s->lock);\n    return 0;\n\nfail:\n    g_free(s->catalog_bitmap);\n    return ret;\n}",
        "func": "static int bochs_open(BlockDriverState *bs, QDict *options, int flags,\n                      Error **errp)\n{\n    BDRVBochsState *s = bs->opaque;\n    uint32_t i;\n    struct bochs_header bochs;\n    int ret;\n\n    bs->read_only = 1; // no write support yet\n\n    ret = bdrv_pread(bs->file, 0, &bochs, sizeof(bochs));\n    if (ret < 0) {\n        return ret;\n    }\n\n    if (strcmp(bochs.magic, HEADER_MAGIC) ||\n        strcmp(bochs.type, REDOLOG_TYPE) ||\n        strcmp(bochs.subtype, GROWING_TYPE) ||\n\t((le32_to_cpu(bochs.version) != HEADER_VERSION) &&\n\t(le32_to_cpu(bochs.version) != HEADER_V1))) {\n        error_setg(errp, \"Image not in Bochs format\");\n        return -EINVAL;\n    }\n\n    if (le32_to_cpu(bochs.version) == HEADER_V1) {\n        bs->total_sectors = le64_to_cpu(bochs.extra.redolog_v1.disk) / 512;\n    } else {\n        bs->total_sectors = le64_to_cpu(bochs.extra.redolog.disk) / 512;\n    }\n\n    /* Limit to 1M entries to avoid unbounded allocation. This is what is\n     * needed for the largest image that bximage can create (~8 TB). */\n    s->catalog_size = le32_to_cpu(bochs.catalog);\n    if (s->catalog_size > 0x100000) {\n        error_setg(errp, \"Catalog size is too large\");\n        return -EFBIG;\n    }\n\n    s->catalog_bitmap = g_malloc(s->catalog_size * 4);\n\n    ret = bdrv_pread(bs->file, le32_to_cpu(bochs.header), s->catalog_bitmap,\n                     s->catalog_size * 4);\n    if (ret < 0) {\n        goto fail;\n    }\n\n    for (i = 0; i < s->catalog_size; i++)\n\tle32_to_cpus(&s->catalog_bitmap[i]);\n\n    s->data_offset = le32_to_cpu(bochs.header) + (s->catalog_size * 4);\n\n    s->bitmap_blocks = 1 + (le32_to_cpu(bochs.bitmap) - 1) / 512;\n    s->extent_blocks = 1 + (le32_to_cpu(bochs.extent) - 1) / 512;\n\n    s->extent_size = le32_to_cpu(bochs.extent);\n    if (s->extent_size == 0) {\n        error_setg(errp, \"Extent size may not be zero\");\n        return -EINVAL;\n    } else if (s->extent_size > 0x800000) {\n        error_setg(errp, \"Extent size %\" PRIu32 \" is too large\",\n                   s->extent_size);\n        return -EINVAL;\n    }\n\n    if (s->catalog_size < bs->total_sectors / s->extent_size) {\n        error_setg(errp, \"Catalog size is too small for this disk size\");\n        ret = -EINVAL;\n        goto fail;\n    }\n\n    qemu_co_mutex_init(&s->lock);\n    return 0;\n\nfail:\n    g_free(s->catalog_bitmap);\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -53,6 +53,14 @@\n     s->extent_blocks = 1 + (le32_to_cpu(bochs.extent) - 1) / 512;\n \n     s->extent_size = le32_to_cpu(bochs.extent);\n+    if (s->extent_size == 0) {\n+        error_setg(errp, \"Extent size may not be zero\");\n+        return -EINVAL;\n+    } else if (s->extent_size > 0x800000) {\n+        error_setg(errp, \"Extent size %\" PRIu32 \" is too large\",\n+                   s->extent_size);\n+        return -EINVAL;\n+    }\n \n     if (s->catalog_size < bs->total_sectors / s->extent_size) {\n         error_setg(errp, \"Catalog size is too small for this disk size\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (s->extent_size == 0) {",
                "        error_setg(errp, \"Extent size may not be zero\");",
                "        return -EINVAL;",
                "    } else if (s->extent_size > 0x800000) {",
                "        error_setg(errp, \"Extent size %\" PRIu32 \" is too large\",",
                "                   s->extent_size);",
                "        return -EINVAL;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0142",
        "func_name": "qemu/parallels_open",
        "description": "QEMU, possibly before 2.0.0, allows local users to cause a denial of service (divide-by-zero error and crash) via a zero value in the (1) tracks field to the seek_to_sector function in block/parallels.c or (2) extent_size field in the bochs function in block/bochs.c.",
        "git_url": "https://github.com/qemu/qemu/commit/9302e863aa8baa5d932fc078967050c055fa1a7f",
        "commit_title": "parallels: Sanity check for s->tracks (CVE-2014-0142)",
        "commit_text": " This avoids a possible division by zero.  Convert s->tracks to unsigned as well because it feels better than surviving just because the results of calculations with s->tracks are converted to unsigned anyway. ",
        "func_before": "static int parallels_open(BlockDriverState *bs, QDict *options, int flags,\n                          Error **errp)\n{\n    BDRVParallelsState *s = bs->opaque;\n    int i;\n    struct parallels_header ph;\n    int ret;\n\n    bs->read_only = 1; // no write support yet\n\n    ret = bdrv_pread(bs->file, 0, &ph, sizeof(ph));\n    if (ret < 0) {\n        goto fail;\n    }\n\n    if (memcmp(ph.magic, HEADER_MAGIC, 16) ||\n        (le32_to_cpu(ph.version) != HEADER_VERSION)) {\n        error_setg(errp, \"Image not in Parallels format\");\n        ret = -EINVAL;\n        goto fail;\n    }\n\n    bs->total_sectors = le32_to_cpu(ph.nb_sectors);\n\n    s->tracks = le32_to_cpu(ph.tracks);\n\n    s->catalog_size = le32_to_cpu(ph.catalog_entries);\n    if (s->catalog_size > INT_MAX / 4) {\n        error_setg(errp, \"Catalog too large\");\n        ret = -EFBIG;\n        goto fail;\n    }\n    s->catalog_bitmap = g_malloc(s->catalog_size * 4);\n\n    ret = bdrv_pread(bs->file, 64, s->catalog_bitmap, s->catalog_size * 4);\n    if (ret < 0) {\n        goto fail;\n    }\n\n    for (i = 0; i < s->catalog_size; i++)\n\tle32_to_cpus(&s->catalog_bitmap[i]);\n\n    qemu_co_mutex_init(&s->lock);\n    return 0;\n\nfail:\n    g_free(s->catalog_bitmap);\n    return ret;\n}",
        "func": "static int parallels_open(BlockDriverState *bs, QDict *options, int flags,\n                          Error **errp)\n{\n    BDRVParallelsState *s = bs->opaque;\n    int i;\n    struct parallels_header ph;\n    int ret;\n\n    bs->read_only = 1; // no write support yet\n\n    ret = bdrv_pread(bs->file, 0, &ph, sizeof(ph));\n    if (ret < 0) {\n        goto fail;\n    }\n\n    if (memcmp(ph.magic, HEADER_MAGIC, 16) ||\n        (le32_to_cpu(ph.version) != HEADER_VERSION)) {\n        error_setg(errp, \"Image not in Parallels format\");\n        ret = -EINVAL;\n        goto fail;\n    }\n\n    bs->total_sectors = le32_to_cpu(ph.nb_sectors);\n\n    s->tracks = le32_to_cpu(ph.tracks);\n    if (s->tracks == 0) {\n        error_setg(errp, \"Invalid image: Zero sectors per track\");\n        ret = -EINVAL;\n        goto fail;\n    }\n\n    s->catalog_size = le32_to_cpu(ph.catalog_entries);\n    if (s->catalog_size > INT_MAX / 4) {\n        error_setg(errp, \"Catalog too large\");\n        ret = -EFBIG;\n        goto fail;\n    }\n    s->catalog_bitmap = g_malloc(s->catalog_size * 4);\n\n    ret = bdrv_pread(bs->file, 64, s->catalog_bitmap, s->catalog_size * 4);\n    if (ret < 0) {\n        goto fail;\n    }\n\n    for (i = 0; i < s->catalog_size; i++)\n\tle32_to_cpus(&s->catalog_bitmap[i]);\n\n    qemu_co_mutex_init(&s->lock);\n    return 0;\n\nfail:\n    g_free(s->catalog_bitmap);\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,6 +23,11 @@\n     bs->total_sectors = le32_to_cpu(ph.nb_sectors);\n \n     s->tracks = le32_to_cpu(ph.tracks);\n+    if (s->tracks == 0) {\n+        error_setg(errp, \"Invalid image: Zero sectors per track\");\n+        ret = -EINVAL;\n+        goto fail;\n+    }\n \n     s->catalog_size = le32_to_cpu(ph.catalog_entries);\n     if (s->catalog_size > INT_MAX / 4) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (s->tracks == 0) {",
                "        error_setg(errp, \"Invalid image: Zero sectors per track\");",
                "        ret = -EINVAL;",
                "        goto fail;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10506",
        "func_name": "uclouvain/openjpeg/opj_pi_next_pcrl",
        "description": "Division-by-zero vulnerabilities in the functions opj_pi_next_cprl, opj_pi_next_pcrl, and opj_pi_next_rpcl in pi.c in OpenJPEG before 2.2.0 allow remote attackers to cause a denial of service (application crash) via crafted j2k files.",
        "git_url": "https://github.com/uclouvain/openjpeg/commit/d27ccf01c68a31ad62b33d2dc1ba2bb1eeaafe7b",
        "commit_title": "Avoid division by zero in opj_pi_next_rpcl, opj_pi_next_pcrl and opj_pi_next_cprl (#938)",
        "commit_text": " Fixes issues with id:000026,sig:08,src:002419,op:int32,pos:60,val:+32 and id:000019,sig:08,src:001098,op:flip1,pos:49",
        "func_before": "static OPJ_BOOL opj_pi_next_pcrl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    OPJ_UINT32 index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        OPJ_UINT32 compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                OPJ_UINT32 dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1u << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1u << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : opj_uint_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : opj_uint_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n            pi->y += (OPJ_INT32)(pi->dy - (OPJ_UINT32)(pi->y % (OPJ_INT32)pi->dy))) {\n        for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                pi->x += (OPJ_INT32)(pi->dx - (OPJ_UINT32)(pi->x % (OPJ_INT32)pi->dx))) {\n            for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                comp = &pi->comps[pi->compno];\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < opj_uint_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    OPJ_UINT32 levelno;\n                    OPJ_INT32 trx0, try0;\n                    OPJ_INT32 trx1, try1;\n                    OPJ_UINT32 rpx, rpy;\n                    OPJ_INT32 prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = opj_int_ceildiv(pi->tx0, (OPJ_INT32)(comp->dx << levelno));\n                    try0 = opj_int_ceildiv(pi->ty0, (OPJ_INT32)(comp->dy << levelno));\n                    trx1 = opj_int_ceildiv(pi->tx1, (OPJ_INT32)(comp->dx << levelno));\n                    try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n                    if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (OPJ_INT32)(comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = opj_int_floordivpow2(opj_int_ceildiv(pi->x,\n                                                (OPJ_INT32)(comp->dx << levelno)), (OPJ_INT32)res->pdx)\n                           - opj_int_floordivpow2(trx0, (OPJ_INT32)res->pdx);\n                    prcj = opj_int_floordivpow2(opj_int_ceildiv(pi->y,\n                                                (OPJ_INT32)(comp->dy << levelno)), (OPJ_INT32)res->pdy)\n                           - opj_int_floordivpow2(try0, (OPJ_INT32)res->pdy);\n                    pi->precno = (OPJ_UINT32)(prci + prcj * (OPJ_INT32)res->pw);\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "func": "static OPJ_BOOL opj_pi_next_pcrl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    OPJ_UINT32 index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        OPJ_UINT32 compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                OPJ_UINT32 dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1u << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1u << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : opj_uint_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : opj_uint_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n            pi->y += (OPJ_INT32)(pi->dy - (OPJ_UINT32)(pi->y % (OPJ_INT32)pi->dy))) {\n        for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                pi->x += (OPJ_INT32)(pi->dx - (OPJ_UINT32)(pi->x % (OPJ_INT32)pi->dx))) {\n            for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                comp = &pi->comps[pi->compno];\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < opj_uint_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    OPJ_UINT32 levelno;\n                    OPJ_INT32 trx0, try0;\n                    OPJ_INT32 trx1, try1;\n                    OPJ_UINT32 rpx, rpy;\n                    OPJ_INT32 prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = opj_int_ceildiv(pi->tx0, (OPJ_INT32)(comp->dx << levelno));\n                    try0 = opj_int_ceildiv(pi->ty0, (OPJ_INT32)(comp->dy << levelno));\n                    trx1 = opj_int_ceildiv(pi->tx1, (OPJ_INT32)(comp->dx << levelno));\n                    try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n\n                    /* To avoid divisions by zero / undefined behaviour on shift */\n                    /* in below tests */\n                    /* Relates to id:000019,sig:08,src:001098,op:flip1,pos:49 */\n                    /* of https://github.com/uclouvain/openjpeg/issues/938 */\n                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n                        continue;\n                    }\n\n                    /* See ISO-15441. B.12.1.4 Position-component-resolution level-layer progression */\n                    if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (OPJ_INT32)(comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = opj_int_floordivpow2(opj_int_ceildiv(pi->x,\n                                                (OPJ_INT32)(comp->dx << levelno)), (OPJ_INT32)res->pdx)\n                           - opj_int_floordivpow2(trx0, (OPJ_INT32)res->pdx);\n                    prcj = opj_int_floordivpow2(opj_int_ceildiv(pi->y,\n                                                (OPJ_INT32)(comp->dy << levelno)), (OPJ_INT32)res->pdy)\n                           - opj_int_floordivpow2(try0, (OPJ_INT32)res->pdy);\n                    pi->precno = (OPJ_UINT32)(prci + prcj * (OPJ_INT32)res->pw);\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -51,6 +51,17 @@\n                     try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                     rpx = res->pdx + levelno;\n                     rpy = res->pdy + levelno;\n+\n+                    /* To avoid divisions by zero / undefined behaviour on shift */\n+                    /* in below tests */\n+                    /* Relates to id:000019,sig:08,src:001098,op:flip1,pos:49 */\n+                    /* of https://github.com/uclouvain/openjpeg/issues/938 */\n+                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n+                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n+                        continue;\n+                    }\n+\n+                    /* See ISO-15441. B.12.1.4 Position-component-resolution level-layer progression */\n                     if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                             ((try0 << levelno) % (1 << rpy))))) {\n                         continue;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "                    /* To avoid divisions by zero / undefined behaviour on shift */",
                "                    /* in below tests */",
                "                    /* Relates to id:000019,sig:08,src:001098,op:flip1,pos:49 */",
                "                    /* of https://github.com/uclouvain/openjpeg/issues/938 */",
                "                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||",
                "                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {",
                "                        continue;",
                "                    }",
                "",
                "                    /* See ISO-15441. B.12.1.4 Position-component-resolution level-layer progression */"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10506",
        "func_name": "uclouvain/openjpeg/opj_pi_next_cprl",
        "description": "Division-by-zero vulnerabilities in the functions opj_pi_next_cprl, opj_pi_next_pcrl, and opj_pi_next_rpcl in pi.c in OpenJPEG before 2.2.0 allow remote attackers to cause a denial of service (application crash) via crafted j2k files.",
        "git_url": "https://github.com/uclouvain/openjpeg/commit/d27ccf01c68a31ad62b33d2dc1ba2bb1eeaafe7b",
        "commit_title": "Avoid division by zero in opj_pi_next_rpcl, opj_pi_next_pcrl and opj_pi_next_cprl (#938)",
        "commit_text": " Fixes issues with id:000026,sig:08,src:002419,op:int32,pos:60,val:+32 and id:000019,sig:08,src:001098,op:flip1,pos:49",
        "func_before": "static OPJ_BOOL opj_pi_next_cprl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    OPJ_UINT32 index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        pi->first = 0;\n    }\n\n    for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n        OPJ_UINT32 resno;\n        comp = &pi->comps[pi->compno];\n        pi->dx = 0;\n        pi->dy = 0;\n        for (resno = 0; resno < comp->numresolutions; resno++) {\n            OPJ_UINT32 dx, dy;\n            res = &comp->resolutions[resno];\n            dx = comp->dx * (1u << (res->pdx + comp->numresolutions - 1 - resno));\n            dy = comp->dy * (1u << (res->pdy + comp->numresolutions - 1 - resno));\n            pi->dx = !pi->dx ? dx : opj_uint_min(pi->dx, dx);\n            pi->dy = !pi->dy ? dy : opj_uint_min(pi->dy, dy);\n        }\n        if (!pi->tp_on) {\n            pi->poc.ty0 = pi->ty0;\n            pi->poc.tx0 = pi->tx0;\n            pi->poc.ty1 = pi->ty1;\n            pi->poc.tx1 = pi->tx1;\n        }\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += (OPJ_INT32)(pi->dy - (OPJ_UINT32)(pi->y % (OPJ_INT32)pi->dy))) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += (OPJ_INT32)(pi->dx - (OPJ_UINT32)(pi->x % (OPJ_INT32)pi->dx))) {\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < opj_uint_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    OPJ_UINT32 levelno;\n                    OPJ_INT32 trx0, try0;\n                    OPJ_INT32 trx1, try1;\n                    OPJ_UINT32 rpx, rpy;\n                    OPJ_INT32 prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = opj_int_ceildiv(pi->tx0, (OPJ_INT32)(comp->dx << levelno));\n                    try0 = opj_int_ceildiv(pi->ty0, (OPJ_INT32)(comp->dy << levelno));\n                    trx1 = opj_int_ceildiv(pi->tx1, (OPJ_INT32)(comp->dx << levelno));\n                    try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n                    if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (OPJ_INT32)(comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = opj_int_floordivpow2(opj_int_ceildiv(pi->x,\n                                                (OPJ_INT32)(comp->dx << levelno)), (OPJ_INT32)res->pdx)\n                           - opj_int_floordivpow2(trx0, (OPJ_INT32)res->pdx);\n                    prcj = opj_int_floordivpow2(opj_int_ceildiv(pi->y,\n                                                (OPJ_INT32)(comp->dy << levelno)), (OPJ_INT32)res->pdy)\n                           - opj_int_floordivpow2(try0, (OPJ_INT32)res->pdy);\n                    pi->precno = (OPJ_UINT32)(prci + prcj * (OPJ_INT32)res->pw);\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "func": "static OPJ_BOOL opj_pi_next_cprl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    OPJ_UINT32 index = 0;\n\n    if (!pi->first) {\n        comp = &pi->comps[pi->compno];\n        goto LABEL_SKIP;\n    } else {\n        pi->first = 0;\n    }\n\n    for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n        OPJ_UINT32 resno;\n        comp = &pi->comps[pi->compno];\n        pi->dx = 0;\n        pi->dy = 0;\n        for (resno = 0; resno < comp->numresolutions; resno++) {\n            OPJ_UINT32 dx, dy;\n            res = &comp->resolutions[resno];\n            dx = comp->dx * (1u << (res->pdx + comp->numresolutions - 1 - resno));\n            dy = comp->dy * (1u << (res->pdy + comp->numresolutions - 1 - resno));\n            pi->dx = !pi->dx ? dx : opj_uint_min(pi->dx, dx);\n            pi->dy = !pi->dy ? dy : opj_uint_min(pi->dy, dy);\n        }\n        if (!pi->tp_on) {\n            pi->poc.ty0 = pi->ty0;\n            pi->poc.tx0 = pi->tx0;\n            pi->poc.ty1 = pi->ty1;\n            pi->poc.tx1 = pi->tx1;\n        }\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += (OPJ_INT32)(pi->dy - (OPJ_UINT32)(pi->y % (OPJ_INT32)pi->dy))) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += (OPJ_INT32)(pi->dx - (OPJ_UINT32)(pi->x % (OPJ_INT32)pi->dx))) {\n                for (pi->resno = pi->poc.resno0;\n                        pi->resno < opj_uint_min(pi->poc.resno1, comp->numresolutions); pi->resno++) {\n                    OPJ_UINT32 levelno;\n                    OPJ_INT32 trx0, try0;\n                    OPJ_INT32 trx1, try1;\n                    OPJ_UINT32 rpx, rpy;\n                    OPJ_INT32 prci, prcj;\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = opj_int_ceildiv(pi->tx0, (OPJ_INT32)(comp->dx << levelno));\n                    try0 = opj_int_ceildiv(pi->ty0, (OPJ_INT32)(comp->dy << levelno));\n                    trx1 = opj_int_ceildiv(pi->tx1, (OPJ_INT32)(comp->dx << levelno));\n                    try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n\n                    /* To avoid divisions by zero / undefined behaviour on shift */\n                    /* in below tests */\n                    /* Fixes reading id:000019,sig:08,src:001098,op:flip1,pos:49 */\n                    /* of https://github.com/uclouvain/openjpeg/issues/938 */\n                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n                        continue;\n                    }\n\n                    /* See ISO-15441. B.12.1.5 Component-position-resolution level-layer progression */\n                    if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (OPJ_INT32)(comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = opj_int_floordivpow2(opj_int_ceildiv(pi->x,\n                                                (OPJ_INT32)(comp->dx << levelno)), (OPJ_INT32)res->pdx)\n                           - opj_int_floordivpow2(trx0, (OPJ_INT32)res->pdx);\n                    prcj = opj_int_floordivpow2(opj_int_ceildiv(pi->y,\n                                                (OPJ_INT32)(comp->dy << levelno)), (OPJ_INT32)res->pdy)\n                           - opj_int_floordivpow2(try0, (OPJ_INT32)res->pdy);\n                    pi->precno = (OPJ_UINT32)(prci + prcj * (OPJ_INT32)res->pw);\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -49,6 +49,17 @@\n                     try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                     rpx = res->pdx + levelno;\n                     rpy = res->pdy + levelno;\n+\n+                    /* To avoid divisions by zero / undefined behaviour on shift */\n+                    /* in below tests */\n+                    /* Fixes reading id:000019,sig:08,src:001098,op:flip1,pos:49 */\n+                    /* of https://github.com/uclouvain/openjpeg/issues/938 */\n+                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n+                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n+                        continue;\n+                    }\n+\n+                    /* See ISO-15441. B.12.1.5 Component-position-resolution level-layer progression */\n                     if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                             ((try0 << levelno) % (1 << rpy))))) {\n                         continue;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "                    /* To avoid divisions by zero / undefined behaviour on shift */",
                "                    /* in below tests */",
                "                    /* Fixes reading id:000019,sig:08,src:001098,op:flip1,pos:49 */",
                "                    /* of https://github.com/uclouvain/openjpeg/issues/938 */",
                "                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||",
                "                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {",
                "                        continue;",
                "                    }",
                "",
                "                    /* See ISO-15441. B.12.1.5 Component-position-resolution level-layer progression */"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10506",
        "func_name": "uclouvain/openjpeg/opj_pi_next_rpcl",
        "description": "Division-by-zero vulnerabilities in the functions opj_pi_next_cprl, opj_pi_next_pcrl, and opj_pi_next_rpcl in pi.c in OpenJPEG before 2.2.0 allow remote attackers to cause a denial of service (application crash) via crafted j2k files.",
        "git_url": "https://github.com/uclouvain/openjpeg/commit/d27ccf01c68a31ad62b33d2dc1ba2bb1eeaafe7b",
        "commit_title": "Avoid division by zero in opj_pi_next_rpcl, opj_pi_next_pcrl and opj_pi_next_cprl (#938)",
        "commit_text": " Fixes issues with id:000026,sig:08,src:002419,op:int32,pos:60,val:+32 and id:000019,sig:08,src:001098,op:flip1,pos:49",
        "func_before": "static OPJ_BOOL opj_pi_next_rpcl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    OPJ_UINT32 index = 0;\n\n    if (!pi->first) {\n        goto LABEL_SKIP;\n    } else {\n        OPJ_UINT32 compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                OPJ_UINT32 dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1u << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1u << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : opj_uint_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : opj_uint_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->resno = pi->poc.resno0; pi->resno < pi->poc.resno1; pi->resno++) {\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += (OPJ_INT32)(pi->dy - (OPJ_UINT32)(pi->y % (OPJ_INT32)pi->dy))) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += (OPJ_INT32)(pi->dx - (OPJ_UINT32)(pi->x % (OPJ_INT32)pi->dx))) {\n                for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                    OPJ_UINT32 levelno;\n                    OPJ_INT32 trx0, try0;\n                    OPJ_INT32  trx1, try1;\n                    OPJ_UINT32  rpx, rpy;\n                    OPJ_INT32  prci, prcj;\n                    comp = &pi->comps[pi->compno];\n                    if (pi->resno >= comp->numresolutions) {\n                        continue;\n                    }\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = opj_int_ceildiv(pi->tx0, (OPJ_INT32)(comp->dx << levelno));\n                    try0 = opj_int_ceildiv(pi->ty0, (OPJ_INT32)(comp->dy << levelno));\n                    trx1 = opj_int_ceildiv(pi->tx1, (OPJ_INT32)(comp->dx << levelno));\n                    try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n                    if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (OPJ_INT32)(comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = opj_int_floordivpow2(opj_int_ceildiv(pi->x,\n                                                (OPJ_INT32)(comp->dx << levelno)), (OPJ_INT32)res->pdx)\n                           - opj_int_floordivpow2(trx0, (OPJ_INT32)res->pdx);\n                    prcj = opj_int_floordivpow2(opj_int_ceildiv(pi->y,\n                                                (OPJ_INT32)(comp->dy << levelno)), (OPJ_INT32)res->pdy)\n                           - opj_int_floordivpow2(try0, (OPJ_INT32)res->pdy);\n                    pi->precno = (OPJ_UINT32)(prci + prcj * (OPJ_INT32)res->pw);\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "func": "static OPJ_BOOL opj_pi_next_rpcl(opj_pi_iterator_t * pi)\n{\n    opj_pi_comp_t *comp = NULL;\n    opj_pi_resolution_t *res = NULL;\n    OPJ_UINT32 index = 0;\n\n    if (!pi->first) {\n        goto LABEL_SKIP;\n    } else {\n        OPJ_UINT32 compno, resno;\n        pi->first = 0;\n        pi->dx = 0;\n        pi->dy = 0;\n        for (compno = 0; compno < pi->numcomps; compno++) {\n            comp = &pi->comps[compno];\n            for (resno = 0; resno < comp->numresolutions; resno++) {\n                OPJ_UINT32 dx, dy;\n                res = &comp->resolutions[resno];\n                dx = comp->dx * (1u << (res->pdx + comp->numresolutions - 1 - resno));\n                dy = comp->dy * (1u << (res->pdy + comp->numresolutions - 1 - resno));\n                pi->dx = !pi->dx ? dx : opj_uint_min(pi->dx, dx);\n                pi->dy = !pi->dy ? dy : opj_uint_min(pi->dy, dy);\n            }\n        }\n    }\n    if (!pi->tp_on) {\n        pi->poc.ty0 = pi->ty0;\n        pi->poc.tx0 = pi->tx0;\n        pi->poc.ty1 = pi->ty1;\n        pi->poc.tx1 = pi->tx1;\n    }\n    for (pi->resno = pi->poc.resno0; pi->resno < pi->poc.resno1; pi->resno++) {\n        for (pi->y = pi->poc.ty0; pi->y < pi->poc.ty1;\n                pi->y += (OPJ_INT32)(pi->dy - (OPJ_UINT32)(pi->y % (OPJ_INT32)pi->dy))) {\n            for (pi->x = pi->poc.tx0; pi->x < pi->poc.tx1;\n                    pi->x += (OPJ_INT32)(pi->dx - (OPJ_UINT32)(pi->x % (OPJ_INT32)pi->dx))) {\n                for (pi->compno = pi->poc.compno0; pi->compno < pi->poc.compno1; pi->compno++) {\n                    OPJ_UINT32 levelno;\n                    OPJ_INT32 trx0, try0;\n                    OPJ_INT32  trx1, try1;\n                    OPJ_UINT32  rpx, rpy;\n                    OPJ_INT32  prci, prcj;\n                    comp = &pi->comps[pi->compno];\n                    if (pi->resno >= comp->numresolutions) {\n                        continue;\n                    }\n                    res = &comp->resolutions[pi->resno];\n                    levelno = comp->numresolutions - 1 - pi->resno;\n                    trx0 = opj_int_ceildiv(pi->tx0, (OPJ_INT32)(comp->dx << levelno));\n                    try0 = opj_int_ceildiv(pi->ty0, (OPJ_INT32)(comp->dy << levelno));\n                    trx1 = opj_int_ceildiv(pi->tx1, (OPJ_INT32)(comp->dx << levelno));\n                    try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                    rpx = res->pdx + levelno;\n                    rpy = res->pdy + levelno;\n\n                    /* To avoid divisions by zero / undefined behaviour on shift */\n                    /* in below tests */\n                    /* Fixes reading id:000026,sig:08,src:002419,op:int32,pos:60,val:+32 */\n                    /* of https://github.com/uclouvain/openjpeg/issues/938 */\n                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n                        continue;\n                    }\n\n                    /* See ISO-15441. B.12.1.3 Resolution level-position-component-layer progression */\n                    if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                            ((try0 << levelno) % (1 << rpy))))) {\n                        continue;\n                    }\n                    if (!((pi->x % (OPJ_INT32)(comp->dx << rpx) == 0) || ((pi->x == pi->tx0) &&\n                            ((trx0 << levelno) % (1 << rpx))))) {\n                        continue;\n                    }\n\n                    if ((res->pw == 0) || (res->ph == 0)) {\n                        continue;\n                    }\n\n                    if ((trx0 == trx1) || (try0 == try1)) {\n                        continue;\n                    }\n\n                    prci = opj_int_floordivpow2(opj_int_ceildiv(pi->x,\n                                                (OPJ_INT32)(comp->dx << levelno)), (OPJ_INT32)res->pdx)\n                           - opj_int_floordivpow2(trx0, (OPJ_INT32)res->pdx);\n                    prcj = opj_int_floordivpow2(opj_int_ceildiv(pi->y,\n                                                (OPJ_INT32)(comp->dy << levelno)), (OPJ_INT32)res->pdy)\n                           - opj_int_floordivpow2(try0, (OPJ_INT32)res->pdy);\n                    pi->precno = (OPJ_UINT32)(prci + prcj * (OPJ_INT32)res->pw);\n                    for (pi->layno = pi->poc.layno0; pi->layno < pi->poc.layno1; pi->layno++) {\n                        index = pi->layno * pi->step_l + pi->resno * pi->step_r + pi->compno *\n                                pi->step_c + pi->precno * pi->step_p;\n                        if (!pi->include[index]) {\n                            pi->include[index] = 1;\n                            return OPJ_TRUE;\n                        }\nLABEL_SKIP:\n                        ;\n                    }\n                }\n            }\n        }\n    }\n\n    return OPJ_FALSE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,6 +52,17 @@\n                     try1 = opj_int_ceildiv(pi->ty1, (OPJ_INT32)(comp->dy << levelno));\n                     rpx = res->pdx + levelno;\n                     rpy = res->pdy + levelno;\n+\n+                    /* To avoid divisions by zero / undefined behaviour on shift */\n+                    /* in below tests */\n+                    /* Fixes reading id:000026,sig:08,src:002419,op:int32,pos:60,val:+32 */\n+                    /* of https://github.com/uclouvain/openjpeg/issues/938 */\n+                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||\n+                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {\n+                        continue;\n+                    }\n+\n+                    /* See ISO-15441. B.12.1.3 Resolution level-position-component-layer progression */\n                     if (!((pi->y % (OPJ_INT32)(comp->dy << rpy) == 0) || ((pi->y == pi->ty0) &&\n                             ((try0 << levelno) % (1 << rpy))))) {\n                         continue;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "                    /* To avoid divisions by zero / undefined behaviour on shift */",
                "                    /* in below tests */",
                "                    /* Fixes reading id:000026,sig:08,src:002419,op:int32,pos:60,val:+32 */",
                "                    /* of https://github.com/uclouvain/openjpeg/issues/938 */",
                "                    if (rpx >= 31 || ((comp->dx << rpx) >> rpx) != comp->dx ||",
                "                            rpy >= 31 || ((comp->dy << rpy) >> rpy) != comp->dy) {",
                "                        continue;",
                "                    }",
                "",
                "                    /* See ISO-15441. B.12.1.3 Resolution level-position-component-layer progression */"
            ]
        }
    },
    {
        "cve_id": "CVE-2017-14106",
        "func_name": "torvalds/linux/tcp_disconnect",
        "description": "The tcp_disconnect function in net/ipv4/tcp.c in the Linux kernel before 4.12 allows local users to cause a denial of service (__tcp_select_window divide-by-zero error and system crash) by triggering a disconnect within a certain tcp_recvmsg code path.",
        "git_url": "https://github.com/torvalds/linux/commit/499350a5a6e7512d9ed369ed63a4244b6536f4f8",
        "commit_title": "tcp: initialize rcv_mss to TCP_MIN_MSS instead of 0",
        "commit_text": " When tcp_disconnect() is called, inet_csk_delack_init() sets icsk->icsk_ack.rcv_mss to 0. This could potentially cause tcp_recvmsg() => tcp_cleanup_rbuf() => __tcp_select_window() call path to have division by 0 issue. So this patch initializes rcv_mss to TCP_MIN_MSS instead of 0. ",
        "func_before": "int tcp_disconnect(struct sock *sk, int flags)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tint err = 0;\n\tint old_state = sk->sk_state;\n\n\tif (old_state != TCP_CLOSE)\n\t\ttcp_set_state(sk, TCP_CLOSE);\n\n\t/* ABORT function of RFC793 */\n\tif (old_state == TCP_LISTEN) {\n\t\tinet_csk_listen_stop(sk);\n\t} else if (unlikely(tp->repair)) {\n\t\tsk->sk_err = ECONNABORTED;\n\t} else if (tcp_need_reset(old_state) ||\n\t\t   (tp->snd_nxt != tp->write_seq &&\n\t\t    (1 << old_state) & (TCPF_CLOSING | TCPF_LAST_ACK))) {\n\t\t/* The last check adjusts for discrepancy of Linux wrt. RFC\n\t\t * states\n\t\t */\n\t\ttcp_send_active_reset(sk, gfp_any());\n\t\tsk->sk_err = ECONNRESET;\n\t} else if (old_state == TCP_SYN_SENT)\n\t\tsk->sk_err = ECONNRESET;\n\n\ttcp_clear_xmit_timers(sk);\n\t__skb_queue_purge(&sk->sk_receive_queue);\n\ttcp_write_queue_purge(sk);\n\ttcp_fastopen_active_disable_ofo_check(sk);\n\tskb_rbtree_purge(&tp->out_of_order_queue);\n\n\tinet->inet_dport = 0;\n\n\tif (!(sk->sk_userlocks & SOCK_BINDADDR_LOCK))\n\t\tinet_reset_saddr(sk);\n\n\tsk->sk_shutdown = 0;\n\tsock_reset_flag(sk, SOCK_DONE);\n\ttp->srtt_us = 0;\n\ttp->write_seq += tp->max_window + 2;\n\tif (tp->write_seq == 0)\n\t\ttp->write_seq = 1;\n\ticsk->icsk_backoff = 0;\n\ttp->snd_cwnd = 2;\n\ticsk->icsk_probes_out = 0;\n\ttp->packets_out = 0;\n\ttp->snd_ssthresh = TCP_INFINITE_SSTHRESH;\n\ttp->snd_cwnd_cnt = 0;\n\ttp->window_clamp = 0;\n\ttcp_set_ca_state(sk, TCP_CA_Open);\n\ttcp_clear_retrans(tp);\n\tinet_csk_delack_init(sk);\n\ttcp_init_send_head(sk);\n\tmemset(&tp->rx_opt, 0, sizeof(tp->rx_opt));\n\t__sk_dst_reset(sk);\n\ttcp_saved_syn_free(tp);\n\n\t/* Clean up fastopen related fields */\n\ttcp_free_fastopen_req(tp);\n\tinet->defer_connect = 0;\n\n\tWARN_ON(inet->inet_num && !icsk->icsk_bind_hash);\n\n\tsk->sk_error_report(sk);\n\treturn err;\n}",
        "func": "int tcp_disconnect(struct sock *sk, int flags)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct inet_connection_sock *icsk = inet_csk(sk);\n\tstruct tcp_sock *tp = tcp_sk(sk);\n\tint err = 0;\n\tint old_state = sk->sk_state;\n\n\tif (old_state != TCP_CLOSE)\n\t\ttcp_set_state(sk, TCP_CLOSE);\n\n\t/* ABORT function of RFC793 */\n\tif (old_state == TCP_LISTEN) {\n\t\tinet_csk_listen_stop(sk);\n\t} else if (unlikely(tp->repair)) {\n\t\tsk->sk_err = ECONNABORTED;\n\t} else if (tcp_need_reset(old_state) ||\n\t\t   (tp->snd_nxt != tp->write_seq &&\n\t\t    (1 << old_state) & (TCPF_CLOSING | TCPF_LAST_ACK))) {\n\t\t/* The last check adjusts for discrepancy of Linux wrt. RFC\n\t\t * states\n\t\t */\n\t\ttcp_send_active_reset(sk, gfp_any());\n\t\tsk->sk_err = ECONNRESET;\n\t} else if (old_state == TCP_SYN_SENT)\n\t\tsk->sk_err = ECONNRESET;\n\n\ttcp_clear_xmit_timers(sk);\n\t__skb_queue_purge(&sk->sk_receive_queue);\n\ttcp_write_queue_purge(sk);\n\ttcp_fastopen_active_disable_ofo_check(sk);\n\tskb_rbtree_purge(&tp->out_of_order_queue);\n\n\tinet->inet_dport = 0;\n\n\tif (!(sk->sk_userlocks & SOCK_BINDADDR_LOCK))\n\t\tinet_reset_saddr(sk);\n\n\tsk->sk_shutdown = 0;\n\tsock_reset_flag(sk, SOCK_DONE);\n\ttp->srtt_us = 0;\n\ttp->write_seq += tp->max_window + 2;\n\tif (tp->write_seq == 0)\n\t\ttp->write_seq = 1;\n\ticsk->icsk_backoff = 0;\n\ttp->snd_cwnd = 2;\n\ticsk->icsk_probes_out = 0;\n\ttp->packets_out = 0;\n\ttp->snd_ssthresh = TCP_INFINITE_SSTHRESH;\n\ttp->snd_cwnd_cnt = 0;\n\ttp->window_clamp = 0;\n\ttcp_set_ca_state(sk, TCP_CA_Open);\n\ttcp_clear_retrans(tp);\n\tinet_csk_delack_init(sk);\n\t/* Initialize rcv_mss to TCP_MIN_MSS to avoid division by 0\n\t * issue in __tcp_select_window()\n\t */\n\ticsk->icsk_ack.rcv_mss = TCP_MIN_MSS;\n\ttcp_init_send_head(sk);\n\tmemset(&tp->rx_opt, 0, sizeof(tp->rx_opt));\n\t__sk_dst_reset(sk);\n\ttcp_saved_syn_free(tp);\n\n\t/* Clean up fastopen related fields */\n\ttcp_free_fastopen_req(tp);\n\tinet->defer_connect = 0;\n\n\tWARN_ON(inet->inet_num && !icsk->icsk_bind_hash);\n\n\tsk->sk_error_report(sk);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,6 +52,10 @@\n \ttcp_set_ca_state(sk, TCP_CA_Open);\n \ttcp_clear_retrans(tp);\n \tinet_csk_delack_init(sk);\n+\t/* Initialize rcv_mss to TCP_MIN_MSS to avoid division by 0\n+\t * issue in __tcp_select_window()\n+\t */\n+\ticsk->icsk_ack.rcv_mss = TCP_MIN_MSS;\n \ttcp_init_send_head(sk);\n \tmemset(&tp->rx_opt, 0, sizeof(tp->rx_opt));\n \t__sk_dst_reset(sk);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Initialize rcv_mss to TCP_MIN_MSS to avoid division by 0",
                "\t * issue in __tcp_select_window()",
                "\t */",
                "\ticsk->icsk_ack.rcv_mss = TCP_MIN_MSS;"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-23903",
        "func_name": "xiph/speex/read_wav_header",
        "description": "A Divide by Zero vulnerability in the function static int read_samples of Speex v1.2 allows attackers to cause a denial of service (DoS) via a crafted WAV file.",
        "git_url": "https://github.com/xiph/speex/commit/870ff845b32f314aec0036641ffe18aba4916887",
        "commit_title": "wav_io: guard against invalid channel numbers",
        "commit_text": " Fixes #13",
        "func_before": "int read_wav_header(FILE *file, int *rate, int *channels, int *format, spx_int32_t *size)\n{\n   char ch[5];\n   spx_int32_t itmp;\n   spx_int16_t stmp;\n   spx_int32_t bpersec;\n   spx_int16_t balign;\n   int skip_bytes;\n   int i;\n\n   ch[4]=0;\n#if 0\n   fread(ch, 1, 4, file);\n   if (strcmp(ch, \"RIFF\")!=0)\n   {\n      fseek(file, 0, SEEK_SET);\n      return 0;\n   }\n\n   fread(&itmp, 4, 1, file);\n   *size = le_int(itmp-36);\n\n   fread(ch, 1, 4, file);\n   if (strcmp(ch, \"WAVE\")!=0)\n   {\n      fprintf (stderr, \"RIFF file is not a WAVE file\\n\");\n      return -1;\n   }\n#endif\n   fread(ch, 1, 4, file);\n   while (strcmp(ch, \"fmt \")!=0)\n   {\n      fread(&itmp, 4, 1, file);\n      itmp = le_int(itmp);\n      /*fprintf (stderr, \"skip=%d\\n\", itmp);*/\n      /*strange way of seeking, but it works even for pipes*/\n      for (i=0;i<itmp;i++) {\n        if (fgetc(file) == EOF) {\n          break;\n        }\n      }\n      /*fseek(file, itmp, SEEK_CUR);*/\n      fread(ch, 1, 4, file);\n      if (feof(file))\n      {\n         fprintf (stderr, \"Corrupted WAVE file: no \\\"fmt \\\"\\n\");\n         return -1;\n      }\n   }\n   /*if (strcmp(ch, \"fmt \")!=0)\n   {\n      fprintf (stderr, \"Corrupted WAVE file: no \\\"fmt \\\"\\n\");\n      return -1;\n      }*/\n\n   fread(&itmp, 4, 1, file);\n   itmp = le_int(itmp);\n   skip_bytes=itmp-16;\n   /*fprintf (stderr, \"skip=%d\\n\", skip_bytes);*/\n\n   fread(&stmp, 2, 1, file);\n   stmp = le_short(stmp);\n   if (stmp!=1)\n   {\n      fprintf (stderr, \"Only PCM encoding is supported\\n\");\n      return -1;\n   }\n\n   fread(&stmp, 2, 1, file);\n   stmp = le_short(stmp);\n   *channels = stmp;\n\n   if (stmp>2)\n   {\n      fprintf (stderr, \"Only mono and (intensity) stereo supported\\n\");\n      return -1;\n   }\n\n   fread(&itmp, 4, 1, file);\n   itmp = le_int(itmp);\n   *rate = itmp;\n   if (*rate != 8000 && *rate != 16000 && *rate != 11025 && *rate != 22050 && *rate != 32000 && *rate != 44100 && *rate != 48000)\n   {\n      fprintf (stderr, \"Only 8 kHz (narrowband) and 16 kHz (wideband) supported (plus 11.025 kHz and 22.05 kHz, but your mileage may vary)\\n\");\n      return -1;\n   }\n\n   fread(&itmp, 4, 1, file);\n   bpersec = le_int(itmp);\n\n   fread(&stmp, 2, 1, file);\n   balign = le_short(stmp);\n\n   fread(&stmp, 2, 1, file);\n   stmp = le_short(stmp);\n   if (stmp!=16 && stmp!=8)\n   {\n      fprintf (stderr, \"Only 8/16-bit linear supported\\n\");\n      return -1;\n   }\n   *format=stmp;\n\n   if (bpersec!=*rate**channels*stmp/8)\n   {\n      fprintf (stderr, \"Corrupted header: ByteRate mismatch\\n\");\n      return -1;\n   }\n\n   if (balign!=*channels*stmp/8)\n   {\n      fprintf (stderr, \"Corrupted header: BlockAlign mismatch\\n\");\n      return -1;\n   }\n\n\n   /*strange way of seeking, but it works even for pipes*/\n   if (skip_bytes>0) {\n      for (i=0;i<skip_bytes;i++) {\n        if (fgetc(file) == EOF) {\n          break;\n        }\n      }\n   }\n\n   /*fseek(file, skip_bytes, SEEK_CUR);*/\n\n   fread(ch, 1, 4, file);\n   while (strcmp(ch, \"data\")!=0)\n   {\n      fread(&itmp, 4, 1, file);\n      itmp = le_int(itmp);\n      /*strange way of seeking, but it works even for pipes*/\n      for (i=0;i<itmp;i++) {\n        if (fgetc(file) == EOF) {\n          break;\n        }\n      }\n      /*fseek(file, itmp, SEEK_CUR);*/\n      fread(ch, 1, 4, file);\n      if (feof(file))\n      {\n         fprintf (stderr, \"Corrupted WAVE file: no \\\"data\\\"\\n\");\n         return -1;\n      }\n   }\n\n   /*Ignore this for now*/\n   fread(&itmp, 4, 1, file);\n   itmp = le_int(itmp);\n\n   *size=itmp;\n\n   return 1;\n}",
        "func": "int read_wav_header(FILE *file, int *rate, int *channels, int *format, spx_int32_t *size)\n{\n   char ch[5];\n   spx_int32_t itmp;\n   spx_int16_t stmp;\n   spx_int32_t bpersec;\n   spx_int16_t balign;\n   int skip_bytes;\n   int i;\n\n   ch[4]=0;\n#if 0\n   fread(ch, 1, 4, file);\n   if (strcmp(ch, \"RIFF\")!=0)\n   {\n      fseek(file, 0, SEEK_SET);\n      return 0;\n   }\n\n   fread(&itmp, 4, 1, file);\n   *size = le_int(itmp-36);\n\n   fread(ch, 1, 4, file);\n   if (strcmp(ch, \"WAVE\")!=0)\n   {\n      fprintf (stderr, \"RIFF file is not a WAVE file\\n\");\n      return -1;\n   }\n#endif\n   fread(ch, 1, 4, file);\n   while (strcmp(ch, \"fmt \")!=0)\n   {\n      fread(&itmp, 4, 1, file);\n      itmp = le_int(itmp);\n      /*fprintf (stderr, \"skip=%d\\n\", itmp);*/\n      /*strange way of seeking, but it works even for pipes*/\n      for (i=0;i<itmp;i++) {\n        if (fgetc(file) == EOF) {\n          break;\n        }\n      }\n      /*fseek(file, itmp, SEEK_CUR);*/\n      fread(ch, 1, 4, file);\n      if (feof(file))\n      {\n         fprintf (stderr, \"Corrupted WAVE file: no \\\"fmt \\\"\\n\");\n         return -1;\n      }\n   }\n   /*if (strcmp(ch, \"fmt \")!=0)\n   {\n      fprintf (stderr, \"Corrupted WAVE file: no \\\"fmt \\\"\\n\");\n      return -1;\n      }*/\n\n   fread(&itmp, 4, 1, file);\n   itmp = le_int(itmp);\n   skip_bytes=itmp-16;\n   /*fprintf (stderr, \"skip=%d\\n\", skip_bytes);*/\n\n   fread(&stmp, 2, 1, file);\n   stmp = le_short(stmp);\n   if (stmp!=1)\n   {\n      fprintf (stderr, \"Only PCM encoding is supported\\n\");\n      return -1;\n   }\n\n   fread(&stmp, 2, 1, file);\n   stmp = le_short(stmp);\n   *channels = stmp;\n\n   if (stmp>2 || stmp<1)\n   {\n      fprintf (stderr, \"Only mono and (intensity) stereo supported\\n\");\n      return -1;\n   }\n\n   fread(&itmp, 4, 1, file);\n   itmp = le_int(itmp);\n   *rate = itmp;\n   if (*rate != 8000 && *rate != 16000 && *rate != 11025 && *rate != 22050 && *rate != 32000 && *rate != 44100 && *rate != 48000)\n   {\n      fprintf (stderr, \"Only 8 kHz (narrowband) and 16 kHz (wideband) supported (plus 11.025 kHz and 22.05 kHz, but your mileage may vary)\\n\");\n      return -1;\n   }\n\n   fread(&itmp, 4, 1, file);\n   bpersec = le_int(itmp);\n\n   fread(&stmp, 2, 1, file);\n   balign = le_short(stmp);\n\n   fread(&stmp, 2, 1, file);\n   stmp = le_short(stmp);\n   if (stmp!=16 && stmp!=8)\n   {\n      fprintf (stderr, \"Only 8/16-bit linear supported\\n\");\n      return -1;\n   }\n   *format=stmp;\n\n   if (bpersec!=*rate**channels*stmp/8)\n   {\n      fprintf (stderr, \"Corrupted header: ByteRate mismatch\\n\");\n      return -1;\n   }\n\n   if (balign!=*channels*stmp/8)\n   {\n      fprintf (stderr, \"Corrupted header: BlockAlign mismatch\\n\");\n      return -1;\n   }\n\n\n   /*strange way of seeking, but it works even for pipes*/\n   if (skip_bytes>0) {\n      for (i=0;i<skip_bytes;i++) {\n        if (fgetc(file) == EOF) {\n          break;\n        }\n      }\n   }\n\n   /*fseek(file, skip_bytes, SEEK_CUR);*/\n\n   fread(ch, 1, 4, file);\n   while (strcmp(ch, \"data\")!=0)\n   {\n      fread(&itmp, 4, 1, file);\n      itmp = le_int(itmp);\n      /*strange way of seeking, but it works even for pipes*/\n      for (i=0;i<itmp;i++) {\n        if (fgetc(file) == EOF) {\n          break;\n        }\n      }\n      /*fseek(file, itmp, SEEK_CUR);*/\n      fread(ch, 1, 4, file);\n      if (feof(file))\n      {\n         fprintf (stderr, \"Corrupted WAVE file: no \\\"data\\\"\\n\");\n         return -1;\n      }\n   }\n\n   /*Ignore this for now*/\n   fread(&itmp, 4, 1, file);\n   itmp = le_int(itmp);\n\n   *size=itmp;\n\n   return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -70,7 +70,7 @@\n    stmp = le_short(stmp);\n    *channels = stmp;\n \n-   if (stmp>2)\n+   if (stmp>2 || stmp<1)\n    {\n       fprintf (stderr, \"Only mono and (intensity) stereo supported\\n\");\n       return -1;",
        "diff_line_info": {
            "deleted_lines": [
                "   if (stmp>2)"
            ],
            "added_lines": [
                "   if (stmp>2 || stmp<1)"
            ]
        }
    },
    {
        "cve_id": "CVE-2020-27560",
        "func_name": "ImageMagick/OptimizeLayerFrames",
        "description": "ImageMagick 7.0.10-34 allows Division by Zero in OptimizeLayerFrames in MagickCore/layer.c, which may cause a denial of service.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/ef59bd764f88d893f1219fee8ba696a5d3f8c1c4",
        "commit_title": "There is a Division by Zero in function OptimizeLayerFrames (#2743)",
        "commit_text": " in file MagickCore/layer.c. cur->ticks_per_seconds can be zero\r with a crafted input argument *image. This is similar to\r CVE-2019-13454.",
        "func_before": "static Image *OptimizeLayerFrames(const Image *image,const LayerMethod method,\n  ExceptionInfo *exception)\n{\n  ExceptionInfo\n    *sans_exception;\n\n  Image\n    *prev_image,\n    *dup_image,\n    *bgnd_image,\n    *optimized_image;\n\n  RectangleInfo\n    try_bounds,\n    bgnd_bounds,\n    dup_bounds,\n    *bounds;\n\n  MagickBooleanType\n    add_frames,\n    try_cleared,\n    cleared;\n\n  DisposeType\n    *disposals;\n\n  register const Image\n    *curr;\n\n  register ssize_t\n    i;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  assert(method == OptimizeLayer ||\n         method == OptimizeImageLayer ||\n         method == OptimizePlusLayer);\n  /*\n    Are we allowed to add/remove frames from animation?\n  */\n  add_frames=method == OptimizePlusLayer ? MagickTrue : MagickFalse;\n  /*\n    Ensure  all the images are the same size.\n  */\n  curr=GetFirstImageInList(image);\n  for (; curr != (Image *) NULL; curr=GetNextImageInList(curr))\n  {\n    if ((curr->columns != image->columns) || (curr->rows != image->rows))\n      ThrowImageException(OptionError,\"ImagesAreNotTheSameSize\");\n\n    if ((curr->page.x != 0) || (curr->page.y != 0) ||\n        (curr->page.width != image->page.width) ||\n        (curr->page.height != image->page.height))\n      ThrowImageException(OptionError,\"ImagePagesAreNotCoalesced\");\n  }\n  /*\n    Allocate memory (times 2 if we allow the use of frame duplications)\n  */\n  curr=GetFirstImageInList(image);\n  bounds=(RectangleInfo *) AcquireQuantumMemory((size_t)\n    GetImageListLength(curr),(add_frames != MagickFalse ? 2UL : 1UL)*\n    sizeof(*bounds));\n  if (bounds == (RectangleInfo *) NULL)\n    ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n  disposals=(DisposeType *) AcquireQuantumMemory((size_t)\n    GetImageListLength(image),(add_frames != MagickFalse ? 2UL : 1UL)*\n    sizeof(*disposals));\n  if (disposals == (DisposeType *) NULL)\n    {\n      bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n      ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  /*\n    Initialise Previous Image as fully transparent\n  */\n  prev_image=CloneImage(curr,curr->columns,curr->rows,MagickTrue,exception);\n  if (prev_image == (Image *) NULL)\n    {\n      bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n      disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n      return((Image *) NULL);\n    }\n  prev_image->page=curr->page;  /* ERROR: <-- should not be need, but is! */\n  prev_image->page.x=0;\n  prev_image->page.y=0;\n  prev_image->dispose=NoneDispose;\n  prev_image->background_color.alpha_trait=BlendPixelTrait;\n  prev_image->background_color.alpha=(MagickRealType) TransparentAlpha;\n  (void) SetImageBackgroundColor(prev_image,exception);\n  /*\n    Figure out the area of overlay of the first frame\n    No pixel could be cleared as all pixels are already cleared.\n  */\n#if DEBUG_OPT_FRAME\n  i=0;\n  (void) FormatLocaleFile(stderr,\"frame %.20g :-\\n\",(double) i);\n#endif\n  disposals[0]=NoneDispose;\n  bounds[0]=CompareImagesBounds(prev_image,curr,CompareAnyLayer,exception);\n#if DEBUG_OPT_FRAME\n  (void) FormatLocaleFile(stderr, \"overlay: %.20gx%.20g%+.20g%+.20g\\n\\n\",\n    (double) bounds[i].width,(double) bounds[i].height,\n    (double) bounds[i].x,(double) bounds[i].y );\n#endif\n  /*\n    Compute the bounding box of changes for each pair of images.\n  */\n  i=1;\n  bgnd_image=(Image *) NULL;\n  dup_image=(Image *) NULL;\n  dup_bounds.width=0;\n  dup_bounds.height=0;\n  dup_bounds.x=0;\n  dup_bounds.y=0;\n  curr=GetNextImageInList(curr);\n  for ( ; curr != (const Image *) NULL; curr=GetNextImageInList(curr))\n  {\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr,\"frame %.20g :-\\n\",(double) i);\n#endif\n    /*\n      Assume none disposal is the best\n    */\n    bounds[i]=CompareImagesBounds(curr->previous,curr,CompareAnyLayer,exception);\n    cleared=IsBoundsCleared(curr->previous,curr,&bounds[i],exception);\n    disposals[i-1]=NoneDispose;\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"overlay: %.20gx%.20g%+.20g%+.20g%s%s\\n\",\n         (double) bounds[i].width,(double) bounds[i].height,\n         (double) bounds[i].x,(double) bounds[i].y,\n         bounds[i].x < 0?\"  (unchanged)\":\"\",\n         cleared?\"  (pixels cleared)\":\"\");\n#endif\n    if ( bounds[i].x < 0 ) {\n      /*\n        Image frame is exactly the same as the previous frame!\n        If not adding frames leave it to be cropped down to a null image.\n        Otherwise mark previous image for deleted, transfering its crop bounds\n        to the current image.\n      */\n      if ( add_frames && i>=2 ) {\n        disposals[i-1]=DelDispose;\n        disposals[i]=NoneDispose;\n        bounds[i]=bounds[i-1];\n        i++;\n        continue;\n      }\n    }\n    else\n      {\n        /*\n          Compare a none disposal against a previous disposal\n        */\n        try_bounds=CompareImagesBounds(prev_image,curr,CompareAnyLayer,exception);\n        try_cleared=IsBoundsCleared(prev_image,curr,&try_bounds,exception);\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"test_prev: %.20gx%.20g%+.20g%+.20g%s\\n\",\n         (double) try_bounds.width,(double) try_bounds.height,\n         (double) try_bounds.x,(double) try_bounds.y,\n         try_cleared?\"  (pixels were cleared)\":\"\");\n#endif\n        if ( (!try_cleared && cleared ) ||\n                try_bounds.width * try_bounds.height\n                    <  bounds[i].width * bounds[i].height )\n          {\n            cleared=try_cleared;\n            bounds[i]=try_bounds;\n            disposals[i-1]=PreviousDispose;\n#if DEBUG_OPT_FRAME\n            (void) FormatLocaleFile(stderr,\"previous: accepted\\n\");\n          } else {\n            (void) FormatLocaleFile(stderr,\"previous: rejected\\n\");\n#endif\n          }\n\n        /*\n          If we are allowed lets try a complex frame duplication.\n          It is useless if the previous image already clears pixels correctly.\n          This method will always clear all the pixels that need to be cleared.\n        */\n        dup_bounds.width=dup_bounds.height=0; /* no dup, no pixel added */\n        if ( add_frames )\n          {\n            dup_image=CloneImage(curr->previous,0,0,MagickTrue,exception);\n            if (dup_image == (Image *) NULL)\n              {\n                bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n                disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n                prev_image=DestroyImage(prev_image);\n                return((Image *) NULL);\n              }\n            dup_image->background_color.alpha_trait=BlendPixelTrait;\n            dup_bounds=CompareImagesBounds(dup_image,curr,CompareClearLayer,exception);\n            ClearBounds(dup_image,&dup_bounds,exception);\n            try_bounds=CompareImagesBounds(dup_image,curr,CompareAnyLayer,exception);\n            if ( cleared ||\n                   dup_bounds.width*dup_bounds.height\n                      +try_bounds.width*try_bounds.height\n                   < bounds[i].width * bounds[i].height )\n              {\n                cleared=MagickFalse;\n                bounds[i]=try_bounds;\n                disposals[i-1]=DupDispose;\n                /* to be finalised later, if found to be optimial */\n              }\n            else\n              dup_bounds.width=dup_bounds.height=0;\n          }\n        /*\n          Now compare against a simple background disposal\n        */\n        bgnd_image=CloneImage(curr->previous,0,0,MagickTrue,exception);\n        if (bgnd_image == (Image *) NULL)\n          {\n            bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n            disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n            prev_image=DestroyImage(prev_image);\n            if ( dup_image != (Image *) NULL)\n              dup_image=DestroyImage(dup_image);\n            return((Image *) NULL);\n          }\n        bgnd_image->background_color.alpha_trait=BlendPixelTrait;\n        bgnd_bounds=bounds[i-1]; /* interum bounds of the previous image */\n        ClearBounds(bgnd_image,&bgnd_bounds,exception);\n        try_bounds=CompareImagesBounds(bgnd_image,curr,CompareAnyLayer,exception);\n        try_cleared=IsBoundsCleared(bgnd_image,curr,&try_bounds,exception);\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"background: %s\\n\",\n         try_cleared?\"(pixels cleared)\":\"\");\n#endif\n        if ( try_cleared )\n          {\n            /*\n              Straight background disposal failed to clear pixels needed!\n              Lets try expanding the disposal area of the previous frame, to\n              include the pixels that are cleared.  This guaranteed\n              to work, though may not be the most optimized solution.\n            */\n            try_bounds=CompareImagesBounds(curr->previous,curr,CompareClearLayer,exception);\n#if DEBUG_OPT_FRAME\n            (void) FormatLocaleFile(stderr, \"expand_clear: %.20gx%.20g%+.20g%+.20g%s\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y,\n                try_bounds.x<0?\"  (no expand nessary)\":\"\");\n#endif\n            if ( bgnd_bounds.x < 0 )\n              bgnd_bounds = try_bounds;\n            else\n              {\n#if DEBUG_OPT_FRAME\n                (void) FormatLocaleFile(stderr, \"expand_bgnd: %.20gx%.20g%+.20g%+.20g\\n\",\n                    (double) bgnd_bounds.width,(double) bgnd_bounds.height,\n                    (double) bgnd_bounds.x,(double) bgnd_bounds.y );\n#endif\n                if ( try_bounds.x < bgnd_bounds.x )\n                  {\n                     bgnd_bounds.width+= bgnd_bounds.x-try_bounds.x;\n                     if ( bgnd_bounds.width < try_bounds.width )\n                       bgnd_bounds.width = try_bounds.width;\n                     bgnd_bounds.x = try_bounds.x;\n                  }\n                else\n                  {\n                     try_bounds.width += try_bounds.x - bgnd_bounds.x;\n                     if ( bgnd_bounds.width < try_bounds.width )\n                       bgnd_bounds.width = try_bounds.width;\n                  }\n                if ( try_bounds.y < bgnd_bounds.y )\n                  {\n                     bgnd_bounds.height += bgnd_bounds.y - try_bounds.y;\n                     if ( bgnd_bounds.height < try_bounds.height )\n                       bgnd_bounds.height = try_bounds.height;\n                     bgnd_bounds.y = try_bounds.y;\n                  }\n                else\n                  {\n                    try_bounds.height += try_bounds.y - bgnd_bounds.y;\n                     if ( bgnd_bounds.height < try_bounds.height )\n                       bgnd_bounds.height = try_bounds.height;\n                  }\n#if DEBUG_OPT_FRAME\n                (void) FormatLocaleFile(stderr, \"        to : %.20gx%.20g%+.20g%+.20g\\n\",\n                    (double) bgnd_bounds.width,(double) bgnd_bounds.height,\n                    (double) bgnd_bounds.x,(double) bgnd_bounds.y );\n#endif\n              }\n            ClearBounds(bgnd_image,&bgnd_bounds,exception);\n#if DEBUG_OPT_FRAME\n/* Something strange is happening with a specific animation\n * CompareAnyLayers (normal method) and CompareClearLayers returns the whole\n * image, which is not posibly correct!  As verified by previous tests.\n * Something changed beyond the bgnd_bounds clearing.  But without being able\n * to see, or writet he image at this point it is hard to tell what is wrong!\n * Only CompareOverlay seemed to return something sensible.\n */\n            try_bounds=CompareImagesBounds(bgnd_image,curr,CompareClearLayer,exception);\n            (void) FormatLocaleFile(stderr, \"expand_ctst: %.20gx%.20g%+.20g%+.20g\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y );\n            try_bounds=CompareImagesBounds(bgnd_image,curr,CompareAnyLayer,exception);\n            try_cleared=IsBoundsCleared(bgnd_image,curr,&try_bounds,exception);\n            (void) FormatLocaleFile(stderr, \"expand_any : %.20gx%.20g%+.20g%+.20g%s\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y,\n                try_cleared?\"   (pixels cleared)\":\"\");\n#endif\n            try_bounds=CompareImagesBounds(bgnd_image,curr,CompareOverlayLayer,exception);\n#if DEBUG_OPT_FRAME\n            try_cleared=IsBoundsCleared(bgnd_image,curr,&try_bounds,exception);\n            (void) FormatLocaleFile(stderr, \"expand_test: %.20gx%.20g%+.20g%+.20g%s\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y,\n                try_cleared?\"   (pixels cleared)\":\"\");\n#endif\n          }\n        /*\n          Test if this background dispose is smaller than any of the\n          other methods we tryed before this (including duplicated frame)\n        */\n        if ( cleared ||\n              bgnd_bounds.width*bgnd_bounds.height\n                +try_bounds.width*try_bounds.height\n              < bounds[i-1].width*bounds[i-1].height\n                  +dup_bounds.width*dup_bounds.height\n                  +bounds[i].width*bounds[i].height )\n          {\n            cleared=MagickFalse;\n            bounds[i-1]=bgnd_bounds;\n            bounds[i]=try_bounds;\n            if ( disposals[i-1] == DupDispose )\n              dup_image=DestroyImage(dup_image);\n            disposals[i-1]=BackgroundDispose;\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr,\"expand_bgnd: accepted\\n\");\n          } else {\n    (void) FormatLocaleFile(stderr,\"expand_bgnd: reject\\n\");\n#endif\n          }\n      }\n    /*\n       Finalise choice of dispose, set new prev_image,\n       and junk any extra images as appropriate,\n    */\n    if ( disposals[i-1] == DupDispose )\n      {\n         if (bgnd_image != (Image *) NULL)\n           bgnd_image=DestroyImage(bgnd_image);\n         prev_image=DestroyImage(prev_image);\n         prev_image=dup_image, dup_image=(Image *) NULL;\n         bounds[i+1]=bounds[i];\n         bounds[i]=dup_bounds;\n         disposals[i-1]=DupDispose;\n         disposals[i]=BackgroundDispose;\n         i++;\n      }\n    else\n      {\n        if ( dup_image != (Image *) NULL)\n          dup_image=DestroyImage(dup_image);\n        if ( disposals[i-1] != PreviousDispose )\n          prev_image=DestroyImage(prev_image);\n        if ( disposals[i-1] == BackgroundDispose )\n          prev_image=bgnd_image, bgnd_image=(Image *) NULL;\n        if (bgnd_image != (Image *) NULL)\n          bgnd_image=DestroyImage(bgnd_image);\n        if ( disposals[i-1] == NoneDispose )\n          {\n            prev_image=ReferenceImage(curr->previous);\n            if (prev_image == (Image *) NULL)\n              {\n                bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n                disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n                return((Image *) NULL);\n              }\n          }\n\n      }\n    assert(prev_image != (Image *) NULL);\n    disposals[i]=disposals[i-1];\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"final   %.20g : %s  %.20gx%.20g%+.20g%+.20g\\n\",\n         (double) i-1,\n         CommandOptionToMnemonic(MagickDisposeOptions,disposals[i-1]),\n         (double) bounds[i-1].width,(double) bounds[i-1].height,\n         (double) bounds[i-1].x,(double) bounds[i-1].y );\n#endif\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"interum %.20g : %s  %.20gx%.20g%+.20g%+.20g\\n\",\n         (double) i,\n         CommandOptionToMnemonic(MagickDisposeOptions,disposals[i]),\n         (double) bounds[i].width,(double) bounds[i].height,\n         (double) bounds[i].x,(double) bounds[i].y );\n    (void) FormatLocaleFile(stderr,\"\\n\");\n#endif\n    i++;\n  }\n  prev_image=DestroyImage(prev_image);\n  /*\n    Optimize all images in sequence.\n  */\n  sans_exception=AcquireExceptionInfo();\n  i=0;\n  curr=GetFirstImageInList(image);\n  optimized_image=NewImageList();\n  while ( curr != (const Image *) NULL )\n  {\n    prev_image=CloneImage(curr,0,0,MagickTrue,exception);\n    if (prev_image == (Image *) NULL)\n      break;\n    prev_image->background_color.alpha_trait=BlendPixelTrait;\n    if ( disposals[i] == DelDispose ) {\n      size_t time = 0;\n      while ( disposals[i] == DelDispose ) {\n        time += curr->delay*1000/curr->ticks_per_second;\n        curr=GetNextImageInList(curr);\n        i++;\n      }\n      time += curr->delay*1000/curr->ticks_per_second;\n      prev_image->ticks_per_second = 100L;\n      prev_image->delay = time*prev_image->ticks_per_second/1000;\n    }\n    bgnd_image=CropImage(prev_image,&bounds[i],sans_exception);\n    prev_image=DestroyImage(prev_image);\n    if (bgnd_image == (Image *) NULL)\n      break;\n    bgnd_image->dispose=disposals[i];\n    if ( disposals[i] == DupDispose ) {\n      bgnd_image->delay=0;\n      bgnd_image->dispose=NoneDispose;\n    }\n    else\n      curr=GetNextImageInList(curr);\n    AppendImageToList(&optimized_image,bgnd_image);\n    i++;\n  }\n  sans_exception=DestroyExceptionInfo(sans_exception);\n  bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n  disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n  if (curr != (Image *) NULL)\n    {\n      optimized_image=DestroyImageList(optimized_image);\n      return((Image *) NULL);\n    }\n  return(GetFirstImageInList(optimized_image));\n}",
        "func": "static Image *OptimizeLayerFrames(const Image *image,const LayerMethod method,\n  ExceptionInfo *exception)\n{\n  ExceptionInfo\n    *sans_exception;\n\n  Image\n    *prev_image,\n    *dup_image,\n    *bgnd_image,\n    *optimized_image;\n\n  RectangleInfo\n    try_bounds,\n    bgnd_bounds,\n    dup_bounds,\n    *bounds;\n\n  MagickBooleanType\n    add_frames,\n    try_cleared,\n    cleared;\n\n  DisposeType\n    *disposals;\n\n  register const Image\n    *curr;\n\n  register ssize_t\n    i;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  assert(method == OptimizeLayer ||\n         method == OptimizeImageLayer ||\n         method == OptimizePlusLayer);\n  /*\n    Are we allowed to add/remove frames from animation?\n  */\n  add_frames=method == OptimizePlusLayer ? MagickTrue : MagickFalse;\n  /*\n    Ensure  all the images are the same size.\n  */\n  curr=GetFirstImageInList(image);\n  for (; curr != (Image *) NULL; curr=GetNextImageInList(curr))\n  {\n    if ((curr->columns != image->columns) || (curr->rows != image->rows))\n      ThrowImageException(OptionError,\"ImagesAreNotTheSameSize\");\n\n    if ((curr->page.x != 0) || (curr->page.y != 0) ||\n        (curr->page.width != image->page.width) ||\n        (curr->page.height != image->page.height))\n      ThrowImageException(OptionError,\"ImagePagesAreNotCoalesced\");\n  }\n  /*\n    Allocate memory (times 2 if we allow the use of frame duplications)\n  */\n  curr=GetFirstImageInList(image);\n  bounds=(RectangleInfo *) AcquireQuantumMemory((size_t)\n    GetImageListLength(curr),(add_frames != MagickFalse ? 2UL : 1UL)*\n    sizeof(*bounds));\n  if (bounds == (RectangleInfo *) NULL)\n    ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n  disposals=(DisposeType *) AcquireQuantumMemory((size_t)\n    GetImageListLength(image),(add_frames != MagickFalse ? 2UL : 1UL)*\n    sizeof(*disposals));\n  if (disposals == (DisposeType *) NULL)\n    {\n      bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n      ThrowImageException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  /*\n    Initialise Previous Image as fully transparent\n  */\n  prev_image=CloneImage(curr,curr->columns,curr->rows,MagickTrue,exception);\n  if (prev_image == (Image *) NULL)\n    {\n      bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n      disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n      return((Image *) NULL);\n    }\n  prev_image->page=curr->page;  /* ERROR: <-- should not be need, but is! */\n  prev_image->page.x=0;\n  prev_image->page.y=0;\n  prev_image->dispose=NoneDispose;\n  prev_image->background_color.alpha_trait=BlendPixelTrait;\n  prev_image->background_color.alpha=(MagickRealType) TransparentAlpha;\n  (void) SetImageBackgroundColor(prev_image,exception);\n  /*\n    Figure out the area of overlay of the first frame\n    No pixel could be cleared as all pixels are already cleared.\n  */\n#if DEBUG_OPT_FRAME\n  i=0;\n  (void) FormatLocaleFile(stderr,\"frame %.20g :-\\n\",(double) i);\n#endif\n  disposals[0]=NoneDispose;\n  bounds[0]=CompareImagesBounds(prev_image,curr,CompareAnyLayer,exception);\n#if DEBUG_OPT_FRAME\n  (void) FormatLocaleFile(stderr, \"overlay: %.20gx%.20g%+.20g%+.20g\\n\\n\",\n    (double) bounds[i].width,(double) bounds[i].height,\n    (double) bounds[i].x,(double) bounds[i].y );\n#endif\n  /*\n    Compute the bounding box of changes for each pair of images.\n  */\n  i=1;\n  bgnd_image=(Image *) NULL;\n  dup_image=(Image *) NULL;\n  dup_bounds.width=0;\n  dup_bounds.height=0;\n  dup_bounds.x=0;\n  dup_bounds.y=0;\n  curr=GetNextImageInList(curr);\n  for ( ; curr != (const Image *) NULL; curr=GetNextImageInList(curr))\n  {\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr,\"frame %.20g :-\\n\",(double) i);\n#endif\n    /*\n      Assume none disposal is the best\n    */\n    bounds[i]=CompareImagesBounds(curr->previous,curr,CompareAnyLayer,exception);\n    cleared=IsBoundsCleared(curr->previous,curr,&bounds[i],exception);\n    disposals[i-1]=NoneDispose;\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"overlay: %.20gx%.20g%+.20g%+.20g%s%s\\n\",\n         (double) bounds[i].width,(double) bounds[i].height,\n         (double) bounds[i].x,(double) bounds[i].y,\n         bounds[i].x < 0?\"  (unchanged)\":\"\",\n         cleared?\"  (pixels cleared)\":\"\");\n#endif\n    if ( bounds[i].x < 0 ) {\n      /*\n        Image frame is exactly the same as the previous frame!\n        If not adding frames leave it to be cropped down to a null image.\n        Otherwise mark previous image for deleted, transfering its crop bounds\n        to the current image.\n      */\n      if ( add_frames && i>=2 ) {\n        disposals[i-1]=DelDispose;\n        disposals[i]=NoneDispose;\n        bounds[i]=bounds[i-1];\n        i++;\n        continue;\n      }\n    }\n    else\n      {\n        /*\n          Compare a none disposal against a previous disposal\n        */\n        try_bounds=CompareImagesBounds(prev_image,curr,CompareAnyLayer,exception);\n        try_cleared=IsBoundsCleared(prev_image,curr,&try_bounds,exception);\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"test_prev: %.20gx%.20g%+.20g%+.20g%s\\n\",\n         (double) try_bounds.width,(double) try_bounds.height,\n         (double) try_bounds.x,(double) try_bounds.y,\n         try_cleared?\"  (pixels were cleared)\":\"\");\n#endif\n        if ( (!try_cleared && cleared ) ||\n                try_bounds.width * try_bounds.height\n                    <  bounds[i].width * bounds[i].height )\n          {\n            cleared=try_cleared;\n            bounds[i]=try_bounds;\n            disposals[i-1]=PreviousDispose;\n#if DEBUG_OPT_FRAME\n            (void) FormatLocaleFile(stderr,\"previous: accepted\\n\");\n          } else {\n            (void) FormatLocaleFile(stderr,\"previous: rejected\\n\");\n#endif\n          }\n\n        /*\n          If we are allowed lets try a complex frame duplication.\n          It is useless if the previous image already clears pixels correctly.\n          This method will always clear all the pixels that need to be cleared.\n        */\n        dup_bounds.width=dup_bounds.height=0; /* no dup, no pixel added */\n        if ( add_frames )\n          {\n            dup_image=CloneImage(curr->previous,0,0,MagickTrue,exception);\n            if (dup_image == (Image *) NULL)\n              {\n                bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n                disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n                prev_image=DestroyImage(prev_image);\n                return((Image *) NULL);\n              }\n            dup_image->background_color.alpha_trait=BlendPixelTrait;\n            dup_bounds=CompareImagesBounds(dup_image,curr,CompareClearLayer,exception);\n            ClearBounds(dup_image,&dup_bounds,exception);\n            try_bounds=CompareImagesBounds(dup_image,curr,CompareAnyLayer,exception);\n            if ( cleared ||\n                   dup_bounds.width*dup_bounds.height\n                      +try_bounds.width*try_bounds.height\n                   < bounds[i].width * bounds[i].height )\n              {\n                cleared=MagickFalse;\n                bounds[i]=try_bounds;\n                disposals[i-1]=DupDispose;\n                /* to be finalised later, if found to be optimial */\n              }\n            else\n              dup_bounds.width=dup_bounds.height=0;\n          }\n        /*\n          Now compare against a simple background disposal\n        */\n        bgnd_image=CloneImage(curr->previous,0,0,MagickTrue,exception);\n        if (bgnd_image == (Image *) NULL)\n          {\n            bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n            disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n            prev_image=DestroyImage(prev_image);\n            if ( dup_image != (Image *) NULL)\n              dup_image=DestroyImage(dup_image);\n            return((Image *) NULL);\n          }\n        bgnd_image->background_color.alpha_trait=BlendPixelTrait;\n        bgnd_bounds=bounds[i-1]; /* interum bounds of the previous image */\n        ClearBounds(bgnd_image,&bgnd_bounds,exception);\n        try_bounds=CompareImagesBounds(bgnd_image,curr,CompareAnyLayer,exception);\n        try_cleared=IsBoundsCleared(bgnd_image,curr,&try_bounds,exception);\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"background: %s\\n\",\n         try_cleared?\"(pixels cleared)\":\"\");\n#endif\n        if ( try_cleared )\n          {\n            /*\n              Straight background disposal failed to clear pixels needed!\n              Lets try expanding the disposal area of the previous frame, to\n              include the pixels that are cleared.  This guaranteed\n              to work, though may not be the most optimized solution.\n            */\n            try_bounds=CompareImagesBounds(curr->previous,curr,CompareClearLayer,exception);\n#if DEBUG_OPT_FRAME\n            (void) FormatLocaleFile(stderr, \"expand_clear: %.20gx%.20g%+.20g%+.20g%s\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y,\n                try_bounds.x<0?\"  (no expand nessary)\":\"\");\n#endif\n            if ( bgnd_bounds.x < 0 )\n              bgnd_bounds = try_bounds;\n            else\n              {\n#if DEBUG_OPT_FRAME\n                (void) FormatLocaleFile(stderr, \"expand_bgnd: %.20gx%.20g%+.20g%+.20g\\n\",\n                    (double) bgnd_bounds.width,(double) bgnd_bounds.height,\n                    (double) bgnd_bounds.x,(double) bgnd_bounds.y );\n#endif\n                if ( try_bounds.x < bgnd_bounds.x )\n                  {\n                     bgnd_bounds.width+= bgnd_bounds.x-try_bounds.x;\n                     if ( bgnd_bounds.width < try_bounds.width )\n                       bgnd_bounds.width = try_bounds.width;\n                     bgnd_bounds.x = try_bounds.x;\n                  }\n                else\n                  {\n                     try_bounds.width += try_bounds.x - bgnd_bounds.x;\n                     if ( bgnd_bounds.width < try_bounds.width )\n                       bgnd_bounds.width = try_bounds.width;\n                  }\n                if ( try_bounds.y < bgnd_bounds.y )\n                  {\n                     bgnd_bounds.height += bgnd_bounds.y - try_bounds.y;\n                     if ( bgnd_bounds.height < try_bounds.height )\n                       bgnd_bounds.height = try_bounds.height;\n                     bgnd_bounds.y = try_bounds.y;\n                  }\n                else\n                  {\n                    try_bounds.height += try_bounds.y - bgnd_bounds.y;\n                     if ( bgnd_bounds.height < try_bounds.height )\n                       bgnd_bounds.height = try_bounds.height;\n                  }\n#if DEBUG_OPT_FRAME\n                (void) FormatLocaleFile(stderr, \"        to : %.20gx%.20g%+.20g%+.20g\\n\",\n                    (double) bgnd_bounds.width,(double) bgnd_bounds.height,\n                    (double) bgnd_bounds.x,(double) bgnd_bounds.y );\n#endif\n              }\n            ClearBounds(bgnd_image,&bgnd_bounds,exception);\n#if DEBUG_OPT_FRAME\n/* Something strange is happening with a specific animation\n * CompareAnyLayers (normal method) and CompareClearLayers returns the whole\n * image, which is not posibly correct!  As verified by previous tests.\n * Something changed beyond the bgnd_bounds clearing.  But without being able\n * to see, or writet he image at this point it is hard to tell what is wrong!\n * Only CompareOverlay seemed to return something sensible.\n */\n            try_bounds=CompareImagesBounds(bgnd_image,curr,CompareClearLayer,exception);\n            (void) FormatLocaleFile(stderr, \"expand_ctst: %.20gx%.20g%+.20g%+.20g\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y );\n            try_bounds=CompareImagesBounds(bgnd_image,curr,CompareAnyLayer,exception);\n            try_cleared=IsBoundsCleared(bgnd_image,curr,&try_bounds,exception);\n            (void) FormatLocaleFile(stderr, \"expand_any : %.20gx%.20g%+.20g%+.20g%s\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y,\n                try_cleared?\"   (pixels cleared)\":\"\");\n#endif\n            try_bounds=CompareImagesBounds(bgnd_image,curr,CompareOverlayLayer,exception);\n#if DEBUG_OPT_FRAME\n            try_cleared=IsBoundsCleared(bgnd_image,curr,&try_bounds,exception);\n            (void) FormatLocaleFile(stderr, \"expand_test: %.20gx%.20g%+.20g%+.20g%s\\n\",\n                (double) try_bounds.width,(double) try_bounds.height,\n                (double) try_bounds.x,(double) try_bounds.y,\n                try_cleared?\"   (pixels cleared)\":\"\");\n#endif\n          }\n        /*\n          Test if this background dispose is smaller than any of the\n          other methods we tryed before this (including duplicated frame)\n        */\n        if ( cleared ||\n              bgnd_bounds.width*bgnd_bounds.height\n                +try_bounds.width*try_bounds.height\n              < bounds[i-1].width*bounds[i-1].height\n                  +dup_bounds.width*dup_bounds.height\n                  +bounds[i].width*bounds[i].height )\n          {\n            cleared=MagickFalse;\n            bounds[i-1]=bgnd_bounds;\n            bounds[i]=try_bounds;\n            if ( disposals[i-1] == DupDispose )\n              dup_image=DestroyImage(dup_image);\n            disposals[i-1]=BackgroundDispose;\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr,\"expand_bgnd: accepted\\n\");\n          } else {\n    (void) FormatLocaleFile(stderr,\"expand_bgnd: reject\\n\");\n#endif\n          }\n      }\n    /*\n       Finalise choice of dispose, set new prev_image,\n       and junk any extra images as appropriate,\n    */\n    if ( disposals[i-1] == DupDispose )\n      {\n         if (bgnd_image != (Image *) NULL)\n           bgnd_image=DestroyImage(bgnd_image);\n         prev_image=DestroyImage(prev_image);\n         prev_image=dup_image, dup_image=(Image *) NULL;\n         bounds[i+1]=bounds[i];\n         bounds[i]=dup_bounds;\n         disposals[i-1]=DupDispose;\n         disposals[i]=BackgroundDispose;\n         i++;\n      }\n    else\n      {\n        if ( dup_image != (Image *) NULL)\n          dup_image=DestroyImage(dup_image);\n        if ( disposals[i-1] != PreviousDispose )\n          prev_image=DestroyImage(prev_image);\n        if ( disposals[i-1] == BackgroundDispose )\n          prev_image=bgnd_image, bgnd_image=(Image *) NULL;\n        if (bgnd_image != (Image *) NULL)\n          bgnd_image=DestroyImage(bgnd_image);\n        if ( disposals[i-1] == NoneDispose )\n          {\n            prev_image=ReferenceImage(curr->previous);\n            if (prev_image == (Image *) NULL)\n              {\n                bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n                disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n                return((Image *) NULL);\n              }\n          }\n\n      }\n    assert(prev_image != (Image *) NULL);\n    disposals[i]=disposals[i-1];\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"final   %.20g : %s  %.20gx%.20g%+.20g%+.20g\\n\",\n         (double) i-1,\n         CommandOptionToMnemonic(MagickDisposeOptions,disposals[i-1]),\n         (double) bounds[i-1].width,(double) bounds[i-1].height,\n         (double) bounds[i-1].x,(double) bounds[i-1].y );\n#endif\n#if DEBUG_OPT_FRAME\n    (void) FormatLocaleFile(stderr, \"interum %.20g : %s  %.20gx%.20g%+.20g%+.20g\\n\",\n         (double) i,\n         CommandOptionToMnemonic(MagickDisposeOptions,disposals[i]),\n         (double) bounds[i].width,(double) bounds[i].height,\n         (double) bounds[i].x,(double) bounds[i].y );\n    (void) FormatLocaleFile(stderr,\"\\n\");\n#endif\n    i++;\n  }\n  prev_image=DestroyImage(prev_image);\n  /*\n    Optimize all images in sequence.\n  */\n  sans_exception=AcquireExceptionInfo();\n  i=0;\n  curr=GetFirstImageInList(image);\n  optimized_image=NewImageList();\n  while ( curr != (const Image *) NULL )\n  {\n    prev_image=CloneImage(curr,0,0,MagickTrue,exception);\n    if (prev_image == (Image *) NULL)\n      break;\n    prev_image->background_color.alpha_trait=BlendPixelTrait;\n    if ( disposals[i] == DelDispose ) {\n      size_t time = 0;\n      while ( disposals[i] == DelDispose ) {\n        time +=(size_t) (curr->delay*1000*\n          PerceptibleReciprocal((double) curr->ticks_per_second));\n        curr=GetNextImageInList(curr);\n        i++;\n      }\n      time += (size_t)(curr->delay*1000*\n        PerceptibleReciprocal((double) curr->ticks_per_second));\n      prev_image->ticks_per_second = 100L;\n      prev_image->delay = time*prev_image->ticks_per_second/1000;\n    }\n    bgnd_image=CropImage(prev_image,&bounds[i],sans_exception);\n    prev_image=DestroyImage(prev_image);\n    if (bgnd_image == (Image *) NULL)\n      break;\n    bgnd_image->dispose=disposals[i];\n    if ( disposals[i] == DupDispose ) {\n      bgnd_image->delay=0;\n      bgnd_image->dispose=NoneDispose;\n    }\n    else\n      curr=GetNextImageInList(curr);\n    AppendImageToList(&optimized_image,bgnd_image);\n    i++;\n  }\n  sans_exception=DestroyExceptionInfo(sans_exception);\n  bounds=(RectangleInfo *) RelinquishMagickMemory(bounds);\n  disposals=(DisposeType *) RelinquishMagickMemory(disposals);\n  if (curr != (Image *) NULL)\n    {\n      optimized_image=DestroyImageList(optimized_image);\n      return((Image *) NULL);\n    }\n  return(GetFirstImageInList(optimized_image));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -415,11 +415,13 @@\n     if ( disposals[i] == DelDispose ) {\n       size_t time = 0;\n       while ( disposals[i] == DelDispose ) {\n-        time += curr->delay*1000/curr->ticks_per_second;\n+        time +=(size_t) (curr->delay*1000*\n+          PerceptibleReciprocal((double) curr->ticks_per_second));\n         curr=GetNextImageInList(curr);\n         i++;\n       }\n-      time += curr->delay*1000/curr->ticks_per_second;\n+      time += (size_t)(curr->delay*1000*\n+        PerceptibleReciprocal((double) curr->ticks_per_second));\n       prev_image->ticks_per_second = 100L;\n       prev_image->delay = time*prev_image->ticks_per_second/1000;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        time += curr->delay*1000/curr->ticks_per_second;",
                "      time += curr->delay*1000/curr->ticks_per_second;"
            ],
            "added_lines": [
                "        time +=(size_t) (curr->delay*1000*",
                "          PerceptibleReciprocal((double) curr->ticks_per_second));",
                "      time += (size_t)(curr->delay*1000*",
                "        PerceptibleReciprocal((double) curr->ticks_per_second));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-20241",
        "func_name": "ImageMagick/WriteJP2Image",
        "description": "A flaw was found in ImageMagick in coders/jp2.c. An attacker who submits a crafted file that is processed by ImageMagick could trigger undefined behavior in the form of math division by zero. The highest threat from this vulnerability is to system availability.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/1e59e000ecae2523e707242621738da27d0d6296",
        "commit_title": "fix division by zero in WriteJP2Image() in coders/jp2.c",
        "commit_text": "",
        "func_before": "static MagickBooleanType WriteJP2Image(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  const char\n    *option,\n    *property;\n\n  int\n    jp2_status;\n\n  MagickBooleanType\n    status;\n\n  opj_codec_t\n    *jp2_codec;\n\n  OPJ_COLOR_SPACE\n    jp2_colorspace;\n\n  opj_cparameters_t\n    *parameters;\n\n  opj_image_cmptparm_t\n    jp2_info[5];\n\n  opj_image_t\n    *jp2_image;\n\n  opj_stream_t\n    *jp2_stream;\n\n  ssize_t\n    i;\n\n  ssize_t\n    y;\n\n  unsigned int\n    channels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  /*\n    Initialize JPEG 2000 API.\n  */\n  parameters=(opj_cparameters_t *) AcquireMagickMemory(sizeof(*parameters));\n  if (parameters == (opj_cparameters_t *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n  opj_set_default_encoder_parameters(parameters);\n  option=GetImageOption(image_info,\"jp2:number-resolutions\");\n  if (option != (const char *) NULL)\n    parameters->numresolution=StringToInteger(option);\n  else\n    parameters->numresolution=CalculateNumResolutions(image->columns,\n      image->rows);\n  parameters->tcp_numlayers=1;\n  parameters->tcp_rates[0]=0;  /* lossless */\n  parameters->cp_disto_alloc=1;\n  if ((image_info->quality != 0) && (image_info->quality != 100))\n    {\n      parameters->tcp_distoratio[0]=(double) image_info->quality;\n      parameters->cp_fixed_quality=OPJ_TRUE;\n      parameters->cp_disto_alloc=0;\n    }\n  if (image_info->extract != (char *) NULL)\n    {\n      RectangleInfo\n        geometry;\n\n      int\n        flags;\n\n      /*\n        Set tile size.\n      */\n      (void) memset(&geometry,0,sizeof(geometry));\n      flags=ParseAbsoluteGeometry(image_info->extract,&geometry);\n      parameters->cp_tdx=(int) geometry.width;\n      parameters->cp_tdy=(int) geometry.width;\n      if ((flags & HeightValue) != 0)\n        parameters->cp_tdy=(int) geometry.height;\n      if ((flags & XValue) != 0)\n        parameters->cp_tx0=geometry.x;\n      if ((flags & YValue) != 0)\n        parameters->cp_ty0=geometry.y;\n      parameters->tile_size_on=OPJ_TRUE;\n      parameters->numresolution=CalculateNumResolutions(parameters->cp_tdx,\n        parameters->cp_tdy);\n    }\n  option=GetImageOption(image_info,\"jp2:quality\");\n  if (option != (const char *) NULL)\n    {\n      const char\n        *p;\n\n      /*\n        Set quality PSNR.\n      */\n      p=option;\n      for (i=0; sscanf(p,\"%f\",&parameters->tcp_distoratio[i]) == 1; i++)\n      {\n        if (i > 100)\n          break;\n        while ((*p != '\\0') && (*p != ','))\n          p++;\n        if (*p == '\\0')\n          break;\n        p++;\n      }\n      parameters->tcp_numlayers=i+1;\n      parameters->cp_fixed_quality=OPJ_TRUE;\n      parameters->cp_disto_alloc=0;\n    }\n  option=GetImageOption(image_info,\"jp2:progression-order\");\n  if (option != (const char *) NULL)\n    {\n      if (LocaleCompare(option,\"LRCP\") == 0)\n        parameters->prog_order=OPJ_LRCP;\n      if (LocaleCompare(option,\"RLCP\") == 0)\n        parameters->prog_order=OPJ_RLCP;\n      if (LocaleCompare(option,\"RPCL\") == 0)\n        parameters->prog_order=OPJ_RPCL;\n      if (LocaleCompare(option,\"PCRL\") == 0)\n        parameters->prog_order=OPJ_PCRL;\n      if (LocaleCompare(option,\"CPRL\") == 0)\n        parameters->prog_order=OPJ_CPRL;\n    }\n  option=GetImageOption(image_info,\"jp2:rate\");\n  if (option != (const char *) NULL)\n    {\n      const char\n        *p;\n\n      /*\n        Set compression rate.\n      */\n      p=option;\n      for (i=0; sscanf(p,\"%f\",&parameters->tcp_rates[i]) == 1; i++)\n      {\n        if (i >= 100)\n          break;\n        while ((*p != '\\0') && (*p != ','))\n          p++;\n        if (*p == '\\0')\n          break;\n        p++;\n      }\n      parameters->tcp_numlayers=i+1;\n      parameters->cp_disto_alloc=OPJ_TRUE;\n    }\n  if (image_info->sampling_factor != (const char *) NULL)\n    (void) sscanf(image_info->sampling_factor,\"%d,%d\",\n      &parameters->subsampling_dx,&parameters->subsampling_dy);\n  property=GetImageProperty(image,\"comment\",exception);\n  if (property != (const char *) NULL)\n    parameters->cp_comment=(char *) property;\n  channels=3;\n  jp2_colorspace=OPJ_CLRSPC_SRGB;\n  if (image->colorspace == YUVColorspace)\n    {\n      jp2_colorspace=OPJ_CLRSPC_SYCC;\n      parameters->subsampling_dx=2;\n    }\n  else\n    {\n      if (IsGrayColorspace(image->colorspace) != MagickFalse)\n        {\n          channels=1;\n          jp2_colorspace=OPJ_CLRSPC_GRAY;\n        }\n      else\n        (void) TransformImageColorspace(image,sRGBColorspace,exception);\n      if (image->alpha_trait != UndefinedPixelTrait)\n        channels++;\n    }\n  parameters->tcp_mct=channels == 3 ? 1 : 0;\n  memset(jp2_info,0,sizeof(jp2_info));\n  for (i=0; i < (ssize_t) channels; i++)\n  {\n    jp2_info[i].prec=(OPJ_UINT32) image->depth;\n    jp2_info[i].bpp=(OPJ_UINT32) image->depth;\n    if ((image->depth == 1) &&\n        ((LocaleCompare(image_info->magick,\"JPT\") == 0) ||\n         (LocaleCompare(image_info->magick,\"JP2\") == 0)))\n      {\n        jp2_info[i].prec++;  /* OpenJPEG returns exception for depth @ 1 */\n        jp2_info[i].bpp++;\n      }\n    jp2_info[i].sgnd=0;\n    jp2_info[i].dx=parameters->subsampling_dx;\n    jp2_info[i].dy=parameters->subsampling_dy;\n    jp2_info[i].w=(OPJ_UINT32) image->columns;\n    jp2_info[i].h=(OPJ_UINT32) image->rows;\n  }\n  jp2_image=opj_image_create((OPJ_UINT32) channels,jp2_info,jp2_colorspace);\n  if (jp2_image == (opj_image_t *) NULL)\n    {\n      parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n      ThrowWriterException(DelegateError,\"UnableToEncodeImageFile\");\n    }\n  jp2_image->x0=parameters->image_offset_x0;\n  jp2_image->y0=parameters->image_offset_y0;\n  jp2_image->x1=(unsigned int) (2*parameters->image_offset_x0+\n    (image->columns-1)*parameters->subsampling_dx+1);\n  jp2_image->y1=(unsigned int) (2*parameters->image_offset_y0+\n    (image->rows-1)*parameters->subsampling_dx+1);\n  if ((image->depth == 12) &&\n      ((image->columns == 2048) || (image->rows == 1080) ||\n       (image->columns == 4096) || (image->rows == 2160)))\n    CinemaProfileCompliance(jp2_image,parameters);\n  if (channels == 4)\n    jp2_image->comps[3].alpha=1;\n  else\n   if ((channels == 2) && (jp2_colorspace == OPJ_CLRSPC_GRAY))\n     jp2_image->comps[1].alpha=1;\n  /*\n    Convert to JP2 pixels.\n  */\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    const Quantum\n      *p;\n\n    ssize_t\n      x;\n\n    p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      for (i=0; i < (ssize_t) channels; i++)\n      {\n        double\n          scale;\n\n        int\n          *q;\n\n        scale=(double) (((size_t) 1UL << jp2_image->comps[i].prec)-1)/\n          QuantumRange;\n        q=jp2_image->comps[i].data+(y/jp2_image->comps[i].dy*\n          image->columns/jp2_image->comps[i].dx+x/jp2_image->comps[i].dx);\n        switch (i)\n        {\n          case 0:\n          {\n            if (jp2_colorspace == OPJ_CLRSPC_GRAY)\n              {\n                *q=(int) (scale*GetPixelGray(image,p));\n                break;\n              }\n            *q=(int) (scale*GetPixelRed(image,p));\n            break;\n          }\n          case 1:\n          {\n            if (jp2_colorspace == OPJ_CLRSPC_GRAY)\n              {\n                *q=(int) (scale*GetPixelAlpha(image,p));\n                break;\n              }\n            *q=(int) (scale*GetPixelGreen(image,p));\n            break;\n          }\n          case 2:\n          {\n            *q=(int) (scale*GetPixelBlue(image,p));\n            break;\n          }\n          case 3:\n          {\n            *q=(int) (scale*GetPixelAlpha(image,p));\n            break;\n          }\n        }\n      }\n      p+=GetPixelChannels(image);\n    }\n    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n      image->rows);\n    if (status == MagickFalse)\n      break;\n  }\n  if (LocaleCompare(image_info->magick,\"JPT\") == 0)\n    jp2_codec=opj_create_compress(OPJ_CODEC_JPT);\n  else\n    if (LocaleCompare(image_info->magick,\"J2K\") == 0)\n      jp2_codec=opj_create_compress(OPJ_CODEC_J2K);\n    else\n      jp2_codec=opj_create_compress(OPJ_CODEC_JP2);\n  opj_set_warning_handler(jp2_codec,JP2WarningHandler,exception);\n  opj_set_error_handler(jp2_codec,JP2ErrorHandler,exception);\n  opj_setup_encoder(jp2_codec,parameters,jp2_image);\n  jp2_stream=opj_stream_create(OPJ_J2K_STREAM_CHUNK_SIZE,OPJ_FALSE);\n  if (jp2_stream == (opj_stream_t *) NULL)\n    {\n      opj_destroy_codec(jp2_codec);\n      opj_image_destroy(jp2_image);\n      parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n      ThrowWriterException(DelegateError,\"UnableToEncodeImageFile\");\n    }\n  opj_stream_set_read_function(jp2_stream,JP2ReadHandler);\n  opj_stream_set_write_function(jp2_stream,JP2WriteHandler);\n  opj_stream_set_seek_function(jp2_stream,JP2SeekHandler);\n  opj_stream_set_skip_function(jp2_stream,JP2SkipHandler);\n  opj_stream_set_user_data(jp2_stream,image,NULL);\n  jp2_status=opj_start_compress(jp2_codec,jp2_image,jp2_stream);\n  if ((jp2_status == 0) || (opj_encode(jp2_codec,jp2_stream) == 0) ||\n      (opj_end_compress(jp2_codec,jp2_stream) == 0))\n    {\n      opj_stream_destroy(jp2_stream);\n      opj_destroy_codec(jp2_codec);\n      opj_image_destroy(jp2_image);\n      parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n      ThrowWriterException(DelegateError,\"UnableToEncodeImageFile\");\n    }\n  /*\n    Free resources.\n  */\n  opj_stream_destroy(jp2_stream);\n  opj_destroy_codec(jp2_codec);\n  opj_image_destroy(jp2_image);\n  parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}",
        "func": "static MagickBooleanType WriteJP2Image(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  const char\n    *option,\n    *property;\n\n  int\n    jp2_status;\n\n  MagickBooleanType\n    status;\n\n  opj_codec_t\n    *jp2_codec;\n\n  OPJ_COLOR_SPACE\n    jp2_colorspace;\n\n  opj_cparameters_t\n    *parameters;\n\n  opj_image_cmptparm_t\n    jp2_info[5];\n\n  opj_image_t\n    *jp2_image;\n\n  opj_stream_t\n    *jp2_stream;\n\n  ssize_t\n    i;\n\n  ssize_t\n    y;\n\n  unsigned int\n    channels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  /*\n    Initialize JPEG 2000 API.\n  */\n  parameters=(opj_cparameters_t *) AcquireMagickMemory(sizeof(*parameters));\n  if (parameters == (opj_cparameters_t *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n  opj_set_default_encoder_parameters(parameters);\n  option=GetImageOption(image_info,\"jp2:number-resolutions\");\n  if (option != (const char *) NULL)\n    parameters->numresolution=StringToInteger(option);\n  else\n    parameters->numresolution=CalculateNumResolutions(image->columns,\n      image->rows);\n  parameters->tcp_numlayers=1;\n  parameters->tcp_rates[0]=0;  /* lossless */\n  parameters->cp_disto_alloc=1;\n  if ((image_info->quality != 0) && (image_info->quality != 100))\n    {\n      parameters->tcp_distoratio[0]=(double) image_info->quality;\n      parameters->cp_fixed_quality=OPJ_TRUE;\n      parameters->cp_disto_alloc=0;\n    }\n  if (image_info->extract != (char *) NULL)\n    {\n      RectangleInfo\n        geometry;\n\n      int\n        flags;\n\n      /*\n        Set tile size.\n      */\n      (void) memset(&geometry,0,sizeof(geometry));\n      flags=ParseAbsoluteGeometry(image_info->extract,&geometry);\n      parameters->cp_tdx=(int) geometry.width;\n      parameters->cp_tdy=(int) geometry.width;\n      if ((flags & HeightValue) != 0)\n        parameters->cp_tdy=(int) geometry.height;\n      if ((flags & XValue) != 0)\n        parameters->cp_tx0=geometry.x;\n      if ((flags & YValue) != 0)\n        parameters->cp_ty0=geometry.y;\n      parameters->tile_size_on=OPJ_TRUE;\n      parameters->numresolution=CalculateNumResolutions(parameters->cp_tdx,\n        parameters->cp_tdy);\n    }\n  option=GetImageOption(image_info,\"jp2:quality\");\n  if (option != (const char *) NULL)\n    {\n      const char\n        *p;\n\n      /*\n        Set quality PSNR.\n      */\n      p=option;\n      for (i=0; sscanf(p,\"%f\",&parameters->tcp_distoratio[i]) == 1; i++)\n      {\n        if (i > 100)\n          break;\n        while ((*p != '\\0') && (*p != ','))\n          p++;\n        if (*p == '\\0')\n          break;\n        p++;\n      }\n      parameters->tcp_numlayers=i+1;\n      parameters->cp_fixed_quality=OPJ_TRUE;\n      parameters->cp_disto_alloc=0;\n    }\n  option=GetImageOption(image_info,\"jp2:progression-order\");\n  if (option != (const char *) NULL)\n    {\n      if (LocaleCompare(option,\"LRCP\") == 0)\n        parameters->prog_order=OPJ_LRCP;\n      if (LocaleCompare(option,\"RLCP\") == 0)\n        parameters->prog_order=OPJ_RLCP;\n      if (LocaleCompare(option,\"RPCL\") == 0)\n        parameters->prog_order=OPJ_RPCL;\n      if (LocaleCompare(option,\"PCRL\") == 0)\n        parameters->prog_order=OPJ_PCRL;\n      if (LocaleCompare(option,\"CPRL\") == 0)\n        parameters->prog_order=OPJ_CPRL;\n    }\n  option=GetImageOption(image_info,\"jp2:rate\");\n  if (option != (const char *) NULL)\n    {\n      const char\n        *p;\n\n      /*\n        Set compression rate.\n      */\n      p=option;\n      for (i=0; sscanf(p,\"%f\",&parameters->tcp_rates[i]) == 1; i++)\n      {\n        if (i >= 100)\n          break;\n        while ((*p != '\\0') && (*p != ','))\n          p++;\n        if (*p == '\\0')\n          break;\n        p++;\n      }\n      parameters->tcp_numlayers=i+1;\n      parameters->cp_disto_alloc=OPJ_TRUE;\n    }\n  if (image_info->sampling_factor != (const char *) NULL)\n    (void) sscanf(image_info->sampling_factor,\"%d,%d\",\n      &parameters->subsampling_dx,&parameters->subsampling_dy);\n  property=GetImageProperty(image,\"comment\",exception);\n  if (property != (const char *) NULL)\n    parameters->cp_comment=(char *) property;\n  channels=3;\n  jp2_colorspace=OPJ_CLRSPC_SRGB;\n  if (image->colorspace == YUVColorspace)\n    {\n      jp2_colorspace=OPJ_CLRSPC_SYCC;\n      parameters->subsampling_dx=2;\n    }\n  else\n    {\n      if (IsGrayColorspace(image->colorspace) != MagickFalse)\n        {\n          channels=1;\n          jp2_colorspace=OPJ_CLRSPC_GRAY;\n        }\n      else\n        (void) TransformImageColorspace(image,sRGBColorspace,exception);\n      if (image->alpha_trait != UndefinedPixelTrait)\n        channels++;\n    }\n  parameters->tcp_mct=channels == 3 ? 1 : 0;\n  memset(jp2_info,0,sizeof(jp2_info));\n  for (i=0; i < (ssize_t) channels; i++)\n  {\n    jp2_info[i].prec=(OPJ_UINT32) image->depth;\n    jp2_info[i].bpp=(OPJ_UINT32) image->depth;\n    if ((image->depth == 1) &&\n        ((LocaleCompare(image_info->magick,\"JPT\") == 0) ||\n         (LocaleCompare(image_info->magick,\"JP2\") == 0)))\n      {\n        jp2_info[i].prec++;  /* OpenJPEG returns exception for depth @ 1 */\n        jp2_info[i].bpp++;\n      }\n    jp2_info[i].sgnd=0;\n    jp2_info[i].dx=parameters->subsampling_dx;\n    jp2_info[i].dy=parameters->subsampling_dy;\n    jp2_info[i].w=(OPJ_UINT32) image->columns;\n    jp2_info[i].h=(OPJ_UINT32) image->rows;\n  }\n  jp2_image=opj_image_create((OPJ_UINT32) channels,jp2_info,jp2_colorspace);\n  if (jp2_image == (opj_image_t *) NULL)\n    {\n      parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n      ThrowWriterException(DelegateError,\"UnableToEncodeImageFile\");\n    }\n  jp2_image->x0=parameters->image_offset_x0;\n  jp2_image->y0=parameters->image_offset_y0;\n  jp2_image->x1=(unsigned int) (2*parameters->image_offset_x0+\n    (image->columns-1)*parameters->subsampling_dx+1);\n  jp2_image->y1=(unsigned int) (2*parameters->image_offset_y0+\n    (image->rows-1)*parameters->subsampling_dx+1);\n  if ((image->depth == 12) &&\n      ((image->columns == 2048) || (image->rows == 1080) ||\n       (image->columns == 4096) || (image->rows == 2160)))\n    CinemaProfileCompliance(jp2_image,parameters);\n  if (channels == 4)\n    jp2_image->comps[3].alpha=1;\n  else\n   if ((channels == 2) && (jp2_colorspace == OPJ_CLRSPC_GRAY))\n     jp2_image->comps[1].alpha=1;\n  /*\n    Convert to JP2 pixels.\n  */\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    const Quantum\n      *p;\n\n    ssize_t\n      x;\n\n    p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      for (i=0; i < (ssize_t) channels; i++)\n      {\n        double\n          scale;\n\n        int\n          *q;\n\n        scale=(double) (((size_t) 1UL << jp2_image->comps[i].prec)-1)/\n          QuantumRange;\n        q=jp2_image->comps[i].data+(y*PerceptibleReciprocal(jp2_image->comps[i].dy)*\n          image->columns*PerceptibleReciprocal(jp2_image->comps[i].dx)+x*PerceptibleReciprocal(jp2_image->comps[i].dx));\n        switch (i)\n        {\n          case 0:\n          {\n            if (jp2_colorspace == OPJ_CLRSPC_GRAY)\n              {\n                *q=(int) (scale*GetPixelGray(image,p));\n                break;\n              }\n            *q=(int) (scale*GetPixelRed(image,p));\n            break;\n          }\n          case 1:\n          {\n            if (jp2_colorspace == OPJ_CLRSPC_GRAY)\n              {\n                *q=(int) (scale*GetPixelAlpha(image,p));\n                break;\n              }\n            *q=(int) (scale*GetPixelGreen(image,p));\n            break;\n          }\n          case 2:\n          {\n            *q=(int) (scale*GetPixelBlue(image,p));\n            break;\n          }\n          case 3:\n          {\n            *q=(int) (scale*GetPixelAlpha(image,p));\n            break;\n          }\n        }\n      }\n      p+=GetPixelChannels(image);\n    }\n    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n      image->rows);\n    if (status == MagickFalse)\n      break;\n  }\n  if (LocaleCompare(image_info->magick,\"JPT\") == 0)\n    jp2_codec=opj_create_compress(OPJ_CODEC_JPT);\n  else\n    if (LocaleCompare(image_info->magick,\"J2K\") == 0)\n      jp2_codec=opj_create_compress(OPJ_CODEC_J2K);\n    else\n      jp2_codec=opj_create_compress(OPJ_CODEC_JP2);\n  opj_set_warning_handler(jp2_codec,JP2WarningHandler,exception);\n  opj_set_error_handler(jp2_codec,JP2ErrorHandler,exception);\n  opj_setup_encoder(jp2_codec,parameters,jp2_image);\n  jp2_stream=opj_stream_create(OPJ_J2K_STREAM_CHUNK_SIZE,OPJ_FALSE);\n  if (jp2_stream == (opj_stream_t *) NULL)\n    {\n      opj_destroy_codec(jp2_codec);\n      opj_image_destroy(jp2_image);\n      parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n      ThrowWriterException(DelegateError,\"UnableToEncodeImageFile\");\n    }\n  opj_stream_set_read_function(jp2_stream,JP2ReadHandler);\n  opj_stream_set_write_function(jp2_stream,JP2WriteHandler);\n  opj_stream_set_seek_function(jp2_stream,JP2SeekHandler);\n  opj_stream_set_skip_function(jp2_stream,JP2SkipHandler);\n  opj_stream_set_user_data(jp2_stream,image,NULL);\n  jp2_status=opj_start_compress(jp2_codec,jp2_image,jp2_stream);\n  if ((jp2_status == 0) || (opj_encode(jp2_codec,jp2_stream) == 0) ||\n      (opj_end_compress(jp2_codec,jp2_stream) == 0))\n    {\n      opj_stream_destroy(jp2_stream);\n      opj_destroy_codec(jp2_codec);\n      opj_image_destroy(jp2_image);\n      parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n      ThrowWriterException(DelegateError,\"UnableToEncodeImageFile\");\n    }\n  /*\n    Free resources.\n  */\n  opj_stream_destroy(jp2_stream);\n  opj_destroy_codec(jp2_codec);\n  opj_image_destroy(jp2_image);\n  parameters=(opj_cparameters_t *) RelinquishMagickMemory(parameters);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -251,8 +251,8 @@\n \n         scale=(double) (((size_t) 1UL << jp2_image->comps[i].prec)-1)/\n           QuantumRange;\n-        q=jp2_image->comps[i].data+(y/jp2_image->comps[i].dy*\n-          image->columns/jp2_image->comps[i].dx+x/jp2_image->comps[i].dx);\n+        q=jp2_image->comps[i].data+(y*PerceptibleReciprocal(jp2_image->comps[i].dy)*\n+          image->columns*PerceptibleReciprocal(jp2_image->comps[i].dx)+x*PerceptibleReciprocal(jp2_image->comps[i].dx));\n         switch (i)\n         {\n           case 0:",
        "diff_line_info": {
            "deleted_lines": [
                "        q=jp2_image->comps[i].data+(y/jp2_image->comps[i].dy*",
                "          image->columns/jp2_image->comps[i].dx+x/jp2_image->comps[i].dx);"
            ],
            "added_lines": [
                "        q=jp2_image->comps[i].data+(y*PerceptibleReciprocal(jp2_image->comps[i].dy)*",
                "          image->columns*PerceptibleReciprocal(jp2_image->comps[i].dx)+x*PerceptibleReciprocal(jp2_image->comps[i].dx));"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-20243",
        "func_name": "ImageMagick/GetResizeFilterWeight",
        "description": "A flaw was found in ImageMagick in MagickCore/resize.c. An attacker who submits a crafted file that is processed by ImageMagick could trigger undefined behavior in the form of math division by zero. The highest threat from this vulnerability is to system availability.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/20d458c47610440db337666e78a5a9e43ec8b07d",
        "commit_title": "uses the PerceptibleReciprocal() to prevent the divide-by-zero from occurring",
        "commit_text": "",
        "func_before": "MagickPrivate double GetResizeFilterWeight(const ResizeFilter *resize_filter,\n  const double x)\n{\n  double\n    scale,\n    weight,\n    x_blur;\n\n  /*\n    Windowing function - scale the weighting filter by this amount.\n  */\n  assert(resize_filter != (ResizeFilter *) NULL);\n  assert(resize_filter->signature == MagickCoreSignature);\n  x_blur=fabs((double) x)/resize_filter->blur;  /* X offset with blur scaling */\n  if ((resize_filter->window_support < MagickEpsilon) ||\n      (resize_filter->window == Box))\n    scale=1.0;  /* Point or Box Filter -- avoid division by zero */\n  else\n    {\n      scale=resize_filter->scale;\n      scale=resize_filter->window(x_blur*scale,resize_filter);\n    }\n  weight=scale*resize_filter->filter(x_blur,resize_filter);\n  return(weight);\n}",
        "func": "MagickPrivate double GetResizeFilterWeight(const ResizeFilter *resize_filter,\n  const double x)\n{\n  double\n    scale,\n    weight,\n    x_blur;\n\n  /*\n    Windowing function - scale the weighting filter by this amount.\n  */\n  assert(resize_filter != (ResizeFilter *) NULL);\n  assert(resize_filter->signature == MagickCoreSignature);\n  x_blur=fabs((double) x)*PerceptibleReciprocal(resize_filter->blur);  /* X offset with blur scaling */\n  if ((resize_filter->window_support < MagickEpsilon) ||\n      (resize_filter->window == Box))\n    scale=1.0;  /* Point or Box Filter -- avoid division by zero */\n  else\n    {\n      scale=resize_filter->scale;\n      scale=resize_filter->window(x_blur*scale,resize_filter);\n    }\n  weight=scale*resize_filter->filter(x_blur,resize_filter);\n  return(weight);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n   */\n   assert(resize_filter != (ResizeFilter *) NULL);\n   assert(resize_filter->signature == MagickCoreSignature);\n-  x_blur=fabs((double) x)/resize_filter->blur;  /* X offset with blur scaling */\n+  x_blur=fabs((double) x)*PerceptibleReciprocal(resize_filter->blur);  /* X offset with blur scaling */\n   if ((resize_filter->window_support < MagickEpsilon) ||\n       (resize_filter->window == Box))\n     scale=1.0;  /* Point or Box Filter -- avoid division by zero */",
        "diff_line_info": {
            "deleted_lines": [
                "  x_blur=fabs((double) x)/resize_filter->blur;  /* X offset with blur scaling */"
            ],
            "added_lines": [
                "  x_blur=fabs((double) x)*PerceptibleReciprocal(resize_filter->blur);  /* X offset with blur scaling */"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-20244",
        "func_name": "ImageMagick/ImplodeImage",
        "description": "A flaw was found in ImageMagick in MagickCore/visual-effects.c. An attacker who submits a crafted file that is processed by ImageMagick could trigger undefined behavior in the form of math division by zero. The highest threat from this vulnerability is to system availability.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/6720594ccb46afeb3365fb54d814271608f754b3",
        "commit_title": "uses the PerceptibleReciprocal() to prevent the divide-by-zero from occurring",
        "commit_text": "",
        "func_before": "MagickExport Image *ImplodeImage(const Image *image,const double amount,\n  const PixelInterpolateMethod method,ExceptionInfo *exception)\n{\n#define ImplodeImageTag  \"Implode/Image\"\n\n  CacheView\n    *canvas_view,\n    *implode_view,\n    *interpolate_view;\n\n  double\n    radius;\n\n  Image\n    *canvas_image,\n    *implode_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  PointInfo\n    center,\n    scale;\n\n  ssize_t\n    y;\n\n  /*\n    Initialize implode image attributes.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  canvas_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (canvas_image == (Image *) NULL)\n    return((Image *) NULL);\n  if ((canvas_image->alpha_trait == UndefinedPixelTrait) &&\n      (canvas_image->background_color.alpha != OpaqueAlpha))\n    (void) SetImageAlphaChannel(canvas_image,OpaqueAlphaChannel,exception);\n  implode_image=CloneImage(canvas_image,0,0,MagickTrue,exception);\n  if (implode_image == (Image *) NULL)\n    {\n      canvas_image=DestroyImage(canvas_image);\n      return((Image *) NULL);\n    }\n  if (SetImageStorageClass(implode_image,DirectClass,exception) == MagickFalse)\n    {\n      canvas_image=DestroyImage(canvas_image);\n      implode_image=DestroyImage(implode_image);\n      return((Image *) NULL);\n    }\n  /*\n    Compute scaling factor.\n  */\n  scale.x=1.0;\n  scale.y=1.0;\n  center.x=0.5*canvas_image->columns;\n  center.y=0.5*canvas_image->rows;\n  radius=center.x;\n  if (canvas_image->columns > canvas_image->rows)\n    scale.y=(double) canvas_image->columns/(double) canvas_image->rows;\n  else\n    if (canvas_image->columns < canvas_image->rows)\n      {\n        scale.x=(double) canvas_image->rows/(double) canvas_image->columns;\n        radius=center.y;\n      }\n  /*\n    Implode image.\n  */\n  status=MagickTrue;\n  progress=0;\n  canvas_view=AcquireVirtualCacheView(canvas_image,exception);\n  interpolate_view=AcquireVirtualCacheView(canvas_image,exception);\n  implode_view=AcquireAuthenticCacheView(implode_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(canvas_image,implode_image,canvas_image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) canvas_image->rows; y++)\n  {\n    double\n      distance;\n\n    PointInfo\n      delta;\n\n    const Quantum\n      *magick_restrict p;\n\n    ssize_t\n      x;\n\n    Quantum\n      *magick_restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(canvas_view,0,y,canvas_image->columns,1,\n      exception);\n    q=QueueCacheViewAuthenticPixels(implode_view,0,y,implode_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    delta.y=scale.y*(double) (y-center.y);\n    for (x=0; x < (ssize_t) canvas_image->columns; x++)\n    {\n      ssize_t\n        i;\n\n      /*\n        Determine if the pixel is within an ellipse.\n      */\n      delta.x=scale.x*(double) (x-center.x);\n      distance=delta.x*delta.x+delta.y*delta.y;\n      if (distance >= (radius*radius))\n        for (i=0; i < (ssize_t) GetPixelChannels(canvas_image); i++)\n        {\n          PixelChannel channel = GetPixelChannelChannel(canvas_image,i);\n          PixelTrait traits = GetPixelChannelTraits(canvas_image,channel);\n          PixelTrait implode_traits = GetPixelChannelTraits(implode_image,\n            channel);\n          if ((traits == UndefinedPixelTrait) ||\n              (implode_traits == UndefinedPixelTrait))\n            continue;\n          SetPixelChannel(implode_image,channel,p[i],q);\n        }\n      else\n        {\n          double\n            factor;\n\n          /*\n            Implode the pixel.\n          */\n          factor=1.0;\n          if (distance > 0.0)\n            factor=pow(sin(MagickPI*sqrt((double) distance)/radius/2),-amount);\n          status=InterpolatePixelChannels(canvas_image,interpolate_view,\n            implode_image,method,(double) (factor*delta.x/scale.x+center.x),\n            (double) (factor*delta.y/scale.y+center.y),q,exception);\n          if (status == MagickFalse)\n            break;\n        }\n      p+=GetPixelChannels(canvas_image);\n      q+=GetPixelChannels(implode_image);\n    }\n    if (SyncCacheViewAuthenticPixels(implode_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (canvas_image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(canvas_image,ImplodeImageTag,progress,\n          canvas_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  implode_view=DestroyCacheView(implode_view);\n  interpolate_view=DestroyCacheView(interpolate_view);\n  canvas_view=DestroyCacheView(canvas_view);\n  canvas_image=DestroyImage(canvas_image);\n  if (status == MagickFalse)\n    implode_image=DestroyImage(implode_image);\n  return(implode_image);\n}",
        "func": "MagickExport Image *ImplodeImage(const Image *image,const double amount,\n  const PixelInterpolateMethod method,ExceptionInfo *exception)\n{\n#define ImplodeImageTag  \"Implode/Image\"\n\n  CacheView\n    *canvas_view,\n    *implode_view,\n    *interpolate_view;\n\n  double\n    radius;\n\n  Image\n    *canvas_image,\n    *implode_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  PointInfo\n    center,\n    scale;\n\n  ssize_t\n    y;\n\n  /*\n    Initialize implode image attributes.\n  */\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  canvas_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (canvas_image == (Image *) NULL)\n    return((Image *) NULL);\n  if ((canvas_image->alpha_trait == UndefinedPixelTrait) &&\n      (canvas_image->background_color.alpha != OpaqueAlpha))\n    (void) SetImageAlphaChannel(canvas_image,OpaqueAlphaChannel,exception);\n  implode_image=CloneImage(canvas_image,0,0,MagickTrue,exception);\n  if (implode_image == (Image *) NULL)\n    {\n      canvas_image=DestroyImage(canvas_image);\n      return((Image *) NULL);\n    }\n  if (SetImageStorageClass(implode_image,DirectClass,exception) == MagickFalse)\n    {\n      canvas_image=DestroyImage(canvas_image);\n      implode_image=DestroyImage(implode_image);\n      return((Image *) NULL);\n    }\n  /*\n    Compute scaling factor.\n  */\n  scale.x=1.0;\n  scale.y=1.0;\n  center.x=0.5*canvas_image->columns;\n  center.y=0.5*canvas_image->rows;\n  radius=center.x;\n  if (canvas_image->columns > canvas_image->rows)\n    scale.y=(double) canvas_image->columns*PerceptibleReciprocal((double) canvas_image->rows);\n  else\n    if (canvas_image->columns < canvas_image->rows)\n      {\n        scale.x=(double) canvas_image->rows*PerceptibleReciprocal((double) canvas_image->columns);\n        radius=center.y;\n      }\n  /*\n    Implode image.\n  */\n  status=MagickTrue;\n  progress=0;\n  canvas_view=AcquireVirtualCacheView(canvas_image,exception);\n  interpolate_view=AcquireVirtualCacheView(canvas_image,exception);\n  implode_view=AcquireAuthenticCacheView(implode_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(canvas_image,implode_image,canvas_image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) canvas_image->rows; y++)\n  {\n    double\n      distance;\n\n    PointInfo\n      delta;\n\n    const Quantum\n      *magick_restrict p;\n\n    ssize_t\n      x;\n\n    Quantum\n      *magick_restrict q;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(canvas_view,0,y,canvas_image->columns,1,\n      exception);\n    q=QueueCacheViewAuthenticPixels(implode_view,0,y,implode_image->columns,1,\n      exception);\n    if ((p == (const Quantum *) NULL) || (q == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    delta.y=scale.y*(double) (y-center.y);\n    for (x=0; x < (ssize_t) canvas_image->columns; x++)\n    {\n      ssize_t\n        i;\n\n      /*\n        Determine if the pixel is within an ellipse.\n      */\n      delta.x=scale.x*(double) (x-center.x);\n      distance=delta.x*delta.x+delta.y*delta.y;\n      if (distance >= (radius*radius))\n        for (i=0; i < (ssize_t) GetPixelChannels(canvas_image); i++)\n        {\n          PixelChannel channel = GetPixelChannelChannel(canvas_image,i);\n          PixelTrait traits = GetPixelChannelTraits(canvas_image,channel);\n          PixelTrait implode_traits = GetPixelChannelTraits(implode_image,\n            channel);\n          if ((traits == UndefinedPixelTrait) ||\n              (implode_traits == UndefinedPixelTrait))\n            continue;\n          SetPixelChannel(implode_image,channel,p[i],q);\n        }\n      else\n        {\n          double\n            factor;\n\n          /*\n            Implode the pixel.\n          */\n          factor=1.0;\n          if (distance > 0.0)\n            factor=pow(sin(MagickPI*sqrt((double) distance)*PerceptibleReciprocal(radius)/2),-amount);\n          status=InterpolatePixelChannels(canvas_image,interpolate_view,\n            implode_image,method,(double) (factor*delta.x*PerceptibleReciprocal(scale.x)+center.x),\n            (double) (factor*delta.y*PerceptibleReciprocal(scale.y)+center.y),q,exception);\n          if (status == MagickFalse)\n            break;\n        }\n      p+=GetPixelChannels(canvas_image);\n      q+=GetPixelChannels(implode_image);\n    }\n    if (SyncCacheViewAuthenticPixels(implode_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (canvas_image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(canvas_image,ImplodeImageTag,progress,\n          canvas_image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  implode_view=DestroyCacheView(implode_view);\n  interpolate_view=DestroyCacheView(interpolate_view);\n  canvas_view=DestroyCacheView(canvas_view);\n  canvas_image=DestroyImage(canvas_image);\n  if (status == MagickFalse)\n    implode_image=DestroyImage(implode_image);\n  return(implode_image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -64,11 +64,11 @@\n   center.y=0.5*canvas_image->rows;\n   radius=center.x;\n   if (canvas_image->columns > canvas_image->rows)\n-    scale.y=(double) canvas_image->columns/(double) canvas_image->rows;\n+    scale.y=(double) canvas_image->columns*PerceptibleReciprocal((double) canvas_image->rows);\n   else\n     if (canvas_image->columns < canvas_image->rows)\n       {\n-        scale.x=(double) canvas_image->rows/(double) canvas_image->columns;\n+        scale.x=(double) canvas_image->rows*PerceptibleReciprocal((double) canvas_image->columns);\n         radius=center.y;\n       }\n   /*\n@@ -144,10 +144,10 @@\n           */\n           factor=1.0;\n           if (distance > 0.0)\n-            factor=pow(sin(MagickPI*sqrt((double) distance)/radius/2),-amount);\n+            factor=pow(sin(MagickPI*sqrt((double) distance)*PerceptibleReciprocal(radius)/2),-amount);\n           status=InterpolatePixelChannels(canvas_image,interpolate_view,\n-            implode_image,method,(double) (factor*delta.x/scale.x+center.x),\n-            (double) (factor*delta.y/scale.y+center.y),q,exception);\n+            implode_image,method,(double) (factor*delta.x*PerceptibleReciprocal(scale.x)+center.x),\n+            (double) (factor*delta.y*PerceptibleReciprocal(scale.y)+center.y),q,exception);\n           if (status == MagickFalse)\n             break;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "    scale.y=(double) canvas_image->columns/(double) canvas_image->rows;",
                "        scale.x=(double) canvas_image->rows/(double) canvas_image->columns;",
                "            factor=pow(sin(MagickPI*sqrt((double) distance)/radius/2),-amount);",
                "            implode_image,method,(double) (factor*delta.x/scale.x+center.x),",
                "            (double) (factor*delta.y/scale.y+center.y),q,exception);"
            ],
            "added_lines": [
                "    scale.y=(double) canvas_image->columns*PerceptibleReciprocal((double) canvas_image->rows);",
                "        scale.x=(double) canvas_image->rows*PerceptibleReciprocal((double) canvas_image->columns);",
                "            factor=pow(sin(MagickPI*sqrt((double) distance)*PerceptibleReciprocal(radius)/2),-amount);",
                "            implode_image,method,(double) (factor*delta.x*PerceptibleReciprocal(scale.x)+center.x),",
                "            (double) (factor*delta.y*PerceptibleReciprocal(scale.y)+center.y),q,exception);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-20245",
        "func_name": "ImageMagick/WriteAnimatedWEBPImage",
        "description": "A flaw was found in ImageMagick in coders/webp.c. An attacker who submits a crafted file that is processed by ImageMagick could trigger undefined behavior in the form of math division by zero. The highest threat from this vulnerability is to system availability.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/ffb683e62ddedc6436a1b88388eb690d7ca57bf2",
        "commit_title": "https://github.com/ImageMagick/ImageMagick/issues/3176",
        "commit_text": "",
        "func_before": "static MagickBooleanType WriteAnimatedWEBPImage(const ImageInfo *image_info,\n  Image *image,WebPConfig *configure,WebPData *webp_data,\n  ExceptionInfo *exception)\n{\n  Image\n    *first_image;\n\n  size_t\n    effective_delta,\n    frame_timestamp;\n\n  WebPAnimEncoder\n    *enc;\n\n  WebPAnimEncoderOptions\n    enc_options;\n\n  WebPPicture\n    picture;\n\n  MagickBooleanType\n    status;\n\n  first_image=CoalesceImages(image,exception);\n  if (first_image == (Image *) NULL)\n    return(MagickFalse);\n  image=first_image;\n  effective_delta=0;\n  frame_timestamp=0;\n\n  (void) WebPAnimEncoderOptionsInit(&enc_options);\n  if (image_info->verbose)\n    enc_options.verbose=1;\n  enc=WebPAnimEncoderNew((int) image->page.width,(int) image->page.height,\n    &enc_options);\n\n  status=MagickTrue;\n  while (image != NULL)\n  {\n    status=(MagickBooleanType) WebPPictureInit(&picture);\n    if (status == MagickFalse)\n      {\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          ResourceLimitError,\"UnableToEncodeImageFile\",\"`%s'\",image->filename);\n        break;\n      }\n\n    status=WriteSingleWEBPPicture(image_info,image,configure,&picture,\n      exception);\n    if (status == MagickFalse)\n      break;\n\n    status=(MagickBooleanType) WebPAnimEncoderAdd(enc,&picture,\n      (int) frame_timestamp,configure);\n    WebPPictureFree(&picture);\n    if (status == MagickFalse)\n      {\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          CoderError,WebPAnimEncoderGetError(enc),\"`%s'\",image->filename);\n        break;\n      }\n\n    effective_delta=image->delay*1000/image->ticks_per_second;\n    if (effective_delta < 10)\n      effective_delta=100; /* Consistent with gif2webp */\n    frame_timestamp+=effective_delta;\n\n    image=GetNextImageInList(image);\n  }\n\n  if (status != MagickFalse)\n    {\n      // add last null frame and assemble picture.\n      status=(MagickBooleanType) WebPAnimEncoderAdd(enc,(WebPPicture *) NULL,\n        (int) frame_timestamp,configure);\n      if (status != MagickFalse)\n        status=(MagickBooleanType) WebPAnimEncoderAssemble(enc,webp_data);\n\n      if (status == MagickFalse)\n          (void) ThrowMagickException(exception,GetMagickModule(),\n            CoderError,WebPAnimEncoderGetError(enc),\"`%s'\",\n            first_image->filename);\n    }\n\n  WebPAnimEncoderDelete(enc);\n  DestroyImageList(first_image);\n  return(status);\n}",
        "func": "static MagickBooleanType WriteAnimatedWEBPImage(const ImageInfo *image_info,\n  Image *image,WebPConfig *configure,WebPData *webp_data,\n  ExceptionInfo *exception)\n{\n  Image\n    *first_image;\n\n  size_t\n    effective_delta,\n    frame_timestamp;\n\n  WebPAnimEncoder\n    *enc;\n\n  WebPAnimEncoderOptions\n    enc_options;\n\n  WebPPicture\n    picture;\n\n  MagickBooleanType\n    status;\n\n  first_image=CoalesceImages(image,exception);\n  if (first_image == (Image *) NULL)\n    return(MagickFalse);\n  image=first_image;\n  effective_delta=0;\n  frame_timestamp=0;\n\n  (void) WebPAnimEncoderOptionsInit(&enc_options);\n  if (image_info->verbose)\n    enc_options.verbose=1;\n  enc=WebPAnimEncoderNew((int) image->page.width,(int) image->page.height,\n    &enc_options);\n\n  status=MagickTrue;\n  while (image != NULL)\n  {\n    status=(MagickBooleanType) WebPPictureInit(&picture);\n    if (status == MagickFalse)\n      {\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          ResourceLimitError,\"UnableToEncodeImageFile\",\"`%s'\",image->filename);\n        break;\n      }\n\n    status=WriteSingleWEBPPicture(image_info,image,configure,&picture,\n      exception);\n    if (status == MagickFalse)\n      break;\n\n    status=(MagickBooleanType) WebPAnimEncoderAdd(enc,&picture,\n      (int) frame_timestamp,configure);\n    WebPPictureFree(&picture);\n    if (status == MagickFalse)\n      {\n        (void) ThrowMagickException(exception,GetMagickModule(),\n          CoderError,WebPAnimEncoderGetError(enc),\"`%s'\",image->filename);\n        break;\n      }\n\n    effective_delta=image->delay*1000*PerceptibleReciprocal(\n      image->ticks_per_second);\n    if (effective_delta < 10)\n      effective_delta=100; /* Consistent with gif2webp */\n    frame_timestamp+=effective_delta;\n\n    image=GetNextImageInList(image);\n  }\n\n  if (status != MagickFalse)\n    {\n      // add last null frame and assemble picture.\n      status=(MagickBooleanType) WebPAnimEncoderAdd(enc,(WebPPicture *) NULL,\n        (int) frame_timestamp,configure);\n      if (status != MagickFalse)\n        status=(MagickBooleanType) WebPAnimEncoderAssemble(enc,webp_data);\n\n      if (status == MagickFalse)\n          (void) ThrowMagickException(exception,GetMagickModule(),\n            CoderError,WebPAnimEncoderGetError(enc),\"`%s'\",\n            first_image->filename);\n    }\n\n  WebPAnimEncoderDelete(enc);\n  DestroyImageList(first_image);\n  return(status);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -60,7 +60,8 @@\n         break;\n       }\n \n-    effective_delta=image->delay*1000/image->ticks_per_second;\n+    effective_delta=image->delay*1000*PerceptibleReciprocal(\n+      image->ticks_per_second);\n     if (effective_delta < 10)\n       effective_delta=100; /* Consistent with gif2webp */\n     frame_timestamp+=effective_delta;",
        "diff_line_info": {
            "deleted_lines": [
                "    effective_delta=image->delay*1000/image->ticks_per_second;"
            ],
            "added_lines": [
                "    effective_delta=image->delay*1000*PerceptibleReciprocal(",
                "      image->ticks_per_second);"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-28856",
        "func_name": "jsummers/deark/fmtutil_macbitmap_read_pixmap_only_fields",
        "description": "In Deark before v1.5.8, a specially crafted input file can cause a division by zero in (src/fmtutil.c) because of the value of pixelsize.",
        "git_url": "https://github.com/jsummers/deark/commit/62acb7753b0e3c0d3ab3c15057b0a65222313334",
        "commit_title": "pict,macrsrc: Fixed a bug that could cause division by 0",
        "commit_text": " Found by F. elik.",
        "func_before": "void fmtutil_macbitmap_read_pixmap_only_fields(deark *c, dbuf *f, struct fmtutil_macbitmap_info *bi,\n\ti64 pos)\n{\n\ti64 pixmap_version;\n\ti64 pack_size;\n\ti64 plane_bytes;\n\ti64 n;\n\n\tde_dbg(c, \"additional PixMap header fields, at %d\", (int)pos);\n\tde_dbg_indent(c, 1);\n\n\tpixmap_version = dbuf_getu16be(f, pos+0);\n\tde_dbg(c, \"pixmap version: %d\", (int)pixmap_version);\n\n\tbi->packing_type = dbuf_getu16be(f, pos+2);\n\tde_dbg(c, \"packing type: %d\", (int)bi->packing_type);\n\n\tpack_size = dbuf_getu32be(f, pos+4);\n\tde_dbg(c, \"pixel data length: %d\", (int)pack_size);\n\n\tbi->hdpi = pict_read_fixed(f, pos+8);\n\tbi->vdpi = pict_read_fixed(f, pos+12);\n\tde_dbg(c, \"dpi: %.2f\"DE_CHAR_TIMES\"%.2f\", bi->hdpi, bi->vdpi);\n\n\tbi->pixeltype = dbuf_getu16be(f, pos+16);\n\tbi->pixelsize = dbuf_getu16be(f, pos+18);\n\tbi->cmpcount = dbuf_getu16be(f, pos+20);\n\tbi->cmpsize = dbuf_getu16be(f, pos+22);\n\tde_dbg(c, \"pixel type=%d, bits/pixel=%d, components/pixel=%d, bits/comp=%d\",\n\t\t(int)bi->pixeltype, (int)bi->pixelsize, (int)bi->cmpcount, (int)bi->cmpsize);\n\n\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n\tif(bi->pdwidth < bi->npwidth) {\n\t\tbi->pdwidth = bi->npwidth;\n\t}\n\n\tplane_bytes = dbuf_getu32be(f, pos+24);\n\tde_dbg(c, \"plane bytes: %d\", (int)plane_bytes);\n\n\tbi->pmTable = (u32)dbuf_getu32be(f, pos+28);\n\tde_dbg(c, \"pmTable: 0x%08x\", (unsigned int)bi->pmTable);\n\n\tn = dbuf_getu32be(f, pos+32);\n\tde_dbg(c, \"pmReserved: 0x%08x\", (unsigned int)n);\n\n\tde_dbg_indent(c, -1);\n}",
        "func": "void fmtutil_macbitmap_read_pixmap_only_fields(deark *c, dbuf *f, struct fmtutil_macbitmap_info *bi,\n\ti64 pos)\n{\n\ti64 pixmap_version;\n\ti64 pack_size;\n\ti64 plane_bytes;\n\ti64 n;\n\n\tde_dbg(c, \"additional PixMap header fields, at %d\", (int)pos);\n\tde_dbg_indent(c, 1);\n\n\tpixmap_version = dbuf_getu16be(f, pos+0);\n\tde_dbg(c, \"pixmap version: %d\", (int)pixmap_version);\n\n\tbi->packing_type = dbuf_getu16be(f, pos+2);\n\tde_dbg(c, \"packing type: %d\", (int)bi->packing_type);\n\n\tpack_size = dbuf_getu32be(f, pos+4);\n\tde_dbg(c, \"pixel data length: %d\", (int)pack_size);\n\n\tbi->hdpi = pict_read_fixed(f, pos+8);\n\tbi->vdpi = pict_read_fixed(f, pos+12);\n\tde_dbg(c, \"dpi: %.2f\"DE_CHAR_TIMES\"%.2f\", bi->hdpi, bi->vdpi);\n\n\tbi->pixeltype = dbuf_getu16be(f, pos+16);\n\tbi->pixelsize = dbuf_getu16be(f, pos+18);\n\tbi->cmpcount = dbuf_getu16be(f, pos+20);\n\tbi->cmpsize = dbuf_getu16be(f, pos+22);\n\tde_dbg(c, \"pixel type=%d, bits/pixel=%d, components/pixel=%d, bits/comp=%d\",\n\t\t(int)bi->pixeltype, (int)bi->pixelsize, (int)bi->cmpcount, (int)bi->cmpsize);\n\n\tif(bi->pixelsize>0) {\n\t\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n\t}\n\tif(bi->pdwidth < bi->npwidth) {\n\t\tbi->pdwidth = bi->npwidth;\n\t}\n\n\tplane_bytes = dbuf_getu32be(f, pos+24);\n\tde_dbg(c, \"plane bytes: %d\", (int)plane_bytes);\n\n\tbi->pmTable = (u32)dbuf_getu32be(f, pos+28);\n\tde_dbg(c, \"pmTable: 0x%08x\", (unsigned int)bi->pmTable);\n\n\tn = dbuf_getu32be(f, pos+32);\n\tde_dbg(c, \"pmReserved: 0x%08x\", (unsigned int)n);\n\n\tde_dbg_indent(c, -1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,7 +29,9 @@\n \tde_dbg(c, \"pixel type=%d, bits/pixel=%d, components/pixel=%d, bits/comp=%d\",\n \t\t(int)bi->pixeltype, (int)bi->pixelsize, (int)bi->cmpcount, (int)bi->cmpsize);\n \n-\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n+\tif(bi->pixelsize>0) {\n+\t\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;\n+\t}\n \tif(bi->pdwidth < bi->npwidth) {\n \t\tbi->pdwidth = bi->npwidth;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;"
            ],
            "added_lines": [
                "\tif(bi->pixelsize>0) {",
                "\t\tbi->pdwidth = (bi->rowbytes*8)/bi->pixelsize;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-3896",
        "func_name": "vim/scroll_cursor_bot",
        "description": "Divide By Zero in vim/vim from9.0.1367-1 to9.0.1367-3\n",
        "git_url": "https://github.com/vim/vim/commit/e6db8a95174d0a63ba95504fbb1804b9a551bafd",
        "commit_title": "Fix codestyle.",
        "commit_text": "",
        "func_before": "void\nscroll_cursor_bot(int min_scroll, int set_topbot)\n{\n    int\t\tused;\n    int\t\tscrolled = 0;\n    int\t\textra = 0;\n    int\t\ti;\n    linenr_T\tline_count;\n    linenr_T\told_topline = curwin->w_topline;\n    int\t\told_skipcol = curwin->w_skipcol;\n    lineoff_T\tloff;\n    lineoff_T\tboff;\n#ifdef FEAT_DIFF\n    int\t\told_topfill = curwin->w_topfill;\n    int\t\tfill_below_window;\n#endif\n    linenr_T\told_botline = curwin->w_botline;\n    linenr_T\told_valid = curwin->w_valid;\n    int\t\told_empty_rows = curwin->w_empty_rows;\n    linenr_T\tcln;\t\t    // Cursor Line Number\n    long\tso = get_scrolloff_value();\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n\n    cln = curwin->w_cursor.lnum;\n    if (set_topbot)\n    {\n\tint set_skipcol = FALSE;\n\n\tused = 0;\n\tcurwin->w_botline = cln + 1;\n#ifdef FEAT_DIFF\n\tloff.fill = 0;\n#endif\n\tfor (curwin->w_topline = curwin->w_botline;\n\t\tcurwin->w_topline > 1;\n\t\tcurwin->w_topline = loff.lnum)\n\t{\n\t    loff.lnum = curwin->w_topline;\n\t    topline_back_winheight(&loff, FALSE);\n\t    if (loff.height == MAXCOL)\n\t\tbreak;\n\t    if (used + loff.height > curwin->w_height)\n\t    {\n\t\tif (do_sms)\n\t\t{\n\t\t    // 'smoothscroll' and 'wrap' are set.  The above line is\n\t\t    // too long to show in its entirety, so we show just a part\n\t\t    // of it.\n\t\t    if (used < curwin->w_height)\n\t\t    {\n\t\t\tint plines_offset = used + loff.height\n\t\t\t\t\t\t\t    - curwin->w_height;\n\t\t\tused = curwin->w_height;\n#ifdef FEAT_DIFF\n\t\t\tcurwin->w_topfill = loff.fill;\n#endif\n\t\t\tcurwin->w_topline = loff.lnum;\n\t\t\tcurwin->w_skipcol = skipcol_from_plines(\n\t\t\t\t\t\t\tcurwin, plines_offset);\n\t\t\tset_skipcol = TRUE;\n\t\t    }\n\t\t}\n\t\tbreak;\n\t    }\n\t    used += loff.height;\n#ifdef FEAT_DIFF\n\t    curwin->w_topfill = loff.fill;\n#endif\n\t}\n\tset_empty_rows(curwin, used);\n\tcurwin->w_valid |= VALID_BOTLINE|VALID_BOTLINE_AP;\n\tif (curwin->w_topline != old_topline\n#ifdef FEAT_DIFF\n\t\t|| curwin->w_topfill != old_topfill\n#endif\n\t\t|| set_skipcol\n\t\t|| curwin->w_skipcol != 0)\n\t{\n\t    curwin->w_valid &= ~(VALID_WROW|VALID_CROW);\n\t    if (set_skipcol)\n\t\tredraw_later(UPD_NOT_VALID);\n\t    else\n\t\treset_skipcol();\n\t}\n    }\n    else\n\tvalidate_botline();\n\n    // The lines of the cursor line itself are always used.\n#ifdef FEAT_DIFF\n    used = plines_nofill(cln);\n#else\n    validate_cheight();\n    used = curwin->w_cline_height;\n#endif\n\n    // If the cursor is on or below botline, we will at least scroll by the\n    // height of the cursor line, which is \"used\".  Correct for empty lines,\n    // which are really part of botline.\n    if (cln >= curwin->w_botline)\n    {\n\tscrolled = used;\n\tif (cln == curwin->w_botline)\n\t    scrolled -= curwin->w_empty_rows;\n\tif (do_sms)\n\t{\n\t    // 'smoothscroll' and 'wrap' are set.\n\t    // Calculate how many screen lines the current top line of window\n\t    // occupies. If it is occupying more than the entire window, we\n\t    // need to scroll the additional clipped lines to scroll past the\n\t    // top line before we can move on to the other lines.\n\t    int top_plines =\n#ifdef FEAT_DIFF\n\t\t\t    plines_win_nofill\n#else\n\t\t\t    plines_win\n#endif\n\t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n\t    int skip_lines = 0;\n\t    int width1 = curwin->w_width - curwin_col_off();\n\t    if (width1 > 0) {\n\t\tint width2 = width1 + curwin_col_off2();\n\t\t// similar formula is used in curs_columns()\n\t\tif (curwin->w_skipcol > width1)\n\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n\t\telse if (curwin->w_skipcol > 0)\n\t\t    skip_lines = 1;\n\n\t\ttop_plines -= skip_lines;\n\t\tif (top_plines > curwin->w_height)\n\t\t{\n\t\t    scrolled += (top_plines - curwin->w_height);\n\t\t}\n\t    }\n\t}\n    }\n\n    /*\n     * Stop counting lines to scroll when\n     * - hitting start of the file\n     * - scrolled nothing or at least 'sj' lines\n     * - at least 'scrolloff' lines below the cursor\n     * - lines between botline and cursor have been counted\n     */\n#ifdef FEAT_FOLDING\n    if (!hasFolding(curwin->w_cursor.lnum, &loff.lnum, &boff.lnum))\n#endif\n    {\n\tloff.lnum = cln;\n\tboff.lnum = cln;\n    }\n#ifdef FEAT_DIFF\n    loff.fill = 0;\n    boff.fill = 0;\n    fill_below_window = diff_check_fill(curwin, curwin->w_botline)\n\t\t\t\t\t\t      - curwin->w_filler_rows;\n#endif\n\n    while (loff.lnum > 1)\n    {\n\t// Stop when scrolled nothing or at least \"min_scroll\", found \"extra\"\n\t// context for 'scrolloff' and counted all lines below the window.\n\tif ((((scrolled <= 0 || scrolled >= min_scroll)\n\t\t    && extra >= (mouse_dragging > 0 ? mouse_dragging - 1 : so))\n\t\t    || boff.lnum + 1 > curbuf->b_ml.ml_line_count)\n\t\t&& loff.lnum <= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum < curwin->w_botline\n\t\t    || loff.fill >= fill_below_window)\n#endif\n\t\t)\n\t    break;\n\n\t// Add one line above\n\ttopline_back(&loff);\n\tif (loff.height == MAXCOL)\n\t    used = MAXCOL;\n\telse\n\t    used += loff.height;\n\tif (used > curwin->w_height)\n\t    break;\n\tif (loff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum > curwin->w_botline\n\t\t    || loff.fill <= fill_below_window)\n#endif\n\t\t)\n\t{\n\t    // Count screen lines that are below the window.\n\t    scrolled += loff.height;\n\t    if (loff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && loff.fill == 0\n#endif\n\t\t    )\n\t\tscrolled -= curwin->w_empty_rows;\n\t}\n\n\tif (boff.lnum < curbuf->b_ml.ml_line_count)\n\t{\n\t    // Add one line below\n\t    botline_forw(&boff);\n\t    used += boff.height;\n\t    if (used > curwin->w_height)\n\t\tbreak;\n\t    if (extra < ( mouse_dragging > 0 ? mouse_dragging - 1 : so)\n\t\t    || scrolled < min_scroll)\n\t    {\n\t\textra += boff.height;\n\t\tif (boff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t|| (boff.lnum + 1 == curwin->w_botline\n\t\t\t    && boff.fill > curwin->w_filler_rows)\n#endif\n\t\t   )\n\t\t{\n\t\t    // Count screen lines that are below the window.\n\t\t    scrolled += boff.height;\n\t\t    if (boff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && boff.fill == 0\n#endif\n\t\t\t    )\n\t\t\tscrolled -= curwin->w_empty_rows;\n\t\t}\n\t    }\n\t}\n    }\n\n    // curwin->w_empty_rows is larger, no need to scroll\n    if (scrolled <= 0)\n\tline_count = 0;\n    // more than a screenfull, don't scroll but redraw\n    else if (used > curwin->w_height)\n\tline_count = used;\n    // scroll minimal number of lines\n    else\n    {\n\tline_count = 0;\n#ifdef FEAT_DIFF\n\tboff.fill = curwin->w_topfill;\n#endif\n\tboff.lnum = curwin->w_topline - 1;\n\tfor (i = 0; i < scrolled && boff.lnum < curwin->w_botline; )\n\t{\n\t    botline_forw(&boff);\n\t    i += boff.height;\n\t    ++line_count;\n\t}\n\tif (i < scrolled)\t// below curwin->w_botline, don't scroll\n\t    line_count = 9999;\n    }\n\n    /*\n     * Scroll up if the cursor is off the bottom of the screen a bit.\n     * Otherwise put it at 1/2 of the screen.\n     */\n    if (line_count >= curwin->w_height && line_count > min_scroll)\n\tscroll_cursor_halfway(FALSE, TRUE);\n    else if (line_count > 0)\n    {\n\tif (do_sms)\n\t    scrollup(scrolled, TRUE);  // TODO\n\telse\n\t    scrollup(line_count, TRUE);\n    }\n\n    /*\n     * If topline didn't change we need to restore w_botline and w_empty_rows\n     * (we changed them).\n     * If topline did change, update_screen() will set botline.\n     */\n    if (curwin->w_topline == old_topline\n\t    && curwin->w_skipcol == old_skipcol\n\t    && set_topbot)\n    {\n\tcurwin->w_botline = old_botline;\n\tcurwin->w_empty_rows = old_empty_rows;\n\tcurwin->w_valid = old_valid;\n    }\n    curwin->w_valid |= VALID_TOPLINE;\n}",
        "func": "void\nscroll_cursor_bot(int min_scroll, int set_topbot)\n{\n    int\t\tused;\n    int\t\tscrolled = 0;\n    int\t\textra = 0;\n    int\t\ti;\n    linenr_T\tline_count;\n    linenr_T\told_topline = curwin->w_topline;\n    int\t\told_skipcol = curwin->w_skipcol;\n    lineoff_T\tloff;\n    lineoff_T\tboff;\n#ifdef FEAT_DIFF\n    int\t\told_topfill = curwin->w_topfill;\n    int\t\tfill_below_window;\n#endif\n    linenr_T\told_botline = curwin->w_botline;\n    linenr_T\told_valid = curwin->w_valid;\n    int\t\told_empty_rows = curwin->w_empty_rows;\n    linenr_T\tcln;\t\t    // Cursor Line Number\n    long\tso = get_scrolloff_value();\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n\n    cln = curwin->w_cursor.lnum;\n    if (set_topbot)\n    {\n\tint set_skipcol = FALSE;\n\n\tused = 0;\n\tcurwin->w_botline = cln + 1;\n#ifdef FEAT_DIFF\n\tloff.fill = 0;\n#endif\n\tfor (curwin->w_topline = curwin->w_botline;\n\t\tcurwin->w_topline > 1;\n\t\tcurwin->w_topline = loff.lnum)\n\t{\n\t    loff.lnum = curwin->w_topline;\n\t    topline_back_winheight(&loff, FALSE);\n\t    if (loff.height == MAXCOL)\n\t\tbreak;\n\t    if (used + loff.height > curwin->w_height)\n\t    {\n\t\tif (do_sms)\n\t\t{\n\t\t    // 'smoothscroll' and 'wrap' are set.  The above line is\n\t\t    // too long to show in its entirety, so we show just a part\n\t\t    // of it.\n\t\t    if (used < curwin->w_height)\n\t\t    {\n\t\t\tint plines_offset = used + loff.height\n\t\t\t\t\t\t\t    - curwin->w_height;\n\t\t\tused = curwin->w_height;\n#ifdef FEAT_DIFF\n\t\t\tcurwin->w_topfill = loff.fill;\n#endif\n\t\t\tcurwin->w_topline = loff.lnum;\n\t\t\tcurwin->w_skipcol = skipcol_from_plines(\n\t\t\t\t\t\t\tcurwin, plines_offset);\n\t\t\tset_skipcol = TRUE;\n\t\t    }\n\t\t}\n\t\tbreak;\n\t    }\n\t    used += loff.height;\n#ifdef FEAT_DIFF\n\t    curwin->w_topfill = loff.fill;\n#endif\n\t}\n\tset_empty_rows(curwin, used);\n\tcurwin->w_valid |= VALID_BOTLINE|VALID_BOTLINE_AP;\n\tif (curwin->w_topline != old_topline\n#ifdef FEAT_DIFF\n\t\t|| curwin->w_topfill != old_topfill\n#endif\n\t\t|| set_skipcol\n\t\t|| curwin->w_skipcol != 0)\n\t{\n\t    curwin->w_valid &= ~(VALID_WROW|VALID_CROW);\n\t    if (set_skipcol)\n\t\tredraw_later(UPD_NOT_VALID);\n\t    else\n\t\treset_skipcol();\n\t}\n    }\n    else\n\tvalidate_botline();\n\n    // The lines of the cursor line itself are always used.\n#ifdef FEAT_DIFF\n    used = plines_nofill(cln);\n#else\n    validate_cheight();\n    used = curwin->w_cline_height;\n#endif\n\n    // If the cursor is on or below botline, we will at least scroll by the\n    // height of the cursor line, which is \"used\".  Correct for empty lines,\n    // which are really part of botline.\n    if (cln >= curwin->w_botline)\n    {\n\tscrolled = used;\n\tif (cln == curwin->w_botline)\n\t    scrolled -= curwin->w_empty_rows;\n\tif (do_sms)\n\t{\n\t    // 'smoothscroll' and 'wrap' are set.\n\t    // Calculate how many screen lines the current top line of window\n\t    // occupies. If it is occupying more than the entire window, we\n\t    // need to scroll the additional clipped lines to scroll past the\n\t    // top line before we can move on to the other lines.\n\t    int top_plines =\n#ifdef FEAT_DIFF\n\t\t\t    plines_win_nofill\n#else\n\t\t\t    plines_win\n#endif\n\t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n\t    int skip_lines = 0;\n\t    int width1 = curwin->w_width - curwin_col_off();\n\t    if (width1 > 0)\n\t    {\n\t\tint width2 = width1 + curwin_col_off2();\n\t\t// similar formula is used in curs_columns()\n\t\tif (curwin->w_skipcol > width1)\n\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n\t\telse if (curwin->w_skipcol > 0)\n\t\t    skip_lines = 1;\n\n\t\ttop_plines -= skip_lines;\n\t\tif (top_plines > curwin->w_height)\n\t\t{\n\t\t    scrolled += (top_plines - curwin->w_height);\n\t\t}\n\t    }\n\t}\n    }\n\n    /*\n     * Stop counting lines to scroll when\n     * - hitting start of the file\n     * - scrolled nothing or at least 'sj' lines\n     * - at least 'scrolloff' lines below the cursor\n     * - lines between botline and cursor have been counted\n     */\n#ifdef FEAT_FOLDING\n    if (!hasFolding(curwin->w_cursor.lnum, &loff.lnum, &boff.lnum))\n#endif\n    {\n\tloff.lnum = cln;\n\tboff.lnum = cln;\n    }\n#ifdef FEAT_DIFF\n    loff.fill = 0;\n    boff.fill = 0;\n    fill_below_window = diff_check_fill(curwin, curwin->w_botline)\n\t\t\t\t\t\t      - curwin->w_filler_rows;\n#endif\n\n    while (loff.lnum > 1)\n    {\n\t// Stop when scrolled nothing or at least \"min_scroll\", found \"extra\"\n\t// context for 'scrolloff' and counted all lines below the window.\n\tif ((((scrolled <= 0 || scrolled >= min_scroll)\n\t\t    && extra >= (mouse_dragging > 0 ? mouse_dragging - 1 : so))\n\t\t    || boff.lnum + 1 > curbuf->b_ml.ml_line_count)\n\t\t&& loff.lnum <= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum < curwin->w_botline\n\t\t    || loff.fill >= fill_below_window)\n#endif\n\t\t)\n\t    break;\n\n\t// Add one line above\n\ttopline_back(&loff);\n\tif (loff.height == MAXCOL)\n\t    used = MAXCOL;\n\telse\n\t    used += loff.height;\n\tif (used > curwin->w_height)\n\t    break;\n\tif (loff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum > curwin->w_botline\n\t\t    || loff.fill <= fill_below_window)\n#endif\n\t\t)\n\t{\n\t    // Count screen lines that are below the window.\n\t    scrolled += loff.height;\n\t    if (loff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && loff.fill == 0\n#endif\n\t\t    )\n\t\tscrolled -= curwin->w_empty_rows;\n\t}\n\n\tif (boff.lnum < curbuf->b_ml.ml_line_count)\n\t{\n\t    // Add one line below\n\t    botline_forw(&boff);\n\t    used += boff.height;\n\t    if (used > curwin->w_height)\n\t\tbreak;\n\t    if (extra < ( mouse_dragging > 0 ? mouse_dragging - 1 : so)\n\t\t    || scrolled < min_scroll)\n\t    {\n\t\textra += boff.height;\n\t\tif (boff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t|| (boff.lnum + 1 == curwin->w_botline\n\t\t\t    && boff.fill > curwin->w_filler_rows)\n#endif\n\t\t   )\n\t\t{\n\t\t    // Count screen lines that are below the window.\n\t\t    scrolled += boff.height;\n\t\t    if (boff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && boff.fill == 0\n#endif\n\t\t\t    )\n\t\t\tscrolled -= curwin->w_empty_rows;\n\t\t}\n\t    }\n\t}\n    }\n\n    // curwin->w_empty_rows is larger, no need to scroll\n    if (scrolled <= 0)\n\tline_count = 0;\n    // more than a screenfull, don't scroll but redraw\n    else if (used > curwin->w_height)\n\tline_count = used;\n    // scroll minimal number of lines\n    else\n    {\n\tline_count = 0;\n#ifdef FEAT_DIFF\n\tboff.fill = curwin->w_topfill;\n#endif\n\tboff.lnum = curwin->w_topline - 1;\n\tfor (i = 0; i < scrolled && boff.lnum < curwin->w_botline; )\n\t{\n\t    botline_forw(&boff);\n\t    i += boff.height;\n\t    ++line_count;\n\t}\n\tif (i < scrolled)\t// below curwin->w_botline, don't scroll\n\t    line_count = 9999;\n    }\n\n    /*\n     * Scroll up if the cursor is off the bottom of the screen a bit.\n     * Otherwise put it at 1/2 of the screen.\n     */\n    if (line_count >= curwin->w_height && line_count > min_scroll)\n\tscroll_cursor_halfway(FALSE, TRUE);\n    else if (line_count > 0)\n    {\n\tif (do_sms)\n\t    scrollup(scrolled, TRUE);  // TODO\n\telse\n\t    scrollup(line_count, TRUE);\n    }\n\n    /*\n     * If topline didn't change we need to restore w_botline and w_empty_rows\n     * (we changed them).\n     * If topline did change, update_screen() will set botline.\n     */\n    if (curwin->w_topline == old_topline\n\t    && curwin->w_skipcol == old_skipcol\n\t    && set_topbot)\n    {\n\tcurwin->w_botline = old_botline;\n\tcurwin->w_empty_rows = old_empty_rows;\n\tcurwin->w_valid = old_valid;\n    }\n    curwin->w_valid |= VALID_TOPLINE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -118,7 +118,8 @@\n \t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n \t    int skip_lines = 0;\n \t    int width1 = curwin->w_width - curwin_col_off();\n-\t    if (width1 > 0) {\n+\t    if (width1 > 0)\n+\t    {\n \t\tint width2 = width1 + curwin_col_off2();\n \t\t// similar formula is used in curs_columns()\n \t\tif (curwin->w_skipcol > width1)",
        "diff_line_info": {
            "deleted_lines": [
                "\t    if (width1 > 0) {"
            ],
            "added_lines": [
                "\t    if (width1 > 0)",
                "\t    {"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-3896",
        "func_name": "vim/scroll_cursor_bot",
        "description": "Divide By Zero in vim/vim from9.0.1367-1 to9.0.1367-3\n",
        "git_url": "https://github.com/vim/vim/commit/8154e642aa476e1a5d3de66c34e8289845b2b797",
        "commit_title": "patch 9.0.1664: divide by zero when scrolling with 'smoothscroll' set",
        "commit_text": " Problem:    Divide by zero when scrolling with 'smoothscroll' set. Solution:   Avoid using a negative width. (closes #12540, closes #12528)",
        "func_before": "void\nscroll_cursor_bot(int min_scroll, int set_topbot)\n{\n    int\t\tused;\n    int\t\tscrolled = 0;\n    int\t\textra = 0;\n    int\t\ti;\n    linenr_T\tline_count;\n    linenr_T\told_topline = curwin->w_topline;\n    int\t\told_skipcol = curwin->w_skipcol;\n    lineoff_T\tloff;\n    lineoff_T\tboff;\n#ifdef FEAT_DIFF\n    int\t\told_topfill = curwin->w_topfill;\n    int\t\tfill_below_window;\n#endif\n    linenr_T\told_botline = curwin->w_botline;\n    linenr_T\told_valid = curwin->w_valid;\n    int\t\told_empty_rows = curwin->w_empty_rows;\n    linenr_T\tcln;\t\t    // Cursor Line Number\n    long\tso = get_scrolloff_value();\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n\n    cln = curwin->w_cursor.lnum;\n    if (set_topbot)\n    {\n\tint set_skipcol = FALSE;\n\n\tused = 0;\n\tcurwin->w_botline = cln + 1;\n#ifdef FEAT_DIFF\n\tloff.fill = 0;\n#endif\n\tfor (curwin->w_topline = curwin->w_botline;\n\t\tcurwin->w_topline > 1;\n\t\tcurwin->w_topline = loff.lnum)\n\t{\n\t    loff.lnum = curwin->w_topline;\n\t    topline_back_winheight(&loff, FALSE);\n\t    if (loff.height == MAXCOL)\n\t\tbreak;\n\t    if (used + loff.height > curwin->w_height)\n\t    {\n\t\tif (do_sms)\n\t\t{\n\t\t    // 'smoothscroll' and 'wrap' are set.  The above line is\n\t\t    // too long to show in its entirety, so we show just a part\n\t\t    // of it.\n\t\t    if (used < curwin->w_height)\n\t\t    {\n\t\t\tint plines_offset = used + loff.height\n\t\t\t\t\t\t\t    - curwin->w_height;\n\t\t\tused = curwin->w_height;\n#ifdef FEAT_DIFF\n\t\t\tcurwin->w_topfill = loff.fill;\n#endif\n\t\t\tcurwin->w_topline = loff.lnum;\n\t\t\tcurwin->w_skipcol = skipcol_from_plines(\n\t\t\t\t\t\t\tcurwin, plines_offset);\n\t\t\tset_skipcol = TRUE;\n\t\t    }\n\t\t}\n\t\tbreak;\n\t    }\n\t    used += loff.height;\n#ifdef FEAT_DIFF\n\t    curwin->w_topfill = loff.fill;\n#endif\n\t}\n\tset_empty_rows(curwin, used);\n\tcurwin->w_valid |= VALID_BOTLINE|VALID_BOTLINE_AP;\n\tif (curwin->w_topline != old_topline\n#ifdef FEAT_DIFF\n\t\t|| curwin->w_topfill != old_topfill\n#endif\n\t\t|| set_skipcol\n\t\t|| curwin->w_skipcol != 0)\n\t{\n\t    curwin->w_valid &= ~(VALID_WROW|VALID_CROW);\n\t    if (set_skipcol)\n\t\tredraw_later(UPD_NOT_VALID);\n\t    else\n\t\treset_skipcol();\n\t}\n    }\n    else\n\tvalidate_botline();\n\n    // The lines of the cursor line itself are always used.\n#ifdef FEAT_DIFF\n    used = plines_nofill(cln);\n#else\n    validate_cheight();\n    used = curwin->w_cline_height;\n#endif\n\n    // If the cursor is on or below botline, we will at least scroll by the\n    // height of the cursor line, which is \"used\".  Correct for empty lines,\n    // which are really part of botline.\n    if (cln >= curwin->w_botline)\n    {\n\tscrolled = used;\n\tif (cln == curwin->w_botline)\n\t    scrolled -= curwin->w_empty_rows;\n\tif (do_sms)\n\t{\n\t    // 'smoothscroll' and 'wrap' are set.\n\t    // Calculate how many screen lines the current top line of window\n\t    // occupies. If it is occupying more than the entire window, we\n\t    // need to scroll the additional clipped lines to scroll past the\n\t    // top line before we can move on to the other lines.\n\t    int top_plines =\n#ifdef FEAT_DIFF\n\t\t\t    plines_win_nofill\n#else\n\t\t\t    plines_win\n#endif\n\t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n\t    int skip_lines = 0;\n\t    int width1 = curwin->w_width - curwin_col_off();\n\t    int width2 = width1 + curwin_col_off2();\n\t    // similar formula is used in curs_columns()\n\t    if (curwin->w_skipcol > width1)\n\t\tskip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n\t    else if (curwin->w_skipcol > 0)\n\t\tskip_lines = 1;\n\n\t    top_plines -= skip_lines;\n\t    if (top_plines > curwin->w_height)\n\t    {\n\t\tscrolled += (top_plines - curwin->w_height);\n\t    }\n\t}\n    }\n\n    /*\n     * Stop counting lines to scroll when\n     * - hitting start of the file\n     * - scrolled nothing or at least 'sj' lines\n     * - at least 'scrolloff' lines below the cursor\n     * - lines between botline and cursor have been counted\n     */\n#ifdef FEAT_FOLDING\n    if (!hasFolding(curwin->w_cursor.lnum, &loff.lnum, &boff.lnum))\n#endif\n    {\n\tloff.lnum = cln;\n\tboff.lnum = cln;\n    }\n#ifdef FEAT_DIFF\n    loff.fill = 0;\n    boff.fill = 0;\n    fill_below_window = diff_check_fill(curwin, curwin->w_botline)\n\t\t\t\t\t\t      - curwin->w_filler_rows;\n#endif\n\n    while (loff.lnum > 1)\n    {\n\t// Stop when scrolled nothing or at least \"min_scroll\", found \"extra\"\n\t// context for 'scrolloff' and counted all lines below the window.\n\tif ((((scrolled <= 0 || scrolled >= min_scroll)\n\t\t    && extra >= (mouse_dragging > 0 ? mouse_dragging - 1 : so))\n\t\t    || boff.lnum + 1 > curbuf->b_ml.ml_line_count)\n\t\t&& loff.lnum <= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum < curwin->w_botline\n\t\t    || loff.fill >= fill_below_window)\n#endif\n\t\t)\n\t    break;\n\n\t// Add one line above\n\ttopline_back(&loff);\n\tif (loff.height == MAXCOL)\n\t    used = MAXCOL;\n\telse\n\t    used += loff.height;\n\tif (used > curwin->w_height)\n\t    break;\n\tif (loff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum > curwin->w_botline\n\t\t    || loff.fill <= fill_below_window)\n#endif\n\t\t)\n\t{\n\t    // Count screen lines that are below the window.\n\t    scrolled += loff.height;\n\t    if (loff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && loff.fill == 0\n#endif\n\t\t    )\n\t\tscrolled -= curwin->w_empty_rows;\n\t}\n\n\tif (boff.lnum < curbuf->b_ml.ml_line_count)\n\t{\n\t    // Add one line below\n\t    botline_forw(&boff);\n\t    used += boff.height;\n\t    if (used > curwin->w_height)\n\t\tbreak;\n\t    if (extra < ( mouse_dragging > 0 ? mouse_dragging - 1 : so)\n\t\t    || scrolled < min_scroll)\n\t    {\n\t\textra += boff.height;\n\t\tif (boff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t|| (boff.lnum + 1 == curwin->w_botline\n\t\t\t    && boff.fill > curwin->w_filler_rows)\n#endif\n\t\t   )\n\t\t{\n\t\t    // Count screen lines that are below the window.\n\t\t    scrolled += boff.height;\n\t\t    if (boff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && boff.fill == 0\n#endif\n\t\t\t    )\n\t\t\tscrolled -= curwin->w_empty_rows;\n\t\t}\n\t    }\n\t}\n    }\n\n    // curwin->w_empty_rows is larger, no need to scroll\n    if (scrolled <= 0)\n\tline_count = 0;\n    // more than a screenfull, don't scroll but redraw\n    else if (used > curwin->w_height)\n\tline_count = used;\n    // scroll minimal number of lines\n    else\n    {\n\tline_count = 0;\n#ifdef FEAT_DIFF\n\tboff.fill = curwin->w_topfill;\n#endif\n\tboff.lnum = curwin->w_topline - 1;\n\tfor (i = 0; i < scrolled && boff.lnum < curwin->w_botline; )\n\t{\n\t    botline_forw(&boff);\n\t    i += boff.height;\n\t    ++line_count;\n\t}\n\tif (i < scrolled)\t// below curwin->w_botline, don't scroll\n\t    line_count = 9999;\n    }\n\n    /*\n     * Scroll up if the cursor is off the bottom of the screen a bit.\n     * Otherwise put it at 1/2 of the screen.\n     */\n    if (line_count >= curwin->w_height && line_count > min_scroll)\n\tscroll_cursor_halfway(FALSE, TRUE);\n    else if (line_count > 0)\n    {\n\tif (do_sms)\n\t    scrollup(scrolled, TRUE);  // TODO\n\telse\n\t    scrollup(line_count, TRUE);\n    }\n\n    /*\n     * If topline didn't change we need to restore w_botline and w_empty_rows\n     * (we changed them).\n     * If topline did change, update_screen() will set botline.\n     */\n    if (curwin->w_topline == old_topline\n\t    && curwin->w_skipcol == old_skipcol\n\t    && set_topbot)\n    {\n\tcurwin->w_botline = old_botline;\n\tcurwin->w_empty_rows = old_empty_rows;\n\tcurwin->w_valid = old_valid;\n    }\n    curwin->w_valid |= VALID_TOPLINE;\n}",
        "func": "void\nscroll_cursor_bot(int min_scroll, int set_topbot)\n{\n    int\t\tused;\n    int\t\tscrolled = 0;\n    int\t\textra = 0;\n    int\t\ti;\n    linenr_T\tline_count;\n    linenr_T\told_topline = curwin->w_topline;\n    int\t\told_skipcol = curwin->w_skipcol;\n    lineoff_T\tloff;\n    lineoff_T\tboff;\n#ifdef FEAT_DIFF\n    int\t\told_topfill = curwin->w_topfill;\n    int\t\tfill_below_window;\n#endif\n    linenr_T\told_botline = curwin->w_botline;\n    linenr_T\told_valid = curwin->w_valid;\n    int\t\told_empty_rows = curwin->w_empty_rows;\n    linenr_T\tcln;\t\t    // Cursor Line Number\n    long\tso = get_scrolloff_value();\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n\n    cln = curwin->w_cursor.lnum;\n    if (set_topbot)\n    {\n\tint set_skipcol = FALSE;\n\n\tused = 0;\n\tcurwin->w_botline = cln + 1;\n#ifdef FEAT_DIFF\n\tloff.fill = 0;\n#endif\n\tfor (curwin->w_topline = curwin->w_botline;\n\t\tcurwin->w_topline > 1;\n\t\tcurwin->w_topline = loff.lnum)\n\t{\n\t    loff.lnum = curwin->w_topline;\n\t    topline_back_winheight(&loff, FALSE);\n\t    if (loff.height == MAXCOL)\n\t\tbreak;\n\t    if (used + loff.height > curwin->w_height)\n\t    {\n\t\tif (do_sms)\n\t\t{\n\t\t    // 'smoothscroll' and 'wrap' are set.  The above line is\n\t\t    // too long to show in its entirety, so we show just a part\n\t\t    // of it.\n\t\t    if (used < curwin->w_height)\n\t\t    {\n\t\t\tint plines_offset = used + loff.height\n\t\t\t\t\t\t\t    - curwin->w_height;\n\t\t\tused = curwin->w_height;\n#ifdef FEAT_DIFF\n\t\t\tcurwin->w_topfill = loff.fill;\n#endif\n\t\t\tcurwin->w_topline = loff.lnum;\n\t\t\tcurwin->w_skipcol = skipcol_from_plines(\n\t\t\t\t\t\t\tcurwin, plines_offset);\n\t\t\tset_skipcol = TRUE;\n\t\t    }\n\t\t}\n\t\tbreak;\n\t    }\n\t    used += loff.height;\n#ifdef FEAT_DIFF\n\t    curwin->w_topfill = loff.fill;\n#endif\n\t}\n\tset_empty_rows(curwin, used);\n\tcurwin->w_valid |= VALID_BOTLINE|VALID_BOTLINE_AP;\n\tif (curwin->w_topline != old_topline\n#ifdef FEAT_DIFF\n\t\t|| curwin->w_topfill != old_topfill\n#endif\n\t\t|| set_skipcol\n\t\t|| curwin->w_skipcol != 0)\n\t{\n\t    curwin->w_valid &= ~(VALID_WROW|VALID_CROW);\n\t    if (set_skipcol)\n\t\tredraw_later(UPD_NOT_VALID);\n\t    else\n\t\treset_skipcol();\n\t}\n    }\n    else\n\tvalidate_botline();\n\n    // The lines of the cursor line itself are always used.\n#ifdef FEAT_DIFF\n    used = plines_nofill(cln);\n#else\n    validate_cheight();\n    used = curwin->w_cline_height;\n#endif\n\n    // If the cursor is on or below botline, we will at least scroll by the\n    // height of the cursor line, which is \"used\".  Correct for empty lines,\n    // which are really part of botline.\n    if (cln >= curwin->w_botline)\n    {\n\tscrolled = used;\n\tif (cln == curwin->w_botline)\n\t    scrolled -= curwin->w_empty_rows;\n\tif (do_sms)\n\t{\n\t    // 'smoothscroll' and 'wrap' are set.\n\t    // Calculate how many screen lines the current top line of window\n\t    // occupies. If it is occupying more than the entire window, we\n\t    // need to scroll the additional clipped lines to scroll past the\n\t    // top line before we can move on to the other lines.\n\t    int top_plines =\n#ifdef FEAT_DIFF\n\t\t\t    plines_win_nofill\n#else\n\t\t\t    plines_win\n#endif\n\t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n\t    int skip_lines = 0;\n\t    int width1 = curwin->w_width - curwin_col_off();\n\t    if (width1 > 0)\n\t    {\n\t\tint width2 = width1 + curwin_col_off2();\n\t\t// similar formula is used in curs_columns()\n\t\tif (curwin->w_skipcol > width1)\n\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n\t\telse if (curwin->w_skipcol > 0)\n\t\t    skip_lines = 1;\n\n\t\ttop_plines -= skip_lines;\n\t\tif (top_plines > curwin->w_height)\n\t\t{\n\t\t    scrolled += (top_plines - curwin->w_height);\n\t\t}\n\t    }\n\t}\n    }\n\n    /*\n     * Stop counting lines to scroll when\n     * - hitting start of the file\n     * - scrolled nothing or at least 'sj' lines\n     * - at least 'scrolloff' lines below the cursor\n     * - lines between botline and cursor have been counted\n     */\n#ifdef FEAT_FOLDING\n    if (!hasFolding(curwin->w_cursor.lnum, &loff.lnum, &boff.lnum))\n#endif\n    {\n\tloff.lnum = cln;\n\tboff.lnum = cln;\n    }\n#ifdef FEAT_DIFF\n    loff.fill = 0;\n    boff.fill = 0;\n    fill_below_window = diff_check_fill(curwin, curwin->w_botline)\n\t\t\t\t\t\t      - curwin->w_filler_rows;\n#endif\n\n    while (loff.lnum > 1)\n    {\n\t// Stop when scrolled nothing or at least \"min_scroll\", found \"extra\"\n\t// context for 'scrolloff' and counted all lines below the window.\n\tif ((((scrolled <= 0 || scrolled >= min_scroll)\n\t\t    && extra >= (mouse_dragging > 0 ? mouse_dragging - 1 : so))\n\t\t    || boff.lnum + 1 > curbuf->b_ml.ml_line_count)\n\t\t&& loff.lnum <= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum < curwin->w_botline\n\t\t    || loff.fill >= fill_below_window)\n#endif\n\t\t)\n\t    break;\n\n\t// Add one line above\n\ttopline_back(&loff);\n\tif (loff.height == MAXCOL)\n\t    used = MAXCOL;\n\telse\n\t    used += loff.height;\n\tif (used > curwin->w_height)\n\t    break;\n\tif (loff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum > curwin->w_botline\n\t\t    || loff.fill <= fill_below_window)\n#endif\n\t\t)\n\t{\n\t    // Count screen lines that are below the window.\n\t    scrolled += loff.height;\n\t    if (loff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && loff.fill == 0\n#endif\n\t\t    )\n\t\tscrolled -= curwin->w_empty_rows;\n\t}\n\n\tif (boff.lnum < curbuf->b_ml.ml_line_count)\n\t{\n\t    // Add one line below\n\t    botline_forw(&boff);\n\t    used += boff.height;\n\t    if (used > curwin->w_height)\n\t\tbreak;\n\t    if (extra < ( mouse_dragging > 0 ? mouse_dragging - 1 : so)\n\t\t    || scrolled < min_scroll)\n\t    {\n\t\textra += boff.height;\n\t\tif (boff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t|| (boff.lnum + 1 == curwin->w_botline\n\t\t\t    && boff.fill > curwin->w_filler_rows)\n#endif\n\t\t   )\n\t\t{\n\t\t    // Count screen lines that are below the window.\n\t\t    scrolled += boff.height;\n\t\t    if (boff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && boff.fill == 0\n#endif\n\t\t\t    )\n\t\t\tscrolled -= curwin->w_empty_rows;\n\t\t}\n\t    }\n\t}\n    }\n\n    // curwin->w_empty_rows is larger, no need to scroll\n    if (scrolled <= 0)\n\tline_count = 0;\n    // more than a screenfull, don't scroll but redraw\n    else if (used > curwin->w_height)\n\tline_count = used;\n    // scroll minimal number of lines\n    else\n    {\n\tline_count = 0;\n#ifdef FEAT_DIFF\n\tboff.fill = curwin->w_topfill;\n#endif\n\tboff.lnum = curwin->w_topline - 1;\n\tfor (i = 0; i < scrolled && boff.lnum < curwin->w_botline; )\n\t{\n\t    botline_forw(&boff);\n\t    i += boff.height;\n\t    ++line_count;\n\t}\n\tif (i < scrolled)\t// below curwin->w_botline, don't scroll\n\t    line_count = 9999;\n    }\n\n    /*\n     * Scroll up if the cursor is off the bottom of the screen a bit.\n     * Otherwise put it at 1/2 of the screen.\n     */\n    if (line_count >= curwin->w_height && line_count > min_scroll)\n\tscroll_cursor_halfway(FALSE, TRUE);\n    else if (line_count > 0)\n    {\n\tif (do_sms)\n\t    scrollup(scrolled, TRUE);  // TODO\n\telse\n\t    scrollup(line_count, TRUE);\n    }\n\n    /*\n     * If topline didn't change we need to restore w_botline and w_empty_rows\n     * (we changed them).\n     * If topline did change, update_screen() will set botline.\n     */\n    if (curwin->w_topline == old_topline\n\t    && curwin->w_skipcol == old_skipcol\n\t    && set_topbot)\n    {\n\tcurwin->w_botline = old_botline;\n\tcurwin->w_empty_rows = old_empty_rows;\n\tcurwin->w_valid = old_valid;\n    }\n    curwin->w_valid |= VALID_TOPLINE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -118,17 +118,20 @@\n \t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n \t    int skip_lines = 0;\n \t    int width1 = curwin->w_width - curwin_col_off();\n-\t    int width2 = width1 + curwin_col_off2();\n-\t    // similar formula is used in curs_columns()\n-\t    if (curwin->w_skipcol > width1)\n-\t\tskip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n-\t    else if (curwin->w_skipcol > 0)\n-\t\tskip_lines = 1;\n-\n-\t    top_plines -= skip_lines;\n-\t    if (top_plines > curwin->w_height)\n+\t    if (width1 > 0)\n \t    {\n-\t\tscrolled += (top_plines - curwin->w_height);\n+\t\tint width2 = width1 + curwin_col_off2();\n+\t\t// similar formula is used in curs_columns()\n+\t\tif (curwin->w_skipcol > width1)\n+\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n+\t\telse if (curwin->w_skipcol > 0)\n+\t\t    skip_lines = 1;\n+\n+\t\ttop_plines -= skip_lines;\n+\t\tif (top_plines > curwin->w_height)\n+\t\t{\n+\t\t    scrolled += (top_plines - curwin->w_height);\n+\t\t}\n \t    }\n \t}\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "\t    int width2 = width1 + curwin_col_off2();",
                "\t    // similar formula is used in curs_columns()",
                "\t    if (curwin->w_skipcol > width1)",
                "\t\tskip_lines += (curwin->w_skipcol - width1) / width2 + 1;",
                "\t    else if (curwin->w_skipcol > 0)",
                "\t\tskip_lines = 1;",
                "",
                "\t    top_plines -= skip_lines;",
                "\t    if (top_plines > curwin->w_height)",
                "\t\tscrolled += (top_plines - curwin->w_height);"
            ],
            "added_lines": [
                "\t    if (width1 > 0)",
                "\t\tint width2 = width1 + curwin_col_off2();",
                "\t\t// similar formula is used in curs_columns()",
                "\t\tif (curwin->w_skipcol > width1)",
                "\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;",
                "\t\telse if (curwin->w_skipcol > 0)",
                "\t\t    skip_lines = 1;",
                "",
                "\t\ttop_plines -= skip_lines;",
                "\t\tif (top_plines > curwin->w_height)",
                "\t\t{",
                "\t\t    scrolled += (top_plines - curwin->w_height);",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-3896",
        "func_name": "vim/scroll_cursor_bot",
        "description": "Divide By Zero in vim/vim from9.0.1367-1 to9.0.1367-3\n",
        "git_url": "https://github.com/vim/vim/commit/3d11c74327eef4f2f9fb9c30c4dc3c950a1e71f3",
        "commit_title": "Fix divide-by-zero vulnerability in scroll_cursor_bot.",
        "commit_text": "Fix #12528",
        "func_before": "void\nscroll_cursor_bot(int min_scroll, int set_topbot)\n{\n    int\t\tused;\n    int\t\tscrolled = 0;\n    int\t\textra = 0;\n    int\t\ti;\n    linenr_T\tline_count;\n    linenr_T\told_topline = curwin->w_topline;\n    int\t\told_skipcol = curwin->w_skipcol;\n    lineoff_T\tloff;\n    lineoff_T\tboff;\n#ifdef FEAT_DIFF\n    int\t\told_topfill = curwin->w_topfill;\n    int\t\tfill_below_window;\n#endif\n    linenr_T\told_botline = curwin->w_botline;\n    linenr_T\told_valid = curwin->w_valid;\n    int\t\told_empty_rows = curwin->w_empty_rows;\n    linenr_T\tcln;\t\t    // Cursor Line Number\n    long\tso = get_scrolloff_value();\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n\n    cln = curwin->w_cursor.lnum;\n    if (set_topbot)\n    {\n\tint set_skipcol = FALSE;\n\n\tused = 0;\n\tcurwin->w_botline = cln + 1;\n#ifdef FEAT_DIFF\n\tloff.fill = 0;\n#endif\n\tfor (curwin->w_topline = curwin->w_botline;\n\t\tcurwin->w_topline > 1;\n\t\tcurwin->w_topline = loff.lnum)\n\t{\n\t    loff.lnum = curwin->w_topline;\n\t    topline_back_winheight(&loff, FALSE);\n\t    if (loff.height == MAXCOL)\n\t\tbreak;\n\t    if (used + loff.height > curwin->w_height)\n\t    {\n\t\tif (do_sms)\n\t\t{\n\t\t    // 'smoothscroll' and 'wrap' are set.  The above line is\n\t\t    // too long to show in its entirety, so we show just a part\n\t\t    // of it.\n\t\t    if (used < curwin->w_height)\n\t\t    {\n\t\t\tint plines_offset = used + loff.height\n\t\t\t\t\t\t\t    - curwin->w_height;\n\t\t\tused = curwin->w_height;\n#ifdef FEAT_DIFF\n\t\t\tcurwin->w_topfill = loff.fill;\n#endif\n\t\t\tcurwin->w_topline = loff.lnum;\n\t\t\tcurwin->w_skipcol = skipcol_from_plines(\n\t\t\t\t\t\t\tcurwin, plines_offset);\n\t\t\tset_skipcol = TRUE;\n\t\t    }\n\t\t}\n\t\tbreak;\n\t    }\n\t    used += loff.height;\n#ifdef FEAT_DIFF\n\t    curwin->w_topfill = loff.fill;\n#endif\n\t}\n\tset_empty_rows(curwin, used);\n\tcurwin->w_valid |= VALID_BOTLINE|VALID_BOTLINE_AP;\n\tif (curwin->w_topline != old_topline\n#ifdef FEAT_DIFF\n\t\t|| curwin->w_topfill != old_topfill\n#endif\n\t\t|| set_skipcol\n\t\t|| curwin->w_skipcol != 0)\n\t{\n\t    curwin->w_valid &= ~(VALID_WROW|VALID_CROW);\n\t    if (set_skipcol)\n\t\tredraw_later(UPD_NOT_VALID);\n\t    else\n\t\treset_skipcol();\n\t}\n    }\n    else\n\tvalidate_botline();\n\n    // The lines of the cursor line itself are always used.\n#ifdef FEAT_DIFF\n    used = plines_nofill(cln);\n#else\n    validate_cheight();\n    used = curwin->w_cline_height;\n#endif\n\n    // If the cursor is on or below botline, we will at least scroll by the\n    // height of the cursor line, which is \"used\".  Correct for empty lines,\n    // which are really part of botline.\n    if (cln >= curwin->w_botline)\n    {\n\tscrolled = used;\n\tif (cln == curwin->w_botline)\n\t    scrolled -= curwin->w_empty_rows;\n\tif (do_sms)\n\t{\n\t    // 'smoothscroll' and 'wrap' are set.\n\t    // Calculate how many screen lines the current top line of window\n\t    // occupies. If it is occupying more than the entire window, we\n\t    // need to scroll the additional clipped lines to scroll past the\n\t    // top line before we can move on to the other lines.\n\t    int top_plines =\n#ifdef FEAT_DIFF\n\t\t\t    plines_win_nofill\n#else\n\t\t\t    plines_win\n#endif\n\t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n\t    int skip_lines = 0;\n\t    int width1 = curwin->w_width - curwin_col_off();\n\t    int width2 = width1 + curwin_col_off2();\n\t    // similar formula is used in curs_columns()\n\t    if (curwin->w_skipcol > width1)\n\t\tskip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n\t    else if (curwin->w_skipcol > 0)\n\t\tskip_lines = 1;\n\n\t    top_plines -= skip_lines;\n\t    if (top_plines > curwin->w_height)\n\t    {\n\t\tscrolled += (top_plines - curwin->w_height);\n\t    }\n\t}\n    }\n\n    /*\n     * Stop counting lines to scroll when\n     * - hitting start of the file\n     * - scrolled nothing or at least 'sj' lines\n     * - at least 'scrolloff' lines below the cursor\n     * - lines between botline and cursor have been counted\n     */\n#ifdef FEAT_FOLDING\n    if (!hasFolding(curwin->w_cursor.lnum, &loff.lnum, &boff.lnum))\n#endif\n    {\n\tloff.lnum = cln;\n\tboff.lnum = cln;\n    }\n#ifdef FEAT_DIFF\n    loff.fill = 0;\n    boff.fill = 0;\n    fill_below_window = diff_check_fill(curwin, curwin->w_botline)\n\t\t\t\t\t\t      - curwin->w_filler_rows;\n#endif\n\n    while (loff.lnum > 1)\n    {\n\t// Stop when scrolled nothing or at least \"min_scroll\", found \"extra\"\n\t// context for 'scrolloff' and counted all lines below the window.\n\tif ((((scrolled <= 0 || scrolled >= min_scroll)\n\t\t    && extra >= (mouse_dragging > 0 ? mouse_dragging - 1 : so))\n\t\t    || boff.lnum + 1 > curbuf->b_ml.ml_line_count)\n\t\t&& loff.lnum <= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum < curwin->w_botline\n\t\t    || loff.fill >= fill_below_window)\n#endif\n\t\t)\n\t    break;\n\n\t// Add one line above\n\ttopline_back(&loff);\n\tif (loff.height == MAXCOL)\n\t    used = MAXCOL;\n\telse\n\t    used += loff.height;\n\tif (used > curwin->w_height)\n\t    break;\n\tif (loff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum > curwin->w_botline\n\t\t    || loff.fill <= fill_below_window)\n#endif\n\t\t)\n\t{\n\t    // Count screen lines that are below the window.\n\t    scrolled += loff.height;\n\t    if (loff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && loff.fill == 0\n#endif\n\t\t    )\n\t\tscrolled -= curwin->w_empty_rows;\n\t}\n\n\tif (boff.lnum < curbuf->b_ml.ml_line_count)\n\t{\n\t    // Add one line below\n\t    botline_forw(&boff);\n\t    used += boff.height;\n\t    if (used > curwin->w_height)\n\t\tbreak;\n\t    if (extra < ( mouse_dragging > 0 ? mouse_dragging - 1 : so)\n\t\t    || scrolled < min_scroll)\n\t    {\n\t\textra += boff.height;\n\t\tif (boff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t|| (boff.lnum + 1 == curwin->w_botline\n\t\t\t    && boff.fill > curwin->w_filler_rows)\n#endif\n\t\t   )\n\t\t{\n\t\t    // Count screen lines that are below the window.\n\t\t    scrolled += boff.height;\n\t\t    if (boff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && boff.fill == 0\n#endif\n\t\t\t    )\n\t\t\tscrolled -= curwin->w_empty_rows;\n\t\t}\n\t    }\n\t}\n    }\n\n    // curwin->w_empty_rows is larger, no need to scroll\n    if (scrolled <= 0)\n\tline_count = 0;\n    // more than a screenfull, don't scroll but redraw\n    else if (used > curwin->w_height)\n\tline_count = used;\n    // scroll minimal number of lines\n    else\n    {\n\tline_count = 0;\n#ifdef FEAT_DIFF\n\tboff.fill = curwin->w_topfill;\n#endif\n\tboff.lnum = curwin->w_topline - 1;\n\tfor (i = 0; i < scrolled && boff.lnum < curwin->w_botline; )\n\t{\n\t    botline_forw(&boff);\n\t    i += boff.height;\n\t    ++line_count;\n\t}\n\tif (i < scrolled)\t// below curwin->w_botline, don't scroll\n\t    line_count = 9999;\n    }\n\n    /*\n     * Scroll up if the cursor is off the bottom of the screen a bit.\n     * Otherwise put it at 1/2 of the screen.\n     */\n    if (line_count >= curwin->w_height && line_count > min_scroll)\n\tscroll_cursor_halfway(FALSE, TRUE);\n    else if (line_count > 0)\n    {\n\tif (do_sms)\n\t    scrollup(scrolled, TRUE);  // TODO\n\telse\n\t    scrollup(line_count, TRUE);\n    }\n\n    /*\n     * If topline didn't change we need to restore w_botline and w_empty_rows\n     * (we changed them).\n     * If topline did change, update_screen() will set botline.\n     */\n    if (curwin->w_topline == old_topline\n\t    && curwin->w_skipcol == old_skipcol\n\t    && set_topbot)\n    {\n\tcurwin->w_botline = old_botline;\n\tcurwin->w_empty_rows = old_empty_rows;\n\tcurwin->w_valid = old_valid;\n    }\n    curwin->w_valid |= VALID_TOPLINE;\n}",
        "func": "void\nscroll_cursor_bot(int min_scroll, int set_topbot)\n{\n    int\t\tused;\n    int\t\tscrolled = 0;\n    int\t\textra = 0;\n    int\t\ti;\n    linenr_T\tline_count;\n    linenr_T\told_topline = curwin->w_topline;\n    int\t\told_skipcol = curwin->w_skipcol;\n    lineoff_T\tloff;\n    lineoff_T\tboff;\n#ifdef FEAT_DIFF\n    int\t\told_topfill = curwin->w_topfill;\n    int\t\tfill_below_window;\n#endif\n    linenr_T\told_botline = curwin->w_botline;\n    linenr_T\told_valid = curwin->w_valid;\n    int\t\told_empty_rows = curwin->w_empty_rows;\n    linenr_T\tcln;\t\t    // Cursor Line Number\n    long\tso = get_scrolloff_value();\n    int\t\tdo_sms = curwin->w_p_wrap && curwin->w_p_sms;\n\n    cln = curwin->w_cursor.lnum;\n    if (set_topbot)\n    {\n\tint set_skipcol = FALSE;\n\n\tused = 0;\n\tcurwin->w_botline = cln + 1;\n#ifdef FEAT_DIFF\n\tloff.fill = 0;\n#endif\n\tfor (curwin->w_topline = curwin->w_botline;\n\t\tcurwin->w_topline > 1;\n\t\tcurwin->w_topline = loff.lnum)\n\t{\n\t    loff.lnum = curwin->w_topline;\n\t    topline_back_winheight(&loff, FALSE);\n\t    if (loff.height == MAXCOL)\n\t\tbreak;\n\t    if (used + loff.height > curwin->w_height)\n\t    {\n\t\tif (do_sms)\n\t\t{\n\t\t    // 'smoothscroll' and 'wrap' are set.  The above line is\n\t\t    // too long to show in its entirety, so we show just a part\n\t\t    // of it.\n\t\t    if (used < curwin->w_height)\n\t\t    {\n\t\t\tint plines_offset = used + loff.height\n\t\t\t\t\t\t\t    - curwin->w_height;\n\t\t\tused = curwin->w_height;\n#ifdef FEAT_DIFF\n\t\t\tcurwin->w_topfill = loff.fill;\n#endif\n\t\t\tcurwin->w_topline = loff.lnum;\n\t\t\tcurwin->w_skipcol = skipcol_from_plines(\n\t\t\t\t\t\t\tcurwin, plines_offset);\n\t\t\tset_skipcol = TRUE;\n\t\t    }\n\t\t}\n\t\tbreak;\n\t    }\n\t    used += loff.height;\n#ifdef FEAT_DIFF\n\t    curwin->w_topfill = loff.fill;\n#endif\n\t}\n\tset_empty_rows(curwin, used);\n\tcurwin->w_valid |= VALID_BOTLINE|VALID_BOTLINE_AP;\n\tif (curwin->w_topline != old_topline\n#ifdef FEAT_DIFF\n\t\t|| curwin->w_topfill != old_topfill\n#endif\n\t\t|| set_skipcol\n\t\t|| curwin->w_skipcol != 0)\n\t{\n\t    curwin->w_valid &= ~(VALID_WROW|VALID_CROW);\n\t    if (set_skipcol)\n\t\tredraw_later(UPD_NOT_VALID);\n\t    else\n\t\treset_skipcol();\n\t}\n    }\n    else\n\tvalidate_botline();\n\n    // The lines of the cursor line itself are always used.\n#ifdef FEAT_DIFF\n    used = plines_nofill(cln);\n#else\n    validate_cheight();\n    used = curwin->w_cline_height;\n#endif\n\n    // If the cursor is on or below botline, we will at least scroll by the\n    // height of the cursor line, which is \"used\".  Correct for empty lines,\n    // which are really part of botline.\n    if (cln >= curwin->w_botline)\n    {\n\tscrolled = used;\n\tif (cln == curwin->w_botline)\n\t    scrolled -= curwin->w_empty_rows;\n\tif (do_sms)\n\t{\n\t    // 'smoothscroll' and 'wrap' are set.\n\t    // Calculate how many screen lines the current top line of window\n\t    // occupies. If it is occupying more than the entire window, we\n\t    // need to scroll the additional clipped lines to scroll past the\n\t    // top line before we can move on to the other lines.\n\t    int top_plines =\n#ifdef FEAT_DIFF\n\t\t\t    plines_win_nofill\n#else\n\t\t\t    plines_win\n#endif\n\t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n\t    int skip_lines = 0;\n\t    int width1 = curwin->w_width - curwin_col_off();\n\t    if (width1 > 0) {\n\t\tint width2 = width1 + curwin_col_off2();\n\t\t// similar formula is used in curs_columns()\n\t\tif (curwin->w_skipcol > width1)\n\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n\t\telse if (curwin->w_skipcol > 0)\n\t\t    skip_lines = 1;\n\n\t\ttop_plines -= skip_lines;\n\t\tif (top_plines > curwin->w_height)\n\t\t{\n\t\t    scrolled += (top_plines - curwin->w_height);\n\t\t}\n\t    }\n\t}\n    }\n\n    /*\n     * Stop counting lines to scroll when\n     * - hitting start of the file\n     * - scrolled nothing or at least 'sj' lines\n     * - at least 'scrolloff' lines below the cursor\n     * - lines between botline and cursor have been counted\n     */\n#ifdef FEAT_FOLDING\n    if (!hasFolding(curwin->w_cursor.lnum, &loff.lnum, &boff.lnum))\n#endif\n    {\n\tloff.lnum = cln;\n\tboff.lnum = cln;\n    }\n#ifdef FEAT_DIFF\n    loff.fill = 0;\n    boff.fill = 0;\n    fill_below_window = diff_check_fill(curwin, curwin->w_botline)\n\t\t\t\t\t\t      - curwin->w_filler_rows;\n#endif\n\n    while (loff.lnum > 1)\n    {\n\t// Stop when scrolled nothing or at least \"min_scroll\", found \"extra\"\n\t// context for 'scrolloff' and counted all lines below the window.\n\tif ((((scrolled <= 0 || scrolled >= min_scroll)\n\t\t    && extra >= (mouse_dragging > 0 ? mouse_dragging - 1 : so))\n\t\t    || boff.lnum + 1 > curbuf->b_ml.ml_line_count)\n\t\t&& loff.lnum <= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum < curwin->w_botline\n\t\t    || loff.fill >= fill_below_window)\n#endif\n\t\t)\n\t    break;\n\n\t// Add one line above\n\ttopline_back(&loff);\n\tif (loff.height == MAXCOL)\n\t    used = MAXCOL;\n\telse\n\t    used += loff.height;\n\tif (used > curwin->w_height)\n\t    break;\n\tif (loff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t&& (loff.lnum > curwin->w_botline\n\t\t    || loff.fill <= fill_below_window)\n#endif\n\t\t)\n\t{\n\t    // Count screen lines that are below the window.\n\t    scrolled += loff.height;\n\t    if (loff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && loff.fill == 0\n#endif\n\t\t    )\n\t\tscrolled -= curwin->w_empty_rows;\n\t}\n\n\tif (boff.lnum < curbuf->b_ml.ml_line_count)\n\t{\n\t    // Add one line below\n\t    botline_forw(&boff);\n\t    used += boff.height;\n\t    if (used > curwin->w_height)\n\t\tbreak;\n\t    if (extra < ( mouse_dragging > 0 ? mouse_dragging - 1 : so)\n\t\t    || scrolled < min_scroll)\n\t    {\n\t\textra += boff.height;\n\t\tif (boff.lnum >= curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t|| (boff.lnum + 1 == curwin->w_botline\n\t\t\t    && boff.fill > curwin->w_filler_rows)\n#endif\n\t\t   )\n\t\t{\n\t\t    // Count screen lines that are below the window.\n\t\t    scrolled += boff.height;\n\t\t    if (boff.lnum == curwin->w_botline\n#ifdef FEAT_DIFF\n\t\t\t    && boff.fill == 0\n#endif\n\t\t\t    )\n\t\t\tscrolled -= curwin->w_empty_rows;\n\t\t}\n\t    }\n\t}\n    }\n\n    // curwin->w_empty_rows is larger, no need to scroll\n    if (scrolled <= 0)\n\tline_count = 0;\n    // more than a screenfull, don't scroll but redraw\n    else if (used > curwin->w_height)\n\tline_count = used;\n    // scroll minimal number of lines\n    else\n    {\n\tline_count = 0;\n#ifdef FEAT_DIFF\n\tboff.fill = curwin->w_topfill;\n#endif\n\tboff.lnum = curwin->w_topline - 1;\n\tfor (i = 0; i < scrolled && boff.lnum < curwin->w_botline; )\n\t{\n\t    botline_forw(&boff);\n\t    i += boff.height;\n\t    ++line_count;\n\t}\n\tif (i < scrolled)\t// below curwin->w_botline, don't scroll\n\t    line_count = 9999;\n    }\n\n    /*\n     * Scroll up if the cursor is off the bottom of the screen a bit.\n     * Otherwise put it at 1/2 of the screen.\n     */\n    if (line_count >= curwin->w_height && line_count > min_scroll)\n\tscroll_cursor_halfway(FALSE, TRUE);\n    else if (line_count > 0)\n    {\n\tif (do_sms)\n\t    scrollup(scrolled, TRUE);  // TODO\n\telse\n\t    scrollup(line_count, TRUE);\n    }\n\n    /*\n     * If topline didn't change we need to restore w_botline and w_empty_rows\n     * (we changed them).\n     * If topline did change, update_screen() will set botline.\n     */\n    if (curwin->w_topline == old_topline\n\t    && curwin->w_skipcol == old_skipcol\n\t    && set_topbot)\n    {\n\tcurwin->w_botline = old_botline;\n\tcurwin->w_empty_rows = old_empty_rows;\n\tcurwin->w_valid = old_valid;\n    }\n    curwin->w_valid |= VALID_TOPLINE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -118,17 +118,19 @@\n \t\t\t\t\t(curwin, curwin->w_topline, FALSE);\n \t    int skip_lines = 0;\n \t    int width1 = curwin->w_width - curwin_col_off();\n-\t    int width2 = width1 + curwin_col_off2();\n-\t    // similar formula is used in curs_columns()\n-\t    if (curwin->w_skipcol > width1)\n-\t\tskip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n-\t    else if (curwin->w_skipcol > 0)\n-\t\tskip_lines = 1;\n-\n-\t    top_plines -= skip_lines;\n-\t    if (top_plines > curwin->w_height)\n-\t    {\n-\t\tscrolled += (top_plines - curwin->w_height);\n+\t    if (width1 > 0) {\n+\t\tint width2 = width1 + curwin_col_off2();\n+\t\t// similar formula is used in curs_columns()\n+\t\tif (curwin->w_skipcol > width1)\n+\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;\n+\t\telse if (curwin->w_skipcol > 0)\n+\t\t    skip_lines = 1;\n+\n+\t\ttop_plines -= skip_lines;\n+\t\tif (top_plines > curwin->w_height)\n+\t\t{\n+\t\t    scrolled += (top_plines - curwin->w_height);\n+\t\t}\n \t    }\n \t}\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "\t    int width2 = width1 + curwin_col_off2();",
                "\t    // similar formula is used in curs_columns()",
                "\t    if (curwin->w_skipcol > width1)",
                "\t\tskip_lines += (curwin->w_skipcol - width1) / width2 + 1;",
                "\t    else if (curwin->w_skipcol > 0)",
                "\t\tskip_lines = 1;",
                "",
                "\t    top_plines -= skip_lines;",
                "\t    if (top_plines > curwin->w_height)",
                "\t    {",
                "\t\tscrolled += (top_plines - curwin->w_height);"
            ],
            "added_lines": [
                "\t    if (width1 > 0) {",
                "\t\tint width2 = width1 + curwin_col_off2();",
                "\t\t// similar formula is used in curs_columns()",
                "\t\tif (curwin->w_skipcol > width1)",
                "\t\t    skip_lines += (curwin->w_skipcol - width1) / width2 + 1;",
                "\t\telse if (curwin->w_skipcol > 0)",
                "\t\t    skip_lines = 1;",
                "",
                "\t\ttop_plines -= skip_lines;",
                "\t\tif (top_plines > curwin->w_height)",
                "\t\t{",
                "\t\t    scrolled += (top_plines - curwin->w_height);",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-20588",
        "func_name": "xen-project/xen/parse_spec_ctrl",
        "description": "\nA division-by-zero error on some AMD processors can potentially return speculative data resulting in loss of confidentiality.\n\n\n\n\n\n\n\n",
        "git_url": "https://github.com/xen-project/xen/commit/b5926c6ecf05c28ee99c6248c42d691ccbf0c315",
        "commit_title": "x86/spec-ctrl: Mitigate the Zen1 DIV leakage",
        "commit_text": " In the Zen1 microarchitecure, there is one divider in the pipeline which services uops from both threads.  In the case of #DE, the latched result from the previous DIV to execute will be forwarded speculatively.  This is an interesting covert channel that allows two threads to communicate without any system calls.  In also allows userspace to obtain the result of the most recent DIV instruction executed (even speculatively) in the core, which can be from a higher privilege context.  Scrub the result from the divider by executing a non-faulting divide.  This needs performing on the exit-to-guest paths, and ist_exit-to-Xen.  Alternatives in IST context is believed safe now that it's done in NMI context.  This is XSA-439 / CVE-2023-20588. ",
        "func_before": "static int __init cf_check parse_spec_ctrl(const char *s)\n{\n    const char *ss;\n    int val, rc = 0;\n\n    do {\n        ss = strchr(s, ',');\n        if ( !ss )\n            ss = strchr(s, '\\0');\n\n        /* Global and Xen-wide disable. */\n        val = parse_bool(s, ss);\n        if ( !val )\n        {\n            opt_msr_sc_pv = false;\n            opt_msr_sc_hvm = false;\n\n            opt_eager_fpu = 0;\n\n            if ( opt_xpti_hwdom < 0 )\n                opt_xpti_hwdom = 0;\n            if ( opt_xpti_domu < 0 )\n                opt_xpti_domu = 0;\n\n            if ( opt_smt < 0 )\n                opt_smt = 1;\n\n            if ( opt_pv_l1tf_hwdom < 0 )\n                opt_pv_l1tf_hwdom = 0;\n            if ( opt_pv_l1tf_domu < 0 )\n                opt_pv_l1tf_domu = 0;\n\n            if ( opt_tsx == -1 )\n                opt_tsx = -3;\n\n        disable_common:\n            opt_rsb_pv = false;\n            opt_rsb_hvm = false;\n            opt_md_clear_pv = 0;\n            opt_md_clear_hvm = 0;\n            opt_ibpb_entry_pv = 0;\n            opt_ibpb_entry_hvm = 0;\n            opt_ibpb_entry_dom0 = false;\n\n            opt_thunk = THUNK_JMP;\n            opt_ibrs = 0;\n            opt_ibpb_ctxt_switch = false;\n            opt_ssbd = false;\n            opt_l1d_flush = 0;\n            opt_branch_harden = false;\n            opt_srb_lock = 0;\n            opt_unpriv_mmio = false;\n            opt_gds_mit = 0;\n        }\n        else if ( val > 0 )\n            rc = -EINVAL;\n        else if ( (val = parse_boolean(\"xen\", s, ss)) >= 0 )\n        {\n            if ( !val )\n                goto disable_common;\n\n            rc = -EINVAL;\n        }\n\n        /* Xen's alternative blocks. */\n        else if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n        {\n            opt_msr_sc_pv = val;\n            opt_rsb_pv = val;\n            opt_md_clear_pv = val;\n            opt_ibpb_entry_pv = val;\n        }\n        else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n        {\n            opt_msr_sc_hvm = val;\n            opt_rsb_hvm = val;\n            opt_md_clear_hvm = val;\n            opt_ibpb_entry_hvm = val;\n        }\n        else if ( (val = parse_boolean(\"msr-sc\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_msr_sc_pv = opt_msr_sc_hvm = val;\n                break;\n\n            case -2:\n                s += strlen(\"msr-sc=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_msr_sc_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_msr_sc_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n        else if ( (val = parse_boolean(\"rsb\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_rsb_pv = opt_rsb_hvm = val;\n                break;\n\n            case -2:\n                s += strlen(\"rsb=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_rsb_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_rsb_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n        else if ( (val = parse_boolean(\"md-clear\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_md_clear_pv = opt_md_clear_hvm = val;\n                break;\n\n            case -2:\n                s += strlen(\"md-clear=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_md_clear_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_md_clear_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n        else if ( (val = parse_boolean(\"ibpb-entry\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_ibpb_entry_pv = opt_ibpb_entry_hvm =\n                    opt_ibpb_entry_dom0 = val;\n                break;\n\n            case -2:\n                s += strlen(\"ibpb-entry=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_ibpb_entry_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_ibpb_entry_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n\n        /* Xen's speculative sidechannel mitigation settings. */\n        else if ( !strncmp(s, \"bti-thunk=\", 10) )\n        {\n            s += 10;\n\n            if ( !cmdline_strcmp(s, \"retpoline\") )\n                opt_thunk = THUNK_RETPOLINE;\n            else if ( !cmdline_strcmp(s, \"lfence\") )\n                opt_thunk = THUNK_LFENCE;\n            else if ( !cmdline_strcmp(s, \"jmp\") )\n                opt_thunk = THUNK_JMP;\n            else\n                rc = -EINVAL;\n        }\n\n        /* Bits in MSR_SPEC_CTRL. */\n        else if ( (val = parse_boolean(\"ibrs\", s, ss)) >= 0 )\n            opt_ibrs = val;\n        else if ( (val = parse_boolean(\"stibp\", s, ss)) >= 0 )\n            opt_stibp = val;\n        else if ( (val = parse_boolean(\"ssbd\", s, ss)) >= 0 )\n            opt_ssbd = val;\n        else if ( (val = parse_boolean(\"psfd\", s, ss)) >= 0 )\n            opt_psfd = val;\n\n        /* Misc settings. */\n        else if ( (val = parse_boolean(\"ibpb\", s, ss)) >= 0 )\n            opt_ibpb_ctxt_switch = val;\n        else if ( (val = parse_boolean(\"eager-fpu\", s, ss)) >= 0 )\n            opt_eager_fpu = val;\n        else if ( (val = parse_boolean(\"l1d-flush\", s, ss)) >= 0 )\n            opt_l1d_flush = val;\n        else if ( (val = parse_boolean(\"branch-harden\", s, ss)) >= 0 )\n            opt_branch_harden = val;\n        else if ( (val = parse_boolean(\"srb-lock\", s, ss)) >= 0 )\n            opt_srb_lock = val;\n        else if ( (val = parse_boolean(\"unpriv-mmio\", s, ss)) >= 0 )\n            opt_unpriv_mmio = val;\n        else if ( (val = parse_boolean(\"gds-mit\", s, ss)) >= 0 )\n            opt_gds_mit = val;\n        else\n            rc = -EINVAL;\n\n        s = ss + 1;\n    } while ( *ss );\n\n    return rc;\n}",
        "func": "static int __init cf_check parse_spec_ctrl(const char *s)\n{\n    const char *ss;\n    int val, rc = 0;\n\n    do {\n        ss = strchr(s, ',');\n        if ( !ss )\n            ss = strchr(s, '\\0');\n\n        /* Global and Xen-wide disable. */\n        val = parse_bool(s, ss);\n        if ( !val )\n        {\n            opt_msr_sc_pv = false;\n            opt_msr_sc_hvm = false;\n\n            opt_eager_fpu = 0;\n\n            if ( opt_xpti_hwdom < 0 )\n                opt_xpti_hwdom = 0;\n            if ( opt_xpti_domu < 0 )\n                opt_xpti_domu = 0;\n\n            if ( opt_smt < 0 )\n                opt_smt = 1;\n\n            if ( opt_pv_l1tf_hwdom < 0 )\n                opt_pv_l1tf_hwdom = 0;\n            if ( opt_pv_l1tf_domu < 0 )\n                opt_pv_l1tf_domu = 0;\n\n            if ( opt_tsx == -1 )\n                opt_tsx = -3;\n\n        disable_common:\n            opt_rsb_pv = false;\n            opt_rsb_hvm = false;\n            opt_md_clear_pv = 0;\n            opt_md_clear_hvm = 0;\n            opt_ibpb_entry_pv = 0;\n            opt_ibpb_entry_hvm = 0;\n            opt_ibpb_entry_dom0 = false;\n\n            opt_thunk = THUNK_JMP;\n            opt_ibrs = 0;\n            opt_ibpb_ctxt_switch = false;\n            opt_ssbd = false;\n            opt_l1d_flush = 0;\n            opt_branch_harden = false;\n            opt_srb_lock = 0;\n            opt_unpriv_mmio = false;\n            opt_gds_mit = 0;\n            opt_div_scrub = 0;\n        }\n        else if ( val > 0 )\n            rc = -EINVAL;\n        else if ( (val = parse_boolean(\"xen\", s, ss)) >= 0 )\n        {\n            if ( !val )\n                goto disable_common;\n\n            rc = -EINVAL;\n        }\n\n        /* Xen's alternative blocks. */\n        else if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n        {\n            opt_msr_sc_pv = val;\n            opt_rsb_pv = val;\n            opt_md_clear_pv = val;\n            opt_ibpb_entry_pv = val;\n        }\n        else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n        {\n            opt_msr_sc_hvm = val;\n            opt_rsb_hvm = val;\n            opt_md_clear_hvm = val;\n            opt_ibpb_entry_hvm = val;\n        }\n        else if ( (val = parse_boolean(\"msr-sc\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_msr_sc_pv = opt_msr_sc_hvm = val;\n                break;\n\n            case -2:\n                s += strlen(\"msr-sc=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_msr_sc_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_msr_sc_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n        else if ( (val = parse_boolean(\"rsb\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_rsb_pv = opt_rsb_hvm = val;\n                break;\n\n            case -2:\n                s += strlen(\"rsb=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_rsb_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_rsb_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n        else if ( (val = parse_boolean(\"md-clear\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_md_clear_pv = opt_md_clear_hvm = val;\n                break;\n\n            case -2:\n                s += strlen(\"md-clear=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_md_clear_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_md_clear_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n        else if ( (val = parse_boolean(\"ibpb-entry\", s, ss)) != -1 )\n        {\n            switch ( val )\n            {\n            case 0:\n            case 1:\n                opt_ibpb_entry_pv = opt_ibpb_entry_hvm =\n                    opt_ibpb_entry_dom0 = val;\n                break;\n\n            case -2:\n                s += strlen(\"ibpb-entry=\");\n                if ( (val = parse_boolean(\"pv\", s, ss)) >= 0 )\n                    opt_ibpb_entry_pv = val;\n                else if ( (val = parse_boolean(\"hvm\", s, ss)) >= 0 )\n                    opt_ibpb_entry_hvm = val;\n                else\n            default:\n                    rc = -EINVAL;\n                break;\n            }\n        }\n\n        /* Xen's speculative sidechannel mitigation settings. */\n        else if ( !strncmp(s, \"bti-thunk=\", 10) )\n        {\n            s += 10;\n\n            if ( !cmdline_strcmp(s, \"retpoline\") )\n                opt_thunk = THUNK_RETPOLINE;\n            else if ( !cmdline_strcmp(s, \"lfence\") )\n                opt_thunk = THUNK_LFENCE;\n            else if ( !cmdline_strcmp(s, \"jmp\") )\n                opt_thunk = THUNK_JMP;\n            else\n                rc = -EINVAL;\n        }\n\n        /* Bits in MSR_SPEC_CTRL. */\n        else if ( (val = parse_boolean(\"ibrs\", s, ss)) >= 0 )\n            opt_ibrs = val;\n        else if ( (val = parse_boolean(\"stibp\", s, ss)) >= 0 )\n            opt_stibp = val;\n        else if ( (val = parse_boolean(\"ssbd\", s, ss)) >= 0 )\n            opt_ssbd = val;\n        else if ( (val = parse_boolean(\"psfd\", s, ss)) >= 0 )\n            opt_psfd = val;\n\n        /* Misc settings. */\n        else if ( (val = parse_boolean(\"ibpb\", s, ss)) >= 0 )\n            opt_ibpb_ctxt_switch = val;\n        else if ( (val = parse_boolean(\"eager-fpu\", s, ss)) >= 0 )\n            opt_eager_fpu = val;\n        else if ( (val = parse_boolean(\"l1d-flush\", s, ss)) >= 0 )\n            opt_l1d_flush = val;\n        else if ( (val = parse_boolean(\"branch-harden\", s, ss)) >= 0 )\n            opt_branch_harden = val;\n        else if ( (val = parse_boolean(\"srb-lock\", s, ss)) >= 0 )\n            opt_srb_lock = val;\n        else if ( (val = parse_boolean(\"unpriv-mmio\", s, ss)) >= 0 )\n            opt_unpriv_mmio = val;\n        else if ( (val = parse_boolean(\"gds-mit\", s, ss)) >= 0 )\n            opt_gds_mit = val;\n        else if ( (val = parse_boolean(\"div-scrub\", s, ss)) >= 0 )\n            opt_div_scrub = val;\n        else\n            rc = -EINVAL;\n\n        s = ss + 1;\n    } while ( *ss );\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -51,6 +51,7 @@\n             opt_srb_lock = 0;\n             opt_unpriv_mmio = false;\n             opt_gds_mit = 0;\n+            opt_div_scrub = 0;\n         }\n         else if ( val > 0 )\n             rc = -EINVAL;\n@@ -203,6 +204,8 @@\n             opt_unpriv_mmio = val;\n         else if ( (val = parse_boolean(\"gds-mit\", s, ss)) >= 0 )\n             opt_gds_mit = val;\n+        else if ( (val = parse_boolean(\"div-scrub\", s, ss)) >= 0 )\n+            opt_div_scrub = val;\n         else\n             rc = -EINVAL;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            opt_div_scrub = 0;",
                "        else if ( (val = parse_boolean(\"div-scrub\", s, ss)) >= 0 )",
                "            opt_div_scrub = val;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-20588",
        "func_name": "xen-project/xen/init_speculation_mitigations",
        "description": "\nA division-by-zero error on some AMD processors can potentially return speculative data resulting in loss of confidentiality.\n\n\n\n\n\n\n\n",
        "git_url": "https://github.com/xen-project/xen/commit/b5926c6ecf05c28ee99c6248c42d691ccbf0c315",
        "commit_title": "x86/spec-ctrl: Mitigate the Zen1 DIV leakage",
        "commit_text": " In the Zen1 microarchitecure, there is one divider in the pipeline which services uops from both threads.  In the case of #DE, the latched result from the previous DIV to execute will be forwarded speculatively.  This is an interesting covert channel that allows two threads to communicate without any system calls.  In also allows userspace to obtain the result of the most recent DIV instruction executed (even speculatively) in the core, which can be from a higher privilege context.  Scrub the result from the divider by executing a non-faulting divide.  This needs performing on the exit-to-guest paths, and ist_exit-to-Xen.  Alternatives in IST context is believed safe now that it's done in NMI context.  This is XSA-439 / CVE-2023-20588. ",
        "func_before": "void __init init_speculation_mitigations(void)\n{\n    enum ind_thunk thunk = THUNK_DEFAULT;\n    bool has_spec_ctrl, ibrs = false, hw_smt_enabled;\n    bool cpu_has_bug_taa, retpoline_safe;\n\n    hw_smt_enabled = check_smt_enabled();\n\n    has_spec_ctrl = (boot_cpu_has(X86_FEATURE_IBRSB) ||\n                     boot_cpu_has(X86_FEATURE_IBRS));\n\n    /*\n     * First, disable the use of retpolines if Xen is using CET.  Retpolines\n     * are a ROP gadget so incompatbile with Shadow Stacks, while IBT depends\n     * on executing indirect branches for the safety properties to apply.\n     *\n     * In the absence of retpolines, IBRS needs to be used for speculative\n     * safety.  All CET-capable hardware has efficient IBRS.\n     */\n    if ( read_cr4() & X86_CR4_CET )\n    {\n        if ( !has_spec_ctrl )\n        {\n            printk(XENLOG_WARNING \"?!? CET active, but no MSR_SPEC_CTRL?\\n\");\n            add_taint(TAINT_CPU_OUT_OF_SPEC);\n        }\n        else if ( opt_ibrs == -1 )\n            opt_ibrs = ibrs = true;\n\n        if ( opt_thunk == THUNK_DEFAULT || opt_thunk == THUNK_RETPOLINE )\n            thunk = THUNK_JMP;\n    }\n\n    /* Determine if retpoline is safe on this CPU.  Fix up RSBA/RRSBA enumerations. */\n    retpoline_safe = retpoline_calculations();\n\n    /*\n     * Has the user specified any custom BTI mitigations?  If so, follow their\n     * instructions exactly and disable all heuristics.\n     */\n    if ( opt_thunk != THUNK_DEFAULT || opt_ibrs != -1 )\n    {\n        thunk = opt_thunk;\n        ibrs  = !!opt_ibrs;\n    }\n    else\n    {\n        /*\n         * Evaluate the safest Branch Target Injection mitigations to use.\n         * First, begin with compiler-aided mitigations.\n         */\n        if ( IS_ENABLED(CONFIG_INDIRECT_THUNK) )\n        {\n            /*\n             * On all hardware, we'd like to use retpoline in preference to\n             * IBRS, but only if it is safe on this hardware.\n             */\n            if ( retpoline_safe )\n                thunk = THUNK_RETPOLINE;\n            else if ( has_spec_ctrl )\n                ibrs = true;\n        }\n        /* Without compiler thunk support, use IBRS if available. */\n        else if ( has_spec_ctrl )\n            ibrs = true;\n    }\n\n    /*\n     * Supplimentary minor adjustments.  Without compiler support, there are\n     * no thunks.\n     */\n    if ( !IS_ENABLED(CONFIG_INDIRECT_THUNK) )\n        thunk = THUNK_NONE;\n\n    /*\n     * If IBRS is in use and thunks are compiled in, there is no point\n     * suffering extra overhead.  Switch to the least-overhead thunk.\n     */\n    if ( ibrs && thunk == THUNK_DEFAULT )\n        thunk = THUNK_JMP;\n\n    /*\n     * If there are still no thunk preferences, the compiled default is\n     * actually retpoline, and it is better than nothing.\n     */\n    if ( thunk == THUNK_DEFAULT )\n        thunk = THUNK_RETPOLINE;\n\n    /* Apply the chosen settings. */\n    if ( thunk == THUNK_LFENCE )\n        setup_force_cpu_cap(X86_FEATURE_IND_THUNK_LFENCE);\n    else if ( thunk == THUNK_JMP )\n        setup_force_cpu_cap(X86_FEATURE_IND_THUNK_JMP);\n\n    /* Intel hardware: MSR_SPEC_CTRL alternatives setup. */\n    if ( boot_cpu_has(X86_FEATURE_IBRSB) )\n    {\n        if ( opt_msr_sc_pv )\n        {\n            default_spec_ctrl_flags |= SCF_ist_sc_msr;\n            setup_force_cpu_cap(X86_FEATURE_SC_MSR_PV);\n        }\n\n        if ( opt_msr_sc_hvm )\n        {\n            /*\n             * While the guest MSR_SPEC_CTRL value is loaded/saved atomically,\n             * Xen's value is not restored atomically.  An early NMI hitting\n             * the VMExit path needs to restore Xen's value for safety.\n             */\n            default_spec_ctrl_flags |= SCF_ist_sc_msr;\n            setup_force_cpu_cap(X86_FEATURE_SC_MSR_HVM);\n        }\n    }\n\n    /* AMD hardware: MSR_SPEC_CTRL alternatives setup. */\n    if ( boot_cpu_has(X86_FEATURE_IBRS) )\n    {\n        /*\n         * Virtualising MSR_SPEC_CTRL for guests depends on SVM support, which\n         * on real hardware matches the availability of MSR_SPEC_CTRL in the\n         * first place.\n         *\n         * No need for SCF_ist_sc_msr because Xen's value is restored\n         * atomically WRT NMIs in the VMExit path.\n         *\n         * TODO: Adjust cpu_has_svm_spec_ctrl to be usable earlier on boot.\n         */\n        if ( opt_msr_sc_hvm &&\n             (boot_cpu_data.extended_cpuid_level >= 0x8000000a) &&\n             (cpuid_edx(0x8000000a) & (1u << SVM_FEATURE_SPEC_CTRL)) )\n            setup_force_cpu_cap(X86_FEATURE_SC_MSR_HVM);\n    }\n\n    /* Support VIRT_SPEC_CTRL.SSBD if AMD_SSBD is not available. */\n    if ( opt_msr_sc_hvm && !cpu_has_amd_ssbd &&\n         (cpu_has_virt_ssbd || (amd_legacy_ssbd && amd_setup_legacy_ssbd())) )\n        amd_virt_spec_ctrl = true;\n\n    /* Figure out default_xen_spec_ctrl. */\n    if ( has_spec_ctrl && ibrs )\n    {\n        /* IBRS implies STIBP.  */\n        if ( opt_stibp == -1 )\n            opt_stibp = 1;\n\n        default_xen_spec_ctrl |= SPEC_CTRL_IBRS;\n    }\n\n    /*\n     * Use STIBP by default on all AMD systems.  Zen3 and later enumerate\n     * STIBP_ALWAYS, but STIBP is needed on Zen2 as part of the mitigations\n     * for Branch Type Confusion.\n     *\n     * Leave STIBP off by default on Intel.  Pre-eIBRS systems suffer a\n     * substantial perf hit when it was implemented in microcode.\n     */\n    if ( opt_stibp == -1 )\n        opt_stibp = !!boot_cpu_has(X86_FEATURE_AMD_STIBP);\n\n    if ( opt_stibp && (boot_cpu_has(X86_FEATURE_STIBP) ||\n                       boot_cpu_has(X86_FEATURE_AMD_STIBP)) )\n        default_xen_spec_ctrl |= SPEC_CTRL_STIBP;\n\n    if ( opt_ssbd && (boot_cpu_has(X86_FEATURE_SSBD) ||\n                      boot_cpu_has(X86_FEATURE_AMD_SSBD)) )\n    {\n        /* SSBD implies PSFD */\n        if ( opt_psfd == -1 )\n            opt_psfd = 1;\n\n        default_xen_spec_ctrl |= SPEC_CTRL_SSBD;\n    }\n\n    /*\n     * Don't use PSFD by default.  AMD designed the predictor to\n     * auto-clear on privilege change.  PSFD is implied by SSBD, which is\n     * off by default.\n     */\n    if ( opt_psfd == -1 )\n        opt_psfd = 0;\n\n    if ( opt_psfd && (boot_cpu_has(X86_FEATURE_PSFD) ||\n                      boot_cpu_has(X86_FEATURE_INTEL_PSFD)) )\n        default_xen_spec_ctrl |= SPEC_CTRL_PSFD;\n\n    /*\n     * PV guests can create RSB entries for any linear address they control,\n     * which are outside of Xen's mappings.\n     *\n     * SMEP inhibits speculation to any user mappings, so in principle it is\n     * safe to not overwrite the RSB when SMEP is active.\n     *\n     * However, some caveats apply:\n     *\n     * 1) CALL instructions push the next sequential linear address into the\n     *    RSB, meaning that there is a boundary case at the user=>supervisor\n     *    split.  This can be compensated for by having an unmapped or NX\n     *    page, or an instruction which halts speculation.\n     *\n     *    For Xen, the next sequential linear address is the start of M2P\n     *    (mapped NX), or a zapped hole (unmapped).\n     *\n     * 2) 32bit PV kernels execute in Ring 1 and use supervisor mappings.\n     *    SMEP offers no protection in this case.\n     *\n     * 3) Some CPUs have RSBs which are not full width, which allow the\n     *    attacker's entries to alias Xen addresses.\n     *\n     * 4) Some CPUs have RSBs which are re-partitioned based on thread\n     *    idleness, which allows an attacker to inject entries into the other\n     *    thread.  We still active the optimisation in this case, and mitigate\n     *    in the idle path which has lower overhead.\n     *\n     * It is safe to turn off RSB stuffing when Xen is using SMEP itself, and\n     * 32bit PV guests are disabled, and when the RSB is full width.\n     */\n    BUILD_BUG_ON(RO_MPT_VIRT_START != PML4_ADDR(256));\n    if ( opt_rsb_pv == -1 )\n    {\n        opt_rsb_pv = (opt_pv32 || !boot_cpu_has(X86_FEATURE_XEN_SMEP) ||\n                      !rsb_is_full_width());\n\n        /*\n         * Cross-Thread Return Address Predictions.\n         *\n         * Vulnerable systems are Zen1/Zen2 uarch, which is AMD Fam17 / Hygon\n         * Fam18, when SMT is active.\n         *\n         * To mitigate, we must flush the RSB/RAS/RAP once between entering\n         * Xen and going idle.\n         *\n         * Most cases flush on entry to Xen anyway.  The one case where we\n         * don't is when using the SMEP optimisation for PV guests.  Flushing\n         * before going idle is less overhead than flushing on PV entry.\n         */\n        if ( !opt_rsb_pv && hw_smt_enabled &&\n             (boot_cpu_data.x86_vendor & (X86_VENDOR_AMD|X86_VENDOR_HYGON)) &&\n             (boot_cpu_data.x86 == 0x17 || boot_cpu_data.x86 == 0x18) )\n            setup_force_cpu_cap(X86_FEATURE_SC_RSB_IDLE);\n    }\n\n    if ( opt_rsb_pv )\n    {\n        setup_force_cpu_cap(X86_FEATURE_SC_RSB_PV);\n        default_spec_ctrl_flags |= SCF_ist_rsb;\n    }\n\n    /*\n     * HVM guests can always poison the RSB to point at Xen supervisor\n     * mappings.\n     */\n    if ( opt_rsb_hvm )\n    {\n        setup_force_cpu_cap(X86_FEATURE_SC_RSB_HVM);\n\n        /*\n         * For SVM, Xen's RSB safety actions are performed before STGI, so\n         * behave atomically with respect to IST sources.\n         *\n         * For VT-x, NMIs are atomic with VMExit (the NMI gets queued but not\n         * delivered) whereas other IST sources are not atomic.  Specifically,\n         * #MC can hit ahead the RSB safety action in the vmexit path.\n         *\n         * Therefore, it is necessary for the IST logic to protect Xen against\n         * possible rogue RSB speculation.\n         */\n        if ( !cpu_has_svm )\n            default_spec_ctrl_flags |= SCF_ist_rsb;\n    }\n\n    srso_calculations(hw_smt_enabled);\n\n    ibpb_calculations();\n\n    /* Check whether Eager FPU should be enabled by default. */\n    if ( opt_eager_fpu == -1 )\n        opt_eager_fpu = should_use_eager_fpu();\n\n    /* (Re)init BSP state now that default_spec_ctrl_flags has been calculated. */\n    init_shadow_spec_ctrl_state();\n\n    /*\n     * For microcoded IBRS only (i.e. Intel, pre eIBRS), it is recommended to\n     * clear MSR_SPEC_CTRL before going idle, to avoid impacting sibling\n     * threads.  Activate this if SMT is enabled, and Xen is using a non-zero\n     * MSR_SPEC_CTRL setting.\n     */\n    if ( boot_cpu_has(X86_FEATURE_IBRSB) && !cpu_has_eibrs &&\n         hw_smt_enabled && default_xen_spec_ctrl )\n        setup_force_cpu_cap(X86_FEATURE_SC_MSR_IDLE);\n\n    xpti_init_default();\n\n    l1tf_calculations();\n\n    /*\n     * By default, enable PV domU L1TF mitigations on all L1TF-vulnerable\n     * hardware, except when running in shim mode.\n     *\n     * In shim mode, SHADOW is expected to be compiled out, and a malicious\n     * guest kernel can only attack the shim Xen, not the host Xen.\n     */\n    if ( opt_pv_l1tf_hwdom == -1 )\n        opt_pv_l1tf_hwdom = 0;\n    if ( opt_pv_l1tf_domu == -1 )\n        opt_pv_l1tf_domu = !pv_shim && cpu_has_bug_l1tf;\n\n    /*\n     * By default, enable L1D_FLUSH on L1TF-vulnerable hardware, unless\n     * instructed to skip the flush on vmentry by our outer hypervisor.\n     */\n    if ( !boot_cpu_has(X86_FEATURE_L1D_FLUSH) )\n        opt_l1d_flush = 0;\n    else if ( opt_l1d_flush == -1 )\n        opt_l1d_flush = cpu_has_bug_l1tf && !cpu_has_skip_l1dfl;\n\n    /* We compile lfence's in by default, and nop them out if requested. */\n    if ( !opt_branch_harden )\n        setup_force_cpu_cap(X86_FEATURE_SC_NO_BRANCH_HARDEN);\n\n    /*\n     * We do not disable HT by default on affected hardware.\n     *\n     * Firstly, if the user intends to use exclusively PV, or HVM shadow\n     * guests, HT isn't a concern and should remain fully enabled.  Secondly,\n     * safety for HVM HAP guests can be arranged by the toolstack with core\n     * parking, pinning or cpupool configurations, including mixed setups.\n     *\n     * However, if we are on affected hardware, with HT enabled, and the user\n     * hasn't explicitly chosen whether to use HT or not, nag them to do so.\n     */\n    if ( opt_smt == -1 && cpu_has_bug_l1tf && !pv_shim && hw_smt_enabled )\n        warning_add(\n            \"Booted on L1TF-vulnerable hardware with SMT/Hyperthreading\\n\"\n            \"enabled.  Please assess your configuration and choose an\\n\"\n            \"explicit 'smt=<bool>' setting.  See XSA-273.\\n\");\n\n    mds_calculations();\n\n    /*\n     * Parts which enumerate FB_CLEAR are those which are post-MDS_NO and have\n     * reintroduced the VERW fill buffer flushing side effect because of a\n     * susceptibility to FBSDP.\n     *\n     * If unprivileged guests have (or will have) MMIO mappings, we can\n     * mitigate cross-domain leakage of fill buffer data by issuing VERW on\n     * the return-to-guest path.\n     */\n    if ( opt_unpriv_mmio )\n        opt_fb_clear_mmio = cpu_has_fb_clear;\n\n    /*\n     * By default, enable PV and HVM mitigations on MDS-vulnerable hardware.\n     * This will only be a token effort for MLPDS/MFBDS when HT is enabled,\n     * but it is somewhat better than nothing.\n     */\n    if ( opt_md_clear_pv == -1 )\n        opt_md_clear_pv = ((cpu_has_bug_mds || cpu_has_bug_msbds_only) &&\n                           boot_cpu_has(X86_FEATURE_MD_CLEAR));\n    if ( opt_md_clear_hvm == -1 )\n        opt_md_clear_hvm = ((cpu_has_bug_mds || cpu_has_bug_msbds_only) &&\n                            boot_cpu_has(X86_FEATURE_MD_CLEAR));\n\n    /*\n     * Enable MDS/MMIO defences as applicable.  The Idle blocks need using if\n     * either the PV or HVM MDS defences are used, or if we may give MMIO\n     * access to untrusted guests.\n     *\n     * HVM is more complicated.  The MD_CLEAR microcode extends L1D_FLUSH with\n     * equivalent semantics to avoid needing to perform both flushes on the\n     * HVM path.  Therefore, we don't need VERW in addition to L1D_FLUSH (for\n     * MDS mitigations.  L1D_FLUSH is not safe for MMIO mitigations.)\n     *\n     * After calculating the appropriate idle setting, simplify\n     * opt_md_clear_hvm to mean just \"should we VERW on the way into HVM\n     * guests\", so spec_ctrl_init_domain() can calculate suitable settings.\n     */\n    if ( opt_md_clear_pv || opt_md_clear_hvm || opt_fb_clear_mmio )\n        setup_force_cpu_cap(X86_FEATURE_SC_VERW_IDLE);\n    opt_md_clear_hvm &= !cpu_has_skip_l1dfl && !opt_l1d_flush;\n\n    /*\n     * Warn the user if they are on MLPDS/MFBDS-vulnerable hardware with HT\n     * active and no explicit SMT choice.\n     */\n    if ( opt_smt == -1 && cpu_has_bug_mds && hw_smt_enabled )\n        warning_add(\n            \"Booted on MLPDS/MFBDS-vulnerable hardware with SMT/Hyperthreading\\n\"\n            \"enabled.  Mitigations will not be fully effective.  Please\\n\"\n            \"choose an explicit smt=<bool> setting.  See XSA-297.\\n\");\n\n    /*\n     * Vulnerability to TAA is a little complicated to quantify.\n     *\n     * In the pipeline, it is just another way to get speculative access to\n     * stale load port, store buffer or fill buffer data, and therefore can be\n     * considered a superset of MDS (on TSX-capable parts).  On parts which\n     * predate MDS_NO, the existing VERW flushing will mitigate this\n     * sidechannel as well.\n     *\n     * On parts which contain MDS_NO, the lack of VERW flushing means that an\n     * attacker can still use TSX to target microarchitectural buffers to leak\n     * secrets.  Therefore, we consider TAA to be the set of TSX-capable parts\n     * which have MDS_NO but lack TAA_NO.\n     *\n     * Note: cpu_has_rtm (== hle) could already be hidden by `tsx=0` on the\n     *       cmdline.  MSR_TSX_CTRL will only appear on TSX-capable parts, so\n     *       we check both to spot TSX in a microcode/cmdline independent way.\n     */\n    cpu_has_bug_taa =\n        (cpu_has_rtm || cpu_has_tsx_ctrl) && cpu_has_mds_no && !cpu_has_taa_no;\n\n    /*\n     * On TAA-affected hardware, disabling TSX is the preferred mitigation, vs\n     * the MDS mitigation of disabling HT and using VERW flushing.\n     *\n     * On CPUs which advertise MDS_NO, VERW has no flushing side effect until\n     * the TSX_CTRL microcode (Nov 2019), despite the MD_CLEAR CPUID bit being\n     * advertised, and there isn't a MD_CLEAR_2 flag to use...\n     *\n     * Furthermore, the VERW flushing side effect is removed again on client\n     * parts with the Feb 2022 microcode.\n     *\n     * If we're on affected hardware, able to do something about it (which\n     * implies that VERW might work), no explicit TSX choice and traditional\n     * MDS mitigations (no-SMT, VERW) not obviosuly in use (someone might\n     * plausibly value TSX higher than Hyperthreading...), disable TSX to\n     * mitigate TAA.\n     */\n    if ( opt_tsx == -1 && cpu_has_bug_taa && cpu_has_tsx_ctrl &&\n         ((hw_smt_enabled && opt_smt) ||\n          !boot_cpu_has(X86_FEATURE_SC_VERW_IDLE)) )\n    {\n        opt_tsx = 0;\n        tsx_init();\n    }\n\n    /*\n     * On some SRBDS-affected hardware, it may be safe to relax srb-lock by\n     * default.\n     *\n     * All parts with SRBDS_CTRL suffer SSDP, the mechanism by which stale RNG\n     * data becomes available to other contexts.  To recover the data, an\n     * attacker needs to use:\n     *  - SBDS (MDS or TAA to sample the cores fill buffer)\n     *  - SBDR (Architecturally retrieve stale transaction buffer contents)\n     *  - DRPW (Architecturally latch stale fill buffer data)\n     *\n     * On MDS_NO parts, and with TAA_NO or TSX unavailable/disabled, and there\n     * is no unprivileged MMIO access, the RNG data doesn't need protecting.\n     */\n    if ( cpu_has_srbds_ctrl )\n    {\n        if ( opt_srb_lock == -1 && !opt_unpriv_mmio &&\n             cpu_has_mds_no && !cpu_has_taa_no &&\n             (!cpu_has_hle || (cpu_has_tsx_ctrl && rtm_disabled)) )\n            opt_srb_lock = 0;\n\n        set_in_mcu_opt_ctrl(MCU_OPT_CTRL_RNGDS_MITG_DIS,\n                            opt_srb_lock ? 0 : MCU_OPT_CTRL_RNGDS_MITG_DIS);\n    }\n\n    gds_calculations();\n\n    print_details(thunk);\n\n    /*\n     * If MSR_SPEC_CTRL is available, apply Xen's default setting and discard\n     * any firmware settings.  For performance reasons, when safe to do so, we\n     * delay applying non-zero settings until after dom0 has been constructed.\n     *\n     * \"when safe to do so\" is based on whether we are virtualised.  A native\n     * boot won't have any other code running in a position to mount an\n     * attack.\n     */\n    if ( has_spec_ctrl )\n    {\n        struct cpu_info *info = get_cpu_info();\n        unsigned int val;\n\n        bsp_delay_spec_ctrl = !cpu_has_hypervisor && default_xen_spec_ctrl;\n\n        /*\n         * If delaying MSR_SPEC_CTRL setup, use the same mechanism as\n         * spec_ctrl_enter_idle(), by using a shadow value of zero.\n         */\n        if ( bsp_delay_spec_ctrl )\n        {\n            info->shadow_spec_ctrl = 0;\n            barrier();\n            info->spec_ctrl_flags |= SCF_use_shadow;\n            barrier();\n        }\n\n        val = bsp_delay_spec_ctrl ? 0 : default_xen_spec_ctrl;\n\n        wrmsrl(MSR_SPEC_CTRL, val);\n        info->last_spec_ctrl = val;\n    }\n}",
        "func": "void __init init_speculation_mitigations(void)\n{\n    enum ind_thunk thunk = THUNK_DEFAULT;\n    bool has_spec_ctrl, ibrs = false, hw_smt_enabled;\n    bool cpu_has_bug_taa, retpoline_safe;\n\n    hw_smt_enabled = check_smt_enabled();\n\n    has_spec_ctrl = (boot_cpu_has(X86_FEATURE_IBRSB) ||\n                     boot_cpu_has(X86_FEATURE_IBRS));\n\n    /*\n     * First, disable the use of retpolines if Xen is using CET.  Retpolines\n     * are a ROP gadget so incompatbile with Shadow Stacks, while IBT depends\n     * on executing indirect branches for the safety properties to apply.\n     *\n     * In the absence of retpolines, IBRS needs to be used for speculative\n     * safety.  All CET-capable hardware has efficient IBRS.\n     */\n    if ( read_cr4() & X86_CR4_CET )\n    {\n        if ( !has_spec_ctrl )\n        {\n            printk(XENLOG_WARNING \"?!? CET active, but no MSR_SPEC_CTRL?\\n\");\n            add_taint(TAINT_CPU_OUT_OF_SPEC);\n        }\n        else if ( opt_ibrs == -1 )\n            opt_ibrs = ibrs = true;\n\n        if ( opt_thunk == THUNK_DEFAULT || opt_thunk == THUNK_RETPOLINE )\n            thunk = THUNK_JMP;\n    }\n\n    /* Determine if retpoline is safe on this CPU.  Fix up RSBA/RRSBA enumerations. */\n    retpoline_safe = retpoline_calculations();\n\n    /*\n     * Has the user specified any custom BTI mitigations?  If so, follow their\n     * instructions exactly and disable all heuristics.\n     */\n    if ( opt_thunk != THUNK_DEFAULT || opt_ibrs != -1 )\n    {\n        thunk = opt_thunk;\n        ibrs  = !!opt_ibrs;\n    }\n    else\n    {\n        /*\n         * Evaluate the safest Branch Target Injection mitigations to use.\n         * First, begin with compiler-aided mitigations.\n         */\n        if ( IS_ENABLED(CONFIG_INDIRECT_THUNK) )\n        {\n            /*\n             * On all hardware, we'd like to use retpoline in preference to\n             * IBRS, but only if it is safe on this hardware.\n             */\n            if ( retpoline_safe )\n                thunk = THUNK_RETPOLINE;\n            else if ( has_spec_ctrl )\n                ibrs = true;\n        }\n        /* Without compiler thunk support, use IBRS if available. */\n        else if ( has_spec_ctrl )\n            ibrs = true;\n    }\n\n    /*\n     * Supplimentary minor adjustments.  Without compiler support, there are\n     * no thunks.\n     */\n    if ( !IS_ENABLED(CONFIG_INDIRECT_THUNK) )\n        thunk = THUNK_NONE;\n\n    /*\n     * If IBRS is in use and thunks are compiled in, there is no point\n     * suffering extra overhead.  Switch to the least-overhead thunk.\n     */\n    if ( ibrs && thunk == THUNK_DEFAULT )\n        thunk = THUNK_JMP;\n\n    /*\n     * If there are still no thunk preferences, the compiled default is\n     * actually retpoline, and it is better than nothing.\n     */\n    if ( thunk == THUNK_DEFAULT )\n        thunk = THUNK_RETPOLINE;\n\n    /* Apply the chosen settings. */\n    if ( thunk == THUNK_LFENCE )\n        setup_force_cpu_cap(X86_FEATURE_IND_THUNK_LFENCE);\n    else if ( thunk == THUNK_JMP )\n        setup_force_cpu_cap(X86_FEATURE_IND_THUNK_JMP);\n\n    /* Intel hardware: MSR_SPEC_CTRL alternatives setup. */\n    if ( boot_cpu_has(X86_FEATURE_IBRSB) )\n    {\n        if ( opt_msr_sc_pv )\n        {\n            default_spec_ctrl_flags |= SCF_ist_sc_msr;\n            setup_force_cpu_cap(X86_FEATURE_SC_MSR_PV);\n        }\n\n        if ( opt_msr_sc_hvm )\n        {\n            /*\n             * While the guest MSR_SPEC_CTRL value is loaded/saved atomically,\n             * Xen's value is not restored atomically.  An early NMI hitting\n             * the VMExit path needs to restore Xen's value for safety.\n             */\n            default_spec_ctrl_flags |= SCF_ist_sc_msr;\n            setup_force_cpu_cap(X86_FEATURE_SC_MSR_HVM);\n        }\n    }\n\n    /* AMD hardware: MSR_SPEC_CTRL alternatives setup. */\n    if ( boot_cpu_has(X86_FEATURE_IBRS) )\n    {\n        /*\n         * Virtualising MSR_SPEC_CTRL for guests depends on SVM support, which\n         * on real hardware matches the availability of MSR_SPEC_CTRL in the\n         * first place.\n         *\n         * No need for SCF_ist_sc_msr because Xen's value is restored\n         * atomically WRT NMIs in the VMExit path.\n         *\n         * TODO: Adjust cpu_has_svm_spec_ctrl to be usable earlier on boot.\n         */\n        if ( opt_msr_sc_hvm &&\n             (boot_cpu_data.extended_cpuid_level >= 0x8000000a) &&\n             (cpuid_edx(0x8000000a) & (1u << SVM_FEATURE_SPEC_CTRL)) )\n            setup_force_cpu_cap(X86_FEATURE_SC_MSR_HVM);\n    }\n\n    /* Support VIRT_SPEC_CTRL.SSBD if AMD_SSBD is not available. */\n    if ( opt_msr_sc_hvm && !cpu_has_amd_ssbd &&\n         (cpu_has_virt_ssbd || (amd_legacy_ssbd && amd_setup_legacy_ssbd())) )\n        amd_virt_spec_ctrl = true;\n\n    /* Figure out default_xen_spec_ctrl. */\n    if ( has_spec_ctrl && ibrs )\n    {\n        /* IBRS implies STIBP.  */\n        if ( opt_stibp == -1 )\n            opt_stibp = 1;\n\n        default_xen_spec_ctrl |= SPEC_CTRL_IBRS;\n    }\n\n    /*\n     * Use STIBP by default on all AMD systems.  Zen3 and later enumerate\n     * STIBP_ALWAYS, but STIBP is needed on Zen2 as part of the mitigations\n     * for Branch Type Confusion.\n     *\n     * Leave STIBP off by default on Intel.  Pre-eIBRS systems suffer a\n     * substantial perf hit when it was implemented in microcode.\n     */\n    if ( opt_stibp == -1 )\n        opt_stibp = !!boot_cpu_has(X86_FEATURE_AMD_STIBP);\n\n    if ( opt_stibp && (boot_cpu_has(X86_FEATURE_STIBP) ||\n                       boot_cpu_has(X86_FEATURE_AMD_STIBP)) )\n        default_xen_spec_ctrl |= SPEC_CTRL_STIBP;\n\n    if ( opt_ssbd && (boot_cpu_has(X86_FEATURE_SSBD) ||\n                      boot_cpu_has(X86_FEATURE_AMD_SSBD)) )\n    {\n        /* SSBD implies PSFD */\n        if ( opt_psfd == -1 )\n            opt_psfd = 1;\n\n        default_xen_spec_ctrl |= SPEC_CTRL_SSBD;\n    }\n\n    /*\n     * Don't use PSFD by default.  AMD designed the predictor to\n     * auto-clear on privilege change.  PSFD is implied by SSBD, which is\n     * off by default.\n     */\n    if ( opt_psfd == -1 )\n        opt_psfd = 0;\n\n    if ( opt_psfd && (boot_cpu_has(X86_FEATURE_PSFD) ||\n                      boot_cpu_has(X86_FEATURE_INTEL_PSFD)) )\n        default_xen_spec_ctrl |= SPEC_CTRL_PSFD;\n\n    /*\n     * PV guests can create RSB entries for any linear address they control,\n     * which are outside of Xen's mappings.\n     *\n     * SMEP inhibits speculation to any user mappings, so in principle it is\n     * safe to not overwrite the RSB when SMEP is active.\n     *\n     * However, some caveats apply:\n     *\n     * 1) CALL instructions push the next sequential linear address into the\n     *    RSB, meaning that there is a boundary case at the user=>supervisor\n     *    split.  This can be compensated for by having an unmapped or NX\n     *    page, or an instruction which halts speculation.\n     *\n     *    For Xen, the next sequential linear address is the start of M2P\n     *    (mapped NX), or a zapped hole (unmapped).\n     *\n     * 2) 32bit PV kernels execute in Ring 1 and use supervisor mappings.\n     *    SMEP offers no protection in this case.\n     *\n     * 3) Some CPUs have RSBs which are not full width, which allow the\n     *    attacker's entries to alias Xen addresses.\n     *\n     * 4) Some CPUs have RSBs which are re-partitioned based on thread\n     *    idleness, which allows an attacker to inject entries into the other\n     *    thread.  We still active the optimisation in this case, and mitigate\n     *    in the idle path which has lower overhead.\n     *\n     * It is safe to turn off RSB stuffing when Xen is using SMEP itself, and\n     * 32bit PV guests are disabled, and when the RSB is full width.\n     */\n    BUILD_BUG_ON(RO_MPT_VIRT_START != PML4_ADDR(256));\n    if ( opt_rsb_pv == -1 )\n    {\n        opt_rsb_pv = (opt_pv32 || !boot_cpu_has(X86_FEATURE_XEN_SMEP) ||\n                      !rsb_is_full_width());\n\n        /*\n         * Cross-Thread Return Address Predictions.\n         *\n         * Vulnerable systems are Zen1/Zen2 uarch, which is AMD Fam17 / Hygon\n         * Fam18, when SMT is active.\n         *\n         * To mitigate, we must flush the RSB/RAS/RAP once between entering\n         * Xen and going idle.\n         *\n         * Most cases flush on entry to Xen anyway.  The one case where we\n         * don't is when using the SMEP optimisation for PV guests.  Flushing\n         * before going idle is less overhead than flushing on PV entry.\n         */\n        if ( !opt_rsb_pv && hw_smt_enabled &&\n             (boot_cpu_data.x86_vendor & (X86_VENDOR_AMD|X86_VENDOR_HYGON)) &&\n             (boot_cpu_data.x86 == 0x17 || boot_cpu_data.x86 == 0x18) )\n            setup_force_cpu_cap(X86_FEATURE_SC_RSB_IDLE);\n    }\n\n    if ( opt_rsb_pv )\n    {\n        setup_force_cpu_cap(X86_FEATURE_SC_RSB_PV);\n        default_spec_ctrl_flags |= SCF_ist_rsb;\n    }\n\n    /*\n     * HVM guests can always poison the RSB to point at Xen supervisor\n     * mappings.\n     */\n    if ( opt_rsb_hvm )\n    {\n        setup_force_cpu_cap(X86_FEATURE_SC_RSB_HVM);\n\n        /*\n         * For SVM, Xen's RSB safety actions are performed before STGI, so\n         * behave atomically with respect to IST sources.\n         *\n         * For VT-x, NMIs are atomic with VMExit (the NMI gets queued but not\n         * delivered) whereas other IST sources are not atomic.  Specifically,\n         * #MC can hit ahead the RSB safety action in the vmexit path.\n         *\n         * Therefore, it is necessary for the IST logic to protect Xen against\n         * possible rogue RSB speculation.\n         */\n        if ( !cpu_has_svm )\n            default_spec_ctrl_flags |= SCF_ist_rsb;\n    }\n\n    srso_calculations(hw_smt_enabled);\n\n    ibpb_calculations();\n\n    div_calculations(hw_smt_enabled);\n\n    /* Check whether Eager FPU should be enabled by default. */\n    if ( opt_eager_fpu == -1 )\n        opt_eager_fpu = should_use_eager_fpu();\n\n    /* (Re)init BSP state now that default_spec_ctrl_flags has been calculated. */\n    init_shadow_spec_ctrl_state();\n\n    /*\n     * For microcoded IBRS only (i.e. Intel, pre eIBRS), it is recommended to\n     * clear MSR_SPEC_CTRL before going idle, to avoid impacting sibling\n     * threads.  Activate this if SMT is enabled, and Xen is using a non-zero\n     * MSR_SPEC_CTRL setting.\n     */\n    if ( boot_cpu_has(X86_FEATURE_IBRSB) && !cpu_has_eibrs &&\n         hw_smt_enabled && default_xen_spec_ctrl )\n        setup_force_cpu_cap(X86_FEATURE_SC_MSR_IDLE);\n\n    xpti_init_default();\n\n    l1tf_calculations();\n\n    /*\n     * By default, enable PV domU L1TF mitigations on all L1TF-vulnerable\n     * hardware, except when running in shim mode.\n     *\n     * In shim mode, SHADOW is expected to be compiled out, and a malicious\n     * guest kernel can only attack the shim Xen, not the host Xen.\n     */\n    if ( opt_pv_l1tf_hwdom == -1 )\n        opt_pv_l1tf_hwdom = 0;\n    if ( opt_pv_l1tf_domu == -1 )\n        opt_pv_l1tf_domu = !pv_shim && cpu_has_bug_l1tf;\n\n    /*\n     * By default, enable L1D_FLUSH on L1TF-vulnerable hardware, unless\n     * instructed to skip the flush on vmentry by our outer hypervisor.\n     */\n    if ( !boot_cpu_has(X86_FEATURE_L1D_FLUSH) )\n        opt_l1d_flush = 0;\n    else if ( opt_l1d_flush == -1 )\n        opt_l1d_flush = cpu_has_bug_l1tf && !cpu_has_skip_l1dfl;\n\n    /* We compile lfence's in by default, and nop them out if requested. */\n    if ( !opt_branch_harden )\n        setup_force_cpu_cap(X86_FEATURE_SC_NO_BRANCH_HARDEN);\n\n    /*\n     * We do not disable HT by default on affected hardware.\n     *\n     * Firstly, if the user intends to use exclusively PV, or HVM shadow\n     * guests, HT isn't a concern and should remain fully enabled.  Secondly,\n     * safety for HVM HAP guests can be arranged by the toolstack with core\n     * parking, pinning or cpupool configurations, including mixed setups.\n     *\n     * However, if we are on affected hardware, with HT enabled, and the user\n     * hasn't explicitly chosen whether to use HT or not, nag them to do so.\n     */\n    if ( opt_smt == -1 && cpu_has_bug_l1tf && !pv_shim && hw_smt_enabled )\n        warning_add(\n            \"Booted on L1TF-vulnerable hardware with SMT/Hyperthreading\\n\"\n            \"enabled.  Please assess your configuration and choose an\\n\"\n            \"explicit 'smt=<bool>' setting.  See XSA-273.\\n\");\n\n    mds_calculations();\n\n    /*\n     * Parts which enumerate FB_CLEAR are those which are post-MDS_NO and have\n     * reintroduced the VERW fill buffer flushing side effect because of a\n     * susceptibility to FBSDP.\n     *\n     * If unprivileged guests have (or will have) MMIO mappings, we can\n     * mitigate cross-domain leakage of fill buffer data by issuing VERW on\n     * the return-to-guest path.\n     */\n    if ( opt_unpriv_mmio )\n        opt_fb_clear_mmio = cpu_has_fb_clear;\n\n    /*\n     * By default, enable PV and HVM mitigations on MDS-vulnerable hardware.\n     * This will only be a token effort for MLPDS/MFBDS when HT is enabled,\n     * but it is somewhat better than nothing.\n     */\n    if ( opt_md_clear_pv == -1 )\n        opt_md_clear_pv = ((cpu_has_bug_mds || cpu_has_bug_msbds_only) &&\n                           boot_cpu_has(X86_FEATURE_MD_CLEAR));\n    if ( opt_md_clear_hvm == -1 )\n        opt_md_clear_hvm = ((cpu_has_bug_mds || cpu_has_bug_msbds_only) &&\n                            boot_cpu_has(X86_FEATURE_MD_CLEAR));\n\n    /*\n     * Enable MDS/MMIO defences as applicable.  The Idle blocks need using if\n     * either the PV or HVM MDS defences are used, or if we may give MMIO\n     * access to untrusted guests.\n     *\n     * HVM is more complicated.  The MD_CLEAR microcode extends L1D_FLUSH with\n     * equivalent semantics to avoid needing to perform both flushes on the\n     * HVM path.  Therefore, we don't need VERW in addition to L1D_FLUSH (for\n     * MDS mitigations.  L1D_FLUSH is not safe for MMIO mitigations.)\n     *\n     * After calculating the appropriate idle setting, simplify\n     * opt_md_clear_hvm to mean just \"should we VERW on the way into HVM\n     * guests\", so spec_ctrl_init_domain() can calculate suitable settings.\n     */\n    if ( opt_md_clear_pv || opt_md_clear_hvm || opt_fb_clear_mmio )\n        setup_force_cpu_cap(X86_FEATURE_SC_VERW_IDLE);\n    opt_md_clear_hvm &= !cpu_has_skip_l1dfl && !opt_l1d_flush;\n\n    /*\n     * Warn the user if they are on MLPDS/MFBDS-vulnerable hardware with HT\n     * active and no explicit SMT choice.\n     */\n    if ( opt_smt == -1 && cpu_has_bug_mds && hw_smt_enabled )\n        warning_add(\n            \"Booted on MLPDS/MFBDS-vulnerable hardware with SMT/Hyperthreading\\n\"\n            \"enabled.  Mitigations will not be fully effective.  Please\\n\"\n            \"choose an explicit smt=<bool> setting.  See XSA-297.\\n\");\n\n    /*\n     * Vulnerability to TAA is a little complicated to quantify.\n     *\n     * In the pipeline, it is just another way to get speculative access to\n     * stale load port, store buffer or fill buffer data, and therefore can be\n     * considered a superset of MDS (on TSX-capable parts).  On parts which\n     * predate MDS_NO, the existing VERW flushing will mitigate this\n     * sidechannel as well.\n     *\n     * On parts which contain MDS_NO, the lack of VERW flushing means that an\n     * attacker can still use TSX to target microarchitectural buffers to leak\n     * secrets.  Therefore, we consider TAA to be the set of TSX-capable parts\n     * which have MDS_NO but lack TAA_NO.\n     *\n     * Note: cpu_has_rtm (== hle) could already be hidden by `tsx=0` on the\n     *       cmdline.  MSR_TSX_CTRL will only appear on TSX-capable parts, so\n     *       we check both to spot TSX in a microcode/cmdline independent way.\n     */\n    cpu_has_bug_taa =\n        (cpu_has_rtm || cpu_has_tsx_ctrl) && cpu_has_mds_no && !cpu_has_taa_no;\n\n    /*\n     * On TAA-affected hardware, disabling TSX is the preferred mitigation, vs\n     * the MDS mitigation of disabling HT and using VERW flushing.\n     *\n     * On CPUs which advertise MDS_NO, VERW has no flushing side effect until\n     * the TSX_CTRL microcode (Nov 2019), despite the MD_CLEAR CPUID bit being\n     * advertised, and there isn't a MD_CLEAR_2 flag to use...\n     *\n     * Furthermore, the VERW flushing side effect is removed again on client\n     * parts with the Feb 2022 microcode.\n     *\n     * If we're on affected hardware, able to do something about it (which\n     * implies that VERW might work), no explicit TSX choice and traditional\n     * MDS mitigations (no-SMT, VERW) not obviosuly in use (someone might\n     * plausibly value TSX higher than Hyperthreading...), disable TSX to\n     * mitigate TAA.\n     */\n    if ( opt_tsx == -1 && cpu_has_bug_taa && cpu_has_tsx_ctrl &&\n         ((hw_smt_enabled && opt_smt) ||\n          !boot_cpu_has(X86_FEATURE_SC_VERW_IDLE)) )\n    {\n        opt_tsx = 0;\n        tsx_init();\n    }\n\n    /*\n     * On some SRBDS-affected hardware, it may be safe to relax srb-lock by\n     * default.\n     *\n     * All parts with SRBDS_CTRL suffer SSDP, the mechanism by which stale RNG\n     * data becomes available to other contexts.  To recover the data, an\n     * attacker needs to use:\n     *  - SBDS (MDS or TAA to sample the cores fill buffer)\n     *  - SBDR (Architecturally retrieve stale transaction buffer contents)\n     *  - DRPW (Architecturally latch stale fill buffer data)\n     *\n     * On MDS_NO parts, and with TAA_NO or TSX unavailable/disabled, and there\n     * is no unprivileged MMIO access, the RNG data doesn't need protecting.\n     */\n    if ( cpu_has_srbds_ctrl )\n    {\n        if ( opt_srb_lock == -1 && !opt_unpriv_mmio &&\n             cpu_has_mds_no && !cpu_has_taa_no &&\n             (!cpu_has_hle || (cpu_has_tsx_ctrl && rtm_disabled)) )\n            opt_srb_lock = 0;\n\n        set_in_mcu_opt_ctrl(MCU_OPT_CTRL_RNGDS_MITG_DIS,\n                            opt_srb_lock ? 0 : MCU_OPT_CTRL_RNGDS_MITG_DIS);\n    }\n\n    gds_calculations();\n\n    print_details(thunk);\n\n    /*\n     * If MSR_SPEC_CTRL is available, apply Xen's default setting and discard\n     * any firmware settings.  For performance reasons, when safe to do so, we\n     * delay applying non-zero settings until after dom0 has been constructed.\n     *\n     * \"when safe to do so\" is based on whether we are virtualised.  A native\n     * boot won't have any other code running in a position to mount an\n     * attack.\n     */\n    if ( has_spec_ctrl )\n    {\n        struct cpu_info *info = get_cpu_info();\n        unsigned int val;\n\n        bsp_delay_spec_ctrl = !cpu_has_hypervisor && default_xen_spec_ctrl;\n\n        /*\n         * If delaying MSR_SPEC_CTRL setup, use the same mechanism as\n         * spec_ctrl_enter_idle(), by using a shadow value of zero.\n         */\n        if ( bsp_delay_spec_ctrl )\n        {\n            info->shadow_spec_ctrl = 0;\n            barrier();\n            info->spec_ctrl_flags |= SCF_use_shadow;\n            barrier();\n        }\n\n        val = bsp_delay_spec_ctrl ? 0 : default_xen_spec_ctrl;\n\n        wrmsrl(MSR_SPEC_CTRL, val);\n        info->last_spec_ctrl = val;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -273,6 +273,8 @@\n \n     ibpb_calculations();\n \n+    div_calculations(hw_smt_enabled);\n+\n     /* Check whether Eager FPU should be enabled by default. */\n     if ( opt_eager_fpu == -1 )\n         opt_eager_fpu = should_use_eager_fpu();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    div_calculations(hw_smt_enabled);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-20588",
        "func_name": "xen-project/xen/print_details",
        "description": "\nA division-by-zero error on some AMD processors can potentially return speculative data resulting in loss of confidentiality.\n\n\n\n\n\n\n\n",
        "git_url": "https://github.com/xen-project/xen/commit/b5926c6ecf05c28ee99c6248c42d691ccbf0c315",
        "commit_title": "x86/spec-ctrl: Mitigate the Zen1 DIV leakage",
        "commit_text": " In the Zen1 microarchitecure, there is one divider in the pipeline which services uops from both threads.  In the case of #DE, the latched result from the previous DIV to execute will be forwarded speculatively.  This is an interesting covert channel that allows two threads to communicate without any system calls.  In also allows userspace to obtain the result of the most recent DIV instruction executed (even speculatively) in the core, which can be from a higher privilege context.  Scrub the result from the divider by executing a non-faulting divide.  This needs performing on the exit-to-guest paths, and ist_exit-to-Xen.  Alternatives in IST context is believed safe now that it's done in NMI context.  This is XSA-439 / CVE-2023-20588. ",
        "func_before": "static void __init print_details(enum ind_thunk thunk)\n{\n    unsigned int _7d0 = 0, _7d2 = 0, e8b = 0, e21a = 0, max = 0, tmp;\n    uint64_t caps = 0;\n\n    /* Collect diagnostics about available mitigations. */\n    if ( boot_cpu_data.cpuid_level >= 7 )\n        cpuid_count(7, 0, &max, &tmp, &tmp, &_7d0);\n    if ( max >= 2 )\n        cpuid_count(7, 2, &tmp, &tmp, &tmp, &_7d2);\n    if ( boot_cpu_data.extended_cpuid_level >= 0x80000008 )\n        cpuid(0x80000008, &tmp, &e8b, &tmp, &tmp);\n    if ( boot_cpu_data.extended_cpuid_level >= 0x80000021 )\n        cpuid(0x80000021, &e21a, &tmp, &tmp, &tmp);\n    if ( cpu_has_arch_caps )\n        rdmsrl(MSR_ARCH_CAPABILITIES, caps);\n\n    printk(\"Speculative mitigation facilities:\\n\");\n\n    /*\n     * Hardware read-only information, stating immunity to certain issues, or\n     * suggestions of which mitigation to use.\n     */\n    printk(\"  Hardware hints:%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s\\n\",\n           (caps & ARCH_CAPS_RDCL_NO)                        ? \" RDCL_NO\"        : \"\",\n           (caps & ARCH_CAPS_EIBRS)                          ? \" EIBRS\"          : \"\",\n           (caps & ARCH_CAPS_RSBA)                           ? \" RSBA\"           : \"\",\n           (caps & ARCH_CAPS_RRSBA)                          ? \" RRSBA\"          : \"\",\n           (caps & ARCH_CAPS_SKIP_L1DFL)                     ? \" SKIP_L1DFL\"     : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_SSB_NO)) ||\n           (caps & ARCH_CAPS_SSB_NO)                         ? \" SSB_NO\"         : \"\",\n           (caps & ARCH_CAPS_MDS_NO)                         ? \" MDS_NO\"         : \"\",\n           (caps & ARCH_CAPS_TAA_NO)                         ? \" TAA_NO\"         : \"\",\n           (caps & ARCH_CAPS_SBDR_SSDP_NO)                   ? \" SBDR_SSDP_NO\"   : \"\",\n           (caps & ARCH_CAPS_FBSDP_NO)                       ? \" FBSDP_NO\"       : \"\",\n           (caps & ARCH_CAPS_PSDP_NO)                        ? \" PSDP_NO\"        : \"\",\n           (caps & ARCH_CAPS_FB_CLEAR)                       ? \" FB_CLEAR\"       : \"\",\n           (caps & ARCH_CAPS_PBRSB_NO)                       ? \" PBRSB_NO\"       : \"\",\n           (caps & ARCH_CAPS_GDS_NO)                         ? \" GDS_NO\"         : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS_ALWAYS))    ? \" IBRS_ALWAYS\"    : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_STIBP_ALWAYS))   ? \" STIBP_ALWAYS\"   : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS_FAST))      ? \" IBRS_FAST\"      : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS_SAME_MODE)) ? \" IBRS_SAME_MODE\" : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_BTC_NO))         ? \" BTC_NO\"         : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBPB_RET))       ? \" IBPB_RET\"       : \"\",\n           (e21a & cpufeat_mask(X86_FEATURE_IBPB_BRTYPE))    ? \" IBPB_BRTYPE\"    : \"\",\n           (e21a & cpufeat_mask(X86_FEATURE_SRSO_NO))        ? \" SRSO_NO\"        : \"\");\n\n    /* Hardware features which need driving to mitigate issues. */\n    printk(\"  Hardware features:%s%s%s%s%s%s%s%s%s%s%s%s%s\\n\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBPB)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_IBRSB))          ? \" IBPB\"           : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_IBRSB))          ? \" IBRS\"           : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_AMD_STIBP)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_STIBP))          ? \" STIBP\"          : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_AMD_SSBD)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_SSBD))           ? \" SSBD\"           : \"\",\n           (_7d2 & cpufeat_mask(X86_FEATURE_INTEL_PSFD)) ||\n           (e8b  & cpufeat_mask(X86_FEATURE_PSFD))           ? \" PSFD\"           : \"\",\n           (_7d0 & cpufeat_mask(X86_FEATURE_L1D_FLUSH))      ? \" L1D_FLUSH\"      : \"\",\n           (_7d0 & cpufeat_mask(X86_FEATURE_MD_CLEAR))       ? \" MD_CLEAR\"       : \"\",\n           (_7d0 & cpufeat_mask(X86_FEATURE_SRBDS_CTRL))     ? \" SRBDS_CTRL\"     : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_VIRT_SSBD))      ? \" VIRT_SSBD\"      : \"\",\n           (caps & ARCH_CAPS_TSX_CTRL)                       ? \" TSX_CTRL\"       : \"\",\n           (caps & ARCH_CAPS_FB_CLEAR_CTRL)                  ? \" FB_CLEAR_CTRL\"  : \"\",\n           (caps & ARCH_CAPS_GDS_CTRL)                       ? \" GDS_CTRL\"       : \"\",\n           (e21a & cpufeat_mask(X86_FEATURE_SBPB))           ? \" SBPB\"           : \"\");\n\n    /* Compiled-in support which pertains to mitigations. */\n    if ( IS_ENABLED(CONFIG_INDIRECT_THUNK) || IS_ENABLED(CONFIG_SHADOW_PAGING) )\n        printk(\"  Compiled-in support:\"\n#ifdef CONFIG_INDIRECT_THUNK\n               \" INDIRECT_THUNK\"\n#endif\n#ifdef CONFIG_SHADOW_PAGING\n               \" SHADOW_PAGING\"\n#endif\n               \"\\n\");\n\n    /* Settings for Xen's protection, irrespective of guests. */\n    printk(\"  Xen settings: BTI-Thunk %s, SPEC_CTRL: %s%s%s%s%s, Other:%s%s%s%s%s\\n\",\n           thunk == THUNK_NONE      ? \"N/A\" :\n           thunk == THUNK_RETPOLINE ? \"RETPOLINE\" :\n           thunk == THUNK_LFENCE    ? \"LFENCE\" :\n           thunk == THUNK_JMP       ? \"JMP\" : \"?\",\n           (!boot_cpu_has(X86_FEATURE_IBRSB) &&\n            !boot_cpu_has(X86_FEATURE_IBRS))         ? \"No\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_IBRS)  ? \"IBRS+\" :  \"IBRS-\",\n           (!boot_cpu_has(X86_FEATURE_STIBP) &&\n            !boot_cpu_has(X86_FEATURE_AMD_STIBP))    ? \"\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_STIBP) ? \" STIBP+\" : \" STIBP-\",\n           (!boot_cpu_has(X86_FEATURE_SSBD) &&\n            !boot_cpu_has(X86_FEATURE_AMD_SSBD))     ? \"\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_SSBD)  ? \" SSBD+\" : \" SSBD-\",\n           (!boot_cpu_has(X86_FEATURE_PSFD) &&\n            !boot_cpu_has(X86_FEATURE_INTEL_PSFD))   ? \"\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_PSFD)  ? \" PSFD+\" : \" PSFD-\",\n           !(caps & ARCH_CAPS_TSX_CTRL)              ? \"\" :\n           (opt_tsx & 1)                             ? \" TSX+\" : \" TSX-\",\n           !cpu_has_srbds_ctrl                       ? \"\" :\n           opt_srb_lock                              ? \" SRB_LOCK+\" : \" SRB_LOCK-\",\n           opt_ibpb_ctxt_switch                      ? \" IBPB-ctxt\" : \"\",\n           opt_l1d_flush                             ? \" L1D_FLUSH\" : \"\",\n           opt_md_clear_pv || opt_md_clear_hvm ||\n           opt_fb_clear_mmio                         ? \" VERW\"  : \"\",\n           opt_branch_harden                         ? \" BRANCH_HARDEN\" : \"\");\n\n    /* L1TF diagnostics, printed if vulnerable or PV shadowing is in use. */\n    if ( cpu_has_bug_l1tf || opt_pv_l1tf_hwdom || opt_pv_l1tf_domu )\n        printk(\"  L1TF: believed%s vulnerable, maxphysaddr L1D %u, CPUID %u\"\n               \", Safe address %\"PRIx64\"\\n\",\n               cpu_has_bug_l1tf ? \"\" : \" not\",\n               l1d_maxphysaddr, paddr_bits, l1tf_safe_maddr);\n\n    /*\n     * Alternatives blocks for protecting against and/or virtualising\n     * mitigation support for guests.\n     */\n#ifdef CONFIG_HVM\n    printk(\"  Support for HVM VMs:%s%s%s%s%s%s%s\\n\",\n           (boot_cpu_has(X86_FEATURE_SC_MSR_HVM) ||\n            boot_cpu_has(X86_FEATURE_SC_RSB_HVM) ||\n            boot_cpu_has(X86_FEATURE_IBPB_ENTRY_HVM) ||\n            amd_virt_spec_ctrl ||\n            opt_eager_fpu || opt_md_clear_hvm)       ? \"\"               : \" None\",\n           boot_cpu_has(X86_FEATURE_SC_MSR_HVM)      ? \" MSR_SPEC_CTRL\" : \"\",\n           (boot_cpu_has(X86_FEATURE_SC_MSR_HVM) ||\n            amd_virt_spec_ctrl)                      ? \" MSR_VIRT_SPEC_CTRL\" : \"\",\n           boot_cpu_has(X86_FEATURE_SC_RSB_HVM)      ? \" RSB\"           : \"\",\n           opt_eager_fpu                             ? \" EAGER_FPU\"     : \"\",\n           opt_md_clear_hvm                          ? \" MD_CLEAR\"      : \"\",\n           boot_cpu_has(X86_FEATURE_IBPB_ENTRY_HVM)  ? \" IBPB-entry\"    : \"\");\n\n#endif\n#ifdef CONFIG_PV\n    printk(\"  Support for PV VMs:%s%s%s%s%s%s\\n\",\n           (boot_cpu_has(X86_FEATURE_SC_MSR_PV) ||\n            boot_cpu_has(X86_FEATURE_SC_RSB_PV) ||\n            boot_cpu_has(X86_FEATURE_IBPB_ENTRY_PV) ||\n            opt_eager_fpu || opt_md_clear_pv)        ? \"\"               : \" None\",\n           boot_cpu_has(X86_FEATURE_SC_MSR_PV)       ? \" MSR_SPEC_CTRL\" : \"\",\n           boot_cpu_has(X86_FEATURE_SC_RSB_PV)       ? \" RSB\"           : \"\",\n           opt_eager_fpu                             ? \" EAGER_FPU\"     : \"\",\n           opt_md_clear_pv                           ? \" MD_CLEAR\"      : \"\",\n           boot_cpu_has(X86_FEATURE_IBPB_ENTRY_PV)   ? \" IBPB-entry\"    : \"\");\n\n    printk(\"  XPTI (64-bit PV only): Dom0 %s, DomU %s (with%s PCID)\\n\",\n           opt_xpti_hwdom ? \"enabled\" : \"disabled\",\n           opt_xpti_domu  ? \"enabled\" : \"disabled\",\n           xpti_pcid_enabled() ? \"\" : \"out\");\n\n    printk(\"  PV L1TF shadowing: Dom0 %s, DomU %s\\n\",\n           opt_pv_l1tf_hwdom ? \"enabled\"  : \"disabled\",\n           opt_pv_l1tf_domu  ? \"enabled\"  : \"disabled\");\n#endif\n}",
        "func": "static void __init print_details(enum ind_thunk thunk)\n{\n    unsigned int _7d0 = 0, _7d2 = 0, e8b = 0, e21a = 0, max = 0, tmp;\n    uint64_t caps = 0;\n\n    /* Collect diagnostics about available mitigations. */\n    if ( boot_cpu_data.cpuid_level >= 7 )\n        cpuid_count(7, 0, &max, &tmp, &tmp, &_7d0);\n    if ( max >= 2 )\n        cpuid_count(7, 2, &tmp, &tmp, &tmp, &_7d2);\n    if ( boot_cpu_data.extended_cpuid_level >= 0x80000008 )\n        cpuid(0x80000008, &tmp, &e8b, &tmp, &tmp);\n    if ( boot_cpu_data.extended_cpuid_level >= 0x80000021 )\n        cpuid(0x80000021, &e21a, &tmp, &tmp, &tmp);\n    if ( cpu_has_arch_caps )\n        rdmsrl(MSR_ARCH_CAPABILITIES, caps);\n\n    printk(\"Speculative mitigation facilities:\\n\");\n\n    /*\n     * Hardware read-only information, stating immunity to certain issues, or\n     * suggestions of which mitigation to use.\n     */\n    printk(\"  Hardware hints:%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s%s\\n\",\n           (caps & ARCH_CAPS_RDCL_NO)                        ? \" RDCL_NO\"        : \"\",\n           (caps & ARCH_CAPS_EIBRS)                          ? \" EIBRS\"          : \"\",\n           (caps & ARCH_CAPS_RSBA)                           ? \" RSBA\"           : \"\",\n           (caps & ARCH_CAPS_RRSBA)                          ? \" RRSBA\"          : \"\",\n           (caps & ARCH_CAPS_SKIP_L1DFL)                     ? \" SKIP_L1DFL\"     : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_SSB_NO)) ||\n           (caps & ARCH_CAPS_SSB_NO)                         ? \" SSB_NO\"         : \"\",\n           (caps & ARCH_CAPS_MDS_NO)                         ? \" MDS_NO\"         : \"\",\n           (caps & ARCH_CAPS_TAA_NO)                         ? \" TAA_NO\"         : \"\",\n           (caps & ARCH_CAPS_SBDR_SSDP_NO)                   ? \" SBDR_SSDP_NO\"   : \"\",\n           (caps & ARCH_CAPS_FBSDP_NO)                       ? \" FBSDP_NO\"       : \"\",\n           (caps & ARCH_CAPS_PSDP_NO)                        ? \" PSDP_NO\"        : \"\",\n           (caps & ARCH_CAPS_FB_CLEAR)                       ? \" FB_CLEAR\"       : \"\",\n           (caps & ARCH_CAPS_PBRSB_NO)                       ? \" PBRSB_NO\"       : \"\",\n           (caps & ARCH_CAPS_GDS_NO)                         ? \" GDS_NO\"         : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS_ALWAYS))    ? \" IBRS_ALWAYS\"    : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_STIBP_ALWAYS))   ? \" STIBP_ALWAYS\"   : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS_FAST))      ? \" IBRS_FAST\"      : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS_SAME_MODE)) ? \" IBRS_SAME_MODE\" : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_BTC_NO))         ? \" BTC_NO\"         : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBPB_RET))       ? \" IBPB_RET\"       : \"\",\n           (e21a & cpufeat_mask(X86_FEATURE_IBPB_BRTYPE))    ? \" IBPB_BRTYPE\"    : \"\",\n           (e21a & cpufeat_mask(X86_FEATURE_SRSO_NO))        ? \" SRSO_NO\"        : \"\");\n\n    /* Hardware features which need driving to mitigate issues. */\n    printk(\"  Hardware features:%s%s%s%s%s%s%s%s%s%s%s%s%s\\n\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBPB)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_IBRSB))          ? \" IBPB\"           : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_IBRS)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_IBRSB))          ? \" IBRS\"           : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_AMD_STIBP)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_STIBP))          ? \" STIBP\"          : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_AMD_SSBD)) ||\n           (_7d0 & cpufeat_mask(X86_FEATURE_SSBD))           ? \" SSBD\"           : \"\",\n           (_7d2 & cpufeat_mask(X86_FEATURE_INTEL_PSFD)) ||\n           (e8b  & cpufeat_mask(X86_FEATURE_PSFD))           ? \" PSFD\"           : \"\",\n           (_7d0 & cpufeat_mask(X86_FEATURE_L1D_FLUSH))      ? \" L1D_FLUSH\"      : \"\",\n           (_7d0 & cpufeat_mask(X86_FEATURE_MD_CLEAR))       ? \" MD_CLEAR\"       : \"\",\n           (_7d0 & cpufeat_mask(X86_FEATURE_SRBDS_CTRL))     ? \" SRBDS_CTRL\"     : \"\",\n           (e8b  & cpufeat_mask(X86_FEATURE_VIRT_SSBD))      ? \" VIRT_SSBD\"      : \"\",\n           (caps & ARCH_CAPS_TSX_CTRL)                       ? \" TSX_CTRL\"       : \"\",\n           (caps & ARCH_CAPS_FB_CLEAR_CTRL)                  ? \" FB_CLEAR_CTRL\"  : \"\",\n           (caps & ARCH_CAPS_GDS_CTRL)                       ? \" GDS_CTRL\"       : \"\",\n           (e21a & cpufeat_mask(X86_FEATURE_SBPB))           ? \" SBPB\"           : \"\");\n\n    /* Compiled-in support which pertains to mitigations. */\n    if ( IS_ENABLED(CONFIG_INDIRECT_THUNK) || IS_ENABLED(CONFIG_SHADOW_PAGING) )\n        printk(\"  Compiled-in support:\"\n#ifdef CONFIG_INDIRECT_THUNK\n               \" INDIRECT_THUNK\"\n#endif\n#ifdef CONFIG_SHADOW_PAGING\n               \" SHADOW_PAGING\"\n#endif\n               \"\\n\");\n\n    /* Settings for Xen's protection, irrespective of guests. */\n    printk(\"  Xen settings: BTI-Thunk %s, SPEC_CTRL: %s%s%s%s%s, Other:%s%s%s%s%s%s\\n\",\n           thunk == THUNK_NONE      ? \"N/A\" :\n           thunk == THUNK_RETPOLINE ? \"RETPOLINE\" :\n           thunk == THUNK_LFENCE    ? \"LFENCE\" :\n           thunk == THUNK_JMP       ? \"JMP\" : \"?\",\n           (!boot_cpu_has(X86_FEATURE_IBRSB) &&\n            !boot_cpu_has(X86_FEATURE_IBRS))         ? \"No\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_IBRS)  ? \"IBRS+\" :  \"IBRS-\",\n           (!boot_cpu_has(X86_FEATURE_STIBP) &&\n            !boot_cpu_has(X86_FEATURE_AMD_STIBP))    ? \"\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_STIBP) ? \" STIBP+\" : \" STIBP-\",\n           (!boot_cpu_has(X86_FEATURE_SSBD) &&\n            !boot_cpu_has(X86_FEATURE_AMD_SSBD))     ? \"\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_SSBD)  ? \" SSBD+\" : \" SSBD-\",\n           (!boot_cpu_has(X86_FEATURE_PSFD) &&\n            !boot_cpu_has(X86_FEATURE_INTEL_PSFD))   ? \"\" :\n           (default_xen_spec_ctrl & SPEC_CTRL_PSFD)  ? \" PSFD+\" : \" PSFD-\",\n           !(caps & ARCH_CAPS_TSX_CTRL)              ? \"\" :\n           (opt_tsx & 1)                             ? \" TSX+\" : \" TSX-\",\n           !cpu_has_srbds_ctrl                       ? \"\" :\n           opt_srb_lock                              ? \" SRB_LOCK+\" : \" SRB_LOCK-\",\n           opt_ibpb_ctxt_switch                      ? \" IBPB-ctxt\" : \"\",\n           opt_l1d_flush                             ? \" L1D_FLUSH\" : \"\",\n           opt_md_clear_pv || opt_md_clear_hvm ||\n           opt_fb_clear_mmio                         ? \" VERW\"  : \"\",\n           opt_div_scrub                             ? \" DIV\" : \"\",\n           opt_branch_harden                         ? \" BRANCH_HARDEN\" : \"\");\n\n    /* L1TF diagnostics, printed if vulnerable or PV shadowing is in use. */\n    if ( cpu_has_bug_l1tf || opt_pv_l1tf_hwdom || opt_pv_l1tf_domu )\n        printk(\"  L1TF: believed%s vulnerable, maxphysaddr L1D %u, CPUID %u\"\n               \", Safe address %\"PRIx64\"\\n\",\n               cpu_has_bug_l1tf ? \"\" : \" not\",\n               l1d_maxphysaddr, paddr_bits, l1tf_safe_maddr);\n\n    /*\n     * Alternatives blocks for protecting against and/or virtualising\n     * mitigation support for guests.\n     */\n#ifdef CONFIG_HVM\n    printk(\"  Support for HVM VMs:%s%s%s%s%s%s%s\\n\",\n           (boot_cpu_has(X86_FEATURE_SC_MSR_HVM) ||\n            boot_cpu_has(X86_FEATURE_SC_RSB_HVM) ||\n            boot_cpu_has(X86_FEATURE_IBPB_ENTRY_HVM) ||\n            amd_virt_spec_ctrl ||\n            opt_eager_fpu || opt_md_clear_hvm)       ? \"\"               : \" None\",\n           boot_cpu_has(X86_FEATURE_SC_MSR_HVM)      ? \" MSR_SPEC_CTRL\" : \"\",\n           (boot_cpu_has(X86_FEATURE_SC_MSR_HVM) ||\n            amd_virt_spec_ctrl)                      ? \" MSR_VIRT_SPEC_CTRL\" : \"\",\n           boot_cpu_has(X86_FEATURE_SC_RSB_HVM)      ? \" RSB\"           : \"\",\n           opt_eager_fpu                             ? \" EAGER_FPU\"     : \"\",\n           opt_md_clear_hvm                          ? \" MD_CLEAR\"      : \"\",\n           boot_cpu_has(X86_FEATURE_IBPB_ENTRY_HVM)  ? \" IBPB-entry\"    : \"\");\n\n#endif\n#ifdef CONFIG_PV\n    printk(\"  Support for PV VMs:%s%s%s%s%s%s\\n\",\n           (boot_cpu_has(X86_FEATURE_SC_MSR_PV) ||\n            boot_cpu_has(X86_FEATURE_SC_RSB_PV) ||\n            boot_cpu_has(X86_FEATURE_IBPB_ENTRY_PV) ||\n            opt_eager_fpu || opt_md_clear_pv)        ? \"\"               : \" None\",\n           boot_cpu_has(X86_FEATURE_SC_MSR_PV)       ? \" MSR_SPEC_CTRL\" : \"\",\n           boot_cpu_has(X86_FEATURE_SC_RSB_PV)       ? \" RSB\"           : \"\",\n           opt_eager_fpu                             ? \" EAGER_FPU\"     : \"\",\n           opt_md_clear_pv                           ? \" MD_CLEAR\"      : \"\",\n           boot_cpu_has(X86_FEATURE_IBPB_ENTRY_PV)   ? \" IBPB-entry\"    : \"\");\n\n    printk(\"  XPTI (64-bit PV only): Dom0 %s, DomU %s (with%s PCID)\\n\",\n           opt_xpti_hwdom ? \"enabled\" : \"disabled\",\n           opt_xpti_domu  ? \"enabled\" : \"disabled\",\n           xpti_pcid_enabled() ? \"\" : \"out\");\n\n    printk(\"  PV L1TF shadowing: Dom0 %s, DomU %s\\n\",\n           opt_pv_l1tf_hwdom ? \"enabled\"  : \"disabled\",\n           opt_pv_l1tf_domu  ? \"enabled\"  : \"disabled\");\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -79,7 +79,7 @@\n                \"\\n\");\n \n     /* Settings for Xen's protection, irrespective of guests. */\n-    printk(\"  Xen settings: BTI-Thunk %s, SPEC_CTRL: %s%s%s%s%s, Other:%s%s%s%s%s\\n\",\n+    printk(\"  Xen settings: BTI-Thunk %s, SPEC_CTRL: %s%s%s%s%s, Other:%s%s%s%s%s%s\\n\",\n            thunk == THUNK_NONE      ? \"N/A\" :\n            thunk == THUNK_RETPOLINE ? \"RETPOLINE\" :\n            thunk == THUNK_LFENCE    ? \"LFENCE\" :\n@@ -104,6 +104,7 @@\n            opt_l1d_flush                             ? \" L1D_FLUSH\" : \"\",\n            opt_md_clear_pv || opt_md_clear_hvm ||\n            opt_fb_clear_mmio                         ? \" VERW\"  : \"\",\n+           opt_div_scrub                             ? \" DIV\" : \"\",\n            opt_branch_harden                         ? \" BRANCH_HARDEN\" : \"\");\n \n     /* L1TF diagnostics, printed if vulnerable or PV shadowing is in use. */",
        "diff_line_info": {
            "deleted_lines": [
                "    printk(\"  Xen settings: BTI-Thunk %s, SPEC_CTRL: %s%s%s%s%s, Other:%s%s%s%s%s\\n\","
            ],
            "added_lines": [
                "    printk(\"  Xen settings: BTI-Thunk %s, SPEC_CTRL: %s%s%s%s%s, Other:%s%s%s%s%s%s\\n\",",
                "           opt_div_scrub                             ? \" DIV\" : \"\","
            ]
        }
    },
    {
        "cve_id": "CVE-2020-21710",
        "func_name": "ArtifexSoftware/ghostpdl/epsc_print_page",
        "description": "A divide by zero issue discovered in eps_print_page in gdevepsn.c in Artifex Software GhostScript 9.50 allows remote attackers to cause a denial of service via opening of crafted PDF file.",
        "git_url": "https://github.com/ArtifexSoftware/ghostpdl/commit/4e713293de84b689c4ab358f3e110ea54aa81925",
        "commit_title": "Bug 701843: avoid divide by zero in devices/gdevepsc.c:epsc_print_page().",
        "commit_text": " Fixes:     ./sanbin/gs -dBATCH -dNOPAUSE -dSAFER -r8 -dNOCIE -dFitPage -sOutputFile=tmp -sDEVICE=epsonc  ../bug-701843.pdf",
        "func_before": "static int\nepsc_print_page(gx_device_printer * pdev, gp_file * prn_stream)\n{\n    static int graphics_modes_9[5] = { -1, 0 /*60 */ , 1 /*120 */ , -1, DD + 3  /*240 */\n    };\n    static int graphics_modes_24[7] =\n        { -1, 32 /*60 */ , 33 /*120 */ , 39 /*180 */ ,\n        -1, -1, DD + 40         /*360 */\n    };\n    int y_24pin = pdev->y_pixels_per_inch > 72;\n    int y_mult = (y_24pin ? 3 : 1);\n    int line_size = (pdev->width + 7) >> 3;     /* always mono */\n    int in_size = line_size * (8 * y_mult);\n    int out_size = ((pdev->width + 7) & -8) * y_mult;\n    byte *in;\n    byte *out;\n    int x_dpi = (int)pdev->x_pixels_per_inch;\n\n    char start_graphics;\n    int first_pass;\n    int last_pass;\n    int dots_per_space; \n    int bytes_per_space;\n    int skip = 0, lnum = 0, pass;\n\n    byte *color_in;\n    int color_line_size, color_in_size;\n    int spare_bits;\n    int whole_bits;\n\n    int max_dpi = 60 * (\n            (y_24pin) ?\n            sizeof(graphics_modes_24) / sizeof(graphics_modes_24[0])\n            :\n            sizeof(graphics_modes_9) / sizeof(graphics_modes_9[0])\n            )\n            - 1;\n    if (x_dpi > max_dpi) {\n        return_error(gs_error_rangecheck);\n    }\n    \n    in =\n        (byte *) gs_malloc(pdev->memory, in_size + 1, 1,\n                           \"epsc_print_page(in)\");\n    out =\n        (byte *) gs_malloc(pdev->memory, out_size + 1, 1,\n                           \"epsc_print_page(out)\");\n\n    start_graphics = (char)\n        ((y_24pin ? graphics_modes_24 : graphics_modes_9)[x_dpi / 60]);\n    first_pass = (start_graphics & DD ? 1 : 0);\n    last_pass = first_pass * 2;\n    dots_per_space = x_dpi / 10;    /* pica space = 1/10\" */\n    bytes_per_space = dots_per_space * y_mult;\n\n    /* declare color buffer and related vars */\n    spare_bits = (pdev->width % 8); /* left over bits to go to margin */\n    whole_bits = pdev->width - spare_bits;\n\n    /* Check allocations */\n    if (in == 0 || out == 0) {\n        if (in)\n            gs_free(pdev->memory, (char *)in, in_size + 1, 1,\n                    \"epsc_print_page(in)\");\n        if (out)\n            gs_free(pdev->memory, (char *)out, out_size + 1, 1,\n                    \"epsc_print_page(out)\");\n        return -1;\n    }\n\n    /* Initialize the printer and reset the margins. */\n    gp_fwrite(\"\\033@\\033P\\033l\\000\\033Q\\377\\033U\\001\\r\", 1, 14, prn_stream);\n\n    /* Create color buffer */\n    if (gx_device_has_color(pdev)) {\n        color_line_size = gdev_mem_bytes_per_scan_line((gx_device *) pdev);\n        color_in_size = color_line_size * (8 * y_mult);\n        if ((color_in = (byte *) gs_malloc(pdev->memory, color_in_size + 1, 1,\n                                           \"epsc_print_page(color)\")) == 0) {\n            gs_free(pdev->memory, (char *)in, in_size + 1, 1,\n                    \"epsc_print_page(in)\");\n            gs_free(pdev->memory, (char *)out, out_size + 1, 1,\n                    \"epsc_print_page(out)\");\n            return (-1);\n        }\n    } else {\n        color_in = in;\n        color_in_size = in_size;\n        color_line_size = line_size;\n    }\n\n    /* Print lines of graphics */\n    while (lnum < pdev->height) {\n        int lcnt;\n        byte *nextcolor = NULL; /* position where next color appears */\n        byte *nextmono = NULL;  /* position to map next color */\n\n        /* Copy 1 scan line and test for all zero. */\n        gdev_prn_copy_scan_lines(pdev, lnum, color_in, color_line_size);\n\n        if (color_in[0] == 0 &&\n            !memcmp((char *)color_in, (char *)color_in + 1,\n                    color_line_size - 1)\n            ) {\n            lnum++;\n            skip += 3 / y_mult;\n            continue;\n        }\n\n        /* Vertical tab to the appropriate position. */\n        while (skip > 255) {\n            gp_fputs(\"\\033J\\377\", prn_stream);\n            skip -= 255;\n        }\n        if (skip)\n            gp_fprintf(prn_stream, \"\\033J%c\", skip);\n\n        /* Copy the rest of the scan lines. */\n        lcnt = 1 + gdev_prn_copy_scan_lines(pdev, lnum + 1,\n                                            color_in + color_line_size,\n                                            color_in_size - color_line_size);\n\n        if (lcnt < 8 * y_mult) {\n            memset((char *)(color_in + lcnt * color_line_size), 0,\n                   color_in_size - lcnt * color_line_size);\n            if (gx_device_has_color(pdev))      /* clear the work buffer */\n                memset((char *)(in + lcnt * line_size), 0,\n                       in_size - lcnt * line_size);\n        }\n\n        /*\n        ** We need to create a normal epson scan line from our color scan line\n        ** We do this by setting a bit in the \"in\" buffer if the pixel byte is set\n        ** to any color.  We then search for any more pixels of that color, setting\n        ** \"in\" accordingly.  If any other color is found, we save it for the next\n        ** pass.  There may be up to 7 passes.\n        ** In the future, we should make the passes so as to maximize the\n        ** life of the color ribbon (i.e. go lightest to darkest).\n        */\n        do {\n            byte *inp = in;\n            byte *in_end = in + line_size;\n            byte *out_end = out;\n            byte *out_blk;\n            register byte *outp;\n\n            if (gx_device_has_color(pdev)) {\n                register int i, j;\n                register byte *outbuf, *realbuf;\n                byte current_color;\n                int end_next_bits = whole_bits;\n                int lastbits;\n\n                /* Move to the point in the scanline that has a new color */\n                if (nextcolor) {\n                    realbuf = nextcolor;\n                    outbuf = nextmono;\n                    memset((char *)in, 0, (nextmono - in));\n                    i = nextcolor - color_in;\n                    nextcolor = NULL;\n                    end_next_bits = (i / color_line_size) * color_line_size\n                        + whole_bits;\n                } else {\n                    i = 0;\n                    realbuf = color_in;\n                    outbuf = in;\n                    nextcolor = NULL;\n                }\n                /* move thru the color buffer, turning on the appropriate\n                ** bit in the \"mono\" buffer\", setting pointers to the next\n                ** color and changing the color output of the epson\n                */\n                for (current_color = 0; i <= color_in_size && outbuf < in + in_size; outbuf++) {\n                    /* Remember, line_size is rounded up to next whole byte\n                    ** whereas color_line_size is the proper length\n                    ** We only want to set the proper bits in the last line_size byte.\n                    */\n                    if (spare_bits && i == end_next_bits) {\n                        end_next_bits = whole_bits + i + spare_bits;\n                        lastbits = 8 - spare_bits;\n                    } else\n                        lastbits = 0;\n\n                    for (*outbuf = 0, j = 8;\n                         --j >= lastbits && i <= color_in_size;\n                         realbuf++, i++) {\n                        if (*realbuf) {\n                            if (current_color > 0) {\n                                if (*realbuf == current_color) {\n                                    *outbuf |= 1 << j;\n                                    *realbuf = 0;       /* throw this byte away */\n                                }\n                                /* save this location for next pass */\n                                else if (nextcolor == NULL) {\n                                    nextcolor = realbuf - (7 - j);\n                                    nextmono = outbuf;\n                                }\n                            } else {\n                                *outbuf |= 1 << j;\n                                current_color = *realbuf;       /* set color */\n                                *realbuf = 0;\n                            }\n                        }\n                    }\n                }\n                *outbuf = 0;    /* zero the end, for safe keeping */\n               /* Change color on the EPSON, current_color must be set\n               ** but lets check anyway\n               */\n                if (current_color)\n                    gp_fprintf(prn_stream, \"\\033r%c\", current_color ^ 7);\n            }\n\n            /* We have to 'transpose' blocks of 8 pixels x 8 lines, */\n            /* because that's how the printer wants the data. */\n            /* If we are in a 24-pin mode, we have to transpose */\n            /* groups of 3 lines at a time. */\n\n            if (y_24pin) {\n                for (; inp < in_end; inp++, out_end += 24) {\n                    gdev_prn_transpose_8x8(inp, line_size, out_end, 3);\n                    gdev_prn_transpose_8x8(inp + line_size * 8, line_size,\n                                           out_end + 1, 3);\n                    gdev_prn_transpose_8x8(inp + line_size * 16, line_size,\n                                           out_end + 2, 3);\n                }\n                /* Remove trailing 0s. */\n                while (out_end > out && out_end[-1] == 0 &&\n                       out_end[-2] == 0 && out_end[-3] == 0)\n                    out_end -= 3;\n            } else {\n                for (; inp < in_end; inp++, out_end += 8) {\n                    gdev_prn_transpose_8x8(inp, line_size, out_end, 1);\n                }\n                /* Remove trailing 0s. */\n                while (out_end > out && out_end[-1] == 0)\n                    out_end--;\n            }\n\n            for (pass = first_pass; pass <= last_pass; pass++) {\n                for (out_blk = outp = out; outp < out_end;) {   /* Skip a run of leading 0s. */\n                    /* At least 10 are needed to make tabbing worth it. */\n                    /* We do everything by 3's to avoid having to make */\n                    /* different cases for 9- and 24-pin. */\n\n                    if (*outp == 0 && outp + 12 <= out_end &&\n                        outp[1] == 0 && outp[2] == 0 &&\n                        (outp[3] | outp[4] | outp[5]) == 0 &&\n                        (outp[6] | outp[7] | outp[8]) == 0 &&\n                        (outp[9] | outp[10] | outp[11]) == 0) {\n                        byte *zp = outp;\n                        int tpos;\n                        byte *newp;\n\n                        outp += 12;\n                        while (outp + 3 <= out_end && *outp == 0 &&\n                               outp[1] == 0 && outp[2] == 0)\n                            outp += 3;\n                        tpos = (outp - out) / bytes_per_space;\n                        newp = out + tpos * bytes_per_space;\n                        if (newp > zp + 10) {   /* Output preceding bit data. */\n                            if (zp > out_blk)\n                                /* only false at */\n                                /* beginning of line */\n                                epsc_output_run(out_blk, (int)(zp - out_blk),\n                                                y_mult, start_graphics,\n                                                prn_stream, pass);\n                            /* Tab over to the appropriate position. */\n                            gp_fprintf(prn_stream, \"\\033D%c%c\\t\", tpos, 0);\n                            out_blk = outp = newp;\n                        }\n                    } else\n                        outp += y_mult;\n                }\n                if (outp > out_blk)\n                    epsc_output_run(out_blk, (int)(outp - out_blk),\n                                    y_mult, start_graphics, prn_stream, pass);\n\n                gp_fputc('\\r', prn_stream);\n            }\n        } while (nextcolor);\n        skip = 24;\n        lnum += 8 * y_mult;\n    }\n\n    /* Eject the page and reinitialize the printer */\n    gp_fputs(\"\\f\\033@\", prn_stream);\n\n    gs_free(pdev->memory, (char *)out, out_size + 1, 1,\n            \"epsc_print_page(out)\");\n    gs_free(pdev->memory, (char *)in, in_size + 1, 1, \"epsc_print_page(in)\");\n    if (gx_device_has_color(pdev))\n        gs_free(pdev->memory, (char *)color_in, color_in_size + 1, 1,\n                \"epsc_print_page(rin)\");\n    return 0;\n}",
        "func": "static int\nepsc_print_page(gx_device_printer * pdev, gp_file * prn_stream)\n{\n    static int graphics_modes_9[5] = { -1, 0 /*60 */ , 1 /*120 */ , -1, DD + 3  /*240 */\n    };\n    static int graphics_modes_24[7] =\n        { -1, 32 /*60 */ , 33 /*120 */ , 39 /*180 */ ,\n        -1, -1, DD + 40         /*360 */\n    };\n    int y_24pin = pdev->y_pixels_per_inch > 72;\n    int y_mult = (y_24pin ? 3 : 1);\n    int line_size = (pdev->width + 7) >> 3;     /* always mono */\n    int in_size = line_size * (8 * y_mult);\n    int out_size = ((pdev->width + 7) & -8) * y_mult;\n    byte *in;\n    byte *out;\n    int x_dpi = (int)pdev->x_pixels_per_inch;\n\n    char start_graphics;\n    int first_pass;\n    int last_pass;\n    int dots_per_space; \n    int bytes_per_space;\n    int skip = 0, lnum = 0, pass;\n\n    byte *color_in;\n    int color_line_size, color_in_size;\n    int spare_bits;\n    int whole_bits;\n\n    int max_dpi = 60 * (\n            (y_24pin) ?\n            sizeof(graphics_modes_24) / sizeof(graphics_modes_24[0])\n            :\n            sizeof(graphics_modes_9) / sizeof(graphics_modes_9[0])\n            )\n            - 1;\n    if (x_dpi > max_dpi) {\n        return_error(gs_error_rangecheck);\n    }\n    \n    start_graphics = (char)\n        ((y_24pin ? graphics_modes_24 : graphics_modes_9)[x_dpi / 60]);\n    first_pass = (start_graphics & DD ? 1 : 0);\n    last_pass = first_pass * 2;\n    dots_per_space = x_dpi / 10;    /* pica space = 1/10\" */\n    bytes_per_space = dots_per_space * y_mult;\n    if (bytes_per_space == 0) {\n        /* This avoids divide by zero later on, bug 701843. */\n        return_error(gs_error_rangecheck);\n    }\n\n    in =\n        (byte *) gs_malloc(pdev->memory, in_size + 1, 1,\n                           \"epsc_print_page(in)\");\n    out =\n        (byte *) gs_malloc(pdev->memory, out_size + 1, 1,\n                           \"epsc_print_page(out)\");\n\n    /* declare color buffer and related vars */\n    spare_bits = (pdev->width % 8); /* left over bits to go to margin */\n    whole_bits = pdev->width - spare_bits;\n\n    /* Check allocations */\n    if (in == 0 || out == 0) {\n        if (in)\n            gs_free(pdev->memory, (char *)in, in_size + 1, 1,\n                    \"epsc_print_page(in)\");\n        if (out)\n            gs_free(pdev->memory, (char *)out, out_size + 1, 1,\n                    \"epsc_print_page(out)\");\n        return -1;\n    }\n\n    /* Initialize the printer and reset the margins. */\n    gp_fwrite(\"\\033@\\033P\\033l\\000\\033Q\\377\\033U\\001\\r\", 1, 14, prn_stream);\n\n    /* Create color buffer */\n    if (gx_device_has_color(pdev)) {\n        color_line_size = gdev_mem_bytes_per_scan_line((gx_device *) pdev);\n        color_in_size = color_line_size * (8 * y_mult);\n        if ((color_in = (byte *) gs_malloc(pdev->memory, color_in_size + 1, 1,\n                                           \"epsc_print_page(color)\")) == 0) {\n            gs_free(pdev->memory, (char *)in, in_size + 1, 1,\n                    \"epsc_print_page(in)\");\n            gs_free(pdev->memory, (char *)out, out_size + 1, 1,\n                    \"epsc_print_page(out)\");\n            return (-1);\n        }\n    } else {\n        color_in = in;\n        color_in_size = in_size;\n        color_line_size = line_size;\n    }\n\n    /* Print lines of graphics */\n    while (lnum < pdev->height) {\n        int lcnt;\n        byte *nextcolor = NULL; /* position where next color appears */\n        byte *nextmono = NULL;  /* position to map next color */\n\n        /* Copy 1 scan line and test for all zero. */\n        gdev_prn_copy_scan_lines(pdev, lnum, color_in, color_line_size);\n\n        if (color_in[0] == 0 &&\n            !memcmp((char *)color_in, (char *)color_in + 1,\n                    color_line_size - 1)\n            ) {\n            lnum++;\n            skip += 3 / y_mult;\n            continue;\n        }\n\n        /* Vertical tab to the appropriate position. */\n        while (skip > 255) {\n            gp_fputs(\"\\033J\\377\", prn_stream);\n            skip -= 255;\n        }\n        if (skip)\n            gp_fprintf(prn_stream, \"\\033J%c\", skip);\n\n        /* Copy the rest of the scan lines. */\n        lcnt = 1 + gdev_prn_copy_scan_lines(pdev, lnum + 1,\n                                            color_in + color_line_size,\n                                            color_in_size - color_line_size);\n\n        if (lcnt < 8 * y_mult) {\n            memset((char *)(color_in + lcnt * color_line_size), 0,\n                   color_in_size - lcnt * color_line_size);\n            if (gx_device_has_color(pdev))      /* clear the work buffer */\n                memset((char *)(in + lcnt * line_size), 0,\n                       in_size - lcnt * line_size);\n        }\n\n        /*\n        ** We need to create a normal epson scan line from our color scan line\n        ** We do this by setting a bit in the \"in\" buffer if the pixel byte is set\n        ** to any color.  We then search for any more pixels of that color, setting\n        ** \"in\" accordingly.  If any other color is found, we save it for the next\n        ** pass.  There may be up to 7 passes.\n        ** In the future, we should make the passes so as to maximize the\n        ** life of the color ribbon (i.e. go lightest to darkest).\n        */\n        do {\n            byte *inp = in;\n            byte *in_end = in + line_size;\n            byte *out_end = out;\n            byte *out_blk;\n            register byte *outp;\n\n            if (gx_device_has_color(pdev)) {\n                register int i, j;\n                register byte *outbuf, *realbuf;\n                byte current_color;\n                int end_next_bits = whole_bits;\n                int lastbits;\n\n                /* Move to the point in the scanline that has a new color */\n                if (nextcolor) {\n                    realbuf = nextcolor;\n                    outbuf = nextmono;\n                    memset((char *)in, 0, (nextmono - in));\n                    i = nextcolor - color_in;\n                    nextcolor = NULL;\n                    end_next_bits = (i / color_line_size) * color_line_size\n                        + whole_bits;\n                } else {\n                    i = 0;\n                    realbuf = color_in;\n                    outbuf = in;\n                    nextcolor = NULL;\n                }\n                /* move thru the color buffer, turning on the appropriate\n                ** bit in the \"mono\" buffer\", setting pointers to the next\n                ** color and changing the color output of the epson\n                */\n                for (current_color = 0; i <= color_in_size && outbuf < in + in_size; outbuf++) {\n                    /* Remember, line_size is rounded up to next whole byte\n                    ** whereas color_line_size is the proper length\n                    ** We only want to set the proper bits in the last line_size byte.\n                    */\n                    if (spare_bits && i == end_next_bits) {\n                        end_next_bits = whole_bits + i + spare_bits;\n                        lastbits = 8 - spare_bits;\n                    } else\n                        lastbits = 0;\n\n                    for (*outbuf = 0, j = 8;\n                         --j >= lastbits && i <= color_in_size;\n                         realbuf++, i++) {\n                        if (*realbuf) {\n                            if (current_color > 0) {\n                                if (*realbuf == current_color) {\n                                    *outbuf |= 1 << j;\n                                    *realbuf = 0;       /* throw this byte away */\n                                }\n                                /* save this location for next pass */\n                                else if (nextcolor == NULL) {\n                                    nextcolor = realbuf - (7 - j);\n                                    nextmono = outbuf;\n                                }\n                            } else {\n                                *outbuf |= 1 << j;\n                                current_color = *realbuf;       /* set color */\n                                *realbuf = 0;\n                            }\n                        }\n                    }\n                }\n                *outbuf = 0;    /* zero the end, for safe keeping */\n               /* Change color on the EPSON, current_color must be set\n               ** but lets check anyway\n               */\n                if (current_color)\n                    gp_fprintf(prn_stream, \"\\033r%c\", current_color ^ 7);\n            }\n\n            /* We have to 'transpose' blocks of 8 pixels x 8 lines, */\n            /* because that's how the printer wants the data. */\n            /* If we are in a 24-pin mode, we have to transpose */\n            /* groups of 3 lines at a time. */\n\n            if (y_24pin) {\n                for (; inp < in_end; inp++, out_end += 24) {\n                    gdev_prn_transpose_8x8(inp, line_size, out_end, 3);\n                    gdev_prn_transpose_8x8(inp + line_size * 8, line_size,\n                                           out_end + 1, 3);\n                    gdev_prn_transpose_8x8(inp + line_size * 16, line_size,\n                                           out_end + 2, 3);\n                }\n                /* Remove trailing 0s. */\n                while (out_end > out && out_end[-1] == 0 &&\n                       out_end[-2] == 0 && out_end[-3] == 0)\n                    out_end -= 3;\n            } else {\n                for (; inp < in_end; inp++, out_end += 8) {\n                    gdev_prn_transpose_8x8(inp, line_size, out_end, 1);\n                }\n                /* Remove trailing 0s. */\n                while (out_end > out && out_end[-1] == 0)\n                    out_end--;\n            }\n\n            for (pass = first_pass; pass <= last_pass; pass++) {\n                for (out_blk = outp = out; outp < out_end;) {   /* Skip a run of leading 0s. */\n                    /* At least 10 are needed to make tabbing worth it. */\n                    /* We do everything by 3's to avoid having to make */\n                    /* different cases for 9- and 24-pin. */\n\n                    if (*outp == 0 && outp + 12 <= out_end &&\n                        outp[1] == 0 && outp[2] == 0 &&\n                        (outp[3] | outp[4] | outp[5]) == 0 &&\n                        (outp[6] | outp[7] | outp[8]) == 0 &&\n                        (outp[9] | outp[10] | outp[11]) == 0) {\n                        byte *zp = outp;\n                        int tpos;\n                        byte *newp;\n\n                        outp += 12;\n                        while (outp + 3 <= out_end && *outp == 0 &&\n                               outp[1] == 0 && outp[2] == 0)\n                            outp += 3;\n                        tpos = (outp - out) / bytes_per_space;\n                        newp = out + tpos * bytes_per_space;\n                        if (newp > zp + 10) {   /* Output preceding bit data. */\n                            if (zp > out_blk)\n                                /* only false at */\n                                /* beginning of line */\n                                epsc_output_run(out_blk, (int)(zp - out_blk),\n                                                y_mult, start_graphics,\n                                                prn_stream, pass);\n                            /* Tab over to the appropriate position. */\n                            gp_fprintf(prn_stream, \"\\033D%c%c\\t\", tpos, 0);\n                            out_blk = outp = newp;\n                        }\n                    } else\n                        outp += y_mult;\n                }\n                if (outp > out_blk)\n                    epsc_output_run(out_blk, (int)(outp - out_blk),\n                                    y_mult, start_graphics, prn_stream, pass);\n\n                gp_fputc('\\r', prn_stream);\n            }\n        } while (nextcolor);\n        skip = 24;\n        lnum += 8 * y_mult;\n    }\n\n    /* Eject the page and reinitialize the printer */\n    gp_fputs(\"\\f\\033@\", prn_stream);\n\n    gs_free(pdev->memory, (char *)out, out_size + 1, 1,\n            \"epsc_print_page(out)\");\n    gs_free(pdev->memory, (char *)in, in_size + 1, 1, \"epsc_print_page(in)\");\n    if (gx_device_has_color(pdev))\n        gs_free(pdev->memory, (char *)color_in, color_in_size + 1, 1,\n                \"epsc_print_page(rin)\");\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -39,19 +39,23 @@\n         return_error(gs_error_rangecheck);\n     }\n     \n+    start_graphics = (char)\n+        ((y_24pin ? graphics_modes_24 : graphics_modes_9)[x_dpi / 60]);\n+    first_pass = (start_graphics & DD ? 1 : 0);\n+    last_pass = first_pass * 2;\n+    dots_per_space = x_dpi / 10;    /* pica space = 1/10\" */\n+    bytes_per_space = dots_per_space * y_mult;\n+    if (bytes_per_space == 0) {\n+        /* This avoids divide by zero later on, bug 701843. */\n+        return_error(gs_error_rangecheck);\n+    }\n+\n     in =\n         (byte *) gs_malloc(pdev->memory, in_size + 1, 1,\n                            \"epsc_print_page(in)\");\n     out =\n         (byte *) gs_malloc(pdev->memory, out_size + 1, 1,\n                            \"epsc_print_page(out)\");\n-\n-    start_graphics = (char)\n-        ((y_24pin ? graphics_modes_24 : graphics_modes_9)[x_dpi / 60]);\n-    first_pass = (start_graphics & DD ? 1 : 0);\n-    last_pass = first_pass * 2;\n-    dots_per_space = x_dpi / 10;    /* pica space = 1/10\" */\n-    bytes_per_space = dots_per_space * y_mult;\n \n     /* declare color buffer and related vars */\n     spare_bits = (pdev->width % 8); /* left over bits to go to margin */",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    start_graphics = (char)",
                "        ((y_24pin ? graphics_modes_24 : graphics_modes_9)[x_dpi / 60]);",
                "    first_pass = (start_graphics & DD ? 1 : 0);",
                "    last_pass = first_pass * 2;",
                "    dots_per_space = x_dpi / 10;    /* pica space = 1/10\" */",
                "    bytes_per_space = dots_per_space * y_mult;"
            ],
            "added_lines": [
                "    start_graphics = (char)",
                "        ((y_24pin ? graphics_modes_24 : graphics_modes_9)[x_dpi / 60]);",
                "    first_pass = (start_graphics & DD ? 1 : 0);",
                "    last_pass = first_pass * 2;",
                "    dots_per_space = x_dpi / 10;    /* pica space = 1/10\" */",
                "    bytes_per_space = dots_per_space * y_mult;",
                "    if (bytes_per_space == 0) {",
                "        /* This avoids divide by zero later on, bug 701843. */",
                "        return_error(gs_error_rangecheck);",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2021-40211",
        "func_name": "ImageMagick/ReadEnhMetaFile",
        "description": "An issue was discovered with ImageMagick 7.1.0-4 via Division by zero in function ReadEnhMetaFile of coders/emf.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/e33dfe3e9c860d804db15707552cee246f0b7354",
        "commit_title": "fix Division by zero in ReadEnhMetaFile() of coders/emf.c",
        "commit_text": "",
        "func_before": "static HENHMETAFILE ReadEnhMetaFile(const char *path,ssize_t *width,\n  ssize_t *height)\n{\n#pragma pack( push, 2 )\n  typedef struct\n  {\n    DWORD dwKey;\n    WORD hmf;\n    SMALL_RECT bbox;\n    WORD wInch;\n    DWORD dwReserved;\n    WORD wCheckSum;\n  } APMHEADER, *PAPMHEADER;\n#pragma pack( pop )\n\n  DWORD\n    dwSize;\n\n  ENHMETAHEADER\n    emfh;\n\n  HANDLE\n    hFile;\n\n  HDC\n    hDC;\n\n  HENHMETAFILE\n    hTemp;\n\n  LPBYTE\n    pBits;\n\n  METAFILEPICT\n    mp;\n\n  HMETAFILE\n    hOld;\n\n  *width=512;\n  *height=512;\n  hTemp=GetEnhMetaFile(path);\n#if defined(MAGICKCORE_HAVE__WFOPEN)\n  if (hTemp == (HENHMETAFILE) NULL)\n    {\n      wchar_t\n        *unicode_path;\n\n      unicode_path=ConvertUTF8ToUTF16((const unsigned char *) path);\n      if (unicode_path != (wchar_t *) NULL)\n        {\n          hTemp=GetEnhMetaFileW(unicode_path);\n          unicode_path=(wchar_t *) RelinquishMagickMemory(unicode_path);\n        }\n    }\n#endif\n  if (hTemp != (HENHMETAFILE) NULL)\n    {\n      /*\n        Enhanced metafile.\n      */\n      GetEnhMetaFileHeader(hTemp,sizeof(ENHMETAHEADER),&emfh);\n      *width=emfh.rclFrame.right-emfh.rclFrame.left;\n      *height=emfh.rclFrame.bottom-emfh.rclFrame.top;\n      return(hTemp);\n    }\n  hOld=GetMetaFile(path);\n  if (hOld != (HMETAFILE) NULL)\n    {\n      /*\n        16bit windows metafile.\n      */\n      dwSize=GetMetaFileBitsEx(hOld,0,NULL);\n      if (dwSize == 0)\n        {\n          DeleteMetaFile(hOld);\n          return((HENHMETAFILE) NULL);\n        }\n      pBits=(LPBYTE) AcquireQuantumMemory(dwSize,sizeof(*pBits));\n      if (pBits == (LPBYTE) NULL)\n        {\n          DeleteMetaFile(hOld);\n          return((HENHMETAFILE) NULL);\n        }\n      if (GetMetaFileBitsEx(hOld,dwSize,pBits) == 0)\n        {\n          pBits=(BYTE *) DestroyString((char *) pBits);\n          DeleteMetaFile(hOld);\n          return((HENHMETAFILE) NULL);\n        }\n      /*\n        Make an enhanced metafile from the windows metafile.\n      */\n      mp.mm=MM_ANISOTROPIC;\n      mp.xExt=1000;\n      mp.yExt=1000;\n      mp.hMF=NULL;\n      hDC=GetDC(NULL);\n      hTemp=SetWinMetaFileBits(dwSize,pBits,hDC,&mp);\n      ReleaseDC(NULL,hDC);\n      DeleteMetaFile(hOld);\n      pBits=(BYTE *) DestroyString((char *) pBits);\n      GetEnhMetaFileHeader(hTemp,sizeof(ENHMETAHEADER),&emfh);\n      *width=emfh.rclFrame.right-emfh.rclFrame.left;\n      *height=emfh.rclFrame.bottom-emfh.rclFrame.top;\n      return(hTemp);\n    }\n  /*\n    Aldus Placeable metafile.\n  */\n  hFile=CreateFile(path,GENERIC_READ,0,NULL,OPEN_EXISTING,FILE_ATTRIBUTE_NORMAL,\n    NULL);\n  if (hFile == INVALID_HANDLE_VALUE)\n    return(NULL);\n  dwSize=GetFileSize(hFile,NULL);\n  pBits=(LPBYTE) AcquireQuantumMemory(dwSize,sizeof(*pBits));\n  if (pBits == (LPBYTE) NULL)\n    {\n      CloseHandle(hFile);\n      return((HENHMETAFILE) NULL);\n    }\n  ReadFile(hFile,pBits,dwSize,&dwSize,NULL);\n  CloseHandle(hFile);\n  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l)\n    {\n      pBits=(BYTE *) DestroyString((char *) pBits);\n      return((HENHMETAFILE) NULL);\n    }\n  /*\n    Make an enhanced metafile from the placable metafile.\n  */\n  mp.mm=MM_ANISOTROPIC;\n  mp.xExt=((PAPMHEADER) pBits)->bbox.Right-((PAPMHEADER) pBits)->bbox.Left;\n  *width=mp.xExt;\n  mp.xExt=(mp.xExt*2540l)/(DWORD) (((PAPMHEADER) pBits)->wInch);\n  mp.yExt=((PAPMHEADER)pBits)->bbox.Bottom-((PAPMHEADER) pBits)->bbox.Top;\n  *height=mp.yExt;\n  mp.yExt=(mp.yExt*2540l)/(DWORD) (((PAPMHEADER) pBits)->wInch);\n  mp.hMF=NULL;\n  hDC=GetDC(NULL);\n  hTemp=SetWinMetaFileBits(dwSize,&(pBits[sizeof(APMHEADER)]),hDC,&mp);\n  ReleaseDC(NULL,hDC);\n  pBits=(BYTE *) DestroyString((char *) pBits);\n  return(hTemp);\n}",
        "func": "static HENHMETAFILE ReadEnhMetaFile(const char *path,ssize_t *width,\n  ssize_t *height)\n{\n#pragma pack( push, 2 )\n  typedef struct\n  {\n    DWORD dwKey;\n    WORD hmf;\n    SMALL_RECT bbox;\n    WORD wInch;\n    DWORD dwReserved;\n    WORD wCheckSum;\n  } APMHEADER, *PAPMHEADER;\n#pragma pack( pop )\n\n  DWORD\n    dwSize;\n\n  ENHMETAHEADER\n    emfh;\n\n  HANDLE\n    hFile;\n\n  HDC\n    hDC;\n\n  HENHMETAFILE\n    hTemp;\n\n  LPBYTE\n    pBits;\n\n  METAFILEPICT\n    mp;\n\n  HMETAFILE\n    hOld;\n\n  *width=512;\n  *height=512;\n  hTemp=GetEnhMetaFile(path);\n#if defined(MAGICKCORE_HAVE__WFOPEN)\n  if (hTemp == (HENHMETAFILE) NULL)\n    {\n      wchar_t\n        *unicode_path;\n\n      unicode_path=ConvertUTF8ToUTF16((const unsigned char *) path);\n      if (unicode_path != (wchar_t *) NULL)\n        {\n          hTemp=GetEnhMetaFileW(unicode_path);\n          unicode_path=(wchar_t *) RelinquishMagickMemory(unicode_path);\n        }\n    }\n#endif\n  if (hTemp != (HENHMETAFILE) NULL)\n    {\n      /*\n        Enhanced metafile.\n      */\n      GetEnhMetaFileHeader(hTemp,sizeof(ENHMETAHEADER),&emfh);\n      *width=emfh.rclFrame.right-emfh.rclFrame.left;\n      *height=emfh.rclFrame.bottom-emfh.rclFrame.top;\n      return(hTemp);\n    }\n  hOld=GetMetaFile(path);\n  if (hOld != (HMETAFILE) NULL)\n    {\n      /*\n        16bit windows metafile.\n      */\n      dwSize=GetMetaFileBitsEx(hOld,0,NULL);\n      if (dwSize == 0)\n        {\n          DeleteMetaFile(hOld);\n          return((HENHMETAFILE) NULL);\n        }\n      pBits=(LPBYTE) AcquireQuantumMemory(dwSize,sizeof(*pBits));\n      if (pBits == (LPBYTE) NULL)\n        {\n          DeleteMetaFile(hOld);\n          return((HENHMETAFILE) NULL);\n        }\n      if (GetMetaFileBitsEx(hOld,dwSize,pBits) == 0)\n        {\n          pBits=(BYTE *) DestroyString((char *) pBits);\n          DeleteMetaFile(hOld);\n          return((HENHMETAFILE) NULL);\n        }\n      /*\n        Make an enhanced metafile from the windows metafile.\n      */\n      mp.mm=MM_ANISOTROPIC;\n      mp.xExt=1000;\n      mp.yExt=1000;\n      mp.hMF=NULL;\n      hDC=GetDC(NULL);\n      hTemp=SetWinMetaFileBits(dwSize,pBits,hDC,&mp);\n      ReleaseDC(NULL,hDC);\n      DeleteMetaFile(hOld);\n      pBits=(BYTE *) DestroyString((char *) pBits);\n      GetEnhMetaFileHeader(hTemp,sizeof(ENHMETAHEADER),&emfh);\n      *width=emfh.rclFrame.right-emfh.rclFrame.left;\n      *height=emfh.rclFrame.bottom-emfh.rclFrame.top;\n      return(hTemp);\n    }\n  /*\n    Aldus Placeable metafile.\n  */\n  hFile=CreateFile(path,GENERIC_READ,0,NULL,OPEN_EXISTING,FILE_ATTRIBUTE_NORMAL,\n    NULL);\n  if (hFile == INVALID_HANDLE_VALUE)\n    return(NULL);\n  dwSize=GetFileSize(hFile,NULL);\n  pBits=(LPBYTE) AcquireQuantumMemory(dwSize,sizeof(*pBits));\n  if (pBits == (LPBYTE) NULL)\n    {\n      CloseHandle(hFile);\n      return((HENHMETAFILE) NULL);\n    }\n  ReadFile(hFile,pBits,dwSize,&dwSize,NULL);\n  CloseHandle(hFile);\n  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l || ((PAPMHEADER) pBits)->wInch == 0)\n    {\n      pBits=(BYTE *) DestroyString((char *) pBits);\n      return((HENHMETAFILE) NULL);\n    }\n  /*\n    Make an enhanced metafile from the placable metafile.\n  */\n  mp.mm=MM_ANISOTROPIC;\n  mp.xExt=((PAPMHEADER) pBits)->bbox.Right-((PAPMHEADER) pBits)->bbox.Left;\n  *width=mp.xExt;\n  mp.xExt=(mp.xExt*2540l)/(DWORD) (((PAPMHEADER) pBits)->wInch);\n  mp.yExt=((PAPMHEADER)pBits)->bbox.Bottom-((PAPMHEADER) pBits)->bbox.Top;\n  *height=mp.yExt;\n  mp.yExt=(mp.yExt*2540l)/(DWORD) (((PAPMHEADER) pBits)->wInch);\n  mp.hMF=NULL;\n  hDC=GetDC(NULL);\n  hTemp=SetWinMetaFileBits(dwSize,&(pBits[sizeof(APMHEADER)]),hDC,&mp);\n  ReleaseDC(NULL,hDC);\n  pBits=(BYTE *) DestroyString((char *) pBits);\n  return(hTemp);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -121,7 +121,7 @@\n     }\n   ReadFile(hFile,pBits,dwSize,&dwSize,NULL);\n   CloseHandle(hFile);\n-  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l)\n+  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l || ((PAPMHEADER) pBits)->wInch == 0)\n     {\n       pBits=(BYTE *) DestroyString((char *) pBits);\n       return((HENHMETAFILE) NULL);",
        "diff_line_info": {
            "deleted_lines": [
                "  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l)"
            ],
            "added_lines": [
                "  if (((PAPMHEADER) pBits)->dwKey != 0x9ac6cdd7l || ((PAPMHEADER) pBits)->wInch == 0)"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-40211",
        "func_name": "ImageMagick/XMenuWidget",
        "description": "An issue was discovered with ImageMagick 7.1.0-4 via Division by zero in function ReadEnhMetaFile of coders/emf.c.",
        "git_url": "https://github.com/ImageMagick/ImageMagick/commit/784d270663061bbf472b500215915c282b131ae0",
        "commit_title": "fix Division by zero in XMenuWidget() of MagickCore/widget.c",
        "commit_text": "",
        "func_before": "MagickPrivate int XMenuWidget(Display *display,XWindows *windows,\n  const char *title,const char *const *selections,char *item)\n{\n  Cursor\n    cursor;\n\n  int\n    id,\n    x,\n    y;\n\n  unsigned int\n    height,\n    number_selections,\n    title_height,\n    top_offset,\n    width;\n\n  size_t\n    state;\n\n  XEvent\n    event;\n\n  XFontStruct\n    *font_info;\n\n  XSetWindowAttributes\n    window_attributes;\n\n  XWidgetInfo\n    highlight_info,\n    menu_info,\n    selection_info;\n\n  XWindowChanges\n    window_changes;\n\n  /*\n    Determine Menu widget attributes.\n  */\n  assert(display != (Display *) NULL);\n  assert(windows != (XWindows *) NULL);\n  assert(title != (char *) NULL);\n  assert(selections != (const char **) NULL);\n  assert(item != (char *) NULL);\n  (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",title);\n  font_info=windows->widget.font_info;\n  windows->widget.width=submenu_info.active == 0 ?\n    WidgetTextWidth(font_info,(char *) title) : 0;\n  for (id=0; selections[id] != (char *) NULL; id++)\n  {\n    width=WidgetTextWidth(font_info,(char *) selections[id]);\n    if (width > windows->widget.width)\n      windows->widget.width=width;\n  }\n  number_selections=(unsigned int) id;\n  XGetWidgetInfo((char *) NULL,&menu_info);\n  title_height=(unsigned int) (submenu_info.active == 0 ?\n    (3*(font_info->descent+font_info->ascent) >> 1)+5 : 2);\n  width=WidgetTextWidth(font_info,(char *) title);\n  height=(unsigned int) ((3*(font_info->ascent+font_info->descent)) >> 1);\n  /*\n    Position Menu widget.\n  */\n  windows->widget.width+=QuantumMargin+(menu_info.bevel_width << 1);\n  top_offset=title_height+menu_info.bevel_width-1;\n  windows->widget.height=top_offset+number_selections*height+4;\n  windows->widget.min_width=windows->widget.width;\n  windows->widget.min_height=windows->widget.height;\n  XQueryPosition(display,windows->widget.root,&x,&y);\n  windows->widget.x=x-(QuantumMargin >> 1);\n  if (submenu_info.active != 0)\n    {\n      windows->widget.x=\n        windows->command.x+windows->command.width-QuantumMargin;\n      toggle_info.raised=MagickTrue;\n      XDrawTriangleEast(display,&windows->command,&toggle_info);\n    }\n  windows->widget.y=submenu_info.active == 0 ? y-(int)\n    ((3*title_height) >> 2) : y;\n  if (submenu_info.active != 0)\n    windows->widget.y=windows->command.y+submenu_info.y;\n  XConstrainWindowPosition(display,&windows->widget);\n  /*\n    Map Menu widget.\n  */\n  window_attributes.override_redirect=MagickTrue;\n  (void) XChangeWindowAttributes(display,windows->widget.id,\n    (size_t) CWOverrideRedirect,&window_attributes);\n  window_changes.width=(int) windows->widget.width;\n  window_changes.height=(int) windows->widget.height;\n  window_changes.x=windows->widget.x;\n  window_changes.y=windows->widget.y;\n  (void) XReconfigureWMWindow(display,windows->widget.id,windows->widget.screen,\n    (unsigned int) (CWWidth | CWHeight | CWX | CWY),&window_changes);\n  (void) XMapRaised(display,windows->widget.id);\n  windows->widget.mapped=MagickFalse;\n  /*\n    Respond to X events.\n  */\n  selection_info.height=height;\n  cursor=XCreateFontCursor(display,XC_right_ptr);\n  (void) XCheckDefineCursor(display,windows->image.id,cursor);\n  (void) XCheckDefineCursor(display,windows->command.id,cursor);\n  (void) XCheckDefineCursor(display,windows->widget.id,cursor);\n  state=UpdateConfigurationState;\n  do\n  {\n    if (state & UpdateConfigurationState)\n      {\n        /*\n          Initialize selection information.\n        */\n        XGetWidgetInfo((char *) NULL,&menu_info);\n        menu_info.bevel_width--;\n        menu_info.width=windows->widget.width-((menu_info.bevel_width) << 1);\n        menu_info.height=windows->widget.height-((menu_info.bevel_width) << 1);\n        menu_info.x=(int) menu_info.bevel_width;\n        menu_info.y=(int) menu_info.bevel_width;\n        XGetWidgetInfo((char *) NULL,&selection_info);\n        selection_info.center=MagickFalse;\n        selection_info.width=menu_info.width;\n        selection_info.height=height;\n        selection_info.x=menu_info.x;\n        highlight_info=selection_info;\n        highlight_info.bevel_width--;\n        highlight_info.width-=(highlight_info.bevel_width << 1);\n        highlight_info.height-=(highlight_info.bevel_width << 1);\n        highlight_info.x+=highlight_info.bevel_width;\n        state&=(~UpdateConfigurationState);\n      }\n    if (state & RedrawWidgetState)\n      {\n        /*\n          Redraw Menu widget.\n        */\n        if (submenu_info.active == 0)\n          {\n            y=(int) title_height;\n            XSetBevelColor(display,&windows->widget,MagickFalse);\n            (void) XDrawLine(display,windows->widget.id,\n              windows->widget.widget_context,selection_info.x,y-1,\n              (int) selection_info.width,y-1);\n            XSetBevelColor(display,&windows->widget,MagickTrue);\n            (void) XDrawLine(display,windows->widget.id,\n              windows->widget.widget_context,selection_info.x,y,\n              (int) selection_info.width,y);\n            (void) XSetFillStyle(display,windows->widget.widget_context,\n              FillSolid);\n          }\n        /*\n          Draw menu selections.\n        */\n        selection_info.center=MagickTrue;\n        selection_info.y=(int) menu_info.bevel_width;\n        selection_info.text=(char *) title;\n        if (submenu_info.active == 0)\n          XDrawWidgetText(display,&windows->widget,&selection_info);\n        selection_info.center=MagickFalse;\n        selection_info.y=(int) top_offset;\n        for (id=0; id < (int) number_selections; id++)\n        {\n          selection_info.text=(char *) selections[id];\n          XDrawWidgetText(display,&windows->widget,&selection_info);\n          highlight_info.y=selection_info.y+highlight_info.bevel_width;\n          if (id == selection_info.id)\n            XDrawBevel(display,&windows->widget,&highlight_info);\n          selection_info.y+=(int) selection_info.height;\n        }\n        XDrawBevel(display,&windows->widget,&menu_info);\n        state&=(~RedrawWidgetState);\n      }\n    if (number_selections > 2)\n      {\n        /*\n          Redraw Menu line.\n        */\n        y=(int) (top_offset+selection_info.height*(number_selections-1));\n        XSetBevelColor(display,&windows->widget,MagickFalse);\n        (void) XDrawLine(display,windows->widget.id,\n          windows->widget.widget_context,selection_info.x,y-1,\n          (int) selection_info.width,y-1);\n        XSetBevelColor(display,&windows->widget,MagickTrue);\n        (void) XDrawLine(display,windows->widget.id,\n          windows->widget.widget_context,selection_info.x,y,\n          (int) selection_info.width,y);\n        (void) XSetFillStyle(display,windows->widget.widget_context,FillSolid);\n      }\n    /*\n      Wait for next event.\n    */\n    (void) XIfEvent(display,&event,XScreenEvent,(char *) windows);\n    switch (event.type)\n    {\n      case ButtonPress:\n      {\n        if (event.xbutton.window != windows->widget.id)\n          {\n            /*\n              exit menu.\n            */\n            if (event.xbutton.window == windows->command.id)\n              (void) XPutBackEvent(display,&event);\n            selection_info.id=(~0);\n            *item='\\0';\n            state|=ExitState;\n            break;\n          }\n        state&=(~InactiveWidgetState);\n        id=(event.xbutton.y-top_offset)/(int) selection_info.height;\n        selection_info.id=id;\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Highlight this selection.\n        */\n        selection_info.y=(int) (top_offset+id*selection_info.height);\n        selection_info.text=(char *) selections[id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        highlight_info.y=selection_info.y+highlight_info.bevel_width;\n        XDrawBevel(display,&windows->widget,&highlight_info);\n        break;\n      }\n      case ButtonRelease:\n      {\n        if (windows->widget.mapped == MagickFalse)\n          break;\n        if (event.xbutton.window == windows->command.id)\n          if ((state & InactiveWidgetState) == 0)\n            break;\n        /*\n          exit menu.\n        */\n        XSetCursorState(display,windows,MagickFalse);\n        *item='\\0';\n        state|=ExitState;\n        break;\n      }\n      case ConfigureNotify:\n      {\n        /*\n          Update widget configuration.\n        */\n        if (event.xconfigure.window != windows->widget.id)\n          break;\n        if ((event.xconfigure.width == (int) windows->widget.width) &&\n            (event.xconfigure.height == (int) windows->widget.height))\n          break;\n        windows->widget.width=(unsigned int)\n          MagickMax(event.xconfigure.width,(int) windows->widget.min_width);\n        windows->widget.height=(unsigned int)\n          MagickMax(event.xconfigure.height,(int) windows->widget.min_height);\n        state|=UpdateConfigurationState;\n        break;\n      }\n      case EnterNotify:\n      {\n        if (event.xcrossing.window != windows->widget.id)\n          break;\n        if (event.xcrossing.state == 0)\n          break;\n        state&=(~InactiveWidgetState);\n        id=((event.xcrossing.y-top_offset)/(int) selection_info.height);\n        if ((selection_info.id >= 0) &&\n            (selection_info.id < (int) number_selections))\n          {\n            /*\n              Unhighlight last selection.\n            */\n            if (id == selection_info.id)\n              break;\n            selection_info.y=(int)\n              (top_offset+selection_info.id*selection_info.height);\n            selection_info.text=(char *) selections[selection_info.id];\n            XDrawWidgetText(display,&windows->widget,&selection_info);\n          }\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Highlight this selection.\n        */\n        selection_info.id=id;\n        selection_info.y=(int)\n          (top_offset+selection_info.id*selection_info.height);\n        selection_info.text=(char *) selections[selection_info.id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        highlight_info.y=selection_info.y+highlight_info.bevel_width;\n        XDrawBevel(display,&windows->widget,&highlight_info);\n        break;\n      }\n      case Expose:\n      {\n        if (event.xexpose.window != windows->widget.id)\n          break;\n        if (event.xexpose.count != 0)\n          break;\n        state|=RedrawWidgetState;\n        break;\n      }\n      case LeaveNotify:\n      {\n        if (event.xcrossing.window != windows->widget.id)\n          break;\n        state|=InactiveWidgetState;\n        id=selection_info.id;\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Unhighlight last selection.\n        */\n        selection_info.y=(int) (top_offset+id*selection_info.height);\n        selection_info.id=(~0);\n        selection_info.text=(char *) selections[id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        break;\n      }\n      case MotionNotify:\n      {\n        /*\n          Discard pending button motion events.\n        */\n        while (XCheckMaskEvent(display,ButtonMotionMask,&event)) ;\n        if (submenu_info.active != 0)\n          if (event.xmotion.window == windows->command.id)\n            {\n              if ((state & InactiveWidgetState) == 0)\n                {\n                  if (MatteIsActive(submenu_info,event.xmotion) == MagickFalse)\n                    {\n                      selection_info.id=(~0);\n                        *item='\\0';\n                      state|=ExitState;\n                      break;\n                    }\n                }\n              else\n                if (WindowIsActive(windows->command,event.xmotion))\n                  {\n                    selection_info.id=(~0);\n                    *item='\\0';\n                    state|=ExitState;\n                    break;\n                  }\n            }\n        if (event.xmotion.window != windows->widget.id)\n          break;\n        if (state & InactiveWidgetState)\n          break;\n        id=(event.xmotion.y-top_offset)/(int) selection_info.height;\n        if ((selection_info.id >= 0) &&\n            (selection_info.id < (int) number_selections))\n          {\n            /*\n              Unhighlight last selection.\n            */\n            if (id == selection_info.id)\n              break;\n            selection_info.y=(int)\n              (top_offset+selection_info.id*selection_info.height);\n            selection_info.text=(char *) selections[selection_info.id];\n            XDrawWidgetText(display,&windows->widget,&selection_info);\n          }\n        selection_info.id=id;\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Highlight this selection.\n        */\n        selection_info.y=(int) (top_offset+id*selection_info.height);\n        selection_info.text=(char *) selections[id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        highlight_info.y=selection_info.y+highlight_info.bevel_width;\n        XDrawBevel(display,&windows->widget,&highlight_info);\n        break;\n      }\n      default:\n        break;\n    }\n  } while ((state & ExitState) == 0);\n  (void) XFreeCursor(display,cursor);\n  window_attributes.override_redirect=MagickFalse;\n  (void) XChangeWindowAttributes(display,windows->widget.id,\n    (size_t) CWOverrideRedirect,&window_attributes);\n  (void) XWithdrawWindow(display,windows->widget.id,windows->widget.screen);\n  XCheckRefreshWindows(display,windows);\n  if (submenu_info.active != 0)\n    {\n      submenu_info.active=MagickFalse;\n      toggle_info.raised=MagickFalse;\n      XDrawTriangleEast(display,&windows->command,&toggle_info);\n    }\n  if ((selection_info.id < 0) || (selection_info.id >= (int) number_selections))\n    return(~0);\n  (void) CopyMagickString(item,selections[selection_info.id],MagickPathExtent);\n  return(selection_info.id);\n}",
        "func": "MagickPrivate int XMenuWidget(Display *display,XWindows *windows,\n  const char *title,const char *const *selections,char *item)\n{\n  Cursor\n    cursor;\n\n  int\n    id,\n    x,\n    y;\n\n  unsigned int\n    height,\n    number_selections,\n    title_height,\n    top_offset,\n    width;\n\n  size_t\n    state;\n\n  XEvent\n    event;\n\n  XFontStruct\n    *font_info;\n\n  XSetWindowAttributes\n    window_attributes;\n\n  XWidgetInfo\n    highlight_info,\n    menu_info,\n    selection_info;\n\n  XWindowChanges\n    window_changes;\n\n  /*\n    Determine Menu widget attributes.\n  */\n  assert(display != (Display *) NULL);\n  assert(windows != (XWindows *) NULL);\n  assert(title != (char *) NULL);\n  assert(selections != (const char **) NULL);\n  assert(item != (char *) NULL);\n  (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",title);\n  font_info=windows->widget.font_info;\n  windows->widget.width=submenu_info.active == 0 ?\n    WidgetTextWidth(font_info,(char *) title) : 0;\n  for (id=0; selections[id] != (char *) NULL; id++)\n  {\n    width=WidgetTextWidth(font_info,(char *) selections[id]);\n    if (width > windows->widget.width)\n      windows->widget.width=width;\n  }\n  number_selections=(unsigned int) id;\n  XGetWidgetInfo((char *) NULL,&menu_info);\n  title_height=(unsigned int) (submenu_info.active == 0 ?\n    (3*(font_info->descent+font_info->ascent) >> 1)+5 : 2);\n  width=WidgetTextWidth(font_info,(char *) title);\n  height=(unsigned int) ((3*(font_info->ascent+font_info->descent)) >> 1);\n  /*\n    Position Menu widget.\n  */\n  windows->widget.width+=QuantumMargin+(menu_info.bevel_width << 1);\n  top_offset=title_height+menu_info.bevel_width-1;\n  windows->widget.height=top_offset+number_selections*height+4;\n  windows->widget.min_width=windows->widget.width;\n  windows->widget.min_height=windows->widget.height;\n  XQueryPosition(display,windows->widget.root,&x,&y);\n  windows->widget.x=x-(QuantumMargin >> 1);\n  if (submenu_info.active != 0)\n    {\n      windows->widget.x=\n        windows->command.x+windows->command.width-QuantumMargin;\n      toggle_info.raised=MagickTrue;\n      XDrawTriangleEast(display,&windows->command,&toggle_info);\n    }\n  windows->widget.y=submenu_info.active == 0 ? y-(int)\n    ((3*title_height) >> 2) : y;\n  if (submenu_info.active != 0)\n    windows->widget.y=windows->command.y+submenu_info.y;\n  XConstrainWindowPosition(display,&windows->widget);\n  /*\n    Map Menu widget.\n  */\n  window_attributes.override_redirect=MagickTrue;\n  (void) XChangeWindowAttributes(display,windows->widget.id,\n    (size_t) CWOverrideRedirect,&window_attributes);\n  window_changes.width=(int) windows->widget.width;\n  window_changes.height=(int) windows->widget.height;\n  window_changes.x=windows->widget.x;\n  window_changes.y=windows->widget.y;\n  (void) XReconfigureWMWindow(display,windows->widget.id,windows->widget.screen,\n    (unsigned int) (CWWidth | CWHeight | CWX | CWY),&window_changes);\n  (void) XMapRaised(display,windows->widget.id);\n  windows->widget.mapped=MagickFalse;\n  /*\n    Respond to X events.\n  */\n  selection_info.height=height;\n  cursor=XCreateFontCursor(display,XC_right_ptr);\n  (void) XCheckDefineCursor(display,windows->image.id,cursor);\n  (void) XCheckDefineCursor(display,windows->command.id,cursor);\n  (void) XCheckDefineCursor(display,windows->widget.id,cursor);\n  state=UpdateConfigurationState;\n  do\n  {\n    if (state & UpdateConfigurationState)\n      {\n        /*\n          Initialize selection information.\n        */\n        XGetWidgetInfo((char *) NULL,&menu_info);\n        menu_info.bevel_width--;\n        menu_info.width=windows->widget.width-((menu_info.bevel_width) << 1);\n        menu_info.height=windows->widget.height-((menu_info.bevel_width) << 1);\n        menu_info.x=(int) menu_info.bevel_width;\n        menu_info.y=(int) menu_info.bevel_width;\n        XGetWidgetInfo((char *) NULL,&selection_info);\n        selection_info.center=MagickFalse;\n        selection_info.width=menu_info.width;\n        selection_info.height=height;\n        selection_info.x=menu_info.x;\n        highlight_info=selection_info;\n        highlight_info.bevel_width--;\n        highlight_info.width-=(highlight_info.bevel_width << 1);\n        highlight_info.height-=(highlight_info.bevel_width << 1);\n        highlight_info.x+=highlight_info.bevel_width;\n        state&=(~UpdateConfigurationState);\n      }\n    if (state & RedrawWidgetState)\n      {\n        /*\n          Redraw Menu widget.\n        */\n        if (submenu_info.active == 0)\n          {\n            y=(int) title_height;\n            XSetBevelColor(display,&windows->widget,MagickFalse);\n            (void) XDrawLine(display,windows->widget.id,\n              windows->widget.widget_context,selection_info.x,y-1,\n              (int) selection_info.width,y-1);\n            XSetBevelColor(display,&windows->widget,MagickTrue);\n            (void) XDrawLine(display,windows->widget.id,\n              windows->widget.widget_context,selection_info.x,y,\n              (int) selection_info.width,y);\n            (void) XSetFillStyle(display,windows->widget.widget_context,\n              FillSolid);\n          }\n        /*\n          Draw menu selections.\n        */\n        selection_info.center=MagickTrue;\n        selection_info.y=(int) menu_info.bevel_width;\n        selection_info.text=(char *) title;\n        if (submenu_info.active == 0)\n          XDrawWidgetText(display,&windows->widget,&selection_info);\n        selection_info.center=MagickFalse;\n        selection_info.y=(int) top_offset;\n        for (id=0; id < (int) number_selections; id++)\n        {\n          selection_info.text=(char *) selections[id];\n          XDrawWidgetText(display,&windows->widget,&selection_info);\n          highlight_info.y=selection_info.y+highlight_info.bevel_width;\n          if (id == selection_info.id)\n            XDrawBevel(display,&windows->widget,&highlight_info);\n          selection_info.y+=(int) selection_info.height;\n        }\n        XDrawBevel(display,&windows->widget,&menu_info);\n        state&=(~RedrawWidgetState);\n      }\n    if (number_selections > 2)\n      {\n        /*\n          Redraw Menu line.\n        */\n        y=(int) (top_offset+selection_info.height*(number_selections-1));\n        XSetBevelColor(display,&windows->widget,MagickFalse);\n        (void) XDrawLine(display,windows->widget.id,\n          windows->widget.widget_context,selection_info.x,y-1,\n          (int) selection_info.width,y-1);\n        XSetBevelColor(display,&windows->widget,MagickTrue);\n        (void) XDrawLine(display,windows->widget.id,\n          windows->widget.widget_context,selection_info.x,y,\n          (int) selection_info.width,y);\n        (void) XSetFillStyle(display,windows->widget.widget_context,FillSolid);\n      }\n    /*\n      Wait for next event.\n    */\n    (void) XIfEvent(display,&event,XScreenEvent,(char *) windows);\n    switch (event.type)\n    {\n      case ButtonPress:\n      {\n        if (event.xbutton.window != windows->widget.id)\n          {\n            /*\n              exit menu.\n            */\n            if (event.xbutton.window == windows->command.id)\n              (void) XPutBackEvent(display,&event);\n            selection_info.id=(~0);\n            *item='\\0';\n            state|=ExitState;\n            break;\n          }\n        state&=(~InactiveWidgetState);\n        if (selection_info.height == 0)\n          break;\n        id=(event.xbutton.y-top_offset)/(int) selection_info.height;\n        selection_info.id=id;\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Highlight this selection.\n        */\n        selection_info.y=(int) (top_offset+id*selection_info.height);\n        selection_info.text=(char *) selections[id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        highlight_info.y=selection_info.y+highlight_info.bevel_width;\n        XDrawBevel(display,&windows->widget,&highlight_info);\n        break;\n      }\n      case ButtonRelease:\n      {\n        if (windows->widget.mapped == MagickFalse)\n          break;\n        if (event.xbutton.window == windows->command.id)\n          if ((state & InactiveWidgetState) == 0)\n            break;\n        /*\n          exit menu.\n        */\n        XSetCursorState(display,windows,MagickFalse);\n        *item='\\0';\n        state|=ExitState;\n        break;\n      }\n      case ConfigureNotify:\n      {\n        /*\n          Update widget configuration.\n        */\n        if (event.xconfigure.window != windows->widget.id)\n          break;\n        if ((event.xconfigure.width == (int) windows->widget.width) &&\n            (event.xconfigure.height == (int) windows->widget.height))\n          break;\n        windows->widget.width=(unsigned int)\n          MagickMax(event.xconfigure.width,(int) windows->widget.min_width);\n        windows->widget.height=(unsigned int)\n          MagickMax(event.xconfigure.height,(int) windows->widget.min_height);\n        state|=UpdateConfigurationState;\n        break;\n      }\n      case EnterNotify:\n      {\n        if (event.xcrossing.window != windows->widget.id)\n          break;\n        if (event.xcrossing.state == 0)\n          break;\n        state&=(~InactiveWidgetState);\n        if (selection_info.height == 0)\n          break;\n        id=((event.xcrossing.y-top_offset)/(int) selection_info.height);\n        if ((selection_info.id >= 0) &&\n            (selection_info.id < (int) number_selections))\n          {\n            /*\n              Unhighlight last selection.\n            */\n            if (id == selection_info.id)\n              break;\n            selection_info.y=(int)\n              (top_offset+selection_info.id*selection_info.height);\n            selection_info.text=(char *) selections[selection_info.id];\n            XDrawWidgetText(display,&windows->widget,&selection_info);\n          }\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Highlight this selection.\n        */\n        selection_info.id=id;\n        selection_info.y=(int)\n          (top_offset+selection_info.id*selection_info.height);\n        selection_info.text=(char *) selections[selection_info.id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        highlight_info.y=selection_info.y+highlight_info.bevel_width;\n        XDrawBevel(display,&windows->widget,&highlight_info);\n        break;\n      }\n      case Expose:\n      {\n        if (event.xexpose.window != windows->widget.id)\n          break;\n        if (event.xexpose.count != 0)\n          break;\n        state|=RedrawWidgetState;\n        break;\n      }\n      case LeaveNotify:\n      {\n        if (event.xcrossing.window != windows->widget.id)\n          break;\n        state|=InactiveWidgetState;\n        id=selection_info.id;\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Unhighlight last selection.\n        */\n        selection_info.y=(int) (top_offset+id*selection_info.height);\n        selection_info.id=(~0);\n        selection_info.text=(char *) selections[id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        break;\n      }\n      case MotionNotify:\n      {\n        /*\n          Discard pending button motion events.\n        */\n        while (XCheckMaskEvent(display,ButtonMotionMask,&event)) ;\n        if (submenu_info.active != 0)\n          if (event.xmotion.window == windows->command.id)\n            {\n              if ((state & InactiveWidgetState) == 0)\n                {\n                  if (MatteIsActive(submenu_info,event.xmotion) == MagickFalse)\n                    {\n                      selection_info.id=(~0);\n                        *item='\\0';\n                      state|=ExitState;\n                      break;\n                    }\n                }\n              else\n                if (WindowIsActive(windows->command,event.xmotion))\n                  {\n                    selection_info.id=(~0);\n                    *item='\\0';\n                    state|=ExitState;\n                    break;\n                  }\n            }\n        if (event.xmotion.window != windows->widget.id)\n          break;\n        if (state & InactiveWidgetState)\n          break;\n        if (selection_info.height == 0)\n          break;\n        id=(event.xmotion.y-top_offset)/(int) selection_info.height;\n        if ((selection_info.id >= 0) &&\n            (selection_info.id < (int) number_selections))\n          {\n            /*\n              Unhighlight last selection.\n            */\n            if (id == selection_info.id)\n              break;\n            selection_info.y=(int)\n              (top_offset+selection_info.id*selection_info.height);\n            selection_info.text=(char *) selections[selection_info.id];\n            XDrawWidgetText(display,&windows->widget,&selection_info);\n          }\n        selection_info.id=id;\n        if ((id < 0) || (id >= (int) number_selections))\n          break;\n        /*\n          Highlight this selection.\n        */\n        selection_info.y=(int) (top_offset+id*selection_info.height);\n        selection_info.text=(char *) selections[id];\n        XDrawWidgetText(display,&windows->widget,&selection_info);\n        highlight_info.y=selection_info.y+highlight_info.bevel_width;\n        XDrawBevel(display,&windows->widget,&highlight_info);\n        break;\n      }\n      default:\n        break;\n    }\n  } while ((state & ExitState) == 0);\n  (void) XFreeCursor(display,cursor);\n  window_attributes.override_redirect=MagickFalse;\n  (void) XChangeWindowAttributes(display,windows->widget.id,\n    (size_t) CWOverrideRedirect,&window_attributes);\n  (void) XWithdrawWindow(display,windows->widget.id,windows->widget.screen);\n  XCheckRefreshWindows(display,windows);\n  if (submenu_info.active != 0)\n    {\n      submenu_info.active=MagickFalse;\n      toggle_info.raised=MagickFalse;\n      XDrawTriangleEast(display,&windows->command,&toggle_info);\n    }\n  if ((selection_info.id < 0) || (selection_info.id >= (int) number_selections))\n    return(~0);\n  (void) CopyMagickString(item,selections[selection_info.id],MagickPathExtent);\n  return(selection_info.id);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -208,6 +208,8 @@\n             break;\n           }\n         state&=(~InactiveWidgetState);\n+        if (selection_info.height == 0)\n+          break;\n         id=(event.xbutton.y-top_offset)/(int) selection_info.height;\n         selection_info.id=id;\n         if ((id < 0) || (id >= (int) number_selections))\n@@ -261,6 +263,8 @@\n         if (event.xcrossing.state == 0)\n           break;\n         state&=(~InactiveWidgetState);\n+        if (selection_info.height == 0)\n+          break;\n         id=((event.xcrossing.y-top_offset)/(int) selection_info.height);\n         if ((selection_info.id >= 0) &&\n             (selection_info.id < (int) number_selections))\n@@ -347,6 +351,8 @@\n           break;\n         if (state & InactiveWidgetState)\n           break;\n+        if (selection_info.height == 0)\n+          break;\n         id=(event.xmotion.y-top_offset)/(int) selection_info.height;\n         if ((selection_info.id >= 0) &&\n             (selection_info.id < (int) number_selections))",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (selection_info.height == 0)",
                "          break;",
                "        if (selection_info.height == 0)",
                "          break;",
                "        if (selection_info.height == 0)",
                "          break;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-2906",
        "func_name": "wireshark/dissect_response_frame",
        "description": "Due to a failure in validating the length provided by an attacker-crafted CP2179 packet, Wireshark versions 2.0.0 through 4.0.7 is susceptible to a divide by zero allowing for a denial of service attack.\n",
        "git_url": "https://gitlab.com/wireshark/wireshark/-/commit/44dc70cc5aadca91cb8ba3710c59c3651b7b0d4d",
        "commit_title": "CP2179: Handle timetag info response without records",
        "commit_text": " Fixes #19229 ",
        "func_before": "static int\ndissect_response_frame(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, int offset, guint16 message_type)\n{\n    /* Set up structures needed to add the protocol subtree and manage it */\n    proto_item *response_item = NULL;\n    proto_item *cp2179_proto_item = NULL;\n    proto_item *cp2179_subdata_item = NULL;\n\n    proto_tree *cp2179_proto_tree = NULL;\n    proto_tree *cp2179_addr_tree = NULL;\n    proto_tree *cp2179_fc_tree = NULL;\n    proto_tree *cp2179_data_tree = NULL;\n    proto_tree *cp2179_event_tree = NULL;\n\n    cp2179_conversation  *conv;\n    guint32 req_frame_num;\n    guint16 req_address_word;\n    guint8  req_command_code;\n    gboolean request_found = FALSE;\n    request_frame *request_data;\n\n    gint analogtestvalue = 0;\n    gint analog16_num = 0;\n    gint point_num = 0;\n\n    guint function_code;\n    guint simplestatusseq = 0x30;\n\n    guint16 address_word = 0;\n    guint16 numberofcharacters = -1;\n\n    gfloat specialcalvalue = 0;\n\n    int x, y, num_records = 0, recordsize = 0, num_values = 0;\n\n    cp2179_proto_item = proto_tree_add_item(tree, proto_cp2179, tvb, 0, -1, ENC_NA);\n    cp2179_proto_tree = proto_item_add_subtree(cp2179_proto_item, ett_cp2179_header);\n\n    /* RTU & Master Address are encoded into a 16-bit word */\n    address_word = tvb_get_letohs(tvb, offset);\n\n    cp2179_addr_tree = proto_tree_add_subtree_format(cp2179_proto_tree, tvb, offset, 2, ett_cp2179_addr, NULL,\n                   \"RTU Address: %d, Master Address: %d\", (address_word & 0x7FF), ((address_word & 0xF800) >> 11) );\n\n    proto_tree_add_item(cp2179_addr_tree, hf_cp2179_rtu_address, tvb, 0, 2, ENC_LITTLE_ENDIAN);\n    proto_tree_add_item(cp2179_addr_tree, hf_cp2179_master_address, tvb, 0, 2, ENC_LITTLE_ENDIAN);\n    offset += 2;\n\n    /*The response always echos the function code in request, except when the RTU can't perform the required function.\n    It may set the NOP or RST bit. Bit 0 to bit 5 is the field for function codes. Bit 6 is NOP bit. Bit 7 is RST bit. */\n    function_code = tvb_get_guint8(tvb, offset);\n\n    cp2179_fc_tree = proto_tree_add_subtree_format(cp2179_proto_tree, tvb, offset, 1, ett_cp2179_fc, NULL,\n               \"Function Code: %s (0x%02x)\", val_to_str_const(function_code, FunctionCodenames, \"Unknown Function Code\"), function_code);\n\n    proto_tree_add_item(cp2179_fc_tree, hf_cp2179_function_code, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    proto_tree_add_item(cp2179_fc_tree, hf_cp2179_nop_flag, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    proto_tree_add_item(cp2179_fc_tree, hf_cp2179_rst_flag, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n\n    offset += 1;\n\n    /* Status Byte & Port Status */\n    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_status_byte, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    offset += 1;\n    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_port_status_byte, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    offset += 1;\n\n    /* Number of characters */\n    numberofcharacters = tvb_get_letohs(tvb, 5);\n    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_number_characters, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    offset += 2;\n\n    /* get the converstation data */\n    conv = (cp2179_conversation *)p_get_proto_data(wmem_file_scope(), pinfo, proto_cp2179, 0);\n\n    if (conv) {\n        wmem_list_frame_t *frame = wmem_list_head(conv->request_frame_data);\n        /* Cycle through all logged instances of request frames, looking for request frame number that occurred immediately\n           prior to current frame number that has a matching address word */\n        while (frame && !request_found) {\n            request_data = (request_frame *)wmem_list_frame_data(frame);\n            req_frame_num = request_data->fnum;\n            req_command_code = request_data->commmand_code;\n            req_address_word = request_data->address_word;\n                if ((pinfo->num > req_frame_num) && (req_address_word == address_word)) {\n                    response_item = proto_tree_add_uint(cp2179_proto_tree, hf_cp2179_request_frame, tvb, 0, 0, req_frame_num);\n                    proto_item_set_generated(response_item);\n                    request_found = TRUE;\n                }\n                frame = wmem_list_frame_next(frame);\n        }\n\n        if (request_found)\n        {\n            switch (message_type)\n            {\n                case SBO_SELECT_RESPONSE:\n                case SBO_OPERATE_RESPONSE:\n                case RESET_ACC_RESPONSE:\n                case INIT_RTU_RESPONSE:\n\n                    if ( numberofcharacters > 0 ){\n                        /* Based on the message type, process the next byte differently */\n                        if ( message_type == SBO_SELECT_RESPONSE ){\n                            proto_tree_add_item(cp2179_proto_tree, hf_cp2179_sbo_request_point, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                            offset += 1;\n                        }\n                        if ( message_type == RESET_ACC_RESPONSE ){\n                            proto_tree_add_item(cp2179_proto_tree, hf_cp2179_resetacc_request_point, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                            offset += 1;\n                        }\n                    }\n                    break;\n\n                case SPECIAL_CALC_RESPONSE:\n                    /* Based on the command code from the corresponding request, dissect the data field differently.\n                       If required a range of Special calculation, display the requested sequence ID and corresponding\n                       values. The requested sequence number is obtained from the previous request frame.  */\n                    cp2179_data_tree = proto_tree_add_subtree(cp2179_proto_tree, tvb, offset, numberofcharacters, ett_cp2179_data, NULL, \"CP2179 Data Field\");\n\n                    if (req_command_code == SPECIAL_CALC_ALL ){\n                        do{\n                            specialcalvalue = tvb_get_letohieee_float(tvb, offset );\n                            proto_tree_add_float_format(cp2179_data_tree, hf_cp2179_specialcalc, tvb, offset, 4, specialcalvalue,\n                                \"Special Calculation %u : %f\", point_num, specialcalvalue);\n                            point_num += 1;\n                            offset += 4;\n                        }while(tvb_reported_length_remaining(tvb, offset) > 2);\n                    }\n                    /*If it request all the special calculation data, dissect all of them and associated a sequence ID with it.*/\n                    else if (req_command_code == SPECIAL_CALC_RANGE ){\n                        do{\n                            specialcalvalue = tvb_get_letohieee_float(tvb, offset );\n                            proto_tree_add_float_format(cp2179_data_tree, hf_cp2179_specialcalc, tvb, offset, 4, specialcalvalue,\n                                \"Special Calculation %u : %f\",  request_data->requested_points[point_num], specialcalvalue);\n                            point_num += 1;\n                            offset += 4;\n                        }while(tvb_reported_length_remaining(tvb, offset) > 2);\n                    }\n                    break;\n\n                case SCAN_INCLUSIVE_16_ANALOG_RESPONSE:\n\n                    cp2179_data_tree = proto_tree_add_subtree(cp2179_proto_tree, tvb, offset, numberofcharacters, ett_cp2179_data, NULL, \"CP2179 Data Field\");\n\n                    /* Update Info column with useful information of Command Code Type */\n                    col_append_fstr(pinfo->cinfo, COL_INFO, \" [ %s ]\", val_to_str_ext_const(req_command_code, &cp2179_CommandCodeNames_ext, \"Unknown Command Code\"));\n\n                    /*Report the values of the requested SCAN inclusive data. To figure out which sequence ID the values in the response associated with,\n                      we read the request_frame information and show the corresponding sequence ID of the data in response frame.*/\n                    do{\n                        analogtestvalue = tvb_get_letohis(tvb, offset);\n                        proto_tree_add_int_format(cp2179_data_tree, hf_cp2179_analog_16bit, tvb, offset, 2, request_data->requested_points[point_num],\n                                                   \"Analog (16 bit) %u : %d\",  request_data->requested_points[point_num], analogtestvalue);\n                        point_num += 1;\n                        offset += 2;\n                    }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                    break;\n\n                case BASIC_SCAN_RESPONSE:\n                {\n                    cp2179_data_tree = proto_tree_add_subtree(cp2179_proto_tree, tvb, offset, numberofcharacters, ett_cp2179_data, NULL, \"CP2179 Data Field\");\n\n                    /* Update Info column with useful information of Command Code Type */\n                    col_append_fstr(pinfo->cinfo, COL_INFO, \" [ %s ]\", val_to_str_ext_const(req_command_code, &cp2179_CommandCodeNames_ext, \"Unknown Command Code\"));\n\n                    switch (req_command_code)\n                    {\n                        /* Based the command code from the request frame, we dissect the response data differently.\n                           For example, if the request packet has command byte as ANALOG_16_BIT, the\n                           the data field in the response should be dissected as 16-bit signed integer(s). */\n                        case ACCUMULATOR_16_BIT:\n                            do{\n                                analogtestvalue = tvb_get_letohs(tvb, offset);\n                                proto_tree_add_uint_format(cp2179_data_tree, hf_cp2179_accumulator, tvb, offset, 2, analog16_num,\n                                                           \"Accumulator %u : %u\", analog16_num, analogtestvalue);\n                                analog16_num += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n\n                        case ANALOG_16_BIT:\n                            do{\n                                analogtestvalue = tvb_get_letohis(tvb, offset);\n                                proto_tree_add_int_format(cp2179_data_tree, hf_cp2179_analog_16bit, tvb, offset, 2, analog16_num,\n                                                           \"Analog (16 bit) %u : %i\", analog16_num, analogtestvalue);\n                                analog16_num += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n\n                        case SIMPLE_STATUS_DATA:\n                            do{\n                                cp2179_subdata_item = proto_tree_add_bitmask(cp2179_data_tree, tvb, offset, hf_cp2179_simplestatusbit,\n                                                       ett_cp2179_subdata, cp2179_simplestatus_bits, ENC_LITTLE_ENDIAN);\n                                proto_item_set_text(cp2179_subdata_item, \"Simple Status Point 0x%x\", simplestatusseq);\n\n                                simplestatusseq += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n\n                        case TWO_BIT_STATUS:\n                            do{\n                                cp2179_subdata_item = proto_tree_add_bitmask(cp2179_data_tree, tvb, offset, hf_cp2179_2bitstatus,\n                                                       ett_cp2179_subdata, cp2179_2bitstatus_bits, ENC_LITTLE_ENDIAN);\n                                proto_item_set_text(cp2179_subdata_item, \"2 Bit Status Point 0x%x\", simplestatusseq);\n\n                                simplestatusseq += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n                    } /* end of command code switch */\n\n                    break;\n\n                } /* end of basic scan response switch */\n\n                case TIMETAG_INFO_RESPONSE:\n                {\n                    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_timetag_moredata, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_timetag_numsets, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n\n                    num_records = tvb_get_guint8(tvb, offset) & 0x7F;\n                    recordsize = (numberofcharacters-1) / num_records;\n                    num_values = (recordsize-6) / 2;      /* Determine how many 16-bit analog values are present in each event record */\n\n                    offset += 1;\n\n                    for (x = 0; x < num_records; x++)\n                    {\n                        cp2179_event_tree = proto_tree_add_subtree_format(cp2179_proto_tree, tvb, offset, recordsize, ett_cp2179_event, NULL, \"Event Record # %d\", x+1);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_type, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_date_hundreds, tvb, offset+1, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_date_tens, tvb, offset+2, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_hour, tvb, offset+3, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_minute, tvb, offset+4, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_second, tvb, offset+5, 1, ENC_LITTLE_ENDIAN);\n                        offset += 6;\n\n                        for (y = 0; y < num_values; y++)\n                        {\n                            analogtestvalue = tvb_get_letohis(tvb, offset);\n                            proto_tree_add_int_format(cp2179_event_tree, hf_cp2179_analog_16bit, tvb, offset, 2, analogtestvalue,\n                                                       \"Analog Value (16 bit) %u : %d\",  y+1, analogtestvalue);\n                            offset += 2;\n                        }\n                    }\n                    break;\n                }\n                break;\n\n            } /* end of message type switch */\n\n            proto_tree_add_item(cp2179_proto_tree, hf_cp2179_crc, tvb, offset, 2, ENC_BIG_ENDIAN);\n\n        } /* request found */\n\n    } /* conversation data found */\n\n    if (!request_found) {\n        proto_item_append_text(response_item, \", No Request found\");\n        return 0;\n    }\n\n    return tvb_reported_length(tvb);\n}",
        "func": "static int\ndissect_response_frame(tvbuff_t *tvb, proto_tree *tree, packet_info *pinfo, int offset, guint16 message_type)\n{\n    /* Set up structures needed to add the protocol subtree and manage it */\n    proto_item *response_item = NULL;\n    proto_item *cp2179_proto_item = NULL;\n    proto_item *cp2179_subdata_item = NULL;\n\n    proto_tree *cp2179_proto_tree = NULL;\n    proto_tree *cp2179_addr_tree = NULL;\n    proto_tree *cp2179_fc_tree = NULL;\n    proto_tree *cp2179_data_tree = NULL;\n    proto_tree *cp2179_event_tree = NULL;\n\n    cp2179_conversation  *conv;\n    guint32 req_frame_num;\n    guint16 req_address_word;\n    guint8  req_command_code;\n    gboolean request_found = FALSE;\n    request_frame *request_data;\n\n    gint analogtestvalue = 0;\n    gint analog16_num = 0;\n    gint point_num = 0;\n\n    guint function_code;\n    guint simplestatusseq = 0x30;\n\n    guint16 address_word = 0;\n    guint16 numberofcharacters = -1;\n\n    gfloat specialcalvalue = 0;\n\n    int x, y, num_records = 0, recordsize = 0, num_values = 0;\n\n    cp2179_proto_item = proto_tree_add_item(tree, proto_cp2179, tvb, 0, -1, ENC_NA);\n    cp2179_proto_tree = proto_item_add_subtree(cp2179_proto_item, ett_cp2179_header);\n\n    /* RTU & Master Address are encoded into a 16-bit word */\n    address_word = tvb_get_letohs(tvb, offset);\n\n    cp2179_addr_tree = proto_tree_add_subtree_format(cp2179_proto_tree, tvb, offset, 2, ett_cp2179_addr, NULL,\n                   \"RTU Address: %d, Master Address: %d\", (address_word & 0x7FF), ((address_word & 0xF800) >> 11) );\n\n    proto_tree_add_item(cp2179_addr_tree, hf_cp2179_rtu_address, tvb, 0, 2, ENC_LITTLE_ENDIAN);\n    proto_tree_add_item(cp2179_addr_tree, hf_cp2179_master_address, tvb, 0, 2, ENC_LITTLE_ENDIAN);\n    offset += 2;\n\n    /*The response always echos the function code in request, except when the RTU can't perform the required function.\n    It may set the NOP or RST bit. Bit 0 to bit 5 is the field for function codes. Bit 6 is NOP bit. Bit 7 is RST bit. */\n    function_code = tvb_get_guint8(tvb, offset);\n\n    cp2179_fc_tree = proto_tree_add_subtree_format(cp2179_proto_tree, tvb, offset, 1, ett_cp2179_fc, NULL,\n               \"Function Code: %s (0x%02x)\", val_to_str_const(function_code, FunctionCodenames, \"Unknown Function Code\"), function_code);\n\n    proto_tree_add_item(cp2179_fc_tree, hf_cp2179_function_code, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    proto_tree_add_item(cp2179_fc_tree, hf_cp2179_nop_flag, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    proto_tree_add_item(cp2179_fc_tree, hf_cp2179_rst_flag, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n\n    offset += 1;\n\n    /* Status Byte & Port Status */\n    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_status_byte, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    offset += 1;\n    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_port_status_byte, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n    offset += 1;\n\n    /* Number of characters */\n    numberofcharacters = tvb_get_letohs(tvb, 5);\n    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_number_characters, tvb, offset, 2, ENC_LITTLE_ENDIAN);\n    offset += 2;\n\n    /* get the converstation data */\n    conv = (cp2179_conversation *)p_get_proto_data(wmem_file_scope(), pinfo, proto_cp2179, 0);\n\n    if (conv) {\n        wmem_list_frame_t *frame = wmem_list_head(conv->request_frame_data);\n        /* Cycle through all logged instances of request frames, looking for request frame number that occurred immediately\n           prior to current frame number that has a matching address word */\n        while (frame && !request_found) {\n            request_data = (request_frame *)wmem_list_frame_data(frame);\n            req_frame_num = request_data->fnum;\n            req_command_code = request_data->commmand_code;\n            req_address_word = request_data->address_word;\n                if ((pinfo->num > req_frame_num) && (req_address_word == address_word)) {\n                    response_item = proto_tree_add_uint(cp2179_proto_tree, hf_cp2179_request_frame, tvb, 0, 0, req_frame_num);\n                    proto_item_set_generated(response_item);\n                    request_found = TRUE;\n                }\n                frame = wmem_list_frame_next(frame);\n        }\n\n        if (request_found)\n        {\n            switch (message_type)\n            {\n                case SBO_SELECT_RESPONSE:\n                case SBO_OPERATE_RESPONSE:\n                case RESET_ACC_RESPONSE:\n                case INIT_RTU_RESPONSE:\n\n                    if ( numberofcharacters > 0 ){\n                        /* Based on the message type, process the next byte differently */\n                        if ( message_type == SBO_SELECT_RESPONSE ){\n                            proto_tree_add_item(cp2179_proto_tree, hf_cp2179_sbo_request_point, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                            offset += 1;\n                        }\n                        if ( message_type == RESET_ACC_RESPONSE ){\n                            proto_tree_add_item(cp2179_proto_tree, hf_cp2179_resetacc_request_point, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                            offset += 1;\n                        }\n                    }\n                    break;\n\n                case SPECIAL_CALC_RESPONSE:\n                    /* Based on the command code from the corresponding request, dissect the data field differently.\n                       If required a range of Special calculation, display the requested sequence ID and corresponding\n                       values. The requested sequence number is obtained from the previous request frame.  */\n                    cp2179_data_tree = proto_tree_add_subtree(cp2179_proto_tree, tvb, offset, numberofcharacters, ett_cp2179_data, NULL, \"CP2179 Data Field\");\n\n                    if (req_command_code == SPECIAL_CALC_ALL ){\n                        do{\n                            specialcalvalue = tvb_get_letohieee_float(tvb, offset );\n                            proto_tree_add_float_format(cp2179_data_tree, hf_cp2179_specialcalc, tvb, offset, 4, specialcalvalue,\n                                \"Special Calculation %u : %f\", point_num, specialcalvalue);\n                            point_num += 1;\n                            offset += 4;\n                        }while(tvb_reported_length_remaining(tvb, offset) > 2);\n                    }\n                    /*If it request all the special calculation data, dissect all of them and associated a sequence ID with it.*/\n                    else if (req_command_code == SPECIAL_CALC_RANGE ){\n                        do{\n                            specialcalvalue = tvb_get_letohieee_float(tvb, offset );\n                            proto_tree_add_float_format(cp2179_data_tree, hf_cp2179_specialcalc, tvb, offset, 4, specialcalvalue,\n                                \"Special Calculation %u : %f\",  request_data->requested_points[point_num], specialcalvalue);\n                            point_num += 1;\n                            offset += 4;\n                        }while(tvb_reported_length_remaining(tvb, offset) > 2);\n                    }\n                    break;\n\n                case SCAN_INCLUSIVE_16_ANALOG_RESPONSE:\n\n                    cp2179_data_tree = proto_tree_add_subtree(cp2179_proto_tree, tvb, offset, numberofcharacters, ett_cp2179_data, NULL, \"CP2179 Data Field\");\n\n                    /* Update Info column with useful information of Command Code Type */\n                    col_append_fstr(pinfo->cinfo, COL_INFO, \" [ %s ]\", val_to_str_ext_const(req_command_code, &cp2179_CommandCodeNames_ext, \"Unknown Command Code\"));\n\n                    /*Report the values of the requested SCAN inclusive data. To figure out which sequence ID the values in the response associated with,\n                      we read the request_frame information and show the corresponding sequence ID of the data in response frame.*/\n                    do{\n                        analogtestvalue = tvb_get_letohis(tvb, offset);\n                        proto_tree_add_int_format(cp2179_data_tree, hf_cp2179_analog_16bit, tvb, offset, 2, request_data->requested_points[point_num],\n                                                   \"Analog (16 bit) %u : %d\",  request_data->requested_points[point_num], analogtestvalue);\n                        point_num += 1;\n                        offset += 2;\n                    }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                    break;\n\n                case BASIC_SCAN_RESPONSE:\n                {\n                    cp2179_data_tree = proto_tree_add_subtree(cp2179_proto_tree, tvb, offset, numberofcharacters, ett_cp2179_data, NULL, \"CP2179 Data Field\");\n\n                    /* Update Info column with useful information of Command Code Type */\n                    col_append_fstr(pinfo->cinfo, COL_INFO, \" [ %s ]\", val_to_str_ext_const(req_command_code, &cp2179_CommandCodeNames_ext, \"Unknown Command Code\"));\n\n                    switch (req_command_code)\n                    {\n                        /* Based the command code from the request frame, we dissect the response data differently.\n                           For example, if the request packet has command byte as ANALOG_16_BIT, the\n                           the data field in the response should be dissected as 16-bit signed integer(s). */\n                        case ACCUMULATOR_16_BIT:\n                            do{\n                                analogtestvalue = tvb_get_letohs(tvb, offset);\n                                proto_tree_add_uint_format(cp2179_data_tree, hf_cp2179_accumulator, tvb, offset, 2, analog16_num,\n                                                           \"Accumulator %u : %u\", analog16_num, analogtestvalue);\n                                analog16_num += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n\n                        case ANALOG_16_BIT:\n                            do{\n                                analogtestvalue = tvb_get_letohis(tvb, offset);\n                                proto_tree_add_int_format(cp2179_data_tree, hf_cp2179_analog_16bit, tvb, offset, 2, analog16_num,\n                                                           \"Analog (16 bit) %u : %i\", analog16_num, analogtestvalue);\n                                analog16_num += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n\n                        case SIMPLE_STATUS_DATA:\n                            do{\n                                cp2179_subdata_item = proto_tree_add_bitmask(cp2179_data_tree, tvb, offset, hf_cp2179_simplestatusbit,\n                                                       ett_cp2179_subdata, cp2179_simplestatus_bits, ENC_LITTLE_ENDIAN);\n                                proto_item_set_text(cp2179_subdata_item, \"Simple Status Point 0x%x\", simplestatusseq);\n\n                                simplestatusseq += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n\n                        case TWO_BIT_STATUS:\n                            do{\n                                cp2179_subdata_item = proto_tree_add_bitmask(cp2179_data_tree, tvb, offset, hf_cp2179_2bitstatus,\n                                                       ett_cp2179_subdata, cp2179_2bitstatus_bits, ENC_LITTLE_ENDIAN);\n                                proto_item_set_text(cp2179_subdata_item, \"2 Bit Status Point 0x%x\", simplestatusseq);\n\n                                simplestatusseq += 1;\n                                offset += 2;\n                            }while(tvb_reported_length_remaining(tvb, offset) > 2);\n\n                            break;\n                    } /* end of command code switch */\n\n                    break;\n\n                } /* end of basic scan response switch */\n\n                case TIMETAG_INFO_RESPONSE:\n                {\n                    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_timetag_moredata, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                    proto_tree_add_item(cp2179_proto_tree, hf_cp2179_timetag_numsets, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n\n                    num_records = tvb_get_guint8(tvb, offset) & 0x7F;\n                    offset += 1;\n\n                    if (num_records == 0 || numberofcharacters <= 1)\n                        break;\n\n                    recordsize = (numberofcharacters-1) / num_records;\n                    num_values = (recordsize-6) / 2;      /* Determine how many 16-bit analog values are present in each event record */\n\n                    for (x = 0; x < num_records; x++)\n                    {\n                        cp2179_event_tree = proto_tree_add_subtree_format(cp2179_proto_tree, tvb, offset, recordsize, ett_cp2179_event, NULL, \"Event Record # %d\", x+1);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_type, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_date_hundreds, tvb, offset+1, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_date_tens, tvb, offset+2, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_hour, tvb, offset+3, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_minute, tvb, offset+4, 1, ENC_LITTLE_ENDIAN);\n                        proto_tree_add_item(cp2179_event_tree, hf_cp2179_timetag_event_second, tvb, offset+5, 1, ENC_LITTLE_ENDIAN);\n                        offset += 6;\n\n                        for (y = 0; y < num_values; y++)\n                        {\n                            analogtestvalue = tvb_get_letohis(tvb, offset);\n                            proto_tree_add_int_format(cp2179_event_tree, hf_cp2179_analog_16bit, tvb, offset, 2, analogtestvalue,\n                                                       \"Analog Value (16 bit) %u : %d\",  y+1, analogtestvalue);\n                            offset += 2;\n                        }\n                    }\n                    break;\n                }\n                break;\n\n            } /* end of message type switch */\n\n            proto_tree_add_item(cp2179_proto_tree, hf_cp2179_crc, tvb, offset, 2, ENC_BIG_ENDIAN);\n\n        } /* request found */\n\n    } /* conversation data found */\n\n    if (!request_found) {\n        proto_item_append_text(response_item, \", No Request found\");\n        return 0;\n    }\n\n    return tvb_reported_length(tvb);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -227,10 +227,13 @@\n                     proto_tree_add_item(cp2179_proto_tree, hf_cp2179_timetag_numsets, tvb, offset, 1, ENC_LITTLE_ENDIAN);\n \n                     num_records = tvb_get_guint8(tvb, offset) & 0x7F;\n+                    offset += 1;\n+\n+                    if (num_records == 0 || numberofcharacters <= 1)\n+                        break;\n+\n                     recordsize = (numberofcharacters-1) / num_records;\n                     num_values = (recordsize-6) / 2;      /* Determine how many 16-bit analog values are present in each event record */\n-\n-                    offset += 1;\n \n                     for (x = 0; x < num_records; x++)\n                     {",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "                    offset += 1;"
            ],
            "added_lines": [
                "                    offset += 1;",
                "",
                "                    if (num_records == 0 || numberofcharacters <= 1)",
                "                        break;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4678",
        "func_name": "gpac/avidmx_setup",
        "description": "Divide By Zero in GitHub repository gpac/gpac prior to 2.3-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4607052c482a51dbdacfe1ade10645c181d07b07",
        "commit_title": "fixed #2576",
        "commit_text": "",
        "func_before": "static void avidmx_setup(GF_Filter *filter, GF_AVIDmxCtx *ctx)\n{\n\tu32 sync_id = 0;\n\tu32 codecid = 0;\n\tBool unframed;\n\tu32 i, count, pfmt=0;\n\tGF_Fraction64 dur;\n\tchar *comp;\n\n\tif (ctx->use_file_fps) {\n\t\tDouble fps = AVI_frame_rate(ctx->avi);\n\t\tgf_media_get_video_timing(fps, &ctx->fps.num, &ctx->fps.den);\n\t}\n\n\tdur.den = ctx->fps.num;\n\tdur.num = (u64) (ctx->fps.den * AVI_video_frames(ctx->avi));\n\n\tunframed = GF_TRUE;\n\tcomp = AVI_video_compressor(ctx->avi);\n\tif (!comp) {\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Cannot retrieve video compressor name, ignoring video stream\\n\"));\n\t}\n\t/*these are/should be OK*/\n\telse if (!stricmp(comp, \"DIVX\") || !stricmp(comp, \"DX50\")\t/*DivX*/\n\t\t|| !stricmp(comp, \"XVID\") /*XviD*/\n\t\t|| !stricmp(comp, \"3iv2\") /*3ivX*/\n\t\t|| !stricmp(comp, \"fvfw\") /*ffmpeg*/\n\t\t|| !stricmp(comp, \"NDIG\") /*nero*/\n\t\t|| !stricmp(comp, \"MP4V\") /*!! not tested*/\n\t\t|| !stricmp(comp, \"M4CC\") /*Divio - not tested*/\n\t\t|| !stricmp(comp, \"PVMM\") /*PacketVideo - not tested*/\n\t\t|| !stricmp(comp, \"SEDG\") /*Samsung - not tested*/\n\t\t|| !stricmp(comp, \"RMP4\") /*Sigma - not tested*/\n\t\t|| !stricmp(comp, \"MP43\") /*not tested*/\n\t\t|| !stricmp(comp, \"FMP4\") /*not tested*/\n\t\t|| !stricmp(comp, \"VP6F\") /*not tested*/\n\t) {\n\t\tcodecid = GF_CODECID_MPEG4_PART2;\n\t} else if ( !stricmp(comp, \"H264\") /*not tested*/\n\t\t|| !stricmp(comp, \"X264\") /*not tested*/\n\t) {\n\t\tcodecid = GF_CODECID_AVC;\n\t} else if ( !stricmp(comp, \"avc1\") ) {\n\t\tcodecid = GF_CODECID_AVC;\n\t\tunframed = GF_FALSE;\n\t} else if (!stricmp(comp, \"DIV3\") || !stricmp(comp, \"DIV4\")) {\n//\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Video format %s not compliant with MPEG-4 Visual - please recompress the file first\\n\", comp));\n\t\tcodecid = GF_CODECID_MSPEG4_V3;\n\t\tunframed = GF_FALSE;\n\t} else if (!comp[0]) {\n\t\tcodecid = GF_CODECID_RAW;\n\t\tpfmt = GF_PIXEL_BGR;\n\t} else {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[AVIDmx] Video format %s not natively supported, signaling as is\\n\", comp));\n\t\tcodecid = gf_4cc_parse(comp);\n\t\tunframed = GF_FALSE;\n\t}\n\n\tctx->v_in_use = GF_FALSE;\n\tif (codecid) {\n\t\tu32 w, h;\n\t\tif (!ctx->v_opid) {\n\t\t\tctx->v_opid = gf_filter_pid_new(filter);\n\t\t}\n\t\tctx->nb_frames = (u32) AVI_video_frames(ctx->avi);\n\t\tctx->cur_frame = 0;\n\t\tsync_id = 1;\n\t\tctx->v_in_use = GF_TRUE;\n\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_STREAM_TYPE, &PROP_UINT(GF_STREAM_VISUAL) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_CODECID, &PROP_UINT(codecid) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_TIMESCALE, &PROP_UINT(ctx->fps.num) );\n\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_ID, &PROP_UINT( sync_id) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_CLOCK_ID, &PROP_UINT( sync_id ) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_FPS, &PROP_FRAC( ctx->fps ) );\n\t\tw = AVI_video_width(ctx->avi);\n\t\th = AVI_video_height(ctx->avi);\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_WIDTH, &PROP_UINT( w ) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_HEIGHT, &PROP_UINT( h ) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_DURATION, &PROP_FRAC64( dur ) );\n\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_PLAYBACK_MODE, &PROP_UINT(GF_PLAYBACK_MODE_FASTFORWARD ) );\n\n\t\tif (pfmt) {\n\t\t\tu32 stride=0;\n\t\t\tgf_pixel_get_size_info(pfmt, w, h, NULL, &stride, NULL, NULL, NULL);\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_STRIDE, &PROP_UINT( stride ) );\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_PIXFMT, &PROP_UINT( pfmt ) );\n\t\t} else if (unframed) {\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_UNFRAMED, &PROP_BOOL(GF_TRUE) );\n\t\t\tgf_filter_pid_set_property_str(ctx->v_opid, \"nocts\", &PROP_BOOL( GF_TRUE ) );\n\t\t} else if (ctx->avi->extradata_size && ctx->avi->extradata) {\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_DECODER_CONFIG, &PROP_DATA(ctx->avi->extradata, ctx->avi->extradata_size) );\n\t\t}\n\t\tif (ctx->noreframe)\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_UNFRAMED, NULL);\n\t}\n\n\tunframed = GF_FALSE;\n\tcount = AVI_audio_tracks(ctx->avi);\n\tfor (i=0; i<count; i++) {\n\t\tu32 a_fmt, afmt=0, nb_bits;\n\t\tAVI_set_audio_track(ctx->avi, i);\n\n\t\tcodecid = 0;\n\t\ta_fmt = AVI_audio_format(ctx->avi);\n\t\tnb_bits = AVI_audio_bits(ctx->avi);\n\t\tswitch (a_fmt) {\n\t\tcase WAVE_FORMAT_PCM:\n\t\tcase GF_4CC('P','C','M',' '):\n\t\t\tcodecid = GF_CODECID_RAW;\n\t\t\tswitch (nb_bits) {\n\t\t\tcase 8:\n\t\t\t\tafmt = GF_AUDIO_FMT_U8;\n\t\t\t\tbreak;\n\t\t\tcase 16:\n\t\t\t\tafmt = GF_AUDIO_FMT_S16;\n\t\t\t\tbreak;\n\t\t\tcase 24:\n\t\t\t\tafmt = GF_AUDIO_FMT_S24;\n\t\t\t\tbreak;\n\t\t\tcase 32:\n\t\t\t\tafmt = GF_AUDIO_FMT_S32;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Audio bit depth %d not mapped, patch welcome\\n\", nb_bits));\n\t\t\t\tafmt = GF_AUDIO_FMT_S16;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_ADPCM:\n\t\t\tcodecid = GF_CODECID_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_IBM_CVSD:\n\t\t\tcodecid = GF_CODECID_IBM_CVSD;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_ALAW:\n\t\t\tcodecid = GF_CODECID_ALAW;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_MULAW:\n\t\t\tcodecid = GF_CODECID_MULAW;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_OKI_ADPCM:\n\t\t\tcodecid = GF_CODECID_OKI_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_DVI_ADPCM:\n\t\t\tcodecid = GF_CODECID_DVI_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_DIGISTD:\n\t\t\tcodecid = GF_CODECID_DIGISTD;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_YAMAHA_ADPCM:\n\t\t\tcodecid = GF_CODECID_YAMAHA_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_DSP_TRUESPEECH:\n\t\t\tcodecid = GF_CODECID_DSP_TRUESPEECH;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_GSM610:\n\t\t\tcodecid = GF_CODECID_GSM610;\n\t\t\tbreak;\n\t\tcase IBM_FORMAT_MULAW:\n\t\t\tcodecid = GF_CODECID_IBM_MULAW;\n\t\t\tbreak;\n\t\tcase IBM_FORMAT_ALAW:\n\t\t\tcodecid = GF_CODECID_IBM_ALAW;\n\t\t\tbreak;\n\t\tcase IBM_FORMAT_ADPCM:\n\t\t\tcodecid = GF_CODECID_IBM_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_MP3:\n\t\t\tcodecid = GF_CODECID_MPEG_AUDIO;\n\t\t\tunframed = GF_TRUE;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_AAC_ADTS:\n\t\t\tcodecid = GF_CODECID_AAC_MPEG4;\n\t\t\tunframed = GF_TRUE;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_AAC:\n\t\t\tcodecid = GF_CODECID_AAC_MPEG4;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_AC3:\n\t\t\tcodecid = GF_CODECID_AC3;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Audio format %d not supported, patch welcome\\n\", a_fmt));\n\t\t\tbreak;\n\t\t}\n\n\t\tif (codecid) {\n\t\t\tAVIAstream *st = NULL;\n\t\t\tu32 brate, j, c  = gf_list_count(ctx->audios);\n\t\t\tfor (j=0; j<c; j++) {\n\t\t\t\tst = gf_list_get(ctx->audios, j);\n\t\t\t\tif (!st->in_use) break;\n\t\t\t\tst = NULL;\n\t\t\t}\n\t\t\tif (!st) {\n\t\t\t\tGF_SAFEALLOC(st, AVIAstream);\n\t\t\t\tif (!st) continue;\n\t\t\t\tst->opid = gf_filter_pid_new(filter);\n\t\t\t\tgf_list_add(ctx->audios, st);\n\t\t\t}\n\t\t\tst->in_use = GF_TRUE;\n\t\t\tst->stream_num = i;\n\t\t\tif (!sync_id) sync_id = 2 + st->stream_num;\n\t\t\tst->audio_done = GF_FALSE;\n\n\t\t\tif (codecid==GF_CODECID_MPEG_AUDIO) {\n\t\t\t\tu32 cid=0;\n\t\t\t\tchar data[8];\n\t\t\t\tAVI_set_audio_track(ctx->avi, i);\n\t\t\t\tAVI_read_audio(ctx->avi, data, 8, (int*)&cid);\n#ifndef GPAC_DISABLE_AV_PARSERS\n\t\t\t\tu32 hdr = GF_4CC(data[0], data[1], data[2], data[3]);\n\t\t\t\tcid = gf_mp3_object_type_indication(hdr);\n#endif\n\t\t\t\tAVI_set_audio_position(ctx->avi, 0);\n\t\t\t\tif (cid) codecid = cid;\n\t\t\t}\n\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_STREAM_TYPE, &PROP_UINT(GF_STREAM_AUDIO) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_CODECID, &PROP_UINT( codecid) );\n\t\t\tst->freq = AVI_audio_rate(ctx->avi);\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_SAMPLE_RATE, &PROP_UINT( st->freq ) );\n\t\t\tst->nb_channels = AVI_audio_channels(ctx->avi);\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_NUM_CHANNELS, &PROP_UINT( st->nb_channels ) );\n\t\t\tbrate = AVI_audio_mp3rate(ctx->avi);\n\t\t\t//for mp3 and aac\n\t\t\tif (brate && (unframed || (codecid == GF_CODECID_AAC_MPEG4)))\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_BITRATE, &PROP_UINT( brate ) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_ID, &PROP_UINT( 2 + st->stream_num) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_CLOCK_ID, &PROP_UINT( sync_id ) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_DURATION, &PROP_FRAC64( dur ) );\n\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_PLAYBACK_MODE, &PROP_UINT(GF_PLAYBACK_MODE_FASTFORWARD ) );\n\t\t\tst->audio_bps = 0;\n\t\t\tif (unframed) {\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_UNFRAMED, &PROP_BOOL( GF_TRUE ) );\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_TIMESCALE, &PROP_UINT(st->freq) );\n\t\t\t} else {\n\t\t\t\tif (afmt) {\n\t\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_AUDIO_FORMAT, &PROP_UINT(afmt) );\n\t\t\t\t}\n\t\t\t\tst->audio_bps = AVI_audio_bits(ctx->avi);\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_TIMESCALE, &PROP_UINT(st->freq) );\n\n\t\t\t\tif (codecid == GF_CODECID_AAC_MPEG4) {\n#ifndef GPAC_DISABLE_AV_PARSERS\n\t\t\t\t\tGF_M4ADecSpecInfo acfg;\n\t\t\t\t\tu8 *dsi=NULL;\n\t\t\t\t\tu32 dsi_len=0;\n\t\t\t\t\tmemset(&acfg, 0, sizeof(GF_M4ADecSpecInfo));\n\t\t\t\t\tacfg.base_object_type = GF_M4A_AAC_LC;\n\t\t\t\t\tacfg.base_sr = st->freq;\n\t\t\t\t\tacfg.nb_chan = st->nb_channels;\n\t\t\t\t\tacfg.sbr_object_type = 0;\n\t\t\t\t\tacfg.audioPL = gf_m4a_get_profile(&acfg);\n\t\t\t\t\tgf_m4a_write_config(&acfg, &dsi, &dsi_len);\n\t\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_DECODER_CONFIG, &PROP_DATA_NO_COPY(dsi, dsi_len) );\n#endif\n\t\t\t\t\tst->audio_bps = 0;\n\t\t\t\t\tst->is_aac = GF_TRUE;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (ctx->noreframe)\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_UNFRAMED, NULL);\n\t\t}\n\t}\n}",
        "func": "static void avidmx_setup(GF_Filter *filter, GF_AVIDmxCtx *ctx)\n{\n\tu32 sync_id = 0;\n\tu32 codecid = 0;\n\tBool unframed;\n\tu32 i, count, pfmt=0;\n\tGF_Fraction64 dur;\n\tchar *comp;\n\n\tif (ctx->use_file_fps) {\n\t\tDouble fps = AVI_frame_rate(ctx->avi);\n\t\tgf_media_get_video_timing(fps, &ctx->fps.num, &ctx->fps.den);\n\t\tif (!ctx->fps.num) ctx->fps.num = ctx->fps.den = 1000;\n\t}\n\n\tdur.den = ctx->fps.num;\n\tdur.num = (u64) (ctx->fps.den * AVI_video_frames(ctx->avi));\n\n\tunframed = GF_TRUE;\n\tcomp = AVI_video_compressor(ctx->avi);\n\tif (!comp) {\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Cannot retrieve video compressor name, ignoring video stream\\n\"));\n\t}\n\t/*these are/should be OK*/\n\telse if (!stricmp(comp, \"DIVX\") || !stricmp(comp, \"DX50\")\t/*DivX*/\n\t\t|| !stricmp(comp, \"XVID\") /*XviD*/\n\t\t|| !stricmp(comp, \"3iv2\") /*3ivX*/\n\t\t|| !stricmp(comp, \"fvfw\") /*ffmpeg*/\n\t\t|| !stricmp(comp, \"NDIG\") /*nero*/\n\t\t|| !stricmp(comp, \"MP4V\") /*!! not tested*/\n\t\t|| !stricmp(comp, \"M4CC\") /*Divio - not tested*/\n\t\t|| !stricmp(comp, \"PVMM\") /*PacketVideo - not tested*/\n\t\t|| !stricmp(comp, \"SEDG\") /*Samsung - not tested*/\n\t\t|| !stricmp(comp, \"RMP4\") /*Sigma - not tested*/\n\t\t|| !stricmp(comp, \"MP43\") /*not tested*/\n\t\t|| !stricmp(comp, \"FMP4\") /*not tested*/\n\t\t|| !stricmp(comp, \"VP6F\") /*not tested*/\n\t) {\n\t\tcodecid = GF_CODECID_MPEG4_PART2;\n\t} else if ( !stricmp(comp, \"H264\") /*not tested*/\n\t\t|| !stricmp(comp, \"X264\") /*not tested*/\n\t) {\n\t\tcodecid = GF_CODECID_AVC;\n\t} else if ( !stricmp(comp, \"avc1\") ) {\n\t\tcodecid = GF_CODECID_AVC;\n\t\tunframed = GF_FALSE;\n\t} else if (!stricmp(comp, \"DIV3\") || !stricmp(comp, \"DIV4\")) {\n//\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Video format %s not compliant with MPEG-4 Visual - please recompress the file first\\n\", comp));\n\t\tcodecid = GF_CODECID_MSPEG4_V3;\n\t\tunframed = GF_FALSE;\n\t} else if (!comp[0]) {\n\t\tcodecid = GF_CODECID_RAW;\n\t\tpfmt = GF_PIXEL_BGR;\n\t} else {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[AVIDmx] Video format %s not natively supported, signaling as is\\n\", comp));\n\t\tcodecid = gf_4cc_parse(comp);\n\t\tunframed = GF_FALSE;\n\t}\n\n\tctx->v_in_use = GF_FALSE;\n\tif (codecid) {\n\t\tu32 w, h;\n\t\tif (!ctx->v_opid) {\n\t\t\tctx->v_opid = gf_filter_pid_new(filter);\n\t\t}\n\t\tctx->nb_frames = (u32) AVI_video_frames(ctx->avi);\n\t\tctx->cur_frame = 0;\n\t\tsync_id = 1;\n\t\tctx->v_in_use = GF_TRUE;\n\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_STREAM_TYPE, &PROP_UINT(GF_STREAM_VISUAL) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_CODECID, &PROP_UINT(codecid) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_TIMESCALE, &PROP_UINT(ctx->fps.num) );\n\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_ID, &PROP_UINT( sync_id) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_CLOCK_ID, &PROP_UINT( sync_id ) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_FPS, &PROP_FRAC( ctx->fps ) );\n\t\tw = AVI_video_width(ctx->avi);\n\t\th = AVI_video_height(ctx->avi);\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_WIDTH, &PROP_UINT( w ) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_HEIGHT, &PROP_UINT( h ) );\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_DURATION, &PROP_FRAC64( dur ) );\n\n\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_PLAYBACK_MODE, &PROP_UINT(GF_PLAYBACK_MODE_FASTFORWARD ) );\n\n\t\tif (pfmt) {\n\t\t\tu32 stride=0;\n\t\t\tgf_pixel_get_size_info(pfmt, w, h, NULL, &stride, NULL, NULL, NULL);\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_STRIDE, &PROP_UINT( stride ) );\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_PIXFMT, &PROP_UINT( pfmt ) );\n\t\t} else if (unframed) {\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_UNFRAMED, &PROP_BOOL(GF_TRUE) );\n\t\t\tgf_filter_pid_set_property_str(ctx->v_opid, \"nocts\", &PROP_BOOL( GF_TRUE ) );\n\t\t} else if (ctx->avi->extradata_size && ctx->avi->extradata) {\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_DECODER_CONFIG, &PROP_DATA(ctx->avi->extradata, ctx->avi->extradata_size) );\n\t\t}\n\t\tif (ctx->noreframe)\n\t\t\tgf_filter_pid_set_property(ctx->v_opid, GF_PROP_PID_UNFRAMED, NULL);\n\t}\n\n\tunframed = GF_FALSE;\n\tcount = AVI_audio_tracks(ctx->avi);\n\tfor (i=0; i<count; i++) {\n\t\tu32 a_fmt, afmt=0, nb_bits;\n\t\tAVI_set_audio_track(ctx->avi, i);\n\n\t\tcodecid = 0;\n\t\ta_fmt = AVI_audio_format(ctx->avi);\n\t\tnb_bits = AVI_audio_bits(ctx->avi);\n\t\tswitch (a_fmt) {\n\t\tcase WAVE_FORMAT_PCM:\n\t\tcase GF_4CC('P','C','M',' '):\n\t\t\tcodecid = GF_CODECID_RAW;\n\t\t\tswitch (nb_bits) {\n\t\t\tcase 8:\n\t\t\t\tafmt = GF_AUDIO_FMT_U8;\n\t\t\t\tbreak;\n\t\t\tcase 16:\n\t\t\t\tafmt = GF_AUDIO_FMT_S16;\n\t\t\t\tbreak;\n\t\t\tcase 24:\n\t\t\t\tafmt = GF_AUDIO_FMT_S24;\n\t\t\t\tbreak;\n\t\t\tcase 32:\n\t\t\t\tafmt = GF_AUDIO_FMT_S32;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Audio bit depth %d not mapped, patch welcome\\n\", nb_bits));\n\t\t\t\tafmt = GF_AUDIO_FMT_S16;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_ADPCM:\n\t\t\tcodecid = GF_CODECID_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_IBM_CVSD:\n\t\t\tcodecid = GF_CODECID_IBM_CVSD;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_ALAW:\n\t\t\tcodecid = GF_CODECID_ALAW;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_MULAW:\n\t\t\tcodecid = GF_CODECID_MULAW;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_OKI_ADPCM:\n\t\t\tcodecid = GF_CODECID_OKI_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_DVI_ADPCM:\n\t\t\tcodecid = GF_CODECID_DVI_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_DIGISTD:\n\t\t\tcodecid = GF_CODECID_DIGISTD;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_YAMAHA_ADPCM:\n\t\t\tcodecid = GF_CODECID_YAMAHA_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_DSP_TRUESPEECH:\n\t\t\tcodecid = GF_CODECID_DSP_TRUESPEECH;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_GSM610:\n\t\t\tcodecid = GF_CODECID_GSM610;\n\t\t\tbreak;\n\t\tcase IBM_FORMAT_MULAW:\n\t\t\tcodecid = GF_CODECID_IBM_MULAW;\n\t\t\tbreak;\n\t\tcase IBM_FORMAT_ALAW:\n\t\t\tcodecid = GF_CODECID_IBM_ALAW;\n\t\t\tbreak;\n\t\tcase IBM_FORMAT_ADPCM:\n\t\t\tcodecid = GF_CODECID_IBM_ADPCM;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_MP3:\n\t\t\tcodecid = GF_CODECID_MPEG_AUDIO;\n\t\t\tunframed = GF_TRUE;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_AAC_ADTS:\n\t\t\tcodecid = GF_CODECID_AAC_MPEG4;\n\t\t\tunframed = GF_TRUE;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_AAC:\n\t\t\tcodecid = GF_CODECID_AAC_MPEG4;\n\t\t\tbreak;\n\t\tcase WAVE_FORMAT_AC3:\n\t\t\tcodecid = GF_CODECID_AC3;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AVIDmx] Audio format %d not supported, patch welcome\\n\", a_fmt));\n\t\t\tbreak;\n\t\t}\n\n\t\tif (codecid) {\n\t\t\tAVIAstream *st = NULL;\n\t\t\tu32 brate, j, c  = gf_list_count(ctx->audios);\n\t\t\tfor (j=0; j<c; j++) {\n\t\t\t\tst = gf_list_get(ctx->audios, j);\n\t\t\t\tif (!st->in_use) break;\n\t\t\t\tst = NULL;\n\t\t\t}\n\t\t\tif (!st) {\n\t\t\t\tGF_SAFEALLOC(st, AVIAstream);\n\t\t\t\tif (!st) continue;\n\t\t\t\tst->opid = gf_filter_pid_new(filter);\n\t\t\t\tgf_list_add(ctx->audios, st);\n\t\t\t}\n\t\t\tst->in_use = GF_TRUE;\n\t\t\tst->stream_num = i;\n\t\t\tif (!sync_id) sync_id = 2 + st->stream_num;\n\t\t\tst->audio_done = GF_FALSE;\n\n\t\t\tif (codecid==GF_CODECID_MPEG_AUDIO) {\n\t\t\t\tu32 cid=0;\n\t\t\t\tchar data[8];\n\t\t\t\tAVI_set_audio_track(ctx->avi, i);\n\t\t\t\tAVI_read_audio(ctx->avi, data, 8, (int*)&cid);\n#ifndef GPAC_DISABLE_AV_PARSERS\n\t\t\t\tu32 hdr = GF_4CC(data[0], data[1], data[2], data[3]);\n\t\t\t\tcid = gf_mp3_object_type_indication(hdr);\n#endif\n\t\t\t\tAVI_set_audio_position(ctx->avi, 0);\n\t\t\t\tif (cid) codecid = cid;\n\t\t\t}\n\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_STREAM_TYPE, &PROP_UINT(GF_STREAM_AUDIO) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_CODECID, &PROP_UINT( codecid) );\n\t\t\tst->freq = AVI_audio_rate(ctx->avi);\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_SAMPLE_RATE, &PROP_UINT( st->freq ) );\n\t\t\tst->nb_channels = AVI_audio_channels(ctx->avi);\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_NUM_CHANNELS, &PROP_UINT( st->nb_channels ) );\n\t\t\tbrate = AVI_audio_mp3rate(ctx->avi);\n\t\t\t//for mp3 and aac\n\t\t\tif (brate && (unframed || (codecid == GF_CODECID_AAC_MPEG4)))\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_BITRATE, &PROP_UINT( brate ) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_ID, &PROP_UINT( 2 + st->stream_num) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_CLOCK_ID, &PROP_UINT( sync_id ) );\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_DURATION, &PROP_FRAC64( dur ) );\n\n\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_PLAYBACK_MODE, &PROP_UINT(GF_PLAYBACK_MODE_FASTFORWARD ) );\n\t\t\tst->audio_bps = 0;\n\t\t\tif (unframed) {\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_UNFRAMED, &PROP_BOOL( GF_TRUE ) );\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_TIMESCALE, &PROP_UINT(st->freq) );\n\t\t\t} else {\n\t\t\t\tif (afmt) {\n\t\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_AUDIO_FORMAT, &PROP_UINT(afmt) );\n\t\t\t\t}\n\t\t\t\tst->audio_bps = AVI_audio_bits(ctx->avi);\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_TIMESCALE, &PROP_UINT(st->freq) );\n\n\t\t\t\tif (codecid == GF_CODECID_AAC_MPEG4) {\n#ifndef GPAC_DISABLE_AV_PARSERS\n\t\t\t\t\tGF_M4ADecSpecInfo acfg;\n\t\t\t\t\tu8 *dsi=NULL;\n\t\t\t\t\tu32 dsi_len=0;\n\t\t\t\t\tmemset(&acfg, 0, sizeof(GF_M4ADecSpecInfo));\n\t\t\t\t\tacfg.base_object_type = GF_M4A_AAC_LC;\n\t\t\t\t\tacfg.base_sr = st->freq;\n\t\t\t\t\tacfg.nb_chan = st->nb_channels;\n\t\t\t\t\tacfg.sbr_object_type = 0;\n\t\t\t\t\tacfg.audioPL = gf_m4a_get_profile(&acfg);\n\t\t\t\t\tgf_m4a_write_config(&acfg, &dsi, &dsi_len);\n\t\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_DECODER_CONFIG, &PROP_DATA_NO_COPY(dsi, dsi_len) );\n#endif\n\t\t\t\t\tst->audio_bps = 0;\n\t\t\t\t\tst->is_aac = GF_TRUE;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (ctx->noreframe)\n\t\t\t\tgf_filter_pid_set_property(st->opid, GF_PROP_PID_UNFRAMED, NULL);\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,7 @@\n \tif (ctx->use_file_fps) {\n \t\tDouble fps = AVI_frame_rate(ctx->avi);\n \t\tgf_media_get_video_timing(fps, &ctx->fps.num, &ctx->fps.den);\n+\t\tif (!ctx->fps.num) ctx->fps.num = ctx->fps.den = 1000;\n \t}\n \n \tdur.den = ctx->fps.num;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (!ctx->fps.num) ctx->fps.num = ctx->fps.den = 1000;"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4678",
        "func_name": "gpac/mhas_dmx_process",
        "description": "Divide By Zero in GitHub repository gpac/gpac prior to 2.3-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4607052c482a51dbdacfe1ade10645c181d07b07",
        "commit_title": "fixed #2576",
        "commit_text": "",
        "func_before": "GF_Err mhas_dmx_process(GF_Filter *filter)\n{\n\tGF_MHASDmxCtx *ctx = gf_filter_get_udta(filter);\n\tGF_FilterPacket *in_pck;\n\tu8 *output;\n\tu8 *start;\n\tBool final_flush=GF_FALSE;\n\tu32 pck_size, remain, prev_pck_size;\n\tu64 cts = GF_FILTER_NO_TS;\n\tu32 au_start = 0;\n\tu32 consumed = 0;\n\tu32 nb_trunc_samples = 0;\n\tBool trunc_from_begin = 0;\n\tBool has_cfg = 0;\n\n\t//always reparse duration\n\tif (!ctx->duration.num)\n\t\tmhas_dmx_check_dur(filter, ctx);\n\n\tif (ctx->opid && !ctx->is_playing)\n\t\treturn GF_OK;\n\n\tin_pck = gf_filter_pid_get_packet(ctx->ipid);\n\tif (!in_pck) {\n\t\tif (gf_filter_pid_is_eos(ctx->ipid)) {\n\t\t\tif (!ctx->mhas_buffer_size) {\n\t\t\t\tif (ctx->opid)\n\t\t\t\t\tgf_filter_pid_set_eos(ctx->opid);\n\t\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\t\tctx->src_pck = NULL;\n\t\t\t\treturn GF_EOS;\n\t\t\t}\n\t\t\tfinal_flush = GF_TRUE;\n\t\t} else if (!ctx->resume_from) {\n\t\t\treturn GF_OK;\n\t\t}\n\t}\n\n\tprev_pck_size = ctx->mhas_buffer_size;\n\tif (ctx->resume_from)\n\t\tin_pck = NULL;\n\n\tif (in_pck) {\n\t\tu8 *data = (u8 *) gf_filter_pck_get_data(in_pck, &pck_size);\n\n\t\tif (ctx->byte_offset != GF_FILTER_NO_BO) {\n\t\t\tu64 byte_offset = gf_filter_pck_get_byte_offset(in_pck);\n\t\t\tif (!ctx->mhas_buffer_size) {\n\t\t\t\tctx->byte_offset = byte_offset;\n\t\t\t} else if (ctx->byte_offset + ctx->mhas_buffer_size != byte_offset) {\n\t\t\t\tctx->byte_offset = GF_FILTER_NO_BO;\n\t\t\t\tif ((byte_offset != GF_FILTER_NO_BO) && (byte_offset>ctx->mhas_buffer_size) ) {\n\t\t\t\t\tctx->byte_offset = byte_offset - ctx->mhas_buffer_size;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (ctx->mhas_buffer_size + pck_size > ctx->mhas_buffer_alloc) {\n\t\t\tctx->mhas_buffer_alloc = ctx->mhas_buffer_size + pck_size;\n\t\t\tctx->mhas_buffer = gf_realloc(ctx->mhas_buffer, ctx->mhas_buffer_alloc);\n\t\t}\n\t\tmemcpy(ctx->mhas_buffer + ctx->mhas_buffer_size, data, pck_size);\n\t\tctx->mhas_buffer_size += pck_size;\n\t}\n\n\t//input pid sets some timescale - we flushed pending data , update cts\n\tif (ctx->timescale && in_pck) {\n\t\tcts = gf_filter_pck_get_cts(in_pck);\n\t\t//init cts at first packet\n\t\tif (!ctx->cts && (cts != GF_FILTER_NO_TS))\n\t\t\tctx->cts = cts;\n\t}\n\n\tif (cts == GF_FILTER_NO_TS) {\n\t\t//avoids updating cts\n\t\tprev_pck_size = 0;\n\t}\n\n\tremain = ctx->mhas_buffer_size;\n\tstart = ctx->mhas_buffer;\n\n\tif (ctx->resume_from) {\n\t\tstart += ctx->resume_from - 1;\n\t\tremain -= ctx->resume_from - 1;\n\t\tctx->resume_from = 0;\n\t}\n\n\twhile (ctx->nosync && (remain>3)) {\n\t\t//wait till we have a frame header\n\t\tu8 *hdr_start = memchr(start, 0xC0, remain);\n\t\tif (!hdr_start) {\n\t\t\tremain=0;\n\t\t\tbreak;\n\t\t}\n\t\tif ((hdr_start[1]==0x01) && (hdr_start[2]==0xA5)) {\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] Sync found !\\n\"));\n\t\t\tctx->nosync = GF_FALSE;\n\t\t\tbreak;\n\t\t}\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] not sync, skipping byte\\n\"));\n\t\tstart++;\n\t\tremain--;\n\t}\n\tif (ctx->nosync)\n\t\tgoto skip;\n\n\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\tctx->buffer_too_small = GF_FALSE;\n\n\t//MHAS packet\n\twhile (remain > consumed) {\n\t\tu32 pay_start, parse_end, mhas_size, mhas_label;\n\t\tBool mhas_sap = 0;\n\t\tu32 mhas_type;\n\t\tif (!ctx->is_playing && ctx->opid) {\n\t\t\tctx->resume_from = 1;\n\t\t\tconsumed = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tmhas_type = (u32) gf_mpegh_escaped_value(ctx->bs, 3, 8, 8);\n\t\tmhas_label = (u32) gf_mpegh_escaped_value(ctx->bs, 2, 8, 32);\n\t\tmhas_size = (u32) gf_mpegh_escaped_value(ctx->bs, 11, 24, 24);\n\n\t\tif (ctx->buffer_too_small)\n\t\t\tbreak;\n\n\n\t\tif (mhas_type>18) {\n\t\t\tctx->nb_unknown_pck++;\n\t\t\tif (ctx->nb_unknown_pck > ctx->pcksync) {\n\t\t\t\tGF_LOG(ctx->is_sync ? GF_LOG_WARNING : GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] %d packets of unknown type, considering sync was lost\\n\"));\n\t\t\t\tctx->is_sync = GF_FALSE;\n\t\t\t\tconsumed = 0;\n\t\t\t\tctx->nosync = GF_TRUE;\n\t\t\t\tctx->nb_unknown_pck = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (!mhas_size) {\n\t\t\tGF_LOG(ctx->is_sync ? GF_LOG_WARNING : GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] MHAS packet with 0 payload size, considering sync was lost\\n\"));\n\t\t\tctx->is_sync = GF_FALSE;\n\t\t\tconsumed = 0;\n\t\t\tctx->nosync = GF_TRUE;\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tpay_start = (u32) gf_bs_get_position(ctx->bs);\n\n\t\tif (ctx->buffer_too_small) break;\n\t\tif (mhas_size > gf_bs_available(ctx->bs)) {\n\t\t\t//incomplete frame, keep in buffer\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] incomplete packet type %d %s label \"LLU\" size \"LLU\" - keeping in buffer\\n\", mhas_type, mhas_pck_name(mhas_type), mhas_label, mhas_size));\n\t\t\tbreak;\n\t\t}\n\t\tctx->is_sync = GF_TRUE;\n\n\t\t//frame\n\t\tif (mhas_type==2) {\n\t\t\tmhas_sap = gf_bs_peek_bits(ctx->bs, 1, 0);\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t}\n\t\t//config\n\t\telse if (mhas_type==1) {\n\t\t\ts32 CICPspeakerLayoutIdx = -1;\n\t\t\ts32 numSpeakers = -1;\n\t\t\tu32 sr = 0;\n\t\t\tu32 frame_len;\n\t\t\tu32 pl = gf_bs_read_u8(ctx->bs);\n\t\t\tu32 idx = gf_bs_read_int(ctx->bs, 5);\n\t\t\tif (idx==0x1f)\n\t\t\t\tsr = gf_bs_read_int(ctx->bs, 24);\n\t\t\telse if (idx < nb_usac_sr) {\n\t\t\t\tsr = USACSampleRates[idx];\n\t\t\t}\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t\tidx = gf_bs_read_int(ctx->bs, 3);\n\t\t\tif ((idx==0) || (idx==2) ) frame_len = 768;\n\t\t\telse frame_len = 1024;\n\t\t\tgf_bs_read_int(ctx->bs, 1);\n\t\t\tgf_bs_read_int(ctx->bs, 1);\n\n\t\t\t//speaker config\n\t\t\tu32 speakerLayoutType = gf_bs_read_int(ctx->bs, 2);\n\t\t\tif (speakerLayoutType == 0) {\n\t\t\t\tCICPspeakerLayoutIdx = gf_bs_read_int(ctx->bs, 6);\n\t\t\t} else {\n\t\t\t\tnumSpeakers = (s32) gf_mpegh_escaped_value(ctx->bs, 5, 8, 16) + 1;\n\t\t\t\t//TODO ...\n\t\t\t}\n\n\t\t\tmhas_dmx_check_pid(filter, ctx, pl, sr, frame_len, CICPspeakerLayoutIdx, numSpeakers, start + pay_start, (u32) mhas_size);\n\n\t\t\thas_cfg = GF_TRUE;\n\t\t}\n\t\t//audio truncation\n\t\telse if (mhas_type==17) {\n\t\t\tBool isActive = gf_bs_read_int(ctx->bs, 1);\n\t\t\t/*Bool ati_reserved = */gf_bs_read_int(ctx->bs, 1);\n\t\t\ttrunc_from_begin = gf_bs_read_int(ctx->bs, 1);\n\t\t\tnb_trunc_samples = gf_bs_read_int(ctx->bs, 13);\n\t\t\tif (!isActive) {\n\t\t\t\tnb_trunc_samples = 0;\n\t\t\t}\n\t\t}\n\t\t//sync, syncgap\n\t\telse if ((mhas_type==6) || (mhas_type==7)) {\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t}\n#if 0\n\t\t//MARKER\n\t\telse if (mhas_type==8) {\n\t\t\tu8 marker_type = gf_bs_read_u8(ctx->bs);\n\t\t\t//config reload force\n\t\t\tif (marker_type==0x01) {}\n\t\t\t//SAP\n\t\t\telse if (marker_type==0x02) {\n\t\t\t\thas_marker = GF_TRUE;\n\t\t\t}\n\t\t}\n#endif\n\n\t\tgf_bs_align(ctx->bs);\n\t\tparse_end = (u32) gf_bs_get_position(ctx->bs) - pay_start;\n\t\t//remaining of packet payload\n\t\tgf_bs_skip_bytes(ctx->bs, mhas_size - parse_end);\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] MHAS Packet type %d %s label \"LLU\" size \"LLU\"\\n\", mhas_type, mhas_pck_name(mhas_type), mhas_label, mhas_size));\n\n\t\tif (ctx->timescale && !prev_pck_size && (cts != GF_FILTER_NO_TS) ) {\n\t\t\tctx->cts = cts;\n\t\t\tcts = GF_FILTER_NO_TS;\n\t\t}\n\n\t\t//frame\n\t\tif ((mhas_type==2) && ctx->opid) {\n\t\t\tGF_FilterPacket *dst;\n\t\t\tu64 pck_dur = ctx->frame_len;\n\n\n\t\t\tu32 au_size;\n\t\t\tif (ctx->mpha) {\n\t\t\t\tau_start = pay_start;\n\t\t\t\tau_size = mhas_size;\n\t\t\t} else {\n\t\t\t\tau_size = (u32) gf_bs_get_position(ctx->bs) - au_start;\n\t\t\t}\n\n\t\t\tif (nb_trunc_samples) {\n\t\t\t\tif (trunc_from_begin) {\n\t\t\t\t\tif (!ctx->nb_frames) {\n\t\t\t\t\t\ts64 offset = trunc_from_begin;\n\t\t\t\t\t\tif (ctx->timescale) {\n\t\t\t\t\t\t\toffset *= ctx->timescale;\n\t\t\t\t\t\t\toffset /= ctx->sample_rate;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tgf_filter_pid_set_property(ctx->opid, GF_PROP_PID_DELAY , &PROP_LONGSINT( -offset));\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tpck_dur -= nb_trunc_samples;\n\t\t\t\t}\n\t\t\t\tnb_trunc_samples = 0;\n\t\t\t}\n\n\t\t\tif (ctx->timescale) {\n\t\t\t\tpck_dur = gf_timestamp_rescale(pck_dur, ctx->sample_rate, ctx->timescale);\n\t\t\t}\n\n\t\t\tdst = gf_filter_pck_new_alloc(ctx->opid, au_size, &output);\n\t\t\tif (!dst) break;\n\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst);\n\n\t\t\tmemcpy(output, start + au_start, au_size);\n\t\t\tif (!has_cfg)\n\t\t\t\tmhas_sap = 0;\n\n\t\t\tif (mhas_sap) {\n\t\t\t\tgf_filter_pck_set_sap(dst, GF_FILTER_SAP_1);\n\t\t\t}\n\t\t\tgf_filter_pck_set_dts(dst, ctx->cts);\n\t\t\tgf_filter_pck_set_cts(dst, ctx->cts);\n\t\t\tgf_filter_pck_set_duration(dst, (u32) pck_dur);\n\t\t\tif (ctx->byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tu64 offset = (u64) (start - ctx->mhas_buffer);\n\t\t\t\toffset += ctx->byte_offset + au_start;\n\t\t\t\tgf_filter_pck_set_byte_offset(dst, offset);\n\t\t\t}\n \t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] Send AU CTS \"LLU\" size %d dur %d sap %d\\n\", ctx->cts, au_size, (u32) pck_dur, mhas_sap));\n\t\t\tgf_filter_pck_send(dst);\n\n\t\t\tau_start += au_size;\n\t\t\tconsumed = au_start;\n\t\t\tctx->nb_frames ++;\n\n\t\t\tmhas_dmx_update_cts(ctx);\n\t\t\thas_cfg = 0;\n\n\t\t\tif (prev_pck_size) {\n\t\t\t\tu64 next_pos = (u64) (start + au_start - ctx->mhas_buffer);\n\t\t\t\t//next will be in new packet\n\t\t\t\tif (prev_pck_size <= next_pos) {\n\t\t\t\t\tprev_pck_size = 0;\n\t\t\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\t\t\tctx->src_pck = in_pck;\n\t\t\t\t\tif (in_pck)\n\t\t\t\t\t\tgf_filter_pck_ref_props(&ctx->src_pck);\n\n\t\t\t\t\tif (ctx->timescale && (cts != GF_FILTER_NO_TS) ) {\n\t\t\t\t\t\tctx->cts = cts;\n\t\t\t\t\t\tcts = GF_FILTER_NO_TS;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (remain==consumed)\n\t\t\t\tbreak;\n\n\t\t\tif (gf_filter_pid_would_block(ctx->opid)) {\n\t\t\t\tctx->resume_from = 1;\n\t\t\t\tfinal_flush = GF_FALSE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (consumed) {\n\t\tassert(remain>=consumed);\n\t\tremain -= consumed;\n\t\tstart += consumed;\n\t}\n\nskip:\n\n\tif (remain < ctx->mhas_buffer_size) {\n\t\tmemmove(ctx->mhas_buffer, start, remain);\n\t\t//update byte offset\n\t\tif (ctx->byte_offset != GF_FILTER_NO_BO)\n\t\t\tctx->byte_offset += ctx->mhas_buffer_size - remain;\n\t}\n\tctx->mhas_buffer_size = remain;\n\tif (final_flush)\n\t\tctx->mhas_buffer_size = 0;\n\n\tif (!ctx->mhas_buffer_size) {\n\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\tctx->src_pck = NULL;\n\t}\n\n\tif (in_pck)\n\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\n\treturn GF_OK;\n}",
        "func": "GF_Err mhas_dmx_process(GF_Filter *filter)\n{\n\tGF_MHASDmxCtx *ctx = gf_filter_get_udta(filter);\n\tGF_FilterPacket *in_pck;\n\tu8 *output;\n\tu8 *start;\n\tBool final_flush=GF_FALSE;\n\tu32 pck_size, remain, prev_pck_size;\n\tu64 cts = GF_FILTER_NO_TS;\n\tu32 au_start = 0;\n\tu32 consumed = 0;\n\tu32 nb_trunc_samples = 0;\n\tBool trunc_from_begin = 0;\n\tBool has_cfg = 0;\n\n\t//always reparse duration\n\tif (!ctx->duration.num)\n\t\tmhas_dmx_check_dur(filter, ctx);\n\n\tif (ctx->opid && !ctx->is_playing)\n\t\treturn GF_OK;\n\n\tin_pck = gf_filter_pid_get_packet(ctx->ipid);\n\tif (!in_pck) {\n\t\tif (gf_filter_pid_is_eos(ctx->ipid)) {\n\t\t\tif (!ctx->mhas_buffer_size) {\n\t\t\t\tif (ctx->opid)\n\t\t\t\t\tgf_filter_pid_set_eos(ctx->opid);\n\t\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\t\tctx->src_pck = NULL;\n\t\t\t\treturn GF_EOS;\n\t\t\t}\n\t\t\tfinal_flush = GF_TRUE;\n\t\t} else if (!ctx->resume_from) {\n\t\t\treturn GF_OK;\n\t\t}\n\t}\n\n\tprev_pck_size = ctx->mhas_buffer_size;\n\tif (ctx->resume_from)\n\t\tin_pck = NULL;\n\n\tif (in_pck) {\n\t\tu8 *data = (u8 *) gf_filter_pck_get_data(in_pck, &pck_size);\n\n\t\tif (ctx->byte_offset != GF_FILTER_NO_BO) {\n\t\t\tu64 byte_offset = gf_filter_pck_get_byte_offset(in_pck);\n\t\t\tif (!ctx->mhas_buffer_size) {\n\t\t\t\tctx->byte_offset = byte_offset;\n\t\t\t} else if (ctx->byte_offset + ctx->mhas_buffer_size != byte_offset) {\n\t\t\t\tctx->byte_offset = GF_FILTER_NO_BO;\n\t\t\t\tif ((byte_offset != GF_FILTER_NO_BO) && (byte_offset>ctx->mhas_buffer_size) ) {\n\t\t\t\t\tctx->byte_offset = byte_offset - ctx->mhas_buffer_size;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (ctx->mhas_buffer_size + pck_size > ctx->mhas_buffer_alloc) {\n\t\t\tctx->mhas_buffer_alloc = ctx->mhas_buffer_size + pck_size;\n\t\t\tctx->mhas_buffer = gf_realloc(ctx->mhas_buffer, ctx->mhas_buffer_alloc);\n\t\t}\n\t\tmemcpy(ctx->mhas_buffer + ctx->mhas_buffer_size, data, pck_size);\n\t\tctx->mhas_buffer_size += pck_size;\n\t}\n\n\t//input pid sets some timescale - we flushed pending data , update cts\n\tif (ctx->timescale && in_pck) {\n\t\tcts = gf_filter_pck_get_cts(in_pck);\n\t\t//init cts at first packet\n\t\tif (!ctx->cts && (cts != GF_FILTER_NO_TS))\n\t\t\tctx->cts = cts;\n\t}\n\n\tif (cts == GF_FILTER_NO_TS) {\n\t\t//avoids updating cts\n\t\tprev_pck_size = 0;\n\t}\n\n\tremain = ctx->mhas_buffer_size;\n\tstart = ctx->mhas_buffer;\n\n\tif (ctx->resume_from) {\n\t\tstart += ctx->resume_from - 1;\n\t\tremain -= ctx->resume_from - 1;\n\t\tctx->resume_from = 0;\n\t}\n\n\twhile (ctx->nosync && (remain>3)) {\n\t\t//wait till we have a frame header\n\t\tu8 *hdr_start = memchr(start, 0xC0, remain);\n\t\tif (!hdr_start) {\n\t\t\tremain=0;\n\t\t\tbreak;\n\t\t}\n\t\tif ((hdr_start[1]==0x01) && (hdr_start[2]==0xA5)) {\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] Sync found !\\n\"));\n\t\t\tctx->nosync = GF_FALSE;\n\t\t\tbreak;\n\t\t}\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] not sync, skipping byte\\n\"));\n\t\tstart++;\n\t\tremain--;\n\t}\n\tif (ctx->nosync)\n\t\tgoto skip;\n\n\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\tctx->buffer_too_small = GF_FALSE;\n\n\t//MHAS packet\n\twhile (remain > consumed) {\n\t\tu32 pay_start, parse_end, mhas_size, mhas_label;\n\t\tBool mhas_sap = 0;\n\t\tu32 mhas_type;\n\t\tif (!ctx->is_playing && ctx->opid) {\n\t\t\tctx->resume_from = 1;\n\t\t\tconsumed = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tmhas_type = (u32) gf_mpegh_escaped_value(ctx->bs, 3, 8, 8);\n\t\tmhas_label = (u32) gf_mpegh_escaped_value(ctx->bs, 2, 8, 32);\n\t\tmhas_size = (u32) gf_mpegh_escaped_value(ctx->bs, 11, 24, 24);\n\n\t\tif (ctx->buffer_too_small)\n\t\t\tbreak;\n\n\n\t\tif (mhas_type>18) {\n\t\t\tctx->nb_unknown_pck++;\n\t\t\tif (ctx->nb_unknown_pck > ctx->pcksync) {\n\t\t\t\tGF_LOG(ctx->is_sync ? GF_LOG_WARNING : GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] %d packets of unknown type, considering sync was lost\\n\"));\n\t\t\t\tctx->is_sync = GF_FALSE;\n\t\t\t\tconsumed = 0;\n\t\t\t\tctx->nosync = GF_TRUE;\n\t\t\t\tctx->nb_unknown_pck = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} else if (!mhas_size) {\n\t\t\tGF_LOG(ctx->is_sync ? GF_LOG_WARNING : GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] MHAS packet with 0 payload size, considering sync was lost\\n\"));\n\t\t\tctx->is_sync = GF_FALSE;\n\t\t\tconsumed = 0;\n\t\t\tctx->nosync = GF_TRUE;\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t\tbreak;\n\t\t}\n\n\t\tpay_start = (u32) gf_bs_get_position(ctx->bs);\n\n\t\tif (ctx->buffer_too_small) break;\n\t\tif (mhas_size > gf_bs_available(ctx->bs)) {\n\t\t\t//incomplete frame, keep in buffer\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] incomplete packet type %d %s label \"LLU\" size \"LLU\" - keeping in buffer\\n\", mhas_type, mhas_pck_name(mhas_type), mhas_label, mhas_size));\n\t\t\tbreak;\n\t\t}\n\t\tctx->is_sync = GF_TRUE;\n\n\t\t//frame\n\t\tif (mhas_type==2) {\n\t\t\tmhas_sap = gf_bs_peek_bits(ctx->bs, 1, 0);\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t}\n\t\t//config\n\t\telse if (mhas_type==1) {\n\t\t\ts32 CICPspeakerLayoutIdx = -1;\n\t\t\ts32 numSpeakers = -1;\n\t\t\tu32 sr = 0;\n\t\t\tu32 frame_len;\n\t\t\tu32 pl = gf_bs_read_u8(ctx->bs);\n\t\t\tu32 idx = gf_bs_read_int(ctx->bs, 5);\n\t\t\tif (idx==0x1f)\n\t\t\t\tsr = gf_bs_read_int(ctx->bs, 24);\n\t\t\telse if (idx < nb_usac_sr) {\n\t\t\t\tsr = USACSampleRates[idx];\n\t\t\t}\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t\tidx = gf_bs_read_int(ctx->bs, 3);\n\t\t\tif ((idx==0) || (idx==2) ) frame_len = 768;\n\t\t\telse frame_len = 1024;\n\t\t\tgf_bs_read_int(ctx->bs, 1);\n\t\t\tgf_bs_read_int(ctx->bs, 1);\n\n\t\t\t//speaker config\n\t\t\tu32 speakerLayoutType = gf_bs_read_int(ctx->bs, 2);\n\t\t\tif (speakerLayoutType == 0) {\n\t\t\t\tCICPspeakerLayoutIdx = gf_bs_read_int(ctx->bs, 6);\n\t\t\t} else {\n\t\t\t\tnumSpeakers = (s32) gf_mpegh_escaped_value(ctx->bs, 5, 8, 16) + 1;\n\t\t\t\t//TODO ...\n\t\t\t}\n\t\t\tif (sr) {\n\t\t\t\tmhas_dmx_check_pid(filter, ctx, pl, sr, frame_len, CICPspeakerLayoutIdx, numSpeakers, start + pay_start, (u32) mhas_size);\n\n\t\t\t\thas_cfg = GF_TRUE;\n\t\t\t}\n\t\t}\n\t\t//audio truncation\n\t\telse if (mhas_type==17) {\n\t\t\tBool isActive = gf_bs_read_int(ctx->bs, 1);\n\t\t\t/*Bool ati_reserved = */gf_bs_read_int(ctx->bs, 1);\n\t\t\ttrunc_from_begin = gf_bs_read_int(ctx->bs, 1);\n\t\t\tnb_trunc_samples = gf_bs_read_int(ctx->bs, 13);\n\t\t\tif (!isActive) {\n\t\t\t\tnb_trunc_samples = 0;\n\t\t\t}\n\t\t}\n\t\t//sync, syncgap\n\t\telse if ((mhas_type==6) || (mhas_type==7)) {\n\t\t\tctx->nb_unknown_pck = 0;\n\t\t}\n#if 0\n\t\t//MARKER\n\t\telse if (mhas_type==8) {\n\t\t\tu8 marker_type = gf_bs_read_u8(ctx->bs);\n\t\t\t//config reload force\n\t\t\tif (marker_type==0x01) {}\n\t\t\t//SAP\n\t\t\telse if (marker_type==0x02) {\n\t\t\t\thas_marker = GF_TRUE;\n\t\t\t}\n\t\t}\n#endif\n\n\t\tgf_bs_align(ctx->bs);\n\t\tparse_end = (u32) gf_bs_get_position(ctx->bs) - pay_start;\n\t\t//remaining of packet payload\n\t\tgf_bs_skip_bytes(ctx->bs, mhas_size - parse_end);\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] MHAS Packet type %d %s label \"LLU\" size \"LLU\"\\n\", mhas_type, mhas_pck_name(mhas_type), mhas_label, mhas_size));\n\n\t\tif (ctx->timescale && !prev_pck_size && (cts != GF_FILTER_NO_TS) ) {\n\t\t\tctx->cts = cts;\n\t\t\tcts = GF_FILTER_NO_TS;\n\t\t}\n\n\t\t//frame\n\t\tif ((mhas_type==2) && ctx->opid) {\n\t\t\tGF_FilterPacket *dst;\n\t\t\tu64 pck_dur = ctx->frame_len;\n\n\n\t\t\tu32 au_size;\n\t\t\tif (ctx->mpha) {\n\t\t\t\tau_start = pay_start;\n\t\t\t\tau_size = mhas_size;\n\t\t\t} else {\n\t\t\t\tau_size = (u32) gf_bs_get_position(ctx->bs) - au_start;\n\t\t\t}\n\n\t\t\tif (nb_trunc_samples) {\n\t\t\t\tif (trunc_from_begin) {\n\t\t\t\t\tif (!ctx->nb_frames) {\n\t\t\t\t\t\ts64 offset = trunc_from_begin;\n\t\t\t\t\t\tif (ctx->timescale) {\n\t\t\t\t\t\t\toffset *= ctx->timescale;\n\t\t\t\t\t\t\toffset /= ctx->sample_rate;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tgf_filter_pid_set_property(ctx->opid, GF_PROP_PID_DELAY , &PROP_LONGSINT( -offset));\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tpck_dur -= nb_trunc_samples;\n\t\t\t\t}\n\t\t\t\tnb_trunc_samples = 0;\n\t\t\t}\n\n\t\t\tif (ctx->timescale) {\n\t\t\t\tpck_dur = gf_timestamp_rescale(pck_dur, ctx->sample_rate, ctx->timescale);\n\t\t\t}\n\n\t\t\tdst = gf_filter_pck_new_alloc(ctx->opid, au_size, &output);\n\t\t\tif (!dst) break;\n\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst);\n\n\t\t\tmemcpy(output, start + au_start, au_size);\n\t\t\tif (!has_cfg)\n\t\t\t\tmhas_sap = 0;\n\n\t\t\tif (mhas_sap) {\n\t\t\t\tgf_filter_pck_set_sap(dst, GF_FILTER_SAP_1);\n\t\t\t}\n\t\t\tgf_filter_pck_set_dts(dst, ctx->cts);\n\t\t\tgf_filter_pck_set_cts(dst, ctx->cts);\n\t\t\tgf_filter_pck_set_duration(dst, (u32) pck_dur);\n\t\t\tif (ctx->byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tu64 offset = (u64) (start - ctx->mhas_buffer);\n\t\t\t\toffset += ctx->byte_offset + au_start;\n\t\t\t\tgf_filter_pck_set_byte_offset(dst, offset);\n\t\t\t}\n \t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MHASDmx] Send AU CTS \"LLU\" size %d dur %d sap %d\\n\", ctx->cts, au_size, (u32) pck_dur, mhas_sap));\n\t\t\tgf_filter_pck_send(dst);\n\n\t\t\tau_start += au_size;\n\t\t\tconsumed = au_start;\n\t\t\tctx->nb_frames ++;\n\n\t\t\tmhas_dmx_update_cts(ctx);\n\t\t\thas_cfg = 0;\n\n\t\t\tif (prev_pck_size) {\n\t\t\t\tu64 next_pos = (u64) (start + au_start - ctx->mhas_buffer);\n\t\t\t\t//next will be in new packet\n\t\t\t\tif (prev_pck_size <= next_pos) {\n\t\t\t\t\tprev_pck_size = 0;\n\t\t\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\t\t\tctx->src_pck = in_pck;\n\t\t\t\t\tif (in_pck)\n\t\t\t\t\t\tgf_filter_pck_ref_props(&ctx->src_pck);\n\n\t\t\t\t\tif (ctx->timescale && (cts != GF_FILTER_NO_TS) ) {\n\t\t\t\t\t\tctx->cts = cts;\n\t\t\t\t\t\tcts = GF_FILTER_NO_TS;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (remain==consumed)\n\t\t\t\tbreak;\n\n\t\t\tif (gf_filter_pid_would_block(ctx->opid)) {\n\t\t\t\tctx->resume_from = 1;\n\t\t\t\tfinal_flush = GF_FALSE;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (consumed) {\n\t\tassert(remain>=consumed);\n\t\tremain -= consumed;\n\t\tstart += consumed;\n\t}\n\nskip:\n\n\tif (remain < ctx->mhas_buffer_size) {\n\t\tmemmove(ctx->mhas_buffer, start, remain);\n\t\t//update byte offset\n\t\tif (ctx->byte_offset != GF_FILTER_NO_BO)\n\t\t\tctx->byte_offset += ctx->mhas_buffer_size - remain;\n\t}\n\tctx->mhas_buffer_size = remain;\n\tif (final_flush)\n\t\tctx->mhas_buffer_size = 0;\n\n\tif (!ctx->mhas_buffer_size) {\n\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\tctx->src_pck = NULL;\n\t}\n\n\tif (in_pck)\n\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\n\treturn GF_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -188,10 +188,11 @@\n \t\t\t\tnumSpeakers = (s32) gf_mpegh_escaped_value(ctx->bs, 5, 8, 16) + 1;\n \t\t\t\t//TODO ...\n \t\t\t}\n-\n-\t\t\tmhas_dmx_check_pid(filter, ctx, pl, sr, frame_len, CICPspeakerLayoutIdx, numSpeakers, start + pay_start, (u32) mhas_size);\n-\n-\t\t\thas_cfg = GF_TRUE;\n+\t\t\tif (sr) {\n+\t\t\t\tmhas_dmx_check_pid(filter, ctx, pl, sr, frame_len, CICPspeakerLayoutIdx, numSpeakers, start + pay_start, (u32) mhas_size);\n+\n+\t\t\t\thas_cfg = GF_TRUE;\n+\t\t\t}\n \t\t}\n \t\t//audio truncation\n \t\telse if (mhas_type==17) {",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\t\t\tmhas_dmx_check_pid(filter, ctx, pl, sr, frame_len, CICPspeakerLayoutIdx, numSpeakers, start + pay_start, (u32) mhas_size);",
                "",
                "\t\t\thas_cfg = GF_TRUE;"
            ],
            "added_lines": [
                "\t\t\tif (sr) {",
                "\t\t\t\tmhas_dmx_check_pid(filter, ctx, pl, sr, frame_len, CICPspeakerLayoutIdx, numSpeakers, start + pay_start, (u32) mhas_size);",
                "",
                "\t\t\t\thas_cfg = GF_TRUE;",
                "\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4678",
        "func_name": "gpac/swf_def_font",
        "description": "Divide By Zero in GitHub repository gpac/gpac prior to 2.3-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4607052c482a51dbdacfe1ade10645c181d07b07",
        "commit_title": "fixed #2576",
        "commit_text": "",
        "func_before": "static GF_Err swf_def_font(SWFReader *read, u32 revision)\n{\n\tu32 i, count;\n\tGF_Err e;\n\tSWFFont *ft;\n\tu32 *offset_table = NULL;\n\tu32 start;\n\n\tGF_SAFEALLOC(ft, SWFFont);\n\tif (!ft) return GF_OUT_OF_MEM;\n\n\tft->glyphs = gf_list_new();\n\tft->fontID = swf_get_16(read);\n\te = GF_OK;\n\n\n\tif (revision==0) {\n\t\tstart = swf_get_file_pos(read);\n\n\t\tcount = swf_get_16(read);\n\t\tft->nbGlyphs = count / 2;\n\t\toffset_table = (u32*)gf_malloc(sizeof(u32) * ft->nbGlyphs);\n\t\toffset_table[0] = 0;\n\t\tfor (i=1; i<ft->nbGlyphs; i++) offset_table[i] = swf_get_16(read);\n\n\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\tswf_align(read);\n\t\t\te = swf_seek_file_to(read, start + offset_table[i]);\n\t\t\tif (e) break;\n\t\t\tswf_parse_shape_def(read, ft, 0);\n\t\t}\n\t\tgf_free(offset_table);\n\t\tif (e) return e;\n\t} else if (revision==1) {\n\t\tSWFRec rc;\n\t\tBool wide_offset, wide_codes;\n\t\tu32 code_offset, checkpos;\n\t\tft->has_layout = swf_read_int(read, 1);\n\t\tft->has_shiftJIS = swf_read_int(read, 1);\n\t\tft->is_unicode = swf_read_int(read, 1);\n\t\tft->is_ansi = swf_read_int(read, 1);\n\t\twide_offset = swf_read_int(read, 1);\n\t\twide_codes = swf_read_int(read, 1);\n\t\tft->is_italic = swf_read_int(read, 1);\n\t\tft->is_bold = swf_read_int(read, 1);\n\t\tswf_read_int(read, 8);\n\t\tcount = swf_read_int(read, 8);\n\t\tft->fontName = (char*)gf_malloc(sizeof(u8)*count+1);\n\t\tft->fontName[count] = 0;\n\t\tfor (i=0; i<count; i++) ft->fontName[i] = swf_read_int(read, 8);\n\n\t\tft->nbGlyphs = swf_get_16(read);\n\t\tstart = swf_get_file_pos(read);\n\n\t\tif (ft->nbGlyphs) {\n\t\t\toffset_table = (u32*)gf_malloc(sizeof(u32) * ft->nbGlyphs);\n\t\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\t\tif (wide_offset) offset_table[i] = swf_get_32(read);\n\t\t\t\telse offset_table[i] = swf_get_16(read);\n\t\t\t}\n\t\t}\n\n\t\tif (wide_offset) {\n\t\t\tcode_offset = swf_get_32(read);\n\t\t} else {\n\t\t\tcode_offset = swf_get_16(read);\n\t\t}\n\n\t\tif (ft->nbGlyphs) {\n\t\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\t\tswf_align(read);\n\t\t\t\te = swf_seek_file_to(read, start + offset_table[i]);\n\t\t\t\tif (e) break;\n\n\t\t\t\tswf_parse_shape_def(read, ft, 0);\n\t\t\t}\n\t\t\tgf_free(offset_table);\n\t\t\tif (e) return e;\n\n\t\t\tcheckpos = swf_get_file_pos(read);\n\t\t\tif (checkpos != start + code_offset) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_PARSER, (\"[SWF Parsing] bad code offset in font\\n\"));\n\t\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t}\n\n\t\t\tft->glyph_codes = (u16*)gf_malloc(sizeof(u16) * ft->nbGlyphs);\n\t\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\t\tif (wide_codes) ft->glyph_codes[i] = swf_get_16(read);\n\t\t\t\telse ft->glyph_codes[i] = swf_read_int(read, 8);\n\t\t\t}\n\t\t}\n\t\tif (ft->has_layout) {\n\t\t\tft->ascent = swf_get_s16(read);\n\t\t\tft->descent = swf_get_s16(read);\n\t\t\tft->leading = swf_get_s16(read);\n\t\t\tif (ft->nbGlyphs) {\n\t\t\t\tft->glyph_adv = (s16*)gf_malloc(sizeof(s16) * ft->nbGlyphs);\n\t\t\t\tfor (i=0; i<ft->nbGlyphs; i++) ft->glyph_adv[i] = swf_get_s16(read);\n\t\t\t\tfor (i=0; i<ft->nbGlyphs; i++) swf_get_rec(read, &rc);\n\t\t\t}\n\t\t\t/*kerning info*/\n\t\t\tcount = swf_get_16(read);\n\t\t\tfor (i=0; i<count; i++) {\n\t\t\t\tif (wide_codes) {\n\t\t\t\t\tswf_get_16(read);\n\t\t\t\t\tswf_get_16(read);\n\t\t\t\t} else {\n\t\t\t\t\tswf_read_int(read, 8);\n\t\t\t\t\tswf_read_int(read, 8);\n\t\t\t\t}\n\t\t\t\tswf_get_s16(read);\n\t\t\t}\n\t\t}\n\t}\n\n\tgf_list_add(read->fonts, ft);\n\treturn GF_OK;\n}",
        "func": "static GF_Err swf_def_font(SWFReader *read, u32 revision)\n{\n\tu32 i, count;\n\tGF_Err e;\n\tSWFFont *ft;\n\tu32 *offset_table = NULL;\n\tu32 start;\n\n\tGF_SAFEALLOC(ft, SWFFont);\n\tif (!ft) return GF_OUT_OF_MEM;\n\n\tft->glyphs = gf_list_new();\n\tft->fontID = swf_get_16(read);\n\te = GF_OK;\n\tgf_list_add(read->fonts, ft);\n\n\tif (revision==0) {\n\t\tstart = swf_get_file_pos(read);\n\n\t\tcount = swf_get_16(read);\n\t\tft->nbGlyphs = count / 2;\n\t\toffset_table = (u32*)gf_malloc(sizeof(u32) * ft->nbGlyphs);\n\t\toffset_table[0] = 0;\n\t\tfor (i=1; i<ft->nbGlyphs; i++) offset_table[i] = swf_get_16(read);\n\n\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\tswf_align(read);\n\t\t\te = swf_seek_file_to(read, start + offset_table[i]);\n\t\t\tif (e) break;\n\t\t\tswf_parse_shape_def(read, ft, 0);\n\t\t}\n\t\tgf_free(offset_table);\n\t\tif (e) return e;\n\t} else if (revision==1) {\n\t\tSWFRec rc;\n\t\tBool wide_offset, wide_codes;\n\t\tu32 code_offset, checkpos;\n\t\tft->has_layout = swf_read_int(read, 1);\n\t\tft->has_shiftJIS = swf_read_int(read, 1);\n\t\tft->is_unicode = swf_read_int(read, 1);\n\t\tft->is_ansi = swf_read_int(read, 1);\n\t\twide_offset = swf_read_int(read, 1);\n\t\twide_codes = swf_read_int(read, 1);\n\t\tft->is_italic = swf_read_int(read, 1);\n\t\tft->is_bold = swf_read_int(read, 1);\n\t\tswf_read_int(read, 8);\n\t\tcount = swf_read_int(read, 8);\n\t\tft->fontName = (char*)gf_malloc(sizeof(u8)*count+1);\n\t\tft->fontName[count] = 0;\n\t\tfor (i=0; i<count; i++) ft->fontName[i] = swf_read_int(read, 8);\n\n\t\tft->nbGlyphs = swf_get_16(read);\n\t\tstart = swf_get_file_pos(read);\n\n\t\tif (ft->nbGlyphs) {\n\t\t\toffset_table = (u32*)gf_malloc(sizeof(u32) * ft->nbGlyphs);\n\t\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\t\tif (wide_offset) offset_table[i] = swf_get_32(read);\n\t\t\t\telse offset_table[i] = swf_get_16(read);\n\t\t\t}\n\t\t}\n\n\t\tif (wide_offset) {\n\t\t\tcode_offset = swf_get_32(read);\n\t\t} else {\n\t\t\tcode_offset = swf_get_16(read);\n\t\t}\n\n\t\tif (ft->nbGlyphs) {\n\t\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\t\tswf_align(read);\n\t\t\t\te = swf_seek_file_to(read, start + offset_table[i]);\n\t\t\t\tif (e) break;\n\n\t\t\t\tswf_parse_shape_def(read, ft, 0);\n\t\t\t}\n\t\t\tgf_free(offset_table);\n\t\t\tif (e) return e;\n\n\t\t\tcheckpos = swf_get_file_pos(read);\n\t\t\tif (checkpos != start + code_offset) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_PARSER, (\"[SWF Parsing] bad code offset in font\\n\"));\n\t\t\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t\t\t}\n\n\t\t\tft->glyph_codes = (u16*)gf_malloc(sizeof(u16) * ft->nbGlyphs);\n\t\t\tfor (i=0; i<ft->nbGlyphs; i++) {\n\t\t\t\tif (wide_codes) ft->glyph_codes[i] = swf_get_16(read);\n\t\t\t\telse ft->glyph_codes[i] = swf_read_int(read, 8);\n\t\t\t}\n\t\t}\n\t\tif (ft->has_layout) {\n\t\t\tft->ascent = swf_get_s16(read);\n\t\t\tft->descent = swf_get_s16(read);\n\t\t\tft->leading = swf_get_s16(read);\n\t\t\tif (ft->nbGlyphs) {\n\t\t\t\tft->glyph_adv = (s16*)gf_malloc(sizeof(s16) * ft->nbGlyphs);\n\t\t\t\tfor (i=0; i<ft->nbGlyphs; i++) ft->glyph_adv[i] = swf_get_s16(read);\n\t\t\t\tfor (i=0; i<ft->nbGlyphs; i++) swf_get_rec(read, &rc);\n\t\t\t}\n\t\t\t/*kerning info*/\n\t\t\tcount = swf_get_16(read);\n\t\t\tfor (i=0; i<count; i++) {\n\t\t\t\tif (wide_codes) {\n\t\t\t\t\tswf_get_16(read);\n\t\t\t\t\tswf_get_16(read);\n\t\t\t\t} else {\n\t\t\t\t\tswf_read_int(read, 8);\n\t\t\t\t\tswf_read_int(read, 8);\n\t\t\t\t}\n\t\t\t\tswf_get_s16(read);\n\t\t\t}\n\t\t}\n\t}\n\treturn GF_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n \tft->glyphs = gf_list_new();\n \tft->fontID = swf_get_16(read);\n \te = GF_OK;\n-\n+\tgf_list_add(read->fonts, ft);\n \n \tif (revision==0) {\n \t\tstart = swf_get_file_pos(read);\n@@ -112,7 +112,5 @@\n \t\t\t}\n \t\t}\n \t}\n-\n-\tgf_list_add(read->fonts, ft);\n \treturn GF_OK;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "",
                "\tgf_list_add(read->fonts, ft);"
            ],
            "added_lines": [
                "\tgf_list_add(read->fonts, ft);"
            ]
        }
    },
    {
        "cve_id": "CVE-2023-4678",
        "func_name": "gpac/gf_swf_read_header",
        "description": "Divide By Zero in GitHub repository gpac/gpac prior to 2.3-DEV.",
        "git_url": "https://github.com/gpac/gpac/commit/4607052c482a51dbdacfe1ade10645c181d07b07",
        "commit_title": "fixed #2576",
        "commit_text": "",
        "func_before": "GF_Err gf_swf_read_header(SWFReader *read)\n{\n\tSWFRec rc;\n\tu8 sig[3];\n\n\t/*get signature*/\n\tsig[0] = gf_bs_read_u8(read->bs);\n\tsig[1] = gf_bs_read_u8(read->bs);\n\tsig[2] = gf_bs_read_u8(read->bs);\n\t/*\"FWS\" or \"CWS\"*/\n\tif ( ((sig[0] != 'F') && (sig[0] != 'C')) || (sig[1] != 'W') || (sig[2] != 'S') ) {\n\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t}\n\t/*version = */gf_bs_read_u8(read->bs);\n\tread->length = swf_get_32(read);\n\n\t/*if compressed decompress the whole file*/\n\tif (sig[0] == 'C') {\n\t\tswf_init_decompress(read);\n\t\tif (!read->bs) return GF_NON_COMPLIANT_BITSTREAM;\n\t}\n\n\tswf_get_rec(read, &rc);\n\tread->width = rc.w;\n\tread->height = rc.h;\n\n\tswf_align(read);\n\tread->frame_rate = swf_get_16(read)>>8;\n\tread->frame_count = swf_get_16(read);\n\tGF_LOG(GF_LOG_INFO, GF_LOG_PARSER, (\"SWF Import - Scene Size %gx%g - %d frames @ %d FPS\\n\", read->width, read->height, read->frame_count, read->frame_rate));\n\treturn GF_OK;\n}",
        "func": "GF_Err gf_swf_read_header(SWFReader *read)\n{\n\tSWFRec rc;\n\tu8 sig[3];\n\n\t/*get signature*/\n\tsig[0] = gf_bs_read_u8(read->bs);\n\tsig[1] = gf_bs_read_u8(read->bs);\n\tsig[2] = gf_bs_read_u8(read->bs);\n\t/*\"FWS\" or \"CWS\"*/\n\tif ( ((sig[0] != 'F') && (sig[0] != 'C')) || (sig[1] != 'W') || (sig[2] != 'S') ) {\n\t\treturn GF_NON_COMPLIANT_BITSTREAM;\n\t}\n\t/*version = */gf_bs_read_u8(read->bs);\n\tread->length = swf_get_32(read);\n\n\t/*if compressed decompress the whole file*/\n\tif (sig[0] == 'C') {\n\t\tswf_init_decompress(read);\n\t\tif (!read->bs) return GF_NON_COMPLIANT_BITSTREAM;\n\t}\n\n\tswf_get_rec(read, &rc);\n\tread->width = rc.w;\n\tread->height = rc.h;\n\n\tswf_align(read);\n\tread->frame_rate = swf_get_16(read)>>8;\n\tread->frame_count = swf_get_16(read);\n\tGF_LOG(GF_LOG_INFO, GF_LOG_PARSER, (\"SWF Import - Scene Size %gx%g - %d frames @ %d FPS\\n\", read->width, read->height, read->frame_count, read->frame_rate));\n\tif (!read->frame_rate) read->frame_rate = 1;\n\treturn GF_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,5 +28,6 @@\n \tread->frame_rate = swf_get_16(read)>>8;\n \tread->frame_count = swf_get_16(read);\n \tGF_LOG(GF_LOG_INFO, GF_LOG_PARSER, (\"SWF Import - Scene Size %gx%g - %d frames @ %d FPS\\n\", read->width, read->height, read->frame_count, read->frame_rate));\n+\tif (!read->frame_rate) read->frame_rate = 1;\n \treturn GF_OK;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!read->frame_rate) read->frame_rate = 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8130",
        "func_name": "vadz/libtiff/_TIFFmalloc",
        "description": "The _TIFFmalloc function in tif_unix.c in LibTIFF 4.0.3 does not reject a zero size, which allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted TIFF image that is mishandled by the TIFFWriteScanline function in tif_write.c, as demonstrated by tiffdither.",
        "git_url": "https://github.com/vadz/libtiff/commit/3c5eb8b1be544e41d2c336191bc4936300ad7543",
        "commit_title": "* libtiff/tif_{unix,vms,win32}.c (_TIFFmalloc): ANSI C does not",
        "commit_text": "require malloc() to return NULL pointer if requested allocation size is zero.  Assure that _TIFFmalloc does.",
        "func_before": "void*\n_TIFFmalloc(tmsize_t s)\n{\n\treturn (malloc((size_t) s));\n}",
        "func": "void*\n_TIFFmalloc(tmsize_t s)\n{\n        if (s == 0)\n                return ((void *) NULL);\n\n\treturn (malloc((size_t) s));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n void*\n _TIFFmalloc(tmsize_t s)\n {\n+        if (s == 0)\n+                return ((void *) NULL);\n+\n \treturn (malloc((size_t) s));\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (s == 0)",
                "                return ((void *) NULL);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8130",
        "func_name": "vadz/libtiff/_TIFFmalloc",
        "description": "The _TIFFmalloc function in tif_unix.c in LibTIFF 4.0.3 does not reject a zero size, which allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted TIFF image that is mishandled by the TIFFWriteScanline function in tif_write.c, as demonstrated by tiffdither.",
        "git_url": "https://github.com/vadz/libtiff/commit/3c5eb8b1be544e41d2c336191bc4936300ad7543",
        "commit_title": "* libtiff/tif_{unix,vms,win32}.c (_TIFFmalloc): ANSI C does not",
        "commit_text": "require malloc() to return NULL pointer if requested allocation size is zero.  Assure that _TIFFmalloc does.",
        "func_before": "void*\n_TIFFmalloc(tmsize_t s)\n{\n\treturn (malloc((size_t) s));\n}",
        "func": "void*\n_TIFFmalloc(tmsize_t s)\n{\n        if (s == 0)\n                return ((void *) NULL);\n\n\treturn (malloc((size_t) s));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n void*\n _TIFFmalloc(tmsize_t s)\n {\n+        if (s == 0)\n+                return ((void *) NULL);\n+\n \treturn (malloc((size_t) s));\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (s == 0)",
                "                return ((void *) NULL);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8130",
        "func_name": "vadz/libtiff/_TIFFmalloc",
        "description": "The _TIFFmalloc function in tif_unix.c in LibTIFF 4.0.3 does not reject a zero size, which allows remote attackers to cause a denial of service (divide-by-zero error and application crash) via a crafted TIFF image that is mishandled by the TIFFWriteScanline function in tif_write.c, as demonstrated by tiffdither.",
        "git_url": "https://github.com/vadz/libtiff/commit/3c5eb8b1be544e41d2c336191bc4936300ad7543",
        "commit_title": "* libtiff/tif_{unix,vms,win32}.c (_TIFFmalloc): ANSI C does not",
        "commit_text": "require malloc() to return NULL pointer if requested allocation size is zero.  Assure that _TIFFmalloc does.",
        "func_before": "tdata_t\n_TIFFmalloc(tsize_t s)\n{\n\treturn (malloc((size_t) s));\n}",
        "func": "tdata_t\n_TIFFmalloc(tsize_t s)\n{\n        if (s == 0)\n                return ((void *) NULL);\n\n\treturn (malloc((size_t) s));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n tdata_t\n _TIFFmalloc(tsize_t s)\n {\n+        if (s == 0)\n+                return ((void *) NULL);\n+\n \treturn (malloc((size_t) s));\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        if (s == 0)",
                "                return ((void *) NULL);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2018-9304",
        "func_name": "Exiv2/exiv2/printIFD",
        "description": "In Exiv2 0.26, a divide by zero in BigTiffImage::printIFD in bigtiffimage.cpp could result in denial of service.",
        "git_url": "https://github.com/Exiv2/exiv2/commit/b3199a072073ac6292e5bbbd5cce2167f1932ea8",
        "commit_title": "Fix division by zero in BigTiffImage::printIFD",
        "commit_text": " This fixes #262",
        "func_before": "void printIFD(std::ostream& out, PrintStructureOption option, uint64_t dir_offset, int depth)\n                {\n                    BasicIo& io = Image::io();\n\n                    depth++;\n                    bool bFirst  = true;\n\n                    // buffer\n                    bool bPrint = true;\n\n                    do\n                    {\n                        // Read top of directory\n                        io.seek(dir_offset, BasicIo::beg);\n\n                        const uint64_t entries = readData(header_.format() == Header::StandardTiff? 2: 8);\n                        const bool tooBig = entries > 500;\n\n                        if ( bFirst && bPrint )\n                        {\n                            out << Internal::indent(depth) << Internal::stringFormat(\"STRUCTURE OF BIGTIFF FILE \") << io.path() << std::endl;\n                            if (tooBig)\n                                out << Internal::indent(depth) << \"entries = \" << entries << std::endl;\n                        }\n\n                        if (tooBig)\n                            break;\n\n                        // Read the dictionary\n                        for ( uint64_t i = 0; i < entries; i ++ )\n                        {\n                            if ( bFirst && bPrint )\n                                out << Internal::indent(depth)\n                                    << \" address |    tag                           |     \"\n                                    << \" type |    count |    offset | value\\n\";\n\n                            bFirst = false;\n\n                            const uint16_t tag   = (uint16_t) readData(2);\n                            const uint16_t type  = (uint16_t) readData(2);\n                            const uint64_t count = readData(dataSize_);\n                            const DataBuf  data  = io.read(dataSize_);        // Read data as raw value. what should be done about it will be decided depending on type\n\n                            std::string sp = \"\" ; // output spacer\n\n                            //prepare to print the value\n                            // TODO: figure out what's going on with kount\n                            const uint64_t kount  = isStringType(type)? (count > 32 ? 32 : count) // restrict long arrays\n                                                            : count > 5              ? 5\n                                                            : count\n                                                            ;\n                            const uint32_t pad    = isStringType(type) ? 1 : 0;\n                            const uint32_t size   = isStringType(type) ? 1\n                                                  : is2ByteType(type)  ? 2\n                                                  : is4ByteType(type)  ? 4\n                                                  : is8ByteType(type)  ? 8\n                                                  : 1;\n\n                            // #55 and #56 memory allocation crash test/data/POC8\n\n                            // size * count > std::numeric_limits<uint64_t>::max()\n                            // =>\n                            // size > std::numeric_limits<uint64_t>::max() / count\n                            if (size > std::numeric_limits<uint64_t>::max() / count)\n                                throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n                                                             // more than we can handle\n\n                            if (size * count > std::numeric_limits<uint64_t>::max() - pad)\n                                throw Error(kerInvalidMalloc);             // again more than 2^64\n\n                            const uint64_t allocate = size*count + pad;\n                            if ( allocate > io.size() ) {\n                                throw Error(kerInvalidMalloc);\n                            }\n\n                            DataBuf buf(static_cast<long>(allocate));\n\n                            const uint64_t offset = header_.format() == Header::StandardTiff?\n                                    byteSwap4(data, 0, doSwap_):\n                                    byteSwap8(data, 0, doSwap_);\n\n                            // big data? Use 'data' as pointer to real data\n                            const bool usePointer = (size_t) count*size > (size_t) dataSize_;\n\n                            if ( usePointer )                          // read into buffer\n                            {\n                                size_t   restore = io.tell();          // save\n                                io.seek(offset, BasicIo::beg);         // position\n                                io.read(buf.pData_, (long) count * size);     // read\n                                io.seek(restore, BasicIo::beg);        // restore\n                            }\n                            else  // use 'data' as data :)\n                                std::memcpy(buf.pData_, data.pData_, (size_t) count * size);     // copy data\n\n                            if ( bPrint )\n                            {\n                                const uint64_t entrySize = header_.format() == Header::StandardTiff? 12: 20;\n                                const uint64_t address = dir_offset + 2 + i * entrySize;\n                                const std::string offsetString = usePointer?\n                                    Internal::stringFormat(\"%10u\", offset):\n                                    \"\";\n\n                                out << Internal::indent(depth)\n                                    << Internal::stringFormat(\"%8u | %#06x %-25s |%10s |%9u |%10s | \",\n                                        address, tag, tagName(tag).c_str(), typeName(type), count, offsetString.c_str());\n\n                                if ( isShortType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap2(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap4(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap8(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isRationalType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        uint32_t a = byteSwap4(buf, k*size+0, doSwap_);\n                                        uint32_t b = byteSwap4(buf, k*size+4, doSwap_);\n                                        out << sp << a << \"/\" << b;\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isStringType(type) )\n                                    out << sp << Internal::binaryToString(buf, (size_t) kount);\n\n                                sp = kount == count ? \"\" : \" ...\";\n                                out << sp << std::endl;\n\n                                if ( option == kpsRecursive &&\n                                        (tag == 0x8769 /* ExifTag */ || tag == 0x014a/*SubIFDs*/ || type == tiffIfd || type == tiffIfd8) )\n                                {\n                                    for ( size_t k = 0 ; k < count ; k++ )\n                                    {\n                                        const size_t restore = io.tell();\n                                        const uint64_t ifdOffset = type == tiffIfd8?\n                                            byteSwap8(buf, k*size, doSwap_):\n                                            byteSwap4(buf, k*size, doSwap_);\n\n                                        printIFD(out, option, ifdOffset, depth);\n                                        io.seek(restore, BasicIo::beg);\n                                    }\n                                }\n                                else if ( option == kpsRecursive && tag == 0x83bb /* IPTCNAA */ )\n                                {\n                                    const size_t restore = io.tell();      // save\n                                    io.seek(offset, BasicIo::beg);         // position\n                                    byte* bytes=new byte[(size_t)count] ;  // allocate memory\n                                    io.read(bytes,(long)count)        ;    // read\n                                    io.seek(restore, BasicIo::beg);        // restore\n                                    IptcData::printStructure(out,bytes,(size_t)count,depth);\n                                    delete[] bytes;                        // free\n                                }\n                                else if ( option == kpsRecursive && tag == 0x927c /* MakerNote */ && count > 10)\n                                {\n                                    size_t   restore = io.tell();  // save\n\n                                    long jump= 10           ;\n                                    byte     bytes[20]          ;\n                                    const char* chars = (const char*) &bytes[0] ;\n                                    io.seek(dir_offset, BasicIo::beg);  // position\n                                    io.read(bytes,jump    )     ;  // read\n                                    bytes[jump]=0               ;\n                                    if ( ::strcmp(\"Nikon\",chars) == 0 )\n                                    {\n                                      // tag is an embedded tiff\n                                      std::vector<byte> nikon_bytes(count - jump);\n\n                                      io.read(&nikon_bytes.at(0), (long)nikon_bytes.size());\n                                      MemIo memIo(&nikon_bytes.at(0), (long)count - jump); // create a file\n                                      std::cerr << \"Nikon makernote\" << std::endl;\n                                      // printTiffStructure(memIo,out,option,depth);\n                                      // TODO: fix it\n                                    }\n                                    else\n                                    {\n                                        // tag is an IFD\n                                        io.seek(0, BasicIo::beg);  // position\n                                        std::cerr << \"makernote\" << std::endl;\n                                        printIFD(out,option,offset,depth);\n                                    }\n\n                                    io.seek(restore,BasicIo::beg); // restore\n                                }\n                            }\n                        }\n\n                        const uint64_t nextDirOffset = readData(dataSize_);\n\n                        dir_offset = tooBig ? 0 : nextDirOffset;\n                        out.flush();\n                    } while (dir_offset != 0);\n\n                    if ( bPrint )\n                        out << Internal::indent(depth) << \"END \" << io.path() << std::endl;\n\n                    depth--;\n                }",
        "func": "void printIFD(std::ostream& out, PrintStructureOption option, uint64_t dir_offset, int depth)\n                {\n                    BasicIo& io = Image::io();\n\n                    depth++;\n                    bool bFirst  = true;\n\n                    // buffer\n                    bool bPrint = true;\n\n                    do\n                    {\n                        // Read top of directory\n                        io.seek(dir_offset, BasicIo::beg);\n\n                        const uint64_t entries = readData(header_.format() == Header::StandardTiff? 2: 8);\n                        const bool tooBig = entries > 500;\n\n                        if ( bFirst && bPrint )\n                        {\n                            out << Internal::indent(depth) << Internal::stringFormat(\"STRUCTURE OF BIGTIFF FILE \") << io.path() << std::endl;\n                            if (tooBig)\n                                out << Internal::indent(depth) << \"entries = \" << entries << std::endl;\n                        }\n\n                        if (tooBig)\n                            break;\n\n                        // Read the dictionary\n                        for ( uint64_t i = 0; i < entries; i ++ )\n                        {\n                            if ( bFirst && bPrint )\n                                out << Internal::indent(depth)\n                                    << \" address |    tag                           |     \"\n                                    << \" type |    count |    offset | value\\n\";\n\n                            bFirst = false;\n\n                            const uint16_t tag   = (uint16_t) readData(2);\n                            const uint16_t type  = (uint16_t) readData(2);\n                            const uint64_t count = readData(dataSize_);\n                            const DataBuf  data  = io.read(dataSize_);        // Read data as raw value. what should be done about it will be decided depending on type\n\n                            std::string sp = \"\" ; // output spacer\n\n                            //prepare to print the value\n                            // TODO: figure out what's going on with kount\n                            const uint64_t kount  = isStringType(type)? (count > 32 ? 32 : count) // restrict long arrays\n                                                            : count > 5              ? 5\n                                                            : count\n                                                            ;\n                            const uint32_t pad    = isStringType(type) ? 1 : 0;\n                            const uint32_t size   = isStringType(type) ? 1\n                                                  : is2ByteType(type)  ? 2\n                                                  : is4ByteType(type)  ? 4\n                                                  : is8ByteType(type)  ? 8\n                                                  : 1;\n\n                            // #55 and #56 memory allocation crash test/data/POC8\n\n                            // size * count > std::numeric_limits<uint64_t>::max()\n                            // =>\n                            // size > std::numeric_limits<uint64_t>::max() / count\n                            // (don't perform that check when count == 0 => will cause a division by zero exception)\n                            if (count != 0) {\n                                if (size > std::numeric_limits<uint64_t>::max() / count) {\n                                    throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n                                }\n                            }\n                                                             // more than we can handle\n\n                            if (size * count > std::numeric_limits<uint64_t>::max() - pad)\n                                throw Error(kerInvalidMalloc);             // again more than 2^64\n\n                            const uint64_t allocate = size*count + pad;\n                            if ( allocate > io.size() ) {\n                                throw Error(kerInvalidMalloc);\n                            }\n\n                            DataBuf buf(static_cast<long>(allocate));\n\n                            const uint64_t offset = header_.format() == Header::StandardTiff?\n                                    byteSwap4(data, 0, doSwap_):\n                                    byteSwap8(data, 0, doSwap_);\n\n                            // big data? Use 'data' as pointer to real data\n                            const bool usePointer = (size_t) count*size > (size_t) dataSize_;\n\n                            if ( usePointer )                          // read into buffer\n                            {\n                                size_t   restore = io.tell();          // save\n                                io.seek(offset, BasicIo::beg);         // position\n                                io.read(buf.pData_, (long) count * size);     // read\n                                io.seek(restore, BasicIo::beg);        // restore\n                            }\n                            else  // use 'data' as data :)\n                                std::memcpy(buf.pData_, data.pData_, (size_t) count * size);     // copy data\n\n                            if ( bPrint )\n                            {\n                                const uint64_t entrySize = header_.format() == Header::StandardTiff? 12: 20;\n                                const uint64_t address = dir_offset + 2 + i * entrySize;\n                                const std::string offsetString = usePointer?\n                                    Internal::stringFormat(\"%10u\", offset):\n                                    \"\";\n\n                                out << Internal::indent(depth)\n                                    << Internal::stringFormat(\"%8u | %#06x %-25s |%10s |%9u |%10s | \",\n                                        address, tag, tagName(tag).c_str(), typeName(type), count, offsetString.c_str());\n\n                                if ( isShortType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap2(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap4(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isLongLongType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        out << sp << byteSwap8(buf, k*size, doSwap_);\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isRationalType(type) )\n                                {\n                                    for ( size_t k = 0 ; k < kount ; k++ )\n                                    {\n                                        uint32_t a = byteSwap4(buf, k*size+0, doSwap_);\n                                        uint32_t b = byteSwap4(buf, k*size+4, doSwap_);\n                                        out << sp << a << \"/\" << b;\n                                        sp = \" \";\n                                    }\n                                }\n                                else if ( isStringType(type) )\n                                    out << sp << Internal::binaryToString(buf, (size_t) kount);\n\n                                sp = kount == count ? \"\" : \" ...\";\n                                out << sp << std::endl;\n\n                                if ( option == kpsRecursive &&\n                                        (tag == 0x8769 /* ExifTag */ || tag == 0x014a/*SubIFDs*/ || type == tiffIfd || type == tiffIfd8) )\n                                {\n                                    for ( size_t k = 0 ; k < count ; k++ )\n                                    {\n                                        const size_t restore = io.tell();\n                                        const uint64_t ifdOffset = type == tiffIfd8?\n                                            byteSwap8(buf, k*size, doSwap_):\n                                            byteSwap4(buf, k*size, doSwap_);\n\n                                        printIFD(out, option, ifdOffset, depth);\n                                        io.seek(restore, BasicIo::beg);\n                                    }\n                                }\n                                else if ( option == kpsRecursive && tag == 0x83bb /* IPTCNAA */ )\n                                {\n                                    const size_t restore = io.tell();      // save\n                                    io.seek(offset, BasicIo::beg);         // position\n                                    byte* bytes=new byte[(size_t)count] ;  // allocate memory\n                                    io.read(bytes,(long)count)        ;    // read\n                                    io.seek(restore, BasicIo::beg);        // restore\n                                    IptcData::printStructure(out,bytes,(size_t)count,depth);\n                                    delete[] bytes;                        // free\n                                }\n                                else if ( option == kpsRecursive && tag == 0x927c /* MakerNote */ && count > 10)\n                                {\n                                    size_t   restore = io.tell();  // save\n\n                                    long jump= 10           ;\n                                    byte     bytes[20]          ;\n                                    const char* chars = (const char*) &bytes[0] ;\n                                    io.seek(dir_offset, BasicIo::beg);  // position\n                                    io.read(bytes,jump    )     ;  // read\n                                    bytes[jump]=0               ;\n                                    if ( ::strcmp(\"Nikon\",chars) == 0 )\n                                    {\n                                      // tag is an embedded tiff\n                                      std::vector<byte> nikon_bytes(count - jump);\n\n                                      io.read(&nikon_bytes.at(0), (long)nikon_bytes.size());\n                                      MemIo memIo(&nikon_bytes.at(0), (long)count - jump); // create a file\n                                      std::cerr << \"Nikon makernote\" << std::endl;\n                                      // printTiffStructure(memIo,out,option,depth);\n                                      // TODO: fix it\n                                    }\n                                    else\n                                    {\n                                        // tag is an IFD\n                                        io.seek(0, BasicIo::beg);  // position\n                                        std::cerr << \"makernote\" << std::endl;\n                                        printIFD(out,option,offset,depth);\n                                    }\n\n                                    io.seek(restore,BasicIo::beg); // restore\n                                }\n                            }\n                        }\n\n                        const uint64_t nextDirOffset = readData(dataSize_);\n\n                        dir_offset = tooBig ? 0 : nextDirOffset;\n                        out.flush();\n                    } while (dir_offset != 0);\n\n                    if ( bPrint )\n                        out << Internal::indent(depth) << \"END \" << io.path() << std::endl;\n\n                    depth--;\n                }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -61,8 +61,12 @@\n                             // size * count > std::numeric_limits<uint64_t>::max()\n                             // =>\n                             // size > std::numeric_limits<uint64_t>::max() / count\n-                            if (size > std::numeric_limits<uint64_t>::max() / count)\n-                                throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n+                            // (don't perform that check when count == 0 => will cause a division by zero exception)\n+                            if (count != 0) {\n+                                if (size > std::numeric_limits<uint64_t>::max() / count) {\n+                                    throw Error(kerInvalidMalloc);             // we got number bigger than 2^64\n+                                }\n+                            }\n                                                              // more than we can handle\n \n                             if (size * count > std::numeric_limits<uint64_t>::max() - pad)",
        "diff_line_info": {
            "deleted_lines": [
                "                            if (size > std::numeric_limits<uint64_t>::max() / count)",
                "                                throw Error(kerInvalidMalloc);             // we got number bigger than 2^64"
            ],
            "added_lines": [
                "                            // (don't perform that check when count == 0 => will cause a division by zero exception)",
                "                            if (count != 0) {",
                "                                if (size > std::numeric_limits<uint64_t>::max() / count) {",
                "                                    throw Error(kerInvalidMalloc);             // we got number bigger than 2^64",
                "                                }",
                "                            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2018-1152",
        "func_name": "libjpeg-turbo/start_input_bmp",
        "description": "libjpeg-turbo 1.5.90 is vulnerable to a denial of service vulnerability caused by a divide by zero when processing a crafted BMP image.",
        "git_url": "https://github.com/libjpeg-turbo/libjpeg-turbo/commit/43e84cff1bb2bd8293066f6ac4eb0df61ddddbc6",
        "commit_title": "tjLoadImage(): Fix FPE triggered by malformed BMP",
        "commit_text": " In rdbmp.c, it is necessary to guard against 32-bit overflow/wraparound when allocating the row buffer, because since BMP files have 32-bit width and height fields, the value of biWidth can be up to 4294967295. Specifically, if biWidth is 1073741824 and cinfo->input_components = 4, then the samplesperrow argument in alloc_sarray() would wrap around to 0, and a division by zero error would occur at line 458 in jmemmgr.c.  If biWidth is set to a higher value, then samplesperrow would wrap around to a small number, which would likely cause a buffer overflow (this has not been tested or verified.)",
        "func_before": "METHODDEF(void)\nstart_input_bmp(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  bmp_source_ptr source = (bmp_source_ptr)sinfo;\n  U_CHAR bmpfileheader[14];\n  U_CHAR bmpinfoheader[64];\n\n#define GET_2B(array, offset) \\\n  ((unsigned short)UCH(array[offset]) + \\\n   (((unsigned short)UCH(array[offset + 1])) << 8))\n#define GET_4B(array, offset) \\\n  ((unsigned int)UCH(array[offset]) + \\\n   (((unsigned int)UCH(array[offset + 1])) << 8) + \\\n   (((unsigned int)UCH(array[offset + 2])) << 16) + \\\n   (((unsigned int)UCH(array[offset + 3])) << 24))\n\n  unsigned int bfOffBits;\n  unsigned int headerSize;\n  int biWidth;\n  int biHeight;\n  unsigned short biPlanes;\n  unsigned int biCompression;\n  int biXPelsPerMeter, biYPelsPerMeter;\n  unsigned int biClrUsed = 0;\n  int mapentrysize = 0;         /* 0 indicates no colormap */\n  int bPad;\n  JDIMENSION row_width = 0;\n\n  /* Read and verify the bitmap file header */\n  if (!ReadOK(source->pub.input_file, bmpfileheader, 14))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n  if (GET_2B(bmpfileheader, 0) != 0x4D42) /* 'BM' */\n    ERREXIT(cinfo, JERR_BMP_NOT);\n  bfOffBits = GET_4B(bmpfileheader, 10);\n  /* We ignore the remaining fileheader fields */\n\n  /* The infoheader might be 12 bytes (OS/2 1.x), 40 bytes (Windows),\n   * or 64 bytes (OS/2 2.x).  Check the first 4 bytes to find out which.\n   */\n  if (!ReadOK(source->pub.input_file, bmpinfoheader, 4))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n  headerSize = GET_4B(bmpinfoheader, 0);\n  if (headerSize < 12 || headerSize > 64)\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n  if (!ReadOK(source->pub.input_file, bmpinfoheader + 4, headerSize - 4))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n\n  switch (headerSize) {\n  case 12:\n    /* Decode OS/2 1.x header (Microsoft calls this a BITMAPCOREHEADER) */\n    biWidth = (int)GET_2B(bmpinfoheader, 4);\n    biHeight = (int)GET_2B(bmpinfoheader, 6);\n    biPlanes = GET_2B(bmpinfoheader, 8);\n    source->bits_per_pixel = (int)GET_2B(bmpinfoheader, 10);\n\n    switch (source->bits_per_pixel) {\n    case 8:                     /* colormapped image */\n      mapentrysize = 3;         /* OS/2 uses RGBTRIPLE colormap */\n      TRACEMS2(cinfo, 1, JTRC_BMP_OS2_MAPPED, biWidth, biHeight);\n      break;\n    case 24:                    /* RGB image */\n      TRACEMS2(cinfo, 1, JTRC_BMP_OS2, biWidth, biHeight);\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n      break;\n    }\n    break;\n  case 40:\n  case 64:\n    /* Decode Windows 3.x header (Microsoft calls this a BITMAPINFOHEADER) */\n    /* or OS/2 2.x header, which has additional fields that we ignore */\n    biWidth = (int)GET_4B(bmpinfoheader, 4);\n    biHeight = (int)GET_4B(bmpinfoheader, 8);\n    biPlanes = GET_2B(bmpinfoheader, 12);\n    source->bits_per_pixel = (int)GET_2B(bmpinfoheader, 14);\n    biCompression = GET_4B(bmpinfoheader, 16);\n    biXPelsPerMeter = (int)GET_4B(bmpinfoheader, 24);\n    biYPelsPerMeter = (int)GET_4B(bmpinfoheader, 28);\n    biClrUsed = GET_4B(bmpinfoheader, 32);\n    /* biSizeImage, biClrImportant fields are ignored */\n\n    switch (source->bits_per_pixel) {\n    case 8:                     /* colormapped image */\n      mapentrysize = 4;         /* Windows uses RGBQUAD colormap */\n      TRACEMS2(cinfo, 1, JTRC_BMP_MAPPED, biWidth, biHeight);\n      break;\n    case 24:                    /* RGB image */\n      TRACEMS2(cinfo, 1, JTRC_BMP, biWidth, biHeight);\n      break;\n    case 32:                    /* RGB image + Alpha channel */\n      TRACEMS2(cinfo, 1, JTRC_BMP, biWidth, biHeight);\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n      break;\n    }\n    if (biCompression != 0)\n      ERREXIT(cinfo, JERR_BMP_COMPRESSED);\n\n    if (biXPelsPerMeter > 0 && biYPelsPerMeter > 0) {\n      /* Set JFIF density parameters from the BMP data */\n      cinfo->X_density = (UINT16)(biXPelsPerMeter / 100); /* 100 cm per meter */\n      cinfo->Y_density = (UINT16)(biYPelsPerMeter / 100);\n      cinfo->density_unit = 2;  /* dots/cm */\n    }\n    break;\n  default:\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n    return;\n  }\n\n  if (biWidth <= 0 || biHeight <= 0)\n    ERREXIT(cinfo, JERR_BMP_EMPTY);\n  if (biPlanes != 1)\n    ERREXIT(cinfo, JERR_BMP_BADPLANES);\n\n  /* Compute distance to bitmap data --- will adjust for colormap below */\n  bPad = bfOffBits - (headerSize + 14);\n\n  /* Read the colormap, if any */\n  if (mapentrysize > 0) {\n    if (biClrUsed <= 0)\n      biClrUsed = 256;          /* assume it's 256 */\n    else if (biClrUsed > 256)\n      ERREXIT(cinfo, JERR_BMP_BADCMAP);\n    /* Allocate space to store the colormap */\n    source->colormap = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE, (JDIMENSION)biClrUsed, (JDIMENSION)3);\n    /* and read it from the file */\n    read_colormap(source, (int)biClrUsed, mapentrysize);\n    /* account for size of colormap */\n    bPad -= biClrUsed * mapentrysize;\n  }\n\n  /* Skip any remaining pad bytes */\n  if (bPad < 0)                 /* incorrect bfOffBits value? */\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n  while (--bPad >= 0) {\n    (void)read_byte(source);\n  }\n\n  /* Compute row width in file, including padding to 4-byte boundary */\n  switch (source->bits_per_pixel) {\n  case 8:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_GRAYSCALE)\n      cinfo->input_components = 1;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)biWidth;\n    break;\n  case 24:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_BGR;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)(biWidth * 3);\n    break;\n  case 32:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_BGRA;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)(biWidth * 4);\n    break;\n  default:\n    ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n  }\n  while ((row_width & 3) != 0) row_width++;\n  source->row_width = row_width;\n\n  if (source->use_inversion_array) {\n    /* Allocate space for inversion array, prepare for preload pass */\n    source->whole_image = (*cinfo->mem->request_virt_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE, FALSE,\n       row_width, (JDIMENSION)biHeight, (JDIMENSION)1);\n    source->pub.get_pixel_rows = preload_image;\n    if (cinfo->progress != NULL) {\n      cd_progress_ptr progress = (cd_progress_ptr)cinfo->progress;\n      progress->total_extra_passes++; /* count file input as separate pass */\n    }\n  } else {\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE, row_width);\n    switch (source->bits_per_pixel) {\n    case 8:\n      source->pub.get_pixel_rows = get_8bit_row;\n      break;\n    case 24:\n      source->pub.get_pixel_rows = get_24bit_row;\n      break;\n    case 32:\n      source->pub.get_pixel_rows = get_32bit_row;\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n    }\n  }\n\n  /* Allocate one-row buffer for returned data */\n  source->pub.buffer = (*cinfo->mem->alloc_sarray)\n    ((j_common_ptr)cinfo, JPOOL_IMAGE,\n     (JDIMENSION)(biWidth * cinfo->input_components), (JDIMENSION)1);\n  source->pub.buffer_height = 1;\n\n  cinfo->data_precision = 8;\n  cinfo->image_width = (JDIMENSION)biWidth;\n  cinfo->image_height = (JDIMENSION)biHeight;\n}",
        "func": "METHODDEF(void)\nstart_input_bmp(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  bmp_source_ptr source = (bmp_source_ptr)sinfo;\n  U_CHAR bmpfileheader[14];\n  U_CHAR bmpinfoheader[64];\n\n#define GET_2B(array, offset) \\\n  ((unsigned short)UCH(array[offset]) + \\\n   (((unsigned short)UCH(array[offset + 1])) << 8))\n#define GET_4B(array, offset) \\\n  ((unsigned int)UCH(array[offset]) + \\\n   (((unsigned int)UCH(array[offset + 1])) << 8) + \\\n   (((unsigned int)UCH(array[offset + 2])) << 16) + \\\n   (((unsigned int)UCH(array[offset + 3])) << 24))\n\n  unsigned int bfOffBits;\n  unsigned int headerSize;\n  int biWidth;\n  int biHeight;\n  unsigned short biPlanes;\n  unsigned int biCompression;\n  int biXPelsPerMeter, biYPelsPerMeter;\n  unsigned int biClrUsed = 0;\n  int mapentrysize = 0;         /* 0 indicates no colormap */\n  int bPad;\n  JDIMENSION row_width = 0;\n\n  /* Read and verify the bitmap file header */\n  if (!ReadOK(source->pub.input_file, bmpfileheader, 14))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n  if (GET_2B(bmpfileheader, 0) != 0x4D42) /* 'BM' */\n    ERREXIT(cinfo, JERR_BMP_NOT);\n  bfOffBits = GET_4B(bmpfileheader, 10);\n  /* We ignore the remaining fileheader fields */\n\n  /* The infoheader might be 12 bytes (OS/2 1.x), 40 bytes (Windows),\n   * or 64 bytes (OS/2 2.x).  Check the first 4 bytes to find out which.\n   */\n  if (!ReadOK(source->pub.input_file, bmpinfoheader, 4))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n  headerSize = GET_4B(bmpinfoheader, 0);\n  if (headerSize < 12 || headerSize > 64)\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n  if (!ReadOK(source->pub.input_file, bmpinfoheader + 4, headerSize - 4))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n\n  switch (headerSize) {\n  case 12:\n    /* Decode OS/2 1.x header (Microsoft calls this a BITMAPCOREHEADER) */\n    biWidth = (int)GET_2B(bmpinfoheader, 4);\n    biHeight = (int)GET_2B(bmpinfoheader, 6);\n    biPlanes = GET_2B(bmpinfoheader, 8);\n    source->bits_per_pixel = (int)GET_2B(bmpinfoheader, 10);\n\n    switch (source->bits_per_pixel) {\n    case 8:                     /* colormapped image */\n      mapentrysize = 3;         /* OS/2 uses RGBTRIPLE colormap */\n      TRACEMS2(cinfo, 1, JTRC_BMP_OS2_MAPPED, biWidth, biHeight);\n      break;\n    case 24:                    /* RGB image */\n      TRACEMS2(cinfo, 1, JTRC_BMP_OS2, biWidth, biHeight);\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n      break;\n    }\n    break;\n  case 40:\n  case 64:\n    /* Decode Windows 3.x header (Microsoft calls this a BITMAPINFOHEADER) */\n    /* or OS/2 2.x header, which has additional fields that we ignore */\n    biWidth = (int)GET_4B(bmpinfoheader, 4);\n    biHeight = (int)GET_4B(bmpinfoheader, 8);\n    biPlanes = GET_2B(bmpinfoheader, 12);\n    source->bits_per_pixel = (int)GET_2B(bmpinfoheader, 14);\n    biCompression = GET_4B(bmpinfoheader, 16);\n    biXPelsPerMeter = (int)GET_4B(bmpinfoheader, 24);\n    biYPelsPerMeter = (int)GET_4B(bmpinfoheader, 28);\n    biClrUsed = GET_4B(bmpinfoheader, 32);\n    /* biSizeImage, biClrImportant fields are ignored */\n\n    switch (source->bits_per_pixel) {\n    case 8:                     /* colormapped image */\n      mapentrysize = 4;         /* Windows uses RGBQUAD colormap */\n      TRACEMS2(cinfo, 1, JTRC_BMP_MAPPED, biWidth, biHeight);\n      break;\n    case 24:                    /* RGB image */\n      TRACEMS2(cinfo, 1, JTRC_BMP, biWidth, biHeight);\n      break;\n    case 32:                    /* RGB image + Alpha channel */\n      TRACEMS2(cinfo, 1, JTRC_BMP, biWidth, biHeight);\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n      break;\n    }\n    if (biCompression != 0)\n      ERREXIT(cinfo, JERR_BMP_COMPRESSED);\n\n    if (biXPelsPerMeter > 0 && biYPelsPerMeter > 0) {\n      /* Set JFIF density parameters from the BMP data */\n      cinfo->X_density = (UINT16)(biXPelsPerMeter / 100); /* 100 cm per meter */\n      cinfo->Y_density = (UINT16)(biYPelsPerMeter / 100);\n      cinfo->density_unit = 2;  /* dots/cm */\n    }\n    break;\n  default:\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n    return;\n  }\n\n  if (biWidth <= 0 || biHeight <= 0)\n    ERREXIT(cinfo, JERR_BMP_EMPTY);\n  if (biPlanes != 1)\n    ERREXIT(cinfo, JERR_BMP_BADPLANES);\n\n  /* Compute distance to bitmap data --- will adjust for colormap below */\n  bPad = bfOffBits - (headerSize + 14);\n\n  /* Read the colormap, if any */\n  if (mapentrysize > 0) {\n    if (biClrUsed <= 0)\n      biClrUsed = 256;          /* assume it's 256 */\n    else if (biClrUsed > 256)\n      ERREXIT(cinfo, JERR_BMP_BADCMAP);\n    /* Allocate space to store the colormap */\n    source->colormap = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE, (JDIMENSION)biClrUsed, (JDIMENSION)3);\n    /* and read it from the file */\n    read_colormap(source, (int)biClrUsed, mapentrysize);\n    /* account for size of colormap */\n    bPad -= biClrUsed * mapentrysize;\n  }\n\n  /* Skip any remaining pad bytes */\n  if (bPad < 0)                 /* incorrect bfOffBits value? */\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n  while (--bPad >= 0) {\n    (void)read_byte(source);\n  }\n\n  /* Compute row width in file, including padding to 4-byte boundary */\n  switch (source->bits_per_pixel) {\n  case 8:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_GRAYSCALE)\n      cinfo->input_components = 1;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)biWidth;\n    break;\n  case 24:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_BGR;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)(biWidth * 3);\n    break;\n  case 32:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_BGRA;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)(biWidth * 4);\n    break;\n  default:\n    ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n  }\n  while ((row_width & 3) != 0) row_width++;\n  source->row_width = row_width;\n\n  if (source->use_inversion_array) {\n    /* Allocate space for inversion array, prepare for preload pass */\n    source->whole_image = (*cinfo->mem->request_virt_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE, FALSE,\n       row_width, (JDIMENSION)biHeight, (JDIMENSION)1);\n    source->pub.get_pixel_rows = preload_image;\n    if (cinfo->progress != NULL) {\n      cd_progress_ptr progress = (cd_progress_ptr)cinfo->progress;\n      progress->total_extra_passes++; /* count file input as separate pass */\n    }\n  } else {\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE, row_width);\n    switch (source->bits_per_pixel) {\n    case 8:\n      source->pub.get_pixel_rows = get_8bit_row;\n      break;\n    case 24:\n      source->pub.get_pixel_rows = get_24bit_row;\n      break;\n    case 32:\n      source->pub.get_pixel_rows = get_32bit_row;\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n    }\n  }\n\n  /* Ensure that biWidth * cinfo->input_components doesn't exceed the maximum\n     value of the JDIMENSION type.  This is only a danger with BMP files, since\n     their width and height fields are 32-bit integers. */\n  if ((unsigned long long)biWidth *\n      (unsigned long long)cinfo->input_components > 0xFFFFFFFFULL)\n    ERREXIT(cinfo, JERR_WIDTH_OVERFLOW);\n  /* Allocate one-row buffer for returned data */\n  source->pub.buffer = (*cinfo->mem->alloc_sarray)\n    ((j_common_ptr)cinfo, JPOOL_IMAGE,\n     (JDIMENSION)(biWidth * cinfo->input_components), (JDIMENSION)1);\n  source->pub.buffer_height = 1;\n\n  cinfo->data_precision = 8;\n  cinfo->image_width = (JDIMENSION)biWidth;\n  cinfo->image_height = (JDIMENSION)biHeight;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -211,6 +211,12 @@\n     }\n   }\n \n+  /* Ensure that biWidth * cinfo->input_components doesn't exceed the maximum\n+     value of the JDIMENSION type.  This is only a danger with BMP files, since\n+     their width and height fields are 32-bit integers. */\n+  if ((unsigned long long)biWidth *\n+      (unsigned long long)cinfo->input_components > 0xFFFFFFFFULL)\n+    ERREXIT(cinfo, JERR_WIDTH_OVERFLOW);\n   /* Allocate one-row buffer for returned data */\n   source->pub.buffer = (*cinfo->mem->alloc_sarray)\n     ((j_common_ptr)cinfo, JPOOL_IMAGE,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  /* Ensure that biWidth * cinfo->input_components doesn't exceed the maximum",
                "     value of the JDIMENSION type.  This is only a danger with BMP files, since",
                "     their width and height fields are 32-bit integers. */",
                "  if ((unsigned long long)biWidth *",
                "      (unsigned long long)cinfo->input_components > 0xFFFFFFFFULL)",
                "    ERREXIT(cinfo, JERR_WIDTH_OVERFLOW);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0207",
        "func_name": "torvalds/linux/igmp_heard_query",
        "description": "The igmp_heard_query function in net/ipv4/igmp.c in the Linux kernel before 3.2.1 allows remote attackers to cause a denial of service (divide-by-zero error and panic) via IGMP packets.",
        "git_url": "https://github.com/torvalds/linux/commit/25c413ad0029ea86008234be28aee33456e53e5b",
        "commit_title": "igmp: Avoid zero delay when receiving odd mixture of IGMP queries",
        "commit_text": " commit a8c1f65c79cbbb2f7da782d4c9d15639a9b94b27 upstream.  Commit 5b7c84066733c5dfb0e4016d939757b38de189e4 ('ipv4: correct IGMP behavior on v3 query during v2-compatibility mode') added yet another case for query parsing, which can result in max_delay = 0.  Substitute a value of 1, as in the usual v3 case.  References: http://bugs.debian.org/654876",
        "func_before": "static void igmp_heard_query(struct in_device *in_dev, struct sk_buff *skb,\n\tint len)\n{\n\tstruct igmphdr \t\t*ih = igmp_hdr(skb);\n\tstruct igmpv3_query *ih3 = igmpv3_query_hdr(skb);\n\tstruct ip_mc_list\t*im;\n\t__be32\t\t\tgroup = ih->group;\n\tint\t\t\tmax_delay;\n\tint\t\t\tmark = 0;\n\n\n\tif (len == 8) {\n\t\tif (ih->code == 0) {\n\t\t\t/* Alas, old v1 router presents here. */\n\n\t\t\tmax_delay = IGMP_Query_Response_Interval;\n\t\t\tin_dev->mr_v1_seen = jiffies +\n\t\t\t\tIGMP_V1_Router_Present_Timeout;\n\t\t\tgroup = 0;\n\t\t} else {\n\t\t\t/* v2 router present */\n\t\t\tmax_delay = ih->code*(HZ/IGMP_TIMER_SCALE);\n\t\t\tin_dev->mr_v2_seen = jiffies +\n\t\t\t\tIGMP_V2_Router_Present_Timeout;\n\t\t}\n\t\t/* cancel the interface change timer */\n\t\tin_dev->mr_ifc_count = 0;\n\t\tif (del_timer(&in_dev->mr_ifc_timer))\n\t\t\t__in_dev_put(in_dev);\n\t\t/* clear deleted report items */\n\t\tigmpv3_clear_delrec(in_dev);\n\t} else if (len < 12) {\n\t\treturn;\t/* ignore bogus packet; freed by caller */\n\t} else if (IGMP_V1_SEEN(in_dev)) {\n\t\t/* This is a v3 query with v1 queriers present */\n\t\tmax_delay = IGMP_Query_Response_Interval;\n\t\tgroup = 0;\n\t} else if (IGMP_V2_SEEN(in_dev)) {\n\t\t/* this is a v3 query with v2 queriers present;\n\t\t * Interpretation of the max_delay code is problematic here.\n\t\t * A real v2 host would use ih_code directly, while v3 has a\n\t\t * different encoding. We use the v3 encoding as more likely\n\t\t * to be intended in a v3 query.\n\t\t */\n\t\tmax_delay = IGMPV3_MRC(ih3->code)*(HZ/IGMP_TIMER_SCALE);\n\t} else { /* v3 */\n\t\tif (!pskb_may_pull(skb, sizeof(struct igmpv3_query)))\n\t\t\treturn;\n\n\t\tih3 = igmpv3_query_hdr(skb);\n\t\tif (ih3->nsrcs) {\n\t\t\tif (!pskb_may_pull(skb, sizeof(struct igmpv3_query)\n\t\t\t\t\t   + ntohs(ih3->nsrcs)*sizeof(__be32)))\n\t\t\t\treturn;\n\t\t\tih3 = igmpv3_query_hdr(skb);\n\t\t}\n\n\t\tmax_delay = IGMPV3_MRC(ih3->code)*(HZ/IGMP_TIMER_SCALE);\n\t\tif (!max_delay)\n\t\t\tmax_delay = 1;\t/* can't mod w/ 0 */\n\t\tin_dev->mr_maxdelay = max_delay;\n\t\tif (ih3->qrv)\n\t\t\tin_dev->mr_qrv = ih3->qrv;\n\t\tif (!group) { /* general query */\n\t\t\tif (ih3->nsrcs)\n\t\t\t\treturn;\t/* no sources allowed */\n\t\t\tigmp_gq_start_timer(in_dev);\n\t\t\treturn;\n\t\t}\n\t\t/* mark sources to include, if group & source-specific */\n\t\tmark = ih3->nsrcs != 0;\n\t}\n\n\t/*\n\t * - Start the timers in all of our membership records\n\t *   that the query applies to for the interface on\n\t *   which the query arrived excl. those that belong\n\t *   to a \"local\" group (224.0.0.X)\n\t * - For timers already running check if they need to\n\t *   be reset.\n\t * - Use the igmp->igmp_code field as the maximum\n\t *   delay possible\n\t */\n\trcu_read_lock();\n\tfor_each_pmc_rcu(in_dev, im) {\n\t\tint changed;\n\n\t\tif (group && group != im->multiaddr)\n\t\t\tcontinue;\n\t\tif (im->multiaddr == IGMP_ALL_HOSTS)\n\t\t\tcontinue;\n\t\tspin_lock_bh(&im->lock);\n\t\tif (im->tm_running)\n\t\t\tim->gsquery = im->gsquery && mark;\n\t\telse\n\t\t\tim->gsquery = mark;\n\t\tchanged = !im->gsquery ||\n\t\t\tigmp_marksources(im, ntohs(ih3->nsrcs), ih3->srcs);\n\t\tspin_unlock_bh(&im->lock);\n\t\tif (changed)\n\t\t\tigmp_mod_timer(im, max_delay);\n\t}\n\trcu_read_unlock();\n}",
        "func": "static void igmp_heard_query(struct in_device *in_dev, struct sk_buff *skb,\n\tint len)\n{\n\tstruct igmphdr \t\t*ih = igmp_hdr(skb);\n\tstruct igmpv3_query *ih3 = igmpv3_query_hdr(skb);\n\tstruct ip_mc_list\t*im;\n\t__be32\t\t\tgroup = ih->group;\n\tint\t\t\tmax_delay;\n\tint\t\t\tmark = 0;\n\n\n\tif (len == 8) {\n\t\tif (ih->code == 0) {\n\t\t\t/* Alas, old v1 router presents here. */\n\n\t\t\tmax_delay = IGMP_Query_Response_Interval;\n\t\t\tin_dev->mr_v1_seen = jiffies +\n\t\t\t\tIGMP_V1_Router_Present_Timeout;\n\t\t\tgroup = 0;\n\t\t} else {\n\t\t\t/* v2 router present */\n\t\t\tmax_delay = ih->code*(HZ/IGMP_TIMER_SCALE);\n\t\t\tin_dev->mr_v2_seen = jiffies +\n\t\t\t\tIGMP_V2_Router_Present_Timeout;\n\t\t}\n\t\t/* cancel the interface change timer */\n\t\tin_dev->mr_ifc_count = 0;\n\t\tif (del_timer(&in_dev->mr_ifc_timer))\n\t\t\t__in_dev_put(in_dev);\n\t\t/* clear deleted report items */\n\t\tigmpv3_clear_delrec(in_dev);\n\t} else if (len < 12) {\n\t\treturn;\t/* ignore bogus packet; freed by caller */\n\t} else if (IGMP_V1_SEEN(in_dev)) {\n\t\t/* This is a v3 query with v1 queriers present */\n\t\tmax_delay = IGMP_Query_Response_Interval;\n\t\tgroup = 0;\n\t} else if (IGMP_V2_SEEN(in_dev)) {\n\t\t/* this is a v3 query with v2 queriers present;\n\t\t * Interpretation of the max_delay code is problematic here.\n\t\t * A real v2 host would use ih_code directly, while v3 has a\n\t\t * different encoding. We use the v3 encoding as more likely\n\t\t * to be intended in a v3 query.\n\t\t */\n\t\tmax_delay = IGMPV3_MRC(ih3->code)*(HZ/IGMP_TIMER_SCALE);\n\t\tif (!max_delay)\n\t\t\tmax_delay = 1;\t/* can't mod w/ 0 */\n\t} else { /* v3 */\n\t\tif (!pskb_may_pull(skb, sizeof(struct igmpv3_query)))\n\t\t\treturn;\n\n\t\tih3 = igmpv3_query_hdr(skb);\n\t\tif (ih3->nsrcs) {\n\t\t\tif (!pskb_may_pull(skb, sizeof(struct igmpv3_query)\n\t\t\t\t\t   + ntohs(ih3->nsrcs)*sizeof(__be32)))\n\t\t\t\treturn;\n\t\t\tih3 = igmpv3_query_hdr(skb);\n\t\t}\n\n\t\tmax_delay = IGMPV3_MRC(ih3->code)*(HZ/IGMP_TIMER_SCALE);\n\t\tif (!max_delay)\n\t\t\tmax_delay = 1;\t/* can't mod w/ 0 */\n\t\tin_dev->mr_maxdelay = max_delay;\n\t\tif (ih3->qrv)\n\t\t\tin_dev->mr_qrv = ih3->qrv;\n\t\tif (!group) { /* general query */\n\t\t\tif (ih3->nsrcs)\n\t\t\t\treturn;\t/* no sources allowed */\n\t\t\tigmp_gq_start_timer(in_dev);\n\t\t\treturn;\n\t\t}\n\t\t/* mark sources to include, if group & source-specific */\n\t\tmark = ih3->nsrcs != 0;\n\t}\n\n\t/*\n\t * - Start the timers in all of our membership records\n\t *   that the query applies to for the interface on\n\t *   which the query arrived excl. those that belong\n\t *   to a \"local\" group (224.0.0.X)\n\t * - For timers already running check if they need to\n\t *   be reset.\n\t * - Use the igmp->igmp_code field as the maximum\n\t *   delay possible\n\t */\n\trcu_read_lock();\n\tfor_each_pmc_rcu(in_dev, im) {\n\t\tint changed;\n\n\t\tif (group && group != im->multiaddr)\n\t\t\tcontinue;\n\t\tif (im->multiaddr == IGMP_ALL_HOSTS)\n\t\t\tcontinue;\n\t\tspin_lock_bh(&im->lock);\n\t\tif (im->tm_running)\n\t\t\tim->gsquery = im->gsquery && mark;\n\t\telse\n\t\t\tim->gsquery = mark;\n\t\tchanged = !im->gsquery ||\n\t\t\tigmp_marksources(im, ntohs(ih3->nsrcs), ih3->srcs);\n\t\tspin_unlock_bh(&im->lock);\n\t\tif (changed)\n\t\t\tigmp_mod_timer(im, max_delay);\n\t}\n\trcu_read_unlock();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -43,6 +43,8 @@\n \t\t * to be intended in a v3 query.\n \t\t */\n \t\tmax_delay = IGMPV3_MRC(ih3->code)*(HZ/IGMP_TIMER_SCALE);\n+\t\tif (!max_delay)\n+\t\t\tmax_delay = 1;\t/* can't mod w/ 0 */\n \t} else { /* v3 */\n \t\tif (!pskb_may_pull(skb, sizeof(struct igmpv3_query)))\n \t\t\treturn;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (!max_delay)",
                "\t\t\tmax_delay = 1;\t/* can't mod w/ 0 */"
            ]
        }
    }
]