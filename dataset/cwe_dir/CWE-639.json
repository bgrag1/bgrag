[
    {
        "cve_id": "CVE-2023-49298",
        "func_name": "openzfs/zfs/dnode_is_dirty",
        "description": "OpenZFS through 2.1.13 and 2.2.x through 2.2.1, in certain scenarios involving applications that try to rely on efficient copying of file data, can replace file contents with zero-valued bytes and thus potentially disable security mechanisms. NOTE: this issue is not always security related, but can be security related in realistic situations. A possible example is cp, from a recent GNU Core Utilities (coreutils) version, when attempting to preserve a rule set for denying unauthorized access. (One might use cp when configuring access control, such as with the /etc/hosts.deny file specified in the IBM Support reference.) NOTE: this issue occurs less often in version 2.2.1, and in versions before 2.1.4, because of the default configuration in those versions.",
        "git_url": "https://github.com/openzfs/zfs/commit/c7fadf230f26be750feddaebda95e5cc66896107",
        "commit_title": "dnode_is_dirty: check dnode and its data for dirtiness",
        "commit_text": " Over its history this the dirty dnode test has been changed between checking for a dnodes being on `os_dirty_dnodes` (`dn_dirty_link`) and `dn_dirty_record`.    de198f2d9 Fix lseek(SEEK_DATA/SEEK_HOLE) mmap consistency   2531ce372 Revert \"Report holes when there are only metadata changes\"   ec4f9b8f3 Report holes when there are only metadata changes   454365bba Fix dirty check in dmu_offset_next()   66aca2473 SEEK_HOLE should not block on txg_wait_synced()  Also illumos/illumos-gate@c543ec060d illumos/illumos-gate@2bcf0248e9  It turns out both are actually required.  In the case of appending data to a newly created file, the dnode proper is dirtied (at least to change the blocksize) and dirty records are added.  Thus, a single logical operation is represented by separate dirty indicators, and must not be separated.  The incorrect dirty check becomes a problem when the first block of a file is being appended to while another process is calling lseek to skip holes. There is a small window where the dnode part is undirtied while there are still dirty records. In this case, `lseek(fd, 0, SEEK_DATA)` would not know that the file is dirty, and would go to `dnode_next_offset()`. Since the object has no data blocks yet, it returns `ESRCH`, indicating no data found, which results in `ENXIO` being returned to `lseek()`'s caller.  Since coreutils 9.2, `cp` performs sparse copies by default, that is, it uses `SEEK_DATA` and `SEEK_HOLE` against the source file and attempts to replicate the holes in the target. When it hits the bug, its initial search for data fails, and it goes on to call `fallocate()` to create a hole over the entire destination file.  This has come up more recently as users upgrade their systems, getting OpenZFS 2.2 as well as a newer coreutils. However, this problem has been reproduced against 2.1, as well as on FreeBSD 13 and 14.  This change simply updates the dirty check to check both types of dirty. If there's anything dirty at all, we immediately go to the \"wait for sync\" stage, It doesn't really matter after that; both changes are on disk, so the dirty fields should be correct.  Sponsored-by: Klara, Inc. Sponsored-by: Wasabi Technology, Inc.",
        "func_before": "boolean_t\ndnode_is_dirty(dnode_t *dn)\n{\n\tmutex_enter(&dn->dn_mtx);\n\n\tfor (int i = 0; i < TXG_SIZE; i++) {\n\t\tif (multilist_link_active(&dn->dn_dirty_link[i])) {\n\t\t\tmutex_exit(&dn->dn_mtx);\n\t\t\treturn (B_TRUE);\n\t\t}\n\t}\n\n\tmutex_exit(&dn->dn_mtx);\n\n\treturn (B_FALSE);\n}",
        "func": "boolean_t\ndnode_is_dirty(dnode_t *dn)\n{\n\tmutex_enter(&dn->dn_mtx);\n\n\tfor (int i = 0; i < TXG_SIZE; i++) {\n\t\tif (multilist_link_active(&dn->dn_dirty_link[i]) ||\n\t\t    !list_is_empty(&dn->dn_dirty_records[i])) {\n\t\t\tmutex_exit(&dn->dn_mtx);\n\t\t\treturn (B_TRUE);\n\t\t}\n\t}\n\n\tmutex_exit(&dn->dn_mtx);\n\n\treturn (B_FALSE);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,8 @@\n \tmutex_enter(&dn->dn_mtx);\n \n \tfor (int i = 0; i < TXG_SIZE; i++) {\n-\t\tif (multilist_link_active(&dn->dn_dirty_link[i])) {\n+\t\tif (multilist_link_active(&dn->dn_dirty_link[i]) ||\n+\t\t    !list_is_empty(&dn->dn_dirty_records[i])) {\n \t\t\tmutex_exit(&dn->dn_mtx);\n \t\t\treturn (B_TRUE);\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (multilist_link_active(&dn->dn_dirty_link[i])) {"
            ],
            "added_lines": [
                "\t\tif (multilist_link_active(&dn->dn_dirty_link[i]) ||",
                "\t\t    !list_is_empty(&dn->dn_dirty_records[i])) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2021-43820",
        "func_name": "haiwen/seafile-server/validate_token",
        "description": "Seafile is an open source cloud storage system. A sync token is used in Seafile file syncing protocol to authorize access to library data. To improve performance, the token is cached in memory in seaf-server. Upon receiving a token from sync client or SeaDrive client, the server checks whether the token exist in the cache. However, if the token exists in cache, the server doesn't check whether it's associated with the specific library in the URL. This vulnerability makes it possible to use any valid sync token to access data from any **known** library. Note that the attacker has to first find out the ID of a library which it has no access to. The library ID is a random UUID, which is not possible to be guessed. There are no workarounds for this issue.",
        "git_url": "https://github.com/haiwen/seafile-server/commit/c7c38c129fb8cee5ee14f44982283f4527133dcf",
        "commit_title": "Validate repo_id when validate token from cache",
        "commit_text": "",
        "func_before": "static int\nvalidate_token (HttpServer *htp_server, evhtp_request_t *req,\n                const char *repo_id, char **username,\n                gboolean skip_cache)\n{\n    char *email = NULL;\n    TokenInfo *token_info;\n\n    const char *token = evhtp_kv_find (req->headers_in, \"Seafile-Repo-Token\");\n    if (token == NULL) {\n        evhtp_send_reply (req, EVHTP_RES_BADREQ);\n        return EVHTP_RES_BADREQ;\n    }\n\n    if (!skip_cache) {\n        pthread_mutex_lock (&htp_server->token_cache_lock);\n\n        token_info = g_hash_table_lookup (htp_server->token_cache, token);\n        if (token_info) {\n            if (username)\n                *username = g_strdup(token_info->email);\n            pthread_mutex_unlock (&htp_server->token_cache_lock);\n            return EVHTP_RES_OK;\n        }\n\n        pthread_mutex_unlock (&htp_server->token_cache_lock);\n    }\n\n    email = seaf_repo_manager_get_email_by_token (seaf->repo_mgr,\n                                                  repo_id, token);\n    if (email == NULL) {\n        pthread_mutex_lock (&htp_server->token_cache_lock);\n        g_hash_table_remove (htp_server->token_cache, token);\n        pthread_mutex_unlock (&htp_server->token_cache_lock);\n        return EVHTP_RES_FORBIDDEN;\n    }\n\n    token_info = g_new0 (TokenInfo, 1);\n    token_info->repo_id = g_strdup (repo_id);\n    token_info->expire_time = (gint64)time(NULL) + TOKEN_EXPIRE_TIME;\n    token_info->email = email;\n\n    pthread_mutex_lock (&htp_server->token_cache_lock);\n    g_hash_table_insert (htp_server->token_cache, g_strdup (token), token_info);\n    pthread_mutex_unlock (&htp_server->token_cache_lock);\n\n    if (username)\n        *username = g_strdup(email);\n    return EVHTP_RES_OK;\n}",
        "func": "static int\nvalidate_token (HttpServer *htp_server, evhtp_request_t *req,\n                const char *repo_id, char **username,\n                gboolean skip_cache)\n{\n    char *email = NULL;\n    TokenInfo *token_info;\n\n    const char *token = evhtp_kv_find (req->headers_in, \"Seafile-Repo-Token\");\n    if (token == NULL) {\n        evhtp_send_reply (req, EVHTP_RES_BADREQ);\n        return EVHTP_RES_BADREQ;\n    }\n\n    if (!skip_cache) {\n        pthread_mutex_lock (&htp_server->token_cache_lock);\n\n        token_info = g_hash_table_lookup (htp_server->token_cache, token);\n        if (token_info && strcmp (token_info->repo_id, repo_id) == 0) {\n            if (username)\n                *username = g_strdup(token_info->email);\n            pthread_mutex_unlock (&htp_server->token_cache_lock);\n            return EVHTP_RES_OK;\n        }\n\n        pthread_mutex_unlock (&htp_server->token_cache_lock);\n    }\n\n    email = seaf_repo_manager_get_email_by_token (seaf->repo_mgr,\n                                                  repo_id, token);\n    if (email == NULL) {\n        pthread_mutex_lock (&htp_server->token_cache_lock);\n        g_hash_table_remove (htp_server->token_cache, token);\n        pthread_mutex_unlock (&htp_server->token_cache_lock);\n        return EVHTP_RES_FORBIDDEN;\n    }\n\n    token_info = g_new0 (TokenInfo, 1);\n    token_info->repo_id = g_strdup (repo_id);\n    token_info->expire_time = (gint64)time(NULL) + TOKEN_EXPIRE_TIME;\n    token_info->email = email;\n\n    pthread_mutex_lock (&htp_server->token_cache_lock);\n    g_hash_table_insert (htp_server->token_cache, g_strdup (token), token_info);\n    pthread_mutex_unlock (&htp_server->token_cache_lock);\n\n    if (username)\n        *username = g_strdup(email);\n    return EVHTP_RES_OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,7 @@\n         pthread_mutex_lock (&htp_server->token_cache_lock);\n \n         token_info = g_hash_table_lookup (htp_server->token_cache, token);\n-        if (token_info) {\n+        if (token_info && strcmp (token_info->repo_id, repo_id) == 0) {\n             if (username)\n                 *username = g_strdup(token_info->email);\n             pthread_mutex_unlock (&htp_server->token_cache_lock);",
        "diff_line_info": {
            "deleted_lines": [
                "        if (token_info) {"
            ],
            "added_lines": [
                "        if (token_info && strcmp (token_info->repo_id, repo_id) == 0) {"
            ]
        }
    }
]