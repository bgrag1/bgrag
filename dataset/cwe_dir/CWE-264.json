[
    {
        "cve_id": "CVE-2016-10151",
        "func_name": "achernya/hesiod/hesiod_init",
        "description": "The hesiod_init function in lib/hesiod.c in Hesiod 3.2.1 compares EUID with UID to determine whether to use configurations from environment variables, which allows local users to gain privileges via the (1) HESIOD_CONFIG or (2) HES_DOMAIN environment variable and leveraging certain SUID/SGUID binary.",
        "git_url": "https://github.com/achernya/hesiod/commit/39b21dac9bc6473365de04d94be0da94941c7c73",
        "commit_title": "Use secure_getenv() when it's available",
        "commit_text": " Factor out logic that attempts to only consult the environment when it's safe to do so into its own function, and use secure_getenv() instead of getenv() if it's available.  Original report from https://bugzilla.redhat.com/show_bug.cgi?id=1332508",
        "func_before": "int hesiod_init(void **context)\n{\n  struct hesiod_p *ctx;\n  const char *p, *configname;\n\n  ctx = malloc(sizeof(struct hesiod_p));\n  if (ctx)\n    {\n      *context = ctx;\n      configname = ((getuid() == geteuid()) && (getgid() == getegid())) ? getenv(\"HESIOD_CONFIG\") : NULL;\n      if (!configname)\n\tconfigname = SYSCONFDIR \"/hesiod.conf\";\n      if (read_config_file(ctx, configname) >= 0)\n\t{\n\t  /* The default rhs can be overridden by an environment variable. */\n\t  p = ((getuid() == geteuid()) && (getgid() == getegid())) ? getenv(\"HES_DOMAIN\") : NULL;\n\t  if (p)\n\t    {\n\t      if (ctx->rhs)\n\t\tfree(ctx->rhs);\n\t      ctx->rhs = malloc(strlen(p) + 2);\n\t      if (ctx->rhs)\n\t\t{\n\t\t  *ctx->rhs = '.';\n\t\t  strcpy(ctx->rhs + 1, (*p == '.') ? p + 1 : p);\n\t\t  return 0;\n\t\t}\n\t      else\n\t\terrno = ENOMEM;\n\t    }\n\t  else\n\t    return 0;\n\t}\n    }\n  else\n    errno = ENOMEM;\n\n  if (ctx->lhs)\n    free(ctx->lhs);\n  if (ctx->rhs)\n    free(ctx->rhs);\n  if (ctx)\n    free(ctx);\n  return -1;\n}",
        "func": "int hesiod_init(void **context)\n{\n  struct hesiod_p *ctx;\n  const char *p, *configname;\n\n  ctx = malloc(sizeof(struct hesiod_p));\n  if (ctx)\n    {\n      *context = ctx;\n      configname = hesiod_getenv(\"HESIOD_CONFIG\");\n      if (!configname)\n\tconfigname = SYSCONFDIR \"/hesiod.conf\";\n      if (read_config_file(ctx, configname) >= 0)\n\t{\n\t  /* The default rhs can be overridden by an environment variable. */\n\t  p = hesiod_getenv(\"HES_DOMAIN\");\n\t  if (p)\n\t    {\n\t      if (ctx->rhs)\n\t\tfree(ctx->rhs);\n\t      ctx->rhs = malloc(strlen(p) + 2);\n\t      if (ctx->rhs)\n\t\t{\n\t\t  *ctx->rhs = '.';\n\t\t  strcpy(ctx->rhs + 1, (*p == '.') ? p + 1 : p);\n\t\t  return 0;\n\t\t}\n\t      else\n\t\terrno = ENOMEM;\n\t    }\n\t  else\n\t    return 0;\n\t}\n    }\n  else\n    errno = ENOMEM;\n\n  if (ctx->lhs)\n    free(ctx->lhs);\n  if (ctx->rhs)\n    free(ctx->rhs);\n  if (ctx)\n    free(ctx);\n  return -1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,13 +7,13 @@\n   if (ctx)\n     {\n       *context = ctx;\n-      configname = ((getuid() == geteuid()) && (getgid() == getegid())) ? getenv(\"HESIOD_CONFIG\") : NULL;\n+      configname = hesiod_getenv(\"HESIOD_CONFIG\");\n       if (!configname)\n \tconfigname = SYSCONFDIR \"/hesiod.conf\";\n       if (read_config_file(ctx, configname) >= 0)\n \t{\n \t  /* The default rhs can be overridden by an environment variable. */\n-\t  p = ((getuid() == geteuid()) && (getgid() == getegid())) ? getenv(\"HES_DOMAIN\") : NULL;\n+\t  p = hesiod_getenv(\"HES_DOMAIN\");\n \t  if (p)\n \t    {\n \t      if (ctx->rhs)",
        "diff_line_info": {
            "deleted_lines": [
                "      configname = ((getuid() == geteuid()) && (getgid() == getegid())) ? getenv(\"HESIOD_CONFIG\") : NULL;",
                "\t  p = ((getuid() == geteuid()) && (getgid() == getegid())) ? getenv(\"HES_DOMAIN\") : NULL;"
            ],
            "added_lines": [
                "      configname = hesiod_getenv(\"HESIOD_CONFIG\");",
                "\t  p = hesiod_getenv(\"HES_DOMAIN\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8994",
        "func_name": "php/php-src/zend_accel_hash_unlink",
        "description": "An issue was discovered in PHP 5.x and 7.x, when the configuration uses apache2handler/mod_php or php-fpm with OpCache enabled. With 5.x after 5.6.28 or 7.x after 7.0.13, the issue is resolved in a non-default configuration with the opcache.validate_permission=1 setting. The vulnerability details are as follows. In PHP SAPIs where PHP interpreters share a common parent process, Zend OpCache creates a shared memory object owned by the common parent during initialization. Child PHP processes inherit the SHM descriptor, using it to cache and retrieve compiled script bytecode (\"opcode\" in PHP jargon). Cache keys vary depending on configuration, but filename is a central key component, and compiled opcode can generally be run if a script's filename is known or can be guessed. Many common shared-hosting configurations change EUID in child processes to enforce privilege separation among hosted users (for example using mod_ruid2 for the Apache HTTP Server, or php-fpm user settings). In these scenarios, the default Zend OpCache behavior defeats script file permissions by sharing a single SHM cache among all child PHP processes. PHP scripts often contain sensitive information: Think of CMS configurations where reading or running another user's script usually means gaining privileges to the CMS database.",
        "git_url": "https://github.com/php/php-src/commit/ecba563f2fa1e027ea91b9ee0d50611273852995",
        "commit_title": "Fixed bug #69090 (check cached files permissions)",
        "commit_text": "",
        "func_before": "int zend_accel_hash_unlink(zend_accel_hash *accel_hash, char *key, zend_uint key_length)\n{\n\tzend_ulong hash_value;\n    zend_ulong index;\n    zend_accel_hash_entry *entry, *last_entry=NULL;\n\n\thash_value = zend_inline_hash_func(key, key_length);\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\t\t\tif (!entry->indirect) {\n\t\t\t\taccel_hash->num_direct_entries--;\n\t\t\t}\n\t\t\tif (last_entry) {\n\t\t\t\tlast_entry->next = entry->next;\n\t\t\t} else {\n\t\t\t\taccel_hash->hash_table[index] = entry->next;\n\t\t\t}\n\t\t\treturn SUCCESS;\n\t\t}\n\t\tlast_entry = entry;\n\t\tentry = entry->next;\n\t}\n\treturn FAILURE;\n}",
        "func": "int zend_accel_hash_unlink(zend_accel_hash *accel_hash, char *key, zend_uint key_length)\n{\n\tzend_ulong hash_value;\n    zend_ulong index;\n    zend_accel_hash_entry *entry, *last_entry=NULL;\n\n\thash_value = zend_inline_hash_func(key, key_length);\n#ifndef ZEND_WIN32\n\thash_value ^= ZCG(root_hash);\n#endif\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\t\t\tif (!entry->indirect) {\n\t\t\t\taccel_hash->num_direct_entries--;\n\t\t\t}\n\t\t\tif (last_entry) {\n\t\t\t\tlast_entry->next = entry->next;\n\t\t\t} else {\n\t\t\t\taccel_hash->hash_table[index] = entry->next;\n\t\t\t}\n\t\t\treturn SUCCESS;\n\t\t}\n\t\tlast_entry = entry;\n\t\tentry = entry->next;\n\t}\n\treturn FAILURE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,9 @@\n     zend_accel_hash_entry *entry, *last_entry=NULL;\n \n \thash_value = zend_inline_hash_func(key, key_length);\n+#ifndef ZEND_WIN32\n+\thash_value ^= ZCG(root_hash);\n+#endif\n \tindex = hash_value % accel_hash->max_num_entries;\n \n \tentry = accel_hash->hash_table[index];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifndef ZEND_WIN32",
                "\thash_value ^= ZCG(root_hash);",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8994",
        "func_name": "php/php-src/zend_accel_hash_find",
        "description": "An issue was discovered in PHP 5.x and 7.x, when the configuration uses apache2handler/mod_php or php-fpm with OpCache enabled. With 5.x after 5.6.28 or 7.x after 7.0.13, the issue is resolved in a non-default configuration with the opcache.validate_permission=1 setting. The vulnerability details are as follows. In PHP SAPIs where PHP interpreters share a common parent process, Zend OpCache creates a shared memory object owned by the common parent during initialization. Child PHP processes inherit the SHM descriptor, using it to cache and retrieve compiled script bytecode (\"opcode\" in PHP jargon). Cache keys vary depending on configuration, but filename is a central key component, and compiled opcode can generally be run if a script's filename is known or can be guessed. Many common shared-hosting configurations change EUID in child processes to enforce privilege separation among hosted users (for example using mod_ruid2 for the Apache HTTP Server, or php-fpm user settings). In these scenarios, the default Zend OpCache behavior defeats script file permissions by sharing a single SHM cache among all child PHP processes. PHP scripts often contain sensitive information: Think of CMS configurations where reading or running another user's script usually means gaining privileges to the CMS database.",
        "git_url": "https://github.com/php/php-src/commit/ecba563f2fa1e027ea91b9ee0d50611273852995",
        "commit_title": "Fixed bug #69090 (check cached files permissions)",
        "commit_text": "",
        "func_before": "void* zend_accel_hash_find(zend_accel_hash *accel_hash, char *key, zend_uint key_length)\n{\n\tzend_ulong hash_value;\n\tzend_ulong index;\n\tzend_accel_hash_entry *entry;\n\n\thash_value = zend_inline_hash_func(key, key_length);\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\t\t\tif (entry->indirect) {\n\t\t\t\treturn ((zend_accel_hash_entry *) entry->data)->data;\n\t\t\t} else {\n\t\t\t\treturn entry->data;\n\t\t\t}\n\t\t}\n\t\tentry = entry->next;\n\t}\n\treturn NULL;\n}",
        "func": "void* zend_accel_hash_find(zend_accel_hash *accel_hash, char *key, zend_uint key_length)\n{\n\tzend_ulong hash_value;\n\tzend_ulong index;\n\tzend_accel_hash_entry *entry;\n\n\thash_value = zend_inline_hash_func(key, key_length);\n#ifndef ZEND_WIN32\n\thash_value ^= ZCG(root_hash);\n#endif\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\t\t\tif (entry->indirect) {\n\t\t\t\treturn ((zend_accel_hash_entry *) entry->data)->data;\n\t\t\t} else {\n\t\t\t\treturn entry->data;\n\t\t\t}\n\t\t}\n\t\tentry = entry->next;\n\t}\n\treturn NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,9 @@\n \tzend_accel_hash_entry *entry;\n \n \thash_value = zend_inline_hash_func(key, key_length);\n+#ifndef ZEND_WIN32\n+\thash_value ^= ZCG(root_hash);\n+#endif\n \tindex = hash_value % accel_hash->max_num_entries;\n \n \tentry = accel_hash->hash_table[index];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifndef ZEND_WIN32",
                "\thash_value ^= ZCG(root_hash);",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8994",
        "func_name": "php/php-src/zend_accel_hash_find_entry",
        "description": "An issue was discovered in PHP 5.x and 7.x, when the configuration uses apache2handler/mod_php or php-fpm with OpCache enabled. With 5.x after 5.6.28 or 7.x after 7.0.13, the issue is resolved in a non-default configuration with the opcache.validate_permission=1 setting. The vulnerability details are as follows. In PHP SAPIs where PHP interpreters share a common parent process, Zend OpCache creates a shared memory object owned by the common parent during initialization. Child PHP processes inherit the SHM descriptor, using it to cache and retrieve compiled script bytecode (\"opcode\" in PHP jargon). Cache keys vary depending on configuration, but filename is a central key component, and compiled opcode can generally be run if a script's filename is known or can be guessed. Many common shared-hosting configurations change EUID in child processes to enforce privilege separation among hosted users (for example using mod_ruid2 for the Apache HTTP Server, or php-fpm user settings). In these scenarios, the default Zend OpCache behavior defeats script file permissions by sharing a single SHM cache among all child PHP processes. PHP scripts often contain sensitive information: Think of CMS configurations where reading or running another user's script usually means gaining privileges to the CMS database.",
        "git_url": "https://github.com/php/php-src/commit/ecba563f2fa1e027ea91b9ee0d50611273852995",
        "commit_title": "Fixed bug #69090 (check cached files permissions)",
        "commit_text": "",
        "func_before": "zend_accel_hash_entry* zend_accel_hash_find_entry(zend_accel_hash *accel_hash, char *key, zend_uint key_length)\n{\n\tzend_ulong hash_value;\n\tzend_ulong index;\n\tzend_accel_hash_entry *entry;\n\n\thash_value = zend_inline_hash_func(key, key_length);\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\t\t\tif (entry->indirect) {\n\t\t\t\treturn (zend_accel_hash_entry *) entry->data;\n\t\t\t} else {\n\t\t\t\treturn entry;\n\t\t\t}\n\t\t}\n\t\tentry = entry->next;\n\t}\n\treturn NULL;\n}",
        "func": "zend_accel_hash_entry* zend_accel_hash_find_entry(zend_accel_hash *accel_hash, char *key, zend_uint key_length)\n{\n\tzend_ulong hash_value;\n\tzend_ulong index;\n\tzend_accel_hash_entry *entry;\n\n\thash_value = zend_inline_hash_func(key, key_length);\n#ifndef ZEND_WIN32\n\thash_value ^= ZCG(root_hash);\n#endif\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\t\t\tif (entry->indirect) {\n\t\t\t\treturn (zend_accel_hash_entry *) entry->data;\n\t\t\t} else {\n\t\t\t\treturn entry;\n\t\t\t}\n\t\t}\n\t\tentry = entry->next;\n\t}\n\treturn NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,9 @@\n \tzend_accel_hash_entry *entry;\n \n \thash_value = zend_inline_hash_func(key, key_length);\n+#ifndef ZEND_WIN32\n+\thash_value ^= ZCG(root_hash);\n+#endif\n \tindex = hash_value % accel_hash->max_num_entries;\n \n \tentry = accel_hash->hash_table[index];",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifndef ZEND_WIN32",
                "\thash_value ^= ZCG(root_hash);",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8994",
        "func_name": "php/php-src/zend_accel_hash_update",
        "description": "An issue was discovered in PHP 5.x and 7.x, when the configuration uses apache2handler/mod_php or php-fpm with OpCache enabled. With 5.x after 5.6.28 or 7.x after 7.0.13, the issue is resolved in a non-default configuration with the opcache.validate_permission=1 setting. The vulnerability details are as follows. In PHP SAPIs where PHP interpreters share a common parent process, Zend OpCache creates a shared memory object owned by the common parent during initialization. Child PHP processes inherit the SHM descriptor, using it to cache and retrieve compiled script bytecode (\"opcode\" in PHP jargon). Cache keys vary depending on configuration, but filename is a central key component, and compiled opcode can generally be run if a script's filename is known or can be guessed. Many common shared-hosting configurations change EUID in child processes to enforce privilege separation among hosted users (for example using mod_ruid2 for the Apache HTTP Server, or php-fpm user settings). In these scenarios, the default Zend OpCache behavior defeats script file permissions by sharing a single SHM cache among all child PHP processes. PHP scripts often contain sensitive information: Think of CMS configurations where reading or running another user's script usually means gaining privileges to the CMS database.",
        "git_url": "https://github.com/php/php-src/commit/ecba563f2fa1e027ea91b9ee0d50611273852995",
        "commit_title": "Fixed bug #69090 (check cached files permissions)",
        "commit_text": "",
        "func_before": "zend_accel_hash_entry* zend_accel_hash_update(zend_accel_hash *accel_hash, char *key, zend_uint key_length, zend_bool indirect, void *data)\n{\n\tzend_ulong hash_value;\n\tzend_ulong index;\n\tzend_accel_hash_entry *entry;\n\tzend_accel_hash_entry *indirect_bucket = NULL;\n\n\tif (indirect) {\n\t\tindirect_bucket = (zend_accel_hash_entry*)data;\n\t\twhile (indirect_bucket->indirect) {\n\t\t\tindirect_bucket = (zend_accel_hash_entry*)indirect_bucket->data;\n\t\t}\n\t}\n\n\thash_value = zend_inline_hash_func(key, key_length);\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\t/* try to see if the element already exists in the hash */\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\n\t\t\tif (entry->indirect) {\n\t\t\t\tif (indirect_bucket) {\n\t\t\t\t\tentry->data = indirect_bucket;\n\t\t\t\t} else {\n\t\t\t\t\t((zend_accel_hash_entry*)entry->data)->data = data;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (indirect_bucket) {\n\t\t\t\t\taccel_hash->num_direct_entries--;\n\t\t\t\t\tentry->data = indirect_bucket;\n\t\t\t\t\tentry->indirect = 1;\n\t\t\t\t} else {\n\t\t\t\t\tentry->data = data;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn entry;\n\t\t}\n\t\tentry = entry->next;\n\t}\n\n\t/* Does not exist, add a new entry */\n\tif (accel_hash->num_entries == accel_hash->max_num_entries) {\n\t\treturn NULL;\n\t}\n\n\tentry = &accel_hash->hash_entries[accel_hash->num_entries++];\n\tif (indirect) {\n\t\tentry->data = indirect_bucket;\n\t\tentry->indirect = 1;\n\t} else {\n\t\taccel_hash->num_direct_entries++;\n\t\tentry->data = data;\n\t\tentry->indirect = 0;\n\t}\n\tentry->hash_value = hash_value;\n\tentry->key = key;\n\tentry->key_length = key_length;\n\tentry->next = accel_hash->hash_table[index];\n\taccel_hash->hash_table[index] = entry;\n\treturn entry;\n}",
        "func": "zend_accel_hash_entry* zend_accel_hash_update(zend_accel_hash *accel_hash, char *key, zend_uint key_length, zend_bool indirect, void *data)\n{\n\tzend_ulong hash_value;\n\tzend_ulong index;\n\tzend_accel_hash_entry *entry;\n\tzend_accel_hash_entry *indirect_bucket = NULL;\n\n\tif (indirect) {\n\t\tindirect_bucket = (zend_accel_hash_entry*)data;\n\t\twhile (indirect_bucket->indirect) {\n\t\t\tindirect_bucket = (zend_accel_hash_entry*)indirect_bucket->data;\n\t\t}\n\t}\n\n\thash_value = zend_inline_hash_func(key, key_length);\n#ifndef ZEND_WIN32\n\thash_value ^= ZCG(root_hash);\n#endif\n\tindex = hash_value % accel_hash->max_num_entries;\n\n\t/* try to see if the element already exists in the hash */\n\tentry = accel_hash->hash_table[index];\n\twhile (entry) {\n\t\tif (entry->hash_value == hash_value\n\t\t\t&& entry->key_length == key_length\n\t\t\t&& !memcmp(entry->key, key, key_length)) {\n\n\t\t\tif (entry->indirect) {\n\t\t\t\tif (indirect_bucket) {\n\t\t\t\t\tentry->data = indirect_bucket;\n\t\t\t\t} else {\n\t\t\t\t\t((zend_accel_hash_entry*)entry->data)->data = data;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (indirect_bucket) {\n\t\t\t\t\taccel_hash->num_direct_entries--;\n\t\t\t\t\tentry->data = indirect_bucket;\n\t\t\t\t\tentry->indirect = 1;\n\t\t\t\t} else {\n\t\t\t\t\tentry->data = data;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn entry;\n\t\t}\n\t\tentry = entry->next;\n\t}\n\n\t/* Does not exist, add a new entry */\n\tif (accel_hash->num_entries == accel_hash->max_num_entries) {\n\t\treturn NULL;\n\t}\n\n\tentry = &accel_hash->hash_entries[accel_hash->num_entries++];\n\tif (indirect) {\n\t\tentry->data = indirect_bucket;\n\t\tentry->indirect = 1;\n\t} else {\n\t\taccel_hash->num_direct_entries++;\n\t\tentry->data = data;\n\t\tentry->indirect = 0;\n\t}\n\tentry->hash_value = hash_value;\n\tentry->key = key;\n\tentry->key_length = key_length;\n\tentry->next = accel_hash->hash_table[index];\n\taccel_hash->hash_table[index] = entry;\n\treturn entry;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,9 @@\n \t}\n \n \thash_value = zend_inline_hash_func(key, key_length);\n+#ifndef ZEND_WIN32\n+\thash_value ^= ZCG(root_hash);\n+#endif\n \tindex = hash_value % accel_hash->max_num_entries;\n \n \t/* try to see if the element already exists in the hash */",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifndef ZEND_WIN32",
                "\thash_value ^= ZCG(root_hash);",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8994",
        "func_name": "php/php-src/persistent_compile_file",
        "description": "An issue was discovered in PHP 5.x and 7.x, when the configuration uses apache2handler/mod_php or php-fpm with OpCache enabled. With 5.x after 5.6.28 or 7.x after 7.0.13, the issue is resolved in a non-default configuration with the opcache.validate_permission=1 setting. The vulnerability details are as follows. In PHP SAPIs where PHP interpreters share a common parent process, Zend OpCache creates a shared memory object owned by the common parent during initialization. Child PHP processes inherit the SHM descriptor, using it to cache and retrieve compiled script bytecode (\"opcode\" in PHP jargon). Cache keys vary depending on configuration, but filename is a central key component, and compiled opcode can generally be run if a script's filename is known or can be guessed. Many common shared-hosting configurations change EUID in child processes to enforce privilege separation among hosted users (for example using mod_ruid2 for the Apache HTTP Server, or php-fpm user settings). In these scenarios, the default Zend OpCache behavior defeats script file permissions by sharing a single SHM cache among all child PHP processes. PHP scripts often contain sensitive information: Think of CMS configurations where reading or running another user's script usually means gaining privileges to the CMS database.",
        "git_url": "https://github.com/php/php-src/commit/ecba563f2fa1e027ea91b9ee0d50611273852995",
        "commit_title": "Fixed bug #69090 (check cached files permissions)",
        "commit_text": "",
        "func_before": "zend_op_array *persistent_compile_file(zend_file_handle *file_handle, int type TSRMLS_DC)\n{\n\tzend_persistent_script *persistent_script = NULL;\n\tchar *key = NULL;\n\tint key_length;\n\tint from_shared_memory; /* if the script we've got is stored in SHM */\n\n\tif (!file_handle->filename ||\n\t\t!ZCG(enabled) || !accel_startup_ok ||\n\t\t(!ZCG(counted) && !ZCSG(accelerator_enabled)) ||\n\t    CG(interactive) ||\n\t    (ZCSG(restart_in_progress) && accel_restart_is_active(TSRMLS_C)) ||\n\t    (is_stream_path(file_handle->filename) && \n\t     !is_cacheable_stream_path(file_handle->filename))) {\n\t\t/* The Accelerator is disabled, act as if without the Accelerator */\n\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t}\n\n\t/* Make sure we only increase the currently running processes semaphore\n     * once each execution (this function can be called more than once on\n     * each execution)\n     */\n\tif (!ZCG(counted)) {\n\t\tZCG(counted) = 1;\n\t\taccel_activate_add(TSRMLS_C);\n\t}\n\n\t/* In case this callback is called from include_once, require_once or it's\n\t * a main FastCGI request, the key must be already calculated, and cached\n\t * persistent script already found */\n\tif ((EG(opline_ptr) == NULL &&\n\t     ZCG(cache_opline) == NULL &&\n\t     file_handle->filename == SG(request_info).path_translated &&\n\t     ZCG(cache_persistent_script)) ||\n\t    (EG(opline_ptr) && *EG(opline_ptr) &&\n\t     *EG(opline_ptr) == ZCG(cache_opline) &&\n\t     (*EG(opline_ptr))->opcode == ZEND_INCLUDE_OR_EVAL &&\n#if ZEND_EXTENSION_API_NO > PHP_5_3_X_API_NO\n\t     ((*EG(opline_ptr))->extended_value == ZEND_INCLUDE_ONCE ||\n\t      (*EG(opline_ptr))->extended_value == ZEND_REQUIRE_ONCE))) {\n#else\n \t     ((*EG(opline_ptr))->op2.u.constant.value.lval == ZEND_INCLUDE_ONCE ||\n \t      (*EG(opline_ptr))->op2.u.constant.value.lval == ZEND_REQUIRE_ONCE))) {\n#endif\n\t\tif (!ZCG(key_len)) {\n\t\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t\t}\n\t\t/* persistent script was already found by overridden open() or\n\t\t * resolve_path() callbacks */\n\t\tpersistent_script = ZCG(cache_persistent_script);\n\t\tkey = ZCG(key);\n\t\tkey_length = ZCG(key_len);\n\t} else {\n\t\t/* try to find cached script by key */\n\t\tif ((key = accel_make_persistent_key(file_handle, &key_length TSRMLS_CC)) == NULL) {\n\t\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t\t}\n\t\tpersistent_script = zend_accel_hash_find(&ZCSG(hash), key, key_length + 1);\n\t\tif (!persistent_script) {\n\t\t\t/* try to find cached script by full real path */\n\t\t\tzend_accel_hash_entry *bucket;\n\n\t\t\t/* open file to resolve the path */\n\t\t    if (file_handle->type == ZEND_HANDLE_FILENAME &&\n#if ZEND_EXTENSION_API_NO >= PHP_5_3_X_API_NO\n        \t\taccelerator_orig_zend_stream_open_function(file_handle->filename, file_handle TSRMLS_CC) == FAILURE) {\n#else\n\t\t        zend_stream_open(file_handle->filename, file_handle TSRMLS_CC) == FAILURE) {\n#endif\n\t\t\t\tif (type == ZEND_REQUIRE) {\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename);\n#else\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename TSRMLS_CC);\n#endif\n\t\t\t\t\tzend_bailout();\n\t\t\t\t} else {\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename);\n#else\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename TSRMLS_CC);\n#endif\n\t\t\t\t}\n\t\t\t\treturn NULL;\n\t\t    }\n\n\t\t\tif (file_handle->opened_path &&\n\t\t\t    (bucket = zend_accel_hash_find_entry(&ZCSG(hash), file_handle->opened_path, strlen(file_handle->opened_path) + 1)) != NULL) {\n\n\t\t\t\tpersistent_script = (zend_persistent_script *)bucket->data;\n\t\t\t\tif (!ZCG(accel_directives).revalidate_path &&\n\t\t\t\t    !persistent_script->corrupted) {\n\t\t\t    \tSHM_UNPROTECT();\n\t\t\t\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\t\t\t\tzend_accel_add_key(key, key_length, bucket TSRMLS_CC);\n\t\t\t\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t\t\t    \tSHM_PROTECT();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/* clear cache */\n\tZCG(cache_opline) = NULL;\n\tZCG(cache_persistent_script) = NULL;\n\n\tif (persistent_script && persistent_script->corrupted) {\n\t\tpersistent_script = NULL;\n\t}\n\n\tSHM_UNPROTECT();\n\n\t/* If script is found then validate_timestamps if option is enabled */\n\tif (persistent_script && ZCG(accel_directives).validate_timestamps) {\n\t\tif (validate_timestamp_and_record(persistent_script, file_handle TSRMLS_CC) == FAILURE) {\n\t\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\t\tif (!persistent_script->corrupted) {\n\t\t\t\tpersistent_script->corrupted = 1;\n\t\t\t\tpersistent_script->timestamp = 0;\n\t\t\t\tZSMMG(wasted_shared_memory) += persistent_script->dynamic_members.memory_consumption;\n\t\t\t\tif (ZSMMG(memory_exhausted)) {\n\t\t\t\t\tzend_accel_restart_reason reason =\n\t\t\t\t\t\tzend_accel_hash_is_full(&ZCSG(hash)) ? ACCEL_RESTART_HASH : ACCEL_RESTART_OOM;\n\t\t\t\t\tzend_accel_schedule_restart_if_necessary(reason TSRMLS_CC);\n\t\t\t\t}\n\t\t\t}\n\t\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t\t\tpersistent_script = NULL;\n\t\t}\n\t}\n\n\t/* if turned on - check the compiled script ADLER32 checksum */\n\tif (persistent_script && ZCG(accel_directives).consistency_checks\n\t\t&& persistent_script->dynamic_members.hits % ZCG(accel_directives).consistency_checks == 0) {\n\n\t\tunsigned int checksum = zend_accel_script_checksum(persistent_script);\n\t\tif (checksum != persistent_script->dynamic_members.checksum ) {\n\t\t\t/* The checksum is wrong */\n\t\t\tzend_accel_error(ACCEL_LOG_INFO, \"Checksum failed for '%s':  expected=0x%0.8X, found=0x%0.8X\",\n\t\t\t\t\t\t\t persistent_script->full_path, persistent_script->dynamic_members.checksum, checksum);\n\t\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\t\tif (!persistent_script->corrupted) {\n\t\t\t\tpersistent_script->corrupted = 1;\n\t\t\t\tpersistent_script->timestamp = 0;\n\t\t\t\tZSMMG(wasted_shared_memory) += persistent_script->dynamic_members.memory_consumption;\n\t\t\t\tif (ZSMMG(memory_exhausted)) {\n\t\t\t\t\tzend_accel_restart_reason reason =\n\t\t\t\t\t\tzend_accel_hash_is_full(&ZCSG(hash)) ? ACCEL_RESTART_HASH : ACCEL_RESTART_OOM;\n\t\t\t\t\tzend_accel_schedule_restart_if_necessary(reason TSRMLS_CC);\n\t\t\t\t}\n\t\t\t}\n\t\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t\t\tpersistent_script = NULL;\n\t\t}\n\t}\n\n\t/* If script was not found or invalidated by validate_timestamps */\n\tif (!persistent_script) {\n\t\tzend_op_array *op_array;\n\n\t\t/* Cache miss.. */\n\t\tZCSG(misses)++;\n\n\t\t/* No memory left. Behave like without the Accelerator */\n\t\tif (ZSMMG(memory_exhausted) || ZCSG(restart_pending)) {\n\t\t\tSHM_PROTECT();\n\t\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t\t}\n\n\t\t/* Try and cache the script and assume that it is returned from_shared_memory.\n         * If it isn't compile_and_cache_file() changes the flag to 0\n         */\n       \tfrom_shared_memory = 0;\n\t\tpersistent_script = compile_and_cache_file(file_handle, type, key, key_length, &op_array, &from_shared_memory TSRMLS_CC);\n\n\t\t/* Caching is disabled, returning op_array;\n\t\t * or something went wrong during compilation, returning NULL\n\t\t */\n\t\tif (!persistent_script) {\n\t\t\tSHM_PROTECT();\n\t\t\treturn op_array;\n\t\t}\n\t} else {\n\n#if !ZEND_WIN32\n\t\tZCSG(hits)++; /* TBFixed: may lose one hit */\n\t\tpersistent_script->dynamic_members.hits++; /* see above */\n#else\n\t\tInterlockedIncrement(&ZCSG(hits));\n\t\tInterlockedIncrement(&persistent_script->dynamic_members.hits);\n#endif\n\n\t\t/* see bug #15471 (old BTS) */\n\t\tif (persistent_script->full_path) {\n\t\t\tif (!EG(opline_ptr) || !*EG(opline_ptr) ||\n\t\t\t    (*EG(opline_ptr))->opcode != ZEND_INCLUDE_OR_EVAL ||\n#if ZEND_EXTENSION_API_NO > PHP_5_3_X_API_NO\n\t\t\t    ((*EG(opline_ptr))->extended_value != ZEND_INCLUDE_ONCE &&\n\t\t\t     (*EG(opline_ptr))->extended_value != ZEND_REQUIRE_ONCE)) {\n#else\n \t\t\t    ((*EG(opline_ptr))->op2.u.constant.value.lval != ZEND_INCLUDE_ONCE &&\n \t\t\t     (*EG(opline_ptr))->op2.u.constant.value.lval != ZEND_REQUIRE_ONCE)) {\n#endif\n\t\t\t\tvoid *dummy = (void *) 1;\n\n\t\t\t\tif (zend_hash_quick_add(&EG(included_files), persistent_script->full_path, persistent_script->full_path_len + 1, persistent_script->hash_value, &dummy, sizeof(void *), NULL) == SUCCESS) {\n\t\t\t\t\t/* ext/phar has to load phar's metadata into memory */\n\t\t\t\t\tif (strstr(persistent_script->full_path, \".phar\") && !strstr(persistent_script->full_path, \"://\")) {\n\t\t\t\t\t\tphp_stream_statbuf ssb;\n\t\t\t\t\t\tchar *fname = emalloc(sizeof(\"phar://\") + persistent_script->full_path_len);\n\n\t\t\t\t\t\tmemcpy(fname, \"phar://\", sizeof(\"phar://\") - 1);\n\t\t\t\t\t\tmemcpy(fname + sizeof(\"phar://\") - 1, persistent_script->full_path, persistent_script->full_path_len + 1);\n\t\t\t\t\t\tphp_stream_stat_path(fname, &ssb);\n\t\t\t\t\t\tefree(fname);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\tzend_file_handle_dtor(file_handle);\n#else\n\t\tzend_file_handle_dtor(file_handle TSRMLS_CC);\n#endif\n\t\tfrom_shared_memory = 1;\n\t}\n\n\tpersistent_script->dynamic_members.last_used = ZCG(request_time);\n\n\tSHM_PROTECT();\n\n    /* Fetch jit auto globals used in the script before execution */\n    if (persistent_script->ping_auto_globals_mask) {\n\t\tzend_accel_set_auto_globals(persistent_script->ping_auto_globals_mask TSRMLS_CC);\n\t}\n\n\treturn zend_accel_load_script(persistent_script, from_shared_memory TSRMLS_CC);\n}",
        "func": "zend_op_array *persistent_compile_file(zend_file_handle *file_handle, int type TSRMLS_DC)\n{\n\tzend_persistent_script *persistent_script = NULL;\n\tchar *key = NULL;\n\tint key_length;\n\tint from_shared_memory; /* if the script we've got is stored in SHM */\n\n\tif (!file_handle->filename ||\n\t\t!ZCG(enabled) || !accel_startup_ok ||\n\t\t(!ZCG(counted) && !ZCSG(accelerator_enabled)) ||\n\t    CG(interactive) ||\n\t    (ZCSG(restart_in_progress) && accel_restart_is_active(TSRMLS_C)) ||\n\t    (is_stream_path(file_handle->filename) && \n\t     !is_cacheable_stream_path(file_handle->filename))) {\n\t\t/* The Accelerator is disabled, act as if without the Accelerator */\n\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t}\n\n\t/* Make sure we only increase the currently running processes semaphore\n     * once each execution (this function can be called more than once on\n     * each execution)\n     */\n\tif (!ZCG(counted)) {\n\t\tZCG(counted) = 1;\n\t\taccel_activate_add(TSRMLS_C);\n\t}\n\n\t/* In case this callback is called from include_once, require_once or it's\n\t * a main FastCGI request, the key must be already calculated, and cached\n\t * persistent script already found */\n\tif ((EG(opline_ptr) == NULL &&\n\t     ZCG(cache_opline) == NULL &&\n\t     file_handle->filename == SG(request_info).path_translated &&\n\t     ZCG(cache_persistent_script)) ||\n\t    (EG(opline_ptr) && *EG(opline_ptr) &&\n\t     *EG(opline_ptr) == ZCG(cache_opline) &&\n\t     (*EG(opline_ptr))->opcode == ZEND_INCLUDE_OR_EVAL &&\n#if ZEND_EXTENSION_API_NO > PHP_5_3_X_API_NO\n\t     ((*EG(opline_ptr))->extended_value == ZEND_INCLUDE_ONCE ||\n\t      (*EG(opline_ptr))->extended_value == ZEND_REQUIRE_ONCE))) {\n#else\n \t     ((*EG(opline_ptr))->op2.u.constant.value.lval == ZEND_INCLUDE_ONCE ||\n \t      (*EG(opline_ptr))->op2.u.constant.value.lval == ZEND_REQUIRE_ONCE))) {\n#endif\n\t\tif (!ZCG(key_len)) {\n\t\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t\t}\n\t\t/* persistent script was already found by overridden open() or\n\t\t * resolve_path() callbacks */\n\t\tpersistent_script = ZCG(cache_persistent_script);\n\t\tkey = ZCG(key);\n\t\tkey_length = ZCG(key_len);\n\t} else {\n\t\t/* try to find cached script by key */\n\t\tif ((key = accel_make_persistent_key(file_handle, &key_length TSRMLS_CC)) == NULL) {\n\t\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t\t}\n\t\tpersistent_script = zend_accel_hash_find(&ZCSG(hash), key, key_length + 1);\n\t\tif (!persistent_script) {\n\t\t\t/* try to find cached script by full real path */\n\t\t\tzend_accel_hash_entry *bucket;\n\n\t\t\t/* open file to resolve the path */\n\t\t    if (file_handle->type == ZEND_HANDLE_FILENAME &&\n#if ZEND_EXTENSION_API_NO >= PHP_5_3_X_API_NO\n        \t\taccelerator_orig_zend_stream_open_function(file_handle->filename, file_handle TSRMLS_CC) == FAILURE) {\n#else\n\t\t        zend_stream_open(file_handle->filename, file_handle TSRMLS_CC) == FAILURE) {\n#endif\n\t\t\t\tif (type == ZEND_REQUIRE) {\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename);\n#else\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename TSRMLS_CC);\n#endif\n\t\t\t\t\tzend_bailout();\n\t\t\t\t} else {\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename);\n#else\n\t\t\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename TSRMLS_CC);\n#endif\n\t\t\t\t}\n\t\t\t\treturn NULL;\n\t\t    }\n\n\t\t\tif (file_handle->opened_path &&\n\t\t\t    (bucket = zend_accel_hash_find_entry(&ZCSG(hash), file_handle->opened_path, strlen(file_handle->opened_path) + 1)) != NULL) {\n\n\t\t\t\tpersistent_script = (zend_persistent_script *)bucket->data;\n\t\t\t\tif (!ZCG(accel_directives).revalidate_path &&\n\t\t\t\t    !persistent_script->corrupted) {\n\t\t\t    \tSHM_UNPROTECT();\n\t\t\t\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\t\t\t\tzend_accel_add_key(key, key_length, bucket TSRMLS_CC);\n\t\t\t\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t\t\t    \tSHM_PROTECT();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t/* clear cache */\n\tZCG(cache_opline) = NULL;\n\tZCG(cache_persistent_script) = NULL;\n\n\tif (persistent_script && persistent_script->corrupted) {\n\t\tpersistent_script = NULL;\n\t}\n\n\t/* Revalidate acessibility of cached file */\n\tif (EXPECTED(persistent_script != NULL) &&\n\t    UNEXPECTED(ZCG(accel_directives).validate_permission) &&\n\t    file_handle->type == ZEND_HANDLE_FILENAME &&\n\t    UNEXPECTED(access(file_handle->filename, R_OK) != 0)) {\n\t\tif (type == ZEND_REQUIRE) {\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename);\n#else\n\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename TSRMLS_CC);\n#endif\n\t\t\tzend_bailout();\n\t\t} else {\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename);\n#else\n\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename TSRMLS_CC);\n#endif\n\t\t}\n\t\treturn NULL;\n\t}\n\n\tSHM_UNPROTECT();\n\n\t/* If script is found then validate_timestamps if option is enabled */\n\tif (persistent_script && ZCG(accel_directives).validate_timestamps) {\n\t\tif (validate_timestamp_and_record(persistent_script, file_handle TSRMLS_CC) == FAILURE) {\n\t\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\t\tif (!persistent_script->corrupted) {\n\t\t\t\tpersistent_script->corrupted = 1;\n\t\t\t\tpersistent_script->timestamp = 0;\n\t\t\t\tZSMMG(wasted_shared_memory) += persistent_script->dynamic_members.memory_consumption;\n\t\t\t\tif (ZSMMG(memory_exhausted)) {\n\t\t\t\t\tzend_accel_restart_reason reason =\n\t\t\t\t\t\tzend_accel_hash_is_full(&ZCSG(hash)) ? ACCEL_RESTART_HASH : ACCEL_RESTART_OOM;\n\t\t\t\t\tzend_accel_schedule_restart_if_necessary(reason TSRMLS_CC);\n\t\t\t\t}\n\t\t\t}\n\t\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t\t\tpersistent_script = NULL;\n\t\t}\n\t}\n\n\t/* if turned on - check the compiled script ADLER32 checksum */\n\tif (persistent_script && ZCG(accel_directives).consistency_checks\n\t\t&& persistent_script->dynamic_members.hits % ZCG(accel_directives).consistency_checks == 0) {\n\n\t\tunsigned int checksum = zend_accel_script_checksum(persistent_script);\n\t\tif (checksum != persistent_script->dynamic_members.checksum ) {\n\t\t\t/* The checksum is wrong */\n\t\t\tzend_accel_error(ACCEL_LOG_INFO, \"Checksum failed for '%s':  expected=0x%0.8X, found=0x%0.8X\",\n\t\t\t\t\t\t\t persistent_script->full_path, persistent_script->dynamic_members.checksum, checksum);\n\t\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\t\tif (!persistent_script->corrupted) {\n\t\t\t\tpersistent_script->corrupted = 1;\n\t\t\t\tpersistent_script->timestamp = 0;\n\t\t\t\tZSMMG(wasted_shared_memory) += persistent_script->dynamic_members.memory_consumption;\n\t\t\t\tif (ZSMMG(memory_exhausted)) {\n\t\t\t\t\tzend_accel_restart_reason reason =\n\t\t\t\t\t\tzend_accel_hash_is_full(&ZCSG(hash)) ? ACCEL_RESTART_HASH : ACCEL_RESTART_OOM;\n\t\t\t\t\tzend_accel_schedule_restart_if_necessary(reason TSRMLS_CC);\n\t\t\t\t}\n\t\t\t}\n\t\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t\t\tpersistent_script = NULL;\n\t\t}\n\t}\n\n\t/* If script was not found or invalidated by validate_timestamps */\n\tif (!persistent_script) {\n\t\tzend_op_array *op_array;\n\n\t\t/* Cache miss.. */\n\t\tZCSG(misses)++;\n\n\t\t/* No memory left. Behave like without the Accelerator */\n\t\tif (ZSMMG(memory_exhausted) || ZCSG(restart_pending)) {\n\t\t\tSHM_PROTECT();\n\t\t\treturn accelerator_orig_compile_file(file_handle, type TSRMLS_CC);\n\t\t}\n\n\t\t/* Try and cache the script and assume that it is returned from_shared_memory.\n         * If it isn't compile_and_cache_file() changes the flag to 0\n         */\n       \tfrom_shared_memory = 0;\n\t\tpersistent_script = compile_and_cache_file(file_handle, type, key, key_length, &op_array, &from_shared_memory TSRMLS_CC);\n\n\t\t/* Caching is disabled, returning op_array;\n\t\t * or something went wrong during compilation, returning NULL\n\t\t */\n\t\tif (!persistent_script) {\n\t\t\tSHM_PROTECT();\n\t\t\treturn op_array;\n\t\t}\n\t} else {\n\n#if !ZEND_WIN32\n\t\tZCSG(hits)++; /* TBFixed: may lose one hit */\n\t\tpersistent_script->dynamic_members.hits++; /* see above */\n#else\n\t\tInterlockedIncrement(&ZCSG(hits));\n\t\tInterlockedIncrement(&persistent_script->dynamic_members.hits);\n#endif\n\n\t\t/* see bug #15471 (old BTS) */\n\t\tif (persistent_script->full_path) {\n\t\t\tif (!EG(opline_ptr) || !*EG(opline_ptr) ||\n\t\t\t    (*EG(opline_ptr))->opcode != ZEND_INCLUDE_OR_EVAL ||\n#if ZEND_EXTENSION_API_NO > PHP_5_3_X_API_NO\n\t\t\t    ((*EG(opline_ptr))->extended_value != ZEND_INCLUDE_ONCE &&\n\t\t\t     (*EG(opline_ptr))->extended_value != ZEND_REQUIRE_ONCE)) {\n#else\n \t\t\t    ((*EG(opline_ptr))->op2.u.constant.value.lval != ZEND_INCLUDE_ONCE &&\n \t\t\t     (*EG(opline_ptr))->op2.u.constant.value.lval != ZEND_REQUIRE_ONCE)) {\n#endif\n\t\t\t\tvoid *dummy = (void *) 1;\n\n\t\t\t\tif (zend_hash_quick_add(&EG(included_files), persistent_script->full_path, persistent_script->full_path_len + 1, persistent_script->hash_value, &dummy, sizeof(void *), NULL) == SUCCESS) {\n\t\t\t\t\t/* ext/phar has to load phar's metadata into memory */\n\t\t\t\t\tif (strstr(persistent_script->full_path, \".phar\") && !strstr(persistent_script->full_path, \"://\")) {\n\t\t\t\t\t\tphp_stream_statbuf ssb;\n\t\t\t\t\t\tchar *fname = emalloc(sizeof(\"phar://\") + persistent_script->full_path_len);\n\n\t\t\t\t\t\tmemcpy(fname, \"phar://\", sizeof(\"phar://\") - 1);\n\t\t\t\t\t\tmemcpy(fname + sizeof(\"phar://\") - 1, persistent_script->full_path, persistent_script->full_path_len + 1);\n\t\t\t\t\t\tphp_stream_stat_path(fname, &ssb);\n\t\t\t\t\t\tefree(fname);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n\t\tzend_file_handle_dtor(file_handle);\n#else\n\t\tzend_file_handle_dtor(file_handle TSRMLS_CC);\n#endif\n\t\tfrom_shared_memory = 1;\n\t}\n\n\tpersistent_script->dynamic_members.last_used = ZCG(request_time);\n\n\tSHM_PROTECT();\n\n    /* Fetch jit auto globals used in the script before execution */\n    if (persistent_script->ping_auto_globals_mask) {\n\t\tzend_accel_set_auto_globals(persistent_script->ping_auto_globals_mask TSRMLS_CC);\n\t}\n\n\treturn zend_accel_load_script(persistent_script, from_shared_memory TSRMLS_CC);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -106,6 +106,28 @@\n \n \tif (persistent_script && persistent_script->corrupted) {\n \t\tpersistent_script = NULL;\n+\t}\n+\n+\t/* Revalidate acessibility of cached file */\n+\tif (EXPECTED(persistent_script != NULL) &&\n+\t    UNEXPECTED(ZCG(accel_directives).validate_permission) &&\n+\t    file_handle->type == ZEND_HANDLE_FILENAME &&\n+\t    UNEXPECTED(access(file_handle->filename, R_OK) != 0)) {\n+\t\tif (type == ZEND_REQUIRE) {\n+#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n+\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename);\n+#else\n+\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename TSRMLS_CC);\n+#endif\n+\t\t\tzend_bailout();\n+\t\t} else {\n+#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO\n+\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename);\n+#else\n+\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename TSRMLS_CC);\n+#endif\n+\t\t}\n+\t\treturn NULL;\n \t}\n \n \tSHM_UNPROTECT();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t}",
                "",
                "\t/* Revalidate acessibility of cached file */",
                "\tif (EXPECTED(persistent_script != NULL) &&",
                "\t    UNEXPECTED(ZCG(accel_directives).validate_permission) &&",
                "\t    file_handle->type == ZEND_HANDLE_FILENAME &&",
                "\t    UNEXPECTED(access(file_handle->filename, R_OK) != 0)) {",
                "\t\tif (type == ZEND_REQUIRE) {",
                "#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO",
                "\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename);",
                "#else",
                "\t\t\tzend_message_dispatcher(ZMSG_FAILED_REQUIRE_FOPEN, file_handle->filename TSRMLS_CC);",
                "#endif",
                "\t\t\tzend_bailout();",
                "\t\t} else {",
                "#if ZEND_EXTENSION_API_NO < PHP_5_3_X_API_NO",
                "\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename);",
                "#else",
                "\t\t\tzend_message_dispatcher(ZMSG_FAILED_INCLUDE_FOPEN, file_handle->filename TSRMLS_CC);",
                "#endif",
                "\t\t}",
                "\t\treturn NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8994",
        "func_name": "php/php-src/accel_activate",
        "description": "An issue was discovered in PHP 5.x and 7.x, when the configuration uses apache2handler/mod_php or php-fpm with OpCache enabled. With 5.x after 5.6.28 or 7.x after 7.0.13, the issue is resolved in a non-default configuration with the opcache.validate_permission=1 setting. The vulnerability details are as follows. In PHP SAPIs where PHP interpreters share a common parent process, Zend OpCache creates a shared memory object owned by the common parent during initialization. Child PHP processes inherit the SHM descriptor, using it to cache and retrieve compiled script bytecode (\"opcode\" in PHP jargon). Cache keys vary depending on configuration, but filename is a central key component, and compiled opcode can generally be run if a script's filename is known or can be guessed. Many common shared-hosting configurations change EUID in child processes to enforce privilege separation among hosted users (for example using mod_ruid2 for the Apache HTTP Server, or php-fpm user settings). In these scenarios, the default Zend OpCache behavior defeats script file permissions by sharing a single SHM cache among all child PHP processes. PHP scripts often contain sensitive information: Think of CMS configurations where reading or running another user's script usually means gaining privileges to the CMS database.",
        "git_url": "https://github.com/php/php-src/commit/ecba563f2fa1e027ea91b9ee0d50611273852995",
        "commit_title": "Fixed bug #69090 (check cached files permissions)",
        "commit_text": "",
        "func_before": "static void accel_activate(void)\n{\n\tTSRMLS_FETCH();\n\n\tif (!ZCG(enabled) || !accel_startup_ok) {\n\t\treturn;\n\t}\n\n\tSHM_UNPROTECT();\n\t/* PHP-5.4 and above return \"double\", but we use 1 sec precision */\n\tZCG(request_time) = (time_t)sapi_get_request_time(TSRMLS_C);\n\tZCG(cache_opline) = NULL;\n\tZCG(cache_persistent_script) = NULL;\n\tZCG(include_path_check) = !ZCG(include_path_key);\n\n\tif (ZCG(counted)) {\n#ifdef ZTS\n\t\tzend_accel_error(ACCEL_LOG_WARNING, \"Stuck count for thread id %d\", tsrm_thread_id());\n#else\n\t\tzend_accel_error(ACCEL_LOG_WARNING, \"Stuck count for pid %d\", getpid());\n#endif\n\t\taccel_unlock_all(TSRMLS_C);\n\t\tZCG(counted) = 0;\n\t}\n\n\tif (ZCSG(restart_pending)) {\n\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\tif (ZCSG(restart_pending) != 0) { /* check again, to ensure that the cache wasn't already cleaned by another process */\n\t\t\tif (accel_is_inactive(TSRMLS_C) == SUCCESS) {\n\t\t\t\tzend_accel_error(ACCEL_LOG_DEBUG, \"Restarting!\");\n\t\t\t\tZCSG(restart_pending) = 0;\n\t\t\t\tswitch ZCSG(restart_reason) {\n\t\t\t\t\tcase ACCEL_RESTART_OOM:\n\t\t\t\t\t\tZCSG(oom_restarts)++;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase ACCEL_RESTART_HASH:\n\t\t\t\t\t\tZCSG(hash_restarts)++;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase ACCEL_RESTART_USER:\n\t\t\t\t\t\tZCSG(manual_restarts)++;\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\taccel_restart_enter(TSRMLS_C);\n\n\t\t\t\tzend_reset_cache_vars(TSRMLS_C);\n\t\t\t\tzend_accel_hash_clean(&ZCSG(hash));\n\n\t\t\t\t/* include_paths keeps only the first path */\n\t\t\t\tif (ZCSG(include_paths).num_entries > 1) {\n\t\t\t\t\tZCSG(include_paths).num_entries = 1;\n\t\t\t\t\tZCSG(include_paths).num_direct_entries = 1;\n\t\t\t\t\tmemset(ZCSG(include_paths).hash_table, 0, sizeof(zend_accel_hash_entry*) * ZCSG(include_paths).max_num_entries);\n\t\t\t\t\tZCSG(include_paths).hash_table[zend_inline_hash_func(ZCSG(include_paths).hash_entries[0].key, ZCSG(include_paths).hash_entries[0].key_length) % ZCSG(include_paths).max_num_entries] = &ZCSG(include_paths).hash_entries[0];\n\t\t\t\t}\n\n#if (ZEND_EXTENSION_API_NO > PHP_5_3_X_API_NO) && !defined(ZTS)\n\t\t\t\tif (ZCG(accel_directives).interned_strings_buffer) {\n\t\t\t\t\taccel_interned_strings_restore_state(TSRMLS_C);\n\t\t\t\t}\n#endif\n\n\t\t\t\tzend_shared_alloc_restore_state();\n\t\t\t\tZCSG(accelerator_enabled) = ZCSG(cache_status_before_restart);\n\t\t\t\tZCSG(last_restart_time) = ZCG(request_time);\n\t\t\t\taccel_restart_leave(TSRMLS_C);\n\t\t\t}\n\t\t}\n\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t}\n\n\t/* check if ZCG(function_table) wasn't somehow polluted on the way */\n\tif (ZCG(internal_functions_count) != zend_hash_num_elements(&ZCG(function_table))) {\n\t\tzend_accel_error(ACCEL_LOG_WARNING, \"Internal functions count changed - was %d, now %d\", ZCG(internal_functions_count), zend_hash_num_elements(&ZCG(function_table)));\n\t}\n\n\tZCG(cwd) = NULL;\n\n\tSHM_PROTECT();\n}",
        "func": "static void accel_activate(void)\n{\n\tTSRMLS_FETCH();\n\n\tif (!ZCG(enabled) || !accel_startup_ok) {\n\t\treturn;\n\t}\n\n#ifndef ZEND_WIN32\n\tif (ZCG(accel_directives).validate_root) {\n\t\tstruct stat buf;\n\n\t\tif (stat(\"/\", &buf) != 0) {\n\t\t\tZCG(root_hash) = 0;\n\t\t} else {\n\t\t\tunsigned long x = buf.st_ino;\n\n#if SIZEOF_LONG == 4\n\t\t\tx = ((x >> 16) ^ x) * 0x45d9f3b;\n\t\t\tx = ((x >> 16) ^ x) * 0x45d9f3b;\n\t\t\tx = (x >> 16) ^ x;\n#elif SIZEOF_LONG == 8\n\t\t\tx = (x ^ (x >> 30)) * 0xbf58476d1ce4e5b9;\n\t\t\tx = (x ^ (x >> 27)) * 0x94d049bb133111eb;\n\t\t\tx = x ^ (x >> 31);\n#endif\n\t\t\tZCG(root_hash) = x;\n\t\t}\n\t} else {\n\t\tZCG(root_hash) = 0;\n\t}\n#endif\n\n\tSHM_UNPROTECT();\n\t/* PHP-5.4 and above return \"double\", but we use 1 sec precision */\n\tZCG(request_time) = (time_t)sapi_get_request_time(TSRMLS_C);\n\tZCG(cache_opline) = NULL;\n\tZCG(cache_persistent_script) = NULL;\n\tZCG(include_path_check) = !ZCG(include_path_key);\n\n\tif (ZCG(counted)) {\n#ifdef ZTS\n\t\tzend_accel_error(ACCEL_LOG_WARNING, \"Stuck count for thread id %d\", tsrm_thread_id());\n#else\n\t\tzend_accel_error(ACCEL_LOG_WARNING, \"Stuck count for pid %d\", getpid());\n#endif\n\t\taccel_unlock_all(TSRMLS_C);\n\t\tZCG(counted) = 0;\n\t}\n\n\tif (ZCSG(restart_pending)) {\n\t\tzend_shared_alloc_lock(TSRMLS_C);\n\t\tif (ZCSG(restart_pending) != 0) { /* check again, to ensure that the cache wasn't already cleaned by another process */\n\t\t\tif (accel_is_inactive(TSRMLS_C) == SUCCESS) {\n\t\t\t\tzend_accel_error(ACCEL_LOG_DEBUG, \"Restarting!\");\n\t\t\t\tZCSG(restart_pending) = 0;\n\t\t\t\tswitch ZCSG(restart_reason) {\n\t\t\t\t\tcase ACCEL_RESTART_OOM:\n\t\t\t\t\t\tZCSG(oom_restarts)++;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase ACCEL_RESTART_HASH:\n\t\t\t\t\t\tZCSG(hash_restarts)++;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase ACCEL_RESTART_USER:\n\t\t\t\t\t\tZCSG(manual_restarts)++;\n\t\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\taccel_restart_enter(TSRMLS_C);\n\n\t\t\t\tzend_reset_cache_vars(TSRMLS_C);\n\t\t\t\tzend_accel_hash_clean(&ZCSG(hash));\n\n\t\t\t\t/* include_paths keeps only the first path */\n\t\t\t\tif (ZCSG(include_paths).num_entries > 1) {\n\t\t\t\t\tZCSG(include_paths).num_entries = 1;\n\t\t\t\t\tZCSG(include_paths).num_direct_entries = 1;\n\t\t\t\t\tmemset(ZCSG(include_paths).hash_table, 0, sizeof(zend_accel_hash_entry*) * ZCSG(include_paths).max_num_entries);\n\t\t\t\t\tZCSG(include_paths).hash_table[zend_inline_hash_func(ZCSG(include_paths).hash_entries[0].key, ZCSG(include_paths).hash_entries[0].key_length) % ZCSG(include_paths).max_num_entries] = &ZCSG(include_paths).hash_entries[0];\n\t\t\t\t}\n\n#if (ZEND_EXTENSION_API_NO > PHP_5_3_X_API_NO) && !defined(ZTS)\n\t\t\t\tif (ZCG(accel_directives).interned_strings_buffer) {\n\t\t\t\t\taccel_interned_strings_restore_state(TSRMLS_C);\n\t\t\t\t}\n#endif\n\n\t\t\t\tzend_shared_alloc_restore_state();\n\t\t\t\tZCSG(accelerator_enabled) = ZCSG(cache_status_before_restart);\n\t\t\t\tZCSG(last_restart_time) = ZCG(request_time);\n\t\t\t\taccel_restart_leave(TSRMLS_C);\n\t\t\t}\n\t\t}\n\t\tzend_shared_alloc_unlock(TSRMLS_C);\n\t}\n\n\t/* check if ZCG(function_table) wasn't somehow polluted on the way */\n\tif (ZCG(internal_functions_count) != zend_hash_num_elements(&ZCG(function_table))) {\n\t\tzend_accel_error(ACCEL_LOG_WARNING, \"Internal functions count changed - was %d, now %d\", ZCG(internal_functions_count), zend_hash_num_elements(&ZCG(function_table)));\n\t}\n\n\tZCG(cwd) = NULL;\n\n\tSHM_PROTECT();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,31 @@\n \tif (!ZCG(enabled) || !accel_startup_ok) {\n \t\treturn;\n \t}\n+\n+#ifndef ZEND_WIN32\n+\tif (ZCG(accel_directives).validate_root) {\n+\t\tstruct stat buf;\n+\n+\t\tif (stat(\"/\", &buf) != 0) {\n+\t\t\tZCG(root_hash) = 0;\n+\t\t} else {\n+\t\t\tunsigned long x = buf.st_ino;\n+\n+#if SIZEOF_LONG == 4\n+\t\t\tx = ((x >> 16) ^ x) * 0x45d9f3b;\n+\t\t\tx = ((x >> 16) ^ x) * 0x45d9f3b;\n+\t\t\tx = (x >> 16) ^ x;\n+#elif SIZEOF_LONG == 8\n+\t\t\tx = (x ^ (x >> 30)) * 0xbf58476d1ce4e5b9;\n+\t\t\tx = (x ^ (x >> 27)) * 0x94d049bb133111eb;\n+\t\t\tx = x ^ (x >> 31);\n+#endif\n+\t\t\tZCG(root_hash) = x;\n+\t\t}\n+\t} else {\n+\t\tZCG(root_hash) = 0;\n+\t}\n+#endif\n \n \tSHM_UNPROTECT();\n \t/* PHP-5.4 and above return \"double\", but we use 1 sec precision */",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "#ifndef ZEND_WIN32",
                "\tif (ZCG(accel_directives).validate_root) {",
                "\t\tstruct stat buf;",
                "",
                "\t\tif (stat(\"/\", &buf) != 0) {",
                "\t\t\tZCG(root_hash) = 0;",
                "\t\t} else {",
                "\t\t\tunsigned long x = buf.st_ino;",
                "",
                "#if SIZEOF_LONG == 4",
                "\t\t\tx = ((x >> 16) ^ x) * 0x45d9f3b;",
                "\t\t\tx = ((x >> 16) ^ x) * 0x45d9f3b;",
                "\t\t\tx = (x >> 16) ^ x;",
                "#elif SIZEOF_LONG == 8",
                "\t\t\tx = (x ^ (x >> 30)) * 0xbf58476d1ce4e5b9;",
                "\t\t\tx = (x ^ (x >> 27)) * 0x94d049bb133111eb;",
                "\t\t\tx = x ^ (x >> 31);",
                "#endif",
                "\t\t\tZCG(root_hash) = x;",
                "\t\t}",
                "\t} else {",
                "\t\tZCG(root_hash) = 0;",
                "\t}",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2319",
        "func_name": "torvalds/linux/hfsplus_readdir",
        "description": "Multiple buffer overflows in the hfsplus filesystem implementation in the Linux kernel before 3.3.5 allow local users to gain privileges via a crafted HFS plus filesystem, a related issue to CVE-2009-4020.",
        "git_url": "https://github.com/torvalds/linux/commit/6f24f892871acc47b40dd594c63606a17c714f77",
        "commit_title": "hfsplus: Fix potential buffer overflows",
        "commit_text": " Commit ec81aecb2966 (\"hfs: fix a potential buffer overflow\") fixed a few potential buffer overflows in the hfs filesystem.  But as Timo Warns pointed out, these changes also need to be made on the hfsplus filesystem as well.  Cc: Alexey Khoroshilov <khoroshilov@ispras.ru> Cc: Miklos Szeredi <mszeredi@suse.cz> Cc: Sage Weil <sage@newdream.net> Cc: Eugene Teo <eteo@redhat.com> Cc: Roman Zippel <zippel@linux-m68k.org> Cc: Al Viro <viro@zeniv.linux.org.uk> Cc: Christoph Hellwig <hch@lst.de> Cc: Alexey Dobriyan <adobriyan@gmail.com> Cc: Dave Anderson <anderson@redhat.com> Cc: stable <stable@vger.kernel.org> Cc: Andrew Morton <akpm@linux-foundation.org>",
        "func_before": "static int hfsplus_readdir(struct file *filp, void *dirent, filldir_t filldir)\n{\n\tstruct inode *inode = filp->f_path.dentry->d_inode;\n\tstruct super_block *sb = inode->i_sb;\n\tint len, err;\n\tchar strbuf[HFSPLUS_MAX_STRLEN + 1];\n\thfsplus_cat_entry entry;\n\tstruct hfs_find_data fd;\n\tstruct hfsplus_readdir_data *rd;\n\tu16 type;\n\n\tif (filp->f_pos >= inode->i_size)\n\t\treturn 0;\n\n\terr = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &fd);\n\tif (err)\n\t\treturn err;\n\thfsplus_cat_build_key(sb, fd.search_key, inode->i_ino, NULL);\n\terr = hfs_brec_find(&fd);\n\tif (err)\n\t\tgoto out;\n\n\tswitch ((u32)filp->f_pos) {\n\tcase 0:\n\t\t/* This is completely artificial... */\n\t\tif (filldir(dirent, \".\", 1, 0, inode->i_ino, DT_DIR))\n\t\t\tgoto out;\n\t\tfilp->f_pos++;\n\t\t/* fall through */\n\tcase 1:\n\t\thfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n\t\t\tfd.entrylength);\n\t\tif (be16_to_cpu(entry.type) != HFSPLUS_FOLDER_THREAD) {\n\t\t\tprintk(KERN_ERR \"hfs: bad catalog folder thread\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tif (fd.entrylength < HFSPLUS_MIN_THREAD_SZ) {\n\t\t\tprintk(KERN_ERR \"hfs: truncated catalog thread\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tif (filldir(dirent, \"..\", 2, 1,\n\t\t\t    be32_to_cpu(entry.thread.parentID), DT_DIR))\n\t\t\tgoto out;\n\t\tfilp->f_pos++;\n\t\t/* fall through */\n\tdefault:\n\t\tif (filp->f_pos >= inode->i_size)\n\t\t\tgoto out;\n\t\terr = hfs_brec_goto(&fd, filp->f_pos - 1);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tfor (;;) {\n\t\tif (be32_to_cpu(fd.key->cat.parent) != inode->i_ino) {\n\t\t\tprintk(KERN_ERR \"hfs: walked past end of dir\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\thfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n\t\t\tfd.entrylength);\n\t\ttype = be16_to_cpu(entry.type);\n\t\tlen = HFSPLUS_MAX_STRLEN;\n\t\terr = hfsplus_uni2asc(sb, &fd.key->cat.name, strbuf, &len);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tif (type == HFSPLUS_FOLDER) {\n\t\t\tif (fd.entrylength <\n\t\t\t\t\tsizeof(struct hfsplus_cat_folder)) {\n\t\t\t\tprintk(KERN_ERR \"hfs: small dir entry\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (HFSPLUS_SB(sb)->hidden_dir &&\n\t\t\t    HFSPLUS_SB(sb)->hidden_dir->i_ino ==\n\t\t\t\t\tbe32_to_cpu(entry.folder.id))\n\t\t\t\tgoto next;\n\t\t\tif (filldir(dirent, strbuf, len, filp->f_pos,\n\t\t\t\t    be32_to_cpu(entry.folder.id), DT_DIR))\n\t\t\t\tbreak;\n\t\t} else if (type == HFSPLUS_FILE) {\n\t\t\tif (fd.entrylength < sizeof(struct hfsplus_cat_file)) {\n\t\t\t\tprintk(KERN_ERR \"hfs: small file entry\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (filldir(dirent, strbuf, len, filp->f_pos,\n\t\t\t\t    be32_to_cpu(entry.file.id), DT_REG))\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\tprintk(KERN_ERR \"hfs: bad catalog entry type\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\nnext:\n\t\tfilp->f_pos++;\n\t\tif (filp->f_pos >= inode->i_size)\n\t\t\tgoto out;\n\t\terr = hfs_brec_goto(&fd, 1);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\trd = filp->private_data;\n\tif (!rd) {\n\t\trd = kmalloc(sizeof(struct hfsplus_readdir_data), GFP_KERNEL);\n\t\tif (!rd) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tfilp->private_data = rd;\n\t\trd->file = filp;\n\t\tlist_add(&rd->list, &HFSPLUS_I(inode)->open_dir_list);\n\t}\n\tmemcpy(&rd->key, fd.key, sizeof(struct hfsplus_cat_key));\nout:\n\thfs_find_exit(&fd);\n\treturn err;\n}",
        "func": "static int hfsplus_readdir(struct file *filp, void *dirent, filldir_t filldir)\n{\n\tstruct inode *inode = filp->f_path.dentry->d_inode;\n\tstruct super_block *sb = inode->i_sb;\n\tint len, err;\n\tchar strbuf[HFSPLUS_MAX_STRLEN + 1];\n\thfsplus_cat_entry entry;\n\tstruct hfs_find_data fd;\n\tstruct hfsplus_readdir_data *rd;\n\tu16 type;\n\n\tif (filp->f_pos >= inode->i_size)\n\t\treturn 0;\n\n\terr = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &fd);\n\tif (err)\n\t\treturn err;\n\thfsplus_cat_build_key(sb, fd.search_key, inode->i_ino, NULL);\n\terr = hfs_brec_find(&fd);\n\tif (err)\n\t\tgoto out;\n\n\tswitch ((u32)filp->f_pos) {\n\tcase 0:\n\t\t/* This is completely artificial... */\n\t\tif (filldir(dirent, \".\", 1, 0, inode->i_ino, DT_DIR))\n\t\t\tgoto out;\n\t\tfilp->f_pos++;\n\t\t/* fall through */\n\tcase 1:\n\t\tif (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\thfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n\t\t\tfd.entrylength);\n\t\tif (be16_to_cpu(entry.type) != HFSPLUS_FOLDER_THREAD) {\n\t\t\tprintk(KERN_ERR \"hfs: bad catalog folder thread\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tif (fd.entrylength < HFSPLUS_MIN_THREAD_SZ) {\n\t\t\tprintk(KERN_ERR \"hfs: truncated catalog thread\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\t\tif (filldir(dirent, \"..\", 2, 1,\n\t\t\t    be32_to_cpu(entry.thread.parentID), DT_DIR))\n\t\t\tgoto out;\n\t\tfilp->f_pos++;\n\t\t/* fall through */\n\tdefault:\n\t\tif (filp->f_pos >= inode->i_size)\n\t\t\tgoto out;\n\t\terr = hfs_brec_goto(&fd, filp->f_pos - 1);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\tfor (;;) {\n\t\tif (be32_to_cpu(fd.key->cat.parent) != inode->i_ino) {\n\t\t\tprintk(KERN_ERR \"hfs: walked past end of dir\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\thfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n\t\t\tfd.entrylength);\n\t\ttype = be16_to_cpu(entry.type);\n\t\tlen = HFSPLUS_MAX_STRLEN;\n\t\terr = hfsplus_uni2asc(sb, &fd.key->cat.name, strbuf, &len);\n\t\tif (err)\n\t\t\tgoto out;\n\t\tif (type == HFSPLUS_FOLDER) {\n\t\t\tif (fd.entrylength <\n\t\t\t\t\tsizeof(struct hfsplus_cat_folder)) {\n\t\t\t\tprintk(KERN_ERR \"hfs: small dir entry\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (HFSPLUS_SB(sb)->hidden_dir &&\n\t\t\t    HFSPLUS_SB(sb)->hidden_dir->i_ino ==\n\t\t\t\t\tbe32_to_cpu(entry.folder.id))\n\t\t\t\tgoto next;\n\t\t\tif (filldir(dirent, strbuf, len, filp->f_pos,\n\t\t\t\t    be32_to_cpu(entry.folder.id), DT_DIR))\n\t\t\t\tbreak;\n\t\t} else if (type == HFSPLUS_FILE) {\n\t\t\tif (fd.entrylength < sizeof(struct hfsplus_cat_file)) {\n\t\t\t\tprintk(KERN_ERR \"hfs: small file entry\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (filldir(dirent, strbuf, len, filp->f_pos,\n\t\t\t\t    be32_to_cpu(entry.file.id), DT_REG))\n\t\t\t\tbreak;\n\t\t} else {\n\t\t\tprintk(KERN_ERR \"hfs: bad catalog entry type\\n\");\n\t\t\terr = -EIO;\n\t\t\tgoto out;\n\t\t}\nnext:\n\t\tfilp->f_pos++;\n\t\tif (filp->f_pos >= inode->i_size)\n\t\t\tgoto out;\n\t\terr = hfs_brec_goto(&fd, 1);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\trd = filp->private_data;\n\tif (!rd) {\n\t\trd = kmalloc(sizeof(struct hfsplus_readdir_data), GFP_KERNEL);\n\t\tif (!rd) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out;\n\t\t}\n\t\tfilp->private_data = rd;\n\t\trd->file = filp;\n\t\tlist_add(&rd->list, &HFSPLUS_I(inode)->open_dir_list);\n\t}\n\tmemcpy(&rd->key, fd.key, sizeof(struct hfsplus_cat_key));\nout:\n\thfs_find_exit(&fd);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,6 +28,11 @@\n \t\tfilp->f_pos++;\n \t\t/* fall through */\n \tcase 1:\n+\t\tif (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {\n+\t\t\terr = -EIO;\n+\t\t\tgoto out;\n+\t\t}\n+\n \t\thfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n \t\t\tfd.entrylength);\n \t\tif (be16_to_cpu(entry.type) != HFSPLUS_FOLDER_THREAD) {\n@@ -59,6 +64,12 @@\n \t\t\terr = -EIO;\n \t\t\tgoto out;\n \t\t}\n+\n+\t\tif (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {\n+\t\t\terr = -EIO;\n+\t\t\tgoto out;\n+\t\t}\n+\n \t\thfs_bnode_read(fd.bnode, &entry, fd.entryoffset,\n \t\t\tfd.entrylength);\n \t\ttype = be16_to_cpu(entry.type);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {",
                "\t\t\terr = -EIO;",
                "\t\t\tgoto out;",
                "\t\t}",
                "",
                "",
                "\t\tif (fd.entrylength > sizeof(entry) || fd.entrylength < 0) {",
                "\t\t\terr = -EIO;",
                "\t\t\tgoto out;",
                "\t\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2319",
        "func_name": "torvalds/linux/hfsplus_rename_cat",
        "description": "Multiple buffer overflows in the hfsplus filesystem implementation in the Linux kernel before 3.3.5 allow local users to gain privileges via a crafted HFS plus filesystem, a related issue to CVE-2009-4020.",
        "git_url": "https://github.com/torvalds/linux/commit/6f24f892871acc47b40dd594c63606a17c714f77",
        "commit_title": "hfsplus: Fix potential buffer overflows",
        "commit_text": " Commit ec81aecb2966 (\"hfs: fix a potential buffer overflow\") fixed a few potential buffer overflows in the hfs filesystem.  But as Timo Warns pointed out, these changes also need to be made on the hfsplus filesystem as well.  Cc: Alexey Khoroshilov <khoroshilov@ispras.ru> Cc: Miklos Szeredi <mszeredi@suse.cz> Cc: Sage Weil <sage@newdream.net> Cc: Eugene Teo <eteo@redhat.com> Cc: Roman Zippel <zippel@linux-m68k.org> Cc: Al Viro <viro@zeniv.linux.org.uk> Cc: Christoph Hellwig <hch@lst.de> Cc: Alexey Dobriyan <adobriyan@gmail.com> Cc: Dave Anderson <anderson@redhat.com> Cc: stable <stable@vger.kernel.org> Cc: Andrew Morton <akpm@linux-foundation.org>",
        "func_before": "int hfsplus_rename_cat(u32 cnid,\n\t\t       struct inode *src_dir, struct qstr *src_name,\n\t\t       struct inode *dst_dir, struct qstr *dst_name)\n{\n\tstruct super_block *sb = src_dir->i_sb;\n\tstruct hfs_find_data src_fd, dst_fd;\n\thfsplus_cat_entry entry;\n\tint entry_size, type;\n\tint err;\n\n\tdprint(DBG_CAT_MOD, \"rename_cat: %u - %lu,%s - %lu,%s\\n\",\n\t\tcnid, src_dir->i_ino, src_name->name,\n\t\tdst_dir->i_ino, dst_name->name);\n\terr = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &src_fd);\n\tif (err)\n\t\treturn err;\n\tdst_fd = src_fd;\n\n\t/* find the old dir entry and read the data */\n\thfsplus_cat_build_key(sb, src_fd.search_key, src_dir->i_ino, src_name);\n\terr = hfs_brec_find(&src_fd);\n\tif (err)\n\t\tgoto out;\n\n\thfs_bnode_read(src_fd.bnode, &entry, src_fd.entryoffset,\n\t\t\t\tsrc_fd.entrylength);\n\n\t/* create new dir entry with the data from the old entry */\n\thfsplus_cat_build_key(sb, dst_fd.search_key, dst_dir->i_ino, dst_name);\n\terr = hfs_brec_find(&dst_fd);\n\tif (err != -ENOENT) {\n\t\tif (!err)\n\t\t\terr = -EEXIST;\n\t\tgoto out;\n\t}\n\n\terr = hfs_brec_insert(&dst_fd, &entry, src_fd.entrylength);\n\tif (err)\n\t\tgoto out;\n\tdst_dir->i_size++;\n\tdst_dir->i_mtime = dst_dir->i_ctime = CURRENT_TIME_SEC;\n\n\t/* finally remove the old entry */\n\thfsplus_cat_build_key(sb, src_fd.search_key, src_dir->i_ino, src_name);\n\terr = hfs_brec_find(&src_fd);\n\tif (err)\n\t\tgoto out;\n\terr = hfs_brec_remove(&src_fd);\n\tif (err)\n\t\tgoto out;\n\tsrc_dir->i_size--;\n\tsrc_dir->i_mtime = src_dir->i_ctime = CURRENT_TIME_SEC;\n\n\t/* remove old thread entry */\n\thfsplus_cat_build_key(sb, src_fd.search_key, cnid, NULL);\n\terr = hfs_brec_find(&src_fd);\n\tif (err)\n\t\tgoto out;\n\ttype = hfs_bnode_read_u16(src_fd.bnode, src_fd.entryoffset);\n\terr = hfs_brec_remove(&src_fd);\n\tif (err)\n\t\tgoto out;\n\n\t/* create new thread entry */\n\thfsplus_cat_build_key(sb, dst_fd.search_key, cnid, NULL);\n\tentry_size = hfsplus_fill_cat_thread(sb, &entry, type,\n\t\tdst_dir->i_ino, dst_name);\n\terr = hfs_brec_find(&dst_fd);\n\tif (err != -ENOENT) {\n\t\tif (!err)\n\t\t\terr = -EEXIST;\n\t\tgoto out;\n\t}\n\terr = hfs_brec_insert(&dst_fd, &entry, entry_size);\n\n\thfsplus_mark_inode_dirty(dst_dir, HFSPLUS_I_CAT_DIRTY);\n\thfsplus_mark_inode_dirty(src_dir, HFSPLUS_I_CAT_DIRTY);\nout:\n\thfs_bnode_put(dst_fd.bnode);\n\thfs_find_exit(&src_fd);\n\treturn err;\n}",
        "func": "int hfsplus_rename_cat(u32 cnid,\n\t\t       struct inode *src_dir, struct qstr *src_name,\n\t\t       struct inode *dst_dir, struct qstr *dst_name)\n{\n\tstruct super_block *sb = src_dir->i_sb;\n\tstruct hfs_find_data src_fd, dst_fd;\n\thfsplus_cat_entry entry;\n\tint entry_size, type;\n\tint err;\n\n\tdprint(DBG_CAT_MOD, \"rename_cat: %u - %lu,%s - %lu,%s\\n\",\n\t\tcnid, src_dir->i_ino, src_name->name,\n\t\tdst_dir->i_ino, dst_name->name);\n\terr = hfs_find_init(HFSPLUS_SB(sb)->cat_tree, &src_fd);\n\tif (err)\n\t\treturn err;\n\tdst_fd = src_fd;\n\n\t/* find the old dir entry and read the data */\n\thfsplus_cat_build_key(sb, src_fd.search_key, src_dir->i_ino, src_name);\n\terr = hfs_brec_find(&src_fd);\n\tif (err)\n\t\tgoto out;\n\tif (src_fd.entrylength > sizeof(entry) || src_fd.entrylength < 0) {\n\t\terr = -EIO;\n\t\tgoto out;\n\t}\n\n\thfs_bnode_read(src_fd.bnode, &entry, src_fd.entryoffset,\n\t\t\t\tsrc_fd.entrylength);\n\n\t/* create new dir entry with the data from the old entry */\n\thfsplus_cat_build_key(sb, dst_fd.search_key, dst_dir->i_ino, dst_name);\n\terr = hfs_brec_find(&dst_fd);\n\tif (err != -ENOENT) {\n\t\tif (!err)\n\t\t\terr = -EEXIST;\n\t\tgoto out;\n\t}\n\n\terr = hfs_brec_insert(&dst_fd, &entry, src_fd.entrylength);\n\tif (err)\n\t\tgoto out;\n\tdst_dir->i_size++;\n\tdst_dir->i_mtime = dst_dir->i_ctime = CURRENT_TIME_SEC;\n\n\t/* finally remove the old entry */\n\thfsplus_cat_build_key(sb, src_fd.search_key, src_dir->i_ino, src_name);\n\terr = hfs_brec_find(&src_fd);\n\tif (err)\n\t\tgoto out;\n\terr = hfs_brec_remove(&src_fd);\n\tif (err)\n\t\tgoto out;\n\tsrc_dir->i_size--;\n\tsrc_dir->i_mtime = src_dir->i_ctime = CURRENT_TIME_SEC;\n\n\t/* remove old thread entry */\n\thfsplus_cat_build_key(sb, src_fd.search_key, cnid, NULL);\n\terr = hfs_brec_find(&src_fd);\n\tif (err)\n\t\tgoto out;\n\ttype = hfs_bnode_read_u16(src_fd.bnode, src_fd.entryoffset);\n\terr = hfs_brec_remove(&src_fd);\n\tif (err)\n\t\tgoto out;\n\n\t/* create new thread entry */\n\thfsplus_cat_build_key(sb, dst_fd.search_key, cnid, NULL);\n\tentry_size = hfsplus_fill_cat_thread(sb, &entry, type,\n\t\tdst_dir->i_ino, dst_name);\n\terr = hfs_brec_find(&dst_fd);\n\tif (err != -ENOENT) {\n\t\tif (!err)\n\t\t\terr = -EEXIST;\n\t\tgoto out;\n\t}\n\terr = hfs_brec_insert(&dst_fd, &entry, entry_size);\n\n\thfsplus_mark_inode_dirty(dst_dir, HFSPLUS_I_CAT_DIRTY);\n\thfsplus_mark_inode_dirty(src_dir, HFSPLUS_I_CAT_DIRTY);\nout:\n\thfs_bnode_put(dst_fd.bnode);\n\thfs_find_exit(&src_fd);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,10 @@\n \terr = hfs_brec_find(&src_fd);\n \tif (err)\n \t\tgoto out;\n+\tif (src_fd.entrylength > sizeof(entry) || src_fd.entrylength < 0) {\n+\t\terr = -EIO;\n+\t\tgoto out;\n+\t}\n \n \thfs_bnode_read(src_fd.bnode, &entry, src_fd.entryoffset,\n \t\t\t\tsrc_fd.entrylength);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (src_fd.entrylength > sizeof(entry) || src_fd.entrylength < 0) {",
                "\t\terr = -EIO;",
                "\t\tgoto out;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2320",
        "func_name": "connman/netlink_event",
        "description": "ConnMan before 0.85 does not ensure that netlink messages originate from the kernel, which allows remote attackers to bypass intended access restrictions and cause a denial of service via a crafted netlink message.",
        "git_url": "http://git.kernel.org/?p=network/connman/connman.git;a=commit;h=b0ec6eb4466acc57a9ea8be52c17b674b6ea0618",
        "commit_title": "",
        "commit_text": "",
        "func_before": "static gboolean netlink_event(GIOChannel *chan,\n\t\t\t\tGIOCondition cond, gpointer data)\n{\n\tunsigned char buf[4096];\n\tgsize len;\n\tGIOStatus status;\n\n\tif (cond & (G_IO_NVAL | G_IO_HUP | G_IO_ERR))\n\t\treturn FALSE;\n\n\tmemset(buf, 0, sizeof(buf));\n\n\tstatus = g_io_channel_read_chars(chan, (gchar *) buf,\n\t\t\t\t\t\tsizeof(buf), &len, NULL);\n\n\tswitch (status) {\n\tcase G_IO_STATUS_NORMAL:\n\t\tbreak;\n\tcase G_IO_STATUS_AGAIN:\n\t\treturn TRUE;\n\tdefault:\n\t\treturn FALSE;\n\t}\n\n\trtnl_message(buf, len);\n\n\treturn TRUE;\n}",
        "func": "static gboolean netlink_event(GIOChannel *chan,\n\t\t\t\tGIOCondition cond, gpointer data)\n{\n\tunsigned char buf[4096];\n\tstruct sockaddr_nl nladdr;\n\tsocklen_t addr_len = sizeof(nladdr);\n\tssize_t status;\n\tint fd;\n\n\tif (cond & (G_IO_NVAL | G_IO_HUP | G_IO_ERR))\n\t\treturn FALSE;\n\n\tmemset(buf, 0, sizeof(buf));\n\tmemset(&nladdr, 0, sizeof(nladdr));\n\n\tfd = g_io_channel_unix_get_fd(chan);\n\n\tstatus = recvfrom(fd, buf, sizeof(buf), 0,\n                       (struct sockaddr *) &nladdr, &addr_len);\n\tif (status < 0) {\n\t\tif (errno == EINTR || errno == EAGAIN)\n\t\t\treturn TRUE;\n\n\t\treturn FALSE;\n\t}\n\n\tif (status == 0)\n\t\treturn FALSE;\n\n\tif (nladdr.nl_pid != 0) { /* not sent by kernel, ignore */\n\t\tDBG(\"Received msg from %u, ignoring it\", nladdr.nl_pid);\n\t\treturn TRUE;\n\t}\n\n\trtnl_message(buf, status);\n\n\treturn TRUE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,27 +2,37 @@\n \t\t\t\tGIOCondition cond, gpointer data)\n {\n \tunsigned char buf[4096];\n-\tgsize len;\n-\tGIOStatus status;\n+\tstruct sockaddr_nl nladdr;\n+\tsocklen_t addr_len = sizeof(nladdr);\n+\tssize_t status;\n+\tint fd;\n \n \tif (cond & (G_IO_NVAL | G_IO_HUP | G_IO_ERR))\n \t\treturn FALSE;\n \n \tmemset(buf, 0, sizeof(buf));\n+\tmemset(&nladdr, 0, sizeof(nladdr));\n \n-\tstatus = g_io_channel_read_chars(chan, (gchar *) buf,\n-\t\t\t\t\t\tsizeof(buf), &len, NULL);\n+\tfd = g_io_channel_unix_get_fd(chan);\n \n-\tswitch (status) {\n-\tcase G_IO_STATUS_NORMAL:\n-\t\tbreak;\n-\tcase G_IO_STATUS_AGAIN:\n-\t\treturn TRUE;\n-\tdefault:\n+\tstatus = recvfrom(fd, buf, sizeof(buf), 0,\n+                       (struct sockaddr *) &nladdr, &addr_len);\n+\tif (status < 0) {\n+\t\tif (errno == EINTR || errno == EAGAIN)\n+\t\t\treturn TRUE;\n+\n \t\treturn FALSE;\n \t}\n \n-\trtnl_message(buf, len);\n+\tif (status == 0)\n+\t\treturn FALSE;\n+\n+\tif (nladdr.nl_pid != 0) { /* not sent by kernel, ignore */\n+\t\tDBG(\"Received msg from %u, ignoring it\", nladdr.nl_pid);\n+\t\treturn TRUE;\n+\t}\n+\n+\trtnl_message(buf, status);\n \n \treturn TRUE;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tgsize len;",
                "\tGIOStatus status;",
                "\tstatus = g_io_channel_read_chars(chan, (gchar *) buf,",
                "\t\t\t\t\t\tsizeof(buf), &len, NULL);",
                "\tswitch (status) {",
                "\tcase G_IO_STATUS_NORMAL:",
                "\t\tbreak;",
                "\tcase G_IO_STATUS_AGAIN:",
                "\t\treturn TRUE;",
                "\tdefault:",
                "\trtnl_message(buf, len);"
            ],
            "added_lines": [
                "\tstruct sockaddr_nl nladdr;",
                "\tsocklen_t addr_len = sizeof(nladdr);",
                "\tssize_t status;",
                "\tint fd;",
                "\tmemset(&nladdr, 0, sizeof(nladdr));",
                "\tfd = g_io_channel_unix_get_fd(chan);",
                "\tstatus = recvfrom(fd, buf, sizeof(buf), 0,",
                "                       (struct sockaddr *) &nladdr, &addr_len);",
                "\tif (status < 0) {",
                "\t\tif (errno == EINTR || errno == EAGAIN)",
                "\t\t\treturn TRUE;",
                "",
                "\tif (status == 0)",
                "\t\treturn FALSE;",
                "",
                "\tif (nladdr.nl_pid != 0) { /* not sent by kernel, ignore */",
                "\t\tDBG(\"Received msg from %u, ignoring it\", nladdr.nl_pid);",
                "\t\treturn TRUE;",
                "\t}",
                "",
                "\trtnl_message(buf, status);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2320",
        "func_name": "connman/rtnl_message",
        "description": "ConnMan before 0.85 does not ensure that netlink messages originate from the kernel, which allows remote attackers to bypass intended access restrictions and cause a denial of service via a crafted netlink message.",
        "git_url": "http://git.kernel.org/?p=network/connman/connman.git;a=commit;h=b0ec6eb4466acc57a9ea8be52c17b674b6ea0618",
        "commit_title": "",
        "commit_text": "",
        "func_before": "static void rtnl_message(void *buf, size_t len)\n{\n\tDBG(\"buf %p len %zd\", buf, len);\n\n\twhile (len > 0) {\n\t\tstruct nlmsghdr *hdr = buf;\n\t\tstruct nlmsgerr *err;\n\n\t\tif (!NLMSG_OK(hdr, len))\n\t\t\tbreak;\n\n\t\tDBG(\"%s len %d type %d flags 0x%04x seq %d\",\n\t\t\t\t\ttype2string(hdr->nlmsg_type),\n\t\t\t\t\thdr->nlmsg_len, hdr->nlmsg_type,\n\t\t\t\t\thdr->nlmsg_flags, hdr->nlmsg_seq);\n\n\t\tswitch (hdr->nlmsg_type) {\n\t\tcase NLMSG_NOOP:\n\t\tcase NLMSG_OVERRUN:\n\t\t\treturn;\n\t\tcase NLMSG_DONE:\n\t\t\tprocess_response(hdr->nlmsg_seq);\n\t\t\treturn;\n\t\tcase NLMSG_ERROR:\n\t\t\terr = NLMSG_DATA(hdr);\n\t\t\tDBG(\"error %d (%s)\", -err->error,\n\t\t\t\t\t\tstrerror(-err->error));\n\t\t\treturn;\n\t\tcase RTM_NEWLINK:\n\t\t\trtnl_newlink(hdr);\n\t\t\tbreak;\n\t\tcase RTM_DELLINK:\n\t\t\trtnl_dellink(hdr);\n\t\t\tbreak;\n\t\tcase RTM_NEWADDR:\n\t\t\trtnl_newaddr(hdr);\n\t\t\tbreak;\n\t\tcase RTM_DELADDR:\n\t\t\trtnl_deladdr(hdr);\n\t\t\tbreak;\n\t\tcase RTM_NEWROUTE:\n\t\t\trtnl_newroute(hdr);\n\t\t\tbreak;\n\t\tcase RTM_DELROUTE:\n\t\t\trtnl_delroute(hdr);\n\t\t\tbreak;\n\t\tcase RTM_NEWNDUSEROPT:\n\t\t\trtnl_newnduseropt(hdr);\n\t\t\tbreak;\n\t\t}\n\n\t\tlen -= hdr->nlmsg_len;\n\t\tbuf += hdr->nlmsg_len;\n\t}\n}",
        "func": "static void rtnl_message(void *buf, size_t len)\n{\n\tDBG(\"buf %p len %zd\", buf, len);\n\n\twhile (len > 0) {\n\t\tstruct nlmsghdr *hdr = buf;\n\t\tstruct nlmsgerr *err;\n\n\t\tif (!NLMSG_OK(hdr, len))\n\t\t\tbreak;\n\n\t\tDBG(\"%s len %d type %d flags 0x%04x seq %d pid %d\",\n\t\t\t\t\ttype2string(hdr->nlmsg_type),\n\t\t\t\t\thdr->nlmsg_len, hdr->nlmsg_type,\n\t\t\t\t\thdr->nlmsg_flags, hdr->nlmsg_seq,\n\t\t\t\t\thdr->nlmsg_pid);\n\n\t\tswitch (hdr->nlmsg_type) {\n\t\tcase NLMSG_NOOP:\n\t\tcase NLMSG_OVERRUN:\n\t\t\treturn;\n\t\tcase NLMSG_DONE:\n\t\t\tprocess_response(hdr->nlmsg_seq);\n\t\t\treturn;\n\t\tcase NLMSG_ERROR:\n\t\t\terr = NLMSG_DATA(hdr);\n\t\t\tDBG(\"error %d (%s)\", -err->error,\n\t\t\t\t\t\tstrerror(-err->error));\n\t\t\treturn;\n\t\tcase RTM_NEWLINK:\n\t\t\trtnl_newlink(hdr);\n\t\t\tbreak;\n\t\tcase RTM_DELLINK:\n\t\t\trtnl_dellink(hdr);\n\t\t\tbreak;\n\t\tcase RTM_NEWADDR:\n\t\t\trtnl_newaddr(hdr);\n\t\t\tbreak;\n\t\tcase RTM_DELADDR:\n\t\t\trtnl_deladdr(hdr);\n\t\t\tbreak;\n\t\tcase RTM_NEWROUTE:\n\t\t\trtnl_newroute(hdr);\n\t\t\tbreak;\n\t\tcase RTM_DELROUTE:\n\t\t\trtnl_delroute(hdr);\n\t\t\tbreak;\n\t\tcase RTM_NEWNDUSEROPT:\n\t\t\trtnl_newnduseropt(hdr);\n\t\t\tbreak;\n\t\t}\n\n\t\tlen -= hdr->nlmsg_len;\n\t\tbuf += hdr->nlmsg_len;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,10 +9,11 @@\n \t\tif (!NLMSG_OK(hdr, len))\n \t\t\tbreak;\n \n-\t\tDBG(\"%s len %d type %d flags 0x%04x seq %d\",\n+\t\tDBG(\"%s len %d type %d flags 0x%04x seq %d pid %d\",\n \t\t\t\t\ttype2string(hdr->nlmsg_type),\n \t\t\t\t\thdr->nlmsg_len, hdr->nlmsg_type,\n-\t\t\t\t\thdr->nlmsg_flags, hdr->nlmsg_seq);\n+\t\t\t\t\thdr->nlmsg_flags, hdr->nlmsg_seq,\n+\t\t\t\t\thdr->nlmsg_pid);\n \n \t\tswitch (hdr->nlmsg_type) {\n \t\tcase NLMSG_NOOP:",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tDBG(\"%s len %d type %d flags 0x%04x seq %d\",",
                "\t\t\t\t\thdr->nlmsg_flags, hdr->nlmsg_seq);"
            ],
            "added_lines": [
                "\t\tDBG(\"%s len %d type %d flags 0x%04x seq %d pid %d\",",
                "\t\t\t\t\thdr->nlmsg_flags, hdr->nlmsg_seq,",
                "\t\t\t\t\thdr->nlmsg_pid);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2320",
        "func_name": "connman/inet_rtnl_recv",
        "description": "ConnMan before 0.85 does not ensure that netlink messages originate from the kernel, which allows remote attackers to bypass intended access restrictions and cause a denial of service via a crafted netlink message.",
        "git_url": "http://git.kernel.org/?p=network/connman/connman.git;a=commit;h=c1b968984212b46bea1330f5ae029507b9bfded9",
        "commit_title": "",
        "commit_text": "",
        "func_before": "static int inet_rtnl_recv(GIOChannel *chan, gpointer user_data)\n{\n\tstruct inet_rtnl_cb_data *rtnl_data = user_data;\n\tstruct __connman_inet_rtnl_handle *rth = rtnl_data->rtnl;\n\tstruct nlmsghdr *h = NULL;\n\tunsigned char buf[4096];\n\tvoid *ptr = buf;\n\tgsize len;\n\tint status;\n\n\tmemset(buf, 0, sizeof(buf));\n\n\tstatus = g_io_channel_read_chars(chan, (gchar *) buf,\n\t\t\t\t\t\tsizeof(buf), &len, NULL);\n\n\tDBG(\"status %d\", status);\n\n\tswitch (status) {\n\tcase G_IO_STATUS_NORMAL:\n\t\tbreak;\n\tcase G_IO_STATUS_AGAIN:\n\t\treturn 0;\n\tdefault:\n\t\treturn -1;\n\t}\n\n\twhile (len > 0) {\n\t\tstruct nlmsgerr *err;\n\n\t\th = ptr;\n\n\t\tif (!NLMSG_OK(h, len)) {\n\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (h->nlmsg_seq != rth->seq) {\n\t\t\t/* Skip this msg */\n\t\t\tDBG(\"skip %d/%d len %d\", rth->seq,\n\t\t\t\th->nlmsg_seq, h->nlmsg_len);\n\n\t\t\tlen -= h->nlmsg_len;\n\t\t\tptr += h->nlmsg_len;\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (h->nlmsg_type) {\n\t\tcase NLMSG_NOOP:\n\t\tcase NLMSG_OVERRUN:\n\t\t\treturn -1;\n\n\t\tcase NLMSG_ERROR:\n\t\t\terr = (struct nlmsgerr *)NLMSG_DATA(h);\n\t\t\tconnman_error(\"RTNETLINK answers %s (%d)\",\n\t\t\t\tstrerror(-err->error), -err->error);\n\t\t\treturn err->error;\n\t\t}\n\n\t\tbreak;\n\t}\n\n\tif (h->nlmsg_seq == rth->seq) {\n\t\tDBG(\"received %d seq %d\", h->nlmsg_len, h->nlmsg_seq);\n\n\t\trtnl_data->callback(h, rtnl_data->user_data);\n\n\t\tif (rtnl_data->rtnl_timeout > 0) {\n\t\t\tg_source_remove(rtnl_data->rtnl_timeout);\n\t\t\trtnl_data->rtnl_timeout = 0;\n\t\t}\n\n\t\t__connman_inet_rtnl_close(rth);\n\t\tg_free(rth);\n\t}\n\n\treturn 0;\n}",
        "func": "static int inet_rtnl_recv(GIOChannel *chan, gpointer user_data)\n{\n\tstruct inet_rtnl_cb_data *rtnl_data = user_data;\n\tstruct __connman_inet_rtnl_handle *rth = rtnl_data->rtnl;\n\tstruct nlmsghdr *h = NULL;\n\tstruct sockaddr_nl nladdr;\n\tsocklen_t addr_len = sizeof(nladdr);\n\tunsigned char buf[4096];\n\tvoid *ptr = buf;\n\tgsize len;\n\tint status, fd;\n\n\tmemset(buf, 0, sizeof(buf));\n\tmemset(&nladdr, 0, sizeof(nladdr));\n\n\tfd = g_io_channel_unix_get_fd(chan);\n\n\tstatus = recvfrom(fd, buf, sizeof(buf), 0,\n                       (struct sockaddr *) &nladdr, &addr_len);\n\tif (status < 0) {\n\t\tif (errno == EINTR || errno == EAGAIN)\n\t\t\treturn 0;\n\n\t\treturn -1;\n\t}\n\n\tif (status == 0)\n\t\treturn -1;\n\n\tif (nladdr.nl_pid != 0) { /* not sent by kernel, ignore */\n\t\tDBG(\"Received msg from %u, ignoring it\", nladdr.nl_pid);\n\t\treturn 0;\n\t}\n\n\tlen = status;\n\n\twhile (len > 0) {\n\t\tstruct nlmsgerr *err;\n\n\t\th = ptr;\n\n\t\tif (!NLMSG_OK(h, len)) {\n\t\t\treturn -1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (h->nlmsg_seq != rth->seq) {\n\t\t\t/* Skip this msg */\n\t\t\tDBG(\"skip %d/%d len %d\", rth->seq,\n\t\t\t\th->nlmsg_seq, h->nlmsg_len);\n\n\t\t\tlen -= h->nlmsg_len;\n\t\t\tptr += h->nlmsg_len;\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (h->nlmsg_type) {\n\t\tcase NLMSG_NOOP:\n\t\tcase NLMSG_OVERRUN:\n\t\t\treturn -1;\n\n\t\tcase NLMSG_ERROR:\n\t\t\terr = (struct nlmsgerr *)NLMSG_DATA(h);\n\t\t\tconnman_error(\"RTNETLINK answers %s (%d)\",\n\t\t\t\tstrerror(-err->error), -err->error);\n\t\t\treturn err->error;\n\t\t}\n\n\t\tbreak;\n\t}\n\n\tif (h->nlmsg_seq == rth->seq) {\n\t\tDBG(\"received %d seq %d\", h->nlmsg_len, h->nlmsg_seq);\n\n\t\trtnl_data->callback(h, rtnl_data->user_data);\n\n\t\tif (rtnl_data->rtnl_timeout > 0) {\n\t\t\tg_source_remove(rtnl_data->rtnl_timeout);\n\t\t\trtnl_data->rtnl_timeout = 0;\n\t\t}\n\n\t\t__connman_inet_rtnl_close(rth);\n\t\tg_free(rth);\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,26 +3,36 @@\n \tstruct inet_rtnl_cb_data *rtnl_data = user_data;\n \tstruct __connman_inet_rtnl_handle *rth = rtnl_data->rtnl;\n \tstruct nlmsghdr *h = NULL;\n+\tstruct sockaddr_nl nladdr;\n+\tsocklen_t addr_len = sizeof(nladdr);\n \tunsigned char buf[4096];\n \tvoid *ptr = buf;\n \tgsize len;\n-\tint status;\n+\tint status, fd;\n \n \tmemset(buf, 0, sizeof(buf));\n+\tmemset(&nladdr, 0, sizeof(nladdr));\n \n-\tstatus = g_io_channel_read_chars(chan, (gchar *) buf,\n-\t\t\t\t\t\tsizeof(buf), &len, NULL);\n+\tfd = g_io_channel_unix_get_fd(chan);\n \n-\tDBG(\"status %d\", status);\n+\tstatus = recvfrom(fd, buf, sizeof(buf), 0,\n+                       (struct sockaddr *) &nladdr, &addr_len);\n+\tif (status < 0) {\n+\t\tif (errno == EINTR || errno == EAGAIN)\n+\t\t\treturn 0;\n \n-\tswitch (status) {\n-\tcase G_IO_STATUS_NORMAL:\n-\t\tbreak;\n-\tcase G_IO_STATUS_AGAIN:\n-\t\treturn 0;\n-\tdefault:\n \t\treturn -1;\n \t}\n+\n+\tif (status == 0)\n+\t\treturn -1;\n+\n+\tif (nladdr.nl_pid != 0) { /* not sent by kernel, ignore */\n+\t\tDBG(\"Received msg from %u, ignoring it\", nladdr.nl_pid);\n+\t\treturn 0;\n+\t}\n+\n+\tlen = status;\n \n \twhile (len > 0) {\n \t\tstruct nlmsgerr *err;",
        "diff_line_info": {
            "deleted_lines": [
                "\tint status;",
                "\tstatus = g_io_channel_read_chars(chan, (gchar *) buf,",
                "\t\t\t\t\t\tsizeof(buf), &len, NULL);",
                "\tDBG(\"status %d\", status);",
                "\tswitch (status) {",
                "\tcase G_IO_STATUS_NORMAL:",
                "\t\tbreak;",
                "\tcase G_IO_STATUS_AGAIN:",
                "\t\treturn 0;",
                "\tdefault:"
            ],
            "added_lines": [
                "\tstruct sockaddr_nl nladdr;",
                "\tsocklen_t addr_len = sizeof(nladdr);",
                "\tint status, fd;",
                "\tmemset(&nladdr, 0, sizeof(nladdr));",
                "\tfd = g_io_channel_unix_get_fd(chan);",
                "\tstatus = recvfrom(fd, buf, sizeof(buf), 0,",
                "                       (struct sockaddr *) &nladdr, &addr_len);",
                "\tif (status < 0) {",
                "\t\tif (errno == EINTR || errno == EAGAIN)",
                "\t\t\treturn 0;",
                "",
                "\tif (status == 0)",
                "\t\treturn -1;",
                "",
                "\tif (nladdr.nl_pid != 0) { /* not sent by kernel, ignore */",
                "\t\tDBG(\"Received msg from %u, ignoring it\", nladdr.nl_pid);",
                "\t\treturn 0;",
                "\t}",
                "",
                "\tlen = status;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2495",
        "func_name": "torvalds/linux/do_io_accounting",
        "description": "fs/proc/base.c in the Linux kernel before 2.6.39.4 does not properly restrict access to /proc/#####/io files, which allows local users to obtain sensitive I/O statistics by polling a file, as demonstrated by discovering the length of another user's password.",
        "git_url": "https://github.com/torvalds/linux/commit/1d1221f375c94ef961ba8574ac4f85c8870ddd51",
        "commit_title": "proc: restrict access to /proc/PID/io",
        "commit_text": " /proc/PID/io may be used for gathering private information.  E.g.  for openssh and vsftpd daemons wchars/rchars may be used to learn the precise password length.  Restrict it to processes being able to ptrace the target process.  ptrace_may_access() is needed to prevent keeping open file descriptor of \"io\" file, executing setuid binary and gathering io information of the setuid'ed process. ",
        "func_before": "static int do_io_accounting(struct task_struct *task, char *buffer, int whole)\n{\n\tstruct task_io_accounting acct = task->ioac;\n\tunsigned long flags;\n\n\tif (whole && lock_task_sighand(task, &flags)) {\n\t\tstruct task_struct *t = task;\n\n\t\ttask_io_accounting_add(&acct, &task->signal->ioac);\n\t\twhile_each_thread(task, t)\n\t\t\ttask_io_accounting_add(&acct, &t->ioac);\n\n\t\tunlock_task_sighand(task, &flags);\n\t}\n\treturn sprintf(buffer,\n\t\t\t\"rchar: %llu\\n\"\n\t\t\t\"wchar: %llu\\n\"\n\t\t\t\"syscr: %llu\\n\"\n\t\t\t\"syscw: %llu\\n\"\n\t\t\t\"read_bytes: %llu\\n\"\n\t\t\t\"write_bytes: %llu\\n\"\n\t\t\t\"cancelled_write_bytes: %llu\\n\",\n\t\t\t(unsigned long long)acct.rchar,\n\t\t\t(unsigned long long)acct.wchar,\n\t\t\t(unsigned long long)acct.syscr,\n\t\t\t(unsigned long long)acct.syscw,\n\t\t\t(unsigned long long)acct.read_bytes,\n\t\t\t(unsigned long long)acct.write_bytes,\n\t\t\t(unsigned long long)acct.cancelled_write_bytes);\n}",
        "func": "static int do_io_accounting(struct task_struct *task, char *buffer, int whole)\n{\n\tstruct task_io_accounting acct = task->ioac;\n\tunsigned long flags;\n\n\tif (!ptrace_may_access(task, PTRACE_MODE_READ))\n\t\treturn -EACCES;\n\n\tif (whole && lock_task_sighand(task, &flags)) {\n\t\tstruct task_struct *t = task;\n\n\t\ttask_io_accounting_add(&acct, &task->signal->ioac);\n\t\twhile_each_thread(task, t)\n\t\t\ttask_io_accounting_add(&acct, &t->ioac);\n\n\t\tunlock_task_sighand(task, &flags);\n\t}\n\treturn sprintf(buffer,\n\t\t\t\"rchar: %llu\\n\"\n\t\t\t\"wchar: %llu\\n\"\n\t\t\t\"syscr: %llu\\n\"\n\t\t\t\"syscw: %llu\\n\"\n\t\t\t\"read_bytes: %llu\\n\"\n\t\t\t\"write_bytes: %llu\\n\"\n\t\t\t\"cancelled_write_bytes: %llu\\n\",\n\t\t\t(unsigned long long)acct.rchar,\n\t\t\t(unsigned long long)acct.wchar,\n\t\t\t(unsigned long long)acct.syscr,\n\t\t\t(unsigned long long)acct.syscw,\n\t\t\t(unsigned long long)acct.read_bytes,\n\t\t\t(unsigned long long)acct.write_bytes,\n\t\t\t(unsigned long long)acct.cancelled_write_bytes);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,9 @@\n {\n \tstruct task_io_accounting acct = task->ioac;\n \tunsigned long flags;\n+\n+\tif (!ptrace_may_access(task, PTRACE_MODE_READ))\n+\t\treturn -EACCES;\n \n \tif (whole && lock_task_sighand(task, &flags)) {\n \t\tstruct task_struct *t = task;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!ptrace_may_access(task, PTRACE_MODE_READ))",
                "\t\treturn -EACCES;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2313",
        "func_name": "torvalds/linux/rio_ioctl",
        "description": "The rio_ioctl function in drivers/net/ethernet/dlink/dl2k.c in the Linux kernel before 3.3.7 does not restrict access to the SIOCSMIIREG command, which allows local users to write data to an Ethernet adapter via an ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/1bb57e940e1958e40d51f2078f50c3a96a9b2d75",
        "commit_title": "dl2k: Clean up rio_ioctl",
        "commit_text": " The dl2k driver's rio_ioctl call has a few issues: - No permissions checking - Implements SIOCGMIIREG and SIOCGMIIREG using the SIOCDEVPRIVATE numbers - Has a few ioctls that may have been used for debugging at one point   but have no place in the kernel proper.  This patch removes all but the MII ioctls, renumbers them to use the standard ones, and adds the proper permission check for SIOCSMIIREG.  We can also get rid of the dl2k-specific struct mii_data in favor of the generic struct mii_ioctl_data.  Since we have the phyid on hand, we can add the SIOCGMIIPHY ioctl too.  Most of the MII code for the driver could probably be converted to use the generic MII library but I don't have a device to test the results. ",
        "func_before": "static int\nrio_ioctl (struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tint phy_addr;\n\tstruct netdev_private *np = netdev_priv(dev);\n\tstruct mii_data *miidata = (struct mii_data *) &rq->ifr_ifru;\n\n\tstruct netdev_desc *desc;\n\tint i;\n\n\tphy_addr = np->phy_addr;\n\tswitch (cmd) {\n\tcase SIOCDEVPRIVATE:\n\t\tbreak;\n\n\tcase SIOCDEVPRIVATE + 1:\n\t\tmiidata->out_value = mii_read (dev, phy_addr, miidata->reg_num);\n\t\tbreak;\n\tcase SIOCDEVPRIVATE + 2:\n\t\tmii_write (dev, phy_addr, miidata->reg_num, miidata->in_value);\n\t\tbreak;\n\tcase SIOCDEVPRIVATE + 3:\n\t\tbreak;\n\tcase SIOCDEVPRIVATE + 4:\n\t\tbreak;\n\tcase SIOCDEVPRIVATE + 5:\n\t\tnetif_stop_queue (dev);\n\t\tbreak;\n\tcase SIOCDEVPRIVATE + 6:\n\t\tnetif_wake_queue (dev);\n\t\tbreak;\n\tcase SIOCDEVPRIVATE + 7:\n\t\tprintk\n\t\t    (\"tx_full=%x cur_tx=%lx old_tx=%lx cur_rx=%lx old_rx=%lx\\n\",\n\t\t     netif_queue_stopped(dev), np->cur_tx, np->old_tx, np->cur_rx,\n\t\t     np->old_rx);\n\t\tbreak;\n\tcase SIOCDEVPRIVATE + 8:\n\t\tprintk(\"TX ring:\\n\");\n\t\tfor (i = 0; i < TX_RING_SIZE; i++) {\n\t\t\tdesc = &np->tx_ring[i];\n\t\t\tprintk\n\t\t\t    (\"%02x:cur:%08x next:%08x status:%08x frag1:%08x frag0:%08x\",\n\t\t\t     i,\n\t\t\t     (u32) (np->tx_ring_dma + i * sizeof (*desc)),\n\t\t\t     (u32)le64_to_cpu(desc->next_desc),\n\t\t\t     (u32)le64_to_cpu(desc->status),\n\t\t\t     (u32)(le64_to_cpu(desc->fraginfo) >> 32),\n\t\t\t     (u32)le64_to_cpu(desc->fraginfo));\n\t\t\tprintk (\"\\n\");\n\t\t}\n\t\tprintk (\"\\n\");\n\t\tbreak;\n\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\treturn 0;\n}",
        "func": "static int\nrio_ioctl (struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tint phy_addr;\n\tstruct netdev_private *np = netdev_priv(dev);\n\tstruct mii_ioctl_data *miidata = if_mii(rq);\n\n\tphy_addr = np->phy_addr;\n\tswitch (cmd) {\n\tcase SIOCGMIIPHY:\n\t\tmiidata->phy_id = phy_addr;\n\t\tbreak;\n\tcase SIOCGMIIREG:\n\t\tmiidata->val_out = mii_read (dev, phy_addr, miidata->reg_num);\n\t\tbreak;\n\tcase SIOCSMIIREG:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmii_write (dev, phy_addr, miidata->reg_num, miidata->val_in);\n\t\tbreak;\n\tdefault:\n\t\treturn -EOPNOTSUPP;\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,55 +3,21 @@\n {\n \tint phy_addr;\n \tstruct netdev_private *np = netdev_priv(dev);\n-\tstruct mii_data *miidata = (struct mii_data *) &rq->ifr_ifru;\n-\n-\tstruct netdev_desc *desc;\n-\tint i;\n+\tstruct mii_ioctl_data *miidata = if_mii(rq);\n \n \tphy_addr = np->phy_addr;\n \tswitch (cmd) {\n-\tcase SIOCDEVPRIVATE:\n+\tcase SIOCGMIIPHY:\n+\t\tmiidata->phy_id = phy_addr;\n \t\tbreak;\n-\n-\tcase SIOCDEVPRIVATE + 1:\n-\t\tmiidata->out_value = mii_read (dev, phy_addr, miidata->reg_num);\n+\tcase SIOCGMIIREG:\n+\t\tmiidata->val_out = mii_read (dev, phy_addr, miidata->reg_num);\n \t\tbreak;\n-\tcase SIOCDEVPRIVATE + 2:\n-\t\tmii_write (dev, phy_addr, miidata->reg_num, miidata->in_value);\n+\tcase SIOCSMIIREG:\n+\t\tif (!capable(CAP_NET_ADMIN))\n+\t\t\treturn -EPERM;\n+\t\tmii_write (dev, phy_addr, miidata->reg_num, miidata->val_in);\n \t\tbreak;\n-\tcase SIOCDEVPRIVATE + 3:\n-\t\tbreak;\n-\tcase SIOCDEVPRIVATE + 4:\n-\t\tbreak;\n-\tcase SIOCDEVPRIVATE + 5:\n-\t\tnetif_stop_queue (dev);\n-\t\tbreak;\n-\tcase SIOCDEVPRIVATE + 6:\n-\t\tnetif_wake_queue (dev);\n-\t\tbreak;\n-\tcase SIOCDEVPRIVATE + 7:\n-\t\tprintk\n-\t\t    (\"tx_full=%x cur_tx=%lx old_tx=%lx cur_rx=%lx old_rx=%lx\\n\",\n-\t\t     netif_queue_stopped(dev), np->cur_tx, np->old_tx, np->cur_rx,\n-\t\t     np->old_rx);\n-\t\tbreak;\n-\tcase SIOCDEVPRIVATE + 8:\n-\t\tprintk(\"TX ring:\\n\");\n-\t\tfor (i = 0; i < TX_RING_SIZE; i++) {\n-\t\t\tdesc = &np->tx_ring[i];\n-\t\t\tprintk\n-\t\t\t    (\"%02x:cur:%08x next:%08x status:%08x frag1:%08x frag0:%08x\",\n-\t\t\t     i,\n-\t\t\t     (u32) (np->tx_ring_dma + i * sizeof (*desc)),\n-\t\t\t     (u32)le64_to_cpu(desc->next_desc),\n-\t\t\t     (u32)le64_to_cpu(desc->status),\n-\t\t\t     (u32)(le64_to_cpu(desc->fraginfo) >> 32),\n-\t\t\t     (u32)le64_to_cpu(desc->fraginfo));\n-\t\t\tprintk (\"\\n\");\n-\t\t}\n-\t\tprintk (\"\\n\");\n-\t\tbreak;\n-\n \tdefault:\n \t\treturn -EOPNOTSUPP;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct mii_data *miidata = (struct mii_data *) &rq->ifr_ifru;",
                "",
                "\tstruct netdev_desc *desc;",
                "\tint i;",
                "\tcase SIOCDEVPRIVATE:",
                "",
                "\tcase SIOCDEVPRIVATE + 1:",
                "\t\tmiidata->out_value = mii_read (dev, phy_addr, miidata->reg_num);",
                "\tcase SIOCDEVPRIVATE + 2:",
                "\t\tmii_write (dev, phy_addr, miidata->reg_num, miidata->in_value);",
                "\tcase SIOCDEVPRIVATE + 3:",
                "\t\tbreak;",
                "\tcase SIOCDEVPRIVATE + 4:",
                "\t\tbreak;",
                "\tcase SIOCDEVPRIVATE + 5:",
                "\t\tnetif_stop_queue (dev);",
                "\t\tbreak;",
                "\tcase SIOCDEVPRIVATE + 6:",
                "\t\tnetif_wake_queue (dev);",
                "\t\tbreak;",
                "\tcase SIOCDEVPRIVATE + 7:",
                "\t\tprintk",
                "\t\t    (\"tx_full=%x cur_tx=%lx old_tx=%lx cur_rx=%lx old_rx=%lx\\n\",",
                "\t\t     netif_queue_stopped(dev), np->cur_tx, np->old_tx, np->cur_rx,",
                "\t\t     np->old_rx);",
                "\t\tbreak;",
                "\tcase SIOCDEVPRIVATE + 8:",
                "\t\tprintk(\"TX ring:\\n\");",
                "\t\tfor (i = 0; i < TX_RING_SIZE; i++) {",
                "\t\t\tdesc = &np->tx_ring[i];",
                "\t\t\tprintk",
                "\t\t\t    (\"%02x:cur:%08x next:%08x status:%08x frag1:%08x frag0:%08x\",",
                "\t\t\t     i,",
                "\t\t\t     (u32) (np->tx_ring_dma + i * sizeof (*desc)),",
                "\t\t\t     (u32)le64_to_cpu(desc->next_desc),",
                "\t\t\t     (u32)le64_to_cpu(desc->status),",
                "\t\t\t     (u32)(le64_to_cpu(desc->fraginfo) >> 32),",
                "\t\t\t     (u32)le64_to_cpu(desc->fraginfo));",
                "\t\t\tprintk (\"\\n\");",
                "\t\t}",
                "\t\tprintk (\"\\n\");",
                "\t\tbreak;",
                ""
            ],
            "added_lines": [
                "\tstruct mii_ioctl_data *miidata = if_mii(rq);",
                "\tcase SIOCGMIIPHY:",
                "\t\tmiidata->phy_id = phy_addr;",
                "\tcase SIOCGMIIREG:",
                "\t\tmiidata->val_out = mii_read (dev, phy_addr, miidata->reg_num);",
                "\tcase SIOCSMIIREG:",
                "\t\tif (!capable(CAP_NET_ADMIN))",
                "\t\t\treturn -EPERM;",
                "\t\tmii_write (dev, phy_addr, miidata->reg_num, miidata->val_in);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4328",
        "func_name": "gnash/nsPluginInstance::setupCookies",
        "description": "plugin/npapi/plugin.cpp in Gnash before 0.8.10 uses weak permissions (world readable) for cookie files with predictable names in /tmp, which allows local users to obtain sensitive information.",
        "git_url": "http://git.savannah.gnu.org/gitweb/?p=gnash.git;a=commit;h=fa481c116e65ccf9137c7ddc8abc3cf05dc12f55",
        "commit_title": "",
        "commit_text": "Make cookie file not world-readable. Fixes bugs.debian.org/649384 ",
        "func_before": "void\nnsPluginInstance::setupCookies(const std::string& pageurl)\n{\n    // Cookie appear to drop anything past the domain, so we strip\n    // that off.\n    std::string::size_type pos;\n    pos = pageurl.find(\"/\", pageurl.find(\"//\", 0) + 2) + 1;\n    std::string url = pageurl.substr(0, pos);\n\n    std::string ncookie;\n \n    char *cookie = 0;\n    uint32_t length = 0;\n\n    NPError rv = NPERR_GENERIC_ERROR;\n#if NPAPI_VERSION != 190\n    if (NPNFuncs.getvalueforurl) {\n        rv = NPN_GetValueForURL(_instance, NPNURLVCookie, url.c_str(),\n                                &cookie, &length);\n    } else {\n        LOG_ONCE( gnash::log_debug(\"Browser doesn't support getvalueforurl\") );\n    }\n#endif\n\n    // Firefox does not (always) return the cookies that are associated\n    // with a domain name through GetValueForURL.\n    if (rv == NPERR_GENERIC_ERROR) {\n        log_debug(\"Trying window.document.cookie for cookies\");\n        ncookie = getDocumentProp(\"cookie\");\n    }\n\n    if (cookie) {\n        ncookie.assign(cookie, length);\n        NPN_MemFree(cookie);\n    }\n\n    if (ncookie.empty()) {\n        gnash::log_debug(\"No stored Cookie for %s\", url);\n        return;\n    }\n\n    gnash::log_debug(\"The Cookie for %s is %s\", url, ncookie);\n    std::ofstream cookiefile;\n    std::stringstream ss;\n    ss << \"/tmp/gnash-cookies.\" << getpid();\n\n    cookiefile.open(ss.str().c_str(), std::ios::out | std::ios::trunc);\n\n    // Firefox provides cookies in the following format:\n    //\n    // cookie1=value1;cookie2=value2;cookie3=value3\n    //\n    // Whereas libcurl expects cookies in the following format:\n    //\n    // Set-Cookie: cookie1=value1;\n    // Set-Cookie: cookie2=value2;\n  \n    typedef boost::char_separator<char> char_sep;\n    typedef boost::tokenizer<char_sep> tokenizer;\n    tokenizer tok(ncookie, char_sep(\";\"));\n\n    for (tokenizer::iterator it=tok.begin(); it != tok.end(); ++it) {\n        cookiefile << \"Set-Cookie: \" << *it << std::endl;\n    }\n \n    cookiefile.close();\n  \n    if (setenv(\"GNASH_COOKIES_IN\", ss.str().c_str(), 1) < 0) {\n        gnash::log_error(\n            \"Couldn't set environment variable GNASH_COOKIES_IN to %s\",\n            ncookie);\n    }\n}",
        "func": "void\nnsPluginInstance::setupCookies(const std::string& pageurl)\n{\n    // Cookie appear to drop anything past the domain, so we strip\n    // that off.\n    std::string::size_type pos;\n    pos = pageurl.find(\"/\", pageurl.find(\"//\", 0) + 2) + 1;\n    std::string url = pageurl.substr(0, pos);\n\n    std::string ncookie;\n \n    char *cookie = 0;\n    uint32_t length = 0;\n\n    NPError rv = NPERR_GENERIC_ERROR;\n#if NPAPI_VERSION != 190\n    if (NPNFuncs.getvalueforurl) {\n        rv = NPN_GetValueForURL(_instance, NPNURLVCookie, url.c_str(),\n                                &cookie, &length);\n    } else {\n        LOG_ONCE( gnash::log_debug(\"Browser doesn't support getvalueforurl\") );\n    }\n#endif\n\n    // Firefox does not (always) return the cookies that are associated\n    // with a domain name through GetValueForURL.\n    if (rv == NPERR_GENERIC_ERROR) {\n        log_debug(\"Trying window.document.cookie for cookies\");\n        ncookie = getDocumentProp(\"cookie\");\n    }\n\n    if (cookie) {\n        ncookie.assign(cookie, length);\n        NPN_MemFree(cookie);\n    }\n\n    if (ncookie.empty()) {\n        gnash::log_debug(\"No stored Cookie for %s\", url);\n        return;\n    }\n\n    gnash::log_debug(\"The Cookie for %s is %s\", url, ncookie);\n    std::ofstream cookiefile;\n    std::stringstream ss;\n    ss << \"/tmp/gnash-cookies.\" << getpid();\n\n    cookiefile.open(ss.str().c_str(), std::ios::out | std::ios::trunc);\n    chmod (ss.str().c_str(), 0600);\n\n    // Firefox provides cookies in the following format:\n    //\n    // cookie1=value1;cookie2=value2;cookie3=value3\n    //\n    // Whereas libcurl expects cookies in the following format:\n    //\n    // Set-Cookie: cookie1=value1;\n    // Set-Cookie: cookie2=value2;\n  \n    typedef boost::char_separator<char> char_sep;\n    typedef boost::tokenizer<char_sep> tokenizer;\n    tokenizer tok(ncookie, char_sep(\";\"));\n\n    for (tokenizer::iterator it=tok.begin(); it != tok.end(); ++it) {\n        cookiefile << \"Set-Cookie: \" << *it << std::endl;\n    }\n \n    cookiefile.close();\n  \n    if (setenv(\"GNASH_COOKIES_IN\", ss.str().c_str(), 1) < 0) {\n        gnash::log_error(\n            \"Couldn't set environment variable GNASH_COOKIES_IN to %s\",\n            ncookie);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -45,6 +45,7 @@\n     ss << \"/tmp/gnash-cookies.\" << getpid();\n \n     cookiefile.open(ss.str().c_str(), std::ios::out | std::ios::trunc);\n+    chmod (ss.str().c_str(), 0600);\n \n     // Firefox provides cookies in the following format:\n     //",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    chmod (ss.str().c_str(), 0600);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0006",
        "func_name": "torvalds/linux/ima_lsm_rule_init",
        "description": "The ima_lsm_rule_init function in security/integrity/ima/ima_policy.c in the Linux kernel before 2.6.37, when the Linux Security Modules (LSM) framework is disabled, allows local users to bypass Integrity Measurement Architecture (IMA) rules in opportunistic circumstances by leveraging an administrator's addition of an IMA rule for LSM.",
        "git_url": "https://github.com/torvalds/linux/commit/867c20265459d30a01b021a9c1e81fb4c5832aa9",
        "commit_title": "ima: fix add LSM rule bug",
        "commit_text": " If security_filter_rule_init() doesn't return a rule, then not everything is as fine as the return code implies.  This bug only occurs when the LSM (eg. SELinux) is disabled at runtime.  Adding an empty LSM rule causes ima_match_rules() to always succeed, ignoring any remaining rules.   default IMA TCB policy:   # PROC_SUPER_MAGIC   dont_measure fsmagic=0x9fa0   # SYSFS_MAGIC   dont_measure fsmagic=0x62656572   # DEBUGFS_MAGIC   dont_measure fsmagic=0x64626720   # TMPFS_MAGIC   dont_measure fsmagic=0x01021994   # SECURITYFS_MAGIC   dont_measure fsmagic=0x73636673    < LSM specific rule >   dont_measure obj_type=var_log_t    measure func=BPRM_CHECK   measure func=FILE_MMAP mask=MAY_EXEC   measure func=FILE_CHECK mask=MAY_READ uid=0  Thus without the patch, with the boot parameters 'tcb selinux=0', adding the above 'dont_measure obj_type=var_log_t' rule to the default IMA TCB measurement policy, would result in nothing being measured.  The patch prevents the default TCB policy from being replaced.  Cc: James Morris <jmorris@namei.org> Cc: David Safford <safford@watson.ibm.com> Cc: <stable@kernel.org>",
        "func_before": "static int ima_lsm_rule_init(struct ima_measure_rule_entry *entry,\n\t\t\t     char *args, int lsm_rule, int audit_type)\n{\n\tint result;\n\n\tif (entry->lsm[lsm_rule].rule)\n\t\treturn -EINVAL;\n\n\tentry->lsm[lsm_rule].type = audit_type;\n\tresult = security_filter_rule_init(entry->lsm[lsm_rule].type,\n\t\t\t\t\t   Audit_equal, args,\n\t\t\t\t\t   &entry->lsm[lsm_rule].rule);\n\treturn result;\n}",
        "func": "static int ima_lsm_rule_init(struct ima_measure_rule_entry *entry,\n\t\t\t     char *args, int lsm_rule, int audit_type)\n{\n\tint result;\n\n\tif (entry->lsm[lsm_rule].rule)\n\t\treturn -EINVAL;\n\n\tentry->lsm[lsm_rule].type = audit_type;\n\tresult = security_filter_rule_init(entry->lsm[lsm_rule].type,\n\t\t\t\t\t   Audit_equal, args,\n\t\t\t\t\t   &entry->lsm[lsm_rule].rule);\n\tif (!entry->lsm[lsm_rule].rule)\n\t\treturn -EINVAL;\n\treturn result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,5 +10,7 @@\n \tresult = security_filter_rule_init(entry->lsm[lsm_rule].type,\n \t\t\t\t\t   Audit_equal, args,\n \t\t\t\t\t   &entry->lsm[lsm_rule].rule);\n+\tif (!entry->lsm[lsm_rule].rule)\n+\t\treturn -EINVAL;\n \treturn result;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!entry->lsm[lsm_rule].rule)",
                "\t\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1021",
        "func_name": "torvalds/linux/acpi_debugfs_init",
        "description": "drivers/acpi/debugfs.c in the Linux kernel before 3.0 allows local users to modify arbitrary kernel memory locations by leveraging root privileges to write to the /sys/kernel/debug/acpi/custom_method file. NOTE: this vulnerability exists because of an incomplete fix for CVE-2010-4347.",
        "git_url": "https://github.com/torvalds/linux/commit/526b4af47f44148c9d665e57723ed9f86634c6e3",
        "commit_title": "ACPI: Split out custom_method functionality into an own driver",
        "commit_text": " With /sys/kernel/debug/acpi/custom_method root can write to arbitrary memory and increase his priveleges, even if these are restricted.  -> Make this an own debug .config option and warn about the security issue in the config description.  -> Still keep acpi/debugfs.c which now only creates an empty    /sys/kernel/debug/acpi directory. There might be other    users of it later. ",
        "func_before": "void __init acpi_debugfs_init(void)\n{\n\tacpi_debugfs_dir = debugfs_create_dir(\"acpi\", NULL);\n\n\tacpi_custom_method_init();\n}",
        "func": "void __init acpi_debugfs_init(void)\n{\n\tacpi_debugfs_dir = debugfs_create_dir(\"acpi\", NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,4 @@\n void __init acpi_debugfs_init(void)\n {\n \tacpi_debugfs_dir = debugfs_create_dir(\"acpi\", NULL);\n-\n-\tacpi_custom_method_init();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "\tacpi_custom_method_init();"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2011-1477",
        "func_name": "torvalds/linux/opl3_panning",
        "description": "Multiple array index errors in sound/oss/opl3.c in the Linux kernel before 2.6.39 allow local users to cause a denial of service (heap memory corruption) or possibly gain privileges by leveraging write access to /dev/sequencer.",
        "git_url": "https://github.com/torvalds/linux/commit/4d00135a680727f6c3be78f8befaac009030e4df",
        "commit_title": "sound/oss/opl3: validate voice and channel indexes",
        "commit_text": " User-controllable indexes for voice and channel values may cause reading and writing beyond the bounds of their respective arrays, leading to potentially exploitable memory corruption.  Validate these indexes.  Cc: stable@kernel.org",
        "func_before": "static void opl3_panning(int dev, int voice, int value)\n{\n\tdevc->voc[voice].panning = value;\n}",
        "func": "static void opl3_panning(int dev, int voice, int value)\n{\n\n\tif (voice < 0 || voice >= devc->nr_voice)\n\t\treturn;\n\n\tdevc->voc[voice].panning = value;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,8 @@\n static void opl3_panning(int dev, int voice, int value)\n {\n+\n+\tif (voice < 0 || voice >= devc->nr_voice)\n+\t\treturn;\n+\n \tdevc->voc[voice].panning = value;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (voice < 0 || voice >= devc->nr_voice)",
                "\t\treturn;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1477",
        "func_name": "torvalds/linux/opl3_setup_voice",
        "description": "Multiple array index errors in sound/oss/opl3.c in the Linux kernel before 2.6.39 allow local users to cause a denial of service (heap memory corruption) or possibly gain privileges by leveraging write access to /dev/sequencer.",
        "git_url": "https://github.com/torvalds/linux/commit/4d00135a680727f6c3be78f8befaac009030e4df",
        "commit_title": "sound/oss/opl3: validate voice and channel indexes",
        "commit_text": " User-controllable indexes for voice and channel values may cause reading and writing beyond the bounds of their respective arrays, leading to potentially exploitable memory corruption.  Validate these indexes.  Cc: stable@kernel.org",
        "func_before": "static void opl3_setup_voice(int dev, int voice, int chn)\n{\n\tstruct channel_info *info =\n\t&synth_devs[dev]->chn_info[chn];\n\n\topl3_set_instr(dev, voice, info->pgm_num);\n\n\tdevc->voc[voice].bender = 0;\n\tdevc->voc[voice].bender_range = info->bender_range;\n\tdevc->voc[voice].volume = info->controllers[CTL_MAIN_VOLUME];\n\tdevc->voc[voice].panning = (info->controllers[CTL_PAN] * 2) - 128;\n}",
        "func": "static void opl3_setup_voice(int dev, int voice, int chn)\n{\n\tstruct channel_info *info;\n\n\tif (voice < 0 || voice >= devc->nr_voice)\n\t\treturn;\n\n\tif (chn < 0 || chn > 15)\n\t\treturn;\n\n\tinfo = &synth_devs[dev]->chn_info[chn];\n\n\topl3_set_instr(dev, voice, info->pgm_num);\n\n\tdevc->voc[voice].bender = 0;\n\tdevc->voc[voice].bender_range = info->bender_range;\n\tdevc->voc[voice].volume = info->controllers[CTL_MAIN_VOLUME];\n\tdevc->voc[voice].panning = (info->controllers[CTL_PAN] * 2) - 128;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,14 @@\n static void opl3_setup_voice(int dev, int voice, int chn)\n {\n-\tstruct channel_info *info =\n-\t&synth_devs[dev]->chn_info[chn];\n+\tstruct channel_info *info;\n+\n+\tif (voice < 0 || voice >= devc->nr_voice)\n+\t\treturn;\n+\n+\tif (chn < 0 || chn > 15)\n+\t\treturn;\n+\n+\tinfo = &synth_devs[dev]->chn_info[chn];\n \n \topl3_set_instr(dev, voice, info->pgm_num);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct channel_info *info =",
                "\t&synth_devs[dev]->chn_info[chn];"
            ],
            "added_lines": [
                "\tstruct channel_info *info;",
                "",
                "\tif (voice < 0 || voice >= devc->nr_voice)",
                "\t\treturn;",
                "",
                "\tif (chn < 0 || chn > 15)",
                "\t\treturn;",
                "",
                "\tinfo = &synth_devs[dev]->chn_info[chn];"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0028",
        "func_name": "torvalds/linux/mm_release",
        "description": "The robust futex implementation in the Linux kernel before 2.6.28 does not properly handle processes that make exec system calls, which allows local users to cause a denial of service or possibly gain privileges by writing to a memory location in a child process.",
        "git_url": "https://github.com/torvalds/linux/commit/8141c7f3e7aee618312fa1c15109e1219de784a7",
        "commit_title": "Move \"exit_robust_list\" into mm_release()",
        "commit_text": " We don't want to get rid of the futexes just at exit() time, we want to drop them when doing an execve() too, since that gets rid of the previous VM image too.  Doing it at mm_release() time means that we automatically always do it when we disassociate a VM map from the task.  Cc: Andrew Morton <akpm@linux-foundation.org> Cc: Nick Piggin <npiggin@suse.de> Cc: Hugh Dickins <hugh@veritas.com> Cc: Ingo Molnar <mingo@elte.hu> Cc: Thomas Gleixner <tglx@linutronix.de> Cc: Brad Spengler <spender@grsecurity.net> Cc: Alex Efros <powerman@powerman.name> Cc: Peter Zijlstra <a.p.zijlstra@chello.nl> Cc: Oleg Nesterov <oleg@redhat.com>",
        "func_before": "void mm_release(struct task_struct *tsk, struct mm_struct *mm)\n{\n\tstruct completion *vfork_done = tsk->vfork_done;\n\n\t/* Get rid of any cached register state */\n\tdeactivate_mm(tsk, mm);\n\n\t/* notify parent sleeping on vfork() */\n\tif (vfork_done) {\n\t\ttsk->vfork_done = NULL;\n\t\tcomplete(vfork_done);\n\t}\n\n\t/*\n\t * If we're exiting normally, clear a user-space tid field if\n\t * requested.  We leave this alone when dying by signal, to leave\n\t * the value intact in a core dump, and to save the unnecessary\n\t * trouble otherwise.  Userland only wants this done for a sys_exit.\n\t */\n\tif (tsk->clear_child_tid\n\t    && !(tsk->flags & PF_SIGNALED)\n\t    && atomic_read(&mm->mm_users) > 1) {\n\t\tu32 __user * tidptr = tsk->clear_child_tid;\n\t\ttsk->clear_child_tid = NULL;\n\n\t\t/*\n\t\t * We don't check the error code - if userspace has\n\t\t * not set up a proper pointer then tough luck.\n\t\t */\n\t\tput_user(0, tidptr);\n\t\tsys_futex(tidptr, FUTEX_WAKE, 1, NULL, NULL, 0);\n\t}\n}",
        "func": "void mm_release(struct task_struct *tsk, struct mm_struct *mm)\n{\n\tstruct completion *vfork_done = tsk->vfork_done;\n\n\t/* Get rid of any futexes when releasing the mm */\n#ifdef CONFIG_FUTEX\n\tif (unlikely(tsk->robust_list))\n\t\texit_robust_list(tsk);\n#ifdef CONFIG_COMPAT\n\tif (unlikely(tsk->compat_robust_list))\n\t\tcompat_exit_robust_list(tsk);\n#endif\n#endif\n\n\t/* Get rid of any cached register state */\n\tdeactivate_mm(tsk, mm);\n\n\t/* notify parent sleeping on vfork() */\n\tif (vfork_done) {\n\t\ttsk->vfork_done = NULL;\n\t\tcomplete(vfork_done);\n\t}\n\n\t/*\n\t * If we're exiting normally, clear a user-space tid field if\n\t * requested.  We leave this alone when dying by signal, to leave\n\t * the value intact in a core dump, and to save the unnecessary\n\t * trouble otherwise.  Userland only wants this done for a sys_exit.\n\t */\n\tif (tsk->clear_child_tid\n\t    && !(tsk->flags & PF_SIGNALED)\n\t    && atomic_read(&mm->mm_users) > 1) {\n\t\tu32 __user * tidptr = tsk->clear_child_tid;\n\t\ttsk->clear_child_tid = NULL;\n\n\t\t/*\n\t\t * We don't check the error code - if userspace has\n\t\t * not set up a proper pointer then tough luck.\n\t\t */\n\t\tput_user(0, tidptr);\n\t\tsys_futex(tidptr, FUTEX_WAKE, 1, NULL, NULL, 0);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,16 @@\n void mm_release(struct task_struct *tsk, struct mm_struct *mm)\n {\n \tstruct completion *vfork_done = tsk->vfork_done;\n+\n+\t/* Get rid of any futexes when releasing the mm */\n+#ifdef CONFIG_FUTEX\n+\tif (unlikely(tsk->robust_list))\n+\t\texit_robust_list(tsk);\n+#ifdef CONFIG_COMPAT\n+\tif (unlikely(tsk->compat_robust_list))\n+\t\tcompat_exit_robust_list(tsk);\n+#endif\n+#endif\n \n \t/* Get rid of any cached register state */\n \tdeactivate_mm(tsk, mm);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* Get rid of any futexes when releasing the mm */",
                "#ifdef CONFIG_FUTEX",
                "\tif (unlikely(tsk->robust_list))",
                "\t\texit_robust_list(tsk);",
                "#ifdef CONFIG_COMPAT",
                "\tif (unlikely(tsk->compat_robust_list))",
                "\t\tcompat_exit_robust_list(tsk);",
                "#endif",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0028",
        "func_name": "torvalds/linux/do_exit",
        "description": "The robust futex implementation in the Linux kernel before 2.6.28 does not properly handle processes that make exec system calls, which allows local users to cause a denial of service or possibly gain privileges by writing to a memory location in a child process.",
        "git_url": "https://github.com/torvalds/linux/commit/8141c7f3e7aee618312fa1c15109e1219de784a7",
        "commit_title": "Move \"exit_robust_list\" into mm_release()",
        "commit_text": " We don't want to get rid of the futexes just at exit() time, we want to drop them when doing an execve() too, since that gets rid of the previous VM image too.  Doing it at mm_release() time means that we automatically always do it when we disassociate a VM map from the task.  Cc: Andrew Morton <akpm@linux-foundation.org> Cc: Nick Piggin <npiggin@suse.de> Cc: Hugh Dickins <hugh@veritas.com> Cc: Ingo Molnar <mingo@elte.hu> Cc: Thomas Gleixner <tglx@linutronix.de> Cc: Brad Spengler <spender@grsecurity.net> Cc: Alex Efros <powerman@powerman.name> Cc: Peter Zijlstra <a.p.zijlstra@chello.nl> Cc: Oleg Nesterov <oleg@redhat.com>",
        "func_before": "NORET_TYPE void do_exit(long code)\n{\n\tstruct task_struct *tsk = current;\n\tint group_dead;\n\n\tprofile_task_exit(tsk);\n\n\tWARN_ON(atomic_read(&tsk->fs_excl));\n\n\tif (unlikely(in_interrupt()))\n\t\tpanic(\"Aiee, killing interrupt handler!\");\n\tif (unlikely(!tsk->pid))\n\t\tpanic(\"Attempted to kill the idle task!\");\n\n\ttracehook_report_exit(&code);\n\n\t/*\n\t * We're taking recursive faults here in do_exit. Safest is to just\n\t * leave this task alone and wait for reboot.\n\t */\n\tif (unlikely(tsk->flags & PF_EXITING)) {\n\t\tprintk(KERN_ALERT\n\t\t\t\"Fixing recursive fault but reboot is needed!\\n\");\n\t\t/*\n\t\t * We can do this unlocked here. The futex code uses\n\t\t * this flag just to verify whether the pi state\n\t\t * cleanup has been done or not. In the worst case it\n\t\t * loops once more. We pretend that the cleanup was\n\t\t * done as there is no way to return. Either the\n\t\t * OWNER_DIED bit is set by now or we push the blocked\n\t\t * task into the wait for ever nirwana as well.\n\t\t */\n\t\ttsk->flags |= PF_EXITPIDONE;\n\t\tif (tsk->io_context)\n\t\t\texit_io_context();\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\tschedule();\n\t}\n\n\texit_signals(tsk);  /* sets PF_EXITING */\n\t/*\n\t * tsk->flags are checked in the futex code to protect against\n\t * an exiting task cleaning up the robust pi futexes.\n\t */\n\tsmp_mb();\n\tspin_unlock_wait(&tsk->pi_lock);\n\n\tif (unlikely(in_atomic()))\n\t\tprintk(KERN_INFO \"note: %s[%d] exited with preempt_count %d\\n\",\n\t\t\t\tcurrent->comm, task_pid_nr(current),\n\t\t\t\tpreempt_count());\n\n\tacct_update_integrals(tsk);\n\tif (tsk->mm) {\n\t\tupdate_hiwater_rss(tsk->mm);\n\t\tupdate_hiwater_vm(tsk->mm);\n\t}\n\tgroup_dead = atomic_dec_and_test(&tsk->signal->live);\n\tif (group_dead) {\n\t\thrtimer_cancel(&tsk->signal->real_timer);\n\t\texit_itimers(tsk->signal);\n\t}\n\tacct_collect(code, group_dead);\n#ifdef CONFIG_FUTEX\n\tif (unlikely(tsk->robust_list))\n\t\texit_robust_list(tsk);\n#ifdef CONFIG_COMPAT\n\tif (unlikely(tsk->compat_robust_list))\n\t\tcompat_exit_robust_list(tsk);\n#endif\n#endif\n\tif (group_dead)\n\t\ttty_audit_exit();\n\tif (unlikely(tsk->audit_context))\n\t\taudit_free(tsk);\n\n\ttsk->exit_code = code;\n\ttaskstats_exit(tsk, group_dead);\n\n\texit_mm(tsk);\n\n\tif (group_dead)\n\t\tacct_process();\n\ttrace_sched_process_exit(tsk);\n\n\texit_sem(tsk);\n\texit_files(tsk);\n\texit_fs(tsk);\n\tcheck_stack_usage();\n\texit_thread();\n\tcgroup_exit(tsk, 1);\n\texit_keys(tsk);\n\n\tif (group_dead && tsk->signal->leader)\n\t\tdisassociate_ctty(1);\n\n\tmodule_put(task_thread_info(tsk)->exec_domain->module);\n\tif (tsk->binfmt)\n\t\tmodule_put(tsk->binfmt->module);\n\n\tproc_exit_connector(tsk);\n\texit_notify(tsk, group_dead);\n#ifdef CONFIG_NUMA\n\tmpol_put(tsk->mempolicy);\n\ttsk->mempolicy = NULL;\n#endif\n#ifdef CONFIG_FUTEX\n\t/*\n\t * This must happen late, after the PID is not\n\t * hashed anymore:\n\t */\n\tif (unlikely(!list_empty(&tsk->pi_state_list)))\n\t\texit_pi_state_list(tsk);\n\tif (unlikely(current->pi_state_cache))\n\t\tkfree(current->pi_state_cache);\n#endif\n\t/*\n\t * Make sure we are holding no locks:\n\t */\n\tdebug_check_no_locks_held(tsk);\n\t/*\n\t * We can do this unlocked here. The futex code uses this flag\n\t * just to verify whether the pi state cleanup has been done\n\t * or not. In the worst case it loops once more.\n\t */\n\ttsk->flags |= PF_EXITPIDONE;\n\n\tif (tsk->io_context)\n\t\texit_io_context();\n\n\tif (tsk->splice_pipe)\n\t\t__free_pipe_info(tsk->splice_pipe);\n\n\tpreempt_disable();\n\t/* causes final put_task_struct in finish_task_switch(). */\n\ttsk->state = TASK_DEAD;\n\n\tschedule();\n\tBUG();\n\t/* Avoid \"noreturn function does return\".  */\n\tfor (;;)\n\t\tcpu_relax();\t/* For when BUG is null */\n}",
        "func": "NORET_TYPE void do_exit(long code)\n{\n\tstruct task_struct *tsk = current;\n\tint group_dead;\n\n\tprofile_task_exit(tsk);\n\n\tWARN_ON(atomic_read(&tsk->fs_excl));\n\n\tif (unlikely(in_interrupt()))\n\t\tpanic(\"Aiee, killing interrupt handler!\");\n\tif (unlikely(!tsk->pid))\n\t\tpanic(\"Attempted to kill the idle task!\");\n\n\ttracehook_report_exit(&code);\n\n\t/*\n\t * We're taking recursive faults here in do_exit. Safest is to just\n\t * leave this task alone and wait for reboot.\n\t */\n\tif (unlikely(tsk->flags & PF_EXITING)) {\n\t\tprintk(KERN_ALERT\n\t\t\t\"Fixing recursive fault but reboot is needed!\\n\");\n\t\t/*\n\t\t * We can do this unlocked here. The futex code uses\n\t\t * this flag just to verify whether the pi state\n\t\t * cleanup has been done or not. In the worst case it\n\t\t * loops once more. We pretend that the cleanup was\n\t\t * done as there is no way to return. Either the\n\t\t * OWNER_DIED bit is set by now or we push the blocked\n\t\t * task into the wait for ever nirwana as well.\n\t\t */\n\t\ttsk->flags |= PF_EXITPIDONE;\n\t\tif (tsk->io_context)\n\t\t\texit_io_context();\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\tschedule();\n\t}\n\n\texit_signals(tsk);  /* sets PF_EXITING */\n\t/*\n\t * tsk->flags are checked in the futex code to protect against\n\t * an exiting task cleaning up the robust pi futexes.\n\t */\n\tsmp_mb();\n\tspin_unlock_wait(&tsk->pi_lock);\n\n\tif (unlikely(in_atomic()))\n\t\tprintk(KERN_INFO \"note: %s[%d] exited with preempt_count %d\\n\",\n\t\t\t\tcurrent->comm, task_pid_nr(current),\n\t\t\t\tpreempt_count());\n\n\tacct_update_integrals(tsk);\n\tif (tsk->mm) {\n\t\tupdate_hiwater_rss(tsk->mm);\n\t\tupdate_hiwater_vm(tsk->mm);\n\t}\n\tgroup_dead = atomic_dec_and_test(&tsk->signal->live);\n\tif (group_dead) {\n\t\thrtimer_cancel(&tsk->signal->real_timer);\n\t\texit_itimers(tsk->signal);\n\t}\n\tacct_collect(code, group_dead);\n\tif (group_dead)\n\t\ttty_audit_exit();\n\tif (unlikely(tsk->audit_context))\n\t\taudit_free(tsk);\n\n\ttsk->exit_code = code;\n\ttaskstats_exit(tsk, group_dead);\n\n\texit_mm(tsk);\n\n\tif (group_dead)\n\t\tacct_process();\n\ttrace_sched_process_exit(tsk);\n\n\texit_sem(tsk);\n\texit_files(tsk);\n\texit_fs(tsk);\n\tcheck_stack_usage();\n\texit_thread();\n\tcgroup_exit(tsk, 1);\n\texit_keys(tsk);\n\n\tif (group_dead && tsk->signal->leader)\n\t\tdisassociate_ctty(1);\n\n\tmodule_put(task_thread_info(tsk)->exec_domain->module);\n\tif (tsk->binfmt)\n\t\tmodule_put(tsk->binfmt->module);\n\n\tproc_exit_connector(tsk);\n\texit_notify(tsk, group_dead);\n#ifdef CONFIG_NUMA\n\tmpol_put(tsk->mempolicy);\n\ttsk->mempolicy = NULL;\n#endif\n#ifdef CONFIG_FUTEX\n\t/*\n\t * This must happen late, after the PID is not\n\t * hashed anymore:\n\t */\n\tif (unlikely(!list_empty(&tsk->pi_state_list)))\n\t\texit_pi_state_list(tsk);\n\tif (unlikely(current->pi_state_cache))\n\t\tkfree(current->pi_state_cache);\n#endif\n\t/*\n\t * Make sure we are holding no locks:\n\t */\n\tdebug_check_no_locks_held(tsk);\n\t/*\n\t * We can do this unlocked here. The futex code uses this flag\n\t * just to verify whether the pi state cleanup has been done\n\t * or not. In the worst case it loops once more.\n\t */\n\ttsk->flags |= PF_EXITPIDONE;\n\n\tif (tsk->io_context)\n\t\texit_io_context();\n\n\tif (tsk->splice_pipe)\n\t\t__free_pipe_info(tsk->splice_pipe);\n\n\tpreempt_disable();\n\t/* causes final put_task_struct in finish_task_switch(). */\n\ttsk->state = TASK_DEAD;\n\n\tschedule();\n\tBUG();\n\t/* Avoid \"noreturn function does return\".  */\n\tfor (;;)\n\t\tcpu_relax();\t/* For when BUG is null */\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -61,14 +61,6 @@\n \t\texit_itimers(tsk->signal);\n \t}\n \tacct_collect(code, group_dead);\n-#ifdef CONFIG_FUTEX\n-\tif (unlikely(tsk->robust_list))\n-\t\texit_robust_list(tsk);\n-#ifdef CONFIG_COMPAT\n-\tif (unlikely(tsk->compat_robust_list))\n-\t\tcompat_exit_robust_list(tsk);\n-#endif\n-#endif\n \tif (group_dead)\n \t\ttty_audit_exit();\n \tif (unlikely(tsk->audit_context))",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef CONFIG_FUTEX",
                "\tif (unlikely(tsk->robust_list))",
                "\t\texit_robust_list(tsk);",
                "#ifdef CONFIG_COMPAT",
                "\tif (unlikely(tsk->compat_robust_list))",
                "\t\tcompat_exit_robust_list(tsk);",
                "#endif",
                "#endif"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2011-4127",
        "func_name": "torvalds/linux/linear_ioctl",
        "description": "The Linux kernel before 3.2.2 does not properly restrict SG_IO ioctl calls, which allows local users to bypass intended restrictions on disk read and write operations by sending a SCSI command to (1) a partition block device or (2) an LVM volume.",
        "git_url": "https://github.com/torvalds/linux/commit/ec8013beddd717d1740cfefb1a9b900deef85462",
        "commit_title": "dm: do not forward ioctls from logical volumes to the underlying device",
        "commit_text": " A logical volume can map to just part of underlying physical volume. In this case, it must be treated like a partition.  Based on a patch from Alasdair G Kergon.  Cc: Alasdair G Kergon <agk@redhat.com> Cc: dm-devel@redhat.com",
        "func_before": "static int linear_ioctl(struct dm_target *ti, unsigned int cmd,\n\t\t\tunsigned long arg)\n{\n\tstruct linear_c *lc = (struct linear_c *) ti->private;\n\treturn __blkdev_driver_ioctl(lc->dev->bdev, lc->dev->mode, cmd, arg);\n}",
        "func": "static int linear_ioctl(struct dm_target *ti, unsigned int cmd,\n\t\t\tunsigned long arg)\n{\n\tstruct linear_c *lc = (struct linear_c *) ti->private;\n\tstruct dm_dev *dev = lc->dev;\n\tint r = 0;\n\n\t/*\n\t * Only pass ioctls through if the device sizes match exactly.\n\t */\n\tif (lc->start ||\n\t    ti->len != i_size_read(dev->bdev->bd_inode) >> SECTOR_SHIFT)\n\t\tr = scsi_verify_blk_ioctl(NULL, cmd);\n\n\treturn r ? : __blkdev_driver_ioctl(dev->bdev, dev->mode, cmd, arg);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,15 @@\n \t\t\tunsigned long arg)\n {\n \tstruct linear_c *lc = (struct linear_c *) ti->private;\n-\treturn __blkdev_driver_ioctl(lc->dev->bdev, lc->dev->mode, cmd, arg);\n+\tstruct dm_dev *dev = lc->dev;\n+\tint r = 0;\n+\n+\t/*\n+\t * Only pass ioctls through if the device sizes match exactly.\n+\t */\n+\tif (lc->start ||\n+\t    ti->len != i_size_read(dev->bdev->bd_inode) >> SECTOR_SHIFT)\n+\t\tr = scsi_verify_blk_ioctl(NULL, cmd);\n+\n+\treturn r ? : __blkdev_driver_ioctl(dev->bdev, dev->mode, cmd, arg);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn __blkdev_driver_ioctl(lc->dev->bdev, lc->dev->mode, cmd, arg);"
            ],
            "added_lines": [
                "\tstruct dm_dev *dev = lc->dev;",
                "\tint r = 0;",
                "",
                "\t/*",
                "\t * Only pass ioctls through if the device sizes match exactly.",
                "\t */",
                "\tif (lc->start ||",
                "\t    ti->len != i_size_read(dev->bdev->bd_inode) >> SECTOR_SHIFT)",
                "\t\tr = scsi_verify_blk_ioctl(NULL, cmd);",
                "",
                "\treturn r ? : __blkdev_driver_ioctl(dev->bdev, dev->mode, cmd, arg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4127",
        "func_name": "torvalds/linux/flakey_ioctl",
        "description": "The Linux kernel before 3.2.2 does not properly restrict SG_IO ioctl calls, which allows local users to bypass intended restrictions on disk read and write operations by sending a SCSI command to (1) a partition block device or (2) an LVM volume.",
        "git_url": "https://github.com/torvalds/linux/commit/ec8013beddd717d1740cfefb1a9b900deef85462",
        "commit_title": "dm: do not forward ioctls from logical volumes to the underlying device",
        "commit_text": " A logical volume can map to just part of underlying physical volume. In this case, it must be treated like a partition.  Based on a patch from Alasdair G Kergon.  Cc: Alasdair G Kergon <agk@redhat.com> Cc: dm-devel@redhat.com",
        "func_before": "static int flakey_ioctl(struct dm_target *ti, unsigned int cmd, unsigned long arg)\n{\n\tstruct flakey_c *fc = ti->private;\n\n\treturn __blkdev_driver_ioctl(fc->dev->bdev, fc->dev->mode, cmd, arg);\n}",
        "func": "static int flakey_ioctl(struct dm_target *ti, unsigned int cmd, unsigned long arg)\n{\n\tstruct flakey_c *fc = ti->private;\n\tstruct dm_dev *dev = fc->dev;\n\tint r = 0;\n\n\t/*\n\t * Only pass ioctls through if the device sizes match exactly.\n\t */\n\tif (fc->start ||\n\t    ti->len != i_size_read(dev->bdev->bd_inode) >> SECTOR_SHIFT)\n\t\tr = scsi_verify_blk_ioctl(NULL, cmd);\n\n\treturn r ? : __blkdev_driver_ioctl(dev->bdev, dev->mode, cmd, arg);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,15 @@\n static int flakey_ioctl(struct dm_target *ti, unsigned int cmd, unsigned long arg)\n {\n \tstruct flakey_c *fc = ti->private;\n+\tstruct dm_dev *dev = fc->dev;\n+\tint r = 0;\n \n-\treturn __blkdev_driver_ioctl(fc->dev->bdev, fc->dev->mode, cmd, arg);\n+\t/*\n+\t * Only pass ioctls through if the device sizes match exactly.\n+\t */\n+\tif (fc->start ||\n+\t    ti->len != i_size_read(dev->bdev->bd_inode) >> SECTOR_SHIFT)\n+\t\tr = scsi_verify_blk_ioctl(NULL, cmd);\n+\n+\treturn r ? : __blkdev_driver_ioctl(dev->bdev, dev->mode, cmd, arg);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn __blkdev_driver_ioctl(fc->dev->bdev, fc->dev->mode, cmd, arg);"
            ],
            "added_lines": [
                "\tstruct dm_dev *dev = fc->dev;",
                "\tint r = 0;",
                "\t/*",
                "\t * Only pass ioctls through if the device sizes match exactly.",
                "\t */",
                "\tif (fc->start ||",
                "\t    ti->len != i_size_read(dev->bdev->bd_inode) >> SECTOR_SHIFT)",
                "\t\tr = scsi_verify_blk_ioctl(NULL, cmd);",
                "",
                "\treturn r ? : __blkdev_driver_ioctl(dev->bdev, dev->mode, cmd, arg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4127",
        "func_name": "torvalds/linux/multipath_ioctl",
        "description": "The Linux kernel before 3.2.2 does not properly restrict SG_IO ioctl calls, which allows local users to bypass intended restrictions on disk read and write operations by sending a SCSI command to (1) a partition block device or (2) an LVM volume.",
        "git_url": "https://github.com/torvalds/linux/commit/ec8013beddd717d1740cfefb1a9b900deef85462",
        "commit_title": "dm: do not forward ioctls from logical volumes to the underlying device",
        "commit_text": " A logical volume can map to just part of underlying physical volume. In this case, it must be treated like a partition.  Based on a patch from Alasdair G Kergon.  Cc: Alasdair G Kergon <agk@redhat.com> Cc: dm-devel@redhat.com",
        "func_before": "static int multipath_ioctl(struct dm_target *ti, unsigned int cmd,\n\t\t\t   unsigned long arg)\n{\n\tstruct multipath *m = (struct multipath *) ti->private;\n\tstruct block_device *bdev = NULL;\n\tfmode_t mode = 0;\n\tunsigned long flags;\n\tint r = 0;\n\n\tspin_lock_irqsave(&m->lock, flags);\n\n\tif (!m->current_pgpath)\n\t\t__choose_pgpath(m, 0);\n\n\tif (m->current_pgpath) {\n\t\tbdev = m->current_pgpath->path.dev->bdev;\n\t\tmode = m->current_pgpath->path.dev->mode;\n\t}\n\n\tif (m->queue_io)\n\t\tr = -EAGAIN;\n\telse if (!bdev)\n\t\tr = -EIO;\n\n\tspin_unlock_irqrestore(&m->lock, flags);\n\n\treturn r ? : __blkdev_driver_ioctl(bdev, mode, cmd, arg);\n}",
        "func": "static int multipath_ioctl(struct dm_target *ti, unsigned int cmd,\n\t\t\t   unsigned long arg)\n{\n\tstruct multipath *m = (struct multipath *) ti->private;\n\tstruct block_device *bdev = NULL;\n\tfmode_t mode = 0;\n\tunsigned long flags;\n\tint r = 0;\n\n\tspin_lock_irqsave(&m->lock, flags);\n\n\tif (!m->current_pgpath)\n\t\t__choose_pgpath(m, 0);\n\n\tif (m->current_pgpath) {\n\t\tbdev = m->current_pgpath->path.dev->bdev;\n\t\tmode = m->current_pgpath->path.dev->mode;\n\t}\n\n\tif (m->queue_io)\n\t\tr = -EAGAIN;\n\telse if (!bdev)\n\t\tr = -EIO;\n\n\tspin_unlock_irqrestore(&m->lock, flags);\n\n\t/*\n\t * Only pass ioctls through if the device sizes match exactly.\n\t */\n\tif (!r && ti->len != i_size_read(bdev->bd_inode) >> SECTOR_SHIFT)\n\t\tr = scsi_verify_blk_ioctl(NULL, cmd);\n\n\treturn r ? : __blkdev_driver_ioctl(bdev, mode, cmd, arg);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,5 +24,11 @@\n \n \tspin_unlock_irqrestore(&m->lock, flags);\n \n+\t/*\n+\t * Only pass ioctls through if the device sizes match exactly.\n+\t */\n+\tif (!r && ti->len != i_size_read(bdev->bd_inode) >> SECTOR_SHIFT)\n+\t\tr = scsi_verify_blk_ioctl(NULL, cmd);\n+\n \treturn r ? : __blkdev_driver_ioctl(bdev, mode, cmd, arg);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/*",
                "\t * Only pass ioctls through if the device sizes match exactly.",
                "\t */",
                "\tif (!r && ti->len != i_size_read(bdev->bd_inode) >> SECTOR_SHIFT)",
                "\t\tr = scsi_verify_blk_ioctl(NULL, cmd);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4127",
        "func_name": "torvalds/linux/scsi_cmd_blk_ioctl",
        "description": "The Linux kernel before 3.2.2 does not properly restrict SG_IO ioctl calls, which allows local users to bypass intended restrictions on disk read and write operations by sending a SCSI command to (1) a partition block device or (2) an LVM volume.",
        "git_url": "https://github.com/torvalds/linux/commit/0bfc96cb77224736dfa35c3c555d37b3646ef35e",
        "commit_title": "block: fail SCSI passthrough ioctls on partition devices",
        "commit_text": " Linux allows executing the SG_IO ioctl on a partition or LVM volume, and will pass the command to the underlying block device.  This is well-known, but it is also a large security problem when (via Unix permissions, ACLs, SELinux or a combination thereof) a program or user needs to be granted access only to part of the disk.  This patch lets partitions forward a small set of harmless ioctls; others are logged with printk so that we can see which ioctls are actually sent.  In my tests only CDROM_GET_CAPABILITY actually occurred. Of course it was being sent to a (partition on a) hard disk, so it would have failed with ENOTTY and the patch isn't changing anything in practice.  Still, I'm treating it specially to avoid spamming the logs.  In principle, this restriction should include programs running with CAP_SYS_RAWIO.  If for example I let a program access /dev/sda2 and /dev/sdb, it still should not be able to read/write outside the boundaries of /dev/sda2 independent of the capabilities.  However, for now programs with CAP_SYS_RAWIO will still be allowed to send the ioctls.  Their actions will still be logged.  This patch does not affect the non-libata IDE driver.  That driver however already tests for bd != bd->bd_contains before issuing some ioctl; it could be restricted further to forbid these ioctls even for programs running with CAP_SYS_ADMIN/CAP_SYS_RAWIO.  Cc: linux-scsi@vger.kernel.org Cc: Jens Axboe <axboe@kernel.dk> Cc: James Bottomley <JBottomley@parallels.com> [ Make it also print the command name when warning - Linus ]",
        "func_before": "int scsi_cmd_blk_ioctl(struct block_device *bd, fmode_t mode,\n\t\t       unsigned int cmd, void __user *arg)\n{\n\treturn scsi_cmd_ioctl(bd->bd_disk->queue, bd->bd_disk, mode, cmd, arg);\n}",
        "func": "int scsi_cmd_blk_ioctl(struct block_device *bd, fmode_t mode,\n\t\t       unsigned int cmd, void __user *arg)\n{\n\tint ret;\n\n\tret = scsi_verify_blk_ioctl(bd, cmd);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn scsi_cmd_ioctl(bd->bd_disk->queue, bd->bd_disk, mode, cmd, arg);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,11 @@\n int scsi_cmd_blk_ioctl(struct block_device *bd, fmode_t mode,\n \t\t       unsigned int cmd, void __user *arg)\n {\n+\tint ret;\n+\n+\tret = scsi_verify_blk_ioctl(bd, cmd);\n+\tif (ret < 0)\n+\t\treturn ret;\n+\n \treturn scsi_cmd_ioctl(bd->bd_disk->queue, bd->bd_disk, mode, cmd, arg);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tint ret;",
                "",
                "\tret = scsi_verify_blk_ioctl(bd, cmd);",
                "\tif (ret < 0)",
                "\t\treturn ret;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4127",
        "func_name": "torvalds/linux/sd_ioctl",
        "description": "The Linux kernel before 3.2.2 does not properly restrict SG_IO ioctl calls, which allows local users to bypass intended restrictions on disk read and write operations by sending a SCSI command to (1) a partition block device or (2) an LVM volume.",
        "git_url": "https://github.com/torvalds/linux/commit/0bfc96cb77224736dfa35c3c555d37b3646ef35e",
        "commit_title": "block: fail SCSI passthrough ioctls on partition devices",
        "commit_text": " Linux allows executing the SG_IO ioctl on a partition or LVM volume, and will pass the command to the underlying block device.  This is well-known, but it is also a large security problem when (via Unix permissions, ACLs, SELinux or a combination thereof) a program or user needs to be granted access only to part of the disk.  This patch lets partitions forward a small set of harmless ioctls; others are logged with printk so that we can see which ioctls are actually sent.  In my tests only CDROM_GET_CAPABILITY actually occurred. Of course it was being sent to a (partition on a) hard disk, so it would have failed with ENOTTY and the patch isn't changing anything in practice.  Still, I'm treating it specially to avoid spamming the logs.  In principle, this restriction should include programs running with CAP_SYS_RAWIO.  If for example I let a program access /dev/sda2 and /dev/sdb, it still should not be able to read/write outside the boundaries of /dev/sda2 independent of the capabilities.  However, for now programs with CAP_SYS_RAWIO will still be allowed to send the ioctls.  Their actions will still be logged.  This patch does not affect the non-libata IDE driver.  That driver however already tests for bd != bd->bd_contains before issuing some ioctl; it could be restricted further to forbid these ioctls even for programs running with CAP_SYS_ADMIN/CAP_SYS_RAWIO.  Cc: linux-scsi@vger.kernel.org Cc: Jens Axboe <axboe@kernel.dk> Cc: James Bottomley <JBottomley@parallels.com> [ Make it also print the command name when warning - Linus ]",
        "func_before": "static int sd_ioctl(struct block_device *bdev, fmode_t mode,\n\t\t    unsigned int cmd, unsigned long arg)\n{\n\tstruct gendisk *disk = bdev->bd_disk;\n\tstruct scsi_disk *sdkp = scsi_disk(disk);\n\tstruct scsi_device *sdp = sdkp->device;\n\tvoid __user *p = (void __user *)arg;\n\tint error;\n    \n\tSCSI_LOG_IOCTL(1, sd_printk(KERN_INFO, sdkp, \"sd_ioctl: disk=%s, \"\n\t\t\t\t    \"cmd=0x%x\\n\", disk->disk_name, cmd));\n\n\t/*\n\t * If we are in the middle of error recovery, don't let anyone\n\t * else try and use this device.  Also, if error recovery fails, it\n\t * may try and take the device offline, in which case all further\n\t * access to the device is prohibited.\n\t */\n\terror = scsi_nonblockable_ioctl(sdp, cmd, p,\n\t\t\t\t\t(mode & FMODE_NDELAY) != 0);\n\tif (!scsi_block_when_processing_errors(sdp) || !error)\n\t\tgoto out;\n\n\t/*\n\t * Send SCSI addressing ioctls directly to mid level, send other\n\t * ioctls to block level and then onto mid level if they can't be\n\t * resolved.\n\t */\n\tswitch (cmd) {\n\t\tcase SCSI_IOCTL_GET_IDLUN:\n\t\tcase SCSI_IOCTL_GET_BUS_NUMBER:\n\t\t\terror = scsi_ioctl(sdp, cmd, p);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terror = scsi_cmd_blk_ioctl(bdev, mode, cmd, p);\n\t\t\tif (error != -ENOTTY)\n\t\t\t\tbreak;\n\t\t\terror = scsi_ioctl(sdp, cmd, p);\n\t\t\tbreak;\n\t}\nout:\n\treturn error;\n}",
        "func": "static int sd_ioctl(struct block_device *bdev, fmode_t mode,\n\t\t    unsigned int cmd, unsigned long arg)\n{\n\tstruct gendisk *disk = bdev->bd_disk;\n\tstruct scsi_disk *sdkp = scsi_disk(disk);\n\tstruct scsi_device *sdp = sdkp->device;\n\tvoid __user *p = (void __user *)arg;\n\tint error;\n    \n\tSCSI_LOG_IOCTL(1, sd_printk(KERN_INFO, sdkp, \"sd_ioctl: disk=%s, \"\n\t\t\t\t    \"cmd=0x%x\\n\", disk->disk_name, cmd));\n\n\terror = scsi_verify_blk_ioctl(bdev, cmd);\n\tif (error < 0)\n\t\treturn error;\n\n\t/*\n\t * If we are in the middle of error recovery, don't let anyone\n\t * else try and use this device.  Also, if error recovery fails, it\n\t * may try and take the device offline, in which case all further\n\t * access to the device is prohibited.\n\t */\n\terror = scsi_nonblockable_ioctl(sdp, cmd, p,\n\t\t\t\t\t(mode & FMODE_NDELAY) != 0);\n\tif (!scsi_block_when_processing_errors(sdp) || !error)\n\t\tgoto out;\n\n\t/*\n\t * Send SCSI addressing ioctls directly to mid level, send other\n\t * ioctls to block level and then onto mid level if they can't be\n\t * resolved.\n\t */\n\tswitch (cmd) {\n\t\tcase SCSI_IOCTL_GET_IDLUN:\n\t\tcase SCSI_IOCTL_GET_BUS_NUMBER:\n\t\t\terror = scsi_ioctl(sdp, cmd, p);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\terror = scsi_cmd_blk_ioctl(bdev, mode, cmd, p);\n\t\t\tif (error != -ENOTTY)\n\t\t\t\tbreak;\n\t\t\terror = scsi_ioctl(sdp, cmd, p);\n\t\t\tbreak;\n\t}\nout:\n\treturn error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,10 @@\n     \n \tSCSI_LOG_IOCTL(1, sd_printk(KERN_INFO, sdkp, \"sd_ioctl: disk=%s, \"\n \t\t\t\t    \"cmd=0x%x\\n\", disk->disk_name, cmd));\n+\n+\terror = scsi_verify_blk_ioctl(bdev, cmd);\n+\tif (error < 0)\n+\t\treturn error;\n \n \t/*\n \t * If we are in the middle of error recovery, don't let anyone",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\terror = scsi_verify_blk_ioctl(bdev, cmd);",
                "\tif (error < 0)",
                "\t\treturn error;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4127",
        "func_name": "torvalds/linux/sd_compat_ioctl",
        "description": "The Linux kernel before 3.2.2 does not properly restrict SG_IO ioctl calls, which allows local users to bypass intended restrictions on disk read and write operations by sending a SCSI command to (1) a partition block device or (2) an LVM volume.",
        "git_url": "https://github.com/torvalds/linux/commit/0bfc96cb77224736dfa35c3c555d37b3646ef35e",
        "commit_title": "block: fail SCSI passthrough ioctls on partition devices",
        "commit_text": " Linux allows executing the SG_IO ioctl on a partition or LVM volume, and will pass the command to the underlying block device.  This is well-known, but it is also a large security problem when (via Unix permissions, ACLs, SELinux or a combination thereof) a program or user needs to be granted access only to part of the disk.  This patch lets partitions forward a small set of harmless ioctls; others are logged with printk so that we can see which ioctls are actually sent.  In my tests only CDROM_GET_CAPABILITY actually occurred. Of course it was being sent to a (partition on a) hard disk, so it would have failed with ENOTTY and the patch isn't changing anything in practice.  Still, I'm treating it specially to avoid spamming the logs.  In principle, this restriction should include programs running with CAP_SYS_RAWIO.  If for example I let a program access /dev/sda2 and /dev/sdb, it still should not be able to read/write outside the boundaries of /dev/sda2 independent of the capabilities.  However, for now programs with CAP_SYS_RAWIO will still be allowed to send the ioctls.  Their actions will still be logged.  This patch does not affect the non-libata IDE driver.  That driver however already tests for bd != bd->bd_contains before issuing some ioctl; it could be restricted further to forbid these ioctls even for programs running with CAP_SYS_ADMIN/CAP_SYS_RAWIO.  Cc: linux-scsi@vger.kernel.org Cc: Jens Axboe <axboe@kernel.dk> Cc: James Bottomley <JBottomley@parallels.com> [ Make it also print the command name when warning - Linus ]",
        "func_before": "static int sd_compat_ioctl(struct block_device *bdev, fmode_t mode,\n\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\tstruct scsi_device *sdev = scsi_disk(bdev->bd_disk)->device;\n\n\t/*\n\t * If we are in the middle of error recovery, don't let anyone\n\t * else try and use this device.  Also, if error recovery fails, it\n\t * may try and take the device offline, in which case all further\n\t * access to the device is prohibited.\n\t */\n\tif (!scsi_block_when_processing_errors(sdev))\n\t\treturn -ENODEV;\n\t       \n\tif (sdev->host->hostt->compat_ioctl) {\n\t\tint ret;\n\n\t\tret = sdev->host->hostt->compat_ioctl(sdev, cmd, (void __user *)arg);\n\n\t\treturn ret;\n\t}\n\n\t/* \n\t * Let the static ioctl translation table take care of it.\n\t */\n\treturn -ENOIOCTLCMD; \n}",
        "func": "static int sd_compat_ioctl(struct block_device *bdev, fmode_t mode,\n\t\t\t   unsigned int cmd, unsigned long arg)\n{\n\tstruct scsi_device *sdev = scsi_disk(bdev->bd_disk)->device;\n\tint ret;\n\n\tret = scsi_verify_blk_ioctl(bdev, cmd);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/*\n\t * If we are in the middle of error recovery, don't let anyone\n\t * else try and use this device.  Also, if error recovery fails, it\n\t * may try and take the device offline, in which case all further\n\t * access to the device is prohibited.\n\t */\n\tif (!scsi_block_when_processing_errors(sdev))\n\t\treturn -ENODEV;\n\t       \n\tif (sdev->host->hostt->compat_ioctl) {\n\t\tret = sdev->host->hostt->compat_ioctl(sdev, cmd, (void __user *)arg);\n\n\t\treturn ret;\n\t}\n\n\t/* \n\t * Let the static ioctl translation table take care of it.\n\t */\n\treturn -ENOIOCTLCMD; \n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,11 @@\n \t\t\t   unsigned int cmd, unsigned long arg)\n {\n \tstruct scsi_device *sdev = scsi_disk(bdev->bd_disk)->device;\n+\tint ret;\n+\n+\tret = scsi_verify_blk_ioctl(bdev, cmd);\n+\tif (ret < 0)\n+\t\treturn ret;\n \n \t/*\n \t * If we are in the middle of error recovery, don't let anyone\n@@ -13,8 +18,6 @@\n \t\treturn -ENODEV;\n \t       \n \tif (sdev->host->hostt->compat_ioctl) {\n-\t\tint ret;\n-\n \t\tret = sdev->host->hostt->compat_ioctl(sdev, cmd, (void __user *)arg);\n \n \t\treturn ret;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tint ret;",
                ""
            ],
            "added_lines": [
                "\tint ret;",
                "",
                "\tret = scsi_verify_blk_ioctl(bdev, cmd);",
                "\tif (ret < 0)",
                "\t\treturn ret;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2760",
        "func_name": "bmuller/mod_auth_openid/get_request_params",
        "description": "mod_auth_openid before 0.7 for Apache uses world-readable permissions for /tmp/mod_auth_openid.db, which allows local users to obtain session ids.",
        "git_url": "https://github.com/bmuller/mod_auth_openid/commit/b7d6ce77b5469083ee80d578693273e5fe618c83",
        "commit_title": "fix invalid_nonce for long URLs",
        "commit_text": "",
        "func_before": "void get_request_params(request_rec *r, params_t& params) {\n    string query;\n    if(r->method_number == M_GET && r->args != NULL) {\n      debug(\"Request GET params: \" + string(r->args));\n      params = parse_query_string(string(r->args));\n    } else if(r->method_number == M_POST && get_post_data(r, query)) {\n      debug(\"Request POST params: \" + query);\n      params = parse_query_string(query);\n    }\n  }",
        "func": "void get_request_params(request_rec *r, params_t& params) {\n    string query;\n    if(r->method_number == M_GET && r->args != NULL) {\n      debug(\"Request GET params: \" + string(r->args));\n      params = parse_query_string(string(r->args));\n    } else if(r->method_number == M_POST && get_post_data(r, query)) {\n      debug(\"Request POST params: \" + query);\n      params = parse_query_string(query);\n      if (r->args != NULL) {\n        params_t get_params;\n        get_params = parse_query_string(string(r->args));\n        merge_params(get_params, params);\n      }\n    }\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,5 +6,10 @@\n     } else if(r->method_number == M_POST && get_post_data(r, query)) {\n       debug(\"Request POST params: \" + query);\n       params = parse_query_string(query);\n+      if (r->args != NULL) {\n+        params_t get_params;\n+        get_params = parse_query_string(string(r->args));\n+        merge_params(get_params, params);\n+      }\n     }\n   }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      if (r->args != NULL) {",
                "        params_t get_params;",
                "        get_params = parse_query_string(string(r->args));",
                "        merge_params(get_params, params);",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0523",
        "func_name": "gypsy/gypsy_server_create",
        "description": "gypsy 0.8 does not properly restrict the files that can be read while running with root privileges, which allows local users to read otherwise restricted files via unspecified vectors.",
        "git_url": "http://cgit.freedesktop.org/gypsy/commit/?id=40101707cddb319481133b2a137294b6b669bd16",
        "commit_title": "Fixes part of 33431",
        "commit_text": "",
        "func_before": "static void\ngypsy_server_create (GypsyServer           *gps,\n\t\t     const char            *IN_device_path,\n\t\t     DBusGMethodInvocation *context)\n{\n\tGypsyServerPrivate *priv;\n\tGypsyClient *client;\n\tchar *path, *device_name, *sender;\n\tGList *list;\n\n\tpriv = GET_PRIVATE (gps);\n\n\t/* We might be in the termination timeout when we receive a new\n\t   create request, so cancel that timeout */\n\tif (priv->terminate_id > 0) {\n\t\tg_source_remove (priv->terminate_id);\n\t\tpriv->terminate_id = 0;\n\t}\n\n\tGYPSY_NOTE (SERVER, \"Creating client for %s\", IN_device_path);\n\tdevice_name = g_path_get_basename (IN_device_path);\n\tGYPSY_NOTE (SERVER, \"Device name: %s\", device_name);\n\tpath = g_strdup_printf (\"%s%s\", GYPSY_GPS_PATH, \n\t\t\t\tg_strdelimit (device_name, \":\", '_'));\n\tg_free (device_name);\n\n\tclient = (GypsyClient *) dbus_g_connection_lookup_g_object (priv->connection, path);\n\tif (client == NULL) {\n\t\t/* If there isn't already an object registered on that path\n\t\t   create and register it */\n\t\tclient = g_object_new (GYPSY_TYPE_CLIENT, \n\t\t\t\t       \"device_path\", IN_device_path,\n\t\t\t\t       NULL);\n\t\n\t\tdbus_g_connection_register_g_object (priv->connection, path,\n\t\t\t\t\t\t     G_OBJECT (client));\n\t} else {\n\t\t/* Ref the client so that when one client calls shutdown\n\t\t   we won't destroy another clients object */\n\t\tg_object_ref (client);\n\t}\n\n\tGYPSY_NOTE (SERVER, \"Registered client on %s\", path);\n\n\t/* Update the hash of open connnctions */\n\tsender = dbus_g_method_get_sender (context);\n\tlist = g_hash_table_lookup (priv->connections, sender);\n\tlist = g_list_prepend (list, client);\n\tg_hash_table_insert (priv->connections, sender, list);\n\n\tpriv->client_count++;\n\n\tdbus_g_method_return (context, path);\n\tg_free (path);\n}",
        "func": "static void\ngypsy_server_create (GypsyServer           *gps,\n\t\t     const char            *IN_device_path,\n\t\t     DBusGMethodInvocation *context)\n{\n\tGypsyServerPrivate *priv;\n\tGypsyClient *client;\n\tchar *path, *device_name, *sender;\n\tGList *list;\n\tint i;\n\tgboolean allowed;\n\n\tpriv = GET_PRIVATE (gps);\n\n\t/* We might be in the termination timeout when we receive a new\n\t   create request, so cancel that timeout */\n\tif (priv->terminate_id > 0) {\n\t\tg_source_remove (priv->terminate_id);\n\t\tpriv->terminate_id = 0;\n\t}\n\n\tGYPSY_NOTE (SERVER, \"Creating client for %s\", IN_device_path);\n\n\t/* compare priv->device_path to allowed globs\n\t * if not allowed, error out */\n\tallowed = FALSE;\n\tfor (i = 0; i < priv->allowed_device_glob_count; i++) {\n\t\tif (g_str_equal (priv->allowed_device_globs[i], \"bluetooth\")) {\n#ifdef HAVE_BLUEZ\n\t\t\tif (bachk (IN_device_path) == 0) {\n\t\t\t\tallowed = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n#else\n\t\t\tcontinue;\n#endif /* HAVE_BLUEZ */\n\t\t}\n\t\tif (g_pattern_match_simple (priv->allowed_device_globs[i],\n\t\t\t\t\t    IN_device_path)) {\n\t\t\tallowed = TRUE;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (allowed == FALSE) {\n\t\tg_warning (\"The device path %s is not allowed by config file\",\n\t\t\t   IN_device_path);\n\t\tGError *error = NULL;\n\t\terror = g_error_new (GYPSY_SERVER_ERROR,\n\t\t\t\t     GYPSY_SERVER_ERROR_BAD_PATH,\n\t\t\t\t     \"Bad path: %s\",\n\t\t\t\t     IN_device_path);\n\t\tdbus_g_method_return_error (context, error);\n\t\tg_error_free (error);\n\t\treturn;\n\t}\n\n\tdevice_name = g_path_get_basename (IN_device_path);\n\tGYPSY_NOTE (SERVER, \"Device name: %s\", device_name);\n\tpath = g_strdup_printf (\"%s%s\", GYPSY_GPS_PATH, \n\t\t\t\tg_strdelimit (device_name, \":\", '_'));\n\tg_free (device_name);\n\n\tclient = (GypsyClient *) dbus_g_connection_lookup_g_object (priv->connection, path);\n\tif (client == NULL) {\n\t\t/* If there isn't already an object registered on that path\n\t\t   create and register it */\n\t\tclient = g_object_new (GYPSY_TYPE_CLIENT, \n\t\t\t\t       \"device_path\", IN_device_path,\n\t\t\t\t       NULL);\n\t\n\t\tdbus_g_connection_register_g_object (priv->connection, path,\n\t\t\t\t\t\t     G_OBJECT (client));\n\t} else {\n\t\t/* Ref the client so that when one client calls shutdown\n\t\t   we won't destroy another clients object */\n\t\tg_object_ref (client);\n\t}\n\n\tGYPSY_NOTE (SERVER, \"Registered client on %s\", path);\n\n\t/* Update the hash of open connnctions */\n\tsender = dbus_g_method_get_sender (context);\n\tlist = g_hash_table_lookup (priv->connections, sender);\n\tlist = g_list_prepend (list, client);\n\tg_hash_table_insert (priv->connections, sender, list);\n\n\tpriv->client_count++;\n\n\tdbus_g_method_return (context, path);\n\tg_free (path);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,8 @@\n \tGypsyClient *client;\n \tchar *path, *device_name, *sender;\n \tGList *list;\n+\tint i;\n+\tgboolean allowed;\n \n \tpriv = GET_PRIVATE (gps);\n \n@@ -18,6 +20,40 @@\n \t}\n \n \tGYPSY_NOTE (SERVER, \"Creating client for %s\", IN_device_path);\n+\n+\t/* compare priv->device_path to allowed globs\n+\t * if not allowed, error out */\n+\tallowed = FALSE;\n+\tfor (i = 0; i < priv->allowed_device_glob_count; i++) {\n+\t\tif (g_str_equal (priv->allowed_device_globs[i], \"bluetooth\")) {\n+#ifdef HAVE_BLUEZ\n+\t\t\tif (bachk (IN_device_path) == 0) {\n+\t\t\t\tallowed = TRUE;\n+\t\t\t\tbreak;\n+\t\t\t}\n+#else\n+\t\t\tcontinue;\n+#endif /* HAVE_BLUEZ */\n+\t\t}\n+\t\tif (g_pattern_match_simple (priv->allowed_device_globs[i],\n+\t\t\t\t\t    IN_device_path)) {\n+\t\t\tallowed = TRUE;\n+\t\t\tbreak;\n+\t\t}\n+\t}\n+\tif (allowed == FALSE) {\n+\t\tg_warning (\"The device path %s is not allowed by config file\",\n+\t\t\t   IN_device_path);\n+\t\tGError *error = NULL;\n+\t\terror = g_error_new (GYPSY_SERVER_ERROR,\n+\t\t\t\t     GYPSY_SERVER_ERROR_BAD_PATH,\n+\t\t\t\t     \"Bad path: %s\",\n+\t\t\t\t     IN_device_path);\n+\t\tdbus_g_method_return_error (context, error);\n+\t\tg_error_free (error);\n+\t\treturn;\n+\t}\n+\n \tdevice_name = g_path_get_basename (IN_device_path);\n \tGYPSY_NOTE (SERVER, \"Device name: %s\", device_name);\n \tpath = g_strdup_printf (\"%s%s\", GYPSY_GPS_PATH, ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tint i;",
                "\tgboolean allowed;",
                "",
                "\t/* compare priv->device_path to allowed globs",
                "\t * if not allowed, error out */",
                "\tallowed = FALSE;",
                "\tfor (i = 0; i < priv->allowed_device_glob_count; i++) {",
                "\t\tif (g_str_equal (priv->allowed_device_globs[i], \"bluetooth\")) {",
                "#ifdef HAVE_BLUEZ",
                "\t\t\tif (bachk (IN_device_path) == 0) {",
                "\t\t\t\tallowed = TRUE;",
                "\t\t\t\tbreak;",
                "\t\t\t}",
                "#else",
                "\t\t\tcontinue;",
                "#endif /* HAVE_BLUEZ */",
                "\t\t}",
                "\t\tif (g_pattern_match_simple (priv->allowed_device_globs[i],",
                "\t\t\t\t\t    IN_device_path)) {",
                "\t\t\tallowed = TRUE;",
                "\t\t\tbreak;",
                "\t\t}",
                "\t}",
                "\tif (allowed == FALSE) {",
                "\t\tg_warning (\"The device path %s is not allowed by config file\",",
                "\t\t\t   IN_device_path);",
                "\t\tGError *error = NULL;",
                "\t\terror = g_error_new (GYPSY_SERVER_ERROR,",
                "\t\t\t\t     GYPSY_SERVER_ERROR_BAD_PATH,",
                "\t\t\t\t     \"Bad path: %s\",",
                "\t\t\t\t     IN_device_path);",
                "\t\tdbus_g_method_return_error (context, error);",
                "\t\tg_error_free (error);",
                "\t\treturn;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0523",
        "func_name": "gypsy/gypsy_server_init",
        "description": "gypsy 0.8 does not properly restrict the files that can be read while running with root privileges, which allows local users to read otherwise restricted files via unspecified vectors.",
        "git_url": "http://cgit.freedesktop.org/gypsy/commit/?id=40101707cddb319481133b2a137294b6b669bd16",
        "commit_title": "Fixes part of 33431",
        "commit_text": "",
        "func_before": "static void\ngypsy_server_init (GypsyServer *gps)\n{\n\tGypsyServerPrivate *priv = GET_PRIVATE (gps);\n\tGError *error = NULL;\n\n\tpriv->connection = dbus_g_bus_get (DBUS_BUS_SYSTEM, &error);\n\tif (priv->connection == NULL) {\n\t\tg_warning (\"Error connecting to system bus:\\n%s\",\n\t\t\t   error->message);\n\t\tg_error_free (error);\n\t\treturn;\n\t}\n\tdbus_g_connection_ref (priv->connection);\n\n\tpriv->connections = g_hash_table_new_full (g_str_hash, g_str_equal,\n\t\t\t\t\t\t   g_free, NULL);\n\n\tpriv->client_count = 0;\n\tpriv->terminate_id = 0;\n}",
        "func": "static void\ngypsy_server_init (GypsyServer *gps)\n{\n\tGypsyServerPrivate *priv = GET_PRIVATE (gps);\n\tGError *error = NULL;\n\tGKeyFile *key_file = NULL;\n\n\tpriv->connection = dbus_g_bus_get (DBUS_BUS_SYSTEM, &error);\n\tif (priv->connection == NULL) {\n\t\tg_warning (\"Error connecting to system bus:\\n%s\",\n\t\t\t   error->message);\n\t\tg_error_free (error);\n\t\treturn;\n\t}\n\tdbus_g_connection_ref (priv->connection);\n\n\tpriv->connections = g_hash_table_new_full (g_str_hash, g_str_equal,\n\t\t\t\t\t\t   g_free, NULL);\n\n\tpriv->client_count = 0;\n\tpriv->terminate_id = 0;\n\n\tkey_file = g_key_file_new();\n\tif (!g_key_file_load_from_file (key_file, CONFIG_FILE_PATH,\n\t\t\t\t       G_KEY_FILE_NONE, &error))\n\t\tgoto error;\n\n\tpriv->allowed_device_globs = g_key_file_get_string_list (key_file,\n\t\t\t\t\t\t\t\t GYPSY_CONF_GROUP,\n\t\t\t\t\t\t\t\t GYPSY_CONF_GLOB_KEY,\n\t\t\t\t\t\t\t\t &(priv->allowed_device_glob_count),\n\t\t\t\t\t\t\t\t &error);\n\tif (!priv->allowed_device_globs)\n\t\tgoto error;\n\n\treturn;\n\nerror:\n\tg_warning (\"Error parsing config file:\\n%s\",\n\t\t   error->message);\n\tg_error_free (error);\n\tg_key_file_free (key_file);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,7 @@\n {\n \tGypsyServerPrivate *priv = GET_PRIVATE (gps);\n \tGError *error = NULL;\n+\tGKeyFile *key_file = NULL;\n \n \tpriv->connection = dbus_g_bus_get (DBUS_BUS_SYSTEM, &error);\n \tif (priv->connection == NULL) {\n@@ -18,4 +19,25 @@\n \n \tpriv->client_count = 0;\n \tpriv->terminate_id = 0;\n+\n+\tkey_file = g_key_file_new();\n+\tif (!g_key_file_load_from_file (key_file, CONFIG_FILE_PATH,\n+\t\t\t\t       G_KEY_FILE_NONE, &error))\n+\t\tgoto error;\n+\n+\tpriv->allowed_device_globs = g_key_file_get_string_list (key_file,\n+\t\t\t\t\t\t\t\t GYPSY_CONF_GROUP,\n+\t\t\t\t\t\t\t\t GYPSY_CONF_GLOB_KEY,\n+\t\t\t\t\t\t\t\t &(priv->allowed_device_glob_count),\n+\t\t\t\t\t\t\t\t &error);\n+\tif (!priv->allowed_device_globs)\n+\t\tgoto error;\n+\n+\treturn;\n+\n+error:\n+\tg_warning (\"Error parsing config file:\\n%s\",\n+\t\t   error->message);\n+\tg_error_free (error);\n+\tg_key_file_free (key_file);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tGKeyFile *key_file = NULL;",
                "",
                "\tkey_file = g_key_file_new();",
                "\tif (!g_key_file_load_from_file (key_file, CONFIG_FILE_PATH,",
                "\t\t\t\t       G_KEY_FILE_NONE, &error))",
                "\t\tgoto error;",
                "",
                "\tpriv->allowed_device_globs = g_key_file_get_string_list (key_file,",
                "\t\t\t\t\t\t\t\t GYPSY_CONF_GROUP,",
                "\t\t\t\t\t\t\t\t GYPSY_CONF_GLOB_KEY,",
                "\t\t\t\t\t\t\t\t &(priv->allowed_device_glob_count),",
                "\t\t\t\t\t\t\t\t &error);",
                "\tif (!priv->allowed_device_globs)",
                "\t\tgoto error;",
                "",
                "\treturn;",
                "",
                "error:",
                "\tg_warning (\"Error parsing config file:\\n%s\",",
                "\t\t   error->message);",
                "\tg_error_free (error);",
                "\tg_key_file_free (key_file);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1833",
        "func_name": "torvalds/linux/ecryptfs_mount",
        "description": "Race condition in the ecryptfs_mount function in fs/ecryptfs/main.c in the eCryptfs subsystem in the Linux kernel before 3.1 allows local users to bypass intended file permissions via a mount.ecryptfs_private mount with a mismatched uid.",
        "git_url": "https://github.com/torvalds/linux/commit/764355487ea220fdc2faf128d577d7f679b91f97",
        "commit_title": "Ecryptfs: Add mount option to check uid of device being mounted = expect uid",
        "commit_text": " Close a TOCTOU race for mounts done via ecryptfs-mount-private.  The mount source (device) can be raced when the ownership test is done in userspace. Provide Ecryptfs a means to force the uid check at mount time.  Cc: <stable@kernel.org>",
        "func_before": "static struct dentry *ecryptfs_mount(struct file_system_type *fs_type, int flags,\n\t\t\tconst char *dev_name, void *raw_data)\n{\n\tstruct super_block *s;\n\tstruct ecryptfs_sb_info *sbi;\n\tstruct ecryptfs_dentry_info *root_info;\n\tconst char *err = \"Getting sb failed\";\n\tstruct inode *inode;\n\tstruct path path;\n\tint rc;\n\n\tsbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);\n\tif (!sbi) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trc = ecryptfs_parse_options(sbi, raw_data);\n\tif (rc) {\n\t\terr = \"Error parsing options\";\n\t\tgoto out;\n\t}\n\n\ts = sget(fs_type, NULL, set_anon_super, NULL);\n\tif (IS_ERR(s)) {\n\t\trc = PTR_ERR(s);\n\t\tgoto out;\n\t}\n\n\ts->s_flags = flags;\n\trc = bdi_setup_and_register(&sbi->bdi, \"ecryptfs\", BDI_CAP_MAP_COPY);\n\tif (rc)\n\t\tgoto out1;\n\n\tecryptfs_set_superblock_private(s, sbi);\n\ts->s_bdi = &sbi->bdi;\n\n\t/* ->kill_sb() will take care of sbi after that point */\n\tsbi = NULL;\n\ts->s_op = &ecryptfs_sops;\n\ts->s_d_op = &ecryptfs_dops;\n\n\terr = \"Reading sb failed\";\n\trc = kern_path(dev_name, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &path);\n\tif (rc) {\n\t\tecryptfs_printk(KERN_WARNING, \"kern_path() failed\\n\");\n\t\tgoto out1;\n\t}\n\tif (path.dentry->d_sb->s_type == &ecryptfs_fs_type) {\n\t\trc = -EINVAL;\n\t\tprintk(KERN_ERR \"Mount on filesystem of type \"\n\t\t\t\"eCryptfs explicitly disallowed due to \"\n\t\t\t\"known incompatibilities\\n\");\n\t\tgoto out_free;\n\t}\n\tecryptfs_set_superblock_lower(s, path.dentry->d_sb);\n\ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n\ts->s_blocksize = path.dentry->d_sb->s_blocksize;\n\ts->s_magic = ECRYPTFS_SUPER_MAGIC;\n\n\tinode = ecryptfs_get_inode(path.dentry->d_inode, s);\n\trc = PTR_ERR(inode);\n\tif (IS_ERR(inode))\n\t\tgoto out_free;\n\n\ts->s_root = d_alloc_root(inode);\n\tif (!s->s_root) {\n\t\tiput(inode);\n\t\trc = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\trc = -ENOMEM;\n\troot_info = kmem_cache_zalloc(ecryptfs_dentry_info_cache, GFP_KERNEL);\n\tif (!root_info)\n\t\tgoto out_free;\n\n\t/* ->kill_sb() will take care of root_info */\n\tecryptfs_set_dentry_private(s->s_root, root_info);\n\tecryptfs_set_dentry_lower(s->s_root, path.dentry);\n\tecryptfs_set_dentry_lower_mnt(s->s_root, path.mnt);\n\n\ts->s_flags |= MS_ACTIVE;\n\treturn dget(s->s_root);\n\nout_free:\n\tpath_put(&path);\nout1:\n\tdeactivate_locked_super(s);\nout:\n\tif (sbi) {\n\t\tecryptfs_destroy_mount_crypt_stat(&sbi->mount_crypt_stat);\n\t\tkmem_cache_free(ecryptfs_sb_info_cache, sbi);\n\t}\n\tprintk(KERN_ERR \"%s; rc = [%d]\\n\", err, rc);\n\treturn ERR_PTR(rc);\n}",
        "func": "static struct dentry *ecryptfs_mount(struct file_system_type *fs_type, int flags,\n\t\t\tconst char *dev_name, void *raw_data)\n{\n\tstruct super_block *s;\n\tstruct ecryptfs_sb_info *sbi;\n\tstruct ecryptfs_dentry_info *root_info;\n\tconst char *err = \"Getting sb failed\";\n\tstruct inode *inode;\n\tstruct path path;\n\tuid_t check_ruid;\n\tint rc;\n\n\tsbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);\n\tif (!sbi) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);\n\tif (rc) {\n\t\terr = \"Error parsing options\";\n\t\tgoto out;\n\t}\n\n\ts = sget(fs_type, NULL, set_anon_super, NULL);\n\tif (IS_ERR(s)) {\n\t\trc = PTR_ERR(s);\n\t\tgoto out;\n\t}\n\n\ts->s_flags = flags;\n\trc = bdi_setup_and_register(&sbi->bdi, \"ecryptfs\", BDI_CAP_MAP_COPY);\n\tif (rc)\n\t\tgoto out1;\n\n\tecryptfs_set_superblock_private(s, sbi);\n\ts->s_bdi = &sbi->bdi;\n\n\t/* ->kill_sb() will take care of sbi after that point */\n\tsbi = NULL;\n\ts->s_op = &ecryptfs_sops;\n\ts->s_d_op = &ecryptfs_dops;\n\n\terr = \"Reading sb failed\";\n\trc = kern_path(dev_name, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &path);\n\tif (rc) {\n\t\tecryptfs_printk(KERN_WARNING, \"kern_path() failed\\n\");\n\t\tgoto out1;\n\t}\n\tif (path.dentry->d_sb->s_type == &ecryptfs_fs_type) {\n\t\trc = -EINVAL;\n\t\tprintk(KERN_ERR \"Mount on filesystem of type \"\n\t\t\t\"eCryptfs explicitly disallowed due to \"\n\t\t\t\"known incompatibilities\\n\");\n\t\tgoto out_free;\n\t}\n\n\tif (check_ruid && path.dentry->d_inode->i_uid != current_uid()) {\n\t\trc = -EPERM;\n\t\tprintk(KERN_ERR \"Mount of device (uid: %d) not owned by \"\n\t\t       \"requested user (uid: %d)\\n\",\n\t\t       path.dentry->d_inode->i_uid, current_uid());\n\t\tgoto out_free;\n\t}\n\n\tecryptfs_set_superblock_lower(s, path.dentry->d_sb);\n\ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n\ts->s_blocksize = path.dentry->d_sb->s_blocksize;\n\ts->s_magic = ECRYPTFS_SUPER_MAGIC;\n\n\tinode = ecryptfs_get_inode(path.dentry->d_inode, s);\n\trc = PTR_ERR(inode);\n\tif (IS_ERR(inode))\n\t\tgoto out_free;\n\n\ts->s_root = d_alloc_root(inode);\n\tif (!s->s_root) {\n\t\tiput(inode);\n\t\trc = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\trc = -ENOMEM;\n\troot_info = kmem_cache_zalloc(ecryptfs_dentry_info_cache, GFP_KERNEL);\n\tif (!root_info)\n\t\tgoto out_free;\n\n\t/* ->kill_sb() will take care of root_info */\n\tecryptfs_set_dentry_private(s->s_root, root_info);\n\tecryptfs_set_dentry_lower(s->s_root, path.dentry);\n\tecryptfs_set_dentry_lower_mnt(s->s_root, path.mnt);\n\n\ts->s_flags |= MS_ACTIVE;\n\treturn dget(s->s_root);\n\nout_free:\n\tpath_put(&path);\nout1:\n\tdeactivate_locked_super(s);\nout:\n\tif (sbi) {\n\t\tecryptfs_destroy_mount_crypt_stat(&sbi->mount_crypt_stat);\n\t\tkmem_cache_free(ecryptfs_sb_info_cache, sbi);\n\t}\n\tprintk(KERN_ERR \"%s; rc = [%d]\\n\", err, rc);\n\treturn ERR_PTR(rc);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n \tconst char *err = \"Getting sb failed\";\n \tstruct inode *inode;\n \tstruct path path;\n+\tuid_t check_ruid;\n \tint rc;\n \n \tsbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);\n@@ -15,7 +16,7 @@\n \t\tgoto out;\n \t}\n \n-\trc = ecryptfs_parse_options(sbi, raw_data);\n+\trc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);\n \tif (rc) {\n \t\terr = \"Error parsing options\";\n \t\tgoto out;\n@@ -53,6 +54,15 @@\n \t\t\t\"known incompatibilities\\n\");\n \t\tgoto out_free;\n \t}\n+\n+\tif (check_ruid && path.dentry->d_inode->i_uid != current_uid()) {\n+\t\trc = -EPERM;\n+\t\tprintk(KERN_ERR \"Mount of device (uid: %d) not owned by \"\n+\t\t       \"requested user (uid: %d)\\n\",\n+\t\t       path.dentry->d_inode->i_uid, current_uid());\n+\t\tgoto out_free;\n+\t}\n+\n \tecryptfs_set_superblock_lower(s, path.dentry->d_sb);\n \ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n \ts->s_blocksize = path.dentry->d_sb->s_blocksize;",
        "diff_line_info": {
            "deleted_lines": [
                "\trc = ecryptfs_parse_options(sbi, raw_data);"
            ],
            "added_lines": [
                "\tuid_t check_ruid;",
                "\trc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);",
                "",
                "\tif (check_ruid && path.dentry->d_inode->i_uid != current_uid()) {",
                "\t\trc = -EPERM;",
                "\t\tprintk(KERN_ERR \"Mount of device (uid: %d) not owned by \"",
                "\t\t       \"requested user (uid: %d)\\n\",",
                "\t\t       path.dentry->d_inode->i_uid, current_uid());",
                "\t\tgoto out_free;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1833",
        "func_name": "torvalds/linux/ecryptfs_parse_options",
        "description": "Race condition in the ecryptfs_mount function in fs/ecryptfs/main.c in the eCryptfs subsystem in the Linux kernel before 3.1 allows local users to bypass intended file permissions via a mount.ecryptfs_private mount with a mismatched uid.",
        "git_url": "https://github.com/torvalds/linux/commit/764355487ea220fdc2faf128d577d7f679b91f97",
        "commit_title": "Ecryptfs: Add mount option to check uid of device being mounted = expect uid",
        "commit_text": " Close a TOCTOU race for mounts done via ecryptfs-mount-private.  The mount source (device) can be raced when the ownership test is done in userspace. Provide Ecryptfs a means to force the uid check at mount time.  Cc: <stable@kernel.org>",
        "func_before": "static int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options)\n{\n\tchar *p;\n\tint rc = 0;\n\tint sig_set = 0;\n\tint cipher_name_set = 0;\n\tint fn_cipher_name_set = 0;\n\tint cipher_key_bytes;\n\tint cipher_key_bytes_set = 0;\n\tint fn_cipher_key_bytes;\n\tint fn_cipher_key_bytes_set = 0;\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat =\n\t\t&sbi->mount_crypt_stat;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint token;\n\tchar *sig_src;\n\tchar *cipher_name_dst;\n\tchar *cipher_name_src;\n\tchar *fn_cipher_name_dst;\n\tchar *fn_cipher_name_src;\n\tchar *fnek_dst;\n\tchar *fnek_src;\n\tchar *cipher_key_bytes_src;\n\tchar *fn_cipher_key_bytes_src;\n\n\tif (!options) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\tecryptfs_init_mount_crypt_stat(mount_crypt_stat);\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase ecryptfs_opt_sig:\n\t\tcase ecryptfs_opt_ecryptfs_sig:\n\t\t\tsig_src = args[0].from;\n\t\t\trc = ecryptfs_add_global_auth_tok(mount_crypt_stat,\n\t\t\t\t\t\t\t  sig_src, 0);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global sig; rc = [%d]\\n\", rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsig_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_cipher:\n\t\tcase ecryptfs_opt_ecryptfs_cipher:\n\t\t\tcipher_name_src = args[0].from;\n\t\t\tcipher_name_dst =\n\t\t\t\tmount_crypt_stat->\n\t\t\t\tglobal_default_cipher_name;\n\t\t\tstrncpy(cipher_name_dst, cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tcipher_name_dst[ECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tcipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_ecryptfs_key_bytes:\n\t\t\tcipher_key_bytes_src = args[0].from;\n\t\t\tcipher_key_bytes =\n\t\t\t\t(int)simple_strtol(cipher_key_bytes_src,\n\t\t\t\t\t\t   &cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_cipher_key_size =\n\t\t\t\tcipher_key_bytes;\n\t\t\tcipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_passthrough:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_PLAINTEXT_PASSTHROUGH_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_xattr_metadata:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_encrypted_view:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_ENCRYPTED_VIEW_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fnek_sig:\n\t\t\tfnek_src = args[0].from;\n\t\t\tfnek_dst =\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig;\n\t\t\tstrncpy(fnek_dst, fnek_src, ECRYPTFS_SIG_SIZE_HEX);\n\t\t\tmount_crypt_stat->global_default_fnek_sig[\n\t\t\t\tECRYPTFS_SIG_SIZE_HEX] = '\\0';\n\t\t\trc = ecryptfs_add_global_auth_tok(\n\t\t\t\tmount_crypt_stat,\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig,\n\t\t\t\tECRYPTFS_AUTH_TOK_FNEK);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global fnek sig [%s]; rc = [%d]\\n\",\n\t\t\t\t       mount_crypt_stat->global_default_fnek_sig,\n\t\t\t\t       rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\t(ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES\n\t\t\t\t | ECRYPTFS_GLOBAL_ENCFN_USE_MOUNT_FNEK);\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher:\n\t\t\tfn_cipher_name_src = args[0].from;\n\t\t\tfn_cipher_name_dst =\n\t\t\t\tmount_crypt_stat->global_default_fn_cipher_name;\n\t\t\tstrncpy(fn_cipher_name_dst, fn_cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_name[\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tfn_cipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher_key_bytes:\n\t\t\tfn_cipher_key_bytes_src = args[0].from;\n\t\t\tfn_cipher_key_bytes =\n\t\t\t\t(int)simple_strtol(fn_cipher_key_bytes_src,\n\t\t\t\t\t\t   &fn_cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\t\tfn_cipher_key_bytes;\n\t\t\tfn_cipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_unlink_sigs:\n\t\t\tmount_crypt_stat->flags |= ECRYPTFS_UNLINK_SIGS;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_mount_auth_tok_only:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_GLOBAL_MOUNT_AUTH_TOK_ONLY;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_err:\n\t\tdefault:\n\t\t\tprintk(KERN_WARNING\n\t\t\t       \"%s: eCryptfs: unrecognized option [%s]\\n\",\n\t\t\t       __func__, p);\n\t\t}\n\t}\n\tif (!sig_set) {\n\t\trc = -EINVAL;\n\t\tecryptfs_printk(KERN_ERR, \"You must supply at least one valid \"\n\t\t\t\t\"auth tok signature as a mount \"\n\t\t\t\t\"parameter; see the eCryptfs README\\n\");\n\t\tgoto out;\n\t}\n\tif (!cipher_name_set) {\n\t\tint cipher_name_len = strlen(ECRYPTFS_DEFAULT_CIPHER);\n\n\t\tBUG_ON(cipher_name_len >= ECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\tstrcpy(mount_crypt_stat->global_default_cipher_name,\n\t\t       ECRYPTFS_DEFAULT_CIPHER);\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_name_set)\n\t\tstrcpy(mount_crypt_stat->global_default_fn_cipher_name,\n\t\t       mount_crypt_stat->global_default_cipher_name);\n\tif (!cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_cipher_key_size = 0;\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\tmount_crypt_stat->global_default_cipher_key_size;\n\tmutex_lock(&key_tfm_list_mutex);\n\tif (!ecryptfs_tfm_exists(mount_crypt_stat->global_default_cipher_name,\n\t\t\t\t NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_cipher_name,\n\t\t\tmount_crypt_stat->global_default_cipher_key_size);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_cipher_key_size,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !ecryptfs_tfm_exists(\n\t\t    mount_crypt_stat->global_default_fn_cipher_name, NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_key_bytes,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmutex_unlock(&key_tfm_list_mutex);\n\trc = ecryptfs_init_global_auth_toks(mount_crypt_stat);\n\tif (rc)\n\t\tprintk(KERN_WARNING \"One or more global auth toks could not \"\n\t\t       \"properly register; rc = [%d]\\n\", rc);\nout:\n\treturn rc;\n}",
        "func": "static int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options,\n\t\t\t\t  uid_t *check_ruid)\n{\n\tchar *p;\n\tint rc = 0;\n\tint sig_set = 0;\n\tint cipher_name_set = 0;\n\tint fn_cipher_name_set = 0;\n\tint cipher_key_bytes;\n\tint cipher_key_bytes_set = 0;\n\tint fn_cipher_key_bytes;\n\tint fn_cipher_key_bytes_set = 0;\n\tstruct ecryptfs_mount_crypt_stat *mount_crypt_stat =\n\t\t&sbi->mount_crypt_stat;\n\tsubstring_t args[MAX_OPT_ARGS];\n\tint token;\n\tchar *sig_src;\n\tchar *cipher_name_dst;\n\tchar *cipher_name_src;\n\tchar *fn_cipher_name_dst;\n\tchar *fn_cipher_name_src;\n\tchar *fnek_dst;\n\tchar *fnek_src;\n\tchar *cipher_key_bytes_src;\n\tchar *fn_cipher_key_bytes_src;\n\n\t*check_ruid = 0;\n\n\tif (!options) {\n\t\trc = -EINVAL;\n\t\tgoto out;\n\t}\n\tecryptfs_init_mount_crypt_stat(mount_crypt_stat);\n\twhile ((p = strsep(&options, \",\")) != NULL) {\n\t\tif (!*p)\n\t\t\tcontinue;\n\t\ttoken = match_token(p, tokens, args);\n\t\tswitch (token) {\n\t\tcase ecryptfs_opt_sig:\n\t\tcase ecryptfs_opt_ecryptfs_sig:\n\t\t\tsig_src = args[0].from;\n\t\t\trc = ecryptfs_add_global_auth_tok(mount_crypt_stat,\n\t\t\t\t\t\t\t  sig_src, 0);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global sig; rc = [%d]\\n\", rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsig_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_cipher:\n\t\tcase ecryptfs_opt_ecryptfs_cipher:\n\t\t\tcipher_name_src = args[0].from;\n\t\t\tcipher_name_dst =\n\t\t\t\tmount_crypt_stat->\n\t\t\t\tglobal_default_cipher_name;\n\t\t\tstrncpy(cipher_name_dst, cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tcipher_name_dst[ECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tcipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_ecryptfs_key_bytes:\n\t\t\tcipher_key_bytes_src = args[0].from;\n\t\t\tcipher_key_bytes =\n\t\t\t\t(int)simple_strtol(cipher_key_bytes_src,\n\t\t\t\t\t\t   &cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_cipher_key_size =\n\t\t\t\tcipher_key_bytes;\n\t\t\tcipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_passthrough:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_PLAINTEXT_PASSTHROUGH_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_xattr_metadata:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_encrypted_view:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_XATTR_METADATA_ENABLED;\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_ENCRYPTED_VIEW_ENABLED;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fnek_sig:\n\t\t\tfnek_src = args[0].from;\n\t\t\tfnek_dst =\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig;\n\t\t\tstrncpy(fnek_dst, fnek_src, ECRYPTFS_SIG_SIZE_HEX);\n\t\t\tmount_crypt_stat->global_default_fnek_sig[\n\t\t\t\tECRYPTFS_SIG_SIZE_HEX] = '\\0';\n\t\t\trc = ecryptfs_add_global_auth_tok(\n\t\t\t\tmount_crypt_stat,\n\t\t\t\tmount_crypt_stat->global_default_fnek_sig,\n\t\t\t\tECRYPTFS_AUTH_TOK_FNEK);\n\t\t\tif (rc) {\n\t\t\t\tprintk(KERN_ERR \"Error attempting to register \"\n\t\t\t\t       \"global fnek sig [%s]; rc = [%d]\\n\",\n\t\t\t\t       mount_crypt_stat->global_default_fnek_sig,\n\t\t\t\t       rc);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\t(ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES\n\t\t\t\t | ECRYPTFS_GLOBAL_ENCFN_USE_MOUNT_FNEK);\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher:\n\t\t\tfn_cipher_name_src = args[0].from;\n\t\t\tfn_cipher_name_dst =\n\t\t\t\tmount_crypt_stat->global_default_fn_cipher_name;\n\t\t\tstrncpy(fn_cipher_name_dst, fn_cipher_name_src,\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_name[\n\t\t\t\tECRYPTFS_MAX_CIPHER_NAME_SIZE] = '\\0';\n\t\t\tfn_cipher_name_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_fn_cipher_key_bytes:\n\t\t\tfn_cipher_key_bytes_src = args[0].from;\n\t\t\tfn_cipher_key_bytes =\n\t\t\t\t(int)simple_strtol(fn_cipher_key_bytes_src,\n\t\t\t\t\t\t   &fn_cipher_key_bytes_src, 0);\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\t\tfn_cipher_key_bytes;\n\t\t\tfn_cipher_key_bytes_set = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_unlink_sigs:\n\t\t\tmount_crypt_stat->flags |= ECRYPTFS_UNLINK_SIGS;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_mount_auth_tok_only:\n\t\t\tmount_crypt_stat->flags |=\n\t\t\t\tECRYPTFS_GLOBAL_MOUNT_AUTH_TOK_ONLY;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_check_dev_ruid:\n\t\t\t*check_ruid = 1;\n\t\t\tbreak;\n\t\tcase ecryptfs_opt_err:\n\t\tdefault:\n\t\t\tprintk(KERN_WARNING\n\t\t\t       \"%s: eCryptfs: unrecognized option [%s]\\n\",\n\t\t\t       __func__, p);\n\t\t}\n\t}\n\tif (!sig_set) {\n\t\trc = -EINVAL;\n\t\tecryptfs_printk(KERN_ERR, \"You must supply at least one valid \"\n\t\t\t\t\"auth tok signature as a mount \"\n\t\t\t\t\"parameter; see the eCryptfs README\\n\");\n\t\tgoto out;\n\t}\n\tif (!cipher_name_set) {\n\t\tint cipher_name_len = strlen(ECRYPTFS_DEFAULT_CIPHER);\n\n\t\tBUG_ON(cipher_name_len >= ECRYPTFS_MAX_CIPHER_NAME_SIZE);\n\t\tstrcpy(mount_crypt_stat->global_default_cipher_name,\n\t\t       ECRYPTFS_DEFAULT_CIPHER);\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_name_set)\n\t\tstrcpy(mount_crypt_stat->global_default_fn_cipher_name,\n\t\t       mount_crypt_stat->global_default_cipher_name);\n\tif (!cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_cipher_key_size = 0;\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !fn_cipher_key_bytes_set)\n\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes =\n\t\t\tmount_crypt_stat->global_default_cipher_key_size;\n\tmutex_lock(&key_tfm_list_mutex);\n\tif (!ecryptfs_tfm_exists(mount_crypt_stat->global_default_cipher_name,\n\t\t\t\t NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_cipher_name,\n\t\t\tmount_crypt_stat->global_default_cipher_key_size);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_cipher_key_size,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tif ((mount_crypt_stat->flags & ECRYPTFS_GLOBAL_ENCRYPT_FILENAMES)\n\t    && !ecryptfs_tfm_exists(\n\t\t    mount_crypt_stat->global_default_fn_cipher_name, NULL)) {\n\t\trc = ecryptfs_add_new_key_tfm(\n\t\t\tNULL, mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\tmount_crypt_stat->global_default_fn_cipher_key_bytes);\n\t\tif (rc) {\n\t\t\tprintk(KERN_ERR \"Error attempting to initialize \"\n\t\t\t       \"cipher with name = [%s] and key size = [%td]; \"\n\t\t\t       \"rc = [%d]\\n\",\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_name,\n\t\t\t       mount_crypt_stat->global_default_fn_cipher_key_bytes,\n\t\t\t       rc);\n\t\t\trc = -EINVAL;\n\t\t\tmutex_unlock(&key_tfm_list_mutex);\n\t\t\tgoto out;\n\t\t}\n\t}\n\tmutex_unlock(&key_tfm_list_mutex);\n\trc = ecryptfs_init_global_auth_toks(mount_crypt_stat);\n\tif (rc)\n\t\tprintk(KERN_WARNING \"One or more global auth toks could not \"\n\t\t       \"properly register; rc = [%d]\\n\", rc);\nout:\n\treturn rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-static int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options)\n+static int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options,\n+\t\t\t\t  uid_t *check_ruid)\n {\n \tchar *p;\n \tint rc = 0;\n@@ -23,6 +24,8 @@\n \tchar *cipher_key_bytes_src;\n \tchar *fn_cipher_key_bytes_src;\n \n+\t*check_ruid = 0;\n+\n \tif (!options) {\n \t\trc = -EINVAL;\n \t\tgoto out;\n@@ -126,6 +129,9 @@\n \t\tcase ecryptfs_opt_mount_auth_tok_only:\n \t\t\tmount_crypt_stat->flags |=\n \t\t\t\tECRYPTFS_GLOBAL_MOUNT_AUTH_TOK_ONLY;\n+\t\t\tbreak;\n+\t\tcase ecryptfs_opt_check_dev_ruid:\n+\t\t\t*check_ruid = 1;\n \t\t\tbreak;\n \t\tcase ecryptfs_opt_err:\n \t\tdefault:",
        "diff_line_info": {
            "deleted_lines": [
                "static int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options)"
            ],
            "added_lines": [
                "static int ecryptfs_parse_options(struct ecryptfs_sb_info *sbi, char *options,",
                "\t\t\t\t  uid_t *check_ruid)",
                "\t*check_ruid = 0;",
                "",
                "\t\t\tbreak;",
                "\t\tcase ecryptfs_opt_check_dev_ruid:",
                "\t\t\t*check_ruid = 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-3466",
        "func_name": "GNOME/gnome-keyring/gkm_secret_item_real_get_attribute",
        "description": "GNOME gnome-keyring 3.4.0 through 3.4.1, when gpg-cache-method is set to \"idle\" or \"timeout,\" does not properly limit the amount of time a passphrase is cached, which allows attackers to have an unspecified impact via unknown attack vectors.",
        "git_url": "https://github.com/GNOME/gnome-keyring/commit/5dff623470b859e332dbe12afb0dc57b292832d2",
        "commit_title": "secret-store: Mark a secret item as 'used' when accessed",
        "commit_text": "  * This makes the gpg-agent idle feature work correctly  https://bugzilla.gnome.org/show_bug.cgi?id=681081",
        "func_before": "static CK_RV\ngkm_secret_item_real_get_attribute (GkmObject *base, GkmSession *session, CK_ATTRIBUTE_PTR attr)\n{\n\tGkmSecretItem *self = GKM_SECRET_ITEM (base);\n\tGkmSecretData *sdata;\n\tconst gchar *identifier;\n\tconst guchar *secret;\n\tgsize n_secret = 0;\n\tCK_RV rv;\n\n\tg_return_val_if_fail (self->collection, CKR_GENERAL_ERROR);\n\n\tswitch (attr->type) {\n\tcase CKA_CLASS:\n\t\treturn gkm_attribute_set_ulong (attr, CKO_SECRET_KEY);\n\n\tcase CKA_VALUE:\n\t\tsdata = gkm_secret_collection_unlocked_use (self->collection, session);\n\t\tif (sdata == NULL)\n\t\t\treturn CKR_USER_NOT_LOGGED_IN;\n\t\tidentifier = gkm_secret_object_get_identifier (GKM_SECRET_OBJECT (self));\n\t\tsecret = gkm_secret_data_get_raw (sdata, identifier, &n_secret);\n\t\trv = gkm_attribute_set_data (attr, secret, n_secret);\n\t\tg_object_unref (sdata);\n\t\treturn rv;\n\n\tcase CKA_G_COLLECTION:\n\t\tg_return_val_if_fail (self->collection, CKR_GENERAL_ERROR);\n\t\tidentifier = gkm_secret_object_get_identifier (GKM_SECRET_OBJECT (self->collection));\n\t\treturn gkm_attribute_set_string (attr, identifier);\n\n\tcase CKA_G_FIELDS:\n\t\tif (!self->fields)\n\t\t\treturn gkm_attribute_set_data (attr, NULL, 0);\n\t\treturn gkm_secret_fields_serialize (attr, self->fields);\n\n\tcase CKA_G_SCHEMA:\n\t\treturn gkm_attribute_set_string (attr, self->schema);\n\t}\n\n\treturn GKM_OBJECT_CLASS (gkm_secret_item_parent_class)->get_attribute (base, session, attr);\n}",
        "func": "static CK_RV\ngkm_secret_item_real_get_attribute (GkmObject *base, GkmSession *session, CK_ATTRIBUTE_PTR attr)\n{\n\tGkmSecretItem *self = GKM_SECRET_ITEM (base);\n\tGkmSecretData *sdata;\n\tconst gchar *identifier;\n\tconst guchar *secret;\n\tgsize n_secret = 0;\n\tCK_RV rv;\n\n\tg_return_val_if_fail (self->collection, CKR_GENERAL_ERROR);\n\n\tswitch (attr->type) {\n\tcase CKA_CLASS:\n\t\treturn gkm_attribute_set_ulong (attr, CKO_SECRET_KEY);\n\n\tcase CKA_VALUE:\n\t\tsdata = gkm_secret_collection_unlocked_use (self->collection, session);\n\t\tif (sdata == NULL)\n\t\t\treturn CKR_USER_NOT_LOGGED_IN;\n\t\tidentifier = gkm_secret_object_get_identifier (GKM_SECRET_OBJECT (self));\n\t\tsecret = gkm_secret_data_get_raw (sdata, identifier, &n_secret);\n\t\trv = gkm_attribute_set_data (attr, secret, n_secret);\n\t\tgkm_object_mark_used (base);\n\t\tg_object_unref (sdata);\n\t\treturn rv;\n\n\tcase CKA_G_COLLECTION:\n\t\tg_return_val_if_fail (self->collection, CKR_GENERAL_ERROR);\n\t\tidentifier = gkm_secret_object_get_identifier (GKM_SECRET_OBJECT (self->collection));\n\t\treturn gkm_attribute_set_string (attr, identifier);\n\n\tcase CKA_G_FIELDS:\n\t\tif (!self->fields)\n\t\t\treturn gkm_attribute_set_data (attr, NULL, 0);\n\t\treturn gkm_secret_fields_serialize (attr, self->fields);\n\n\tcase CKA_G_SCHEMA:\n\t\treturn gkm_attribute_set_string (attr, self->schema);\n\t}\n\n\treturn GKM_OBJECT_CLASS (gkm_secret_item_parent_class)->get_attribute (base, session, attr);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,7 @@\n \t\tidentifier = gkm_secret_object_get_identifier (GKM_SECRET_OBJECT (self));\n \t\tsecret = gkm_secret_data_get_raw (sdata, identifier, &n_secret);\n \t\trv = gkm_attribute_set_data (attr, secret, n_secret);\n+\t\tgkm_object_mark_used (base);\n \t\tg_object_unref (sdata);\n \t\treturn rv;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tgkm_object_mark_used (base);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-3466",
        "func_name": "GNOME/gnome-keyring/do_get_password",
        "description": "GNOME gnome-keyring 3.4.0 through 3.4.1, when gpg-cache-method is set to \"idle\" or \"timeout,\" does not properly limit the amount of time a passphrase is cached, which allows attackers to have an unspecified impact via unknown attack vectors.",
        "git_url": "https://github.com/GNOME/gnome-keyring/commit/51606f299e5ee9d48096db0a5957efe26cbf7cc3",
        "commit_title": "gpg-agent: Hook up the TTL cache option",
        "commit_text": "  * So that when the gsettings gpg-cache-method is 'idle' or 'timeout'    we use gpg-cache-ttl to control how long the passphrase is cached    for.  * This is a regression from 3.3.x  https://bugzilla.gnome.org/show_bug.cgi?id=681081",
        "func_before": "static gchar*\ndo_get_password (GckSession *session, const gchar *keyid, const gchar *errmsg,\n                 const gchar *prompt_text, const gchar *description, gboolean confirm)\n{\n\tGckBuilder builder = GCK_BUILDER_INIT;\n\tGckAttributes *attrs;\n\tgchar *password = NULL;\n\tGcrPrompt *prompt;\n\tgboolean chosen;\n\tGError *error = NULL;\n\n\tg_assert (GCK_IS_SESSION (session));\n\n\t/* Do we have the keyid? */\n\tpassword = do_lookup_password (session, keyid);\n\tif (password != NULL)\n\t\treturn password;\n\n\tprompt = open_password_prompt (session, keyid, errmsg, prompt_text,\n\t                               description, confirm);\n\tif (prompt != NULL) {\n\t\tpassword = egg_secure_strdup (gcr_prompt_password (prompt, NULL, &error));\n\t\tif (password == NULL) {\n\t\t\tif (error && !g_error_matches (error, G_IO_ERROR, G_IO_ERROR_CANCELLED))\n\t\t\t\tg_warning (\"couldn't prompt for password: %s\", egg_error_message (error));\n\t\t\tg_clear_error (&error);\n\t\t}\n\t}\n\n\tif (password != NULL && keyid != NULL) {\n\n\t\t/* Load up the save options */\n\t\tchosen = gcr_prompt_get_choice_chosen (prompt);\n\n\t\tif (chosen)\n\t\t\tgck_builder_add_string (&builder, CKA_G_COLLECTION, \"login\");\n\t\telse\n\t\t\tgck_builder_add_string (&builder, CKA_G_COLLECTION, \"session\");\n\n\t\t/* Now actually save the password */\n\t\tattrs = gck_attributes_ref_sink (gck_builder_end (&builder));\n\t\tdo_save_password (session, keyid, description, password, attrs);\n\t\tgck_attributes_unref (attrs);\n\n\t\tsave_unlock_options (prompt);\n\t}\n\n\tg_clear_object (&prompt);\n\treturn password;\n}",
        "func": "static gchar*\ndo_get_password (GckSession *session, const gchar *keyid, const gchar *errmsg,\n                 const gchar *prompt_text, const gchar *description, gboolean confirm)\n{\n\tGckBuilder builder = GCK_BUILDER_INIT;\n\tGSettings *settings;\n\tGckAttributes *attrs;\n\tgchar *password = NULL;\n\tGcrPrompt *prompt;\n\tgboolean chosen;\n\tGError *error = NULL;\n\tgint lifetime;\n\tgchar *method;\n\n\tg_assert (GCK_IS_SESSION (session));\n\n\t/* Do we have the keyid? */\n\tpassword = do_lookup_password (session, keyid);\n\tif (password != NULL)\n\t\treturn password;\n\n\tprompt = open_password_prompt (session, keyid, errmsg, prompt_text,\n\t                               description, confirm);\n\tif (prompt != NULL) {\n\t\tpassword = egg_secure_strdup (gcr_prompt_password (prompt, NULL, &error));\n\t\tif (password == NULL) {\n\t\t\tif (error && !g_error_matches (error, G_IO_ERROR, G_IO_ERROR_CANCELLED))\n\t\t\t\tg_warning (\"couldn't prompt for password: %s\", egg_error_message (error));\n\t\t\tg_clear_error (&error);\n\t\t}\n\t}\n\n\tif (password != NULL && keyid != NULL) {\n\t\tsettings = gkd_gpg_agent_settings ();\n\n\t\t/* Load up the save options */\n\t\tchosen = gcr_prompt_get_choice_chosen (prompt);\n\n\t\tif (chosen) {\n\t\t\tg_settings_set_string (settings, \"gpg-cache-method\", GCR_UNLOCK_OPTION_ALWAYS);\n\t\t\tgck_builder_add_string (&builder, CKA_G_COLLECTION, \"login\");\n\n\t\t} else {\n\t\t\tmethod = g_settings_get_string (settings, \"gpg-cache-method\");\n\t\t\tlifetime = g_settings_get_int (settings, \"gpg-cache-ttl\");\n\n\t\t\tif (g_strcmp0 (method, GCR_UNLOCK_OPTION_IDLE) == 0) {\n\t\t\t\tgck_builder_add_boolean (&builder, CKA_GNOME_TRANSIENT, TRUE);\n\t\t\t\tgck_builder_add_ulong (&builder, CKA_G_DESTRUCT_IDLE, lifetime);\n\n\t\t\t} else if (g_strcmp0 (method, GCR_UNLOCK_OPTION_TIMEOUT) == 0) {\n\t\t\t\tgck_builder_add_boolean (&builder, CKA_GNOME_TRANSIENT, TRUE);\n\t\t\t\tgck_builder_add_ulong (&builder, CKA_G_DESTRUCT_AFTER, lifetime);\n\n\t\t\t} else if (g_strcmp0 (method, GCR_UNLOCK_OPTION_SESSION)){\n\t\t\t\tg_message (\"Unsupported gpg-cache-method setting: %s\", method);\n\t\t\t}\n\n\t\t\tgck_builder_add_string (&builder, CKA_G_COLLECTION, \"session\");\n\t\t\tg_free (method);\n\t\t}\n\n\t\t/* Now actually save the password */\n\t\tattrs = gck_attributes_ref_sink (gck_builder_end (&builder));\n\t\tdo_save_password (session, keyid, description, password, attrs);\n\t\tgck_attributes_unref (attrs);\n\t}\n\n\tg_clear_object (&prompt);\n\treturn password;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,11 +3,14 @@\n                  const gchar *prompt_text, const gchar *description, gboolean confirm)\n {\n \tGckBuilder builder = GCK_BUILDER_INIT;\n+\tGSettings *settings;\n \tGckAttributes *attrs;\n \tgchar *password = NULL;\n \tGcrPrompt *prompt;\n \tgboolean chosen;\n \tGError *error = NULL;\n+\tgint lifetime;\n+\tgchar *method;\n \n \tg_assert (GCK_IS_SESSION (session));\n \n@@ -28,21 +31,39 @@\n \t}\n \n \tif (password != NULL && keyid != NULL) {\n+\t\tsettings = gkd_gpg_agent_settings ();\n \n \t\t/* Load up the save options */\n \t\tchosen = gcr_prompt_get_choice_chosen (prompt);\n \n-\t\tif (chosen)\n+\t\tif (chosen) {\n+\t\t\tg_settings_set_string (settings, \"gpg-cache-method\", GCR_UNLOCK_OPTION_ALWAYS);\n \t\t\tgck_builder_add_string (&builder, CKA_G_COLLECTION, \"login\");\n-\t\telse\n+\n+\t\t} else {\n+\t\t\tmethod = g_settings_get_string (settings, \"gpg-cache-method\");\n+\t\t\tlifetime = g_settings_get_int (settings, \"gpg-cache-ttl\");\n+\n+\t\t\tif (g_strcmp0 (method, GCR_UNLOCK_OPTION_IDLE) == 0) {\n+\t\t\t\tgck_builder_add_boolean (&builder, CKA_GNOME_TRANSIENT, TRUE);\n+\t\t\t\tgck_builder_add_ulong (&builder, CKA_G_DESTRUCT_IDLE, lifetime);\n+\n+\t\t\t} else if (g_strcmp0 (method, GCR_UNLOCK_OPTION_TIMEOUT) == 0) {\n+\t\t\t\tgck_builder_add_boolean (&builder, CKA_GNOME_TRANSIENT, TRUE);\n+\t\t\t\tgck_builder_add_ulong (&builder, CKA_G_DESTRUCT_AFTER, lifetime);\n+\n+\t\t\t} else if (g_strcmp0 (method, GCR_UNLOCK_OPTION_SESSION)){\n+\t\t\t\tg_message (\"Unsupported gpg-cache-method setting: %s\", method);\n+\t\t\t}\n+\n \t\t\tgck_builder_add_string (&builder, CKA_G_COLLECTION, \"session\");\n+\t\t\tg_free (method);\n+\t\t}\n \n \t\t/* Now actually save the password */\n \t\tattrs = gck_attributes_ref_sink (gck_builder_end (&builder));\n \t\tdo_save_password (session, keyid, description, password, attrs);\n \t\tgck_attributes_unref (attrs);\n-\n-\t\tsave_unlock_options (prompt);\n \t}\n \n \tg_clear_object (&prompt);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (chosen)",
                "\t\telse",
                "",
                "\t\tsave_unlock_options (prompt);"
            ],
            "added_lines": [
                "\tGSettings *settings;",
                "\tgint lifetime;",
                "\tgchar *method;",
                "\t\tsettings = gkd_gpg_agent_settings ();",
                "\t\tif (chosen) {",
                "\t\t\tg_settings_set_string (settings, \"gpg-cache-method\", GCR_UNLOCK_OPTION_ALWAYS);",
                "",
                "\t\t} else {",
                "\t\t\tmethod = g_settings_get_string (settings, \"gpg-cache-method\");",
                "\t\t\tlifetime = g_settings_get_int (settings, \"gpg-cache-ttl\");",
                "",
                "\t\t\tif (g_strcmp0 (method, GCR_UNLOCK_OPTION_IDLE) == 0) {",
                "\t\t\t\tgck_builder_add_boolean (&builder, CKA_GNOME_TRANSIENT, TRUE);",
                "\t\t\t\tgck_builder_add_ulong (&builder, CKA_G_DESTRUCT_IDLE, lifetime);",
                "",
                "\t\t\t} else if (g_strcmp0 (method, GCR_UNLOCK_OPTION_TIMEOUT) == 0) {",
                "\t\t\t\tgck_builder_add_boolean (&builder, CKA_GNOME_TRANSIENT, TRUE);",
                "\t\t\t\tgck_builder_add_ulong (&builder, CKA_G_DESTRUCT_AFTER, lifetime);",
                "",
                "\t\t\t} else if (g_strcmp0 (method, GCR_UNLOCK_OPTION_SESSION)){",
                "\t\t\t\tg_message (\"Unsupported gpg-cache-method setting: %s\", method);",
                "\t\t\t}",
                "",
                "\t\t\tg_free (method);",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2486",
        "func_name": "davidben/nspluginwrapper/g_NPN_GetValue",
        "description": "nspluginwrapper before 1.4.4 does not properly provide access to NPNVprivateModeBool variable settings, which could prevent Firefox plugins from determining if they should run in Private Browsing mode and allow remote attackers to bypass intended access restrictions, as demonstrated using Flash.",
        "git_url": "https://github.com/davidben/nspluginwrapper/commit/7e4ab8e1189846041f955e6c83f72bc1624e7a98",
        "commit_title": "Support all the new variables added",
        "commit_text": "",
        "func_before": "static NPError\ng_NPN_GetValue(NPP instance, NPNVariable variable, void *value)\n{\n  D(bug(\"NPN_GetValue instance=%p, variable=%d [%s]\\n\", instance, variable, string_of_NPNVariable(variable)));\n\n  if (!thread_check()) {\n\tnpw_printf(\"WARNING: NPN_GetValue not called from the main thread\\n\");\n\treturn NPERR_INVALID_INSTANCE_ERROR;\n  }\n\n  PluginInstance *plugin = NULL;\n  if (instance)\n\tplugin = PLUGIN_INSTANCE(instance);\n\n  switch (variable) {\n  case NPNVxDisplay:\n\t*(void **)value = x_display;\n\tbreak;\n  case NPNVxtAppContext:\n\t*(void **)value = XtDisplayToApplicationContext(x_display);\n\tbreak;\n  case NPNVToolkit:\n\t*(NPNToolkitType *)value = NPW_TOOLKIT;\n\tbreak;\n#if USE_XPCOM\n  case NPNVserviceManager: {\n\tnsIServiceManager *sm;\n\tint ret = NS_GetServiceManager(&sm);\n\tif (NS_FAILED(ret)) {\n\t  npw_printf(\"WARNING: NS_GetServiceManager failed\\n\");\n\t  return NPERR_GENERIC_ERROR;\n\t}\n\t*(nsIServiceManager **)value = sm;\n\tbreak;\n  }\n  case NPNVDOMWindow:\n  case NPNVDOMElement:\n\tnpw_printf(\"WARNING: %s is not supported by NPN_GetValue()\\n\", string_of_NPNVariable(variable));\n\treturn NPERR_INVALID_PARAM;\n#endif\n  case NPNVnetscapeWindow:\n\tif (plugin == NULL) {\n\t  npw_printf(\"ERROR: NPNVnetscapeWindow requires a non NULL instance\\n\");\n\t  return NPERR_INVALID_INSTANCE_ERROR;\n\t}\n\tif (plugin->browser_toplevel == NULL) {\n\t  GdkNativeWindow netscape_xid = None;\n\t  NPError error = g_NPN_GetValue_real(instance, variable, &netscape_xid);\n\t  if (error != NPERR_NO_ERROR)\n\t\treturn error;\n\t  if (netscape_xid == None)\n\t\treturn NPERR_GENERIC_ERROR;\n\t  plugin->browser_toplevel = gdk_window_foreign_new(netscape_xid);\n\t  if (plugin->browser_toplevel == NULL)\n\t\treturn NPERR_GENERIC_ERROR;\n\t}\n\t*((GdkNativeWindow *)value) = GDK_WINDOW_XWINDOW(plugin->browser_toplevel);\n\tbreak;\n#if ALLOW_WINDOWLESS_PLUGINS\n  case NPNVSupportsWindowless:\n#endif\n  case NPNVSupportsXEmbedBool:\n  case NPNVWindowNPObject:\n  case NPNVPluginElementNPObject:\n\treturn g_NPN_GetValue_real(instance, variable, value);\n  default:\n\tswitch (variable & 0xff) {\n\tcase 13: /* NPNVToolkit */\n\t  if (NPW_TOOLKIT == NPNVGtk2) {\n\t\t// Gtk2 does not need to depend on a specific C++ ABI\n\t\t*(NPNToolkitType *)value = NPW_TOOLKIT;\n\t\treturn NPERR_NO_ERROR;\n\t  }\n\t  break;\n\t}\n\tD(bug(\"WARNING: unhandled variable %d (%s) in NPN_GetValue()\\n\", variable, string_of_NPNVariable(variable)));\n\treturn NPERR_INVALID_PARAM;\n  }\n\n  return NPERR_NO_ERROR;\n}",
        "func": "static NPError\ng_NPN_GetValue(NPP instance, NPNVariable variable, void *value)\n{\n  D(bug(\"NPN_GetValue instance=%p, variable=%d [%s]\\n\", instance, variable, string_of_NPNVariable(variable)));\n\n  if (!thread_check()) {\n\tnpw_printf(\"WARNING: NPN_GetValue not called from the main thread\\n\");\n\treturn NPERR_INVALID_INSTANCE_ERROR;\n  }\n\n  PluginInstance *plugin = NULL;\n  if (instance)\n\tplugin = PLUGIN_INSTANCE(instance);\n\n  switch (variable) {\n  case NPNVxDisplay:\n\t*(void **)value = x_display;\n\tbreak;\n  case NPNVxtAppContext:\n\t*(void **)value = XtDisplayToApplicationContext(x_display);\n\tbreak;\n  case NPNVToolkit:\n\t*(NPNToolkitType *)value = NPW_TOOLKIT;\n\tbreak;\n#if USE_XPCOM\n  case NPNVserviceManager: {\n\tnsIServiceManager *sm;\n\tint ret = NS_GetServiceManager(&sm);\n\tif (NS_FAILED(ret)) {\n\t  npw_printf(\"WARNING: NS_GetServiceManager failed\\n\");\n\t  return NPERR_GENERIC_ERROR;\n\t}\n\t*(nsIServiceManager **)value = sm;\n\tbreak;\n  }\n  case NPNVDOMWindow:\n  case NPNVDOMElement:\n\tnpw_printf(\"WARNING: %s is not supported by NPN_GetValue()\\n\", string_of_NPNVariable(variable));\n\treturn NPERR_INVALID_PARAM;\n#endif\n  case NPNVnetscapeWindow:\n\tif (plugin == NULL) {\n\t  npw_printf(\"ERROR: NPNVnetscapeWindow requires a non NULL instance\\n\");\n\t  return NPERR_INVALID_INSTANCE_ERROR;\n\t}\n\tif (plugin->browser_toplevel == NULL) {\n\t  GdkNativeWindow netscape_xid = None;\n\t  NPError error = g_NPN_GetValue_real(instance, variable, &netscape_xid);\n\t  if (error != NPERR_NO_ERROR)\n\t\treturn error;\n\t  if (netscape_xid == None)\n\t\treturn NPERR_GENERIC_ERROR;\n\t  plugin->browser_toplevel = gdk_window_foreign_new(netscape_xid);\n\t  if (plugin->browser_toplevel == NULL)\n\t\treturn NPERR_GENERIC_ERROR;\n\t}\n\t*((GdkNativeWindow *)value) = GDK_WINDOW_XWINDOW(plugin->browser_toplevel);\n\tbreak;\n#if ALLOW_WINDOWLESS_PLUGINS\n  case NPNVSupportsWindowless:\n#endif\n  case NPNVSupportsXEmbedBool:\n  case NPNVWindowNPObject:\n  case NPNVPluginElementNPObject:\n  case NPNVprivateModeBool:\n  case NPNVsupportsAdvancedKeyHandling:\n\treturn g_NPN_GetValue_real(instance, variable, value);\n  default:\n\tswitch (variable & 0xff) {\n\tcase 13: /* NPNVToolkit */\n\t  if (NPW_TOOLKIT == NPNVGtk2) {\n\t\t// Gtk2 does not need to depend on a specific C++ ABI\n\t\t*(NPNToolkitType *)value = NPW_TOOLKIT;\n\t\treturn NPERR_NO_ERROR;\n\t  }\n\t  break;\n\t}\n\tD(bug(\"WARNING: unhandled variable %d (%s) in NPN_GetValue()\\n\", variable, string_of_NPNVariable(variable)));\n\treturn NPERR_INVALID_PARAM;\n  }\n\n  return NPERR_NO_ERROR;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -62,6 +62,8 @@\n   case NPNVSupportsXEmbedBool:\n   case NPNVWindowNPObject:\n   case NPNVPluginElementNPObject:\n+  case NPNVprivateModeBool:\n+  case NPNVsupportsAdvancedKeyHandling:\n \treturn g_NPN_GetValue_real(instance, variable, value);\n   default:\n \tswitch (variable & 0xff) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  case NPNVprivateModeBool:",
                "  case NPNVsupportsAdvancedKeyHandling:"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2486",
        "func_name": "davidben/nspluginwrapper/rpc_type_of_NPNVariable",
        "description": "nspluginwrapper before 1.4.4 does not properly provide access to NPNVprivateModeBool variable settings, which could prevent Firefox plugins from determining if they should run in Private Browsing mode and allow remote attackers to bypass intended access restrictions, as demonstrated using Flash.",
        "git_url": "https://github.com/davidben/nspluginwrapper/commit/7e4ab8e1189846041f955e6c83f72bc1624e7a98",
        "commit_title": "Support all the new variables added",
        "commit_text": "",
        "func_before": "int rpc_type_of_NPNVariable(int variable)\n{\n  int type;\n  switch (variable) {\n  case NPNVjavascriptEnabledBool:\n  case NPNVasdEnabledBool:\n  case NPNVisOfflineBool:\n  case NPNVSupportsXEmbedBool:\n  case NPNVSupportsWindowless:\n\ttype = RPC_TYPE_BOOLEAN;\n\tbreak;\n  case NPNVToolkit:\n  case NPNVnetscapeWindow:\n\ttype = RPC_TYPE_UINT32;\n\tbreak;\n  case NPNVWindowNPObject:\n  case NPNVPluginElementNPObject:\n\ttype = RPC_TYPE_NP_OBJECT;\n\tbreak;\n  default:\n\ttype = RPC_ERROR_GENERIC;\n\tbreak;\n  }\n  return type;\n}",
        "func": "int rpc_type_of_NPNVariable(int variable)\n{\n  int type;\n  switch (variable) {\n  case NPNVjavascriptEnabledBool:\n  case NPNVasdEnabledBool:\n  case NPNVisOfflineBool:\n  case NPNVSupportsXEmbedBool:\n  case NPNVSupportsWindowless:\n  case NPNVprivateModeBool:\n  case NPNVsupportsAdvancedKeyHandling:\n\ttype = RPC_TYPE_BOOLEAN;\n\tbreak;\n  case NPNVToolkit:\n  case NPNVnetscapeWindow:\n\ttype = RPC_TYPE_UINT32;\n\tbreak;\n  case NPNVWindowNPObject:\n  case NPNVPluginElementNPObject:\n\ttype = RPC_TYPE_NP_OBJECT;\n\tbreak;\n  default:\n\ttype = RPC_ERROR_GENERIC;\n\tbreak;\n  }\n  return type;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,8 @@\n   case NPNVisOfflineBool:\n   case NPNVSupportsXEmbedBool:\n   case NPNVSupportsWindowless:\n+  case NPNVprivateModeBool:\n+  case NPNVsupportsAdvancedKeyHandling:\n \ttype = RPC_TYPE_BOOLEAN;\n \tbreak;\n   case NPNVToolkit:",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  case NPNVprivateModeBool:",
                "  case NPNVsupportsAdvancedKeyHandling:"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2486",
        "func_name": "davidben/nspluginwrapper/rpc_type_of_NPPVariable",
        "description": "nspluginwrapper before 1.4.4 does not properly provide access to NPNVprivateModeBool variable settings, which could prevent Firefox plugins from determining if they should run in Private Browsing mode and allow remote attackers to bypass intended access restrictions, as demonstrated using Flash.",
        "git_url": "https://github.com/davidben/nspluginwrapper/commit/7e4ab8e1189846041f955e6c83f72bc1624e7a98",
        "commit_title": "Support all the new variables added",
        "commit_text": "",
        "func_before": "int rpc_type_of_NPPVariable(int variable)\n{\n  int type;\n  switch (variable) {\n  case NPPVpluginNameString:\n  case NPPVpluginDescriptionString:\n  case NPPVformValue: // byte values of 0 does not appear in the UTF-8 encoding but for U+0000\n\ttype = RPC_TYPE_STRING;\n\tbreak;\n  case NPPVpluginWindowSize:\n  case NPPVpluginTimerInterval:\n\ttype = RPC_TYPE_INT32;\n\tbreak;\n  case NPPVpluginNeedsXEmbed:\n  case NPPVpluginWindowBool:\n  case NPPVpluginTransparentBool:\n  case NPPVjavascriptPushCallerBool:\n  case NPPVpluginKeepLibraryInMemory:\n\ttype = RPC_TYPE_BOOLEAN;\n\tbreak;\n  case NPPVpluginScriptableNPObject:\n\ttype = RPC_TYPE_NP_OBJECT;\n\tbreak;\n  default:\n\ttype = RPC_ERROR_GENERIC;\n\tbreak;\n  }\n  return type;\n}",
        "func": "int rpc_type_of_NPPVariable(int variable)\n{\n  int type;\n  switch (variable) {\n  case NPPVpluginNameString:\n  case NPPVpluginDescriptionString:\n  case NPPVformValue: // byte values of 0 does not appear in the UTF-8 encoding but for U+0000\n  case NPPVpluginNativeAccessibleAtkPlugId:\n\ttype = RPC_TYPE_STRING;\n\tbreak;\n  case NPPVpluginWindowSize:\n  case NPPVpluginTimerInterval:\n\ttype = RPC_TYPE_INT32;\n\tbreak;\n  case NPPVpluginNeedsXEmbed:\n  case NPPVpluginWindowBool:\n  case NPPVpluginTransparentBool:\n  case NPPVjavascriptPushCallerBool:\n  case NPPVpluginKeepLibraryInMemory:\n  case NPPVpluginUrlRequestsDisplayedBool:\n  case NPPVpluginWantsAllNetworkStreams:\n  case NPPVpluginCancelSrcStream:\n  case NPPVSupportsAdvancedKeyHandling:\n\ttype = RPC_TYPE_BOOLEAN;\n\tbreak;\n  case NPPVpluginScriptableNPObject:\n\ttype = RPC_TYPE_NP_OBJECT;\n\tbreak;\n  default:\n\ttype = RPC_ERROR_GENERIC;\n\tbreak;\n  }\n  return type;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n   case NPPVpluginNameString:\n   case NPPVpluginDescriptionString:\n   case NPPVformValue: // byte values of 0 does not appear in the UTF-8 encoding but for U+0000\n+  case NPPVpluginNativeAccessibleAtkPlugId:\n \ttype = RPC_TYPE_STRING;\n \tbreak;\n   case NPPVpluginWindowSize:\n@@ -16,6 +17,10 @@\n   case NPPVpluginTransparentBool:\n   case NPPVjavascriptPushCallerBool:\n   case NPPVpluginKeepLibraryInMemory:\n+  case NPPVpluginUrlRequestsDisplayedBool:\n+  case NPPVpluginWantsAllNetworkStreams:\n+  case NPPVpluginCancelSrcStream:\n+  case NPPVSupportsAdvancedKeyHandling:\n \ttype = RPC_TYPE_BOOLEAN;\n \tbreak;\n   case NPPVpluginScriptableNPObject:",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  case NPPVpluginNativeAccessibleAtkPlugId:",
                "  case NPPVpluginUrlRequestsDisplayedBool:",
                "  case NPPVpluginWantsAllNetworkStreams:",
                "  case NPPVpluginCancelSrcStream:",
                "  case NPPVSupportsAdvancedKeyHandling:"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2486",
        "func_name": "davidben/nspluginwrapper/string_of_NPNVariable",
        "description": "nspluginwrapper before 1.4.4 does not properly provide access to NPNVprivateModeBool variable settings, which could prevent Firefox plugins from determining if they should run in Private Browsing mode and allow remote attackers to bypass intended access restrictions, as demonstrated using Flash.",
        "git_url": "https://github.com/davidben/nspluginwrapper/commit/7e4ab8e1189846041f955e6c83f72bc1624e7a98",
        "commit_title": "Support all the new variables added",
        "commit_text": "",
        "func_before": "const char *string_of_NPNVariable(int variable)\n{\n  const char *str;\n\n  switch (variable) {\n#define _(VAL) case VAL: str = #VAL; break;\n\t_(NPNVxDisplay);\n\t_(NPNVxtAppContext);\n\t_(NPNVnetscapeWindow);\n\t_(NPNVjavascriptEnabledBool);\n\t_(NPNVasdEnabledBool);\n\t_(NPNVisOfflineBool);\n\t_(NPNVserviceManager);\n\t_(NPNVDOMElement);\n\t_(NPNVDOMWindow);\n\t_(NPNVToolkit);\n\t_(NPNVSupportsXEmbedBool);\n\t_(NPNVWindowNPObject);\n\t_(NPNVPluginElementNPObject);\n\t_(NPNVSupportsWindowless);\n#undef _\n  default:\n\tswitch (variable & 0xff) {\n#define _(VAL, VAR) case VAL: str = #VAR; break\n\t  _(10, NPNVserviceManager);\n\t  _(11, NPNVDOMElement);\n\t  _(12, NPNVDOMWindow);\n\t  _(13, NPNVToolkit);\n#undef _\n\tdefault:\n\t  str = \"<unknown variable>\";\n\t  break;\n\t}\n\tbreak;\n  }\n\n  return str;\n}",
        "func": "const char *string_of_NPNVariable(int variable)\n{\n  const char *str;\n\n  switch (variable) {\n#define _(VAL) case VAL: str = #VAL; break;\n\t_(NPNVxDisplay);\n\t_(NPNVxtAppContext);\n\t_(NPNVnetscapeWindow);\n\t_(NPNVjavascriptEnabledBool);\n\t_(NPNVasdEnabledBool);\n\t_(NPNVisOfflineBool);\n\t_(NPNVserviceManager);\n\t_(NPNVDOMElement);\n\t_(NPNVDOMWindow);\n\t_(NPNVToolkit);\n\t_(NPNVSupportsXEmbedBool);\n\t_(NPNVWindowNPObject);\n\t_(NPNVPluginElementNPObject);\n\t_(NPNVSupportsWindowless);\n\t_(NPNVprivateModeBool);\n\t_(NPNVsupportsAdvancedKeyHandling);\n#undef _\n  default:\n\tswitch (variable & 0xff) {\n#define _(VAL, VAR) case VAL: str = #VAR; break\n\t  _(10, NPNVserviceManager);\n\t  _(11, NPNVDOMElement);\n\t  _(12, NPNVDOMWindow);\n\t  _(13, NPNVToolkit);\n#undef _\n\tdefault:\n\t  str = \"<unknown variable>\";\n\t  break;\n\t}\n\tbreak;\n  }\n\n  return str;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,6 +18,8 @@\n \t_(NPNVWindowNPObject);\n \t_(NPNVPluginElementNPObject);\n \t_(NPNVSupportsWindowless);\n+\t_(NPNVprivateModeBool);\n+\t_(NPNVsupportsAdvancedKeyHandling);\n #undef _\n   default:\n \tswitch (variable & 0xff) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t_(NPNVprivateModeBool);",
                "\t_(NPNVsupportsAdvancedKeyHandling);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-2486",
        "func_name": "davidben/nspluginwrapper/string_of_NPPVariable",
        "description": "nspluginwrapper before 1.4.4 does not properly provide access to NPNVprivateModeBool variable settings, which could prevent Firefox plugins from determining if they should run in Private Browsing mode and allow remote attackers to bypass intended access restrictions, as demonstrated using Flash.",
        "git_url": "https://github.com/davidben/nspluginwrapper/commit/7e4ab8e1189846041f955e6c83f72bc1624e7a98",
        "commit_title": "Support all the new variables added",
        "commit_text": "",
        "func_before": "const char *string_of_NPPVariable(int variable)\n{\n  const char *str;\n\n  switch (variable) {\n#define _(VAL) case VAL: str = #VAL; break;\n\t_(NPPVpluginNameString);\n\t_(NPPVpluginDescriptionString);\n\t_(NPPVpluginWindowBool);\n\t_(NPPVpluginTransparentBool);\n\t_(NPPVjavaClass);\n\t_(NPPVpluginWindowSize);\n\t_(NPPVpluginTimerInterval);\n\t_(NPPVpluginScriptableInstance);\n\t_(NPPVpluginScriptableIID);\n\t_(NPPVjavascriptPushCallerBool);\n\t_(NPPVpluginKeepLibraryInMemory);\n\t_(NPPVpluginNeedsXEmbed);\n\t_(NPPVpluginScriptableNPObject);\n\t_(NPPVformValue);\n#undef _\n  default:\n\tswitch (variable & 0xff) {\n#define _(VAL, VAR) case VAL: str = #VAR; break\n\t  _(10, NPPVpluginScriptableInstance);\n#undef _\n\tdefault:\n\t  str = \"<unknown variable>\";\n\t  break;\n\t}\n\tbreak;\n  }\n\n  return str;\n}",
        "func": "const char *string_of_NPPVariable(int variable)\n{\n  const char *str;\n\n  switch (variable) {\n#define _(VAL) case VAL: str = #VAL; break;\n\t_(NPPVpluginNameString);\n\t_(NPPVpluginDescriptionString);\n\t_(NPPVpluginWindowBool);\n\t_(NPPVpluginTransparentBool);\n\t_(NPPVjavaClass);\n\t_(NPPVpluginWindowSize);\n\t_(NPPVpluginTimerInterval);\n\t_(NPPVpluginScriptableInstance);\n\t_(NPPVpluginScriptableIID);\n\t_(NPPVjavascriptPushCallerBool);\n\t_(NPPVpluginKeepLibraryInMemory);\n\t_(NPPVpluginNeedsXEmbed);\n\t_(NPPVpluginScriptableNPObject);\n\t_(NPPVformValue);\n\t_(NPPVpluginUrlRequestsDisplayedBool);\n\t_(NPPVpluginWantsAllNetworkStreams);\n\t_(NPPVpluginNativeAccessibleAtkPlugId);\n\t_(NPPVpluginCancelSrcStream);\n\t_(NPPVSupportsAdvancedKeyHandling);\n#undef _\n  default:\n\tswitch (variable & 0xff) {\n#define _(VAL, VAR) case VAL: str = #VAR; break\n\t  _(10, NPPVpluginScriptableInstance);\n#undef _\n\tdefault:\n\t  str = \"<unknown variable>\";\n\t  break;\n\t}\n\tbreak;\n  }\n\n  return str;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,6 +18,11 @@\n \t_(NPPVpluginNeedsXEmbed);\n \t_(NPPVpluginScriptableNPObject);\n \t_(NPPVformValue);\n+\t_(NPPVpluginUrlRequestsDisplayedBool);\n+\t_(NPPVpluginWantsAllNetworkStreams);\n+\t_(NPPVpluginNativeAccessibleAtkPlugId);\n+\t_(NPPVpluginCancelSrcStream);\n+\t_(NPPVSupportsAdvancedKeyHandling);\n #undef _\n   default:\n \tswitch (variable & 0xff) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t_(NPPVpluginUrlRequestsDisplayedBool);",
                "\t_(NPPVpluginWantsAllNetworkStreams);",
                "\t_(NPPVpluginNativeAccessibleAtkPlugId);",
                "\t_(NPPVpluginCancelSrcStream);",
                "\t_(NPPVSupportsAdvancedKeyHandling);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-0268",
        "func_name": "torvalds/linux/msr_open",
        "description": "The msr_open function in arch/x86/kernel/msr.c in the Linux kernel before 3.7.6 allows local users to bypass intended capability restrictions by executing a crafted application as root, as demonstrated by msr32.c.",
        "git_url": "https://github.com/torvalds/linux/commit/c903f0456bc69176912dee6dd25c6a66ee1aed00",
        "commit_title": "x86/msr: Add capabilities check",
        "commit_text": " At the moment the MSR driver only relies upon file system checks. This means that anything as root with any capability set can write to MSRs. Historically that wasn't very interesting but on modern processors the MSRs are such that writing to them provides several ways to execute arbitary code in kernel space. Sample code and documentation on doing this is circulating and MSR attacks are used on Windows 64bit rootkits already.  In the Linux case you still need to be able to open the device file so the impact is fairly limited and reduces the security of some capability and security model based systems down towards that of a generic \"root owns the box\" setup.  Therefore they should require CAP_SYS_RAWIO to prevent an elevation of capabilities. The impact of this is fairly minimal on most setups because they don't have heavy use of capabilities. Those using SELinux, SMACK or AppArmor rules might want to consider if their rulesets on the MSR driver could be tighter.  Cc: Linus Torvalds <torvalds@linux-foundation.org> Cc: Andrew Morton <akpm@linux-foundation.org> Cc: Peter Zijlstra <a.p.zijlstra@chello.nl> Cc: Horses <stable@kernel.org>",
        "func_before": "static int msr_open(struct inode *inode, struct file *file)\n{\n\tunsigned int cpu;\n\tstruct cpuinfo_x86 *c;\n\n\tcpu = iminor(file->f_path.dentry->d_inode);\n\tif (cpu >= nr_cpu_ids || !cpu_online(cpu))\n\t\treturn -ENXIO;\t/* No such CPU */\n\n\tc = &cpu_data(cpu);\n\tif (!cpu_has(c, X86_FEATURE_MSR))\n\t\treturn -EIO;\t/* MSR not supported */\n\n\treturn 0;\n}",
        "func": "static int msr_open(struct inode *inode, struct file *file)\n{\n\tunsigned int cpu;\n\tstruct cpuinfo_x86 *c;\n\n\tif (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\n\tcpu = iminor(file->f_path.dentry->d_inode);\n\tif (cpu >= nr_cpu_ids || !cpu_online(cpu))\n\t\treturn -ENXIO;\t/* No such CPU */\n\n\tc = &cpu_data(cpu);\n\tif (!cpu_has(c, X86_FEATURE_MSR))\n\t\treturn -EIO;\t/* MSR not supported */\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,9 @@\n {\n \tunsigned int cpu;\n \tstruct cpuinfo_x86 *c;\n+\n+\tif (!capable(CAP_SYS_RAWIO))\n+\t\treturn -EPERM;\n \n \tcpu = iminor(file->f_path.dentry->d_inode);\n \tif (cpu >= nr_cpu_ids || !cpu_online(cpu))",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!capable(CAP_SYS_RAWIO))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1774",
        "func_name": "torvalds/linux/chase_port",
        "description": "The chase_port function in drivers/usb/serial/io_ti.c in the Linux kernel before 3.7.4 allows local users to cause a denial of service (NULL pointer dereference and system crash) via an attempted /dev/ttyUSB read or write operation on a disconnected Edgeport USB serial converter.",
        "git_url": "https://github.com/torvalds/linux/commit/1ee0a224bc9aad1de496c795f96bc6ba2c394811",
        "commit_title": "USB: io_ti: Fix NULL dereference in chase_port()",
        "commit_text": " The tty is NULL when the port is hanging up. chase_port() needs to check for this.  This patch is intended for stable series. The behavior was observed and tested in Linux 3.2 and 3.7.1.  Johan Hovold submitted a more elaborate patch for the mainline kernel.  [   56.277883] usb 1-1: edge_bulk_in_callback - nonzero read bulk status received: -84 [   56.278811] usb 1-1: USB disconnect, device number 3 [   56.278856] usb 1-1: edge_bulk_in_callback - stopping read! [   56.279562] BUG: unable to handle kernel NULL pointer dereference at 00000000000001c8 [   56.280536] IP: [<ffffffff8144e62a>] _raw_spin_lock_irqsave+0x19/0x35 [   56.281212] PGD 1dc1b067 PUD 1e0f7067 PMD 0 [   56.282085] Oops: 0002 [#1] SMP [   56.282744] Modules linked in: [   56.283512] CPU 1 [   56.283512] Pid: 25, comm: khubd Not tainted 3.7.1 #1 innotek GmbH VirtualBox/VirtualBox [   56.283512] RIP: 0010:[<ffffffff8144e62a>]  [<ffffffff8144e62a>] _raw_spin_lock_irqsave+0x19/0x35 [   56.283512] RSP: 0018:ffff88001fa99ab0  EFLAGS: 00010046 [   56.283512] RAX: 0000000000000046 RBX: 00000000000001c8 RCX: 0000000000640064 [   56.283512] RDX: 0000000000010000 RSI: ffff88001fa99b20 RDI: 00000000000001c8 [   56.283512] RBP: ffff88001fa99b20 R08: 0000000000000000 R09: 0000000000000000 [   56.283512] R10: 0000000000000000 R11: ffffffff812fcb4c R12: ffff88001ddf53c0 [   56.283512] R13: 0000000000000000 R14: 00000000000001c8 R15: ffff88001e19b9f4 [   56.283512] FS:  0000000000000000(0000) GS:ffff88001fd00000(0000) knlGS:0000000000000000 [   56.283512] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b [   56.283512] CR2: 00000000000001c8 CR3: 000000001dc51000 CR4: 00000000000006e0 [   56.283512] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 [   56.283512] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400 [   56.283512] Process khubd (pid: 25, threadinfo ffff88001fa98000, task ffff88001fa94f80) [   56.283512] Stack: [   56.283512]  0000000000000046 00000000000001c8 ffffffff810578ec ffffffff812fcb4c [   56.283512]  ffff88001e19b980 0000000000002710 ffffffff812ffe81 0000000000000001 [   56.283512]  ffff88001fa94f80 0000000000000202 ffffffff00000001 0000000000000296 [   56.283512] Call Trace: [   56.283512]  [<ffffffff810578ec>] ? add_wait_queue+0x12/0x3c [   56.283512]  [<ffffffff812fcb4c>] ? usb_serial_port_work+0x28/0x28 [   56.283512]  [<ffffffff812ffe81>] ? chase_port+0x84/0x2d6 [   56.283512]  [<ffffffff81063f27>] ? try_to_wake_up+0x199/0x199 [   56.283512]  [<ffffffff81263a5c>] ? tty_ldisc_hangup+0x222/0x298 [   56.283512]  [<ffffffff81300171>] ? edge_close+0x64/0x129 [   56.283512]  [<ffffffff810612f7>] ? __wake_up+0x35/0x46 [   56.283512]  [<ffffffff8106135b>] ? should_resched+0x5/0x23 [   56.283512]  [<ffffffff81264916>] ? tty_port_shutdown+0x39/0x44 [   56.283512]  [<ffffffff812fcb4c>] ? usb_serial_port_work+0x28/0x28 [   56.283512]  [<ffffffff8125d38c>] ? __tty_hangup+0x307/0x351 [   56.283512]  [<ffffffff812e6ddc>] ? usb_hcd_flush_endpoint+0xde/0xed [   56.283512]  [<ffffffff8144e625>] ? _raw_spin_lock_irqsave+0x14/0x35 [   56.283512]  [<ffffffff812fd361>] ? usb_serial_disconnect+0x57/0xc2 [   56.283512]  [<ffffffff812ea99b>] ? usb_unbind_interface+0x5c/0x131 [   56.283512]  [<ffffffff8128d738>] ? __device_release_driver+0x7f/0xd5 [   56.283512]  [<ffffffff8128d9cd>] ? device_release_driver+0x1a/0x25 [   56.283512]  [<ffffffff8128d393>] ? bus_remove_device+0xd2/0xe7 [   56.283512]  [<ffffffff8128b7a3>] ? device_del+0x119/0x167 [   56.283512]  [<ffffffff812e8d9d>] ? usb_disable_device+0x6a/0x180 [   56.283512]  [<ffffffff812e2ae0>] ? usb_disconnect+0x81/0xe6 [   56.283512]  [<ffffffff812e4435>] ? hub_thread+0x577/0xe82 [   56.283512]  [<ffffffff8144daa7>] ? __schedule+0x490/0x4be [   56.283512]  [<ffffffff8105798f>] ? abort_exclusive_wait+0x79/0x79 [   56.283512]  [<ffffffff812e3ebe>] ? usb_remote_wakeup+0x2f/0x2f [   56.283512]  [<ffffffff812e3ebe>] ? usb_remote_wakeup+0x2f/0x2f [   56.283512]  [<ffffffff810570b4>] ? kthread+0x81/0x89 [   56.283512]  [<ffffffff81057033>] ? __kthread_parkme+0x5c/0x5c [   56.283512]  [<ffffffff8145387c>] ? ret_from_fork+0x7c/0xb0 [   56.283512]  [<ffffffff81057033>] ? __kthread_parkme+0x5c/0x5c [   56.283512] Code: 8b 7c 24 08 e8 17 0b c3 ff 48 8b 04 24 48 83 c4 10 c3 53 48 89 fb 41 50 e8 e0 0a c3 ff 48 89 04 24 e8 e7 0a c3 ff ba 00 00 01 00 <f0> 0f c1 13 48 8b 04 24 89 d1 c1 ea 10 66 39 d1 74 07 f3 90 66 [   56.283512] RIP  [<ffffffff8144e62a>] _raw_spin_lock_irqsave+0x19/0x35 [   56.283512]  RSP <ffff88001fa99ab0> [   56.283512] CR2: 00000000000001c8 [   56.283512] ---[ end trace 49714df27e1679ce ]---  Cc: Johan Hovold <jhovold@gmail.com> Cc: stable <stable@vger.kernel.org>",
        "func_before": "static void chase_port(struct edgeport_port *port, unsigned long timeout,\n\t\t\t\t\t\t\t\tint flush)\n{\n\tint baud_rate;\n\tstruct tty_struct *tty = tty_port_tty_get(&port->port->port);\n\tstruct usb_serial *serial = port->port->serial;\n\twait_queue_t wait;\n\tunsigned long flags;\n\n\tif (!timeout)\n\t\ttimeout = (HZ * EDGE_CLOSING_WAIT)/100;\n\n\t/* wait for data to drain from the buffer */\n\tspin_lock_irqsave(&port->ep_lock, flags);\n\tinit_waitqueue_entry(&wait, current);\n\tadd_wait_queue(&tty->write_wait, &wait);\n\tfor (;;) {\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tif (kfifo_len(&port->write_fifo) == 0\n\t\t|| timeout == 0 || signal_pending(current)\n\t\t|| serial->disconnected)\n\t\t\t/* disconnect */\n\t\t\tbreak;\n\t\tspin_unlock_irqrestore(&port->ep_lock, flags);\n\t\ttimeout = schedule_timeout(timeout);\n\t\tspin_lock_irqsave(&port->ep_lock, flags);\n\t}\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&tty->write_wait, &wait);\n\tif (flush)\n\t\tkfifo_reset_out(&port->write_fifo);\n\tspin_unlock_irqrestore(&port->ep_lock, flags);\n\ttty_kref_put(tty);\n\n\t/* wait for data to drain from the device */\n\ttimeout += jiffies;\n\twhile ((long)(jiffies - timeout) < 0 && !signal_pending(current)\n\t\t\t\t\t\t&& !serial->disconnected) {\n\t\t/* not disconnected */\n\t\tif (!tx_active(port))\n\t\t\tbreak;\n\t\tmsleep(10);\n\t}\n\n\t/* disconnected */\n\tif (serial->disconnected)\n\t\treturn;\n\n\t/* wait one more character time, based on baud rate */\n\t/* (tx_active doesn't seem to wait for the last byte) */\n\tbaud_rate = port->baud_rate;\n\tif (baud_rate == 0)\n\t\tbaud_rate = 50;\n\tmsleep(max(1, DIV_ROUND_UP(10000, baud_rate)));\n}",
        "func": "static void chase_port(struct edgeport_port *port, unsigned long timeout,\n\t\t\t\t\t\t\t\tint flush)\n{\n\tint baud_rate;\n\tstruct tty_struct *tty = tty_port_tty_get(&port->port->port);\n\tstruct usb_serial *serial = port->port->serial;\n\twait_queue_t wait;\n\tunsigned long flags;\n\n\tif (!tty)\n\t\treturn;\n\n\tif (!timeout)\n\t\ttimeout = (HZ * EDGE_CLOSING_WAIT)/100;\n\n\t/* wait for data to drain from the buffer */\n\tspin_lock_irqsave(&port->ep_lock, flags);\n\tinit_waitqueue_entry(&wait, current);\n\tadd_wait_queue(&tty->write_wait, &wait);\n\tfor (;;) {\n\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\tif (kfifo_len(&port->write_fifo) == 0\n\t\t|| timeout == 0 || signal_pending(current)\n\t\t|| serial->disconnected)\n\t\t\t/* disconnect */\n\t\t\tbreak;\n\t\tspin_unlock_irqrestore(&port->ep_lock, flags);\n\t\ttimeout = schedule_timeout(timeout);\n\t\tspin_lock_irqsave(&port->ep_lock, flags);\n\t}\n\tset_current_state(TASK_RUNNING);\n\tremove_wait_queue(&tty->write_wait, &wait);\n\tif (flush)\n\t\tkfifo_reset_out(&port->write_fifo);\n\tspin_unlock_irqrestore(&port->ep_lock, flags);\n\ttty_kref_put(tty);\n\n\t/* wait for data to drain from the device */\n\ttimeout += jiffies;\n\twhile ((long)(jiffies - timeout) < 0 && !signal_pending(current)\n\t\t\t\t\t\t&& !serial->disconnected) {\n\t\t/* not disconnected */\n\t\tif (!tx_active(port))\n\t\t\tbreak;\n\t\tmsleep(10);\n\t}\n\n\t/* disconnected */\n\tif (serial->disconnected)\n\t\treturn;\n\n\t/* wait one more character time, based on baud rate */\n\t/* (tx_active doesn't seem to wait for the last byte) */\n\tbaud_rate = port->baud_rate;\n\tif (baud_rate == 0)\n\t\tbaud_rate = 50;\n\tmsleep(max(1, DIV_ROUND_UP(10000, baud_rate)));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,9 @@\n \tstruct usb_serial *serial = port->port->serial;\n \twait_queue_t wait;\n \tunsigned long flags;\n+\n+\tif (!tty)\n+\t\treturn;\n \n \tif (!timeout)\n \t\ttimeout = (HZ * EDGE_CLOSING_WAIT)/100;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!tty)",
                "\t\treturn;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-0914",
        "func_name": "torvalds/linux/flush_signal_handlers",
        "description": "The flush_signal_handlers function in kernel/signal.c in the Linux kernel before 3.8.4 preserves the value of the sa_restorer field across an exec operation, which makes it easier for local users to bypass the ASLR protection mechanism via a crafted application containing a sigaction system call.",
        "git_url": "https://github.com/torvalds/linux/commit/2ca39528c01a933f6689cd6505ce65bd6d68a530",
        "commit_title": "signal: always clear sa_restorer on execve",
        "commit_text": " When the new signal handlers are set up, the location of sa_restorer is not cleared, leaking a parent process's address space location to children.  This allows for a potential bypass of the parent's ASLR by examining the sa_restorer value returned when calling sigaction().  Based on what should be considered \"secret\" about addresses, it only matters across the exec not the fork (since the VMAs haven't changed until the exec).  But since exec sets SIG_DFL and keeps sa_restorer, this is where it should be fixed.  Given the few uses of sa_restorer, a \"set\" function was not written since this would be the only use.  Instead, we use __ARCH_HAS_SA_RESTORER, as already done in other places.  Example of the leak before applying this patch:    $ cat /proc/$$/maps   ...   7fb9f3083000-7fb9f3238000 r-xp 00000000 fd:01 404469 .../libc-2.15.so   ...   $ ./leak   ...   7f278bc74000-7f278be29000 r-xp 00000000 fd:01 404469 .../libc-2.15.so   ...   1 0 (nil) 0x7fb9f30b94a0   2 4000000 (nil) 0x7f278bcaa4a0   3 4000000 (nil) 0x7f278bcaa4a0   4 0 (nil) 0x7fb9f30b94a0   ...  [akpm@linux-foundation.org: use SA_RESTORER for backportability] Cc: Emese Revfy <re.emese@gmail.com> Cc: PaX Team <pageexec@freemail.hu> Cc: Al Viro <viro@zeniv.linux.org.uk> Cc: Oleg Nesterov <oleg@redhat.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Serge Hallyn <serge.hallyn@canonical.com> Cc: Julien Tinnes <jln@google.com> Cc: <stable@vger.kernel.org>",
        "func_before": "void\nflush_signal_handlers(struct task_struct *t, int force_default)\n{\n\tint i;\n\tstruct k_sigaction *ka = &t->sighand->action[0];\n\tfor (i = _NSIG ; i != 0 ; i--) {\n\t\tif (force_default || ka->sa.sa_handler != SIG_IGN)\n\t\t\tka->sa.sa_handler = SIG_DFL;\n\t\tka->sa.sa_flags = 0;\n\t\tsigemptyset(&ka->sa.sa_mask);\n\t\tka++;\n\t}\n}",
        "func": "void\nflush_signal_handlers(struct task_struct *t, int force_default)\n{\n\tint i;\n\tstruct k_sigaction *ka = &t->sighand->action[0];\n\tfor (i = _NSIG ; i != 0 ; i--) {\n\t\tif (force_default || ka->sa.sa_handler != SIG_IGN)\n\t\t\tka->sa.sa_handler = SIG_DFL;\n\t\tka->sa.sa_flags = 0;\n#ifdef SA_RESTORER\n\t\tka->sa.sa_restorer = NULL;\n#endif\n\t\tsigemptyset(&ka->sa.sa_mask);\n\t\tka++;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,9 @@\n \t\tif (force_default || ka->sa.sa_handler != SIG_IGN)\n \t\t\tka->sa.sa_handler = SIG_DFL;\n \t\tka->sa.sa_flags = 0;\n+#ifdef SA_RESTORER\n+\t\tka->sa.sa_restorer = NULL;\n+#endif\n \t\tsigemptyset(&ka->sa.sa_mask);\n \t\tka++;\n \t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "#ifdef SA_RESTORER",
                "\t\tka->sa.sa_restorer = NULL;",
                "#endif"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1858",
        "func_name": "torvalds/linux/copy_process",
        "description": "The clone system-call implementation in the Linux kernel before 3.8.3 does not properly handle a combination of the CLONE_NEWUSER and CLONE_FS flags, which allows local users to gain privileges by calling chroot and leveraging the sharing of the / directory between a parent process and a child process.",
        "git_url": "https://github.com/torvalds/linux/commit/e66eded8309ebf679d3d3c1f5820d1f2ca332c71",
        "commit_title": "userns: Don't allow CLONE_NEWUSER | CLONE_FS",
        "commit_text": " Don't allowing sharing the root directory with processes in a different user namespace.  There doesn't seem to be any point, and to allow it would require the overhead of putting a user namespace reference in fs_struct (for permission checks) and incrementing that reference count on practically every call to fork.  So just perform the inexpensive test of forbidding sharing fs_struct acrosss processes in different user namespaces.  We already disallow other forms of threading when unsharing a user namespace so this should be no real burden in practice.  This updates setns, clone, and unshare to disallow multiple user namespaces sharing an fs_struct.  Cc: stable@vger.kernel.org",
        "func_before": "static struct task_struct *copy_process(unsigned long clone_flags,\n\t\t\t\t\tunsigned long stack_start,\n\t\t\t\t\tunsigned long stack_size,\n\t\t\t\t\tint __user *child_tidptr,\n\t\t\t\t\tstruct pid *pid,\n\t\t\t\t\tint trace)\n{\n\tint retval;\n\tstruct task_struct *p;\n\n\tif ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * Thread groups must share signals as well, and detached threads\n\t * can only be started up within the thread group.\n\t */\n\tif ((clone_flags & CLONE_THREAD) && !(clone_flags & CLONE_SIGHAND))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * Shared signal handlers imply shared VM. By way of the above,\n\t * thread groups also imply shared VM. Blocking this case allows\n\t * for various simplifications in other code.\n\t */\n\tif ((clone_flags & CLONE_SIGHAND) && !(clone_flags & CLONE_VM))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * Siblings of global init remain as zombies on exit since they are\n\t * not reaped by their parent (swapper). To solve this and to avoid\n\t * multi-rooted process trees, prevent global and container-inits\n\t * from creating siblings.\n\t */\n\tif ((clone_flags & CLONE_PARENT) &&\n\t\t\t\tcurrent->signal->flags & SIGNAL_UNKILLABLE)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * If the new process will be in a different pid namespace\n\t * don't allow the creation of threads.\n\t */\n\tif ((clone_flags & (CLONE_VM|CLONE_NEWPID)) &&\n\t    (task_active_pid_ns(current) != current->nsproxy->pid_ns))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tretval = security_task_create(clone_flags);\n\tif (retval)\n\t\tgoto fork_out;\n\n\tretval = -ENOMEM;\n\tp = dup_task_struct(current);\n\tif (!p)\n\t\tgoto fork_out;\n\n\tftrace_graph_init_task(p);\n\tget_seccomp_filter(p);\n\n\trt_mutex_init_task(p);\n\n#ifdef CONFIG_PROVE_LOCKING\n\tDEBUG_LOCKS_WARN_ON(!p->hardirqs_enabled);\n\tDEBUG_LOCKS_WARN_ON(!p->softirqs_enabled);\n#endif\n\tretval = -EAGAIN;\n\tif (atomic_read(&p->real_cred->user->processes) >=\n\t\t\ttask_rlimit(p, RLIMIT_NPROC)) {\n\t\tif (!capable(CAP_SYS_ADMIN) && !capable(CAP_SYS_RESOURCE) &&\n\t\t    p->real_cred->user != INIT_USER)\n\t\t\tgoto bad_fork_free;\n\t}\n\tcurrent->flags &= ~PF_NPROC_EXCEEDED;\n\n\tretval = copy_creds(p, clone_flags);\n\tif (retval < 0)\n\t\tgoto bad_fork_free;\n\n\t/*\n\t * If multiple threads are within copy_process(), then this check\n\t * triggers too late. This doesn't hurt, the check is only there\n\t * to stop root fork bombs.\n\t */\n\tretval = -EAGAIN;\n\tif (nr_threads >= max_threads)\n\t\tgoto bad_fork_cleanup_count;\n\n\tif (!try_module_get(task_thread_info(p)->exec_domain->module))\n\t\tgoto bad_fork_cleanup_count;\n\n\tp->did_exec = 0;\n\tdelayacct_tsk_init(p);\t/* Must remain after dup_task_struct() */\n\tcopy_flags(clone_flags, p);\n\tINIT_LIST_HEAD(&p->children);\n\tINIT_LIST_HEAD(&p->sibling);\n\trcu_copy_process(p);\n\tp->vfork_done = NULL;\n\tspin_lock_init(&p->alloc_lock);\n\n\tinit_sigpending(&p->pending);\n\n\tp->utime = p->stime = p->gtime = 0;\n\tp->utimescaled = p->stimescaled = 0;\n#ifndef CONFIG_VIRT_CPU_ACCOUNTING\n\tp->prev_cputime.utime = p->prev_cputime.stime = 0;\n#endif\n#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN\n\tseqlock_init(&p->vtime_seqlock);\n\tp->vtime_snap = 0;\n\tp->vtime_snap_whence = VTIME_SLEEPING;\n#endif\n\n#if defined(SPLIT_RSS_COUNTING)\n\tmemset(&p->rss_stat, 0, sizeof(p->rss_stat));\n#endif\n\n\tp->default_timer_slack_ns = current->timer_slack_ns;\n\n\ttask_io_accounting_init(&p->ioac);\n\tacct_clear_integrals(p);\n\n\tposix_cpu_timers_init(p);\n\n\tdo_posix_clock_monotonic_gettime(&p->start_time);\n\tp->real_start_time = p->start_time;\n\tmonotonic_to_bootbased(&p->real_start_time);\n\tp->io_context = NULL;\n\tp->audit_context = NULL;\n\tif (clone_flags & CLONE_THREAD)\n\t\tthreadgroup_change_begin(current);\n\tcgroup_fork(p);\n#ifdef CONFIG_NUMA\n\tp->mempolicy = mpol_dup(p->mempolicy);\n\tif (IS_ERR(p->mempolicy)) {\n\t\tretval = PTR_ERR(p->mempolicy);\n\t\tp->mempolicy = NULL;\n\t\tgoto bad_fork_cleanup_cgroup;\n\t}\n\tmpol_fix_fork_child_flag(p);\n#endif\n#ifdef CONFIG_CPUSETS\n\tp->cpuset_mem_spread_rotor = NUMA_NO_NODE;\n\tp->cpuset_slab_spread_rotor = NUMA_NO_NODE;\n\tseqcount_init(&p->mems_allowed_seq);\n#endif\n#ifdef CONFIG_TRACE_IRQFLAGS\n\tp->irq_events = 0;\n\tp->hardirqs_enabled = 0;\n\tp->hardirq_enable_ip = 0;\n\tp->hardirq_enable_event = 0;\n\tp->hardirq_disable_ip = _THIS_IP_;\n\tp->hardirq_disable_event = 0;\n\tp->softirqs_enabled = 1;\n\tp->softirq_enable_ip = _THIS_IP_;\n\tp->softirq_enable_event = 0;\n\tp->softirq_disable_ip = 0;\n\tp->softirq_disable_event = 0;\n\tp->hardirq_context = 0;\n\tp->softirq_context = 0;\n#endif\n#ifdef CONFIG_LOCKDEP\n\tp->lockdep_depth = 0; /* no locks held yet */\n\tp->curr_chain_key = 0;\n\tp->lockdep_recursion = 0;\n#endif\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\tp->blocked_on = NULL; /* not blocked yet */\n#endif\n#ifdef CONFIG_MEMCG\n\tp->memcg_batch.do_batch = 0;\n\tp->memcg_batch.memcg = NULL;\n#endif\n\n\t/* Perform scheduler related setup. Assign this task to a CPU. */\n\tsched_fork(p);\n\n\tretval = perf_event_init_task(p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_policy;\n\tretval = audit_alloc(p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_policy;\n\t/* copy all the process information */\n\tretval = copy_semundo(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_audit;\n\tretval = copy_files(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_semundo;\n\tretval = copy_fs(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_files;\n\tretval = copy_sighand(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_fs;\n\tretval = copy_signal(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_sighand;\n\tretval = copy_mm(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_signal;\n\tretval = copy_namespaces(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_mm;\n\tretval = copy_io(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_namespaces;\n\tretval = copy_thread(clone_flags, stack_start, stack_size, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_io;\n\n\tif (pid != &init_struct_pid) {\n\t\tretval = -ENOMEM;\n\t\tpid = alloc_pid(p->nsproxy->pid_ns);\n\t\tif (!pid)\n\t\t\tgoto bad_fork_cleanup_io;\n\t}\n\n\tp->pid = pid_nr(pid);\n\tp->tgid = p->pid;\n\tif (clone_flags & CLONE_THREAD)\n\t\tp->tgid = current->tgid;\n\n\tp->set_child_tid = (clone_flags & CLONE_CHILD_SETTID) ? child_tidptr : NULL;\n\t/*\n\t * Clear TID on mm_release()?\n\t */\n\tp->clear_child_tid = (clone_flags & CLONE_CHILD_CLEARTID) ? child_tidptr : NULL;\n#ifdef CONFIG_BLOCK\n\tp->plug = NULL;\n#endif\n#ifdef CONFIG_FUTEX\n\tp->robust_list = NULL;\n#ifdef CONFIG_COMPAT\n\tp->compat_robust_list = NULL;\n#endif\n\tINIT_LIST_HEAD(&p->pi_state_list);\n\tp->pi_state_cache = NULL;\n#endif\n\tuprobe_copy_process(p);\n\t/*\n\t * sigaltstack should be cleared when sharing the same VM\n\t */\n\tif ((clone_flags & (CLONE_VM|CLONE_VFORK)) == CLONE_VM)\n\t\tp->sas_ss_sp = p->sas_ss_size = 0;\n\n\t/*\n\t * Syscall tracing and stepping should be turned off in the\n\t * child regardless of CLONE_PTRACE.\n\t */\n\tuser_disable_single_step(p);\n\tclear_tsk_thread_flag(p, TIF_SYSCALL_TRACE);\n#ifdef TIF_SYSCALL_EMU\n\tclear_tsk_thread_flag(p, TIF_SYSCALL_EMU);\n#endif\n\tclear_all_latency_tracing(p);\n\n\t/* ok, now we should be set up.. */\n\tif (clone_flags & CLONE_THREAD)\n\t\tp->exit_signal = -1;\n\telse if (clone_flags & CLONE_PARENT)\n\t\tp->exit_signal = current->group_leader->exit_signal;\n\telse\n\t\tp->exit_signal = (clone_flags & CSIGNAL);\n\n\tp->pdeath_signal = 0;\n\tp->exit_state = 0;\n\n\tp->nr_dirtied = 0;\n\tp->nr_dirtied_pause = 128 >> (PAGE_SHIFT - 10);\n\tp->dirty_paused_when = 0;\n\n\t/*\n\t * Ok, make it visible to the rest of the system.\n\t * We dont wake it up yet.\n\t */\n\tp->group_leader = p;\n\tINIT_LIST_HEAD(&p->thread_group);\n\tp->task_works = NULL;\n\n\t/* Need tasklist lock for parent etc handling! */\n\twrite_lock_irq(&tasklist_lock);\n\n\t/* CLONE_PARENT re-uses the old parent */\n\tif (clone_flags & (CLONE_PARENT|CLONE_THREAD)) {\n\t\tp->real_parent = current->real_parent;\n\t\tp->parent_exec_id = current->parent_exec_id;\n\t} else {\n\t\tp->real_parent = current;\n\t\tp->parent_exec_id = current->self_exec_id;\n\t}\n\n\tspin_lock(&current->sighand->siglock);\n\n\t/*\n\t * Process group and session signals need to be delivered to just the\n\t * parent before the fork or both the parent and the child after the\n\t * fork. Restart if a signal comes in before we add the new process to\n\t * it's process group.\n\t * A fatal signal pending means that current will exit, so the new\n\t * thread can't slip out of an OOM kill (or normal SIGKILL).\n\t*/\n\trecalc_sigpending();\n\tif (signal_pending(current)) {\n\t\tspin_unlock(&current->sighand->siglock);\n\t\twrite_unlock_irq(&tasklist_lock);\n\t\tretval = -ERESTARTNOINTR;\n\t\tgoto bad_fork_free_pid;\n\t}\n\n\tif (clone_flags & CLONE_THREAD) {\n\t\tcurrent->signal->nr_threads++;\n\t\tatomic_inc(&current->signal->live);\n\t\tatomic_inc(&current->signal->sigcnt);\n\t\tp->group_leader = current->group_leader;\n\t\tlist_add_tail_rcu(&p->thread_group, &p->group_leader->thread_group);\n\t}\n\n\tif (likely(p->pid)) {\n\t\tptrace_init_task(p, (clone_flags & CLONE_PTRACE) || trace);\n\n\t\tif (thread_group_leader(p)) {\n\t\t\tif (is_child_reaper(pid)) {\n\t\t\t\tns_of_pid(pid)->child_reaper = p;\n\t\t\t\tp->signal->flags |= SIGNAL_UNKILLABLE;\n\t\t\t}\n\n\t\t\tp->signal->leader_pid = pid;\n\t\t\tp->signal->tty = tty_kref_get(current->signal->tty);\n\t\t\tattach_pid(p, PIDTYPE_PGID, task_pgrp(current));\n\t\t\tattach_pid(p, PIDTYPE_SID, task_session(current));\n\t\t\tlist_add_tail(&p->sibling, &p->real_parent->children);\n\t\t\tlist_add_tail_rcu(&p->tasks, &init_task.tasks);\n\t\t\t__this_cpu_inc(process_counts);\n\t\t}\n\t\tattach_pid(p, PIDTYPE_PID, pid);\n\t\tnr_threads++;\n\t}\n\n\ttotal_forks++;\n\tspin_unlock(&current->sighand->siglock);\n\twrite_unlock_irq(&tasklist_lock);\n\tproc_fork_connector(p);\n\tcgroup_post_fork(p);\n\tif (clone_flags & CLONE_THREAD)\n\t\tthreadgroup_change_end(current);\n\tperf_event_fork(p);\n\n\ttrace_task_newtask(p, clone_flags);\n\n\treturn p;\n\nbad_fork_free_pid:\n\tif (pid != &init_struct_pid)\n\t\tfree_pid(pid);\nbad_fork_cleanup_io:\n\tif (p->io_context)\n\t\texit_io_context(p);\nbad_fork_cleanup_namespaces:\n\texit_task_namespaces(p);\nbad_fork_cleanup_mm:\n\tif (p->mm)\n\t\tmmput(p->mm);\nbad_fork_cleanup_signal:\n\tif (!(clone_flags & CLONE_THREAD))\n\t\tfree_signal_struct(p->signal);\nbad_fork_cleanup_sighand:\n\t__cleanup_sighand(p->sighand);\nbad_fork_cleanup_fs:\n\texit_fs(p); /* blocking */\nbad_fork_cleanup_files:\n\texit_files(p); /* blocking */\nbad_fork_cleanup_semundo:\n\texit_sem(p);\nbad_fork_cleanup_audit:\n\taudit_free(p);\nbad_fork_cleanup_policy:\n\tperf_event_free_task(p);\n#ifdef CONFIG_NUMA\n\tmpol_put(p->mempolicy);\nbad_fork_cleanup_cgroup:\n#endif\n\tif (clone_flags & CLONE_THREAD)\n\t\tthreadgroup_change_end(current);\n\tcgroup_exit(p, 0);\n\tdelayacct_tsk_free(p);\n\tmodule_put(task_thread_info(p)->exec_domain->module);\nbad_fork_cleanup_count:\n\tatomic_dec(&p->cred->user->processes);\n\texit_creds(p);\nbad_fork_free:\n\tfree_task(p);\nfork_out:\n\treturn ERR_PTR(retval);\n}",
        "func": "static struct task_struct *copy_process(unsigned long clone_flags,\n\t\t\t\t\tunsigned long stack_start,\n\t\t\t\t\tunsigned long stack_size,\n\t\t\t\t\tint __user *child_tidptr,\n\t\t\t\t\tstruct pid *pid,\n\t\t\t\t\tint trace)\n{\n\tint retval;\n\tstruct task_struct *p;\n\n\tif ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tif ((clone_flags & (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * Thread groups must share signals as well, and detached threads\n\t * can only be started up within the thread group.\n\t */\n\tif ((clone_flags & CLONE_THREAD) && !(clone_flags & CLONE_SIGHAND))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * Shared signal handlers imply shared VM. By way of the above,\n\t * thread groups also imply shared VM. Blocking this case allows\n\t * for various simplifications in other code.\n\t */\n\tif ((clone_flags & CLONE_SIGHAND) && !(clone_flags & CLONE_VM))\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * Siblings of global init remain as zombies on exit since they are\n\t * not reaped by their parent (swapper). To solve this and to avoid\n\t * multi-rooted process trees, prevent global and container-inits\n\t * from creating siblings.\n\t */\n\tif ((clone_flags & CLONE_PARENT) &&\n\t\t\t\tcurrent->signal->flags & SIGNAL_UNKILLABLE)\n\t\treturn ERR_PTR(-EINVAL);\n\n\t/*\n\t * If the new process will be in a different pid namespace\n\t * don't allow the creation of threads.\n\t */\n\tif ((clone_flags & (CLONE_VM|CLONE_NEWPID)) &&\n\t    (task_active_pid_ns(current) != current->nsproxy->pid_ns))\n\t\treturn ERR_PTR(-EINVAL);\n\n\tretval = security_task_create(clone_flags);\n\tif (retval)\n\t\tgoto fork_out;\n\n\tretval = -ENOMEM;\n\tp = dup_task_struct(current);\n\tif (!p)\n\t\tgoto fork_out;\n\n\tftrace_graph_init_task(p);\n\tget_seccomp_filter(p);\n\n\trt_mutex_init_task(p);\n\n#ifdef CONFIG_PROVE_LOCKING\n\tDEBUG_LOCKS_WARN_ON(!p->hardirqs_enabled);\n\tDEBUG_LOCKS_WARN_ON(!p->softirqs_enabled);\n#endif\n\tretval = -EAGAIN;\n\tif (atomic_read(&p->real_cred->user->processes) >=\n\t\t\ttask_rlimit(p, RLIMIT_NPROC)) {\n\t\tif (!capable(CAP_SYS_ADMIN) && !capable(CAP_SYS_RESOURCE) &&\n\t\t    p->real_cred->user != INIT_USER)\n\t\t\tgoto bad_fork_free;\n\t}\n\tcurrent->flags &= ~PF_NPROC_EXCEEDED;\n\n\tretval = copy_creds(p, clone_flags);\n\tif (retval < 0)\n\t\tgoto bad_fork_free;\n\n\t/*\n\t * If multiple threads are within copy_process(), then this check\n\t * triggers too late. This doesn't hurt, the check is only there\n\t * to stop root fork bombs.\n\t */\n\tretval = -EAGAIN;\n\tif (nr_threads >= max_threads)\n\t\tgoto bad_fork_cleanup_count;\n\n\tif (!try_module_get(task_thread_info(p)->exec_domain->module))\n\t\tgoto bad_fork_cleanup_count;\n\n\tp->did_exec = 0;\n\tdelayacct_tsk_init(p);\t/* Must remain after dup_task_struct() */\n\tcopy_flags(clone_flags, p);\n\tINIT_LIST_HEAD(&p->children);\n\tINIT_LIST_HEAD(&p->sibling);\n\trcu_copy_process(p);\n\tp->vfork_done = NULL;\n\tspin_lock_init(&p->alloc_lock);\n\n\tinit_sigpending(&p->pending);\n\n\tp->utime = p->stime = p->gtime = 0;\n\tp->utimescaled = p->stimescaled = 0;\n#ifndef CONFIG_VIRT_CPU_ACCOUNTING\n\tp->prev_cputime.utime = p->prev_cputime.stime = 0;\n#endif\n#ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN\n\tseqlock_init(&p->vtime_seqlock);\n\tp->vtime_snap = 0;\n\tp->vtime_snap_whence = VTIME_SLEEPING;\n#endif\n\n#if defined(SPLIT_RSS_COUNTING)\n\tmemset(&p->rss_stat, 0, sizeof(p->rss_stat));\n#endif\n\n\tp->default_timer_slack_ns = current->timer_slack_ns;\n\n\ttask_io_accounting_init(&p->ioac);\n\tacct_clear_integrals(p);\n\n\tposix_cpu_timers_init(p);\n\n\tdo_posix_clock_monotonic_gettime(&p->start_time);\n\tp->real_start_time = p->start_time;\n\tmonotonic_to_bootbased(&p->real_start_time);\n\tp->io_context = NULL;\n\tp->audit_context = NULL;\n\tif (clone_flags & CLONE_THREAD)\n\t\tthreadgroup_change_begin(current);\n\tcgroup_fork(p);\n#ifdef CONFIG_NUMA\n\tp->mempolicy = mpol_dup(p->mempolicy);\n\tif (IS_ERR(p->mempolicy)) {\n\t\tretval = PTR_ERR(p->mempolicy);\n\t\tp->mempolicy = NULL;\n\t\tgoto bad_fork_cleanup_cgroup;\n\t}\n\tmpol_fix_fork_child_flag(p);\n#endif\n#ifdef CONFIG_CPUSETS\n\tp->cpuset_mem_spread_rotor = NUMA_NO_NODE;\n\tp->cpuset_slab_spread_rotor = NUMA_NO_NODE;\n\tseqcount_init(&p->mems_allowed_seq);\n#endif\n#ifdef CONFIG_TRACE_IRQFLAGS\n\tp->irq_events = 0;\n\tp->hardirqs_enabled = 0;\n\tp->hardirq_enable_ip = 0;\n\tp->hardirq_enable_event = 0;\n\tp->hardirq_disable_ip = _THIS_IP_;\n\tp->hardirq_disable_event = 0;\n\tp->softirqs_enabled = 1;\n\tp->softirq_enable_ip = _THIS_IP_;\n\tp->softirq_enable_event = 0;\n\tp->softirq_disable_ip = 0;\n\tp->softirq_disable_event = 0;\n\tp->hardirq_context = 0;\n\tp->softirq_context = 0;\n#endif\n#ifdef CONFIG_LOCKDEP\n\tp->lockdep_depth = 0; /* no locks held yet */\n\tp->curr_chain_key = 0;\n\tp->lockdep_recursion = 0;\n#endif\n\n#ifdef CONFIG_DEBUG_MUTEXES\n\tp->blocked_on = NULL; /* not blocked yet */\n#endif\n#ifdef CONFIG_MEMCG\n\tp->memcg_batch.do_batch = 0;\n\tp->memcg_batch.memcg = NULL;\n#endif\n\n\t/* Perform scheduler related setup. Assign this task to a CPU. */\n\tsched_fork(p);\n\n\tretval = perf_event_init_task(p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_policy;\n\tretval = audit_alloc(p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_policy;\n\t/* copy all the process information */\n\tretval = copy_semundo(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_audit;\n\tretval = copy_files(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_semundo;\n\tretval = copy_fs(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_files;\n\tretval = copy_sighand(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_fs;\n\tretval = copy_signal(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_sighand;\n\tretval = copy_mm(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_signal;\n\tretval = copy_namespaces(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_mm;\n\tretval = copy_io(clone_flags, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_namespaces;\n\tretval = copy_thread(clone_flags, stack_start, stack_size, p);\n\tif (retval)\n\t\tgoto bad_fork_cleanup_io;\n\n\tif (pid != &init_struct_pid) {\n\t\tretval = -ENOMEM;\n\t\tpid = alloc_pid(p->nsproxy->pid_ns);\n\t\tif (!pid)\n\t\t\tgoto bad_fork_cleanup_io;\n\t}\n\n\tp->pid = pid_nr(pid);\n\tp->tgid = p->pid;\n\tif (clone_flags & CLONE_THREAD)\n\t\tp->tgid = current->tgid;\n\n\tp->set_child_tid = (clone_flags & CLONE_CHILD_SETTID) ? child_tidptr : NULL;\n\t/*\n\t * Clear TID on mm_release()?\n\t */\n\tp->clear_child_tid = (clone_flags & CLONE_CHILD_CLEARTID) ? child_tidptr : NULL;\n#ifdef CONFIG_BLOCK\n\tp->plug = NULL;\n#endif\n#ifdef CONFIG_FUTEX\n\tp->robust_list = NULL;\n#ifdef CONFIG_COMPAT\n\tp->compat_robust_list = NULL;\n#endif\n\tINIT_LIST_HEAD(&p->pi_state_list);\n\tp->pi_state_cache = NULL;\n#endif\n\tuprobe_copy_process(p);\n\t/*\n\t * sigaltstack should be cleared when sharing the same VM\n\t */\n\tif ((clone_flags & (CLONE_VM|CLONE_VFORK)) == CLONE_VM)\n\t\tp->sas_ss_sp = p->sas_ss_size = 0;\n\n\t/*\n\t * Syscall tracing and stepping should be turned off in the\n\t * child regardless of CLONE_PTRACE.\n\t */\n\tuser_disable_single_step(p);\n\tclear_tsk_thread_flag(p, TIF_SYSCALL_TRACE);\n#ifdef TIF_SYSCALL_EMU\n\tclear_tsk_thread_flag(p, TIF_SYSCALL_EMU);\n#endif\n\tclear_all_latency_tracing(p);\n\n\t/* ok, now we should be set up.. */\n\tif (clone_flags & CLONE_THREAD)\n\t\tp->exit_signal = -1;\n\telse if (clone_flags & CLONE_PARENT)\n\t\tp->exit_signal = current->group_leader->exit_signal;\n\telse\n\t\tp->exit_signal = (clone_flags & CSIGNAL);\n\n\tp->pdeath_signal = 0;\n\tp->exit_state = 0;\n\n\tp->nr_dirtied = 0;\n\tp->nr_dirtied_pause = 128 >> (PAGE_SHIFT - 10);\n\tp->dirty_paused_when = 0;\n\n\t/*\n\t * Ok, make it visible to the rest of the system.\n\t * We dont wake it up yet.\n\t */\n\tp->group_leader = p;\n\tINIT_LIST_HEAD(&p->thread_group);\n\tp->task_works = NULL;\n\n\t/* Need tasklist lock for parent etc handling! */\n\twrite_lock_irq(&tasklist_lock);\n\n\t/* CLONE_PARENT re-uses the old parent */\n\tif (clone_flags & (CLONE_PARENT|CLONE_THREAD)) {\n\t\tp->real_parent = current->real_parent;\n\t\tp->parent_exec_id = current->parent_exec_id;\n\t} else {\n\t\tp->real_parent = current;\n\t\tp->parent_exec_id = current->self_exec_id;\n\t}\n\n\tspin_lock(&current->sighand->siglock);\n\n\t/*\n\t * Process group and session signals need to be delivered to just the\n\t * parent before the fork or both the parent and the child after the\n\t * fork. Restart if a signal comes in before we add the new process to\n\t * it's process group.\n\t * A fatal signal pending means that current will exit, so the new\n\t * thread can't slip out of an OOM kill (or normal SIGKILL).\n\t*/\n\trecalc_sigpending();\n\tif (signal_pending(current)) {\n\t\tspin_unlock(&current->sighand->siglock);\n\t\twrite_unlock_irq(&tasklist_lock);\n\t\tretval = -ERESTARTNOINTR;\n\t\tgoto bad_fork_free_pid;\n\t}\n\n\tif (clone_flags & CLONE_THREAD) {\n\t\tcurrent->signal->nr_threads++;\n\t\tatomic_inc(&current->signal->live);\n\t\tatomic_inc(&current->signal->sigcnt);\n\t\tp->group_leader = current->group_leader;\n\t\tlist_add_tail_rcu(&p->thread_group, &p->group_leader->thread_group);\n\t}\n\n\tif (likely(p->pid)) {\n\t\tptrace_init_task(p, (clone_flags & CLONE_PTRACE) || trace);\n\n\t\tif (thread_group_leader(p)) {\n\t\t\tif (is_child_reaper(pid)) {\n\t\t\t\tns_of_pid(pid)->child_reaper = p;\n\t\t\t\tp->signal->flags |= SIGNAL_UNKILLABLE;\n\t\t\t}\n\n\t\t\tp->signal->leader_pid = pid;\n\t\t\tp->signal->tty = tty_kref_get(current->signal->tty);\n\t\t\tattach_pid(p, PIDTYPE_PGID, task_pgrp(current));\n\t\t\tattach_pid(p, PIDTYPE_SID, task_session(current));\n\t\t\tlist_add_tail(&p->sibling, &p->real_parent->children);\n\t\t\tlist_add_tail_rcu(&p->tasks, &init_task.tasks);\n\t\t\t__this_cpu_inc(process_counts);\n\t\t}\n\t\tattach_pid(p, PIDTYPE_PID, pid);\n\t\tnr_threads++;\n\t}\n\n\ttotal_forks++;\n\tspin_unlock(&current->sighand->siglock);\n\twrite_unlock_irq(&tasklist_lock);\n\tproc_fork_connector(p);\n\tcgroup_post_fork(p);\n\tif (clone_flags & CLONE_THREAD)\n\t\tthreadgroup_change_end(current);\n\tperf_event_fork(p);\n\n\ttrace_task_newtask(p, clone_flags);\n\n\treturn p;\n\nbad_fork_free_pid:\n\tif (pid != &init_struct_pid)\n\t\tfree_pid(pid);\nbad_fork_cleanup_io:\n\tif (p->io_context)\n\t\texit_io_context(p);\nbad_fork_cleanup_namespaces:\n\texit_task_namespaces(p);\nbad_fork_cleanup_mm:\n\tif (p->mm)\n\t\tmmput(p->mm);\nbad_fork_cleanup_signal:\n\tif (!(clone_flags & CLONE_THREAD))\n\t\tfree_signal_struct(p->signal);\nbad_fork_cleanup_sighand:\n\t__cleanup_sighand(p->sighand);\nbad_fork_cleanup_fs:\n\texit_fs(p); /* blocking */\nbad_fork_cleanup_files:\n\texit_files(p); /* blocking */\nbad_fork_cleanup_semundo:\n\texit_sem(p);\nbad_fork_cleanup_audit:\n\taudit_free(p);\nbad_fork_cleanup_policy:\n\tperf_event_free_task(p);\n#ifdef CONFIG_NUMA\n\tmpol_put(p->mempolicy);\nbad_fork_cleanup_cgroup:\n#endif\n\tif (clone_flags & CLONE_THREAD)\n\t\tthreadgroup_change_end(current);\n\tcgroup_exit(p, 0);\n\tdelayacct_tsk_free(p);\n\tmodule_put(task_thread_info(p)->exec_domain->module);\nbad_fork_cleanup_count:\n\tatomic_dec(&p->cred->user->processes);\n\texit_creds(p);\nbad_fork_free:\n\tfree_task(p);\nfork_out:\n\treturn ERR_PTR(retval);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,9 @@\n \tstruct task_struct *p;\n \n \tif ((clone_flags & (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))\n+\t\treturn ERR_PTR(-EINVAL);\n+\n+\tif ((clone_flags & (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))\n \t\treturn ERR_PTR(-EINVAL);\n \n \t/*",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\treturn ERR_PTR(-EINVAL);",
                "",
                "\tif ((clone_flags & (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1858",
        "func_name": "torvalds/linux/userns_install",
        "description": "The clone system-call implementation in the Linux kernel before 3.8.3 does not properly handle a combination of the CLONE_NEWUSER and CLONE_FS flags, which allows local users to gain privileges by calling chroot and leveraging the sharing of the / directory between a parent process and a child process.",
        "git_url": "https://github.com/torvalds/linux/commit/e66eded8309ebf679d3d3c1f5820d1f2ca332c71",
        "commit_title": "userns: Don't allow CLONE_NEWUSER | CLONE_FS",
        "commit_text": " Don't allowing sharing the root directory with processes in a different user namespace.  There doesn't seem to be any point, and to allow it would require the overhead of putting a user namespace reference in fs_struct (for permission checks) and incrementing that reference count on practically every call to fork.  So just perform the inexpensive test of forbidding sharing fs_struct acrosss processes in different user namespaces.  We already disallow other forms of threading when unsharing a user namespace so this should be no real burden in practice.  This updates setns, clone, and unshare to disallow multiple user namespaces sharing an fs_struct.  Cc: stable@vger.kernel.org",
        "func_before": "static int userns_install(struct nsproxy *nsproxy, void *ns)\n{\n\tstruct user_namespace *user_ns = ns;\n\tstruct cred *cred;\n\n\t/* Don't allow gaining capabilities by reentering\n\t * the same user namespace.\n\t */\n\tif (user_ns == current_user_ns())\n\t\treturn -EINVAL;\n\n\t/* Threaded processes may not enter a different user namespace */\n\tif (atomic_read(&current->mm->mm_users) > 1)\n\t\treturn -EINVAL;\n\n\tif (!ns_capable(user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcred = prepare_creds();\n\tif (!cred)\n\t\treturn -ENOMEM;\n\n\tput_user_ns(cred->user_ns);\n\tset_cred_user_ns(cred, get_user_ns(user_ns));\n\n\treturn commit_creds(cred);\n}",
        "func": "static int userns_install(struct nsproxy *nsproxy, void *ns)\n{\n\tstruct user_namespace *user_ns = ns;\n\tstruct cred *cred;\n\n\t/* Don't allow gaining capabilities by reentering\n\t * the same user namespace.\n\t */\n\tif (user_ns == current_user_ns())\n\t\treturn -EINVAL;\n\n\t/* Threaded processes may not enter a different user namespace */\n\tif (atomic_read(&current->mm->mm_users) > 1)\n\t\treturn -EINVAL;\n\n\tif (current->fs->users != 1)\n\t\treturn -EINVAL;\n\n\tif (!ns_capable(user_ns, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tcred = prepare_creds();\n\tif (!cred)\n\t\treturn -ENOMEM;\n\n\tput_user_ns(cred->user_ns);\n\tset_cred_user_ns(cred, get_user_ns(user_ns));\n\n\treturn commit_creds(cred);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,9 @@\n \tif (atomic_read(&current->mm->mm_users) > 1)\n \t\treturn -EINVAL;\n \n+\tif (current->fs->users != 1)\n+\t\treturn -EINVAL;\n+\n \tif (!ns_capable(user_ns, CAP_SYS_ADMIN))\n \t\treturn -EPERM;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (current->fs->users != 1)",
                "\t\treturn -EINVAL;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1956",
        "func_name": "torvalds/linux/create_user_ns",
        "description": "The create_user_ns function in kernel/user_namespace.c in the Linux kernel before 3.8.6 does not check whether a chroot directory exists that differs from the namespace root directory, which allows local users to bypass intended filesystem restrictions via a crafted clone system call.",
        "git_url": "https://github.com/torvalds/linux/commit/3151527ee007b73a0ebd296010f1c0454a919c7d",
        "commit_title": "userns:  Don't allow creation if the user is chrooted",
        "commit_text": " Guarantee that the policy of which files may be access that is established by setting the root directory will not be violated by user namespaces by verifying that the root directory points to the root of the mount namespace at the time of user namespace creation.  Changing the root is a privileged operation, and as a matter of policy it serves to limit unprivileged processes to files below the current root directory.  For reasons of simplicity and comprehensibility the privilege to change the root directory is gated solely on the CAP_SYS_CHROOT capability in the user namespace.  Therefore when creating a user namespace we must ensure that the policy of which files may be access can not be violated by changing the root directory.  Anyone who runs a processes in a chroot and would like to use user namespace can setup the same view of filesystems with a mount namespace instead.  With this result that this is not a practical limitation for using user namespaces.  Cc: stable@vger.kernel.org",
        "func_before": "int create_user_ns(struct cred *new)\n{\n\tstruct user_namespace *ns, *parent_ns = new->user_ns;\n\tkuid_t owner = new->euid;\n\tkgid_t group = new->egid;\n\tint ret;\n\n\t/* The creator needs a mapping in the parent user namespace\n\t * or else we won't be able to reasonably tell userspace who\n\t * created a user_namespace.\n\t */\n\tif (!kuid_has_mapping(parent_ns, owner) ||\n\t    !kgid_has_mapping(parent_ns, group))\n\t\treturn -EPERM;\n\n\tns = kmem_cache_zalloc(user_ns_cachep, GFP_KERNEL);\n\tif (!ns)\n\t\treturn -ENOMEM;\n\n\tret = proc_alloc_inum(&ns->proc_inum);\n\tif (ret) {\n\t\tkmem_cache_free(user_ns_cachep, ns);\n\t\treturn ret;\n\t}\n\n\tatomic_set(&ns->count, 1);\n\t/* Leave the new->user_ns reference with the new user namespace. */\n\tns->parent = parent_ns;\n\tns->owner = owner;\n\tns->group = group;\n\n\tset_cred_user_ns(new, ns);\n\n\treturn 0;\n}",
        "func": "int create_user_ns(struct cred *new)\n{\n\tstruct user_namespace *ns, *parent_ns = new->user_ns;\n\tkuid_t owner = new->euid;\n\tkgid_t group = new->egid;\n\tint ret;\n\n\t/*\n\t * Verify that we can not violate the policy of which files\n\t * may be accessed that is specified by the root directory,\n\t * by verifing that the root directory is at the root of the\n\t * mount namespace which allows all files to be accessed.\n\t */\n\tif (current_chrooted())\n\t\treturn -EPERM;\n\n\t/* The creator needs a mapping in the parent user namespace\n\t * or else we won't be able to reasonably tell userspace who\n\t * created a user_namespace.\n\t */\n\tif (!kuid_has_mapping(parent_ns, owner) ||\n\t    !kgid_has_mapping(parent_ns, group))\n\t\treturn -EPERM;\n\n\tns = kmem_cache_zalloc(user_ns_cachep, GFP_KERNEL);\n\tif (!ns)\n\t\treturn -ENOMEM;\n\n\tret = proc_alloc_inum(&ns->proc_inum);\n\tif (ret) {\n\t\tkmem_cache_free(user_ns_cachep, ns);\n\t\treturn ret;\n\t}\n\n\tatomic_set(&ns->count, 1);\n\t/* Leave the new->user_ns reference with the new user namespace. */\n\tns->parent = parent_ns;\n\tns->owner = owner;\n\tns->group = group;\n\n\tset_cred_user_ns(new, ns);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,15 @@\n \tkuid_t owner = new->euid;\n \tkgid_t group = new->egid;\n \tint ret;\n+\n+\t/*\n+\t * Verify that we can not violate the policy of which files\n+\t * may be accessed that is specified by the root directory,\n+\t * by verifing that the root directory is at the root of the\n+\t * mount namespace which allows all files to be accessed.\n+\t */\n+\tif (current_chrooted())\n+\t\treturn -EPERM;\n \n \t/* The creator needs a mapping in the parent user namespace\n \t * or else we won't be able to reasonably tell userspace who",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/*",
                "\t * Verify that we can not violate the policy of which files",
                "\t * may be accessed that is specified by the root directory,",
                "\t * by verifing that the root directory is at the root of the",
                "\t * mount namespace which allows all files to be accessed.",
                "\t */",
                "\tif (current_chrooted())",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1957",
        "func_name": "torvalds/linux/propagate_mnt",
        "description": "The clone_mnt function in fs/namespace.c in the Linux kernel before 3.8.6 does not properly restrict changes to the MNT_READONLY flag, which allows local users to bypass an intended read-only property of a filesystem by leveraging a separate mount namespace.",
        "git_url": "https://github.com/torvalds/linux/commit/132c94e31b8bca8ea921f9f96a57d684fa4ae0a9",
        "commit_title": "vfs: Carefully propogate mounts across user namespaces",
        "commit_text": " As a matter of policy MNT_READONLY should not be changable if the original mounter had more privileges than creator of the mount namespace.  Add the flag CL_UNPRIVILEGED to note when we are copying a mount from a mount namespace that requires more privileges to a mount namespace that requires fewer privileges.  When the CL_UNPRIVILEGED flag is set cause clone_mnt to set MNT_NO_REMOUNT if any of the mnt flags that should never be changed are set.  This protects both mount propagation and the initial creation of a less privileged mount namespace.  Cc: stable@vger.kernel.org",
        "func_before": "int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,\n\t\t    struct mount *source_mnt, struct list_head *tree_list)\n{\n\tstruct mount *m, *child;\n\tint ret = 0;\n\tstruct mount *prev_dest_mnt = dest_mnt;\n\tstruct mount *prev_src_mnt  = source_mnt;\n\tLIST_HEAD(tmp_list);\n\tLIST_HEAD(umount_list);\n\n\tfor (m = propagation_next(dest_mnt, dest_mnt); m;\n\t\t\tm = propagation_next(m, dest_mnt)) {\n\t\tint type;\n\t\tstruct mount *source;\n\n\t\tif (IS_MNT_NEW(m))\n\t\t\tcontinue;\n\n\t\tsource =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);\n\n\t\tchild = copy_tree(source, source->mnt.mnt_root, type);\n\t\tif (IS_ERR(child)) {\n\t\t\tret = PTR_ERR(child);\n\t\t\tlist_splice(tree_list, tmp_list.prev);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (is_subdir(dest_dentry, m->mnt.mnt_root)) {\n\t\t\tmnt_set_mountpoint(m, dest_dentry, child);\n\t\t\tlist_add_tail(&child->mnt_hash, tree_list);\n\t\t} else {\n\t\t\t/*\n\t\t\t * This can happen if the parent mount was bind mounted\n\t\t\t * on some subdirectory of a shared/slave mount.\n\t\t\t */\n\t\t\tlist_add_tail(&child->mnt_hash, &tmp_list);\n\t\t}\n\t\tprev_dest_mnt = m;\n\t\tprev_src_mnt  = child;\n\t}\nout:\n\tbr_write_lock(&vfsmount_lock);\n\twhile (!list_empty(&tmp_list)) {\n\t\tchild = list_first_entry(&tmp_list, struct mount, mnt_hash);\n\t\tumount_tree(child, 0, &umount_list);\n\t}\n\tbr_write_unlock(&vfsmount_lock);\n\trelease_mounts(&umount_list);\n\treturn ret;\n}",
        "func": "int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,\n\t\t    struct mount *source_mnt, struct list_head *tree_list)\n{\n\tstruct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;\n\tstruct mount *m, *child;\n\tint ret = 0;\n\tstruct mount *prev_dest_mnt = dest_mnt;\n\tstruct mount *prev_src_mnt  = source_mnt;\n\tLIST_HEAD(tmp_list);\n\tLIST_HEAD(umount_list);\n\n\tfor (m = propagation_next(dest_mnt, dest_mnt); m;\n\t\t\tm = propagation_next(m, dest_mnt)) {\n\t\tint type;\n\t\tstruct mount *source;\n\n\t\tif (IS_MNT_NEW(m))\n\t\t\tcontinue;\n\n\t\tsource =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);\n\n\t\t/* Notice when we are propagating across user namespaces */\n\t\tif (m->mnt_ns->user_ns != user_ns)\n\t\t\ttype |= CL_UNPRIVILEGED;\n\n\t\tchild = copy_tree(source, source->mnt.mnt_root, type);\n\t\tif (IS_ERR(child)) {\n\t\t\tret = PTR_ERR(child);\n\t\t\tlist_splice(tree_list, tmp_list.prev);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (is_subdir(dest_dentry, m->mnt.mnt_root)) {\n\t\t\tmnt_set_mountpoint(m, dest_dentry, child);\n\t\t\tlist_add_tail(&child->mnt_hash, tree_list);\n\t\t} else {\n\t\t\t/*\n\t\t\t * This can happen if the parent mount was bind mounted\n\t\t\t * on some subdirectory of a shared/slave mount.\n\t\t\t */\n\t\t\tlist_add_tail(&child->mnt_hash, &tmp_list);\n\t\t}\n\t\tprev_dest_mnt = m;\n\t\tprev_src_mnt  = child;\n\t}\nout:\n\tbr_write_lock(&vfsmount_lock);\n\twhile (!list_empty(&tmp_list)) {\n\t\tchild = list_first_entry(&tmp_list, struct mount, mnt_hash);\n\t\tumount_tree(child, 0, &umount_list);\n\t}\n\tbr_write_unlock(&vfsmount_lock);\n\trelease_mounts(&umount_list);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n int propagate_mnt(struct mount *dest_mnt, struct dentry *dest_dentry,\n \t\t    struct mount *source_mnt, struct list_head *tree_list)\n {\n+\tstruct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;\n \tstruct mount *m, *child;\n \tint ret = 0;\n \tstruct mount *prev_dest_mnt = dest_mnt;\n@@ -17,6 +18,10 @@\n \t\t\tcontinue;\n \n \t\tsource =  get_source(m, prev_dest_mnt, prev_src_mnt, &type);\n+\n+\t\t/* Notice when we are propagating across user namespaces */\n+\t\tif (m->mnt_ns->user_ns != user_ns)\n+\t\t\ttype |= CL_UNPRIVILEGED;\n \n \t\tchild = copy_tree(source, source->mnt.mnt_root, type);\n \t\tif (IS_ERR(child)) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tstruct user_namespace *user_ns = current->nsproxy->mnt_ns->user_ns;",
                "",
                "\t\t/* Notice when we are propagating across user namespaces */",
                "\t\tif (m->mnt_ns->user_ns != user_ns)",
                "\t\t\ttype |= CL_UNPRIVILEGED;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1957",
        "func_name": "torvalds/linux/clone_mnt",
        "description": "The clone_mnt function in fs/namespace.c in the Linux kernel before 3.8.6 does not properly restrict changes to the MNT_READONLY flag, which allows local users to bypass an intended read-only property of a filesystem by leveraging a separate mount namespace.",
        "git_url": "https://github.com/torvalds/linux/commit/132c94e31b8bca8ea921f9f96a57d684fa4ae0a9",
        "commit_title": "vfs: Carefully propogate mounts across user namespaces",
        "commit_text": " As a matter of policy MNT_READONLY should not be changable if the original mounter had more privileges than creator of the mount namespace.  Add the flag CL_UNPRIVILEGED to note when we are copying a mount from a mount namespace that requires more privileges to a mount namespace that requires fewer privileges.  When the CL_UNPRIVILEGED flag is set cause clone_mnt to set MNT_NO_REMOUNT if any of the mnt flags that should never be changed are set.  This protects both mount propagation and the initial creation of a less privileged mount namespace.  Cc: stable@vger.kernel.org",
        "func_before": "static struct mount *clone_mnt(struct mount *old, struct dentry *root,\n\t\t\t\t\tint flag)\n{\n\tstruct super_block *sb = old->mnt.mnt_sb;\n\tstruct mount *mnt;\n\tint err;\n\n\tmnt = alloc_vfsmnt(old->mnt_devname);\n\tif (!mnt)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (flag & (CL_SLAVE | CL_PRIVATE | CL_SHARED_TO_SLAVE))\n\t\tmnt->mnt_group_id = 0; /* not a peer of original */\n\telse\n\t\tmnt->mnt_group_id = old->mnt_group_id;\n\n\tif ((flag & CL_MAKE_SHARED) && !mnt->mnt_group_id) {\n\t\terr = mnt_alloc_group_id(mnt);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t}\n\n\tmnt->mnt.mnt_flags = old->mnt.mnt_flags & ~MNT_WRITE_HOLD;\n\tatomic_inc(&sb->s_active);\n\tmnt->mnt.mnt_sb = sb;\n\tmnt->mnt.mnt_root = dget(root);\n\tmnt->mnt_mountpoint = mnt->mnt.mnt_root;\n\tmnt->mnt_parent = mnt;\n\tbr_write_lock(&vfsmount_lock);\n\tlist_add_tail(&mnt->mnt_instance, &sb->s_mounts);\n\tbr_write_unlock(&vfsmount_lock);\n\n\tif ((flag & CL_SLAVE) ||\n\t    ((flag & CL_SHARED_TO_SLAVE) && IS_MNT_SHARED(old))) {\n\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave_list);\n\t\tmnt->mnt_master = old;\n\t\tCLEAR_MNT_SHARED(mnt);\n\t} else if (!(flag & CL_PRIVATE)) {\n\t\tif ((flag & CL_MAKE_SHARED) || IS_MNT_SHARED(old))\n\t\t\tlist_add(&mnt->mnt_share, &old->mnt_share);\n\t\tif (IS_MNT_SLAVE(old))\n\t\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave);\n\t\tmnt->mnt_master = old->mnt_master;\n\t}\n\tif (flag & CL_MAKE_SHARED)\n\t\tset_mnt_shared(mnt);\n\n\t/* stick the duplicate mount on the same expiry list\n\t * as the original if that was on one */\n\tif (flag & CL_EXPIRE) {\n\t\tif (!list_empty(&old->mnt_expire))\n\t\t\tlist_add(&mnt->mnt_expire, &old->mnt_expire);\n\t}\n\n\treturn mnt;\n\n out_free:\n\tfree_vfsmnt(mnt);\n\treturn ERR_PTR(err);\n}",
        "func": "static struct mount *clone_mnt(struct mount *old, struct dentry *root,\n\t\t\t\t\tint flag)\n{\n\tstruct super_block *sb = old->mnt.mnt_sb;\n\tstruct mount *mnt;\n\tint err;\n\n\tmnt = alloc_vfsmnt(old->mnt_devname);\n\tif (!mnt)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tif (flag & (CL_SLAVE | CL_PRIVATE | CL_SHARED_TO_SLAVE))\n\t\tmnt->mnt_group_id = 0; /* not a peer of original */\n\telse\n\t\tmnt->mnt_group_id = old->mnt_group_id;\n\n\tif ((flag & CL_MAKE_SHARED) && !mnt->mnt_group_id) {\n\t\terr = mnt_alloc_group_id(mnt);\n\t\tif (err)\n\t\t\tgoto out_free;\n\t}\n\n\tmnt->mnt.mnt_flags = old->mnt.mnt_flags & ~MNT_WRITE_HOLD;\n\t/* Don't allow unprivileged users to change mount flags */\n\tif ((flag & CL_UNPRIVILEGED) && (mnt->mnt.mnt_flags & MNT_READONLY))\n\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;\n\n\tatomic_inc(&sb->s_active);\n\tmnt->mnt.mnt_sb = sb;\n\tmnt->mnt.mnt_root = dget(root);\n\tmnt->mnt_mountpoint = mnt->mnt.mnt_root;\n\tmnt->mnt_parent = mnt;\n\tbr_write_lock(&vfsmount_lock);\n\tlist_add_tail(&mnt->mnt_instance, &sb->s_mounts);\n\tbr_write_unlock(&vfsmount_lock);\n\n\tif ((flag & CL_SLAVE) ||\n\t    ((flag & CL_SHARED_TO_SLAVE) && IS_MNT_SHARED(old))) {\n\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave_list);\n\t\tmnt->mnt_master = old;\n\t\tCLEAR_MNT_SHARED(mnt);\n\t} else if (!(flag & CL_PRIVATE)) {\n\t\tif ((flag & CL_MAKE_SHARED) || IS_MNT_SHARED(old))\n\t\t\tlist_add(&mnt->mnt_share, &old->mnt_share);\n\t\tif (IS_MNT_SLAVE(old))\n\t\t\tlist_add(&mnt->mnt_slave, &old->mnt_slave);\n\t\tmnt->mnt_master = old->mnt_master;\n\t}\n\tif (flag & CL_MAKE_SHARED)\n\t\tset_mnt_shared(mnt);\n\n\t/* stick the duplicate mount on the same expiry list\n\t * as the original if that was on one */\n\tif (flag & CL_EXPIRE) {\n\t\tif (!list_empty(&old->mnt_expire))\n\t\t\tlist_add(&mnt->mnt_expire, &old->mnt_expire);\n\t}\n\n\treturn mnt;\n\n out_free:\n\tfree_vfsmnt(mnt);\n\treturn ERR_PTR(err);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,10 @@\n \t}\n \n \tmnt->mnt.mnt_flags = old->mnt.mnt_flags & ~MNT_WRITE_HOLD;\n+\t/* Don't allow unprivileged users to change mount flags */\n+\tif ((flag & CL_UNPRIVILEGED) && (mnt->mnt.mnt_flags & MNT_READONLY))\n+\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;\n+\n \tatomic_inc(&sb->s_active);\n \tmnt->mnt.mnt_sb = sb;\n \tmnt->mnt.mnt_root = dget(root);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Don't allow unprivileged users to change mount flags */",
                "\tif ((flag & CL_UNPRIVILEGED) && (mnt->mnt.mnt_flags & MNT_READONLY))",
                "\t\tmnt->mnt.mnt_flags |= MNT_LOCK_READONLY;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1957",
        "func_name": "torvalds/linux/dup_mnt_ns",
        "description": "The clone_mnt function in fs/namespace.c in the Linux kernel before 3.8.6 does not properly restrict changes to the MNT_READONLY flag, which allows local users to bypass an intended read-only property of a filesystem by leveraging a separate mount namespace.",
        "git_url": "https://github.com/torvalds/linux/commit/132c94e31b8bca8ea921f9f96a57d684fa4ae0a9",
        "commit_title": "vfs: Carefully propogate mounts across user namespaces",
        "commit_text": " As a matter of policy MNT_READONLY should not be changable if the original mounter had more privileges than creator of the mount namespace.  Add the flag CL_UNPRIVILEGED to note when we are copying a mount from a mount namespace that requires more privileges to a mount namespace that requires fewer privileges.  When the CL_UNPRIVILEGED flag is set cause clone_mnt to set MNT_NO_REMOUNT if any of the mnt flags that should never be changed are set.  This protects both mount propagation and the initial creation of a less privileged mount namespace.  Cc: stable@vger.kernel.org",
        "func_before": "static struct mnt_namespace *dup_mnt_ns(struct mnt_namespace *mnt_ns,\n\t\tstruct user_namespace *user_ns, struct fs_struct *fs)\n{\n\tstruct mnt_namespace *new_ns;\n\tstruct vfsmount *rootmnt = NULL, *pwdmnt = NULL;\n\tstruct mount *p, *q;\n\tstruct mount *old = mnt_ns->root;\n\tstruct mount *new;\n\tint copy_flags;\n\n\tnew_ns = alloc_mnt_ns(user_ns);\n\tif (IS_ERR(new_ns))\n\t\treturn new_ns;\n\n\tdown_write(&namespace_sem);\n\t/* First pass: copy the tree topology */\n\tcopy_flags = CL_COPY_ALL | CL_EXPIRE;\n\tif (user_ns != mnt_ns->user_ns)\n\t\tcopy_flags |= CL_SHARED_TO_SLAVE;\n\tnew = copy_tree(old, old->mnt.mnt_root, copy_flags);\n\tif (IS_ERR(new)) {\n\t\tup_write(&namespace_sem);\n\t\tfree_mnt_ns(new_ns);\n\t\treturn ERR_CAST(new);\n\t}\n\tnew_ns->root = new;\n\tbr_write_lock(&vfsmount_lock);\n\tlist_add_tail(&new_ns->list, &new->mnt_list);\n\tbr_write_unlock(&vfsmount_lock);\n\n\t/*\n\t * Second pass: switch the tsk->fs->* elements and mark new vfsmounts\n\t * as belonging to new namespace.  We have already acquired a private\n\t * fs_struct, so tsk->fs->lock is not needed.\n\t */\n\tp = old;\n\tq = new;\n\twhile (p) {\n\t\tq->mnt_ns = new_ns;\n\t\tif (fs) {\n\t\t\tif (&p->mnt == fs->root.mnt) {\n\t\t\t\tfs->root.mnt = mntget(&q->mnt);\n\t\t\t\trootmnt = &p->mnt;\n\t\t\t}\n\t\t\tif (&p->mnt == fs->pwd.mnt) {\n\t\t\t\tfs->pwd.mnt = mntget(&q->mnt);\n\t\t\t\tpwdmnt = &p->mnt;\n\t\t\t}\n\t\t}\n\t\tp = next_mnt(p, old);\n\t\tq = next_mnt(q, new);\n\t}\n\tup_write(&namespace_sem);\n\n\tif (rootmnt)\n\t\tmntput(rootmnt);\n\tif (pwdmnt)\n\t\tmntput(pwdmnt);\n\n\treturn new_ns;\n}",
        "func": "static struct mnt_namespace *dup_mnt_ns(struct mnt_namespace *mnt_ns,\n\t\tstruct user_namespace *user_ns, struct fs_struct *fs)\n{\n\tstruct mnt_namespace *new_ns;\n\tstruct vfsmount *rootmnt = NULL, *pwdmnt = NULL;\n\tstruct mount *p, *q;\n\tstruct mount *old = mnt_ns->root;\n\tstruct mount *new;\n\tint copy_flags;\n\n\tnew_ns = alloc_mnt_ns(user_ns);\n\tif (IS_ERR(new_ns))\n\t\treturn new_ns;\n\n\tdown_write(&namespace_sem);\n\t/* First pass: copy the tree topology */\n\tcopy_flags = CL_COPY_ALL | CL_EXPIRE;\n\tif (user_ns != mnt_ns->user_ns)\n\t\tcopy_flags |= CL_SHARED_TO_SLAVE | CL_UNPRIVILEGED;\n\tnew = copy_tree(old, old->mnt.mnt_root, copy_flags);\n\tif (IS_ERR(new)) {\n\t\tup_write(&namespace_sem);\n\t\tfree_mnt_ns(new_ns);\n\t\treturn ERR_CAST(new);\n\t}\n\tnew_ns->root = new;\n\tbr_write_lock(&vfsmount_lock);\n\tlist_add_tail(&new_ns->list, &new->mnt_list);\n\tbr_write_unlock(&vfsmount_lock);\n\n\t/*\n\t * Second pass: switch the tsk->fs->* elements and mark new vfsmounts\n\t * as belonging to new namespace.  We have already acquired a private\n\t * fs_struct, so tsk->fs->lock is not needed.\n\t */\n\tp = old;\n\tq = new;\n\twhile (p) {\n\t\tq->mnt_ns = new_ns;\n\t\tif (fs) {\n\t\t\tif (&p->mnt == fs->root.mnt) {\n\t\t\t\tfs->root.mnt = mntget(&q->mnt);\n\t\t\t\trootmnt = &p->mnt;\n\t\t\t}\n\t\t\tif (&p->mnt == fs->pwd.mnt) {\n\t\t\t\tfs->pwd.mnt = mntget(&q->mnt);\n\t\t\t\tpwdmnt = &p->mnt;\n\t\t\t}\n\t\t}\n\t\tp = next_mnt(p, old);\n\t\tq = next_mnt(q, new);\n\t}\n\tup_write(&namespace_sem);\n\n\tif (rootmnt)\n\t\tmntput(rootmnt);\n\tif (pwdmnt)\n\t\tmntput(pwdmnt);\n\n\treturn new_ns;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,7 @@\n \t/* First pass: copy the tree topology */\n \tcopy_flags = CL_COPY_ALL | CL_EXPIRE;\n \tif (user_ns != mnt_ns->user_ns)\n-\t\tcopy_flags |= CL_SHARED_TO_SLAVE;\n+\t\tcopy_flags |= CL_SHARED_TO_SLAVE | CL_UNPRIVILEGED;\n \tnew = copy_tree(old, old->mnt.mnt_root, copy_flags);\n \tif (IS_ERR(new)) {\n \t\tup_write(&namespace_sem);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tcopy_flags |= CL_SHARED_TO_SLAVE;"
            ],
            "added_lines": [
                "\t\tcopy_flags |= CL_SHARED_TO_SLAVE | CL_UNPRIVILEGED;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1958",
        "func_name": "torvalds/linux/scm_check_creds",
        "description": "The scm_check_creds function in net/core/scm.c in the Linux kernel before 3.8.6 does not properly enforce capability requirements for controlling the PID value associated with a UNIX domain socket, which allows local users to bypass intended access restrictions by leveraging the time interval during which a user namespace has been created but a PID namespace has not been created.",
        "git_url": "https://github.com/torvalds/linux/commit/92f28d973cce45ef5823209aab3138eb45d8b349",
        "commit_title": "scm: Require CAP_SYS_ADMIN over the current pidns to spoof pids.",
        "commit_text": " Don't allow spoofing pids over unix domain sockets in the corner cases where a user has created a user namespace but has not yet created a pid namespace.  Cc: stable@vger.kernel.org",
        "func_before": "static __inline__ int scm_check_creds(struct ucred *creds)\n{\n\tconst struct cred *cred = current_cred();\n\tkuid_t uid = make_kuid(cred->user_ns, creds->uid);\n\tkgid_t gid = make_kgid(cred->user_ns, creds->gid);\n\n\tif (!uid_valid(uid) || !gid_valid(gid))\n\t\treturn -EINVAL;\n\n\tif ((creds->pid == task_tgid_vnr(current) || nsown_capable(CAP_SYS_ADMIN)) &&\n\t    ((uid_eq(uid, cred->uid)   || uid_eq(uid, cred->euid) ||\n\t      uid_eq(uid, cred->suid)) || nsown_capable(CAP_SETUID)) &&\n\t    ((gid_eq(gid, cred->gid)   || gid_eq(gid, cred->egid) ||\n\t      gid_eq(gid, cred->sgid)) || nsown_capable(CAP_SETGID))) {\n\t       return 0;\n\t}\n\treturn -EPERM;\n}",
        "func": "static __inline__ int scm_check_creds(struct ucred *creds)\n{\n\tconst struct cred *cred = current_cred();\n\tkuid_t uid = make_kuid(cred->user_ns, creds->uid);\n\tkgid_t gid = make_kgid(cred->user_ns, creds->gid);\n\n\tif (!uid_valid(uid) || !gid_valid(gid))\n\t\treturn -EINVAL;\n\n\tif ((creds->pid == task_tgid_vnr(current) ||\n\t     ns_capable(current->nsproxy->pid_ns->user_ns, CAP_SYS_ADMIN)) &&\n\t    ((uid_eq(uid, cred->uid)   || uid_eq(uid, cred->euid) ||\n\t      uid_eq(uid, cred->suid)) || nsown_capable(CAP_SETUID)) &&\n\t    ((gid_eq(gid, cred->gid)   || gid_eq(gid, cred->egid) ||\n\t      gid_eq(gid, cred->sgid)) || nsown_capable(CAP_SETGID))) {\n\t       return 0;\n\t}\n\treturn -EPERM;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,8 @@\n \tif (!uid_valid(uid) || !gid_valid(gid))\n \t\treturn -EINVAL;\n \n-\tif ((creds->pid == task_tgid_vnr(current) || nsown_capable(CAP_SYS_ADMIN)) &&\n+\tif ((creds->pid == task_tgid_vnr(current) ||\n+\t     ns_capable(current->nsproxy->pid_ns->user_ns, CAP_SYS_ADMIN)) &&\n \t    ((uid_eq(uid, cred->uid)   || uid_eq(uid, cred->euid) ||\n \t      uid_eq(uid, cred->suid)) || nsown_capable(CAP_SETUID)) &&\n \t    ((gid_eq(gid, cred->gid)   || gid_eq(gid, cred->egid) ||",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((creds->pid == task_tgid_vnr(current) || nsown_capable(CAP_SYS_ADMIN)) &&"
            ],
            "added_lines": [
                "\tif ((creds->pid == task_tgid_vnr(current) ||",
                "\t     ns_capable(current->nsproxy->pid_ns->user_ns, CAP_SYS_ADMIN)) &&"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1959",
        "func_name": "torvalds/linux/map_write",
        "description": "kernel/user_namespace.c in the Linux kernel before 3.8.9 does not have appropriate capability requirements for the uid_map and gid_map files, which allows local users to gain privileges by opening a file within an unprivileged process and then modifying the file within a privileged process.",
        "git_url": "https://github.com/torvalds/linux/commit/6708075f104c3c9b04b23336bb0366ca30c3931b",
        "commit_title": "userns: Don't let unprivileged users trick privileged users into setting the id_map",
        "commit_text": " When we require privilege for setting /proc/<pid>/uid_map or /proc/<pid>/gid_map no longer allow an unprivileged user to open the file and pass it to a privileged program to write to the file.  Instead when privilege is required require both the opener and the writer to have the necessary capabilities.  I have tested this code and verified that setting /proc/<pid>/uid_map fails when an unprivileged user opens the file and a privielged user attempts to set the mapping, that unprivileged users can still map their own id, and that a privileged users can still setup an arbitrary mapping. ",
        "func_before": "static ssize_t map_write(struct file *file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos,\n\t\t\t int cap_setid,\n\t\t\t struct uid_gid_map *map,\n\t\t\t struct uid_gid_map *parent_map)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_map new_map;\n\tunsigned idx;\n\tstruct uid_gid_extent *extent = NULL;\n\tunsigned long page = 0;\n\tchar *kbuf, *pos, *next_line;\n\tssize_t ret = -EINVAL;\n\n\t/*\n\t * The id_map_mutex serializes all writes to any given map.\n\t *\n\t * Any map is only ever written once.\n\t *\n\t * An id map fits within 1 cache line on most architectures.\n\t *\n\t * On read nothing needs to be done unless you are on an\n\t * architecture with a crazy cache coherency model like alpha.\n\t *\n\t * There is a one time data dependency between reading the\n\t * count of the extents and the values of the extents.  The\n\t * desired behavior is to see the values of the extents that\n\t * were written before the count of the extents.\n\t *\n\t * To achieve this smp_wmb() is used on guarantee the write\n\t * order and smp_read_barrier_depends() is guaranteed that we\n\t * don't have crazy architectures returning stale data.\n\t *\n\t */\n\tmutex_lock(&id_map_mutex);\n\n\tret = -EPERM;\n\t/* Only allow one successful write to the map */\n\tif (map->nr_extents != 0)\n\t\tgoto out;\n\n\t/* Require the appropriate privilege CAP_SETUID or CAP_SETGID\n\t * over the user namespace in order to set the id mapping.\n\t */\n\tif (cap_valid(cap_setid) && !ns_capable(ns, cap_setid))\n\t\tgoto out;\n\n\t/* Get a buffer */\n\tret = -ENOMEM;\n\tpage = __get_free_page(GFP_TEMPORARY);\n\tkbuf = (char *) page;\n\tif (!page)\n\t\tgoto out;\n\n\t/* Only allow <= page size writes at the beginning of the file */\n\tret = -EINVAL;\n\tif ((*ppos != 0) || (count >= PAGE_SIZE))\n\t\tgoto out;\n\n\t/* Slurp in the user data */\n\tret = -EFAULT;\n\tif (copy_from_user(kbuf, buf, count))\n\t\tgoto out;\n\tkbuf[count] = '\\0';\n\n\t/* Parse the user data */\n\tret = -EINVAL;\n\tpos = kbuf;\n\tnew_map.nr_extents = 0;\n\tfor (;pos; pos = next_line) {\n\t\textent = &new_map.extent[new_map.nr_extents];\n\n\t\t/* Find the end of line and ensure I don't look past it */\n\t\tnext_line = strchr(pos, '\\n');\n\t\tif (next_line) {\n\t\t\t*next_line = '\\0';\n\t\t\tnext_line++;\n\t\t\tif (*next_line == '\\0')\n\t\t\t\tnext_line = NULL;\n\t\t}\n\n\t\tpos = skip_spaces(pos);\n\t\textent->first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent->lower_first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent->count = simple_strtoul(pos, &pos, 10);\n\t\tif (*pos && !isspace(*pos))\n\t\t\tgoto out;\n\n\t\t/* Verify there is not trailing junk on the line */\n\t\tpos = skip_spaces(pos);\n\t\tif (*pos != '\\0')\n\t\t\tgoto out;\n\n\t\t/* Verify we have been given valid starting values */\n\t\tif ((extent->first == (u32) -1) ||\n\t\t    (extent->lower_first == (u32) -1 ))\n\t\t\tgoto out;\n\n\t\t/* Verify count is not zero and does not cause the extent to wrap */\n\t\tif ((extent->first + extent->count) <= extent->first)\n\t\t\tgoto out;\n\t\tif ((extent->lower_first + extent->count) <= extent->lower_first)\n\t\t\tgoto out;\n\n\t\t/* Do the ranges in extent overlap any previous extents? */\n\t\tif (mappings_overlap(&new_map, extent))\n\t\t\tgoto out;\n\n\t\tnew_map.nr_extents++;\n\n\t\t/* Fail if the file contains too many extents */\n\t\tif ((new_map.nr_extents == UID_GID_MAP_MAX_EXTENTS) &&\n\t\t    (next_line != NULL))\n\t\t\tgoto out;\n\t}\n\t/* Be very certaint the new map actually exists */\n\tif (new_map.nr_extents == 0)\n\t\tgoto out;\n\n\tret = -EPERM;\n\t/* Validate the user is allowed to use user id's mapped to. */\n\tif (!new_idmap_permitted(ns, cap_setid, &new_map))\n\t\tgoto out;\n\n\t/* Map the lower ids from the parent user namespace to the\n\t * kernel global id space.\n\t */\n\tfor (idx = 0; idx < new_map.nr_extents; idx++) {\n\t\tu32 lower_first;\n\t\textent = &new_map.extent[idx];\n\n\t\tlower_first = map_id_range_down(parent_map,\n\t\t\t\t\t\textent->lower_first,\n\t\t\t\t\t\textent->count);\n\n\t\t/* Fail if we can not map the specified extent to\n\t\t * the kernel global id space.\n\t\t */\n\t\tif (lower_first == (u32) -1)\n\t\t\tgoto out;\n\n\t\textent->lower_first = lower_first;\n\t}\n\n\t/* Install the map */\n\tmemcpy(map->extent, new_map.extent,\n\t\tnew_map.nr_extents*sizeof(new_map.extent[0]));\n\tsmp_wmb();\n\tmap->nr_extents = new_map.nr_extents;\n\n\t*ppos = count;\n\tret = count;\nout:\n\tmutex_unlock(&id_map_mutex);\n\tif (page)\n\t\tfree_page(page);\n\treturn ret;\n}",
        "func": "static ssize_t map_write(struct file *file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos,\n\t\t\t int cap_setid,\n\t\t\t struct uid_gid_map *map,\n\t\t\t struct uid_gid_map *parent_map)\n{\n\tstruct seq_file *seq = file->private_data;\n\tstruct user_namespace *ns = seq->private;\n\tstruct uid_gid_map new_map;\n\tunsigned idx;\n\tstruct uid_gid_extent *extent = NULL;\n\tunsigned long page = 0;\n\tchar *kbuf, *pos, *next_line;\n\tssize_t ret = -EINVAL;\n\n\t/*\n\t * The id_map_mutex serializes all writes to any given map.\n\t *\n\t * Any map is only ever written once.\n\t *\n\t * An id map fits within 1 cache line on most architectures.\n\t *\n\t * On read nothing needs to be done unless you are on an\n\t * architecture with a crazy cache coherency model like alpha.\n\t *\n\t * There is a one time data dependency between reading the\n\t * count of the extents and the values of the extents.  The\n\t * desired behavior is to see the values of the extents that\n\t * were written before the count of the extents.\n\t *\n\t * To achieve this smp_wmb() is used on guarantee the write\n\t * order and smp_read_barrier_depends() is guaranteed that we\n\t * don't have crazy architectures returning stale data.\n\t *\n\t */\n\tmutex_lock(&id_map_mutex);\n\n\tret = -EPERM;\n\t/* Only allow one successful write to the map */\n\tif (map->nr_extents != 0)\n\t\tgoto out;\n\n\t/* Require the appropriate privilege CAP_SETUID or CAP_SETGID\n\t * over the user namespace in order to set the id mapping.\n\t */\n\tif (cap_valid(cap_setid) && !ns_capable(ns, cap_setid))\n\t\tgoto out;\n\n\t/* Get a buffer */\n\tret = -ENOMEM;\n\tpage = __get_free_page(GFP_TEMPORARY);\n\tkbuf = (char *) page;\n\tif (!page)\n\t\tgoto out;\n\n\t/* Only allow <= page size writes at the beginning of the file */\n\tret = -EINVAL;\n\tif ((*ppos != 0) || (count >= PAGE_SIZE))\n\t\tgoto out;\n\n\t/* Slurp in the user data */\n\tret = -EFAULT;\n\tif (copy_from_user(kbuf, buf, count))\n\t\tgoto out;\n\tkbuf[count] = '\\0';\n\n\t/* Parse the user data */\n\tret = -EINVAL;\n\tpos = kbuf;\n\tnew_map.nr_extents = 0;\n\tfor (;pos; pos = next_line) {\n\t\textent = &new_map.extent[new_map.nr_extents];\n\n\t\t/* Find the end of line and ensure I don't look past it */\n\t\tnext_line = strchr(pos, '\\n');\n\t\tif (next_line) {\n\t\t\t*next_line = '\\0';\n\t\t\tnext_line++;\n\t\t\tif (*next_line == '\\0')\n\t\t\t\tnext_line = NULL;\n\t\t}\n\n\t\tpos = skip_spaces(pos);\n\t\textent->first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent->lower_first = simple_strtoul(pos, &pos, 10);\n\t\tif (!isspace(*pos))\n\t\t\tgoto out;\n\n\t\tpos = skip_spaces(pos);\n\t\textent->count = simple_strtoul(pos, &pos, 10);\n\t\tif (*pos && !isspace(*pos))\n\t\t\tgoto out;\n\n\t\t/* Verify there is not trailing junk on the line */\n\t\tpos = skip_spaces(pos);\n\t\tif (*pos != '\\0')\n\t\t\tgoto out;\n\n\t\t/* Verify we have been given valid starting values */\n\t\tif ((extent->first == (u32) -1) ||\n\t\t    (extent->lower_first == (u32) -1 ))\n\t\t\tgoto out;\n\n\t\t/* Verify count is not zero and does not cause the extent to wrap */\n\t\tif ((extent->first + extent->count) <= extent->first)\n\t\t\tgoto out;\n\t\tif ((extent->lower_first + extent->count) <= extent->lower_first)\n\t\t\tgoto out;\n\n\t\t/* Do the ranges in extent overlap any previous extents? */\n\t\tif (mappings_overlap(&new_map, extent))\n\t\t\tgoto out;\n\n\t\tnew_map.nr_extents++;\n\n\t\t/* Fail if the file contains too many extents */\n\t\tif ((new_map.nr_extents == UID_GID_MAP_MAX_EXTENTS) &&\n\t\t    (next_line != NULL))\n\t\t\tgoto out;\n\t}\n\t/* Be very certaint the new map actually exists */\n\tif (new_map.nr_extents == 0)\n\t\tgoto out;\n\n\tret = -EPERM;\n\t/* Validate the user is allowed to use user id's mapped to. */\n\tif (!new_idmap_permitted(file, ns, cap_setid, &new_map))\n\t\tgoto out;\n\n\t/* Map the lower ids from the parent user namespace to the\n\t * kernel global id space.\n\t */\n\tfor (idx = 0; idx < new_map.nr_extents; idx++) {\n\t\tu32 lower_first;\n\t\textent = &new_map.extent[idx];\n\n\t\tlower_first = map_id_range_down(parent_map,\n\t\t\t\t\t\textent->lower_first,\n\t\t\t\t\t\textent->count);\n\n\t\t/* Fail if we can not map the specified extent to\n\t\t * the kernel global id space.\n\t\t */\n\t\tif (lower_first == (u32) -1)\n\t\t\tgoto out;\n\n\t\textent->lower_first = lower_first;\n\t}\n\n\t/* Install the map */\n\tmemcpy(map->extent, new_map.extent,\n\t\tnew_map.nr_extents*sizeof(new_map.extent[0]));\n\tsmp_wmb();\n\tmap->nr_extents = new_map.nr_extents;\n\n\t*ppos = count;\n\tret = count;\nout:\n\tmutex_unlock(&id_map_mutex);\n\tif (page)\n\t\tfree_page(page);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -128,7 +128,7 @@\n \n \tret = -EPERM;\n \t/* Validate the user is allowed to use user id's mapped to. */\n-\tif (!new_idmap_permitted(ns, cap_setid, &new_map))\n+\tif (!new_idmap_permitted(file, ns, cap_setid, &new_map))\n \t\tgoto out;\n \n \t/* Map the lower ids from the parent user namespace to the",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!new_idmap_permitted(ns, cap_setid, &new_map))"
            ],
            "added_lines": [
                "\tif (!new_idmap_permitted(file, ns, cap_setid, &new_map))"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1959",
        "func_name": "torvalds/linux/new_idmap_permitted",
        "description": "kernel/user_namespace.c in the Linux kernel before 3.8.9 does not have appropriate capability requirements for the uid_map and gid_map files, which allows local users to gain privileges by opening a file within an unprivileged process and then modifying the file within a privileged process.",
        "git_url": "https://github.com/torvalds/linux/commit/6708075f104c3c9b04b23336bb0366ca30c3931b",
        "commit_title": "userns: Don't let unprivileged users trick privileged users into setting the id_map",
        "commit_text": " When we require privilege for setting /proc/<pid>/uid_map or /proc/<pid>/gid_map no longer allow an unprivileged user to open the file and pass it to a privileged program to write to the file.  Instead when privilege is required require both the opener and the writer to have the necessary capabilities.  I have tested this code and verified that setting /proc/<pid>/uid_map fails when an unprivileged user opens the file and a privielged user attempts to set the mapping, that unprivileged users can still map their own id, and that a privileged users can still setup an arbitrary mapping. ",
        "func_before": "static bool new_idmap_permitted(struct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *new_map)\n{\n\t/* Allow mapping to your own filesystem ids */\n\tif ((new_map->nr_extents == 1) && (new_map->extent[0].count == 1)) {\n\t\tu32 id = new_map->extent[0].lower_first;\n\t\tif (cap_setid == CAP_SETUID) {\n\t\t\tkuid_t uid = make_kuid(ns->parent, id);\n\t\t\tif (uid_eq(uid, current_fsuid()))\n\t\t\t\treturn true;\n\t\t}\n\t\telse if (cap_setid == CAP_SETGID) {\n\t\t\tkgid_t gid = make_kgid(ns->parent, id);\n\t\t\tif (gid_eq(gid, current_fsgid()))\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* Allow anyone to set a mapping that doesn't require privilege */\n\tif (!cap_valid(cap_setid))\n\t\treturn true;\n\n\t/* Allow the specified ids if we have the appropriate capability\n\t * (CAP_SETUID or CAP_SETGID) over the parent user namespace.\n\t */\n\tif (ns_capable(ns->parent, cap_setid))\n\t\treturn true;\n\n\treturn false;\n}",
        "func": "static bool new_idmap_permitted(const struct file *file, \n\t\t\t\tstruct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *new_map)\n{\n\t/* Allow mapping to your own filesystem ids */\n\tif ((new_map->nr_extents == 1) && (new_map->extent[0].count == 1)) {\n\t\tu32 id = new_map->extent[0].lower_first;\n\t\tif (cap_setid == CAP_SETUID) {\n\t\t\tkuid_t uid = make_kuid(ns->parent, id);\n\t\t\tif (uid_eq(uid, current_fsuid()))\n\t\t\t\treturn true;\n\t\t}\n\t\telse if (cap_setid == CAP_SETGID) {\n\t\t\tkgid_t gid = make_kgid(ns->parent, id);\n\t\t\tif (gid_eq(gid, current_fsgid()))\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* Allow anyone to set a mapping that doesn't require privilege */\n\tif (!cap_valid(cap_setid))\n\t\treturn true;\n\n\t/* Allow the specified ids if we have the appropriate capability\n\t * (CAP_SETUID or CAP_SETGID) over the parent user namespace.\n\t * And the opener of the id file also had the approprpiate capability.\n\t */\n\tif (ns_capable(ns->parent, cap_setid) &&\n\t    file_ns_capable(file, ns->parent, cap_setid))\n\t\treturn true;\n\n\treturn false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-static bool new_idmap_permitted(struct user_namespace *ns, int cap_setid,\n+static bool new_idmap_permitted(const struct file *file, \n+\t\t\t\tstruct user_namespace *ns, int cap_setid,\n \t\t\t\tstruct uid_gid_map *new_map)\n {\n \t/* Allow mapping to your own filesystem ids */\n@@ -22,8 +23,10 @@\n \n \t/* Allow the specified ids if we have the appropriate capability\n \t * (CAP_SETUID or CAP_SETGID) over the parent user namespace.\n+\t * And the opener of the id file also had the approprpiate capability.\n \t */\n-\tif (ns_capable(ns->parent, cap_setid))\n+\tif (ns_capable(ns->parent, cap_setid) &&\n+\t    file_ns_capable(file, ns->parent, cap_setid))\n \t\treturn true;\n \n \treturn false;",
        "diff_line_info": {
            "deleted_lines": [
                "static bool new_idmap_permitted(struct user_namespace *ns, int cap_setid,",
                "\tif (ns_capable(ns->parent, cap_setid))"
            ],
            "added_lines": [
                "static bool new_idmap_permitted(const struct file *file, ",
                "\t\t\t\tstruct user_namespace *ns, int cap_setid,",
                "\t * And the opener of the id file also had the approprpiate capability.",
                "\tif (ns_capable(ns->parent, cap_setid) &&",
                "\t    file_ns_capable(file, ns->parent, cap_setid))"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1959",
        "func_name": "torvalds/linux/new_idmap_permitted",
        "description": "kernel/user_namespace.c in the Linux kernel before 3.8.9 does not have appropriate capability requirements for the uid_map and gid_map files, which allows local users to gain privileges by opening a file within an unprivileged process and then modifying the file within a privileged process.",
        "git_url": "https://github.com/torvalds/linux/commit/e3211c120a85b792978bcb4be7b2886df18d27f0",
        "commit_title": "userns: Check uid_map's opener's fsuid, not the current fsuid",
        "commit_text": "",
        "func_before": "static bool new_idmap_permitted(const struct file *file, \n\t\t\t\tstruct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *new_map)\n{\n\t/* Allow mapping to your own filesystem ids */\n\tif ((new_map->nr_extents == 1) && (new_map->extent[0].count == 1)) {\n\t\tu32 id = new_map->extent[0].lower_first;\n\t\tif (cap_setid == CAP_SETUID) {\n\t\t\tkuid_t uid = make_kuid(ns->parent, id);\n\t\t\tif (uid_eq(uid, current_fsuid()))\n\t\t\t\treturn true;\n\t\t}\n\t\telse if (cap_setid == CAP_SETGID) {\n\t\t\tkgid_t gid = make_kgid(ns->parent, id);\n\t\t\tif (gid_eq(gid, current_fsgid()))\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* Allow anyone to set a mapping that doesn't require privilege */\n\tif (!cap_valid(cap_setid))\n\t\treturn true;\n\n\t/* Allow the specified ids if we have the appropriate capability\n\t * (CAP_SETUID or CAP_SETGID) over the parent user namespace.\n\t * And the opener of the id file also had the approprpiate capability.\n\t */\n\tif (ns_capable(ns->parent, cap_setid) &&\n\t    file_ns_capable(file, ns->parent, cap_setid))\n\t\treturn true;\n\n\treturn false;\n}",
        "func": "static bool new_idmap_permitted(const struct file *file, \n\t\t\t\tstruct user_namespace *ns, int cap_setid,\n\t\t\t\tstruct uid_gid_map *new_map)\n{\n\t/* Allow mapping to your own filesystem ids */\n\tif ((new_map->nr_extents == 1) && (new_map->extent[0].count == 1)) {\n\t\tu32 id = new_map->extent[0].lower_first;\n\t\tif (cap_setid == CAP_SETUID) {\n\t\t\tkuid_t uid = make_kuid(ns->parent, id);\n\t\t\tif (uid_eq(uid, file->f_cred->fsuid))\n\t\t\t\treturn true;\n\t\t}\n\t\telse if (cap_setid == CAP_SETGID) {\n\t\t\tkgid_t gid = make_kgid(ns->parent, id);\n\t\t\tif (gid_eq(gid, file->f_cred->fsgid))\n\t\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* Allow anyone to set a mapping that doesn't require privilege */\n\tif (!cap_valid(cap_setid))\n\t\treturn true;\n\n\t/* Allow the specified ids if we have the appropriate capability\n\t * (CAP_SETUID or CAP_SETGID) over the parent user namespace.\n\t * And the opener of the id file also had the approprpiate capability.\n\t */\n\tif (ns_capable(ns->parent, cap_setid) &&\n\t    file_ns_capable(file, ns->parent, cap_setid))\n\t\treturn true;\n\n\treturn false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,12 +7,12 @@\n \t\tu32 id = new_map->extent[0].lower_first;\n \t\tif (cap_setid == CAP_SETUID) {\n \t\t\tkuid_t uid = make_kuid(ns->parent, id);\n-\t\t\tif (uid_eq(uid, current_fsuid()))\n+\t\t\tif (uid_eq(uid, file->f_cred->fsuid))\n \t\t\t\treturn true;\n \t\t}\n \t\telse if (cap_setid == CAP_SETGID) {\n \t\t\tkgid_t gid = make_kgid(ns->parent, id);\n-\t\t\tif (gid_eq(gid, current_fsgid()))\n+\t\t\tif (gid_eq(gid, file->f_cred->fsgid))\n \t\t\t\treturn true;\n \t\t}\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (uid_eq(uid, current_fsuid()))",
                "\t\t\tif (gid_eq(gid, current_fsgid()))"
            ],
            "added_lines": [
                "\t\t\tif (uid_eq(uid, file->f_cred->fsuid))",
                "\t\t\tif (gid_eq(gid, file->f_cred->fsgid))"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-1979",
        "func_name": "torvalds/linux/scm_set_cred",
        "description": "The scm_set_cred function in include/net/scm.h in the Linux kernel before 3.8.11 uses incorrect uid and gid values during credentials passing, which allows local users to gain privileges via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/83f1b4ba917db5dc5a061a44b3403ddb6e783494",
        "commit_title": "net: fix incorrect credentials passing",
        "commit_text": " Commit 257b5358b32f (\"scm: Capture the full credentials of the scm sender\") changed the credentials passing code to pass in the effective uid/gid instead of the real uid/gid.  Obviously this doesn't matter most of the time (since normally they are the same), but it results in differences for suid binaries when the wrong uid/gid ends up being used.  This just undoes that (presumably unintentional) part of the commit.  Cc: Eric W. Biederman <ebiederm@xmission.com> Cc: Serge E. Hallyn <serge@hallyn.com> Cc: David S. Miller <davem@davemloft.net> Cc: stable@vger.kernel.org",
        "func_before": "static __inline__ void scm_set_cred(struct scm_cookie *scm,\n\t\t\t\t    struct pid *pid, const struct cred *cred)\n{\n\tscm->pid  = get_pid(pid);\n\tscm->cred = cred ? get_cred(cred) : NULL;\n\tscm->creds.pid = pid_vnr(pid);\n\tscm->creds.uid = cred ? cred->euid : INVALID_UID;\n\tscm->creds.gid = cred ? cred->egid : INVALID_GID;\n}",
        "func": "static __inline__ void scm_set_cred(struct scm_cookie *scm,\n\t\t\t\t    struct pid *pid, const struct cred *cred)\n{\n\tscm->pid  = get_pid(pid);\n\tscm->cred = cred ? get_cred(cred) : NULL;\n\tscm->creds.pid = pid_vnr(pid);\n\tscm->creds.uid = cred ? cred->uid : INVALID_UID;\n\tscm->creds.gid = cred ? cred->gid : INVALID_GID;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,6 @@\n \tscm->pid  = get_pid(pid);\n \tscm->cred = cred ? get_cred(cred) : NULL;\n \tscm->creds.pid = pid_vnr(pid);\n-\tscm->creds.uid = cred ? cred->euid : INVALID_UID;\n-\tscm->creds.gid = cred ? cred->egid : INVALID_GID;\n+\tscm->creds.uid = cred ? cred->uid : INVALID_UID;\n+\tscm->creds.gid = cred ? cred->gid : INVALID_GID;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tscm->creds.uid = cred ? cred->euid : INVALID_UID;",
                "\tscm->creds.gid = cred ? cred->egid : INVALID_GID;"
            ],
            "added_lines": [
                "\tscm->creds.uid = cred ? cred->uid : INVALID_UID;",
                "\tscm->creds.gid = cred ? cred->gid : INVALID_GID;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2007",
        "func_name": "qemu/qmp_guest_file_open",
        "description": "The qemu guest agent in Qemu 1.4.1 and earlier, as used by Xen, when started in daemon mode, uses weak permissions for certain files, which allows local users to read and write to these files.",
        "git_url": "https://github.com/qemu/qemu/commit/c689b4f1bac352dcfd6ecb9a1d45337de0f1de67",
        "commit_title": "qga: set umask 0077 when daemonizing (CVE-2013-2007)",
        "commit_text": " The qemu guest agent creates a bunch of files with insecure permissions when started in daemon mode. For example:    -rw-rw-rw- 1 root root /var/log/qemu-ga.log   -rw-rw-rw- 1 root root /var/run/qga.state   -rw-rw-rw- 1 root root /var/log/qga-fsfreeze-hook.log  In addition, at least all files created with the \"guest-file-open\" QMP command, and all files created with shell output redirection (or otherwise) by utilities invoked by the fsfreeze hook script are affected.  For now mask all file mode bits for \"group\" and \"others\" in become_daemon().  Temporarily, for compatibility reasons, stick with the 0666 file-mode in case of files newly created by the \"guest-file-open\" QMP call. Do so without changing the umask temporarily. ",
        "func_before": "int64_t qmp_guest_file_open(const char *path, bool has_mode, const char *mode, Error **err)\n{\n    FILE *fh;\n    int fd;\n    int64_t ret = -1, handle;\n\n    if (!has_mode) {\n        mode = \"r\";\n    }\n    slog(\"guest-file-open called, filepath: %s, mode: %s\", path, mode);\n    fh = fopen(path, mode);\n    if (!fh) {\n        error_setg_errno(err, errno, \"failed to open file '%s' (mode: '%s')\",\n                         path, mode);\n        return -1;\n    }\n\n    /* set fd non-blocking to avoid common use cases (like reading from a\n     * named pipe) from hanging the agent\n     */\n    fd = fileno(fh);\n    ret = fcntl(fd, F_GETFL);\n    ret = fcntl(fd, F_SETFL, ret | O_NONBLOCK);\n    if (ret == -1) {\n        error_setg_errno(err, errno, \"failed to make file '%s' non-blocking\",\n                         path);\n        fclose(fh);\n        return -1;\n    }\n\n    handle = guest_file_handle_add(fh, err);\n    if (error_is_set(err)) {\n        fclose(fh);\n        return -1;\n    }\n\n    slog(\"guest-file-open, handle: %d\", handle);\n    return handle;\n}",
        "func": "int64_t qmp_guest_file_open(const char *path, bool has_mode, const char *mode, Error **err)\n{\n    FILE *fh;\n    Error *local_err = NULL;\n    int fd;\n    int64_t ret = -1, handle;\n\n    if (!has_mode) {\n        mode = \"r\";\n    }\n    slog(\"guest-file-open called, filepath: %s, mode: %s\", path, mode);\n    fh = safe_open_or_create(path, mode, &local_err);\n    if (local_err != NULL) {\n        error_propagate(err, local_err);\n        return -1;\n    }\n\n    /* set fd non-blocking to avoid common use cases (like reading from a\n     * named pipe) from hanging the agent\n     */\n    fd = fileno(fh);\n    ret = fcntl(fd, F_GETFL);\n    ret = fcntl(fd, F_SETFL, ret | O_NONBLOCK);\n    if (ret == -1) {\n        error_setg_errno(err, errno, \"failed to make file '%s' non-blocking\",\n                         path);\n        fclose(fh);\n        return -1;\n    }\n\n    handle = guest_file_handle_add(fh, err);\n    if (error_is_set(err)) {\n        fclose(fh);\n        return -1;\n    }\n\n    slog(\"guest-file-open, handle: %d\", handle);\n    return handle;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n int64_t qmp_guest_file_open(const char *path, bool has_mode, const char *mode, Error **err)\n {\n     FILE *fh;\n+    Error *local_err = NULL;\n     int fd;\n     int64_t ret = -1, handle;\n \n@@ -8,10 +9,9 @@\n         mode = \"r\";\n     }\n     slog(\"guest-file-open called, filepath: %s, mode: %s\", path, mode);\n-    fh = fopen(path, mode);\n-    if (!fh) {\n-        error_setg_errno(err, errno, \"failed to open file '%s' (mode: '%s')\",\n-                         path, mode);\n+    fh = safe_open_or_create(path, mode, &local_err);\n+    if (local_err != NULL) {\n+        error_propagate(err, local_err);\n         return -1;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    fh = fopen(path, mode);",
                "    if (!fh) {",
                "        error_setg_errno(err, errno, \"failed to open file '%s' (mode: '%s')\",",
                "                         path, mode);"
            ],
            "added_lines": [
                "    Error *local_err = NULL;",
                "    fh = safe_open_or_create(path, mode, &local_err);",
                "    if (local_err != NULL) {",
                "        error_propagate(err, local_err);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2007",
        "func_name": "qemu/become_daemon",
        "description": "The qemu guest agent in Qemu 1.4.1 and earlier, as used by Xen, when started in daemon mode, uses weak permissions for certain files, which allows local users to read and write to these files.",
        "git_url": "https://github.com/qemu/qemu/commit/c689b4f1bac352dcfd6ecb9a1d45337de0f1de67",
        "commit_title": "qga: set umask 0077 when daemonizing (CVE-2013-2007)",
        "commit_text": " The qemu guest agent creates a bunch of files with insecure permissions when started in daemon mode. For example:    -rw-rw-rw- 1 root root /var/log/qemu-ga.log   -rw-rw-rw- 1 root root /var/run/qga.state   -rw-rw-rw- 1 root root /var/log/qga-fsfreeze-hook.log  In addition, at least all files created with the \"guest-file-open\" QMP command, and all files created with shell output redirection (or otherwise) by utilities invoked by the fsfreeze hook script are affected.  For now mask all file mode bits for \"group\" and \"others\" in become_daemon().  Temporarily, for compatibility reasons, stick with the 0666 file-mode in case of files newly created by the \"guest-file-open\" QMP call. Do so without changing the umask temporarily. ",
        "func_before": "static void become_daemon(const char *pidfile)\n{\n#ifndef _WIN32\n    pid_t pid, sid;\n\n    pid = fork();\n    if (pid < 0) {\n        exit(EXIT_FAILURE);\n    }\n    if (pid > 0) {\n        exit(EXIT_SUCCESS);\n    }\n\n    if (pidfile) {\n        if (!ga_open_pidfile(pidfile)) {\n            g_critical(\"failed to create pidfile\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    umask(0);\n    sid = setsid();\n    if (sid < 0) {\n        goto fail;\n    }\n    if ((chdir(\"/\")) < 0) {\n        goto fail;\n    }\n\n    reopen_fd_to_null(STDIN_FILENO);\n    reopen_fd_to_null(STDOUT_FILENO);\n    reopen_fd_to_null(STDERR_FILENO);\n    return;\n\nfail:\n    if (pidfile) {\n        unlink(pidfile);\n    }\n    g_critical(\"failed to daemonize\");\n    exit(EXIT_FAILURE);\n#endif\n}",
        "func": "static void become_daemon(const char *pidfile)\n{\n#ifndef _WIN32\n    pid_t pid, sid;\n\n    pid = fork();\n    if (pid < 0) {\n        exit(EXIT_FAILURE);\n    }\n    if (pid > 0) {\n        exit(EXIT_SUCCESS);\n    }\n\n    if (pidfile) {\n        if (!ga_open_pidfile(pidfile)) {\n            g_critical(\"failed to create pidfile\");\n            exit(EXIT_FAILURE);\n        }\n    }\n\n    umask(S_IRWXG | S_IRWXO);\n    sid = setsid();\n    if (sid < 0) {\n        goto fail;\n    }\n    if ((chdir(\"/\")) < 0) {\n        goto fail;\n    }\n\n    reopen_fd_to_null(STDIN_FILENO);\n    reopen_fd_to_null(STDOUT_FILENO);\n    reopen_fd_to_null(STDERR_FILENO);\n    return;\n\nfail:\n    if (pidfile) {\n        unlink(pidfile);\n    }\n    g_critical(\"failed to daemonize\");\n    exit(EXIT_FAILURE);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,7 @@\n         }\n     }\n \n-    umask(0);\n+    umask(S_IRWXG | S_IRWXO);\n     sid = setsid();\n     if (sid < 0) {\n         goto fail;",
        "diff_line_info": {
            "deleted_lines": [
                "    umask(0);"
            ],
            "added_lines": [
                "    umask(S_IRWXG | S_IRWXO);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1585",
        "func_name": "torvalds/linux/cifs_find_smb_ses",
        "description": "The cifs_find_smb_ses function in fs/cifs/connect.c in the Linux kernel before 2.6.36 does not properly determine the associations between users and sessions, which allows local users to bypass CIFS share authentication by leveraging a mount of a share by a different user.",
        "git_url": "https://github.com/torvalds/linux/commit/4ff67b720c02c36e54d55b88c2931879b7db1cd2",
        "commit_title": "cifs: clean up cifs_find_smb_ses (try #2)",
        "commit_text": " This patch replaces the earlier patch by the same name. The only difference is that MAX_PASSWORD_SIZE has been increased to attempt to match the limits that windows enforces.  Do a better job of matching sessions by authtype. Matching by username for a Kerberos session is incorrect, and anonymous sessions need special handling.  Also, in the case where we do match by username, we also need to match by password. That ensures that someone else doesn't \"borrow\" an existing session without needing to know the password.  Finally, passwords can be longer than 16 bytes. Bump MAX_PASSWORD_SIZE to 512 to match the size that the userspace mount helper allows. ",
        "func_before": "static struct cifsSesInfo *\ncifs_find_smb_ses(struct TCP_Server_Info *server, char *username)\n{\n\tstruct list_head *tmp;\n\tstruct cifsSesInfo *ses;\n\n\twrite_lock(&cifs_tcp_ses_lock);\n\tlist_for_each(tmp, &server->smb_ses_list) {\n\t\tses = list_entry(tmp, struct cifsSesInfo, smb_ses_list);\n\t\tif (strncmp(ses->userName, username, MAX_USERNAME_SIZE))\n\t\t\tcontinue;\n\n\t\t++ses->ses_count;\n\t\twrite_unlock(&cifs_tcp_ses_lock);\n\t\treturn ses;\n\t}\n\twrite_unlock(&cifs_tcp_ses_lock);\n\treturn NULL;\n}",
        "func": "static struct cifsSesInfo *\ncifs_find_smb_ses(struct TCP_Server_Info *server, struct smb_vol *vol)\n{\n\tstruct cifsSesInfo *ses;\n\n\twrite_lock(&cifs_tcp_ses_lock);\n\tlist_for_each_entry(ses, &server->smb_ses_list, smb_ses_list) {\n\t\tswitch (server->secType) {\n\t\tcase Kerberos:\n\t\t\tif (vol->linux_uid != ses->linux_uid)\n\t\t\t\tcontinue;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t/* anything else takes username/password */\n\t\t\tif (strncmp(ses->userName, vol->username,\n\t\t\t\t    MAX_USERNAME_SIZE))\n\t\t\t\tcontinue;\n\t\t\tif (strlen(vol->username) != 0 &&\n\t\t\t    strncmp(ses->password, vol->password,\n\t\t\t\t    MAX_PASSWORD_SIZE))\n\t\t\t\tcontinue;\n\t\t}\n\t\t++ses->ses_count;\n\t\twrite_unlock(&cifs_tcp_ses_lock);\n\t\treturn ses;\n\t}\n\twrite_unlock(&cifs_tcp_ses_lock);\n\treturn NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,15 +1,25 @@\n static struct cifsSesInfo *\n-cifs_find_smb_ses(struct TCP_Server_Info *server, char *username)\n+cifs_find_smb_ses(struct TCP_Server_Info *server, struct smb_vol *vol)\n {\n-\tstruct list_head *tmp;\n \tstruct cifsSesInfo *ses;\n \n \twrite_lock(&cifs_tcp_ses_lock);\n-\tlist_for_each(tmp, &server->smb_ses_list) {\n-\t\tses = list_entry(tmp, struct cifsSesInfo, smb_ses_list);\n-\t\tif (strncmp(ses->userName, username, MAX_USERNAME_SIZE))\n-\t\t\tcontinue;\n-\n+\tlist_for_each_entry(ses, &server->smb_ses_list, smb_ses_list) {\n+\t\tswitch (server->secType) {\n+\t\tcase Kerberos:\n+\t\t\tif (vol->linux_uid != ses->linux_uid)\n+\t\t\t\tcontinue;\n+\t\t\tbreak;\n+\t\tdefault:\n+\t\t\t/* anything else takes username/password */\n+\t\t\tif (strncmp(ses->userName, vol->username,\n+\t\t\t\t    MAX_USERNAME_SIZE))\n+\t\t\t\tcontinue;\n+\t\t\tif (strlen(vol->username) != 0 &&\n+\t\t\t    strncmp(ses->password, vol->password,\n+\t\t\t\t    MAX_PASSWORD_SIZE))\n+\t\t\t\tcontinue;\n+\t\t}\n \t\t++ses->ses_count;\n \t\twrite_unlock(&cifs_tcp_ses_lock);\n \t\treturn ses;",
        "diff_line_info": {
            "deleted_lines": [
                "cifs_find_smb_ses(struct TCP_Server_Info *server, char *username)",
                "\tstruct list_head *tmp;",
                "\tlist_for_each(tmp, &server->smb_ses_list) {",
                "\t\tses = list_entry(tmp, struct cifsSesInfo, smb_ses_list);",
                "\t\tif (strncmp(ses->userName, username, MAX_USERNAME_SIZE))",
                "\t\t\tcontinue;",
                ""
            ],
            "added_lines": [
                "cifs_find_smb_ses(struct TCP_Server_Info *server, struct smb_vol *vol)",
                "\tlist_for_each_entry(ses, &server->smb_ses_list, smb_ses_list) {",
                "\t\tswitch (server->secType) {",
                "\t\tcase Kerberos:",
                "\t\t\tif (vol->linux_uid != ses->linux_uid)",
                "\t\t\t\tcontinue;",
                "\t\t\tbreak;",
                "\t\tdefault:",
                "\t\t\t/* anything else takes username/password */",
                "\t\t\tif (strncmp(ses->userName, vol->username,",
                "\t\t\t\t    MAX_USERNAME_SIZE))",
                "\t\t\t\tcontinue;",
                "\t\t\tif (strlen(vol->username) != 0 &&",
                "\t\t\t    strncmp(ses->password, vol->password,",
                "\t\t\t\t    MAX_PASSWORD_SIZE))",
                "\t\t\t\tcontinue;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-1585",
        "func_name": "torvalds/linux/cifs_get_smb_ses",
        "description": "The cifs_find_smb_ses function in fs/cifs/connect.c in the Linux kernel before 2.6.36 does not properly determine the associations between users and sessions, which allows local users to bypass CIFS share authentication by leveraging a mount of a share by a different user.",
        "git_url": "https://github.com/torvalds/linux/commit/4ff67b720c02c36e54d55b88c2931879b7db1cd2",
        "commit_title": "cifs: clean up cifs_find_smb_ses (try #2)",
        "commit_text": " This patch replaces the earlier patch by the same name. The only difference is that MAX_PASSWORD_SIZE has been increased to attempt to match the limits that windows enforces.  Do a better job of matching sessions by authtype. Matching by username for a Kerberos session is incorrect, and anonymous sessions need special handling.  Also, in the case where we do match by username, we also need to match by password. That ensures that someone else doesn't \"borrow\" an existing session without needing to know the password.  Finally, passwords can be longer than 16 bytes. Bump MAX_PASSWORD_SIZE to 512 to match the size that the userspace mount helper allows. ",
        "func_before": "static struct cifsSesInfo *\ncifs_get_smb_ses(struct TCP_Server_Info *server, struct smb_vol *volume_info)\n{\n\tint rc = -ENOMEM, xid;\n\tstruct cifsSesInfo *ses;\n\n\txid = GetXid();\n\n\tses = cifs_find_smb_ses(server, volume_info->username);\n\tif (ses) {\n\t\tcFYI(1, \"Existing smb sess found (status=%d)\", ses->status);\n\n\t\t/* existing SMB ses has a server reference already */\n\t\tcifs_put_tcp_session(server);\n\n\t\tmutex_lock(&ses->session_mutex);\n\t\trc = cifs_negotiate_protocol(xid, ses);\n\t\tif (rc) {\n\t\t\tmutex_unlock(&ses->session_mutex);\n\t\t\t/* problem -- put our ses reference */\n\t\t\tcifs_put_smb_ses(ses);\n\t\t\tFreeXid(xid);\n\t\t\treturn ERR_PTR(rc);\n\t\t}\n\t\tif (ses->need_reconnect) {\n\t\t\tcFYI(1, \"Session needs reconnect\");\n\t\t\trc = cifs_setup_session(xid, ses,\n\t\t\t\t\t\tvolume_info->local_nls);\n\t\t\tif (rc) {\n\t\t\t\tmutex_unlock(&ses->session_mutex);\n\t\t\t\t/* problem -- put our reference */\n\t\t\t\tcifs_put_smb_ses(ses);\n\t\t\t\tFreeXid(xid);\n\t\t\t\treturn ERR_PTR(rc);\n\t\t\t}\n\t\t}\n\t\tmutex_unlock(&ses->session_mutex);\n\t\tFreeXid(xid);\n\t\treturn ses;\n\t}\n\n\tcFYI(1, \"Existing smb sess not found\");\n\tses = sesInfoAlloc();\n\tif (ses == NULL)\n\t\tgoto get_ses_fail;\n\n\t/* new SMB session uses our server ref */\n\tses->server = server;\n\tif (server->addr.sockAddr6.sin6_family == AF_INET6)\n\t\tsprintf(ses->serverName, \"%pI6\",\n\t\t\t&server->addr.sockAddr6.sin6_addr);\n\telse\n\t\tsprintf(ses->serverName, \"%pI4\",\n\t\t\t&server->addr.sockAddr.sin_addr.s_addr);\n\n\tif (volume_info->username)\n\t\tstrncpy(ses->userName, volume_info->username,\n\t\t\tMAX_USERNAME_SIZE);\n\n\t/* volume_info->password freed at unmount */\n\tif (volume_info->password) {\n\t\tses->password = kstrdup(volume_info->password, GFP_KERNEL);\n\t\tif (!ses->password)\n\t\t\tgoto get_ses_fail;\n\t}\n\tif (volume_info->domainname) {\n\t\tint len = strlen(volume_info->domainname);\n\t\tses->domainName = kmalloc(len + 1, GFP_KERNEL);\n\t\tif (ses->domainName)\n\t\t\tstrcpy(ses->domainName, volume_info->domainname);\n\t}\n\tses->linux_uid = volume_info->linux_uid;\n\tses->overrideSecFlg = volume_info->secFlg;\n\n\tmutex_lock(&ses->session_mutex);\n\trc = cifs_negotiate_protocol(xid, ses);\n\tif (!rc)\n\t\trc = cifs_setup_session(xid, ses, volume_info->local_nls);\n\tmutex_unlock(&ses->session_mutex);\n\tif (rc)\n\t\tgoto get_ses_fail;\n\n\t/* success, put it on the list */\n\twrite_lock(&cifs_tcp_ses_lock);\n\tlist_add(&ses->smb_ses_list, &server->smb_ses_list);\n\twrite_unlock(&cifs_tcp_ses_lock);\n\n\tFreeXid(xid);\n\treturn ses;\n\nget_ses_fail:\n\tsesInfoFree(ses);\n\tFreeXid(xid);\n\treturn ERR_PTR(rc);\n}",
        "func": "static struct cifsSesInfo *\ncifs_get_smb_ses(struct TCP_Server_Info *server, struct smb_vol *volume_info)\n{\n\tint rc = -ENOMEM, xid;\n\tstruct cifsSesInfo *ses;\n\n\txid = GetXid();\n\n\tses = cifs_find_smb_ses(server, volume_info);\n\tif (ses) {\n\t\tcFYI(1, \"Existing smb sess found (status=%d)\", ses->status);\n\n\t\t/* existing SMB ses has a server reference already */\n\t\tcifs_put_tcp_session(server);\n\n\t\tmutex_lock(&ses->session_mutex);\n\t\trc = cifs_negotiate_protocol(xid, ses);\n\t\tif (rc) {\n\t\t\tmutex_unlock(&ses->session_mutex);\n\t\t\t/* problem -- put our ses reference */\n\t\t\tcifs_put_smb_ses(ses);\n\t\t\tFreeXid(xid);\n\t\t\treturn ERR_PTR(rc);\n\t\t}\n\t\tif (ses->need_reconnect) {\n\t\t\tcFYI(1, \"Session needs reconnect\");\n\t\t\trc = cifs_setup_session(xid, ses,\n\t\t\t\t\t\tvolume_info->local_nls);\n\t\t\tif (rc) {\n\t\t\t\tmutex_unlock(&ses->session_mutex);\n\t\t\t\t/* problem -- put our reference */\n\t\t\t\tcifs_put_smb_ses(ses);\n\t\t\t\tFreeXid(xid);\n\t\t\t\treturn ERR_PTR(rc);\n\t\t\t}\n\t\t}\n\t\tmutex_unlock(&ses->session_mutex);\n\t\tFreeXid(xid);\n\t\treturn ses;\n\t}\n\n\tcFYI(1, \"Existing smb sess not found\");\n\tses = sesInfoAlloc();\n\tif (ses == NULL)\n\t\tgoto get_ses_fail;\n\n\t/* new SMB session uses our server ref */\n\tses->server = server;\n\tif (server->addr.sockAddr6.sin6_family == AF_INET6)\n\t\tsprintf(ses->serverName, \"%pI6\",\n\t\t\t&server->addr.sockAddr6.sin6_addr);\n\telse\n\t\tsprintf(ses->serverName, \"%pI4\",\n\t\t\t&server->addr.sockAddr.sin_addr.s_addr);\n\n\tif (volume_info->username)\n\t\tstrncpy(ses->userName, volume_info->username,\n\t\t\tMAX_USERNAME_SIZE);\n\n\t/* volume_info->password freed at unmount */\n\tif (volume_info->password) {\n\t\tses->password = kstrdup(volume_info->password, GFP_KERNEL);\n\t\tif (!ses->password)\n\t\t\tgoto get_ses_fail;\n\t}\n\tif (volume_info->domainname) {\n\t\tint len = strlen(volume_info->domainname);\n\t\tses->domainName = kmalloc(len + 1, GFP_KERNEL);\n\t\tif (ses->domainName)\n\t\t\tstrcpy(ses->domainName, volume_info->domainname);\n\t}\n\tses->linux_uid = volume_info->linux_uid;\n\tses->overrideSecFlg = volume_info->secFlg;\n\n\tmutex_lock(&ses->session_mutex);\n\trc = cifs_negotiate_protocol(xid, ses);\n\tif (!rc)\n\t\trc = cifs_setup_session(xid, ses, volume_info->local_nls);\n\tmutex_unlock(&ses->session_mutex);\n\tif (rc)\n\t\tgoto get_ses_fail;\n\n\t/* success, put it on the list */\n\twrite_lock(&cifs_tcp_ses_lock);\n\tlist_add(&ses->smb_ses_list, &server->smb_ses_list);\n\twrite_unlock(&cifs_tcp_ses_lock);\n\n\tFreeXid(xid);\n\treturn ses;\n\nget_ses_fail:\n\tsesInfoFree(ses);\n\tFreeXid(xid);\n\treturn ERR_PTR(rc);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n \n \txid = GetXid();\n \n-\tses = cifs_find_smb_ses(server, volume_info->username);\n+\tses = cifs_find_smb_ses(server, volume_info);\n \tif (ses) {\n \t\tcFYI(1, \"Existing smb sess found (status=%d)\", ses->status);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tses = cifs_find_smb_ses(server, volume_info->username);"
            ],
            "added_lines": [
                "\tses = cifs_find_smb_ses(server, volume_info);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4347",
        "func_name": "torvalds/linux/kvm_vm_ioctl_assign_device",
        "description": "The kvm_vm_ioctl_assign_device function in virt/kvm/assigned-dev.c in the KVM subsystem in the Linux kernel before 3.1.10 does not verify permission to access PCI configuration space and BAR resources, which allows host OS users to assign PCI devices and cause a denial of service (host OS crash) via a KVM_ASSIGN_PCI_DEVICE operation.",
        "git_url": "https://github.com/torvalds/linux/commit/c4e7f9022e506c6635a5037713c37118e23193e4",
        "commit_title": "KVM: Device assignment permission checks",
        "commit_text": " (cherry picked from commit 3d27e23b17010c668db311140b17bbbb70c78fb9)  Only allow KVM device assignment to attach to devices which:   - Are not bridges  - Have BAR resources (assume others are special devices)  - The user has permissions to use  Assigning a bridge is a configuration error, it's not supported, and typically doesn't result in the behavior the user is expecting anyway. Devices without BAR resources are typically chipset components that also don't have host drivers.  We don't want users to hold such devices captive or cause system problems by fencing them off into an iommu domain.  We determine \"permission to use\" by testing whether the user has access to the PCI sysfs resource files.  By default a normal user will not have access to these files, so it provides a good indication that an administration agent has granted the user access to the device.  [Yang Bai: add missing #include] [avi: fix comment style] ",
        "func_before": "static int kvm_vm_ioctl_assign_device(struct kvm *kvm,\n\t\t\t\t      struct kvm_assigned_pci_dev *assigned_dev)\n{\n\tint r = 0, idx;\n\tstruct kvm_assigned_dev_kernel *match;\n\tstruct pci_dev *dev;\n\n\tif (!(assigned_dev->flags & KVM_DEV_ASSIGN_ENABLE_IOMMU))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&kvm->lock);\n\tidx = srcu_read_lock(&kvm->srcu);\n\n\tmatch = kvm_find_assigned_dev(&kvm->arch.assigned_dev_head,\n\t\t\t\t      assigned_dev->assigned_dev_id);\n\tif (match) {\n\t\t/* device already assigned */\n\t\tr = -EEXIST;\n\t\tgoto out;\n\t}\n\n\tmatch = kzalloc(sizeof(struct kvm_assigned_dev_kernel), GFP_KERNEL);\n\tif (match == NULL) {\n\t\tprintk(KERN_INFO \"%s: Couldn't allocate memory\\n\",\n\t\t       __func__);\n\t\tr = -ENOMEM;\n\t\tgoto out;\n\t}\n\tdev = pci_get_domain_bus_and_slot(assigned_dev->segnr,\n\t\t\t\t   assigned_dev->busnr,\n\t\t\t\t   assigned_dev->devfn);\n\tif (!dev) {\n\t\tprintk(KERN_INFO \"%s: host device not found\\n\", __func__);\n\t\tr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\tif (pci_enable_device(dev)) {\n\t\tprintk(KERN_INFO \"%s: Could not enable PCI device\\n\", __func__);\n\t\tr = -EBUSY;\n\t\tgoto out_put;\n\t}\n\tr = pci_request_regions(dev, \"kvm_assigned_device\");\n\tif (r) {\n\t\tprintk(KERN_INFO \"%s: Could not get access to device regions\\n\",\n\t\t       __func__);\n\t\tgoto out_disable;\n\t}\n\n\tpci_reset_function(dev);\n\tpci_save_state(dev);\n\tmatch->pci_saved_state = pci_store_saved_state(dev);\n\tif (!match->pci_saved_state)\n\t\tprintk(KERN_DEBUG \"%s: Couldn't store %s saved state\\n\",\n\t\t       __func__, dev_name(&dev->dev));\n\tmatch->assigned_dev_id = assigned_dev->assigned_dev_id;\n\tmatch->host_segnr = assigned_dev->segnr;\n\tmatch->host_busnr = assigned_dev->busnr;\n\tmatch->host_devfn = assigned_dev->devfn;\n\tmatch->flags = assigned_dev->flags;\n\tmatch->dev = dev;\n\tspin_lock_init(&match->intx_lock);\n\tmatch->irq_source_id = -1;\n\tmatch->kvm = kvm;\n\tmatch->ack_notifier.irq_acked = kvm_assigned_dev_ack_irq;\n\n\tlist_add(&match->list, &kvm->arch.assigned_dev_head);\n\n\tif (!kvm->arch.iommu_domain) {\n\t\tr = kvm_iommu_map_guest(kvm);\n\t\tif (r)\n\t\t\tgoto out_list_del;\n\t}\n\tr = kvm_assign_device(kvm, match);\n\tif (r)\n\t\tgoto out_list_del;\n\nout:\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\tmutex_unlock(&kvm->lock);\n\treturn r;\nout_list_del:\n\tif (pci_load_and_free_saved_state(dev, &match->pci_saved_state))\n\t\tprintk(KERN_INFO \"%s: Couldn't reload %s saved state\\n\",\n\t\t       __func__, dev_name(&dev->dev));\n\tlist_del(&match->list);\n\tpci_release_regions(dev);\nout_disable:\n\tpci_disable_device(dev);\nout_put:\n\tpci_dev_put(dev);\nout_free:\n\tkfree(match);\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\tmutex_unlock(&kvm->lock);\n\treturn r;\n}",
        "func": "static int kvm_vm_ioctl_assign_device(struct kvm *kvm,\n\t\t\t\t      struct kvm_assigned_pci_dev *assigned_dev)\n{\n\tint r = 0, idx;\n\tstruct kvm_assigned_dev_kernel *match;\n\tstruct pci_dev *dev;\n\tu8 header_type;\n\n\tif (!(assigned_dev->flags & KVM_DEV_ASSIGN_ENABLE_IOMMU))\n\t\treturn -EINVAL;\n\n\tmutex_lock(&kvm->lock);\n\tidx = srcu_read_lock(&kvm->srcu);\n\n\tmatch = kvm_find_assigned_dev(&kvm->arch.assigned_dev_head,\n\t\t\t\t      assigned_dev->assigned_dev_id);\n\tif (match) {\n\t\t/* device already assigned */\n\t\tr = -EEXIST;\n\t\tgoto out;\n\t}\n\n\tmatch = kzalloc(sizeof(struct kvm_assigned_dev_kernel), GFP_KERNEL);\n\tif (match == NULL) {\n\t\tprintk(KERN_INFO \"%s: Couldn't allocate memory\\n\",\n\t\t       __func__);\n\t\tr = -ENOMEM;\n\t\tgoto out;\n\t}\n\tdev = pci_get_domain_bus_and_slot(assigned_dev->segnr,\n\t\t\t\t   assigned_dev->busnr,\n\t\t\t\t   assigned_dev->devfn);\n\tif (!dev) {\n\t\tprintk(KERN_INFO \"%s: host device not found\\n\", __func__);\n\t\tr = -EINVAL;\n\t\tgoto out_free;\n\t}\n\n\t/* Don't allow bridges to be assigned */\n\tpci_read_config_byte(dev, PCI_HEADER_TYPE, &header_type);\n\tif ((header_type & PCI_HEADER_TYPE) != PCI_HEADER_TYPE_NORMAL) {\n\t\tr = -EPERM;\n\t\tgoto out_put;\n\t}\n\n\tr = probe_sysfs_permissions(dev);\n\tif (r)\n\t\tgoto out_put;\n\n\tif (pci_enable_device(dev)) {\n\t\tprintk(KERN_INFO \"%s: Could not enable PCI device\\n\", __func__);\n\t\tr = -EBUSY;\n\t\tgoto out_put;\n\t}\n\tr = pci_request_regions(dev, \"kvm_assigned_device\");\n\tif (r) {\n\t\tprintk(KERN_INFO \"%s: Could not get access to device regions\\n\",\n\t\t       __func__);\n\t\tgoto out_disable;\n\t}\n\n\tpci_reset_function(dev);\n\tpci_save_state(dev);\n\tmatch->pci_saved_state = pci_store_saved_state(dev);\n\tif (!match->pci_saved_state)\n\t\tprintk(KERN_DEBUG \"%s: Couldn't store %s saved state\\n\",\n\t\t       __func__, dev_name(&dev->dev));\n\tmatch->assigned_dev_id = assigned_dev->assigned_dev_id;\n\tmatch->host_segnr = assigned_dev->segnr;\n\tmatch->host_busnr = assigned_dev->busnr;\n\tmatch->host_devfn = assigned_dev->devfn;\n\tmatch->flags = assigned_dev->flags;\n\tmatch->dev = dev;\n\tspin_lock_init(&match->intx_lock);\n\tmatch->irq_source_id = -1;\n\tmatch->kvm = kvm;\n\tmatch->ack_notifier.irq_acked = kvm_assigned_dev_ack_irq;\n\n\tlist_add(&match->list, &kvm->arch.assigned_dev_head);\n\n\tif (!kvm->arch.iommu_domain) {\n\t\tr = kvm_iommu_map_guest(kvm);\n\t\tif (r)\n\t\t\tgoto out_list_del;\n\t}\n\tr = kvm_assign_device(kvm, match);\n\tif (r)\n\t\tgoto out_list_del;\n\nout:\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\tmutex_unlock(&kvm->lock);\n\treturn r;\nout_list_del:\n\tif (pci_load_and_free_saved_state(dev, &match->pci_saved_state))\n\t\tprintk(KERN_INFO \"%s: Couldn't reload %s saved state\\n\",\n\t\t       __func__, dev_name(&dev->dev));\n\tlist_del(&match->list);\n\tpci_release_regions(dev);\nout_disable:\n\tpci_disable_device(dev);\nout_put:\n\tpci_dev_put(dev);\nout_free:\n\tkfree(match);\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\tmutex_unlock(&kvm->lock);\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,7 @@\n \tint r = 0, idx;\n \tstruct kvm_assigned_dev_kernel *match;\n \tstruct pci_dev *dev;\n+\tu8 header_type;\n \n \tif (!(assigned_dev->flags & KVM_DEV_ASSIGN_ENABLE_IOMMU))\n \t\treturn -EINVAL;\n@@ -34,6 +35,18 @@\n \t\tr = -EINVAL;\n \t\tgoto out_free;\n \t}\n+\n+\t/* Don't allow bridges to be assigned */\n+\tpci_read_config_byte(dev, PCI_HEADER_TYPE, &header_type);\n+\tif ((header_type & PCI_HEADER_TYPE) != PCI_HEADER_TYPE_NORMAL) {\n+\t\tr = -EPERM;\n+\t\tgoto out_put;\n+\t}\n+\n+\tr = probe_sysfs_permissions(dev);\n+\tif (r)\n+\t\tgoto out_put;\n+\n \tif (pci_enable_device(dev)) {\n \t\tprintk(KERN_INFO \"%s: Could not enable PCI device\\n\", __func__);\n \t\tr = -EBUSY;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tu8 header_type;",
                "",
                "\t/* Don't allow bridges to be assigned */",
                "\tpci_read_config_byte(dev, PCI_HEADER_TYPE, &header_type);",
                "\tif ((header_type & PCI_HEADER_TYPE) != PCI_HEADER_TYPE_NORMAL) {",
                "\t\tr = -EPERM;",
                "\t\tgoto out_put;",
                "\t}",
                "",
                "\tr = probe_sysfs_permissions(dev);",
                "\tif (r)",
                "\t\tgoto out_put;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperAudioInputHost::OnOpen",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "int32_t PepperAudioInputHost::OnOpen(\n    ppapi::host::HostMessageContext* context,\n    const std::string& device_id,\n    PP_AudioSampleRate sample_rate,\n    uint32_t sample_frame_count) {\n  if (open_context_)\n    return PP_ERROR_INPROGRESS;\n  if (audio_input_)\n    return PP_ERROR_FAILED;\n\n  webkit::ppapi::PluginDelegate* plugin_delegate = GetPluginDelegate();\n  if (!plugin_delegate)\n    return PP_ERROR_FAILED;\n\n  // When it is done, we'll get called back on StreamCreated() or\n  // StreamCreationFailed().\n  audio_input_ = plugin_delegate->CreateAudioInput(\n      device_id, sample_rate, sample_frame_count, this);\n  if (audio_input_) {\n    open_context_.reset(new ppapi::host::ReplyMessageContext(\n        context->MakeReplyMessageContext()));\n    return PP_OK_COMPLETIONPENDING;\n  } else {\n    return PP_ERROR_FAILED;\n  }\n}",
        "func": "int32_t PepperAudioInputHost::OnOpen(\n    ppapi::host::HostMessageContext* context,\n    const std::string& device_id,\n    PP_AudioSampleRate sample_rate,\n    uint32_t sample_frame_count) {\n  if (open_context_)\n    return PP_ERROR_INPROGRESS;\n  if (audio_input_)\n    return PP_ERROR_FAILED;\n\n  webkit::ppapi::PluginDelegate* plugin_delegate = GetPluginDelegate();\n  if (!plugin_delegate)\n    return PP_ERROR_FAILED;\n\n  webkit::ppapi::PluginInstance* instance =\n      renderer_ppapi_host_->GetPluginInstance(pp_instance());\n  if (!instance)\n    return PP_ERROR_FAILED;\n\n  // When it is done, we'll get called back on StreamCreated() or\n  // StreamCreationFailed().\n  audio_input_ = plugin_delegate->CreateAudioInput(\n      device_id, instance->container()->element().document().url(),\n      sample_rate, sample_frame_count, this);\n  if (audio_input_) {\n    open_context_.reset(new ppapi::host::ReplyMessageContext(\n        context->MakeReplyMessageContext()));\n    return PP_OK_COMPLETIONPENDING;\n  } else {\n    return PP_ERROR_FAILED;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,10 +12,16 @@\n   if (!plugin_delegate)\n     return PP_ERROR_FAILED;\n \n+  webkit::ppapi::PluginInstance* instance =\n+      renderer_ppapi_host_->GetPluginInstance(pp_instance());\n+  if (!instance)\n+    return PP_ERROR_FAILED;\n+\n   // When it is done, we'll get called back on StreamCreated() or\n   // StreamCreationFailed().\n   audio_input_ = plugin_delegate->CreateAudioInput(\n-      device_id, sample_rate, sample_frame_count, this);\n+      device_id, instance->container()->element().document().url(),\n+      sample_rate, sample_frame_count, this);\n   if (audio_input_) {\n     open_context_.reset(new ppapi::host::ReplyMessageContext(\n         context->MakeReplyMessageContext()));",
        "diff_line_info": {
            "deleted_lines": [
                "      device_id, sample_rate, sample_frame_count, this);"
            ],
            "added_lines": [
                "  webkit::ppapi::PluginInstance* instance =",
                "      renderer_ppapi_host_->GetPluginInstance(pp_instance());",
                "  if (!instance)",
                "    return PP_ERROR_FAILED;",
                "",
                "      device_id, instance->container()->element().document().url(),",
                "      sample_rate, sample_frame_count, this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/MediaStreamDevicesController::MediaStreamDevicesController",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "MediaStreamDevicesController::MediaStreamDevicesController(\n    content::WebContents* web_contents,\n    const content::MediaStreamRequest& request,\n    const content::MediaResponseCallback& callback)\n    : web_contents_(web_contents),\n      request_(request),\n      callback_(callback),\n      microphone_requested_(\n          request.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE),\n      webcam_requested_(\n          request.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE) {\n  profile_ = Profile::FromBrowserContext(web_contents->GetBrowserContext());\n  content_settings_ = TabSpecificContentSettings::FromWebContents(web_contents);\n\n  // Don't call GetDevicePolicy from the initializer list since the\n  // implementation depends on member variables.\n  if (microphone_requested_ &&\n      GetDevicePolicy(prefs::kAudioCaptureAllowed,\n                      prefs::kAudioCaptureAllowedUrls) == ALWAYS_DENY) {\n    microphone_requested_ = false;\n  }\n\n  if (webcam_requested_ &&\n      GetDevicePolicy(prefs::kVideoCaptureAllowed,\n                      prefs::kVideoCaptureAllowedUrls) == ALWAYS_DENY) {\n    webcam_requested_ = false;\n  }\n}",
        "func": "MediaStreamDevicesController::MediaStreamDevicesController(\n    content::WebContents* web_contents,\n    const content::MediaStreamRequest& request,\n    const content::MediaResponseCallback& callback)\n    : web_contents_(web_contents),\n      request_(request),\n      callback_(callback),\n      // For MEDIA_OPEN_DEVICE requests (Pepper) we always request both webcam\n      // and microphone to avoid popping two infobars.\n      microphone_requested_(\n          request.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE ||\n          request.request_type == content::MEDIA_OPEN_DEVICE),\n      webcam_requested_(\n          request.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE ||\n          request.request_type == content::MEDIA_OPEN_DEVICE) {\n  profile_ = Profile::FromBrowserContext(web_contents->GetBrowserContext());\n  content_settings_ = TabSpecificContentSettings::FromWebContents(web_contents);\n\n  // Don't call GetDevicePolicy from the initializer list since the\n  // implementation depends on member variables.\n  if (microphone_requested_ &&\n      GetDevicePolicy(prefs::kAudioCaptureAllowed,\n                      prefs::kAudioCaptureAllowedUrls) == ALWAYS_DENY) {\n    microphone_requested_ = false;\n  }\n\n  if (webcam_requested_ &&\n      GetDevicePolicy(prefs::kVideoCaptureAllowed,\n                      prefs::kVideoCaptureAllowedUrls) == ALWAYS_DENY) {\n    webcam_requested_ = false;\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,10 +5,14 @@\n     : web_contents_(web_contents),\n       request_(request),\n       callback_(callback),\n+      // For MEDIA_OPEN_DEVICE requests (Pepper) we always request both webcam\n+      // and microphone to avoid popping two infobars.\n       microphone_requested_(\n-          request.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE),\n+          request.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE ||\n+          request.request_type == content::MEDIA_OPEN_DEVICE),\n       webcam_requested_(\n-          request.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE) {\n+          request.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE ||\n+          request.request_type == content::MEDIA_OPEN_DEVICE) {\n   profile_ = Profile::FromBrowserContext(web_contents->GetBrowserContext());\n   content_settings_ = TabSpecificContentSettings::FromWebContents(web_contents);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "          request.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE),",
                "          request.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE) {"
            ],
            "added_lines": [
                "      // For MEDIA_OPEN_DEVICE requests (Pepper) we always request both webcam",
                "      // and microphone to avoid popping two infobars.",
                "          request.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE ||",
                "          request.request_type == content::MEDIA_OPEN_DEVICE),",
                "          request.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE ||",
                "          request.request_type == content::MEDIA_OPEN_DEVICE) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/MediaStreamDevicesController::DismissInfoBarAndTakeActionOnSettings",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "bool MediaStreamDevicesController::DismissInfoBarAndTakeActionOnSettings() {\n  // If this is a no UI check for policies only go straight to accept - policy\n  // check will be done automatically on the way.\n  if (request_.request_type == content::MEDIA_OPEN_DEVICE) {\n    Accept(false);\n    return true;\n  }\n\n  // Tab capture is allowed for extensions only and infobar is not shown for\n  // extensions.\n  if (request_.audio_type == content::MEDIA_TAB_AUDIO_CAPTURE ||\n      request_.video_type == content::MEDIA_TAB_VIDEO_CAPTURE) {\n    Deny(false);\n    return true;\n  }\n\n  // Deny the request if the security origin is empty, this happens with\n  // file access without |--allow-file-access-from-files| flag.\n  if (request_.security_origin.is_empty()) {\n    Deny(false);\n    return true;\n  }\n\n  // Deny the request if there is no device attached to the OS.\n  if (!HasAnyAvailableDevice()) {\n    Deny(false);\n    return true;\n  }\n\n  // Check if any allow exception has been made for this request.\n  if (IsRequestAllowedByDefault()) {\n    Accept(false);\n    return true;\n  }\n\n  // Check if any block exception has been made for this request.\n  if (IsRequestBlockedByDefault()) {\n    Deny(false);\n    return true;\n  }\n\n  // Check if the media default setting is set to block.\n  if (IsDefaultMediaAccessBlocked()) {\n    Deny(false);\n    return true;\n  }\n\n  // Show the infobar.\n  return false;\n}",
        "func": "bool MediaStreamDevicesController::DismissInfoBarAndTakeActionOnSettings() {\n  // Tab capture is allowed for extensions only and infobar is not shown for\n  // extensions.\n  if (request_.audio_type == content::MEDIA_TAB_AUDIO_CAPTURE ||\n      request_.video_type == content::MEDIA_TAB_VIDEO_CAPTURE) {\n    Deny(false);\n    return true;\n  }\n\n  // Deny the request if the security origin is empty, this happens with\n  // file access without |--allow-file-access-from-files| flag.\n  if (request_.security_origin.is_empty()) {\n    Deny(false);\n    return true;\n  }\n\n  // Deny the request if there is no device attached to the OS.\n  if (!HasAnyAvailableDevice()) {\n    Deny(false);\n    return true;\n  }\n\n  // Check if any allow exception has been made for this request.\n  if (IsRequestAllowedByDefault()) {\n    Accept(false);\n    return true;\n  }\n\n  // Check if any block exception has been made for this request.\n  if (IsRequestBlockedByDefault()) {\n    Deny(false);\n    return true;\n  }\n\n  // Check if the media default setting is set to block.\n  if (IsDefaultMediaAccessBlocked()) {\n    Deny(false);\n    return true;\n  }\n\n  // Show the infobar.\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,4 @@\n bool MediaStreamDevicesController::DismissInfoBarAndTakeActionOnSettings() {\n-  // If this is a no UI check for policies only go straight to accept - policy\n-  // check will be done automatically on the way.\n-  if (request_.request_type == content::MEDIA_OPEN_DEVICE) {\n-    Accept(false);\n-    return true;\n-  }\n-\n   // Tab capture is allowed for extensions only and infobar is not shown for\n   // extensions.\n   if (request_.audio_type == content::MEDIA_TAB_AUDIO_CAPTURE ||",
        "diff_line_info": {
            "deleted_lines": [
                "  // If this is a no UI check for policies only go straight to accept - policy",
                "  // check will be done automatically on the way.",
                "  if (request_.request_type == content::MEDIA_OPEN_DEVICE) {",
                "    Accept(false);",
                "    return true;",
                "  }",
                ""
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/MediaStreamDevicesController::Accept",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "void MediaStreamDevicesController::Accept(bool update_content_setting) {\n  // TODO(xians): Remove the following call after the UI handles microphone\n  // and camera seprately.\n  if (content_settings_)\n    content_settings_->OnMediaStreamAllowed();\n\n  NotifyUIRequestAccepted();\n\n  // Get the default devices for the request.\n  content::MediaStreamDevices devices;\n  if (microphone_requested_ || webcam_requested_) {\n    switch (request_.request_type) {\n      case content::MEDIA_OPEN_DEVICE:\n        // For open device request pick the desired device or fall back to the\n        // first available of the given type.\n        MediaCaptureDevicesDispatcher::GetInstance()->GetRequestedDevice(\n            request_.requested_device_id,\n            microphone_requested_,\n            webcam_requested_,\n            &devices);\n        break;\n      case content::MEDIA_DEVICE_ACCESS:\n      case content::MEDIA_GENERATE_STREAM:\n      case content::MEDIA_ENUMERATE_DEVICES:\n        // Get the default devices for the request.\n        MediaCaptureDevicesDispatcher::GetInstance()->\n            GetDefaultDevicesForProfile(profile_,\n                                        microphone_requested_,\n                                        webcam_requested_,\n                                        &devices);\n        break;\n    }\n\n    if (update_content_setting && IsSchemeSecure() && !devices.empty())\n      SetPermission(true);\n  }\n\n  scoped_ptr<content::MediaStreamUI> ui;\n  if (!devices.empty()) {\n    ui = MediaCaptureDevicesDispatcher::GetInstance()->\n        GetMediaStreamCaptureIndicator()->RegisterMediaStream(\n            web_contents_, devices);\n  }\n  content::MediaResponseCallback cb = callback_;\n  callback_.Reset();\n  cb.Run(devices, ui.Pass());\n}",
        "func": "void MediaStreamDevicesController::Accept(bool update_content_setting) {\n  // TODO(xians): Remove the following call after the UI handles microphone\n  // and camera seprately.\n  if (content_settings_)\n    content_settings_->OnMediaStreamAllowed();\n\n  NotifyUIRequestAccepted();\n\n  // Get the default devices for the request.\n  content::MediaStreamDevices devices;\n  if (microphone_requested_ || webcam_requested_) {\n    switch (request_.request_type) {\n      case content::MEDIA_OPEN_DEVICE:\n        // For open device request pick the desired device or fall back to the\n        // first available of the given type.\n        MediaCaptureDevicesDispatcher::GetInstance()->GetRequestedDevice(\n            request_.requested_device_id,\n            request_.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE,\n            request_.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE,\n            &devices);\n        break;\n      case content::MEDIA_DEVICE_ACCESS:\n      case content::MEDIA_GENERATE_STREAM:\n      case content::MEDIA_ENUMERATE_DEVICES:\n        // Get the default devices for the request.\n        MediaCaptureDevicesDispatcher::GetInstance()->\n            GetDefaultDevicesForProfile(profile_,\n                                        microphone_requested_,\n                                        webcam_requested_,\n                                        &devices);\n        break;\n    }\n\n    if (update_content_setting && IsSchemeSecure() && !devices.empty())\n      SetPermission(true);\n  }\n\n  scoped_ptr<content::MediaStreamUI> ui;\n  if (!devices.empty()) {\n    ui = MediaCaptureDevicesDispatcher::GetInstance()->\n        GetMediaStreamCaptureIndicator()->RegisterMediaStream(\n            web_contents_, devices);\n  }\n  content::MediaResponseCallback cb = callback_;\n  callback_.Reset();\n  cb.Run(devices, ui.Pass());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,8 +15,8 @@\n         // first available of the given type.\n         MediaCaptureDevicesDispatcher::GetInstance()->GetRequestedDevice(\n             request_.requested_device_id,\n-            microphone_requested_,\n-            webcam_requested_,\n+            request_.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE,\n+            request_.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE,\n             &devices);\n         break;\n       case content::MEDIA_DEVICE_ACCESS:",
        "diff_line_info": {
            "deleted_lines": [
                "            microphone_requested_,",
                "            webcam_requested_,"
            ],
            "added_lines": [
                "            request_.audio_type == content::MEDIA_DEVICE_AUDIO_CAPTURE,",
                "            request_.video_type == content::MEDIA_DEVICE_VIDEO_CAPTURE,"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperPluginDelegateImpl::CreateAudioInput",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "webkit::ppapi::PluginDelegate::PlatformAudioInput*\nPepperPluginDelegateImpl::CreateAudioInput(\n    const std::string& device_id,\n    uint32_t sample_rate,\n    uint32_t sample_count,\n    webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n  return PepperPlatformAudioInputImpl::Create(\n      AsWeakPtr(), device_id, static_cast<int>(sample_rate),\n      static_cast<int>(sample_count), client);\n}",
        "func": "webkit::ppapi::PluginDelegate::PlatformAudioInput*\nPepperPluginDelegateImpl::CreateAudioInput(\n    const std::string& device_id,\n    const GURL& document_url,\n    uint32_t sample_rate,\n    uint32_t sample_count,\n    webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n  return PepperPlatformAudioInputImpl::Create(\n      AsWeakPtr(), device_id, document_url, static_cast<int>(sample_rate),\n      static_cast<int>(sample_count), client);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,11 @@\n webkit::ppapi::PluginDelegate::PlatformAudioInput*\n PepperPluginDelegateImpl::CreateAudioInput(\n     const std::string& device_id,\n+    const GURL& document_url,\n     uint32_t sample_rate,\n     uint32_t sample_count,\n     webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n   return PepperPlatformAudioInputImpl::Create(\n-      AsWeakPtr(), device_id, static_cast<int>(sample_rate),\n+      AsWeakPtr(), device_id, document_url, static_cast<int>(sample_rate),\n       static_cast<int>(sample_count), client);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      AsWeakPtr(), device_id, static_cast<int>(sample_rate),"
            ],
            "added_lines": [
                "    const GURL& document_url,",
                "      AsWeakPtr(), device_id, document_url, static_cast<int>(sample_rate),"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperPluginDelegateImpl::CreateVideoCapture",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "webkit::ppapi::PluginDelegate::PlatformVideoCapture*\nPepperPluginDelegateImpl::CreateVideoCapture(\n    const std::string& device_id,\n    PlatformVideoCaptureEventHandler* handler) {\n  return new PepperPlatformVideoCaptureImpl(AsWeakPtr(), device_id, handler);\n}",
        "func": "webkit::ppapi::PluginDelegate::PlatformVideoCapture*\nPepperPluginDelegateImpl::CreateVideoCapture(\n    const std::string& device_id,\n    const GURL& document_url,\n    PlatformVideoCaptureEventHandler* handler) {\n  return new PepperPlatformVideoCaptureImpl(AsWeakPtr(), device_id,\n                                            document_url, handler);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n webkit::ppapi::PluginDelegate::PlatformVideoCapture*\n PepperPluginDelegateImpl::CreateVideoCapture(\n     const std::string& device_id,\n+    const GURL& document_url,\n     PlatformVideoCaptureEventHandler* handler) {\n-  return new PepperPlatformVideoCaptureImpl(AsWeakPtr(), device_id, handler);\n+  return new PepperPlatformVideoCaptureImpl(AsWeakPtr(), device_id,\n+                                            document_url, handler);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  return new PepperPlatformVideoCaptureImpl(AsWeakPtr(), device_id, handler);"
            ],
            "added_lines": [
                "    const GURL& document_url,",
                "  return new PepperPlatformVideoCaptureImpl(AsWeakPtr(), device_id,",
                "                                            document_url, handler);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperPluginDelegateImpl::OpenDevice",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "int PepperPluginDelegateImpl::OpenDevice(PP_DeviceType_Dev type,\n                                         const std::string& device_id,\n                                         const OpenDeviceCallback& callback) {\n  int request_id =\n      device_enumeration_event_handler_->RegisterOpenDeviceCallback(callback);\n\n#if defined(ENABLE_WEBRTC)\n  render_view_->media_stream_dispatcher()->OpenDevice(\n      request_id,\n      device_enumeration_event_handler_.get()->AsWeakPtr(),\n      device_id,\n      PepperDeviceEnumerationEventHandler::FromPepperDeviceType(type),\n      GURL());\n#else\n  base::MessageLoop::current()->PostTask(\n      FROM_HERE,\n      base::Bind(&PepperDeviceEnumerationEventHandler::OnDeviceOpenFailed,\n                 device_enumeration_event_handler_->AsWeakPtr(),\n                 request_id));\n#endif\n\n  return request_id;\n}",
        "func": "int PepperPluginDelegateImpl::OpenDevice(PP_DeviceType_Dev type,\n                                         const std::string& device_id,\n                                         const GURL& document_url,\n                                         const OpenDeviceCallback& callback) {\n  int request_id =\n      device_enumeration_event_handler_->RegisterOpenDeviceCallback(callback);\n\n#if defined(ENABLE_WEBRTC)\n  render_view_->media_stream_dispatcher()->OpenDevice(\n      request_id,\n      device_enumeration_event_handler_.get()->AsWeakPtr(),\n      device_id,\n      PepperDeviceEnumerationEventHandler::FromPepperDeviceType(type),\n      document_url.GetOrigin());\n#else\n  base::MessageLoop::current()->PostTask(\n      FROM_HERE,\n      base::Bind(&PepperDeviceEnumerationEventHandler::OnDeviceOpenFailed,\n                 device_enumeration_event_handler_->AsWeakPtr(),\n                 request_id));\n#endif\n\n  return request_id;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n int PepperPluginDelegateImpl::OpenDevice(PP_DeviceType_Dev type,\n                                          const std::string& device_id,\n+                                         const GURL& document_url,\n                                          const OpenDeviceCallback& callback) {\n   int request_id =\n       device_enumeration_event_handler_->RegisterOpenDeviceCallback(callback);\n@@ -10,7 +11,7 @@\n       device_enumeration_event_handler_.get()->AsWeakPtr(),\n       device_id,\n       PepperDeviceEnumerationEventHandler::FromPepperDeviceType(type),\n-      GURL());\n+      document_url.GetOrigin());\n #else\n   base::MessageLoop::current()->PostTask(\n       FROM_HERE,",
        "diff_line_info": {
            "deleted_lines": [
                "      GURL());"
            ],
            "added_lines": [
                "                                         const GURL& document_url,",
                "      document_url.GetOrigin());"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/MockPluginDelegate::CreateAudioInput",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "MockPluginDelegate::PlatformAudioInput* MockPluginDelegate::CreateAudioInput(\n    const std::string& device_id,\n    uint32_t sample_rate,\n    uint32_t sample_count,\n    PlatformAudioInputClient* client) {\n  return NULL;\n}",
        "func": "MockPluginDelegate::PlatformAudioInput* MockPluginDelegate::CreateAudioInput(\n    const std::string& device_id,\n    const GURL& document_url,\n    uint32_t sample_rate,\n    uint32_t sample_count,\n    PlatformAudioInputClient* client) {\n  return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n MockPluginDelegate::PlatformAudioInput* MockPluginDelegate::CreateAudioInput(\n     const std::string& device_id,\n+    const GURL& document_url,\n     uint32_t sample_rate,\n     uint32_t sample_count,\n     PlatformAudioInputClient* client) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    const GURL& document_url,"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/MockPluginDelegate::CreateVideoCapture",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "MockPluginDelegate::PlatformVideoCapture*\nMockPluginDelegate::CreateVideoCapture(\n    const std::string& device_id,\n    PlatformVideoCaptureEventHandler* handler){\n  return NULL;\n}",
        "func": "MockPluginDelegate::PlatformVideoCapture*\nMockPluginDelegate::CreateVideoCapture(\n    const std::string& device_id,\n    const GURL& document_url,\n    PlatformVideoCaptureEventHandler* handler){\n  return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n MockPluginDelegate::PlatformVideoCapture*\n MockPluginDelegate::CreateVideoCapture(\n     const std::string& device_id,\n+    const GURL& document_url,\n     PlatformVideoCaptureEventHandler* handler){\n   return NULL;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    const GURL& document_url,"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperPlatformAudioInputImpl::Initialize",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "bool PepperPlatformAudioInputImpl::Initialize(\n    const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n    const std::string& device_id,\n    int sample_rate,\n    int frames_per_buffer,\n    webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n  DCHECK(main_message_loop_proxy_->BelongsToCurrentThread());\n\n  if (!plugin_delegate.get() || !client)\n    return false;\n\n  ipc_ = RenderThreadImpl::current()->audio_input_message_filter()->\n      CreateAudioInputIPC(plugin_delegate->GetRoutingID());\n\n  plugin_delegate_ = plugin_delegate;\n  client_ = client;\n\n  params_.Reset(media::AudioParameters::AUDIO_PCM_LINEAR,\n                media::CHANNEL_LAYOUT_MONO, 1, 0,\n                sample_rate, 16, frames_per_buffer);\n\n  // We need to open the device and obtain the label and session ID before\n  // initializing.\n  plugin_delegate_->OpenDevice(\n      PP_DEVICETYPE_DEV_AUDIOCAPTURE,\n      device_id.empty() ? media::AudioManagerBase::kDefaultDeviceId : device_id,\n      base::Bind(&PepperPlatformAudioInputImpl::OnDeviceOpened, this));\n\n  return true;\n}",
        "func": "bool PepperPlatformAudioInputImpl::Initialize(\n    const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n    const std::string& device_id,\n    const GURL& document_url,\n    int sample_rate,\n    int frames_per_buffer,\n    webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n  DCHECK(main_message_loop_proxy_->BelongsToCurrentThread());\n\n  if (!plugin_delegate.get() || !client)\n    return false;\n\n  ipc_ = RenderThreadImpl::current()->audio_input_message_filter()->\n      CreateAudioInputIPC(plugin_delegate->GetRoutingID());\n\n  plugin_delegate_ = plugin_delegate;\n  client_ = client;\n\n  params_.Reset(media::AudioParameters::AUDIO_PCM_LINEAR,\n                media::CHANNEL_LAYOUT_MONO, 1, 0,\n                sample_rate, 16, frames_per_buffer);\n\n  // We need to open the device and obtain the label and session ID before\n  // initializing.\n  plugin_delegate_->OpenDevice(\n      PP_DEVICETYPE_DEV_AUDIOCAPTURE,\n      device_id.empty() ? media::AudioManagerBase::kDefaultDeviceId : device_id,\n      document_url,\n      base::Bind(&PepperPlatformAudioInputImpl::OnDeviceOpened, this));\n\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n bool PepperPlatformAudioInputImpl::Initialize(\n     const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n     const std::string& device_id,\n+    const GURL& document_url,\n     int sample_rate,\n     int frames_per_buffer,\n     webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n@@ -24,6 +25,7 @@\n   plugin_delegate_->OpenDevice(\n       PP_DEVICETYPE_DEV_AUDIOCAPTURE,\n       device_id.empty() ? media::AudioManagerBase::kDefaultDeviceId : device_id,\n+      document_url,\n       base::Bind(&PepperPlatformAudioInputImpl::OnDeviceOpened, this));\n \n   return true;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    const GURL& document_url,",
                "      document_url,"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperPlatformAudioInputImpl::Create",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "PepperPlatformAudioInputImpl* PepperPlatformAudioInputImpl::Create(\n    const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n    const std::string& device_id,\n    int sample_rate,\n    int frames_per_buffer,\n    webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n  scoped_refptr<PepperPlatformAudioInputImpl> audio_input(\n      new PepperPlatformAudioInputImpl());\n  if (audio_input->Initialize(plugin_delegate, device_id, sample_rate,\n                              frames_per_buffer, client)) {\n    // Balanced by Release invoked in\n    // PepperPlatformAudioInputImpl::ShutDownOnIOThread().\n    audio_input->AddRef();\n    return audio_input.get();\n  }\n  return NULL;\n}",
        "func": "PepperPlatformAudioInputImpl* PepperPlatformAudioInputImpl::Create(\n    const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n    const std::string& device_id,\n    const GURL& document_url,\n    int sample_rate,\n    int frames_per_buffer,\n    webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n  scoped_refptr<PepperPlatformAudioInputImpl> audio_input(\n      new PepperPlatformAudioInputImpl());\n  if (audio_input->Initialize(plugin_delegate, device_id, document_url,\n                              sample_rate, frames_per_buffer, client)) {\n    // Balanced by Release invoked in\n    // PepperPlatformAudioInputImpl::ShutDownOnIOThread().\n    audio_input->AddRef();\n    return audio_input.get();\n  }\n  return NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,14 @@\n PepperPlatformAudioInputImpl* PepperPlatformAudioInputImpl::Create(\n     const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n     const std::string& device_id,\n+    const GURL& document_url,\n     int sample_rate,\n     int frames_per_buffer,\n     webkit::ppapi::PluginDelegate::PlatformAudioInputClient* client) {\n   scoped_refptr<PepperPlatformAudioInputImpl> audio_input(\n       new PepperPlatformAudioInputImpl());\n-  if (audio_input->Initialize(plugin_delegate, device_id, sample_rate,\n-                              frames_per_buffer, client)) {\n+  if (audio_input->Initialize(plugin_delegate, device_id, document_url,\n+                              sample_rate, frames_per_buffer, client)) {\n     // Balanced by Release invoked in\n     // PepperPlatformAudioInputImpl::ShutDownOnIOThread().\n     audio_input->AddRef();",
        "diff_line_info": {
            "deleted_lines": [
                "  if (audio_input->Initialize(plugin_delegate, device_id, sample_rate,",
                "                              frames_per_buffer, client)) {"
            ],
            "added_lines": [
                "    const GURL& document_url,",
                "  if (audio_input->Initialize(plugin_delegate, device_id, document_url,",
                "                              sample_rate, frames_per_buffer, client)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperVideoCaptureHost::OnOpen",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "int32_t PepperVideoCaptureHost::OnOpen(\n    ppapi::host::HostMessageContext* context,\n    const std::string& device_id,\n    const PP_VideoCaptureDeviceInfo_Dev& requested_info,\n    uint32_t buffer_count) {\n  if (platform_video_capture_.get())\n    return PP_ERROR_FAILED;\n\n  webkit::ppapi::PluginDelegate* plugin_delegate = GetPluginDelegate();\n  if (!plugin_delegate)\n    return PP_ERROR_FAILED;\n\n  SetRequestedInfo(requested_info, buffer_count);\n\n  platform_video_capture_ =\n      plugin_delegate->CreateVideoCapture(device_id, this);\n\n  open_reply_context_ = context->MakeReplyMessageContext();\n\n  // It is able to complete synchronously if the default device is used.\n  bool sync_completion = device_id.empty();\n  if (sync_completion) {\n    // Send OpenACK directly, but still need to return PP_OK_COMPLETIONPENDING\n    // to make PluginResource happy.\n    OnInitialized(platform_video_capture_.get(), true);\n  }\n\n  return PP_OK_COMPLETIONPENDING;\n}",
        "func": "int32_t PepperVideoCaptureHost::OnOpen(\n    ppapi::host::HostMessageContext* context,\n    const std::string& device_id,\n    const PP_VideoCaptureDeviceInfo_Dev& requested_info,\n    uint32_t buffer_count) {\n  if (platform_video_capture_.get())\n    return PP_ERROR_FAILED;\n\n  webkit::ppapi::PluginDelegate* plugin_delegate = GetPluginDelegate();\n  if (!plugin_delegate)\n    return PP_ERROR_FAILED;\n\n  SetRequestedInfo(requested_info, buffer_count);\n\n  webkit::ppapi::PluginInstance* instance =\n      renderer_ppapi_host_->GetPluginInstance(pp_instance());\n  if (!instance)\n    return PP_ERROR_FAILED;\n\n  platform_video_capture_ =\n      plugin_delegate->CreateVideoCapture(device_id,\n          instance->container()->element().document().url(), this);\n\n  open_reply_context_ = context->MakeReplyMessageContext();\n\n  return PP_OK_COMPLETIONPENDING;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,18 +12,16 @@\n \n   SetRequestedInfo(requested_info, buffer_count);\n \n+  webkit::ppapi::PluginInstance* instance =\n+      renderer_ppapi_host_->GetPluginInstance(pp_instance());\n+  if (!instance)\n+    return PP_ERROR_FAILED;\n+\n   platform_video_capture_ =\n-      plugin_delegate->CreateVideoCapture(device_id, this);\n+      plugin_delegate->CreateVideoCapture(device_id,\n+          instance->container()->element().document().url(), this);\n \n   open_reply_context_ = context->MakeReplyMessageContext();\n \n-  // It is able to complete synchronously if the default device is used.\n-  bool sync_completion = device_id.empty();\n-  if (sync_completion) {\n-    // Send OpenACK directly, but still need to return PP_OK_COMPLETIONPENDING\n-    // to make PluginResource happy.\n-    OnInitialized(platform_video_capture_.get(), true);\n-  }\n-\n   return PP_OK_COMPLETIONPENDING;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      plugin_delegate->CreateVideoCapture(device_id, this);",
                "  // It is able to complete synchronously if the default device is used.",
                "  bool sync_completion = device_id.empty();",
                "  if (sync_completion) {",
                "    // Send OpenACK directly, but still need to return PP_OK_COMPLETIONPENDING",
                "    // to make PluginResource happy.",
                "    OnInitialized(platform_video_capture_.get(), true);",
                "  }",
                ""
            ],
            "added_lines": [
                "  webkit::ppapi::PluginInstance* instance =",
                "      renderer_ppapi_host_->GetPluginInstance(pp_instance());",
                "  if (!instance)",
                "    return PP_ERROR_FAILED;",
                "",
                "      plugin_delegate->CreateVideoCapture(device_id,",
                "          instance->container()->element().document().url(), this);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2866",
        "func_name": "chromium/PepperPlatformVideoCaptureImpl::PepperPlatformVideoCaptureImpl",
        "description": "The Flash plug-in in Google Chrome before 27.0.1453.116, as used on Google Chrome OS before 27.0.1453.116 and separately, does not properly determine whether a user wishes to permit camera or microphone access by a Flash application, which allows remote attackers to obtain sensitive information from a machine's physical environment via a clickjacking attack, as demonstrated by an attack using a crafted Cascading Style Sheets (CSS) opacity property.",
        "git_url": "https://github.com/chromium/chromium/commit/ae6ef14fe8d5c5df694efc7e09bcf86e4747d7ad",
        "commit_title": "Make the infobar popup when Pepper Flash requests the camera/microphone",
        "commit_text": " This makes opening the microphone/camera devices for pepper pop the same infobar as WebRTC with an allow/deny button.  TBR=tsepez@chromium.org, xians@chromium.org, yzshen@chromium.org  ",
        "func_before": "PepperPlatformVideoCaptureImpl::PepperPlatformVideoCaptureImpl(\n    const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n    const std::string& device_id,\n    webkit::ppapi::PluginDelegate::PlatformVideoCaptureEventHandler* handler)\n    : plugin_delegate_(plugin_delegate),\n      device_id_(device_id),\n      session_id_(0),\n      handler_proxy_(new media::VideoCaptureHandlerProxy(\n          this, base::MessageLoopProxy::current())),\n      handler_(handler),\n      video_capture_(NULL),\n      unbalanced_start_(false) {\n  if (device_id.empty()) {\n    // \"1\" is the session ID for the default device.\n    session_id_ = 1;\n    Initialize();\n  } else {\n    // We need to open the device and obtain the label and session ID before\n    // initializing.\n    if (plugin_delegate_.get()) {\n      plugin_delegate_->OpenDevice(\n          PP_DEVICETYPE_DEV_VIDEOCAPTURE,\n          device_id,\n          base::Bind(&PepperPlatformVideoCaptureImpl::OnDeviceOpened, this));\n    }\n  }\n}",
        "func": "PepperPlatformVideoCaptureImpl::PepperPlatformVideoCaptureImpl(\n    const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n    const std::string& device_id,\n    const GURL& document_url,\n    webkit::ppapi::PluginDelegate::PlatformVideoCaptureEventHandler* handler)\n    : plugin_delegate_(plugin_delegate),\n      device_id_(device_id),\n      session_id_(0),\n      handler_proxy_(new media::VideoCaptureHandlerProxy(\n          this, base::MessageLoopProxy::current())),\n      handler_(handler),\n      video_capture_(NULL),\n      unbalanced_start_(false) {\n  // We need to open the device and obtain the label and session ID before\n  // initializing.\n  if (plugin_delegate_.get()) {\n    plugin_delegate_->OpenDevice(\n        PP_DEVICETYPE_DEV_VIDEOCAPTURE,\n        device_id,\n        document_url,\n        base::Bind(&PepperPlatformVideoCaptureImpl::OnDeviceOpened, this));\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n PepperPlatformVideoCaptureImpl::PepperPlatformVideoCaptureImpl(\n     const base::WeakPtr<PepperPluginDelegateImpl>& plugin_delegate,\n     const std::string& device_id,\n+    const GURL& document_url,\n     webkit::ppapi::PluginDelegate::PlatformVideoCaptureEventHandler* handler)\n     : plugin_delegate_(plugin_delegate),\n       device_id_(device_id),\n@@ -10,18 +11,13 @@\n       handler_(handler),\n       video_capture_(NULL),\n       unbalanced_start_(false) {\n-  if (device_id.empty()) {\n-    // \"1\" is the session ID for the default device.\n-    session_id_ = 1;\n-    Initialize();\n-  } else {\n-    // We need to open the device and obtain the label and session ID before\n-    // initializing.\n-    if (plugin_delegate_.get()) {\n-      plugin_delegate_->OpenDevice(\n-          PP_DEVICETYPE_DEV_VIDEOCAPTURE,\n-          device_id,\n-          base::Bind(&PepperPlatformVideoCaptureImpl::OnDeviceOpened, this));\n-    }\n+  // We need to open the device and obtain the label and session ID before\n+  // initializing.\n+  if (plugin_delegate_.get()) {\n+    plugin_delegate_->OpenDevice(\n+        PP_DEVICETYPE_DEV_VIDEOCAPTURE,\n+        device_id,\n+        document_url,\n+        base::Bind(&PepperPlatformVideoCaptureImpl::OnDeviceOpened, this));\n   }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (device_id.empty()) {",
                "    // \"1\" is the session ID for the default device.",
                "    session_id_ = 1;",
                "    Initialize();",
                "  } else {",
                "    // We need to open the device and obtain the label and session ID before",
                "    // initializing.",
                "    if (plugin_delegate_.get()) {",
                "      plugin_delegate_->OpenDevice(",
                "          PP_DEVICETYPE_DEV_VIDEOCAPTURE,",
                "          device_id,",
                "          base::Bind(&PepperPlatformVideoCaptureImpl::OnDeviceOpened, this));",
                "    }"
            ],
            "added_lines": [
                "    const GURL& document_url,",
                "  // We need to open the device and obtain the label and session ID before",
                "  // initializing.",
                "  if (plugin_delegate_.get()) {",
                "    plugin_delegate_->OpenDevice(",
                "        PP_DEVICETYPE_DEV_VIDEOCAPTURE,",
                "        device_id,",
                "        document_url,",
                "        base::Bind(&PepperPlatformVideoCaptureImpl::OnDeviceOpened, this));"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2881",
        "func_name": "chromium/V8Window::indexedSecurityCheckCustom",
        "description": "Google Chrome before 28.0.1500.95 does not properly handle frames, which allows remote attackers to bypass the Same Origin Policy via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/c52aaf32adda2716f43065ddabaa2708378f1dcf",
        "commit_title": "Make indexedSecurityCheckCustom more robust",
        "commit_text": " I don't know any way in which this change is observable, but this CL makes indexedSecurityCheckCustom match namedSecurityCheckCustom in form.   ",
        "func_before": "bool V8Window::indexedSecurityCheckCustom(v8::Local<v8::Object> host, uint32_t index, v8::AccessType type, v8::Local<v8::Value>)\n{\n    v8::Isolate* isolate = v8::Isolate::GetCurrent();\n    v8::Handle<v8::Object> window = host->FindInstanceInPrototypeChain(V8Window::GetTemplate(isolate, worldTypeInMainThread(isolate)));\n    if (window.IsEmpty())\n        return false;\n\n    DOMWindow* targetWindow = V8Window::toNative(window);\n\n    ASSERT(targetWindow);\n\n    Frame* target = targetWindow->frame();\n    if (!target)\n        return false;\n    Frame* childFrame =  target->tree()->scopedChild(index);\n\n    // Notify the loader's client if the initial document has been accessed.\n    if (target->loader()->stateMachine()->isDisplayingInitialEmptyDocument())\n        target->loader()->didAccessInitialDocument();\n\n    // Notice that we can't call HasRealNamedProperty for ACCESS_HAS\n    // because that would generate infinite recursion.\n    if (type == v8::ACCESS_HAS && childFrame)\n        return true;\n    if (type == v8::ACCESS_GET && childFrame && !host->HasRealIndexedProperty(index))\n        return true;\n\n    return BindingSecurity::shouldAllowAccessToFrame(target, DoNotReportSecurityError);\n}",
        "func": "bool V8Window::indexedSecurityCheckCustom(v8::Local<v8::Object> host, uint32_t index, v8::AccessType type, v8::Local<v8::Value>)\n{\n    v8::Isolate* isolate = v8::Isolate::GetCurrent();\n    v8::Handle<v8::Object> window = host->FindInstanceInPrototypeChain(V8Window::GetTemplate(isolate, worldTypeInMainThread(isolate)));\n    if (window.IsEmpty())\n        return false;\n\n    DOMWindow* targetWindow = V8Window::toNative(window);\n\n    ASSERT(targetWindow);\n\n    Frame* target = targetWindow->frame();\n    if (!target)\n        return false;\n\n    // Notify the loader's client if the initial document has been accessed.\n    if (target->loader()->stateMachine()->isDisplayingInitialEmptyDocument())\n        target->loader()->didAccessInitialDocument();\n\n    Frame* childFrame =  target->tree()->scopedChild(index);\n\n    // Notice that we can't call HasRealNamedProperty for ACCESS_HAS\n    // because that would generate infinite recursion.\n    if (type == v8::ACCESS_HAS && childFrame)\n        return true;\n    if (type == v8::ACCESS_GET\n        && childFrame\n        && !host->HasRealIndexedProperty(index)\n        && !window->HasRealIndexedProperty(index))\n        return true;\n\n    return BindingSecurity::shouldAllowAccessToFrame(target, DoNotReportSecurityError);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,17 +12,21 @@\n     Frame* target = targetWindow->frame();\n     if (!target)\n         return false;\n-    Frame* childFrame =  target->tree()->scopedChild(index);\n \n     // Notify the loader's client if the initial document has been accessed.\n     if (target->loader()->stateMachine()->isDisplayingInitialEmptyDocument())\n         target->loader()->didAccessInitialDocument();\n \n+    Frame* childFrame =  target->tree()->scopedChild(index);\n+\n     // Notice that we can't call HasRealNamedProperty for ACCESS_HAS\n     // because that would generate infinite recursion.\n     if (type == v8::ACCESS_HAS && childFrame)\n         return true;\n-    if (type == v8::ACCESS_GET && childFrame && !host->HasRealIndexedProperty(index))\n+    if (type == v8::ACCESS_GET\n+        && childFrame\n+        && !host->HasRealIndexedProperty(index)\n+        && !window->HasRealIndexedProperty(index))\n         return true;\n \n     return BindingSecurity::shouldAllowAccessToFrame(target, DoNotReportSecurityError);",
        "diff_line_info": {
            "deleted_lines": [
                "    Frame* childFrame =  target->tree()->scopedChild(index);",
                "    if (type == v8::ACCESS_GET && childFrame && !host->HasRealIndexedProperty(index))"
            ],
            "added_lines": [
                "    Frame* childFrame =  target->tree()->scopedChild(index);",
                "",
                "    if (type == v8::ACCESS_GET",
                "        && childFrame",
                "        && !host->HasRealIndexedProperty(index)",
                "        && !window->HasRealIndexedProperty(index))"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4718",
        "func_name": "php/php-src/php_session_initialize",
        "description": "Session fixation vulnerability in the Sessions subsystem in PHP before 5.5.2 allows remote attackers to hijack web sessions by specifying a session ID.",
        "git_url": "https://github.com/php/php-src/commit/25e8fcc88fa20dc9d4c47184471003f436927cde",
        "commit_title": "Strict session",
        "commit_text": "",
        "func_before": "static void php_session_initialize(TSRMLS_D) /* {{{ */\n{\n\tchar *val;\n\tint vallen;\n\n\t/* check session name for invalid characters */\n\tif (PS(id) && strpbrk(PS(id), \"\\r\\n\\t <>'\\\"\\\\\")) {\n\t\tefree(PS(id));\n\t\tPS(id) = NULL;\n\t}\n\n\tif (!PS(mod)) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"No storage module chosen - failed to initialize session\");\n\t\treturn;\n\t}\n\n\t/* Open session handler first */\n\tif (PS(mod)->s_open(&PS(mod_data), PS(save_path), PS(session_name) TSRMLS_CC) == FAILURE) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"Failed to initialize storage module: %s (path: %s)\", PS(mod)->s_name, PS(save_path));\n\t\treturn;\n\t}\n\n\t/* If there is no ID, use session module to create one */\n\tif (!PS(id)) {\nnew_session:\n\t\tPS(id) = PS(mod)->s_create_sid(&PS(mod_data), NULL TSRMLS_CC);\n\t\tif (PS(use_cookies)) {\n\t\t\tPS(send_cookie) = 1;\n\t\t}\n\t}\n\n\t/* Read data */\n\t/* Question: if you create a SID here, should you also try to read data?\n\t * I'm not sure, but while not doing so will remove one session operation\n\t * it could prove usefull for those sites which wish to have \"default\"\n\t * session information. */\n\tphp_session_track_init(TSRMLS_C);\n\tPS(invalid_session_id) = 0;\n\tif (PS(mod)->s_read(&PS(mod_data), PS(id), &val, &vallen TSRMLS_CC) == SUCCESS) {\n\t\tphp_session_decode(val, vallen TSRMLS_CC);\n\t\tefree(val);\n\t} else if (PS(invalid_session_id)) { /* address instances where the session read fails due to an invalid id */\n\t\tPS(invalid_session_id) = 0;\n\t\tefree(PS(id));\n\t\tPS(id) = NULL;\n\t\tgoto new_session;\n\t}\n}",
        "func": "static void php_session_initialize(TSRMLS_D) /* {{{ */\n{\n\tchar *val = NULL;\n\tint vallen;\n\n\tif (!PS(mod)) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"No storage module chosen - failed to initialize session\");\n\t\treturn;\n\t}\n\n\t/* Open session handler first */\n\tif (PS(mod)->s_open(&PS(mod_data), PS(save_path), PS(session_name) TSRMLS_CC) == FAILURE) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"Failed to initialize storage module: %s (path: %s)\", PS(mod)->s_name, PS(save_path));\n\t\treturn;\n\t}\n\n\t/* If there is no ID, use session module to create one */\n\tif (!PS(id)) {\n\t\tPS(id) = PS(mod)->s_create_sid(&PS(mod_data), NULL TSRMLS_CC);\n\t\tif (!PS(id)) {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"Failed to create session ID: %s (path: %s)\", PS(mod)->s_name, PS(save_path));\n\t\t\treturn;\n\t\t}\n\t\tif (PS(use_cookies)) {\n\t\t\tPS(send_cookie) = 1;\n\t\t}\n\t}\n\n\tphp_session_reset_id(TSRMLS_C);\n\tPS(session_status) = php_session_active;\n\n\t/* Read data */\n\tphp_session_track_init(TSRMLS_C);\n\tif (PS(mod)->s_read(&PS(mod_data), PS(id), &val, &vallen TSRMLS_CC) == FAILURE) {\n\t\t/* Some broken save handler implementation returns FAILURE for non-existent session ID */\n\t\t/* It's better to rase error for this, but disabled error for better compatibility */\n\t\t/*\n\t\tphp_error_docref(NULL TSRMLS_CC, E_NOTICE, \"Failed to read session data: %s (path: %s)\", PS(mod)->s_name, PS(save_path));\n\t\t*/\n\t}\n\tif (val) {\n\t\tphp_session_decode(val, vallen TSRMLS_CC);\n\t\tefree(val);\n\t}\n\n\tif (!PS(use_cookies) && PS(send_cookie)) {\n\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {\n\t\t\tPS(apply_trans_sid) = 1;\n\t\t}\n\t\tPS(send_cookie) = 0;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,7 @@\n static void php_session_initialize(TSRMLS_D) /* {{{ */\n {\n-\tchar *val;\n+\tchar *val = NULL;\n \tint vallen;\n-\n-\t/* check session name for invalid characters */\n-\tif (PS(id) && strpbrk(PS(id), \"\\r\\n\\t <>'\\\"\\\\\")) {\n-\t\tefree(PS(id));\n-\t\tPS(id) = NULL;\n-\t}\n \n \tif (!PS(mod)) {\n \t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"No storage module chosen - failed to initialize session\");\n@@ -22,27 +16,37 @@\n \n \t/* If there is no ID, use session module to create one */\n \tif (!PS(id)) {\n-new_session:\n \t\tPS(id) = PS(mod)->s_create_sid(&PS(mod_data), NULL TSRMLS_CC);\n+\t\tif (!PS(id)) {\n+\t\t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"Failed to create session ID: %s (path: %s)\", PS(mod)->s_name, PS(save_path));\n+\t\t\treturn;\n+\t\t}\n \t\tif (PS(use_cookies)) {\n \t\t\tPS(send_cookie) = 1;\n \t\t}\n \t}\n \n+\tphp_session_reset_id(TSRMLS_C);\n+\tPS(session_status) = php_session_active;\n+\n \t/* Read data */\n-\t/* Question: if you create a SID here, should you also try to read data?\n-\t * I'm not sure, but while not doing so will remove one session operation\n-\t * it could prove usefull for those sites which wish to have \"default\"\n-\t * session information. */\n \tphp_session_track_init(TSRMLS_C);\n-\tPS(invalid_session_id) = 0;\n-\tif (PS(mod)->s_read(&PS(mod_data), PS(id), &val, &vallen TSRMLS_CC) == SUCCESS) {\n+\tif (PS(mod)->s_read(&PS(mod_data), PS(id), &val, &vallen TSRMLS_CC) == FAILURE) {\n+\t\t/* Some broken save handler implementation returns FAILURE for non-existent session ID */\n+\t\t/* It's better to rase error for this, but disabled error for better compatibility */\n+\t\t/*\n+\t\tphp_error_docref(NULL TSRMLS_CC, E_NOTICE, \"Failed to read session data: %s (path: %s)\", PS(mod)->s_name, PS(save_path));\n+\t\t*/\n+\t}\n+\tif (val) {\n \t\tphp_session_decode(val, vallen TSRMLS_CC);\n \t\tefree(val);\n-\t} else if (PS(invalid_session_id)) { /* address instances where the session read fails due to an invalid id */\n-\t\tPS(invalid_session_id) = 0;\n-\t\tefree(PS(id));\n-\t\tPS(id) = NULL;\n-\t\tgoto new_session;\n+\t}\n+\n+\tif (!PS(use_cookies) && PS(send_cookie)) {\n+\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {\n+\t\t\tPS(apply_trans_sid) = 1;\n+\t\t}\n+\t\tPS(send_cookie) = 0;\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tchar *val;",
                "",
                "\t/* check session name for invalid characters */",
                "\tif (PS(id) && strpbrk(PS(id), \"\\r\\n\\t <>'\\\"\\\\\")) {",
                "\t\tefree(PS(id));",
                "\t\tPS(id) = NULL;",
                "\t}",
                "new_session:",
                "\t/* Question: if you create a SID here, should you also try to read data?",
                "\t * I'm not sure, but while not doing so will remove one session operation",
                "\t * it could prove usefull for those sites which wish to have \"default\"",
                "\t * session information. */",
                "\tPS(invalid_session_id) = 0;",
                "\tif (PS(mod)->s_read(&PS(mod_data), PS(id), &val, &vallen TSRMLS_CC) == SUCCESS) {",
                "\t} else if (PS(invalid_session_id)) { /* address instances where the session read fails due to an invalid id */",
                "\t\tPS(invalid_session_id) = 0;",
                "\t\tefree(PS(id));",
                "\t\tPS(id) = NULL;",
                "\t\tgoto new_session;"
            ],
            "added_lines": [
                "\tchar *val = NULL;",
                "\t\tif (!PS(id)) {",
                "\t\t\tphp_error_docref(NULL TSRMLS_CC, E_ERROR, \"Failed to create session ID: %s (path: %s)\", PS(mod)->s_name, PS(save_path));",
                "\t\t\treturn;",
                "\t\t}",
                "\tphp_session_reset_id(TSRMLS_C);",
                "\tPS(session_status) = php_session_active;",
                "",
                "\tif (PS(mod)->s_read(&PS(mod_data), PS(id), &val, &vallen TSRMLS_CC) == FAILURE) {",
                "\t\t/* Some broken save handler implementation returns FAILURE for non-existent session ID */",
                "\t\t/* It's better to rase error for this, but disabled error for better compatibility */",
                "\t\t/*",
                "\t\tphp_error_docref(NULL TSRMLS_CC, E_NOTICE, \"Failed to read session data: %s (path: %s)\", PS(mod)->s_name, PS(save_path));",
                "\t\t*/",
                "\t}",
                "\tif (val) {",
                "\t}",
                "",
                "\tif (!PS(use_cookies) && PS(send_cookie)) {",
                "\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {",
                "\t\t\tPS(apply_trans_sid) = 1;",
                "\t\t}",
                "\t\tPS(send_cookie) = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4718",
        "func_name": "php/php-src/php_session_destroy",
        "description": "Session fixation vulnerability in the Sessions subsystem in PHP before 5.5.2 allows remote attackers to hijack web sessions by specifying a session ID.",
        "git_url": "https://github.com/php/php-src/commit/25e8fcc88fa20dc9d4c47184471003f436927cde",
        "commit_title": "Strict session",
        "commit_text": "",
        "func_before": "static int php_session_destroy(TSRMLS_D) /* {{{ */\n{\n\tint retval = SUCCESS;\n\n\tif (PS(session_status) != php_session_active) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Trying to destroy uninitialized session\");\n\t\treturn FAILURE;\n\t}\n\n\tif (PS(mod)->s_destroy(&PS(mod_data), PS(id) TSRMLS_CC) == FAILURE) {\n\t\tretval = FAILURE;\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Session object destruction failed\");\n\t}\n\n\tphp_rshutdown_session_globals(TSRMLS_C);\n\tphp_rinit_session_globals(TSRMLS_C);\n\n\treturn retval;\n}",
        "func": "static int php_session_destroy(TSRMLS_D) /* {{{ */\n{\n\tint retval = SUCCESS;\n\n\tif (PS(session_status) != php_session_active) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Trying to destroy uninitialized session\");\n\t\treturn FAILURE;\n\t}\n\n\tif (PS(id) && PS(mod)->s_destroy(&PS(mod_data), PS(id) TSRMLS_CC) == FAILURE) {\n\t\tretval = FAILURE;\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Session object destruction failed\");\n\t}\n\n\tphp_rshutdown_session_globals(TSRMLS_C);\n\tphp_rinit_session_globals(TSRMLS_C);\n\n\treturn retval;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n \t\treturn FAILURE;\n \t}\n \n-\tif (PS(mod)->s_destroy(&PS(mod_data), PS(id) TSRMLS_CC) == FAILURE) {\n+\tif (PS(id) && PS(mod)->s_destroy(&PS(mod_data), PS(id) TSRMLS_CC) == FAILURE) {\n \t\tretval = FAILURE;\n \t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Session object destruction failed\");\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (PS(mod)->s_destroy(&PS(mod_data), PS(id) TSRMLS_CC) == FAILURE) {"
            ],
            "added_lines": [
                "\tif (PS(id) && PS(mod)->s_destroy(&PS(mod_data), PS(id) TSRMLS_CC) == FAILURE) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4718",
        "func_name": "php/php-src/php_session_start",
        "description": "Session fixation vulnerability in the Sessions subsystem in PHP before 5.5.2 allows remote attackers to hijack web sessions by specifying a session ID.",
        "git_url": "https://github.com/php/php-src/commit/25e8fcc88fa20dc9d4c47184471003f436927cde",
        "commit_title": "Strict session",
        "commit_text": "",
        "func_before": "PHPAPI void php_session_start(TSRMLS_D) /* {{{ */\n{\n\tzval **ppid;\n\tzval **data;\n\tchar *p, *value;\n\tint nrand;\n\tint lensess;\n\n\tif (PS(use_only_cookies)) {\n\t\tPS(apply_trans_sid) = 0;\n\t} else {\n\t\tPS(apply_trans_sid) = PS(use_trans_sid);\n\t}\n\n\tswitch (PS(session_status)) {\n\t\tcase php_session_active:\n\t\t\tphp_error(E_NOTICE, \"A session had already been started - ignoring session_start()\");\n\t\t\treturn;\n\t\t\tbreak;\n\n\t\tcase php_session_disabled:\n\t\t\tvalue = zend_ini_string(\"session.save_handler\", sizeof(\"session.save_handler\"), 0);\n\t\t\tif (!PS(mod) && value) {\n\t\t\t\tPS(mod) = _php_find_ps_module(value TSRMLS_CC);\n\t\t\t\tif (!PS(mod)) {\n\t\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Cannot find save handler '%s' - session startup failed\", value);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tvalue = zend_ini_string(\"session.serialize_handler\", sizeof(\"session.serialize_handler\"), 0);\n\t\t\tif (!PS(serializer) && value) {\n\t\t\t\tPS(serializer) = _php_find_ps_serializer(value TSRMLS_CC);\n\t\t\t\tif (!PS(serializer)) {\n\t\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Cannot find serialization handler '%s' - session startup failed\", value);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tPS(session_status) = php_session_none;\n\t\t\t/* fallthrough */\n\n\t\tdefault:\n\t\tcase php_session_none:\n\t\t\tPS(define_sid) = 1;\n\t\t\tPS(send_cookie) = 1;\n\t}\n\n\tlensess = strlen(PS(session_name));\n\n\t/* Cookies are preferred, because initially\n\t * cookie and get variables will be available. */\n\n\tif (!PS(id)) {\n\t\tif (PS(use_cookies) && zend_hash_find(&EG(symbol_table), \"_COOKIE\", sizeof(\"_COOKIE\"), (void **) &data) == SUCCESS &&\n\t\t\t\tZ_TYPE_PP(data) == IS_ARRAY &&\n\t\t\t\tzend_hash_find(Z_ARRVAL_PP(data), PS(session_name), lensess + 1, (void **) &ppid) == SUCCESS\n\t\t) {\n\t\t\tPPID2SID;\n\t\t\tPS(apply_trans_sid) = 0;\n\t\t\tPS(send_cookie) = 0;\n\t\t\tPS(define_sid) = 0;\n\t\t}\n\n\t\tif (!PS(use_only_cookies) && !PS(id) &&\n\t\t\t\tzend_hash_find(&EG(symbol_table), \"_GET\", sizeof(\"_GET\"), (void **) &data) == SUCCESS &&\n\t\t\t\tZ_TYPE_PP(data) == IS_ARRAY &&\n\t\t\t\tzend_hash_find(Z_ARRVAL_PP(data), PS(session_name), lensess + 1, (void **) &ppid) == SUCCESS\n\t\t) {\n\t\t\tPPID2SID;\n\t\t\tPS(send_cookie) = 0;\n\t\t}\n\n\t\tif (!PS(use_only_cookies) && !PS(id) &&\n\t\t\t\tzend_hash_find(&EG(symbol_table), \"_POST\", sizeof(\"_POST\"), (void **) &data) == SUCCESS &&\n\t\t\t\tZ_TYPE_PP(data) == IS_ARRAY &&\n\t\t\t\tzend_hash_find(Z_ARRVAL_PP(data), PS(session_name), lensess + 1, (void **) &ppid) == SUCCESS\n\t\t) {\n\t\t\tPPID2SID;\n\t\t\tPS(send_cookie) = 0;\n\t\t}\n\t}\n\n\t/* Check the REQUEST_URI symbol for a string of the form\n\t * '<session-name>=<session-id>' to allow URLs of the form\n\t * http://yoursite/<session-name>=<session-id>/script.php */\n\n\tif (!PS(use_only_cookies) && !PS(id) && PG(http_globals)[TRACK_VARS_SERVER] &&\n\t\t\tzend_hash_find(Z_ARRVAL_P(PG(http_globals)[TRACK_VARS_SERVER]), \"REQUEST_URI\", sizeof(\"REQUEST_URI\"), (void **) &data) == SUCCESS &&\n\t\t\tZ_TYPE_PP(data) == IS_STRING &&\n\t\t\t(p = strstr(Z_STRVAL_PP(data), PS(session_name))) &&\n\t\t\tp[lensess] == '='\n\t) {\n\t\tchar *q;\n\n\t\tp += lensess + 1;\n\t\tif ((q = strpbrk(p, \"/?\\\\\"))) {\n\t\t\tPS(id) = estrndup(p, q - p);\n\t\t\tPS(send_cookie) = 0;\n\t\t}\n\t}\n\n\t/* Check whether the current request was referred to by\n\t * an external site which invalidates the previously found id. */\n\n\tif (PS(id) &&\n\t\t\tPS(extern_referer_chk)[0] != '\\0' &&\n\t\t\tPG(http_globals)[TRACK_VARS_SERVER] &&\n\t\t\tzend_hash_find(Z_ARRVAL_P(PG(http_globals)[TRACK_VARS_SERVER]), \"HTTP_REFERER\", sizeof(\"HTTP_REFERER\"), (void **) &data) == SUCCESS &&\n\t\t\tZ_TYPE_PP(data) == IS_STRING &&\n\t\t\tZ_STRLEN_PP(data) != 0 &&\n\t\t\tstrstr(Z_STRVAL_PP(data), PS(extern_referer_chk)) == NULL\n\t) {\n\t\tefree(PS(id));\n\t\tPS(id) = NULL;\n\t\tPS(send_cookie) = 1;\n\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {\n\t\t\tPS(apply_trans_sid) = 1;\n\t\t}\n\t}\n\n\tphp_session_initialize(TSRMLS_C);\n\n\tif (!PS(use_cookies) && PS(send_cookie)) {\n\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {\n\t\t\tPS(apply_trans_sid) = 1;\n\t\t}\n\t\tPS(send_cookie) = 0;\n\t}\n\n\tphp_session_reset_id(TSRMLS_C);\n\n\tPS(session_status) = php_session_active;\n\n\tphp_session_cache_limiter(TSRMLS_C);\n\n\tif ((PS(mod_data) || PS(mod_user_implemented)) && PS(gc_probability) > 0) {\n\t\tint nrdels = -1;\n\n\t\tnrand = (int) ((float) PS(gc_divisor) * php_combined_lcg(TSRMLS_C));\n\t\tif (nrand < PS(gc_probability)) {\n\t\t\tPS(mod)->s_gc(&PS(mod_data), PS(gc_maxlifetime), &nrdels TSRMLS_CC);\n#ifdef SESSION_DEBUG\n\t\t\tif (nrdels != -1) {\n\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_NOTICE, \"purged %d expired session objects\", nrdels);\n\t\t\t}\n#endif\n\t\t}\n\t}\n}",
        "func": "PHPAPI void php_session_start(TSRMLS_D) /* {{{ */\n{\n\tzval **ppid;\n\tzval **data;\n\tchar *p, *value;\n\tint nrand;\n\tint lensess;\n\n\tif (PS(use_only_cookies)) {\n\t\tPS(apply_trans_sid) = 0;\n\t} else {\n\t\tPS(apply_trans_sid) = PS(use_trans_sid);\n\t}\n\n\tswitch (PS(session_status)) {\n\t\tcase php_session_active:\n\t\t\tphp_error(E_NOTICE, \"A session had already been started - ignoring session_start()\");\n\t\t\treturn;\n\t\t\tbreak;\n\n\t\tcase php_session_disabled:\n\t\t\tvalue = zend_ini_string(\"session.save_handler\", sizeof(\"session.save_handler\"), 0);\n\t\t\tif (!PS(mod) && value) {\n\t\t\t\tPS(mod) = _php_find_ps_module(value TSRMLS_CC);\n\t\t\t\tif (!PS(mod)) {\n\t\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Cannot find save handler '%s' - session startup failed\", value);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tvalue = zend_ini_string(\"session.serialize_handler\", sizeof(\"session.serialize_handler\"), 0);\n\t\t\tif (!PS(serializer) && value) {\n\t\t\t\tPS(serializer) = _php_find_ps_serializer(value TSRMLS_CC);\n\t\t\t\tif (!PS(serializer)) {\n\t\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Cannot find serialization handler '%s' - session startup failed\", value);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tPS(session_status) = php_session_none;\n\t\t\t/* fallthrough */\n\n\t\tdefault:\n\t\tcase php_session_none:\n\t\t\tPS(define_sid) = 1;\n\t\t\tPS(send_cookie) = 1;\n\t}\n\n\tlensess = strlen(PS(session_name));\n\n\t/* Cookies are preferred, because initially\n\t * cookie and get variables will be available. */\n\n\tif (!PS(id)) {\n\t\tif (PS(use_cookies) && zend_hash_find(&EG(symbol_table), \"_COOKIE\", sizeof(\"_COOKIE\"), (void **) &data) == SUCCESS &&\n\t\t\t\tZ_TYPE_PP(data) == IS_ARRAY &&\n\t\t\t\tzend_hash_find(Z_ARRVAL_PP(data), PS(session_name), lensess + 1, (void **) &ppid) == SUCCESS\n\t\t) {\n\t\t\tPPID2SID;\n\t\t\tPS(apply_trans_sid) = 0;\n\t\t\tPS(send_cookie) = 0;\n\t\t\tPS(define_sid) = 0;\n\t\t}\n\n\t\tif (!PS(use_only_cookies) && !PS(id) &&\n\t\t\t\tzend_hash_find(&EG(symbol_table), \"_GET\", sizeof(\"_GET\"), (void **) &data) == SUCCESS &&\n\t\t\t\tZ_TYPE_PP(data) == IS_ARRAY &&\n\t\t\t\tzend_hash_find(Z_ARRVAL_PP(data), PS(session_name), lensess + 1, (void **) &ppid) == SUCCESS\n\t\t) {\n\t\t\tPPID2SID;\n\t\t\tPS(send_cookie) = 0;\n\t\t}\n\n\t\tif (!PS(use_only_cookies) && !PS(id) &&\n\t\t\t\tzend_hash_find(&EG(symbol_table), \"_POST\", sizeof(\"_POST\"), (void **) &data) == SUCCESS &&\n\t\t\t\tZ_TYPE_PP(data) == IS_ARRAY &&\n\t\t\t\tzend_hash_find(Z_ARRVAL_PP(data), PS(session_name), lensess + 1, (void **) &ppid) == SUCCESS\n\t\t) {\n\t\t\tPPID2SID;\n\t\t\tPS(send_cookie) = 0;\n\t\t}\n\t}\n\n\t/* Check the REQUEST_URI symbol for a string of the form\n\t * '<session-name>=<session-id>' to allow URLs of the form\n\t * http://yoursite/<session-name>=<session-id>/script.php */\n\n\tif (!PS(use_only_cookies) && !PS(id) && PG(http_globals)[TRACK_VARS_SERVER] &&\n\t\t\tzend_hash_find(Z_ARRVAL_P(PG(http_globals)[TRACK_VARS_SERVER]), \"REQUEST_URI\", sizeof(\"REQUEST_URI\"), (void **) &data) == SUCCESS &&\n\t\t\tZ_TYPE_PP(data) == IS_STRING &&\n\t\t\t(p = strstr(Z_STRVAL_PP(data), PS(session_name))) &&\n\t\t\tp[lensess] == '='\n\t) {\n\t\tchar *q;\n\n\t\tp += lensess + 1;\n\t\tif ((q = strpbrk(p, \"/?\\\\\"))) {\n\t\t\tPS(id) = estrndup(p, q - p);\n\t\t\tPS(send_cookie) = 0;\n\t\t}\n\t}\n\n\t/* Check whether the current request was referred to by\n\t * an external site which invalidates the previously found id. */\n\n\tif (PS(id) &&\n\t\t\tPS(extern_referer_chk)[0] != '\\0' &&\n\t\t\tPG(http_globals)[TRACK_VARS_SERVER] &&\n\t\t\tzend_hash_find(Z_ARRVAL_P(PG(http_globals)[TRACK_VARS_SERVER]), \"HTTP_REFERER\", sizeof(\"HTTP_REFERER\"), (void **) &data) == SUCCESS &&\n\t\t\tZ_TYPE_PP(data) == IS_STRING &&\n\t\t\tZ_STRLEN_PP(data) != 0 &&\n\t\t\tstrstr(Z_STRVAL_PP(data), PS(extern_referer_chk)) == NULL\n\t) {\n\t\tefree(PS(id));\n\t\tPS(id) = NULL;\n\t\tPS(send_cookie) = 1;\n\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {\n\t\t\tPS(apply_trans_sid) = 1;\n\t\t}\n\t}\n\n\t/* Finally check session id for dangarous characters\n\t * Security note: session id may be embedded in HTML pages.*/\n\tif (PS(id) && strpbrk(PS(id), \"\\r\\n\\t <>'\\\"\\\\\")) {\n\t\tefree(PS(id));\n\t\tPS(id) = NULL;\n\t}\n\n\tphp_session_initialize(TSRMLS_C);\n\tphp_session_cache_limiter(TSRMLS_C);\n\n\tif ((PS(mod_data) || PS(mod_user_implemented)) && PS(gc_probability) > 0) {\n\t\tint nrdels = -1;\n\n\t\tnrand = (int) ((float) PS(gc_divisor) * php_combined_lcg(TSRMLS_C));\n\t\tif (nrand < PS(gc_probability)) {\n\t\t\tPS(mod)->s_gc(&PS(mod_data), PS(gc_maxlifetime), &nrdels TSRMLS_CC);\n#ifdef SESSION_DEBUG\n\t\t\tif (nrdels != -1) {\n\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_NOTICE, \"purged %d expired session objects\", nrdels);\n\t\t\t}\n#endif\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -117,19 +117,14 @@\n \t\t}\n \t}\n \n-\tphp_session_initialize(TSRMLS_C);\n-\n-\tif (!PS(use_cookies) && PS(send_cookie)) {\n-\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {\n-\t\t\tPS(apply_trans_sid) = 1;\n-\t\t}\n-\t\tPS(send_cookie) = 0;\n+\t/* Finally check session id for dangarous characters\n+\t * Security note: session id may be embedded in HTML pages.*/\n+\tif (PS(id) && strpbrk(PS(id), \"\\r\\n\\t <>'\\\"\\\\\")) {\n+\t\tefree(PS(id));\n+\t\tPS(id) = NULL;\n \t}\n \n-\tphp_session_reset_id(TSRMLS_C);\n-\n-\tPS(session_status) = php_session_active;\n-\n+\tphp_session_initialize(TSRMLS_C);\n \tphp_session_cache_limiter(TSRMLS_C);\n \n \tif ((PS(mod_data) || PS(mod_user_implemented)) && PS(gc_probability) > 0) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tphp_session_initialize(TSRMLS_C);",
                "",
                "\tif (!PS(use_cookies) && PS(send_cookie)) {",
                "\t\tif (PS(use_trans_sid) && !PS(use_only_cookies)) {",
                "\t\t\tPS(apply_trans_sid) = 1;",
                "\t\t}",
                "\t\tPS(send_cookie) = 0;",
                "\tphp_session_reset_id(TSRMLS_C);",
                "",
                "\tPS(session_status) = php_session_active;",
                ""
            ],
            "added_lines": [
                "\t/* Finally check session id for dangarous characters",
                "\t * Security note: session id may be embedded in HTML pages.*/",
                "\tif (PS(id) && strpbrk(PS(id), \"\\r\\n\\t <>'\\\"\\\\\")) {",
                "\t\tefree(PS(id));",
                "\t\tPS(id) = NULL;",
                "\tphp_session_initialize(TSRMLS_C);"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4718",
        "func_name": "php/php-src/php_session_reset_id",
        "description": "Session fixation vulnerability in the Sessions subsystem in PHP before 5.5.2 allows remote attackers to hijack web sessions by specifying a session ID.",
        "git_url": "https://github.com/php/php-src/commit/25e8fcc88fa20dc9d4c47184471003f436927cde",
        "commit_title": "Strict session",
        "commit_text": "",
        "func_before": "static void php_session_reset_id(TSRMLS_D) /* {{{ */\n{\n\tint module_number = PS(module_number);\n\n\tif (PS(use_cookies) && PS(send_cookie)) {\n\t\tphp_session_send_cookie(TSRMLS_C);\n\t\tPS(send_cookie) = 0;\n\t}\n\n\t/* if the SID constant exists, destroy it. */\n\tzend_hash_del(EG(zend_constants), \"sid\", sizeof(\"sid\"));\n\n\tif (PS(define_sid)) {\n\t\tsmart_str var = {0};\n\n\t\tsmart_str_appends(&var, PS(session_name));\n\t\tsmart_str_appendc(&var, '=');\n\t\tsmart_str_appends(&var, PS(id));\n\t\tsmart_str_0(&var);\n\t\tREGISTER_STRINGL_CONSTANT(\"SID\", var.c, var.len, 0);\n\t} else {\n\t\tREGISTER_STRINGL_CONSTANT(\"SID\", STR_EMPTY_ALLOC(), 0, 0);\n\t}\n\n\tif (PS(apply_trans_sid)) {\n\t\tphp_url_scanner_reset_vars(TSRMLS_C);\n\t\tphp_url_scanner_add_var(PS(session_name), strlen(PS(session_name)), PS(id), strlen(PS(id)), 1 TSRMLS_CC);\n\t}\n}",
        "func": "PHPAPI void php_session_reset_id(TSRMLS_D) /* {{{ */\n{\n\tint module_number = PS(module_number);\n\n\tif (!PS(id)) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Cannot set session ID - session ID is not initialized\");\n\t\treturn;\n\t}\n\n\tif (PS(use_cookies) && PS(send_cookie)) {\n\t\tphp_session_send_cookie(TSRMLS_C);\n\t\tPS(send_cookie) = 0;\n\t}\n\n\t/* if the SID constant exists, destroy it. */\n\tzend_hash_del(EG(zend_constants), \"sid\", sizeof(\"sid\"));\n\n\tif (PS(define_sid)) {\n\t\tsmart_str var = {0};\n\n\t\tsmart_str_appends(&var, PS(session_name));\n\t\tsmart_str_appendc(&var, '=');\n\t\tsmart_str_appends(&var, PS(id));\n\t\tsmart_str_0(&var);\n\t\tREGISTER_STRINGL_CONSTANT(\"SID\", var.c, var.len, 0);\n\t} else {\n\t\tREGISTER_STRINGL_CONSTANT(\"SID\", STR_EMPTY_ALLOC(), 0, 0);\n\t}\n\n\tif (PS(apply_trans_sid)) {\n\t\tphp_url_scanner_reset_vars(TSRMLS_C);\n\t\tphp_url_scanner_add_var(PS(session_name), strlen(PS(session_name)), PS(id), strlen(PS(id)), 1 TSRMLS_CC);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,11 @@\n-static void php_session_reset_id(TSRMLS_D) /* {{{ */\n+PHPAPI void php_session_reset_id(TSRMLS_D) /* {{{ */\n {\n \tint module_number = PS(module_number);\n+\n+\tif (!PS(id)) {\n+\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Cannot set session ID - session ID is not initialized\");\n+\t\treturn;\n+\t}\n \n \tif (PS(use_cookies) && PS(send_cookie)) {\n \t\tphp_session_send_cookie(TSRMLS_C);",
        "diff_line_info": {
            "deleted_lines": [
                "static void php_session_reset_id(TSRMLS_D) /* {{{ */"
            ],
            "added_lines": [
                "PHPAPI void php_session_reset_id(TSRMLS_D) /* {{{ */",
                "",
                "\tif (!PS(id)) {",
                "\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Cannot set session ID - session ID is not initialized\");",
                "\t\treturn;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4718",
        "func_name": "php/php-src/ps_sd_new",
        "description": "Session fixation vulnerability in the Sessions subsystem in PHP before 5.5.2 allows remote attackers to hijack web sessions by specifying a session ID.",
        "git_url": "https://github.com/php/php-src/commit/25e8fcc88fa20dc9d4c47184471003f436927cde",
        "commit_title": "Strict session",
        "commit_text": "",
        "func_before": "static ps_sd *ps_sd_new(ps_mm *data, const char *key)\n{\n\tphp_uint32 hv, slot;\n\tps_sd *sd;\n\tint keylen;\n\n\tkeylen = strlen(key);\n\n\tsd = mm_malloc(data->mm, sizeof(ps_sd) + keylen);\n\tif (!sd) {\n\t\tTSRMLS_FETCH();\n\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"mm_malloc failed, avail %d, err %s\", mm_available(data->mm), mm_error());\n\t\treturn NULL;\n\t}\n\n\thv = ps_sd_hash(key, keylen);\n\tslot = hv & data->hash_max;\n\n\tsd->ctime = 0;\n\tsd->hv = hv;\n\tsd->data = NULL;\n\tsd->alloclen = sd->datalen = 0;\n\n\tmemcpy(sd->key, key, keylen + 1);\n\n\tsd->next = data->hash[slot];\n\tdata->hash[slot] = sd;\n\n\tdata->hash_cnt++;\n\n\tif (!sd->next) {\n\t\tif (data->hash_cnt >= data->hash_max) {\n\t\t\thash_split(data);\n\t\t}\n\t}\n\n\tps_mm_debug((\"inserting %s(%p) into slot %d\\n\", key, sd, slot));\n\n\treturn sd;\n}",
        "func": "static ps_sd *ps_sd_new(ps_mm *data, const char *key)\n{\n\tphp_uint32 hv, slot;\n\tps_sd *sd;\n\tint keylen;\n\n\tkeylen = strlen(key);\n\n\tsd = mm_malloc(data->mm, sizeof(ps_sd) + keylen);\n\tif (!sd) {\n\t\tTSRMLS_FETCH();\n\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"mm_malloc failed, avail %ld, err %s\", mm_available(data->mm), mm_error());\n\t\treturn NULL;\n\t}\n\n\thv = ps_sd_hash(key, keylen);\n\tslot = hv & data->hash_max;\n\n\tsd->ctime = 0;\n\tsd->hv = hv;\n\tsd->data = NULL;\n\tsd->alloclen = sd->datalen = 0;\n\n\tmemcpy(sd->key, key, keylen + 1);\n\n\tsd->next = data->hash[slot];\n\tdata->hash[slot] = sd;\n\n\tdata->hash_cnt++;\n\n\tif (!sd->next) {\n\t\tif (data->hash_cnt >= data->hash_max) {\n\t\t\thash_split(data);\n\t\t}\n\t}\n\n\tps_mm_debug((\"inserting %s(%p) into slot %d\\n\", key, sd, slot));\n\n\treturn sd;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n \tif (!sd) {\n \t\tTSRMLS_FETCH();\n \n-\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"mm_malloc failed, avail %d, err %s\", mm_available(data->mm), mm_error());\n+\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"mm_malloc failed, avail %ld, err %s\", mm_available(data->mm), mm_error());\n \t\treturn NULL;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"mm_malloc failed, avail %d, err %s\", mm_available(data->mm), mm_error());"
            ],
            "added_lines": [
                "\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"mm_malloc failed, avail %ld, err %s\", mm_available(data->mm), mm_error());"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-4718",
        "func_name": "php/php-src/ps_files_open",
        "description": "Session fixation vulnerability in the Sessions subsystem in PHP before 5.5.2 allows remote attackers to hijack web sessions by specifying a session ID.",
        "git_url": "https://github.com/php/php-src/commit/25e8fcc88fa20dc9d4c47184471003f436927cde",
        "commit_title": "Strict session",
        "commit_text": "",
        "func_before": "static void ps_files_open(ps_files *data, const char *key TSRMLS_DC)\n{\n\tchar buf[MAXPATHLEN];\n\n\tif (data->fd < 0 || !data->lastkey || strcmp(key, data->lastkey)) {\n\t\tif (data->lastkey) {\n\t\t\tefree(data->lastkey);\n\t\t\tdata->lastkey = NULL;\n\t\t}\n\n\t\tps_files_close(data);\n\n\t\tif (!ps_files_valid_key(key)) {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"The session id is too long or contains illegal characters, valid characters are a-z, A-Z, 0-9 and '-,'\");\n\t\t\tPS(invalid_session_id) = 1;\n\t\t\treturn;\n\t\t}\n\t\tif (!ps_files_path_create(buf, sizeof(buf), data, key)) {\n\t\t\treturn;\n\t\t}\n\n\t\tdata->lastkey = estrdup(key);\n\n\t\tdata->fd = VCWD_OPEN_MODE(buf, O_CREAT | O_RDWR | O_BINARY, data->filemode);\n\n\t\tif (data->fd != -1) {\n#ifndef PHP_WIN32\n\t\t\t/* check to make sure that the opened file is not a symlink, linking to data outside of allowable dirs */\n\t\t\tif (PG(open_basedir)) {\n\t\t\t\tstruct stat sbuf;\n\n\t\t\t\tif (fstat(data->fd, &sbuf)) {\n\t\t\t\t\tclose(data->fd);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (S_ISLNK(sbuf.st_mode) && php_check_open_basedir(buf TSRMLS_CC)) {\n\t\t\t\t\tclose(data->fd);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tflock(data->fd, LOCK_EX);\n\n#ifdef F_SETFD\n# ifndef FD_CLOEXEC\n#  define FD_CLOEXEC 1\n# endif\n\t\t\tif (fcntl(data->fd, F_SETFD, FD_CLOEXEC)) {\n\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"fcntl(%d, F_SETFD, FD_CLOEXEC) failed: %s (%d)\", data->fd, strerror(errno), errno);\n\t\t\t}\n#endif\n\t\t} else {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"open(%s, O_RDWR) failed: %s (%d)\", buf, strerror(errno), errno);\n\t\t}\n\t}\n}",
        "func": "static void ps_files_open(ps_files *data, const char *key TSRMLS_DC)\n{\n\tchar buf[MAXPATHLEN];\n\n\tif (data->fd < 0 || !data->lastkey || strcmp(key, data->lastkey)) {\n\t\tif (data->lastkey) {\n\t\t\tefree(data->lastkey);\n\t\t\tdata->lastkey = NULL;\n\t\t}\n\n\t\tps_files_close(data);\n\n\t\tif (php_session_valid_key(key) == FAILURE) {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"The session id is too long or contains illegal characters, valid characters are a-z, A-Z, 0-9 and '-,'\");\n\t\t\treturn;\n\t\t}\n\n\t\tif (!ps_files_path_create(buf, sizeof(buf), data, key)) {\n\t\t\treturn;\n\t\t}\n\n\t\tdata->lastkey = estrdup(key);\n\n\t\tdata->fd = VCWD_OPEN_MODE(buf, O_CREAT | O_RDWR | O_BINARY, data->filemode);\n\n\t\tif (data->fd != -1) {\n#ifndef PHP_WIN32\n\t\t\t/* check to make sure that the opened file is not a symlink, linking to data outside of allowable dirs */\n\t\t\tif (PG(open_basedir)) {\n\t\t\t\tstruct stat sbuf;\n\n\t\t\t\tif (fstat(data->fd, &sbuf)) {\n\t\t\t\t\tclose(data->fd);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif (S_ISLNK(sbuf.st_mode) && php_check_open_basedir(buf TSRMLS_CC)) {\n\t\t\t\t\tclose(data->fd);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tflock(data->fd, LOCK_EX);\n\n#ifdef F_SETFD\n# ifndef FD_CLOEXEC\n#  define FD_CLOEXEC 1\n# endif\n\t\t\tif (fcntl(data->fd, F_SETFD, FD_CLOEXEC)) {\n\t\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"fcntl(%d, F_SETFD, FD_CLOEXEC) failed: %s (%d)\", data->fd, strerror(errno), errno);\n\t\t\t}\n#endif\n\t\t} else {\n\t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"open(%s, O_RDWR) failed: %s (%d)\", buf, strerror(errno), errno);\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,11 +10,11 @@\n \n \t\tps_files_close(data);\n \n-\t\tif (!ps_files_valid_key(key)) {\n+\t\tif (php_session_valid_key(key) == FAILURE) {\n \t\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"The session id is too long or contains illegal characters, valid characters are a-z, A-Z, 0-9 and '-,'\");\n-\t\t\tPS(invalid_session_id) = 1;\n \t\t\treturn;\n \t\t}\n+\n \t\tif (!ps_files_path_create(buf, sizeof(buf), data, key)) {\n \t\t\treturn;\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (!ps_files_valid_key(key)) {",
                "\t\t\tPS(invalid_session_id) = 1;"
            ],
            "added_lines": [
                "\t\tif (php_session_valid_key(key) == FAILURE) {",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2905",
        "func_name": "chromium/SharedMemory::Create",
        "description": "The SharedMemory::Create function in memory/shared_memory_posix.cc in Google Chrome before 29.0.1547.57 uses weak permissions under /dev/shm/, which allows attackers to obtain sensitive information via direct access to a POSIX shared-memory file.",
        "git_url": "https://github.com/chromium/chromium/commit/afb848acb43ba316097ab4fddfa38dbd80bc6a71",
        "commit_title": "Posix: fix named SHM mappings permissions.",
        "commit_text": " Make sure that named mappings in /dev/shm/ aren't created with broad permissions.   ",
        "func_before": "bool SharedMemory::Create(const SharedMemoryCreateOptions& options) {\n  DCHECK_EQ(-1, mapped_file_);\n  if (options.size == 0) return false;\n\n  if (options.size > static_cast<size_t>(std::numeric_limits<int>::max()))\n    return false;\n\n  // This function theoretically can block on the disk, but realistically\n  // the temporary files we create will just go into the buffer cache\n  // and be deleted before they ever make it out to disk.\n  base::ThreadRestrictions::ScopedAllowIO allow_io;\n\n  FILE *fp;\n  bool fix_size = true;\n\n  FilePath path;\n  if (options.name == NULL || options.name->empty()) {\n    // It doesn't make sense to have a open-existing private piece of shmem\n    DCHECK(!options.open_existing);\n    // Q: Why not use the shm_open() etc. APIs?\n    // A: Because they're limited to 4mb on OS X.  FFFFFFFUUUUUUUUUUU\n    fp = file_util::CreateAndOpenTemporaryShmemFile(&path, options.executable);\n\n    // Deleting the file prevents anyone else from mapping it in (making it\n    // private), and prevents the need for cleanup (once the last fd is closed,\n    // it is truly freed).\n    if (fp) {\n      if (unlink(path.value().c_str()))\n        PLOG(WARNING) << \"unlink\";\n    }\n  } else {\n    if (!FilePathForMemoryName(*options.name, &path))\n      return false;\n\n    fp = file_util::OpenFile(path, \"w+x\");\n    if (fp == NULL && options.open_existing) {\n      // \"w+\" will truncate if it already exists.\n      fp = file_util::OpenFile(path, \"a+\");\n      fix_size = false;\n    }\n  }\n  if (fp && fix_size) {\n    // Get current size.\n    struct stat stat;\n    if (fstat(fileno(fp), &stat) != 0) {\n      file_util::CloseFile(fp);\n      return false;\n    }\n    const size_t current_size = stat.st_size;\n    if (current_size != options.size) {\n      if (HANDLE_EINTR(ftruncate(fileno(fp), options.size)) != 0) {\n        file_util::CloseFile(fp);\n        return false;\n      }\n    }\n    requested_size_ = options.size;\n  }\n  if (fp == NULL) {\n#if !defined(OS_MACOSX)\n    PLOG(ERROR) << \"Creating shared memory in \" << path.value() << \" failed\";\n    FilePath dir = path.DirName();\n    if (access(dir.value().c_str(), W_OK | X_OK) < 0) {\n      PLOG(ERROR) << \"Unable to access(W_OK|X_OK) \" << dir.value();\n      if (dir.value() == \"/dev/shm\") {\n        LOG(FATAL) << \"This is frequently caused by incorrect permissions on \"\n                   << \"/dev/shm.  Try 'sudo chmod 1777 /dev/shm' to fix.\";\n      }\n    }\n#else\n    PLOG(ERROR) << \"Creating shared memory in \" << path.value() << \" failed\";\n#endif\n    return false;\n  }\n\n  return PrepareMapFile(fp);\n}",
        "func": "bool SharedMemory::Create(const SharedMemoryCreateOptions& options) {\n  DCHECK_EQ(-1, mapped_file_);\n  if (options.size == 0) return false;\n\n  if (options.size > static_cast<size_t>(std::numeric_limits<int>::max()))\n    return false;\n\n  // This function theoretically can block on the disk, but realistically\n  // the temporary files we create will just go into the buffer cache\n  // and be deleted before they ever make it out to disk.\n  base::ThreadRestrictions::ScopedAllowIO allow_io;\n\n  FILE *fp;\n  bool fix_size = true;\n\n  FilePath path;\n  if (options.name == NULL || options.name->empty()) {\n    // It doesn't make sense to have a open-existing private piece of shmem\n    DCHECK(!options.open_existing);\n    // Q: Why not use the shm_open() etc. APIs?\n    // A: Because they're limited to 4mb on OS X.  FFFFFFFUUUUUUUUUUU\n    fp = file_util::CreateAndOpenTemporaryShmemFile(&path, options.executable);\n\n    // Deleting the file prevents anyone else from mapping it in (making it\n    // private), and prevents the need for cleanup (once the last fd is closed,\n    // it is truly freed).\n    if (fp) {\n      if (unlink(path.value().c_str()))\n        PLOG(WARNING) << \"unlink\";\n    }\n  } else {\n    if (!FilePathForMemoryName(*options.name, &path))\n      return false;\n\n    // Make sure that the file is opened without any permission\n    // to other users on the system.\n    const mode_t kOwnerOnly = S_IRUSR | S_IWUSR;\n\n    // First, try to create the file.\n    int fd = HANDLE_EINTR(\n        open(path.value().c_str(), O_RDWR | O_CREAT | O_EXCL, kOwnerOnly));\n    if (fd == -1 && options.open_existing) {\n      // If this doesn't work, try and open an existing file in append mode.\n      // Opening an existing file in a world writable directory has two main\n      // security implications:\n      // - Attackers could plant a file under their control, so ownership of\n      //   the file is checked below.\n      // - Attackers could plant a symbolic link so that an unexpected file\n      //   is opened, so O_NOFOLLOW is passed to open().\n      fd = HANDLE_EINTR(\n          open(path.value().c_str(), O_RDWR | O_APPEND | O_NOFOLLOW));\n\n      // Check that the current user owns the file.\n      // If uid != euid, then a more complex permission model is used and this\n      // API is not appropriate.\n      const uid_t real_uid = getuid();\n      const uid_t effective_uid = geteuid();\n      struct stat sb;\n      if (fd >= 0 &&\n          (fstat(fd, &sb) != 0 || sb.st_uid != real_uid ||\n           sb.st_uid != effective_uid)) {\n        LOG(ERROR) <<\n            \"Invalid owner when opening existing shared memory file.\";\n        HANDLE_EINTR(close(fd));\n        return false;\n      }\n\n      // An existing file was opened, so its size should not be fixed.\n      fix_size = false;\n    }\n    fp = NULL;\n    if (fd >= 0) {\n      // \"a+\" is always appropriate: if it's a new file, a+ is similar to w+.\n      fp = fdopen(fd, \"a+\");\n    }\n  }\n  if (fp && fix_size) {\n    // Get current size.\n    struct stat stat;\n    if (fstat(fileno(fp), &stat) != 0) {\n      file_util::CloseFile(fp);\n      return false;\n    }\n    const size_t current_size = stat.st_size;\n    if (current_size != options.size) {\n      if (HANDLE_EINTR(ftruncate(fileno(fp), options.size)) != 0) {\n        file_util::CloseFile(fp);\n        return false;\n      }\n    }\n    requested_size_ = options.size;\n  }\n  if (fp == NULL) {\n#if !defined(OS_MACOSX)\n    PLOG(ERROR) << \"Creating shared memory in \" << path.value() << \" failed\";\n    FilePath dir = path.DirName();\n    if (access(dir.value().c_str(), W_OK | X_OK) < 0) {\n      PLOG(ERROR) << \"Unable to access(W_OK|X_OK) \" << dir.value();\n      if (dir.value() == \"/dev/shm\") {\n        LOG(FATAL) << \"This is frequently caused by incorrect permissions on \"\n                   << \"/dev/shm.  Try 'sudo chmod 1777 /dev/shm' to fix.\";\n      }\n    }\n#else\n    PLOG(ERROR) << \"Creating shared memory in \" << path.value() << \" failed\";\n#endif\n    return false;\n  }\n\n  return PrepareMapFile(fp);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,11 +32,46 @@\n     if (!FilePathForMemoryName(*options.name, &path))\n       return false;\n \n-    fp = file_util::OpenFile(path, \"w+x\");\n-    if (fp == NULL && options.open_existing) {\n-      // \"w+\" will truncate if it already exists.\n-      fp = file_util::OpenFile(path, \"a+\");\n+    // Make sure that the file is opened without any permission\n+    // to other users on the system.\n+    const mode_t kOwnerOnly = S_IRUSR | S_IWUSR;\n+\n+    // First, try to create the file.\n+    int fd = HANDLE_EINTR(\n+        open(path.value().c_str(), O_RDWR | O_CREAT | O_EXCL, kOwnerOnly));\n+    if (fd == -1 && options.open_existing) {\n+      // If this doesn't work, try and open an existing file in append mode.\n+      // Opening an existing file in a world writable directory has two main\n+      // security implications:\n+      // - Attackers could plant a file under their control, so ownership of\n+      //   the file is checked below.\n+      // - Attackers could plant a symbolic link so that an unexpected file\n+      //   is opened, so O_NOFOLLOW is passed to open().\n+      fd = HANDLE_EINTR(\n+          open(path.value().c_str(), O_RDWR | O_APPEND | O_NOFOLLOW));\n+\n+      // Check that the current user owns the file.\n+      // If uid != euid, then a more complex permission model is used and this\n+      // API is not appropriate.\n+      const uid_t real_uid = getuid();\n+      const uid_t effective_uid = geteuid();\n+      struct stat sb;\n+      if (fd >= 0 &&\n+          (fstat(fd, &sb) != 0 || sb.st_uid != real_uid ||\n+           sb.st_uid != effective_uid)) {\n+        LOG(ERROR) <<\n+            \"Invalid owner when opening existing shared memory file.\";\n+        HANDLE_EINTR(close(fd));\n+        return false;\n+      }\n+\n+      // An existing file was opened, so its size should not be fixed.\n       fix_size = false;\n+    }\n+    fp = NULL;\n+    if (fd >= 0) {\n+      // \"a+\" is always appropriate: if it's a new file, a+ is similar to w+.\n+      fp = fdopen(fd, \"a+\");\n     }\n   }\n   if (fp && fix_size) {",
        "diff_line_info": {
            "deleted_lines": [
                "    fp = file_util::OpenFile(path, \"w+x\");",
                "    if (fp == NULL && options.open_existing) {",
                "      // \"w+\" will truncate if it already exists.",
                "      fp = file_util::OpenFile(path, \"a+\");"
            ],
            "added_lines": [
                "    // Make sure that the file is opened without any permission",
                "    // to other users on the system.",
                "    const mode_t kOwnerOnly = S_IRUSR | S_IWUSR;",
                "",
                "    // First, try to create the file.",
                "    int fd = HANDLE_EINTR(",
                "        open(path.value().c_str(), O_RDWR | O_CREAT | O_EXCL, kOwnerOnly));",
                "    if (fd == -1 && options.open_existing) {",
                "      // If this doesn't work, try and open an existing file in append mode.",
                "      // Opening an existing file in a world writable directory has two main",
                "      // security implications:",
                "      // - Attackers could plant a file under their control, so ownership of",
                "      //   the file is checked below.",
                "      // - Attackers could plant a symbolic link so that an unexpected file",
                "      //   is opened, so O_NOFOLLOW is passed to open().",
                "      fd = HANDLE_EINTR(",
                "          open(path.value().c_str(), O_RDWR | O_APPEND | O_NOFOLLOW));",
                "",
                "      // Check that the current user owns the file.",
                "      // If uid != euid, then a more complex permission model is used and this",
                "      // API is not appropriate.",
                "      const uid_t real_uid = getuid();",
                "      const uid_t effective_uid = geteuid();",
                "      struct stat sb;",
                "      if (fd >= 0 &&",
                "          (fstat(fd, &sb) != 0 || sb.st_uid != real_uid ||",
                "           sb.st_uid != effective_uid)) {",
                "        LOG(ERROR) <<",
                "            \"Invalid owner when opening existing shared memory file.\";",
                "        HANDLE_EINTR(close(fd));",
                "        return false;",
                "      }",
                "",
                "      // An existing file was opened, so its size should not be fixed.",
                "    }",
                "    fp = NULL;",
                "    if (fd >= 0) {",
                "      // \"a+\" is always appropriate: if it's a new file, a+ is similar to w+.",
                "      fp = fdopen(fd, \"a+\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4300",
        "func_name": "torvalds/linux/scm_check_creds",
        "description": "The scm_check_creds function in net/core/scm.c in the Linux kernel before 3.11 performs a capability check in an incorrect namespace, which allows local users to gain privileges via PID spoofing.",
        "git_url": "https://github.com/torvalds/linux/commit/d661684cf6820331feae71146c35da83d794467e",
        "commit_title": "net: Check the correct namespace when spoofing pid over SCM_RIGHTS",
        "commit_text": " This is a security bug.  The follow-up will fix nsproxy to discourage this type of issue from happening again.  Cc: stable@vger.kernel.org",
        "func_before": "static __inline__ int scm_check_creds(struct ucred *creds)\n{\n\tconst struct cred *cred = current_cred();\n\tkuid_t uid = make_kuid(cred->user_ns, creds->uid);\n\tkgid_t gid = make_kgid(cred->user_ns, creds->gid);\n\n\tif (!uid_valid(uid) || !gid_valid(gid))\n\t\treturn -EINVAL;\n\n\tif ((creds->pid == task_tgid_vnr(current) ||\n\t     ns_capable(current->nsproxy->pid_ns->user_ns, CAP_SYS_ADMIN)) &&\n\t    ((uid_eq(uid, cred->uid)   || uid_eq(uid, cred->euid) ||\n\t      uid_eq(uid, cred->suid)) || nsown_capable(CAP_SETUID)) &&\n\t    ((gid_eq(gid, cred->gid)   || gid_eq(gid, cred->egid) ||\n\t      gid_eq(gid, cred->sgid)) || nsown_capable(CAP_SETGID))) {\n\t       return 0;\n\t}\n\treturn -EPERM;\n}",
        "func": "static __inline__ int scm_check_creds(struct ucred *creds)\n{\n\tconst struct cred *cred = current_cred();\n\tkuid_t uid = make_kuid(cred->user_ns, creds->uid);\n\tkgid_t gid = make_kgid(cred->user_ns, creds->gid);\n\n\tif (!uid_valid(uid) || !gid_valid(gid))\n\t\treturn -EINVAL;\n\n\tif ((creds->pid == task_tgid_vnr(current) ||\n\t     ns_capable(task_active_pid_ns(current)->user_ns, CAP_SYS_ADMIN)) &&\n\t    ((uid_eq(uid, cred->uid)   || uid_eq(uid, cred->euid) ||\n\t      uid_eq(uid, cred->suid)) || nsown_capable(CAP_SETUID)) &&\n\t    ((gid_eq(gid, cred->gid)   || gid_eq(gid, cred->egid) ||\n\t      gid_eq(gid, cred->sgid)) || nsown_capable(CAP_SETGID))) {\n\t       return 0;\n\t}\n\treturn -EPERM;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \t\treturn -EINVAL;\n \n \tif ((creds->pid == task_tgid_vnr(current) ||\n-\t     ns_capable(current->nsproxy->pid_ns->user_ns, CAP_SYS_ADMIN)) &&\n+\t     ns_capable(task_active_pid_ns(current)->user_ns, CAP_SYS_ADMIN)) &&\n \t    ((uid_eq(uid, cred->uid)   || uid_eq(uid, cred->euid) ||\n \t      uid_eq(uid, cred->suid)) || nsown_capable(CAP_SETUID)) &&\n \t    ((gid_eq(gid, cred->gid)   || gid_eq(gid, cred->egid) ||",
        "diff_line_info": {
            "deleted_lines": [
                "\t     ns_capable(current->nsproxy->pid_ns->user_ns, CAP_SYS_ADMIN)) &&"
            ],
            "added_lines": [
                "\t     ns_capable(task_active_pid_ns(current)->user_ns, CAP_SYS_ADMIN)) &&"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4342",
        "func_name": "xinetd-org/xinetd/tcpmux_handler",
        "description": "xinetd does not enforce the user and group configuration directives for TCPMUX services, which causes these services to be run as root and makes it easier for remote attackers to gain privileges by leveraging another vulnerability in a service.",
        "git_url": "https://github.com/xinetd-org/xinetd/commit/91e2401a219121eae15244a6b25d2e79c1af5864",
        "commit_title": "CVE-2013-4342: xinetd: ignores user and group directives for TCPMUX services",
        "commit_text": " Originally reported to Debian in 2005 <http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=324678> and rediscovered <https://bugzilla.redhat.com/show_bug.cgi?id=1006100>, xinetd would execute TCPMUX services without dropping privilege to match the service configuration allowing the service to run with same privilege as the xinetd process (root).",
        "func_before": "static void tcpmux_handler( const struct server *serp )\n{\n   char      svc_name[ BUFFER_SIZE ] ;\n   int       cc ;\n   int       descriptor = SERVER_FD( serp ) ;\n   const     struct service *svc = SERVER_SERVICE( serp ) ;\n   unsigned  u;\n   struct    service *sp = NULL;\n   struct    server server, *nserp;\n   struct    service_config *scp = NULL;\n\n   close_all_svc_descriptors();\n\n   /*  Read in the name of the service in the format \"svc_name\\r\\n\".\n    *\n    *  XXX: should loop on partial reads (could probably use Sread() if\n    *  it wasn't thrown out of xinetd source code a few revisions back).\n    */\n   do\n   {\n      cc = read( descriptor, svc_name, sizeof( svc_name ) ) ;\n   } while (cc == -1 && errno == EINTR);\n\n   if ( cc <= 0 )\n   {\n      msg(LOG_ERR, \"tcpmux_handler\", \"read failed\");\n      exit(0);\n   }\n\n   if ( ( cc <= 2 ) ||\n        ( ( svc_name[cc - 1] != '\\n' ) || ( svc_name[cc - 2] != '\\r' ) ) )\n   {\n      if ( debug.on )\n         msg(LOG_DEBUG, \"tcpmux_handler\", \"Invalid service name format.\");\n      \n      exit(0);\n   }\n\n   svc_name[cc - 2] = '\\0';  /*  Remove \\r\\n for compare */\n\n   if ( debug.on )\n   {\n      msg(LOG_DEBUG, \"tcpmux_handler\", \"Input (%d bytes) %s as service name.\",\n          cc, svc_name);\n   }\n\n   /*  Search the services for the a match on name.\n    */\n\n   for ( u = 0 ; u < pset_count( SERVICES( ps ) ) ; u++ )\n   {\n      sp = SP( pset_pointer( SERVICES( ps ), u ) ) ;\n\n      if ( strcasecmp( svc_name, SC_NAME( SVC_CONF( sp ) ) ) == 0 )\n      {\n         /*  Found the pointer. Validate its type.\n          */\n         scp = SVC_CONF( sp );\n\n         if ( ! SVC_IS_MUXCLIENT( sp ) && ! SVC_IS_MUXPLUSCLIENT( sp ) )\n         {\n            if ( debug.on )\n            {\n               msg(LOG_DEBUG, \"tcpmux_handler\", \"Non-tcpmux service name: %s.\",\n                   svc_name);\n            }\n            continue;\n         }\n\n         /*  Send the accept string if we're a PLUS (+) client.\n          */\n\n         if ( SVC_IS_MUXPLUSCLIENT( sp ) )\n         {\n            if ( Swrite( descriptor, TCPMUX_ACK, sizeof( TCPMUX_ACK ) ) !=\n                 sizeof( TCPMUX_ACK ) )\n            {\n                msg(LOG_ERR, \"tcpmux_handler\", \"Ack write failed for %s.\",\n\t\t    svc_name);\n                exit(0);\n            }\n         }\n         break;  /*  Time to get on with the service */\n      }\n      continue;  /*  Keep looking */\n   }\n\n   if ( u >= pset_count( SERVICES( ps ) ) )\n   {\n      if ( debug.on )\n      {\n         msg(LOG_DEBUG, \"tcpmux_handler\", \"Service name %s not found.\",\n             svc_name);\n      }\n\n      /*  If a service was not found, we should say so. */\n      if ( Swrite( descriptor, TCPMUX_NOT_FOUND, sizeof( TCPMUX_NOT_FOUND ) ) !=\n           sizeof ( TCPMUX_NOT_FOUND ) )\n      {\n         msg(LOG_ERR, \"tcpmux_handler\", \"Not found write failed for %s.\",\n             svc_name);\n         exit(0);\n      }\n       \n      /*  Flush and exit, nothing to do */\n      Sflush( descriptor );\n      Sclose( descriptor );\n      exit(0);\n   }\n\n   if( SVC_WAITS( svc ) ) /* Service forks, so close it */\n      Sclose(descriptor);\n\n   server.svr_sp = sp;\n   server.svr_conn = SERVER_CONNECTION(serp);\n   nserp = server_alloc(&server);\n   if( SC_IS_INTERNAL( scp ) ) {\n      SC_INTERNAL(scp, nserp);\n   } else {\n      exec_server(nserp);\n   }\n}",
        "func": "static void tcpmux_handler( const struct server *serp )\n{\n   char      svc_name[ BUFFER_SIZE ] ;\n   int       cc ;\n   int       descriptor = SERVER_FD( serp ) ;\n   const     struct service *svc = SERVER_SERVICE( serp ) ;\n   unsigned  u;\n   struct    service *sp = NULL;\n   struct    server server, *nserp;\n   struct    service_config *scp = NULL;\n\n   close_all_svc_descriptors();\n\n   /*  Read in the name of the service in the format \"svc_name\\r\\n\".\n    *\n    *  XXX: should loop on partial reads (could probably use Sread() if\n    *  it wasn't thrown out of xinetd source code a few revisions back).\n    */\n   do\n   {\n      cc = read( descriptor, svc_name, sizeof( svc_name ) ) ;\n   } while (cc == -1 && errno == EINTR);\n\n   if ( cc <= 0 )\n   {\n      msg(LOG_ERR, \"tcpmux_handler\", \"read failed\");\n      exit(0);\n   }\n\n   if ( ( cc <= 2 ) ||\n        ( ( svc_name[cc - 1] != '\\n' ) || ( svc_name[cc - 2] != '\\r' ) ) )\n   {\n      if ( debug.on )\n         msg(LOG_DEBUG, \"tcpmux_handler\", \"Invalid service name format.\");\n      \n      exit(0);\n   }\n\n   svc_name[cc - 2] = '\\0';  /*  Remove \\r\\n for compare */\n\n   if ( debug.on )\n   {\n      msg(LOG_DEBUG, \"tcpmux_handler\", \"Input (%d bytes) %s as service name.\",\n          cc, svc_name);\n   }\n\n   /*  Search the services for the a match on name.\n    */\n\n   for ( u = 0 ; u < pset_count( SERVICES( ps ) ) ; u++ )\n   {\n      sp = SP( pset_pointer( SERVICES( ps ), u ) ) ;\n\n      if ( strcasecmp( svc_name, SC_NAME( SVC_CONF( sp ) ) ) == 0 )\n      {\n         /*  Found the pointer. Validate its type.\n          */\n         scp = SVC_CONF( sp );\n\n         if ( ! SVC_IS_MUXCLIENT( sp ) && ! SVC_IS_MUXPLUSCLIENT( sp ) )\n         {\n            if ( debug.on )\n            {\n               msg(LOG_DEBUG, \"tcpmux_handler\", \"Non-tcpmux service name: %s.\",\n                   svc_name);\n            }\n            continue;\n         }\n\n         /*  Send the accept string if we're a PLUS (+) client.\n          */\n\n         if ( SVC_IS_MUXPLUSCLIENT( sp ) )\n         {\n            if ( Swrite( descriptor, TCPMUX_ACK, sizeof( TCPMUX_ACK ) ) !=\n                 sizeof( TCPMUX_ACK ) )\n            {\n                msg(LOG_ERR, \"tcpmux_handler\", \"Ack write failed for %s.\",\n\t\t    svc_name);\n                exit(0);\n            }\n         }\n         break;  /*  Time to get on with the service */\n      }\n      continue;  /*  Keep looking */\n   }\n\n   if ( u >= pset_count( SERVICES( ps ) ) )\n   {\n      if ( debug.on )\n      {\n         msg(LOG_DEBUG, \"tcpmux_handler\", \"Service name %s not found.\",\n             svc_name);\n      }\n\n      /*  If a service was not found, we should say so. */\n      if ( Swrite( descriptor, TCPMUX_NOT_FOUND, sizeof( TCPMUX_NOT_FOUND ) ) !=\n           sizeof ( TCPMUX_NOT_FOUND ) )\n      {\n         msg(LOG_ERR, \"tcpmux_handler\", \"Not found write failed for %s.\",\n             svc_name);\n         exit(0);\n      }\n       \n      /*  Flush and exit, nothing to do */\n      Sflush( descriptor );\n      Sclose( descriptor );\n      exit(0);\n   }\n\n   if( SVC_WAITS( svc ) ) /* Service forks, so close it */\n      Sclose(descriptor);\n\n   server.svr_sp = sp;\n   server.svr_conn = SERVER_CONNECTION(serp);\n   nserp = server_alloc(&server);\n   if( SC_IS_INTERNAL( scp ) ) {\n      SC_INTERNAL(scp, nserp);\n   } else {\n      child_process(nserp);\n   }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -117,6 +117,6 @@\n    if( SC_IS_INTERNAL( scp ) ) {\n       SC_INTERNAL(scp, nserp);\n    } else {\n-      exec_server(nserp);\n+      child_process(nserp);\n    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      exec_server(nserp);"
            ],
            "added_lines": [
                "      child_process(nserp);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4299",
        "func_name": "torvalds/linux/persistent_prepare_exception",
        "description": "Interpretation conflict in drivers/md/dm-snap-persistent.c in the Linux kernel through 3.11.6 allows remote authenticated users to obtain sensitive information or modify data via a crafted mapping to a snapshot block device.",
        "git_url": "https://github.com/torvalds/linux/commit/e9c6a182649f4259db704ae15a91ac820e63b0ca",
        "commit_title": "dm snapshot: fix data corruption",
        "commit_text": " This patch fixes a particular type of data corruption that has been encountered when loading a snapshot's metadata from disk.  When we allocate a new chunk in persistent_prepare, we increment ps->next_free and we make sure that it doesn't point to a metadata area by further incrementing it if necessary.  When we load metadata from disk on device activation, ps->next_free is positioned after the last used data chunk. However, if this last used data chunk is followed by a metadata area, ps->next_free is positioned erroneously to the metadata area. A newly-allocated chunk is placed at the same location as the metadata area, resulting in data or metadata corruption.  This patch changes the code so that ps->next_free skips the metadata area when metadata are loaded in function read_exceptions.  The patch also moves a piece of code from persistent_prepare_exception to a separate function skip_metadata to avoid code duplication.  CVE-2013-4299  Cc: stable@vger.kernel.org Cc: Mike Snitzer <snitzer@redhat.com>",
        "func_before": "static int persistent_prepare_exception(struct dm_exception_store *store,\n\t\t\t\t\tstruct dm_exception *e)\n{\n\tstruct pstore *ps = get_info(store);\n\tuint32_t stride;\n\tchunk_t next_free;\n\tsector_t size = get_dev_size(dm_snap_cow(store->snap)->bdev);\n\n\t/* Is there enough room ? */\n\tif (size < ((ps->next_free + 1) * store->chunk_size))\n\t\treturn -ENOSPC;\n\n\te->new_chunk = ps->next_free;\n\n\t/*\n\t * Move onto the next free pending, making sure to take\n\t * into account the location of the metadata chunks.\n\t */\n\tstride = (ps->exceptions_per_area + 1);\n\tnext_free = ++ps->next_free;\n\tif (sector_div(next_free, stride) == 1)\n\t\tps->next_free++;\n\n\tatomic_inc(&ps->pending_count);\n\treturn 0;\n}",
        "func": "static int persistent_prepare_exception(struct dm_exception_store *store,\n\t\t\t\t\tstruct dm_exception *e)\n{\n\tstruct pstore *ps = get_info(store);\n\tsector_t size = get_dev_size(dm_snap_cow(store->snap)->bdev);\n\n\t/* Is there enough room ? */\n\tif (size < ((ps->next_free + 1) * store->chunk_size))\n\t\treturn -ENOSPC;\n\n\te->new_chunk = ps->next_free;\n\n\t/*\n\t * Move onto the next free pending, making sure to take\n\t * into account the location of the metadata chunks.\n\t */\n\tps->next_free++;\n\tskip_metadata(ps);\n\n\tatomic_inc(&ps->pending_count);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,8 +2,6 @@\n \t\t\t\t\tstruct dm_exception *e)\n {\n \tstruct pstore *ps = get_info(store);\n-\tuint32_t stride;\n-\tchunk_t next_free;\n \tsector_t size = get_dev_size(dm_snap_cow(store->snap)->bdev);\n \n \t/* Is there enough room ? */\n@@ -16,10 +14,8 @@\n \t * Move onto the next free pending, making sure to take\n \t * into account the location of the metadata chunks.\n \t */\n-\tstride = (ps->exceptions_per_area + 1);\n-\tnext_free = ++ps->next_free;\n-\tif (sector_div(next_free, stride) == 1)\n-\t\tps->next_free++;\n+\tps->next_free++;\n+\tskip_metadata(ps);\n \n \tatomic_inc(&ps->pending_count);\n \treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\tuint32_t stride;",
                "\tchunk_t next_free;",
                "\tstride = (ps->exceptions_per_area + 1);",
                "\tnext_free = ++ps->next_free;",
                "\tif (sector_div(next_free, stride) == 1)",
                "\t\tps->next_free++;"
            ],
            "added_lines": [
                "\tps->next_free++;",
                "\tskip_metadata(ps);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4299",
        "func_name": "torvalds/linux/read_exceptions",
        "description": "Interpretation conflict in drivers/md/dm-snap-persistent.c in the Linux kernel through 3.11.6 allows remote authenticated users to obtain sensitive information or modify data via a crafted mapping to a snapshot block device.",
        "git_url": "https://github.com/torvalds/linux/commit/e9c6a182649f4259db704ae15a91ac820e63b0ca",
        "commit_title": "dm snapshot: fix data corruption",
        "commit_text": " This patch fixes a particular type of data corruption that has been encountered when loading a snapshot's metadata from disk.  When we allocate a new chunk in persistent_prepare, we increment ps->next_free and we make sure that it doesn't point to a metadata area by further incrementing it if necessary.  When we load metadata from disk on device activation, ps->next_free is positioned after the last used data chunk. However, if this last used data chunk is followed by a metadata area, ps->next_free is positioned erroneously to the metadata area. A newly-allocated chunk is placed at the same location as the metadata area, resulting in data or metadata corruption.  This patch changes the code so that ps->next_free skips the metadata area when metadata are loaded in function read_exceptions.  The patch also moves a piece of code from persistent_prepare_exception to a separate function skip_metadata to avoid code duplication.  CVE-2013-4299  Cc: stable@vger.kernel.org Cc: Mike Snitzer <snitzer@redhat.com>",
        "func_before": "static int read_exceptions(struct pstore *ps,\n\t\t\t   int (*callback)(void *callback_context, chunk_t old,\n\t\t\t\t\t   chunk_t new),\n\t\t\t   void *callback_context)\n{\n\tint r, full = 1;\n\n\t/*\n\t * Keeping reading chunks and inserting exceptions until\n\t * we find a partially full area.\n\t */\n\tfor (ps->current_area = 0; full; ps->current_area++) {\n\t\tr = area_io(ps, READ);\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tr = insert_exceptions(ps, callback, callback_context, &full);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tps->current_area--;\n\n\treturn 0;\n}",
        "func": "static int read_exceptions(struct pstore *ps,\n\t\t\t   int (*callback)(void *callback_context, chunk_t old,\n\t\t\t\t\t   chunk_t new),\n\t\t\t   void *callback_context)\n{\n\tint r, full = 1;\n\n\t/*\n\t * Keeping reading chunks and inserting exceptions until\n\t * we find a partially full area.\n\t */\n\tfor (ps->current_area = 0; full; ps->current_area++) {\n\t\tr = area_io(ps, READ);\n\t\tif (r)\n\t\t\treturn r;\n\n\t\tr = insert_exceptions(ps, callback, callback_context, &full);\n\t\tif (r)\n\t\t\treturn r;\n\t}\n\n\tps->current_area--;\n\n\tskip_metadata(ps);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,5 +21,7 @@\n \n \tps->current_area--;\n \n+\tskip_metadata(ps);\n+\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tskip_metadata(ps);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4470",
        "func_name": "torvalds/linux/ip6_ufo_append_data",
        "description": "The Linux kernel before 3.12, when UDP Fragmentation Offload (UFO) is enabled, does not properly initialize certain data structures, which allows local users to cause a denial of service (memory corruption and system crash) or possibly gain privileges via a crafted application that uses the UDP_CORK option in a setsockopt system call and sends both short and long packets, related to the ip_ufo_append_data function in net/ipv4/ip_output.c and the ip6_ufo_append_data function in net/ipv6/ip6_output.c.",
        "git_url": "https://github.com/torvalds/linux/commit/c547dbf55d5f8cf615ccc0e7265e98db27d3fb8b",
        "commit_title": "ip6_output: do skb ufo init for peeked non ufo skb as well",
        "commit_text": " Now, if user application does: sendto len<mtu flag MSG_MORE sendto len>mtu flag 0 The skb is not treated as fragmented one because it is not initialized that way. So move the initialization to fix this.  introduced by: commit e89e9cf539a28df7d0eb1d0a545368e9920b34ac \"[IPv4/IPv6]: UFO Scatter-gather approach\" ",
        "func_before": "static inline int ip6_ufo_append_data(struct sock *sk,\n\t\t\tint getfrag(void *from, char *to, int offset, int len,\n\t\t\tint odd, struct sk_buff *skb),\n\t\t\tvoid *from, int length, int hh_len, int fragheaderlen,\n\t\t\tint transhdrlen, int mtu,unsigned int flags,\n\t\t\tstruct rt6_info *rt)\n\n{\n\tstruct sk_buff *skb;\n\tint err;\n\n\t/* There is support for UDP large send offload by network\n\t * device, so create one single skb packet containing complete\n\t * udp datagram\n\t */\n\tif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL) {\n\t\tstruct frag_hdr fhdr;\n\n\t\tskb = sock_alloc_send_skb(sk,\n\t\t\thh_len + fragheaderlen + transhdrlen + 20,\n\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\tif (skb == NULL)\n\t\t\treturn err;\n\n\t\t/* reserve space for Hardware header */\n\t\tskb_reserve(skb, hh_len);\n\n\t\t/* create space for UDP/IP header */\n\t\tskb_put(skb,fragheaderlen + transhdrlen);\n\n\t\t/* initialize network header pointer */\n\t\tskb_reset_network_header(skb);\n\n\t\t/* initialize protocol header pointer */\n\t\tskb->transport_header = skb->network_header + fragheaderlen;\n\n\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\tskb->ip_summed = CHECKSUM_PARTIAL;\n\t\tskb->csum = 0;\n\n\t\t/* Specify the length of each IPv6 datagram fragment.\n\t\t * It has to be a multiple of 8.\n\t\t */\n\t\tskb_shinfo(skb)->gso_size = (mtu - fragheaderlen -\n\t\t\t\t\t     sizeof(struct frag_hdr)) & ~7;\n\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n\t\tipv6_select_ident(&fhdr, rt);\n\t\tskb_shinfo(skb)->ip6_frag_id = fhdr.identification;\n\t\t__skb_queue_tail(&sk->sk_write_queue, skb);\n\t}\n\n\treturn skb_append_datato_frags(sk, skb, getfrag, from,\n\t\t\t\t       (length - transhdrlen));\n}",
        "func": "static inline int ip6_ufo_append_data(struct sock *sk,\n\t\t\tint getfrag(void *from, char *to, int offset, int len,\n\t\t\tint odd, struct sk_buff *skb),\n\t\t\tvoid *from, int length, int hh_len, int fragheaderlen,\n\t\t\tint transhdrlen, int mtu,unsigned int flags,\n\t\t\tstruct rt6_info *rt)\n\n{\n\tstruct sk_buff *skb;\n\tstruct frag_hdr fhdr;\n\tint err;\n\n\t/* There is support for UDP large send offload by network\n\t * device, so create one single skb packet containing complete\n\t * udp datagram\n\t */\n\tif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL) {\n\t\tskb = sock_alloc_send_skb(sk,\n\t\t\thh_len + fragheaderlen + transhdrlen + 20,\n\t\t\t(flags & MSG_DONTWAIT), &err);\n\t\tif (skb == NULL)\n\t\t\treturn err;\n\n\t\t/* reserve space for Hardware header */\n\t\tskb_reserve(skb, hh_len);\n\n\t\t/* create space for UDP/IP header */\n\t\tskb_put(skb,fragheaderlen + transhdrlen);\n\n\t\t/* initialize network header pointer */\n\t\tskb_reset_network_header(skb);\n\n\t\t/* initialize protocol header pointer */\n\t\tskb->transport_header = skb->network_header + fragheaderlen;\n\n\t\tskb->protocol = htons(ETH_P_IPV6);\n\t\tskb->csum = 0;\n\n\t\t__skb_queue_tail(&sk->sk_write_queue, skb);\n\t} else if (skb_is_gso(skb)) {\n\t\tgoto append;\n\t}\n\n\tskb->ip_summed = CHECKSUM_PARTIAL;\n\t/* Specify the length of each IPv6 datagram fragment.\n\t * It has to be a multiple of 8.\n\t */\n\tskb_shinfo(skb)->gso_size = (mtu - fragheaderlen -\n\t\t\t\t     sizeof(struct frag_hdr)) & ~7;\n\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n\tipv6_select_ident(&fhdr, rt);\n\tskb_shinfo(skb)->ip6_frag_id = fhdr.identification;\n\nappend:\n\treturn skb_append_datato_frags(sk, skb, getfrag, from,\n\t\t\t\t       (length - transhdrlen));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n \n {\n \tstruct sk_buff *skb;\n+\tstruct frag_hdr fhdr;\n \tint err;\n \n \t/* There is support for UDP large send offload by network\n@@ -14,8 +15,6 @@\n \t * udp datagram\n \t */\n \tif ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL) {\n-\t\tstruct frag_hdr fhdr;\n-\n \t\tskb = sock_alloc_send_skb(sk,\n \t\t\thh_len + fragheaderlen + transhdrlen + 20,\n \t\t\t(flags & MSG_DONTWAIT), &err);\n@@ -35,20 +34,24 @@\n \t\tskb->transport_header = skb->network_header + fragheaderlen;\n \n \t\tskb->protocol = htons(ETH_P_IPV6);\n-\t\tskb->ip_summed = CHECKSUM_PARTIAL;\n \t\tskb->csum = 0;\n \n-\t\t/* Specify the length of each IPv6 datagram fragment.\n-\t\t * It has to be a multiple of 8.\n-\t\t */\n-\t\tskb_shinfo(skb)->gso_size = (mtu - fragheaderlen -\n-\t\t\t\t\t     sizeof(struct frag_hdr)) & ~7;\n-\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n-\t\tipv6_select_ident(&fhdr, rt);\n-\t\tskb_shinfo(skb)->ip6_frag_id = fhdr.identification;\n \t\t__skb_queue_tail(&sk->sk_write_queue, skb);\n+\t} else if (skb_is_gso(skb)) {\n+\t\tgoto append;\n \t}\n \n+\tskb->ip_summed = CHECKSUM_PARTIAL;\n+\t/* Specify the length of each IPv6 datagram fragment.\n+\t * It has to be a multiple of 8.\n+\t */\n+\tskb_shinfo(skb)->gso_size = (mtu - fragheaderlen -\n+\t\t\t\t     sizeof(struct frag_hdr)) & ~7;\n+\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n+\tipv6_select_ident(&fhdr, rt);\n+\tskb_shinfo(skb)->ip6_frag_id = fhdr.identification;\n+\n+append:\n \treturn skb_append_datato_frags(sk, skb, getfrag, from,\n \t\t\t\t       (length - transhdrlen));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tstruct frag_hdr fhdr;",
                "",
                "\t\tskb->ip_summed = CHECKSUM_PARTIAL;",
                "\t\t/* Specify the length of each IPv6 datagram fragment.",
                "\t\t * It has to be a multiple of 8.",
                "\t\t */",
                "\t\tskb_shinfo(skb)->gso_size = (mtu - fragheaderlen -",
                "\t\t\t\t\t     sizeof(struct frag_hdr)) & ~7;",
                "\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;",
                "\t\tipv6_select_ident(&fhdr, rt);",
                "\t\tskb_shinfo(skb)->ip6_frag_id = fhdr.identification;"
            ],
            "added_lines": [
                "\tstruct frag_hdr fhdr;",
                "\t} else if (skb_is_gso(skb)) {",
                "\t\tgoto append;",
                "\tskb->ip_summed = CHECKSUM_PARTIAL;",
                "\t/* Specify the length of each IPv6 datagram fragment.",
                "\t * It has to be a multiple of 8.",
                "\t */",
                "\tskb_shinfo(skb)->gso_size = (mtu - fragheaderlen -",
                "\t\t\t\t     sizeof(struct frag_hdr)) & ~7;",
                "\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;",
                "\tipv6_select_ident(&fhdr, rt);",
                "\tskb_shinfo(skb)->ip6_frag_id = fhdr.identification;",
                "",
                "append:"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-4470",
        "func_name": "torvalds/linux/ip_ufo_append_data",
        "description": "The Linux kernel before 3.12, when UDP Fragmentation Offload (UFO) is enabled, does not properly initialize certain data structures, which allows local users to cause a denial of service (memory corruption and system crash) or possibly gain privileges via a crafted application that uses the UDP_CORK option in a setsockopt system call and sends both short and long packets, related to the ip_ufo_append_data function in net/ipv4/ip_output.c and the ip6_ufo_append_data function in net/ipv6/ip6_output.c.",
        "git_url": "https://github.com/torvalds/linux/commit/e93b7d748be887cd7639b113ba7d7ef792a7efb9",
        "commit_title": "ip_output: do skb ufo init for peeked non ufo skb as well",
        "commit_text": " Now, if user application does: sendto len<mtu flag MSG_MORE sendto len>mtu flag 0 The skb is not treated as fragmented one because it is not initialized that way. So move the initialization to fix this.  introduced by: commit e89e9cf539a28df7d0eb1d0a545368e9920b34ac \"[IPv4/IPv6]: UFO Scatter-gather approach\" ",
        "func_before": "static inline int ip_ufo_append_data(struct sock *sk,\n\t\t\tstruct sk_buff_head *queue,\n\t\t\tint getfrag(void *from, char *to, int offset, int len,\n\t\t\t       int odd, struct sk_buff *skb),\n\t\t\tvoid *from, int length, int hh_len, int fragheaderlen,\n\t\t\tint transhdrlen, int maxfraglen, unsigned int flags)\n{\n\tstruct sk_buff *skb;\n\tint err;\n\n\t/* There is support for UDP fragmentation offload by network\n\t * device, so create one single skb packet containing complete\n\t * udp datagram\n\t */\n\tif ((skb = skb_peek_tail(queue)) == NULL) {\n\t\tskb = sock_alloc_send_skb(sk,\n\t\t\thh_len + fragheaderlen + transhdrlen + 20,\n\t\t\t(flags & MSG_DONTWAIT), &err);\n\n\t\tif (skb == NULL)\n\t\t\treturn err;\n\n\t\t/* reserve space for Hardware header */\n\t\tskb_reserve(skb, hh_len);\n\n\t\t/* create space for UDP/IP header */\n\t\tskb_put(skb, fragheaderlen + transhdrlen);\n\n\t\t/* initialize network header pointer */\n\t\tskb_reset_network_header(skb);\n\n\t\t/* initialize protocol header pointer */\n\t\tskb->transport_header = skb->network_header + fragheaderlen;\n\n\t\tskb->ip_summed = CHECKSUM_PARTIAL;\n\t\tskb->csum = 0;\n\n\t\t/* specify the length of each IP datagram fragment */\n\t\tskb_shinfo(skb)->gso_size = maxfraglen - fragheaderlen;\n\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n\t\t__skb_queue_tail(queue, skb);\n\t}\n\n\treturn skb_append_datato_frags(sk, skb, getfrag, from,\n\t\t\t\t       (length - transhdrlen));\n}",
        "func": "static inline int ip_ufo_append_data(struct sock *sk,\n\t\t\tstruct sk_buff_head *queue,\n\t\t\tint getfrag(void *from, char *to, int offset, int len,\n\t\t\t       int odd, struct sk_buff *skb),\n\t\t\tvoid *from, int length, int hh_len, int fragheaderlen,\n\t\t\tint transhdrlen, int maxfraglen, unsigned int flags)\n{\n\tstruct sk_buff *skb;\n\tint err;\n\n\t/* There is support for UDP fragmentation offload by network\n\t * device, so create one single skb packet containing complete\n\t * udp datagram\n\t */\n\tif ((skb = skb_peek_tail(queue)) == NULL) {\n\t\tskb = sock_alloc_send_skb(sk,\n\t\t\thh_len + fragheaderlen + transhdrlen + 20,\n\t\t\t(flags & MSG_DONTWAIT), &err);\n\n\t\tif (skb == NULL)\n\t\t\treturn err;\n\n\t\t/* reserve space for Hardware header */\n\t\tskb_reserve(skb, hh_len);\n\n\t\t/* create space for UDP/IP header */\n\t\tskb_put(skb, fragheaderlen + transhdrlen);\n\n\t\t/* initialize network header pointer */\n\t\tskb_reset_network_header(skb);\n\n\t\t/* initialize protocol header pointer */\n\t\tskb->transport_header = skb->network_header + fragheaderlen;\n\n\t\tskb->csum = 0;\n\n\n\t\t__skb_queue_tail(queue, skb);\n\t} else if (skb_is_gso(skb)) {\n\t\tgoto append;\n\t}\n\n\tskb->ip_summed = CHECKSUM_PARTIAL;\n\t/* specify the length of each IP datagram fragment */\n\tskb_shinfo(skb)->gso_size = maxfraglen - fragheaderlen;\n\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n\nappend:\n\treturn skb_append_datato_frags(sk, skb, getfrag, from,\n\t\t\t\t       (length - transhdrlen));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,15 +32,20 @@\n \t\t/* initialize protocol header pointer */\n \t\tskb->transport_header = skb->network_header + fragheaderlen;\n \n-\t\tskb->ip_summed = CHECKSUM_PARTIAL;\n \t\tskb->csum = 0;\n \n-\t\t/* specify the length of each IP datagram fragment */\n-\t\tskb_shinfo(skb)->gso_size = maxfraglen - fragheaderlen;\n-\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n+\n \t\t__skb_queue_tail(queue, skb);\n+\t} else if (skb_is_gso(skb)) {\n+\t\tgoto append;\n \t}\n \n+\tskb->ip_summed = CHECKSUM_PARTIAL;\n+\t/* specify the length of each IP datagram fragment */\n+\tskb_shinfo(skb)->gso_size = maxfraglen - fragheaderlen;\n+\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;\n+\n+append:\n \treturn skb_append_datato_frags(sk, skb, getfrag, from,\n \t\t\t\t       (length - transhdrlen));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tskb->ip_summed = CHECKSUM_PARTIAL;",
                "\t\t/* specify the length of each IP datagram fragment */",
                "\t\tskb_shinfo(skb)->gso_size = maxfraglen - fragheaderlen;",
                "\t\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;"
            ],
            "added_lines": [
                "",
                "\t} else if (skb_is_gso(skb)) {",
                "\t\tgoto append;",
                "\tskb->ip_summed = CHECKSUM_PARTIAL;",
                "\t/* specify the length of each IP datagram fragment */",
                "\tskb_shinfo(skb)->gso_size = maxfraglen - fragheaderlen;",
                "\tskb_shinfo(skb)->gso_type = SKB_GSO_UDP;",
                "",
                "append:"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6383",
        "func_name": "torvalds/linux/aac_compat_ioctl",
        "description": "The aac_compat_ioctl function in drivers/scsi/aacraid/linit.c in the Linux kernel before 3.11.8 does not require the CAP_SYS_RAWIO capability, which allows local users to bypass intended access restrictions via a crafted ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/f856567b930dfcdbc3323261bf77240ccdde01f5",
        "commit_title": "aacraid: missing capable() check in compat ioctl",
        "commit_text": " In commit d496f94d22d1 ('[SCSI] aacraid: fix security weakness') we added a check on CAP_SYS_RAWIO to the ioctl.  The compat ioctls need the check as well.  Cc: stable@kernel.org",
        "func_before": "static int aac_compat_ioctl(struct scsi_device *sdev, int cmd, void __user *arg)\n{\n\tstruct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;\n\treturn aac_compat_do_ioctl(dev, cmd, (unsigned long)arg);\n}",
        "func": "static int aac_compat_ioctl(struct scsi_device *sdev, int cmd, void __user *arg)\n{\n\tstruct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;\n\tif (!capable(CAP_SYS_RAWIO))\n\t\treturn -EPERM;\n\treturn aac_compat_do_ioctl(dev, cmd, (unsigned long)arg);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,7 @@\n static int aac_compat_ioctl(struct scsi_device *sdev, int cmd, void __user *arg)\n {\n \tstruct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;\n+\tif (!capable(CAP_SYS_RAWIO))\n+\t\treturn -EPERM;\n \treturn aac_compat_do_ioctl(dev, cmd, (unsigned long)arg);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!capable(CAP_SYS_RAWIO))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2929",
        "func_name": "torvalds/linux/__ptrace_may_access",
        "description": "The Linux kernel before 3.12.2 does not properly use the get_dumpable function, which allows local users to bypass intended ptrace restrictions or obtain sensitive information from IA64 scratch registers via a crafted application, related to kernel/ptrace.c and arch/ia64/include/asm/processor.h.",
        "git_url": "https://github.com/torvalds/linux/commit/d049f74f2dbe71354d43d393ac3a188947811348",
        "commit_title": "exec/ptrace: fix get_dumpable() incorrect tests",
        "commit_text": " The get_dumpable() return value is not boolean.  Most users of the function actually want to be testing for non-SUID_DUMP_USER(1) rather than SUID_DUMP_DISABLE(0).  The SUID_DUMP_ROOT(2) is also considered a protected state.  Almost all places did this correctly, excepting the two places fixed in this patch.  Wrong logic:     if (dumpable == SUID_DUMP_DISABLE) { /* be protective */ }         or     if (dumpable == 0) { /* be protective */ }         or     if (!dumpable) { /* be protective */ }  Correct logic:     if (dumpable != SUID_DUMP_USER) { /* be protective */ }         or     if (dumpable != 1) { /* be protective */ }  Without this patch, if the system had set the sysctl fs/suid_dumpable=2, a user was able to ptrace attach to processes that had dropped privileges to that user.  (This may have been partially mitigated if Yama was enabled.)  The macros have been moved into the file that declares get/set_dumpable(), which means things like the ia64 code can see them too.  CVE-2013-2929  Cc: \"Luck, Tony\" <tony.luck@intel.com> Cc: Oleg Nesterov <oleg@redhat.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: <stable@vger.kernel.org>",
        "func_before": "static int __ptrace_may_access(struct task_struct *task, unsigned int mode)\n{\n\tconst struct cred *cred = current_cred(), *tcred;\n\n\t/* May we inspect the given task?\n\t * This check is used both for attaching with ptrace\n\t * and for allowing access to sensitive information in /proc.\n\t *\n\t * ptrace_attach denies several cases that /proc allows\n\t * because setting up the necessary parent/child relationship\n\t * or halting the specified task is impossible.\n\t */\n\tint dumpable = 0;\n\t/* Don't let security modules deny introspection */\n\tif (same_thread_group(task, current))\n\t\treturn 0;\n\trcu_read_lock();\n\ttcred = __task_cred(task);\n\tif (uid_eq(cred->uid, tcred->euid) &&\n\t    uid_eq(cred->uid, tcred->suid) &&\n\t    uid_eq(cred->uid, tcred->uid)  &&\n\t    gid_eq(cred->gid, tcred->egid) &&\n\t    gid_eq(cred->gid, tcred->sgid) &&\n\t    gid_eq(cred->gid, tcred->gid))\n\t\tgoto ok;\n\tif (ptrace_has_cap(tcred->user_ns, mode))\n\t\tgoto ok;\n\trcu_read_unlock();\n\treturn -EPERM;\nok:\n\trcu_read_unlock();\n\tsmp_rmb();\n\tif (task->mm)\n\t\tdumpable = get_dumpable(task->mm);\n\trcu_read_lock();\n\tif (!dumpable && !ptrace_has_cap(__task_cred(task)->user_ns, mode)) {\n\t\trcu_read_unlock();\n\t\treturn -EPERM;\n\t}\n\trcu_read_unlock();\n\n\treturn security_ptrace_access_check(task, mode);\n}",
        "func": "static int __ptrace_may_access(struct task_struct *task, unsigned int mode)\n{\n\tconst struct cred *cred = current_cred(), *tcred;\n\n\t/* May we inspect the given task?\n\t * This check is used both for attaching with ptrace\n\t * and for allowing access to sensitive information in /proc.\n\t *\n\t * ptrace_attach denies several cases that /proc allows\n\t * because setting up the necessary parent/child relationship\n\t * or halting the specified task is impossible.\n\t */\n\tint dumpable = 0;\n\t/* Don't let security modules deny introspection */\n\tif (same_thread_group(task, current))\n\t\treturn 0;\n\trcu_read_lock();\n\ttcred = __task_cred(task);\n\tif (uid_eq(cred->uid, tcred->euid) &&\n\t    uid_eq(cred->uid, tcred->suid) &&\n\t    uid_eq(cred->uid, tcred->uid)  &&\n\t    gid_eq(cred->gid, tcred->egid) &&\n\t    gid_eq(cred->gid, tcred->sgid) &&\n\t    gid_eq(cred->gid, tcred->gid))\n\t\tgoto ok;\n\tif (ptrace_has_cap(tcred->user_ns, mode))\n\t\tgoto ok;\n\trcu_read_unlock();\n\treturn -EPERM;\nok:\n\trcu_read_unlock();\n\tsmp_rmb();\n\tif (task->mm)\n\t\tdumpable = get_dumpable(task->mm);\n\trcu_read_lock();\n\tif (dumpable != SUID_DUMP_USER &&\n\t    !ptrace_has_cap(__task_cred(task)->user_ns, mode)) {\n\t\trcu_read_unlock();\n\t\treturn -EPERM;\n\t}\n\trcu_read_unlock();\n\n\treturn security_ptrace_access_check(task, mode);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,7 +33,8 @@\n \tif (task->mm)\n \t\tdumpable = get_dumpable(task->mm);\n \trcu_read_lock();\n-\tif (!dumpable && !ptrace_has_cap(__task_cred(task)->user_ns, mode)) {\n+\tif (dumpable != SUID_DUMP_USER &&\n+\t    !ptrace_has_cap(__task_cred(task)->user_ns, mode)) {\n \t\trcu_read_unlock();\n \t\treturn -EPERM;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!dumpable && !ptrace_has_cap(__task_cred(task)->user_ns, mode)) {"
            ],
            "added_lines": [
                "\tif (dumpable != SUID_DUMP_USER &&",
                "\t    !ptrace_has_cap(__task_cred(task)->user_ns, mode)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-2930",
        "func_name": "torvalds/linux/perf_trace_event_perm",
        "description": "The perf_trace_event_perm function in kernel/trace/trace_event_perf.c in the Linux kernel before 3.12.2 does not properly restrict access to the perf subsystem, which allows local users to enable function tracing via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/12ae030d54ef250706da5642fc7697cc60ad0df7",
        "commit_title": "perf/ftrace: Fix paranoid level for enabling function tracer",
        "commit_text": " The current default perf paranoid level is \"1\" which has \"perf_paranoid_kernel()\" return false, and giving any operations that use it, access to normal users. Unfortunately, this includes function tracing and normal users should not be allowed to enable function tracing by default.  The proper level is defined at \"-1\" (full perf access), which \"perf_paranoid_tracepoint_raw()\" will only give access to. Use that check instead for enabling function tracing.  Cc: Peter Zijlstra <peterz@infradead.org> Cc: Ingo Molnar <mingo@kernel.org> Cc: Jiri Olsa <jolsa@redhat.com> Cc: Frederic Weisbecker <fweisbec@gmail.com> Cc: stable@vger.kernel.org # 3.4+ CVE: CVE-2013-2930",
        "func_before": "static int perf_trace_event_perm(struct ftrace_event_call *tp_event,\n\t\t\t\t struct perf_event *p_event)\n{\n\t/* The ftrace function trace is allowed only for root. */\n\tif (ftrace_event_is_function(tp_event) &&\n\t    perf_paranoid_kernel() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\t/* No tracing, just counting, so no obvious leak */\n\tif (!(p_event->attr.sample_type & PERF_SAMPLE_RAW))\n\t\treturn 0;\n\n\t/* Some events are ok to be traced by non-root users... */\n\tif (p_event->attach_state == PERF_ATTACH_TASK) {\n\t\tif (tp_event->flags & TRACE_EVENT_FL_CAP_ANY)\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * ...otherwise raw tracepoint data can be a severe data leak,\n\t * only allow root to have these.\n\t */\n\tif (perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\treturn 0;\n}",
        "func": "static int perf_trace_event_perm(struct ftrace_event_call *tp_event,\n\t\t\t\t struct perf_event *p_event)\n{\n\t/* The ftrace function trace is allowed only for root. */\n\tif (ftrace_event_is_function(tp_event) &&\n\t    perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\t/* No tracing, just counting, so no obvious leak */\n\tif (!(p_event->attr.sample_type & PERF_SAMPLE_RAW))\n\t\treturn 0;\n\n\t/* Some events are ok to be traced by non-root users... */\n\tif (p_event->attach_state == PERF_ATTACH_TASK) {\n\t\tif (tp_event->flags & TRACE_EVENT_FL_CAP_ANY)\n\t\t\treturn 0;\n\t}\n\n\t/*\n\t * ...otherwise raw tracepoint data can be a severe data leak,\n\t * only allow root to have these.\n\t */\n\tif (perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n {\n \t/* The ftrace function trace is allowed only for root. */\n \tif (ftrace_event_is_function(tp_event) &&\n-\t    perf_paranoid_kernel() && !capable(CAP_SYS_ADMIN))\n+\t    perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))\n \t\treturn -EPERM;\n \n \t/* No tracing, just counting, so no obvious leak */",
        "diff_line_info": {
            "deleted_lines": [
                "\t    perf_paranoid_kernel() && !capable(CAP_SYS_ADMIN))"
            ],
            "added_lines": [
                "\t    perf_paranoid_tracepoint_raw() && !capable(CAP_SYS_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6431",
        "func_name": "torvalds/linux/fib6_add",
        "description": "The fib6_add function in net/ipv6/ip6_fib.c in the Linux kernel before 3.11.5 does not properly implement error-code encoding, which allows local users to cause a denial of service (NULL pointer dereference and system crash) by leveraging the CAP_NET_ADMIN capability for an IPv6 SIOCADDRT ioctl call.",
        "git_url": "https://github.com/torvalds/linux/commit/ae7b4e1f213aa659aedf9c6ecad0bf5f0476e1e2",
        "commit_title": "net: fib: fib6_add: fix potential NULL pointer dereference",
        "commit_text": " When the kernel is compiled with CONFIG_IPV6_SUBTREES, and we return with an error in fn = fib6_add_1(), then error codes are encoded into the return pointer e.g. ERR_PTR(-ENOENT). In such an error case, we write the error code into err and jump to out, hence enter the if(err) condition. Now, if CONFIG_IPV6_SUBTREES is enabled, we check for:    if (pn != fn && pn->leaf == rt)     ...   if (pn != fn && !pn->leaf && !(pn->fn_flags & RTN_RTINFO))     ...  Since pn is NULL and fn is f.e. ERR_PTR(-ENOENT), then pn != fn evaluates to true and causes a NULL-pointer dereference on further checks on pn. Fix it, by setting both NULL in error case, so that pn != fn already evaluates to false and no further dereference takes place.  This was first correctly implemented in 4a287eba2 (\"IPv6 routing, NLM_F_* flag support: REPLACE and EXCL flags support, warn about missing CREATE flag\"), but the bug got later on introduced by 188c517a0 (\"ipv6: return errno pointers consistently for fib6_add_1()\").  Cc: Lin Ming <mlin@ss.pku.edu.cn> Cc: Matti Vaittinen <matti.vaittinen@nsn.com> Cc: Hannes Frederic Sowa <hannes@stressinduktion.org>",
        "func_before": "int fib6_add(struct fib6_node *root, struct rt6_info *rt, struct nl_info *info)\n{\n\tstruct fib6_node *fn, *pn = NULL;\n\tint err = -ENOMEM;\n\tint allow_create = 1;\n\tint replace_required = 0;\n\n\tif (info->nlh) {\n\t\tif (!(info->nlh->nlmsg_flags & NLM_F_CREATE))\n\t\t\tallow_create = 0;\n\t\tif (info->nlh->nlmsg_flags & NLM_F_REPLACE)\n\t\t\treplace_required = 1;\n\t}\n\tif (!allow_create && !replace_required)\n\t\tpr_warn(\"RTM_NEWROUTE with no NLM_F_CREATE or NLM_F_REPLACE\\n\");\n\n\tfn = fib6_add_1(root, &rt->rt6i_dst.addr, rt->rt6i_dst.plen,\n\t\t\toffsetof(struct rt6_info, rt6i_dst), allow_create,\n\t\t\treplace_required);\n\n\tif (IS_ERR(fn)) {\n\t\terr = PTR_ERR(fn);\n\t\tgoto out;\n\t}\n\n\tpn = fn;\n\n#ifdef CONFIG_IPV6_SUBTREES\n\tif (rt->rt6i_src.plen) {\n\t\tstruct fib6_node *sn;\n\n\t\tif (!fn->subtree) {\n\t\t\tstruct fib6_node *sfn;\n\n\t\t\t/*\n\t\t\t * Create subtree.\n\t\t\t *\n\t\t\t *\t\tfn[main tree]\n\t\t\t *\t\t|\n\t\t\t *\t\tsfn[subtree root]\n\t\t\t *\t\t   \\\n\t\t\t *\t\t    sn[new leaf node]\n\t\t\t */\n\n\t\t\t/* Create subtree root node */\n\t\t\tsfn = node_alloc();\n\t\t\tif (!sfn)\n\t\t\t\tgoto st_failure;\n\n\t\t\tsfn->leaf = info->nl_net->ipv6.ip6_null_entry;\n\t\t\tatomic_inc(&info->nl_net->ipv6.ip6_null_entry->rt6i_ref);\n\t\t\tsfn->fn_flags = RTN_ROOT;\n\t\t\tsfn->fn_sernum = fib6_new_sernum();\n\n\t\t\t/* Now add the first leaf node to new subtree */\n\n\t\t\tsn = fib6_add_1(sfn, &rt->rt6i_src.addr,\n\t\t\t\t\trt->rt6i_src.plen,\n\t\t\t\t\toffsetof(struct rt6_info, rt6i_src),\n\t\t\t\t\tallow_create, replace_required);\n\n\t\t\tif (IS_ERR(sn)) {\n\t\t\t\t/* If it is failed, discard just allocated\n\t\t\t\t   root, and then (in st_failure) stale node\n\t\t\t\t   in main tree.\n\t\t\t\t */\n\t\t\t\tnode_free(sfn);\n\t\t\t\terr = PTR_ERR(sn);\n\t\t\t\tgoto st_failure;\n\t\t\t}\n\n\t\t\t/* Now link new subtree to main tree */\n\t\t\tsfn->parent = fn;\n\t\t\tfn->subtree = sfn;\n\t\t} else {\n\t\t\tsn = fib6_add_1(fn->subtree, &rt->rt6i_src.addr,\n\t\t\t\t\trt->rt6i_src.plen,\n\t\t\t\t\toffsetof(struct rt6_info, rt6i_src),\n\t\t\t\t\tallow_create, replace_required);\n\n\t\t\tif (IS_ERR(sn)) {\n\t\t\t\terr = PTR_ERR(sn);\n\t\t\t\tgoto st_failure;\n\t\t\t}\n\t\t}\n\n\t\tif (!fn->leaf) {\n\t\t\tfn->leaf = rt;\n\t\t\tatomic_inc(&rt->rt6i_ref);\n\t\t}\n\t\tfn = sn;\n\t}\n#endif\n\n\terr = fib6_add_rt2node(fn, rt, info);\n\tif (!err) {\n\t\tfib6_start_gc(info->nl_net, rt);\n\t\tif (!(rt->rt6i_flags & RTF_CACHE))\n\t\t\tfib6_prune_clones(info->nl_net, pn, rt);\n\t}\n\nout:\n\tif (err) {\n#ifdef CONFIG_IPV6_SUBTREES\n\t\t/*\n\t\t * If fib6_add_1 has cleared the old leaf pointer in the\n\t\t * super-tree leaf node we have to find a new one for it.\n\t\t */\n\t\tif (pn != fn && pn->leaf == rt) {\n\t\t\tpn->leaf = NULL;\n\t\t\tatomic_dec(&rt->rt6i_ref);\n\t\t}\n\t\tif (pn != fn && !pn->leaf && !(pn->fn_flags & RTN_RTINFO)) {\n\t\t\tpn->leaf = fib6_find_prefix(info->nl_net, pn);\n#if RT6_DEBUG >= 2\n\t\t\tif (!pn->leaf) {\n\t\t\t\tWARN_ON(pn->leaf == NULL);\n\t\t\t\tpn->leaf = info->nl_net->ipv6.ip6_null_entry;\n\t\t\t}\n#endif\n\t\t\tatomic_inc(&pn->leaf->rt6i_ref);\n\t\t}\n#endif\n\t\tdst_free(&rt->dst);\n\t}\n\treturn err;\n\n#ifdef CONFIG_IPV6_SUBTREES\n\t/* Subtree creation failed, probably main tree node\n\t   is orphan. If it is, shoot it.\n\t */\nst_failure:\n\tif (fn && !(fn->fn_flags & (RTN_RTINFO|RTN_ROOT)))\n\t\tfib6_repair_tree(info->nl_net, fn);\n\tdst_free(&rt->dst);\n\treturn err;\n#endif\n}",
        "func": "int fib6_add(struct fib6_node *root, struct rt6_info *rt, struct nl_info *info)\n{\n\tstruct fib6_node *fn, *pn = NULL;\n\tint err = -ENOMEM;\n\tint allow_create = 1;\n\tint replace_required = 0;\n\n\tif (info->nlh) {\n\t\tif (!(info->nlh->nlmsg_flags & NLM_F_CREATE))\n\t\t\tallow_create = 0;\n\t\tif (info->nlh->nlmsg_flags & NLM_F_REPLACE)\n\t\t\treplace_required = 1;\n\t}\n\tif (!allow_create && !replace_required)\n\t\tpr_warn(\"RTM_NEWROUTE with no NLM_F_CREATE or NLM_F_REPLACE\\n\");\n\n\tfn = fib6_add_1(root, &rt->rt6i_dst.addr, rt->rt6i_dst.plen,\n\t\t\toffsetof(struct rt6_info, rt6i_dst), allow_create,\n\t\t\treplace_required);\n\tif (IS_ERR(fn)) {\n\t\terr = PTR_ERR(fn);\n\t\tfn = NULL;\n\t\tgoto out;\n\t}\n\n\tpn = fn;\n\n#ifdef CONFIG_IPV6_SUBTREES\n\tif (rt->rt6i_src.plen) {\n\t\tstruct fib6_node *sn;\n\n\t\tif (!fn->subtree) {\n\t\t\tstruct fib6_node *sfn;\n\n\t\t\t/*\n\t\t\t * Create subtree.\n\t\t\t *\n\t\t\t *\t\tfn[main tree]\n\t\t\t *\t\t|\n\t\t\t *\t\tsfn[subtree root]\n\t\t\t *\t\t   \\\n\t\t\t *\t\t    sn[new leaf node]\n\t\t\t */\n\n\t\t\t/* Create subtree root node */\n\t\t\tsfn = node_alloc();\n\t\t\tif (!sfn)\n\t\t\t\tgoto st_failure;\n\n\t\t\tsfn->leaf = info->nl_net->ipv6.ip6_null_entry;\n\t\t\tatomic_inc(&info->nl_net->ipv6.ip6_null_entry->rt6i_ref);\n\t\t\tsfn->fn_flags = RTN_ROOT;\n\t\t\tsfn->fn_sernum = fib6_new_sernum();\n\n\t\t\t/* Now add the first leaf node to new subtree */\n\n\t\t\tsn = fib6_add_1(sfn, &rt->rt6i_src.addr,\n\t\t\t\t\trt->rt6i_src.plen,\n\t\t\t\t\toffsetof(struct rt6_info, rt6i_src),\n\t\t\t\t\tallow_create, replace_required);\n\n\t\t\tif (IS_ERR(sn)) {\n\t\t\t\t/* If it is failed, discard just allocated\n\t\t\t\t   root, and then (in st_failure) stale node\n\t\t\t\t   in main tree.\n\t\t\t\t */\n\t\t\t\tnode_free(sfn);\n\t\t\t\terr = PTR_ERR(sn);\n\t\t\t\tgoto st_failure;\n\t\t\t}\n\n\t\t\t/* Now link new subtree to main tree */\n\t\t\tsfn->parent = fn;\n\t\t\tfn->subtree = sfn;\n\t\t} else {\n\t\t\tsn = fib6_add_1(fn->subtree, &rt->rt6i_src.addr,\n\t\t\t\t\trt->rt6i_src.plen,\n\t\t\t\t\toffsetof(struct rt6_info, rt6i_src),\n\t\t\t\t\tallow_create, replace_required);\n\n\t\t\tif (IS_ERR(sn)) {\n\t\t\t\terr = PTR_ERR(sn);\n\t\t\t\tgoto st_failure;\n\t\t\t}\n\t\t}\n\n\t\tif (!fn->leaf) {\n\t\t\tfn->leaf = rt;\n\t\t\tatomic_inc(&rt->rt6i_ref);\n\t\t}\n\t\tfn = sn;\n\t}\n#endif\n\n\terr = fib6_add_rt2node(fn, rt, info);\n\tif (!err) {\n\t\tfib6_start_gc(info->nl_net, rt);\n\t\tif (!(rt->rt6i_flags & RTF_CACHE))\n\t\t\tfib6_prune_clones(info->nl_net, pn, rt);\n\t}\n\nout:\n\tif (err) {\n#ifdef CONFIG_IPV6_SUBTREES\n\t\t/*\n\t\t * If fib6_add_1 has cleared the old leaf pointer in the\n\t\t * super-tree leaf node we have to find a new one for it.\n\t\t */\n\t\tif (pn != fn && pn->leaf == rt) {\n\t\t\tpn->leaf = NULL;\n\t\t\tatomic_dec(&rt->rt6i_ref);\n\t\t}\n\t\tif (pn != fn && !pn->leaf && !(pn->fn_flags & RTN_RTINFO)) {\n\t\t\tpn->leaf = fib6_find_prefix(info->nl_net, pn);\n#if RT6_DEBUG >= 2\n\t\t\tif (!pn->leaf) {\n\t\t\t\tWARN_ON(pn->leaf == NULL);\n\t\t\t\tpn->leaf = info->nl_net->ipv6.ip6_null_entry;\n\t\t\t}\n#endif\n\t\t\tatomic_inc(&pn->leaf->rt6i_ref);\n\t\t}\n#endif\n\t\tdst_free(&rt->dst);\n\t}\n\treturn err;\n\n#ifdef CONFIG_IPV6_SUBTREES\n\t/* Subtree creation failed, probably main tree node\n\t   is orphan. If it is, shoot it.\n\t */\nst_failure:\n\tif (fn && !(fn->fn_flags & (RTN_RTINFO|RTN_ROOT)))\n\t\tfib6_repair_tree(info->nl_net, fn);\n\tdst_free(&rt->dst);\n\treturn err;\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,9 +17,9 @@\n \tfn = fib6_add_1(root, &rt->rt6i_dst.addr, rt->rt6i_dst.plen,\n \t\t\toffsetof(struct rt6_info, rt6i_dst), allow_create,\n \t\t\treplace_required);\n-\n \tif (IS_ERR(fn)) {\n \t\terr = PTR_ERR(fn);\n+\t\tfn = NULL;\n \t\tgoto out;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                ""
            ],
            "added_lines": [
                "\t\tfn = NULL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1438",
        "func_name": "torvalds/linux/restore_fpu_checking",
        "description": "The restore_fpu_checking function in arch/x86/include/asm/fpu-internal.h in the Linux kernel before 3.12.8 on the AMD K7 and K8 platforms does not clear pending exceptions before proceeding to an EMMS instruction, which allows local users to cause a denial of service (task kill) or possibly gain privileges via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/26bef1318adc1b3a530ecc807ef99346db2aa8b0",
        "commit_title": "x86, fpu, amd: Clear exceptions in AMD FXSAVE workaround",
        "commit_text": " Before we do an EMMS in the AMD FXSAVE information leak workaround we need to clear any pending exceptions, otherwise we trap with a floating-point exception inside this code.  Link: http://lkml.kernel.org/r/CA%2B55aFxQnY_PCG_n4=0w-VG=YLXL-yr7oMxyy0WU2gCBAf3ydg@mail.gmail.com",
        "func_before": "static inline int restore_fpu_checking(struct task_struct *tsk)\n{\n\t/* AMD K7/K8 CPUs don't save/restore FDP/FIP/FOP unless an exception\n\t   is pending.  Clear the x87 state here by setting it to fixed\n\t   values. \"m\" is a random variable that should be in L1 */\n\talternative_input(\n\t\tASM_NOP8 ASM_NOP2,\n\t\t\"emms\\n\\t\"\t\t/* clear stack tags */\n\t\t\"fildl %P[addr]\",\t/* set F?P to defined value */\n\t\tX86_FEATURE_FXSAVE_LEAK,\n\t\t[addr] \"m\" (tsk->thread.fpu.has_fpu));\n\n\treturn fpu_restore_checking(&tsk->thread.fpu);\n}",
        "func": "static inline int restore_fpu_checking(struct task_struct *tsk)\n{\n\t/* AMD K7/K8 CPUs don't save/restore FDP/FIP/FOP unless an exception\n\t   is pending.  Clear the x87 state here by setting it to fixed\n\t   values. \"m\" is a random variable that should be in L1 */\n\tif (unlikely(static_cpu_has(X86_FEATURE_FXSAVE_LEAK))) {\n\t\tasm volatile(\n\t\t\t\"fnclex\\n\\t\"\n\t\t\t\"emms\\n\\t\"\n\t\t\t\"fildl %P[addr]\"\t/* set F?P to defined value */\n\t\t\t: : [addr] \"m\" (tsk->thread.fpu.has_fpu));\n\t}\n\n\treturn fpu_restore_checking(&tsk->thread.fpu);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,12 +3,13 @@\n \t/* AMD K7/K8 CPUs don't save/restore FDP/FIP/FOP unless an exception\n \t   is pending.  Clear the x87 state here by setting it to fixed\n \t   values. \"m\" is a random variable that should be in L1 */\n-\talternative_input(\n-\t\tASM_NOP8 ASM_NOP2,\n-\t\t\"emms\\n\\t\"\t\t/* clear stack tags */\n-\t\t\"fildl %P[addr]\",\t/* set F?P to defined value */\n-\t\tX86_FEATURE_FXSAVE_LEAK,\n-\t\t[addr] \"m\" (tsk->thread.fpu.has_fpu));\n+\tif (unlikely(static_cpu_has(X86_FEATURE_FXSAVE_LEAK))) {\n+\t\tasm volatile(\n+\t\t\t\"fnclex\\n\\t\"\n+\t\t\t\"emms\\n\\t\"\n+\t\t\t\"fildl %P[addr]\"\t/* set F?P to defined value */\n+\t\t\t: : [addr] \"m\" (tsk->thread.fpu.has_fpu));\n+\t}\n \n \treturn fpu_restore_checking(&tsk->thread.fpu);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\talternative_input(",
                "\t\tASM_NOP8 ASM_NOP2,",
                "\t\t\"emms\\n\\t\"\t\t/* clear stack tags */",
                "\t\t\"fildl %P[addr]\",\t/* set F?P to defined value */",
                "\t\tX86_FEATURE_FXSAVE_LEAK,",
                "\t\t[addr] \"m\" (tsk->thread.fpu.has_fpu));"
            ],
            "added_lines": [
                "\tif (unlikely(static_cpu_has(X86_FEATURE_FXSAVE_LEAK))) {",
                "\t\tasm volatile(",
                "\t\t\t\"fnclex\\n\\t\"",
                "\t\t\t\"emms\\n\\t\"",
                "\t\t\t\"fildl %P[addr]\"\t/* set F?P to defined value */",
                "\t\t\t: : [addr] \"m\" (tsk->thread.fpu.has_fpu));",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-0339",
        "func_name": "GNOME/libxml2/xmlParseReference",
        "description": "libxml2 through 2.9.1 does not properly handle external entities expansion unless an application developer uses the xmlSAX2ResolveEntity or xmlSetExternalEntityLoader function, which allows remote attackers to cause a denial of service (resource consumption), send HTTP requests to intranet servers, or read arbitrary files via a crafted XML document, aka an XML External Entity (XXE) issue.  NOTE: it could be argued that because libxml2 already provides the ability to disable external entity expansion, the responsibility for resolving this issue lies with application developers; according to this argument, this entry should be REJECTed and each affected application would need its own CVE.",
        "git_url": "https://github.com/GNOME/libxml2/commit/4629ee02ac649c27f9c0cf98ba017c6b5526070f",
        "commit_title": "Do not fetch external parsed entities",
        "commit_text": " Unless explicietely asked for when validating or replacing entities with their value. Problem pointed out by Tom Lane <tgl@redhat.com>  * parser.c: do not load external parsed entities unless needed * test/errors/extparsedent.xml result/errors/extparsedent.xml*:   add a regression test to avoid change of the behaviour in the future",
        "func_before": "void\nxmlParseReference(xmlParserCtxtPtr ctxt) {\n    xmlEntityPtr ent;\n    xmlChar *val;\n    int was_checked;\n    xmlNodePtr list = NULL;\n    xmlParserErrors ret = XML_ERR_OK;\n\n\n    if (RAW != '&')\n        return;\n\n    /*\n     * Simple case of a CharRef\n     */\n    if (NXT(1) == '#') {\n\tint i = 0;\n\txmlChar out[10];\n\tint hex = NXT(2);\n\tint value = xmlParseCharRef(ctxt);\n\n\tif (value == 0)\n\t    return;\n\tif (ctxt->charset != XML_CHAR_ENCODING_UTF8) {\n\t    /*\n\t     * So we are using non-UTF-8 buffers\n\t     * Check that the char fit on 8bits, if not\n\t     * generate a CharRef.\n\t     */\n\t    if (value <= 0xFF) {\n\t\tout[0] = value;\n\t\tout[1] = 0;\n\t\tif ((ctxt->sax != NULL) && (ctxt->sax->characters != NULL) &&\n\t\t    (!ctxt->disableSAX))\n\t\t    ctxt->sax->characters(ctxt->userData, out, 1);\n\t    } else {\n\t\tif ((hex == 'x') || (hex == 'X'))\n\t\t    snprintf((char *)out, sizeof(out), \"#x%X\", value);\n\t\telse\n\t\t    snprintf((char *)out, sizeof(out), \"#%d\", value);\n\t\tif ((ctxt->sax != NULL) && (ctxt->sax->reference != NULL) &&\n\t\t    (!ctxt->disableSAX))\n\t\t    ctxt->sax->reference(ctxt->userData, out);\n\t    }\n\t} else {\n\t    /*\n\t     * Just encode the value in UTF-8\n\t     */\n\t    COPY_BUF(0 ,out, i, value);\n\t    out[i] = 0;\n\t    if ((ctxt->sax != NULL) && (ctxt->sax->characters != NULL) &&\n\t\t(!ctxt->disableSAX))\n\t\tctxt->sax->characters(ctxt->userData, out, i);\n\t}\n\treturn;\n    }\n\n    /*\n     * We are seeing an entity reference\n     */\n    ent = xmlParseEntityRef(ctxt);\n    if (ent == NULL) return;\n    if (!ctxt->wellFormed)\n\treturn;\n    was_checked = ent->checked;\n\n    /* special case of predefined entities */\n    if ((ent->name == NULL) ||\n        (ent->etype == XML_INTERNAL_PREDEFINED_ENTITY)) {\n\tval = ent->content;\n\tif (val == NULL) return;\n\t/*\n\t * inline the entity.\n\t */\n\tif ((ctxt->sax != NULL) && (ctxt->sax->characters != NULL) &&\n\t    (!ctxt->disableSAX))\n\t    ctxt->sax->characters(ctxt->userData, val, xmlStrlen(val));\n\treturn;\n    }\n\n    /*\n     * The first reference to the entity trigger a parsing phase\n     * where the ent->children is filled with the result from\n     * the parsing.\n     */\n    if (ent->checked == 0) {\n\tunsigned long oldnbent = ctxt->nbentities;\n\n\t/*\n\t * This is a bit hackish but this seems the best\n\t * way to make sure both SAX and DOM entity support\n\t * behaves okay.\n\t */\n\tvoid *user_data;\n\tif (ctxt->userData == ctxt)\n\t    user_data = NULL;\n\telse\n\t    user_data = ctxt->userData;\n\n\t/*\n\t * Check that this entity is well formed\n\t * 4.3.2: An internal general parsed entity is well-formed\n\t * if its replacement text matches the production labeled\n\t * content.\n\t */\n\tif (ent->etype == XML_INTERNAL_GENERAL_ENTITY) {\n\t    ctxt->depth++;\n\t    ret = xmlParseBalancedChunkMemoryInternal(ctxt, ent->content,\n\t                                              user_data, &list);\n\t    ctxt->depth--;\n\n\t} else if (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY) {\n\t    ctxt->depth++;\n\t    ret = xmlParseExternalEntityPrivate(ctxt->myDoc, ctxt, ctxt->sax,\n\t                                   user_data, ctxt->depth, ent->URI,\n\t\t\t\t\t   ent->ExternalID, &list);\n\t    ctxt->depth--;\n\t} else {\n\t    ret = XML_ERR_ENTITY_PE_INTERNAL;\n\t    xmlErrMsgStr(ctxt, XML_ERR_INTERNAL_ERROR,\n\t\t\t \"invalid entity type found\\n\", NULL);\n\t}\n\n\t/*\n\t * Store the number of entities needing parsing for this entity\n\t * content and do checkings\n\t */\n\tent->checked = ctxt->nbentities - oldnbent;\n\tif (ret == XML_ERR_ENTITY_LOOP) {\n\t    xmlFatalErr(ctxt, XML_ERR_ENTITY_LOOP, NULL);\n\t    xmlFreeNodeList(list);\n\t    return;\n\t}\n\tif (xmlParserEntityCheck(ctxt, 0, ent)) {\n\t    xmlFreeNodeList(list);\n\t    return;\n\t}\n\n\tif ((ret == XML_ERR_OK) && (list != NULL)) {\n\t    if (((ent->etype == XML_INTERNAL_GENERAL_ENTITY) ||\n\t     (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY))&&\n\t\t(ent->children == NULL)) {\n\t\tent->children = list;\n\t\tif (ctxt->replaceEntities) {\n\t\t    /*\n\t\t     * Prune it directly in the generated document\n\t\t     * except for single text nodes.\n\t\t     */\n\t\t    if (((list->type == XML_TEXT_NODE) &&\n\t\t\t (list->next == NULL)) ||\n\t\t\t(ctxt->parseMode == XML_PARSE_READER)) {\n\t\t\tlist->parent = (xmlNodePtr) ent;\n\t\t\tlist = NULL;\n\t\t\tent->owner = 1;\n\t\t    } else {\n\t\t\tent->owner = 0;\n\t\t\twhile (list != NULL) {\n\t\t\t    list->parent = (xmlNodePtr) ctxt->node;\n\t\t\t    list->doc = ctxt->myDoc;\n\t\t\t    if (list->next == NULL)\n\t\t\t\tent->last = list;\n\t\t\t    list = list->next;\n\t\t\t}\n\t\t\tlist = ent->children;\n#ifdef LIBXML_LEGACY_ENABLED\n\t\t\tif (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY)\n\t\t\t  xmlAddEntityReference(ent, list, NULL);\n#endif /* LIBXML_LEGACY_ENABLED */\n\t\t    }\n\t\t} else {\n\t\t    ent->owner = 1;\n\t\t    while (list != NULL) {\n\t\t\tlist->parent = (xmlNodePtr) ent;\n\t\t\txmlSetTreeDoc(list, ent->doc);\n\t\t\tif (list->next == NULL)\n\t\t\t    ent->last = list;\n\t\t\tlist = list->next;\n\t\t    }\n\t\t}\n\t    } else {\n\t\txmlFreeNodeList(list);\n\t\tlist = NULL;\n\t    }\n\t} else if ((ret != XML_ERR_OK) &&\n\t\t   (ret != XML_WAR_UNDECLARED_ENTITY)) {\n\t    xmlFatalErrMsgStr(ctxt, XML_ERR_UNDECLARED_ENTITY,\n\t\t     \"Entity '%s' failed to parse\\n\", ent->name);\n\t} else if (list != NULL) {\n\t    xmlFreeNodeList(list);\n\t    list = NULL;\n\t}\n\tif (ent->checked == 0)\n\t    ent->checked = 1;\n    } else if (ent->checked != 1) {\n\tctxt->nbentities += ent->checked;\n    }\n\n    /*\n     * Now that the entity content has been gathered\n     * provide it to the application, this can take different forms based\n     * on the parsing modes.\n     */\n    if (ent->children == NULL) {\n\t/*\n\t * Probably running in SAX mode and the callbacks don't\n\t * build the entity content. So unless we already went\n\t * though parsing for first checking go though the entity\n\t * content to generate callbacks associated to the entity\n\t */\n\tif (was_checked != 0) {\n\t    void *user_data;\n\t    /*\n\t     * This is a bit hackish but this seems the best\n\t     * way to make sure both SAX and DOM entity support\n\t     * behaves okay.\n\t     */\n\t    if (ctxt->userData == ctxt)\n\t\tuser_data = NULL;\n\t    else\n\t\tuser_data = ctxt->userData;\n\n\t    if (ent->etype == XML_INTERNAL_GENERAL_ENTITY) {\n\t\tctxt->depth++;\n\t\tret = xmlParseBalancedChunkMemoryInternal(ctxt,\n\t\t\t\t   ent->content, user_data, NULL);\n\t\tctxt->depth--;\n\t    } else if (ent->etype ==\n\t\t       XML_EXTERNAL_GENERAL_PARSED_ENTITY) {\n\t\tctxt->depth++;\n\t\tret = xmlParseExternalEntityPrivate(ctxt->myDoc, ctxt,\n\t\t\t   ctxt->sax, user_data, ctxt->depth,\n\t\t\t   ent->URI, ent->ExternalID, NULL);\n\t\tctxt->depth--;\n\t    } else {\n\t\tret = XML_ERR_ENTITY_PE_INTERNAL;\n\t\txmlErrMsgStr(ctxt, XML_ERR_INTERNAL_ERROR,\n\t\t\t     \"invalid entity type found\\n\", NULL);\n\t    }\n\t    if (ret == XML_ERR_ENTITY_LOOP) {\n\t\txmlFatalErr(ctxt, XML_ERR_ENTITY_LOOP, NULL);\n\t\treturn;\n\t    }\n\t}\n\tif ((ctxt->sax != NULL) && (ctxt->sax->reference != NULL) &&\n\t    (ctxt->replaceEntities == 0) && (!ctxt->disableSAX)) {\n\t    /*\n\t     * Entity reference callback comes second, it's somewhat\n\t     * superfluous but a compatibility to historical behaviour\n\t     */\n\t    ctxt->sax->reference(ctxt->userData, ent->name);\n\t}\n\treturn;\n    }\n\n    /*\n     * If we didn't get any children for the entity being built\n     */\n    if ((ctxt->sax != NULL) && (ctxt->sax->reference != NULL) &&\n\t(ctxt->replaceEntities == 0) && (!ctxt->disableSAX)) {\n\t/*\n\t * Create a node.\n\t */\n\tctxt->sax->reference(ctxt->userData, ent->name);\n\treturn;\n    }\n\n    if ((ctxt->replaceEntities) || (ent->children == NULL))  {\n\t/*\n\t * There is a problem on the handling of _private for entities\n\t * (bug 155816): Should we copy the content of the field from\n\t * the entity (possibly overwriting some value set by the user\n\t * when a copy is created), should we leave it alone, or should\n\t * we try to take care of different situations?  The problem\n\t * is exacerbated by the usage of this field by the xmlReader.\n\t * To fix this bug, we look at _private on the created node\n\t * and, if it's NULL, we copy in whatever was in the entity.\n\t * If it's not NULL we leave it alone.  This is somewhat of a\n\t * hack - maybe we should have further tests to determine\n\t * what to do.\n\t */\n\tif ((ctxt->node != NULL) && (ent->children != NULL)) {\n\t    /*\n\t     * Seems we are generating the DOM content, do\n\t     * a simple tree copy for all references except the first\n\t     * In the first occurrence list contains the replacement.\n\t     * progressive == 2 means we are operating on the Reader\n\t     * and since nodes are discarded we must copy all the time.\n\t     */\n\t    if (((list == NULL) && (ent->owner == 0)) ||\n\t\t(ctxt->parseMode == XML_PARSE_READER)) {\n\t\txmlNodePtr nw = NULL, cur, firstChild = NULL;\n\n\t\t/*\n\t\t * when operating on a reader, the entities definitions\n\t\t * are always owning the entities subtree.\n\t\tif (ctxt->parseMode == XML_PARSE_READER)\n\t\t    ent->owner = 1;\n\t\t */\n\n\t\tcur = ent->children;\n\t\twhile (cur != NULL) {\n\t\t    nw = xmlDocCopyNode(cur, ctxt->myDoc, 1);\n\t\t    if (nw != NULL) {\n\t\t\tif (nw->_private == NULL)\n\t\t\t    nw->_private = cur->_private;\n\t\t\tif (firstChild == NULL){\n\t\t\t    firstChild = nw;\n\t\t\t}\n\t\t\tnw = xmlAddChild(ctxt->node, nw);\n\t\t    }\n\t\t    if (cur == ent->last) {\n\t\t\t/*\n\t\t\t * needed to detect some strange empty\n\t\t\t * node cases in the reader tests\n\t\t\t */\n\t\t\tif ((ctxt->parseMode == XML_PARSE_READER) &&\n\t\t\t    (nw != NULL) &&\n\t\t\t    (nw->type == XML_ELEMENT_NODE) &&\n\t\t\t    (nw->children == NULL))\n\t\t\t    nw->extra = 1;\n\n\t\t\tbreak;\n\t\t    }\n\t\t    cur = cur->next;\n\t\t}\n#ifdef LIBXML_LEGACY_ENABLED\n\t\tif (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY)\n\t\t  xmlAddEntityReference(ent, firstChild, nw);\n#endif /* LIBXML_LEGACY_ENABLED */\n\t    } else if (list == NULL) {\n\t\txmlNodePtr nw = NULL, cur, next, last,\n\t\t\t   firstChild = NULL;\n\t\t/*\n\t\t * Copy the entity child list and make it the new\n\t\t * entity child list. The goal is to make sure any\n\t\t * ID or REF referenced will be the one from the\n\t\t * document content and not the entity copy.\n\t\t */\n\t\tcur = ent->children;\n\t\tent->children = NULL;\n\t\tlast = ent->last;\n\t\tent->last = NULL;\n\t\twhile (cur != NULL) {\n\t\t    next = cur->next;\n\t\t    cur->next = NULL;\n\t\t    cur->parent = NULL;\n\t\t    nw = xmlDocCopyNode(cur, ctxt->myDoc, 1);\n\t\t    if (nw != NULL) {\n\t\t\tif (nw->_private == NULL)\n\t\t\t    nw->_private = cur->_private;\n\t\t\tif (firstChild == NULL){\n\t\t\t    firstChild = cur;\n\t\t\t}\n\t\t\txmlAddChild((xmlNodePtr) ent, nw);\n\t\t\txmlAddChild(ctxt->node, cur);\n\t\t    }\n\t\t    if (cur == last)\n\t\t\tbreak;\n\t\t    cur = next;\n\t\t}\n\t\tif (ent->owner == 0)\n\t\t    ent->owner = 1;\n#ifdef LIBXML_LEGACY_ENABLED\n\t\tif (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY)\n\t\t  xmlAddEntityReference(ent, firstChild, nw);\n#endif /* LIBXML_LEGACY_ENABLED */\n\t    } else {\n\t\tconst xmlChar *nbktext;\n\n\t\t/*\n\t\t * the name change is to avoid coalescing of the\n\t\t * node with a possible previous text one which\n\t\t * would make ent->children a dangling pointer\n\t\t */\n\t\tnbktext = xmlDictLookup(ctxt->dict, BAD_CAST \"nbktext\",\n\t\t\t\t\t-1);\n\t\tif (ent->children->type == XML_TEXT_NODE)\n\t\t    ent->children->name = nbktext;\n\t\tif ((ent->last != ent->children) &&\n\t\t    (ent->last->type == XML_TEXT_NODE))\n\t\t    ent->last->name = nbktext;\n\t\txmlAddChildList(ctxt->node, ent->children);\n\t    }\n\n\t    /*\n\t     * This is to avoid a nasty side effect, see\n\t     * characters() in SAX.c\n\t     */\n\t    ctxt->nodemem = 0;\n\t    ctxt->nodelen = 0;\n\t    return;\n\t}\n    }\n}",
        "func": "void\nxmlParseReference(xmlParserCtxtPtr ctxt) {\n    xmlEntityPtr ent;\n    xmlChar *val;\n    int was_checked;\n    xmlNodePtr list = NULL;\n    xmlParserErrors ret = XML_ERR_OK;\n\n\n    if (RAW != '&')\n        return;\n\n    /*\n     * Simple case of a CharRef\n     */\n    if (NXT(1) == '#') {\n\tint i = 0;\n\txmlChar out[10];\n\tint hex = NXT(2);\n\tint value = xmlParseCharRef(ctxt);\n\n\tif (value == 0)\n\t    return;\n\tif (ctxt->charset != XML_CHAR_ENCODING_UTF8) {\n\t    /*\n\t     * So we are using non-UTF-8 buffers\n\t     * Check that the char fit on 8bits, if not\n\t     * generate a CharRef.\n\t     */\n\t    if (value <= 0xFF) {\n\t\tout[0] = value;\n\t\tout[1] = 0;\n\t\tif ((ctxt->sax != NULL) && (ctxt->sax->characters != NULL) &&\n\t\t    (!ctxt->disableSAX))\n\t\t    ctxt->sax->characters(ctxt->userData, out, 1);\n\t    } else {\n\t\tif ((hex == 'x') || (hex == 'X'))\n\t\t    snprintf((char *)out, sizeof(out), \"#x%X\", value);\n\t\telse\n\t\t    snprintf((char *)out, sizeof(out), \"#%d\", value);\n\t\tif ((ctxt->sax != NULL) && (ctxt->sax->reference != NULL) &&\n\t\t    (!ctxt->disableSAX))\n\t\t    ctxt->sax->reference(ctxt->userData, out);\n\t    }\n\t} else {\n\t    /*\n\t     * Just encode the value in UTF-8\n\t     */\n\t    COPY_BUF(0 ,out, i, value);\n\t    out[i] = 0;\n\t    if ((ctxt->sax != NULL) && (ctxt->sax->characters != NULL) &&\n\t\t(!ctxt->disableSAX))\n\t\tctxt->sax->characters(ctxt->userData, out, i);\n\t}\n\treturn;\n    }\n\n    /*\n     * We are seeing an entity reference\n     */\n    ent = xmlParseEntityRef(ctxt);\n    if (ent == NULL) return;\n    if (!ctxt->wellFormed)\n\treturn;\n    was_checked = ent->checked;\n\n    /* special case of predefined entities */\n    if ((ent->name == NULL) ||\n        (ent->etype == XML_INTERNAL_PREDEFINED_ENTITY)) {\n\tval = ent->content;\n\tif (val == NULL) return;\n\t/*\n\t * inline the entity.\n\t */\n\tif ((ctxt->sax != NULL) && (ctxt->sax->characters != NULL) &&\n\t    (!ctxt->disableSAX))\n\t    ctxt->sax->characters(ctxt->userData, val, xmlStrlen(val));\n\treturn;\n    }\n\n    /*\n     * The first reference to the entity trigger a parsing phase\n     * where the ent->children is filled with the result from\n     * the parsing.\n     * Note: external parsed entities will not be loaded, it is not\n     * required for a non-validating parser, unless the parsing option\n     * of validating, or substituting entities were given. Doing so is\n     * far more secure as the parser will only process data coming from\n     * the document entity by default.\n     */\n    if ((ent->checked == 0) &&\n        ((ent->etype != XML_EXTERNAL_GENERAL_PARSED_ENTITY) ||\n         (ctxt->options & (XML_PARSE_NOENT | XML_PARSE_DTDVALID)))) {\n\tunsigned long oldnbent = ctxt->nbentities;\n\n\t/*\n\t * This is a bit hackish but this seems the best\n\t * way to make sure both SAX and DOM entity support\n\t * behaves okay.\n\t */\n\tvoid *user_data;\n\tif (ctxt->userData == ctxt)\n\t    user_data = NULL;\n\telse\n\t    user_data = ctxt->userData;\n\n\t/*\n\t * Check that this entity is well formed\n\t * 4.3.2: An internal general parsed entity is well-formed\n\t * if its replacement text matches the production labeled\n\t * content.\n\t */\n\tif (ent->etype == XML_INTERNAL_GENERAL_ENTITY) {\n\t    ctxt->depth++;\n\t    ret = xmlParseBalancedChunkMemoryInternal(ctxt, ent->content,\n\t                                              user_data, &list);\n\t    ctxt->depth--;\n\n\t} else if (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY) {\n\t    ctxt->depth++;\n\t    ret = xmlParseExternalEntityPrivate(ctxt->myDoc, ctxt, ctxt->sax,\n\t                                   user_data, ctxt->depth, ent->URI,\n\t\t\t\t\t   ent->ExternalID, &list);\n\t    ctxt->depth--;\n\t} else {\n\t    ret = XML_ERR_ENTITY_PE_INTERNAL;\n\t    xmlErrMsgStr(ctxt, XML_ERR_INTERNAL_ERROR,\n\t\t\t \"invalid entity type found\\n\", NULL);\n\t}\n\n\t/*\n\t * Store the number of entities needing parsing for this entity\n\t * content and do checkings\n\t */\n\tent->checked = ctxt->nbentities - oldnbent;\n\tif (ret == XML_ERR_ENTITY_LOOP) {\n\t    xmlFatalErr(ctxt, XML_ERR_ENTITY_LOOP, NULL);\n\t    xmlFreeNodeList(list);\n\t    return;\n\t}\n\tif (xmlParserEntityCheck(ctxt, 0, ent)) {\n\t    xmlFreeNodeList(list);\n\t    return;\n\t}\n\n\tif ((ret == XML_ERR_OK) && (list != NULL)) {\n\t    if (((ent->etype == XML_INTERNAL_GENERAL_ENTITY) ||\n\t     (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY))&&\n\t\t(ent->children == NULL)) {\n\t\tent->children = list;\n\t\tif (ctxt->replaceEntities) {\n\t\t    /*\n\t\t     * Prune it directly in the generated document\n\t\t     * except for single text nodes.\n\t\t     */\n\t\t    if (((list->type == XML_TEXT_NODE) &&\n\t\t\t (list->next == NULL)) ||\n\t\t\t(ctxt->parseMode == XML_PARSE_READER)) {\n\t\t\tlist->parent = (xmlNodePtr) ent;\n\t\t\tlist = NULL;\n\t\t\tent->owner = 1;\n\t\t    } else {\n\t\t\tent->owner = 0;\n\t\t\twhile (list != NULL) {\n\t\t\t    list->parent = (xmlNodePtr) ctxt->node;\n\t\t\t    list->doc = ctxt->myDoc;\n\t\t\t    if (list->next == NULL)\n\t\t\t\tent->last = list;\n\t\t\t    list = list->next;\n\t\t\t}\n\t\t\tlist = ent->children;\n#ifdef LIBXML_LEGACY_ENABLED\n\t\t\tif (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY)\n\t\t\t  xmlAddEntityReference(ent, list, NULL);\n#endif /* LIBXML_LEGACY_ENABLED */\n\t\t    }\n\t\t} else {\n\t\t    ent->owner = 1;\n\t\t    while (list != NULL) {\n\t\t\tlist->parent = (xmlNodePtr) ent;\n\t\t\txmlSetTreeDoc(list, ent->doc);\n\t\t\tif (list->next == NULL)\n\t\t\t    ent->last = list;\n\t\t\tlist = list->next;\n\t\t    }\n\t\t}\n\t    } else {\n\t\txmlFreeNodeList(list);\n\t\tlist = NULL;\n\t    }\n\t} else if ((ret != XML_ERR_OK) &&\n\t\t   (ret != XML_WAR_UNDECLARED_ENTITY)) {\n\t    xmlFatalErrMsgStr(ctxt, XML_ERR_UNDECLARED_ENTITY,\n\t\t     \"Entity '%s' failed to parse\\n\", ent->name);\n\t} else if (list != NULL) {\n\t    xmlFreeNodeList(list);\n\t    list = NULL;\n\t}\n\tif (ent->checked == 0)\n\t    ent->checked = 1;\n    } else if (ent->checked != 1) {\n\tctxt->nbentities += ent->checked;\n    }\n\n    /*\n     * Now that the entity content has been gathered\n     * provide it to the application, this can take different forms based\n     * on the parsing modes.\n     */\n    if (ent->children == NULL) {\n\t/*\n\t * Probably running in SAX mode and the callbacks don't\n\t * build the entity content. So unless we already went\n\t * though parsing for first checking go though the entity\n\t * content to generate callbacks associated to the entity\n\t */\n\tif (was_checked != 0) {\n\t    void *user_data;\n\t    /*\n\t     * This is a bit hackish but this seems the best\n\t     * way to make sure both SAX and DOM entity support\n\t     * behaves okay.\n\t     */\n\t    if (ctxt->userData == ctxt)\n\t\tuser_data = NULL;\n\t    else\n\t\tuser_data = ctxt->userData;\n\n\t    if (ent->etype == XML_INTERNAL_GENERAL_ENTITY) {\n\t\tctxt->depth++;\n\t\tret = xmlParseBalancedChunkMemoryInternal(ctxt,\n\t\t\t\t   ent->content, user_data, NULL);\n\t\tctxt->depth--;\n\t    } else if (ent->etype ==\n\t\t       XML_EXTERNAL_GENERAL_PARSED_ENTITY) {\n\t\tctxt->depth++;\n\t\tret = xmlParseExternalEntityPrivate(ctxt->myDoc, ctxt,\n\t\t\t   ctxt->sax, user_data, ctxt->depth,\n\t\t\t   ent->URI, ent->ExternalID, NULL);\n\t\tctxt->depth--;\n\t    } else {\n\t\tret = XML_ERR_ENTITY_PE_INTERNAL;\n\t\txmlErrMsgStr(ctxt, XML_ERR_INTERNAL_ERROR,\n\t\t\t     \"invalid entity type found\\n\", NULL);\n\t    }\n\t    if (ret == XML_ERR_ENTITY_LOOP) {\n\t\txmlFatalErr(ctxt, XML_ERR_ENTITY_LOOP, NULL);\n\t\treturn;\n\t    }\n\t}\n\tif ((ctxt->sax != NULL) && (ctxt->sax->reference != NULL) &&\n\t    (ctxt->replaceEntities == 0) && (!ctxt->disableSAX)) {\n\t    /*\n\t     * Entity reference callback comes second, it's somewhat\n\t     * superfluous but a compatibility to historical behaviour\n\t     */\n\t    ctxt->sax->reference(ctxt->userData, ent->name);\n\t}\n\treturn;\n    }\n\n    /*\n     * If we didn't get any children for the entity being built\n     */\n    if ((ctxt->sax != NULL) && (ctxt->sax->reference != NULL) &&\n\t(ctxt->replaceEntities == 0) && (!ctxt->disableSAX)) {\n\t/*\n\t * Create a node.\n\t */\n\tctxt->sax->reference(ctxt->userData, ent->name);\n\treturn;\n    }\n\n    if ((ctxt->replaceEntities) || (ent->children == NULL))  {\n\t/*\n\t * There is a problem on the handling of _private for entities\n\t * (bug 155816): Should we copy the content of the field from\n\t * the entity (possibly overwriting some value set by the user\n\t * when a copy is created), should we leave it alone, or should\n\t * we try to take care of different situations?  The problem\n\t * is exacerbated by the usage of this field by the xmlReader.\n\t * To fix this bug, we look at _private on the created node\n\t * and, if it's NULL, we copy in whatever was in the entity.\n\t * If it's not NULL we leave it alone.  This is somewhat of a\n\t * hack - maybe we should have further tests to determine\n\t * what to do.\n\t */\n\tif ((ctxt->node != NULL) && (ent->children != NULL)) {\n\t    /*\n\t     * Seems we are generating the DOM content, do\n\t     * a simple tree copy for all references except the first\n\t     * In the first occurrence list contains the replacement.\n\t     * progressive == 2 means we are operating on the Reader\n\t     * and since nodes are discarded we must copy all the time.\n\t     */\n\t    if (((list == NULL) && (ent->owner == 0)) ||\n\t\t(ctxt->parseMode == XML_PARSE_READER)) {\n\t\txmlNodePtr nw = NULL, cur, firstChild = NULL;\n\n\t\t/*\n\t\t * when operating on a reader, the entities definitions\n\t\t * are always owning the entities subtree.\n\t\tif (ctxt->parseMode == XML_PARSE_READER)\n\t\t    ent->owner = 1;\n\t\t */\n\n\t\tcur = ent->children;\n\t\twhile (cur != NULL) {\n\t\t    nw = xmlDocCopyNode(cur, ctxt->myDoc, 1);\n\t\t    if (nw != NULL) {\n\t\t\tif (nw->_private == NULL)\n\t\t\t    nw->_private = cur->_private;\n\t\t\tif (firstChild == NULL){\n\t\t\t    firstChild = nw;\n\t\t\t}\n\t\t\tnw = xmlAddChild(ctxt->node, nw);\n\t\t    }\n\t\t    if (cur == ent->last) {\n\t\t\t/*\n\t\t\t * needed to detect some strange empty\n\t\t\t * node cases in the reader tests\n\t\t\t */\n\t\t\tif ((ctxt->parseMode == XML_PARSE_READER) &&\n\t\t\t    (nw != NULL) &&\n\t\t\t    (nw->type == XML_ELEMENT_NODE) &&\n\t\t\t    (nw->children == NULL))\n\t\t\t    nw->extra = 1;\n\n\t\t\tbreak;\n\t\t    }\n\t\t    cur = cur->next;\n\t\t}\n#ifdef LIBXML_LEGACY_ENABLED\n\t\tif (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY)\n\t\t  xmlAddEntityReference(ent, firstChild, nw);\n#endif /* LIBXML_LEGACY_ENABLED */\n\t    } else if (list == NULL) {\n\t\txmlNodePtr nw = NULL, cur, next, last,\n\t\t\t   firstChild = NULL;\n\t\t/*\n\t\t * Copy the entity child list and make it the new\n\t\t * entity child list. The goal is to make sure any\n\t\t * ID or REF referenced will be the one from the\n\t\t * document content and not the entity copy.\n\t\t */\n\t\tcur = ent->children;\n\t\tent->children = NULL;\n\t\tlast = ent->last;\n\t\tent->last = NULL;\n\t\twhile (cur != NULL) {\n\t\t    next = cur->next;\n\t\t    cur->next = NULL;\n\t\t    cur->parent = NULL;\n\t\t    nw = xmlDocCopyNode(cur, ctxt->myDoc, 1);\n\t\t    if (nw != NULL) {\n\t\t\tif (nw->_private == NULL)\n\t\t\t    nw->_private = cur->_private;\n\t\t\tif (firstChild == NULL){\n\t\t\t    firstChild = cur;\n\t\t\t}\n\t\t\txmlAddChild((xmlNodePtr) ent, nw);\n\t\t\txmlAddChild(ctxt->node, cur);\n\t\t    }\n\t\t    if (cur == last)\n\t\t\tbreak;\n\t\t    cur = next;\n\t\t}\n\t\tif (ent->owner == 0)\n\t\t    ent->owner = 1;\n#ifdef LIBXML_LEGACY_ENABLED\n\t\tif (ent->etype == XML_EXTERNAL_GENERAL_PARSED_ENTITY)\n\t\t  xmlAddEntityReference(ent, firstChild, nw);\n#endif /* LIBXML_LEGACY_ENABLED */\n\t    } else {\n\t\tconst xmlChar *nbktext;\n\n\t\t/*\n\t\t * the name change is to avoid coalescing of the\n\t\t * node with a possible previous text one which\n\t\t * would make ent->children a dangling pointer\n\t\t */\n\t\tnbktext = xmlDictLookup(ctxt->dict, BAD_CAST \"nbktext\",\n\t\t\t\t\t-1);\n\t\tif (ent->children->type == XML_TEXT_NODE)\n\t\t    ent->children->name = nbktext;\n\t\tif ((ent->last != ent->children) &&\n\t\t    (ent->last->type == XML_TEXT_NODE))\n\t\t    ent->last->name = nbktext;\n\t\txmlAddChildList(ctxt->node, ent->children);\n\t    }\n\n\t    /*\n\t     * This is to avoid a nasty side effect, see\n\t     * characters() in SAX.c\n\t     */\n\t    ctxt->nodemem = 0;\n\t    ctxt->nodelen = 0;\n\t    return;\n\t}\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -82,8 +82,15 @@\n      * The first reference to the entity trigger a parsing phase\n      * where the ent->children is filled with the result from\n      * the parsing.\n+     * Note: external parsed entities will not be loaded, it is not\n+     * required for a non-validating parser, unless the parsing option\n+     * of validating, or substituting entities were given. Doing so is\n+     * far more secure as the parser will only process data coming from\n+     * the document entity by default.\n      */\n-    if (ent->checked == 0) {\n+    if ((ent->checked == 0) &&\n+        ((ent->etype != XML_EXTERNAL_GENERAL_PARSED_ENTITY) ||\n+         (ctxt->options & (XML_PARSE_NOENT | XML_PARSE_DTDVALID)))) {\n \tunsigned long oldnbent = ctxt->nbentities;\n \n \t/*",
        "diff_line_info": {
            "deleted_lines": [
                "    if (ent->checked == 0) {"
            ],
            "added_lines": [
                "     * Note: external parsed entities will not be loaded, it is not",
                "     * required for a non-validating parser, unless the parsing option",
                "     * of validating, or substituting entities were given. Doing so is",
                "     * far more secure as the parser will only process data coming from",
                "     * the document entity by default.",
                "    if ((ent->checked == 0) &&",
                "        ((ent->etype != XML_EXTERNAL_GENERAL_PARSED_ENTITY) ||",
                "         (ctxt->options & (XML_PARSE_NOENT | XML_PARSE_DTDVALID)))) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6412",
        "func_name": "hercules-team/augeas/transform_save",
        "description": "The transform_save function in transform.c in Augeas 1.0.0 through 1.1.0 does not properly calculate the permission values when the umask contains a \"7,\" which causes world-writable permissions to be used for new files and allows local users to modify the files via unspecified vectors.",
        "git_url": "https://github.com/hercules-team/augeas/commit/f5b4fc0ceb0e5a2be5f3a19f63ad936897a3ac26",
        "commit_title": "Fix umask handling when creating new files",
        "commit_text": "   * src/transform.c (transform_save): faulty umask arithmetic would cause     overly-open file modes when the umask contains \"7\", as the umask was     incorrectly subtracted from the target file mode  Fixes CVE-2013-6412, RHBZ#1034261",
        "func_before": "int transform_save(struct augeas *aug, struct tree *xfm,\n                   const char *path, struct tree *tree) {\n    int   fd;\n    FILE *fp = NULL, *augorig_canon_fp = NULL;\n    char *augtemp = NULL, *augnew = NULL, *augorig = NULL, *augsave = NULL;\n    char *augorig_canon = NULL, *augdest = NULL;\n    int   augorig_exists;\n    int   copy_if_rename_fails = 0;\n    char *text = NULL;\n    const char *filename = path + strlen(AUGEAS_FILES_TREE) + 1;\n    const char *err_status = NULL;\n    char *dyn_err_status = NULL;\n    struct lns_error *err = NULL;\n    const char *lens_name;\n    struct lens *lens = xfm_lens(aug, xfm, &lens_name);\n    int result = -1, r;\n    bool force_reload;\n\n    errno = 0;\n\n    if (lens == NULL) {\n        err_status = \"lens_name\";\n        goto done;\n    }\n\n    copy_if_rename_fails =\n        aug_get(aug, AUGEAS_COPY_IF_RENAME_FAILS, NULL) == 1;\n\n    if (asprintf(&augorig, \"%s%s\", aug->root, filename) == -1) {\n        augorig = NULL;\n        goto done;\n    }\n\n    augorig_canon = canonicalize_file_name(augorig);\n    augorig_exists = 1;\n    if (augorig_canon == NULL) {\n        if (errno == ENOENT) {\n            augorig_canon = augorig;\n            augorig_exists = 0;\n        } else {\n            err_status = \"canon_augorig\";\n            goto done;\n        }\n    }\n\n    if (access(augorig_canon, R_OK) == 0) {\n        augorig_canon_fp = fopen(augorig_canon, \"r\");\n        text = xfread_file(augorig_canon_fp);\n    } else {\n        text = strdup(\"\");\n    }\n\n    if (text == NULL) {\n        err_status = \"put_read\";\n        goto done;\n    }\n\n    text = append_newline(text, strlen(text));\n\n    /* Figure out where to put the .augnew and temp file. If no .augnew file\n       then put the temp file next to augorig_canon, else next to .augnew. */\n    if (aug->flags & AUG_SAVE_NEWFILE) {\n        if (xasprintf(&augnew, \"%s\" EXT_AUGNEW, augorig) < 0) {\n            err_status = \"augnew_oom\";\n            goto done;\n        }\n        augdest = augnew;\n    } else {\n        augdest = augorig_canon;\n    }\n\n    if (xasprintf(&augtemp, \"%s.XXXXXX\", augdest) < 0) {\n        err_status = \"augtemp_oom\";\n        goto done;\n    }\n\n    // FIXME: We might have to create intermediate directories\n    // to be able to write augnew, but we have no idea what permissions\n    // etc. they should get. Just the process default ?\n    fd = mkstemp(augtemp);\n    if (fd < 0) {\n        err_status = \"mk_augtemp\";\n        goto done;\n    }\n    fp = fdopen(fd, \"w\");\n    if (fp == NULL) {\n        err_status = \"open_augtemp\";\n        goto done;\n    }\n\n    if (augorig_exists) {\n        if (transfer_file_attrs(augorig_canon_fp, fp, &err_status) != 0) {\n            err_status = \"xfer_attrs\";\n            goto done;\n        }\n    } else {\n        /* Since mkstemp is used, the temp file will have secure permissions\n         * instead of those implied by umask, so change them for new files */\n        mode_t curumsk = umask(022);\n        umask(curumsk);\n\n        if (fchmod(fileno(fp), 0666 - curumsk) < 0) {\n            err_status = \"create_chmod\";\n            return -1;\n        }\n    }\n\n    if (tree != NULL)\n        lns_put(fp, lens, tree->children, text, &err);\n\n    if (ferror(fp)) {\n        err_status = \"error_augtemp\";\n        goto done;\n    }\n\n    if (fflush(fp) != 0) {\n        err_status = \"flush_augtemp\";\n        goto done;\n    }\n\n    if (fsync(fileno(fp)) < 0) {\n        err_status = \"sync_augtemp\";\n        goto done;\n    }\n\n    if (fclose(fp) != 0) {\n        err_status = \"close_augtemp\";\n        fp = NULL;\n        goto done;\n    }\n\n    fp = NULL;\n\n    if (err != NULL) {\n        err_status = err->pos >= 0 ? \"parse_skel_failed\" : \"put_failed\";\n        unlink(augtemp);\n        goto done;\n    }\n\n    {\n        char *new_text = xread_file(augtemp);\n        int same = 0;\n        if (new_text == NULL) {\n            err_status = \"read_augtemp\";\n            goto done;\n        }\n        same = STREQ(text, new_text);\n        FREE(new_text);\n        if (same) {\n            result = 0;\n            unlink(augtemp);\n            goto done;\n        } else if (aug->flags & AUG_SAVE_NOOP) {\n            result = 1;\n            unlink(augtemp);\n            goto done;\n        }\n    }\n\n    if (!(aug->flags & AUG_SAVE_NEWFILE)) {\n        if (augorig_exists && (aug->flags & AUG_SAVE_BACKUP)) {\n            r = xasprintf(&augsave, \"%s\" EXT_AUGSAVE, augorig);\n            if (r == -1) {\n                augsave = NULL;\n                goto done;\n            }\n\n            r = clone_file(augorig_canon, augsave, &err_status, 1, 1);\n            if (r != 0) {\n                dyn_err_status = strappend(err_status, \"_augsave\");\n                goto done;\n            }\n        }\n    }\n\n    r = clone_file(augtemp, augdest, &err_status, copy_if_rename_fails, 0);\n    if (r != 0) {\n        dyn_err_status = strappend(err_status, \"_augtemp\");\n        goto done;\n    }\n\n    result = 1;\n\n done:\n    force_reload = aug->flags & AUG_SAVE_NEWFILE;\n    r = add_file_info(aug, path, lens, lens_name, augorig, force_reload);\n    if (r < 0) {\n        err_status = \"file_info\";\n        result = -1;\n    }\n    if (result > 0) {\n        r = file_saved_event(aug, path);\n        if (r < 0) {\n            err_status = \"saved_event\";\n            result = -1;\n        }\n    }\n    {\n        const char *emsg =\n            dyn_err_status == NULL ? err_status : dyn_err_status;\n        store_error(aug, filename, path, emsg, errno, err, text);\n    }\n    free(dyn_err_status);\n    lens_release(lens);\n    free(text);\n    free(augtemp);\n    free(augnew);\n    if (augorig_canon != augorig)\n        free(augorig_canon);\n    free(augorig);\n    free(augsave);\n    free_lns_error(err);\n\n    if (fp != NULL)\n        fclose(fp);\n    if (augorig_canon_fp != NULL)\n        fclose(augorig_canon_fp);\n    return result;\n}",
        "func": "int transform_save(struct augeas *aug, struct tree *xfm,\n                   const char *path, struct tree *tree) {\n    int   fd;\n    FILE *fp = NULL, *augorig_canon_fp = NULL;\n    char *augtemp = NULL, *augnew = NULL, *augorig = NULL, *augsave = NULL;\n    char *augorig_canon = NULL, *augdest = NULL;\n    int   augorig_exists;\n    int   copy_if_rename_fails = 0;\n    char *text = NULL;\n    const char *filename = path + strlen(AUGEAS_FILES_TREE) + 1;\n    const char *err_status = NULL;\n    char *dyn_err_status = NULL;\n    struct lns_error *err = NULL;\n    const char *lens_name;\n    struct lens *lens = xfm_lens(aug, xfm, &lens_name);\n    int result = -1, r;\n    bool force_reload;\n\n    errno = 0;\n\n    if (lens == NULL) {\n        err_status = \"lens_name\";\n        goto done;\n    }\n\n    copy_if_rename_fails =\n        aug_get(aug, AUGEAS_COPY_IF_RENAME_FAILS, NULL) == 1;\n\n    if (asprintf(&augorig, \"%s%s\", aug->root, filename) == -1) {\n        augorig = NULL;\n        goto done;\n    }\n\n    augorig_canon = canonicalize_file_name(augorig);\n    augorig_exists = 1;\n    if (augorig_canon == NULL) {\n        if (errno == ENOENT) {\n            augorig_canon = augorig;\n            augorig_exists = 0;\n        } else {\n            err_status = \"canon_augorig\";\n            goto done;\n        }\n    }\n\n    if (access(augorig_canon, R_OK) == 0) {\n        augorig_canon_fp = fopen(augorig_canon, \"r\");\n        text = xfread_file(augorig_canon_fp);\n    } else {\n        text = strdup(\"\");\n    }\n\n    if (text == NULL) {\n        err_status = \"put_read\";\n        goto done;\n    }\n\n    text = append_newline(text, strlen(text));\n\n    /* Figure out where to put the .augnew and temp file. If no .augnew file\n       then put the temp file next to augorig_canon, else next to .augnew. */\n    if (aug->flags & AUG_SAVE_NEWFILE) {\n        if (xasprintf(&augnew, \"%s\" EXT_AUGNEW, augorig) < 0) {\n            err_status = \"augnew_oom\";\n            goto done;\n        }\n        augdest = augnew;\n    } else {\n        augdest = augorig_canon;\n    }\n\n    if (xasprintf(&augtemp, \"%s.XXXXXX\", augdest) < 0) {\n        err_status = \"augtemp_oom\";\n        goto done;\n    }\n\n    // FIXME: We might have to create intermediate directories\n    // to be able to write augnew, but we have no idea what permissions\n    // etc. they should get. Just the process default ?\n    fd = mkstemp(augtemp);\n    if (fd < 0) {\n        err_status = \"mk_augtemp\";\n        goto done;\n    }\n    fp = fdopen(fd, \"w\");\n    if (fp == NULL) {\n        err_status = \"open_augtemp\";\n        goto done;\n    }\n\n    if (augorig_exists) {\n        if (transfer_file_attrs(augorig_canon_fp, fp, &err_status) != 0) {\n            err_status = \"xfer_attrs\";\n            goto done;\n        }\n    } else {\n        /* Since mkstemp is used, the temp file will have secure permissions\n         * instead of those implied by umask, so change them for new files */\n        mode_t curumsk = umask(022);\n        umask(curumsk);\n\n        if (fchmod(fileno(fp), 0666 & ~curumsk) < 0) {\n            err_status = \"create_chmod\";\n            return -1;\n        }\n    }\n\n    if (tree != NULL)\n        lns_put(fp, lens, tree->children, text, &err);\n\n    if (ferror(fp)) {\n        err_status = \"error_augtemp\";\n        goto done;\n    }\n\n    if (fflush(fp) != 0) {\n        err_status = \"flush_augtemp\";\n        goto done;\n    }\n\n    if (fsync(fileno(fp)) < 0) {\n        err_status = \"sync_augtemp\";\n        goto done;\n    }\n\n    if (fclose(fp) != 0) {\n        err_status = \"close_augtemp\";\n        fp = NULL;\n        goto done;\n    }\n\n    fp = NULL;\n\n    if (err != NULL) {\n        err_status = err->pos >= 0 ? \"parse_skel_failed\" : \"put_failed\";\n        unlink(augtemp);\n        goto done;\n    }\n\n    {\n        char *new_text = xread_file(augtemp);\n        int same = 0;\n        if (new_text == NULL) {\n            err_status = \"read_augtemp\";\n            goto done;\n        }\n        same = STREQ(text, new_text);\n        FREE(new_text);\n        if (same) {\n            result = 0;\n            unlink(augtemp);\n            goto done;\n        } else if (aug->flags & AUG_SAVE_NOOP) {\n            result = 1;\n            unlink(augtemp);\n            goto done;\n        }\n    }\n\n    if (!(aug->flags & AUG_SAVE_NEWFILE)) {\n        if (augorig_exists && (aug->flags & AUG_SAVE_BACKUP)) {\n            r = xasprintf(&augsave, \"%s\" EXT_AUGSAVE, augorig);\n            if (r == -1) {\n                augsave = NULL;\n                goto done;\n            }\n\n            r = clone_file(augorig_canon, augsave, &err_status, 1, 1);\n            if (r != 0) {\n                dyn_err_status = strappend(err_status, \"_augsave\");\n                goto done;\n            }\n        }\n    }\n\n    r = clone_file(augtemp, augdest, &err_status, copy_if_rename_fails, 0);\n    if (r != 0) {\n        dyn_err_status = strappend(err_status, \"_augtemp\");\n        goto done;\n    }\n\n    result = 1;\n\n done:\n    force_reload = aug->flags & AUG_SAVE_NEWFILE;\n    r = add_file_info(aug, path, lens, lens_name, augorig, force_reload);\n    if (r < 0) {\n        err_status = \"file_info\";\n        result = -1;\n    }\n    if (result > 0) {\n        r = file_saved_event(aug, path);\n        if (r < 0) {\n            err_status = \"saved_event\";\n            result = -1;\n        }\n    }\n    {\n        const char *emsg =\n            dyn_err_status == NULL ? err_status : dyn_err_status;\n        store_error(aug, filename, path, emsg, errno, err, text);\n    }\n    free(dyn_err_status);\n    lens_release(lens);\n    free(text);\n    free(augtemp);\n    free(augnew);\n    if (augorig_canon != augorig)\n        free(augorig_canon);\n    free(augorig);\n    free(augsave);\n    free_lns_error(err);\n\n    if (fp != NULL)\n        fclose(fp);\n    if (augorig_canon_fp != NULL)\n        fclose(augorig_canon_fp);\n    return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -99,7 +99,7 @@\n         mode_t curumsk = umask(022);\n         umask(curumsk);\n \n-        if (fchmod(fileno(fp), 0666 - curumsk) < 0) {\n+        if (fchmod(fileno(fp), 0666 & ~curumsk) < 0) {\n             err_status = \"create_chmod\";\n             return -1;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "        if (fchmod(fileno(fp), 0666 - curumsk) < 0) {"
            ],
            "added_lines": [
                "        if (fchmod(fileno(fp), 0666 & ~curumsk) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-1666",
        "func_name": "xen-project/xen/do_physdev_op",
        "description": "The do_physdev_op function in Xen 4.1.5, 4.1.6.1, 4.2.2 through 4.2.3, and 4.3.x does not properly restrict access to the (1) PHYSDEVOP_prepare_msix and (2) PHYSDEVOP_release_msix operations, which allows local PV guests to cause a denial of service (host or guest malfunction) or possibly gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/9c7e789a1b60b6114e0b1ef16dff95f03f532fb5",
        "commit_title": "x86: PHYSDEVOP_{prepare,release}_msix are privileged",
        "commit_text": " Yet this wasn't being enforced.  This is XSA-87. ",
        "func_before": "ret_t do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)\n{\n    int irq;\n    ret_t ret;\n    struct vcpu *v = current;\n\n    switch ( cmd )\n    {\n    case PHYSDEVOP_eoi: {\n        struct physdev_eoi eoi;\n        struct pirq *pirq;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&eoi, arg, 1) != 0 )\n            break;\n        ret = -EINVAL;\n        if ( eoi.irq >= v->domain->nr_pirqs )\n            break;\n        spin_lock(&v->domain->event_lock);\n        pirq = pirq_info(v->domain, eoi.irq);\n        if ( !pirq ) {\n            spin_unlock(&v->domain->event_lock);\n            break;\n        }\n        if ( is_pv_domain(v->domain) &&\n             v->domain->arch.pv_domain.auto_unmask )\n            evtchn_unmask(pirq->evtchn);\n        if ( is_pv_domain(v->domain) ||\n             domain_pirq_to_irq(v->domain, eoi.irq) > 0 )\n            pirq_guest_eoi(pirq);\n        if ( is_hvm_domain(v->domain) &&\n                domain_pirq_to_emuirq(v->domain, eoi.irq) > 0 )\n        {\n            struct hvm_irq *hvm_irq = &v->domain->arch.hvm_domain.irq;\n            int gsi = domain_pirq_to_emuirq(v->domain, eoi.irq);\n\n            /* if this is a level irq and count > 0, send another\n             * notification */ \n            if ( gsi >= NR_ISAIRQS /* ISA irqs are edge triggered */\n                    && hvm_irq->gsi_assert_count[gsi] )\n                send_guest_pirq(v->domain, pirq);\n        }\n        spin_unlock(&v->domain->event_lock);\n        ret = 0;\n        break;\n    }\n\n    case PHYSDEVOP_pirq_eoi_gmfn_v2:\n    case PHYSDEVOP_pirq_eoi_gmfn_v1: {\n        struct physdev_pirq_eoi_gmfn info;\n        unsigned long mfn;\n        struct page_info *page;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&info, arg, 1) != 0 )\n            break;\n\n        ret = -EINVAL;\n        page = get_page_from_gfn(current->domain, info.gmfn, NULL, P2M_ALLOC);\n        if ( !page )\n            break;\n        if ( !get_page_type(page, PGT_writable_page) )\n        {\n            put_page(page);\n            break;\n        }\n        mfn = page_to_mfn(page);\n\n        if ( cmpxchg(&v->domain->arch.pv_domain.pirq_eoi_map_mfn,\n                     0, mfn) != 0 )\n        {\n            put_page_and_type(mfn_to_page(mfn));\n            ret = -EBUSY;\n            break;\n        }\n\n        v->domain->arch.pv_domain.pirq_eoi_map = map_domain_page_global(mfn);\n        if ( v->domain->arch.pv_domain.pirq_eoi_map == NULL )\n        {\n            v->domain->arch.pv_domain.pirq_eoi_map_mfn = 0;\n            put_page_and_type(mfn_to_page(mfn));\n            ret = -ENOSPC;\n            break;\n        }\n        if ( cmd == PHYSDEVOP_pirq_eoi_gmfn_v1 )\n            v->domain->arch.pv_domain.auto_unmask = 1;\n\n        ret = 0;\n        break;\n    }\n\n    /* Legacy since 0x00030202. */\n    case PHYSDEVOP_IRQ_UNMASK_NOTIFY: {\n        ret = pirq_guest_unmask(v->domain);\n        break;\n    }\n\n    case PHYSDEVOP_irq_status_query: {\n        struct physdev_irq_status_query irq_status_query;\n        ret = -EFAULT;\n        if ( copy_from_guest(&irq_status_query, arg, 1) != 0 )\n            break;\n        irq = irq_status_query.irq;\n        ret = -EINVAL;\n        if ( (irq < 0) || (irq >= v->domain->nr_pirqs) )\n            break;\n        irq_status_query.flags = 0;\n        if ( is_hvm_domain(v->domain) &&\n             domain_pirq_to_irq(v->domain, irq) <= 0 &&\n             domain_pirq_to_emuirq(v->domain, irq) == IRQ_UNBOUND )\n        {\n            ret = -EINVAL;\n            break;\n        }\n\n        /*\n         * Even edge-triggered or message-based IRQs can need masking from\n         * time to time. If teh guest is not dynamically checking for this\n         * via the new pirq_eoi_map mechanism, it must conservatively always\n         * execute the EOI hypercall. In practice, this only really makes a\n         * difference for maskable MSI sources, and if those are supported\n         * then dom0 is probably modern anyway.\n         */\n        irq_status_query.flags |= XENIRQSTAT_needs_eoi;\n        if ( pirq_shared(v->domain, irq) )\n            irq_status_query.flags |= XENIRQSTAT_shared;\n        ret = __copy_to_guest(arg, &irq_status_query, 1) ? -EFAULT : 0;\n        break;\n    }\n\n    case PHYSDEVOP_map_pirq: {\n        physdev_map_pirq_t map;\n        struct msi_info msi;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&map, arg, 1) != 0 )\n            break;\n\n        switch ( map.type )\n        {\n        case MAP_PIRQ_TYPE_MSI_SEG:\n            map.type = MAP_PIRQ_TYPE_MSI;\n            msi.seg = map.bus >> 16;\n            break;\n\n        case MAP_PIRQ_TYPE_MULTI_MSI:\n            if ( map.table_base )\n                return -EINVAL;\n            msi.seg = map.bus >> 16;\n            break;\n\n        default:\n            msi.seg = 0;\n            break;\n        }\n        msi.bus = map.bus;\n        msi.devfn = map.devfn;\n        msi.entry_nr = map.entry_nr;\n        msi.table_base = map.table_base;\n        ret = physdev_map_pirq(map.domid, map.type, &map.index, &map.pirq,\n                               &msi);\n\n        if ( map.type == MAP_PIRQ_TYPE_MULTI_MSI )\n            map.entry_nr = msi.entry_nr;\n        if ( __copy_to_guest(arg, &map, 1) )\n            ret = -EFAULT;\n        break;\n    }\n\n    case PHYSDEVOP_unmap_pirq: {\n        struct physdev_unmap_pirq unmap;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&unmap, arg, 1) != 0 )\n            break;\n\n        ret = physdev_unmap_pirq(unmap.domid, unmap.pirq);\n        break;\n    }\n\n    case PHYSDEVOP_apic_read: {\n        struct physdev_apic apic;\n        ret = -EFAULT;\n        if ( copy_from_guest(&apic, arg, 1) != 0 )\n            break;\n        ret = xsm_apic(XSM_PRIV, v->domain, cmd);\n        if ( ret )\n            break;\n        ret = ioapic_guest_read(apic.apic_physbase, apic.reg, &apic.value);\n        if ( __copy_to_guest(arg, &apic, 1) )\n            ret = -EFAULT;\n        break;\n    }\n\n    case PHYSDEVOP_apic_write: {\n        struct physdev_apic apic;\n        ret = -EFAULT;\n        if ( copy_from_guest(&apic, arg, 1) != 0 )\n            break;\n        ret = xsm_apic(XSM_PRIV, v->domain, cmd);\n        if ( ret )\n            break;\n        ret = ioapic_guest_write(apic.apic_physbase, apic.reg, apic.value);\n        break;\n    }\n\n    case PHYSDEVOP_alloc_irq_vector: {\n        struct physdev_irq irq_op;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&irq_op, arg, 1) != 0 )\n            break;\n\n        /* Use the APIC check since this dummy hypercall should still only\n         * be called by the domain with access to program the ioapic */\n        ret = xsm_apic(XSM_PRIV, v->domain, cmd);\n        if ( ret )\n            break;\n\n        /* Vector is only used by hypervisor, and dom0 shouldn't\n           touch it in its world, return irq_op.irq as the vecotr,\n           and make this hypercall dummy, and also defer the vector \n           allocation when dom0 tries to programe ioapic entry. */\n        irq_op.vector = irq_op.irq;\n        ret = 0;\n        \n        if ( __copy_to_guest(arg, &irq_op, 1) )\n            ret = -EFAULT;\n        break;\n    }\n\n    case PHYSDEVOP_set_iopl: {\n        struct physdev_set_iopl set_iopl;\n\n        ret = -ENOSYS;\n        if ( is_pvh_vcpu(current) )\n            break;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&set_iopl, arg, 1) != 0 )\n            break;\n        ret = -EINVAL;\n        if ( set_iopl.iopl > 3 )\n            break;\n        ret = 0;\n        v->arch.pv_vcpu.iopl = set_iopl.iopl;\n        break;\n    }\n\n    case PHYSDEVOP_set_iobitmap: {\n        struct physdev_set_iobitmap set_iobitmap;\n\n        ret = -ENOSYS;\n        if ( is_pvh_vcpu(current) )\n            break;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&set_iobitmap, arg, 1) != 0 )\n            break;\n        ret = -EINVAL;\n        if ( !guest_handle_okay(set_iobitmap.bitmap, IOBMP_BYTES) ||\n             (set_iobitmap.nr_ports > 65536) )\n            break;\n        ret = 0;\n#ifndef COMPAT\n        v->arch.pv_vcpu.iobmp = set_iobitmap.bitmap;\n#else\n        guest_from_compat_handle(v->arch.pv_vcpu.iobmp, set_iobitmap.bitmap);\n#endif\n        v->arch.pv_vcpu.iobmp_limit = set_iobitmap.nr_ports;\n        break;\n    }\n\n    case PHYSDEVOP_manage_pci_add: {\n        struct physdev_manage_pci manage_pci;\n        ret = -EFAULT;\n        if ( copy_from_guest(&manage_pci, arg, 1) != 0 )\n            break;\n\n        ret = pci_add_device(0, manage_pci.bus, manage_pci.devfn, NULL);\n        break;\n    }\n\n    case PHYSDEVOP_manage_pci_remove: {\n        struct physdev_manage_pci manage_pci;\n        ret = -EFAULT;\n        if ( copy_from_guest(&manage_pci, arg, 1) != 0 )\n            break;\n\n        ret = pci_remove_device(0, manage_pci.bus, manage_pci.devfn);\n        break;\n    }\n\n    case PHYSDEVOP_manage_pci_add_ext: {\n        struct physdev_manage_pci_ext manage_pci_ext;\n        struct pci_dev_info pdev_info;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&manage_pci_ext, arg, 1) != 0 )\n            break;\n\n        ret = -EINVAL;\n        if ( (manage_pci_ext.is_extfn > 1) || (manage_pci_ext.is_virtfn > 1) )\n            break;\n\n        pdev_info.is_extfn = manage_pci_ext.is_extfn;\n        pdev_info.is_virtfn = manage_pci_ext.is_virtfn;\n        pdev_info.physfn.bus = manage_pci_ext.physfn.bus;\n        pdev_info.physfn.devfn = manage_pci_ext.physfn.devfn;\n        ret = pci_add_device(0, manage_pci_ext.bus,\n                             manage_pci_ext.devfn,\n                             &pdev_info);\n        break;\n    }\n\n    case PHYSDEVOP_pci_device_add: {\n        struct physdev_pci_device_add add;\n        struct pci_dev_info pdev_info;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&add, arg, 1) != 0 )\n            break;\n\n        pdev_info.is_extfn = !!(add.flags & XEN_PCI_DEV_EXTFN);\n        if ( add.flags & XEN_PCI_DEV_VIRTFN )\n        {\n            pdev_info.is_virtfn = 1;\n            pdev_info.physfn.bus = add.physfn.bus;\n            pdev_info.physfn.devfn = add.physfn.devfn;\n        }\n        else\n            pdev_info.is_virtfn = 0;\n        ret = pci_add_device(add.seg, add.bus, add.devfn, &pdev_info);\n        break;\n    }\n\n    case PHYSDEVOP_pci_device_remove: {\n        struct physdev_pci_device dev;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&dev, arg, 1) != 0 )\n            break;\n\n        ret = pci_remove_device(dev.seg, dev.bus, dev.devfn);\n        break;\n    }\n\n    case PHYSDEVOP_prepare_msix:\n    case PHYSDEVOP_release_msix: {\n        struct physdev_pci_device dev;\n\n        if ( copy_from_guest(&dev, arg, 1) )\n            ret = -EFAULT;\n        else\n            ret = pci_prepare_msix(dev.seg, dev.bus, dev.devfn,\n                                   cmd != PHYSDEVOP_prepare_msix);\n        break;\n    }\n\n    case PHYSDEVOP_pci_mmcfg_reserved: {\n        struct physdev_pci_mmcfg_reserved info;\n\n        ret = xsm_resource_setup_misc(XSM_PRIV);\n        if ( ret )\n            break;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&info, arg, 1) )\n            break;\n\n        ret = pci_mmcfg_reserved(info.address, info.segment,\n                                 info.start_bus, info.end_bus, info.flags);\n        break;\n    }\n\n    case PHYSDEVOP_restore_msi: {\n        struct physdev_restore_msi restore_msi;\n        struct pci_dev *pdev;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&restore_msi, arg, 1) != 0 )\n            break;\n\n        spin_lock(&pcidevs_lock);\n        pdev = pci_get_pdev(0, restore_msi.bus, restore_msi.devfn);\n        ret = pdev ? pci_restore_msi_state(pdev) : -ENODEV;\n        spin_unlock(&pcidevs_lock);\n        break;\n    }\n\n    case PHYSDEVOP_restore_msi_ext: {\n        struct physdev_pci_device dev;\n        struct pci_dev *pdev;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&dev, arg, 1) != 0 )\n            break;\n\n        spin_lock(&pcidevs_lock);\n        pdev = pci_get_pdev(dev.seg, dev.bus, dev.devfn);\n        ret = pdev ? pci_restore_msi_state(pdev) : -ENODEV;\n        spin_unlock(&pcidevs_lock);\n        break;\n    }\n\n    case PHYSDEVOP_setup_gsi: {\n        struct physdev_setup_gsi setup_gsi;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&setup_gsi, arg, 1) != 0 )\n            break;\n        \n        ret = -EINVAL;\n        if ( setup_gsi.gsi < 0 || setup_gsi.gsi >= nr_irqs_gsi )\n            break;\n\n        ret = xsm_resource_setup_gsi(XSM_PRIV, setup_gsi.gsi);\n        if ( ret )\n            break;\n\n        ret = mp_register_gsi(setup_gsi.gsi, setup_gsi.triggering,\n                              setup_gsi.polarity);\n        break; \n    }\n    case PHYSDEVOP_get_free_pirq: {\n        struct physdev_get_free_pirq out;\n        struct domain *d = v->domain;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&out, arg, 1) != 0 )\n            break;\n\n        spin_lock(&d->event_lock);\n\n        ret = get_free_pirq(d, out.type);\n        if ( ret >= 0 )\n        {\n            struct pirq *info = pirq_get_info(d, ret);\n\n            if ( info )\n                info->arch.irq = PIRQ_ALLOCATED;\n            else\n                ret = -ENOMEM;\n        }\n\n        spin_unlock(&d->event_lock);\n\n        if ( ret >= 0 )\n        {\n            out.pirq = ret;\n            ret = __copy_to_guest(arg, &out, 1) ? -EFAULT : 0;\n        }\n\n        break;\n    }\n\n    case PHYSDEVOP_dbgp_op: {\n        struct physdev_dbgp_op op;\n\n        if ( !is_hardware_domain(v->domain) )\n            ret = -EPERM;\n        else if ( copy_from_guest(&op, arg, 1) )\n            ret = -EFAULT;\n        else\n            ret = dbgp_op(&op);\n        break;\n    }\n\n    default:\n        ret = -ENOSYS;\n        break;\n    }\n\n    return ret;\n}",
        "func": "ret_t do_physdev_op(int cmd, XEN_GUEST_HANDLE_PARAM(void) arg)\n{\n    int irq;\n    ret_t ret;\n    struct vcpu *v = current;\n\n    switch ( cmd )\n    {\n    case PHYSDEVOP_eoi: {\n        struct physdev_eoi eoi;\n        struct pirq *pirq;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&eoi, arg, 1) != 0 )\n            break;\n        ret = -EINVAL;\n        if ( eoi.irq >= v->domain->nr_pirqs )\n            break;\n        spin_lock(&v->domain->event_lock);\n        pirq = pirq_info(v->domain, eoi.irq);\n        if ( !pirq ) {\n            spin_unlock(&v->domain->event_lock);\n            break;\n        }\n        if ( is_pv_domain(v->domain) &&\n             v->domain->arch.pv_domain.auto_unmask )\n            evtchn_unmask(pirq->evtchn);\n        if ( is_pv_domain(v->domain) ||\n             domain_pirq_to_irq(v->domain, eoi.irq) > 0 )\n            pirq_guest_eoi(pirq);\n        if ( is_hvm_domain(v->domain) &&\n                domain_pirq_to_emuirq(v->domain, eoi.irq) > 0 )\n        {\n            struct hvm_irq *hvm_irq = &v->domain->arch.hvm_domain.irq;\n            int gsi = domain_pirq_to_emuirq(v->domain, eoi.irq);\n\n            /* if this is a level irq and count > 0, send another\n             * notification */ \n            if ( gsi >= NR_ISAIRQS /* ISA irqs are edge triggered */\n                    && hvm_irq->gsi_assert_count[gsi] )\n                send_guest_pirq(v->domain, pirq);\n        }\n        spin_unlock(&v->domain->event_lock);\n        ret = 0;\n        break;\n    }\n\n    case PHYSDEVOP_pirq_eoi_gmfn_v2:\n    case PHYSDEVOP_pirq_eoi_gmfn_v1: {\n        struct physdev_pirq_eoi_gmfn info;\n        unsigned long mfn;\n        struct page_info *page;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&info, arg, 1) != 0 )\n            break;\n\n        ret = -EINVAL;\n        page = get_page_from_gfn(current->domain, info.gmfn, NULL, P2M_ALLOC);\n        if ( !page )\n            break;\n        if ( !get_page_type(page, PGT_writable_page) )\n        {\n            put_page(page);\n            break;\n        }\n        mfn = page_to_mfn(page);\n\n        if ( cmpxchg(&v->domain->arch.pv_domain.pirq_eoi_map_mfn,\n                     0, mfn) != 0 )\n        {\n            put_page_and_type(mfn_to_page(mfn));\n            ret = -EBUSY;\n            break;\n        }\n\n        v->domain->arch.pv_domain.pirq_eoi_map = map_domain_page_global(mfn);\n        if ( v->domain->arch.pv_domain.pirq_eoi_map == NULL )\n        {\n            v->domain->arch.pv_domain.pirq_eoi_map_mfn = 0;\n            put_page_and_type(mfn_to_page(mfn));\n            ret = -ENOSPC;\n            break;\n        }\n        if ( cmd == PHYSDEVOP_pirq_eoi_gmfn_v1 )\n            v->domain->arch.pv_domain.auto_unmask = 1;\n\n        ret = 0;\n        break;\n    }\n\n    /* Legacy since 0x00030202. */\n    case PHYSDEVOP_IRQ_UNMASK_NOTIFY: {\n        ret = pirq_guest_unmask(v->domain);\n        break;\n    }\n\n    case PHYSDEVOP_irq_status_query: {\n        struct physdev_irq_status_query irq_status_query;\n        ret = -EFAULT;\n        if ( copy_from_guest(&irq_status_query, arg, 1) != 0 )\n            break;\n        irq = irq_status_query.irq;\n        ret = -EINVAL;\n        if ( (irq < 0) || (irq >= v->domain->nr_pirqs) )\n            break;\n        irq_status_query.flags = 0;\n        if ( is_hvm_domain(v->domain) &&\n             domain_pirq_to_irq(v->domain, irq) <= 0 &&\n             domain_pirq_to_emuirq(v->domain, irq) == IRQ_UNBOUND )\n        {\n            ret = -EINVAL;\n            break;\n        }\n\n        /*\n         * Even edge-triggered or message-based IRQs can need masking from\n         * time to time. If teh guest is not dynamically checking for this\n         * via the new pirq_eoi_map mechanism, it must conservatively always\n         * execute the EOI hypercall. In practice, this only really makes a\n         * difference for maskable MSI sources, and if those are supported\n         * then dom0 is probably modern anyway.\n         */\n        irq_status_query.flags |= XENIRQSTAT_needs_eoi;\n        if ( pirq_shared(v->domain, irq) )\n            irq_status_query.flags |= XENIRQSTAT_shared;\n        ret = __copy_to_guest(arg, &irq_status_query, 1) ? -EFAULT : 0;\n        break;\n    }\n\n    case PHYSDEVOP_map_pirq: {\n        physdev_map_pirq_t map;\n        struct msi_info msi;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&map, arg, 1) != 0 )\n            break;\n\n        switch ( map.type )\n        {\n        case MAP_PIRQ_TYPE_MSI_SEG:\n            map.type = MAP_PIRQ_TYPE_MSI;\n            msi.seg = map.bus >> 16;\n            break;\n\n        case MAP_PIRQ_TYPE_MULTI_MSI:\n            if ( map.table_base )\n                return -EINVAL;\n            msi.seg = map.bus >> 16;\n            break;\n\n        default:\n            msi.seg = 0;\n            break;\n        }\n        msi.bus = map.bus;\n        msi.devfn = map.devfn;\n        msi.entry_nr = map.entry_nr;\n        msi.table_base = map.table_base;\n        ret = physdev_map_pirq(map.domid, map.type, &map.index, &map.pirq,\n                               &msi);\n\n        if ( map.type == MAP_PIRQ_TYPE_MULTI_MSI )\n            map.entry_nr = msi.entry_nr;\n        if ( __copy_to_guest(arg, &map, 1) )\n            ret = -EFAULT;\n        break;\n    }\n\n    case PHYSDEVOP_unmap_pirq: {\n        struct physdev_unmap_pirq unmap;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&unmap, arg, 1) != 0 )\n            break;\n\n        ret = physdev_unmap_pirq(unmap.domid, unmap.pirq);\n        break;\n    }\n\n    case PHYSDEVOP_apic_read: {\n        struct physdev_apic apic;\n        ret = -EFAULT;\n        if ( copy_from_guest(&apic, arg, 1) != 0 )\n            break;\n        ret = xsm_apic(XSM_PRIV, v->domain, cmd);\n        if ( ret )\n            break;\n        ret = ioapic_guest_read(apic.apic_physbase, apic.reg, &apic.value);\n        if ( __copy_to_guest(arg, &apic, 1) )\n            ret = -EFAULT;\n        break;\n    }\n\n    case PHYSDEVOP_apic_write: {\n        struct physdev_apic apic;\n        ret = -EFAULT;\n        if ( copy_from_guest(&apic, arg, 1) != 0 )\n            break;\n        ret = xsm_apic(XSM_PRIV, v->domain, cmd);\n        if ( ret )\n            break;\n        ret = ioapic_guest_write(apic.apic_physbase, apic.reg, apic.value);\n        break;\n    }\n\n    case PHYSDEVOP_alloc_irq_vector: {\n        struct physdev_irq irq_op;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&irq_op, arg, 1) != 0 )\n            break;\n\n        /* Use the APIC check since this dummy hypercall should still only\n         * be called by the domain with access to program the ioapic */\n        ret = xsm_apic(XSM_PRIV, v->domain, cmd);\n        if ( ret )\n            break;\n\n        /* Vector is only used by hypervisor, and dom0 shouldn't\n           touch it in its world, return irq_op.irq as the vecotr,\n           and make this hypercall dummy, and also defer the vector \n           allocation when dom0 tries to programe ioapic entry. */\n        irq_op.vector = irq_op.irq;\n        ret = 0;\n        \n        if ( __copy_to_guest(arg, &irq_op, 1) )\n            ret = -EFAULT;\n        break;\n    }\n\n    case PHYSDEVOP_set_iopl: {\n        struct physdev_set_iopl set_iopl;\n\n        ret = -ENOSYS;\n        if ( is_pvh_vcpu(current) )\n            break;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&set_iopl, arg, 1) != 0 )\n            break;\n        ret = -EINVAL;\n        if ( set_iopl.iopl > 3 )\n            break;\n        ret = 0;\n        v->arch.pv_vcpu.iopl = set_iopl.iopl;\n        break;\n    }\n\n    case PHYSDEVOP_set_iobitmap: {\n        struct physdev_set_iobitmap set_iobitmap;\n\n        ret = -ENOSYS;\n        if ( is_pvh_vcpu(current) )\n            break;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&set_iobitmap, arg, 1) != 0 )\n            break;\n        ret = -EINVAL;\n        if ( !guest_handle_okay(set_iobitmap.bitmap, IOBMP_BYTES) ||\n             (set_iobitmap.nr_ports > 65536) )\n            break;\n        ret = 0;\n#ifndef COMPAT\n        v->arch.pv_vcpu.iobmp = set_iobitmap.bitmap;\n#else\n        guest_from_compat_handle(v->arch.pv_vcpu.iobmp, set_iobitmap.bitmap);\n#endif\n        v->arch.pv_vcpu.iobmp_limit = set_iobitmap.nr_ports;\n        break;\n    }\n\n    case PHYSDEVOP_manage_pci_add: {\n        struct physdev_manage_pci manage_pci;\n        ret = -EFAULT;\n        if ( copy_from_guest(&manage_pci, arg, 1) != 0 )\n            break;\n\n        ret = pci_add_device(0, manage_pci.bus, manage_pci.devfn, NULL);\n        break;\n    }\n\n    case PHYSDEVOP_manage_pci_remove: {\n        struct physdev_manage_pci manage_pci;\n        ret = -EFAULT;\n        if ( copy_from_guest(&manage_pci, arg, 1) != 0 )\n            break;\n\n        ret = pci_remove_device(0, manage_pci.bus, manage_pci.devfn);\n        break;\n    }\n\n    case PHYSDEVOP_manage_pci_add_ext: {\n        struct physdev_manage_pci_ext manage_pci_ext;\n        struct pci_dev_info pdev_info;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&manage_pci_ext, arg, 1) != 0 )\n            break;\n\n        ret = -EINVAL;\n        if ( (manage_pci_ext.is_extfn > 1) || (manage_pci_ext.is_virtfn > 1) )\n            break;\n\n        pdev_info.is_extfn = manage_pci_ext.is_extfn;\n        pdev_info.is_virtfn = manage_pci_ext.is_virtfn;\n        pdev_info.physfn.bus = manage_pci_ext.physfn.bus;\n        pdev_info.physfn.devfn = manage_pci_ext.physfn.devfn;\n        ret = pci_add_device(0, manage_pci_ext.bus,\n                             manage_pci_ext.devfn,\n                             &pdev_info);\n        break;\n    }\n\n    case PHYSDEVOP_pci_device_add: {\n        struct physdev_pci_device_add add;\n        struct pci_dev_info pdev_info;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&add, arg, 1) != 0 )\n            break;\n\n        pdev_info.is_extfn = !!(add.flags & XEN_PCI_DEV_EXTFN);\n        if ( add.flags & XEN_PCI_DEV_VIRTFN )\n        {\n            pdev_info.is_virtfn = 1;\n            pdev_info.physfn.bus = add.physfn.bus;\n            pdev_info.physfn.devfn = add.physfn.devfn;\n        }\n        else\n            pdev_info.is_virtfn = 0;\n        ret = pci_add_device(add.seg, add.bus, add.devfn, &pdev_info);\n        break;\n    }\n\n    case PHYSDEVOP_pci_device_remove: {\n        struct physdev_pci_device dev;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&dev, arg, 1) != 0 )\n            break;\n\n        ret = pci_remove_device(dev.seg, dev.bus, dev.devfn);\n        break;\n    }\n\n    case PHYSDEVOP_prepare_msix:\n    case PHYSDEVOP_release_msix: {\n        struct physdev_pci_device dev;\n\n        if ( copy_from_guest(&dev, arg, 1) )\n            ret = -EFAULT;\n        else\n            ret = xsm_resource_setup_pci(XSM_PRIV,\n                                         (dev.seg << 16) | (dev.bus << 8) |\n                                         dev.devfn) ?:\n                  pci_prepare_msix(dev.seg, dev.bus, dev.devfn,\n                                   cmd != PHYSDEVOP_prepare_msix);\n        break;\n    }\n\n    case PHYSDEVOP_pci_mmcfg_reserved: {\n        struct physdev_pci_mmcfg_reserved info;\n\n        ret = xsm_resource_setup_misc(XSM_PRIV);\n        if ( ret )\n            break;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&info, arg, 1) )\n            break;\n\n        ret = pci_mmcfg_reserved(info.address, info.segment,\n                                 info.start_bus, info.end_bus, info.flags);\n        break;\n    }\n\n    case PHYSDEVOP_restore_msi: {\n        struct physdev_restore_msi restore_msi;\n        struct pci_dev *pdev;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&restore_msi, arg, 1) != 0 )\n            break;\n\n        spin_lock(&pcidevs_lock);\n        pdev = pci_get_pdev(0, restore_msi.bus, restore_msi.devfn);\n        ret = pdev ? pci_restore_msi_state(pdev) : -ENODEV;\n        spin_unlock(&pcidevs_lock);\n        break;\n    }\n\n    case PHYSDEVOP_restore_msi_ext: {\n        struct physdev_pci_device dev;\n        struct pci_dev *pdev;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&dev, arg, 1) != 0 )\n            break;\n\n        spin_lock(&pcidevs_lock);\n        pdev = pci_get_pdev(dev.seg, dev.bus, dev.devfn);\n        ret = pdev ? pci_restore_msi_state(pdev) : -ENODEV;\n        spin_unlock(&pcidevs_lock);\n        break;\n    }\n\n    case PHYSDEVOP_setup_gsi: {\n        struct physdev_setup_gsi setup_gsi;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&setup_gsi, arg, 1) != 0 )\n            break;\n        \n        ret = -EINVAL;\n        if ( setup_gsi.gsi < 0 || setup_gsi.gsi >= nr_irqs_gsi )\n            break;\n\n        ret = xsm_resource_setup_gsi(XSM_PRIV, setup_gsi.gsi);\n        if ( ret )\n            break;\n\n        ret = mp_register_gsi(setup_gsi.gsi, setup_gsi.triggering,\n                              setup_gsi.polarity);\n        break; \n    }\n    case PHYSDEVOP_get_free_pirq: {\n        struct physdev_get_free_pirq out;\n        struct domain *d = v->domain;\n\n        ret = -EFAULT;\n        if ( copy_from_guest(&out, arg, 1) != 0 )\n            break;\n\n        spin_lock(&d->event_lock);\n\n        ret = get_free_pirq(d, out.type);\n        if ( ret >= 0 )\n        {\n            struct pirq *info = pirq_get_info(d, ret);\n\n            if ( info )\n                info->arch.irq = PIRQ_ALLOCATED;\n            else\n                ret = -ENOMEM;\n        }\n\n        spin_unlock(&d->event_lock);\n\n        if ( ret >= 0 )\n        {\n            out.pirq = ret;\n            ret = __copy_to_guest(arg, &out, 1) ? -EFAULT : 0;\n        }\n\n        break;\n    }\n\n    case PHYSDEVOP_dbgp_op: {\n        struct physdev_dbgp_op op;\n\n        if ( !is_hardware_domain(v->domain) )\n            ret = -EPERM;\n        else if ( copy_from_guest(&op, arg, 1) )\n            ret = -EFAULT;\n        else\n            ret = dbgp_op(&op);\n        break;\n    }\n\n    default:\n        ret = -ENOSYS;\n        break;\n    }\n\n    return ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -352,7 +352,10 @@\n         if ( copy_from_guest(&dev, arg, 1) )\n             ret = -EFAULT;\n         else\n-            ret = pci_prepare_msix(dev.seg, dev.bus, dev.devfn,\n+            ret = xsm_resource_setup_pci(XSM_PRIV,\n+                                         (dev.seg << 16) | (dev.bus << 8) |\n+                                         dev.devfn) ?:\n+                  pci_prepare_msix(dev.seg, dev.bus, dev.devfn,\n                                    cmd != PHYSDEVOP_prepare_msix);\n         break;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "            ret = pci_prepare_msix(dev.seg, dev.bus, dev.devfn,"
            ],
            "added_lines": [
                "            ret = xsm_resource_setup_pci(XSM_PRIV,",
                "                                         (dev.seg << 16) | (dev.bus << 8) |",
                "                                         dev.devfn) ?:",
                "                  pci_prepare_msix(dev.seg, dev.bus, dev.devfn,"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0875",
        "func_name": "systemtap/set_expr_rule",
        "description": "SystemTap 1.7, 1.6.7, and probably other versions, when unprivileged mode is enabled, allows local users to obtain sensitive information from kernel memory or cause a denial of service (kernel panic and crash) via vectors related to crafted DWARF data, which triggers a read of an invalid pointer.",
        "git_url": "http://sourceware.org/git/?p=systemtap.git;a=commit;h=64b0cff3b",
        "commit_title": "",
        "commit_text": "PR13714 - Make sure REG_STATE.cfa_is_expr is always set correctly.  runtime/unwind.c (processCFI): Always set REG_STATE.cfa_is_expr and add new sanity checks to make sure the cfa definition rules are sane.  Since the cfa expr pointer and cfa register/offset rule shared a union not setting REG_STATE.cfa_is_expr could result in compute_expr () wrongly being called and using the register/offset as expr pointer. ",
        "func_before": "static void set_expr_rule(uleb128_t reg, enum item_location where,\n\t\t\t  const u8 **expr, const u8 *end,\n\t\t\t  struct unwind_state *state)\n{\n\tconst u8 *const start = *expr;\n\tuleb128_t len = get_uleb128(expr, end);\n\tdbug_unwind(1, \"reg=%lx, where=%d, expr=%lu@%p\\n\",\n\t\t    reg, where, len, *expr);\n\tif (end - *expr >= len && reg < ARRAY_SIZE(REG_STATE.regs)) {\n\t\tREG_STATE.regs[reg].where = where;\n\t\tREG_STATE.regs[reg].expr = start;\n\t\t*expr += len;\n\t}\n}",
        "func": "static void set_expr_rule(uleb128_t reg, enum item_location where,\n\t\t\t  const u8 **expr, const u8 *end,\n\t\t\t  struct unwind_state *state)\n{\n\tconst u8 *const start = *expr;\n\tuleb128_t len = get_uleb128(expr, end);\n\tdbug_unwind(1, \"reg=%lx, where=%d, expr=%lu@%p\\n\",\n\t\t    reg, where, len, *expr);\n\t/* Sanity check that expr falls completely inside known data. */\n\tif (end - *expr >= len && reg < ARRAY_SIZE(REG_STATE.regs)) {\n\t\tREG_STATE.regs[reg].where = where;\n\t\tREG_STATE.regs[reg].expr = start;\n\t\t*expr += len;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,7 @@\n \tuleb128_t len = get_uleb128(expr, end);\n \tdbug_unwind(1, \"reg=%lx, where=%d, expr=%lu@%p\\n\",\n \t\t    reg, where, len, *expr);\n+\t/* Sanity check that expr falls completely inside known data. */\n \tif (end - *expr >= len && reg < ARRAY_SIZE(REG_STATE.regs)) {\n \t\tREG_STATE.regs[reg].where = where;\n \t\tREG_STATE.regs[reg].expr = start;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Sanity check that expr falls completely inside known data. */"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0875",
        "func_name": "systemtap/processCFI",
        "description": "SystemTap 1.7, 1.6.7, and probably other versions, when unprivileged mode is enabled, allows local users to obtain sensitive information from kernel memory or cause a denial of service (kernel panic and crash) via vectors related to crafted DWARF data, which triggers a read of an invalid pointer.",
        "git_url": "http://sourceware.org/git/?p=systemtap.git;a=commit;h=64b0cff3b",
        "commit_title": "",
        "commit_text": "PR13714 - Make sure REG_STATE.cfa_is_expr is always set correctly.  runtime/unwind.c (processCFI): Always set REG_STATE.cfa_is_expr and add new sanity checks to make sure the cfa definition rules are sane.  Since the cfa expr pointer and cfa register/offset rule shared a union not setting REG_STATE.cfa_is_expr could result in compute_expr () wrongly being called and using the register/offset as expr pointer. ",
        "func_before": "static int processCFI(const u8 *start, const u8 *end, unsigned long targetLoc,\n\t\t      signed ptrType, int user, struct unwind_state *state)\n{\n\tunion {\n\t\tconst u8 *p8;\n\t\tconst u16 *p16;\n\t\tconst u32 *p32;\n\t} ptr;\n\tint result = 1;\n\n\tif (end - start > MAX_CFI) {\n\t\t_stp_warn(\"Too many CFI instuctions\\n\");\n\t\treturn 0;\n\t}\n\n\tdbug_unwind(1, \"targetLoc=%lx state->loc=%lx\\n\", targetLoc, state->loc);\n\tfor (ptr.p8 = start; result && ptr.p8 < end;) {\n\t\tswitch (*ptr.p8 >> 6) {\n\t\t\tuleb128_t value;\n\t\tcase 0:\n\t\t\tswitch (*ptr.p8++) {\n\t\t\tcase DW_CFA_nop:\n\t\t\t\tdbug_unwind(1, \"DW_CFA_nop\\n\");\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_set_loc:\n\t\t\t\tif ((state->loc = read_pointer(&ptr.p8, end, ptrType, user)) == 0)\n\t\t\t\t\tresult = 0;\n\t\t\t\tdbug_unwind(1, \"DW_CFA_set_loc %lx (result=%d)\\n\", state->loc, result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_advance_loc1:\n\t\t\t\tresult = ptr.p8 < end && advance_loc(*ptr.p8++, state);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc1 (result=%d)\\n\", result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_advance_loc2:\n\t\t\t\tresult = ptr.p8 <= end + 2 && advance_loc(*ptr.p16++, state);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc2 (result=%d)\\n\", result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_advance_loc4:\n\t\t\t\tresult = ptr.p8 <= end + 4 && advance_loc(*ptr.p32++, state);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc4 (result=%d)\\n\", result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_offset_extended:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_offset_extended value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Memory, get_uleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_val_offset:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_val_offset value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Value, get_uleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_offset_extended_sf:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_offset_extended_sf value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Memory, get_sleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_val_offset_sf:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_val_offset_sf value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Value, get_sleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_same_value:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_same_value value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Same, 0, state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_restore_extended:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_restore_extended value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tmemcpy(&REG_STATE.regs[value], &state->cie_regs[value], sizeof(struct unwind_item));\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_undefined:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_undefined value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Nowhere, 0, state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_register: {\n\t\t\t\tuleb128_t reg_value;\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\treg_value = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_register value %ld to reg_info idx %ld (reg_value %ld to reg_info idx %ld)\\n\", value, DWARF_REG_MAP(value), reg_value, DWARF_REG_MAP(reg_value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\treg_value = DWARF_REG_MAP(reg_value);\n\t\t\t\tset_rule(value, Register, reg_value, state);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase DW_CFA_expression:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_expression value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_expr_rule(value, Expr, &ptr.p8, end, state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_val_expression:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_val_expression value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_expr_rule(value, ValExpr, &ptr.p8, end,\n\t\t\t\t\t      state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_remember_state:\n\t\t\t\tstate->stackDepth++;\n\t\t\t\tif (state->stackDepth >= STP_MAX_STACK_DEPTH) {\n\t\t\t\t\t_stp_warn(\"Too many stacked DW_CFA_remember_state\\n\");\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tmemcpy(&REG_STATE,\n\t\t\t\t       &state->reg[state->stackDepth - 1],\n\t\t\t\t       sizeof (REG_STATE));\n\t\t\t\tdbug_unwind(1, \"DW_CFA_remember_state (stackDepth=%d)\\n\", state->stackDepth);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_restore_state:\n\t\t\t\tif (state->stackDepth == 0) {\n\t\t\t\t\t_stp_warn(\"Unbalanced DW_CFA_restore_state\\n\");\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tstate->stackDepth--;\n\t\t\t\tdbug_unwind(1, \"DW_CFA_restore_state (stackDepth=%d)\\n\", state->stackDepth);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tREG_STATE.cfa.reg = value;\n\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa reg=%ld\\n\", REG_STATE.cfa.reg);\n\t\t\t\t/*nobreak */\n\t\t\tcase DW_CFA_def_cfa_offset:\n\t\t\t\tREG_STATE.cfa.offs = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset offs=%lx\\n\", REG_STATE.cfa.offs);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa_sf:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_sf value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tREG_STATE.cfa.reg = value;\n\t\t\t\t/*nobreak */\n\t\t\tcase DW_CFA_def_cfa_offset_sf:\n\t\t\t\tREG_STATE.cfa.offs = get_sleb128(&ptr.p8, end) * state->dataAlign;\n\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset_sf offs=%lx\\n\", REG_STATE.cfa.offs);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa_register:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_register value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tREG_STATE.cfa.reg = value;\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa_expression: {\n\t\t\t\tconst u8 *cfa_expr = ptr.p8;\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tif (ptr.p8 < end && end - ptr.p8 >= value) {\n\t\t\t\t\tREG_STATE.cfa_is_expr = 1;\n\t\t\t\t\tREG_STATE.cfa_expr = cfa_expr;\n\t\t\t\t\tptr.p8 += value;\n\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_expression %lu@%p\\n\", value, cfa_expr);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\t_stp_warn(\"BAD DW_CFA_def_cfa_expression value %lu\\n\", value);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase DW_CFA_GNU_args_size:\n\t\t\t\tget_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_GNU_args_size\\n\");\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_GNU_negative_offset_extended:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_GNU_negative_offset_extended value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Memory, (uleb128_t)0 - get_uleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_GNU_window_save:\n\t\t\tdefault:\n\t\t\t\t_stp_warn(\"unimplemented call frame instruction: 0x%x\\n\", *(ptr.p8 - 1));\n\t\t\t\tresult = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tresult = advance_loc(*ptr.p8++ & 0x3f, state);\n\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc\\n\");\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tvalue = *ptr.p8++ & 0x3f;\n\t\t\tdbug_unwind(1, \"map DW_CFA_offset value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\tset_rule(value, Memory, get_uleb128(&ptr.p8, end), state);\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tvalue = *ptr.p8++ & 0x3f;\n\t\t\tdbug_unwind(1, \"map DW_CFA_restore value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\tmemcpy(&REG_STATE.regs[value], &state->cie_regs[value], sizeof(struct unwind_item));\n\t\t\tbreak;\n\t\t}\n\t\tdbug_unwind(1, \"targetLoc=%lx state->loc=%lx\\n\", targetLoc, state->loc);\n\t\tif (ptr.p8 > end)\n\t\t\tresult = 0;\n\t\tif (result && targetLoc != 0 && targetLoc < state->loc)\n\t\t\treturn 1;\n\t}\n\treturn result && ptr.p8 == end;\n}",
        "func": "static int processCFI(const u8 *start, const u8 *end, unsigned long targetLoc,\n\t\t      signed ptrType, int user, struct unwind_state *state)\n{\n\tunion {\n\t\tconst u8 *p8;\n\t\tconst u16 *p16;\n\t\tconst u32 *p32;\n\t} ptr;\n\tint result = 1;\n\n\tif (end - start > MAX_CFI) {\n\t\t_stp_warn(\"Too many CFI instuctions\\n\");\n\t\treturn 0;\n\t}\n\n\tdbug_unwind(1, \"targetLoc=%lx state->loc=%lx\\n\", targetLoc, state->loc);\n\tfor (ptr.p8 = start; result && ptr.p8 < end;) {\n\t\tswitch (*ptr.p8 >> 6) {\n\t\t\tuleb128_t value;\n\t\tcase 0:\n\t\t\tswitch (*ptr.p8++) {\n\t\t\tcase DW_CFA_nop:\n\t\t\t\tdbug_unwind(1, \"DW_CFA_nop\\n\");\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_set_loc:\n\t\t\t\tif ((state->loc = read_pointer(&ptr.p8, end, ptrType, user)) == 0)\n\t\t\t\t\tresult = 0;\n\t\t\t\tdbug_unwind(1, \"DW_CFA_set_loc %lx (result=%d)\\n\", state->loc, result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_advance_loc1:\n\t\t\t\tresult = ptr.p8 < end && advance_loc(*ptr.p8++, state);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc1 (result=%d)\\n\", result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_advance_loc2:\n\t\t\t\tresult = ptr.p8 <= end + 2 && advance_loc(*ptr.p16++, state);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc2 (result=%d)\\n\", result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_advance_loc4:\n\t\t\t\tresult = ptr.p8 <= end + 4 && advance_loc(*ptr.p32++, state);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc4 (result=%d)\\n\", result);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_offset_extended:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_offset_extended value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Memory, get_uleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_val_offset:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_val_offset value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Value, get_uleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_offset_extended_sf:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_offset_extended_sf value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Memory, get_sleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_val_offset_sf:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_val_offset_sf value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Value, get_sleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_same_value:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_same_value value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Same, 0, state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_restore_extended:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_restore_extended value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tmemcpy(&REG_STATE.regs[value], &state->cie_regs[value], sizeof(struct unwind_item));\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_undefined:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_undefined value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Nowhere, 0, state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_register: {\n\t\t\t\tuleb128_t reg_value;\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\treg_value = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_register value %ld to reg_info idx %ld (reg_value %ld to reg_info idx %ld)\\n\", value, DWARF_REG_MAP(value), reg_value, DWARF_REG_MAP(reg_value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\treg_value = DWARF_REG_MAP(reg_value);\n\t\t\t\tset_rule(value, Register, reg_value, state);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase DW_CFA_expression:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_expression value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_expr_rule(value, Expr, &ptr.p8, end, state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_val_expression:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_val_expression value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_expr_rule(value, ValExpr, &ptr.p8, end,\n\t\t\t\t\t      state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_remember_state:\n\t\t\t\tstate->stackDepth++;\n\t\t\t\tif (state->stackDepth >= STP_MAX_STACK_DEPTH) {\n\t\t\t\t\t_stp_warn(\"Too many stacked DW_CFA_remember_state\\n\");\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tmemcpy(&REG_STATE,\n\t\t\t\t       &state->reg[state->stackDepth - 1],\n\t\t\t\t       sizeof (REG_STATE));\n\t\t\t\tdbug_unwind(1, \"DW_CFA_remember_state (stackDepth=%d)\\n\", state->stackDepth);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_restore_state:\n\t\t\t\tif (state->stackDepth == 0) {\n\t\t\t\t\t_stp_warn(\"Unbalanced DW_CFA_restore_state\\n\");\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tstate->stackDepth--;\n\t\t\t\tdbug_unwind(1, \"DW_CFA_restore_state (stackDepth=%d)\\n\", state->stackDepth);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tREG_STATE.cfa_is_expr = 0;\n\t\t\t\tREG_STATE.cfa.reg = value;\n\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa reg=%ld\\n\", REG_STATE.cfa.reg);\n\t\t\t\t/*nobreak */\n\t\t\tcase DW_CFA_def_cfa_offset:\n\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {\n\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_offset\\n\");\n\t\t\t\t} else {\n\t\t\t\t\tREG_STATE.cfa.offs = get_uleb128(&ptr.p8, end);\n\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset offs=%lx\\n\", REG_STATE.cfa.offs);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa_sf:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_sf value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tREG_STATE.cfa_is_expr = 0;\n\t\t\t\tREG_STATE.cfa.reg = value;\n\t\t\t\t/*nobreak */\n\t\t\tcase DW_CFA_def_cfa_offset_sf:\n\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {\n\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_offset_sf\\n\");\n\t\t\t\t} else {\n\t\t\t\t\tREG_STATE.cfa.offs = get_sleb128(&ptr.p8, end) * state->dataAlign;\n\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset_sf offs=%lx\\n\", REG_STATE.cfa.offs);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa_register:\n\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {\n\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_register\\n\");\n\t\t\t\t} else {\n\t\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_register value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\t\tREG_STATE.cfa.reg = value;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_def_cfa_expression: {\n\t\t\t\tconst u8 *cfa_expr = ptr.p8;\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\t/* Sanity check that cfa_expr falls completely\n\t\t\t\t   inside known data. */\n\t\t\t\tif (ptr.p8 < end && end - ptr.p8 >= value) {\n\t\t\t\t\tREG_STATE.cfa_is_expr = 1;\n\t\t\t\t\tREG_STATE.cfa_expr = cfa_expr;\n\t\t\t\t\tptr.p8 += value;\n\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_expression %lu@%p\\n\", value, cfa_expr);\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\t_stp_warn(\"BAD DW_CFA_def_cfa_expression value %lu\\n\", value);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcase DW_CFA_GNU_args_size:\n\t\t\t\tget_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"DW_CFA_GNU_args_size\\n\");\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_GNU_negative_offset_extended:\n\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n\t\t\t\tdbug_unwind(1, \"map DW_CFA_GNU_negative_offset_extended value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\t\tset_rule(value, Memory, (uleb128_t)0 - get_uleb128(&ptr.p8, end), state);\n\t\t\t\tbreak;\n\t\t\tcase DW_CFA_GNU_window_save:\n\t\t\tdefault:\n\t\t\t\t_stp_warn(\"unimplemented call frame instruction: 0x%x\\n\", *(ptr.p8 - 1));\n\t\t\t\tresult = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tresult = advance_loc(*ptr.p8++ & 0x3f, state);\n\t\t\tdbug_unwind(1, \"DW_CFA_advance_loc\\n\");\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tvalue = *ptr.p8++ & 0x3f;\n\t\t\tdbug_unwind(1, \"map DW_CFA_offset value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\tset_rule(value, Memory, get_uleb128(&ptr.p8, end), state);\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tvalue = *ptr.p8++ & 0x3f;\n\t\t\tdbug_unwind(1, \"map DW_CFA_restore value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n\t\t\tvalue = DWARF_REG_MAP(value);\n\t\t\tmemcpy(&REG_STATE.regs[value], &state->cie_regs[value], sizeof(struct unwind_item));\n\t\t\tbreak;\n\t\t}\n\t\tdbug_unwind(1, \"targetLoc=%lx state->loc=%lx\\n\", targetLoc, state->loc);\n\t\tif (ptr.p8 > end)\n\t\t\tresult = 0;\n\t\tif (result && targetLoc != 0 && targetLoc < state->loc)\n\t\t\treturn 1;\n\t}\n\treturn result && ptr.p8 == end;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -126,30 +126,46 @@\n \t\t\tcase DW_CFA_def_cfa:\n \t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n \t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n+\t\t\t\tREG_STATE.cfa_is_expr = 0;\n \t\t\t\tREG_STATE.cfa.reg = value;\n \t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa reg=%ld\\n\", REG_STATE.cfa.reg);\n \t\t\t\t/*nobreak */\n \t\t\tcase DW_CFA_def_cfa_offset:\n-\t\t\t\tREG_STATE.cfa.offs = get_uleb128(&ptr.p8, end);\n-\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset offs=%lx\\n\", REG_STATE.cfa.offs);\n+\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {\n+\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_offset\\n\");\n+\t\t\t\t} else {\n+\t\t\t\t\tREG_STATE.cfa.offs = get_uleb128(&ptr.p8, end);\n+\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset offs=%lx\\n\", REG_STATE.cfa.offs);\n+\t\t\t\t}\n \t\t\t\tbreak;\n \t\t\tcase DW_CFA_def_cfa_sf:\n \t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n \t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_sf value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n+\t\t\t\tREG_STATE.cfa_is_expr = 0;\n \t\t\t\tREG_STATE.cfa.reg = value;\n \t\t\t\t/*nobreak */\n \t\t\tcase DW_CFA_def_cfa_offset_sf:\n-\t\t\t\tREG_STATE.cfa.offs = get_sleb128(&ptr.p8, end) * state->dataAlign;\n-\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset_sf offs=%lx\\n\", REG_STATE.cfa.offs);\n+\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {\n+\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_offset_sf\\n\");\n+\t\t\t\t} else {\n+\t\t\t\t\tREG_STATE.cfa.offs = get_sleb128(&ptr.p8, end) * state->dataAlign;\n+\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset_sf offs=%lx\\n\", REG_STATE.cfa.offs);\n+\t\t\t\t}\n \t\t\t\tbreak;\n \t\t\tcase DW_CFA_def_cfa_register:\n-\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n-\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_register value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n-\t\t\t\tREG_STATE.cfa.reg = value;\n+\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {\n+\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_register\\n\");\n+\t\t\t\t} else {\n+\t\t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n+\t\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_register value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));\n+\t\t\t\t\tREG_STATE.cfa.reg = value;\n+\t\t\t\t}\n \t\t\t\tbreak;\n \t\t\tcase DW_CFA_def_cfa_expression: {\n \t\t\t\tconst u8 *cfa_expr = ptr.p8;\n \t\t\t\tvalue = get_uleb128(&ptr.p8, end);\n+\t\t\t\t/* Sanity check that cfa_expr falls completely\n+\t\t\t\t   inside known data. */\n \t\t\t\tif (ptr.p8 < end && end - ptr.p8 >= value) {\n \t\t\t\t\tREG_STATE.cfa_is_expr = 1;\n \t\t\t\t\tREG_STATE.cfa_expr = cfa_expr;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\tREG_STATE.cfa.offs = get_uleb128(&ptr.p8, end);",
                "\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset offs=%lx\\n\", REG_STATE.cfa.offs);",
                "\t\t\t\tREG_STATE.cfa.offs = get_sleb128(&ptr.p8, end) * state->dataAlign;",
                "\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset_sf offs=%lx\\n\", REG_STATE.cfa.offs);",
                "\t\t\t\tvalue = get_uleb128(&ptr.p8, end);",
                "\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_register value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));",
                "\t\t\t\tREG_STATE.cfa.reg = value;"
            ],
            "added_lines": [
                "\t\t\t\tREG_STATE.cfa_is_expr = 0;",
                "\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {",
                "\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_offset\\n\");",
                "\t\t\t\t} else {",
                "\t\t\t\t\tREG_STATE.cfa.offs = get_uleb128(&ptr.p8, end);",
                "\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset offs=%lx\\n\", REG_STATE.cfa.offs);",
                "\t\t\t\t}",
                "\t\t\t\tREG_STATE.cfa_is_expr = 0;",
                "\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {",
                "\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_offset_sf\\n\");",
                "\t\t\t\t} else {",
                "\t\t\t\t\tREG_STATE.cfa.offs = get_sleb128(&ptr.p8, end) * state->dataAlign;",
                "\t\t\t\t\tdbug_unwind(1, \"DW_CFA_def_cfa_offset_sf offs=%lx\\n\", REG_STATE.cfa.offs);",
                "\t\t\t\t}",
                "\t\t\t\tif (REG_STATE.cfa_is_expr != 0) {",
                "\t\t\t\t\t_stp_warn(\"Unexpected DW_CFA_def_cfa_register\\n\");",
                "\t\t\t\t} else {",
                "\t\t\t\t\tvalue = get_uleb128(&ptr.p8, end);",
                "\t\t\t\t\tdbug_unwind(1, \"map DW_CFA_def_cfa_register value %ld to reg_info idx %ld\\n\", value, DWARF_REG_MAP(value));",
                "\t\t\t\t\tREG_STATE.cfa.reg = value;",
                "\t\t\t\t}",
                "\t\t\t\t/* Sanity check that cfa_expr falls completely",
                "\t\t\t\t   inside known data. */"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6657",
        "func_name": "chromium/XSSAuditor::filterButtonToken",
        "description": "core/html/parser/XSSAuditor.cpp in the XSS auditor in Blink, as used in Google Chrome before 33.0.1750.117, inserts the about:blank URL during certain blocking of FORM elements within HTTP requests, which allows remote attackers to bypass the Same Origin Policy and obtain sensitive information via unspecified vectors.",
        "git_url": "https://github.com/chromium/chromium/commit/a6d23b1b720689b2247e9e046f0be4e1eaf8f314",
        "commit_title": "Use data:, rather than about:blank as a substitute form action so the resulting blank page will have an unique origin.",
        "commit_text": " This is similar to the work we did in XSSAuditorDelegate for the mode=block case, where we used the SecurityOrigin::urlWithUniqueOrign constant.  We can't use that here due to threading.  Testing is covered by rebasing the existing test cases.  ",
        "func_before": "bool XSSAuditor::filterButtonToken(const FilterTokenRequest& request)\n{\n    ASSERT(request.token.type() == HTMLToken::StartTag);\n    ASSERT(hasName(request.token, buttonTag));\n\n    return eraseAttributeIfInjected(request, formactionAttr, blankURL().string(), SrcLikeAttribute);\n}",
        "func": "bool XSSAuditor::filterButtonToken(const FilterTokenRequest& request)\n{\n    ASSERT(request.token.type() == HTMLToken::StartTag);\n    ASSERT(hasName(request.token, buttonTag));\n\n    return eraseAttributeIfInjected(request, formactionAttr, kURLWithUniqueOrigin, SrcLikeAttribute);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,5 @@\n     ASSERT(request.token.type() == HTMLToken::StartTag);\n     ASSERT(hasName(request.token, buttonTag));\n \n-    return eraseAttributeIfInjected(request, formactionAttr, blankURL().string(), SrcLikeAttribute);\n+    return eraseAttributeIfInjected(request, formactionAttr, kURLWithUniqueOrigin, SrcLikeAttribute);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return eraseAttributeIfInjected(request, formactionAttr, blankURL().string(), SrcLikeAttribute);"
            ],
            "added_lines": [
                "    return eraseAttributeIfInjected(request, formactionAttr, kURLWithUniqueOrigin, SrcLikeAttribute);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6657",
        "func_name": "chromium/XSSAuditor::filterFormToken",
        "description": "core/html/parser/XSSAuditor.cpp in the XSS auditor in Blink, as used in Google Chrome before 33.0.1750.117, inserts the about:blank URL during certain blocking of FORM elements within HTTP requests, which allows remote attackers to bypass the Same Origin Policy and obtain sensitive information via unspecified vectors.",
        "git_url": "https://github.com/chromium/chromium/commit/a6d23b1b720689b2247e9e046f0be4e1eaf8f314",
        "commit_title": "Use data:, rather than about:blank as a substitute form action so the resulting blank page will have an unique origin.",
        "commit_text": " This is similar to the work we did in XSSAuditorDelegate for the mode=block case, where we used the SecurityOrigin::urlWithUniqueOrign constant.  We can't use that here due to threading.  Testing is covered by rebasing the existing test cases.  ",
        "func_before": "bool XSSAuditor::filterFormToken(const FilterTokenRequest& request)\n{\n    ASSERT(request.token.type() == HTMLToken::StartTag);\n    ASSERT(hasName(request.token, formTag));\n\n    return eraseAttributeIfInjected(request, actionAttr, blankURL().string());\n}",
        "func": "bool XSSAuditor::filterFormToken(const FilterTokenRequest& request)\n{\n    ASSERT(request.token.type() == HTMLToken::StartTag);\n    ASSERT(hasName(request.token, formTag));\n\n    return eraseAttributeIfInjected(request, actionAttr, kURLWithUniqueOrigin);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,5 @@\n     ASSERT(request.token.type() == HTMLToken::StartTag);\n     ASSERT(hasName(request.token, formTag));\n \n-    return eraseAttributeIfInjected(request, actionAttr, blankURL().string());\n+    return eraseAttributeIfInjected(request, actionAttr, kURLWithUniqueOrigin);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return eraseAttributeIfInjected(request, actionAttr, blankURL().string());"
            ],
            "added_lines": [
                "    return eraseAttributeIfInjected(request, actionAttr, kURLWithUniqueOrigin);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6657",
        "func_name": "chromium/XSSAuditor::filterInputToken",
        "description": "core/html/parser/XSSAuditor.cpp in the XSS auditor in Blink, as used in Google Chrome before 33.0.1750.117, inserts the about:blank URL during certain blocking of FORM elements within HTTP requests, which allows remote attackers to bypass the Same Origin Policy and obtain sensitive information via unspecified vectors.",
        "git_url": "https://github.com/chromium/chromium/commit/a6d23b1b720689b2247e9e046f0be4e1eaf8f314",
        "commit_title": "Use data:, rather than about:blank as a substitute form action so the resulting blank page will have an unique origin.",
        "commit_text": " This is similar to the work we did in XSSAuditorDelegate for the mode=block case, where we used the SecurityOrigin::urlWithUniqueOrign constant.  We can't use that here due to threading.  Testing is covered by rebasing the existing test cases.  ",
        "func_before": "bool XSSAuditor::filterInputToken(const FilterTokenRequest& request)\n{\n    ASSERT(request.token.type() == HTMLToken::StartTag);\n    ASSERT(hasName(request.token, inputTag));\n\n    return eraseAttributeIfInjected(request, formactionAttr, blankURL().string(), SrcLikeAttribute);\n}",
        "func": "bool XSSAuditor::filterInputToken(const FilterTokenRequest& request)\n{\n    ASSERT(request.token.type() == HTMLToken::StartTag);\n    ASSERT(hasName(request.token, inputTag));\n\n    return eraseAttributeIfInjected(request, formactionAttr, kURLWithUniqueOrigin, SrcLikeAttribute);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,5 +3,5 @@\n     ASSERT(request.token.type() == HTMLToken::StartTag);\n     ASSERT(hasName(request.token, inputTag));\n \n-    return eraseAttributeIfInjected(request, formactionAttr, blankURL().string(), SrcLikeAttribute);\n+    return eraseAttributeIfInjected(request, formactionAttr, kURLWithUniqueOrigin, SrcLikeAttribute);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return eraseAttributeIfInjected(request, formactionAttr, blankURL().string(), SrcLikeAttribute);"
            ],
            "added_lines": [
                "    return eraseAttributeIfInjected(request, formactionAttr, kURLWithUniqueOrigin, SrcLikeAttribute);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/OSExchangeDataProviderWin::GetURLAndTitle",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "bool OSExchangeDataProviderWin::GetURLAndTitle(GURL* url,\n                                               base::string16* title) const {\n  base::string16 url_str;\n  bool success = ClipboardUtil::GetUrl(source_object_, &url_str, title, true);\n  if (success) {\n    GURL test_url(url_str);\n    if (test_url.is_valid()) {\n      *url = test_url;\n      return true;\n    }\n  } else if (GetPlainTextURL(source_object_, url)) {\n    if (url->is_valid())\n      *title = net::GetSuggestedFilename(*url, \"\", \"\", \"\", \"\", std::string());\n    else\n      title->clear();\n    return true;\n  }\n  return false;\n}",
        "func": "bool OSExchangeDataProviderWin::GetURLAndTitle(\n    OSExchangeData::FilenameToURLPolicy policy,\n    GURL* url,\n    base::string16* title) const {\n  base::string16 url_str;\n  bool success = ClipboardUtil::GetUrl(\n      source_object_,\n      &url_str,\n      title,\n      policy == OSExchangeData::CONVERT_FILENAMES ? true : false);\n  if (success) {\n    GURL test_url(url_str);\n    if (test_url.is_valid()) {\n      *url = test_url;\n      return true;\n    }\n  } else if (GetPlainTextURL(source_object_, url)) {\n    if (url->is_valid())\n      *title = net::GetSuggestedFilename(*url, \"\", \"\", \"\", \"\", std::string());\n    else\n      title->clear();\n    return true;\n  }\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,13 @@\n-bool OSExchangeDataProviderWin::GetURLAndTitle(GURL* url,\n-                                               base::string16* title) const {\n+bool OSExchangeDataProviderWin::GetURLAndTitle(\n+    OSExchangeData::FilenameToURLPolicy policy,\n+    GURL* url,\n+    base::string16* title) const {\n   base::string16 url_str;\n-  bool success = ClipboardUtil::GetUrl(source_object_, &url_str, title, true);\n+  bool success = ClipboardUtil::GetUrl(\n+      source_object_,\n+      &url_str,\n+      title,\n+      policy == OSExchangeData::CONVERT_FILENAMES ? true : false);\n   if (success) {\n     GURL test_url(url_str);\n     if (test_url.is_valid()) {",
        "diff_line_info": {
            "deleted_lines": [
                "bool OSExchangeDataProviderWin::GetURLAndTitle(GURL* url,",
                "                                               base::string16* title) const {",
                "  bool success = ClipboardUtil::GetUrl(source_object_, &url_str, title, true);"
            ],
            "added_lines": [
                "bool OSExchangeDataProviderWin::GetURLAndTitle(",
                "    OSExchangeData::FilenameToURLPolicy policy,",
                "    GURL* url,",
                "    base::string16* title) const {",
                "  bool success = ClipboardUtil::GetUrl(",
                "      source_object_,",
                "      &url_str,",
                "      title,",
                "      policy == OSExchangeData::CONVERT_FILENAMES ? true : false);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/OmniboxViewViews::OnDrop",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "int OmniboxViewViews::OnDrop(const ui::OSExchangeData& data) {\n  if (HasTextBeingDragged())\n    return ui::DragDropTypes::DRAG_NONE;\n\n  if (data.HasURL()) {\n    GURL url;\n    base::string16 title;\n    if (data.GetURLAndTitle(&url, &title)) {\n      base::string16 text(\n          StripJavascriptSchemas(base::UTF8ToUTF16(url.spec())));\n      if (model()->CanPasteAndGo(text)) {\n        model()->PasteAndGo(text);\n        return ui::DragDropTypes::DRAG_COPY;\n      }\n    }\n  } else if (data.HasString()) {\n    base::string16 text;\n    if (data.GetString(&text)) {\n      base::string16 collapsed_text(CollapseWhitespace(text, true));\n      if (model()->CanPasteAndGo(collapsed_text))\n        model()->PasteAndGo(collapsed_text);\n      return ui::DragDropTypes::DRAG_COPY;\n    }\n  }\n\n  return ui::DragDropTypes::DRAG_NONE;\n}",
        "func": "int OmniboxViewViews::OnDrop(const ui::OSExchangeData& data) {\n  if (HasTextBeingDragged())\n    return ui::DragDropTypes::DRAG_NONE;\n\n  if (data.HasURL()) {\n    GURL url;\n    base::string16 title;\n    if (data.GetURLAndTitle(\n            ui::OSExchangeData::CONVERT_FILENAMES, &url, &title)) {\n      base::string16 text(\n          StripJavascriptSchemas(base::UTF8ToUTF16(url.spec())));\n      if (model()->CanPasteAndGo(text)) {\n        model()->PasteAndGo(text);\n        return ui::DragDropTypes::DRAG_COPY;\n      }\n    }\n  } else if (data.HasString()) {\n    base::string16 text;\n    if (data.GetString(&text)) {\n      base::string16 collapsed_text(CollapseWhitespace(text, true));\n      if (model()->CanPasteAndGo(collapsed_text))\n        model()->PasteAndGo(collapsed_text);\n      return ui::DragDropTypes::DRAG_COPY;\n    }\n  }\n\n  return ui::DragDropTypes::DRAG_NONE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,8 @@\n   if (data.HasURL()) {\n     GURL url;\n     base::string16 title;\n-    if (data.GetURLAndTitle(&url, &title)) {\n+    if (data.GetURLAndTitle(\n+            ui::OSExchangeData::CONVERT_FILENAMES, &url, &title)) {\n       base::string16 text(\n           StripJavascriptSchemas(base::UTF8ToUTF16(url.spec())));\n       if (model()->CanPasteAndGo(text)) {",
        "diff_line_info": {
            "deleted_lines": [
                "    if (data.GetURLAndTitle(&url, &title)) {"
            ],
            "added_lines": [
                "    if (data.GetURLAndTitle(",
                "            ui::OSExchangeData::CONVERT_FILENAMES, &url, &title)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/OSExchangeDataProviderAura::GetURLAndTitle",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "bool OSExchangeDataProviderAura::GetURLAndTitle(GURL* url,\n                                                base::string16* title) const {\n  if ((formats_ & OSExchangeData::URL) == 0) {\n    title->clear();\n    return GetPlainTextURL(url);\n  }\n\n  if (!url_.is_valid())\n    return false;\n\n  *url = url_;\n  *title = title_;\n  return true;\n}",
        "func": "bool OSExchangeDataProviderAura::GetURLAndTitle(\n    OSExchangeData::FilenameToURLPolicy policy,\n    GURL* url,\n    base::string16* title) const {\n  // TODO(dcheng): implement filename conversion.\n  if ((formats_ & OSExchangeData::URL) == 0) {\n    title->clear();\n    return GetPlainTextURL(url);\n  }\n\n  if (!url_.is_valid())\n    return false;\n\n  *url = url_;\n  *title = title_;\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,8 @@\n-bool OSExchangeDataProviderAura::GetURLAndTitle(GURL* url,\n-                                                base::string16* title) const {\n+bool OSExchangeDataProviderAura::GetURLAndTitle(\n+    OSExchangeData::FilenameToURLPolicy policy,\n+    GURL* url,\n+    base::string16* title) const {\n+  // TODO(dcheng): implement filename conversion.\n   if ((formats_ & OSExchangeData::URL) == 0) {\n     title->clear();\n     return GetPlainTextURL(url);",
        "diff_line_info": {
            "deleted_lines": [
                "bool OSExchangeDataProviderAura::GetURLAndTitle(GURL* url,",
                "                                                base::string16* title) const {"
            ],
            "added_lines": [
                "bool OSExchangeDataProviderAura::GetURLAndTitle(",
                "    OSExchangeData::FilenameToURLPolicy policy,",
                "    GURL* url,",
                "    base::string16* title) const {",
                "  // TODO(dcheng): implement filename conversion."
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/BookmarkNodeData::Read",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "bool BookmarkNodeData::Read(const ui::OSExchangeData& data) {\n  elements.clear();\n\n  profile_path_.clear();\n\n  if (data.HasCustomFormat(GetBookmarkCustomFormat())) {\n    Pickle drag_data_pickle;\n    if (data.GetPickledData(GetBookmarkCustomFormat(), &drag_data_pickle)) {\n      if (!ReadFromPickle(&drag_data_pickle))\n        return false;\n    }\n  } else {\n    // See if there is a URL on the clipboard.\n    Element element;\n    GURL url;\n    base::string16 title;\n    if (data.GetURLAndTitle(&url, &title))\n      ReadFromTuple(url, title);\n  }\n\n  return is_valid();\n}",
        "func": "bool BookmarkNodeData::Read(const ui::OSExchangeData& data) {\n  elements.clear();\n\n  profile_path_.clear();\n\n  if (data.HasCustomFormat(GetBookmarkCustomFormat())) {\n    Pickle drag_data_pickle;\n    if (data.GetPickledData(GetBookmarkCustomFormat(), &drag_data_pickle)) {\n      if (!ReadFromPickle(&drag_data_pickle))\n        return false;\n    }\n  } else {\n    // See if there is a URL on the clipboard.\n    Element element;\n    GURL url;\n    base::string16 title;\n    if (data.GetURLAndTitle(\n            ui::OSExchangeData::CONVERT_FILENAMES, &url, &title))\n      ReadFromTuple(url, title);\n  }\n\n  return is_valid();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,8 @@\n     Element element;\n     GURL url;\n     base::string16 title;\n-    if (data.GetURLAndTitle(&url, &title))\n+    if (data.GetURLAndTitle(\n+            ui::OSExchangeData::CONVERT_FILENAMES, &url, &title))\n       ReadFromTuple(url, title);\n   }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (data.GetURLAndTitle(&url, &title))"
            ],
            "added_lines": [
                "    if (data.GetURLAndTitle(",
                "            ui::OSExchangeData::CONVERT_FILENAMES, &url, &title))"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/TabStrip::OnPerformDrop",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "int TabStrip::OnPerformDrop(const DropTargetEvent& event) {\n  if (!drop_info_.get())\n    return ui::DragDropTypes::DRAG_NONE;\n\n  const int drop_index = drop_info_->drop_index;\n  const bool drop_before = drop_info_->drop_before;\n  const bool file_supported = drop_info_->file_supported;\n\n  // Hide the drop indicator.\n  SetDropIndex(-1, false);\n\n  // Do nothing if the file was unsupported or the URL is invalid. The URL may\n  // have been changed after |drop_info_| was created.\n  GURL url;\n  base::string16 title;\n  if (!file_supported ||\n      !event.data().GetURLAndTitle(&url, &title) || !url.is_valid())\n    return ui::DragDropTypes::DRAG_NONE;\n\n  controller()->PerformDrop(drop_before, drop_index, url);\n\n  return GetDropEffect(event);\n}",
        "func": "int TabStrip::OnPerformDrop(const DropTargetEvent& event) {\n  if (!drop_info_.get())\n    return ui::DragDropTypes::DRAG_NONE;\n\n  const int drop_index = drop_info_->drop_index;\n  const bool drop_before = drop_info_->drop_before;\n  const bool file_supported = drop_info_->file_supported;\n\n  // Hide the drop indicator.\n  SetDropIndex(-1, false);\n\n  // Do nothing if the file was unsupported or the URL is invalid. The URL may\n  // have been changed after |drop_info_| was created.\n  GURL url;\n  base::string16 title;\n  if (!file_supported ||\n      !event.data().GetURLAndTitle(\n           ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) ||\n      !url.is_valid())\n    return ui::DragDropTypes::DRAG_NONE;\n\n  controller()->PerformDrop(drop_before, drop_index, url);\n\n  return GetDropEffect(event);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,9 @@\n   GURL url;\n   base::string16 title;\n   if (!file_supported ||\n-      !event.data().GetURLAndTitle(&url, &title) || !url.is_valid())\n+      !event.data().GetURLAndTitle(\n+           ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) ||\n+      !url.is_valid())\n     return ui::DragDropTypes::DRAG_NONE;\n \n   controller()->PerformDrop(drop_before, drop_index, url);",
        "diff_line_info": {
            "deleted_lines": [
                "      !event.data().GetURLAndTitle(&url, &title) || !url.is_valid())"
            ],
            "added_lines": [
                "      !event.data().GetURLAndTitle(",
                "           ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) ||",
                "      !url.is_valid())"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/TabStrip::OnDragEntered",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "void TabStrip::OnDragEntered(const DropTargetEvent& event) {\n  // Force animations to stop, otherwise it makes the index calculation tricky.\n  StopAnimating(true);\n\n  UpdateDropIndex(event);\n\n  GURL url;\n  base::string16 title;\n\n  // Check whether the event data includes supported drop data.\n  if (event.data().GetURLAndTitle(&url, &title) && url.is_valid()) {\n    drop_info_->url = url;\n\n    // For file:// URLs, kick off a MIME type request in case they're dropped.\n    if (url.SchemeIsFile())\n      controller()->CheckFileSupported(url);\n  }\n}",
        "func": "void TabStrip::OnDragEntered(const DropTargetEvent& event) {\n  // Force animations to stop, otherwise it makes the index calculation tricky.\n  StopAnimating(true);\n\n  UpdateDropIndex(event);\n\n  GURL url;\n  base::string16 title;\n\n  // Check whether the event data includes supported drop data.\n  if (event.data().GetURLAndTitle(\n          ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) &&\n      url.is_valid()) {\n    drop_info_->url = url;\n\n    // For file:// URLs, kick off a MIME type request in case they're dropped.\n    if (url.SchemeIsFile())\n      controller()->CheckFileSupported(url);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,9 @@\n   base::string16 title;\n \n   // Check whether the event data includes supported drop data.\n-  if (event.data().GetURLAndTitle(&url, &title) && url.is_valid()) {\n+  if (event.data().GetURLAndTitle(\n+          ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) &&\n+      url.is_valid()) {\n     drop_info_->url = url;\n \n     // For file:// URLs, kick off a MIME type request in case they're dropped.",
        "diff_line_info": {
            "deleted_lines": [
                "  if (event.data().GetURLAndTitle(&url, &title) && url.is_valid()) {"
            ],
            "added_lines": [
                "  if (event.data().GetURLAndTitle(",
                "          ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) &&",
                "      url.is_valid()) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/BrowserRootView::OnPerformDrop",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "int BrowserRootView::OnPerformDrop(const ui::DropTargetEvent& event) {\n  if (!forwarding_to_tab_strip_)\n    return ui::DragDropTypes::DRAG_NONE;\n\n  // Extract the URL and create a new ui::OSExchangeData containing the URL. We\n  // do this as the TabStrip doesn't know about the autocomplete edit and needs\n  // to know about it to handle 'paste and go'.\n  GURL url;\n  base::string16 title;\n  ui::OSExchangeData mapped_data;\n  if (!event.data().GetURLAndTitle(&url, &title) || !url.is_valid()) {\n    // The url isn't valid. Use the paste and go url.\n    if (GetPasteAndGoURL(event.data(), &url))\n      mapped_data.SetURL(url, base::string16());\n    // else case: couldn't extract a url or 'paste and go' url. This ends up\n    // passing through an ui::OSExchangeData with nothing in it. We need to do\n    // this so that the tab strip cleans up properly.\n  } else {\n    mapped_data.SetURL(url, base::string16());\n  }\n  forwarding_to_tab_strip_ = false;\n  scoped_ptr<ui::DropTargetEvent> mapped_event(\n      MapEventToTabStrip(event, mapped_data));\n  return tabstrip()->OnPerformDrop(*mapped_event);\n}",
        "func": "int BrowserRootView::OnPerformDrop(const ui::DropTargetEvent& event) {\n  if (!forwarding_to_tab_strip_)\n    return ui::DragDropTypes::DRAG_NONE;\n\n  // Extract the URL and create a new ui::OSExchangeData containing the URL. We\n  // do this as the TabStrip doesn't know about the autocomplete edit and needs\n  // to know about it to handle 'paste and go'.\n  GURL url;\n  base::string16 title;\n  ui::OSExchangeData mapped_data;\n  if (!event.data().GetURLAndTitle(\n           ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) ||\n      !url.is_valid()) {\n    // The url isn't valid. Use the paste and go url.\n    if (GetPasteAndGoURL(event.data(), &url))\n      mapped_data.SetURL(url, base::string16());\n    // else case: couldn't extract a url or 'paste and go' url. This ends up\n    // passing through an ui::OSExchangeData with nothing in it. We need to do\n    // this so that the tab strip cleans up properly.\n  } else {\n    mapped_data.SetURL(url, base::string16());\n  }\n  forwarding_to_tab_strip_ = false;\n  scoped_ptr<ui::DropTargetEvent> mapped_event(\n      MapEventToTabStrip(event, mapped_data));\n  return tabstrip()->OnPerformDrop(*mapped_event);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,9 @@\n   GURL url;\n   base::string16 title;\n   ui::OSExchangeData mapped_data;\n-  if (!event.data().GetURLAndTitle(&url, &title) || !url.is_valid()) {\n+  if (!event.data().GetURLAndTitle(\n+           ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) ||\n+      !url.is_valid()) {\n     // The url isn't valid. Use the paste and go url.\n     if (GetPasteAndGoURL(event.data(), &url))\n       mapped_data.SetURL(url, base::string16());",
        "diff_line_info": {
            "deleted_lines": [
                "  if (!event.data().GetURLAndTitle(&url, &title) || !url.is_valid()) {"
            ],
            "added_lines": [
                "  if (!event.data().GetURLAndTitle(",
                "           ui::OSExchangeData::CONVERT_FILENAMES, &url, &title) ||",
                "      !url.is_valid()) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/HomeButton::OnPerformDrop",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "int HomeButton::OnPerformDrop(const ui::DropTargetEvent& event) {\n  GURL new_homepage_url;\n  base::string16 title;\n  if (event.data().GetURLAndTitle(&new_homepage_url, &title) &&\n      new_homepage_url.is_valid()) {\n    PrefService* prefs = browser_->profile()->GetPrefs();\n    bool old_is_ntp = prefs->GetBoolean(prefs::kHomePageIsNewTabPage);\n    GURL old_homepage(prefs->GetString(prefs::kHomePage));\n\n    prefs->SetBoolean(prefs::kHomePageIsNewTabPage, false);\n    prefs->SetString(prefs::kHomePage, new_homepage_url.spec());\n\n    HomePageUndoBubble::ShowBubble(browser_, old_is_ntp, old_homepage, this);\n  }\n  return ui::DragDropTypes::DRAG_NONE;\n}",
        "func": "int HomeButton::OnPerformDrop(const ui::DropTargetEvent& event) {\n  GURL new_homepage_url;\n  base::string16 title;\n  if (event.data().GetURLAndTitle(\n          ui::OSExchangeData::CONVERT_FILENAMES, &new_homepage_url, &title) &&\n      new_homepage_url.is_valid()) {\n    PrefService* prefs = browser_->profile()->GetPrefs();\n    bool old_is_ntp = prefs->GetBoolean(prefs::kHomePageIsNewTabPage);\n    GURL old_homepage(prefs->GetString(prefs::kHomePage));\n\n    prefs->SetBoolean(prefs::kHomePageIsNewTabPage, false);\n    prefs->SetString(prefs::kHomePage, new_homepage_url.spec());\n\n    HomePageUndoBubble::ShowBubble(browser_, old_is_ntp, old_homepage, this);\n  }\n  return ui::DragDropTypes::DRAG_NONE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,8 @@\n int HomeButton::OnPerformDrop(const ui::DropTargetEvent& event) {\n   GURL new_homepage_url;\n   base::string16 title;\n-  if (event.data().GetURLAndTitle(&new_homepage_url, &title) &&\n+  if (event.data().GetURLAndTitle(\n+          ui::OSExchangeData::CONVERT_FILENAMES, &new_homepage_url, &title) &&\n       new_homepage_url.is_valid()) {\n     PrefService* prefs = browser_->profile()->GetPrefs();\n     bool old_is_ntp = prefs->GetBoolean(prefs::kHomePageIsNewTabPage);",
        "diff_line_info": {
            "deleted_lines": [
                "  if (event.data().GetURLAndTitle(&new_homepage_url, &title) &&"
            ],
            "added_lines": [
                "  if (event.data().GetURLAndTitle(",
                "          ui::OSExchangeData::CONVERT_FILENAMES, &new_homepage_url, &title) &&"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/OSExchangeData::GetURLAndTitle",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "bool OSExchangeData::GetURLAndTitle(GURL* url, base::string16* title) const {\n  return provider_->GetURLAndTitle(url, title);\n}",
        "func": "bool OSExchangeData::GetURLAndTitle(FilenameToURLPolicy policy,\n                                    GURL* url,\n                                    base::string16* title) const {\n  return provider_->GetURLAndTitle(policy, url, title);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,3 +1,5 @@\n-bool OSExchangeData::GetURLAndTitle(GURL* url, base::string16* title) const {\n-  return provider_->GetURLAndTitle(url, title);\n+bool OSExchangeData::GetURLAndTitle(FilenameToURLPolicy policy,\n+                                    GURL* url,\n+                                    base::string16* title) const {\n+  return provider_->GetURLAndTitle(policy, url, title);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "bool OSExchangeData::GetURLAndTitle(GURL* url, base::string16* title) const {",
                "  return provider_->GetURLAndTitle(url, title);"
            ],
            "added_lines": [
                "bool OSExchangeData::GetURLAndTitle(FilenameToURLPolicy policy,",
                "                                    GURL* url,",
                "                                    base::string16* title) const {",
                "  return provider_->GetURLAndTitle(policy, url, title);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/PrepareDropData",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "void PrepareDropData(DropData* drop_data, const ui::OSExchangeData& data) {\n  base::string16 plain_text;\n  data.GetString(&plain_text);\n  if (!plain_text.empty())\n    drop_data->text = base::NullableString16(plain_text, false);\n\n  GURL url;\n  base::string16 url_title;\n  data.GetURLAndTitle(&url, &url_title);\n  if (url.is_valid()) {\n    drop_data->url = url;\n    drop_data->url_title = url_title;\n  }\n\n  base::string16 html;\n  GURL html_base_url;\n  data.GetHtml(&html, &html_base_url);\n  if (!html.empty())\n    drop_data->html = base::NullableString16(html, false);\n  if (html_base_url.is_valid())\n    drop_data->html_base_url = html_base_url;\n\n  std::vector<ui::OSExchangeData::FileInfo> files;\n  if (data.GetFilenames(&files) && !files.empty()) {\n    for (std::vector<ui::OSExchangeData::FileInfo>::const_iterator\n             it = files.begin(); it != files.end(); ++it) {\n      drop_data->filenames.push_back(\n          DropData::FileInfo(\n              base::UTF8ToUTF16(it->path.AsUTF8Unsafe()),\n              base::UTF8ToUTF16(it->display_name.AsUTF8Unsafe())));\n    }\n  }\n\n  Pickle pickle;\n  if (data.GetPickledData(ui::Clipboard::GetWebCustomDataFormatType(), &pickle))\n    ui::ReadCustomDataIntoMap(\n        pickle.data(), pickle.size(), &drop_data->custom_data);\n}",
        "func": "void PrepareDropData(DropData* drop_data, const ui::OSExchangeData& data) {\n  base::string16 plain_text;\n  data.GetString(&plain_text);\n  if (!plain_text.empty())\n    drop_data->text = base::NullableString16(plain_text, false);\n\n  GURL url;\n  base::string16 url_title;\n  data.GetURLAndTitle(\n      ui::OSExchangeData::DO_NOT_CONVERT_FILENAMES, &url, &url_title);\n  if (url.is_valid()) {\n    drop_data->url = url;\n    drop_data->url_title = url_title;\n  }\n\n  base::string16 html;\n  GURL html_base_url;\n  data.GetHtml(&html, &html_base_url);\n  if (!html.empty())\n    drop_data->html = base::NullableString16(html, false);\n  if (html_base_url.is_valid())\n    drop_data->html_base_url = html_base_url;\n\n  std::vector<ui::OSExchangeData::FileInfo> files;\n  if (data.GetFilenames(&files) && !files.empty()) {\n    for (std::vector<ui::OSExchangeData::FileInfo>::const_iterator\n             it = files.begin(); it != files.end(); ++it) {\n      drop_data->filenames.push_back(\n          DropData::FileInfo(\n              base::UTF8ToUTF16(it->path.AsUTF8Unsafe()),\n              base::UTF8ToUTF16(it->display_name.AsUTF8Unsafe())));\n    }\n  }\n\n  Pickle pickle;\n  if (data.GetPickledData(ui::Clipboard::GetWebCustomDataFormatType(), &pickle))\n    ui::ReadCustomDataIntoMap(\n        pickle.data(), pickle.size(), &drop_data->custom_data);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,8 @@\n \n   GURL url;\n   base::string16 url_title;\n-  data.GetURLAndTitle(&url, &url_title);\n+  data.GetURLAndTitle(\n+      ui::OSExchangeData::DO_NOT_CONVERT_FILENAMES, &url, &url_title);\n   if (url.is_valid()) {\n     drop_data->url = url;\n     drop_data->url_title = url_title;",
        "diff_line_info": {
            "deleted_lines": [
                "  data.GetURLAndTitle(&url, &url_title);"
            ],
            "added_lines": [
                "  data.GetURLAndTitle(",
                "      ui::OSExchangeData::DO_NOT_CONVERT_FILENAMES, &url, &url_title);"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6660",
        "func_name": "chromium/OSExchangeDataProviderAuraX11::GetURLAndTitle",
        "description": "The drag-and-drop implementation in Google Chrome before 33.0.1750.117 does not properly restrict the information in WebDropData data structures, which allows remote attackers to discover full pathnames via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/1161a49d663dd395bd639549c2dfe7324f847938",
        "commit_title": "Don't populate URL data in WebDropData when dragging files.",
        "commit_text": " This is considered a potential security issue as well, since it leaks filesystem paths.   ",
        "func_before": "bool OSExchangeDataProviderAuraX11::GetURLAndTitle(\n    GURL* url,\n    base::string16* title) const {\n  std::vector< ::Atom> url_atoms = ui::GetURLAtomsFrom(&atom_cache_);\n  std::vector< ::Atom> requested_types;\n  ui::GetAtomIntersection(url_atoms, GetTargets(), &requested_types);\n\n  ui::SelectionData data(format_map_.GetFirstOf(requested_types));\n  if (data.IsValid()) {\n    // TODO(erg): Technically, both of these forms can accept multiple URLs,\n    // but that doesn't match the assumptions of the rest of the system which\n    // expect single types.\n\n    if (data.GetType() == atom_cache_.GetAtom(kMimeTypeMozillaURL)) {\n      // Mozilla URLs are (UTF16: URL, newline, title).\n      base::string16 unparsed;\n      data.AssignTo(&unparsed);\n\n      std::vector<base::string16> tokens;\n      size_t num_tokens = Tokenize(unparsed, base::ASCIIToUTF16(\"\\n\"), &tokens);\n      if (num_tokens > 0) {\n        if (num_tokens > 1)\n          *title = tokens[1];\n        else\n          *title = base::string16();\n\n        *url = GURL(tokens[0]);\n        return true;\n      }\n    } else if (data.GetType() == atom_cache_.GetAtom(\n                   Clipboard::kMimeTypeURIList)) {\n      std::vector<std::string> tokens = ui::ParseURIList(data);\n      for (std::vector<std::string>::const_iterator it = tokens.begin();\n           it != tokens.end(); ++it) {\n        GURL test_url(*it);\n        if (!test_url.SchemeIsFile()) {\n          *url = test_url;\n          *title = base::string16();\n          return true;\n        }\n      }\n    }\n  }\n\n  return false;\n}",
        "func": "bool OSExchangeDataProviderAuraX11::GetURLAndTitle(\n    OSExchangeData::FilenameToURLPolicy policy,\n    GURL* url,\n    base::string16* title) const {\n  std::vector< ::Atom> url_atoms = ui::GetURLAtomsFrom(&atom_cache_);\n  std::vector< ::Atom> requested_types;\n  ui::GetAtomIntersection(url_atoms, GetTargets(), &requested_types);\n\n  ui::SelectionData data(format_map_.GetFirstOf(requested_types));\n  if (data.IsValid()) {\n    // TODO(erg): Technically, both of these forms can accept multiple URLs,\n    // but that doesn't match the assumptions of the rest of the system which\n    // expect single types.\n\n    if (data.GetType() == atom_cache_.GetAtom(kMimeTypeMozillaURL)) {\n      // Mozilla URLs are (UTF16: URL, newline, title).\n      base::string16 unparsed;\n      data.AssignTo(&unparsed);\n\n      std::vector<base::string16> tokens;\n      size_t num_tokens = Tokenize(unparsed, base::ASCIIToUTF16(\"\\n\"), &tokens);\n      if (num_tokens > 0) {\n        if (num_tokens > 1)\n          *title = tokens[1];\n        else\n          *title = base::string16();\n\n        *url = GURL(tokens[0]);\n        return true;\n      }\n    } else if (data.GetType() == atom_cache_.GetAtom(\n                   Clipboard::kMimeTypeURIList)) {\n      std::vector<std::string> tokens = ui::ParseURIList(data);\n      for (std::vector<std::string>::const_iterator it = tokens.begin();\n           it != tokens.end(); ++it) {\n        GURL test_url(*it);\n        if (!test_url.SchemeIsFile() ||\n            policy == OSExchangeData::CONVERT_FILENAMES) {\n          *url = test_url;\n          *title = base::string16();\n          return true;\n        }\n      }\n    }\n  }\n\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n bool OSExchangeDataProviderAuraX11::GetURLAndTitle(\n+    OSExchangeData::FilenameToURLPolicy policy,\n     GURL* url,\n     base::string16* title) const {\n   std::vector< ::Atom> url_atoms = ui::GetURLAtomsFrom(&atom_cache_);\n@@ -33,7 +34,8 @@\n       for (std::vector<std::string>::const_iterator it = tokens.begin();\n            it != tokens.end(); ++it) {\n         GURL test_url(*it);\n-        if (!test_url.SchemeIsFile()) {\n+        if (!test_url.SchemeIsFile() ||\n+            policy == OSExchangeData::CONVERT_FILENAMES) {\n           *url = test_url;\n           *title = base::string16();\n           return true;",
        "diff_line_info": {
            "deleted_lines": [
                "        if (!test_url.SchemeIsFile()) {"
            ],
            "added_lines": [
                "    OSExchangeData::FilenameToURLPolicy policy,",
                "        if (!test_url.SchemeIsFile() ||",
                "            policy == OSExchangeData::CONVERT_FILENAMES) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2013-6666",
        "func_name": "chromium/PepperFlashRendererHost::OnNavigate",
        "description": "The PepperFlashRendererHost::OnNavigate function in renderer/pepper/pepper_flash_renderer_host.cc in Google Chrome before 33.0.1750.146 does not verify that all headers are Cross-Origin Resource Sharing (CORS) simple headers before proceeding with a PPB_Flash.Navigate operation, which might allow remote attackers to bypass intended CORS restrictions via an inappropriate header.",
        "git_url": "https://github.com/chromium/chromium/commit/59296d9276ffcc8bced092828210748d2ed19ab0",
        "commit_title": "PPB_Flash.Navigate(): Disallow certain HTTP request headers.",
        "commit_text": " With this CL, PPB_Flash.Navigate() fails the operation with PP_ERROR_NOACCESS if the request headers contain non-simple headers.   ",
        "func_before": "int32_t PepperFlashRendererHost::OnNavigate(\n    ppapi::host::HostMessageContext* host_context,\n    const ppapi::URLRequestInfoData& data,\n    const std::string& target,\n    bool from_user_action) {\n  // If our PepperPluginInstance is already destroyed, just return a failure.\n  content::PepperPluginInstance* plugin_instance =\n      host_->GetPluginInstance(pp_instance());\n  if (!plugin_instance)\n    return PP_ERROR_FAILED;\n\n  // Navigate may call into Javascript (e.g. with a \"javascript:\" URL),\n  // or do things like navigate away from the page, either one of which will\n  // need to re-enter into the plugin. It is safe, because it is essentially\n  // equivalent to NPN_GetURL, where Flash would expect re-entrancy.\n  ppapi::proxy::HostDispatcher* host_dispatcher =\n      ppapi::proxy::HostDispatcher::GetForInstance(pp_instance());\n  host_dispatcher->set_allow_plugin_reentrancy();\n\n  // Grab a weak pointer to ourselves on the stack so we can check if we are\n  // still alive.\n  base::WeakPtr<PepperFlashRendererHost> weak_ptr = weak_factory_.GetWeakPtr();\n  // Keep track of reply contexts in case we are destroyed during a Navigate\n  // call. Even if we are destroyed, we still need to send these replies to\n  // unblock the plugin process.\n  navigate_replies_.push_back(host_context->MakeReplyMessageContext());\n  plugin_instance->Navigate(data, target.c_str(), from_user_action);\n  // This object might have been destroyed by this point. If it is destroyed\n  // the reply will be sent in the destructor. Otherwise send the reply here.\n  if (weak_ptr.get()) {\n    SendReply(navigate_replies_.back(), IPC::Message());\n    navigate_replies_.pop_back();\n  }\n\n  // Return PP_OK_COMPLETIONPENDING so that no reply is automatically sent.\n  return PP_OK_COMPLETIONPENDING;\n}",
        "func": "int32_t PepperFlashRendererHost::OnNavigate(\n    ppapi::host::HostMessageContext* host_context,\n    const ppapi::URLRequestInfoData& data,\n    const std::string& target,\n    bool from_user_action) {\n  // If our PepperPluginInstance is already destroyed, just return a failure.\n  content::PepperPluginInstance* plugin_instance =\n      host_->GetPluginInstance(pp_instance());\n  if (!plugin_instance)\n    return PP_ERROR_FAILED;\n\n  std::map<std::string, FlashNavigateUsage>& rejected_headers =\n      g_rejected_headers.Get();\n  if (rejected_headers.empty()) {\n    for (size_t i = 0; i < arraysize(kRejectedHttpRequestHeaders); ++i)\n      rejected_headers[kRejectedHttpRequestHeaders[i]] =\n          static_cast<FlashNavigateUsage>(i);\n  }\n\n  net::HttpUtil::HeadersIterator header_iter(data.headers.begin(),\n                                             data.headers.end(),\n                                             \"\\n\\r\");\n  bool rejected = false;\n  while (header_iter.GetNext()) {\n    std::string lower_case_header_name = StringToLowerASCII(header_iter.name());\n    if (!IsSimpleHeader(lower_case_header_name, header_iter.values())) {\n      rejected = true;\n\n      std::map<std::string, FlashNavigateUsage>::const_iterator iter =\n          rejected_headers.find(lower_case_header_name);\n      FlashNavigateUsage usage = iter != rejected_headers.end() ?\n          iter->second : REJECT_OTHER_HEADERS;\n      RecordFlashNavigateUsage(usage);\n    }\n  }\n\n  RecordFlashNavigateUsage(TOTAL_NAVIGATE_REQUESTS);\n  if (rejected) {\n    RecordFlashNavigateUsage(TOTAL_REJECTED_NAVIGATE_REQUESTS);\n    return PP_ERROR_NOACCESS;\n  }\n\n  // Navigate may call into Javascript (e.g. with a \"javascript:\" URL),\n  // or do things like navigate away from the page, either one of which will\n  // need to re-enter into the plugin. It is safe, because it is essentially\n  // equivalent to NPN_GetURL, where Flash would expect re-entrancy.\n  ppapi::proxy::HostDispatcher* host_dispatcher =\n      ppapi::proxy::HostDispatcher::GetForInstance(pp_instance());\n  host_dispatcher->set_allow_plugin_reentrancy();\n\n  // Grab a weak pointer to ourselves on the stack so we can check if we are\n  // still alive.\n  base::WeakPtr<PepperFlashRendererHost> weak_ptr = weak_factory_.GetWeakPtr();\n  // Keep track of reply contexts in case we are destroyed during a Navigate\n  // call. Even if we are destroyed, we still need to send these replies to\n  // unblock the plugin process.\n  navigate_replies_.push_back(host_context->MakeReplyMessageContext());\n  plugin_instance->Navigate(data, target.c_str(), from_user_action);\n  // This object might have been destroyed by this point. If it is destroyed\n  // the reply will be sent in the destructor. Otherwise send the reply here.\n  if (weak_ptr.get()) {\n    SendReply(navigate_replies_.back(), IPC::Message());\n    navigate_replies_.pop_back();\n  }\n\n  // Return PP_OK_COMPLETIONPENDING so that no reply is automatically sent.\n  return PP_OK_COMPLETIONPENDING;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,37 @@\n       host_->GetPluginInstance(pp_instance());\n   if (!plugin_instance)\n     return PP_ERROR_FAILED;\n+\n+  std::map<std::string, FlashNavigateUsage>& rejected_headers =\n+      g_rejected_headers.Get();\n+  if (rejected_headers.empty()) {\n+    for (size_t i = 0; i < arraysize(kRejectedHttpRequestHeaders); ++i)\n+      rejected_headers[kRejectedHttpRequestHeaders[i]] =\n+          static_cast<FlashNavigateUsage>(i);\n+  }\n+\n+  net::HttpUtil::HeadersIterator header_iter(data.headers.begin(),\n+                                             data.headers.end(),\n+                                             \"\\n\\r\");\n+  bool rejected = false;\n+  while (header_iter.GetNext()) {\n+    std::string lower_case_header_name = StringToLowerASCII(header_iter.name());\n+    if (!IsSimpleHeader(lower_case_header_name, header_iter.values())) {\n+      rejected = true;\n+\n+      std::map<std::string, FlashNavigateUsage>::const_iterator iter =\n+          rejected_headers.find(lower_case_header_name);\n+      FlashNavigateUsage usage = iter != rejected_headers.end() ?\n+          iter->second : REJECT_OTHER_HEADERS;\n+      RecordFlashNavigateUsage(usage);\n+    }\n+  }\n+\n+  RecordFlashNavigateUsage(TOTAL_NAVIGATE_REQUESTS);\n+  if (rejected) {\n+    RecordFlashNavigateUsage(TOTAL_REJECTED_NAVIGATE_REQUESTS);\n+    return PP_ERROR_NOACCESS;\n+  }\n \n   // Navigate may call into Javascript (e.g. with a \"javascript:\" URL),\n   // or do things like navigate away from the page, either one of which will",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  std::map<std::string, FlashNavigateUsage>& rejected_headers =",
                "      g_rejected_headers.Get();",
                "  if (rejected_headers.empty()) {",
                "    for (size_t i = 0; i < arraysize(kRejectedHttpRequestHeaders); ++i)",
                "      rejected_headers[kRejectedHttpRequestHeaders[i]] =",
                "          static_cast<FlashNavigateUsage>(i);",
                "  }",
                "",
                "  net::HttpUtil::HeadersIterator header_iter(data.headers.begin(),",
                "                                             data.headers.end(),",
                "                                             \"\\n\\r\");",
                "  bool rejected = false;",
                "  while (header_iter.GetNext()) {",
                "    std::string lower_case_header_name = StringToLowerASCII(header_iter.name());",
                "    if (!IsSimpleHeader(lower_case_header_name, header_iter.values())) {",
                "      rejected = true;",
                "",
                "      std::map<std::string, FlashNavigateUsage>::const_iterator iter =",
                "          rejected_headers.find(lower_case_header_name);",
                "      FlashNavigateUsage usage = iter != rejected_headers.end() ?",
                "          iter->second : REJECT_OTHER_HEADERS;",
                "      RecordFlashNavigateUsage(usage);",
                "    }",
                "  }",
                "",
                "  RecordFlashNavigateUsage(TOTAL_NAVIGATE_REQUESTS);",
                "  if (rejected) {",
                "    RecordFlashNavigateUsage(TOTAL_REJECTED_NAVIGATE_REQUESTS);",
                "    return PP_ERROR_NOACCESS;",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/dn_nl_newaddr",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int dn_nl_newaddr(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct net_device *dev;\n\tstruct dn_dev *dn_db;\n\tstruct ifaddrmsg *ifm;\n\tstruct dn_ifaddr *ifa;\n\tint err;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, dn_ifa_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[IFA_LOCAL] == NULL)\n\t\treturn -EINVAL;\n\n\tifm = nlmsg_data(nlh);\n\tif ((dev = __dev_get_by_index(&init_net, ifm->ifa_index)) == NULL)\n\t\treturn -ENODEV;\n\n\tif ((dn_db = rtnl_dereference(dev->dn_ptr)) == NULL) {\n\t\tdn_db = dn_dev_create(dev, &err);\n\t\tif (!dn_db)\n\t\t\treturn err;\n\t}\n\n\tif ((ifa = dn_dev_alloc_ifa()) == NULL)\n\t\treturn -ENOBUFS;\n\n\tif (tb[IFA_ADDRESS] == NULL)\n\t\ttb[IFA_ADDRESS] = tb[IFA_LOCAL];\n\n\tifa->ifa_local = nla_get_le16(tb[IFA_LOCAL]);\n\tifa->ifa_address = nla_get_le16(tb[IFA_ADDRESS]);\n\tifa->ifa_flags = tb[IFA_FLAGS] ? nla_get_u32(tb[IFA_FLAGS]) :\n\t\t\t\t\t ifm->ifa_flags;\n\tifa->ifa_scope = ifm->ifa_scope;\n\tifa->ifa_dev = dn_db;\n\n\tif (tb[IFA_LABEL])\n\t\tnla_strlcpy(ifa->ifa_label, tb[IFA_LABEL], IFNAMSIZ);\n\telse\n\t\tmemcpy(ifa->ifa_label, dev->name, IFNAMSIZ);\n\n\terr = dn_dev_insert_ifa(dn_db, ifa);\n\tif (err)\n\t\tdn_dev_free_ifa(ifa);\n\n\treturn err;\n}",
        "func": "static int dn_nl_newaddr(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct net_device *dev;\n\tstruct dn_dev *dn_db;\n\tstruct ifaddrmsg *ifm;\n\tstruct dn_ifaddr *ifa;\n\tint err;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, dn_ifa_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[IFA_LOCAL] == NULL)\n\t\treturn -EINVAL;\n\n\tifm = nlmsg_data(nlh);\n\tif ((dev = __dev_get_by_index(&init_net, ifm->ifa_index)) == NULL)\n\t\treturn -ENODEV;\n\n\tif ((dn_db = rtnl_dereference(dev->dn_ptr)) == NULL) {\n\t\tdn_db = dn_dev_create(dev, &err);\n\t\tif (!dn_db)\n\t\t\treturn err;\n\t}\n\n\tif ((ifa = dn_dev_alloc_ifa()) == NULL)\n\t\treturn -ENOBUFS;\n\n\tif (tb[IFA_ADDRESS] == NULL)\n\t\ttb[IFA_ADDRESS] = tb[IFA_LOCAL];\n\n\tifa->ifa_local = nla_get_le16(tb[IFA_LOCAL]);\n\tifa->ifa_address = nla_get_le16(tb[IFA_ADDRESS]);\n\tifa->ifa_flags = tb[IFA_FLAGS] ? nla_get_u32(tb[IFA_FLAGS]) :\n\t\t\t\t\t ifm->ifa_flags;\n\tifa->ifa_scope = ifm->ifa_scope;\n\tifa->ifa_dev = dn_db;\n\n\tif (tb[IFA_LABEL])\n\t\tnla_strlcpy(ifa->ifa_label, tb[IFA_LABEL], IFNAMSIZ);\n\telse\n\t\tmemcpy(ifa->ifa_label, dev->name, IFNAMSIZ);\n\n\terr = dn_dev_insert_ifa(dn_db, ifa);\n\tif (err)\n\t\tdn_dev_free_ifa(ifa);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \tstruct dn_ifaddr *ifa;\n \tint err;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (!net_eq(net, &init_net))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/dn_nl_deladdr",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int dn_nl_deladdr(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct dn_dev *dn_db;\n\tstruct ifaddrmsg *ifm;\n\tstruct dn_ifaddr *ifa;\n\tstruct dn_ifaddr __rcu **ifap;\n\tint err = -EINVAL;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\tgoto errout;\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, dn_ifa_policy);\n\tif (err < 0)\n\t\tgoto errout;\n\n\terr = -ENODEV;\n\tifm = nlmsg_data(nlh);\n\tif ((dn_db = dn_dev_by_index(ifm->ifa_index)) == NULL)\n\t\tgoto errout;\n\n\terr = -EADDRNOTAVAIL;\n\tfor (ifap = &dn_db->ifa_list;\n\t     (ifa = rtnl_dereference(*ifap)) != NULL;\n\t     ifap = &ifa->ifa_next) {\n\t\tif (tb[IFA_LOCAL] &&\n\t\t    nla_memcmp(tb[IFA_LOCAL], &ifa->ifa_local, 2))\n\t\t\tcontinue;\n\n\t\tif (tb[IFA_LABEL] && nla_strcmp(tb[IFA_LABEL], ifa->ifa_label))\n\t\t\tcontinue;\n\n\t\tdn_dev_del_ifa(dn_db, ifap, 1);\n\t\treturn 0;\n\t}\n\nerrout:\n\treturn err;\n}",
        "func": "static int dn_nl_deladdr(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct dn_dev *dn_db;\n\tstruct ifaddrmsg *ifm;\n\tstruct dn_ifaddr *ifa;\n\tstruct dn_ifaddr __rcu **ifap;\n\tint err = -EINVAL;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\tgoto errout;\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, dn_ifa_policy);\n\tif (err < 0)\n\t\tgoto errout;\n\n\terr = -ENODEV;\n\tifm = nlmsg_data(nlh);\n\tif ((dn_db = dn_dev_by_index(ifm->ifa_index)) == NULL)\n\t\tgoto errout;\n\n\terr = -EADDRNOTAVAIL;\n\tfor (ifap = &dn_db->ifa_list;\n\t     (ifa = rtnl_dereference(*ifap)) != NULL;\n\t     ifap = &ifa->ifa_next) {\n\t\tif (tb[IFA_LOCAL] &&\n\t\t    nla_memcmp(tb[IFA_LOCAL], &ifa->ifa_local, 2))\n\t\t\tcontinue;\n\n\t\tif (tb[IFA_LABEL] && nla_strcmp(tb[IFA_LABEL], ifa->ifa_label))\n\t\t\tcontinue;\n\n\t\tdn_dev_del_ifa(dn_db, ifap, 1);\n\t\treturn 0;\n\t}\n\nerrout:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \tstruct dn_ifaddr __rcu **ifap;\n \tint err = -EINVAL;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (!net_eq(net, &init_net))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/nfnetlink_rcv",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static void nfnetlink_rcv(struct sk_buff *skb)\n{\n\tstruct nlmsghdr *nlh = nlmsg_hdr(skb);\n\tstruct net *net = sock_net(skb->sk);\n\tint msglen;\n\n\tif (nlh->nlmsg_len < NLMSG_HDRLEN ||\n\t    skb->len < nlh->nlmsg_len)\n\t\treturn;\n\n\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN)) {\n\t\tnetlink_ack(skb, nlh, -EPERM);\n\t\treturn;\n\t}\n\n\tif (nlh->nlmsg_type == NFNL_MSG_BATCH_BEGIN) {\n\t\tstruct nfgenmsg *nfgenmsg;\n\n\t\tmsglen = NLMSG_ALIGN(nlh->nlmsg_len);\n\t\tif (msglen > skb->len)\n\t\t\tmsglen = skb->len;\n\n\t\tif (nlh->nlmsg_len < NLMSG_HDRLEN ||\n\t\t    skb->len < NLMSG_HDRLEN + sizeof(struct nfgenmsg))\n\t\t\treturn;\n\n\t\tnfgenmsg = nlmsg_data(nlh);\n\t\tskb_pull(skb, msglen);\n\t\tnfnetlink_rcv_batch(skb, nlh, nfgenmsg->res_id);\n\t} else {\n\t\tnetlink_rcv_skb(skb, &nfnetlink_rcv_msg);\n\t}\n}",
        "func": "static void nfnetlink_rcv(struct sk_buff *skb)\n{\n\tstruct nlmsghdr *nlh = nlmsg_hdr(skb);\n\tstruct net *net = sock_net(skb->sk);\n\tint msglen;\n\n\tif (nlh->nlmsg_len < NLMSG_HDRLEN ||\n\t    skb->len < nlh->nlmsg_len)\n\t\treturn;\n\n\tif (!netlink_net_capable(skb, CAP_NET_ADMIN)) {\n\t\tnetlink_ack(skb, nlh, -EPERM);\n\t\treturn;\n\t}\n\n\tif (nlh->nlmsg_type == NFNL_MSG_BATCH_BEGIN) {\n\t\tstruct nfgenmsg *nfgenmsg;\n\n\t\tmsglen = NLMSG_ALIGN(nlh->nlmsg_len);\n\t\tif (msglen > skb->len)\n\t\t\tmsglen = skb->len;\n\n\t\tif (nlh->nlmsg_len < NLMSG_HDRLEN ||\n\t\t    skb->len < NLMSG_HDRLEN + sizeof(struct nfgenmsg))\n\t\t\treturn;\n\n\t\tnfgenmsg = nlmsg_data(nlh);\n\t\tskb_pull(skb, msglen);\n\t\tnfnetlink_rcv_batch(skb, nlh, nfgenmsg->res_id);\n\t} else {\n\t\tnetlink_rcv_skb(skb, &nfnetlink_rcv_msg);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \t    skb->len < nlh->nlmsg_len)\n \t\treturn;\n \n-\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN)) {\n+\tif (!netlink_net_capable(skb, CAP_NET_ADMIN)) {\n \t\tnetlink_ack(skb, nlh, -EPERM);\n \t\treturn;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN)) {"
            ],
            "added_lines": [
                "\tif (!netlink_net_capable(skb, CAP_NET_ADMIN)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/dn_fib_rtm_newroute",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int dn_fib_rtm_newroute(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct dn_fib_table *tb;\n\tstruct rtmsg *r = nlmsg_data(nlh);\n\tstruct nlattr *attrs[RTA_MAX+1];\n\tint err;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*r), attrs, RTA_MAX, rtm_dn_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\ttb = dn_fib_get_table(rtm_get_table(attrs, r->rtm_table), 1);\n\tif (!tb)\n\t\treturn -ENOBUFS;\n\n\treturn tb->insert(tb, r, attrs, nlh, &NETLINK_CB(skb));\n}",
        "func": "static int dn_fib_rtm_newroute(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct dn_fib_table *tb;\n\tstruct rtmsg *r = nlmsg_data(nlh);\n\tstruct nlattr *attrs[RTA_MAX+1];\n\tint err;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*r), attrs, RTA_MAX, rtm_dn_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\ttb = dn_fib_get_table(rtm_get_table(attrs, r->rtm_table), 1);\n\tif (!tb)\n\t\treturn -ENOBUFS;\n\n\treturn tb->insert(tb, r, attrs, nlh, &NETLINK_CB(skb));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n \tstruct nlattr *attrs[RTA_MAX+1];\n \tint err;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (!net_eq(net, &init_net))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/dn_fib_rtm_delroute",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int dn_fib_rtm_delroute(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct dn_fib_table *tb;\n\tstruct rtmsg *r = nlmsg_data(nlh);\n\tstruct nlattr *attrs[RTA_MAX+1];\n\tint err;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*r), attrs, RTA_MAX, rtm_dn_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\ttb = dn_fib_get_table(rtm_get_table(attrs, r->rtm_table), 0);\n\tif (!tb)\n\t\treturn -ESRCH;\n\n\treturn tb->delete(tb, r, attrs, nlh, &NETLINK_CB(skb));\n}",
        "func": "static int dn_fib_rtm_delroute(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct dn_fib_table *tb;\n\tstruct rtmsg *r = nlmsg_data(nlh);\n\tstruct nlattr *attrs[RTA_MAX+1];\n\tint err;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!net_eq(net, &init_net))\n\t\treturn -EINVAL;\n\n\terr = nlmsg_parse(nlh, sizeof(*r), attrs, RTA_MAX, rtm_dn_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\ttb = dn_fib_get_table(rtm_get_table(attrs, r->rtm_table), 0);\n\tif (!tb)\n\t\treturn -ESRCH;\n\n\treturn tb->delete(tb, r, attrs, nlh, &NETLINK_CB(skb));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,7 @@\n \tstruct nlattr *attrs[RTA_MAX+1];\n \tint err;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (!net_eq(net, &init_net))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/tc_modify_qdisc",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int tc_modify_qdisc(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm;\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tu32 clid;\n\tstruct Qdisc *q, *p;\n\tint err;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\t/* Reinit, just in case something touches this. */\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\ttcm = nlmsg_data(n);\n\tclid = tcm->tcm_parent;\n\tq = p = NULL;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\n\tif (clid) {\n\t\tif (clid != TC_H_ROOT) {\n\t\t\tif (clid != TC_H_INGRESS) {\n\t\t\t\tp = qdisc_lookup(dev, TC_H_MAJ(clid));\n\t\t\t\tif (!p)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t\tq = qdisc_leaf(p, clid);\n\t\t\t} else if (dev_ingress_queue_create(dev)) {\n\t\t\t\tq = dev_ingress_queue(dev)->qdisc_sleeping;\n\t\t\t}\n\t\t} else {\n\t\t\tq = dev->qdisc;\n\t\t}\n\n\t\t/* It may be default qdisc, ignore it */\n\t\tif (q && q->handle == 0)\n\t\t\tq = NULL;\n\n\t\tif (!q || !tcm->tcm_handle || q->handle != tcm->tcm_handle) {\n\t\t\tif (tcm->tcm_handle) {\n\t\t\t\tif (q && !(n->nlmsg_flags & NLM_F_REPLACE))\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (TC_H_MIN(tcm->tcm_handle))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (q == p ||\n\t\t\t\t    (p && check_loop(q, p, 0)))\n\t\t\t\t\treturn -ELOOP;\n\t\t\t\tatomic_inc(&q->refcnt);\n\t\t\t\tgoto graft;\n\t\t\t} else {\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\n\t\t\t\t/* This magic test requires explanation.\n\t\t\t\t *\n\t\t\t\t *   We know, that some child q is already\n\t\t\t\t *   attached to this parent and have choice:\n\t\t\t\t *   either to change it or to create/graft new one.\n\t\t\t\t *\n\t\t\t\t *   1. We are allowed to create/graft only\n\t\t\t\t *   if CREATE and REPLACE flags are set.\n\t\t\t\t *\n\t\t\t\t *   2. If EXCL is set, requestor wanted to say,\n\t\t\t\t *   that qdisc tcm_handle is not expected\n\t\t\t\t *   to exist, so that we choose create/graft too.\n\t\t\t\t *\n\t\t\t\t *   3. The last case is when no flags are set.\n\t\t\t\t *   Alas, it is sort of hole in API, we\n\t\t\t\t *   cannot decide what to do unambiguously.\n\t\t\t\t *   For now we select create/graft, if\n\t\t\t\t *   user gave KIND, which does not match existing.\n\t\t\t\t */\n\t\t\t\tif ((n->nlmsg_flags & NLM_F_CREATE) &&\n\t\t\t\t    (n->nlmsg_flags & NLM_F_REPLACE) &&\n\t\t\t\t    ((n->nlmsg_flags & NLM_F_EXCL) ||\n\t\t\t\t     (tca[TCA_KIND] &&\n\t\t\t\t      nla_strcmp(tca[TCA_KIND], q->ops->id))))\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (!tcm->tcm_handle)\n\t\t\treturn -EINVAL;\n\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t}\n\n\t/* Change qdisc parameters */\n\tif (q == NULL)\n\t\treturn -ENOENT;\n\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\treturn -EEXIST;\n\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\treturn -EINVAL;\n\terr = qdisc_change(q, tca);\n\tif (err == 0)\n\t\tqdisc_notify(net, skb, n, clid, NULL, q);\n\treturn err;\n\ncreate_n_graft:\n\tif (!(n->nlmsg_flags & NLM_F_CREATE))\n\t\treturn -ENOENT;\n\tif (clid == TC_H_INGRESS) {\n\t\tif (dev_ingress_queue(dev))\n\t\t\tq = qdisc_create(dev, dev_ingress_queue(dev), p,\n\t\t\t\t\t tcm->tcm_parent, tcm->tcm_parent,\n\t\t\t\t\t tca, &err);\n\t\telse\n\t\t\terr = -ENOENT;\n\t} else {\n\t\tstruct netdev_queue *dev_queue;\n\n\t\tif (p && p->ops->cl_ops && p->ops->cl_ops->select_queue)\n\t\t\tdev_queue = p->ops->cl_ops->select_queue(p, tcm);\n\t\telse if (p)\n\t\t\tdev_queue = p->dev_queue;\n\t\telse\n\t\t\tdev_queue = netdev_get_tx_queue(dev, 0);\n\n\t\tq = qdisc_create(dev, dev_queue, p,\n\t\t\t\t tcm->tcm_parent, tcm->tcm_handle,\n\t\t\t\t tca, &err);\n\t}\n\tif (q == NULL) {\n\t\tif (err == -EAGAIN)\n\t\t\tgoto replay;\n\t\treturn err;\n\t}\n\ngraft:\n\terr = qdisc_graft(dev, p, skb, n, clid, q, NULL);\n\tif (err) {\n\t\tif (q)\n\t\t\tqdisc_destroy(q);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}",
        "func": "static int tc_modify_qdisc(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm;\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tu32 clid;\n\tstruct Qdisc *q, *p;\n\tint err;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\t/* Reinit, just in case something touches this. */\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\ttcm = nlmsg_data(n);\n\tclid = tcm->tcm_parent;\n\tq = p = NULL;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\n\tif (clid) {\n\t\tif (clid != TC_H_ROOT) {\n\t\t\tif (clid != TC_H_INGRESS) {\n\t\t\t\tp = qdisc_lookup(dev, TC_H_MAJ(clid));\n\t\t\t\tif (!p)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t\tq = qdisc_leaf(p, clid);\n\t\t\t} else if (dev_ingress_queue_create(dev)) {\n\t\t\t\tq = dev_ingress_queue(dev)->qdisc_sleeping;\n\t\t\t}\n\t\t} else {\n\t\t\tq = dev->qdisc;\n\t\t}\n\n\t\t/* It may be default qdisc, ignore it */\n\t\tif (q && q->handle == 0)\n\t\t\tq = NULL;\n\n\t\tif (!q || !tcm->tcm_handle || q->handle != tcm->tcm_handle) {\n\t\t\tif (tcm->tcm_handle) {\n\t\t\t\tif (q && !(n->nlmsg_flags & NLM_F_REPLACE))\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (TC_H_MIN(tcm->tcm_handle))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\t\treturn -EEXIST;\n\t\t\t\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\t\t\t\treturn -EINVAL;\n\t\t\t\tif (q == p ||\n\t\t\t\t    (p && check_loop(q, p, 0)))\n\t\t\t\t\treturn -ELOOP;\n\t\t\t\tatomic_inc(&q->refcnt);\n\t\t\t\tgoto graft;\n\t\t\t} else {\n\t\t\t\tif (!q)\n\t\t\t\t\tgoto create_n_graft;\n\n\t\t\t\t/* This magic test requires explanation.\n\t\t\t\t *\n\t\t\t\t *   We know, that some child q is already\n\t\t\t\t *   attached to this parent and have choice:\n\t\t\t\t *   either to change it or to create/graft new one.\n\t\t\t\t *\n\t\t\t\t *   1. We are allowed to create/graft only\n\t\t\t\t *   if CREATE and REPLACE flags are set.\n\t\t\t\t *\n\t\t\t\t *   2. If EXCL is set, requestor wanted to say,\n\t\t\t\t *   that qdisc tcm_handle is not expected\n\t\t\t\t *   to exist, so that we choose create/graft too.\n\t\t\t\t *\n\t\t\t\t *   3. The last case is when no flags are set.\n\t\t\t\t *   Alas, it is sort of hole in API, we\n\t\t\t\t *   cannot decide what to do unambiguously.\n\t\t\t\t *   For now we select create/graft, if\n\t\t\t\t *   user gave KIND, which does not match existing.\n\t\t\t\t */\n\t\t\t\tif ((n->nlmsg_flags & NLM_F_CREATE) &&\n\t\t\t\t    (n->nlmsg_flags & NLM_F_REPLACE) &&\n\t\t\t\t    ((n->nlmsg_flags & NLM_F_EXCL) ||\n\t\t\t\t     (tca[TCA_KIND] &&\n\t\t\t\t      nla_strcmp(tca[TCA_KIND], q->ops->id))))\n\t\t\t\t\tgoto create_n_graft;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (!tcm->tcm_handle)\n\t\t\treturn -EINVAL;\n\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t}\n\n\t/* Change qdisc parameters */\n\tif (q == NULL)\n\t\treturn -ENOENT;\n\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\treturn -EEXIST;\n\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\treturn -EINVAL;\n\terr = qdisc_change(q, tca);\n\tif (err == 0)\n\t\tqdisc_notify(net, skb, n, clid, NULL, q);\n\treturn err;\n\ncreate_n_graft:\n\tif (!(n->nlmsg_flags & NLM_F_CREATE))\n\t\treturn -ENOENT;\n\tif (clid == TC_H_INGRESS) {\n\t\tif (dev_ingress_queue(dev))\n\t\t\tq = qdisc_create(dev, dev_ingress_queue(dev), p,\n\t\t\t\t\t tcm->tcm_parent, tcm->tcm_parent,\n\t\t\t\t\t tca, &err);\n\t\telse\n\t\t\terr = -ENOENT;\n\t} else {\n\t\tstruct netdev_queue *dev_queue;\n\n\t\tif (p && p->ops->cl_ops && p->ops->cl_ops->select_queue)\n\t\t\tdev_queue = p->ops->cl_ops->select_queue(p, tcm);\n\t\telse if (p)\n\t\t\tdev_queue = p->dev_queue;\n\t\telse\n\t\t\tdev_queue = netdev_get_tx_queue(dev, 0);\n\n\t\tq = qdisc_create(dev, dev_queue, p,\n\t\t\t\t tcm->tcm_parent, tcm->tcm_handle,\n\t\t\t\t tca, &err);\n\t}\n\tif (q == NULL) {\n\t\tif (err == -EAGAIN)\n\t\t\tgoto replay;\n\t\treturn err;\n\t}\n\ngraft:\n\terr = qdisc_graft(dev, p, skb, n, clid, q, NULL);\n\tif (err) {\n\t\tif (q)\n\t\t\tqdisc_destroy(q);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \tstruct Qdisc *q, *p;\n \tint err;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n replay:",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/tc_get_qdisc",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int tc_get_qdisc(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm = nlmsg_data(n);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tu32 clid;\n\tstruct Qdisc *q = NULL;\n\tstruct Qdisc *p = NULL;\n\tint err;\n\n\tif ((n->nlmsg_type != RTM_GETQDISC) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tclid = tcm->tcm_parent;\n\tif (clid) {\n\t\tif (clid != TC_H_ROOT) {\n\t\t\tif (TC_H_MAJ(clid) != TC_H_MAJ(TC_H_INGRESS)) {\n\t\t\t\tp = qdisc_lookup(dev, TC_H_MAJ(clid));\n\t\t\t\tif (!p)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t\tq = qdisc_leaf(p, clid);\n\t\t\t} else if (dev_ingress_queue(dev)) {\n\t\t\t\tq = dev_ingress_queue(dev)->qdisc_sleeping;\n\t\t\t}\n\t\t} else {\n\t\t\tq = dev->qdisc;\n\t\t}\n\t\tif (!q)\n\t\t\treturn -ENOENT;\n\n\t\tif (tcm->tcm_handle && q->handle != tcm->tcm_handle)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t\tif (!q)\n\t\t\treturn -ENOENT;\n\t}\n\n\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\treturn -EINVAL;\n\n\tif (n->nlmsg_type == RTM_DELQDISC) {\n\t\tif (!clid)\n\t\t\treturn -EINVAL;\n\t\tif (q->handle == 0)\n\t\t\treturn -ENOENT;\n\t\terr = qdisc_graft(dev, p, skb, n, clid, NULL, q);\n\t\tif (err != 0)\n\t\t\treturn err;\n\t} else {\n\t\tqdisc_notify(net, skb, n, clid, NULL, q);\n\t}\n\treturn 0;\n}",
        "func": "static int tc_get_qdisc(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm = nlmsg_data(n);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tu32 clid;\n\tstruct Qdisc *q = NULL;\n\tstruct Qdisc *p = NULL;\n\tint err;\n\n\tif ((n->nlmsg_type != RTM_GETQDISC) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\tclid = tcm->tcm_parent;\n\tif (clid) {\n\t\tif (clid != TC_H_ROOT) {\n\t\t\tif (TC_H_MAJ(clid) != TC_H_MAJ(TC_H_INGRESS)) {\n\t\t\t\tp = qdisc_lookup(dev, TC_H_MAJ(clid));\n\t\t\t\tif (!p)\n\t\t\t\t\treturn -ENOENT;\n\t\t\t\tq = qdisc_leaf(p, clid);\n\t\t\t} else if (dev_ingress_queue(dev)) {\n\t\t\t\tq = dev_ingress_queue(dev)->qdisc_sleeping;\n\t\t\t}\n\t\t} else {\n\t\t\tq = dev->qdisc;\n\t\t}\n\t\tif (!q)\n\t\t\treturn -ENOENT;\n\n\t\tif (tcm->tcm_handle && q->handle != tcm->tcm_handle)\n\t\t\treturn -EINVAL;\n\t} else {\n\t\tq = qdisc_lookup(dev, tcm->tcm_handle);\n\t\tif (!q)\n\t\t\treturn -ENOENT;\n\t}\n\n\tif (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], q->ops->id))\n\t\treturn -EINVAL;\n\n\tif (n->nlmsg_type == RTM_DELQDISC) {\n\t\tif (!clid)\n\t\t\treturn -EINVAL;\n\t\tif (q->handle == 0)\n\t\t\treturn -ENOENT;\n\t\terr = qdisc_graft(dev, p, skb, n, clid, NULL, q);\n\t\tif (err != 0)\n\t\t\treturn err;\n\t} else {\n\t\tqdisc_notify(net, skb, n, clid, NULL, q);\n\t}\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n \tstruct Qdisc *p = NULL;\n \tint err;\n \n-\tif ((n->nlmsg_type != RTM_GETQDISC) && !capable(CAP_NET_ADMIN))\n+\tif ((n->nlmsg_type != RTM_GETQDISC) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((n->nlmsg_type != RTM_GETQDISC) && !capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif ((n->nlmsg_type != RTM_GETQDISC) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/tc_ctl_tclass",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int tc_ctl_tclass(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm = nlmsg_data(n);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tstruct Qdisc *q = NULL;\n\tconst struct Qdisc_class_ops *cops;\n\tunsigned long cl = 0;\n\tunsigned long new_cl;\n\tu32 portid;\n\tu32 clid;\n\tu32 qid;\n\tint err;\n\n\tif ((n->nlmsg_type != RTM_GETTCLASS) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\t/*\n\t   parent == TC_H_UNSPEC - unspecified parent.\n\t   parent == TC_H_ROOT   - class is root, which has no parent.\n\t   parent == X:0\t - parent is root class.\n\t   parent == X:Y\t - parent is a node in hierarchy.\n\t   parent == 0:Y\t - parent is X:Y, where X:0 is qdisc.\n\n\t   handle == 0:0\t - generate handle from kernel pool.\n\t   handle == 0:Y\t - class is X:Y, where X:0 is qdisc.\n\t   handle == X:Y\t - clear.\n\t   handle == X:0\t - root class.\n\t */\n\n\t/* Step 1. Determine qdisc handle X:0 */\n\n\tportid = tcm->tcm_parent;\n\tclid = tcm->tcm_handle;\n\tqid = TC_H_MAJ(clid);\n\n\tif (portid != TC_H_ROOT) {\n\t\tu32 qid1 = TC_H_MAJ(portid);\n\n\t\tif (qid && qid1) {\n\t\t\t/* If both majors are known, they must be identical. */\n\t\t\tif (qid != qid1)\n\t\t\t\treturn -EINVAL;\n\t\t} else if (qid1) {\n\t\t\tqid = qid1;\n\t\t} else if (qid == 0)\n\t\t\tqid = dev->qdisc->handle;\n\n\t\t/* Now qid is genuine qdisc handle consistent\n\t\t * both with parent and child.\n\t\t *\n\t\t * TC_H_MAJ(portid) still may be unspecified, complete it now.\n\t\t */\n\t\tif (portid)\n\t\t\tportid = TC_H_MAKE(qid, portid);\n\t} else {\n\t\tif (qid == 0)\n\t\t\tqid = dev->qdisc->handle;\n\t}\n\n\t/* OK. Locate qdisc */\n\tq = qdisc_lookup(dev, qid);\n\tif (!q)\n\t\treturn -ENOENT;\n\n\t/* An check that it supports classes */\n\tcops = q->ops->cl_ops;\n\tif (cops == NULL)\n\t\treturn -EINVAL;\n\n\t/* Now try to get class */\n\tif (clid == 0) {\n\t\tif (portid == TC_H_ROOT)\n\t\t\tclid = qid;\n\t} else\n\t\tclid = TC_H_MAKE(qid, clid);\n\n\tif (clid)\n\t\tcl = cops->get(q, clid);\n\n\tif (cl == 0) {\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTCLASS ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto out;\n\t} else {\n\t\tswitch (n->nlmsg_type) {\n\t\tcase RTM_NEWTCLASS:\n\t\t\terr = -EEXIST;\n\t\t\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\tcase RTM_DELTCLASS:\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tif (cops->delete)\n\t\t\t\terr = cops->delete(q, cl);\n\t\t\tif (err == 0)\n\t\t\t\ttclass_notify(net, skb, n, q, cl, RTM_DELTCLASS);\n\t\t\tgoto out;\n\t\tcase RTM_GETTCLASS:\n\t\t\terr = tclass_notify(net, skb, n, q, cl, RTM_NEWTCLASS);\n\t\t\tgoto out;\n\t\tdefault:\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tnew_cl = cl;\n\terr = -EOPNOTSUPP;\n\tif (cops->change)\n\t\terr = cops->change(q, clid, portid, tca, &new_cl);\n\tif (err == 0)\n\t\ttclass_notify(net, skb, n, q, new_cl, RTM_NEWTCLASS);\n\nout:\n\tif (cl)\n\t\tcops->put(q, cl);\n\n\treturn err;\n}",
        "func": "static int tc_ctl_tclass(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct tcmsg *tcm = nlmsg_data(n);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tstruct net_device *dev;\n\tstruct Qdisc *q = NULL;\n\tconst struct Qdisc_class_ops *cops;\n\tunsigned long cl = 0;\n\tunsigned long new_cl;\n\tu32 portid;\n\tu32 clid;\n\tu32 qid;\n\tint err;\n\n\tif ((n->nlmsg_type != RTM_GETTCLASS) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tdev = __dev_get_by_index(net, tcm->tcm_ifindex);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\t/*\n\t   parent == TC_H_UNSPEC - unspecified parent.\n\t   parent == TC_H_ROOT   - class is root, which has no parent.\n\t   parent == X:0\t - parent is root class.\n\t   parent == X:Y\t - parent is a node in hierarchy.\n\t   parent == 0:Y\t - parent is X:Y, where X:0 is qdisc.\n\n\t   handle == 0:0\t - generate handle from kernel pool.\n\t   handle == 0:Y\t - class is X:Y, where X:0 is qdisc.\n\t   handle == X:Y\t - clear.\n\t   handle == X:0\t - root class.\n\t */\n\n\t/* Step 1. Determine qdisc handle X:0 */\n\n\tportid = tcm->tcm_parent;\n\tclid = tcm->tcm_handle;\n\tqid = TC_H_MAJ(clid);\n\n\tif (portid != TC_H_ROOT) {\n\t\tu32 qid1 = TC_H_MAJ(portid);\n\n\t\tif (qid && qid1) {\n\t\t\t/* If both majors are known, they must be identical. */\n\t\t\tif (qid != qid1)\n\t\t\t\treturn -EINVAL;\n\t\t} else if (qid1) {\n\t\t\tqid = qid1;\n\t\t} else if (qid == 0)\n\t\t\tqid = dev->qdisc->handle;\n\n\t\t/* Now qid is genuine qdisc handle consistent\n\t\t * both with parent and child.\n\t\t *\n\t\t * TC_H_MAJ(portid) still may be unspecified, complete it now.\n\t\t */\n\t\tif (portid)\n\t\t\tportid = TC_H_MAKE(qid, portid);\n\t} else {\n\t\tif (qid == 0)\n\t\t\tqid = dev->qdisc->handle;\n\t}\n\n\t/* OK. Locate qdisc */\n\tq = qdisc_lookup(dev, qid);\n\tif (!q)\n\t\treturn -ENOENT;\n\n\t/* An check that it supports classes */\n\tcops = q->ops->cl_ops;\n\tif (cops == NULL)\n\t\treturn -EINVAL;\n\n\t/* Now try to get class */\n\tif (clid == 0) {\n\t\tif (portid == TC_H_ROOT)\n\t\t\tclid = qid;\n\t} else\n\t\tclid = TC_H_MAKE(qid, clid);\n\n\tif (clid)\n\t\tcl = cops->get(q, clid);\n\n\tif (cl == 0) {\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTCLASS ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto out;\n\t} else {\n\t\tswitch (n->nlmsg_type) {\n\t\tcase RTM_NEWTCLASS:\n\t\t\terr = -EEXIST;\n\t\t\tif (n->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\tgoto out;\n\t\t\tbreak;\n\t\tcase RTM_DELTCLASS:\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tif (cops->delete)\n\t\t\t\terr = cops->delete(q, cl);\n\t\t\tif (err == 0)\n\t\t\t\ttclass_notify(net, skb, n, q, cl, RTM_DELTCLASS);\n\t\t\tgoto out;\n\t\tcase RTM_GETTCLASS:\n\t\t\terr = tclass_notify(net, skb, n, q, cl, RTM_NEWTCLASS);\n\t\t\tgoto out;\n\t\tdefault:\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tnew_cl = cl;\n\terr = -EOPNOTSUPP;\n\tif (cops->change)\n\t\terr = cops->change(q, clid, portid, tca, &new_cl);\n\tif (err == 0)\n\t\ttclass_notify(net, skb, n, q, new_cl, RTM_NEWTCLASS);\n\nout:\n\tif (cl)\n\t\tcops->put(q, cl);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \tu32 qid;\n \tint err;\n \n-\tif ((n->nlmsg_type != RTM_GETTCLASS) && !capable(CAP_NET_ADMIN))\n+\tif ((n->nlmsg_type != RTM_GETTCLASS) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \terr = nlmsg_parse(n, sizeof(*tcm), tca, TCA_MAX, NULL);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((n->nlmsg_type != RTM_GETTCLASS) && !capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif ((n->nlmsg_type != RTM_GETTCLASS) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/packet_diag_dump",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int packet_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tint num = 0, s_num = cb->args[0];\n\tstruct packet_diag_req *req;\n\tstruct net *net;\n\tstruct sock *sk;\n\tbool may_report_filterinfo;\n\n\tnet = sock_net(skb->sk);\n\treq = nlmsg_data(cb->nlh);\n\tmay_report_filterinfo = ns_capable(net->user_ns, CAP_NET_ADMIN);\n\n\tmutex_lock(&net->packet.sklist_lock);\n\tsk_for_each(sk, &net->packet.sklist) {\n\t\tif (!net_eq(sock_net(sk), net))\n\t\t\tcontinue;\n\t\tif (num < s_num)\n\t\t\tgoto next;\n\n\t\tif (sk_diag_fill(sk, skb, req,\n\t\t\t\t may_report_filterinfo,\n\t\t\t\t sk_user_ns(NETLINK_CB(cb->skb).sk),\n\t\t\t\t NETLINK_CB(cb->skb).portid,\n\t\t\t\t cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t\t sock_i_ino(sk)) < 0)\n\t\t\tgoto done;\nnext:\n\t\tnum++;\n\t}\ndone:\n\tmutex_unlock(&net->packet.sklist_lock);\n\tcb->args[0] = num;\n\n\treturn skb->len;\n}",
        "func": "static int packet_diag_dump(struct sk_buff *skb, struct netlink_callback *cb)\n{\n\tint num = 0, s_num = cb->args[0];\n\tstruct packet_diag_req *req;\n\tstruct net *net;\n\tstruct sock *sk;\n\tbool may_report_filterinfo;\n\n\tnet = sock_net(skb->sk);\n\treq = nlmsg_data(cb->nlh);\n\tmay_report_filterinfo = netlink_net_capable(cb->skb, CAP_NET_ADMIN);\n\n\tmutex_lock(&net->packet.sklist_lock);\n\tsk_for_each(sk, &net->packet.sklist) {\n\t\tif (!net_eq(sock_net(sk), net))\n\t\t\tcontinue;\n\t\tif (num < s_num)\n\t\t\tgoto next;\n\n\t\tif (sk_diag_fill(sk, skb, req,\n\t\t\t\t may_report_filterinfo,\n\t\t\t\t sk_user_ns(NETLINK_CB(cb->skb).sk),\n\t\t\t\t NETLINK_CB(cb->skb).portid,\n\t\t\t\t cb->nlh->nlmsg_seq, NLM_F_MULTI,\n\t\t\t\t sock_i_ino(sk)) < 0)\n\t\t\tgoto done;\nnext:\n\t\tnum++;\n\t}\ndone:\n\tmutex_unlock(&net->packet.sklist_lock);\n\tcb->args[0] = num;\n\n\treturn skb->len;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \n \tnet = sock_net(skb->sk);\n \treq = nlmsg_data(cb->nlh);\n-\tmay_report_filterinfo = ns_capable(net->user_ns, CAP_NET_ADMIN);\n+\tmay_report_filterinfo = netlink_net_capable(cb->skb, CAP_NET_ADMIN);\n \n \tmutex_lock(&net->packet.sklist_lock);\n \tsk_for_each(sk, &net->packet.sklist) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tmay_report_filterinfo = ns_capable(net->user_ns, CAP_NET_ADMIN);"
            ],
            "added_lines": [
                "\tmay_report_filterinfo = netlink_net_capable(cb->skb, CAP_NET_ADMIN);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/dnrmg_receive_user_skb",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static inline void dnrmg_receive_user_skb(struct sk_buff *skb)\n{\n\tstruct nlmsghdr *nlh = nlmsg_hdr(skb);\n\n\tif (nlh->nlmsg_len < sizeof(*nlh) || skb->len < nlh->nlmsg_len)\n\t\treturn;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\tRCV_SKB_FAIL(-EPERM);\n\n\t/* Eventually we might send routing messages too */\n\n\tRCV_SKB_FAIL(-EINVAL);\n}",
        "func": "static inline void dnrmg_receive_user_skb(struct sk_buff *skb)\n{\n\tstruct nlmsghdr *nlh = nlmsg_hdr(skb);\n\n\tif (nlh->nlmsg_len < sizeof(*nlh) || skb->len < nlh->nlmsg_len)\n\t\treturn;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\tRCV_SKB_FAIL(-EPERM);\n\n\t/* Eventually we might send routing messages too */\n\n\tRCV_SKB_FAIL(-EINVAL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n \tif (nlh->nlmsg_len < sizeof(*nlh) || skb->len < nlh->nlmsg_len)\n \t\treturn;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\tRCV_SKB_FAIL(-EPERM);\n \n \t/* Eventually we might send routing messages too */",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/audit_netlink_ok",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int audit_netlink_ok(struct sk_buff *skb, u16 msg_type)\n{\n\tint err = 0;\n\n\t/* Only support initial user namespace for now. */\n\t/*\n\t * We return ECONNREFUSED because it tricks userspace into thinking\n\t * that audit was not configured into the kernel.  Lots of users\n\t * configure their PAM stack (because that's what the distro does)\n\t * to reject login if unable to send messages to audit.  If we return\n\t * ECONNREFUSED the PAM stack thinks the kernel does not have audit\n\t * configured in and will let login proceed.  If we return EPERM\n\t * userspace will reject all logins.  This should be removed when we\n\t * support non init namespaces!!\n\t */\n\tif (current_user_ns() != &init_user_ns)\n\t\treturn -ECONNREFUSED;\n\n\tswitch (msg_type) {\n\tcase AUDIT_LIST:\n\tcase AUDIT_ADD:\n\tcase AUDIT_DEL:\n\t\treturn -EOPNOTSUPP;\n\tcase AUDIT_GET:\n\tcase AUDIT_SET:\n\tcase AUDIT_GET_FEATURE:\n\tcase AUDIT_SET_FEATURE:\n\tcase AUDIT_LIST_RULES:\n\tcase AUDIT_ADD_RULE:\n\tcase AUDIT_DEL_RULE:\n\tcase AUDIT_SIGNAL_INFO:\n\tcase AUDIT_TTY_GET:\n\tcase AUDIT_TTY_SET:\n\tcase AUDIT_TRIM:\n\tcase AUDIT_MAKE_EQUIV:\n\t\t/* Only support auditd and auditctl in initial pid namespace\n\t\t * for now. */\n\t\tif ((task_active_pid_ns(current) != &init_pid_ns))\n\t\t\treturn -EPERM;\n\n\t\tif (!capable(CAP_AUDIT_CONTROL))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tcase AUDIT_USER:\n\tcase AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:\n\tcase AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:\n\t\tif (!capable(CAP_AUDIT_WRITE))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tdefault:  /* bad msg */\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}",
        "func": "static int audit_netlink_ok(struct sk_buff *skb, u16 msg_type)\n{\n\tint err = 0;\n\n\t/* Only support initial user namespace for now. */\n\t/*\n\t * We return ECONNREFUSED because it tricks userspace into thinking\n\t * that audit was not configured into the kernel.  Lots of users\n\t * configure their PAM stack (because that's what the distro does)\n\t * to reject login if unable to send messages to audit.  If we return\n\t * ECONNREFUSED the PAM stack thinks the kernel does not have audit\n\t * configured in and will let login proceed.  If we return EPERM\n\t * userspace will reject all logins.  This should be removed when we\n\t * support non init namespaces!!\n\t */\n\tif (current_user_ns() != &init_user_ns)\n\t\treturn -ECONNREFUSED;\n\n\tswitch (msg_type) {\n\tcase AUDIT_LIST:\n\tcase AUDIT_ADD:\n\tcase AUDIT_DEL:\n\t\treturn -EOPNOTSUPP;\n\tcase AUDIT_GET:\n\tcase AUDIT_SET:\n\tcase AUDIT_GET_FEATURE:\n\tcase AUDIT_SET_FEATURE:\n\tcase AUDIT_LIST_RULES:\n\tcase AUDIT_ADD_RULE:\n\tcase AUDIT_DEL_RULE:\n\tcase AUDIT_SIGNAL_INFO:\n\tcase AUDIT_TTY_GET:\n\tcase AUDIT_TTY_SET:\n\tcase AUDIT_TRIM:\n\tcase AUDIT_MAKE_EQUIV:\n\t\t/* Only support auditd and auditctl in initial pid namespace\n\t\t * for now. */\n\t\tif ((task_active_pid_ns(current) != &init_pid_ns))\n\t\t\treturn -EPERM;\n\n\t\tif (!netlink_capable(skb, CAP_AUDIT_CONTROL))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tcase AUDIT_USER:\n\tcase AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:\n\tcase AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:\n\t\tif (!netlink_capable(skb, CAP_AUDIT_WRITE))\n\t\t\terr = -EPERM;\n\t\tbreak;\n\tdefault:  /* bad msg */\n\t\terr = -EINVAL;\n\t}\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,13 +38,13 @@\n \t\tif ((task_active_pid_ns(current) != &init_pid_ns))\n \t\t\treturn -EPERM;\n \n-\t\tif (!capable(CAP_AUDIT_CONTROL))\n+\t\tif (!netlink_capable(skb, CAP_AUDIT_CONTROL))\n \t\t\terr = -EPERM;\n \t\tbreak;\n \tcase AUDIT_USER:\n \tcase AUDIT_FIRST_USER_MSG ... AUDIT_LAST_USER_MSG:\n \tcase AUDIT_FIRST_USER_MSG2 ... AUDIT_LAST_USER_MSG2:\n-\t\tif (!capable(CAP_AUDIT_WRITE))\n+\t\tif (!netlink_capable(skb, CAP_AUDIT_WRITE))\n \t\t\terr = -EPERM;\n \t\tbreak;\n \tdefault:  /* bad msg */",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (!capable(CAP_AUDIT_CONTROL))",
                "\t\tif (!capable(CAP_AUDIT_WRITE))"
            ],
            "added_lines": [
                "\t\tif (!netlink_capable(skb, CAP_AUDIT_CONTROL))",
                "\t\tif (!netlink_capable(skb, CAP_AUDIT_WRITE))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/dcb_doit",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int dcb_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct net_device *netdev;\n\tstruct dcbmsg *dcb = nlmsg_data(nlh);\n\tstruct nlattr *tb[DCB_ATTR_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = -EINVAL;\n\tstruct sk_buff *reply_skb;\n\tstruct nlmsghdr *reply_nlh = NULL;\n\tconst struct reply_func *fn;\n\n\tif ((nlh->nlmsg_type == RTM_SETDCB) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(nlh, sizeof(*dcb), tb, DCB_ATTR_MAX,\n\t\t\t  dcbnl_rtnl_policy);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (dcb->cmd > DCB_CMD_MAX)\n\t\treturn -EINVAL;\n\n\t/* check if a reply function has been defined for the command */\n\tfn = &reply_funcs[dcb->cmd];\n\tif (!fn->cb)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!tb[DCB_ATTR_IFNAME])\n\t\treturn -EINVAL;\n\n\tnetdev = __dev_get_by_name(net, nla_data(tb[DCB_ATTR_IFNAME]));\n\tif (!netdev)\n\t\treturn -ENODEV;\n\n\tif (!netdev->dcbnl_ops)\n\t\treturn -EOPNOTSUPP;\n\n\treply_skb = dcbnl_newmsg(fn->type, dcb->cmd, portid, nlh->nlmsg_seq,\n\t\t\t\t nlh->nlmsg_flags, &reply_nlh);\n\tif (!reply_skb)\n\t\treturn -ENOBUFS;\n\n\tret = fn->cb(netdev, nlh, nlh->nlmsg_seq, tb, reply_skb);\n\tif (ret < 0) {\n\t\tnlmsg_free(reply_skb);\n\t\tgoto out;\n\t}\n\n\tnlmsg_end(reply_skb, reply_nlh);\n\n\tret = rtnl_unicast(reply_skb, net, portid);\nout:\n\treturn ret;\n}",
        "func": "static int dcb_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct net_device *netdev;\n\tstruct dcbmsg *dcb = nlmsg_data(nlh);\n\tstruct nlattr *tb[DCB_ATTR_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = -EINVAL;\n\tstruct sk_buff *reply_skb;\n\tstruct nlmsghdr *reply_nlh = NULL;\n\tconst struct reply_func *fn;\n\n\tif ((nlh->nlmsg_type == RTM_SETDCB) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(nlh, sizeof(*dcb), tb, DCB_ATTR_MAX,\n\t\t\t  dcbnl_rtnl_policy);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (dcb->cmd > DCB_CMD_MAX)\n\t\treturn -EINVAL;\n\n\t/* check if a reply function has been defined for the command */\n\tfn = &reply_funcs[dcb->cmd];\n\tif (!fn->cb)\n\t\treturn -EOPNOTSUPP;\n\n\tif (!tb[DCB_ATTR_IFNAME])\n\t\treturn -EINVAL;\n\n\tnetdev = __dev_get_by_name(net, nla_data(tb[DCB_ATTR_IFNAME]));\n\tif (!netdev)\n\t\treturn -ENODEV;\n\n\tif (!netdev->dcbnl_ops)\n\t\treturn -EOPNOTSUPP;\n\n\treply_skb = dcbnl_newmsg(fn->type, dcb->cmd, portid, nlh->nlmsg_seq,\n\t\t\t\t nlh->nlmsg_flags, &reply_nlh);\n\tif (!reply_skb)\n\t\treturn -ENOBUFS;\n\n\tret = fn->cb(netdev, nlh, nlh->nlmsg_seq, tb, reply_skb);\n\tif (ret < 0) {\n\t\tnlmsg_free(reply_skb);\n\t\tgoto out;\n\t}\n\n\tnlmsg_end(reply_skb, reply_nlh);\n\n\tret = rtnl_unicast(reply_skb, net, portid);\nout:\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n \tstruct nlmsghdr *reply_nlh = NULL;\n \tconst struct reply_func *fn;\n \n-\tif ((nlh->nlmsg_type == RTM_SETDCB) && !capable(CAP_NET_ADMIN))\n+\tif ((nlh->nlmsg_type == RTM_SETDCB) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tret = nlmsg_parse(nlh, sizeof(*dcb), tb, DCB_ATTR_MAX,",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((nlh->nlmsg_type == RTM_SETDCB) && !capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif ((nlh->nlmsg_type == RTM_SETDCB) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/tc_ctl_action",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int tc_ctl_action(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_ACT_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = 0, ovr = 0;\n\n\tif ((n->nlmsg_type != RTM_GETACTION) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(n, sizeof(struct tcamsg), tca, TCA_ACT_MAX, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (tca[TCA_ACT_TAB] == NULL) {\n\t\tpr_notice(\"tc_ctl_action: received NO action attribs\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* n->nlmsg_flags & NLM_F_CREATE */\n\tswitch (n->nlmsg_type) {\n\tcase RTM_NEWACTION:\n\t\t/* we are going to assume all other flags\n\t\t * imply create only if it doesn't exist\n\t\t * Note that CREATE | EXCL implies that\n\t\t * but since we want avoid ambiguity (eg when flags\n\t\t * is zero) then just set this\n\t\t */\n\t\tif (n->nlmsg_flags & NLM_F_REPLACE)\n\t\t\tovr = 1;\nreplay:\n\t\tret = tcf_action_add(net, tca[TCA_ACT_TAB], n, portid, ovr);\n\t\tif (ret == -EAGAIN)\n\t\t\tgoto replay;\n\t\tbreak;\n\tcase RTM_DELACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_DELACTION);\n\t\tbreak;\n\tcase RTM_GETACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_GETACTION);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn ret;\n}",
        "func": "static int tc_ctl_action(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_ACT_MAX + 1];\n\tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n\tint ret = 0, ovr = 0;\n\n\tif ((n->nlmsg_type != RTM_GETACTION) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tret = nlmsg_parse(n, sizeof(struct tcamsg), tca, TCA_ACT_MAX, NULL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (tca[TCA_ACT_TAB] == NULL) {\n\t\tpr_notice(\"tc_ctl_action: received NO action attribs\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* n->nlmsg_flags & NLM_F_CREATE */\n\tswitch (n->nlmsg_type) {\n\tcase RTM_NEWACTION:\n\t\t/* we are going to assume all other flags\n\t\t * imply create only if it doesn't exist\n\t\t * Note that CREATE | EXCL implies that\n\t\t * but since we want avoid ambiguity (eg when flags\n\t\t * is zero) then just set this\n\t\t */\n\t\tif (n->nlmsg_flags & NLM_F_REPLACE)\n\t\t\tovr = 1;\nreplay:\n\t\tret = tcf_action_add(net, tca[TCA_ACT_TAB], n, portid, ovr);\n\t\tif (ret == -EAGAIN)\n\t\t\tgoto replay;\n\t\tbreak;\n\tcase RTM_DELACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_DELACTION);\n\t\tbreak;\n\tcase RTM_GETACTION:\n\t\tret = tca_action_gd(net, tca[TCA_ACT_TAB], n,\n\t\t\t\t    portid, RTM_GETACTION);\n\t\tbreak;\n\tdefault:\n\t\tBUG();\n\t}\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n \tu32 portid = skb ? NETLINK_CB(skb).portid : 0;\n \tint ret = 0, ovr = 0;\n \n-\tif ((n->nlmsg_type != RTM_GETACTION) && !capable(CAP_NET_ADMIN))\n+\tif ((n->nlmsg_type != RTM_GETACTION) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tret = nlmsg_parse(n, sizeof(struct tcamsg), tca, TCA_ACT_MAX, NULL);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((n->nlmsg_type != RTM_GETACTION) && !capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif ((n->nlmsg_type != RTM_GETACTION) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/scsi_nl_rcv_msg",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static void\nscsi_nl_rcv_msg(struct sk_buff *skb)\n{\n\tstruct nlmsghdr *nlh;\n\tstruct scsi_nl_hdr *hdr;\n\tu32 rlen;\n\tint err, tport;\n\n\twhile (skb->len >= NLMSG_HDRLEN) {\n\t\terr = 0;\n\n\t\tnlh = nlmsg_hdr(skb);\n\t\tif ((nlh->nlmsg_len < (sizeof(*nlh) + sizeof(*hdr))) ||\n\t\t    (skb->len < nlh->nlmsg_len)) {\n\t\t\tprintk(KERN_WARNING \"%s: discarding partial skb\\n\",\n\t\t\t\t __func__);\n\t\t\treturn;\n\t\t}\n\n\t\trlen = NLMSG_ALIGN(nlh->nlmsg_len);\n\t\tif (rlen > skb->len)\n\t\t\trlen = skb->len;\n\n\t\tif (nlh->nlmsg_type != SCSI_TRANSPORT_MSG) {\n\t\t\terr = -EBADMSG;\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\thdr = nlmsg_data(nlh);\n\t\tif ((hdr->version != SCSI_NL_VERSION) ||\n\t\t    (hdr->magic != SCSI_NL_MAGIC)) {\n\t\t\terr = -EPROTOTYPE;\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\tif (!capable(CAP_SYS_ADMIN)) {\n\t\t\terr = -EPERM;\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\tif (nlh->nlmsg_len < (sizeof(*nlh) + hdr->msglen)) {\n\t\t\tprintk(KERN_WARNING \"%s: discarding partial message\\n\",\n\t\t\t\t __func__);\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\t/*\n\t\t * Deliver message to the appropriate transport\n\t\t */\n\t\ttport = hdr->transport;\n\t\tif (tport == SCSI_NL_TRANSPORT) {\n\t\t\tswitch (hdr->msgtype) {\n\t\t\tcase SCSI_NL_SHOST_VENDOR:\n\t\t\t\t/* Locate the driver that corresponds to the message */\n\t\t\t\terr = -ESRCH;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\terr = -EBADR;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (err)\n\t\t\t\tprintk(KERN_WARNING \"%s: Msgtype %d failed - err %d\\n\",\n\t\t\t\t       __func__, hdr->msgtype, err);\n\t\t}\n\t\telse\n\t\t\terr = -ENOENT;\n\nnext_msg:\n\t\tif ((err) || (nlh->nlmsg_flags & NLM_F_ACK))\n\t\t\tnetlink_ack(skb, nlh, err);\n\n\t\tskb_pull(skb, rlen);\n\t}\n}",
        "func": "static void\nscsi_nl_rcv_msg(struct sk_buff *skb)\n{\n\tstruct nlmsghdr *nlh;\n\tstruct scsi_nl_hdr *hdr;\n\tu32 rlen;\n\tint err, tport;\n\n\twhile (skb->len >= NLMSG_HDRLEN) {\n\t\terr = 0;\n\n\t\tnlh = nlmsg_hdr(skb);\n\t\tif ((nlh->nlmsg_len < (sizeof(*nlh) + sizeof(*hdr))) ||\n\t\t    (skb->len < nlh->nlmsg_len)) {\n\t\t\tprintk(KERN_WARNING \"%s: discarding partial skb\\n\",\n\t\t\t\t __func__);\n\t\t\treturn;\n\t\t}\n\n\t\trlen = NLMSG_ALIGN(nlh->nlmsg_len);\n\t\tif (rlen > skb->len)\n\t\t\trlen = skb->len;\n\n\t\tif (nlh->nlmsg_type != SCSI_TRANSPORT_MSG) {\n\t\t\terr = -EBADMSG;\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\thdr = nlmsg_data(nlh);\n\t\tif ((hdr->version != SCSI_NL_VERSION) ||\n\t\t    (hdr->magic != SCSI_NL_MAGIC)) {\n\t\t\terr = -EPROTOTYPE;\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\tif (!netlink_capable(skb, CAP_SYS_ADMIN)) {\n\t\t\terr = -EPERM;\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\tif (nlh->nlmsg_len < (sizeof(*nlh) + hdr->msglen)) {\n\t\t\tprintk(KERN_WARNING \"%s: discarding partial message\\n\",\n\t\t\t\t __func__);\n\t\t\tgoto next_msg;\n\t\t}\n\n\t\t/*\n\t\t * Deliver message to the appropriate transport\n\t\t */\n\t\ttport = hdr->transport;\n\t\tif (tport == SCSI_NL_TRANSPORT) {\n\t\t\tswitch (hdr->msgtype) {\n\t\t\tcase SCSI_NL_SHOST_VENDOR:\n\t\t\t\t/* Locate the driver that corresponds to the message */\n\t\t\t\terr = -ESRCH;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\terr = -EBADR;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (err)\n\t\t\t\tprintk(KERN_WARNING \"%s: Msgtype %d failed - err %d\\n\",\n\t\t\t\t       __func__, hdr->msgtype, err);\n\t\t}\n\t\telse\n\t\t\terr = -ENOENT;\n\nnext_msg:\n\t\tif ((err) || (nlh->nlmsg_flags & NLM_F_ACK))\n\t\t\tnetlink_ack(skb, nlh, err);\n\n\t\tskb_pull(skb, rlen);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,7 +33,7 @@\n \t\t\tgoto next_msg;\n \t\t}\n \n-\t\tif (!capable(CAP_SYS_ADMIN)) {\n+\t\tif (!netlink_capable(skb, CAP_SYS_ADMIN)) {\n \t\t\terr = -EPERM;\n \t\t\tgoto next_msg;\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (!capable(CAP_SYS_ADMIN)) {"
            ],
            "added_lines": [
                "\t\tif (!netlink_capable(skb, CAP_SYS_ADMIN)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/crypto_user_rcv_msg",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int crypto_user_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct nlattr *attrs[CRYPTOCFGA_MAX+1];\n\tconst struct crypto_link *link;\n\tint type, err;\n\n\ttype = nlh->nlmsg_type;\n\tif (type > CRYPTO_MSG_MAX)\n\t\treturn -EINVAL;\n\n\ttype -= CRYPTO_MSG_BASE;\n\tlink = &crypto_dispatch[type];\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif ((type == (CRYPTO_MSG_GETALG - CRYPTO_MSG_BASE) &&\n\t    (nlh->nlmsg_flags & NLM_F_DUMP))) {\n\t\tstruct crypto_alg *alg;\n\t\tu16 dump_alloc = 0;\n\n\t\tif (link->dump == NULL)\n\t\t\treturn -EINVAL;\n\n\t\tlist_for_each_entry(alg, &crypto_alg_list, cra_list)\n\t\t\tdump_alloc += CRYPTO_REPORT_MAXSIZE;\n\n\t\t{\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.dump = link->dump,\n\t\t\t\t.done = link->done,\n\t\t\t\t.min_dump_alloc = dump_alloc,\n\t\t\t};\n\t\t\treturn netlink_dump_start(crypto_nlsk, skb, nlh, &c);\n\t\t}\n\t}\n\n\terr = nlmsg_parse(nlh, crypto_msg_min[type], attrs, CRYPTOCFGA_MAX,\n\t\t\t  crypto_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (link->doit == NULL)\n\t\treturn -EINVAL;\n\n\treturn link->doit(skb, nlh, attrs);\n}",
        "func": "static int crypto_user_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct nlattr *attrs[CRYPTOCFGA_MAX+1];\n\tconst struct crypto_link *link;\n\tint type, err;\n\n\ttype = nlh->nlmsg_type;\n\tif (type > CRYPTO_MSG_MAX)\n\t\treturn -EINVAL;\n\n\ttype -= CRYPTO_MSG_BASE;\n\tlink = &crypto_dispatch[type];\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif ((type == (CRYPTO_MSG_GETALG - CRYPTO_MSG_BASE) &&\n\t    (nlh->nlmsg_flags & NLM_F_DUMP))) {\n\t\tstruct crypto_alg *alg;\n\t\tu16 dump_alloc = 0;\n\n\t\tif (link->dump == NULL)\n\t\t\treturn -EINVAL;\n\n\t\tlist_for_each_entry(alg, &crypto_alg_list, cra_list)\n\t\t\tdump_alloc += CRYPTO_REPORT_MAXSIZE;\n\n\t\t{\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.dump = link->dump,\n\t\t\t\t.done = link->done,\n\t\t\t\t.min_dump_alloc = dump_alloc,\n\t\t\t};\n\t\t\treturn netlink_dump_start(crypto_nlsk, skb, nlh, &c);\n\t\t}\n\t}\n\n\terr = nlmsg_parse(nlh, crypto_msg_min[type], attrs, CRYPTOCFGA_MAX,\n\t\t\t  crypto_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (link->doit == NULL)\n\t\treturn -EINVAL;\n\n\treturn link->doit(skb, nlh, attrs);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n \ttype -= CRYPTO_MSG_BASE;\n \tlink = &crypto_dispatch[type];\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif ((type == (CRYPTO_MSG_GETALG - CRYPTO_MSG_BASE) &&",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/handle_cmd",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int handle_cmd(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *rep_buf;\n\tstruct nlmsghdr *rep_nlh;\n\tstruct nlmsghdr *req_nlh = info->nlhdr;\n\tstruct tipc_genlmsghdr *req_userhdr = info->userhdr;\n\tint hdr_space = nlmsg_total_size(GENL_HDRLEN + TIPC_GENL_HDRLEN);\n\tu16 cmd;\n\n\tif ((req_userhdr->cmd & 0xC000) && (!capable(CAP_NET_ADMIN)))\n\t\tcmd = TIPC_CMD_NOT_NET_ADMIN;\n\telse\n\t\tcmd = req_userhdr->cmd;\n\n\trep_buf = tipc_cfg_do_cmd(req_userhdr->dest, cmd,\n\t\t\tnlmsg_data(req_nlh) + GENL_HDRLEN + TIPC_GENL_HDRLEN,\n\t\t\tnlmsg_attrlen(req_nlh, GENL_HDRLEN + TIPC_GENL_HDRLEN),\n\t\t\thdr_space);\n\n\tif (rep_buf) {\n\t\tskb_push(rep_buf, hdr_space);\n\t\trep_nlh = nlmsg_hdr(rep_buf);\n\t\tmemcpy(rep_nlh, req_nlh, hdr_space);\n\t\trep_nlh->nlmsg_len = rep_buf->len;\n\t\tgenlmsg_unicast(&init_net, rep_buf, NETLINK_CB(skb).portid);\n\t}\n\n\treturn 0;\n}",
        "func": "static int handle_cmd(struct sk_buff *skb, struct genl_info *info)\n{\n\tstruct sk_buff *rep_buf;\n\tstruct nlmsghdr *rep_nlh;\n\tstruct nlmsghdr *req_nlh = info->nlhdr;\n\tstruct tipc_genlmsghdr *req_userhdr = info->userhdr;\n\tint hdr_space = nlmsg_total_size(GENL_HDRLEN + TIPC_GENL_HDRLEN);\n\tu16 cmd;\n\n\tif ((req_userhdr->cmd & 0xC000) && (!netlink_capable(skb, CAP_NET_ADMIN)))\n\t\tcmd = TIPC_CMD_NOT_NET_ADMIN;\n\telse\n\t\tcmd = req_userhdr->cmd;\n\n\trep_buf = tipc_cfg_do_cmd(req_userhdr->dest, cmd,\n\t\t\tnlmsg_data(req_nlh) + GENL_HDRLEN + TIPC_GENL_HDRLEN,\n\t\t\tnlmsg_attrlen(req_nlh, GENL_HDRLEN + TIPC_GENL_HDRLEN),\n\t\t\thdr_space);\n\n\tif (rep_buf) {\n\t\tskb_push(rep_buf, hdr_space);\n\t\trep_nlh = nlmsg_hdr(rep_buf);\n\t\tmemcpy(rep_nlh, req_nlh, hdr_space);\n\t\trep_nlh->nlmsg_len = rep_buf->len;\n\t\tgenlmsg_unicast(&init_net, rep_buf, NETLINK_CB(skb).portid);\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n \tint hdr_space = nlmsg_total_size(GENL_HDRLEN + TIPC_GENL_HDRLEN);\n \tu16 cmd;\n \n-\tif ((req_userhdr->cmd & 0xC000) && (!capable(CAP_NET_ADMIN)))\n+\tif ((req_userhdr->cmd & 0xC000) && (!netlink_capable(skb, CAP_NET_ADMIN)))\n \t\tcmd = TIPC_CMD_NOT_NET_ADMIN;\n \telse\n \t\tcmd = req_userhdr->cmd;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((req_userhdr->cmd & 0xC000) && (!capable(CAP_NET_ADMIN)))"
            ],
            "added_lines": [
                "\tif ((req_userhdr->cmd & 0xC000) && (!netlink_capable(skb, CAP_NET_ADMIN)))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/route_doit",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int route_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[RTA_MAX+1];\n\tstruct net_device *dev;\n\tstruct rtmsg *rtm;\n\tint err;\n\tu8 dst;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*rtm), tb, RTA_MAX, rtm_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\trtm = nlmsg_data(nlh);\n\tif (rtm->rtm_table != RT_TABLE_MAIN || rtm->rtm_type != RTN_UNICAST)\n\t\treturn -EINVAL;\n\tif (tb[RTA_DST] == NULL || tb[RTA_OIF] == NULL)\n\t\treturn -EINVAL;\n\tdst = nla_get_u8(tb[RTA_DST]);\n\tif (dst & 3) /* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, nla_get_u32(tb[RTA_OIF]));\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWROUTE)\n\t\terr = phonet_route_add(dev, dst);\n\telse\n\t\terr = phonet_route_del(dev, dst);\n\tif (!err)\n\t\trtm_phonet_notify(nlh->nlmsg_type, dev, dst);\n\treturn err;\n}",
        "func": "static int route_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[RTA_MAX+1];\n\tstruct net_device *dev;\n\tstruct rtmsg *rtm;\n\tint err;\n\tu8 dst;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*rtm), tb, RTA_MAX, rtm_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\trtm = nlmsg_data(nlh);\n\tif (rtm->rtm_table != RT_TABLE_MAIN || rtm->rtm_type != RTN_UNICAST)\n\t\treturn -EINVAL;\n\tif (tb[RTA_DST] == NULL || tb[RTA_OIF] == NULL)\n\t\treturn -EINVAL;\n\tdst = nla_get_u8(tb[RTA_DST]);\n\tif (dst & 3) /* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, nla_get_u32(tb[RTA_OIF]));\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWROUTE)\n\t\terr = phonet_route_add(dev, dst);\n\telse\n\t\terr = phonet_route_del(dev, dst);\n\tif (!err)\n\t\trtm_phonet_notify(nlh->nlmsg_type, dev, dst);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,10 +7,10 @@\n \tint err;\n \tu8 dst;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n-\tif (!capable(CAP_SYS_ADMIN))\n+\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n \t\treturn -EPERM;\n \n \tASSERT_RTNL();",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))",
                "\tif (!capable(CAP_SYS_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))",
                "\tif (!netlink_capable(skb, CAP_SYS_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/addr_doit",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int addr_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct net_device *dev;\n\tstruct ifaddrmsg *ifm;\n\tint err;\n\tu8 pnaddr;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, ifa_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tifm = nlmsg_data(nlh);\n\tif (tb[IFA_LOCAL] == NULL)\n\t\treturn -EINVAL;\n\tpnaddr = nla_get_u8(tb[IFA_LOCAL]);\n\tif (pnaddr & 3)\n\t\t/* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifm->ifa_index);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWADDR)\n\t\terr = phonet_address_add(dev, pnaddr);\n\telse\n\t\terr = phonet_address_del(dev, pnaddr);\n\tif (!err)\n\t\tphonet_address_notify(nlh->nlmsg_type, dev, pnaddr);\n\treturn err;\n}",
        "func": "static int addr_doit(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tb[IFA_MAX+1];\n\tstruct net_device *dev;\n\tstruct ifaddrmsg *ifm;\n\tint err;\n\tu8 pnaddr;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tASSERT_RTNL();\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFA_MAX, ifa_phonet_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tifm = nlmsg_data(nlh);\n\tif (tb[IFA_LOCAL] == NULL)\n\t\treturn -EINVAL;\n\tpnaddr = nla_get_u8(tb[IFA_LOCAL]);\n\tif (pnaddr & 3)\n\t\t/* Phonet addresses only have 6 high-order bits */\n\t\treturn -EINVAL;\n\n\tdev = __dev_get_by_index(net, ifm->ifa_index);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\tif (nlh->nlmsg_type == RTM_NEWADDR)\n\t\terr = phonet_address_add(dev, pnaddr);\n\telse\n\t\terr = phonet_address_del(dev, pnaddr);\n\tif (!err)\n\t\tphonet_address_notify(nlh->nlmsg_type, dev, pnaddr);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,10 +7,10 @@\n \tint err;\n \tu8 pnaddr;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n-\tif (!capable(CAP_SYS_ADMIN))\n+\tif (!netlink_capable(skb, CAP_SYS_ADMIN))\n \t\treturn -EPERM;\n \n \tASSERT_RTNL();",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))",
                "\tif (!capable(CAP_SYS_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))",
                "\tif (!netlink_capable(skb, CAP_SYS_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/xfrm_user_rcv_msg",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int xfrm_user_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *attrs[XFRMA_MAX+1];\n\tconst struct xfrm_link *link;\n\tint type, err;\n\n\ttype = nlh->nlmsg_type;\n\tif (type > XFRM_MSG_MAX)\n\t\treturn -EINVAL;\n\n\ttype -= XFRM_MSG_BASE;\n\tlink = &xfrm_dispatch[type];\n\n\t/* All operations require privileges, even GET */\n\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif ((type == (XFRM_MSG_GETSA - XFRM_MSG_BASE) ||\n\t     type == (XFRM_MSG_GETPOLICY - XFRM_MSG_BASE)) &&\n\t    (nlh->nlmsg_flags & NLM_F_DUMP)) {\n\t\tif (link->dump == NULL)\n\t\t\treturn -EINVAL;\n\n\t\t{\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.dump = link->dump,\n\t\t\t\t.done = link->done,\n\t\t\t};\n\t\t\treturn netlink_dump_start(net->xfrm.nlsk, skb, nlh, &c);\n\t\t}\n\t}\n\n\terr = nlmsg_parse(nlh, xfrm_msg_min[type], attrs, XFRMA_MAX,\n\t\t\t  xfrma_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (link->doit == NULL)\n\t\treturn -EINVAL;\n\n\treturn link->doit(skb, nlh, attrs);\n}",
        "func": "static int xfrm_user_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *attrs[XFRMA_MAX+1];\n\tconst struct xfrm_link *link;\n\tint type, err;\n\n\ttype = nlh->nlmsg_type;\n\tif (type > XFRM_MSG_MAX)\n\t\treturn -EINVAL;\n\n\ttype -= XFRM_MSG_BASE;\n\tlink = &xfrm_dispatch[type];\n\n\t/* All operations require privileges, even GET */\n\tif (!netlink_net_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif ((type == (XFRM_MSG_GETSA - XFRM_MSG_BASE) ||\n\t     type == (XFRM_MSG_GETPOLICY - XFRM_MSG_BASE)) &&\n\t    (nlh->nlmsg_flags & NLM_F_DUMP)) {\n\t\tif (link->dump == NULL)\n\t\t\treturn -EINVAL;\n\n\t\t{\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.dump = link->dump,\n\t\t\t\t.done = link->done,\n\t\t\t};\n\t\t\treturn netlink_dump_start(net->xfrm.nlsk, skb, nlh, &c);\n\t\t}\n\t}\n\n\terr = nlmsg_parse(nlh, xfrm_msg_min[type], attrs, XFRMA_MAX,\n\t\t\t  xfrma_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (link->doit == NULL)\n\t\treturn -EINVAL;\n\n\treturn link->doit(skb, nlh, attrs);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \tlink = &xfrm_dispatch[type];\n \n \t/* All operations require privileges, even GET */\n-\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\n+\tif (!netlink_net_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif ((type == (XFRM_MSG_GETSA - XFRM_MSG_BASE) ||",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_net_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/cn_proc_mcast_ctl",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static void cn_proc_mcast_ctl(struct cn_msg *msg,\n\t\t\t      struct netlink_skb_parms *nsp)\n{\n\tenum proc_cn_mcast_op *mc_op = NULL;\n\tint err = 0;\n\n\tif (msg->len != sizeof(*mc_op))\n\t\treturn;\n\n\t/* \n\t * Events are reported with respect to the initial pid\n\t * and user namespaces so ignore requestors from\n\t * other namespaces.\n\t */\n\tif ((current_user_ns() != &init_user_ns) ||\n\t    (task_active_pid_ns(current) != &init_pid_ns))\n\t\treturn;\n\n\t/* Can only change if privileged. */\n\tif (!capable(CAP_NET_ADMIN)) {\n\t\terr = EPERM;\n\t\tgoto out;\n\t}\n\n\tmc_op = (enum proc_cn_mcast_op *)msg->data;\n\tswitch (*mc_op) {\n\tcase PROC_CN_MCAST_LISTEN:\n\t\tatomic_inc(&proc_event_num_listeners);\n\t\tbreak;\n\tcase PROC_CN_MCAST_IGNORE:\n\t\tatomic_dec(&proc_event_num_listeners);\n\t\tbreak;\n\tdefault:\n\t\terr = EINVAL;\n\t\tbreak;\n\t}\n\nout:\n\tcn_proc_ack(err, msg->seq, msg->ack);\n}",
        "func": "static void cn_proc_mcast_ctl(struct cn_msg *msg,\n\t\t\t      struct netlink_skb_parms *nsp)\n{\n\tenum proc_cn_mcast_op *mc_op = NULL;\n\tint err = 0;\n\n\tif (msg->len != sizeof(*mc_op))\n\t\treturn;\n\n\t/* \n\t * Events are reported with respect to the initial pid\n\t * and user namespaces so ignore requestors from\n\t * other namespaces.\n\t */\n\tif ((current_user_ns() != &init_user_ns) ||\n\t    (task_active_pid_ns(current) != &init_pid_ns))\n\t\treturn;\n\n\t/* Can only change if privileged. */\n\tif (!__netlink_ns_capable(nsp, &init_user_ns, CAP_NET_ADMIN)) {\n\t\terr = EPERM;\n\t\tgoto out;\n\t}\n\n\tmc_op = (enum proc_cn_mcast_op *)msg->data;\n\tswitch (*mc_op) {\n\tcase PROC_CN_MCAST_LISTEN:\n\t\tatomic_inc(&proc_event_num_listeners);\n\t\tbreak;\n\tcase PROC_CN_MCAST_IGNORE:\n\t\tatomic_dec(&proc_event_num_listeners);\n\t\tbreak;\n\tdefault:\n\t\terr = EINVAL;\n\t\tbreak;\n\t}\n\nout:\n\tcn_proc_ack(err, msg->seq, msg->ack);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,7 @@\n \t\treturn;\n \n \t/* Can only change if privileged. */\n-\tif (!capable(CAP_NET_ADMIN)) {\n+\tif (!__netlink_ns_capable(nsp, &init_user_ns, CAP_NET_ADMIN)) {\n \t\terr = EPERM;\n \t\tgoto out;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN)) {"
            ],
            "added_lines": [
                "\tif (!__netlink_ns_capable(nsp, &init_user_ns, CAP_NET_ADMIN)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/tc_ctl_tfilter",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int tc_ctl_tfilter(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tspinlock_t *root_lock;\n\tstruct tcmsg *t;\n\tu32 protocol;\n\tu32 prio;\n\tu32 nprio;\n\tu32 parent;\n\tstruct net_device *dev;\n\tstruct Qdisc  *q;\n\tstruct tcf_proto **back, **chain;\n\tstruct tcf_proto *tp;\n\tconst struct tcf_proto_ops *tp_ops;\n\tconst struct Qdisc_class_ops *cops;\n\tunsigned long cl;\n\tunsigned long fh;\n\tint err;\n\tint tp_created = 0;\n\n\tif ((n->nlmsg_type != RTM_GETTFILTER) && !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\terr = nlmsg_parse(n, sizeof(*t), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tt = nlmsg_data(n);\n\tprotocol = TC_H_MIN(t->tcm_info);\n\tprio = TC_H_MAJ(t->tcm_info);\n\tnprio = prio;\n\tparent = t->tcm_parent;\n\tcl = 0;\n\n\tif (prio == 0) {\n\t\t/* If no priority is given, user wants we allocated it. */\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\treturn -ENOENT;\n\t\tprio = TC_H_MAKE(0x80000000U, 0U);\n\t}\n\n\t/* Find head of filter chain. */\n\n\t/* Find link */\n\tdev = __dev_get_by_index(net, t->tcm_ifindex);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\t/* Find qdisc */\n\tif (!parent) {\n\t\tq = dev->qdisc;\n\t\tparent = q->handle;\n\t} else {\n\t\tq = qdisc_lookup(dev, TC_H_MAJ(t->tcm_parent));\n\t\tif (q == NULL)\n\t\t\treturn -EINVAL;\n\t}\n\n\t/* Is it classful? */\n\tcops = q->ops->cl_ops;\n\tif (!cops)\n\t\treturn -EINVAL;\n\n\tif (cops->tcf_chain == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Do we search for filter, attached to class? */\n\tif (TC_H_MIN(parent)) {\n\t\tcl = cops->get(q, parent);\n\t\tif (cl == 0)\n\t\t\treturn -ENOENT;\n\t}\n\n\t/* And the last stroke */\n\tchain = cops->tcf_chain(q, cl);\n\terr = -EINVAL;\n\tif (chain == NULL)\n\t\tgoto errout;\n\n\t/* Check the chain for existence of proto-tcf with this priority */\n\tfor (back = chain; (tp = *back) != NULL; back = &tp->next) {\n\t\tif (tp->prio >= prio) {\n\t\t\tif (tp->prio == prio) {\n\t\t\t\tif (!nprio ||\n\t\t\t\t    (tp->protocol != protocol && protocol))\n\t\t\t\t\tgoto errout;\n\t\t\t} else\n\t\t\t\ttp = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\troot_lock = qdisc_root_sleeping_lock(q);\n\n\tif (tp == NULL) {\n\t\t/* Proto-tcf does not exist, create new one */\n\n\t\tif (tca[TCA_KIND] == NULL || !protocol)\n\t\t\tgoto errout;\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\n\n\t\t/* Create new proto tcf */\n\n\t\terr = -ENOBUFS;\n\t\ttp = kzalloc(sizeof(*tp), GFP_KERNEL);\n\t\tif (tp == NULL)\n\t\t\tgoto errout;\n\t\terr = -ENOENT;\n\t\ttp_ops = tcf_proto_lookup_ops(tca[TCA_KIND]);\n\t\tif (tp_ops == NULL) {\n#ifdef CONFIG_MODULES\n\t\t\tstruct nlattr *kind = tca[TCA_KIND];\n\t\t\tchar name[IFNAMSIZ];\n\n\t\t\tif (kind != NULL &&\n\t\t\t    nla_strlcpy(name, kind, IFNAMSIZ) < IFNAMSIZ) {\n\t\t\t\trtnl_unlock();\n\t\t\t\trequest_module(\"cls_%s\", name);\n\t\t\t\trtnl_lock();\n\t\t\t\ttp_ops = tcf_proto_lookup_ops(kind);\n\t\t\t\t/* We dropped the RTNL semaphore in order to\n\t\t\t\t * perform the module load.  So, even if we\n\t\t\t\t * succeeded in loading the module we have to\n\t\t\t\t * replay the request.  We indicate this using\n\t\t\t\t * -EAGAIN.\n\t\t\t\t */\n\t\t\t\tif (tp_ops != NULL) {\n\t\t\t\t\tmodule_put(tp_ops->owner);\n\t\t\t\t\terr = -EAGAIN;\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\t\ttp->ops = tp_ops;\n\t\ttp->protocol = protocol;\n\t\ttp->prio = nprio ? : TC_H_MAJ(tcf_auto_prio(*back));\n\t\ttp->q = q;\n\t\ttp->classify = tp_ops->classify;\n\t\ttp->classid = parent;\n\n\t\terr = tp_ops->init(tp);\n\t\tif (err != 0) {\n\t\t\tmodule_put(tp_ops->owner);\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\n\t\ttp_created = 1;\n\n\t} else if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], tp->ops->kind))\n\t\tgoto errout;\n\n\tfh = tp->ops->get(tp, t->tcm_handle);\n\n\tif (fh == 0) {\n\t\tif (n->nlmsg_type == RTM_DELTFILTER && t->tcm_handle == 0) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\t*back = tp->next;\n\t\t\tspin_unlock_bh(root_lock);\n\n\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\ttcf_destroy(tp);\n\t\t\terr = 0;\n\t\t\tgoto errout;\n\t\t}\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\t} else {\n\t\tswitch (n->nlmsg_type) {\n\t\tcase RTM_NEWTFILTER:\n\t\t\terr = -EEXIST;\n\t\t\tif (n->nlmsg_flags & NLM_F_EXCL) {\n\t\t\t\tif (tp_created)\n\t\t\t\t\ttcf_destroy(tp);\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RTM_DELTFILTER:\n\t\t\terr = tp->ops->delete(tp, fh);\n\t\t\tif (err == 0)\n\t\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\tgoto errout;\n\t\tcase RTM_GETTFILTER:\n\t\t\terr = tfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t\t\tgoto errout;\n\t\tdefault:\n\t\t\terr = -EINVAL;\n\t\t\tgoto errout;\n\t\t}\n\t}\n\n\terr = tp->ops->change(net, skb, tp, cl, t->tcm_handle, tca, &fh);\n\tif (err == 0) {\n\t\tif (tp_created) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\ttp->next = *back;\n\t\t\t*back = tp;\n\t\t\tspin_unlock_bh(root_lock);\n\t\t}\n\t\ttfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t} else {\n\t\tif (tp_created)\n\t\t\ttcf_destroy(tp);\n\t}\n\nerrout:\n\tif (cl)\n\t\tcops->put(q, cl);\n\tif (err == -EAGAIN)\n\t\t/* Replay the request. */\n\t\tgoto replay;\n\treturn err;\n}",
        "func": "static int tc_ctl_tfilter(struct sk_buff *skb, struct nlmsghdr *n)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct nlattr *tca[TCA_MAX + 1];\n\tspinlock_t *root_lock;\n\tstruct tcmsg *t;\n\tu32 protocol;\n\tu32 prio;\n\tu32 nprio;\n\tu32 parent;\n\tstruct net_device *dev;\n\tstruct Qdisc  *q;\n\tstruct tcf_proto **back, **chain;\n\tstruct tcf_proto *tp;\n\tconst struct tcf_proto_ops *tp_ops;\n\tconst struct Qdisc_class_ops *cops;\n\tunsigned long cl;\n\tunsigned long fh;\n\tint err;\n\tint tp_created = 0;\n\n\tif ((n->nlmsg_type != RTM_GETTFILTER) && !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\nreplay:\n\terr = nlmsg_parse(n, sizeof(*t), tca, TCA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tt = nlmsg_data(n);\n\tprotocol = TC_H_MIN(t->tcm_info);\n\tprio = TC_H_MAJ(t->tcm_info);\n\tnprio = prio;\n\tparent = t->tcm_parent;\n\tcl = 0;\n\n\tif (prio == 0) {\n\t\t/* If no priority is given, user wants we allocated it. */\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\treturn -ENOENT;\n\t\tprio = TC_H_MAKE(0x80000000U, 0U);\n\t}\n\n\t/* Find head of filter chain. */\n\n\t/* Find link */\n\tdev = __dev_get_by_index(net, t->tcm_ifindex);\n\tif (dev == NULL)\n\t\treturn -ENODEV;\n\n\t/* Find qdisc */\n\tif (!parent) {\n\t\tq = dev->qdisc;\n\t\tparent = q->handle;\n\t} else {\n\t\tq = qdisc_lookup(dev, TC_H_MAJ(t->tcm_parent));\n\t\tif (q == NULL)\n\t\t\treturn -EINVAL;\n\t}\n\n\t/* Is it classful? */\n\tcops = q->ops->cl_ops;\n\tif (!cops)\n\t\treturn -EINVAL;\n\n\tif (cops->tcf_chain == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\t/* Do we search for filter, attached to class? */\n\tif (TC_H_MIN(parent)) {\n\t\tcl = cops->get(q, parent);\n\t\tif (cl == 0)\n\t\t\treturn -ENOENT;\n\t}\n\n\t/* And the last stroke */\n\tchain = cops->tcf_chain(q, cl);\n\terr = -EINVAL;\n\tif (chain == NULL)\n\t\tgoto errout;\n\n\t/* Check the chain for existence of proto-tcf with this priority */\n\tfor (back = chain; (tp = *back) != NULL; back = &tp->next) {\n\t\tif (tp->prio >= prio) {\n\t\t\tif (tp->prio == prio) {\n\t\t\t\tif (!nprio ||\n\t\t\t\t    (tp->protocol != protocol && protocol))\n\t\t\t\t\tgoto errout;\n\t\t\t} else\n\t\t\t\ttp = NULL;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\troot_lock = qdisc_root_sleeping_lock(q);\n\n\tif (tp == NULL) {\n\t\t/* Proto-tcf does not exist, create new one */\n\n\t\tif (tca[TCA_KIND] == NULL || !protocol)\n\t\t\tgoto errout;\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\n\n\t\t/* Create new proto tcf */\n\n\t\terr = -ENOBUFS;\n\t\ttp = kzalloc(sizeof(*tp), GFP_KERNEL);\n\t\tif (tp == NULL)\n\t\t\tgoto errout;\n\t\terr = -ENOENT;\n\t\ttp_ops = tcf_proto_lookup_ops(tca[TCA_KIND]);\n\t\tif (tp_ops == NULL) {\n#ifdef CONFIG_MODULES\n\t\t\tstruct nlattr *kind = tca[TCA_KIND];\n\t\t\tchar name[IFNAMSIZ];\n\n\t\t\tif (kind != NULL &&\n\t\t\t    nla_strlcpy(name, kind, IFNAMSIZ) < IFNAMSIZ) {\n\t\t\t\trtnl_unlock();\n\t\t\t\trequest_module(\"cls_%s\", name);\n\t\t\t\trtnl_lock();\n\t\t\t\ttp_ops = tcf_proto_lookup_ops(kind);\n\t\t\t\t/* We dropped the RTNL semaphore in order to\n\t\t\t\t * perform the module load.  So, even if we\n\t\t\t\t * succeeded in loading the module we have to\n\t\t\t\t * replay the request.  We indicate this using\n\t\t\t\t * -EAGAIN.\n\t\t\t\t */\n\t\t\t\tif (tp_ops != NULL) {\n\t\t\t\t\tmodule_put(tp_ops->owner);\n\t\t\t\t\terr = -EAGAIN;\n\t\t\t\t}\n\t\t\t}\n#endif\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\t\ttp->ops = tp_ops;\n\t\ttp->protocol = protocol;\n\t\ttp->prio = nprio ? : TC_H_MAJ(tcf_auto_prio(*back));\n\t\ttp->q = q;\n\t\ttp->classify = tp_ops->classify;\n\t\ttp->classid = parent;\n\n\t\terr = tp_ops->init(tp);\n\t\tif (err != 0) {\n\t\t\tmodule_put(tp_ops->owner);\n\t\t\tkfree(tp);\n\t\t\tgoto errout;\n\t\t}\n\n\t\ttp_created = 1;\n\n\t} else if (tca[TCA_KIND] && nla_strcmp(tca[TCA_KIND], tp->ops->kind))\n\t\tgoto errout;\n\n\tfh = tp->ops->get(tp, t->tcm_handle);\n\n\tif (fh == 0) {\n\t\tif (n->nlmsg_type == RTM_DELTFILTER && t->tcm_handle == 0) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\t*back = tp->next;\n\t\t\tspin_unlock_bh(root_lock);\n\n\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\ttcf_destroy(tp);\n\t\t\terr = 0;\n\t\t\tgoto errout;\n\t\t}\n\n\t\terr = -ENOENT;\n\t\tif (n->nlmsg_type != RTM_NEWTFILTER ||\n\t\t    !(n->nlmsg_flags & NLM_F_CREATE))\n\t\t\tgoto errout;\n\t} else {\n\t\tswitch (n->nlmsg_type) {\n\t\tcase RTM_NEWTFILTER:\n\t\t\terr = -EEXIST;\n\t\t\tif (n->nlmsg_flags & NLM_F_EXCL) {\n\t\t\t\tif (tp_created)\n\t\t\t\t\ttcf_destroy(tp);\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase RTM_DELTFILTER:\n\t\t\terr = tp->ops->delete(tp, fh);\n\t\t\tif (err == 0)\n\t\t\t\ttfilter_notify(net, skb, n, tp, fh, RTM_DELTFILTER);\n\t\t\tgoto errout;\n\t\tcase RTM_GETTFILTER:\n\t\t\terr = tfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t\t\tgoto errout;\n\t\tdefault:\n\t\t\terr = -EINVAL;\n\t\t\tgoto errout;\n\t\t}\n\t}\n\n\terr = tp->ops->change(net, skb, tp, cl, t->tcm_handle, tca, &fh);\n\tif (err == 0) {\n\t\tif (tp_created) {\n\t\t\tspin_lock_bh(root_lock);\n\t\t\ttp->next = *back;\n\t\t\t*back = tp;\n\t\t\tspin_unlock_bh(root_lock);\n\t\t}\n\t\ttfilter_notify(net, skb, n, tp, fh, RTM_NEWTFILTER);\n\t} else {\n\t\tif (tp_created)\n\t\t\ttcf_destroy(tp);\n\t}\n\nerrout:\n\tif (cl)\n\t\tcops->put(q, cl);\n\tif (err == -EAGAIN)\n\t\t/* Replay the request. */\n\t\tgoto replay;\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,7 +19,7 @@\n \tint err;\n \tint tp_created = 0;\n \n-\tif ((n->nlmsg_type != RTM_GETTFILTER) && !capable(CAP_NET_ADMIN))\n+\tif ((n->nlmsg_type != RTM_GETTFILTER) && !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n replay:",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((n->nlmsg_type != RTM_GETTFILTER) && !capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif ((n->nlmsg_type != RTM_GETTFILTER) && !netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/cgw_remove_job",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int cgw_remove_job(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct cgw_job *gwj = NULL;\n\tstruct hlist_node *nx;\n\tstruct rtcanmsg *r;\n\tstruct cf_mod mod;\n\tstruct can_can_gw ccgw;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\terr = cgw_parse_attr(nlh, &mod, CGW_TYPE_CAN_CAN, &ccgw, &limhops);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* two interface indices both set to 0 => remove all entries */\n\tif (!ccgw.src_idx && !ccgw.dst_idx) {\n\t\tcgw_remove_all_jobs();\n\t\treturn 0;\n\t}\n\n\terr = -EINVAL;\n\n\tASSERT_RTNL();\n\n\t/* remove only the first matching entry */\n\thlist_for_each_entry_safe(gwj, nx, &cgw_list, list) {\n\n\t\tif (gwj->flags != r->flags)\n\t\t\tcontinue;\n\n\t\tif (gwj->limit_hops != limhops)\n\t\t\tcontinue;\n\n\t\tif (memcmp(&gwj->mod, &mod, sizeof(mod)))\n\t\t\tcontinue;\n\n\t\t/* if (r->gwtype == CGW_TYPE_CAN_CAN) - is made sure here */\n\t\tif (memcmp(&gwj->ccgw, &ccgw, sizeof(ccgw)))\n\t\t\tcontinue;\n\n\t\thlist_del(&gwj->list);\n\t\tcgw_unregister_filter(gwj);\n\t\tkmem_cache_free(cgw_cache, gwj);\n\t\terr = 0;\n\t\tbreak;\n\t}\n\n\treturn err;\n}",
        "func": "static int cgw_remove_job(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct cgw_job *gwj = NULL;\n\tstruct hlist_node *nx;\n\tstruct rtcanmsg *r;\n\tstruct cf_mod mod;\n\tstruct can_can_gw ccgw;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\terr = cgw_parse_attr(nlh, &mod, CGW_TYPE_CAN_CAN, &ccgw, &limhops);\n\tif (err < 0)\n\t\treturn err;\n\n\t/* two interface indices both set to 0 => remove all entries */\n\tif (!ccgw.src_idx && !ccgw.dst_idx) {\n\t\tcgw_remove_all_jobs();\n\t\treturn 0;\n\t}\n\n\terr = -EINVAL;\n\n\tASSERT_RTNL();\n\n\t/* remove only the first matching entry */\n\thlist_for_each_entry_safe(gwj, nx, &cgw_list, list) {\n\n\t\tif (gwj->flags != r->flags)\n\t\t\tcontinue;\n\n\t\tif (gwj->limit_hops != limhops)\n\t\t\tcontinue;\n\n\t\tif (memcmp(&gwj->mod, &mod, sizeof(mod)))\n\t\t\tcontinue;\n\n\t\t/* if (r->gwtype == CGW_TYPE_CAN_CAN) - is made sure here */\n\t\tif (memcmp(&gwj->ccgw, &ccgw, sizeof(ccgw)))\n\t\t\tcontinue;\n\n\t\thlist_del(&gwj->list);\n\t\tcgw_unregister_filter(gwj);\n\t\tkmem_cache_free(cgw_cache, gwj);\n\t\terr = 0;\n\t\tbreak;\n\t}\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \tu8 limhops = 0;\n \tint err = 0;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (nlmsg_len(nlh) < sizeof(*r))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/cgw_create_job",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int cgw_create_job(struct sk_buff *skb,  struct nlmsghdr *nlh)\n{\n\tstruct rtcanmsg *r;\n\tstruct cgw_job *gwj;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\tgwj = kmem_cache_alloc(cgw_cache, GFP_KERNEL);\n\tif (!gwj)\n\t\treturn -ENOMEM;\n\n\tgwj->handled_frames = 0;\n\tgwj->dropped_frames = 0;\n\tgwj->deleted_frames = 0;\n\tgwj->flags = r->flags;\n\tgwj->gwtype = r->gwtype;\n\n\terr = cgw_parse_attr(nlh, &gwj->mod, CGW_TYPE_CAN_CAN, &gwj->ccgw,\n\t\t\t     &limhops);\n\tif (err < 0)\n\t\tgoto out;\n\n\terr = -ENODEV;\n\n\t/* ifindex == 0 is not allowed for job creation */\n\tif (!gwj->ccgw.src_idx || !gwj->ccgw.dst_idx)\n\t\tgoto out;\n\n\tgwj->src.dev = __dev_get_by_index(&init_net, gwj->ccgw.src_idx);\n\n\tif (!gwj->src.dev)\n\t\tgoto out;\n\n\tif (gwj->src.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->dst.dev = __dev_get_by_index(&init_net, gwj->ccgw.dst_idx);\n\n\tif (!gwj->dst.dev)\n\t\tgoto out;\n\n\tif (gwj->dst.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->limit_hops = limhops;\n\n\tASSERT_RTNL();\n\n\terr = cgw_register_filter(gwj);\n\tif (!err)\n\t\thlist_add_head_rcu(&gwj->list, &cgw_list);\nout:\n\tif (err)\n\t\tkmem_cache_free(cgw_cache, gwj);\n\n\treturn err;\n}",
        "func": "static int cgw_create_job(struct sk_buff *skb,  struct nlmsghdr *nlh)\n{\n\tstruct rtcanmsg *r;\n\tstruct cgw_job *gwj;\n\tu8 limhops = 0;\n\tint err = 0;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (nlmsg_len(nlh) < sizeof(*r))\n\t\treturn -EINVAL;\n\n\tr = nlmsg_data(nlh);\n\tif (r->can_family != AF_CAN)\n\t\treturn -EPFNOSUPPORT;\n\n\t/* so far we only support CAN -> CAN routings */\n\tif (r->gwtype != CGW_TYPE_CAN_CAN)\n\t\treturn -EINVAL;\n\n\tgwj = kmem_cache_alloc(cgw_cache, GFP_KERNEL);\n\tif (!gwj)\n\t\treturn -ENOMEM;\n\n\tgwj->handled_frames = 0;\n\tgwj->dropped_frames = 0;\n\tgwj->deleted_frames = 0;\n\tgwj->flags = r->flags;\n\tgwj->gwtype = r->gwtype;\n\n\terr = cgw_parse_attr(nlh, &gwj->mod, CGW_TYPE_CAN_CAN, &gwj->ccgw,\n\t\t\t     &limhops);\n\tif (err < 0)\n\t\tgoto out;\n\n\terr = -ENODEV;\n\n\t/* ifindex == 0 is not allowed for job creation */\n\tif (!gwj->ccgw.src_idx || !gwj->ccgw.dst_idx)\n\t\tgoto out;\n\n\tgwj->src.dev = __dev_get_by_index(&init_net, gwj->ccgw.src_idx);\n\n\tif (!gwj->src.dev)\n\t\tgoto out;\n\n\tif (gwj->src.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->dst.dev = __dev_get_by_index(&init_net, gwj->ccgw.dst_idx);\n\n\tif (!gwj->dst.dev)\n\t\tgoto out;\n\n\tif (gwj->dst.dev->type != ARPHRD_CAN)\n\t\tgoto out;\n\n\tgwj->limit_hops = limhops;\n\n\tASSERT_RTNL();\n\n\terr = cgw_register_filter(gwj);\n\tif (!err)\n\t\thlist_add_head_rcu(&gwj->list, &cgw_list);\nout:\n\tif (err)\n\t\tkmem_cache_free(cgw_cache, gwj);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n \tu8 limhops = 0;\n \tint err = 0;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (nlmsg_len(nlh) < sizeof(*r))",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/genl_family_rcv_msg",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int genl_family_rcv_msg(struct genl_family *family,\n\t\t\t       struct sk_buff *skb,\n\t\t\t       struct nlmsghdr *nlh)\n{\n\tconst struct genl_ops *ops;\n\tstruct net *net = sock_net(skb->sk);\n\tstruct genl_info info;\n\tstruct genlmsghdr *hdr = nlmsg_data(nlh);\n\tstruct nlattr **attrbuf;\n\tint hdrlen, err;\n\n\t/* this family doesn't exist in this netns */\n\tif (!family->netnsok && !net_eq(net, &init_net))\n\t\treturn -ENOENT;\n\n\thdrlen = GENL_HDRLEN + family->hdrsize;\n\tif (nlh->nlmsg_len < nlmsg_msg_size(hdrlen))\n\t\treturn -EINVAL;\n\n\tops = genl_get_cmd(hdr->cmd, family);\n\tif (ops == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\tif ((ops->flags & GENL_ADMIN_PERM) &&\n\t    !capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif ((nlh->nlmsg_flags & NLM_F_DUMP) == NLM_F_DUMP) {\n\t\tint rc;\n\n\t\tif (ops->dumpit == NULL)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif (!family->parallel_ops) {\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.module = family->module,\n\t\t\t\t/* we have const, but the netlink API doesn't */\n\t\t\t\t.data = (void *)ops,\n\t\t\t\t.dump = genl_lock_dumpit,\n\t\t\t\t.done = genl_lock_done,\n\t\t\t};\n\n\t\t\tgenl_unlock();\n\t\t\trc = __netlink_dump_start(net->genl_sock, skb, nlh, &c);\n\t\t\tgenl_lock();\n\n\t\t} else {\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.module = family->module,\n\t\t\t\t.dump = ops->dumpit,\n\t\t\t\t.done = ops->done,\n\t\t\t};\n\n\t\t\trc = __netlink_dump_start(net->genl_sock, skb, nlh, &c);\n\t\t}\n\n\t\treturn rc;\n\t}\n\n\tif (ops->doit == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\tif (family->maxattr && family->parallel_ops) {\n\t\tattrbuf = kmalloc((family->maxattr+1) *\n\t\t\t\t\tsizeof(struct nlattr *), GFP_KERNEL);\n\t\tif (attrbuf == NULL)\n\t\t\treturn -ENOMEM;\n\t} else\n\t\tattrbuf = family->attrbuf;\n\n\tif (attrbuf) {\n\t\terr = nlmsg_parse(nlh, hdrlen, attrbuf, family->maxattr,\n\t\t\t\t  ops->policy);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tinfo.snd_seq = nlh->nlmsg_seq;\n\tinfo.snd_portid = NETLINK_CB(skb).portid;\n\tinfo.nlhdr = nlh;\n\tinfo.genlhdr = nlmsg_data(nlh);\n\tinfo.userhdr = nlmsg_data(nlh) + GENL_HDRLEN;\n\tinfo.attrs = attrbuf;\n\tinfo.dst_sk = skb->sk;\n\tgenl_info_net_set(&info, net);\n\tmemset(&info.user_ptr, 0, sizeof(info.user_ptr));\n\n\tif (family->pre_doit) {\n\t\terr = family->pre_doit(ops, skb, &info);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\terr = ops->doit(skb, &info);\n\n\tif (family->post_doit)\n\t\tfamily->post_doit(ops, skb, &info);\n\nout:\n\tif (family->parallel_ops)\n\t\tkfree(attrbuf);\n\n\treturn err;\n}",
        "func": "static int genl_family_rcv_msg(struct genl_family *family,\n\t\t\t       struct sk_buff *skb,\n\t\t\t       struct nlmsghdr *nlh)\n{\n\tconst struct genl_ops *ops;\n\tstruct net *net = sock_net(skb->sk);\n\tstruct genl_info info;\n\tstruct genlmsghdr *hdr = nlmsg_data(nlh);\n\tstruct nlattr **attrbuf;\n\tint hdrlen, err;\n\n\t/* this family doesn't exist in this netns */\n\tif (!family->netnsok && !net_eq(net, &init_net))\n\t\treturn -ENOENT;\n\n\thdrlen = GENL_HDRLEN + family->hdrsize;\n\tif (nlh->nlmsg_len < nlmsg_msg_size(hdrlen))\n\t\treturn -EINVAL;\n\n\tops = genl_get_cmd(hdr->cmd, family);\n\tif (ops == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\tif ((ops->flags & GENL_ADMIN_PERM) &&\n\t    !netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif ((nlh->nlmsg_flags & NLM_F_DUMP) == NLM_F_DUMP) {\n\t\tint rc;\n\n\t\tif (ops->dumpit == NULL)\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif (!family->parallel_ops) {\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.module = family->module,\n\t\t\t\t/* we have const, but the netlink API doesn't */\n\t\t\t\t.data = (void *)ops,\n\t\t\t\t.dump = genl_lock_dumpit,\n\t\t\t\t.done = genl_lock_done,\n\t\t\t};\n\n\t\t\tgenl_unlock();\n\t\t\trc = __netlink_dump_start(net->genl_sock, skb, nlh, &c);\n\t\t\tgenl_lock();\n\n\t\t} else {\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.module = family->module,\n\t\t\t\t.dump = ops->dumpit,\n\t\t\t\t.done = ops->done,\n\t\t\t};\n\n\t\t\trc = __netlink_dump_start(net->genl_sock, skb, nlh, &c);\n\t\t}\n\n\t\treturn rc;\n\t}\n\n\tif (ops->doit == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\tif (family->maxattr && family->parallel_ops) {\n\t\tattrbuf = kmalloc((family->maxattr+1) *\n\t\t\t\t\tsizeof(struct nlattr *), GFP_KERNEL);\n\t\tif (attrbuf == NULL)\n\t\t\treturn -ENOMEM;\n\t} else\n\t\tattrbuf = family->attrbuf;\n\n\tif (attrbuf) {\n\t\terr = nlmsg_parse(nlh, hdrlen, attrbuf, family->maxattr,\n\t\t\t\t  ops->policy);\n\t\tif (err < 0)\n\t\t\tgoto out;\n\t}\n\n\tinfo.snd_seq = nlh->nlmsg_seq;\n\tinfo.snd_portid = NETLINK_CB(skb).portid;\n\tinfo.nlhdr = nlh;\n\tinfo.genlhdr = nlmsg_data(nlh);\n\tinfo.userhdr = nlmsg_data(nlh) + GENL_HDRLEN;\n\tinfo.attrs = attrbuf;\n\tinfo.dst_sk = skb->sk;\n\tgenl_info_net_set(&info, net);\n\tmemset(&info.user_ptr, 0, sizeof(info.user_ptr));\n\n\tif (family->pre_doit) {\n\t\terr = family->pre_doit(ops, skb, &info);\n\t\tif (err)\n\t\t\tgoto out;\n\t}\n\n\terr = ops->doit(skb, &info);\n\n\tif (family->post_doit)\n\t\tfamily->post_doit(ops, skb, &info);\n\nout:\n\tif (family->parallel_ops)\n\t\tkfree(attrbuf);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,7 +22,7 @@\n \t\treturn -EOPNOTSUPP;\n \n \tif ((ops->flags & GENL_ADMIN_PERM) &&\n-\t    !capable(CAP_NET_ADMIN))\n+\t    !netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif ((nlh->nlmsg_flags & NLM_F_DUMP) == NLM_F_DUMP) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t    !capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\t    !netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/rtnl_newlink",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int rtnl_newlink(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tconst struct rtnl_link_ops *ops;\n\tconst struct rtnl_link_ops *m_ops = NULL;\n\tstruct net_device *dev;\n\tstruct net_device *master_dev = NULL;\n\tstruct ifinfomsg *ifm;\n\tchar kind[MODULE_NAME_LEN];\n\tchar ifname[IFNAMSIZ];\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tstruct nlattr *linkinfo[IFLA_INFO_MAX+1];\n\tint err;\n\n#ifdef CONFIG_MODULES\nreplay:\n#endif\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[IFLA_IFNAME])\n\t\tnla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);\n\telse\n\t\tifname[0] = '\\0';\n\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifi_index > 0)\n\t\tdev = __dev_get_by_index(net, ifm->ifi_index);\n\telse {\n\t\tif (ifname[0])\n\t\t\tdev = __dev_get_by_name(net, ifname);\n\t\telse\n\t\t\tdev = NULL;\n\t}\n\n\tif (dev) {\n\t\tmaster_dev = netdev_master_upper_dev_get(dev);\n\t\tif (master_dev)\n\t\t\tm_ops = master_dev->rtnl_link_ops;\n\t}\n\n\terr = validate_linkmsg(dev, tb);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[IFLA_LINKINFO]) {\n\t\terr = nla_parse_nested(linkinfo, IFLA_INFO_MAX,\n\t\t\t\t       tb[IFLA_LINKINFO], ifla_info_policy);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t} else\n\t\tmemset(linkinfo, 0, sizeof(linkinfo));\n\n\tif (linkinfo[IFLA_INFO_KIND]) {\n\t\tnla_strlcpy(kind, linkinfo[IFLA_INFO_KIND], sizeof(kind));\n\t\tops = rtnl_link_ops_get(kind);\n\t} else {\n\t\tkind[0] = '\\0';\n\t\tops = NULL;\n\t}\n\n\tif (1) {\n\t\tstruct nlattr *attr[ops ? ops->maxtype + 1 : 0];\n\t\tstruct nlattr *slave_attr[m_ops ? m_ops->slave_maxtype + 1 : 0];\n\t\tstruct nlattr **data = NULL;\n\t\tstruct nlattr **slave_data = NULL;\n\t\tstruct net *dest_net;\n\n\t\tif (ops) {\n\t\t\tif (ops->maxtype && linkinfo[IFLA_INFO_DATA]) {\n\t\t\t\terr = nla_parse_nested(attr, ops->maxtype,\n\t\t\t\t\t\t       linkinfo[IFLA_INFO_DATA],\n\t\t\t\t\t\t       ops->policy);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tdata = attr;\n\t\t\t}\n\t\t\tif (ops->validate) {\n\t\t\t\terr = ops->validate(tb, data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\n\t\tif (m_ops) {\n\t\t\tif (m_ops->slave_maxtype &&\n\t\t\t    linkinfo[IFLA_INFO_SLAVE_DATA]) {\n\t\t\t\terr = nla_parse_nested(slave_attr,\n\t\t\t\t\t\t       m_ops->slave_maxtype,\n\t\t\t\t\t\t       linkinfo[IFLA_INFO_SLAVE_DATA],\n\t\t\t\t\t\t       m_ops->slave_policy);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tslave_data = slave_attr;\n\t\t\t}\n\t\t\tif (m_ops->slave_validate) {\n\t\t\t\terr = m_ops->slave_validate(tb, slave_data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\n\t\tif (dev) {\n\t\t\tint modified = 0;\n\n\t\t\tif (nlh->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\treturn -EEXIST;\n\t\t\tif (nlh->nlmsg_flags & NLM_F_REPLACE)\n\t\t\t\treturn -EOPNOTSUPP;\n\n\t\t\tif (linkinfo[IFLA_INFO_DATA]) {\n\t\t\t\tif (!ops || ops != dev->rtnl_link_ops ||\n\t\t\t\t    !ops->changelink)\n\t\t\t\t\treturn -EOPNOTSUPP;\n\n\t\t\t\terr = ops->changelink(dev, tb, data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tmodified = 1;\n\t\t\t}\n\n\t\t\tif (linkinfo[IFLA_INFO_SLAVE_DATA]) {\n\t\t\t\tif (!m_ops || !m_ops->slave_changelink)\n\t\t\t\t\treturn -EOPNOTSUPP;\n\n\t\t\t\terr = m_ops->slave_changelink(master_dev, dev,\n\t\t\t\t\t\t\t      tb, slave_data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tmodified = 1;\n\t\t\t}\n\n\t\t\treturn do_setlink(dev, ifm, tb, ifname, modified);\n\t\t}\n\n\t\tif (!(nlh->nlmsg_flags & NLM_F_CREATE)) {\n\t\t\tif (ifm->ifi_index == 0 && tb[IFLA_GROUP])\n\t\t\t\treturn rtnl_group_changelink(net,\n\t\t\t\t\t\tnla_get_u32(tb[IFLA_GROUP]),\n\t\t\t\t\t\tifm, tb);\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tif (tb[IFLA_MAP] || tb[IFLA_MASTER] || tb[IFLA_PROTINFO])\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif (!ops) {\n#ifdef CONFIG_MODULES\n\t\t\tif (kind[0]) {\n\t\t\t\t__rtnl_unlock();\n\t\t\t\trequest_module(\"rtnl-link-%s\", kind);\n\t\t\t\trtnl_lock();\n\t\t\t\tops = rtnl_link_ops_get(kind);\n\t\t\t\tif (ops)\n\t\t\t\t\tgoto replay;\n\t\t\t}\n#endif\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (!ifname[0])\n\t\t\tsnprintf(ifname, IFNAMSIZ, \"%s%%d\", ops->kind);\n\n\t\tdest_net = rtnl_link_get_net(net, tb);\n\t\tif (IS_ERR(dest_net))\n\t\t\treturn PTR_ERR(dest_net);\n\n\t\tdev = rtnl_create_link(dest_net, ifname, ops, tb);\n\t\tif (IS_ERR(dev)) {\n\t\t\terr = PTR_ERR(dev);\n\t\t\tgoto out;\n\t\t}\n\n\t\tdev->ifindex = ifm->ifi_index;\n\n\t\tif (ops->newlink) {\n\t\t\terr = ops->newlink(net, dev, tb, data);\n\t\t\t/* Drivers should call free_netdev() in ->destructor\n\t\t\t * and unregister it on failure so that device could be\n\t\t\t * finally freed in rtnl_unlock.\n\t\t\t */\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\terr = register_netdevice(dev);\n\t\t\tif (err < 0) {\n\t\t\t\tfree_netdev(dev);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\terr = rtnl_configure_link(dev, ifm);\n\t\tif (err < 0)\n\t\t\tunregister_netdevice(dev);\nout:\n\t\tput_net(dest_net);\n\t\treturn err;\n\t}\n}",
        "func": "static int rtnl_newlink(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tconst struct rtnl_link_ops *ops;\n\tconst struct rtnl_link_ops *m_ops = NULL;\n\tstruct net_device *dev;\n\tstruct net_device *master_dev = NULL;\n\tstruct ifinfomsg *ifm;\n\tchar kind[MODULE_NAME_LEN];\n\tchar ifname[IFNAMSIZ];\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tstruct nlattr *linkinfo[IFLA_INFO_MAX+1];\n\tint err;\n\n#ifdef CONFIG_MODULES\nreplay:\n#endif\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[IFLA_IFNAME])\n\t\tnla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);\n\telse\n\t\tifname[0] = '\\0';\n\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifi_index > 0)\n\t\tdev = __dev_get_by_index(net, ifm->ifi_index);\n\telse {\n\t\tif (ifname[0])\n\t\t\tdev = __dev_get_by_name(net, ifname);\n\t\telse\n\t\t\tdev = NULL;\n\t}\n\n\tif (dev) {\n\t\tmaster_dev = netdev_master_upper_dev_get(dev);\n\t\tif (master_dev)\n\t\t\tm_ops = master_dev->rtnl_link_ops;\n\t}\n\n\terr = validate_linkmsg(dev, tb);\n\tif (err < 0)\n\t\treturn err;\n\n\tif (tb[IFLA_LINKINFO]) {\n\t\terr = nla_parse_nested(linkinfo, IFLA_INFO_MAX,\n\t\t\t\t       tb[IFLA_LINKINFO], ifla_info_policy);\n\t\tif (err < 0)\n\t\t\treturn err;\n\t} else\n\t\tmemset(linkinfo, 0, sizeof(linkinfo));\n\n\tif (linkinfo[IFLA_INFO_KIND]) {\n\t\tnla_strlcpy(kind, linkinfo[IFLA_INFO_KIND], sizeof(kind));\n\t\tops = rtnl_link_ops_get(kind);\n\t} else {\n\t\tkind[0] = '\\0';\n\t\tops = NULL;\n\t}\n\n\tif (1) {\n\t\tstruct nlattr *attr[ops ? ops->maxtype + 1 : 0];\n\t\tstruct nlattr *slave_attr[m_ops ? m_ops->slave_maxtype + 1 : 0];\n\t\tstruct nlattr **data = NULL;\n\t\tstruct nlattr **slave_data = NULL;\n\t\tstruct net *dest_net;\n\n\t\tif (ops) {\n\t\t\tif (ops->maxtype && linkinfo[IFLA_INFO_DATA]) {\n\t\t\t\terr = nla_parse_nested(attr, ops->maxtype,\n\t\t\t\t\t\t       linkinfo[IFLA_INFO_DATA],\n\t\t\t\t\t\t       ops->policy);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tdata = attr;\n\t\t\t}\n\t\t\tif (ops->validate) {\n\t\t\t\terr = ops->validate(tb, data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\n\t\tif (m_ops) {\n\t\t\tif (m_ops->slave_maxtype &&\n\t\t\t    linkinfo[IFLA_INFO_SLAVE_DATA]) {\n\t\t\t\terr = nla_parse_nested(slave_attr,\n\t\t\t\t\t\t       m_ops->slave_maxtype,\n\t\t\t\t\t\t       linkinfo[IFLA_INFO_SLAVE_DATA],\n\t\t\t\t\t\t       m_ops->slave_policy);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tslave_data = slave_attr;\n\t\t\t}\n\t\t\tif (m_ops->slave_validate) {\n\t\t\t\terr = m_ops->slave_validate(tb, slave_data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t}\n\t\t}\n\n\t\tif (dev) {\n\t\t\tint modified = 0;\n\n\t\t\tif (nlh->nlmsg_flags & NLM_F_EXCL)\n\t\t\t\treturn -EEXIST;\n\t\t\tif (nlh->nlmsg_flags & NLM_F_REPLACE)\n\t\t\t\treturn -EOPNOTSUPP;\n\n\t\t\tif (linkinfo[IFLA_INFO_DATA]) {\n\t\t\t\tif (!ops || ops != dev->rtnl_link_ops ||\n\t\t\t\t    !ops->changelink)\n\t\t\t\t\treturn -EOPNOTSUPP;\n\n\t\t\t\terr = ops->changelink(dev, tb, data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tmodified = 1;\n\t\t\t}\n\n\t\t\tif (linkinfo[IFLA_INFO_SLAVE_DATA]) {\n\t\t\t\tif (!m_ops || !m_ops->slave_changelink)\n\t\t\t\t\treturn -EOPNOTSUPP;\n\n\t\t\t\terr = m_ops->slave_changelink(master_dev, dev,\n\t\t\t\t\t\t\t      tb, slave_data);\n\t\t\t\tif (err < 0)\n\t\t\t\t\treturn err;\n\t\t\t\tmodified = 1;\n\t\t\t}\n\n\t\t\treturn do_setlink(skb, dev, ifm, tb, ifname, modified);\n\t\t}\n\n\t\tif (!(nlh->nlmsg_flags & NLM_F_CREATE)) {\n\t\t\tif (ifm->ifi_index == 0 && tb[IFLA_GROUP])\n\t\t\t\treturn rtnl_group_changelink(skb, net,\n\t\t\t\t\t\tnla_get_u32(tb[IFLA_GROUP]),\n\t\t\t\t\t\tifm, tb);\n\t\t\treturn -ENODEV;\n\t\t}\n\n\t\tif (tb[IFLA_MAP] || tb[IFLA_MASTER] || tb[IFLA_PROTINFO])\n\t\t\treturn -EOPNOTSUPP;\n\n\t\tif (!ops) {\n#ifdef CONFIG_MODULES\n\t\t\tif (kind[0]) {\n\t\t\t\t__rtnl_unlock();\n\t\t\t\trequest_module(\"rtnl-link-%s\", kind);\n\t\t\t\trtnl_lock();\n\t\t\t\tops = rtnl_link_ops_get(kind);\n\t\t\t\tif (ops)\n\t\t\t\t\tgoto replay;\n\t\t\t}\n#endif\n\t\t\treturn -EOPNOTSUPP;\n\t\t}\n\n\t\tif (!ifname[0])\n\t\t\tsnprintf(ifname, IFNAMSIZ, \"%s%%d\", ops->kind);\n\n\t\tdest_net = rtnl_link_get_net(net, tb);\n\t\tif (IS_ERR(dest_net))\n\t\t\treturn PTR_ERR(dest_net);\n\n\t\tdev = rtnl_create_link(dest_net, ifname, ops, tb);\n\t\tif (IS_ERR(dev)) {\n\t\t\terr = PTR_ERR(dev);\n\t\t\tgoto out;\n\t\t}\n\n\t\tdev->ifindex = ifm->ifi_index;\n\n\t\tif (ops->newlink) {\n\t\t\terr = ops->newlink(net, dev, tb, data);\n\t\t\t/* Drivers should call free_netdev() in ->destructor\n\t\t\t * and unregister it on failure so that device could be\n\t\t\t * finally freed in rtnl_unlock.\n\t\t\t */\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\terr = register_netdevice(dev);\n\t\t\tif (err < 0) {\n\t\t\t\tfree_netdev(dev);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\terr = rtnl_configure_link(dev, ifm);\n\t\tif (err < 0)\n\t\t\tunregister_netdevice(dev);\nout:\n\t\tput_net(dest_net);\n\t\treturn err;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -131,12 +131,12 @@\n \t\t\t\tmodified = 1;\n \t\t\t}\n \n-\t\t\treturn do_setlink(dev, ifm, tb, ifname, modified);\n+\t\t\treturn do_setlink(skb, dev, ifm, tb, ifname, modified);\n \t\t}\n \n \t\tif (!(nlh->nlmsg_flags & NLM_F_CREATE)) {\n \t\t\tif (ifm->ifi_index == 0 && tb[IFLA_GROUP])\n-\t\t\t\treturn rtnl_group_changelink(net,\n+\t\t\t\treturn rtnl_group_changelink(skb, net,\n \t\t\t\t\t\tnla_get_u32(tb[IFLA_GROUP]),\n \t\t\t\t\t\tifm, tb);\n \t\t\treturn -ENODEV;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\treturn do_setlink(dev, ifm, tb, ifname, modified);",
                "\t\t\t\treturn rtnl_group_changelink(net,"
            ],
            "added_lines": [
                "\t\t\treturn do_setlink(skb, dev, ifm, tb, ifname, modified);",
                "\t\t\t\treturn rtnl_group_changelink(skb, net,"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/rtnl_fdb_del",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int rtnl_fdb_del(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ndmsg *ndm;\n\tstruct nlattr *tb[NDA_MAX+1];\n\tstruct net_device *dev;\n\tint err = -EINVAL;\n\t__u8 *addr;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tndm = nlmsg_data(nlh);\n\tif (ndm->ndm_ifindex == 0) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid ifindex\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = __dev_get_by_index(net, ndm->ndm_ifindex);\n\tif (dev == NULL) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with unknown ifindex\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!tb[NDA_LLADDR] || nla_len(tb[NDA_LLADDR]) != ETH_ALEN) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid address\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\taddr = nla_data(tb[NDA_LLADDR]);\n\n\terr = -EOPNOTSUPP;\n\n\t/* Support fdb on master device the net/bridge default case */\n\tif ((!ndm->ndm_flags || ndm->ndm_flags & NTF_MASTER) &&\n\t    (dev->priv_flags & IFF_BRIDGE_PORT)) {\n\t\tstruct net_device *br_dev = netdev_master_upper_dev_get(dev);\n\t\tconst struct net_device_ops *ops = br_dev->netdev_ops;\n\n\t\tif (ops->ndo_fdb_del)\n\t\t\terr = ops->ndo_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (err)\n\t\t\tgoto out;\n\t\telse\n\t\t\tndm->ndm_flags &= ~NTF_MASTER;\n\t}\n\n\t/* Embedded bridge, macvlan, and any other device support */\n\tif (ndm->ndm_flags & NTF_SELF) {\n\t\tif (dev->netdev_ops->ndo_fdb_del)\n\t\t\terr = dev->netdev_ops->ndo_fdb_del(ndm, tb, dev, addr);\n\t\telse\n\t\t\terr = ndo_dflt_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (!err) {\n\t\t\trtnl_fdb_notify(dev, addr, RTM_DELNEIGH);\n\t\t\tndm->ndm_flags &= ~NTF_SELF;\n\t\t}\n\t}\nout:\n\treturn err;\n}",
        "func": "static int rtnl_fdb_del(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ndmsg *ndm;\n\tstruct nlattr *tb[NDA_MAX+1];\n\tstruct net_device *dev;\n\tint err = -EINVAL;\n\t__u8 *addr;\n\n\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\terr = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);\n\tif (err < 0)\n\t\treturn err;\n\n\tndm = nlmsg_data(nlh);\n\tif (ndm->ndm_ifindex == 0) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid ifindex\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tdev = __dev_get_by_index(net, ndm->ndm_ifindex);\n\tif (dev == NULL) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with unknown ifindex\\n\");\n\t\treturn -ENODEV;\n\t}\n\n\tif (!tb[NDA_LLADDR] || nla_len(tb[NDA_LLADDR]) != ETH_ALEN) {\n\t\tpr_info(\"PF_BRIDGE: RTM_DELNEIGH with invalid address\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\taddr = nla_data(tb[NDA_LLADDR]);\n\n\terr = -EOPNOTSUPP;\n\n\t/* Support fdb on master device the net/bridge default case */\n\tif ((!ndm->ndm_flags || ndm->ndm_flags & NTF_MASTER) &&\n\t    (dev->priv_flags & IFF_BRIDGE_PORT)) {\n\t\tstruct net_device *br_dev = netdev_master_upper_dev_get(dev);\n\t\tconst struct net_device_ops *ops = br_dev->netdev_ops;\n\n\t\tif (ops->ndo_fdb_del)\n\t\t\terr = ops->ndo_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (err)\n\t\t\tgoto out;\n\t\telse\n\t\t\tndm->ndm_flags &= ~NTF_MASTER;\n\t}\n\n\t/* Embedded bridge, macvlan, and any other device support */\n\tif (ndm->ndm_flags & NTF_SELF) {\n\t\tif (dev->netdev_ops->ndo_fdb_del)\n\t\t\terr = dev->netdev_ops->ndo_fdb_del(ndm, tb, dev, addr);\n\t\telse\n\t\t\terr = ndo_dflt_fdb_del(ndm, tb, dev, addr);\n\n\t\tif (!err) {\n\t\t\trtnl_fdb_notify(dev, addr, RTM_DELNEIGH);\n\t\t\tndm->ndm_flags &= ~NTF_SELF;\n\t\t}\n\t}\nout:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,7 @@\n \tint err = -EINVAL;\n \t__u8 *addr;\n \n-\tif (!capable(CAP_NET_ADMIN))\n+\tif (!netlink_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \terr = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!capable(CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (!netlink_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/rtnl_group_changelink",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int rtnl_group_changelink(struct net *net, int group,\n\t\tstruct ifinfomsg *ifm,\n\t\tstruct nlattr **tb)\n{\n\tstruct net_device *dev;\n\tint err;\n\n\tfor_each_netdev(net, dev) {\n\t\tif (dev->group == group) {\n\t\t\terr = do_setlink(dev, ifm, tb, NULL, 0);\n\t\t\tif (err < 0)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "func": "static int rtnl_group_changelink(const struct sk_buff *skb,\n\t\tstruct net *net, int group,\n\t\tstruct ifinfomsg *ifm,\n\t\tstruct nlattr **tb)\n{\n\tstruct net_device *dev;\n\tint err;\n\n\tfor_each_netdev(net, dev) {\n\t\tif (dev->group == group) {\n\t\t\terr = do_setlink(skb, dev, ifm, tb, NULL, 0);\n\t\t\tif (err < 0)\n\t\t\t\treturn err;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-static int rtnl_group_changelink(struct net *net, int group,\n+static int rtnl_group_changelink(const struct sk_buff *skb,\n+\t\tstruct net *net, int group,\n \t\tstruct ifinfomsg *ifm,\n \t\tstruct nlattr **tb)\n {\n@@ -7,7 +8,7 @@\n \n \tfor_each_netdev(net, dev) {\n \t\tif (dev->group == group) {\n-\t\t\terr = do_setlink(dev, ifm, tb, NULL, 0);\n+\t\t\terr = do_setlink(skb, dev, ifm, tb, NULL, 0);\n \t\t\tif (err < 0)\n \t\t\t\treturn err;\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "static int rtnl_group_changelink(struct net *net, int group,",
                "\t\t\terr = do_setlink(dev, ifm, tb, NULL, 0);"
            ],
            "added_lines": [
                "static int rtnl_group_changelink(const struct sk_buff *skb,",
                "\t\tstruct net *net, int group,",
                "\t\t\terr = do_setlink(skb, dev, ifm, tb, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/rtnetlink_rcv_msg",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int rtnetlink_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\trtnl_doit_func doit;\n\tint sz_idx, kind;\n\tint family;\n\tint type;\n\tint err;\n\n\ttype = nlh->nlmsg_type;\n\tif (type > RTM_MAX)\n\t\treturn -EOPNOTSUPP;\n\n\ttype -= RTM_BASE;\n\n\t/* All the messages must have at least 1 byte length */\n\tif (nlmsg_len(nlh) < sizeof(struct rtgenmsg))\n\t\treturn 0;\n\n\tfamily = ((struct rtgenmsg *)nlmsg_data(nlh))->rtgen_family;\n\tsz_idx = type>>2;\n\tkind = type&3;\n\n\tif (kind != 2 && !ns_capable(net->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (kind == 2 && nlh->nlmsg_flags&NLM_F_DUMP) {\n\t\tstruct sock *rtnl;\n\t\trtnl_dumpit_func dumpit;\n\t\trtnl_calcit_func calcit;\n\t\tu16 min_dump_alloc = 0;\n\n\t\tdumpit = rtnl_get_dumpit(family, type);\n\t\tif (dumpit == NULL)\n\t\t\treturn -EOPNOTSUPP;\n\t\tcalcit = rtnl_get_calcit(family, type);\n\t\tif (calcit)\n\t\t\tmin_dump_alloc = calcit(skb, nlh);\n\n\t\t__rtnl_unlock();\n\t\trtnl = net->rtnl;\n\t\t{\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.dump\t\t= dumpit,\n\t\t\t\t.min_dump_alloc\t= min_dump_alloc,\n\t\t\t};\n\t\t\terr = netlink_dump_start(rtnl, skb, nlh, &c);\n\t\t}\n\t\trtnl_lock();\n\t\treturn err;\n\t}\n\n\tdoit = rtnl_get_doit(family, type);\n\tif (doit == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\treturn doit(skb, nlh);\n}",
        "func": "static int rtnetlink_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\trtnl_doit_func doit;\n\tint sz_idx, kind;\n\tint family;\n\tint type;\n\tint err;\n\n\ttype = nlh->nlmsg_type;\n\tif (type > RTM_MAX)\n\t\treturn -EOPNOTSUPP;\n\n\ttype -= RTM_BASE;\n\n\t/* All the messages must have at least 1 byte length */\n\tif (nlmsg_len(nlh) < sizeof(struct rtgenmsg))\n\t\treturn 0;\n\n\tfamily = ((struct rtgenmsg *)nlmsg_data(nlh))->rtgen_family;\n\tsz_idx = type>>2;\n\tkind = type&3;\n\n\tif (kind != 2 && !netlink_net_capable(skb, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (kind == 2 && nlh->nlmsg_flags&NLM_F_DUMP) {\n\t\tstruct sock *rtnl;\n\t\trtnl_dumpit_func dumpit;\n\t\trtnl_calcit_func calcit;\n\t\tu16 min_dump_alloc = 0;\n\n\t\tdumpit = rtnl_get_dumpit(family, type);\n\t\tif (dumpit == NULL)\n\t\t\treturn -EOPNOTSUPP;\n\t\tcalcit = rtnl_get_calcit(family, type);\n\t\tif (calcit)\n\t\t\tmin_dump_alloc = calcit(skb, nlh);\n\n\t\t__rtnl_unlock();\n\t\trtnl = net->rtnl;\n\t\t{\n\t\t\tstruct netlink_dump_control c = {\n\t\t\t\t.dump\t\t= dumpit,\n\t\t\t\t.min_dump_alloc\t= min_dump_alloc,\n\t\t\t};\n\t\t\terr = netlink_dump_start(rtnl, skb, nlh, &c);\n\t\t}\n\t\trtnl_lock();\n\t\treturn err;\n\t}\n\n\tdoit = rtnl_get_doit(family, type);\n\tif (doit == NULL)\n\t\treturn -EOPNOTSUPP;\n\n\treturn doit(skb, nlh);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,7 +21,7 @@\n \tsz_idx = type>>2;\n \tkind = type&3;\n \n-\tif (kind != 2 && !ns_capable(net->user_ns, CAP_NET_ADMIN))\n+\tif (kind != 2 && !netlink_net_capable(skb, CAP_NET_ADMIN))\n \t\treturn -EPERM;\n \n \tif (kind == 2 && nlh->nlmsg_flags&NLM_F_DUMP) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (kind != 2 && !ns_capable(net->user_ns, CAP_NET_ADMIN))"
            ],
            "added_lines": [
                "\tif (kind != 2 && !netlink_net_capable(skb, CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/do_setlink",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int do_setlink(struct net_device *dev, struct ifinfomsg *ifm,\n\t\t      struct nlattr **tb, char *ifname, int modified)\n{\n\tconst struct net_device_ops *ops = dev->netdev_ops;\n\tint err;\n\n\tif (tb[IFLA_NET_NS_PID] || tb[IFLA_NET_NS_FD]) {\n\t\tstruct net *net = rtnl_link_get_net(dev_net(dev), tb);\n\t\tif (IS_ERR(net)) {\n\t\t\terr = PTR_ERR(net);\n\t\t\tgoto errout;\n\t\t}\n\t\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN)) {\n\t\t\terr = -EPERM;\n\t\t\tgoto errout;\n\t\t}\n\t\terr = dev_change_net_namespace(dev, net, ifname);\n\t\tput_net(net);\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_MAP]) {\n\t\tstruct rtnl_link_ifmap *u_map;\n\t\tstruct ifmap k_map;\n\n\t\tif (!ops->ndo_set_config) {\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto errout;\n\t\t}\n\n\t\tif (!netif_device_present(dev)) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto errout;\n\t\t}\n\n\t\tu_map = nla_data(tb[IFLA_MAP]);\n\t\tk_map.mem_start = (unsigned long) u_map->mem_start;\n\t\tk_map.mem_end = (unsigned long) u_map->mem_end;\n\t\tk_map.base_addr = (unsigned short) u_map->base_addr;\n\t\tk_map.irq = (unsigned char) u_map->irq;\n\t\tk_map.dma = (unsigned char) u_map->dma;\n\t\tk_map.port = (unsigned char) u_map->port;\n\n\t\terr = ops->ndo_set_config(dev, &k_map);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_ADDRESS]) {\n\t\tstruct sockaddr *sa;\n\t\tint len;\n\n\t\tlen = sizeof(sa_family_t) + dev->addr_len;\n\t\tsa = kmalloc(len, GFP_KERNEL);\n\t\tif (!sa) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto errout;\n\t\t}\n\t\tsa->sa_family = dev->type;\n\t\tmemcpy(sa->sa_data, nla_data(tb[IFLA_ADDRESS]),\n\t\t       dev->addr_len);\n\t\terr = dev_set_mac_address(dev, sa);\n\t\tkfree(sa);\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_MTU]) {\n\t\terr = dev_set_mtu(dev, nla_get_u32(tb[IFLA_MTU]));\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_GROUP]) {\n\t\tdev_set_group(dev, nla_get_u32(tb[IFLA_GROUP]));\n\t\tmodified = 1;\n\t}\n\n\t/*\n\t * Interface selected by interface index but interface\n\t * name provided implies that a name change has been\n\t * requested.\n\t */\n\tif (ifm->ifi_index > 0 && ifname[0]) {\n\t\terr = dev_change_name(dev, ifname);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_IFALIAS]) {\n\t\terr = dev_set_alias(dev, nla_data(tb[IFLA_IFALIAS]),\n\t\t\t\t    nla_len(tb[IFLA_IFALIAS]));\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_BROADCAST]) {\n\t\tnla_memcpy(dev->broadcast, tb[IFLA_BROADCAST], dev->addr_len);\n\t\tcall_netdevice_notifiers(NETDEV_CHANGEADDR, dev);\n\t}\n\n\tif (ifm->ifi_flags || ifm->ifi_change) {\n\t\terr = dev_change_flags(dev, rtnl_dev_combine_flags(dev, ifm));\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t}\n\n\tif (tb[IFLA_MASTER]) {\n\t\terr = do_set_master(dev, nla_get_u32(tb[IFLA_MASTER]));\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_CARRIER]) {\n\t\terr = dev_change_carrier(dev, nla_get_u8(tb[IFLA_CARRIER]));\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_TXQLEN])\n\t\tdev->tx_queue_len = nla_get_u32(tb[IFLA_TXQLEN]);\n\n\tif (tb[IFLA_OPERSTATE])\n\t\tset_operstate(dev, nla_get_u8(tb[IFLA_OPERSTATE]));\n\n\tif (tb[IFLA_LINKMODE]) {\n\t\twrite_lock_bh(&dev_base_lock);\n\t\tdev->link_mode = nla_get_u8(tb[IFLA_LINKMODE]);\n\t\twrite_unlock_bh(&dev_base_lock);\n\t}\n\n\tif (tb[IFLA_VFINFO_LIST]) {\n\t\tstruct nlattr *attr;\n\t\tint rem;\n\t\tnla_for_each_nested(attr, tb[IFLA_VFINFO_LIST], rem) {\n\t\t\tif (nla_type(attr) != IFLA_VF_INFO) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\terr = do_setvfinfo(dev, attr);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\t\t\tmodified = 1;\n\t\t}\n\t}\n\terr = 0;\n\n\tif (tb[IFLA_VF_PORTS]) {\n\t\tstruct nlattr *port[IFLA_PORT_MAX+1];\n\t\tstruct nlattr *attr;\n\t\tint vf;\n\t\tint rem;\n\n\t\terr = -EOPNOTSUPP;\n\t\tif (!ops->ndo_set_vf_port)\n\t\t\tgoto errout;\n\n\t\tnla_for_each_nested(attr, tb[IFLA_VF_PORTS], rem) {\n\t\t\tif (nla_type(attr) != IFLA_VF_PORT)\n\t\t\t\tcontinue;\n\t\t\terr = nla_parse_nested(port, IFLA_PORT_MAX,\n\t\t\t\tattr, ifla_port_policy);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\t\t\tif (!port[IFLA_PORT_VF]) {\n\t\t\t\terr = -EOPNOTSUPP;\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\tvf = nla_get_u32(port[IFLA_PORT_VF]);\n\t\t\terr = ops->ndo_set_vf_port(dev, vf, port);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\t\t\tmodified = 1;\n\t\t}\n\t}\n\terr = 0;\n\n\tif (tb[IFLA_PORT_SELF]) {\n\t\tstruct nlattr *port[IFLA_PORT_MAX+1];\n\n\t\terr = nla_parse_nested(port, IFLA_PORT_MAX,\n\t\t\ttb[IFLA_PORT_SELF], ifla_port_policy);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\n\t\terr = -EOPNOTSUPP;\n\t\tif (ops->ndo_set_vf_port)\n\t\t\terr = ops->ndo_set_vf_port(dev, PORT_SELF_VF, port);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_AF_SPEC]) {\n\t\tstruct nlattr *af;\n\t\tint rem;\n\n\t\tnla_for_each_nested(af, tb[IFLA_AF_SPEC], rem) {\n\t\t\tconst struct rtnl_af_ops *af_ops;\n\n\t\t\tif (!(af_ops = rtnl_af_lookup(nla_type(af))))\n\t\t\t\tBUG();\n\n\t\t\terr = af_ops->set_link_af(dev, af);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\n\t\t\tmodified = 1;\n\t\t}\n\t}\n\terr = 0;\n\nerrout:\n\tif (err < 0 && modified)\n\t\tnet_warn_ratelimited(\"A link change request failed with some changes committed already. Interface %s may have been left with an inconsistent configuration, please check.\\n\",\n\t\t\t\t     dev->name);\n\n\treturn err;\n}",
        "func": "static int do_setlink(const struct sk_buff *skb,\n\t\t      struct net_device *dev, struct ifinfomsg *ifm,\n\t\t      struct nlattr **tb, char *ifname, int modified)\n{\n\tconst struct net_device_ops *ops = dev->netdev_ops;\n\tint err;\n\n\tif (tb[IFLA_NET_NS_PID] || tb[IFLA_NET_NS_FD]) {\n\t\tstruct net *net = rtnl_link_get_net(dev_net(dev), tb);\n\t\tif (IS_ERR(net)) {\n\t\t\terr = PTR_ERR(net);\n\t\t\tgoto errout;\n\t\t}\n\t\tif (!netlink_ns_capable(skb, net->user_ns, CAP_NET_ADMIN)) {\n\t\t\terr = -EPERM;\n\t\t\tgoto errout;\n\t\t}\n\t\terr = dev_change_net_namespace(dev, net, ifname);\n\t\tput_net(net);\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_MAP]) {\n\t\tstruct rtnl_link_ifmap *u_map;\n\t\tstruct ifmap k_map;\n\n\t\tif (!ops->ndo_set_config) {\n\t\t\terr = -EOPNOTSUPP;\n\t\t\tgoto errout;\n\t\t}\n\n\t\tif (!netif_device_present(dev)) {\n\t\t\terr = -ENODEV;\n\t\t\tgoto errout;\n\t\t}\n\n\t\tu_map = nla_data(tb[IFLA_MAP]);\n\t\tk_map.mem_start = (unsigned long) u_map->mem_start;\n\t\tk_map.mem_end = (unsigned long) u_map->mem_end;\n\t\tk_map.base_addr = (unsigned short) u_map->base_addr;\n\t\tk_map.irq = (unsigned char) u_map->irq;\n\t\tk_map.dma = (unsigned char) u_map->dma;\n\t\tk_map.port = (unsigned char) u_map->port;\n\n\t\terr = ops->ndo_set_config(dev, &k_map);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_ADDRESS]) {\n\t\tstruct sockaddr *sa;\n\t\tint len;\n\n\t\tlen = sizeof(sa_family_t) + dev->addr_len;\n\t\tsa = kmalloc(len, GFP_KERNEL);\n\t\tif (!sa) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto errout;\n\t\t}\n\t\tsa->sa_family = dev->type;\n\t\tmemcpy(sa->sa_data, nla_data(tb[IFLA_ADDRESS]),\n\t\t       dev->addr_len);\n\t\terr = dev_set_mac_address(dev, sa);\n\t\tkfree(sa);\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_MTU]) {\n\t\terr = dev_set_mtu(dev, nla_get_u32(tb[IFLA_MTU]));\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_GROUP]) {\n\t\tdev_set_group(dev, nla_get_u32(tb[IFLA_GROUP]));\n\t\tmodified = 1;\n\t}\n\n\t/*\n\t * Interface selected by interface index but interface\n\t * name provided implies that a name change has been\n\t * requested.\n\t */\n\tif (ifm->ifi_index > 0 && ifname[0]) {\n\t\terr = dev_change_name(dev, ifname);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_IFALIAS]) {\n\t\terr = dev_set_alias(dev, nla_data(tb[IFLA_IFALIAS]),\n\t\t\t\t    nla_len(tb[IFLA_IFALIAS]));\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_BROADCAST]) {\n\t\tnla_memcpy(dev->broadcast, tb[IFLA_BROADCAST], dev->addr_len);\n\t\tcall_netdevice_notifiers(NETDEV_CHANGEADDR, dev);\n\t}\n\n\tif (ifm->ifi_flags || ifm->ifi_change) {\n\t\terr = dev_change_flags(dev, rtnl_dev_combine_flags(dev, ifm));\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t}\n\n\tif (tb[IFLA_MASTER]) {\n\t\terr = do_set_master(dev, nla_get_u32(tb[IFLA_MASTER]));\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_CARRIER]) {\n\t\terr = dev_change_carrier(dev, nla_get_u8(tb[IFLA_CARRIER]));\n\t\tif (err)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_TXQLEN])\n\t\tdev->tx_queue_len = nla_get_u32(tb[IFLA_TXQLEN]);\n\n\tif (tb[IFLA_OPERSTATE])\n\t\tset_operstate(dev, nla_get_u8(tb[IFLA_OPERSTATE]));\n\n\tif (tb[IFLA_LINKMODE]) {\n\t\twrite_lock_bh(&dev_base_lock);\n\t\tdev->link_mode = nla_get_u8(tb[IFLA_LINKMODE]);\n\t\twrite_unlock_bh(&dev_base_lock);\n\t}\n\n\tif (tb[IFLA_VFINFO_LIST]) {\n\t\tstruct nlattr *attr;\n\t\tint rem;\n\t\tnla_for_each_nested(attr, tb[IFLA_VFINFO_LIST], rem) {\n\t\t\tif (nla_type(attr) != IFLA_VF_INFO) {\n\t\t\t\terr = -EINVAL;\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\terr = do_setvfinfo(dev, attr);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\t\t\tmodified = 1;\n\t\t}\n\t}\n\terr = 0;\n\n\tif (tb[IFLA_VF_PORTS]) {\n\t\tstruct nlattr *port[IFLA_PORT_MAX+1];\n\t\tstruct nlattr *attr;\n\t\tint vf;\n\t\tint rem;\n\n\t\terr = -EOPNOTSUPP;\n\t\tif (!ops->ndo_set_vf_port)\n\t\t\tgoto errout;\n\n\t\tnla_for_each_nested(attr, tb[IFLA_VF_PORTS], rem) {\n\t\t\tif (nla_type(attr) != IFLA_VF_PORT)\n\t\t\t\tcontinue;\n\t\t\terr = nla_parse_nested(port, IFLA_PORT_MAX,\n\t\t\t\tattr, ifla_port_policy);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\t\t\tif (!port[IFLA_PORT_VF]) {\n\t\t\t\terr = -EOPNOTSUPP;\n\t\t\t\tgoto errout;\n\t\t\t}\n\t\t\tvf = nla_get_u32(port[IFLA_PORT_VF]);\n\t\t\terr = ops->ndo_set_vf_port(dev, vf, port);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\t\t\tmodified = 1;\n\t\t}\n\t}\n\terr = 0;\n\n\tif (tb[IFLA_PORT_SELF]) {\n\t\tstruct nlattr *port[IFLA_PORT_MAX+1];\n\n\t\terr = nla_parse_nested(port, IFLA_PORT_MAX,\n\t\t\ttb[IFLA_PORT_SELF], ifla_port_policy);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\n\t\terr = -EOPNOTSUPP;\n\t\tif (ops->ndo_set_vf_port)\n\t\t\terr = ops->ndo_set_vf_port(dev, PORT_SELF_VF, port);\n\t\tif (err < 0)\n\t\t\tgoto errout;\n\t\tmodified = 1;\n\t}\n\n\tif (tb[IFLA_AF_SPEC]) {\n\t\tstruct nlattr *af;\n\t\tint rem;\n\n\t\tnla_for_each_nested(af, tb[IFLA_AF_SPEC], rem) {\n\t\t\tconst struct rtnl_af_ops *af_ops;\n\n\t\t\tif (!(af_ops = rtnl_af_lookup(nla_type(af))))\n\t\t\t\tBUG();\n\n\t\t\terr = af_ops->set_link_af(dev, af);\n\t\t\tif (err < 0)\n\t\t\t\tgoto errout;\n\n\t\t\tmodified = 1;\n\t\t}\n\t}\n\terr = 0;\n\nerrout:\n\tif (err < 0 && modified)\n\t\tnet_warn_ratelimited(\"A link change request failed with some changes committed already. Interface %s may have been left with an inconsistent configuration, please check.\\n\",\n\t\t\t\t     dev->name);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-static int do_setlink(struct net_device *dev, struct ifinfomsg *ifm,\n+static int do_setlink(const struct sk_buff *skb,\n+\t\t      struct net_device *dev, struct ifinfomsg *ifm,\n \t\t      struct nlattr **tb, char *ifname, int modified)\n {\n \tconst struct net_device_ops *ops = dev->netdev_ops;\n@@ -10,7 +11,7 @@\n \t\t\terr = PTR_ERR(net);\n \t\t\tgoto errout;\n \t\t}\n-\t\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN)) {\n+\t\tif (!netlink_ns_capable(skb, net->user_ns, CAP_NET_ADMIN)) {\n \t\t\terr = -EPERM;\n \t\t\tgoto errout;\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "static int do_setlink(struct net_device *dev, struct ifinfomsg *ifm,",
                "\t\tif (!ns_capable(net->user_ns, CAP_NET_ADMIN)) {"
            ],
            "added_lines": [
                "static int do_setlink(const struct sk_buff *skb,",
                "\t\t      struct net_device *dev, struct ifinfomsg *ifm,",
                "\t\tif (!netlink_ns_capable(skb, net->user_ns, CAP_NET_ADMIN)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-0181",
        "func_name": "kernel/git/netdev/net/rtnl_setlink",
        "description": "The Netlink implementation in the Linux kernel through 3.14.1 does not provide a mechanism for authorizing socket operations based on the opener of a socket, which allows local users to bypass intended access restrictions and modify network configurations by using a Netlink socket for the (1) stdout or (2) stderr of a setuid program.",
        "git_url": "https://git.kernel.org/cgit/linux/kernel/git/davem/net.git/commit/?h=90f62cf30a78721641e08737bda787552428061e",
        "commit_title": "It is possible by passing a netlink socket to a more privileged",
        "commit_text": "executable and then to fool that executable into writing to the socket data that happens to be valid netlink message to do something that privileged executable did not intend to do.  To keep this from happening replace bare capable and ns_capable calls with netlink_capable, netlink_net_calls and netlink_ns_capable calls. Which act the same as the previous calls except they verify that the opener of the socket had the desired permissions as well.  ",
        "func_before": "static int rtnl_setlink(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ifinfomsg *ifm;\n\tstruct net_device *dev;\n\tint err;\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tchar ifname[IFNAMSIZ];\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);\n\tif (err < 0)\n\t\tgoto errout;\n\n\tif (tb[IFLA_IFNAME])\n\t\tnla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);\n\telse\n\t\tifname[0] = '\\0';\n\n\terr = -EINVAL;\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifi_index > 0)\n\t\tdev = __dev_get_by_index(net, ifm->ifi_index);\n\telse if (tb[IFLA_IFNAME])\n\t\tdev = __dev_get_by_name(net, ifname);\n\telse\n\t\tgoto errout;\n\n\tif (dev == NULL) {\n\t\terr = -ENODEV;\n\t\tgoto errout;\n\t}\n\n\terr = validate_linkmsg(dev, tb);\n\tif (err < 0)\n\t\tgoto errout;\n\n\terr = do_setlink(dev, ifm, tb, ifname, 0);\nerrout:\n\treturn err;\n}",
        "func": "static int rtnl_setlink(struct sk_buff *skb, struct nlmsghdr *nlh)\n{\n\tstruct net *net = sock_net(skb->sk);\n\tstruct ifinfomsg *ifm;\n\tstruct net_device *dev;\n\tint err;\n\tstruct nlattr *tb[IFLA_MAX+1];\n\tchar ifname[IFNAMSIZ];\n\n\terr = nlmsg_parse(nlh, sizeof(*ifm), tb, IFLA_MAX, ifla_policy);\n\tif (err < 0)\n\t\tgoto errout;\n\n\tif (tb[IFLA_IFNAME])\n\t\tnla_strlcpy(ifname, tb[IFLA_IFNAME], IFNAMSIZ);\n\telse\n\t\tifname[0] = '\\0';\n\n\terr = -EINVAL;\n\tifm = nlmsg_data(nlh);\n\tif (ifm->ifi_index > 0)\n\t\tdev = __dev_get_by_index(net, ifm->ifi_index);\n\telse if (tb[IFLA_IFNAME])\n\t\tdev = __dev_get_by_name(net, ifname);\n\telse\n\t\tgoto errout;\n\n\tif (dev == NULL) {\n\t\terr = -ENODEV;\n\t\tgoto errout;\n\t}\n\n\terr = validate_linkmsg(dev, tb);\n\tif (err < 0)\n\t\tgoto errout;\n\n\terr = do_setlink(skb, dev, ifm, tb, ifname, 0);\nerrout:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,7 +34,7 @@\n \tif (err < 0)\n \t\tgoto errout;\n \n-\terr = do_setlink(dev, ifm, tb, ifname, 0);\n+\terr = do_setlink(skb, dev, ifm, tb, ifname, 0);\n errout:\n \treturn err;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\terr = do_setlink(dev, ifm, tb, ifname, 0);"
            ],
            "added_lines": [
                "\terr = do_setlink(skb, dev, ifm, tb, ifname, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-2905",
        "func_name": "fish-shell/main",
        "description": "fish (aka fish-shell) 1.16.0 before 2.1.1 does not properly check the credentials, which allows local users to gain privileges via the universal variable socket, related to /tmp/fishd.socket.user permissions.",
        "git_url": "https://github.com/fish-shell/fish-shell/commit/ba1b5e34a77369e28ff563e47c088c55664a8a11",
        "commit_title": "Check effective credentials of socket peers",
        "commit_text": " Fix for CVE-2014-2905.  Code for getpeereid() on non-BSD systems imported from the PostgreSQL project under a BSD-style license.  Closes #1436",
        "func_before": "int main(int argc, char ** argv)\n{\n    int child_socket;\n    struct sockaddr_un remote;\n    socklen_t t;\n    int max_fd;\n    int update_count=0;\n\n    fd_set read_fd, write_fd;\n\n    set_main_thread();\n    setup_fork_guards();\n\n    program_name=L\"fishd\";\n    wsetlocale(LC_ALL, L\"\");\n\n    /*\n      Parse options\n    */\n    while (1)\n    {\n        static struct option\n                long_options[] =\n        {\n            {\n                \"help\", no_argument, 0, 'h'\n            }\n            ,\n            {\n                \"version\", no_argument, 0, 'v'\n            }\n            ,\n            {\n                0, 0, 0, 0\n            }\n        }\n        ;\n\n        int opt_index = 0;\n\n        int opt = getopt_long(argc,\n                              argv,\n                              GETOPT_STRING,\n                              long_options,\n                              &opt_index);\n\n        if (opt == -1)\n            break;\n\n        switch (opt)\n        {\n            case 0:\n                break;\n\n            case 'h':\n                print_help(argv[0], 1);\n                exit(0);\n\n            case 'v':\n                debug(0, L\"%ls, version %s\\n\", program_name, FISH_BUILD_VERSION);\n                exit(0);\n\n            case '?':\n                return 1;\n\n        }\n    }\n\n    init();\n    while (1)\n    {\n        int res;\n\n        t = sizeof(remote);\n\n        FD_ZERO(&read_fd);\n        FD_ZERO(&write_fd);\n        FD_SET(sock, &read_fd);\n        max_fd = sock+1;\n        for (connection_list_t::const_iterator iter = connections.begin(); iter != connections.end(); ++iter)\n        {\n            const connection_t &c = *iter;\n            FD_SET(c.fd, &read_fd);\n            max_fd = maxi(max_fd, c.fd+1);\n\n            if (! c.unsent.empty())\n            {\n                FD_SET(c.fd, &write_fd);\n            }\n        }\n\n        while (1)\n        {\n            res=select(max_fd, &read_fd, &write_fd, 0, 0);\n\n            if (quit)\n            {\n                save();\n                exit(0);\n            }\n\n            if (res != -1)\n                break;\n\n            if (errno != EINTR)\n            {\n                wperror(L\"select\");\n                exit(1);\n            }\n        }\n\n        if (FD_ISSET(sock, &read_fd))\n        {\n            if ((child_socket =\n                        accept(sock,\n                               (struct sockaddr *)&remote,\n                               &t)) == -1)\n            {\n                wperror(L\"accept\");\n                exit(1);\n            }\n            else\n            {\n                debug(4, L\"Connected with new child on fd %d\", child_socket);\n\n                if (make_fd_nonblocking(child_socket) != 0)\n                {\n                    wperror(L\"fcntl\");\n                    close(child_socket);\n                }\n                else\n                {\n                    connections.push_front(connection_t(child_socket));\n                    connection_t &newc = connections.front();\n                    send(newc.fd, GREETING, strlen(GREETING), MSG_DONTWAIT);\n                    enqueue_all(&newc);\n                }\n            }\n        }\n\n        for (connection_list_t::iterator iter = connections.begin(); iter != connections.end(); ++iter)\n        {\n            if (FD_ISSET(iter->fd, &write_fd))\n            {\n                try_send_all(&*iter);\n            }\n        }\n\n        for (connection_list_t::iterator iter = connections.begin(); iter != connections.end(); ++iter)\n        {\n            if (FD_ISSET(iter->fd, &read_fd))\n            {\n                read_message(&*iter);\n\n                /*\n                  Occasionally we save during normal use, so that we\n                  won't lose everything on a system crash\n                */\n                update_count++;\n                if (update_count >= 64)\n                {\n                    save();\n                    update_count = 0;\n                }\n            }\n        }\n\n        for (connection_list_t::iterator iter = connections.begin(); iter != connections.end();)\n        {\n            if (iter->killme)\n            {\n                debug(4, L\"Close connection %d\", iter->fd);\n\n                while (! iter->unsent.empty())\n                {\n                    message_t *msg = iter->unsent.front();\n                    iter->unsent.pop();\n                    msg->count--;\n                    if (! msg->count)\n                        free(msg);\n                }\n\n                connection_destroy(&*iter);\n                iter = connections.erase(iter);\n            }\n            else\n            {\n                ++iter;\n            }\n        }\n\n        if (connections.empty())\n        {\n            debug(0, L\"No more clients. Quitting\");\n            save();\n            break;\n        }\n\n    }\n}",
        "func": "int main(int argc, char ** argv)\n{\n    int child_socket;\n    struct sockaddr_un remote;\n    socklen_t t;\n    uid_t sock_euid;\n    gid_t sock_egid;\n    int max_fd;\n    int update_count=0;\n\n    fd_set read_fd, write_fd;\n\n    set_main_thread();\n    setup_fork_guards();\n\n    program_name=L\"fishd\";\n    wsetlocale(LC_ALL, L\"\");\n\n    /*\n      Parse options\n    */\n    while (1)\n    {\n        static struct option\n                long_options[] =\n        {\n            {\n                \"help\", no_argument, 0, 'h'\n            }\n            ,\n            {\n                \"version\", no_argument, 0, 'v'\n            }\n            ,\n            {\n                0, 0, 0, 0\n            }\n        }\n        ;\n\n        int opt_index = 0;\n\n        int opt = getopt_long(argc,\n                              argv,\n                              GETOPT_STRING,\n                              long_options,\n                              &opt_index);\n\n        if (opt == -1)\n            break;\n\n        switch (opt)\n        {\n            case 0:\n                break;\n\n            case 'h':\n                print_help(argv[0], 1);\n                exit(0);\n\n            case 'v':\n                debug(0, L\"%ls, version %s\\n\", program_name, FISH_BUILD_VERSION);\n                exit(0);\n\n            case '?':\n                return 1;\n\n        }\n    }\n\n    init();\n    while (1)\n    {\n        int res;\n\n        t = sizeof(remote);\n\n        FD_ZERO(&read_fd);\n        FD_ZERO(&write_fd);\n        FD_SET(sock, &read_fd);\n        max_fd = sock+1;\n        for (connection_list_t::const_iterator iter = connections.begin(); iter != connections.end(); ++iter)\n        {\n            const connection_t &c = *iter;\n            FD_SET(c.fd, &read_fd);\n            max_fd = maxi(max_fd, c.fd+1);\n\n            if (! c.unsent.empty())\n            {\n                FD_SET(c.fd, &write_fd);\n            }\n        }\n\n        while (1)\n        {\n            res=select(max_fd, &read_fd, &write_fd, 0, 0);\n\n            if (quit)\n            {\n                save();\n                exit(0);\n            }\n\n            if (res != -1)\n                break;\n\n            if (errno != EINTR)\n            {\n                wperror(L\"select\");\n                exit(1);\n            }\n        }\n\n        if (FD_ISSET(sock, &read_fd))\n        {\n            if ((child_socket =\n                        accept(sock,\n                               (struct sockaddr *)&remote,\n                               &t)) == -1)\n            {\n                wperror(L\"accept\");\n                exit(1);\n            }\n            else\n            {\n                debug(4, L\"Connected with new child on fd %d\", child_socket);\n\n                if (((getpeereid(child_socket, &sock_euid, &sock_egid) != 0) || sock_euid != geteuid()))\n                {\n                    debug(1, L\"Wrong credentials for child on fd %d\", child_socket);\n                    close(child_socket);\n                }\n                else if (make_fd_nonblocking(child_socket) != 0)\n                {\n                    wperror(L\"fcntl\");\n                    close(child_socket);\n                }\n                else\n                {\n                    connections.push_front(connection_t(child_socket));\n                    connection_t &newc = connections.front();\n                    send(newc.fd, GREETING, strlen(GREETING), MSG_DONTWAIT);\n                    enqueue_all(&newc);\n                }\n            }\n        }\n\n        for (connection_list_t::iterator iter = connections.begin(); iter != connections.end(); ++iter)\n        {\n            if (FD_ISSET(iter->fd, &write_fd))\n            {\n                try_send_all(&*iter);\n            }\n        }\n\n        for (connection_list_t::iterator iter = connections.begin(); iter != connections.end(); ++iter)\n        {\n            if (FD_ISSET(iter->fd, &read_fd))\n            {\n                read_message(&*iter);\n\n                /*\n                  Occasionally we save during normal use, so that we\n                  won't lose everything on a system crash\n                */\n                update_count++;\n                if (update_count >= 64)\n                {\n                    save();\n                    update_count = 0;\n                }\n            }\n        }\n\n        for (connection_list_t::iterator iter = connections.begin(); iter != connections.end();)\n        {\n            if (iter->killme)\n            {\n                debug(4, L\"Close connection %d\", iter->fd);\n\n                while (! iter->unsent.empty())\n                {\n                    message_t *msg = iter->unsent.front();\n                    iter->unsent.pop();\n                    msg->count--;\n                    if (! msg->count)\n                        free(msg);\n                }\n\n                connection_destroy(&*iter);\n                iter = connections.erase(iter);\n            }\n            else\n            {\n                ++iter;\n            }\n        }\n\n        if (connections.empty())\n        {\n            debug(0, L\"No more clients. Quitting\");\n            save();\n            break;\n        }\n\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,8 @@\n     int child_socket;\n     struct sockaddr_un remote;\n     socklen_t t;\n+    uid_t sock_euid;\n+    gid_t sock_egid;\n     int max_fd;\n     int update_count=0;\n \n@@ -123,7 +125,12 @@\n             {\n                 debug(4, L\"Connected with new child on fd %d\", child_socket);\n \n-                if (make_fd_nonblocking(child_socket) != 0)\n+                if (((getpeereid(child_socket, &sock_euid, &sock_egid) != 0) || sock_euid != geteuid()))\n+                {\n+                    debug(1, L\"Wrong credentials for child on fd %d\", child_socket);\n+                    close(child_socket);\n+                }\n+                else if (make_fd_nonblocking(child_socket) != 0)\n                 {\n                     wperror(L\"fcntl\");\n                     close(child_socket);",
        "diff_line_info": {
            "deleted_lines": [
                "                if (make_fd_nonblocking(child_socket) != 0)"
            ],
            "added_lines": [
                "    uid_t sock_euid;",
                "    gid_t sock_egid;",
                "                if (((getpeereid(child_socket, &sock_euid, &sock_egid) != 0) || sock_euid != geteuid()))",
                "                {",
                "                    debug(1, L\"Wrong credentials for child on fd %d\", child_socket);",
                "                    close(child_socket);",
                "                }",
                "                else if (make_fd_nonblocking(child_socket) != 0)"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-2905",
        "func_name": "fish-shell/try_get_socket_once",
        "description": "fish (aka fish-shell) 1.16.0 before 2.1.1 does not properly check the credentials, which allows local users to gain privileges via the universal variable socket, related to /tmp/fishd.socket.user permissions.",
        "git_url": "https://github.com/fish-shell/fish-shell/commit/ba1b5e34a77369e28ff563e47c088c55664a8a11",
        "commit_title": "Check effective credentials of socket peers",
        "commit_text": " Fix for CVE-2014-2905.  Code for getpeereid() on non-BSD systems imported from the PostgreSQL project under a BSD-style license.  Closes #1436",
        "func_before": "static int try_get_socket_once(void)\n{\n    int s;\n\n    wchar_t *wdir;\n    wchar_t *wuname;\n    char *dir = 0;\n\n    wdir = path;\n    wuname = user;\n\n    if ((s = socket(AF_UNIX, SOCK_STREAM, 0)) == -1)\n    {\n        wperror(L\"socket\");\n        return -1;\n    }\n\n    if (wdir)\n        dir = wcs2str(wdir);\n    else\n        dir = strdup(\"/tmp\");\n\n    std::string uname;\n    if (wuname)\n    {\n        uname = wcs2string(wuname);\n    }\n    else\n    {\n        struct passwd *pw = getpwuid(getuid());\n        if (pw && pw->pw_name)\n        {\n            uname = pw->pw_name;\n        }\n    }\n\n    std::string name;\n    name.reserve(strlen(dir) + uname.size() + strlen(SOCK_FILENAME) + 2);\n    name.append(dir);\n    name.append(\"/\");\n    name.append(SOCK_FILENAME);\n    name.append(uname);\n\n    free(dir);\n\n    debug(3, L\"Connect to socket %s at fd %d\", name.c_str(), s);\n\n    struct sockaddr_un local = {};\n    local.sun_family = AF_UNIX;\n    strncpy(local.sun_path, name.c_str(), (sizeof local.sun_path) - 1);\n\n    if (connect(s, (struct sockaddr *)&local, sizeof local) == -1)\n    {\n        close(s);\n\n        /* If it fails on first try, it's probably no serious error, but fishd hasn't been launched yet.\n         This happens (at least) on the first concurrent session. */\n        if (get_socket_count > 1)\n            wperror(L\"connect\");\n\n        return -1;\n    }\n\n    if ((make_fd_nonblocking(s) != 0) || (fcntl(s, F_SETFD, FD_CLOEXEC) != 0))\n    {\n        wperror(L\"fcntl\");\n        close(s);\n\n        return -1;\n    }\n\n    debug(3, L\"Connected to fd %d\", s);\n\n    return s;\n}",
        "func": "static int try_get_socket_once(void)\n{\n    int s;\n\n    wchar_t *wdir;\n    wchar_t *wuname;\n    char *dir = 0;\n\n    wdir = path;\n    wuname = user;\n    uid_t seuid;\n    gid_t segid;\n\n    if ((s = socket(AF_UNIX, SOCK_STREAM, 0)) == -1)\n    {\n        wperror(L\"socket\");\n        return -1;\n    }\n\n    if (wdir)\n        dir = wcs2str(wdir);\n    else\n        dir = strdup(\"/tmp\");\n\n    std::string uname;\n    if (wuname)\n    {\n        uname = wcs2string(wuname);\n    }\n    else\n    {\n        struct passwd *pw = getpwuid(getuid());\n        if (pw && pw->pw_name)\n        {\n            uname = pw->pw_name;\n        }\n    }\n\n    std::string name;\n    name.reserve(strlen(dir) + uname.size() + strlen(SOCK_FILENAME) + 2);\n    name.append(dir);\n    name.append(\"/\");\n    name.append(SOCK_FILENAME);\n    name.append(uname);\n\n    free(dir);\n\n    debug(3, L\"Connect to socket %s at fd %d\", name.c_str(), s);\n\n    struct sockaddr_un local = {};\n    local.sun_family = AF_UNIX;\n    strncpy(local.sun_path, name.c_str(), (sizeof local.sun_path) - 1);\n\n    if (connect(s, (struct sockaddr *)&local, sizeof local) == -1)\n    {\n        close(s);\n\n        /* If it fails on first try, it's probably no serious error, but fishd hasn't been launched yet.\n         This happens (at least) on the first concurrent session. */\n        if (get_socket_count > 1)\n            wperror(L\"connect\");\n\n        return -1;\n    }\n\n    if ((getpeereid(s, &seuid, &segid) != 0) || seuid != geteuid())\n    {\n        debug(1, L\"Wrong credentials for socket %s at fd %d\", name.c_str(), s);\n        close(s);\n        return -1;\n    }\n\n    if ((make_fd_nonblocking(s) != 0) || (fcntl(s, F_SETFD, FD_CLOEXEC) != 0))\n    {\n        wperror(L\"fcntl\");\n        close(s);\n\n        return -1;\n    }\n\n    debug(3, L\"Connected to fd %d\", s);\n\n    return s;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,8 @@\n \n     wdir = path;\n     wuname = user;\n+    uid_t seuid;\n+    gid_t segid;\n \n     if ((s = socket(AF_UNIX, SOCK_STREAM, 0)) == -1)\n     {\n@@ -61,6 +63,13 @@\n         return -1;\n     }\n \n+    if ((getpeereid(s, &seuid, &segid) != 0) || seuid != geteuid())\n+    {\n+        debug(1, L\"Wrong credentials for socket %s at fd %d\", name.c_str(), s);\n+        close(s);\n+        return -1;\n+    }\n+\n     if ((make_fd_nonblocking(s) != 0) || (fcntl(s, F_SETFD, FD_CLOEXEC) != 0))\n     {\n         wperror(L\"fcntl\");",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    uid_t seuid;",
                "    gid_t segid;",
                "    if ((getpeereid(s, &seuid, &segid) != 0) || seuid != geteuid())",
                "    {",
                "        debug(1, L\"Wrong credentials for socket %s at fd %d\", name.c_str(), s);",
                "        close(s);",
                "        return -1;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3125",
        "func_name": "xen-project/xen/ctxt_switch_to",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly context switch the CNTKCTL_EL1 register, which allows local guest users to modify the hardware timers and cause a denial of service (crash) via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/893256ffae0cf3be34a33a15efe2f2058b4b4fb7",
        "commit_title": "xen/arm: Correctly save/restore CNTKCTL_EL1",
        "commit_text": " CNTKCTL_EL1 is used by the guest to control access to the timer from userspace.  It therefore needs to be save/restored by Xen as part of the VCPU state.  By default Linux on ARM64 exposes the timer to userspace.  Furthermore on ARM64, Linux provides helpers in a VDSO (gettimeofday/__do_get_tspec) that use the timer counter.  Conversely, during CPU bring up, Xen will set CNTKCTL_EL1 to 0 (i.e disallow timer access to the userspace).  As a result, currently, if dom0 has 1 VCPU which is migrated to another PCPU, init might crash.  Alternatively, a guest (malicious or not) might decide to disable access to the timer from userspace.  If the register is not save/restored, when a DOM0 VCPU runs again, a similar crash would result.  Also, drop CNTKCTL_EL1 initialization in init_timer_interrupt.  Xen should let the guest deal with this register.  This is XSA-91 / CVE-2014-3125. ",
        "func_before": "static void ctxt_switch_to(struct vcpu *n)\n{\n    p2m_restore_state(n);\n\n    WRITE_SYSREG32(n->domain->arch.vpidr, VPIDR_EL2);\n    WRITE_SYSREG(n->arch.vmpidr, VMPIDR_EL2);\n\n    /* VGIC */\n    gic_restore_state(n);\n\n    /* VFP */\n    vfp_restore_state(n);\n\n    /* XXX MPU */\n\n    /* Fault Status */\n#if defined(CONFIG_ARM_32)\n    WRITE_CP32(n->arch.dfar, DFAR);\n    WRITE_CP32(n->arch.ifar, IFAR);\n    WRITE_CP32(n->arch.dfsr, DFSR);\n#elif defined(CONFIG_ARM_64)\n    WRITE_SYSREG64(n->arch.far, FAR_EL1);\n    WRITE_SYSREG64(n->arch.esr, ESR_EL1);\n#endif\n\n    if ( is_32bit_domain(n->domain) )\n        WRITE_SYSREG(n->arch.ifsr, IFSR32_EL2);\n    WRITE_SYSREG(n->arch.afsr0, AFSR0_EL1);\n    WRITE_SYSREG(n->arch.afsr1, AFSR1_EL1);\n\n    /* MMU */\n    WRITE_SYSREG(n->arch.vbar, VBAR_EL1);\n    WRITE_SYSREG(n->arch.ttbcr, TCR_EL1);\n    WRITE_SYSREG64(n->arch.ttbr0, TTBR0_EL1);\n    WRITE_SYSREG64(n->arch.ttbr1, TTBR1_EL1);\n    if ( is_32bit_domain(n->domain) )\n        WRITE_SYSREG(n->arch.dacr, DACR32_EL2);\n    WRITE_SYSREG64(n->arch.par, PAR_EL1);\n#if defined(CONFIG_ARM_32)\n    WRITE_CP32(n->arch.mair0, MAIR0);\n    WRITE_CP32(n->arch.mair1, MAIR1);\n    WRITE_CP32(n->arch.amair0, AMAIR0);\n    WRITE_CP32(n->arch.amair1, AMAIR1);\n#elif defined(CONFIG_ARM_64)\n    WRITE_SYSREG64(n->arch.mair, MAIR_EL1);\n    WRITE_SYSREG64(n->arch.amair, AMAIR_EL1);\n#endif\n    isb();\n\n    /* Control Registers */\n    WRITE_SYSREG(n->arch.cpacr, CPACR_EL1);\n\n    WRITE_SYSREG(n->arch.contextidr, CONTEXTIDR_EL1);\n    WRITE_SYSREG(n->arch.tpidr_el0, TPIDR_EL0);\n    WRITE_SYSREG(n->arch.tpidrro_el0, TPIDRRO_EL0);\n    WRITE_SYSREG(n->arch.tpidr_el1, TPIDR_EL1);\n\n    if ( is_32bit_domain(n->domain) && cpu_has_thumbee )\n    {\n        WRITE_SYSREG32(n->arch.teecr, TEECR32_EL1);\n        WRITE_SYSREG32(n->arch.teehbr, TEEHBR32_EL1);\n    }\n\n#ifdef CONFIG_ARM_32\n    WRITE_CP32(n->arch.joscr, JOSCR);\n    WRITE_CP32(n->arch.jmcr, JMCR);\n#endif\n    isb();\n\n    /* CP 15 */\n    WRITE_SYSREG(n->arch.csselr, CSSELR_EL1);\n\n    isb();\n\n    /* This is could trigger an hardware interrupt from the virtual\n     * timer. The interrupt needs to be injected into the guest. */\n    virt_timer_restore(n);\n}",
        "func": "static void ctxt_switch_to(struct vcpu *n)\n{\n    p2m_restore_state(n);\n\n    WRITE_SYSREG32(n->domain->arch.vpidr, VPIDR_EL2);\n    WRITE_SYSREG(n->arch.vmpidr, VMPIDR_EL2);\n\n    /* VGIC */\n    gic_restore_state(n);\n\n    /* VFP */\n    vfp_restore_state(n);\n\n    /* XXX MPU */\n\n    /* Fault Status */\n#if defined(CONFIG_ARM_32)\n    WRITE_CP32(n->arch.dfar, DFAR);\n    WRITE_CP32(n->arch.ifar, IFAR);\n    WRITE_CP32(n->arch.dfsr, DFSR);\n#elif defined(CONFIG_ARM_64)\n    WRITE_SYSREG64(n->arch.far, FAR_EL1);\n    WRITE_SYSREG64(n->arch.esr, ESR_EL1);\n#endif\n\n    if ( is_32bit_domain(n->domain) )\n        WRITE_SYSREG(n->arch.ifsr, IFSR32_EL2);\n    WRITE_SYSREG(n->arch.afsr0, AFSR0_EL1);\n    WRITE_SYSREG(n->arch.afsr1, AFSR1_EL1);\n\n    /* MMU */\n    WRITE_SYSREG(n->arch.vbar, VBAR_EL1);\n    WRITE_SYSREG(n->arch.ttbcr, TCR_EL1);\n    WRITE_SYSREG64(n->arch.ttbr0, TTBR0_EL1);\n    WRITE_SYSREG64(n->arch.ttbr1, TTBR1_EL1);\n    if ( is_32bit_domain(n->domain) )\n        WRITE_SYSREG(n->arch.dacr, DACR32_EL2);\n    WRITE_SYSREG64(n->arch.par, PAR_EL1);\n#if defined(CONFIG_ARM_32)\n    WRITE_CP32(n->arch.mair0, MAIR0);\n    WRITE_CP32(n->arch.mair1, MAIR1);\n    WRITE_CP32(n->arch.amair0, AMAIR0);\n    WRITE_CP32(n->arch.amair1, AMAIR1);\n#elif defined(CONFIG_ARM_64)\n    WRITE_SYSREG64(n->arch.mair, MAIR_EL1);\n    WRITE_SYSREG64(n->arch.amair, AMAIR_EL1);\n#endif\n    isb();\n\n    /* Control Registers */\n    WRITE_SYSREG(n->arch.cpacr, CPACR_EL1);\n\n    WRITE_SYSREG(n->arch.contextidr, CONTEXTIDR_EL1);\n    WRITE_SYSREG(n->arch.tpidr_el0, TPIDR_EL0);\n    WRITE_SYSREG(n->arch.tpidrro_el0, TPIDRRO_EL0);\n    WRITE_SYSREG(n->arch.tpidr_el1, TPIDR_EL1);\n\n    if ( is_32bit_domain(n->domain) && cpu_has_thumbee )\n    {\n        WRITE_SYSREG32(n->arch.teecr, TEECR32_EL1);\n        WRITE_SYSREG32(n->arch.teehbr, TEEHBR32_EL1);\n    }\n\n#ifdef CONFIG_ARM_32\n    WRITE_CP32(n->arch.joscr, JOSCR);\n    WRITE_CP32(n->arch.jmcr, JMCR);\n#endif\n    isb();\n\n    /* CP 15 */\n    WRITE_SYSREG(n->arch.csselr, CSSELR_EL1);\n\n    isb();\n\n    /* This is could trigger an hardware interrupt from the virtual\n     * timer. The interrupt needs to be injected into the guest. */\n    WRITE_SYSREG32(n->arch.cntkctl, CNTKCTL_EL1);\n    virt_timer_restore(n);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -74,5 +74,6 @@\n \n     /* This is could trigger an hardware interrupt from the virtual\n      * timer. The interrupt needs to be injected into the guest. */\n+    WRITE_SYSREG32(n->arch.cntkctl, CNTKCTL_EL1);\n     virt_timer_restore(n);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    WRITE_SYSREG32(n->arch.cntkctl, CNTKCTL_EL1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3125",
        "func_name": "xen-project/xen/ctxt_switch_from",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly context switch the CNTKCTL_EL1 register, which allows local guest users to modify the hardware timers and cause a denial of service (crash) via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/893256ffae0cf3be34a33a15efe2f2058b4b4fb7",
        "commit_title": "xen/arm: Correctly save/restore CNTKCTL_EL1",
        "commit_text": " CNTKCTL_EL1 is used by the guest to control access to the timer from userspace.  It therefore needs to be save/restored by Xen as part of the VCPU state.  By default Linux on ARM64 exposes the timer to userspace.  Furthermore on ARM64, Linux provides helpers in a VDSO (gettimeofday/__do_get_tspec) that use the timer counter.  Conversely, during CPU bring up, Xen will set CNTKCTL_EL1 to 0 (i.e disallow timer access to the userspace).  As a result, currently, if dom0 has 1 VCPU which is migrated to another PCPU, init might crash.  Alternatively, a guest (malicious or not) might decide to disable access to the timer from userspace.  If the register is not save/restored, when a DOM0 VCPU runs again, a similar crash would result.  Also, drop CNTKCTL_EL1 initialization in init_timer_interrupt.  Xen should let the guest deal with this register.  This is XSA-91 / CVE-2014-3125. ",
        "func_before": "static void ctxt_switch_from(struct vcpu *p)\n{\n    p2m_save_state(p);\n\n    /* CP 15 */\n    p->arch.csselr = READ_SYSREG(CSSELR_EL1);\n\n    /* Control Registers */\n    p->arch.cpacr = READ_SYSREG(CPACR_EL1);\n\n    p->arch.contextidr = READ_SYSREG(CONTEXTIDR_EL1);\n    p->arch.tpidr_el0 = READ_SYSREG(TPIDR_EL0);\n    p->arch.tpidrro_el0 = READ_SYSREG(TPIDRRO_EL0);\n    p->arch.tpidr_el1 = READ_SYSREG(TPIDR_EL1);\n\n    /* Arch timer */\n    virt_timer_save(p);\n\n    if ( is_32bit_domain(p->domain) && cpu_has_thumbee )\n    {\n        p->arch.teecr = READ_SYSREG32(TEECR32_EL1);\n        p->arch.teehbr = READ_SYSREG32(TEEHBR32_EL1);\n    }\n\n#ifdef CONFIG_ARM_32\n    p->arch.joscr = READ_CP32(JOSCR);\n    p->arch.jmcr = READ_CP32(JMCR);\n#endif\n\n    isb();\n\n    /* MMU */\n    p->arch.vbar = READ_SYSREG(VBAR_EL1);\n    p->arch.ttbcr = READ_SYSREG(TCR_EL1);\n    p->arch.ttbr0 = READ_SYSREG64(TTBR0_EL1);\n    p->arch.ttbr1 = READ_SYSREG64(TTBR1_EL1);\n    if ( is_32bit_domain(p->domain) )\n        p->arch.dacr = READ_SYSREG(DACR32_EL2);\n    p->arch.par = READ_SYSREG64(PAR_EL1);\n#if defined(CONFIG_ARM_32)\n    p->arch.mair0 = READ_CP32(MAIR0);\n    p->arch.mair1 = READ_CP32(MAIR1);\n    p->arch.amair0 = READ_CP32(AMAIR0);\n    p->arch.amair1 = READ_CP32(AMAIR1);\n#else\n    p->arch.mair = READ_SYSREG64(MAIR_EL1);\n    p->arch.amair = READ_SYSREG64(AMAIR_EL1);\n#endif\n\n    /* Fault Status */\n#if defined(CONFIG_ARM_32)\n    p->arch.dfar = READ_CP32(DFAR);\n    p->arch.ifar = READ_CP32(IFAR);\n    p->arch.dfsr = READ_CP32(DFSR);\n#elif defined(CONFIG_ARM_64)\n    p->arch.far = READ_SYSREG64(FAR_EL1);\n    p->arch.esr = READ_SYSREG64(ESR_EL1);\n#endif\n\n    if ( is_32bit_domain(p->domain) )\n        p->arch.ifsr  = READ_SYSREG(IFSR32_EL2);\n    p->arch.afsr0 = READ_SYSREG(AFSR0_EL1);\n    p->arch.afsr1 = READ_SYSREG(AFSR1_EL1);\n\n    /* XXX MPU */\n\n    /* VFP */\n    vfp_save_state(p);\n\n    /* VGIC */\n    gic_save_state(p);\n\n    isb();\n    context_saved(p);\n}",
        "func": "static void ctxt_switch_from(struct vcpu *p)\n{\n    p2m_save_state(p);\n\n    /* CP 15 */\n    p->arch.csselr = READ_SYSREG(CSSELR_EL1);\n\n    /* Control Registers */\n    p->arch.cpacr = READ_SYSREG(CPACR_EL1);\n\n    p->arch.contextidr = READ_SYSREG(CONTEXTIDR_EL1);\n    p->arch.tpidr_el0 = READ_SYSREG(TPIDR_EL0);\n    p->arch.tpidrro_el0 = READ_SYSREG(TPIDRRO_EL0);\n    p->arch.tpidr_el1 = READ_SYSREG(TPIDR_EL1);\n\n    /* Arch timer */\n    p->arch.cntkctl = READ_SYSREG32(CNTKCTL_EL1);\n    virt_timer_save(p);\n\n    if ( is_32bit_domain(p->domain) && cpu_has_thumbee )\n    {\n        p->arch.teecr = READ_SYSREG32(TEECR32_EL1);\n        p->arch.teehbr = READ_SYSREG32(TEEHBR32_EL1);\n    }\n\n#ifdef CONFIG_ARM_32\n    p->arch.joscr = READ_CP32(JOSCR);\n    p->arch.jmcr = READ_CP32(JMCR);\n#endif\n\n    isb();\n\n    /* MMU */\n    p->arch.vbar = READ_SYSREG(VBAR_EL1);\n    p->arch.ttbcr = READ_SYSREG(TCR_EL1);\n    p->arch.ttbr0 = READ_SYSREG64(TTBR0_EL1);\n    p->arch.ttbr1 = READ_SYSREG64(TTBR1_EL1);\n    if ( is_32bit_domain(p->domain) )\n        p->arch.dacr = READ_SYSREG(DACR32_EL2);\n    p->arch.par = READ_SYSREG64(PAR_EL1);\n#if defined(CONFIG_ARM_32)\n    p->arch.mair0 = READ_CP32(MAIR0);\n    p->arch.mair1 = READ_CP32(MAIR1);\n    p->arch.amair0 = READ_CP32(AMAIR0);\n    p->arch.amair1 = READ_CP32(AMAIR1);\n#else\n    p->arch.mair = READ_SYSREG64(MAIR_EL1);\n    p->arch.amair = READ_SYSREG64(AMAIR_EL1);\n#endif\n\n    /* Fault Status */\n#if defined(CONFIG_ARM_32)\n    p->arch.dfar = READ_CP32(DFAR);\n    p->arch.ifar = READ_CP32(IFAR);\n    p->arch.dfsr = READ_CP32(DFSR);\n#elif defined(CONFIG_ARM_64)\n    p->arch.far = READ_SYSREG64(FAR_EL1);\n    p->arch.esr = READ_SYSREG64(ESR_EL1);\n#endif\n\n    if ( is_32bit_domain(p->domain) )\n        p->arch.ifsr  = READ_SYSREG(IFSR32_EL2);\n    p->arch.afsr0 = READ_SYSREG(AFSR0_EL1);\n    p->arch.afsr1 = READ_SYSREG(AFSR1_EL1);\n\n    /* XXX MPU */\n\n    /* VFP */\n    vfp_save_state(p);\n\n    /* VGIC */\n    gic_save_state(p);\n\n    isb();\n    context_saved(p);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,6 +14,7 @@\n     p->arch.tpidr_el1 = READ_SYSREG(TPIDR_EL1);\n \n     /* Arch timer */\n+    p->arch.cntkctl = READ_SYSREG32(CNTKCTL_EL1);\n     virt_timer_save(p);\n \n     if ( is_32bit_domain(p->domain) && cpu_has_thumbee )",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    p->arch.cntkctl = READ_SYSREG32(CNTKCTL_EL1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3125",
        "func_name": "xen-project/xen/init_timer_interrupt",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly context switch the CNTKCTL_EL1 register, which allows local guest users to modify the hardware timers and cause a denial of service (crash) via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/893256ffae0cf3be34a33a15efe2f2058b4b4fb7",
        "commit_title": "xen/arm: Correctly save/restore CNTKCTL_EL1",
        "commit_text": " CNTKCTL_EL1 is used by the guest to control access to the timer from userspace.  It therefore needs to be save/restored by Xen as part of the VCPU state.  By default Linux on ARM64 exposes the timer to userspace.  Furthermore on ARM64, Linux provides helpers in a VDSO (gettimeofday/__do_get_tspec) that use the timer counter.  Conversely, during CPU bring up, Xen will set CNTKCTL_EL1 to 0 (i.e disallow timer access to the userspace).  As a result, currently, if dom0 has 1 VCPU which is migrated to another PCPU, init might crash.  Alternatively, a guest (malicious or not) might decide to disable access to the timer from userspace.  If the register is not save/restored, when a DOM0 VCPU runs again, a similar crash would result.  Also, drop CNTKCTL_EL1 initialization in init_timer_interrupt.  Xen should let the guest deal with this register.  This is XSA-91 / CVE-2014-3125. ",
        "func_before": "void __cpuinit init_timer_interrupt(void)\n{\n    /* Sensible defaults */\n    WRITE_SYSREG64(0, CNTVOFF_EL2);     /* No VM-specific offset */\n    WRITE_SYSREG32(0, CNTKCTL_EL1);     /* No user-mode access */\n#if USE_HYP_TIMER\n    /* Do not let the VMs program the physical timer, only read the physical counter */\n    WRITE_SYSREG32(CNTHCTL_PA, CNTHCTL_EL2);\n#else\n    /* Cannot let VMs access physical counter if we are using it */\n    WRITE_SYSREG32(0, CNTHCTL_EL2);\n#endif\n    WRITE_SYSREG32(0, CNTP_CTL_EL0);    /* Physical timer disabled */\n    WRITE_SYSREG32(0, CNTHP_CTL_EL2);   /* Hypervisor's timer disabled */\n    isb();\n\n    request_dt_irq(&timer_irq[TIMER_HYP_PPI], timer_interrupt,\n                   \"hyptimer\", NULL);\n    request_dt_irq(&timer_irq[TIMER_VIRT_PPI], vtimer_interrupt,\n                   \"virtimer\", NULL);\n    request_dt_irq(&timer_irq[TIMER_PHYS_NONSECURE_PPI], timer_interrupt,\n                   \"phytimer\", NULL);\n}",
        "func": "void __cpuinit init_timer_interrupt(void)\n{\n    /* Sensible defaults */\n    WRITE_SYSREG64(0, CNTVOFF_EL2);     /* No VM-specific offset */\n#if USE_HYP_TIMER\n    /* Do not let the VMs program the physical timer, only read the physical counter */\n    WRITE_SYSREG32(CNTHCTL_PA, CNTHCTL_EL2);\n#else\n    /* Cannot let VMs access physical counter if we are using it */\n    WRITE_SYSREG32(0, CNTHCTL_EL2);\n#endif\n    WRITE_SYSREG32(0, CNTP_CTL_EL0);    /* Physical timer disabled */\n    WRITE_SYSREG32(0, CNTHP_CTL_EL2);   /* Hypervisor's timer disabled */\n    isb();\n\n    request_dt_irq(&timer_irq[TIMER_HYP_PPI], timer_interrupt,\n                   \"hyptimer\", NULL);\n    request_dt_irq(&timer_irq[TIMER_VIRT_PPI], vtimer_interrupt,\n                   \"virtimer\", NULL);\n    request_dt_irq(&timer_irq[TIMER_PHYS_NONSECURE_PPI], timer_interrupt,\n                   \"phytimer\", NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,6 @@\n {\n     /* Sensible defaults */\n     WRITE_SYSREG64(0, CNTVOFF_EL2);     /* No VM-specific offset */\n-    WRITE_SYSREG32(0, CNTKCTL_EL1);     /* No user-mode access */\n #if USE_HYP_TIMER\n     /* Do not let the VMs program the physical timer, only read the physical counter */\n     WRITE_SYSREG32(CNTHCTL_PA, CNTHCTL_EL2);",
        "diff_line_info": {
            "deleted_lines": [
                "    WRITE_SYSREG32(0, CNTKCTL_EL1);     /* No user-mode access */"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-3124",
        "func_name": "xen-project/xen/do_hvm_op",
        "description": "The HVMOP_set_mem_type control in Xen 4.1 through 4.4.x allows local guest HVM administrators to cause a denial of service (hypervisor crash) or possibly execute arbitrary code by leveraging a separate qemu-dm vulnerability to trigger invalid page table translations for unspecified memory page types.",
        "git_url": "https://github.com/xen-project/xen/commit/83bb5eb4d340acebf27b34108fb1dae062146a68",
        "commit_title": "x86/HVM: restrict HVMOP_set_mem_type",
        "commit_text": " Permitting arbitrary type changes here has the potential of creating present P2M (and hence EPT/NPT/IOMMU) entries pointing to an invalid MFN (INVALID_MFN truncated to the respective hardware structure field's width). This would become a problem the latest when something real sat at the end of the physical address space; I'm suspecting though that other things might break with such bogus entries.  Along with that drop a bogus (and otherwise becoming stale) log message.  Afaict the similar operation in p2m_set_mem_access() is safe.  This is XSA-92. ",
        "func_before": "long do_hvm_op(unsigned long op, XEN_GUEST_HANDLE_PARAM(void) arg)\n\n{\n    struct domain *curr_d = current->domain;\n    unsigned long start_iter = op & ~HVMOP_op_mask;\n    long rc = 0;\n\n    switch ( op &= HVMOP_op_mask )\n    {\n    case HVMOP_set_param:\n    case HVMOP_get_param:\n    {\n        struct xen_hvm_param a;\n        struct hvm_ioreq_page *iorp;\n        struct domain *d;\n        struct vcpu *v;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        if ( a.index >= HVM_NR_PARAMS )\n            return -EINVAL;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = -EINVAL;\n        if ( !has_hvm_container_domain(d) )\n            goto param_fail;\n\n        if ( is_pvh_domain(d)\n             && (a.index != HVM_PARAM_CALLBACK_IRQ) )\n            goto param_fail;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail;\n\n        if ( op == HVMOP_set_param )\n        {\n            rc = 0;\n\n            switch ( a.index )\n            {\n            case HVM_PARAM_IOREQ_PFN:\n                iorp = &d->arch.hvm_domain.ioreq;\n                if ( (rc = hvm_set_ioreq_page(d, iorp, a.value)) != 0 )\n                    break;\n                spin_lock(&iorp->lock);\n                if ( iorp->va != NULL )\n                    /* Initialise evtchn port info if VCPUs already created. */\n                    for_each_vcpu ( d, v )\n                        get_ioreq(v)->vp_eport = v->arch.hvm_vcpu.xen_port;\n                spin_unlock(&iorp->lock);\n                break;\n            case HVM_PARAM_BUFIOREQ_PFN: \n                iorp = &d->arch.hvm_domain.buf_ioreq;\n                rc = hvm_set_ioreq_page(d, iorp, a.value);\n                break;\n            case HVM_PARAM_CALLBACK_IRQ:\n                hvm_set_callback_via(d, a.value);\n                hvm_latch_shinfo_size(d);\n                break;\n            case HVM_PARAM_TIMER_MODE:\n                if ( a.value > HVMPTM_one_missed_tick_pending )\n                    rc = -EINVAL;\n                break;\n            case HVM_PARAM_VIRIDIAN:\n                if ( a.value > 1 )\n                    rc = -EINVAL;\n                break;\n            case HVM_PARAM_IDENT_PT:\n                /* Not reflexive, as we must domain_pause(). */\n                rc = -EPERM;\n                if ( curr_d == d )\n                    break;\n\n                rc = -EINVAL;\n                if ( d->arch.hvm_domain.params[a.index] != 0 )\n                    break;\n\n                rc = 0;\n                if ( !paging_mode_hap(d) )\n                    break;\n\n                /*\n                 * Update GUEST_CR3 in each VMCS to point at identity map.\n                 * All foreign updates to guest state must synchronise on\n                 * the domctl_lock.\n                 */\n                rc = -EAGAIN;\n                if ( !domctl_lock_acquire() )\n                    break;\n\n                rc = 0;\n                domain_pause(d);\n                d->arch.hvm_domain.params[a.index] = a.value;\n                for_each_vcpu ( d, v )\n                    paging_update_cr3(v);\n                domain_unpause(d);\n\n                domctl_lock_release();\n                break;\n            case HVM_PARAM_DM_DOMAIN:\n                /* Not reflexive, as we must domain_pause(). */\n                rc = -EPERM;\n                if ( curr_d == d )\n                    break;\n\n                if ( a.value == DOMID_SELF )\n                    a.value = curr_d->domain_id;\n\n                rc = 0;\n                domain_pause(d); /* safe to change per-vcpu xen_port */\n                if ( d->vcpu[0] )\n                    rc = hvm_replace_event_channel(d->vcpu[0], a.value,\n                             (int *)&d->vcpu[0]->domain->arch.hvm_domain.params\n                                     [HVM_PARAM_BUFIOREQ_EVTCHN]);\n                if ( rc )\n                {\n                    domain_unpause(d);\n                    break;\n                }\n                iorp = &d->arch.hvm_domain.ioreq;\n                for_each_vcpu ( d, v )\n                {\n                    rc = hvm_replace_event_channel(v, a.value,\n                                                   &v->arch.hvm_vcpu.xen_port);\n                    if ( rc )\n                        break;\n\n                    spin_lock(&iorp->lock);\n                    if ( iorp->va != NULL )\n                        get_ioreq(v)->vp_eport = v->arch.hvm_vcpu.xen_port;\n                    spin_unlock(&iorp->lock);\n                }\n                domain_unpause(d);\n                break;\n            case HVM_PARAM_ACPI_S_STATE:\n                /* Not reflexive, as we must domain_pause(). */\n                rc = -EPERM;\n                if ( curr_d == d )\n                    break;\n\n                rc = 0;\n                if ( a.value == 3 )\n                    hvm_s3_suspend(d);\n                else if ( a.value == 0 )\n                    hvm_s3_resume(d);\n                else\n                    rc = -EINVAL;\n\n                break;\n            case HVM_PARAM_ACPI_IOPORTS_LOCATION:\n                rc = pmtimer_change_ioport(d, a.value);\n                break;\n            case HVM_PARAM_MEMORY_EVENT_CR0:\n            case HVM_PARAM_MEMORY_EVENT_CR3:\n            case HVM_PARAM_MEMORY_EVENT_CR4:\n                if ( d == current->domain )\n                    rc = -EPERM;\n                break;\n            case HVM_PARAM_MEMORY_EVENT_INT3:\n            case HVM_PARAM_MEMORY_EVENT_SINGLE_STEP:\n            case HVM_PARAM_MEMORY_EVENT_MSR:\n                if ( d == current->domain )\n                {\n                    rc = -EPERM;\n                    break;\n                }\n                if ( a.value & HVMPME_onchangeonly )\n                    rc = -EINVAL;\n                break;\n            case HVM_PARAM_NESTEDHVM:\n                rc = xsm_hvm_param_nested(XSM_PRIV, d);\n                if ( rc )\n                    break;\n                if ( a.value > 1 )\n                    rc = -EINVAL;\n                /* Remove the check below once we have\n                 * shadow-on-shadow.\n                 */\n                if ( cpu_has_svm && !paging_mode_hap(d) && a.value )\n                    rc = -EINVAL;\n                /* Set up NHVM state for any vcpus that are already up */\n                if ( a.value &&\n                     !d->arch.hvm_domain.params[HVM_PARAM_NESTEDHVM] )\n                    for_each_vcpu(d, v)\n                        if ( rc == 0 )\n                            rc = nestedhvm_vcpu_initialise(v);\n                if ( !a.value || rc )\n                    for_each_vcpu(d, v)\n                        nestedhvm_vcpu_destroy(v);\n                break;\n            case HVM_PARAM_BUFIOREQ_EVTCHN:\n                rc = -EINVAL;\n                break;\n            case HVM_PARAM_TRIPLE_FAULT_REASON:\n                if ( a.value > SHUTDOWN_MAX )\n                    rc = -EINVAL;\n                break;\n            }\n\n            if ( rc == 0 ) \n            {\n                d->arch.hvm_domain.params[a.index] = a.value;\n\n                switch( a.index )\n                {\n                case HVM_PARAM_MEMORY_EVENT_INT3:\n                case HVM_PARAM_MEMORY_EVENT_SINGLE_STEP:\n                {\n                    domain_pause(d);\n                    domain_unpause(d); /* Causes guest to latch new status */\n                    break;\n                }\n                case HVM_PARAM_MEMORY_EVENT_CR3:\n                {\n                    for_each_vcpu ( d, v )\n                        hvm_funcs.update_guest_cr(v, 0); /* Latches new CR3 mask through CR0 code */\n                    break;\n                }\n                }\n\n            }\n\n        }\n        else\n        {\n            switch ( a.index )\n            {\n            case HVM_PARAM_ACPI_S_STATE:\n                a.value = d->arch.hvm_domain.is_s3_suspended ? 3 : 0;\n                break;\n            default:\n                a.value = d->arch.hvm_domain.params[a.index];\n                break;\n            }\n            rc = __copy_to_guest(arg, &a, 1) ? -EFAULT : 0;\n        }\n\n        HVM_DBG_LOG(DBG_LEVEL_HCALL, \"%s param %u = %\"PRIx64,\n                    op == HVMOP_set_param ? \"set\" : \"get\",\n                    a.index, a.value);\n\n    param_fail:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_set_pci_intx_level:\n        rc = hvmop_set_pci_intx_level(\n            guest_handle_cast(arg, xen_hvm_set_pci_intx_level_t));\n        break;\n\n    case HVMOP_set_isa_irq_level:\n        rc = hvmop_set_isa_irq_level(\n            guest_handle_cast(arg, xen_hvm_set_isa_irq_level_t));\n        break;\n\n    case HVMOP_inject_msi:\n        rc = hvmop_inject_msi(\n            guest_handle_cast(arg, xen_hvm_inject_msi_t));\n        break;\n\n    case HVMOP_set_pci_link_route:\n        rc = hvmop_set_pci_link_route(\n            guest_handle_cast(arg, xen_hvm_set_pci_link_route_t));\n        break;\n\n    case HVMOP_flush_tlbs:\n        rc = guest_handle_is_null(arg) ? hvmop_flush_tlb_all() : -ENOSYS;\n        break;\n\n    case HVMOP_track_dirty_vram:\n    {\n        struct xen_hvm_track_dirty_vram a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(a.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail2;\n\n        if ( a.nr > GB(1) >> PAGE_SHIFT )\n            goto param_fail2;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail2;\n\n        rc = -ESRCH;\n        if ( d->is_dying )\n            goto param_fail2;\n\n        rc = -EINVAL;\n        if ( d->vcpu == NULL || d->vcpu[0] == NULL )\n            goto param_fail2;\n\n        if ( shadow_mode_enabled(d) )\n            rc = shadow_track_dirty_vram(d, a.first_pfn, a.nr, a.dirty_bitmap);\n        else\n            rc = hap_track_dirty_vram(d, a.first_pfn, a.nr, a.dirty_bitmap);\n\n    param_fail2:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_modified_memory:\n    {\n        struct xen_hvm_modified_memory a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(a.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail3;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail3;\n\n        rc = -EINVAL;\n        if ( a.nr < start_iter ||\n             ((a.first_pfn + a.nr - 1) < a.first_pfn) ||\n             ((a.first_pfn + a.nr - 1) > domain_get_maximum_gpfn(d)) )\n            goto param_fail3;\n\n        rc = 0;\n        if ( !paging_mode_log_dirty(d) )\n            goto param_fail3;\n\n        while ( a.nr > start_iter )\n        {\n            unsigned long pfn = a.first_pfn + start_iter;\n            struct page_info *page;\n\n            page = get_page_from_gfn(d, pfn, NULL, P2M_UNSHARE);\n            if ( page )\n            {\n                paging_mark_dirty(d, page_to_mfn(page));\n                /* These are most probably not page tables any more */\n                /* don't take a long time and don't die either */\n                sh_remove_shadows(d->vcpu[0], _mfn(page_to_mfn(page)), 1, 0);\n                put_page(page);\n            }\n\n            /* Check for continuation if it's not the last interation */\n            if ( a.nr > ++start_iter && !(start_iter & HVMOP_op_mask) &&\n                 hypercall_preempt_check() )\n            {\n                rc = -EAGAIN;\n                break;\n            }\n        }\n\n    param_fail3:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_get_mem_type:\n    {\n        struct xen_hvm_get_mem_type a;\n        struct domain *d;\n        p2m_type_t t;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail_getmemtype;\n\n        rc = -EINVAL;\n        if ( is_hvm_domain(d) )\n        {\n            /* Use get_gfn query as we are interested in the current \n             * type, not in allocating or unsharing. That'll happen \n             * on access. */\n            get_gfn_query_unlocked(d, a.pfn, &t);\n            if ( p2m_is_mmio(t) )\n                a.mem_type =  HVMMEM_mmio_dm;\n            else if ( p2m_is_readonly(t) )\n                a.mem_type =  HVMMEM_ram_ro;\n            else if ( p2m_is_ram(t) )\n                a.mem_type =  HVMMEM_ram_rw;\n            else if ( p2m_is_pod(t) )\n                a.mem_type =  HVMMEM_ram_rw;\n            else if ( p2m_is_grant(t) )\n                a.mem_type =  HVMMEM_ram_rw;\n            else\n                a.mem_type =  HVMMEM_mmio_dm;\n            rc = __copy_to_guest(arg, &a, 1) ? -EFAULT : 0;\n        }\n\n    param_fail_getmemtype:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_set_mem_type:\n    {\n        struct xen_hvm_set_mem_type a;\n        struct domain *d;\n        \n        /* Interface types to internal p2m types */\n        static const p2m_type_t memtype[] = {\n            [HVMMEM_ram_rw]  = p2m_ram_rw,\n            [HVMMEM_ram_ro]  = p2m_ram_ro,\n            [HVMMEM_mmio_dm] = p2m_mmio_dm\n        };\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(a.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail4;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail4;\n\n        rc = -EINVAL;\n        if ( a.nr < start_iter ||\n             ((a.first_pfn + a.nr - 1) < a.first_pfn) ||\n             ((a.first_pfn + a.nr - 1) > domain_get_maximum_gpfn(d)) )\n            goto param_fail4;\n            \n        if ( a.hvmmem_type >= ARRAY_SIZE(memtype) )\n            goto param_fail4;\n\n        while ( a.nr > start_iter )\n        {\n            unsigned long pfn = a.first_pfn + start_iter;\n            p2m_type_t t;\n            p2m_type_t nt;\n            mfn_t mfn;\n            mfn = get_gfn_unshare(d, pfn, &t);\n            if ( p2m_is_paging(t) )\n            {\n                put_gfn(d, pfn);\n                p2m_mem_paging_populate(d, pfn);\n                rc = -EINVAL;\n                goto param_fail4;\n            }\n            if ( p2m_is_shared(t) )\n            {\n                put_gfn(d, pfn);\n                rc = -EINVAL;\n                goto param_fail4;\n            } \n            if ( p2m_is_grant(t) )\n            {\n                put_gfn(d, pfn);\n                gdprintk(XENLOG_WARNING,\n                         \"type for pfn %#lx changed to grant while \"\n                         \"we were working?\\n\", pfn);\n                goto param_fail4;\n            }\n            else\n            {\n                nt = p2m_change_type(d, pfn, t, memtype[a.hvmmem_type]);\n                if ( nt != t )\n                {\n                    put_gfn(d, pfn);\n                    gdprintk(XENLOG_WARNING,\n                             \"type of pfn %#lx changed from %d to %d while \"\n                             \"we were trying to change it to %d\\n\",\n                             pfn, t, nt, memtype[a.hvmmem_type]);\n                    goto param_fail4;\n                }\n            }\n            put_gfn(d, pfn);\n\n            /* Check for continuation if it's not the last interation */\n            if ( a.nr > ++start_iter && !(start_iter & HVMOP_op_mask) &&\n                 hypercall_preempt_check() )\n            {\n                rc = -EAGAIN;\n                goto param_fail4;\n            }\n        }\n\n        rc = 0;\n\n    param_fail4:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_pagetable_dying:\n    {\n        struct xen_hvm_pagetable_dying a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) || !paging_mode_shadow(d) )\n            goto param_fail7;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail7;\n\n        rc = 0;\n        pagetable_dying(d, a.gpa);\n\n    param_fail7:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_get_time: {\n        xen_hvm_get_time_t gxt;\n\n        gxt.now = NOW();\n        if ( copy_to_guest(arg, &gxt, 1) )\n            rc = -EFAULT;\n        break;\n    }\n\n    case HVMOP_xentrace: {\n        xen_hvm_xentrace_t tr;\n\n        if ( copy_from_guest(&tr, arg, 1 ) )\n            return -EFAULT;\n\n        if ( tr.extra_bytes > sizeof(tr.extra)\n             || (tr.event & ~((1u<<TRC_SUBCLS_SHIFT)-1)) )\n            return -EINVAL;\n\n        /* Cycles will be taken at the vmexit and vmenter */\n        trace_var(tr.event | TRC_GUEST, 0 /*!cycles*/,\n                  tr.extra_bytes, tr.extra);\n        break;\n    }\n\n    case HVMOP_inject_trap: \n    {\n        xen_hvm_inject_trap_t tr;\n        struct domain *d;\n        struct vcpu *v;\n\n        if ( copy_from_guest(&tr, arg, 1 ) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(tr.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail8;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail8;\n\n        rc = -ENOENT;\n        if ( tr.vcpuid >= d->max_vcpus || (v = d->vcpu[tr.vcpuid]) == NULL )\n            goto param_fail8;\n        \n        if ( v->arch.hvm_vcpu.inject_trap.vector != -1 )\n            rc = -EBUSY;\n        else \n        {\n            v->arch.hvm_vcpu.inject_trap.vector = tr.vector;\n            v->arch.hvm_vcpu.inject_trap.type = tr.type;\n            v->arch.hvm_vcpu.inject_trap.error_code = tr.error_code;\n            v->arch.hvm_vcpu.inject_trap.insn_len = tr.insn_len;\n            v->arch.hvm_vcpu.inject_trap.cr2 = tr.cr2;\n            rc = 0;\n        }\n\n    param_fail8:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    default:\n    {\n        gdprintk(XENLOG_DEBUG, \"Bad HVM op %ld.\\n\", op);\n        rc = -ENOSYS;\n        break;\n    }\n    }\n\n    if ( rc == -EAGAIN )\n    {\n        ASSERT(!(start_iter & HVMOP_op_mask));\n        rc = hypercall_create_continuation(__HYPERVISOR_hvm_op, \"lh\",\n                                           op | start_iter, arg);\n    }\n\n    return rc;\n}",
        "func": "long do_hvm_op(unsigned long op, XEN_GUEST_HANDLE_PARAM(void) arg)\n\n{\n    struct domain *curr_d = current->domain;\n    unsigned long start_iter = op & ~HVMOP_op_mask;\n    long rc = 0;\n\n    switch ( op &= HVMOP_op_mask )\n    {\n    case HVMOP_set_param:\n    case HVMOP_get_param:\n    {\n        struct xen_hvm_param a;\n        struct hvm_ioreq_page *iorp;\n        struct domain *d;\n        struct vcpu *v;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        if ( a.index >= HVM_NR_PARAMS )\n            return -EINVAL;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = -EINVAL;\n        if ( !has_hvm_container_domain(d) )\n            goto param_fail;\n\n        if ( is_pvh_domain(d)\n             && (a.index != HVM_PARAM_CALLBACK_IRQ) )\n            goto param_fail;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail;\n\n        if ( op == HVMOP_set_param )\n        {\n            rc = 0;\n\n            switch ( a.index )\n            {\n            case HVM_PARAM_IOREQ_PFN:\n                iorp = &d->arch.hvm_domain.ioreq;\n                if ( (rc = hvm_set_ioreq_page(d, iorp, a.value)) != 0 )\n                    break;\n                spin_lock(&iorp->lock);\n                if ( iorp->va != NULL )\n                    /* Initialise evtchn port info if VCPUs already created. */\n                    for_each_vcpu ( d, v )\n                        get_ioreq(v)->vp_eport = v->arch.hvm_vcpu.xen_port;\n                spin_unlock(&iorp->lock);\n                break;\n            case HVM_PARAM_BUFIOREQ_PFN: \n                iorp = &d->arch.hvm_domain.buf_ioreq;\n                rc = hvm_set_ioreq_page(d, iorp, a.value);\n                break;\n            case HVM_PARAM_CALLBACK_IRQ:\n                hvm_set_callback_via(d, a.value);\n                hvm_latch_shinfo_size(d);\n                break;\n            case HVM_PARAM_TIMER_MODE:\n                if ( a.value > HVMPTM_one_missed_tick_pending )\n                    rc = -EINVAL;\n                break;\n            case HVM_PARAM_VIRIDIAN:\n                if ( a.value > 1 )\n                    rc = -EINVAL;\n                break;\n            case HVM_PARAM_IDENT_PT:\n                /* Not reflexive, as we must domain_pause(). */\n                rc = -EPERM;\n                if ( curr_d == d )\n                    break;\n\n                rc = -EINVAL;\n                if ( d->arch.hvm_domain.params[a.index] != 0 )\n                    break;\n\n                rc = 0;\n                if ( !paging_mode_hap(d) )\n                    break;\n\n                /*\n                 * Update GUEST_CR3 in each VMCS to point at identity map.\n                 * All foreign updates to guest state must synchronise on\n                 * the domctl_lock.\n                 */\n                rc = -EAGAIN;\n                if ( !domctl_lock_acquire() )\n                    break;\n\n                rc = 0;\n                domain_pause(d);\n                d->arch.hvm_domain.params[a.index] = a.value;\n                for_each_vcpu ( d, v )\n                    paging_update_cr3(v);\n                domain_unpause(d);\n\n                domctl_lock_release();\n                break;\n            case HVM_PARAM_DM_DOMAIN:\n                /* Not reflexive, as we must domain_pause(). */\n                rc = -EPERM;\n                if ( curr_d == d )\n                    break;\n\n                if ( a.value == DOMID_SELF )\n                    a.value = curr_d->domain_id;\n\n                rc = 0;\n                domain_pause(d); /* safe to change per-vcpu xen_port */\n                if ( d->vcpu[0] )\n                    rc = hvm_replace_event_channel(d->vcpu[0], a.value,\n                             (int *)&d->vcpu[0]->domain->arch.hvm_domain.params\n                                     [HVM_PARAM_BUFIOREQ_EVTCHN]);\n                if ( rc )\n                {\n                    domain_unpause(d);\n                    break;\n                }\n                iorp = &d->arch.hvm_domain.ioreq;\n                for_each_vcpu ( d, v )\n                {\n                    rc = hvm_replace_event_channel(v, a.value,\n                                                   &v->arch.hvm_vcpu.xen_port);\n                    if ( rc )\n                        break;\n\n                    spin_lock(&iorp->lock);\n                    if ( iorp->va != NULL )\n                        get_ioreq(v)->vp_eport = v->arch.hvm_vcpu.xen_port;\n                    spin_unlock(&iorp->lock);\n                }\n                domain_unpause(d);\n                break;\n            case HVM_PARAM_ACPI_S_STATE:\n                /* Not reflexive, as we must domain_pause(). */\n                rc = -EPERM;\n                if ( curr_d == d )\n                    break;\n\n                rc = 0;\n                if ( a.value == 3 )\n                    hvm_s3_suspend(d);\n                else if ( a.value == 0 )\n                    hvm_s3_resume(d);\n                else\n                    rc = -EINVAL;\n\n                break;\n            case HVM_PARAM_ACPI_IOPORTS_LOCATION:\n                rc = pmtimer_change_ioport(d, a.value);\n                break;\n            case HVM_PARAM_MEMORY_EVENT_CR0:\n            case HVM_PARAM_MEMORY_EVENT_CR3:\n            case HVM_PARAM_MEMORY_EVENT_CR4:\n                if ( d == current->domain )\n                    rc = -EPERM;\n                break;\n            case HVM_PARAM_MEMORY_EVENT_INT3:\n            case HVM_PARAM_MEMORY_EVENT_SINGLE_STEP:\n            case HVM_PARAM_MEMORY_EVENT_MSR:\n                if ( d == current->domain )\n                {\n                    rc = -EPERM;\n                    break;\n                }\n                if ( a.value & HVMPME_onchangeonly )\n                    rc = -EINVAL;\n                break;\n            case HVM_PARAM_NESTEDHVM:\n                rc = xsm_hvm_param_nested(XSM_PRIV, d);\n                if ( rc )\n                    break;\n                if ( a.value > 1 )\n                    rc = -EINVAL;\n                /* Remove the check below once we have\n                 * shadow-on-shadow.\n                 */\n                if ( cpu_has_svm && !paging_mode_hap(d) && a.value )\n                    rc = -EINVAL;\n                /* Set up NHVM state for any vcpus that are already up */\n                if ( a.value &&\n                     !d->arch.hvm_domain.params[HVM_PARAM_NESTEDHVM] )\n                    for_each_vcpu(d, v)\n                        if ( rc == 0 )\n                            rc = nestedhvm_vcpu_initialise(v);\n                if ( !a.value || rc )\n                    for_each_vcpu(d, v)\n                        nestedhvm_vcpu_destroy(v);\n                break;\n            case HVM_PARAM_BUFIOREQ_EVTCHN:\n                rc = -EINVAL;\n                break;\n            case HVM_PARAM_TRIPLE_FAULT_REASON:\n                if ( a.value > SHUTDOWN_MAX )\n                    rc = -EINVAL;\n                break;\n            }\n\n            if ( rc == 0 ) \n            {\n                d->arch.hvm_domain.params[a.index] = a.value;\n\n                switch( a.index )\n                {\n                case HVM_PARAM_MEMORY_EVENT_INT3:\n                case HVM_PARAM_MEMORY_EVENT_SINGLE_STEP:\n                {\n                    domain_pause(d);\n                    domain_unpause(d); /* Causes guest to latch new status */\n                    break;\n                }\n                case HVM_PARAM_MEMORY_EVENT_CR3:\n                {\n                    for_each_vcpu ( d, v )\n                        hvm_funcs.update_guest_cr(v, 0); /* Latches new CR3 mask through CR0 code */\n                    break;\n                }\n                }\n\n            }\n\n        }\n        else\n        {\n            switch ( a.index )\n            {\n            case HVM_PARAM_ACPI_S_STATE:\n                a.value = d->arch.hvm_domain.is_s3_suspended ? 3 : 0;\n                break;\n            default:\n                a.value = d->arch.hvm_domain.params[a.index];\n                break;\n            }\n            rc = __copy_to_guest(arg, &a, 1) ? -EFAULT : 0;\n        }\n\n        HVM_DBG_LOG(DBG_LEVEL_HCALL, \"%s param %u = %\"PRIx64,\n                    op == HVMOP_set_param ? \"set\" : \"get\",\n                    a.index, a.value);\n\n    param_fail:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_set_pci_intx_level:\n        rc = hvmop_set_pci_intx_level(\n            guest_handle_cast(arg, xen_hvm_set_pci_intx_level_t));\n        break;\n\n    case HVMOP_set_isa_irq_level:\n        rc = hvmop_set_isa_irq_level(\n            guest_handle_cast(arg, xen_hvm_set_isa_irq_level_t));\n        break;\n\n    case HVMOP_inject_msi:\n        rc = hvmop_inject_msi(\n            guest_handle_cast(arg, xen_hvm_inject_msi_t));\n        break;\n\n    case HVMOP_set_pci_link_route:\n        rc = hvmop_set_pci_link_route(\n            guest_handle_cast(arg, xen_hvm_set_pci_link_route_t));\n        break;\n\n    case HVMOP_flush_tlbs:\n        rc = guest_handle_is_null(arg) ? hvmop_flush_tlb_all() : -ENOSYS;\n        break;\n\n    case HVMOP_track_dirty_vram:\n    {\n        struct xen_hvm_track_dirty_vram a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(a.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail2;\n\n        if ( a.nr > GB(1) >> PAGE_SHIFT )\n            goto param_fail2;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail2;\n\n        rc = -ESRCH;\n        if ( d->is_dying )\n            goto param_fail2;\n\n        rc = -EINVAL;\n        if ( d->vcpu == NULL || d->vcpu[0] == NULL )\n            goto param_fail2;\n\n        if ( shadow_mode_enabled(d) )\n            rc = shadow_track_dirty_vram(d, a.first_pfn, a.nr, a.dirty_bitmap);\n        else\n            rc = hap_track_dirty_vram(d, a.first_pfn, a.nr, a.dirty_bitmap);\n\n    param_fail2:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_modified_memory:\n    {\n        struct xen_hvm_modified_memory a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(a.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail3;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail3;\n\n        rc = -EINVAL;\n        if ( a.nr < start_iter ||\n             ((a.first_pfn + a.nr - 1) < a.first_pfn) ||\n             ((a.first_pfn + a.nr - 1) > domain_get_maximum_gpfn(d)) )\n            goto param_fail3;\n\n        rc = 0;\n        if ( !paging_mode_log_dirty(d) )\n            goto param_fail3;\n\n        while ( a.nr > start_iter )\n        {\n            unsigned long pfn = a.first_pfn + start_iter;\n            struct page_info *page;\n\n            page = get_page_from_gfn(d, pfn, NULL, P2M_UNSHARE);\n            if ( page )\n            {\n                paging_mark_dirty(d, page_to_mfn(page));\n                /* These are most probably not page tables any more */\n                /* don't take a long time and don't die either */\n                sh_remove_shadows(d->vcpu[0], _mfn(page_to_mfn(page)), 1, 0);\n                put_page(page);\n            }\n\n            /* Check for continuation if it's not the last interation */\n            if ( a.nr > ++start_iter && !(start_iter & HVMOP_op_mask) &&\n                 hypercall_preempt_check() )\n            {\n                rc = -EAGAIN;\n                break;\n            }\n        }\n\n    param_fail3:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_get_mem_type:\n    {\n        struct xen_hvm_get_mem_type a;\n        struct domain *d;\n        p2m_type_t t;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail_getmemtype;\n\n        rc = -EINVAL;\n        if ( is_hvm_domain(d) )\n        {\n            /* Use get_gfn query as we are interested in the current \n             * type, not in allocating or unsharing. That'll happen \n             * on access. */\n            get_gfn_query_unlocked(d, a.pfn, &t);\n            if ( p2m_is_mmio(t) )\n                a.mem_type =  HVMMEM_mmio_dm;\n            else if ( p2m_is_readonly(t) )\n                a.mem_type =  HVMMEM_ram_ro;\n            else if ( p2m_is_ram(t) )\n                a.mem_type =  HVMMEM_ram_rw;\n            else if ( p2m_is_pod(t) )\n                a.mem_type =  HVMMEM_ram_rw;\n            else if ( p2m_is_grant(t) )\n                a.mem_type =  HVMMEM_ram_rw;\n            else\n                a.mem_type =  HVMMEM_mmio_dm;\n            rc = __copy_to_guest(arg, &a, 1) ? -EFAULT : 0;\n        }\n\n    param_fail_getmemtype:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_set_mem_type:\n    {\n        struct xen_hvm_set_mem_type a;\n        struct domain *d;\n        \n        /* Interface types to internal p2m types */\n        static const p2m_type_t memtype[] = {\n            [HVMMEM_ram_rw]  = p2m_ram_rw,\n            [HVMMEM_ram_ro]  = p2m_ram_ro,\n            [HVMMEM_mmio_dm] = p2m_mmio_dm\n        };\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(a.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail4;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail4;\n\n        rc = -EINVAL;\n        if ( a.nr < start_iter ||\n             ((a.first_pfn + a.nr - 1) < a.first_pfn) ||\n             ((a.first_pfn + a.nr - 1) > domain_get_maximum_gpfn(d)) )\n            goto param_fail4;\n            \n        if ( a.hvmmem_type >= ARRAY_SIZE(memtype) )\n            goto param_fail4;\n\n        while ( a.nr > start_iter )\n        {\n            unsigned long pfn = a.first_pfn + start_iter;\n            p2m_type_t t;\n            p2m_type_t nt;\n            mfn_t mfn;\n            mfn = get_gfn_unshare(d, pfn, &t);\n            if ( p2m_is_paging(t) )\n            {\n                put_gfn(d, pfn);\n                p2m_mem_paging_populate(d, pfn);\n                rc = -EINVAL;\n                goto param_fail4;\n            }\n            if ( p2m_is_shared(t) )\n            {\n                put_gfn(d, pfn);\n                rc = -EINVAL;\n                goto param_fail4;\n            } \n            if ( !p2m_is_ram(t) &&\n                 (!p2m_is_hole(t) || a.hvmmem_type != HVMMEM_mmio_dm) )\n            {\n                put_gfn(d, pfn);\n                goto param_fail4;\n            }\n            else\n            {\n                nt = p2m_change_type(d, pfn, t, memtype[a.hvmmem_type]);\n                if ( nt != t )\n                {\n                    put_gfn(d, pfn);\n                    gdprintk(XENLOG_WARNING,\n                             \"type of pfn %#lx changed from %d to %d while \"\n                             \"we were trying to change it to %d\\n\",\n                             pfn, t, nt, memtype[a.hvmmem_type]);\n                    goto param_fail4;\n                }\n            }\n            put_gfn(d, pfn);\n\n            /* Check for continuation if it's not the last interation */\n            if ( a.nr > ++start_iter && !(start_iter & HVMOP_op_mask) &&\n                 hypercall_preempt_check() )\n            {\n                rc = -EAGAIN;\n                goto param_fail4;\n            }\n        }\n\n        rc = 0;\n\n    param_fail4:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_pagetable_dying:\n    {\n        struct xen_hvm_pagetable_dying a;\n        struct domain *d;\n\n        if ( copy_from_guest(&a, arg, 1) )\n            return -EFAULT;\n\n        d = rcu_lock_domain_by_any_id(a.domid);\n        if ( d == NULL )\n            return -ESRCH;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) || !paging_mode_shadow(d) )\n            goto param_fail7;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail7;\n\n        rc = 0;\n        pagetable_dying(d, a.gpa);\n\n    param_fail7:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    case HVMOP_get_time: {\n        xen_hvm_get_time_t gxt;\n\n        gxt.now = NOW();\n        if ( copy_to_guest(arg, &gxt, 1) )\n            rc = -EFAULT;\n        break;\n    }\n\n    case HVMOP_xentrace: {\n        xen_hvm_xentrace_t tr;\n\n        if ( copy_from_guest(&tr, arg, 1 ) )\n            return -EFAULT;\n\n        if ( tr.extra_bytes > sizeof(tr.extra)\n             || (tr.event & ~((1u<<TRC_SUBCLS_SHIFT)-1)) )\n            return -EINVAL;\n\n        /* Cycles will be taken at the vmexit and vmenter */\n        trace_var(tr.event | TRC_GUEST, 0 /*!cycles*/,\n                  tr.extra_bytes, tr.extra);\n        break;\n    }\n\n    case HVMOP_inject_trap: \n    {\n        xen_hvm_inject_trap_t tr;\n        struct domain *d;\n        struct vcpu *v;\n\n        if ( copy_from_guest(&tr, arg, 1 ) )\n            return -EFAULT;\n\n        rc = rcu_lock_remote_domain_by_id(tr.domid, &d);\n        if ( rc != 0 )\n            return rc;\n\n        rc = -EINVAL;\n        if ( !is_hvm_domain(d) )\n            goto param_fail8;\n\n        rc = xsm_hvm_param(XSM_TARGET, d, op);\n        if ( rc )\n            goto param_fail8;\n\n        rc = -ENOENT;\n        if ( tr.vcpuid >= d->max_vcpus || (v = d->vcpu[tr.vcpuid]) == NULL )\n            goto param_fail8;\n        \n        if ( v->arch.hvm_vcpu.inject_trap.vector != -1 )\n            rc = -EBUSY;\n        else \n        {\n            v->arch.hvm_vcpu.inject_trap.vector = tr.vector;\n            v->arch.hvm_vcpu.inject_trap.type = tr.type;\n            v->arch.hvm_vcpu.inject_trap.error_code = tr.error_code;\n            v->arch.hvm_vcpu.inject_trap.insn_len = tr.insn_len;\n            v->arch.hvm_vcpu.inject_trap.cr2 = tr.cr2;\n            rc = 0;\n        }\n\n    param_fail8:\n        rcu_unlock_domain(d);\n        break;\n    }\n\n    default:\n    {\n        gdprintk(XENLOG_DEBUG, \"Bad HVM op %ld.\\n\", op);\n        rc = -ENOSYS;\n        break;\n    }\n    }\n\n    if ( rc == -EAGAIN )\n    {\n        ASSERT(!(start_iter & HVMOP_op_mask));\n        rc = hypercall_create_continuation(__HYPERVISOR_hvm_op, \"lh\",\n                                           op | start_iter, arg);\n    }\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -473,12 +473,10 @@\n                 rc = -EINVAL;\n                 goto param_fail4;\n             } \n-            if ( p2m_is_grant(t) )\n+            if ( !p2m_is_ram(t) &&\n+                 (!p2m_is_hole(t) || a.hvmmem_type != HVMMEM_mmio_dm) )\n             {\n                 put_gfn(d, pfn);\n-                gdprintk(XENLOG_WARNING,\n-                         \"type for pfn %#lx changed to grant while \"\n-                         \"we were working?\\n\", pfn);\n                 goto param_fail4;\n             }\n             else",
        "diff_line_info": {
            "deleted_lines": [
                "            if ( p2m_is_grant(t) )",
                "                gdprintk(XENLOG_WARNING,",
                "                         \"type for pfn %#lx changed to grant while \"",
                "                         \"we were working?\\n\", pfn);"
            ],
            "added_lines": [
                "            if ( !p2m_is_ram(t) &&",
                "                 (!p2m_is_hole(t) || a.hvmmem_type != HVMMEM_mmio_dm) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/gva_to_ma_par",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static inline uint64_t gva_to_ma_par(vaddr_t va)\n{\n    uint64_t par, tmp;\n    tmp = READ_CP64(PAR);\n    WRITE_CP32(va, ATS12NSOPR);\n    isb(); /* Ensure result is available. */\n    par = READ_CP64(PAR);\n    WRITE_CP64(tmp, PAR);\n    return par;\n}",
        "func": "static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)\n{\n    uint64_t par, tmp;\n    tmp = READ_CP64(PAR);\n    if ( (flags & GV2M_WRITE) == GV2M_WRITE )\n        WRITE_CP32(va, ATS12NSOPW);\n    else\n        WRITE_CP32(va, ATS12NSOPR);\n    isb(); /* Ensure result is available. */\n    par = READ_CP64(PAR);\n    WRITE_CP64(tmp, PAR);\n    return par;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,11 @@\n-static inline uint64_t gva_to_ma_par(vaddr_t va)\n+static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)\n {\n     uint64_t par, tmp;\n     tmp = READ_CP64(PAR);\n-    WRITE_CP32(va, ATS12NSOPR);\n+    if ( (flags & GV2M_WRITE) == GV2M_WRITE )\n+        WRITE_CP32(va, ATS12NSOPW);\n+    else\n+        WRITE_CP32(va, ATS12NSOPR);\n     isb(); /* Ensure result is available. */\n     par = READ_CP64(PAR);\n     WRITE_CP64(tmp, PAR);",
        "diff_line_info": {
            "deleted_lines": [
                "static inline uint64_t gva_to_ma_par(vaddr_t va)",
                "    WRITE_CP32(va, ATS12NSOPR);"
            ],
            "added_lines": [
                "static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)",
                "    if ( (flags & GV2M_WRITE) == GV2M_WRITE )",
                "        WRITE_CP32(va, ATS12NSOPW);",
                "    else",
                "        WRITE_CP32(va, ATS12NSOPR);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/gvirt_to_maddr",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static inline int gvirt_to_maddr(vaddr_t va, paddr_t *pa)\n{\n    uint64_t par = gva_to_ma_par(va);\n    if ( par & PAR_F )\n        return -EFAULT;\n    *pa = (par & PADDR_MASK & PAGE_MASK) | ((unsigned long) va & ~PAGE_MASK);\n    return 0;\n}",
        "func": "static inline int gvirt_to_maddr(vaddr_t va, paddr_t *pa, unsigned int flags)\n{\n    uint64_t par = gva_to_ma_par(va, flags);\n    if ( par & PAR_F )\n        return -EFAULT;\n    *pa = (par & PADDR_MASK & PAGE_MASK) | ((unsigned long) va & ~PAGE_MASK);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n-static inline int gvirt_to_maddr(vaddr_t va, paddr_t *pa)\n+static inline int gvirt_to_maddr(vaddr_t va, paddr_t *pa, unsigned int flags)\n {\n-    uint64_t par = gva_to_ma_par(va);\n+    uint64_t par = gva_to_ma_par(va, flags);\n     if ( par & PAR_F )\n         return -EFAULT;\n     *pa = (par & PADDR_MASK & PAGE_MASK) | ((unsigned long) va & ~PAGE_MASK);",
        "diff_line_info": {
            "deleted_lines": [
                "static inline int gvirt_to_maddr(vaddr_t va, paddr_t *pa)",
                "    uint64_t par = gva_to_ma_par(va);"
            ],
            "added_lines": [
                "static inline int gvirt_to_maddr(vaddr_t va, paddr_t *pa, unsigned int flags)",
                "    uint64_t par = gva_to_ma_par(va, flags);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/kernel_zimage_load",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static void kernel_zimage_load(struct kernel_info *info)\n{\n    paddr_t load_addr = kernel_zimage_place(info);\n    paddr_t paddr = info->zimage.kernel_addr;\n    paddr_t len = info->zimage.len;\n    unsigned long offs;\n\n    info->entry = load_addr;\n\n    place_modules(info, load_addr, load_addr + len);\n\n    printk(\"Loading zImage from %\"PRIpaddr\" to %\"PRIpaddr\"-%\"PRIpaddr\"\\n\",\n           paddr, load_addr, load_addr + len);\n    for ( offs = 0; offs < len; )\n    {\n        int rc;\n        paddr_t s, l, ma;\n        void *dst;\n\n        s = offs & ~PAGE_MASK;\n        l = min(PAGE_SIZE - s, len);\n\n        rc = gvirt_to_maddr(load_addr + offs, &ma);\n        if ( rc )\n        {\n            panic(\"Unable to map translate guest address\");\n            return;\n        }\n\n        dst = map_domain_page(ma>>PAGE_SHIFT);\n\n        copy_from_paddr(dst + s, paddr + offs, l);\n\n        unmap_domain_page(dst);\n        offs += l;\n    }\n}",
        "func": "static void kernel_zimage_load(struct kernel_info *info)\n{\n    paddr_t load_addr = kernel_zimage_place(info);\n    paddr_t paddr = info->zimage.kernel_addr;\n    paddr_t len = info->zimage.len;\n    unsigned long offs;\n\n    info->entry = load_addr;\n\n    place_modules(info, load_addr, load_addr + len);\n\n    printk(\"Loading zImage from %\"PRIpaddr\" to %\"PRIpaddr\"-%\"PRIpaddr\"\\n\",\n           paddr, load_addr, load_addr + len);\n    for ( offs = 0; offs < len; )\n    {\n        int rc;\n        paddr_t s, l, ma;\n        void *dst;\n\n        s = offs & ~PAGE_MASK;\n        l = min(PAGE_SIZE - s, len);\n\n        rc = gvirt_to_maddr(load_addr + offs, &ma, GV2M_WRITE);\n        if ( rc )\n        {\n            panic(\"Unable to map translate guest address\");\n            return;\n        }\n\n        dst = map_domain_page(ma>>PAGE_SHIFT);\n\n        copy_from_paddr(dst + s, paddr + offs, l);\n\n        unmap_domain_page(dst);\n        offs += l;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,7 @@\n         s = offs & ~PAGE_MASK;\n         l = min(PAGE_SIZE - s, len);\n \n-        rc = gvirt_to_maddr(load_addr + offs, &ma);\n+        rc = gvirt_to_maddr(load_addr + offs, &ma, GV2M_WRITE);\n         if ( rc )\n         {\n             panic(\"Unable to map translate guest address\");",
        "diff_line_info": {
            "deleted_lines": [
                "        rc = gvirt_to_maddr(load_addr + offs, &ma);"
            ],
            "added_lines": [
                "        rc = gvirt_to_maddr(load_addr + offs, &ma, GV2M_WRITE);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/gva_to_ma_par",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static inline uint64_t gva_to_ma_par(vaddr_t va)\n{\n    uint64_t par, tmp;\n    tmp = READ_CP64(PAR);\n    WRITE_CP32(va, ATS12NSOPR);\n    isb(); /* Ensure result is available. */\n    par = READ_CP64(PAR);\n    WRITE_CP64(tmp, PAR);\n    return par;\n}",
        "func": "static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)\n{\n    uint64_t par, tmp;\n    tmp = READ_CP64(PAR);\n    if ( (flags & GV2M_WRITE) == GV2M_WRITE )\n        WRITE_CP32(va, ATS12NSOPW);\n    else\n        WRITE_CP32(va, ATS12NSOPR);\n    isb(); /* Ensure result is available. */\n    par = READ_CP64(PAR);\n    WRITE_CP64(tmp, PAR);\n    return par;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,11 @@\n-static inline uint64_t gva_to_ma_par(vaddr_t va)\n+static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)\n {\n     uint64_t par, tmp;\n     tmp = READ_CP64(PAR);\n-    WRITE_CP32(va, ATS12NSOPR);\n+    if ( (flags & GV2M_WRITE) == GV2M_WRITE )\n+        WRITE_CP32(va, ATS12NSOPW);\n+    else\n+        WRITE_CP32(va, ATS12NSOPR);\n     isb(); /* Ensure result is available. */\n     par = READ_CP64(PAR);\n     WRITE_CP64(tmp, PAR);",
        "diff_line_info": {
            "deleted_lines": [
                "static inline uint64_t gva_to_ma_par(vaddr_t va)",
                "    WRITE_CP32(va, ATS12NSOPR);"
            ],
            "added_lines": [
                "static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)",
                "    if ( (flags & GV2M_WRITE) == GV2M_WRITE )",
                "        WRITE_CP32(va, ATS12NSOPW);",
                "    else",
                "        WRITE_CP32(va, ATS12NSOPR);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/initrd_load",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static void initrd_load(struct kernel_info *kinfo)\n{\n    paddr_t load_addr = kinfo->initrd_paddr;\n    paddr_t paddr = early_info.modules.module[MOD_INITRD].start;\n    paddr_t len = early_info.modules.module[MOD_INITRD].size;\n    unsigned long offs;\n    int node;\n    int res;\n    __be32 val[2];\n    __be32 *cellp;\n\n    if ( !len )\n        return;\n\n    printk(\"Loading dom0 initrd from %\"PRIpaddr\" to 0x%\"PRIpaddr\"-0x%\"PRIpaddr\"\\n\",\n           paddr, load_addr, load_addr + len);\n\n    /* Fix up linux,initrd-start and linux,initrd-end in /chosen */\n    node = fdt_path_offset(kinfo->fdt, \"/chosen\");\n    if ( node < 0 )\n        panic(\"Cannot find the /chosen node\");\n\n    cellp = (__be32 *)val;\n    dt_set_cell(&cellp, ARRAY_SIZE(val), load_addr);\n    res = fdt_setprop_inplace(kinfo->fdt, node, \"linux,initrd-start\",\n                              val, sizeof(val));\n    if ( res )\n        panic(\"Cannot fix up \\\"linux,initrd-start\\\" property\");\n\n    cellp = (__be32 *)val;\n    dt_set_cell(&cellp, ARRAY_SIZE(val), load_addr + len);\n    res = fdt_setprop_inplace(kinfo->fdt, node, \"linux,initrd-end\",\n                              val, sizeof(val));\n    if ( res )\n        panic(\"Cannot fix up \\\"linux,initrd-end\\\" property\");\n\n    for ( offs = 0; offs < len; )\n    {\n        int rc;\n        paddr_t s, l, ma;\n        void *dst;\n\n        s = offs & ~PAGE_MASK;\n        l = min(PAGE_SIZE - s, len);\n\n        rc = gvirt_to_maddr(load_addr + offs, &ma);\n        if ( rc )\n        {\n            panic(\"Unable to translate guest address\");\n            return;\n        }\n\n        dst = map_domain_page(ma>>PAGE_SHIFT);\n\n        copy_from_paddr(dst + s, paddr + offs, l);\n\n        unmap_domain_page(dst);\n        offs += l;\n    }\n}",
        "func": "static void initrd_load(struct kernel_info *kinfo)\n{\n    paddr_t load_addr = kinfo->initrd_paddr;\n    paddr_t paddr = early_info.modules.module[MOD_INITRD].start;\n    paddr_t len = early_info.modules.module[MOD_INITRD].size;\n    unsigned long offs;\n    int node;\n    int res;\n    __be32 val[2];\n    __be32 *cellp;\n\n    if ( !len )\n        return;\n\n    printk(\"Loading dom0 initrd from %\"PRIpaddr\" to 0x%\"PRIpaddr\"-0x%\"PRIpaddr\"\\n\",\n           paddr, load_addr, load_addr + len);\n\n    /* Fix up linux,initrd-start and linux,initrd-end in /chosen */\n    node = fdt_path_offset(kinfo->fdt, \"/chosen\");\n    if ( node < 0 )\n        panic(\"Cannot find the /chosen node\");\n\n    cellp = (__be32 *)val;\n    dt_set_cell(&cellp, ARRAY_SIZE(val), load_addr);\n    res = fdt_setprop_inplace(kinfo->fdt, node, \"linux,initrd-start\",\n                              val, sizeof(val));\n    if ( res )\n        panic(\"Cannot fix up \\\"linux,initrd-start\\\" property\");\n\n    cellp = (__be32 *)val;\n    dt_set_cell(&cellp, ARRAY_SIZE(val), load_addr + len);\n    res = fdt_setprop_inplace(kinfo->fdt, node, \"linux,initrd-end\",\n                              val, sizeof(val));\n    if ( res )\n        panic(\"Cannot fix up \\\"linux,initrd-end\\\" property\");\n\n    for ( offs = 0; offs < len; )\n    {\n        int rc;\n        paddr_t s, l, ma;\n        void *dst;\n\n        s = offs & ~PAGE_MASK;\n        l = min(PAGE_SIZE - s, len);\n\n        rc = gvirt_to_maddr(load_addr + offs, &ma, GV2M_WRITE);\n        if ( rc )\n        {\n            panic(\"Unable to translate guest address\");\n            return;\n        }\n\n        dst = map_domain_page(ma>>PAGE_SHIFT);\n\n        copy_from_paddr(dst + s, paddr + offs, l);\n\n        unmap_domain_page(dst);\n        offs += l;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -43,7 +43,7 @@\n         s = offs & ~PAGE_MASK;\n         l = min(PAGE_SIZE - s, len);\n \n-        rc = gvirt_to_maddr(load_addr + offs, &ma);\n+        rc = gvirt_to_maddr(load_addr + offs, &ma, GV2M_WRITE);\n         if ( rc )\n         {\n             panic(\"Unable to translate guest address\");",
        "diff_line_info": {
            "deleted_lines": [
                "        rc = gvirt_to_maddr(load_addr + offs, &ma);"
            ],
            "added_lines": [
                "        rc = gvirt_to_maddr(load_addr + offs, &ma, GV2M_WRITE);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/gva_to_ma_par",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static inline uint64_t gva_to_ma_par(vaddr_t va)\n{\n    uint64_t par, tmp;\n    tmp = READ_CP64(PAR);\n    WRITE_CP32(va, ATS12NSOPR);\n    isb(); /* Ensure result is available. */\n    par = READ_CP64(PAR);\n    WRITE_CP64(tmp, PAR);\n    return par;\n}",
        "func": "static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)\n{\n    uint64_t par, tmp;\n    tmp = READ_CP64(PAR);\n    if ( (flags & GV2M_WRITE) == GV2M_WRITE )\n        WRITE_CP32(va, ATS12NSOPW);\n    else\n        WRITE_CP32(va, ATS12NSOPR);\n    isb(); /* Ensure result is available. */\n    par = READ_CP64(PAR);\n    WRITE_CP64(tmp, PAR);\n    return par;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,11 @@\n-static inline uint64_t gva_to_ma_par(vaddr_t va)\n+static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)\n {\n     uint64_t par, tmp;\n     tmp = READ_CP64(PAR);\n-    WRITE_CP32(va, ATS12NSOPR);\n+    if ( (flags & GV2M_WRITE) == GV2M_WRITE )\n+        WRITE_CP32(va, ATS12NSOPW);\n+    else\n+        WRITE_CP32(va, ATS12NSOPR);\n     isb(); /* Ensure result is available. */\n     par = READ_CP64(PAR);\n     WRITE_CP64(tmp, PAR);",
        "diff_line_info": {
            "deleted_lines": [
                "static inline uint64_t gva_to_ma_par(vaddr_t va)",
                "    WRITE_CP32(va, ATS12NSOPR);"
            ],
            "added_lines": [
                "static inline uint64_t gva_to_ma_par(vaddr_t va, unsigned int flags)",
                "    if ( (flags & GV2M_WRITE) == GV2M_WRITE )",
                "        WRITE_CP32(va, ATS12NSOPW);",
                "    else",
                "        WRITE_CP32(va, ATS12NSOPR);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/raw_copy_from_guest",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "unsigned long raw_copy_from_guest(void *to, const void __user *from, unsigned len)\n{\n    unsigned offset = (vaddr_t)from & ~PAGE_MASK;\n\n    while ( len )\n    {\n        paddr_t g;\n        void *p;\n        unsigned size = min(len, (unsigned)(PAGE_SIZE - offset));\n\n        if ( gvirt_to_maddr((vaddr_t) from & PAGE_MASK, &g) )\n            return len;\n\n        p = map_domain_page(g>>PAGE_SHIFT);\n        p += ((vaddr_t)from & (~PAGE_MASK));\n\n        memcpy(to, p, size);\n\n        unmap_domain_page(p);\n        len -= size;\n        from += size;\n        to += size;\n        /*\n         * After the first iteration, guest virtual address is correctly\n         * aligned to PAGE_SIZE.\n         */\n        offset = 0;\n    }\n    return 0;\n}",
        "func": "unsigned long raw_copy_from_guest(void *to, const void __user *from, unsigned len)\n{\n    unsigned offset = (vaddr_t)from & ~PAGE_MASK;\n\n    while ( len )\n    {\n        paddr_t g;\n        void *p;\n        unsigned size = min(len, (unsigned)(PAGE_SIZE - offset));\n\n        if ( gvirt_to_maddr((vaddr_t) from & PAGE_MASK, &g, GV2M_READ) )\n            return len;\n\n        p = map_domain_page(g>>PAGE_SHIFT);\n        p += ((vaddr_t)from & (~PAGE_MASK));\n\n        memcpy(to, p, size);\n\n        unmap_domain_page(p);\n        len -= size;\n        from += size;\n        to += size;\n        /*\n         * After the first iteration, guest virtual address is correctly\n         * aligned to PAGE_SIZE.\n         */\n        offset = 0;\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n         void *p;\n         unsigned size = min(len, (unsigned)(PAGE_SIZE - offset));\n \n-        if ( gvirt_to_maddr((vaddr_t) from & PAGE_MASK, &g) )\n+        if ( gvirt_to_maddr((vaddr_t) from & PAGE_MASK, &g, GV2M_READ) )\n             return len;\n \n         p = map_domain_page(g>>PAGE_SHIFT);",
        "diff_line_info": {
            "deleted_lines": [
                "        if ( gvirt_to_maddr((vaddr_t) from & PAGE_MASK, &g) )"
            ],
            "added_lines": [
                "        if ( gvirt_to_maddr((vaddr_t) from & PAGE_MASK, &g, GV2M_READ) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/raw_clear_guest",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "unsigned long raw_clear_guest(void *to, unsigned len)\n{\n    /* XXX needs to handle faults */\n    unsigned offset = (vaddr_t)to & ~PAGE_MASK;\n\n    while ( len )\n    {\n        paddr_t g;\n        void *p;\n        unsigned size = min(len, (unsigned)PAGE_SIZE - offset);\n\n        if ( gvirt_to_maddr((vaddr_t) to, &g) )\n            return len;\n\n        p = map_domain_page(g>>PAGE_SHIFT);\n        p += offset;\n        memset(p, 0x00, size);\n\n        unmap_domain_page(p - offset);\n        len -= size;\n        to += size;\n        /*\n         * After the first iteration, guest virtual address is correctly\n         * aligned to PAGE_SIZE.\n         */\n        offset = 0;\n    }\n\n    return 0;\n}",
        "func": "unsigned long raw_clear_guest(void *to, unsigned len)\n{\n    /* XXX needs to handle faults */\n    unsigned offset = (vaddr_t)to & ~PAGE_MASK;\n\n    while ( len )\n    {\n        paddr_t g;\n        void *p;\n        unsigned size = min(len, (unsigned)PAGE_SIZE - offset);\n\n        if ( gvirt_to_maddr((vaddr_t) to, &g, GV2M_WRITE) )\n            return len;\n\n        p = map_domain_page(g>>PAGE_SHIFT);\n        p += offset;\n        memset(p, 0x00, size);\n\n        unmap_domain_page(p - offset);\n        len -= size;\n        to += size;\n        /*\n         * After the first iteration, guest virtual address is correctly\n         * aligned to PAGE_SIZE.\n         */\n        offset = 0;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,7 @@\n         void *p;\n         unsigned size = min(len, (unsigned)PAGE_SIZE - offset);\n \n-        if ( gvirt_to_maddr((vaddr_t) to, &g) )\n+        if ( gvirt_to_maddr((vaddr_t) to, &g, GV2M_WRITE) )\n             return len;\n \n         p = map_domain_page(g>>PAGE_SHIFT);",
        "diff_line_info": {
            "deleted_lines": [
                "        if ( gvirt_to_maddr((vaddr_t) to, &g) )"
            ],
            "added_lines": [
                "        if ( gvirt_to_maddr((vaddr_t) to, &g, GV2M_WRITE) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/raw_copy_to_guest_helper",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static unsigned long raw_copy_to_guest_helper(void *to, const void *from,\n                                              unsigned len, int flush_dcache)\n{\n    /* XXX needs to handle faults */\n    unsigned offset = (vaddr_t)to & ~PAGE_MASK;\n\n    while ( len )\n    {\n        paddr_t g;\n        void *p;\n        unsigned size = min(len, (unsigned)PAGE_SIZE - offset);\n\n        if ( gvirt_to_maddr((vaddr_t) to, &g) )\n            return len;\n\n        p = map_domain_page(g>>PAGE_SHIFT);\n        p += offset;\n        memcpy(p, from, size);\n        if ( flush_dcache )\n            clean_xen_dcache_va_range(p, size);\n\n        unmap_domain_page(p - offset);\n        len -= size;\n        from += size;\n        to += size;\n        /*\n         * After the first iteration, guest virtual address is correctly\n         * aligned to PAGE_SIZE.\n         */\n        offset = 0;\n    }\n\n    return 0;\n}",
        "func": "static unsigned long raw_copy_to_guest_helper(void *to, const void *from,\n                                              unsigned len, int flush_dcache)\n{\n    /* XXX needs to handle faults */\n    unsigned offset = (vaddr_t)to & ~PAGE_MASK;\n\n    while ( len )\n    {\n        paddr_t g;\n        void *p;\n        unsigned size = min(len, (unsigned)PAGE_SIZE - offset);\n\n        if ( gvirt_to_maddr((vaddr_t) to, &g, GV2M_WRITE) )\n            return len;\n\n        p = map_domain_page(g>>PAGE_SHIFT);\n        p += offset;\n        memcpy(p, from, size);\n        if ( flush_dcache )\n            clean_xen_dcache_va_range(p, size);\n\n        unmap_domain_page(p - offset);\n        len -= size;\n        from += size;\n        to += size;\n        /*\n         * After the first iteration, guest virtual address is correctly\n         * aligned to PAGE_SIZE.\n         */\n        offset = 0;\n    }\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n         void *p;\n         unsigned size = min(len, (unsigned)PAGE_SIZE - offset);\n \n-        if ( gvirt_to_maddr((vaddr_t) to, &g) )\n+        if ( gvirt_to_maddr((vaddr_t) to, &g, GV2M_WRITE) )\n             return len;\n \n         p = map_domain_page(g>>PAGE_SHIFT);",
        "diff_line_info": {
            "deleted_lines": [
                "        if ( gvirt_to_maddr((vaddr_t) to, &g) )"
            ],
            "added_lines": [
                "        if ( gvirt_to_maddr((vaddr_t) to, &g, GV2M_WRITE) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3969",
        "func_name": "xen-project/xen/show_guest_stack",
        "description": "Xen 4.4.x, when running on an ARM system, does not properly check write permissions on virtual addresses, which allows local guest administrators to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/xen-project/xen/commit/0fbaa84f60af1c27dcc78a6154d64227381e72e9",
        "commit_title": "xen: arm: check permissions when copying to/from guest virtual addresses",
        "commit_text": " In particular we need to make sure the guest has write permissions to buffers which it passes as output buffers for hypercalls, otherwise the guest can overwrite memory which it shouldn't be able to write (like r/o grant table mappings).  This is XSA-98. ",
        "func_before": "static void show_guest_stack(struct vcpu *v, struct cpu_user_regs *regs)\n{\n    int i;\n    vaddr_t sp;\n    paddr_t stack_phys;\n    void *mapped;\n    unsigned long *stack, addr;\n\n    if ( test_bit(_VPF_down, &v->pause_flags) )\n    {\n        printk(\"No stack trace, VCPU offline\\n\");\n        return;\n    }\n\n    switch ( regs->cpsr & PSR_MODE_MASK )\n    {\n    case PSR_MODE_USR:\n    case PSR_MODE_SYS:\n#ifdef CONFIG_ARM_64\n    case PSR_MODE_EL0t:\n#endif\n        printk(\"No stack trace for guest user-mode\\n\");\n        return;\n\n    case PSR_MODE_FIQ:\n        sp = regs->sp_fiq;\n        break;\n    case PSR_MODE_IRQ:\n        sp = regs->sp_irq;\n        break;\n    case PSR_MODE_SVC:\n        sp = regs->sp_svc;\n        break;\n    case PSR_MODE_ABT:\n        sp = regs->sp_abt;\n        break;\n    case PSR_MODE_UND:\n        sp = regs->sp_und;\n        break;\n\n#ifdef CONFIG_ARM_64\n    case PSR_MODE_EL1t:\n        sp = regs->sp_el0;\n        break;\n    case PSR_MODE_EL1h:\n        sp = regs->sp_el1;\n        break;\n#endif\n\n    case PSR_MODE_HYP:\n    case PSR_MODE_MON:\n#ifdef CONFIG_ARM_64\n    case PSR_MODE_EL3h:\n    case PSR_MODE_EL3t:\n    case PSR_MODE_EL2h:\n    case PSR_MODE_EL2t:\n#endif\n    default:\n        BUG();\n        return;\n    }\n\n    printk(\"Guest stack trace from sp=%\"PRIvaddr\":\\n  \", sp);\n\n    if ( gvirt_to_maddr(sp, &stack_phys) )\n    {\n        printk(\"Failed to convert stack to physical address\\n\");\n        return;\n    }\n\n    mapped = map_domain_page(stack_phys >> PAGE_SHIFT);\n\n    stack = mapped + (sp & ~PAGE_MASK);\n\n    for ( i = 0; i < (debug_stack_lines*stack_words_per_line); i++ )\n    {\n        if ( (((long)stack - 1) ^ ((long)(stack + 1) - 1)) & PAGE_SIZE )\n            break;\n        addr = *stack;\n        if ( (i != 0) && ((i % stack_words_per_line) == 0) )\n            printk(\"\\n  \");\n        printk(\" %p\", _p(addr));\n        stack++;\n    }\n    if ( i == 0 )\n        printk(\"Stack empty.\");\n    printk(\"\\n\");\n    unmap_domain_page(mapped);\n\n}",
        "func": "static void show_guest_stack(struct vcpu *v, struct cpu_user_regs *regs)\n{\n    int i;\n    vaddr_t sp;\n    paddr_t stack_phys;\n    void *mapped;\n    unsigned long *stack, addr;\n\n    if ( test_bit(_VPF_down, &v->pause_flags) )\n    {\n        printk(\"No stack trace, VCPU offline\\n\");\n        return;\n    }\n\n    switch ( regs->cpsr & PSR_MODE_MASK )\n    {\n    case PSR_MODE_USR:\n    case PSR_MODE_SYS:\n#ifdef CONFIG_ARM_64\n    case PSR_MODE_EL0t:\n#endif\n        printk(\"No stack trace for guest user-mode\\n\");\n        return;\n\n    case PSR_MODE_FIQ:\n        sp = regs->sp_fiq;\n        break;\n    case PSR_MODE_IRQ:\n        sp = regs->sp_irq;\n        break;\n    case PSR_MODE_SVC:\n        sp = regs->sp_svc;\n        break;\n    case PSR_MODE_ABT:\n        sp = regs->sp_abt;\n        break;\n    case PSR_MODE_UND:\n        sp = regs->sp_und;\n        break;\n\n#ifdef CONFIG_ARM_64\n    case PSR_MODE_EL1t:\n        sp = regs->sp_el0;\n        break;\n    case PSR_MODE_EL1h:\n        sp = regs->sp_el1;\n        break;\n#endif\n\n    case PSR_MODE_HYP:\n    case PSR_MODE_MON:\n#ifdef CONFIG_ARM_64\n    case PSR_MODE_EL3h:\n    case PSR_MODE_EL3t:\n    case PSR_MODE_EL2h:\n    case PSR_MODE_EL2t:\n#endif\n    default:\n        BUG();\n        return;\n    }\n\n    printk(\"Guest stack trace from sp=%\"PRIvaddr\":\\n  \", sp);\n\n    if ( gvirt_to_maddr(sp, &stack_phys, GV2M_READ) )\n    {\n        printk(\"Failed to convert stack to physical address\\n\");\n        return;\n    }\n\n    mapped = map_domain_page(stack_phys >> PAGE_SHIFT);\n\n    stack = mapped + (sp & ~PAGE_MASK);\n\n    for ( i = 0; i < (debug_stack_lines*stack_words_per_line); i++ )\n    {\n        if ( (((long)stack - 1) ^ ((long)(stack + 1) - 1)) & PAGE_SIZE )\n            break;\n        addr = *stack;\n        if ( (i != 0) && ((i % stack_words_per_line) == 0) )\n            printk(\"\\n  \");\n        printk(\" %p\", _p(addr));\n        stack++;\n    }\n    if ( i == 0 )\n        printk(\"Stack empty.\");\n    printk(\"\\n\");\n    unmap_domain_page(mapped);\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -62,7 +62,7 @@\n \n     printk(\"Guest stack trace from sp=%\"PRIvaddr\":\\n  \", sp);\n \n-    if ( gvirt_to_maddr(sp, &stack_phys) )\n+    if ( gvirt_to_maddr(sp, &stack_phys, GV2M_READ) )\n     {\n         printk(\"Failed to convert stack to physical address\\n\");\n         return;",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( gvirt_to_maddr(sp, &stack_phys) )"
            ],
            "added_lines": [
                "    if ( gvirt_to_maddr(sp, &stack_phys, GV2M_READ) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3980",
        "func_name": "ueno/libfep/_fep_open_control_socket",
        "description": "libfep 0.0.5 before 0.1.0 does not properly use UNIX domain sockets in the abstract namespace, which allows local users to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/ueno/libfep/commit/293d9d3f7565f01a9dc40b53259886832eaa2ace",
        "commit_title": "Don't use abstract Unix domain sockets",
        "commit_text": "",
        "func_before": "int\n_fep_open_control_socket (Fep *fep)\n{\n  struct sockaddr_un sun;\n  char *path;\n  int fd;\n  ssize_t sun_len;\n\n  fd = socket (AF_UNIX, SOCK_STREAM, 0);\n  if (fd < 0)\n    {\n      perror (\"socket\");\n      return -1;\n    }\n\n  path = create_socket_name (\"fep-XXXXXX/control\");\n  if (strlen (path) + 1 >= sizeof(sun.sun_path))\n    {\n      fep_log (FEP_LOG_LEVEL_WARNING,\n\t       \"unix domain socket path too long: %d + 1 >= %d\",\n\t       strlen (path),\n\t       sizeof (sun.sun_path));\n      free (path);\n      return -1;\n    }\n\n  memset (&sun, 0, sizeof(sun));\n  sun.sun_family = AF_UNIX;\n\n#ifdef __linux__\n  sun.sun_path[0] = '\\0';\n  memcpy (sun.sun_path + 1, path, strlen (path));\n  sun_len = offsetof (struct sockaddr_un, sun_path) + strlen (path) + 1;\n  remove_control_socket (path);\n#else\n  memcpy (sun.sun_path, path, strlen (path));\n  sun_len = sizeof (struct sockaddr_un);\n#endif\n\n  if (bind (fd, (const struct sockaddr *) &sun, sun_len) < 0)\n    {\n      perror (\"bind\");\n      free (path);\n      close (fd);\n      return -1;\n    }\n\n  if (listen (fd, 5) < 0)\n    {\n      perror (\"listen\");\n      free (path);\n      close (fd);\n      return -1;\n    }\n\n  fep->server = fd;\n  fep->control_socket_path = path;\n  return 0;\n}",
        "func": "int\n_fep_open_control_socket (Fep *fep)\n{\n  struct sockaddr_un sun;\n  char *path;\n  int fd;\n  ssize_t sun_len;\n\n  fd = socket (AF_UNIX, SOCK_STREAM, 0);\n  if (fd < 0)\n    {\n      perror (\"socket\");\n      return -1;\n    }\n\n  path = create_socket_name (\"fep-XXXXXX/control\");\n  if (strlen (path) + 1 >= sizeof(sun.sun_path))\n    {\n      fep_log (FEP_LOG_LEVEL_WARNING,\n\t       \"unix domain socket path too long: %d + 1 >= %d\",\n\t       strlen (path),\n\t       sizeof (sun.sun_path));\n      free (path);\n      return -1;\n    }\n\n  memset (&sun, 0, sizeof(sun));\n  sun.sun_family = AF_UNIX;\n\n  memcpy (sun.sun_path, path, strlen (path));\n  sun_len = sizeof (struct sockaddr_un);\n\n  if (bind (fd, (const struct sockaddr *) &sun, sun_len) < 0)\n    {\n      perror (\"bind\");\n      free (path);\n      close (fd);\n      return -1;\n    }\n\n  if (listen (fd, 5) < 0)\n    {\n      perror (\"listen\");\n      free (path);\n      close (fd);\n      return -1;\n    }\n\n  fep->server = fd;\n  fep->control_socket_path = path;\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,15 +27,8 @@\n   memset (&sun, 0, sizeof(sun));\n   sun.sun_family = AF_UNIX;\n \n-#ifdef __linux__\n-  sun.sun_path[0] = '\\0';\n-  memcpy (sun.sun_path + 1, path, strlen (path));\n-  sun_len = offsetof (struct sockaddr_un, sun_path) + strlen (path) + 1;\n-  remove_control_socket (path);\n-#else\n   memcpy (sun.sun_path, path, strlen (path));\n   sun_len = sizeof (struct sockaddr_un);\n-#endif\n \n   if (bind (fd, (const struct sockaddr *) &sun, sun_len) < 0)\n     {",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef __linux__",
                "  sun.sun_path[0] = '\\0';",
                "  memcpy (sun.sun_path + 1, path, strlen (path));",
                "  sun_len = offsetof (struct sockaddr_un, sun_path) + strlen (path) + 1;",
                "  remove_control_socket (path);",
                "#else",
                "#endif"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-3980",
        "func_name": "ueno/libfep/fep_client_open",
        "description": "libfep 0.0.5 before 0.1.0 does not properly use UNIX domain sockets in the abstract namespace, which allows local users to gain privileges via unspecified vectors.",
        "git_url": "https://github.com/ueno/libfep/commit/293d9d3f7565f01a9dc40b53259886832eaa2ace",
        "commit_title": "Don't use abstract Unix domain sockets",
        "commit_text": "",
        "func_before": "FepClient *\nfep_client_open (const char *address)\n{\n  FepClient *client;\n  struct sockaddr_un sun;\n  ssize_t sun_len;\n  int retval;\n\n  if (!address)\n    address = getenv (\"LIBFEP_CONTROL_SOCK\");\n  if (!address)\n    return NULL;\n\n  if (strlen (address) + 1 >= sizeof(sun.sun_path))\n    {\n      fep_log (FEP_LOG_LEVEL_WARNING,\n\t       \"unix domain socket path too long: %d + 1 >= %d\",\n\t       strlen (address),\n\t       sizeof (sun.sun_path));\n      free (address);\n      return NULL;\n    }\n\n  client = xzalloc (sizeof(FepClient));\n  client->filter_running = false;\n  client->messages = NULL;\n\n  memset (&sun, 0, sizeof(struct sockaddr_un));\n  sun.sun_family = AF_UNIX;\n\n#ifdef __linux__\n  sun.sun_path[0] = '\\0';\n  memcpy (sun.sun_path + 1, address, strlen (address));\n  sun_len = offsetof (struct sockaddr_un, sun_path) + strlen (address) + 1;\n#else\n  memcpy (sun.sun_path, address, strlen (address));\n  sun_len = sizeof (struct sockaddr_un);\n#endif\n\n  client->control = socket (AF_UNIX, SOCK_STREAM, 0);\n  if (client->control < 0)\n    {\n      free (client);\n      return NULL;\n    }\n\n  retval = connect (client->control,\n\t\t    (const struct sockaddr *) &sun,\n\t\t    sun_len);\n  if (retval < 0)\n    {\n      close (client->control);\n      free (client);\n      return NULL;\n    }\n\n  return client;\n}",
        "func": "FepClient *\nfep_client_open (const char *address)\n{\n  FepClient *client;\n  struct sockaddr_un sun;\n  ssize_t sun_len;\n  int retval;\n\n  if (!address)\n    address = getenv (\"LIBFEP_CONTROL_SOCK\");\n  if (!address)\n    return NULL;\n\n  if (strlen (address) + 1 >= sizeof(sun.sun_path))\n    {\n      fep_log (FEP_LOG_LEVEL_WARNING,\n\t       \"unix domain socket path too long: %d + 1 >= %d\",\n\t       strlen (address),\n\t       sizeof (sun.sun_path));\n      free (address);\n      return NULL;\n    }\n\n  client = xzalloc (sizeof(FepClient));\n  client->filter_running = false;\n  client->messages = NULL;\n\n  memset (&sun, 0, sizeof(struct sockaddr_un));\n  sun.sun_family = AF_UNIX;\n\n  memcpy (sun.sun_path, address, strlen (address));\n  sun_len = sizeof (struct sockaddr_un);\n\n  client->control = socket (AF_UNIX, SOCK_STREAM, 0);\n  if (client->control < 0)\n    {\n      free (client);\n      return NULL;\n    }\n\n  retval = connect (client->control,\n\t\t    (const struct sockaddr *) &sun,\n\t\t    sun_len);\n  if (retval < 0)\n    {\n      close (client->control);\n      free (client);\n      return NULL;\n    }\n\n  return client;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,14 +28,8 @@\n   memset (&sun, 0, sizeof(struct sockaddr_un));\n   sun.sun_family = AF_UNIX;\n \n-#ifdef __linux__\n-  sun.sun_path[0] = '\\0';\n-  memcpy (sun.sun_path + 1, address, strlen (address));\n-  sun_len = offsetof (struct sockaddr_un, sun_path) + strlen (address) + 1;\n-#else\n   memcpy (sun.sun_path, address, strlen (address));\n   sun_len = sizeof (struct sockaddr_un);\n-#endif\n \n   client->control = socket (AF_UNIX, SOCK_STREAM, 0);\n   if (client->control < 0)",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef __linux__",
                "  sun.sun_path[0] = '\\0';",
                "  memcpy (sun.sun_path + 1, address, strlen (address));",
                "  sun_len = offsetof (struct sockaddr_un, sun_path) + strlen (address) + 1;",
                "#else",
                "#endif"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2013-2182",
        "func_name": "monkey/_mkp_stage_30",
        "description": "The Mandril security plugin in Monkey HTTP Daemon (monkeyd) before 1.5.0 allows remote attackers to bypass access restrictions via a crafted URI, as demonstrated by an encoded forward slash.",
        "git_url": "https://github.com/monkey/monkey/commit/15f72c1ee5e0afad20232bdf0fcecab8d62a5d89",
        "commit_title": "Mandril: check decoded URI (fix #92)",
        "commit_text": "",
        "func_before": "int _mkp_stage_30(struct plugin *p,\n        struct client_session *cs,\n        struct session_request *sr)\n{\n    mk_ptr_t referer;\n    (void) p;\n    (void) cs;\n\n    PLUGIN_TRACE(\"[FD %i] Mandril validating URL\", cs->socket);\n    if (mk_security_check_url(sr->uri) < 0) {\n        PLUGIN_TRACE(\"[FD %i] Close connection, blocked URL\", cs->socket);\n        mk_api->header_set_http_status(sr, MK_CLIENT_FORBIDDEN);\n        return MK_PLUGIN_RET_CLOSE_CONX;\n    }\n\n    PLUGIN_TRACE(\"[FD %d] Mandril validating hotlinking\", cs->socket);\n    referer = mk_api->header_get(&sr->headers_toc, \"Referer\", strlen(\"Referer\"));\n    if (mk_security_check_hotlink(sr->uri_processed, sr->host, referer) < 0) {\n        PLUGIN_TRACE(\"[FD %i] Close connection, deny hotlinking.\", cs->socket);\n        mk_api->header_set_http_status(sr, MK_CLIENT_FORBIDDEN);\n        return MK_PLUGIN_RET_CLOSE_CONX;\n    }\n\n    return MK_PLUGIN_RET_NOT_ME;\n}",
        "func": "int _mkp_stage_30(struct plugin *p,\n        struct client_session *cs,\n        struct session_request *sr)\n{\n    mk_ptr_t referer;\n    (void) p;\n    (void) cs;\n\n    PLUGIN_TRACE(\"[FD %i] Mandril validating URL\", cs->socket);\n\n    if (mk_security_check_url(sr->uri_processed) < 0) {\n        PLUGIN_TRACE(\"[FD %i] Close connection, blocked URL\", cs->socket);\n        mk_api->header_set_http_status(sr, MK_CLIENT_FORBIDDEN);\n        return MK_PLUGIN_RET_CLOSE_CONX;\n    }\n\n    PLUGIN_TRACE(\"[FD %d] Mandril validating hotlinking\", cs->socket);\n    referer = mk_api->header_get(&sr->headers_toc, \"Referer\", strlen(\"Referer\"));\n    if (mk_security_check_hotlink(sr->uri_processed, sr->host, referer) < 0) {\n        PLUGIN_TRACE(\"[FD %i] Close connection, deny hotlinking.\", cs->socket);\n        mk_api->header_set_http_status(sr, MK_CLIENT_FORBIDDEN);\n        return MK_PLUGIN_RET_CLOSE_CONX;\n    }\n\n    return MK_PLUGIN_RET_NOT_ME;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,8 @@\n     (void) cs;\n \n     PLUGIN_TRACE(\"[FD %i] Mandril validating URL\", cs->socket);\n-    if (mk_security_check_url(sr->uri) < 0) {\n+\n+    if (mk_security_check_url(sr->uri_processed) < 0) {\n         PLUGIN_TRACE(\"[FD %i] Close connection, blocked URL\", cs->socket);\n         mk_api->header_set_http_status(sr, MK_CLIENT_FORBIDDEN);\n         return MK_PLUGIN_RET_CLOSE_CONX;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (mk_security_check_url(sr->uri) < 0) {"
            ],
            "added_lines": [
                "",
                "    if (mk_security_check_url(sr->uri_processed) < 0) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4014",
        "func_name": "torvalds/linux/generic_permission",
        "description": "The capabilities implementation in the Linux kernel before 3.14.8 does not properly consider that namespaces are inapplicable to inodes, which allows local users to bypass intended chmod restrictions by first creating a user namespace, as demonstrated by setting the setgid bit on a file with group ownership of root.",
        "git_url": "https://github.com/torvalds/linux/commit/23adbe12ef7d3d4195e80800ab36b37bee28cd03",
        "commit_title": "fs,userns: Change inode_capable to capable_wrt_inode_uidgid",
        "commit_text": " The kernel has no concept of capabilities with respect to inodes; inodes exist independently of namespaces.  For example, inode_capable(inode, CAP_LINUX_IMMUTABLE) would be nonsense.  This patch changes inode_capable to check for uid and gid mappings and renames it to capable_wrt_inode_uidgid, which should make it more obvious what it does.  Fixes CVE-2014-4014.  Cc: Theodore Ts'o <tytso@mit.edu> Cc: Serge Hallyn <serge.hallyn@ubuntu.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Dave Chinner <david@fromorbit.com> Cc: stable@vger.kernel.org",
        "func_before": "int generic_permission(struct inode *inode, int mask)\n{\n\tint ret;\n\n\t/*\n\t * Do the basic permission checks.\n\t */\n\tret = acl_permission_check(inode, mask);\n\tif (ret != -EACCES)\n\t\treturn ret;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\t/* DACs are overridable for directories */\n\t\tif (inode_capable(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\t\tif (!(mask & MAY_WRITE))\n\t\t\tif (inode_capable(inode, CAP_DAC_READ_SEARCH))\n\t\t\t\treturn 0;\n\t\treturn -EACCES;\n\t}\n\t/*\n\t * Read/write DACs are always overridable.\n\t * Executable DACs are overridable when there is\n\t * at least one exec bit set.\n\t */\n\tif (!(mask & MAY_EXEC) || (inode->i_mode & S_IXUGO))\n\t\tif (inode_capable(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\n\t/*\n\t * Searching includes executable on directories, else just read.\n\t */\n\tmask &= MAY_READ | MAY_WRITE | MAY_EXEC;\n\tif (mask == MAY_READ)\n\t\tif (inode_capable(inode, CAP_DAC_READ_SEARCH))\n\t\t\treturn 0;\n\n\treturn -EACCES;\n}",
        "func": "int generic_permission(struct inode *inode, int mask)\n{\n\tint ret;\n\n\t/*\n\t * Do the basic permission checks.\n\t */\n\tret = acl_permission_check(inode, mask);\n\tif (ret != -EACCES)\n\t\treturn ret;\n\n\tif (S_ISDIR(inode->i_mode)) {\n\t\t/* DACs are overridable for directories */\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\t\tif (!(mask & MAY_WRITE))\n\t\t\tif (capable_wrt_inode_uidgid(inode,\n\t\t\t\t\t\t     CAP_DAC_READ_SEARCH))\n\t\t\t\treturn 0;\n\t\treturn -EACCES;\n\t}\n\t/*\n\t * Read/write DACs are always overridable.\n\t * Executable DACs are overridable when there is\n\t * at least one exec bit set.\n\t */\n\tif (!(mask & MAY_EXEC) || (inode->i_mode & S_IXUGO))\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n\t\t\treturn 0;\n\n\t/*\n\t * Searching includes executable on directories, else just read.\n\t */\n\tmask &= MAY_READ | MAY_WRITE | MAY_EXEC;\n\tif (mask == MAY_READ)\n\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_READ_SEARCH))\n\t\t\treturn 0;\n\n\treturn -EACCES;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,10 +11,11 @@\n \n \tif (S_ISDIR(inode->i_mode)) {\n \t\t/* DACs are overridable for directories */\n-\t\tif (inode_capable(inode, CAP_DAC_OVERRIDE))\n+\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n \t\t\treturn 0;\n \t\tif (!(mask & MAY_WRITE))\n-\t\t\tif (inode_capable(inode, CAP_DAC_READ_SEARCH))\n+\t\t\tif (capable_wrt_inode_uidgid(inode,\n+\t\t\t\t\t\t     CAP_DAC_READ_SEARCH))\n \t\t\t\treturn 0;\n \t\treturn -EACCES;\n \t}\n@@ -24,7 +25,7 @@\n \t * at least one exec bit set.\n \t */\n \tif (!(mask & MAY_EXEC) || (inode->i_mode & S_IXUGO))\n-\t\tif (inode_capable(inode, CAP_DAC_OVERRIDE))\n+\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))\n \t\t\treturn 0;\n \n \t/*\n@@ -32,7 +33,7 @@\n \t */\n \tmask &= MAY_READ | MAY_WRITE | MAY_EXEC;\n \tif (mask == MAY_READ)\n-\t\tif (inode_capable(inode, CAP_DAC_READ_SEARCH))\n+\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_READ_SEARCH))\n \t\t\treturn 0;\n \n \treturn -EACCES;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (inode_capable(inode, CAP_DAC_OVERRIDE))",
                "\t\t\tif (inode_capable(inode, CAP_DAC_READ_SEARCH))",
                "\t\tif (inode_capable(inode, CAP_DAC_OVERRIDE))",
                "\t\tif (inode_capable(inode, CAP_DAC_READ_SEARCH))"
            ],
            "added_lines": [
                "\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))",
                "\t\t\tif (capable_wrt_inode_uidgid(inode,",
                "\t\t\t\t\t\t     CAP_DAC_READ_SEARCH))",
                "\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_OVERRIDE))",
                "\t\tif (capable_wrt_inode_uidgid(inode, CAP_DAC_READ_SEARCH))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4014",
        "func_name": "torvalds/linux/check_sticky",
        "description": "The capabilities implementation in the Linux kernel before 3.14.8 does not properly consider that namespaces are inapplicable to inodes, which allows local users to bypass intended chmod restrictions by first creating a user namespace, as demonstrated by setting the setgid bit on a file with group ownership of root.",
        "git_url": "https://github.com/torvalds/linux/commit/23adbe12ef7d3d4195e80800ab36b37bee28cd03",
        "commit_title": "fs,userns: Change inode_capable to capable_wrt_inode_uidgid",
        "commit_text": " The kernel has no concept of capabilities with respect to inodes; inodes exist independently of namespaces.  For example, inode_capable(inode, CAP_LINUX_IMMUTABLE) would be nonsense.  This patch changes inode_capable to check for uid and gid mappings and renames it to capable_wrt_inode_uidgid, which should make it more obvious what it does.  Fixes CVE-2014-4014.  Cc: Theodore Ts'o <tytso@mit.edu> Cc: Serge Hallyn <serge.hallyn@ubuntu.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Dave Chinner <david@fromorbit.com> Cc: stable@vger.kernel.org",
        "func_before": "static inline int check_sticky(struct inode *dir, struct inode *inode)\n{\n\tkuid_t fsuid = current_fsuid();\n\n\tif (!(dir->i_mode & S_ISVTX))\n\t\treturn 0;\n\tif (uid_eq(inode->i_uid, fsuid))\n\t\treturn 0;\n\tif (uid_eq(dir->i_uid, fsuid))\n\t\treturn 0;\n\treturn !inode_capable(inode, CAP_FOWNER);\n}",
        "func": "static inline int check_sticky(struct inode *dir, struct inode *inode)\n{\n\tkuid_t fsuid = current_fsuid();\n\n\tif (!(dir->i_mode & S_ISVTX))\n\t\treturn 0;\n\tif (uid_eq(inode->i_uid, fsuid))\n\t\treturn 0;\n\tif (uid_eq(dir->i_uid, fsuid))\n\t\treturn 0;\n\treturn !capable_wrt_inode_uidgid(inode, CAP_FOWNER);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,5 +8,5 @@\n \t\treturn 0;\n \tif (uid_eq(dir->i_uid, fsuid))\n \t\treturn 0;\n-\treturn !inode_capable(inode, CAP_FOWNER);\n+\treturn !capable_wrt_inode_uidgid(inode, CAP_FOWNER);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn !inode_capable(inode, CAP_FOWNER);"
            ],
            "added_lines": [
                "\treturn !capable_wrt_inode_uidgid(inode, CAP_FOWNER);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4014",
        "func_name": "torvalds/linux/xfs_ioctl_setattr",
        "description": "The capabilities implementation in the Linux kernel before 3.14.8 does not properly consider that namespaces are inapplicable to inodes, which allows local users to bypass intended chmod restrictions by first creating a user namespace, as demonstrated by setting the setgid bit on a file with group ownership of root.",
        "git_url": "https://github.com/torvalds/linux/commit/23adbe12ef7d3d4195e80800ab36b37bee28cd03",
        "commit_title": "fs,userns: Change inode_capable to capable_wrt_inode_uidgid",
        "commit_text": " The kernel has no concept of capabilities with respect to inodes; inodes exist independently of namespaces.  For example, inode_capable(inode, CAP_LINUX_IMMUTABLE) would be nonsense.  This patch changes inode_capable to check for uid and gid mappings and renames it to capable_wrt_inode_uidgid, which should make it more obvious what it does.  Fixes CVE-2014-4014.  Cc: Theodore Ts'o <tytso@mit.edu> Cc: Serge Hallyn <serge.hallyn@ubuntu.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Dave Chinner <david@fromorbit.com> Cc: stable@vger.kernel.org",
        "func_before": "STATIC int\nxfs_ioctl_setattr(\n\txfs_inode_t\t\t*ip,\n\tstruct fsxattr\t\t*fa,\n\tint\t\t\tmask)\n{\n\tstruct xfs_mount\t*mp = ip->i_mount;\n\tstruct xfs_trans\t*tp;\n\tunsigned int\t\tlock_flags = 0;\n\tstruct xfs_dquot\t*udqp = NULL;\n\tstruct xfs_dquot\t*pdqp = NULL;\n\tstruct xfs_dquot\t*olddquot = NULL;\n\tint\t\t\tcode;\n\n\ttrace_xfs_ioctl_setattr(ip);\n\n\tif (mp->m_flags & XFS_MOUNT_RDONLY)\n\t\treturn XFS_ERROR(EROFS);\n\tif (XFS_FORCED_SHUTDOWN(mp))\n\t\treturn XFS_ERROR(EIO);\n\n\t/*\n\t * Disallow 32bit project ids when projid32bit feature is not enabled.\n\t */\n\tif ((mask & FSX_PROJID) && (fa->fsx_projid > (__uint16_t)-1) &&\n\t\t\t!xfs_sb_version_hasprojid32bit(&ip->i_mount->m_sb))\n\t\treturn XFS_ERROR(EINVAL);\n\n\t/*\n\t * If disk quotas is on, we make sure that the dquots do exist on disk,\n\t * before we start any other transactions. Trying to do this later\n\t * is messy. We don't care to take a readlock to look at the ids\n\t * in inode here, because we can't hold it across the trans_reserve.\n\t * If the IDs do change before we take the ilock, we're covered\n\t * because the i_*dquot fields will get updated anyway.\n\t */\n\tif (XFS_IS_QUOTA_ON(mp) && (mask & FSX_PROJID)) {\n\t\tcode = xfs_qm_vop_dqalloc(ip, ip->i_d.di_uid,\n\t\t\t\t\t ip->i_d.di_gid, fa->fsx_projid,\n\t\t\t\t\t XFS_QMOPT_PQUOTA, &udqp, NULL, &pdqp);\n\t\tif (code)\n\t\t\treturn code;\n\t}\n\n\t/*\n\t * For the other attributes, we acquire the inode lock and\n\t * first do an error checking pass.\n\t */\n\ttp = xfs_trans_alloc(mp, XFS_TRANS_SETATTR_NOT_SIZE);\n\tcode = xfs_trans_reserve(tp, &M_RES(mp)->tr_ichange, 0, 0);\n\tif (code)\n\t\tgoto error_return;\n\n\tlock_flags = XFS_ILOCK_EXCL;\n\txfs_ilock(ip, lock_flags);\n\n\t/*\n\t * CAP_FOWNER overrides the following restrictions:\n\t *\n\t * The user ID of the calling process must be equal\n\t * to the file owner ID, except in cases where the\n\t * CAP_FSETID capability is applicable.\n\t */\n\tif (!inode_owner_or_capable(VFS_I(ip))) {\n\t\tcode = XFS_ERROR(EPERM);\n\t\tgoto error_return;\n\t}\n\n\t/*\n\t * Do a quota reservation only if projid is actually going to change.\n\t * Only allow changing of projid from init_user_ns since it is a\n\t * non user namespace aware identifier.\n\t */\n\tif (mask & FSX_PROJID) {\n\t\tif (current_user_ns() != &init_user_ns) {\n\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\tgoto error_return;\n\t\t}\n\n\t\tif (XFS_IS_QUOTA_RUNNING(mp) &&\n\t\t    XFS_IS_PQUOTA_ON(mp) &&\n\t\t    xfs_get_projid(ip) != fa->fsx_projid) {\n\t\t\tASSERT(tp);\n\t\t\tcode = xfs_qm_vop_chown_reserve(tp, ip, udqp, NULL,\n\t\t\t\t\t\tpdqp, capable(CAP_FOWNER) ?\n\t\t\t\t\t\tXFS_QMOPT_FORCE_RES : 0);\n\t\t\tif (code)\t/* out of quota */\n\t\t\t\tgoto error_return;\n\t\t}\n\t}\n\n\tif (mask & FSX_EXTSIZE) {\n\t\t/*\n\t\t * Can't change extent size if any extents are allocated.\n\t\t */\n\t\tif (ip->i_d.di_nextents &&\n\t\t    ((ip->i_d.di_extsize << mp->m_sb.sb_blocklog) !=\n\t\t     fa->fsx_extsize)) {\n\t\t\tcode = XFS_ERROR(EINVAL);\t/* EFBIG? */\n\t\t\tgoto error_return;\n\t\t}\n\n\t\t/*\n\t\t * Extent size must be a multiple of the appropriate block\n\t\t * size, if set at all. It must also be smaller than the\n\t\t * maximum extent size supported by the filesystem.\n\t\t *\n\t\t * Also, for non-realtime files, limit the extent size hint to\n\t\t * half the size of the AGs in the filesystem so alignment\n\t\t * doesn't result in extents larger than an AG.\n\t\t */\n\t\tif (fa->fsx_extsize != 0) {\n\t\t\txfs_extlen_t    size;\n\t\t\txfs_fsblock_t   extsize_fsb;\n\n\t\t\textsize_fsb = XFS_B_TO_FSB(mp, fa->fsx_extsize);\n\t\t\tif (extsize_fsb > MAXEXTLEN) {\n\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\tgoto error_return;\n\t\t\t}\n\n\t\t\tif (XFS_IS_REALTIME_INODE(ip) ||\n\t\t\t    ((mask & FSX_XFLAGS) &&\n\t\t\t    (fa->fsx_xflags & XFS_XFLAG_REALTIME))) {\n\t\t\t\tsize = mp->m_sb.sb_rextsize <<\n\t\t\t\t       mp->m_sb.sb_blocklog;\n\t\t\t} else {\n\t\t\t\tsize = mp->m_sb.sb_blocksize;\n\t\t\t\tif (extsize_fsb > mp->m_sb.sb_agblocks / 2) {\n\t\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (fa->fsx_extsize % size) {\n\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\tgoto error_return;\n\t\t\t}\n\t\t}\n\t}\n\n\n\tif (mask & FSX_XFLAGS) {\n\t\t/*\n\t\t * Can't change realtime flag if any extents are allocated.\n\t\t */\n\t\tif ((ip->i_d.di_nextents || ip->i_delayed_blks) &&\n\t\t    (XFS_IS_REALTIME_INODE(ip)) !=\n\t\t    (fa->fsx_xflags & XFS_XFLAG_REALTIME)) {\n\t\t\tcode = XFS_ERROR(EINVAL);\t/* EFBIG? */\n\t\t\tgoto error_return;\n\t\t}\n\n\t\t/*\n\t\t * If realtime flag is set then must have realtime data.\n\t\t */\n\t\tif ((fa->fsx_xflags & XFS_XFLAG_REALTIME)) {\n\t\t\tif ((mp->m_sb.sb_rblocks == 0) ||\n\t\t\t    (mp->m_sb.sb_rextsize == 0) ||\n\t\t\t    (ip->i_d.di_extsize % mp->m_sb.sb_rextsize)) {\n\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\tgoto error_return;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Can't modify an immutable/append-only file unless\n\t\t * we have appropriate permission.\n\t\t */\n\t\tif ((ip->i_d.di_flags &\n\t\t\t\t(XFS_DIFLAG_IMMUTABLE|XFS_DIFLAG_APPEND) ||\n\t\t     (fa->fsx_xflags &\n\t\t\t\t(XFS_XFLAG_IMMUTABLE | XFS_XFLAG_APPEND))) &&\n\t\t    !capable(CAP_LINUX_IMMUTABLE)) {\n\t\t\tcode = XFS_ERROR(EPERM);\n\t\t\tgoto error_return;\n\t\t}\n\t}\n\n\txfs_trans_ijoin(tp, ip, 0);\n\n\t/*\n\t * Change file ownership.  Must be the owner or privileged.\n\t */\n\tif (mask & FSX_PROJID) {\n\t\t/*\n\t\t * CAP_FSETID overrides the following restrictions:\n\t\t *\n\t\t * The set-user-ID and set-group-ID bits of a file will be\n\t\t * cleared upon successful return from chown()\n\t\t */\n\t\tif ((ip->i_d.di_mode & (S_ISUID|S_ISGID)) &&\n\t\t    !inode_capable(VFS_I(ip), CAP_FSETID))\n\t\t\tip->i_d.di_mode &= ~(S_ISUID|S_ISGID);\n\n\t\t/*\n\t\t * Change the ownerships and register quota modifications\n\t\t * in the transaction.\n\t\t */\n\t\tif (xfs_get_projid(ip) != fa->fsx_projid) {\n\t\t\tif (XFS_IS_QUOTA_RUNNING(mp) && XFS_IS_PQUOTA_ON(mp)) {\n\t\t\t\tolddquot = xfs_qm_vop_chown(tp, ip,\n\t\t\t\t\t\t\t&ip->i_pdquot, pdqp);\n\t\t\t}\n\t\t\txfs_set_projid(ip, fa->fsx_projid);\n\n\t\t\t/*\n\t\t\t * We may have to rev the inode as well as\n\t\t\t * the superblock version number since projids didn't\n\t\t\t * exist before DINODE_VERSION_2 and SB_VERSION_NLINK.\n\t\t\t */\n\t\t\tif (ip->i_d.di_version == 1)\n\t\t\t\txfs_bump_ino_vers2(tp, ip);\n\t\t}\n\n\t}\n\n\tif (mask & FSX_EXTSIZE)\n\t\tip->i_d.di_extsize = fa->fsx_extsize >> mp->m_sb.sb_blocklog;\n\tif (mask & FSX_XFLAGS) {\n\t\txfs_set_diflags(ip, fa->fsx_xflags);\n\t\txfs_diflags_to_linux(ip);\n\t}\n\n\txfs_trans_ichgtime(tp, ip, XFS_ICHGTIME_CHG);\n\txfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);\n\n\tXFS_STATS_INC(xs_ig_attrchg);\n\n\t/*\n\t * If this is a synchronous mount, make sure that the\n\t * transaction goes to disk before returning to the user.\n\t * This is slightly sub-optimal in that truncates require\n\t * two sync transactions instead of one for wsync filesystems.\n\t * One for the truncate and one for the timestamps since we\n\t * don't want to change the timestamps unless we're sure the\n\t * truncate worked.  Truncates are less than 1% of the laddis\n\t * mix so this probably isn't worth the trouble to optimize.\n\t */\n\tif (mp->m_flags & XFS_MOUNT_WSYNC)\n\t\txfs_trans_set_sync(tp);\n\tcode = xfs_trans_commit(tp, 0);\n\txfs_iunlock(ip, lock_flags);\n\n\t/*\n\t * Release any dquot(s) the inode had kept before chown.\n\t */\n\txfs_qm_dqrele(olddquot);\n\txfs_qm_dqrele(udqp);\n\txfs_qm_dqrele(pdqp);\n\n\treturn code;\n\n error_return:\n\txfs_qm_dqrele(udqp);\n\txfs_qm_dqrele(pdqp);\n\txfs_trans_cancel(tp, 0);\n\tif (lock_flags)\n\t\txfs_iunlock(ip, lock_flags);\n\treturn code;\n}",
        "func": "STATIC int\nxfs_ioctl_setattr(\n\txfs_inode_t\t\t*ip,\n\tstruct fsxattr\t\t*fa,\n\tint\t\t\tmask)\n{\n\tstruct xfs_mount\t*mp = ip->i_mount;\n\tstruct xfs_trans\t*tp;\n\tunsigned int\t\tlock_flags = 0;\n\tstruct xfs_dquot\t*udqp = NULL;\n\tstruct xfs_dquot\t*pdqp = NULL;\n\tstruct xfs_dquot\t*olddquot = NULL;\n\tint\t\t\tcode;\n\n\ttrace_xfs_ioctl_setattr(ip);\n\n\tif (mp->m_flags & XFS_MOUNT_RDONLY)\n\t\treturn XFS_ERROR(EROFS);\n\tif (XFS_FORCED_SHUTDOWN(mp))\n\t\treturn XFS_ERROR(EIO);\n\n\t/*\n\t * Disallow 32bit project ids when projid32bit feature is not enabled.\n\t */\n\tif ((mask & FSX_PROJID) && (fa->fsx_projid > (__uint16_t)-1) &&\n\t\t\t!xfs_sb_version_hasprojid32bit(&ip->i_mount->m_sb))\n\t\treturn XFS_ERROR(EINVAL);\n\n\t/*\n\t * If disk quotas is on, we make sure that the dquots do exist on disk,\n\t * before we start any other transactions. Trying to do this later\n\t * is messy. We don't care to take a readlock to look at the ids\n\t * in inode here, because we can't hold it across the trans_reserve.\n\t * If the IDs do change before we take the ilock, we're covered\n\t * because the i_*dquot fields will get updated anyway.\n\t */\n\tif (XFS_IS_QUOTA_ON(mp) && (mask & FSX_PROJID)) {\n\t\tcode = xfs_qm_vop_dqalloc(ip, ip->i_d.di_uid,\n\t\t\t\t\t ip->i_d.di_gid, fa->fsx_projid,\n\t\t\t\t\t XFS_QMOPT_PQUOTA, &udqp, NULL, &pdqp);\n\t\tif (code)\n\t\t\treturn code;\n\t}\n\n\t/*\n\t * For the other attributes, we acquire the inode lock and\n\t * first do an error checking pass.\n\t */\n\ttp = xfs_trans_alloc(mp, XFS_TRANS_SETATTR_NOT_SIZE);\n\tcode = xfs_trans_reserve(tp, &M_RES(mp)->tr_ichange, 0, 0);\n\tif (code)\n\t\tgoto error_return;\n\n\tlock_flags = XFS_ILOCK_EXCL;\n\txfs_ilock(ip, lock_flags);\n\n\t/*\n\t * CAP_FOWNER overrides the following restrictions:\n\t *\n\t * The user ID of the calling process must be equal\n\t * to the file owner ID, except in cases where the\n\t * CAP_FSETID capability is applicable.\n\t */\n\tif (!inode_owner_or_capable(VFS_I(ip))) {\n\t\tcode = XFS_ERROR(EPERM);\n\t\tgoto error_return;\n\t}\n\n\t/*\n\t * Do a quota reservation only if projid is actually going to change.\n\t * Only allow changing of projid from init_user_ns since it is a\n\t * non user namespace aware identifier.\n\t */\n\tif (mask & FSX_PROJID) {\n\t\tif (current_user_ns() != &init_user_ns) {\n\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\tgoto error_return;\n\t\t}\n\n\t\tif (XFS_IS_QUOTA_RUNNING(mp) &&\n\t\t    XFS_IS_PQUOTA_ON(mp) &&\n\t\t    xfs_get_projid(ip) != fa->fsx_projid) {\n\t\t\tASSERT(tp);\n\t\t\tcode = xfs_qm_vop_chown_reserve(tp, ip, udqp, NULL,\n\t\t\t\t\t\tpdqp, capable(CAP_FOWNER) ?\n\t\t\t\t\t\tXFS_QMOPT_FORCE_RES : 0);\n\t\t\tif (code)\t/* out of quota */\n\t\t\t\tgoto error_return;\n\t\t}\n\t}\n\n\tif (mask & FSX_EXTSIZE) {\n\t\t/*\n\t\t * Can't change extent size if any extents are allocated.\n\t\t */\n\t\tif (ip->i_d.di_nextents &&\n\t\t    ((ip->i_d.di_extsize << mp->m_sb.sb_blocklog) !=\n\t\t     fa->fsx_extsize)) {\n\t\t\tcode = XFS_ERROR(EINVAL);\t/* EFBIG? */\n\t\t\tgoto error_return;\n\t\t}\n\n\t\t/*\n\t\t * Extent size must be a multiple of the appropriate block\n\t\t * size, if set at all. It must also be smaller than the\n\t\t * maximum extent size supported by the filesystem.\n\t\t *\n\t\t * Also, for non-realtime files, limit the extent size hint to\n\t\t * half the size of the AGs in the filesystem so alignment\n\t\t * doesn't result in extents larger than an AG.\n\t\t */\n\t\tif (fa->fsx_extsize != 0) {\n\t\t\txfs_extlen_t    size;\n\t\t\txfs_fsblock_t   extsize_fsb;\n\n\t\t\textsize_fsb = XFS_B_TO_FSB(mp, fa->fsx_extsize);\n\t\t\tif (extsize_fsb > MAXEXTLEN) {\n\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\tgoto error_return;\n\t\t\t}\n\n\t\t\tif (XFS_IS_REALTIME_INODE(ip) ||\n\t\t\t    ((mask & FSX_XFLAGS) &&\n\t\t\t    (fa->fsx_xflags & XFS_XFLAG_REALTIME))) {\n\t\t\t\tsize = mp->m_sb.sb_rextsize <<\n\t\t\t\t       mp->m_sb.sb_blocklog;\n\t\t\t} else {\n\t\t\t\tsize = mp->m_sb.sb_blocksize;\n\t\t\t\tif (extsize_fsb > mp->m_sb.sb_agblocks / 2) {\n\t\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\t\tgoto error_return;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (fa->fsx_extsize % size) {\n\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\tgoto error_return;\n\t\t\t}\n\t\t}\n\t}\n\n\n\tif (mask & FSX_XFLAGS) {\n\t\t/*\n\t\t * Can't change realtime flag if any extents are allocated.\n\t\t */\n\t\tif ((ip->i_d.di_nextents || ip->i_delayed_blks) &&\n\t\t    (XFS_IS_REALTIME_INODE(ip)) !=\n\t\t    (fa->fsx_xflags & XFS_XFLAG_REALTIME)) {\n\t\t\tcode = XFS_ERROR(EINVAL);\t/* EFBIG? */\n\t\t\tgoto error_return;\n\t\t}\n\n\t\t/*\n\t\t * If realtime flag is set then must have realtime data.\n\t\t */\n\t\tif ((fa->fsx_xflags & XFS_XFLAG_REALTIME)) {\n\t\t\tif ((mp->m_sb.sb_rblocks == 0) ||\n\t\t\t    (mp->m_sb.sb_rextsize == 0) ||\n\t\t\t    (ip->i_d.di_extsize % mp->m_sb.sb_rextsize)) {\n\t\t\t\tcode = XFS_ERROR(EINVAL);\n\t\t\t\tgoto error_return;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Can't modify an immutable/append-only file unless\n\t\t * we have appropriate permission.\n\t\t */\n\t\tif ((ip->i_d.di_flags &\n\t\t\t\t(XFS_DIFLAG_IMMUTABLE|XFS_DIFLAG_APPEND) ||\n\t\t     (fa->fsx_xflags &\n\t\t\t\t(XFS_XFLAG_IMMUTABLE | XFS_XFLAG_APPEND))) &&\n\t\t    !capable(CAP_LINUX_IMMUTABLE)) {\n\t\t\tcode = XFS_ERROR(EPERM);\n\t\t\tgoto error_return;\n\t\t}\n\t}\n\n\txfs_trans_ijoin(tp, ip, 0);\n\n\t/*\n\t * Change file ownership.  Must be the owner or privileged.\n\t */\n\tif (mask & FSX_PROJID) {\n\t\t/*\n\t\t * CAP_FSETID overrides the following restrictions:\n\t\t *\n\t\t * The set-user-ID and set-group-ID bits of a file will be\n\t\t * cleared upon successful return from chown()\n\t\t */\n\t\tif ((ip->i_d.di_mode & (S_ISUID|S_ISGID)) &&\n\t\t    !capable_wrt_inode_uidgid(VFS_I(ip), CAP_FSETID))\n\t\t\tip->i_d.di_mode &= ~(S_ISUID|S_ISGID);\n\n\t\t/*\n\t\t * Change the ownerships and register quota modifications\n\t\t * in the transaction.\n\t\t */\n\t\tif (xfs_get_projid(ip) != fa->fsx_projid) {\n\t\t\tif (XFS_IS_QUOTA_RUNNING(mp) && XFS_IS_PQUOTA_ON(mp)) {\n\t\t\t\tolddquot = xfs_qm_vop_chown(tp, ip,\n\t\t\t\t\t\t\t&ip->i_pdquot, pdqp);\n\t\t\t}\n\t\t\txfs_set_projid(ip, fa->fsx_projid);\n\n\t\t\t/*\n\t\t\t * We may have to rev the inode as well as\n\t\t\t * the superblock version number since projids didn't\n\t\t\t * exist before DINODE_VERSION_2 and SB_VERSION_NLINK.\n\t\t\t */\n\t\t\tif (ip->i_d.di_version == 1)\n\t\t\t\txfs_bump_ino_vers2(tp, ip);\n\t\t}\n\n\t}\n\n\tif (mask & FSX_EXTSIZE)\n\t\tip->i_d.di_extsize = fa->fsx_extsize >> mp->m_sb.sb_blocklog;\n\tif (mask & FSX_XFLAGS) {\n\t\txfs_set_diflags(ip, fa->fsx_xflags);\n\t\txfs_diflags_to_linux(ip);\n\t}\n\n\txfs_trans_ichgtime(tp, ip, XFS_ICHGTIME_CHG);\n\txfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);\n\n\tXFS_STATS_INC(xs_ig_attrchg);\n\n\t/*\n\t * If this is a synchronous mount, make sure that the\n\t * transaction goes to disk before returning to the user.\n\t * This is slightly sub-optimal in that truncates require\n\t * two sync transactions instead of one for wsync filesystems.\n\t * One for the truncate and one for the timestamps since we\n\t * don't want to change the timestamps unless we're sure the\n\t * truncate worked.  Truncates are less than 1% of the laddis\n\t * mix so this probably isn't worth the trouble to optimize.\n\t */\n\tif (mp->m_flags & XFS_MOUNT_WSYNC)\n\t\txfs_trans_set_sync(tp);\n\tcode = xfs_trans_commit(tp, 0);\n\txfs_iunlock(ip, lock_flags);\n\n\t/*\n\t * Release any dquot(s) the inode had kept before chown.\n\t */\n\txfs_qm_dqrele(olddquot);\n\txfs_qm_dqrele(udqp);\n\txfs_qm_dqrele(pdqp);\n\n\treturn code;\n\n error_return:\n\txfs_qm_dqrele(udqp);\n\txfs_qm_dqrele(pdqp);\n\txfs_trans_cancel(tp, 0);\n\tif (lock_flags)\n\t\txfs_iunlock(ip, lock_flags);\n\treturn code;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -190,7 +190,7 @@\n \t\t * cleared upon successful return from chown()\n \t\t */\n \t\tif ((ip->i_d.di_mode & (S_ISUID|S_ISGID)) &&\n-\t\t    !inode_capable(VFS_I(ip), CAP_FSETID))\n+\t\t    !capable_wrt_inode_uidgid(VFS_I(ip), CAP_FSETID))\n \t\t\tip->i_d.di_mode &= ~(S_ISUID|S_ISGID);\n \n \t\t/*",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t    !inode_capable(VFS_I(ip), CAP_FSETID))"
            ],
            "added_lines": [
                "\t\t    !capable_wrt_inode_uidgid(VFS_I(ip), CAP_FSETID))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4014",
        "func_name": "torvalds/linux/inode_owner_or_capable",
        "description": "The capabilities implementation in the Linux kernel before 3.14.8 does not properly consider that namespaces are inapplicable to inodes, which allows local users to bypass intended chmod restrictions by first creating a user namespace, as demonstrated by setting the setgid bit on a file with group ownership of root.",
        "git_url": "https://github.com/torvalds/linux/commit/23adbe12ef7d3d4195e80800ab36b37bee28cd03",
        "commit_title": "fs,userns: Change inode_capable to capable_wrt_inode_uidgid",
        "commit_text": " The kernel has no concept of capabilities with respect to inodes; inodes exist independently of namespaces.  For example, inode_capable(inode, CAP_LINUX_IMMUTABLE) would be nonsense.  This patch changes inode_capable to check for uid and gid mappings and renames it to capable_wrt_inode_uidgid, which should make it more obvious what it does.  Fixes CVE-2014-4014.  Cc: Theodore Ts'o <tytso@mit.edu> Cc: Serge Hallyn <serge.hallyn@ubuntu.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Dave Chinner <david@fromorbit.com> Cc: stable@vger.kernel.org",
        "func_before": "bool inode_owner_or_capable(const struct inode *inode)\n{\n\tif (uid_eq(current_fsuid(), inode->i_uid))\n\t\treturn true;\n\tif (inode_capable(inode, CAP_FOWNER))\n\t\treturn true;\n\treturn false;\n}",
        "func": "bool inode_owner_or_capable(const struct inode *inode)\n{\n\tstruct user_namespace *ns;\n\n\tif (uid_eq(current_fsuid(), inode->i_uid))\n\t\treturn true;\n\n\tns = current_user_ns();\n\tif (ns_capable(ns, CAP_FOWNER) && kuid_has_mapping(ns, inode->i_uid))\n\t\treturn true;\n\treturn false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,12 @@\n bool inode_owner_or_capable(const struct inode *inode)\n {\n+\tstruct user_namespace *ns;\n+\n \tif (uid_eq(current_fsuid(), inode->i_uid))\n \t\treturn true;\n-\tif (inode_capable(inode, CAP_FOWNER))\n+\n+\tns = current_user_ns();\n+\tif (ns_capable(ns, CAP_FOWNER) && kuid_has_mapping(ns, inode->i_uid))\n \t\treturn true;\n \treturn false;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (inode_capable(inode, CAP_FOWNER))"
            ],
            "added_lines": [
                "\tstruct user_namespace *ns;",
                "",
                "",
                "\tns = current_user_ns();",
                "\tif (ns_capable(ns, CAP_FOWNER) && kuid_has_mapping(ns, inode->i_uid))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4014",
        "func_name": "torvalds/linux/setattr_copy",
        "description": "The capabilities implementation in the Linux kernel before 3.14.8 does not properly consider that namespaces are inapplicable to inodes, which allows local users to bypass intended chmod restrictions by first creating a user namespace, as demonstrated by setting the setgid bit on a file with group ownership of root.",
        "git_url": "https://github.com/torvalds/linux/commit/23adbe12ef7d3d4195e80800ab36b37bee28cd03",
        "commit_title": "fs,userns: Change inode_capable to capable_wrt_inode_uidgid",
        "commit_text": " The kernel has no concept of capabilities with respect to inodes; inodes exist independently of namespaces.  For example, inode_capable(inode, CAP_LINUX_IMMUTABLE) would be nonsense.  This patch changes inode_capable to check for uid and gid mappings and renames it to capable_wrt_inode_uidgid, which should make it more obvious what it does.  Fixes CVE-2014-4014.  Cc: Theodore Ts'o <tytso@mit.edu> Cc: Serge Hallyn <serge.hallyn@ubuntu.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Dave Chinner <david@fromorbit.com> Cc: stable@vger.kernel.org",
        "func_before": "void setattr_copy(struct inode *inode, const struct iattr *attr)\n{\n\tunsigned int ia_valid = attr->ia_valid;\n\n\tif (ia_valid & ATTR_UID)\n\t\tinode->i_uid = attr->ia_uid;\n\tif (ia_valid & ATTR_GID)\n\t\tinode->i_gid = attr->ia_gid;\n\tif (ia_valid & ATTR_ATIME)\n\t\tinode->i_atime = timespec_trunc(attr->ia_atime,\n\t\t\t\t\t\tinode->i_sb->s_time_gran);\n\tif (ia_valid & ATTR_MTIME)\n\t\tinode->i_mtime = timespec_trunc(attr->ia_mtime,\n\t\t\t\t\t\tinode->i_sb->s_time_gran);\n\tif (ia_valid & ATTR_CTIME)\n\t\tinode->i_ctime = timespec_trunc(attr->ia_ctime,\n\t\t\t\t\t\tinode->i_sb->s_time_gran);\n\tif (ia_valid & ATTR_MODE) {\n\t\tumode_t mode = attr->ia_mode;\n\n\t\tif (!in_group_p(inode->i_gid) &&\n\t\t    !inode_capable(inode, CAP_FSETID))\n\t\t\tmode &= ~S_ISGID;\n\t\tinode->i_mode = mode;\n\t}\n}",
        "func": "void setattr_copy(struct inode *inode, const struct iattr *attr)\n{\n\tunsigned int ia_valid = attr->ia_valid;\n\n\tif (ia_valid & ATTR_UID)\n\t\tinode->i_uid = attr->ia_uid;\n\tif (ia_valid & ATTR_GID)\n\t\tinode->i_gid = attr->ia_gid;\n\tif (ia_valid & ATTR_ATIME)\n\t\tinode->i_atime = timespec_trunc(attr->ia_atime,\n\t\t\t\t\t\tinode->i_sb->s_time_gran);\n\tif (ia_valid & ATTR_MTIME)\n\t\tinode->i_mtime = timespec_trunc(attr->ia_mtime,\n\t\t\t\t\t\tinode->i_sb->s_time_gran);\n\tif (ia_valid & ATTR_CTIME)\n\t\tinode->i_ctime = timespec_trunc(attr->ia_ctime,\n\t\t\t\t\t\tinode->i_sb->s_time_gran);\n\tif (ia_valid & ATTR_MODE) {\n\t\tumode_t mode = attr->ia_mode;\n\n\t\tif (!in_group_p(inode->i_gid) &&\n\t\t    !capable_wrt_inode_uidgid(inode, CAP_FSETID))\n\t\t\tmode &= ~S_ISGID;\n\t\tinode->i_mode = mode;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,7 +19,7 @@\n \t\tumode_t mode = attr->ia_mode;\n \n \t\tif (!in_group_p(inode->i_gid) &&\n-\t\t    !inode_capable(inode, CAP_FSETID))\n+\t\t    !capable_wrt_inode_uidgid(inode, CAP_FSETID))\n \t\t\tmode &= ~S_ISGID;\n \t\tinode->i_mode = mode;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t    !inode_capable(inode, CAP_FSETID))"
            ],
            "added_lines": [
                "\t\t    !capable_wrt_inode_uidgid(inode, CAP_FSETID))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-4014",
        "func_name": "torvalds/linux/inode_change_ok",
        "description": "The capabilities implementation in the Linux kernel before 3.14.8 does not properly consider that namespaces are inapplicable to inodes, which allows local users to bypass intended chmod restrictions by first creating a user namespace, as demonstrated by setting the setgid bit on a file with group ownership of root.",
        "git_url": "https://github.com/torvalds/linux/commit/23adbe12ef7d3d4195e80800ab36b37bee28cd03",
        "commit_title": "fs,userns: Change inode_capable to capable_wrt_inode_uidgid",
        "commit_text": " The kernel has no concept of capabilities with respect to inodes; inodes exist independently of namespaces.  For example, inode_capable(inode, CAP_LINUX_IMMUTABLE) would be nonsense.  This patch changes inode_capable to check for uid and gid mappings and renames it to capable_wrt_inode_uidgid, which should make it more obvious what it does.  Fixes CVE-2014-4014.  Cc: Theodore Ts'o <tytso@mit.edu> Cc: Serge Hallyn <serge.hallyn@ubuntu.com> Cc: \"Eric W. Biederman\" <ebiederm@xmission.com> Cc: Dave Chinner <david@fromorbit.com> Cc: stable@vger.kernel.org",
        "func_before": "int inode_change_ok(const struct inode *inode, struct iattr *attr)\n{\n\tunsigned int ia_valid = attr->ia_valid;\n\n\t/*\n\t * First check size constraints.  These can't be overriden using\n\t * ATTR_FORCE.\n\t */\n\tif (ia_valid & ATTR_SIZE) {\n\t\tint error = inode_newsize_ok(inode, attr->ia_size);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\t/* If force is set do it anyway. */\n\tif (ia_valid & ATTR_FORCE)\n\t\treturn 0;\n\n\t/* Make sure a caller can chown. */\n\tif ((ia_valid & ATTR_UID) &&\n\t    (!uid_eq(current_fsuid(), inode->i_uid) ||\n\t     !uid_eq(attr->ia_uid, inode->i_uid)) &&\n\t    !inode_capable(inode, CAP_CHOWN))\n\t\treturn -EPERM;\n\n\t/* Make sure caller can chgrp. */\n\tif ((ia_valid & ATTR_GID) &&\n\t    (!uid_eq(current_fsuid(), inode->i_uid) ||\n\t    (!in_group_p(attr->ia_gid) && !gid_eq(attr->ia_gid, inode->i_gid))) &&\n\t    !inode_capable(inode, CAP_CHOWN))\n\t\treturn -EPERM;\n\n\t/* Make sure a caller can chmod. */\n\tif (ia_valid & ATTR_MODE) {\n\t\tif (!inode_owner_or_capable(inode))\n\t\t\treturn -EPERM;\n\t\t/* Also check the setgid bit! */\n\t\tif (!in_group_p((ia_valid & ATTR_GID) ? attr->ia_gid :\n\t\t\t\tinode->i_gid) &&\n\t\t    !inode_capable(inode, CAP_FSETID))\n\t\t\tattr->ia_mode &= ~S_ISGID;\n\t}\n\n\t/* Check for setting the inode time. */\n\tif (ia_valid & (ATTR_MTIME_SET | ATTR_ATIME_SET | ATTR_TIMES_SET)) {\n\t\tif (!inode_owner_or_capable(inode))\n\t\t\treturn -EPERM;\n\t}\n\n\treturn 0;\n}",
        "func": "int inode_change_ok(const struct inode *inode, struct iattr *attr)\n{\n\tunsigned int ia_valid = attr->ia_valid;\n\n\t/*\n\t * First check size constraints.  These can't be overriden using\n\t * ATTR_FORCE.\n\t */\n\tif (ia_valid & ATTR_SIZE) {\n\t\tint error = inode_newsize_ok(inode, attr->ia_size);\n\t\tif (error)\n\t\t\treturn error;\n\t}\n\n\t/* If force is set do it anyway. */\n\tif (ia_valid & ATTR_FORCE)\n\t\treturn 0;\n\n\t/* Make sure a caller can chown. */\n\tif ((ia_valid & ATTR_UID) &&\n\t    (!uid_eq(current_fsuid(), inode->i_uid) ||\n\t     !uid_eq(attr->ia_uid, inode->i_uid)) &&\n\t    !capable_wrt_inode_uidgid(inode, CAP_CHOWN))\n\t\treturn -EPERM;\n\n\t/* Make sure caller can chgrp. */\n\tif ((ia_valid & ATTR_GID) &&\n\t    (!uid_eq(current_fsuid(), inode->i_uid) ||\n\t    (!in_group_p(attr->ia_gid) && !gid_eq(attr->ia_gid, inode->i_gid))) &&\n\t    !capable_wrt_inode_uidgid(inode, CAP_CHOWN))\n\t\treturn -EPERM;\n\n\t/* Make sure a caller can chmod. */\n\tif (ia_valid & ATTR_MODE) {\n\t\tif (!inode_owner_or_capable(inode))\n\t\t\treturn -EPERM;\n\t\t/* Also check the setgid bit! */\n\t\tif (!in_group_p((ia_valid & ATTR_GID) ? attr->ia_gid :\n\t\t\t\tinode->i_gid) &&\n\t\t    !capable_wrt_inode_uidgid(inode, CAP_FSETID))\n\t\t\tattr->ia_mode &= ~S_ISGID;\n\t}\n\n\t/* Check for setting the inode time. */\n\tif (ia_valid & (ATTR_MTIME_SET | ATTR_ATIME_SET | ATTR_TIMES_SET)) {\n\t\tif (!inode_owner_or_capable(inode))\n\t\t\treturn -EPERM;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,14 +20,14 @@\n \tif ((ia_valid & ATTR_UID) &&\n \t    (!uid_eq(current_fsuid(), inode->i_uid) ||\n \t     !uid_eq(attr->ia_uid, inode->i_uid)) &&\n-\t    !inode_capable(inode, CAP_CHOWN))\n+\t    !capable_wrt_inode_uidgid(inode, CAP_CHOWN))\n \t\treturn -EPERM;\n \n \t/* Make sure caller can chgrp. */\n \tif ((ia_valid & ATTR_GID) &&\n \t    (!uid_eq(current_fsuid(), inode->i_uid) ||\n \t    (!in_group_p(attr->ia_gid) && !gid_eq(attr->ia_gid, inode->i_gid))) &&\n-\t    !inode_capable(inode, CAP_CHOWN))\n+\t    !capable_wrt_inode_uidgid(inode, CAP_CHOWN))\n \t\treturn -EPERM;\n \n \t/* Make sure a caller can chmod. */\n@@ -37,7 +37,7 @@\n \t\t/* Also check the setgid bit! */\n \t\tif (!in_group_p((ia_valid & ATTR_GID) ? attr->ia_gid :\n \t\t\t\tinode->i_gid) &&\n-\t\t    !inode_capable(inode, CAP_FSETID))\n+\t\t    !capable_wrt_inode_uidgid(inode, CAP_FSETID))\n \t\t\tattr->ia_mode &= ~S_ISGID;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t    !inode_capable(inode, CAP_CHOWN))",
                "\t    !inode_capable(inode, CAP_CHOWN))",
                "\t\t    !inode_capable(inode, CAP_FSETID))"
            ],
            "added_lines": [
                "\t    !capable_wrt_inode_uidgid(inode, CAP_CHOWN))",
                "\t    !capable_wrt_inode_uidgid(inode, CAP_CHOWN))",
                "\t\t    !capable_wrt_inode_uidgid(inode, CAP_FSETID))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3160",
        "func_name": "chromium/ResourceFetcher::canRequest",
        "description": "The ResourceFetcher::canRequest function in core/fetch/ResourceFetcher.cpp in Blink, as used in Google Chrome before 36.0.1985.125, does not properly restrict subresource requests associated with SVG files, which allows remote attackers to bypass the Same Origin Policy via a crafted file.",
        "git_url": "https://github.com/chromium/chromium/commit/ee281f7cac9df44fe241a37f188b28be8845ded0",
        "commit_title": "Enforce SVG image security rules",
        "commit_text": " SVG images have unique security rules that prevent them from loading any external resources. This patch enforces these rules in ResourceFetcher::canRequest for all non-data-uri resources. This locks down our SVG resource handling and fixes two security bugs.  In the case of SVG images that reference other images, we had a bug where a cached subresource would be used directly from the cache. This has been fixed because the canRequest check occurs before we use cached resources.  In the case of SVG images that use CSS imports, we had a bug where imports were blindly requested. This has been fixed by stopping all non-data-uri requests in SVG images.  With this patch we now match Gecko's behavior on both testcases.   ",
        "func_before": "bool ResourceFetcher::canRequest(Resource::Type type, const KURL& url, const ResourceLoaderOptions& options, bool forPreload, FetchRequest::OriginRestriction originRestriction) const\n{\n    SecurityOrigin* securityOrigin = options.securityOrigin.get();\n    if (!securityOrigin && document())\n        securityOrigin = document()->securityOrigin();\n\n    if (securityOrigin && !securityOrigin->canDisplay(url)) {\n        if (!forPreload)\n            context().reportLocalLoadFailed(url);\n        WTF_LOG(ResourceLoading, \"ResourceFetcher::requestResource URL was not allowed by SecurityOrigin::canDisplay\");\n        return 0;\n    }\n\n    // FIXME: Convert this to check the isolated world's Content Security Policy once webkit.org/b/104520 is solved.\n    bool shouldBypassMainWorldContentSecurityPolicy = (frame() && frame()->script().shouldBypassMainWorldContentSecurityPolicy()) || (options.contentSecurityPolicyOption == DoNotCheckContentSecurityPolicy);\n\n    // Some types of resources can be loaded only from the same origin. Other\n    // types of resources, like Images, Scripts, and CSS, can be loaded from\n    // any URL.\n    switch (type) {\n    case Resource::MainResource:\n    case Resource::Image:\n    case Resource::CSSStyleSheet:\n    case Resource::Script:\n    case Resource::Font:\n    case Resource::Raw:\n    case Resource::LinkPrefetch:\n    case Resource::LinkSubresource:\n    case Resource::TextTrack:\n    case Resource::ImportResource:\n    case Resource::Media:\n        // By default these types of resources can be loaded from any origin.\n        // FIXME: Are we sure about Resource::Font?\n        if (originRestriction == FetchRequest::RestrictToSameOrigin && !securityOrigin->canRequest(url)) {\n            printAccessDeniedMessage(url);\n            return false;\n        }\n        break;\n    case Resource::XSLStyleSheet:\n        ASSERT(RuntimeEnabledFeatures::xsltEnabled());\n    case Resource::SVGDocument:\n        if (!securityOrigin->canRequest(url)) {\n            printAccessDeniedMessage(url);\n            return false;\n        }\n        break;\n    }\n\n    // Don't send CSP messages for preloads, we might never actually display those items.\n    ContentSecurityPolicy::ReportingStatus cspReporting = forPreload ?\n        ContentSecurityPolicy::SuppressReport : ContentSecurityPolicy::SendReport;\n\n    switch (type) {\n    case Resource::XSLStyleSheet:\n        ASSERT(RuntimeEnabledFeatures::xsltEnabled());\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowScriptFromSource(url, cspReporting))\n            return false;\n        break;\n    case Resource::Script:\n    case Resource::ImportResource:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowScriptFromSource(url, cspReporting))\n            return false;\n\n        if (frame()) {\n            Settings* settings = frame()->settings();\n            if (!frame()->loader().client()->allowScriptFromSource(!settings || settings->scriptEnabled(), url)) {\n                frame()->loader().client()->didNotAllowScript();\n                return false;\n            }\n        }\n        break;\n    case Resource::CSSStyleSheet:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowStyleFromSource(url, cspReporting))\n            return false;\n        break;\n    case Resource::SVGDocument:\n    case Resource::Image:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowImageFromSource(url, cspReporting))\n            return false;\n        break;\n    case Resource::Font: {\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowFontFromSource(url, cspReporting))\n            return false;\n        break;\n    }\n    case Resource::MainResource:\n    case Resource::Raw:\n    case Resource::LinkPrefetch:\n    case Resource::LinkSubresource:\n        break;\n    case Resource::Media:\n    case Resource::TextTrack:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowMediaFromSource(url, cspReporting))\n            return false;\n        break;\n    }\n\n    // Last of all, check for insecure content. We do this last so that when\n    // folks block insecure content with a CSP policy, they don't get a warning.\n    // They'll still get a warning in the console about CSP blocking the load.\n\n    // FIXME: Should we consider forPreload here?\n    if (!checkInsecureContent(type, url, options.mixedContentBlockingTreatment))\n        return false;\n\n    return true;\n}",
        "func": "bool ResourceFetcher::canRequest(Resource::Type type, const KURL& url, const ResourceLoaderOptions& options, bool forPreload, FetchRequest::OriginRestriction originRestriction) const\n{\n    SecurityOrigin* securityOrigin = options.securityOrigin.get();\n    if (!securityOrigin && document())\n        securityOrigin = document()->securityOrigin();\n\n    if (securityOrigin && !securityOrigin->canDisplay(url)) {\n        if (!forPreload)\n            context().reportLocalLoadFailed(url);\n        WTF_LOG(ResourceLoading, \"ResourceFetcher::requestResource URL was not allowed by SecurityOrigin::canDisplay\");\n        return 0;\n    }\n\n    // FIXME: Convert this to check the isolated world's Content Security Policy once webkit.org/b/104520 is solved.\n    bool shouldBypassMainWorldContentSecurityPolicy = (frame() && frame()->script().shouldBypassMainWorldContentSecurityPolicy()) || (options.contentSecurityPolicyOption == DoNotCheckContentSecurityPolicy);\n\n    // Some types of resources can be loaded only from the same origin. Other\n    // types of resources, like Images, Scripts, and CSS, can be loaded from\n    // any URL.\n    switch (type) {\n    case Resource::MainResource:\n    case Resource::Image:\n    case Resource::CSSStyleSheet:\n    case Resource::Script:\n    case Resource::Font:\n    case Resource::Raw:\n    case Resource::LinkPrefetch:\n    case Resource::LinkSubresource:\n    case Resource::TextTrack:\n    case Resource::ImportResource:\n    case Resource::Media:\n        // By default these types of resources can be loaded from any origin.\n        // FIXME: Are we sure about Resource::Font?\n        if (originRestriction == FetchRequest::RestrictToSameOrigin && !securityOrigin->canRequest(url)) {\n            printAccessDeniedMessage(url);\n            return false;\n        }\n        break;\n    case Resource::XSLStyleSheet:\n        ASSERT(RuntimeEnabledFeatures::xsltEnabled());\n    case Resource::SVGDocument:\n        if (!securityOrigin->canRequest(url)) {\n            printAccessDeniedMessage(url);\n            return false;\n        }\n        break;\n    }\n\n    // Don't send CSP messages for preloads, we might never actually display those items.\n    ContentSecurityPolicy::ReportingStatus cspReporting = forPreload ?\n        ContentSecurityPolicy::SuppressReport : ContentSecurityPolicy::SendReport;\n\n    switch (type) {\n    case Resource::XSLStyleSheet:\n        ASSERT(RuntimeEnabledFeatures::xsltEnabled());\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowScriptFromSource(url, cspReporting))\n            return false;\n        break;\n    case Resource::Script:\n    case Resource::ImportResource:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowScriptFromSource(url, cspReporting))\n            return false;\n\n        if (frame()) {\n            Settings* settings = frame()->settings();\n            if (!frame()->loader().client()->allowScriptFromSource(!settings || settings->scriptEnabled(), url)) {\n                frame()->loader().client()->didNotAllowScript();\n                return false;\n            }\n        }\n        break;\n    case Resource::CSSStyleSheet:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowStyleFromSource(url, cspReporting))\n            return false;\n        break;\n    case Resource::SVGDocument:\n    case Resource::Image:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowImageFromSource(url, cspReporting))\n            return false;\n        break;\n    case Resource::Font: {\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowFontFromSource(url, cspReporting))\n            return false;\n        break;\n    }\n    case Resource::MainResource:\n    case Resource::Raw:\n    case Resource::LinkPrefetch:\n    case Resource::LinkSubresource:\n        break;\n    case Resource::Media:\n    case Resource::TextTrack:\n        if (!shouldBypassMainWorldContentSecurityPolicy && !m_document->contentSecurityPolicy()->allowMediaFromSource(url, cspReporting))\n            return false;\n        break;\n    }\n\n    // SVG Images have unique security rules that prevent all subresource requests\n    // except for data urls.\n    if (type != Resource::MainResource) {\n        if (frame() && frame()->chromeClient().isSVGImageChromeClient() && !url.protocolIsData())\n            return false;\n    }\n\n    // Last of all, check for insecure content. We do this last so that when\n    // folks block insecure content with a CSP policy, they don't get a warning.\n    // They'll still get a warning in the console about CSP blocking the load.\n\n    // FIXME: Should we consider forPreload here?\n    if (!checkInsecureContent(type, url, options.mixedContentBlockingTreatment))\n        return false;\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -95,6 +95,13 @@\n         break;\n     }\n \n+    // SVG Images have unique security rules that prevent all subresource requests\n+    // except for data urls.\n+    if (type != Resource::MainResource) {\n+        if (frame() && frame()->chromeClient().isSVGImageChromeClient() && !url.protocolIsData())\n+            return false;\n+    }\n+\n     // Last of all, check for insecure content. We do this last so that when\n     // folks block insecure content with a CSP policy, they don't get a warning.\n     // They'll still get a warning in the console about CSP blocking the load.",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // SVG Images have unique security rules that prevent all subresource requests",
                "    // except for data urls.",
                "    if (type != Resource::MainResource) {",
                "        if (frame() && frame()->chromeClient().isSVGImageChromeClient() && !url.protocolIsData())",
                "            return false;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3161",
        "func_name": "chromium/WebMediaPlayerAndroid::load",
        "description": "The WebMediaPlayerAndroid::load function in content/renderer/media/android/webmediaplayer_android.cc in Google Chrome before 36.0.1985.122 on Android does not properly interact with redirects, which allows remote attackers to bypass the Same Origin Policy via a crafted web site that hosts a video stream.",
        "git_url": "https://github.com/chromium/chromium/commit/f689da10139d76dd3fb8a0e92d5732324cb2d90c",
        "commit_title": "Always mark cross-origin as true for regular media urls",
        "commit_text": " We cannot guarantee that urls will not be redirected when android mediaplayer requests video streams. Always treat media urls as cross-origin for now.   ",
        "func_before": "void WebMediaPlayerAndroid::load(LoadType load_type,\n                                 const blink::WebURL& url,\n                                 CORSMode cors_mode) {\n  switch (load_type) {\n    case LoadTypeURL:\n      player_type_ = MEDIA_PLAYER_TYPE_URL;\n      break;\n\n    case LoadTypeMediaSource:\n      player_type_ = MEDIA_PLAYER_TYPE_MEDIA_SOURCE;\n      break;\n\n    case LoadTypeMediaStream:\n      CHECK(false) << \"WebMediaPlayerAndroid doesn't support MediaStream on \"\n                      \"this platform\";\n      return;\n  }\n\n  has_media_metadata_ = false;\n  has_media_info_ = false;\n\n  int demuxer_client_id = 0;\n  if (player_type_ != MEDIA_PLAYER_TYPE_URL) {\n    has_media_info_ = true;\n\n    RendererDemuxerAndroid* demuxer =\n        RenderThreadImpl::current()->renderer_demuxer();\n    demuxer_client_id = demuxer->GetNextDemuxerClientID();\n\n    media_source_delegate_.reset(new MediaSourceDelegate(\n        demuxer, demuxer_client_id, media_loop_, media_log_));\n\n    if (player_type_ == MEDIA_PLAYER_TYPE_MEDIA_SOURCE) {\n      media::SetDecryptorReadyCB set_decryptor_ready_cb =\n          media::BindToCurrentLoop(\n              base::Bind(&WebMediaPlayerAndroid::SetDecryptorReadyCB,\n                         weak_factory_.GetWeakPtr()));\n\n      media_source_delegate_->InitializeMediaSource(\n          base::Bind(&WebMediaPlayerAndroid::OnMediaSourceOpened,\n                     weak_factory_.GetWeakPtr()),\n          base::Bind(&WebMediaPlayerAndroid::OnNeedKey,\n                     weak_factory_.GetWeakPtr()),\n          set_decryptor_ready_cb,\n          base::Bind(&WebMediaPlayerAndroid::UpdateNetworkState,\n                     weak_factory_.GetWeakPtr()),\n          base::Bind(&WebMediaPlayerAndroid::OnDurationChanged,\n                     weak_factory_.GetWeakPtr()));\n    }\n  } else {\n    info_loader_.reset(\n        new MediaInfoLoader(\n            url,\n            cors_mode,\n            base::Bind(&WebMediaPlayerAndroid::DidLoadMediaInfo,\n                       weak_factory_.GetWeakPtr())));\n    info_loader_->Start(frame_);\n  }\n\n  url_ = url;\n  GURL first_party_url = frame_->document().firstPartyForCookies();\n  manager_->Initialize(\n      player_type_, player_id_, url, first_party_url, demuxer_client_id);\n\n  if (manager_->ShouldEnterFullscreen(frame_))\n    manager_->EnterFullscreen(player_id_, frame_);\n\n  UpdateNetworkState(WebMediaPlayer::NetworkStateLoading);\n  UpdateReadyState(WebMediaPlayer::ReadyStateHaveNothing);\n}",
        "func": "void WebMediaPlayerAndroid::load(LoadType load_type,\n                                 const blink::WebURL& url,\n                                 CORSMode cors_mode) {\n  switch (load_type) {\n    case LoadTypeURL:\n      player_type_ = MEDIA_PLAYER_TYPE_URL;\n      break;\n\n    case LoadTypeMediaSource:\n      player_type_ = MEDIA_PLAYER_TYPE_MEDIA_SOURCE;\n      break;\n\n    case LoadTypeMediaStream:\n      CHECK(false) << \"WebMediaPlayerAndroid doesn't support MediaStream on \"\n                      \"this platform\";\n      return;\n  }\n\n  has_media_metadata_ = false;\n  has_media_info_ = false;\n\n  int demuxer_client_id = 0;\n  if (player_type_ != MEDIA_PLAYER_TYPE_URL) {\n    has_media_info_ = true;\n\n    RendererDemuxerAndroid* demuxer =\n        RenderThreadImpl::current()->renderer_demuxer();\n    demuxer_client_id = demuxer->GetNextDemuxerClientID();\n\n    media_source_delegate_.reset(new MediaSourceDelegate(\n        demuxer, demuxer_client_id, media_loop_, media_log_));\n\n    if (player_type_ == MEDIA_PLAYER_TYPE_MEDIA_SOURCE) {\n      media::SetDecryptorReadyCB set_decryptor_ready_cb =\n          media::BindToCurrentLoop(\n              base::Bind(&WebMediaPlayerAndroid::SetDecryptorReadyCB,\n                         weak_factory_.GetWeakPtr()));\n\n      media_source_delegate_->InitializeMediaSource(\n          base::Bind(&WebMediaPlayerAndroid::OnMediaSourceOpened,\n                     weak_factory_.GetWeakPtr()),\n          base::Bind(&WebMediaPlayerAndroid::OnNeedKey,\n                     weak_factory_.GetWeakPtr()),\n          set_decryptor_ready_cb,\n          base::Bind(&WebMediaPlayerAndroid::UpdateNetworkState,\n                     weak_factory_.GetWeakPtr()),\n          base::Bind(&WebMediaPlayerAndroid::OnDurationChanged,\n                     weak_factory_.GetWeakPtr()));\n    }\n  } else {\n    info_loader_.reset(\n        new MediaInfoLoader(\n            url,\n            cors_mode,\n            base::Bind(&WebMediaPlayerAndroid::DidLoadMediaInfo,\n                       weak_factory_.GetWeakPtr())));\n    // TODO(qinmin): The url might be redirected when android media player\n    // requests the stream. As a result, we cannot guarantee there is only\n    // a single origin. Remove the following line when b/12573548 is fixed.\n    // Check http://crbug.com/334204.\n    info_loader_->set_single_origin(false);\n    info_loader_->Start(frame_);\n  }\n\n  url_ = url;\n  GURL first_party_url = frame_->document().firstPartyForCookies();\n  manager_->Initialize(\n      player_type_, player_id_, url, first_party_url, demuxer_client_id);\n\n  if (manager_->ShouldEnterFullscreen(frame_))\n    manager_->EnterFullscreen(player_id_, frame_);\n\n  UpdateNetworkState(WebMediaPlayer::NetworkStateLoading);\n  UpdateReadyState(WebMediaPlayer::ReadyStateHaveNothing);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,6 +54,11 @@\n             cors_mode,\n             base::Bind(&WebMediaPlayerAndroid::DidLoadMediaInfo,\n                        weak_factory_.GetWeakPtr())));\n+    // TODO(qinmin): The url might be redirected when android media player\n+    // requests the stream. As a result, we cannot guarantee there is only\n+    // a single origin. Remove the following line when b/12573548 is fixed.\n+    // Check http://crbug.com/334204.\n+    info_loader_->set_single_origin(false);\n     info_loader_->Start(frame_);\n   }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // TODO(qinmin): The url might be redirected when android media player",
                "    // requests the stream. As a result, we cannot guarantee there is only",
                "    // a single origin. Remove the following line when b/12573548 is fixed.",
                "    // Check http://crbug.com/334204.",
                "    info_loader_->set_single_origin(false);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2521",
        "func_name": "wireshark/WinMain",
        "description": "Untrusted search path vulnerability in the WiresharkApplication class in ui/qt/wireshark_application.cpp in Wireshark 1.12.x before 1.12.10 and 2.0.x before 2.0.2 on Windows allows local users to gain privileges via a Trojan horse riched20.dll.dll file in the current working directory, related to use of QLibrary.",
        "git_url": "https://github.com/wireshark/wireshark/commit/4a79cf2e1ab056faaddd252aa56520435b318a56",
        "commit_title": "Switch from QLibrary to ws_load_library.",
        "commit_text": " From the comments in qlibrary_win.cpp:  // We make the following attempts at locating the library: [ ... ] // Windows // if (absolute) //     fileName //     fileName + \".dll\" // else //     fileName + \".dll\" //     fileName  We were passing \"riched20.dll\" to QLibrary, which meant that it searched for \"riched20.dll.dll\" first.  Switch to ws_load_library, which we use elsewhere and which has much safer default behavior. ",
        "func_before": "int _stdcall\nWinMain (struct HINSTANCE__ *hInstance,\n         struct HINSTANCE__ *hPrevInstance,\n         char               *lpszCmdLine,\n         int                 nCmdShow)\n{\n    INITCOMMONCONTROLSEX comm_ctrl;\n\n    /*\n     * Initialize our DLL search path. MUST be called before LoadLibrary\n     * or g_module_open.\n     */\n    ws_init_dll_search_path();\n\n    /* Initialize our controls. Required for native Windows file dialogs. */\n    memset (&comm_ctrl, 0, sizeof(comm_ctrl));\n    comm_ctrl.dwSize = sizeof(comm_ctrl);\n    /* Includes the animate, header, hot key, list view, progress bar,\n     * status bar, tab, tooltip, toolbar, trackbar, tree view, and\n     * up-down controls\n     */\n    comm_ctrl.dwICC = ICC_WIN95_CLASSES;\n    InitCommonControlsEx(&comm_ctrl);\n\n    /* RichEd20.DLL is needed for filter entries. */\n    ws_load_library(\"riched20.dll\");\n\n    set_has_console(FALSE);\n    set_console_wait(FALSE);\n    return main (__argc, __argv);\n}",
        "func": "int _stdcall\nWinMain (struct HINSTANCE__ *hInstance,\n         struct HINSTANCE__ *hPrevInstance,\n         char               *lpszCmdLine,\n         int                 nCmdShow)\n{\n    INITCOMMONCONTROLSEX comm_ctrl;\n\n    /*\n     * Initialize our DLL search path. MUST be called before LoadLibrary\n     * or g_module_open.\n     */\n    ws_init_dll_search_path();\n\n    /* Initialize our controls. Required for native Windows file dialogs. */\n    memset (&comm_ctrl, 0, sizeof(comm_ctrl));\n    comm_ctrl.dwSize = sizeof(comm_ctrl);\n    /* Includes the animate, header, hot key, list view, progress bar,\n     * status bar, tab, tooltip, toolbar, trackbar, tree view, and\n     * up-down controls\n     */\n    comm_ctrl.dwICC = ICC_WIN95_CLASSES;\n    InitCommonControlsEx(&comm_ctrl);\n\n    /* RichEd20.DLL is needed for native file dialog filter entries. */\n    ws_load_library(\"riched20.dll\");\n\n    set_has_console(FALSE);\n    set_console_wait(FALSE);\n    return main (__argc, __argv);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,7 +22,7 @@\n     comm_ctrl.dwICC = ICC_WIN95_CLASSES;\n     InitCommonControlsEx(&comm_ctrl);\n \n-    /* RichEd20.DLL is needed for filter entries. */\n+    /* RichEd20.DLL is needed for native file dialog filter entries. */\n     ws_load_library(\"riched20.dll\");\n \n     set_has_console(FALSE);",
        "diff_line_info": {
            "deleted_lines": [
                "    /* RichEd20.DLL is needed for filter entries. */"
            ],
            "added_lines": [
                "    /* RichEd20.DLL is needed for native file dialog filter entries. */"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2521",
        "func_name": "wireshark/WiresharkApplication::WiresharkApplication",
        "description": "Untrusted search path vulnerability in the WiresharkApplication class in ui/qt/wireshark_application.cpp in Wireshark 1.12.x before 1.12.10 and 2.0.x before 2.0.2 on Windows allows local users to gain privileges via a Trojan horse riched20.dll.dll file in the current working directory, related to use of QLibrary.",
        "git_url": "https://github.com/wireshark/wireshark/commit/4a79cf2e1ab056faaddd252aa56520435b318a56",
        "commit_title": "Switch from QLibrary to ws_load_library.",
        "commit_text": " From the comments in qlibrary_win.cpp:  // We make the following attempts at locating the library: [ ... ] // Windows // if (absolute) //     fileName //     fileName + \".dll\" // else //     fileName + \".dll\" //     fileName  We were passing \"riched20.dll\" to QLibrary, which meant that it searched for \"riched20.dll.dll\" first.  Switch to ws_load_library, which we use elsewhere and which has much safer default behavior. ",
        "func_before": "WiresharkApplication::WiresharkApplication(int &argc,  char **argv) :\n    QApplication(argc, argv),\n    initialized_(false),\n    is_reloading_lua_(false),\n    if_notifier_(NULL),\n    active_captures_(0)\n{\n    wsApp = this;\n    setApplicationName(\"Wireshark\");\n\n    Q_INIT_RESOURCE(about);\n    Q_INIT_RESOURCE(i18n);\n    Q_INIT_RESOURCE(layout);\n    Q_INIT_RESOURCE(toolbar);\n    Q_INIT_RESOURCE(wsicon);\n    Q_INIT_RESOURCE(languages);\n\n#ifdef Q_OS_WIN\n    /* RichEd20.DLL is needed for native file dialog filter entries. */\n    if (QLibrary::isLibrary(\"riched20.dll\")) {\n        QLibrary riched20(\"riched20.dll\");\n        riched20.load();\n        if (!riched20.isLoaded()) {\n            qDebug() << riched20.errorString();\n        }\n    }\n#endif // Q_OS_WIN\n\n#if (QT_VERSION >= QT_VERSION_CHECK(5, 1, 0))\n    setAttribute(Qt::AA_UseHighDpiPixmaps);\n#endif\n\n    QList<int> icon_sizes = QList<int>() << 16 << 24 << 32 << 48 << 64 << 128 << 256 << 512 << 1024;\n    foreach (int icon_size, icon_sizes) {\n        QString icon_path = QString(\":/wsicon/wsicon%1.png\").arg(icon_size);\n        normal_icon_.addFile(icon_path);\n        icon_path = QString(\":/wsicon/wsiconcap%1.png\").arg(icon_size);\n        capture_icon_.addFile(icon_path);\n    }\n\n    //\n    // XXX - this means we try to check for the existence of all files\n    // in the recent list every 2 seconds; that causes noticeable network\n    // traffic if any of them are stored on file servers.\n    //\n    // QFileSystemWatcher should allow us to watch for files being\n    // removed or renamed.  It uses kqueues and EVFILT_VNODE on FreeBSD,\n    // NetBSD, FSEvents on OS X, inotify on Linux if available, and\n    // FindFirstChagneNotification() on Windows.  On all other platforms,\n    // it just periodically polls, as we're doing now.\n    //\n    // For unmounts:\n    //\n    // OS X and FreeBSD deliver NOTE_REVOKE notes for EVFILT_VNODE, and\n    // QFileSystemWatcher delivers signals for them, just as it does for\n    // NOTE_DELETE and NOTE_RENAME.\n    //\n    // On Linux, inotify:\n    //\n    //    http://man7.org/linux/man-pages/man7/inotify.7.html\n    //\n    // appears to deliver \"filesystem containing watched object was\n    // unmounted\" events.  It looks as if Qt turns them into \"changed\"\n    // events.\n    //\n    // On Windows, it's not clearly documented what happens on a handle\n    // opened with FindFirstChangeNotification() if the volume on which\n    // the path handed to FindFirstChangeNotification() is removed, or\n    // ejected, or whatever the Windowsese is for \"unmounted\".  The\n    // handle obviously isn't valid any more, but whether it just hangs\n    // around and never delivers any notifications or delivers an\n    // event that turns into an error indication doesn't seem to be\n    // documented.  If it just hangs around, I think our main loop will\n    // receive a WM_DEVICECHANGE Windows message with DBT_DEVICEREMOVECOMPLETE\n    // if an unmount occurs - even for network devices.  If we need to watch\n    // for those, we can use the winEvent method of the QWidget for the\n    // top-level window to get Windows messages.\n    //\n    // Note also that remote file systems might not report file\n    // removal or renames if they're done on the server or done by\n    // another client.  At least on OS X, they *will* get reported\n    // if they're done on the machine running the program doing the\n    // kqueue stuff, and, at least in newer versions, should get\n    // reported on SMB-mounted (and AFP-mounted?) file systems\n    // even if done on the server or another client.\n    //\n    // But, when push comes to shove, the file manager(s) on the\n    // OSes in question probably use the same mechanisms to\n    // monitor folders in folder windows or open/save dialogs or...,\n    // so my inclination is just to use QFileSystemWatcher.\n    //\n    // However, that wouldn't catch files that become *re*-accessible\n    // by virtue of a file system being re-mounted.  The only way to\n    // catch *that* would be to watch for mounts and re-check all\n    // marked-as-inaccessible files.\n    //\n    // OS X and FreeBSD also support EVFILT_FS events, which notify you\n    // of file system mounts and unmounts.  We'd need to add our own\n    // kqueue for that, if we can check those with QSocketNotifier.\n    //\n    // On Linux, at least as of 2006, you're supposed to poll /proc/mounts:\n    //\n    //    https://lkml.org/lkml/2006/2/22/169\n    //\n    // to discover mounts.\n    //\n    // On Windows, you'd probably have to watch for WM_DEVICECHANGE events.\n    //\n    // Then again, with an automounter, a file system containing a\n    // recent capture might get unmounted automatically if you haven't\n    // referred to anything on that file system for a while, and get\n    // treated as inaccessible.  However, if you try to access it,\n    // the automounter will attempt to re-mount it, so the access *will*\n    // succeed if the automounter can remount the file.\n    //\n    // (Speaking of automounters, repeatedly polling recent files will\n    // keep the file system from being unmounted, for what that's worth.)\n    //\n    // At least on OS X, you can determine whether a file is on an\n    // automounted file system by calling statfs() on its path and\n    // checking whether MNT_AUTOMOUNTED is set in f_flags.  FreeBSD\n    // appears to support that flag as well, but no other *BSD appears\n    // to.\n    //\n    // I'm not sure what can be done on Linux.\n    //\n    recent_timer_.setParent(this);\n    connect(&recent_timer_, SIGNAL(timeout()), this, SLOT(refreshRecentFiles()));\n    recent_timer_.start(2000);\n\n    addr_resolv_timer_.setParent(this);\n    connect(&addr_resolv_timer_, SIGNAL(timeout()), this, SLOT(refreshAddressResolution()));\n    addr_resolv_timer_.start(1000);\n\n    tap_update_timer_.setParent(this);\n    tap_update_timer_.setInterval(TAP_UPDATE_DEFAULT_INTERVAL);\n    connect(this, SIGNAL(appInitialized()), &tap_update_timer_, SLOT(start()));\n    connect(&tap_update_timer_, SIGNAL(timeout()), this, SLOT(updateTaps()));\n\n    // Application-wide style sheet\n    QString app_style_sheet = qApp->styleSheet();\n#if defined(Q_OS_MAC) && QT_VERSION < QT_VERSION_CHECK(5, 6, 0)\n    // Qt uses the HITheme API to draw splitters. In recent versions of OS X\n    // this looks particularly bad: https://bugreports.qt.io/browse/QTBUG-43425\n    // This doesn't look native but it looks better than Yosemite's bit-rotten\n    // rendering of HIThemeSplitterDrawInfo.\n    app_style_sheet +=\n            \"QSplitter::handle:vertical { height: 0px; }\\n\"\n            \"QSplitter::handle:horizontal { width: 0px; }\\n\";\n#endif\n    qApp->setStyleSheet(app_style_sheet);\n\n    connect(qApp, SIGNAL(aboutToQuit()), this, SLOT(cleanup()));\n}",
        "func": "WiresharkApplication::WiresharkApplication(int &argc,  char **argv) :\n    QApplication(argc, argv),\n    initialized_(false),\n    is_reloading_lua_(false),\n    if_notifier_(NULL),\n    active_captures_(0)\n{\n    wsApp = this;\n    setApplicationName(\"Wireshark\");\n\n    Q_INIT_RESOURCE(about);\n    Q_INIT_RESOURCE(i18n);\n    Q_INIT_RESOURCE(layout);\n    Q_INIT_RESOURCE(toolbar);\n    Q_INIT_RESOURCE(wsicon);\n    Q_INIT_RESOURCE(languages);\n\n#ifdef Q_OS_WIN\n    /* RichEd20.DLL is needed for native file dialog filter entries. */\n    ws_load_library(\"riched20.dll\");\n#endif // Q_OS_WIN\n\n#if (QT_VERSION >= QT_VERSION_CHECK(5, 1, 0))\n    setAttribute(Qt::AA_UseHighDpiPixmaps);\n#endif\n\n    QList<int> icon_sizes = QList<int>() << 16 << 24 << 32 << 48 << 64 << 128 << 256 << 512 << 1024;\n    foreach (int icon_size, icon_sizes) {\n        QString icon_path = QString(\":/wsicon/wsicon%1.png\").arg(icon_size);\n        normal_icon_.addFile(icon_path);\n        icon_path = QString(\":/wsicon/wsiconcap%1.png\").arg(icon_size);\n        capture_icon_.addFile(icon_path);\n    }\n\n    //\n    // XXX - this means we try to check for the existence of all files\n    // in the recent list every 2 seconds; that causes noticeable network\n    // traffic if any of them are stored on file servers.\n    //\n    // QFileSystemWatcher should allow us to watch for files being\n    // removed or renamed.  It uses kqueues and EVFILT_VNODE on FreeBSD,\n    // NetBSD, FSEvents on OS X, inotify on Linux if available, and\n    // FindFirstChagneNotification() on Windows.  On all other platforms,\n    // it just periodically polls, as we're doing now.\n    //\n    // For unmounts:\n    //\n    // OS X and FreeBSD deliver NOTE_REVOKE notes for EVFILT_VNODE, and\n    // QFileSystemWatcher delivers signals for them, just as it does for\n    // NOTE_DELETE and NOTE_RENAME.\n    //\n    // On Linux, inotify:\n    //\n    //    http://man7.org/linux/man-pages/man7/inotify.7.html\n    //\n    // appears to deliver \"filesystem containing watched object was\n    // unmounted\" events.  It looks as if Qt turns them into \"changed\"\n    // events.\n    //\n    // On Windows, it's not clearly documented what happens on a handle\n    // opened with FindFirstChangeNotification() if the volume on which\n    // the path handed to FindFirstChangeNotification() is removed, or\n    // ejected, or whatever the Windowsese is for \"unmounted\".  The\n    // handle obviously isn't valid any more, but whether it just hangs\n    // around and never delivers any notifications or delivers an\n    // event that turns into an error indication doesn't seem to be\n    // documented.  If it just hangs around, I think our main loop will\n    // receive a WM_DEVICECHANGE Windows message with DBT_DEVICEREMOVECOMPLETE\n    // if an unmount occurs - even for network devices.  If we need to watch\n    // for those, we can use the winEvent method of the QWidget for the\n    // top-level window to get Windows messages.\n    //\n    // Note also that remote file systems might not report file\n    // removal or renames if they're done on the server or done by\n    // another client.  At least on OS X, they *will* get reported\n    // if they're done on the machine running the program doing the\n    // kqueue stuff, and, at least in newer versions, should get\n    // reported on SMB-mounted (and AFP-mounted?) file systems\n    // even if done on the server or another client.\n    //\n    // But, when push comes to shove, the file manager(s) on the\n    // OSes in question probably use the same mechanisms to\n    // monitor folders in folder windows or open/save dialogs or...,\n    // so my inclination is just to use QFileSystemWatcher.\n    //\n    // However, that wouldn't catch files that become *re*-accessible\n    // by virtue of a file system being re-mounted.  The only way to\n    // catch *that* would be to watch for mounts and re-check all\n    // marked-as-inaccessible files.\n    //\n    // OS X and FreeBSD also support EVFILT_FS events, which notify you\n    // of file system mounts and unmounts.  We'd need to add our own\n    // kqueue for that, if we can check those with QSocketNotifier.\n    //\n    // On Linux, at least as of 2006, you're supposed to poll /proc/mounts:\n    //\n    //    https://lkml.org/lkml/2006/2/22/169\n    //\n    // to discover mounts.\n    //\n    // On Windows, you'd probably have to watch for WM_DEVICECHANGE events.\n    //\n    // Then again, with an automounter, a file system containing a\n    // recent capture might get unmounted automatically if you haven't\n    // referred to anything on that file system for a while, and get\n    // treated as inaccessible.  However, if you try to access it,\n    // the automounter will attempt to re-mount it, so the access *will*\n    // succeed if the automounter can remount the file.\n    //\n    // (Speaking of automounters, repeatedly polling recent files will\n    // keep the file system from being unmounted, for what that's worth.)\n    //\n    // At least on OS X, you can determine whether a file is on an\n    // automounted file system by calling statfs() on its path and\n    // checking whether MNT_AUTOMOUNTED is set in f_flags.  FreeBSD\n    // appears to support that flag as well, but no other *BSD appears\n    // to.\n    //\n    // I'm not sure what can be done on Linux.\n    //\n    recent_timer_.setParent(this);\n    connect(&recent_timer_, SIGNAL(timeout()), this, SLOT(refreshRecentFiles()));\n    recent_timer_.start(2000);\n\n    addr_resolv_timer_.setParent(this);\n    connect(&addr_resolv_timer_, SIGNAL(timeout()), this, SLOT(refreshAddressResolution()));\n    addr_resolv_timer_.start(1000);\n\n    tap_update_timer_.setParent(this);\n    tap_update_timer_.setInterval(TAP_UPDATE_DEFAULT_INTERVAL);\n    connect(this, SIGNAL(appInitialized()), &tap_update_timer_, SLOT(start()));\n    connect(&tap_update_timer_, SIGNAL(timeout()), this, SLOT(updateTaps()));\n\n    // Application-wide style sheet\n    QString app_style_sheet = qApp->styleSheet();\n#if defined(Q_OS_MAC) && QT_VERSION < QT_VERSION_CHECK(5, 6, 0)\n    // Qt uses the HITheme API to draw splitters. In recent versions of OS X\n    // this looks particularly bad: https://bugreports.qt.io/browse/QTBUG-43425\n    // This doesn't look native but it looks better than Yosemite's bit-rotten\n    // rendering of HIThemeSplitterDrawInfo.\n    app_style_sheet +=\n            \"QSplitter::handle:vertical { height: 0px; }\\n\"\n            \"QSplitter::handle:horizontal { width: 0px; }\\n\";\n#endif\n    qApp->setStyleSheet(app_style_sheet);\n\n    connect(qApp, SIGNAL(aboutToQuit()), this, SLOT(cleanup()));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,13 +17,7 @@\n \n #ifdef Q_OS_WIN\n     /* RichEd20.DLL is needed for native file dialog filter entries. */\n-    if (QLibrary::isLibrary(\"riched20.dll\")) {\n-        QLibrary riched20(\"riched20.dll\");\n-        riched20.load();\n-        if (!riched20.isLoaded()) {\n-            qDebug() << riched20.errorString();\n-        }\n-    }\n+    ws_load_library(\"riched20.dll\");\n #endif // Q_OS_WIN\n \n #if (QT_VERSION >= QT_VERSION_CHECK(5, 1, 0))",
        "diff_line_info": {
            "deleted_lines": [
                "    if (QLibrary::isLibrary(\"riched20.dll\")) {",
                "        QLibrary riched20(\"riched20.dll\");",
                "        riched20.load();",
                "        if (!riched20.isLoaded()) {",
                "            qDebug() << riched20.errorString();",
                "        }",
                "    }"
            ],
            "added_lines": [
                "    ws_load_library(\"riched20.dll\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1630",
        "func_name": "chromium/ContainerNode::parserRemoveChild",
        "description": "The ContainerNode::parserRemoveChild function in WebKit/Source/core/dom/ContainerNode.cpp in Blink, as used in Google Chrome before 49.0.2623.75, mishandles widget updates, which makes it easier for remote attackers to bypass the Same Origin Policy via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/05926d6f4e749cd49a16fa04a35e3498eb1b01a0",
        "commit_title": "Defer widget updates in ContainerNode::parserRemoveChild.",
        "commit_text": " ContainerNode::parserRemoveChild is the only consumer of ContainerNode::removeBetween that doesn't defer widget updates during the call. This could potentially lead to problems with scripts running at an inopportune time.  This patch adds a RAII guard that runs deferred widget updates at the end of parserRemoveChild.    ",
        "func_before": "void ContainerNode::parserRemoveChild(Node& oldChild)\n{\n    ASSERT(oldChild.parentNode() == this);\n    ASSERT(!oldChild.isDocumentFragment());\n\n    // This may cause arbitrary Javascript execution via onunload handlers.\n    if (oldChild.connectedSubframeCount())\n        ChildFrameDisconnector(oldChild).disconnect();\n\n    if (oldChild.parentNode() != this)\n        return;\n\n    ChildListMutationScope(*this).willRemoveChild(oldChild);\n    oldChild.notifyMutationObserversNodeWillDetach();\n\n    Node* prev = oldChild.previousSibling();\n    Node* next = oldChild.nextSibling();\n    removeBetween(prev, next, oldChild);\n\n    notifyNodeRemoved(oldChild);\n    childrenChanged(ChildrenChange::forRemoval(oldChild, prev, next, ChildrenChangeSourceParser));\n}",
        "func": "void ContainerNode::parserRemoveChild(Node& oldChild)\n{\n    ASSERT(oldChild.parentNode() == this);\n    ASSERT(!oldChild.isDocumentFragment());\n\n    // This may cause arbitrary Javascript execution via onunload handlers.\n    if (oldChild.connectedSubframeCount())\n        ChildFrameDisconnector(oldChild).disconnect();\n\n    if (oldChild.parentNode() != this)\n        return;\n\n    ChildListMutationScope(*this).willRemoveChild(oldChild);\n    oldChild.notifyMutationObserversNodeWillDetach();\n\n    HTMLFrameOwnerElement::UpdateSuspendScope suspendWidgetHierarchyUpdates;\n    Node* prev = oldChild.previousSibling();\n    Node* next = oldChild.nextSibling();\n    removeBetween(prev, next, oldChild);\n\n    notifyNodeRemoved(oldChild);\n    childrenChanged(ChildrenChange::forRemoval(oldChild, prev, next, ChildrenChangeSourceParser));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n     ChildListMutationScope(*this).willRemoveChild(oldChild);\n     oldChild.notifyMutationObserversNodeWillDetach();\n \n+    HTMLFrameOwnerElement::UpdateSuspendScope suspendWidgetHierarchyUpdates;\n     Node* prev = oldChild.previousSibling();\n     Node* next = oldChild.nextSibling();\n     removeBetween(prev, next, oldChild);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    HTMLFrameOwnerElement::UpdateSuspendScope suspendWidgetHierarchyUpdates;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1631",
        "func_name": "chromium/PPB_Flash_MessageLoop_Impl::InternalRun",
        "description": "The PPB_Flash_MessageLoop_Impl::InternalRun function in content/renderer/pepper/ppb_flash_message_loop_impl.cc in the Pepper plugin in Google Chrome before 49.0.2623.75 mishandles nested message loops, which allows remote attackers to bypass the Same Origin Policy via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/dd77c2a41c72589d929db0592565125ca629fb2c",
        "commit_title": "Fix PPB_Flash_MessageLoop.",
        "commit_text": " This CL suspends script callbacks and resource loads while running nested message loop using PPB_Flash_MessageLoop.    ",
        "func_before": "int32_t PPB_Flash_MessageLoop_Impl::InternalRun(\n    const RunFromHostProxyCallback& callback) {\n  if (state_->run_called()) {\n    if (!callback.is_null())\n      callback.Run(PP_ERROR_FAILED);\n    return PP_ERROR_FAILED;\n  }\n  state_->set_run_called();\n  state_->set_run_callback(callback);\n\n  // It is possible that the PPB_Flash_MessageLoop_Impl object has been\n  // destroyed when the nested message loop exits.\n  scoped_refptr<State> state_protector(state_);\n  {\n    base::MessageLoop::ScopedNestableTaskAllower allow(\n        base::MessageLoop::current());\n    base::MessageLoop::current()->Run();\n  }\n  // Don't access data members of the class below.\n\n  return state_protector->result();\n}",
        "func": "int32_t PPB_Flash_MessageLoop_Impl::InternalRun(\n    const RunFromHostProxyCallback& callback) {\n  if (state_->run_called()) {\n    if (!callback.is_null())\n      callback.Run(PP_ERROR_FAILED);\n    return PP_ERROR_FAILED;\n  }\n  state_->set_run_called();\n  state_->set_run_callback(callback);\n\n  // It is possible that the PPB_Flash_MessageLoop_Impl object has been\n  // destroyed when the nested message loop exits.\n  scoped_refptr<State> state_protector(state_);\n  {\n    base::MessageLoop::ScopedNestableTaskAllower allow(\n        base::MessageLoop::current());\n    blink::WebView::willEnterModalLoop();\n\n    base::MessageLoop::current()->Run();\n\n    blink::WebView::didExitModalLoop();\n  }\n  // Don't access data members of the class below.\n\n  return state_protector->result();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,7 +14,11 @@\n   {\n     base::MessageLoop::ScopedNestableTaskAllower allow(\n         base::MessageLoop::current());\n+    blink::WebView::willEnterModalLoop();\n+\n     base::MessageLoop::current()->Run();\n+\n+    blink::WebView::didExitModalLoop();\n   }\n   // Don't access data members of the class below.\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    blink::WebView::willEnterModalLoop();",
                "",
                "",
                "    blink::WebView::didExitModalLoop();"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/APIActivityLogger::LogInternal",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "void APIActivityLogger::LogInternal(\n    const CallType call_type,\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  DCHECK_GT(args.Length(), 2);\n  DCHECK(args[0]->IsString());\n  DCHECK(args[1]->IsString());\n  DCHECK(args[2]->IsArray());\n\n  std::string ext_id = *v8::String::Utf8Value(args[0]);\n  ExtensionHostMsg_APIActionOrEvent_Params params;\n  params.api_call = *v8::String::Utf8Value(args[1]);\n  if (args.Length() == 4)  // Extras are optional.\n    params.extra = *v8::String::Utf8Value(args[3]);\n  else\n    params.extra = \"\";\n\n  // Get the array of api call arguments.\n  v8::Local<v8::Array> arg_array = v8::Local<v8::Array>::Cast(args[2]);\n  if (arg_array->Length() > 0) {\n    scoped_ptr<V8ValueConverter> converter(V8ValueConverter::create());\n    ActivityLogConverterStrategy strategy;\n    converter->SetFunctionAllowed(true);\n    converter->SetStrategy(&strategy);\n    scoped_ptr<base::ListValue> arg_list(new base::ListValue());\n    for (size_t i = 0; i < arg_array->Length(); ++i) {\n      arg_list->Set(\n          i,\n          converter->FromV8Value(arg_array->Get(i),\n                                 args.GetIsolate()->GetCurrentContext()));\n    }\n    params.arguments.Swap(arg_list.get());\n  }\n\n  if (call_type == APICALL) {\n    content::RenderThread::Get()->Send(\n        new ExtensionHostMsg_AddAPIActionToActivityLog(ext_id, params));\n  } else if (call_type == EVENT) {\n    content::RenderThread::Get()->Send(\n        new ExtensionHostMsg_AddEventToActivityLog(ext_id, params));\n  }\n}",
        "func": "void APIActivityLogger::LogInternal(\n    const CallType call_type,\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  CHECK_GT(args.Length(), 2);\n  CHECK(args[0]->IsString());\n  CHECK(args[1]->IsString());\n  CHECK(args[2]->IsArray());\n\n  std::string ext_id = *v8::String::Utf8Value(args[0]);\n  ExtensionHostMsg_APIActionOrEvent_Params params;\n  params.api_call = *v8::String::Utf8Value(args[1]);\n  if (args.Length() == 4)  // Extras are optional.\n    params.extra = *v8::String::Utf8Value(args[3]);\n  else\n    params.extra = \"\";\n\n  // Get the array of api call arguments.\n  v8::Local<v8::Array> arg_array = v8::Local<v8::Array>::Cast(args[2]);\n  if (arg_array->Length() > 0) {\n    scoped_ptr<V8ValueConverter> converter(V8ValueConverter::create());\n    ActivityLogConverterStrategy strategy;\n    converter->SetFunctionAllowed(true);\n    converter->SetStrategy(&strategy);\n    scoped_ptr<base::ListValue> arg_list(new base::ListValue());\n    for (size_t i = 0; i < arg_array->Length(); ++i) {\n      arg_list->Set(\n          i,\n          converter->FromV8Value(arg_array->Get(i),\n                                 args.GetIsolate()->GetCurrentContext()));\n    }\n    params.arguments.Swap(arg_list.get());\n  }\n\n  if (call_type == APICALL) {\n    content::RenderThread::Get()->Send(\n        new ExtensionHostMsg_AddAPIActionToActivityLog(ext_id, params));\n  } else if (call_type == EVENT) {\n    content::RenderThread::Get()->Send(\n        new ExtensionHostMsg_AddEventToActivityLog(ext_id, params));\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,10 @@\n void APIActivityLogger::LogInternal(\n     const CallType call_type,\n     const v8::FunctionCallbackInfo<v8::Value>& args) {\n-  DCHECK_GT(args.Length(), 2);\n-  DCHECK(args[0]->IsString());\n-  DCHECK(args[1]->IsString());\n-  DCHECK(args[2]->IsArray());\n+  CHECK_GT(args.Length(), 2);\n+  CHECK(args[0]->IsString());\n+  CHECK(args[1]->IsString());\n+  CHECK(args[2]->IsArray());\n \n   std::string ext_id = *v8::String::Utf8Value(args[0]);\n   ExtensionHostMsg_APIActionOrEvent_Params params;",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK_GT(args.Length(), 2);",
                "  DCHECK(args[0]->IsString());",
                "  DCHECK(args[1]->IsString());",
                "  DCHECK(args[2]->IsArray());"
            ],
            "added_lines": [
                "  CHECK_GT(args.Length(), 2);",
                "  CHECK(args[0]->IsString());",
                "  CHECK(args[1]->IsString());",
                "  CHECK(args[2]->IsArray());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/GetBlobUuid",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "void GetBlobUuid(const v8::FunctionCallbackInfo<v8::Value>& args) {\n  DCHECK_EQ(1, args.Length());\n  blink::WebBlob blob = blink::WebBlob::fromV8Value(args[0]);\n  args.GetReturnValue().Set(\n      v8::String::NewFromUtf8(args.GetIsolate(), blob.uuid().utf8().data()));\n}",
        "func": "void GetBlobUuid(const v8::FunctionCallbackInfo<v8::Value>& args) {\n  CHECK_EQ(1, args.Length());\n  blink::WebBlob blob = blink::WebBlob::fromV8Value(args[0]);\n  args.GetReturnValue().Set(\n      v8::String::NewFromUtf8(args.GetIsolate(), blob.uuid().utf8().data()));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n void GetBlobUuid(const v8::FunctionCallbackInfo<v8::Value>& args) {\n-  DCHECK_EQ(1, args.Length());\n+  CHECK_EQ(1, args.Length());\n   blink::WebBlob blob = blink::WebBlob::fromV8Value(args[0]);\n   args.GetReturnValue().Set(\n       v8::String::NewFromUtf8(args.GetIsolate(), blob.uuid().utf8().data()));",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK_EQ(1, args.Length());"
            ],
            "added_lines": [
                "  CHECK_EQ(1, args.Length());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/BlobNativeHandler::TakeBrowserProcessBlob",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "void BlobNativeHandler::TakeBrowserProcessBlob(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  DCHECK_EQ(3, args.Length());\n  DCHECK(args[0]->IsString());\n  DCHECK(args[1]->IsString());\n  DCHECK(args[2]->IsInt32());\n  std::string uuid(*v8::String::Utf8Value(args[0]));\n  std::string type(*v8::String::Utf8Value(args[1]));\n  blink::WebBlob blob =\n      blink::WebBlob::createFromUUID(blink::WebString::fromUTF8(uuid),\n                                     blink::WebString::fromUTF8(type),\n                                     args[2]->Int32Value());\n  args.GetReturnValue().Set(blob.toV8Value(\n      context()->v8_context()->Global(), args.GetIsolate()));\n}",
        "func": "void BlobNativeHandler::TakeBrowserProcessBlob(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  CHECK_EQ(3, args.Length());\n  CHECK(args[0]->IsString());\n  CHECK(args[1]->IsString());\n  CHECK(args[2]->IsInt32());\n  std::string uuid(*v8::String::Utf8Value(args[0]));\n  std::string type(*v8::String::Utf8Value(args[1]));\n  blink::WebBlob blob =\n      blink::WebBlob::createFromUUID(blink::WebString::fromUTF8(uuid),\n                                     blink::WebString::fromUTF8(type),\n                                     args[2]->Int32Value());\n  args.GetReturnValue().Set(blob.toV8Value(\n      context()->v8_context()->Global(), args.GetIsolate()));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,9 @@\n void BlobNativeHandler::TakeBrowserProcessBlob(\n     const v8::FunctionCallbackInfo<v8::Value>& args) {\n-  DCHECK_EQ(3, args.Length());\n-  DCHECK(args[0]->IsString());\n-  DCHECK(args[1]->IsString());\n-  DCHECK(args[2]->IsInt32());\n+  CHECK_EQ(3, args.Length());\n+  CHECK(args[0]->IsString());\n+  CHECK(args[1]->IsString());\n+  CHECK(args[2]->IsInt32());\n   std::string uuid(*v8::String::Utf8Value(args[0]));\n   std::string type(*v8::String::Utf8Value(args[1]));\n   blink::WebBlob blob =",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK_EQ(3, args.Length());",
                "  DCHECK(args[0]->IsString());",
                "  DCHECK(args[1]->IsString());",
                "  DCHECK(args[2]->IsInt32());"
            ],
            "added_lines": [
                "  CHECK_EQ(3, args.Length());",
                "  CHECK(args[0]->IsString());",
                "  CHECK(args[1]->IsString());",
                "  CHECK(args[2]->IsInt32());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/SetExportsProperty",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "void SetExportsProperty(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  v8::Local<v8::Object> obj = args.This();\n  DCHECK_EQ(2, args.Length());\n  DCHECK(args[0]->IsString());\n  v8::Maybe<bool> result =\n      obj->DefineOwnProperty(args.GetIsolate()->GetCurrentContext(),\n                             args[0]->ToString(), args[1], v8::ReadOnly);\n  if (!result.FromMaybe(false))\n    LOG(ERROR) << \"Failed to set private property on the export.\";\n}",
        "func": "void SetExportsProperty(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  v8::Local<v8::Object> obj = args.This();\n  CHECK_EQ(2, args.Length());\n  CHECK(args[0]->IsString());\n  v8::Maybe<bool> result =\n      obj->DefineOwnProperty(args.GetIsolate()->GetCurrentContext(),\n                             args[0]->ToString(), args[1], v8::ReadOnly);\n  if (!result.FromMaybe(false))\n    LOG(ERROR) << \"Failed to set private property on the export.\";\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,8 @@\n void SetExportsProperty(\n     const v8::FunctionCallbackInfo<v8::Value>& args) {\n   v8::Local<v8::Object> obj = args.This();\n-  DCHECK_EQ(2, args.Length());\n-  DCHECK(args[0]->IsString());\n+  CHECK_EQ(2, args.Length());\n+  CHECK(args[0]->IsString());\n   v8::Maybe<bool> result =\n       obj->DefineOwnProperty(args.GetIsolate()->GetCurrentContext(),\n                              args[0]->ToString(), args[1], v8::ReadOnly);",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK_EQ(2, args.Length());",
                "  DCHECK(args[0]->IsString());"
            ],
            "added_lines": [
                "  CHECK_EQ(2, args.Length());",
                "  CHECK(args[0]->IsString());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/SetProperty",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "bool SetProperty(v8::Isolate* isolate,\n                 v8::Local<v8::Object> object,\n                 KeyType key,\n                 v8::Local<v8::Value> value) {\n  auto maybe = object->Set(isolate->GetCurrentContext(), key, value);\n  return !maybe.IsNothing() && maybe.FromJust();\n}",
        "func": "bool SetProperty(v8::Isolate* isolate,\n                 v8::Local<v8::Object> object,\n                 KeyType key,\n                 v8::Local<v8::Value> value) {\n  auto maybe =\n      object->DefineOwnProperty(isolate->GetCurrentContext(), key, value);\n  return !maybe.IsNothing() && maybe.FromJust();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n                  v8::Local<v8::Object> object,\n                  KeyType key,\n                  v8::Local<v8::Value> value) {\n-  auto maybe = object->Set(isolate->GetCurrentContext(), key, value);\n+  auto maybe =\n+      object->DefineOwnProperty(isolate->GetCurrentContext(), key, value);\n   return !maybe.IsNothing() && maybe.FromJust();\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  auto maybe = object->Set(isolate->GetCurrentContext(), key, value);"
            ],
            "added_lines": [
                "  auto maybe =",
                "      object->DefineOwnProperty(isolate->GetCurrentContext(), key, value);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/SetProperty",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "inline bool SetProperty(v8::Local<v8::Context> context,\n                        v8::Local<v8::Object> object,\n                        uint32_t index,\n                        v8::Local<v8::Value> value) {\n  return IsTrue(object->Set(context, index, value));\n}",
        "func": "inline bool SetProperty(v8::Local<v8::Context> context,\n                        v8::Local<v8::Object> object,\n                        uint32_t index,\n                        v8::Local<v8::Value> value) {\n  return SetProperty(context, object, base::UintToString(index).c_str(), value);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,5 @@\n                         v8::Local<v8::Object> object,\n                         uint32_t index,\n                         v8::Local<v8::Value> value) {\n-  return IsTrue(object->Set(context, index, value));\n+  return SetProperty(context, object, base::UintToString(index).c_str(), value);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  return IsTrue(object->Set(context, index, value));"
            ],
            "added_lines": [
                "  return SetProperty(context, object, base::UintToString(index).c_str(), value);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/FileSystemNatives::GetFileEntry",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "void FileSystemNatives::GetFileEntry(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  DCHECK(args.Length() == 5);\n  DCHECK(args[0]->IsString());\n  std::string type_string = *v8::String::Utf8Value(args[0]);\n  blink::WebFileSystemType type;\n  bool is_valid_type = storage::GetFileSystemPublicType(type_string, &type);\n  DCHECK(is_valid_type);\n  if (is_valid_type == false) {\n    return;\n  }\n\n  DCHECK(args[1]->IsString());\n  DCHECK(args[2]->IsString());\n  DCHECK(args[3]->IsString());\n  std::string file_system_name(*v8::String::Utf8Value(args[1]));\n  GURL file_system_root_url(*v8::String::Utf8Value(args[2]));\n  std::string file_path_string(*v8::String::Utf8Value(args[3]));\n  base::FilePath file_path = base::FilePath::FromUTF8Unsafe(file_path_string);\n  DCHECK(storage::VirtualPath::IsAbsolute(file_path.value()));\n\n  DCHECK(args[4]->IsBoolean());\n  blink::WebDOMFileSystem::EntryType entry_type =\n      args[4]->BooleanValue() ? blink::WebDOMFileSystem::EntryTypeDirectory\n                              : blink::WebDOMFileSystem::EntryTypeFile;\n\n  blink::WebLocalFrame* webframe =\n      blink::WebLocalFrame::frameForContext(context()->v8_context());\n  DCHECK(webframe);\n  args.GetReturnValue().Set(\n      blink::WebDOMFileSystem::create(\n          webframe,\n          type,\n          blink::WebString::fromUTF8(file_system_name),\n          file_system_root_url)\n          .createV8Entry(blink::WebString::fromUTF8(file_path_string),\n                         entry_type,\n                         context()->v8_context()->Global(),\n                         args.GetIsolate()));\n}",
        "func": "void FileSystemNatives::GetFileEntry(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  CHECK_EQ(5, args.Length());\n  CHECK(args[0]->IsString());\n  std::string type_string = *v8::String::Utf8Value(args[0]);\n  blink::WebFileSystemType type;\n  bool is_valid_type = storage::GetFileSystemPublicType(type_string, &type);\n  DCHECK(is_valid_type);\n  if (is_valid_type == false) {\n    return;\n  }\n\n  CHECK(args[1]->IsString());\n  CHECK(args[2]->IsString());\n  CHECK(args[3]->IsString());\n  std::string file_system_name(*v8::String::Utf8Value(args[1]));\n  GURL file_system_root_url(*v8::String::Utf8Value(args[2]));\n  std::string file_path_string(*v8::String::Utf8Value(args[3]));\n  base::FilePath file_path = base::FilePath::FromUTF8Unsafe(file_path_string);\n  DCHECK(storage::VirtualPath::IsAbsolute(file_path.value()));\n\n  CHECK(args[4]->IsBoolean());\n  blink::WebDOMFileSystem::EntryType entry_type =\n      args[4]->BooleanValue() ? blink::WebDOMFileSystem::EntryTypeDirectory\n                              : blink::WebDOMFileSystem::EntryTypeFile;\n\n  blink::WebLocalFrame* webframe =\n      blink::WebLocalFrame::frameForContext(context()->v8_context());\n  DCHECK(webframe);\n  args.GetReturnValue().Set(\n      blink::WebDOMFileSystem::create(\n          webframe,\n          type,\n          blink::WebString::fromUTF8(file_system_name),\n          file_system_root_url)\n          .createV8Entry(blink::WebString::fromUTF8(file_path_string),\n                         entry_type,\n                         context()->v8_context()->Global(),\n                         args.GetIsolate()));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n void FileSystemNatives::GetFileEntry(\n     const v8::FunctionCallbackInfo<v8::Value>& args) {\n-  DCHECK(args.Length() == 5);\n-  DCHECK(args[0]->IsString());\n+  CHECK_EQ(5, args.Length());\n+  CHECK(args[0]->IsString());\n   std::string type_string = *v8::String::Utf8Value(args[0]);\n   blink::WebFileSystemType type;\n   bool is_valid_type = storage::GetFileSystemPublicType(type_string, &type);\n@@ -10,16 +10,16 @@\n     return;\n   }\n \n-  DCHECK(args[1]->IsString());\n-  DCHECK(args[2]->IsString());\n-  DCHECK(args[3]->IsString());\n+  CHECK(args[1]->IsString());\n+  CHECK(args[2]->IsString());\n+  CHECK(args[3]->IsString());\n   std::string file_system_name(*v8::String::Utf8Value(args[1]));\n   GURL file_system_root_url(*v8::String::Utf8Value(args[2]));\n   std::string file_path_string(*v8::String::Utf8Value(args[3]));\n   base::FilePath file_path = base::FilePath::FromUTF8Unsafe(file_path_string);\n   DCHECK(storage::VirtualPath::IsAbsolute(file_path.value()));\n \n-  DCHECK(args[4]->IsBoolean());\n+  CHECK(args[4]->IsBoolean());\n   blink::WebDOMFileSystem::EntryType entry_type =\n       args[4]->BooleanValue() ? blink::WebDOMFileSystem::EntryTypeDirectory\n                               : blink::WebDOMFileSystem::EntryTypeFile;",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK(args.Length() == 5);",
                "  DCHECK(args[0]->IsString());",
                "  DCHECK(args[1]->IsString());",
                "  DCHECK(args[2]->IsString());",
                "  DCHECK(args[3]->IsString());",
                "  DCHECK(args[4]->IsBoolean());"
            ],
            "added_lines": [
                "  CHECK_EQ(5, args.Length());",
                "  CHECK(args[0]->IsString());",
                "  CHECK(args[1]->IsString());",
                "  CHECK(args[2]->IsString());",
                "  CHECK(args[3]->IsString());",
                "  CHECK(args[4]->IsBoolean());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1632",
        "func_name": "chromium/FileSystemNatives::GetIsolatedFileSystem",
        "description": "The Extensions subsystem in Google Chrome before 49.0.2623.75 does not properly maintain own properties, which allows remote attackers to bypass intended access restrictions via crafted JavaScript code that triggers an incorrect cast, related to extensions/renderer/v8_helpers.h and gin/converter.h.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/415b73b1a400a994a86e6f29709aa0271e895dd5",
        "commit_title": "[Extensions] Don't allow gin::Define to be overridden",
        "commit_text": " Use DefineOwnProperty instead of Set in for gin, including gin::Define. Replace Set in v8_helpers as well, to avoid the same problem. Also update callsites from JS to CHECK expected arguments, rather than DCHECK (since receiving unexpected arguments likely means executing untrusted code).    ",
        "func_before": "void FileSystemNatives::GetIsolatedFileSystem(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  DCHECK(args.Length() == 1 || args.Length() == 2);\n  DCHECK(args[0]->IsString());\n  std::string file_system_id(*v8::String::Utf8Value(args[0]));\n  blink::WebLocalFrame* webframe =\n      blink::WebLocalFrame::frameForContext(context()->v8_context());\n  DCHECK(webframe);\n\n  GURL context_url =\n      extensions::ScriptContext::GetDataSourceURLForFrame(webframe);\n  CHECK(context_url.SchemeIs(extensions::kExtensionScheme));\n\n  std::string name(storage::GetIsolatedFileSystemName(context_url.GetOrigin(),\n                                                      file_system_id));\n\n  // The optional second argument is the subfolder within the isolated file\n  // system at which to root the DOMFileSystem we're returning to the caller.\n  std::string optional_root_name;\n  if (args.Length() == 2) {\n    DCHECK(args[1]->IsString());\n    optional_root_name = *v8::String::Utf8Value(args[1]);\n  }\n\n  GURL root_url(storage::GetIsolatedFileSystemRootURIString(\n      context_url.GetOrigin(), file_system_id, optional_root_name));\n\n  args.GetReturnValue().Set(\n      blink::WebDOMFileSystem::create(webframe,\n                                      blink::WebFileSystemTypeIsolated,\n                                      blink::WebString::fromUTF8(name),\n                                      root_url)\n          .toV8Value(context()->v8_context()->Global(), args.GetIsolate()));\n}",
        "func": "void FileSystemNatives::GetIsolatedFileSystem(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  CHECK(args.Length() == 1 || args.Length() == 2);\n  CHECK(args[0]->IsString());\n  std::string file_system_id(*v8::String::Utf8Value(args[0]));\n  blink::WebLocalFrame* webframe =\n      blink::WebLocalFrame::frameForContext(context()->v8_context());\n  DCHECK(webframe);\n\n  GURL context_url =\n      extensions::ScriptContext::GetDataSourceURLForFrame(webframe);\n  CHECK(context_url.SchemeIs(extensions::kExtensionScheme));\n\n  std::string name(storage::GetIsolatedFileSystemName(context_url.GetOrigin(),\n                                                      file_system_id));\n\n  // The optional second argument is the subfolder within the isolated file\n  // system at which to root the DOMFileSystem we're returning to the caller.\n  std::string optional_root_name;\n  if (args.Length() == 2) {\n    CHECK(args[1]->IsString());\n    optional_root_name = *v8::String::Utf8Value(args[1]);\n  }\n\n  GURL root_url(storage::GetIsolatedFileSystemRootURIString(\n      context_url.GetOrigin(), file_system_id, optional_root_name));\n\n  args.GetReturnValue().Set(\n      blink::WebDOMFileSystem::create(webframe,\n                                      blink::WebFileSystemTypeIsolated,\n                                      blink::WebString::fromUTF8(name),\n                                      root_url)\n          .toV8Value(context()->v8_context()->Global(), args.GetIsolate()));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n void FileSystemNatives::GetIsolatedFileSystem(\n     const v8::FunctionCallbackInfo<v8::Value>& args) {\n-  DCHECK(args.Length() == 1 || args.Length() == 2);\n-  DCHECK(args[0]->IsString());\n+  CHECK(args.Length() == 1 || args.Length() == 2);\n+  CHECK(args[0]->IsString());\n   std::string file_system_id(*v8::String::Utf8Value(args[0]));\n   blink::WebLocalFrame* webframe =\n       blink::WebLocalFrame::frameForContext(context()->v8_context());\n@@ -18,7 +18,7 @@\n   // system at which to root the DOMFileSystem we're returning to the caller.\n   std::string optional_root_name;\n   if (args.Length() == 2) {\n-    DCHECK(args[1]->IsString());\n+    CHECK(args[1]->IsString());\n     optional_root_name = *v8::String::Utf8Value(args[1]);\n   }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK(args.Length() == 1 || args.Length() == 2);",
                "  DCHECK(args[0]->IsString());",
                "    DCHECK(args[1]->IsString());"
            ],
            "added_lines": [
                "  CHECK(args.Length() == 1 || args.Length() == 2);",
                "  CHECK(args[0]->IsString());",
                "    CHECK(args[1]->IsString());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1636",
        "func_name": "chromium/PendingScript::notifyFinished",
        "description": "The PendingScript::notifyFinished function in WebKit/Source/core/dom/PendingScript.cpp in Google Chrome before 49.0.2623.75 relies on memory-cache information about integrity-check occurrences instead of integrity-check successes, which allows remote attackers to bypass the Subresource Integrity (aka SRI) protection mechanism by triggering two loads of the same resource.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/0979e9712439b056355af462d68fe5c6d9ee5466",
        "commit_title": "Fix SRI bypass by loading same resource twice in same origin.",
        "commit_text": " This fixes a bug where the memory cache was bypassing subresource integrity checks when a resource is loaded for a second time in the same origin. The resource in the memory cache was correctly storing that an integrity check had already been done so whene it was retrieved later, it wouldn't need to be checked again, but it didn't store the fact that this was a *failure*, so when the load happened a second time, it assumed it was a good integrity.  This modifies the resources to store a disposition for the integrity check, rather than just that the integrity check occurred. On a reload of the resource, if the integrity had failed the first time, the resource will fail to load.    (cherry picked from commit bf24693238d407f90bec71453b18aae8dd1c0f43)   ",
        "func_before": "void PendingScript::notifyFinished(Resource* resource)\n{\n    // The following SRI checks need to be here because, unfortunately, fetches\n    // are not done purely according to the Fetch spec. In particular,\n    // different requests for the same resource do not have different\n    // responses; the memory cache can (and will) return the exact same\n    // Resource object.\n    //\n    // For different requests, the same Resource object will be returned and\n    // will not be associated with the particular request.  Therefore, when the\n    // body of the response comes in, there's no way to validate the integrity\n    // of the Resource object against a particular request (since there may be\n    // several pending requests all tied to the identical object, and the\n    // actual requests are not stored).\n    //\n    // In order to simulate the correct behavior, Blink explicitly does the SRI\n    // checks here, when a PendingScript tied to a particular request is\n    // finished (and in the case of a StyleSheet, at the point of execution),\n    // while having proper Fetch checks in the fetch module for use in the\n    // fetch JavaScript API. In a future world where the ResourceFetcher uses\n    // the Fetch algorithm, this should be fixed by having separate Response\n    // objects (perhaps attached to identical Resource objects) per request.\n    //\n    // See https://crbug.com/500701 for more information.\n    if (m_element) {\n        ASSERT(resource->type() == Resource::Script);\n        ScriptResource* scriptResource = toScriptResource(resource);\n        String integrityAttr = m_element->fastGetAttribute(HTMLNames::integrityAttr);\n\n        // It is possible to get back a script resource with integrity metadata\n        // for a request with an empty integrity attribute. In that case, the\n        // integrity check should be skipped, so this check ensures that the\n        // integrity attribute isn't empty in addition to checking if the\n        // resource has empty integrity metadata.\n        if (!integrityAttr.isEmpty() && !scriptResource->integrityMetadata().isEmpty()) {\n            if (!scriptResource->integrityAlreadyChecked() && resource->resourceBuffer()) {\n                scriptResource->setIntegrityAlreadyChecked(true);\n                m_integrityFailure = !SubresourceIntegrity::CheckSubresourceIntegrity(scriptResource->integrityMetadata(), *m_element, resource->resourceBuffer()->data(), resource->resourceBuffer()->size(), resource->url(), *resource);\n            }\n        }\n    }\n\n    if (m_streamer)\n        m_streamer->notifyFinished(resource);\n}",
        "func": "void PendingScript::notifyFinished(Resource* resource)\n{\n    // The following SRI checks need to be here because, unfortunately, fetches\n    // are not done purely according to the Fetch spec. In particular,\n    // different requests for the same resource do not have different\n    // responses; the memory cache can (and will) return the exact same\n    // Resource object.\n    //\n    // For different requests, the same Resource object will be returned and\n    // will not be associated with the particular request.  Therefore, when the\n    // body of the response comes in, there's no way to validate the integrity\n    // of the Resource object against a particular request (since there may be\n    // several pending requests all tied to the identical object, and the\n    // actual requests are not stored).\n    //\n    // In order to simulate the correct behavior, Blink explicitly does the SRI\n    // checks here, when a PendingScript tied to a particular request is\n    // finished (and in the case of a StyleSheet, at the point of execution),\n    // while having proper Fetch checks in the fetch module for use in the\n    // fetch JavaScript API. In a future world where the ResourceFetcher uses\n    // the Fetch algorithm, this should be fixed by having separate Response\n    // objects (perhaps attached to identical Resource objects) per request.\n    //\n    // See https://crbug.com/500701 for more information.\n    if (m_element) {\n        ASSERT(resource->type() == Resource::Script);\n        ScriptResource* scriptResource = toScriptResource(resource);\n        String integrityAttr = m_element->fastGetAttribute(HTMLNames::integrityAttr);\n\n        // It is possible to get back a script resource with integrity metadata\n        // for a request with an empty integrity attribute. In that case, the\n        // integrity check should be skipped, so this check ensures that the\n        // integrity attribute isn't empty in addition to checking if the\n        // resource has empty integrity metadata.\n        if (!integrityAttr.isEmpty() && !scriptResource->integrityMetadata().isEmpty()) {\n            ScriptIntegrityDisposition disposition = scriptResource->integrityDisposition();\n            if (disposition == ScriptIntegrityDisposition::Failed) {\n                // TODO(jww): This should probably also generate a console\n                // message identical to the one produced by\n                // CheckSubresourceIntegrity below. See https://crbug.com/585267.\n                m_integrityFailure = true;\n            } else if (disposition == ScriptIntegrityDisposition::NotChecked && resource->resourceBuffer()) {\n                m_integrityFailure = !SubresourceIntegrity::CheckSubresourceIntegrity(scriptResource->integrityMetadata(), *m_element, resource->resourceBuffer()->data(), resource->resourceBuffer()->size(), resource->url(), *resource);\n                scriptResource->setIntegrityDisposition(m_integrityFailure ? ScriptIntegrityDisposition::Failed : ScriptIntegrityDisposition::Passed);\n            }\n        }\n    }\n\n    if (m_streamer)\n        m_streamer->notifyFinished(resource);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,9 +33,15 @@\n         // integrity attribute isn't empty in addition to checking if the\n         // resource has empty integrity metadata.\n         if (!integrityAttr.isEmpty() && !scriptResource->integrityMetadata().isEmpty()) {\n-            if (!scriptResource->integrityAlreadyChecked() && resource->resourceBuffer()) {\n-                scriptResource->setIntegrityAlreadyChecked(true);\n+            ScriptIntegrityDisposition disposition = scriptResource->integrityDisposition();\n+            if (disposition == ScriptIntegrityDisposition::Failed) {\n+                // TODO(jww): This should probably also generate a console\n+                // message identical to the one produced by\n+                // CheckSubresourceIntegrity below. See https://crbug.com/585267.\n+                m_integrityFailure = true;\n+            } else if (disposition == ScriptIntegrityDisposition::NotChecked && resource->resourceBuffer()) {\n                 m_integrityFailure = !SubresourceIntegrity::CheckSubresourceIntegrity(scriptResource->integrityMetadata(), *m_element, resource->resourceBuffer()->data(), resource->resourceBuffer()->size(), resource->url(), *resource);\n+                scriptResource->setIntegrityDisposition(m_integrityFailure ? ScriptIntegrityDisposition::Failed : ScriptIntegrityDisposition::Passed);\n             }\n         }\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "            if (!scriptResource->integrityAlreadyChecked() && resource->resourceBuffer()) {",
                "                scriptResource->setIntegrityAlreadyChecked(true);"
            ],
            "added_lines": [
                "            ScriptIntegrityDisposition disposition = scriptResource->integrityDisposition();",
                "            if (disposition == ScriptIntegrityDisposition::Failed) {",
                "                // TODO(jww): This should probably also generate a console",
                "                // message identical to the one produced by",
                "                // CheckSubresourceIntegrity below. See https://crbug.com/585267.",
                "                m_integrityFailure = true;",
                "            } else if (disposition == ScriptIntegrityDisposition::NotChecked && resource->resourceBuffer()) {",
                "                scriptResource->setIntegrityDisposition(m_integrityFailure ? ScriptIntegrityDisposition::Failed : ScriptIntegrityDisposition::Passed);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1636",
        "func_name": "chromium/ScriptResource::ScriptResource",
        "description": "The PendingScript::notifyFinished function in WebKit/Source/core/dom/PendingScript.cpp in Google Chrome before 49.0.2623.75 relies on memory-cache information about integrity-check occurrences instead of integrity-check successes, which allows remote attackers to bypass the Subresource Integrity (aka SRI) protection mechanism by triggering two loads of the same resource.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/0979e9712439b056355af462d68fe5c6d9ee5466",
        "commit_title": "Fix SRI bypass by loading same resource twice in same origin.",
        "commit_text": " This fixes a bug where the memory cache was bypassing subresource integrity checks when a resource is loaded for a second time in the same origin. The resource in the memory cache was correctly storing that an integrity check had already been done so whene it was retrieved later, it wouldn't need to be checked again, but it didn't store the fact that this was a *failure*, so when the load happened a second time, it assumed it was a good integrity.  This modifies the resources to store a disposition for the integrity check, rather than just that the integrity check occurred. On a reload of the resource, if the integrity had failed the first time, the resource will fail to load.    (cherry picked from commit bf24693238d407f90bec71453b18aae8dd1c0f43)   ",
        "func_before": "ScriptResource::ScriptResource(const ResourceRequest& resourceRequest, const String& charset)\n    : TextResource(resourceRequest, Script, \"application/javascript\", charset), m_integrityChecked(false)\n{\n    DEFINE_STATIC_LOCAL(const AtomicString, acceptScript, (\"*/*\", AtomicString::ConstructFromLiteral));\n\n    // It's javascript we want.\n    // But some websites think their scripts are <some wrong mimetype here>\n    // and refuse to serve them if we only accept application/x-javascript.\n    setAccept(acceptScript);\n}",
        "func": "ScriptResource::ScriptResource(const ResourceRequest& resourceRequest, const String& charset)\n    : TextResource(resourceRequest, Script, \"application/javascript\", charset), m_integrityDisposition(ScriptIntegrityDisposition::NotChecked)\n{\n    DEFINE_STATIC_LOCAL(const AtomicString, acceptScript, (\"*/*\", AtomicString::ConstructFromLiteral));\n\n    // It's javascript we want.\n    // But some websites think their scripts are <some wrong mimetype here>\n    // and refuse to serve them if we only accept application/x-javascript.\n    setAccept(acceptScript);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n ScriptResource::ScriptResource(const ResourceRequest& resourceRequest, const String& charset)\n-    : TextResource(resourceRequest, Script, \"application/javascript\", charset), m_integrityChecked(false)\n+    : TextResource(resourceRequest, Script, \"application/javascript\", charset), m_integrityDisposition(ScriptIntegrityDisposition::NotChecked)\n {\n     DEFINE_STATIC_LOCAL(const AtomicString, acceptScript, (\"*/*\", AtomicString::ConstructFromLiteral));\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    : TextResource(resourceRequest, Script, \"application/javascript\", charset), m_integrityChecked(false)"
            ],
            "added_lines": [
                "    : TextResource(resourceRequest, Script, \"application/javascript\", charset), m_integrityDisposition(ScriptIntegrityDisposition::NotChecked)"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0846",
        "func_name": "android/BpMemory::getMemory",
        "description": "libs/binder/IMemory.cpp in the IMemory Native Interface in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 does not properly consider the heap size, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 26877992.",
        "git_url": "https://android.googlesource.com/platform/frameworks/native/+/f3199c228aced7858b75a8070b8358c155ae0149",
        "commit_title": "Sanity check IMemory access versus underlying mmap",
        "commit_text": " Bug 26877992  ",
        "func_before": "sp<IMemoryHeap> BpMemory::getMemory(ssize_t* offset, size_t* size) const\n{\n    if (mHeap == 0) {\n        Parcel data, reply;\n        data.writeInterfaceToken(IMemory::getInterfaceDescriptor());\n        if (remote()->transact(GET_MEMORY, data, &reply) == NO_ERROR) {\n            sp<IBinder> heap = reply.readStrongBinder();\n            ssize_t o = reply.readInt32();\n            size_t s = reply.readInt32();\n            if (heap != 0) {\n                mHeap = interface_cast<IMemoryHeap>(heap);\n                if (mHeap != 0) {\n                    mOffset = o;\n                    mSize = s;\n                }\n            }\n        }\n    }\n    if (offset) *offset = mOffset;\n    if (size) *size = mSize;\n    return mHeap;\n}",
        "func": "sp<IMemoryHeap> BpMemory::getMemory(ssize_t* offset, size_t* size) const\n{\n    if (mHeap == 0) {\n        Parcel data, reply;\n        data.writeInterfaceToken(IMemory::getInterfaceDescriptor());\n        if (remote()->transact(GET_MEMORY, data, &reply) == NO_ERROR) {\n            sp<IBinder> heap = reply.readStrongBinder();\n            ssize_t o = reply.readInt32();\n            size_t s = reply.readInt32();\n            if (heap != 0) {\n                mHeap = interface_cast<IMemoryHeap>(heap);\n                if (mHeap != 0) {\n                    size_t heapSize = mHeap->getSize();\n                    if (s <= heapSize\n                            && o >= 0\n                            && (static_cast<size_t>(o) <= heapSize - s)) {\n                        mOffset = o;\n                        mSize = s;\n                    } else {\n                        // Hm.\n                        android_errorWriteWithInfoLog(0x534e4554,\n                            \"26877992\", -1, NULL, 0);\n                        mOffset = 0;\n                        mSize = 0;\n                    }\n                }\n            }\n        }\n    }\n    if (offset) *offset = mOffset;\n    if (size) *size = mSize;\n    return (mSize > 0) ? mHeap : 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,13 +10,24 @@\n             if (heap != 0) {\n                 mHeap = interface_cast<IMemoryHeap>(heap);\n                 if (mHeap != 0) {\n-                    mOffset = o;\n-                    mSize = s;\n+                    size_t heapSize = mHeap->getSize();\n+                    if (s <= heapSize\n+                            && o >= 0\n+                            && (static_cast<size_t>(o) <= heapSize - s)) {\n+                        mOffset = o;\n+                        mSize = s;\n+                    } else {\n+                        // Hm.\n+                        android_errorWriteWithInfoLog(0x534e4554,\n+                            \"26877992\", -1, NULL, 0);\n+                        mOffset = 0;\n+                        mSize = 0;\n+                    }\n                 }\n             }\n         }\n     }\n     if (offset) *offset = mOffset;\n     if (size) *size = mSize;\n-    return mHeap;\n+    return (mSize > 0) ? mHeap : 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "                    mOffset = o;",
                "                    mSize = s;",
                "    return mHeap;"
            ],
            "added_lines": [
                "                    size_t heapSize = mHeap->getSize();",
                "                    if (s <= heapSize",
                "                            && o >= 0",
                "                            && (static_cast<size_t>(o) <= heapSize - s)) {",
                "                        mOffset = o;",
                "                        mSize = s;",
                "                    } else {",
                "                        // Hm.",
                "                        android_errorWriteWithInfoLog(0x534e4554,",
                "                            \"26877992\", -1, NULL, 0);",
                "                        mOffset = 0;",
                "                        mSize = 0;",
                "                    }",
                "    return (mSize > 0) ? mHeap : 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0850",
        "func_name": "android/btm_sec_pin_code_request",
        "description": "The PORCHE_PAIRING_CONFLICT feature in Bluetooth in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 allows remote attackers to bypass intended pairing restrictions via a crafted device, aka internal bug 26551752.",
        "git_url": "https://android.googlesource.com/platform/external/bluetooth/bluedroid/+/c677ee92595335233eb0e7b59809a1a94e7a678a",
        "commit_title": "DO NOT MERGE Remove Porsche car-kit pairing workaround",
        "commit_text": " Bug: 26551752 ",
        "func_before": "void btm_sec_pin_code_request (UINT8 *p_bda)\n{\n    tBTM_SEC_DEV_REC *p_dev_rec;\n    tBTM_CB          *p_cb = &btm_cb;\n\n#ifdef PORCHE_PAIRING_CONFLICT\n    UINT8 default_pin_code_len = 4;\n    PIN_CODE default_pin_code = {0x30, 0x30, 0x30, 0x30};\n#endif\n    BTM_TRACE_EVENT (\"btm_sec_pin_code_request()  State: %s, BDA:%04x%08x\",\n                      btm_pair_state_descr(btm_cb.pairing_state),\n                      (p_bda[0]<<8)+p_bda[1], (p_bda[2]<<24)+(p_bda[3]<<16)+(p_bda[4]<<8)+p_bda[5] );\n\n    if (btm_cb.pairing_state != BTM_PAIR_STATE_IDLE)\n    {\n        if ( (memcmp (p_bda, btm_cb.pairing_bda, BD_ADDR_LEN) == 0)  &&\n             (btm_cb.pairing_state == BTM_PAIR_STATE_WAIT_AUTH_COMPLETE) )\n        {\n             /* fake this out - porshe carkit issue - */\n//            btm_cb.pairing_state = BTM_PAIR_STATE_IDLE;\n             if(! btm_cb.pin_code_len_saved)\n             {\n                 btsnd_hcic_pin_code_neg_reply (p_bda);\n                 return;\n             }\n             else\n             {\n                 btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len_saved, p_cb->pin_code);\n      \t         return;\n             }\n        }\n        else if ((btm_cb.pairing_state != BTM_PAIR_STATE_WAIT_PIN_REQ)\n                 || memcmp (p_bda, btm_cb.pairing_bda, BD_ADDR_LEN) != 0)\n        {\n            BTM_TRACE_WARNING (\"btm_sec_pin_code_request() rejected - state: %s\",\n                                btm_pair_state_descr(btm_cb.pairing_state));\n\n#ifdef PORCHE_PAIRING_CONFLICT\n            /* reply pin code again due to counter in_rand when local initiates pairing */\n            BTM_TRACE_EVENT (\"btm_sec_pin_code_request from remote dev. for local initiated pairing\");\n            if(! btm_cb.pin_code_len_saved)\n            {\n                btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n                btsnd_hcic_pin_code_req_reply (p_bda, default_pin_code_len, default_pin_code);\n            }\n            else\n            {\n                btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n                btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len_saved, p_cb->pin_code);\n            }\n#else\n            btsnd_hcic_pin_code_neg_reply (p_bda);\n#endif\n            return;\n        }\n    }\n\n    p_dev_rec = btm_find_or_alloc_dev (p_bda);\n    /* received PIN code request. must be non-sm4 */\n    p_dev_rec->sm4 = BTM_SM4_KNOWN;\n\n    if (btm_cb.pairing_state == BTM_PAIR_STATE_IDLE)\n    {\n        memcpy (btm_cb.pairing_bda, p_bda, BD_ADDR_LEN);\n\n        btm_cb.pairing_flags = BTM_PAIR_FLAGS_PEER_STARTED_DD;\n        /* Make sure we reset the trusted mask to help against attacks */\n        BTM_SEC_CLR_TRUSTED_DEVICE(p_dev_rec->trusted_mask);\n    }\n\n    if (!p_cb->pairing_disabled && (p_cb->cfg.pin_type == HCI_PIN_TYPE_FIXED))\n    {\n        BTM_TRACE_EVENT (\"btm_sec_pin_code_request fixed pin replying\");\n        btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n        btsnd_hcic_pin_code_req_reply (p_bda, p_cb->cfg.pin_code_len, p_cb->cfg.pin_code);\n        return;\n    }\n\n    /* Use the connecting device's CoD for the connection */\n    if ( (!memcmp (p_bda, p_cb->connecting_bda, BD_ADDR_LEN))\n         &&  (p_cb->connecting_dc[0] || p_cb->connecting_dc[1] || p_cb->connecting_dc[2]) )\n        memcpy (p_dev_rec->dev_class, p_cb->connecting_dc, DEV_CLASS_LEN);\n\n    /* We could have started connection after asking user for the PIN code */\n    if (btm_cb.pin_code_len != 0)\n    {\n        BTM_TRACE_EVENT (\"btm_sec_pin_code_request bonding sending reply\");\n        btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len, p_cb->pin_code);\n\n#ifdef PORCHE_PAIRING_CONFLICT\n        btm_cb.pin_code_len_saved = btm_cb.pin_code_len;\n#endif\n\n        /* Mark that we forwarded received from the user PIN code */\n        btm_cb.pin_code_len = 0;\n\n        /* We can change mode back right away, that other connection being established */\n        /* is not forced to be secure - found a FW issue, so we can not do this\n        btm_restore_mode(); */\n\n        btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n    }\n\n    /* If pairing disabled OR (no PIN callback and not bonding) */\n    /* OR we could not allocate entry in the database reject pairing request */\n    else if (p_cb->pairing_disabled\n             || (p_cb->api.p_pin_callback == NULL)\n\n             /* OR Microsoft keyboard can for some reason try to establish connection */\n             /*  the only thing we can do here is to shut it up.  Normally we will be originator */\n             /*  for keyboard bonding */\n             || (!p_dev_rec->is_originator\n                 && ((p_dev_rec->dev_class[1] & BTM_COD_MAJOR_CLASS_MASK) == BTM_COD_MAJOR_PERIPHERAL)\n                 &&  (p_dev_rec->dev_class[2] & BTM_COD_MINOR_KEYBOARD)) )\n    {\n        BTM_TRACE_WARNING(\"btm_sec_pin_code_request(): Pairing disabled:%d; PIN callback:%x, Dev Rec:%x!\",\n                           p_cb->pairing_disabled, p_cb->api.p_pin_callback, p_dev_rec);\n\n        btsnd_hcic_pin_code_neg_reply (p_bda);\n    }\n    /* Notify upper layer of PIN request and start expiration timer */\n    else\n    {\n        btm_cb.pin_code_len_saved = 0;\n        btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_LOCAL_PIN);\n        /* Pin code request can not come at the same time as connection request */\n        memcpy (p_cb->connecting_bda, p_bda, BD_ADDR_LEN);\n        memcpy (p_cb->connecting_dc,  p_dev_rec->dev_class, DEV_CLASS_LEN);\n\n        /* Check if the name is known */\n        /* Even if name is not known we might not be able to get one */\n        /* this is the case when we are already getting something from the */\n        /* device, so HCI level is flow controlled */\n        /* Also cannot send remote name request while paging, i.e. connection is not completed */\n        if (p_dev_rec->sec_flags & BTM_SEC_NAME_KNOWN)\n        {\n            BTM_TRACE_EVENT (\"btm_sec_pin_code_request going for callback\");\n\n            btm_cb.pairing_flags |= BTM_PAIR_FLAGS_PIN_REQD;\n            if (p_cb->api.p_pin_callback)\n                (*p_cb->api.p_pin_callback) (p_bda, p_dev_rec->dev_class, p_dev_rec->sec_bd_name);\n        }\n        else\n        {\n            BTM_TRACE_EVENT (\"btm_sec_pin_code_request going for remote name\");\n\n            /* We received PIN code request for the device with unknown name */\n            /* it is not user friendly just to ask for the PIN without name */\n            /* try to get name at first */\n            if (!btsnd_hcic_rmt_name_req (p_dev_rec->bd_addr,\n                                          HCI_PAGE_SCAN_REP_MODE_R1,\n                                          HCI_MANDATARY_PAGE_SCAN_MODE, 0))\n            {\n                p_dev_rec->sec_flags |= BTM_SEC_NAME_KNOWN;\n                p_dev_rec->sec_bd_name[0] = 'f';\n                p_dev_rec->sec_bd_name[1] = '0';\n                BTM_TRACE_ERROR (\"can not send rmt_name_req?? fake a name and call callback\");\n\n                btm_cb.pairing_flags |= BTM_PAIR_FLAGS_PIN_REQD;\n                if (p_cb->api.p_pin_callback)\n                    (*p_cb->api.p_pin_callback) (p_bda, p_dev_rec->dev_class, p_dev_rec->sec_bd_name);\n            }\n        }\n    }\n\n    return;\n}",
        "func": "void btm_sec_pin_code_request (UINT8 *p_bda)\n{\n    tBTM_SEC_DEV_REC *p_dev_rec;\n    tBTM_CB          *p_cb = &btm_cb;\n\n    BTM_TRACE_EVENT (\"btm_sec_pin_code_request()  State: %s, BDA:%04x%08x\",\n                      btm_pair_state_descr(btm_cb.pairing_state),\n                      (p_bda[0]<<8)+p_bda[1], (p_bda[2]<<24)+(p_bda[3]<<16)+(p_bda[4]<<8)+p_bda[5] );\n\n    if (btm_cb.pairing_state != BTM_PAIR_STATE_IDLE)\n    {\n        if ( (memcmp (p_bda, btm_cb.pairing_bda, BD_ADDR_LEN) == 0)  &&\n             (btm_cb.pairing_state == BTM_PAIR_STATE_WAIT_AUTH_COMPLETE) )\n        {\n             btsnd_hcic_pin_code_neg_reply (p_bda);\n             return;\n        }\n        else if ((btm_cb.pairing_state != BTM_PAIR_STATE_WAIT_PIN_REQ)\n                 || memcmp (p_bda, btm_cb.pairing_bda, BD_ADDR_LEN) != 0)\n        {\n            BTM_TRACE_WARNING (\"btm_sec_pin_code_request() rejected - state: %s\",\n                                btm_pair_state_descr(btm_cb.pairing_state));\n\n            btsnd_hcic_pin_code_neg_reply (p_bda);\n            return;\n        }\n    }\n\n    p_dev_rec = btm_find_or_alloc_dev (p_bda);\n    /* received PIN code request. must be non-sm4 */\n    p_dev_rec->sm4 = BTM_SM4_KNOWN;\n\n    if (btm_cb.pairing_state == BTM_PAIR_STATE_IDLE)\n    {\n        memcpy (btm_cb.pairing_bda, p_bda, BD_ADDR_LEN);\n\n        btm_cb.pairing_flags = BTM_PAIR_FLAGS_PEER_STARTED_DD;\n        /* Make sure we reset the trusted mask to help against attacks */\n        BTM_SEC_CLR_TRUSTED_DEVICE(p_dev_rec->trusted_mask);\n    }\n\n    if (!p_cb->pairing_disabled && (p_cb->cfg.pin_type == HCI_PIN_TYPE_FIXED))\n    {\n        BTM_TRACE_EVENT (\"btm_sec_pin_code_request fixed pin replying\");\n        btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n        btsnd_hcic_pin_code_req_reply (p_bda, p_cb->cfg.pin_code_len, p_cb->cfg.pin_code);\n        return;\n    }\n\n    /* Use the connecting device's CoD for the connection */\n    if ( (!memcmp (p_bda, p_cb->connecting_bda, BD_ADDR_LEN))\n         &&  (p_cb->connecting_dc[0] || p_cb->connecting_dc[1] || p_cb->connecting_dc[2]) )\n        memcpy (p_dev_rec->dev_class, p_cb->connecting_dc, DEV_CLASS_LEN);\n\n    /* We could have started connection after asking user for the PIN code */\n    if (btm_cb.pin_code_len != 0)\n    {\n        BTM_TRACE_EVENT (\"btm_sec_pin_code_request bonding sending reply\");\n        btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len, p_cb->pin_code);\n\n        /* Mark that we forwarded received from the user PIN code */\n        btm_cb.pin_code_len = 0;\n\n        /* We can change mode back right away, that other connection being established */\n        /* is not forced to be secure - found a FW issue, so we can not do this\n        btm_restore_mode(); */\n\n        btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n    }\n\n    /* If pairing disabled OR (no PIN callback and not bonding) */\n    /* OR we could not allocate entry in the database reject pairing request */\n    else if (p_cb->pairing_disabled\n             || (p_cb->api.p_pin_callback == NULL)\n\n             /* OR Microsoft keyboard can for some reason try to establish connection */\n             /*  the only thing we can do here is to shut it up.  Normally we will be originator */\n             /*  for keyboard bonding */\n             || (!p_dev_rec->is_originator\n                 && ((p_dev_rec->dev_class[1] & BTM_COD_MAJOR_CLASS_MASK) == BTM_COD_MAJOR_PERIPHERAL)\n                 &&  (p_dev_rec->dev_class[2] & BTM_COD_MINOR_KEYBOARD)) )\n    {\n        BTM_TRACE_WARNING(\"btm_sec_pin_code_request(): Pairing disabled:%d; PIN callback:%x, Dev Rec:%x!\",\n                           p_cb->pairing_disabled, p_cb->api.p_pin_callback, p_dev_rec);\n\n        btsnd_hcic_pin_code_neg_reply (p_bda);\n    }\n    /* Notify upper layer of PIN request and start expiration timer */\n    else\n    {\n        btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_LOCAL_PIN);\n        /* Pin code request can not come at the same time as connection request */\n        memcpy (p_cb->connecting_bda, p_bda, BD_ADDR_LEN);\n        memcpy (p_cb->connecting_dc,  p_dev_rec->dev_class, DEV_CLASS_LEN);\n\n        /* Check if the name is known */\n        /* Even if name is not known we might not be able to get one */\n        /* this is the case when we are already getting something from the */\n        /* device, so HCI level is flow controlled */\n        /* Also cannot send remote name request while paging, i.e. connection is not completed */\n        if (p_dev_rec->sec_flags & BTM_SEC_NAME_KNOWN)\n        {\n            BTM_TRACE_EVENT (\"btm_sec_pin_code_request going for callback\");\n\n            btm_cb.pairing_flags |= BTM_PAIR_FLAGS_PIN_REQD;\n            if (p_cb->api.p_pin_callback)\n                (*p_cb->api.p_pin_callback) (p_bda, p_dev_rec->dev_class, p_dev_rec->sec_bd_name);\n        }\n        else\n        {\n            BTM_TRACE_EVENT (\"btm_sec_pin_code_request going for remote name\");\n\n            /* We received PIN code request for the device with unknown name */\n            /* it is not user friendly just to ask for the PIN without name */\n            /* try to get name at first */\n            if (!btsnd_hcic_rmt_name_req (p_dev_rec->bd_addr,\n                                          HCI_PAGE_SCAN_REP_MODE_R1,\n                                          HCI_MANDATARY_PAGE_SCAN_MODE, 0))\n            {\n                p_dev_rec->sec_flags |= BTM_SEC_NAME_KNOWN;\n                p_dev_rec->sec_bd_name[0] = 'f';\n                p_dev_rec->sec_bd_name[1] = '0';\n                BTM_TRACE_ERROR (\"can not send rmt_name_req?? fake a name and call callback\");\n\n                btm_cb.pairing_flags |= BTM_PAIR_FLAGS_PIN_REQD;\n                if (p_cb->api.p_pin_callback)\n                    (*p_cb->api.p_pin_callback) (p_bda, p_dev_rec->dev_class, p_dev_rec->sec_bd_name);\n            }\n        }\n    }\n\n    return;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,10 +3,6 @@\n     tBTM_SEC_DEV_REC *p_dev_rec;\n     tBTM_CB          *p_cb = &btm_cb;\n \n-#ifdef PORCHE_PAIRING_CONFLICT\n-    UINT8 default_pin_code_len = 4;\n-    PIN_CODE default_pin_code = {0x30, 0x30, 0x30, 0x30};\n-#endif\n     BTM_TRACE_EVENT (\"btm_sec_pin_code_request()  State: %s, BDA:%04x%08x\",\n                       btm_pair_state_descr(btm_cb.pairing_state),\n                       (p_bda[0]<<8)+p_bda[1], (p_bda[2]<<24)+(p_bda[3]<<16)+(p_bda[4]<<8)+p_bda[5] );\n@@ -16,18 +12,8 @@\n         if ( (memcmp (p_bda, btm_cb.pairing_bda, BD_ADDR_LEN) == 0)  &&\n              (btm_cb.pairing_state == BTM_PAIR_STATE_WAIT_AUTH_COMPLETE) )\n         {\n-             /* fake this out - porshe carkit issue - */\n-//            btm_cb.pairing_state = BTM_PAIR_STATE_IDLE;\n-             if(! btm_cb.pin_code_len_saved)\n-             {\n-                 btsnd_hcic_pin_code_neg_reply (p_bda);\n-                 return;\n-             }\n-             else\n-             {\n-                 btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len_saved, p_cb->pin_code);\n-      \t         return;\n-             }\n+             btsnd_hcic_pin_code_neg_reply (p_bda);\n+             return;\n         }\n         else if ((btm_cb.pairing_state != BTM_PAIR_STATE_WAIT_PIN_REQ)\n                  || memcmp (p_bda, btm_cb.pairing_bda, BD_ADDR_LEN) != 0)\n@@ -35,22 +21,7 @@\n             BTM_TRACE_WARNING (\"btm_sec_pin_code_request() rejected - state: %s\",\n                                 btm_pair_state_descr(btm_cb.pairing_state));\n \n-#ifdef PORCHE_PAIRING_CONFLICT\n-            /* reply pin code again due to counter in_rand when local initiates pairing */\n-            BTM_TRACE_EVENT (\"btm_sec_pin_code_request from remote dev. for local initiated pairing\");\n-            if(! btm_cb.pin_code_len_saved)\n-            {\n-                btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n-                btsnd_hcic_pin_code_req_reply (p_bda, default_pin_code_len, default_pin_code);\n-            }\n-            else\n-            {\n-                btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n-                btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len_saved, p_cb->pin_code);\n-            }\n-#else\n             btsnd_hcic_pin_code_neg_reply (p_bda);\n-#endif\n             return;\n         }\n     }\n@@ -87,10 +58,6 @@\n         BTM_TRACE_EVENT (\"btm_sec_pin_code_request bonding sending reply\");\n         btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len, p_cb->pin_code);\n \n-#ifdef PORCHE_PAIRING_CONFLICT\n-        btm_cb.pin_code_len_saved = btm_cb.pin_code_len;\n-#endif\n-\n         /* Mark that we forwarded received from the user PIN code */\n         btm_cb.pin_code_len = 0;\n \n@@ -121,7 +88,6 @@\n     /* Notify upper layer of PIN request and start expiration timer */\n     else\n     {\n-        btm_cb.pin_code_len_saved = 0;\n         btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_LOCAL_PIN);\n         /* Pin code request can not come at the same time as connection request */\n         memcpy (p_cb->connecting_bda, p_bda, BD_ADDR_LEN);",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef PORCHE_PAIRING_CONFLICT",
                "    UINT8 default_pin_code_len = 4;",
                "    PIN_CODE default_pin_code = {0x30, 0x30, 0x30, 0x30};",
                "#endif",
                "             /* fake this out - porshe carkit issue - */",
                "//            btm_cb.pairing_state = BTM_PAIR_STATE_IDLE;",
                "             if(! btm_cb.pin_code_len_saved)",
                "             {",
                "                 btsnd_hcic_pin_code_neg_reply (p_bda);",
                "                 return;",
                "             }",
                "             else",
                "             {",
                "                 btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len_saved, p_cb->pin_code);",
                "      \t         return;",
                "             }",
                "#ifdef PORCHE_PAIRING_CONFLICT",
                "            /* reply pin code again due to counter in_rand when local initiates pairing */",
                "            BTM_TRACE_EVENT (\"btm_sec_pin_code_request from remote dev. for local initiated pairing\");",
                "            if(! btm_cb.pin_code_len_saved)",
                "            {",
                "                btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);",
                "                btsnd_hcic_pin_code_req_reply (p_bda, default_pin_code_len, default_pin_code);",
                "            }",
                "            else",
                "            {",
                "                btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);",
                "                btsnd_hcic_pin_code_req_reply (p_bda, btm_cb.pin_code_len_saved, p_cb->pin_code);",
                "            }",
                "#else",
                "#endif",
                "#ifdef PORCHE_PAIRING_CONFLICT",
                "        btm_cb.pin_code_len_saved = btm_cb.pin_code_len;",
                "#endif",
                "",
                "        btm_cb.pin_code_len_saved = 0;"
            ],
            "added_lines": [
                "             btsnd_hcic_pin_code_neg_reply (p_bda);",
                "             return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0850",
        "func_name": "android/BTM_PINCodeReply",
        "description": "The PORCHE_PAIRING_CONFLICT feature in Bluetooth in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 allows remote attackers to bypass intended pairing restrictions via a crafted device, aka internal bug 26551752.",
        "git_url": "https://android.googlesource.com/platform/external/bluetooth/bluedroid/+/c677ee92595335233eb0e7b59809a1a94e7a678a",
        "commit_title": "DO NOT MERGE Remove Porsche car-kit pairing workaround",
        "commit_text": " Bug: 26551752 ",
        "func_before": "void BTM_PINCodeReply (BD_ADDR bd_addr, UINT8 res, UINT8 pin_len, UINT8 *p_pin, UINT32 trusted_mask[])\n{\n    tBTM_SEC_DEV_REC *p_dev_rec;\n\n    BTM_TRACE_API (\"BTM_PINCodeReply(): PairState: %s   PairFlags: 0x%02x  PinLen:%d  Result:%d\",\n                    btm_pair_state_descr(btm_cb.pairing_state), btm_cb.pairing_flags, pin_len, res);\n\n    /* If timeout already expired or has been canceled, ignore the reply */\n    if (btm_cb.pairing_state != BTM_PAIR_STATE_WAIT_LOCAL_PIN)\n    {\n        BTM_TRACE_WARNING (\"BTM_PINCodeReply() - Wrong State: %d\", btm_cb.pairing_state);\n        return;\n    }\n\n    if (memcmp (bd_addr, btm_cb.pairing_bda, BD_ADDR_LEN) != 0)\n    {\n        BTM_TRACE_ERROR (\"BTM_PINCodeReply() - Wrong BD Addr\");\n        return;\n    }\n\n    if ((p_dev_rec = btm_find_dev (bd_addr)) == NULL)\n    {\n        BTM_TRACE_ERROR (\"BTM_PINCodeReply() - no dev CB\");\n        return;\n    }\n\n    if ( (pin_len > PIN_CODE_LEN) || (pin_len == 0) || (p_pin == NULL) )\n        res = BTM_ILLEGAL_VALUE;\n\n    if (res != BTM_SUCCESS)\n    {\n        /* if peer started dd OR we started dd and pre-fetch pin was not used send negative reply */\n        if ((btm_cb.pairing_flags & BTM_PAIR_FLAGS_PEER_STARTED_DD) ||\n            ((btm_cb.pairing_flags & BTM_PAIR_FLAGS_WE_STARTED_DD) &&\n            (btm_cb.pairing_flags & BTM_PAIR_FLAGS_DISC_WHEN_DONE)) )\n        {\n            /* use BTM_PAIR_STATE_WAIT_AUTH_COMPLETE to report authentication failed event */\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n            btm_cb.acl_disc_reason = HCI_ERR_HOST_REJECT_SECURITY;\n\n            btsnd_hcic_pin_code_neg_reply (bd_addr);\n        }\n        else\n        {\n            p_dev_rec->security_required = BTM_SEC_NONE;\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_IDLE);\n        }\n        return;\n    }\n    if (trusted_mask)\n        BTM_SEC_COPY_TRUSTED_DEVICE(trusted_mask, p_dev_rec->trusted_mask);\n    p_dev_rec->sec_flags   |= BTM_SEC_LINK_KEY_AUTHED;\n\n    if ( (btm_cb.pairing_flags & BTM_PAIR_FLAGS_WE_STARTED_DD)\n         &&  (p_dev_rec->hci_handle == BTM_SEC_INVALID_HANDLE)\n         &&  (btm_cb.security_mode_changed == FALSE) )\n    {\n        /* This is start of the dedicated bonding if local device is 2.0 */\n        btm_cb.pin_code_len = pin_len;\n        memcpy (btm_cb.pin_code, p_pin, pin_len);\n\n        btm_cb.security_mode_changed = TRUE;\n#ifdef APPL_AUTH_WRITE_EXCEPTION\n        if(!(APPL_AUTH_WRITE_EXCEPTION)(p_dev_rec->bd_addr))\n#endif\n        btsnd_hcic_write_auth_enable (TRUE);\n\n        btm_cb.acl_disc_reason = 0xff ;\n\n        /* if we rejected incoming connection request, we have to wait HCI_Connection_Complete event */\n        /*  before originating  */\n        if (btm_cb.pairing_flags & BTM_PAIR_FLAGS_REJECTED_CONNECT)\n        {\n            BTM_TRACE_WARNING (\"BTM_PINCodeReply(): waiting HCI_Connection_Complete after rejected incoming connection\");\n            /* we change state little bit early so btm_sec_connected() will originate connection */\n            /*   when existing ACL link is down completely */\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_PIN_REQ);\n        }\n        /* if we already accepted incoming connection from pairing device */\n        else if (p_dev_rec->sm4 & BTM_SM4_CONN_PEND)\n        {\n            BTM_TRACE_WARNING (\"BTM_PINCodeReply(): link is connecting so wait pin code request from peer\");\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_PIN_REQ);\n        }\n        else if (btm_sec_dd_create_conn(p_dev_rec) != BTM_CMD_STARTED)\n        {\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_IDLE);\n            p_dev_rec->sec_flags &= ~BTM_SEC_LINK_KEY_AUTHED;\n\n            if (btm_cb.api.p_auth_complete_callback)\n                (*btm_cb.api.p_auth_complete_callback) (p_dev_rec->bd_addr,  p_dev_rec->dev_class,\n                                                    p_dev_rec->sec_bd_name, HCI_ERR_AUTH_FAILURE);\n        }\n        return;\n    }\n\n    btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n    btm_cb.acl_disc_reason = HCI_SUCCESS;\n\n#ifdef PORCHE_PAIRING_CONFLICT\n    BTM_TRACE_EVENT(\"BTM_PINCodeReply(): Saving pin_len: %d btm_cb.pin_code_len: %d\", pin_len, btm_cb.pin_code_len);\n    /* if this was not pre-fetched, save the PIN */\n    if (btm_cb.pin_code_len == 0)\n        memcpy (btm_cb.pin_code, p_pin, pin_len);\n    btm_cb.pin_code_len_saved = pin_len;\n#endif\n    btsnd_hcic_pin_code_req_reply (bd_addr, pin_len, p_pin);\n}",
        "func": "void BTM_PINCodeReply (BD_ADDR bd_addr, UINT8 res, UINT8 pin_len, UINT8 *p_pin, UINT32 trusted_mask[])\n{\n    tBTM_SEC_DEV_REC *p_dev_rec;\n\n    BTM_TRACE_API (\"BTM_PINCodeReply(): PairState: %s   PairFlags: 0x%02x  PinLen:%d  Result:%d\",\n                    btm_pair_state_descr(btm_cb.pairing_state), btm_cb.pairing_flags, pin_len, res);\n\n    /* If timeout already expired or has been canceled, ignore the reply */\n    if (btm_cb.pairing_state != BTM_PAIR_STATE_WAIT_LOCAL_PIN)\n    {\n        BTM_TRACE_WARNING (\"BTM_PINCodeReply() - Wrong State: %d\", btm_cb.pairing_state);\n        return;\n    }\n\n    if (memcmp (bd_addr, btm_cb.pairing_bda, BD_ADDR_LEN) != 0)\n    {\n        BTM_TRACE_ERROR (\"BTM_PINCodeReply() - Wrong BD Addr\");\n        return;\n    }\n\n    if ((p_dev_rec = btm_find_dev (bd_addr)) == NULL)\n    {\n        BTM_TRACE_ERROR (\"BTM_PINCodeReply() - no dev CB\");\n        return;\n    }\n\n    if ( (pin_len > PIN_CODE_LEN) || (pin_len == 0) || (p_pin == NULL) )\n        res = BTM_ILLEGAL_VALUE;\n\n    if (res != BTM_SUCCESS)\n    {\n        /* if peer started dd OR we started dd and pre-fetch pin was not used send negative reply */\n        if ((btm_cb.pairing_flags & BTM_PAIR_FLAGS_PEER_STARTED_DD) ||\n            ((btm_cb.pairing_flags & BTM_PAIR_FLAGS_WE_STARTED_DD) &&\n            (btm_cb.pairing_flags & BTM_PAIR_FLAGS_DISC_WHEN_DONE)) )\n        {\n            /* use BTM_PAIR_STATE_WAIT_AUTH_COMPLETE to report authentication failed event */\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n            btm_cb.acl_disc_reason = HCI_ERR_HOST_REJECT_SECURITY;\n\n            btsnd_hcic_pin_code_neg_reply (bd_addr);\n        }\n        else\n        {\n            p_dev_rec->security_required = BTM_SEC_NONE;\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_IDLE);\n        }\n        return;\n    }\n    if (trusted_mask)\n        BTM_SEC_COPY_TRUSTED_DEVICE(trusted_mask, p_dev_rec->trusted_mask);\n    p_dev_rec->sec_flags   |= BTM_SEC_LINK_KEY_AUTHED;\n\n    if ( (btm_cb.pairing_flags & BTM_PAIR_FLAGS_WE_STARTED_DD)\n         &&  (p_dev_rec->hci_handle == BTM_SEC_INVALID_HANDLE)\n         &&  (btm_cb.security_mode_changed == FALSE) )\n    {\n        /* This is start of the dedicated bonding if local device is 2.0 */\n        btm_cb.pin_code_len = pin_len;\n        memcpy (btm_cb.pin_code, p_pin, pin_len);\n\n        btm_cb.security_mode_changed = TRUE;\n#ifdef APPL_AUTH_WRITE_EXCEPTION\n        if(!(APPL_AUTH_WRITE_EXCEPTION)(p_dev_rec->bd_addr))\n#endif\n        btsnd_hcic_write_auth_enable (TRUE);\n\n        btm_cb.acl_disc_reason = 0xff ;\n\n        /* if we rejected incoming connection request, we have to wait HCI_Connection_Complete event */\n        /*  before originating  */\n        if (btm_cb.pairing_flags & BTM_PAIR_FLAGS_REJECTED_CONNECT)\n        {\n            BTM_TRACE_WARNING (\"BTM_PINCodeReply(): waiting HCI_Connection_Complete after rejected incoming connection\");\n            /* we change state little bit early so btm_sec_connected() will originate connection */\n            /*   when existing ACL link is down completely */\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_PIN_REQ);\n        }\n        /* if we already accepted incoming connection from pairing device */\n        else if (p_dev_rec->sm4 & BTM_SM4_CONN_PEND)\n        {\n            BTM_TRACE_WARNING (\"BTM_PINCodeReply(): link is connecting so wait pin code request from peer\");\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_PIN_REQ);\n        }\n        else if (btm_sec_dd_create_conn(p_dev_rec) != BTM_CMD_STARTED)\n        {\n            btm_sec_change_pairing_state (BTM_PAIR_STATE_IDLE);\n            p_dev_rec->sec_flags &= ~BTM_SEC_LINK_KEY_AUTHED;\n\n            if (btm_cb.api.p_auth_complete_callback)\n                (*btm_cb.api.p_auth_complete_callback) (p_dev_rec->bd_addr,  p_dev_rec->dev_class,\n                                                    p_dev_rec->sec_bd_name, HCI_ERR_AUTH_FAILURE);\n        }\n        return;\n    }\n\n    btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n    btm_cb.acl_disc_reason = HCI_SUCCESS;\n\n    btsnd_hcic_pin_code_req_reply (bd_addr, pin_len, p_pin);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -97,12 +97,5 @@\n     btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);\n     btm_cb.acl_disc_reason = HCI_SUCCESS;\n \n-#ifdef PORCHE_PAIRING_CONFLICT\n-    BTM_TRACE_EVENT(\"BTM_PINCodeReply(): Saving pin_len: %d btm_cb.pin_code_len: %d\", pin_len, btm_cb.pin_code_len);\n-    /* if this was not pre-fetched, save the PIN */\n-    if (btm_cb.pin_code_len == 0)\n-        memcpy (btm_cb.pin_code, p_pin, pin_len);\n-    btm_cb.pin_code_len_saved = pin_len;\n-#endif\n     btsnd_hcic_pin_code_req_reply (bd_addr, pin_len, p_pin);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef PORCHE_PAIRING_CONFLICT",
                "    BTM_TRACE_EVENT(\"BTM_PINCodeReply(): Saving pin_len: %d btm_cb.pin_code_len: %d\", pin_len, btm_cb.pin_code_len);",
                "    /* if this was not pre-fetched, save the PIN */",
                "    if (btm_cb.pin_code_len == 0)",
                "        memcpy (btm_cb.pin_code, p_pin, pin_len);",
                "    btm_cb.pin_code_len_saved = pin_len;",
                "#endif"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2016-2413",
        "func_name": "android/BnOMX::onTransact",
        "description": "media/libmedia/IOMX.cpp in mediaserver in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 does not initialize a handle pointer, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 26403627.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/25be9ac20db51044e1b09ca67906355e4f328d48",
        "commit_title": "IOMX.cpp uninitialized pointer in BnOMX::onTransact",
        "commit_text": " This can lead to local code execution in media server. Fix initializes the pointer and checks the error conditions before returning  Bug: 26403627 ",
        "func_before": "status_t BnOMX::onTransact(\n    uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {\n    switch (code) {\n        case LIVES_LOCALLY:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n            node_id node = (node_id)data.readInt32();\n            pid_t pid = (pid_t)data.readInt32();\n            reply->writeInt32(livesLocally(node, pid));\n\n            return OK;\n        }\n\n        case LIST_NODES:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            List<ComponentInfo> list;\n            listNodes(&list);\n\n            reply->writeInt32(list.size());\n            for (List<ComponentInfo>::iterator it = list.begin();\n                 it != list.end(); ++it) {\n                ComponentInfo &cur = *it;\n\n                reply->writeString8(cur.mName);\n                reply->writeInt32(cur.mRoles.size());\n                for (List<String8>::iterator role_it = cur.mRoles.begin();\n                     role_it != cur.mRoles.end(); ++role_it) {\n                    reply->writeString8(*role_it);\n                }\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOCATE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            const char *name = data.readCString();\n\n            sp<IOMXObserver> observer =\n                interface_cast<IOMXObserver>(data.readStrongBinder());\n\n            node_id node;\n\n            status_t err = allocateNode(name, observer, &node);\n            reply->writeInt32(err);\n            if (err == OK) {\n                reply->writeInt32((int32_t)node);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            reply->writeInt32(freeNode(node));\n\n            return NO_ERROR;\n        }\n\n        case SEND_COMMAND:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            OMX_COMMANDTYPE cmd =\n                static_cast<OMX_COMMANDTYPE>(data.readInt32());\n\n            OMX_S32 param = data.readInt32();\n            reply->writeInt32(sendCommand(node, cmd, param));\n\n            return NO_ERROR;\n        }\n\n        case GET_PARAMETER:\n        case SET_PARAMETER:\n        case GET_CONFIG:\n        case SET_CONFIG:\n        case SET_INTERNAL_OPTION:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_INDEXTYPE index = static_cast<OMX_INDEXTYPE>(data.readInt32());\n\n            size_t size = data.readInt64();\n\n            void *params = malloc(size);\n            data.read(params, size);\n\n            status_t err;\n            switch (code) {\n                case GET_PARAMETER:\n                    err = getParameter(node, index, params, size);\n                    break;\n                case SET_PARAMETER:\n                    err = setParameter(node, index, params, size);\n                    break;\n                case GET_CONFIG:\n                    err = getConfig(node, index, params, size);\n                    break;\n                case SET_CONFIG:\n                    err = setConfig(node, index, params, size);\n                    break;\n                case SET_INTERNAL_OPTION:\n                {\n                    InternalOptionType type =\n                        (InternalOptionType)data.readInt32();\n\n                    err = setInternalOption(node, index, type, params, size);\n                    break;\n                }\n\n                default:\n                    TRESPASS();\n            }\n\n            reply->writeInt32(err);\n\n            if ((code == GET_PARAMETER || code == GET_CONFIG) && err == OK) {\n                reply->write(params, size);\n            }\n\n            free(params);\n            params = NULL;\n\n            return NO_ERROR;\n        }\n\n        case GET_STATE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_STATETYPE state = OMX_StateInvalid;\n\n            status_t err = getState(node, &state);\n            reply->writeInt32(state);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case ENABLE_GRAPHIC_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = enableGraphicBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case GET_GRAPHIC_BUFFER_USAGE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            OMX_U32 usage = 0;\n            status_t err = getGraphicBufferUsage(node, port_index, &usage);\n            reply->writeInt32(err);\n            reply->writeInt32(usage);\n\n            return NO_ERROR;\n        }\n\n        case USE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = useBuffer(node, port_index, params, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case USE_GRAPHIC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n\n            buffer_id buffer;\n            status_t err = useGraphicBuffer(\n                    node, port_index, graphicBuffer, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case UPDATE_GRAPHIC_BUFFER_IN_META:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n            buffer_id buffer = (buffer_id)data.readInt32();\n\n            status_t err = updateGraphicBufferInMeta(\n                    node, port_index, graphicBuffer, buffer);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CREATE_INPUT_SURFACE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            sp<IGraphicBufferProducer> bufferProducer;\n            status_t err = createInputSurface(node, port_index,\n                    &bufferProducer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeStrongBinder(bufferProducer->asBinder());\n            }\n\n            return NO_ERROR;\n        }\n\n        case SIGNAL_END_OF_INPUT_STREAM:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            status_t err = signalEndOfInputStream(node);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case STORE_META_DATA_IN_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = storeMetaDataInBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case PREPARE_FOR_ADAPTIVE_PLAYBACK:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n            OMX_U32 max_width = data.readInt32();\n            OMX_U32 max_height = data.readInt32();\n\n            status_t err = prepareForAdaptivePlayback(\n                    node, port_index, enable, max_width, max_height);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CONFIGURE_VIDEO_TUNNEL_MODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();\n            OMX_U32 audio_hw_sync = data.readInt32();\n\n            native_handle_t *sideband_handle;\n            status_t err = configureVideoTunnelMode(\n                    node, port_index, tunneled, audio_hw_sync, &sideband_handle);\n            reply->writeInt32(err);\n            reply->writeNativeHandle(sideband_handle);\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            if (!isSecure(node) || port_index != 0 /* kPortIndexInput */) {\n                ALOGE(\"b/24310423\");\n                reply->writeInt32(INVALID_OPERATION);\n                return NO_ERROR;\n            }\n\n            size_t size = data.readInt64();\n\n            buffer_id buffer;\n            void *buffer_data;\n            status_t err = allocateBuffer(\n                    node, port_index, size, &buffer, &buffer_data);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n                reply->writeInt64((uintptr_t)buffer_data);\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER_WITH_BACKUP:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = allocateBufferWithBackup(\n                    node, port_index, params, &buffer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(freeBuffer(node, port_index, buffer));\n\n            return NO_ERROR;\n        }\n\n        case FILL_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(fillBuffer(node, buffer));\n\n            return NO_ERROR;\n        }\n\n        case EMPTY_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            OMX_U32 range_offset = data.readInt32();\n            OMX_U32 range_length = data.readInt32();\n            OMX_U32 flags = data.readInt32();\n            OMX_TICKS timestamp = data.readInt64();\n\n            reply->writeInt32(\n                    emptyBuffer(\n                        node, buffer, range_offset, range_length,\n                        flags, timestamp));\n\n            return NO_ERROR;\n        }\n\n        case GET_EXTENSION_INDEX:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            const char *parameter_name = data.readCString();\n\n            OMX_INDEXTYPE index;\n            status_t err = getExtensionIndex(node, parameter_name, &index);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32(index);\n            }\n\n            return OK;\n        }\n\n        default:\n            return BBinder::onTransact(code, data, reply, flags);\n    }\n}",
        "func": "status_t BnOMX::onTransact(\n    uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {\n    switch (code) {\n        case LIVES_LOCALLY:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n            node_id node = (node_id)data.readInt32();\n            pid_t pid = (pid_t)data.readInt32();\n            reply->writeInt32(livesLocally(node, pid));\n\n            return OK;\n        }\n\n        case LIST_NODES:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            List<ComponentInfo> list;\n            listNodes(&list);\n\n            reply->writeInt32(list.size());\n            for (List<ComponentInfo>::iterator it = list.begin();\n                 it != list.end(); ++it) {\n                ComponentInfo &cur = *it;\n\n                reply->writeString8(cur.mName);\n                reply->writeInt32(cur.mRoles.size());\n                for (List<String8>::iterator role_it = cur.mRoles.begin();\n                     role_it != cur.mRoles.end(); ++role_it) {\n                    reply->writeString8(*role_it);\n                }\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOCATE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            const char *name = data.readCString();\n\n            sp<IOMXObserver> observer =\n                interface_cast<IOMXObserver>(data.readStrongBinder());\n\n            node_id node;\n\n            status_t err = allocateNode(name, observer, &node);\n            reply->writeInt32(err);\n            if (err == OK) {\n                reply->writeInt32((int32_t)node);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            reply->writeInt32(freeNode(node));\n\n            return NO_ERROR;\n        }\n\n        case SEND_COMMAND:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            OMX_COMMANDTYPE cmd =\n                static_cast<OMX_COMMANDTYPE>(data.readInt32());\n\n            OMX_S32 param = data.readInt32();\n            reply->writeInt32(sendCommand(node, cmd, param));\n\n            return NO_ERROR;\n        }\n\n        case GET_PARAMETER:\n        case SET_PARAMETER:\n        case GET_CONFIG:\n        case SET_CONFIG:\n        case SET_INTERNAL_OPTION:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_INDEXTYPE index = static_cast<OMX_INDEXTYPE>(data.readInt32());\n\n            size_t size = data.readInt64();\n\n            void *params = malloc(size);\n            data.read(params, size);\n\n            status_t err;\n            switch (code) {\n                case GET_PARAMETER:\n                    err = getParameter(node, index, params, size);\n                    break;\n                case SET_PARAMETER:\n                    err = setParameter(node, index, params, size);\n                    break;\n                case GET_CONFIG:\n                    err = getConfig(node, index, params, size);\n                    break;\n                case SET_CONFIG:\n                    err = setConfig(node, index, params, size);\n                    break;\n                case SET_INTERNAL_OPTION:\n                {\n                    InternalOptionType type =\n                        (InternalOptionType)data.readInt32();\n\n                    err = setInternalOption(node, index, type, params, size);\n                    break;\n                }\n\n                default:\n                    TRESPASS();\n            }\n\n            reply->writeInt32(err);\n\n            if ((code == GET_PARAMETER || code == GET_CONFIG) && err == OK) {\n                reply->write(params, size);\n            }\n\n            free(params);\n            params = NULL;\n\n            return NO_ERROR;\n        }\n\n        case GET_STATE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_STATETYPE state = OMX_StateInvalid;\n\n            status_t err = getState(node, &state);\n            reply->writeInt32(state);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case ENABLE_GRAPHIC_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = enableGraphicBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case GET_GRAPHIC_BUFFER_USAGE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            OMX_U32 usage = 0;\n            status_t err = getGraphicBufferUsage(node, port_index, &usage);\n            reply->writeInt32(err);\n            reply->writeInt32(usage);\n\n            return NO_ERROR;\n        }\n\n        case USE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = useBuffer(node, port_index, params, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case USE_GRAPHIC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n\n            buffer_id buffer;\n            status_t err = useGraphicBuffer(\n                    node, port_index, graphicBuffer, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case UPDATE_GRAPHIC_BUFFER_IN_META:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n            buffer_id buffer = (buffer_id)data.readInt32();\n\n            status_t err = updateGraphicBufferInMeta(\n                    node, port_index, graphicBuffer, buffer);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CREATE_INPUT_SURFACE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            sp<IGraphicBufferProducer> bufferProducer;\n            status_t err = createInputSurface(node, port_index,\n                    &bufferProducer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeStrongBinder(bufferProducer->asBinder());\n            }\n\n            return NO_ERROR;\n        }\n\n        case SIGNAL_END_OF_INPUT_STREAM:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            status_t err = signalEndOfInputStream(node);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case STORE_META_DATA_IN_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = storeMetaDataInBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case PREPARE_FOR_ADAPTIVE_PLAYBACK:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n            OMX_U32 max_width = data.readInt32();\n            OMX_U32 max_height = data.readInt32();\n\n            status_t err = prepareForAdaptivePlayback(\n                    node, port_index, enable, max_width, max_height);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CONFIGURE_VIDEO_TUNNEL_MODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();\n            OMX_U32 audio_hw_sync = data.readInt32();\n\n            native_handle_t *sideband_handle = NULL;\n            status_t err = configureVideoTunnelMode(\n                    node, port_index, tunneled, audio_hw_sync, &sideband_handle);\n            reply->writeInt32(err);\n            if(err == OK){\n                reply->writeNativeHandle(sideband_handle);\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            if (!isSecure(node) || port_index != 0 /* kPortIndexInput */) {\n                ALOGE(\"b/24310423\");\n                reply->writeInt32(INVALID_OPERATION);\n                return NO_ERROR;\n            }\n\n            size_t size = data.readInt64();\n\n            buffer_id buffer;\n            void *buffer_data;\n            status_t err = allocateBuffer(\n                    node, port_index, size, &buffer, &buffer_data);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n                reply->writeInt64((uintptr_t)buffer_data);\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER_WITH_BACKUP:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = allocateBufferWithBackup(\n                    node, port_index, params, &buffer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(freeBuffer(node, port_index, buffer));\n\n            return NO_ERROR;\n        }\n\n        case FILL_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(fillBuffer(node, buffer));\n\n            return NO_ERROR;\n        }\n\n        case EMPTY_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            OMX_U32 range_offset = data.readInt32();\n            OMX_U32 range_length = data.readInt32();\n            OMX_U32 flags = data.readInt32();\n            OMX_TICKS timestamp = data.readInt64();\n\n            reply->writeInt32(\n                    emptyBuffer(\n                        node, buffer, range_offset, range_length,\n                        flags, timestamp));\n\n            return NO_ERROR;\n        }\n\n        case GET_EXTENSION_INDEX:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            const char *parameter_name = data.readCString();\n\n            OMX_INDEXTYPE index;\n            status_t err = getExtensionIndex(node, parameter_name, &index);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32(index);\n            }\n\n            return OK;\n        }\n\n        default:\n            return BBinder::onTransact(code, data, reply, flags);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -308,11 +308,13 @@\n             OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();\n             OMX_U32 audio_hw_sync = data.readInt32();\n \n-            native_handle_t *sideband_handle;\n+            native_handle_t *sideband_handle = NULL;\n             status_t err = configureVideoTunnelMode(\n                     node, port_index, tunneled, audio_hw_sync, &sideband_handle);\n             reply->writeInt32(err);\n-            reply->writeNativeHandle(sideband_handle);\n+            if(err == OK){\n+                reply->writeNativeHandle(sideband_handle);\n+            }\n \n             return NO_ERROR;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "            native_handle_t *sideband_handle;",
                "            reply->writeNativeHandle(sideband_handle);"
            ],
            "added_lines": [
                "            native_handle_t *sideband_handle = NULL;",
                "            if(err == OK){",
                "                reply->writeNativeHandle(sideband_handle);",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2413",
        "func_name": "android/configureVideoTunnelMode",
        "description": "media/libmedia/IOMX.cpp in mediaserver in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 does not initialize a handle pointer, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 26403627.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/25be9ac20db51044e1b09ca67906355e4f328d48",
        "commit_title": "IOMX.cpp uninitialized pointer in BnOMX::onTransact",
        "commit_text": " This can lead to local code execution in media server. Fix initializes the pointer and checks the error conditions before returning  Bug: 26403627 ",
        "func_before": "virtual status_t configureVideoTunnelMode(\n            node_id node, OMX_U32 portIndex, OMX_BOOL tunneled,\n            OMX_U32 audioHwSync, native_handle_t **sidebandHandle ) {\n        Parcel data, reply;\n        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());\n        data.writeInt32((int32_t)node);\n        data.writeInt32(portIndex);\n        data.writeInt32((int32_t)tunneled);\n        data.writeInt32(audioHwSync);\n        remote()->transact(CONFIGURE_VIDEO_TUNNEL_MODE, data, &reply);\n\n        status_t err = reply.readInt32();\n        if (sidebandHandle) {\n            *sidebandHandle = (native_handle_t *)reply.readNativeHandle();\n        }\n        return err;\n    }",
        "func": "virtual status_t configureVideoTunnelMode(\n            node_id node, OMX_U32 portIndex, OMX_BOOL tunneled,\n            OMX_U32 audioHwSync, native_handle_t **sidebandHandle ) {\n        Parcel data, reply;\n        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());\n        data.writeInt32((int32_t)node);\n        data.writeInt32(portIndex);\n        data.writeInt32((int32_t)tunneled);\n        data.writeInt32(audioHwSync);\n        remote()->transact(CONFIGURE_VIDEO_TUNNEL_MODE, data, &reply);\n\n        status_t err = reply.readInt32();\n        if (err == OK && sidebandHandle) {\n            *sidebandHandle = (native_handle_t *)reply.readNativeHandle();\n        }\n        return err;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n         remote()->transact(CONFIGURE_VIDEO_TUNNEL_MODE, data, &reply);\n \n         status_t err = reply.readInt32();\n-        if (sidebandHandle) {\n+        if (err == OK && sidebandHandle) {\n             *sidebandHandle = (native_handle_t *)reply.readNativeHandle();\n         }\n         return err;",
        "diff_line_info": {
            "deleted_lines": [
                "        if (sidebandHandle) {"
            ],
            "added_lines": [
                "        if (err == OK && sidebandHandle) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2416",
        "func_name": "android/BufferQueueConsumer::dump",
        "description": "libs/gui/BufferQueueConsumer.cpp in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 does not check for the android.permission.DUMP permission, which allows attackers to obtain sensitive information, and consequently bypass an unspecified protection mechanism, via a dump request, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 27046057.",
        "git_url": "https://android.googlesource.com/platform/frameworks/native/+/85d253fab5e2c01bd90990667c6de25c282fc5cd",
        "commit_title": "BQ: Add permission check to BufferQueueConsumer::dump",
        "commit_text": " Bug 27046057  ",
        "func_before": "void BufferQueueConsumer::dump(String8& result, const char* prefix) const {\n    mCore->dump(result, prefix);\n}",
        "func": "void BufferQueueConsumer::dump(String8& result, const char* prefix) const {\n    const IPCThreadState* ipc = IPCThreadState::self();\n    const pid_t pid = ipc->getCallingPid();\n    const uid_t uid = ipc->getCallingUid();\n    if ((uid != AID_SHELL)\n            && !PermissionCache::checkPermission(String16(\n            \"android.permission.DUMP\"), pid, uid)) {\n        result.appendFormat(\"Permission Denial: can't dump BufferQueueConsumer \"\n                \"from pid=%d, uid=%d\\n\", pid, uid);\n    } else {\n        mCore->dump(result, prefix);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,3 +1,13 @@\n void BufferQueueConsumer::dump(String8& result, const char* prefix) const {\n-    mCore->dump(result, prefix);\n+    const IPCThreadState* ipc = IPCThreadState::self();\n+    const pid_t pid = ipc->getCallingPid();\n+    const uid_t uid = ipc->getCallingUid();\n+    if ((uid != AID_SHELL)\n+            && !PermissionCache::checkPermission(String16(\n+            \"android.permission.DUMP\"), pid, uid)) {\n+        result.appendFormat(\"Permission Denial: can't dump BufferQueueConsumer \"\n+                \"from pid=%d, uid=%d\\n\", pid, uid);\n+    } else {\n+        mCore->dump(result, prefix);\n+    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    mCore->dump(result, prefix);"
            ],
            "added_lines": [
                "    const IPCThreadState* ipc = IPCThreadState::self();",
                "    const pid_t pid = ipc->getCallingPid();",
                "    const uid_t uid = ipc->getCallingUid();",
                "    if ((uid != AID_SHELL)",
                "            && !PermissionCache::checkPermission(String16(",
                "            \"android.permission.DUMP\"), pid, uid)) {",
                "        result.appendFormat(\"Permission Denial: can't dump BufferQueueConsumer \"",
                "                \"from pid=%d, uid=%d\\n\", pid, uid);",
                "    } else {",
                "        mCore->dump(result, prefix);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2416",
        "func_name": "android/BufferQueueConsumer::dump",
        "description": "libs/gui/BufferQueueConsumer.cpp in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 does not check for the android.permission.DUMP permission, which allows attackers to obtain sensitive information, and consequently bypass an unspecified protection mechanism, via a dump request, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 27046057.",
        "git_url": "https://android.googlesource.com/platform/frameworks/native/+/a40b30f5c43726120bfe69d41ff5aeb31fe1d02a",
        "commit_title": "Add SN logging",
        "commit_text": " Bug 27046057  ",
        "func_before": "void BufferQueueConsumer::dump(String8& result, const char* prefix) const {\n    const IPCThreadState* ipc = IPCThreadState::self();\n    const pid_t pid = ipc->getCallingPid();\n    const uid_t uid = ipc->getCallingUid();\n    if ((uid != AID_SHELL)\n            && !PermissionCache::checkPermission(String16(\n            \"android.permission.DUMP\"), pid, uid)) {\n        result.appendFormat(\"Permission Denial: can't dump BufferQueueConsumer \"\n                \"from pid=%d, uid=%d\\n\", pid, uid);\n    } else {\n        mCore->dump(result, prefix);\n    }\n}",
        "func": "void BufferQueueConsumer::dump(String8& result, const char* prefix) const {\n    const IPCThreadState* ipc = IPCThreadState::self();\n    const pid_t pid = ipc->getCallingPid();\n    const uid_t uid = ipc->getCallingUid();\n    if ((uid != AID_SHELL)\n            && !PermissionCache::checkPermission(String16(\n            \"android.permission.DUMP\"), pid, uid)) {\n        result.appendFormat(\"Permission Denial: can't dump BufferQueueConsumer \"\n                \"from pid=%d, uid=%d\\n\", pid, uid);\n        android_errorWriteWithInfoLog(0x534e4554, \"27046057\", uid, NULL, 0);\n    } else {\n        mCore->dump(result, prefix);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n             \"android.permission.DUMP\"), pid, uid)) {\n         result.appendFormat(\"Permission Denial: can't dump BufferQueueConsumer \"\n                 \"from pid=%d, uid=%d\\n\", pid, uid);\n+        android_errorWriteWithInfoLog(0x534e4554, \"27046057\", uid, NULL, 0);\n     } else {\n         mCore->dump(result, prefix);\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        android_errorWriteWithInfoLog(0x534e4554, \"27046057\", uid, NULL, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2417",
        "func_name": "android/BnOMX::onTransact",
        "description": "media/libmedia/IOMX.cpp in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-04-01 does not initialize a parameter data structure, which allows attackers to obtain sensitive information from process memory, and consequently bypass an unspecified protection mechanism, via unspecified vectors, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 26914474.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/1171e7c047bf79e7c93342bb6a812c9edd86aa84",
        "commit_title": "Clear allocation to avoid info leak",
        "commit_text": " Bug: 26914474 ",
        "func_before": "status_t BnOMX::onTransact(\n    uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {\n    switch (code) {\n        case LIVES_LOCALLY:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n            node_id node = (node_id)data.readInt32();\n            pid_t pid = (pid_t)data.readInt32();\n            reply->writeInt32(livesLocally(node, pid));\n\n            return OK;\n        }\n\n        case LIST_NODES:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            List<ComponentInfo> list;\n            listNodes(&list);\n\n            reply->writeInt32(list.size());\n            for (List<ComponentInfo>::iterator it = list.begin();\n                 it != list.end(); ++it) {\n                ComponentInfo &cur = *it;\n\n                reply->writeString8(cur.mName);\n                reply->writeInt32(cur.mRoles.size());\n                for (List<String8>::iterator role_it = cur.mRoles.begin();\n                     role_it != cur.mRoles.end(); ++role_it) {\n                    reply->writeString8(*role_it);\n                }\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOCATE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            const char *name = data.readCString();\n\n            sp<IOMXObserver> observer =\n                interface_cast<IOMXObserver>(data.readStrongBinder());\n\n            node_id node;\n\n            status_t err = allocateNode(name, observer, &node);\n            reply->writeInt32(err);\n            if (err == OK) {\n                reply->writeInt32((int32_t)node);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            reply->writeInt32(freeNode(node));\n\n            return NO_ERROR;\n        }\n\n        case SEND_COMMAND:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            OMX_COMMANDTYPE cmd =\n                static_cast<OMX_COMMANDTYPE>(data.readInt32());\n\n            OMX_S32 param = data.readInt32();\n            reply->writeInt32(sendCommand(node, cmd, param));\n\n            return NO_ERROR;\n        }\n\n        case GET_PARAMETER:\n        case SET_PARAMETER:\n        case GET_CONFIG:\n        case SET_CONFIG:\n        case SET_INTERNAL_OPTION:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_INDEXTYPE index = static_cast<OMX_INDEXTYPE>(data.readInt32());\n\n            size_t size = data.readInt64();\n\n            void *params = malloc(size);\n            data.read(params, size);\n\n            status_t err;\n            switch (code) {\n                case GET_PARAMETER:\n                    err = getParameter(node, index, params, size);\n                    break;\n                case SET_PARAMETER:\n                    err = setParameter(node, index, params, size);\n                    break;\n                case GET_CONFIG:\n                    err = getConfig(node, index, params, size);\n                    break;\n                case SET_CONFIG:\n                    err = setConfig(node, index, params, size);\n                    break;\n                case SET_INTERNAL_OPTION:\n                {\n                    InternalOptionType type =\n                        (InternalOptionType)data.readInt32();\n\n                    err = setInternalOption(node, index, type, params, size);\n                    break;\n                }\n\n                default:\n                    TRESPASS();\n            }\n\n            reply->writeInt32(err);\n\n            if ((code == GET_PARAMETER || code == GET_CONFIG) && err == OK) {\n                reply->write(params, size);\n            }\n\n            free(params);\n            params = NULL;\n\n            return NO_ERROR;\n        }\n\n        case GET_STATE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_STATETYPE state = OMX_StateInvalid;\n\n            status_t err = getState(node, &state);\n            reply->writeInt32(state);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case ENABLE_GRAPHIC_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = enableGraphicBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case GET_GRAPHIC_BUFFER_USAGE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            OMX_U32 usage = 0;\n            status_t err = getGraphicBufferUsage(node, port_index, &usage);\n            reply->writeInt32(err);\n            reply->writeInt32(usage);\n\n            return NO_ERROR;\n        }\n\n        case USE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = useBuffer(node, port_index, params, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case USE_GRAPHIC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n\n            buffer_id buffer;\n            status_t err = useGraphicBuffer(\n                    node, port_index, graphicBuffer, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case UPDATE_GRAPHIC_BUFFER_IN_META:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n            buffer_id buffer = (buffer_id)data.readInt32();\n\n            status_t err = updateGraphicBufferInMeta(\n                    node, port_index, graphicBuffer, buffer);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CREATE_INPUT_SURFACE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            sp<IGraphicBufferProducer> bufferProducer;\n            status_t err = createInputSurface(node, port_index,\n                    &bufferProducer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeStrongBinder(bufferProducer->asBinder());\n            }\n\n            return NO_ERROR;\n        }\n\n        case SIGNAL_END_OF_INPUT_STREAM:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            status_t err = signalEndOfInputStream(node);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case STORE_META_DATA_IN_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = storeMetaDataInBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case PREPARE_FOR_ADAPTIVE_PLAYBACK:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n            OMX_U32 max_width = data.readInt32();\n            OMX_U32 max_height = data.readInt32();\n\n            status_t err = prepareForAdaptivePlayback(\n                    node, port_index, enable, max_width, max_height);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CONFIGURE_VIDEO_TUNNEL_MODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();\n            OMX_U32 audio_hw_sync = data.readInt32();\n\n            native_handle_t *sideband_handle = NULL;\n            status_t err = configureVideoTunnelMode(\n                    node, port_index, tunneled, audio_hw_sync, &sideband_handle);\n            reply->writeInt32(err);\n            if(err == OK){\n                reply->writeNativeHandle(sideband_handle);\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            if (!isSecure(node) || port_index != 0 /* kPortIndexInput */) {\n                ALOGE(\"b/24310423\");\n                reply->writeInt32(INVALID_OPERATION);\n                return NO_ERROR;\n            }\n\n            size_t size = data.readInt64();\n\n            buffer_id buffer;\n            void *buffer_data;\n            status_t err = allocateBuffer(\n                    node, port_index, size, &buffer, &buffer_data);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n                reply->writeInt64((uintptr_t)buffer_data);\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER_WITH_BACKUP:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = allocateBufferWithBackup(\n                    node, port_index, params, &buffer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(freeBuffer(node, port_index, buffer));\n\n            return NO_ERROR;\n        }\n\n        case FILL_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(fillBuffer(node, buffer));\n\n            return NO_ERROR;\n        }\n\n        case EMPTY_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            OMX_U32 range_offset = data.readInt32();\n            OMX_U32 range_length = data.readInt32();\n            OMX_U32 flags = data.readInt32();\n            OMX_TICKS timestamp = data.readInt64();\n\n            reply->writeInt32(\n                    emptyBuffer(\n                        node, buffer, range_offset, range_length,\n                        flags, timestamp));\n\n            return NO_ERROR;\n        }\n\n        case GET_EXTENSION_INDEX:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            const char *parameter_name = data.readCString();\n\n            OMX_INDEXTYPE index;\n            status_t err = getExtensionIndex(node, parameter_name, &index);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32(index);\n            }\n\n            return OK;\n        }\n\n        default:\n            return BBinder::onTransact(code, data, reply, flags);\n    }\n}",
        "func": "status_t BnOMX::onTransact(\n    uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {\n    switch (code) {\n        case LIVES_LOCALLY:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n            node_id node = (node_id)data.readInt32();\n            pid_t pid = (pid_t)data.readInt32();\n            reply->writeInt32(livesLocally(node, pid));\n\n            return OK;\n        }\n\n        case LIST_NODES:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            List<ComponentInfo> list;\n            listNodes(&list);\n\n            reply->writeInt32(list.size());\n            for (List<ComponentInfo>::iterator it = list.begin();\n                 it != list.end(); ++it) {\n                ComponentInfo &cur = *it;\n\n                reply->writeString8(cur.mName);\n                reply->writeInt32(cur.mRoles.size());\n                for (List<String8>::iterator role_it = cur.mRoles.begin();\n                     role_it != cur.mRoles.end(); ++role_it) {\n                    reply->writeString8(*role_it);\n                }\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOCATE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            const char *name = data.readCString();\n\n            sp<IOMXObserver> observer =\n                interface_cast<IOMXObserver>(data.readStrongBinder());\n\n            node_id node;\n\n            status_t err = allocateNode(name, observer, &node);\n            reply->writeInt32(err);\n            if (err == OK) {\n                reply->writeInt32((int32_t)node);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_NODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            reply->writeInt32(freeNode(node));\n\n            return NO_ERROR;\n        }\n\n        case SEND_COMMAND:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            OMX_COMMANDTYPE cmd =\n                static_cast<OMX_COMMANDTYPE>(data.readInt32());\n\n            OMX_S32 param = data.readInt32();\n            reply->writeInt32(sendCommand(node, cmd, param));\n\n            return NO_ERROR;\n        }\n\n        case GET_PARAMETER:\n        case SET_PARAMETER:\n        case GET_CONFIG:\n        case SET_CONFIG:\n        case SET_INTERNAL_OPTION:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_INDEXTYPE index = static_cast<OMX_INDEXTYPE>(data.readInt32());\n\n            size_t size = data.readInt64();\n\n            status_t err = NO_MEMORY;\n            void *params = calloc(size, 1);\n            if (params) {\n                err = data.read(params, size);\n                if (err != OK) {\n                    android_errorWriteLog(0x534e4554, \"26914474\");\n                } else {\n                    switch (code) {\n                        case GET_PARAMETER:\n                            err = getParameter(node, index, params, size);\n                            break;\n                        case SET_PARAMETER:\n                            err = setParameter(node, index, params, size);\n                            break;\n                        case GET_CONFIG:\n                            err = getConfig(node, index, params, size);\n                            break;\n                        case SET_CONFIG:\n                            err = setConfig(node, index, params, size);\n                            break;\n                        case SET_INTERNAL_OPTION:\n                        {\n                            InternalOptionType type =\n                                (InternalOptionType)data.readInt32();\n\n                            err = setInternalOption(node, index, type, params, size);\n                            break;\n                        }\n\n                        default:\n                            TRESPASS();\n                    }\n                }\n            }\n\n            reply->writeInt32(err);\n\n            if ((code == GET_PARAMETER || code == GET_CONFIG) && err == OK) {\n                reply->write(params, size);\n            }\n\n            free(params);\n            params = NULL;\n\n            return NO_ERROR;\n        }\n\n        case GET_STATE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_STATETYPE state = OMX_StateInvalid;\n\n            status_t err = getState(node, &state);\n            reply->writeInt32(state);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case ENABLE_GRAPHIC_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = enableGraphicBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case GET_GRAPHIC_BUFFER_USAGE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            OMX_U32 usage = 0;\n            status_t err = getGraphicBufferUsage(node, port_index, &usage);\n            reply->writeInt32(err);\n            reply->writeInt32(usage);\n\n            return NO_ERROR;\n        }\n\n        case USE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = useBuffer(node, port_index, params, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case USE_GRAPHIC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n\n            buffer_id buffer;\n            status_t err = useGraphicBuffer(\n                    node, port_index, graphicBuffer, &buffer);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case UPDATE_GRAPHIC_BUFFER_IN_META:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();\n            data.read(*graphicBuffer);\n            buffer_id buffer = (buffer_id)data.readInt32();\n\n            status_t err = updateGraphicBufferInMeta(\n                    node, port_index, graphicBuffer, buffer);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CREATE_INPUT_SURFACE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n\n            sp<IGraphicBufferProducer> bufferProducer;\n            status_t err = createInputSurface(node, port_index,\n                    &bufferProducer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeStrongBinder(bufferProducer->asBinder());\n            }\n\n            return NO_ERROR;\n        }\n\n        case SIGNAL_END_OF_INPUT_STREAM:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n\n            status_t err = signalEndOfInputStream(node);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case STORE_META_DATA_IN_BUFFERS:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n\n            status_t err = storeMetaDataInBuffers(node, port_index, enable);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case PREPARE_FOR_ADAPTIVE_PLAYBACK:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL enable = (OMX_BOOL)data.readInt32();\n            OMX_U32 max_width = data.readInt32();\n            OMX_U32 max_height = data.readInt32();\n\n            status_t err = prepareForAdaptivePlayback(\n                    node, port_index, enable, max_width, max_height);\n            reply->writeInt32(err);\n\n            return NO_ERROR;\n        }\n\n        case CONFIGURE_VIDEO_TUNNEL_MODE:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();\n            OMX_U32 audio_hw_sync = data.readInt32();\n\n            native_handle_t *sideband_handle = NULL;\n            status_t err = configureVideoTunnelMode(\n                    node, port_index, tunneled, audio_hw_sync, &sideband_handle);\n            reply->writeInt32(err);\n            if(err == OK){\n                reply->writeNativeHandle(sideband_handle);\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            if (!isSecure(node) || port_index != 0 /* kPortIndexInput */) {\n                ALOGE(\"b/24310423\");\n                reply->writeInt32(INVALID_OPERATION);\n                return NO_ERROR;\n            }\n\n            size_t size = data.readInt64();\n\n            buffer_id buffer;\n            void *buffer_data;\n            status_t err = allocateBuffer(\n                    node, port_index, size, &buffer, &buffer_data);\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n                reply->writeInt64((uintptr_t)buffer_data);\n            }\n\n            return NO_ERROR;\n        }\n\n        case ALLOC_BUFFER_WITH_BACKUP:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            sp<IMemory> params =\n                interface_cast<IMemory>(data.readStrongBinder());\n\n            buffer_id buffer;\n            status_t err = allocateBufferWithBackup(\n                    node, port_index, params, &buffer);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32((int32_t)buffer);\n            }\n\n            return NO_ERROR;\n        }\n\n        case FREE_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            OMX_U32 port_index = data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(freeBuffer(node, port_index, buffer));\n\n            return NO_ERROR;\n        }\n\n        case FILL_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            reply->writeInt32(fillBuffer(node, buffer));\n\n            return NO_ERROR;\n        }\n\n        case EMPTY_BUFFER:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            buffer_id buffer = (buffer_id)data.readInt32();\n            OMX_U32 range_offset = data.readInt32();\n            OMX_U32 range_length = data.readInt32();\n            OMX_U32 flags = data.readInt32();\n            OMX_TICKS timestamp = data.readInt64();\n\n            reply->writeInt32(\n                    emptyBuffer(\n                        node, buffer, range_offset, range_length,\n                        flags, timestamp));\n\n            return NO_ERROR;\n        }\n\n        case GET_EXTENSION_INDEX:\n        {\n            CHECK_OMX_INTERFACE(IOMX, data, reply);\n\n            node_id node = (node_id)data.readInt32();\n            const char *parameter_name = data.readCString();\n\n            OMX_INDEXTYPE index;\n            status_t err = getExtensionIndex(node, parameter_name, &index);\n\n            reply->writeInt32(err);\n\n            if (err == OK) {\n                reply->writeInt32(index);\n            }\n\n            return OK;\n        }\n\n        default:\n            return BBinder::onTransact(code, data, reply, flags);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -93,34 +93,39 @@\n \n             size_t size = data.readInt64();\n \n-            void *params = malloc(size);\n-            data.read(params, size);\n-\n-            status_t err;\n-            switch (code) {\n-                case GET_PARAMETER:\n-                    err = getParameter(node, index, params, size);\n-                    break;\n-                case SET_PARAMETER:\n-                    err = setParameter(node, index, params, size);\n-                    break;\n-                case GET_CONFIG:\n-                    err = getConfig(node, index, params, size);\n-                    break;\n-                case SET_CONFIG:\n-                    err = setConfig(node, index, params, size);\n-                    break;\n-                case SET_INTERNAL_OPTION:\n-                {\n-                    InternalOptionType type =\n-                        (InternalOptionType)data.readInt32();\n-\n-                    err = setInternalOption(node, index, type, params, size);\n-                    break;\n+            status_t err = NO_MEMORY;\n+            void *params = calloc(size, 1);\n+            if (params) {\n+                err = data.read(params, size);\n+                if (err != OK) {\n+                    android_errorWriteLog(0x534e4554, \"26914474\");\n+                } else {\n+                    switch (code) {\n+                        case GET_PARAMETER:\n+                            err = getParameter(node, index, params, size);\n+                            break;\n+                        case SET_PARAMETER:\n+                            err = setParameter(node, index, params, size);\n+                            break;\n+                        case GET_CONFIG:\n+                            err = getConfig(node, index, params, size);\n+                            break;\n+                        case SET_CONFIG:\n+                            err = setConfig(node, index, params, size);\n+                            break;\n+                        case SET_INTERNAL_OPTION:\n+                        {\n+                            InternalOptionType type =\n+                                (InternalOptionType)data.readInt32();\n+\n+                            err = setInternalOption(node, index, type, params, size);\n+                            break;\n+                        }\n+\n+                        default:\n+                            TRESPASS();\n+                    }\n                 }\n-\n-                default:\n-                    TRESPASS();\n             }\n \n             reply->writeInt32(err);",
        "diff_line_info": {
            "deleted_lines": [
                "            void *params = malloc(size);",
                "            data.read(params, size);",
                "",
                "            status_t err;",
                "            switch (code) {",
                "                case GET_PARAMETER:",
                "                    err = getParameter(node, index, params, size);",
                "                    break;",
                "                case SET_PARAMETER:",
                "                    err = setParameter(node, index, params, size);",
                "                    break;",
                "                case GET_CONFIG:",
                "                    err = getConfig(node, index, params, size);",
                "                    break;",
                "                case SET_CONFIG:",
                "                    err = setConfig(node, index, params, size);",
                "                    break;",
                "                case SET_INTERNAL_OPTION:",
                "                {",
                "                    InternalOptionType type =",
                "                        (InternalOptionType)data.readInt32();",
                "",
                "                    err = setInternalOption(node, index, type, params, size);",
                "                    break;",
                "",
                "                default:",
                "                    TRESPASS();"
            ],
            "added_lines": [
                "            status_t err = NO_MEMORY;",
                "            void *params = calloc(size, 1);",
                "            if (params) {",
                "                err = data.read(params, size);",
                "                if (err != OK) {",
                "                    android_errorWriteLog(0x534e4554, \"26914474\");",
                "                } else {",
                "                    switch (code) {",
                "                        case GET_PARAMETER:",
                "                            err = getParameter(node, index, params, size);",
                "                            break;",
                "                        case SET_PARAMETER:",
                "                            err = setParameter(node, index, params, size);",
                "                            break;",
                "                        case GET_CONFIG:",
                "                            err = getConfig(node, index, params, size);",
                "                            break;",
                "                        case SET_CONFIG:",
                "                            err = setConfig(node, index, params, size);",
                "                            break;",
                "                        case SET_INTERNAL_OPTION:",
                "                        {",
                "                            InternalOptionType type =",
                "                                (InternalOptionType)data.readInt32();",
                "",
                "                            err = setInternalOption(node, index, type, params, size);",
                "                            break;",
                "                        }",
                "",
                "                        default:",
                "                            TRESPASS();",
                "                    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2419",
        "func_name": "android/BnDrm::onTransact",
        "description": "media/libmedia/IDrm.cpp in mediaserver in Android 6.x before 2016-04-01 does not initialize a certain key-request data structure, which allows attackers to obtain sensitive information from process memory, and consequently bypass an unspecified protection mechanism, via unspecified vectors, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 26323455.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/5a856f2092f7086aa0fea9ae06b9255befcdcd34",
        "commit_title": "Fix info leak vulnerability of IDrm",
        "commit_text": " bug: 26323455 ",
        "func_before": "status_t BnDrm::onTransact(\n    uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {\n    switch (code) {\n        case INIT_CHECK:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            reply->writeInt32(initCheck());\n            return OK;\n        }\n\n        case IS_CRYPTO_SUPPORTED:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            uint8_t uuid[16];\n            data.read(uuid, sizeof(uuid));\n            String8 mimeType = data.readString8();\n            reply->writeInt32(isCryptoSchemeSupported(uuid, mimeType));\n\n            return OK;\n        }\n\n        case CREATE_PLUGIN:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            uint8_t uuid[16];\n            data.read(uuid, sizeof(uuid));\n            reply->writeInt32(createPlugin(uuid));\n            return OK;\n        }\n\n        case DESTROY_PLUGIN:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            reply->writeInt32(destroyPlugin());\n            return OK;\n        }\n\n        case OPEN_SESSION:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            status_t result = openSession(sessionId);\n            writeVector(reply, sessionId);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case CLOSE_SESSION:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            reply->writeInt32(closeSession(sessionId));\n            return OK;\n        }\n\n        case GET_KEY_REQUEST:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, initData;\n\n            readVector(data, sessionId);\n            readVector(data, initData);\n            String8 mimeType = data.readString8();\n            DrmPlugin::KeyType keyType = (DrmPlugin::KeyType)data.readInt32();\n\n            KeyedVector<String8, String8> optionalParameters;\n            uint32_t count = data.readInt32();\n            for (size_t i = 0; i < count; ++i) {\n                String8 key, value;\n                key = data.readString8();\n                value = data.readString8();\n                optionalParameters.add(key, value);\n            }\n\n            Vector<uint8_t> request;\n            String8 defaultUrl;\n            DrmPlugin::KeyRequestType keyRequestType;\n\n            status_t result = getKeyRequest(sessionId, initData, mimeType,\n                    keyType, optionalParameters, request, defaultUrl,\n                    &keyRequestType);\n\n            writeVector(reply, request);\n            reply->writeString8(defaultUrl);\n            reply->writeInt32(static_cast<int32_t>(keyRequestType));\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case PROVIDE_KEY_RESPONSE:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, response, keySetId;\n            readVector(data, sessionId);\n            readVector(data, response);\n            uint32_t result = provideKeyResponse(sessionId, response, keySetId);\n            writeVector(reply, keySetId);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case REMOVE_KEYS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> keySetId;\n            readVector(data, keySetId);\n            reply->writeInt32(removeKeys(keySetId));\n            return OK;\n        }\n\n        case RESTORE_KEYS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keySetId;\n            readVector(data, sessionId);\n            readVector(data, keySetId);\n            reply->writeInt32(restoreKeys(sessionId, keySetId));\n            return OK;\n        }\n\n        case QUERY_KEY_STATUS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            KeyedVector<String8, String8> infoMap;\n            status_t result = queryKeyStatus(sessionId, infoMap);\n            size_t count = infoMap.size();\n            reply->writeInt32(count);\n            for (size_t i = 0; i < count; ++i) {\n                reply->writeString8(infoMap.keyAt(i));\n                reply->writeString8(infoMap.valueAt(i));\n            }\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_PROVISION_REQUEST:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 certType = data.readString8();\n            String8 certAuthority = data.readString8();\n\n            Vector<uint8_t> request;\n            String8 defaultUrl;\n            status_t result = getProvisionRequest(certType, certAuthority,\n                                                  request, defaultUrl);\n            writeVector(reply, request);\n            reply->writeString8(defaultUrl);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case PROVIDE_PROVISION_RESPONSE:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> response;\n            Vector<uint8_t> certificate;\n            Vector<uint8_t> wrappedKey;\n            readVector(data, response);\n            status_t result = provideProvisionResponse(response, certificate, wrappedKey);\n            writeVector(reply, certificate);\n            writeVector(reply, wrappedKey);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case UNPROVISION_DEVICE:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            status_t result = unprovisionDevice();\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_SECURE_STOPS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            List<Vector<uint8_t> > secureStops;\n            status_t result = getSecureStops(secureStops);\n            size_t count = secureStops.size();\n            reply->writeInt32(count);\n            List<Vector<uint8_t> >::iterator iter = secureStops.begin();\n            while(iter != secureStops.end()) {\n                size_t size = iter->size();\n                reply->writeInt32(size);\n                reply->write(iter->array(), iter->size());\n                iter++;\n            }\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_SECURE_STOP:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> ssid, secureStop;\n            readVector(data, ssid);\n            status_t result = getSecureStop(ssid, secureStop);\n            writeVector(reply, secureStop);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case RELEASE_SECURE_STOPS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> ssRelease;\n            readVector(data, ssRelease);\n            reply->writeInt32(releaseSecureStops(ssRelease));\n            return OK;\n        }\n\n        case RELEASE_ALL_SECURE_STOPS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            reply->writeInt32(releaseAllSecureStops());\n            return OK;\n        }\n\n        case GET_PROPERTY_STRING:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            String8 value;\n            status_t result = getPropertyString(name, value);\n            reply->writeString8(value);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_PROPERTY_BYTE_ARRAY:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            Vector<uint8_t> value;\n            status_t result = getPropertyByteArray(name, value);\n            writeVector(reply, value);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case SET_PROPERTY_STRING:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            String8 value = data.readString8();\n            reply->writeInt32(setPropertyString(name, value));\n            return OK;\n        }\n\n        case SET_PROPERTY_BYTE_ARRAY:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            Vector<uint8_t> value;\n            readVector(data, value);\n            reply->writeInt32(setPropertyByteArray(name, value));\n            return OK;\n        }\n\n        case SET_CIPHER_ALGORITHM:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            String8 algorithm = data.readString8();\n            reply->writeInt32(setCipherAlgorithm(sessionId, algorithm));\n            return OK;\n        }\n\n        case SET_MAC_ALGORITHM:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            String8 algorithm = data.readString8();\n            reply->writeInt32(setMacAlgorithm(sessionId, algorithm));\n            return OK;\n        }\n\n        case ENCRYPT:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, input, iv, output;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, input);\n            readVector(data, iv);\n            uint32_t result = encrypt(sessionId, keyId, input, iv, output);\n            writeVector(reply, output);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case DECRYPT:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, input, iv, output;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, input);\n            readVector(data, iv);\n            uint32_t result = decrypt(sessionId, keyId, input, iv, output);\n            writeVector(reply, output);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case SIGN:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, message, signature;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, message);\n            uint32_t result = sign(sessionId, keyId, message, signature);\n            writeVector(reply, signature);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case VERIFY:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, message, signature;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, message);\n            readVector(data, signature);\n            bool match;\n            uint32_t result = verify(sessionId, keyId, message, signature, match);\n            reply->writeInt32(match);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case SIGN_RSA:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, message, wrappedKey, signature;\n            readVector(data, sessionId);\n            String8 algorithm = data.readString8();\n            readVector(data, message);\n            readVector(data, wrappedKey);\n            uint32_t result = signRSA(sessionId, algorithm, message, wrappedKey, signature);\n            writeVector(reply, signature);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n    case SET_LISTENER: {\n        CHECK_INTERFACE(IDrm, data, reply);\n        sp<IDrmClient> listener =\n            interface_cast<IDrmClient>(data.readStrongBinder());\n        reply->writeInt32(setListener(listener));\n        return NO_ERROR;\n    } break;\n\n    default:\n        return BBinder::onTransact(code, data, reply, flags);\n    }\n}",
        "func": "status_t BnDrm::onTransact(\n    uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {\n    switch (code) {\n        case INIT_CHECK:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            reply->writeInt32(initCheck());\n            return OK;\n        }\n\n        case IS_CRYPTO_SUPPORTED:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            uint8_t uuid[16];\n            data.read(uuid, sizeof(uuid));\n            String8 mimeType = data.readString8();\n            reply->writeInt32(isCryptoSchemeSupported(uuid, mimeType));\n\n            return OK;\n        }\n\n        case CREATE_PLUGIN:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            uint8_t uuid[16];\n            data.read(uuid, sizeof(uuid));\n            reply->writeInt32(createPlugin(uuid));\n            return OK;\n        }\n\n        case DESTROY_PLUGIN:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            reply->writeInt32(destroyPlugin());\n            return OK;\n        }\n\n        case OPEN_SESSION:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            status_t result = openSession(sessionId);\n            writeVector(reply, sessionId);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case CLOSE_SESSION:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            reply->writeInt32(closeSession(sessionId));\n            return OK;\n        }\n\n        case GET_KEY_REQUEST:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, initData;\n\n            readVector(data, sessionId);\n            readVector(data, initData);\n            String8 mimeType = data.readString8();\n            DrmPlugin::KeyType keyType = (DrmPlugin::KeyType)data.readInt32();\n\n            KeyedVector<String8, String8> optionalParameters;\n            uint32_t count = data.readInt32();\n            for (size_t i = 0; i < count; ++i) {\n                String8 key, value;\n                key = data.readString8();\n                value = data.readString8();\n                optionalParameters.add(key, value);\n            }\n\n            Vector<uint8_t> request;\n            String8 defaultUrl;\n            DrmPlugin::KeyRequestType keyRequestType = DrmPlugin::kKeyRequestType_Unknown;\n\n            status_t result = getKeyRequest(sessionId, initData, mimeType,\n                    keyType, optionalParameters, request, defaultUrl,\n                    &keyRequestType);\n\n            writeVector(reply, request);\n            reply->writeString8(defaultUrl);\n            reply->writeInt32(static_cast<int32_t>(keyRequestType));\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case PROVIDE_KEY_RESPONSE:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, response, keySetId;\n            readVector(data, sessionId);\n            readVector(data, response);\n            uint32_t result = provideKeyResponse(sessionId, response, keySetId);\n            writeVector(reply, keySetId);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case REMOVE_KEYS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> keySetId;\n            readVector(data, keySetId);\n            reply->writeInt32(removeKeys(keySetId));\n            return OK;\n        }\n\n        case RESTORE_KEYS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keySetId;\n            readVector(data, sessionId);\n            readVector(data, keySetId);\n            reply->writeInt32(restoreKeys(sessionId, keySetId));\n            return OK;\n        }\n\n        case QUERY_KEY_STATUS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            KeyedVector<String8, String8> infoMap;\n            status_t result = queryKeyStatus(sessionId, infoMap);\n            size_t count = infoMap.size();\n            reply->writeInt32(count);\n            for (size_t i = 0; i < count; ++i) {\n                reply->writeString8(infoMap.keyAt(i));\n                reply->writeString8(infoMap.valueAt(i));\n            }\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_PROVISION_REQUEST:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 certType = data.readString8();\n            String8 certAuthority = data.readString8();\n\n            Vector<uint8_t> request;\n            String8 defaultUrl;\n            status_t result = getProvisionRequest(certType, certAuthority,\n                                                  request, defaultUrl);\n            writeVector(reply, request);\n            reply->writeString8(defaultUrl);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case PROVIDE_PROVISION_RESPONSE:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> response;\n            Vector<uint8_t> certificate;\n            Vector<uint8_t> wrappedKey;\n            readVector(data, response);\n            status_t result = provideProvisionResponse(response, certificate, wrappedKey);\n            writeVector(reply, certificate);\n            writeVector(reply, wrappedKey);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case UNPROVISION_DEVICE:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            status_t result = unprovisionDevice();\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_SECURE_STOPS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            List<Vector<uint8_t> > secureStops;\n            status_t result = getSecureStops(secureStops);\n            size_t count = secureStops.size();\n            reply->writeInt32(count);\n            List<Vector<uint8_t> >::iterator iter = secureStops.begin();\n            while(iter != secureStops.end()) {\n                size_t size = iter->size();\n                reply->writeInt32(size);\n                reply->write(iter->array(), iter->size());\n                iter++;\n            }\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_SECURE_STOP:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> ssid, secureStop;\n            readVector(data, ssid);\n            status_t result = getSecureStop(ssid, secureStop);\n            writeVector(reply, secureStop);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case RELEASE_SECURE_STOPS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> ssRelease;\n            readVector(data, ssRelease);\n            reply->writeInt32(releaseSecureStops(ssRelease));\n            return OK;\n        }\n\n        case RELEASE_ALL_SECURE_STOPS:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            reply->writeInt32(releaseAllSecureStops());\n            return OK;\n        }\n\n        case GET_PROPERTY_STRING:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            String8 value;\n            status_t result = getPropertyString(name, value);\n            reply->writeString8(value);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case GET_PROPERTY_BYTE_ARRAY:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            Vector<uint8_t> value;\n            status_t result = getPropertyByteArray(name, value);\n            writeVector(reply, value);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case SET_PROPERTY_STRING:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            String8 value = data.readString8();\n            reply->writeInt32(setPropertyString(name, value));\n            return OK;\n        }\n\n        case SET_PROPERTY_BYTE_ARRAY:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            String8 name = data.readString8();\n            Vector<uint8_t> value;\n            readVector(data, value);\n            reply->writeInt32(setPropertyByteArray(name, value));\n            return OK;\n        }\n\n        case SET_CIPHER_ALGORITHM:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            String8 algorithm = data.readString8();\n            reply->writeInt32(setCipherAlgorithm(sessionId, algorithm));\n            return OK;\n        }\n\n        case SET_MAC_ALGORITHM:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId;\n            readVector(data, sessionId);\n            String8 algorithm = data.readString8();\n            reply->writeInt32(setMacAlgorithm(sessionId, algorithm));\n            return OK;\n        }\n\n        case ENCRYPT:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, input, iv, output;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, input);\n            readVector(data, iv);\n            uint32_t result = encrypt(sessionId, keyId, input, iv, output);\n            writeVector(reply, output);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case DECRYPT:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, input, iv, output;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, input);\n            readVector(data, iv);\n            uint32_t result = decrypt(sessionId, keyId, input, iv, output);\n            writeVector(reply, output);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case SIGN:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, message, signature;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, message);\n            uint32_t result = sign(sessionId, keyId, message, signature);\n            writeVector(reply, signature);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case VERIFY:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, keyId, message, signature;\n            readVector(data, sessionId);\n            readVector(data, keyId);\n            readVector(data, message);\n            readVector(data, signature);\n            bool match;\n            uint32_t result = verify(sessionId, keyId, message, signature, match);\n            reply->writeInt32(match);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n        case SIGN_RSA:\n        {\n            CHECK_INTERFACE(IDrm, data, reply);\n            Vector<uint8_t> sessionId, message, wrappedKey, signature;\n            readVector(data, sessionId);\n            String8 algorithm = data.readString8();\n            readVector(data, message);\n            readVector(data, wrappedKey);\n            uint32_t result = signRSA(sessionId, algorithm, message, wrappedKey, signature);\n            writeVector(reply, signature);\n            reply->writeInt32(result);\n            return OK;\n        }\n\n    case SET_LISTENER: {\n        CHECK_INTERFACE(IDrm, data, reply);\n        sp<IDrmClient> listener =\n            interface_cast<IDrmClient>(data.readStrongBinder());\n        reply->writeInt32(setListener(listener));\n        return NO_ERROR;\n    } break;\n\n    default:\n        return BBinder::onTransact(code, data, reply, flags);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -75,7 +75,7 @@\n \n             Vector<uint8_t> request;\n             String8 defaultUrl;\n-            DrmPlugin::KeyRequestType keyRequestType;\n+            DrmPlugin::KeyRequestType keyRequestType = DrmPlugin::kKeyRequestType_Unknown;\n \n             status_t result = getKeyRequest(sessionId, initData, mimeType,\n                     keyType, optionalParameters, request, defaultUrl,",
        "diff_line_info": {
            "deleted_lines": [
                "            DrmPlugin::KeyRequestType keyRequestType;"
            ],
            "added_lines": [
                "            DrmPlugin::KeyRequestType keyRequestType = DrmPlugin::kKeyRequestType_Unknown;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2420",
        "func_name": "android/engrave_tombstone",
        "description": "rootdir/init.rc in Android 4.x before 4.4.4 does not ensure that the /data/tombstones directory exists for the Debuggerd component, which allows attackers to gain privileges via a crafted application, aka internal bug 26403620.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/81df1cc77722000f8d0025c1ab00ced123aa573c",
        "commit_title": "Don't create tombstone directory.",
        "commit_text": " Partial backport of cf79748.  Bug: http://b/26403620 ",
        "func_before": "char* engrave_tombstone(pid_t pid, pid_t tid, int signal, int original_si_code,\n                        uintptr_t abort_msg_address, bool dump_sibling_threads,\n                        bool* detach_failed, int* total_sleep_time_usec) {\n\n  log_t log;\n  log.current_tid = tid;\n  log.crashed_tid = tid;\n\n  if ((mkdir(TOMBSTONE_DIR, 0755) == -1) && (errno != EEXIST)) {\n    _LOG(&log, logtype::ERROR, \"failed to create %s: %s\\n\", TOMBSTONE_DIR, strerror(errno));\n  }\n\n  if (chown(TOMBSTONE_DIR, AID_SYSTEM, AID_SYSTEM) == -1) {\n    _LOG(&log, logtype::ERROR, \"failed to change ownership of %s: %s\\n\", TOMBSTONE_DIR, strerror(errno));\n  }\n\n  int fd = -1;\n  char* path = NULL;\n  if (selinux_android_restorecon(TOMBSTONE_DIR, 0) == 0) {\n    path = find_and_open_tombstone(&fd);\n  } else {\n    _LOG(&log, logtype::ERROR, \"Failed to restore security context, not writing tombstone.\\n\");\n  }\n\n  if (fd < 0) {\n    _LOG(&log, logtype::ERROR, \"Skipping tombstone write, nothing to do.\\n\");\n    *detach_failed = false;\n    return NULL;\n  }\n\n  log.tfd = fd;\n  // Preserve amfd since it can be modified through the calls below without\n  // being closed.\n  int amfd = activity_manager_connect();\n  log.amfd = amfd;\n  *detach_failed = dump_crash(&log, pid, tid, signal, original_si_code, abort_msg_address,\n                              dump_sibling_threads, total_sleep_time_usec);\n\n  ALOGI(\"\\nTombstone written to: %s\\n\", path);\n\n  // Either of these file descriptors can be -1, any error is ignored.\n  close(amfd);\n  close(fd);\n\n  return path;\n}",
        "func": "char* engrave_tombstone(pid_t pid, pid_t tid, int signal, int original_si_code,\n                        uintptr_t abort_msg_address, bool dump_sibling_threads,\n                        bool* detach_failed, int* total_sleep_time_usec) {\n\n  log_t log;\n  log.current_tid = tid;\n  log.crashed_tid = tid;\n\n  int fd = -1;\n  char* path = find_and_open_tombstone(&fd);\n\n  if (fd < 0) {\n    _LOG(&log, logtype::ERROR, \"Skipping tombstone write, nothing to do.\\n\");\n    *detach_failed = false;\n    return NULL;\n  }\n\n  log.tfd = fd;\n  // Preserve amfd since it can be modified through the calls below without\n  // being closed.\n  int amfd = activity_manager_connect();\n  log.amfd = amfd;\n  *detach_failed = dump_crash(&log, pid, tid, signal, original_si_code, abort_msg_address,\n                              dump_sibling_threads, total_sleep_time_usec);\n\n  ALOGI(\"\\nTombstone written to: %s\\n\", path);\n\n  // Either of these file descriptors can be -1, any error is ignored.\n  close(amfd);\n  close(fd);\n\n  return path;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,21 +6,8 @@\n   log.current_tid = tid;\n   log.crashed_tid = tid;\n \n-  if ((mkdir(TOMBSTONE_DIR, 0755) == -1) && (errno != EEXIST)) {\n-    _LOG(&log, logtype::ERROR, \"failed to create %s: %s\\n\", TOMBSTONE_DIR, strerror(errno));\n-  }\n-\n-  if (chown(TOMBSTONE_DIR, AID_SYSTEM, AID_SYSTEM) == -1) {\n-    _LOG(&log, logtype::ERROR, \"failed to change ownership of %s: %s\\n\", TOMBSTONE_DIR, strerror(errno));\n-  }\n-\n   int fd = -1;\n-  char* path = NULL;\n-  if (selinux_android_restorecon(TOMBSTONE_DIR, 0) == 0) {\n-    path = find_and_open_tombstone(&fd);\n-  } else {\n-    _LOG(&log, logtype::ERROR, \"Failed to restore security context, not writing tombstone.\\n\");\n-  }\n+  char* path = find_and_open_tombstone(&fd);\n \n   if (fd < 0) {\n     _LOG(&log, logtype::ERROR, \"Skipping tombstone write, nothing to do.\\n\");",
        "diff_line_info": {
            "deleted_lines": [
                "  if ((mkdir(TOMBSTONE_DIR, 0755) == -1) && (errno != EEXIST)) {",
                "    _LOG(&log, logtype::ERROR, \"failed to create %s: %s\\n\", TOMBSTONE_DIR, strerror(errno));",
                "  }",
                "",
                "  if (chown(TOMBSTONE_DIR, AID_SYSTEM, AID_SYSTEM) == -1) {",
                "    _LOG(&log, logtype::ERROR, \"failed to change ownership of %s: %s\\n\", TOMBSTONE_DIR, strerror(errno));",
                "  }",
                "",
                "  char* path = NULL;",
                "  if (selinux_android_restorecon(TOMBSTONE_DIR, 0) == 0) {",
                "    path = find_and_open_tombstone(&fd);",
                "  } else {",
                "    _LOG(&log, logtype::ERROR, \"Failed to restore security context, not writing tombstone.\\n\");",
                "  }"
            ],
            "added_lines": [
                "  char* path = find_and_open_tombstone(&fd);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3960",
        "func_name": "xen-project/xen/hap_domain_init",
        "description": "Integer overflow in the x86 shadow pagetable code in Xen allows local guest OS users to cause a denial of service (host crash) or possibly gain privileges by shadowing a superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/8b17648339ba801c4c7937b5f13dd25068e54e60",
        "commit_title": "x86: limit GFNs to 32 bits for shadowed superpages.",
        "commit_text": " Superpage shadows store the shadowed GFN in the backpointer field, which for non-BIGMEM builds is 32 bits wide.  Shadowing a superpage mapping of a guest-physical address above 2^44 would lead to the GFN being truncated there, and a crash when we come to remove the shadow from the hash table.  Track the valid width of a GFN for each guest, including reporting it through CPUID, and enforce it in the shadow pagetables.  Set the maximum witth to 32 for guests where this truncation could occur.  This is XSA-173. ",
        "func_before": "void hap_domain_init(struct domain *d)\n{\n    INIT_PAGE_LIST_HEAD(&d->arch.paging.hap.freelist);\n\n    /* Use HAP logdirty mechanism. */\n    paging_log_dirty_init(d, hap_enable_log_dirty,\n                          hap_disable_log_dirty,\n                          hap_clean_dirty_bitmap);\n}",
        "func": "void hap_domain_init(struct domain *d)\n{\n    INIT_PAGE_LIST_HEAD(&d->arch.paging.hap.freelist);\n\n    d->arch.paging.gfn_bits = hap_paddr_bits - PAGE_SHIFT;\n\n    /* Use HAP logdirty mechanism. */\n    paging_log_dirty_init(d, hap_enable_log_dirty,\n                          hap_disable_log_dirty,\n                          hap_clean_dirty_bitmap);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,8 @@\n void hap_domain_init(struct domain *d)\n {\n     INIT_PAGE_LIST_HEAD(&d->arch.paging.hap.freelist);\n+\n+    d->arch.paging.gfn_bits = hap_paddr_bits - PAGE_SHIFT;\n \n     /* Use HAP logdirty mechanism. */\n     paging_log_dirty_init(d, hap_enable_log_dirty,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    d->arch.paging.gfn_bits = hap_paddr_bits - PAGE_SHIFT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3960",
        "func_name": "xen-project/xen/guest_walk_tables",
        "description": "Integer overflow in the x86 shadow pagetable code in Xen allows local guest OS users to cause a denial of service (host crash) or possibly gain privileges by shadowing a superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/8b17648339ba801c4c7937b5f13dd25068e54e60",
        "commit_title": "x86: limit GFNs to 32 bits for shadowed superpages.",
        "commit_text": " Superpage shadows store the shadowed GFN in the backpointer field, which for non-BIGMEM builds is 32 bits wide.  Shadowing a superpage mapping of a guest-physical address above 2^44 would lead to the GFN being truncated there, and a crash when we come to remove the shadow from the hash table.  Track the valid width of a GFN for each guest, including reporting it through CPUID, and enforce it in the shadow pagetables.  Set the maximum witth to 32 for guests where this truncation could occur.  This is XSA-173. ",
        "func_before": "uint32_t\nguest_walk_tables(struct vcpu *v, struct p2m_domain *p2m,\n                  unsigned long va, walk_t *gw, \n                  uint32_t pfec, mfn_t top_mfn, void *top_map)\n{\n    struct domain *d = v->domain;\n    p2m_type_t p2mt;\n    guest_l1e_t *l1p = NULL;\n    guest_l2e_t *l2p = NULL;\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n    guest_l3e_t *l3p = NULL;\n    guest_l4e_t *l4p;\n#endif\n    unsigned int pkey;\n    uint32_t gflags, mflags, iflags, rc = 0;\n    bool_t smep = 0, smap = 0;\n    bool_t pse1G = 0, pse2M = 0;\n    p2m_query_t qt = P2M_ALLOC | P2M_UNSHARE;\n\n    perfc_incr(guest_walk);\n    memset(gw, 0, sizeof(*gw));\n    gw->va = va;\n\n    /* Mandatory bits that must be set in every entry.  We invert NX and\n     * the invalid bits, to calculate as if there were an \"X\" bit that\n     * allowed access.  We will accumulate, in rc, the set of flags that\n     * are missing/unwanted. */\n    mflags = mandatory_flags(v, pfec);\n    iflags = (_PAGE_NX_BIT | _PAGE_INVALID_BITS);\n\n    if ( is_hvm_domain(d) && !(pfec & PFEC_user_mode) )\n    {\n        struct segment_register seg;\n        const struct cpu_user_regs *regs = guest_cpu_user_regs();\n\n        /* SMEP: kernel-mode instruction fetches from user-mode mappings\n         * should fault.  Unlike NX or invalid bits, we're looking for _all_\n         * entries in the walk to have _PAGE_USER set, so we need to do the\n         * whole walk as if it were a user-mode one and then invert the answer. */\n        smep =  hvm_smep_enabled(v) && (pfec & PFEC_insn_fetch);\n\n        switch ( v->arch.smap_check_policy )\n        {\n        case SMAP_CHECK_HONOR_CPL_AC:\n            hvm_get_segment_register(v, x86_seg_ss, &seg);\n\n            /*\n             * SMAP: kernel-mode data accesses from user-mode mappings\n             * should fault.\n             * A fault is considered as a SMAP violation if the following\n             * conditions come true:\n             *   - X86_CR4_SMAP is set in CR4\n             *   - A user page is accessed\n             *   - CPL = 3 or X86_EFLAGS_AC is clear\n             *   - Page fault in kernel mode\n             */\n            smap = hvm_smap_enabled(v) &&\n                   ((seg.attr.fields.dpl == 3) ||\n                    !(regs->eflags & X86_EFLAGS_AC));\n            break;\n        case SMAP_CHECK_ENABLED:\n            smap = hvm_smap_enabled(v);\n            break;\n        default:\n            ASSERT(v->arch.smap_check_policy == SMAP_CHECK_DISABLED);\n            break;\n        }\n    }\n\n    if ( smep || smap )\n        mflags |= _PAGE_USER;\n\n#if GUEST_PAGING_LEVELS >= 3 /* PAE or 64... */\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n\n    /* Get the l4e from the top level table and check its flags*/\n    gw->l4mfn = top_mfn;\n    l4p = (guest_l4e_t *) top_map;\n    gw->l4e = l4p[guest_l4_table_offset(va)];\n    gflags = guest_l4e_get_flags(gw->l4e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    /* Map the l3 table */\n    l3p = map_domain_gfn(p2m, \n                         guest_l4e_get_gfn(gw->l4e), \n                         &gw->l3mfn,\n                         &p2mt,\n                         qt,\n                         &rc); \n    if(l3p == NULL)\n        goto out;\n    /* Get the l3e and check its flags*/\n    gw->l3e = l3p[guest_l3_table_offset(va)];\n    pkey = guest_l3e_get_pkey(gw->l3e);\n    gflags = guest_l3e_get_flags(gw->l3e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n    \n    pse1G = (gflags & _PAGE_PSE) && guest_supports_1G_superpages(v); \n\n    if ( pse1G )\n    {\n        /* Generate a fake l1 table entry so callers don't all \n         * have to understand superpages. */\n        gfn_t start = guest_l3e_get_gfn(gw->l3e);\n        /* Grant full access in the l1e, since all the guest entry's\n         * access controls are enforced in the l3e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l3e_get_flags(gw->l3e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( gfn_x(start) & GUEST_L3_GFN_MASK & ~0x1 )\n            rc |= _PAGE_INVALID_BITS;\n\n        /* Increment the pfn by the right number of 4k pages. */\n        start = _gfn((gfn_x(start) & ~GUEST_L3_GFN_MASK) +\n                     ((va >> PAGE_SHIFT) & GUEST_L3_GFN_MASK));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l2mfn = gw->l1mfn = _mfn(INVALID_MFN);\n        goto set_ad;\n    }\n\n#else /* PAE only... */\n\n    /* Get the l3e and check its flag */\n    gw->l3e = ((guest_l3e_t *) top_map)[guest_l3_table_offset(va)];\n    if ( !(guest_l3e_get_flags(gw->l3e) & _PAGE_PRESENT) ) \n    {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n\n#endif /* PAE or 64... */\n\n    /* Map the l2 table */\n    l2p = map_domain_gfn(p2m, \n                         guest_l3e_get_gfn(gw->l3e), \n                         &gw->l2mfn,\n                         &p2mt, \n                         qt,\n                         &rc); \n    if(l2p == NULL)\n        goto out;\n    /* Get the l2e */\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#else /* 32-bit only... */\n\n    /* Get l2e from the top level table */\n    gw->l2mfn = top_mfn;\n    l2p = (guest_l2e_t *) top_map;\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#endif /* All levels... */\n\n    pkey = guest_l2e_get_pkey(gw->l2e);\n    gflags = guest_l2e_get_flags(gw->l2e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    pse2M = (gflags & _PAGE_PSE) && guest_supports_superpages(v); \n\n    if ( pse2M )\n    {\n        /* Special case: this guest VA is in a PSE superpage, so there's\n         * no guest l1e.  We make one up so that the propagation code\n         * can generate a shadow l1 table.  Start with the gfn of the \n         * first 4k-page of the superpage. */\n        gfn_t start = guest_l2e_get_gfn(gw->l2e);\n        /* Grant full access in the l1e, since all the guest entry's \n         * access controls are enforced in the shadow l2e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l2e_get_flags(gw->l2e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( gfn_x(start) & GUEST_L2_GFN_MASK & ~0x1 )\n        {\n#if GUEST_PAGING_LEVELS == 2\n            /*\n             * Note that _PAGE_INVALID_BITS is zero in this case, yielding a\n             * no-op here.\n             *\n             * Architecturally, the walk should fail if bit 21 is set (others\n             * aren't being checked at least in PSE36 mode), but we'll ignore\n             * this here in order to avoid specifying a non-natural, non-zero\n             * _PAGE_INVALID_BITS value just for that case.\n             */\n#endif\n            rc |= _PAGE_INVALID_BITS;\n        }\n        /* Increment the pfn by the right number of 4k pages.  \n         * Mask out PAT and invalid bits. */\n        start = _gfn((gfn_x(start) & ~GUEST_L2_GFN_MASK) +\n                     guest_l1_table_offset(va));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l1mfn = _mfn(INVALID_MFN);\n    } \n    else \n    {\n        /* Not a superpage: carry on and find the l1e. */\n        l1p = map_domain_gfn(p2m, \n                             guest_l2e_get_gfn(gw->l2e), \n                             &gw->l1mfn,\n                             &p2mt,\n                             qt,\n                             &rc);\n        if(l1p == NULL)\n            goto out;\n        gw->l1e = l1p[guest_l1_table_offset(va)];\n        pkey = guest_l1e_get_pkey(gw->l1e);\n        gflags = guest_l1e_get_flags(gw->l1e) ^ iflags;\n        if ( !(gflags & _PAGE_PRESENT) ) {\n            rc |= _PAGE_PRESENT;\n            goto out;\n        }\n        rc |= ((gflags & mflags) ^ mflags);\n    }\n\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\nset_ad:\n    if ( pkey_fault(v, pfec, gflags, pkey) )\n        rc |= _PAGE_PKEY_BITS;\n#endif\n    /* Now re-invert the user-mode requirement for SMEP and SMAP */\n    if ( smep || smap )\n        rc ^= _PAGE_USER;\n\n    /* Go back and set accessed and dirty bits only if the walk was a\n     * success.  Although the PRMs say higher-level _PAGE_ACCESSED bits\n     * get set whenever a lower-level PT is used, at least some hardware\n     * walkers behave this way. */\n    if ( rc == 0 ) \n    {\n#if GUEST_PAGING_LEVELS == 4 /* 64-bit only... */\n        if ( set_ad_bits(l4p + guest_l4_table_offset(va), &gw->l4e, 0) )\n            paging_mark_dirty(d, mfn_x(gw->l4mfn));\n        if ( set_ad_bits(l3p + guest_l3_table_offset(va), &gw->l3e,\n                         (pse1G && (pfec & PFEC_write_access))) )\n            paging_mark_dirty(d, mfn_x(gw->l3mfn));\n#endif\n        if ( !pse1G ) \n        {\n            if ( set_ad_bits(l2p + guest_l2_table_offset(va), &gw->l2e,\n                             (pse2M && (pfec & PFEC_write_access))) )\n                paging_mark_dirty(d, mfn_x(gw->l2mfn));            \n            if ( !pse2M ) \n            {\n                if ( set_ad_bits(l1p + guest_l1_table_offset(va), &gw->l1e, \n                                 (pfec & PFEC_write_access)) )\n                    paging_mark_dirty(d, mfn_x(gw->l1mfn));\n            }\n        }\n    }\n\n out:\n#if GUEST_PAGING_LEVELS == 4\n    if ( l3p ) \n    {\n        unmap_domain_page(l3p);\n        put_page(mfn_to_page(mfn_x(gw->l3mfn)));\n    }\n#endif\n#if GUEST_PAGING_LEVELS >= 3\n    if ( l2p ) \n    {\n        unmap_domain_page(l2p);\n        put_page(mfn_to_page(mfn_x(gw->l2mfn)));\n    }\n#endif\n    if ( l1p ) \n    {\n        unmap_domain_page(l1p);\n        put_page(mfn_to_page(mfn_x(gw->l1mfn)));\n    }\n\n    return rc;\n}",
        "func": "uint32_t\nguest_walk_tables(struct vcpu *v, struct p2m_domain *p2m,\n                  unsigned long va, walk_t *gw, \n                  uint32_t pfec, mfn_t top_mfn, void *top_map)\n{\n    struct domain *d = v->domain;\n    p2m_type_t p2mt;\n    guest_l1e_t *l1p = NULL;\n    guest_l2e_t *l2p = NULL;\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n    guest_l3e_t *l3p = NULL;\n    guest_l4e_t *l4p;\n#endif\n    unsigned int pkey;\n    uint32_t gflags, mflags, iflags, rc = 0;\n    bool_t smep = 0, smap = 0;\n    bool_t pse1G = 0, pse2M = 0;\n    p2m_query_t qt = P2M_ALLOC | P2M_UNSHARE;\n\n    perfc_incr(guest_walk);\n    memset(gw, 0, sizeof(*gw));\n    gw->va = va;\n\n    /* Mandatory bits that must be set in every entry.  We invert NX and\n     * the invalid bits, to calculate as if there were an \"X\" bit that\n     * allowed access.  We will accumulate, in rc, the set of flags that\n     * are missing/unwanted. */\n    mflags = mandatory_flags(v, pfec);\n    iflags = (_PAGE_NX_BIT | _PAGE_INVALID_BITS);\n\n    if ( is_hvm_domain(d) && !(pfec & PFEC_user_mode) )\n    {\n        struct segment_register seg;\n        const struct cpu_user_regs *regs = guest_cpu_user_regs();\n\n        /* SMEP: kernel-mode instruction fetches from user-mode mappings\n         * should fault.  Unlike NX or invalid bits, we're looking for _all_\n         * entries in the walk to have _PAGE_USER set, so we need to do the\n         * whole walk as if it were a user-mode one and then invert the answer. */\n        smep =  hvm_smep_enabled(v) && (pfec & PFEC_insn_fetch);\n\n        switch ( v->arch.smap_check_policy )\n        {\n        case SMAP_CHECK_HONOR_CPL_AC:\n            hvm_get_segment_register(v, x86_seg_ss, &seg);\n\n            /*\n             * SMAP: kernel-mode data accesses from user-mode mappings\n             * should fault.\n             * A fault is considered as a SMAP violation if the following\n             * conditions come true:\n             *   - X86_CR4_SMAP is set in CR4\n             *   - A user page is accessed\n             *   - CPL = 3 or X86_EFLAGS_AC is clear\n             *   - Page fault in kernel mode\n             */\n            smap = hvm_smap_enabled(v) &&\n                   ((seg.attr.fields.dpl == 3) ||\n                    !(regs->eflags & X86_EFLAGS_AC));\n            break;\n        case SMAP_CHECK_ENABLED:\n            smap = hvm_smap_enabled(v);\n            break;\n        default:\n            ASSERT(v->arch.smap_check_policy == SMAP_CHECK_DISABLED);\n            break;\n        }\n    }\n\n    if ( smep || smap )\n        mflags |= _PAGE_USER;\n\n#if GUEST_PAGING_LEVELS >= 3 /* PAE or 64... */\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n\n    /* Get the l4e from the top level table and check its flags*/\n    gw->l4mfn = top_mfn;\n    l4p = (guest_l4e_t *) top_map;\n    gw->l4e = l4p[guest_l4_table_offset(va)];\n    gflags = guest_l4e_get_flags(gw->l4e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    /* Map the l3 table */\n    l3p = map_domain_gfn(p2m, \n                         guest_l4e_get_gfn(gw->l4e), \n                         &gw->l3mfn,\n                         &p2mt,\n                         qt,\n                         &rc); \n    if(l3p == NULL)\n        goto out;\n    /* Get the l3e and check its flags*/\n    gw->l3e = l3p[guest_l3_table_offset(va)];\n    pkey = guest_l3e_get_pkey(gw->l3e);\n    gflags = guest_l3e_get_flags(gw->l3e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n    \n    pse1G = (gflags & _PAGE_PSE) && guest_supports_1G_superpages(v); \n\n    if ( pse1G )\n    {\n        /* Generate a fake l1 table entry so callers don't all \n         * have to understand superpages. */\n        gfn_t start = guest_l3e_get_gfn(gw->l3e);\n        /* Grant full access in the l1e, since all the guest entry's\n         * access controls are enforced in the l3e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l3e_get_flags(gw->l3e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( gfn_x(start) & GUEST_L3_GFN_MASK & ~0x1 )\n            rc |= _PAGE_INVALID_BITS;\n\n        /* Increment the pfn by the right number of 4k pages. */\n        start = _gfn((gfn_x(start) & ~GUEST_L3_GFN_MASK) +\n                     ((va >> PAGE_SHIFT) & GUEST_L3_GFN_MASK));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l2mfn = gw->l1mfn = _mfn(INVALID_MFN);\n        goto set_ad;\n    }\n\n#else /* PAE only... */\n\n    /* Get the l3e and check its flag */\n    gw->l3e = ((guest_l3e_t *) top_map)[guest_l3_table_offset(va)];\n    if ( !(guest_l3e_get_flags(gw->l3e) & _PAGE_PRESENT) ) \n    {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n\n#endif /* PAE or 64... */\n\n    /* Map the l2 table */\n    l2p = map_domain_gfn(p2m, \n                         guest_l3e_get_gfn(gw->l3e), \n                         &gw->l2mfn,\n                         &p2mt, \n                         qt,\n                         &rc); \n    if(l2p == NULL)\n        goto out;\n    /* Get the l2e */\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#else /* 32-bit only... */\n\n    /* Get l2e from the top level table */\n    gw->l2mfn = top_mfn;\n    l2p = (guest_l2e_t *) top_map;\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#endif /* All levels... */\n\n    pkey = guest_l2e_get_pkey(gw->l2e);\n    gflags = guest_l2e_get_flags(gw->l2e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    pse2M = (gflags & _PAGE_PSE) && guest_supports_superpages(v); \n\n    if ( pse2M )\n    {\n        /* Special case: this guest VA is in a PSE superpage, so there's\n         * no guest l1e.  We make one up so that the propagation code\n         * can generate a shadow l1 table.  Start with the gfn of the \n         * first 4k-page of the superpage. */\n        gfn_t start = guest_l2e_get_gfn(gw->l2e);\n        /* Grant full access in the l1e, since all the guest entry's \n         * access controls are enforced in the shadow l2e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l2e_get_flags(gw->l2e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( gfn_x(start) & GUEST_L2_GFN_MASK & ~0x1 )\n            rc |= _PAGE_INVALID_BITS;\n\n        /* Increment the pfn by the right number of 4k pages.  \n         * Mask out PAT and invalid bits. */\n        start = _gfn((gfn_x(start) & ~GUEST_L2_GFN_MASK) +\n                     guest_l1_table_offset(va));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l1mfn = _mfn(INVALID_MFN);\n    } \n    else \n    {\n        /* Not a superpage: carry on and find the l1e. */\n        l1p = map_domain_gfn(p2m, \n                             guest_l2e_get_gfn(gw->l2e), \n                             &gw->l1mfn,\n                             &p2mt,\n                             qt,\n                             &rc);\n        if(l1p == NULL)\n            goto out;\n        gw->l1e = l1p[guest_l1_table_offset(va)];\n        pkey = guest_l1e_get_pkey(gw->l1e);\n        gflags = guest_l1e_get_flags(gw->l1e) ^ iflags;\n        if ( !(gflags & _PAGE_PRESENT) ) {\n            rc |= _PAGE_PRESENT;\n            goto out;\n        }\n        rc |= ((gflags & mflags) ^ mflags);\n    }\n\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\nset_ad:\n    if ( pkey_fault(v, pfec, gflags, pkey) )\n        rc |= _PAGE_PKEY_BITS;\n#endif\n    /* Now re-invert the user-mode requirement for SMEP and SMAP */\n    if ( smep || smap )\n        rc ^= _PAGE_USER;\n\n    /* Go back and set accessed and dirty bits only if the walk was a\n     * success.  Although the PRMs say higher-level _PAGE_ACCESSED bits\n     * get set whenever a lower-level PT is used, at least some hardware\n     * walkers behave this way. */\n    if ( rc == 0 ) \n    {\n#if GUEST_PAGING_LEVELS == 4 /* 64-bit only... */\n        if ( set_ad_bits(l4p + guest_l4_table_offset(va), &gw->l4e, 0) )\n            paging_mark_dirty(d, mfn_x(gw->l4mfn));\n        if ( set_ad_bits(l3p + guest_l3_table_offset(va), &gw->l3e,\n                         (pse1G && (pfec & PFEC_write_access))) )\n            paging_mark_dirty(d, mfn_x(gw->l3mfn));\n#endif\n        if ( !pse1G ) \n        {\n            if ( set_ad_bits(l2p + guest_l2_table_offset(va), &gw->l2e,\n                             (pse2M && (pfec & PFEC_write_access))) )\n                paging_mark_dirty(d, mfn_x(gw->l2mfn));            \n            if ( !pse2M ) \n            {\n                if ( set_ad_bits(l1p + guest_l1_table_offset(va), &gw->l1e, \n                                 (pfec & PFEC_write_access)) )\n                    paging_mark_dirty(d, mfn_x(gw->l1mfn));\n            }\n        }\n    }\n\n out:\n#if GUEST_PAGING_LEVELS == 4\n    if ( l3p ) \n    {\n        unmap_domain_page(l3p);\n        put_page(mfn_to_page(mfn_x(gw->l3mfn)));\n    }\n#endif\n#if GUEST_PAGING_LEVELS >= 3\n    if ( l2p ) \n    {\n        unmap_domain_page(l2p);\n        put_page(mfn_to_page(mfn_x(gw->l2mfn)));\n    }\n#endif\n    if ( l1p ) \n    {\n        unmap_domain_page(l1p);\n        put_page(mfn_to_page(mfn_x(gw->l1mfn)));\n    }\n\n    /* If this guest has a restricted physical address space then the\n     * target GFN must fit within it. */\n    if ( !(rc & _PAGE_PRESENT)\n         && gfn_x(guest_l1e_get_gfn(gw->l1e)) >> d->arch.paging.gfn_bits )\n        rc |= _PAGE_INVALID_BITS;\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -198,20 +198,8 @@\n             flags &= ~_PAGE_PAT;\n \n         if ( gfn_x(start) & GUEST_L2_GFN_MASK & ~0x1 )\n-        {\n-#if GUEST_PAGING_LEVELS == 2\n-            /*\n-             * Note that _PAGE_INVALID_BITS is zero in this case, yielding a\n-             * no-op here.\n-             *\n-             * Architecturally, the walk should fail if bit 21 is set (others\n-             * aren't being checked at least in PSE36 mode), but we'll ignore\n-             * this here in order to avoid specifying a non-natural, non-zero\n-             * _PAGE_INVALID_BITS value just for that case.\n-             */\n-#endif\n             rc |= _PAGE_INVALID_BITS;\n-        }\n+\n         /* Increment the pfn by the right number of 4k pages.  \n          * Mask out PAT and invalid bits. */\n         start = _gfn((gfn_x(start) & ~GUEST_L2_GFN_MASK) +\n@@ -297,5 +285,11 @@\n         put_page(mfn_to_page(mfn_x(gw->l1mfn)));\n     }\n \n+    /* If this guest has a restricted physical address space then the\n+     * target GFN must fit within it. */\n+    if ( !(rc & _PAGE_PRESENT)\n+         && gfn_x(guest_l1e_get_gfn(gw->l1e)) >> d->arch.paging.gfn_bits )\n+        rc |= _PAGE_INVALID_BITS;\n+\n     return rc;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        {",
                "#if GUEST_PAGING_LEVELS == 2",
                "            /*",
                "             * Note that _PAGE_INVALID_BITS is zero in this case, yielding a",
                "             * no-op here.",
                "             *",
                "             * Architecturally, the walk should fail if bit 21 is set (others",
                "             * aren't being checked at least in PSE36 mode), but we'll ignore",
                "             * this here in order to avoid specifying a non-natural, non-zero",
                "             * _PAGE_INVALID_BITS value just for that case.",
                "             */",
                "#endif",
                "        }"
            ],
            "added_lines": [
                "",
                "    /* If this guest has a restricted physical address space then the",
                "     * target GFN must fit within it. */",
                "    if ( !(rc & _PAGE_PRESENT)",
                "         && gfn_x(guest_l1e_get_gfn(gw->l1e)) >> d->arch.paging.gfn_bits )",
                "        rc |= _PAGE_INVALID_BITS;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3960",
        "func_name": "xen-project/xen/early_cpu_detect",
        "description": "Integer overflow in the x86 shadow pagetable code in Xen allows local guest OS users to cause a denial of service (host crash) or possibly gain privileges by shadowing a superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/8b17648339ba801c4c7937b5f13dd25068e54e60",
        "commit_title": "x86: limit GFNs to 32 bits for shadowed superpages.",
        "commit_text": " Superpage shadows store the shadowed GFN in the backpointer field, which for non-BIGMEM builds is 32 bits wide.  Shadowing a superpage mapping of a guest-physical address above 2^44 would lead to the GFN being truncated there, and a crash when we come to remove the shadow from the hash table.  Track the valid width of a GFN for each guest, including reporting it through CPUID, and enforce it in the shadow pagetables.  Set the maximum witth to 32 for guests where this truncation could occur.  This is XSA-173. ",
        "func_before": "static void __init early_cpu_detect(void)\n{\n\tstruct cpuinfo_x86 *c = &boot_cpu_data;\n\tu32 eax, ebx, ecx, edx;\n\n\tc->x86_cache_alignment = 32;\n\n\t/* Get vendor name */\n\tcpuid(0x00000000, &c->cpuid_level,\n\t      (int *)&c->x86_vendor_id[0],\n\t      (int *)&c->x86_vendor_id[8],\n\t      (int *)&c->x86_vendor_id[4]);\n\n\tc->x86_vendor = get_cpu_vendor(c->x86_vendor_id, gcv_host_early);\n\n\tcpuid(0x00000001, &eax, &ebx, &ecx, &edx);\n\tc->x86 = (eax >> 8) & 15;\n\tc->x86_model = (eax >> 4) & 15;\n\tif (c->x86 == 0xf)\n\t\tc->x86 += (eax >> 20) & 0xff;\n\tif (c->x86 >= 0x6)\n\t\tc->x86_model += ((eax >> 16) & 0xF) << 4;\n\tc->x86_mask = eax & 15;\n\tedx &= ~cleared_caps[cpufeat_word(X86_FEATURE_FPU)];\n\tecx &= ~cleared_caps[cpufeat_word(X86_FEATURE_SSE3)];\n\tif (edx & cpufeat_mask(X86_FEATURE_CLFLUSH))\n\t\tc->x86_cache_alignment = ((ebx >> 8) & 0xff) * 8;\n\t/* Leaf 0x1 capabilities filled in early for Xen. */\n\tc->x86_capability[cpufeat_word(X86_FEATURE_FPU)] = edx;\n\tc->x86_capability[cpufeat_word(X86_FEATURE_SSE3)] = ecx;\n\n\tif ( cpuid_eax(0x80000000) >= 0x80000008 )\n\t\tpaddr_bits = cpuid_eax(0x80000008) & 0xff;\n}",
        "func": "static void __init early_cpu_detect(void)\n{\n\tstruct cpuinfo_x86 *c = &boot_cpu_data;\n\tu32 eax, ebx, ecx, edx;\n\n\tc->x86_cache_alignment = 32;\n\n\t/* Get vendor name */\n\tcpuid(0x00000000, &c->cpuid_level,\n\t      (int *)&c->x86_vendor_id[0],\n\t      (int *)&c->x86_vendor_id[8],\n\t      (int *)&c->x86_vendor_id[4]);\n\n\tc->x86_vendor = get_cpu_vendor(c->x86_vendor_id, gcv_host_early);\n\n\tcpuid(0x00000001, &eax, &ebx, &ecx, &edx);\n\tc->x86 = (eax >> 8) & 15;\n\tc->x86_model = (eax >> 4) & 15;\n\tif (c->x86 == 0xf)\n\t\tc->x86 += (eax >> 20) & 0xff;\n\tif (c->x86 >= 0x6)\n\t\tc->x86_model += ((eax >> 16) & 0xF) << 4;\n\tc->x86_mask = eax & 15;\n\tedx &= ~cleared_caps[cpufeat_word(X86_FEATURE_FPU)];\n\tecx &= ~cleared_caps[cpufeat_word(X86_FEATURE_SSE3)];\n\tif (edx & cpufeat_mask(X86_FEATURE_CLFLUSH))\n\t\tc->x86_cache_alignment = ((ebx >> 8) & 0xff) * 8;\n\t/* Leaf 0x1 capabilities filled in early for Xen. */\n\tc->x86_capability[cpufeat_word(X86_FEATURE_FPU)] = edx;\n\tc->x86_capability[cpufeat_word(X86_FEATURE_SSE3)] = ecx;\n\n\tif ( cpuid_eax(0x80000000) >= 0x80000008 ) {\n\t\teax = cpuid_eax(0x80000008);\n\t\tpaddr_bits = eax & 0xff;\n\t\thap_paddr_bits = ((eax >> 16) & 0xff) ?: paddr_bits;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,6 +29,9 @@\n \tc->x86_capability[cpufeat_word(X86_FEATURE_FPU)] = edx;\n \tc->x86_capability[cpufeat_word(X86_FEATURE_SSE3)] = ecx;\n \n-\tif ( cpuid_eax(0x80000000) >= 0x80000008 )\n-\t\tpaddr_bits = cpuid_eax(0x80000008) & 0xff;\n+\tif ( cpuid_eax(0x80000000) >= 0x80000008 ) {\n+\t\teax = cpuid_eax(0x80000008);\n+\t\tpaddr_bits = eax & 0xff;\n+\t\thap_paddr_bits = ((eax >> 16) & 0xff) ?: paddr_bits;\n+\t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ( cpuid_eax(0x80000000) >= 0x80000008 )",
                "\t\tpaddr_bits = cpuid_eax(0x80000008) & 0xff;"
            ],
            "added_lines": [
                "\tif ( cpuid_eax(0x80000000) >= 0x80000008 ) {",
                "\t\teax = cpuid_eax(0x80000008);",
                "\t\tpaddr_bits = eax & 0xff;",
                "\t\thap_paddr_bits = ((eax >> 16) & 0xff) ?: paddr_bits;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3960",
        "func_name": "xen-project/xen/map_domain_gfn",
        "description": "Integer overflow in the x86 shadow pagetable code in Xen allows local guest OS users to cause a denial of service (host crash) or possibly gain privileges by shadowing a superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/8b17648339ba801c4c7937b5f13dd25068e54e60",
        "commit_title": "x86: limit GFNs to 32 bits for shadowed superpages.",
        "commit_text": " Superpage shadows store the shadowed GFN in the backpointer field, which for non-BIGMEM builds is 32 bits wide.  Shadowing a superpage mapping of a guest-physical address above 2^44 would lead to the GFN being truncated there, and a crash when we come to remove the shadow from the hash table.  Track the valid width of a GFN for each guest, including reporting it through CPUID, and enforce it in the shadow pagetables.  Set the maximum witth to 32 for guests where this truncation could occur.  This is XSA-173. ",
        "func_before": "void *map_domain_gfn(struct p2m_domain *p2m, gfn_t gfn, mfn_t *mfn,\n                     p2m_type_t *p2mt, p2m_query_t q, uint32_t *rc)\n{\n    struct page_info *page;\n\n    /* Translate the gfn, unsharing if shared. */\n    page = get_page_from_gfn_p2m(p2m->domain, p2m, gfn_x(gfn), p2mt, NULL, q);\n    if ( p2m_is_paging(*p2mt) )\n    {\n        ASSERT(p2m_is_hostp2m(p2m));\n        if ( page )\n            put_page(page);\n        p2m_mem_paging_populate(p2m->domain, gfn_x(gfn));\n        *rc = _PAGE_PAGED;\n        return NULL;\n    }\n    if ( p2m_is_shared(*p2mt) )\n    {\n        if ( page )\n            put_page(page);\n        *rc = _PAGE_SHARED;\n        return NULL;\n    }\n    if ( !page )\n    {\n        *rc |= _PAGE_PRESENT;\n        return NULL;\n    }\n    *mfn = page_to_mfn(page);\n    ASSERT(mfn_valid(*mfn));\n\n    return map_domain_page(*mfn);\n}",
        "func": "void *map_domain_gfn(struct p2m_domain *p2m, gfn_t gfn, mfn_t *mfn,\n                     p2m_type_t *p2mt, p2m_query_t q, uint32_t *rc)\n{\n    struct page_info *page;\n\n    if ( gfn_x(gfn) >> p2m->domain->arch.paging.gfn_bits )\n    {\n        *rc = _PAGE_INVALID_BIT;\n        return NULL;\n    }\n\n    /* Translate the gfn, unsharing if shared. */\n    page = get_page_from_gfn_p2m(p2m->domain, p2m, gfn_x(gfn), p2mt, NULL, q);\n    if ( p2m_is_paging(*p2mt) )\n    {\n        ASSERT(p2m_is_hostp2m(p2m));\n        if ( page )\n            put_page(page);\n        p2m_mem_paging_populate(p2m->domain, gfn_x(gfn));\n        *rc = _PAGE_PAGED;\n        return NULL;\n    }\n    if ( p2m_is_shared(*p2mt) )\n    {\n        if ( page )\n            put_page(page);\n        *rc = _PAGE_SHARED;\n        return NULL;\n    }\n    if ( !page )\n    {\n        *rc |= _PAGE_PRESENT;\n        return NULL;\n    }\n    *mfn = page_to_mfn(page);\n    ASSERT(mfn_valid(*mfn));\n\n    return map_domain_page(*mfn);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,12 @@\n                      p2m_type_t *p2mt, p2m_query_t q, uint32_t *rc)\n {\n     struct page_info *page;\n+\n+    if ( gfn_x(gfn) >> p2m->domain->arch.paging.gfn_bits )\n+    {\n+        *rc = _PAGE_INVALID_BIT;\n+        return NULL;\n+    }\n \n     /* Translate the gfn, unsharing if shared. */\n     page = get_page_from_gfn_p2m(p2m->domain, p2m, gfn_x(gfn), p2mt, NULL, q);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if ( gfn_x(gfn) >> p2m->domain->arch.paging.gfn_bits )",
                "    {",
                "        *rc = _PAGE_INVALID_BIT;",
                "        return NULL;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3960",
        "func_name": "xen-project/xen/early_cpu_detect",
        "description": "Integer overflow in the x86 shadow pagetable code in Xen allows local guest OS users to cause a denial of service (host crash) or possibly gain privileges by shadowing a superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/8b17648339ba801c4c7937b5f13dd25068e54e60",
        "commit_title": "x86: limit GFNs to 32 bits for shadowed superpages.",
        "commit_text": " Superpage shadows store the shadowed GFN in the backpointer field, which for non-BIGMEM builds is 32 bits wide.  Shadowing a superpage mapping of a guest-physical address above 2^44 would lead to the GFN being truncated there, and a crash when we come to remove the shadow from the hash table.  Track the valid width of a GFN for each guest, including reporting it through CPUID, and enforce it in the shadow pagetables.  Set the maximum witth to 32 for guests where this truncation could occur.  This is XSA-173. ",
        "func_before": "static void __init early_cpu_detect(void)\n{\n\tstruct cpuinfo_x86 *c = &boot_cpu_data;\n\tu32 eax, ebx, ecx, edx;\n\n\tc->x86_cache_alignment = 32;\n\n\t/* Get vendor name */\n\tcpuid(0x00000000, &c->cpuid_level,\n\t      (int *)&c->x86_vendor_id[0],\n\t      (int *)&c->x86_vendor_id[8],\n\t      (int *)&c->x86_vendor_id[4]);\n\n\tc->x86_vendor = get_cpu_vendor(c->x86_vendor_id, gcv_host_early);\n\n\tcpuid(0x00000001, &eax, &ebx, &ecx, &edx);\n\tc->x86 = (eax >> 8) & 15;\n\tc->x86_model = (eax >> 4) & 15;\n\tif (c->x86 == 0xf)\n\t\tc->x86 += (eax >> 20) & 0xff;\n\tif (c->x86 >= 0x6)\n\t\tc->x86_model += ((eax >> 16) & 0xF) << 4;\n\tc->x86_mask = eax & 15;\n\tedx &= ~cleared_caps[cpufeat_word(X86_FEATURE_FPU)];\n\tecx &= ~cleared_caps[cpufeat_word(X86_FEATURE_SSE3)];\n\tif (edx & cpufeat_mask(X86_FEATURE_CLFLUSH))\n\t\tc->x86_cache_alignment = ((ebx >> 8) & 0xff) * 8;\n\t/* Leaf 0x1 capabilities filled in early for Xen. */\n\tc->x86_capability[cpufeat_word(X86_FEATURE_FPU)] = edx;\n\tc->x86_capability[cpufeat_word(X86_FEATURE_SSE3)] = ecx;\n\n\tif ( cpuid_eax(0x80000000) >= 0x80000008 )\n\t\tpaddr_bits = cpuid_eax(0x80000008) & 0xff;\n}",
        "func": "static void __init early_cpu_detect(void)\n{\n\tstruct cpuinfo_x86 *c = &boot_cpu_data;\n\tu32 eax, ebx, ecx, edx;\n\n\tc->x86_cache_alignment = 32;\n\n\t/* Get vendor name */\n\tcpuid(0x00000000, &c->cpuid_level,\n\t      (int *)&c->x86_vendor_id[0],\n\t      (int *)&c->x86_vendor_id[8],\n\t      (int *)&c->x86_vendor_id[4]);\n\n\tc->x86_vendor = get_cpu_vendor(c->x86_vendor_id, gcv_host_early);\n\n\tcpuid(0x00000001, &eax, &ebx, &ecx, &edx);\n\tc->x86 = (eax >> 8) & 15;\n\tc->x86_model = (eax >> 4) & 15;\n\tif (c->x86 == 0xf)\n\t\tc->x86 += (eax >> 20) & 0xff;\n\tif (c->x86 >= 0x6)\n\t\tc->x86_model += ((eax >> 16) & 0xF) << 4;\n\tc->x86_mask = eax & 15;\n\tedx &= ~cleared_caps[cpufeat_word(X86_FEATURE_FPU)];\n\tecx &= ~cleared_caps[cpufeat_word(X86_FEATURE_SSE3)];\n\tif (edx & cpufeat_mask(X86_FEATURE_CLFLUSH))\n\t\tc->x86_cache_alignment = ((ebx >> 8) & 0xff) * 8;\n\t/* Leaf 0x1 capabilities filled in early for Xen. */\n\tc->x86_capability[cpufeat_word(X86_FEATURE_FPU)] = edx;\n\tc->x86_capability[cpufeat_word(X86_FEATURE_SSE3)] = ecx;\n\n\tif ( cpuid_eax(0x80000000) >= 0x80000008 ) {\n\t\teax = cpuid_eax(0x80000008);\n\t\tpaddr_bits = eax & 0xff;\n\t\thap_paddr_bits = ((eax >> 16) & 0xff) ?: paddr_bits;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,6 +29,9 @@\n \tc->x86_capability[cpufeat_word(X86_FEATURE_FPU)] = edx;\n \tc->x86_capability[cpufeat_word(X86_FEATURE_SSE3)] = ecx;\n \n-\tif ( cpuid_eax(0x80000000) >= 0x80000008 )\n-\t\tpaddr_bits = cpuid_eax(0x80000008) & 0xff;\n+\tif ( cpuid_eax(0x80000000) >= 0x80000008 ) {\n+\t\teax = cpuid_eax(0x80000008);\n+\t\tpaddr_bits = eax & 0xff;\n+\t\thap_paddr_bits = ((eax >> 16) & 0xff) ?: paddr_bits;\n+\t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ( cpuid_eax(0x80000000) >= 0x80000008 )",
                "\t\tpaddr_bits = cpuid_eax(0x80000008) & 0xff;"
            ],
            "added_lines": [
                "\tif ( cpuid_eax(0x80000000) >= 0x80000008 ) {",
                "\t\teax = cpuid_eax(0x80000008);",
                "\t\tpaddr_bits = eax & 0xff;",
                "\t\thap_paddr_bits = ((eax >> 16) & 0xff) ?: paddr_bits;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3960",
        "func_name": "xen-project/xen/hvm_cpuid",
        "description": "Integer overflow in the x86 shadow pagetable code in Xen allows local guest OS users to cause a denial of service (host crash) or possibly gain privileges by shadowing a superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/8b17648339ba801c4c7937b5f13dd25068e54e60",
        "commit_title": "x86: limit GFNs to 32 bits for shadowed superpages.",
        "commit_text": " Superpage shadows store the shadowed GFN in the backpointer field, which for non-BIGMEM builds is 32 bits wide.  Shadowing a superpage mapping of a guest-physical address above 2^44 would lead to the GFN being truncated there, and a crash when we come to remove the shadow from the hash table.  Track the valid width of a GFN for each guest, including reporting it through CPUID, and enforce it in the shadow pagetables.  Set the maximum witth to 32 for guests where this truncation could occur.  This is XSA-173. ",
        "func_before": "void hvm_cpuid(unsigned int input, unsigned int *eax, unsigned int *ebx,\n                                   unsigned int *ecx, unsigned int *edx)\n{\n    struct vcpu *v = current;\n    struct domain *d = v->domain;\n    unsigned int count, dummy = 0;\n\n    if ( !eax )\n        eax = &dummy;\n    if ( !ebx )\n        ebx = &dummy;\n    if ( !ecx )\n        ecx = &dummy;\n    count = *ecx;\n    if ( !edx )\n        edx = &dummy;\n\n    if ( cpuid_viridian_leaves(input, eax, ebx, ecx, edx) )\n        return;\n\n    if ( cpuid_hypervisor_leaves(input, count, eax, ebx, ecx, edx) )\n        return;\n\n    domain_cpuid(d, input, count, eax, ebx, ecx, edx);\n\n    switch ( input )\n    {\n        unsigned int sub_leaf, _eax, _ebx, _ecx, _edx;\n\n    case 0x1:\n        /* Fix up VLAPIC details. */\n        *ebx &= 0x00FFFFFFu;\n        *ebx |= (v->vcpu_id * 2) << 24;\n\n        *ecx &= hvm_featureset[FEATURESET_1c];\n        *edx &= hvm_featureset[FEATURESET_1d];\n\n        /* APIC exposed to guests, but Fast-forward MSR_APIC_BASE.EN back in. */\n        if ( vlapic_hw_disabled(vcpu_vlapic(v)) )\n            *edx &= ~cpufeat_bit(X86_FEATURE_APIC);\n\n        /* OSXSAVE cleared by hvm_featureset.  Fast-forward CR4 back in. */\n        if ( v->arch.hvm_vcpu.guest_cr[4] & X86_CR4_OSXSAVE )\n            *ecx |= cpufeat_mask(X86_FEATURE_OSXSAVE);\n\n        /* Don't expose HAP-only features to non-hap guests. */\n        if ( !hap_enabled(d) )\n        {\n            *ecx &= ~cpufeat_mask(X86_FEATURE_PCID);\n\n            /*\n             * PSE36 is not supported in shadow mode.  This bit should be\n             * unilaterally cleared.\n             *\n             * However, an unspecified version of Hyper-V from 2011 refuses\n             * to start as the \"cpu does not provide required hw features\" if\n             * it can't see PSE36.\n             *\n             * As a workaround, leak the toolstack-provided PSE36 value into a\n             * shadow guest if the guest is already using PAE paging (and\n             * won't care about reverting back to PSE paging).  Otherwise,\n             * knoble it, so a 32bit guest doesn't get the impression that it\n             * could try to use PSE36 paging.\n             */\n            if ( !(hvm_pae_enabled(v) || hvm_long_mode_enabled(v)) )\n                *edx &= ~cpufeat_mask(X86_FEATURE_PSE36);\n        }\n        break;\n\n    case 0x7:\n        if ( count == 0 )\n        {\n            /* Fold host's FDP_EXCP_ONLY and NO_FPU_SEL into guest's view. */\n            *ebx &= (hvm_featureset[FEATURESET_7b0] &\n                     ~special_features[FEATURESET_7b0]);\n            *ebx |= (host_featureset[FEATURESET_7b0] &\n                     special_features[FEATURESET_7b0]);\n\n            *ecx &= hvm_featureset[FEATURESET_7c0];\n\n            /* Don't expose HAP-only features to non-hap guests. */\n            if ( !hap_enabled(d) )\n            {\n                 *ebx &= ~cpufeat_mask(X86_FEATURE_INVPCID);\n                 *ecx &= ~cpufeat_mask(X86_FEATURE_PKU);\n            }\n\n            /* OSPKE cleared by hvm_featureset.  Fast-forward CR4 back in. */\n            if ( v->arch.hvm_vcpu.guest_cr[4] & X86_CR4_PKE )\n                *ecx |= cpufeat_mask(X86_FEATURE_OSPKE);\n        }\n        break;\n\n    case 0xb:\n        /* Fix the x2APIC identifier. */\n        *edx = v->vcpu_id * 2;\n        break;\n\n    case 0xd:\n        /* EBX value of main leaf 0 depends on enabled xsave features */\n        if ( count == 0 && v->arch.xcr0 ) \n        {\n            /* reset EBX to default value first */\n            *ebx = XSTATE_AREA_MIN_SIZE; \n            for ( sub_leaf = 2; sub_leaf < 63; sub_leaf++ )\n            {\n                if ( !(v->arch.xcr0 & (1ULL << sub_leaf)) )\n                    continue;\n                domain_cpuid(d, input, sub_leaf, &_eax, &_ebx, &_ecx, \n                             &_edx);\n                if ( (_eax + _ebx) > *ebx )\n                    *ebx = _eax + _ebx;\n            }\n        }\n\n        if ( count == 1 )\n        {\n            *eax &= hvm_featureset[FEATURESET_Da1];\n\n            if ( *eax & cpufeat_mask(X86_FEATURE_XSAVES) )\n            {\n                uint64_t xfeatures = v->arch.xcr0 | v->arch.hvm_vcpu.msr_xss;\n\n                *ebx = XSTATE_AREA_MIN_SIZE;\n                if ( xfeatures & ~XSTATE_FP_SSE )\n                    for ( sub_leaf = 2; sub_leaf < 63; sub_leaf++ )\n                        if ( xfeatures & (1ULL << sub_leaf) )\n                        {\n                            if ( test_bit(sub_leaf, &xstate_align) )\n                                *ebx = ROUNDUP(*ebx, 64);\n                            *ebx += xstate_sizes[sub_leaf];\n                        }\n            }\n            else\n                *ebx = *ecx = *edx = 0;\n        }\n        break;\n\n    case 0x80000001:\n        *ecx &= hvm_featureset[FEATURESET_e1c];\n        *edx &= hvm_featureset[FEATURESET_e1d];\n\n        /* If not emulating AMD, clear the duplicated features in e1d. */\n        if ( d->arch.x86_vendor != X86_VENDOR_AMD )\n            *edx &= ~CPUID_COMMON_1D_FEATURES;\n        /* fast-forward MSR_APIC_BASE.EN if it hasn't already been clobbered. */\n        else if ( vlapic_hw_disabled(vcpu_vlapic(v)) )\n            *edx &= ~cpufeat_bit(X86_FEATURE_APIC);\n\n        /* Don't expose HAP-only features to non-hap guests. */\n        if ( !hap_enabled(d) )\n        {\n            *edx &= ~cpufeat_mask(X86_FEATURE_PAGE1GB);\n\n            /*\n             * PSE36 is not supported in shadow mode.  This bit should be\n             * unilaterally cleared.\n             *\n             * However, an unspecified version of Hyper-V from 2011 refuses\n             * to start as the \"cpu does not provide required hw features\" if\n             * it can't see PSE36.\n             *\n             * As a workaround, leak the toolstack-provided PSE36 value into a\n             * shadow guest if the guest is already using PAE paging (and\n             * won't care about reverting back to PSE paging).  Otherwise,\n             * knoble it, so a 32bit guest doesn't get the impression that it\n             * could try to use PSE36 paging.\n             */\n            if ( !(hvm_pae_enabled(v) || hvm_long_mode_enabled(v)) )\n                *edx &= ~cpufeat_mask(X86_FEATURE_PSE36);\n        }\n        break;\n\n    case 0x80000007:\n        *edx &= hvm_featureset[FEATURESET_e7d];\n        break;\n\n    case 0x80000008:\n        count = cpuid_eax(0x80000008);\n        count = (count >> 16) & 0xff ?: count & 0xff;\n        if ( (*eax & 0xff) > count )\n            *eax = (*eax & ~0xff) | count;\n\n        hvm_cpuid(1, NULL, NULL, NULL, &_edx);\n        count = _edx & (cpufeat_mask(X86_FEATURE_PAE) |\n                        cpufeat_mask(X86_FEATURE_PSE36)) ? 36 : 32;\n        if ( (*eax & 0xff) < count )\n            *eax = (*eax & ~0xff) | count;\n\n        hvm_cpuid(0x80000001, NULL, NULL, NULL, &_edx);\n        *eax = (*eax & ~0xffff00) | (_edx & cpufeat_mask(X86_FEATURE_LM)\n                                     ? 0x3000 : 0x2000);\n\n        *ebx &= hvm_featureset[FEATURESET_e8b];\n        break;\n    }\n}",
        "func": "void hvm_cpuid(unsigned int input, unsigned int *eax, unsigned int *ebx,\n                                   unsigned int *ecx, unsigned int *edx)\n{\n    struct vcpu *v = current;\n    struct domain *d = v->domain;\n    unsigned int count, dummy = 0;\n\n    if ( !eax )\n        eax = &dummy;\n    if ( !ebx )\n        ebx = &dummy;\n    if ( !ecx )\n        ecx = &dummy;\n    count = *ecx;\n    if ( !edx )\n        edx = &dummy;\n\n    if ( cpuid_viridian_leaves(input, eax, ebx, ecx, edx) )\n        return;\n\n    if ( cpuid_hypervisor_leaves(input, count, eax, ebx, ecx, edx) )\n        return;\n\n    domain_cpuid(d, input, count, eax, ebx, ecx, edx);\n\n    switch ( input )\n    {\n        unsigned int sub_leaf, _eax, _ebx, _ecx, _edx;\n\n    case 0x1:\n        /* Fix up VLAPIC details. */\n        *ebx &= 0x00FFFFFFu;\n        *ebx |= (v->vcpu_id * 2) << 24;\n\n        *ecx &= hvm_featureset[FEATURESET_1c];\n        *edx &= hvm_featureset[FEATURESET_1d];\n\n        /* APIC exposed to guests, but Fast-forward MSR_APIC_BASE.EN back in. */\n        if ( vlapic_hw_disabled(vcpu_vlapic(v)) )\n            *edx &= ~cpufeat_bit(X86_FEATURE_APIC);\n\n        /* OSXSAVE cleared by hvm_featureset.  Fast-forward CR4 back in. */\n        if ( v->arch.hvm_vcpu.guest_cr[4] & X86_CR4_OSXSAVE )\n            *ecx |= cpufeat_mask(X86_FEATURE_OSXSAVE);\n\n        /* Don't expose HAP-only features to non-hap guests. */\n        if ( !hap_enabled(d) )\n        {\n            *ecx &= ~cpufeat_mask(X86_FEATURE_PCID);\n\n            /*\n             * PSE36 is not supported in shadow mode.  This bit should be\n             * unilaterally cleared.\n             *\n             * However, an unspecified version of Hyper-V from 2011 refuses\n             * to start as the \"cpu does not provide required hw features\" if\n             * it can't see PSE36.\n             *\n             * As a workaround, leak the toolstack-provided PSE36 value into a\n             * shadow guest if the guest is already using PAE paging (and\n             * won't care about reverting back to PSE paging).  Otherwise,\n             * knoble it, so a 32bit guest doesn't get the impression that it\n             * could try to use PSE36 paging.\n             */\n            if ( !(hvm_pae_enabled(v) || hvm_long_mode_enabled(v)) )\n                *edx &= ~cpufeat_mask(X86_FEATURE_PSE36);\n        }\n        break;\n\n    case 0x7:\n        if ( count == 0 )\n        {\n            /* Fold host's FDP_EXCP_ONLY and NO_FPU_SEL into guest's view. */\n            *ebx &= (hvm_featureset[FEATURESET_7b0] &\n                     ~special_features[FEATURESET_7b0]);\n            *ebx |= (host_featureset[FEATURESET_7b0] &\n                     special_features[FEATURESET_7b0]);\n\n            *ecx &= hvm_featureset[FEATURESET_7c0];\n\n            /* Don't expose HAP-only features to non-hap guests. */\n            if ( !hap_enabled(d) )\n            {\n                 *ebx &= ~cpufeat_mask(X86_FEATURE_INVPCID);\n                 *ecx &= ~cpufeat_mask(X86_FEATURE_PKU);\n            }\n\n            /* OSPKE cleared by hvm_featureset.  Fast-forward CR4 back in. */\n            if ( v->arch.hvm_vcpu.guest_cr[4] & X86_CR4_PKE )\n                *ecx |= cpufeat_mask(X86_FEATURE_OSPKE);\n        }\n        break;\n\n    case 0xb:\n        /* Fix the x2APIC identifier. */\n        *edx = v->vcpu_id * 2;\n        break;\n\n    case 0xd:\n        /* EBX value of main leaf 0 depends on enabled xsave features */\n        if ( count == 0 && v->arch.xcr0 ) \n        {\n            /* reset EBX to default value first */\n            *ebx = XSTATE_AREA_MIN_SIZE; \n            for ( sub_leaf = 2; sub_leaf < 63; sub_leaf++ )\n            {\n                if ( !(v->arch.xcr0 & (1ULL << sub_leaf)) )\n                    continue;\n                domain_cpuid(d, input, sub_leaf, &_eax, &_ebx, &_ecx, \n                             &_edx);\n                if ( (_eax + _ebx) > *ebx )\n                    *ebx = _eax + _ebx;\n            }\n        }\n\n        if ( count == 1 )\n        {\n            *eax &= hvm_featureset[FEATURESET_Da1];\n\n            if ( *eax & cpufeat_mask(X86_FEATURE_XSAVES) )\n            {\n                uint64_t xfeatures = v->arch.xcr0 | v->arch.hvm_vcpu.msr_xss;\n\n                *ebx = XSTATE_AREA_MIN_SIZE;\n                if ( xfeatures & ~XSTATE_FP_SSE )\n                    for ( sub_leaf = 2; sub_leaf < 63; sub_leaf++ )\n                        if ( xfeatures & (1ULL << sub_leaf) )\n                        {\n                            if ( test_bit(sub_leaf, &xstate_align) )\n                                *ebx = ROUNDUP(*ebx, 64);\n                            *ebx += xstate_sizes[sub_leaf];\n                        }\n            }\n            else\n                *ebx = *ecx = *edx = 0;\n        }\n        break;\n\n    case 0x80000001:\n        *ecx &= hvm_featureset[FEATURESET_e1c];\n        *edx &= hvm_featureset[FEATURESET_e1d];\n\n        /* If not emulating AMD, clear the duplicated features in e1d. */\n        if ( d->arch.x86_vendor != X86_VENDOR_AMD )\n            *edx &= ~CPUID_COMMON_1D_FEATURES;\n        /* fast-forward MSR_APIC_BASE.EN if it hasn't already been clobbered. */\n        else if ( vlapic_hw_disabled(vcpu_vlapic(v)) )\n            *edx &= ~cpufeat_bit(X86_FEATURE_APIC);\n\n        /* Don't expose HAP-only features to non-hap guests. */\n        if ( !hap_enabled(d) )\n        {\n            *edx &= ~cpufeat_mask(X86_FEATURE_PAGE1GB);\n\n            /*\n             * PSE36 is not supported in shadow mode.  This bit should be\n             * unilaterally cleared.\n             *\n             * However, an unspecified version of Hyper-V from 2011 refuses\n             * to start as the \"cpu does not provide required hw features\" if\n             * it can't see PSE36.\n             *\n             * As a workaround, leak the toolstack-provided PSE36 value into a\n             * shadow guest if the guest is already using PAE paging (and\n             * won't care about reverting back to PSE paging).  Otherwise,\n             * knoble it, so a 32bit guest doesn't get the impression that it\n             * could try to use PSE36 paging.\n             */\n            if ( !(hvm_pae_enabled(v) || hvm_long_mode_enabled(v)) )\n                *edx &= ~cpufeat_mask(X86_FEATURE_PSE36);\n        }\n        break;\n\n    case 0x80000007:\n        *edx &= hvm_featureset[FEATURESET_e7d];\n        break;\n\n    case 0x80000008:\n        count = d->arch.paging.gfn_bits + PAGE_SHIFT;\n        if ( (*eax & 0xff) > count )\n            *eax = (*eax & ~0xff) | count;\n\n        hvm_cpuid(1, NULL, NULL, NULL, &_edx);\n        count = _edx & (cpufeat_mask(X86_FEATURE_PAE) |\n                        cpufeat_mask(X86_FEATURE_PSE36)) ? 36 : 32;\n        if ( (*eax & 0xff) < count )\n            *eax = (*eax & ~0xff) | count;\n\n        hvm_cpuid(0x80000001, NULL, NULL, NULL, &_edx);\n        *eax = (*eax & ~0xffff00) | (_edx & cpufeat_mask(X86_FEATURE_LM)\n                                     ? 0x3000 : 0x2000);\n\n        *ebx &= hvm_featureset[FEATURESET_e8b];\n        break;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -176,8 +176,7 @@\n         break;\n \n     case 0x80000008:\n-        count = cpuid_eax(0x80000008);\n-        count = (count >> 16) & 0xff ?: count & 0xff;\n+        count = d->arch.paging.gfn_bits + PAGE_SHIFT;\n         if ( (*eax & 0xff) > count )\n             *eax = (*eax & ~0xff) | count;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        count = cpuid_eax(0x80000008);",
                "        count = (count >> 16) & 0xff ?: count & 0xff;"
            ],
            "added_lines": [
                "        count = d->arch.paging.gfn_bits + PAGE_SHIFT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3960",
        "func_name": "xen-project/xen/_sh_propagate",
        "description": "Integer overflow in the x86 shadow pagetable code in Xen allows local guest OS users to cause a denial of service (host crash) or possibly gain privileges by shadowing a superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/8b17648339ba801c4c7937b5f13dd25068e54e60",
        "commit_title": "x86: limit GFNs to 32 bits for shadowed superpages.",
        "commit_text": " Superpage shadows store the shadowed GFN in the backpointer field, which for non-BIGMEM builds is 32 bits wide.  Shadowing a superpage mapping of a guest-physical address above 2^44 would lead to the GFN being truncated there, and a crash when we come to remove the shadow from the hash table.  Track the valid width of a GFN for each guest, including reporting it through CPUID, and enforce it in the shadow pagetables.  Set the maximum witth to 32 for guests where this truncation could occur.  This is XSA-173. ",
        "func_before": "static always_inline void\n_sh_propagate(struct vcpu *v,\n              guest_intpte_t guest_intpte,\n              mfn_t target_mfn,\n              void *shadow_entry_ptr,\n              int level,\n              fetch_type_t ft,\n              p2m_type_t p2mt)\n{\n    guest_l1e_t guest_entry = { guest_intpte };\n    shadow_l1e_t *sp = shadow_entry_ptr;\n    struct domain *d = v->domain;\n    struct sh_dirty_vram *dirty_vram = d->arch.hvm_domain.dirty_vram;\n    gfn_t target_gfn = guest_l1e_get_gfn(guest_entry);\n    u32 pass_thru_flags;\n    u32 gflags, sflags;\n    bool_t mmio_mfn;\n\n    /* We don't shadow PAE l3s */\n    ASSERT(GUEST_PAGING_LEVELS > 3 || level != 3);\n\n    /* Check there's something for the shadows to map to */\n    if ( !p2m_is_valid(p2mt) && !p2m_is_grant(p2mt) )\n    {\n        *sp = shadow_l1e_empty();\n        goto done;\n    }\n\n    gflags = guest_l1e_get_flags(guest_entry);\n\n    if ( unlikely(!(gflags & _PAGE_PRESENT)) )\n    {\n#if !(SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)\n        /* If a guest l1 entry is not present, shadow with the magic\n         * guest-not-present entry. */\n        if ( level == 1 )\n            *sp = sh_l1e_gnp();\n        else\n#endif /* !OOS */\n            *sp = shadow_l1e_empty();\n        goto done;\n    }\n\n    if ( level == 1 && p2mt == p2m_mmio_dm )\n    {\n        /* Guest l1e maps emulated MMIO space */\n        *sp = sh_l1e_mmio(target_gfn, gflags);\n        if ( !d->arch.paging.shadow.has_fast_mmio_entries )\n            d->arch.paging.shadow.has_fast_mmio_entries = 1;\n        goto done;\n    }\n\n    // Must have a valid target_mfn unless this is a prefetch or an l1\n    // pointing at MMIO space.  In the case of a prefetch, an invalid\n    // mfn means that we can not usefully shadow anything, and so we\n    // return early.\n    //\n    mmio_mfn = !mfn_valid(target_mfn)\n               || (level == 1\n                   && page_get_owner(mfn_to_page(target_mfn)) == dom_io);\n    if ( mmio_mfn\n         && !(level == 1 && (!shadow_mode_refcounts(d)\n                             || p2mt == p2m_mmio_direct)) )\n    {\n        ASSERT((ft == ft_prefetch));\n        *sp = shadow_l1e_empty();\n        goto done;\n    }\n\n    // Propagate bits from the guest to the shadow.\n    // Some of these may be overwritten, below.\n    // Since we know the guest's PRESENT bit is set, we also set the shadow's\n    // SHADOW_PRESENT bit.\n    //\n    pass_thru_flags = (_PAGE_ACCESSED | _PAGE_USER |\n                       _PAGE_RW | _PAGE_PRESENT);\n    if ( guest_supports_nx(v) )\n        pass_thru_flags |= _PAGE_NX_BIT;\n    if ( level == 1 && !shadow_mode_refcounts(d) && mmio_mfn )\n        pass_thru_flags |= _PAGE_PAT | _PAGE_PCD | _PAGE_PWT;\n    sflags = gflags & pass_thru_flags;\n\n    /*\n     * For HVM domains with direct access to MMIO areas, set the correct\n     * caching attributes in the shadows to match what was asked for.\n     */\n    if ( (level == 1) && is_hvm_domain(d) &&\n         !is_xen_heap_mfn(mfn_x(target_mfn)) )\n    {\n        int type;\n\n        ASSERT(!(sflags & (_PAGE_PAT | _PAGE_PCD | _PAGE_PWT)));\n\n        /* compute the PAT index for shadow page entry when VT-d is enabled\n         * and device assigned.\n         * 1) direct MMIO: compute the PAT index with gMTRR=UC and gPAT.\n         * 2) if enables snoop control, compute the PAT index as WB.\n         * 3) if disables snoop control, compute the PAT index with\n         *    gMTRR and gPAT.\n         */\n        if ( !mmio_mfn &&\n             (type = hvm_get_mem_pinned_cacheattr(d, target_gfn, 0)) >= 0 )\n            sflags |= pat_type_2_pte_flags(type);\n        else if ( d->arch.hvm_domain.is_in_uc_mode )\n            sflags |= pat_type_2_pte_flags(PAT_TYPE_UNCACHABLE);\n        else\n            if ( iomem_access_permitted(d, mfn_x(target_mfn), mfn_x(target_mfn)) )\n            {\n                if ( p2mt == p2m_mmio_direct )\n                    sflags |= get_pat_flags(v,\n                            gflags,\n                            gfn_to_paddr(target_gfn),\n                            pfn_to_paddr(mfn_x(target_mfn)),\n                            MTRR_TYPE_UNCACHABLE);\n                else if ( iommu_snoop )\n                    sflags |= pat_type_2_pte_flags(PAT_TYPE_WRBACK);\n                else\n                    sflags |= get_pat_flags(v,\n                            gflags,\n                            gfn_to_paddr(target_gfn),\n                            pfn_to_paddr(mfn_x(target_mfn)),\n                            NO_HARDCODE_MEM_TYPE);\n            }\n    }\n\n    // Set the A&D bits for higher level shadows.\n    // Higher level entries do not, strictly speaking, have dirty bits, but\n    // since we use shadow linear tables, each of these entries may, at some\n    // point in time, also serve as a shadow L1 entry.\n    // By setting both the A&D bits in each of these, we eliminate the burden\n    // on the hardware to update these bits on initial accesses.\n    //\n    if ( (level > 1) && !((SHADOW_PAGING_LEVELS == 3) && (level == 3)) )\n        sflags |= _PAGE_ACCESSED | _PAGE_DIRTY;\n\n    // If the A or D bit has not yet been set in the guest, then we must\n    // prevent the corresponding kind of access.\n    //\n    if ( unlikely(!(gflags & _PAGE_ACCESSED)) )\n        sflags &= ~_PAGE_PRESENT;\n\n    /* D bits exist in L1es and PSE L2es */\n    if ( unlikely(((level == 1) ||\n                   ((level == 2) &&\n                    (gflags & _PAGE_PSE) &&\n                    guest_supports_superpages(v)))\n                  && !(gflags & _PAGE_DIRTY)) )\n        sflags &= ~_PAGE_RW;\n\n    // shadow_mode_log_dirty support\n    //\n    // Only allow the guest write access to a page a) on a demand fault,\n    // or b) if the page is already marked as dirty.\n    //\n    // (We handle log-dirty entirely inside the shadow code, without using the\n    // p2m_ram_logdirty p2m type: only HAP uses that.)\n    if ( unlikely((level == 1) && shadow_mode_log_dirty(d)) )\n    {\n        if ( mfn_valid(target_mfn) ) {\n            if ( ft & FETCH_TYPE_WRITE )\n                paging_mark_dirty(d, mfn_x(target_mfn));\n            else if ( !paging_mfn_is_dirty(d, target_mfn) )\n                sflags &= ~_PAGE_RW;\n        }\n    }\n\n    if ( unlikely((level == 1) && dirty_vram\n            && dirty_vram->last_dirty == -1\n            && gfn_x(target_gfn) >= dirty_vram->begin_pfn\n            && gfn_x(target_gfn) < dirty_vram->end_pfn) )\n    {\n        if ( ft & FETCH_TYPE_WRITE )\n            dirty_vram->last_dirty = NOW();\n        else\n            sflags &= ~_PAGE_RW;\n    }\n\n    /* Read-only memory */\n    if ( p2m_is_readonly(p2mt) )\n        sflags &= ~_PAGE_RW;\n    else if ( p2mt == p2m_mmio_direct &&\n              rangeset_contains_singleton(mmio_ro_ranges, mfn_x(target_mfn)) )\n    {\n        sflags &= ~(_PAGE_RW | _PAGE_PAT);\n        sflags |= _PAGE_PCD | _PAGE_PWT;\n    }\n\n    // protect guest page tables\n    //\n    if ( unlikely((level == 1)\n                  && sh_mfn_is_a_page_table(target_mfn)\n#if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC )\n                  /* Unless the page is out of sync and the guest is\n                     writing to it. */\n                  && !(mfn_oos_may_write(target_mfn)\n                       && (ft == ft_demand_write))\n#endif /* OOS */\n                  ) )\n        sflags &= ~_PAGE_RW;\n\n    // PV guests in 64-bit mode use two different page tables for user vs\n    // supervisor permissions, making the guest's _PAGE_USER bit irrelevant.\n    // It is always shadowed as present...\n    if ( (GUEST_PAGING_LEVELS == 4) && !is_pv_32bit_domain(d)\n         && is_pv_domain(d) )\n    {\n        sflags |= _PAGE_USER;\n    }\n\n    *sp = shadow_l1e_from_mfn(target_mfn, sflags);\n\n done:\n    SHADOW_DEBUG(PROPAGATE,\n                 \"%s level %u guest %\" SH_PRI_gpte \" shadow %\" SH_PRI_pte \"\\n\",\n                 fetch_type_names[ft], level, guest_entry.l1, sp->l1);\n}",
        "func": "static always_inline void\n_sh_propagate(struct vcpu *v,\n              guest_intpte_t guest_intpte,\n              mfn_t target_mfn,\n              void *shadow_entry_ptr,\n              int level,\n              fetch_type_t ft,\n              p2m_type_t p2mt)\n{\n    guest_l1e_t guest_entry = { guest_intpte };\n    shadow_l1e_t *sp = shadow_entry_ptr;\n    struct domain *d = v->domain;\n    struct sh_dirty_vram *dirty_vram = d->arch.hvm_domain.dirty_vram;\n    gfn_t target_gfn = guest_l1e_get_gfn(guest_entry);\n    u32 pass_thru_flags;\n    u32 gflags, sflags;\n    bool_t mmio_mfn;\n\n    /* We don't shadow PAE l3s */\n    ASSERT(GUEST_PAGING_LEVELS > 3 || level != 3);\n\n    /* Check there's something for the shadows to map to */\n    if ( (!p2m_is_valid(p2mt) && !p2m_is_grant(p2mt))\n         || gfn_x(target_gfn) >> d->arch.paging.gfn_bits )\n    {\n        *sp = shadow_l1e_empty();\n        goto done;\n    }\n\n    gflags = guest_l1e_get_flags(guest_entry);\n\n    if ( unlikely(!(gflags & _PAGE_PRESENT)) )\n    {\n#if !(SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC)\n        /* If a guest l1 entry is not present, shadow with the magic\n         * guest-not-present entry. */\n        if ( level == 1 )\n            *sp = sh_l1e_gnp();\n        else\n#endif /* !OOS */\n            *sp = shadow_l1e_empty();\n        goto done;\n    }\n\n    if ( level == 1 && p2mt == p2m_mmio_dm )\n    {\n        /* Guest l1e maps emulated MMIO space */\n        *sp = sh_l1e_mmio(target_gfn, gflags);\n        if ( !d->arch.paging.shadow.has_fast_mmio_entries )\n            d->arch.paging.shadow.has_fast_mmio_entries = 1;\n        goto done;\n    }\n\n    // Must have a valid target_mfn unless this is a prefetch or an l1\n    // pointing at MMIO space.  In the case of a prefetch, an invalid\n    // mfn means that we can not usefully shadow anything, and so we\n    // return early.\n    //\n    mmio_mfn = !mfn_valid(target_mfn)\n               || (level == 1\n                   && page_get_owner(mfn_to_page(target_mfn)) == dom_io);\n    if ( mmio_mfn\n         && !(level == 1 && (!shadow_mode_refcounts(d)\n                             || p2mt == p2m_mmio_direct)) )\n    {\n        ASSERT((ft == ft_prefetch));\n        *sp = shadow_l1e_empty();\n        goto done;\n    }\n\n    // Propagate bits from the guest to the shadow.\n    // Some of these may be overwritten, below.\n    // Since we know the guest's PRESENT bit is set, we also set the shadow's\n    // SHADOW_PRESENT bit.\n    //\n    pass_thru_flags = (_PAGE_ACCESSED | _PAGE_USER |\n                       _PAGE_RW | _PAGE_PRESENT);\n    if ( guest_supports_nx(v) )\n        pass_thru_flags |= _PAGE_NX_BIT;\n    if ( level == 1 && !shadow_mode_refcounts(d) && mmio_mfn )\n        pass_thru_flags |= _PAGE_PAT | _PAGE_PCD | _PAGE_PWT;\n    sflags = gflags & pass_thru_flags;\n\n    /*\n     * For HVM domains with direct access to MMIO areas, set the correct\n     * caching attributes in the shadows to match what was asked for.\n     */\n    if ( (level == 1) && is_hvm_domain(d) &&\n         !is_xen_heap_mfn(mfn_x(target_mfn)) )\n    {\n        int type;\n\n        ASSERT(!(sflags & (_PAGE_PAT | _PAGE_PCD | _PAGE_PWT)));\n\n        /* compute the PAT index for shadow page entry when VT-d is enabled\n         * and device assigned.\n         * 1) direct MMIO: compute the PAT index with gMTRR=UC and gPAT.\n         * 2) if enables snoop control, compute the PAT index as WB.\n         * 3) if disables snoop control, compute the PAT index with\n         *    gMTRR and gPAT.\n         */\n        if ( !mmio_mfn &&\n             (type = hvm_get_mem_pinned_cacheattr(d, target_gfn, 0)) >= 0 )\n            sflags |= pat_type_2_pte_flags(type);\n        else if ( d->arch.hvm_domain.is_in_uc_mode )\n            sflags |= pat_type_2_pte_flags(PAT_TYPE_UNCACHABLE);\n        else\n            if ( iomem_access_permitted(d, mfn_x(target_mfn), mfn_x(target_mfn)) )\n            {\n                if ( p2mt == p2m_mmio_direct )\n                    sflags |= get_pat_flags(v,\n                            gflags,\n                            gfn_to_paddr(target_gfn),\n                            pfn_to_paddr(mfn_x(target_mfn)),\n                            MTRR_TYPE_UNCACHABLE);\n                else if ( iommu_snoop )\n                    sflags |= pat_type_2_pte_flags(PAT_TYPE_WRBACK);\n                else\n                    sflags |= get_pat_flags(v,\n                            gflags,\n                            gfn_to_paddr(target_gfn),\n                            pfn_to_paddr(mfn_x(target_mfn)),\n                            NO_HARDCODE_MEM_TYPE);\n            }\n    }\n\n    // Set the A&D bits for higher level shadows.\n    // Higher level entries do not, strictly speaking, have dirty bits, but\n    // since we use shadow linear tables, each of these entries may, at some\n    // point in time, also serve as a shadow L1 entry.\n    // By setting both the A&D bits in each of these, we eliminate the burden\n    // on the hardware to update these bits on initial accesses.\n    //\n    if ( (level > 1) && !((SHADOW_PAGING_LEVELS == 3) && (level == 3)) )\n        sflags |= _PAGE_ACCESSED | _PAGE_DIRTY;\n\n    // If the A or D bit has not yet been set in the guest, then we must\n    // prevent the corresponding kind of access.\n    //\n    if ( unlikely(!(gflags & _PAGE_ACCESSED)) )\n        sflags &= ~_PAGE_PRESENT;\n\n    /* D bits exist in L1es and PSE L2es */\n    if ( unlikely(((level == 1) ||\n                   ((level == 2) &&\n                    (gflags & _PAGE_PSE) &&\n                    guest_supports_superpages(v)))\n                  && !(gflags & _PAGE_DIRTY)) )\n        sflags &= ~_PAGE_RW;\n\n    // shadow_mode_log_dirty support\n    //\n    // Only allow the guest write access to a page a) on a demand fault,\n    // or b) if the page is already marked as dirty.\n    //\n    // (We handle log-dirty entirely inside the shadow code, without using the\n    // p2m_ram_logdirty p2m type: only HAP uses that.)\n    if ( unlikely((level == 1) && shadow_mode_log_dirty(d)) )\n    {\n        if ( mfn_valid(target_mfn) ) {\n            if ( ft & FETCH_TYPE_WRITE )\n                paging_mark_dirty(d, mfn_x(target_mfn));\n            else if ( !paging_mfn_is_dirty(d, target_mfn) )\n                sflags &= ~_PAGE_RW;\n        }\n    }\n\n    if ( unlikely((level == 1) && dirty_vram\n            && dirty_vram->last_dirty == -1\n            && gfn_x(target_gfn) >= dirty_vram->begin_pfn\n            && gfn_x(target_gfn) < dirty_vram->end_pfn) )\n    {\n        if ( ft & FETCH_TYPE_WRITE )\n            dirty_vram->last_dirty = NOW();\n        else\n            sflags &= ~_PAGE_RW;\n    }\n\n    /* Read-only memory */\n    if ( p2m_is_readonly(p2mt) )\n        sflags &= ~_PAGE_RW;\n    else if ( p2mt == p2m_mmio_direct &&\n              rangeset_contains_singleton(mmio_ro_ranges, mfn_x(target_mfn)) )\n    {\n        sflags &= ~(_PAGE_RW | _PAGE_PAT);\n        sflags |= _PAGE_PCD | _PAGE_PWT;\n    }\n\n    // protect guest page tables\n    //\n    if ( unlikely((level == 1)\n                  && sh_mfn_is_a_page_table(target_mfn)\n#if (SHADOW_OPTIMIZATIONS & SHOPT_OUT_OF_SYNC )\n                  /* Unless the page is out of sync and the guest is\n                     writing to it. */\n                  && !(mfn_oos_may_write(target_mfn)\n                       && (ft == ft_demand_write))\n#endif /* OOS */\n                  ) )\n        sflags &= ~_PAGE_RW;\n\n    // PV guests in 64-bit mode use two different page tables for user vs\n    // supervisor permissions, making the guest's _PAGE_USER bit irrelevant.\n    // It is always shadowed as present...\n    if ( (GUEST_PAGING_LEVELS == 4) && !is_pv_32bit_domain(d)\n         && is_pv_domain(d) )\n    {\n        sflags |= _PAGE_USER;\n    }\n\n    *sp = shadow_l1e_from_mfn(target_mfn, sflags);\n\n done:\n    SHADOW_DEBUG(PROPAGATE,\n                 \"%s level %u guest %\" SH_PRI_gpte \" shadow %\" SH_PRI_pte \"\\n\",\n                 fetch_type_names[ft], level, guest_entry.l1, sp->l1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,8 @@\n     ASSERT(GUEST_PAGING_LEVELS > 3 || level != 3);\n \n     /* Check there's something for the shadows to map to */\n-    if ( !p2m_is_valid(p2mt) && !p2m_is_grant(p2mt) )\n+    if ( (!p2m_is_valid(p2mt) && !p2m_is_grant(p2mt))\n+         || gfn_x(target_gfn) >> d->arch.paging.gfn_bits )\n     {\n         *sp = shadow_l1e_empty();\n         goto done;",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( !p2m_is_valid(p2mt) && !p2m_is_grant(p2mt) )"
            ],
            "added_lines": [
                "    if ( (!p2m_is_valid(p2mt) && !p2m_is_grant(p2mt))",
                "         || gfn_x(target_gfn) >> d->arch.paging.gfn_bits )"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2430",
        "func_name": "android/Backtrace::GetFunctionName",
        "description": "libbacktrace/Backtrace.cpp in debuggerd in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 allows attackers to gain privileges via an application containing a crafted symbol name, aka internal bug 27299236.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/ad54cfed4516292654c997910839153264ae00a0",
        "commit_title": "Don't demangle symbol names.",
        "commit_text": " Bug: http://b/27299236 ",
        "func_before": "std::string Backtrace::GetFunctionName(uintptr_t pc, uintptr_t* offset) {\n  std::string func_name = GetFunctionNameRaw(pc, offset);\n  if (!func_name.empty()) {\n#if defined(__APPLE__)\n    // Mac OS' __cxa_demangle demangles \"f\" as \"float\"; last tested on 10.7.\n    if (func_name[0] != '_') {\n      return func_name;\n    }\n#endif\n    char* name = __cxa_demangle(func_name.c_str(), 0, 0, 0);\n    if (name) {\n      func_name = name;\n      free(name);\n    }\n  }\n  return func_name;\n}",
        "func": "std::string Backtrace::GetFunctionName(uintptr_t pc, uintptr_t* offset) {\n  std::string func_name = GetFunctionNameRaw(pc, offset);\n  return func_name;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,17 +1,4 @@\n std::string Backtrace::GetFunctionName(uintptr_t pc, uintptr_t* offset) {\n   std::string func_name = GetFunctionNameRaw(pc, offset);\n-  if (!func_name.empty()) {\n-#if defined(__APPLE__)\n-    // Mac OS' __cxa_demangle demangles \"f\" as \"float\"; last tested on 10.7.\n-    if (func_name[0] != '_') {\n-      return func_name;\n-    }\n-#endif\n-    char* name = __cxa_demangle(func_name.c_str(), 0, 0, 0);\n-    if (name) {\n-      func_name = name;\n-      free(name);\n-    }\n-  }\n   return func_name;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (!func_name.empty()) {",
                "#if defined(__APPLE__)",
                "    // Mac OS' __cxa_demangle demangles \"f\" as \"float\"; last tested on 10.7.",
                "    if (func_name[0] != '_') {",
                "      return func_name;",
                "    }",
                "#endif",
                "    char* name = __cxa_demangle(func_name.c_str(), 0, 0, 0);",
                "    if (name) {",
                "      func_name = name;",
                "      free(name);",
                "    }",
                "  }"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2016-2440",
        "func_name": "android/IPCThreadState::executeCommand",
        "description": "libs/binder/IPCThreadState.cpp in Binder in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 mishandles object references, which allows attackers to gain privileges via a crafted application, aka internal bug 27252896.",
        "git_url": "https://android.googlesource.com/platform/frameworks/native/+/a59b827869a2ea04022dd225007f29af8d61837a",
        "commit_title": "Fix issue #27252896: Security Vulnerability -- weak binder",
        "commit_text": " Sending transaction to freed BBinder through weak handle can cause use of a (mostly) freed object.  We need to try to safely promote to a strong reference first.  (cherry picked from commit c11146106f94e07016e8e26e4f8628f9a0c73199) ",
        "func_before": "status_t IPCThreadState::executeCommand(int32_t cmd)\n{\n    BBinder* obj;\n    RefBase::weakref_type* refs;\n    status_t result = NO_ERROR;\n    \n    switch ((uint32_t)cmd) {\n    case BR_ERROR:\n        result = mIn.readInt32();\n        break;\n        \n    case BR_OK:\n        break;\n        \n    case BR_ACQUIRE:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        ALOG_ASSERT(refs->refBase() == obj,\n                   \"BR_ACQUIRE: object %p does not match cookie %p (expected %p)\",\n                   refs, obj, refs->refBase());\n        obj->incStrong(mProcess.get());\n        IF_LOG_REMOTEREFS() {\n            LOG_REMOTEREFS(\"BR_ACQUIRE from driver on %p\", obj);\n            obj->printRefs();\n        }\n        mOut.writeInt32(BC_ACQUIRE_DONE);\n        mOut.writePointer((uintptr_t)refs);\n        mOut.writePointer((uintptr_t)obj);\n        break;\n        \n    case BR_RELEASE:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        ALOG_ASSERT(refs->refBase() == obj,\n                   \"BR_RELEASE: object %p does not match cookie %p (expected %p)\",\n                   refs, obj, refs->refBase());\n        IF_LOG_REMOTEREFS() {\n            LOG_REMOTEREFS(\"BR_RELEASE from driver on %p\", obj);\n            obj->printRefs();\n        }\n        mPendingStrongDerefs.push(obj);\n        break;\n        \n    case BR_INCREFS:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        refs->incWeak(mProcess.get());\n        mOut.writeInt32(BC_INCREFS_DONE);\n        mOut.writePointer((uintptr_t)refs);\n        mOut.writePointer((uintptr_t)obj);\n        break;\n        \n    case BR_DECREFS:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        // NOTE: This assertion is not valid, because the object may no\n        // longer exist (thus the (BBinder*)cast above resulting in a different\n        // memory address).\n        //ALOG_ASSERT(refs->refBase() == obj,\n        //           \"BR_DECREFS: object %p does not match cookie %p (expected %p)\",\n        //           refs, obj, refs->refBase());\n        mPendingWeakDerefs.push(refs);\n        break;\n        \n    case BR_ATTEMPT_ACQUIRE:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n         \n        {\n            const bool success = refs->attemptIncStrong(mProcess.get());\n            ALOG_ASSERT(success && refs->refBase() == obj,\n                       \"BR_ATTEMPT_ACQUIRE: object %p does not match cookie %p (expected %p)\",\n                       refs, obj, refs->refBase());\n            \n            mOut.writeInt32(BC_ACQUIRE_RESULT);\n            mOut.writeInt32((int32_t)success);\n        }\n        break;\n    \n    case BR_TRANSACTION:\n        {\n            binder_transaction_data tr;\n            result = mIn.read(&tr, sizeof(tr));\n            ALOG_ASSERT(result == NO_ERROR,\n                \"Not enough command data for brTRANSACTION\");\n            if (result != NO_ERROR) break;\n            \n            Parcel buffer;\n            buffer.ipcSetDataReference(\n                reinterpret_cast<const uint8_t*>(tr.data.ptr.buffer),\n                tr.data_size,\n                reinterpret_cast<const binder_size_t*>(tr.data.ptr.offsets),\n                tr.offsets_size/sizeof(binder_size_t), freeBuffer, this);\n            \n            const pid_t origPid = mCallingPid;\n            const uid_t origUid = mCallingUid;\n            const int32_t origStrictModePolicy = mStrictModePolicy;\n            const int32_t origTransactionBinderFlags = mLastTransactionBinderFlags;\n\n            mCallingPid = tr.sender_pid;\n            mCallingUid = tr.sender_euid;\n            mLastTransactionBinderFlags = tr.flags;\n\n            int curPrio = getpriority(PRIO_PROCESS, mMyThreadId);\n            if (gDisableBackgroundScheduling) {\n                if (curPrio > ANDROID_PRIORITY_NORMAL) {\n                    // We have inherited a reduced priority from the caller, but do not\n                    // want to run in that state in this process.  The driver set our\n                    // priority already (though not our scheduling class), so bounce\n                    // it back to the default before invoking the transaction.\n                    setpriority(PRIO_PROCESS, mMyThreadId, ANDROID_PRIORITY_NORMAL);\n                }\n            } else {\n                if (curPrio >= ANDROID_PRIORITY_BACKGROUND) {\n                    // We want to use the inherited priority from the caller.\n                    // Ensure this thread is in the background scheduling class,\n                    // since the driver won't modify scheduling classes for us.\n                    // The scheduling group is reset to default by the caller\n                    // once this method returns after the transaction is complete.\n                    set_sched_policy(mMyThreadId, SP_BACKGROUND);\n                }\n            }\n\n            //ALOGI(\">>>> TRANSACT from pid %d uid %d\\n\", mCallingPid, mCallingUid);\n\n            Parcel reply;\n            status_t error;\n            IF_LOG_TRANSACTIONS() {\n                TextOutput::Bundle _b(alog);\n                alog << \"BR_TRANSACTION thr \" << (void*)pthread_self()\n                    << \" / obj \" << tr.target.ptr << \" / code \"\n                    << TypeCode(tr.code) << \": \" << indent << buffer\n                    << dedent << endl\n                    << \"Data addr = \"\n                    << reinterpret_cast<const uint8_t*>(tr.data.ptr.buffer)\n                    << \", offsets addr=\"\n                    << reinterpret_cast<const size_t*>(tr.data.ptr.offsets) << endl;\n            }\n            if (tr.target.ptr) {\n                sp<BBinder> b((BBinder*)tr.cookie);\n                error = b->transact(tr.code, buffer, &reply, tr.flags);\n\n            } else {\n                error = the_context_object->transact(tr.code, buffer, &reply, tr.flags);\n            }\n\n            //ALOGI(\"<<<< TRANSACT from pid %d restore pid %d uid %d\\n\",\n            //     mCallingPid, origPid, origUid);\n            \n            if ((tr.flags & TF_ONE_WAY) == 0) {\n                LOG_ONEWAY(\"Sending reply to %d!\", mCallingPid);\n                if (error < NO_ERROR) reply.setError(error);\n                sendReply(reply, 0);\n            } else {\n                LOG_ONEWAY(\"NOT sending reply to %d!\", mCallingPid);\n            }\n            \n            mCallingPid = origPid;\n            mCallingUid = origUid;\n            mStrictModePolicy = origStrictModePolicy;\n            mLastTransactionBinderFlags = origTransactionBinderFlags;\n\n            IF_LOG_TRANSACTIONS() {\n                TextOutput::Bundle _b(alog);\n                alog << \"BC_REPLY thr \" << (void*)pthread_self() << \" / obj \"\n                    << tr.target.ptr << \": \" << indent << reply << dedent << endl;\n            }\n            \n        }\n        break;\n    \n    case BR_DEAD_BINDER:\n        {\n            BpBinder *proxy = (BpBinder*)mIn.readPointer();\n            proxy->sendObituary();\n            mOut.writeInt32(BC_DEAD_BINDER_DONE);\n            mOut.writePointer((uintptr_t)proxy);\n        } break;\n        \n    case BR_CLEAR_DEATH_NOTIFICATION_DONE:\n        {\n            BpBinder *proxy = (BpBinder*)mIn.readPointer();\n            proxy->getWeakRefs()->decWeak(proxy);\n        } break;\n        \n    case BR_FINISHED:\n        result = TIMED_OUT;\n        break;\n        \n    case BR_NOOP:\n        break;\n        \n    case BR_SPAWN_LOOPER:\n        mProcess->spawnPooledThread(false);\n        break;\n        \n    default:\n        printf(\"*** BAD COMMAND %d received from Binder driver\\n\", cmd);\n        result = UNKNOWN_ERROR;\n        break;\n    }\n\n    if (result != NO_ERROR) {\n        mLastError = result;\n    }\n    \n    return result;\n}",
        "func": "status_t IPCThreadState::executeCommand(int32_t cmd)\n{\n    BBinder* obj;\n    RefBase::weakref_type* refs;\n    status_t result = NO_ERROR;\n    \n    switch ((uint32_t)cmd) {\n    case BR_ERROR:\n        result = mIn.readInt32();\n        break;\n        \n    case BR_OK:\n        break;\n        \n    case BR_ACQUIRE:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        ALOG_ASSERT(refs->refBase() == obj,\n                   \"BR_ACQUIRE: object %p does not match cookie %p (expected %p)\",\n                   refs, obj, refs->refBase());\n        obj->incStrong(mProcess.get());\n        IF_LOG_REMOTEREFS() {\n            LOG_REMOTEREFS(\"BR_ACQUIRE from driver on %p\", obj);\n            obj->printRefs();\n        }\n        mOut.writeInt32(BC_ACQUIRE_DONE);\n        mOut.writePointer((uintptr_t)refs);\n        mOut.writePointer((uintptr_t)obj);\n        break;\n        \n    case BR_RELEASE:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        ALOG_ASSERT(refs->refBase() == obj,\n                   \"BR_RELEASE: object %p does not match cookie %p (expected %p)\",\n                   refs, obj, refs->refBase());\n        IF_LOG_REMOTEREFS() {\n            LOG_REMOTEREFS(\"BR_RELEASE from driver on %p\", obj);\n            obj->printRefs();\n        }\n        mPendingStrongDerefs.push(obj);\n        break;\n        \n    case BR_INCREFS:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        refs->incWeak(mProcess.get());\n        mOut.writeInt32(BC_INCREFS_DONE);\n        mOut.writePointer((uintptr_t)refs);\n        mOut.writePointer((uintptr_t)obj);\n        break;\n        \n    case BR_DECREFS:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n        // NOTE: This assertion is not valid, because the object may no\n        // longer exist (thus the (BBinder*)cast above resulting in a different\n        // memory address).\n        //ALOG_ASSERT(refs->refBase() == obj,\n        //           \"BR_DECREFS: object %p does not match cookie %p (expected %p)\",\n        //           refs, obj, refs->refBase());\n        mPendingWeakDerefs.push(refs);\n        break;\n        \n    case BR_ATTEMPT_ACQUIRE:\n        refs = (RefBase::weakref_type*)mIn.readPointer();\n        obj = (BBinder*)mIn.readPointer();\n         \n        {\n            const bool success = refs->attemptIncStrong(mProcess.get());\n            ALOG_ASSERT(success && refs->refBase() == obj,\n                       \"BR_ATTEMPT_ACQUIRE: object %p does not match cookie %p (expected %p)\",\n                       refs, obj, refs->refBase());\n            \n            mOut.writeInt32(BC_ACQUIRE_RESULT);\n            mOut.writeInt32((int32_t)success);\n        }\n        break;\n    \n    case BR_TRANSACTION:\n        {\n            binder_transaction_data tr;\n            result = mIn.read(&tr, sizeof(tr));\n            ALOG_ASSERT(result == NO_ERROR,\n                \"Not enough command data for brTRANSACTION\");\n            if (result != NO_ERROR) break;\n            \n            Parcel buffer;\n            buffer.ipcSetDataReference(\n                reinterpret_cast<const uint8_t*>(tr.data.ptr.buffer),\n                tr.data_size,\n                reinterpret_cast<const binder_size_t*>(tr.data.ptr.offsets),\n                tr.offsets_size/sizeof(binder_size_t), freeBuffer, this);\n            \n            const pid_t origPid = mCallingPid;\n            const uid_t origUid = mCallingUid;\n            const int32_t origStrictModePolicy = mStrictModePolicy;\n            const int32_t origTransactionBinderFlags = mLastTransactionBinderFlags;\n\n            mCallingPid = tr.sender_pid;\n            mCallingUid = tr.sender_euid;\n            mLastTransactionBinderFlags = tr.flags;\n\n            int curPrio = getpriority(PRIO_PROCESS, mMyThreadId);\n            if (gDisableBackgroundScheduling) {\n                if (curPrio > ANDROID_PRIORITY_NORMAL) {\n                    // We have inherited a reduced priority from the caller, but do not\n                    // want to run in that state in this process.  The driver set our\n                    // priority already (though not our scheduling class), so bounce\n                    // it back to the default before invoking the transaction.\n                    setpriority(PRIO_PROCESS, mMyThreadId, ANDROID_PRIORITY_NORMAL);\n                }\n            } else {\n                if (curPrio >= ANDROID_PRIORITY_BACKGROUND) {\n                    // We want to use the inherited priority from the caller.\n                    // Ensure this thread is in the background scheduling class,\n                    // since the driver won't modify scheduling classes for us.\n                    // The scheduling group is reset to default by the caller\n                    // once this method returns after the transaction is complete.\n                    set_sched_policy(mMyThreadId, SP_BACKGROUND);\n                }\n            }\n\n            //ALOGI(\">>>> TRANSACT from pid %d uid %d\\n\", mCallingPid, mCallingUid);\n\n            Parcel reply;\n            status_t error;\n            IF_LOG_TRANSACTIONS() {\n                TextOutput::Bundle _b(alog);\n                alog << \"BR_TRANSACTION thr \" << (void*)pthread_self()\n                    << \" / obj \" << tr.target.ptr << \" / code \"\n                    << TypeCode(tr.code) << \": \" << indent << buffer\n                    << dedent << endl\n                    << \"Data addr = \"\n                    << reinterpret_cast<const uint8_t*>(tr.data.ptr.buffer)\n                    << \", offsets addr=\"\n                    << reinterpret_cast<const size_t*>(tr.data.ptr.offsets) << endl;\n            }\n            if (tr.target.ptr) {\n                // We only have a weak reference on the target object, so we must first try to\n                // safely acquire a strong reference before doing anything else with it.\n                if (reinterpret_cast<RefBase::weakref_type*>(\n                        tr.target.ptr)->attemptIncStrong(this)) {\n                    error = reinterpret_cast<BBinder*>(tr.cookie)->transact(tr.code, buffer,\n                            &reply, tr.flags);\n                    reinterpret_cast<BBinder*>(tr.cookie)->decStrong(this);\n                } else {\n                    error = UNKNOWN_TRANSACTION;\n                }\n\n            } else {\n                error = the_context_object->transact(tr.code, buffer, &reply, tr.flags);\n            }\n\n            //ALOGI(\"<<<< TRANSACT from pid %d restore pid %d uid %d\\n\",\n            //     mCallingPid, origPid, origUid);\n            \n            if ((tr.flags & TF_ONE_WAY) == 0) {\n                LOG_ONEWAY(\"Sending reply to %d!\", mCallingPid);\n                if (error < NO_ERROR) reply.setError(error);\n                sendReply(reply, 0);\n            } else {\n                LOG_ONEWAY(\"NOT sending reply to %d!\", mCallingPid);\n            }\n            \n            mCallingPid = origPid;\n            mCallingUid = origUid;\n            mStrictModePolicy = origStrictModePolicy;\n            mLastTransactionBinderFlags = origTransactionBinderFlags;\n\n            IF_LOG_TRANSACTIONS() {\n                TextOutput::Bundle _b(alog);\n                alog << \"BC_REPLY thr \" << (void*)pthread_self() << \" / obj \"\n                    << tr.target.ptr << \": \" << indent << reply << dedent << endl;\n            }\n            \n        }\n        break;\n    \n    case BR_DEAD_BINDER:\n        {\n            BpBinder *proxy = (BpBinder*)mIn.readPointer();\n            proxy->sendObituary();\n            mOut.writeInt32(BC_DEAD_BINDER_DONE);\n            mOut.writePointer((uintptr_t)proxy);\n        } break;\n        \n    case BR_CLEAR_DEATH_NOTIFICATION_DONE:\n        {\n            BpBinder *proxy = (BpBinder*)mIn.readPointer();\n            proxy->getWeakRefs()->decWeak(proxy);\n        } break;\n        \n    case BR_FINISHED:\n        result = TIMED_OUT;\n        break;\n        \n    case BR_NOOP:\n        break;\n        \n    case BR_SPAWN_LOOPER:\n        mProcess->spawnPooledThread(false);\n        break;\n        \n    default:\n        printf(\"*** BAD COMMAND %d received from Binder driver\\n\", cmd);\n        result = UNKNOWN_ERROR;\n        break;\n    }\n\n    if (result != NO_ERROR) {\n        mLastError = result;\n    }\n    \n    return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -137,8 +137,16 @@\n                     << reinterpret_cast<const size_t*>(tr.data.ptr.offsets) << endl;\n             }\n             if (tr.target.ptr) {\n-                sp<BBinder> b((BBinder*)tr.cookie);\n-                error = b->transact(tr.code, buffer, &reply, tr.flags);\n+                // We only have a weak reference on the target object, so we must first try to\n+                // safely acquire a strong reference before doing anything else with it.\n+                if (reinterpret_cast<RefBase::weakref_type*>(\n+                        tr.target.ptr)->attemptIncStrong(this)) {\n+                    error = reinterpret_cast<BBinder*>(tr.cookie)->transact(tr.code, buffer,\n+                            &reply, tr.flags);\n+                    reinterpret_cast<BBinder*>(tr.cookie)->decStrong(this);\n+                } else {\n+                    error = UNKNOWN_TRANSACTION;\n+                }\n \n             } else {\n                 error = the_context_object->transact(tr.code, buffer, &reply, tr.flags);",
        "diff_line_info": {
            "deleted_lines": [
                "                sp<BBinder> b((BBinder*)tr.cookie);",
                "                error = b->transact(tr.code, buffer, &reply, tr.flags);"
            ],
            "added_lines": [
                "                // We only have a weak reference on the target object, so we must first try to",
                "                // safely acquire a strong reference before doing anything else with it.",
                "                if (reinterpret_cast<RefBase::weakref_type*>(",
                "                        tr.target.ptr)->attemptIncStrong(this)) {",
                "                    error = reinterpret_cast<BBinder*>(tr.cookie)->transact(tr.code, buffer,",
                "                            &reply, tr.flags);",
                "                    reinterpret_cast<BBinder*>(tr.cookie)->decStrong(this);",
                "                } else {",
                "                    error = UNKNOWN_TRANSACTION;",
                "                }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2448",
        "func_name": "android/NuPlayer::NuPlayerStreamListener::read",
        "description": "media/libmediaplayerservice/nuplayer/NuPlayerStreamListener.cpp in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not properly validate entry data structures, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 27533704.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/a2d1d85726aa2a3126e9c331a8e00a8c319c9e2b",
        "commit_title": "NuPlayerStreamListener: NULL and bounds check before memcpy",
        "commit_text": " Bug: 27533704 ",
        "func_before": "ssize_t NuPlayer::NuPlayerStreamListener::read(\n        void *data, size_t size, sp<AMessage> *extra) {\n    CHECK_GT(size, 0u);\n\n    extra->clear();\n\n    Mutex::Autolock autoLock(mLock);\n\n    if (mEOS) {\n        return 0;\n    }\n\n    if (mQueue.empty()) {\n        mSendDataNotification = true;\n\n        return -EWOULDBLOCK;\n    }\n\n    QueueEntry *entry = &*mQueue.begin();\n\n    if (entry->mIsCommand) {\n        switch (entry->mCommand) {\n            case EOS:\n            {\n                mQueue.erase(mQueue.begin());\n                entry = NULL;\n\n                mEOS = true;\n                return 0;\n            }\n\n            case DISCONTINUITY:\n            {\n                *extra = entry->mExtra;\n\n                mQueue.erase(mQueue.begin());\n                entry = NULL;\n\n                return INFO_DISCONTINUITY;\n            }\n\n            default:\n                TRESPASS();\n                break;\n        }\n    }\n\n    size_t copy = entry->mSize;\n    if (copy > size) {\n        copy = size;\n    }\n\n    memcpy(data,\n           (const uint8_t *)mBuffers.editItemAt(entry->mIndex)->pointer()\n            + entry->mOffset,\n           copy);\n\n    entry->mOffset += copy;\n    entry->mSize -= copy;\n\n    if (entry->mSize == 0) {\n        mSource->onBufferAvailable(entry->mIndex);\n        mQueue.erase(mQueue.begin());\n        entry = NULL;\n    }\n\n    return copy;\n}",
        "func": "ssize_t NuPlayer::NuPlayerStreamListener::read(\n        void *data, size_t size, sp<AMessage> *extra) {\n    CHECK_GT(size, 0u);\n\n    extra->clear();\n\n    Mutex::Autolock autoLock(mLock);\n\n    if (mEOS) {\n        return 0;\n    }\n\n    if (mQueue.empty()) {\n        mSendDataNotification = true;\n\n        return -EWOULDBLOCK;\n    }\n\n    QueueEntry *entry = &*mQueue.begin();\n\n    if (entry->mIsCommand) {\n        switch (entry->mCommand) {\n            case EOS:\n            {\n                mQueue.erase(mQueue.begin());\n                entry = NULL;\n\n                mEOS = true;\n                return 0;\n            }\n\n            case DISCONTINUITY:\n            {\n                *extra = entry->mExtra;\n\n                mQueue.erase(mQueue.begin());\n                entry = NULL;\n\n                return INFO_DISCONTINUITY;\n            }\n\n            default:\n                TRESPASS();\n                break;\n        }\n    }\n\n    size_t copy = entry->mSize;\n    if (copy > size) {\n        copy = size;\n    }\n\n    if (entry->mIndex >= mBuffers.size()) {\n        return ERROR_MALFORMED;\n    }\n\n    sp<IMemory> mem = mBuffers.editItemAt(entry->mIndex);\n    if (mem == NULL || mem->size() < copy || mem->size() - copy < entry->mOffset) {\n        return ERROR_MALFORMED;\n    }\n\n    memcpy(data,\n           (const uint8_t *)mem->pointer()\n            + entry->mOffset,\n           copy);\n\n    entry->mOffset += copy;\n    entry->mSize -= copy;\n\n    if (entry->mSize == 0) {\n        mSource->onBufferAvailable(entry->mIndex);\n        mQueue.erase(mQueue.begin());\n        entry = NULL;\n    }\n\n    return copy;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -50,8 +50,17 @@\n         copy = size;\n     }\n \n+    if (entry->mIndex >= mBuffers.size()) {\n+        return ERROR_MALFORMED;\n+    }\n+\n+    sp<IMemory> mem = mBuffers.editItemAt(entry->mIndex);\n+    if (mem == NULL || mem->size() < copy || mem->size() - copy < entry->mOffset) {\n+        return ERROR_MALFORMED;\n+    }\n+\n     memcpy(data,\n-           (const uint8_t *)mBuffers.editItemAt(entry->mIndex)->pointer()\n+           (const uint8_t *)mem->pointer()\n             + entry->mOffset,\n            copy);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "           (const uint8_t *)mBuffers.editItemAt(entry->mIndex)->pointer()"
            ],
            "added_lines": [
                "    if (entry->mIndex >= mBuffers.size()) {",
                "        return ERROR_MALFORMED;",
                "    }",
                "",
                "    sp<IMemory> mem = mBuffers.editItemAt(entry->mIndex);",
                "    if (mem == NULL || mem->size() < copy || mem->size() - copy < entry->mOffset) {",
                "        return ERROR_MALFORMED;",
                "    }",
                "",
                "           (const uint8_t *)mem->pointer()"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2449",
        "func_name": "android/Camera3Device::createDefaultRequest",
        "description": "services/camera/libcameraservice/device3/Camera3Device.cpp in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not validate template IDs, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 27568958.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/b04aee833c5cfb6b31b8558350feb14bb1a0f353",
        "commit_title": "Camera3Device: Validate template ID",
        "commit_text": " Validate template ID before creating a default request.  Bug: 26866110 Bug: 27568958 ",
        "func_before": "status_t Camera3Device::createDefaultRequest(int templateId,\n        CameraMetadata *request) {\n    ATRACE_CALL();\n    ALOGV(\"%s: for template %d\", __FUNCTION__, templateId);\n    Mutex::Autolock il(mInterfaceLock);\n    Mutex::Autolock l(mLock);\n\n    switch (mStatus) {\n        case STATUS_ERROR:\n            CLOGE(\"Device has encountered a serious error\");\n            return INVALID_OPERATION;\n        case STATUS_UNINITIALIZED:\n            CLOGE(\"Device is not initialized!\");\n            return INVALID_OPERATION;\n        case STATUS_UNCONFIGURED:\n        case STATUS_CONFIGURED:\n        case STATUS_ACTIVE:\n            // OK\n            break;\n        default:\n            SET_ERR_L(\"Unexpected status: %d\", mStatus);\n            return INVALID_OPERATION;\n    }\n\n    if (!mRequestTemplateCache[templateId].isEmpty()) {\n        *request = mRequestTemplateCache[templateId];\n        return OK;\n    }\n\n    const camera_metadata_t *rawRequest;\n    ATRACE_BEGIN(\"camera3->construct_default_request_settings\");\n    rawRequest = mHal3Device->ops->construct_default_request_settings(\n        mHal3Device, templateId);\n    ATRACE_END();\n    if (rawRequest == NULL) {\n        ALOGI(\"%s: template %d is not supported on this camera device\",\n              __FUNCTION__, templateId);\n        return BAD_VALUE;\n    }\n    *request = rawRequest;\n    mRequestTemplateCache[templateId] = rawRequest;\n\n    return OK;\n}",
        "func": "status_t Camera3Device::createDefaultRequest(int templateId,\n        CameraMetadata *request) {\n    ATRACE_CALL();\n    ALOGV(\"%s: for template %d\", __FUNCTION__, templateId);\n\n    if (templateId <= 0 || templateId >= CAMERA3_TEMPLATE_COUNT) {\n        android_errorWriteWithInfoLog(CameraService::SN_EVENT_LOG_ID, \"26866110\",\n                IPCThreadState::self()->getCallingUid(), NULL, 0);\n        return BAD_VALUE;\n    }\n\n    Mutex::Autolock il(mInterfaceLock);\n    Mutex::Autolock l(mLock);\n\n    switch (mStatus) {\n        case STATUS_ERROR:\n            CLOGE(\"Device has encountered a serious error\");\n            return INVALID_OPERATION;\n        case STATUS_UNINITIALIZED:\n            CLOGE(\"Device is not initialized!\");\n            return INVALID_OPERATION;\n        case STATUS_UNCONFIGURED:\n        case STATUS_CONFIGURED:\n        case STATUS_ACTIVE:\n            // OK\n            break;\n        default:\n            SET_ERR_L(\"Unexpected status: %d\", mStatus);\n            return INVALID_OPERATION;\n    }\n\n    if (!mRequestTemplateCache[templateId].isEmpty()) {\n        *request = mRequestTemplateCache[templateId];\n        return OK;\n    }\n\n    const camera_metadata_t *rawRequest;\n    ATRACE_BEGIN(\"camera3->construct_default_request_settings\");\n    rawRequest = mHal3Device->ops->construct_default_request_settings(\n        mHal3Device, templateId);\n    ATRACE_END();\n    if (rawRequest == NULL) {\n        ALOGI(\"%s: template %d is not supported on this camera device\",\n              __FUNCTION__, templateId);\n        return BAD_VALUE;\n    }\n    *request = rawRequest;\n    mRequestTemplateCache[templateId] = rawRequest;\n\n    return OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,13 @@\n         CameraMetadata *request) {\n     ATRACE_CALL();\n     ALOGV(\"%s: for template %d\", __FUNCTION__, templateId);\n+\n+    if (templateId <= 0 || templateId >= CAMERA3_TEMPLATE_COUNT) {\n+        android_errorWriteWithInfoLog(CameraService::SN_EVENT_LOG_ID, \"26866110\",\n+                IPCThreadState::self()->getCallingUid(), NULL, 0);\n+        return BAD_VALUE;\n+    }\n+\n     Mutex::Autolock il(mInterfaceLock);\n     Mutex::Autolock l(mLock);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (templateId <= 0 || templateId >= CAMERA3_TEMPLATE_COUNT) {",
                "        android_errorWriteWithInfoLog(CameraService::SN_EVENT_LOG_ID, \"26866110\",",
                "                IPCThreadState::self()->getCallingUid(), NULL, 0);",
                "        return BAD_VALUE;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2450",
        "func_name": "android/SoftVPXEncoder::onQueueFilled",
        "description": "codecs/on2/enc/SoftVPXEncoder.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not validate OMX buffer sizes, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 27569635.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/7fd96ebfc4c9da496c59d7c45e1f62be178e626d",
        "commit_title": "codecs: check OMX buffer size before use in VP8 encoder.",
        "commit_text": " Bug: 27569635 ",
        "func_before": "void SoftVPXEncoder::onQueueFilled(OMX_U32 /* portIndex */) {\n    // Initialize encoder if not already\n    if (mCodecContext == NULL) {\n        if (OK != initEncoder()) {\n            ALOGE(\"Failed to initialize encoder\");\n            notify(OMX_EventError,\n                   OMX_ErrorUndefined,\n                   0,  // Extra notification data\n                   NULL);  // Notification data pointer\n            return;\n        }\n    }\n\n    vpx_codec_err_t codec_return;\n    List<BufferInfo *> &inputBufferInfoQueue = getPortQueue(kInputPortIndex);\n    List<BufferInfo *> &outputBufferInfoQueue = getPortQueue(kOutputPortIndex);\n\n    while (!inputBufferInfoQueue.empty() && !outputBufferInfoQueue.empty()) {\n        BufferInfo *inputBufferInfo = *inputBufferInfoQueue.begin();\n        OMX_BUFFERHEADERTYPE *inputBufferHeader = inputBufferInfo->mHeader;\n\n        BufferInfo *outputBufferInfo = *outputBufferInfoQueue.begin();\n        OMX_BUFFERHEADERTYPE *outputBufferHeader = outputBufferInfo->mHeader;\n\n        if ((inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) &&\n                inputBufferHeader->nFilledLen == 0) {\n            inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());\n            inputBufferInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inputBufferHeader);\n\n            outputBufferHeader->nFilledLen = 0;\n            outputBufferHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());\n            outputBufferInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outputBufferHeader);\n            return;\n        }\n\n        const uint8_t *source =\n            inputBufferHeader->pBuffer + inputBufferHeader->nOffset;\n\n        if (mInputDataIsMeta) {\n            source = extractGraphicBuffer(\n                    mConversionBuffer, mWidth * mHeight * 3 / 2,\n                    source, inputBufferHeader->nFilledLen,\n                    mWidth, mHeight);\n            if (source == NULL) {\n                ALOGE(\"Unable to extract gralloc buffer in metadata mode\");\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);\n                return;\n            }\n        } else if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {\n            ConvertYUV420SemiPlanarToYUV420Planar(\n                    source, mConversionBuffer, mWidth, mHeight);\n\n            source = mConversionBuffer;\n        }\n        vpx_image_t raw_frame;\n        vpx_img_wrap(&raw_frame, VPX_IMG_FMT_I420, mWidth, mHeight,\n                     kInputBufferAlignment, (uint8_t *)source);\n\n        vpx_enc_frame_flags_t flags = 0;\n        if (mTemporalPatternLength > 0) {\n            flags = getEncodeFlags();\n        }\n        if (mKeyFrameRequested) {\n            flags |= VPX_EFLAG_FORCE_KF;\n            mKeyFrameRequested = false;\n        }\n\n        if (mBitrateUpdated) {\n            mCodecConfiguration->rc_target_bitrate = mBitrate/1000;\n            vpx_codec_err_t res = vpx_codec_enc_config_set(mCodecContext,\n                                                           mCodecConfiguration);\n            if (res != VPX_CODEC_OK) {\n                ALOGE(\"vp8 encoder failed to update bitrate: %s\",\n                      vpx_codec_err_to_string(res));\n                notify(OMX_EventError,\n                       OMX_ErrorUndefined,\n                       0, // Extra notification data\n                       NULL); // Notification data pointer\n            }\n            mBitrateUpdated = false;\n        }\n\n        uint32_t frameDuration;\n        if (inputBufferHeader->nTimeStamp > mLastTimestamp) {\n            frameDuration = (uint32_t)(inputBufferHeader->nTimeStamp - mLastTimestamp);\n        } else {\n            frameDuration = (uint32_t)(((uint64_t)1000000 << 16) / mFramerate);\n        }\n        mLastTimestamp = inputBufferHeader->nTimeStamp;\n        codec_return = vpx_codec_encode(\n                mCodecContext,\n                &raw_frame,\n                inputBufferHeader->nTimeStamp,  // in timebase units\n                frameDuration,  // frame duration in timebase units\n                flags,  // frame flags\n                VPX_DL_REALTIME);  // encoding deadline\n        if (codec_return != VPX_CODEC_OK) {\n            ALOGE(\"vpx encoder failed to encode frame\");\n            notify(OMX_EventError,\n                   OMX_ErrorUndefined,\n                   0,  // Extra notification data\n                   NULL);  // Notification data pointer\n            return;\n        }\n\n        vpx_codec_iter_t encoded_packet_iterator = NULL;\n        const vpx_codec_cx_pkt_t* encoded_packet;\n\n        while ((encoded_packet = vpx_codec_get_cx_data(\n                        mCodecContext, &encoded_packet_iterator))) {\n            if (encoded_packet->kind == VPX_CODEC_CX_FRAME_PKT) {\n                outputBufferHeader->nTimeStamp = encoded_packet->data.frame.pts;\n                outputBufferHeader->nFlags = 0;\n                if (encoded_packet->data.frame.flags & VPX_FRAME_IS_KEY)\n                  outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;\n                outputBufferHeader->nOffset = 0;\n                outputBufferHeader->nFilledLen = encoded_packet->data.frame.sz;\n                memcpy(outputBufferHeader->pBuffer,\n                       encoded_packet->data.frame.buf,\n                       encoded_packet->data.frame.sz);\n                outputBufferInfo->mOwnedByUs = false;\n                outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());\n                if (inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_EOS;\n                }\n                notifyFillBufferDone(outputBufferHeader);\n            }\n        }\n\n        inputBufferInfo->mOwnedByUs = false;\n        inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());\n        notifyEmptyBufferDone(inputBufferHeader);\n    }\n}",
        "func": "void SoftVPXEncoder::onQueueFilled(OMX_U32 /* portIndex */) {\n    // Initialize encoder if not already\n    if (mCodecContext == NULL) {\n        if (OK != initEncoder()) {\n            ALOGE(\"Failed to initialize encoder\");\n            notify(OMX_EventError,\n                   OMX_ErrorUndefined,\n                   0,  // Extra notification data\n                   NULL);  // Notification data pointer\n            return;\n        }\n    }\n\n    vpx_codec_err_t codec_return;\n    List<BufferInfo *> &inputBufferInfoQueue = getPortQueue(kInputPortIndex);\n    List<BufferInfo *> &outputBufferInfoQueue = getPortQueue(kOutputPortIndex);\n\n    while (!inputBufferInfoQueue.empty() && !outputBufferInfoQueue.empty()) {\n        BufferInfo *inputBufferInfo = *inputBufferInfoQueue.begin();\n        OMX_BUFFERHEADERTYPE *inputBufferHeader = inputBufferInfo->mHeader;\n\n        BufferInfo *outputBufferInfo = *outputBufferInfoQueue.begin();\n        OMX_BUFFERHEADERTYPE *outputBufferHeader = outputBufferInfo->mHeader;\n\n        if ((inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) &&\n                inputBufferHeader->nFilledLen == 0) {\n            inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());\n            inputBufferInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inputBufferHeader);\n\n            outputBufferHeader->nFilledLen = 0;\n            outputBufferHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());\n            outputBufferInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outputBufferHeader);\n            return;\n        }\n\n        const uint8_t *source =\n            inputBufferHeader->pBuffer + inputBufferHeader->nOffset;\n\n        size_t frameSize = mWidth * mHeight * 3 / 2;\n        if (mInputDataIsMeta) {\n            source = extractGraphicBuffer(\n                    mConversionBuffer, frameSize,\n                    source, inputBufferHeader->nFilledLen,\n                    mWidth, mHeight);\n            if (source == NULL) {\n                ALOGE(\"Unable to extract gralloc buffer in metadata mode\");\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);\n                return;\n            }\n        } else {\n            if (inputBufferHeader->nFilledLen < frameSize) {\n                android_errorWriteLog(0x534e4554, \"27569635\");\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);\n                return;\n            } else if (inputBufferHeader->nFilledLen > frameSize) {\n                ALOGW(\"Input buffer contains too many pixels\");\n            }\n\n            if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {\n                ConvertYUV420SemiPlanarToYUV420Planar(\n                        source, mConversionBuffer, mWidth, mHeight);\n\n                source = mConversionBuffer;\n            }\n        }\n        vpx_image_t raw_frame;\n        vpx_img_wrap(&raw_frame, VPX_IMG_FMT_I420, mWidth, mHeight,\n                     kInputBufferAlignment, (uint8_t *)source);\n\n        vpx_enc_frame_flags_t flags = 0;\n        if (mTemporalPatternLength > 0) {\n            flags = getEncodeFlags();\n        }\n        if (mKeyFrameRequested) {\n            flags |= VPX_EFLAG_FORCE_KF;\n            mKeyFrameRequested = false;\n        }\n\n        if (mBitrateUpdated) {\n            mCodecConfiguration->rc_target_bitrate = mBitrate/1000;\n            vpx_codec_err_t res = vpx_codec_enc_config_set(mCodecContext,\n                                                           mCodecConfiguration);\n            if (res != VPX_CODEC_OK) {\n                ALOGE(\"vp8 encoder failed to update bitrate: %s\",\n                      vpx_codec_err_to_string(res));\n                notify(OMX_EventError,\n                       OMX_ErrorUndefined,\n                       0, // Extra notification data\n                       NULL); // Notification data pointer\n            }\n            mBitrateUpdated = false;\n        }\n\n        uint32_t frameDuration;\n        if (inputBufferHeader->nTimeStamp > mLastTimestamp) {\n            frameDuration = (uint32_t)(inputBufferHeader->nTimeStamp - mLastTimestamp);\n        } else {\n            frameDuration = (uint32_t)(((uint64_t)1000000 << 16) / mFramerate);\n        }\n        mLastTimestamp = inputBufferHeader->nTimeStamp;\n        codec_return = vpx_codec_encode(\n                mCodecContext,\n                &raw_frame,\n                inputBufferHeader->nTimeStamp,  // in timebase units\n                frameDuration,  // frame duration in timebase units\n                flags,  // frame flags\n                VPX_DL_REALTIME);  // encoding deadline\n        if (codec_return != VPX_CODEC_OK) {\n            ALOGE(\"vpx encoder failed to encode frame\");\n            notify(OMX_EventError,\n                   OMX_ErrorUndefined,\n                   0,  // Extra notification data\n                   NULL);  // Notification data pointer\n            return;\n        }\n\n        vpx_codec_iter_t encoded_packet_iterator = NULL;\n        const vpx_codec_cx_pkt_t* encoded_packet;\n\n        while ((encoded_packet = vpx_codec_get_cx_data(\n                        mCodecContext, &encoded_packet_iterator))) {\n            if (encoded_packet->kind == VPX_CODEC_CX_FRAME_PKT) {\n                outputBufferHeader->nTimeStamp = encoded_packet->data.frame.pts;\n                outputBufferHeader->nFlags = 0;\n                if (encoded_packet->data.frame.flags & VPX_FRAME_IS_KEY)\n                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;\n                outputBufferHeader->nOffset = 0;\n                outputBufferHeader->nFilledLen = encoded_packet->data.frame.sz;\n                if (outputBufferHeader->nFilledLen > outputBufferHeader->nAllocLen) {\n                    android_errorWriteLog(0x534e4554, \"27569635\");\n                    notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);\n                    return;\n                }\n                memcpy(outputBufferHeader->pBuffer,\n                       encoded_packet->data.frame.buf,\n                       encoded_packet->data.frame.sz);\n                outputBufferInfo->mOwnedByUs = false;\n                outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());\n                if (inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_EOS;\n                }\n                notifyFillBufferDone(outputBufferHeader);\n            }\n        }\n\n        inputBufferInfo->mOwnedByUs = false;\n        inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());\n        notifyEmptyBufferDone(inputBufferHeader);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -40,9 +40,10 @@\n         const uint8_t *source =\n             inputBufferHeader->pBuffer + inputBufferHeader->nOffset;\n \n+        size_t frameSize = mWidth * mHeight * 3 / 2;\n         if (mInputDataIsMeta) {\n             source = extractGraphicBuffer(\n-                    mConversionBuffer, mWidth * mHeight * 3 / 2,\n+                    mConversionBuffer, frameSize,\n                     source, inputBufferHeader->nFilledLen,\n                     mWidth, mHeight);\n             if (source == NULL) {\n@@ -50,11 +51,21 @@\n                 notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);\n                 return;\n             }\n-        } else if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {\n-            ConvertYUV420SemiPlanarToYUV420Planar(\n-                    source, mConversionBuffer, mWidth, mHeight);\n+        } else {\n+            if (inputBufferHeader->nFilledLen < frameSize) {\n+                android_errorWriteLog(0x534e4554, \"27569635\");\n+                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);\n+                return;\n+            } else if (inputBufferHeader->nFilledLen > frameSize) {\n+                ALOGW(\"Input buffer contains too many pixels\");\n+            }\n \n-            source = mConversionBuffer;\n+            if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {\n+                ConvertYUV420SemiPlanarToYUV420Planar(\n+                        source, mConversionBuffer, mWidth, mHeight);\n+\n+                source = mConversionBuffer;\n+            }\n         }\n         vpx_image_t raw_frame;\n         vpx_img_wrap(&raw_frame, VPX_IMG_FMT_I420, mWidth, mHeight,\n@@ -116,9 +127,14 @@\n                 outputBufferHeader->nTimeStamp = encoded_packet->data.frame.pts;\n                 outputBufferHeader->nFlags = 0;\n                 if (encoded_packet->data.frame.flags & VPX_FRAME_IS_KEY)\n-                  outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;\n+                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;\n                 outputBufferHeader->nOffset = 0;\n                 outputBufferHeader->nFilledLen = encoded_packet->data.frame.sz;\n+                if (outputBufferHeader->nFilledLen > outputBufferHeader->nAllocLen) {\n+                    android_errorWriteLog(0x534e4554, \"27569635\");\n+                    notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);\n+                    return;\n+                }\n                 memcpy(outputBufferHeader->pBuffer,\n                        encoded_packet->data.frame.buf,\n                        encoded_packet->data.frame.sz);",
        "diff_line_info": {
            "deleted_lines": [
                "                    mConversionBuffer, mWidth * mHeight * 3 / 2,",
                "        } else if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {",
                "            ConvertYUV420SemiPlanarToYUV420Planar(",
                "                    source, mConversionBuffer, mWidth, mHeight);",
                "            source = mConversionBuffer;",
                "                  outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;"
            ],
            "added_lines": [
                "        size_t frameSize = mWidth * mHeight * 3 / 2;",
                "                    mConversionBuffer, frameSize,",
                "        } else {",
                "            if (inputBufferHeader->nFilledLen < frameSize) {",
                "                android_errorWriteLog(0x534e4554, \"27569635\");",
                "                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);",
                "                return;",
                "            } else if (inputBufferHeader->nFilledLen > frameSize) {",
                "                ALOGW(\"Input buffer contains too many pixels\");",
                "            }",
                "            if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {",
                "                ConvertYUV420SemiPlanarToYUV420Planar(",
                "                        source, mConversionBuffer, mWidth, mHeight);",
                "",
                "                source = mConversionBuffer;",
                "            }",
                "                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;",
                "                if (outputBufferHeader->nFilledLen > outputBufferHeader->nAllocLen) {",
                "                    android_errorWriteLog(0x534e4554, \"27569635\");",
                "                    notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);",
                "                    return;",
                "                }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2451",
        "func_name": "android/OMX::binderDied",
        "description": "codecs/on2/dec/SoftVPX.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not validate VPX output buffer sizes, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 27597103.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/f9ed2fe6d61259e779a37d4c2d7edb33a1c1f8ba",
        "commit_title": "Add VPX output buffer size check",
        "commit_text": " and handle dead observers more gracefully  Bug: 27597103 ",
        "func_before": "void OMX::binderDied(const wp<IBinder> &the_late_who) {\n    OMXNodeInstance *instance;\n\n    {\n        Mutex::Autolock autoLock(mLock);\n\n        ssize_t index = mLiveNodes.indexOfKey(the_late_who);\n        CHECK(index >= 0);\n\n        instance = mLiveNodes.editValueAt(index);\n        mLiveNodes.removeItemsAt(index);\n\n        index = mDispatchers.indexOfKey(instance->nodeID());\n        CHECK(index >= 0);\n        mDispatchers.removeItemsAt(index);\n\n        invalidateNodeID_l(instance->nodeID());\n    }\n\n    instance->onObserverDied(mMaster);\n}",
        "func": "void OMX::binderDied(const wp<IBinder> &the_late_who) {\n    OMXNodeInstance *instance;\n\n    {\n        Mutex::Autolock autoLock(mLock);\n\n        ssize_t index = mLiveNodes.indexOfKey(the_late_who);\n\n        if (index < 0) {\n            ALOGE(\"b/27597103, nonexistent observer on binderDied\");\n            android_errorWriteLog(0x534e4554, \"27597103\");\n            return;\n        }\n\n        instance = mLiveNodes.editValueAt(index);\n        mLiveNodes.removeItemsAt(index);\n\n        index = mDispatchers.indexOfKey(instance->nodeID());\n        CHECK(index >= 0);\n        mDispatchers.removeItemsAt(index);\n\n        invalidateNodeID_l(instance->nodeID());\n    }\n\n    instance->onObserverDied(mMaster);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,12 @@\n         Mutex::Autolock autoLock(mLock);\n \n         ssize_t index = mLiveNodes.indexOfKey(the_late_who);\n-        CHECK(index >= 0);\n+\n+        if (index < 0) {\n+            ALOGE(\"b/27597103, nonexistent observer on binderDied\");\n+            android_errorWriteLog(0x534e4554, \"27597103\");\n+            return;\n+        }\n \n         instance = mLiveNodes.editValueAt(index);\n         mLiveNodes.removeItemsAt(index);",
        "diff_line_info": {
            "deleted_lines": [
                "        CHECK(index >= 0);"
            ],
            "added_lines": [
                "",
                "        if (index < 0) {",
                "            ALOGE(\"b/27597103, nonexistent observer on binderDied\");",
                "            android_errorWriteLog(0x534e4554, \"27597103\");",
                "            return;",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2451",
        "func_name": "android/SoftVPX::outputBuffers",
        "description": "codecs/on2/dec/SoftVPX.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not validate VPX output buffer sizes, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 27597103.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/f9ed2fe6d61259e779a37d4c2d7edb33a1c1f8ba",
        "commit_title": "Add VPX output buffer size check",
        "commit_text": " and handle dead observers more gracefully  Bug: 27597103 ",
        "func_before": "bool SoftVPX::outputBuffers(bool flushDecoder, bool display, bool eos, bool *portWillReset) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n    BufferInfo *outInfo = NULL;\n    OMX_BUFFERHEADERTYPE *outHeader = NULL;\n    vpx_codec_iter_t iter = NULL;\n\n    if (flushDecoder && mFrameParallelMode) {\n        // Flush decoder by passing NULL data ptr and 0 size.\n        // Ideally, this should never fail.\n        if (vpx_codec_decode((vpx_codec_ctx_t *)mCtx, NULL, 0, NULL, 0)) {\n            ALOGE(\"Failed to flush on2 decoder.\");\n            return false;\n        }\n    }\n\n    if (!display) {\n        if (!flushDecoder) {\n            ALOGE(\"Invalid operation.\");\n            return false;\n        }\n        // Drop all the decoded frames in decoder.\n        while ((mImg = vpx_codec_get_frame((vpx_codec_ctx_t *)mCtx, &iter))) {\n        }\n        return true;\n    }\n\n    while (!outQueue.empty()) {\n        if (mImg == NULL) {\n            mImg = vpx_codec_get_frame((vpx_codec_ctx_t *)mCtx, &iter);\n            if (mImg == NULL) {\n                break;\n            }\n        }\n        uint32_t width = mImg->d_w;\n        uint32_t height = mImg->d_h;\n        outInfo = *outQueue.begin();\n        outHeader = outInfo->mHeader;\n        CHECK_EQ(mImg->fmt, VPX_IMG_FMT_I420);\n        handlePortSettingsChange(portWillReset, width, height);\n        if (*portWillReset) {\n            return true;\n        }\n\n        outHeader->nOffset = 0;\n        outHeader->nFlags = 0;\n        outHeader->nFilledLen = (outputBufferWidth() * outputBufferHeight() * 3) / 2;\n        outHeader->nTimeStamp = *(OMX_TICKS *)mImg->user_priv;\n\n        uint8_t *dst = outHeader->pBuffer;\n        const uint8_t *srcY = (const uint8_t *)mImg->planes[VPX_PLANE_Y];\n        const uint8_t *srcU = (const uint8_t *)mImg->planes[VPX_PLANE_U];\n        const uint8_t *srcV = (const uint8_t *)mImg->planes[VPX_PLANE_V];\n        size_t srcYStride = mImg->stride[VPX_PLANE_Y];\n        size_t srcUStride = mImg->stride[VPX_PLANE_U];\n        size_t srcVStride = mImg->stride[VPX_PLANE_V];\n        copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);\n\n        mImg = NULL;\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n    }\n\n    if (!eos) {\n        return true;\n    }\n\n    if (!outQueue.empty()) {\n        outInfo = *outQueue.begin();\n        outQueue.erase(outQueue.begin());\n        outHeader = outInfo->mHeader;\n        outHeader->nTimeStamp = 0;\n        outHeader->nFilledLen = 0;\n        outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n        outInfo->mOwnedByUs = false;\n        notifyFillBufferDone(outHeader);\n        mEOSStatus = OUTPUT_FRAMES_FLUSHED;\n    }\n    return true;\n}",
        "func": "bool SoftVPX::outputBuffers(bool flushDecoder, bool display, bool eos, bool *portWillReset) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n    BufferInfo *outInfo = NULL;\n    OMX_BUFFERHEADERTYPE *outHeader = NULL;\n    vpx_codec_iter_t iter = NULL;\n\n    if (flushDecoder && mFrameParallelMode) {\n        // Flush decoder by passing NULL data ptr and 0 size.\n        // Ideally, this should never fail.\n        if (vpx_codec_decode((vpx_codec_ctx_t *)mCtx, NULL, 0, NULL, 0)) {\n            ALOGE(\"Failed to flush on2 decoder.\");\n            return false;\n        }\n    }\n\n    if (!display) {\n        if (!flushDecoder) {\n            ALOGE(\"Invalid operation.\");\n            return false;\n        }\n        // Drop all the decoded frames in decoder.\n        while ((mImg = vpx_codec_get_frame((vpx_codec_ctx_t *)mCtx, &iter))) {\n        }\n        return true;\n    }\n\n    while (!outQueue.empty()) {\n        if (mImg == NULL) {\n            mImg = vpx_codec_get_frame((vpx_codec_ctx_t *)mCtx, &iter);\n            if (mImg == NULL) {\n                break;\n            }\n        }\n        uint32_t width = mImg->d_w;\n        uint32_t height = mImg->d_h;\n        outInfo = *outQueue.begin();\n        outHeader = outInfo->mHeader;\n        CHECK_EQ(mImg->fmt, VPX_IMG_FMT_I420);\n        handlePortSettingsChange(portWillReset, width, height);\n        if (*portWillReset) {\n            return true;\n        }\n\n        outHeader->nOffset = 0;\n        outHeader->nFlags = 0;\n        outHeader->nFilledLen = (outputBufferWidth() * outputBufferHeight() * 3) / 2;\n        outHeader->nTimeStamp = *(OMX_TICKS *)mImg->user_priv;\n        if (outHeader->nAllocLen >= outHeader->nFilledLen) {\n            uint8_t *dst = outHeader->pBuffer;\n            const uint8_t *srcY = (const uint8_t *)mImg->planes[VPX_PLANE_Y];\n            const uint8_t *srcU = (const uint8_t *)mImg->planes[VPX_PLANE_U];\n            const uint8_t *srcV = (const uint8_t *)mImg->planes[VPX_PLANE_V];\n            size_t srcYStride = mImg->stride[VPX_PLANE_Y];\n            size_t srcUStride = mImg->stride[VPX_PLANE_U];\n            size_t srcVStride = mImg->stride[VPX_PLANE_V];\n            copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);\n        } else {\n            ALOGE(\"b/27597103, buffer too small\");\n            android_errorWriteLog(0x534e4554, \"27597103\");\n            outHeader->nFilledLen = 0;\n        }\n\n        mImg = NULL;\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n    }\n\n    if (!eos) {\n        return true;\n    }\n\n    if (!outQueue.empty()) {\n        outInfo = *outQueue.begin();\n        outQueue.erase(outQueue.begin());\n        outHeader = outInfo->mHeader;\n        outHeader->nTimeStamp = 0;\n        outHeader->nFilledLen = 0;\n        outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n        outInfo->mOwnedByUs = false;\n        notifyFillBufferDone(outHeader);\n        mEOSStatus = OUTPUT_FRAMES_FLUSHED;\n    }\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,15 +46,20 @@\n         outHeader->nFlags = 0;\n         outHeader->nFilledLen = (outputBufferWidth() * outputBufferHeight() * 3) / 2;\n         outHeader->nTimeStamp = *(OMX_TICKS *)mImg->user_priv;\n-\n-        uint8_t *dst = outHeader->pBuffer;\n-        const uint8_t *srcY = (const uint8_t *)mImg->planes[VPX_PLANE_Y];\n-        const uint8_t *srcU = (const uint8_t *)mImg->planes[VPX_PLANE_U];\n-        const uint8_t *srcV = (const uint8_t *)mImg->planes[VPX_PLANE_V];\n-        size_t srcYStride = mImg->stride[VPX_PLANE_Y];\n-        size_t srcUStride = mImg->stride[VPX_PLANE_U];\n-        size_t srcVStride = mImg->stride[VPX_PLANE_V];\n-        copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);\n+        if (outHeader->nAllocLen >= outHeader->nFilledLen) {\n+            uint8_t *dst = outHeader->pBuffer;\n+            const uint8_t *srcY = (const uint8_t *)mImg->planes[VPX_PLANE_Y];\n+            const uint8_t *srcU = (const uint8_t *)mImg->planes[VPX_PLANE_U];\n+            const uint8_t *srcV = (const uint8_t *)mImg->planes[VPX_PLANE_V];\n+            size_t srcYStride = mImg->stride[VPX_PLANE_Y];\n+            size_t srcUStride = mImg->stride[VPX_PLANE_U];\n+            size_t srcVStride = mImg->stride[VPX_PLANE_V];\n+            copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);\n+        } else {\n+            ALOGE(\"b/27597103, buffer too small\");\n+            android_errorWriteLog(0x534e4554, \"27597103\");\n+            outHeader->nFilledLen = 0;\n+        }\n \n         mImg = NULL;\n         outInfo->mOwnedByUs = false;",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "        uint8_t *dst = outHeader->pBuffer;",
                "        const uint8_t *srcY = (const uint8_t *)mImg->planes[VPX_PLANE_Y];",
                "        const uint8_t *srcU = (const uint8_t *)mImg->planes[VPX_PLANE_U];",
                "        const uint8_t *srcV = (const uint8_t *)mImg->planes[VPX_PLANE_V];",
                "        size_t srcYStride = mImg->stride[VPX_PLANE_Y];",
                "        size_t srcUStride = mImg->stride[VPX_PLANE_U];",
                "        size_t srcVStride = mImg->stride[VPX_PLANE_V];",
                "        copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);"
            ],
            "added_lines": [
                "        if (outHeader->nAllocLen >= outHeader->nFilledLen) {",
                "            uint8_t *dst = outHeader->pBuffer;",
                "            const uint8_t *srcY = (const uint8_t *)mImg->planes[VPX_PLANE_Y];",
                "            const uint8_t *srcU = (const uint8_t *)mImg->planes[VPX_PLANE_U];",
                "            const uint8_t *srcV = (const uint8_t *)mImg->planes[VPX_PLANE_V];",
                "            size_t srcYStride = mImg->stride[VPX_PLANE_Y];",
                "            size_t srcUStride = mImg->stride[VPX_PLANE_U];",
                "            size_t srcVStride = mImg->stride[VPX_PLANE_V];",
                "            copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);",
                "        } else {",
                "            ALOGE(\"b/27597103, buffer too small\");",
                "            android_errorWriteLog(0x534e4554, \"27597103\");",
                "            outHeader->nFilledLen = 0;",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2452",
        "func_name": "android/SoftAMR::onQueueFilled",
        "description": "codecs/amrnb/dec/SoftAMR.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not validate buffer sizes, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bugs 27662364 and 27843673.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/65756b4082cd79a2d99b2ccb5b392291fd53703f",
        "commit_title": "SoftAMR: check input buffer size to avoid overflow.",
        "commit_text": " Bug: 27662364 ",
        "func_before": "void SoftAMR::onQueueFilled(OMX_U32 /* portIndex */) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    while (!inQueue.empty() && !outQueue.empty()) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            outHeader->nFilledLen = 0;\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outQueue.erase(outQueue.begin());\n            outInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outHeader);\n            return;\n        }\n\n        if (inHeader->nOffset == 0) {\n            mAnchorTimeUs = inHeader->nTimeStamp;\n            mNumSamplesOutput = 0;\n        }\n\n        const uint8_t *inputPtr = inHeader->pBuffer + inHeader->nOffset;\n        int32_t numBytesRead;\n\n        if (mMode == MODE_NARROW) {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: NB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            numBytesRead =\n                AMRDecode(mState,\n                  (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),\n                  (UWord8 *)&inputPtr[1],\n                  reinterpret_cast<int16_t *>(outHeader->pBuffer),\n                  MIME_IETF);\n\n            if (numBytesRead == -1) {\n                ALOGE(\"PV AMR decoder AMRDecode() call failed\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            ++numBytesRead;  // Include the frame type header byte.\n\n            if (static_cast<size_t>(numBytesRead) > inHeader->nFilledLen) {\n                // This is bad, should never have happened, but did. Abort now.\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n        } else {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: WB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n\n            if (mode >= 10 && mode <= 13) {\n                ALOGE(\"encountered illegal frame type %d in AMR WB content.\",\n                      mode);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            size_t frameSize = getFrameSize(mode);\n            CHECK_GE(inHeader->nFilledLen, frameSize);\n\n            int16_t *outPtr = (int16_t *)outHeader->pBuffer;\n\n            if (mode >= 9) {\n                // Produce silence instead of comfort noise and for\n                // speech lost/no data.\n                memset(outPtr, 0, kNumSamplesPerFrameWB * sizeof(int16_t));\n            } else if (mode < 9) {\n                int16 frameType;\n                RX_State_wb rx_state;\n                mime_unsorting(\n                        const_cast<uint8_t *>(&inputPtr[1]),\n                        mInputSampleBuffer,\n                        &frameType, &mode, 1, &rx_state);\n\n                int16_t numSamplesOutput;\n                pvDecoder_AmrWb(\n                        mode, mInputSampleBuffer,\n                        outPtr,\n                        &numSamplesOutput,\n                        mDecoderBuf, frameType, mDecoderCookie);\n\n                CHECK_EQ((int)numSamplesOutput, (int)kNumSamplesPerFrameWB);\n\n                for (int i = 0; i < kNumSamplesPerFrameWB; ++i) {\n                    /* Delete the 2 LSBs (14-bit output) */\n                    outPtr[i] &= 0xfffC;\n                }\n            }\n\n            numBytesRead = frameSize;\n        }\n\n        inHeader->nOffset += numBytesRead;\n        inHeader->nFilledLen -= numBytesRead;\n\n        outHeader->nFlags = 0;\n        outHeader->nOffset = 0;\n\n        if (mMode == MODE_NARROW) {\n            outHeader->nFilledLen = kNumSamplesPerFrameNB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateNB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameNB;\n        } else {\n            outHeader->nFilledLen = kNumSamplesPerFrameWB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateWB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameWB;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mInputBufferCount;\n    }\n}",
        "func": "void SoftAMR::onQueueFilled(OMX_U32 /* portIndex */) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    while (!inQueue.empty() && !outQueue.empty()) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            notifyEmptyBufferDone(inHeader);\n            continue;\n        }\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            outHeader->nFilledLen = 0;\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outQueue.erase(outQueue.begin());\n            outInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outHeader);\n            return;\n        }\n\n        if (inHeader->nOffset == 0) {\n            mAnchorTimeUs = inHeader->nTimeStamp;\n            mNumSamplesOutput = 0;\n        }\n\n        const uint8_t *inputPtr = inHeader->pBuffer + inHeader->nOffset;\n        int32_t numBytesRead;\n\n        if (mMode == MODE_NARROW) {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: NB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n            // for WMF since MIME_IETF is used when calling AMRDecode.\n            size_t frameSize = WmfDecBytesPerFrame[mode] + 1;\n\n            if (inHeader->nFilledLen < frameSize) {\n                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            numBytesRead =\n                AMRDecode(mState,\n                  (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),\n                  (UWord8 *)&inputPtr[1],\n                  reinterpret_cast<int16_t *>(outHeader->pBuffer),\n                  MIME_IETF);\n\n            if (numBytesRead == -1) {\n                ALOGE(\"PV AMR decoder AMRDecode() call failed\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            ++numBytesRead;  // Include the frame type header byte.\n\n            if (static_cast<size_t>(numBytesRead) > inHeader->nFilledLen) {\n                // This is bad, should never have happened, but did. Abort now.\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n        } else {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: WB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n\n            if (mode >= 10 && mode <= 13) {\n                ALOGE(\"encountered illegal frame type %d in AMR WB content.\",\n                      mode);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            size_t frameSize = getFrameSize(mode);\n            if (inHeader->nFilledLen < frameSize) {\n                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16_t *outPtr = (int16_t *)outHeader->pBuffer;\n\n            if (mode >= 9) {\n                // Produce silence instead of comfort noise and for\n                // speech lost/no data.\n                memset(outPtr, 0, kNumSamplesPerFrameWB * sizeof(int16_t));\n            } else if (mode < 9) {\n                int16 frameType;\n                RX_State_wb rx_state;\n                mime_unsorting(\n                        const_cast<uint8_t *>(&inputPtr[1]),\n                        mInputSampleBuffer,\n                        &frameType, &mode, 1, &rx_state);\n\n                int16_t numSamplesOutput;\n                pvDecoder_AmrWb(\n                        mode, mInputSampleBuffer,\n                        outPtr,\n                        &numSamplesOutput,\n                        mDecoderBuf, frameType, mDecoderCookie);\n\n                CHECK_EQ((int)numSamplesOutput, (int)kNumSamplesPerFrameWB);\n\n                for (int i = 0; i < kNumSamplesPerFrameWB; ++i) {\n                    /* Delete the 2 LSBs (14-bit output) */\n                    outPtr[i] &= 0xfffC;\n                }\n            }\n\n            numBytesRead = frameSize;\n        }\n\n        inHeader->nOffset += numBytesRead;\n        inHeader->nFilledLen -= numBytesRead;\n\n        outHeader->nFlags = 0;\n        outHeader->nOffset = 0;\n\n        if (mMode == MODE_NARROW) {\n            outHeader->nFilledLen = kNumSamplesPerFrameNB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateNB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameNB;\n        } else {\n            outHeader->nFilledLen = kNumSamplesPerFrameWB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateWB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameWB;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mInputBufferCount;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,13 @@\n     while (!inQueue.empty() && !outQueue.empty()) {\n         BufferInfo *inInfo = *inQueue.begin();\n         OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n+\n+        if (inHeader->nFilledLen == 0) {\n+            inInfo->mOwnedByUs = false;\n+            inQueue.erase(inQueue.begin());\n+            notifyEmptyBufferDone(inHeader);\n+            continue;\n+        }\n \n         BufferInfo *outInfo = *outQueue.begin();\n         OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n@@ -41,6 +48,17 @@\n                        kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);\n                 android_errorWriteLog(0x534e4554, \"27662364\");\n                 notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n+                mSignalledError = true;\n+                return;\n+            }\n+\n+            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n+            // for WMF since MIME_IETF is used when calling AMRDecode.\n+            size_t frameSize = WmfDecBytesPerFrame[mode] + 1;\n+\n+            if (inHeader->nFilledLen < frameSize) {\n+                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n+                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n                 mSignalledError = true;\n                 return;\n             }\n@@ -94,7 +112,12 @@\n             }\n \n             size_t frameSize = getFrameSize(mode);\n-            CHECK_GE(inHeader->nFilledLen, frameSize);\n+            if (inHeader->nFilledLen < frameSize) {\n+                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n+                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n+                mSignalledError = true;\n+                return;\n+            }\n \n             int16_t *outPtr = (int16_t *)outHeader->pBuffer;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            CHECK_GE(inHeader->nFilledLen, frameSize);"
            ],
            "added_lines": [
                "",
                "        if (inHeader->nFilledLen == 0) {",
                "            inInfo->mOwnedByUs = false;",
                "            inQueue.erase(inQueue.begin());",
                "            notifyEmptyBufferDone(inHeader);",
                "            continue;",
                "        }",
                "                mSignalledError = true;",
                "                return;",
                "            }",
                "",
                "            int16 mode = ((inputPtr[0] >> 3) & 0x0f);",
                "            // for WMF since MIME_IETF is used when calling AMRDecode.",
                "            size_t frameSize = WmfDecBytesPerFrame[mode] + 1;",
                "",
                "            if (inHeader->nFilledLen < frameSize) {",
                "                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);",
                "                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);",
                "            if (inHeader->nFilledLen < frameSize) {",
                "                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);",
                "                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);",
                "                mSignalledError = true;",
                "                return;",
                "            }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2452",
        "func_name": "android/SoftAMR::onQueueFilled",
        "description": "codecs/amrnb/dec/SoftAMR.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not validate buffer sizes, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bugs 27662364 and 27843673.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/daa85dac2055b22dabbb3b4e537597e6ab73a866",
        "commit_title": "Fix AMR decoder",
        "commit_text": " Previous change caused EOS to be ignored.  Bug: 27843673 Related-to-bug: 27662364 ",
        "func_before": "void SoftAMR::onQueueFilled(OMX_U32 /* portIndex */) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    while (!inQueue.empty() && !outQueue.empty()) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            notifyEmptyBufferDone(inHeader);\n            continue;\n        }\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            outHeader->nFilledLen = 0;\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outQueue.erase(outQueue.begin());\n            outInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outHeader);\n            return;\n        }\n\n        if (inHeader->nOffset == 0) {\n            mAnchorTimeUs = inHeader->nTimeStamp;\n            mNumSamplesOutput = 0;\n        }\n\n        const uint8_t *inputPtr = inHeader->pBuffer + inHeader->nOffset;\n        int32_t numBytesRead;\n\n        if (mMode == MODE_NARROW) {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: NB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n            // for WMF since MIME_IETF is used when calling AMRDecode.\n            size_t frameSize = WmfDecBytesPerFrame[mode] + 1;\n\n            if (inHeader->nFilledLen < frameSize) {\n                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            numBytesRead =\n                AMRDecode(mState,\n                  (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),\n                  (UWord8 *)&inputPtr[1],\n                  reinterpret_cast<int16_t *>(outHeader->pBuffer),\n                  MIME_IETF);\n\n            if (numBytesRead == -1) {\n                ALOGE(\"PV AMR decoder AMRDecode() call failed\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            ++numBytesRead;  // Include the frame type header byte.\n\n            if (static_cast<size_t>(numBytesRead) > inHeader->nFilledLen) {\n                // This is bad, should never have happened, but did. Abort now.\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n        } else {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: WB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n\n            if (mode >= 10 && mode <= 13) {\n                ALOGE(\"encountered illegal frame type %d in AMR WB content.\",\n                      mode);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            size_t frameSize = getFrameSize(mode);\n            if (inHeader->nFilledLen < frameSize) {\n                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16_t *outPtr = (int16_t *)outHeader->pBuffer;\n\n            if (mode >= 9) {\n                // Produce silence instead of comfort noise and for\n                // speech lost/no data.\n                memset(outPtr, 0, kNumSamplesPerFrameWB * sizeof(int16_t));\n            } else if (mode < 9) {\n                int16 frameType;\n                RX_State_wb rx_state;\n                mime_unsorting(\n                        const_cast<uint8_t *>(&inputPtr[1]),\n                        mInputSampleBuffer,\n                        &frameType, &mode, 1, &rx_state);\n\n                int16_t numSamplesOutput;\n                pvDecoder_AmrWb(\n                        mode, mInputSampleBuffer,\n                        outPtr,\n                        &numSamplesOutput,\n                        mDecoderBuf, frameType, mDecoderCookie);\n\n                CHECK_EQ((int)numSamplesOutput, (int)kNumSamplesPerFrameWB);\n\n                for (int i = 0; i < kNumSamplesPerFrameWB; ++i) {\n                    /* Delete the 2 LSBs (14-bit output) */\n                    outPtr[i] &= 0xfffC;\n                }\n            }\n\n            numBytesRead = frameSize;\n        }\n\n        inHeader->nOffset += numBytesRead;\n        inHeader->nFilledLen -= numBytesRead;\n\n        outHeader->nFlags = 0;\n        outHeader->nOffset = 0;\n\n        if (mMode == MODE_NARROW) {\n            outHeader->nFilledLen = kNumSamplesPerFrameNB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateNB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameNB;\n        } else {\n            outHeader->nFilledLen = kNumSamplesPerFrameWB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateWB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameWB;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mInputBufferCount;\n    }\n}",
        "func": "void SoftAMR::onQueueFilled(OMX_U32 /* portIndex */) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    while (!inQueue.empty() && !outQueue.empty()) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            outHeader->nFilledLen = 0;\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outQueue.erase(outQueue.begin());\n            outInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outHeader);\n            return;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            notifyEmptyBufferDone(inHeader);\n            continue;\n        }\n\n        if (inHeader->nOffset == 0) {\n            mAnchorTimeUs = inHeader->nTimeStamp;\n            mNumSamplesOutput = 0;\n        }\n\n        const uint8_t *inputPtr = inHeader->pBuffer + inHeader->nOffset;\n        int32_t numBytesRead;\n\n        if (mMode == MODE_NARROW) {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: NB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n            // for WMF since MIME_IETF is used when calling AMRDecode.\n            size_t frameSize = WmfDecBytesPerFrame[mode] + 1;\n\n            if (inHeader->nFilledLen < frameSize) {\n                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            numBytesRead =\n                AMRDecode(mState,\n                  (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),\n                  (UWord8 *)&inputPtr[1],\n                  reinterpret_cast<int16_t *>(outHeader->pBuffer),\n                  MIME_IETF);\n\n            if (numBytesRead == -1) {\n                ALOGE(\"PV AMR decoder AMRDecode() call failed\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            ++numBytesRead;  // Include the frame type header byte.\n\n            if (static_cast<size_t>(numBytesRead) > inHeader->nFilledLen) {\n                // This is bad, should never have happened, but did. Abort now.\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n        } else {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: WB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n\n            if (mode >= 10 && mode <= 13) {\n                ALOGE(\"encountered illegal frame type %d in AMR WB content.\",\n                      mode);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            size_t frameSize = getFrameSize(mode);\n            if (inHeader->nFilledLen < frameSize) {\n                ALOGE(\"b/27662364: expected %zu bytes vs %u\", frameSize, inHeader->nFilledLen);\n                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16_t *outPtr = (int16_t *)outHeader->pBuffer;\n\n            if (mode >= 9) {\n                // Produce silence instead of comfort noise and for\n                // speech lost/no data.\n                memset(outPtr, 0, kNumSamplesPerFrameWB * sizeof(int16_t));\n            } else if (mode < 9) {\n                int16 frameType;\n                RX_State_wb rx_state;\n                mime_unsorting(\n                        const_cast<uint8_t *>(&inputPtr[1]),\n                        mInputSampleBuffer,\n                        &frameType, &mode, 1, &rx_state);\n\n                int16_t numSamplesOutput;\n                pvDecoder_AmrWb(\n                        mode, mInputSampleBuffer,\n                        outPtr,\n                        &numSamplesOutput,\n                        mDecoderBuf, frameType, mDecoderCookie);\n\n                CHECK_EQ((int)numSamplesOutput, (int)kNumSamplesPerFrameWB);\n\n                for (int i = 0; i < kNumSamplesPerFrameWB; ++i) {\n                    /* Delete the 2 LSBs (14-bit output) */\n                    outPtr[i] &= 0xfffC;\n                }\n            }\n\n            numBytesRead = frameSize;\n        }\n\n        inHeader->nOffset += numBytesRead;\n        inHeader->nFilledLen -= numBytesRead;\n\n        outHeader->nFlags = 0;\n        outHeader->nOffset = 0;\n\n        if (mMode == MODE_NARROW) {\n            outHeader->nFilledLen = kNumSamplesPerFrameNB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateNB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameNB;\n        } else {\n            outHeader->nFilledLen = kNumSamplesPerFrameWB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateWB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameWB;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mInputBufferCount;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,13 +9,6 @@\n     while (!inQueue.empty() && !outQueue.empty()) {\n         BufferInfo *inInfo = *inQueue.begin();\n         OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n-\n-        if (inHeader->nFilledLen == 0) {\n-            inInfo->mOwnedByUs = false;\n-            inQueue.erase(inQueue.begin());\n-            notifyEmptyBufferDone(inHeader);\n-            continue;\n-        }\n \n         BufferInfo *outInfo = *outQueue.begin();\n         OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n@@ -32,6 +25,13 @@\n             outInfo->mOwnedByUs = false;\n             notifyFillBufferDone(outHeader);\n             return;\n+        }\n+\n+        if (inHeader->nFilledLen == 0) {\n+            inInfo->mOwnedByUs = false;\n+            inQueue.erase(inQueue.begin());\n+            notifyEmptyBufferDone(inHeader);\n+            continue;\n         }\n \n         if (inHeader->nOffset == 0) {",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "        if (inHeader->nFilledLen == 0) {",
                "            inInfo->mOwnedByUs = false;",
                "            inQueue.erase(inQueue.begin());",
                "            notifyEmptyBufferDone(inHeader);",
                "            continue;",
                "        }"
            ],
            "added_lines": [
                "        }",
                "",
                "        if (inHeader->nFilledLen == 0) {",
                "            inInfo->mOwnedByUs = false;",
                "            inQueue.erase(inQueue.begin());",
                "            notifyEmptyBufferDone(inHeader);",
                "            continue;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2452",
        "func_name": "android/SoftAMR::onQueueFilled",
        "description": "codecs/amrnb/dec/SoftAMR.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-05-01 does not validate buffer sizes, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bugs 27662364 and 27843673.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/44749eb4f273f0eb681d0fa013e3beef754fa687",
        "commit_title": "SoftAMR: check output buffer size to avoid overflow.",
        "commit_text": " Bug: 27662364 ",
        "func_before": "void SoftAMR::onQueueFilled(OMX_U32 /* portIndex */) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    while (!inQueue.empty() && !outQueue.empty()) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            outHeader->nFilledLen = 0;\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outQueue.erase(outQueue.begin());\n            outInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outHeader);\n            return;\n        }\n\n        if (inHeader->nOffset == 0) {\n            mAnchorTimeUs = inHeader->nTimeStamp;\n            mNumSamplesOutput = 0;\n        }\n\n        const uint8_t *inputPtr = inHeader->pBuffer + inHeader->nOffset;\n        int32_t numBytesRead;\n\n        if (mMode == MODE_NARROW) {\n            numBytesRead =\n                AMRDecode(mState,\n                  (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),\n                  (UWord8 *)&inputPtr[1],\n                  reinterpret_cast<int16_t *>(outHeader->pBuffer),\n                  MIME_IETF);\n\n            if (numBytesRead == -1) {\n                ALOGE(\"PV AMR decoder AMRDecode() call failed\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            ++numBytesRead;  // Include the frame type header byte.\n\n            if (static_cast<size_t>(numBytesRead) > inHeader->nFilledLen) {\n                // This is bad, should never have happened, but did. Abort now.\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n        } else {\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n\n            if (mode >= 10 && mode <= 13) {\n                ALOGE(\"encountered illegal frame type %d in AMR WB content.\",\n                      mode);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            size_t frameSize = getFrameSize(mode);\n            CHECK_GE(inHeader->nFilledLen, frameSize);\n\n            int16_t *outPtr = (int16_t *)outHeader->pBuffer;\n\n            if (mode >= 9) {\n                // Produce silence instead of comfort noise and for\n                // speech lost/no data.\n                memset(outPtr, 0, kNumSamplesPerFrameWB * sizeof(int16_t));\n            } else if (mode < 9) {\n                int16 frameType;\n                RX_State_wb rx_state;\n                mime_unsorting(\n                        const_cast<uint8_t *>(&inputPtr[1]),\n                        mInputSampleBuffer,\n                        &frameType, &mode, 1, &rx_state);\n\n                int16_t numSamplesOutput;\n                pvDecoder_AmrWb(\n                        mode, mInputSampleBuffer,\n                        outPtr,\n                        &numSamplesOutput,\n                        mDecoderBuf, frameType, mDecoderCookie);\n\n                CHECK_EQ((int)numSamplesOutput, (int)kNumSamplesPerFrameWB);\n\n                for (int i = 0; i < kNumSamplesPerFrameWB; ++i) {\n                    /* Delete the 2 LSBs (14-bit output) */\n                    outPtr[i] &= 0xfffC;\n                }\n            }\n\n            numBytesRead = frameSize;\n        }\n\n        inHeader->nOffset += numBytesRead;\n        inHeader->nFilledLen -= numBytesRead;\n\n        outHeader->nFlags = 0;\n        outHeader->nOffset = 0;\n\n        if (mMode == MODE_NARROW) {\n            outHeader->nFilledLen = kNumSamplesPerFrameNB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateNB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameNB;\n        } else {\n            outHeader->nFilledLen = kNumSamplesPerFrameWB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateWB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameWB;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mInputBufferCount;\n    }\n}",
        "func": "void SoftAMR::onQueueFilled(OMX_U32 /* portIndex */) {\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    while (!inQueue.empty() && !outQueue.empty()) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            outHeader->nFilledLen = 0;\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n            outQueue.erase(outQueue.begin());\n            outInfo->mOwnedByUs = false;\n            notifyFillBufferDone(outHeader);\n            return;\n        }\n\n        if (inHeader->nOffset == 0) {\n            mAnchorTimeUs = inHeader->nTimeStamp;\n            mNumSamplesOutput = 0;\n        }\n\n        const uint8_t *inputPtr = inHeader->pBuffer + inHeader->nOffset;\n        int32_t numBytesRead;\n\n        if (mMode == MODE_NARROW) {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: NB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            numBytesRead =\n                AMRDecode(mState,\n                  (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),\n                  (UWord8 *)&inputPtr[1],\n                  reinterpret_cast<int16_t *>(outHeader->pBuffer),\n                  MIME_IETF);\n\n            if (numBytesRead == -1) {\n                ALOGE(\"PV AMR decoder AMRDecode() call failed\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            ++numBytesRead;  // Include the frame type header byte.\n\n            if (static_cast<size_t>(numBytesRead) > inHeader->nFilledLen) {\n                // This is bad, should never have happened, but did. Abort now.\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n        } else {\n            if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {\n                ALOGE(\"b/27662364: WB expected output buffer %zu bytes vs %u\",\n                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"27662364\");\n                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n\n            if (mode >= 10 && mode <= 13) {\n                ALOGE(\"encountered illegal frame type %d in AMR WB content.\",\n                      mode);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n\n                return;\n            }\n\n            size_t frameSize = getFrameSize(mode);\n            CHECK_GE(inHeader->nFilledLen, frameSize);\n\n            int16_t *outPtr = (int16_t *)outHeader->pBuffer;\n\n            if (mode >= 9) {\n                // Produce silence instead of comfort noise and for\n                // speech lost/no data.\n                memset(outPtr, 0, kNumSamplesPerFrameWB * sizeof(int16_t));\n            } else if (mode < 9) {\n                int16 frameType;\n                RX_State_wb rx_state;\n                mime_unsorting(\n                        const_cast<uint8_t *>(&inputPtr[1]),\n                        mInputSampleBuffer,\n                        &frameType, &mode, 1, &rx_state);\n\n                int16_t numSamplesOutput;\n                pvDecoder_AmrWb(\n                        mode, mInputSampleBuffer,\n                        outPtr,\n                        &numSamplesOutput,\n                        mDecoderBuf, frameType, mDecoderCookie);\n\n                CHECK_EQ((int)numSamplesOutput, (int)kNumSamplesPerFrameWB);\n\n                for (int i = 0; i < kNumSamplesPerFrameWB; ++i) {\n                    /* Delete the 2 LSBs (14-bit output) */\n                    outPtr[i] &= 0xfffC;\n                }\n            }\n\n            numBytesRead = frameSize;\n        }\n\n        inHeader->nOffset += numBytesRead;\n        inHeader->nFilledLen -= numBytesRead;\n\n        outHeader->nFlags = 0;\n        outHeader->nOffset = 0;\n\n        if (mMode == MODE_NARROW) {\n            outHeader->nFilledLen = kNumSamplesPerFrameNB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateNB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameNB;\n        } else {\n            outHeader->nFilledLen = kNumSamplesPerFrameWB * sizeof(int16_t);\n\n            outHeader->nTimeStamp =\n                mAnchorTimeUs\n                    + (mNumSamplesOutput * 1000000ll) / kSampleRateWB;\n\n            mNumSamplesOutput += kNumSamplesPerFrameWB;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mInputBufferCount;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,6 +36,15 @@\n         int32_t numBytesRead;\n \n         if (mMode == MODE_NARROW) {\n+            if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {\n+                ALOGE(\"b/27662364: NB expected output buffer %zu bytes vs %u\",\n+                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);\n+                android_errorWriteLog(0x534e4554, \"27662364\");\n+                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n+                mSignalledError = true;\n+                return;\n+            }\n+\n             numBytesRead =\n                 AMRDecode(mState,\n                   (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),\n@@ -63,6 +72,15 @@\n                 return;\n             }\n         } else {\n+            if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {\n+                ALOGE(\"b/27662364: WB expected output buffer %zu bytes vs %u\",\n+                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);\n+                android_errorWriteLog(0x534e4554, \"27662364\");\n+                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);\n+                mSignalledError = true;\n+                return;\n+            }\n+\n             int16 mode = ((inputPtr[0] >> 3) & 0x0f);\n \n             if (mode >= 10 && mode <= 13) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {",
                "                ALOGE(\"b/27662364: NB expected output buffer %zu bytes vs %u\",",
                "                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);",
                "                android_errorWriteLog(0x534e4554, \"27662364\");",
                "                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);",
                "                mSignalledError = true;",
                "                return;",
                "            }",
                "",
                "            if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {",
                "                ALOGE(\"b/27662364: WB expected output buffer %zu bytes vs %u\",",
                "                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);",
                "                android_errorWriteLog(0x534e4554, \"27662364\");",
                "                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);",
                "                mSignalledError = true;",
                "                return;",
                "            }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4480",
        "func_name": "xen-project/xen/guest_walk_tables",
        "description": "The guest_walk_tables function in arch/x86/mm/guest_walk.c in Xen 4.6.x and earlier does not properly handle the Page Size (PS) page table entry bit at the L4 and L3 page table levels, which might allow local guest OS users to gain privileges via a crafted mapping of memory.",
        "git_url": "https://github.com/xen-project/xen/commit/46699c7393bd991234b5642763c5c24b6b39a6c4",
        "commit_title": "x86/mm: fully honor PS bits in guest page table walks",
        "commit_text": " In L4 entries it is currently unconditionally reserved (and hence should, when set, always result in a reserved bit page fault), and is reserved on hardware not supporting 1Gb pages (and hence should, when set, similarly cause a reserved bit page fault on such hardware).  This is CVE-2016-4480 / XSA-176. ",
        "func_before": "uint32_t\nguest_walk_tables(struct vcpu *v, struct p2m_domain *p2m,\n                  unsigned long va, walk_t *gw, \n                  uint32_t pfec, mfn_t top_mfn, void *top_map)\n{\n    struct domain *d = v->domain;\n    p2m_type_t p2mt;\n    guest_l1e_t *l1p = NULL;\n    guest_l2e_t *l2p = NULL;\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n    guest_l3e_t *l3p = NULL;\n    guest_l4e_t *l4p;\n#endif\n    unsigned int pkey;\n    uint32_t gflags, mflags, iflags, rc = 0;\n    bool_t smep = 0, smap = 0;\n    bool_t pse1G = 0, pse2M = 0;\n    p2m_query_t qt = P2M_ALLOC | P2M_UNSHARE;\n\n    perfc_incr(guest_walk);\n    memset(gw, 0, sizeof(*gw));\n    gw->va = va;\n\n    /* Mandatory bits that must be set in every entry.  We invert NX and\n     * the invalid bits, to calculate as if there were an \"X\" bit that\n     * allowed access.  We will accumulate, in rc, the set of flags that\n     * are missing/unwanted. */\n    mflags = mandatory_flags(v, pfec);\n    iflags = (_PAGE_NX_BIT | _PAGE_INVALID_BITS);\n\n    if ( is_hvm_domain(d) && !(pfec & PFEC_user_mode) )\n    {\n        struct segment_register seg;\n        const struct cpu_user_regs *regs = guest_cpu_user_regs();\n\n        /* SMEP: kernel-mode instruction fetches from user-mode mappings\n         * should fault.  Unlike NX or invalid bits, we're looking for _all_\n         * entries in the walk to have _PAGE_USER set, so we need to do the\n         * whole walk as if it were a user-mode one and then invert the answer. */\n        smep =  hvm_smep_enabled(v) && (pfec & PFEC_insn_fetch);\n\n        switch ( v->arch.smap_check_policy )\n        {\n        case SMAP_CHECK_HONOR_CPL_AC:\n            hvm_get_segment_register(v, x86_seg_ss, &seg);\n\n            /*\n             * SMAP: kernel-mode data accesses from user-mode mappings\n             * should fault.\n             * A fault is considered as a SMAP violation if the following\n             * conditions come true:\n             *   - X86_CR4_SMAP is set in CR4\n             *   - A user page is accessed\n             *   - CPL = 3 or X86_EFLAGS_AC is clear\n             *   - Page fault in kernel mode\n             */\n            smap = hvm_smap_enabled(v) &&\n                   ((seg.attr.fields.dpl == 3) ||\n                    !(regs->eflags & X86_EFLAGS_AC));\n            break;\n        case SMAP_CHECK_ENABLED:\n            smap = hvm_smap_enabled(v);\n            break;\n        default:\n            ASSERT(v->arch.smap_check_policy == SMAP_CHECK_DISABLED);\n            break;\n        }\n    }\n\n    if ( smep || smap )\n        mflags |= _PAGE_USER;\n\n#if GUEST_PAGING_LEVELS >= 3 /* PAE or 64... */\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n\n    /* Get the l4e from the top level table and check its flags*/\n    gw->l4mfn = top_mfn;\n    l4p = (guest_l4e_t *) top_map;\n    gw->l4e = l4p[guest_l4_table_offset(va)];\n    gflags = guest_l4e_get_flags(gw->l4e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    /* Map the l3 table */\n    l3p = map_domain_gfn(p2m, \n                         guest_l4e_get_gfn(gw->l4e), \n                         &gw->l3mfn,\n                         &p2mt,\n                         qt,\n                         &rc); \n    if(l3p == NULL)\n        goto out;\n    /* Get the l3e and check its flags*/\n    gw->l3e = l3p[guest_l3_table_offset(va)];\n    pkey = guest_l3e_get_pkey(gw->l3e);\n    gflags = guest_l3e_get_flags(gw->l3e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n    \n    pse1G = (gflags & _PAGE_PSE) && guest_supports_1G_superpages(v); \n\n    if ( pse1G )\n    {\n        /* Generate a fake l1 table entry so callers don't all \n         * have to understand superpages. */\n        gfn_t start = guest_l3e_get_gfn(gw->l3e);\n        /* Grant full access in the l1e, since all the guest entry's\n         * access controls are enforced in the l3e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l3e_get_flags(gw->l3e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( gfn_x(start) & GUEST_L3_GFN_MASK & ~0x1 )\n            rc |= _PAGE_INVALID_BITS;\n\n        /* Increment the pfn by the right number of 4k pages. */\n        start = _gfn((gfn_x(start) & ~GUEST_L3_GFN_MASK) +\n                     ((va >> PAGE_SHIFT) & GUEST_L3_GFN_MASK));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l2mfn = gw->l1mfn = _mfn(INVALID_MFN);\n        goto set_ad;\n    }\n\n#else /* PAE only... */\n\n    /* Get the l3e and check its flag */\n    gw->l3e = ((guest_l3e_t *) top_map)[guest_l3_table_offset(va)];\n    if ( !(guest_l3e_get_flags(gw->l3e) & _PAGE_PRESENT) ) \n    {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n\n#endif /* PAE or 64... */\n\n    /* Map the l2 table */\n    l2p = map_domain_gfn(p2m, \n                         guest_l3e_get_gfn(gw->l3e), \n                         &gw->l2mfn,\n                         &p2mt, \n                         qt,\n                         &rc); \n    if(l2p == NULL)\n        goto out;\n    /* Get the l2e */\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#else /* 32-bit only... */\n\n    /* Get l2e from the top level table */\n    gw->l2mfn = top_mfn;\n    l2p = (guest_l2e_t *) top_map;\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#endif /* All levels... */\n\n    pkey = guest_l2e_get_pkey(gw->l2e);\n    gflags = guest_l2e_get_flags(gw->l2e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    pse2M = (gflags & _PAGE_PSE) && guest_supports_superpages(v); \n\n    if ( pse2M )\n    {\n        /* Special case: this guest VA is in a PSE superpage, so there's\n         * no guest l1e.  We make one up so that the propagation code\n         * can generate a shadow l1 table.  Start with the gfn of the \n         * first 4k-page of the superpage. */\n        gfn_t start = guest_l2e_get_gfn(gw->l2e);\n        /* Grant full access in the l1e, since all the guest entry's \n         * access controls are enforced in the shadow l2e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l2e_get_flags(gw->l2e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( gfn_x(start) & GUEST_L2_GFN_MASK & ~0x1 )\n            rc |= _PAGE_INVALID_BITS;\n\n        /* Increment the pfn by the right number of 4k pages.  \n         * Mask out PAT and invalid bits. */\n        start = _gfn((gfn_x(start) & ~GUEST_L2_GFN_MASK) +\n                     guest_l1_table_offset(va));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l1mfn = _mfn(INVALID_MFN);\n    } \n    else \n    {\n        /* Not a superpage: carry on and find the l1e. */\n        l1p = map_domain_gfn(p2m, \n                             guest_l2e_get_gfn(gw->l2e), \n                             &gw->l1mfn,\n                             &p2mt,\n                             qt,\n                             &rc);\n        if(l1p == NULL)\n            goto out;\n        gw->l1e = l1p[guest_l1_table_offset(va)];\n        pkey = guest_l1e_get_pkey(gw->l1e);\n        gflags = guest_l1e_get_flags(gw->l1e) ^ iflags;\n        if ( !(gflags & _PAGE_PRESENT) ) {\n            rc |= _PAGE_PRESENT;\n            goto out;\n        }\n        rc |= ((gflags & mflags) ^ mflags);\n    }\n\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\nset_ad:\n    if ( pkey_fault(v, pfec, gflags, pkey) )\n        rc |= _PAGE_PKEY_BITS;\n#endif\n    /* Now re-invert the user-mode requirement for SMEP and SMAP */\n    if ( smep || smap )\n        rc ^= _PAGE_USER;\n\n    /* Go back and set accessed and dirty bits only if the walk was a\n     * success.  Although the PRMs say higher-level _PAGE_ACCESSED bits\n     * get set whenever a lower-level PT is used, at least some hardware\n     * walkers behave this way. */\n    if ( rc == 0 ) \n    {\n#if GUEST_PAGING_LEVELS == 4 /* 64-bit only... */\n        if ( set_ad_bits(l4p + guest_l4_table_offset(va), &gw->l4e, 0) )\n            paging_mark_dirty(d, mfn_x(gw->l4mfn));\n        if ( set_ad_bits(l3p + guest_l3_table_offset(va), &gw->l3e,\n                         (pse1G && (pfec & PFEC_write_access))) )\n            paging_mark_dirty(d, mfn_x(gw->l3mfn));\n#endif\n        if ( !pse1G ) \n        {\n            if ( set_ad_bits(l2p + guest_l2_table_offset(va), &gw->l2e,\n                             (pse2M && (pfec & PFEC_write_access))) )\n                paging_mark_dirty(d, mfn_x(gw->l2mfn));            \n            if ( !pse2M ) \n            {\n                if ( set_ad_bits(l1p + guest_l1_table_offset(va), &gw->l1e, \n                                 (pfec & PFEC_write_access)) )\n                    paging_mark_dirty(d, mfn_x(gw->l1mfn));\n            }\n        }\n    }\n\n out:\n#if GUEST_PAGING_LEVELS == 4\n    if ( l3p ) \n    {\n        unmap_domain_page(l3p);\n        put_page(mfn_to_page(mfn_x(gw->l3mfn)));\n    }\n#endif\n#if GUEST_PAGING_LEVELS >= 3\n    if ( l2p ) \n    {\n        unmap_domain_page(l2p);\n        put_page(mfn_to_page(mfn_x(gw->l2mfn)));\n    }\n#endif\n    if ( l1p ) \n    {\n        unmap_domain_page(l1p);\n        put_page(mfn_to_page(mfn_x(gw->l1mfn)));\n    }\n\n    /* If this guest has a restricted physical address space then the\n     * target GFN must fit within it. */\n    if ( !(rc & _PAGE_PRESENT)\n         && gfn_x(guest_l1e_get_gfn(gw->l1e)) >> d->arch.paging.gfn_bits )\n        rc |= _PAGE_INVALID_BITS;\n\n    return rc;\n}",
        "func": "uint32_t\nguest_walk_tables(struct vcpu *v, struct p2m_domain *p2m,\n                  unsigned long va, walk_t *gw, \n                  uint32_t pfec, mfn_t top_mfn, void *top_map)\n{\n    struct domain *d = v->domain;\n    p2m_type_t p2mt;\n    guest_l1e_t *l1p = NULL;\n    guest_l2e_t *l2p = NULL;\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n    guest_l3e_t *l3p = NULL;\n    guest_l4e_t *l4p;\n#endif\n    unsigned int pkey;\n    uint32_t gflags, mflags, iflags, rc = 0;\n    bool_t smep = 0, smap = 0;\n    bool_t pse1G = 0, pse2M = 0;\n    p2m_query_t qt = P2M_ALLOC | P2M_UNSHARE;\n\n    perfc_incr(guest_walk);\n    memset(gw, 0, sizeof(*gw));\n    gw->va = va;\n\n    /* Mandatory bits that must be set in every entry.  We invert NX and\n     * the invalid bits, to calculate as if there were an \"X\" bit that\n     * allowed access.  We will accumulate, in rc, the set of flags that\n     * are missing/unwanted. */\n    mflags = mandatory_flags(v, pfec);\n    iflags = (_PAGE_NX_BIT | _PAGE_INVALID_BITS);\n\n    if ( is_hvm_domain(d) && !(pfec & PFEC_user_mode) )\n    {\n        struct segment_register seg;\n        const struct cpu_user_regs *regs = guest_cpu_user_regs();\n\n        /* SMEP: kernel-mode instruction fetches from user-mode mappings\n         * should fault.  Unlike NX or invalid bits, we're looking for _all_\n         * entries in the walk to have _PAGE_USER set, so we need to do the\n         * whole walk as if it were a user-mode one and then invert the answer. */\n        smep =  hvm_smep_enabled(v) && (pfec & PFEC_insn_fetch);\n\n        switch ( v->arch.smap_check_policy )\n        {\n        case SMAP_CHECK_HONOR_CPL_AC:\n            hvm_get_segment_register(v, x86_seg_ss, &seg);\n\n            /*\n             * SMAP: kernel-mode data accesses from user-mode mappings\n             * should fault.\n             * A fault is considered as a SMAP violation if the following\n             * conditions come true:\n             *   - X86_CR4_SMAP is set in CR4\n             *   - A user page is accessed\n             *   - CPL = 3 or X86_EFLAGS_AC is clear\n             *   - Page fault in kernel mode\n             */\n            smap = hvm_smap_enabled(v) &&\n                   ((seg.attr.fields.dpl == 3) ||\n                    !(regs->eflags & X86_EFLAGS_AC));\n            break;\n        case SMAP_CHECK_ENABLED:\n            smap = hvm_smap_enabled(v);\n            break;\n        default:\n            ASSERT(v->arch.smap_check_policy == SMAP_CHECK_DISABLED);\n            break;\n        }\n    }\n\n    if ( smep || smap )\n        mflags |= _PAGE_USER;\n\n#if GUEST_PAGING_LEVELS >= 3 /* PAE or 64... */\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\n\n    /* Get the l4e from the top level table and check its flags*/\n    gw->l4mfn = top_mfn;\n    l4p = (guest_l4e_t *) top_map;\n    gw->l4e = l4p[guest_l4_table_offset(va)];\n    gflags = guest_l4e_get_flags(gw->l4e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    if ( gflags & _PAGE_PSE )\n    {\n        rc |= _PAGE_PSE | _PAGE_INVALID_BIT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    /* Map the l3 table */\n    l3p = map_domain_gfn(p2m, \n                         guest_l4e_get_gfn(gw->l4e), \n                         &gw->l3mfn,\n                         &p2mt,\n                         qt,\n                         &rc); \n    if(l3p == NULL)\n        goto out;\n    /* Get the l3e and check its flags*/\n    gw->l3e = l3p[guest_l3_table_offset(va)];\n    pkey = guest_l3e_get_pkey(gw->l3e);\n    gflags = guest_l3e_get_flags(gw->l3e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n    \n    pse1G = !!(gflags & _PAGE_PSE);\n\n    if ( pse1G )\n    {\n        /* Generate a fake l1 table entry so callers don't all \n         * have to understand superpages. */\n        gfn_t start = guest_l3e_get_gfn(gw->l3e);\n        /* Grant full access in the l1e, since all the guest entry's\n         * access controls are enforced in the l3e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l3e_get_flags(gw->l3e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( !guest_supports_1G_superpages(v) )\n            rc |= _PAGE_PSE | _PAGE_INVALID_BIT;\n        if ( gfn_x(start) & GUEST_L3_GFN_MASK & ~0x1 )\n            rc |= _PAGE_INVALID_BITS;\n\n        /* Increment the pfn by the right number of 4k pages. */\n        start = _gfn((gfn_x(start) & ~GUEST_L3_GFN_MASK) +\n                     ((va >> PAGE_SHIFT) & GUEST_L3_GFN_MASK));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l2mfn = gw->l1mfn = _mfn(INVALID_MFN);\n        goto set_ad;\n    }\n\n#else /* PAE only... */\n\n    /* Get the l3e and check its flag */\n    gw->l3e = ((guest_l3e_t *) top_map)[guest_l3_table_offset(va)];\n    if ( !(guest_l3e_get_flags(gw->l3e) & _PAGE_PRESENT) ) \n    {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n\n#endif /* PAE or 64... */\n\n    /* Map the l2 table */\n    l2p = map_domain_gfn(p2m, \n                         guest_l3e_get_gfn(gw->l3e), \n                         &gw->l2mfn,\n                         &p2mt, \n                         qt,\n                         &rc); \n    if(l2p == NULL)\n        goto out;\n    /* Get the l2e */\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#else /* 32-bit only... */\n\n    /* Get l2e from the top level table */\n    gw->l2mfn = top_mfn;\n    l2p = (guest_l2e_t *) top_map;\n    gw->l2e = l2p[guest_l2_table_offset(va)];\n\n#endif /* All levels... */\n\n    pkey = guest_l2e_get_pkey(gw->l2e);\n    gflags = guest_l2e_get_flags(gw->l2e) ^ iflags;\n    if ( !(gflags & _PAGE_PRESENT) ) {\n        rc |= _PAGE_PRESENT;\n        goto out;\n    }\n    rc |= ((gflags & mflags) ^ mflags);\n\n    pse2M = (gflags & _PAGE_PSE) && guest_supports_superpages(v); \n\n    if ( pse2M )\n    {\n        /* Special case: this guest VA is in a PSE superpage, so there's\n         * no guest l1e.  We make one up so that the propagation code\n         * can generate a shadow l1 table.  Start with the gfn of the \n         * first 4k-page of the superpage. */\n        gfn_t start = guest_l2e_get_gfn(gw->l2e);\n        /* Grant full access in the l1e, since all the guest entry's \n         * access controls are enforced in the shadow l2e. */\n        int flags = (_PAGE_PRESENT|_PAGE_USER|_PAGE_RW|\n                     _PAGE_ACCESSED|_PAGE_DIRTY);\n        /* Import cache-control bits. Note that _PAGE_PAT is actually\n         * _PAGE_PSE, and it is always set. We will clear it in case\n         * _PAGE_PSE_PAT (bit 12, i.e. first bit of gfn) is clear. */\n        flags |= (guest_l2e_get_flags(gw->l2e)\n                  & (_PAGE_PAT|_PAGE_PWT|_PAGE_PCD));\n        if ( !(gfn_x(start) & 1) )\n            /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n            flags &= ~_PAGE_PAT;\n\n        if ( gfn_x(start) & GUEST_L2_GFN_MASK & ~0x1 )\n            rc |= _PAGE_INVALID_BITS;\n\n        /* Increment the pfn by the right number of 4k pages.  \n         * Mask out PAT and invalid bits. */\n        start = _gfn((gfn_x(start) & ~GUEST_L2_GFN_MASK) +\n                     guest_l1_table_offset(va));\n        gw->l1e = guest_l1e_from_gfn(start, flags);\n        gw->l1mfn = _mfn(INVALID_MFN);\n    } \n    else \n    {\n        /* Not a superpage: carry on and find the l1e. */\n        l1p = map_domain_gfn(p2m, \n                             guest_l2e_get_gfn(gw->l2e), \n                             &gw->l1mfn,\n                             &p2mt,\n                             qt,\n                             &rc);\n        if(l1p == NULL)\n            goto out;\n        gw->l1e = l1p[guest_l1_table_offset(va)];\n        pkey = guest_l1e_get_pkey(gw->l1e);\n        gflags = guest_l1e_get_flags(gw->l1e) ^ iflags;\n        if ( !(gflags & _PAGE_PRESENT) ) {\n            rc |= _PAGE_PRESENT;\n            goto out;\n        }\n        rc |= ((gflags & mflags) ^ mflags);\n    }\n\n#if GUEST_PAGING_LEVELS >= 4 /* 64-bit only... */\nset_ad:\n    if ( pkey_fault(v, pfec, gflags, pkey) )\n        rc |= _PAGE_PKEY_BITS;\n#endif\n    /* Now re-invert the user-mode requirement for SMEP and SMAP */\n    if ( smep || smap )\n        rc ^= _PAGE_USER;\n\n    /* Go back and set accessed and dirty bits only if the walk was a\n     * success.  Although the PRMs say higher-level _PAGE_ACCESSED bits\n     * get set whenever a lower-level PT is used, at least some hardware\n     * walkers behave this way. */\n    if ( rc == 0 ) \n    {\n#if GUEST_PAGING_LEVELS == 4 /* 64-bit only... */\n        if ( set_ad_bits(l4p + guest_l4_table_offset(va), &gw->l4e, 0) )\n            paging_mark_dirty(d, mfn_x(gw->l4mfn));\n        if ( set_ad_bits(l3p + guest_l3_table_offset(va), &gw->l3e,\n                         (pse1G && (pfec & PFEC_write_access))) )\n            paging_mark_dirty(d, mfn_x(gw->l3mfn));\n#endif\n        if ( !pse1G ) \n        {\n            if ( set_ad_bits(l2p + guest_l2_table_offset(va), &gw->l2e,\n                             (pse2M && (pfec & PFEC_write_access))) )\n                paging_mark_dirty(d, mfn_x(gw->l2mfn));            \n            if ( !pse2M ) \n            {\n                if ( set_ad_bits(l1p + guest_l1_table_offset(va), &gw->l1e, \n                                 (pfec & PFEC_write_access)) )\n                    paging_mark_dirty(d, mfn_x(gw->l1mfn));\n            }\n        }\n    }\n\n out:\n#if GUEST_PAGING_LEVELS == 4\n    if ( l3p ) \n    {\n        unmap_domain_page(l3p);\n        put_page(mfn_to_page(mfn_x(gw->l3mfn)));\n    }\n#endif\n#if GUEST_PAGING_LEVELS >= 3\n    if ( l2p ) \n    {\n        unmap_domain_page(l2p);\n        put_page(mfn_to_page(mfn_x(gw->l2mfn)));\n    }\n#endif\n    if ( l1p ) \n    {\n        unmap_domain_page(l1p);\n        put_page(mfn_to_page(mfn_x(gw->l1mfn)));\n    }\n\n    /* If this guest has a restricted physical address space then the\n     * target GFN must fit within it. */\n    if ( !(rc & _PAGE_PRESENT)\n         && gfn_x(guest_l1e_get_gfn(gw->l1e)) >> d->arch.paging.gfn_bits )\n        rc |= _PAGE_INVALID_BITS;\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -82,6 +82,11 @@\n         rc |= _PAGE_PRESENT;\n         goto out;\n     }\n+    if ( gflags & _PAGE_PSE )\n+    {\n+        rc |= _PAGE_PSE | _PAGE_INVALID_BIT;\n+        goto out;\n+    }\n     rc |= ((gflags & mflags) ^ mflags);\n \n     /* Map the l3 table */\n@@ -103,7 +108,7 @@\n     }\n     rc |= ((gflags & mflags) ^ mflags);\n     \n-    pse1G = (gflags & _PAGE_PSE) && guest_supports_1G_superpages(v); \n+    pse1G = !!(gflags & _PAGE_PSE);\n \n     if ( pse1G )\n     {\n@@ -123,6 +128,8 @@\n             /* _PAGE_PSE_PAT not set: remove _PAGE_PAT from flags. */\n             flags &= ~_PAGE_PAT;\n \n+        if ( !guest_supports_1G_superpages(v) )\n+            rc |= _PAGE_PSE | _PAGE_INVALID_BIT;\n         if ( gfn_x(start) & GUEST_L3_GFN_MASK & ~0x1 )\n             rc |= _PAGE_INVALID_BITS;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    pse1G = (gflags & _PAGE_PSE) && guest_supports_1G_superpages(v); "
            ],
            "added_lines": [
                "    if ( gflags & _PAGE_PSE )",
                "    {",
                "        rc |= _PAGE_PSE | _PAGE_INVALID_BIT;",
                "        goto out;",
                "    }",
                "    pse1G = !!(gflags & _PAGE_PSE);",
                "        if ( !guest_supports_1G_superpages(v) )",
                "            rc |= _PAGE_PSE | _PAGE_INVALID_BIT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4565",
        "func_name": "torvalds/linux/hfi1_file_write",
        "description": "The InfiniBand (aka IB) stack in the Linux kernel before 4.5.3 incorrectly relies on the write system call, which allows local users to cause a denial of service (kernel memory write operation) or possibly have unspecified other impact via a uAPI interface.",
        "git_url": "https://github.com/torvalds/linux/commit/e6bd18f57aad1a2d1ef40e646d03ed0f2515c9e3",
        "commit_title": "IB/security: Restrict use of the write() interface",
        "commit_text": " The drivers/infiniband stack uses write() as a replacement for bi-directional ioctl().  This is not safe. There are ways to trigger write calls that result in the return structure that is normally written to user space being shunted off to user specified kernel memory instead.  For the immediate repair, detect and deny suspicious accesses to the write API.  For long term, update the user space libraries and the kernel API to something that doesn't present the same security vulnerabilities (likely a structured ioctl() interface).  The impacted uAPI interfaces are generally only available if hardware from drivers/infiniband is installed in the system.  [ Expanded check to all known write() entry points ] Cc: stable@vger.kernel.org",
        "func_before": "static ssize_t hfi1_file_write(struct file *fp, const char __user *data,\n\t\t\t       size_t count, loff_t *offset)\n{\n\tconst struct hfi1_cmd __user *ucmd;\n\tstruct hfi1_filedata *fd = fp->private_data;\n\tstruct hfi1_ctxtdata *uctxt = fd->uctxt;\n\tstruct hfi1_cmd cmd;\n\tstruct hfi1_user_info uinfo;\n\tstruct hfi1_tid_info tinfo;\n\tunsigned long addr;\n\tssize_t consumed = 0, copy = 0, ret = 0;\n\tvoid *dest = NULL;\n\t__u64 user_val = 0;\n\tint uctxt_required = 1;\n\tint must_be_root = 0;\n\n\tif (count < sizeof(cmd)) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tucmd = (const struct hfi1_cmd __user *)data;\n\tif (copy_from_user(&cmd, ucmd, sizeof(cmd))) {\n\t\tret = -EFAULT;\n\t\tgoto bail;\n\t}\n\n\tconsumed = sizeof(cmd);\n\n\tswitch (cmd.type) {\n\tcase HFI1_CMD_ASSIGN_CTXT:\n\t\tuctxt_required = 0;\t/* assigned user context not required */\n\t\tcopy = sizeof(uinfo);\n\t\tdest = &uinfo;\n\t\tbreak;\n\tcase HFI1_CMD_SDMA_STATUS_UPD:\n\tcase HFI1_CMD_CREDIT_UPD:\n\t\tcopy = 0;\n\t\tbreak;\n\tcase HFI1_CMD_TID_UPDATE:\n\tcase HFI1_CMD_TID_FREE:\n\tcase HFI1_CMD_TID_INVAL_READ:\n\t\tcopy = sizeof(tinfo);\n\t\tdest = &tinfo;\n\t\tbreak;\n\tcase HFI1_CMD_USER_INFO:\n\tcase HFI1_CMD_RECV_CTRL:\n\tcase HFI1_CMD_POLL_TYPE:\n\tcase HFI1_CMD_ACK_EVENT:\n\tcase HFI1_CMD_CTXT_INFO:\n\tcase HFI1_CMD_SET_PKEY:\n\tcase HFI1_CMD_CTXT_RESET:\n\t\tcopy = 0;\n\t\tuser_val = cmd.addr;\n\t\tbreak;\n\tcase HFI1_CMD_EP_INFO:\n\tcase HFI1_CMD_EP_ERASE_CHIP:\n\tcase HFI1_CMD_EP_ERASE_RANGE:\n\tcase HFI1_CMD_EP_READ_RANGE:\n\tcase HFI1_CMD_EP_WRITE_RANGE:\n\t\tuctxt_required = 0;\t/* assigned user context not required */\n\t\tmust_be_root = 1;\t/* validate user */\n\t\tcopy = 0;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\t/* If the command comes with user data, copy it. */\n\tif (copy) {\n\t\tif (copy_from_user(dest, (void __user *)cmd.addr, copy)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto bail;\n\t\t}\n\t\tconsumed += copy;\n\t}\n\n\t/*\n\t * Make sure there is a uctxt when needed.\n\t */\n\tif (uctxt_required && !uctxt) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\t/* only root can do these operations */\n\tif (must_be_root && !capable(CAP_SYS_ADMIN)) {\n\t\tret = -EPERM;\n\t\tgoto bail;\n\t}\n\n\tswitch (cmd.type) {\n\tcase HFI1_CMD_ASSIGN_CTXT:\n\t\tret = assign_ctxt(fp, &uinfo);\n\t\tif (ret < 0)\n\t\t\tgoto bail;\n\t\tret = setup_ctxt(fp);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tret = user_init(fp);\n\t\tbreak;\n\tcase HFI1_CMD_CTXT_INFO:\n\t\tret = get_ctxt_info(fp, (void __user *)(unsigned long)\n\t\t\t\t    user_val, cmd.len);\n\t\tbreak;\n\tcase HFI1_CMD_USER_INFO:\n\t\tret = get_base_info(fp, (void __user *)(unsigned long)\n\t\t\t\t    user_val, cmd.len);\n\t\tbreak;\n\tcase HFI1_CMD_SDMA_STATUS_UPD:\n\t\tbreak;\n\tcase HFI1_CMD_CREDIT_UPD:\n\t\tif (uctxt && uctxt->sc)\n\t\t\tsc_return_credits(uctxt->sc);\n\t\tbreak;\n\tcase HFI1_CMD_TID_UPDATE:\n\t\tret = hfi1_user_exp_rcv_setup(fp, &tinfo);\n\t\tif (!ret) {\n\t\t\t/*\n\t\t\t * Copy the number of tidlist entries we used\n\t\t\t * and the length of the buffer we registered.\n\t\t\t * These fields are adjacent in the structure so\n\t\t\t * we can copy them at the same time.\n\t\t\t */\n\t\t\taddr = (unsigned long)cmd.addr +\n\t\t\t\toffsetof(struct hfi1_tid_info, tidcnt);\n\t\t\tif (copy_to_user((void __user *)addr, &tinfo.tidcnt,\n\t\t\t\t\t sizeof(tinfo.tidcnt) +\n\t\t\t\t\t sizeof(tinfo.length)))\n\t\t\t\tret = -EFAULT;\n\t\t}\n\t\tbreak;\n\tcase HFI1_CMD_TID_INVAL_READ:\n\t\tret = hfi1_user_exp_rcv_invalid(fp, &tinfo);\n\t\tif (ret)\n\t\t\tbreak;\n\t\taddr = (unsigned long)cmd.addr +\n\t\t\toffsetof(struct hfi1_tid_info, tidcnt);\n\t\tif (copy_to_user((void __user *)addr, &tinfo.tidcnt,\n\t\t\t\t sizeof(tinfo.tidcnt)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\tcase HFI1_CMD_TID_FREE:\n\t\tret = hfi1_user_exp_rcv_clear(fp, &tinfo);\n\t\tif (ret)\n\t\t\tbreak;\n\t\taddr = (unsigned long)cmd.addr +\n\t\t\toffsetof(struct hfi1_tid_info, tidcnt);\n\t\tif (copy_to_user((void __user *)addr, &tinfo.tidcnt,\n\t\t\t\t sizeof(tinfo.tidcnt)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\tcase HFI1_CMD_RECV_CTRL:\n\t\tret = manage_rcvq(uctxt, fd->subctxt, (int)user_val);\n\t\tbreak;\n\tcase HFI1_CMD_POLL_TYPE:\n\t\tuctxt->poll_type = (typeof(uctxt->poll_type))user_val;\n\t\tbreak;\n\tcase HFI1_CMD_ACK_EVENT:\n\t\tret = user_event_ack(uctxt, fd->subctxt, user_val);\n\t\tbreak;\n\tcase HFI1_CMD_SET_PKEY:\n\t\tif (HFI1_CAP_IS_USET(PKEY_CHECK))\n\t\t\tret = set_ctxt_pkey(uctxt, fd->subctxt, user_val);\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\tcase HFI1_CMD_CTXT_RESET: {\n\t\tstruct send_context *sc;\n\t\tstruct hfi1_devdata *dd;\n\n\t\tif (!uctxt || !uctxt->dd || !uctxt->sc) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * There is no protection here. User level has to\n\t\t * guarantee that no one will be writing to the send\n\t\t * context while it is being re-initialized.\n\t\t * If user level breaks that guarantee, it will break\n\t\t * it's own context and no one else's.\n\t\t */\n\t\tdd = uctxt->dd;\n\t\tsc = uctxt->sc;\n\t\t/*\n\t\t * Wait until the interrupt handler has marked the\n\t\t * context as halted or frozen. Report error if we time\n\t\t * out.\n\t\t */\n\t\twait_event_interruptible_timeout(\n\t\t\tsc->halt_wait, (sc->flags & SCF_HALTED),\n\t\t\tmsecs_to_jiffies(SEND_CTXT_HALT_TIMEOUT));\n\t\tif (!(sc->flags & SCF_HALTED)) {\n\t\t\tret = -ENOLCK;\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * If the send context was halted due to a Freeze,\n\t\t * wait until the device has been \"unfrozen\" before\n\t\t * resetting the context.\n\t\t */\n\t\tif (sc->flags & SCF_FROZEN) {\n\t\t\twait_event_interruptible_timeout(\n\t\t\t\tdd->event_queue,\n\t\t\t\t!(ACCESS_ONCE(dd->flags) & HFI1_FROZEN),\n\t\t\t\tmsecs_to_jiffies(SEND_CTXT_HALT_TIMEOUT));\n\t\t\tif (dd->flags & HFI1_FROZEN) {\n\t\t\t\tret = -ENOLCK;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (dd->flags & HFI1_FORCED_FREEZE) {\n\t\t\t\t/*\n\t\t\t\t * Don't allow context reset if we are into\n\t\t\t\t * forced freeze\n\t\t\t\t */\n\t\t\t\tret = -ENODEV;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsc_disable(sc);\n\t\t\tret = sc_enable(sc);\n\t\t\thfi1_rcvctrl(dd, HFI1_RCVCTRL_CTXT_ENB,\n\t\t\t\t     uctxt->ctxt);\n\t\t} else {\n\t\t\tret = sc_restart(sc);\n\t\t}\n\t\tif (!ret)\n\t\t\tsc_return_credits(sc);\n\t\tbreak;\n\t}\n\tcase HFI1_CMD_EP_INFO:\n\tcase HFI1_CMD_EP_ERASE_CHIP:\n\tcase HFI1_CMD_EP_ERASE_RANGE:\n\tcase HFI1_CMD_EP_READ_RANGE:\n\tcase HFI1_CMD_EP_WRITE_RANGE:\n\t\tret = handle_eprom_command(fp, &cmd);\n\t\tbreak;\n\t}\n\n\tif (ret >= 0)\n\t\tret = consumed;\nbail:\n\treturn ret;\n}",
        "func": "static ssize_t hfi1_file_write(struct file *fp, const char __user *data,\n\t\t\t       size_t count, loff_t *offset)\n{\n\tconst struct hfi1_cmd __user *ucmd;\n\tstruct hfi1_filedata *fd = fp->private_data;\n\tstruct hfi1_ctxtdata *uctxt = fd->uctxt;\n\tstruct hfi1_cmd cmd;\n\tstruct hfi1_user_info uinfo;\n\tstruct hfi1_tid_info tinfo;\n\tunsigned long addr;\n\tssize_t consumed = 0, copy = 0, ret = 0;\n\tvoid *dest = NULL;\n\t__u64 user_val = 0;\n\tint uctxt_required = 1;\n\tint must_be_root = 0;\n\n\t/* FIXME: This interface cannot continue out of staging */\n\tif (WARN_ON_ONCE(!ib_safe_file_access(fp)))\n\t\treturn -EACCES;\n\n\tif (count < sizeof(cmd)) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tucmd = (const struct hfi1_cmd __user *)data;\n\tif (copy_from_user(&cmd, ucmd, sizeof(cmd))) {\n\t\tret = -EFAULT;\n\t\tgoto bail;\n\t}\n\n\tconsumed = sizeof(cmd);\n\n\tswitch (cmd.type) {\n\tcase HFI1_CMD_ASSIGN_CTXT:\n\t\tuctxt_required = 0;\t/* assigned user context not required */\n\t\tcopy = sizeof(uinfo);\n\t\tdest = &uinfo;\n\t\tbreak;\n\tcase HFI1_CMD_SDMA_STATUS_UPD:\n\tcase HFI1_CMD_CREDIT_UPD:\n\t\tcopy = 0;\n\t\tbreak;\n\tcase HFI1_CMD_TID_UPDATE:\n\tcase HFI1_CMD_TID_FREE:\n\tcase HFI1_CMD_TID_INVAL_READ:\n\t\tcopy = sizeof(tinfo);\n\t\tdest = &tinfo;\n\t\tbreak;\n\tcase HFI1_CMD_USER_INFO:\n\tcase HFI1_CMD_RECV_CTRL:\n\tcase HFI1_CMD_POLL_TYPE:\n\tcase HFI1_CMD_ACK_EVENT:\n\tcase HFI1_CMD_CTXT_INFO:\n\tcase HFI1_CMD_SET_PKEY:\n\tcase HFI1_CMD_CTXT_RESET:\n\t\tcopy = 0;\n\t\tuser_val = cmd.addr;\n\t\tbreak;\n\tcase HFI1_CMD_EP_INFO:\n\tcase HFI1_CMD_EP_ERASE_CHIP:\n\tcase HFI1_CMD_EP_ERASE_RANGE:\n\tcase HFI1_CMD_EP_READ_RANGE:\n\tcase HFI1_CMD_EP_WRITE_RANGE:\n\t\tuctxt_required = 0;\t/* assigned user context not required */\n\t\tmust_be_root = 1;\t/* validate user */\n\t\tcopy = 0;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\t/* If the command comes with user data, copy it. */\n\tif (copy) {\n\t\tif (copy_from_user(dest, (void __user *)cmd.addr, copy)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto bail;\n\t\t}\n\t\tconsumed += copy;\n\t}\n\n\t/*\n\t * Make sure there is a uctxt when needed.\n\t */\n\tif (uctxt_required && !uctxt) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\t/* only root can do these operations */\n\tif (must_be_root && !capable(CAP_SYS_ADMIN)) {\n\t\tret = -EPERM;\n\t\tgoto bail;\n\t}\n\n\tswitch (cmd.type) {\n\tcase HFI1_CMD_ASSIGN_CTXT:\n\t\tret = assign_ctxt(fp, &uinfo);\n\t\tif (ret < 0)\n\t\t\tgoto bail;\n\t\tret = setup_ctxt(fp);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tret = user_init(fp);\n\t\tbreak;\n\tcase HFI1_CMD_CTXT_INFO:\n\t\tret = get_ctxt_info(fp, (void __user *)(unsigned long)\n\t\t\t\t    user_val, cmd.len);\n\t\tbreak;\n\tcase HFI1_CMD_USER_INFO:\n\t\tret = get_base_info(fp, (void __user *)(unsigned long)\n\t\t\t\t    user_val, cmd.len);\n\t\tbreak;\n\tcase HFI1_CMD_SDMA_STATUS_UPD:\n\t\tbreak;\n\tcase HFI1_CMD_CREDIT_UPD:\n\t\tif (uctxt && uctxt->sc)\n\t\t\tsc_return_credits(uctxt->sc);\n\t\tbreak;\n\tcase HFI1_CMD_TID_UPDATE:\n\t\tret = hfi1_user_exp_rcv_setup(fp, &tinfo);\n\t\tif (!ret) {\n\t\t\t/*\n\t\t\t * Copy the number of tidlist entries we used\n\t\t\t * and the length of the buffer we registered.\n\t\t\t * These fields are adjacent in the structure so\n\t\t\t * we can copy them at the same time.\n\t\t\t */\n\t\t\taddr = (unsigned long)cmd.addr +\n\t\t\t\toffsetof(struct hfi1_tid_info, tidcnt);\n\t\t\tif (copy_to_user((void __user *)addr, &tinfo.tidcnt,\n\t\t\t\t\t sizeof(tinfo.tidcnt) +\n\t\t\t\t\t sizeof(tinfo.length)))\n\t\t\t\tret = -EFAULT;\n\t\t}\n\t\tbreak;\n\tcase HFI1_CMD_TID_INVAL_READ:\n\t\tret = hfi1_user_exp_rcv_invalid(fp, &tinfo);\n\t\tif (ret)\n\t\t\tbreak;\n\t\taddr = (unsigned long)cmd.addr +\n\t\t\toffsetof(struct hfi1_tid_info, tidcnt);\n\t\tif (copy_to_user((void __user *)addr, &tinfo.tidcnt,\n\t\t\t\t sizeof(tinfo.tidcnt)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\tcase HFI1_CMD_TID_FREE:\n\t\tret = hfi1_user_exp_rcv_clear(fp, &tinfo);\n\t\tif (ret)\n\t\t\tbreak;\n\t\taddr = (unsigned long)cmd.addr +\n\t\t\toffsetof(struct hfi1_tid_info, tidcnt);\n\t\tif (copy_to_user((void __user *)addr, &tinfo.tidcnt,\n\t\t\t\t sizeof(tinfo.tidcnt)))\n\t\t\tret = -EFAULT;\n\t\tbreak;\n\tcase HFI1_CMD_RECV_CTRL:\n\t\tret = manage_rcvq(uctxt, fd->subctxt, (int)user_val);\n\t\tbreak;\n\tcase HFI1_CMD_POLL_TYPE:\n\t\tuctxt->poll_type = (typeof(uctxt->poll_type))user_val;\n\t\tbreak;\n\tcase HFI1_CMD_ACK_EVENT:\n\t\tret = user_event_ack(uctxt, fd->subctxt, user_val);\n\t\tbreak;\n\tcase HFI1_CMD_SET_PKEY:\n\t\tif (HFI1_CAP_IS_USET(PKEY_CHECK))\n\t\t\tret = set_ctxt_pkey(uctxt, fd->subctxt, user_val);\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\tcase HFI1_CMD_CTXT_RESET: {\n\t\tstruct send_context *sc;\n\t\tstruct hfi1_devdata *dd;\n\n\t\tif (!uctxt || !uctxt->dd || !uctxt->sc) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * There is no protection here. User level has to\n\t\t * guarantee that no one will be writing to the send\n\t\t * context while it is being re-initialized.\n\t\t * If user level breaks that guarantee, it will break\n\t\t * it's own context and no one else's.\n\t\t */\n\t\tdd = uctxt->dd;\n\t\tsc = uctxt->sc;\n\t\t/*\n\t\t * Wait until the interrupt handler has marked the\n\t\t * context as halted or frozen. Report error if we time\n\t\t * out.\n\t\t */\n\t\twait_event_interruptible_timeout(\n\t\t\tsc->halt_wait, (sc->flags & SCF_HALTED),\n\t\t\tmsecs_to_jiffies(SEND_CTXT_HALT_TIMEOUT));\n\t\tif (!(sc->flags & SCF_HALTED)) {\n\t\t\tret = -ENOLCK;\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * If the send context was halted due to a Freeze,\n\t\t * wait until the device has been \"unfrozen\" before\n\t\t * resetting the context.\n\t\t */\n\t\tif (sc->flags & SCF_FROZEN) {\n\t\t\twait_event_interruptible_timeout(\n\t\t\t\tdd->event_queue,\n\t\t\t\t!(ACCESS_ONCE(dd->flags) & HFI1_FROZEN),\n\t\t\t\tmsecs_to_jiffies(SEND_CTXT_HALT_TIMEOUT));\n\t\t\tif (dd->flags & HFI1_FROZEN) {\n\t\t\t\tret = -ENOLCK;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (dd->flags & HFI1_FORCED_FREEZE) {\n\t\t\t\t/*\n\t\t\t\t * Don't allow context reset if we are into\n\t\t\t\t * forced freeze\n\t\t\t\t */\n\t\t\t\tret = -ENODEV;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tsc_disable(sc);\n\t\t\tret = sc_enable(sc);\n\t\t\thfi1_rcvctrl(dd, HFI1_RCVCTRL_CTXT_ENB,\n\t\t\t\t     uctxt->ctxt);\n\t\t} else {\n\t\t\tret = sc_restart(sc);\n\t\t}\n\t\tif (!ret)\n\t\t\tsc_return_credits(sc);\n\t\tbreak;\n\t}\n\tcase HFI1_CMD_EP_INFO:\n\tcase HFI1_CMD_EP_ERASE_CHIP:\n\tcase HFI1_CMD_EP_ERASE_RANGE:\n\tcase HFI1_CMD_EP_READ_RANGE:\n\tcase HFI1_CMD_EP_WRITE_RANGE:\n\t\tret = handle_eprom_command(fp, &cmd);\n\t\tbreak;\n\t}\n\n\tif (ret >= 0)\n\t\tret = consumed;\nbail:\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,10 @@\n \t__u64 user_val = 0;\n \tint uctxt_required = 1;\n \tint must_be_root = 0;\n+\n+\t/* FIXME: This interface cannot continue out of staging */\n+\tif (WARN_ON_ONCE(!ib_safe_file_access(fp)))\n+\t\treturn -EACCES;\n \n \tif (count < sizeof(cmd)) {\n \t\tret = -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* FIXME: This interface cannot continue out of staging */",
                "\tif (WARN_ON_ONCE(!ib_safe_file_access(fp)))",
                "\t\treturn -EACCES;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4565",
        "func_name": "torvalds/linux/ib_uverbs_write",
        "description": "The InfiniBand (aka IB) stack in the Linux kernel before 4.5.3 incorrectly relies on the write system call, which allows local users to cause a denial of service (kernel memory write operation) or possibly have unspecified other impact via a uAPI interface.",
        "git_url": "https://github.com/torvalds/linux/commit/e6bd18f57aad1a2d1ef40e646d03ed0f2515c9e3",
        "commit_title": "IB/security: Restrict use of the write() interface",
        "commit_text": " The drivers/infiniband stack uses write() as a replacement for bi-directional ioctl().  This is not safe. There are ways to trigger write calls that result in the return structure that is normally written to user space being shunted off to user specified kernel memory instead.  For the immediate repair, detect and deny suspicious accesses to the write API.  For long term, update the user space libraries and the kernel API to something that doesn't present the same security vulnerabilities (likely a structured ioctl() interface).  The impacted uAPI interfaces are generally only available if hardware from drivers/infiniband is installed in the system.  [ Expanded check to all known write() entry points ] Cc: stable@vger.kernel.org",
        "func_before": "static ssize_t ib_uverbs_write(struct file *filp, const char __user *buf,\n\t\t\t     size_t count, loff_t *pos)\n{\n\tstruct ib_uverbs_file *file = filp->private_data;\n\tstruct ib_device *ib_dev;\n\tstruct ib_uverbs_cmd_hdr hdr;\n\t__u32 command;\n\t__u32 flags;\n\tint srcu_key;\n\tssize_t ret;\n\n\tif (count < sizeof hdr)\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&hdr, buf, sizeof hdr))\n\t\treturn -EFAULT;\n\n\tsrcu_key = srcu_read_lock(&file->device->disassociate_srcu);\n\tib_dev = srcu_dereference(file->device->ib_dev,\n\t\t\t\t  &file->device->disassociate_srcu);\n\tif (!ib_dev) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tif (hdr.command & ~(__u32)(IB_USER_VERBS_CMD_FLAGS_MASK |\n\t\t\t\t   IB_USER_VERBS_CMD_COMMAND_MASK)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tcommand = hdr.command & IB_USER_VERBS_CMD_COMMAND_MASK;\n\tif (verify_command_mask(ib_dev, command)) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tif (!file->ucontext &&\n\t    command != IB_USER_VERBS_CMD_GET_CONTEXT) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tflags = (hdr.command &\n\t\t IB_USER_VERBS_CMD_FLAGS_MASK) >> IB_USER_VERBS_CMD_FLAGS_SHIFT;\n\n\tif (!flags) {\n\t\tif (command >= ARRAY_SIZE(uverbs_cmd_table) ||\n\t\t    !uverbs_cmd_table[command]) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (hdr.in_words * 4 != count) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = uverbs_cmd_table[command](file, ib_dev,\n\t\t\t\t\t\t buf + sizeof(hdr),\n\t\t\t\t\t\t hdr.in_words * 4,\n\t\t\t\t\t\t hdr.out_words * 4);\n\n\t} else if (flags == IB_USER_VERBS_CMD_FLAG_EXTENDED) {\n\t\tstruct ib_uverbs_ex_cmd_hdr ex_hdr;\n\t\tstruct ib_udata ucore;\n\t\tstruct ib_udata uhw;\n\t\tsize_t written_count = count;\n\n\t\tif (command >= ARRAY_SIZE(uverbs_ex_cmd_table) ||\n\t\t    !uverbs_ex_cmd_table[command]) {\n\t\t\tret = -ENOSYS;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!file->ucontext) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (count < (sizeof(hdr) + sizeof(ex_hdr))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (copy_from_user(&ex_hdr, buf + sizeof(hdr), sizeof(ex_hdr))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tcount -= sizeof(hdr) + sizeof(ex_hdr);\n\t\tbuf += sizeof(hdr) + sizeof(ex_hdr);\n\n\t\tif ((hdr.in_words + ex_hdr.provider_in_words) * 8 != count) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (ex_hdr.cmd_hdr_reserved) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (ex_hdr.response) {\n\t\t\tif (!hdr.out_words && !ex_hdr.provider_out_words) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tif (!access_ok(VERIFY_WRITE,\n\t\t\t\t       (void __user *) (unsigned long) ex_hdr.response,\n\t\t\t\t       (hdr.out_words + ex_hdr.provider_out_words) * 8)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tif (hdr.out_words || ex_hdr.provider_out_words) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tINIT_UDATA_BUF_OR_NULL(&ucore, buf, (unsigned long) ex_hdr.response,\n\t\t\t\t       hdr.in_words * 8, hdr.out_words * 8);\n\n\t\tINIT_UDATA_BUF_OR_NULL(&uhw,\n\t\t\t\t       buf + ucore.inlen,\n\t\t\t\t       (unsigned long) ex_hdr.response + ucore.outlen,\n\t\t\t\t       ex_hdr.provider_in_words * 8,\n\t\t\t\t       ex_hdr.provider_out_words * 8);\n\n\t\tret = uverbs_ex_cmd_table[command](file,\n\t\t\t\t\t\t   ib_dev,\n\t\t\t\t\t\t   &ucore,\n\t\t\t\t\t\t   &uhw);\n\t\tif (!ret)\n\t\t\tret = written_count;\n\t} else {\n\t\tret = -ENOSYS;\n\t}\n\nout:\n\tsrcu_read_unlock(&file->device->disassociate_srcu, srcu_key);\n\treturn ret;\n}",
        "func": "static ssize_t ib_uverbs_write(struct file *filp, const char __user *buf,\n\t\t\t     size_t count, loff_t *pos)\n{\n\tstruct ib_uverbs_file *file = filp->private_data;\n\tstruct ib_device *ib_dev;\n\tstruct ib_uverbs_cmd_hdr hdr;\n\t__u32 command;\n\t__u32 flags;\n\tint srcu_key;\n\tssize_t ret;\n\n\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))\n\t\treturn -EACCES;\n\n\tif (count < sizeof hdr)\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&hdr, buf, sizeof hdr))\n\t\treturn -EFAULT;\n\n\tsrcu_key = srcu_read_lock(&file->device->disassociate_srcu);\n\tib_dev = srcu_dereference(file->device->ib_dev,\n\t\t\t\t  &file->device->disassociate_srcu);\n\tif (!ib_dev) {\n\t\tret = -EIO;\n\t\tgoto out;\n\t}\n\n\tif (hdr.command & ~(__u32)(IB_USER_VERBS_CMD_FLAGS_MASK |\n\t\t\t\t   IB_USER_VERBS_CMD_COMMAND_MASK)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tcommand = hdr.command & IB_USER_VERBS_CMD_COMMAND_MASK;\n\tif (verify_command_mask(ib_dev, command)) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tif (!file->ucontext &&\n\t    command != IB_USER_VERBS_CMD_GET_CONTEXT) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tflags = (hdr.command &\n\t\t IB_USER_VERBS_CMD_FLAGS_MASK) >> IB_USER_VERBS_CMD_FLAGS_SHIFT;\n\n\tif (!flags) {\n\t\tif (command >= ARRAY_SIZE(uverbs_cmd_table) ||\n\t\t    !uverbs_cmd_table[command]) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (hdr.in_words * 4 != count) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = uverbs_cmd_table[command](file, ib_dev,\n\t\t\t\t\t\t buf + sizeof(hdr),\n\t\t\t\t\t\t hdr.in_words * 4,\n\t\t\t\t\t\t hdr.out_words * 4);\n\n\t} else if (flags == IB_USER_VERBS_CMD_FLAG_EXTENDED) {\n\t\tstruct ib_uverbs_ex_cmd_hdr ex_hdr;\n\t\tstruct ib_udata ucore;\n\t\tstruct ib_udata uhw;\n\t\tsize_t written_count = count;\n\n\t\tif (command >= ARRAY_SIZE(uverbs_ex_cmd_table) ||\n\t\t    !uverbs_ex_cmd_table[command]) {\n\t\t\tret = -ENOSYS;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!file->ucontext) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (count < (sizeof(hdr) + sizeof(ex_hdr))) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (copy_from_user(&ex_hdr, buf + sizeof(hdr), sizeof(ex_hdr))) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\tcount -= sizeof(hdr) + sizeof(ex_hdr);\n\t\tbuf += sizeof(hdr) + sizeof(ex_hdr);\n\n\t\tif ((hdr.in_words + ex_hdr.provider_in_words) * 8 != count) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (ex_hdr.cmd_hdr_reserved) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (ex_hdr.response) {\n\t\t\tif (!hdr.out_words && !ex_hdr.provider_out_words) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\tif (!access_ok(VERIFY_WRITE,\n\t\t\t\t       (void __user *) (unsigned long) ex_hdr.response,\n\t\t\t\t       (hdr.out_words + ex_hdr.provider_out_words) * 8)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t} else {\n\t\t\tif (hdr.out_words || ex_hdr.provider_out_words) {\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\n\t\tINIT_UDATA_BUF_OR_NULL(&ucore, buf, (unsigned long) ex_hdr.response,\n\t\t\t\t       hdr.in_words * 8, hdr.out_words * 8);\n\n\t\tINIT_UDATA_BUF_OR_NULL(&uhw,\n\t\t\t\t       buf + ucore.inlen,\n\t\t\t\t       (unsigned long) ex_hdr.response + ucore.outlen,\n\t\t\t\t       ex_hdr.provider_in_words * 8,\n\t\t\t\t       ex_hdr.provider_out_words * 8);\n\n\t\tret = uverbs_ex_cmd_table[command](file,\n\t\t\t\t\t\t   ib_dev,\n\t\t\t\t\t\t   &ucore,\n\t\t\t\t\t\t   &uhw);\n\t\tif (!ret)\n\t\t\tret = written_count;\n\t} else {\n\t\tret = -ENOSYS;\n\t}\n\nout:\n\tsrcu_read_unlock(&file->device->disassociate_srcu, srcu_key);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,9 @@\n \t__u32 flags;\n \tint srcu_key;\n \tssize_t ret;\n+\n+\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))\n+\t\treturn -EACCES;\n \n \tif (count < sizeof hdr)\n \t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))",
                "\t\treturn -EACCES;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4565",
        "func_name": "torvalds/linux/ib_ucm_write",
        "description": "The InfiniBand (aka IB) stack in the Linux kernel before 4.5.3 incorrectly relies on the write system call, which allows local users to cause a denial of service (kernel memory write operation) or possibly have unspecified other impact via a uAPI interface.",
        "git_url": "https://github.com/torvalds/linux/commit/e6bd18f57aad1a2d1ef40e646d03ed0f2515c9e3",
        "commit_title": "IB/security: Restrict use of the write() interface",
        "commit_text": " The drivers/infiniband stack uses write() as a replacement for bi-directional ioctl().  This is not safe. There are ways to trigger write calls that result in the return structure that is normally written to user space being shunted off to user specified kernel memory instead.  For the immediate repair, detect and deny suspicious accesses to the write API.  For long term, update the user space libraries and the kernel API to something that doesn't present the same security vulnerabilities (likely a structured ioctl() interface).  The impacted uAPI interfaces are generally only available if hardware from drivers/infiniband is installed in the system.  [ Expanded check to all known write() entry points ] Cc: stable@vger.kernel.org",
        "func_before": "static ssize_t ib_ucm_write(struct file *filp, const char __user *buf,\n\t\t\t    size_t len, loff_t *pos)\n{\n\tstruct ib_ucm_file *file = filp->private_data;\n\tstruct ib_ucm_cmd_hdr hdr;\n\tssize_t result;\n\n\tif (len < sizeof(hdr))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&hdr, buf, sizeof(hdr)))\n\t\treturn -EFAULT;\n\n\tif (hdr.cmd >= ARRAY_SIZE(ucm_cmd_table))\n\t\treturn -EINVAL;\n\n\tif (hdr.in + sizeof(hdr) > len)\n\t\treturn -EINVAL;\n\n\tresult = ucm_cmd_table[hdr.cmd](file, buf + sizeof(hdr),\n\t\t\t\t\thdr.in, hdr.out);\n\tif (!result)\n\t\tresult = len;\n\n\treturn result;\n}",
        "func": "static ssize_t ib_ucm_write(struct file *filp, const char __user *buf,\n\t\t\t    size_t len, loff_t *pos)\n{\n\tstruct ib_ucm_file *file = filp->private_data;\n\tstruct ib_ucm_cmd_hdr hdr;\n\tssize_t result;\n\n\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))\n\t\treturn -EACCES;\n\n\tif (len < sizeof(hdr))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&hdr, buf, sizeof(hdr)))\n\t\treturn -EFAULT;\n\n\tif (hdr.cmd >= ARRAY_SIZE(ucm_cmd_table))\n\t\treturn -EINVAL;\n\n\tif (hdr.in + sizeof(hdr) > len)\n\t\treturn -EINVAL;\n\n\tresult = ucm_cmd_table[hdr.cmd](file, buf + sizeof(hdr),\n\t\t\t\t\thdr.in, hdr.out);\n\tif (!result)\n\t\tresult = len;\n\n\treturn result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,9 @@\n \tstruct ib_ucm_file *file = filp->private_data;\n \tstruct ib_ucm_cmd_hdr hdr;\n \tssize_t result;\n+\n+\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))\n+\t\treturn -EACCES;\n \n \tif (len < sizeof(hdr))\n \t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))",
                "\t\treturn -EACCES;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4565",
        "func_name": "torvalds/linux/qib_write",
        "description": "The InfiniBand (aka IB) stack in the Linux kernel before 4.5.3 incorrectly relies on the write system call, which allows local users to cause a denial of service (kernel memory write operation) or possibly have unspecified other impact via a uAPI interface.",
        "git_url": "https://github.com/torvalds/linux/commit/e6bd18f57aad1a2d1ef40e646d03ed0f2515c9e3",
        "commit_title": "IB/security: Restrict use of the write() interface",
        "commit_text": " The drivers/infiniband stack uses write() as a replacement for bi-directional ioctl().  This is not safe. There are ways to trigger write calls that result in the return structure that is normally written to user space being shunted off to user specified kernel memory instead.  For the immediate repair, detect and deny suspicious accesses to the write API.  For long term, update the user space libraries and the kernel API to something that doesn't present the same security vulnerabilities (likely a structured ioctl() interface).  The impacted uAPI interfaces are generally only available if hardware from drivers/infiniband is installed in the system.  [ Expanded check to all known write() entry points ] Cc: stable@vger.kernel.org",
        "func_before": "static ssize_t qib_write(struct file *fp, const char __user *data,\n\t\t\t size_t count, loff_t *off)\n{\n\tconst struct qib_cmd __user *ucmd;\n\tstruct qib_ctxtdata *rcd;\n\tconst void __user *src;\n\tsize_t consumed, copy = 0;\n\tstruct qib_cmd cmd;\n\tssize_t ret = 0;\n\tvoid *dest;\n\n\tif (count < sizeof(cmd.type)) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tucmd = (const struct qib_cmd __user *) data;\n\n\tif (copy_from_user(&cmd.type, &ucmd->type, sizeof(cmd.type))) {\n\t\tret = -EFAULT;\n\t\tgoto bail;\n\t}\n\n\tconsumed = sizeof(cmd.type);\n\n\tswitch (cmd.type) {\n\tcase QIB_CMD_ASSIGN_CTXT:\n\tcase QIB_CMD_USER_INIT:\n\t\tcopy = sizeof(cmd.cmd.user_info);\n\t\tdest = &cmd.cmd.user_info;\n\t\tsrc = &ucmd->cmd.user_info;\n\t\tbreak;\n\n\tcase QIB_CMD_RECV_CTRL:\n\t\tcopy = sizeof(cmd.cmd.recv_ctrl);\n\t\tdest = &cmd.cmd.recv_ctrl;\n\t\tsrc = &ucmd->cmd.recv_ctrl;\n\t\tbreak;\n\n\tcase QIB_CMD_CTXT_INFO:\n\t\tcopy = sizeof(cmd.cmd.ctxt_info);\n\t\tdest = &cmd.cmd.ctxt_info;\n\t\tsrc = &ucmd->cmd.ctxt_info;\n\t\tbreak;\n\n\tcase QIB_CMD_TID_UPDATE:\n\tcase QIB_CMD_TID_FREE:\n\t\tcopy = sizeof(cmd.cmd.tid_info);\n\t\tdest = &cmd.cmd.tid_info;\n\t\tsrc = &ucmd->cmd.tid_info;\n\t\tbreak;\n\n\tcase QIB_CMD_SET_PART_KEY:\n\t\tcopy = sizeof(cmd.cmd.part_key);\n\t\tdest = &cmd.cmd.part_key;\n\t\tsrc = &ucmd->cmd.part_key;\n\t\tbreak;\n\n\tcase QIB_CMD_DISARM_BUFS:\n\tcase QIB_CMD_PIOAVAILUPD: /* force an update of PIOAvail reg */\n\t\tcopy = 0;\n\t\tsrc = NULL;\n\t\tdest = NULL;\n\t\tbreak;\n\n\tcase QIB_CMD_POLL_TYPE:\n\t\tcopy = sizeof(cmd.cmd.poll_type);\n\t\tdest = &cmd.cmd.poll_type;\n\t\tsrc = &ucmd->cmd.poll_type;\n\t\tbreak;\n\n\tcase QIB_CMD_ARMLAUNCH_CTRL:\n\t\tcopy = sizeof(cmd.cmd.armlaunch_ctrl);\n\t\tdest = &cmd.cmd.armlaunch_ctrl;\n\t\tsrc = &ucmd->cmd.armlaunch_ctrl;\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_INFLIGHT:\n\t\tcopy = sizeof(cmd.cmd.sdma_inflight);\n\t\tdest = &cmd.cmd.sdma_inflight;\n\t\tsrc = &ucmd->cmd.sdma_inflight;\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_COMPLETE:\n\t\tcopy = sizeof(cmd.cmd.sdma_complete);\n\t\tdest = &cmd.cmd.sdma_complete;\n\t\tsrc = &ucmd->cmd.sdma_complete;\n\t\tbreak;\n\n\tcase QIB_CMD_ACK_EVENT:\n\t\tcopy = sizeof(cmd.cmd.event_mask);\n\t\tdest = &cmd.cmd.event_mask;\n\t\tsrc = &ucmd->cmd.event_mask;\n\t\tbreak;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tif (copy) {\n\t\tif ((count - consumed) < copy) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto bail;\n\t\t}\n\t\tif (copy_from_user(dest, src, copy)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto bail;\n\t\t}\n\t\tconsumed += copy;\n\t}\n\n\trcd = ctxt_fp(fp);\n\tif (!rcd && cmd.type != QIB_CMD_ASSIGN_CTXT) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tswitch (cmd.type) {\n\tcase QIB_CMD_ASSIGN_CTXT:\n\t\tret = qib_assign_ctxt(fp, &cmd.cmd.user_info);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tbreak;\n\n\tcase QIB_CMD_USER_INIT:\n\t\tret = qib_do_user_init(fp, &cmd.cmd.user_info);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tret = qib_get_base_info(fp, (void __user *) (unsigned long)\n\t\t\t\t\tcmd.cmd.user_info.spu_base_info,\n\t\t\t\t\tcmd.cmd.user_info.spu_base_info_size);\n\t\tbreak;\n\n\tcase QIB_CMD_RECV_CTRL:\n\t\tret = qib_manage_rcvq(rcd, subctxt_fp(fp), cmd.cmd.recv_ctrl);\n\t\tbreak;\n\n\tcase QIB_CMD_CTXT_INFO:\n\t\tret = qib_ctxt_info(fp, (struct qib_ctxt_info __user *)\n\t\t\t\t    (unsigned long) cmd.cmd.ctxt_info);\n\t\tbreak;\n\n\tcase QIB_CMD_TID_UPDATE:\n\t\tret = qib_tid_update(rcd, fp, &cmd.cmd.tid_info);\n\t\tbreak;\n\n\tcase QIB_CMD_TID_FREE:\n\t\tret = qib_tid_free(rcd, subctxt_fp(fp), &cmd.cmd.tid_info);\n\t\tbreak;\n\n\tcase QIB_CMD_SET_PART_KEY:\n\t\tret = qib_set_part_key(rcd, cmd.cmd.part_key);\n\t\tbreak;\n\n\tcase QIB_CMD_DISARM_BUFS:\n\t\t(void)qib_disarm_piobufs_ifneeded(rcd);\n\t\tret = disarm_req_delay(rcd);\n\t\tbreak;\n\n\tcase QIB_CMD_PIOAVAILUPD:\n\t\tqib_force_pio_avail_update(rcd->dd);\n\t\tbreak;\n\n\tcase QIB_CMD_POLL_TYPE:\n\t\trcd->poll_type = cmd.cmd.poll_type;\n\t\tbreak;\n\n\tcase QIB_CMD_ARMLAUNCH_CTRL:\n\t\trcd->dd->f_set_armlaunch(rcd->dd, cmd.cmd.armlaunch_ctrl);\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_INFLIGHT:\n\t\tret = qib_sdma_get_inflight(user_sdma_queue_fp(fp),\n\t\t\t\t\t    (u32 __user *) (unsigned long)\n\t\t\t\t\t    cmd.cmd.sdma_inflight);\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_COMPLETE:\n\t\tret = qib_sdma_get_complete(rcd->ppd,\n\t\t\t\t\t    user_sdma_queue_fp(fp),\n\t\t\t\t\t    (u32 __user *) (unsigned long)\n\t\t\t\t\t    cmd.cmd.sdma_complete);\n\t\tbreak;\n\n\tcase QIB_CMD_ACK_EVENT:\n\t\tret = qib_user_event_ack(rcd, subctxt_fp(fp),\n\t\t\t\t\t cmd.cmd.event_mask);\n\t\tbreak;\n\t}\n\n\tif (ret >= 0)\n\t\tret = consumed;\n\nbail:\n\treturn ret;\n}",
        "func": "static ssize_t qib_write(struct file *fp, const char __user *data,\n\t\t\t size_t count, loff_t *off)\n{\n\tconst struct qib_cmd __user *ucmd;\n\tstruct qib_ctxtdata *rcd;\n\tconst void __user *src;\n\tsize_t consumed, copy = 0;\n\tstruct qib_cmd cmd;\n\tssize_t ret = 0;\n\tvoid *dest;\n\n\tif (WARN_ON_ONCE(!ib_safe_file_access(fp)))\n\t\treturn -EACCES;\n\n\tif (count < sizeof(cmd.type)) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tucmd = (const struct qib_cmd __user *) data;\n\n\tif (copy_from_user(&cmd.type, &ucmd->type, sizeof(cmd.type))) {\n\t\tret = -EFAULT;\n\t\tgoto bail;\n\t}\n\n\tconsumed = sizeof(cmd.type);\n\n\tswitch (cmd.type) {\n\tcase QIB_CMD_ASSIGN_CTXT:\n\tcase QIB_CMD_USER_INIT:\n\t\tcopy = sizeof(cmd.cmd.user_info);\n\t\tdest = &cmd.cmd.user_info;\n\t\tsrc = &ucmd->cmd.user_info;\n\t\tbreak;\n\n\tcase QIB_CMD_RECV_CTRL:\n\t\tcopy = sizeof(cmd.cmd.recv_ctrl);\n\t\tdest = &cmd.cmd.recv_ctrl;\n\t\tsrc = &ucmd->cmd.recv_ctrl;\n\t\tbreak;\n\n\tcase QIB_CMD_CTXT_INFO:\n\t\tcopy = sizeof(cmd.cmd.ctxt_info);\n\t\tdest = &cmd.cmd.ctxt_info;\n\t\tsrc = &ucmd->cmd.ctxt_info;\n\t\tbreak;\n\n\tcase QIB_CMD_TID_UPDATE:\n\tcase QIB_CMD_TID_FREE:\n\t\tcopy = sizeof(cmd.cmd.tid_info);\n\t\tdest = &cmd.cmd.tid_info;\n\t\tsrc = &ucmd->cmd.tid_info;\n\t\tbreak;\n\n\tcase QIB_CMD_SET_PART_KEY:\n\t\tcopy = sizeof(cmd.cmd.part_key);\n\t\tdest = &cmd.cmd.part_key;\n\t\tsrc = &ucmd->cmd.part_key;\n\t\tbreak;\n\n\tcase QIB_CMD_DISARM_BUFS:\n\tcase QIB_CMD_PIOAVAILUPD: /* force an update of PIOAvail reg */\n\t\tcopy = 0;\n\t\tsrc = NULL;\n\t\tdest = NULL;\n\t\tbreak;\n\n\tcase QIB_CMD_POLL_TYPE:\n\t\tcopy = sizeof(cmd.cmd.poll_type);\n\t\tdest = &cmd.cmd.poll_type;\n\t\tsrc = &ucmd->cmd.poll_type;\n\t\tbreak;\n\n\tcase QIB_CMD_ARMLAUNCH_CTRL:\n\t\tcopy = sizeof(cmd.cmd.armlaunch_ctrl);\n\t\tdest = &cmd.cmd.armlaunch_ctrl;\n\t\tsrc = &ucmd->cmd.armlaunch_ctrl;\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_INFLIGHT:\n\t\tcopy = sizeof(cmd.cmd.sdma_inflight);\n\t\tdest = &cmd.cmd.sdma_inflight;\n\t\tsrc = &ucmd->cmd.sdma_inflight;\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_COMPLETE:\n\t\tcopy = sizeof(cmd.cmd.sdma_complete);\n\t\tdest = &cmd.cmd.sdma_complete;\n\t\tsrc = &ucmd->cmd.sdma_complete;\n\t\tbreak;\n\n\tcase QIB_CMD_ACK_EVENT:\n\t\tcopy = sizeof(cmd.cmd.event_mask);\n\t\tdest = &cmd.cmd.event_mask;\n\t\tsrc = &ucmd->cmd.event_mask;\n\t\tbreak;\n\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tif (copy) {\n\t\tif ((count - consumed) < copy) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto bail;\n\t\t}\n\t\tif (copy_from_user(dest, src, copy)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto bail;\n\t\t}\n\t\tconsumed += copy;\n\t}\n\n\trcd = ctxt_fp(fp);\n\tif (!rcd && cmd.type != QIB_CMD_ASSIGN_CTXT) {\n\t\tret = -EINVAL;\n\t\tgoto bail;\n\t}\n\n\tswitch (cmd.type) {\n\tcase QIB_CMD_ASSIGN_CTXT:\n\t\tret = qib_assign_ctxt(fp, &cmd.cmd.user_info);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tbreak;\n\n\tcase QIB_CMD_USER_INIT:\n\t\tret = qib_do_user_init(fp, &cmd.cmd.user_info);\n\t\tif (ret)\n\t\t\tgoto bail;\n\t\tret = qib_get_base_info(fp, (void __user *) (unsigned long)\n\t\t\t\t\tcmd.cmd.user_info.spu_base_info,\n\t\t\t\t\tcmd.cmd.user_info.spu_base_info_size);\n\t\tbreak;\n\n\tcase QIB_CMD_RECV_CTRL:\n\t\tret = qib_manage_rcvq(rcd, subctxt_fp(fp), cmd.cmd.recv_ctrl);\n\t\tbreak;\n\n\tcase QIB_CMD_CTXT_INFO:\n\t\tret = qib_ctxt_info(fp, (struct qib_ctxt_info __user *)\n\t\t\t\t    (unsigned long) cmd.cmd.ctxt_info);\n\t\tbreak;\n\n\tcase QIB_CMD_TID_UPDATE:\n\t\tret = qib_tid_update(rcd, fp, &cmd.cmd.tid_info);\n\t\tbreak;\n\n\tcase QIB_CMD_TID_FREE:\n\t\tret = qib_tid_free(rcd, subctxt_fp(fp), &cmd.cmd.tid_info);\n\t\tbreak;\n\n\tcase QIB_CMD_SET_PART_KEY:\n\t\tret = qib_set_part_key(rcd, cmd.cmd.part_key);\n\t\tbreak;\n\n\tcase QIB_CMD_DISARM_BUFS:\n\t\t(void)qib_disarm_piobufs_ifneeded(rcd);\n\t\tret = disarm_req_delay(rcd);\n\t\tbreak;\n\n\tcase QIB_CMD_PIOAVAILUPD:\n\t\tqib_force_pio_avail_update(rcd->dd);\n\t\tbreak;\n\n\tcase QIB_CMD_POLL_TYPE:\n\t\trcd->poll_type = cmd.cmd.poll_type;\n\t\tbreak;\n\n\tcase QIB_CMD_ARMLAUNCH_CTRL:\n\t\trcd->dd->f_set_armlaunch(rcd->dd, cmd.cmd.armlaunch_ctrl);\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_INFLIGHT:\n\t\tret = qib_sdma_get_inflight(user_sdma_queue_fp(fp),\n\t\t\t\t\t    (u32 __user *) (unsigned long)\n\t\t\t\t\t    cmd.cmd.sdma_inflight);\n\t\tbreak;\n\n\tcase QIB_CMD_SDMA_COMPLETE:\n\t\tret = qib_sdma_get_complete(rcd->ppd,\n\t\t\t\t\t    user_sdma_queue_fp(fp),\n\t\t\t\t\t    (u32 __user *) (unsigned long)\n\t\t\t\t\t    cmd.cmd.sdma_complete);\n\t\tbreak;\n\n\tcase QIB_CMD_ACK_EVENT:\n\t\tret = qib_user_event_ack(rcd, subctxt_fp(fp),\n\t\t\t\t\t cmd.cmd.event_mask);\n\t\tbreak;\n\t}\n\n\tif (ret >= 0)\n\t\tret = consumed;\n\nbail:\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,9 @@\n \tssize_t ret = 0;\n \tvoid *dest;\n \n+\tif (WARN_ON_ONCE(!ib_safe_file_access(fp)))\n+\t\treturn -EACCES;\n+\n \tif (count < sizeof(cmd.type)) {\n \t\tret = -EINVAL;\n \t\tgoto bail;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (WARN_ON_ONCE(!ib_safe_file_access(fp)))",
                "\t\treturn -EACCES;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4565",
        "func_name": "torvalds/linux/ucma_write",
        "description": "The InfiniBand (aka IB) stack in the Linux kernel before 4.5.3 incorrectly relies on the write system call, which allows local users to cause a denial of service (kernel memory write operation) or possibly have unspecified other impact via a uAPI interface.",
        "git_url": "https://github.com/torvalds/linux/commit/e6bd18f57aad1a2d1ef40e646d03ed0f2515c9e3",
        "commit_title": "IB/security: Restrict use of the write() interface",
        "commit_text": " The drivers/infiniband stack uses write() as a replacement for bi-directional ioctl().  This is not safe. There are ways to trigger write calls that result in the return structure that is normally written to user space being shunted off to user specified kernel memory instead.  For the immediate repair, detect and deny suspicious accesses to the write API.  For long term, update the user space libraries and the kernel API to something that doesn't present the same security vulnerabilities (likely a structured ioctl() interface).  The impacted uAPI interfaces are generally only available if hardware from drivers/infiniband is installed in the system.  [ Expanded check to all known write() entry points ] Cc: stable@vger.kernel.org",
        "func_before": "static ssize_t ucma_write(struct file *filp, const char __user *buf,\n\t\t\t  size_t len, loff_t *pos)\n{\n\tstruct ucma_file *file = filp->private_data;\n\tstruct rdma_ucm_cmd_hdr hdr;\n\tssize_t ret;\n\n\tif (len < sizeof(hdr))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&hdr, buf, sizeof(hdr)))\n\t\treturn -EFAULT;\n\n\tif (hdr.cmd >= ARRAY_SIZE(ucma_cmd_table))\n\t\treturn -EINVAL;\n\n\tif (hdr.in + sizeof(hdr) > len)\n\t\treturn -EINVAL;\n\n\tif (!ucma_cmd_table[hdr.cmd])\n\t\treturn -ENOSYS;\n\n\tret = ucma_cmd_table[hdr.cmd](file, buf + sizeof(hdr), hdr.in, hdr.out);\n\tif (!ret)\n\t\tret = len;\n\n\treturn ret;\n}",
        "func": "static ssize_t ucma_write(struct file *filp, const char __user *buf,\n\t\t\t  size_t len, loff_t *pos)\n{\n\tstruct ucma_file *file = filp->private_data;\n\tstruct rdma_ucm_cmd_hdr hdr;\n\tssize_t ret;\n\n\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))\n\t\treturn -EACCES;\n\n\tif (len < sizeof(hdr))\n\t\treturn -EINVAL;\n\n\tif (copy_from_user(&hdr, buf, sizeof(hdr)))\n\t\treturn -EFAULT;\n\n\tif (hdr.cmd >= ARRAY_SIZE(ucma_cmd_table))\n\t\treturn -EINVAL;\n\n\tif (hdr.in + sizeof(hdr) > len)\n\t\treturn -EINVAL;\n\n\tif (!ucma_cmd_table[hdr.cmd])\n\t\treturn -ENOSYS;\n\n\tret = ucma_cmd_table[hdr.cmd](file, buf + sizeof(hdr), hdr.in, hdr.out);\n\tif (!ret)\n\t\tret = len;\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,9 @@\n \tstruct ucma_file *file = filp->private_data;\n \tstruct rdma_ucm_cmd_hdr hdr;\n \tssize_t ret;\n+\n+\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))\n+\t\treturn -EACCES;\n \n \tif (len < sizeof(hdr))\n \t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (WARN_ON_ONCE(!ib_safe_file_access(filp)))",
                "\t\treturn -EACCES;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-2494",
        "func_name": "android/get_node_path_locked",
        "description": "Off-by-one error in sdcard/sdcard.c in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-06-01 allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 28085658.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/864e2e22fcd0cba3f5e67680ccabd0302dfda45d",
        "commit_title": "Fix overflow in path building",
        "commit_text": " An incorrect size was causing an unsigned value to wrap, causing it to write past the end of the buffer.  Bug: 28085658 ",
        "func_before": "static ssize_t get_node_path_locked(struct node* node, char* buf, size_t bufsize) {\n    const char* name;\n    size_t namelen;\n    if (node->graft_path) {\n        name = node->graft_path;\n        namelen = node->graft_pathlen;\n    } else if (node->actual_name) {\n        name = node->actual_name;\n        namelen = node->namelen;\n    } else {\n        name = node->name;\n        namelen = node->namelen;\n    }\n\n    if (bufsize < namelen + 1) {\n        return -1;\n    }\n\n    ssize_t pathlen = 0;\n    if (node->parent && node->graft_path == NULL) {\n        pathlen = get_node_path_locked(node->parent, buf, bufsize - namelen - 2);\n        if (pathlen < 0) {\n            return -1;\n        }\n        buf[pathlen++] = '/';\n    }\n\n    memcpy(buf + pathlen, name, namelen + 1); /* include trailing \\0 */\n    return pathlen + namelen;\n}",
        "func": "static ssize_t get_node_path_locked(struct node* node, char* buf, size_t bufsize) {\n    const char* name;\n    size_t namelen;\n    if (node->graft_path) {\n        name = node->graft_path;\n        namelen = node->graft_pathlen;\n    } else if (node->actual_name) {\n        name = node->actual_name;\n        namelen = node->namelen;\n    } else {\n        name = node->name;\n        namelen = node->namelen;\n    }\n\n    if (bufsize < namelen + 1) {\n        return -1;\n    }\n\n    ssize_t pathlen = 0;\n    if (node->parent && node->graft_path == NULL) {\n        pathlen = get_node_path_locked(node->parent, buf, bufsize - namelen - 1);\n        if (pathlen < 0) {\n            return -1;\n        }\n        buf[pathlen++] = '/';\n    }\n\n    memcpy(buf + pathlen, name, namelen + 1); /* include trailing \\0 */\n    return pathlen + namelen;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,7 @@\n \n     ssize_t pathlen = 0;\n     if (node->parent && node->graft_path == NULL) {\n-        pathlen = get_node_path_locked(node->parent, buf, bufsize - namelen - 2);\n+        pathlen = get_node_path_locked(node->parent, buf, bufsize - namelen - 1);\n         if (pathlen < 0) {\n             return -1;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "        pathlen = get_node_path_locked(node->parent, buf, bufsize - namelen - 2);"
            ],
            "added_lines": [
                "        pathlen = get_node_path_locked(node->parent, buf, bufsize - namelen - 1);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3170",
        "func_name": "chromium/URLPattern::Parse",
        "description": "extensions/common/url_pattern.cc in Google Chrome before 37.0.2062.94 does not prevent use of a '\\0' character in a host name, which allows remote attackers to spoof the extension permission dialog by relying on truncation after this character.",
        "git_url": "https://github.com/chromium/chromium/commit/80d5aa4a1de9107d1442480b8ea9ba06feff2be2",
        "commit_title": "Don't allow null bytes in hosts of host permissions.",
        "commit_text": "  ",
        "func_before": "URLPattern::ParseResult URLPattern::Parse(const std::string& pattern) {\n  spec_.clear();\n  SetMatchAllURLs(false);\n  SetMatchSubdomains(false);\n  SetPort(\"*\");\n\n  // Special case pattern to match every valid URL.\n  if (pattern == kAllUrlsPattern) {\n    SetMatchAllURLs(true);\n    return PARSE_SUCCESS;\n  }\n\n  // Parse out the scheme.\n  size_t scheme_end_pos = pattern.find(url::kStandardSchemeSeparator);\n  bool has_standard_scheme_separator = true;\n\n  // Some urls also use ':' alone as the scheme separator.\n  if (scheme_end_pos == std::string::npos) {\n    scheme_end_pos = pattern.find(':');\n    has_standard_scheme_separator = false;\n  }\n\n  if (scheme_end_pos == std::string::npos)\n    return PARSE_ERROR_MISSING_SCHEME_SEPARATOR;\n\n  if (!SetScheme(pattern.substr(0, scheme_end_pos)))\n    return PARSE_ERROR_INVALID_SCHEME;\n\n  bool standard_scheme = IsStandardScheme(scheme_);\n  if (standard_scheme != has_standard_scheme_separator)\n    return PARSE_ERROR_WRONG_SCHEME_SEPARATOR;\n\n  // Advance past the scheme separator.\n  scheme_end_pos +=\n      (standard_scheme ? strlen(url::kStandardSchemeSeparator) : 1);\n  if (scheme_end_pos >= pattern.size())\n    return PARSE_ERROR_EMPTY_HOST;\n\n  // Parse out the host and path.\n  size_t host_start_pos = scheme_end_pos;\n  size_t path_start_pos = 0;\n\n  if (!standard_scheme) {\n    path_start_pos = host_start_pos;\n  } else if (scheme_ == url::kFileScheme) {\n    size_t host_end_pos = pattern.find(kPathSeparator, host_start_pos);\n    if (host_end_pos == std::string::npos) {\n      // Allow hostname omission.\n      // e.g. file://* is interpreted as file:///*,\n      // file://foo* is interpreted as file:///foo*.\n      path_start_pos = host_start_pos - 1;\n    } else {\n      // Ignore hostname if scheme is file://.\n      // e.g. file://localhost/foo is equal to file:///foo.\n      path_start_pos = host_end_pos;\n    }\n  } else {\n    size_t host_end_pos = pattern.find(kPathSeparator, host_start_pos);\n\n    // Host is required.\n    if (host_start_pos == host_end_pos)\n      return PARSE_ERROR_EMPTY_HOST;\n\n    if (host_end_pos == std::string::npos)\n      return PARSE_ERROR_EMPTY_PATH;\n\n    host_ = pattern.substr(host_start_pos, host_end_pos - host_start_pos);\n\n    // The first component can optionally be '*' to match all subdomains.\n    std::vector<std::string> host_components;\n    base::SplitString(host_, '.', &host_components);\n\n    // Could be empty if the host only consists of whitespace characters.\n    if (host_components.empty())\n      return PARSE_ERROR_EMPTY_HOST;\n\n    if (host_components[0] == \"*\") {\n      match_subdomains_ = true;\n      host_components.erase(host_components.begin(),\n                            host_components.begin() + 1);\n    }\n    host_ = JoinString(host_components, '.');\n\n    path_start_pos = host_end_pos;\n  }\n\n  SetPath(pattern.substr(path_start_pos));\n\n  size_t port_pos = host_.find(':');\n  if (port_pos != std::string::npos) {\n    if (!SetPort(host_.substr(port_pos + 1)))\n      return PARSE_ERROR_INVALID_PORT;\n    host_ = host_.substr(0, port_pos);\n  }\n\n  // No other '*' can occur in the host, though. This isn't necessary, but is\n  // done as a convenience to developers who might otherwise be confused and\n  // think '*' works as a glob in the host.\n  if (host_.find('*') != std::string::npos)\n    return PARSE_ERROR_INVALID_HOST_WILDCARD;\n\n  return PARSE_SUCCESS;\n}",
        "func": "URLPattern::ParseResult URLPattern::Parse(const std::string& pattern) {\n  spec_.clear();\n  SetMatchAllURLs(false);\n  SetMatchSubdomains(false);\n  SetPort(\"*\");\n\n  // Special case pattern to match every valid URL.\n  if (pattern == kAllUrlsPattern) {\n    SetMatchAllURLs(true);\n    return PARSE_SUCCESS;\n  }\n\n  // Parse out the scheme.\n  size_t scheme_end_pos = pattern.find(url::kStandardSchemeSeparator);\n  bool has_standard_scheme_separator = true;\n\n  // Some urls also use ':' alone as the scheme separator.\n  if (scheme_end_pos == std::string::npos) {\n    scheme_end_pos = pattern.find(':');\n    has_standard_scheme_separator = false;\n  }\n\n  if (scheme_end_pos == std::string::npos)\n    return PARSE_ERROR_MISSING_SCHEME_SEPARATOR;\n\n  if (!SetScheme(pattern.substr(0, scheme_end_pos)))\n    return PARSE_ERROR_INVALID_SCHEME;\n\n  bool standard_scheme = IsStandardScheme(scheme_);\n  if (standard_scheme != has_standard_scheme_separator)\n    return PARSE_ERROR_WRONG_SCHEME_SEPARATOR;\n\n  // Advance past the scheme separator.\n  scheme_end_pos +=\n      (standard_scheme ? strlen(url::kStandardSchemeSeparator) : 1);\n  if (scheme_end_pos >= pattern.size())\n    return PARSE_ERROR_EMPTY_HOST;\n\n  // Parse out the host and path.\n  size_t host_start_pos = scheme_end_pos;\n  size_t path_start_pos = 0;\n\n  if (!standard_scheme) {\n    path_start_pos = host_start_pos;\n  } else if (scheme_ == url::kFileScheme) {\n    size_t host_end_pos = pattern.find(kPathSeparator, host_start_pos);\n    if (host_end_pos == std::string::npos) {\n      // Allow hostname omission.\n      // e.g. file://* is interpreted as file:///*,\n      // file://foo* is interpreted as file:///foo*.\n      path_start_pos = host_start_pos - 1;\n    } else {\n      // Ignore hostname if scheme is file://.\n      // e.g. file://localhost/foo is equal to file:///foo.\n      path_start_pos = host_end_pos;\n    }\n  } else {\n    size_t host_end_pos = pattern.find(kPathSeparator, host_start_pos);\n\n    // Host is required.\n    if (host_start_pos == host_end_pos)\n      return PARSE_ERROR_EMPTY_HOST;\n\n    if (host_end_pos == std::string::npos)\n      return PARSE_ERROR_EMPTY_PATH;\n\n    host_ = pattern.substr(host_start_pos, host_end_pos - host_start_pos);\n\n    // The first component can optionally be '*' to match all subdomains.\n    std::vector<std::string> host_components;\n    base::SplitString(host_, '.', &host_components);\n\n    // Could be empty if the host only consists of whitespace characters.\n    if (host_components.empty())\n      return PARSE_ERROR_EMPTY_HOST;\n\n    if (host_components[0] == \"*\") {\n      match_subdomains_ = true;\n      host_components.erase(host_components.begin(),\n                            host_components.begin() + 1);\n    }\n    host_ = JoinString(host_components, '.');\n\n    path_start_pos = host_end_pos;\n  }\n\n  SetPath(pattern.substr(path_start_pos));\n\n  size_t port_pos = host_.find(':');\n  if (port_pos != std::string::npos) {\n    if (!SetPort(host_.substr(port_pos + 1)))\n      return PARSE_ERROR_INVALID_PORT;\n    host_ = host_.substr(0, port_pos);\n  }\n\n  // No other '*' can occur in the host, though. This isn't necessary, but is\n  // done as a convenience to developers who might otherwise be confused and\n  // think '*' works as a glob in the host.\n  if (host_.find('*') != std::string::npos)\n    return PARSE_ERROR_INVALID_HOST_WILDCARD;\n\n  // Null characters are not allowed in hosts.\n  if (host_.find('\\0') != std::string::npos)\n    return PARSE_ERROR_INVALID_HOST;\n\n  return PARSE_SUCCESS;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -99,5 +99,9 @@\n   if (host_.find('*') != std::string::npos)\n     return PARSE_ERROR_INVALID_HOST_WILDCARD;\n \n+  // Null characters are not allowed in hosts.\n+  if (host_.find('\\0') != std::string::npos)\n+    return PARSE_ERROR_INVALID_HOST;\n+\n   return PARSE_SUCCESS;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  // Null characters are not allowed in hosts.",
                "  if (host_.find('\\0') != std::string::npos)",
                "    return PARSE_ERROR_INVALID_HOST;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3172",
        "func_name": "chromium/PermissionsData::CanRunOnPage",
        "description": "The Debugger extension API in browser/extensions/api/debugger/debugger_api.cc in Google Chrome before 37.0.2062.94 does not validate a tab's URL before an attach operation, which allows remote attackers to bypass intended access limitations via an extension that uses a restricted URL, as demonstrated by a chrome:// URL.",
        "git_url": "https://github.com/chromium/chromium/commit/684a212a93141908bcc10f4bc57f3edb53d2d21f",
        "commit_title": "Have the Debugger extension api check that it has access to the tab",
        "commit_text": " Check PermissionsData::CanAccessTab() prior to attaching the debugger.   ",
        "func_before": "bool PermissionsData::CanRunOnPage(const Extension* extension,\n                                   const GURL& document_url,\n                                   const GURL& top_frame_url,\n                                   int tab_id,\n                                   int process_id,\n                                   const URLPatternSet& permitted_url_patterns,\n                                   std::string* error) const {\n  if (g_policy_delegate &&\n      !g_policy_delegate->CanExecuteScriptOnPage(\n          extension, document_url, top_frame_url, tab_id, process_id, error)) {\n    return false;\n  }\n\n  bool can_execute_everywhere = CanExecuteScriptEverywhere(extension);\n  if (!can_execute_everywhere &&\n      !ExtensionsClient::Get()->IsScriptableURL(document_url, error)) {\n    return false;\n  }\n\n  if (!base::CommandLine::ForCurrentProcess()->HasSwitch(\n          switches::kExtensionsOnChromeURLs)) {\n    if (document_url.SchemeIs(content::kChromeUIScheme) &&\n        !can_execute_everywhere) {\n      if (error)\n        *error = manifest_errors::kCannotAccessChromeUrl;\n      return false;\n    }\n  }\n\n  if (top_frame_url.SchemeIs(kExtensionScheme) &&\n      top_frame_url.GetOrigin() !=\n          Extension::GetBaseURLFromExtensionId(extension->id()).GetOrigin() &&\n      !can_execute_everywhere) {\n    if (error)\n      *error = manifest_errors::kCannotAccessExtensionUrl;\n    return false;\n  }\n\n  if (HasTabSpecificPermissionToExecuteScript(tab_id, top_frame_url))\n    return true;\n\n  bool can_access = permitted_url_patterns.MatchesURL(document_url);\n\n  if (!can_access && error) {\n    *error = ErrorUtils::FormatErrorMessage(manifest_errors::kCannotAccessPage,\n                                            document_url.spec());\n  }\n\n  return can_access;\n}",
        "func": "bool PermissionsData::CanRunOnPage(const Extension* extension,\n                                   const GURL& document_url,\n                                   const GURL& top_frame_url,\n                                   int tab_id,\n                                   int process_id,\n                                   const URLPatternSet& permitted_url_patterns,\n                                   std::string* error) const {\n  if (g_policy_delegate &&\n      !g_policy_delegate->CanExecuteScriptOnPage(\n          extension, document_url, top_frame_url, tab_id, process_id, error)) {\n    return false;\n  }\n\n  if (IsRestrictedUrl(document_url, top_frame_url, extension, error))\n    return false;\n\n  if (HasTabSpecificPermissionToExecuteScript(tab_id, top_frame_url))\n    return true;\n\n  bool can_access = permitted_url_patterns.MatchesURL(document_url);\n\n  if (!can_access && error) {\n    *error = ErrorUtils::FormatErrorMessage(manifest_errors::kCannotAccessPage,\n                                            document_url.spec());\n  }\n\n  return can_access;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,30 +11,8 @@\n     return false;\n   }\n \n-  bool can_execute_everywhere = CanExecuteScriptEverywhere(extension);\n-  if (!can_execute_everywhere &&\n-      !ExtensionsClient::Get()->IsScriptableURL(document_url, error)) {\n+  if (IsRestrictedUrl(document_url, top_frame_url, extension, error))\n     return false;\n-  }\n-\n-  if (!base::CommandLine::ForCurrentProcess()->HasSwitch(\n-          switches::kExtensionsOnChromeURLs)) {\n-    if (document_url.SchemeIs(content::kChromeUIScheme) &&\n-        !can_execute_everywhere) {\n-      if (error)\n-        *error = manifest_errors::kCannotAccessChromeUrl;\n-      return false;\n-    }\n-  }\n-\n-  if (top_frame_url.SchemeIs(kExtensionScheme) &&\n-      top_frame_url.GetOrigin() !=\n-          Extension::GetBaseURLFromExtensionId(extension->id()).GetOrigin() &&\n-      !can_execute_everywhere) {\n-    if (error)\n-      *error = manifest_errors::kCannotAccessExtensionUrl;\n-    return false;\n-  }\n \n   if (HasTabSpecificPermissionToExecuteScript(tab_id, top_frame_url))\n     return true;",
        "diff_line_info": {
            "deleted_lines": [
                "  bool can_execute_everywhere = CanExecuteScriptEverywhere(extension);",
                "  if (!can_execute_everywhere &&",
                "      !ExtensionsClient::Get()->IsScriptableURL(document_url, error)) {",
                "  }",
                "",
                "  if (!base::CommandLine::ForCurrentProcess()->HasSwitch(",
                "          switches::kExtensionsOnChromeURLs)) {",
                "    if (document_url.SchemeIs(content::kChromeUIScheme) &&",
                "        !can_execute_everywhere) {",
                "      if (error)",
                "        *error = manifest_errors::kCannotAccessChromeUrl;",
                "      return false;",
                "    }",
                "  }",
                "",
                "  if (top_frame_url.SchemeIs(kExtensionScheme) &&",
                "      top_frame_url.GetOrigin() !=",
                "          Extension::GetBaseURLFromExtensionId(extension->id()).GetOrigin() &&",
                "      !can_execute_everywhere) {",
                "    if (error)",
                "      *error = manifest_errors::kCannotAccessExtensionUrl;",
                "    return false;",
                "  }"
            ],
            "added_lines": [
                "  if (IsRestrictedUrl(document_url, top_frame_url, extension, error))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3172",
        "func_name": "chromium/DebuggerAttachFunction::RunAsync",
        "description": "The Debugger extension API in browser/extensions/api/debugger/debugger_api.cc in Google Chrome before 37.0.2062.94 does not validate a tab's URL before an attach operation, which allows remote attackers to bypass intended access limitations via an extension that uses a restricted URL, as demonstrated by a chrome:// URL.",
        "git_url": "https://github.com/chromium/chromium/commit/684a212a93141908bcc10f4bc57f3edb53d2d21f",
        "commit_title": "Have the Debugger extension api check that it has access to the tab",
        "commit_text": " Check PermissionsData::CanAccessTab() prior to attaching the debugger.   ",
        "func_before": "bool DebuggerAttachFunction::RunAsync() {\n  scoped_ptr<Attach::Params> params(Attach::Params::Create(*args_));\n  EXTENSION_FUNCTION_VALIDATE(params.get());\n\n  CopyDebuggee(&debuggee_, params->target);\n  if (!InitAgentHost())\n    return false;\n\n  if (!DevToolsHttpHandler::IsSupportedProtocolVersion(\n          params->required_version)) {\n    error_ = ErrorUtils::FormatErrorMessage(\n        keys::kProtocolVersionNotSupportedError,\n        params->required_version);\n    return false;\n  }\n\n  if (agent_host_->IsAttached()) {\n    FormatErrorMessage(keys::kAlreadyAttachedError);\n    return false;\n  }\n\n  infobars::InfoBar* infobar = NULL;\n  if (!CommandLine::ForCurrentProcess()->\n       HasSwitch(switches::kSilentDebuggerExtensionAPI)) {\n    // Do not attach to the target if for any reason the infobar cannot be shown\n    // for this WebContents instance.\n    infobar = ExtensionDevToolsInfoBarDelegate::Create(\n        agent_host_->GetRenderViewHost(), GetExtension()->name());\n    if (!infobar) {\n      error_ = ErrorUtils::FormatErrorMessage(\n          keys::kSilentDebuggingRequired,\n          switches::kSilentDebuggerExtensionAPI);\n      return false;\n    }\n  }\n\n  new ExtensionDevToolsClientHost(GetProfile(),\n                                  agent_host_.get(),\n                                  GetExtension()->id(),\n                                  GetExtension()->name(),\n                                  debuggee_,\n                                  infobar);\n  SendResponse(true);\n  return true;\n}",
        "func": "bool DebuggerAttachFunction::RunAsync() {\n  scoped_ptr<Attach::Params> params(Attach::Params::Create(*args_));\n  EXTENSION_FUNCTION_VALIDATE(params.get());\n\n  CopyDebuggee(&debuggee_, params->target);\n  if (!InitAgentHost())\n    return false;\n\n  if (!DevToolsHttpHandler::IsSupportedProtocolVersion(\n          params->required_version)) {\n    error_ = ErrorUtils::FormatErrorMessage(\n        keys::kProtocolVersionNotSupportedError,\n        params->required_version);\n    return false;\n  }\n\n  if (agent_host_->IsAttached()) {\n    FormatErrorMessage(keys::kAlreadyAttachedError);\n    return false;\n  }\n\n  const Extension* extension = GetExtension();\n  infobars::InfoBar* infobar = NULL;\n  if (!CommandLine::ForCurrentProcess()->\n       HasSwitch(::switches::kSilentDebuggerExtensionAPI)) {\n    // Do not attach to the target if for any reason the infobar cannot be shown\n    // for this WebContents instance.\n    infobar = ExtensionDevToolsInfoBarDelegate::Create(\n        agent_host_->GetRenderViewHost(), extension->name());\n    if (!infobar) {\n      error_ = ErrorUtils::FormatErrorMessage(\n          keys::kSilentDebuggingRequired,\n          ::switches::kSilentDebuggerExtensionAPI);\n      return false;\n    }\n  }\n\n  new ExtensionDevToolsClientHost(GetProfile(),\n                                  agent_host_.get(),\n                                  extension->id(),\n                                  extension->name(),\n                                  debuggee_,\n                                  infobar);\n  SendResponse(true);\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,25 +19,26 @@\n     return false;\n   }\n \n+  const Extension* extension = GetExtension();\n   infobars::InfoBar* infobar = NULL;\n   if (!CommandLine::ForCurrentProcess()->\n-       HasSwitch(switches::kSilentDebuggerExtensionAPI)) {\n+       HasSwitch(::switches::kSilentDebuggerExtensionAPI)) {\n     // Do not attach to the target if for any reason the infobar cannot be shown\n     // for this WebContents instance.\n     infobar = ExtensionDevToolsInfoBarDelegate::Create(\n-        agent_host_->GetRenderViewHost(), GetExtension()->name());\n+        agent_host_->GetRenderViewHost(), extension->name());\n     if (!infobar) {\n       error_ = ErrorUtils::FormatErrorMessage(\n           keys::kSilentDebuggingRequired,\n-          switches::kSilentDebuggerExtensionAPI);\n+          ::switches::kSilentDebuggerExtensionAPI);\n       return false;\n     }\n   }\n \n   new ExtensionDevToolsClientHost(GetProfile(),\n                                   agent_host_.get(),\n-                                  GetExtension()->id(),\n-                                  GetExtension()->name(),\n+                                  extension->id(),\n+                                  extension->name(),\n                                   debuggee_,\n                                   infobar);\n   SendResponse(true);",
        "diff_line_info": {
            "deleted_lines": [
                "       HasSwitch(switches::kSilentDebuggerExtensionAPI)) {",
                "        agent_host_->GetRenderViewHost(), GetExtension()->name());",
                "          switches::kSilentDebuggerExtensionAPI);",
                "                                  GetExtension()->id(),",
                "                                  GetExtension()->name(),"
            ],
            "added_lines": [
                "  const Extension* extension = GetExtension();",
                "       HasSwitch(::switches::kSilentDebuggerExtensionAPI)) {",
                "        agent_host_->GetRenderViewHost(), extension->name());",
                "          ::switches::kSilentDebuggerExtensionAPI);",
                "                                  extension->id(),",
                "                                  extension->name(),"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3172",
        "func_name": "chromium/DebuggerFunction::InitAgentHost",
        "description": "The Debugger extension API in browser/extensions/api/debugger/debugger_api.cc in Google Chrome before 37.0.2062.94 does not validate a tab's URL before an attach operation, which allows remote attackers to bypass intended access limitations via an extension that uses a restricted URL, as demonstrated by a chrome:// URL.",
        "git_url": "https://github.com/chromium/chromium/commit/684a212a93141908bcc10f4bc57f3edb53d2d21f",
        "commit_title": "Have the Debugger extension api check that it has access to the tab",
        "commit_text": " Check PermissionsData::CanAccessTab() prior to attaching the debugger.   ",
        "func_before": "bool DebuggerFunction::InitAgentHost() {\n  if (debuggee_.tab_id) {\n    WebContents* web_contents = NULL;\n    bool result = ExtensionTabUtil::GetTabById(*debuggee_.tab_id,\n                                               GetProfile(),\n                                               include_incognito(),\n                                               NULL,\n                                               NULL,\n                                               &web_contents,\n                                               NULL);\n    if (result && web_contents) {\n      if (content::HasWebUIScheme(web_contents->GetURL())) {\n        error_ = ErrorUtils::FormatErrorMessage(\n            keys::kAttachToWebUIError,\n            web_contents->GetURL().scheme());\n        return false;\n      }\n      agent_host_ = DevToolsAgentHost::GetOrCreateFor(web_contents);\n    }\n  } else if (debuggee_.extension_id) {\n    ExtensionHost* extension_host =\n        ExtensionSystem::Get(GetProfile())\n            ->process_manager()\n            ->GetBackgroundHostForExtension(*debuggee_.extension_id);\n    if (extension_host) {\n      agent_host_ = DevToolsAgentHost::GetOrCreateFor(\n          extension_host->render_view_host());\n    }\n  } else if (debuggee_.target_id) {\n    agent_host_ = DevToolsAgentHost::GetForId(*debuggee_.target_id);\n  } else {\n    error_ = keys::kInvalidTargetError;\n    return false;\n  }\n\n  if (!agent_host_.get()) {\n    FormatErrorMessage(keys::kNoTargetError);\n    return false;\n  }\n  return true;\n}",
        "func": "bool DebuggerFunction::InitAgentHost() {\n  const Extension* extension = GetExtension();\n  if (debuggee_.tab_id) {\n    WebContents* web_contents = NULL;\n    bool result = ExtensionTabUtil::GetTabById(*debuggee_.tab_id,\n                                               GetProfile(),\n                                               include_incognito(),\n                                               NULL,\n                                               NULL,\n                                               &web_contents,\n                                               NULL);\n    if (result && web_contents) {\n      // TODO(rdevlin.cronin) This should definitely be GetLastCommittedURL().\n      GURL url = web_contents->GetVisibleURL();\n      if (PermissionsData::IsRestrictedUrl(url, url, extension, &error_))\n        return false;\n      agent_host_ = DevToolsAgentHost::GetOrCreateFor(web_contents);\n    }\n  } else if (debuggee_.extension_id) {\n    ExtensionHost* extension_host =\n        ExtensionSystem::Get(GetProfile())\n            ->process_manager()\n            ->GetBackgroundHostForExtension(*debuggee_.extension_id);\n    if (extension_host) {\n      if (PermissionsData::IsRestrictedUrl(extension_host->GetURL(),\n                                           extension_host->GetURL(),\n                                           extension,\n                                           &error_)) {\n        return false;\n      }\n      agent_host_ = DevToolsAgentHost::GetOrCreateFor(\n          extension_host->render_view_host());\n    }\n  } else if (debuggee_.target_id) {\n    agent_host_ = DevToolsAgentHost::GetForId(*debuggee_.target_id);\n  } else {\n    error_ = keys::kInvalidTargetError;\n    return false;\n  }\n\n  if (!agent_host_.get()) {\n    FormatErrorMessage(keys::kNoTargetError);\n    return false;\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n bool DebuggerFunction::InitAgentHost() {\n+  const Extension* extension = GetExtension();\n   if (debuggee_.tab_id) {\n     WebContents* web_contents = NULL;\n     bool result = ExtensionTabUtil::GetTabById(*debuggee_.tab_id,\n@@ -9,12 +10,10 @@\n                                                &web_contents,\n                                                NULL);\n     if (result && web_contents) {\n-      if (content::HasWebUIScheme(web_contents->GetURL())) {\n-        error_ = ErrorUtils::FormatErrorMessage(\n-            keys::kAttachToWebUIError,\n-            web_contents->GetURL().scheme());\n+      // TODO(rdevlin.cronin) This should definitely be GetLastCommittedURL().\n+      GURL url = web_contents->GetVisibleURL();\n+      if (PermissionsData::IsRestrictedUrl(url, url, extension, &error_))\n         return false;\n-      }\n       agent_host_ = DevToolsAgentHost::GetOrCreateFor(web_contents);\n     }\n   } else if (debuggee_.extension_id) {\n@@ -23,6 +22,12 @@\n             ->process_manager()\n             ->GetBackgroundHostForExtension(*debuggee_.extension_id);\n     if (extension_host) {\n+      if (PermissionsData::IsRestrictedUrl(extension_host->GetURL(),\n+                                           extension_host->GetURL(),\n+                                           extension,\n+                                           &error_)) {\n+        return false;\n+      }\n       agent_host_ = DevToolsAgentHost::GetOrCreateFor(\n           extension_host->render_view_host());\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "      if (content::HasWebUIScheme(web_contents->GetURL())) {",
                "        error_ = ErrorUtils::FormatErrorMessage(",
                "            keys::kAttachToWebUIError,",
                "            web_contents->GetURL().scheme());",
                "      }"
            ],
            "added_lines": [
                "  const Extension* extension = GetExtension();",
                "      // TODO(rdevlin.cronin) This should definitely be GetLastCommittedURL().",
                "      GURL url = web_contents->GetVisibleURL();",
                "      if (PermissionsData::IsRestrictedUrl(url, url, extension, &error_))",
                "      if (PermissionsData::IsRestrictedUrl(extension_host->GetURL(),",
                "                                           extension_host->GetURL(),",
                "                                           extension,",
                "                                           &error_)) {",
                "        return false;",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/_show_registers",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/fc0cafeab30fe93963457fafbad7a01c7f55ea5f",
        "commit_title": "xen: arm: handle AArch32 userspace when dumping 64-bit guest state.",
        "commit_text": " A 64-bit guest can still be in 32-bit mode when running userspace, handle this case by dumping the correct 32-bit state.  Note that on ARM it is not possible to change mode without the help of the next exception level, hence there is no way a 64-bit guest can be running in 32-bit kernel modes.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void _show_registers(struct cpu_user_regs *regs,\n                            struct reg_ctxt *ctxt,\n                            int guest_mode,\n                            const struct vcpu *v)\n{\n    print_xen_info();\n\n    printk(\"CPU:    %d\\n\", smp_processor_id());\n\n    if ( guest_mode )\n    {\n        if ( is_32bit_domain(v->domain) )\n            show_registers_32(regs, ctxt, guest_mode, v);\n#ifdef CONFIG_ARM_64\n        else if ( is_64bit_domain(v->domain) )\n            show_registers_64(regs, ctxt, guest_mode, v);\n#endif\n    }\n    else\n    {\n#ifdef CONFIG_ARM_64\n        show_registers_64(regs, ctxt, guest_mode, v);\n#else\n        show_registers_32(regs, ctxt, guest_mode, v);\n#endif\n    }\n    printk(\"  VTCR_EL2: %08\"PRIx32\"\\n\", READ_SYSREG32(VTCR_EL2));\n    printk(\" VTTBR_EL2: %016\"PRIx64\"\\n\", ctxt->vttbr_el2);\n    printk(\"\\n\");\n\n    printk(\" SCTLR_EL2: %08\"PRIx32\"\\n\", READ_SYSREG32(SCTLR_EL2));\n    printk(\"   HCR_EL2: %016\"PRIregister\"\\n\", READ_SYSREG(HCR_EL2));\n    printk(\" TTBR0_EL2: %016\"PRIx64\"\\n\", READ_SYSREG64(TTBR0_EL2));\n    printk(\"\\n\");\n    printk(\"   ESR_EL2: %08\"PRIx32\"\\n\", READ_SYSREG32(ESR_EL2));\n    printk(\" HPFAR_EL2: %016\"PRIregister\"\\n\", READ_SYSREG(HPFAR_EL2));\n\n#ifdef CONFIG_ARM_32\n    printk(\"     HDFAR: %08\"PRIx32\"\\n\", READ_CP32(HDFAR));\n    printk(\"     HIFAR: %08\"PRIx32\"\\n\", READ_CP32(HIFAR));\n#else\n    printk(\"   FAR_EL2: %016\"PRIx64\"\\n\", READ_SYSREG64(FAR_EL2));\n#endif\n    printk(\"\\n\");\n}",
        "func": "static void _show_registers(struct cpu_user_regs *regs,\n                            struct reg_ctxt *ctxt,\n                            int guest_mode,\n                            const struct vcpu *v)\n{\n    print_xen_info();\n\n    printk(\"CPU:    %d\\n\", smp_processor_id());\n\n    if ( guest_mode )\n    {\n        if ( is_32bit_domain(v->domain) )\n            show_registers_32(regs, ctxt, guest_mode, v);\n#ifdef CONFIG_ARM_64\n        else if ( is_64bit_domain(v->domain) )\n        {\n            if ( psr_mode_is_32bit(regs->cpsr) )\n            {\n                BUG_ON(!usr_mode(regs));\n                show_registers_32(regs, ctxt, guest_mode, v);\n            }\n            else\n            {\n                show_registers_64(regs, ctxt, guest_mode, v);\n            }\n        }\n#endif\n    }\n    else\n    {\n#ifdef CONFIG_ARM_64\n        show_registers_64(regs, ctxt, guest_mode, v);\n#else\n        show_registers_32(regs, ctxt, guest_mode, v);\n#endif\n    }\n    printk(\"  VTCR_EL2: %08\"PRIx32\"\\n\", READ_SYSREG32(VTCR_EL2));\n    printk(\" VTTBR_EL2: %016\"PRIx64\"\\n\", ctxt->vttbr_el2);\n    printk(\"\\n\");\n\n    printk(\" SCTLR_EL2: %08\"PRIx32\"\\n\", READ_SYSREG32(SCTLR_EL2));\n    printk(\"   HCR_EL2: %016\"PRIregister\"\\n\", READ_SYSREG(HCR_EL2));\n    printk(\" TTBR0_EL2: %016\"PRIx64\"\\n\", READ_SYSREG64(TTBR0_EL2));\n    printk(\"\\n\");\n    printk(\"   ESR_EL2: %08\"PRIx32\"\\n\", READ_SYSREG32(ESR_EL2));\n    printk(\" HPFAR_EL2: %016\"PRIregister\"\\n\", READ_SYSREG(HPFAR_EL2));\n\n#ifdef CONFIG_ARM_32\n    printk(\"     HDFAR: %08\"PRIx32\"\\n\", READ_CP32(HDFAR));\n    printk(\"     HIFAR: %08\"PRIx32\"\\n\", READ_CP32(HIFAR));\n#else\n    printk(\"   FAR_EL2: %016\"PRIx64\"\\n\", READ_SYSREG64(FAR_EL2));\n#endif\n    printk(\"\\n\");\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,17 @@\n             show_registers_32(regs, ctxt, guest_mode, v);\n #ifdef CONFIG_ARM_64\n         else if ( is_64bit_domain(v->domain) )\n-            show_registers_64(regs, ctxt, guest_mode, v);\n+        {\n+            if ( psr_mode_is_32bit(regs->cpsr) )\n+            {\n+                BUG_ON(!usr_mode(regs));\n+                show_registers_32(regs, ctxt, guest_mode, v);\n+            }\n+            else\n+            {\n+                show_registers_64(regs, ctxt, guest_mode, v);\n+            }\n+        }\n #endif\n     }\n     else",
        "diff_line_info": {
            "deleted_lines": [
                "            show_registers_64(regs, ctxt, guest_mode, v);"
            ],
            "added_lines": [
                "        {",
                "            if ( psr_mode_is_32bit(regs->cpsr) )",
                "            {",
                "                BUG_ON(!usr_mode(regs));",
                "                show_registers_32(regs, ctxt, guest_mode, v);",
                "            }",
                "            else",
                "            {",
                "                show_registers_64(regs, ctxt, guest_mode, v);",
                "            }",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/do_trap_hypervisor",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/c0020e0997024eb741d60de9a480bf2878f891af",
        "commit_title": "xen: arm: Handle traps from 32-bit userspace on 64-bit kernel as undef",
        "commit_text": " We are not setup to handle these properly. This turns a host crash into a trap to the guest kernel which will likely result in killing the offending process.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "asmlinkage void do_trap_hypervisor(struct cpu_user_regs *regs)\n{\n    union hsr hsr = { .bits = READ_SYSREG32(ESR_EL2) };\n\n    enter_hypervisor_head(regs);\n\n    switch (hsr.ec) {\n    case HSR_EC_WFI_WFE:\n        if ( !check_conditional_instr(regs, hsr) )\n        {\n            advance_pc(regs, hsr);\n            return;\n        }\n        if ( hsr.wfi_wfe.ti ) {\n            /* Yield the VCPU for WFE */\n            vcpu_yield();\n        } else {\n            /* Block the VCPU for WFI */\n            vcpu_block_unless_event_pending(current);\n        }\n        advance_pc(regs, hsr);\n        break;\n    case HSR_EC_CP15_32:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp15_32(regs, hsr);\n        break;\n    case HSR_EC_CP15_64:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp15_64(regs, hsr);\n        break;\n    case HSR_EC_CP14_32:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp14_32(regs, hsr);\n        break;\n    case HSR_EC_CP14_DBG:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp14_dbg(regs, hsr);\n        break;\n    case HSR_EC_CP:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp(regs, hsr);\n        break;\n    case HSR_EC_SMC32:\n        inject_undef32_exception(regs);\n        break;\n    case HSR_EC_HVC32:\n#ifndef NDEBUG\n        if ( (hsr.iss & 0xff00) == 0xff00 )\n            return do_debug_trap(regs, hsr.iss & 0x00ff);\n#endif\n        if ( hsr.iss == 0 )\n            return do_trap_psci(regs);\n        do_trap_hypercall(regs, (register_t *)&regs->r12, hsr.iss);\n        break;\n#ifdef CONFIG_ARM_64\n    case HSR_EC_HVC64:\n#ifndef NDEBUG\n        if ( (hsr.iss & 0xff00) == 0xff00 )\n            return do_debug_trap(regs, hsr.iss & 0x00ff);\n#endif\n        if ( hsr.iss == 0 )\n            return do_trap_psci(regs);\n        do_trap_hypercall(regs, &regs->x16, hsr.iss);\n        break;\n    case HSR_EC_SMC64:\n        inject_undef64_exception(regs, hsr.len);\n        break;\n    case HSR_EC_SYSREG:\n        if ( is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_sysreg(regs, hsr);\n        break;\n#endif\n\n    case HSR_EC_INSTR_ABORT_LOWER_EL:\n        do_trap_instr_abort_guest(regs, hsr);\n        break;\n    case HSR_EC_DATA_ABORT_LOWER_EL:\n        do_trap_data_abort_guest(regs, hsr);\n        break;\n    default:\n bad_trap:\n        printk(\"Hypervisor Trap. HSR=0x%x EC=0x%x IL=%x Syndrome=0x%\"PRIx32\"\\n\",\n               hsr.bits, hsr.ec, hsr.len, hsr.iss);\n        do_unexpected_trap(\"Hypervisor\", regs);\n    }\n}",
        "func": "asmlinkage void do_trap_hypervisor(struct cpu_user_regs *regs)\n{\n    union hsr hsr = { .bits = READ_SYSREG32(ESR_EL2) };\n\n    enter_hypervisor_head(regs);\n\n    /*\n     * We currently do not handle 32-bit userspace on 64-bit kernels\n     * correctly (See XSA-102). Until that is resolved we treat any\n     * trap from 32-bit userspace on 64-bit kernel as undefined.\n     */\n    if ( is_64bit_domain(current->domain) && psr_mode_is_32bit(regs->cpsr) )\n    {\n        inject_undef_exception(regs, hsr.len);\n        return;\n    }\n\n    switch (hsr.ec) {\n    case HSR_EC_WFI_WFE:\n        if ( !check_conditional_instr(regs, hsr) )\n        {\n            advance_pc(regs, hsr);\n            return;\n        }\n        if ( hsr.wfi_wfe.ti ) {\n            /* Yield the VCPU for WFE */\n            vcpu_yield();\n        } else {\n            /* Block the VCPU for WFI */\n            vcpu_block_unless_event_pending(current);\n        }\n        advance_pc(regs, hsr);\n        break;\n    case HSR_EC_CP15_32:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp15_32(regs, hsr);\n        break;\n    case HSR_EC_CP15_64:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp15_64(regs, hsr);\n        break;\n    case HSR_EC_CP14_32:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp14_32(regs, hsr);\n        break;\n    case HSR_EC_CP14_DBG:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp14_dbg(regs, hsr);\n        break;\n    case HSR_EC_CP:\n        if ( !is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_cp(regs, hsr);\n        break;\n    case HSR_EC_SMC32:\n        inject_undef32_exception(regs);\n        break;\n    case HSR_EC_HVC32:\n#ifndef NDEBUG\n        if ( (hsr.iss & 0xff00) == 0xff00 )\n            return do_debug_trap(regs, hsr.iss & 0x00ff);\n#endif\n        if ( hsr.iss == 0 )\n            return do_trap_psci(regs);\n        do_trap_hypercall(regs, (register_t *)&regs->r12, hsr.iss);\n        break;\n#ifdef CONFIG_ARM_64\n    case HSR_EC_HVC64:\n#ifndef NDEBUG\n        if ( (hsr.iss & 0xff00) == 0xff00 )\n            return do_debug_trap(regs, hsr.iss & 0x00ff);\n#endif\n        if ( hsr.iss == 0 )\n            return do_trap_psci(regs);\n        do_trap_hypercall(regs, &regs->x16, hsr.iss);\n        break;\n    case HSR_EC_SMC64:\n        inject_undef64_exception(regs, hsr.len);\n        break;\n    case HSR_EC_SYSREG:\n        if ( is_32bit_domain(current->domain) )\n            goto bad_trap;\n        do_sysreg(regs, hsr);\n        break;\n#endif\n\n    case HSR_EC_INSTR_ABORT_LOWER_EL:\n        do_trap_instr_abort_guest(regs, hsr);\n        break;\n    case HSR_EC_DATA_ABORT_LOWER_EL:\n        do_trap_data_abort_guest(regs, hsr);\n        break;\n    default:\n bad_trap:\n        printk(\"Hypervisor Trap. HSR=0x%x EC=0x%x IL=%x Syndrome=0x%\"PRIx32\"\\n\",\n               hsr.bits, hsr.ec, hsr.len, hsr.iss);\n        do_unexpected_trap(\"Hypervisor\", regs);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,17 @@\n     union hsr hsr = { .bits = READ_SYSREG32(ESR_EL2) };\n \n     enter_hypervisor_head(regs);\n+\n+    /*\n+     * We currently do not handle 32-bit userspace on 64-bit kernels\n+     * correctly (See XSA-102). Until that is resolved we treat any\n+     * trap from 32-bit userspace on 64-bit kernel as undefined.\n+     */\n+    if ( is_64bit_domain(current->domain) && psr_mode_is_32bit(regs->cpsr) )\n+    {\n+        inject_undef_exception(regs, hsr.len);\n+        return;\n+    }\n \n     switch (hsr.ec) {\n     case HSR_EC_WFI_WFE:",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    /*",
                "     * We currently do not handle 32-bit userspace on 64-bit kernels",
                "     * correctly (See XSA-102). Until that is resolved we treat any",
                "     * trap from 32-bit userspace on 64-bit kernel as undefined.",
                "     */",
                "    if ( is_64bit_domain(current->domain) && psr_mode_is_32bit(regs->cpsr) )",
                "    {",
                "        inject_undef_exception(regs, hsr.len);",
                "        return;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/do_cp15_64",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void do_cp15_64(struct cpu_user_regs *regs,\n                       union hsr hsr)\n{\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n    switch ( hsr.bits & HSR_CP64_REGS_MASK )\n    {\n    case HSR_CPREG64(CNTPCT):\n        if ( !vtimer_emulate(regs, hsr) )\n        {\n            dprintk(XENLOG_ERR,\n                    \"failed emulation of 64-bit vtimer CP register access\\n\");\n            domain_crash_synchronous();\n        }\n        break;\n    default:\n        {\n#ifndef NDEBUG\n            struct hsr_cp64 cp64 = hsr.cp64;\n\n            gdprintk(XENLOG_ERR,\n                     \"%s p15, %d, r%d, r%d, cr%d @ 0x%\"PRIregister\"\\n\",\n                     cp64.read ? \"mrrc\" : \"mcrr\",\n                     cp64.op1, cp64.reg1, cp64.reg2, cp64.crm, regs->pc);\n            gdprintk(XENLOG_ERR, \"unhandled 64-bit CP15 access %#x\\n\",\n                     hsr.bits & HSR_CP64_REGS_MASK);\n#endif\n            inject_undef32_exception(regs);\n            return;\n        }\n    }\n    advance_pc(regs, hsr);\n}",
        "func": "static void do_cp15_64(struct cpu_user_regs *regs,\n                       union hsr hsr)\n{\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n    switch ( hsr.bits & HSR_CP64_REGS_MASK )\n    {\n    case HSR_CPREG64(CNTPCT):\n        if ( !vtimer_emulate(regs, hsr) )\n        {\n            dprintk(XENLOG_ERR,\n                    \"failed emulation of 64-bit vtimer CP register access\\n\");\n            domain_crash_synchronous();\n        }\n        break;\n    default:\n        {\n#ifndef NDEBUG\n            struct hsr_cp64 cp64 = hsr.cp64;\n\n            gdprintk(XENLOG_ERR,\n                     \"%s p15, %d, r%d, r%d, cr%d @ 0x%\"PRIregister\"\\n\",\n                     cp64.read ? \"mrrc\" : \"mcrr\",\n                     cp64.op1, cp64.reg1, cp64.reg2, cp64.crm, regs->pc);\n            gdprintk(XENLOG_ERR, \"unhandled 64-bit CP15 access %#x\\n\",\n                     hsr.bits & HSR_CP64_REGS_MASK);\n#endif\n            inject_undef_exception(regs, hsr.len);\n            return;\n        }\n    }\n    advance_pc(regs, hsr);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,7 +29,7 @@\n             gdprintk(XENLOG_ERR, \"unhandled 64-bit CP15 access %#x\\n\",\n                      hsr.bits & HSR_CP64_REGS_MASK);\n #endif\n-            inject_undef32_exception(regs);\n+            inject_undef_exception(regs, hsr.len);\n             return;\n         }\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "            inject_undef32_exception(regs);"
            ],
            "added_lines": [
                "            inject_undef_exception(regs, hsr.len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/do_sysreg",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void do_sysreg(struct cpu_user_regs *regs,\n                      union hsr hsr)\n{\n    register_t *x = select_user_reg(regs, hsr.sysreg.reg);\n\n    switch ( hsr.bits & HSR_SYSREG_REGS_MASK )\n    {\n    /* RAZ/WI registers: */\n    /*  - Debug */\n    case HSR_SYSREG_MDSCR_EL1:\n    /*  - Perf monitors */\n    case HSR_SYSREG_PMINTENSET_EL1:\n    case HSR_SYSREG_PMINTENCLR_EL1:\n    case HSR_SYSREG_PMCR_EL0:\n    case HSR_SYSREG_PMCNTENSET_EL0:\n    case HSR_SYSREG_PMCNTENCLR_EL0:\n    case HSR_SYSREG_PMOVSCLR_EL0:\n    case HSR_SYSREG_PMSWINC_EL0:\n    case HSR_SYSREG_PMSELR_EL0:\n    case HSR_SYSREG_PMCEID0_EL0:\n    case HSR_SYSREG_PMCEID1_EL0:\n    case HSR_SYSREG_PMCCNTR_EL0:\n    case HSR_SYSREG_PMXEVTYPER_EL0:\n    case HSR_SYSREG_PMXEVCNTR_EL0:\n    case HSR_SYSREG_PMUSERENR_EL0:\n    case HSR_SYSREG_PMOVSSET_EL0:\n    /* - Breakpoints */\n    HSR_SYSREG_DBG_CASES(DBGBVR):\n    HSR_SYSREG_DBG_CASES(DBGBCR):\n    /* - Watchpoints */\n    HSR_SYSREG_DBG_CASES(DBGWVR):\n    HSR_SYSREG_DBG_CASES(DBGWCR):\n    /* - Double Lock Register */\n    case HSR_SYSREG_OSDLR_EL1:\n        if ( hsr.sysreg.read )\n            *x = 0;\n        /* else: write ignored */\n        break;\n\n    /* Write only, Write ignore registers: */\n    case HSR_SYSREG_OSLAR_EL1:\n        if ( hsr.sysreg.read )\n            goto bad_sysreg;\n        /* else: write ignored */\n        break;\n    case HSR_SYSREG_CNTP_CTL_EL0:\n    case HSR_SYSREG_CNTP_TVAL_EL0:\n        if ( !vtimer_emulate(regs, hsr) )\n        {\n            dprintk(XENLOG_ERR,\n                    \"failed emulation of 64-bit vtimer sysreg access\\n\");\n            domain_crash_synchronous();\n        }\n        break;\n    default:\n bad_sysreg:\n        {\n            struct hsr_sysreg sysreg = hsr.sysreg;\n#ifndef NDEBUG\n\n            gdprintk(XENLOG_ERR,\n                     \"%s %d, %d, c%d, c%d, %d %s x%d @ 0x%\"PRIregister\"\\n\",\n                     sysreg.read ? \"mrs\" : \"msr\",\n                     sysreg.op0, sysreg.op1,\n                     sysreg.crn, sysreg.crm,\n                     sysreg.op2,\n                     sysreg.read ? \"=>\" : \"<=\",\n                     sysreg.reg, regs->pc);\n            gdprintk(XENLOG_ERR, \"unhandled 64-bit sysreg access %#x\\n\",\n                     hsr.bits & HSR_SYSREG_REGS_MASK);\n#endif\n            inject_undef64_exception(regs, sysreg.len);\n        }\n    }\n\n    regs->pc += 4;\n}",
        "func": "static void do_sysreg(struct cpu_user_regs *regs,\n                      union hsr hsr)\n{\n    register_t *x = select_user_reg(regs, hsr.sysreg.reg);\n\n    switch ( hsr.bits & HSR_SYSREG_REGS_MASK )\n    {\n    /* RAZ/WI registers: */\n    /*  - Debug */\n    case HSR_SYSREG_MDSCR_EL1:\n    /*  - Perf monitors */\n    case HSR_SYSREG_PMINTENSET_EL1:\n    case HSR_SYSREG_PMINTENCLR_EL1:\n    case HSR_SYSREG_PMCR_EL0:\n    case HSR_SYSREG_PMCNTENSET_EL0:\n    case HSR_SYSREG_PMCNTENCLR_EL0:\n    case HSR_SYSREG_PMOVSCLR_EL0:\n    case HSR_SYSREG_PMSWINC_EL0:\n    case HSR_SYSREG_PMSELR_EL0:\n    case HSR_SYSREG_PMCEID0_EL0:\n    case HSR_SYSREG_PMCEID1_EL0:\n    case HSR_SYSREG_PMCCNTR_EL0:\n    case HSR_SYSREG_PMXEVTYPER_EL0:\n    case HSR_SYSREG_PMXEVCNTR_EL0:\n    case HSR_SYSREG_PMUSERENR_EL0:\n    case HSR_SYSREG_PMOVSSET_EL0:\n    /* - Breakpoints */\n    HSR_SYSREG_DBG_CASES(DBGBVR):\n    HSR_SYSREG_DBG_CASES(DBGBCR):\n    /* - Watchpoints */\n    HSR_SYSREG_DBG_CASES(DBGWVR):\n    HSR_SYSREG_DBG_CASES(DBGWCR):\n    /* - Double Lock Register */\n    case HSR_SYSREG_OSDLR_EL1:\n        if ( hsr.sysreg.read )\n            *x = 0;\n        /* else: write ignored */\n        break;\n\n    /* Write only, Write ignore registers: */\n    case HSR_SYSREG_OSLAR_EL1:\n        if ( hsr.sysreg.read )\n            goto bad_sysreg;\n        /* else: write ignored */\n        break;\n    case HSR_SYSREG_CNTP_CTL_EL0:\n    case HSR_SYSREG_CNTP_TVAL_EL0:\n        if ( !vtimer_emulate(regs, hsr) )\n        {\n            dprintk(XENLOG_ERR,\n                    \"failed emulation of 64-bit vtimer sysreg access\\n\");\n            domain_crash_synchronous();\n        }\n        break;\n    default:\n bad_sysreg:\n        {\n            struct hsr_sysreg sysreg = hsr.sysreg;\n#ifndef NDEBUG\n\n            gdprintk(XENLOG_ERR,\n                     \"%s %d, %d, c%d, c%d, %d %s x%d @ 0x%\"PRIregister\"\\n\",\n                     sysreg.read ? \"mrs\" : \"msr\",\n                     sysreg.op0, sysreg.op1,\n                     sysreg.crn, sysreg.crm,\n                     sysreg.op2,\n                     sysreg.read ? \"=>\" : \"<=\",\n                     sysreg.reg, regs->pc);\n            gdprintk(XENLOG_ERR, \"unhandled 64-bit sysreg access %#x\\n\",\n                     hsr.bits & HSR_SYSREG_REGS_MASK);\n#endif\n            inject_undef_exception(regs, sysreg.len);\n        }\n    }\n\n    regs->pc += 4;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -69,7 +69,7 @@\n             gdprintk(XENLOG_ERR, \"unhandled 64-bit sysreg access %#x\\n\",\n                      hsr.bits & HSR_SYSREG_REGS_MASK);\n #endif\n-            inject_undef64_exception(regs, sysreg.len);\n+            inject_undef_exception(regs, sysreg.len);\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            inject_undef64_exception(regs, sysreg.len);"
            ],
            "added_lines": [
                "            inject_undef_exception(regs, sysreg.len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/inject_abt32_exception",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void inject_abt32_exception(struct cpu_user_regs *regs,\n                                   int prefetch,\n                                   register_t addr)\n{\n    uint32_t spsr = regs->cpsr;\n    int is_thumb = (regs->cpsr & PSR_THUMB);\n    /* Saved PC points to the instruction past the faulting instruction. */\n    uint32_t return_offset = is_thumb ? 4 : 0;\n    register_t fsr;\n\n    BUG_ON( !is_32bit_domain(current->domain) );\n\n    cpsr_switch_mode(regs, PSR_MODE_ABT);\n\n    /* Update banked registers */\n    regs->spsr_abt = spsr;\n    regs->lr_abt = regs->pc32 + return_offset;\n\n    regs->pc32 = exception_handler(prefetch ? VECTOR32_PABT : VECTOR32_DABT);\n\n    /* Inject a debug fault, best we can do right now */\n    if ( READ_SYSREG(TCR_EL1) & TTBCR_EAE )\n        fsr = FSR_LPAE | FSRL_STATUS_DEBUG;\n    else\n        fsr = FSRS_FS_DEBUG;\n\n    if ( prefetch )\n    {\n        /* Set IFAR and IFSR */\n#ifdef CONFIG_ARM_32\n        WRITE_SYSREG(addr, IFAR);\n        WRITE_SYSREG(fsr, IFSR);\n#else\n        /* FAR_EL1[63:32] is AArch32 register IFAR */\n        register_t far = READ_SYSREG(FAR_EL1) & 0xffffffffUL;\n        far |= addr << 32;\n        WRITE_SYSREG(far, FAR_EL1);\n        WRITE_SYSREG(fsr, IFSR32_EL2);\n\n#endif\n    }\n    else\n    {\n#ifdef CONFIG_ARM_32\n        /* Set DFAR and DFSR */\n        WRITE_SYSREG(addr, DFAR);\n        WRITE_SYSREG(fsr, DFSR);\n#else\n        /* FAR_EL1[31:0] is AArch32 register DFAR */\n        register_t far = READ_SYSREG(FAR_EL1) & ~0xffffffffUL;\n        far |= addr;\n        WRITE_SYSREG(far, FAR_EL1);\n        /* ESR_EL1 is AArch32 register DFSR */\n        WRITE_SYSREG(fsr, ESR_EL1);\n#endif\n    }\n}",
        "func": "static void inject_abt32_exception(struct cpu_user_regs *regs,\n                                   int prefetch,\n                                   register_t addr)\n{\n    uint32_t spsr = regs->cpsr;\n    int is_thumb = (regs->cpsr & PSR_THUMB);\n    /* Saved PC points to the instruction past the faulting instruction. */\n    uint32_t return_offset = is_thumb ? 4 : 0;\n    register_t fsr;\n\n    BUG_ON( !is_32bit_domain(current->domain) );\n\n    cpsr_switch_mode(regs, PSR_MODE_ABT);\n\n    /* Update banked registers */\n    regs->spsr_abt = spsr;\n    regs->lr_abt = regs->pc32 + return_offset;\n\n    regs->pc32 = exception_handler32(prefetch ? VECTOR32_PABT : VECTOR32_DABT);\n\n    /* Inject a debug fault, best we can do right now */\n    if ( READ_SYSREG(TCR_EL1) & TTBCR_EAE )\n        fsr = FSR_LPAE | FSRL_STATUS_DEBUG;\n    else\n        fsr = FSRS_FS_DEBUG;\n\n    if ( prefetch )\n    {\n        /* Set IFAR and IFSR */\n#ifdef CONFIG_ARM_32\n        WRITE_SYSREG(addr, IFAR);\n        WRITE_SYSREG(fsr, IFSR);\n#else\n        /* FAR_EL1[63:32] is AArch32 register IFAR */\n        register_t far = READ_SYSREG(FAR_EL1) & 0xffffffffUL;\n        far |= addr << 32;\n        WRITE_SYSREG(far, FAR_EL1);\n        WRITE_SYSREG(fsr, IFSR32_EL2);\n\n#endif\n    }\n    else\n    {\n#ifdef CONFIG_ARM_32\n        /* Set DFAR and DFSR */\n        WRITE_SYSREG(addr, DFAR);\n        WRITE_SYSREG(fsr, DFSR);\n#else\n        /* FAR_EL1[31:0] is AArch32 register DFAR */\n        register_t far = READ_SYSREG(FAR_EL1) & ~0xffffffffUL;\n        far |= addr;\n        WRITE_SYSREG(far, FAR_EL1);\n        /* ESR_EL1 is AArch32 register DFSR */\n        WRITE_SYSREG(fsr, ESR_EL1);\n#endif\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,7 @@\n     regs->spsr_abt = spsr;\n     regs->lr_abt = regs->pc32 + return_offset;\n \n-    regs->pc32 = exception_handler(prefetch ? VECTOR32_PABT : VECTOR32_DABT);\n+    regs->pc32 = exception_handler32(prefetch ? VECTOR32_PABT : VECTOR32_DABT);\n \n     /* Inject a debug fault, best we can do right now */\n     if ( READ_SYSREG(TCR_EL1) & TTBCR_EAE )",
        "diff_line_info": {
            "deleted_lines": [
                "    regs->pc32 = exception_handler(prefetch ? VECTOR32_PABT : VECTOR32_DABT);"
            ],
            "added_lines": [
                "    regs->pc32 = exception_handler32(prefetch ? VECTOR32_PABT : VECTOR32_DABT);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/inject_undef64_exception",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void inject_undef64_exception(struct cpu_user_regs *regs, int instr_len)\n{\n    union hsr esr = {\n        .iss = 0,\n        .len = instr_len,\n        .ec = HSR_EC_UNKNOWN,\n    };\n\n    BUG_ON( is_32bit_domain(current->domain) );\n\n    regs->spsr_el1 = regs->cpsr;\n    regs->elr_el1 = regs->pc;\n\n    regs->cpsr = PSR_MODE_EL1h | PSR_ABT_MASK | PSR_FIQ_MASK | \\\n        PSR_IRQ_MASK | PSR_DBG_MASK;\n    regs->pc = READ_SYSREG(VBAR_EL1) + VECTOR64_CURRENT_SPx_SYNC;\n\n    WRITE_SYSREG32(esr.bits, ESR_EL1);\n}",
        "func": "static void inject_undef64_exception(struct cpu_user_regs *regs, int instr_len)\n{\n    vaddr_t handler;\n    union hsr esr = {\n        .iss = 0,\n        .len = instr_len,\n        .ec = HSR_EC_UNKNOWN,\n    };\n\n    BUG_ON( is_32bit_domain(current->domain) );\n\n    handler = exception_handler64(regs, VECTOR64_SYNC_OFFSET);\n\n    regs->spsr_el1 = regs->cpsr;\n    regs->elr_el1 = regs->pc;\n\n    regs->cpsr = PSR_MODE_EL1h | PSR_ABT_MASK | PSR_FIQ_MASK | \\\n        PSR_IRQ_MASK | PSR_DBG_MASK;\n    regs->pc = handler;\n\n    WRITE_SYSREG32(esr.bits, ESR_EL1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n static void inject_undef64_exception(struct cpu_user_regs *regs, int instr_len)\n {\n+    vaddr_t handler;\n     union hsr esr = {\n         .iss = 0,\n         .len = instr_len,\n@@ -8,12 +9,14 @@\n \n     BUG_ON( is_32bit_domain(current->domain) );\n \n+    handler = exception_handler64(regs, VECTOR64_SYNC_OFFSET);\n+\n     regs->spsr_el1 = regs->cpsr;\n     regs->elr_el1 = regs->pc;\n \n     regs->cpsr = PSR_MODE_EL1h | PSR_ABT_MASK | PSR_FIQ_MASK | \\\n         PSR_IRQ_MASK | PSR_DBG_MASK;\n-    regs->pc = READ_SYSREG(VBAR_EL1) + VECTOR64_CURRENT_SPx_SYNC;\n+    regs->pc = handler;\n \n     WRITE_SYSREG32(esr.bits, ESR_EL1);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    regs->pc = READ_SYSREG(VBAR_EL1) + VECTOR64_CURRENT_SPx_SYNC;"
            ],
            "added_lines": [
                "    vaddr_t handler;",
                "    handler = exception_handler64(regs, VECTOR64_SYNC_OFFSET);",
                "",
                "    regs->pc = handler;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/do_cp15_32",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void do_cp15_32(struct cpu_user_regs *regs,\n                       union hsr hsr)\n{\n    struct hsr_cp32 cp32 = hsr.cp32;\n    uint32_t *r = (uint32_t*)select_user_reg(regs, cp32.reg);\n    struct vcpu *v = current;\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n    switch ( hsr.bits & HSR_CP32_REGS_MASK )\n    {\n    case HSR_CPREG32(CLIDR):\n        if ( !cp32.read )\n        {\n            dprintk(XENLOG_ERR,\n                    \"attempt to write to read-only register CLIDR\\n\");\n            domain_crash_synchronous();\n        }\n        *r = READ_SYSREG32(CLIDR_EL1);\n        break;\n    case HSR_CPREG32(CCSIDR):\n        if ( !cp32.read )\n        {\n            dprintk(XENLOG_ERR,\n                    \"attempt to write to read-only register CCSIDR\\n\");\n            domain_crash_synchronous();\n        }\n        *r = READ_SYSREG32(CCSIDR_EL1);\n        break;\n    case HSR_CPREG32(DCCISW):\n        if ( cp32.read )\n        {\n            dprintk(XENLOG_ERR,\n                    \"attempt to read from write-only register DCCISW\\n\");\n            domain_crash_synchronous();\n        }\n#ifdef CONFIG_ARM_32\n        WRITE_CP32(*r, DCCISW);\n#else\n        asm volatile(\"dc cisw, %0;\" : : \"r\" (*r) : \"memory\");\n#endif\n        break;\n    case HSR_CPREG32(CNTP_CTL):\n    case HSR_CPREG32(CNTP_TVAL):\n        if ( !vtimer_emulate(regs, hsr) )\n        {\n            dprintk(XENLOG_ERR,\n                    \"failed emulation of 32-bit vtimer CP register access\\n\");\n            domain_crash_synchronous();\n        }\n        break;\n    case HSR_CPREG32(ACTLR):\n        if ( cp32.read )\n           *r = v->arch.actlr;\n        break;\n\n    /* We could trap ID_DFR0 and tell the guest we don't support\n     * performance monitoring, but Linux doesn't check the ID_DFR0.\n     * Therefore it will read PMCR.\n     *\n     * We tell the guest we have 0 counters. Unfortunately we must\n     * always support PMCCNTR (the cyle counter): we just RAZ/WI for all\n     * PM register, which doesn't crash the kernel at least\n     */\n    case HSR_CPREG32(PMCR):\n    case HSR_CPREG32(PMCNTENSET):\n    case HSR_CPREG32(PMCNTENCLR):\n    case HSR_CPREG32(PMOVSR):\n    case HSR_CPREG32(PMSWINC):\n    case HSR_CPREG32(PMSELR):\n    case HSR_CPREG32(PMCEID0):\n    case HSR_CPREG32(PMCEID1):\n    case HSR_CPREG32(PMCCNTR):\n    case HSR_CPREG32(PMXEVCNTR):\n    case HSR_CPREG32(PMXEVCNR):\n    case HSR_CPREG32(PMUSERENR):\n    case HSR_CPREG32(PMINTENSET):\n    case HSR_CPREG32(PMINTENCLR):\n    case HSR_CPREG32(PMOVSSET):\n        if ( cp32.read )\n            *r = 0;\n        break;\n\n    default:\n#ifndef NDEBUG\n        gdprintk(XENLOG_ERR,\n                 \"%s p15, %d, r%d, cr%d, cr%d, %d @ 0x%\"PRIregister\"\\n\",\n                 cp32.read ? \"mrc\" : \"mcr\",\n                 cp32.op1, cp32.reg, cp32.crn, cp32.crm, cp32.op2, regs->pc);\n        gdprintk(XENLOG_ERR, \"unhandled 32-bit CP15 access %#x\\n\",\n                 hsr.bits & HSR_CP32_REGS_MASK);\n#endif\n        inject_undef32_exception(regs);\n        return;\n    }\n    advance_pc(regs, hsr);\n}",
        "func": "static void do_cp15_32(struct cpu_user_regs *regs,\n                       union hsr hsr)\n{\n    struct hsr_cp32 cp32 = hsr.cp32;\n    uint32_t *r = (uint32_t*)select_user_reg(regs, cp32.reg);\n    struct vcpu *v = current;\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n    switch ( hsr.bits & HSR_CP32_REGS_MASK )\n    {\n    case HSR_CPREG32(CLIDR):\n        if ( !cp32.read )\n        {\n            dprintk(XENLOG_ERR,\n                    \"attempt to write to read-only register CLIDR\\n\");\n            domain_crash_synchronous();\n        }\n        *r = READ_SYSREG32(CLIDR_EL1);\n        break;\n    case HSR_CPREG32(CCSIDR):\n        if ( !cp32.read )\n        {\n            dprintk(XENLOG_ERR,\n                    \"attempt to write to read-only register CCSIDR\\n\");\n            domain_crash_synchronous();\n        }\n        *r = READ_SYSREG32(CCSIDR_EL1);\n        break;\n    case HSR_CPREG32(DCCISW):\n        if ( cp32.read )\n        {\n            dprintk(XENLOG_ERR,\n                    \"attempt to read from write-only register DCCISW\\n\");\n            domain_crash_synchronous();\n        }\n#ifdef CONFIG_ARM_32\n        WRITE_CP32(*r, DCCISW);\n#else\n        asm volatile(\"dc cisw, %0;\" : : \"r\" (*r) : \"memory\");\n#endif\n        break;\n    case HSR_CPREG32(CNTP_CTL):\n    case HSR_CPREG32(CNTP_TVAL):\n        if ( !vtimer_emulate(regs, hsr) )\n        {\n            dprintk(XENLOG_ERR,\n                    \"failed emulation of 32-bit vtimer CP register access\\n\");\n            domain_crash_synchronous();\n        }\n        break;\n    case HSR_CPREG32(ACTLR):\n        if ( cp32.read )\n           *r = v->arch.actlr;\n        break;\n\n    /* We could trap ID_DFR0 and tell the guest we don't support\n     * performance monitoring, but Linux doesn't check the ID_DFR0.\n     * Therefore it will read PMCR.\n     *\n     * We tell the guest we have 0 counters. Unfortunately we must\n     * always support PMCCNTR (the cyle counter): we just RAZ/WI for all\n     * PM register, which doesn't crash the kernel at least\n     */\n    case HSR_CPREG32(PMCR):\n    case HSR_CPREG32(PMCNTENSET):\n    case HSR_CPREG32(PMCNTENCLR):\n    case HSR_CPREG32(PMOVSR):\n    case HSR_CPREG32(PMSWINC):\n    case HSR_CPREG32(PMSELR):\n    case HSR_CPREG32(PMCEID0):\n    case HSR_CPREG32(PMCEID1):\n    case HSR_CPREG32(PMCCNTR):\n    case HSR_CPREG32(PMXEVCNTR):\n    case HSR_CPREG32(PMXEVCNR):\n    case HSR_CPREG32(PMUSERENR):\n    case HSR_CPREG32(PMINTENSET):\n    case HSR_CPREG32(PMINTENCLR):\n    case HSR_CPREG32(PMOVSSET):\n        if ( cp32.read )\n            *r = 0;\n        break;\n\n    default:\n#ifndef NDEBUG\n        gdprintk(XENLOG_ERR,\n                 \"%s p15, %d, r%d, cr%d, cr%d, %d @ 0x%\"PRIregister\"\\n\",\n                 cp32.read ? \"mrc\" : \"mcr\",\n                 cp32.op1, cp32.reg, cp32.crn, cp32.crm, cp32.op2, regs->pc);\n        gdprintk(XENLOG_ERR, \"unhandled 32-bit CP15 access %#x\\n\",\n                 hsr.bits & HSR_CP32_REGS_MASK);\n#endif\n        inject_undef_exception(regs, hsr.len);\n        return;\n    }\n    advance_pc(regs, hsr);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -94,7 +94,7 @@\n         gdprintk(XENLOG_ERR, \"unhandled 32-bit CP15 access %#x\\n\",\n                  hsr.bits & HSR_CP32_REGS_MASK);\n #endif\n-        inject_undef32_exception(regs);\n+        inject_undef_exception(regs, hsr.len);\n         return;\n     }\n     advance_pc(regs, hsr);",
        "diff_line_info": {
            "deleted_lines": [
                "        inject_undef32_exception(regs);"
            ],
            "added_lines": [
                "        inject_undef_exception(regs, hsr.len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/do_cp",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void do_cp(struct cpu_user_regs *regs, union hsr hsr)\n{\n#ifndef NDEBUG\n    struct hsr_cp cp = hsr.cp;\n#endif\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n#ifndef NDEBUG\n    ASSERT(!cp.tas); /* We don't trap SIMD instruction */\n    gdprintk(XENLOG_ERR, \"unhandled CP%d access\\n\", cp.coproc);\n#endif\n    inject_undef32_exception(regs);\n}",
        "func": "static void do_cp(struct cpu_user_regs *regs, union hsr hsr)\n{\n#ifndef NDEBUG\n    struct hsr_cp cp = hsr.cp;\n#endif\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n#ifndef NDEBUG\n    ASSERT(!cp.tas); /* We don't trap SIMD instruction */\n    gdprintk(XENLOG_ERR, \"unhandled CP%d access\\n\", cp.coproc);\n#endif\n    inject_undef_exception(regs, hsr.len);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,5 +14,5 @@\n     ASSERT(!cp.tas); /* We don't trap SIMD instruction */\n     gdprintk(XENLOG_ERR, \"unhandled CP%d access\\n\", cp.coproc);\n #endif\n-    inject_undef32_exception(regs);\n+    inject_undef_exception(regs, hsr.len);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    inject_undef32_exception(regs);"
            ],
            "added_lines": [
                "    inject_undef_exception(regs, hsr.len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/inject_abt64_exception",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void inject_abt64_exception(struct cpu_user_regs *regs,\n                                   int prefetch,\n                                   register_t addr,\n                                   int instr_len)\n{\n    union hsr esr = {\n        .iss = 0,\n        .len = instr_len,\n    };\n\n    /*\n     * Trap may have been taken from EL0, which might be in AArch32\n     * mode (PSR_MODE_BIT set), or in AArch64 mode (PSR_MODE_EL0t).\n     *\n     * Since we know the kernel must be 64-bit any trap from a 32-bit\n     * mode must have been from EL0.\n     */\n    if ( psr_mode_is_32bit(regs->cpsr) || psr_mode(regs->cpsr,PSR_MODE_EL0t) )\n        esr.ec = prefetch\n            ? HSR_EC_INSTR_ABORT_LOWER_EL : HSR_EC_DATA_ABORT_LOWER_EL;\n    else\n        esr.ec = prefetch\n            ? HSR_EC_INSTR_ABORT_CURR_EL : HSR_EC_DATA_ABORT_CURR_EL;\n\n    BUG_ON( is_32bit_domain(current->domain) );\n\n    regs->spsr_el1 = regs->cpsr;\n    regs->elr_el1 = regs->pc;\n\n    regs->cpsr = PSR_MODE_EL1h | PSR_ABT_MASK | PSR_FIQ_MASK | \\\n        PSR_IRQ_MASK | PSR_DBG_MASK;\n    regs->pc = READ_SYSREG(VBAR_EL1) + VECTOR64_CURRENT_SPx_SYNC;\n\n    WRITE_SYSREG(addr, FAR_EL1);\n    WRITE_SYSREG32(esr.bits, ESR_EL1);\n}",
        "func": "static void inject_abt64_exception(struct cpu_user_regs *regs,\n                                   int prefetch,\n                                   register_t addr,\n                                   int instr_len)\n{\n    vaddr_t handler;\n    union hsr esr = {\n        .iss = 0,\n        .len = instr_len,\n    };\n\n    /*\n     * Trap may have been taken from EL0, which might be in AArch32\n     * mode (PSR_MODE_BIT set), or in AArch64 mode (PSR_MODE_EL0t).\n     *\n     * Since we know the kernel must be 64-bit any trap from a 32-bit\n     * mode must have been from EL0.\n     */\n    if ( psr_mode_is_32bit(regs->cpsr) || psr_mode(regs->cpsr,PSR_MODE_EL0t) )\n        esr.ec = prefetch\n            ? HSR_EC_INSTR_ABORT_LOWER_EL : HSR_EC_DATA_ABORT_LOWER_EL;\n    else\n        esr.ec = prefetch\n            ? HSR_EC_INSTR_ABORT_CURR_EL : HSR_EC_DATA_ABORT_CURR_EL;\n\n    BUG_ON( is_32bit_domain(current->domain) );\n\n    handler = exception_handler64(regs, VECTOR64_SYNC_OFFSET);\n\n    regs->spsr_el1 = regs->cpsr;\n    regs->elr_el1 = regs->pc;\n\n    regs->cpsr = PSR_MODE_EL1h | PSR_ABT_MASK | PSR_FIQ_MASK | \\\n        PSR_IRQ_MASK | PSR_DBG_MASK;\n    regs->pc = handler;\n\n    WRITE_SYSREG(addr, FAR_EL1);\n    WRITE_SYSREG32(esr.bits, ESR_EL1);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,7 @@\n                                    register_t addr,\n                                    int instr_len)\n {\n+    vaddr_t handler;\n     union hsr esr = {\n         .iss = 0,\n         .len = instr_len,\n@@ -24,12 +25,14 @@\n \n     BUG_ON( is_32bit_domain(current->domain) );\n \n+    handler = exception_handler64(regs, VECTOR64_SYNC_OFFSET);\n+\n     regs->spsr_el1 = regs->cpsr;\n     regs->elr_el1 = regs->pc;\n \n     regs->cpsr = PSR_MODE_EL1h | PSR_ABT_MASK | PSR_FIQ_MASK | \\\n         PSR_IRQ_MASK | PSR_DBG_MASK;\n-    regs->pc = READ_SYSREG(VBAR_EL1) + VECTOR64_CURRENT_SPx_SYNC;\n+    regs->pc = handler;\n \n     WRITE_SYSREG(addr, FAR_EL1);\n     WRITE_SYSREG32(esr.bits, ESR_EL1);",
        "diff_line_info": {
            "deleted_lines": [
                "    regs->pc = READ_SYSREG(VBAR_EL1) + VECTOR64_CURRENT_SPx_SYNC;"
            ],
            "added_lines": [
                "    vaddr_t handler;",
                "    handler = exception_handler64(regs, VECTOR64_SYNC_OFFSET);",
                "",
                "    regs->pc = handler;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/inject_undef32_exception",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void inject_undef32_exception(struct cpu_user_regs *regs)\n{\n    uint32_t spsr = regs->cpsr;\n    int is_thumb = (regs->cpsr & PSR_THUMB);\n    /* Saved PC points to the instruction past the faulting instruction. */\n    uint32_t return_offset = is_thumb ? 2 : 4;\n\n    BUG_ON( !is_32bit_domain(current->domain) );\n\n    /* Update processor mode */\n    cpsr_switch_mode(regs, PSR_MODE_UND);\n\n    /* Update banked registers */\n    regs->spsr_und = spsr;\n    regs->lr_und = regs->pc32 + return_offset;\n\n    /* Branch to exception vector */\n    regs->pc32 = exception_handler(VECTOR32_UND);\n}",
        "func": "static void inject_undef32_exception(struct cpu_user_regs *regs)\n{\n    uint32_t spsr = regs->cpsr;\n    int is_thumb = (regs->cpsr & PSR_THUMB);\n    /* Saved PC points to the instruction past the faulting instruction. */\n    uint32_t return_offset = is_thumb ? 2 : 4;\n\n    BUG_ON( !is_32bit_domain(current->domain) );\n\n    /* Update processor mode */\n    cpsr_switch_mode(regs, PSR_MODE_UND);\n\n    /* Update banked registers */\n    regs->spsr_und = spsr;\n    regs->lr_und = regs->pc32 + return_offset;\n\n    /* Branch to exception vector */\n    regs->pc32 = exception_handler32(VECTOR32_UND);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,5 +15,5 @@\n     regs->lr_und = regs->pc32 + return_offset;\n \n     /* Branch to exception vector */\n-    regs->pc32 = exception_handler(VECTOR32_UND);\n+    regs->pc32 = exception_handler32(VECTOR32_UND);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    regs->pc32 = exception_handler(VECTOR32_UND);"
            ],
            "added_lines": [
                "    regs->pc32 = exception_handler32(VECTOR32_UND);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/do_cp14_dbg",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void do_cp14_dbg(struct cpu_user_regs *regs, union hsr hsr)\n{\n#ifndef NDEBUG\n    struct hsr_cp64 cp64 = hsr.cp64;\n#endif\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n#ifndef NDEBUG\n    gdprintk(XENLOG_ERR,\n             \"%s p14, %d, r%d, r%d, cr%d @ 0x%\"PRIregister\"\\n\",\n             cp64.read ? \"mrrc\" : \"mcrr\",\n             cp64.op1, cp64.reg1, cp64.reg2, cp64.crm, regs->pc);\n    gdprintk(XENLOG_ERR, \"unhandled 64-bit CP14 access %#x\\n\",\n             hsr.bits & HSR_CP64_REGS_MASK);\n#endif\n    inject_undef32_exception(regs);\n}",
        "func": "static void do_cp14_dbg(struct cpu_user_regs *regs, union hsr hsr)\n{\n#ifndef NDEBUG\n    struct hsr_cp64 cp64 = hsr.cp64;\n#endif\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n#ifndef NDEBUG\n    gdprintk(XENLOG_ERR,\n             \"%s p14, %d, r%d, r%d, cr%d @ 0x%\"PRIregister\"\\n\",\n             cp64.read ? \"mrrc\" : \"mcrr\",\n             cp64.op1, cp64.reg1, cp64.reg2, cp64.crm, regs->pc);\n    gdprintk(XENLOG_ERR, \"unhandled 64-bit CP14 access %#x\\n\",\n             hsr.bits & HSR_CP64_REGS_MASK);\n#endif\n    inject_undef_exception(regs, hsr.len);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,5 +18,5 @@\n     gdprintk(XENLOG_ERR, \"unhandled 64-bit CP14 access %#x\\n\",\n              hsr.bits & HSR_CP64_REGS_MASK);\n #endif\n-    inject_undef32_exception(regs);\n+    inject_undef_exception(regs, hsr.len);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    inject_undef32_exception(regs);"
            ],
            "added_lines": [
                "    inject_undef_exception(regs, hsr.len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-5147",
        "func_name": "xen-project/xen/do_cp14_32",
        "description": "Xen 4.4.x, when running a 64-bit kernel on an ARM system, does not properly handle traps from the guest domain that use a different address width, which allows local guest users to cause a denial of service (host crash) via a crafted 32-bit process.",
        "git_url": "https://github.com/xen-project/xen/commit/a98669781769e821413dfef4ef99b93171375610",
        "commit_title": "xen: arm: Correctly handle exception injection from userspace on 64-bit.",
        "commit_text": " Firstly we must be prepared to propagate traps from 32-bit userspace even for 64-bit guests, so wrap the existing inject_undef??_exception into inject_undef_exception and use that when injecting an undef exception. The various other exception cases (aborts etc) already do this.  Secondly when injecting the trap we must pick the correct exception vector depending on whether the source of the trap was 32-bit EL0, 64-bit EL0 or EL1.  This is part of CVE-2014-5147 / XSA-102. ",
        "func_before": "static void do_cp14_32(struct cpu_user_regs *regs, union hsr hsr)\n{\n    struct hsr_cp32 cp32 = hsr.cp32;\n    uint32_t *r = (uint32_t *)select_user_reg(regs, cp32.reg);\n    struct domain *d = current->domain;\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n    switch ( hsr.bits & HSR_CP32_REGS_MASK )\n    {\n    case HSR_CPREG32(DBGDIDR):\n\n        /* Read-only register */\n        if ( !cp32.read )\n            goto bad_cp;\n\n        /* Implement the minimum requirements:\n         *  - Number of watchpoints: 1\n         *  - Number of breakpoints: 2\n         *  - Version: ARMv7 v7.1\n         *  - Variant and Revision bits match MDIR\n         */\n        *r = (1 << 24) | (5 << 16);\n        *r |= ((d->arch.vpidr >> 20) & 0xf) | (d->arch.vpidr & 0xf);\n        break;\n\n    case HSR_CPREG32(DBGDSCRINT):\n    case HSR_CPREG32(DBGDSCREXT):\n        /* Implement debug status and control register as RAZ/WI.\n         * The OS won't use Hardware debug if MDBGen not set\n         */\n        if ( cp32.read )\n           *r = 0;\n        break;\n    case HSR_CPREG32(DBGVCR):\n    case HSR_CPREG32(DBGOSLAR):\n    case HSR_CPREG32(DBGBVR0):\n    case HSR_CPREG32(DBGBCR0):\n    case HSR_CPREG32(DBGWVR0):\n    case HSR_CPREG32(DBGWCR0):\n    case HSR_CPREG32(DBGBVR1):\n    case HSR_CPREG32(DBGBCR1):\n    case HSR_CPREG32(DBGOSDLR):\n        /* RAZ/WI */\n        if ( cp32.read )\n            *r = 0;\n        break;\n\n    default:\nbad_cp:\n#ifndef NDEBUG\n        gdprintk(XENLOG_ERR,\n                 \"%s p14, %d, r%d, cr%d, cr%d, %d @ 0x%\"PRIregister\"\\n\",\n                  cp32.read ? \"mrc\" : \"mcr\",\n                  cp32.op1, cp32.reg, cp32.crn, cp32.crm, cp32.op2, regs->pc);\n        gdprintk(XENLOG_ERR, \"unhandled 32-bit cp14 access %#x\\n\",\n                 hsr.bits & HSR_CP32_REGS_MASK);\n#endif\n        inject_undef32_exception(regs);\n        return;\n    }\n\n    advance_pc(regs, hsr);\n}",
        "func": "static void do_cp14_32(struct cpu_user_regs *regs, union hsr hsr)\n{\n    struct hsr_cp32 cp32 = hsr.cp32;\n    uint32_t *r = (uint32_t *)select_user_reg(regs, cp32.reg);\n    struct domain *d = current->domain;\n\n    if ( !check_conditional_instr(regs, hsr) )\n    {\n        advance_pc(regs, hsr);\n        return;\n    }\n\n    switch ( hsr.bits & HSR_CP32_REGS_MASK )\n    {\n    case HSR_CPREG32(DBGDIDR):\n\n        /* Read-only register */\n        if ( !cp32.read )\n            goto bad_cp;\n\n        /* Implement the minimum requirements:\n         *  - Number of watchpoints: 1\n         *  - Number of breakpoints: 2\n         *  - Version: ARMv7 v7.1\n         *  - Variant and Revision bits match MDIR\n         */\n        *r = (1 << 24) | (5 << 16);\n        *r |= ((d->arch.vpidr >> 20) & 0xf) | (d->arch.vpidr & 0xf);\n        break;\n\n    case HSR_CPREG32(DBGDSCRINT):\n    case HSR_CPREG32(DBGDSCREXT):\n        /* Implement debug status and control register as RAZ/WI.\n         * The OS won't use Hardware debug if MDBGen not set\n         */\n        if ( cp32.read )\n           *r = 0;\n        break;\n    case HSR_CPREG32(DBGVCR):\n    case HSR_CPREG32(DBGOSLAR):\n    case HSR_CPREG32(DBGBVR0):\n    case HSR_CPREG32(DBGBCR0):\n    case HSR_CPREG32(DBGWVR0):\n    case HSR_CPREG32(DBGWCR0):\n    case HSR_CPREG32(DBGBVR1):\n    case HSR_CPREG32(DBGBCR1):\n    case HSR_CPREG32(DBGOSDLR):\n        /* RAZ/WI */\n        if ( cp32.read )\n            *r = 0;\n        break;\n\n    default:\nbad_cp:\n#ifndef NDEBUG\n        gdprintk(XENLOG_ERR,\n                 \"%s p14, %d, r%d, cr%d, cr%d, %d @ 0x%\"PRIregister\"\\n\",\n                  cp32.read ? \"mrc\" : \"mcr\",\n                  cp32.op1, cp32.reg, cp32.crn, cp32.crm, cp32.op2, regs->pc);\n        gdprintk(XENLOG_ERR, \"unhandled 32-bit cp14 access %#x\\n\",\n                 hsr.bits & HSR_CP32_REGS_MASK);\n#endif\n        inject_undef_exception(regs, hsr.len);\n        return;\n    }\n\n    advance_pc(regs, hsr);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -60,7 +60,7 @@\n         gdprintk(XENLOG_ERR, \"unhandled 32-bit cp14 access %#x\\n\",\n                  hsr.bits & HSR_CP32_REGS_MASK);\n #endif\n-        inject_undef32_exception(regs);\n+        inject_undef_exception(regs, hsr.len);\n         return;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        inject_undef32_exception(regs);"
            ],
            "added_lines": [
                "        inject_undef_exception(regs, hsr.len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6041",
        "func_name": "android/DOMWindow::open",
        "description": "The Android WebView in Android before 4.4 allows remote attackers to bypass the Same Origin Policy via a crafted attribute containing a \\u0000 character, as demonstrated by an onclick=\"window.open('\\u0000javascript: sequence to the Android Browser application 4.2.1 or a third-party web browser.",
        "git_url": "https://android.googlesource.com/platform/external/webkit/+/7e4405a7a12750ee27325f065b9825c25b40598c",
        "commit_title": "Cherry pick r91611 Perform the JavaScript navigation check on a complete URL",
        "commit_text": " Bug: 17050386  ",
        "func_before": "PassRefPtr<DOMWindow> DOMWindow::open(const String& urlString, const AtomicString& frameName, const String& windowFeaturesString,\n    DOMWindow* activeWindow, DOMWindow* firstWindow)\n{\n    if (!m_frame)\n        return 0;\n    Frame* activeFrame = activeWindow->frame();\n    if (!activeFrame)\n        return 0;\n    Frame* firstFrame = firstWindow->frame();\n    if (!firstFrame)\n        return 0;\n\n    if (!firstWindow->allowPopUp()) {\n        // Because FrameTree::find() returns true for empty strings, we must check for empty frame names.\n        // Otherwise, illegitimate window.open() calls with no name will pass right through the popup blocker.\n        if (frameName.isEmpty() || !m_frame->tree()->find(frameName))\n            return 0;\n    }\n\n    // Get the target frame for the special cases of _top and _parent.\n    // In those cases, we schedule a location change right now and return early.\n    Frame* targetFrame = 0;\n    if (frameName == \"_top\")\n        targetFrame = m_frame->tree()->top();\n    else if (frameName == \"_parent\") {\n        if (Frame* parent = m_frame->tree()->parent())\n            targetFrame = parent;\n        else\n            targetFrame = m_frame;\n    }\n    if (targetFrame) {\n        if (!activeFrame->loader()->shouldAllowNavigation(targetFrame))\n            return 0;\n\n        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))\n            return targetFrame->domWindow();\n\n        if (urlString.isEmpty())\n            return targetFrame->domWindow();\n\n        // For whatever reason, Firefox uses the first window rather than the active window to\n        // determine the outgoing referrer. We replicate that behavior here.\n        targetFrame->navigationScheduler()->scheduleLocationChange(activeFrame->document()->securityOrigin(),\n            firstFrame->document()->completeURL(urlString).string(),\n            firstFrame->loader()->outgoingReferrer(),\n            !activeFrame->script()->anyPageIsProcessingUserGesture(), false);\n\n        return targetFrame->domWindow();\n    }\n\n    WindowFeatures windowFeatures(windowFeaturesString);\n    FloatRect windowRect(windowFeatures.xSet ? windowFeatures.x : 0, windowFeatures.ySet ? windowFeatures.y : 0,\n        windowFeatures.widthSet ? windowFeatures.width : 0, windowFeatures.heightSet ? windowFeatures.height : 0);\n    Page* page = m_frame->page();\n    DOMWindow::adjustWindowRect(screenAvailableRect(page ? page->mainFrame()->view() : 0), windowRect, windowRect);\n    windowFeatures.x = windowRect.x();\n    windowFeatures.y = windowRect.y();\n    windowFeatures.height = windowRect.height();\n    windowFeatures.width = windowRect.width();\n\n    Frame* result = createWindow(urlString, frameName, windowFeatures, activeWindow, firstFrame, m_frame);\n    return result ? result->domWindow() : 0;\n}",
        "func": "PassRefPtr<DOMWindow> DOMWindow::open(const String& urlString, const AtomicString& frameName, const String& windowFeaturesString,\n    DOMWindow* activeWindow, DOMWindow* firstWindow)\n{\n    if (!m_frame)\n        return 0;\n    Frame* activeFrame = activeWindow->frame();\n    if (!activeFrame)\n        return 0;\n    Frame* firstFrame = firstWindow->frame();\n    if (!firstFrame)\n        return 0;\n\n    if (!firstWindow->allowPopUp()) {\n        // Because FrameTree::find() returns true for empty strings, we must check for empty frame names.\n        // Otherwise, illegitimate window.open() calls with no name will pass right through the popup blocker.\n        if (frameName.isEmpty() || !m_frame->tree()->find(frameName))\n            return 0;\n    }\n\n    // Get the target frame for the special cases of _top and _parent.\n    // In those cases, we schedule a location change right now and return early.\n    Frame* targetFrame = 0;\n    if (frameName == \"_top\")\n        targetFrame = m_frame->tree()->top();\n    else if (frameName == \"_parent\") {\n        if (Frame* parent = m_frame->tree()->parent())\n            targetFrame = parent;\n        else\n            targetFrame = m_frame;\n    }\n    if (targetFrame) {\n        if (!activeFrame->loader()->shouldAllowNavigation(targetFrame))\n            return 0;\n\n        KURL completedURL = firstFrame->document()->completeURL(urlString);\n\n        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, completedURL))\n            return targetFrame->domWindow();\n\n        if (urlString.isEmpty())\n            return targetFrame->domWindow();\n\n        // For whatever reason, Firefox uses the first window rather than the active window to\n        // determine the outgoing referrer. We replicate that behavior here.\n        targetFrame->navigationScheduler()->scheduleLocationChange(activeFrame->document()->securityOrigin(),\n            completedURL,\n            firstFrame->loader()->outgoingReferrer(),\n            !activeFrame->script()->anyPageIsProcessingUserGesture(), false);\n\n        return targetFrame->domWindow();\n    }\n\n    WindowFeatures windowFeatures(windowFeaturesString);\n    FloatRect windowRect(windowFeatures.xSet ? windowFeatures.x : 0, windowFeatures.ySet ? windowFeatures.y : 0,\n        windowFeatures.widthSet ? windowFeatures.width : 0, windowFeatures.heightSet ? windowFeatures.height : 0);\n    Page* page = m_frame->page();\n    DOMWindow::adjustWindowRect(screenAvailableRect(page ? page->mainFrame()->view() : 0), windowRect, windowRect);\n    windowFeatures.x = windowRect.x();\n    windowFeatures.y = windowRect.y();\n    windowFeatures.height = windowRect.height();\n    windowFeatures.width = windowRect.width();\n\n    Frame* result = createWindow(urlString, frameName, windowFeatures, activeWindow, firstFrame, m_frame);\n    return result ? result->domWindow() : 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,7 +32,9 @@\n         if (!activeFrame->loader()->shouldAllowNavigation(targetFrame))\n             return 0;\n \n-        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))\n+        KURL completedURL = firstFrame->document()->completeURL(urlString);\n+\n+        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, completedURL))\n             return targetFrame->domWindow();\n \n         if (urlString.isEmpty())\n@@ -41,7 +43,7 @@\n         // For whatever reason, Firefox uses the first window rather than the active window to\n         // determine the outgoing referrer. We replicate that behavior here.\n         targetFrame->navigationScheduler()->scheduleLocationChange(activeFrame->document()->securityOrigin(),\n-            firstFrame->document()->completeURL(urlString).string(),\n+            completedURL,\n             firstFrame->loader()->outgoingReferrer(),\n             !activeFrame->script()->anyPageIsProcessingUserGesture(), false);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))",
                "            firstFrame->document()->completeURL(urlString).string(),"
            ],
            "added_lines": [
                "        KURL completedURL = firstFrame->document()->completeURL(urlString);",
                "",
                "        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, completedURL))",
                "            completedURL,"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6041",
        "func_name": "android/DOMWindow::setLocation",
        "description": "The Android WebView in Android before 4.4 allows remote attackers to bypass the Same Origin Policy via a crafted attribute containing a \\u0000 character, as demonstrated by an onclick=\"window.open('\\u0000javascript: sequence to the Android Browser application 4.2.1 or a third-party web browser.",
        "git_url": "https://android.googlesource.com/platform/external/webkit/+/7e4405a7a12750ee27325f065b9825c25b40598c",
        "commit_title": "Cherry pick r91611 Perform the JavaScript navigation check on a complete URL",
        "commit_text": " Bug: 17050386  ",
        "func_before": "void DOMWindow::setLocation(const String& urlString, DOMWindow* activeWindow, DOMWindow* firstWindow, SetLocationLocking locking)\n{\n    if (!m_frame)\n        return;\n\n    Frame* activeFrame = activeWindow->frame();\n    if (!activeFrame)\n        return;\n\n    if (!activeFrame->loader()->shouldAllowNavigation(m_frame))\n        return;\n\n    Frame* firstFrame = firstWindow->frame();\n    if (!firstFrame)\n        return;\n\n    KURL completedURL = firstFrame->document()->completeURL(urlString);\n    if (completedURL.isNull())\n        return;\n\n    if (isInsecureScriptAccess(activeWindow, urlString))\n        return;\n\n    // We want a new history item if we are processing a user gesture.\n    m_frame->navigationScheduler()->scheduleLocationChange(activeFrame->document()->securityOrigin(),\n        completedURL, activeFrame->loader()->outgoingReferrer(),\n        locking != LockHistoryBasedOnGestureState || !activeFrame->script()->anyPageIsProcessingUserGesture(),\n        locking != LockHistoryBasedOnGestureState);\n}",
        "func": "void DOMWindow::setLocation(const String& urlString, DOMWindow* activeWindow, DOMWindow* firstWindow, SetLocationLocking locking)\n{\n    if (!m_frame)\n        return;\n\n    Frame* activeFrame = activeWindow->frame();\n    if (!activeFrame)\n        return;\n\n    if (!activeFrame->loader()->shouldAllowNavigation(m_frame))\n        return;\n\n    Frame* firstFrame = firstWindow->frame();\n    if (!firstFrame)\n        return;\n\n    KURL completedURL = firstFrame->document()->completeURL(urlString);\n    if (completedURL.isNull())\n        return;\n\n    if (isInsecureScriptAccess(activeWindow, completedURL))\n        return;\n\n    // We want a new history item if we are processing a user gesture.\n    m_frame->navigationScheduler()->scheduleLocationChange(activeFrame->document()->securityOrigin(),\n        completedURL, activeFrame->loader()->outgoingReferrer(),\n        locking != LockHistoryBasedOnGestureState || !activeFrame->script()->anyPageIsProcessingUserGesture(),\n        locking != LockHistoryBasedOnGestureState);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,7 @@\n     if (completedURL.isNull())\n         return;\n \n-    if (isInsecureScriptAccess(activeWindow, urlString))\n+    if (isInsecureScriptAccess(activeWindow, completedURL))\n         return;\n \n     // We want a new history item if we are processing a user gesture.",
        "diff_line_info": {
            "deleted_lines": [
                "    if (isInsecureScriptAccess(activeWindow, urlString))"
            ],
            "added_lines": [
                "    if (isInsecureScriptAccess(activeWindow, completedURL))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6041",
        "func_name": "android/DOMWindow::createWindow",
        "description": "The Android WebView in Android before 4.4 allows remote attackers to bypass the Same Origin Policy via a crafted attribute containing a \\u0000 character, as demonstrated by an onclick=\"window.open('\\u0000javascript: sequence to the Android Browser application 4.2.1 or a third-party web browser.",
        "git_url": "https://android.googlesource.com/platform/external/webkit/+/7e4405a7a12750ee27325f065b9825c25b40598c",
        "commit_title": "Cherry pick r91611 Perform the JavaScript navigation check on a complete URL",
        "commit_text": " Bug: 17050386  ",
        "func_before": "Frame* DOMWindow::createWindow(const String& urlString, const AtomicString& frameName, const WindowFeatures& windowFeatures,\n    DOMWindow* activeWindow, Frame* firstFrame, Frame* openerFrame, PrepareDialogFunction function, void* functionContext)\n{\n    Frame* activeFrame = activeWindow->frame();\n\n    // For whatever reason, Firefox uses the first frame to determine the outgoingReferrer. We replicate that behavior here.\n    String referrer = firstFrame->loader()->outgoingReferrer();\n\n    KURL completedURL = urlString.isEmpty() ? KURL(ParsedURLString, \"\") : firstFrame->document()->completeURL(urlString);\n    ResourceRequest request(completedURL, referrer);\n    FrameLoader::addHTTPOriginIfNeeded(request, firstFrame->loader()->outgoingOrigin());\n    FrameLoadRequest frameRequest(activeWindow->securityOrigin(), request, frameName);\n\n    // We pass the opener frame for the lookupFrame in case the active frame is different from\n    // the opener frame, and the name references a frame relative to the opener frame.\n    bool created;\n    Frame* newFrame = WebCore::createWindow(activeFrame, openerFrame, frameRequest, windowFeatures, created);\n    if (!newFrame)\n        return 0;\n\n    newFrame->loader()->setOpener(openerFrame);\n    newFrame->page()->setOpenedByDOM();\n\n    if (newFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))\n        return newFrame;\n\n    if (function)\n        function(newFrame->domWindow(), functionContext);\n\n    if (created)\n        newFrame->loader()->changeLocation(activeWindow->securityOrigin(), completedURL, referrer, false, false);\n    else if (!urlString.isEmpty()) {\n        newFrame->navigationScheduler()->scheduleLocationChange(activeWindow->securityOrigin(), completedURL.string(), referrer,\n            !activeFrame->script()->anyPageIsProcessingUserGesture(), false);\n    }\n\n    return newFrame;\n}",
        "func": "Frame* DOMWindow::createWindow(const String& urlString, const AtomicString& frameName, const WindowFeatures& windowFeatures,\n    DOMWindow* activeWindow, Frame* firstFrame, Frame* openerFrame, PrepareDialogFunction function, void* functionContext)\n{\n    Frame* activeFrame = activeWindow->frame();\n\n    // For whatever reason, Firefox uses the first frame to determine the outgoingReferrer. We replicate that behavior here.\n    String referrer = firstFrame->loader()->outgoingReferrer();\n\n    KURL completedURL = urlString.isEmpty() ? KURL(ParsedURLString, \"\") : firstFrame->document()->completeURL(urlString);\n    ResourceRequest request(completedURL, referrer);\n    FrameLoader::addHTTPOriginIfNeeded(request, firstFrame->loader()->outgoingOrigin());\n    FrameLoadRequest frameRequest(activeWindow->securityOrigin(), request, frameName);\n\n    // We pass the opener frame for the lookupFrame in case the active frame is different from\n    // the opener frame, and the name references a frame relative to the opener frame.\n    bool created;\n    Frame* newFrame = WebCore::createWindow(activeFrame, openerFrame, frameRequest, windowFeatures, created);\n    if (!newFrame)\n        return 0;\n\n    newFrame->loader()->setOpener(openerFrame);\n    newFrame->page()->setOpenedByDOM();\n\n    if (newFrame->domWindow()->isInsecureScriptAccess(activeWindow, completedURL))\n        return newFrame;\n\n    if (function)\n        function(newFrame->domWindow(), functionContext);\n\n    if (created)\n        newFrame->loader()->changeLocation(activeWindow->securityOrigin(), completedURL, referrer, false, false);\n    else if (!urlString.isEmpty()) {\n        newFrame->navigationScheduler()->scheduleLocationChange(activeWindow->securityOrigin(), completedURL.string(), referrer,\n            !activeFrame->script()->anyPageIsProcessingUserGesture(), false);\n    }\n\n    return newFrame;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,7 +21,7 @@\n     newFrame->loader()->setOpener(openerFrame);\n     newFrame->page()->setOpenedByDOM();\n \n-    if (newFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))\n+    if (newFrame->domWindow()->isInsecureScriptAccess(activeWindow, completedURL))\n         return newFrame;\n \n     if (function)",
        "diff_line_info": {
            "deleted_lines": [
                "    if (newFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))"
            ],
            "added_lines": [
                "    if (newFrame->domWindow()->isInsecureScriptAccess(activeWindow, completedURL))"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-6041",
        "func_name": "android/DOMWindow::open",
        "description": "The Android WebView in Android before 4.4 allows remote attackers to bypass the Same Origin Policy via a crafted attribute containing a \\u0000 character, as demonstrated by an onclick=\"window.open('\\u0000javascript: sequence to the Android Browser application 4.2.1 or a third-party web browser.",
        "git_url": "https://android.googlesource.com/platform/external/webkit/+/1368e05e8875f00e8d2529fe6050d08b55ea4d87",
        "commit_title": "Cherry pick r91152 DOMWindow::open performs a security check on a wrong window DO NOT MERGE",
        "commit_text": " Bug: 17050386 ",
        "func_before": "PassRefPtr<DOMWindow> DOMWindow::open(const String& urlString, const AtomicString& frameName, const String& windowFeaturesString,\n    DOMWindow* activeWindow, DOMWindow* firstWindow)\n{\n    if (!m_frame)\n        return 0;\n    Frame* activeFrame = activeWindow->frame();\n    if (!activeFrame)\n        return 0;\n    Frame* firstFrame = firstWindow->frame();\n    if (!firstFrame)\n        return 0;\n\n    if (!firstWindow->allowPopUp()) {\n        // Because FrameTree::find() returns true for empty strings, we must check for empty frame names.\n        // Otherwise, illegitimate window.open() calls with no name will pass right through the popup blocker.\n        if (frameName.isEmpty() || !m_frame->tree()->find(frameName))\n            return 0;\n    }\n\n    // Get the target frame for the special cases of _top and _parent.\n    // In those cases, we schedule a location change right now and return early.\n    Frame* targetFrame = 0;\n    if (frameName == \"_top\")\n        targetFrame = m_frame->tree()->top();\n    else if (frameName == \"_parent\") {\n        if (Frame* parent = m_frame->tree()->parent())\n            targetFrame = parent;\n        else\n            targetFrame = m_frame;\n    }\n    if (targetFrame) {\n        if (!activeFrame->loader()->shouldAllowNavigation(targetFrame))\n            return 0;\n\n        if (isInsecureScriptAccess(activeWindow, urlString))\n            return targetFrame->domWindow();\n\n        if (urlString.isEmpty())\n            return targetFrame->domWindow();\n\n        // For whatever reason, Firefox uses the first window rather than the active window to\n        // determine the outgoing referrer. We replicate that behavior here.\n        targetFrame->navigationScheduler()->scheduleLocationChange(activeFrame->document()->securityOrigin(),\n            firstFrame->document()->completeURL(urlString).string(),\n            firstFrame->loader()->outgoingReferrer(),\n            !activeFrame->script()->anyPageIsProcessingUserGesture(), false);\n\n        return targetFrame->domWindow();\n    }\n\n    WindowFeatures windowFeatures(windowFeaturesString);\n    FloatRect windowRect(windowFeatures.xSet ? windowFeatures.x : 0, windowFeatures.ySet ? windowFeatures.y : 0,\n        windowFeatures.widthSet ? windowFeatures.width : 0, windowFeatures.heightSet ? windowFeatures.height : 0);\n    Page* page = m_frame->page();\n    DOMWindow::adjustWindowRect(screenAvailableRect(page ? page->mainFrame()->view() : 0), windowRect, windowRect);\n    windowFeatures.x = windowRect.x();\n    windowFeatures.y = windowRect.y();\n    windowFeatures.height = windowRect.height();\n    windowFeatures.width = windowRect.width();\n\n    Frame* result = createWindow(urlString, frameName, windowFeatures, activeWindow, firstFrame, m_frame);\n    return result ? result->domWindow() : 0;\n}",
        "func": "PassRefPtr<DOMWindow> DOMWindow::open(const String& urlString, const AtomicString& frameName, const String& windowFeaturesString,\n    DOMWindow* activeWindow, DOMWindow* firstWindow)\n{\n    if (!m_frame)\n        return 0;\n    Frame* activeFrame = activeWindow->frame();\n    if (!activeFrame)\n        return 0;\n    Frame* firstFrame = firstWindow->frame();\n    if (!firstFrame)\n        return 0;\n\n    if (!firstWindow->allowPopUp()) {\n        // Because FrameTree::find() returns true for empty strings, we must check for empty frame names.\n        // Otherwise, illegitimate window.open() calls with no name will pass right through the popup blocker.\n        if (frameName.isEmpty() || !m_frame->tree()->find(frameName))\n            return 0;\n    }\n\n    // Get the target frame for the special cases of _top and _parent.\n    // In those cases, we schedule a location change right now and return early.\n    Frame* targetFrame = 0;\n    if (frameName == \"_top\")\n        targetFrame = m_frame->tree()->top();\n    else if (frameName == \"_parent\") {\n        if (Frame* parent = m_frame->tree()->parent())\n            targetFrame = parent;\n        else\n            targetFrame = m_frame;\n    }\n    if (targetFrame) {\n        if (!activeFrame->loader()->shouldAllowNavigation(targetFrame))\n            return 0;\n\n        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))\n            return targetFrame->domWindow();\n\n        if (urlString.isEmpty())\n            return targetFrame->domWindow();\n\n        // For whatever reason, Firefox uses the first window rather than the active window to\n        // determine the outgoing referrer. We replicate that behavior here.\n        targetFrame->navigationScheduler()->scheduleLocationChange(activeFrame->document()->securityOrigin(),\n            firstFrame->document()->completeURL(urlString).string(),\n            firstFrame->loader()->outgoingReferrer(),\n            !activeFrame->script()->anyPageIsProcessingUserGesture(), false);\n\n        return targetFrame->domWindow();\n    }\n\n    WindowFeatures windowFeatures(windowFeaturesString);\n    FloatRect windowRect(windowFeatures.xSet ? windowFeatures.x : 0, windowFeatures.ySet ? windowFeatures.y : 0,\n        windowFeatures.widthSet ? windowFeatures.width : 0, windowFeatures.heightSet ? windowFeatures.height : 0);\n    Page* page = m_frame->page();\n    DOMWindow::adjustWindowRect(screenAvailableRect(page ? page->mainFrame()->view() : 0), windowRect, windowRect);\n    windowFeatures.x = windowRect.x();\n    windowFeatures.y = windowRect.y();\n    windowFeatures.height = windowRect.height();\n    windowFeatures.width = windowRect.width();\n\n    Frame* result = createWindow(urlString, frameName, windowFeatures, activeWindow, firstFrame, m_frame);\n    return result ? result->domWindow() : 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,7 +32,7 @@\n         if (!activeFrame->loader()->shouldAllowNavigation(targetFrame))\n             return 0;\n \n-        if (isInsecureScriptAccess(activeWindow, urlString))\n+        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))\n             return targetFrame->domWindow();\n \n         if (urlString.isEmpty())",
        "diff_line_info": {
            "deleted_lines": [
                "        if (isInsecureScriptAccess(activeWindow, urlString))"
            ],
            "added_lines": [
                "        if (targetFrame->domWindow()->isInsecureScriptAccess(activeWindow, urlString))"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-6657",
        "func_name": "torvalds/linux/sock_setsockopt",
        "description": "The sock_setsockopt function in net/core/sock.c in the Linux kernel before 3.5.7 does not ensure that a keepalive action is associated with a stream socket, which allows local users to cause a denial of service (system crash) by leveraging the ability to create a raw socket.",
        "git_url": "https://github.com/torvalds/linux/commit/3e10986d1d698140747fcfc2761ec9cb64c1d582",
        "commit_title": "net: guard tcp_set_keepalive() to tcp sockets",
        "commit_text": " Its possible to use RAW sockets to get a crash in tcp_set_keepalive() / sk_reset_timer()  Fix is to make sure socket is a SOCK_STREAM one. ",
        "func_before": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_bindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) || capable(CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RX_HARDWARE);\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SYS_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RAW_HARDWARE);\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\t\t/* We implement the SO_SNDLOWAT etc to\n\t\t   not be settable (1003.1g 5.3) */\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tsock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
        "func": "int sock_setsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, unsigned int optlen)\n{\n\tstruct sock *sk = sock->sk;\n\tint val;\n\tint valbool;\n\tstruct linger ling;\n\tint ret = 0;\n\n\t/*\n\t *\tOptions without arguments\n\t */\n\n\tif (optname == SO_BINDTODEVICE)\n\t\treturn sock_bindtodevice(sk, optval, optlen);\n\n\tif (optlen < sizeof(int))\n\t\treturn -EINVAL;\n\n\tif (get_user(val, (int __user *)optval))\n\t\treturn -EFAULT;\n\n\tvalbool = val ? 1 : 0;\n\n\tlock_sock(sk);\n\n\tswitch (optname) {\n\tcase SO_DEBUG:\n\t\tif (val && !capable(CAP_NET_ADMIN))\n\t\t\tret = -EACCES;\n\t\telse\n\t\t\tsock_valbool_flag(sk, SOCK_DBG, valbool);\n\t\tbreak;\n\tcase SO_REUSEADDR:\n\t\tsk->sk_reuse = (valbool ? SK_CAN_REUSE : SK_NO_REUSE);\n\t\tbreak;\n\tcase SO_TYPE:\n\tcase SO_PROTOCOL:\n\tcase SO_DOMAIN:\n\tcase SO_ERROR:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\tcase SO_DONTROUTE:\n\t\tsock_valbool_flag(sk, SOCK_LOCALROUTE, valbool);\n\t\tbreak;\n\tcase SO_BROADCAST:\n\t\tsock_valbool_flag(sk, SOCK_BROADCAST, valbool);\n\t\tbreak;\n\tcase SO_SNDBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_wmem_max);\nset_sndbuf:\n\t\tsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\n\t\tsk->sk_sndbuf = max_t(u32, val * 2, SOCK_MIN_SNDBUF);\n\t\t/* Wake up sending tasks if we upped the value. */\n\t\tsk->sk_write_space(sk);\n\t\tbreak;\n\n\tcase SO_SNDBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_sndbuf;\n\n\tcase SO_RCVBUF:\n\t\t/* Don't error on this BSD doesn't and if you think\n\t\t * about it this is right. Otherwise apps have to\n\t\t * play 'guess the biggest size' games. RCVBUF/SNDBUF\n\t\t * are treated in BSD as hints\n\t\t */\n\t\tval = min_t(u32, val, sysctl_rmem_max);\nset_rcvbuf:\n\t\tsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\n\t\t/*\n\t\t * We double it on the way in to account for\n\t\t * \"struct sk_buff\" etc. overhead.   Applications\n\t\t * assume that the SO_RCVBUF setting they make will\n\t\t * allow that much actual data to be received on that\n\t\t * socket.\n\t\t *\n\t\t * Applications are unaware that \"struct sk_buff\" and\n\t\t * other overheads allocate from the receive buffer\n\t\t * during socket buffer allocation.\n\t\t *\n\t\t * And after considering the possible alternatives,\n\t\t * returning the value we actually used in getsockopt\n\t\t * is the most desirable behavior.\n\t\t */\n\t\tsk->sk_rcvbuf = max_t(u32, val * 2, SOCK_MIN_RCVBUF);\n\t\tbreak;\n\n\tcase SO_RCVBUFFORCE:\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tret = -EPERM;\n\t\t\tbreak;\n\t\t}\n\t\tgoto set_rcvbuf;\n\n\tcase SO_KEEPALIVE:\n#ifdef CONFIG_INET\n\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n\t\t    sk->sk_type == SOCK_STREAM)\n\t\t\ttcp_set_keepalive(sk, valbool);\n#endif\n\t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tsock_valbool_flag(sk, SOCK_URGINLINE, valbool);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tsk->sk_no_check = valbool;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tif ((val >= 0 && val <= 6) || capable(CAP_NET_ADMIN))\n\t\t\tsk->sk_priority = val;\n\t\telse\n\t\t\tret = -EPERM;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tif (optlen < sizeof(ling)) {\n\t\t\tret = -EINVAL;\t/* 1003.1g */\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&ling, optval, sizeof(ling))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tif (!ling.l_onoff)\n\t\t\tsock_reset_flag(sk, SOCK_LINGER);\n\t\telse {\n#if (BITS_PER_LONG == 32)\n\t\t\tif ((unsigned int)ling.l_linger >= MAX_SCHEDULE_TIMEOUT/HZ)\n\t\t\t\tsk->sk_lingertime = MAX_SCHEDULE_TIMEOUT;\n\t\t\telse\n#endif\n\t\t\t\tsk->sk_lingertime = (unsigned int)ling.l_linger * HZ;\n\t\t\tsock_set_flag(sk, SOCK_LINGER);\n\t\t}\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"setsockopt\");\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSCRED, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSCRED, &sock->flags);\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\tcase SO_TIMESTAMPNS:\n\t\tif (valbool)  {\n\t\t\tif (optname == SO_TIMESTAMP)\n\t\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\telse\n\t\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t\tsock_set_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_enable_timestamp(sk, SOCK_TIMESTAMP);\n\t\t} else {\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMP);\n\t\t\tsock_reset_flag(sk, SOCK_RCVTSTAMPNS);\n\t\t}\n\t\tbreak;\n\n\tcase SO_TIMESTAMPING:\n\t\tif (val & ~SOF_TIMESTAMPING_MASK) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_TX_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_TX_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RX_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RX_HARDWARE);\n\t\tif (val & SOF_TIMESTAMPING_RX_SOFTWARE)\n\t\t\tsock_enable_timestamp(sk,\n\t\t\t\t\t      SOCK_TIMESTAMPING_RX_SOFTWARE);\n\t\telse\n\t\t\tsock_disable_timestamp(sk,\n\t\t\t\t\t       (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE));\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SOFTWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SOFTWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_SYS_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_SYS_HARDWARE);\n\t\tsock_valbool_flag(sk, SOCK_TIMESTAMPING_RAW_HARDWARE,\n\t\t\t\t  val & SOF_TIMESTAMPING_RAW_HARDWARE);\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tif (val < 0)\n\t\t\tval = INT_MAX;\n\t\tsk->sk_rcvlowat = val ? : 1;\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_rcvtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tret = sock_set_timeout(&sk->sk_sndtimeo, optval, optlen);\n\t\tbreak;\n\n\tcase SO_ATTACH_FILTER:\n\t\tret = -EINVAL;\n\t\tif (optlen == sizeof(struct sock_fprog)) {\n\t\t\tstruct sock_fprog fprog;\n\n\t\t\tret = -EFAULT;\n\t\t\tif (copy_from_user(&fprog, optval, sizeof(fprog)))\n\t\t\t\tbreak;\n\n\t\t\tret = sk_attach_filter(&fprog, sk);\n\t\t}\n\t\tbreak;\n\n\tcase SO_DETACH_FILTER:\n\t\tret = sk_detach_filter(sk);\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tif (valbool)\n\t\t\tset_bit(SOCK_PASSSEC, &sock->flags);\n\t\telse\n\t\t\tclear_bit(SOCK_PASSSEC, &sock->flags);\n\t\tbreak;\n\tcase SO_MARK:\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\tret = -EPERM;\n\t\telse\n\t\t\tsk->sk_mark = val;\n\t\tbreak;\n\n\t\t/* We implement the SO_SNDLOWAT etc to\n\t\t   not be settable (1003.1g 5.3) */\n\tcase SO_RXQ_OVFL:\n\t\tsock_valbool_flag(sk, SOCK_RXQ_OVFL, valbool);\n\t\tbreak;\n\n\tcase SO_WIFI_STATUS:\n\t\tsock_valbool_flag(sk, SOCK_WIFI_STATUS, valbool);\n\t\tbreak;\n\n\tcase SO_PEEK_OFF:\n\t\tif (sock->ops->set_peek_off)\n\t\t\tsock->ops->set_peek_off(sk, val);\n\t\telse\n\t\t\tret = -EOPNOTSUPP;\n\t\tbreak;\n\n\tcase SO_NOFCS:\n\t\tsock_valbool_flag(sk, SOCK_NOFCS, valbool);\n\t\tbreak;\n\n\tdefault:\n\t\tret = -ENOPROTOOPT;\n\t\tbreak;\n\t}\n\trelease_sock(sk);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -103,7 +103,8 @@\n \n \tcase SO_KEEPALIVE:\n #ifdef CONFIG_INET\n-\t\tif (sk->sk_protocol == IPPROTO_TCP)\n+\t\tif (sk->sk_protocol == IPPROTO_TCP &&\n+\t\t    sk->sk_type == SOCK_STREAM)\n \t\t\ttcp_set_keepalive(sk, valbool);\n #endif\n \t\tsock_valbool_flag(sk, SOCK_KEEPOPEN, valbool);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (sk->sk_protocol == IPPROTO_TCP)"
            ],
            "added_lines": [
                "\t\tif (sk->sk_protocol == IPPROTO_TCP &&",
                "\t\t    sk->sk_type == SOCK_STREAM)"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3189",
        "func_name": "chromium/Control::PaintMultipleRects",
        "description": "The chrome_pdf::CopyImage function in pdf/draw_utils.cc in the PDFium component in Google Chrome before 38.0.2125.101 does not properly validate image-data dimensions, which allows remote attackers to cause a denial of service (out-of-bounds read) or possibly have unspecified other impact via unknown vectors.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/d734d197bb5462a65c37b17594a8c8d07dd79bc1",
        "commit_title": "Avoid OOB memcpy in chrome_pdf::CopyImage.",
        "commit_text": " This is a re-work of palmer's patch at https://codereview.chromium.org/515023002/ which has more context, but comes down to stricter bounds checking.  We also correct an arithmetic bug when copying the image behind a control that is positioned before the origin of the image.    ",
        "func_before": "void Control::PaintMultipleRects(pp::ImageData* image_data,\n                                 const std::list<pp::Rect>& rects) {\n  DCHECK(rects.size() > 0);\n  if (rects.size() == 1) {\n    Paint(image_data, rects.front());\n    return;\n  }\n\n  // Some rects in the input list may overlap. To prevent double\n  // painting (causes problems with semi-transparent controls) we'll\n  // paint control into buffer image data only once and copy requested\n  // rectangles.\n  pp::ImageData buffer(owner()->GetInstance(), image_data->format(),\n                       rect().size(), false);\n  if (buffer.is_null())\n    return;\n\n  pp::Rect draw_rc = pp::Rect(image_data->size()).Intersect(rect());\n  pp::Rect ctrl_rc = pp::Rect(rect().point() - draw_rc.point(), draw_rc.size());\n  CopyImage(*image_data, draw_rc, &buffer, ctrl_rc, false);\n\n  // Temporary move control to origin (0,0) and draw it into temp buffer.\n  // Move to the original position afterward. Since this is going on temp\n  // buffer, we don't need to invalidate here.\n  pp::Rect temp = rect();\n  MoveTo(pp::Point(0, 0), false);\n  Paint(&buffer, ctrl_rc);\n  MoveTo(temp.point(), false);\n\n  std::list<pp::Rect>::const_iterator iter;\n  for (iter = rects.begin(); iter != rects.end(); ++iter) {\n    pp::Rect draw_rc = rect().Intersect(*iter);\n    if (!draw_rc.IsEmpty()) {\n      // Copy requested rect from the buffer image.\n      pp::Rect src_rc = draw_rc;\n      src_rc.Offset(-rect().x(), -rect().y());\n      CopyImage(buffer, src_rc, image_data, draw_rc, false);\n    }\n  }\n}",
        "func": "void Control::PaintMultipleRects(pp::ImageData* image_data,\n                                 const std::list<pp::Rect>& rects) {\n  DCHECK(rects.size() > 0);\n  if (rects.size() == 1) {\n    Paint(image_data, rects.front());\n    return;\n  }\n\n  // Some rects in the input list may overlap. To prevent double\n  // painting (causes problems with semi-transparent controls) we'll\n  // paint control into buffer image data only once and copy requested\n  // rectangles.\n  pp::ImageData buffer(owner()->GetInstance(), image_data->format(),\n                       rect().size(), false);\n  if (buffer.is_null())\n    return;\n\n  pp::Rect draw_rc = pp::Rect(image_data->size()).Intersect(rect());\n  pp::Rect ctrl_rc = pp::Rect(draw_rc.point() - rect().point(), draw_rc.size());\n  CopyImage(*image_data, draw_rc, &buffer, ctrl_rc, false);\n\n  // Temporary move control to origin (0,0) and draw it into temp buffer.\n  // Move to the original position afterward. Since this is going on temp\n  // buffer, we don't need to invalidate here.\n  pp::Rect temp = rect();\n  MoveTo(pp::Point(0, 0), false);\n  Paint(&buffer, ctrl_rc);\n  MoveTo(temp.point(), false);\n\n  std::list<pp::Rect>::const_iterator iter;\n  for (iter = rects.begin(); iter != rects.end(); ++iter) {\n    pp::Rect draw_rc = rect().Intersect(*iter);\n    if (!draw_rc.IsEmpty()) {\n      // Copy requested rect from the buffer image.\n      pp::Rect src_rc = draw_rc;\n      src_rc.Offset(-rect().x(), -rect().y());\n      CopyImage(buffer, src_rc, image_data, draw_rc, false);\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,7 @@\n     return;\n \n   pp::Rect draw_rc = pp::Rect(image_data->size()).Intersect(rect());\n-  pp::Rect ctrl_rc = pp::Rect(rect().point() - draw_rc.point(), draw_rc.size());\n+  pp::Rect ctrl_rc = pp::Rect(draw_rc.point() - rect().point(), draw_rc.size());\n   CopyImage(*image_data, draw_rc, &buffer, ctrl_rc, false);\n \n   // Temporary move control to origin (0,0) and draw it into temp buffer.",
        "diff_line_info": {
            "deleted_lines": [
                "  pp::Rect ctrl_rc = pp::Rect(rect().point() - draw_rc.point(), draw_rc.size());"
            ],
            "added_lines": [
                "  pp::Rect ctrl_rc = pp::Rect(draw_rc.point() - rect().point(), draw_rc.size());"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3189",
        "func_name": "chromium/CopyImage",
        "description": "The chrome_pdf::CopyImage function in pdf/draw_utils.cc in the PDFium component in Google Chrome before 38.0.2125.101 does not properly validate image-data dimensions, which allows remote attackers to cause a denial of service (out-of-bounds read) or possibly have unspecified other impact via unknown vectors.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/d734d197bb5462a65c37b17594a8c8d07dd79bc1",
        "commit_title": "Avoid OOB memcpy in chrome_pdf::CopyImage.",
        "commit_text": " This is a re-work of palmer's patch at https://codereview.chromium.org/515023002/ which has more context, but comes down to stricter bounds checking.  We also correct an arithmetic bug when copying the image behind a control that is positioned before the origin of the image.    ",
        "func_before": "void CopyImage(const pp::ImageData& src, const pp::Rect& src_rc,\n               pp::ImageData* dest, const pp::Rect& dest_rc,\n               bool stretch) {\n  DCHECK(src_rc.width() <= dest_rc.width() &&\n         src_rc.height() <= dest_rc.height());\n  if (src_rc.IsEmpty())\n    return;\n\n  const uint32_t* src_origin_pixel = src.GetAddr32(src_rc.point());\n  uint32_t* dest_origin_pixel = dest->GetAddr32(dest_rc.point());\n  if (stretch) {\n    double x_ratio = static_cast<double>(src_rc.width()) / dest_rc.width();\n    double y_ratio = static_cast<double>(src_rc.height()) / dest_rc.height();\n    int32_t height = dest_rc.height();\n    int32_t width = dest_rc.width();\n    for (int32_t y = 0; y < height; ++y) {\n      uint32_t* dest_pixel = dest_origin_pixel;\n      for (int32_t x = 0; x < width; ++x) {\n        uint32 src_x = static_cast<uint32>(x * x_ratio);\n        uint32 src_y = static_cast<uint32>(y * y_ratio);\n        const uint32_t* src_pixel = src.GetAddr32(\n            pp::Point(src_rc.x() + src_x, src_rc.y() + src_y));\n        *dest_pixel = *src_pixel;\n        dest_pixel++;\n      }\n      dest_origin_pixel = reinterpret_cast<uint32_t*>(\n          reinterpret_cast<char*>(dest_origin_pixel) + dest->stride());\n    }\n  } else {\n    int32_t height = src_rc.height();\n    base::CheckedNumeric<int32_t> width_bytes = src_rc.width();\n    width_bytes *= 4;\n    for (int32_t y = 0; y < height; ++y) {\n      memcpy(dest_origin_pixel, src_origin_pixel, width_bytes.ValueOrDie());\n      src_origin_pixel = reinterpret_cast<const uint32_t*>(\n          reinterpret_cast<const char*>(src_origin_pixel) + src.stride());\n      dest_origin_pixel = reinterpret_cast<uint32_t*>(\n          reinterpret_cast<char*>(dest_origin_pixel) + dest->stride());\n    }\n  }\n}",
        "func": "void CopyImage(const pp::ImageData& src, const pp::Rect& src_rc,\n               pp::ImageData* dest, const pp::Rect& dest_rc,\n               bool stretch) {\n  if (src_rc.IsEmpty() || !ImageDataContainsRect(src, src_rc))\n    return;\n\n  pp::Rect stretched_rc(dest_rc.point(),\n                        stretch ? dest_rc.size() : src_rc.size());\n  if (stretched_rc.IsEmpty() || !ImageDataContainsRect(*dest, stretched_rc))\n    return;\n\n  const uint32_t* src_origin_pixel = src.GetAddr32(src_rc.point());\n  uint32_t* dest_origin_pixel = dest->GetAddr32(dest_rc.point());\n  if (stretch) {\n    double x_ratio = static_cast<double>(src_rc.width()) / dest_rc.width();\n    double y_ratio = static_cast<double>(src_rc.height()) / dest_rc.height();\n    int32_t height = dest_rc.height();\n    int32_t width = dest_rc.width();\n    for (int32_t y = 0; y < height; ++y) {\n      uint32_t* dest_pixel = dest_origin_pixel;\n      for (int32_t x = 0; x < width; ++x) {\n        uint32 src_x = static_cast<uint32>(x * x_ratio);\n        uint32 src_y = static_cast<uint32>(y * y_ratio);\n        const uint32_t* src_pixel = src.GetAddr32(\n            pp::Point(src_rc.x() + src_x, src_rc.y() + src_y));\n        *dest_pixel = *src_pixel;\n        dest_pixel++;\n      }\n      dest_origin_pixel = reinterpret_cast<uint32_t*>(\n          reinterpret_cast<char*>(dest_origin_pixel) + dest->stride());\n    }\n  } else {\n    int32_t height = src_rc.height();\n    base::CheckedNumeric<int32_t> width_bytes = src_rc.width();\n    width_bytes *= 4;\n    for (int32_t y = 0; y < height; ++y) {\n      memcpy(dest_origin_pixel, src_origin_pixel, width_bytes.ValueOrDie());\n      src_origin_pixel = reinterpret_cast<const uint32_t*>(\n          reinterpret_cast<const char*>(src_origin_pixel) + src.stride());\n      dest_origin_pixel = reinterpret_cast<uint32_t*>(\n          reinterpret_cast<char*>(dest_origin_pixel) + dest->stride());\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,12 @@\n void CopyImage(const pp::ImageData& src, const pp::Rect& src_rc,\n                pp::ImageData* dest, const pp::Rect& dest_rc,\n                bool stretch) {\n-  DCHECK(src_rc.width() <= dest_rc.width() &&\n-         src_rc.height() <= dest_rc.height());\n-  if (src_rc.IsEmpty())\n+  if (src_rc.IsEmpty() || !ImageDataContainsRect(src, src_rc))\n+    return;\n+\n+  pp::Rect stretched_rc(dest_rc.point(),\n+                        stretch ? dest_rc.size() : src_rc.size());\n+  if (stretched_rc.IsEmpty() || !ImageDataContainsRect(*dest, stretched_rc))\n     return;\n \n   const uint32_t* src_origin_pixel = src.GetAddr32(src_rc.point());",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK(src_rc.width() <= dest_rc.width() &&",
                "         src_rc.height() <= dest_rc.height());",
                "  if (src_rc.IsEmpty())"
            ],
            "added_lines": [
                "  if (src_rc.IsEmpty() || !ImageDataContainsRect(src, src_rc))",
                "    return;",
                "",
                "  pp::Rect stretched_rc(dest_rc.point(),",
                "                        stretch ? dest_rc.size() : src_rc.size());",
                "  if (stretched_rc.IsEmpty() || !ImageDataContainsRect(*dest, stretched_rc))"
            ]
        }
    },
    {
        "cve_id": "CVE-2019-9637",
        "func_name": "php/php-src/php_plain_files_rename",
        "description": "An issue was discovered in PHP before 7.1.27, 7.2.x before 7.2.16, and 7.3.x before 7.3.3. Due to the way rename() across filesystems is implemented, it is possible that file being renamed is briefly available with wrong permissions while the rename is ongoing, thus enabling unauthorized users to access the data.",
        "git_url": "https://github.com/php/php-src/commit/e3133e4db70476fb7adfdedb738483e2255ce0e1",
        "commit_title": "Fix bug #77630 - safer rename() procedure",
        "commit_text": " In order to rename safer, we do the following: - set umask to 077 (unfortunately, not TS, so excluding ZTS) - chown() first, to set proper group before allowing group access - chmod() after, even if chown() fails",
        "func_before": "static int php_plain_files_rename(php_stream_wrapper *wrapper, const char *url_from, const char *url_to, int options, php_stream_context *context)\n{\n\tint ret;\n\n\tif (!url_from || !url_to) {\n\t\treturn 0;\n\t}\n\n#ifdef PHP_WIN32\n\tif (!php_win32_check_trailing_space(url_from, (int)strlen(url_from))) {\n\t\tphp_win32_docref2_from_error(ERROR_INVALID_NAME, url_from, url_to);\n\t\treturn 0;\n\t}\n\tif (!php_win32_check_trailing_space(url_to, (int)strlen(url_to))) {\n\t\tphp_win32_docref2_from_error(ERROR_INVALID_NAME, url_from, url_to);\n\t\treturn 0;\n\t}\n#endif\n\n\tif (strncasecmp(url_from, \"file://\", sizeof(\"file://\") - 1) == 0) {\n\t\turl_from += sizeof(\"file://\") - 1;\n\t}\n\n\tif (strncasecmp(url_to, \"file://\", sizeof(\"file://\") - 1) == 0) {\n\t\turl_to += sizeof(\"file://\") - 1;\n\t}\n\n\tif (php_check_open_basedir(url_from) || php_check_open_basedir(url_to)) {\n\t\treturn 0;\n\t}\n\n\tret = VCWD_RENAME(url_from, url_to);\n\n\tif (ret == -1) {\n#ifndef PHP_WIN32\n# ifdef EXDEV\n\t\tif (errno == EXDEV) {\n\t\t\tzend_stat_t sb;\n\t\t\tif (php_copy_file(url_from, url_to) == SUCCESS) {\n\t\t\t\tif (VCWD_STAT(url_from, &sb) == 0) {\n#  if !defined(TSRM_WIN32) && !defined(NETWARE)\n\t\t\t\t\tif (VCWD_CHMOD(url_to, sb.st_mode)) {\n\t\t\t\t\t\tif (errno == EPERM) {\n\t\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t\t\t\t\tVCWD_UNLINK(url_from);\n\t\t\t\t\t\t\treturn 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\tif (VCWD_CHOWN(url_to, sb.st_uid, sb.st_gid)) {\n\t\t\t\t\t\tif (errno == EPERM) {\n\t\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t\t\t\t\tVCWD_UNLINK(url_from);\n\t\t\t\t\t\t\treturn 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n#  endif\n\t\t\t\t\tVCWD_UNLINK(url_from);\n\t\t\t\t\treturn 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\treturn 0;\n\t\t}\n# endif\n#endif\n\n#ifdef PHP_WIN32\n\t\tphp_win32_docref2_from_error(GetLastError(), url_from, url_to);\n#else\n\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n#endif\n\t\treturn 0;\n\t}\n\n\t/* Clear stat cache (and realpath cache) */\n\tphp_clear_stat_cache(1, NULL, 0);\n\n\treturn 1;\n}",
        "func": "static int php_plain_files_rename(php_stream_wrapper *wrapper, const char *url_from, const char *url_to, int options, php_stream_context *context)\n{\n\tint ret;\n\n\tif (!url_from || !url_to) {\n\t\treturn 0;\n\t}\n\n#ifdef PHP_WIN32\n\tif (!php_win32_check_trailing_space(url_from, (int)strlen(url_from))) {\n\t\tphp_win32_docref2_from_error(ERROR_INVALID_NAME, url_from, url_to);\n\t\treturn 0;\n\t}\n\tif (!php_win32_check_trailing_space(url_to, (int)strlen(url_to))) {\n\t\tphp_win32_docref2_from_error(ERROR_INVALID_NAME, url_from, url_to);\n\t\treturn 0;\n\t}\n#endif\n\n\tif (strncasecmp(url_from, \"file://\", sizeof(\"file://\") - 1) == 0) {\n\t\turl_from += sizeof(\"file://\") - 1;\n\t}\n\n\tif (strncasecmp(url_to, \"file://\", sizeof(\"file://\") - 1) == 0) {\n\t\turl_to += sizeof(\"file://\") - 1;\n\t}\n\n\tif (php_check_open_basedir(url_from) || php_check_open_basedir(url_to)) {\n\t\treturn 0;\n\t}\n\n\tret = VCWD_RENAME(url_from, url_to);\n\n\tif (ret == -1) {\n#ifndef PHP_WIN32\n# ifdef EXDEV\n\t\tif (errno == EXDEV) {\n\t\t\tzend_stat_t sb;\n# if !defined(ZTS) && !defined(TSRM_WIN32) && !defined(NETWARE)\n\t\t\t/* not sure what to do in ZTS case, umask is not thread-safe */\n\t\t\tint oldmask = umask(077);\n# endif\n\t\t\tint success = 0;\n\t\t\tif (php_copy_file(url_from, url_to) == SUCCESS) {\n\t\t\t\tif (VCWD_STAT(url_from, &sb) == 0) {\n\t\t\t\t\tsuccess = 1;\n#  if !defined(TSRM_WIN32) && !defined(NETWARE)\n\t\t\t\t\t/*\n\t\t\t\t\t * Try to set user and permission info on the target.\n\t\t\t\t\t * If we're not root, then some of these may fail.\n\t\t\t\t\t * We try chown first, to set proper group info, relying\n\t\t\t\t\t * on the system environment to have proper umask to not allow\n\t\t\t\t\t * access to the file in the meantime.\n\t\t\t\t\t */\n\t\t\t\t\tif (VCWD_CHOWN(url_to, sb.st_uid, sb.st_gid)) {\n\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t\t\t\tif (errno != EPERM) {\n\t\t\t\t\t\t\tsuccess = 0;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif (success) {\n\t\t\t\t\t\tif (VCWD_CHMOD(url_to, sb.st_mode)) {\n\t\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t\t\t\t\tif (errno != EPERM) {\n\t\t\t\t\t\t\t\tsuccess = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n#  endif\n\t\t\t\t\tif (success) {\n\t\t\t\t\t\tVCWD_UNLINK(url_from);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n\t\t\t}\n#  if !defined(ZTS) && !defined(TSRM_WIN32) && !defined(NETWARE)\n\t\t\tumask(oldmask);\n#  endif\n\t\t\treturn success;\n\t\t}\n# endif\n#endif\n\n#ifdef PHP_WIN32\n\t\tphp_win32_docref2_from_error(GetLastError(), url_from, url_to);\n#else\n\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n#endif\n\t\treturn 0;\n\t}\n\n\t/* Clear stat cache (and realpath cache) */\n\tphp_clear_stat_cache(1, NULL, 0);\n\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,34 +36,51 @@\n # ifdef EXDEV\n \t\tif (errno == EXDEV) {\n \t\t\tzend_stat_t sb;\n+# if !defined(ZTS) && !defined(TSRM_WIN32) && !defined(NETWARE)\n+\t\t\t/* not sure what to do in ZTS case, umask is not thread-safe */\n+\t\t\tint oldmask = umask(077);\n+# endif\n+\t\t\tint success = 0;\n \t\t\tif (php_copy_file(url_from, url_to) == SUCCESS) {\n \t\t\t\tif (VCWD_STAT(url_from, &sb) == 0) {\n+\t\t\t\t\tsuccess = 1;\n #  if !defined(TSRM_WIN32) && !defined(NETWARE)\n-\t\t\t\t\tif (VCWD_CHMOD(url_to, sb.st_mode)) {\n-\t\t\t\t\t\tif (errno == EPERM) {\n+\t\t\t\t\t/*\n+\t\t\t\t\t * Try to set user and permission info on the target.\n+\t\t\t\t\t * If we're not root, then some of these may fail.\n+\t\t\t\t\t * We try chown first, to set proper group info, relying\n+\t\t\t\t\t * on the system environment to have proper umask to not allow\n+\t\t\t\t\t * access to the file in the meantime.\n+\t\t\t\t\t */\n+\t\t\t\t\tif (VCWD_CHOWN(url_to, sb.st_uid, sb.st_gid)) {\n+\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n+\t\t\t\t\t\tif (errno != EPERM) {\n+\t\t\t\t\t\t\tsuccess = 0;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tif (success) {\n+\t\t\t\t\t\tif (VCWD_CHMOD(url_to, sb.st_mode)) {\n \t\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n-\t\t\t\t\t\t\tVCWD_UNLINK(url_from);\n-\t\t\t\t\t\t\treturn 1;\n+\t\t\t\t\t\t\tif (errno != EPERM) {\n+\t\t\t\t\t\t\t\tsuccess = 0;\n+\t\t\t\t\t\t\t}\n \t\t\t\t\t\t}\n-\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n-\t\t\t\t\t\treturn 0;\n-\t\t\t\t\t}\n-\t\t\t\t\tif (VCWD_CHOWN(url_to, sb.st_uid, sb.st_gid)) {\n-\t\t\t\t\t\tif (errno == EPERM) {\n-\t\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n-\t\t\t\t\t\t\tVCWD_UNLINK(url_from);\n-\t\t\t\t\t\t\treturn 1;\n-\t\t\t\t\t\t}\n-\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n-\t\t\t\t\t\treturn 0;\n \t\t\t\t\t}\n #  endif\n-\t\t\t\t\tVCWD_UNLINK(url_from);\n-\t\t\t\t\treturn 1;\n+\t\t\t\t\tif (success) {\n+\t\t\t\t\t\tVCWD_UNLINK(url_from);\n+\t\t\t\t\t}\n+\t\t\t\t} else {\n+\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n \t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n \t\t\t}\n-\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));\n-\t\t\treturn 0;\n+#  if !defined(ZTS) && !defined(TSRM_WIN32) && !defined(NETWARE)\n+\t\t\tumask(oldmask);\n+#  endif\n+\t\t\treturn success;\n \t\t}\n # endif\n #endif",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\tif (VCWD_CHMOD(url_to, sb.st_mode)) {",
                "\t\t\t\t\t\tif (errno == EPERM) {",
                "\t\t\t\t\t\t\tVCWD_UNLINK(url_from);",
                "\t\t\t\t\t\t\treturn 1;",
                "\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));",
                "\t\t\t\t\t\treturn 0;",
                "\t\t\t\t\t}",
                "\t\t\t\t\tif (VCWD_CHOWN(url_to, sb.st_uid, sb.st_gid)) {",
                "\t\t\t\t\t\tif (errno == EPERM) {",
                "\t\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));",
                "\t\t\t\t\t\t\tVCWD_UNLINK(url_from);",
                "\t\t\t\t\t\t\treturn 1;",
                "\t\t\t\t\t\t}",
                "\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));",
                "\t\t\t\t\t\treturn 0;",
                "\t\t\t\t\tVCWD_UNLINK(url_from);",
                "\t\t\t\t\treturn 1;",
                "\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));",
                "\t\t\treturn 0;"
            ],
            "added_lines": [
                "# if !defined(ZTS) && !defined(TSRM_WIN32) && !defined(NETWARE)",
                "\t\t\t/* not sure what to do in ZTS case, umask is not thread-safe */",
                "\t\t\tint oldmask = umask(077);",
                "# endif",
                "\t\t\tint success = 0;",
                "\t\t\t\t\tsuccess = 1;",
                "\t\t\t\t\t/*",
                "\t\t\t\t\t * Try to set user and permission info on the target.",
                "\t\t\t\t\t * If we're not root, then some of these may fail.",
                "\t\t\t\t\t * We try chown first, to set proper group info, relying",
                "\t\t\t\t\t * on the system environment to have proper umask to not allow",
                "\t\t\t\t\t * access to the file in the meantime.",
                "\t\t\t\t\t */",
                "\t\t\t\t\tif (VCWD_CHOWN(url_to, sb.st_uid, sb.st_gid)) {",
                "\t\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));",
                "\t\t\t\t\t\tif (errno != EPERM) {",
                "\t\t\t\t\t\t\tsuccess = 0;",
                "\t\t\t\t\t\t}",
                "\t\t\t\t\t}",
                "",
                "\t\t\t\t\tif (success) {",
                "\t\t\t\t\t\tif (VCWD_CHMOD(url_to, sb.st_mode)) {",
                "\t\t\t\t\t\t\tif (errno != EPERM) {",
                "\t\t\t\t\t\t\t\tsuccess = 0;",
                "\t\t\t\t\t\t\t}",
                "\t\t\t\t\tif (success) {",
                "\t\t\t\t\t\tVCWD_UNLINK(url_from);",
                "\t\t\t\t\t}",
                "\t\t\t\t} else {",
                "\t\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));",
                "\t\t\t} else {",
                "\t\t\t\tphp_error_docref2(NULL, url_from, url_to, E_WARNING, \"%s\", strerror(errno));",
                "#  if !defined(ZTS) && !defined(TSRM_WIN32) && !defined(NETWARE)",
                "\t\t\tumask(oldmask);",
                "#  endif",
                "\t\t\treturn success;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9646",
        "func_name": "chromium/GoogleChromeDistribution::DoPostUninstallOperations",
        "description": "Unquoted Windows search path vulnerability in the GoogleChromeDistribution::DoPostUninstallOperations function in installer/util/google_chrome_distribution.cc in the uninstall-survey feature in Google Chrome before 40.0.2214.91 allows local users to gain privileges via a Trojan horse program in the %SYSTEMDRIVE% directory, as demonstrated by program.exe, a different vulnerability than CVE-2015-1205.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/bf5ba14fbc8a1dbe23b6132a15551f8d9e36dba1",
        "commit_title": "Quote the path to IE when launching it for the uninstall survey.",
        "commit_text": "   ",
        "func_before": "void GoogleChromeDistribution::DoPostUninstallOperations(\n    const Version& version,\n    const base::FilePath& local_data_path,\n    const base::string16& distribution_data) {\n  // Send the Chrome version and OS version as params to the form.\n  // It would be nice to send the locale, too, but I don't see an\n  // easy way to get that in the existing code. It's something we\n  // can add later, if needed.\n  // We depend on installed_version.GetString() not having spaces or other\n  // characters that need escaping: 0.2.13.4. Should that change, we will\n  // need to escape the string before using it in a URL.\n  const base::string16 kVersionParam = L\"crversion\";\n  const base::string16 kOSParam = L\"os\";\n  base::win::OSInfo::VersionNumber version_number =\n      base::win::OSInfo::GetInstance()->version_number();\n  base::string16 os_version = base::StringPrintf(L\"%d.%d.%d\",\n      version_number.major, version_number.minor, version_number.build);\n\n  base::FilePath iexplore;\n  if (!PathService::Get(base::DIR_PROGRAM_FILES, &iexplore))\n    return;\n\n  iexplore = iexplore.AppendASCII(\"Internet Explorer\");\n  iexplore = iexplore.AppendASCII(\"iexplore.exe\");\n\n  base::string16 command = iexplore.value() + L\" \" + GetUninstallSurveyUrl() +\n      L\"&\" + kVersionParam + L\"=\" + base::UTF8ToWide(version.GetString()) +\n      L\"&\" + kOSParam + L\"=\" + os_version;\n\n  base::string16 uninstall_metrics;\n  if (installer::ExtractUninstallMetricsFromFile(local_data_path,\n                                                 &uninstall_metrics)) {\n    // The user has opted into anonymous usage data collection, so append\n    // metrics and distribution data.\n    command += uninstall_metrics;\n    if (!distribution_data.empty()) {\n      command += L\"&\";\n      command += distribution_data;\n    }\n  }\n\n  int pid = 0;\n  // The reason we use WMI to launch the process is because the uninstall\n  // process runs inside a Job object controlled by the shell. As long as there\n  // are processes running, the shell will not close the uninstall applet. WMI\n  // allows us to escape from the Job object so the applet will close.\n  installer::WMIProcess::Launch(command, &pid);\n}",
        "func": "void GoogleChromeDistribution::DoPostUninstallOperations(\n    const Version& version,\n    const base::FilePath& local_data_path,\n    const base::string16& distribution_data) {\n  // Send the Chrome version and OS version as params to the form.\n  // It would be nice to send the locale, too, but I don't see an\n  // easy way to get that in the existing code. It's something we\n  // can add later, if needed.\n  // We depend on installed_version.GetString() not having spaces or other\n  // characters that need escaping: 0.2.13.4. Should that change, we will\n  // need to escape the string before using it in a URL.\n  const base::string16 kVersionParam = L\"crversion\";\n  const base::string16 kOSParam = L\"os\";\n  base::win::OSInfo::VersionNumber version_number =\n      base::win::OSInfo::GetInstance()->version_number();\n  base::string16 os_version = base::StringPrintf(L\"%d.%d.%d\",\n      version_number.major, version_number.minor, version_number.build);\n\n  base::FilePath iexplore;\n  if (!PathService::Get(base::DIR_PROGRAM_FILES, &iexplore))\n    return;\n\n  iexplore = iexplore.AppendASCII(\"Internet Explorer\");\n  iexplore = iexplore.AppendASCII(\"iexplore.exe\");\n\n  base::string16 command = L\"\\\"\" + iexplore.value() + L\"\\\" \" +\n      GetUninstallSurveyUrl() +\n      L\"&\" + kVersionParam + L\"=\" + base::ASCIIToUTF16(version.GetString()) +\n      L\"&\" + kOSParam + L\"=\" + os_version;\n\n  base::string16 uninstall_metrics;\n  if (installer::ExtractUninstallMetricsFromFile(local_data_path,\n                                                 &uninstall_metrics)) {\n    // The user has opted into anonymous usage data collection, so append\n    // metrics and distribution data.\n    command += uninstall_metrics;\n    if (!distribution_data.empty()) {\n      command += L\"&\";\n      command += distribution_data;\n    }\n  }\n\n  int pid = 0;\n  // The reason we use WMI to launch the process is because the uninstall\n  // process runs inside a Job object controlled by the shell. As long as there\n  // are processes running, the shell will not close the uninstall applet. WMI\n  // allows us to escape from the Job object so the applet will close.\n  installer::WMIProcess::Launch(command, &pid);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,8 +23,9 @@\n   iexplore = iexplore.AppendASCII(\"Internet Explorer\");\n   iexplore = iexplore.AppendASCII(\"iexplore.exe\");\n \n-  base::string16 command = iexplore.value() + L\" \" + GetUninstallSurveyUrl() +\n-      L\"&\" + kVersionParam + L\"=\" + base::UTF8ToWide(version.GetString()) +\n+  base::string16 command = L\"\\\"\" + iexplore.value() + L\"\\\" \" +\n+      GetUninstallSurveyUrl() +\n+      L\"&\" + kVersionParam + L\"=\" + base::ASCIIToUTF16(version.GetString()) +\n       L\"&\" + kOSParam + L\"=\" + os_version;\n \n   base::string16 uninstall_metrics;",
        "diff_line_info": {
            "deleted_lines": [
                "  base::string16 command = iexplore.value() + L\" \" + GetUninstallSurveyUrl() +",
                "      L\"&\" + kVersionParam + L\"=\" + base::UTF8ToWide(version.GetString()) +"
            ],
            "added_lines": [
                "  base::string16 command = L\"\\\"\" + iexplore.value() + L\"\\\" \" +",
                "      GetUninstallSurveyUrl() +",
                "      L\"&\" + kVersionParam + L\"=\" + base::ASCIIToUTF16(version.GetString()) +"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9675",
        "func_name": "freetype/freetype2/_bdf_parse_glyphs",
        "description": "bdf/bdflib.c in FreeType before 2.5.4 identifies property names by only verifying that an initial substring is present, which allows remote attackers to discover heap pointer values and bypass the ASLR protection mechanism via a crafted BDF font.",
        "git_url": "http://git.savannah.gnu.org/cgit/freetype/freetype2.git/commit/?id=2c4832d30939b45c05757f0a05128ce64c4cacc7",
        "commit_title": "* src/bdf/bdflib.c (_bdf_strncmp): New macro that checks one",
        "commit_text": "character more than `strncmp'. s/ft_strncmp/_bdf_strncmp/ everywhere. ",
        "func_before": "static FT_Error\n  _bdf_parse_glyphs( char*          line,\n                     unsigned long  linelen,\n                     unsigned long  lineno,\n                     void*          call_data,\n                     void*          client_data )\n  {\n    int                c, mask_index;\n    char*              s;\n    unsigned char*     bp;\n    unsigned long      i, slen, nibbles;\n\n    _bdf_parse_t*      p;\n    bdf_glyph_t*       glyph;\n    bdf_font_t*        font;\n\n    FT_Memory          memory;\n    FT_Error           error = FT_Err_Ok;\n\n    FT_UNUSED( call_data );\n    FT_UNUSED( lineno );        /* only used in debug mode */\n\n\n    p = (_bdf_parse_t *)client_data;\n\n    font   = p->font;\n    memory = font->memory;\n\n    /* Check for a comment. */\n    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )\n    {\n      linelen -= 7;\n\n      s = line + 7;\n      if ( *s != 0 )\n      {\n        s++;\n        linelen--;\n      }\n      error = _bdf_add_comment( p->font, s, linelen );\n      goto Exit;\n    }\n\n    /* The very first thing expected is the number of glyphs. */\n    if ( !( p->flags & _BDF_GLYPHS ) )\n    {\n      if ( ft_strncmp( line, \"CHARS\", 5 ) != 0 )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"CHARS\" ));\n        error = FT_THROW( Missing_Chars_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      p->cnt = font->glyphs_size = _bdf_atoul( p->list.field[1], 0, 10 );\n\n      /* Make sure the number of glyphs is non-zero. */\n      if ( p->cnt == 0 )\n        font->glyphs_size = 64;\n\n      /* Limit ourselves to 1,114,112 glyphs in the font (this is the */\n      /* number of code points available in Unicode).                 */\n      if ( p->cnt >= 0x110000UL )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG5, lineno, \"CHARS\" ));\n        error = FT_THROW( Invalid_Argument );\n        goto Exit;\n      }\n\n      if ( FT_NEW_ARRAY( font->glyphs, font->glyphs_size ) )\n        goto Exit;\n\n      p->flags |= _BDF_GLYPHS;\n\n      goto Exit;\n    }\n\n    /* Check for the ENDFONT field. */\n    if ( ft_strncmp( line, \"ENDFONT\", 7 ) == 0 )\n    {\n      /* Sort the glyphs by encoding. */\n      ft_qsort( (char *)font->glyphs,\n                font->glyphs_used,\n                sizeof ( bdf_glyph_t ),\n                by_encoding );\n\n      p->flags &= ~_BDF_START;\n\n      goto Exit;\n    }\n\n    /* Check for the ENDCHAR field. */\n    if ( ft_strncmp( line, \"ENDCHAR\", 7 ) == 0 )\n    {\n      p->glyph_enc = 0;\n      p->flags    &= ~_BDF_GLYPH_BITS;\n\n      goto Exit;\n    }\n\n    /* Check whether a glyph is being scanned but should be */\n    /* ignored because it is an unencoded glyph.            */\n    if ( ( p->flags & _BDF_GLYPH )     &&\n         p->glyph_enc            == -1 &&\n         p->opts->keep_unencoded == 0  )\n      goto Exit;\n\n    /* Check for the STARTCHAR field. */\n    if ( ft_strncmp( line, \"STARTCHAR\", 9 ) == 0 )\n    {\n      /* Set the character name in the parse info first until the */\n      /* encoding can be checked for an unencoded character.      */\n      FT_FREE( p->glyph_name );\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      _bdf_list_shift( &p->list, 1 );\n\n      s = _bdf_list_join( &p->list, ' ', &slen );\n\n      if ( !s )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG8, lineno, \"STARTCHAR\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      if ( FT_NEW_ARRAY( p->glyph_name, slen + 1 ) )\n        goto Exit;\n\n      FT_MEM_COPY( p->glyph_name, s, slen + 1 );\n\n      p->flags |= _BDF_GLYPH;\n\n      FT_TRACE4(( DBGMSG1, lineno, s ));\n\n      goto Exit;\n    }\n\n    /* Check for the ENCODING field. */\n    if ( ft_strncmp( line, \"ENCODING\", 8 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_GLYPH ) )\n      {\n        /* Missing STARTCHAR field. */\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"STARTCHAR\" ));\n        error = FT_THROW( Missing_Startchar_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      p->glyph_enc = _bdf_atol( p->list.field[1], 0, 10 );\n\n      /* Normalize negative encoding values.  The specification only */\n      /* allows -1, but we can be more generous here.                */\n      if ( p->glyph_enc < -1 )\n        p->glyph_enc = -1;\n\n      /* Check for alternative encoding format. */\n      if ( p->glyph_enc == -1 && p->list.used > 2 )\n        p->glyph_enc = _bdf_atol( p->list.field[2], 0, 10 );\n\n      if ( p->glyph_enc < -1 )\n        p->glyph_enc = -1;\n\n      FT_TRACE4(( DBGMSG2, p->glyph_enc ));\n\n      /* Check that the encoding is in the Unicode range because  */\n      /* otherwise p->have (a bitmap with static size) overflows. */\n      if ( p->glyph_enc > 0                                      &&\n           (size_t)p->glyph_enc >= sizeof ( p->have ) /\n                                   sizeof ( unsigned long ) * 32 )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG5, lineno, \"ENCODING\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      /* Check whether this encoding has already been encountered. */\n      /* If it has then change it to unencoded so it gets added if */\n      /* indicated.                                                */\n      if ( p->glyph_enc >= 0 )\n      {\n        if ( _bdf_glyph_modified( p->have, p->glyph_enc ) )\n        {\n          /* Emit a message saying a glyph has been moved to the */\n          /* unencoded area.                                     */\n          FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG12,\n                      p->glyph_enc, p->glyph_name ));\n          p->glyph_enc = -1;\n          font->modified = 1;\n        }\n        else\n          _bdf_set_glyph_modified( p->have, p->glyph_enc );\n      }\n\n      if ( p->glyph_enc >= 0 )\n      {\n        /* Make sure there are enough glyphs allocated in case the */\n        /* number of characters happen to be wrong.                */\n        if ( font->glyphs_used == font->glyphs_size )\n        {\n          if ( FT_RENEW_ARRAY( font->glyphs,\n                               font->glyphs_size,\n                               font->glyphs_size + 64 ) )\n            goto Exit;\n\n          font->glyphs_size += 64;\n        }\n\n        glyph           = font->glyphs + font->glyphs_used++;\n        glyph->name     = p->glyph_name;\n        glyph->encoding = p->glyph_enc;\n\n        /* Reset the initial glyph info. */\n        p->glyph_name = 0;\n      }\n      else\n      {\n        /* Unencoded glyph.  Check whether it should */\n        /* be added or not.                          */\n        if ( p->opts->keep_unencoded != 0 )\n        {\n          /* Allocate the next unencoded glyph. */\n          if ( font->unencoded_used == font->unencoded_size )\n          {\n            if ( FT_RENEW_ARRAY( font->unencoded ,\n                                 font->unencoded_size,\n                                 font->unencoded_size + 4 ) )\n              goto Exit;\n\n            font->unencoded_size += 4;\n          }\n\n          glyph           = font->unencoded + font->unencoded_used;\n          glyph->name     = p->glyph_name;\n          glyph->encoding = font->unencoded_used++;\n        }\n        else\n          /* Free up the glyph name if the unencoded shouldn't be */\n          /* kept.                                                */\n          FT_FREE( p->glyph_name );\n\n        p->glyph_name = 0;\n      }\n\n      /* Clear the flags that might be added when width and height are */\n      /* checked for consistency.                                      */\n      p->flags &= ~( _BDF_GLYPH_WIDTH_CHECK | _BDF_GLYPH_HEIGHT_CHECK );\n\n      p->flags |= _BDF_ENCODING;\n\n      goto Exit;\n    }\n\n    /* Point at the glyph being constructed. */\n    if ( p->glyph_enc == -1 )\n      glyph = font->unencoded + ( font->unencoded_used - 1 );\n    else\n      glyph = font->glyphs + ( font->glyphs_used - 1 );\n\n    /* Check whether a bitmap is being constructed. */\n    if ( p->flags & _BDF_BITMAP )\n    {\n      /* If there are more rows than are specified in the glyph metrics, */\n      /* ignore the remaining lines.                                     */\n      if ( p->row >= (unsigned long)glyph->bbx.height )\n      {\n        if ( !( p->flags & _BDF_GLYPH_HEIGHT_CHECK ) )\n        {\n          FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG13, glyph->encoding ));\n          p->flags |= _BDF_GLYPH_HEIGHT_CHECK;\n          font->modified = 1;\n        }\n\n        goto Exit;\n      }\n\n      /* Only collect the number of nibbles indicated by the glyph     */\n      /* metrics.  If there are more columns, they are simply ignored. */\n      nibbles = glyph->bpr << 1;\n      bp      = glyph->bitmap + p->row * glyph->bpr;\n\n      for ( i = 0; i < nibbles; i++ )\n      {\n        c = line[i];\n        if ( !sbitset( hdigits, c ) )\n          break;\n        *bp = (FT_Byte)( ( *bp << 4 ) + a2i[c] );\n        if ( i + 1 < nibbles && ( i & 1 ) )\n          *++bp = 0;\n      }\n\n      /* If any line has not enough columns,            */\n      /* indicate they have been padded with zero bits. */\n      if ( i < nibbles                            &&\n           !( p->flags & _BDF_GLYPH_WIDTH_CHECK ) )\n      {\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG16, glyph->encoding ));\n        p->flags       |= _BDF_GLYPH_WIDTH_CHECK;\n        font->modified  = 1;\n      }\n\n      /* Remove possible garbage at the right. */\n      mask_index = ( glyph->bbx.width * p->font->bpp ) & 7;\n      if ( glyph->bbx.width )\n        *bp &= nibble_mask[mask_index];\n\n      /* If any line has extra columns, indicate they have been removed. */\n      if ( i == nibbles                           &&\n           sbitset( hdigits, line[nibbles] )      &&\n           !( p->flags & _BDF_GLYPH_WIDTH_CHECK ) )\n      {\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG14, glyph->encoding ));\n        p->flags       |= _BDF_GLYPH_WIDTH_CHECK;\n        font->modified  = 1;\n      }\n\n      p->row++;\n      goto Exit;\n    }\n\n    /* Expect the SWIDTH (scalable width) field next. */\n    if ( ft_strncmp( line, \"SWIDTH\", 6 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_ENCODING ) )\n        goto Missing_Encoding;\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      glyph->swidth = (unsigned short)_bdf_atoul( p->list.field[1], 0, 10 );\n      p->flags |= _BDF_SWIDTH;\n\n      goto Exit;\n    }\n\n    /* Expect the DWIDTH (scalable width) field next. */\n    if ( ft_strncmp( line, \"DWIDTH\", 6 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_ENCODING ) )\n        goto Missing_Encoding;\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      glyph->dwidth = (unsigned short)_bdf_atoul( p->list.field[1], 0, 10 );\n\n      if ( !( p->flags & _BDF_SWIDTH ) )\n      {\n        /* Missing SWIDTH field.  Emit an auto correction message and set */\n        /* the scalable width from the device width.                      */\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG9, lineno ));\n\n        glyph->swidth = (unsigned short)FT_MulDiv(\n                          glyph->dwidth, 72000L,\n                          (FT_Long)( font->point_size *\n                                     font->resolution_x ) );\n      }\n\n      p->flags |= _BDF_DWIDTH;\n      goto Exit;\n    }\n\n    /* Expect the BBX field next. */\n    if ( ft_strncmp( line, \"BBX\", 3 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_ENCODING ) )\n        goto Missing_Encoding;\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      glyph->bbx.width    = _bdf_atos( p->list.field[1], 0, 10 );\n      glyph->bbx.height   = _bdf_atos( p->list.field[2], 0, 10 );\n      glyph->bbx.x_offset = _bdf_atos( p->list.field[3], 0, 10 );\n      glyph->bbx.y_offset = _bdf_atos( p->list.field[4], 0, 10 );\n\n      /* Generate the ascent and descent of the character. */\n      glyph->bbx.ascent  = (short)( glyph->bbx.height + glyph->bbx.y_offset );\n      glyph->bbx.descent = (short)( -glyph->bbx.y_offset );\n\n      /* Determine the overall font bounding box as the characters are */\n      /* loaded so corrections can be done later if indicated.         */\n      p->maxas    = (short)FT_MAX( glyph->bbx.ascent, p->maxas );\n      p->maxds    = (short)FT_MAX( glyph->bbx.descent, p->maxds );\n\n      p->rbearing = (short)( glyph->bbx.width + glyph->bbx.x_offset );\n\n      p->maxrb    = (short)FT_MAX( p->rbearing, p->maxrb );\n      p->minlb    = (short)FT_MIN( glyph->bbx.x_offset, p->minlb );\n      p->maxlb    = (short)FT_MAX( glyph->bbx.x_offset, p->maxlb );\n\n      if ( !( p->flags & _BDF_DWIDTH ) )\n      {\n        /* Missing DWIDTH field.  Emit an auto correction message and set */\n        /* the device width to the glyph width.                           */\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG10, lineno ));\n        glyph->dwidth = glyph->bbx.width;\n      }\n\n      /* If the BDF_CORRECT_METRICS flag is set, then adjust the SWIDTH */\n      /* value if necessary.                                            */\n      if ( p->opts->correct_metrics != 0 )\n      {\n        /* Determine the point size of the glyph. */\n        unsigned short  sw = (unsigned short)FT_MulDiv(\n                               glyph->dwidth, 72000L,\n                               (FT_Long)( font->point_size *\n                                          font->resolution_x ) );\n\n\n        if ( sw != glyph->swidth )\n        {\n          glyph->swidth = sw;\n\n          if ( p->glyph_enc == -1 )\n            _bdf_set_glyph_modified( font->umod,\n                                     font->unencoded_used - 1 );\n          else\n            _bdf_set_glyph_modified( font->nmod, glyph->encoding );\n\n          p->flags       |= _BDF_SWIDTH_ADJ;\n          font->modified  = 1;\n        }\n      }\n\n      p->flags |= _BDF_BBX;\n      goto Exit;\n    }\n\n    /* And finally, gather up the bitmap. */\n    if ( ft_strncmp( line, \"BITMAP\", 6 ) == 0 )\n    {\n      unsigned long  bitmap_size;\n\n\n      if ( !( p->flags & _BDF_BBX ) )\n      {\n        /* Missing BBX field. */\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"BBX\" ));\n        error = FT_THROW( Missing_Bbx_Field );\n        goto Exit;\n      }\n\n      /* Allocate enough space for the bitmap. */\n      glyph->bpr = ( glyph->bbx.width * p->font->bpp + 7 ) >> 3;\n\n      bitmap_size = glyph->bpr * glyph->bbx.height;\n      if ( glyph->bpr > 0xFFFFU || bitmap_size > 0xFFFFU )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG4, lineno ));\n        error = FT_THROW( Bbx_Too_Big );\n        goto Exit;\n      }\n      else\n        glyph->bytes = (unsigned short)bitmap_size;\n\n      if ( FT_NEW_ARRAY( glyph->bitmap, glyph->bytes ) )\n        goto Exit;\n\n      p->row    = 0;\n      p->flags |= _BDF_BITMAP;\n\n      goto Exit;\n    }\n\n    FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG9, lineno ));\n    error = FT_THROW( Invalid_File_Format );\n    goto Exit;\n\n  Missing_Encoding:\n    /* Missing ENCODING field. */\n    FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"ENCODING\" ));\n    error = FT_THROW( Missing_Encoding_Field );\n\n  Exit:\n    if ( error && ( p->flags & _BDF_GLYPH ) )\n      FT_FREE( p->glyph_name );\n\n    return error;\n  }",
        "func": "static FT_Error\n  _bdf_parse_glyphs( char*          line,\n                     unsigned long  linelen,\n                     unsigned long  lineno,\n                     void*          call_data,\n                     void*          client_data )\n  {\n    int                c, mask_index;\n    char*              s;\n    unsigned char*     bp;\n    unsigned long      i, slen, nibbles;\n\n    _bdf_parse_t*      p;\n    bdf_glyph_t*       glyph;\n    bdf_font_t*        font;\n\n    FT_Memory          memory;\n    FT_Error           error = FT_Err_Ok;\n\n    FT_UNUSED( call_data );\n    FT_UNUSED( lineno );        /* only used in debug mode */\n\n\n    p = (_bdf_parse_t *)client_data;\n\n    font   = p->font;\n    memory = font->memory;\n\n    /* Check for a comment. */\n    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )\n    {\n      linelen -= 7;\n\n      s = line + 7;\n      if ( *s != 0 )\n      {\n        s++;\n        linelen--;\n      }\n      error = _bdf_add_comment( p->font, s, linelen );\n      goto Exit;\n    }\n\n    /* The very first thing expected is the number of glyphs. */\n    if ( !( p->flags & _BDF_GLYPHS ) )\n    {\n      if ( _bdf_strncmp( line, \"CHARS\", 5 ) != 0 )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"CHARS\" ));\n        error = FT_THROW( Missing_Chars_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      p->cnt = font->glyphs_size = _bdf_atoul( p->list.field[1], 0, 10 );\n\n      /* Make sure the number of glyphs is non-zero. */\n      if ( p->cnt == 0 )\n        font->glyphs_size = 64;\n\n      /* Limit ourselves to 1,114,112 glyphs in the font (this is the */\n      /* number of code points available in Unicode).                 */\n      if ( p->cnt >= 0x110000UL )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG5, lineno, \"CHARS\" ));\n        error = FT_THROW( Invalid_Argument );\n        goto Exit;\n      }\n\n      if ( FT_NEW_ARRAY( font->glyphs, font->glyphs_size ) )\n        goto Exit;\n\n      p->flags |= _BDF_GLYPHS;\n\n      goto Exit;\n    }\n\n    /* Check for the ENDFONT field. */\n    if ( _bdf_strncmp( line, \"ENDFONT\", 7 ) == 0 )\n    {\n      /* Sort the glyphs by encoding. */\n      ft_qsort( (char *)font->glyphs,\n                font->glyphs_used,\n                sizeof ( bdf_glyph_t ),\n                by_encoding );\n\n      p->flags &= ~_BDF_START;\n\n      goto Exit;\n    }\n\n    /* Check for the ENDCHAR field. */\n    if ( _bdf_strncmp( line, \"ENDCHAR\", 7 ) == 0 )\n    {\n      p->glyph_enc = 0;\n      p->flags    &= ~_BDF_GLYPH_BITS;\n\n      goto Exit;\n    }\n\n    /* Check whether a glyph is being scanned but should be */\n    /* ignored because it is an unencoded glyph.            */\n    if ( ( p->flags & _BDF_GLYPH )     &&\n         p->glyph_enc            == -1 &&\n         p->opts->keep_unencoded == 0  )\n      goto Exit;\n\n    /* Check for the STARTCHAR field. */\n    if ( _bdf_strncmp( line, \"STARTCHAR\", 9 ) == 0 )\n    {\n      /* Set the character name in the parse info first until the */\n      /* encoding can be checked for an unencoded character.      */\n      FT_FREE( p->glyph_name );\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      _bdf_list_shift( &p->list, 1 );\n\n      s = _bdf_list_join( &p->list, ' ', &slen );\n\n      if ( !s )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG8, lineno, \"STARTCHAR\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      if ( FT_NEW_ARRAY( p->glyph_name, slen + 1 ) )\n        goto Exit;\n\n      FT_MEM_COPY( p->glyph_name, s, slen + 1 );\n\n      p->flags |= _BDF_GLYPH;\n\n      FT_TRACE4(( DBGMSG1, lineno, s ));\n\n      goto Exit;\n    }\n\n    /* Check for the ENCODING field. */\n    if ( _bdf_strncmp( line, \"ENCODING\", 8 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_GLYPH ) )\n      {\n        /* Missing STARTCHAR field. */\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"STARTCHAR\" ));\n        error = FT_THROW( Missing_Startchar_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      p->glyph_enc = _bdf_atol( p->list.field[1], 0, 10 );\n\n      /* Normalize negative encoding values.  The specification only */\n      /* allows -1, but we can be more generous here.                */\n      if ( p->glyph_enc < -1 )\n        p->glyph_enc = -1;\n\n      /* Check for alternative encoding format. */\n      if ( p->glyph_enc == -1 && p->list.used > 2 )\n        p->glyph_enc = _bdf_atol( p->list.field[2], 0, 10 );\n\n      if ( p->glyph_enc < -1 )\n        p->glyph_enc = -1;\n\n      FT_TRACE4(( DBGMSG2, p->glyph_enc ));\n\n      /* Check that the encoding is in the Unicode range because  */\n      /* otherwise p->have (a bitmap with static size) overflows. */\n      if ( p->glyph_enc > 0                                      &&\n           (size_t)p->glyph_enc >= sizeof ( p->have ) /\n                                   sizeof ( unsigned long ) * 32 )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG5, lineno, \"ENCODING\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      /* Check whether this encoding has already been encountered. */\n      /* If it has then change it to unencoded so it gets added if */\n      /* indicated.                                                */\n      if ( p->glyph_enc >= 0 )\n      {\n        if ( _bdf_glyph_modified( p->have, p->glyph_enc ) )\n        {\n          /* Emit a message saying a glyph has been moved to the */\n          /* unencoded area.                                     */\n          FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG12,\n                      p->glyph_enc, p->glyph_name ));\n          p->glyph_enc = -1;\n          font->modified = 1;\n        }\n        else\n          _bdf_set_glyph_modified( p->have, p->glyph_enc );\n      }\n\n      if ( p->glyph_enc >= 0 )\n      {\n        /* Make sure there are enough glyphs allocated in case the */\n        /* number of characters happen to be wrong.                */\n        if ( font->glyphs_used == font->glyphs_size )\n        {\n          if ( FT_RENEW_ARRAY( font->glyphs,\n                               font->glyphs_size,\n                               font->glyphs_size + 64 ) )\n            goto Exit;\n\n          font->glyphs_size += 64;\n        }\n\n        glyph           = font->glyphs + font->glyphs_used++;\n        glyph->name     = p->glyph_name;\n        glyph->encoding = p->glyph_enc;\n\n        /* Reset the initial glyph info. */\n        p->glyph_name = 0;\n      }\n      else\n      {\n        /* Unencoded glyph.  Check whether it should */\n        /* be added or not.                          */\n        if ( p->opts->keep_unencoded != 0 )\n        {\n          /* Allocate the next unencoded glyph. */\n          if ( font->unencoded_used == font->unencoded_size )\n          {\n            if ( FT_RENEW_ARRAY( font->unencoded ,\n                                 font->unencoded_size,\n                                 font->unencoded_size + 4 ) )\n              goto Exit;\n\n            font->unencoded_size += 4;\n          }\n\n          glyph           = font->unencoded + font->unencoded_used;\n          glyph->name     = p->glyph_name;\n          glyph->encoding = font->unencoded_used++;\n        }\n        else\n          /* Free up the glyph name if the unencoded shouldn't be */\n          /* kept.                                                */\n          FT_FREE( p->glyph_name );\n\n        p->glyph_name = 0;\n      }\n\n      /* Clear the flags that might be added when width and height are */\n      /* checked for consistency.                                      */\n      p->flags &= ~( _BDF_GLYPH_WIDTH_CHECK | _BDF_GLYPH_HEIGHT_CHECK );\n\n      p->flags |= _BDF_ENCODING;\n\n      goto Exit;\n    }\n\n    /* Point at the glyph being constructed. */\n    if ( p->glyph_enc == -1 )\n      glyph = font->unencoded + ( font->unencoded_used - 1 );\n    else\n      glyph = font->glyphs + ( font->glyphs_used - 1 );\n\n    /* Check whether a bitmap is being constructed. */\n    if ( p->flags & _BDF_BITMAP )\n    {\n      /* If there are more rows than are specified in the glyph metrics, */\n      /* ignore the remaining lines.                                     */\n      if ( p->row >= (unsigned long)glyph->bbx.height )\n      {\n        if ( !( p->flags & _BDF_GLYPH_HEIGHT_CHECK ) )\n        {\n          FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG13, glyph->encoding ));\n          p->flags |= _BDF_GLYPH_HEIGHT_CHECK;\n          font->modified = 1;\n        }\n\n        goto Exit;\n      }\n\n      /* Only collect the number of nibbles indicated by the glyph     */\n      /* metrics.  If there are more columns, they are simply ignored. */\n      nibbles = glyph->bpr << 1;\n      bp      = glyph->bitmap + p->row * glyph->bpr;\n\n      for ( i = 0; i < nibbles; i++ )\n      {\n        c = line[i];\n        if ( !sbitset( hdigits, c ) )\n          break;\n        *bp = (FT_Byte)( ( *bp << 4 ) + a2i[c] );\n        if ( i + 1 < nibbles && ( i & 1 ) )\n          *++bp = 0;\n      }\n\n      /* If any line has not enough columns,            */\n      /* indicate they have been padded with zero bits. */\n      if ( i < nibbles                            &&\n           !( p->flags & _BDF_GLYPH_WIDTH_CHECK ) )\n      {\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG16, glyph->encoding ));\n        p->flags       |= _BDF_GLYPH_WIDTH_CHECK;\n        font->modified  = 1;\n      }\n\n      /* Remove possible garbage at the right. */\n      mask_index = ( glyph->bbx.width * p->font->bpp ) & 7;\n      if ( glyph->bbx.width )\n        *bp &= nibble_mask[mask_index];\n\n      /* If any line has extra columns, indicate they have been removed. */\n      if ( i == nibbles                           &&\n           sbitset( hdigits, line[nibbles] )      &&\n           !( p->flags & _BDF_GLYPH_WIDTH_CHECK ) )\n      {\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG14, glyph->encoding ));\n        p->flags       |= _BDF_GLYPH_WIDTH_CHECK;\n        font->modified  = 1;\n      }\n\n      p->row++;\n      goto Exit;\n    }\n\n    /* Expect the SWIDTH (scalable width) field next. */\n    if ( _bdf_strncmp( line, \"SWIDTH\", 6 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_ENCODING ) )\n        goto Missing_Encoding;\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      glyph->swidth = (unsigned short)_bdf_atoul( p->list.field[1], 0, 10 );\n      p->flags |= _BDF_SWIDTH;\n\n      goto Exit;\n    }\n\n    /* Expect the DWIDTH (scalable width) field next. */\n    if ( _bdf_strncmp( line, \"DWIDTH\", 6 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_ENCODING ) )\n        goto Missing_Encoding;\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      glyph->dwidth = (unsigned short)_bdf_atoul( p->list.field[1], 0, 10 );\n\n      if ( !( p->flags & _BDF_SWIDTH ) )\n      {\n        /* Missing SWIDTH field.  Emit an auto correction message and set */\n        /* the scalable width from the device width.                      */\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG9, lineno ));\n\n        glyph->swidth = (unsigned short)FT_MulDiv(\n                          glyph->dwidth, 72000L,\n                          (FT_Long)( font->point_size *\n                                     font->resolution_x ) );\n      }\n\n      p->flags |= _BDF_DWIDTH;\n      goto Exit;\n    }\n\n    /* Expect the BBX field next. */\n    if ( _bdf_strncmp( line, \"BBX\", 3 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_ENCODING ) )\n        goto Missing_Encoding;\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      glyph->bbx.width    = _bdf_atos( p->list.field[1], 0, 10 );\n      glyph->bbx.height   = _bdf_atos( p->list.field[2], 0, 10 );\n      glyph->bbx.x_offset = _bdf_atos( p->list.field[3], 0, 10 );\n      glyph->bbx.y_offset = _bdf_atos( p->list.field[4], 0, 10 );\n\n      /* Generate the ascent and descent of the character. */\n      glyph->bbx.ascent  = (short)( glyph->bbx.height + glyph->bbx.y_offset );\n      glyph->bbx.descent = (short)( -glyph->bbx.y_offset );\n\n      /* Determine the overall font bounding box as the characters are */\n      /* loaded so corrections can be done later if indicated.         */\n      p->maxas    = (short)FT_MAX( glyph->bbx.ascent, p->maxas );\n      p->maxds    = (short)FT_MAX( glyph->bbx.descent, p->maxds );\n\n      p->rbearing = (short)( glyph->bbx.width + glyph->bbx.x_offset );\n\n      p->maxrb    = (short)FT_MAX( p->rbearing, p->maxrb );\n      p->minlb    = (short)FT_MIN( glyph->bbx.x_offset, p->minlb );\n      p->maxlb    = (short)FT_MAX( glyph->bbx.x_offset, p->maxlb );\n\n      if ( !( p->flags & _BDF_DWIDTH ) )\n      {\n        /* Missing DWIDTH field.  Emit an auto correction message and set */\n        /* the device width to the glyph width.                           */\n        FT_TRACE2(( \"_bdf_parse_glyphs: \" ACMSG10, lineno ));\n        glyph->dwidth = glyph->bbx.width;\n      }\n\n      /* If the BDF_CORRECT_METRICS flag is set, then adjust the SWIDTH */\n      /* value if necessary.                                            */\n      if ( p->opts->correct_metrics != 0 )\n      {\n        /* Determine the point size of the glyph. */\n        unsigned short  sw = (unsigned short)FT_MulDiv(\n                               glyph->dwidth, 72000L,\n                               (FT_Long)( font->point_size *\n                                          font->resolution_x ) );\n\n\n        if ( sw != glyph->swidth )\n        {\n          glyph->swidth = sw;\n\n          if ( p->glyph_enc == -1 )\n            _bdf_set_glyph_modified( font->umod,\n                                     font->unencoded_used - 1 );\n          else\n            _bdf_set_glyph_modified( font->nmod, glyph->encoding );\n\n          p->flags       |= _BDF_SWIDTH_ADJ;\n          font->modified  = 1;\n        }\n      }\n\n      p->flags |= _BDF_BBX;\n      goto Exit;\n    }\n\n    /* And finally, gather up the bitmap. */\n    if ( _bdf_strncmp( line, \"BITMAP\", 6 ) == 0 )\n    {\n      unsigned long  bitmap_size;\n\n\n      if ( !( p->flags & _BDF_BBX ) )\n      {\n        /* Missing BBX field. */\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"BBX\" ));\n        error = FT_THROW( Missing_Bbx_Field );\n        goto Exit;\n      }\n\n      /* Allocate enough space for the bitmap. */\n      glyph->bpr = ( glyph->bbx.width * p->font->bpp + 7 ) >> 3;\n\n      bitmap_size = glyph->bpr * glyph->bbx.height;\n      if ( glyph->bpr > 0xFFFFU || bitmap_size > 0xFFFFU )\n      {\n        FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG4, lineno ));\n        error = FT_THROW( Bbx_Too_Big );\n        goto Exit;\n      }\n      else\n        glyph->bytes = (unsigned short)bitmap_size;\n\n      if ( FT_NEW_ARRAY( glyph->bitmap, glyph->bytes ) )\n        goto Exit;\n\n      p->row    = 0;\n      p->flags |= _BDF_BITMAP;\n\n      goto Exit;\n    }\n\n    FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG9, lineno ));\n    error = FT_THROW( Invalid_File_Format );\n    goto Exit;\n\n  Missing_Encoding:\n    /* Missing ENCODING field. */\n    FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"ENCODING\" ));\n    error = FT_THROW( Missing_Encoding_Field );\n\n  Exit:\n    if ( error && ( p->flags & _BDF_GLYPH ) )\n      FT_FREE( p->glyph_name );\n\n    return error;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,7 +27,7 @@\n     memory = font->memory;\n \n     /* Check for a comment. */\n-    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )\n+    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )\n     {\n       linelen -= 7;\n \n@@ -44,7 +44,7 @@\n     /* The very first thing expected is the number of glyphs. */\n     if ( !( p->flags & _BDF_GLYPHS ) )\n     {\n-      if ( ft_strncmp( line, \"CHARS\", 5 ) != 0 )\n+      if ( _bdf_strncmp( line, \"CHARS\", 5 ) != 0 )\n       {\n         FT_ERROR(( \"_bdf_parse_glyphs: \" ERRMSG1, lineno, \"CHARS\" ));\n         error = FT_THROW( Missing_Chars_Field );\n@@ -78,7 +78,7 @@\n     }\n \n     /* Check for the ENDFONT field. */\n-    if ( ft_strncmp( line, \"ENDFONT\", 7 ) == 0 )\n+    if ( _bdf_strncmp( line, \"ENDFONT\", 7 ) == 0 )\n     {\n       /* Sort the glyphs by encoding. */\n       ft_qsort( (char *)font->glyphs,\n@@ -92,7 +92,7 @@\n     }\n \n     /* Check for the ENDCHAR field. */\n-    if ( ft_strncmp( line, \"ENDCHAR\", 7 ) == 0 )\n+    if ( _bdf_strncmp( line, \"ENDCHAR\", 7 ) == 0 )\n     {\n       p->glyph_enc = 0;\n       p->flags    &= ~_BDF_GLYPH_BITS;\n@@ -108,7 +108,7 @@\n       goto Exit;\n \n     /* Check for the STARTCHAR field. */\n-    if ( ft_strncmp( line, \"STARTCHAR\", 9 ) == 0 )\n+    if ( _bdf_strncmp( line, \"STARTCHAR\", 9 ) == 0 )\n     {\n       /* Set the character name in the parse info first until the */\n       /* encoding can be checked for an unencoded character.      */\n@@ -142,7 +142,7 @@\n     }\n \n     /* Check for the ENCODING field. */\n-    if ( ft_strncmp( line, \"ENCODING\", 8 ) == 0 )\n+    if ( _bdf_strncmp( line, \"ENCODING\", 8 ) == 0 )\n     {\n       if ( !( p->flags & _BDF_GLYPH ) )\n       {\n@@ -328,7 +328,7 @@\n     }\n \n     /* Expect the SWIDTH (scalable width) field next. */\n-    if ( ft_strncmp( line, \"SWIDTH\", 6 ) == 0 )\n+    if ( _bdf_strncmp( line, \"SWIDTH\", 6 ) == 0 )\n     {\n       if ( !( p->flags & _BDF_ENCODING ) )\n         goto Missing_Encoding;\n@@ -344,7 +344,7 @@\n     }\n \n     /* Expect the DWIDTH (scalable width) field next. */\n-    if ( ft_strncmp( line, \"DWIDTH\", 6 ) == 0 )\n+    if ( _bdf_strncmp( line, \"DWIDTH\", 6 ) == 0 )\n     {\n       if ( !( p->flags & _BDF_ENCODING ) )\n         goto Missing_Encoding;\n@@ -372,7 +372,7 @@\n     }\n \n     /* Expect the BBX field next. */\n-    if ( ft_strncmp( line, \"BBX\", 3 ) == 0 )\n+    if ( _bdf_strncmp( line, \"BBX\", 3 ) == 0 )\n     {\n       if ( !( p->flags & _BDF_ENCODING ) )\n         goto Missing_Encoding;\n@@ -440,7 +440,7 @@\n     }\n \n     /* And finally, gather up the bitmap. */\n-    if ( ft_strncmp( line, \"BITMAP\", 6 ) == 0 )\n+    if ( _bdf_strncmp( line, \"BITMAP\", 6 ) == 0 )\n     {\n       unsigned long  bitmap_size;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )",
                "      if ( ft_strncmp( line, \"CHARS\", 5 ) != 0 )",
                "    if ( ft_strncmp( line, \"ENDFONT\", 7 ) == 0 )",
                "    if ( ft_strncmp( line, \"ENDCHAR\", 7 ) == 0 )",
                "    if ( ft_strncmp( line, \"STARTCHAR\", 9 ) == 0 )",
                "    if ( ft_strncmp( line, \"ENCODING\", 8 ) == 0 )",
                "    if ( ft_strncmp( line, \"SWIDTH\", 6 ) == 0 )",
                "    if ( ft_strncmp( line, \"DWIDTH\", 6 ) == 0 )",
                "    if ( ft_strncmp( line, \"BBX\", 3 ) == 0 )",
                "    if ( ft_strncmp( line, \"BITMAP\", 6 ) == 0 )"
            ],
            "added_lines": [
                "    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )",
                "      if ( _bdf_strncmp( line, \"CHARS\", 5 ) != 0 )",
                "    if ( _bdf_strncmp( line, \"ENDFONT\", 7 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"ENDCHAR\", 7 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"STARTCHAR\", 9 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"ENCODING\", 8 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"SWIDTH\", 6 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"DWIDTH\", 6 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"BBX\", 3 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"BITMAP\", 6 ) == 0 )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9675",
        "func_name": "freetype/freetype2/_bdf_add_property",
        "description": "bdf/bdflib.c in FreeType before 2.5.4 identifies property names by only verifying that an initial substring is present, which allows remote attackers to discover heap pointer values and bypass the ASLR protection mechanism via a crafted BDF font.",
        "git_url": "http://git.savannah.gnu.org/cgit/freetype/freetype2.git/commit/?id=2c4832d30939b45c05757f0a05128ce64c4cacc7",
        "commit_title": "* src/bdf/bdflib.c (_bdf_strncmp): New macro that checks one",
        "commit_text": "character more than `strncmp'. s/ft_strncmp/_bdf_strncmp/ everywhere. ",
        "func_before": "static FT_Error\n  _bdf_add_property( bdf_font_t*    font,\n                     char*          name,\n                     char*          value,\n                     unsigned long  lineno )\n  {\n    size_t          propid;\n    hashnode        hn;\n    bdf_property_t  *prop, *fp;\n    FT_Memory       memory = font->memory;\n    FT_Error        error  = FT_Err_Ok;\n\n    FT_UNUSED( lineno );        /* only used in debug mode */\n\n\n    /* First, check whether the property already exists in the font. */\n    if ( ( hn = hash_lookup( name, (hashtable *)font->internal ) ) != 0 )\n    {\n      /* The property already exists in the font, so simply replace */\n      /* the value of the property with the current value.          */\n      fp = font->props + hn->data;\n\n      switch ( fp->format )\n      {\n      case BDF_ATOM:\n        /* Delete the current atom if it exists. */\n        FT_FREE( fp->value.atom );\n\n        if ( value && value[0] != 0 )\n        {\n          if ( FT_STRDUP( fp->value.atom, value ) )\n            goto Exit;\n        }\n        break;\n\n      case BDF_INTEGER:\n        fp->value.l = _bdf_atol( value, 0, 10 );\n        break;\n\n      case BDF_CARDINAL:\n        fp->value.ul = _bdf_atoul( value, 0, 10 );\n        break;\n\n      default:\n        ;\n      }\n\n      goto Exit;\n    }\n\n    /* See whether this property type exists yet or not. */\n    /* If not, create it.                                */\n    hn = hash_lookup( name, &(font->proptbl) );\n    if ( hn == 0 )\n    {\n      error = bdf_create_property( name, BDF_ATOM, font );\n      if ( error )\n        goto Exit;\n      hn = hash_lookup( name, &(font->proptbl) );\n    }\n\n    /* Allocate another property if this is overflow. */\n    if ( font->props_used == font->props_size )\n    {\n      if ( font->props_size == 0 )\n      {\n        if ( FT_NEW_ARRAY( font->props, 1 ) )\n          goto Exit;\n      }\n      else\n      {\n        if ( FT_RENEW_ARRAY( font->props,\n                             font->props_size,\n                             font->props_size + 1 ) )\n          goto Exit;\n      }\n\n      fp = font->props + font->props_size;\n      FT_MEM_ZERO( fp, sizeof ( bdf_property_t ) );\n      font->props_size++;\n    }\n\n    propid = hn->data;\n    if ( propid >= _num_bdf_properties )\n      prop = font->user_props + ( propid - _num_bdf_properties );\n    else\n      prop = (bdf_property_t*)_bdf_properties + propid;\n\n    fp = font->props + font->props_used;\n\n    fp->name    = prop->name;\n    fp->format  = prop->format;\n    fp->builtin = prop->builtin;\n\n    switch ( prop->format )\n    {\n    case BDF_ATOM:\n      fp->value.atom = 0;\n      if ( value != 0 && value[0] )\n      {\n        if ( FT_STRDUP( fp->value.atom, value ) )\n          goto Exit;\n      }\n      break;\n\n    case BDF_INTEGER:\n      fp->value.l = _bdf_atol( value, 0, 10 );\n      break;\n\n    case BDF_CARDINAL:\n      fp->value.ul = _bdf_atoul( value, 0, 10 );\n      break;\n    }\n\n    /* If the property happens to be a comment, then it doesn't need */\n    /* to be added to the internal hash table.                       */\n    if ( ft_strncmp( name, \"COMMENT\", 7 ) != 0 )\n    {\n      /* Add the property to the font property table. */\n      error = hash_insert( fp->name,\n                           font->props_used,\n                           (hashtable *)font->internal,\n                           memory );\n      if ( error )\n        goto Exit;\n    }\n\n    font->props_used++;\n\n    /* Some special cases need to be handled here.  The DEFAULT_CHAR       */\n    /* property needs to be located if it exists in the property list, the */\n    /* FONT_ASCENT and FONT_DESCENT need to be assigned if they are        */\n    /* present, and the SPACING property should override the default       */\n    /* spacing.                                                            */\n    if ( ft_strncmp( name, \"DEFAULT_CHAR\", 12 ) == 0 )\n      font->default_char = fp->value.l;\n    else if ( ft_strncmp( name, \"FONT_ASCENT\", 11 ) == 0 )\n      font->font_ascent = fp->value.l;\n    else if ( ft_strncmp( name, \"FONT_DESCENT\", 12 ) == 0 )\n      font->font_descent = fp->value.l;\n    else if ( ft_strncmp( name, \"SPACING\", 7 ) == 0 )\n    {\n      if ( !fp->value.atom )\n      {\n        FT_ERROR(( \"_bdf_add_property: \" ERRMSG8, lineno, \"SPACING\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      if ( fp->value.atom[0] == 'p' || fp->value.atom[0] == 'P' )\n        font->spacing = BDF_PROPORTIONAL;\n      else if ( fp->value.atom[0] == 'm' || fp->value.atom[0] == 'M' )\n        font->spacing = BDF_MONOWIDTH;\n      else if ( fp->value.atom[0] == 'c' || fp->value.atom[0] == 'C' )\n        font->spacing = BDF_CHARCELL;\n    }\n\n  Exit:\n    return error;\n  }",
        "func": "static FT_Error\n  _bdf_add_property( bdf_font_t*    font,\n                     char*          name,\n                     char*          value,\n                     unsigned long  lineno )\n  {\n    size_t          propid;\n    hashnode        hn;\n    bdf_property_t  *prop, *fp;\n    FT_Memory       memory = font->memory;\n    FT_Error        error  = FT_Err_Ok;\n\n    FT_UNUSED( lineno );        /* only used in debug mode */\n\n\n    /* First, check whether the property already exists in the font. */\n    if ( ( hn = hash_lookup( name, (hashtable *)font->internal ) ) != 0 )\n    {\n      /* The property already exists in the font, so simply replace */\n      /* the value of the property with the current value.          */\n      fp = font->props + hn->data;\n\n      switch ( fp->format )\n      {\n      case BDF_ATOM:\n        /* Delete the current atom if it exists. */\n        FT_FREE( fp->value.atom );\n\n        if ( value && value[0] != 0 )\n        {\n          if ( FT_STRDUP( fp->value.atom, value ) )\n            goto Exit;\n        }\n        break;\n\n      case BDF_INTEGER:\n        fp->value.l = _bdf_atol( value, 0, 10 );\n        break;\n\n      case BDF_CARDINAL:\n        fp->value.ul = _bdf_atoul( value, 0, 10 );\n        break;\n\n      default:\n        ;\n      }\n\n      goto Exit;\n    }\n\n    /* See whether this property type exists yet or not. */\n    /* If not, create it.                                */\n    hn = hash_lookup( name, &(font->proptbl) );\n    if ( hn == 0 )\n    {\n      error = bdf_create_property( name, BDF_ATOM, font );\n      if ( error )\n        goto Exit;\n      hn = hash_lookup( name, &(font->proptbl) );\n    }\n\n    /* Allocate another property if this is overflow. */\n    if ( font->props_used == font->props_size )\n    {\n      if ( font->props_size == 0 )\n      {\n        if ( FT_NEW_ARRAY( font->props, 1 ) )\n          goto Exit;\n      }\n      else\n      {\n        if ( FT_RENEW_ARRAY( font->props,\n                             font->props_size,\n                             font->props_size + 1 ) )\n          goto Exit;\n      }\n\n      fp = font->props + font->props_size;\n      FT_MEM_ZERO( fp, sizeof ( bdf_property_t ) );\n      font->props_size++;\n    }\n\n    propid = hn->data;\n    if ( propid >= _num_bdf_properties )\n      prop = font->user_props + ( propid - _num_bdf_properties );\n    else\n      prop = (bdf_property_t*)_bdf_properties + propid;\n\n    fp = font->props + font->props_used;\n\n    fp->name    = prop->name;\n    fp->format  = prop->format;\n    fp->builtin = prop->builtin;\n\n    switch ( prop->format )\n    {\n    case BDF_ATOM:\n      fp->value.atom = 0;\n      if ( value != 0 && value[0] )\n      {\n        if ( FT_STRDUP( fp->value.atom, value ) )\n          goto Exit;\n      }\n      break;\n\n    case BDF_INTEGER:\n      fp->value.l = _bdf_atol( value, 0, 10 );\n      break;\n\n    case BDF_CARDINAL:\n      fp->value.ul = _bdf_atoul( value, 0, 10 );\n      break;\n    }\n\n    /* If the property happens to be a comment, then it doesn't need */\n    /* to be added to the internal hash table.                       */\n    if ( _bdf_strncmp( name, \"COMMENT\", 7 ) != 0 )\n    {\n      /* Add the property to the font property table. */\n      error = hash_insert( fp->name,\n                           font->props_used,\n                           (hashtable *)font->internal,\n                           memory );\n      if ( error )\n        goto Exit;\n    }\n\n    font->props_used++;\n\n    /* Some special cases need to be handled here.  The DEFAULT_CHAR       */\n    /* property needs to be located if it exists in the property list, the */\n    /* FONT_ASCENT and FONT_DESCENT need to be assigned if they are        */\n    /* present, and the SPACING property should override the default       */\n    /* spacing.                                                            */\n    if ( _bdf_strncmp( name, \"DEFAULT_CHAR\", 12 ) == 0 )\n      font->default_char = fp->value.l;\n    else if ( _bdf_strncmp( name, \"FONT_ASCENT\", 11 ) == 0 )\n      font->font_ascent = fp->value.l;\n    else if ( _bdf_strncmp( name, \"FONT_DESCENT\", 12 ) == 0 )\n      font->font_descent = fp->value.l;\n    else if ( _bdf_strncmp( name, \"SPACING\", 7 ) == 0 )\n    {\n      if ( !fp->value.atom )\n      {\n        FT_ERROR(( \"_bdf_add_property: \" ERRMSG8, lineno, \"SPACING\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      if ( fp->value.atom[0] == 'p' || fp->value.atom[0] == 'P' )\n        font->spacing = BDF_PROPORTIONAL;\n      else if ( fp->value.atom[0] == 'm' || fp->value.atom[0] == 'M' )\n        font->spacing = BDF_MONOWIDTH;\n      else if ( fp->value.atom[0] == 'c' || fp->value.atom[0] == 'C' )\n        font->spacing = BDF_CHARCELL;\n    }\n\n  Exit:\n    return error;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -114,7 +114,7 @@\n \n     /* If the property happens to be a comment, then it doesn't need */\n     /* to be added to the internal hash table.                       */\n-    if ( ft_strncmp( name, \"COMMENT\", 7 ) != 0 )\n+    if ( _bdf_strncmp( name, \"COMMENT\", 7 ) != 0 )\n     {\n       /* Add the property to the font property table. */\n       error = hash_insert( fp->name,\n@@ -132,13 +132,13 @@\n     /* FONT_ASCENT and FONT_DESCENT need to be assigned if they are        */\n     /* present, and the SPACING property should override the default       */\n     /* spacing.                                                            */\n-    if ( ft_strncmp( name, \"DEFAULT_CHAR\", 12 ) == 0 )\n+    if ( _bdf_strncmp( name, \"DEFAULT_CHAR\", 12 ) == 0 )\n       font->default_char = fp->value.l;\n-    else if ( ft_strncmp( name, \"FONT_ASCENT\", 11 ) == 0 )\n+    else if ( _bdf_strncmp( name, \"FONT_ASCENT\", 11 ) == 0 )\n       font->font_ascent = fp->value.l;\n-    else if ( ft_strncmp( name, \"FONT_DESCENT\", 12 ) == 0 )\n+    else if ( _bdf_strncmp( name, \"FONT_DESCENT\", 12 ) == 0 )\n       font->font_descent = fp->value.l;\n-    else if ( ft_strncmp( name, \"SPACING\", 7 ) == 0 )\n+    else if ( _bdf_strncmp( name, \"SPACING\", 7 ) == 0 )\n     {\n       if ( !fp->value.atom )\n       {",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( ft_strncmp( name, \"COMMENT\", 7 ) != 0 )",
                "    if ( ft_strncmp( name, \"DEFAULT_CHAR\", 12 ) == 0 )",
                "    else if ( ft_strncmp( name, \"FONT_ASCENT\", 11 ) == 0 )",
                "    else if ( ft_strncmp( name, \"FONT_DESCENT\", 12 ) == 0 )",
                "    else if ( ft_strncmp( name, \"SPACING\", 7 ) == 0 )"
            ],
            "added_lines": [
                "    if ( _bdf_strncmp( name, \"COMMENT\", 7 ) != 0 )",
                "    if ( _bdf_strncmp( name, \"DEFAULT_CHAR\", 12 ) == 0 )",
                "    else if ( _bdf_strncmp( name, \"FONT_ASCENT\", 11 ) == 0 )",
                "    else if ( _bdf_strncmp( name, \"FONT_DESCENT\", 12 ) == 0 )",
                "    else if ( _bdf_strncmp( name, \"SPACING\", 7 ) == 0 )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9675",
        "func_name": "freetype/freetype2/_bdf_parse_start",
        "description": "bdf/bdflib.c in FreeType before 2.5.4 identifies property names by only verifying that an initial substring is present, which allows remote attackers to discover heap pointer values and bypass the ASLR protection mechanism via a crafted BDF font.",
        "git_url": "http://git.savannah.gnu.org/cgit/freetype/freetype2.git/commit/?id=2c4832d30939b45c05757f0a05128ce64c4cacc7",
        "commit_title": "* src/bdf/bdflib.c (_bdf_strncmp): New macro that checks one",
        "commit_text": "character more than `strncmp'. s/ft_strncmp/_bdf_strncmp/ everywhere. ",
        "func_before": "static FT_Error\n  _bdf_parse_start( char*          line,\n                    unsigned long  linelen,\n                    unsigned long  lineno,\n                    void*          call_data,\n                    void*          client_data )\n  {\n    unsigned long      slen;\n    _bdf_line_func_t*  next;\n    _bdf_parse_t*      p;\n    bdf_font_t*        font;\n    char               *s;\n\n    FT_Memory          memory = NULL;\n    FT_Error           error  = FT_Err_Ok;\n\n    FT_UNUSED( lineno );            /* only used in debug mode */\n\n\n    next = (_bdf_line_func_t *)call_data;\n    p    = (_bdf_parse_t *)    client_data;\n\n    if ( p->font )\n      memory = p->font->memory;\n\n    /* Check for a comment.  This is done to handle those fonts that have */\n    /* comments before the STARTFONT line for some reason.                */\n    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )\n    {\n      if ( p->opts->keep_comments != 0 && p->font != 0 )\n      {\n        linelen -= 7;\n\n        s = line + 7;\n        if ( *s != 0 )\n        {\n          s++;\n          linelen--;\n        }\n\n        error = _bdf_add_comment( p->font, s, linelen );\n        if ( error )\n          goto Exit;\n        /* here font is not defined! */\n      }\n\n      goto Exit;\n    }\n\n    if ( !( p->flags & _BDF_START ) )\n    {\n      memory = p->memory;\n\n      if ( ft_strncmp( line, \"STARTFONT\", 9 ) != 0 )\n      {\n        /* we don't emit an error message since this code gets */\n        /* explicitly caught one level higher                  */\n        error = FT_THROW( Missing_Startfont_Field );\n        goto Exit;\n      }\n\n      p->flags = _BDF_START;\n      font = p->font = 0;\n\n      if ( FT_NEW( font ) )\n        goto Exit;\n      p->font = font;\n\n      font->memory = p->memory;\n      p->memory    = 0;\n\n      { /* setup */\n        size_t           i;\n        bdf_property_t*  prop;\n\n\n        error = hash_init( &(font->proptbl), memory );\n        if ( error )\n          goto Exit;\n        for ( i = 0, prop = (bdf_property_t*)_bdf_properties;\n              i < _num_bdf_properties; i++, prop++ )\n        {\n          error = hash_insert( prop->name, i,\n                               &(font->proptbl), memory );\n          if ( error )\n            goto Exit;\n        }\n      }\n\n      if ( FT_ALLOC( p->font->internal, sizeof ( hashtable ) ) )\n        goto Exit;\n      error = hash_init( (hashtable *)p->font->internal,memory );\n      if ( error )\n        goto Exit;\n      p->font->spacing      = p->opts->font_spacing;\n      p->font->default_char = -1;\n\n      goto Exit;\n    }\n\n    /* Check for the start of the properties. */\n    if ( ft_strncmp( line, \"STARTPROPERTIES\", 15 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_FONT_BBX ) )\n      {\n        /* Missing the FONTBOUNDINGBOX field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"FONTBOUNDINGBOX\" ));\n        error = FT_THROW( Missing_Fontboundingbox_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      /* at this point, `p->font' can't be NULL */\n      p->cnt = p->font->props_size = _bdf_atoul( p->list.field[1], 0, 10 );\n\n      if ( FT_NEW_ARRAY( p->font->props, p->cnt ) )\n      {\n        p->font->props_size = 0;\n        goto Exit;\n      }\n\n      p->flags |= _BDF_PROPS;\n      *next     = _bdf_parse_properties;\n\n      goto Exit;\n    }\n\n    /* Check for the FONTBOUNDINGBOX field. */\n    if ( ft_strncmp( line, \"FONTBOUNDINGBOX\", 15 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_SIZE ) )\n      {\n        /* Missing the SIZE field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"SIZE\" ));\n        error = FT_THROW( Missing_Size_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      p->font->bbx.width  = _bdf_atos( p->list.field[1], 0, 10 );\n      p->font->bbx.height = _bdf_atos( p->list.field[2], 0, 10 );\n\n      p->font->bbx.x_offset = _bdf_atos( p->list.field[3], 0, 10 );\n      p->font->bbx.y_offset = _bdf_atos( p->list.field[4], 0, 10 );\n\n      p->font->bbx.ascent  = (short)( p->font->bbx.height +\n                                      p->font->bbx.y_offset );\n\n      p->font->bbx.descent = (short)( -p->font->bbx.y_offset );\n\n      p->flags |= _BDF_FONT_BBX;\n\n      goto Exit;\n    }\n\n    /* The next thing to check for is the FONT field. */\n    if ( ft_strncmp( line, \"FONT\", 4 ) == 0 )\n    {\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      _bdf_list_shift( &p->list, 1 );\n\n      s = _bdf_list_join( &p->list, ' ', &slen );\n\n      if ( !s )\n      {\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG8, lineno, \"FONT\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      /* Allowing multiple `FONT' lines (which is invalid) doesn't hurt... */\n      FT_FREE( p->font->name );\n\n      if ( FT_NEW_ARRAY( p->font->name, slen + 1 ) )\n        goto Exit;\n      FT_MEM_COPY( p->font->name, s, slen + 1 );\n\n      /* If the font name is an XLFD name, set the spacing to the one in  */\n      /* the font name.  If there is no spacing fall back on the default. */\n      error = _bdf_set_default_spacing( p->font, p->opts, lineno );\n      if ( error )\n        goto Exit;\n\n      p->flags |= _BDF_FONT_NAME;\n\n      goto Exit;\n    }\n\n    /* Check for the SIZE field. */\n    if ( ft_strncmp( line, \"SIZE\", 4 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_FONT_NAME ) )\n      {\n        /* Missing the FONT field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"FONT\" ));\n        error = FT_THROW( Missing_Font_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      p->font->point_size   = _bdf_atoul( p->list.field[1], 0, 10 );\n      p->font->resolution_x = _bdf_atoul( p->list.field[2], 0, 10 );\n      p->font->resolution_y = _bdf_atoul( p->list.field[3], 0, 10 );\n\n      /* Check for the bits per pixel field. */\n      if ( p->list.used == 5 )\n      {\n        unsigned short bitcount, i, shift;\n\n\n        p->font->bpp = (unsigned short)_bdf_atos( p->list.field[4], 0, 10 );\n\n        /* Only values 1, 2, 4, 8 are allowed. */\n        shift = p->font->bpp;\n        bitcount = 0;\n        for ( i = 0; shift > 0; i++ )\n        {\n          if ( shift & 1 )\n            bitcount = i;\n          shift >>= 1;\n        }\n\n        shift = (short)( ( bitcount > 3 ) ? 8 : ( 1 << bitcount ) );\n\n        if ( p->font->bpp > shift || p->font->bpp != shift )\n        {\n          /* select next higher value */\n          p->font->bpp = (unsigned short)( shift << 1 );\n          FT_TRACE2(( \"_bdf_parse_start: \" ACMSG11, p->font->bpp ));\n        }\n      }\n      else\n        p->font->bpp = 1;\n\n      p->flags |= _BDF_SIZE;\n\n      goto Exit;\n    }\n\n    /* Check for the CHARS field -- font properties are optional */\n    if ( ft_strncmp( line, \"CHARS\", 5 ) == 0 )\n    {\n      char  nbuf[128];\n\n\n      if ( !( p->flags & _BDF_FONT_BBX ) )\n      {\n        /* Missing the FONTBOUNDINGBOX field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"FONTBOUNDINGBOX\" ));\n        error = FT_THROW( Missing_Fontboundingbox_Field );\n        goto Exit;\n      }\n\n      /* Add the two standard X11 properties which are required */\n      /* for compiling fonts.                                   */\n      p->font->font_ascent = p->font->bbx.ascent;\n      ft_sprintf( nbuf, \"%hd\", p->font->bbx.ascent );\n      error = _bdf_add_property( p->font, (char *)\"FONT_ASCENT\",\n                                 nbuf, lineno );\n      if ( error )\n        goto Exit;\n      FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG1, p->font->bbx.ascent ));\n\n      p->font->font_descent = p->font->bbx.descent;\n      ft_sprintf( nbuf, \"%hd\", p->font->bbx.descent );\n      error = _bdf_add_property( p->font, (char *)\"FONT_DESCENT\",\n                                 nbuf, lineno );\n      if ( error )\n        goto Exit;\n      FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG2, p->font->bbx.descent ));\n\n      p->font->modified = 1;\n\n      *next = _bdf_parse_glyphs;\n\n      /* A special return value. */\n      error = -1;\n      goto Exit;\n    }\n\n    FT_ERROR(( \"_bdf_parse_start: \" ERRMSG9, lineno ));\n    error = FT_THROW( Invalid_File_Format );\n\n  Exit:\n    return error;\n  }",
        "func": "static FT_Error\n  _bdf_parse_start( char*          line,\n                    unsigned long  linelen,\n                    unsigned long  lineno,\n                    void*          call_data,\n                    void*          client_data )\n  {\n    unsigned long      slen;\n    _bdf_line_func_t*  next;\n    _bdf_parse_t*      p;\n    bdf_font_t*        font;\n    char               *s;\n\n    FT_Memory          memory = NULL;\n    FT_Error           error  = FT_Err_Ok;\n\n    FT_UNUSED( lineno );            /* only used in debug mode */\n\n\n    next = (_bdf_line_func_t *)call_data;\n    p    = (_bdf_parse_t *)    client_data;\n\n    if ( p->font )\n      memory = p->font->memory;\n\n    /* Check for a comment.  This is done to handle those fonts that have */\n    /* comments before the STARTFONT line for some reason.                */\n    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )\n    {\n      if ( p->opts->keep_comments != 0 && p->font != 0 )\n      {\n        linelen -= 7;\n\n        s = line + 7;\n        if ( *s != 0 )\n        {\n          s++;\n          linelen--;\n        }\n\n        error = _bdf_add_comment( p->font, s, linelen );\n        if ( error )\n          goto Exit;\n        /* here font is not defined! */\n      }\n\n      goto Exit;\n    }\n\n    if ( !( p->flags & _BDF_START ) )\n    {\n      memory = p->memory;\n\n      if ( _bdf_strncmp( line, \"STARTFONT\", 9 ) != 0 )\n      {\n        /* we don't emit an error message since this code gets */\n        /* explicitly caught one level higher                  */\n        error = FT_THROW( Missing_Startfont_Field );\n        goto Exit;\n      }\n\n      p->flags = _BDF_START;\n      font = p->font = 0;\n\n      if ( FT_NEW( font ) )\n        goto Exit;\n      p->font = font;\n\n      font->memory = p->memory;\n      p->memory    = 0;\n\n      { /* setup */\n        size_t           i;\n        bdf_property_t*  prop;\n\n\n        error = hash_init( &(font->proptbl), memory );\n        if ( error )\n          goto Exit;\n        for ( i = 0, prop = (bdf_property_t*)_bdf_properties;\n              i < _num_bdf_properties; i++, prop++ )\n        {\n          error = hash_insert( prop->name, i,\n                               &(font->proptbl), memory );\n          if ( error )\n            goto Exit;\n        }\n      }\n\n      if ( FT_ALLOC( p->font->internal, sizeof ( hashtable ) ) )\n        goto Exit;\n      error = hash_init( (hashtable *)p->font->internal,memory );\n      if ( error )\n        goto Exit;\n      p->font->spacing      = p->opts->font_spacing;\n      p->font->default_char = -1;\n\n      goto Exit;\n    }\n\n    /* Check for the start of the properties. */\n    if ( _bdf_strncmp( line, \"STARTPROPERTIES\", 15 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_FONT_BBX ) )\n      {\n        /* Missing the FONTBOUNDINGBOX field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"FONTBOUNDINGBOX\" ));\n        error = FT_THROW( Missing_Fontboundingbox_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      /* at this point, `p->font' can't be NULL */\n      p->cnt = p->font->props_size = _bdf_atoul( p->list.field[1], 0, 10 );\n\n      if ( FT_NEW_ARRAY( p->font->props, p->cnt ) )\n      {\n        p->font->props_size = 0;\n        goto Exit;\n      }\n\n      p->flags |= _BDF_PROPS;\n      *next     = _bdf_parse_properties;\n\n      goto Exit;\n    }\n\n    /* Check for the FONTBOUNDINGBOX field. */\n    if ( _bdf_strncmp( line, \"FONTBOUNDINGBOX\", 15 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_SIZE ) )\n      {\n        /* Missing the SIZE field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"SIZE\" ));\n        error = FT_THROW( Missing_Size_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      p->font->bbx.width  = _bdf_atos( p->list.field[1], 0, 10 );\n      p->font->bbx.height = _bdf_atos( p->list.field[2], 0, 10 );\n\n      p->font->bbx.x_offset = _bdf_atos( p->list.field[3], 0, 10 );\n      p->font->bbx.y_offset = _bdf_atos( p->list.field[4], 0, 10 );\n\n      p->font->bbx.ascent  = (short)( p->font->bbx.height +\n                                      p->font->bbx.y_offset );\n\n      p->font->bbx.descent = (short)( -p->font->bbx.y_offset );\n\n      p->flags |= _BDF_FONT_BBX;\n\n      goto Exit;\n    }\n\n    /* The next thing to check for is the FONT field. */\n    if ( _bdf_strncmp( line, \"FONT\", 4 ) == 0 )\n    {\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      _bdf_list_shift( &p->list, 1 );\n\n      s = _bdf_list_join( &p->list, ' ', &slen );\n\n      if ( !s )\n      {\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG8, lineno, \"FONT\" ));\n        error = FT_THROW( Invalid_File_Format );\n        goto Exit;\n      }\n\n      /* Allowing multiple `FONT' lines (which is invalid) doesn't hurt... */\n      FT_FREE( p->font->name );\n\n      if ( FT_NEW_ARRAY( p->font->name, slen + 1 ) )\n        goto Exit;\n      FT_MEM_COPY( p->font->name, s, slen + 1 );\n\n      /* If the font name is an XLFD name, set the spacing to the one in  */\n      /* the font name.  If there is no spacing fall back on the default. */\n      error = _bdf_set_default_spacing( p->font, p->opts, lineno );\n      if ( error )\n        goto Exit;\n\n      p->flags |= _BDF_FONT_NAME;\n\n      goto Exit;\n    }\n\n    /* Check for the SIZE field. */\n    if ( _bdf_strncmp( line, \"SIZE\", 4 ) == 0 )\n    {\n      if ( !( p->flags & _BDF_FONT_NAME ) )\n      {\n        /* Missing the FONT field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"FONT\" ));\n        error = FT_THROW( Missing_Font_Field );\n        goto Exit;\n      }\n\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n\n      p->font->point_size   = _bdf_atoul( p->list.field[1], 0, 10 );\n      p->font->resolution_x = _bdf_atoul( p->list.field[2], 0, 10 );\n      p->font->resolution_y = _bdf_atoul( p->list.field[3], 0, 10 );\n\n      /* Check for the bits per pixel field. */\n      if ( p->list.used == 5 )\n      {\n        unsigned short bitcount, i, shift;\n\n\n        p->font->bpp = (unsigned short)_bdf_atos( p->list.field[4], 0, 10 );\n\n        /* Only values 1, 2, 4, 8 are allowed. */\n        shift = p->font->bpp;\n        bitcount = 0;\n        for ( i = 0; shift > 0; i++ )\n        {\n          if ( shift & 1 )\n            bitcount = i;\n          shift >>= 1;\n        }\n\n        shift = (short)( ( bitcount > 3 ) ? 8 : ( 1 << bitcount ) );\n\n        if ( p->font->bpp > shift || p->font->bpp != shift )\n        {\n          /* select next higher value */\n          p->font->bpp = (unsigned short)( shift << 1 );\n          FT_TRACE2(( \"_bdf_parse_start: \" ACMSG11, p->font->bpp ));\n        }\n      }\n      else\n        p->font->bpp = 1;\n\n      p->flags |= _BDF_SIZE;\n\n      goto Exit;\n    }\n\n    /* Check for the CHARS field -- font properties are optional */\n    if ( _bdf_strncmp( line, \"CHARS\", 5 ) == 0 )\n    {\n      char  nbuf[128];\n\n\n      if ( !( p->flags & _BDF_FONT_BBX ) )\n      {\n        /* Missing the FONTBOUNDINGBOX field. */\n        FT_ERROR(( \"_bdf_parse_start: \" ERRMSG1, lineno, \"FONTBOUNDINGBOX\" ));\n        error = FT_THROW( Missing_Fontboundingbox_Field );\n        goto Exit;\n      }\n\n      /* Add the two standard X11 properties which are required */\n      /* for compiling fonts.                                   */\n      p->font->font_ascent = p->font->bbx.ascent;\n      ft_sprintf( nbuf, \"%hd\", p->font->bbx.ascent );\n      error = _bdf_add_property( p->font, (char *)\"FONT_ASCENT\",\n                                 nbuf, lineno );\n      if ( error )\n        goto Exit;\n      FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG1, p->font->bbx.ascent ));\n\n      p->font->font_descent = p->font->bbx.descent;\n      ft_sprintf( nbuf, \"%hd\", p->font->bbx.descent );\n      error = _bdf_add_property( p->font, (char *)\"FONT_DESCENT\",\n                                 nbuf, lineno );\n      if ( error )\n        goto Exit;\n      FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG2, p->font->bbx.descent ));\n\n      p->font->modified = 1;\n\n      *next = _bdf_parse_glyphs;\n\n      /* A special return value. */\n      error = -1;\n      goto Exit;\n    }\n\n    FT_ERROR(( \"_bdf_parse_start: \" ERRMSG9, lineno ));\n    error = FT_THROW( Invalid_File_Format );\n\n  Exit:\n    return error;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,7 +25,7 @@\n \n     /* Check for a comment.  This is done to handle those fonts that have */\n     /* comments before the STARTFONT line for some reason.                */\n-    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )\n+    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )\n     {\n       if ( p->opts->keep_comments != 0 && p->font != 0 )\n       {\n@@ -51,7 +51,7 @@\n     {\n       memory = p->memory;\n \n-      if ( ft_strncmp( line, \"STARTFONT\", 9 ) != 0 )\n+      if ( _bdf_strncmp( line, \"STARTFONT\", 9 ) != 0 )\n       {\n         /* we don't emit an error message since this code gets */\n         /* explicitly caught one level higher                  */\n@@ -99,7 +99,7 @@\n     }\n \n     /* Check for the start of the properties. */\n-    if ( ft_strncmp( line, \"STARTPROPERTIES\", 15 ) == 0 )\n+    if ( _bdf_strncmp( line, \"STARTPROPERTIES\", 15 ) == 0 )\n     {\n       if ( !( p->flags & _BDF_FONT_BBX ) )\n       {\n@@ -128,7 +128,7 @@\n     }\n \n     /* Check for the FONTBOUNDINGBOX field. */\n-    if ( ft_strncmp( line, \"FONTBOUNDINGBOX\", 15 ) == 0 )\n+    if ( _bdf_strncmp( line, \"FONTBOUNDINGBOX\", 15 ) == 0 )\n     {\n       if ( !( p->flags & _BDF_SIZE ) )\n       {\n@@ -159,7 +159,7 @@\n     }\n \n     /* The next thing to check for is the FONT field. */\n-    if ( ft_strncmp( line, \"FONT\", 4 ) == 0 )\n+    if ( _bdf_strncmp( line, \"FONT\", 4 ) == 0 )\n     {\n       error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n       if ( error )\n@@ -194,7 +194,7 @@\n     }\n \n     /* Check for the SIZE field. */\n-    if ( ft_strncmp( line, \"SIZE\", 4 ) == 0 )\n+    if ( _bdf_strncmp( line, \"SIZE\", 4 ) == 0 )\n     {\n       if ( !( p->flags & _BDF_FONT_NAME ) )\n       {\n@@ -248,7 +248,7 @@\n     }\n \n     /* Check for the CHARS field -- font properties are optional */\n-    if ( ft_strncmp( line, \"CHARS\", 5 ) == 0 )\n+    if ( _bdf_strncmp( line, \"CHARS\", 5 ) == 0 )\n     {\n       char  nbuf[128];\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )",
                "      if ( ft_strncmp( line, \"STARTFONT\", 9 ) != 0 )",
                "    if ( ft_strncmp( line, \"STARTPROPERTIES\", 15 ) == 0 )",
                "    if ( ft_strncmp( line, \"FONTBOUNDINGBOX\", 15 ) == 0 )",
                "    if ( ft_strncmp( line, \"FONT\", 4 ) == 0 )",
                "    if ( ft_strncmp( line, \"SIZE\", 4 ) == 0 )",
                "    if ( ft_strncmp( line, \"CHARS\", 5 ) == 0 )"
            ],
            "added_lines": [
                "    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )",
                "      if ( _bdf_strncmp( line, \"STARTFONT\", 9 ) != 0 )",
                "    if ( _bdf_strncmp( line, \"STARTPROPERTIES\", 15 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"FONTBOUNDINGBOX\", 15 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"FONT\", 4 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"SIZE\", 4 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"CHARS\", 5 ) == 0 )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9675",
        "func_name": "freetype/freetype2/_bdf_parse_properties",
        "description": "bdf/bdflib.c in FreeType before 2.5.4 identifies property names by only verifying that an initial substring is present, which allows remote attackers to discover heap pointer values and bypass the ASLR protection mechanism via a crafted BDF font.",
        "git_url": "http://git.savannah.gnu.org/cgit/freetype/freetype2.git/commit/?id=2c4832d30939b45c05757f0a05128ce64c4cacc7",
        "commit_title": "* src/bdf/bdflib.c (_bdf_strncmp): New macro that checks one",
        "commit_text": "character more than `strncmp'. s/ft_strncmp/_bdf_strncmp/ everywhere. ",
        "func_before": "static FT_Error\n  _bdf_parse_properties( char*          line,\n                         unsigned long  linelen,\n                         unsigned long  lineno,\n                         void*          call_data,\n                         void*          client_data )\n  {\n    unsigned long      vlen;\n    _bdf_line_func_t*  next;\n    _bdf_parse_t*      p;\n    char*              name;\n    char*              value;\n    char               nbuf[128];\n    FT_Error           error = FT_Err_Ok;\n\n    FT_UNUSED( lineno );\n\n\n    next = (_bdf_line_func_t *)call_data;\n    p    = (_bdf_parse_t *)    client_data;\n\n    /* Check for the end of the properties. */\n    if ( ft_strncmp( line, \"ENDPROPERTIES\", 13 ) == 0 )\n    {\n      /* If the FONT_ASCENT or FONT_DESCENT properties have not been      */\n      /* encountered yet, then make sure they are added as properties and */\n      /* make sure they are set from the font bounding box info.          */\n      /*                                                                  */\n      /* This is *always* done regardless of the options, because X11     */\n      /* requires these two fields to compile fonts.                      */\n      if ( bdf_get_font_property( p->font, \"FONT_ASCENT\" ) == 0 )\n      {\n        p->font->font_ascent = p->font->bbx.ascent;\n        ft_sprintf( nbuf, \"%hd\", p->font->bbx.ascent );\n        error = _bdf_add_property( p->font, (char *)\"FONT_ASCENT\",\n                                   nbuf, lineno );\n        if ( error )\n          goto Exit;\n\n        FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG1, p->font->bbx.ascent ));\n        p->font->modified = 1;\n      }\n\n      if ( bdf_get_font_property( p->font, \"FONT_DESCENT\" ) == 0 )\n      {\n        p->font->font_descent = p->font->bbx.descent;\n        ft_sprintf( nbuf, \"%hd\", p->font->bbx.descent );\n        error = _bdf_add_property( p->font, (char *)\"FONT_DESCENT\",\n                                   nbuf, lineno );\n        if ( error )\n          goto Exit;\n\n        FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG2, p->font->bbx.descent ));\n        p->font->modified = 1;\n      }\n\n      p->flags &= ~_BDF_PROPS;\n      *next     = _bdf_parse_glyphs;\n\n      goto Exit;\n    }\n\n    /* Ignore the _XFREE86_GLYPH_RANGES properties. */\n    if ( ft_strncmp( line, \"_XFREE86_GLYPH_RANGES\", 21 ) == 0 )\n      goto Exit;\n\n    /* Handle COMMENT fields and properties in a special way to preserve */\n    /* the spacing.                                                      */\n    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )\n    {\n      name = value = line;\n      value += 7;\n      if ( *value )\n        *value++ = 0;\n      error = _bdf_add_property( p->font, name, value, lineno );\n      if ( error )\n        goto Exit;\n    }\n    else if ( _bdf_is_atom( line, linelen, &name, &value, p->font ) )\n    {\n      error = _bdf_add_property( p->font, name, value, lineno );\n      if ( error )\n        goto Exit;\n    }\n    else\n    {\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      name = p->list.field[0];\n\n      _bdf_list_shift( &p->list, 1 );\n      value = _bdf_list_join( &p->list, ' ', &vlen );\n\n      error = _bdf_add_property( p->font, name, value, lineno );\n      if ( error )\n        goto Exit;\n    }\n\n  Exit:\n    return error;\n  }",
        "func": "static FT_Error\n  _bdf_parse_properties( char*          line,\n                         unsigned long  linelen,\n                         unsigned long  lineno,\n                         void*          call_data,\n                         void*          client_data )\n  {\n    unsigned long      vlen;\n    _bdf_line_func_t*  next;\n    _bdf_parse_t*      p;\n    char*              name;\n    char*              value;\n    char               nbuf[128];\n    FT_Error           error = FT_Err_Ok;\n\n    FT_UNUSED( lineno );\n\n\n    next = (_bdf_line_func_t *)call_data;\n    p    = (_bdf_parse_t *)    client_data;\n\n    /* Check for the end of the properties. */\n    if ( _bdf_strncmp( line, \"ENDPROPERTIES\", 13 ) == 0 )\n    {\n      /* If the FONT_ASCENT or FONT_DESCENT properties have not been      */\n      /* encountered yet, then make sure they are added as properties and */\n      /* make sure they are set from the font bounding box info.          */\n      /*                                                                  */\n      /* This is *always* done regardless of the options, because X11     */\n      /* requires these two fields to compile fonts.                      */\n      if ( bdf_get_font_property( p->font, \"FONT_ASCENT\" ) == 0 )\n      {\n        p->font->font_ascent = p->font->bbx.ascent;\n        ft_sprintf( nbuf, \"%hd\", p->font->bbx.ascent );\n        error = _bdf_add_property( p->font, (char *)\"FONT_ASCENT\",\n                                   nbuf, lineno );\n        if ( error )\n          goto Exit;\n\n        FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG1, p->font->bbx.ascent ));\n        p->font->modified = 1;\n      }\n\n      if ( bdf_get_font_property( p->font, \"FONT_DESCENT\" ) == 0 )\n      {\n        p->font->font_descent = p->font->bbx.descent;\n        ft_sprintf( nbuf, \"%hd\", p->font->bbx.descent );\n        error = _bdf_add_property( p->font, (char *)\"FONT_DESCENT\",\n                                   nbuf, lineno );\n        if ( error )\n          goto Exit;\n\n        FT_TRACE2(( \"_bdf_parse_properties: \" ACMSG2, p->font->bbx.descent ));\n        p->font->modified = 1;\n      }\n\n      p->flags &= ~_BDF_PROPS;\n      *next     = _bdf_parse_glyphs;\n\n      goto Exit;\n    }\n\n    /* Ignore the _XFREE86_GLYPH_RANGES properties. */\n    if ( _bdf_strncmp( line, \"_XFREE86_GLYPH_RANGES\", 21 ) == 0 )\n      goto Exit;\n\n    /* Handle COMMENT fields and properties in a special way to preserve */\n    /* the spacing.                                                      */\n    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )\n    {\n      name = value = line;\n      value += 7;\n      if ( *value )\n        *value++ = 0;\n      error = _bdf_add_property( p->font, name, value, lineno );\n      if ( error )\n        goto Exit;\n    }\n    else if ( _bdf_is_atom( line, linelen, &name, &value, p->font ) )\n    {\n      error = _bdf_add_property( p->font, name, value, lineno );\n      if ( error )\n        goto Exit;\n    }\n    else\n    {\n      error = _bdf_list_split( &p->list, (char *)\" +\", line, linelen );\n      if ( error )\n        goto Exit;\n      name = p->list.field[0];\n\n      _bdf_list_shift( &p->list, 1 );\n      value = _bdf_list_join( &p->list, ' ', &vlen );\n\n      error = _bdf_add_property( p->font, name, value, lineno );\n      if ( error )\n        goto Exit;\n    }\n\n  Exit:\n    return error;\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,7 +20,7 @@\n     p    = (_bdf_parse_t *)    client_data;\n \n     /* Check for the end of the properties. */\n-    if ( ft_strncmp( line, \"ENDPROPERTIES\", 13 ) == 0 )\n+    if ( _bdf_strncmp( line, \"ENDPROPERTIES\", 13 ) == 0 )\n     {\n       /* If the FONT_ASCENT or FONT_DESCENT properties have not been      */\n       /* encountered yet, then make sure they are added as properties and */\n@@ -61,12 +61,12 @@\n     }\n \n     /* Ignore the _XFREE86_GLYPH_RANGES properties. */\n-    if ( ft_strncmp( line, \"_XFREE86_GLYPH_RANGES\", 21 ) == 0 )\n+    if ( _bdf_strncmp( line, \"_XFREE86_GLYPH_RANGES\", 21 ) == 0 )\n       goto Exit;\n \n     /* Handle COMMENT fields and properties in a special way to preserve */\n     /* the spacing.                                                      */\n-    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )\n+    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )\n     {\n       name = value = line;\n       value += 7;",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( ft_strncmp( line, \"ENDPROPERTIES\", 13 ) == 0 )",
                "    if ( ft_strncmp( line, \"_XFREE86_GLYPH_RANGES\", 21 ) == 0 )",
                "    if ( ft_strncmp( line, \"COMMENT\", 7 ) == 0 )"
            ],
            "added_lines": [
                "    if ( _bdf_strncmp( line, \"ENDPROPERTIES\", 13 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"_XFREE86_GLYPH_RANGES\", 21 ) == 0 )",
                "    if ( _bdf_strncmp( line, \"COMMENT\", 7 ) == 0 )"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1226",
        "func_name": "chromium/DebuggerFunction::InitAgentHost",
        "description": "The DebuggerFunction::InitAgentHost function in browser/extensions/api/debugger/debugger_api.cc in Google Chrome before 41.0.2272.76 does not properly restrict what URLs are available as debugger targets, which allows remote attackers to bypass intended access restrictions via a crafted extension.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/409bf9d6104f83c80cd85bd261784b39cab8e93e",
        "commit_title": "Validate debuggee.targetId before use in chrome.debugger",
        "commit_text": " And refactored the tests to make sure that the debugger is detached upon returning from RunAttachFunction. Previously, if the debugger unexpectedly succeeded in attaching, the method would return (because empty error != some error), causing the attached debugger to not be detached.    ",
        "func_before": "bool DebuggerFunction::InitAgentHost() {\n  if (debuggee_.tab_id) {\n    WebContents* web_contents = NULL;\n    bool result = ExtensionTabUtil::GetTabById(*debuggee_.tab_id,\n                                               GetProfile(),\n                                               include_incognito(),\n                                               NULL,\n                                               NULL,\n                                               &web_contents,\n                                               NULL);\n    if (result && web_contents) {\n      // TODO(rdevlin.cronin) This should definitely be GetLastCommittedURL().\n      GURL url = web_contents->GetVisibleURL();\n      if (PermissionsData::IsRestrictedUrl(url, url, extension(), &error_))\n        return false;\n      agent_host_ = DevToolsAgentHost::GetOrCreateFor(web_contents);\n    }\n  } else if (debuggee_.extension_id) {\n    ExtensionHost* extension_host =\n        ProcessManager::Get(GetProfile())\n            ->GetBackgroundHostForExtension(*debuggee_.extension_id);\n    if (extension_host) {\n      if (PermissionsData::IsRestrictedUrl(extension_host->GetURL(),\n                                           extension_host->GetURL(),\n                                           extension(),\n                                           &error_)) {\n        return false;\n      }\n      agent_host_ =\n          DevToolsAgentHost::GetOrCreateFor(extension_host->host_contents());\n    }\n  } else if (debuggee_.target_id) {\n    agent_host_ = DevToolsAgentHost::GetForId(*debuggee_.target_id);\n  } else {\n    error_ = keys::kInvalidTargetError;\n    return false;\n  }\n\n  if (!agent_host_.get()) {\n    FormatErrorMessage(keys::kNoTargetError);\n    return false;\n  }\n  return true;\n}",
        "func": "bool DebuggerFunction::InitAgentHost() {\n  if (debuggee_.tab_id) {\n    WebContents* web_contents = NULL;\n    bool result = ExtensionTabUtil::GetTabById(*debuggee_.tab_id,\n                                               GetProfile(),\n                                               include_incognito(),\n                                               NULL,\n                                               NULL,\n                                               &web_contents,\n                                               NULL);\n    if (result && web_contents) {\n      // TODO(rdevlin.cronin) This should definitely be GetLastCommittedURL().\n      GURL url = web_contents->GetVisibleURL();\n      if (PermissionsData::IsRestrictedUrl(url, url, extension(), &error_))\n        return false;\n      agent_host_ = DevToolsAgentHost::GetOrCreateFor(web_contents);\n    }\n  } else if (debuggee_.extension_id) {\n    ExtensionHost* extension_host =\n        ProcessManager::Get(GetProfile())\n            ->GetBackgroundHostForExtension(*debuggee_.extension_id);\n    if (extension_host) {\n      if (PermissionsData::IsRestrictedUrl(extension_host->GetURL(),\n                                           extension_host->GetURL(),\n                                           extension(),\n                                           &error_)) {\n        return false;\n      }\n      agent_host_ =\n          DevToolsAgentHost::GetOrCreateFor(extension_host->host_contents());\n    }\n  } else if (debuggee_.target_id) {\n    agent_host_ = DevToolsAgentHost::GetForId(*debuggee_.target_id);\n    if (agent_host_.get()) {\n      if (PermissionsData::IsRestrictedUrl(agent_host_->GetURL(),\n                                           agent_host_->GetURL(),\n                                           extension(),\n                                           &error_)) {\n        agent_host_ = nullptr;\n        return false;\n      }\n    }\n  } else {\n    error_ = keys::kInvalidTargetError;\n    return false;\n  }\n\n  if (!agent_host_.get()) {\n    FormatErrorMessage(keys::kNoTargetError);\n    return false;\n  }\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,6 +31,15 @@\n     }\n   } else if (debuggee_.target_id) {\n     agent_host_ = DevToolsAgentHost::GetForId(*debuggee_.target_id);\n+    if (agent_host_.get()) {\n+      if (PermissionsData::IsRestrictedUrl(agent_host_->GetURL(),\n+                                           agent_host_->GetURL(),\n+                                           extension(),\n+                                           &error_)) {\n+        agent_host_ = nullptr;\n+        return false;\n+      }\n+    }\n   } else {\n     error_ = keys::kInvalidTargetError;\n     return false;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (agent_host_.get()) {",
                "      if (PermissionsData::IsRestrictedUrl(agent_host_->GetURL(),",
                "                                           agent_host_->GetURL(),",
                "                                           extension(),",
                "                                           &error_)) {",
                "        agent_host_ = nullptr;",
                "        return false;",
                "      }",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2150",
        "func_name": "torvalds/linux/command_write",
        "description": "Xen 3.3.x through 4.5.x and the Linux kernel through 3.19.1 do not properly restrict access to PCI command registers, which might allow local guest OS users to cause a denial of service (non-maskable interrupt and host crash) by disabling the (1) memory or (2) I/O decoding for a PCI Express device and then accessing the device, which triggers an Unsupported Request (UR) response.",
        "git_url": "https://github.com/torvalds/linux/commit/af6fc858a35b90e89ea7a7ee58e66628c55c776b",
        "commit_title": "xen-pciback: limit guest control of command register",
        "commit_text": " Otherwise the guest can abuse that control to cause e.g. PCIe Unsupported Request responses by disabling memory and/or I/O decoding and subsequently causing (CPU side) accesses to the respective address ranges, which (depending on system configuration) may be fatal to the host.  Note that to alter any of the bits collected together as PCI_COMMAND_GUEST permissive mode is now required to be enabled globally or on the specific device.  This is CVE-2015-2150 / XSA-120.  Cc: <stable@vger.kernel.org>",
        "func_before": "static int command_write(struct pci_dev *dev, int offset, u16 value, void *data)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint err;\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (!pci_is_enabled(dev) && is_enable_cmd(value)) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable\\n\",\n\t\t\t       pci_name(dev));\n\t\terr = pci_enable_device(dev);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (dev_data)\n\t\t\tdev_data->enable_intx = 1;\n\t} else if (pci_is_enabled(dev) && !is_enable_cmd(value)) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: disable\\n\",\n\t\t\t       pci_name(dev));\n\t\tpci_disable_device(dev);\n\t\tif (dev_data)\n\t\t\tdev_data->enable_intx = 0;\n\t}\n\n\tif (!dev->is_busmaster && is_master_cmd(value)) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: set bus master\\n\",\n\t\t\t       pci_name(dev));\n\t\tpci_set_master(dev);\n\t}\n\n\tif (value & PCI_COMMAND_INVALIDATE) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG\n\t\t\t       DRV_NAME \": %s: enable memory-write-invalidate\\n\",\n\t\t\t       pci_name(dev));\n\t\terr = pci_set_mwi(dev);\n\t\tif (err) {\n\t\t\tpr_warn(\"%s: cannot enable memory-write-invalidate (%d)\\n\",\n\t\t\t\tpci_name(dev), err);\n\t\t\tvalue &= ~PCI_COMMAND_INVALIDATE;\n\t\t}\n\t}\n\n\treturn pci_write_config_word(dev, offset, value);\n}",
        "func": "static int command_write(struct pci_dev *dev, int offset, u16 value, void *data)\n{\n\tstruct xen_pcibk_dev_data *dev_data;\n\tint err;\n\tu16 val;\n\tstruct pci_cmd_info *cmd = data;\n\n\tdev_data = pci_get_drvdata(dev);\n\tif (!pci_is_enabled(dev) && is_enable_cmd(value)) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: enable\\n\",\n\t\t\t       pci_name(dev));\n\t\terr = pci_enable_device(dev);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (dev_data)\n\t\t\tdev_data->enable_intx = 1;\n\t} else if (pci_is_enabled(dev) && !is_enable_cmd(value)) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: disable\\n\",\n\t\t\t       pci_name(dev));\n\t\tpci_disable_device(dev);\n\t\tif (dev_data)\n\t\t\tdev_data->enable_intx = 0;\n\t}\n\n\tif (!dev->is_busmaster && is_master_cmd(value)) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG DRV_NAME \": %s: set bus master\\n\",\n\t\t\t       pci_name(dev));\n\t\tpci_set_master(dev);\n\t}\n\n\tif (value & PCI_COMMAND_INVALIDATE) {\n\t\tif (unlikely(verbose_request))\n\t\t\tprintk(KERN_DEBUG\n\t\t\t       DRV_NAME \": %s: enable memory-write-invalidate\\n\",\n\t\t\t       pci_name(dev));\n\t\terr = pci_set_mwi(dev);\n\t\tif (err) {\n\t\t\tpr_warn(\"%s: cannot enable memory-write-invalidate (%d)\\n\",\n\t\t\t\tpci_name(dev), err);\n\t\t\tvalue &= ~PCI_COMMAND_INVALIDATE;\n\t\t}\n\t}\n\n\tcmd->val = value;\n\n\tif (!permissive && (!dev_data || !dev_data->permissive))\n\t\treturn 0;\n\n\t/* Only allow the guest to control certain bits. */\n\terr = pci_read_config_word(dev, offset, &val);\n\tif (err || val == value)\n\t\treturn err;\n\n\tvalue &= PCI_COMMAND_GUEST;\n\tvalue |= val & ~PCI_COMMAND_GUEST;\n\n\treturn pci_write_config_word(dev, offset, value);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,8 @@\n {\n \tstruct xen_pcibk_dev_data *dev_data;\n \tint err;\n+\tu16 val;\n+\tstruct pci_cmd_info *cmd = data;\n \n \tdev_data = pci_get_drvdata(dev);\n \tif (!pci_is_enabled(dev) && is_enable_cmd(value)) {\n@@ -42,5 +44,18 @@\n \t\t}\n \t}\n \n+\tcmd->val = value;\n+\n+\tif (!permissive && (!dev_data || !dev_data->permissive))\n+\t\treturn 0;\n+\n+\t/* Only allow the guest to control certain bits. */\n+\terr = pci_read_config_word(dev, offset, &val);\n+\tif (err || val == value)\n+\t\treturn err;\n+\n+\tvalue &= PCI_COMMAND_GUEST;\n+\tvalue |= val & ~PCI_COMMAND_GUEST;\n+\n \treturn pci_write_config_word(dev, offset, value);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tu16 val;",
                "\tstruct pci_cmd_info *cmd = data;",
                "\tcmd->val = value;",
                "",
                "\tif (!permissive && (!dev_data || !dev_data->permissive))",
                "\t\treturn 0;",
                "",
                "\t/* Only allow the guest to control certain bits. */",
                "\terr = pci_read_config_word(dev, offset, &val);",
                "\tif (err || val == value)",
                "\t\treturn err;",
                "",
                "\tvalue &= PCI_COMMAND_GUEST;",
                "\tvalue |= val & ~PCI_COMMAND_GUEST;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2150",
        "func_name": "torvalds/linux/command_read",
        "description": "Xen 3.3.x through 4.5.x and the Linux kernel through 3.19.1 do not properly restrict access to PCI command registers, which might allow local guest OS users to cause a denial of service (non-maskable interrupt and host crash) by disabling the (1) memory or (2) I/O decoding for a PCI Express device and then accessing the device, which triggers an Unsupported Request (UR) response.",
        "git_url": "https://github.com/torvalds/linux/commit/af6fc858a35b90e89ea7a7ee58e66628c55c776b",
        "commit_title": "xen-pciback: limit guest control of command register",
        "commit_text": " Otherwise the guest can abuse that control to cause e.g. PCIe Unsupported Request responses by disabling memory and/or I/O decoding and subsequently causing (CPU side) accesses to the respective address ranges, which (depending on system configuration) may be fatal to the host.  Note that to alter any of the bits collected together as PCI_COMMAND_GUEST permissive mode is now required to be enabled globally or on the specific device.  This is CVE-2015-2150 / XSA-120.  Cc: <stable@vger.kernel.org>",
        "func_before": "static int command_read(struct pci_dev *dev, int offset, u16 *value, void *data)\n{\n\tint i;\n\tint ret;\n\n\tret = xen_pcibk_read_config_word(dev, offset, value, data);\n\tif (!pci_is_enabled(dev))\n\t\treturn ret;\n\n\tfor (i = 0; i < PCI_ROM_RESOURCE; i++) {\n\t\tif (dev->resource[i].flags & IORESOURCE_IO)\n\t\t\t*value |= PCI_COMMAND_IO;\n\t\tif (dev->resource[i].flags & IORESOURCE_MEM)\n\t\t\t*value |= PCI_COMMAND_MEMORY;\n\t}\n\n\treturn ret;\n}",
        "func": "static int command_read(struct pci_dev *dev, int offset, u16 *value, void *data)\n{\n\tint ret = pci_read_config_word(dev, offset, value);\n\tconst struct pci_cmd_info *cmd = data;\n\n\t*value &= PCI_COMMAND_GUEST;\n\t*value |= cmd->val & ~PCI_COMMAND_GUEST;\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,18 +1,10 @@\n static int command_read(struct pci_dev *dev, int offset, u16 *value, void *data)\n {\n-\tint i;\n-\tint ret;\n+\tint ret = pci_read_config_word(dev, offset, value);\n+\tconst struct pci_cmd_info *cmd = data;\n \n-\tret = xen_pcibk_read_config_word(dev, offset, value, data);\n-\tif (!pci_is_enabled(dev))\n-\t\treturn ret;\n-\n-\tfor (i = 0; i < PCI_ROM_RESOURCE; i++) {\n-\t\tif (dev->resource[i].flags & IORESOURCE_IO)\n-\t\t\t*value |= PCI_COMMAND_IO;\n-\t\tif (dev->resource[i].flags & IORESOURCE_MEM)\n-\t\t\t*value |= PCI_COMMAND_MEMORY;\n-\t}\n+\t*value &= PCI_COMMAND_GUEST;\n+\t*value |= cmd->val & ~PCI_COMMAND_GUEST;\n \n \treturn ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tint i;",
                "\tint ret;",
                "\tret = xen_pcibk_read_config_word(dev, offset, value, data);",
                "\tif (!pci_is_enabled(dev))",
                "\t\treturn ret;",
                "",
                "\tfor (i = 0; i < PCI_ROM_RESOURCE; i++) {",
                "\t\tif (dev->resource[i].flags & IORESOURCE_IO)",
                "\t\t\t*value |= PCI_COMMAND_IO;",
                "\t\tif (dev->resource[i].flags & IORESOURCE_MEM)",
                "\t\t\t*value |= PCI_COMMAND_MEMORY;",
                "\t}"
            ],
            "added_lines": [
                "\tint ret = pci_read_config_word(dev, offset, value);",
                "\tconst struct pci_cmd_info *cmd = data;",
                "\t*value &= PCI_COMMAND_GUEST;",
                "\t*value |= cmd->val & ~PCI_COMMAND_GUEST;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1593",
        "func_name": "torvalds/linux/randomize_stack_top",
        "description": "The stack randomization feature in the Linux kernel before 3.19.1 on 64-bit platforms uses incorrect data types for the results of bitwise left-shift operations, which makes it easier for attackers to bypass the ASLR protection mechanism by predicting the address of the top of the stack, related to the randomize_stack_top function in fs/binfmt_elf.c and the stack_maxrandom_size function in arch/x86/mm/mmap.c.",
        "git_url": "https://github.com/torvalds/linux/commit/4e7c22d447bb6d7e37bfe39ff658486ae78e8d77",
        "commit_title": "x86, mm/ASLR: Fix stack randomization on 64-bit systems",
        "commit_text": " The issue is that the stack for processes is not properly randomized on 64 bit architectures due to an integer overflow.  The affected function is randomize_stack_top() in file \"fs/binfmt_elf.c\":    static unsigned long randomize_stack_top(unsigned long stack_top)   {            unsigned int random_variable = 0;             if ((current->flags & PF_RANDOMIZE) &&                    !(current->personality & ADDR_NO_RANDOMIZE)) {                    random_variable = get_random_int() & STACK_RND_MASK;                    random_variable <<= PAGE_SHIFT;            }            return PAGE_ALIGN(stack_top) + random_variable;            return PAGE_ALIGN(stack_top) - random_variable;   }  Note that, it declares the \"random_variable\" variable as \"unsigned int\". Since the result of the shifting operation between STACK_RND_MASK (which is 0x3fffff on x86_64, 22 bits) and PAGE_SHIFT (which is 12 on x86_64):  \t  random_variable <<= PAGE_SHIFT;  then the two leftmost bits are dropped when storing the result in the \"random_variable\". This variable shall be at least 34 bits long to hold the (22+12) result.  These two dropped bits have an impact on the entropy of process stack. Concretely, the total stack entropy is reduced by four: from 2^28 to 2^30 (One fourth of expected entropy).  This patch restores back the entropy by correcting the types involved in the operations in the functions randomize_stack_top() and stack_maxrandom_size().  The successful fix can be tested with:    $ for i in `seq 1 10`; do cat /proc/self/maps | grep stack; done   7ffeda566000-7ffeda587000 rw-p 00000000 00:00 0                          [stack]   7fff5a332000-7fff5a353000 rw-p 00000000 00:00 0                          [stack]   7ffcdb7a1000-7ffcdb7c2000 rw-p 00000000 00:00 0                          [stack]   7ffd5e2c4000-7ffd5e2e5000 rw-p 00000000 00:00 0                          [stack]   ...  Once corrected, the leading bytes should be between 7ffc and 7fff, rather than always being 7fff.  [ Rebased, fixed 80 char bugs, cleaned up commit message, added test example and CVE ] Cc: <stable@vger.kernel.org> Cc: Linus Torvalds <torvalds@linux-foundation.org> Cc: Andrew Morton <akpm@linux-foundation.org> Cc: Al Viro <viro@zeniv.linux.org.uk> Link: http://lkml.kernel.org/r/20150214173350.GA18393@www.outflux.net",
        "func_before": "static unsigned long randomize_stack_top(unsigned long stack_top)\n{\n\tunsigned int random_variable = 0;\n\n\tif ((current->flags & PF_RANDOMIZE) &&\n\t\t!(current->personality & ADDR_NO_RANDOMIZE)) {\n\t\trandom_variable = get_random_int() & STACK_RND_MASK;\n\t\trandom_variable <<= PAGE_SHIFT;\n\t}\n#ifdef CONFIG_STACK_GROWSUP\n\treturn PAGE_ALIGN(stack_top) + random_variable;\n#else\n\treturn PAGE_ALIGN(stack_top) - random_variable;\n#endif\n}",
        "func": "static unsigned long randomize_stack_top(unsigned long stack_top)\n{\n\tunsigned long random_variable = 0;\n\n\tif ((current->flags & PF_RANDOMIZE) &&\n\t\t!(current->personality & ADDR_NO_RANDOMIZE)) {\n\t\trandom_variable = (unsigned long) get_random_int();\n\t\trandom_variable &= STACK_RND_MASK;\n\t\trandom_variable <<= PAGE_SHIFT;\n\t}\n#ifdef CONFIG_STACK_GROWSUP\n\treturn PAGE_ALIGN(stack_top) + random_variable;\n#else\n\treturn PAGE_ALIGN(stack_top) - random_variable;\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,11 @@\n static unsigned long randomize_stack_top(unsigned long stack_top)\n {\n-\tunsigned int random_variable = 0;\n+\tunsigned long random_variable = 0;\n \n \tif ((current->flags & PF_RANDOMIZE) &&\n \t\t!(current->personality & ADDR_NO_RANDOMIZE)) {\n-\t\trandom_variable = get_random_int() & STACK_RND_MASK;\n+\t\trandom_variable = (unsigned long) get_random_int();\n+\t\trandom_variable &= STACK_RND_MASK;\n \t\trandom_variable <<= PAGE_SHIFT;\n \t}\n #ifdef CONFIG_STACK_GROWSUP",
        "diff_line_info": {
            "deleted_lines": [
                "\tunsigned int random_variable = 0;",
                "\t\trandom_variable = get_random_int() & STACK_RND_MASK;"
            ],
            "added_lines": [
                "\tunsigned long random_variable = 0;",
                "\t\trandom_variable = (unsigned long) get_random_int();",
                "\t\trandom_variable &= STACK_RND_MASK;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1593",
        "func_name": "torvalds/linux/stack_maxrandom_size",
        "description": "The stack randomization feature in the Linux kernel before 3.19.1 on 64-bit platforms uses incorrect data types for the results of bitwise left-shift operations, which makes it easier for attackers to bypass the ASLR protection mechanism by predicting the address of the top of the stack, related to the randomize_stack_top function in fs/binfmt_elf.c and the stack_maxrandom_size function in arch/x86/mm/mmap.c.",
        "git_url": "https://github.com/torvalds/linux/commit/4e7c22d447bb6d7e37bfe39ff658486ae78e8d77",
        "commit_title": "x86, mm/ASLR: Fix stack randomization on 64-bit systems",
        "commit_text": " The issue is that the stack for processes is not properly randomized on 64 bit architectures due to an integer overflow.  The affected function is randomize_stack_top() in file \"fs/binfmt_elf.c\":    static unsigned long randomize_stack_top(unsigned long stack_top)   {            unsigned int random_variable = 0;             if ((current->flags & PF_RANDOMIZE) &&                    !(current->personality & ADDR_NO_RANDOMIZE)) {                    random_variable = get_random_int() & STACK_RND_MASK;                    random_variable <<= PAGE_SHIFT;            }            return PAGE_ALIGN(stack_top) + random_variable;            return PAGE_ALIGN(stack_top) - random_variable;   }  Note that, it declares the \"random_variable\" variable as \"unsigned int\". Since the result of the shifting operation between STACK_RND_MASK (which is 0x3fffff on x86_64, 22 bits) and PAGE_SHIFT (which is 12 on x86_64):  \t  random_variable <<= PAGE_SHIFT;  then the two leftmost bits are dropped when storing the result in the \"random_variable\". This variable shall be at least 34 bits long to hold the (22+12) result.  These two dropped bits have an impact on the entropy of process stack. Concretely, the total stack entropy is reduced by four: from 2^28 to 2^30 (One fourth of expected entropy).  This patch restores back the entropy by correcting the types involved in the operations in the functions randomize_stack_top() and stack_maxrandom_size().  The successful fix can be tested with:    $ for i in `seq 1 10`; do cat /proc/self/maps | grep stack; done   7ffeda566000-7ffeda587000 rw-p 00000000 00:00 0                          [stack]   7fff5a332000-7fff5a353000 rw-p 00000000 00:00 0                          [stack]   7ffcdb7a1000-7ffcdb7c2000 rw-p 00000000 00:00 0                          [stack]   7ffd5e2c4000-7ffd5e2e5000 rw-p 00000000 00:00 0                          [stack]   ...  Once corrected, the leading bytes should be between 7ffc and 7fff, rather than always being 7fff.  [ Rebased, fixed 80 char bugs, cleaned up commit message, added test example and CVE ] Cc: <stable@vger.kernel.org> Cc: Linus Torvalds <torvalds@linux-foundation.org> Cc: Andrew Morton <akpm@linux-foundation.org> Cc: Al Viro <viro@zeniv.linux.org.uk> Link: http://lkml.kernel.org/r/20150214173350.GA18393@www.outflux.net",
        "func_before": "static unsigned int stack_maxrandom_size(void)\n{\n\tunsigned int max = 0;\n\tif ((current->flags & PF_RANDOMIZE) &&\n\t\t!(current->personality & ADDR_NO_RANDOMIZE)) {\n\t\tmax = ((-1U) & STACK_RND_MASK) << PAGE_SHIFT;\n\t}\n\n\treturn max;\n}",
        "func": "static unsigned long stack_maxrandom_size(void)\n{\n\tunsigned long max = 0;\n\tif ((current->flags & PF_RANDOMIZE) &&\n\t\t!(current->personality & ADDR_NO_RANDOMIZE)) {\n\t\tmax = ((-1UL) & STACK_RND_MASK) << PAGE_SHIFT;\n\t}\n\n\treturn max;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,9 @@\n-static unsigned int stack_maxrandom_size(void)\n+static unsigned long stack_maxrandom_size(void)\n {\n-\tunsigned int max = 0;\n+\tunsigned long max = 0;\n \tif ((current->flags & PF_RANDOMIZE) &&\n \t\t!(current->personality & ADDR_NO_RANDOMIZE)) {\n-\t\tmax = ((-1U) & STACK_RND_MASK) << PAGE_SHIFT;\n+\t\tmax = ((-1UL) & STACK_RND_MASK) << PAGE_SHIFT;\n \t}\n \n \treturn max;",
        "diff_line_info": {
            "deleted_lines": [
                "static unsigned int stack_maxrandom_size(void)",
                "\tunsigned int max = 0;",
                "\t\tmax = ((-1U) & STACK_RND_MASK) << PAGE_SHIFT;"
            ],
            "added_lines": [
                "static unsigned long stack_maxrandom_size(void)",
                "\tunsigned long max = 0;",
                "\t\tmax = ((-1UL) & STACK_RND_MASK) << PAGE_SHIFT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2152",
        "func_name": "xen-project/xen/libxl__build_device_model_args_new",
        "description": "Xen 4.5.x and earlier enables certain default backends when emulating a VGA device for an x86 HVM guest qemu even when the configuration disables them, which allows local guest users to obtain access to the VGA console by (1) setting the DISPLAY environment variable, when compiled with SDL support, or connecting to the VNC server on (2) ::1 or (3) 127.0.0.1, when not compiled with SDL support.",
        "git_url": "https://github.com/xen-project/xen/commit/91b0ae9db33f72468b1d411a07f53085c893c097",
        "commit_title": "tools: libxl: Explicitly disable graphics backends on qemu cmdline",
        "commit_text": " By default qemu will try to create some sort of backend for the emulated VGA device, either SDL or VNC.  However when the user specifies sdl=0 and vnc=0 in their configuration libxl was not explicitly disabling either backend, which could lead to one unexpectedly running.  If either sdl=1 or vnc=1 is configured then both before and after this change only the backends which are explicitly enabled are configured, i.e. this issue only occurs when all backends are supposed to have been disabled.  This affects qemu-xen and qemu-xen-traditional differently.  If qemu-xen was compiled with SDL support then this would result in an SDL window being opened if $DISPLAY is valid, or a failure to start the guest if not. Passing \"-display none\" to qemu before any further -sdl options disables this default behaviour and ensures that SDL is only started if the libxl configuration demands it.  If qemu-xen was compiled without SDL support then qemu would instead start a VNC server listening on ::1 (IPv6 localhost) or 127.0.0.1 (IPv4 localhost) with IPv6 preferred if available. Explicitly pass \"-vnc none\" when vnc is not enabled in the libxl configuration to remove this possibility.  qemu-xen-traditional would never start a vnc backend unless asked. However by default it will start an SDL backend, the way to disable this is to pass a -vnc option. In other words passing \"-vnc none\" will disable both vnc and sdl by default. sdl can then be reenabled if configured by subsequent use of the -sdl option.  Tested with both qemu-xen and qemu-xen-traditional built with SDL support and: \txl cr # defaults \txl cr sdl=0 vnc=0 \txl cr sdl=1 vnc=0 \txl cr sdl=0 vnc=1 \txl cr sdl=0 vnc=0 vga=\\\"none\\\" \txl cr sdl=0 vnc=0 nographic=1 with both valid and invalid $DISPLAY.  This is XSA-119 / CVE-2015-2152. ",
        "func_before": "static char ** libxl__build_device_model_args_new(libxl__gc *gc,\n                                        const char *dm, int guest_domid,\n                                        const libxl_domain_config *guest_config,\n                                        const libxl__domain_build_state *state,\n                                        int *dm_state_fd)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    const libxl_domain_create_info *c_info = &guest_config->c_info;\n    const libxl_domain_build_info *b_info = &guest_config->b_info;\n    const libxl_device_disk *disks = guest_config->disks;\n    const libxl_device_nic *nics = guest_config->nics;\n    const int num_disks = guest_config->num_disks;\n    const int num_nics = guest_config->num_nics;\n    const libxl_vnc_info *vnc = libxl__dm_vnc(guest_config);\n    const libxl_sdl_info *sdl = dm_sdl(guest_config);\n    const char *keymap = dm_keymap(guest_config);\n    char *machinearg;\n    flexarray_t *dm_args;\n    int i, connection, devid;\n    uint64_t ram_size;\n    const char *path, *chardev;\n\n    dm_args = flexarray_make(gc, 16, 1);\n\n    flexarray_vappend(dm_args, dm,\n                      \"-xen-domid\",\n                      libxl__sprintf(gc, \"%d\", guest_domid), NULL);\n\n    flexarray_append(dm_args, \"-chardev\");\n    flexarray_append(dm_args,\n                     libxl__sprintf(gc, \"socket,id=libxl-cmd,\"\n                                    \"path=%s/qmp-libxl-%d,server,nowait\",\n                                    libxl__run_dir_path(), guest_domid));\n\n    flexarray_append(dm_args, \"-no-shutdown\");\n    flexarray_append(dm_args, \"-mon\");\n    flexarray_append(dm_args, \"chardev=libxl-cmd,mode=control\");\n\n    for (i = 0; i < guest_config->num_channels; i++) {\n        connection = guest_config->channels[i].connection;\n        devid = guest_config->channels[i].devid;\n        switch (connection) {\n            case LIBXL_CHANNEL_CONNECTION_PTY:\n                chardev = GCSPRINTF(\"pty,id=libxl-channel%d\", devid);\n                break;\n            case LIBXL_CHANNEL_CONNECTION_SOCKET:\n                path = guest_config->channels[i].u.socket.path;\n                chardev = GCSPRINTF(\"socket,id=libxl-channel%d,path=%s,\"\n                                    \"server,nowait\", devid, path);\n                break;\n            default:\n                /* We've forgotten to add the clause */\n                LOG(ERROR, \"%s: unknown channel connection %d\",\n                    __func__, connection);\n                return NULL;\n        }\n        flexarray_append(dm_args, \"-chardev\");\n        flexarray_append(dm_args, (void*)chardev);\n    }\n\n    /*\n     * Remove default devices created by qemu. Qemu will create only devices\n     * defined by xen, since the devices not defined by xen are not usable.\n     */\n    flexarray_append(dm_args, \"-nodefaults\");\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_PV) {\n        flexarray_append(dm_args, \"-xen-attach\");\n    }\n\n    if (c_info->name) {\n        flexarray_vappend(dm_args, \"-name\", c_info->name, NULL);\n    }\n\n    if (vnc) {\n        char *vncarg = NULL;\n\n        flexarray_append(dm_args, \"-vnc\");\n\n        /*\n         * If vnc->listen is present and contains a :, and\n         *  - vnc->display is 0, use vnc->listen\n         *  - vnc->display is non-zero, be confused\n         * If vnc->listen is present but doesn't, use vnc->listen:vnc->display.\n         * If vnc->listen is not present, use 127.0.0.1:vnc->display\n         * (Remembering that vnc->display already defaults to 0.)\n         */\n        if (vnc->listen) {\n            if (strchr(vnc->listen, ':') != NULL) {\n                if (vnc->display) {\n                    LOG(ERROR, \"vncdisplay set, vnclisten contains display\");\n                    return NULL;\n                }\n                vncarg = vnc->listen;\n            } else {\n                vncarg = libxl__sprintf(gc, \"%s:%d\", vnc->listen,\n                                        vnc->display);\n            }\n        } else\n            vncarg = libxl__sprintf(gc, \"127.0.0.1:%d\", vnc->display);\n\n        if (vnc->passwd && vnc->passwd[0]) {\n            vncarg = libxl__sprintf(gc, \"%s,password\", vncarg);\n        }\n\n        if (libxl_defbool_val(vnc->findunused)) {\n            /* This option asks to QEMU to try this number of port before to\n             * give up.  So QEMU will try ports between $display and $display +\n             * 99.  This option needs to be the last one of the vnc options. */\n            vncarg = libxl__sprintf(gc, \"%s,to=99\", vncarg);\n        }\n\n        flexarray_append(dm_args, vncarg);\n    }\n\n    if (sdl) {\n        flexarray_append(dm_args, \"-sdl\");\n        /* XXX sdl->{display,xauthority} into $DISPLAY/$XAUTHORITY */\n    }\n\n    if (keymap) {\n        flexarray_vappend(dm_args, \"-k\", keymap, NULL);\n    }\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        int ioemu_nics = 0;\n\n        if (b_info->kernel)\n            flexarray_vappend(dm_args, \"-kernel\", b_info->kernel, NULL);\n\n        if (b_info->ramdisk)\n            flexarray_vappend(dm_args, \"-initrd\", b_info->ramdisk, NULL);\n\n        if (b_info->cmdline)\n            flexarray_vappend(dm_args, \"-append\", b_info->cmdline, NULL);\n\n        if (b_info->u.hvm.serial || b_info->u.hvm.serial_list) {\n            if ( b_info->u.hvm.serial && b_info->u.hvm.serial_list )\n            {\n                LOG(ERROR, \"Both serial and serial_list set\");\n                return NULL;\n            }\n            if (b_info->u.hvm.serial) {\n                flexarray_vappend(dm_args,\n                                  \"-serial\", b_info->u.hvm.serial, NULL);\n            } else if (b_info->u.hvm.serial_list) {\n                char **p;\n                for (p = b_info->u.hvm.serial_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-serial\",\n                                      *p, NULL);\n                }\n            }\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.nographic) && (!sdl && !vnc)) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.spice.enable)) {\n            const libxl_spice_info *spice = &b_info->u.hvm.spice;\n            char *spiceoptions = dm_spice_options(gc, spice);\n            if (!spiceoptions)\n                return NULL;\n\n            flexarray_append(dm_args, \"-spice\");\n            flexarray_append(dm_args, spiceoptions);\n            if (libxl_defbool_val(b_info->u.hvm.spice.vdagent)) {\n                flexarray_vappend(dm_args, \"-device\", \"virtio-serial\",\n                    \"-chardev\", \"spicevmc,id=vdagent,name=vdagent\", \"-device\",\n                    \"virtserialport,chardev=vdagent,name=com.redhat.spice.0\",\n                    NULL);\n            }\n        }\n\n        switch (b_info->u.hvm.vga.kind) {\n        case LIBXL_VGA_INTERFACE_TYPE_STD:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"VGA,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_CIRRUS:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"cirrus-vga,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_NONE:\n            break;\n        }\n\n        if (b_info->u.hvm.boot) {\n            flexarray_vappend(dm_args, \"-boot\",\n                    libxl__sprintf(gc, \"order=%s\", b_info->u.hvm.boot), NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.usb)\n            || b_info->u.hvm.usbdevice\n            || b_info->u.hvm.usbdevice_list) {\n            if ( b_info->u.hvm.usbdevice && b_info->u.hvm.usbdevice_list )\n            {\n                LOG(ERROR, \"Both usbdevice and usbdevice_list set\");\n                return NULL;\n            }\n            flexarray_append(dm_args, \"-usb\");\n            if (b_info->u.hvm.usbdevice) {\n                flexarray_vappend(dm_args,\n                                  \"-usbdevice\", b_info->u.hvm.usbdevice, NULL);\n            } else if (b_info->u.hvm.usbdevice_list) {\n                char **p;\n                for (p = b_info->u.hvm.usbdevice_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-usbdevice\",\n                                      *p, NULL);\n                }\n            }\n        } else if (b_info->u.hvm.usbversion) {\n            switch (b_info->u.hvm.usbversion) {\n            case 1:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"piix3-usb-uhci,id=usb\", NULL);\n                break;\n            case 2:\n                flexarray_append_pair(dm_args, \"-device\",\n                    \"ich9-usb-ehci1,id=usb,addr=0x1d.0x7,multifunction=on\");\n                for (i = 1; i < 4; i++)\n                    flexarray_append_pair(dm_args, \"-device\",\n                        GCSPRINTF(\"ich9-usb-uhci%d,masterbus=usb.0,\"\n                        \"firstport=%d,addr=0x1d.%#x,multifunction=on\",\n                        i, 2*(i-1), i-1));\n                break;\n            case 3:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"nec-usb-xhci,id=usb\", NULL);\n                break;\n            default:\n                LOG(ERROR, \"usbversion parameter is invalid, \"\n                    \"must be between 1 and 3\");\n                return NULL;\n            }\n            if (b_info->u.hvm.spice.usbredirection >= 0 &&\n                b_info->u.hvm.spice.usbredirection < 5) {\n                for (i = 1; i <= b_info->u.hvm.spice.usbredirection; i++)\n                    flexarray_vappend(dm_args, \"-chardev\", libxl__sprintf(gc,\n                        \"spicevmc,name=usbredir,id=usbrc%d\", i), \"-device\",\n                        libxl__sprintf(gc, \"usb-redir,chardev=usbrc%d,\"\n                        \"id=usbrc%d\", i, i), NULL);\n            } else {\n                LOG(ERROR, \"usbredirection parameter is invalid, \"\n                    \"it must be between 1 and 4\");\n                return NULL;\n            }\n        }\n        if (b_info->u.hvm.soundhw) {\n            flexarray_vappend(dm_args, \"-soundhw\", b_info->u.hvm.soundhw, NULL);\n        }\n        if (!libxl_defbool_val(b_info->u.hvm.acpi)) {\n            flexarray_append(dm_args, \"-no-acpi\");\n        }\n        if (b_info->max_vcpus > 1) {\n            flexarray_append(dm_args, \"-smp\");\n            if (b_info->avail_vcpus.size) {\n                int nr_set_cpus = 0;\n                nr_set_cpus = libxl_bitmap_count_set(&b_info->avail_vcpus);\n\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d,maxcpus=%d\",\n                                                         nr_set_cpus,\n                                                         b_info->max_vcpus));\n            } else\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d\",\n                                                         b_info->max_vcpus));\n        }\n        for (i = 0; i < num_nics; i++) {\n            if (nics[i].nictype == LIBXL_NIC_TYPE_VIF_IOEMU) {\n                char *smac = libxl__sprintf(gc,\n                                LIBXL_MAC_FMT, LIBXL_MAC_BYTES(nics[i].mac));\n                const char *ifname = libxl__device_nic_devname(gc,\n                                                guest_domid, nics[i].devid,\n                                                LIBXL_NIC_TYPE_VIF_IOEMU);\n                flexarray_append(dm_args, \"-device\");\n                flexarray_append(dm_args,\n                   libxl__sprintf(gc, \"%s,id=nic%d,netdev=net%d,mac=%s\",\n                                                nics[i].model, nics[i].devid,\n                                                nics[i].devid, smac));\n                flexarray_append(dm_args, \"-netdev\");\n                flexarray_append(dm_args, GCSPRINTF(\n                                          \"type=tap,id=net%d,ifname=%s,\"\n                                          \"script=%s,downscript=%s\",\n                                          nics[i].devid, ifname,\n                                          libxl_tapif_script(gc),\n                                          libxl_tapif_script(gc)));\n                ioemu_nics++;\n            }\n        }\n        /* If we have no emulated nics, tell qemu not to create any */\n        if ( ioemu_nics == 0 ) {\n            flexarray_append(dm_args, \"-net\");\n            flexarray_append(dm_args, \"none\");\n        }\n        if (libxl_defbool_val(b_info->u.hvm.gfx_passthru)) {\n            flexarray_append(dm_args, \"-gfx_passthru\");\n        }\n    } else {\n        if (!sdl && !vnc) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n    }\n\n    if (state->saved_state) {\n        /* This file descriptor is meant to be used by QEMU */\n        *dm_state_fd = open(state->saved_state, O_RDONLY);\n        flexarray_append(dm_args, \"-incoming\");\n        flexarray_append(dm_args, GCSPRINTF(\"fd:%d\",*dm_state_fd));\n    }\n    for (i = 0; b_info->extra && b_info->extra[i] != NULL; i++)\n        flexarray_append(dm_args, b_info->extra[i]);\n\n    flexarray_append(dm_args, \"-machine\");\n    switch (b_info->type) {\n    case LIBXL_DOMAIN_TYPE_PV:\n        flexarray_append(dm_args, \"xenpv\");\n        for (i = 0; b_info->extra_pv && b_info->extra_pv[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_pv[i]);\n        break;\n    case LIBXL_DOMAIN_TYPE_HVM:\n        if (!libxl_defbool_val(b_info->u.hvm.xen_platform_pci)) {\n            /* Switching here to the machine \"pc\" which does not add\n             * the xen-platform device instead of the default \"xenfv\" machine.\n             */\n            machinearg = libxl__sprintf(gc, \"pc,accel=xen\");\n        } else {\n            machinearg = libxl__sprintf(gc, \"xenfv\");\n        }\n        if (b_info->u.hvm.mmio_hole_memkb) {\n            uint64_t max_ram_below_4g = (1ULL << 32) -\n                (b_info->u.hvm.mmio_hole_memkb << 10);\n\n            if (max_ram_below_4g > HVM_BELOW_4G_MMIO_START) {\n                LOG(WARN, \"mmio_hole_memkb=%\"PRIu64\n                    \" invalid ignored.\\n\",\n                    b_info->u.hvm.mmio_hole_memkb);\n            } else {\n                machinearg = libxl__sprintf(gc, \"%s,max-ram-below-4g=%\"PRIu64,\n                                            machinearg, max_ram_below_4g);\n            }\n        }\n        flexarray_append(dm_args, machinearg);\n        for (i = 0; b_info->extra_hvm && b_info->extra_hvm[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_hvm[i]);\n        break;\n    default:\n        abort();\n    }\n\n    ram_size = libxl__sizekb_to_mb(b_info->max_memkb - b_info->video_memkb);\n    flexarray_append(dm_args, \"-m\");\n    flexarray_append(dm_args, libxl__sprintf(gc, \"%\"PRId64, ram_size));\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        for (i = 0; i < num_disks; i++) {\n            int disk, part;\n            int dev_number =\n                libxl__device_disk_dev_number(disks[i].vdev, &disk, &part);\n            const char *format = qemu_disk_format_string(disks[i].format);\n            char *drive;\n            const char *pdev_path;\n\n            if (dev_number == -1) {\n                LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                           \" disk number for %s\", disks[i].vdev);\n                continue;\n            }\n\n            if (disks[i].is_cdrom) {\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY)\n                    drive = libxl__sprintf\n                        (gc, \"if=ide,index=%d,media=cdrom,cache=writeback,id=ide-%i\",\n                         disk, dev_number);\n                else\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,media=cdrom,format=%s,cache=writeback,id=ide-%i\",\n                         disks[i].pdev_path, disk, format, dev_number);\n            } else {\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"cannot support\"\n                               \" empty disk format for %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (format == NULL) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                               \" disk image format %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (disks[i].backend == LIBXL_DISK_BACKEND_TAP) {\n                    format = qemu_disk_format_string(LIBXL_DISK_FORMAT_RAW);\n                    pdev_path = libxl__blktap_devpath(gc, disks[i].pdev_path,\n                                                      disks[i].format);\n                } else {\n                    pdev_path = disks[i].pdev_path;\n                }\n\n                /*\n                 * Explicit sd disks are passed through as is.\n                 *\n                 * For other disks we translate devices 0..3 into\n                 * hd[a-d] and ignore the rest.\n                 */\n                if (strncmp(disks[i].vdev, \"sd\", 2) == 0)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=scsi,bus=0,unit=%d,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else if (disk < 4)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,media=disk,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else\n                    continue; /* Do not emulate this disk */\n            }\n\n            flexarray_append(dm_args, \"-drive\");\n            flexarray_append(dm_args, drive);\n        }\n\n        switch (b_info->u.hvm.vendor_device) {\n        case LIBXL_VENDOR_DEVICE_XENSERVER:\n            flexarray_append(dm_args, \"-device\");\n            flexarray_append(dm_args, \"xen-pvdevice,device-id=0xc000\");\n            break;\n        default:\n            break;\n        }\n    }\n    flexarray_append(dm_args, NULL);\n    return (char **) flexarray_contents(dm_args);\n}",
        "func": "static char ** libxl__build_device_model_args_new(libxl__gc *gc,\n                                        const char *dm, int guest_domid,\n                                        const libxl_domain_config *guest_config,\n                                        const libxl__domain_build_state *state,\n                                        int *dm_state_fd)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    const libxl_domain_create_info *c_info = &guest_config->c_info;\n    const libxl_domain_build_info *b_info = &guest_config->b_info;\n    const libxl_device_disk *disks = guest_config->disks;\n    const libxl_device_nic *nics = guest_config->nics;\n    const int num_disks = guest_config->num_disks;\n    const int num_nics = guest_config->num_nics;\n    const libxl_vnc_info *vnc = libxl__dm_vnc(guest_config);\n    const libxl_sdl_info *sdl = dm_sdl(guest_config);\n    const char *keymap = dm_keymap(guest_config);\n    char *machinearg;\n    flexarray_t *dm_args;\n    int i, connection, devid;\n    uint64_t ram_size;\n    const char *path, *chardev;\n\n    dm_args = flexarray_make(gc, 16, 1);\n\n    flexarray_vappend(dm_args, dm,\n                      \"-xen-domid\",\n                      libxl__sprintf(gc, \"%d\", guest_domid), NULL);\n\n    flexarray_append(dm_args, \"-chardev\");\n    flexarray_append(dm_args,\n                     libxl__sprintf(gc, \"socket,id=libxl-cmd,\"\n                                    \"path=%s/qmp-libxl-%d,server,nowait\",\n                                    libxl__run_dir_path(), guest_domid));\n\n    flexarray_append(dm_args, \"-no-shutdown\");\n    flexarray_append(dm_args, \"-mon\");\n    flexarray_append(dm_args, \"chardev=libxl-cmd,mode=control\");\n\n    for (i = 0; i < guest_config->num_channels; i++) {\n        connection = guest_config->channels[i].connection;\n        devid = guest_config->channels[i].devid;\n        switch (connection) {\n            case LIBXL_CHANNEL_CONNECTION_PTY:\n                chardev = GCSPRINTF(\"pty,id=libxl-channel%d\", devid);\n                break;\n            case LIBXL_CHANNEL_CONNECTION_SOCKET:\n                path = guest_config->channels[i].u.socket.path;\n                chardev = GCSPRINTF(\"socket,id=libxl-channel%d,path=%s,\"\n                                    \"server,nowait\", devid, path);\n                break;\n            default:\n                /* We've forgotten to add the clause */\n                LOG(ERROR, \"%s: unknown channel connection %d\",\n                    __func__, connection);\n                return NULL;\n        }\n        flexarray_append(dm_args, \"-chardev\");\n        flexarray_append(dm_args, (void*)chardev);\n    }\n\n    /*\n     * Remove default devices created by qemu. Qemu will create only devices\n     * defined by xen, since the devices not defined by xen are not usable.\n     */\n    flexarray_append(dm_args, \"-nodefaults\");\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_PV) {\n        flexarray_append(dm_args, \"-xen-attach\");\n    }\n\n    if (c_info->name) {\n        flexarray_vappend(dm_args, \"-name\", c_info->name, NULL);\n    }\n\n    if (vnc) {\n        char *vncarg = NULL;\n\n        flexarray_append(dm_args, \"-vnc\");\n\n        /*\n         * If vnc->listen is present and contains a :, and\n         *  - vnc->display is 0, use vnc->listen\n         *  - vnc->display is non-zero, be confused\n         * If vnc->listen is present but doesn't, use vnc->listen:vnc->display.\n         * If vnc->listen is not present, use 127.0.0.1:vnc->display\n         * (Remembering that vnc->display already defaults to 0.)\n         */\n        if (vnc->listen) {\n            if (strchr(vnc->listen, ':') != NULL) {\n                if (vnc->display) {\n                    LOG(ERROR, \"vncdisplay set, vnclisten contains display\");\n                    return NULL;\n                }\n                vncarg = vnc->listen;\n            } else {\n                vncarg = libxl__sprintf(gc, \"%s:%d\", vnc->listen,\n                                        vnc->display);\n            }\n        } else\n            vncarg = libxl__sprintf(gc, \"127.0.0.1:%d\", vnc->display);\n\n        if (vnc->passwd && vnc->passwd[0]) {\n            vncarg = libxl__sprintf(gc, \"%s,password\", vncarg);\n        }\n\n        if (libxl_defbool_val(vnc->findunused)) {\n            /* This option asks to QEMU to try this number of port before to\n             * give up.  So QEMU will try ports between $display and $display +\n             * 99.  This option needs to be the last one of the vnc options. */\n            vncarg = libxl__sprintf(gc, \"%s,to=99\", vncarg);\n        }\n\n        flexarray_append(dm_args, vncarg);\n    } else\n        /*\n         * Ensure that by default no vnc server is created.\n         */\n        flexarray_append_pair(dm_args, \"-vnc\", \"none\");\n\n    /*\n     * Ensure that by default no display backend is created. Further\n     * options given below might then enable more.\n     */\n    flexarray_append_pair(dm_args, \"-display\", \"none\");\n\n    if (sdl) {\n        flexarray_append(dm_args, \"-sdl\");\n        /* XXX sdl->{display,xauthority} into $DISPLAY/$XAUTHORITY */\n    }\n\n    if (keymap) {\n        flexarray_vappend(dm_args, \"-k\", keymap, NULL);\n    }\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        int ioemu_nics = 0;\n\n        if (b_info->kernel)\n            flexarray_vappend(dm_args, \"-kernel\", b_info->kernel, NULL);\n\n        if (b_info->ramdisk)\n            flexarray_vappend(dm_args, \"-initrd\", b_info->ramdisk, NULL);\n\n        if (b_info->cmdline)\n            flexarray_vappend(dm_args, \"-append\", b_info->cmdline, NULL);\n\n        if (b_info->u.hvm.serial || b_info->u.hvm.serial_list) {\n            if ( b_info->u.hvm.serial && b_info->u.hvm.serial_list )\n            {\n                LOG(ERROR, \"Both serial and serial_list set\");\n                return NULL;\n            }\n            if (b_info->u.hvm.serial) {\n                flexarray_vappend(dm_args,\n                                  \"-serial\", b_info->u.hvm.serial, NULL);\n            } else if (b_info->u.hvm.serial_list) {\n                char **p;\n                for (p = b_info->u.hvm.serial_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-serial\",\n                                      *p, NULL);\n                }\n            }\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.nographic) && (!sdl && !vnc)) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.spice.enable)) {\n            const libxl_spice_info *spice = &b_info->u.hvm.spice;\n            char *spiceoptions = dm_spice_options(gc, spice);\n            if (!spiceoptions)\n                return NULL;\n\n            flexarray_append(dm_args, \"-spice\");\n            flexarray_append(dm_args, spiceoptions);\n            if (libxl_defbool_val(b_info->u.hvm.spice.vdagent)) {\n                flexarray_vappend(dm_args, \"-device\", \"virtio-serial\",\n                    \"-chardev\", \"spicevmc,id=vdagent,name=vdagent\", \"-device\",\n                    \"virtserialport,chardev=vdagent,name=com.redhat.spice.0\",\n                    NULL);\n            }\n        }\n\n        switch (b_info->u.hvm.vga.kind) {\n        case LIBXL_VGA_INTERFACE_TYPE_STD:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"VGA,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_CIRRUS:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"cirrus-vga,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_NONE:\n            break;\n        }\n\n        if (b_info->u.hvm.boot) {\n            flexarray_vappend(dm_args, \"-boot\",\n                    libxl__sprintf(gc, \"order=%s\", b_info->u.hvm.boot), NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.usb)\n            || b_info->u.hvm.usbdevice\n            || b_info->u.hvm.usbdevice_list) {\n            if ( b_info->u.hvm.usbdevice && b_info->u.hvm.usbdevice_list )\n            {\n                LOG(ERROR, \"Both usbdevice and usbdevice_list set\");\n                return NULL;\n            }\n            flexarray_append(dm_args, \"-usb\");\n            if (b_info->u.hvm.usbdevice) {\n                flexarray_vappend(dm_args,\n                                  \"-usbdevice\", b_info->u.hvm.usbdevice, NULL);\n            } else if (b_info->u.hvm.usbdevice_list) {\n                char **p;\n                for (p = b_info->u.hvm.usbdevice_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-usbdevice\",\n                                      *p, NULL);\n                }\n            }\n        } else if (b_info->u.hvm.usbversion) {\n            switch (b_info->u.hvm.usbversion) {\n            case 1:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"piix3-usb-uhci,id=usb\", NULL);\n                break;\n            case 2:\n                flexarray_append_pair(dm_args, \"-device\",\n                    \"ich9-usb-ehci1,id=usb,addr=0x1d.0x7,multifunction=on\");\n                for (i = 1; i < 4; i++)\n                    flexarray_append_pair(dm_args, \"-device\",\n                        GCSPRINTF(\"ich9-usb-uhci%d,masterbus=usb.0,\"\n                        \"firstport=%d,addr=0x1d.%#x,multifunction=on\",\n                        i, 2*(i-1), i-1));\n                break;\n            case 3:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"nec-usb-xhci,id=usb\", NULL);\n                break;\n            default:\n                LOG(ERROR, \"usbversion parameter is invalid, \"\n                    \"must be between 1 and 3\");\n                return NULL;\n            }\n            if (b_info->u.hvm.spice.usbredirection >= 0 &&\n                b_info->u.hvm.spice.usbredirection < 5) {\n                for (i = 1; i <= b_info->u.hvm.spice.usbredirection; i++)\n                    flexarray_vappend(dm_args, \"-chardev\", libxl__sprintf(gc,\n                        \"spicevmc,name=usbredir,id=usbrc%d\", i), \"-device\",\n                        libxl__sprintf(gc, \"usb-redir,chardev=usbrc%d,\"\n                        \"id=usbrc%d\", i, i), NULL);\n            } else {\n                LOG(ERROR, \"usbredirection parameter is invalid, \"\n                    \"it must be between 1 and 4\");\n                return NULL;\n            }\n        }\n        if (b_info->u.hvm.soundhw) {\n            flexarray_vappend(dm_args, \"-soundhw\", b_info->u.hvm.soundhw, NULL);\n        }\n        if (!libxl_defbool_val(b_info->u.hvm.acpi)) {\n            flexarray_append(dm_args, \"-no-acpi\");\n        }\n        if (b_info->max_vcpus > 1) {\n            flexarray_append(dm_args, \"-smp\");\n            if (b_info->avail_vcpus.size) {\n                int nr_set_cpus = 0;\n                nr_set_cpus = libxl_bitmap_count_set(&b_info->avail_vcpus);\n\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d,maxcpus=%d\",\n                                                         nr_set_cpus,\n                                                         b_info->max_vcpus));\n            } else\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d\",\n                                                         b_info->max_vcpus));\n        }\n        for (i = 0; i < num_nics; i++) {\n            if (nics[i].nictype == LIBXL_NIC_TYPE_VIF_IOEMU) {\n                char *smac = libxl__sprintf(gc,\n                                LIBXL_MAC_FMT, LIBXL_MAC_BYTES(nics[i].mac));\n                const char *ifname = libxl__device_nic_devname(gc,\n                                                guest_domid, nics[i].devid,\n                                                LIBXL_NIC_TYPE_VIF_IOEMU);\n                flexarray_append(dm_args, \"-device\");\n                flexarray_append(dm_args,\n                   libxl__sprintf(gc, \"%s,id=nic%d,netdev=net%d,mac=%s\",\n                                                nics[i].model, nics[i].devid,\n                                                nics[i].devid, smac));\n                flexarray_append(dm_args, \"-netdev\");\n                flexarray_append(dm_args, GCSPRINTF(\n                                          \"type=tap,id=net%d,ifname=%s,\"\n                                          \"script=%s,downscript=%s\",\n                                          nics[i].devid, ifname,\n                                          libxl_tapif_script(gc),\n                                          libxl_tapif_script(gc)));\n                ioemu_nics++;\n            }\n        }\n        /* If we have no emulated nics, tell qemu not to create any */\n        if ( ioemu_nics == 0 ) {\n            flexarray_append(dm_args, \"-net\");\n            flexarray_append(dm_args, \"none\");\n        }\n        if (libxl_defbool_val(b_info->u.hvm.gfx_passthru)) {\n            flexarray_append(dm_args, \"-gfx_passthru\");\n        }\n    } else {\n        if (!sdl && !vnc) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n    }\n\n    if (state->saved_state) {\n        /* This file descriptor is meant to be used by QEMU */\n        *dm_state_fd = open(state->saved_state, O_RDONLY);\n        flexarray_append(dm_args, \"-incoming\");\n        flexarray_append(dm_args, GCSPRINTF(\"fd:%d\",*dm_state_fd));\n    }\n    for (i = 0; b_info->extra && b_info->extra[i] != NULL; i++)\n        flexarray_append(dm_args, b_info->extra[i]);\n\n    flexarray_append(dm_args, \"-machine\");\n    switch (b_info->type) {\n    case LIBXL_DOMAIN_TYPE_PV:\n        flexarray_append(dm_args, \"xenpv\");\n        for (i = 0; b_info->extra_pv && b_info->extra_pv[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_pv[i]);\n        break;\n    case LIBXL_DOMAIN_TYPE_HVM:\n        if (!libxl_defbool_val(b_info->u.hvm.xen_platform_pci)) {\n            /* Switching here to the machine \"pc\" which does not add\n             * the xen-platform device instead of the default \"xenfv\" machine.\n             */\n            machinearg = libxl__sprintf(gc, \"pc,accel=xen\");\n        } else {\n            machinearg = libxl__sprintf(gc, \"xenfv\");\n        }\n        if (b_info->u.hvm.mmio_hole_memkb) {\n            uint64_t max_ram_below_4g = (1ULL << 32) -\n                (b_info->u.hvm.mmio_hole_memkb << 10);\n\n            if (max_ram_below_4g > HVM_BELOW_4G_MMIO_START) {\n                LOG(WARN, \"mmio_hole_memkb=%\"PRIu64\n                    \" invalid ignored.\\n\",\n                    b_info->u.hvm.mmio_hole_memkb);\n            } else {\n                machinearg = libxl__sprintf(gc, \"%s,max-ram-below-4g=%\"PRIu64,\n                                            machinearg, max_ram_below_4g);\n            }\n        }\n        flexarray_append(dm_args, machinearg);\n        for (i = 0; b_info->extra_hvm && b_info->extra_hvm[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_hvm[i]);\n        break;\n    default:\n        abort();\n    }\n\n    ram_size = libxl__sizekb_to_mb(b_info->max_memkb - b_info->video_memkb);\n    flexarray_append(dm_args, \"-m\");\n    flexarray_append(dm_args, libxl__sprintf(gc, \"%\"PRId64, ram_size));\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        for (i = 0; i < num_disks; i++) {\n            int disk, part;\n            int dev_number =\n                libxl__device_disk_dev_number(disks[i].vdev, &disk, &part);\n            const char *format = qemu_disk_format_string(disks[i].format);\n            char *drive;\n            const char *pdev_path;\n\n            if (dev_number == -1) {\n                LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                           \" disk number for %s\", disks[i].vdev);\n                continue;\n            }\n\n            if (disks[i].is_cdrom) {\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY)\n                    drive = libxl__sprintf\n                        (gc, \"if=ide,index=%d,media=cdrom,cache=writeback,id=ide-%i\",\n                         disk, dev_number);\n                else\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,media=cdrom,format=%s,cache=writeback,id=ide-%i\",\n                         disks[i].pdev_path, disk, format, dev_number);\n            } else {\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"cannot support\"\n                               \" empty disk format for %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (format == NULL) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                               \" disk image format %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (disks[i].backend == LIBXL_DISK_BACKEND_TAP) {\n                    format = qemu_disk_format_string(LIBXL_DISK_FORMAT_RAW);\n                    pdev_path = libxl__blktap_devpath(gc, disks[i].pdev_path,\n                                                      disks[i].format);\n                } else {\n                    pdev_path = disks[i].pdev_path;\n                }\n\n                /*\n                 * Explicit sd disks are passed through as is.\n                 *\n                 * For other disks we translate devices 0..3 into\n                 * hd[a-d] and ignore the rest.\n                 */\n                if (strncmp(disks[i].vdev, \"sd\", 2) == 0)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=scsi,bus=0,unit=%d,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else if (disk < 4)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,media=disk,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else\n                    continue; /* Do not emulate this disk */\n            }\n\n            flexarray_append(dm_args, \"-drive\");\n            flexarray_append(dm_args, drive);\n        }\n\n        switch (b_info->u.hvm.vendor_device) {\n        case LIBXL_VENDOR_DEVICE_XENSERVER:\n            flexarray_append(dm_args, \"-device\");\n            flexarray_append(dm_args, \"xen-pvdevice,device-id=0xc000\");\n            break;\n        default:\n            break;\n        }\n    }\n    flexarray_append(dm_args, NULL);\n    return (char **) flexarray_contents(dm_args);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -111,7 +111,17 @@\n         }\n \n         flexarray_append(dm_args, vncarg);\n-    }\n+    } else\n+        /*\n+         * Ensure that by default no vnc server is created.\n+         */\n+        flexarray_append_pair(dm_args, \"-vnc\", \"none\");\n+\n+    /*\n+     * Ensure that by default no display backend is created. Further\n+     * options given below might then enable more.\n+     */\n+    flexarray_append_pair(dm_args, \"-display\", \"none\");\n \n     if (sdl) {\n         flexarray_append(dm_args, \"-sdl\");",
        "diff_line_info": {
            "deleted_lines": [
                "    }"
            ],
            "added_lines": [
                "    } else",
                "        /*",
                "         * Ensure that by default no vnc server is created.",
                "         */",
                "        flexarray_append_pair(dm_args, \"-vnc\", \"none\");",
                "",
                "    /*",
                "     * Ensure that by default no display backend is created. Further",
                "     * options given below might then enable more.",
                "     */",
                "    flexarray_append_pair(dm_args, \"-display\", \"none\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2152",
        "func_name": "xen-project/xen/libxl__build_device_model_args_old",
        "description": "Xen 4.5.x and earlier enables certain default backends when emulating a VGA device for an x86 HVM guest qemu even when the configuration disables them, which allows local guest users to obtain access to the VGA console by (1) setting the DISPLAY environment variable, when compiled with SDL support, or connecting to the VNC server on (2) ::1 or (3) 127.0.0.1, when not compiled with SDL support.",
        "git_url": "https://github.com/xen-project/xen/commit/91b0ae9db33f72468b1d411a07f53085c893c097",
        "commit_title": "tools: libxl: Explicitly disable graphics backends on qemu cmdline",
        "commit_text": " By default qemu will try to create some sort of backend for the emulated VGA device, either SDL or VNC.  However when the user specifies sdl=0 and vnc=0 in their configuration libxl was not explicitly disabling either backend, which could lead to one unexpectedly running.  If either sdl=1 or vnc=1 is configured then both before and after this change only the backends which are explicitly enabled are configured, i.e. this issue only occurs when all backends are supposed to have been disabled.  This affects qemu-xen and qemu-xen-traditional differently.  If qemu-xen was compiled with SDL support then this would result in an SDL window being opened if $DISPLAY is valid, or a failure to start the guest if not. Passing \"-display none\" to qemu before any further -sdl options disables this default behaviour and ensures that SDL is only started if the libxl configuration demands it.  If qemu-xen was compiled without SDL support then qemu would instead start a VNC server listening on ::1 (IPv6 localhost) or 127.0.0.1 (IPv4 localhost) with IPv6 preferred if available. Explicitly pass \"-vnc none\" when vnc is not enabled in the libxl configuration to remove this possibility.  qemu-xen-traditional would never start a vnc backend unless asked. However by default it will start an SDL backend, the way to disable this is to pass a -vnc option. In other words passing \"-vnc none\" will disable both vnc and sdl by default. sdl can then be reenabled if configured by subsequent use of the -sdl option.  Tested with both qemu-xen and qemu-xen-traditional built with SDL support and: \txl cr # defaults \txl cr sdl=0 vnc=0 \txl cr sdl=1 vnc=0 \txl cr sdl=0 vnc=1 \txl cr sdl=0 vnc=0 vga=\\\"none\\\" \txl cr sdl=0 vnc=0 nographic=1 with both valid and invalid $DISPLAY.  This is XSA-119 / CVE-2015-2152. ",
        "func_before": "static char ** libxl__build_device_model_args_old(libxl__gc *gc,\n                                        const char *dm, int domid,\n                                        const libxl_domain_config *guest_config,\n                                        const libxl__domain_build_state *state)\n{\n    const libxl_domain_create_info *c_info = &guest_config->c_info;\n    const libxl_domain_build_info *b_info = &guest_config->b_info;\n    const libxl_device_nic *nics = guest_config->nics;\n    const libxl_vnc_info *vnc = libxl__dm_vnc(guest_config);\n    const libxl_sdl_info *sdl = dm_sdl(guest_config);\n    const int num_nics = guest_config->num_nics;\n    const char *keymap = dm_keymap(guest_config);\n    int i;\n    flexarray_t *dm_args;\n    dm_args = flexarray_make(gc, 16, 1);\n\n    flexarray_vappend(dm_args, dm,\n                      \"-d\", libxl__sprintf(gc, \"%d\", domid), NULL);\n\n    if (c_info->name)\n        flexarray_vappend(dm_args, \"-domain-name\", c_info->name, NULL);\n\n    if (vnc) {\n        char *vncarg = NULL;\n\n        flexarray_append(dm_args, \"-vnc\");\n\n        /*\n         * If vnc->listen is present and contains a :, and\n         *  - vnc->display is 0, use vnc->listen\n         *  - vnc->display is non-zero, be confused\n         * If vnc->listen is present but doesn't, use vnc->listen:vnc->display.\n         * If vnc->listen is not present, use 127.0.0.1:vnc->display\n         * (Remembering that vnc->display already defaults to 0.)\n         */\n        if (vnc->listen) {\n            if (strchr(vnc->listen, ':') != NULL) {\n                if (vnc->display) {\n                    LOG(ERROR, \"vncdisplay set, vnclisten contains display\");\n                    return NULL;\n                }\n                vncarg = vnc->listen;\n            } else {\n                vncarg = libxl__sprintf(gc, \"%s:%d\", vnc->listen,\n                                        vnc->display);\n            }\n        } else\n            vncarg = libxl__sprintf(gc, \"127.0.0.1:%d\", vnc->display);\n\n        if (vnc->passwd && vnc->passwd[0]) {\n            vncarg = libxl__sprintf(gc, \"%s,password\", vncarg);\n        }\n\n        flexarray_append(dm_args, vncarg);\n\n        if (libxl_defbool_val(vnc->findunused)) {\n            flexarray_append(dm_args, \"-vncunused\");\n        }\n    }\n\n    if (sdl) {\n        flexarray_append(dm_args, \"-sdl\");\n        if (!libxl_defbool_val(sdl->opengl)) {\n            flexarray_append(dm_args, \"-disable-opengl\");\n        }\n        /* XXX sdl->{display,xauthority} into $DISPLAY/$XAUTHORITY */\n    }\n    if (keymap) {\n        flexarray_vappend(dm_args, \"-k\", keymap, NULL);\n    }\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        int ioemu_nics = 0;\n        int nr_set_cpus = 0;\n        char *s;\n\n        if (b_info->kernel) {\n            LOG(ERROR, \"HVM direct kernel boot is not supported by \"\n                \"qemu-xen-traditional\");\n            return NULL;\n        }\n\n        if (b_info->u.hvm.serial || b_info->u.hvm.serial_list) {\n            if ( b_info->u.hvm.serial && b_info->u.hvm.serial_list )\n            {\n                LOG(ERROR, \"Both serial and serial_list set\");\n                return NULL;\n            }\n            if (b_info->u.hvm.serial) {\n                flexarray_vappend(dm_args,\n                                  \"-serial\", b_info->u.hvm.serial, NULL);\n            } else if (b_info->u.hvm.serial_list) {\n                char **p;\n                for (p = b_info->u.hvm.serial_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-serial\",\n                                      *p, NULL);\n                }\n            }\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.nographic) && (!sdl && !vnc)) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n\n        if (b_info->video_memkb) {\n            flexarray_vappend(dm_args, \"-videoram\",\n                    libxl__sprintf(gc, \"%d\",\n                                   libxl__sizekb_to_mb(b_info->video_memkb)),\n                    NULL);\n        }\n\n        switch (b_info->u.hvm.vga.kind) {\n        case LIBXL_VGA_INTERFACE_TYPE_STD:\n            flexarray_append(dm_args, \"-std-vga\");\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_CIRRUS:\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_NONE:\n            flexarray_append_pair(dm_args, \"-vga\", \"none\");\n            break;\n        }\n\n        if (b_info->u.hvm.boot) {\n            flexarray_vappend(dm_args, \"-boot\", b_info->u.hvm.boot, NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.usb)\n            || b_info->u.hvm.usbdevice\n            || b_info->u.hvm.usbdevice_list) {\n            if ( b_info->u.hvm.usbdevice && b_info->u.hvm.usbdevice_list )\n            {\n                LOG(ERROR, \"Both usbdevice and usbdevice_list set\");\n                return NULL;\n            }\n            flexarray_append(dm_args, \"-usb\");\n            if (b_info->u.hvm.usbdevice) {\n                flexarray_vappend(dm_args,\n                                  \"-usbdevice\", b_info->u.hvm.usbdevice, NULL);\n            } else if (b_info->u.hvm.usbdevice_list) {\n                char **p;\n                for (p = b_info->u.hvm.usbdevice_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-usbdevice\",\n                                      *p, NULL);\n                }\n            }\n        }\n        if (b_info->u.hvm.soundhw) {\n            flexarray_vappend(dm_args, \"-soundhw\", b_info->u.hvm.soundhw, NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.acpi)) {\n            flexarray_append(dm_args, \"-acpi\");\n        }\n        if (b_info->max_vcpus > 1) {\n            flexarray_vappend(dm_args, \"-vcpus\",\n                              libxl__sprintf(gc, \"%d\", b_info->max_vcpus),\n                              NULL);\n        }\n\n        nr_set_cpus = libxl_bitmap_count_set(&b_info->avail_vcpus);\n        s = libxl_bitmap_to_hex_string(CTX, &b_info->avail_vcpus);\n        flexarray_vappend(dm_args, \"-vcpu_avail\",\n                              libxl__sprintf(gc, \"%s\", s), NULL);\n        free(s);\n\n        for (i = 0; i < num_nics; i++) {\n            if (nics[i].nictype == LIBXL_NIC_TYPE_VIF_IOEMU) {\n                char *smac = libxl__sprintf(gc,\n                                   LIBXL_MAC_FMT, LIBXL_MAC_BYTES(nics[i].mac));\n                const char *ifname = libxl__device_nic_devname(gc,\n                                                domid, nics[i].devid,\n                                                LIBXL_NIC_TYPE_VIF_IOEMU);\n                flexarray_vappend(dm_args,\n                                  \"-net\",\n                                  GCSPRINTF(\n                                      \"nic,vlan=%d,macaddr=%s,model=%s\",\n                                      nics[i].devid, smac, nics[i].model),\n                                  \"-net\",\n                                  GCSPRINTF(\n                                      \"tap,vlan=%d,ifname=%s,bridge=%s,\"\n                                      \"script=%s,downscript=%s\",\n                                      nics[i].devid, ifname, nics[i].bridge,\n                                      libxl_tapif_script(gc),\n                                      libxl_tapif_script(gc)),\n                                  NULL);\n                ioemu_nics++;\n            }\n        }\n        /* If we have no emulated nics, tell qemu not to create any */\n        if ( ioemu_nics == 0 ) {\n            flexarray_vappend(dm_args, \"-net\", \"none\", NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.gfx_passthru)) {\n            flexarray_append(dm_args, \"-gfx_passthru\");\n        }\n    } else {\n        if (!sdl && !vnc)\n            flexarray_append(dm_args, \"-nographic\");\n    }\n\n    if (state->saved_state) {\n        flexarray_vappend(dm_args, \"-loadvm\", state->saved_state, NULL);\n    }\n    for (i = 0; b_info->extra && b_info->extra[i] != NULL; i++)\n        flexarray_append(dm_args, b_info->extra[i]);\n    flexarray_append(dm_args, \"-M\");\n    switch (b_info->type) {\n    case LIBXL_DOMAIN_TYPE_PV:\n        flexarray_append(dm_args, \"xenpv\");\n        for (i = 0; b_info->extra_pv && b_info->extra_pv[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_pv[i]);\n        break;\n    case LIBXL_DOMAIN_TYPE_HVM:\n        flexarray_append(dm_args, \"xenfv\");\n        for (i = 0; b_info->extra_hvm && b_info->extra_hvm[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_hvm[i]);\n        break;\n    default:\n        abort();\n    }\n    flexarray_append(dm_args, NULL);\n    return (char **) flexarray_contents(dm_args);\n}",
        "func": "static char ** libxl__build_device_model_args_old(libxl__gc *gc,\n                                        const char *dm, int domid,\n                                        const libxl_domain_config *guest_config,\n                                        const libxl__domain_build_state *state)\n{\n    const libxl_domain_create_info *c_info = &guest_config->c_info;\n    const libxl_domain_build_info *b_info = &guest_config->b_info;\n    const libxl_device_nic *nics = guest_config->nics;\n    const libxl_vnc_info *vnc = libxl__dm_vnc(guest_config);\n    const libxl_sdl_info *sdl = dm_sdl(guest_config);\n    const int num_nics = guest_config->num_nics;\n    const char *keymap = dm_keymap(guest_config);\n    int i;\n    flexarray_t *dm_args;\n    dm_args = flexarray_make(gc, 16, 1);\n\n    flexarray_vappend(dm_args, dm,\n                      \"-d\", libxl__sprintf(gc, \"%d\", domid), NULL);\n\n    if (c_info->name)\n        flexarray_vappend(dm_args, \"-domain-name\", c_info->name, NULL);\n\n    if (vnc) {\n        char *vncarg = NULL;\n\n        flexarray_append(dm_args, \"-vnc\");\n\n        /*\n         * If vnc->listen is present and contains a :, and\n         *  - vnc->display is 0, use vnc->listen\n         *  - vnc->display is non-zero, be confused\n         * If vnc->listen is present but doesn't, use vnc->listen:vnc->display.\n         * If vnc->listen is not present, use 127.0.0.1:vnc->display\n         * (Remembering that vnc->display already defaults to 0.)\n         */\n        if (vnc->listen) {\n            if (strchr(vnc->listen, ':') != NULL) {\n                if (vnc->display) {\n                    LOG(ERROR, \"vncdisplay set, vnclisten contains display\");\n                    return NULL;\n                }\n                vncarg = vnc->listen;\n            } else {\n                vncarg = libxl__sprintf(gc, \"%s:%d\", vnc->listen,\n                                        vnc->display);\n            }\n        } else\n            vncarg = libxl__sprintf(gc, \"127.0.0.1:%d\", vnc->display);\n\n        if (vnc->passwd && vnc->passwd[0]) {\n            vncarg = libxl__sprintf(gc, \"%s,password\", vncarg);\n        }\n\n        flexarray_append(dm_args, vncarg);\n\n        if (libxl_defbool_val(vnc->findunused)) {\n            flexarray_append(dm_args, \"-vncunused\");\n        }\n    } else\n        /*\n         * VNC is not enabled by default by qemu-xen-traditional,\n         * however passing -vnc none causes SDL to not be\n         * (unexpectedly) enabled by default. This is overridden by\n         * explicitly passing -sdl below as required.\n         */\n        flexarray_append_pair(dm_args, \"-vnc\", \"none\");\n\n    if (sdl) {\n        flexarray_append(dm_args, \"-sdl\");\n        if (!libxl_defbool_val(sdl->opengl)) {\n            flexarray_append(dm_args, \"-disable-opengl\");\n        }\n        /* XXX sdl->{display,xauthority} into $DISPLAY/$XAUTHORITY */\n    }\n    if (keymap) {\n        flexarray_vappend(dm_args, \"-k\", keymap, NULL);\n    }\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        int ioemu_nics = 0;\n        int nr_set_cpus = 0;\n        char *s;\n\n        if (b_info->kernel) {\n            LOG(ERROR, \"HVM direct kernel boot is not supported by \"\n                \"qemu-xen-traditional\");\n            return NULL;\n        }\n\n        if (b_info->u.hvm.serial || b_info->u.hvm.serial_list) {\n            if ( b_info->u.hvm.serial && b_info->u.hvm.serial_list )\n            {\n                LOG(ERROR, \"Both serial and serial_list set\");\n                return NULL;\n            }\n            if (b_info->u.hvm.serial) {\n                flexarray_vappend(dm_args,\n                                  \"-serial\", b_info->u.hvm.serial, NULL);\n            } else if (b_info->u.hvm.serial_list) {\n                char **p;\n                for (p = b_info->u.hvm.serial_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-serial\",\n                                      *p, NULL);\n                }\n            }\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.nographic) && (!sdl && !vnc)) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n\n        if (b_info->video_memkb) {\n            flexarray_vappend(dm_args, \"-videoram\",\n                    libxl__sprintf(gc, \"%d\",\n                                   libxl__sizekb_to_mb(b_info->video_memkb)),\n                    NULL);\n        }\n\n        switch (b_info->u.hvm.vga.kind) {\n        case LIBXL_VGA_INTERFACE_TYPE_STD:\n            flexarray_append(dm_args, \"-std-vga\");\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_CIRRUS:\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_NONE:\n            flexarray_append_pair(dm_args, \"-vga\", \"none\");\n            break;\n        }\n\n        if (b_info->u.hvm.boot) {\n            flexarray_vappend(dm_args, \"-boot\", b_info->u.hvm.boot, NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.usb)\n            || b_info->u.hvm.usbdevice\n            || b_info->u.hvm.usbdevice_list) {\n            if ( b_info->u.hvm.usbdevice && b_info->u.hvm.usbdevice_list )\n            {\n                LOG(ERROR, \"Both usbdevice and usbdevice_list set\");\n                return NULL;\n            }\n            flexarray_append(dm_args, \"-usb\");\n            if (b_info->u.hvm.usbdevice) {\n                flexarray_vappend(dm_args,\n                                  \"-usbdevice\", b_info->u.hvm.usbdevice, NULL);\n            } else if (b_info->u.hvm.usbdevice_list) {\n                char **p;\n                for (p = b_info->u.hvm.usbdevice_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-usbdevice\",\n                                      *p, NULL);\n                }\n            }\n        }\n        if (b_info->u.hvm.soundhw) {\n            flexarray_vappend(dm_args, \"-soundhw\", b_info->u.hvm.soundhw, NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.acpi)) {\n            flexarray_append(dm_args, \"-acpi\");\n        }\n        if (b_info->max_vcpus > 1) {\n            flexarray_vappend(dm_args, \"-vcpus\",\n                              libxl__sprintf(gc, \"%d\", b_info->max_vcpus),\n                              NULL);\n        }\n\n        nr_set_cpus = libxl_bitmap_count_set(&b_info->avail_vcpus);\n        s = libxl_bitmap_to_hex_string(CTX, &b_info->avail_vcpus);\n        flexarray_vappend(dm_args, \"-vcpu_avail\",\n                              libxl__sprintf(gc, \"%s\", s), NULL);\n        free(s);\n\n        for (i = 0; i < num_nics; i++) {\n            if (nics[i].nictype == LIBXL_NIC_TYPE_VIF_IOEMU) {\n                char *smac = libxl__sprintf(gc,\n                                   LIBXL_MAC_FMT, LIBXL_MAC_BYTES(nics[i].mac));\n                const char *ifname = libxl__device_nic_devname(gc,\n                                                domid, nics[i].devid,\n                                                LIBXL_NIC_TYPE_VIF_IOEMU);\n                flexarray_vappend(dm_args,\n                                  \"-net\",\n                                  GCSPRINTF(\n                                      \"nic,vlan=%d,macaddr=%s,model=%s\",\n                                      nics[i].devid, smac, nics[i].model),\n                                  \"-net\",\n                                  GCSPRINTF(\n                                      \"tap,vlan=%d,ifname=%s,bridge=%s,\"\n                                      \"script=%s,downscript=%s\",\n                                      nics[i].devid, ifname, nics[i].bridge,\n                                      libxl_tapif_script(gc),\n                                      libxl_tapif_script(gc)),\n                                  NULL);\n                ioemu_nics++;\n            }\n        }\n        /* If we have no emulated nics, tell qemu not to create any */\n        if ( ioemu_nics == 0 ) {\n            flexarray_vappend(dm_args, \"-net\", \"none\", NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.gfx_passthru)) {\n            flexarray_append(dm_args, \"-gfx_passthru\");\n        }\n    } else {\n        if (!sdl && !vnc)\n            flexarray_append(dm_args, \"-nographic\");\n    }\n\n    if (state->saved_state) {\n        flexarray_vappend(dm_args, \"-loadvm\", state->saved_state, NULL);\n    }\n    for (i = 0; b_info->extra && b_info->extra[i] != NULL; i++)\n        flexarray_append(dm_args, b_info->extra[i]);\n    flexarray_append(dm_args, \"-M\");\n    switch (b_info->type) {\n    case LIBXL_DOMAIN_TYPE_PV:\n        flexarray_append(dm_args, \"xenpv\");\n        for (i = 0; b_info->extra_pv && b_info->extra_pv[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_pv[i]);\n        break;\n    case LIBXL_DOMAIN_TYPE_HVM:\n        flexarray_append(dm_args, \"xenfv\");\n        for (i = 0; b_info->extra_hvm && b_info->extra_hvm[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_hvm[i]);\n        break;\n    default:\n        abort();\n    }\n    flexarray_append(dm_args, NULL);\n    return (char **) flexarray_contents(dm_args);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,7 +56,14 @@\n         if (libxl_defbool_val(vnc->findunused)) {\n             flexarray_append(dm_args, \"-vncunused\");\n         }\n-    }\n+    } else\n+        /*\n+         * VNC is not enabled by default by qemu-xen-traditional,\n+         * however passing -vnc none causes SDL to not be\n+         * (unexpectedly) enabled by default. This is overridden by\n+         * explicitly passing -sdl below as required.\n+         */\n+        flexarray_append_pair(dm_args, \"-vnc\", \"none\");\n \n     if (sdl) {\n         flexarray_append(dm_args, \"-sdl\");",
        "diff_line_info": {
            "deleted_lines": [
                "    }"
            ],
            "added_lines": [
                "    } else",
                "        /*",
                "         * VNC is not enabled by default by qemu-xen-traditional,",
                "         * however passing -vnc none causes SDL to not be",
                "         * (unexpectedly) enabled by default. This is overridden by",
                "         * explicitly passing -sdl below as required.",
                "         */",
                "        flexarray_append_pair(dm_args, \"-vnc\", \"none\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1235",
        "func_name": "chromium/ContainerNode::parserRemoveChild",
        "description": "The ContainerNode::parserRemoveChild function in core/dom/ContainerNode.cpp in the HTML parser in Blink, as used in Google Chrome before 42.0.2311.90, allows remote attackers to bypass the Same Origin Policy via a crafted HTML document with an IFRAME element.",
        "git_url": "https://github.com/chromium/chromium/commit/74928e8fa2a5033dfd69584dc8a8321191fc44a4",
        "commit_title": "Fix inconsistent frame detach behavior of ContainerNode::parserRemoveChild.",
        "commit_text": " Before this CL, ContainerNode::parserRemoveChild didn't detach descendent <frame>s like ContainerNode::removeChild did. ContainerNode::parserRemoveChild is called from document parsers for reparenting, and this may leave the <frame>s in broken state.  This CL fixes the issue by issuing ChildFrameDisconnector from parserRemoveChild.  Node::updateAncestorConnectedSubframeCountForRemoval is removed, as the decrement is now issued from HTMLFrameOwnerElement::clearContentFrame called from fromChildFrameDisconnector.  Rebaselined: fast/parser/adoption-agency-crash-01.html fast/parser/adoption-agency-crash-03.html - The iframes parser removed shouldn't be invoked onload handler anyway.   ",
        "func_before": "void ContainerNode::parserRemoveChild(Node& oldChild)\n{\n    ASSERT(oldChild.parentNode() == this);\n    ASSERT(!oldChild.isDocumentFragment());\n\n    Node* prev = oldChild.previousSibling();\n    Node* next = oldChild.nextSibling();\n\n    oldChild.updateAncestorConnectedSubframeCountForRemoval();\n\n    ChildListMutationScope(*this).willRemoveChild(oldChild);\n    oldChild.notifyMutationObserversNodeWillDetach();\n\n    removeBetween(prev, next, oldChild);\n\n    notifyNodeRemoved(oldChild);\n    childrenChanged(ChildrenChange::forRemoval(oldChild, prev, next, ChildrenChangeSourceParser));\n}",
        "func": "void ContainerNode::parserRemoveChild(Node& oldChild)\n{\n    ASSERT(oldChild.parentNode() == this);\n    ASSERT(!oldChild.isDocumentFragment());\n\n    Node* prev = oldChild.previousSibling();\n    Node* next = oldChild.nextSibling();\n\n    if (oldChild.connectedSubframeCount())\n        ChildFrameDisconnector(oldChild).disconnect();\n\n    ChildListMutationScope(*this).willRemoveChild(oldChild);\n    oldChild.notifyMutationObserversNodeWillDetach();\n\n    removeBetween(prev, next, oldChild);\n\n    notifyNodeRemoved(oldChild);\n    childrenChanged(ChildrenChange::forRemoval(oldChild, prev, next, ChildrenChangeSourceParser));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,7 +6,8 @@\n     Node* prev = oldChild.previousSibling();\n     Node* next = oldChild.nextSibling();\n \n-    oldChild.updateAncestorConnectedSubframeCountForRemoval();\n+    if (oldChild.connectedSubframeCount())\n+        ChildFrameDisconnector(oldChild).disconnect();\n \n     ChildListMutationScope(*this).willRemoveChild(oldChild);\n     oldChild.notifyMutationObserversNodeWillDetach();",
        "diff_line_info": {
            "deleted_lines": [
                "    oldChild.updateAncestorConnectedSubframeCountForRemoval();"
            ],
            "added_lines": [
                "    if (oldChild.connectedSubframeCount())",
                "        ChildFrameDisconnector(oldChild).disconnect();"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1236",
        "func_name": "chromium/MediaElementAudioSourceNode::process",
        "description": "The MediaElementAudioSourceNode::process function in modules/webaudio/MediaElementAudioSourceNode.cpp in the Web Audio API implementation in Blink, as used in Google Chrome before 42.0.2311.90, allows remote attackers to bypass the Same Origin Policy and obtain sensitive audio sample values via a crafted web site containing a media element.",
        "git_url": "https://github.com/chromium/chromium/commit/6834289784ed45b5524de0fb7ef43ae283b0d6d3",
        "commit_title": "Output silence if the MediaElementAudioSourceNode has a different origin",
        "commit_text": " See http://webaudio.github.io/web-audio-api/#security-with-mediaelementaudiosourcenode-and-cross-origin-resources  Two new tests added for the same origin and a cross origin source.   ",
        "func_before": "void MediaElementAudioSourceNode::process(size_t numberOfFrames)\n{\n    AudioBus* outputBus = output(0)->bus();\n\n    if (!mediaElement() || !m_sourceNumberOfChannels || !m_sourceSampleRate) {\n        outputBus->zero();\n        return;\n    }\n\n    // Use a tryLock() to avoid contention in the real-time audio thread.\n    // If we fail to acquire the lock then the HTMLMediaElement must be in the middle of\n    // reconfiguring its playback engine, so we output silence in this case.\n    MutexTryLocker tryLocker(m_processLock);\n    if (tryLocker.locked()) {\n        if (AudioSourceProvider* provider = mediaElement()->audioSourceProvider()) {\n            if (m_multiChannelResampler.get()) {\n                ASSERT(m_sourceSampleRate != sampleRate());\n                m_multiChannelResampler->process(provider, outputBus, numberOfFrames);\n            } else {\n                // Bypass the resampler completely if the source is at the context's sample-rate.\n                ASSERT(m_sourceSampleRate == sampleRate());\n                provider->provideInput(outputBus, numberOfFrames);\n            }\n        } else {\n            // Either this port doesn't yet support HTMLMediaElement audio stream access,\n            // or the stream is not yet available.\n            outputBus->zero();\n        }\n    } else {\n        // We failed to acquire the lock.\n        outputBus->zero();\n    }\n}",
        "func": "void MediaElementAudioSourceNode::process(size_t numberOfFrames)\n{\n    AudioBus* outputBus = output(0)->bus();\n\n    if (!mediaElement() || !m_sourceNumberOfChannels || !m_sourceSampleRate) {\n        outputBus->zero();\n        return;\n    }\n\n    // Use a tryLock() to avoid contention in the real-time audio thread.\n    // If we fail to acquire the lock then the HTMLMediaElement must be in the middle of\n    // reconfiguring its playback engine, so we output silence in this case.\n    MutexTryLocker tryLocker(m_processLock);\n    if (tryLocker.locked()) {\n        if (AudioSourceProvider* provider = mediaElement()->audioSourceProvider()) {\n            // Grab data from the provider so that the element continues to make progress, even if\n            // we're going to output silence anyway.\n            if (m_multiChannelResampler.get()) {\n                ASSERT(m_sourceSampleRate != sampleRate());\n                m_multiChannelResampler->process(provider, outputBus, numberOfFrames);\n            } else {\n                // Bypass the resampler completely if the source is at the context's sample-rate.\n                ASSERT(m_sourceSampleRate == sampleRate());\n                provider->provideInput(outputBus, numberOfFrames);\n            }\n            // Output silence if we don't have access to the element.\n            if (!(mediaElement()->webMediaPlayer()->didPassCORSAccessCheck()\n                || context()->securityOrigin()->canRequest(mediaElement()->currentSrc()))) {\n                outputBus->zero();\n            }\n        } else {\n            // Either this port doesn't yet support HTMLMediaElement audio stream access,\n            // or the stream is not yet available.\n            outputBus->zero();\n        }\n    } else {\n        // We failed to acquire the lock.\n        outputBus->zero();\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,8 @@\n     MutexTryLocker tryLocker(m_processLock);\n     if (tryLocker.locked()) {\n         if (AudioSourceProvider* provider = mediaElement()->audioSourceProvider()) {\n+            // Grab data from the provider so that the element continues to make progress, even if\n+            // we're going to output silence anyway.\n             if (m_multiChannelResampler.get()) {\n                 ASSERT(m_sourceSampleRate != sampleRate());\n                 m_multiChannelResampler->process(provider, outputBus, numberOfFrames);\n@@ -20,6 +22,11 @@\n                 // Bypass the resampler completely if the source is at the context's sample-rate.\n                 ASSERT(m_sourceSampleRate == sampleRate());\n                 provider->provideInput(outputBus, numberOfFrames);\n+            }\n+            // Output silence if we don't have access to the element.\n+            if (!(mediaElement()->webMediaPlayer()->didPassCORSAccessCheck()\n+                || context()->securityOrigin()->canRequest(mediaElement()->currentSrc()))) {\n+                outputBus->zero();\n             }\n         } else {\n             // Either this port doesn't yet support HTMLMediaElement audio stream access,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "            // Grab data from the provider so that the element continues to make progress, even if",
                "            // we're going to output silence anyway.",
                "            }",
                "            // Output silence if we don't have access to the element.",
                "            if (!(mediaElement()->webMediaPlayer()->didPassCORSAccessCheck()",
                "                || context()->securityOrigin()->canRequest(mediaElement()->currentSrc()))) {",
                "                outputBus->zero();"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1254",
        "func_name": "chromium/Document::Document",
        "description": "core/dom/Document.cpp in Blink, as used in Google Chrome before 43.0.2357.65, enables the inheritance of the designMode attribute, which allows remote attackers to bypass the Same Origin Policy by leveraging the availability of editing.",
        "git_url": "https://github.com/chromium/chromium/commit/6c1f5c63fa856651e2ce54a3e68e97ee05f7c329",
        "commit_title": "Remove inheritance of designMode attribute.",
        "commit_text": " This matches the behavior of IE and Firefox, and conveniently removes a problematic bit of code for OOPI.   ",
        "func_before": "Document::Document(const DocumentInit& initializer, DocumentClassFlags documentClasses)\n    : ContainerNode(0, CreateDocument)\n    , TreeScope(*this)\n    , m_hasNodesWithPlaceholderStyle(false)\n    , m_evaluateMediaQueriesOnStyleRecalc(false)\n    , m_pendingSheetLayout(NoLayoutWithPendingSheets)\n    , m_frame(initializer.frame())\n    , m_domWindow(m_frame ? m_frame->localDOMWindow() : 0)\n    , m_importsController(initializer.importsController())\n    , m_activeParserCount(0)\n    , m_contextFeatures(ContextFeatures::defaultSwitch())\n    , m_wellFormed(false)\n    , m_printing(false)\n    , m_paginatedForScreen(false)\n    , m_compatibilityMode(NoQuirksMode)\n    , m_compatibilityModeLocked(false)\n    , m_executeScriptsWaitingForResourcesTimer(this, &Document::executeScriptsWaitingForResourcesTimerFired)\n    , m_hasAutofocused(false)\n    , m_clearFocusedElementTimer(this, &Document::clearFocusedElementTimerFired)\n    , m_domTreeVersion(++s_globalTreeVersion)\n    , m_styleVersion(0)\n    , m_listenerTypes(0)\n    , m_mutationObserverTypes(0)\n    , m_visitedLinkState(VisitedLinkState::create(*this))\n    , m_visuallyOrdered(false)\n    , m_readyState(Complete)\n    , m_parsingState(FinishedParsing)\n    , m_gotoAnchorNeededAfterStylesheetsLoad(false)\n    , m_containsValidityStyleRules(false)\n    , m_updateFocusAppearanceRestoresSelection(false)\n    , m_containsPlugins(false)\n    , m_ignoreDestructiveWriteCount(0)\n    , m_markers(adoptPtrWillBeNoop(new DocumentMarkerController))\n    , m_updateFocusAppearanceTimer(this, &Document::updateFocusAppearanceTimerFired)\n    , m_cssTarget(nullptr)\n    , m_loadEventProgress(LoadEventNotRun)\n    , m_startTime(currentTime())\n    , m_scriptRunner(ScriptRunner::create(this))\n    , m_xmlVersion(\"1.0\")\n    , m_xmlStandalone(StandaloneUnspecified)\n    , m_hasXMLDeclaration(0)\n    , m_designMode(inherit)\n    , m_hasAnnotatedRegions(false)\n    , m_annotatedRegionsDirty(false)\n    , m_useSecureKeyboardEntryWhenActive(false)\n    , m_documentClasses(documentClasses)\n    , m_isViewSource(false)\n    , m_sawElementsInKnownNamespaces(false)\n    , m_isSrcdocDocument(false)\n    , m_isMobileDocument(false)\n    , m_isTransitionDocument(false)\n    , m_layoutView(0)\n#if !ENABLE(OILPAN)\n    , m_weakFactory(this)\n#endif\n    , m_contextDocument(initializer.contextDocument())\n    , m_hasFullscreenSupplement(false)\n    , m_loadEventDelayCount(0)\n    , m_loadEventDelayTimer(this, &Document::loadEventDelayTimerFired)\n    , m_pluginLoadingTimer(this, &Document::pluginLoadingTimerFired)\n    , m_referrerPolicy(ReferrerPolicyDefault)\n    , m_writeRecursionIsTooDeep(false)\n    , m_writeRecursionDepth(0)\n    , m_taskRunner(MainThreadTaskRunner::create(this))\n    , m_registrationContext(initializer.registrationContext(this))\n    , m_elementDataCacheClearTimer(this, &Document::elementDataCacheClearTimerFired)\n    , m_timeline(AnimationTimeline::create(this))\n    , m_templateDocumentHost(nullptr)\n    , m_didAssociateFormControlsTimer(this, &Document::didAssociateFormControlsTimerFired)\n    , m_hasViewportUnits(false)\n    , m_styleRecalcElementCounter(0)\n    , m_parserSyncPolicy(AllowAsynchronousParsing)\n{\n    if (m_frame) {\n        ASSERT(m_frame->page());\n        provideContextFeaturesToDocumentFrom(*this, *m_frame->page());\n\n        m_fetcher = m_frame->loader().documentLoader()->fetcher();\n    }\n\n    if (!m_fetcher)\n        m_fetcher = FrameFetchContext::createContextAndFetcher(nullptr);\n    static_cast<FrameFetchContext&>(m_fetcher->context()).setDocument(this);\n\n    // We depend on the url getting immediately set in subframes, but we\n    // also depend on the url NOT getting immediately set in opened windows.\n    // See fast/dom/early-frame-url.html\n    // and fast/dom/location-new-window-no-crash.html, respectively.\n    // FIXME: Can/should we unify this behavior?\n    if (initializer.shouldSetURL())\n        setURL(initializer.url());\n\n    initSecurityContext(initializer);\n    initDNSPrefetch();\n\n#if !ENABLE(OILPAN)\n    for (unsigned i = 0; i < WTF_ARRAY_LENGTH(m_nodeListCounts); ++i)\n        m_nodeListCounts[i] = 0;\n#endif\n\n    InspectorCounters::incrementCounter(InspectorCounters::DocumentCounter);\n\n    m_lifecycle.advanceTo(DocumentLifecycle::Inactive);\n\n    // Since CSSFontSelector requires Document::m_fetcher and StyleEngine owns\n    // CSSFontSelector, need to initialize m_styleEngine after initializing\n    // m_fetcher.\n    m_styleEngine = StyleEngine::create(*this);\n\n    // The parent's parser should be suspended together with all the other objects,\n    // else this new Document would have a new ExecutionContext which suspended state\n    // would not match the one from the parent, and could start loading resources\n    // ignoring the defersLoading flag.\n    ASSERT(!parentDocument() || !parentDocument()->activeDOMObjectsAreSuspended());\n\n#ifndef NDEBUG\n    liveDocumentSet().add(this);\n#endif\n}",
        "func": "Document::Document(const DocumentInit& initializer, DocumentClassFlags documentClasses)\n    : ContainerNode(0, CreateDocument)\n    , TreeScope(*this)\n    , m_hasNodesWithPlaceholderStyle(false)\n    , m_evaluateMediaQueriesOnStyleRecalc(false)\n    , m_pendingSheetLayout(NoLayoutWithPendingSheets)\n    , m_frame(initializer.frame())\n    , m_domWindow(m_frame ? m_frame->localDOMWindow() : 0)\n    , m_importsController(initializer.importsController())\n    , m_activeParserCount(0)\n    , m_contextFeatures(ContextFeatures::defaultSwitch())\n    , m_wellFormed(false)\n    , m_printing(false)\n    , m_paginatedForScreen(false)\n    , m_compatibilityMode(NoQuirksMode)\n    , m_compatibilityModeLocked(false)\n    , m_executeScriptsWaitingForResourcesTimer(this, &Document::executeScriptsWaitingForResourcesTimerFired)\n    , m_hasAutofocused(false)\n    , m_clearFocusedElementTimer(this, &Document::clearFocusedElementTimerFired)\n    , m_domTreeVersion(++s_globalTreeVersion)\n    , m_styleVersion(0)\n    , m_listenerTypes(0)\n    , m_mutationObserverTypes(0)\n    , m_visitedLinkState(VisitedLinkState::create(*this))\n    , m_visuallyOrdered(false)\n    , m_readyState(Complete)\n    , m_parsingState(FinishedParsing)\n    , m_gotoAnchorNeededAfterStylesheetsLoad(false)\n    , m_containsValidityStyleRules(false)\n    , m_updateFocusAppearanceRestoresSelection(false)\n    , m_containsPlugins(false)\n    , m_ignoreDestructiveWriteCount(0)\n    , m_markers(adoptPtrWillBeNoop(new DocumentMarkerController))\n    , m_updateFocusAppearanceTimer(this, &Document::updateFocusAppearanceTimerFired)\n    , m_cssTarget(nullptr)\n    , m_loadEventProgress(LoadEventNotRun)\n    , m_startTime(currentTime())\n    , m_scriptRunner(ScriptRunner::create(this))\n    , m_xmlVersion(\"1.0\")\n    , m_xmlStandalone(StandaloneUnspecified)\n    , m_hasXMLDeclaration(0)\n    , m_designMode(false)\n    , m_hasAnnotatedRegions(false)\n    , m_annotatedRegionsDirty(false)\n    , m_useSecureKeyboardEntryWhenActive(false)\n    , m_documentClasses(documentClasses)\n    , m_isViewSource(false)\n    , m_sawElementsInKnownNamespaces(false)\n    , m_isSrcdocDocument(false)\n    , m_isMobileDocument(false)\n    , m_isTransitionDocument(false)\n    , m_layoutView(0)\n#if !ENABLE(OILPAN)\n    , m_weakFactory(this)\n#endif\n    , m_contextDocument(initializer.contextDocument())\n    , m_hasFullscreenSupplement(false)\n    , m_loadEventDelayCount(0)\n    , m_loadEventDelayTimer(this, &Document::loadEventDelayTimerFired)\n    , m_pluginLoadingTimer(this, &Document::pluginLoadingTimerFired)\n    , m_referrerPolicy(ReferrerPolicyDefault)\n    , m_writeRecursionIsTooDeep(false)\n    , m_writeRecursionDepth(0)\n    , m_taskRunner(MainThreadTaskRunner::create(this))\n    , m_registrationContext(initializer.registrationContext(this))\n    , m_elementDataCacheClearTimer(this, &Document::elementDataCacheClearTimerFired)\n    , m_timeline(AnimationTimeline::create(this))\n    , m_templateDocumentHost(nullptr)\n    , m_didAssociateFormControlsTimer(this, &Document::didAssociateFormControlsTimerFired)\n    , m_hasViewportUnits(false)\n    , m_styleRecalcElementCounter(0)\n    , m_parserSyncPolicy(AllowAsynchronousParsing)\n{\n    if (m_frame) {\n        ASSERT(m_frame->page());\n        provideContextFeaturesToDocumentFrom(*this, *m_frame->page());\n\n        m_fetcher = m_frame->loader().documentLoader()->fetcher();\n    }\n\n    if (!m_fetcher)\n        m_fetcher = FrameFetchContext::createContextAndFetcher(nullptr);\n    static_cast<FrameFetchContext&>(m_fetcher->context()).setDocument(this);\n\n    // We depend on the url getting immediately set in subframes, but we\n    // also depend on the url NOT getting immediately set in opened windows.\n    // See fast/dom/early-frame-url.html\n    // and fast/dom/location-new-window-no-crash.html, respectively.\n    // FIXME: Can/should we unify this behavior?\n    if (initializer.shouldSetURL())\n        setURL(initializer.url());\n\n    initSecurityContext(initializer);\n    initDNSPrefetch();\n\n#if !ENABLE(OILPAN)\n    for (unsigned i = 0; i < WTF_ARRAY_LENGTH(m_nodeListCounts); ++i)\n        m_nodeListCounts[i] = 0;\n#endif\n\n    InspectorCounters::incrementCounter(InspectorCounters::DocumentCounter);\n\n    m_lifecycle.advanceTo(DocumentLifecycle::Inactive);\n\n    // Since CSSFontSelector requires Document::m_fetcher and StyleEngine owns\n    // CSSFontSelector, need to initialize m_styleEngine after initializing\n    // m_fetcher.\n    m_styleEngine = StyleEngine::create(*this);\n\n    // The parent's parser should be suspended together with all the other objects,\n    // else this new Document would have a new ExecutionContext which suspended state\n    // would not match the one from the parent, and could start loading resources\n    // ignoring the defersLoading flag.\n    ASSERT(!parentDocument() || !parentDocument()->activeDOMObjectsAreSuspended());\n\n#ifndef NDEBUG\n    liveDocumentSet().add(this);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -39,7 +39,7 @@\n     , m_xmlVersion(\"1.0\")\n     , m_xmlStandalone(StandaloneUnspecified)\n     , m_hasXMLDeclaration(0)\n-    , m_designMode(inherit)\n+    , m_designMode(false)\n     , m_hasAnnotatedRegions(false)\n     , m_annotatedRegionsDirty(false)\n     , m_useSecureKeyboardEntryWhenActive(false)",
        "diff_line_info": {
            "deleted_lines": [
                "    , m_designMode(inherit)"
            ],
            "added_lines": [
                "    , m_designMode(false)"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2694",
        "func_name": "krb5/on_response",
        "description": "The kdcpreauth modules in MIT Kerberos 5 (aka krb5) 1.12.x and 1.13.x before 1.13.2 do not properly track whether a client's request has been validated, which allows remote attackers to bypass an intended preauthentication requirement by providing (1) zero bytes of data or (2) an arbitrary realm name, related to plugins/preauth/otp/main.c and plugins/preauth/pkinit/pkinit_srv.c.",
        "git_url": "https://github.com/krb5/krb5/commit/e3b5a5e5267818c97750b266df50b6a3d4649604",
        "commit_title": "Prevent requires_preauth bypass [CVE-2015-2694]",
        "commit_text": " In the OTP kdcpreauth module, don't set the TKT_FLG_PRE_AUTH bit until the request is successfully verified.  In the PKINIT kdcpreauth module, don't respond with code 0 on empty input or an unconfigured realm.  Together these bugs could cause the KDC preauth framework to erroneously treat a request as pre-authenticated.  CVE-2015-2694:  In MIT krb5 1.12 and later, when the KDC is configured with PKINIT support, an unauthenticated remote attacker can bypass the requires_preauth flag on a client principal and obtain a ciphertext encrypted in the principal's long-term key.  This ciphertext could be used to conduct an off-line dictionary attack against the user's password.      CVSSv2 Vector: AV:N/AC:M/Au:N/C:P/I:P/A:N/E:POC/RL:OF/RC:C  ticket: 8160 (new) target_version: 1.13.2 tags: pullup subject: requires_preauth bypass in PKINIT-enabled KDC [CVE-2015-2694]",
        "func_before": "static void\non_response(void *data, krb5_error_code retval, otp_response response)\n{\n    struct request_state rs = *(struct request_state *)data;\n\n    free(data);\n\n    if (retval == 0 && response != otp_response_success)\n        retval = KRB5_PREAUTH_FAILED;\n\n    rs.respond(rs.arg, retval, NULL, NULL, NULL);\n}",
        "func": "static void\non_response(void *data, krb5_error_code retval, otp_response response)\n{\n    struct request_state rs = *(struct request_state *)data;\n\n    free(data);\n\n    if (retval == 0 && response != otp_response_success)\n        retval = KRB5_PREAUTH_FAILED;\n\n    if (retval == 0)\n        rs.enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;\n\n    rs.respond(rs.arg, retval, NULL, NULL, NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,5 +8,8 @@\n     if (retval == 0 && response != otp_response_success)\n         retval = KRB5_PREAUTH_FAILED;\n \n+    if (retval == 0)\n+        rs.enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;\n+\n     rs.respond(rs.arg, retval, NULL, NULL, NULL);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (retval == 0)",
                "        rs.enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2694",
        "func_name": "krb5/otp_verify",
        "description": "The kdcpreauth modules in MIT Kerberos 5 (aka krb5) 1.12.x and 1.13.x before 1.13.2 do not properly track whether a client's request has been validated, which allows remote attackers to bypass an intended preauthentication requirement by providing (1) zero bytes of data or (2) an arbitrary realm name, related to plugins/preauth/otp/main.c and plugins/preauth/pkinit/pkinit_srv.c.",
        "git_url": "https://github.com/krb5/krb5/commit/e3b5a5e5267818c97750b266df50b6a3d4649604",
        "commit_title": "Prevent requires_preauth bypass [CVE-2015-2694]",
        "commit_text": " In the OTP kdcpreauth module, don't set the TKT_FLG_PRE_AUTH bit until the request is successfully verified.  In the PKINIT kdcpreauth module, don't respond with code 0 on empty input or an unconfigured realm.  Together these bugs could cause the KDC preauth framework to erroneously treat a request as pre-authenticated.  CVE-2015-2694:  In MIT krb5 1.12 and later, when the KDC is configured with PKINIT support, an unauthenticated remote attacker can bypass the requires_preauth flag on a client principal and obtain a ciphertext encrypted in the principal's long-term key.  This ciphertext could be used to conduct an off-line dictionary attack against the user's password.      CVSSv2 Vector: AV:N/AC:M/Au:N/C:P/I:P/A:N/E:POC/RL:OF/RC:C  ticket: 8160 (new) target_version: 1.13.2 tags: pullup subject: requires_preauth bypass in PKINIT-enabled KDC [CVE-2015-2694]",
        "func_before": "static void\notp_verify(krb5_context context, krb5_data *req_pkt, krb5_kdc_req *request,\n           krb5_enc_tkt_part *enc_tkt_reply, krb5_pa_data *pa,\n           krb5_kdcpreauth_callbacks cb, krb5_kdcpreauth_rock rock,\n           krb5_kdcpreauth_moddata moddata,\n           krb5_kdcpreauth_verify_respond_fn respond, void *arg)\n{\n    krb5_keyblock *armor_key = NULL;\n    krb5_pa_otp_req *req = NULL;\n    struct request_state *rs;\n    krb5_error_code retval;\n    krb5_data d, plaintext;\n    char *config;\n\n    enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;\n\n    /* Get the FAST armor key. */\n    armor_key = cb->fast_armor(context, rock);\n    if (armor_key == NULL) {\n        retval = KRB5KDC_ERR_PREAUTH_FAILED;\n        com_err(\"otp\", retval, \"No armor key found when verifying padata\");\n        goto error;\n    }\n\n    /* Decode the request. */\n    d = make_data(pa->contents, pa->length);\n    retval = decode_krb5_pa_otp_req(&d, &req);\n    if (retval != 0) {\n        com_err(\"otp\", retval, \"Unable to decode OTP request\");\n        goto error;\n    }\n\n    /* Decrypt the nonce from the request. */\n    retval = decrypt_encdata(context, armor_key, req, &plaintext);\n    if (retval != 0) {\n        com_err(\"otp\", retval, \"Unable to decrypt nonce\");\n        goto error;\n    }\n\n    /* Verify the nonce or timestamp. */\n    retval = nonce_verify(context, armor_key, &plaintext);\n    if (retval != 0)\n        retval = timestamp_verify(context, &plaintext);\n    krb5_free_data_contents(context, &plaintext);\n    if (retval != 0) {\n        com_err(\"otp\", retval, \"Unable to verify nonce or timestamp\");\n        goto error;\n    }\n\n    /* Create the request state. */\n    rs = k5alloc(sizeof(struct request_state), &retval);\n    if (rs == NULL)\n        goto error;\n    rs->arg = arg;\n    rs->respond = respond;\n\n    /* Get the principal's OTP configuration string. */\n    retval = cb->get_string(context, rock, \"otp\", &config);\n    if (retval == 0 && config == NULL)\n        retval = KRB5_PREAUTH_FAILED;\n    if (retval != 0) {\n        free(rs);\n        goto error;\n    }\n\n    /* Send the request. */\n    otp_state_verify((otp_state *)moddata, cb->event_context(context, rock),\n                     request->client, config, req, on_response, rs);\n    cb->free_string(context, rock, config);\n\n    k5_free_pa_otp_req(context, req);\n    return;\n\nerror:\n    k5_free_pa_otp_req(context, req);\n    (*respond)(arg, retval, NULL, NULL, NULL);\n}",
        "func": "static void\notp_verify(krb5_context context, krb5_data *req_pkt, krb5_kdc_req *request,\n           krb5_enc_tkt_part *enc_tkt_reply, krb5_pa_data *pa,\n           krb5_kdcpreauth_callbacks cb, krb5_kdcpreauth_rock rock,\n           krb5_kdcpreauth_moddata moddata,\n           krb5_kdcpreauth_verify_respond_fn respond, void *arg)\n{\n    krb5_keyblock *armor_key = NULL;\n    krb5_pa_otp_req *req = NULL;\n    struct request_state *rs;\n    krb5_error_code retval;\n    krb5_data d, plaintext;\n    char *config;\n\n    /* Get the FAST armor key. */\n    armor_key = cb->fast_armor(context, rock);\n    if (armor_key == NULL) {\n        retval = KRB5KDC_ERR_PREAUTH_FAILED;\n        com_err(\"otp\", retval, \"No armor key found when verifying padata\");\n        goto error;\n    }\n\n    /* Decode the request. */\n    d = make_data(pa->contents, pa->length);\n    retval = decode_krb5_pa_otp_req(&d, &req);\n    if (retval != 0) {\n        com_err(\"otp\", retval, \"Unable to decode OTP request\");\n        goto error;\n    }\n\n    /* Decrypt the nonce from the request. */\n    retval = decrypt_encdata(context, armor_key, req, &plaintext);\n    if (retval != 0) {\n        com_err(\"otp\", retval, \"Unable to decrypt nonce\");\n        goto error;\n    }\n\n    /* Verify the nonce or timestamp. */\n    retval = nonce_verify(context, armor_key, &plaintext);\n    if (retval != 0)\n        retval = timestamp_verify(context, &plaintext);\n    krb5_free_data_contents(context, &plaintext);\n    if (retval != 0) {\n        com_err(\"otp\", retval, \"Unable to verify nonce or timestamp\");\n        goto error;\n    }\n\n    /* Create the request state.  Save the response callback, and the\n     * enc_tkt_reply pointer so we can set the TKT_FLG_PRE_AUTH flag later. */\n    rs = k5alloc(sizeof(struct request_state), &retval);\n    if (rs == NULL)\n        goto error;\n    rs->arg = arg;\n    rs->respond = respond;\n    rs->enc_tkt_reply = enc_tkt_reply;\n\n    /* Get the principal's OTP configuration string. */\n    retval = cb->get_string(context, rock, \"otp\", &config);\n    if (retval == 0 && config == NULL)\n        retval = KRB5_PREAUTH_FAILED;\n    if (retval != 0) {\n        free(rs);\n        goto error;\n    }\n\n    /* Send the request. */\n    otp_state_verify((otp_state *)moddata, cb->event_context(context, rock),\n                     request->client, config, req, on_response, rs);\n    cb->free_string(context, rock, config);\n\n    k5_free_pa_otp_req(context, req);\n    return;\n\nerror:\n    k5_free_pa_otp_req(context, req);\n    (*respond)(arg, retval, NULL, NULL, NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,8 +11,6 @@\n     krb5_error_code retval;\n     krb5_data d, plaintext;\n     char *config;\n-\n-    enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;\n \n     /* Get the FAST armor key. */\n     armor_key = cb->fast_armor(context, rock);\n@@ -47,12 +45,14 @@\n         goto error;\n     }\n \n-    /* Create the request state. */\n+    /* Create the request state.  Save the response callback, and the\n+     * enc_tkt_reply pointer so we can set the TKT_FLG_PRE_AUTH flag later. */\n     rs = k5alloc(sizeof(struct request_state), &retval);\n     if (rs == NULL)\n         goto error;\n     rs->arg = arg;\n     rs->respond = respond;\n+    rs->enc_tkt_reply = enc_tkt_reply;\n \n     /* Get the principal's OTP configuration string. */\n     retval = cb->get_string(context, rock, \"otp\", &config);",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "    enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;",
                "    /* Create the request state. */"
            ],
            "added_lines": [
                "    /* Create the request state.  Save the response callback, and the",
                "     * enc_tkt_reply pointer so we can set the TKT_FLG_PRE_AUTH flag later. */",
                "    rs->enc_tkt_reply = enc_tkt_reply;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2694",
        "func_name": "krb5/pkinit_server_verify_padata",
        "description": "The kdcpreauth modules in MIT Kerberos 5 (aka krb5) 1.12.x and 1.13.x before 1.13.2 do not properly track whether a client's request has been validated, which allows remote attackers to bypass an intended preauthentication requirement by providing (1) zero bytes of data or (2) an arbitrary realm name, related to plugins/preauth/otp/main.c and plugins/preauth/pkinit/pkinit_srv.c.",
        "git_url": "https://github.com/krb5/krb5/commit/e3b5a5e5267818c97750b266df50b6a3d4649604",
        "commit_title": "Prevent requires_preauth bypass [CVE-2015-2694]",
        "commit_text": " In the OTP kdcpreauth module, don't set the TKT_FLG_PRE_AUTH bit until the request is successfully verified.  In the PKINIT kdcpreauth module, don't respond with code 0 on empty input or an unconfigured realm.  Together these bugs could cause the KDC preauth framework to erroneously treat a request as pre-authenticated.  CVE-2015-2694:  In MIT krb5 1.12 and later, when the KDC is configured with PKINIT support, an unauthenticated remote attacker can bypass the requires_preauth flag on a client principal and obtain a ciphertext encrypted in the principal's long-term key.  This ciphertext could be used to conduct an off-line dictionary attack against the user's password.      CVSSv2 Vector: AV:N/AC:M/Au:N/C:P/I:P/A:N/E:POC/RL:OF/RC:C  ticket: 8160 (new) target_version: 1.13.2 tags: pullup subject: requires_preauth bypass in PKINIT-enabled KDC [CVE-2015-2694]",
        "func_before": "static void\npkinit_server_verify_padata(krb5_context context,\n                            krb5_data *req_pkt,\n                            krb5_kdc_req * request,\n                            krb5_enc_tkt_part * enc_tkt_reply,\n                            krb5_pa_data * data,\n                            krb5_kdcpreauth_callbacks cb,\n                            krb5_kdcpreauth_rock rock,\n                            krb5_kdcpreauth_moddata moddata,\n                            krb5_kdcpreauth_verify_respond_fn respond,\n                            void *arg)\n{\n    krb5_error_code retval = 0;\n    krb5_data authp_data = {0, 0, NULL}, krb5_authz = {0, 0, NULL};\n    krb5_pa_pk_as_req *reqp = NULL;\n    krb5_pa_pk_as_req_draft9 *reqp9 = NULL;\n    krb5_auth_pack *auth_pack = NULL;\n    krb5_auth_pack_draft9 *auth_pack9 = NULL;\n    pkinit_kdc_context plgctx = NULL;\n    pkinit_kdc_req_context reqctx = NULL;\n    krb5_checksum cksum = {0, 0, 0, NULL};\n    krb5_data *der_req = NULL;\n    int valid_eku = 0, valid_san = 0;\n    krb5_data k5data;\n    int is_signed = 1;\n    krb5_pa_data **e_data = NULL;\n    krb5_kdcpreauth_modreq modreq = NULL;\n\n    pkiDebug(\"pkinit_verify_padata: entered!\\n\");\n    if (data == NULL || data->length <= 0 || data->contents == NULL) {\n        (*respond)(arg, 0, NULL, NULL, NULL);\n        return;\n    }\n\n\n    if (moddata == NULL) {\n        (*respond)(arg, EINVAL, NULL, NULL, NULL);\n        return;\n    }\n\n    plgctx = pkinit_find_realm_context(context, moddata, request->server);\n    if (plgctx == NULL) {\n        (*respond)(arg, 0, NULL, NULL, NULL);\n        return;\n    }\n\n#ifdef DEBUG_ASN1\n    print_buffer_bin(data->contents, data->length, \"/tmp/kdc_as_req\");\n#endif\n    /* create a per-request context */\n    retval = pkinit_init_kdc_req_context(context, &reqctx);\n    if (retval)\n        goto cleanup;\n    reqctx->pa_type = data->pa_type;\n\n    PADATA_TO_KRB5DATA(data, &k5data);\n\n    switch ((int)data->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        pkiDebug(\"processing KRB5_PADATA_PK_AS_REQ\\n\");\n        retval = k5int_decode_krb5_pa_pk_as_req(&k5data, &reqp);\n        if (retval) {\n            pkiDebug(\"decode_krb5_pa_pk_as_req failed\\n\");\n            goto cleanup;\n        }\n#ifdef DEBUG_ASN1\n        print_buffer_bin(reqp->signedAuthPack.data,\n                         reqp->signedAuthPack.length,\n                         \"/tmp/kdc_signed_data\");\n#endif\n        retval = cms_signeddata_verify(context, plgctx->cryptoctx,\n                                       reqctx->cryptoctx, plgctx->idctx, CMS_SIGN_CLIENT,\n                                       plgctx->opts->require_crl_checking,\n                                       (unsigned char *)\n                                       reqp->signedAuthPack.data, reqp->signedAuthPack.length,\n                                       (unsigned char **)&authp_data.data,\n                                       &authp_data.length,\n                                       (unsigned char **)&krb5_authz.data,\n                                       &krb5_authz.length, &is_signed);\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        pkiDebug(\"processing KRB5_PADATA_PK_AS_REQ_OLD\\n\");\n        retval = k5int_decode_krb5_pa_pk_as_req_draft9(&k5data, &reqp9);\n        if (retval) {\n            pkiDebug(\"decode_krb5_pa_pk_as_req_draft9 failed\\n\");\n            goto cleanup;\n        }\n#ifdef DEBUG_ASN1\n        print_buffer_bin(reqp9->signedAuthPack.data,\n                         reqp9->signedAuthPack.length,\n                         \"/tmp/kdc_signed_data_draft9\");\n#endif\n\n        retval = cms_signeddata_verify(context, plgctx->cryptoctx,\n                                       reqctx->cryptoctx, plgctx->idctx, CMS_SIGN_DRAFT9,\n                                       plgctx->opts->require_crl_checking,\n                                       (unsigned char *)\n                                       reqp9->signedAuthPack.data, reqp9->signedAuthPack.length,\n                                       (unsigned char **)&authp_data.data,\n                                       &authp_data.length,\n                                       (unsigned char **)&krb5_authz.data,\n                                       &krb5_authz.length, NULL);\n        break;\n    default:\n        pkiDebug(\"unrecognized pa_type = %d\\n\", data->pa_type);\n        retval = EINVAL;\n        goto cleanup;\n    }\n    if (retval) {\n        pkiDebug(\"pkcs7_signeddata_verify failed\\n\");\n        goto cleanup;\n    }\n    if (is_signed) {\n\n        retval = verify_client_san(context, plgctx, reqctx, request->client,\n                                   &valid_san);\n        if (retval)\n            goto cleanup;\n        if (!valid_san) {\n            pkiDebug(\"%s: did not find an acceptable SAN in user \"\n                     \"certificate\\n\", __FUNCTION__);\n            retval = KRB5KDC_ERR_CLIENT_NAME_MISMATCH;\n            goto cleanup;\n        }\n        retval = verify_client_eku(context, plgctx, reqctx, &valid_eku);\n        if (retval)\n            goto cleanup;\n\n        if (!valid_eku) {\n            pkiDebug(\"%s: did not find an acceptable EKU in user \"\n                     \"certificate\\n\", __FUNCTION__);\n            retval = KRB5KDC_ERR_INCONSISTENT_KEY_PURPOSE;\n            goto cleanup;\n        }\n    } else { /* !is_signed */\n        if (!krb5_principal_compare(context, request->client,\n                                    krb5_anonymous_principal())) {\n            retval = KRB5KDC_ERR_PREAUTH_FAILED;\n            krb5_set_error_message(context, retval,\n                                   _(\"Pkinit request not signed, but client \"\n                                     \"not anonymous.\"));\n            goto cleanup;\n        }\n    }\n#ifdef DEBUG_ASN1\n    print_buffer_bin(authp_data.data, authp_data.length, \"/tmp/kdc_auth_pack\");\n#endif\n\n    OCTETDATA_TO_KRB5DATA(&authp_data, &k5data);\n    switch ((int)data->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        retval = k5int_decode_krb5_auth_pack(&k5data, &auth_pack);\n        if (retval) {\n            pkiDebug(\"failed to decode krb5_auth_pack\\n\");\n            goto cleanup;\n        }\n\n        retval = krb5_check_clockskew(context,\n                                      auth_pack->pkAuthenticator.ctime);\n        if (retval)\n            goto cleanup;\n\n        /* check dh parameters */\n        if (auth_pack->clientPublicValue != NULL) {\n            retval = server_check_dh(context, plgctx->cryptoctx,\n                                     reqctx->cryptoctx, plgctx->idctx,\n                                     &auth_pack->clientPublicValue->algorithm.parameters,\n                                     plgctx->opts->dh_min_bits);\n\n            if (retval) {\n                pkiDebug(\"bad dh parameters\\n\");\n                goto cleanup;\n            }\n        } else if (!is_signed) {\n            /*Anonymous pkinit requires DH*/\n            retval = KRB5KDC_ERR_PREAUTH_FAILED;\n            krb5_set_error_message(context, retval,\n                                   _(\"Anonymous pkinit without DH public \"\n                                     \"value not supported.\"));\n            goto cleanup;\n        }\n        der_req = cb->request_body(context, rock);\n        retval = krb5_c_make_checksum(context, CKSUMTYPE_NIST_SHA, NULL,\n                                      0, der_req, &cksum);\n        if (retval) {\n            pkiDebug(\"unable to calculate AS REQ checksum\\n\");\n            goto cleanup;\n        }\n        if (cksum.length != auth_pack->pkAuthenticator.paChecksum.length ||\n            k5_bcmp(cksum.contents,\n                    auth_pack->pkAuthenticator.paChecksum.contents,\n                    cksum.length) != 0) {\n            pkiDebug(\"failed to match the checksum\\n\");\n#ifdef DEBUG_CKSUM\n            pkiDebug(\"calculating checksum on buf size (%d)\\n\",\n                     req_pkt->length);\n            print_buffer(req_pkt->data, req_pkt->length);\n            pkiDebug(\"received checksum type=%d size=%d \",\n                     auth_pack->pkAuthenticator.paChecksum.checksum_type,\n                     auth_pack->pkAuthenticator.paChecksum.length);\n            print_buffer(auth_pack->pkAuthenticator.paChecksum.contents,\n                         auth_pack->pkAuthenticator.paChecksum.length);\n            pkiDebug(\"expected checksum type=%d size=%d \",\n                     cksum.checksum_type, cksum.length);\n            print_buffer(cksum.contents, cksum.length);\n#endif\n\n            retval = KRB5KDC_ERR_PA_CHECKSUM_MUST_BE_INCLUDED;\n            goto cleanup;\n        }\n\n        /* check if kdcPkId present and match KDC's subjectIdentifier */\n        if (reqp->kdcPkId.data != NULL) {\n            int valid_kdcPkId = 0;\n            retval = pkinit_check_kdc_pkid(context, plgctx->cryptoctx,\n                                           reqctx->cryptoctx, plgctx->idctx,\n                                           (unsigned char *)reqp->kdcPkId.data,\n                                           reqp->kdcPkId.length, &valid_kdcPkId);\n            if (retval)\n                goto cleanup;\n            if (!valid_kdcPkId)\n                pkiDebug(\"kdcPkId in AS_REQ does not match KDC's cert\"\n                         \"RFC says to ignore and proceed\\n\");\n\n        }\n        /* remember the decoded auth_pack for verify_padata routine */\n        reqctx->rcv_auth_pack = auth_pack;\n        auth_pack = NULL;\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        retval = k5int_decode_krb5_auth_pack_draft9(&k5data, &auth_pack9);\n        if (retval) {\n            pkiDebug(\"failed to decode krb5_auth_pack_draft9\\n\");\n            goto cleanup;\n        }\n        if (auth_pack9->clientPublicValue != NULL) {\n            retval = server_check_dh(context, plgctx->cryptoctx,\n                                     reqctx->cryptoctx, plgctx->idctx,\n                                     &auth_pack9->clientPublicValue->algorithm.parameters,\n                                     plgctx->opts->dh_min_bits);\n\n            if (retval) {\n                pkiDebug(\"bad dh parameters\\n\");\n                goto cleanup;\n            }\n        }\n        /* remember the decoded auth_pack for verify_padata routine */\n        reqctx->rcv_auth_pack9 = auth_pack9;\n        auth_pack9 = NULL;\n        break;\n    }\n\n    /* remember to set the PREAUTH flag in the reply */\n    enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;\n    modreq = (krb5_kdcpreauth_modreq)reqctx;\n    reqctx = NULL;\n\ncleanup:\n    if (retval && data->pa_type == KRB5_PADATA_PK_AS_REQ) {\n        pkiDebug(\"pkinit_verify_padata failed: creating e-data\\n\");\n        if (pkinit_create_edata(context, plgctx->cryptoctx, reqctx->cryptoctx,\n                                plgctx->idctx, plgctx->opts, retval, &e_data))\n            pkiDebug(\"pkinit_create_edata failed\\n\");\n    }\n\n    switch ((int)data->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        free_krb5_pa_pk_as_req(&reqp);\n        free(cksum.contents);\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        free_krb5_pa_pk_as_req_draft9(&reqp9);\n    }\n    free(authp_data.data);\n    free(krb5_authz.data);\n    if (reqctx != NULL)\n        pkinit_fini_kdc_req_context(context, reqctx);\n    free_krb5_auth_pack(&auth_pack);\n    free_krb5_auth_pack_draft9(context, &auth_pack9);\n\n    (*respond)(arg, retval, modreq, e_data, NULL);\n}",
        "func": "static void\npkinit_server_verify_padata(krb5_context context,\n                            krb5_data *req_pkt,\n                            krb5_kdc_req * request,\n                            krb5_enc_tkt_part * enc_tkt_reply,\n                            krb5_pa_data * data,\n                            krb5_kdcpreauth_callbacks cb,\n                            krb5_kdcpreauth_rock rock,\n                            krb5_kdcpreauth_moddata moddata,\n                            krb5_kdcpreauth_verify_respond_fn respond,\n                            void *arg)\n{\n    krb5_error_code retval = 0;\n    krb5_data authp_data = {0, 0, NULL}, krb5_authz = {0, 0, NULL};\n    krb5_pa_pk_as_req *reqp = NULL;\n    krb5_pa_pk_as_req_draft9 *reqp9 = NULL;\n    krb5_auth_pack *auth_pack = NULL;\n    krb5_auth_pack_draft9 *auth_pack9 = NULL;\n    pkinit_kdc_context plgctx = NULL;\n    pkinit_kdc_req_context reqctx = NULL;\n    krb5_checksum cksum = {0, 0, 0, NULL};\n    krb5_data *der_req = NULL;\n    int valid_eku = 0, valid_san = 0;\n    krb5_data k5data;\n    int is_signed = 1;\n    krb5_pa_data **e_data = NULL;\n    krb5_kdcpreauth_modreq modreq = NULL;\n\n    pkiDebug(\"pkinit_verify_padata: entered!\\n\");\n    if (data == NULL || data->length <= 0 || data->contents == NULL) {\n        (*respond)(arg, EINVAL, NULL, NULL, NULL);\n        return;\n    }\n\n\n    if (moddata == NULL) {\n        (*respond)(arg, EINVAL, NULL, NULL, NULL);\n        return;\n    }\n\n    plgctx = pkinit_find_realm_context(context, moddata, request->server);\n    if (plgctx == NULL) {\n        (*respond)(arg, EINVAL, NULL, NULL, NULL);\n        return;\n    }\n\n#ifdef DEBUG_ASN1\n    print_buffer_bin(data->contents, data->length, \"/tmp/kdc_as_req\");\n#endif\n    /* create a per-request context */\n    retval = pkinit_init_kdc_req_context(context, &reqctx);\n    if (retval)\n        goto cleanup;\n    reqctx->pa_type = data->pa_type;\n\n    PADATA_TO_KRB5DATA(data, &k5data);\n\n    switch ((int)data->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        pkiDebug(\"processing KRB5_PADATA_PK_AS_REQ\\n\");\n        retval = k5int_decode_krb5_pa_pk_as_req(&k5data, &reqp);\n        if (retval) {\n            pkiDebug(\"decode_krb5_pa_pk_as_req failed\\n\");\n            goto cleanup;\n        }\n#ifdef DEBUG_ASN1\n        print_buffer_bin(reqp->signedAuthPack.data,\n                         reqp->signedAuthPack.length,\n                         \"/tmp/kdc_signed_data\");\n#endif\n        retval = cms_signeddata_verify(context, plgctx->cryptoctx,\n                                       reqctx->cryptoctx, plgctx->idctx, CMS_SIGN_CLIENT,\n                                       plgctx->opts->require_crl_checking,\n                                       (unsigned char *)\n                                       reqp->signedAuthPack.data, reqp->signedAuthPack.length,\n                                       (unsigned char **)&authp_data.data,\n                                       &authp_data.length,\n                                       (unsigned char **)&krb5_authz.data,\n                                       &krb5_authz.length, &is_signed);\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        pkiDebug(\"processing KRB5_PADATA_PK_AS_REQ_OLD\\n\");\n        retval = k5int_decode_krb5_pa_pk_as_req_draft9(&k5data, &reqp9);\n        if (retval) {\n            pkiDebug(\"decode_krb5_pa_pk_as_req_draft9 failed\\n\");\n            goto cleanup;\n        }\n#ifdef DEBUG_ASN1\n        print_buffer_bin(reqp9->signedAuthPack.data,\n                         reqp9->signedAuthPack.length,\n                         \"/tmp/kdc_signed_data_draft9\");\n#endif\n\n        retval = cms_signeddata_verify(context, plgctx->cryptoctx,\n                                       reqctx->cryptoctx, plgctx->idctx, CMS_SIGN_DRAFT9,\n                                       plgctx->opts->require_crl_checking,\n                                       (unsigned char *)\n                                       reqp9->signedAuthPack.data, reqp9->signedAuthPack.length,\n                                       (unsigned char **)&authp_data.data,\n                                       &authp_data.length,\n                                       (unsigned char **)&krb5_authz.data,\n                                       &krb5_authz.length, NULL);\n        break;\n    default:\n        pkiDebug(\"unrecognized pa_type = %d\\n\", data->pa_type);\n        retval = EINVAL;\n        goto cleanup;\n    }\n    if (retval) {\n        pkiDebug(\"pkcs7_signeddata_verify failed\\n\");\n        goto cleanup;\n    }\n    if (is_signed) {\n\n        retval = verify_client_san(context, plgctx, reqctx, request->client,\n                                   &valid_san);\n        if (retval)\n            goto cleanup;\n        if (!valid_san) {\n            pkiDebug(\"%s: did not find an acceptable SAN in user \"\n                     \"certificate\\n\", __FUNCTION__);\n            retval = KRB5KDC_ERR_CLIENT_NAME_MISMATCH;\n            goto cleanup;\n        }\n        retval = verify_client_eku(context, plgctx, reqctx, &valid_eku);\n        if (retval)\n            goto cleanup;\n\n        if (!valid_eku) {\n            pkiDebug(\"%s: did not find an acceptable EKU in user \"\n                     \"certificate\\n\", __FUNCTION__);\n            retval = KRB5KDC_ERR_INCONSISTENT_KEY_PURPOSE;\n            goto cleanup;\n        }\n    } else { /* !is_signed */\n        if (!krb5_principal_compare(context, request->client,\n                                    krb5_anonymous_principal())) {\n            retval = KRB5KDC_ERR_PREAUTH_FAILED;\n            krb5_set_error_message(context, retval,\n                                   _(\"Pkinit request not signed, but client \"\n                                     \"not anonymous.\"));\n            goto cleanup;\n        }\n    }\n#ifdef DEBUG_ASN1\n    print_buffer_bin(authp_data.data, authp_data.length, \"/tmp/kdc_auth_pack\");\n#endif\n\n    OCTETDATA_TO_KRB5DATA(&authp_data, &k5data);\n    switch ((int)data->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        retval = k5int_decode_krb5_auth_pack(&k5data, &auth_pack);\n        if (retval) {\n            pkiDebug(\"failed to decode krb5_auth_pack\\n\");\n            goto cleanup;\n        }\n\n        retval = krb5_check_clockskew(context,\n                                      auth_pack->pkAuthenticator.ctime);\n        if (retval)\n            goto cleanup;\n\n        /* check dh parameters */\n        if (auth_pack->clientPublicValue != NULL) {\n            retval = server_check_dh(context, plgctx->cryptoctx,\n                                     reqctx->cryptoctx, plgctx->idctx,\n                                     &auth_pack->clientPublicValue->algorithm.parameters,\n                                     plgctx->opts->dh_min_bits);\n\n            if (retval) {\n                pkiDebug(\"bad dh parameters\\n\");\n                goto cleanup;\n            }\n        } else if (!is_signed) {\n            /*Anonymous pkinit requires DH*/\n            retval = KRB5KDC_ERR_PREAUTH_FAILED;\n            krb5_set_error_message(context, retval,\n                                   _(\"Anonymous pkinit without DH public \"\n                                     \"value not supported.\"));\n            goto cleanup;\n        }\n        der_req = cb->request_body(context, rock);\n        retval = krb5_c_make_checksum(context, CKSUMTYPE_NIST_SHA, NULL,\n                                      0, der_req, &cksum);\n        if (retval) {\n            pkiDebug(\"unable to calculate AS REQ checksum\\n\");\n            goto cleanup;\n        }\n        if (cksum.length != auth_pack->pkAuthenticator.paChecksum.length ||\n            k5_bcmp(cksum.contents,\n                    auth_pack->pkAuthenticator.paChecksum.contents,\n                    cksum.length) != 0) {\n            pkiDebug(\"failed to match the checksum\\n\");\n#ifdef DEBUG_CKSUM\n            pkiDebug(\"calculating checksum on buf size (%d)\\n\",\n                     req_pkt->length);\n            print_buffer(req_pkt->data, req_pkt->length);\n            pkiDebug(\"received checksum type=%d size=%d \",\n                     auth_pack->pkAuthenticator.paChecksum.checksum_type,\n                     auth_pack->pkAuthenticator.paChecksum.length);\n            print_buffer(auth_pack->pkAuthenticator.paChecksum.contents,\n                         auth_pack->pkAuthenticator.paChecksum.length);\n            pkiDebug(\"expected checksum type=%d size=%d \",\n                     cksum.checksum_type, cksum.length);\n            print_buffer(cksum.contents, cksum.length);\n#endif\n\n            retval = KRB5KDC_ERR_PA_CHECKSUM_MUST_BE_INCLUDED;\n            goto cleanup;\n        }\n\n        /* check if kdcPkId present and match KDC's subjectIdentifier */\n        if (reqp->kdcPkId.data != NULL) {\n            int valid_kdcPkId = 0;\n            retval = pkinit_check_kdc_pkid(context, plgctx->cryptoctx,\n                                           reqctx->cryptoctx, plgctx->idctx,\n                                           (unsigned char *)reqp->kdcPkId.data,\n                                           reqp->kdcPkId.length, &valid_kdcPkId);\n            if (retval)\n                goto cleanup;\n            if (!valid_kdcPkId)\n                pkiDebug(\"kdcPkId in AS_REQ does not match KDC's cert\"\n                         \"RFC says to ignore and proceed\\n\");\n\n        }\n        /* remember the decoded auth_pack for verify_padata routine */\n        reqctx->rcv_auth_pack = auth_pack;\n        auth_pack = NULL;\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        retval = k5int_decode_krb5_auth_pack_draft9(&k5data, &auth_pack9);\n        if (retval) {\n            pkiDebug(\"failed to decode krb5_auth_pack_draft9\\n\");\n            goto cleanup;\n        }\n        if (auth_pack9->clientPublicValue != NULL) {\n            retval = server_check_dh(context, plgctx->cryptoctx,\n                                     reqctx->cryptoctx, plgctx->idctx,\n                                     &auth_pack9->clientPublicValue->algorithm.parameters,\n                                     plgctx->opts->dh_min_bits);\n\n            if (retval) {\n                pkiDebug(\"bad dh parameters\\n\");\n                goto cleanup;\n            }\n        }\n        /* remember the decoded auth_pack for verify_padata routine */\n        reqctx->rcv_auth_pack9 = auth_pack9;\n        auth_pack9 = NULL;\n        break;\n    }\n\n    /* remember to set the PREAUTH flag in the reply */\n    enc_tkt_reply->flags |= TKT_FLG_PRE_AUTH;\n    modreq = (krb5_kdcpreauth_modreq)reqctx;\n    reqctx = NULL;\n\ncleanup:\n    if (retval && data->pa_type == KRB5_PADATA_PK_AS_REQ) {\n        pkiDebug(\"pkinit_verify_padata failed: creating e-data\\n\");\n        if (pkinit_create_edata(context, plgctx->cryptoctx, reqctx->cryptoctx,\n                                plgctx->idctx, plgctx->opts, retval, &e_data))\n            pkiDebug(\"pkinit_create_edata failed\\n\");\n    }\n\n    switch ((int)data->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        free_krb5_pa_pk_as_req(&reqp);\n        free(cksum.contents);\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        free_krb5_pa_pk_as_req_draft9(&reqp9);\n    }\n    free(authp_data.data);\n    free(krb5_authz.data);\n    if (reqctx != NULL)\n        pkinit_fini_kdc_req_context(context, reqctx);\n    free_krb5_auth_pack(&auth_pack);\n    free_krb5_auth_pack_draft9(context, &auth_pack9);\n\n    (*respond)(arg, retval, modreq, e_data, NULL);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,7 +28,7 @@\n \n     pkiDebug(\"pkinit_verify_padata: entered!\\n\");\n     if (data == NULL || data->length <= 0 || data->contents == NULL) {\n-        (*respond)(arg, 0, NULL, NULL, NULL);\n+        (*respond)(arg, EINVAL, NULL, NULL, NULL);\n         return;\n     }\n \n@@ -40,7 +40,7 @@\n \n     plgctx = pkinit_find_realm_context(context, moddata, request->server);\n     if (plgctx == NULL) {\n-        (*respond)(arg, 0, NULL, NULL, NULL);\n+        (*respond)(arg, EINVAL, NULL, NULL, NULL);\n         return;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        (*respond)(arg, 0, NULL, NULL, NULL);",
                "        (*respond)(arg, 0, NULL, NULL, NULL);"
            ],
            "added_lines": [
                "        (*respond)(arg, EINVAL, NULL, NULL, NULL);",
                "        (*respond)(arg, EINVAL, NULL, NULL, NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3185",
        "func_name": "apache/httpd/ap_process_request_internal",
        "description": "The ap_some_auth_required function in server/request.c in the Apache HTTP Server 2.4.x before 2.4.14 does not consider that a Require directive may be associated with an authorization setting rather than an authentication setting, which allows remote attackers to bypass intended access restrictions in opportunistic circumstances by leveraging the presence of a module that relies on the 2.2 API behavior.",
        "git_url": "https://github.com/apache/httpd/commit/db81019ab88734ed35fa70294a0cfa7a19743f73",
        "commit_title": "SECURITY: CVE-2015-3185 (cve.mitre.org)",
        "commit_text": " Replacement of ap_some_auth_required (unusable in Apache httpd 2.4) with new ap_some_authn_required and ap_force_authn hook.  Submitted by: breser  ",
        "func_before": "AP_DECLARE(int) ap_process_request_internal(request_rec *r)\n{\n    int file_req = (r->main && r->filename);\n    int access_status;\n    core_dir_config *d;\n\n    /* Ignore embedded %2F's in path for proxy requests */\n    if (!r->proxyreq && r->parsed_uri.path) {\n        d = ap_get_core_module_config(r->per_dir_config);\n        if (d->allow_encoded_slashes) {\n            access_status = ap_unescape_url_keep2f(r->parsed_uri.path, d->decode_encoded_slashes);\n        }\n        else {\n            access_status = ap_unescape_url(r->parsed_uri.path);\n        }\n        if (access_status) {\n            if (access_status == HTTP_NOT_FOUND) {\n                if (! d->allow_encoded_slashes) {\n                    ap_log_rerror(APLOG_MARK, APLOG_INFO, 0, r, APLOGNO(00026)\n                                  \"found %%2f (encoded '/') in URI \"\n                                  \"(decoded='%s'), returning 404\",\n                                  r->parsed_uri.path);\n                }\n            }\n            return access_status;\n        }\n    }\n\n    ap_getparents(r->uri);     /* OK --- shrinking transformations... */\n\n    /* All file subrequests are a huge pain... they cannot bubble through the\n     * next several steps.  Only file subrequests are allowed an empty uri,\n     * otherwise let translate_name kill the request.\n     */\n    if (!file_req) {\n        if ((access_status = ap_location_walk(r))) {\n            return access_status;\n        }\n        if ((access_status = ap_if_walk(r))) {\n            return access_status;\n        }\n\n        /* Don't set per-dir loglevel if LogLevelOverride is set */\n        if (!r->connection->log) {\n            d = ap_get_core_module_config(r->per_dir_config);\n            if (d->log)\n                r->log = d->log;\n        }\n\n        if ((access_status = ap_run_translate_name(r))) {\n            return decl_die(access_status, \"translate\", r);\n        }\n    }\n\n    /* Reset to the server default config prior to running map_to_storage\n     */\n    r->per_dir_config = r->server->lookup_defaults;\n\n    if ((access_status = ap_run_map_to_storage(r))) {\n        /* This request wasn't in storage (e.g. TRACE) */\n        return access_status;\n    }\n\n    /* Rerun the location walk, which overrides any map_to_storage config.\n     */\n    if ((access_status = ap_location_walk(r))) {\n        return access_status;\n    }\n    if ((access_status = ap_if_walk(r))) {\n        return access_status;\n    }\n\n    /* Don't set per-dir loglevel if LogLevelOverride is set */\n    if (!r->connection->log) {\n        d = ap_get_core_module_config(r->per_dir_config);\n        if (d->log)\n            r->log = d->log;\n    }\n\n    if ((access_status = ap_run_post_perdir_config(r))) {\n        return access_status;\n    }\n\n    /* Only on the main request! */\n    if (r->main == NULL) {\n        if ((access_status = ap_run_header_parser(r))) {\n            return access_status;\n        }\n    }\n\n    /* Skip authn/authz if the parent or prior request passed the authn/authz,\n     * and that configuration didn't change (this requires optimized _walk()\n     * functions in map_to_storage that use the same merge results given\n     * identical input.)  If the config changes, we must re-auth.\n     */\n    if (r->prev && (r->prev->per_dir_config == r->per_dir_config)) {\n        r->user = r->prev->user;\n        r->ap_auth_type = r->prev->ap_auth_type;\n    }\n    else if (r->main && (r->main->per_dir_config == r->per_dir_config)) {\n        r->user = r->main->user;\n        r->ap_auth_type = r->main->ap_auth_type;\n    }\n    else {\n        switch (ap_satisfies(r)) {\n        case SATISFY_ALL:\n        case SATISFY_NOSPEC:\n            if ((access_status = ap_run_access_checker(r)) != OK) {\n                return decl_die(access_status,\n                                \"check access (with Satisfy All)\", r);\n            }\n\n            access_status = ap_run_access_checker_ex(r);\n            if (access_status == OK) {\n                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n                              \"request authorized without authentication by \"\n                              \"access_checker_ex hook: %s\", r->uri);\n            }\n            else if (access_status != DECLINED) {\n                return decl_die(access_status, \"check access\", r);\n            }\n            else {\n                if ((access_status = ap_run_check_user_id(r)) != OK) {\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if (r->user == NULL) {\n                    /* don't let buggy authn module crash us in authz */\n                    ap_log_rerror(APLOG_MARK, APLOG_ERR, 0, r, APLOGNO(00027)\n                                  \"No authentication done but request not \"\n                                  \"allowed without authentication for %s. \"\n                                  \"Authentication not configured?\",\n                                  r->uri);\n                    access_status = HTTP_INTERNAL_SERVER_ERROR;\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if ((access_status = ap_run_auth_checker(r)) != OK) {\n                    return decl_die(access_status, \"check authorization\", r);\n                }\n            }\n            break;\n        case SATISFY_ANY:\n            if ((access_status = ap_run_access_checker(r)) == OK) {\n                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n                              \"request authorized without authentication by \"\n                              \"access_checker hook and 'Satisfy any': %s\",\n                              r->uri);\n                break;\n            }\n\n            access_status = ap_run_access_checker_ex(r);\n            if (access_status == OK) {\n                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n                              \"request authorized without authentication by \"\n                              \"access_checker_ex hook: %s\", r->uri);\n            }\n            else if (access_status != DECLINED) {\n                return decl_die(access_status, \"check access\", r);\n            }\n            else {\n                if ((access_status = ap_run_check_user_id(r)) != OK) {\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if (r->user == NULL) {\n                    /* don't let buggy authn module crash us in authz */\n                    ap_log_rerror(APLOG_MARK, APLOG_ERR, 0, r, APLOGNO(00028)\n                                  \"No authentication done but request not \"\n                                  \"allowed without authentication for %s. \"\n                                  \"Authentication not configured?\",\n                                  r->uri);\n                    access_status = HTTP_INTERNAL_SERVER_ERROR;\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if ((access_status = ap_run_auth_checker(r)) != OK) {\n                    return decl_die(access_status, \"check authorization\", r);\n                }\n            }\n            break;\n        }\n    }\n    /* XXX Must make certain the ap_run_type_checker short circuits mime\n     * in mod-proxy for r->proxyreq && r->parsed_uri.scheme\n     *                              && !strcmp(r->parsed_uri.scheme, \"http\")\n     */\n    if ((access_status = ap_run_type_checker(r)) != OK) {\n        return decl_die(access_status, \"find types\", r);\n    }\n\n    if ((access_status = ap_run_fixups(r)) != OK) {\n        ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r, \"fixups hook gave %d: %s\",\n                      access_status, r->uri);\n        return access_status;\n    }\n\n    return OK;\n}",
        "func": "AP_DECLARE(int) ap_process_request_internal(request_rec *r)\n{\n    int file_req = (r->main && r->filename);\n    int access_status;\n    core_dir_config *d;\n\n    /* Ignore embedded %2F's in path for proxy requests */\n    if (!r->proxyreq && r->parsed_uri.path) {\n        d = ap_get_core_module_config(r->per_dir_config);\n        if (d->allow_encoded_slashes) {\n            access_status = ap_unescape_url_keep2f(r->parsed_uri.path, d->decode_encoded_slashes);\n        }\n        else {\n            access_status = ap_unescape_url(r->parsed_uri.path);\n        }\n        if (access_status) {\n            if (access_status == HTTP_NOT_FOUND) {\n                if (! d->allow_encoded_slashes) {\n                    ap_log_rerror(APLOG_MARK, APLOG_INFO, 0, r, APLOGNO(00026)\n                                  \"found %%2f (encoded '/') in URI \"\n                                  \"(decoded='%s'), returning 404\",\n                                  r->parsed_uri.path);\n                }\n            }\n            return access_status;\n        }\n    }\n\n    ap_getparents(r->uri);     /* OK --- shrinking transformations... */\n\n    /* All file subrequests are a huge pain... they cannot bubble through the\n     * next several steps.  Only file subrequests are allowed an empty uri,\n     * otherwise let translate_name kill the request.\n     */\n    if (!file_req) {\n        if ((access_status = ap_location_walk(r))) {\n            return access_status;\n        }\n        if ((access_status = ap_if_walk(r))) {\n            return access_status;\n        }\n\n        /* Don't set per-dir loglevel if LogLevelOverride is set */\n        if (!r->connection->log) {\n            d = ap_get_core_module_config(r->per_dir_config);\n            if (d->log)\n                r->log = d->log;\n        }\n\n        if ((access_status = ap_run_translate_name(r))) {\n            return decl_die(access_status, \"translate\", r);\n        }\n    }\n\n    /* Reset to the server default config prior to running map_to_storage\n     */\n    r->per_dir_config = r->server->lookup_defaults;\n\n    if ((access_status = ap_run_map_to_storage(r))) {\n        /* This request wasn't in storage (e.g. TRACE) */\n        return access_status;\n    }\n\n    /* Rerun the location walk, which overrides any map_to_storage config.\n     */\n    if ((access_status = ap_location_walk(r))) {\n        return access_status;\n    }\n    if ((access_status = ap_if_walk(r))) {\n        return access_status;\n    }\n\n    /* Don't set per-dir loglevel if LogLevelOverride is set */\n    if (!r->connection->log) {\n        d = ap_get_core_module_config(r->per_dir_config);\n        if (d->log)\n            r->log = d->log;\n    }\n\n    if ((access_status = ap_run_post_perdir_config(r))) {\n        return access_status;\n    }\n\n    /* Only on the main request! */\n    if (r->main == NULL) {\n        if ((access_status = ap_run_header_parser(r))) {\n            return access_status;\n        }\n    }\n\n    /* Skip authn/authz if the parent or prior request passed the authn/authz,\n     * and that configuration didn't change (this requires optimized _walk()\n     * functions in map_to_storage that use the same merge results given\n     * identical input.)  If the config changes, we must re-auth.\n     */\n    if (r->prev && (r->prev->per_dir_config == r->per_dir_config)) {\n        r->user = r->prev->user;\n        r->ap_auth_type = r->prev->ap_auth_type;\n    }\n    else if (r->main && (r->main->per_dir_config == r->per_dir_config)) {\n        r->user = r->main->user;\n        r->ap_auth_type = r->main->ap_auth_type;\n    }\n    else {\n        switch (ap_satisfies(r)) {\n        case SATISFY_ALL:\n        case SATISFY_NOSPEC:\n            if ((access_status = ap_run_access_checker(r)) != OK) {\n                return decl_die(access_status,\n                                \"check access (with Satisfy All)\", r);\n            }\n\n            access_status = ap_run_access_checker_ex(r);\n            if (access_status == DECLINED\n                || (access_status == OK && ap_run_force_authn(r) == OK)) {\n                if ((access_status = ap_run_check_user_id(r)) != OK) {\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if (r->user == NULL) {\n                    /* don't let buggy authn module crash us in authz */\n                    ap_log_rerror(APLOG_MARK, APLOG_ERR, 0, r, APLOGNO(00027)\n                                  \"No authentication done but request not \"\n                                  \"allowed without authentication for %s. \"\n                                  \"Authentication not configured?\",\n                                  r->uri);\n                    access_status = HTTP_INTERNAL_SERVER_ERROR;\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if ((access_status = ap_run_auth_checker(r)) != OK) {\n                    return decl_die(access_status, \"check authorization\", r);\n                }\n            }\n            else if (access_status == OK) {\n                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n                              \"request authorized without authentication by \"\n                              \"access_checker_ex hook: %s\", r->uri);\n            }\n            else {\n                return decl_die(access_status, \"check access\", r);\n            }\n            break;\n        case SATISFY_ANY:\n            if ((access_status = ap_run_access_checker(r)) == OK) {\n                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n                              \"request authorized without authentication by \"\n                              \"access_checker hook and 'Satisfy any': %s\",\n                              r->uri);\n                break;\n            }\n\n            access_status = ap_run_access_checker_ex(r);\n            if (access_status == DECLINED\n                || (access_status == OK && ap_run_force_authn(r) == OK)) {\n                if ((access_status = ap_run_check_user_id(r)) != OK) {\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if (r->user == NULL) {\n                    /* don't let buggy authn module crash us in authz */\n                    ap_log_rerror(APLOG_MARK, APLOG_ERR, 0, r, APLOGNO(00028)\n                                  \"No authentication done but request not \"\n                                  \"allowed without authentication for %s. \"\n                                  \"Authentication not configured?\",\n                                  r->uri);\n                    access_status = HTTP_INTERNAL_SERVER_ERROR;\n                    return decl_die(access_status, \"check user\", r);\n                }\n                if ((access_status = ap_run_auth_checker(r)) != OK) {\n                    return decl_die(access_status, \"check authorization\", r);\n                }\n            }\n            else if (access_status == OK) {\n                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n                              \"request authorized without authentication by \"\n                              \"access_checker_ex hook: %s\", r->uri);\n            }\n            else {\n                return decl_die(access_status, \"check access\", r);\n            }\n            break;\n        }\n    }\n    /* XXX Must make certain the ap_run_type_checker short circuits mime\n     * in mod-proxy for r->proxyreq && r->parsed_uri.scheme\n     *                              && !strcmp(r->parsed_uri.scheme, \"http\")\n     */\n    if ((access_status = ap_run_type_checker(r)) != OK) {\n        return decl_die(access_status, \"find types\", r);\n    }\n\n    if ((access_status = ap_run_fixups(r)) != OK) {\n        ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r, \"fixups hook gave %d: %s\",\n                      access_status, r->uri);\n        return access_status;\n    }\n\n    return OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -111,15 +111,8 @@\n             }\n \n             access_status = ap_run_access_checker_ex(r);\n-            if (access_status == OK) {\n-                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n-                              \"request authorized without authentication by \"\n-                              \"access_checker_ex hook: %s\", r->uri);\n-            }\n-            else if (access_status != DECLINED) {\n-                return decl_die(access_status, \"check access\", r);\n-            }\n-            else {\n+            if (access_status == DECLINED\n+                || (access_status == OK && ap_run_force_authn(r) == OK)) {\n                 if ((access_status = ap_run_check_user_id(r)) != OK) {\n                     return decl_die(access_status, \"check user\", r);\n                 }\n@@ -137,6 +130,14 @@\n                     return decl_die(access_status, \"check authorization\", r);\n                 }\n             }\n+            else if (access_status == OK) {\n+                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n+                              \"request authorized without authentication by \"\n+                              \"access_checker_ex hook: %s\", r->uri);\n+            }\n+            else {\n+                return decl_die(access_status, \"check access\", r);\n+            }\n             break;\n         case SATISFY_ANY:\n             if ((access_status = ap_run_access_checker(r)) == OK) {\n@@ -148,15 +149,8 @@\n             }\n \n             access_status = ap_run_access_checker_ex(r);\n-            if (access_status == OK) {\n-                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n-                              \"request authorized without authentication by \"\n-                              \"access_checker_ex hook: %s\", r->uri);\n-            }\n-            else if (access_status != DECLINED) {\n-                return decl_die(access_status, \"check access\", r);\n-            }\n-            else {\n+            if (access_status == DECLINED\n+                || (access_status == OK && ap_run_force_authn(r) == OK)) {\n                 if ((access_status = ap_run_check_user_id(r)) != OK) {\n                     return decl_die(access_status, \"check user\", r);\n                 }\n@@ -173,6 +167,14 @@\n                 if ((access_status = ap_run_auth_checker(r)) != OK) {\n                     return decl_die(access_status, \"check authorization\", r);\n                 }\n+            }\n+            else if (access_status == OK) {\n+                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,\n+                              \"request authorized without authentication by \"\n+                              \"access_checker_ex hook: %s\", r->uri);\n+            }\n+            else {\n+                return decl_die(access_status, \"check access\", r);\n             }\n             break;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "            if (access_status == OK) {",
                "                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,",
                "                              \"request authorized without authentication by \"",
                "                              \"access_checker_ex hook: %s\", r->uri);",
                "            }",
                "            else if (access_status != DECLINED) {",
                "                return decl_die(access_status, \"check access\", r);",
                "            }",
                "            else {",
                "            if (access_status == OK) {",
                "                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,",
                "                              \"request authorized without authentication by \"",
                "                              \"access_checker_ex hook: %s\", r->uri);",
                "            }",
                "            else if (access_status != DECLINED) {",
                "                return decl_die(access_status, \"check access\", r);",
                "            }",
                "            else {"
            ],
            "added_lines": [
                "            if (access_status == DECLINED",
                "                || (access_status == OK && ap_run_force_authn(r) == OK)) {",
                "            else if (access_status == OK) {",
                "                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,",
                "                              \"request authorized without authentication by \"",
                "                              \"access_checker_ex hook: %s\", r->uri);",
                "            }",
                "            else {",
                "                return decl_die(access_status, \"check access\", r);",
                "            }",
                "            if (access_status == DECLINED",
                "                || (access_status == OK && ap_run_force_authn(r) == OK)) {",
                "            }",
                "            else if (access_status == OK) {",
                "                ap_log_rerror(APLOG_MARK, APLOG_TRACE3, 0, r,",
                "                              \"request authorized without authentication by \"",
                "                              \"access_checker_ex hook: %s\", r->uri);",
                "            }",
                "            else {",
                "                return decl_die(access_status, \"check access\", r);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1867",
        "func_name": "ClusterLabs/pacemaker/__xml_acl_post_process",
        "description": "Pacemaker before 1.1.13 does not properly evaluate added nodes, which allows remote read-only users to gain privileges via an acl command.",
        "git_url": "https://github.com/ClusterLabs/pacemaker/commit/84ac07c7d02b3badd708b1ef13a2159dede70715",
        "commit_title": "Fix: acl: Do not delay evaluation of added nodes in some situations",
        "commit_text": " It is not appropriate when the node has no children as it is not a placeholder",
        "func_before": "static void\n__xml_acl_post_process(xmlNode * xml)\n{\n    xmlNode *cIter = __xml_first_child(xml);\n    xml_private_t *p = xml->_private;\n\n    if(is_set(p->flags, xpf_created)) {\n        xmlAttr *xIter = NULL;\n\n        /* Always allow new scaffolding, ie. node with no attributes or only an 'id' */\n\n        for (xIter = crm_first_attr(xml); xIter != NULL; xIter = xIter->next) {\n            const char *prop_name = (const char *)xIter->name;\n\n            if (strcmp(prop_name, XML_ATTR_ID) == 0) {\n                /* Delay the acl check */\n                continue;\n\n            } else if(__xml_acl_check(xml, NULL, xpf_acl_write)) {\n                crm_trace(\"Creation of %s=%s is allowed\", crm_element_name(xml), ID(xml));\n                break;\n\n            } else {\n                char *path = xml_get_path(xml);\n                crm_trace(\"Cannot add new node %s at %s\", crm_element_name(xml), path);\n\n                if(xml != xmlDocGetRootElement(xml->doc)) {\n                    xmlUnlinkNode(xml);\n                    xmlFreeNode(xml);\n                }\n                free(path);\n                return;\n            }\n        }\n    }\n\n    while (cIter != NULL) {\n        xmlNode *child = cIter;\n        cIter = __xml_next(cIter); /* In case it is free'd */\n        __xml_acl_post_process(child);\n    }\n}",
        "func": "static void\n__xml_acl_post_process(xmlNode * xml)\n{\n    xmlNode *cIter = __xml_first_child(xml);\n    xml_private_t *p = xml->_private;\n\n    if(is_set(p->flags, xpf_created)) {\n        xmlAttr *xIter = NULL;\n        char *path = xml_get_path(xml);\n\n        /* Always allow new scaffolding, ie. node with no attributes or only an 'id'\n         * Except in the ACLs section\n         */\n\n        for (xIter = crm_first_attr(xml); xIter != NULL; xIter = xIter->next) {\n            const char *prop_name = (const char *)xIter->name;\n\n            if (strcmp(prop_name, XML_ATTR_ID) == 0 && strstr(path, \"/\"XML_CIB_TAG_ACLS\"/\") == NULL) {\n                /* Delay the acl check */\n                continue;\n\n            } else if(__xml_acl_check(xml, NULL, xpf_acl_write)) {\n                crm_trace(\"Creation of %s=%s is allowed\", crm_element_name(xml), ID(xml));\n                break;\n\n            } else {\n                crm_trace(\"Cannot add new node %s at %s\", crm_element_name(xml), path);\n\n                if(xml != xmlDocGetRootElement(xml->doc)) {\n                    xmlUnlinkNode(xml);\n                    xmlFreeNode(xml);\n                }\n                free(path);\n                return;\n            }\n        }\n        free(path);\n    }\n\n    while (cIter != NULL) {\n        xmlNode *child = cIter;\n        cIter = __xml_next(cIter); /* In case it is free'd */\n        __xml_acl_post_process(child);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,13 +6,16 @@\n \n     if(is_set(p->flags, xpf_created)) {\n         xmlAttr *xIter = NULL;\n+        char *path = xml_get_path(xml);\n \n-        /* Always allow new scaffolding, ie. node with no attributes or only an 'id' */\n+        /* Always allow new scaffolding, ie. node with no attributes or only an 'id'\n+         * Except in the ACLs section\n+         */\n \n         for (xIter = crm_first_attr(xml); xIter != NULL; xIter = xIter->next) {\n             const char *prop_name = (const char *)xIter->name;\n \n-            if (strcmp(prop_name, XML_ATTR_ID) == 0) {\n+            if (strcmp(prop_name, XML_ATTR_ID) == 0 && strstr(path, \"/\"XML_CIB_TAG_ACLS\"/\") == NULL) {\n                 /* Delay the acl check */\n                 continue;\n \n@@ -21,7 +24,6 @@\n                 break;\n \n             } else {\n-                char *path = xml_get_path(xml);\n                 crm_trace(\"Cannot add new node %s at %s\", crm_element_name(xml), path);\n \n                 if(xml != xmlDocGetRootElement(xml->doc)) {\n@@ -32,6 +34,7 @@\n                 return;\n             }\n         }\n+        free(path);\n     }\n \n     while (cIter != NULL) {",
        "diff_line_info": {
            "deleted_lines": [
                "        /* Always allow new scaffolding, ie. node with no attributes or only an 'id' */",
                "            if (strcmp(prop_name, XML_ATTR_ID) == 0) {",
                "                char *path = xml_get_path(xml);"
            ],
            "added_lines": [
                "        char *path = xml_get_path(xml);",
                "        /* Always allow new scaffolding, ie. node with no attributes or only an 'id'",
                "         * Except in the ACLs section",
                "         */",
                "            if (strcmp(prop_name, XML_ATTR_ID) == 0 && strstr(path, \"/\"XML_CIB_TAG_ACLS\"/\") == NULL) {",
                "        free(path);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6564",
        "func_name": "openssh/openssh-portable/mm_answer_pam_free_ctx",
        "description": "Use-after-free vulnerability in the mm_answer_pam_free_ctx function in monitor.c in sshd in OpenSSH before 7.0 on non-OpenBSD platforms might allow local users to gain privileges by leveraging control of the sshd uid to send an unexpectedly early MONITOR_REQ_PAM_FREE_CTX request.",
        "git_url": "https://github.com/openssh/openssh-portable/commit/5e75f5198769056089fb06c4d738ab0e5abc66f7",
        "commit_title": "set sshpam_ctxt to NULL after free",
        "commit_text": " Avoids use-after-free in monitor when privsep child is compromised. Reported by Moritz Jodeit; ok dtucker@",
        "func_before": "int\nmm_answer_pam_free_ctx(int sock, Buffer *m)\n{\n\n\tdebug3(\"%s\", __func__);\n\t(sshpam_device.free_ctx)(sshpam_ctxt);\n\tbuffer_clear(m);\n\tmm_request_send(sock, MONITOR_ANS_PAM_FREE_CTX, m);\n\tauth_method = \"keyboard-interactive\";\n\tauth_submethod = \"pam\";\n\treturn (sshpam_authok == sshpam_ctxt);\n}",
        "func": "int\nmm_answer_pam_free_ctx(int sock, Buffer *m)\n{\n\tint r = sshpam_authok != NULL && sshpam_authok == sshpam_ctxt;\n\n\tdebug3(\"%s\", __func__);\n\t(sshpam_device.free_ctx)(sshpam_ctxt);\n\tsshpam_ctxt = sshpam_authok = NULL;\n\tbuffer_clear(m);\n\tmm_request_send(sock, MONITOR_ANS_PAM_FREE_CTX, m);\n\tauth_method = \"keyboard-interactive\";\n\tauth_submethod = \"pam\";\n\treturn r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,12 +1,14 @@\n int\n mm_answer_pam_free_ctx(int sock, Buffer *m)\n {\n+\tint r = sshpam_authok != NULL && sshpam_authok == sshpam_ctxt;\n \n \tdebug3(\"%s\", __func__);\n \t(sshpam_device.free_ctx)(sshpam_ctxt);\n+\tsshpam_ctxt = sshpam_authok = NULL;\n \tbuffer_clear(m);\n \tmm_request_send(sock, MONITOR_ANS_PAM_FREE_CTX, m);\n \tauth_method = \"keyboard-interactive\";\n \tauth_submethod = \"pam\";\n-\treturn (sshpam_authok == sshpam_ctxt);\n+\treturn r;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn (sshpam_authok == sshpam_ctxt);"
            ],
            "added_lines": [
                "\tint r = sshpam_authok != NULL && sshpam_authok == sshpam_ctxt;",
                "\tsshpam_ctxt = sshpam_authok = NULL;",
                "\treturn r;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6520",
        "func_name": "tillkamppeter/ippusbxd/tcp_open",
        "description": "IPPUSBXD before 1.22 listens on all interfaces, which allows remote attackers to obtain access to USB connected printers via a direct request.",
        "git_url": "https://github.com/tillkamppeter/ippusbxd/commit/46844402bca7a38fc224483ba6f0a93c4613203f",
        "commit_title": "SECURITY FIX: Actually restrict the access to the printer to localhost",
        "commit_text": " Before, any machine in any network connected by any of the interfaces (as listed by \"ifconfig\") could access to an IPP-over-USB printer on the assigned port, allowing users on remote machines to print and to access the web configuration interface of a IPP-over-USB printer in contrary to conventional USB printers which are only accessible locally.",
        "func_before": "struct tcp_sock_t *tcp_open(uint16_t port)\n{\n\tstruct tcp_sock_t *this = calloc(1, sizeof *this);\n\tif (this == NULL) {\n\t\tERR(\"callocing this failed\");\n\t\tgoto error;\n\t}\n\n\t// Open [S]ocket [D]escriptor\n\tthis->sd = -1;\n\tthis->sd = socket(AF_INET6, SOCK_STREAM, 0);\n\tif (this->sd < 0) {\n\t\tERR(\"sockect open failed\");\n\t\tgoto error;\n\t}\n\n\t// Configure socket params\n\tstruct sockaddr_in6 addr;\n\tmemset(&addr, 0, sizeof addr);\n\taddr.sin6_family = AF_INET6;\n\taddr.sin6_port = htons(port);\n\taddr.sin6_addr = in6addr_any;\n\n\t// Bind to localhost\n\tif (bind(this->sd,\n\t        (struct sockaddr *)&addr,\n\t        sizeof addr) < 0) {\n\t\tif (g_options.only_desired_port == 1)\n\t\t\tERR(\"Bind on port failed. \"\n\t\t\t    \"Requested port may be taken or require root permissions.\");\n\t\tgoto error;\n\t}\n\n\t// Let kernel over-accept max number of connections\n\tif (listen(this->sd, HTTP_MAX_PENDING_CONNS) < 0) {\n\t\tERR(\"listen failed on socket\");\n\t\tgoto error;\n\t}\n\n\treturn this;\n\nerror:\n\tif (this != NULL) {\n\t\tif (this->sd != -1) {\n\t\t\tclose(this->sd);\n\t\t}\n\t\tfree(this);\n\t}\n\treturn NULL;\n}",
        "func": "struct tcp_sock_t *tcp_open(uint16_t port)\n{\n\tstruct tcp_sock_t *this = calloc(1, sizeof *this);\n\tif (this == NULL) {\n\t\tERR(\"IPv4: callocing this failed\");\n\t\tgoto error;\n\t}\n\n\t// Open [S]ocket [D]escriptor\n\tthis->sd = -1;\n\tthis->sd = socket(AF_INET, SOCK_STREAM, 0);\n\tif (this->sd < 0) {\n\t\tERR(\"IPv4 socket open failed\");\n\t\tgoto error;\n\t}\n\n\t// Configure socket params\n\tstruct sockaddr_in addr;\n\tmemset(&addr, 0, sizeof addr);\n\taddr.sin_family = AF_INET;\n\taddr.sin_port = htons(port);\n\taddr.sin_addr.s_addr = htonl(0x7F000001);\n\n\t// Bind to localhost\n\tif (bind(this->sd,\n\t        (struct sockaddr *)&addr,\n\t        sizeof addr) < 0) {\n\t\tif (g_options.only_desired_port == 1)\n\t\t\tERR(\"IPv4 bind on port failed. \"\n\t\t\t    \"Requested port may be taken or require root permissions.\");\n\t\tgoto error;\n\t}\n\n\t// Let kernel over-accept max number of connections\n\tif (listen(this->sd, HTTP_MAX_PENDING_CONNS) < 0) {\n\t\tERR(\"IPv4 listen failed on socket\");\n\t\tgoto error;\n\t}\n\n\treturn this;\n\nerror:\n\tif (this != NULL) {\n\t\tif (this->sd != -1) {\n\t\t\tclose(this->sd);\n\t\t}\n\t\tfree(this);\n\t}\n\treturn NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,38 +2,38 @@\n {\n \tstruct tcp_sock_t *this = calloc(1, sizeof *this);\n \tif (this == NULL) {\n-\t\tERR(\"callocing this failed\");\n+\t\tERR(\"IPv4: callocing this failed\");\n \t\tgoto error;\n \t}\n \n \t// Open [S]ocket [D]escriptor\n \tthis->sd = -1;\n-\tthis->sd = socket(AF_INET6, SOCK_STREAM, 0);\n+\tthis->sd = socket(AF_INET, SOCK_STREAM, 0);\n \tif (this->sd < 0) {\n-\t\tERR(\"sockect open failed\");\n+\t\tERR(\"IPv4 socket open failed\");\n \t\tgoto error;\n \t}\n \n \t// Configure socket params\n-\tstruct sockaddr_in6 addr;\n+\tstruct sockaddr_in addr;\n \tmemset(&addr, 0, sizeof addr);\n-\taddr.sin6_family = AF_INET6;\n-\taddr.sin6_port = htons(port);\n-\taddr.sin6_addr = in6addr_any;\n+\taddr.sin_family = AF_INET;\n+\taddr.sin_port = htons(port);\n+\taddr.sin_addr.s_addr = htonl(0x7F000001);\n \n \t// Bind to localhost\n \tif (bind(this->sd,\n \t        (struct sockaddr *)&addr,\n \t        sizeof addr) < 0) {\n \t\tif (g_options.only_desired_port == 1)\n-\t\t\tERR(\"Bind on port failed. \"\n+\t\t\tERR(\"IPv4 bind on port failed. \"\n \t\t\t    \"Requested port may be taken or require root permissions.\");\n \t\tgoto error;\n \t}\n \n \t// Let kernel over-accept max number of connections\n \tif (listen(this->sd, HTTP_MAX_PENDING_CONNS) < 0) {\n-\t\tERR(\"listen failed on socket\");\n+\t\tERR(\"IPv4 listen failed on socket\");\n \t\tgoto error;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tERR(\"callocing this failed\");",
                "\tthis->sd = socket(AF_INET6, SOCK_STREAM, 0);",
                "\t\tERR(\"sockect open failed\");",
                "\tstruct sockaddr_in6 addr;",
                "\taddr.sin6_family = AF_INET6;",
                "\taddr.sin6_port = htons(port);",
                "\taddr.sin6_addr = in6addr_any;",
                "\t\t\tERR(\"Bind on port failed. \"",
                "\t\tERR(\"listen failed on socket\");"
            ],
            "added_lines": [
                "\t\tERR(\"IPv4: callocing this failed\");",
                "\tthis->sd = socket(AF_INET, SOCK_STREAM, 0);",
                "\t\tERR(\"IPv4 socket open failed\");",
                "\tstruct sockaddr_in addr;",
                "\taddr.sin_family = AF_INET;",
                "\taddr.sin_port = htons(port);",
                "\taddr.sin_addr.s_addr = htonl(0x7F000001);",
                "\t\t\tERR(\"IPv4 bind on port failed. \"",
                "\t\tERR(\"IPv4 listen failed on socket\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6520",
        "func_name": "tillkamppeter/ippusbxd/start_daemon",
        "description": "IPPUSBXD before 1.22 listens on all interfaces, which allows remote attackers to obtain access to USB connected printers via a direct request.",
        "git_url": "https://github.com/tillkamppeter/ippusbxd/commit/46844402bca7a38fc224483ba6f0a93c4613203f",
        "commit_title": "SECURITY FIX: Actually restrict the access to the printer to localhost",
        "commit_text": " Before, any machine in any network connected by any of the interfaces (as listed by \"ifconfig\") could access to an IPP-over-USB printer on the assigned port, allowing users on remote machines to print and to access the web configuration interface of a IPP-over-USB printer in contrary to conventional USB printers which are only accessible locally.",
        "func_before": "static void start_daemon()\n{\n\t// Capture USB device if not in no-printer mode\n\tstruct usb_sock_t *usb_sock;\n\tif (g_options.noprinter_mode == 0) {\n\t\tusb_sock = usb_open();\n\t\tif (usb_sock == NULL)\n\t\t\tgoto cleanup_usb;\n\t} else\n\t\tusb_sock = NULL;\n\n\t// Capture a socket\n\tuint16_t desired_port = g_options.desired_port;\n\tstruct tcp_sock_t *tcp_socket;\n\twhile ((tcp_socket = tcp_open(desired_port)) == NULL &&\n\t       g_options.only_desired_port == 0) {\n\t\t// Search for a free port\n\t\tdesired_port ++;\n\t\t// We failed with 0 as port number or we reached the max\n\t\t// port number\n\t\tif (desired_port == 1 || desired_port == 0)\n\t\t\t// IANA recommendation of 49152 to 65535 for ephemeral\n\t\t\t// ports\n\t\t\t// https://en.wikipedia.org/wiki/Ephemeral_port\n\t\t\tdesired_port = 49152;\n\t}\n\tif (tcp_socket == NULL)\n\t\tgoto cleanup_tcp;\n\n\tuint16_t real_port = tcp_port_number_get(tcp_socket);\n\tif (desired_port != 0 && g_options.only_desired_port == 1 &&\n\t    desired_port != real_port) {\n\t\tERR(\"Received port number did not match requested port number.\"\n\t\t    \" The requested port number may be too high.\");\n\t\tgoto cleanup_tcp;\n\t}\n\tprintf(\"%u|\", real_port);\n\tfflush(stdout);\n\n\t// Lose connection to caller\n\tuint16_t pid;\n\tif (!g_options.nofork_mode && (pid = fork()) > 0) {\n\t\tprintf(\"%u|\", pid);\n\t\texit(0);\n\t}\n\n\t// Register for unplug event\n\tif (usb_can_callback(usb_sock))\n\t\tusb_register_callback(usb_sock);\n\n\tfor (;;) {\n\t\tstruct service_thread_param *args = calloc(1, sizeof(*args));\n\t\tif (args == NULL) {\n\t\t\tERR(\"Failed to alloc space for thread args\");\n\t\t\tgoto cleanup_thread;\n\t\t}\n\n\t\targs->usb_sock = usb_sock;\n\t\targs->tcp = tcp_conn_accept(tcp_socket);\n\t\tif (args->tcp == NULL) {\n\t\t\tERR(\"Failed to open tcp connection\");\n\t\t\tgoto cleanup_thread;\n\t\t}\n\n\t\tint status = pthread_create(&args->thread_handle, NULL,\n\t\t                            &service_connection, args);\n\t\tif (status) {\n\t\t\tERR(\"Failed to spawn thread, error %d\", status);\n\t\t\tgoto cleanup_thread;\n\t\t}\n\n\t\tcontinue;\n\n\tcleanup_thread:\n\t\tif (args != NULL) {\n\t\t\tif (args->tcp != NULL)\n\t\t\t\ttcp_conn_close(args->tcp);\n\t\t\tfree(args);\n\t\t}\n\t\tbreak;\n\t}\n\ncleanup_tcp:\n\tif (tcp_socket!= NULL)\n\t\ttcp_close(tcp_socket);\ncleanup_usb:\n\tif (usb_sock != NULL)\n\t\tusb_close(usb_sock);\n\treturn;\n}",
        "func": "static void start_daemon()\n{\n\t// Capture USB device if not in no-printer mode\n\tstruct usb_sock_t *usb_sock;\n\tif (g_options.noprinter_mode == 0) {\n\t\tusb_sock = usb_open();\n\t\tif (usb_sock == NULL)\n\t\t\tgoto cleanup_usb;\n\t} else\n\t\tusb_sock = NULL;\n\n\t// Capture a socket\n\tuint16_t desired_port = g_options.desired_port;\n\tstruct tcp_sock_t *tcp_socket = NULL, *tcp6_socket = NULL;\n\tfor (;;) {\n\t\ttcp_socket = tcp_open(desired_port);\n\t\ttcp6_socket = tcp6_open(desired_port);\n\t\tif (tcp_socket || tcp6_socket || g_options.only_desired_port)\n\t\t\tbreak;\n\t\t// Search for a free port\n\t\tdesired_port ++;\n\t\t// We failed with 0 as port number or we reached the max\n\t\t// port number\n\t\tif (desired_port == 1 || desired_port == 0)\n\t\t\t// IANA recommendation of 49152 to 65535 for ephemeral\n\t\t\t// ports\n\t\t\t// https://en.wikipedia.org/wiki/Ephemeral_port\n\t\t\tdesired_port = 49152;\n\t\tNOTE(\"Access to desired port failed, trying alternative port %d\", desired_port);\n\t}\n\tif (tcp_socket == NULL && tcp6_socket == NULL)\n\t\tgoto cleanup_tcp;\n\n\tuint16_t real_port;\n\tif (tcp_socket)\n\t  real_port = tcp_port_number_get(tcp_socket);\n\telse\n\t  real_port = tcp_port_number_get(tcp6_socket);\n\tif (desired_port != 0 && g_options.only_desired_port == 1 &&\n\t    desired_port != real_port) {\n\t\tERR(\"Received port number did not match requested port number.\"\n\t\t    \" The requested port number may be too high.\");\n\t\tgoto cleanup_tcp;\n\t}\n\tprintf(\"%u|\", real_port);\n\tfflush(stdout);\n\n\tNOTE(\"Port: %d, IPv4 %savailable, IPv6 %savailable\",\n\t     real_port, tcp_socket ? \"\" : \"not \", tcp6_socket ? \"\" : \"not \");\n\n\t// Lose connection to caller\n\tuint16_t pid;\n\tif (!g_options.nofork_mode && (pid = fork()) > 0) {\n\t\tprintf(\"%u|\", pid);\n\t\texit(0);\n\t}\n\n\t// Register for unplug event\n\tif (usb_can_callback(usb_sock))\n\t\tusb_register_callback(usb_sock);\n\n\tfor (;;) {\n\t\tstruct service_thread_param *args = calloc(1, sizeof(*args));\n\t\tif (args == NULL) {\n\t\t\tERR(\"Failed to alloc space for thread args\");\n\t\t\tgoto cleanup_thread;\n\t\t}\n\n\t\targs->usb_sock = usb_sock;\n\n\t\t// For each request/response round we use the socket (IPv4 or\n\t\t// IPv6) which receives data first\n\t\targs->tcp = tcp_conn_select(tcp_socket, tcp6_socket);\n\t\tif (args->tcp == NULL) {\n\t\t\tERR(\"Failed to open tcp connection\");\n\t\t\tgoto cleanup_thread;\n\t\t}\n\n\t\tint status = pthread_create(&args->thread_handle, NULL,\n\t\t                            &service_connection, args);\n\t\tif (status) {\n\t\t\tERR(\"Failed to spawn thread, error %d\", status);\n\t\t\tgoto cleanup_thread;\n\t\t}\n\n\t\tcontinue;\n\n\tcleanup_thread:\n\t\tif (args != NULL) {\n\t\t\tif (args->tcp != NULL)\n\t\t\t\ttcp_conn_close(args->tcp);\n\t\t\tfree(args);\n\t\t}\n\t\tbreak;\n\t}\n\ncleanup_tcp:\n\tif (tcp_socket!= NULL)\n\t\ttcp_close(tcp_socket);\n\tif (tcp6_socket!= NULL)\n\t\ttcp_close(tcp6_socket);\ncleanup_usb:\n\tif (usb_sock != NULL)\n\t\tusb_close(usb_sock);\n\treturn;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,9 +11,12 @@\n \n \t// Capture a socket\n \tuint16_t desired_port = g_options.desired_port;\n-\tstruct tcp_sock_t *tcp_socket;\n-\twhile ((tcp_socket = tcp_open(desired_port)) == NULL &&\n-\t       g_options.only_desired_port == 0) {\n+\tstruct tcp_sock_t *tcp_socket = NULL, *tcp6_socket = NULL;\n+\tfor (;;) {\n+\t\ttcp_socket = tcp_open(desired_port);\n+\t\ttcp6_socket = tcp6_open(desired_port);\n+\t\tif (tcp_socket || tcp6_socket || g_options.only_desired_port)\n+\t\t\tbreak;\n \t\t// Search for a free port\n \t\tdesired_port ++;\n \t\t// We failed with 0 as port number or we reached the max\n@@ -23,11 +26,16 @@\n \t\t\t// ports\n \t\t\t// https://en.wikipedia.org/wiki/Ephemeral_port\n \t\t\tdesired_port = 49152;\n+\t\tNOTE(\"Access to desired port failed, trying alternative port %d\", desired_port);\n \t}\n-\tif (tcp_socket == NULL)\n+\tif (tcp_socket == NULL && tcp6_socket == NULL)\n \t\tgoto cleanup_tcp;\n \n-\tuint16_t real_port = tcp_port_number_get(tcp_socket);\n+\tuint16_t real_port;\n+\tif (tcp_socket)\n+\t  real_port = tcp_port_number_get(tcp_socket);\n+\telse\n+\t  real_port = tcp_port_number_get(tcp6_socket);\n \tif (desired_port != 0 && g_options.only_desired_port == 1 &&\n \t    desired_port != real_port) {\n \t\tERR(\"Received port number did not match requested port number.\"\n@@ -36,6 +44,9 @@\n \t}\n \tprintf(\"%u|\", real_port);\n \tfflush(stdout);\n+\n+\tNOTE(\"Port: %d, IPv4 %savailable, IPv6 %savailable\",\n+\t     real_port, tcp_socket ? \"\" : \"not \", tcp6_socket ? \"\" : \"not \");\n \n \t// Lose connection to caller\n \tuint16_t pid;\n@@ -56,7 +67,10 @@\n \t\t}\n \n \t\targs->usb_sock = usb_sock;\n-\t\targs->tcp = tcp_conn_accept(tcp_socket);\n+\n+\t\t// For each request/response round we use the socket (IPv4 or\n+\t\t// IPv6) which receives data first\n+\t\targs->tcp = tcp_conn_select(tcp_socket, tcp6_socket);\n \t\tif (args->tcp == NULL) {\n \t\t\tERR(\"Failed to open tcp connection\");\n \t\t\tgoto cleanup_thread;\n@@ -83,6 +97,8 @@\n cleanup_tcp:\n \tif (tcp_socket!= NULL)\n \t\ttcp_close(tcp_socket);\n+\tif (tcp6_socket!= NULL)\n+\t\ttcp_close(tcp6_socket);\n cleanup_usb:\n \tif (usb_sock != NULL)\n \t\tusb_close(usb_sock);",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct tcp_sock_t *tcp_socket;",
                "\twhile ((tcp_socket = tcp_open(desired_port)) == NULL &&",
                "\t       g_options.only_desired_port == 0) {",
                "\tif (tcp_socket == NULL)",
                "\tuint16_t real_port = tcp_port_number_get(tcp_socket);",
                "\t\targs->tcp = tcp_conn_accept(tcp_socket);"
            ],
            "added_lines": [
                "\tstruct tcp_sock_t *tcp_socket = NULL, *tcp6_socket = NULL;",
                "\tfor (;;) {",
                "\t\ttcp_socket = tcp_open(desired_port);",
                "\t\ttcp6_socket = tcp6_open(desired_port);",
                "\t\tif (tcp_socket || tcp6_socket || g_options.only_desired_port)",
                "\t\t\tbreak;",
                "\t\tNOTE(\"Access to desired port failed, trying alternative port %d\", desired_port);",
                "\tif (tcp_socket == NULL && tcp6_socket == NULL)",
                "\tuint16_t real_port;",
                "\tif (tcp_socket)",
                "\t  real_port = tcp_port_number_get(tcp_socket);",
                "\telse",
                "\t  real_port = tcp_port_number_get(tcp6_socket);",
                "",
                "\tNOTE(\"Port: %d, IPv4 %savailable, IPv6 %savailable\",",
                "\t     real_port, tcp_socket ? \"\" : \"not \", tcp6_socket ? \"\" : \"not \");",
                "",
                "\t\t// For each request/response round we use the socket (IPv4 or",
                "\t\t// IPv6) which receives data first",
                "\t\targs->tcp = tcp_conn_select(tcp_socket, tcp6_socket);",
                "\tif (tcp6_socket!= NULL)",
                "\t\ttcp_close(tcp6_socket);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6654",
        "func_name": "xen-project/xen/xenmem_add_to_physmap_one",
        "description": "The xenmem_add_to_physmap_one function in arch/arm/mm.c in Xen 4.5.x, 4.4.x, and earlier does not limit the number of printk console messages when reporting a failure to retrieve a reference on a foreign page, which allows remote domains to cause a denial of service by leveraging permissions to map the memory of a foreign guest.",
        "git_url": "https://github.com/xen-project/xen/commit/afc13fe5e21d18c09e44f8ae6f7f4484e9f1de7f",
        "commit_title": "xen/arm: mm: Do not dump the p2m when mapping a foreign gfn",
        "commit_text": " The physmap operation XENMAPSPACE_gfmn_foreign is dumping the p2m when an error occured by calling dump_p2m_lookup. But this function is not using ratelimited printk.  Any domain able to map foreign gfmn would be able to flood the Xen console.  The information wasn't not useful so drop it.  This is XSA-141. ",
        "func_before": "int xenmem_add_to_physmap_one(\n    struct domain *d,\n    unsigned int space,\n    domid_t foreign_domid,\n    unsigned long idx,\n    xen_pfn_t gpfn)\n{\n    unsigned long mfn = 0;\n    int rc;\n    p2m_type_t t;\n    struct page_info *page = NULL;\n\n    switch ( space )\n    {\n    case XENMAPSPACE_grant_table:\n        write_lock(&d->grant_table->lock);\n\n        if ( d->grant_table->gt_version == 0 )\n            d->grant_table->gt_version = 1;\n\n        if ( d->grant_table->gt_version == 2 &&\n                (idx & XENMAPIDX_grant_table_status) )\n        {\n            idx &= ~XENMAPIDX_grant_table_status;\n            if ( idx < nr_status_frames(d->grant_table) )\n                mfn = virt_to_mfn(d->grant_table->status[idx]);\n            else\n                return -EINVAL;\n        }\n        else\n        {\n            if ( (idx >= nr_grant_frames(d->grant_table)) &&\n                 (idx < max_grant_frames) )\n                gnttab_grow_table(d, idx + 1);\n\n            if ( idx < nr_grant_frames(d->grant_table) )\n                mfn = virt_to_mfn(d->grant_table->shared_raw[idx]);\n            else\n                return -EINVAL;\n        }\n        \n        d->arch.grant_table_gpfn[idx] = gpfn;\n\n        t = p2m_ram_rw;\n\n        write_unlock(&d->grant_table->lock);\n        break;\n    case XENMAPSPACE_shared_info:\n        if ( idx != 0 )\n            return -EINVAL;\n\n        mfn = virt_to_mfn(d->shared_info);\n        t = p2m_ram_rw;\n\n        break;\n    case XENMAPSPACE_gmfn_foreign:\n    {\n        struct domain *od;\n        p2m_type_t p2mt;\n        od = rcu_lock_domain_by_any_id(foreign_domid);\n        if ( od == NULL )\n            return -ESRCH;\n\n        if ( od == d )\n        {\n            rcu_unlock_domain(od);\n            return -EINVAL;\n        }\n\n        rc = xsm_map_gmfn_foreign(XSM_TARGET, d, od);\n        if ( rc )\n        {\n            rcu_unlock_domain(od);\n            return rc;\n        }\n\n        /* Take reference to the foreign domain page.\n         * Reference will be released in XENMEM_remove_from_physmap */\n        page = get_page_from_gfn(od, idx, &p2mt, P2M_ALLOC);\n        if ( !page )\n        {\n            dump_p2m_lookup(od, pfn_to_paddr(idx));\n            rcu_unlock_domain(od);\n            return -EINVAL;\n        }\n\n        if ( !p2m_is_ram(p2mt) )\n        {\n            put_page(page);\n            rcu_unlock_domain(od);\n            return -EINVAL;\n        }\n\n        mfn = page_to_mfn(page);\n        t = p2m_map_foreign;\n\n        rcu_unlock_domain(od);\n        break;\n    }\n\n    default:\n        return -ENOSYS;\n    }\n\n    /* Map at new location. */\n    rc = guest_physmap_add_entry(d, gpfn, mfn, 0, t);\n\n    /* If we fail to add the mapping, we need to drop the reference we\n     * took earlier on foreign pages */\n    if ( rc && space == XENMAPSPACE_gmfn_foreign )\n    {\n        ASSERT(page != NULL);\n        put_page(page);\n    }\n\n    return rc;\n}",
        "func": "int xenmem_add_to_physmap_one(\n    struct domain *d,\n    unsigned int space,\n    domid_t foreign_domid,\n    unsigned long idx,\n    xen_pfn_t gpfn)\n{\n    unsigned long mfn = 0;\n    int rc;\n    p2m_type_t t;\n    struct page_info *page = NULL;\n\n    switch ( space )\n    {\n    case XENMAPSPACE_grant_table:\n        write_lock(&d->grant_table->lock);\n\n        if ( d->grant_table->gt_version == 0 )\n            d->grant_table->gt_version = 1;\n\n        if ( d->grant_table->gt_version == 2 &&\n                (idx & XENMAPIDX_grant_table_status) )\n        {\n            idx &= ~XENMAPIDX_grant_table_status;\n            if ( idx < nr_status_frames(d->grant_table) )\n                mfn = virt_to_mfn(d->grant_table->status[idx]);\n            else\n                return -EINVAL;\n        }\n        else\n        {\n            if ( (idx >= nr_grant_frames(d->grant_table)) &&\n                 (idx < max_grant_frames) )\n                gnttab_grow_table(d, idx + 1);\n\n            if ( idx < nr_grant_frames(d->grant_table) )\n                mfn = virt_to_mfn(d->grant_table->shared_raw[idx]);\n            else\n                return -EINVAL;\n        }\n        \n        d->arch.grant_table_gpfn[idx] = gpfn;\n\n        t = p2m_ram_rw;\n\n        write_unlock(&d->grant_table->lock);\n        break;\n    case XENMAPSPACE_shared_info:\n        if ( idx != 0 )\n            return -EINVAL;\n\n        mfn = virt_to_mfn(d->shared_info);\n        t = p2m_ram_rw;\n\n        break;\n    case XENMAPSPACE_gmfn_foreign:\n    {\n        struct domain *od;\n        p2m_type_t p2mt;\n        od = rcu_lock_domain_by_any_id(foreign_domid);\n        if ( od == NULL )\n            return -ESRCH;\n\n        if ( od == d )\n        {\n            rcu_unlock_domain(od);\n            return -EINVAL;\n        }\n\n        rc = xsm_map_gmfn_foreign(XSM_TARGET, d, od);\n        if ( rc )\n        {\n            rcu_unlock_domain(od);\n            return rc;\n        }\n\n        /* Take reference to the foreign domain page.\n         * Reference will be released in XENMEM_remove_from_physmap */\n        page = get_page_from_gfn(od, idx, &p2mt, P2M_ALLOC);\n        if ( !page )\n        {\n            rcu_unlock_domain(od);\n            return -EINVAL;\n        }\n\n        if ( !p2m_is_ram(p2mt) )\n        {\n            put_page(page);\n            rcu_unlock_domain(od);\n            return -EINVAL;\n        }\n\n        mfn = page_to_mfn(page);\n        t = p2m_map_foreign;\n\n        rcu_unlock_domain(od);\n        break;\n    }\n\n    default:\n        return -ENOSYS;\n    }\n\n    /* Map at new location. */\n    rc = guest_physmap_add_entry(d, gpfn, mfn, 0, t);\n\n    /* If we fail to add the mapping, we need to drop the reference we\n     * took earlier on foreign pages */\n    if ( rc && space == XENMAPSPACE_gmfn_foreign )\n    {\n        ASSERT(page != NULL);\n        put_page(page);\n    }\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -79,7 +79,6 @@\n         page = get_page_from_gfn(od, idx, &p2mt, P2M_ALLOC);\n         if ( !page )\n         {\n-            dump_p2m_lookup(od, pfn_to_paddr(idx));\n             rcu_unlock_domain(od);\n             return -EINVAL;\n         }",
        "diff_line_info": {
            "deleted_lines": [
                "            dump_p2m_lookup(od, pfn_to_paddr(idx));"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-1291",
        "func_name": "chromium/ContainerNode::parserRemoveChild",
        "description": "The ContainerNode::parserRemoveChild function in core/dom/ContainerNode.cpp in Blink, as used in Google Chrome before 45.0.2454.85, does not check whether a node is expected, which allows remote attackers to bypass the Same Origin Policy or cause a denial of service (DOM tree corruption) via a web site with crafted JavaScript code and IFRAME elements.",
        "git_url": "https://github.com/chromium/chromium/commit/2c36e1fa592c341f27f758cf8b6770957c9bfdd4",
        "commit_title": "parserRemoveChild: Avoid unintended DOM modifications after user script run.",
        "commit_text": " Surprisingly, ContainerNode::parserRemoveChild may run arbitrary user script during its DOM modification if its target contained iframes. Before this CL, this could lead to corrupt DOM tree, as the target node could be moved during parserRemoveChild execution.  This CL adds a bail-out if stmt after disconnecting child frame to abort if precondition has changed.   ",
        "func_before": "void ContainerNode::parserRemoveChild(Node& oldChild)\n{\n    ASSERT(oldChild.parentNode() == this);\n    ASSERT(!oldChild.isDocumentFragment());\n\n    Node* prev = oldChild.previousSibling();\n    Node* next = oldChild.nextSibling();\n\n    if (oldChild.connectedSubframeCount())\n        ChildFrameDisconnector(oldChild).disconnect();\n\n    ChildListMutationScope(*this).willRemoveChild(oldChild);\n    oldChild.notifyMutationObserversNodeWillDetach();\n\n    removeBetween(prev, next, oldChild);\n\n    notifyNodeRemoved(oldChild);\n    childrenChanged(ChildrenChange::forRemoval(oldChild, prev, next, ChildrenChangeSourceParser));\n}",
        "func": "void ContainerNode::parserRemoveChild(Node& oldChild)\n{\n    ASSERT(oldChild.parentNode() == this);\n    ASSERT(!oldChild.isDocumentFragment());\n\n    // This may cause arbitrary Javascript execution via onunload handlers.\n    if (oldChild.connectedSubframeCount())\n        ChildFrameDisconnector(oldChild).disconnect();\n\n    if (oldChild.parentNode() != this)\n        return;\n\n    ChildListMutationScope(*this).willRemoveChild(oldChild);\n    oldChild.notifyMutationObserversNodeWillDetach();\n\n    Node* prev = oldChild.previousSibling();\n    Node* next = oldChild.nextSibling();\n    removeBetween(prev, next, oldChild);\n\n    notifyNodeRemoved(oldChild);\n    childrenChanged(ChildrenChange::forRemoval(oldChild, prev, next, ChildrenChangeSourceParser));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,15 +3,18 @@\n     ASSERT(oldChild.parentNode() == this);\n     ASSERT(!oldChild.isDocumentFragment());\n \n-    Node* prev = oldChild.previousSibling();\n-    Node* next = oldChild.nextSibling();\n-\n+    // This may cause arbitrary Javascript execution via onunload handlers.\n     if (oldChild.connectedSubframeCount())\n         ChildFrameDisconnector(oldChild).disconnect();\n+\n+    if (oldChild.parentNode() != this)\n+        return;\n \n     ChildListMutationScope(*this).willRemoveChild(oldChild);\n     oldChild.notifyMutationObserversNodeWillDetach();\n \n+    Node* prev = oldChild.previousSibling();\n+    Node* next = oldChild.nextSibling();\n     removeBetween(prev, next, oldChild);\n \n     notifyNodeRemoved(oldChild);",
        "diff_line_info": {
            "deleted_lines": [
                "    Node* prev = oldChild.previousSibling();",
                "    Node* next = oldChild.nextSibling();",
                ""
            ],
            "added_lines": [
                "    // This may cause arbitrary Javascript execution via onunload handlers.",
                "",
                "    if (oldChild.parentNode() != this)",
                "        return;",
                "    Node* prev = oldChild.previousSibling();",
                "    Node* next = oldChild.nextSibling();"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4440",
        "func_name": "torvalds/linux/hardware_setup",
        "description": "arch/x86/kvm/vmx.c in the Linux kernel through 4.6.3 mishandles the APICv on/off state, which allows guest OS users to obtain direct APIC MSR access on the host OS, and consequently cause a denial of service (host OS crash) or possibly execute arbitrary code on the host OS, via x2APIC mode.",
        "git_url": "https://github.com/torvalds/linux/commit/3ce424e45411cf5a13105e0386b6ecf6eeb4f66f",
        "commit_title": "kvm:vmx: more complete state update on APICv on/off",
        "commit_text": " The function to update APICv on/off state (in particular, to deactivate it when enabling Hyper-V SynIC) is incomplete: it doesn't adjust APICv-related fields among secondary processor-based VM-execution controls.  As a result, Windows 2012 guests get stuck when SynIC-based auto-EOI interrupt intersected with e.g. an IPI in the guest.  In addition, the MSR intercept bitmap isn't updated every time \"virtualize x2APIC mode\" is toggled.  This path can only be triggered by a malicious guest, because Windows didn't use x2APIC but rather their own synthetic APIC access MSRs; however a guest running in a SynIC-enabled VM could switch to x2APIC and thus obtain direct access to host APIC MSRs (CVE-2016-4440).  The patch fixes those omissions. ",
        "func_before": "static __init int hardware_setup(void)\n{\n\tint r = -ENOMEM, i, msr;\n\n\trdmsrl_safe(MSR_EFER, &host_efer);\n\n\tfor (i = 0; i < ARRAY_SIZE(vmx_msr_index); ++i)\n\t\tkvm_define_shared_msr(i, vmx_msr_index[i]);\n\n\tvmx_io_bitmap_a = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_io_bitmap_a)\n\t\treturn r;\n\n\tvmx_io_bitmap_b = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_io_bitmap_b)\n\t\tgoto out;\n\n\tvmx_msr_bitmap_legacy = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_legacy)\n\t\tgoto out1;\n\n\tvmx_msr_bitmap_legacy_x2apic =\n\t\t\t\t(unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_legacy_x2apic)\n\t\tgoto out2;\n\n\tvmx_msr_bitmap_longmode = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_longmode)\n\t\tgoto out3;\n\n\tvmx_msr_bitmap_longmode_x2apic =\n\t\t\t\t(unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_longmode_x2apic)\n\t\tgoto out4;\n\n\tif (nested) {\n\t\tvmx_msr_bitmap_nested =\n\t\t\t(unsigned long *)__get_free_page(GFP_KERNEL);\n\t\tif (!vmx_msr_bitmap_nested)\n\t\t\tgoto out5;\n\t}\n\n\tvmx_vmread_bitmap = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_vmread_bitmap)\n\t\tgoto out6;\n\n\tvmx_vmwrite_bitmap = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_vmwrite_bitmap)\n\t\tgoto out7;\n\n\tmemset(vmx_vmread_bitmap, 0xff, PAGE_SIZE);\n\tmemset(vmx_vmwrite_bitmap, 0xff, PAGE_SIZE);\n\n\t/*\n\t * Allow direct access to the PC debug port (it is often used for I/O\n\t * delays, but the vmexits simply slow things down).\n\t */\n\tmemset(vmx_io_bitmap_a, 0xff, PAGE_SIZE);\n\tclear_bit(0x80, vmx_io_bitmap_a);\n\n\tmemset(vmx_io_bitmap_b, 0xff, PAGE_SIZE);\n\n\tmemset(vmx_msr_bitmap_legacy, 0xff, PAGE_SIZE);\n\tmemset(vmx_msr_bitmap_longmode, 0xff, PAGE_SIZE);\n\tif (nested)\n\t\tmemset(vmx_msr_bitmap_nested, 0xff, PAGE_SIZE);\n\n\tif (setup_vmcs_config(&vmcs_config) < 0) {\n\t\tr = -EIO;\n\t\tgoto out8;\n\t}\n\n\tif (boot_cpu_has(X86_FEATURE_NX))\n\t\tkvm_enable_efer_bits(EFER_NX);\n\n\tif (!cpu_has_vmx_vpid())\n\t\tenable_vpid = 0;\n\tif (!cpu_has_vmx_shadow_vmcs())\n\t\tenable_shadow_vmcs = 0;\n\tif (enable_shadow_vmcs)\n\t\tinit_vmcs_shadow_fields();\n\n\tif (!cpu_has_vmx_ept() ||\n\t    !cpu_has_vmx_ept_4levels()) {\n\t\tenable_ept = 0;\n\t\tenable_unrestricted_guest = 0;\n\t\tenable_ept_ad_bits = 0;\n\t}\n\n\tif (!cpu_has_vmx_ept_ad_bits())\n\t\tenable_ept_ad_bits = 0;\n\n\tif (!cpu_has_vmx_unrestricted_guest())\n\t\tenable_unrestricted_guest = 0;\n\n\tif (!cpu_has_vmx_flexpriority())\n\t\tflexpriority_enabled = 0;\n\n\t/*\n\t * set_apic_access_page_addr() is used to reload apic access\n\t * page upon invalidation.  No need to do anything if not\n\t * using the APIC_ACCESS_ADDR VMCS field.\n\t */\n\tif (!flexpriority_enabled)\n\t\tkvm_x86_ops->set_apic_access_page_addr = NULL;\n\n\tif (!cpu_has_vmx_tpr_shadow())\n\t\tkvm_x86_ops->update_cr8_intercept = NULL;\n\n\tif (enable_ept && !cpu_has_vmx_ept_2m_page())\n\t\tkvm_disable_largepages();\n\n\tif (!cpu_has_vmx_ple())\n\t\tple_gap = 0;\n\n\tif (!cpu_has_vmx_apicv())\n\t\tenable_apicv = 0;\n\n\tif (cpu_has_vmx_tsc_scaling()) {\n\t\tkvm_has_tsc_control = true;\n\t\tkvm_max_tsc_scaling_ratio = KVM_VMX_TSC_MULTIPLIER_MAX;\n\t\tkvm_tsc_scaling_ratio_frac_bits = 48;\n\t}\n\n\tvmx_disable_intercept_for_msr(MSR_FS_BASE, false);\n\tvmx_disable_intercept_for_msr(MSR_GS_BASE, false);\n\tvmx_disable_intercept_for_msr(MSR_KERNEL_GS_BASE, true);\n\tvmx_disable_intercept_for_msr(MSR_IA32_SYSENTER_CS, false);\n\tvmx_disable_intercept_for_msr(MSR_IA32_SYSENTER_ESP, false);\n\tvmx_disable_intercept_for_msr(MSR_IA32_SYSENTER_EIP, false);\n\tvmx_disable_intercept_for_msr(MSR_IA32_BNDCFGS, true);\n\n\tmemcpy(vmx_msr_bitmap_legacy_x2apic,\n\t\t\tvmx_msr_bitmap_legacy, PAGE_SIZE);\n\tmemcpy(vmx_msr_bitmap_longmode_x2apic,\n\t\t\tvmx_msr_bitmap_longmode, PAGE_SIZE);\n\n\tset_bit(0, vmx_vpid_bitmap); /* 0 is reserved for host */\n\n\tif (enable_apicv) {\n\t\tfor (msr = 0x800; msr <= 0x8ff; msr++)\n\t\t\tvmx_disable_intercept_msr_read_x2apic(msr);\n\n\t\t/* According SDM, in x2apic mode, the whole id reg is used.\n\t\t * But in KVM, it only use the highest eight bits. Need to\n\t\t * intercept it */\n\t\tvmx_enable_intercept_msr_read_x2apic(0x802);\n\t\t/* TMCCT */\n\t\tvmx_enable_intercept_msr_read_x2apic(0x839);\n\t\t/* TPR */\n\t\tvmx_disable_intercept_msr_write_x2apic(0x808);\n\t\t/* EOI */\n\t\tvmx_disable_intercept_msr_write_x2apic(0x80b);\n\t\t/* SELF-IPI */\n\t\tvmx_disable_intercept_msr_write_x2apic(0x83f);\n\t}\n\n\tif (enable_ept) {\n\t\tkvm_mmu_set_mask_ptes(0ull,\n\t\t\t(enable_ept_ad_bits) ? VMX_EPT_ACCESS_BIT : 0ull,\n\t\t\t(enable_ept_ad_bits) ? VMX_EPT_DIRTY_BIT : 0ull,\n\t\t\t0ull, VMX_EPT_EXECUTABLE_MASK);\n\t\tept_set_mmio_spte_mask();\n\t\tkvm_enable_tdp();\n\t} else\n\t\tkvm_disable_tdp();\n\n\tupdate_ple_window_actual_max();\n\n\t/*\n\t * Only enable PML when hardware supports PML feature, and both EPT\n\t * and EPT A/D bit features are enabled -- PML depends on them to work.\n\t */\n\tif (!enable_ept || !enable_ept_ad_bits || !cpu_has_vmx_pml())\n\t\tenable_pml = 0;\n\n\tif (!enable_pml) {\n\t\tkvm_x86_ops->slot_enable_log_dirty = NULL;\n\t\tkvm_x86_ops->slot_disable_log_dirty = NULL;\n\t\tkvm_x86_ops->flush_log_dirty = NULL;\n\t\tkvm_x86_ops->enable_log_dirty_pt_masked = NULL;\n\t}\n\n\tkvm_set_posted_intr_wakeup_handler(wakeup_handler);\n\n\treturn alloc_kvm_area();\n\nout8:\n\tfree_page((unsigned long)vmx_vmwrite_bitmap);\nout7:\n\tfree_page((unsigned long)vmx_vmread_bitmap);\nout6:\n\tif (nested)\n\t\tfree_page((unsigned long)vmx_msr_bitmap_nested);\nout5:\n\tfree_page((unsigned long)vmx_msr_bitmap_longmode_x2apic);\nout4:\n\tfree_page((unsigned long)vmx_msr_bitmap_longmode);\nout3:\n\tfree_page((unsigned long)vmx_msr_bitmap_legacy_x2apic);\nout2:\n\tfree_page((unsigned long)vmx_msr_bitmap_legacy);\nout1:\n\tfree_page((unsigned long)vmx_io_bitmap_b);\nout:\n\tfree_page((unsigned long)vmx_io_bitmap_a);\n\n    return r;\n}",
        "func": "static __init int hardware_setup(void)\n{\n\tint r = -ENOMEM, i, msr;\n\n\trdmsrl_safe(MSR_EFER, &host_efer);\n\n\tfor (i = 0; i < ARRAY_SIZE(vmx_msr_index); ++i)\n\t\tkvm_define_shared_msr(i, vmx_msr_index[i]);\n\n\tvmx_io_bitmap_a = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_io_bitmap_a)\n\t\treturn r;\n\n\tvmx_io_bitmap_b = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_io_bitmap_b)\n\t\tgoto out;\n\n\tvmx_msr_bitmap_legacy = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_legacy)\n\t\tgoto out1;\n\n\tvmx_msr_bitmap_legacy_x2apic =\n\t\t\t\t(unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_legacy_x2apic)\n\t\tgoto out2;\n\n\tvmx_msr_bitmap_longmode = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_longmode)\n\t\tgoto out3;\n\n\tvmx_msr_bitmap_longmode_x2apic =\n\t\t\t\t(unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_msr_bitmap_longmode_x2apic)\n\t\tgoto out4;\n\n\tif (nested) {\n\t\tvmx_msr_bitmap_nested =\n\t\t\t(unsigned long *)__get_free_page(GFP_KERNEL);\n\t\tif (!vmx_msr_bitmap_nested)\n\t\t\tgoto out5;\n\t}\n\n\tvmx_vmread_bitmap = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_vmread_bitmap)\n\t\tgoto out6;\n\n\tvmx_vmwrite_bitmap = (unsigned long *)__get_free_page(GFP_KERNEL);\n\tif (!vmx_vmwrite_bitmap)\n\t\tgoto out7;\n\n\tmemset(vmx_vmread_bitmap, 0xff, PAGE_SIZE);\n\tmemset(vmx_vmwrite_bitmap, 0xff, PAGE_SIZE);\n\n\t/*\n\t * Allow direct access to the PC debug port (it is often used for I/O\n\t * delays, but the vmexits simply slow things down).\n\t */\n\tmemset(vmx_io_bitmap_a, 0xff, PAGE_SIZE);\n\tclear_bit(0x80, vmx_io_bitmap_a);\n\n\tmemset(vmx_io_bitmap_b, 0xff, PAGE_SIZE);\n\n\tmemset(vmx_msr_bitmap_legacy, 0xff, PAGE_SIZE);\n\tmemset(vmx_msr_bitmap_longmode, 0xff, PAGE_SIZE);\n\tif (nested)\n\t\tmemset(vmx_msr_bitmap_nested, 0xff, PAGE_SIZE);\n\n\tif (setup_vmcs_config(&vmcs_config) < 0) {\n\t\tr = -EIO;\n\t\tgoto out8;\n\t}\n\n\tif (boot_cpu_has(X86_FEATURE_NX))\n\t\tkvm_enable_efer_bits(EFER_NX);\n\n\tif (!cpu_has_vmx_vpid())\n\t\tenable_vpid = 0;\n\tif (!cpu_has_vmx_shadow_vmcs())\n\t\tenable_shadow_vmcs = 0;\n\tif (enable_shadow_vmcs)\n\t\tinit_vmcs_shadow_fields();\n\n\tif (!cpu_has_vmx_ept() ||\n\t    !cpu_has_vmx_ept_4levels()) {\n\t\tenable_ept = 0;\n\t\tenable_unrestricted_guest = 0;\n\t\tenable_ept_ad_bits = 0;\n\t}\n\n\tif (!cpu_has_vmx_ept_ad_bits())\n\t\tenable_ept_ad_bits = 0;\n\n\tif (!cpu_has_vmx_unrestricted_guest())\n\t\tenable_unrestricted_guest = 0;\n\n\tif (!cpu_has_vmx_flexpriority())\n\t\tflexpriority_enabled = 0;\n\n\t/*\n\t * set_apic_access_page_addr() is used to reload apic access\n\t * page upon invalidation.  No need to do anything if not\n\t * using the APIC_ACCESS_ADDR VMCS field.\n\t */\n\tif (!flexpriority_enabled)\n\t\tkvm_x86_ops->set_apic_access_page_addr = NULL;\n\n\tif (!cpu_has_vmx_tpr_shadow())\n\t\tkvm_x86_ops->update_cr8_intercept = NULL;\n\n\tif (enable_ept && !cpu_has_vmx_ept_2m_page())\n\t\tkvm_disable_largepages();\n\n\tif (!cpu_has_vmx_ple())\n\t\tple_gap = 0;\n\n\tif (!cpu_has_vmx_apicv())\n\t\tenable_apicv = 0;\n\n\tif (cpu_has_vmx_tsc_scaling()) {\n\t\tkvm_has_tsc_control = true;\n\t\tkvm_max_tsc_scaling_ratio = KVM_VMX_TSC_MULTIPLIER_MAX;\n\t\tkvm_tsc_scaling_ratio_frac_bits = 48;\n\t}\n\n\tvmx_disable_intercept_for_msr(MSR_FS_BASE, false);\n\tvmx_disable_intercept_for_msr(MSR_GS_BASE, false);\n\tvmx_disable_intercept_for_msr(MSR_KERNEL_GS_BASE, true);\n\tvmx_disable_intercept_for_msr(MSR_IA32_SYSENTER_CS, false);\n\tvmx_disable_intercept_for_msr(MSR_IA32_SYSENTER_ESP, false);\n\tvmx_disable_intercept_for_msr(MSR_IA32_SYSENTER_EIP, false);\n\tvmx_disable_intercept_for_msr(MSR_IA32_BNDCFGS, true);\n\n\tmemcpy(vmx_msr_bitmap_legacy_x2apic,\n\t\t\tvmx_msr_bitmap_legacy, PAGE_SIZE);\n\tmemcpy(vmx_msr_bitmap_longmode_x2apic,\n\t\t\tvmx_msr_bitmap_longmode, PAGE_SIZE);\n\n\tset_bit(0, vmx_vpid_bitmap); /* 0 is reserved for host */\n\n\tfor (msr = 0x800; msr <= 0x8ff; msr++)\n\t\tvmx_disable_intercept_msr_read_x2apic(msr);\n\n\t/* According SDM, in x2apic mode, the whole id reg is used.  But in\n\t * KVM, it only use the highest eight bits. Need to intercept it */\n\tvmx_enable_intercept_msr_read_x2apic(0x802);\n\t/* TMCCT */\n\tvmx_enable_intercept_msr_read_x2apic(0x839);\n\t/* TPR */\n\tvmx_disable_intercept_msr_write_x2apic(0x808);\n\t/* EOI */\n\tvmx_disable_intercept_msr_write_x2apic(0x80b);\n\t/* SELF-IPI */\n\tvmx_disable_intercept_msr_write_x2apic(0x83f);\n\n\tif (enable_ept) {\n\t\tkvm_mmu_set_mask_ptes(0ull,\n\t\t\t(enable_ept_ad_bits) ? VMX_EPT_ACCESS_BIT : 0ull,\n\t\t\t(enable_ept_ad_bits) ? VMX_EPT_DIRTY_BIT : 0ull,\n\t\t\t0ull, VMX_EPT_EXECUTABLE_MASK);\n\t\tept_set_mmio_spte_mask();\n\t\tkvm_enable_tdp();\n\t} else\n\t\tkvm_disable_tdp();\n\n\tupdate_ple_window_actual_max();\n\n\t/*\n\t * Only enable PML when hardware supports PML feature, and both EPT\n\t * and EPT A/D bit features are enabled -- PML depends on them to work.\n\t */\n\tif (!enable_ept || !enable_ept_ad_bits || !cpu_has_vmx_pml())\n\t\tenable_pml = 0;\n\n\tif (!enable_pml) {\n\t\tkvm_x86_ops->slot_enable_log_dirty = NULL;\n\t\tkvm_x86_ops->slot_disable_log_dirty = NULL;\n\t\tkvm_x86_ops->flush_log_dirty = NULL;\n\t\tkvm_x86_ops->enable_log_dirty_pt_masked = NULL;\n\t}\n\n\tkvm_set_posted_intr_wakeup_handler(wakeup_handler);\n\n\treturn alloc_kvm_area();\n\nout8:\n\tfree_page((unsigned long)vmx_vmwrite_bitmap);\nout7:\n\tfree_page((unsigned long)vmx_vmread_bitmap);\nout6:\n\tif (nested)\n\t\tfree_page((unsigned long)vmx_msr_bitmap_nested);\nout5:\n\tfree_page((unsigned long)vmx_msr_bitmap_longmode_x2apic);\nout4:\n\tfree_page((unsigned long)vmx_msr_bitmap_longmode);\nout3:\n\tfree_page((unsigned long)vmx_msr_bitmap_legacy_x2apic);\nout2:\n\tfree_page((unsigned long)vmx_msr_bitmap_legacy);\nout1:\n\tfree_page((unsigned long)vmx_io_bitmap_b);\nout:\n\tfree_page((unsigned long)vmx_io_bitmap_a);\n\n    return r;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -137,23 +137,20 @@\n \n \tset_bit(0, vmx_vpid_bitmap); /* 0 is reserved for host */\n \n-\tif (enable_apicv) {\n-\t\tfor (msr = 0x800; msr <= 0x8ff; msr++)\n-\t\t\tvmx_disable_intercept_msr_read_x2apic(msr);\n-\n-\t\t/* According SDM, in x2apic mode, the whole id reg is used.\n-\t\t * But in KVM, it only use the highest eight bits. Need to\n-\t\t * intercept it */\n-\t\tvmx_enable_intercept_msr_read_x2apic(0x802);\n-\t\t/* TMCCT */\n-\t\tvmx_enable_intercept_msr_read_x2apic(0x839);\n-\t\t/* TPR */\n-\t\tvmx_disable_intercept_msr_write_x2apic(0x808);\n-\t\t/* EOI */\n-\t\tvmx_disable_intercept_msr_write_x2apic(0x80b);\n-\t\t/* SELF-IPI */\n-\t\tvmx_disable_intercept_msr_write_x2apic(0x83f);\n-\t}\n+\tfor (msr = 0x800; msr <= 0x8ff; msr++)\n+\t\tvmx_disable_intercept_msr_read_x2apic(msr);\n+\n+\t/* According SDM, in x2apic mode, the whole id reg is used.  But in\n+\t * KVM, it only use the highest eight bits. Need to intercept it */\n+\tvmx_enable_intercept_msr_read_x2apic(0x802);\n+\t/* TMCCT */\n+\tvmx_enable_intercept_msr_read_x2apic(0x839);\n+\t/* TPR */\n+\tvmx_disable_intercept_msr_write_x2apic(0x808);\n+\t/* EOI */\n+\tvmx_disable_intercept_msr_write_x2apic(0x80b);\n+\t/* SELF-IPI */\n+\tvmx_disable_intercept_msr_write_x2apic(0x83f);\n \n \tif (enable_ept) {\n \t\tkvm_mmu_set_mask_ptes(0ull,",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (enable_apicv) {",
                "\t\tfor (msr = 0x800; msr <= 0x8ff; msr++)",
                "\t\t\tvmx_disable_intercept_msr_read_x2apic(msr);",
                "",
                "\t\t/* According SDM, in x2apic mode, the whole id reg is used.",
                "\t\t * But in KVM, it only use the highest eight bits. Need to",
                "\t\t * intercept it */",
                "\t\tvmx_enable_intercept_msr_read_x2apic(0x802);",
                "\t\t/* TMCCT */",
                "\t\tvmx_enable_intercept_msr_read_x2apic(0x839);",
                "\t\t/* TPR */",
                "\t\tvmx_disable_intercept_msr_write_x2apic(0x808);",
                "\t\t/* EOI */",
                "\t\tvmx_disable_intercept_msr_write_x2apic(0x80b);",
                "\t\t/* SELF-IPI */",
                "\t\tvmx_disable_intercept_msr_write_x2apic(0x83f);",
                "\t}"
            ],
            "added_lines": [
                "\tfor (msr = 0x800; msr <= 0x8ff; msr++)",
                "\t\tvmx_disable_intercept_msr_read_x2apic(msr);",
                "",
                "\t/* According SDM, in x2apic mode, the whole id reg is used.  But in",
                "\t * KVM, it only use the highest eight bits. Need to intercept it */",
                "\tvmx_enable_intercept_msr_read_x2apic(0x802);",
                "\t/* TMCCT */",
                "\tvmx_enable_intercept_msr_read_x2apic(0x839);",
                "\t/* TPR */",
                "\tvmx_disable_intercept_msr_write_x2apic(0x808);",
                "\t/* EOI */",
                "\tvmx_disable_intercept_msr_write_x2apic(0x80b);",
                "\t/* SELF-IPI */",
                "\tvmx_disable_intercept_msr_write_x2apic(0x83f);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4440",
        "func_name": "torvalds/linux/vmx_refresh_apicv_exec_ctrl",
        "description": "arch/x86/kvm/vmx.c in the Linux kernel through 4.6.3 mishandles the APICv on/off state, which allows guest OS users to obtain direct APIC MSR access on the host OS, and consequently cause a denial of service (host OS crash) or possibly execute arbitrary code on the host OS, via x2APIC mode.",
        "git_url": "https://github.com/torvalds/linux/commit/3ce424e45411cf5a13105e0386b6ecf6eeb4f66f",
        "commit_title": "kvm:vmx: more complete state update on APICv on/off",
        "commit_text": " The function to update APICv on/off state (in particular, to deactivate it when enabling Hyper-V SynIC) is incomplete: it doesn't adjust APICv-related fields among secondary processor-based VM-execution controls.  As a result, Windows 2012 guests get stuck when SynIC-based auto-EOI interrupt intersected with e.g. an IPI in the guest.  In addition, the MSR intercept bitmap isn't updated every time \"virtualize x2APIC mode\" is toggled.  This path can only be triggered by a malicious guest, because Windows didn't use x2APIC but rather their own synthetic APIC access MSRs; however a guest running in a SynIC-enabled VM could switch to x2APIC and thus obtain direct access to host APIC MSRs (CVE-2016-4440).  The patch fixes those omissions. ",
        "func_before": "static void vmx_refresh_apicv_exec_ctrl(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tvmcs_write32(PIN_BASED_VM_EXEC_CONTROL, vmx_pin_based_exec_ctrl(vmx));\n}",
        "func": "static void vmx_refresh_apicv_exec_ctrl(struct kvm_vcpu *vcpu)\n{\n\tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n\n\tvmcs_write32(PIN_BASED_VM_EXEC_CONTROL, vmx_pin_based_exec_ctrl(vmx));\n\tif (cpu_has_secondary_exec_ctrls()) {\n\t\tif (kvm_vcpu_apicv_active(vcpu))\n\t\t\tvmcs_set_bits(SECONDARY_VM_EXEC_CONTROL,\n\t\t\t\t      SECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\t\t      SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n\t\telse\n\t\t\tvmcs_clear_bits(SECONDARY_VM_EXEC_CONTROL,\n\t\t\t\t\tSECONDARY_EXEC_APIC_REGISTER_VIRT |\n\t\t\t\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n\t}\n\n\tif (cpu_has_vmx_msr_bitmap())\n\t\tvmx_set_msr_bitmap(vcpu);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,4 +3,17 @@\n \tstruct vcpu_vmx *vmx = to_vmx(vcpu);\n \n \tvmcs_write32(PIN_BASED_VM_EXEC_CONTROL, vmx_pin_based_exec_ctrl(vmx));\n+\tif (cpu_has_secondary_exec_ctrls()) {\n+\t\tif (kvm_vcpu_apicv_active(vcpu))\n+\t\t\tvmcs_set_bits(SECONDARY_VM_EXEC_CONTROL,\n+\t\t\t\t      SECONDARY_EXEC_APIC_REGISTER_VIRT |\n+\t\t\t\t      SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n+\t\telse\n+\t\t\tvmcs_clear_bits(SECONDARY_VM_EXEC_CONTROL,\n+\t\t\t\t\tSECONDARY_EXEC_APIC_REGISTER_VIRT |\n+\t\t\t\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);\n+\t}\n+\n+\tif (cpu_has_vmx_msr_bitmap())\n+\t\tvmx_set_msr_bitmap(vcpu);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (cpu_has_secondary_exec_ctrls()) {",
                "\t\tif (kvm_vcpu_apicv_active(vcpu))",
                "\t\t\tvmcs_set_bits(SECONDARY_VM_EXEC_CONTROL,",
                "\t\t\t\t      SECONDARY_EXEC_APIC_REGISTER_VIRT |",
                "\t\t\t\t      SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);",
                "\t\telse",
                "\t\t\tvmcs_clear_bits(SECONDARY_VM_EXEC_CONTROL,",
                "\t\t\t\t\tSECONDARY_EXEC_APIC_REGISTER_VIRT |",
                "\t\t\t\t\tSECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);",
                "\t}",
                "",
                "\tif (cpu_has_vmx_msr_bitmap())",
                "\t\tvmx_set_msr_bitmap(vcpu);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4440",
        "func_name": "torvalds/linux/vmx_set_msr_bitmap",
        "description": "arch/x86/kvm/vmx.c in the Linux kernel through 4.6.3 mishandles the APICv on/off state, which allows guest OS users to obtain direct APIC MSR access on the host OS, and consequently cause a denial of service (host OS crash) or possibly execute arbitrary code on the host OS, via x2APIC mode.",
        "git_url": "https://github.com/torvalds/linux/commit/3ce424e45411cf5a13105e0386b6ecf6eeb4f66f",
        "commit_title": "kvm:vmx: more complete state update on APICv on/off",
        "commit_text": " The function to update APICv on/off state (in particular, to deactivate it when enabling Hyper-V SynIC) is incomplete: it doesn't adjust APICv-related fields among secondary processor-based VM-execution controls.  As a result, Windows 2012 guests get stuck when SynIC-based auto-EOI interrupt intersected with e.g. an IPI in the guest.  In addition, the MSR intercept bitmap isn't updated every time \"virtualize x2APIC mode\" is toggled.  This path can only be triggered by a malicious guest, because Windows didn't use x2APIC but rather their own synthetic APIC access MSRs; however a guest running in a SynIC-enabled VM could switch to x2APIC and thus obtain direct access to host APIC MSRs (CVE-2016-4440).  The patch fixes those omissions. ",
        "func_before": "static void vmx_set_msr_bitmap(struct kvm_vcpu *vcpu)\n{\n\tunsigned long *msr_bitmap;\n\n\tif (is_guest_mode(vcpu))\n\t\tmsr_bitmap = vmx_msr_bitmap_nested;\n\telse if (vcpu->arch.apic_base & X2APIC_ENABLE) {\n\t\tif (is_long_mode(vcpu))\n\t\t\tmsr_bitmap = vmx_msr_bitmap_longmode_x2apic;\n\t\telse\n\t\t\tmsr_bitmap = vmx_msr_bitmap_legacy_x2apic;\n\t} else {\n\t\tif (is_long_mode(vcpu))\n\t\t\tmsr_bitmap = vmx_msr_bitmap_longmode;\n\t\telse\n\t\t\tmsr_bitmap = vmx_msr_bitmap_legacy;\n\t}\n\n\tvmcs_write64(MSR_BITMAP, __pa(msr_bitmap));\n}",
        "func": "static void vmx_set_msr_bitmap(struct kvm_vcpu *vcpu)\n{\n\tunsigned long *msr_bitmap;\n\n\tif (is_guest_mode(vcpu))\n\t\tmsr_bitmap = vmx_msr_bitmap_nested;\n\telse if (cpu_has_secondary_exec_ctrls() &&\n\t\t (vmcs_read32(SECONDARY_VM_EXEC_CONTROL) &\n\t\t  SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE)) {\n\t\tif (is_long_mode(vcpu))\n\t\t\tmsr_bitmap = vmx_msr_bitmap_longmode_x2apic;\n\t\telse\n\t\t\tmsr_bitmap = vmx_msr_bitmap_legacy_x2apic;\n\t} else {\n\t\tif (is_long_mode(vcpu))\n\t\t\tmsr_bitmap = vmx_msr_bitmap_longmode;\n\t\telse\n\t\t\tmsr_bitmap = vmx_msr_bitmap_legacy;\n\t}\n\n\tvmcs_write64(MSR_BITMAP, __pa(msr_bitmap));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,7 +4,9 @@\n \n \tif (is_guest_mode(vcpu))\n \t\tmsr_bitmap = vmx_msr_bitmap_nested;\n-\telse if (vcpu->arch.apic_base & X2APIC_ENABLE) {\n+\telse if (cpu_has_secondary_exec_ctrls() &&\n+\t\t (vmcs_read32(SECONDARY_VM_EXEC_CONTROL) &\n+\t\t  SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE)) {\n \t\tif (is_long_mode(vcpu))\n \t\t\tmsr_bitmap = vmx_msr_bitmap_longmode_x2apic;\n \t\telse",
        "diff_line_info": {
            "deleted_lines": [
                "\telse if (vcpu->arch.apic_base & X2APIC_ENABLE) {"
            ],
            "added_lines": [
                "\telse if (cpu_has_secondary_exec_ctrls() &&",
                "\t\t (vmcs_read32(SECONDARY_VM_EXEC_CONTROL) &",
                "\t\t  SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/xt_compat_check_entry_offsets",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "int xt_compat_check_entry_offsets(const void *base,\n\t\t\t\t  unsigned int target_offset,\n\t\t\t\t  unsigned int next_offset)\n{\n\tconst struct compat_xt_entry_target *t;\n\tconst char *e = base;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct compat_xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "func": "int xt_compat_check_entry_offsets(const void *base, const char *elems,\n\t\t\t\t  unsigned int target_offset,\n\t\t\t\t  unsigned int next_offset)\n{\n\tlong size_of_base_struct = elems - (const char *)base;\n\tconst struct compat_xt_entry_target *t;\n\tconst char *e = base;\n\n\tif (target_offset < size_of_base_struct)\n\t\treturn -EINVAL;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct compat_xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,13 @@\n-int xt_compat_check_entry_offsets(const void *base,\n+int xt_compat_check_entry_offsets(const void *base, const char *elems,\n \t\t\t\t  unsigned int target_offset,\n \t\t\t\t  unsigned int next_offset)\n {\n+\tlong size_of_base_struct = elems - (const char *)base;\n \tconst struct compat_xt_entry_target *t;\n \tconst char *e = base;\n+\n+\tif (target_offset < size_of_base_struct)\n+\t\treturn -EINVAL;\n \n \tif (target_offset + sizeof(*t) > next_offset)\n \t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [
                "int xt_compat_check_entry_offsets(const void *base,"
            ],
            "added_lines": [
                "int xt_compat_check_entry_offsets(const void *base, const char *elems,",
                "\tlong size_of_base_struct = elems - (const char *)base;",
                "",
                "\tif (target_offset < size_of_base_struct)",
                "\t\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/xt_check_entry_offsets",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "int xt_check_entry_offsets(const void *base,\n\t\t\t   unsigned int target_offset,\n\t\t\t   unsigned int next_offset)\n{\n\tconst struct xt_entry_target *t;\n\tconst char *e = base;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "func": "int xt_check_entry_offsets(const void *base,\n\t\t\t   const char *elems,\n\t\t\t   unsigned int target_offset,\n\t\t\t   unsigned int next_offset)\n{\n\tlong size_of_base_struct = elems - (const char *)base;\n\tconst struct xt_entry_target *t;\n\tconst char *e = base;\n\n\t/* target start is within the ip/ip6/arpt_entry struct */\n\tif (target_offset < size_of_base_struct)\n\t\treturn -EINVAL;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,15 @@\n int xt_check_entry_offsets(const void *base,\n+\t\t\t   const char *elems,\n \t\t\t   unsigned int target_offset,\n \t\t\t   unsigned int next_offset)\n {\n+\tlong size_of_base_struct = elems - (const char *)base;\n \tconst struct xt_entry_target *t;\n \tconst char *e = base;\n+\n+\t/* target start is within the ip/ip6/arpt_entry struct */\n+\tif (target_offset < size_of_base_struct)\n+\t\treturn -EINVAL;\n \n \tif (target_offset + sizeof(*t) > next_offset)\n \t\treturn -EINVAL;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t\t   const char *elems,",
                "\tlong size_of_base_struct = elems - (const char *)base;",
                "",
                "\t/* target start is within the ip/ip6/arpt_entry struct */",
                "\tif (target_offset < size_of_base_struct)",
                "\t\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/check_entry_size_and_hooks",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "func": "static inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -26,7 +26,8 @@\n \tif (!arp_checkentry(&e->arp))\n \t\treturn -EINVAL;\n \n-\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n+\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n+\t\t\t\t     e->next_offset);\n \tif (err)\n \t\treturn err;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);"
            ],
            "added_lines": [
                "\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,",
                "\t\t\t\t     e->next_offset);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/check_compat_entry_size_and_hooks",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
        "func": "static inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,7 +31,7 @@\n \tif (!arp_checkentry(&e->arp))\n \t\treturn -EINVAL;\n \n-\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n+\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n \t\t\t\t\t    e->next_offset);\n \tif (ret)\n \t\treturn ret;",
        "diff_line_info": {
            "deleted_lines": [
                "\tret = xt_compat_check_entry_offsets(e, e->target_offset,"
            ],
            "added_lines": [
                "\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/check_entry_size_and_hooks",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "func": "static int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,7 +27,8 @@\n \tif (!ip_checkentry(&e->ip))\n \t\treturn -EINVAL;\n \n-\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n+\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n+\t\t\t\t     e->next_offset);\n \tif (err)\n \t\treturn err;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);"
            ],
            "added_lines": [
                "\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,",
                "\t\t\t\t     e->next_offset);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/check_compat_entry_size_and_hooks",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ipt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ip, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
        "func": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ipt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ip, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,7 +33,7 @@\n \tif (!ip_checkentry(&e->ip))\n \t\treturn -EINVAL;\n \n-\tret = xt_compat_check_entry_offsets(e,\n+\tret = xt_compat_check_entry_offsets(e, e->elems,\n \t\t\t\t\t    e->target_offset, e->next_offset);\n \tif (ret)\n \t\treturn ret;",
        "diff_line_info": {
            "deleted_lines": [
                "\tret = xt_compat_check_entry_offsets(e,"
            ],
            "added_lines": [
                "\tret = xt_compat_check_entry_offsets(e, e->elems,"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/check_entry_size_and_hooks",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "func": "static int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,7 +27,8 @@\n \tif (!ip6_checkentry(&e->ipv6))\n \t\treturn -EINVAL;\n \n-\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n+\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n+\t\t\t\t     e->next_offset);\n \tif (err)\n \t\treturn err;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);"
            ],
            "added_lines": [
                "\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,",
                "\t\t\t\t     e->next_offset);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-4997",
        "func_name": "torvalds/linux/check_compat_entry_size_and_hooks",
        "description": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.",
        "git_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c",
        "commit_title": "netfilter: x_tables: check for bogus target offset",
        "commit_text": " We're currently asserting that targetoff + targetsize <= nextoff.  Extend it to also check that targetoff is >= sizeof(xt_entry). Since this is generic code, add an argument pointing to the start of the match/target, we can then derive the base structure size from the delta.  We also need the e->elems pointer in a followup change to validate matches. ",
        "func_before": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ip6t_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
        "func": "static int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ip6t_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,7 +33,7 @@\n \tif (!ip6_checkentry(&e->ipv6))\n \t\treturn -EINVAL;\n \n-\tret = xt_compat_check_entry_offsets(e,\n+\tret = xt_compat_check_entry_offsets(e, e->elems,\n \t\t\t\t\t    e->target_offset, e->next_offset);\n \tif (ret)\n \t\treturn ret;",
        "diff_line_info": {
            "deleted_lines": [
                "\tret = xt_compat_check_entry_offsets(e,"
            ],
            "added_lines": [
                "\tret = xt_compat_check_entry_offsets(e, e->elems,"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3758",
        "func_name": "android/dexOptGenerateCacheFileName",
        "description": "Multiple buffer overflows in libdex/OptInvocation.cpp in DexClassLoader in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-07-01 allow attackers to gain privileges via a crafted application that provides a long filename, aka internal bug 27840771.",
        "git_url": "https://android.googlesource.com/platform/dalvik/+/338aeaf28e9981c15d0673b18487dba61eb5447c",
        "commit_title": "Fix potential buffer overrun.",
        "commit_text": "  ",
        "func_before": "char* dexOptGenerateCacheFileName(const char* fileName, const char* subFileName)\n{\n    char nameBuf[512];\n    char absoluteFile[sizeof(nameBuf)];\n    const size_t kBufLen = sizeof(nameBuf) - 1;\n    const char* dataRoot;\n    char* cp;\n\n    /*\n     * Get the absolute path of the Jar or DEX file.\n     */\n    absoluteFile[0] = '\\0';\n    if (fileName[0] != '/') {\n        /*\n         * Generate the absolute path.  This doesn't do everything it\n         * should, e.g. if filename is \"./out/whatever\" it doesn't crunch\n         * the leading \"./\" out, but it'll do.\n         */\n        if (getcwd(absoluteFile, kBufLen) == NULL) {\n            ALOGE(\"Can't get CWD while opening jar file\");\n            return NULL;\n        }\n        strncat(absoluteFile, \"/\", kBufLen);\n    }\n    strncat(absoluteFile, fileName, kBufLen);\n\n    /*\n     * Append the name of the Jar file entry, if any.  This is not currently\n     * required, but will be if we start putting more than one DEX file\n     * in a Jar.\n     */\n    if (subFileName != NULL) {\n        strncat(absoluteFile, \"/\", kBufLen);\n        strncat(absoluteFile, subFileName, kBufLen);\n    }\n\n    /* Turn the path into a flat filename by replacing\n     * any slashes after the first one with '@' characters.\n     */\n    cp = absoluteFile + 1;\n    while (*cp != '\\0') {\n        if (*cp == '/') {\n            *cp = '@';\n        }\n        cp++;\n    }\n\n    /* Build the name of the cache directory.\n     */\n    dataRoot = getenv(\"ANDROID_DATA\");\n    if (dataRoot == NULL)\n        dataRoot = \"/data\";\n    snprintf(nameBuf, kBufLen, \"%s/%s\", dataRoot, kCacheDirectoryName);\n    if (strcmp(dataRoot, \"/data\") != 0) {\n        int result = dexOptMkdir(nameBuf, 0700);\n        if (result != 0 && errno != EEXIST) {\n            ALOGE(\"Failed to create dalvik-cache directory %s: %s\", nameBuf, strerror(errno));\n            return NULL;\n        }\n    }\n    snprintf(nameBuf, kBufLen, \"%s/%s/%s\", dataRoot, kCacheDirectoryName, kInstructionSet);\n    if (strcmp(dataRoot, \"/data\") != 0) {\n        int result = dexOptMkdir(nameBuf, 0700);\n        if (result != 0 && errno != EEXIST) {\n            ALOGE(\"Failed to create dalvik-cache directory %s: %s\", nameBuf, strerror(errno));\n            return NULL;\n        }\n    }\n\n    /* Tack on the file name for the actual cache file path.\n     */\n    strncat(nameBuf, absoluteFile, kBufLen);\n\n    ALOGV(\"Cache file for '%s' '%s' is '%s'\", fileName, subFileName, nameBuf);\n    return strdup(nameBuf);\n}",
        "func": "char* dexOptGenerateCacheFileName(const char* fileName, const char* subFileName)\n{\n    char nameBuf[512];\n    char absoluteFile[sizeof(nameBuf)];\n    const size_t kBufLen = sizeof(nameBuf) - 1;\n    const char* dataRoot;\n    char* cp;\n\n    /*\n     * Get the absolute path of the Jar or DEX file.\n     */\n    absoluteFile[0] = '\\0';\n    if (fileName[0] != '/') {\n        /*\n         * Generate the absolute path.  This doesn't do everything it\n         * should, e.g. if filename is \"./out/whatever\" it doesn't crunch\n         * the leading \"./\" out, but it'll do.\n         */\n        if (getcwd(absoluteFile, kBufLen) == NULL) {\n            ALOGE(\"Can't get CWD while opening jar file\");\n            return NULL;\n        }\n        strncat(absoluteFile, \"/\", kBufLen - strlen(absoluteFile));\n    }\n    strncat(absoluteFile, fileName, kBufLen - strlen(absoluteFile));\n\n    /*\n     * Append the name of the Jar file entry, if any.  This is not currently\n     * required, but will be if we start putting more than one DEX file\n     * in a Jar.\n     */\n    if (subFileName != NULL) {\n        strncat(absoluteFile, \"/\", kBufLen - strlen(absoluteFile));\n        strncat(absoluteFile, subFileName, kBufLen - strlen(absoluteFile));\n    }\n\n    /* Turn the path into a flat filename by replacing\n     * any slashes after the first one with '@' characters.\n     */\n    cp = absoluteFile + 1;\n    while (*cp != '\\0') {\n        if (*cp == '/') {\n            *cp = '@';\n        }\n        cp++;\n    }\n\n    /* Build the name of the cache directory.\n     */\n    dataRoot = getenv(\"ANDROID_DATA\");\n    if (dataRoot == NULL)\n        dataRoot = \"/data\";\n    snprintf(nameBuf, kBufLen, \"%s/%s\", dataRoot, kCacheDirectoryName);\n    if (strcmp(dataRoot, \"/data\") != 0) {\n        int result = dexOptMkdir(nameBuf, 0700);\n        if (result != 0 && errno != EEXIST) {\n            ALOGE(\"Failed to create dalvik-cache directory %s: %s\", nameBuf, strerror(errno));\n            return NULL;\n        }\n    }\n    snprintf(nameBuf, kBufLen, \"%s/%s/%s\", dataRoot, kCacheDirectoryName, kInstructionSet);\n    if (strcmp(dataRoot, \"/data\") != 0) {\n        int result = dexOptMkdir(nameBuf, 0700);\n        if (result != 0 && errno != EEXIST) {\n            ALOGE(\"Failed to create dalvik-cache directory %s: %s\", nameBuf, strerror(errno));\n            return NULL;\n        }\n    }\n\n    /* Tack on the file name for the actual cache file path.\n     */\n    strncat(nameBuf, absoluteFile, kBufLen - strlen(nameBuf));\n\n    ALOGV(\"Cache file for '%s' '%s' is '%s'\", fileName, subFileName, nameBuf);\n    return strdup(nameBuf);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,9 +20,9 @@\n             ALOGE(\"Can't get CWD while opening jar file\");\n             return NULL;\n         }\n-        strncat(absoluteFile, \"/\", kBufLen);\n+        strncat(absoluteFile, \"/\", kBufLen - strlen(absoluteFile));\n     }\n-    strncat(absoluteFile, fileName, kBufLen);\n+    strncat(absoluteFile, fileName, kBufLen - strlen(absoluteFile));\n \n     /*\n      * Append the name of the Jar file entry, if any.  This is not currently\n@@ -30,8 +30,8 @@\n      * in a Jar.\n      */\n     if (subFileName != NULL) {\n-        strncat(absoluteFile, \"/\", kBufLen);\n-        strncat(absoluteFile, subFileName, kBufLen);\n+        strncat(absoluteFile, \"/\", kBufLen - strlen(absoluteFile));\n+        strncat(absoluteFile, subFileName, kBufLen - strlen(absoluteFile));\n     }\n \n     /* Turn the path into a flat filename by replacing\n@@ -69,7 +69,7 @@\n \n     /* Tack on the file name for the actual cache file path.\n      */\n-    strncat(nameBuf, absoluteFile, kBufLen);\n+    strncat(nameBuf, absoluteFile, kBufLen - strlen(nameBuf));\n \n     ALOGV(\"Cache file for '%s' '%s' is '%s'\", fileName, subFileName, nameBuf);\n     return strdup(nameBuf);",
        "diff_line_info": {
            "deleted_lines": [
                "        strncat(absoluteFile, \"/\", kBufLen);",
                "    strncat(absoluteFile, fileName, kBufLen);",
                "        strncat(absoluteFile, \"/\", kBufLen);",
                "        strncat(absoluteFile, subFileName, kBufLen);",
                "    strncat(nameBuf, absoluteFile, kBufLen);"
            ],
            "added_lines": [
                "        strncat(absoluteFile, \"/\", kBufLen - strlen(absoluteFile));",
                "    strncat(absoluteFile, fileName, kBufLen - strlen(absoluteFile));",
                "        strncat(absoluteFile, \"/\", kBufLen - strlen(absoluteFile));",
                "        strncat(absoluteFile, subFileName, kBufLen - strlen(absoluteFile));",
                "    strncat(nameBuf, absoluteFile, kBufLen - strlen(nameBuf));"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9870",
        "func_name": "torvalds/linux/arch_ptrace",
        "description": "The Linux kernel before 3.11 on ARM platforms, as used in Android before 2016-08-05 on Nexus 5 and 7 (2013) devices, does not properly consider user-space access to the TPIDRURW register, which allows local users to gain privileges via a crafted application, aka Android internal bug 28749743 and Qualcomm internal bug CR561044.",
        "git_url": "https://github.com/torvalds/linux/commit/a4780adeefd042482f624f5e0d577bf9cdcbb760",
        "commit_title": "ARM: 7735/2: Preserve the user r/w register TPIDRURW on context switch and fork",
        "commit_text": " Since commit 6a1c53124aa1 the user writeable TLS register was zeroed to prevent it from being used as a covert channel between two tasks.  There are more and more applications coming to Windows RT, Wine could support them, but mostly they expect to have the thread environment block (TEB) in TPIDRURW.  This patch preserves that register per thread instead of clearing it. Unlike the TPIDRURO, which is already switched, the TPIDRURW can be updated from userspace so needs careful treatment in the case that we modify TPIDRURW and call fork(). To avoid this we must always read TPIDRURW in copy_thread. ",
        "func_before": "long arch_ptrace(struct task_struct *child, long request,\n\t\t unsigned long addr, unsigned long data)\n{\n\tint ret;\n\tunsigned long __user *datap = (unsigned long __user *) data;\n\n\tswitch (request) {\n\t\tcase PTRACE_PEEKUSR:\n\t\t\tret = ptrace_read_user(child, addr, datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_POKEUSR:\n\t\t\tret = ptrace_write_user(child, addr, data);\n\t\t\tbreak;\n\n\t\tcase PTRACE_GETREGS:\n\t\t\tret = copy_regset_to_user(child,\n\t\t\t\t\t\t  &user_arm_view, REGSET_GPR,\n\t\t\t\t\t\t  0, sizeof(struct pt_regs),\n\t\t\t\t\t\t  datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETREGS:\n\t\t\tret = copy_regset_from_user(child,\n\t\t\t\t\t\t    &user_arm_view, REGSET_GPR,\n\t\t\t\t\t\t    0, sizeof(struct pt_regs),\n\t\t\t\t\t\t    datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_GETFPREGS:\n\t\t\tret = copy_regset_to_user(child,\n\t\t\t\t\t\t  &user_arm_view, REGSET_FPR,\n\t\t\t\t\t\t  0, sizeof(union fp_state),\n\t\t\t\t\t\t  datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETFPREGS:\n\t\t\tret = copy_regset_from_user(child,\n\t\t\t\t\t\t    &user_arm_view, REGSET_FPR,\n\t\t\t\t\t\t    0, sizeof(union fp_state),\n\t\t\t\t\t\t    datap);\n\t\t\tbreak;\n\n#ifdef CONFIG_IWMMXT\n\t\tcase PTRACE_GETWMMXREGS:\n\t\t\tret = ptrace_getwmmxregs(child, datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETWMMXREGS:\n\t\t\tret = ptrace_setwmmxregs(child, datap);\n\t\t\tbreak;\n#endif\n\n\t\tcase PTRACE_GET_THREAD_AREA:\n\t\t\tret = put_user(task_thread_info(child)->tp_value,\n\t\t\t\t       datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SET_SYSCALL:\n\t\t\ttask_thread_info(child)->syscall = data;\n\t\t\tret = 0;\n\t\t\tbreak;\n\n#ifdef CONFIG_CRUNCH\n\t\tcase PTRACE_GETCRUNCHREGS:\n\t\t\tret = ptrace_getcrunchregs(child, datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETCRUNCHREGS:\n\t\t\tret = ptrace_setcrunchregs(child, datap);\n\t\t\tbreak;\n#endif\n\n#ifdef CONFIG_VFP\n\t\tcase PTRACE_GETVFPREGS:\n\t\t\tret = copy_regset_to_user(child,\n\t\t\t\t\t\t  &user_arm_view, REGSET_VFP,\n\t\t\t\t\t\t  0, ARM_VFPREGS_SIZE,\n\t\t\t\t\t\t  datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETVFPREGS:\n\t\t\tret = copy_regset_from_user(child,\n\t\t\t\t\t\t    &user_arm_view, REGSET_VFP,\n\t\t\t\t\t\t    0, ARM_VFPREGS_SIZE,\n\t\t\t\t\t\t    datap);\n\t\t\tbreak;\n#endif\n\n#ifdef CONFIG_HAVE_HW_BREAKPOINT\n\t\tcase PTRACE_GETHBPREGS:\n\t\t\tif (ptrace_get_breakpoints(child) < 0)\n\t\t\t\treturn -ESRCH;\n\n\t\t\tret = ptrace_gethbpregs(child, addr,\n\t\t\t\t\t\t(unsigned long __user *)data);\n\t\t\tptrace_put_breakpoints(child);\n\t\t\tbreak;\n\t\tcase PTRACE_SETHBPREGS:\n\t\t\tif (ptrace_get_breakpoints(child) < 0)\n\t\t\t\treturn -ESRCH;\n\n\t\t\tret = ptrace_sethbpregs(child, addr,\n\t\t\t\t\t\t(unsigned long __user *)data);\n\t\t\tptrace_put_breakpoints(child);\n\t\t\tbreak;\n#endif\n\n\t\tdefault:\n\t\t\tret = ptrace_request(child, request, addr, data);\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}",
        "func": "long arch_ptrace(struct task_struct *child, long request,\n\t\t unsigned long addr, unsigned long data)\n{\n\tint ret;\n\tunsigned long __user *datap = (unsigned long __user *) data;\n\n\tswitch (request) {\n\t\tcase PTRACE_PEEKUSR:\n\t\t\tret = ptrace_read_user(child, addr, datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_POKEUSR:\n\t\t\tret = ptrace_write_user(child, addr, data);\n\t\t\tbreak;\n\n\t\tcase PTRACE_GETREGS:\n\t\t\tret = copy_regset_to_user(child,\n\t\t\t\t\t\t  &user_arm_view, REGSET_GPR,\n\t\t\t\t\t\t  0, sizeof(struct pt_regs),\n\t\t\t\t\t\t  datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETREGS:\n\t\t\tret = copy_regset_from_user(child,\n\t\t\t\t\t\t    &user_arm_view, REGSET_GPR,\n\t\t\t\t\t\t    0, sizeof(struct pt_regs),\n\t\t\t\t\t\t    datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_GETFPREGS:\n\t\t\tret = copy_regset_to_user(child,\n\t\t\t\t\t\t  &user_arm_view, REGSET_FPR,\n\t\t\t\t\t\t  0, sizeof(union fp_state),\n\t\t\t\t\t\t  datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETFPREGS:\n\t\t\tret = copy_regset_from_user(child,\n\t\t\t\t\t\t    &user_arm_view, REGSET_FPR,\n\t\t\t\t\t\t    0, sizeof(union fp_state),\n\t\t\t\t\t\t    datap);\n\t\t\tbreak;\n\n#ifdef CONFIG_IWMMXT\n\t\tcase PTRACE_GETWMMXREGS:\n\t\t\tret = ptrace_getwmmxregs(child, datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETWMMXREGS:\n\t\t\tret = ptrace_setwmmxregs(child, datap);\n\t\t\tbreak;\n#endif\n\n\t\tcase PTRACE_GET_THREAD_AREA:\n\t\t\tret = put_user(task_thread_info(child)->tp_value[0],\n\t\t\t\t       datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SET_SYSCALL:\n\t\t\ttask_thread_info(child)->syscall = data;\n\t\t\tret = 0;\n\t\t\tbreak;\n\n#ifdef CONFIG_CRUNCH\n\t\tcase PTRACE_GETCRUNCHREGS:\n\t\t\tret = ptrace_getcrunchregs(child, datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETCRUNCHREGS:\n\t\t\tret = ptrace_setcrunchregs(child, datap);\n\t\t\tbreak;\n#endif\n\n#ifdef CONFIG_VFP\n\t\tcase PTRACE_GETVFPREGS:\n\t\t\tret = copy_regset_to_user(child,\n\t\t\t\t\t\t  &user_arm_view, REGSET_VFP,\n\t\t\t\t\t\t  0, ARM_VFPREGS_SIZE,\n\t\t\t\t\t\t  datap);\n\t\t\tbreak;\n\n\t\tcase PTRACE_SETVFPREGS:\n\t\t\tret = copy_regset_from_user(child,\n\t\t\t\t\t\t    &user_arm_view, REGSET_VFP,\n\t\t\t\t\t\t    0, ARM_VFPREGS_SIZE,\n\t\t\t\t\t\t    datap);\n\t\t\tbreak;\n#endif\n\n#ifdef CONFIG_HAVE_HW_BREAKPOINT\n\t\tcase PTRACE_GETHBPREGS:\n\t\t\tif (ptrace_get_breakpoints(child) < 0)\n\t\t\t\treturn -ESRCH;\n\n\t\t\tret = ptrace_gethbpregs(child, addr,\n\t\t\t\t\t\t(unsigned long __user *)data);\n\t\t\tptrace_put_breakpoints(child);\n\t\t\tbreak;\n\t\tcase PTRACE_SETHBPREGS:\n\t\t\tif (ptrace_get_breakpoints(child) < 0)\n\t\t\t\treturn -ESRCH;\n\n\t\t\tret = ptrace_sethbpregs(child, addr,\n\t\t\t\t\t\t(unsigned long __user *)data);\n\t\t\tptrace_put_breakpoints(child);\n\t\t\tbreak;\n#endif\n\n\t\tdefault:\n\t\t\tret = ptrace_request(child, request, addr, data);\n\t\t\tbreak;\n\t}\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -52,7 +52,7 @@\n #endif\n \n \t\tcase PTRACE_GET_THREAD_AREA:\n-\t\t\tret = put_user(task_thread_info(child)->tp_value,\n+\t\t\tret = put_user(task_thread_info(child)->tp_value[0],\n \t\t\t\t       datap);\n \t\t\tbreak;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tret = put_user(task_thread_info(child)->tp_value,"
            ],
            "added_lines": [
                "\t\t\tret = put_user(task_thread_info(child)->tp_value[0],"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9870",
        "func_name": "torvalds/linux/copy_thread",
        "description": "The Linux kernel before 3.11 on ARM platforms, as used in Android before 2016-08-05 on Nexus 5 and 7 (2013) devices, does not properly consider user-space access to the TPIDRURW register, which allows local users to gain privileges via a crafted application, aka Android internal bug 28749743 and Qualcomm internal bug CR561044.",
        "git_url": "https://github.com/torvalds/linux/commit/a4780adeefd042482f624f5e0d577bf9cdcbb760",
        "commit_title": "ARM: 7735/2: Preserve the user r/w register TPIDRURW on context switch and fork",
        "commit_text": " Since commit 6a1c53124aa1 the user writeable TLS register was zeroed to prevent it from being used as a covert channel between two tasks.  There are more and more applications coming to Windows RT, Wine could support them, but mostly they expect to have the thread environment block (TEB) in TPIDRURW.  This patch preserves that register per thread instead of clearing it. Unlike the TPIDRURO, which is already switched, the TPIDRURW can be updated from userspace so needs careful treatment in the case that we modify TPIDRURW and call fork(). To avoid this we must always read TPIDRURW in copy_thread. ",
        "func_before": "int\ncopy_thread(unsigned long clone_flags, unsigned long stack_start,\n\t    unsigned long stk_sz, struct task_struct *p)\n{\n\tstruct thread_info *thread = task_thread_info(p);\n\tstruct pt_regs *childregs = task_pt_regs(p);\n\n\tmemset(&thread->cpu_context, 0, sizeof(struct cpu_context_save));\n\n\tif (likely(!(p->flags & PF_KTHREAD))) {\n\t\t*childregs = *current_pt_regs();\n\t\tchildregs->ARM_r0 = 0;\n\t\tif (stack_start)\n\t\t\tchildregs->ARM_sp = stack_start;\n\t} else {\n\t\tmemset(childregs, 0, sizeof(struct pt_regs));\n\t\tthread->cpu_context.r4 = stk_sz;\n\t\tthread->cpu_context.r5 = stack_start;\n\t\tchildregs->ARM_cpsr = SVC_MODE;\n\t}\n\tthread->cpu_context.pc = (unsigned long)ret_from_fork;\n\tthread->cpu_context.sp = (unsigned long)childregs;\n\n\tclear_ptrace_hw_breakpoint(p);\n\n\tif (clone_flags & CLONE_SETTLS)\n\t\tthread->tp_value = childregs->ARM_r3;\n\n\tthread_notify(THREAD_NOTIFY_COPY, thread);\n\n\treturn 0;\n}",
        "func": "int\ncopy_thread(unsigned long clone_flags, unsigned long stack_start,\n\t    unsigned long stk_sz, struct task_struct *p)\n{\n\tstruct thread_info *thread = task_thread_info(p);\n\tstruct pt_regs *childregs = task_pt_regs(p);\n\n\tmemset(&thread->cpu_context, 0, sizeof(struct cpu_context_save));\n\n\tif (likely(!(p->flags & PF_KTHREAD))) {\n\t\t*childregs = *current_pt_regs();\n\t\tchildregs->ARM_r0 = 0;\n\t\tif (stack_start)\n\t\t\tchildregs->ARM_sp = stack_start;\n\t} else {\n\t\tmemset(childregs, 0, sizeof(struct pt_regs));\n\t\tthread->cpu_context.r4 = stk_sz;\n\t\tthread->cpu_context.r5 = stack_start;\n\t\tchildregs->ARM_cpsr = SVC_MODE;\n\t}\n\tthread->cpu_context.pc = (unsigned long)ret_from_fork;\n\tthread->cpu_context.sp = (unsigned long)childregs;\n\n\tclear_ptrace_hw_breakpoint(p);\n\n\tif (clone_flags & CLONE_SETTLS)\n\t\tthread->tp_value[0] = childregs->ARM_r3;\n\tthread->tp_value[1] = get_tpuser();\n\n\tthread_notify(THREAD_NOTIFY_COPY, thread);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,7 +24,8 @@\n \tclear_ptrace_hw_breakpoint(p);\n \n \tif (clone_flags & CLONE_SETTLS)\n-\t\tthread->tp_value = childregs->ARM_r3;\n+\t\tthread->tp_value[0] = childregs->ARM_r3;\n+\tthread->tp_value[1] = get_tpuser();\n \n \tthread_notify(THREAD_NOTIFY_COPY, thread);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tthread->tp_value = childregs->ARM_r3;"
            ],
            "added_lines": [
                "\t\tthread->tp_value[0] = childregs->ARM_r3;",
                "\tthread->tp_value[1] = get_tpuser();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9870",
        "func_name": "torvalds/linux/get_tp_trap",
        "description": "The Linux kernel before 3.11 on ARM platforms, as used in Android before 2016-08-05 on Nexus 5 and 7 (2013) devices, does not properly consider user-space access to the TPIDRURW register, which allows local users to gain privileges via a crafted application, aka Android internal bug 28749743 and Qualcomm internal bug CR561044.",
        "git_url": "https://github.com/torvalds/linux/commit/a4780adeefd042482f624f5e0d577bf9cdcbb760",
        "commit_title": "ARM: 7735/2: Preserve the user r/w register TPIDRURW on context switch and fork",
        "commit_text": " Since commit 6a1c53124aa1 the user writeable TLS register was zeroed to prevent it from being used as a covert channel between two tasks.  There are more and more applications coming to Windows RT, Wine could support them, but mostly they expect to have the thread environment block (TEB) in TPIDRURW.  This patch preserves that register per thread instead of clearing it. Unlike the TPIDRURO, which is already switched, the TPIDRURW can be updated from userspace so needs careful treatment in the case that we modify TPIDRURW and call fork(). To avoid this we must always read TPIDRURW in copy_thread. ",
        "func_before": "static int get_tp_trap(struct pt_regs *regs, unsigned int instr)\n{\n\tint reg = (instr >> 12) & 15;\n\tif (reg == 15)\n\t\treturn 1;\n\tregs->uregs[reg] = current_thread_info()->tp_value;\n\tregs->ARM_pc += 4;\n\treturn 0;\n}",
        "func": "static int get_tp_trap(struct pt_regs *regs, unsigned int instr)\n{\n\tint reg = (instr >> 12) & 15;\n\tif (reg == 15)\n\t\treturn 1;\n\tregs->uregs[reg] = current_thread_info()->tp_value[0];\n\tregs->ARM_pc += 4;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,7 @@\n \tint reg = (instr >> 12) & 15;\n \tif (reg == 15)\n \t\treturn 1;\n-\tregs->uregs[reg] = current_thread_info()->tp_value;\n+\tregs->uregs[reg] = current_thread_info()->tp_value[0];\n \tregs->ARM_pc += 4;\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tregs->uregs[reg] = current_thread_info()->tp_value;"
            ],
            "added_lines": [
                "\tregs->uregs[reg] = current_thread_info()->tp_value[0];"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9870",
        "func_name": "torvalds/linux/arm_syscall",
        "description": "The Linux kernel before 3.11 on ARM platforms, as used in Android before 2016-08-05 on Nexus 5 and 7 (2013) devices, does not properly consider user-space access to the TPIDRURW register, which allows local users to gain privileges via a crafted application, aka Android internal bug 28749743 and Qualcomm internal bug CR561044.",
        "git_url": "https://github.com/torvalds/linux/commit/a4780adeefd042482f624f5e0d577bf9cdcbb760",
        "commit_title": "ARM: 7735/2: Preserve the user r/w register TPIDRURW on context switch and fork",
        "commit_text": " Since commit 6a1c53124aa1 the user writeable TLS register was zeroed to prevent it from being used as a covert channel between two tasks.  There are more and more applications coming to Windows RT, Wine could support them, but mostly they expect to have the thread environment block (TEB) in TPIDRURW.  This patch preserves that register per thread instead of clearing it. Unlike the TPIDRURO, which is already switched, the TPIDRURW can be updated from userspace so needs careful treatment in the case that we modify TPIDRURW and call fork(). To avoid this we must always read TPIDRURW in copy_thread. ",
        "func_before": "asmlinkage int arm_syscall(int no, struct pt_regs *regs)\n{\n\tstruct thread_info *thread = current_thread_info();\n\tsiginfo_t info;\n\n\tif ((no >> 16) != (__ARM_NR_BASE>> 16))\n\t\treturn bad_syscall(no, regs);\n\n\tswitch (no & 0xffff) {\n\tcase 0: /* branch through 0 */\n\t\tinfo.si_signo = SIGSEGV;\n\t\tinfo.si_errno = 0;\n\t\tinfo.si_code  = SEGV_MAPERR;\n\t\tinfo.si_addr  = NULL;\n\n\t\tarm_notify_die(\"branch through zero\", regs, &info, 0, 0);\n\t\treturn 0;\n\n\tcase NR(breakpoint): /* SWI BREAK_POINT */\n\t\tregs->ARM_pc -= thumb_mode(regs) ? 2 : 4;\n\t\tptrace_break(current, regs);\n\t\treturn regs->ARM_r0;\n\n\t/*\n\t * Flush a region from virtual address 'r0' to virtual address 'r1'\n\t * _exclusive_.  There is no alignment requirement on either address;\n\t * user space does not need to know the hardware cache layout.\n\t *\n\t * r2 contains flags.  It should ALWAYS be passed as ZERO until it\n\t * is defined to be something else.  For now we ignore it, but may\n\t * the fires of hell burn in your belly if you break this rule. ;)\n\t *\n\t * (at a later date, we may want to allow this call to not flush\n\t * various aspects of the cache.  Passing '0' will guarantee that\n\t * everything necessary gets flushed to maintain consistency in\n\t * the specified region).\n\t */\n\tcase NR(cacheflush):\n\t\treturn do_cache_op(regs->ARM_r0, regs->ARM_r1, regs->ARM_r2);\n\n\tcase NR(usr26):\n\t\tif (!(elf_hwcap & HWCAP_26BIT))\n\t\t\tbreak;\n\t\tregs->ARM_cpsr &= ~MODE32_BIT;\n\t\treturn regs->ARM_r0;\n\n\tcase NR(usr32):\n\t\tif (!(elf_hwcap & HWCAP_26BIT))\n\t\t\tbreak;\n\t\tregs->ARM_cpsr |= MODE32_BIT;\n\t\treturn regs->ARM_r0;\n\n\tcase NR(set_tls):\n\t\tthread->tp_value = regs->ARM_r0;\n\t\tif (tls_emu)\n\t\t\treturn 0;\n\t\tif (has_tls_reg) {\n\t\t\tasm (\"mcr p15, 0, %0, c13, c0, 3\"\n\t\t\t\t: : \"r\" (regs->ARM_r0));\n\t\t} else {\n\t\t\t/*\n\t\t\t * User space must never try to access this directly.\n\t\t\t * Expect your app to break eventually if you do so.\n\t\t\t * The user helper at 0xffff0fe0 must be used instead.\n\t\t\t * (see entry-armv.S for details)\n\t\t\t */\n\t\t\t*((unsigned int *)0xffff0ff0) = regs->ARM_r0;\n\t\t}\n\t\treturn 0;\n\n#ifdef CONFIG_NEEDS_SYSCALL_FOR_CMPXCHG\n\t/*\n\t * Atomically store r1 in *r2 if *r2 is equal to r0 for user space.\n\t * Return zero in r0 if *MEM was changed or non-zero if no exchange\n\t * happened.  Also set the user C flag accordingly.\n\t * If access permissions have to be fixed up then non-zero is\n\t * returned and the operation has to be re-attempted.\n\t *\n\t * *NOTE*: This is a ghost syscall private to the kernel.  Only the\n\t * __kuser_cmpxchg code in entry-armv.S should be aware of its\n\t * existence.  Don't ever use this from user code.\n\t */\n\tcase NR(cmpxchg):\n\tfor (;;) {\n\t\textern void do_DataAbort(unsigned long addr, unsigned int fsr,\n\t\t\t\t\t struct pt_regs *regs);\n\t\tunsigned long val;\n\t\tunsigned long addr = regs->ARM_r2;\n\t\tstruct mm_struct *mm = current->mm;\n\t\tpgd_t *pgd; pmd_t *pmd; pte_t *pte;\n\t\tspinlock_t *ptl;\n\n\t\tregs->ARM_cpsr &= ~PSR_C_BIT;\n\t\tdown_read(&mm->mmap_sem);\n\t\tpgd = pgd_offset(mm, addr);\n\t\tif (!pgd_present(*pgd))\n\t\t\tgoto bad_access;\n\t\tpmd = pmd_offset(pgd, addr);\n\t\tif (!pmd_present(*pmd))\n\t\t\tgoto bad_access;\n\t\tpte = pte_offset_map_lock(mm, pmd, addr, &ptl);\n\t\tif (!pte_present(*pte) || !pte_write(*pte) || !pte_dirty(*pte)) {\n\t\t\tpte_unmap_unlock(pte, ptl);\n\t\t\tgoto bad_access;\n\t\t}\n\t\tval = *(unsigned long *)addr;\n\t\tval -= regs->ARM_r0;\n\t\tif (val == 0) {\n\t\t\t*(unsigned long *)addr = regs->ARM_r1;\n\t\t\tregs->ARM_cpsr |= PSR_C_BIT;\n\t\t}\n\t\tpte_unmap_unlock(pte, ptl);\n\t\tup_read(&mm->mmap_sem);\n\t\treturn val;\n\n\t\tbad_access:\n\t\tup_read(&mm->mmap_sem);\n\t\t/* simulate a write access fault */\n\t\tdo_DataAbort(addr, 15 + (1 << 11), regs);\n\t}\n#endif\n\n\tdefault:\n\t\t/* Calls 9f00xx..9f07ff are defined to return -ENOSYS\n\t\t   if not implemented, rather than raising SIGILL.  This\n\t\t   way the calling program can gracefully determine whether\n\t\t   a feature is supported.  */\n\t\tif ((no & 0xffff) <= 0x7ff)\n\t\t\treturn -ENOSYS;\n\t\tbreak;\n\t}\n#ifdef CONFIG_DEBUG_USER\n\t/*\n\t * experience shows that these seem to indicate that\n\t * something catastrophic has happened\n\t */\n\tif (user_debug & UDBG_SYSCALL) {\n\t\tprintk(\"[%d] %s: arm syscall %d\\n\",\n\t\t       task_pid_nr(current), current->comm, no);\n\t\tdump_instr(\"\", regs);\n\t\tif (user_mode(regs)) {\n\t\t\t__show_regs(regs);\n\t\t\tc_backtrace(regs->ARM_fp, processor_mode(regs));\n\t\t}\n\t}\n#endif\n\tinfo.si_signo = SIGILL;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = ILL_ILLTRP;\n\tinfo.si_addr  = (void __user *)instruction_pointer(regs) -\n\t\t\t (thumb_mode(regs) ? 2 : 4);\n\n\tarm_notify_die(\"Oops - bad syscall(2)\", regs, &info, no, 0);\n\treturn 0;\n}",
        "func": "asmlinkage int arm_syscall(int no, struct pt_regs *regs)\n{\n\tstruct thread_info *thread = current_thread_info();\n\tsiginfo_t info;\n\n\tif ((no >> 16) != (__ARM_NR_BASE>> 16))\n\t\treturn bad_syscall(no, regs);\n\n\tswitch (no & 0xffff) {\n\tcase 0: /* branch through 0 */\n\t\tinfo.si_signo = SIGSEGV;\n\t\tinfo.si_errno = 0;\n\t\tinfo.si_code  = SEGV_MAPERR;\n\t\tinfo.si_addr  = NULL;\n\n\t\tarm_notify_die(\"branch through zero\", regs, &info, 0, 0);\n\t\treturn 0;\n\n\tcase NR(breakpoint): /* SWI BREAK_POINT */\n\t\tregs->ARM_pc -= thumb_mode(regs) ? 2 : 4;\n\t\tptrace_break(current, regs);\n\t\treturn regs->ARM_r0;\n\n\t/*\n\t * Flush a region from virtual address 'r0' to virtual address 'r1'\n\t * _exclusive_.  There is no alignment requirement on either address;\n\t * user space does not need to know the hardware cache layout.\n\t *\n\t * r2 contains flags.  It should ALWAYS be passed as ZERO until it\n\t * is defined to be something else.  For now we ignore it, but may\n\t * the fires of hell burn in your belly if you break this rule. ;)\n\t *\n\t * (at a later date, we may want to allow this call to not flush\n\t * various aspects of the cache.  Passing '0' will guarantee that\n\t * everything necessary gets flushed to maintain consistency in\n\t * the specified region).\n\t */\n\tcase NR(cacheflush):\n\t\treturn do_cache_op(regs->ARM_r0, regs->ARM_r1, regs->ARM_r2);\n\n\tcase NR(usr26):\n\t\tif (!(elf_hwcap & HWCAP_26BIT))\n\t\t\tbreak;\n\t\tregs->ARM_cpsr &= ~MODE32_BIT;\n\t\treturn regs->ARM_r0;\n\n\tcase NR(usr32):\n\t\tif (!(elf_hwcap & HWCAP_26BIT))\n\t\t\tbreak;\n\t\tregs->ARM_cpsr |= MODE32_BIT;\n\t\treturn regs->ARM_r0;\n\n\tcase NR(set_tls):\n\t\tthread->tp_value[0] = regs->ARM_r0;\n\t\tif (tls_emu)\n\t\t\treturn 0;\n\t\tif (has_tls_reg) {\n\t\t\tasm (\"mcr p15, 0, %0, c13, c0, 3\"\n\t\t\t\t: : \"r\" (regs->ARM_r0));\n\t\t} else {\n\t\t\t/*\n\t\t\t * User space must never try to access this directly.\n\t\t\t * Expect your app to break eventually if you do so.\n\t\t\t * The user helper at 0xffff0fe0 must be used instead.\n\t\t\t * (see entry-armv.S for details)\n\t\t\t */\n\t\t\t*((unsigned int *)0xffff0ff0) = regs->ARM_r0;\n\t\t}\n\t\treturn 0;\n\n#ifdef CONFIG_NEEDS_SYSCALL_FOR_CMPXCHG\n\t/*\n\t * Atomically store r1 in *r2 if *r2 is equal to r0 for user space.\n\t * Return zero in r0 if *MEM was changed or non-zero if no exchange\n\t * happened.  Also set the user C flag accordingly.\n\t * If access permissions have to be fixed up then non-zero is\n\t * returned and the operation has to be re-attempted.\n\t *\n\t * *NOTE*: This is a ghost syscall private to the kernel.  Only the\n\t * __kuser_cmpxchg code in entry-armv.S should be aware of its\n\t * existence.  Don't ever use this from user code.\n\t */\n\tcase NR(cmpxchg):\n\tfor (;;) {\n\t\textern void do_DataAbort(unsigned long addr, unsigned int fsr,\n\t\t\t\t\t struct pt_regs *regs);\n\t\tunsigned long val;\n\t\tunsigned long addr = regs->ARM_r2;\n\t\tstruct mm_struct *mm = current->mm;\n\t\tpgd_t *pgd; pmd_t *pmd; pte_t *pte;\n\t\tspinlock_t *ptl;\n\n\t\tregs->ARM_cpsr &= ~PSR_C_BIT;\n\t\tdown_read(&mm->mmap_sem);\n\t\tpgd = pgd_offset(mm, addr);\n\t\tif (!pgd_present(*pgd))\n\t\t\tgoto bad_access;\n\t\tpmd = pmd_offset(pgd, addr);\n\t\tif (!pmd_present(*pmd))\n\t\t\tgoto bad_access;\n\t\tpte = pte_offset_map_lock(mm, pmd, addr, &ptl);\n\t\tif (!pte_present(*pte) || !pte_write(*pte) || !pte_dirty(*pte)) {\n\t\t\tpte_unmap_unlock(pte, ptl);\n\t\t\tgoto bad_access;\n\t\t}\n\t\tval = *(unsigned long *)addr;\n\t\tval -= regs->ARM_r0;\n\t\tif (val == 0) {\n\t\t\t*(unsigned long *)addr = regs->ARM_r1;\n\t\t\tregs->ARM_cpsr |= PSR_C_BIT;\n\t\t}\n\t\tpte_unmap_unlock(pte, ptl);\n\t\tup_read(&mm->mmap_sem);\n\t\treturn val;\n\n\t\tbad_access:\n\t\tup_read(&mm->mmap_sem);\n\t\t/* simulate a write access fault */\n\t\tdo_DataAbort(addr, 15 + (1 << 11), regs);\n\t}\n#endif\n\n\tdefault:\n\t\t/* Calls 9f00xx..9f07ff are defined to return -ENOSYS\n\t\t   if not implemented, rather than raising SIGILL.  This\n\t\t   way the calling program can gracefully determine whether\n\t\t   a feature is supported.  */\n\t\tif ((no & 0xffff) <= 0x7ff)\n\t\t\treturn -ENOSYS;\n\t\tbreak;\n\t}\n#ifdef CONFIG_DEBUG_USER\n\t/*\n\t * experience shows that these seem to indicate that\n\t * something catastrophic has happened\n\t */\n\tif (user_debug & UDBG_SYSCALL) {\n\t\tprintk(\"[%d] %s: arm syscall %d\\n\",\n\t\t       task_pid_nr(current), current->comm, no);\n\t\tdump_instr(\"\", regs);\n\t\tif (user_mode(regs)) {\n\t\t\t__show_regs(regs);\n\t\t\tc_backtrace(regs->ARM_fp, processor_mode(regs));\n\t\t}\n\t}\n#endif\n\tinfo.si_signo = SIGILL;\n\tinfo.si_errno = 0;\n\tinfo.si_code  = ILL_ILLTRP;\n\tinfo.si_addr  = (void __user *)instruction_pointer(regs) -\n\t\t\t (thumb_mode(regs) ? 2 : 4);\n\n\tarm_notify_die(\"Oops - bad syscall(2)\", regs, &info, no, 0);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -51,7 +51,7 @@\n \t\treturn regs->ARM_r0;\n \n \tcase NR(set_tls):\n-\t\tthread->tp_value = regs->ARM_r0;\n+\t\tthread->tp_value[0] = regs->ARM_r0;\n \t\tif (tls_emu)\n \t\t\treturn 0;\n \t\tif (has_tls_reg) {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tthread->tp_value = regs->ARM_r0;"
            ],
            "added_lines": [
                "\t\tthread->tp_value[0] = regs->ARM_r0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9888",
        "func_name": "torvalds/linux/arm_coherent_dma_alloc",
        "description": "arch/arm/mm/dma-mapping.c in the Linux kernel before 3.13 on ARM platforms, as used in Android before 2016-08-05 on Nexus 5 and 7 (2013) devices, does not prevent executable DMA mappings, which might allow local users to gain privileges via a crafted application, aka Android internal bug 28803642 and Qualcomm internal bug CR642735.",
        "git_url": "https://github.com/torvalds/linux/commit/0ea1ec713f04bdfac343c9702b21cd3a7c711826",
        "commit_title": "ARM: dma-mapping: don't allow DMA mappings to be marked executable",
        "commit_text": " DMA mapping permissions were being derived from pgprot_kernel directly without using PAGE_KERNEL.  This causes them to be marked with executable permission, which is not what we want.  Fix this. ",
        "func_before": "static void *arm_coherent_dma_alloc(struct device *dev, size_t size,\n\tdma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)\n{\n\tpgprot_t prot = __get_dma_pgprot(attrs, pgprot_kernel);\n\tvoid *memory;\n\n\tif (dma_alloc_from_coherent(dev, size, handle, &memory))\n\t\treturn memory;\n\n\treturn __dma_alloc(dev, size, handle, gfp, prot, true,\n\t\t\t   __builtin_return_address(0));\n}",
        "func": "static void *arm_coherent_dma_alloc(struct device *dev, size_t size,\n\tdma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)\n{\n\tpgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);\n\tvoid *memory;\n\n\tif (dma_alloc_from_coherent(dev, size, handle, &memory))\n\t\treturn memory;\n\n\treturn __dma_alloc(dev, size, handle, gfp, prot, true,\n\t\t\t   __builtin_return_address(0));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static void *arm_coherent_dma_alloc(struct device *dev, size_t size,\n \tdma_addr_t *handle, gfp_t gfp, struct dma_attrs *attrs)\n {\n-\tpgprot_t prot = __get_dma_pgprot(attrs, pgprot_kernel);\n+\tpgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);\n \tvoid *memory;\n \n \tif (dma_alloc_from_coherent(dev, size, handle, &memory))",
        "diff_line_info": {
            "deleted_lines": [
                "\tpgprot_t prot = __get_dma_pgprot(attrs, pgprot_kernel);"
            ],
            "added_lines": [
                "\tpgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9888",
        "func_name": "torvalds/linux/arm_dma_alloc",
        "description": "arch/arm/mm/dma-mapping.c in the Linux kernel before 3.13 on ARM platforms, as used in Android before 2016-08-05 on Nexus 5 and 7 (2013) devices, does not prevent executable DMA mappings, which might allow local users to gain privileges via a crafted application, aka Android internal bug 28803642 and Qualcomm internal bug CR642735.",
        "git_url": "https://github.com/torvalds/linux/commit/0ea1ec713f04bdfac343c9702b21cd3a7c711826",
        "commit_title": "ARM: dma-mapping: don't allow DMA mappings to be marked executable",
        "commit_text": " DMA mapping permissions were being derived from pgprot_kernel directly without using PAGE_KERNEL.  This causes them to be marked with executable permission, which is not what we want.  Fix this. ",
        "func_before": "void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,\n\t\t    gfp_t gfp, struct dma_attrs *attrs)\n{\n\tpgprot_t prot = __get_dma_pgprot(attrs, pgprot_kernel);\n\tvoid *memory;\n\n\tif (dma_alloc_from_coherent(dev, size, handle, &memory))\n\t\treturn memory;\n\n\treturn __dma_alloc(dev, size, handle, gfp, prot, false,\n\t\t\t   __builtin_return_address(0));\n}",
        "func": "void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,\n\t\t    gfp_t gfp, struct dma_attrs *attrs)\n{\n\tpgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);\n\tvoid *memory;\n\n\tif (dma_alloc_from_coherent(dev, size, handle, &memory))\n\t\treturn memory;\n\n\treturn __dma_alloc(dev, size, handle, gfp, prot, false,\n\t\t\t   __builtin_return_address(0));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n void *arm_dma_alloc(struct device *dev, size_t size, dma_addr_t *handle,\n \t\t    gfp_t gfp, struct dma_attrs *attrs)\n {\n-\tpgprot_t prot = __get_dma_pgprot(attrs, pgprot_kernel);\n+\tpgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);\n \tvoid *memory;\n \n \tif (dma_alloc_from_coherent(dev, size, handle, &memory))",
        "diff_line_info": {
            "deleted_lines": [
                "\tpgprot_t prot = __get_dma_pgprot(attrs, pgprot_kernel);"
            ],
            "added_lines": [
                "\tpgprot_t prot = __get_dma_pgprot(attrs, PAGE_KERNEL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6187",
        "func_name": "torvalds/linux/apparmor_setprocattr",
        "description": "The apparmor_setprocattr function in security/apparmor/lsm.c in the Linux kernel before 4.6.5 does not validate the buffer size, which allows local users to gain privileges by triggering an AppArmor setprocattr hook.",
        "git_url": "https://github.com/torvalds/linux/commit/30a46a4647fd1df9cf52e43bf467f0d9265096ca",
        "commit_title": "apparmor: fix oops, validate buffer size in apparmor_setprocattr()",
        "commit_text": " When proc_pid_attr_write() was changed to use memdup_user apparmor's (interface violating) assumption that the setprocattr buffer was always a single page was violated.  The size test is not strictly speaking needed as proc_pid_attr_write() will reject anything larger, but for the sake of robustness we can keep it in.  SMACK and SELinux look safe to me, but somebody else should probably have a look just in case.  Based on original patch from Vegard Nossum <vegard.nossum@oracle.com> modified for the case that apparmor provides null termination.  Cc: Al Viro <viro@zeniv.linux.org.uk> Cc: John Johansen <john.johansen@canonical.com> Cc: Paul Moore <paul@paul-moore.com> Cc: Stephen Smalley <sds@tycho.nsa.gov> Cc: Eric Paris <eparis@parisplace.org> Cc: Casey Schaufler <casey@schaufler-ca.com> Cc: stable@kernel.org",
        "func_before": "static int apparmor_setprocattr(struct task_struct *task, char *name,\n\t\t\t\tvoid *value, size_t size)\n{\n\tstruct common_audit_data sa;\n\tstruct apparmor_audit_data aad = {0,};\n\tchar *command, *args = value;\n\tsize_t arg_size;\n\tint error;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\t/* args points to a PAGE_SIZE buffer, AppArmor requires that\n\t * the buffer must be null terminated or have size <= PAGE_SIZE -1\n\t * so that AppArmor can null terminate them\n\t */\n\tif (args[size - 1] != '\\0') {\n\t\tif (size == PAGE_SIZE)\n\t\t\treturn -EINVAL;\n\t\targs[size] = '\\0';\n\t}\n\n\t/* task can only write its own attributes */\n\tif (current != task)\n\t\treturn -EACCES;\n\n\targs = value;\n\targs = strim(args);\n\tcommand = strsep(&args, \" \");\n\tif (!args)\n\t\treturn -EINVAL;\n\targs = skip_spaces(args);\n\tif (!*args)\n\t\treturn -EINVAL;\n\n\targ_size = size - (args - (char *) value);\n\tif (strcmp(name, \"current\") == 0) {\n\t\tif (strcmp(command, \"changehat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permhat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t AA_DO_TEST);\n\t\t} else if (strcmp(command, \"changeprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     AA_DO_TEST);\n\t\t} else\n\t\t\tgoto fail;\n\t} else if (strcmp(name, \"exec\") == 0) {\n\t\tif (strcmp(command, \"exec\") == 0)\n\t\t\terror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\telse\n\t\t\tgoto fail;\n\t} else\n\t\t/* only support the \"current\" and \"exec\" process attributes */\n\t\treturn -EINVAL;\n\n\tif (!error)\n\t\terror = size;\n\treturn error;\n\nfail:\n\tsa.type = LSM_AUDIT_DATA_NONE;\n\tsa.aad = &aad;\n\taad.profile = aa_current_profile();\n\taad.op = OP_SETPROCATTR;\n\taad.info = name;\n\taad.error = -EINVAL;\n\taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n\treturn -EINVAL;\n}",
        "func": "static int apparmor_setprocattr(struct task_struct *task, char *name,\n\t\t\t\tvoid *value, size_t size)\n{\n\tstruct common_audit_data sa;\n\tstruct apparmor_audit_data aad = {0,};\n\tchar *command, *largs = NULL, *args = value;\n\tsize_t arg_size;\n\tint error;\n\n\tif (size == 0)\n\t\treturn -EINVAL;\n\t/* task can only write its own attributes */\n\tif (current != task)\n\t\treturn -EACCES;\n\n\t/* AppArmor requires that the buffer must be null terminated atm */\n\tif (args[size - 1] != '\\0') {\n\t\t/* null terminate */\n\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);\n\t\tif (!args)\n\t\t\treturn -ENOMEM;\n\t\tmemcpy(args, value, size);\n\t\targs[size] = '\\0';\n\t}\n\n\terror = -EINVAL;\n\targs = strim(args);\n\tcommand = strsep(&args, \" \");\n\tif (!args)\n\t\tgoto out;\n\targs = skip_spaces(args);\n\tif (!*args)\n\t\tgoto out;\n\n\targ_size = size - (args - (char *) value);\n\tif (strcmp(name, \"current\") == 0) {\n\t\tif (strcmp(command, \"changehat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permhat\") == 0) {\n\t\t\terror = aa_setprocattr_changehat(args, arg_size,\n\t\t\t\t\t\t\t AA_DO_TEST);\n\t\t} else if (strcmp(command, \"changeprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\t} else if (strcmp(command, \"permprofile\") == 0) {\n\t\t\terror = aa_setprocattr_changeprofile(args, !AA_ONEXEC,\n\t\t\t\t\t\t\t     AA_DO_TEST);\n\t\t} else\n\t\t\tgoto fail;\n\t} else if (strcmp(name, \"exec\") == 0) {\n\t\tif (strcmp(command, \"exec\") == 0)\n\t\t\terror = aa_setprocattr_changeprofile(args, AA_ONEXEC,\n\t\t\t\t\t\t\t     !AA_DO_TEST);\n\t\telse\n\t\t\tgoto fail;\n\t} else\n\t\t/* only support the \"current\" and \"exec\" process attributes */\n\t\tgoto fail;\n\n\tif (!error)\n\t\terror = size;\nout:\n\tkfree(largs);\n\treturn error;\n\nfail:\n\tsa.type = LSM_AUDIT_DATA_NONE;\n\tsa.aad = &aad;\n\taad.profile = aa_current_profile();\n\taad.op = OP_SETPROCATTR;\n\taad.info = name;\n\taad.error = error = -EINVAL;\n\taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n\tgoto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,34 +3,34 @@\n {\n \tstruct common_audit_data sa;\n \tstruct apparmor_audit_data aad = {0,};\n-\tchar *command, *args = value;\n+\tchar *command, *largs = NULL, *args = value;\n \tsize_t arg_size;\n \tint error;\n \n \tif (size == 0)\n \t\treturn -EINVAL;\n-\t/* args points to a PAGE_SIZE buffer, AppArmor requires that\n-\t * the buffer must be null terminated or have size <= PAGE_SIZE -1\n-\t * so that AppArmor can null terminate them\n-\t */\n-\tif (args[size - 1] != '\\0') {\n-\t\tif (size == PAGE_SIZE)\n-\t\t\treturn -EINVAL;\n-\t\targs[size] = '\\0';\n-\t}\n-\n \t/* task can only write its own attributes */\n \tif (current != task)\n \t\treturn -EACCES;\n \n-\targs = value;\n+\t/* AppArmor requires that the buffer must be null terminated atm */\n+\tif (args[size - 1] != '\\0') {\n+\t\t/* null terminate */\n+\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);\n+\t\tif (!args)\n+\t\t\treturn -ENOMEM;\n+\t\tmemcpy(args, value, size);\n+\t\targs[size] = '\\0';\n+\t}\n+\n+\terror = -EINVAL;\n \targs = strim(args);\n \tcommand = strsep(&args, \" \");\n \tif (!args)\n-\t\treturn -EINVAL;\n+\t\tgoto out;\n \targs = skip_spaces(args);\n \tif (!*args)\n-\t\treturn -EINVAL;\n+\t\tgoto out;\n \n \targ_size = size - (args - (char *) value);\n \tif (strcmp(name, \"current\") == 0) {\n@@ -56,10 +56,12 @@\n \t\t\tgoto fail;\n \t} else\n \t\t/* only support the \"current\" and \"exec\" process attributes */\n-\t\treturn -EINVAL;\n+\t\tgoto fail;\n \n \tif (!error)\n \t\terror = size;\n+out:\n+\tkfree(largs);\n \treturn error;\n \n fail:\n@@ -68,7 +70,7 @@\n \taad.profile = aa_current_profile();\n \taad.op = OP_SETPROCATTR;\n \taad.info = name;\n-\taad.error = -EINVAL;\n+\taad.error = error = -EINVAL;\n \taa_audit_msg(AUDIT_APPARMOR_DENIED, &sa, NULL);\n-\treturn -EINVAL;\n+\tgoto out;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tchar *command, *args = value;",
                "\t/* args points to a PAGE_SIZE buffer, AppArmor requires that",
                "\t * the buffer must be null terminated or have size <= PAGE_SIZE -1",
                "\t * so that AppArmor can null terminate them",
                "\t */",
                "\tif (args[size - 1] != '\\0') {",
                "\t\tif (size == PAGE_SIZE)",
                "\t\t\treturn -EINVAL;",
                "\t\targs[size] = '\\0';",
                "\t}",
                "",
                "\targs = value;",
                "\t\treturn -EINVAL;",
                "\t\treturn -EINVAL;",
                "\t\treturn -EINVAL;",
                "\taad.error = -EINVAL;",
                "\treturn -EINVAL;"
            ],
            "added_lines": [
                "\tchar *command, *largs = NULL, *args = value;",
                "\t/* AppArmor requires that the buffer must be null terminated atm */",
                "\tif (args[size - 1] != '\\0') {",
                "\t\t/* null terminate */",
                "\t\tlargs = args = kmalloc(size + 1, GFP_KERNEL);",
                "\t\tif (!args)",
                "\t\t\treturn -ENOMEM;",
                "\t\tmemcpy(args, value, size);",
                "\t\targs[size] = '\\0';",
                "\t}",
                "",
                "\terror = -EINVAL;",
                "\t\tgoto out;",
                "\t\tgoto out;",
                "\t\tgoto fail;",
                "out:",
                "\tkfree(largs);",
                "\taad.error = error = -EINVAL;",
                "\tgoto out;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3870",
        "func_name": "android/SimpleSoftOMXComponent::onPortEnable",
        "description": "omx/SimpleSoftOMXComponent.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-09-01, and 7.0 before 2016-09-01 does not prevent input-port changes, which allows attackers to gain privileges via a crafted application, aka internal bug 29421804.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/1e9801783770917728b7edbdeff3d0ec09c621ac",
        "commit_title": "omx: prevent input port enable/disable for software codecs",
        "commit_text": " Bug: 29421804 ",
        "func_before": "void SimpleSoftOMXComponent::onPortEnable(OMX_U32 portIndex, bool enable) {\n    CHECK_LT(portIndex, mPorts.size());\n\n    PortInfo *port = &mPorts.editItemAt(portIndex);\n    CHECK_EQ((int)port->mTransition, (int)PortInfo::NONE);\n    CHECK(port->mDef.bEnabled == !enable);\n\n    if (!enable) {\n        port->mDef.bEnabled = OMX_FALSE;\n        port->mTransition = PortInfo::DISABLING;\n\n        for (size_t i = 0; i < port->mBuffers.size(); ++i) {\n            BufferInfo *buffer = &port->mBuffers.editItemAt(i);\n\n            if (buffer->mOwnedByUs) {\n                buffer->mOwnedByUs = false;\n\n                if (port->mDef.eDir == OMX_DirInput) {\n                    notifyEmptyBufferDone(buffer->mHeader);\n                } else {\n                    CHECK_EQ(port->mDef.eDir, OMX_DirOutput);\n                    notifyFillBufferDone(buffer->mHeader);\n                }\n            }\n        }\n\n        port->mQueue.clear();\n    } else {\n        port->mTransition = PortInfo::ENABLING;\n    }\n\n    checkTransitions();\n}",
        "func": "void SimpleSoftOMXComponent::onPortEnable(OMX_U32 portIndex, bool enable) {\n    CHECK_LT(portIndex, mPorts.size());\n\n    PortInfo *port = &mPorts.editItemAt(portIndex);\n    CHECK_EQ((int)port->mTransition, (int)PortInfo::NONE);\n    CHECK(port->mDef.bEnabled == !enable);\n\n    if (port->mDef.eDir != OMX_DirOutput) {\n        ALOGE(\"Port enable/disable allowed only on output ports.\");\n        notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n        android_errorWriteLog(0x534e4554, \"29421804\");\n        return;\n    }\n\n    if (!enable) {\n        port->mDef.bEnabled = OMX_FALSE;\n        port->mTransition = PortInfo::DISABLING;\n\n        for (size_t i = 0; i < port->mBuffers.size(); ++i) {\n            BufferInfo *buffer = &port->mBuffers.editItemAt(i);\n\n            if (buffer->mOwnedByUs) {\n                buffer->mOwnedByUs = false;\n\n                if (port->mDef.eDir == OMX_DirInput) {\n                    notifyEmptyBufferDone(buffer->mHeader);\n                } else {\n                    CHECK_EQ(port->mDef.eDir, OMX_DirOutput);\n                    notifyFillBufferDone(buffer->mHeader);\n                }\n            }\n        }\n\n        port->mQueue.clear();\n    } else {\n        port->mTransition = PortInfo::ENABLING;\n    }\n\n    checkTransitions();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,13 @@\n     PortInfo *port = &mPorts.editItemAt(portIndex);\n     CHECK_EQ((int)port->mTransition, (int)PortInfo::NONE);\n     CHECK(port->mDef.bEnabled == !enable);\n+\n+    if (port->mDef.eDir != OMX_DirOutput) {\n+        ALOGE(\"Port enable/disable allowed only on output ports.\");\n+        notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n+        android_errorWriteLog(0x534e4554, \"29421804\");\n+        return;\n+    }\n \n     if (!enable) {\n         port->mDef.bEnabled = OMX_FALSE;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (port->mDef.eDir != OMX_DirOutput) {",
                "        ALOGE(\"Port enable/disable allowed only on output ports.\");",
                "        notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);",
                "        android_errorWriteLog(0x534e4554, \"29421804\");",
                "        return;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3871",
        "func_name": "android/SoftMP3::memsetSafe",
        "description": "Multiple buffer overflows in codecs/mp3dec/SoftMP3.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-09-01, and 7.0 before 2016-09-01 allow attackers to gain privileges via a crafted application, aka internal bug 29422022.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/3c4edac2a5b00dec6c8579a0ee658cfb3bb16d94",
        "commit_title": "Fix build",
        "commit_text": " ",
        "func_before": "void *SoftMP3::memsetSafe(OMX_BUFFERHEADERTYPE *outHeader, int c, size_t len) {\n    if (len > outHeader->nAllocLen) {\n        ALOGE(\"memset buffer too small: got %lu, expected %zu\", outHeader->nAllocLen, len);\n        android_errorWriteLog(0x534e4554, \"29422022\");\n        notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n        mSignalledError = true;\n        return NULL;\n    }\n    return memset(outHeader->pBuffer, c, len);\n}",
        "func": "void *SoftMP3::memsetSafe(OMX_BUFFERHEADERTYPE *outHeader, int c, size_t len) {\n    if (len > outHeader->nAllocLen) {\n        ALOGE(\"memset buffer too small: got %lu, expected %zu\", (unsigned long)outHeader->nAllocLen, len);\n        android_errorWriteLog(0x534e4554, \"29422022\");\n        notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n        mSignalledError = true;\n        return NULL;\n    }\n    return memset(outHeader->pBuffer, c, len);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n void *SoftMP3::memsetSafe(OMX_BUFFERHEADERTYPE *outHeader, int c, size_t len) {\n     if (len > outHeader->nAllocLen) {\n-        ALOGE(\"memset buffer too small: got %lu, expected %zu\", outHeader->nAllocLen, len);\n+        ALOGE(\"memset buffer too small: got %lu, expected %zu\", (unsigned long)outHeader->nAllocLen, len);\n         android_errorWriteLog(0x534e4554, \"29422022\");\n         notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n         mSignalledError = true;",
        "diff_line_info": {
            "deleted_lines": [
                "        ALOGE(\"memset buffer too small: got %lu, expected %zu\", outHeader->nAllocLen, len);"
            ],
            "added_lines": [
                "        ALOGE(\"memset buffer too small: got %lu, expected %zu\", (unsigned long)outHeader->nAllocLen, len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3871",
        "func_name": "android/SoftMP3::onQueueFilled",
        "description": "Multiple buffer overflows in codecs/mp3dec/SoftMP3.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-09-01, and 7.0 before 2016-09-01 allow attackers to gain privileges via a crafted application, aka internal bug 29422022.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/c2639afac631f5c1ffddf70ee8a6fe943d0bedf9",
        "commit_title": "SoftMP3: memset safely",
        "commit_text": " Bug: 29422022 ",
        "func_before": "void SoftMP3::onQueueFilled(OMX_U32 /* portIndex */) {\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    while ((!inQueue.empty() || (mSawInputEos && !mSignalledOutputEos)) && !outQueue.empty()) {\n        BufferInfo *inInfo = NULL;\n        OMX_BUFFERHEADERTYPE *inHeader = NULL;\n        if (!inQueue.empty()) {\n            inInfo = *inQueue.begin();\n            inHeader = inInfo->mHeader;\n        }\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n        outHeader->nFlags = 0;\n\n        if (inHeader) {\n            if (inHeader->nOffset == 0 && inHeader->nFilledLen) {\n                mAnchorTimeUs = inHeader->nTimeStamp;\n                mNumFramesOutput = 0;\n            }\n\n            if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                mSawInputEos = true;\n            }\n\n            mConfig->pInputBuffer =\n                inHeader->pBuffer + inHeader->nOffset;\n\n            mConfig->inputBufferCurrentLength = inHeader->nFilledLen;\n        } else {\n            mConfig->pInputBuffer = NULL;\n            mConfig->inputBufferCurrentLength = 0;\n        }\n        mConfig->inputBufferMaxLength = 0;\n        mConfig->inputBufferUsedLength = 0;\n\n        mConfig->outputFrameSize = kOutputBufferSize / sizeof(int16_t);\n        if ((int32)outHeader->nAllocLen < mConfig->outputFrameSize) {\n            ALOGE(\"input buffer too small: got %u, expected %u\",\n                outHeader->nAllocLen, mConfig->outputFrameSize);\n            android_errorWriteLog(0x534e4554, \"27793371\");\n            notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n            mSignalledError = true;\n            return;\n        }\n\n        mConfig->pOutputBuffer =\n            reinterpret_cast<int16_t *>(outHeader->pBuffer);\n\n        ERROR_CODE decoderErr;\n        if ((decoderErr = pvmp3_framedecoder(mConfig, mDecoderBuf))\n                != NO_DECODING_ERROR) {\n            ALOGV(\"mp3 decoder returned error %d\", decoderErr);\n\n            if (decoderErr != NO_ENOUGH_MAIN_DATA_ERROR\n                        && decoderErr != SIDE_INFO_ERROR) {\n                ALOGE(\"mp3 decoder returned error %d\", decoderErr);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, decoderErr, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            if (mConfig->outputFrameSize == 0) {\n                mConfig->outputFrameSize = kOutputBufferSize / sizeof(int16_t);\n            }\n\n            if (decoderErr == NO_ENOUGH_MAIN_DATA_ERROR && mSawInputEos) {\n                if (!mIsFirst) {\n                    // pad the end of the stream with 529 samples, since that many samples\n                    // were trimmed off the beginning when decoding started\n                    outHeader->nOffset = 0;\n                    outHeader->nFilledLen = kPVMP3DecoderDelay * mNumChannels * sizeof(int16_t);\n\n                    memset(outHeader->pBuffer, 0, outHeader->nFilledLen);\n                }\n                outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n                mSignalledOutputEos = true;\n            } else {\n                // This is recoverable, just ignore the current frame and\n                // play silence instead.\n\n                // TODO: should we skip silence (and consume input data)\n                // if mIsFirst is true as we may not have a valid\n                // mConfig->samplingRate and mConfig->num_channels?\n                ALOGV_IF(mIsFirst, \"insufficient data for first frame, sending silence\");\n                memset(outHeader->pBuffer,\n                       0,\n                       mConfig->outputFrameSize * sizeof(int16_t));\n\n                if (inHeader) {\n                    mConfig->inputBufferUsedLength = inHeader->nFilledLen;\n                }\n            }\n        } else if (mConfig->samplingRate != mSamplingRate\n                || mConfig->num_channels != mNumChannels) {\n            mSamplingRate = mConfig->samplingRate;\n            mNumChannels = mConfig->num_channels;\n\n            notify(OMX_EventPortSettingsChanged, 1, 0, NULL);\n            mOutputPortSettingsChange = AWAITING_DISABLED;\n            return;\n        }\n\n        if (mIsFirst) {\n            mIsFirst = false;\n            // The decoder delay is 529 samples, so trim that many samples off\n            // the start of the first output buffer. This essentially makes this\n            // decoder have zero delay, which the rest of the pipeline assumes.\n            outHeader->nOffset =\n                kPVMP3DecoderDelay * mNumChannels * sizeof(int16_t);\n\n            outHeader->nFilledLen =\n                mConfig->outputFrameSize * sizeof(int16_t) - outHeader->nOffset;\n        } else if (!mSignalledOutputEos) {\n            outHeader->nOffset = 0;\n            outHeader->nFilledLen = mConfig->outputFrameSize * sizeof(int16_t);\n        }\n\n        outHeader->nTimeStamp =\n            mAnchorTimeUs + (mNumFramesOutput * 1000000ll) / mSamplingRate;\n\n        if (inHeader) {\n            CHECK_GE(inHeader->nFilledLen, mConfig->inputBufferUsedLength);\n\n            inHeader->nOffset += mConfig->inputBufferUsedLength;\n            inHeader->nFilledLen -= mConfig->inputBufferUsedLength;\n\n\n            if (inHeader->nFilledLen == 0) {\n                inInfo->mOwnedByUs = false;\n                inQueue.erase(inQueue.begin());\n                inInfo = NULL;\n                notifyEmptyBufferDone(inHeader);\n                inHeader = NULL;\n            }\n        }\n\n        mNumFramesOutput += mConfig->outputFrameSize / mNumChannels;\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n    }\n}",
        "func": "void SoftMP3::onQueueFilled(OMX_U32 /* portIndex */) {\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    while ((!inQueue.empty() || (mSawInputEos && !mSignalledOutputEos)) && !outQueue.empty()) {\n        BufferInfo *inInfo = NULL;\n        OMX_BUFFERHEADERTYPE *inHeader = NULL;\n        if (!inQueue.empty()) {\n            inInfo = *inQueue.begin();\n            inHeader = inInfo->mHeader;\n        }\n\n        BufferInfo *outInfo = *outQueue.begin();\n        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;\n        outHeader->nFlags = 0;\n\n        if (inHeader) {\n            if (inHeader->nOffset == 0 && inHeader->nFilledLen) {\n                mAnchorTimeUs = inHeader->nTimeStamp;\n                mNumFramesOutput = 0;\n            }\n\n            if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                mSawInputEos = true;\n            }\n\n            mConfig->pInputBuffer =\n                inHeader->pBuffer + inHeader->nOffset;\n\n            mConfig->inputBufferCurrentLength = inHeader->nFilledLen;\n        } else {\n            mConfig->pInputBuffer = NULL;\n            mConfig->inputBufferCurrentLength = 0;\n        }\n        mConfig->inputBufferMaxLength = 0;\n        mConfig->inputBufferUsedLength = 0;\n\n        mConfig->outputFrameSize = kOutputBufferSize / sizeof(int16_t);\n        if ((int32)outHeader->nAllocLen < mConfig->outputFrameSize) {\n            ALOGE(\"input buffer too small: got %u, expected %u\",\n                outHeader->nAllocLen, mConfig->outputFrameSize);\n            android_errorWriteLog(0x534e4554, \"27793371\");\n            notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n            mSignalledError = true;\n            return;\n        }\n\n        mConfig->pOutputBuffer =\n            reinterpret_cast<int16_t *>(outHeader->pBuffer);\n\n        ERROR_CODE decoderErr;\n        if ((decoderErr = pvmp3_framedecoder(mConfig, mDecoderBuf))\n                != NO_DECODING_ERROR) {\n            ALOGV(\"mp3 decoder returned error %d\", decoderErr);\n\n            if (decoderErr != NO_ENOUGH_MAIN_DATA_ERROR\n                        && decoderErr != SIDE_INFO_ERROR) {\n                ALOGE(\"mp3 decoder returned error %d\", decoderErr);\n\n                notify(OMX_EventError, OMX_ErrorUndefined, decoderErr, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            if (mConfig->outputFrameSize == 0) {\n                mConfig->outputFrameSize = kOutputBufferSize / sizeof(int16_t);\n            }\n\n            if (decoderErr == NO_ENOUGH_MAIN_DATA_ERROR && mSawInputEos) {\n                if (!mIsFirst) {\n                    // pad the end of the stream with 529 samples, since that many samples\n                    // were trimmed off the beginning when decoding started\n                    outHeader->nOffset = 0;\n                    outHeader->nFilledLen = kPVMP3DecoderDelay * mNumChannels * sizeof(int16_t);\n\n                    if (!memsetSafe(outHeader, 0, outHeader->nFilledLen)) {\n                        return;\n                    }\n\n                }\n                outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n                mSignalledOutputEos = true;\n            } else {\n                // This is recoverable, just ignore the current frame and\n                // play silence instead.\n\n                // TODO: should we skip silence (and consume input data)\n                // if mIsFirst is true as we may not have a valid\n                // mConfig->samplingRate and mConfig->num_channels?\n                ALOGV_IF(mIsFirst, \"insufficient data for first frame, sending silence\");\n                if (!memsetSafe(outHeader, 0, mConfig->outputFrameSize * sizeof(int16_t))) {\n                    return;\n                }\n\n                if (inHeader) {\n                    mConfig->inputBufferUsedLength = inHeader->nFilledLen;\n                }\n            }\n        } else if (mConfig->samplingRate != mSamplingRate\n                || mConfig->num_channels != mNumChannels) {\n            mSamplingRate = mConfig->samplingRate;\n            mNumChannels = mConfig->num_channels;\n\n            notify(OMX_EventPortSettingsChanged, 1, 0, NULL);\n            mOutputPortSettingsChange = AWAITING_DISABLED;\n            return;\n        }\n\n        if (mIsFirst) {\n            mIsFirst = false;\n            // The decoder delay is 529 samples, so trim that many samples off\n            // the start of the first output buffer. This essentially makes this\n            // decoder have zero delay, which the rest of the pipeline assumes.\n            outHeader->nOffset =\n                kPVMP3DecoderDelay * mNumChannels * sizeof(int16_t);\n\n            outHeader->nFilledLen =\n                mConfig->outputFrameSize * sizeof(int16_t) - outHeader->nOffset;\n        } else if (!mSignalledOutputEos) {\n            outHeader->nOffset = 0;\n            outHeader->nFilledLen = mConfig->outputFrameSize * sizeof(int16_t);\n        }\n\n        outHeader->nTimeStamp =\n            mAnchorTimeUs + (mNumFramesOutput * 1000000ll) / mSamplingRate;\n\n        if (inHeader) {\n            CHECK_GE(inHeader->nFilledLen, mConfig->inputBufferUsedLength);\n\n            inHeader->nOffset += mConfig->inputBufferUsedLength;\n            inHeader->nFilledLen -= mConfig->inputBufferUsedLength;\n\n\n            if (inHeader->nFilledLen == 0) {\n                inInfo->mOwnedByUs = false;\n                inQueue.erase(inQueue.begin());\n                inInfo = NULL;\n                notifyEmptyBufferDone(inHeader);\n                inHeader = NULL;\n            }\n        }\n\n        mNumFramesOutput += mConfig->outputFrameSize / mNumChannels;\n\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(outQueue.begin());\n        outInfo = NULL;\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -77,7 +77,10 @@\n                     outHeader->nOffset = 0;\n                     outHeader->nFilledLen = kPVMP3DecoderDelay * mNumChannels * sizeof(int16_t);\n \n-                    memset(outHeader->pBuffer, 0, outHeader->nFilledLen);\n+                    if (!memsetSafe(outHeader, 0, outHeader->nFilledLen)) {\n+                        return;\n+                    }\n+\n                 }\n                 outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n                 mSignalledOutputEos = true;\n@@ -89,9 +92,9 @@\n                 // if mIsFirst is true as we may not have a valid\n                 // mConfig->samplingRate and mConfig->num_channels?\n                 ALOGV_IF(mIsFirst, \"insufficient data for first frame, sending silence\");\n-                memset(outHeader->pBuffer,\n-                       0,\n-                       mConfig->outputFrameSize * sizeof(int16_t));\n+                if (!memsetSafe(outHeader, 0, mConfig->outputFrameSize * sizeof(int16_t))) {\n+                    return;\n+                }\n \n                 if (inHeader) {\n                     mConfig->inputBufferUsedLength = inHeader->nFilledLen;",
        "diff_line_info": {
            "deleted_lines": [
                "                    memset(outHeader->pBuffer, 0, outHeader->nFilledLen);",
                "                memset(outHeader->pBuffer,",
                "                       0,",
                "                       mConfig->outputFrameSize * sizeof(int16_t));"
            ],
            "added_lines": [
                "                    if (!memsetSafe(outHeader, 0, outHeader->nFilledLen)) {",
                "                        return;",
                "                    }",
                "",
                "                if (!memsetSafe(outHeader, 0, mConfig->outputFrameSize * sizeof(int16_t))) {",
                "                    return;",
                "                }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3871",
        "func_name": "android/SoftMP3::memsetSafe",
        "description": "Multiple buffer overflows in codecs/mp3dec/SoftMP3.cpp in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-09-01, and 7.0 before 2016-09-01 allow attackers to gain privileges via a crafted application, aka internal bug 29422022.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/c17ad2f0c7e00fd1bbf01d0dfed41f72d78267ad",
        "commit_title": "Fix build",
        "commit_text": " ",
        "func_before": "void *SoftMP3::memsetSafe(OMX_BUFFERHEADERTYPE *outHeader, int c, size_t len) {\n    if (len > outHeader->nAllocLen) {\n        ALOGE(\"memset buffer too small: got %lu, expected %zu\", (unsigned long)outHeader->nAllocLen, len);\n        android_errorWriteLog(0x534e4554, \"29422022\");\n        notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n        mSignalledError = true;\n        return NULL;\n    }\n    return memset(outHeader->pBuffer, c, len);\n}",
        "func": "void *SoftMP3::memsetSafe(OMX_BUFFERHEADERTYPE *outHeader, int c, size_t len) {\n    if (len > outHeader->nAllocLen) {\n        ALOGE(\"memset buffer too small: got %u, expected %zu\", outHeader->nAllocLen, len);\n        android_errorWriteLog(0x534e4554, \"29422022\");\n        notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n        mSignalledError = true;\n        return NULL;\n    }\n    return memset(outHeader->pBuffer, c, len);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n void *SoftMP3::memsetSafe(OMX_BUFFERHEADERTYPE *outHeader, int c, size_t len) {\n     if (len > outHeader->nAllocLen) {\n-        ALOGE(\"memset buffer too small: got %lu, expected %zu\", (unsigned long)outHeader->nAllocLen, len);\n+        ALOGE(\"memset buffer too small: got %u, expected %zu\", outHeader->nAllocLen, len);\n         android_errorWriteLog(0x534e4554, \"29422022\");\n         notify(OMX_EventError, OMX_ErrorUndefined, OUTPUT_BUFFER_TOO_SMALL, NULL);\n         mSignalledError = true;",
        "diff_line_info": {
            "deleted_lines": [
                "        ALOGE(\"memset buffer too small: got %lu, expected %zu\", (unsigned long)outHeader->nAllocLen, len);"
            ],
            "added_lines": [
                "        ALOGE(\"memset buffer too small: got %u, expected %zu\", outHeader->nAllocLen, len);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3885",
        "func_name": "android/read_request",
        "description": "debuggerd/debuggerd.cpp in Debuggerd in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-09-01, and 7.0 before 2016-09-01 mishandles the interaction between PTRACE_ATTACH operations and thread exits, which allows attackers to gain privileges via a crafted application, aka internal bug 29555636.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/d7603583f90c2bc6074a4ee2886bd28082d7c65b",
        "commit_title": "debuggerd: verify that traced threads belong to the right process.",
        "commit_text": " Fix two races in debuggerd's PTRACE_ATTACH logic:   1. The target thread in a crash dump request could exit between the      /proc/<pid>/task/<tid> check and the PTRACE_ATTACH.   2. Sibling threads could exit between listing /proc/<pid>/task and the      PTRACE_ATTACH.  Bug: http://b/29555636 ",
        "func_before": "static int read_request(int fd, debugger_request_t* out_request) {\n  ucred cr;\n  socklen_t len = sizeof(cr);\n  int status = getsockopt(fd, SOL_SOCKET, SO_PEERCRED, &cr, &len);\n  if (status != 0) {\n    ALOGE(\"cannot get credentials\");\n    return -1;\n  }\n\n  ALOGV(\"reading tid\");\n  fcntl(fd, F_SETFL, O_NONBLOCK);\n\n  pollfd pollfds[1];\n  pollfds[0].fd = fd;\n  pollfds[0].events = POLLIN;\n  pollfds[0].revents = 0;\n  status = TEMP_FAILURE_RETRY(poll(pollfds, 1, 3000));\n  if (status != 1) {\n    ALOGE(\"timed out reading tid (from pid=%d uid=%d)\\n\", cr.pid, cr.uid);\n    return -1;\n  }\n\n  debugger_msg_t msg;\n  memset(&msg, 0, sizeof(msg));\n  status = TEMP_FAILURE_RETRY(read(fd, &msg, sizeof(msg)));\n  if (status < 0) {\n    ALOGE(\"read failure? %s (pid=%d uid=%d)\\n\", strerror(errno), cr.pid, cr.uid);\n    return -1;\n  }\n  if (status != sizeof(debugger_msg_t)) {\n    ALOGE(\"invalid crash request of size %d (from pid=%d uid=%d)\\n\", status, cr.pid, cr.uid);\n    return -1;\n  }\n\n  out_request->action = static_cast<debugger_action_t>(msg.action);\n  out_request->tid = msg.tid;\n  out_request->pid = cr.pid;\n  out_request->uid = cr.uid;\n  out_request->gid = cr.gid;\n  out_request->abort_msg_address = msg.abort_msg_address;\n  out_request->original_si_code = msg.original_si_code;\n\n  if (msg.action == DEBUGGER_ACTION_CRASH) {\n    // Ensure that the tid reported by the crashing process is valid.\n    char buf[64];\n    struct stat s;\n    snprintf(buf, sizeof buf, \"/proc/%d/task/%d\", out_request->pid, out_request->tid);\n    if (stat(buf, &s)) {\n      ALOGE(\"tid %d does not exist in pid %d. ignoring debug request\\n\",\n          out_request->tid, out_request->pid);\n      return -1;\n    }\n  } else if (cr.uid == 0\n            || (cr.uid == AID_SYSTEM && msg.action == DEBUGGER_ACTION_DUMP_BACKTRACE)) {\n    // Only root or system can ask us to attach to any process and dump it explicitly.\n    // However, system is only allowed to collect backtraces but cannot dump tombstones.\n    status = get_process_info(out_request->tid, &out_request->pid,\n                              &out_request->uid, &out_request->gid);\n    if (status < 0) {\n      ALOGE(\"tid %d does not exist. ignoring explicit dump request\\n\", out_request->tid);\n      return -1;\n    }\n\n    if (!selinux_action_allowed(fd, out_request))\n      return -1;\n  } else {\n    // No one else is allowed to dump arbitrary processes.\n    return -1;\n  }\n  return 0;\n}",
        "func": "static int read_request(int fd, debugger_request_t* out_request) {\n  ucred cr;\n  socklen_t len = sizeof(cr);\n  int status = getsockopt(fd, SOL_SOCKET, SO_PEERCRED, &cr, &len);\n  if (status != 0) {\n    ALOGE(\"cannot get credentials\");\n    return -1;\n  }\n\n  ALOGV(\"reading tid\");\n  fcntl(fd, F_SETFL, O_NONBLOCK);\n\n  pollfd pollfds[1];\n  pollfds[0].fd = fd;\n  pollfds[0].events = POLLIN;\n  pollfds[0].revents = 0;\n  status = TEMP_FAILURE_RETRY(poll(pollfds, 1, 3000));\n  if (status != 1) {\n    ALOGE(\"timed out reading tid (from pid=%d uid=%d)\\n\", cr.pid, cr.uid);\n    return -1;\n  }\n\n  debugger_msg_t msg;\n  memset(&msg, 0, sizeof(msg));\n  status = TEMP_FAILURE_RETRY(read(fd, &msg, sizeof(msg)));\n  if (status < 0) {\n    ALOGE(\"read failure? %s (pid=%d uid=%d)\\n\", strerror(errno), cr.pid, cr.uid);\n    return -1;\n  }\n  if (status != sizeof(debugger_msg_t)) {\n    ALOGE(\"invalid crash request of size %d (from pid=%d uid=%d)\\n\", status, cr.pid, cr.uid);\n    return -1;\n  }\n\n  out_request->action = static_cast<debugger_action_t>(msg.action);\n  out_request->tid = msg.tid;\n  out_request->pid = cr.pid;\n  out_request->uid = cr.uid;\n  out_request->gid = cr.gid;\n  out_request->abort_msg_address = msg.abort_msg_address;\n  out_request->original_si_code = msg.original_si_code;\n\n  if (msg.action == DEBUGGER_ACTION_CRASH) {\n    // Ensure that the tid reported by the crashing process is valid.\n    // This check needs to happen again after ptracing the requested thread to prevent a race.\n    if (!pid_contains_tid(out_request->pid, out_request->tid)) {\n      ALOGE(\"tid %d does not exist in pid %d. ignoring debug request\\n\", out_request->tid,\n            out_request->pid);\n      return -1;\n    }\n  } else if (cr.uid == 0 || (cr.uid == AID_SYSTEM && msg.action == DEBUGGER_ACTION_DUMP_BACKTRACE)) {\n    // Only root or system can ask us to attach to any process and dump it explicitly.\n    // However, system is only allowed to collect backtraces but cannot dump tombstones.\n    status = get_process_info(out_request->tid, &out_request->pid,\n                              &out_request->uid, &out_request->gid);\n    if (status < 0) {\n      ALOGE(\"tid %d does not exist. ignoring explicit dump request\\n\", out_request->tid);\n      return -1;\n    }\n\n    if (!selinux_action_allowed(fd, out_request))\n      return -1;\n  } else {\n    // No one else is allowed to dump arbitrary processes.\n    return -1;\n  }\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,16 +42,13 @@\n \n   if (msg.action == DEBUGGER_ACTION_CRASH) {\n     // Ensure that the tid reported by the crashing process is valid.\n-    char buf[64];\n-    struct stat s;\n-    snprintf(buf, sizeof buf, \"/proc/%d/task/%d\", out_request->pid, out_request->tid);\n-    if (stat(buf, &s)) {\n-      ALOGE(\"tid %d does not exist in pid %d. ignoring debug request\\n\",\n-          out_request->tid, out_request->pid);\n+    // This check needs to happen again after ptracing the requested thread to prevent a race.\n+    if (!pid_contains_tid(out_request->pid, out_request->tid)) {\n+      ALOGE(\"tid %d does not exist in pid %d. ignoring debug request\\n\", out_request->tid,\n+            out_request->pid);\n       return -1;\n     }\n-  } else if (cr.uid == 0\n-            || (cr.uid == AID_SYSTEM && msg.action == DEBUGGER_ACTION_DUMP_BACKTRACE)) {\n+  } else if (cr.uid == 0 || (cr.uid == AID_SYSTEM && msg.action == DEBUGGER_ACTION_DUMP_BACKTRACE)) {\n     // Only root or system can ask us to attach to any process and dump it explicitly.\n     // However, system is only allowed to collect backtraces but cannot dump tombstones.\n     status = get_process_info(out_request->tid, &out_request->pid,",
        "diff_line_info": {
            "deleted_lines": [
                "    char buf[64];",
                "    struct stat s;",
                "    snprintf(buf, sizeof buf, \"/proc/%d/task/%d\", out_request->pid, out_request->tid);",
                "    if (stat(buf, &s)) {",
                "      ALOGE(\"tid %d does not exist in pid %d. ignoring debug request\\n\",",
                "          out_request->tid, out_request->pid);",
                "  } else if (cr.uid == 0",
                "            || (cr.uid == AID_SYSTEM && msg.action == DEBUGGER_ACTION_DUMP_BACKTRACE)) {"
            ],
            "added_lines": [
                "    // This check needs to happen again after ptracing the requested thread to prevent a race.",
                "    if (!pid_contains_tid(out_request->pid, out_request->tid)) {",
                "      ALOGE(\"tid %d does not exist in pid %d. ignoring debug request\\n\", out_request->tid,",
                "            out_request->pid);",
                "  } else if (cr.uid == 0 || (cr.uid == AID_SYSTEM && msg.action == DEBUGGER_ACTION_DUMP_BACKTRACE)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3885",
        "func_name": "android/worker_process",
        "description": "debuggerd/debuggerd.cpp in Debuggerd in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-09-01, and 7.0 before 2016-09-01 mishandles the interaction between PTRACE_ATTACH operations and thread exits, which allows attackers to gain privileges via a crafted application, aka internal bug 29555636.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/d7603583f90c2bc6074a4ee2886bd28082d7c65b",
        "commit_title": "debuggerd: verify that traced threads belong to the right process.",
        "commit_text": " Fix two races in debuggerd's PTRACE_ATTACH logic:   1. The target thread in a crash dump request could exit between the      /proc/<pid>/task/<tid> check and the PTRACE_ATTACH.   2. Sibling threads could exit between listing /proc/<pid>/task and the      PTRACE_ATTACH.  Bug: http://b/29555636 ",
        "func_before": "static void worker_process(int fd, debugger_request_t& request) {\n  // Open the tombstone file if we need it.\n  std::string tombstone_path;\n  int tombstone_fd = -1;\n  switch (request.action) {\n    case DEBUGGER_ACTION_DUMP_TOMBSTONE:\n    case DEBUGGER_ACTION_CRASH:\n      tombstone_fd = open_tombstone(&tombstone_path);\n      if (tombstone_fd == -1) {\n        ALOGE(\"debuggerd: failed to open tombstone file: %s\\n\", strerror(errno));\n        exit(1);\n      }\n      break;\n\n    case DEBUGGER_ACTION_DUMP_BACKTRACE:\n      break;\n\n    default:\n      ALOGE(\"debuggerd: unexpected request action: %d\", request.action);\n      exit(1);\n  }\n\n  // At this point, the thread that made the request is blocked in\n  // a read() call.  If the thread has crashed, then this gives us\n  // time to PTRACE_ATTACH to it before it has a chance to really fault.\n  //\n  // The PTRACE_ATTACH sends a SIGSTOP to the target process, but it\n  // won't necessarily have stopped by the time ptrace() returns.  (We\n  // currently assume it does.)  We write to the file descriptor to\n  // ensure that it can run as soon as we call PTRACE_CONT below.\n  // See details in bionic/libc/linker/debugger.c, in function\n  // debugger_signal_handler().\n\n  // Attach to the target process.\n  if (ptrace(PTRACE_ATTACH, request.tid, 0, 0) != 0) {\n    ALOGE(\"debuggerd: ptrace attach failed: %s\", strerror(errno));\n    exit(1);\n  }\n\n  // Don't attach to the sibling threads if we want to attach gdb.\n  // Supposedly, it makes the process less reliable.\n  bool attach_gdb = should_attach_gdb(request);\n  if (attach_gdb) {\n    // Open all of the input devices we need to listen for VOLUMEDOWN before dropping privileges.\n    if (init_getevent() != 0) {\n      ALOGE(\"debuggerd: failed to initialize input device, not waiting for gdb\");\n      attach_gdb = false;\n    }\n\n  }\n\n  std::set<pid_t> siblings;\n  if (!attach_gdb) {\n    ptrace_siblings(request.pid, request.tid, siblings);\n  }\n\n  // Generate the backtrace map before dropping privileges.\n  std::unique_ptr<BacktraceMap> backtrace_map(BacktraceMap::Create(request.pid));\n\n  int amfd = -1;\n  std::unique_ptr<std::string> amfd_data;\n  if (request.action == DEBUGGER_ACTION_CRASH) {\n    // Connect to the activity manager before dropping privileges.\n    amfd = activity_manager_connect();\n    amfd_data.reset(new std::string);\n  }\n\n  bool succeeded = false;\n\n  // Now that we've done everything that requires privileges, we can drop them.\n  if (!drop_privileges()) {\n    ALOGE(\"debuggerd: failed to drop privileges, exiting\");\n    _exit(1);\n  }\n\n  int crash_signal = SIGKILL;\n  succeeded = perform_dump(request, fd, tombstone_fd, backtrace_map.get(), siblings,\n                           &crash_signal, amfd_data.get());\n  if (succeeded) {\n    if (request.action == DEBUGGER_ACTION_DUMP_TOMBSTONE) {\n      if (!tombstone_path.empty()) {\n        android::base::WriteFully(fd, tombstone_path.c_str(), tombstone_path.length());\n      }\n    }\n  }\n\n  if (attach_gdb) {\n    // Tell the signal process to send SIGSTOP to the target.\n    if (!send_signal(request.pid, 0, SIGSTOP)) {\n      ALOGE(\"debuggerd: failed to stop process for gdb attach: %s\", strerror(errno));\n      attach_gdb = false;\n    }\n  }\n\n  if (!attach_gdb) {\n    // Tell the Activity Manager about the crashing process. If we are\n    // waiting for gdb to attach, do not send this or Activity Manager\n    // might kill the process before anyone can attach.\n    activity_manager_write(request.pid, crash_signal, amfd, *amfd_data.get());\n  }\n\n  if (ptrace(PTRACE_DETACH, request.tid, 0, 0) != 0) {\n    ALOGE(\"debuggerd: ptrace detach from %d failed: %s\", request.tid, strerror(errno));\n  }\n\n  for (pid_t sibling : siblings) {\n    ptrace(PTRACE_DETACH, sibling, 0, 0);\n  }\n\n  // Send the signal back to the process if it crashed and we're not waiting for gdb.\n  if (!attach_gdb && request.action == DEBUGGER_ACTION_CRASH) {\n    if (!send_signal(request.pid, request.tid, crash_signal)) {\n      ALOGE(\"debuggerd: failed to kill process %d: %s\", request.pid, strerror(errno));\n    }\n  }\n\n  // Wait for gdb, if requested.\n  if (attach_gdb) {\n    wait_for_user_action(request);\n\n    // Now tell the activity manager about this process.\n    activity_manager_write(request.pid, crash_signal, amfd, *amfd_data.get());\n\n    // Tell the signal process to send SIGCONT to the target.\n    if (!send_signal(request.pid, 0, SIGCONT)) {\n      ALOGE(\"debuggerd: failed to resume process %d: %s\", request.pid, strerror(errno));\n    }\n\n    uninit_getevent();\n  }\n\n  close(amfd);\n\n  exit(!succeeded);\n}",
        "func": "static void worker_process(int fd, debugger_request_t& request) {\n  // Open the tombstone file if we need it.\n  std::string tombstone_path;\n  int tombstone_fd = -1;\n  switch (request.action) {\n    case DEBUGGER_ACTION_DUMP_TOMBSTONE:\n    case DEBUGGER_ACTION_CRASH:\n      tombstone_fd = open_tombstone(&tombstone_path);\n      if (tombstone_fd == -1) {\n        ALOGE(\"debuggerd: failed to open tombstone file: %s\\n\", strerror(errno));\n        exit(1);\n      }\n      break;\n\n    case DEBUGGER_ACTION_DUMP_BACKTRACE:\n      break;\n\n    default:\n      ALOGE(\"debuggerd: unexpected request action: %d\", request.action);\n      exit(1);\n  }\n\n  // At this point, the thread that made the request is blocked in\n  // a read() call.  If the thread has crashed, then this gives us\n  // time to PTRACE_ATTACH to it before it has a chance to really fault.\n  //\n  // The PTRACE_ATTACH sends a SIGSTOP to the target process, but it\n  // won't necessarily have stopped by the time ptrace() returns.  (We\n  // currently assume it does.)  We write to the file descriptor to\n  // ensure that it can run as soon as we call PTRACE_CONT below.\n  // See details in bionic/libc/linker/debugger.c, in function\n  // debugger_signal_handler().\n\n  // Attach to the target process.\n  if (!ptrace_attach_thread(request.pid, request.tid)) {\n    ALOGE(\"debuggerd: ptrace attach failed: %s\", strerror(errno));\n    exit(1);\n  }\n\n  // DEBUGGER_ACTION_CRASH requests can come from arbitrary processes and the tid field in the\n  // request is sent from the other side. If an attacker can cause a process to be spawned with the\n  // pid of their process, they could trick debuggerd into dumping that process by exiting after\n  // sending the request. Validate the trusted request.uid/gid to defend against this.\n  if (request.action == DEBUGGER_ACTION_CRASH) {\n    pid_t pid;\n    uid_t uid;\n    gid_t gid;\n    if (get_process_info(request.tid, &pid, &uid, &gid) != 0) {\n      ALOGE(\"debuggerd: failed to get process info for tid '%d'\", request.tid);\n      exit(1);\n    }\n\n    if (pid != request.pid || uid != request.uid || gid != request.gid) {\n      ALOGE(\n        \"debuggerd: attached task %d does not match request: \"\n        \"expected pid=%d,uid=%d,gid=%d, actual pid=%d,uid=%d,gid=%d\",\n        request.tid, request.pid, request.uid, request.gid, pid, uid, gid);\n      exit(1);\n    }\n  }\n\n  // Don't attach to the sibling threads if we want to attach gdb.\n  // Supposedly, it makes the process less reliable.\n  bool attach_gdb = should_attach_gdb(request);\n  if (attach_gdb) {\n    // Open all of the input devices we need to listen for VOLUMEDOWN before dropping privileges.\n    if (init_getevent() != 0) {\n      ALOGE(\"debuggerd: failed to initialize input device, not waiting for gdb\");\n      attach_gdb = false;\n    }\n\n  }\n\n  std::set<pid_t> siblings;\n  if (!attach_gdb) {\n    ptrace_siblings(request.pid, request.tid, siblings);\n  }\n\n  // Generate the backtrace map before dropping privileges.\n  std::unique_ptr<BacktraceMap> backtrace_map(BacktraceMap::Create(request.pid));\n\n  int amfd = -1;\n  std::unique_ptr<std::string> amfd_data;\n  if (request.action == DEBUGGER_ACTION_CRASH) {\n    // Connect to the activity manager before dropping privileges.\n    amfd = activity_manager_connect();\n    amfd_data.reset(new std::string);\n  }\n\n  bool succeeded = false;\n\n  // Now that we've done everything that requires privileges, we can drop them.\n  if (!drop_privileges()) {\n    ALOGE(\"debuggerd: failed to drop privileges, exiting\");\n    _exit(1);\n  }\n\n  int crash_signal = SIGKILL;\n  succeeded = perform_dump(request, fd, tombstone_fd, backtrace_map.get(), siblings,\n                           &crash_signal, amfd_data.get());\n  if (succeeded) {\n    if (request.action == DEBUGGER_ACTION_DUMP_TOMBSTONE) {\n      if (!tombstone_path.empty()) {\n        android::base::WriteFully(fd, tombstone_path.c_str(), tombstone_path.length());\n      }\n    }\n  }\n\n  if (attach_gdb) {\n    // Tell the signal process to send SIGSTOP to the target.\n    if (!send_signal(request.pid, 0, SIGSTOP)) {\n      ALOGE(\"debuggerd: failed to stop process for gdb attach: %s\", strerror(errno));\n      attach_gdb = false;\n    }\n  }\n\n  if (!attach_gdb) {\n    // Tell the Activity Manager about the crashing process. If we are\n    // waiting for gdb to attach, do not send this or Activity Manager\n    // might kill the process before anyone can attach.\n    activity_manager_write(request.pid, crash_signal, amfd, *amfd_data.get());\n  }\n\n  if (ptrace(PTRACE_DETACH, request.tid, 0, 0) != 0) {\n    ALOGE(\"debuggerd: ptrace detach from %d failed: %s\", request.tid, strerror(errno));\n  }\n\n  for (pid_t sibling : siblings) {\n    ptrace(PTRACE_DETACH, sibling, 0, 0);\n  }\n\n  // Send the signal back to the process if it crashed and we're not waiting for gdb.\n  if (!attach_gdb && request.action == DEBUGGER_ACTION_CRASH) {\n    if (!send_signal(request.pid, request.tid, crash_signal)) {\n      ALOGE(\"debuggerd: failed to kill process %d: %s\", request.pid, strerror(errno));\n    }\n  }\n\n  // Wait for gdb, if requested.\n  if (attach_gdb) {\n    wait_for_user_action(request);\n\n    // Now tell the activity manager about this process.\n    activity_manager_write(request.pid, crash_signal, amfd, *amfd_data.get());\n\n    // Tell the signal process to send SIGCONT to the target.\n    if (!send_signal(request.pid, 0, SIGCONT)) {\n      ALOGE(\"debuggerd: failed to resume process %d: %s\", request.pid, strerror(errno));\n    }\n\n    uninit_getevent();\n  }\n\n  close(amfd);\n\n  exit(!succeeded);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,9 +32,31 @@\n   // debugger_signal_handler().\n \n   // Attach to the target process.\n-  if (ptrace(PTRACE_ATTACH, request.tid, 0, 0) != 0) {\n+  if (!ptrace_attach_thread(request.pid, request.tid)) {\n     ALOGE(\"debuggerd: ptrace attach failed: %s\", strerror(errno));\n     exit(1);\n+  }\n+\n+  // DEBUGGER_ACTION_CRASH requests can come from arbitrary processes and the tid field in the\n+  // request is sent from the other side. If an attacker can cause a process to be spawned with the\n+  // pid of their process, they could trick debuggerd into dumping that process by exiting after\n+  // sending the request. Validate the trusted request.uid/gid to defend against this.\n+  if (request.action == DEBUGGER_ACTION_CRASH) {\n+    pid_t pid;\n+    uid_t uid;\n+    gid_t gid;\n+    if (get_process_info(request.tid, &pid, &uid, &gid) != 0) {\n+      ALOGE(\"debuggerd: failed to get process info for tid '%d'\", request.tid);\n+      exit(1);\n+    }\n+\n+    if (pid != request.pid || uid != request.uid || gid != request.gid) {\n+      ALOGE(\n+        \"debuggerd: attached task %d does not match request: \"\n+        \"expected pid=%d,uid=%d,gid=%d, actual pid=%d,uid=%d,gid=%d\",\n+        request.tid, request.pid, request.uid, request.gid, pid, uid, gid);\n+      exit(1);\n+    }\n   }\n \n   // Don't attach to the sibling threads if we want to attach gdb.",
        "diff_line_info": {
            "deleted_lines": [
                "  if (ptrace(PTRACE_ATTACH, request.tid, 0, 0) != 0) {"
            ],
            "added_lines": [
                "  if (!ptrace_attach_thread(request.pid, request.tid)) {",
                "  }",
                "",
                "  // DEBUGGER_ACTION_CRASH requests can come from arbitrary processes and the tid field in the",
                "  // request is sent from the other side. If an attacker can cause a process to be spawned with the",
                "  // pid of their process, they could trick debuggerd into dumping that process by exiting after",
                "  // sending the request. Validate the trusted request.uid/gid to defend against this.",
                "  if (request.action == DEBUGGER_ACTION_CRASH) {",
                "    pid_t pid;",
                "    uid_t uid;",
                "    gid_t gid;",
                "    if (get_process_info(request.tid, &pid, &uid, &gid) != 0) {",
                "      ALOGE(\"debuggerd: failed to get process info for tid '%d'\", request.tid);",
                "      exit(1);",
                "    }",
                "",
                "    if (pid != request.pid || uid != request.uid || gid != request.gid) {",
                "      ALOGE(",
                "        \"debuggerd: attached task %d does not match request: \"",
                "        \"expected pid=%d,uid=%d,gid=%d, actual pid=%d,uid=%d,gid=%d\",",
                "        request.tid, request.pid, request.uid, request.gid, pid, uid, gid);",
                "      exit(1);",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3885",
        "func_name": "android/ptrace_siblings",
        "description": "debuggerd/debuggerd.cpp in Debuggerd in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-09-01, and 7.0 before 2016-09-01 mishandles the interaction between PTRACE_ATTACH operations and thread exits, which allows attackers to gain privileges via a crafted application, aka internal bug 29555636.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/d7603583f90c2bc6074a4ee2886bd28082d7c65b",
        "commit_title": "debuggerd: verify that traced threads belong to the right process.",
        "commit_text": " Fix two races in debuggerd's PTRACE_ATTACH logic:   1. The target thread in a crash dump request could exit between the      /proc/<pid>/task/<tid> check and the PTRACE_ATTACH.   2. Sibling threads could exit between listing /proc/<pid>/task and the      PTRACE_ATTACH.  Bug: http://b/29555636 ",
        "func_before": "static void ptrace_siblings(pid_t pid, pid_t main_tid, std::set<pid_t>& tids) {\n  char task_path[64];\n\n  snprintf(task_path, sizeof(task_path), \"/proc/%d/task\", pid);\n\n  std::unique_ptr<DIR, int (*)(DIR*)> d(opendir(task_path), closedir);\n\n  // Bail early if the task directory cannot be opened.\n  if (!d) {\n    ALOGE(\"debuggerd: failed to open /proc/%d/task: %s\", pid, strerror(errno));\n    return;\n  }\n\n  struct dirent* de;\n  while ((de = readdir(d.get())) != NULL) {\n    // Ignore \".\" and \"..\".\n    if (!strcmp(de->d_name, \".\") || !strcmp(de->d_name, \"..\")) {\n      continue;\n    }\n\n    char* end;\n    pid_t tid = strtoul(de->d_name, &end, 10);\n    if (*end) {\n      continue;\n    }\n\n    if (tid == main_tid) {\n      continue;\n    }\n\n    if (ptrace(PTRACE_ATTACH, tid, 0, 0) < 0) {\n      ALOGE(\"debuggerd: ptrace attach to %d failed: %s\", tid, strerror(errno));\n      continue;\n    }\n\n    tids.insert(tid);\n  }\n}",
        "func": "static void ptrace_siblings(pid_t pid, pid_t main_tid, std::set<pid_t>& tids) {\n  char task_path[PATH_MAX];\n\n  if (snprintf(task_path, PATH_MAX, \"/proc/%d/task\", pid) >= PATH_MAX) {\n    ALOGE(\"debuggerd: task path overflow (pid = %d)\\n\", pid);\n    abort();\n  }\n\n  std::unique_ptr<DIR, int (*)(DIR*)> d(opendir(task_path), closedir);\n\n  // Bail early if the task directory cannot be opened.\n  if (!d) {\n    ALOGE(\"debuggerd: failed to open /proc/%d/task: %s\", pid, strerror(errno));\n    return;\n  }\n\n  struct dirent* de;\n  while ((de = readdir(d.get())) != NULL) {\n    // Ignore \".\" and \"..\".\n    if (!strcmp(de->d_name, \".\") || !strcmp(de->d_name, \"..\")) {\n      continue;\n    }\n\n    char* end;\n    pid_t tid = strtoul(de->d_name, &end, 10);\n    if (*end) {\n      continue;\n    }\n\n    if (tid == main_tid) {\n      continue;\n    }\n\n    if (!ptrace_attach_thread(pid, tid)) {\n      ALOGE(\"debuggerd: ptrace attach to %d failed: %s\", tid, strerror(errno));\n      continue;\n    }\n\n    tids.insert(tid);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,10 @@\n static void ptrace_siblings(pid_t pid, pid_t main_tid, std::set<pid_t>& tids) {\n-  char task_path[64];\n+  char task_path[PATH_MAX];\n \n-  snprintf(task_path, sizeof(task_path), \"/proc/%d/task\", pid);\n+  if (snprintf(task_path, PATH_MAX, \"/proc/%d/task\", pid) >= PATH_MAX) {\n+    ALOGE(\"debuggerd: task path overflow (pid = %d)\\n\", pid);\n+    abort();\n+  }\n \n   std::unique_ptr<DIR, int (*)(DIR*)> d(opendir(task_path), closedir);\n \n@@ -28,7 +31,7 @@\n       continue;\n     }\n \n-    if (ptrace(PTRACE_ATTACH, tid, 0, 0) < 0) {\n+    if (!ptrace_attach_thread(pid, tid)) {\n       ALOGE(\"debuggerd: ptrace attach to %d failed: %s\", tid, strerror(errno));\n       continue;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "  char task_path[64];",
                "  snprintf(task_path, sizeof(task_path), \"/proc/%d/task\", pid);",
                "    if (ptrace(PTRACE_ATTACH, tid, 0, 0) < 0) {"
            ],
            "added_lines": [
                "  char task_path[PATH_MAX];",
                "  if (snprintf(task_path, PATH_MAX, \"/proc/%d/task\", pid) >= PATH_MAX) {",
                "    ALOGE(\"debuggerd: task path overflow (pid = %d)\\n\", pid);",
                "    abort();",
                "  }",
                "    if (!ptrace_attach_thread(pid, tid)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3890",
        "func_name": "android/local_socket_close",
        "description": "The Java Debug Wire Protocol (JDWP) implementation in adb/sockets.cpp in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-09-01 mishandles socket close operations, which allows attackers to gain privileges via a crafted application, aka internal bug 28347842.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/268068f25673242d1d5130d96202d3288c91b700",
        "commit_title": "adb: switch the socket list mutex to a recursive_mutex.",
        "commit_text": " sockets.cpp was branching on whether a socket close function was local_socket_close in order to avoid a potential deadlock if the socket list lock was held while closing a peer socket.  Bug: http://b/28347842 (cherry picked from commit 9b587dec6d0a57c8fe1083c1c543fbeb163d65fa) ",
        "func_before": "static void local_socket_close(asocket* s) {\n    adb_mutex_lock(&socket_list_lock);\n    local_socket_close_locked(s);\n    adb_mutex_unlock(&socket_list_lock);\n}",
        "func": "static void local_socket_close(asocket* s) {\n    D(\"entered local_socket_close. LS(%d) fd=%d\", s->id, s->fd);\n    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n    if (s->peer) {\n        D(\"LS(%d): closing peer. peer->id=%d peer->fd=%d\", s->id, s->peer->id, s->peer->fd);\n        /* Note: it's important to call shutdown before disconnecting from\n         * the peer, this ensures that remote sockets can still get the id\n         * of the local socket they're connected to, to send a CLOSE()\n         * protocol event. */\n        if (s->peer->shutdown) {\n            s->peer->shutdown(s->peer);\n        }\n        s->peer->peer = nullptr;\n        s->peer->close(s->peer);\n        s->peer = nullptr;\n    }\n\n    /* If we are already closing, or if there are no\n    ** pending packets, destroy immediately\n    */\n    if (s->closing || s->has_write_error || s->pkt_first == NULL) {\n        int id = s->id;\n        local_socket_destroy(s);\n        D(\"LS(%d): closed\", id);\n        return;\n    }\n\n    /* otherwise, put on the closing list\n    */\n    D(\"LS(%d): closing\", s->id);\n    s->closing = 1;\n    fdevent_del(&s->fde, FDE_READ);\n    remove_socket(s);\n    D(\"LS(%d): put on socket_closing_list fd=%d\", s->id, s->fd);\n    insert_local_socket(s, &local_socket_closing_list);\n    CHECK_EQ(FDE_WRITE, s->fde.state & FDE_WRITE);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,37 @@\n static void local_socket_close(asocket* s) {\n-    adb_mutex_lock(&socket_list_lock);\n-    local_socket_close_locked(s);\n-    adb_mutex_unlock(&socket_list_lock);\n+    D(\"entered local_socket_close. LS(%d) fd=%d\", s->id, s->fd);\n+    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n+    if (s->peer) {\n+        D(\"LS(%d): closing peer. peer->id=%d peer->fd=%d\", s->id, s->peer->id, s->peer->fd);\n+        /* Note: it's important to call shutdown before disconnecting from\n+         * the peer, this ensures that remote sockets can still get the id\n+         * of the local socket they're connected to, to send a CLOSE()\n+         * protocol event. */\n+        if (s->peer->shutdown) {\n+            s->peer->shutdown(s->peer);\n+        }\n+        s->peer->peer = nullptr;\n+        s->peer->close(s->peer);\n+        s->peer = nullptr;\n+    }\n+\n+    /* If we are already closing, or if there are no\n+    ** pending packets, destroy immediately\n+    */\n+    if (s->closing || s->has_write_error || s->pkt_first == NULL) {\n+        int id = s->id;\n+        local_socket_destroy(s);\n+        D(\"LS(%d): closed\", id);\n+        return;\n+    }\n+\n+    /* otherwise, put on the closing list\n+    */\n+    D(\"LS(%d): closing\", s->id);\n+    s->closing = 1;\n+    fdevent_del(&s->fde, FDE_READ);\n+    remove_socket(s);\n+    D(\"LS(%d): put on socket_closing_list fd=%d\", s->id, s->fd);\n+    insert_local_socket(s, &local_socket_closing_list);\n+    CHECK_EQ(FDE_WRITE, s->fde.state & FDE_WRITE);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    adb_mutex_lock(&socket_list_lock);",
                "    local_socket_close_locked(s);",
                "    adb_mutex_unlock(&socket_list_lock);"
            ],
            "added_lines": [
                "    D(\"entered local_socket_close. LS(%d) fd=%d\", s->id, s->fd);",
                "    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);",
                "    if (s->peer) {",
                "        D(\"LS(%d): closing peer. peer->id=%d peer->fd=%d\", s->id, s->peer->id, s->peer->fd);",
                "        /* Note: it's important to call shutdown before disconnecting from",
                "         * the peer, this ensures that remote sockets can still get the id",
                "         * of the local socket they're connected to, to send a CLOSE()",
                "         * protocol event. */",
                "        if (s->peer->shutdown) {",
                "            s->peer->shutdown(s->peer);",
                "        }",
                "        s->peer->peer = nullptr;",
                "        s->peer->close(s->peer);",
                "        s->peer = nullptr;",
                "    }",
                "",
                "    /* If we are already closing, or if there are no",
                "    ** pending packets, destroy immediately",
                "    */",
                "    if (s->closing || s->has_write_error || s->pkt_first == NULL) {",
                "        int id = s->id;",
                "        local_socket_destroy(s);",
                "        D(\"LS(%d): closed\", id);",
                "        return;",
                "    }",
                "",
                "    /* otherwise, put on the closing list",
                "    */",
                "    D(\"LS(%d): closing\", s->id);",
                "    s->closing = 1;",
                "    fdevent_del(&s->fde, FDE_READ);",
                "    remove_socket(s);",
                "    D(\"LS(%d): put on socket_closing_list fd=%d\", s->id, s->fd);",
                "    insert_local_socket(s, &local_socket_closing_list);",
                "    CHECK_EQ(FDE_WRITE, s->fde.state & FDE_WRITE);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3890",
        "func_name": "android/close_all_sockets",
        "description": "The Java Debug Wire Protocol (JDWP) implementation in adb/sockets.cpp in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-09-01 mishandles socket close operations, which allows attackers to gain privileges via a crafted application, aka internal bug 28347842.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/268068f25673242d1d5130d96202d3288c91b700",
        "commit_title": "adb: switch the socket list mutex to a recursive_mutex.",
        "commit_text": " sockets.cpp was branching on whether a socket close function was local_socket_close in order to avoid a potential deadlock if the socket list lock was held while closing a peer socket.  Bug: http://b/28347842 (cherry picked from commit 9b587dec6d0a57c8fe1083c1c543fbeb163d65fa) ",
        "func_before": "void close_all_sockets(atransport* t) {\n    asocket* s;\n\n    /* this is a little gross, but since s->close() *will* modify\n    ** the list out from under you, your options are limited.\n    */\n    adb_mutex_lock(&socket_list_lock);\nrestart:\n    for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n        if (s->transport == t || (s->peer && s->peer->transport == t)) {\n            local_socket_close_locked(s);\n            goto restart;\n        }\n    }\n    adb_mutex_unlock(&socket_list_lock);\n}",
        "func": "void close_all_sockets(atransport* t) {\n    asocket* s;\n\n    /* this is a little gross, but since s->close() *will* modify\n    ** the list out from under you, your options are limited.\n    */\n    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\nrestart:\n    for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n        if (s->transport == t || (s->peer && s->peer->transport == t)) {\n            local_socket_close(s);\n            goto restart;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,13 +4,12 @@\n     /* this is a little gross, but since s->close() *will* modify\n     ** the list out from under you, your options are limited.\n     */\n-    adb_mutex_lock(&socket_list_lock);\n+    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n restart:\n     for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n         if (s->transport == t || (s->peer && s->peer->transport == t)) {\n-            local_socket_close_locked(s);\n+            local_socket_close(s);\n             goto restart;\n         }\n     }\n-    adb_mutex_unlock(&socket_list_lock);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    adb_mutex_lock(&socket_list_lock);",
                "            local_socket_close_locked(s);",
                "    adb_mutex_unlock(&socket_list_lock);"
            ],
            "added_lines": [
                "    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);",
                "            local_socket_close(s);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3890",
        "func_name": "android/install_local_socket",
        "description": "The Java Debug Wire Protocol (JDWP) implementation in adb/sockets.cpp in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-09-01 mishandles socket close operations, which allows attackers to gain privileges via a crafted application, aka internal bug 28347842.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/268068f25673242d1d5130d96202d3288c91b700",
        "commit_title": "adb: switch the socket list mutex to a recursive_mutex.",
        "commit_text": " sockets.cpp was branching on whether a socket close function was local_socket_close in order to avoid a potential deadlock if the socket list lock was held while closing a peer socket.  Bug: http://b/28347842 (cherry picked from commit 9b587dec6d0a57c8fe1083c1c543fbeb163d65fa) ",
        "func_before": "void install_local_socket(asocket* s) {\n    adb_mutex_lock(&socket_list_lock);\n\n    s->id = local_socket_next_id++;\n\n    // Socket ids should never be 0.\n    if (local_socket_next_id == 0) {\n        local_socket_next_id = 1;\n    }\n\n    insert_local_socket(s, &local_socket_list);\n\n    adb_mutex_unlock(&socket_list_lock);\n}",
        "func": "void install_local_socket(asocket* s) {\n    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n\n    s->id = local_socket_next_id++;\n\n    // Socket ids should never be 0.\n    if (local_socket_next_id == 0) {\n        fatal(\"local socket id overflow\");\n    }\n\n    insert_local_socket(s, &local_socket_list);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,14 +1,12 @@\n void install_local_socket(asocket* s) {\n-    adb_mutex_lock(&socket_list_lock);\n+    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n \n     s->id = local_socket_next_id++;\n \n     // Socket ids should never be 0.\n     if (local_socket_next_id == 0) {\n-        local_socket_next_id = 1;\n+        fatal(\"local socket id overflow\");\n     }\n \n     insert_local_socket(s, &local_socket_list);\n-\n-    adb_mutex_unlock(&socket_list_lock);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    adb_mutex_lock(&socket_list_lock);",
                "        local_socket_next_id = 1;",
                "",
                "    adb_mutex_unlock(&socket_list_lock);"
            ],
            "added_lines": [
                "    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);",
                "        fatal(\"local socket id overflow\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3890",
        "func_name": "android/find_local_socket",
        "description": "The Java Debug Wire Protocol (JDWP) implementation in adb/sockets.cpp in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-09-01 mishandles socket close operations, which allows attackers to gain privileges via a crafted application, aka internal bug 28347842.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/268068f25673242d1d5130d96202d3288c91b700",
        "commit_title": "adb: switch the socket list mutex to a recursive_mutex.",
        "commit_text": " sockets.cpp was branching on whether a socket close function was local_socket_close in order to avoid a potential deadlock if the socket list lock was held while closing a peer socket.  Bug: http://b/28347842 (cherry picked from commit 9b587dec6d0a57c8fe1083c1c543fbeb163d65fa) ",
        "func_before": "asocket* find_local_socket(unsigned local_id, unsigned peer_id) {\n    asocket* s;\n    asocket* result = NULL;\n\n    adb_mutex_lock(&socket_list_lock);\n    for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n        if (s->id != local_id) {\n            continue;\n        }\n        if (peer_id == 0 || (s->peer && s->peer->id == peer_id)) {\n            result = s;\n        }\n        break;\n    }\n    adb_mutex_unlock(&socket_list_lock);\n\n    return result;\n}",
        "func": "asocket* find_local_socket(unsigned local_id, unsigned peer_id) {\n    asocket* s;\n    asocket* result = NULL;\n\n    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n    for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n        if (s->id != local_id) {\n            continue;\n        }\n        if (peer_id == 0 || (s->peer && s->peer->id == peer_id)) {\n            result = s;\n        }\n        break;\n    }\n\n    return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n     asocket* s;\n     asocket* result = NULL;\n \n-    adb_mutex_lock(&socket_list_lock);\n+    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\n     for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n         if (s->id != local_id) {\n             continue;\n@@ -12,7 +12,6 @@\n         }\n         break;\n     }\n-    adb_mutex_unlock(&socket_list_lock);\n \n     return result;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    adb_mutex_lock(&socket_list_lock);",
                "    adb_mutex_unlock(&socket_list_lock);"
            ],
            "added_lines": [
                "    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3890",
        "func_name": "android/close_all_sockets",
        "description": "The Java Debug Wire Protocol (JDWP) implementation in adb/sockets.cpp in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, and 6.x before 2016-09-01 mishandles socket close operations, which allows attackers to gain privileges via a crafted application, aka internal bug 28347842.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/014b01706cc64dc9c2ad94a96f62e07c058d0b5d",
        "commit_title": "adb: use asocket's close function when closing.",
        "commit_text": " close_all_sockets was assuming that all registered local sockets used local_socket_close as their close function. However, this is not true for JDWP sockets.  Bug: http://b/28347842 (cherry picked from commit 53eb31d87cb84a4212f4850bf745646e1fb12814) ",
        "func_before": "void close_all_sockets(atransport* t) {\n    asocket* s;\n\n    /* this is a little gross, but since s->close() *will* modify\n    ** the list out from under you, your options are limited.\n    */\n    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\nrestart:\n    for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n        if (s->transport == t || (s->peer && s->peer->transport == t)) {\n            local_socket_close(s);\n            goto restart;\n        }\n    }\n}",
        "func": "void close_all_sockets(atransport* t) {\n    asocket* s;\n\n    /* this is a little gross, but since s->close() *will* modify\n    ** the list out from under you, your options are limited.\n    */\n    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);\nrestart:\n    for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n        if (s->transport == t || (s->peer && s->peer->transport == t)) {\n            s->close(s);\n            goto restart;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n restart:\n     for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {\n         if (s->transport == t || (s->peer && s->peer->transport == t)) {\n-            local_socket_close(s);\n+            s->close(s);\n             goto restart;\n         }\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "            local_socket_close(s);"
            ],
            "added_lines": [
                "            s->close(s);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7092",
        "func_name": "xen-project/xen/get_page_from_l3e",
        "description": "The get_page_from_l3e function in arch/x86/mm.c in Xen allows local 32-bit PV guest OS administrators to gain host OS privileges via vectors related to L3 recursive pagetables.",
        "git_url": "https://github.com/xen-project/xen/commit/c844d637d92a75854ea5c8d4e5ca34302a9f623c",
        "commit_title": "x86/32on64: don't allow recursive page tables from L3",
        "commit_text": " L3 entries are special in PAE mode, and hence can't reasonably be used for setting up recursive (and hence linear) page table mappings. Since abuse is possible when the guest in fact gets run on 4-level page tables, this needs to be excluded explicitly.  This is XSA-185 / CVE-2016-7092. ",
        "func_before": "static int\nget_page_from_l3e(\n    l3_pgentry_t l3e, unsigned long pfn, struct domain *d, int partial)\n{\n    int rc;\n\n    if ( !(l3e_get_flags(l3e) & _PAGE_PRESENT) )\n        return 1;\n\n    if ( unlikely((l3e_get_flags(l3e) & l3_disallow_mask(d))) )\n    {\n        MEM_LOG(\"Bad L3 flags %x\", l3e_get_flags(l3e) & l3_disallow_mask(d));\n        return -EINVAL;\n    }\n\n    rc = get_page_and_type_from_pagenr(\n        l3e_get_pfn(l3e), PGT_l2_page_table, d, partial, 1);\n    if ( unlikely(rc == -EINVAL) && get_l3_linear_pagetable(l3e, pfn, d) )\n        rc = 0;\n\n    return rc;\n}",
        "func": "static int\nget_page_from_l3e(\n    l3_pgentry_t l3e, unsigned long pfn, struct domain *d, int partial)\n{\n    int rc;\n\n    if ( !(l3e_get_flags(l3e) & _PAGE_PRESENT) )\n        return 1;\n\n    if ( unlikely((l3e_get_flags(l3e) & l3_disallow_mask(d))) )\n    {\n        MEM_LOG(\"Bad L3 flags %x\", l3e_get_flags(l3e) & l3_disallow_mask(d));\n        return -EINVAL;\n    }\n\n    rc = get_page_and_type_from_pagenr(\n        l3e_get_pfn(l3e), PGT_l2_page_table, d, partial, 1);\n    if ( unlikely(rc == -EINVAL) &&\n         !is_pv_32bit_domain(d) &&\n         get_l3_linear_pagetable(l3e, pfn, d) )\n        rc = 0;\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,9 @@\n \n     rc = get_page_and_type_from_pagenr(\n         l3e_get_pfn(l3e), PGT_l2_page_table, d, partial, 1);\n-    if ( unlikely(rc == -EINVAL) && get_l3_linear_pagetable(l3e, pfn, d) )\n+    if ( unlikely(rc == -EINVAL) &&\n+         !is_pv_32bit_domain(d) &&\n+         get_l3_linear_pagetable(l3e, pfn, d) )\n         rc = 0;\n \n     return rc;",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( unlikely(rc == -EINVAL) && get_l3_linear_pagetable(l3e, pfn, d) )"
            ],
            "added_lines": [
                "    if ( unlikely(rc == -EINVAL) &&",
                "         !is_pv_32bit_domain(d) &&",
                "         get_l3_linear_pagetable(l3e, pfn, d) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7142",
        "func_name": "inspircd/CommandAuthenticate",
        "description": "The m_sasl module in InspIRCd before 2.0.23, when used with a service that supports SASL_EXTERNAL authentication, allows remote attackers to spoof certificate fingerprints and consequently log in as another user via a crafted SASL message.",
        "git_url": "https://github.com/inspircd/inspircd/commit/74fafb7f11b06747f69f182ad5e3769b665eea7a",
        "commit_title": "m_sasl: don't allow AUTHENTICATE with mechanisms with a space",
        "commit_text": "",
        "func_before": "CommandAuthenticate(Module* Creator, SimpleExtItem<SaslAuthenticator>& ext, GenericCap& Cap)\n\t\t: Command(Creator, \"AUTHENTICATE\", 1), authExt(ext), cap(Cap)\n\t{\n\t\tworks_before_reg = true;\n\t}",
        "func": "CommandAuthenticate(Module* Creator, SimpleExtItem<SaslAuthenticator>& ext, GenericCap& Cap)\n\t\t: Command(Creator, \"AUTHENTICATE\", 1), authExt(ext), cap(Cap)\n\t{\n\t\tworks_before_reg = true;\n\t\tallow_empty_last_param = false;\n\t}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,4 +2,5 @@\n \t\t: Command(Creator, \"AUTHENTICATE\", 1), authExt(ext), cap(Cap)\n \t{\n \t\tworks_before_reg = true;\n+\t\tallow_empty_last_param = false;\n \t}",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tallow_empty_last_param = false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3699",
        "func_name": "mjg59/linux/acpi_initrd_override",
        "description": "The Linux kernel, as used in Red Hat Enterprise Linux 7.2 and Red Hat Enterprise MRG 2 and when booted with UEFI Secure Boot enabled, allows local users to bypass intended Secure Boot restrictions and execute untrusted code by appending ACPI tables to the initrd.",
        "git_url": "https://github.com/mjg59/linux/commit/a4a5ed2835e8ea042868b7401dced3f517cafa76",
        "commit_title": "acpi: Disable ACPI table override if securelevel is set",
        "commit_text": " From the kernel documentation (initrd_table_override.txt):    If the ACPI_INITRD_TABLE_OVERRIDE compile option is true, it is possible   to override nearly any ACPI table provided by the BIOS with an   instrumented, modified one.  When securelevel is set, the kernel should disallow any unauthenticated changes to kernel space. ACPI tables contain code invoked by the kernel, so do not allow ACPI tables to be overridden if securelevel is set. ",
        "func_before": "void __init acpi_initrd_override(void *data, size_t size)\n{\n\tint sig, no, table_nr = 0, total_offset = 0;\n\tlong offset = 0;\n\tstruct acpi_table_header *table;\n\tchar cpio_path[32] = \"kernel/firmware/acpi/\";\n\tstruct cpio_data file;\n\n\tif (data == NULL || size == 0)\n\t\treturn;\n\n\tfor (no = 0; no < ACPI_OVERRIDE_TABLES; no++) {\n\t\tfile = find_cpio_data(cpio_path, data, size, &offset);\n\t\tif (!file.data)\n\t\t\tbreak;\n\n\t\tdata += offset;\n\t\tsize -= offset;\n\n\t\tif (file.size < sizeof(struct acpi_table_header)) {\n\t\t\tpr_err(\"ACPI OVERRIDE: Table smaller than ACPI header [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\n\t\ttable = file.data;\n\n\t\tfor (sig = 0; table_sigs[sig]; sig++)\n\t\t\tif (!memcmp(table->signature, table_sigs[sig], 4))\n\t\t\t\tbreak;\n\n\t\tif (!table_sigs[sig]) {\n\t\t\tpr_err(\"ACPI OVERRIDE: Unknown signature [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (file.size != table->length) {\n\t\t\tpr_err(\"ACPI OVERRIDE: File length does not match table length [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (acpi_table_checksum(file.data, table->length)) {\n\t\t\tpr_err(\"ACPI OVERRIDE: Bad table checksum [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tpr_info(\"%4.4s ACPI table found in initrd [%s%s][0x%x]\\n\",\n\t\t\ttable->signature, cpio_path, file.name, table->length);\n\n\t\tall_tables_size += table->length;\n\t\tacpi_initrd_files[table_nr].data = file.data;\n\t\tacpi_initrd_files[table_nr].size = file.size;\n\t\ttable_nr++;\n\t}\n\tif (table_nr == 0)\n\t\treturn;\n\n\tacpi_tables_addr =\n\t\tmemblock_find_in_range(0, max_low_pfn_mapped << PAGE_SHIFT,\n\t\t\t\t       all_tables_size, PAGE_SIZE);\n\tif (!acpi_tables_addr) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\t/*\n\t * Only calling e820_add_reserve does not work and the\n\t * tables are invalid (memory got used) later.\n\t * memblock_reserve works as expected and the tables won't get modified.\n\t * But it's not enough on X86 because ioremap will\n\t * complain later (used by acpi_os_map_memory) that the pages\n\t * that should get mapped are not marked \"reserved\".\n\t * Both memblock_reserve and e820_add_region (via arch_reserve_mem_area)\n\t * works fine.\n\t */\n\tmemblock_reserve(acpi_tables_addr, all_tables_size);\n\tarch_reserve_mem_area(acpi_tables_addr, all_tables_size);\n\n\t/*\n\t * early_ioremap only can remap 256k one time. If we map all\n\t * tables one time, we will hit the limit. Need to map chunks\n\t * one by one during copying the same as that in relocate_initrd().\n\t */\n\tfor (no = 0; no < table_nr; no++) {\n\t\tunsigned char *src_p = acpi_initrd_files[no].data;\n\t\tphys_addr_t size = acpi_initrd_files[no].size;\n\t\tphys_addr_t dest_addr = acpi_tables_addr + total_offset;\n\t\tphys_addr_t slop, clen;\n\t\tchar *dest_p;\n\n\t\ttotal_offset += size;\n\n\t\twhile (size) {\n\t\t\tslop = dest_addr & ~PAGE_MASK;\n\t\t\tclen = size;\n\t\t\tif (clen > MAP_CHUNK_SIZE - slop)\n\t\t\t\tclen = MAP_CHUNK_SIZE - slop;\n\t\t\tdest_p = early_ioremap(dest_addr & PAGE_MASK,\n\t\t\t\t\t\t clen + slop);\n\t\t\tmemcpy(dest_p + slop, src_p, clen);\n\t\t\tearly_iounmap(dest_p, clen + slop);\n\t\t\tsrc_p += clen;\n\t\t\tdest_addr += clen;\n\t\t\tsize -= clen;\n\t\t}\n\t}\n}",
        "func": "void __init acpi_initrd_override(void *data, size_t size)\n{\n\tint sig, no, table_nr = 0, total_offset = 0;\n\tlong offset = 0;\n\tstruct acpi_table_header *table;\n\tchar cpio_path[32] = \"kernel/firmware/acpi/\";\n\tstruct cpio_data file;\n\n\tif (data == NULL || size == 0)\n\t\treturn;\n\n\tfor (no = 0; no < ACPI_OVERRIDE_TABLES; no++) {\n\t\tfile = find_cpio_data(cpio_path, data, size, &offset);\n\t\tif (!file.data)\n\t\t\tbreak;\n\n\t\tdata += offset;\n\t\tsize -= offset;\n\n\t\tif (file.size < sizeof(struct acpi_table_header)) {\n\t\t\tpr_err(\"ACPI OVERRIDE: Table smaller than ACPI header [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\n\t\ttable = file.data;\n\n\t\tfor (sig = 0; table_sigs[sig]; sig++)\n\t\t\tif (!memcmp(table->signature, table_sigs[sig], 4))\n\t\t\t\tbreak;\n\n\t\tif (!table_sigs[sig]) {\n\t\t\tpr_err(\"ACPI OVERRIDE: Unknown signature [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (file.size != table->length) {\n\t\t\tpr_err(\"ACPI OVERRIDE: File length does not match table length [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (acpi_table_checksum(file.data, table->length)) {\n\t\t\tpr_err(\"ACPI OVERRIDE: Bad table checksum [%s%s]\\n\",\n\t\t\t\tcpio_path, file.name);\n\t\t\tcontinue;\n\t\t}\n\n\t\tpr_info(\"%4.4s ACPI table found in initrd [%s%s][0x%x]\\n\",\n\t\t\ttable->signature, cpio_path, file.name, table->length);\n\n\t\tall_tables_size += table->length;\n\t\tacpi_initrd_files[table_nr].data = file.data;\n\t\tacpi_initrd_files[table_nr].size = file.size;\n\t\ttable_nr++;\n\t}\n\tif (table_nr == 0)\n\t\treturn;\n\n\tif (get_securelevel() > 0) {\n\t\tpr_notice(PREFIX\n\t\t\t\"securelevel enabled, ignoring table override\\n\");\n\t\treturn;\n\t}\n\n\tacpi_tables_addr =\n\t\tmemblock_find_in_range(0, max_low_pfn_mapped << PAGE_SHIFT,\n\t\t\t\t       all_tables_size, PAGE_SIZE);\n\tif (!acpi_tables_addr) {\n\t\tWARN_ON(1);\n\t\treturn;\n\t}\n\t/*\n\t * Only calling e820_add_reserve does not work and the\n\t * tables are invalid (memory got used) later.\n\t * memblock_reserve works as expected and the tables won't get modified.\n\t * But it's not enough on X86 because ioremap will\n\t * complain later (used by acpi_os_map_memory) that the pages\n\t * that should get mapped are not marked \"reserved\".\n\t * Both memblock_reserve and e820_add_region (via arch_reserve_mem_area)\n\t * works fine.\n\t */\n\tmemblock_reserve(acpi_tables_addr, all_tables_size);\n\tarch_reserve_mem_area(acpi_tables_addr, all_tables_size);\n\n\t/*\n\t * early_ioremap only can remap 256k one time. If we map all\n\t * tables one time, we will hit the limit. Need to map chunks\n\t * one by one during copying the same as that in relocate_initrd().\n\t */\n\tfor (no = 0; no < table_nr; no++) {\n\t\tunsigned char *src_p = acpi_initrd_files[no].data;\n\t\tphys_addr_t size = acpi_initrd_files[no].size;\n\t\tphys_addr_t dest_addr = acpi_tables_addr + total_offset;\n\t\tphys_addr_t slop, clen;\n\t\tchar *dest_p;\n\n\t\ttotal_offset += size;\n\n\t\twhile (size) {\n\t\t\tslop = dest_addr & ~PAGE_MASK;\n\t\t\tclen = size;\n\t\t\tif (clen > MAP_CHUNK_SIZE - slop)\n\t\t\t\tclen = MAP_CHUNK_SIZE - slop;\n\t\t\tdest_p = early_ioremap(dest_addr & PAGE_MASK,\n\t\t\t\t\t\t clen + slop);\n\t\t\tmemcpy(dest_p + slop, src_p, clen);\n\t\t\tearly_iounmap(dest_p, clen + slop);\n\t\t\tsrc_p += clen;\n\t\t\tdest_addr += clen;\n\t\t\tsize -= clen;\n\t\t}\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,6 +56,12 @@\n \tif (table_nr == 0)\n \t\treturn;\n \n+\tif (get_securelevel() > 0) {\n+\t\tpr_notice(PREFIX\n+\t\t\t\"securelevel enabled, ignoring table override\\n\");\n+\t\treturn;\n+\t}\n+\n \tacpi_tables_addr =\n \t\tmemblock_find_in_range(0, max_low_pfn_mapped << PAGE_SHIFT,\n \t\t\t\t       all_tables_size, PAGE_SIZE);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (get_securelevel() > 0) {",
                "\t\tpr_notice(PREFIX",
                "\t\t\t\"securelevel enabled, ignoring table override\\n\");",
                "\t\treturn;",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3699",
        "func_name": "mjg59/linux/setup_arch",
        "description": "The Linux kernel, as used in Red Hat Enterprise Linux 7.2 and Red Hat Enterprise MRG 2 and when booted with UEFI Secure Boot enabled, allows local users to bypass intended Secure Boot restrictions and execute untrusted code by appending ACPI tables to the initrd.",
        "git_url": "https://github.com/mjg59/linux/commit/a4a5ed2835e8ea042868b7401dced3f517cafa76",
        "commit_title": "acpi: Disable ACPI table override if securelevel is set",
        "commit_text": " From the kernel documentation (initrd_table_override.txt):    If the ACPI_INITRD_TABLE_OVERRIDE compile option is true, it is possible   to override nearly any ACPI table provided by the BIOS with an   instrumented, modified one.  When securelevel is set, the kernel should disallow any unauthenticated changes to kernel space. ACPI tables contain code invoked by the kernel, so do not allow ACPI tables to be overridden if securelevel is set. ",
        "func_before": "void __init setup_arch(char **cmdline_p)\n{\n\tmemblock_reserve(__pa_symbol(_text),\n\t\t\t (unsigned long)__bss_stop - (unsigned long)_text);\n\n\tearly_reserve_initrd();\n\n\t/*\n\t * At this point everything still needed from the boot loader\n\t * or BIOS or kernel text should be early reserved or marked not\n\t * RAM in e820. All other memory is free game.\n\t */\n\n#ifdef CONFIG_X86_32\n\tmemcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));\n\n\t/*\n\t * copy kernel address range established so far and switch\n\t * to the proper swapper page table\n\t */\n\tclone_pgd_range(swapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tinitial_page_table + KERNEL_PGD_BOUNDARY,\n\t\t\tKERNEL_PGD_PTRS);\n\n\tload_cr3(swapper_pg_dir);\n\t/*\n\t * Note: Quark X1000 CPUs advertise PGE incorrectly and require\n\t * a cr3 based tlb flush, so the following __flush_tlb_all()\n\t * will not flush anything because the cpu quirk which clears\n\t * X86_FEATURE_PGE has not been invoked yet. Though due to the\n\t * load_cr3() above the TLB has been flushed already. The\n\t * quirk is invoked before subsequent calls to __flush_tlb_all()\n\t * so proper operation is guaranteed.\n\t */\n\t__flush_tlb_all();\n#else\n\tprintk(KERN_INFO \"Command line: %s\\n\", boot_command_line);\n#endif\n\n\t/*\n\t * If we have OLPC OFW, we might end up relocating the fixmap due to\n\t * reserve_top(), so do this before touching the ioremap area.\n\t */\n\tolpc_ofw_detect();\n\n\tearly_trap_init();\n\tearly_cpu_init();\n\tearly_ioremap_init();\n\n\tsetup_olpc_ofw_pgd();\n\n\tROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);\n\tscreen_info = boot_params.screen_info;\n\tedid_info = boot_params.edid_info;\n#ifdef CONFIG_X86_32\n\tapm_info.bios = boot_params.apm_bios_info;\n\tist_info = boot_params.ist_info;\n#endif\n\tsaved_video_mode = boot_params.hdr.vid_mode;\n\tbootloader_type = boot_params.hdr.type_of_loader;\n\tif ((bootloader_type >> 4) == 0xe) {\n\t\tbootloader_type &= 0xf;\n\t\tbootloader_type |= (boot_params.hdr.ext_loader_type+0x10) << 4;\n\t}\n\tbootloader_version  = bootloader_type & 0xf;\n\tbootloader_version |= boot_params.hdr.ext_loader_ver << 4;\n\n#ifdef CONFIG_BLK_DEV_RAM\n\trd_image_start = boot_params.hdr.ram_size & RAMDISK_IMAGE_START_MASK;\n\trd_prompt = ((boot_params.hdr.ram_size & RAMDISK_PROMPT_FLAG) != 0);\n\trd_doload = ((boot_params.hdr.ram_size & RAMDISK_LOAD_FLAG) != 0);\n#endif\n#ifdef CONFIG_EFI\n\tif (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,\n\t\t     EFI32_LOADER_SIGNATURE, 4)) {\n\t\tset_bit(EFI_BOOT, &efi.flags);\n\t} else if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,\n\t\t     EFI64_LOADER_SIGNATURE, 4)) {\n\t\tset_bit(EFI_BOOT, &efi.flags);\n\t\tset_bit(EFI_64BIT, &efi.flags);\n\t}\n\n\tif (efi_enabled(EFI_BOOT))\n\t\tefi_memblock_x86_reserve_range();\n#endif\n\n\tx86_init.oem.arch_setup();\n\n\tiomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;\n\tsetup_memory_map();\n\tparse_setup_data();\n\n\tcopy_edd();\n\n\tif (!boot_params.hdr.root_flags)\n\t\troot_mountflags &= ~MS_RDONLY;\n\tinit_mm.start_code = (unsigned long) _text;\n\tinit_mm.end_code = (unsigned long) _etext;\n\tinit_mm.end_data = (unsigned long) _edata;\n\tinit_mm.brk = _brk_end;\n\n\tmpx_mm_init(&init_mm);\n\n\tcode_resource.start = __pa_symbol(_text);\n\tcode_resource.end = __pa_symbol(_etext)-1;\n\tdata_resource.start = __pa_symbol(_etext);\n\tdata_resource.end = __pa_symbol(_edata)-1;\n\tbss_resource.start = __pa_symbol(__bss_start);\n\tbss_resource.end = __pa_symbol(__bss_stop)-1;\n\n#ifdef CONFIG_CMDLINE_BOOL\n#ifdef CONFIG_CMDLINE_OVERRIDE\n\tstrlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);\n#else\n\tif (builtin_cmdline[0]) {\n\t\t/* append boot loader cmdline to builtin */\n\t\tstrlcat(builtin_cmdline, \" \", COMMAND_LINE_SIZE);\n\t\tstrlcat(builtin_cmdline, boot_command_line, COMMAND_LINE_SIZE);\n\t\tstrlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);\n\t}\n#endif\n#endif\n\n\tstrlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);\n\t*cmdline_p = command_line;\n\n\t/*\n\t * x86_configure_nx() is called before parse_early_param() to detect\n\t * whether hardware doesn't support NX (so that the early EHCI debug\n\t * console setup can safely call set_fixmap()). It may then be called\n\t * again from within noexec_setup() during parsing early parameters\n\t * to honor the respective command line option.\n\t */\n\tx86_configure_nx();\n\n\tparse_early_param();\n\n\tx86_report_nx();\n\n\t/* after early param, so could get panic from serial */\n\tmemblock_x86_reserve_range_setup_data();\n\n\tif (acpi_mps_check()) {\n#ifdef CONFIG_X86_LOCAL_APIC\n\t\tdisable_apic = 1;\n#endif\n\t\tsetup_clear_cpu_cap(X86_FEATURE_APIC);\n\t}\n\n#ifdef CONFIG_PCI\n\tif (pci_early_dump_regs)\n\t\tearly_dump_pci_devices();\n#endif\n\n\t/* update the e820_saved too */\n\te820_reserve_setup_data();\n\tfinish_e820_parsing();\n\n\tif (efi_enabled(EFI_BOOT))\n\t\tefi_init();\n\n\tdmi_scan_machine();\n\tdmi_memdev_walk();\n\tdmi_set_dump_stack_arch_desc();\n\n\t/*\n\t * VMware detection requires dmi to be available, so this\n\t * needs to be done after dmi_scan_machine, for the BP.\n\t */\n\tinit_hypervisor_platform();\n\n\tx86_init.resources.probe_roms();\n\n\t/* after parse_early_param, so could debug it */\n\tinsert_resource(&iomem_resource, &code_resource);\n\tinsert_resource(&iomem_resource, &data_resource);\n\tinsert_resource(&iomem_resource, &bss_resource);\n\n\te820_add_kernel_range();\n\ttrim_bios_range();\n#ifdef CONFIG_X86_32\n\tif (ppro_with_ram_bug()) {\n\t\te820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,\n\t\t\t\t  E820_RESERVED);\n\t\tsanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);\n\t\tprintk(KERN_INFO \"fixed physical RAM map:\\n\");\n\t\te820_print_map(\"bad_ppro\");\n\t}\n#else\n\tearly_gart_iommu_check();\n#endif\n\n\t/*\n\t * partially used pages are not usable - thus\n\t * we are rounding upwards:\n\t */\n\tmax_pfn = e820_end_of_ram_pfn();\n\n\t/* update e820 for memory not covered by WB MTRRs */\n\tmtrr_bp_init();\n\tif (mtrr_trim_uncached_memory(max_pfn))\n\t\tmax_pfn = e820_end_of_ram_pfn();\n\n\tmax_possible_pfn = max_pfn;\n\n#ifdef CONFIG_X86_32\n\t/* max_low_pfn get updated here */\n\tfind_low_pfn_range();\n#else\n\tcheck_x2apic();\n\n\t/* How many end-of-memory variables you have, grandma! */\n\t/* need this before calling reserve_initrd */\n\tif (max_pfn > (1UL<<(32 - PAGE_SHIFT)))\n\t\tmax_low_pfn = e820_end_of_low_ram_pfn();\n\telse\n\t\tmax_low_pfn = max_pfn;\n\n\thigh_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;\n#endif\n\n\t/*\n\t * Find and reserve possible boot-time SMP configuration:\n\t */\n\tfind_smp_config();\n\n\treserve_ibft_region();\n\n\tearly_alloc_pgt_buf();\n\n\t/*\n\t * Need to conclude brk, before memblock_x86_fill()\n\t *  it could use memblock_find_in_range, could overlap with\n\t *  brk area.\n\t */\n\treserve_brk();\n\n\tcleanup_highmap();\n\n\tmemblock_set_current_limit(ISA_END_ADDRESS);\n\tmemblock_x86_fill();\n\n\tif (efi_enabled(EFI_BOOT)) {\n\t\tefi_fake_memmap();\n\t\tefi_find_mirror();\n\t}\n\n\t/*\n\t * The EFI specification says that boot service code won't be called\n\t * after ExitBootServices(). This is, in fact, a lie.\n\t */\n\tif (efi_enabled(EFI_MEMMAP))\n\t\tefi_reserve_boot_services();\n\n\t/* preallocate 4k for mptable mpc */\n\tearly_reserve_e820_mpc_new();\n\n#ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION\n\tsetup_bios_corruption_check();\n#endif\n\n#ifdef CONFIG_X86_32\n\tprintk(KERN_DEBUG \"initial memory mapped: [mem 0x00000000-%#010lx]\\n\",\n\t\t\t(max_pfn_mapped<<PAGE_SHIFT) - 1);\n#endif\n\n\treserve_real_mode();\n\n\ttrim_platform_memory_ranges();\n\ttrim_low_memory_range();\n\n\tinit_mem_mapping();\n\n\tearly_trap_pf_init();\n\n\tsetup_real_mode();\n\n\tmemblock_set_current_limit(get_max_mapped());\n\n\t/*\n\t * NOTE: On x86-32, only from this point on, fixmaps are ready for use.\n\t */\n\n#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT\n\tif (init_ohci1394_dma_early)\n\t\tinit_ohci1394_dma_on_all_controllers();\n#endif\n\t/* Allocate bigger log buffer */\n\tsetup_log_buf(1);\n\n\treserve_initrd();\n\n#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)\n\tacpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);\n#endif\n\n\tvsmp_init();\n\n\tio_delay_init();\n\n#ifdef CONFIG_EFI_SECURE_BOOT_SECURELEVEL\n\tif (boot_params.secure_boot) {\n\t\tset_securelevel(1);\n\t}\n#endif\n\n\t/*\n\t * Parse the ACPI tables for possible boot-time SMP configuration.\n\t */\n\tacpi_boot_table_init();\n\n\tearly_acpi_boot_init();\n\n\tinitmem_init();\n\tdma_contiguous_reserve(max_pfn_mapped << PAGE_SHIFT);\n\n\t/*\n\t * Reserve memory for crash kernel after SRAT is parsed so that it\n\t * won't consume hotpluggable memory.\n\t */\n\treserve_crashkernel();\n\n\tmemblock_find_dma_reserve();\n\n#ifdef CONFIG_KVM_GUEST\n\tkvmclock_init();\n#endif\n\n\tx86_init.paging.pagetable_init();\n\n\tkasan_init();\n\n\tif (boot_cpu_data.cpuid_level >= 0) {\n\t\t/* A CPU has %cr4 if and only if it has CPUID */\n\t\tmmu_cr4_features = __read_cr4();\n\t\tif (trampoline_cr4_features)\n\t\t\t*trampoline_cr4_features = mmu_cr4_features;\n\t}\n\n#ifdef CONFIG_X86_32\n\t/* sync back kernel address range */\n\tclone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,\n\t\t\tswapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tKERNEL_PGD_PTRS);\n\n\t/*\n\t * sync back low identity map too.  It is used for example\n\t * in the 32-bit EFI stub.\n\t */\n\tclone_pgd_range(initial_page_table,\n\t\t\tswapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tmin(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));\n#endif\n\n\ttboot_probe();\n\n\tmap_vsyscall();\n\n\tgeneric_apic_probe();\n\n\tearly_quirks();\n\n\t/*\n\t * Read APIC and some other early information from ACPI tables.\n\t */\n\tacpi_boot_init();\n\tsfi_init();\n\tx86_dtb_init();\n\n\t/*\n\t * get boot-time SMP configuration:\n\t */\n\tif (smp_found_config)\n\t\tget_smp_config();\n\n\tprefill_possible_map();\n\n\tinit_cpu_to_node();\n\n\tinit_apic_mappings();\n\tio_apic_init_mappings();\n\n\tkvm_guest_init();\n\n\te820_reserve_resources();\n\te820_mark_nosave_regions(max_low_pfn);\n\n\tx86_init.resources.reserve_resources();\n\n\te820_setup_gap();\n\n#ifdef CONFIG_VT\n#if defined(CONFIG_VGA_CONSOLE)\n\tif (!efi_enabled(EFI_BOOT) || (efi_mem_type(0xa0000) != EFI_CONVENTIONAL_MEMORY))\n\t\tconswitchp = &vga_con;\n#elif defined(CONFIG_DUMMY_CONSOLE)\n\tconswitchp = &dummy_con;\n#endif\n#endif\n\tx86_init.oem.banner();\n\n\tx86_init.timers.wallclock_init();\n\n\tmcheck_init();\n\n\tarch_init_ideal_nops();\n\n\tregister_refined_jiffies(CLOCK_TICK_RATE);\n\n#ifdef CONFIG_EFI\n\tif (efi_enabled(EFI_BOOT))\n\t\tefi_apply_memmap_quirks();\n#endif\n}",
        "func": "void __init setup_arch(char **cmdline_p)\n{\n\tmemblock_reserve(__pa_symbol(_text),\n\t\t\t (unsigned long)__bss_stop - (unsigned long)_text);\n\n\tearly_reserve_initrd();\n\n\t/*\n\t * At this point everything still needed from the boot loader\n\t * or BIOS or kernel text should be early reserved or marked not\n\t * RAM in e820. All other memory is free game.\n\t */\n\n#ifdef CONFIG_X86_32\n\tmemcpy(&boot_cpu_data, &new_cpu_data, sizeof(new_cpu_data));\n\n\t/*\n\t * copy kernel address range established so far and switch\n\t * to the proper swapper page table\n\t */\n\tclone_pgd_range(swapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tinitial_page_table + KERNEL_PGD_BOUNDARY,\n\t\t\tKERNEL_PGD_PTRS);\n\n\tload_cr3(swapper_pg_dir);\n\t/*\n\t * Note: Quark X1000 CPUs advertise PGE incorrectly and require\n\t * a cr3 based tlb flush, so the following __flush_tlb_all()\n\t * will not flush anything because the cpu quirk which clears\n\t * X86_FEATURE_PGE has not been invoked yet. Though due to the\n\t * load_cr3() above the TLB has been flushed already. The\n\t * quirk is invoked before subsequent calls to __flush_tlb_all()\n\t * so proper operation is guaranteed.\n\t */\n\t__flush_tlb_all();\n#else\n\tprintk(KERN_INFO \"Command line: %s\\n\", boot_command_line);\n#endif\n\n\t/*\n\t * If we have OLPC OFW, we might end up relocating the fixmap due to\n\t * reserve_top(), so do this before touching the ioremap area.\n\t */\n\tolpc_ofw_detect();\n\n\tearly_trap_init();\n\tearly_cpu_init();\n\tearly_ioremap_init();\n\n\tsetup_olpc_ofw_pgd();\n\n\tROOT_DEV = old_decode_dev(boot_params.hdr.root_dev);\n\tscreen_info = boot_params.screen_info;\n\tedid_info = boot_params.edid_info;\n#ifdef CONFIG_X86_32\n\tapm_info.bios = boot_params.apm_bios_info;\n\tist_info = boot_params.ist_info;\n#endif\n\tsaved_video_mode = boot_params.hdr.vid_mode;\n\tbootloader_type = boot_params.hdr.type_of_loader;\n\tif ((bootloader_type >> 4) == 0xe) {\n\t\tbootloader_type &= 0xf;\n\t\tbootloader_type |= (boot_params.hdr.ext_loader_type+0x10) << 4;\n\t}\n\tbootloader_version  = bootloader_type & 0xf;\n\tbootloader_version |= boot_params.hdr.ext_loader_ver << 4;\n\n#ifdef CONFIG_BLK_DEV_RAM\n\trd_image_start = boot_params.hdr.ram_size & RAMDISK_IMAGE_START_MASK;\n\trd_prompt = ((boot_params.hdr.ram_size & RAMDISK_PROMPT_FLAG) != 0);\n\trd_doload = ((boot_params.hdr.ram_size & RAMDISK_LOAD_FLAG) != 0);\n#endif\n#ifdef CONFIG_EFI\n\tif (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,\n\t\t     EFI32_LOADER_SIGNATURE, 4)) {\n\t\tset_bit(EFI_BOOT, &efi.flags);\n\t} else if (!strncmp((char *)&boot_params.efi_info.efi_loader_signature,\n\t\t     EFI64_LOADER_SIGNATURE, 4)) {\n\t\tset_bit(EFI_BOOT, &efi.flags);\n\t\tset_bit(EFI_64BIT, &efi.flags);\n\t}\n\n\tif (efi_enabled(EFI_BOOT))\n\t\tefi_memblock_x86_reserve_range();\n#endif\n\n\tx86_init.oem.arch_setup();\n\n\tiomem_resource.end = (1ULL << boot_cpu_data.x86_phys_bits) - 1;\n\tsetup_memory_map();\n\tparse_setup_data();\n\n\tcopy_edd();\n\n\tif (!boot_params.hdr.root_flags)\n\t\troot_mountflags &= ~MS_RDONLY;\n\tinit_mm.start_code = (unsigned long) _text;\n\tinit_mm.end_code = (unsigned long) _etext;\n\tinit_mm.end_data = (unsigned long) _edata;\n\tinit_mm.brk = _brk_end;\n\n\tmpx_mm_init(&init_mm);\n\n\tcode_resource.start = __pa_symbol(_text);\n\tcode_resource.end = __pa_symbol(_etext)-1;\n\tdata_resource.start = __pa_symbol(_etext);\n\tdata_resource.end = __pa_symbol(_edata)-1;\n\tbss_resource.start = __pa_symbol(__bss_start);\n\tbss_resource.end = __pa_symbol(__bss_stop)-1;\n\n#ifdef CONFIG_CMDLINE_BOOL\n#ifdef CONFIG_CMDLINE_OVERRIDE\n\tstrlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);\n#else\n\tif (builtin_cmdline[0]) {\n\t\t/* append boot loader cmdline to builtin */\n\t\tstrlcat(builtin_cmdline, \" \", COMMAND_LINE_SIZE);\n\t\tstrlcat(builtin_cmdline, boot_command_line, COMMAND_LINE_SIZE);\n\t\tstrlcpy(boot_command_line, builtin_cmdline, COMMAND_LINE_SIZE);\n\t}\n#endif\n#endif\n\n\tstrlcpy(command_line, boot_command_line, COMMAND_LINE_SIZE);\n\t*cmdline_p = command_line;\n\n\t/*\n\t * x86_configure_nx() is called before parse_early_param() to detect\n\t * whether hardware doesn't support NX (so that the early EHCI debug\n\t * console setup can safely call set_fixmap()). It may then be called\n\t * again from within noexec_setup() during parsing early parameters\n\t * to honor the respective command line option.\n\t */\n\tx86_configure_nx();\n\n\tparse_early_param();\n\n\tx86_report_nx();\n\n\t/* after early param, so could get panic from serial */\n\tmemblock_x86_reserve_range_setup_data();\n\n\tif (acpi_mps_check()) {\n#ifdef CONFIG_X86_LOCAL_APIC\n\t\tdisable_apic = 1;\n#endif\n\t\tsetup_clear_cpu_cap(X86_FEATURE_APIC);\n\t}\n\n#ifdef CONFIG_PCI\n\tif (pci_early_dump_regs)\n\t\tearly_dump_pci_devices();\n#endif\n\n\t/* update the e820_saved too */\n\te820_reserve_setup_data();\n\tfinish_e820_parsing();\n\n\tif (efi_enabled(EFI_BOOT))\n\t\tefi_init();\n\n\tdmi_scan_machine();\n\tdmi_memdev_walk();\n\tdmi_set_dump_stack_arch_desc();\n\n\t/*\n\t * VMware detection requires dmi to be available, so this\n\t * needs to be done after dmi_scan_machine, for the BP.\n\t */\n\tinit_hypervisor_platform();\n\n\tx86_init.resources.probe_roms();\n\n\t/* after parse_early_param, so could debug it */\n\tinsert_resource(&iomem_resource, &code_resource);\n\tinsert_resource(&iomem_resource, &data_resource);\n\tinsert_resource(&iomem_resource, &bss_resource);\n\n\te820_add_kernel_range();\n\ttrim_bios_range();\n#ifdef CONFIG_X86_32\n\tif (ppro_with_ram_bug()) {\n\t\te820_update_range(0x70000000ULL, 0x40000ULL, E820_RAM,\n\t\t\t\t  E820_RESERVED);\n\t\tsanitize_e820_map(e820.map, ARRAY_SIZE(e820.map), &e820.nr_map);\n\t\tprintk(KERN_INFO \"fixed physical RAM map:\\n\");\n\t\te820_print_map(\"bad_ppro\");\n\t}\n#else\n\tearly_gart_iommu_check();\n#endif\n\n\t/*\n\t * partially used pages are not usable - thus\n\t * we are rounding upwards:\n\t */\n\tmax_pfn = e820_end_of_ram_pfn();\n\n\t/* update e820 for memory not covered by WB MTRRs */\n\tmtrr_bp_init();\n\tif (mtrr_trim_uncached_memory(max_pfn))\n\t\tmax_pfn = e820_end_of_ram_pfn();\n\n\tmax_possible_pfn = max_pfn;\n\n#ifdef CONFIG_X86_32\n\t/* max_low_pfn get updated here */\n\tfind_low_pfn_range();\n#else\n\tcheck_x2apic();\n\n\t/* How many end-of-memory variables you have, grandma! */\n\t/* need this before calling reserve_initrd */\n\tif (max_pfn > (1UL<<(32 - PAGE_SHIFT)))\n\t\tmax_low_pfn = e820_end_of_low_ram_pfn();\n\telse\n\t\tmax_low_pfn = max_pfn;\n\n\thigh_memory = (void *)__va(max_pfn * PAGE_SIZE - 1) + 1;\n#endif\n\n\t/*\n\t * Find and reserve possible boot-time SMP configuration:\n\t */\n\tfind_smp_config();\n\n\treserve_ibft_region();\n\n\tearly_alloc_pgt_buf();\n\n\t/*\n\t * Need to conclude brk, before memblock_x86_fill()\n\t *  it could use memblock_find_in_range, could overlap with\n\t *  brk area.\n\t */\n\treserve_brk();\n\n\tcleanup_highmap();\n\n\tmemblock_set_current_limit(ISA_END_ADDRESS);\n\tmemblock_x86_fill();\n\n\tif (efi_enabled(EFI_BOOT)) {\n\t\tefi_fake_memmap();\n\t\tefi_find_mirror();\n\t}\n\n\t/*\n\t * The EFI specification says that boot service code won't be called\n\t * after ExitBootServices(). This is, in fact, a lie.\n\t */\n\tif (efi_enabled(EFI_MEMMAP))\n\t\tefi_reserve_boot_services();\n\n\t/* preallocate 4k for mptable mpc */\n\tearly_reserve_e820_mpc_new();\n\n#ifdef CONFIG_X86_CHECK_BIOS_CORRUPTION\n\tsetup_bios_corruption_check();\n#endif\n\n#ifdef CONFIG_X86_32\n\tprintk(KERN_DEBUG \"initial memory mapped: [mem 0x00000000-%#010lx]\\n\",\n\t\t\t(max_pfn_mapped<<PAGE_SHIFT) - 1);\n#endif\n\n\treserve_real_mode();\n\n\ttrim_platform_memory_ranges();\n\ttrim_low_memory_range();\n\n\tinit_mem_mapping();\n\n\tearly_trap_pf_init();\n\n\tsetup_real_mode();\n\n\tmemblock_set_current_limit(get_max_mapped());\n\n\t/*\n\t * NOTE: On x86-32, only from this point on, fixmaps are ready for use.\n\t */\n\n#ifdef CONFIG_PROVIDE_OHCI1394_DMA_INIT\n\tif (init_ohci1394_dma_early)\n\t\tinit_ohci1394_dma_on_all_controllers();\n#endif\n\t/* Allocate bigger log buffer */\n\tsetup_log_buf(1);\n\n#ifdef CONFIG_EFI_SECURE_BOOT_SECURELEVEL\n\tif (boot_params.secure_boot) {\n\t\tset_securelevel(1);\n\t}\n#endif\n\n\treserve_initrd();\n\n#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)\n\tacpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);\n#endif\n\n\tvsmp_init();\n\n\tio_delay_init();\n\n\t/*\n\t * Parse the ACPI tables for possible boot-time SMP configuration.\n\t */\n\tacpi_boot_table_init();\n\n\tearly_acpi_boot_init();\n\n\tinitmem_init();\n\tdma_contiguous_reserve(max_pfn_mapped << PAGE_SHIFT);\n\n\t/*\n\t * Reserve memory for crash kernel after SRAT is parsed so that it\n\t * won't consume hotpluggable memory.\n\t */\n\treserve_crashkernel();\n\n\tmemblock_find_dma_reserve();\n\n#ifdef CONFIG_KVM_GUEST\n\tkvmclock_init();\n#endif\n\n\tx86_init.paging.pagetable_init();\n\n\tkasan_init();\n\n\tif (boot_cpu_data.cpuid_level >= 0) {\n\t\t/* A CPU has %cr4 if and only if it has CPUID */\n\t\tmmu_cr4_features = __read_cr4();\n\t\tif (trampoline_cr4_features)\n\t\t\t*trampoline_cr4_features = mmu_cr4_features;\n\t}\n\n#ifdef CONFIG_X86_32\n\t/* sync back kernel address range */\n\tclone_pgd_range(initial_page_table + KERNEL_PGD_BOUNDARY,\n\t\t\tswapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tKERNEL_PGD_PTRS);\n\n\t/*\n\t * sync back low identity map too.  It is used for example\n\t * in the 32-bit EFI stub.\n\t */\n\tclone_pgd_range(initial_page_table,\n\t\t\tswapper_pg_dir     + KERNEL_PGD_BOUNDARY,\n\t\t\tmin(KERNEL_PGD_PTRS, KERNEL_PGD_BOUNDARY));\n#endif\n\n\ttboot_probe();\n\n\tmap_vsyscall();\n\n\tgeneric_apic_probe();\n\n\tearly_quirks();\n\n\t/*\n\t * Read APIC and some other early information from ACPI tables.\n\t */\n\tacpi_boot_init();\n\tsfi_init();\n\tx86_dtb_init();\n\n\t/*\n\t * get boot-time SMP configuration:\n\t */\n\tif (smp_found_config)\n\t\tget_smp_config();\n\n\tprefill_possible_map();\n\n\tinit_cpu_to_node();\n\n\tinit_apic_mappings();\n\tio_apic_init_mappings();\n\n\tkvm_guest_init();\n\n\te820_reserve_resources();\n\te820_mark_nosave_regions(max_low_pfn);\n\n\tx86_init.resources.reserve_resources();\n\n\te820_setup_gap();\n\n#ifdef CONFIG_VT\n#if defined(CONFIG_VGA_CONSOLE)\n\tif (!efi_enabled(EFI_BOOT) || (efi_mem_type(0xa0000) != EFI_CONVENTIONAL_MEMORY))\n\t\tconswitchp = &vga_con;\n#elif defined(CONFIG_DUMMY_CONSOLE)\n\tconswitchp = &dummy_con;\n#endif\n#endif\n\tx86_init.oem.banner();\n\n\tx86_init.timers.wallclock_init();\n\n\tmcheck_init();\n\n\tarch_init_ideal_nops();\n\n\tregister_refined_jiffies(CLOCK_TICK_RATE);\n\n#ifdef CONFIG_EFI\n\tif (efi_enabled(EFI_BOOT))\n\t\tefi_apply_memmap_quirks();\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -288,21 +288,21 @@\n \t/* Allocate bigger log buffer */\n \tsetup_log_buf(1);\n \n-\treserve_initrd();\n-\n-#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)\n-\tacpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);\n-#endif\n-\n-\tvsmp_init();\n-\n-\tio_delay_init();\n-\n #ifdef CONFIG_EFI_SECURE_BOOT_SECURELEVEL\n \tif (boot_params.secure_boot) {\n \t\tset_securelevel(1);\n \t}\n #endif\n+\n+\treserve_initrd();\n+\n+#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)\n+\tacpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);\n+#endif\n+\n+\tvsmp_init();\n+\n+\tio_delay_init();\n \n \t/*\n \t * Parse the ACPI tables for possible boot-time SMP configuration.",
        "diff_line_info": {
            "deleted_lines": [
                "\treserve_initrd();",
                "",
                "#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)",
                "\tacpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);",
                "#endif",
                "",
                "\tvsmp_init();",
                "",
                "\tio_delay_init();",
                ""
            ],
            "added_lines": [
                "",
                "\treserve_initrd();",
                "",
                "#if defined(CONFIG_ACPI) && defined(CONFIG_BLK_DEV_INITRD)",
                "\tacpi_initrd_override((void *)initrd_start, initrd_end - initrd_start);",
                "#endif",
                "",
                "\tvsmp_init();",
                "",
                "\tio_delay_init();"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8955",
        "func_name": "torvalds/linux/validate_group",
        "description": "arch/arm64/kernel/perf_event.c in the Linux kernel before 4.1 on arm64 platforms allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via vectors involving events that are mishandled during a span of multiple HW PMUs.",
        "git_url": "https://github.com/torvalds/linux/commit/8fff105e13041e49b82f92eef034f363a6b1c071",
        "commit_title": "arm64: perf: reject groups spanning multiple HW PMUs",
        "commit_text": " The perf core implicitly rejects events spanning multiple HW PMUs, as in these cases the event->ctx will differ. However this validation is performed after pmu::event_init() is called in perf_init_event(), and thus pmu::event_init() may be called with a group leader from a different HW PMU.  The ARM64 PMU driver does not take this fact into account, and when validating groups assumes that it can call to_arm_pmu(event->pmu) for any HW event. When the event in question is from another HW PMU this is wrong, and results in dereferencing garbage.  This patch updates the ARM64 PMU driver to first test for and reject events from other PMUs, moving the to_arm_pmu and related logic after this test. Fixes a crash triggered by perf_fuzzer on Linux-4.0-rc2, with a CCI PMU present:  Bad mode in Synchronous Abort handler detected, code 0x86000006 -- IABT (current EL) CPU: 0 PID: 1371 Comm: perf_fuzzer Not tainted 3.19.0+ #249 Hardware name: V2F-1XV7 Cortex-A53x2 SMM (DT) task: ffffffc07c73a280 ti: ffffffc07b0a0000 task.ti: ffffffc07b0a0000 PC is at 0x0 LR is at validate_event+0x90/0xa8 pc : [<0000000000000000>] lr : [<ffffffc000090228>] pstate: 00000145 sp : ffffffc07b0a3ba0  [<          (null)>]           (null) [<ffffffc0000907d8>] armpmu_event_init+0x174/0x3cc [<ffffffc00015d870>] perf_try_init_event+0x34/0x70 [<ffffffc000164094>] perf_init_event+0xe0/0x10c [<ffffffc000164348>] perf_event_alloc+0x288/0x358 [<ffffffc000164c5c>] SyS_perf_event_open+0x464/0x98c Code: bad PC value  Also cleans up the code to use the arm_pmu only when we know that we are dealing with an arm pmu event.  Cc: Will Deacon <will.deacon@arm.com>",
        "func_before": "static int\nvalidate_group(struct perf_event *event)\n{\n\tstruct perf_event *sibling, *leader = event->group_leader;\n\tstruct pmu_hw_events fake_pmu;\n\tDECLARE_BITMAP(fake_used_mask, ARMPMU_MAX_HWEVENTS);\n\n\t/*\n\t * Initialise the fake PMU. We only need to populate the\n\t * used_mask for the purposes of validation.\n\t */\n\tmemset(fake_used_mask, 0, sizeof(fake_used_mask));\n\tfake_pmu.used_mask = fake_used_mask;\n\n\tif (!validate_event(&fake_pmu, leader))\n\t\treturn -EINVAL;\n\n\tlist_for_each_entry(sibling, &leader->sibling_list, group_entry) {\n\t\tif (!validate_event(&fake_pmu, sibling))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!validate_event(&fake_pmu, event))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "func": "static int\nvalidate_group(struct perf_event *event)\n{\n\tstruct perf_event *sibling, *leader = event->group_leader;\n\tstruct pmu_hw_events fake_pmu;\n\tDECLARE_BITMAP(fake_used_mask, ARMPMU_MAX_HWEVENTS);\n\n\t/*\n\t * Initialise the fake PMU. We only need to populate the\n\t * used_mask for the purposes of validation.\n\t */\n\tmemset(fake_used_mask, 0, sizeof(fake_used_mask));\n\tfake_pmu.used_mask = fake_used_mask;\n\n\tif (!validate_event(event->pmu, &fake_pmu, leader))\n\t\treturn -EINVAL;\n\n\tlist_for_each_entry(sibling, &leader->sibling_list, group_entry) {\n\t\tif (!validate_event(event->pmu, &fake_pmu, sibling))\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (!validate_event(event->pmu, &fake_pmu, event))\n\t\treturn -EINVAL;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,15 +12,15 @@\n \tmemset(fake_used_mask, 0, sizeof(fake_used_mask));\n \tfake_pmu.used_mask = fake_used_mask;\n \n-\tif (!validate_event(&fake_pmu, leader))\n+\tif (!validate_event(event->pmu, &fake_pmu, leader))\n \t\treturn -EINVAL;\n \n \tlist_for_each_entry(sibling, &leader->sibling_list, group_entry) {\n-\t\tif (!validate_event(&fake_pmu, sibling))\n+\t\tif (!validate_event(event->pmu, &fake_pmu, sibling))\n \t\t\treturn -EINVAL;\n \t}\n \n-\tif (!validate_event(&fake_pmu, event))\n+\tif (!validate_event(event->pmu, &fake_pmu, event))\n \t\treturn -EINVAL;\n \n \treturn 0;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!validate_event(&fake_pmu, leader))",
                "\t\tif (!validate_event(&fake_pmu, sibling))",
                "\tif (!validate_event(&fake_pmu, event))"
            ],
            "added_lines": [
                "\tif (!validate_event(event->pmu, &fake_pmu, leader))",
                "\t\tif (!validate_event(event->pmu, &fake_pmu, sibling))",
                "\tif (!validate_event(event->pmu, &fake_pmu, event))"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8955",
        "func_name": "torvalds/linux/validate_event",
        "description": "arch/arm64/kernel/perf_event.c in the Linux kernel before 4.1 on arm64 platforms allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via vectors involving events that are mishandled during a span of multiple HW PMUs.",
        "git_url": "https://github.com/torvalds/linux/commit/8fff105e13041e49b82f92eef034f363a6b1c071",
        "commit_title": "arm64: perf: reject groups spanning multiple HW PMUs",
        "commit_text": " The perf core implicitly rejects events spanning multiple HW PMUs, as in these cases the event->ctx will differ. However this validation is performed after pmu::event_init() is called in perf_init_event(), and thus pmu::event_init() may be called with a group leader from a different HW PMU.  The ARM64 PMU driver does not take this fact into account, and when validating groups assumes that it can call to_arm_pmu(event->pmu) for any HW event. When the event in question is from another HW PMU this is wrong, and results in dereferencing garbage.  This patch updates the ARM64 PMU driver to first test for and reject events from other PMUs, moving the to_arm_pmu and related logic after this test. Fixes a crash triggered by perf_fuzzer on Linux-4.0-rc2, with a CCI PMU present:  Bad mode in Synchronous Abort handler detected, code 0x86000006 -- IABT (current EL) CPU: 0 PID: 1371 Comm: perf_fuzzer Not tainted 3.19.0+ #249 Hardware name: V2F-1XV7 Cortex-A53x2 SMM (DT) task: ffffffc07c73a280 ti: ffffffc07b0a0000 task.ti: ffffffc07b0a0000 PC is at 0x0 LR is at validate_event+0x90/0xa8 pc : [<0000000000000000>] lr : [<ffffffc000090228>] pstate: 00000145 sp : ffffffc07b0a3ba0  [<          (null)>]           (null) [<ffffffc0000907d8>] armpmu_event_init+0x174/0x3cc [<ffffffc00015d870>] perf_try_init_event+0x34/0x70 [<ffffffc000164094>] perf_init_event+0xe0/0x10c [<ffffffc000164348>] perf_event_alloc+0x288/0x358 [<ffffffc000164c5c>] SyS_perf_event_open+0x464/0x98c Code: bad PC value  Also cleans up the code to use the arm_pmu only when we know that we are dealing with an arm pmu event.  Cc: Will Deacon <will.deacon@arm.com>",
        "func_before": "static int\nvalidate_event(struct pmu_hw_events *hw_events,\n\t       struct perf_event *event)\n{\n\tstruct arm_pmu *armpmu = to_arm_pmu(event->pmu);\n\tstruct hw_perf_event fake_event = event->hw;\n\tstruct pmu *leader_pmu = event->group_leader->pmu;\n\n\tif (is_software_event(event))\n\t\treturn 1;\n\n\tif (event->pmu != leader_pmu || event->state < PERF_EVENT_STATE_OFF)\n\t\treturn 1;\n\n\tif (event->state == PERF_EVENT_STATE_OFF && !event->attr.enable_on_exec)\n\t\treturn 1;\n\n\treturn armpmu->get_event_idx(hw_events, &fake_event) >= 0;\n}",
        "func": "static int\nvalidate_event(struct pmu *pmu, struct pmu_hw_events *hw_events,\n\t\t\t\tstruct perf_event *event)\n{\n\tstruct arm_pmu *armpmu;\n\tstruct hw_perf_event fake_event = event->hw;\n\tstruct pmu *leader_pmu = event->group_leader->pmu;\n\n\tif (is_software_event(event))\n\t\treturn 1;\n\n\t/*\n\t * Reject groups spanning multiple HW PMUs (e.g. CPU + CCI). The\n\t * core perf code won't check that the pmu->ctx == leader->ctx\n\t * until after pmu->event_init(event).\n\t */\n\tif (event->pmu != pmu)\n\t\treturn 0;\n\n\tif (event->pmu != leader_pmu || event->state < PERF_EVENT_STATE_OFF)\n\t\treturn 1;\n\n\tif (event->state == PERF_EVENT_STATE_OFF && !event->attr.enable_on_exec)\n\t\treturn 1;\n\n\tarmpmu = to_arm_pmu(event->pmu);\n\treturn armpmu->get_event_idx(hw_events, &fake_event) >= 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,21 @@\n static int\n-validate_event(struct pmu_hw_events *hw_events,\n-\t       struct perf_event *event)\n+validate_event(struct pmu *pmu, struct pmu_hw_events *hw_events,\n+\t\t\t\tstruct perf_event *event)\n {\n-\tstruct arm_pmu *armpmu = to_arm_pmu(event->pmu);\n+\tstruct arm_pmu *armpmu;\n \tstruct hw_perf_event fake_event = event->hw;\n \tstruct pmu *leader_pmu = event->group_leader->pmu;\n \n \tif (is_software_event(event))\n \t\treturn 1;\n+\n+\t/*\n+\t * Reject groups spanning multiple HW PMUs (e.g. CPU + CCI). The\n+\t * core perf code won't check that the pmu->ctx == leader->ctx\n+\t * until after pmu->event_init(event).\n+\t */\n+\tif (event->pmu != pmu)\n+\t\treturn 0;\n \n \tif (event->pmu != leader_pmu || event->state < PERF_EVENT_STATE_OFF)\n \t\treturn 1;\n@@ -15,5 +23,6 @@\n \tif (event->state == PERF_EVENT_STATE_OFF && !event->attr.enable_on_exec)\n \t\treturn 1;\n \n+\tarmpmu = to_arm_pmu(event->pmu);\n \treturn armpmu->get_event_idx(hw_events, &fake_event) >= 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "validate_event(struct pmu_hw_events *hw_events,",
                "\t       struct perf_event *event)",
                "\tstruct arm_pmu *armpmu = to_arm_pmu(event->pmu);"
            ],
            "added_lines": [
                "validate_event(struct pmu *pmu, struct pmu_hw_events *hw_events,",
                "\t\t\t\tstruct perf_event *event)",
                "\tstruct arm_pmu *armpmu;",
                "",
                "\t/*",
                "\t * Reject groups spanning multiple HW PMUs (e.g. CPU + CCI). The",
                "\t * core perf code won't check that the pmu->ctx == leader->ctx",
                "\t * until after pmu->event_init(event).",
                "\t */",
                "\tif (event->pmu != pmu)",
                "\t\treturn 0;",
                "\tarmpmu = to_arm_pmu(event->pmu);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3900",
        "func_name": "android/svc_can_register",
        "description": "cmds/servicemanager/service_manager.c in ServiceManager in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 does not properly restrict service registration, which allows attackers to gain privileges via a crafted application, aka internal bug 29431260.",
        "git_url": "https://android.googlesource.com/platform/frameworks/native/+/d3c6ce463ac91ecbeb2128beb475d31d3ca6ef42",
        "commit_title": "ServiceManager: Restore basic uid check",
        "commit_text": " Prevent apps from registering services without relying on selinux checks.  Bug: 29431260  (cherry picked from commit 2b74d2c1d2a2c1bb6e9c420f7e9b339ba2a95179) ",
        "func_before": "static int svc_can_register(const uint16_t *name, size_t name_len, pid_t spid, uid_t uid)\n{\n    const char *perm = \"add\";\n    return check_mac_perms_from_lookup(spid, uid, perm, str8(name, name_len)) ? 1 : 0;\n}",
        "func": "static int svc_can_register(const uint16_t *name, size_t name_len, pid_t spid, uid_t uid)\n{\n    const char *perm = \"add\";\n\n    if (uid >= AID_APP) {\n        return 0; /* Don't allow apps to register services */\n    }\n\n    return check_mac_perms_from_lookup(spid, uid, perm, str8(name, name_len)) ? 1 : 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,10 @@\n static int svc_can_register(const uint16_t *name, size_t name_len, pid_t spid, uid_t uid)\n {\n     const char *perm = \"add\";\n+\n+    if (uid >= AID_APP) {\n+        return 0; /* Don't allow apps to register services */\n+    }\n+\n     return check_mac_perms_from_lookup(spid, uid, perm, str8(name, name_len)) ? 1 : 0;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    if (uid >= AID_APP) {",
                "        return 0; /* Don't allow apps to register services */",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3900",
        "func_name": "android/svc_can_register",
        "description": "cmds/servicemanager/service_manager.c in ServiceManager in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 does not properly restrict service registration, which allows attackers to gain privileges via a crafted application, aka internal bug 29431260.",
        "git_url": "https://android.googlesource.com/platform/frameworks/native/+/047eec456943dc082e33220d28abb7df4e089f69",
        "commit_title": "ServiceManager: Allow system services running as secondary users to add services",
        "commit_text": " This should be reverted when all system services have been cleaned up to not do this. A process looking up a service while running in the background will see the service registered by the active user (assuming the service is registered on every user switch), not the service registered by the user that the process itself belongs to.  BUG: 30795333 (cherry picked from commit e6bbe69ba739c8a08837134437aaccfea5f1d943) ",
        "func_before": "static int svc_can_register(const uint16_t *name, size_t name_len, pid_t spid, uid_t uid)\n{\n    const char *perm = \"add\";\n\n    if (uid >= AID_APP) {\n        return 0; /* Don't allow apps to register services */\n    }\n\n    return check_mac_perms_from_lookup(spid, uid, perm, str8(name, name_len)) ? 1 : 0;\n}",
        "func": "static int svc_can_register(const uint16_t *name, size_t name_len, pid_t spid, uid_t uid)\n{\n    const char *perm = \"add\";\n\n    if (multiuser_get_app_id(uid) >= AID_APP) {\n        return 0; /* Don't allow apps to register services */\n    }\n\n    return check_mac_perms_from_lookup(spid, uid, perm, str8(name, name_len)) ? 1 : 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n {\n     const char *perm = \"add\";\n \n-    if (uid >= AID_APP) {\n+    if (multiuser_get_app_id(uid) >= AID_APP) {\n         return 0; /* Don't allow apps to register services */\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    if (uid >= AID_APP) {"
            ],
            "added_lines": [
                "    if (multiuser_get_app_id(uid) >= AID_APP) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3909",
        "func_name": "android/SoftMPEG4::onQueueFilled",
        "description": "The SoftMPEG4 component in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 30033990.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/c48ef757cc50906e8726a3bebc3b60716292cdba",
        "commit_title": "Fix build breakage caused by commit",
        "commit_text": "940829f69b52d6038db66a9c727534636ecc456d.  (cherry picked from commit baa9146401e28c5acf54dea21ddd197f0d3a8fcd) ",
        "func_before": "void SoftMPEG4::onQueueFilled(OMX_U32 /* portIndex */) {\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    while (!inQueue.empty() && outQueue.size() == kNumOutputBuffers) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n        if (inHeader == NULL) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            continue;\n        }\n\n        PortInfo *port = editPortInfo(1);\n\n        OMX_BUFFERHEADERTYPE *outHeader =\n            port->mBuffers.editItemAt(mNumSamplesOutput & 1).mHeader;\n\n        if (inHeader->nFilledLen == 0) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            ++mInputBufferCount;\n\n            if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                outHeader->nFilledLen = 0;\n                outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n                List<BufferInfo *>::iterator it = outQueue.begin();\n                while ((*it)->mHeader != outHeader) {\n                    ++it;\n                }\n\n                BufferInfo *outInfo = *it;\n                outInfo->mOwnedByUs = false;\n                outQueue.erase(it);\n                outInfo = NULL;\n\n                notifyFillBufferDone(outHeader);\n                outHeader = NULL;\n            }\n            return;\n        }\n\n        uint8_t *bitstream = inHeader->pBuffer + inHeader->nOffset;\n        uint32_t *start_code = (uint32_t *)bitstream;\n        bool volHeader = *start_code == 0xB0010000;\n        if (volHeader) {\n            PVCleanUpVideoDecoder(mHandle);\n            mInitialized = false;\n        }\n\n        if (!mInitialized) {\n            uint8_t *vol_data[1];\n            int32_t vol_size = 0;\n\n            vol_data[0] = NULL;\n\n            if ((inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) || volHeader) {\n                vol_data[0] = bitstream;\n                vol_size = inHeader->nFilledLen;\n            }\n\n            MP4DecodingMode mode =\n                (mMode == MODE_MPEG4) ? MPEG4_MODE : H263_MODE;\n\n            Bool success = PVInitVideoDecoder(\n                    mHandle, vol_data, &vol_size, 1,\n                    outputBufferWidth(), outputBufferHeight(), mode);\n\n            if (!success) {\n                ALOGW(\"PVInitVideoDecoder failed. Unsupported content?\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            MP4DecodingMode actualMode = PVGetDecBitstreamMode(mHandle);\n            if (mode != actualMode) {\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            PVSetPostProcType((VideoDecControls *) mHandle, 0);\n\n            bool hasFrameData = false;\n            if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {\n                inInfo->mOwnedByUs = false;\n                inQueue.erase(inQueue.begin());\n                inInfo = NULL;\n                notifyEmptyBufferDone(inHeader);\n                inHeader = NULL;\n            } else if (volHeader) {\n                hasFrameData = true;\n            }\n\n            mInitialized = true;\n\n            if (mode == MPEG4_MODE && handlePortSettingsChange()) {\n                return;\n            }\n\n            if (!hasFrameData) {\n                continue;\n            }\n        }\n\n        if (!mFramesConfigured) {\n            PortInfo *port = editPortInfo(1);\n            OMX_BUFFERHEADERTYPE *outHeader = port->mBuffers.editItemAt(1).mHeader;\n\n            OMX_U32 yFrameSize = sizeof(uint8) * mHandle->size;\n            if ((outHeader->nAllocLen < yFrameSize) ||\n                    (outHeader->nAllocLen - yFrameSize < yFrameSize / 2)) {\n                ALOGE(\"Too small output buffer for reference frame: %zu bytes\",\n                        outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"30033990\");\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n            PVSetReferenceYUV(mHandle, outHeader->pBuffer);\n            mFramesConfigured = true;\n        }\n\n        uint32_t useExtTimestamp = (inHeader->nOffset == 0);\n\n        // decoder deals in ms (int32_t), OMX in us (int64_t)\n        // so use fake timestamp instead\n        uint32_t timestamp = 0xFFFFFFFF;\n        if (useExtTimestamp) {\n            mPvToOmxTimeMap.add(mPvTime, inHeader->nTimeStamp);\n            timestamp = mPvTime;\n            mPvTime++;\n        }\n\n        int32_t bufferSize = inHeader->nFilledLen;\n        int32_t tmp = bufferSize;\n\n        OMX_U32 frameSize;\n        OMX_U64 yFrameSize = (OMX_U64)mWidth * (OMX_U64)mHeight;\n        if (yFrameSize > ((OMX_U64)UINT32_MAX / 3) * 2) {\n            ALOGE(\"Frame size too large\");\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n        frameSize = (OMX_U32)(yFrameSize + (yFrameSize / 2));\n\n        if (outHeader->nAllocLen < frameSize) {\n            android_errorWriteLog(0x534e4554, \"27833616\");\n            ALOGE(\"Insufficient output buffer size\");\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n        // The PV decoder is lying to us, sometimes it'll claim to only have\n        // consumed a subset of the buffer when it clearly consumed all of it.\n        // ignore whatever it says...\n        if (PVDecodeVideoFrame(\n                    mHandle, &bitstream, &timestamp, &tmp,\n                    &useExtTimestamp,\n                    outHeader->pBuffer) != PV_TRUE) {\n            ALOGE(\"failed to decode video frame.\");\n\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n\n        // H263 doesn't have VOL header, the frame size information is in short header, i.e. the\n        // decoder may detect size change after PVDecodeVideoFrame.\n        if (handlePortSettingsChange()) {\n            return;\n        }\n\n        // decoder deals in ms, OMX in us.\n        outHeader->nTimeStamp = mPvToOmxTimeMap.valueFor(timestamp);\n        mPvToOmxTimeMap.removeItem(timestamp);\n\n        inHeader->nOffset += bufferSize;\n        inHeader->nFilledLen = 0;\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n        } else {\n            outHeader->nFlags = 0;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        ++mInputBufferCount;\n\n        outHeader->nOffset = 0;\n        outHeader->nFilledLen = frameSize;\n\n        List<BufferInfo *>::iterator it = outQueue.begin();\n        while ((*it)->mHeader != outHeader) {\n            ++it;\n        }\n\n        BufferInfo *outInfo = *it;\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(it);\n        outInfo = NULL;\n\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mNumSamplesOutput;\n    }\n}",
        "func": "void SoftMPEG4::onQueueFilled(OMX_U32 /* portIndex */) {\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    while (!inQueue.empty() && outQueue.size() == kNumOutputBuffers) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n        if (inHeader == NULL) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            continue;\n        }\n\n        PortInfo *port = editPortInfo(1);\n\n        OMX_BUFFERHEADERTYPE *outHeader =\n            port->mBuffers.editItemAt(mNumSamplesOutput & 1).mHeader;\n\n        if (inHeader->nFilledLen == 0) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            ++mInputBufferCount;\n\n            if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                outHeader->nFilledLen = 0;\n                outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n                List<BufferInfo *>::iterator it = outQueue.begin();\n                while ((*it)->mHeader != outHeader) {\n                    ++it;\n                }\n\n                BufferInfo *outInfo = *it;\n                outInfo->mOwnedByUs = false;\n                outQueue.erase(it);\n                outInfo = NULL;\n\n                notifyFillBufferDone(outHeader);\n                outHeader = NULL;\n            }\n            return;\n        }\n\n        uint8_t *bitstream = inHeader->pBuffer + inHeader->nOffset;\n        uint32_t *start_code = (uint32_t *)bitstream;\n        bool volHeader = *start_code == 0xB0010000;\n        if (volHeader) {\n            PVCleanUpVideoDecoder(mHandle);\n            mInitialized = false;\n        }\n\n        if (!mInitialized) {\n            uint8_t *vol_data[1];\n            int32_t vol_size = 0;\n\n            vol_data[0] = NULL;\n\n            if ((inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) || volHeader) {\n                vol_data[0] = bitstream;\n                vol_size = inHeader->nFilledLen;\n            }\n\n            MP4DecodingMode mode =\n                (mMode == MODE_MPEG4) ? MPEG4_MODE : H263_MODE;\n\n            Bool success = PVInitVideoDecoder(\n                    mHandle, vol_data, &vol_size, 1,\n                    outputBufferWidth(), outputBufferHeight(), mode);\n\n            if (!success) {\n                ALOGW(\"PVInitVideoDecoder failed. Unsupported content?\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            MP4DecodingMode actualMode = PVGetDecBitstreamMode(mHandle);\n            if (mode != actualMode) {\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            PVSetPostProcType((VideoDecControls *) mHandle, 0);\n\n            bool hasFrameData = false;\n            if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {\n                inInfo->mOwnedByUs = false;\n                inQueue.erase(inQueue.begin());\n                inInfo = NULL;\n                notifyEmptyBufferDone(inHeader);\n                inHeader = NULL;\n            } else if (volHeader) {\n                hasFrameData = true;\n            }\n\n            mInitialized = true;\n\n            if (mode == MPEG4_MODE && handlePortSettingsChange()) {\n                return;\n            }\n\n            if (!hasFrameData) {\n                continue;\n            }\n        }\n\n        if (!mFramesConfigured) {\n            PortInfo *port = editPortInfo(1);\n            OMX_BUFFERHEADERTYPE *outHeader = port->mBuffers.editItemAt(1).mHeader;\n\n            OMX_U32 yFrameSize = sizeof(uint8) * mHandle->size;\n            if ((outHeader->nAllocLen < yFrameSize) ||\n                    (outHeader->nAllocLen - yFrameSize < yFrameSize / 2)) {\n                ALOGE(\"Too small output buffer for reference frame: %lu bytes\",\n                        (unsigned long)outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"30033990\");\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n            PVSetReferenceYUV(mHandle, outHeader->pBuffer);\n            mFramesConfigured = true;\n        }\n\n        uint32_t useExtTimestamp = (inHeader->nOffset == 0);\n\n        // decoder deals in ms (int32_t), OMX in us (int64_t)\n        // so use fake timestamp instead\n        uint32_t timestamp = 0xFFFFFFFF;\n        if (useExtTimestamp) {\n            mPvToOmxTimeMap.add(mPvTime, inHeader->nTimeStamp);\n            timestamp = mPvTime;\n            mPvTime++;\n        }\n\n        int32_t bufferSize = inHeader->nFilledLen;\n        int32_t tmp = bufferSize;\n\n        OMX_U32 frameSize;\n        OMX_U64 yFrameSize = (OMX_U64)mWidth * (OMX_U64)mHeight;\n        if (yFrameSize > ((OMX_U64)UINT32_MAX / 3) * 2) {\n            ALOGE(\"Frame size too large\");\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n        frameSize = (OMX_U32)(yFrameSize + (yFrameSize / 2));\n\n        if (outHeader->nAllocLen < frameSize) {\n            android_errorWriteLog(0x534e4554, \"27833616\");\n            ALOGE(\"Insufficient output buffer size\");\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n        // The PV decoder is lying to us, sometimes it'll claim to only have\n        // consumed a subset of the buffer when it clearly consumed all of it.\n        // ignore whatever it says...\n        if (PVDecodeVideoFrame(\n                    mHandle, &bitstream, &timestamp, &tmp,\n                    &useExtTimestamp,\n                    outHeader->pBuffer) != PV_TRUE) {\n            ALOGE(\"failed to decode video frame.\");\n\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n\n        // H263 doesn't have VOL header, the frame size information is in short header, i.e. the\n        // decoder may detect size change after PVDecodeVideoFrame.\n        if (handlePortSettingsChange()) {\n            return;\n        }\n\n        // decoder deals in ms, OMX in us.\n        outHeader->nTimeStamp = mPvToOmxTimeMap.valueFor(timestamp);\n        mPvToOmxTimeMap.removeItem(timestamp);\n\n        inHeader->nOffset += bufferSize;\n        inHeader->nFilledLen = 0;\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n        } else {\n            outHeader->nFlags = 0;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        ++mInputBufferCount;\n\n        outHeader->nOffset = 0;\n        outHeader->nFilledLen = frameSize;\n\n        List<BufferInfo *>::iterator it = outQueue.begin();\n        while ((*it)->mHeader != outHeader) {\n            ++it;\n        }\n\n        BufferInfo *outInfo = *it;\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(it);\n        outInfo = NULL;\n\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mNumSamplesOutput;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -119,8 +119,8 @@\n             OMX_U32 yFrameSize = sizeof(uint8) * mHandle->size;\n             if ((outHeader->nAllocLen < yFrameSize) ||\n                     (outHeader->nAllocLen - yFrameSize < yFrameSize / 2)) {\n-                ALOGE(\"Too small output buffer for reference frame: %zu bytes\",\n-                        outHeader->nAllocLen);\n+                ALOGE(\"Too small output buffer for reference frame: %lu bytes\",\n+                        (unsigned long)outHeader->nAllocLen);\n                 android_errorWriteLog(0x534e4554, \"30033990\");\n                 notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                 mSignalledError = true;",
        "diff_line_info": {
            "deleted_lines": [
                "                ALOGE(\"Too small output buffer for reference frame: %zu bytes\",",
                "                        outHeader->nAllocLen);"
            ],
            "added_lines": [
                "                ALOGE(\"Too small output buffer for reference frame: %lu bytes\",",
                "                        (unsigned long)outHeader->nAllocLen);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3909",
        "func_name": "android/SoftMPEG4::onQueueFilled",
        "description": "The SoftMPEG4 component in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 30033990.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/d4271b792bdad85a80e2b83ab34c4b30b74f53ec",
        "commit_title": "SoftMPEG4: Check the buffer size before writing the reference frame.",
        "commit_text": " Also prevent overflow in SoftMPEG4 and division by zero in SoftMPEG4Encoder.  Bug: 30033990 (cherry picked from commit 695123195034402ca76169b195069c28c30342d3) ",
        "func_before": "void SoftMPEG4::onQueueFilled(OMX_U32 /* portIndex */) {\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    while (!inQueue.empty() && outQueue.size() == kNumOutputBuffers) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n        if (inHeader == NULL) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            continue;\n        }\n\n        PortInfo *port = editPortInfo(1);\n\n        OMX_BUFFERHEADERTYPE *outHeader =\n            port->mBuffers.editItemAt(mNumSamplesOutput & 1).mHeader;\n\n        if (inHeader->nFilledLen == 0) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            ++mInputBufferCount;\n\n            if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                outHeader->nFilledLen = 0;\n                outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n                List<BufferInfo *>::iterator it = outQueue.begin();\n                while ((*it)->mHeader != outHeader) {\n                    ++it;\n                }\n\n                BufferInfo *outInfo = *it;\n                outInfo->mOwnedByUs = false;\n                outQueue.erase(it);\n                outInfo = NULL;\n\n                notifyFillBufferDone(outHeader);\n                outHeader = NULL;\n            }\n            return;\n        }\n\n        uint8_t *bitstream = inHeader->pBuffer + inHeader->nOffset;\n        uint32_t *start_code = (uint32_t *)bitstream;\n        bool volHeader = *start_code == 0xB0010000;\n        if (volHeader) {\n            PVCleanUpVideoDecoder(mHandle);\n            mInitialized = false;\n        }\n\n        if (!mInitialized) {\n            uint8_t *vol_data[1];\n            int32_t vol_size = 0;\n\n            vol_data[0] = NULL;\n\n            if ((inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) || volHeader) {\n                vol_data[0] = bitstream;\n                vol_size = inHeader->nFilledLen;\n            }\n\n            MP4DecodingMode mode =\n                (mMode == MODE_MPEG4) ? MPEG4_MODE : H263_MODE;\n\n            Bool success = PVInitVideoDecoder(\n                    mHandle, vol_data, &vol_size, 1,\n                    outputBufferWidth(), outputBufferHeight(), mode);\n\n            if (!success) {\n                ALOGW(\"PVInitVideoDecoder failed. Unsupported content?\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            MP4DecodingMode actualMode = PVGetDecBitstreamMode(mHandle);\n            if (mode != actualMode) {\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            PVSetPostProcType((VideoDecControls *) mHandle, 0);\n\n            bool hasFrameData = false;\n            if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {\n                inInfo->mOwnedByUs = false;\n                inQueue.erase(inQueue.begin());\n                inInfo = NULL;\n                notifyEmptyBufferDone(inHeader);\n                inHeader = NULL;\n            } else if (volHeader) {\n                hasFrameData = true;\n            }\n\n            mInitialized = true;\n\n            if (mode == MPEG4_MODE && handlePortSettingsChange()) {\n                return;\n            }\n\n            if (!hasFrameData) {\n                continue;\n            }\n        }\n\n        if (!mFramesConfigured) {\n            PortInfo *port = editPortInfo(1);\n            OMX_BUFFERHEADERTYPE *outHeader = port->mBuffers.editItemAt(1).mHeader;\n\n            PVSetReferenceYUV(mHandle, outHeader->pBuffer);\n\n            mFramesConfigured = true;\n        }\n\n        uint32_t useExtTimestamp = (inHeader->nOffset == 0);\n\n        // decoder deals in ms (int32_t), OMX in us (int64_t)\n        // so use fake timestamp instead\n        uint32_t timestamp = 0xFFFFFFFF;\n        if (useExtTimestamp) {\n            mPvToOmxTimeMap.add(mPvTime, inHeader->nTimeStamp);\n            timestamp = mPvTime;\n            mPvTime++;\n        }\n\n        int32_t bufferSize = inHeader->nFilledLen;\n        int32_t tmp = bufferSize;\n\n        OMX_U32 frameSize = (mWidth * mHeight * 3) / 2;\n        if (outHeader->nAllocLen < frameSize) {\n            android_errorWriteLog(0x534e4554, \"27833616\");\n            ALOGE(\"Insufficient output buffer size\");\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n        // The PV decoder is lying to us, sometimes it'll claim to only have\n        // consumed a subset of the buffer when it clearly consumed all of it.\n        // ignore whatever it says...\n        if (PVDecodeVideoFrame(\n                    mHandle, &bitstream, &timestamp, &tmp,\n                    &useExtTimestamp,\n                    outHeader->pBuffer) != PV_TRUE) {\n            ALOGE(\"failed to decode video frame.\");\n\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n\n        // H263 doesn't have VOL header, the frame size information is in short header, i.e. the\n        // decoder may detect size change after PVDecodeVideoFrame.\n        if (handlePortSettingsChange()) {\n            return;\n        }\n\n        // decoder deals in ms, OMX in us.\n        outHeader->nTimeStamp = mPvToOmxTimeMap.valueFor(timestamp);\n        mPvToOmxTimeMap.removeItem(timestamp);\n\n        inHeader->nOffset += bufferSize;\n        inHeader->nFilledLen = 0;\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n        } else {\n            outHeader->nFlags = 0;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        ++mInputBufferCount;\n\n        outHeader->nOffset = 0;\n        outHeader->nFilledLen = frameSize;\n\n        List<BufferInfo *>::iterator it = outQueue.begin();\n        while ((*it)->mHeader != outHeader) {\n            ++it;\n        }\n\n        BufferInfo *outInfo = *it;\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(it);\n        outInfo = NULL;\n\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mNumSamplesOutput;\n    }\n}",
        "func": "void SoftMPEG4::onQueueFilled(OMX_U32 /* portIndex */) {\n    if (mSignalledError || mOutputPortSettingsChange != NONE) {\n        return;\n    }\n\n    List<BufferInfo *> &inQueue = getPortQueue(0);\n    List<BufferInfo *> &outQueue = getPortQueue(1);\n\n    while (!inQueue.empty() && outQueue.size() == kNumOutputBuffers) {\n        BufferInfo *inInfo = *inQueue.begin();\n        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;\n        if (inHeader == NULL) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            continue;\n        }\n\n        PortInfo *port = editPortInfo(1);\n\n        OMX_BUFFERHEADERTYPE *outHeader =\n            port->mBuffers.editItemAt(mNumSamplesOutput & 1).mHeader;\n\n        if (inHeader->nFilledLen == 0) {\n            inQueue.erase(inQueue.begin());\n            inInfo->mOwnedByUs = false;\n            notifyEmptyBufferDone(inHeader);\n\n            ++mInputBufferCount;\n\n            if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n                outHeader->nFilledLen = 0;\n                outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n\n                List<BufferInfo *>::iterator it = outQueue.begin();\n                while ((*it)->mHeader != outHeader) {\n                    ++it;\n                }\n\n                BufferInfo *outInfo = *it;\n                outInfo->mOwnedByUs = false;\n                outQueue.erase(it);\n                outInfo = NULL;\n\n                notifyFillBufferDone(outHeader);\n                outHeader = NULL;\n            }\n            return;\n        }\n\n        uint8_t *bitstream = inHeader->pBuffer + inHeader->nOffset;\n        uint32_t *start_code = (uint32_t *)bitstream;\n        bool volHeader = *start_code == 0xB0010000;\n        if (volHeader) {\n            PVCleanUpVideoDecoder(mHandle);\n            mInitialized = false;\n        }\n\n        if (!mInitialized) {\n            uint8_t *vol_data[1];\n            int32_t vol_size = 0;\n\n            vol_data[0] = NULL;\n\n            if ((inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) || volHeader) {\n                vol_data[0] = bitstream;\n                vol_size = inHeader->nFilledLen;\n            }\n\n            MP4DecodingMode mode =\n                (mMode == MODE_MPEG4) ? MPEG4_MODE : H263_MODE;\n\n            Bool success = PVInitVideoDecoder(\n                    mHandle, vol_data, &vol_size, 1,\n                    outputBufferWidth(), outputBufferHeight(), mode);\n\n            if (!success) {\n                ALOGW(\"PVInitVideoDecoder failed. Unsupported content?\");\n\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            MP4DecodingMode actualMode = PVGetDecBitstreamMode(mHandle);\n            if (mode != actualMode) {\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n\n            PVSetPostProcType((VideoDecControls *) mHandle, 0);\n\n            bool hasFrameData = false;\n            if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {\n                inInfo->mOwnedByUs = false;\n                inQueue.erase(inQueue.begin());\n                inInfo = NULL;\n                notifyEmptyBufferDone(inHeader);\n                inHeader = NULL;\n            } else if (volHeader) {\n                hasFrameData = true;\n            }\n\n            mInitialized = true;\n\n            if (mode == MPEG4_MODE && handlePortSettingsChange()) {\n                return;\n            }\n\n            if (!hasFrameData) {\n                continue;\n            }\n        }\n\n        if (!mFramesConfigured) {\n            PortInfo *port = editPortInfo(1);\n            OMX_BUFFERHEADERTYPE *outHeader = port->mBuffers.editItemAt(1).mHeader;\n\n            OMX_U32 yFrameSize = sizeof(uint8) * mHandle->size;\n            if ((outHeader->nAllocLen < yFrameSize) ||\n                    (outHeader->nAllocLen - yFrameSize < yFrameSize / 2)) {\n                ALOGE(\"Too small output buffer for reference frame: %zu bytes\",\n                        outHeader->nAllocLen);\n                android_errorWriteLog(0x534e4554, \"30033990\");\n                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n                mSignalledError = true;\n                return;\n            }\n            PVSetReferenceYUV(mHandle, outHeader->pBuffer);\n            mFramesConfigured = true;\n        }\n\n        uint32_t useExtTimestamp = (inHeader->nOffset == 0);\n\n        // decoder deals in ms (int32_t), OMX in us (int64_t)\n        // so use fake timestamp instead\n        uint32_t timestamp = 0xFFFFFFFF;\n        if (useExtTimestamp) {\n            mPvToOmxTimeMap.add(mPvTime, inHeader->nTimeStamp);\n            timestamp = mPvTime;\n            mPvTime++;\n        }\n\n        int32_t bufferSize = inHeader->nFilledLen;\n        int32_t tmp = bufferSize;\n\n        OMX_U32 frameSize;\n        OMX_U64 yFrameSize = (OMX_U64)mWidth * (OMX_U64)mHeight;\n        if (yFrameSize > ((OMX_U64)UINT32_MAX / 3) * 2) {\n            ALOGE(\"Frame size too large\");\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n        frameSize = (OMX_U32)(yFrameSize + (yFrameSize / 2));\n\n        if (outHeader->nAllocLen < frameSize) {\n            android_errorWriteLog(0x534e4554, \"27833616\");\n            ALOGE(\"Insufficient output buffer size\");\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n        // The PV decoder is lying to us, sometimes it'll claim to only have\n        // consumed a subset of the buffer when it clearly consumed all of it.\n        // ignore whatever it says...\n        if (PVDecodeVideoFrame(\n                    mHandle, &bitstream, &timestamp, &tmp,\n                    &useExtTimestamp,\n                    outHeader->pBuffer) != PV_TRUE) {\n            ALOGE(\"failed to decode video frame.\");\n\n            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n            mSignalledError = true;\n            return;\n        }\n\n        // H263 doesn't have VOL header, the frame size information is in short header, i.e. the\n        // decoder may detect size change after PVDecodeVideoFrame.\n        if (handlePortSettingsChange()) {\n            return;\n        }\n\n        // decoder deals in ms, OMX in us.\n        outHeader->nTimeStamp = mPvToOmxTimeMap.valueFor(timestamp);\n        mPvToOmxTimeMap.removeItem(timestamp);\n\n        inHeader->nOffset += bufferSize;\n        inHeader->nFilledLen = 0;\n        if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {\n            outHeader->nFlags = OMX_BUFFERFLAG_EOS;\n        } else {\n            outHeader->nFlags = 0;\n        }\n\n        if (inHeader->nFilledLen == 0) {\n            inInfo->mOwnedByUs = false;\n            inQueue.erase(inQueue.begin());\n            inInfo = NULL;\n            notifyEmptyBufferDone(inHeader);\n            inHeader = NULL;\n        }\n\n        ++mInputBufferCount;\n\n        outHeader->nOffset = 0;\n        outHeader->nFilledLen = frameSize;\n\n        List<BufferInfo *>::iterator it = outQueue.begin();\n        while ((*it)->mHeader != outHeader) {\n            ++it;\n        }\n\n        BufferInfo *outInfo = *it;\n        outInfo->mOwnedByUs = false;\n        outQueue.erase(it);\n        outInfo = NULL;\n\n        notifyFillBufferDone(outHeader);\n        outHeader = NULL;\n\n        ++mNumSamplesOutput;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -116,8 +116,17 @@\n             PortInfo *port = editPortInfo(1);\n             OMX_BUFFERHEADERTYPE *outHeader = port->mBuffers.editItemAt(1).mHeader;\n \n+            OMX_U32 yFrameSize = sizeof(uint8) * mHandle->size;\n+            if ((outHeader->nAllocLen < yFrameSize) ||\n+                    (outHeader->nAllocLen - yFrameSize < yFrameSize / 2)) {\n+                ALOGE(\"Too small output buffer for reference frame: %zu bytes\",\n+                        outHeader->nAllocLen);\n+                android_errorWriteLog(0x534e4554, \"30033990\");\n+                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n+                mSignalledError = true;\n+                return;\n+            }\n             PVSetReferenceYUV(mHandle, outHeader->pBuffer);\n-\n             mFramesConfigured = true;\n         }\n \n@@ -135,7 +144,16 @@\n         int32_t bufferSize = inHeader->nFilledLen;\n         int32_t tmp = bufferSize;\n \n-        OMX_U32 frameSize = (mWidth * mHeight * 3) / 2;\n+        OMX_U32 frameSize;\n+        OMX_U64 yFrameSize = (OMX_U64)mWidth * (OMX_U64)mHeight;\n+        if (yFrameSize > ((OMX_U64)UINT32_MAX / 3) * 2) {\n+            ALOGE(\"Frame size too large\");\n+            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);\n+            mSignalledError = true;\n+            return;\n+        }\n+        frameSize = (OMX_U32)(yFrameSize + (yFrameSize / 2));\n+\n         if (outHeader->nAllocLen < frameSize) {\n             android_errorWriteLog(0x534e4554, \"27833616\");\n             ALOGE(\"Insufficient output buffer size\");",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "        OMX_U32 frameSize = (mWidth * mHeight * 3) / 2;"
            ],
            "added_lines": [
                "            OMX_U32 yFrameSize = sizeof(uint8) * mHandle->size;",
                "            if ((outHeader->nAllocLen < yFrameSize) ||",
                "                    (outHeader->nAllocLen - yFrameSize < yFrameSize / 2)) {",
                "                ALOGE(\"Too small output buffer for reference frame: %zu bytes\",",
                "                        outHeader->nAllocLen);",
                "                android_errorWriteLog(0x534e4554, \"30033990\");",
                "                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);",
                "                mSignalledError = true;",
                "                return;",
                "            }",
                "        OMX_U32 frameSize;",
                "        OMX_U64 yFrameSize = (OMX_U64)mWidth * (OMX_U64)mHeight;",
                "        if (yFrameSize > ((OMX_U64)UINT32_MAX / 3) * 2) {",
                "            ALOGE(\"Frame size too large\");",
                "            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);",
                "            mSignalledError = true;",
                "            return;",
                "        }",
                "        frameSize = (OMX_U32)(yFrameSize + (yFrameSize / 2));",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3909",
        "func_name": "android/SoftMPEG4Encoder::initEncParams",
        "description": "The SoftMPEG4 component in libstagefright in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 30033990.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/d4271b792bdad85a80e2b83ab34c4b30b74f53ec",
        "commit_title": "SoftMPEG4: Check the buffer size before writing the reference frame.",
        "commit_text": " Also prevent overflow in SoftMPEG4 and division by zero in SoftMPEG4Encoder.  Bug: 30033990 (cherry picked from commit 695123195034402ca76169b195069c28c30342d3) ",
        "func_before": "OMX_ERRORTYPE SoftMPEG4Encoder::initEncParams() {\n    CHECK(mHandle != NULL);\n    memset(mHandle, 0, sizeof(tagvideoEncControls));\n\n    CHECK(mEncParams != NULL);\n    memset(mEncParams, 0, sizeof(tagvideoEncOptions));\n    if (!PVGetDefaultEncOption(mEncParams, 0)) {\n        ALOGE(\"Failed to get default encoding parameters\");\n        return OMX_ErrorUndefined;\n    }\n    mEncParams->encMode = mEncodeMode;\n    mEncParams->encWidth[0] = mWidth;\n    mEncParams->encHeight[0] = mHeight;\n    mEncParams->encFrameRate[0] = mFramerate >> 16; // mFramerate is in Q16 format\n    mEncParams->rcType = VBR_1;\n    mEncParams->vbvDelay = 5.0f;\n\n    // FIXME:\n    // Add more profile and level support for MPEG4 encoder\n    mEncParams->profile_level = CORE_PROFILE_LEVEL2;\n    mEncParams->packetSize = 32;\n    mEncParams->rvlcEnable = PV_OFF;\n    mEncParams->numLayers = 1;\n    mEncParams->timeIncRes = 1000;\n    mEncParams->tickPerSrc = ((int64_t)mEncParams->timeIncRes << 16) / mFramerate;\n\n    mEncParams->bitRate[0] = mBitrate;\n    mEncParams->iQuant[0] = 15;\n    mEncParams->pQuant[0] = 12;\n    mEncParams->quantType[0] = 0;\n    mEncParams->noFrameSkipped = PV_OFF;\n\n    if (mColorFormat != OMX_COLOR_FormatYUV420Planar || mInputDataIsMeta) {\n        // Color conversion is needed.\n        free(mInputFrameData);\n        mInputFrameData = NULL;\n        if (((uint64_t)mWidth * mHeight) > ((uint64_t)INT32_MAX / 3)) {\n            ALOGE(\"b/25812794, Buffer size is too big.\");\n            return OMX_ErrorBadParameter;\n        }\n        mInputFrameData =\n            (uint8_t *) malloc((mWidth * mHeight * 3 ) >> 1);\n        CHECK(mInputFrameData != NULL);\n    }\n\n    // PV's MPEG4 encoder requires the video dimension of multiple\n    if (mWidth % 16 != 0 || mHeight % 16 != 0) {\n        ALOGE(\"Video frame size %dx%d must be a multiple of 16\",\n            mWidth, mHeight);\n        return OMX_ErrorBadParameter;\n    }\n\n    // Set IDR frame refresh interval\n    if (mIDRFrameRefreshIntervalInSec < 0) {\n        mEncParams->intraPeriod = -1;\n    } else if (mIDRFrameRefreshIntervalInSec == 0) {\n        mEncParams->intraPeriod = 1;  // All I frames\n    } else {\n        mEncParams->intraPeriod =\n            (mIDRFrameRefreshIntervalInSec * mFramerate) >> 16;\n    }\n\n    mEncParams->numIntraMB = 0;\n    mEncParams->sceneDetect = PV_ON;\n    mEncParams->searchRange = 16;\n    mEncParams->mv8x8Enable = PV_OFF;\n    mEncParams->gobHeaderInterval = 0;\n    mEncParams->useACPred = PV_ON;\n    mEncParams->intraDCVlcTh = 0;\n\n    return OMX_ErrorNone;\n}",
        "func": "OMX_ERRORTYPE SoftMPEG4Encoder::initEncParams() {\n    CHECK(mHandle != NULL);\n    memset(mHandle, 0, sizeof(tagvideoEncControls));\n\n    CHECK(mEncParams != NULL);\n    memset(mEncParams, 0, sizeof(tagvideoEncOptions));\n    if (!PVGetDefaultEncOption(mEncParams, 0)) {\n        ALOGE(\"Failed to get default encoding parameters\");\n        return OMX_ErrorUndefined;\n    }\n    if (mFramerate == 0) {\n        ALOGE(\"Framerate should not be 0\");\n        return OMX_ErrorUndefined;\n    }\n    mEncParams->encMode = mEncodeMode;\n    mEncParams->encWidth[0] = mWidth;\n    mEncParams->encHeight[0] = mHeight;\n    mEncParams->encFrameRate[0] = mFramerate >> 16; // mFramerate is in Q16 format\n    mEncParams->rcType = VBR_1;\n    mEncParams->vbvDelay = 5.0f;\n\n    // FIXME:\n    // Add more profile and level support for MPEG4 encoder\n    mEncParams->profile_level = CORE_PROFILE_LEVEL2;\n    mEncParams->packetSize = 32;\n    mEncParams->rvlcEnable = PV_OFF;\n    mEncParams->numLayers = 1;\n    mEncParams->timeIncRes = 1000;\n    mEncParams->tickPerSrc = ((int64_t)mEncParams->timeIncRes << 16) / mFramerate;\n\n    mEncParams->bitRate[0] = mBitrate;\n    mEncParams->iQuant[0] = 15;\n    mEncParams->pQuant[0] = 12;\n    mEncParams->quantType[0] = 0;\n    mEncParams->noFrameSkipped = PV_OFF;\n\n    if (mColorFormat != OMX_COLOR_FormatYUV420Planar || mInputDataIsMeta) {\n        // Color conversion is needed.\n        free(mInputFrameData);\n        mInputFrameData = NULL;\n        if (((uint64_t)mWidth * mHeight) > ((uint64_t)INT32_MAX / 3)) {\n            ALOGE(\"b/25812794, Buffer size is too big.\");\n            return OMX_ErrorBadParameter;\n        }\n        mInputFrameData =\n            (uint8_t *) malloc((mWidth * mHeight * 3 ) >> 1);\n        CHECK(mInputFrameData != NULL);\n    }\n\n    // PV's MPEG4 encoder requires the video dimension of multiple\n    if (mWidth % 16 != 0 || mHeight % 16 != 0) {\n        ALOGE(\"Video frame size %dx%d must be a multiple of 16\",\n            mWidth, mHeight);\n        return OMX_ErrorBadParameter;\n    }\n\n    // Set IDR frame refresh interval\n    if (mIDRFrameRefreshIntervalInSec < 0) {\n        mEncParams->intraPeriod = -1;\n    } else if (mIDRFrameRefreshIntervalInSec == 0) {\n        mEncParams->intraPeriod = 1;  // All I frames\n    } else {\n        mEncParams->intraPeriod =\n            (mIDRFrameRefreshIntervalInSec * mFramerate) >> 16;\n    }\n\n    mEncParams->numIntraMB = 0;\n    mEncParams->sceneDetect = PV_ON;\n    mEncParams->searchRange = 16;\n    mEncParams->mv8x8Enable = PV_OFF;\n    mEncParams->gobHeaderInterval = 0;\n    mEncParams->useACPred = PV_ON;\n    mEncParams->intraDCVlcTh = 0;\n\n    return OMX_ErrorNone;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,10 @@\n     memset(mEncParams, 0, sizeof(tagvideoEncOptions));\n     if (!PVGetDefaultEncOption(mEncParams, 0)) {\n         ALOGE(\"Failed to get default encoding parameters\");\n+        return OMX_ErrorUndefined;\n+    }\n+    if (mFramerate == 0) {\n+        ALOGE(\"Framerate should not be 0\");\n         return OMX_ErrorUndefined;\n     }\n     mEncParams->encMode = mEncodeMode;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        return OMX_ErrorUndefined;",
                "    }",
                "    if (mFramerate == 0) {",
                "        ALOGE(\"Framerate should not be 0\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3910",
        "func_name": "android/SoundTriggerHwService::Module::startRecognition",
        "description": "services/soundtrigger/SoundTriggerHwService.cpp in mediaserver in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 30148546.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/035cb12f392860113dce96116a5150e2fde6f0cc",
        "commit_title": "soundtrigger: add size check on sound model and recogntion data",
        "commit_text": " Bug: 30148546  (cherry picked from commit bb00d8f139ff51336ab3c810d35685003949bcf8) (cherry picked from commit ef0c91518446e65533ca8bab6726a845f27c73fd) ",
        "func_before": "status_t SoundTriggerHwService::Module::startRecognition(sound_model_handle_t handle,\n                                 const sp<IMemory>& dataMemory)\n{\n    ALOGV(\"startRecognition() model handle %d\", handle);\n    if (!captureHotwordAllowed()) {\n        return PERMISSION_DENIED;\n    }\n\n    if (dataMemory != 0 && dataMemory->pointer() == NULL) {\n        ALOGE(\"startRecognition() dataMemory is non-0 but has NULL pointer()\");\n        return BAD_VALUE;\n\n    }\n    AutoMutex lock(mLock);\n    if (mServiceState == SOUND_TRIGGER_STATE_DISABLED) {\n        return INVALID_OPERATION;\n    }\n    sp<Model> model = getModel(handle);\n    if (model == 0) {\n        return BAD_VALUE;\n    }\n    if ((dataMemory == 0) ||\n            (dataMemory->size() < sizeof(struct sound_trigger_recognition_config))) {\n        return BAD_VALUE;\n    }\n\n    if (model->mState == Model::STATE_ACTIVE) {\n        return INVALID_OPERATION;\n    }\n\n    struct sound_trigger_recognition_config *config =\n            (struct sound_trigger_recognition_config *)dataMemory->pointer();\n\n    //TODO: get capture handle and device from audio policy service\n    config->capture_handle = model->mCaptureIOHandle;\n    config->capture_device = model->mCaptureDevice;\n    status_t status = mHwDevice->start_recognition(mHwDevice, handle, config,\n                                        SoundTriggerHwService::recognitionCallback,\n                                        this);\n\n    if (status == NO_ERROR) {\n        model->mState = Model::STATE_ACTIVE;\n        model->mConfig = *config;\n    }\n\n    return status;\n}",
        "func": "status_t SoundTriggerHwService::Module::startRecognition(sound_model_handle_t handle,\n                                 const sp<IMemory>& dataMemory)\n{\n    ALOGV(\"startRecognition() model handle %d\", handle);\n    if (!captureHotwordAllowed()) {\n        return PERMISSION_DENIED;\n    }\n\n    if (dataMemory == 0 || dataMemory->pointer() == NULL) {\n        ALOGE(\"startRecognition() dataMemory is 0 or has NULL pointer()\");\n        return BAD_VALUE;\n\n    }\n\n    struct sound_trigger_recognition_config *config =\n            (struct sound_trigger_recognition_config *)dataMemory->pointer();\n\n    if (config->data_offset < sizeof(struct sound_trigger_recognition_config) ||\n            config->data_size > (UINT_MAX - config->data_offset) ||\n            dataMemory->size() < config->data_offset ||\n            config->data_size > (dataMemory->size() - config->data_offset)) {\n        ALOGE(\"startRecognition() data_size is too big\");\n        return BAD_VALUE;\n    }\n\n    AutoMutex lock(mLock);\n    if (mServiceState == SOUND_TRIGGER_STATE_DISABLED) {\n        return INVALID_OPERATION;\n    }\n    sp<Model> model = getModel(handle);\n    if (model == 0) {\n        return BAD_VALUE;\n    }\n\n    if (model->mState == Model::STATE_ACTIVE) {\n        return INVALID_OPERATION;\n    }\n\n\n    //TODO: get capture handle and device from audio policy service\n    config->capture_handle = model->mCaptureIOHandle;\n    config->capture_device = model->mCaptureDevice;\n    status_t status = mHwDevice->start_recognition(mHwDevice, handle, config,\n                                        SoundTriggerHwService::recognitionCallback,\n                                        this);\n\n    if (status == NO_ERROR) {\n        model->mState = Model::STATE_ACTIVE;\n        model->mConfig = *config;\n    }\n\n    return status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,11 +6,23 @@\n         return PERMISSION_DENIED;\n     }\n \n-    if (dataMemory != 0 && dataMemory->pointer() == NULL) {\n-        ALOGE(\"startRecognition() dataMemory is non-0 but has NULL pointer()\");\n+    if (dataMemory == 0 || dataMemory->pointer() == NULL) {\n+        ALOGE(\"startRecognition() dataMemory is 0 or has NULL pointer()\");\n         return BAD_VALUE;\n \n     }\n+\n+    struct sound_trigger_recognition_config *config =\n+            (struct sound_trigger_recognition_config *)dataMemory->pointer();\n+\n+    if (config->data_offset < sizeof(struct sound_trigger_recognition_config) ||\n+            config->data_size > (UINT_MAX - config->data_offset) ||\n+            dataMemory->size() < config->data_offset ||\n+            config->data_size > (dataMemory->size() - config->data_offset)) {\n+        ALOGE(\"startRecognition() data_size is too big\");\n+        return BAD_VALUE;\n+    }\n+\n     AutoMutex lock(mLock);\n     if (mServiceState == SOUND_TRIGGER_STATE_DISABLED) {\n         return INVALID_OPERATION;\n@@ -19,17 +31,11 @@\n     if (model == 0) {\n         return BAD_VALUE;\n     }\n-    if ((dataMemory == 0) ||\n-            (dataMemory->size() < sizeof(struct sound_trigger_recognition_config))) {\n-        return BAD_VALUE;\n-    }\n \n     if (model->mState == Model::STATE_ACTIVE) {\n         return INVALID_OPERATION;\n     }\n \n-    struct sound_trigger_recognition_config *config =\n-            (struct sound_trigger_recognition_config *)dataMemory->pointer();\n \n     //TODO: get capture handle and device from audio policy service\n     config->capture_handle = model->mCaptureIOHandle;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (dataMemory != 0 && dataMemory->pointer() == NULL) {",
                "        ALOGE(\"startRecognition() dataMemory is non-0 but has NULL pointer()\");",
                "    if ((dataMemory == 0) ||",
                "            (dataMemory->size() < sizeof(struct sound_trigger_recognition_config))) {",
                "        return BAD_VALUE;",
                "    }",
                "    struct sound_trigger_recognition_config *config =",
                "            (struct sound_trigger_recognition_config *)dataMemory->pointer();"
            ],
            "added_lines": [
                "    if (dataMemory == 0 || dataMemory->pointer() == NULL) {",
                "        ALOGE(\"startRecognition() dataMemory is 0 or has NULL pointer()\");",
                "",
                "    struct sound_trigger_recognition_config *config =",
                "            (struct sound_trigger_recognition_config *)dataMemory->pointer();",
                "",
                "    if (config->data_offset < sizeof(struct sound_trigger_recognition_config) ||",
                "            config->data_size > (UINT_MAX - config->data_offset) ||",
                "            dataMemory->size() < config->data_offset ||",
                "            config->data_size > (dataMemory->size() - config->data_offset)) {",
                "        ALOGE(\"startRecognition() data_size is too big\");",
                "        return BAD_VALUE;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3910",
        "func_name": "android/SoundTriggerHwService::Module::loadSoundModel",
        "description": "services/soundtrigger/SoundTriggerHwService.cpp in mediaserver in Android 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 30148546.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/035cb12f392860113dce96116a5150e2fde6f0cc",
        "commit_title": "soundtrigger: add size check on sound model and recogntion data",
        "commit_text": " Bug: 30148546  (cherry picked from commit bb00d8f139ff51336ab3c810d35685003949bcf8) (cherry picked from commit ef0c91518446e65533ca8bab6726a845f27c73fd) ",
        "func_before": "status_t SoundTriggerHwService::Module::loadSoundModel(const sp<IMemory>& modelMemory,\n                                sound_model_handle_t *handle)\n{\n    ALOGV(\"loadSoundModel() handle\");\n    if (!captureHotwordAllowed()) {\n        return PERMISSION_DENIED;\n    }\n\n    if (modelMemory == 0 || modelMemory->pointer() == NULL) {\n        ALOGE(\"loadSoundModel() modelMemory is 0 or has NULL pointer()\");\n        return BAD_VALUE;\n    }\n    struct sound_trigger_sound_model *sound_model =\n            (struct sound_trigger_sound_model *)modelMemory->pointer();\n\n    AutoMutex lock(mLock);\n\n    if (mModels.size() >= mDescriptor.properties.max_sound_models) {\n        ALOGW(\"loadSoundModel(): Not loading, max number of models (%d) would be exceeded\",\n              mDescriptor.properties.max_sound_models);\n        return INVALID_OPERATION;\n    }\n\n    status_t status = mHwDevice->load_sound_model(mHwDevice, sound_model,\n                                                  SoundTriggerHwService::soundModelCallback,\n                                                  this, handle);\n\n    if (status != NO_ERROR) {\n        return status;\n    }\n    audio_session_t session;\n    audio_io_handle_t ioHandle;\n    audio_devices_t device;\n\n    status = AudioSystem::acquireSoundTriggerSession(&session, &ioHandle, &device);\n    if (status != NO_ERROR) {\n        return status;\n    }\n\n    sp<Model> model = new Model(*handle, session, ioHandle, device, sound_model->type);\n    mModels.replaceValueFor(*handle, model);\n\n    return status;\n}",
        "func": "status_t SoundTriggerHwService::Module::loadSoundModel(const sp<IMemory>& modelMemory,\n                                sound_model_handle_t *handle)\n{\n    ALOGV(\"loadSoundModel() handle\");\n    if (!captureHotwordAllowed()) {\n        return PERMISSION_DENIED;\n    }\n\n    if (modelMemory == 0 || modelMemory->pointer() == NULL) {\n        ALOGE(\"loadSoundModel() modelMemory is 0 or has NULL pointer()\");\n        return BAD_VALUE;\n    }\n    struct sound_trigger_sound_model *sound_model =\n            (struct sound_trigger_sound_model *)modelMemory->pointer();\n\n    size_t structSize;\n    if (sound_model->type == SOUND_MODEL_TYPE_KEYPHRASE) {\n        structSize = sizeof(struct sound_trigger_phrase_sound_model);\n    } else {\n        structSize = sizeof(struct sound_trigger_sound_model);\n    }\n\n    if (sound_model->data_offset < structSize ||\n           sound_model->data_size > (UINT_MAX - sound_model->data_offset) ||\n           modelMemory->size() < sound_model->data_offset ||\n           sound_model->data_size > (modelMemory->size() - sound_model->data_offset)) {\n        android_errorWriteLog(0x534e4554, \"30148546\");\n        ALOGE(\"loadSoundModel() data_size is too big\");\n        return BAD_VALUE;\n    }\n\n    AutoMutex lock(mLock);\n\n    if (mModels.size() >= mDescriptor.properties.max_sound_models) {\n        ALOGW(\"loadSoundModel(): Not loading, max number of models (%d) would be exceeded\",\n              mDescriptor.properties.max_sound_models);\n        return INVALID_OPERATION;\n    }\n\n    status_t status = mHwDevice->load_sound_model(mHwDevice, sound_model,\n                                                  SoundTriggerHwService::soundModelCallback,\n                                                  this, handle);\n\n    if (status != NO_ERROR) {\n        return status;\n    }\n    audio_session_t session;\n    audio_io_handle_t ioHandle;\n    audio_devices_t device;\n\n    status = AudioSystem::acquireSoundTriggerSession(&session, &ioHandle, &device);\n    if (status != NO_ERROR) {\n        return status;\n    }\n\n    sp<Model> model = new Model(*handle, session, ioHandle, device, sound_model->type);\n    mModels.replaceValueFor(*handle, model);\n\n    return status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,22 @@\n     }\n     struct sound_trigger_sound_model *sound_model =\n             (struct sound_trigger_sound_model *)modelMemory->pointer();\n+\n+    size_t structSize;\n+    if (sound_model->type == SOUND_MODEL_TYPE_KEYPHRASE) {\n+        structSize = sizeof(struct sound_trigger_phrase_sound_model);\n+    } else {\n+        structSize = sizeof(struct sound_trigger_sound_model);\n+    }\n+\n+    if (sound_model->data_offset < structSize ||\n+           sound_model->data_size > (UINT_MAX - sound_model->data_offset) ||\n+           modelMemory->size() < sound_model->data_offset ||\n+           sound_model->data_size > (modelMemory->size() - sound_model->data_offset)) {\n+        android_errorWriteLog(0x534e4554, \"30148546\");\n+        ALOGE(\"loadSoundModel() data_size is too big\");\n+        return BAD_VALUE;\n+    }\n \n     AutoMutex lock(mLock);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    size_t structSize;",
                "    if (sound_model->type == SOUND_MODEL_TYPE_KEYPHRASE) {",
                "        structSize = sizeof(struct sound_trigger_phrase_sound_model);",
                "    } else {",
                "        structSize = sizeof(struct sound_trigger_sound_model);",
                "    }",
                "",
                "    if (sound_model->data_offset < structSize ||",
                "           sound_model->data_size > (UINT_MAX - sound_model->data_offset) ||",
                "           modelMemory->size() < sound_model->data_offset ||",
                "           sound_model->data_size > (modelMemory->size() - sound_model->data_offset)) {",
                "        android_errorWriteLog(0x534e4554, \"30148546\");",
                "        ALOGE(\"loadSoundModel() data_size is too big\");",
                "        return BAD_VALUE;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3913",
        "func_name": "android/MediaPlayerService::Client::setNextPlayer",
        "description": "media/libmediaplayerservice/MediaPlayerService.cpp in mediaserver in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 does not validate a certain static_cast operation, which allows attackers to gain privileges via a crafted application, aka internal bug 30204103.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/0c3b93c8c2027e74af642967eee5c142c8fd185d",
        "commit_title": "MediaPlayerService: avoid invalid static cast",
        "commit_text": " Bug: 30204103 (cherry picked from commit ee0a0e39acdcf8f97e0d6945c31ff36a06a36e9d) ",
        "func_before": "status_t MediaPlayerService::Client::setNextPlayer(const sp<IMediaPlayer>& player) {\n    ALOGV(\"setNextPlayer\");\n    Mutex::Autolock l(mLock);\n    sp<Client> c = static_cast<Client*>(player.get());\n    mNextClient = c;\n\n    if (c != NULL) {\n        if (mAudioOutput != NULL) {\n            mAudioOutput->setNextOutput(c->mAudioOutput);\n        } else if ((mPlayer != NULL) && !mPlayer->hardwareOutput()) {\n            ALOGE(\"no current audio output\");\n        }\n\n        if ((mPlayer != NULL) && (mNextClient->getPlayer() != NULL)) {\n            mPlayer->setNextPlayer(mNextClient->getPlayer());\n        }\n    }\n\n    return OK;\n}",
        "func": "status_t MediaPlayerService::Client::setNextPlayer(const sp<IMediaPlayer>& player) {\n    ALOGV(\"setNextPlayer\");\n    Mutex::Autolock l(mLock);\n    sp<Client> c = static_cast<Client*>(player.get());\n    if (!mService->hasClient(c)) {\n      return BAD_VALUE;\n    }\n\n    mNextClient = c;\n\n    if (c != NULL) {\n        if (mAudioOutput != NULL) {\n            mAudioOutput->setNextOutput(c->mAudioOutput);\n        } else if ((mPlayer != NULL) && !mPlayer->hardwareOutput()) {\n            ALOGE(\"no current audio output\");\n        }\n\n        if ((mPlayer != NULL) && (mNextClient->getPlayer() != NULL)) {\n            mPlayer->setNextPlayer(mNextClient->getPlayer());\n        }\n    }\n\n    return OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,10 @@\n     ALOGV(\"setNextPlayer\");\n     Mutex::Autolock l(mLock);\n     sp<Client> c = static_cast<Client*>(player.get());\n+    if (!mService->hasClient(c)) {\n+      return BAD_VALUE;\n+    }\n+\n     mNextClient = c;\n \n     if (c != NULL) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (!mService->hasClient(c)) {",
                "      return BAD_VALUE;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3915",
        "func_name": "android/append_camera_metadata",
        "description": "camera/src/camera_metadata.c in the Camera service in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 30591838.",
        "git_url": "https://android.googlesource.com/platform/system/media/+/e9e44f797742f52996ebf307740dad58c28fd9b5",
        "commit_title": "Camera metadata: Check for inconsistent data count",
        "commit_text": " Resolve merge conflict for nyc-release Also check for overflow of data/entry count on append.  Bug: 30591838 ",
        "func_before": "int append_camera_metadata(camera_metadata_t *dst,\n        const camera_metadata_t *src) {\n    if (dst == NULL || src == NULL ) return ERROR;\n\n    if (dst->entry_capacity < src->entry_count + dst->entry_count) return ERROR;\n    if (dst->data_capacity < src->data_count + dst->data_count) return ERROR;\n\n    memcpy(get_entries(dst) + dst->entry_count, get_entries(src),\n            sizeof(camera_metadata_buffer_entry_t[src->entry_count]));\n    memcpy(get_data(dst) + dst->data_count, get_data(src),\n            sizeof(uint8_t[src->data_count]));\n    if (dst->data_count != 0) {\n        camera_metadata_buffer_entry_t *entry = get_entries(dst) + dst->entry_count;\n        for (size_t i = 0; i < src->entry_count; i++, entry++) {\n            if ( calculate_camera_metadata_entry_data_size(entry->type,\n                            entry->count) > 0 ) {\n                entry->data.offset += dst->data_count;\n            }\n        }\n    }\n    if (dst->entry_count == 0) {\n        // Appending onto empty buffer, keep sorted state\n        dst->flags |= src->flags & FLAG_SORTED;\n    } else if (src->entry_count != 0) {\n        // Both src, dst are nonempty, cannot assume sort remains\n        dst->flags &= ~FLAG_SORTED;\n    } else {\n        // Src is empty, keep dst sorted state\n    }\n    dst->entry_count += src->entry_count;\n    dst->data_count += src->data_count;\n\n    assert(validate_camera_metadata_structure(dst, NULL) == OK);\n    return OK;\n}",
        "func": "int append_camera_metadata(camera_metadata_t *dst,\n        const camera_metadata_t *src) {\n    if (dst == NULL || src == NULL ) return ERROR;\n\n    // Check for overflow\n    if (src->entry_count + dst->entry_count < src->entry_count) return ERROR;\n    if (src->data_count + dst->data_count < src->data_count) return ERROR;\n    // Check for space\n    if (dst->entry_capacity < src->entry_count + dst->entry_count) return ERROR;\n    if (dst->data_capacity < src->data_count + dst->data_count) return ERROR;\n\n    memcpy(get_entries(dst) + dst->entry_count, get_entries(src),\n            sizeof(camera_metadata_buffer_entry_t[src->entry_count]));\n    memcpy(get_data(dst) + dst->data_count, get_data(src),\n            sizeof(uint8_t[src->data_count]));\n    if (dst->data_count != 0) {\n        camera_metadata_buffer_entry_t *entry = get_entries(dst) + dst->entry_count;\n        for (size_t i = 0; i < src->entry_count; i++, entry++) {\n            if ( calculate_camera_metadata_entry_data_size(entry->type,\n                            entry->count) > 0 ) {\n                entry->data.offset += dst->data_count;\n            }\n        }\n    }\n    if (dst->entry_count == 0) {\n        // Appending onto empty buffer, keep sorted state\n        dst->flags |= src->flags & FLAG_SORTED;\n    } else if (src->entry_count != 0) {\n        // Both src, dst are nonempty, cannot assume sort remains\n        dst->flags &= ~FLAG_SORTED;\n    } else {\n        // Src is empty, keep dst sorted state\n    }\n    dst->entry_count += src->entry_count;\n    dst->data_count += src->data_count;\n\n    assert(validate_camera_metadata_structure(dst, NULL) == OK);\n    return OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,10 @@\n         const camera_metadata_t *src) {\n     if (dst == NULL || src == NULL ) return ERROR;\n \n+    // Check for overflow\n+    if (src->entry_count + dst->entry_count < src->entry_count) return ERROR;\n+    if (src->data_count + dst->data_count < src->data_count) return ERROR;\n+    // Check for space\n     if (dst->entry_capacity < src->entry_count + dst->entry_count) return ERROR;\n     if (dst->data_capacity < src->data_count + dst->data_count) return ERROR;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // Check for overflow",
                "    if (src->entry_count + dst->entry_count < src->entry_count) return ERROR;",
                "    if (src->data_count + dst->data_count < src->data_count) return ERROR;",
                "    // Check for space"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3915",
        "func_name": "android/validate_camera_metadata_structure",
        "description": "camera/src/camera_metadata.c in the Camera service in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 30591838.",
        "git_url": "https://android.googlesource.com/platform/system/media/+/e9e44f797742f52996ebf307740dad58c28fd9b5",
        "commit_title": "Camera metadata: Check for inconsistent data count",
        "commit_text": " Resolve merge conflict for nyc-release Also check for overflow of data/entry count on append.  Bug: 30591838 ",
        "func_before": "int validate_camera_metadata_structure(const camera_metadata_t *metadata,\n                                       const size_t *expected_size) {\n\n    if (metadata == NULL) {\n        ALOGE(\"%s: metadata is null!\", __FUNCTION__);\n        return ERROR;\n    }\n\n    // Check that the metadata pointer is well-aligned first.\n    {\n        static const struct {\n            const char *name;\n            size_t alignment;\n        } alignments[] = {\n            {\n                .name = \"camera_metadata\",\n                .alignment = METADATA_ALIGNMENT\n            },\n            {\n                .name = \"camera_metadata_buffer_entry\",\n                .alignment = ENTRY_ALIGNMENT\n            },\n            {\n                .name = \"camera_metadata_data\",\n                .alignment = DATA_ALIGNMENT\n            },\n        };\n\n        for (size_t i = 0; i < sizeof(alignments)/sizeof(alignments[0]); ++i) {\n            uintptr_t aligned_ptr = ALIGN_TO(metadata, alignments[i].alignment);\n\n            if ((uintptr_t)metadata != aligned_ptr) {\n                ALOGE(\"%s: Metadata pointer is not aligned (actual %p, \"\n                      \"expected %p) to type %s\",\n                      __FUNCTION__, metadata,\n                      (void*)aligned_ptr, alignments[i].name);\n                return ERROR;\n            }\n        }\n    }\n\n    /**\n     * Check that the metadata contents are correct\n     */\n\n    if (expected_size != NULL && metadata->size > *expected_size) {\n        ALOGE(\"%s: Metadata size (%\" PRIu32 \") should be <= expected size (%zu)\",\n              __FUNCTION__, metadata->size, *expected_size);\n        return ERROR;\n    }\n\n    if (metadata->entry_count > metadata->entry_capacity) {\n        ALOGE(\"%s: Entry count (%\" PRIu32 \") should be <= entry capacity \"\n              \"(%\" PRIu32 \")\",\n              __FUNCTION__, metadata->entry_count, metadata->entry_capacity);\n        return ERROR;\n    }\n\n    const metadata_uptrdiff_t entries_end =\n        metadata->entries_start + metadata->entry_capacity;\n    if (entries_end < metadata->entries_start || // overflow check\n        entries_end > metadata->data_start) {\n\n        ALOGE(\"%s: Entry start + capacity (%\" PRIu32 \") should be <= data start \"\n              \"(%\" PRIu32 \")\",\n               __FUNCTION__,\n              (metadata->entries_start + metadata->entry_capacity),\n              metadata->data_start);\n        return ERROR;\n    }\n\n    const metadata_uptrdiff_t data_end =\n        metadata->data_start + metadata->data_capacity;\n    if (data_end < metadata->data_start || // overflow check\n        data_end > metadata->size) {\n\n        ALOGE(\"%s: Data start + capacity (%\" PRIu32 \") should be <= total size \"\n              \"(%\" PRIu32 \")\",\n               __FUNCTION__,\n              (metadata->data_start + metadata->data_capacity),\n              metadata->size);\n        return ERROR;\n    }\n\n    // Validate each entry\n    const metadata_size_t entry_count = metadata->entry_count;\n    camera_metadata_buffer_entry_t *entries = get_entries(metadata);\n\n    for (size_t i = 0; i < entry_count; ++i) {\n\n        if ((uintptr_t)&entries[i] != ALIGN_TO(&entries[i], ENTRY_ALIGNMENT)) {\n            ALOGE(\"%s: Entry index %zu had bad alignment (address %p),\"\n                  \" expected alignment %zu\",\n                  __FUNCTION__, i, &entries[i], ENTRY_ALIGNMENT);\n            return ERROR;\n        }\n\n        camera_metadata_buffer_entry_t entry = entries[i];\n\n        if (entry.type >= NUM_TYPES) {\n            ALOGE(\"%s: Entry index %zu had a bad type %d\",\n                  __FUNCTION__, i, entry.type);\n            return ERROR;\n        }\n\n        // TODO: fix vendor_tag_ops across processes so we don't need to special\n        //       case vendor-specific tags\n        uint32_t tag_section = entry.tag >> 16;\n        int tag_type = get_camera_metadata_tag_type(entry.tag);\n        if (tag_type != (int)entry.type && tag_section < VENDOR_SECTION) {\n            ALOGE(\"%s: Entry index %zu had tag type %d, but the type was %d\",\n                  __FUNCTION__, i, tag_type, entry.type);\n            return ERROR;\n        }\n\n        size_t data_size;\n        if (validate_and_calculate_camera_metadata_entry_data_size(&data_size, entry.type,\n                entry.count) != OK) {\n            ALOGE(\"%s: Entry data size is invalid. type: %u count: %u\", __FUNCTION__, entry.type,\n                    entry.count);\n            return ERROR;\n        }\n\n        if (data_size != 0) {\n            camera_metadata_data_t *data =\n                    (camera_metadata_data_t*) (get_data(metadata) +\n                                               entry.data.offset);\n\n            if ((uintptr_t)data != ALIGN_TO(data, DATA_ALIGNMENT)) {\n                ALOGE(\"%s: Entry index %zu had bad data alignment (address %p),\"\n                      \" expected align %zu, (tag name %s, data size %zu)\",\n                      __FUNCTION__, i, data, DATA_ALIGNMENT,\n                      get_camera_metadata_tag_name(entry.tag) ?: \"unknown\",\n                      data_size);\n                return ERROR;\n            }\n\n            size_t data_entry_end = entry.data.offset + data_size;\n            if (data_entry_end < entry.data.offset || // overflow check\n                data_entry_end > metadata->data_capacity) {\n\n                ALOGE(\"%s: Entry index %zu data ends (%zu) beyond the capacity \"\n                      \"%\" PRIu32, __FUNCTION__, i, data_entry_end,\n                      metadata->data_capacity);\n                return ERROR;\n            }\n\n        } else if (entry.count == 0) {\n            if (entry.data.offset != 0) {\n                ALOGE(\"%s: Entry index %zu had 0 items, but offset was non-0 \"\n                     \"(%\" PRIu32 \"), tag name: %s\", __FUNCTION__, i, entry.data.offset,\n                        get_camera_metadata_tag_name(entry.tag) ?: \"unknown\");\n                return ERROR;\n            }\n        } // else data stored inline, so we look at value which can be anything.\n    }\n\n    return OK;\n}",
        "func": "int validate_camera_metadata_structure(const camera_metadata_t *metadata,\n                                       const size_t *expected_size) {\n\n    if (metadata == NULL) {\n        ALOGE(\"%s: metadata is null!\", __FUNCTION__);\n        return ERROR;\n    }\n\n    // Check that the metadata pointer is well-aligned first.\n    {\n        static const struct {\n            const char *name;\n            size_t alignment;\n        } alignments[] = {\n            {\n                .name = \"camera_metadata\",\n                .alignment = METADATA_ALIGNMENT\n            },\n            {\n                .name = \"camera_metadata_buffer_entry\",\n                .alignment = ENTRY_ALIGNMENT\n            },\n            {\n                .name = \"camera_metadata_data\",\n                .alignment = DATA_ALIGNMENT\n            },\n        };\n\n        for (size_t i = 0; i < sizeof(alignments)/sizeof(alignments[0]); ++i) {\n            uintptr_t aligned_ptr = ALIGN_TO(metadata, alignments[i].alignment);\n\n            if ((uintptr_t)metadata != aligned_ptr) {\n                ALOGE(\"%s: Metadata pointer is not aligned (actual %p, \"\n                      \"expected %p) to type %s\",\n                      __FUNCTION__, metadata,\n                      (void*)aligned_ptr, alignments[i].name);\n                return ERROR;\n            }\n        }\n    }\n\n    /**\n     * Check that the metadata contents are correct\n     */\n\n    if (expected_size != NULL && metadata->size > *expected_size) {\n        ALOGE(\"%s: Metadata size (%\" PRIu32 \") should be <= expected size (%zu)\",\n              __FUNCTION__, metadata->size, *expected_size);\n        return ERROR;\n    }\n\n    if (metadata->entry_count > metadata->entry_capacity) {\n        ALOGE(\"%s: Entry count (%\" PRIu32 \") should be <= entry capacity \"\n              \"(%\" PRIu32 \")\",\n              __FUNCTION__, metadata->entry_count, metadata->entry_capacity);\n        return ERROR;\n    }\n\n    if (metadata->data_count > metadata->data_capacity) {\n        ALOGE(\"%s: Data count (%\" PRIu32 \") should be <= data capacity \"\n              \"(%\" PRIu32 \")\",\n              __FUNCTION__, metadata->data_count, metadata->data_capacity);\n        android_errorWriteLog(SN_EVENT_LOG_ID, \"30591838\");\n        return ERROR;\n    }\n\n    const metadata_uptrdiff_t entries_end = metadata->entries_start + metadata->entry_capacity;\n    if (entries_end < metadata->entries_start || // overflow check\n        entries_end > metadata->data_start) {\n\n        ALOGE(\"%s: Entry start + capacity (%\" PRIu32 \") should be <= data start \"\n              \"(%\" PRIu32 \")\",\n               __FUNCTION__,\n              (metadata->entries_start + metadata->entry_capacity),\n              metadata->data_start);\n        return ERROR;\n    }\n\n    const metadata_uptrdiff_t data_end =\n        metadata->data_start + metadata->data_capacity;\n    if (data_end < metadata->data_start || // overflow check\n        data_end > metadata->size) {\n\n        ALOGE(\"%s: Data start + capacity (%\" PRIu32 \") should be <= total size \"\n              \"(%\" PRIu32 \")\",\n               __FUNCTION__,\n              (metadata->data_start + metadata->data_capacity),\n              metadata->size);\n        return ERROR;\n    }\n\n    // Validate each entry\n    const metadata_size_t entry_count = metadata->entry_count;\n    camera_metadata_buffer_entry_t *entries = get_entries(metadata);\n\n    for (size_t i = 0; i < entry_count; ++i) {\n\n        if ((uintptr_t)&entries[i] != ALIGN_TO(&entries[i], ENTRY_ALIGNMENT)) {\n            ALOGE(\"%s: Entry index %zu had bad alignment (address %p),\"\n                  \" expected alignment %zu\",\n                  __FUNCTION__, i, &entries[i], ENTRY_ALIGNMENT);\n            return ERROR;\n        }\n\n        camera_metadata_buffer_entry_t entry = entries[i];\n\n        if (entry.type >= NUM_TYPES) {\n            ALOGE(\"%s: Entry index %zu had a bad type %d\",\n                  __FUNCTION__, i, entry.type);\n            return ERROR;\n        }\n\n        // TODO: fix vendor_tag_ops across processes so we don't need to special\n        //       case vendor-specific tags\n        uint32_t tag_section = entry.tag >> 16;\n        int tag_type = get_camera_metadata_tag_type(entry.tag);\n        if (tag_type != (int)entry.type && tag_section < VENDOR_SECTION) {\n            ALOGE(\"%s: Entry index %zu had tag type %d, but the type was %d\",\n                  __FUNCTION__, i, tag_type, entry.type);\n            return ERROR;\n        }\n\n        size_t data_size;\n        if (validate_and_calculate_camera_metadata_entry_data_size(&data_size, entry.type,\n                entry.count) != OK) {\n            ALOGE(\"%s: Entry data size is invalid. type: %u count: %u\", __FUNCTION__, entry.type,\n                    entry.count);\n            return ERROR;\n        }\n\n        if (data_size != 0) {\n            camera_metadata_data_t *data =\n                    (camera_metadata_data_t*) (get_data(metadata) +\n                                               entry.data.offset);\n\n            if ((uintptr_t)data != ALIGN_TO(data, DATA_ALIGNMENT)) {\n                ALOGE(\"%s: Entry index %zu had bad data alignment (address %p),\"\n                      \" expected align %zu, (tag name %s, data size %zu)\",\n                      __FUNCTION__, i, data, DATA_ALIGNMENT,\n                      get_camera_metadata_tag_name(entry.tag) ?: \"unknown\",\n                      data_size);\n                return ERROR;\n            }\n\n            size_t data_entry_end = entry.data.offset + data_size;\n            if (data_entry_end < entry.data.offset || // overflow check\n                data_entry_end > metadata->data_capacity) {\n\n                ALOGE(\"%s: Entry index %zu data ends (%zu) beyond the capacity \"\n                      \"%\" PRIu32, __FUNCTION__, i, data_entry_end,\n                      metadata->data_capacity);\n                return ERROR;\n            }\n\n        } else if (entry.count == 0) {\n            if (entry.data.offset != 0) {\n                ALOGE(\"%s: Entry index %zu had 0 items, but offset was non-0 \"\n                     \"(%\" PRIu32 \"), tag name: %s\", __FUNCTION__, i, entry.data.offset,\n                        get_camera_metadata_tag_name(entry.tag) ?: \"unknown\");\n                return ERROR;\n            }\n        } // else data stored inline, so we look at value which can be anything.\n    }\n\n    return OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -56,8 +56,15 @@\n         return ERROR;\n     }\n \n-    const metadata_uptrdiff_t entries_end =\n-        metadata->entries_start + metadata->entry_capacity;\n+    if (metadata->data_count > metadata->data_capacity) {\n+        ALOGE(\"%s: Data count (%\" PRIu32 \") should be <= data capacity \"\n+              \"(%\" PRIu32 \")\",\n+              __FUNCTION__, metadata->data_count, metadata->data_capacity);\n+        android_errorWriteLog(SN_EVENT_LOG_ID, \"30591838\");\n+        return ERROR;\n+    }\n+\n+    const metadata_uptrdiff_t entries_end = metadata->entries_start + metadata->entry_capacity;\n     if (entries_end < metadata->entries_start || // overflow check\n         entries_end > metadata->data_start) {\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    const metadata_uptrdiff_t entries_end =",
                "        metadata->entries_start + metadata->entry_capacity;"
            ],
            "added_lines": [
                "    if (metadata->data_count > metadata->data_capacity) {",
                "        ALOGE(\"%s: Data count (%\" PRIu32 \") should be <= data capacity \"",
                "              \"(%\" PRIu32 \")\",",
                "              __FUNCTION__, metadata->data_count, metadata->data_capacity);",
                "        android_errorWriteLog(SN_EVENT_LOG_ID, \"30591838\");",
                "        return ERROR;",
                "    }",
                "",
                "    const metadata_uptrdiff_t entries_end = metadata->entries_start + metadata->entry_capacity;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3921",
        "func_name": "android/FrameworkListener::init",
        "description": "libsysutils/src/FrameworkListener.cpp in Framework Listener in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 29831647.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/771ab014c24a682b32990da08e87e2f0ab765bd2",
        "commit_title": "Fix vold vulnerability in FrameworkListener",
        "commit_text": " Modify FrameworkListener to ignore commands that exceed the maximum buffer length and send an error message.  Bug: 29831647 (cherry picked from commit baa126dc158a40bc83c17c6d428c760e5b93fb1a) (cherry picked from commit 470484d2a25ad432190a01d1c763b4b36db33c7e) ",
        "func_before": "void FrameworkListener::init(const char *socketName UNUSED, bool withSeq) {\n    mCommands = new FrameworkCommandCollection();\n    errorRate = 0;\n    mCommandCount = 0;\n    mWithSeq = withSeq;\n}",
        "func": "void FrameworkListener::init(const char *socketName UNUSED, bool withSeq) {\n    mCommands = new FrameworkCommandCollection();\n    errorRate = 0;\n    mCommandCount = 0;\n    mWithSeq = withSeq;\n    mSkipToNextNullByte = false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,4 +3,5 @@\n     errorRate = 0;\n     mCommandCount = 0;\n     mWithSeq = withSeq;\n+    mSkipToNextNullByte = false;\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    mSkipToNextNullByte = false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3921",
        "func_name": "android/FrameworkListener::onDataAvailable",
        "description": "libsysutils/src/FrameworkListener.cpp in Framework Listener in Android 4.x before 4.4.4, 5.0.x before 5.0.2, 5.1.x before 5.1.1, 6.x before 2016-10-01, and 7.0 before 2016-10-01 allows attackers to gain privileges via a crafted application, aka internal bug 29831647.",
        "git_url": "https://android.googlesource.com/platform/system/core/+/771ab014c24a682b32990da08e87e2f0ab765bd2",
        "commit_title": "Fix vold vulnerability in FrameworkListener",
        "commit_text": " Modify FrameworkListener to ignore commands that exceed the maximum buffer length and send an error message.  Bug: 29831647 (cherry picked from commit baa126dc158a40bc83c17c6d428c760e5b93fb1a) (cherry picked from commit 470484d2a25ad432190a01d1c763b4b36db33c7e) ",
        "func_before": "bool FrameworkListener::onDataAvailable(SocketClient *c) {\n    char buffer[CMD_BUF_SIZE];\n    int len;\n\n    len = TEMP_FAILURE_RETRY(read(c->getSocket(), buffer, sizeof(buffer)));\n    if (len < 0) {\n        SLOGE(\"read() failed (%s)\", strerror(errno));\n        return false;\n    } else if (!len)\n        return false;\n   if(buffer[len-1] != '\\0')\n        SLOGW(\"String is not zero-terminated\");\n\n    int offset = 0;\n    int i;\n\n    for (i = 0; i < len; i++) {\n        if (buffer[i] == '\\0') {\n            /* IMPORTANT: dispatchCommand() expects a zero-terminated string */\n            dispatchCommand(c, buffer + offset);\n            offset = i + 1;\n        }\n    }\n\n    return true;\n}",
        "func": "bool FrameworkListener::onDataAvailable(SocketClient *c) {\n    char buffer[CMD_BUF_SIZE];\n    int len;\n\n    len = TEMP_FAILURE_RETRY(read(c->getSocket(), buffer, sizeof(buffer)));\n    if (len < 0) {\n        SLOGE(\"read() failed (%s)\", strerror(errno));\n        return false;\n    } else if (!len) {\n        return false;\n    } else if (buffer[len-1] != '\\0') {\n        SLOGW(\"String is not zero-terminated\");\n        android_errorWriteLog(0x534e4554, \"29831647\");\n        c->sendMsg(500, \"Command too large for buffer\", false);\n        mSkipToNextNullByte = true;\n        return false;\n    }\n\n    int offset = 0;\n    int i;\n\n    for (i = 0; i < len; i++) {\n        if (buffer[i] == '\\0') {\n            /* IMPORTANT: dispatchCommand() expects a zero-terminated string */\n            if (mSkipToNextNullByte) {\n                mSkipToNextNullByte = false;\n            } else {\n                dispatchCommand(c, buffer + offset);\n            }\n            offset = i + 1;\n        }\n    }\n\n    mSkipToNextNullByte = false;\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,10 +6,15 @@\n     if (len < 0) {\n         SLOGE(\"read() failed (%s)\", strerror(errno));\n         return false;\n-    } else if (!len)\n+    } else if (!len) {\n         return false;\n-   if(buffer[len-1] != '\\0')\n+    } else if (buffer[len-1] != '\\0') {\n         SLOGW(\"String is not zero-terminated\");\n+        android_errorWriteLog(0x534e4554, \"29831647\");\n+        c->sendMsg(500, \"Command too large for buffer\", false);\n+        mSkipToNextNullByte = true;\n+        return false;\n+    }\n \n     int offset = 0;\n     int i;\n@@ -17,10 +22,15 @@\n     for (i = 0; i < len; i++) {\n         if (buffer[i] == '\\0') {\n             /* IMPORTANT: dispatchCommand() expects a zero-terminated string */\n-            dispatchCommand(c, buffer + offset);\n+            if (mSkipToNextNullByte) {\n+                mSkipToNextNullByte = false;\n+            } else {\n+                dispatchCommand(c, buffer + offset);\n+            }\n             offset = i + 1;\n         }\n     }\n \n+    mSkipToNextNullByte = false;\n     return true;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    } else if (!len)",
                "   if(buffer[len-1] != '\\0')",
                "            dispatchCommand(c, buffer + offset);"
            ],
            "added_lines": [
                "    } else if (!len) {",
                "    } else if (buffer[len-1] != '\\0') {",
                "        android_errorWriteLog(0x534e4554, \"29831647\");",
                "        c->sendMsg(500, \"Command too large for buffer\", false);",
                "        mSkipToNextNullByte = true;",
                "        return false;",
                "    }",
                "            if (mSkipToNextNullByte) {",
                "                mSkipToNextNullByte = false;",
                "            } else {",
                "                dispatchCommand(c, buffer + offset);",
                "            }",
                "    mSkipToNextNullByte = false;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3922",
        "func_name": "android/RilSapSocket::sendResponse",
        "description": "libril/RilSapSocket.cpp in Telephony in Android 6.x before 2016-10-01 and 7.0 before 2016-10-01 relies on variable-length arrays, which allows attackers to gain privileges via a crafted application, aka internal bug 30202619.",
        "git_url": "https://android.googlesource.com/platform/hardware/ril/+/95610818918f6f11fe7d23aca1380e6c0fac2af0",
        "commit_title": "Replace variable-length arrays on stack with malloc.",
        "commit_text": " Bug: 30202619 (cherry picked from commit 943905bb9f99e3caa856b42c531e2be752da8834) ",
        "func_before": "void RilSapSocket::sendResponse(MsgHeader* hdr) {\n    size_t encoded_size = 0;\n    uint32_t written_size;\n    size_t buffer_size = 0;\n    pb_ostream_t ostream;\n    bool success = false;\n\n    pthread_mutex_lock(&write_lock);\n\n    if ((success = pb_get_encoded_size(&encoded_size, MsgHeader_fields,\n        hdr)) && encoded_size <= INT32_MAX && commandFd != -1) {\n        buffer_size = encoded_size + sizeof(uint32_t);\n        uint8_t buffer[buffer_size];\n        written_size = htonl((uint32_t) encoded_size);\n        ostream = pb_ostream_from_buffer(buffer, buffer_size);\n        pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));\n        success = pb_encode(&ostream, MsgHeader_fields, hdr);\n\n        if (success) {\n            RLOGD(\"Size: %d (0x%x) Size as written: 0x%x\", encoded_size, encoded_size,\n        written_size);\n            log_hex(\"onRequestComplete\", &buffer[sizeof(written_size)], encoded_size);\n            RLOGI(\"[%d] < SAP RESPONSE type: %d. id: %d. error: %d\",\n        hdr->token, hdr->type, hdr->id,hdr->error );\n\n            if ( 0 != blockingWrite_helper(commandFd, buffer, buffer_size)) {\n                RLOGE(\"Error %d while writing to fd\", errno);\n            } else {\n                RLOGD(\"Write successful\");\n            }\n        } else {\n            RLOGE(\"Error while encoding response of type %d id %d buffer_size: %d: %s.\",\n            hdr->type, hdr->id, buffer_size, PB_GET_ERROR(&ostream));\n        }\n    } else {\n    RLOGE(\"Not sending response type %d: encoded_size: %u. commandFd: %d. encoded size result: %d\",\n        hdr->type, encoded_size, commandFd, success);\n    }\n\n    pthread_mutex_unlock(&write_lock);\n}",
        "func": "void RilSapSocket::sendResponse(MsgHeader* hdr) {\n    size_t encoded_size = 0;\n    uint32_t written_size;\n    size_t buffer_size = 0;\n    pb_ostream_t ostream;\n    bool success = false;\n\n    pthread_mutex_lock(&write_lock);\n\n    if ((success = pb_get_encoded_size(&encoded_size, MsgHeader_fields,\n        hdr)) && encoded_size <= INT32_MAX && commandFd != -1) {\n        buffer_size = encoded_size + sizeof(uint32_t);\n        uint8_t* buffer = (uint8_t*)malloc(buffer_size);\n        if (!buffer) {\n            RLOGE(\"sendResponse: OOM\");\n            pthread_mutex_unlock(&write_lock);\n            return;\n        }\n        written_size = htonl((uint32_t) encoded_size);\n        ostream = pb_ostream_from_buffer(buffer, buffer_size);\n        pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));\n        success = pb_encode(&ostream, MsgHeader_fields, hdr);\n\n        if (success) {\n            RLOGD(\"Size: %d (0x%x) Size as written: 0x%x\", encoded_size, encoded_size,\n        written_size);\n            log_hex(\"onRequestComplete\", &buffer[sizeof(written_size)], encoded_size);\n            RLOGI(\"[%d] < SAP RESPONSE type: %d. id: %d. error: %d\",\n        hdr->token, hdr->type, hdr->id,hdr->error );\n\n            if ( 0 != blockingWrite_helper(commandFd, buffer, buffer_size)) {\n                RLOGE(\"Error %d while writing to fd\", errno);\n            } else {\n                RLOGD(\"Write successful\");\n            }\n        } else {\n            RLOGE(\"Error while encoding response of type %d id %d buffer_size: %d: %s.\",\n            hdr->type, hdr->id, buffer_size, PB_GET_ERROR(&ostream));\n        }\n        free(buffer);\n    } else {\n    RLOGE(\"Not sending response type %d: encoded_size: %u. commandFd: %d. encoded size result: %d\",\n        hdr->type, encoded_size, commandFd, success);\n    }\n\n    pthread_mutex_unlock(&write_lock);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,12 @@\n     if ((success = pb_get_encoded_size(&encoded_size, MsgHeader_fields,\n         hdr)) && encoded_size <= INT32_MAX && commandFd != -1) {\n         buffer_size = encoded_size + sizeof(uint32_t);\n-        uint8_t buffer[buffer_size];\n+        uint8_t* buffer = (uint8_t*)malloc(buffer_size);\n+        if (!buffer) {\n+            RLOGE(\"sendResponse: OOM\");\n+            pthread_mutex_unlock(&write_lock);\n+            return;\n+        }\n         written_size = htonl((uint32_t) encoded_size);\n         ostream = pb_ostream_from_buffer(buffer, buffer_size);\n         pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));\n@@ -32,6 +37,7 @@\n             RLOGE(\"Error while encoding response of type %d id %d buffer_size: %d: %s.\",\n             hdr->type, hdr->id, buffer_size, PB_GET_ERROR(&ostream));\n         }\n+        free(buffer);\n     } else {\n     RLOGE(\"Not sending response type %d: encoded_size: %u. commandFd: %d. encoded size result: %d\",\n         hdr->type, encoded_size, commandFd, success);",
        "diff_line_info": {
            "deleted_lines": [
                "        uint8_t buffer[buffer_size];"
            ],
            "added_lines": [
                "        uint8_t* buffer = (uint8_t*)malloc(buffer_size);",
                "        if (!buffer) {",
                "            RLOGE(\"sendResponse: OOM\");",
                "            pthread_mutex_unlock(&write_lock);",
                "            return;",
                "        }",
                "        free(buffer);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3922",
        "func_name": "android/RilSapSocket::sendDisconnect",
        "description": "libril/RilSapSocket.cpp in Telephony in Android 6.x before 2016-10-01 and 7.0 before 2016-10-01 relies on variable-length arrays, which allows attackers to gain privileges via a crafted application, aka internal bug 30202619.",
        "git_url": "https://android.googlesource.com/platform/hardware/ril/+/95610818918f6f11fe7d23aca1380e6c0fac2af0",
        "commit_title": "Replace variable-length arrays on stack with malloc.",
        "commit_text": " Bug: 30202619 (cherry picked from commit 943905bb9f99e3caa856b42c531e2be752da8834) ",
        "func_before": "void RilSapSocket::sendDisconnect() {\n    size_t encoded_size = 0;\n    uint32_t written_size;\n    size_t buffer_size = 0;\n    pb_ostream_t ostream;\n    bool success = false;\n\n    RIL_SIM_SAP_DISCONNECT_REQ disconnectReq;\n\n   if ((success = pb_get_encoded_size(&encoded_size, RIL_SIM_SAP_DISCONNECT_REQ_fields,\n        &disconnectReq)) && encoded_size <= INT32_MAX) {\n        buffer_size = encoded_size + sizeof(uint32_t);\n        uint8_t buffer[buffer_size];\n        written_size = htonl((uint32_t) encoded_size);\n        ostream = pb_ostream_from_buffer(buffer, buffer_size);\n        pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));\n        success = pb_encode(&ostream, RIL_SIM_SAP_DISCONNECT_REQ_fields, buffer);\n\n        if(success) {\n            // Buffer will be deallocated in sOnRequestComplete()\n            pb_bytes_array_t *payload = (pb_bytes_array_t *)calloc(1,\n                    sizeof(pb_bytes_array_t) + written_size);\n            if (!payload) {\n                RLOGE(\"sendDisconnect: OOM\");\n                return;\n            }\n            memcpy(payload->bytes, buffer, written_size);\n            payload->size = written_size;\n            // MsgHeader will be deallocated in sOnRequestComplete()\n            MsgHeader *hdr = (MsgHeader *)malloc(sizeof(MsgHeader));\n            if (!hdr) {\n                RLOGE(\"sendDisconnect: OOM\");\n                free(payload);\n                return;\n            }\n            hdr->payload = payload;\n            hdr->type = MsgType_REQUEST;\n            hdr->id = MsgId_RIL_SIM_SAP_DISCONNECT;\n            hdr->error = Error_RIL_E_SUCCESS;\n            dispatchDisconnect(hdr);\n        }\n        else {\n            RLOGE(\"Encode failed in send disconnect!\");\n        }\n    }\n}",
        "func": "void RilSapSocket::sendDisconnect() {\n    size_t encoded_size = 0;\n    uint32_t written_size;\n    size_t buffer_size = 0;\n    pb_ostream_t ostream;\n    bool success = false;\n\n    RIL_SIM_SAP_DISCONNECT_REQ disconnectReq;\n\n   if ((success = pb_get_encoded_size(&encoded_size, RIL_SIM_SAP_DISCONNECT_REQ_fields,\n        &disconnectReq)) && encoded_size <= INT32_MAX) {\n        buffer_size = encoded_size + sizeof(uint32_t);\n        uint8_t* buffer = (uint8_t*)malloc(buffer_size);\n        if (!buffer) {\n            RLOGE(\"sendDisconnect: OOM\");\n            return;\n        }\n        written_size = htonl((uint32_t) encoded_size);\n        ostream = pb_ostream_from_buffer(buffer, buffer_size);\n        pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));\n        success = pb_encode(&ostream, RIL_SIM_SAP_DISCONNECT_REQ_fields, buffer);\n\n        if(success) {\n            // Buffer will be deallocated in sOnRequestComplete()\n            pb_bytes_array_t *payload = (pb_bytes_array_t *)calloc(1,\n                    sizeof(pb_bytes_array_t) + written_size);\n            if (!payload) {\n                RLOGE(\"sendDisconnect: OOM\");\n                return;\n            }\n            memcpy(payload->bytes, buffer, written_size);\n            payload->size = written_size;\n            // MsgHeader will be deallocated in sOnRequestComplete()\n            MsgHeader *hdr = (MsgHeader *)malloc(sizeof(MsgHeader));\n            if (!hdr) {\n                RLOGE(\"sendDisconnect: OOM\");\n                free(payload);\n                return;\n            }\n            hdr->payload = payload;\n            hdr->type = MsgType_REQUEST;\n            hdr->id = MsgId_RIL_SIM_SAP_DISCONNECT;\n            hdr->error = Error_RIL_E_SUCCESS;\n            dispatchDisconnect(hdr);\n        }\n        else {\n            RLOGE(\"Encode failed in send disconnect!\");\n        }\n        free(buffer);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,11 @@\n    if ((success = pb_get_encoded_size(&encoded_size, RIL_SIM_SAP_DISCONNECT_REQ_fields,\n         &disconnectReq)) && encoded_size <= INT32_MAX) {\n         buffer_size = encoded_size + sizeof(uint32_t);\n-        uint8_t buffer[buffer_size];\n+        uint8_t* buffer = (uint8_t*)malloc(buffer_size);\n+        if (!buffer) {\n+            RLOGE(\"sendDisconnect: OOM\");\n+            return;\n+        }\n         written_size = htonl((uint32_t) encoded_size);\n         ostream = pb_ostream_from_buffer(buffer, buffer_size);\n         pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));\n@@ -42,5 +46,6 @@\n         else {\n             RLOGE(\"Encode failed in send disconnect!\");\n         }\n+        free(buffer);\n     }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        uint8_t buffer[buffer_size];"
            ],
            "added_lines": [
                "        uint8_t* buffer = (uint8_t*)malloc(buffer_size);",
                "        if (!buffer) {",
                "            RLOGE(\"sendDisconnect: OOM\");",
                "            return;",
                "        }",
                "        free(buffer);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8966",
        "func_name": "torvalds/linux/sys_oabi_fcntl64",
        "description": "arch/arm/kernel/sys_oabi-compat.c in the Linux kernel before 4.4 allows local users to gain privileges via a crafted (1) F_OFD_GETLK, (2) F_OFD_SETLK, or (3) F_OFD_SETLKW command in an fcntl64 system call.",
        "git_url": "https://github.com/torvalds/linux/commit/76cc404bfdc0d419c720de4daaf2584542734f42",
        "commit_title": "[PATCH] arm: fix handling of F_OFD_... in oabi_fcntl64()",
        "commit_text": " Cc: stable@vger.kernel.org # 3.15+",
        "func_before": "asmlinkage long sys_oabi_fcntl64(unsigned int fd, unsigned int cmd,\n\t\t\t\t unsigned long arg)\n{\n\tstruct oabi_flock64 user;\n\tstruct flock64 kernel;\n\tmm_segment_t fs = USER_DS; /* initialized to kill a warning */\n\tunsigned long local_arg = arg;\n\tint ret;\n\n\tswitch (cmd) {\n\tcase F_OFD_GETLK:\n\tcase F_OFD_SETLK:\n\tcase F_OFD_SETLKW:\n\tcase F_GETLK64:\n\tcase F_SETLK64:\n\tcase F_SETLKW64:\n\t\tif (copy_from_user(&user, (struct oabi_flock64 __user *)arg,\n\t\t\t\t   sizeof(user)))\n\t\t\treturn -EFAULT;\n\t\tkernel.l_type\t= user.l_type;\n\t\tkernel.l_whence\t= user.l_whence;\n\t\tkernel.l_start\t= user.l_start;\n\t\tkernel.l_len\t= user.l_len;\n\t\tkernel.l_pid\t= user.l_pid;\n\t\tlocal_arg = (unsigned long)&kernel;\n\t\tfs = get_fs();\n\t\tset_fs(KERNEL_DS);\n\t}\n\n\tret = sys_fcntl64(fd, cmd, local_arg);\n\n\tswitch (cmd) {\n\tcase F_GETLK64:\n\t\tif (!ret) {\n\t\t\tuser.l_type\t= kernel.l_type;\n\t\t\tuser.l_whence\t= kernel.l_whence;\n\t\t\tuser.l_start\t= kernel.l_start;\n\t\t\tuser.l_len\t= kernel.l_len;\n\t\t\tuser.l_pid\t= kernel.l_pid;\n\t\t\tif (copy_to_user((struct oabi_flock64 __user *)arg,\n\t\t\t\t\t &user, sizeof(user)))\n\t\t\t\tret = -EFAULT;\n\t\t}\n\tcase F_SETLK64:\n\tcase F_SETLKW64:\n\t\tset_fs(fs);\n\t}\n\n\treturn ret;\n}",
        "func": "asmlinkage long sys_oabi_fcntl64(unsigned int fd, unsigned int cmd,\n\t\t\t\t unsigned long arg)\n{\n\tswitch (cmd) {\n\tcase F_OFD_GETLK:\n\tcase F_OFD_SETLK:\n\tcase F_OFD_SETLKW:\n\tcase F_GETLK64:\n\tcase F_SETLK64:\n\tcase F_SETLKW64:\n\t\treturn do_locks(fd, cmd, arg);\n\n\tdefault:\n\t\treturn sys_fcntl64(fd, cmd, arg);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,12 +1,6 @@\n asmlinkage long sys_oabi_fcntl64(unsigned int fd, unsigned int cmd,\n \t\t\t\t unsigned long arg)\n {\n-\tstruct oabi_flock64 user;\n-\tstruct flock64 kernel;\n-\tmm_segment_t fs = USER_DS; /* initialized to kill a warning */\n-\tunsigned long local_arg = arg;\n-\tint ret;\n-\n \tswitch (cmd) {\n \tcase F_OFD_GETLK:\n \tcase F_OFD_SETLK:\n@@ -14,37 +8,9 @@\n \tcase F_GETLK64:\n \tcase F_SETLK64:\n \tcase F_SETLKW64:\n-\t\tif (copy_from_user(&user, (struct oabi_flock64 __user *)arg,\n-\t\t\t\t   sizeof(user)))\n-\t\t\treturn -EFAULT;\n-\t\tkernel.l_type\t= user.l_type;\n-\t\tkernel.l_whence\t= user.l_whence;\n-\t\tkernel.l_start\t= user.l_start;\n-\t\tkernel.l_len\t= user.l_len;\n-\t\tkernel.l_pid\t= user.l_pid;\n-\t\tlocal_arg = (unsigned long)&kernel;\n-\t\tfs = get_fs();\n-\t\tset_fs(KERNEL_DS);\n+\t\treturn do_locks(fd, cmd, arg);\n+\n+\tdefault:\n+\t\treturn sys_fcntl64(fd, cmd, arg);\n \t}\n-\n-\tret = sys_fcntl64(fd, cmd, local_arg);\n-\n-\tswitch (cmd) {\n-\tcase F_GETLK64:\n-\t\tif (!ret) {\n-\t\t\tuser.l_type\t= kernel.l_type;\n-\t\t\tuser.l_whence\t= kernel.l_whence;\n-\t\t\tuser.l_start\t= kernel.l_start;\n-\t\t\tuser.l_len\t= kernel.l_len;\n-\t\t\tuser.l_pid\t= kernel.l_pid;\n-\t\t\tif (copy_to_user((struct oabi_flock64 __user *)arg,\n-\t\t\t\t\t &user, sizeof(user)))\n-\t\t\t\tret = -EFAULT;\n-\t\t}\n-\tcase F_SETLK64:\n-\tcase F_SETLKW64:\n-\t\tset_fs(fs);\n-\t}\n-\n-\treturn ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct oabi_flock64 user;",
                "\tstruct flock64 kernel;",
                "\tmm_segment_t fs = USER_DS; /* initialized to kill a warning */",
                "\tunsigned long local_arg = arg;",
                "\tint ret;",
                "",
                "\t\tif (copy_from_user(&user, (struct oabi_flock64 __user *)arg,",
                "\t\t\t\t   sizeof(user)))",
                "\t\t\treturn -EFAULT;",
                "\t\tkernel.l_type\t= user.l_type;",
                "\t\tkernel.l_whence\t= user.l_whence;",
                "\t\tkernel.l_start\t= user.l_start;",
                "\t\tkernel.l_len\t= user.l_len;",
                "\t\tkernel.l_pid\t= user.l_pid;",
                "\t\tlocal_arg = (unsigned long)&kernel;",
                "\t\tfs = get_fs();",
                "\t\tset_fs(KERNEL_DS);",
                "",
                "\tret = sys_fcntl64(fd, cmd, local_arg);",
                "",
                "\tswitch (cmd) {",
                "\tcase F_GETLK64:",
                "\t\tif (!ret) {",
                "\t\t\tuser.l_type\t= kernel.l_type;",
                "\t\t\tuser.l_whence\t= kernel.l_whence;",
                "\t\t\tuser.l_start\t= kernel.l_start;",
                "\t\t\tuser.l_len\t= kernel.l_len;",
                "\t\t\tuser.l_pid\t= kernel.l_pid;",
                "\t\t\tif (copy_to_user((struct oabi_flock64 __user *)arg,",
                "\t\t\t\t\t &user, sizeof(user)))",
                "\t\t\t\tret = -EFAULT;",
                "\t\t}",
                "\tcase F_SETLK64:",
                "\tcase F_SETLKW64:",
                "\t\tset_fs(fs);",
                "\t}",
                "",
                "\treturn ret;"
            ],
            "added_lines": [
                "\t\treturn do_locks(fd, cmd, arg);",
                "",
                "\tdefault:",
                "\t\treturn sys_fcntl64(fd, cmd, arg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9120",
        "func_name": "torvalds/linux/ion_handle_put",
        "description": "Race condition in the ion_ioctl function in drivers/staging/android/ion/ion.c in the Linux kernel before 4.6 allows local users to gain privileges or cause a denial of service (use-after-free) by calling ION_IOC_FREE on two CPUs at the same time.",
        "git_url": "https://github.com/torvalds/linux/commit/9590232bb4f4cc824f3425a6e1349afbe6d6d2b7",
        "commit_title": "staging/android/ion : fix a race condition in the ion driver",
        "commit_text": " There is a use-after-free problem in the ion driver. This is caused by a race condition in the ion_ioctl() function.  A handle has ref count of 1 and two tasks on different cpus calls ION_IOC_FREE simultaneously.  cpu 0                                   cpu 1 ------------------------------------------------------- ion_handle_get_by_id() (ref == 2)                             ion_handle_get_by_id()                             (ref == 3)  ion_free() (ref == 2)  ion_handle_put() (ref == 1)                              ion_free()                             (ref == 0 so ion_handle_destroy() is                             called                             and the handle is freed.)                              ion_handle_put() is called and it                             decreases the slub's next free pointer  The problem is detected as an unaligned access in the spin lock functions since it uses load exclusive  instruction. In some cases it corrupts the slub's free pointer which causes a mis-aligned access to the next free pointer.(kmalloc returns a pointer like ffffc0745b4580aa). And it causes lots of other hard-to-debug problems.  This symptom is caused since the first member in the ion_handle structure is the reference count and the ion driver decrements the reference after it has been freed.  To fix this problem client->lock mutex is extended to protect all the codes that uses the handle. ",
        "func_before": "static int ion_handle_put(struct ion_handle *handle)\n{\n\tstruct ion_client *client = handle->client;\n\tint ret;\n\n\tmutex_lock(&client->lock);\n\tret = kref_put(&handle->ref, ion_handle_destroy);\n\tmutex_unlock(&client->lock);\n\n\treturn ret;\n}",
        "func": "int ion_handle_put(struct ion_handle *handle)\n{\n\tstruct ion_client *client = handle->client;\n\tint ret;\n\n\tmutex_lock(&client->lock);\n\tret = ion_handle_put_nolock(handle);\n\tmutex_unlock(&client->lock);\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,10 @@\n-static int ion_handle_put(struct ion_handle *handle)\n+int ion_handle_put(struct ion_handle *handle)\n {\n \tstruct ion_client *client = handle->client;\n \tint ret;\n \n \tmutex_lock(&client->lock);\n-\tret = kref_put(&handle->ref, ion_handle_destroy);\n+\tret = ion_handle_put_nolock(handle);\n \tmutex_unlock(&client->lock);\n \n \treturn ret;",
        "diff_line_info": {
            "deleted_lines": [
                "static int ion_handle_put(struct ion_handle *handle)",
                "\tret = kref_put(&handle->ref, ion_handle_destroy);"
            ],
            "added_lines": [
                "int ion_handle_put(struct ion_handle *handle)",
                "\tret = ion_handle_put_nolock(handle);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9120",
        "func_name": "torvalds/linux/ion_ioctl",
        "description": "Race condition in the ion_ioctl function in drivers/staging/android/ion/ion.c in the Linux kernel before 4.6 allows local users to gain privileges or cause a denial of service (use-after-free) by calling ION_IOC_FREE on two CPUs at the same time.",
        "git_url": "https://github.com/torvalds/linux/commit/9590232bb4f4cc824f3425a6e1349afbe6d6d2b7",
        "commit_title": "staging/android/ion : fix a race condition in the ion driver",
        "commit_text": " There is a use-after-free problem in the ion driver. This is caused by a race condition in the ion_ioctl() function.  A handle has ref count of 1 and two tasks on different cpus calls ION_IOC_FREE simultaneously.  cpu 0                                   cpu 1 ------------------------------------------------------- ion_handle_get_by_id() (ref == 2)                             ion_handle_get_by_id()                             (ref == 3)  ion_free() (ref == 2)  ion_handle_put() (ref == 1)                              ion_free()                             (ref == 0 so ion_handle_destroy() is                             called                             and the handle is freed.)                              ion_handle_put() is called and it                             decreases the slub's next free pointer  The problem is detected as an unaligned access in the spin lock functions since it uses load exclusive  instruction. In some cases it corrupts the slub's free pointer which causes a mis-aligned access to the next free pointer.(kmalloc returns a pointer like ffffc0745b4580aa). And it causes lots of other hard-to-debug problems.  This symptom is caused since the first member in the ion_handle structure is the reference count and the ion driver decrements the reference after it has been freed.  To fix this problem client->lock mutex is extended to protect all the codes that uses the handle. ",
        "func_before": "static long ion_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)\n{\n\tstruct ion_client *client = filp->private_data;\n\tstruct ion_device *dev = client->dev;\n\tstruct ion_handle *cleanup_handle = NULL;\n\tint ret = 0;\n\tunsigned int dir;\n\n\tunion {\n\t\tstruct ion_fd_data fd;\n\t\tstruct ion_allocation_data allocation;\n\t\tstruct ion_handle_data handle;\n\t\tstruct ion_custom_data custom;\n\t} data;\n\n\tdir = ion_ioctl_dir(cmd);\n\n\tif (_IOC_SIZE(cmd) > sizeof(data))\n\t\treturn -EINVAL;\n\n\tif (dir & _IOC_WRITE)\n\t\tif (copy_from_user(&data, (void __user *)arg, _IOC_SIZE(cmd)))\n\t\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase ION_IOC_ALLOC:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\thandle = ion_alloc(client, data.allocation.len,\n\t\t\t\t\t\tdata.allocation.align,\n\t\t\t\t\t\tdata.allocation.heap_id_mask,\n\t\t\t\t\t\tdata.allocation.flags);\n\t\tif (IS_ERR(handle))\n\t\t\treturn PTR_ERR(handle);\n\n\t\tdata.allocation.handle = handle->id;\n\n\t\tcleanup_handle = handle;\n\t\tbreak;\n\t}\n\tcase ION_IOC_FREE:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\thandle = ion_handle_get_by_id(client, data.handle.handle);\n\t\tif (IS_ERR(handle))\n\t\t\treturn PTR_ERR(handle);\n\t\tion_free(client, handle);\n\t\tion_handle_put(handle);\n\t\tbreak;\n\t}\n\tcase ION_IOC_SHARE:\n\tcase ION_IOC_MAP:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\thandle = ion_handle_get_by_id(client, data.handle.handle);\n\t\tif (IS_ERR(handle))\n\t\t\treturn PTR_ERR(handle);\n\t\tdata.fd.fd = ion_share_dma_buf_fd(client, handle);\n\t\tion_handle_put(handle);\n\t\tif (data.fd.fd < 0)\n\t\t\tret = data.fd.fd;\n\t\tbreak;\n\t}\n\tcase ION_IOC_IMPORT:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\thandle = ion_import_dma_buf_fd(client, data.fd.fd);\n\t\tif (IS_ERR(handle))\n\t\t\tret = PTR_ERR(handle);\n\t\telse\n\t\t\tdata.handle.handle = handle->id;\n\t\tbreak;\n\t}\n\tcase ION_IOC_SYNC:\n\t{\n\t\tret = ion_sync_for_device(client, data.fd.fd);\n\t\tbreak;\n\t}\n\tcase ION_IOC_CUSTOM:\n\t{\n\t\tif (!dev->custom_ioctl)\n\t\t\treturn -ENOTTY;\n\t\tret = dev->custom_ioctl(client, data.custom.cmd,\n\t\t\t\t\t\tdata.custom.arg);\n\t\tbreak;\n\t}\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\tif (dir & _IOC_READ) {\n\t\tif (copy_to_user((void __user *)arg, &data, _IOC_SIZE(cmd))) {\n\t\t\tif (cleanup_handle)\n\t\t\t\tion_free(client, cleanup_handle);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\treturn ret;\n}",
        "func": "static long ion_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)\n{\n\tstruct ion_client *client = filp->private_data;\n\tstruct ion_device *dev = client->dev;\n\tstruct ion_handle *cleanup_handle = NULL;\n\tint ret = 0;\n\tunsigned int dir;\n\n\tunion {\n\t\tstruct ion_fd_data fd;\n\t\tstruct ion_allocation_data allocation;\n\t\tstruct ion_handle_data handle;\n\t\tstruct ion_custom_data custom;\n\t} data;\n\n\tdir = ion_ioctl_dir(cmd);\n\n\tif (_IOC_SIZE(cmd) > sizeof(data))\n\t\treturn -EINVAL;\n\n\tif (dir & _IOC_WRITE)\n\t\tif (copy_from_user(&data, (void __user *)arg, _IOC_SIZE(cmd)))\n\t\t\treturn -EFAULT;\n\n\tswitch (cmd) {\n\tcase ION_IOC_ALLOC:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\thandle = ion_alloc(client, data.allocation.len,\n\t\t\t\t\t\tdata.allocation.align,\n\t\t\t\t\t\tdata.allocation.heap_id_mask,\n\t\t\t\t\t\tdata.allocation.flags);\n\t\tif (IS_ERR(handle))\n\t\t\treturn PTR_ERR(handle);\n\n\t\tdata.allocation.handle = handle->id;\n\n\t\tcleanup_handle = handle;\n\t\tbreak;\n\t}\n\tcase ION_IOC_FREE:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\tmutex_lock(&client->lock);\n\t\thandle = ion_handle_get_by_id_nolock(client, data.handle.handle);\n\t\tif (IS_ERR(handle)) {\n\t\t\tmutex_unlock(&client->lock);\n\t\t\treturn PTR_ERR(handle);\n\t\t}\n\t\tion_free_nolock(client, handle);\n\t\tion_handle_put_nolock(handle);\n\t\tmutex_unlock(&client->lock);\n\t\tbreak;\n\t}\n\tcase ION_IOC_SHARE:\n\tcase ION_IOC_MAP:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\thandle = ion_handle_get_by_id(client, data.handle.handle);\n\t\tif (IS_ERR(handle))\n\t\t\treturn PTR_ERR(handle);\n\t\tdata.fd.fd = ion_share_dma_buf_fd(client, handle);\n\t\tion_handle_put(handle);\n\t\tif (data.fd.fd < 0)\n\t\t\tret = data.fd.fd;\n\t\tbreak;\n\t}\n\tcase ION_IOC_IMPORT:\n\t{\n\t\tstruct ion_handle *handle;\n\n\t\thandle = ion_import_dma_buf_fd(client, data.fd.fd);\n\t\tif (IS_ERR(handle))\n\t\t\tret = PTR_ERR(handle);\n\t\telse\n\t\t\tdata.handle.handle = handle->id;\n\t\tbreak;\n\t}\n\tcase ION_IOC_SYNC:\n\t{\n\t\tret = ion_sync_for_device(client, data.fd.fd);\n\t\tbreak;\n\t}\n\tcase ION_IOC_CUSTOM:\n\t{\n\t\tif (!dev->custom_ioctl)\n\t\t\treturn -ENOTTY;\n\t\tret = dev->custom_ioctl(client, data.custom.cmd,\n\t\t\t\t\t\tdata.custom.arg);\n\t\tbreak;\n\t}\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n\n\tif (dir & _IOC_READ) {\n\t\tif (copy_to_user((void __user *)arg, &data, _IOC_SIZE(cmd))) {\n\t\t\tif (cleanup_handle)\n\t\t\t\tion_free(client, cleanup_handle);\n\t\t\treturn -EFAULT;\n\t\t}\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -43,11 +43,15 @@\n \t{\n \t\tstruct ion_handle *handle;\n \n-\t\thandle = ion_handle_get_by_id(client, data.handle.handle);\n-\t\tif (IS_ERR(handle))\n+\t\tmutex_lock(&client->lock);\n+\t\thandle = ion_handle_get_by_id_nolock(client, data.handle.handle);\n+\t\tif (IS_ERR(handle)) {\n+\t\t\tmutex_unlock(&client->lock);\n \t\t\treturn PTR_ERR(handle);\n-\t\tion_free(client, handle);\n-\t\tion_handle_put(handle);\n+\t\t}\n+\t\tion_free_nolock(client, handle);\n+\t\tion_handle_put_nolock(handle);\n+\t\tmutex_unlock(&client->lock);\n \t\tbreak;\n \t}\n \tcase ION_IOC_SHARE:",
        "diff_line_info": {
            "deleted_lines": [
                "\t\thandle = ion_handle_get_by_id(client, data.handle.handle);",
                "\t\tif (IS_ERR(handle))",
                "\t\tion_free(client, handle);",
                "\t\tion_handle_put(handle);"
            ],
            "added_lines": [
                "\t\tmutex_lock(&client->lock);",
                "\t\thandle = ion_handle_get_by_id_nolock(client, data.handle.handle);",
                "\t\tif (IS_ERR(handle)) {",
                "\t\t\tmutex_unlock(&client->lock);",
                "\t\t}",
                "\t\tion_free_nolock(client, handle);",
                "\t\tion_handle_put_nolock(handle);",
                "\t\tmutex_unlock(&client->lock);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9120",
        "func_name": "torvalds/linux/ion_handle_get_by_id",
        "description": "Race condition in the ion_ioctl function in drivers/staging/android/ion/ion.c in the Linux kernel before 4.6 allows local users to gain privileges or cause a denial of service (use-after-free) by calling ION_IOC_FREE on two CPUs at the same time.",
        "git_url": "https://github.com/torvalds/linux/commit/9590232bb4f4cc824f3425a6e1349afbe6d6d2b7",
        "commit_title": "staging/android/ion : fix a race condition in the ion driver",
        "commit_text": " There is a use-after-free problem in the ion driver. This is caused by a race condition in the ion_ioctl() function.  A handle has ref count of 1 and two tasks on different cpus calls ION_IOC_FREE simultaneously.  cpu 0                                   cpu 1 ------------------------------------------------------- ion_handle_get_by_id() (ref == 2)                             ion_handle_get_by_id()                             (ref == 3)  ion_free() (ref == 2)  ion_handle_put() (ref == 1)                              ion_free()                             (ref == 0 so ion_handle_destroy() is                             called                             and the handle is freed.)                              ion_handle_put() is called and it                             decreases the slub's next free pointer  The problem is detected as an unaligned access in the spin lock functions since it uses load exclusive  instruction. In some cases it corrupts the slub's free pointer which causes a mis-aligned access to the next free pointer.(kmalloc returns a pointer like ffffc0745b4580aa). And it causes lots of other hard-to-debug problems.  This symptom is caused since the first member in the ion_handle structure is the reference count and the ion driver decrements the reference after it has been freed.  To fix this problem client->lock mutex is extended to protect all the codes that uses the handle. ",
        "func_before": "static struct ion_handle *ion_handle_get_by_id(struct ion_client *client,\n\t\t\t\t\t\tint id)\n{\n\tstruct ion_handle *handle;\n\n\tmutex_lock(&client->lock);\n\thandle = idr_find(&client->idr, id);\n\tif (handle)\n\t\tion_handle_get(handle);\n\tmutex_unlock(&client->lock);\n\n\treturn handle ? handle : ERR_PTR(-EINVAL);\n}",
        "func": "struct ion_handle *ion_handle_get_by_id(struct ion_client *client,\n\t\t\t\t\t\tint id)\n{\n\tstruct ion_handle *handle;\n\n\tmutex_lock(&client->lock);\n\thandle = ion_handle_get_by_id_nolock(client, id);\n\tmutex_unlock(&client->lock);\n\n\treturn handle;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,11 @@\n-static struct ion_handle *ion_handle_get_by_id(struct ion_client *client,\n+struct ion_handle *ion_handle_get_by_id(struct ion_client *client,\n \t\t\t\t\t\tint id)\n {\n \tstruct ion_handle *handle;\n \n \tmutex_lock(&client->lock);\n-\thandle = idr_find(&client->idr, id);\n-\tif (handle)\n-\t\tion_handle_get(handle);\n+\thandle = ion_handle_get_by_id_nolock(client, id);\n \tmutex_unlock(&client->lock);\n \n-\treturn handle ? handle : ERR_PTR(-EINVAL);\n+\treturn handle;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static struct ion_handle *ion_handle_get_by_id(struct ion_client *client,",
                "\thandle = idr_find(&client->idr, id);",
                "\tif (handle)",
                "\t\tion_handle_get(handle);",
                "\treturn handle ? handle : ERR_PTR(-EINVAL);"
            ],
            "added_lines": [
                "struct ion_handle *ion_handle_get_by_id(struct ion_client *client,",
                "\thandle = ion_handle_get_by_id_nolock(client, id);",
                "\treturn handle;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9120",
        "func_name": "torvalds/linux/ion_free",
        "description": "Race condition in the ion_ioctl function in drivers/staging/android/ion/ion.c in the Linux kernel before 4.6 allows local users to gain privileges or cause a denial of service (use-after-free) by calling ION_IOC_FREE on two CPUs at the same time.",
        "git_url": "https://github.com/torvalds/linux/commit/9590232bb4f4cc824f3425a6e1349afbe6d6d2b7",
        "commit_title": "staging/android/ion : fix a race condition in the ion driver",
        "commit_text": " There is a use-after-free problem in the ion driver. This is caused by a race condition in the ion_ioctl() function.  A handle has ref count of 1 and two tasks on different cpus calls ION_IOC_FREE simultaneously.  cpu 0                                   cpu 1 ------------------------------------------------------- ion_handle_get_by_id() (ref == 2)                             ion_handle_get_by_id()                             (ref == 3)  ion_free() (ref == 2)  ion_handle_put() (ref == 1)                              ion_free()                             (ref == 0 so ion_handle_destroy() is                             called                             and the handle is freed.)                              ion_handle_put() is called and it                             decreases the slub's next free pointer  The problem is detected as an unaligned access in the spin lock functions since it uses load exclusive  instruction. In some cases it corrupts the slub's free pointer which causes a mis-aligned access to the next free pointer.(kmalloc returns a pointer like ffffc0745b4580aa). And it causes lots of other hard-to-debug problems.  This symptom is caused since the first member in the ion_handle structure is the reference count and the ion driver decrements the reference after it has been freed.  To fix this problem client->lock mutex is extended to protect all the codes that uses the handle. ",
        "func_before": "void ion_free(struct ion_client *client, struct ion_handle *handle)\n{\n\tbool valid_handle;\n\n\tBUG_ON(client != handle->client);\n\n\tmutex_lock(&client->lock);\n\tvalid_handle = ion_handle_validate(client, handle);\n\n\tif (!valid_handle) {\n\t\tWARN(1, \"%s: invalid handle passed to free.\\n\", __func__);\n\t\tmutex_unlock(&client->lock);\n\t\treturn;\n\t}\n\tmutex_unlock(&client->lock);\n\tion_handle_put(handle);\n}",
        "func": "void ion_free(struct ion_client *client, struct ion_handle *handle)\n{\n\tBUG_ON(client != handle->client);\n\n\tmutex_lock(&client->lock);\n\tion_free_nolock(client, handle);\n\tmutex_unlock(&client->lock);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,17 +1,8 @@\n void ion_free(struct ion_client *client, struct ion_handle *handle)\n {\n-\tbool valid_handle;\n-\n \tBUG_ON(client != handle->client);\n \n \tmutex_lock(&client->lock);\n-\tvalid_handle = ion_handle_validate(client, handle);\n-\n-\tif (!valid_handle) {\n-\t\tWARN(1, \"%s: invalid handle passed to free.\\n\", __func__);\n-\t\tmutex_unlock(&client->lock);\n-\t\treturn;\n-\t}\n+\tion_free_nolock(client, handle);\n \tmutex_unlock(&client->lock);\n-\tion_handle_put(handle);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tbool valid_handle;",
                "",
                "\tvalid_handle = ion_handle_validate(client, handle);",
                "",
                "\tif (!valid_handle) {",
                "\t\tWARN(1, \"%s: invalid handle passed to free.\\n\", __func__);",
                "\t\tmutex_unlock(&client->lock);",
                "\t\treturn;",
                "\t}",
                "\tion_handle_put(handle);"
            ],
            "added_lines": [
                "\tion_free_nolock(client, handle);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6706",
        "func_name": "android/OMXNodeInstance::enableNativeBuffers",
        "description": "An elevation of privilege vulnerability in libstagefright in Mediaserver in Android 7.0 before 2016-11-01 could enable a local malicious application to execute arbitrary code within the context of a privileged process. This issue is rated as High because it could be used to gain local access to elevated capabilities, which are not normally accessible to a third-party application. Android ID: A-31385713.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/1d4feebdb85db46e138530f360d9ff2490e14353",
        "commit_title": "OMXNodeInstance: sanity check portIndex.",
        "commit_text": " Bug: 31385713 (cherry picked from commit f80a1f5075a7c6e1982d37c68bfed7c9a611bb20) ",
        "func_before": "status_t OMXNodeInstance::enableNativeBuffers(\n        OMX_U32 portIndex, OMX_BOOL graphic, OMX_BOOL enable) {\n    Mutex::Autolock autoLock(mLock);\n    CLOG_CONFIG(enableNativeBuffers, \"%s:%u%s, %d\", portString(portIndex), portIndex,\n                graphic ? \", graphic\" : \"\", enable);\n    OMX_STRING name = const_cast<OMX_STRING>(\n            graphic ? \"OMX.google.android.index.enableAndroidNativeBuffers\"\n                    : \"OMX.google.android.index.allocateNativeHandle\");\n\n    OMX_INDEXTYPE index;\n    OMX_ERRORTYPE err = OMX_GetExtensionIndex(mHandle, name, &index);\n\n    if (err == OMX_ErrorNone) {\n        EnableAndroidNativeBuffersParams params;\n        InitOMXParams(&params);\n        params.nPortIndex = portIndex;\n        params.enable = enable;\n\n        err = OMX_SetParameter(mHandle, index, &params);\n        CLOG_IF_ERROR(setParameter, err, \"%s(%#x): %s:%u en=%d\", name, index,\n                      portString(portIndex), portIndex, enable);\n        if (!graphic) {\n            if (err == OMX_ErrorNone) {\n                mSecureBufferType[portIndex] =\n                    enable ? kSecureBufferTypeNativeHandle : kSecureBufferTypeOpaque;\n            } else if (mSecureBufferType[portIndex] == kSecureBufferTypeUnknown) {\n                mSecureBufferType[portIndex] = kSecureBufferTypeOpaque;\n            }\n        }\n    } else {\n        CLOG_ERROR_IF(enable, getExtensionIndex, err, \"%s\", name);\n        if (!graphic) {\n            // Extension not supported, check for manual override with system property\n            // This is a temporary workaround until partners support the OMX extension\n            char value[PROPERTY_VALUE_MAX];\n            if (property_get(\"media.mediadrmservice.enable\", value, NULL)\n                && (!strcmp(\"1\", value) || !strcasecmp(\"true\", value))) {\n                CLOG_CONFIG(enableNativeBuffers, \"system property override: using native-handles\");\n                mSecureBufferType[portIndex] = kSecureBufferTypeNativeHandle;\n            } else if (mSecureBufferType[portIndex] == kSecureBufferTypeUnknown) {\n                mSecureBufferType[portIndex] = kSecureBufferTypeOpaque;\n            }\n            err = OMX_ErrorNone;\n        }\n    }\n\n    return StatusFromOMXError(err);\n}",
        "func": "status_t OMXNodeInstance::enableNativeBuffers(\n        OMX_U32 portIndex, OMX_BOOL graphic, OMX_BOOL enable) {\n    if (portIndex >= NELEM(mSecureBufferType)) {\n        ALOGE(\"b/31385713, portIndex(%u)\", portIndex);\n        android_errorWriteLog(0x534e4554, \"31385713\");\n        return BAD_VALUE;\n    }\n\n    Mutex::Autolock autoLock(mLock);\n    CLOG_CONFIG(enableNativeBuffers, \"%s:%u%s, %d\", portString(portIndex), portIndex,\n                graphic ? \", graphic\" : \"\", enable);\n    OMX_STRING name = const_cast<OMX_STRING>(\n            graphic ? \"OMX.google.android.index.enableAndroidNativeBuffers\"\n                    : \"OMX.google.android.index.allocateNativeHandle\");\n\n    OMX_INDEXTYPE index;\n    OMX_ERRORTYPE err = OMX_GetExtensionIndex(mHandle, name, &index);\n\n    if (err == OMX_ErrorNone) {\n        EnableAndroidNativeBuffersParams params;\n        InitOMXParams(&params);\n        params.nPortIndex = portIndex;\n        params.enable = enable;\n\n        err = OMX_SetParameter(mHandle, index, &params);\n        CLOG_IF_ERROR(setParameter, err, \"%s(%#x): %s:%u en=%d\", name, index,\n                      portString(portIndex), portIndex, enable);\n        if (!graphic) {\n            if (err == OMX_ErrorNone) {\n                mSecureBufferType[portIndex] =\n                    enable ? kSecureBufferTypeNativeHandle : kSecureBufferTypeOpaque;\n            } else if (mSecureBufferType[portIndex] == kSecureBufferTypeUnknown) {\n                mSecureBufferType[portIndex] = kSecureBufferTypeOpaque;\n            }\n        }\n    } else {\n        CLOG_ERROR_IF(enable, getExtensionIndex, err, \"%s\", name);\n        if (!graphic) {\n            // Extension not supported, check for manual override with system property\n            // This is a temporary workaround until partners support the OMX extension\n            char value[PROPERTY_VALUE_MAX];\n            if (property_get(\"media.mediadrmservice.enable\", value, NULL)\n                && (!strcmp(\"1\", value) || !strcasecmp(\"true\", value))) {\n                CLOG_CONFIG(enableNativeBuffers, \"system property override: using native-handles\");\n                mSecureBufferType[portIndex] = kSecureBufferTypeNativeHandle;\n            } else if (mSecureBufferType[portIndex] == kSecureBufferTypeUnknown) {\n                mSecureBufferType[portIndex] = kSecureBufferTypeOpaque;\n            }\n            err = OMX_ErrorNone;\n        }\n    }\n\n    return StatusFromOMXError(err);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,11 @@\n status_t OMXNodeInstance::enableNativeBuffers(\n         OMX_U32 portIndex, OMX_BOOL graphic, OMX_BOOL enable) {\n+    if (portIndex >= NELEM(mSecureBufferType)) {\n+        ALOGE(\"b/31385713, portIndex(%u)\", portIndex);\n+        android_errorWriteLog(0x534e4554, \"31385713\");\n+        return BAD_VALUE;\n+    }\n+\n     Mutex::Autolock autoLock(mLock);\n     CLOG_CONFIG(enableNativeBuffers, \"%s:%u%s, %d\", portString(portIndex), portIndex,\n                 graphic ? \", graphic\" : \"\", enable);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (portIndex >= NELEM(mSecureBufferType)) {",
                "        ALOGE(\"b/31385713, portIndex(%u)\", portIndex);",
                "        android_errorWriteLog(0x534e4554, \"31385713\");",
                "        return BAD_VALUE;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-6706",
        "func_name": "android/OMXNodeInstance::allocateSecureBuffer",
        "description": "An elevation of privilege vulnerability in libstagefright in Mediaserver in Android 7.0 before 2016-11-01 could enable a local malicious application to execute arbitrary code within the context of a privileged process. This issue is rated as High because it could be used to gain local access to elevated capabilities, which are not normally accessible to a third-party application. Android ID: A-31385713.",
        "git_url": "https://android.googlesource.com/platform/frameworks/av/+/1d4feebdb85db46e138530f360d9ff2490e14353",
        "commit_title": "OMXNodeInstance: sanity check portIndex.",
        "commit_text": " Bug: 31385713 (cherry picked from commit f80a1f5075a7c6e1982d37c68bfed7c9a611bb20) ",
        "func_before": "status_t OMXNodeInstance::allocateSecureBuffer(\n        OMX_U32 portIndex, size_t size, OMX::buffer_id *buffer,\n        void **buffer_data, sp<NativeHandle> *native_handle) {\n    if (buffer == NULL || buffer_data == NULL || native_handle == NULL) {\n        ALOGE(\"b/25884056\");\n        return BAD_VALUE;\n    }\n\n    Mutex::Autolock autoLock(mLock);\n\n    BufferMeta *buffer_meta = new BufferMeta(size, portIndex);\n\n    OMX_BUFFERHEADERTYPE *header;\n\n    OMX_ERRORTYPE err = OMX_AllocateBuffer(\n            mHandle, &header, portIndex, buffer_meta, size);\n\n    if (err != OMX_ErrorNone) {\n        CLOG_ERROR(allocateBuffer, err, BUFFER_FMT(portIndex, \"%zu@\", size));\n        delete buffer_meta;\n        buffer_meta = NULL;\n\n        *buffer = 0;\n\n        return StatusFromOMXError(err);\n    }\n\n    CHECK_EQ(header->pAppPrivate, buffer_meta);\n\n    *buffer = makeBufferID(header);\n    if (mSecureBufferType[portIndex] == kSecureBufferTypeNativeHandle) {\n        *buffer_data = NULL;\n        *native_handle = NativeHandle::create(\n                (native_handle_t *)header->pBuffer, false /* ownsHandle */);\n    } else {\n        *buffer_data = header->pBuffer;\n        *native_handle = NULL;\n    }\n\n    addActiveBuffer(portIndex, *buffer);\n\n    sp<GraphicBufferSource> bufferSource(getGraphicBufferSource());\n    if (bufferSource != NULL && portIndex == kPortIndexInput) {\n        bufferSource->addCodecBuffer(header);\n    }\n    CLOG_BUFFER(allocateSecureBuffer, NEW_BUFFER_FMT(\n            *buffer, portIndex, \"%zu@%p:%p\", size, *buffer_data,\n            *native_handle == NULL ? NULL : (*native_handle)->handle()));\n\n    return OK;\n}",
        "func": "status_t OMXNodeInstance::allocateSecureBuffer(\n        OMX_U32 portIndex, size_t size, OMX::buffer_id *buffer,\n        void **buffer_data, sp<NativeHandle> *native_handle) {\n    if (buffer == NULL || buffer_data == NULL || native_handle == NULL) {\n        ALOGE(\"b/25884056\");\n        return BAD_VALUE;\n    }\n\n    if (portIndex >= NELEM(mSecureBufferType)) {\n        ALOGE(\"b/31385713, portIndex(%u)\", portIndex);\n        android_errorWriteLog(0x534e4554, \"31385713\");\n        return BAD_VALUE;\n    }\n\n    Mutex::Autolock autoLock(mLock);\n\n    BufferMeta *buffer_meta = new BufferMeta(size, portIndex);\n\n    OMX_BUFFERHEADERTYPE *header;\n\n    OMX_ERRORTYPE err = OMX_AllocateBuffer(\n            mHandle, &header, portIndex, buffer_meta, size);\n\n    if (err != OMX_ErrorNone) {\n        CLOG_ERROR(allocateBuffer, err, BUFFER_FMT(portIndex, \"%zu@\", size));\n        delete buffer_meta;\n        buffer_meta = NULL;\n\n        *buffer = 0;\n\n        return StatusFromOMXError(err);\n    }\n\n    CHECK_EQ(header->pAppPrivate, buffer_meta);\n\n    *buffer = makeBufferID(header);\n    if (mSecureBufferType[portIndex] == kSecureBufferTypeNativeHandle) {\n        *buffer_data = NULL;\n        *native_handle = NativeHandle::create(\n                (native_handle_t *)header->pBuffer, false /* ownsHandle */);\n    } else {\n        *buffer_data = header->pBuffer;\n        *native_handle = NULL;\n    }\n\n    addActiveBuffer(portIndex, *buffer);\n\n    sp<GraphicBufferSource> bufferSource(getGraphicBufferSource());\n    if (bufferSource != NULL && portIndex == kPortIndexInput) {\n        bufferSource->addCodecBuffer(header);\n    }\n    CLOG_BUFFER(allocateSecureBuffer, NEW_BUFFER_FMT(\n            *buffer, portIndex, \"%zu@%p:%p\", size, *buffer_data,\n            *native_handle == NULL ? NULL : (*native_handle)->handle()));\n\n    return OK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,12 @@\n         void **buffer_data, sp<NativeHandle> *native_handle) {\n     if (buffer == NULL || buffer_data == NULL || native_handle == NULL) {\n         ALOGE(\"b/25884056\");\n+        return BAD_VALUE;\n+    }\n+\n+    if (portIndex >= NELEM(mSecureBufferType)) {\n+        ALOGE(\"b/31385713, portIndex(%u)\", portIndex);\n+        android_errorWriteLog(0x534e4554, \"31385713\");\n         return BAD_VALUE;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        return BAD_VALUE;",
                "    }",
                "",
                "    if (portIndex >= NELEM(mSecureBufferType)) {",
                "        ALOGE(\"b/31385713, portIndex(%u)\", portIndex);",
                "        android_errorWriteLog(0x534e4554, \"31385713\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7942",
        "func_name": "xorg/lib/libX11/XGetImage",
        "description": "The XGetImage function in X.org libX11 before 1.6.4 might allow remote X servers to gain privileges via vectors involving image type and geometry, which triggers out-of-bounds read operations.",
        "git_url": "https://cgit.freedesktop.org/xorg/lib/libX11/commit/?id=8ea762f94f4c942d898fdeb590a1630c83235c17",
        "commit_title": "Check if enough bytes were received for specified image type and",
        "commit_text": "geometry. Otherwise GetPixel and other functions could trigger an out of boundary read later on.  ",
        "func_before": "XImage *XGetImage (\n     register Display *dpy,\n     Drawable d,\n     int x,\n     int y,\n     unsigned int width,\n     unsigned int height,\n     unsigned long plane_mask,\n     int format)\t/* either XYPixmap or ZPixmap */\n{\n\txGetImageReply rep;\n\tregister xGetImageReq *req;\n\tchar *data;\n\tunsigned long nbytes;\n\tXImage *image;\n\tLockDisplay(dpy);\n\tGetReq (GetImage, req);\n\t/*\n\t * first set up the standard stuff in the request\n\t */\n\treq->drawable = d;\n\treq->x = x;\n\treq->y = y;\n\treq->width = width;\n\treq->height = height;\n\treq->planeMask = plane_mask;\n\treq->format = format;\n\n\tif (_XReply (dpy, (xReply *) &rep, 0, xFalse) == 0 ||\n\t    rep.length == 0) {\n\t\tUnlockDisplay(dpy);\n\t\tSyncHandle();\n\t\treturn (XImage *)NULL;\n\t}\n\n\tif (rep.length < (INT_MAX >> 2)) {\n\t    nbytes = (unsigned long)rep.length << 2;\n\t    data = Xmalloc(nbytes);\n\t} else\n\t    data = NULL;\n\tif (! data) {\n\t    _XEatDataWords(dpy, rep.length);\n\t    UnlockDisplay(dpy);\n\t    SyncHandle();\n\t    return (XImage *) NULL;\n\t}\n        _XReadPad (dpy, data, nbytes);\n        if (format == XYPixmap)\n\t   image = XCreateImage(dpy, _XVIDtoVisual(dpy, rep.visual),\n\t\t  Ones (plane_mask &\n\t\t\t(((unsigned long)0xFFFFFFFF) >> (32 - rep.depth))),\n\t\t  format, 0, data, width, height, dpy->bitmap_pad, 0);\n\telse /* format == ZPixmap */\n           image = XCreateImage (dpy, _XVIDtoVisual(dpy, rep.visual),\n\t\t rep.depth, ZPixmap, 0, data, width, height,\n\t\t  _XGetScanlinePad(dpy, (int) rep.depth), 0);\n\n\tif (!image)\n\t    Xfree(data);\n\tUnlockDisplay(dpy);\n\tSyncHandle();\n\treturn (image);\n}",
        "func": "XImage *XGetImage (\n     register Display *dpy,\n     Drawable d,\n     int x,\n     int y,\n     unsigned int width,\n     unsigned int height,\n     unsigned long plane_mask,\n     int format)\t/* either XYPixmap or ZPixmap */\n{\n\txGetImageReply rep;\n\tregister xGetImageReq *req;\n\tchar *data;\n\tunsigned long nbytes;\n\tXImage *image;\n\tint planes;\n\tLockDisplay(dpy);\n\tGetReq (GetImage, req);\n\t/*\n\t * first set up the standard stuff in the request\n\t */\n\treq->drawable = d;\n\treq->x = x;\n\treq->y = y;\n\treq->width = width;\n\treq->height = height;\n\treq->planeMask = plane_mask;\n\treq->format = format;\n\n\tif (_XReply (dpy, (xReply *) &rep, 0, xFalse) == 0 ||\n\t    rep.length == 0) {\n\t\tUnlockDisplay(dpy);\n\t\tSyncHandle();\n\t\treturn (XImage *)NULL;\n\t}\n\n\tif (rep.length < (INT_MAX >> 2)) {\n\t    nbytes = (unsigned long)rep.length << 2;\n\t    data = Xmalloc(nbytes);\n\t} else\n\t    data = NULL;\n\tif (! data) {\n\t    _XEatDataWords(dpy, rep.length);\n\t    UnlockDisplay(dpy);\n\t    SyncHandle();\n\t    return (XImage *) NULL;\n\t}\n        _XReadPad (dpy, data, nbytes);\n        if (format == XYPixmap) {\n\t    image = XCreateImage(dpy, _XVIDtoVisual(dpy, rep.visual),\n\t\tOnes (plane_mask &\n\t\t    (((unsigned long)0xFFFFFFFF) >> (32 - rep.depth))),\n\t\tformat, 0, data, width, height, dpy->bitmap_pad, 0);\n\t    planes = image->depth;\n\t} else { /* format == ZPixmap */\n            image = XCreateImage (dpy, _XVIDtoVisual(dpy, rep.visual),\n\t\trep.depth, ZPixmap, 0, data, width, height,\n\t\t    _XGetScanlinePad(dpy, (int) rep.depth), 0);\n\t    planes = 1;\n\t}\n\n\tif (!image)\n\t    Xfree(data);\n\tif (planes < 1 || image->height < 1 || image->bytes_per_line < 1 ||\n\t    INT_MAX / image->height <= image->bytes_per_line ||\n\t    INT_MAX / planes <= image->height * image->bytes_per_line ||\n\t    nbytes < planes * image->height * image->bytes_per_line) {\n\t    XDestroyImage(image);\n\t    image = NULL;\n\t}\n\tUnlockDisplay(dpy);\n\tSyncHandle();\n\treturn (image);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,7 @@\n \tchar *data;\n \tunsigned long nbytes;\n \tXImage *image;\n+\tint planes;\n \tLockDisplay(dpy);\n \tGetReq (GetImage, req);\n \t/*\n@@ -45,18 +46,28 @@\n \t    return (XImage *) NULL;\n \t}\n         _XReadPad (dpy, data, nbytes);\n-        if (format == XYPixmap)\n-\t   image = XCreateImage(dpy, _XVIDtoVisual(dpy, rep.visual),\n-\t\t  Ones (plane_mask &\n-\t\t\t(((unsigned long)0xFFFFFFFF) >> (32 - rep.depth))),\n-\t\t  format, 0, data, width, height, dpy->bitmap_pad, 0);\n-\telse /* format == ZPixmap */\n-           image = XCreateImage (dpy, _XVIDtoVisual(dpy, rep.visual),\n-\t\t rep.depth, ZPixmap, 0, data, width, height,\n-\t\t  _XGetScanlinePad(dpy, (int) rep.depth), 0);\n+        if (format == XYPixmap) {\n+\t    image = XCreateImage(dpy, _XVIDtoVisual(dpy, rep.visual),\n+\t\tOnes (plane_mask &\n+\t\t    (((unsigned long)0xFFFFFFFF) >> (32 - rep.depth))),\n+\t\tformat, 0, data, width, height, dpy->bitmap_pad, 0);\n+\t    planes = image->depth;\n+\t} else { /* format == ZPixmap */\n+            image = XCreateImage (dpy, _XVIDtoVisual(dpy, rep.visual),\n+\t\trep.depth, ZPixmap, 0, data, width, height,\n+\t\t    _XGetScanlinePad(dpy, (int) rep.depth), 0);\n+\t    planes = 1;\n+\t}\n \n \tif (!image)\n \t    Xfree(data);\n+\tif (planes < 1 || image->height < 1 || image->bytes_per_line < 1 ||\n+\t    INT_MAX / image->height <= image->bytes_per_line ||\n+\t    INT_MAX / planes <= image->height * image->bytes_per_line ||\n+\t    nbytes < planes * image->height * image->bytes_per_line) {\n+\t    XDestroyImage(image);\n+\t    image = NULL;\n+\t}\n \tUnlockDisplay(dpy);\n \tSyncHandle();\n \treturn (image);",
        "diff_line_info": {
            "deleted_lines": [
                "        if (format == XYPixmap)",
                "\t   image = XCreateImage(dpy, _XVIDtoVisual(dpy, rep.visual),",
                "\t\t  Ones (plane_mask &",
                "\t\t\t(((unsigned long)0xFFFFFFFF) >> (32 - rep.depth))),",
                "\t\t  format, 0, data, width, height, dpy->bitmap_pad, 0);",
                "\telse /* format == ZPixmap */",
                "           image = XCreateImage (dpy, _XVIDtoVisual(dpy, rep.visual),",
                "\t\t rep.depth, ZPixmap, 0, data, width, height,",
                "\t\t  _XGetScanlinePad(dpy, (int) rep.depth), 0);"
            ],
            "added_lines": [
                "\tint planes;",
                "        if (format == XYPixmap) {",
                "\t    image = XCreateImage(dpy, _XVIDtoVisual(dpy, rep.visual),",
                "\t\tOnes (plane_mask &",
                "\t\t    (((unsigned long)0xFFFFFFFF) >> (32 - rep.depth))),",
                "\t\tformat, 0, data, width, height, dpy->bitmap_pad, 0);",
                "\t    planes = image->depth;",
                "\t} else { /* format == ZPixmap */",
                "            image = XCreateImage (dpy, _XVIDtoVisual(dpy, rep.visual),",
                "\t\trep.depth, ZPixmap, 0, data, width, height,",
                "\t\t    _XGetScanlinePad(dpy, (int) rep.depth), 0);",
                "\t    planes = 1;",
                "\t}",
                "\tif (planes < 1 || image->height < 1 || image->bytes_per_line < 1 ||",
                "\t    INT_MAX / image->height <= image->bytes_per_line ||",
                "\t    INT_MAX / planes <= image->height * image->bytes_per_line ||",
                "\t    nbytes < planes * image->height * image->bytes_per_line) {",
                "\t    XDestroyImage(image);",
                "\t    image = NULL;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-7944",
        "func_name": "xorg/lib/libXfixes/XFixesFetchRegionAndBounds",
        "description": "Integer overflow in X.org libXfixes before 5.0.3 on 32-bit platforms might allow remote X servers to gain privileges via a length value of INT_MAX, which triggers the client to stop reading data and get out of sync.",
        "git_url": "https://cgit.freedesktop.org/xorg/lib/libXfixes/commit/?id=61c1039ee23a2d1de712843bed3480654d7ef42e",
        "commit_title": "The 32 bit field \"rep.length\" is not checked for validity, which allows",
        "commit_text": "an integer overflow on 32 bit systems.  A malicious server could send INT_MAX as length, which gets multiplied by the size of XRectangle. In that case the client won't read the whole data from server, getting out of sync.  ",
        "func_before": "XRectangle *\nXFixesFetchRegionAndBounds (Display\t    *dpy,\n\t\t\t    XserverRegion   region,\n\t\t\t    int\t\t    *nrectanglesRet,\n\t\t\t    XRectangle\t    *bounds)\n{\n    XFixesExtDisplayInfo\t*info = XFixesFindDisplay (dpy);\n    xXFixesFetchRegionReq\t*req;\n    xXFixesFetchRegionReply\trep;\n    XRectangle\t\t\t*rects;\n    int    \t\t\tnrects;\n    long    \t\t\tnbytes;\n    long\t\t\tnread;\n\n    XFixesCheckExtension (dpy, info, NULL);\n    LockDisplay (dpy);\n    GetReq (XFixesFetchRegion, req);\n    req->reqType = info->codes->major_opcode;\n    req->xfixesReqType = X_XFixesFetchRegion;\n    req->region = region;\n    *nrectanglesRet = 0;\n    if (!_XReply (dpy, (xReply *) &rep, 0, xFalse))\n    {\n\tUnlockDisplay (dpy);\n\tSyncHandle ();\n\treturn NULL;\n    }\n    bounds->x = rep.x;\n    bounds->y = rep.y;\n    bounds->width = rep.width;\n    bounds->height = rep.height;\n    nbytes = (long) rep.length << 2;\n    nrects = rep.length >> 1;\n    rects = Xmalloc (nrects * sizeof (XRectangle));\n    if (!rects)\n    {\n\t_XEatDataWords(dpy, rep.length);\n\tUnlockDisplay (dpy);\n\tSyncHandle ();\n\treturn NULL;\n    }\n    nread = nrects << 3;\n    _XRead16 (dpy, (short *) rects, nread);\n    /* skip any padding */\n    if(nbytes > nread)\n    {\n\t_XEatData (dpy, (unsigned long) (nbytes - nread));\n    }\n    UnlockDisplay (dpy);\n    SyncHandle();\n    *nrectanglesRet = nrects;\n    return rects;\n}",
        "func": "XRectangle *\nXFixesFetchRegionAndBounds (Display\t    *dpy,\n\t\t\t    XserverRegion   region,\n\t\t\t    int\t\t    *nrectanglesRet,\n\t\t\t    XRectangle\t    *bounds)\n{\n    XFixesExtDisplayInfo\t*info = XFixesFindDisplay (dpy);\n    xXFixesFetchRegionReq\t*req;\n    xXFixesFetchRegionReply\trep;\n    XRectangle\t\t\t*rects;\n    int    \t\t\tnrects;\n    long    \t\t\tnbytes;\n    long\t\t\tnread;\n\n    XFixesCheckExtension (dpy, info, NULL);\n    LockDisplay (dpy);\n    GetReq (XFixesFetchRegion, req);\n    req->reqType = info->codes->major_opcode;\n    req->xfixesReqType = X_XFixesFetchRegion;\n    req->region = region;\n    *nrectanglesRet = 0;\n    if (!_XReply (dpy, (xReply *) &rep, 0, xFalse))\n    {\n\tUnlockDisplay (dpy);\n\tSyncHandle ();\n\treturn NULL;\n    }\n    bounds->x = rep.x;\n    bounds->y = rep.y;\n    bounds->width = rep.width;\n    bounds->height = rep.height;\n\n    if (rep.length < (INT_MAX >> 2)) {\n\tnbytes = (long) rep.length << 2;\n\tnrects = rep.length >> 1;\n\trects = Xmalloc (nrects * sizeof (XRectangle));\n    } else {\n\tnbytes = 0;\n\tnrects = 0;\n\trects = NULL;\n    }\n\n    if (!rects)\n    {\n\t_XEatDataWords(dpy, rep.length);\n\tUnlockDisplay (dpy);\n\tSyncHandle ();\n\treturn NULL;\n    }\n    nread = nrects << 3;\n    _XRead16 (dpy, (short *) rects, nread);\n    /* skip any padding */\n    if(nbytes > nread)\n    {\n\t_XEatData (dpy, (unsigned long) (nbytes - nread));\n    }\n    UnlockDisplay (dpy);\n    SyncHandle();\n    *nrectanglesRet = nrects;\n    return rects;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,9 +29,17 @@\n     bounds->y = rep.y;\n     bounds->width = rep.width;\n     bounds->height = rep.height;\n-    nbytes = (long) rep.length << 2;\n-    nrects = rep.length >> 1;\n-    rects = Xmalloc (nrects * sizeof (XRectangle));\n+\n+    if (rep.length < (INT_MAX >> 2)) {\n+\tnbytes = (long) rep.length << 2;\n+\tnrects = rep.length >> 1;\n+\trects = Xmalloc (nrects * sizeof (XRectangle));\n+    } else {\n+\tnbytes = 0;\n+\tnrects = 0;\n+\trects = NULL;\n+    }\n+\n     if (!rects)\n     {\n \t_XEatDataWords(dpy, rep.length);",
        "diff_line_info": {
            "deleted_lines": [
                "    nbytes = (long) rep.length << 2;",
                "    nrects = rep.length >> 1;",
                "    rects = Xmalloc (nrects * sizeof (XRectangle));"
            ],
            "added_lines": [
                "",
                "    if (rep.length < (INT_MAX >> 2)) {",
                "\tnbytes = (long) rep.length << 2;",
                "\tnrects = rep.length >> 1;",
                "\trects = Xmalloc (nrects * sizeof (XRectangle));",
                "    } else {",
                "\tnbytes = 0;",
                "\tnrects = 0;",
                "\trects = NULL;",
                "    }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10010",
        "func_name": "openbsd/src/server_input_global_request",
        "description": "sshd in OpenSSH before 7.4, when privilege separation is not used, creates forwarded Unix-domain sockets as root, which might allow local users to gain privileges via unspecified vectors, related to serverloop.c.",
        "git_url": "https://github.com/openbsd/src/commit/c76fac666ea038753294f2ac94d310f8adece9ce",
        "commit_title": "disable Unix-domain socket forwarding when privsep is disabled",
        "commit_text": "",
        "func_before": "static int\nserver_input_global_request(int type, u_int32_t seq, void *ctxt)\n{\n\tchar *rtype;\n\tint want_reply;\n\tint r, success = 0, allocated_listen_port = 0;\n\tstruct sshbuf *resp = NULL;\n\n\trtype = packet_get_string(NULL);\n\twant_reply = packet_get_char();\n\tdebug(\"server_input_global_request: rtype %s want_reply %d\", rtype, want_reply);\n\n\t/* -R style forwarding */\n\tif (strcmp(rtype, \"tcpip-forward\") == 0) {\n\t\tstruct passwd *pw;\n\t\tstruct Forward fwd;\n\n\t\tpw = the_authctxt->pw;\n\t\tif (pw == NULL || !the_authctxt->valid)\n\t\t\tfatal(\"server_input_global_request: no/invalid user\");\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_host = packet_get_string(NULL);\n\t\tfwd.listen_port = (u_short)packet_get_int();\n\t\tdebug(\"server_input_global_request: tcpip-forward listen %s port %d\",\n\t\t    fwd.listen_host, fwd.listen_port);\n\n\t\t/* check permissions */\n\t\tif ((options.allow_tcp_forwarding & FORWARD_REMOTE) == 0 ||\n\t\t    no_port_forwarding_flag || options.disable_forwarding ||\n\t\t    (!want_reply && fwd.listen_port == 0) ||\n\t\t    (fwd.listen_port != 0 &&\n\t\t     !bind_permitted(fwd.listen_port, pw->pw_uid))) {\n\t\t\tsuccess = 0;\n\t\t\tpacket_send_debug(\"Server has disabled port forwarding.\");\n\t\t} else {\n\t\t\t/* Start listening on the port */\n\t\t\tsuccess = channel_setup_remote_fwd_listener(&fwd,\n\t\t\t    &allocated_listen_port, &options.fwd_opts);\n\t\t}\n\t\tfree(fwd.listen_host);\n\t\tif ((resp = sshbuf_new()) == NULL)\n\t\t\tfatal(\"%s: sshbuf_new\", __func__);\n\t\tif (allocated_listen_port != 0 &&\n\t\t    (r = sshbuf_put_u32(resp, allocated_listen_port)) != 0)\n\t\t\tfatal(\"%s: sshbuf_put_u32: %s\", __func__, ssh_err(r));\n\t} else if (strcmp(rtype, \"cancel-tcpip-forward\") == 0) {\n\t\tstruct Forward fwd;\n\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_host = packet_get_string(NULL);\n\t\tfwd.listen_port = (u_short)packet_get_int();\n\t\tdebug(\"%s: cancel-tcpip-forward addr %s port %d\", __func__,\n\t\t    fwd.listen_host, fwd.listen_port);\n\n\t\tsuccess = channel_cancel_rport_listener(&fwd);\n\t\tfree(fwd.listen_host);\n\t} else if (strcmp(rtype, \"streamlocal-forward@openssh.com\") == 0) {\n\t\tstruct Forward fwd;\n\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_path = packet_get_string(NULL);\n\t\tdebug(\"server_input_global_request: streamlocal-forward listen path %s\",\n\t\t    fwd.listen_path);\n\n\t\t/* check permissions */\n\t\tif ((options.allow_streamlocal_forwarding & FORWARD_REMOTE) == 0\n\t\t    || no_port_forwarding_flag || options.disable_forwarding) {\n\t\t\tsuccess = 0;\n\t\t\tpacket_send_debug(\"Server has disabled port forwarding.\");\n\t\t} else {\n\t\t\t/* Start listening on the socket */\n\t\t\tsuccess = channel_setup_remote_fwd_listener(\n\t\t\t    &fwd, NULL, &options.fwd_opts);\n\t\t}\n\t\tfree(fwd.listen_path);\n\t} else if (strcmp(rtype, \"cancel-streamlocal-forward@openssh.com\") == 0) {\n\t\tstruct Forward fwd;\n\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_path = packet_get_string(NULL);\n\t\tdebug(\"%s: cancel-streamlocal-forward path %s\", __func__,\n\t\t    fwd.listen_path);\n\n\t\tsuccess = channel_cancel_rport_listener(&fwd);\n\t\tfree(fwd.listen_path);\n\t} else if (strcmp(rtype, \"no-more-sessions@openssh.com\") == 0) {\n\t\tno_more_sessions = 1;\n\t\tsuccess = 1;\n\t} else if (strcmp(rtype, \"hostkeys-prove-00@openssh.com\") == 0) {\n\t\tsuccess = server_input_hostkeys_prove(&resp);\n\t}\n\tif (want_reply) {\n\t\tpacket_start(success ?\n\t\t    SSH2_MSG_REQUEST_SUCCESS : SSH2_MSG_REQUEST_FAILURE);\n\t\tif (success && resp != NULL)\n\t\t\tssh_packet_put_raw(active_state, sshbuf_ptr(resp),\n\t\t\t    sshbuf_len(resp));\n\t\tpacket_send();\n\t\tpacket_write_wait();\n\t}\n\tfree(rtype);\n\tsshbuf_free(resp);\n\treturn 0;\n}",
        "func": "static int\nserver_input_global_request(int type, u_int32_t seq, void *ctxt)\n{\n\tchar *rtype;\n\tint want_reply;\n\tint r, success = 0, allocated_listen_port = 0;\n\tstruct sshbuf *resp = NULL;\n\n\trtype = packet_get_string(NULL);\n\twant_reply = packet_get_char();\n\tdebug(\"server_input_global_request: rtype %s want_reply %d\", rtype, want_reply);\n\n\t/* -R style forwarding */\n\tif (strcmp(rtype, \"tcpip-forward\") == 0) {\n\t\tstruct passwd *pw;\n\t\tstruct Forward fwd;\n\n\t\tpw = the_authctxt->pw;\n\t\tif (pw == NULL || !the_authctxt->valid)\n\t\t\tfatal(\"server_input_global_request: no/invalid user\");\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_host = packet_get_string(NULL);\n\t\tfwd.listen_port = (u_short)packet_get_int();\n\t\tdebug(\"server_input_global_request: tcpip-forward listen %s port %d\",\n\t\t    fwd.listen_host, fwd.listen_port);\n\n\t\t/* check permissions */\n\t\tif ((options.allow_tcp_forwarding & FORWARD_REMOTE) == 0 ||\n\t\t    no_port_forwarding_flag || options.disable_forwarding ||\n\t\t    (!want_reply && fwd.listen_port == 0) ||\n\t\t    (fwd.listen_port != 0 &&\n\t\t     !bind_permitted(fwd.listen_port, pw->pw_uid))) {\n\t\t\tsuccess = 0;\n\t\t\tpacket_send_debug(\"Server has disabled port forwarding.\");\n\t\t} else {\n\t\t\t/* Start listening on the port */\n\t\t\tsuccess = channel_setup_remote_fwd_listener(&fwd,\n\t\t\t    &allocated_listen_port, &options.fwd_opts);\n\t\t}\n\t\tfree(fwd.listen_host);\n\t\tif ((resp = sshbuf_new()) == NULL)\n\t\t\tfatal(\"%s: sshbuf_new\", __func__);\n\t\tif (allocated_listen_port != 0 &&\n\t\t    (r = sshbuf_put_u32(resp, allocated_listen_port)) != 0)\n\t\t\tfatal(\"%s: sshbuf_put_u32: %s\", __func__, ssh_err(r));\n\t} else if (strcmp(rtype, \"cancel-tcpip-forward\") == 0) {\n\t\tstruct Forward fwd;\n\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_host = packet_get_string(NULL);\n\t\tfwd.listen_port = (u_short)packet_get_int();\n\t\tdebug(\"%s: cancel-tcpip-forward addr %s port %d\", __func__,\n\t\t    fwd.listen_host, fwd.listen_port);\n\n\t\tsuccess = channel_cancel_rport_listener(&fwd);\n\t\tfree(fwd.listen_host);\n\t} else if (strcmp(rtype, \"streamlocal-forward@openssh.com\") == 0) {\n\t\tstruct Forward fwd;\n\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_path = packet_get_string(NULL);\n\t\tdebug(\"server_input_global_request: streamlocal-forward listen path %s\",\n\t\t    fwd.listen_path);\n\n\t\t/* check permissions */\n\t\tif ((options.allow_streamlocal_forwarding & FORWARD_REMOTE) == 0\n\t\t    || no_port_forwarding_flag || options.disable_forwarding ||\n\t\t    !use_privsep) {\n\t\t\tsuccess = 0;\n\t\t\tpacket_send_debug(\"Server has disabled port forwarding.\");\n\t\t} else {\n\t\t\t/* Start listening on the socket */\n\t\t\tsuccess = channel_setup_remote_fwd_listener(\n\t\t\t    &fwd, NULL, &options.fwd_opts);\n\t\t}\n\t\tfree(fwd.listen_path);\n\t} else if (strcmp(rtype, \"cancel-streamlocal-forward@openssh.com\") == 0) {\n\t\tstruct Forward fwd;\n\n\t\tmemset(&fwd, 0, sizeof(fwd));\n\t\tfwd.listen_path = packet_get_string(NULL);\n\t\tdebug(\"%s: cancel-streamlocal-forward path %s\", __func__,\n\t\t    fwd.listen_path);\n\n\t\tsuccess = channel_cancel_rport_listener(&fwd);\n\t\tfree(fwd.listen_path);\n\t} else if (strcmp(rtype, \"no-more-sessions@openssh.com\") == 0) {\n\t\tno_more_sessions = 1;\n\t\tsuccess = 1;\n\t} else if (strcmp(rtype, \"hostkeys-prove-00@openssh.com\") == 0) {\n\t\tsuccess = server_input_hostkeys_prove(&resp);\n\t}\n\tif (want_reply) {\n\t\tpacket_start(success ?\n\t\t    SSH2_MSG_REQUEST_SUCCESS : SSH2_MSG_REQUEST_FAILURE);\n\t\tif (success && resp != NULL)\n\t\t\tssh_packet_put_raw(active_state, sshbuf_ptr(resp),\n\t\t\t    sshbuf_len(resp));\n\t\tpacket_send();\n\t\tpacket_write_wait();\n\t}\n\tfree(rtype);\n\tsshbuf_free(resp);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -64,7 +64,8 @@\n \n \t\t/* check permissions */\n \t\tif ((options.allow_streamlocal_forwarding & FORWARD_REMOTE) == 0\n-\t\t    || no_port_forwarding_flag || options.disable_forwarding) {\n+\t\t    || no_port_forwarding_flag || options.disable_forwarding ||\n+\t\t    !use_privsep) {\n \t\t\tsuccess = 0;\n \t\t\tpacket_send_debug(\"Server has disabled port forwarding.\");\n \t\t} else {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t    || no_port_forwarding_flag || options.disable_forwarding) {"
            ],
            "added_lines": [
                "\t\t    || no_port_forwarding_flag || options.disable_forwarding ||",
                "\t\t    !use_privsep) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10010",
        "func_name": "openbsd/src/server_request_direct_streamlocal",
        "description": "sshd in OpenSSH before 7.4, when privilege separation is not used, creates forwarded Unix-domain sockets as root, which might allow local users to gain privileges via unspecified vectors, related to serverloop.c.",
        "git_url": "https://github.com/openbsd/src/commit/c76fac666ea038753294f2ac94d310f8adece9ce",
        "commit_title": "disable Unix-domain socket forwarding when privsep is disabled",
        "commit_text": "",
        "func_before": "static Channel *\nserver_request_direct_streamlocal(void)\n{\n\tChannel *c = NULL;\n\tchar *target, *originator;\n\tu_short originator_port;\n\n\ttarget = packet_get_string(NULL);\n\toriginator = packet_get_string(NULL);\n\toriginator_port = packet_get_int();\n\tpacket_check_eom();\n\n\tdebug(\"server_request_direct_streamlocal: originator %s port %d, target %s\",\n\t    originator, originator_port, target);\n\n\t/* XXX fine grained permissions */\n\tif ((options.allow_streamlocal_forwarding & FORWARD_LOCAL) != 0 &&\n\t    !no_port_forwarding_flag && !options.disable_forwarding) {\n\t\tc = channel_connect_to_path(target,\n\t\t    \"direct-streamlocal@openssh.com\", \"direct-streamlocal\");\n\t} else {\n\t\tlogit(\"refused streamlocal port forward: \"\n\t\t    \"originator %s port %d, target %s\",\n\t\t    originator, originator_port, target);\n\t}\n\n\tfree(originator);\n\tfree(target);\n\n\treturn c;\n}",
        "func": "static Channel *\nserver_request_direct_streamlocal(void)\n{\n\tChannel *c = NULL;\n\tchar *target, *originator;\n\tu_short originator_port;\n\n\ttarget = packet_get_string(NULL);\n\toriginator = packet_get_string(NULL);\n\toriginator_port = packet_get_int();\n\tpacket_check_eom();\n\n\tdebug(\"server_request_direct_streamlocal: originator %s port %d, target %s\",\n\t    originator, originator_port, target);\n\n\t/* XXX fine grained permissions */\n\tif ((options.allow_streamlocal_forwarding & FORWARD_LOCAL) != 0 &&\n\t    !no_port_forwarding_flag && !options.disable_forwarding &&\n\t    use_privsep) {\n\t\tc = channel_connect_to_path(target,\n\t\t    \"direct-streamlocal@openssh.com\", \"direct-streamlocal\");\n\t} else {\n\t\tlogit(\"refused streamlocal port forward: \"\n\t\t    \"originator %s port %d, target %s\",\n\t\t    originator, originator_port, target);\n\t}\n\n\tfree(originator);\n\tfree(target);\n\n\treturn c;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,8 @@\n \n \t/* XXX fine grained permissions */\n \tif ((options.allow_streamlocal_forwarding & FORWARD_LOCAL) != 0 &&\n-\t    !no_port_forwarding_flag && !options.disable_forwarding) {\n+\t    !no_port_forwarding_flag && !options.disable_forwarding &&\n+\t    use_privsep) {\n \t\tc = channel_connect_to_path(target,\n \t\t    \"direct-streamlocal@openssh.com\", \"direct-streamlocal\");\n \t} else {",
        "diff_line_info": {
            "deleted_lines": [
                "\t    !no_port_forwarding_flag && !options.disable_forwarding) {"
            ],
            "added_lines": [
                "\t    !no_port_forwarding_flag && !options.disable_forwarding &&",
                "\t    use_privsep) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10156",
        "func_name": "systemd/timer_enter_running",
        "description": "A flaw in systemd v228 in /src/basic/fs-util.c caused world writable suid files to be created when using the systemd timers features, allowing local attackers to escalate their privileges to root. This is fixed in v229.",
        "git_url": "https://github.com/systemd/systemd/commit/ee735086f8670be1591fa9593e80dd60163a7a2f",
        "commit_title": "util-lib: use MODE_INVALID as invalid value for mode_t everywhere",
        "commit_text": "",
        "func_before": "static void timer_enter_running(Timer *t) {\n        _cleanup_bus_error_free_ sd_bus_error error = SD_BUS_ERROR_NULL;\n        int r;\n\n        assert(t);\n\n        /* Don't start job if we are supposed to go down */\n        if (unit_stop_pending(UNIT(t)))\n                return;\n\n        r = manager_add_job(UNIT(t)->manager, JOB_START, UNIT_TRIGGER(UNIT(t)),\n                            JOB_REPLACE, true, &error, NULL);\n        if (r < 0)\n                goto fail;\n\n        dual_timestamp_get(&t->last_trigger);\n\n        if (t->stamp_path)\n                touch_file(t->stamp_path, true, t->last_trigger.realtime, UID_INVALID, GID_INVALID, 0);\n\n        timer_set_state(t, TIMER_RUNNING);\n        return;\n\nfail:\n        log_unit_warning(UNIT(t), \"Failed to queue unit startup job: %s\", bus_error_message(&error, r));\n        timer_enter_dead(t, TIMER_FAILURE_RESOURCES);\n}",
        "func": "static void timer_enter_running(Timer *t) {\n        _cleanup_bus_error_free_ sd_bus_error error = SD_BUS_ERROR_NULL;\n        int r;\n\n        assert(t);\n\n        /* Don't start job if we are supposed to go down */\n        if (unit_stop_pending(UNIT(t)))\n                return;\n\n        r = manager_add_job(UNIT(t)->manager, JOB_START, UNIT_TRIGGER(UNIT(t)),\n                            JOB_REPLACE, true, &error, NULL);\n        if (r < 0)\n                goto fail;\n\n        dual_timestamp_get(&t->last_trigger);\n\n        if (t->stamp_path)\n                touch_file(t->stamp_path, true, t->last_trigger.realtime, UID_INVALID, GID_INVALID, MODE_INVALID);\n\n        timer_set_state(t, TIMER_RUNNING);\n        return;\n\nfail:\n        log_unit_warning(UNIT(t), \"Failed to queue unit startup job: %s\", bus_error_message(&error, r));\n        timer_enter_dead(t, TIMER_FAILURE_RESOURCES);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,7 +16,7 @@\n         dual_timestamp_get(&t->last_trigger);\n \n         if (t->stamp_path)\n-                touch_file(t->stamp_path, true, t->last_trigger.realtime, UID_INVALID, GID_INVALID, 0);\n+                touch_file(t->stamp_path, true, t->last_trigger.realtime, UID_INVALID, GID_INVALID, MODE_INVALID);\n \n         timer_set_state(t, TIMER_RUNNING);\n         return;",
        "diff_line_info": {
            "deleted_lines": [
                "                touch_file(t->stamp_path, true, t->last_trigger.realtime, UID_INVALID, GID_INVALID, 0);"
            ],
            "added_lines": [
                "                touch_file(t->stamp_path, true, t->last_trigger.realtime, UID_INVALID, GID_INVALID, MODE_INVALID);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10156",
        "func_name": "systemd/timer_start",
        "description": "A flaw in systemd v228 in /src/basic/fs-util.c caused world writable suid files to be created when using the systemd timers features, allowing local attackers to escalate their privileges to root. This is fixed in v229.",
        "git_url": "https://github.com/systemd/systemd/commit/ee735086f8670be1591fa9593e80dd60163a7a2f",
        "commit_title": "util-lib: use MODE_INVALID as invalid value for mode_t everywhere",
        "commit_text": "",
        "func_before": "static int timer_start(Unit *u) {\n        Timer *t = TIMER(u);\n        TimerValue *v;\n\n        assert(t);\n        assert(t->state == TIMER_DEAD || t->state == TIMER_FAILED);\n\n        if (UNIT_TRIGGER(u)->load_state != UNIT_LOADED)\n                return -ENOENT;\n\n        t->last_trigger = DUAL_TIMESTAMP_NULL;\n\n        /* Reenable all timers that depend on unit activation time */\n        LIST_FOREACH(value, v, t->values)\n                if (v->base == TIMER_ACTIVE)\n                        v->disabled = false;\n\n        if (t->stamp_path) {\n                struct stat st;\n\n                if (stat(t->stamp_path, &st) >= 0)\n                        t->last_trigger.realtime = timespec_load(&st.st_atim);\n                else if (errno == ENOENT)\n                        /* The timer has never run before,\n                         * make sure a stamp file exists.\n                         */\n                        touch_file(t->stamp_path, true, USEC_INFINITY, UID_INVALID, GID_INVALID, 0);\n        }\n\n        t->result = TIMER_SUCCESS;\n        timer_enter_waiting(t, true);\n        return 1;\n}",
        "func": "static int timer_start(Unit *u) {\n        Timer *t = TIMER(u);\n        TimerValue *v;\n\n        assert(t);\n        assert(t->state == TIMER_DEAD || t->state == TIMER_FAILED);\n\n        if (UNIT_TRIGGER(u)->load_state != UNIT_LOADED)\n                return -ENOENT;\n\n        t->last_trigger = DUAL_TIMESTAMP_NULL;\n\n        /* Reenable all timers that depend on unit activation time */\n        LIST_FOREACH(value, v, t->values)\n                if (v->base == TIMER_ACTIVE)\n                        v->disabled = false;\n\n        if (t->stamp_path) {\n                struct stat st;\n\n                if (stat(t->stamp_path, &st) >= 0)\n                        t->last_trigger.realtime = timespec_load(&st.st_atim);\n                else if (errno == ENOENT)\n                        /* The timer has never run before,\n                         * make sure a stamp file exists.\n                         */\n                        touch_file(t->stamp_path, true, USEC_INFINITY, UID_INVALID, GID_INVALID, MODE_INVALID);\n        }\n\n        t->result = TIMER_SUCCESS;\n        timer_enter_waiting(t, true);\n        return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,7 +24,7 @@\n                         /* The timer has never run before,\n                          * make sure a stamp file exists.\n                          */\n-                        touch_file(t->stamp_path, true, USEC_INFINITY, UID_INVALID, GID_INVALID, 0);\n+                        touch_file(t->stamp_path, true, USEC_INFINITY, UID_INVALID, GID_INVALID, MODE_INVALID);\n         }\n \n         t->result = TIMER_SUCCESS;",
        "diff_line_info": {
            "deleted_lines": [
                "                        touch_file(t->stamp_path, true, USEC_INFINITY, UID_INVALID, GID_INVALID, 0);"
            ],
            "added_lines": [
                "                        touch_file(t->stamp_path, true, USEC_INFINITY, UID_INVALID, GID_INVALID, MODE_INVALID);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10156",
        "func_name": "systemd/touch_file",
        "description": "A flaw in systemd v228 in /src/basic/fs-util.c caused world writable suid files to be created when using the systemd timers features, allowing local attackers to escalate their privileges to root. This is fixed in v229.",
        "git_url": "https://github.com/systemd/systemd/commit/ee735086f8670be1591fa9593e80dd60163a7a2f",
        "commit_title": "util-lib: use MODE_INVALID as invalid value for mode_t everywhere",
        "commit_text": "",
        "func_before": "int touch_file(const char *path, bool parents, usec_t stamp, uid_t uid, gid_t gid, mode_t mode) {\n        _cleanup_close_ int fd;\n        int r;\n\n        assert(path);\n\n        if (parents)\n                mkdir_parents(path, 0755);\n\n        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY, mode > 0 ? mode : 0644);\n        if (fd < 0)\n                return -errno;\n\n        if (mode > 0) {\n                r = fchmod(fd, mode);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (uid != UID_INVALID || gid != GID_INVALID) {\n                r = fchown(fd, uid, gid);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (stamp != USEC_INFINITY) {\n                struct timespec ts[2];\n\n                timespec_store(&ts[0], stamp);\n                ts[1] = ts[0];\n                r = futimens(fd, ts);\n        } else\n                r = futimens(fd, NULL);\n        if (r < 0)\n                return -errno;\n\n        return 0;\n}",
        "func": "int touch_file(const char *path, bool parents, usec_t stamp, uid_t uid, gid_t gid, mode_t mode) {\n        _cleanup_close_ int fd;\n        int r;\n\n        assert(path);\n\n        if (parents)\n                mkdir_parents(path, 0755);\n\n        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY, mode > 0 ? mode : 0644);\n        if (fd < 0)\n                return -errno;\n\n        if (mode != MODE_INVALID) {\n                r = fchmod(fd, mode);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (uid != UID_INVALID || gid != GID_INVALID) {\n                r = fchown(fd, uid, gid);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (stamp != USEC_INFINITY) {\n                struct timespec ts[2];\n\n                timespec_store(&ts[0], stamp);\n                ts[1] = ts[0];\n                r = futimens(fd, ts);\n        } else\n                r = futimens(fd, NULL);\n        if (r < 0)\n                return -errno;\n\n        return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n         if (fd < 0)\n                 return -errno;\n \n-        if (mode > 0) {\n+        if (mode != MODE_INVALID) {\n                 r = fchmod(fd, mode);\n                 if (r < 0)\n                         return -errno;",
        "diff_line_info": {
            "deleted_lines": [
                "        if (mode > 0) {"
            ],
            "added_lines": [
                "        if (mode != MODE_INVALID) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10156",
        "func_name": "systemd/touch",
        "description": "A flaw in systemd v228 in /src/basic/fs-util.c caused world writable suid files to be created when using the systemd timers features, allowing local attackers to escalate their privileges to root. This is fixed in v229.",
        "git_url": "https://github.com/systemd/systemd/commit/ee735086f8670be1591fa9593e80dd60163a7a2f",
        "commit_title": "util-lib: use MODE_INVALID as invalid value for mode_t everywhere",
        "commit_text": "",
        "func_before": "int touch(const char *path) {\n        return touch_file(path, false, USEC_INFINITY, UID_INVALID, GID_INVALID, 0);\n}",
        "func": "int touch(const char *path) {\n        return touch_file(path, false, USEC_INFINITY, UID_INVALID, GID_INVALID, MODE_INVALID);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,3 +1,3 @@\n int touch(const char *path) {\n-        return touch_file(path, false, USEC_INFINITY, UID_INVALID, GID_INVALID, 0);\n+        return touch_file(path, false, USEC_INFINITY, UID_INVALID, GID_INVALID, MODE_INVALID);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "        return touch_file(path, false, USEC_INFINITY, UID_INVALID, GID_INVALID, 0);"
            ],
            "added_lines": [
                "        return touch_file(path, false, USEC_INFINITY, UID_INVALID, GID_INVALID, MODE_INVALID);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10156",
        "func_name": "systemd/touch_file",
        "description": "A flaw in systemd v228 in /src/basic/fs-util.c caused world writable suid files to be created when using the systemd timers features, allowing local attackers to escalate their privileges to root. This is fixed in v229.",
        "git_url": "https://github.com/systemd/systemd/commit/06eeacb6fe029804f296b065b3ce91e796e1cd0e",
        "commit_title": "basic: fix touch() creating files with 07777 mode",
        "commit_text": " mode_t is unsigned, so MODE_INVALID < 0 can never be true.  This fixes a possible DoS where any user could fill /run by writing to a world-writable /run/systemd/show-status.",
        "func_before": "int touch_file(const char *path, bool parents, usec_t stamp, uid_t uid, gid_t gid, mode_t mode) {\n        _cleanup_close_ int fd;\n        int r;\n\n        assert(path);\n\n        if (parents)\n                mkdir_parents(path, 0755);\n\n        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY, mode > 0 ? mode : 0644);\n        if (fd < 0)\n                return -errno;\n\n        if (mode != MODE_INVALID) {\n                r = fchmod(fd, mode);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (uid != UID_INVALID || gid != GID_INVALID) {\n                r = fchown(fd, uid, gid);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (stamp != USEC_INFINITY) {\n                struct timespec ts[2];\n\n                timespec_store(&ts[0], stamp);\n                ts[1] = ts[0];\n                r = futimens(fd, ts);\n        } else\n                r = futimens(fd, NULL);\n        if (r < 0)\n                return -errno;\n\n        return 0;\n}",
        "func": "int touch_file(const char *path, bool parents, usec_t stamp, uid_t uid, gid_t gid, mode_t mode) {\n        _cleanup_close_ int fd;\n        int r;\n\n        assert(path);\n\n        if (parents)\n                mkdir_parents(path, 0755);\n\n        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY,\n                        (mode == 0 || mode == MODE_INVALID) ? 0644 : mode);\n        if (fd < 0)\n                return -errno;\n\n        if (mode != MODE_INVALID) {\n                r = fchmod(fd, mode);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (uid != UID_INVALID || gid != GID_INVALID) {\n                r = fchown(fd, uid, gid);\n                if (r < 0)\n                        return -errno;\n        }\n\n        if (stamp != USEC_INFINITY) {\n                struct timespec ts[2];\n\n                timespec_store(&ts[0], stamp);\n                ts[1] = ts[0];\n                r = futimens(fd, ts);\n        } else\n                r = futimens(fd, NULL);\n        if (r < 0)\n                return -errno;\n\n        return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,7 +7,8 @@\n         if (parents)\n                 mkdir_parents(path, 0755);\n \n-        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY, mode > 0 ? mode : 0644);\n+        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY,\n+                        (mode == 0 || mode == MODE_INVALID) ? 0644 : mode);\n         if (fd < 0)\n                 return -errno;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY, mode > 0 ? mode : 0644);"
            ],
            "added_lines": [
                "        fd = open(path, O_WRONLY|O_CREAT|O_CLOEXEC|O_NOCTTY,",
                "                        (mode == 0 || mode == MODE_INVALID) ? 0644 : mode);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9382",
        "func_name": "xen-project/xen/hvm_load_segment_selector",
        "description": "Xen 4.0.x through 4.7.x mishandle x86 task switches to VM86 mode, which allows local 32-bit x86 HVM guest OS users to gain privileges or cause a denial of service (guest OS crash) by leveraging a guest operating system that uses hardware task switching and allows a new task to start in VM86 mode.",
        "git_url": "https://github.com/xen-project/xen/commit/93aa42b85ae0084ba7b749d0e990c94fbf0c17e3",
        "commit_title": "x86/HVM: don't load LDTR with VM86 mode attrs during task switch",
        "commit_text": " Just like TR, LDTR is purely a protected mode facility and hence needs to be loaded accordingly. Also move its loading to where it architecurally belongs.  This is CVE-2016-9382 / XSA-192. ",
        "func_before": "static int hvm_load_segment_selector(\n    enum x86_segment seg, uint16_t sel)\n{\n    struct segment_register desctab, cs, segr;\n    struct desc_struct *pdesc, desc;\n    u8 dpl, rpl, cpl;\n    bool_t writable;\n    int fault_type = TRAP_invalid_tss;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    struct vcpu *v = current;\n\n    if ( regs->eflags & X86_EFLAGS_VM )\n    {\n        segr.sel = sel;\n        segr.base = (uint32_t)sel << 4;\n        segr.limit = 0xffffu;\n        segr.attr.bytes = 0xf3;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        if ( (seg == x86_seg_cs) || (seg == x86_seg_ss) )\n            goto fail;\n        memset(&segr, 0, sizeof(segr));\n        segr.sel = sel;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* LDT descriptor must be in the GDT. */\n    if ( (seg == x86_seg_ldtr) && (sel & 4) )\n        goto fail;\n\n    hvm_get_segment_register(v, x86_seg_cs, &cs);\n    hvm_get_segment_register(\n        v, (sel & 4) ? x86_seg_ldtr : x86_seg_gdtr, &desctab);\n\n    /* Segment not valid for use (cooked meaning of .p)? */\n    if ( !desctab.attr.fields.p )\n        goto fail;\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto fail;\n\n    pdesc = hvm_map_entry(desctab.base + (sel & 0xfff8), &writable);\n    if ( pdesc == NULL )\n        goto hvm_map_fail;\n\n    do {\n        desc = *pdesc;\n\n        /* LDT descriptor is a system segment. All others are code/data. */\n        if ( (desc.b & (1u<<12)) == ((seg == x86_seg_ldtr) << 12) )\n            goto unmap_and_fail;\n\n        dpl = (desc.b >> 13) & 3;\n        rpl = sel & 3;\n        cpl = cs.sel & 3;\n\n        switch ( seg )\n        {\n        case x86_seg_cs:\n            /* Code segment? */\n            if ( !(desc.b & _SEGMENT_CODE) )\n                goto unmap_and_fail;\n            /* Non-conforming segment: check DPL against RPL. */\n            if ( !(desc.b & _SEGMENT_EC) && (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ss:\n            /* Writable data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) != _SEGMENT_WR )\n                goto unmap_and_fail;\n            if ( (dpl != cpl) || (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ldtr:\n            /* LDT system segment? */\n            if ( (desc.b & _SEGMENT_TYPE) != (2u<<8) )\n                goto unmap_and_fail;\n            goto skip_accessed_flag;\n        default:\n            /* Readable code or data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) == _SEGMENT_CODE )\n                goto unmap_and_fail;\n            /*\n             * Data or non-conforming code segment:\n             * check DPL against RPL and CPL.\n             */\n            if ( ((desc.b & (_SEGMENT_EC|_SEGMENT_CODE)) !=\n                  (_SEGMENT_EC|_SEGMENT_CODE))\n                 && ((dpl < cpl) || (dpl < rpl)) )\n                goto unmap_and_fail;\n            break;\n        }\n\n        /* Segment present in memory? */\n        if ( !(desc.b & _SEGMENT_P) )\n        {\n            fault_type = (seg != x86_seg_ss) ? TRAP_no_segment\n                                             : TRAP_stack_error;\n            goto unmap_and_fail;\n        }\n    } while ( !(desc.b & 0x100) && /* Ensure Accessed flag is set */\n              writable && /* except if we are to discard writes */\n              (cmpxchg(&pdesc->b, desc.b, desc.b | 0x100) != desc.b) );\n\n    /* Force the Accessed flag in our local copy. */\n    desc.b |= 0x100;\n\n skip_accessed_flag:\n    hvm_unmap_entry(pdesc);\n\n    segr.base = (((desc.b <<  0) & 0xff000000u) |\n                 ((desc.b << 16) & 0x00ff0000u) |\n                 ((desc.a >> 16) & 0x0000ffffu));\n    segr.attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                       ((desc.b >> 12) & 0x0f00u));\n    segr.limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( segr.attr.fields.g )\n        segr.limit = (segr.limit << 12) | 0xfffu;\n    segr.sel = sel;\n    hvm_set_segment_register(v, seg, &segr);\n\n    return 0;\n\n unmap_and_fail:\n    hvm_unmap_entry(pdesc);\n fail:\n    hvm_inject_hw_exception(fault_type, sel & 0xfffc);\n hvm_map_fail:\n    return 1;\n}",
        "func": "static int hvm_load_segment_selector(\n    enum x86_segment seg, uint16_t sel, unsigned int eflags)\n{\n    struct segment_register desctab, cs, segr;\n    struct desc_struct *pdesc, desc;\n    u8 dpl, rpl, cpl;\n    bool_t writable;\n    int fault_type = TRAP_invalid_tss;\n    struct vcpu *v = current;\n\n    if ( eflags & X86_EFLAGS_VM )\n    {\n        segr.sel = sel;\n        segr.base = (uint32_t)sel << 4;\n        segr.limit = 0xffffu;\n        segr.attr.bytes = 0xf3;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        if ( (seg == x86_seg_cs) || (seg == x86_seg_ss) )\n            goto fail;\n        memset(&segr, 0, sizeof(segr));\n        segr.sel = sel;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* LDT descriptor must be in the GDT. */\n    if ( (seg == x86_seg_ldtr) && (sel & 4) )\n        goto fail;\n\n    hvm_get_segment_register(v, x86_seg_cs, &cs);\n    hvm_get_segment_register(\n        v, (sel & 4) ? x86_seg_ldtr : x86_seg_gdtr, &desctab);\n\n    /* Segment not valid for use (cooked meaning of .p)? */\n    if ( !desctab.attr.fields.p )\n        goto fail;\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto fail;\n\n    pdesc = hvm_map_entry(desctab.base + (sel & 0xfff8), &writable);\n    if ( pdesc == NULL )\n        goto hvm_map_fail;\n\n    do {\n        desc = *pdesc;\n\n        /* LDT descriptor is a system segment. All others are code/data. */\n        if ( (desc.b & (1u<<12)) == ((seg == x86_seg_ldtr) << 12) )\n            goto unmap_and_fail;\n\n        dpl = (desc.b >> 13) & 3;\n        rpl = sel & 3;\n        cpl = cs.sel & 3;\n\n        switch ( seg )\n        {\n        case x86_seg_cs:\n            /* Code segment? */\n            if ( !(desc.b & _SEGMENT_CODE) )\n                goto unmap_and_fail;\n            /* Non-conforming segment: check DPL against RPL. */\n            if ( !(desc.b & _SEGMENT_EC) && (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ss:\n            /* Writable data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) != _SEGMENT_WR )\n                goto unmap_and_fail;\n            if ( (dpl != cpl) || (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ldtr:\n            /* LDT system segment? */\n            if ( (desc.b & _SEGMENT_TYPE) != (2u<<8) )\n                goto unmap_and_fail;\n            goto skip_accessed_flag;\n        default:\n            /* Readable code or data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) == _SEGMENT_CODE )\n                goto unmap_and_fail;\n            /*\n             * Data or non-conforming code segment:\n             * check DPL against RPL and CPL.\n             */\n            if ( ((desc.b & (_SEGMENT_EC|_SEGMENT_CODE)) !=\n                  (_SEGMENT_EC|_SEGMENT_CODE))\n                 && ((dpl < cpl) || (dpl < rpl)) )\n                goto unmap_and_fail;\n            break;\n        }\n\n        /* Segment present in memory? */\n        if ( !(desc.b & _SEGMENT_P) )\n        {\n            fault_type = (seg != x86_seg_ss) ? TRAP_no_segment\n                                             : TRAP_stack_error;\n            goto unmap_and_fail;\n        }\n    } while ( !(desc.b & 0x100) && /* Ensure Accessed flag is set */\n              writable && /* except if we are to discard writes */\n              (cmpxchg(&pdesc->b, desc.b, desc.b | 0x100) != desc.b) );\n\n    /* Force the Accessed flag in our local copy. */\n    desc.b |= 0x100;\n\n skip_accessed_flag:\n    hvm_unmap_entry(pdesc);\n\n    segr.base = (((desc.b <<  0) & 0xff000000u) |\n                 ((desc.b << 16) & 0x00ff0000u) |\n                 ((desc.a >> 16) & 0x0000ffffu));\n    segr.attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                       ((desc.b >> 12) & 0x0f00u));\n    segr.limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( segr.attr.fields.g )\n        segr.limit = (segr.limit << 12) | 0xfffu;\n    segr.sel = sel;\n    hvm_set_segment_register(v, seg, &segr);\n\n    return 0;\n\n unmap_and_fail:\n    hvm_unmap_entry(pdesc);\n fail:\n    hvm_inject_hw_exception(fault_type, sel & 0xfffc);\n hvm_map_fail:\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,15 +1,14 @@\n static int hvm_load_segment_selector(\n-    enum x86_segment seg, uint16_t sel)\n+    enum x86_segment seg, uint16_t sel, unsigned int eflags)\n {\n     struct segment_register desctab, cs, segr;\n     struct desc_struct *pdesc, desc;\n     u8 dpl, rpl, cpl;\n     bool_t writable;\n     int fault_type = TRAP_invalid_tss;\n-    struct cpu_user_regs *regs = guest_cpu_user_regs();\n     struct vcpu *v = current;\n \n-    if ( regs->eflags & X86_EFLAGS_VM )\n+    if ( eflags & X86_EFLAGS_VM )\n     {\n         segr.sel = sel;\n         segr.base = (uint32_t)sel << 4;",
        "diff_line_info": {
            "deleted_lines": [
                "    enum x86_segment seg, uint16_t sel)",
                "    struct cpu_user_regs *regs = guest_cpu_user_regs();",
                "    if ( regs->eflags & X86_EFLAGS_VM )"
            ],
            "added_lines": [
                "    enum x86_segment seg, uint16_t sel, unsigned int eflags)",
                "    if ( eflags & X86_EFLAGS_VM )"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9382",
        "func_name": "xen-project/xen/hvm_task_switch",
        "description": "Xen 4.0.x through 4.7.x mishandle x86 task switches to VM86 mode, which allows local 32-bit x86 HVM guest OS users to gain privileges or cause a denial of service (guest OS crash) by leveraging a guest operating system that uses hardware task switching and allows a new task to start in VM86 mode.",
        "git_url": "https://github.com/xen-project/xen/commit/93aa42b85ae0084ba7b749d0e990c94fbf0c17e3",
        "commit_title": "x86/HVM: don't load LDTR with VM86 mode attrs during task switch",
        "commit_text": " Just like TR, LDTR is purely a protected mode facility and hence needs to be loaded accordingly. Also move its loading to where it architecurally belongs.  This is CVE-2016-9382 / XSA-192. ",
        "func_before": "void hvm_task_switch(\n    uint16_t tss_sel, enum hvm_task_switch_reason taskswitch_reason,\n    int32_t errcode)\n{\n    struct vcpu *v = current;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    struct segment_register gdt, tr, prev_tr, segr;\n    struct desc_struct *optss_desc = NULL, *nptss_desc = NULL, tss_desc;\n    bool_t otd_writable, ntd_writable;\n    unsigned long eflags;\n    int exn_raised, rc;\n    struct {\n        u16 back_link,__blh;\n        u32 esp0;\n        u16 ss0, _0;\n        u32 esp1;\n        u16 ss1, _1;\n        u32 esp2;\n        u16 ss2, _2;\n        u32 cr3, eip, eflags, eax, ecx, edx, ebx, esp, ebp, esi, edi;\n        u16 es, _3, cs, _4, ss, _5, ds, _6, fs, _7, gs, _8, ldt, _9;\n        u16 trace, iomap;\n    } tss = { 0 };\n\n    hvm_get_segment_register(v, x86_seg_gdtr, &gdt);\n    hvm_get_segment_register(v, x86_seg_tr, &prev_tr);\n\n    if ( ((tss_sel & 0xfff8) + 7) > gdt.limit )\n    {\n        hvm_inject_hw_exception((taskswitch_reason == TSW_iret) ?\n                             TRAP_invalid_tss : TRAP_gp_fault,\n                             tss_sel & 0xfff8);\n        goto out;\n    }\n\n    optss_desc = hvm_map_entry(gdt.base + (prev_tr.sel & 0xfff8),\n                               &otd_writable);\n    if ( optss_desc == NULL )\n        goto out;\n\n    nptss_desc = hvm_map_entry(gdt.base + (tss_sel & 0xfff8), &ntd_writable);\n    if ( nptss_desc == NULL )\n        goto out;\n\n    tss_desc = *nptss_desc;\n    tr.sel = tss_sel;\n    tr.base = (((tss_desc.b <<  0) & 0xff000000u) |\n               ((tss_desc.b << 16) & 0x00ff0000u) |\n               ((tss_desc.a >> 16) & 0x0000ffffu));\n    tr.attr.bytes = (((tss_desc.b >>  8) & 0x00ffu) |\n                     ((tss_desc.b >> 12) & 0x0f00u));\n    tr.limit = (tss_desc.b & 0x000f0000u) | (tss_desc.a & 0x0000ffffu);\n    if ( tr.attr.fields.g )\n        tr.limit = (tr.limit << 12) | 0xfffu;\n\n    if ( tr.attr.fields.type != ((taskswitch_reason == TSW_iret) ? 0xb : 0x9) )\n    {\n        hvm_inject_hw_exception(\n            (taskswitch_reason == TSW_iret) ? TRAP_invalid_tss : TRAP_gp_fault,\n            tss_sel & 0xfff8);\n        goto out;\n    }\n\n    if ( !tr.attr.fields.p )\n    {\n        hvm_inject_hw_exception(TRAP_no_segment, tss_sel & 0xfff8);\n        goto out;\n    }\n\n    if ( tr.limit < (sizeof(tss)-1) )\n    {\n        hvm_inject_hw_exception(TRAP_invalid_tss, tss_sel & 0xfff8);\n        goto out;\n    }\n\n    rc = hvm_copy_from_guest_virt(\n        &tss, prev_tr.base, sizeof(tss), PFEC_page_present);\n    if ( rc != HVMCOPY_okay )\n        goto out;\n\n    eflags = regs->eflags;\n    if ( taskswitch_reason == TSW_iret )\n        eflags &= ~X86_EFLAGS_NT;\n\n    tss.cr3    = v->arch.hvm_vcpu.guest_cr[3];\n    tss.eip    = regs->eip;\n    tss.eflags = eflags;\n    tss.eax    = regs->eax;\n    tss.ecx    = regs->ecx;\n    tss.edx    = regs->edx;\n    tss.ebx    = regs->ebx;\n    tss.esp    = regs->esp;\n    tss.ebp    = regs->ebp;\n    tss.esi    = regs->esi;\n    tss.edi    = regs->edi;\n\n    hvm_get_segment_register(v, x86_seg_es, &segr);\n    tss.es = segr.sel;\n    hvm_get_segment_register(v, x86_seg_cs, &segr);\n    tss.cs = segr.sel;\n    hvm_get_segment_register(v, x86_seg_ss, &segr);\n    tss.ss = segr.sel;\n    hvm_get_segment_register(v, x86_seg_ds, &segr);\n    tss.ds = segr.sel;\n    hvm_get_segment_register(v, x86_seg_fs, &segr);\n    tss.fs = segr.sel;\n    hvm_get_segment_register(v, x86_seg_gs, &segr);\n    tss.gs = segr.sel;\n    hvm_get_segment_register(v, x86_seg_ldtr, &segr);\n    tss.ldt = segr.sel;\n\n    rc = hvm_copy_to_guest_virt(\n        prev_tr.base, &tss, sizeof(tss), PFEC_page_present);\n    if ( rc != HVMCOPY_okay )\n        goto out;\n\n    rc = hvm_copy_from_guest_virt(\n        &tss, tr.base, sizeof(tss), PFEC_page_present);\n    /*\n     * Note: The HVMCOPY_gfn_shared case could be optimised, if the callee\n     * functions knew we want RO access.\n     */\n    if ( rc != HVMCOPY_okay )\n        goto out;\n\n\n    if ( hvm_set_cr3(tss.cr3, 1) )\n        goto out;\n\n    regs->eip    = tss.eip;\n    regs->eflags = tss.eflags | 2;\n    regs->eax    = tss.eax;\n    regs->ecx    = tss.ecx;\n    regs->edx    = tss.edx;\n    regs->ebx    = tss.ebx;\n    regs->esp    = tss.esp;\n    regs->ebp    = tss.ebp;\n    regs->esi    = tss.esi;\n    regs->edi    = tss.edi;\n\n    if ( (taskswitch_reason == TSW_call_or_int) )\n    {\n        regs->eflags |= X86_EFLAGS_NT;\n        tss.back_link = prev_tr.sel;\n    }\n\n    exn_raised = 0;\n    if ( hvm_load_segment_selector(x86_seg_ldtr, tss.ldt) ||\n         hvm_load_segment_selector(x86_seg_es, tss.es) ||\n         hvm_load_segment_selector(x86_seg_cs, tss.cs) ||\n         hvm_load_segment_selector(x86_seg_ss, tss.ss) ||\n         hvm_load_segment_selector(x86_seg_ds, tss.ds) ||\n         hvm_load_segment_selector(x86_seg_fs, tss.fs) ||\n         hvm_load_segment_selector(x86_seg_gs, tss.gs) )\n        exn_raised = 1;\n\n    rc = hvm_copy_to_guest_virt(\n        tr.base, &tss, sizeof(tss), PFEC_page_present);\n    if ( rc == HVMCOPY_bad_gva_to_gfn )\n        exn_raised = 1;\n    else if ( rc != HVMCOPY_okay )\n        goto out;\n\n    if ( (tss.trace & 1) && !exn_raised )\n        hvm_inject_hw_exception(TRAP_debug, HVM_DELIVER_NO_ERROR_CODE);\n\n    tr.attr.fields.type = 0xb; /* busy 32-bit tss */\n    hvm_set_segment_register(v, x86_seg_tr, &tr);\n\n    v->arch.hvm_vcpu.guest_cr[0] |= X86_CR0_TS;\n    hvm_update_guest_cr(v, 0);\n\n    if ( (taskswitch_reason == TSW_iret ||\n          taskswitch_reason == TSW_jmp) && otd_writable )\n        clear_bit(41, optss_desc); /* clear B flag of old task */\n\n    if ( taskswitch_reason != TSW_iret && ntd_writable )\n        set_bit(41, nptss_desc); /* set B flag of new task */\n\n    if ( errcode >= 0 )\n    {\n        struct segment_register reg;\n        unsigned long linear_addr;\n        regs->esp -= 4;\n        hvm_get_segment_register(current, x86_seg_ss, &reg);\n        /* Todo: do not ignore access faults here. */\n        if ( hvm_virtual_to_linear_addr(x86_seg_ss, &reg, regs->esp,\n                                        4, hvm_access_write, 32,\n                                        &linear_addr) )\n            hvm_copy_to_guest_virt_nofault(linear_addr, &errcode, 4, 0);\n    }\n\n out:\n    hvm_unmap_entry(optss_desc);\n    hvm_unmap_entry(nptss_desc);\n}",
        "func": "void hvm_task_switch(\n    uint16_t tss_sel, enum hvm_task_switch_reason taskswitch_reason,\n    int32_t errcode)\n{\n    struct vcpu *v = current;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    struct segment_register gdt, tr, prev_tr, segr;\n    struct desc_struct *optss_desc = NULL, *nptss_desc = NULL, tss_desc;\n    bool_t otd_writable, ntd_writable;\n    unsigned long eflags;\n    int exn_raised, rc;\n    struct {\n        u16 back_link,__blh;\n        u32 esp0;\n        u16 ss0, _0;\n        u32 esp1;\n        u16 ss1, _1;\n        u32 esp2;\n        u16 ss2, _2;\n        u32 cr3, eip, eflags, eax, ecx, edx, ebx, esp, ebp, esi, edi;\n        u16 es, _3, cs, _4, ss, _5, ds, _6, fs, _7, gs, _8, ldt, _9;\n        u16 trace, iomap;\n    } tss = { 0 };\n\n    hvm_get_segment_register(v, x86_seg_gdtr, &gdt);\n    hvm_get_segment_register(v, x86_seg_tr, &prev_tr);\n\n    if ( ((tss_sel & 0xfff8) + 7) > gdt.limit )\n    {\n        hvm_inject_hw_exception((taskswitch_reason == TSW_iret) ?\n                             TRAP_invalid_tss : TRAP_gp_fault,\n                             tss_sel & 0xfff8);\n        goto out;\n    }\n\n    optss_desc = hvm_map_entry(gdt.base + (prev_tr.sel & 0xfff8),\n                               &otd_writable);\n    if ( optss_desc == NULL )\n        goto out;\n\n    nptss_desc = hvm_map_entry(gdt.base + (tss_sel & 0xfff8), &ntd_writable);\n    if ( nptss_desc == NULL )\n        goto out;\n\n    tss_desc = *nptss_desc;\n    tr.sel = tss_sel;\n    tr.base = (((tss_desc.b <<  0) & 0xff000000u) |\n               ((tss_desc.b << 16) & 0x00ff0000u) |\n               ((tss_desc.a >> 16) & 0x0000ffffu));\n    tr.attr.bytes = (((tss_desc.b >>  8) & 0x00ffu) |\n                     ((tss_desc.b >> 12) & 0x0f00u));\n    tr.limit = (tss_desc.b & 0x000f0000u) | (tss_desc.a & 0x0000ffffu);\n    if ( tr.attr.fields.g )\n        tr.limit = (tr.limit << 12) | 0xfffu;\n\n    if ( tr.attr.fields.type != ((taskswitch_reason == TSW_iret) ? 0xb : 0x9) )\n    {\n        hvm_inject_hw_exception(\n            (taskswitch_reason == TSW_iret) ? TRAP_invalid_tss : TRAP_gp_fault,\n            tss_sel & 0xfff8);\n        goto out;\n    }\n\n    if ( !tr.attr.fields.p )\n    {\n        hvm_inject_hw_exception(TRAP_no_segment, tss_sel & 0xfff8);\n        goto out;\n    }\n\n    if ( tr.limit < (sizeof(tss)-1) )\n    {\n        hvm_inject_hw_exception(TRAP_invalid_tss, tss_sel & 0xfff8);\n        goto out;\n    }\n\n    rc = hvm_copy_from_guest_virt(\n        &tss, prev_tr.base, sizeof(tss), PFEC_page_present);\n    if ( rc != HVMCOPY_okay )\n        goto out;\n\n    eflags = regs->eflags;\n    if ( taskswitch_reason == TSW_iret )\n        eflags &= ~X86_EFLAGS_NT;\n\n    tss.cr3    = v->arch.hvm_vcpu.guest_cr[3];\n    tss.eip    = regs->eip;\n    tss.eflags = eflags;\n    tss.eax    = regs->eax;\n    tss.ecx    = regs->ecx;\n    tss.edx    = regs->edx;\n    tss.ebx    = regs->ebx;\n    tss.esp    = regs->esp;\n    tss.ebp    = regs->ebp;\n    tss.esi    = regs->esi;\n    tss.edi    = regs->edi;\n\n    hvm_get_segment_register(v, x86_seg_es, &segr);\n    tss.es = segr.sel;\n    hvm_get_segment_register(v, x86_seg_cs, &segr);\n    tss.cs = segr.sel;\n    hvm_get_segment_register(v, x86_seg_ss, &segr);\n    tss.ss = segr.sel;\n    hvm_get_segment_register(v, x86_seg_ds, &segr);\n    tss.ds = segr.sel;\n    hvm_get_segment_register(v, x86_seg_fs, &segr);\n    tss.fs = segr.sel;\n    hvm_get_segment_register(v, x86_seg_gs, &segr);\n    tss.gs = segr.sel;\n    hvm_get_segment_register(v, x86_seg_ldtr, &segr);\n    tss.ldt = segr.sel;\n\n    rc = hvm_copy_to_guest_virt(\n        prev_tr.base, &tss, sizeof(tss), PFEC_page_present);\n    if ( rc != HVMCOPY_okay )\n        goto out;\n\n    rc = hvm_copy_from_guest_virt(\n        &tss, tr.base, sizeof(tss), PFEC_page_present);\n    /*\n     * Note: The HVMCOPY_gfn_shared case could be optimised, if the callee\n     * functions knew we want RO access.\n     */\n    if ( rc != HVMCOPY_okay )\n        goto out;\n\n    if ( hvm_load_segment_selector(x86_seg_ldtr, tss.ldt, 0) )\n        goto out;\n\n    if ( hvm_set_cr3(tss.cr3, 1) )\n        goto out;\n\n    regs->eip    = tss.eip;\n    regs->eflags = tss.eflags | 2;\n    regs->eax    = tss.eax;\n    regs->ecx    = tss.ecx;\n    regs->edx    = tss.edx;\n    regs->ebx    = tss.ebx;\n    regs->esp    = tss.esp;\n    regs->ebp    = tss.ebp;\n    regs->esi    = tss.esi;\n    regs->edi    = tss.edi;\n\n    if ( (taskswitch_reason == TSW_call_or_int) )\n    {\n        regs->eflags |= X86_EFLAGS_NT;\n        tss.back_link = prev_tr.sel;\n    }\n\n    exn_raised = 0;\n    if ( hvm_load_segment_selector(x86_seg_es, tss.es, tss.eflags) ||\n         hvm_load_segment_selector(x86_seg_cs, tss.cs, tss.eflags) ||\n         hvm_load_segment_selector(x86_seg_ss, tss.ss, tss.eflags) ||\n         hvm_load_segment_selector(x86_seg_ds, tss.ds, tss.eflags) ||\n         hvm_load_segment_selector(x86_seg_fs, tss.fs, tss.eflags) ||\n         hvm_load_segment_selector(x86_seg_gs, tss.gs, tss.eflags) )\n        exn_raised = 1;\n\n    rc = hvm_copy_to_guest_virt(\n        tr.base, &tss, sizeof(tss), PFEC_page_present);\n    if ( rc == HVMCOPY_bad_gva_to_gfn )\n        exn_raised = 1;\n    else if ( rc != HVMCOPY_okay )\n        goto out;\n\n    if ( (tss.trace & 1) && !exn_raised )\n        hvm_inject_hw_exception(TRAP_debug, HVM_DELIVER_NO_ERROR_CODE);\n\n    tr.attr.fields.type = 0xb; /* busy 32-bit tss */\n    hvm_set_segment_register(v, x86_seg_tr, &tr);\n\n    v->arch.hvm_vcpu.guest_cr[0] |= X86_CR0_TS;\n    hvm_update_guest_cr(v, 0);\n\n    if ( (taskswitch_reason == TSW_iret ||\n          taskswitch_reason == TSW_jmp) && otd_writable )\n        clear_bit(41, optss_desc); /* clear B flag of old task */\n\n    if ( taskswitch_reason != TSW_iret && ntd_writable )\n        set_bit(41, nptss_desc); /* set B flag of new task */\n\n    if ( errcode >= 0 )\n    {\n        struct segment_register reg;\n        unsigned long linear_addr;\n        regs->esp -= 4;\n        hvm_get_segment_register(current, x86_seg_ss, &reg);\n        /* Todo: do not ignore access faults here. */\n        if ( hvm_virtual_to_linear_addr(x86_seg_ss, &reg, regs->esp,\n                                        4, hvm_access_write, 32,\n                                        &linear_addr) )\n            hvm_copy_to_guest_virt_nofault(linear_addr, &errcode, 4, 0);\n    }\n\n out:\n    hvm_unmap_entry(optss_desc);\n    hvm_unmap_entry(nptss_desc);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -123,6 +123,8 @@\n     if ( rc != HVMCOPY_okay )\n         goto out;\n \n+    if ( hvm_load_segment_selector(x86_seg_ldtr, tss.ldt, 0) )\n+        goto out;\n \n     if ( hvm_set_cr3(tss.cr3, 1) )\n         goto out;\n@@ -145,13 +147,12 @@\n     }\n \n     exn_raised = 0;\n-    if ( hvm_load_segment_selector(x86_seg_ldtr, tss.ldt) ||\n-         hvm_load_segment_selector(x86_seg_es, tss.es) ||\n-         hvm_load_segment_selector(x86_seg_cs, tss.cs) ||\n-         hvm_load_segment_selector(x86_seg_ss, tss.ss) ||\n-         hvm_load_segment_selector(x86_seg_ds, tss.ds) ||\n-         hvm_load_segment_selector(x86_seg_fs, tss.fs) ||\n-         hvm_load_segment_selector(x86_seg_gs, tss.gs) )\n+    if ( hvm_load_segment_selector(x86_seg_es, tss.es, tss.eflags) ||\n+         hvm_load_segment_selector(x86_seg_cs, tss.cs, tss.eflags) ||\n+         hvm_load_segment_selector(x86_seg_ss, tss.ss, tss.eflags) ||\n+         hvm_load_segment_selector(x86_seg_ds, tss.ds, tss.eflags) ||\n+         hvm_load_segment_selector(x86_seg_fs, tss.fs, tss.eflags) ||\n+         hvm_load_segment_selector(x86_seg_gs, tss.gs, tss.eflags) )\n         exn_raised = 1;\n \n     rc = hvm_copy_to_guest_virt(",
        "diff_line_info": {
            "deleted_lines": [
                "    if ( hvm_load_segment_selector(x86_seg_ldtr, tss.ldt) ||",
                "         hvm_load_segment_selector(x86_seg_es, tss.es) ||",
                "         hvm_load_segment_selector(x86_seg_cs, tss.cs) ||",
                "         hvm_load_segment_selector(x86_seg_ss, tss.ss) ||",
                "         hvm_load_segment_selector(x86_seg_ds, tss.ds) ||",
                "         hvm_load_segment_selector(x86_seg_fs, tss.fs) ||",
                "         hvm_load_segment_selector(x86_seg_gs, tss.gs) )"
            ],
            "added_lines": [
                "    if ( hvm_load_segment_selector(x86_seg_ldtr, tss.ldt, 0) )",
                "        goto out;",
                "    if ( hvm_load_segment_selector(x86_seg_es, tss.es, tss.eflags) ||",
                "         hvm_load_segment_selector(x86_seg_cs, tss.cs, tss.eflags) ||",
                "         hvm_load_segment_selector(x86_seg_ss, tss.ss, tss.eflags) ||",
                "         hvm_load_segment_selector(x86_seg_ds, tss.ds, tss.eflags) ||",
                "         hvm_load_segment_selector(x86_seg_fs, tss.fs, tss.eflags) ||",
                "         hvm_load_segment_selector(x86_seg_gs, tss.gs, tss.eflags) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9386",
        "func_name": "xen-project/xen/svm_get_segment_register",
        "description": "The x86 emulator in Xen does not properly treat x86 NULL segments as unusable when accessing memory, which might allow local HVM guest users to gain privileges via vectors involving \"unexpected\" base/limit values.",
        "git_url": "https://github.com/xen-project/xen/commit/04beafa8e6c66f5cd814c00e2d2b51cfbc41cb8a",
        "commit_title": "x86/hvm: Fix the handling of non-present segments",
        "commit_text": " In 32bit, the data segments may be NULL to indicate that the segment is ineligible for use.  In both 32bit and 64bit, the LDT selector may be NULL to indicate that the entire LDT is ineligible for use.  However, nothing in Xen actually checks for this condition when performing other segmentation checks.  (Note however that limit and writeability checks are correctly performed).  Neither Intel nor AMD specify the exact behaviour of loading a NULL segment. Experimentally, AMD zeroes all attributes but leaves the base and limit unmodified.  Intel zeroes the base, sets the limit to 0xfffffff and resets the attributes to just .G and .D/B.  The use of the segment information in the VMCB/VMCS is equivalent to a native pipeline interacting with the segment cache.  The present bit can therefore have a subtly different meaning, and it is now cooked to uniformly indicate whether the segment is usable or not.  GDTR and IDTR don't have access rights like the other segments, but for consistency, they are treated as being present so no special casing is needed elsewhere in the segmentation logic.  AMD hardware does not consider the present bit for %cs and %tr, and will function as if they were present.  They are therefore unconditionally set to present when reading information from the VMCB, to maintain the new meaning of usability.  Intel hardware has a separate unusable bit in the VMCS segment attributes. This bit is inverted and stored in the present field, so the hvm code can work with architecturally-common state.  This is CVE-2016-9386 / XSA-191. ",
        "func_before": "static void svm_get_segment_register(struct vcpu *v, enum x86_segment seg,\n                                     struct segment_register *reg)\n{\n    struct vmcb_struct *vmcb = v->arch.hvm_svm.vmcb;\n\n    ASSERT((v == current) || !vcpu_runnable(v));\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        memcpy(reg, &vmcb->cs, sizeof(*reg));\n        reg->attr.fields.g = reg->limit > 0xFFFFF;\n        break;\n    case x86_seg_ds:\n        memcpy(reg, &vmcb->ds, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_es:\n        memcpy(reg, &vmcb->es, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_fs:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->fs, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_gs:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->gs, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_ss:\n        memcpy(reg, &vmcb->ss, sizeof(*reg));\n        reg->attr.fields.dpl = vmcb->_cpl;\n        if ( reg->attr.fields.type == 0 )\n            reg->attr.fields.db = 0;\n        break;\n    case x86_seg_tr:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->tr, sizeof(*reg));\n        reg->attr.fields.type |= 0x2;\n        break;\n    case x86_seg_gdtr:\n        memcpy(reg, &vmcb->gdtr, sizeof(*reg));\n        break;\n    case x86_seg_idtr:\n        memcpy(reg, &vmcb->idtr, sizeof(*reg));\n        break;\n    case x86_seg_ldtr:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->ldtr, sizeof(*reg));\n        break;\n    default:\n        BUG();\n    }\n}",
        "func": "static void svm_get_segment_register(struct vcpu *v, enum x86_segment seg,\n                                     struct segment_register *reg)\n{\n    struct vmcb_struct *vmcb = v->arch.hvm_svm.vmcb;\n\n    ASSERT((v == current) || !vcpu_runnable(v));\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        memcpy(reg, &vmcb->cs, sizeof(*reg));\n        reg->attr.fields.p = 1;\n        reg->attr.fields.g = reg->limit > 0xFFFFF;\n        break;\n    case x86_seg_ds:\n        memcpy(reg, &vmcb->ds, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_es:\n        memcpy(reg, &vmcb->es, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_fs:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->fs, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_gs:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->gs, sizeof(*reg));\n        if ( reg->attr.fields.type != 0 )\n            reg->attr.fields.type |= 0x1;\n        break;\n    case x86_seg_ss:\n        memcpy(reg, &vmcb->ss, sizeof(*reg));\n        reg->attr.fields.dpl = vmcb->_cpl;\n        if ( reg->attr.fields.type == 0 )\n            reg->attr.fields.db = 0;\n        break;\n    case x86_seg_tr:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->tr, sizeof(*reg));\n        reg->attr.fields.p = 1;\n        reg->attr.fields.type |= 0x2;\n        break;\n    case x86_seg_gdtr:\n        memcpy(reg, &vmcb->gdtr, sizeof(*reg));\n        reg->attr.bytes = 0x80;\n        break;\n    case x86_seg_idtr:\n        memcpy(reg, &vmcb->idtr, sizeof(*reg));\n        reg->attr.bytes = 0x80;\n        break;\n    case x86_seg_ldtr:\n        svm_sync_vmcb(v);\n        memcpy(reg, &vmcb->ldtr, sizeof(*reg));\n        break;\n    default:\n        BUG();\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,7 @@\n     {\n     case x86_seg_cs:\n         memcpy(reg, &vmcb->cs, sizeof(*reg));\n+        reg->attr.fields.p = 1;\n         reg->attr.fields.g = reg->limit > 0xFFFFF;\n         break;\n     case x86_seg_ds:\n@@ -42,13 +43,16 @@\n     case x86_seg_tr:\n         svm_sync_vmcb(v);\n         memcpy(reg, &vmcb->tr, sizeof(*reg));\n+        reg->attr.fields.p = 1;\n         reg->attr.fields.type |= 0x2;\n         break;\n     case x86_seg_gdtr:\n         memcpy(reg, &vmcb->gdtr, sizeof(*reg));\n+        reg->attr.bytes = 0x80;\n         break;\n     case x86_seg_idtr:\n         memcpy(reg, &vmcb->idtr, sizeof(*reg));\n+        reg->attr.bytes = 0x80;\n         break;\n     case x86_seg_ldtr:\n         svm_sync_vmcb(v);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        reg->attr.fields.p = 1;",
                "        reg->attr.fields.p = 1;",
                "        reg->attr.bytes = 0x80;",
                "        reg->attr.bytes = 0x80;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9386",
        "func_name": "xen-project/xen/hvm_virtual_to_linear_addr",
        "description": "The x86 emulator in Xen does not properly treat x86 NULL segments as unusable when accessing memory, which might allow local HVM guest users to gain privileges via vectors involving \"unexpected\" base/limit values.",
        "git_url": "https://github.com/xen-project/xen/commit/04beafa8e6c66f5cd814c00e2d2b51cfbc41cb8a",
        "commit_title": "x86/hvm: Fix the handling of non-present segments",
        "commit_text": " In 32bit, the data segments may be NULL to indicate that the segment is ineligible for use.  In both 32bit and 64bit, the LDT selector may be NULL to indicate that the entire LDT is ineligible for use.  However, nothing in Xen actually checks for this condition when performing other segmentation checks.  (Note however that limit and writeability checks are correctly performed).  Neither Intel nor AMD specify the exact behaviour of loading a NULL segment. Experimentally, AMD zeroes all attributes but leaves the base and limit unmodified.  Intel zeroes the base, sets the limit to 0xfffffff and resets the attributes to just .G and .D/B.  The use of the segment information in the VMCB/VMCS is equivalent to a native pipeline interacting with the segment cache.  The present bit can therefore have a subtly different meaning, and it is now cooked to uniformly indicate whether the segment is usable or not.  GDTR and IDTR don't have access rights like the other segments, but for consistency, they are treated as being present so no special casing is needed elsewhere in the segmentation logic.  AMD hardware does not consider the present bit for %cs and %tr, and will function as if they were present.  They are therefore unconditionally set to present when reading information from the VMCB, to maintain the new meaning of usability.  Intel hardware has a separate unusable bit in the VMCS segment attributes. This bit is inverted and stored in the present field, so the hvm code can work with architecturally-common state.  This is CVE-2016-9386 / XSA-191. ",
        "func_before": "bool_t hvm_virtual_to_linear_addr(\n    enum x86_segment seg,\n    const struct segment_register *reg,\n    unsigned long offset,\n    unsigned int bytes,\n    enum hvm_access_type access_type,\n    unsigned int addr_size,\n    unsigned long *linear_addr)\n{\n    unsigned long addr = offset, last_byte;\n    bool_t okay = 0;\n\n    if ( !(current->arch.hvm_vcpu.guest_cr[0] & X86_CR0_PE) )\n    {\n        /*\n         * REAL MODE: Don't bother with segment access checks.\n         * Certain of them are not done in native real mode anyway.\n         */\n        addr = (uint32_t)(addr + reg->base);\n        last_byte = (uint32_t)addr + bytes - !!bytes;\n        if ( last_byte < addr )\n            goto out;\n    }\n    else if ( addr_size != 64 )\n    {\n        /*\n         * COMPATIBILITY MODE: Apply segment checks and add base.\n         */\n\n        /*\n         * Hardware truncates to 32 bits in compatibility mode.\n         * It does not truncate to 16 bits in 16-bit address-size mode.\n         */\n        addr = (uint32_t)(addr + reg->base);\n\n        switch ( access_type )\n        {\n        case hvm_access_read:\n            if ( (reg->attr.fields.type & 0xa) == 0x8 )\n                goto out; /* execute-only code segment */\n            break;\n        case hvm_access_write:\n            if ( (reg->attr.fields.type & 0xa) != 0x2 )\n                goto out; /* not a writable data segment */\n            break;\n        default:\n            break;\n        }\n\n        last_byte = (uint32_t)offset + bytes - !!bytes;\n\n        /* Is this a grows-down data segment? Special limit check if so. */\n        if ( (reg->attr.fields.type & 0xc) == 0x4 )\n        {\n            /* Is upper limit 0xFFFF or 0xFFFFFFFF? */\n            if ( !reg->attr.fields.db )\n                last_byte = (uint16_t)last_byte;\n\n            /* Check first byte and last byte against respective bounds. */\n            if ( (offset <= reg->limit) || (last_byte < offset) )\n                goto out;\n        }\n        else if ( (last_byte > reg->limit) || (last_byte < offset) )\n            goto out; /* last byte is beyond limit or wraps 0xFFFFFFFF */\n    }\n    else\n    {\n        /*\n         * LONG MODE: FS and GS add segment base. Addresses must be canonical.\n         */\n\n        if ( (seg == x86_seg_fs) || (seg == x86_seg_gs) )\n            addr += reg->base;\n\n        last_byte = addr + bytes - !!bytes;\n        if ( !is_canonical_address(addr) || last_byte < addr ||\n             !is_canonical_address(last_byte) )\n            goto out;\n    }\n\n    /* All checks ok. */\n    okay = 1;\n\n out:\n    /*\n     * Always return the correct linear address, even if a permission check\n     * failed.  The permissions failure is not relevant to some callers.\n     */\n    *linear_addr = addr;\n    return okay;\n}",
        "func": "bool_t hvm_virtual_to_linear_addr(\n    enum x86_segment seg,\n    const struct segment_register *reg,\n    unsigned long offset,\n    unsigned int bytes,\n    enum hvm_access_type access_type,\n    unsigned int addr_size,\n    unsigned long *linear_addr)\n{\n    unsigned long addr = offset, last_byte;\n    bool_t okay = 0;\n\n    if ( !(current->arch.hvm_vcpu.guest_cr[0] & X86_CR0_PE) )\n    {\n        /*\n         * REAL MODE: Don't bother with segment access checks.\n         * Certain of them are not done in native real mode anyway.\n         */\n        addr = (uint32_t)(addr + reg->base);\n        last_byte = (uint32_t)addr + bytes - !!bytes;\n        if ( last_byte < addr )\n            goto out;\n    }\n    else if ( addr_size != 64 )\n    {\n        /*\n         * COMPATIBILITY MODE: Apply segment checks and add base.\n         */\n\n        /*\n         * Hardware truncates to 32 bits in compatibility mode.\n         * It does not truncate to 16 bits in 16-bit address-size mode.\n         */\n        addr = (uint32_t)(addr + reg->base);\n\n        /* Segment not valid for use (cooked meaning of .p)? */\n        if ( !reg->attr.fields.p )\n            goto out;\n\n        switch ( access_type )\n        {\n        case hvm_access_read:\n            if ( (reg->attr.fields.type & 0xa) == 0x8 )\n                goto out; /* execute-only code segment */\n            break;\n        case hvm_access_write:\n            if ( (reg->attr.fields.type & 0xa) != 0x2 )\n                goto out; /* not a writable data segment */\n            break;\n        default:\n            break;\n        }\n\n        last_byte = (uint32_t)offset + bytes - !!bytes;\n\n        /* Is this a grows-down data segment? Special limit check if so. */\n        if ( (reg->attr.fields.type & 0xc) == 0x4 )\n        {\n            /* Is upper limit 0xFFFF or 0xFFFFFFFF? */\n            if ( !reg->attr.fields.db )\n                last_byte = (uint16_t)last_byte;\n\n            /* Check first byte and last byte against respective bounds. */\n            if ( (offset <= reg->limit) || (last_byte < offset) )\n                goto out;\n        }\n        else if ( (last_byte > reg->limit) || (last_byte < offset) )\n            goto out; /* last byte is beyond limit or wraps 0xFFFFFFFF */\n    }\n    else\n    {\n        /*\n         * LONG MODE: FS and GS add segment base. Addresses must be canonical.\n         */\n\n        if ( (seg == x86_seg_fs) || (seg == x86_seg_gs) )\n            addr += reg->base;\n\n        last_byte = addr + bytes - !!bytes;\n        if ( !is_canonical_address(addr) || last_byte < addr ||\n             !is_canonical_address(last_byte) )\n            goto out;\n    }\n\n    /* All checks ok. */\n    okay = 1;\n\n out:\n    /*\n     * Always return the correct linear address, even if a permission check\n     * failed.  The permissions failure is not relevant to some callers.\n     */\n    *linear_addr = addr;\n    return okay;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,6 +32,10 @@\n          * It does not truncate to 16 bits in 16-bit address-size mode.\n          */\n         addr = (uint32_t)(addr + reg->base);\n+\n+        /* Segment not valid for use (cooked meaning of .p)? */\n+        if ( !reg->attr.fields.p )\n+            goto out;\n \n         switch ( access_type )\n         {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "        /* Segment not valid for use (cooked meaning of .p)? */",
                "        if ( !reg->attr.fields.p )",
                "            goto out;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9386",
        "func_name": "xen-project/xen/hvm_load_segment_selector",
        "description": "The x86 emulator in Xen does not properly treat x86 NULL segments as unusable when accessing memory, which might allow local HVM guest users to gain privileges via vectors involving \"unexpected\" base/limit values.",
        "git_url": "https://github.com/xen-project/xen/commit/04beafa8e6c66f5cd814c00e2d2b51cfbc41cb8a",
        "commit_title": "x86/hvm: Fix the handling of non-present segments",
        "commit_text": " In 32bit, the data segments may be NULL to indicate that the segment is ineligible for use.  In both 32bit and 64bit, the LDT selector may be NULL to indicate that the entire LDT is ineligible for use.  However, nothing in Xen actually checks for this condition when performing other segmentation checks.  (Note however that limit and writeability checks are correctly performed).  Neither Intel nor AMD specify the exact behaviour of loading a NULL segment. Experimentally, AMD zeroes all attributes but leaves the base and limit unmodified.  Intel zeroes the base, sets the limit to 0xfffffff and resets the attributes to just .G and .D/B.  The use of the segment information in the VMCB/VMCS is equivalent to a native pipeline interacting with the segment cache.  The present bit can therefore have a subtly different meaning, and it is now cooked to uniformly indicate whether the segment is usable or not.  GDTR and IDTR don't have access rights like the other segments, but for consistency, they are treated as being present so no special casing is needed elsewhere in the segmentation logic.  AMD hardware does not consider the present bit for %cs and %tr, and will function as if they were present.  They are therefore unconditionally set to present when reading information from the VMCB, to maintain the new meaning of usability.  Intel hardware has a separate unusable bit in the VMCS segment attributes. This bit is inverted and stored in the present field, so the hvm code can work with architecturally-common state.  This is CVE-2016-9386 / XSA-191. ",
        "func_before": "static int hvm_load_segment_selector(\n    enum x86_segment seg, uint16_t sel)\n{\n    struct segment_register desctab, cs, segr;\n    struct desc_struct *pdesc, desc;\n    u8 dpl, rpl, cpl;\n    bool_t writable;\n    int fault_type = TRAP_invalid_tss;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    struct vcpu *v = current;\n\n    if ( regs->eflags & X86_EFLAGS_VM )\n    {\n        segr.sel = sel;\n        segr.base = (uint32_t)sel << 4;\n        segr.limit = 0xffffu;\n        segr.attr.bytes = 0xf3;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        if ( (seg == x86_seg_cs) || (seg == x86_seg_ss) )\n            goto fail;\n        memset(&segr, 0, sizeof(segr));\n        segr.sel = sel;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* LDT descriptor must be in the GDT. */\n    if ( (seg == x86_seg_ldtr) && (sel & 4) )\n        goto fail;\n\n    hvm_get_segment_register(v, x86_seg_cs, &cs);\n    hvm_get_segment_register(\n        v, (sel & 4) ? x86_seg_ldtr : x86_seg_gdtr, &desctab);\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto fail;\n\n    pdesc = hvm_map_entry(desctab.base + (sel & 0xfff8), &writable);\n    if ( pdesc == NULL )\n        goto hvm_map_fail;\n\n    do {\n        desc = *pdesc;\n\n        /* LDT descriptor is a system segment. All others are code/data. */\n        if ( (desc.b & (1u<<12)) == ((seg == x86_seg_ldtr) << 12) )\n            goto unmap_and_fail;\n\n        dpl = (desc.b >> 13) & 3;\n        rpl = sel & 3;\n        cpl = cs.sel & 3;\n\n        switch ( seg )\n        {\n        case x86_seg_cs:\n            /* Code segment? */\n            if ( !(desc.b & _SEGMENT_CODE) )\n                goto unmap_and_fail;\n            /* Non-conforming segment: check DPL against RPL. */\n            if ( !(desc.b & _SEGMENT_EC) && (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ss:\n            /* Writable data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) != _SEGMENT_WR )\n                goto unmap_and_fail;\n            if ( (dpl != cpl) || (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ldtr:\n            /* LDT system segment? */\n            if ( (desc.b & _SEGMENT_TYPE) != (2u<<8) )\n                goto unmap_and_fail;\n            goto skip_accessed_flag;\n        default:\n            /* Readable code or data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) == _SEGMENT_CODE )\n                goto unmap_and_fail;\n            /*\n             * Data or non-conforming code segment:\n             * check DPL against RPL and CPL.\n             */\n            if ( ((desc.b & (_SEGMENT_EC|_SEGMENT_CODE)) !=\n                  (_SEGMENT_EC|_SEGMENT_CODE))\n                 && ((dpl < cpl) || (dpl < rpl)) )\n                goto unmap_and_fail;\n            break;\n        }\n\n        /* Segment present in memory? */\n        if ( !(desc.b & _SEGMENT_P) )\n        {\n            fault_type = (seg != x86_seg_ss) ? TRAP_no_segment\n                                             : TRAP_stack_error;\n            goto unmap_and_fail;\n        }\n    } while ( !(desc.b & 0x100) && /* Ensure Accessed flag is set */\n              writable && /* except if we are to discard writes */\n              (cmpxchg(&pdesc->b, desc.b, desc.b | 0x100) != desc.b) );\n\n    /* Force the Accessed flag in our local copy. */\n    desc.b |= 0x100;\n\n skip_accessed_flag:\n    hvm_unmap_entry(pdesc);\n\n    segr.base = (((desc.b <<  0) & 0xff000000u) |\n                 ((desc.b << 16) & 0x00ff0000u) |\n                 ((desc.a >> 16) & 0x0000ffffu));\n    segr.attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                       ((desc.b >> 12) & 0x0f00u));\n    segr.limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( segr.attr.fields.g )\n        segr.limit = (segr.limit << 12) | 0xfffu;\n    segr.sel = sel;\n    hvm_set_segment_register(v, seg, &segr);\n\n    return 0;\n\n unmap_and_fail:\n    hvm_unmap_entry(pdesc);\n fail:\n    hvm_inject_hw_exception(fault_type, sel & 0xfffc);\n hvm_map_fail:\n    return 1;\n}",
        "func": "static int hvm_load_segment_selector(\n    enum x86_segment seg, uint16_t sel)\n{\n    struct segment_register desctab, cs, segr;\n    struct desc_struct *pdesc, desc;\n    u8 dpl, rpl, cpl;\n    bool_t writable;\n    int fault_type = TRAP_invalid_tss;\n    struct cpu_user_regs *regs = guest_cpu_user_regs();\n    struct vcpu *v = current;\n\n    if ( regs->eflags & X86_EFLAGS_VM )\n    {\n        segr.sel = sel;\n        segr.base = (uint32_t)sel << 4;\n        segr.limit = 0xffffu;\n        segr.attr.bytes = 0xf3;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        if ( (seg == x86_seg_cs) || (seg == x86_seg_ss) )\n            goto fail;\n        memset(&segr, 0, sizeof(segr));\n        segr.sel = sel;\n        hvm_set_segment_register(v, seg, &segr);\n        return 0;\n    }\n\n    /* LDT descriptor must be in the GDT. */\n    if ( (seg == x86_seg_ldtr) && (sel & 4) )\n        goto fail;\n\n    hvm_get_segment_register(v, x86_seg_cs, &cs);\n    hvm_get_segment_register(\n        v, (sel & 4) ? x86_seg_ldtr : x86_seg_gdtr, &desctab);\n\n    /* Segment not valid for use (cooked meaning of .p)? */\n    if ( !desctab.attr.fields.p )\n        goto fail;\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto fail;\n\n    pdesc = hvm_map_entry(desctab.base + (sel & 0xfff8), &writable);\n    if ( pdesc == NULL )\n        goto hvm_map_fail;\n\n    do {\n        desc = *pdesc;\n\n        /* LDT descriptor is a system segment. All others are code/data. */\n        if ( (desc.b & (1u<<12)) == ((seg == x86_seg_ldtr) << 12) )\n            goto unmap_and_fail;\n\n        dpl = (desc.b >> 13) & 3;\n        rpl = sel & 3;\n        cpl = cs.sel & 3;\n\n        switch ( seg )\n        {\n        case x86_seg_cs:\n            /* Code segment? */\n            if ( !(desc.b & _SEGMENT_CODE) )\n                goto unmap_and_fail;\n            /* Non-conforming segment: check DPL against RPL. */\n            if ( !(desc.b & _SEGMENT_EC) && (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ss:\n            /* Writable data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) != _SEGMENT_WR )\n                goto unmap_and_fail;\n            if ( (dpl != cpl) || (dpl != rpl) )\n                goto unmap_and_fail;\n            break;\n        case x86_seg_ldtr:\n            /* LDT system segment? */\n            if ( (desc.b & _SEGMENT_TYPE) != (2u<<8) )\n                goto unmap_and_fail;\n            goto skip_accessed_flag;\n        default:\n            /* Readable code or data segment? */\n            if ( (desc.b & (_SEGMENT_CODE|_SEGMENT_WR)) == _SEGMENT_CODE )\n                goto unmap_and_fail;\n            /*\n             * Data or non-conforming code segment:\n             * check DPL against RPL and CPL.\n             */\n            if ( ((desc.b & (_SEGMENT_EC|_SEGMENT_CODE)) !=\n                  (_SEGMENT_EC|_SEGMENT_CODE))\n                 && ((dpl < cpl) || (dpl < rpl)) )\n                goto unmap_and_fail;\n            break;\n        }\n\n        /* Segment present in memory? */\n        if ( !(desc.b & _SEGMENT_P) )\n        {\n            fault_type = (seg != x86_seg_ss) ? TRAP_no_segment\n                                             : TRAP_stack_error;\n            goto unmap_and_fail;\n        }\n    } while ( !(desc.b & 0x100) && /* Ensure Accessed flag is set */\n              writable && /* except if we are to discard writes */\n              (cmpxchg(&pdesc->b, desc.b, desc.b | 0x100) != desc.b) );\n\n    /* Force the Accessed flag in our local copy. */\n    desc.b |= 0x100;\n\n skip_accessed_flag:\n    hvm_unmap_entry(pdesc);\n\n    segr.base = (((desc.b <<  0) & 0xff000000u) |\n                 ((desc.b << 16) & 0x00ff0000u) |\n                 ((desc.a >> 16) & 0x0000ffffu));\n    segr.attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                       ((desc.b >> 12) & 0x0f00u));\n    segr.limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( segr.attr.fields.g )\n        segr.limit = (segr.limit << 12) | 0xfffu;\n    segr.sel = sel;\n    hvm_set_segment_register(v, seg, &segr);\n\n    return 0;\n\n unmap_and_fail:\n    hvm_unmap_entry(pdesc);\n fail:\n    hvm_inject_hw_exception(fault_type, sel & 0xfffc);\n hvm_map_fail:\n    return 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,6 +37,10 @@\n     hvm_get_segment_register(v, x86_seg_cs, &cs);\n     hvm_get_segment_register(\n         v, (sel & 4) ? x86_seg_ldtr : x86_seg_gdtr, &desctab);\n+\n+    /* Segment not valid for use (cooked meaning of .p)? */\n+    if ( !desctab.attr.fields.p )\n+        goto fail;\n \n     /* Check against descriptor table limit. */\n     if ( ((sel & 0xfff8) + 7) > desctab.limit )",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    /* Segment not valid for use (cooked meaning of .p)? */",
                "    if ( !desctab.attr.fields.p )",
                "        goto fail;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9386",
        "func_name": "xen-project/xen/vmx_set_segment_register",
        "description": "The x86 emulator in Xen does not properly treat x86 NULL segments as unusable when accessing memory, which might allow local HVM guest users to gain privileges via vectors involving \"unexpected\" base/limit values.",
        "git_url": "https://github.com/xen-project/xen/commit/04beafa8e6c66f5cd814c00e2d2b51cfbc41cb8a",
        "commit_title": "x86/hvm: Fix the handling of non-present segments",
        "commit_text": " In 32bit, the data segments may be NULL to indicate that the segment is ineligible for use.  In both 32bit and 64bit, the LDT selector may be NULL to indicate that the entire LDT is ineligible for use.  However, nothing in Xen actually checks for this condition when performing other segmentation checks.  (Note however that limit and writeability checks are correctly performed).  Neither Intel nor AMD specify the exact behaviour of loading a NULL segment. Experimentally, AMD zeroes all attributes but leaves the base and limit unmodified.  Intel zeroes the base, sets the limit to 0xfffffff and resets the attributes to just .G and .D/B.  The use of the segment information in the VMCB/VMCS is equivalent to a native pipeline interacting with the segment cache.  The present bit can therefore have a subtly different meaning, and it is now cooked to uniformly indicate whether the segment is usable or not.  GDTR and IDTR don't have access rights like the other segments, but for consistency, they are treated as being present so no special casing is needed elsewhere in the segmentation logic.  AMD hardware does not consider the present bit for %cs and %tr, and will function as if they were present.  They are therefore unconditionally set to present when reading information from the VMCB, to maintain the new meaning of usability.  Intel hardware has a separate unusable bit in the VMCS segment attributes. This bit is inverted and stored in the present field, so the hvm code can work with architecturally-common state.  This is CVE-2016-9386 / XSA-191. ",
        "func_before": "static void vmx_set_segment_register(struct vcpu *v, enum x86_segment seg,\n                                     struct segment_register *reg)\n{\n    uint32_t attr, sel, limit;\n    uint64_t base;\n\n    sel = reg->sel;\n    attr = reg->attr.bytes;\n    limit = reg->limit;\n    base = reg->base;\n\n    /* Adjust CS/SS/DS/ES/FS/GS/TR for virtual 8086 mode */\n    if ( v->arch.hvm_vmx.vmx_realmode && seg <= x86_seg_tr )\n    {\n        /* Remember the proper contents */\n        v->arch.hvm_vmx.vm86_saved_seg[seg] = *reg;\n        \n        if ( seg == x86_seg_tr ) \n        {\n            if ( v->domain->arch.hvm_domain.params[HVM_PARAM_VM86_TSS] )\n            {\n                sel = 0;\n                attr = vm86_tr_attr;\n                limit = 0xff;\n                base = v->domain->arch.hvm_domain.params[HVM_PARAM_VM86_TSS];\n                v->arch.hvm_vmx.vm86_segment_mask &= ~(1u << seg);\n            }\n            else\n                v->arch.hvm_vmx.vm86_segment_mask |= (1u << seg);\n        }\n        else\n        {\n            /* Try to fake it out as a 16bit data segment.  This could\n             * cause confusion for the guest if it reads the selector,\n             * but otherwise we have to emulate if *any* segment hasn't\n             * been reloaded. */\n            if ( base < 0x100000 && !(base & 0xf) && limit >= 0xffff\n                 && reg->attr.fields.p )\n            {\n                sel = base >> 4;\n                attr = vm86_ds_attr;\n                limit = 0xffff;\n                v->arch.hvm_vmx.vm86_segment_mask &= ~(1u << seg);\n            }\n            else \n                v->arch.hvm_vmx.vm86_segment_mask |= (1u << seg);\n        }\n    }\n\n    attr = ((attr & 0xf00) << 4) | (attr & 0xff);\n\n    /* Not-present must mean unusable. */\n    if ( !reg->attr.fields.p )\n        attr |= (1u << 16);\n\n    /* VMX has strict consistency requirement for flag G. */\n    attr |= !!(limit >> 20) << 15;\n\n    vmx_vmcs_enter(v);\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        __vmwrite(GUEST_CS_SELECTOR, sel);\n        __vmwrite(GUEST_CS_LIMIT, limit);\n        __vmwrite(GUEST_CS_BASE, base);\n        __vmwrite(GUEST_CS_AR_BYTES, attr);\n        break;\n    case x86_seg_ds:\n        __vmwrite(GUEST_DS_SELECTOR, sel);\n        __vmwrite(GUEST_DS_LIMIT, limit);\n        __vmwrite(GUEST_DS_BASE, base);\n        __vmwrite(GUEST_DS_AR_BYTES, attr);\n        break;\n    case x86_seg_es:\n        __vmwrite(GUEST_ES_SELECTOR, sel);\n        __vmwrite(GUEST_ES_LIMIT, limit);\n        __vmwrite(GUEST_ES_BASE, base);\n        __vmwrite(GUEST_ES_AR_BYTES, attr);\n        break;\n    case x86_seg_fs:\n        __vmwrite(GUEST_FS_SELECTOR, sel);\n        __vmwrite(GUEST_FS_LIMIT, limit);\n        __vmwrite(GUEST_FS_BASE, base);\n        __vmwrite(GUEST_FS_AR_BYTES, attr);\n        break;\n    case x86_seg_gs:\n        __vmwrite(GUEST_GS_SELECTOR, sel);\n        __vmwrite(GUEST_GS_LIMIT, limit);\n        __vmwrite(GUEST_GS_BASE, base);\n        __vmwrite(GUEST_GS_AR_BYTES, attr);\n        break;\n    case x86_seg_ss:\n        __vmwrite(GUEST_SS_SELECTOR, sel);\n        __vmwrite(GUEST_SS_LIMIT, limit);\n        __vmwrite(GUEST_SS_BASE, base);\n        __vmwrite(GUEST_SS_AR_BYTES, attr);\n        break;\n    case x86_seg_tr:\n        __vmwrite(GUEST_TR_SELECTOR, sel);\n        __vmwrite(GUEST_TR_LIMIT, limit);\n        __vmwrite(GUEST_TR_BASE, base);\n        /* VMX checks that the the busy flag (bit 1) is set. */\n        __vmwrite(GUEST_TR_AR_BYTES, attr | 2);\n        break;\n    case x86_seg_gdtr:\n        __vmwrite(GUEST_GDTR_LIMIT, limit);\n        __vmwrite(GUEST_GDTR_BASE, base);\n        break;\n    case x86_seg_idtr:\n        __vmwrite(GUEST_IDTR_LIMIT, limit);\n        __vmwrite(GUEST_IDTR_BASE, base);\n        break;\n    case x86_seg_ldtr:\n        __vmwrite(GUEST_LDTR_SELECTOR, sel);\n        __vmwrite(GUEST_LDTR_LIMIT, limit);\n        __vmwrite(GUEST_LDTR_BASE, base);\n        __vmwrite(GUEST_LDTR_AR_BYTES, attr);\n        break;\n    default:\n        BUG();\n    }\n\n    vmx_vmcs_exit(v);\n}",
        "func": "static void vmx_set_segment_register(struct vcpu *v, enum x86_segment seg,\n                                     struct segment_register *reg)\n{\n    uint32_t attr, sel, limit;\n    uint64_t base;\n\n    sel = reg->sel;\n    attr = reg->attr.bytes;\n    limit = reg->limit;\n    base = reg->base;\n\n    /* Adjust CS/SS/DS/ES/FS/GS/TR for virtual 8086 mode */\n    if ( v->arch.hvm_vmx.vmx_realmode && seg <= x86_seg_tr )\n    {\n        /* Remember the proper contents */\n        v->arch.hvm_vmx.vm86_saved_seg[seg] = *reg;\n        \n        if ( seg == x86_seg_tr ) \n        {\n            if ( v->domain->arch.hvm_domain.params[HVM_PARAM_VM86_TSS] )\n            {\n                sel = 0;\n                attr = vm86_tr_attr;\n                limit = 0xff;\n                base = v->domain->arch.hvm_domain.params[HVM_PARAM_VM86_TSS];\n                v->arch.hvm_vmx.vm86_segment_mask &= ~(1u << seg);\n            }\n            else\n                v->arch.hvm_vmx.vm86_segment_mask |= (1u << seg);\n        }\n        else\n        {\n            /* Try to fake it out as a 16bit data segment.  This could\n             * cause confusion for the guest if it reads the selector,\n             * but otherwise we have to emulate if *any* segment hasn't\n             * been reloaded. */\n            if ( base < 0x100000 && !(base & 0xf) && limit >= 0xffff\n                 && reg->attr.fields.p )\n            {\n                sel = base >> 4;\n                attr = vm86_ds_attr;\n                limit = 0xffff;\n                v->arch.hvm_vmx.vm86_segment_mask &= ~(1u << seg);\n            }\n            else \n                v->arch.hvm_vmx.vm86_segment_mask |= (1u << seg);\n        }\n    }\n\n    /*\n     * Unfold Xen representation into VT-x representation.  The unusable bit\n     * is unconditionally set to the inverse of present.\n     */\n    attr = (!(attr & (1u << 7)) << 16) | ((attr & 0xf00) << 4) | (attr & 0xff);\n\n    /* VMX has strict consistency requirement for flag G. */\n    attr |= !!(limit >> 20) << 15;\n\n    vmx_vmcs_enter(v);\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        __vmwrite(GUEST_CS_SELECTOR, sel);\n        __vmwrite(GUEST_CS_LIMIT, limit);\n        __vmwrite(GUEST_CS_BASE, base);\n        __vmwrite(GUEST_CS_AR_BYTES, attr);\n        break;\n    case x86_seg_ds:\n        __vmwrite(GUEST_DS_SELECTOR, sel);\n        __vmwrite(GUEST_DS_LIMIT, limit);\n        __vmwrite(GUEST_DS_BASE, base);\n        __vmwrite(GUEST_DS_AR_BYTES, attr);\n        break;\n    case x86_seg_es:\n        __vmwrite(GUEST_ES_SELECTOR, sel);\n        __vmwrite(GUEST_ES_LIMIT, limit);\n        __vmwrite(GUEST_ES_BASE, base);\n        __vmwrite(GUEST_ES_AR_BYTES, attr);\n        break;\n    case x86_seg_fs:\n        __vmwrite(GUEST_FS_SELECTOR, sel);\n        __vmwrite(GUEST_FS_LIMIT, limit);\n        __vmwrite(GUEST_FS_BASE, base);\n        __vmwrite(GUEST_FS_AR_BYTES, attr);\n        break;\n    case x86_seg_gs:\n        __vmwrite(GUEST_GS_SELECTOR, sel);\n        __vmwrite(GUEST_GS_LIMIT, limit);\n        __vmwrite(GUEST_GS_BASE, base);\n        __vmwrite(GUEST_GS_AR_BYTES, attr);\n        break;\n    case x86_seg_ss:\n        __vmwrite(GUEST_SS_SELECTOR, sel);\n        __vmwrite(GUEST_SS_LIMIT, limit);\n        __vmwrite(GUEST_SS_BASE, base);\n        __vmwrite(GUEST_SS_AR_BYTES, attr);\n        break;\n    case x86_seg_tr:\n        __vmwrite(GUEST_TR_SELECTOR, sel);\n        __vmwrite(GUEST_TR_LIMIT, limit);\n        __vmwrite(GUEST_TR_BASE, base);\n        /* VMX checks that the the busy flag (bit 1) is set. */\n        __vmwrite(GUEST_TR_AR_BYTES, attr | 2);\n        break;\n    case x86_seg_gdtr:\n        __vmwrite(GUEST_GDTR_LIMIT, limit);\n        __vmwrite(GUEST_GDTR_BASE, base);\n        break;\n    case x86_seg_idtr:\n        __vmwrite(GUEST_IDTR_LIMIT, limit);\n        __vmwrite(GUEST_IDTR_BASE, base);\n        break;\n    case x86_seg_ldtr:\n        __vmwrite(GUEST_LDTR_SELECTOR, sel);\n        __vmwrite(GUEST_LDTR_LIMIT, limit);\n        __vmwrite(GUEST_LDTR_BASE, base);\n        __vmwrite(GUEST_LDTR_AR_BYTES, attr);\n        break;\n    default:\n        BUG();\n    }\n\n    vmx_vmcs_exit(v);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -47,11 +47,11 @@\n         }\n     }\n \n-    attr = ((attr & 0xf00) << 4) | (attr & 0xff);\n-\n-    /* Not-present must mean unusable. */\n-    if ( !reg->attr.fields.p )\n-        attr |= (1u << 16);\n+    /*\n+     * Unfold Xen representation into VT-x representation.  The unusable bit\n+     * is unconditionally set to the inverse of present.\n+     */\n+    attr = (!(attr & (1u << 7)) << 16) | ((attr & 0xf00) << 4) | (attr & 0xff);\n \n     /* VMX has strict consistency requirement for flag G. */\n     attr |= !!(limit >> 20) << 15;",
        "diff_line_info": {
            "deleted_lines": [
                "    attr = ((attr & 0xf00) << 4) | (attr & 0xff);",
                "",
                "    /* Not-present must mean unusable. */",
                "    if ( !reg->attr.fields.p )",
                "        attr |= (1u << 16);"
            ],
            "added_lines": [
                "    /*",
                "     * Unfold Xen representation into VT-x representation.  The unusable bit",
                "     * is unconditionally set to the inverse of present.",
                "     */",
                "    attr = (!(attr & (1u << 7)) << 16) | ((attr & 0xf00) << 4) | (attr & 0xff);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9386",
        "func_name": "xen-project/xen/vmx_get_segment_register",
        "description": "The x86 emulator in Xen does not properly treat x86 NULL segments as unusable when accessing memory, which might allow local HVM guest users to gain privileges via vectors involving \"unexpected\" base/limit values.",
        "git_url": "https://github.com/xen-project/xen/commit/04beafa8e6c66f5cd814c00e2d2b51cfbc41cb8a",
        "commit_title": "x86/hvm: Fix the handling of non-present segments",
        "commit_text": " In 32bit, the data segments may be NULL to indicate that the segment is ineligible for use.  In both 32bit and 64bit, the LDT selector may be NULL to indicate that the entire LDT is ineligible for use.  However, nothing in Xen actually checks for this condition when performing other segmentation checks.  (Note however that limit and writeability checks are correctly performed).  Neither Intel nor AMD specify the exact behaviour of loading a NULL segment. Experimentally, AMD zeroes all attributes but leaves the base and limit unmodified.  Intel zeroes the base, sets the limit to 0xfffffff and resets the attributes to just .G and .D/B.  The use of the segment information in the VMCB/VMCS is equivalent to a native pipeline interacting with the segment cache.  The present bit can therefore have a subtly different meaning, and it is now cooked to uniformly indicate whether the segment is usable or not.  GDTR and IDTR don't have access rights like the other segments, but for consistency, they are treated as being present so no special casing is needed elsewhere in the segmentation logic.  AMD hardware does not consider the present bit for %cs and %tr, and will function as if they were present.  They are therefore unconditionally set to present when reading information from the VMCB, to maintain the new meaning of usability.  Intel hardware has a separate unusable bit in the VMCS segment attributes. This bit is inverted and stored in the present field, so the hvm code can work with architecturally-common state.  This is CVE-2016-9386 / XSA-191. ",
        "func_before": "void vmx_get_segment_register(struct vcpu *v, enum x86_segment seg,\n                              struct segment_register *reg)\n{\n    unsigned long attr = 0, sel = 0, limit;\n\n    /*\n     * We may get here in the context of dump_execstate(), which may have\n     * interrupted context switching between setting \"current\" and\n     * vmx_do_resume() reaching the end of vmx_load_vmcs(). That would make\n     * all the VMREADs below fail if we don't bail right away.\n     */\n    if ( unlikely(!vmx_vmcs_try_enter(v)) )\n    {\n        static bool_t warned;\n\n        if ( !warned )\n        {\n            warned = 1;\n            printk(XENLOG_WARNING \"Segment register inaccessible for %pv\\n\"\n                   \"(If you see this outside of debugging activity,\"\n                   \" please report to xen-devel@lists.xenproject.org)\\n\",\n                   v);\n        }\n        memset(reg, 0, sizeof(*reg));\n        return;\n    }\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        __vmread(GUEST_CS_SELECTOR, &sel);\n        __vmread(GUEST_CS_LIMIT,    &limit);\n        __vmread(GUEST_CS_BASE,     &reg->base);\n        __vmread(GUEST_CS_AR_BYTES, &attr);\n        break;\n    case x86_seg_ds:\n        __vmread(GUEST_DS_SELECTOR, &sel);\n        __vmread(GUEST_DS_LIMIT,    &limit);\n        __vmread(GUEST_DS_BASE,     &reg->base);\n        __vmread(GUEST_DS_AR_BYTES, &attr);\n        break;\n    case x86_seg_es:\n        __vmread(GUEST_ES_SELECTOR, &sel);\n        __vmread(GUEST_ES_LIMIT,    &limit);\n        __vmread(GUEST_ES_BASE,     &reg->base);\n        __vmread(GUEST_ES_AR_BYTES, &attr);\n        break;\n    case x86_seg_fs:\n        __vmread(GUEST_FS_SELECTOR, &sel);\n        __vmread(GUEST_FS_LIMIT,    &limit);\n        __vmread(GUEST_FS_BASE,     &reg->base);\n        __vmread(GUEST_FS_AR_BYTES, &attr);\n        break;\n    case x86_seg_gs:\n        __vmread(GUEST_GS_SELECTOR, &sel);\n        __vmread(GUEST_GS_LIMIT,    &limit);\n        __vmread(GUEST_GS_BASE,     &reg->base);\n        __vmread(GUEST_GS_AR_BYTES, &attr);\n        break;\n    case x86_seg_ss:\n        __vmread(GUEST_SS_SELECTOR, &sel);\n        __vmread(GUEST_SS_LIMIT,    &limit);\n        __vmread(GUEST_SS_BASE,     &reg->base);\n        __vmread(GUEST_SS_AR_BYTES, &attr);\n        break;\n    case x86_seg_tr:\n        __vmread(GUEST_TR_SELECTOR, &sel);\n        __vmread(GUEST_TR_LIMIT,    &limit);\n        __vmread(GUEST_TR_BASE,     &reg->base);\n        __vmread(GUEST_TR_AR_BYTES, &attr);\n        break;\n    case x86_seg_gdtr:\n        __vmread(GUEST_GDTR_LIMIT, &limit);\n        __vmread(GUEST_GDTR_BASE,  &reg->base);\n        break;\n    case x86_seg_idtr:\n        __vmread(GUEST_IDTR_LIMIT, &limit);\n        __vmread(GUEST_IDTR_BASE,  &reg->base);\n        break;\n    case x86_seg_ldtr:\n        __vmread(GUEST_LDTR_SELECTOR, &sel);\n        __vmread(GUEST_LDTR_LIMIT,    &limit);\n        __vmread(GUEST_LDTR_BASE,     &reg->base);\n        __vmread(GUEST_LDTR_AR_BYTES, &attr);\n        break;\n    default:\n        BUG();\n        return;\n    }\n\n    vmx_vmcs_exit(v);\n\n    reg->sel = sel;\n    reg->limit = limit;\n\n    reg->attr.bytes = (attr & 0xff) | ((attr >> 4) & 0xf00);\n    /* Unusable flag is folded into Present flag. */\n    if ( attr & (1u<<16) )\n        reg->attr.fields.p = 0;\n\n    /* Adjust for virtual 8086 mode */\n    if ( v->arch.hvm_vmx.vmx_realmode && seg <= x86_seg_tr \n         && !(v->arch.hvm_vmx.vm86_segment_mask & (1u << seg)) )\n    {\n        struct segment_register *sreg = &v->arch.hvm_vmx.vm86_saved_seg[seg];\n        if ( seg == x86_seg_tr ) \n            *reg = *sreg;\n        else if ( reg->base != sreg->base || seg == x86_seg_ss )\n        {\n            /* If the guest's reloaded the segment, remember the new version.\n             * We can't tell if the guest reloaded the segment with another \n             * one that has the same base.  By default we assume it hasn't,\n             * since we don't want to lose big-real-mode segment attributes,\n             * but for SS we assume it has: the Ubuntu graphical bootloader\n             * does this and gets badly confused if we leave the old SS in \n             * place. */\n            reg->attr.bytes = (seg == x86_seg_cs ? rm_cs_attr : rm_ds_attr);\n            *sreg = *reg;\n        }\n        else \n        {\n            /* Always give realmode guests a selector that matches the base\n             * but keep the attr and limit from before */\n            *reg = *sreg;\n            reg->sel = reg->base >> 4;\n        }\n    }\n}",
        "func": "void vmx_get_segment_register(struct vcpu *v, enum x86_segment seg,\n                              struct segment_register *reg)\n{\n    unsigned long attr = 0, sel = 0, limit;\n\n    /*\n     * We may get here in the context of dump_execstate(), which may have\n     * interrupted context switching between setting \"current\" and\n     * vmx_do_resume() reaching the end of vmx_load_vmcs(). That would make\n     * all the VMREADs below fail if we don't bail right away.\n     */\n    if ( unlikely(!vmx_vmcs_try_enter(v)) )\n    {\n        static bool_t warned;\n\n        if ( !warned )\n        {\n            warned = 1;\n            printk(XENLOG_WARNING \"Segment register inaccessible for %pv\\n\"\n                   \"(If you see this outside of debugging activity,\"\n                   \" please report to xen-devel@lists.xenproject.org)\\n\",\n                   v);\n        }\n        memset(reg, 0, sizeof(*reg));\n        return;\n    }\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        __vmread(GUEST_CS_SELECTOR, &sel);\n        __vmread(GUEST_CS_LIMIT,    &limit);\n        __vmread(GUEST_CS_BASE,     &reg->base);\n        __vmread(GUEST_CS_AR_BYTES, &attr);\n        break;\n    case x86_seg_ds:\n        __vmread(GUEST_DS_SELECTOR, &sel);\n        __vmread(GUEST_DS_LIMIT,    &limit);\n        __vmread(GUEST_DS_BASE,     &reg->base);\n        __vmread(GUEST_DS_AR_BYTES, &attr);\n        break;\n    case x86_seg_es:\n        __vmread(GUEST_ES_SELECTOR, &sel);\n        __vmread(GUEST_ES_LIMIT,    &limit);\n        __vmread(GUEST_ES_BASE,     &reg->base);\n        __vmread(GUEST_ES_AR_BYTES, &attr);\n        break;\n    case x86_seg_fs:\n        __vmread(GUEST_FS_SELECTOR, &sel);\n        __vmread(GUEST_FS_LIMIT,    &limit);\n        __vmread(GUEST_FS_BASE,     &reg->base);\n        __vmread(GUEST_FS_AR_BYTES, &attr);\n        break;\n    case x86_seg_gs:\n        __vmread(GUEST_GS_SELECTOR, &sel);\n        __vmread(GUEST_GS_LIMIT,    &limit);\n        __vmread(GUEST_GS_BASE,     &reg->base);\n        __vmread(GUEST_GS_AR_BYTES, &attr);\n        break;\n    case x86_seg_ss:\n        __vmread(GUEST_SS_SELECTOR, &sel);\n        __vmread(GUEST_SS_LIMIT,    &limit);\n        __vmread(GUEST_SS_BASE,     &reg->base);\n        __vmread(GUEST_SS_AR_BYTES, &attr);\n        break;\n    case x86_seg_tr:\n        __vmread(GUEST_TR_SELECTOR, &sel);\n        __vmread(GUEST_TR_LIMIT,    &limit);\n        __vmread(GUEST_TR_BASE,     &reg->base);\n        __vmread(GUEST_TR_AR_BYTES, &attr);\n        break;\n    case x86_seg_gdtr:\n        __vmread(GUEST_GDTR_LIMIT, &limit);\n        __vmread(GUEST_GDTR_BASE,  &reg->base);\n        break;\n    case x86_seg_idtr:\n        __vmread(GUEST_IDTR_LIMIT, &limit);\n        __vmread(GUEST_IDTR_BASE,  &reg->base);\n        break;\n    case x86_seg_ldtr:\n        __vmread(GUEST_LDTR_SELECTOR, &sel);\n        __vmread(GUEST_LDTR_LIMIT,    &limit);\n        __vmread(GUEST_LDTR_BASE,     &reg->base);\n        __vmread(GUEST_LDTR_AR_BYTES, &attr);\n        break;\n    default:\n        BUG();\n        return;\n    }\n\n    vmx_vmcs_exit(v);\n\n    reg->sel = sel;\n    reg->limit = limit;\n\n    /*\n     * Fold VT-x representation into Xen's representation.  The Present bit is\n     * unconditionally set to the inverse of unusable.\n     */\n    reg->attr.bytes =\n        (!(attr & (1u << 16)) << 7) | (attr & 0x7f) | ((attr >> 4) & 0xf00);\n\n    /* Adjust for virtual 8086 mode */\n    if ( v->arch.hvm_vmx.vmx_realmode && seg <= x86_seg_tr \n         && !(v->arch.hvm_vmx.vm86_segment_mask & (1u << seg)) )\n    {\n        struct segment_register *sreg = &v->arch.hvm_vmx.vm86_saved_seg[seg];\n        if ( seg == x86_seg_tr ) \n            *reg = *sreg;\n        else if ( reg->base != sreg->base || seg == x86_seg_ss )\n        {\n            /* If the guest's reloaded the segment, remember the new version.\n             * We can't tell if the guest reloaded the segment with another \n             * one that has the same base.  By default we assume it hasn't,\n             * since we don't want to lose big-real-mode segment attributes,\n             * but for SS we assume it has: the Ubuntu graphical bootloader\n             * does this and gets badly confused if we leave the old SS in \n             * place. */\n            reg->attr.bytes = (seg == x86_seg_cs ? rm_cs_attr : rm_ds_attr);\n            *sreg = *reg;\n        }\n        else \n        {\n            /* Always give realmode guests a selector that matches the base\n             * but keep the attr and limit from before */\n            *reg = *sreg;\n            reg->sel = reg->base >> 4;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -93,10 +93,12 @@\n     reg->sel = sel;\n     reg->limit = limit;\n \n-    reg->attr.bytes = (attr & 0xff) | ((attr >> 4) & 0xf00);\n-    /* Unusable flag is folded into Present flag. */\n-    if ( attr & (1u<<16) )\n-        reg->attr.fields.p = 0;\n+    /*\n+     * Fold VT-x representation into Xen's representation.  The Present bit is\n+     * unconditionally set to the inverse of unusable.\n+     */\n+    reg->attr.bytes =\n+        (!(attr & (1u << 16)) << 7) | (attr & 0x7f) | ((attr >> 4) & 0xf00);\n \n     /* Adjust for virtual 8086 mode */\n     if ( v->arch.hvm_vmx.vmx_realmode && seg <= x86_seg_tr ",
        "diff_line_info": {
            "deleted_lines": [
                "    reg->attr.bytes = (attr & 0xff) | ((attr >> 4) & 0xf00);",
                "    /* Unusable flag is folded into Present flag. */",
                "    if ( attr & (1u<<16) )",
                "        reg->attr.fields.p = 0;"
            ],
            "added_lines": [
                "    /*",
                "     * Fold VT-x representation into Xen's representation.  The Present bit is",
                "     * unconditionally set to the inverse of unusable.",
                "     */",
                "    reg->attr.bytes =",
                "        (!(attr & (1u << 16)) << 7) | (attr & 0x7f) | ((attr >> 4) & 0xf00);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-9386",
        "func_name": "xen-project/xen/protmode_load_seg",
        "description": "The x86 emulator in Xen does not properly treat x86 NULL segments as unusable when accessing memory, which might allow local HVM guest users to gain privileges via vectors involving \"unexpected\" base/limit values.",
        "git_url": "https://github.com/xen-project/xen/commit/04beafa8e6c66f5cd814c00e2d2b51cfbc41cb8a",
        "commit_title": "x86/hvm: Fix the handling of non-present segments",
        "commit_text": " In 32bit, the data segments may be NULL to indicate that the segment is ineligible for use.  In both 32bit and 64bit, the LDT selector may be NULL to indicate that the entire LDT is ineligible for use.  However, nothing in Xen actually checks for this condition when performing other segmentation checks.  (Note however that limit and writeability checks are correctly performed).  Neither Intel nor AMD specify the exact behaviour of loading a NULL segment. Experimentally, AMD zeroes all attributes but leaves the base and limit unmodified.  Intel zeroes the base, sets the limit to 0xfffffff and resets the attributes to just .G and .D/B.  The use of the segment information in the VMCB/VMCS is equivalent to a native pipeline interacting with the segment cache.  The present bit can therefore have a subtly different meaning, and it is now cooked to uniformly indicate whether the segment is usable or not.  GDTR and IDTR don't have access rights like the other segments, but for consistency, they are treated as being present so no special casing is needed elsewhere in the segmentation logic.  AMD hardware does not consider the present bit for %cs and %tr, and will function as if they were present.  They are therefore unconditionally set to present when reading information from the VMCB, to maintain the new meaning of usability.  Intel hardware has a separate unusable bit in the VMCS segment attributes. This bit is inverted and stored in the present field, so the hvm code can work with architecturally-common state.  This is CVE-2016-9386 / XSA-191. ",
        "func_before": "static int\nprotmode_load_seg(\n    enum x86_segment seg,\n    uint16_t sel, bool_t is_ret,\n    struct segment_register *sreg,\n    struct x86_emulate_ctxt *ctxt,\n    const struct x86_emulate_ops *ops)\n{\n    struct segment_register desctab;\n    struct { uint32_t a, b; } desc;\n    uint8_t dpl, rpl;\n    int cpl = get_cpl(ctxt, ops);\n    uint32_t a_flag = 0x100;\n    int rc, fault_type = EXC_GP;\n\n    if ( cpl < 0 )\n        return X86EMUL_UNHANDLEABLE;\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        switch ( seg )\n        {\n        case x86_seg_ss:\n            if ( mode_64bit() && (cpl != 3) && (cpl == sel) )\n        default:\n                break;\n            /* fall through */\n        case x86_seg_cs:\n        case x86_seg_tr:\n            goto raise_exn;\n        }\n        memset(sreg, 0, sizeof(*sreg));\n        sreg->sel = sel;\n        return X86EMUL_OKAY;\n    }\n\n    /* System segment descriptors must reside in the GDT. */\n    if ( !is_x86_user_segment(seg) && (sel & 4) )\n        goto raise_exn;\n\n    if ( (rc = ops->read_segment((sel & 4) ? x86_seg_ldtr : x86_seg_gdtr,\n                                 &desctab, ctxt)) )\n        return rc;\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto raise_exn;\n\n    if ( (rc = ops->read(x86_seg_none, desctab.base + (sel & 0xfff8),\n                         &desc, sizeof(desc), ctxt)) )\n        return rc;\n\n    if ( !is_x86_user_segment(seg) )\n    {\n        /* System segments must have S flag == 0. */\n        if ( desc.b & (1u << 12) )\n            goto raise_exn;\n        /* We do not support 64-bit descriptor types. */\n        if ( in_longmode(ctxt, ops) )\n            return X86EMUL_UNHANDLEABLE;\n    }\n    /* User segments must have S flag == 1. */\n    else if ( !(desc.b & (1u << 12)) )\n        goto raise_exn;\n\n    dpl = (desc.b >> 13) & 3;\n    rpl = sel & 3;\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        /* Code segment? */\n        if ( !(desc.b & (1u<<11)) )\n            goto raise_exn;\n        if ( is_ret\n             ? /*\n                * Really rpl < cpl, but our sole caller doesn't handle\n                * privilege level changes.\n                */\n               rpl != cpl || (desc.b & (1 << 10) ? dpl > rpl : dpl != rpl)\n             : desc.b & (1 << 10)\n               /* Conforming segment: check DPL against CPL. */\n               ? dpl > cpl\n               /* Non-conforming segment: check RPL and DPL against CPL. */\n               : rpl > cpl || dpl != cpl )\n            goto raise_exn;\n        /*\n         * 64-bit code segments (L bit set) must have D bit clear.\n         * Experimentally in long mode, the L and D bits are checked before\n         * the Present bit.\n         */\n        if ( in_longmode(ctxt, ops) &&\n             (desc.b & (1 << 21)) && (desc.b & (1 << 22)) )\n            goto raise_exn;\n        sel = (sel ^ rpl) | cpl;\n        break;\n    case x86_seg_ss:\n        /* Writable data segment? */\n        if ( (desc.b & (5u<<9)) != (1u<<9) )\n            goto raise_exn;\n        if ( (dpl != cpl) || (dpl != rpl) )\n            goto raise_exn;\n        break;\n    case x86_seg_ldtr:\n        /* LDT system segment? */\n        if ( (desc.b & (15u<<8)) != (2u<<8) )\n            goto raise_exn;\n        a_flag = 0;\n        break;\n    case x86_seg_tr:\n        /* Available TSS system segment? */\n        if ( (desc.b & (15u<<8)) != (9u<<8) )\n            goto raise_exn;\n        a_flag = 0x200; /* busy flag */\n        break;\n    default:\n        /* Readable code or data segment? */\n        if ( (desc.b & (5u<<9)) == (4u<<9) )\n            goto raise_exn;\n        /* Non-conforming segment: check DPL against RPL and CPL. */\n        if ( ((desc.b & (6u<<9)) != (6u<<9)) &&\n             ((dpl < cpl) || (dpl < rpl)) )\n            goto raise_exn;\n        break;\n    }\n\n    /* Segment present in memory? */\n    if ( !(desc.b & (1 << 15)) )\n    {\n        fault_type = seg != x86_seg_ss ? EXC_NP : EXC_SS;\n        goto raise_exn;\n    }\n\n    /* Ensure Accessed flag is set. */\n    if ( a_flag && !(desc.b & a_flag) )\n    {\n        uint32_t new_desc_b = desc.b | a_flag;\n\n        if ( (rc = ops->cmpxchg(x86_seg_none, desctab.base + (sel & 0xfff8) + 4,\n                                &desc.b, &new_desc_b, 4, ctxt)) != 0 )\n            return rc;\n\n        /* Force the Accessed flag in our local copy. */\n        desc.b = new_desc_b;\n    }\n\n    sreg->base = (((desc.b <<  0) & 0xff000000u) |\n                  ((desc.b << 16) & 0x00ff0000u) |\n                  ((desc.a >> 16) & 0x0000ffffu));\n    sreg->attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                        ((desc.b >> 12) & 0x0f00u));\n    sreg->limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( sreg->attr.fields.g )\n        sreg->limit = (sreg->limit << 12) | 0xfffu;\n    sreg->sel = sel;\n    return X86EMUL_OKAY;\n\n raise_exn:\n    if ( ops->inject_hw_exception == NULL )\n        return X86EMUL_UNHANDLEABLE;\n    if ( (rc = ops->inject_hw_exception(fault_type, sel & 0xfffc, ctxt)) )\n        return rc;\n    return X86EMUL_EXCEPTION;\n}",
        "func": "static int\nprotmode_load_seg(\n    enum x86_segment seg,\n    uint16_t sel, bool_t is_ret,\n    struct segment_register *sreg,\n    struct x86_emulate_ctxt *ctxt,\n    const struct x86_emulate_ops *ops)\n{\n    struct segment_register desctab;\n    struct { uint32_t a, b; } desc;\n    uint8_t dpl, rpl;\n    int cpl = get_cpl(ctxt, ops);\n    uint32_t a_flag = 0x100;\n    int rc, fault_type = EXC_GP;\n\n    if ( cpl < 0 )\n        return X86EMUL_UNHANDLEABLE;\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        switch ( seg )\n        {\n        case x86_seg_ss:\n            if ( mode_64bit() && (cpl != 3) && (cpl == sel) )\n        default:\n                break;\n            /* fall through */\n        case x86_seg_cs:\n        case x86_seg_tr:\n            goto raise_exn;\n        }\n        memset(sreg, 0, sizeof(*sreg));\n        sreg->sel = sel;\n        return X86EMUL_OKAY;\n    }\n\n    /* System segment descriptors must reside in the GDT. */\n    if ( !is_x86_user_segment(seg) && (sel & 4) )\n        goto raise_exn;\n\n    if ( (rc = ops->read_segment((sel & 4) ? x86_seg_ldtr : x86_seg_gdtr,\n                                 &desctab, ctxt)) )\n        return rc;\n\n    /* Segment not valid for use (cooked meaning of .p)? */\n    if ( !desctab.attr.fields.p )\n        goto raise_exn;\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto raise_exn;\n\n    if ( (rc = ops->read(x86_seg_none, desctab.base + (sel & 0xfff8),\n                         &desc, sizeof(desc), ctxt)) )\n        return rc;\n\n    if ( !is_x86_user_segment(seg) )\n    {\n        /* System segments must have S flag == 0. */\n        if ( desc.b & (1u << 12) )\n            goto raise_exn;\n        /* We do not support 64-bit descriptor types. */\n        if ( in_longmode(ctxt, ops) )\n            return X86EMUL_UNHANDLEABLE;\n    }\n    /* User segments must have S flag == 1. */\n    else if ( !(desc.b & (1u << 12)) )\n        goto raise_exn;\n\n    dpl = (desc.b >> 13) & 3;\n    rpl = sel & 3;\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        /* Code segment? */\n        if ( !(desc.b & (1u<<11)) )\n            goto raise_exn;\n        if ( is_ret\n             ? /*\n                * Really rpl < cpl, but our sole caller doesn't handle\n                * privilege level changes.\n                */\n               rpl != cpl || (desc.b & (1 << 10) ? dpl > rpl : dpl != rpl)\n             : desc.b & (1 << 10)\n               /* Conforming segment: check DPL against CPL. */\n               ? dpl > cpl\n               /* Non-conforming segment: check RPL and DPL against CPL. */\n               : rpl > cpl || dpl != cpl )\n            goto raise_exn;\n        /*\n         * 64-bit code segments (L bit set) must have D bit clear.\n         * Experimentally in long mode, the L and D bits are checked before\n         * the Present bit.\n         */\n        if ( in_longmode(ctxt, ops) &&\n             (desc.b & (1 << 21)) && (desc.b & (1 << 22)) )\n            goto raise_exn;\n        sel = (sel ^ rpl) | cpl;\n        break;\n    case x86_seg_ss:\n        /* Writable data segment? */\n        if ( (desc.b & (5u<<9)) != (1u<<9) )\n            goto raise_exn;\n        if ( (dpl != cpl) || (dpl != rpl) )\n            goto raise_exn;\n        break;\n    case x86_seg_ldtr:\n        /* LDT system segment? */\n        if ( (desc.b & (15u<<8)) != (2u<<8) )\n            goto raise_exn;\n        a_flag = 0;\n        break;\n    case x86_seg_tr:\n        /* Available TSS system segment? */\n        if ( (desc.b & (15u<<8)) != (9u<<8) )\n            goto raise_exn;\n        a_flag = 0x200; /* busy flag */\n        break;\n    default:\n        /* Readable code or data segment? */\n        if ( (desc.b & (5u<<9)) == (4u<<9) )\n            goto raise_exn;\n        /* Non-conforming segment: check DPL against RPL and CPL. */\n        if ( ((desc.b & (6u<<9)) != (6u<<9)) &&\n             ((dpl < cpl) || (dpl < rpl)) )\n            goto raise_exn;\n        break;\n    }\n\n    /* Segment present in memory? */\n    if ( !(desc.b & (1 << 15)) )\n    {\n        fault_type = seg != x86_seg_ss ? EXC_NP : EXC_SS;\n        goto raise_exn;\n    }\n\n    /* Ensure Accessed flag is set. */\n    if ( a_flag && !(desc.b & a_flag) )\n    {\n        uint32_t new_desc_b = desc.b | a_flag;\n\n        if ( (rc = ops->cmpxchg(x86_seg_none, desctab.base + (sel & 0xfff8) + 4,\n                                &desc.b, &new_desc_b, 4, ctxt)) != 0 )\n            return rc;\n\n        /* Force the Accessed flag in our local copy. */\n        desc.b = new_desc_b;\n    }\n\n    sreg->base = (((desc.b <<  0) & 0xff000000u) |\n                  ((desc.b << 16) & 0x00ff0000u) |\n                  ((desc.a >> 16) & 0x0000ffffu));\n    sreg->attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                        ((desc.b >> 12) & 0x0f00u));\n    sreg->limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( sreg->attr.fields.g )\n        sreg->limit = (sreg->limit << 12) | 0xfffu;\n    sreg->sel = sel;\n    return X86EMUL_OKAY;\n\n raise_exn:\n    if ( ops->inject_hw_exception == NULL )\n        return X86EMUL_UNHANDLEABLE;\n    if ( (rc = ops->inject_hw_exception(fault_type, sel & 0xfffc, ctxt)) )\n        return rc;\n    return X86EMUL_EXCEPTION;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,6 +42,10 @@\n     if ( (rc = ops->read_segment((sel & 4) ? x86_seg_ldtr : x86_seg_gdtr,\n                                  &desctab, ctxt)) )\n         return rc;\n+\n+    /* Segment not valid for use (cooked meaning of .p)? */\n+    if ( !desctab.attr.fields.p )\n+        goto raise_exn;\n \n     /* Check against descriptor table limit. */\n     if ( ((sel & 0xfff8) + 7) > desctab.limit )",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    /* Segment not valid for use (cooked meaning of .p)? */",
                "    if ( !desctab.attr.fields.p )",
                "        goto raise_exn;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-0856",
        "func_name": "sddm/Greeter::start",
        "description": "daemon/Greeter.cpp in sddm before 0.13.0 does not properly disable the KDE crash handler, which allows local users to gain privileges by crashing a greeter when using certain themes, as demonstrated by the plasma-workspace breeze theme.",
        "git_url": "https://github.com/sddm/sddm/commit/4cfed6b0a625593fb43876f04badc4dd99799d86",
        "commit_title": "Disable greeters from loading KDE's debug hander",
        "commit_text": " Some themes may use KDE components which will automatically load KDE's crash handler.  If the greeter were to then somehow crash, that would leave a crash handler allowing other actions, albeit as the locked down SDDM user.  Only SDDM users using the breeze theme from plasma-workspace are affected. Safest and simplest fix is to handle this inside SDDM disabling kcrash via an environment variable for all future themes that may use these libraries.  CVE-2015-0856",
        "func_before": "bool Greeter::start() {\n        // check flag\n        if (m_started)\n            return false;\n\n        if (daemonApp->testing()) {\n            // create process\n            m_process = new QProcess(this);\n\n            // delete process on finish\n            connect(m_process, SIGNAL(finished(int,QProcess::ExitStatus)), this, SLOT(finished()));\n\n            connect(m_process, SIGNAL(readyReadStandardOutput()), SLOT(onReadyReadStandardOutput()));\n            connect(m_process, SIGNAL(readyReadStandardError()), SLOT(onReadyReadStandardError()));\n\n            // log message\n            qDebug() << \"Greeter starting...\";\n\n            // set process environment\n            QProcessEnvironment env = QProcessEnvironment::systemEnvironment();\n            env.insert(QStringLiteral(\"DISPLAY\"), m_display->name());\n            env.insert(QStringLiteral(\"XAUTHORITY\"), m_authPath);\n            env.insert(QStringLiteral(\"XCURSOR_THEME\"), mainConfig.Theme.CursorTheme.get());\n            m_process->setProcessEnvironment(env);\n\n            // start greeter\n            QStringList args;\n            if (daemonApp->testing())\n                args << QStringLiteral(\"--test-mode\");\n            args << QStringLiteral(\"--socket\") << m_socket\n                 << QStringLiteral(\"--theme\") << m_theme;\n            m_process->start(QStringLiteral(\"%1/sddm-greeter\").arg(QStringLiteral(BIN_INSTALL_DIR)), args);\n\n            //if we fail to start bail immediately, and don't block in waitForStarted\n            if (m_process->state() == QProcess::NotRunning) {\n                qCritical() << \"Greeter failed to launch.\";\n                return false;\n            }\n            // wait for greeter to start\n            if (!m_process->waitForStarted()) {\n                // log message\n                qCritical() << \"Failed to start greeter.\";\n\n                // return fail\n                return false;\n            }\n\n            // log message\n            qDebug() << \"Greeter started.\";\n\n            // set flag\n            m_started = true;\n        } else {\n            // authentication\n            m_auth = new Auth(this);\n            m_auth->setVerbose(true);\n            connect(m_auth, SIGNAL(requestChanged()), this, SLOT(onRequestChanged()));\n            connect(m_auth, SIGNAL(session(bool)), this, SLOT(onSessionStarted(bool)));\n            connect(m_auth, SIGNAL(finished(Auth::HelperExitStatus)), this, SLOT(onHelperFinished(Auth::HelperExitStatus)));\n            connect(m_auth, SIGNAL(info(QString,Auth::Info)), this, SLOT(authInfo(QString,Auth::Info)));\n            connect(m_auth, SIGNAL(error(QString,Auth::Error)), this, SLOT(authError(QString,Auth::Error)));\n\n            // greeter command\n            QStringList args;\n            args << QStringLiteral(\"%1/sddm-greeter\").arg(QStringLiteral(BIN_INSTALL_DIR));\n            args << QStringLiteral(\"--socket\") << m_socket\n                 << QStringLiteral(\"--theme\") << m_theme;\n\n            // greeter environment\n            QProcessEnvironment env;\n            QProcessEnvironment sysenv = QProcessEnvironment::systemEnvironment();\n\n            insertEnvironmentList({QStringLiteral(\"LANG\"), QStringLiteral(\"LANGUAGE\"),\n                                   QStringLiteral(\"LC_CTYPE\"), QStringLiteral(\"LC_NUMERIC\"), QStringLiteral(\"LC_TIME\"), QStringLiteral(\"LC_COLLATE\"),\n                                   QStringLiteral(\"LC_MONETARY\"), QStringLiteral(\"LC_MESSAGES\"), QStringLiteral(\"LC_PAPER\"), QStringLiteral(\"LC_NAME\"),\n                                   QStringLiteral(\"LC_ADDRESS\"), QStringLiteral(\"LC_TELEPHONE\"), QStringLiteral(\"LC_MEASUREMENT\"), QStringLiteral(\"LC_IDENTIFICATION\"),\n                                   QStringLiteral(\"LD_LIBRARY_PATH\"),\n                                   QStringLiteral(\"QML2_IMPORT_PATH\"),\n                                   QStringLiteral(\"QT_PLUGIN_PATH\"),\n                                   QStringLiteral(\"XDG_DATA_DIRS\")\n            }, sysenv, env);\n\n            env.insert(QStringLiteral(\"PATH\"), mainConfig.Users.DefaultPath.get());\n            env.insert(QStringLiteral(\"DISPLAY\"), m_display->name());\n            env.insert(QStringLiteral(\"XAUTHORITY\"), m_authPath);\n            env.insert(QStringLiteral(\"XCURSOR_THEME\"), mainConfig.Theme.CursorTheme.get());\n            env.insert(QStringLiteral(\"XDG_SEAT\"), m_display->seat()->name());\n            env.insert(QStringLiteral(\"XDG_SEAT_PATH\"), daemonApp->displayManager()->seatPath(m_display->seat()->name()));\n            env.insert(QStringLiteral(\"XDG_SESSION_PATH\"), daemonApp->displayManager()->sessionPath(QStringLiteral(\"Session%1\").arg(daemonApp->newSessionId())));\n            env.insert(QStringLiteral(\"XDG_VTNR\"), QString::number(m_display->terminalId()));\n            env.insert(QStringLiteral(\"XDG_SESSION_CLASS\"), QStringLiteral(\"greeter\"));\n            env.insert(QStringLiteral(\"XDG_SESSION_TYPE\"), m_display->sessionType());\n            m_auth->insertEnvironment(env);\n\n            // log message\n            qDebug() << \"Greeter starting...\";\n\n            // start greeter\n            m_auth->setUser(QStringLiteral(\"sddm\"));\n            m_auth->setGreeter(true);\n            m_auth->setSession(args.join(QLatin1Char(' ')));\n            m_auth->start();\n        }\n\n        // return success\n        return true;\n    }",
        "func": "bool Greeter::start() {\n        // check flag\n        if (m_started)\n            return false;\n\n        if (daemonApp->testing()) {\n            // create process\n            m_process = new QProcess(this);\n\n            // delete process on finish\n            connect(m_process, SIGNAL(finished(int,QProcess::ExitStatus)), this, SLOT(finished()));\n\n            connect(m_process, SIGNAL(readyReadStandardOutput()), SLOT(onReadyReadStandardOutput()));\n            connect(m_process, SIGNAL(readyReadStandardError()), SLOT(onReadyReadStandardError()));\n\n            // log message\n            qDebug() << \"Greeter starting...\";\n\n            // set process environment\n            QProcessEnvironment env = QProcessEnvironment::systemEnvironment();\n            env.insert(QStringLiteral(\"DISPLAY\"), m_display->name());\n            env.insert(QStringLiteral(\"XAUTHORITY\"), m_authPath);\n            env.insert(QStringLiteral(\"XCURSOR_THEME\"), mainConfig.Theme.CursorTheme.get());\n            m_process->setProcessEnvironment(env);\n\n            // start greeter\n            QStringList args;\n            if (daemonApp->testing())\n                args << QStringLiteral(\"--test-mode\");\n            args << QStringLiteral(\"--socket\") << m_socket\n                 << QStringLiteral(\"--theme\") << m_theme;\n            m_process->start(QStringLiteral(\"%1/sddm-greeter\").arg(QStringLiteral(BIN_INSTALL_DIR)), args);\n\n            //if we fail to start bail immediately, and don't block in waitForStarted\n            if (m_process->state() == QProcess::NotRunning) {\n                qCritical() << \"Greeter failed to launch.\";\n                return false;\n            }\n            // wait for greeter to start\n            if (!m_process->waitForStarted()) {\n                // log message\n                qCritical() << \"Failed to start greeter.\";\n\n                // return fail\n                return false;\n            }\n\n            // log message\n            qDebug() << \"Greeter started.\";\n\n            // set flag\n            m_started = true;\n        } else {\n            // authentication\n            m_auth = new Auth(this);\n            m_auth->setVerbose(true);\n            connect(m_auth, SIGNAL(requestChanged()), this, SLOT(onRequestChanged()));\n            connect(m_auth, SIGNAL(session(bool)), this, SLOT(onSessionStarted(bool)));\n            connect(m_auth, SIGNAL(finished(Auth::HelperExitStatus)), this, SLOT(onHelperFinished(Auth::HelperExitStatus)));\n            connect(m_auth, SIGNAL(info(QString,Auth::Info)), this, SLOT(authInfo(QString,Auth::Info)));\n            connect(m_auth, SIGNAL(error(QString,Auth::Error)), this, SLOT(authError(QString,Auth::Error)));\n\n            // greeter command\n            QStringList args;\n            args << QStringLiteral(\"%1/sddm-greeter\").arg(QStringLiteral(BIN_INSTALL_DIR));\n            args << QStringLiteral(\"--socket\") << m_socket\n                 << QStringLiteral(\"--theme\") << m_theme;\n\n            // greeter environment\n            QProcessEnvironment env;\n            QProcessEnvironment sysenv = QProcessEnvironment::systemEnvironment();\n\n            insertEnvironmentList({QStringLiteral(\"LANG\"), QStringLiteral(\"LANGUAGE\"),\n                                   QStringLiteral(\"LC_CTYPE\"), QStringLiteral(\"LC_NUMERIC\"), QStringLiteral(\"LC_TIME\"), QStringLiteral(\"LC_COLLATE\"),\n                                   QStringLiteral(\"LC_MONETARY\"), QStringLiteral(\"LC_MESSAGES\"), QStringLiteral(\"LC_PAPER\"), QStringLiteral(\"LC_NAME\"),\n                                   QStringLiteral(\"LC_ADDRESS\"), QStringLiteral(\"LC_TELEPHONE\"), QStringLiteral(\"LC_MEASUREMENT\"), QStringLiteral(\"LC_IDENTIFICATION\"),\n                                   QStringLiteral(\"LD_LIBRARY_PATH\"),\n                                   QStringLiteral(\"QML2_IMPORT_PATH\"),\n                                   QStringLiteral(\"QT_PLUGIN_PATH\"),\n                                   QStringLiteral(\"XDG_DATA_DIRS\")\n            }, sysenv, env);\n\n            env.insert(QStringLiteral(\"PATH\"), mainConfig.Users.DefaultPath.get());\n            env.insert(QStringLiteral(\"DISPLAY\"), m_display->name());\n            env.insert(QStringLiteral(\"XAUTHORITY\"), m_authPath);\n            env.insert(QStringLiteral(\"XCURSOR_THEME\"), mainConfig.Theme.CursorTheme.get());\n            env.insert(QStringLiteral(\"XDG_SEAT\"), m_display->seat()->name());\n            env.insert(QStringLiteral(\"XDG_SEAT_PATH\"), daemonApp->displayManager()->seatPath(m_display->seat()->name()));\n            env.insert(QStringLiteral(\"XDG_SESSION_PATH\"), daemonApp->displayManager()->sessionPath(QStringLiteral(\"Session%1\").arg(daemonApp->newSessionId())));\n            env.insert(QStringLiteral(\"XDG_VTNR\"), QString::number(m_display->terminalId()));\n            env.insert(QStringLiteral(\"XDG_SESSION_CLASS\"), QStringLiteral(\"greeter\"));\n            env.insert(QStringLiteral(\"XDG_SESSION_TYPE\"), m_display->sessionType());\n\n            //some themes may use KDE components and that will automatically load KDE's crash handler which we don't want\n            //counterintuitively setting this env disables that handler\n            env.insert(QStringLiteral(\"KDE_DEBUG\"), QStringLiteral(\"1\"));\n            m_auth->insertEnvironment(env);\n\n            // log message\n            qDebug() << \"Greeter starting...\";\n\n            // start greeter\n            m_auth->setUser(QStringLiteral(\"sddm\"));\n            m_auth->setGreeter(true);\n            m_auth->setSession(args.join(QLatin1Char(' ')));\n            m_auth->start();\n        }\n\n        // return success\n        return true;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -90,6 +90,10 @@\n             env.insert(QStringLiteral(\"XDG_VTNR\"), QString::number(m_display->terminalId()));\n             env.insert(QStringLiteral(\"XDG_SESSION_CLASS\"), QStringLiteral(\"greeter\"));\n             env.insert(QStringLiteral(\"XDG_SESSION_TYPE\"), m_display->sessionType());\n+\n+            //some themes may use KDE components and that will automatically load KDE's crash handler which we don't want\n+            //counterintuitively setting this env disables that handler\n+            env.insert(QStringLiteral(\"KDE_DEBUG\"), QStringLiteral(\"1\"));\n             m_auth->insertEnvironment(env);\n \n             // log message",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "            //some themes may use KDE components and that will automatically load KDE's crash handler which we don't want",
                "            //counterintuitively setting this env disables that handler",
                "            env.insert(QStringLiteral(\"KDE_DEBUG\"), QStringLiteral(\"1\"));"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6779",
        "func_name": "chromium/ChromeExtensionWebContentsObserver::RenderViewCreated",
        "description": "PDFium, as used in Google Chrome before 47.0.2526.73, does not properly restrict use of chrome: URLs, which allows remote attackers to bypass intended scheme restrictions via a crafted PDF document, as demonstrated by a document with a link to a chrome://settings URL.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/1eefa26e1795192c5a347a1e1e7a99e88c47f9c4",
        "commit_title": "This patch implements a mechanism for more granular link URL permissions (filtering on scheme/host). This fixes the bug that allowed PDFs to have working links to any \"chrome://\" URLs.",
        "commit_text": "   ",
        "func_before": "void ChromeExtensionWebContentsObserver::RenderViewCreated(\n    content::RenderViewHost* render_view_host) {\n  ReloadIfTerminated(render_view_host);\n  ExtensionWebContentsObserver::RenderViewCreated(render_view_host);\n}",
        "func": "void ChromeExtensionWebContentsObserver::RenderViewCreated(\n    content::RenderViewHost* render_view_host) {\n  ReloadIfTerminated(render_view_host);\n  ExtensionWebContentsObserver::RenderViewCreated(render_view_host);\n\n  const Extension* extension = GetExtension(render_view_host);\n  if (!extension)\n    return;\n\n  int process_id = render_view_host->GetProcess()->GetID();\n  auto policy = content::ChildProcessSecurityPolicy::GetInstance();\n\n  // Components of chrome that are implemented as extensions or platform apps\n  // are allowed to use chrome://resources/ URLs.\n  if ((extension->is_extension() || extension->is_platform_app()) &&\n      Manifest::IsComponentLocation(extension->location())) {\n    policy->GrantOrigin(process_id,\n                        url::Origin(GURL(content::kChromeUIResourcesURL)));\n  }\n\n  // Extensions, legacy packaged apps, and component platform apps are allowed\n  // to use chrome://favicon/ and chrome://extension-icon/ URLs. Hosted apps are\n  // not allowed because they are served via web servers (and are generally\n  // never given access to Chrome APIs).\n  if (extension->is_extension() ||\n      extension->is_legacy_packaged_app() ||\n      (extension->is_platform_app() &&\n       Manifest::IsComponentLocation(extension->location()))) {\n    policy->GrantOrigin(process_id,\n                        url::Origin(GURL(chrome::kChromeUIFaviconURL)));\n    policy->GrantOrigin(process_id,\n                        url::Origin(GURL(chrome::kChromeUIExtensionIconURL)));\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,4 +2,33 @@\n     content::RenderViewHost* render_view_host) {\n   ReloadIfTerminated(render_view_host);\n   ExtensionWebContentsObserver::RenderViewCreated(render_view_host);\n+\n+  const Extension* extension = GetExtension(render_view_host);\n+  if (!extension)\n+    return;\n+\n+  int process_id = render_view_host->GetProcess()->GetID();\n+  auto policy = content::ChildProcessSecurityPolicy::GetInstance();\n+\n+  // Components of chrome that are implemented as extensions or platform apps\n+  // are allowed to use chrome://resources/ URLs.\n+  if ((extension->is_extension() || extension->is_platform_app()) &&\n+      Manifest::IsComponentLocation(extension->location())) {\n+    policy->GrantOrigin(process_id,\n+                        url::Origin(GURL(content::kChromeUIResourcesURL)));\n+  }\n+\n+  // Extensions, legacy packaged apps, and component platform apps are allowed\n+  // to use chrome://favicon/ and chrome://extension-icon/ URLs. Hosted apps are\n+  // not allowed because they are served via web servers (and are generally\n+  // never given access to Chrome APIs).\n+  if (extension->is_extension() ||\n+      extension->is_legacy_packaged_app() ||\n+      (extension->is_platform_app() &&\n+       Manifest::IsComponentLocation(extension->location()))) {\n+    policy->GrantOrigin(process_id,\n+                        url::Origin(GURL(chrome::kChromeUIFaviconURL)));\n+    policy->GrantOrigin(process_id,\n+                        url::Origin(GURL(chrome::kChromeUIExtensionIconURL)));\n+  }\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "  const Extension* extension = GetExtension(render_view_host);",
                "  if (!extension)",
                "    return;",
                "",
                "  int process_id = render_view_host->GetProcess()->GetID();",
                "  auto policy = content::ChildProcessSecurityPolicy::GetInstance();",
                "",
                "  // Components of chrome that are implemented as extensions or platform apps",
                "  // are allowed to use chrome://resources/ URLs.",
                "  if ((extension->is_extension() || extension->is_platform_app()) &&",
                "      Manifest::IsComponentLocation(extension->location())) {",
                "    policy->GrantOrigin(process_id,",
                "                        url::Origin(GURL(content::kChromeUIResourcesURL)));",
                "  }",
                "",
                "  // Extensions, legacy packaged apps, and component platform apps are allowed",
                "  // to use chrome://favicon/ and chrome://extension-icon/ URLs. Hosted apps are",
                "  // not allowed because they are served via web servers (and are generally",
                "  // never given access to Chrome APIs).",
                "  if (extension->is_extension() ||",
                "      extension->is_legacy_packaged_app() ||",
                "      (extension->is_platform_app() &&",
                "       Manifest::IsComponentLocation(extension->location()))) {",
                "    policy->GrantOrigin(process_id,",
                "                        url::Origin(GURL(chrome::kChromeUIFaviconURL)));",
                "    policy->GrantOrigin(process_id,",
                "                        url::Origin(GURL(chrome::kChromeUIExtensionIconURL)));",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6779",
        "func_name": "chromium/NON_EXPORTED_BASE",
        "description": "PDFium, as used in Google Chrome before 47.0.2526.73, does not properly restrict use of chrome: URLs, which allows remote attackers to bypass intended scheme restrictions via a crafted PDF document, as demonstrated by a document with a link to a chrome://settings URL.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/1eefa26e1795192c5a347a1e1e7a99e88c47f9c4",
        "commit_title": "This patch implements a mechanism for more granular link URL permissions (filtering on scheme/host). This fixes the bug that allowed PDFs to have working links to any \"chrome://\" URLs.",
        "commit_text": "   ",
        "func_before": "class CONTENT_EXPORT ChildProcessSecurityPolicyImpl\n    : NON_EXPORTED_BASE(public ChildProcessSecurityPolicy) {\n public:\n  // Object can only be created through GetInstance() so the constructor is\n  // private.\n  ~ChildProcessSecurityPolicyImpl() override;\n\n  static ChildProcessSecurityPolicyImpl* GetInstance();\n\n  // ChildProcessSecurityPolicy implementation.\n  void RegisterWebSafeScheme(const std::string& scheme) override;\n  bool IsWebSafeScheme(const std::string& scheme) override;\n  void GrantReadFile(int child_id, const base::FilePath& file) override;\n  void GrantCreateReadWriteFile(int child_id,\n                                const base::FilePath& file) override;\n  void GrantCopyInto(int child_id, const base::FilePath& dir) override;\n  void GrantDeleteFrom(int child_id, const base::FilePath& dir) override;\n  void GrantReadFileSystem(int child_id,\n                           const std::string& filesystem_id) override;\n  void GrantWriteFileSystem(int child_id,\n                            const std::string& filesystem_id) override;\n  void GrantCreateFileForFileSystem(int child_id,\n                                    const std::string& filesystem_id) override;\n  void GrantCreateReadWriteFileSystem(\n      int child_id,\n      const std::string& filesystem_id) override;\n  void GrantCopyIntoFileSystem(int child_id,\n                               const std::string& filesystem_id) override;\n  void GrantDeleteFromFileSystem(int child_id,\n                                 const std::string& filesystem_id) override;\n  void GrantScheme(int child_id, const std::string& scheme) override;\n  bool CanReadFile(int child_id, const base::FilePath& file) override;\n  bool CanCreateReadWriteFile(int child_id,\n                              const base::FilePath& file) override;\n  bool CanReadFileSystem(int child_id,\n                         const std::string& filesystem_id) override;\n  bool CanReadWriteFileSystem(int child_id,\n                              const std::string& filesystem_id) override;\n  bool CanCopyIntoFileSystem(int child_id,\n                             const std::string& filesystem_id) override;\n  bool CanDeleteFromFileSystem(int child_id,\n                               const std::string& filesystem_id) override;\n  bool HasWebUIBindings(int child_id) override;\n  void GrantSendMidiSysExMessage(int child_id) override;\n  bool CanAccessDataForOrigin(int child_id, const GURL& url) override;\n\n  // Pseudo schemes are treated differently than other schemes because they\n  // cannot be requested like normal URLs.  There is no mechanism for revoking\n  // pseudo schemes.\n  void RegisterPseudoScheme(const std::string& scheme);\n\n  // Returns true iff |scheme| has been registered as pseudo scheme.\n  bool IsPseudoScheme(const std::string& scheme);\n\n  // Upon creation, child processes should register themselves by calling this\n  // this method exactly once.\n  void Add(int child_id);\n\n  // Upon creation, worker thread child processes should register themselves by\n  // calling this this method exactly once. Workers that are not shared will\n  // inherit permissions from their parent renderer process identified with\n  // |main_render_process_id|.\n  void AddWorker(int worker_child_id, int main_render_process_id);\n\n  // Upon destruction, child processess should unregister themselves by caling\n  // this method exactly once.\n  void Remove(int child_id);\n\n  // Whenever the browser processes commands the child process to request a URL,\n  // it should call this method to grant the child process the capability to\n  // request the URL, along with permission to request all URLs of the same\n  // scheme.\n  void GrantRequestURL(int child_id, const GURL& url);\n\n  // Whenever the browser process drops a file icon on a tab, it should call\n  // this method to grant the child process the capability to request this one\n  // file:// URL, but not all urls of the file:// scheme.\n  void GrantRequestSpecificFileURL(int child_id, const GURL& url);\n\n  // Revokes all permissions granted to the given file.\n  void RevokeAllPermissionsForFile(int child_id, const base::FilePath& file);\n\n  // Grant the child process the ability to use Web UI Bindings.\n  void GrantWebUIBindings(int child_id);\n\n  // Grant the child process the ability to read raw cookies.\n  void GrantReadRawCookies(int child_id);\n\n  // Revoke read raw cookies permission.\n  void RevokeReadRawCookies(int child_id);\n\n  // Before servicing a child process's request for a URL, the browser should\n  // call this method to determine whether the process has the capability to\n  // request the URL.\n  bool CanRequestURL(int child_id, const GURL& url);\n\n  // Whether the process is allowed to commit a document from the given URL.\n  // This is more restrictive than CanRequestURL, since CanRequestURL allows\n  // requests that might lead to cross-process navigations or external protocol\n  // handlers.\n  bool CanCommitURL(int child_id, const GURL& url);\n\n  // Explicit permissions checks for FileSystemURL specified files.\n  bool CanReadFileSystemFile(int child_id, const storage::FileSystemURL& url);\n  bool CanWriteFileSystemFile(int child_id, const storage::FileSystemURL& url);\n  bool CanCreateFileSystemFile(int child_id, const storage::FileSystemURL& url);\n  bool CanCreateReadWriteFileSystemFile(int child_id,\n                                        const storage::FileSystemURL& url);\n  bool CanCopyIntoFileSystemFile(int child_id,\n                                 const storage::FileSystemURL& url);\n  bool CanDeleteFileSystemFile(int child_id, const storage::FileSystemURL& url);\n\n  // Returns true if the specified child_id has been granted ReadRawCookies.\n  bool CanReadRawCookies(int child_id);\n\n  // Sets the process as only permitted to use and see the cookies for the\n  // given origin.\n  // Origin lock is applied only if the --site-per-process flag is used.\n  void LockToOrigin(int child_id, const GURL& gurl);\n\n  // Register FileSystem type and permission policy which should be used\n  // for the type.  The |policy| must be a bitwise-or'd value of\n  // storage::FilePermissionPolicy.\n  void RegisterFileSystemPermissionPolicy(storage::FileSystemType type,\n                                          int policy);\n\n  // Returns true if sending system exclusive messages is allowed.\n  bool CanSendMidiSysExMessage(int child_id);\n\n private:\n  friend class ChildProcessSecurityPolicyInProcessBrowserTest;\n  friend class ChildProcessSecurityPolicyTest;\n  FRIEND_TEST_ALL_PREFIXES(ChildProcessSecurityPolicyInProcessBrowserTest,\n                           NoLeak);\n  FRIEND_TEST_ALL_PREFIXES(ChildProcessSecurityPolicyTest, FilePermissions);\n\n  class SecurityState;\n\n  typedef std::set<std::string> SchemeSet;\n  typedef std::map<int, SecurityState*> SecurityStateMap;\n  typedef std::map<int, int> WorkerToMainProcessMap;\n  typedef std::map<storage::FileSystemType, int> FileSystemPermissionPolicyMap;\n\n  // Obtain an instance of ChildProcessSecurityPolicyImpl via GetInstance().\n  ChildProcessSecurityPolicyImpl();\n  friend struct base::DefaultSingletonTraits<ChildProcessSecurityPolicyImpl>;\n\n  // Adds child process during registration.\n  void AddChild(int child_id);\n\n  // Determines if certain permissions were granted for a file to given child\n  // process. |permissions| is an internally defined bit-set.\n  bool ChildProcessHasPermissionsForFile(int child_id,\n                                         const base::FilePath& file,\n                                         int permissions);\n\n  // Grant a particular permission set for a file. |permissions| is an\n  // internally defined bit-set.\n  void GrantPermissionsForFile(int child_id,\n                               const base::FilePath& file,\n                               int permissions);\n\n  // Grants access permission to the given isolated file system\n  // identified by |filesystem_id|.  See comments for\n  // ChildProcessSecurityPolicy::GrantReadFileSystem() for more details.\n  void GrantPermissionsForFileSystem(\n      int child_id,\n      const std::string& filesystem_id,\n      int permission);\n\n  // Determines if certain permissions were granted for a file. |permissions|\n  // is an internally defined bit-set. If |child_id| is a worker process,\n  // this returns true if either the worker process or its parent renderer\n  // has permissions for the file.\n  bool HasPermissionsForFile(int child_id,\n                             const base::FilePath& file,\n                             int permissions);\n\n  // Determines if certain permissions were granted for a file in FileSystem\n  // API. |permissions| is an internally defined bit-set.\n  bool HasPermissionsForFileSystemFile(int child_id,\n                                       const storage::FileSystemURL& url,\n                                       int permissions);\n\n  // Determines if certain permissions were granted for a file system.\n  // |permissions| is an internally defined bit-set.\n  bool HasPermissionsForFileSystem(\n      int child_id,\n      const std::string& filesystem_id,\n      int permission);\n\n  // You must acquire this lock before reading or writing any members of this\n  // class.  You must not block while holding this lock.\n  base::Lock lock_;\n\n  // These schemes are white-listed for all child processes.  This set is\n  // protected by |lock_|.\n  SchemeSet web_safe_schemes_;\n\n  // These schemes do not actually represent retrievable URLs.  For example,\n  // the the URLs in the \"about\" scheme are aliases to other URLs.  This set is\n  // protected by |lock_|.\n  SchemeSet pseudo_schemes_;\n\n  // This map holds a SecurityState for each child process.  The key for the\n  // map is the ID of the ChildProcessHost.  The SecurityState objects are\n  // owned by this object and are protected by |lock_|.  References to them must\n  // not escape this class.\n  SecurityStateMap security_state_;\n\n  // This maps keeps the record of which js worker thread child process\n  // corresponds to which main js thread child process.\n  WorkerToMainProcessMap worker_map_;\n\n  FileSystemPermissionPolicyMap file_system_policy_map_;\n\n  DISALLOW_COPY_AND_ASSIGN(ChildProcessSecurityPolicyImpl);\n}",
        "func": "class CONTENT_EXPORT ChildProcessSecurityPolicyImpl\n    : NON_EXPORTED_BASE(public ChildProcessSecurityPolicy) {\n public:\n  // Object can only be created through GetInstance() so the constructor is\n  // private.\n  ~ChildProcessSecurityPolicyImpl() override;\n\n  static ChildProcessSecurityPolicyImpl* GetInstance();\n\n  // ChildProcessSecurityPolicy implementation.\n  void RegisterWebSafeScheme(const std::string& scheme) override;\n  bool IsWebSafeScheme(const std::string& scheme) override;\n  void GrantReadFile(int child_id, const base::FilePath& file) override;\n  void GrantCreateReadWriteFile(int child_id,\n                                const base::FilePath& file) override;\n  void GrantCopyInto(int child_id, const base::FilePath& dir) override;\n  void GrantDeleteFrom(int child_id, const base::FilePath& dir) override;\n  void GrantReadFileSystem(int child_id,\n                           const std::string& filesystem_id) override;\n  void GrantWriteFileSystem(int child_id,\n                            const std::string& filesystem_id) override;\n  void GrantCreateFileForFileSystem(int child_id,\n                                    const std::string& filesystem_id) override;\n  void GrantCreateReadWriteFileSystem(\n      int child_id,\n      const std::string& filesystem_id) override;\n  void GrantCopyIntoFileSystem(int child_id,\n                               const std::string& filesystem_id) override;\n  void GrantDeleteFromFileSystem(int child_id,\n                                 const std::string& filesystem_id) override;\n  void GrantOrigin(int child_id, const url::Origin& origin) override;\n  void GrantScheme(int child_id, const std::string& scheme) override;\n  bool CanReadFile(int child_id, const base::FilePath& file) override;\n  bool CanCreateReadWriteFile(int child_id,\n                              const base::FilePath& file) override;\n  bool CanReadFileSystem(int child_id,\n                         const std::string& filesystem_id) override;\n  bool CanReadWriteFileSystem(int child_id,\n                              const std::string& filesystem_id) override;\n  bool CanCopyIntoFileSystem(int child_id,\n                             const std::string& filesystem_id) override;\n  bool CanDeleteFromFileSystem(int child_id,\n                               const std::string& filesystem_id) override;\n  bool HasWebUIBindings(int child_id) override;\n  void GrantSendMidiSysExMessage(int child_id) override;\n  bool CanAccessDataForOrigin(int child_id, const GURL& url) override;\n\n  // Pseudo schemes are treated differently than other schemes because they\n  // cannot be requested like normal URLs.  There is no mechanism for revoking\n  // pseudo schemes.\n  void RegisterPseudoScheme(const std::string& scheme);\n\n  // Returns true iff |scheme| has been registered as pseudo scheme.\n  bool IsPseudoScheme(const std::string& scheme);\n\n  // Upon creation, child processes should register themselves by calling this\n  // this method exactly once.\n  void Add(int child_id);\n\n  // Upon creation, worker thread child processes should register themselves by\n  // calling this this method exactly once. Workers that are not shared will\n  // inherit permissions from their parent renderer process identified with\n  // |main_render_process_id|.\n  void AddWorker(int worker_child_id, int main_render_process_id);\n\n  // Upon destruction, child processess should unregister themselves by caling\n  // this method exactly once.\n  void Remove(int child_id);\n\n  // Whenever the browser processes commands the child process to request a URL,\n  // it should call this method to grant the child process the capability to\n  // request the URL, along with permission to request all URLs of the same\n  // scheme.\n  void GrantRequestURL(int child_id, const GURL& url);\n\n  // Whenever the browser process drops a file icon on a tab, it should call\n  // this method to grant the child process the capability to request this one\n  // file:// URL, but not all urls of the file:// scheme.\n  void GrantRequestSpecificFileURL(int child_id, const GURL& url);\n\n  // Revokes all permissions granted to the given file.\n  void RevokeAllPermissionsForFile(int child_id, const base::FilePath& file);\n\n  // Grant the child process the ability to use Web UI Bindings.\n  void GrantWebUIBindings(int child_id);\n\n  // Grant the child process the ability to read raw cookies.\n  void GrantReadRawCookies(int child_id);\n\n  // Revoke read raw cookies permission.\n  void RevokeReadRawCookies(int child_id);\n\n  // Before servicing a child process's request for a URL, the browser should\n  // call this method to determine whether the process has the capability to\n  // request the URL.\n  bool CanRequestURL(int child_id, const GURL& url);\n\n  // Whether the process is allowed to commit a document from the given URL.\n  // This is more restrictive than CanRequestURL, since CanRequestURL allows\n  // requests that might lead to cross-process navigations or external protocol\n  // handlers.\n  bool CanCommitURL(int child_id, const GURL& url);\n\n  // Explicit permissions checks for FileSystemURL specified files.\n  bool CanReadFileSystemFile(int child_id, const storage::FileSystemURL& url);\n  bool CanWriteFileSystemFile(int child_id, const storage::FileSystemURL& url);\n  bool CanCreateFileSystemFile(int child_id, const storage::FileSystemURL& url);\n  bool CanCreateReadWriteFileSystemFile(int child_id,\n                                        const storage::FileSystemURL& url);\n  bool CanCopyIntoFileSystemFile(int child_id,\n                                 const storage::FileSystemURL& url);\n  bool CanDeleteFileSystemFile(int child_id, const storage::FileSystemURL& url);\n\n  // Returns true if the specified child_id has been granted ReadRawCookies.\n  bool CanReadRawCookies(int child_id);\n\n  // Sets the process as only permitted to use and see the cookies for the\n  // given origin.\n  // Origin lock is applied only if the --site-per-process flag is used.\n  void LockToOrigin(int child_id, const GURL& gurl);\n\n  // Register FileSystem type and permission policy which should be used\n  // for the type.  The |policy| must be a bitwise-or'd value of\n  // storage::FilePermissionPolicy.\n  void RegisterFileSystemPermissionPolicy(storage::FileSystemType type,\n                                          int policy);\n\n  // Returns true if sending system exclusive messages is allowed.\n  bool CanSendMidiSysExMessage(int child_id);\n\n private:\n  friend class ChildProcessSecurityPolicyInProcessBrowserTest;\n  friend class ChildProcessSecurityPolicyTest;\n  FRIEND_TEST_ALL_PREFIXES(ChildProcessSecurityPolicyInProcessBrowserTest,\n                           NoLeak);\n  FRIEND_TEST_ALL_PREFIXES(ChildProcessSecurityPolicyTest, FilePermissions);\n\n  class SecurityState;\n\n  typedef std::set<std::string> SchemeSet;\n  typedef std::map<int, SecurityState*> SecurityStateMap;\n  typedef std::map<int, int> WorkerToMainProcessMap;\n  typedef std::map<storage::FileSystemType, int> FileSystemPermissionPolicyMap;\n\n  // Obtain an instance of ChildProcessSecurityPolicyImpl via GetInstance().\n  ChildProcessSecurityPolicyImpl();\n  friend struct base::DefaultSingletonTraits<ChildProcessSecurityPolicyImpl>;\n\n  // Adds child process during registration.\n  void AddChild(int child_id);\n\n  // Determines if certain permissions were granted for a file to given child\n  // process. |permissions| is an internally defined bit-set.\n  bool ChildProcessHasPermissionsForFile(int child_id,\n                                         const base::FilePath& file,\n                                         int permissions);\n\n  // Grant a particular permission set for a file. |permissions| is an\n  // internally defined bit-set.\n  void GrantPermissionsForFile(int child_id,\n                               const base::FilePath& file,\n                               int permissions);\n\n  // Grants access permission to the given isolated file system\n  // identified by |filesystem_id|.  See comments for\n  // ChildProcessSecurityPolicy::GrantReadFileSystem() for more details.\n  void GrantPermissionsForFileSystem(\n      int child_id,\n      const std::string& filesystem_id,\n      int permission);\n\n  // Determines if certain permissions were granted for a file. |permissions|\n  // is an internally defined bit-set. If |child_id| is a worker process,\n  // this returns true if either the worker process or its parent renderer\n  // has permissions for the file.\n  bool HasPermissionsForFile(int child_id,\n                             const base::FilePath& file,\n                             int permissions);\n\n  // Determines if certain permissions were granted for a file in FileSystem\n  // API. |permissions| is an internally defined bit-set.\n  bool HasPermissionsForFileSystemFile(int child_id,\n                                       const storage::FileSystemURL& url,\n                                       int permissions);\n\n  // Determines if certain permissions were granted for a file system.\n  // |permissions| is an internally defined bit-set.\n  bool HasPermissionsForFileSystem(\n      int child_id,\n      const std::string& filesystem_id,\n      int permission);\n\n  // You must acquire this lock before reading or writing any members of this\n  // class.  You must not block while holding this lock.\n  base::Lock lock_;\n\n  // These schemes are white-listed for all child processes.  This set is\n  // protected by |lock_|.\n  SchemeSet web_safe_schemes_;\n\n  // These schemes do not actually represent retrievable URLs.  For example,\n  // the the URLs in the \"about\" scheme are aliases to other URLs.  This set is\n  // protected by |lock_|.\n  SchemeSet pseudo_schemes_;\n\n  // This map holds a SecurityState for each child process.  The key for the\n  // map is the ID of the ChildProcessHost.  The SecurityState objects are\n  // owned by this object and are protected by |lock_|.  References to them must\n  // not escape this class.\n  SecurityStateMap security_state_;\n\n  // This maps keeps the record of which js worker thread child process\n  // corresponds to which main js thread child process.\n  WorkerToMainProcessMap worker_map_;\n\n  FileSystemPermissionPolicyMap file_system_policy_map_;\n\n  DISALLOW_COPY_AND_ASSIGN(ChildProcessSecurityPolicyImpl);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -28,6 +28,7 @@\n                                const std::string& filesystem_id) override;\n   void GrantDeleteFromFileSystem(int child_id,\n                                  const std::string& filesystem_id) override;\n+  void GrantOrigin(int child_id, const url::Origin& origin) override;\n   void GrantScheme(int child_id, const std::string& scheme) override;\n   bool CanReadFile(int child_id, const base::FilePath& file) override;\n   bool CanCreateReadWriteFile(int child_id,",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  void GrantOrigin(int child_id, const url::Origin& origin) override;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6779",
        "func_name": "chromium/CanCommitURL",
        "description": "PDFium, as used in Google Chrome before 47.0.2526.73, does not properly restrict use of chrome: URLs, which allows remote attackers to bypass intended scheme restrictions via a crafted PDF document, as demonstrated by a document with a link to a chrome://settings URL.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/1eefa26e1795192c5a347a1e1e7a99e88c47f9c4",
        "commit_title": "This patch implements a mechanism for more granular link URL permissions (filtering on scheme/host). This fixes the bug that allowed PDFs to have working links to any \"chrome://\" URLs.",
        "commit_text": "   ",
        "func_before": "bool CanCommitURL(const GURL& url) {\n    // Having permission to a scheme implies permssion to all of its URLs.\n    SchemeMap::const_iterator judgment(scheme_policy_.find(url.scheme()));\n    if (judgment != scheme_policy_.end())\n      return judgment->second;\n\n    // file:// URLs are more granular.  The child may have been given\n    // permission to a specific file but not the file:// scheme in general.\n    if (url.SchemeIs(url::kFileScheme)) {\n      base::FilePath path;\n      if (net::FileURLToFilePath(url, &path))\n        return ContainsKey(request_file_set_, path);\n    }\n\n    return false;  // Unmentioned schemes are disallowed.\n  }",
        "func": "bool CanCommitURL(const GURL& url) {\n    // Having permission to a scheme implies permission to all of its URLs.\n    SchemeMap::const_iterator scheme_judgment(\n        scheme_policy_.find(url.scheme()));\n    if (scheme_judgment != scheme_policy_.end())\n      return scheme_judgment->second;\n\n    // Otherwise, check for permission for specific origin.\n    if (ContainsKey(origin_set_, url::Origin(url)))\n      return true;\n\n    // file:// URLs are more granular.  The child may have been given\n    // permission to a specific file but not the file:// scheme in general.\n    if (url.SchemeIs(url::kFileScheme)) {\n      base::FilePath path;\n      if (net::FileURLToFilePath(url, &path))\n        return ContainsKey(request_file_set_, path);\n    }\n\n    return false;  // Unmentioned schemes are disallowed.\n  }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,13 @@\n bool CanCommitURL(const GURL& url) {\n-    // Having permission to a scheme implies permssion to all of its URLs.\n-    SchemeMap::const_iterator judgment(scheme_policy_.find(url.scheme()));\n-    if (judgment != scheme_policy_.end())\n-      return judgment->second;\n+    // Having permission to a scheme implies permission to all of its URLs.\n+    SchemeMap::const_iterator scheme_judgment(\n+        scheme_policy_.find(url.scheme()));\n+    if (scheme_judgment != scheme_policy_.end())\n+      return scheme_judgment->second;\n+\n+    // Otherwise, check for permission for specific origin.\n+    if (ContainsKey(origin_set_, url::Origin(url)))\n+      return true;\n \n     // file:// URLs are more granular.  The child may have been given\n     // permission to a specific file but not the file:// scheme in general.",
        "diff_line_info": {
            "deleted_lines": [
                "    // Having permission to a scheme implies permssion to all of its URLs.",
                "    SchemeMap::const_iterator judgment(scheme_policy_.find(url.scheme()));",
                "    if (judgment != scheme_policy_.end())",
                "      return judgment->second;"
            ],
            "added_lines": [
                "    // Having permission to a scheme implies permission to all of its URLs.",
                "    SchemeMap::const_iterator scheme_judgment(",
                "        scheme_policy_.find(url.scheme()));",
                "    if (scheme_judgment != scheme_policy_.end())",
                "      return scheme_judgment->second;",
                "",
                "    // Otherwise, check for permission for specific origin.",
                "    if (ContainsKey(origin_set_, url::Origin(url)))",
                "      return true;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6779",
        "func_name": "chromium/ExtensionWebContentsObserver::RenderViewCreated",
        "description": "PDFium, as used in Google Chrome before 47.0.2526.73, does not properly restrict use of chrome: URLs, which allows remote attackers to bypass intended scheme restrictions via a crafted PDF document, as demonstrated by a document with a link to a chrome://settings URL.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/1eefa26e1795192c5a347a1e1e7a99e88c47f9c4",
        "commit_title": "This patch implements a mechanism for more granular link URL permissions (filtering on scheme/host). This fixes the bug that allowed PDFs to have working links to any \"chrome://\" URLs.",
        "commit_text": "   ",
        "func_before": "void ExtensionWebContentsObserver::RenderViewCreated(\n    content::RenderViewHost* render_view_host) {\n  // TODO(devlin): Most/all of this should move to RenderFrameCreated.\n  const Extension* extension = GetExtension(render_view_host);\n  if (!extension)\n    return;\n\n  content::RenderProcessHost* process = render_view_host->GetProcess();\n\n  // Some extensions use chrome:// URLs.\n  // This is a temporary solution. Replace it with access to chrome-static://\n  // once it is implemented. See: crbug.com/226927.\n  Manifest::Type type = extension->GetType();\n  if (type == Manifest::TYPE_EXTENSION ||\n      type == Manifest::TYPE_LEGACY_PACKAGED_APP ||\n      (type == Manifest::TYPE_PLATFORM_APP &&\n       extension->location() == Manifest::COMPONENT)) {\n    content::ChildProcessSecurityPolicy::GetInstance()->GrantScheme(\n        process->GetID(), content::kChromeUIScheme);\n  }\n\n  // Some extensions use file:// URLs.\n  if (type == Manifest::TYPE_EXTENSION ||\n      type == Manifest::TYPE_LEGACY_PACKAGED_APP) {\n    ExtensionPrefs* prefs = ExtensionPrefs::Get(browser_context_);\n    if (prefs->AllowFileAccess(extension->id())) {\n      content::ChildProcessSecurityPolicy::GetInstance()->GrantScheme(\n          process->GetID(), url::kFileScheme);\n    }\n  }\n\n  // Tells the new view that it's hosted in an extension process.\n  //\n  // This will often be a rendant IPC, because activating extensions happens at\n  // the process level, not at the view level. However, without some mild\n  // refactoring this isn't trivial to do, and this way is simpler.\n  //\n  // Plus, we can delete the concept of activating an extension once site\n  // isolation is turned on.\n  render_view_host->Send(new ExtensionMsg_ActivateExtension(extension->id()));\n}",
        "func": "void ExtensionWebContentsObserver::RenderViewCreated(\n    content::RenderViewHost* render_view_host) {\n  // TODO(devlin): Most/all of this should move to RenderFrameCreated.\n  const Extension* extension = GetExtension(render_view_host);\n  if (!extension)\n    return;\n\n  Manifest::Type type = extension->GetType();\n\n  // Some extensions use file:// URLs.\n  if (type == Manifest::TYPE_EXTENSION ||\n      type == Manifest::TYPE_LEGACY_PACKAGED_APP) {\n    ExtensionPrefs* prefs = ExtensionPrefs::Get(browser_context_);\n    if (prefs->AllowFileAccess(extension->id())) {\n      content::ChildProcessSecurityPolicy::GetInstance()->GrantScheme(\n          render_view_host->GetProcess()->GetID(), url::kFileScheme);\n    }\n  }\n\n  // Tells the new view that it's hosted in an extension process.\n  //\n  // This will often be a rendant IPC, because activating extensions happens at\n  // the process level, not at the view level. However, without some mild\n  // refactoring this isn't trivial to do, and this way is simpler.\n  //\n  // Plus, we can delete the concept of activating an extension once site\n  // isolation is turned on.\n  render_view_host->Send(new ExtensionMsg_ActivateExtension(extension->id()));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,19 +5,7 @@\n   if (!extension)\n     return;\n \n-  content::RenderProcessHost* process = render_view_host->GetProcess();\n-\n-  // Some extensions use chrome:// URLs.\n-  // This is a temporary solution. Replace it with access to chrome-static://\n-  // once it is implemented. See: crbug.com/226927.\n   Manifest::Type type = extension->GetType();\n-  if (type == Manifest::TYPE_EXTENSION ||\n-      type == Manifest::TYPE_LEGACY_PACKAGED_APP ||\n-      (type == Manifest::TYPE_PLATFORM_APP &&\n-       extension->location() == Manifest::COMPONENT)) {\n-    content::ChildProcessSecurityPolicy::GetInstance()->GrantScheme(\n-        process->GetID(), content::kChromeUIScheme);\n-  }\n \n   // Some extensions use file:// URLs.\n   if (type == Manifest::TYPE_EXTENSION ||\n@@ -25,7 +13,7 @@\n     ExtensionPrefs* prefs = ExtensionPrefs::Get(browser_context_);\n     if (prefs->AllowFileAccess(extension->id())) {\n       content::ChildProcessSecurityPolicy::GetInstance()->GrantScheme(\n-          process->GetID(), url::kFileScheme);\n+          render_view_host->GetProcess()->GetID(), url::kFileScheme);\n     }\n   }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "  content::RenderProcessHost* process = render_view_host->GetProcess();",
                "",
                "  // Some extensions use chrome:// URLs.",
                "  // This is a temporary solution. Replace it with access to chrome-static://",
                "  // once it is implemented. See: crbug.com/226927.",
                "  if (type == Manifest::TYPE_EXTENSION ||",
                "      type == Manifest::TYPE_LEGACY_PACKAGED_APP ||",
                "      (type == Manifest::TYPE_PLATFORM_APP &&",
                "       extension->location() == Manifest::COMPONENT)) {",
                "    content::ChildProcessSecurityPolicy::GetInstance()->GrantScheme(",
                "        process->GetID(), content::kChromeUIScheme);",
                "  }",
                "          process->GetID(), url::kFileScheme);"
            ],
            "added_lines": [
                "          render_view_host->GetProcess()->GetID(), url::kFileScheme);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6785",
        "func_name": "chromium/CSPSource::hostMatches",
        "description": "The CSPSource::hostMatches function in WebKit/Source/core/frame/csp/CSPSource.cpp in the Content Security Policy (CSP) implementation in Google Chrome before 47.0.2526.73 accepts an x.y hostname as a match for a *.x.y pattern, which might allow remote attackers to bypass intended access restrictions in opportunistic circumstances by leveraging a policy that was intended to be specific to subdomains.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/6282934a62f7b1416b677acad89a2880f2de201c",
        "commit_title": "CSP source *.x.y should not match host x.y",
        "commit_text": " This fixes a minor CSP bug where a source in a source list with a wildcard was matching more liberally than it should have. It was matching a source of the form *.x.y to host x.y when, in fact, it should only be matching subdomains.  TBR=mkwst@chromium.org   ",
        "func_before": "bool CSPSource::hostMatches(const KURL& url) const\n{\n    const String& host = url.host();\n    if (equalIgnoringCase(host, m_host))\n        return true;\n    return m_hostWildcard == HasWildcard && host.endsWith(\".\" + m_host, TextCaseInsensitive);\n\n}",
        "func": "bool CSPSource::hostMatches(const KURL& url) const\n{\n    const String& host = url.host();\n    Document* document = m_policy->document();\n    bool match;\n\n    bool equalHosts = equalIgnoringCase(host, m_host);\n    if (m_hostWildcard == HasWildcard) {\n        match = host.endsWith(\".\" + m_host, TextCaseInsensitive);\n\n        // Chrome used to, incorrectly, match *.x.y to x.y. This was fixed, but\n        // the following count measures when a match fails that would have\n        // passed the old, incorrect style, in case a lot of sites were\n        // relying on that behavior.\n        if (document && equalHosts)\n            UseCounter::count(*document, UseCounter::CSPSourceWildcardWouldMatchExactHost);\n    } else {\n        match = equalHosts;\n    }\n\n    return match;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,22 @@\n bool CSPSource::hostMatches(const KURL& url) const\n {\n     const String& host = url.host();\n-    if (equalIgnoringCase(host, m_host))\n-        return true;\n-    return m_hostWildcard == HasWildcard && host.endsWith(\".\" + m_host, TextCaseInsensitive);\n+    Document* document = m_policy->document();\n+    bool match;\n \n+    bool equalHosts = equalIgnoringCase(host, m_host);\n+    if (m_hostWildcard == HasWildcard) {\n+        match = host.endsWith(\".\" + m_host, TextCaseInsensitive);\n+\n+        // Chrome used to, incorrectly, match *.x.y to x.y. This was fixed, but\n+        // the following count measures when a match fails that would have\n+        // passed the old, incorrect style, in case a lot of sites were\n+        // relying on that behavior.\n+        if (document && equalHosts)\n+            UseCounter::count(*document, UseCounter::CSPSourceWildcardWouldMatchExactHost);\n+    } else {\n+        match = equalHosts;\n+    }\n+\n+    return match;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (equalIgnoringCase(host, m_host))",
                "        return true;",
                "    return m_hostWildcard == HasWildcard && host.endsWith(\".\" + m_host, TextCaseInsensitive);"
            ],
            "added_lines": [
                "    Document* document = m_policy->document();",
                "    bool match;",
                "    bool equalHosts = equalIgnoringCase(host, m_host);",
                "    if (m_hostWildcard == HasWildcard) {",
                "        match = host.endsWith(\".\" + m_host, TextCaseInsensitive);",
                "",
                "        // Chrome used to, incorrectly, match *.x.y to x.y. This was fixed, but",
                "        // the following count measures when a match fails that would have",
                "        // passed the old, incorrect style, in case a lot of sites were",
                "        // relying on that behavior.",
                "        if (document && equalHosts)",
                "            UseCounter::count(*document, UseCounter::CSPSourceWildcardWouldMatchExactHost);",
                "    } else {",
                "        match = equalHosts;",
                "    }",
                "",
                "    return match;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6785",
        "func_name": "chromium/ContentSecurityPolicy::document",
        "description": "The CSPSource::hostMatches function in WebKit/Source/core/frame/csp/CSPSource.cpp in the Content Security Policy (CSP) implementation in Google Chrome before 47.0.2526.73 accepts an x.y hostname as a match for a *.x.y pattern, which might allow remote attackers to bypass intended access restrictions in opportunistic circumstances by leveraging a policy that was intended to be specific to subdomains.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/6282934a62f7b1416b677acad89a2880f2de201c",
        "commit_title": "CSP source *.x.y should not match host x.y",
        "commit_text": " This fixes a minor CSP bug where a source in a source list with a wildcard was matching more liberally than it should have. It was matching a source of the form *.x.y to host x.y when, in fact, it should only be matching subdomains.  TBR=mkwst@chromium.org   ",
        "func_before": "Document* ContentSecurityPolicy::document() const\n{\n    return m_executionContext->isDocument() ? toDocument(m_executionContext) : nullptr;\n}",
        "func": "Document* ContentSecurityPolicy::document() const\n{\n    return (m_executionContext && m_executionContext->isDocument()) ? toDocument(m_executionContext) : nullptr;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n Document* ContentSecurityPolicy::document() const\n {\n-    return m_executionContext->isDocument() ? toDocument(m_executionContext) : nullptr;\n+    return (m_executionContext && m_executionContext->isDocument()) ? toDocument(m_executionContext) : nullptr;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return m_executionContext->isDocument() ? toDocument(m_executionContext) : nullptr;"
            ],
            "added_lines": [
                "    return (m_executionContext && m_executionContext->isDocument()) ? toDocument(m_executionContext) : nullptr;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6786",
        "func_name": "chromium/CSPSourceList::matches",
        "description": "The CSPSourceList::matches function in WebKit/Source/core/frame/csp/CSPSourceList.cpp in the Content Security Policy (CSP) implementation in Google Chrome before 47.0.2526.73 accepts a blob:, data:, or filesystem: URL as a match for a * pattern, which allows remote attackers to bypass intended scheme restrictions in opportunistic circumstances by leveraging a policy that relies on this pattern.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/5d0e9f824e05523e03dabc0e341b9f8f17a72bb0",
        "commit_title": "Disallow CSP source * matching of data:, blob:, and filesystem: URLs",
        "commit_text": " The CSP spec specifically excludes matching of data:, blob:, and filesystem: URLs with the source '*' wildcard. This adds checks to make sure that doesn't happen, along with tests.    ",
        "func_before": "bool CSPSourceList::matches(const KURL& url, ContentSecurityPolicy::RedirectStatus redirectStatus) const\n{\n    if (m_allowStar)\n        return true;\n\n    KURL effectiveURL = m_policy->selfMatchesInnerURL() && SecurityOrigin::shouldUseInnerURL(url) ? SecurityOrigin::extractInnerURL(url) : url;\n\n    if (m_allowSelf && m_policy->urlMatchesSelf(effectiveURL))\n        return true;\n\n    for (size_t i = 0; i < m_list.size(); ++i) {\n        if (m_list[i].matches(effectiveURL, redirectStatus))\n            return true;\n    }\n\n    return false;\n}",
        "func": "bool CSPSourceList::matches(const KURL& url, ContentSecurityPolicy::RedirectStatus redirectStatus) const\n{\n    // The CSP spec specifically states that data:, blob:, and filesystem URLs\n    // should not be captured by a '*\" source\n    // (http://www.w3.org/TR/CSP2/#source-list-guid-matching). Thus, in the\n    // case of a full wildcard, data:, blob:, and filesystem: URLs are\n    // explicitly checked for in the source list before allowing them through.\n    if (m_allowStar) {\n        if (url.protocolIs(\"blob\") || url.protocolIs(\"data\") || url.protocolIs(\"filesystem\"))\n            return hasSourceMatchInList(url, redirectStatus);\n        return true;\n    }\n\n    KURL effectiveURL = m_policy->selfMatchesInnerURL() && SecurityOrigin::shouldUseInnerURL(url) ? SecurityOrigin::extractInnerURL(url) : url;\n\n    if (m_allowSelf && m_policy->urlMatchesSelf(effectiveURL))\n        return true;\n\n    return hasSourceMatchInList(effectiveURL, redirectStatus);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,17 +1,20 @@\n bool CSPSourceList::matches(const KURL& url, ContentSecurityPolicy::RedirectStatus redirectStatus) const\n {\n-    if (m_allowStar)\n+    // The CSP spec specifically states that data:, blob:, and filesystem URLs\n+    // should not be captured by a '*\" source\n+    // (http://www.w3.org/TR/CSP2/#source-list-guid-matching). Thus, in the\n+    // case of a full wildcard, data:, blob:, and filesystem: URLs are\n+    // explicitly checked for in the source list before allowing them through.\n+    if (m_allowStar) {\n+        if (url.protocolIs(\"blob\") || url.protocolIs(\"data\") || url.protocolIs(\"filesystem\"))\n+            return hasSourceMatchInList(url, redirectStatus);\n         return true;\n+    }\n \n     KURL effectiveURL = m_policy->selfMatchesInnerURL() && SecurityOrigin::shouldUseInnerURL(url) ? SecurityOrigin::extractInnerURL(url) : url;\n \n     if (m_allowSelf && m_policy->urlMatchesSelf(effectiveURL))\n         return true;\n \n-    for (size_t i = 0; i < m_list.size(); ++i) {\n-        if (m_list[i].matches(effectiveURL, redirectStatus))\n-            return true;\n-    }\n-\n-    return false;\n+    return hasSourceMatchInList(effectiveURL, redirectStatus);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (m_allowStar)",
                "    for (size_t i = 0; i < m_list.size(); ++i) {",
                "        if (m_list[i].matches(effectiveURL, redirectStatus))",
                "            return true;",
                "    }",
                "",
                "    return false;"
            ],
            "added_lines": [
                "    // The CSP spec specifically states that data:, blob:, and filesystem URLs",
                "    // should not be captured by a '*\" source",
                "    // (http://www.w3.org/TR/CSP2/#source-list-guid-matching). Thus, in the",
                "    // case of a full wildcard, data:, blob:, and filesystem: URLs are",
                "    // explicitly checked for in the source list before allowing them through.",
                "    if (m_allowStar) {",
                "        if (url.protocolIs(\"blob\") || url.protocolIs(\"data\") || url.protocolIs(\"filesystem\"))",
                "            return hasSourceMatchInList(url, redirectStatus);",
                "    }",
                "    return hasSourceMatchInList(effectiveURL, redirectStatus);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1342",
        "func_name": "lxc/lxcfs/cg_getattr",
        "description": "LXCFS before 0.12 does not properly enforce directory escapes, which might allow local users to gain privileges by (1) querying or (2) updating a cgroup.",
        "git_url": "https://github.com/lxc/lxcfs/commit/a8b6c3e0537e90fba3c55910fd1b7229d54a60a7",
        "commit_title": "Fix checking of parent directories",
        "commit_text": " Taken from the justification in the launchpad bug:  To a task in freezer cgroup /a/b/c/d, it should appear that there are no cgroups other than its descendents. Since this is a filesystem, we must have the parent directories, but each parent cgroup should only contain the child which the task can see.  So, when this task looks at /a/b, it should see only directory 'c' and no files. Attempt to create /a/b/x should result in -EPERM, whether /a/b/x already exists or not. Attempts to query /a/b/x should result in -ENOENT whether /a/b/x exists or not. Opening /a/b/tasks should result in -ENOENT.  The caller_may_see_dir checks specifically whether a task may see a cgroup directory - i.e. /a/b/x if opening /a/b/x/tasks, and /a/b/c/d if doing opendir('/a/b/c/d').  caller_is_in_ancestor() will return true if the caller in /a/b/c/d looks at /a/b/c/d/e. If the caller is in a child cgroup of the queried one - i.e. if the task in /a/b/c/d queries /a/b, then *nextcg will container the next (the only) directory which he can see in the path - 'c'.  Beyond this, regular DAC permissions should apply, with the root-in-user-namespace privilege over its mapped uids being respected. The fc_may_access check does this check for both directories and files.  This is CVE-2015-1342 (LP: #1508481) ",
        "func_before": "static int cg_getattr(const char *path, struct stat *sb)\n{\n\tstruct timespec now;\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar * cgdir = NULL;\n\tchar *fpath = NULL, *path1, *path2;\n\tstruct cgfs_files *k = NULL;\n\tconst char *cgroup;\n\tconst char *controller = NULL;\n\tint ret = -ENOENT;\n\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tmemset(sb, 0, sizeof(struct stat));\n\n\tif (clock_gettime(CLOCK_REALTIME, &now) < 0)\n\t\treturn -EINVAL;\n\n\tsb->st_uid = sb->st_gid = 0;\n\tsb->st_atim = sb->st_mtim = sb->st_ctim = now;\n\tsb->st_size = 0;\n\n\tif (strcmp(path, \"/cgroup\") == 0) {\n\t\tsb->st_mode = S_IFDIR | 00755;\n\t\tsb->st_nlink = 2;\n\t\treturn 0;\n\t}\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EIO;\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup) {\n\t\t/* this is just /cgroup/controller, return it as a dir */\n\t\tsb->st_mode = S_IFDIR | 00755;\n\t\tsb->st_nlink = 2;\n\t\treturn 0;\n\t}\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\n\tif (!fpath) {\n\t\tpath1 = \"/\";\n\t\tpath2 = cgdir;\n\t} else {\n\t\tpath1 = cgdir;\n\t\tpath2 = fpath;\n\t}\n\n\t/* check that cgcopy is either a child cgroup of cgdir, or listed in its keys.\n\t * Then check that caller's cgroup is under path if fpath is a child\n\t * cgroup, or cgdir if fpath is a file */\n\n\tif (is_child_cgroup(controller, path1, path2)) {\n\t\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {\n\t\t\t/* this is just /cgroup/controller, return it as a dir */\n\t\t\tsb->st_mode = S_IFDIR | 00555;\n\t\t\tsb->st_nlink = 2;\n\t\t\tret = 0;\n\t\t\tgoto out;\n\t\t}\n\t\tif (!fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {\n\t\t\tret = -EACCES;\n\t\t\tgoto out;\n\t\t}\n\n\t\t// get uid, gid, from '/tasks' file and make up a mode\n\t\t// That is a hack, until cgmanager gains a GetCgroupPerms fn.\n\t\tsb->st_mode = S_IFDIR | 00755;\n\t\tk = cgfs_get_key(controller, cgroup, \"tasks\");\n\t\tif (!k) {\n\t\t\tsb->st_uid = sb->st_gid = 0;\n\t\t} else {\n\t\t\tsb->st_uid = k->uid;\n\t\t\tsb->st_gid = k->gid;\n\t\t}\n\t\tfree_key(k);\n\t\tsb->st_nlink = 2;\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tif ((k = cgfs_get_key(controller, path1, path2)) != NULL) {\n\t\tsb->st_mode = S_IFREG | k->mode;\n\t\tsb->st_nlink = 1;\n\t\tsb->st_uid = k->uid;\n\t\tsb->st_gid = k->gid;\n\t\tsb->st_size = 0;\n\t\tfree_key(k);\n\t\tif (!caller_is_in_ancestor(fc->pid, controller, path1, NULL)) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (!fc_may_access(fc, controller, path1, path2, O_RDONLY)) {\n\t\t\tret = -EACCES;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = 0;\n\t}\n\nout:\n\tfree(cgdir);\n\treturn ret;\n}",
        "func": "static int cg_getattr(const char *path, struct stat *sb)\n{\n\tstruct timespec now;\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar * cgdir = NULL;\n\tchar *fpath = NULL, *path1, *path2;\n\tstruct cgfs_files *k = NULL;\n\tconst char *cgroup;\n\tconst char *controller = NULL;\n\tint ret = -ENOENT;\n\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tmemset(sb, 0, sizeof(struct stat));\n\n\tif (clock_gettime(CLOCK_REALTIME, &now) < 0)\n\t\treturn -EINVAL;\n\n\tsb->st_uid = sb->st_gid = 0;\n\tsb->st_atim = sb->st_mtim = sb->st_ctim = now;\n\tsb->st_size = 0;\n\n\tif (strcmp(path, \"/cgroup\") == 0) {\n\t\tsb->st_mode = S_IFDIR | 00755;\n\t\tsb->st_nlink = 2;\n\t\treturn 0;\n\t}\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EIO;\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup) {\n\t\t/* this is just /cgroup/controller, return it as a dir */\n\t\tsb->st_mode = S_IFDIR | 00755;\n\t\tsb->st_nlink = 2;\n\t\treturn 0;\n\t}\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\n\tif (!fpath) {\n\t\tpath1 = \"/\";\n\t\tpath2 = cgdir;\n\t} else {\n\t\tpath1 = cgdir;\n\t\tpath2 = fpath;\n\t}\n\n\t/* check that cgcopy is either a child cgroup of cgdir, or listed in its keys.\n\t * Then check that caller's cgroup is under path if fpath is a child\n\t * cgroup, or cgdir if fpath is a file */\n\n\tif (is_child_cgroup(controller, path1, path2)) {\n\t\tif (!caller_may_see_dir(fc->pid, controller, cgroup)) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {\n\t\t\t/* this is just /cgroup/controller, return it as a dir */\n\t\t\tsb->st_mode = S_IFDIR | 00555;\n\t\t\tsb->st_nlink = 2;\n\t\t\tret = 0;\n\t\t\tgoto out;\n\t\t}\n\t\tif (!fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {\n\t\t\tret = -EACCES;\n\t\t\tgoto out;\n\t\t}\n\n\t\t// get uid, gid, from '/tasks' file and make up a mode\n\t\t// That is a hack, until cgmanager gains a GetCgroupPerms fn.\n\t\tsb->st_mode = S_IFDIR | 00755;\n\t\tk = cgfs_get_key(controller, cgroup, \"tasks\");\n\t\tif (!k) {\n\t\t\tsb->st_uid = sb->st_gid = 0;\n\t\t} else {\n\t\t\tsb->st_uid = k->uid;\n\t\t\tsb->st_gid = k->gid;\n\t\t}\n\t\tfree_key(k);\n\t\tsb->st_nlink = 2;\n\t\tret = 0;\n\t\tgoto out;\n\t}\n\n\tif ((k = cgfs_get_key(controller, path1, path2)) != NULL) {\n\t\tsb->st_mode = S_IFREG | k->mode;\n\t\tsb->st_nlink = 1;\n\t\tsb->st_uid = k->uid;\n\t\tsb->st_gid = k->gid;\n\t\tsb->st_size = 0;\n\t\tfree_key(k);\n\t\tif (!caller_is_in_ancestor(fc->pid, controller, path1, NULL)) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tif (!fc_may_access(fc, controller, path1, path2, O_RDONLY)) {\n\t\t\tret = -EACCES;\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = 0;\n\t}\n\nout:\n\tfree(cgdir);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -54,6 +54,10 @@\n \t * cgroup, or cgdir if fpath is a file */\n \n \tif (is_child_cgroup(controller, path1, path2)) {\n+\t\tif (!caller_may_see_dir(fc->pid, controller, cgroup)) {\n+\t\t\tret = -ENOENT;\n+\t\t\tgoto out;\n+\t\t}\n \t\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {\n \t\t\t/* this is just /cgroup/controller, return it as a dir */\n \t\t\tsb->st_mode = S_IFDIR | 00555;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tif (!caller_may_see_dir(fc->pid, controller, cgroup)) {",
                "\t\t\tret = -ENOENT;",
                "\t\t\tgoto out;",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1342",
        "func_name": "lxc/lxcfs/cg_open",
        "description": "LXCFS before 0.12 does not properly enforce directory escapes, which might allow local users to gain privileges by (1) querying or (2) updating a cgroup.",
        "git_url": "https://github.com/lxc/lxcfs/commit/a8b6c3e0537e90fba3c55910fd1b7229d54a60a7",
        "commit_title": "Fix checking of parent directories",
        "commit_text": " Taken from the justification in the launchpad bug:  To a task in freezer cgroup /a/b/c/d, it should appear that there are no cgroups other than its descendents. Since this is a filesystem, we must have the parent directories, but each parent cgroup should only contain the child which the task can see.  So, when this task looks at /a/b, it should see only directory 'c' and no files. Attempt to create /a/b/x should result in -EPERM, whether /a/b/x already exists or not. Attempts to query /a/b/x should result in -ENOENT whether /a/b/x exists or not. Opening /a/b/tasks should result in -ENOENT.  The caller_may_see_dir checks specifically whether a task may see a cgroup directory - i.e. /a/b/x if opening /a/b/x/tasks, and /a/b/c/d if doing opendir('/a/b/c/d').  caller_is_in_ancestor() will return true if the caller in /a/b/c/d looks at /a/b/c/d/e. If the caller is in a child cgroup of the queried one - i.e. if the task in /a/b/c/d queries /a/b, then *nextcg will container the next (the only) directory which he can see in the path - 'c'.  Beyond this, regular DAC permissions should apply, with the root-in-user-namespace privilege over its mapped uids being respected. The fc_may_access check does this check for both directories and files.  This is CVE-2015-1342 (LP: #1508481) ",
        "func_before": "static int cg_open(const char *path, struct fuse_file_info *fi)\n{\n\tconst char *cgroup;\n\tchar *fpath = NULL, *path1, *path2, * cgdir = NULL, *controller;\n\tstruct cgfs_files *k = NULL;\n\tstruct file_info *file_info;\n\tstruct fuse_context *fc = fuse_get_context();\n\tint ret;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EIO;\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup)\n\t\treturn -EINVAL;\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\tif (!fpath) {\n\t\tpath1 = \"/\";\n\t\tpath2 = cgdir;\n\t} else {\n\t\tpath1 = cgdir;\n\t\tpath2 = fpath;\n\t}\n\n\tk = cgfs_get_key(controller, path1, path2);\n\tif (!k) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tfree_key(k);\n\n\tif (!fc_may_access(fc, controller, path1, path2, fi->flags)) {\n\t\t// should never get here\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\n\t/* we'll free this at cg_release */\n\tfile_info = malloc(sizeof(*file_info));\n\tif (!file_info) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tfile_info->controller = must_copy_string(controller);\n\tfile_info->cgroup = must_copy_string(path1);\n\tfile_info->file = must_copy_string(path2);\n\tfile_info->type = LXC_TYPE_CGFILE;\n\tfile_info->buf = NULL;\n\tfile_info->buflen = 0;\n\n\tfi->fh = (unsigned long)file_info;\n\tret = 0;\n\nout:\n\tfree(cgdir);\n\treturn ret;\n}",
        "func": "static int cg_open(const char *path, struct fuse_file_info *fi)\n{\n\tconst char *cgroup;\n\tchar *fpath = NULL, *path1, *path2, * cgdir = NULL, *controller;\n\tstruct cgfs_files *k = NULL;\n\tstruct file_info *file_info;\n\tstruct fuse_context *fc = fuse_get_context();\n\tint ret;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EIO;\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup)\n\t\treturn -EINVAL;\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\tif (!fpath) {\n\t\tpath1 = \"/\";\n\t\tpath2 = cgdir;\n\t} else {\n\t\tpath1 = cgdir;\n\t\tpath2 = fpath;\n\t}\n\n\tk = cgfs_get_key(controller, path1, path2);\n\tif (!k) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\tfree_key(k);\n\n\tif (!caller_may_see_dir(fc->pid, controller, path1)) {\n\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\tif (!fc_may_access(fc, controller, path1, path2, fi->flags)) {\n\t\t// should never get here\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\n\t/* we'll free this at cg_release */\n\tfile_info = malloc(sizeof(*file_info));\n\tif (!file_info) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tfile_info->controller = must_copy_string(controller);\n\tfile_info->cgroup = must_copy_string(path1);\n\tfile_info->file = must_copy_string(path2);\n\tfile_info->type = LXC_TYPE_CGFILE;\n\tfile_info->buf = NULL;\n\tfile_info->buflen = 0;\n\n\tfi->fh = (unsigned long)file_info;\n\tret = 0;\n\nout:\n\tfree(cgdir);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,6 +33,10 @@\n \t}\n \tfree_key(k);\n \n+\tif (!caller_may_see_dir(fc->pid, controller, path1)) {\n+\t\tret = -ENOENT;\n+\t\tgoto out;\n+\t}\n \tif (!fc_may_access(fc, controller, path1, path2, fi->flags)) {\n \t\t// should never get here\n \t\tret = -EACCES;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!caller_may_see_dir(fc->pid, controller, path1)) {",
                "\t\tret = -ENOENT;",
                "\t\tgoto out;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1342",
        "func_name": "lxc/lxcfs/cg_rmdir",
        "description": "LXCFS before 0.12 does not properly enforce directory escapes, which might allow local users to gain privileges by (1) querying or (2) updating a cgroup.",
        "git_url": "https://github.com/lxc/lxcfs/commit/a8b6c3e0537e90fba3c55910fd1b7229d54a60a7",
        "commit_title": "Fix checking of parent directories",
        "commit_text": " Taken from the justification in the launchpad bug:  To a task in freezer cgroup /a/b/c/d, it should appear that there are no cgroups other than its descendents. Since this is a filesystem, we must have the parent directories, but each parent cgroup should only contain the child which the task can see.  So, when this task looks at /a/b, it should see only directory 'c' and no files. Attempt to create /a/b/x should result in -EPERM, whether /a/b/x already exists or not. Attempts to query /a/b/x should result in -ENOENT whether /a/b/x exists or not. Opening /a/b/tasks should result in -ENOENT.  The caller_may_see_dir checks specifically whether a task may see a cgroup directory - i.e. /a/b/x if opening /a/b/x/tasks, and /a/b/c/d if doing opendir('/a/b/c/d').  caller_is_in_ancestor() will return true if the caller in /a/b/c/d looks at /a/b/c/d/e. If the caller is in a child cgroup of the queried one - i.e. if the task in /a/b/c/d queries /a/b, then *nextcg will container the next (the only) directory which he can see in the path - 'c'.  Beyond this, regular DAC permissions should apply, with the root-in-user-namespace privilege over its mapped uids being respected. The fc_may_access check does this check for both directories and files.  This is CVE-2015-1342 (LP: #1508481) ",
        "func_before": "static int cg_rmdir(const char *path)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar *fpath = NULL, *cgdir = NULL, *controller;\n\tconst char *cgroup;\n\tint ret;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EINVAL;\n\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup)\n\t\treturn -EINVAL;\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\tif (!fpath) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tfprintf(stderr, \"rmdir: verifying access to %s:%s (req path %s)\\n\",\n\t\t\tcontroller, cgdir, path);\n\tif (!fc_may_access(fc, controller, cgdir, NULL, O_WRONLY)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (!cgfs_remove(controller, cgroup)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tret = 0;\n\nout:\n\tfree(cgdir);\n\treturn ret;\n}",
        "func": "static int cg_rmdir(const char *path)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar *fpath = NULL, *cgdir = NULL, *controller, *next = NULL;\n\tconst char *cgroup;\n\tint ret;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EINVAL;\n\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup)\n\t\treturn -EINVAL;\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\tif (!fpath) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, &next)) {\n\t\tif (!fpath || strcmp(next, fpath) == 0)\n\t\t\tret = -EBUSY;\n\t\telse\n\t\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (!fc_may_access(fc, controller, cgdir, NULL, O_WRONLY)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, NULL)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (!cgfs_remove(controller, cgroup)) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tret = 0;\n\nout:\n\tfree(cgdir);\n\tfree(next);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static int cg_rmdir(const char *path)\n {\n \tstruct fuse_context *fc = fuse_get_context();\n-\tchar *fpath = NULL, *cgdir = NULL, *controller;\n+\tchar *fpath = NULL, *cgdir = NULL, *controller, *next = NULL;\n \tconst char *cgroup;\n \tint ret;\n \n@@ -22,8 +22,14 @@\n \t\tgoto out;\n \t}\n \n-\tfprintf(stderr, \"rmdir: verifying access to %s:%s (req path %s)\\n\",\n-\t\t\tcontroller, cgdir, path);\n+\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, &next)) {\n+\t\tif (!fpath || strcmp(next, fpath) == 0)\n+\t\t\tret = -EBUSY;\n+\t\telse\n+\t\t\tret = -ENOENT;\n+\t\tgoto out;\n+\t}\n+\n \tif (!fc_may_access(fc, controller, cgdir, NULL, O_WRONLY)) {\n \t\tret = -EACCES;\n \t\tgoto out;\n@@ -42,5 +48,6 @@\n \n out:\n \tfree(cgdir);\n+\tfree(next);\n \treturn ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tchar *fpath = NULL, *cgdir = NULL, *controller;",
                "\tfprintf(stderr, \"rmdir: verifying access to %s:%s (req path %s)\\n\",",
                "\t\t\tcontroller, cgdir, path);"
            ],
            "added_lines": [
                "\tchar *fpath = NULL, *cgdir = NULL, *controller, *next = NULL;",
                "\tif (!caller_is_in_ancestor(fc->pid, controller, cgroup, &next)) {",
                "\t\tif (!fpath || strcmp(next, fpath) == 0)",
                "\t\t\tret = -EBUSY;",
                "\t\telse",
                "\t\t\tret = -ENOENT;",
                "\t\tgoto out;",
                "\t}",
                "",
                "\tfree(next);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1342",
        "func_name": "lxc/lxcfs/cg_mkdir",
        "description": "LXCFS before 0.12 does not properly enforce directory escapes, which might allow local users to gain privileges by (1) querying or (2) updating a cgroup.",
        "git_url": "https://github.com/lxc/lxcfs/commit/a8b6c3e0537e90fba3c55910fd1b7229d54a60a7",
        "commit_title": "Fix checking of parent directories",
        "commit_text": " Taken from the justification in the launchpad bug:  To a task in freezer cgroup /a/b/c/d, it should appear that there are no cgroups other than its descendents. Since this is a filesystem, we must have the parent directories, but each parent cgroup should only contain the child which the task can see.  So, when this task looks at /a/b, it should see only directory 'c' and no files. Attempt to create /a/b/x should result in -EPERM, whether /a/b/x already exists or not. Attempts to query /a/b/x should result in -ENOENT whether /a/b/x exists or not. Opening /a/b/tasks should result in -ENOENT.  The caller_may_see_dir checks specifically whether a task may see a cgroup directory - i.e. /a/b/x if opening /a/b/x/tasks, and /a/b/c/d if doing opendir('/a/b/c/d').  caller_is_in_ancestor() will return true if the caller in /a/b/c/d looks at /a/b/c/d/e. If the caller is in a child cgroup of the queried one - i.e. if the task in /a/b/c/d queries /a/b, then *nextcg will container the next (the only) directory which he can see in the path - 'c'.  Beyond this, regular DAC permissions should apply, with the root-in-user-namespace privilege over its mapped uids being respected. The fc_may_access check does this check for both directories and files.  This is CVE-2015-1342 (LP: #1508481) ",
        "func_before": "int cg_mkdir(const char *path, mode_t mode)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar *fpath = NULL, *path1, *cgdir = NULL, *controller;\n\tconst char *cgroup;\n\tint ret;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EINVAL;\n\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup)\n\t\treturn -EINVAL;\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\tif (!fpath)\n\t\tpath1 = \"/\";\n\telse\n\t\tpath1 = cgdir;\n\n\tif (!fc_may_access(fc, controller, path1, NULL, O_RDWR)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\tif (!caller_is_in_ancestor(fc->pid, controller, path1, NULL)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\n\tret = cgfs_create(controller, cgroup, fc->uid, fc->gid);\n\tprintf(\"cgfs_create returned %d for %s %s\\n\", ret, controller, cgroup);\n\nout:\n\tfree(cgdir);\n\treturn ret;\n}",
        "func": "int cg_mkdir(const char *path, mode_t mode)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar *fpath = NULL, *path1, *cgdir = NULL, *controller, *next = NULL;\n\tconst char *cgroup;\n\tint ret;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\n\tcontroller = pick_controller_from_path(fc, path);\n\tif (!controller)\n\t\treturn -EINVAL;\n\n\tcgroup = find_cgroup_in_path(path);\n\tif (!cgroup)\n\t\treturn -EINVAL;\n\n\tget_cgdir_and_path(cgroup, &cgdir, &fpath);\n\tif (!fpath)\n\t\tpath1 = \"/\";\n\telse\n\t\tpath1 = cgdir;\n\n\tif (!caller_is_in_ancestor(fc->pid, controller, path1, &next)) {\n\t\tif (fpath && strcmp(next, fpath) == 0)\n\t\t\tret = -EEXIST;\n\t\telse\n\t\t\tret = -ENOENT;\n\t\tgoto out;\n\t}\n\n\tif (!fc_may_access(fc, controller, path1, NULL, O_RDWR)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\tif (!caller_is_in_ancestor(fc->pid, controller, path1, NULL)) {\n\t\tret = -EACCES;\n\t\tgoto out;\n\t}\n\n\tret = cgfs_create(controller, cgroup, fc->uid, fc->gid);\n\tprintf(\"cgfs_create returned %d for %s %s\\n\", ret, controller, cgroup);\n\nout:\n\tfree(cgdir);\n\tfree(next);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n int cg_mkdir(const char *path, mode_t mode)\n {\n \tstruct fuse_context *fc = fuse_get_context();\n-\tchar *fpath = NULL, *path1, *cgdir = NULL, *controller;\n+\tchar *fpath = NULL, *path1, *cgdir = NULL, *controller, *next = NULL;\n \tconst char *cgroup;\n \tint ret;\n \n@@ -23,6 +23,14 @@\n \telse\n \t\tpath1 = cgdir;\n \n+\tif (!caller_is_in_ancestor(fc->pid, controller, path1, &next)) {\n+\t\tif (fpath && strcmp(next, fpath) == 0)\n+\t\t\tret = -EEXIST;\n+\t\telse\n+\t\t\tret = -ENOENT;\n+\t\tgoto out;\n+\t}\n+\n \tif (!fc_may_access(fc, controller, path1, NULL, O_RDWR)) {\n \t\tret = -EACCES;\n \t\tgoto out;\n@@ -37,5 +45,6 @@\n \n out:\n \tfree(cgdir);\n+\tfree(next);\n \treturn ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tchar *fpath = NULL, *path1, *cgdir = NULL, *controller;"
            ],
            "added_lines": [
                "\tchar *fpath = NULL, *path1, *cgdir = NULL, *controller, *next = NULL;",
                "\tif (!caller_is_in_ancestor(fc->pid, controller, path1, &next)) {",
                "\t\tif (fpath && strcmp(next, fpath) == 0)",
                "\t\t\tret = -EEXIST;",
                "\t\telse",
                "\t\t\tret = -ENOENT;",
                "\t\tgoto out;",
                "\t}",
                "",
                "\tfree(next);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1342",
        "func_name": "lxc/lxcfs/cg_opendir",
        "description": "LXCFS before 0.12 does not properly enforce directory escapes, which might allow local users to gain privileges by (1) querying or (2) updating a cgroup.",
        "git_url": "https://github.com/lxc/lxcfs/commit/a8b6c3e0537e90fba3c55910fd1b7229d54a60a7",
        "commit_title": "Fix checking of parent directories",
        "commit_text": " Taken from the justification in the launchpad bug:  To a task in freezer cgroup /a/b/c/d, it should appear that there are no cgroups other than its descendents. Since this is a filesystem, we must have the parent directories, but each parent cgroup should only contain the child which the task can see.  So, when this task looks at /a/b, it should see only directory 'c' and no files. Attempt to create /a/b/x should result in -EPERM, whether /a/b/x already exists or not. Attempts to query /a/b/x should result in -ENOENT whether /a/b/x exists or not. Opening /a/b/tasks should result in -ENOENT.  The caller_may_see_dir checks specifically whether a task may see a cgroup directory - i.e. /a/b/x if opening /a/b/x/tasks, and /a/b/c/d if doing opendir('/a/b/c/d').  caller_is_in_ancestor() will return true if the caller in /a/b/c/d looks at /a/b/c/d/e. If the caller is in a child cgroup of the queried one - i.e. if the task in /a/b/c/d queries /a/b, then *nextcg will container the next (the only) directory which he can see in the path - 'c'.  Beyond this, regular DAC permissions should apply, with the root-in-user-namespace privilege over its mapped uids being respected. The fc_may_access check does this check for both directories and files.  This is CVE-2015-1342 (LP: #1508481) ",
        "func_before": "static int cg_opendir(const char *path, struct fuse_file_info *fi)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tconst char *cgroup;\n\tstruct file_info *dir_info;\n\tchar *controller = NULL;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tif (strcmp(path, \"/cgroup\") == 0) {\n\t\tcgroup = NULL;\n\t\tcontroller = NULL;\n\t} else {\n\t\t// return list of keys for the controller, and list of child cgroups\n\t\tcontroller = pick_controller_from_path(fc, path);\n\t\tif (!controller)\n\t\t\treturn -EIO;\n\n\t\tcgroup = find_cgroup_in_path(path);\n\t\tif (!cgroup) {\n\t\t\t/* this is just /cgroup/controller, return its contents */\n\t\t\tcgroup = \"/\";\n\t\t}\n\t}\n\n\tif (cgroup && !fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {\n\t\treturn -EACCES;\n\t}\n\n\t/* we'll free this at cg_releasedir */\n\tdir_info = malloc(sizeof(*dir_info));\n\tif (!dir_info)\n\t\treturn -ENOMEM;\n\tdir_info->controller = must_copy_string(controller);\n\tdir_info->cgroup = must_copy_string(cgroup);\n\tdir_info->type = LXC_TYPE_CGDIR;\n\tdir_info->buf = NULL;\n\tdir_info->file = NULL;\n\tdir_info->buflen = 0;\n\n\tfi->fh = (unsigned long)dir_info;\n\treturn 0;\n}",
        "func": "static int cg_opendir(const char *path, struct fuse_file_info *fi)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tconst char *cgroup;\n\tstruct file_info *dir_info;\n\tchar *controller = NULL;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tif (strcmp(path, \"/cgroup\") == 0) {\n\t\tcgroup = NULL;\n\t\tcontroller = NULL;\n\t} else {\n\t\t// return list of keys for the controller, and list of child cgroups\n\t\tcontroller = pick_controller_from_path(fc, path);\n\t\tif (!controller)\n\t\t\treturn -EIO;\n\n\t\tcgroup = find_cgroup_in_path(path);\n\t\tif (!cgroup) {\n\t\t\t/* this is just /cgroup/controller, return its contents */\n\t\t\tcgroup = \"/\";\n\t\t}\n\t}\n\n\tif (cgroup) {\n\t\tif (!caller_may_see_dir(fc->pid, controller, cgroup))\n\t\t\treturn -ENOENT;\n\t\tif (!fc_may_access(fc, controller, cgroup, NULL, O_RDONLY))\n\t\t\treturn -EACCES;\n\t}\n\n\t/* we'll free this at cg_releasedir */\n\tdir_info = malloc(sizeof(*dir_info));\n\tif (!dir_info)\n\t\treturn -ENOMEM;\n\tdir_info->controller = must_copy_string(controller);\n\tdir_info->cgroup = must_copy_string(cgroup);\n\tdir_info->type = LXC_TYPE_CGDIR;\n\tdir_info->buf = NULL;\n\tdir_info->file = NULL;\n\tdir_info->buflen = 0;\n\n\tfi->fh = (unsigned long)dir_info;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -24,8 +24,11 @@\n \t\t}\n \t}\n \n-\tif (cgroup && !fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {\n-\t\treturn -EACCES;\n+\tif (cgroup) {\n+\t\tif (!caller_may_see_dir(fc->pid, controller, cgroup))\n+\t\t\treturn -ENOENT;\n+\t\tif (!fc_may_access(fc, controller, cgroup, NULL, O_RDONLY))\n+\t\t\treturn -EACCES;\n \t}\n \n \t/* we'll free this at cg_releasedir */",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (cgroup && !fc_may_access(fc, controller, cgroup, NULL, O_RDONLY)) {",
                "\t\treturn -EACCES;"
            ],
            "added_lines": [
                "\tif (cgroup) {",
                "\t\tif (!caller_may_see_dir(fc->pid, controller, cgroup))",
                "\t\t\treturn -ENOENT;",
                "\t\tif (!fc_may_access(fc, controller, cgroup, NULL, O_RDONLY))",
                "\t\t\treturn -EACCES;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1342",
        "func_name": "lxc/lxcfs/caller_is_in_ancestor",
        "description": "LXCFS before 0.12 does not properly enforce directory escapes, which might allow local users to gain privileges by (1) querying or (2) updating a cgroup.",
        "git_url": "https://github.com/lxc/lxcfs/commit/a8b6c3e0537e90fba3c55910fd1b7229d54a60a7",
        "commit_title": "Fix checking of parent directories",
        "commit_text": " Taken from the justification in the launchpad bug:  To a task in freezer cgroup /a/b/c/d, it should appear that there are no cgroups other than its descendents. Since this is a filesystem, we must have the parent directories, but each parent cgroup should only contain the child which the task can see.  So, when this task looks at /a/b, it should see only directory 'c' and no files. Attempt to create /a/b/x should result in -EPERM, whether /a/b/x already exists or not. Attempts to query /a/b/x should result in -ENOENT whether /a/b/x exists or not. Opening /a/b/tasks should result in -ENOENT.  The caller_may_see_dir checks specifically whether a task may see a cgroup directory - i.e. /a/b/x if opening /a/b/x/tasks, and /a/b/c/d if doing opendir('/a/b/c/d').  caller_is_in_ancestor() will return true if the caller in /a/b/c/d looks at /a/b/c/d/e. If the caller is in a child cgroup of the queried one - i.e. if the task in /a/b/c/d queries /a/b, then *nextcg will container the next (the only) directory which he can see in the path - 'c'.  Beyond this, regular DAC permissions should apply, with the root-in-user-namespace privilege over its mapped uids being respected. The fc_may_access check does this check for both directories and files.  This is CVE-2015-1342 (LP: #1508481) ",
        "func_before": "static bool caller_is_in_ancestor(pid_t pid, const char *contrl, const char *cg, char **nextcg)\n{\n\tchar fnam[PROCLEN];\n\tFILE *f;\n\tbool answer = false;\n\tchar *line = NULL;\n\tsize_t len = 0;\n\tint ret;\n\n\tret = snprintf(fnam, PROCLEN, \"/proc/%d/cgroup\", pid);\n\tif (ret < 0 || ret >= PROCLEN)\n\t\treturn false;\n\tif (!(f = fopen(fnam, \"r\")))\n\t\treturn false;\n\n\twhile (getline(&line, &len, f) != -1) {\n\t\tchar *c1, *c2, *linecmp;\n\t\tif (!line[0])\n\t\t\tcontinue;\n\t\tc1 = strchr(line, ':');\n\t\tif (!c1)\n\t\t\tgoto out;\n\t\tc1++;\n\t\tc2 = strchr(c1, ':');\n\t\tif (!c2)\n\t\t\tgoto out;\n\t\t*c2 = '\\0';\n\t\tif (strcmp(c1, contrl) != 0)\n\t\t\tcontinue;\n\t\tc2++;\n\t\tstripnewline(c2);\n\t\tprune_init_slice(c2);\n\t\t/*\n\t\t * callers pass in '/' for root cgroup, otherwise they pass\n\t\t * in a cgroup without leading '/'\n\t\t */\n\t\tlinecmp = *cg == '/' ? c2 : c2+1;\n\t\tif (strncmp(linecmp, cg, strlen(linecmp)) != 0) {\n\t\t\tif (nextcg)\n\t\t\t\t*nextcg = get_next_cgroup_dir(linecmp, cg);\n\t\t\tgoto out;\n\t\t}\n\t\tanswer = true;\n\t\tgoto out;\n\t}\n\nout:\n\tfclose(f);\n\tfree(line);\n\treturn answer;\n}",
        "func": "static bool caller_is_in_ancestor(pid_t pid, const char *contrl, const char *cg, char **nextcg)\n{\n\tbool answer = false;\n\tchar *c2 = get_pid_cgroup(pid, contrl);\n\tchar *linecmp;\n\n\tif (!c2)\n\t\treturn false;\n\tprune_init_slice(c2);\n\n\t/*\n\t * callers pass in '/' for root cgroup, otherwise they pass\n\t * in a cgroup without leading '/'\n\t */\n\tlinecmp = *cg == '/' ? c2 : c2+1;\n\tif (strncmp(linecmp, cg, strlen(linecmp)) != 0) {\n\t\tif (nextcg) {\n\t\t\t*nextcg = get_next_cgroup_dir(linecmp, cg);\n\t\t}\n\t\tgoto out;\n\t}\n\tanswer = true;\n\nout:\n\tfree(c2);\n\treturn answer;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,51 +1,27 @@\n static bool caller_is_in_ancestor(pid_t pid, const char *contrl, const char *cg, char **nextcg)\n {\n-\tchar fnam[PROCLEN];\n-\tFILE *f;\n \tbool answer = false;\n-\tchar *line = NULL;\n-\tsize_t len = 0;\n-\tint ret;\n+\tchar *c2 = get_pid_cgroup(pid, contrl);\n+\tchar *linecmp;\n \n-\tret = snprintf(fnam, PROCLEN, \"/proc/%d/cgroup\", pid);\n-\tif (ret < 0 || ret >= PROCLEN)\n+\tif (!c2)\n \t\treturn false;\n-\tif (!(f = fopen(fnam, \"r\")))\n-\t\treturn false;\n+\tprune_init_slice(c2);\n \n-\twhile (getline(&line, &len, f) != -1) {\n-\t\tchar *c1, *c2, *linecmp;\n-\t\tif (!line[0])\n-\t\t\tcontinue;\n-\t\tc1 = strchr(line, ':');\n-\t\tif (!c1)\n-\t\t\tgoto out;\n-\t\tc1++;\n-\t\tc2 = strchr(c1, ':');\n-\t\tif (!c2)\n-\t\t\tgoto out;\n-\t\t*c2 = '\\0';\n-\t\tif (strcmp(c1, contrl) != 0)\n-\t\t\tcontinue;\n-\t\tc2++;\n-\t\tstripnewline(c2);\n-\t\tprune_init_slice(c2);\n-\t\t/*\n-\t\t * callers pass in '/' for root cgroup, otherwise they pass\n-\t\t * in a cgroup without leading '/'\n-\t\t */\n-\t\tlinecmp = *cg == '/' ? c2 : c2+1;\n-\t\tif (strncmp(linecmp, cg, strlen(linecmp)) != 0) {\n-\t\t\tif (nextcg)\n-\t\t\t\t*nextcg = get_next_cgroup_dir(linecmp, cg);\n-\t\t\tgoto out;\n+\t/*\n+\t * callers pass in '/' for root cgroup, otherwise they pass\n+\t * in a cgroup without leading '/'\n+\t */\n+\tlinecmp = *cg == '/' ? c2 : c2+1;\n+\tif (strncmp(linecmp, cg, strlen(linecmp)) != 0) {\n+\t\tif (nextcg) {\n+\t\t\t*nextcg = get_next_cgroup_dir(linecmp, cg);\n \t\t}\n-\t\tanswer = true;\n \t\tgoto out;\n \t}\n+\tanswer = true;\n \n out:\n-\tfclose(f);\n-\tfree(line);\n+\tfree(c2);\n \treturn answer;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tchar fnam[PROCLEN];",
                "\tFILE *f;",
                "\tchar *line = NULL;",
                "\tsize_t len = 0;",
                "\tint ret;",
                "\tret = snprintf(fnam, PROCLEN, \"/proc/%d/cgroup\", pid);",
                "\tif (ret < 0 || ret >= PROCLEN)",
                "\tif (!(f = fopen(fnam, \"r\")))",
                "\t\treturn false;",
                "\twhile (getline(&line, &len, f) != -1) {",
                "\t\tchar *c1, *c2, *linecmp;",
                "\t\tif (!line[0])",
                "\t\t\tcontinue;",
                "\t\tc1 = strchr(line, ':');",
                "\t\tif (!c1)",
                "\t\t\tgoto out;",
                "\t\tc1++;",
                "\t\tc2 = strchr(c1, ':');",
                "\t\tif (!c2)",
                "\t\t\tgoto out;",
                "\t\t*c2 = '\\0';",
                "\t\tif (strcmp(c1, contrl) != 0)",
                "\t\t\tcontinue;",
                "\t\tc2++;",
                "\t\tstripnewline(c2);",
                "\t\tprune_init_slice(c2);",
                "\t\t/*",
                "\t\t * callers pass in '/' for root cgroup, otherwise they pass",
                "\t\t * in a cgroup without leading '/'",
                "\t\t */",
                "\t\tlinecmp = *cg == '/' ? c2 : c2+1;",
                "\t\tif (strncmp(linecmp, cg, strlen(linecmp)) != 0) {",
                "\t\t\tif (nextcg)",
                "\t\t\t\t*nextcg = get_next_cgroup_dir(linecmp, cg);",
                "\t\t\tgoto out;",
                "\t\tanswer = true;",
                "\tfclose(f);",
                "\tfree(line);"
            ],
            "added_lines": [
                "\tchar *c2 = get_pid_cgroup(pid, contrl);",
                "\tchar *linecmp;",
                "\tif (!c2)",
                "\tprune_init_slice(c2);",
                "\t/*",
                "\t * callers pass in '/' for root cgroup, otherwise they pass",
                "\t * in a cgroup without leading '/'",
                "\t */",
                "\tlinecmp = *cg == '/' ? c2 : c2+1;",
                "\tif (strncmp(linecmp, cg, strlen(linecmp)) != 0) {",
                "\t\tif (nextcg) {",
                "\t\t\t*nextcg = get_next_cgroup_dir(linecmp, cg);",
                "\tanswer = true;",
                "\tfree(c2);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1344",
        "func_name": "lxc/lxcfs/do_write_pids",
        "description": "The do_write_pids function in lxcfs.c in LXCFS before 0.12 does not properly check permissions, which allows local users to gain privileges by writing a pid to the tasks file.",
        "git_url": "https://github.com/lxc/lxcfs/commit/8ee2a503e102b1a43ec4d83113dc275ab20a869a",
        "commit_title": "Implement privilege check when moving tasks",
        "commit_text": " When writing pids to a tasks file in lxcfs, lxcfs was checking for privilege over the tasks file but not over the pid being moved.  Since the cgm_movepid request is done as root on the host, not with the requestor's credentials, we must copy the check which cgmanager was doing to ensure that the requesting task is allowed to change the victim task's cgroup membership.  This is CVE-2015-1344 https://bugs.launchpad.net/ubuntu/+source/lxcfs/+bug/1512854 ",
        "func_before": "static bool do_write_pids(pid_t tpid, const char *contrl, const char *cg, const char *file, const char *buf)\n{\n\tint sock[2] = {-1, -1};\n\tpid_t qpid, cpid = -1;\n\tFILE *pids_file = NULL;\n\tbool answer = false, fail = false;\n\n\tpids_file = open_pids_file(contrl, cg);\n\tif (!pids_file)\n\t\treturn false;\n\n\t/*\n\t * write the pids to a socket, have helper in writer's pidns\n\t * call movepid for us\n\t */\n\tif (socketpair(AF_UNIX, SOCK_DGRAM, 0, sock) < 0) {\n\t\tperror(\"socketpair\");\n\t\tgoto out;\n\t}\n\n\tcpid = fork();\n\tif (cpid == -1)\n\t\tgoto out;\n\n\tif (!cpid) { // child\n\t\tfclose(pids_file);\n\t\tpid_from_ns_wrapper(sock[1], tpid);\n\t}\n\n\tconst char *ptr = buf;\n\twhile (sscanf(ptr, \"%d\", &qpid) == 1) {\n\t\tstruct ucred cred;\n\t\tchar v;\n\n\t\tif (write(sock[0], &qpid, sizeof(qpid)) != sizeof(qpid)) {\n\t\t\tfprintf(stderr, \"%s: error writing pid to child: %s\\n\",\n\t\t\t\t__func__, strerror(errno));\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (recv_creds(sock[0], &cred, &v)) {\n\t\t\tif (v == '0') {\n\t\t\t\tif (fprintf(pids_file, \"%d\", (int) cred.pid) < 0)\n\t\t\t\t\tfail = true;\n\t\t\t}\n\t\t}\n\n\t\tptr = strchr(ptr, '\\n');\n\t\tif (!ptr)\n\t\t\tbreak;\n\t\tptr++;\n\t}\n\n\t/* All good, write the value */\n\tqpid = -1;\n\tif (write(sock[0], &qpid ,sizeof(qpid)) != sizeof(qpid))\n\t\tfprintf(stderr, \"Warning: failed to ask child to exit\\n\");\n\n\tif (!fail)\n\t\tanswer = true;\n\nout:\n\tif (cpid != -1)\n\t\twait_for_pid(cpid);\n\tif (sock[0] != -1) {\n\t\tclose(sock[0]);\n\t\tclose(sock[1]);\n\t}\n\tif (pids_file) {\n\t\tif (fclose(pids_file) != 0)\n\t\t\tanswer = false;\n\t}\n\treturn answer;\n}",
        "func": "static bool do_write_pids(pid_t tpid, uid_t tuid, const char *contrl, const char *cg,\n\t\tconst char *file, const char *buf)\n{\n\tint sock[2] = {-1, -1};\n\tpid_t qpid, cpid = -1;\n\tFILE *pids_file = NULL;\n\tbool answer = false, fail = false;\n\n\tpids_file = open_pids_file(contrl, cg);\n\tif (!pids_file)\n\t\treturn false;\n\n\t/*\n\t * write the pids to a socket, have helper in writer's pidns\n\t * call movepid for us\n\t */\n\tif (socketpair(AF_UNIX, SOCK_DGRAM, 0, sock) < 0) {\n\t\tperror(\"socketpair\");\n\t\tgoto out;\n\t}\n\n\tcpid = fork();\n\tif (cpid == -1)\n\t\tgoto out;\n\n\tif (!cpid) { // child\n\t\tfclose(pids_file);\n\t\tpid_from_ns_wrapper(sock[1], tpid);\n\t}\n\n\tconst char *ptr = buf;\n\twhile (sscanf(ptr, \"%d\", &qpid) == 1) {\n\t\tstruct ucred cred;\n\t\tchar v;\n\n\t\tif (write(sock[0], &qpid, sizeof(qpid)) != sizeof(qpid)) {\n\t\t\tfprintf(stderr, \"%s: error writing pid to child: %s\\n\",\n\t\t\t\t__func__, strerror(errno));\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (recv_creds(sock[0], &cred, &v)) {\n\t\t\tif (v == '0') {\n\t\t\t\tif (!may_move_pid(tpid, tuid, cred.pid)) {\n\t\t\t\t\tfail = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (fprintf(pids_file, \"%d\", (int) cred.pid) < 0)\n\t\t\t\t\tfail = true;\n\t\t\t}\n\t\t}\n\n\t\tptr = strchr(ptr, '\\n');\n\t\tif (!ptr)\n\t\t\tbreak;\n\t\tptr++;\n\t}\n\n\t/* All good, write the value */\n\tqpid = -1;\n\tif (write(sock[0], &qpid ,sizeof(qpid)) != sizeof(qpid))\n\t\tfprintf(stderr, \"Warning: failed to ask child to exit\\n\");\n\n\tif (!fail)\n\t\tanswer = true;\n\nout:\n\tif (cpid != -1)\n\t\twait_for_pid(cpid);\n\tif (sock[0] != -1) {\n\t\tclose(sock[0]);\n\t\tclose(sock[1]);\n\t}\n\tif (pids_file) {\n\t\tif (fclose(pids_file) != 0)\n\t\t\tanswer = false;\n\t}\n\treturn answer;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-static bool do_write_pids(pid_t tpid, const char *contrl, const char *cg, const char *file, const char *buf)\n+static bool do_write_pids(pid_t tpid, uid_t tuid, const char *contrl, const char *cg,\n+\t\tconst char *file, const char *buf)\n {\n \tint sock[2] = {-1, -1};\n \tpid_t qpid, cpid = -1;\n@@ -40,6 +41,10 @@\n \n \t\tif (recv_creds(sock[0], &cred, &v)) {\n \t\t\tif (v == '0') {\n+\t\t\t\tif (!may_move_pid(tpid, tuid, cred.pid)) {\n+\t\t\t\t\tfail = true;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n \t\t\t\tif (fprintf(pids_file, \"%d\", (int) cred.pid) < 0)\n \t\t\t\t\tfail = true;\n \t\t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "static bool do_write_pids(pid_t tpid, const char *contrl, const char *cg, const char *file, const char *buf)"
            ],
            "added_lines": [
                "static bool do_write_pids(pid_t tpid, uid_t tuid, const char *contrl, const char *cg,",
                "\t\tconst char *file, const char *buf)",
                "\t\t\t\tif (!may_move_pid(tpid, tuid, cred.pid)) {",
                "\t\t\t\t\tfail = true;",
                "\t\t\t\t\tbreak;",
                "\t\t\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1344",
        "func_name": "lxc/lxcfs/cg_write",
        "description": "The do_write_pids function in lxcfs.c in LXCFS before 0.12 does not properly check permissions, which allows local users to gain privileges by writing a pid to the tasks file.",
        "git_url": "https://github.com/lxc/lxcfs/commit/8ee2a503e102b1a43ec4d83113dc275ab20a869a",
        "commit_title": "Implement privilege check when moving tasks",
        "commit_text": " When writing pids to a tasks file in lxcfs, lxcfs was checking for privilege over the tasks file but not over the pid being moved.  Since the cgm_movepid request is done as root on the host, not with the requestor's credentials, we must copy the check which cgmanager was doing to ensure that the requesting task is allowed to change the victim task's cgroup membership.  This is CVE-2015-1344 https://bugs.launchpad.net/ubuntu/+source/lxcfs/+bug/1512854 ",
        "func_before": "int cg_write(const char *path, const char *buf, size_t size, off_t offset,\n\t     struct fuse_file_info *fi)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar *localbuf = NULL;\n\tstruct cgfs_files *k = NULL;\n\tstruct file_info *f = (struct file_info *)fi->fh;\n\tbool r;\n\n\tif (f->type != LXC_TYPE_CGFILE) {\n\t\tfprintf(stderr, \"Internal error: directory cache info used in cg_write\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (offset)\n\t\treturn 0;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tlocalbuf = alloca(size+1);\n\tlocalbuf[size] = '\\0';\n\tmemcpy(localbuf, buf, size);\n\n\tif ((k = cgfs_get_key(f->controller, f->cgroup, f->file)) == NULL) {\n\t\tsize = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!fc_may_access(fc, f->controller, f->cgroup, f->file, O_WRONLY)) {\n\t\tsize = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (strcmp(f->file, \"tasks\") == 0 ||\n\t\t\tstrcmp(f->file, \"/tasks\") == 0 ||\n\t\t\tstrcmp(f->file, \"/cgroup.procs\") == 0 ||\n\t\t\tstrcmp(f->file, \"cgroup.procs\") == 0)\n\t\t// special case - we have to translate the pids\n\t\tr = do_write_pids(fc->pid, f->controller, f->cgroup, f->file, localbuf);\n\telse\n\t\tr = cgfs_set_value(f->controller, f->cgroup, f->file, localbuf);\n\n\tif (!r)\n\t\tsize = -EINVAL;\n\nout:\n\tfree_key(k);\n\treturn size;\n}",
        "func": "int cg_write(const char *path, const char *buf, size_t size, off_t offset,\n\t     struct fuse_file_info *fi)\n{\n\tstruct fuse_context *fc = fuse_get_context();\n\tchar *localbuf = NULL;\n\tstruct cgfs_files *k = NULL;\n\tstruct file_info *f = (struct file_info *)fi->fh;\n\tbool r;\n\n\tif (f->type != LXC_TYPE_CGFILE) {\n\t\tfprintf(stderr, \"Internal error: directory cache info used in cg_write\\n\");\n\t\treturn -EIO;\n\t}\n\n\tif (offset)\n\t\treturn 0;\n\n\tif (!fc)\n\t\treturn -EIO;\n\n\tlocalbuf = alloca(size+1);\n\tlocalbuf[size] = '\\0';\n\tmemcpy(localbuf, buf, size);\n\n\tif ((k = cgfs_get_key(f->controller, f->cgroup, f->file)) == NULL) {\n\t\tsize = -EINVAL;\n\t\tgoto out;\n\t}\n\n\tif (!fc_may_access(fc, f->controller, f->cgroup, f->file, O_WRONLY)) {\n\t\tsize = -EACCES;\n\t\tgoto out;\n\t}\n\n\tif (strcmp(f->file, \"tasks\") == 0 ||\n\t\t\tstrcmp(f->file, \"/tasks\") == 0 ||\n\t\t\tstrcmp(f->file, \"/cgroup.procs\") == 0 ||\n\t\t\tstrcmp(f->file, \"cgroup.procs\") == 0)\n\t\t// special case - we have to translate the pids\n\t\tr = do_write_pids(fc->pid, fc->uid, f->controller, f->cgroup, f->file, localbuf);\n\telse\n\t\tr = cgfs_set_value(f->controller, f->cgroup, f->file, localbuf);\n\n\tif (!r)\n\t\tsize = -EINVAL;\n\nout:\n\tfree_key(k);\n\treturn size;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -37,7 +37,7 @@\n \t\t\tstrcmp(f->file, \"/cgroup.procs\") == 0 ||\n \t\t\tstrcmp(f->file, \"cgroup.procs\") == 0)\n \t\t// special case - we have to translate the pids\n-\t\tr = do_write_pids(fc->pid, f->controller, f->cgroup, f->file, localbuf);\n+\t\tr = do_write_pids(fc->pid, fc->uid, f->controller, f->cgroup, f->file, localbuf);\n \telse\n \t\tr = cgfs_set_value(f->controller, f->cgroup, f->file, localbuf);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tr = do_write_pids(fc->pid, f->controller, f->cgroup, f->file, localbuf);"
            ],
            "added_lines": [
                "\t\tr = do_write_pids(fc->pid, fc->uid, f->controller, f->cgroup, f->file, localbuf);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8660",
        "func_name": "torvalds/linux/ovl_setattr",
        "description": "The ovl_setattr function in fs/overlayfs/inode.c in the Linux kernel through 4.3.3 attempts to merge distinct setattr operations, which allows local users to bypass intended access restrictions and modify the attributes of arbitrary overlay files via a crafted application.",
        "git_url": "https://github.com/torvalds/linux/commit/acff81ec2c79492b180fade3c2894425cd35a545",
        "commit_title": "ovl: fix permission checking for setattr",
        "commit_text": " [Al Viro] The bug is in being too enthusiastic about optimizing ->setattr() away - instead of \"copy verbatim with metadata\" + \"chmod/chown/utimes\" (with the former being always safe and the latter failing in case of insufficient permissions) it tries to combine these two.  Note that copyup itself will have to do ->setattr() anyway; _that_ is where the elevated capabilities are right.  Having these two ->setattr() (one to set verbatim copy of metadata, another to do what overlayfs ->setattr() had been asked to do in the first place) combined is where it breaks.  Cc: <stable@vger.kernel.org>",
        "func_before": "int ovl_setattr(struct dentry *dentry, struct iattr *attr)\n{\n\tint err;\n\tstruct dentry *upperdentry;\n\n\terr = ovl_want_write(dentry);\n\tif (err)\n\t\tgoto out;\n\n\tupperdentry = ovl_dentry_upper(dentry);\n\tif (upperdentry) {\n\t\tmutex_lock(&upperdentry->d_inode->i_mutex);\n\t\terr = notify_change(upperdentry, attr, NULL);\n\t\tmutex_unlock(&upperdentry->d_inode->i_mutex);\n\t} else {\n\t\terr = ovl_copy_up_last(dentry, attr, false);\n\t}\n\tovl_drop_write(dentry);\nout:\n\treturn err;\n}",
        "func": "int ovl_setattr(struct dentry *dentry, struct iattr *attr)\n{\n\tint err;\n\tstruct dentry *upperdentry;\n\n\terr = ovl_want_write(dentry);\n\tif (err)\n\t\tgoto out;\n\n\terr = ovl_copy_up(dentry);\n\tif (!err) {\n\t\tupperdentry = ovl_dentry_upper(dentry);\n\n\t\tmutex_lock(&upperdentry->d_inode->i_mutex);\n\t\terr = notify_change(upperdentry, attr, NULL);\n\t\tmutex_unlock(&upperdentry->d_inode->i_mutex);\n\t}\n\tovl_drop_write(dentry);\nout:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,13 +7,13 @@\n \tif (err)\n \t\tgoto out;\n \n-\tupperdentry = ovl_dentry_upper(dentry);\n-\tif (upperdentry) {\n+\terr = ovl_copy_up(dentry);\n+\tif (!err) {\n+\t\tupperdentry = ovl_dentry_upper(dentry);\n+\n \t\tmutex_lock(&upperdentry->d_inode->i_mutex);\n \t\terr = notify_change(upperdentry, attr, NULL);\n \t\tmutex_unlock(&upperdentry->d_inode->i_mutex);\n-\t} else {\n-\t\terr = ovl_copy_up_last(dentry, attr, false);\n \t}\n \tovl_drop_write(dentry);\n out:",
        "diff_line_info": {
            "deleted_lines": [
                "\tupperdentry = ovl_dentry_upper(dentry);",
                "\tif (upperdentry) {",
                "\t} else {",
                "\t\terr = ovl_copy_up_last(dentry, attr, false);"
            ],
            "added_lines": [
                "\terr = ovl_copy_up(dentry);",
                "\tif (!err) {",
                "\t\tupperdentry = ovl_dentry_upper(dentry);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6640",
        "func_name": "android/prctl_set_vma_anon_name",
        "description": "The prctl_set_vma_anon_name function in kernel/sys.c in Android before 5.1.1 LMY49F and 6.0 before 2016-01-01 does not ensure that only one vma is accessed in a certain update action, which allows attackers to gain privileges or cause a denial of service (vma list corruption) via a crafted application, aka internal bug 20017123.",
        "git_url": "https://android.googlesource.com/kernel%2Fcommon/+/69bfe2d957d903521d32324190c2754cb073be15",
        "commit_title": "mm: fix prctl_set_vma_anon_name",
        "commit_text": " prctl_set_vma_anon_name could attempt to set the name across two vmas at the same time due to a typo, which might corrupt the vma list.  Fix it to use tmp instead of end to limit the name setting to a single vma at a time.  ",
        "func_before": "static int prctl_set_vma_anon_name(unsigned long start, unsigned long end,\n\t\t\tunsigned long arg)\n{\n\tunsigned long tmp;\n\tstruct vm_area_struct * vma, *prev;\n\tint unmapped_error = 0;\n\tint error = -EINVAL;\n\n\t/*\n\t * If the interval [start,end) covers some unmapped address\n\t * ranges, just ignore them, but return -ENOMEM at the end.\n\t * - this matches the handling in madvise.\n\t */\n\tvma = find_vma_prev(current->mm, start, &prev);\n\tif (vma && start > vma->vm_start)\n\t\tprev = vma;\n\n\tfor (;;) {\n\t\t/* Still start < end. */\n\t\terror = -ENOMEM;\n\t\tif (!vma)\n\t\t\treturn error;\n\n\t\t/* Here start < (end|vma->vm_end). */\n\t\tif (start < vma->vm_start) {\n\t\t\tunmapped_error = -ENOMEM;\n\t\t\tstart = vma->vm_start;\n\t\t\tif (start >= end)\n\t\t\t\treturn error;\n\t\t}\n\n\t\t/* Here vma->vm_start <= start < (end|vma->vm_end) */\n\t\ttmp = vma->vm_end;\n\t\tif (end < tmp)\n\t\t\ttmp = end;\n\n\t\t/* Here vma->vm_start <= start < tmp <= (end|vma->vm_end). */\n\t\terror = prctl_update_vma_anon_name(vma, &prev, start, end,\n\t\t\t\t(const char __user *)arg);\n\t\tif (error)\n\t\t\treturn error;\n\t\tstart = tmp;\n\t\tif (prev && start < prev->vm_end)\n\t\t\tstart = prev->vm_end;\n\t\terror = unmapped_error;\n\t\tif (start >= end)\n\t\t\treturn error;\n\t\tif (prev)\n\t\t\tvma = prev->vm_next;\n\t\telse\t/* madvise_remove dropped mmap_sem */\n\t\t\tvma = find_vma(current->mm, start);\n\t}\n}",
        "func": "static int prctl_set_vma_anon_name(unsigned long start, unsigned long end,\n\t\t\tunsigned long arg)\n{\n\tunsigned long tmp;\n\tstruct vm_area_struct * vma, *prev;\n\tint unmapped_error = 0;\n\tint error = -EINVAL;\n\n\t/*\n\t * If the interval [start,end) covers some unmapped address\n\t * ranges, just ignore them, but return -ENOMEM at the end.\n\t * - this matches the handling in madvise.\n\t */\n\tvma = find_vma_prev(current->mm, start, &prev);\n\tif (vma && start > vma->vm_start)\n\t\tprev = vma;\n\n\tfor (;;) {\n\t\t/* Still start < end. */\n\t\terror = -ENOMEM;\n\t\tif (!vma)\n\t\t\treturn error;\n\n\t\t/* Here start < (end|vma->vm_end). */\n\t\tif (start < vma->vm_start) {\n\t\t\tunmapped_error = -ENOMEM;\n\t\t\tstart = vma->vm_start;\n\t\t\tif (start >= end)\n\t\t\t\treturn error;\n\t\t}\n\n\t\t/* Here vma->vm_start <= start < (end|vma->vm_end) */\n\t\ttmp = vma->vm_end;\n\t\tif (end < tmp)\n\t\t\ttmp = end;\n\n\t\t/* Here vma->vm_start <= start < tmp <= (end|vma->vm_end). */\n\t\terror = prctl_update_vma_anon_name(vma, &prev, start, tmp,\n\t\t\t\t(const char __user *)arg);\n\t\tif (error)\n\t\t\treturn error;\n\t\tstart = tmp;\n\t\tif (prev && start < prev->vm_end)\n\t\t\tstart = prev->vm_end;\n\t\terror = unmapped_error;\n\t\tif (start >= end)\n\t\t\treturn error;\n\t\tif (prev)\n\t\t\tvma = prev->vm_next;\n\t\telse\t/* madvise_remove dropped mmap_sem */\n\t\t\tvma = find_vma(current->mm, start);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -35,7 +35,7 @@\n \t\t\ttmp = end;\n \n \t\t/* Here vma->vm_start <= start < tmp <= (end|vma->vm_end). */\n-\t\terror = prctl_update_vma_anon_name(vma, &prev, start, end,\n+\t\terror = prctl_update_vma_anon_name(vma, &prev, start, tmp,\n \t\t\t\t(const char __user *)arg);\n \t\tif (error)\n \t\t\treturn error;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\terror = prctl_update_vma_anon_name(vma, &prev, start, end,"
            ],
            "added_lines": [
                "\t\terror = prctl_update_vma_anon_name(vma, &prev, start, tmp,"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0807",
        "func_name": "android/get_build_id",
        "description": "The get_build_id function in elf_utils.cpp in Debuggerd in Android 6.x before 2016-02-01 allows attackers to gain privileges via a crafted application that mishandles a Desc Size element in an ELF Note, aka internal bug 25187394.",
        "git_url": "https://android.googlesource.com/platform%2Fsystem%2Fcore/+/d917514bd6b270df431ea4e781a865764d406120",
        "commit_title": "Fix incorrect check of descsz value.",
        "commit_text": " Bug: 25187394  (cherry picked from commit 1fa55234d6773e09e3bb934419b5b6cc0df981c9)  ",
        "func_before": "static bool get_build_id(\n    Backtrace* backtrace, uintptr_t base_addr, uint8_t* e_ident, std::string* build_id) {\n  HdrType hdr;\n\n  memcpy(&hdr.e_ident[0], e_ident, EI_NIDENT);\n\n  // First read the rest of the header.\n  if (backtrace->Read(base_addr + EI_NIDENT, reinterpret_cast<uint8_t*>(&hdr) + EI_NIDENT,\n                      sizeof(HdrType) - EI_NIDENT) != sizeof(HdrType) - EI_NIDENT) {\n    return false;\n  }\n\n  for (size_t i = 0; i < hdr.e_phnum; i++) {\n    PhdrType phdr;\n    if (backtrace->Read(base_addr + hdr.e_phoff + i * hdr.e_phentsize,\n                        reinterpret_cast<uint8_t*>(&phdr), sizeof(phdr)) != sizeof(phdr)) {\n      return false;\n    }\n    // Looking for the .note.gnu.build-id note.\n    if (phdr.p_type == PT_NOTE) {\n      size_t hdr_size = phdr.p_filesz;\n      uintptr_t addr = base_addr + phdr.p_offset;\n      while (hdr_size >= sizeof(NhdrType)) {\n        NhdrType nhdr;\n        if (backtrace->Read(addr, reinterpret_cast<uint8_t*>(&nhdr), sizeof(nhdr)) != sizeof(nhdr)) {\n          return false;\n        }\n        addr += sizeof(nhdr);\n        if (nhdr.n_type == NT_GNU_BUILD_ID) {\n          // Skip the name (which is the owner and should be \"GNU\").\n          addr += NOTE_ALIGN(nhdr.n_namesz);\n          uint8_t build_id_data[128];\n          if (nhdr.n_namesz > sizeof(build_id_data)) {\n            ALOGE(\"Possible corrupted note, name size value is too large: %u\",\n                  nhdr.n_namesz);\n            return false;\n          }\n          if (backtrace->Read(addr, build_id_data, nhdr.n_descsz) != nhdr.n_descsz) {\n            return false;\n          }\n\n          build_id->clear();\n          for (size_t bytes = 0; bytes < nhdr.n_descsz; bytes++) {\n            *build_id += android::base::StringPrintf(\"%02x\", build_id_data[bytes]);\n          }\n\n          return true;\n        } else {\n          // Move past the extra note data.\n          hdr_size -= sizeof(nhdr);\n          size_t skip_bytes = NOTE_ALIGN(nhdr.n_namesz) + NOTE_ALIGN(nhdr.n_descsz);\n          addr += skip_bytes;\n          if (hdr_size < skip_bytes) {\n            break;\n          }\n          hdr_size -= skip_bytes;\n        }\n      }\n    }\n  }\n  return false;\n}",
        "func": "static bool get_build_id(\n    Backtrace* backtrace, uintptr_t base_addr, uint8_t* e_ident, std::string* build_id) {\n  HdrType hdr;\n\n  memcpy(&hdr.e_ident[0], e_ident, EI_NIDENT);\n\n  // First read the rest of the header.\n  if (backtrace->Read(base_addr + EI_NIDENT, reinterpret_cast<uint8_t*>(&hdr) + EI_NIDENT,\n                      sizeof(HdrType) - EI_NIDENT) != sizeof(HdrType) - EI_NIDENT) {\n    return false;\n  }\n\n  for (size_t i = 0; i < hdr.e_phnum; i++) {\n    PhdrType phdr;\n    if (backtrace->Read(base_addr + hdr.e_phoff + i * hdr.e_phentsize,\n                        reinterpret_cast<uint8_t*>(&phdr), sizeof(phdr)) != sizeof(phdr)) {\n      return false;\n    }\n    // Looking for the .note.gnu.build-id note.\n    if (phdr.p_type == PT_NOTE) {\n      size_t hdr_size = phdr.p_filesz;\n      uintptr_t addr = base_addr + phdr.p_offset;\n      while (hdr_size >= sizeof(NhdrType)) {\n        NhdrType nhdr;\n        if (backtrace->Read(addr, reinterpret_cast<uint8_t*>(&nhdr), sizeof(nhdr)) != sizeof(nhdr)) {\n          return false;\n        }\n        addr += sizeof(nhdr);\n        if (nhdr.n_type == NT_GNU_BUILD_ID) {\n          // Skip the name (which is the owner and should be \"GNU\").\n          addr += NOTE_ALIGN(nhdr.n_namesz);\n          uint8_t build_id_data[160];\n          if (nhdr.n_descsz > sizeof(build_id_data)) {\n            ALOGE(\"Possible corrupted note, desc size value is too large: %u\",\n                  nhdr.n_descsz);\n            return false;\n          }\n          if (backtrace->Read(addr, build_id_data, nhdr.n_descsz) != nhdr.n_descsz) {\n            return false;\n          }\n\n          build_id->clear();\n          for (size_t bytes = 0; bytes < nhdr.n_descsz; bytes++) {\n            *build_id += android::base::StringPrintf(\"%02x\", build_id_data[bytes]);\n          }\n\n          return true;\n        } else {\n          // Move past the extra note data.\n          hdr_size -= sizeof(nhdr);\n          size_t skip_bytes = NOTE_ALIGN(nhdr.n_namesz) + NOTE_ALIGN(nhdr.n_descsz);\n          addr += skip_bytes;\n          if (hdr_size < skip_bytes) {\n            break;\n          }\n          hdr_size -= skip_bytes;\n        }\n      }\n    }\n  }\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,10 +29,10 @@\n         if (nhdr.n_type == NT_GNU_BUILD_ID) {\n           // Skip the name (which is the owner and should be \"GNU\").\n           addr += NOTE_ALIGN(nhdr.n_namesz);\n-          uint8_t build_id_data[128];\n-          if (nhdr.n_namesz > sizeof(build_id_data)) {\n-            ALOGE(\"Possible corrupted note, name size value is too large: %u\",\n-                  nhdr.n_namesz);\n+          uint8_t build_id_data[160];\n+          if (nhdr.n_descsz > sizeof(build_id_data)) {\n+            ALOGE(\"Possible corrupted note, desc size value is too large: %u\",\n+                  nhdr.n_descsz);\n             return false;\n           }\n           if (backtrace->Read(addr, build_id_data, nhdr.n_descsz) != nhdr.n_descsz) {",
        "diff_line_info": {
            "deleted_lines": [
                "          uint8_t build_id_data[128];",
                "          if (nhdr.n_namesz > sizeof(build_id_data)) {",
                "            ALOGE(\"Possible corrupted note, name size value is too large: %u\",",
                "                  nhdr.n_namesz);"
            ],
            "added_lines": [
                "          uint8_t build_id_data[160];",
                "          if (nhdr.n_descsz > sizeof(build_id_data)) {",
                "            ALOGE(\"Possible corrupted note, desc size value is too large: %u\",",
                "                  nhdr.n_descsz);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0809",
        "func_name": "android/wifi_cleanup",
        "description": "Use-after-free vulnerability in the wifi_cleanup function in bcmdhd/wifi_hal/wifi_hal.cpp in Wi-Fi in Android 6.x before 2016-02-01 allows attackers to gain privileges by leveraging access to the local physical environment during execution of a crafted application, aka internal bug 25753768.",
        "git_url": "https://android.googlesource.com/platform/hardware/broadcom/wlan/+/2c5a4fac8bc8198f6a2635ede776f8de40a0c3e1",
        "commit_title": "Fix use-after-free in wifi_cleanup()",
        "commit_text": " Release reference to cmd only after possibly calling getType().   BUG: 25753768 (cherry picked from commit d7f3cb9915d9ac514393d0ad7767662958054b8f https://googleplex-android-review.git.corp.google.com/#/c/815223) ",
        "func_before": "void wifi_cleanup(wifi_handle handle, wifi_cleaned_up_handler handler)\n{\n    hal_info *info = getHalInfo(handle);\n    char buf[64];\n\n    info->cleaned_up_handler = handler;\n    if (write(info->cleanup_socks[0], \"Exit\", 4) < 1) {\n        // As a fallback set the cleanup flag to TRUE\n        ALOGE(\"could not write to the cleanup socket\");\n    } else {\n        // Listen to the response\n        // Hopefully we dont get errors or get hung up\n        // Not much can be done in that case, but assume that\n        // it has rx'ed the Exit message to exit the thread.\n        // As a fallback set the cleanup flag to TRUE\n        memset(buf, 0, sizeof(buf));\n        int result = read(info->cleanup_socks[0], buf, sizeof(buf));\n        ALOGE(\"%s: Read after POLL returned %d, error no = %d\", __FUNCTION__, result, errno);\n        if (strncmp(buf, \"Done\", 4) == 0) {\n            ALOGE(\"Event processing terminated\");\n        } else {\n            ALOGD(\"Rx'ed %s\", buf);\n        }\n    }\n    info->clean_up = true;\n    pthread_mutex_lock(&info->cb_lock);\n\n    int bad_commands = 0;\n\n    for (int i = 0; i < info->num_event_cb; i++) {\n        cb_info *cbi = &(info->event_cb[i]);\n        WifiCommand *cmd = (WifiCommand *)cbi->cb_arg;\n        ALOGI(\"Command left in event_cb %p:%s\", cmd, (cmd ? cmd->getType(): \"\"));\n    }\n\n    while (info->num_cmd > bad_commands) {\n        int num_cmd = info->num_cmd;\n        cmd_info *cmdi = &(info->cmd[bad_commands]);\n        WifiCommand *cmd = cmdi->cmd;\n        if (cmd != NULL) {\n            ALOGI(\"Cancelling command %p:%s\", cmd, cmd->getType());\n            pthread_mutex_unlock(&info->cb_lock);\n            cmd->cancel();\n            pthread_mutex_lock(&info->cb_lock);\n            /* release reference added when command is saved */\n            cmd->releaseRef();\n            if (num_cmd == info->num_cmd) {\n                ALOGI(\"Cancelling command %p:%s did not work\", cmd, (cmd ? cmd->getType(): \"\"));\n                bad_commands++;\n            }\n        }\n    }\n\n    for (int i = 0; i < info->num_event_cb; i++) {\n        cb_info *cbi = &(info->event_cb[i]);\n        WifiCommand *cmd = (WifiCommand *)cbi->cb_arg;\n        ALOGE(\"Leaked command %p\", cmd);\n    }\n    pthread_mutex_unlock(&info->cb_lock);\n    internal_cleaned_up_handler(handle);\n}",
        "func": "void wifi_cleanup(wifi_handle handle, wifi_cleaned_up_handler handler)\n{\n    hal_info *info = getHalInfo(handle);\n    char buf[64];\n\n    info->cleaned_up_handler = handler;\n    if (write(info->cleanup_socks[0], \"Exit\", 4) < 1) {\n        // As a fallback set the cleanup flag to TRUE\n        ALOGE(\"could not write to the cleanup socket\");\n    } else {\n        // Listen to the response\n        // Hopefully we dont get errors or get hung up\n        // Not much can be done in that case, but assume that\n        // it has rx'ed the Exit message to exit the thread.\n        // As a fallback set the cleanup flag to TRUE\n        memset(buf, 0, sizeof(buf));\n        int result = read(info->cleanup_socks[0], buf, sizeof(buf));\n        ALOGE(\"%s: Read after POLL returned %d, error no = %d\", __FUNCTION__, result, errno);\n        if (strncmp(buf, \"Done\", 4) == 0) {\n            ALOGE(\"Event processing terminated\");\n        } else {\n            ALOGD(\"Rx'ed %s\", buf);\n        }\n    }\n    info->clean_up = true;\n    pthread_mutex_lock(&info->cb_lock);\n\n    int bad_commands = 0;\n\n    for (int i = 0; i < info->num_event_cb; i++) {\n        cb_info *cbi = &(info->event_cb[i]);\n        WifiCommand *cmd = (WifiCommand *)cbi->cb_arg;\n        ALOGI(\"Command left in event_cb %p:%s\", cmd, (cmd ? cmd->getType(): \"\"));\n    }\n\n    while (info->num_cmd > bad_commands) {\n        int num_cmd = info->num_cmd;\n        cmd_info *cmdi = &(info->cmd[bad_commands]);\n        WifiCommand *cmd = cmdi->cmd;\n        if (cmd != NULL) {\n            ALOGI(\"Cancelling command %p:%s\", cmd, cmd->getType());\n            pthread_mutex_unlock(&info->cb_lock);\n            cmd->cancel();\n            pthread_mutex_lock(&info->cb_lock);\n            if (num_cmd == info->num_cmd) {\n                ALOGI(\"Cancelling command %p:%s did not work\", cmd, (cmd ? cmd->getType(): \"\"));\n                bad_commands++;\n            }\n            /* release reference added when command is saved */\n            cmd->releaseRef();\n        }\n    }\n\n    for (int i = 0; i < info->num_event_cb; i++) {\n        cb_info *cbi = &(info->event_cb[i]);\n        WifiCommand *cmd = (WifiCommand *)cbi->cb_arg;\n        ALOGE(\"Leaked command %p\", cmd);\n    }\n    pthread_mutex_unlock(&info->cb_lock);\n    internal_cleaned_up_handler(handle);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,12 +42,12 @@\n             pthread_mutex_unlock(&info->cb_lock);\n             cmd->cancel();\n             pthread_mutex_lock(&info->cb_lock);\n-            /* release reference added when command is saved */\n-            cmd->releaseRef();\n             if (num_cmd == info->num_cmd) {\n                 ALOGI(\"Cancelling command %p:%s did not work\", cmd, (cmd ? cmd->getType(): \"\"));\n                 bad_commands++;\n             }\n+            /* release reference added when command is saved */\n+            cmd->releaseRef();\n         }\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            /* release reference added when command is saved */",
                "            cmd->releaseRef();"
            ],
            "added_lines": [
                "            /* release reference added when command is saved */",
                "            cmd->releaseRef();"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0810",
        "func_name": "android/SoundPool::play",
        "description": "media/libmedia/SoundPool.cpp in mediaserver in Android 4.x before 4.4.4, 5.x before 5.1.1 LMY49G, and 6.x before 2016-02-01 mishandles locking requirements, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 25781119.",
        "git_url": "https://android.googlesource.com/platform%2Fframeworks%2Fav/+/19c47afbc402542720ddd280e1bbde3b2277b586",
        "commit_title": "DO NOT MERGE SoundPool: add lock for findSample access from SoundPoolThread",
        "commit_text": " Sample decoding still occurs in SoundPoolThread without holding the SoundPool lock.  Bug: 25781119 ",
        "func_before": "int SoundPool::play(int sampleID, float leftVolume, float rightVolume,\n        int priority, int loop, float rate)\n{\n    ALOGV(\"play sampleID=%d, leftVolume=%f, rightVolume=%f, priority=%d, loop=%d, rate=%f\",\n            sampleID, leftVolume, rightVolume, priority, loop, rate);\n    sp<Sample> sample;\n    SoundChannel* channel;\n    int channelID;\n\n    Mutex::Autolock lock(&mLock);\n\n    if (mQuit) {\n        return 0;\n    }\n    // is sample ready?\n    sample = findSample(sampleID);\n    if ((sample == 0) || (sample->state() != Sample::READY)) {\n        ALOGW(\"  sample %d not READY\", sampleID);\n        return 0;\n    }\n\n    dump();\n\n    // allocate a channel\n    channel = allocateChannel_l(priority);\n\n    // no channel allocated - return 0\n    if (!channel) {\n        ALOGV(\"No channel allocated\");\n        return 0;\n    }\n\n    channelID = ++mNextChannelID;\n\n    ALOGV(\"play channel %p state = %d\", channel, channel->state());\n    channel->play(sample, channelID, leftVolume, rightVolume, priority, loop, rate);\n    return channelID;\n}",
        "func": "int SoundPool::play(int sampleID, float leftVolume, float rightVolume,\n        int priority, int loop, float rate)\n{\n    ALOGV(\"play sampleID=%d, leftVolume=%f, rightVolume=%f, priority=%d, loop=%d, rate=%f\",\n            sampleID, leftVolume, rightVolume, priority, loop, rate);\n    SoundChannel* channel;\n    int channelID;\n\n    Mutex::Autolock lock(&mLock);\n\n    if (mQuit) {\n        return 0;\n    }\n    // is sample ready?\n    sp<Sample> sample(findSample_l(sampleID));\n    if ((sample == 0) || (sample->state() != Sample::READY)) {\n        ALOGW(\"  sample %d not READY\", sampleID);\n        return 0;\n    }\n\n    dump();\n\n    // allocate a channel\n    channel = allocateChannel_l(priority);\n\n    // no channel allocated - return 0\n    if (!channel) {\n        ALOGV(\"No channel allocated\");\n        return 0;\n    }\n\n    channelID = ++mNextChannelID;\n\n    ALOGV(\"play channel %p state = %d\", channel, channel->state());\n    channel->play(sample, channelID, leftVolume, rightVolume, priority, loop, rate);\n    return channelID;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,6 @@\n {\n     ALOGV(\"play sampleID=%d, leftVolume=%f, rightVolume=%f, priority=%d, loop=%d, rate=%f\",\n             sampleID, leftVolume, rightVolume, priority, loop, rate);\n-    sp<Sample> sample;\n     SoundChannel* channel;\n     int channelID;\n \n@@ -13,7 +12,7 @@\n         return 0;\n     }\n     // is sample ready?\n-    sample = findSample(sampleID);\n+    sp<Sample> sample(findSample_l(sampleID));\n     if ((sample == 0) || (sample->state() != Sample::READY)) {\n         ALOGW(\"  sample %d not READY\", sampleID);\n         return 0;",
        "diff_line_info": {
            "deleted_lines": [
                "    sp<Sample> sample;",
                "    sample = findSample(sampleID);"
            ],
            "added_lines": [
                "    sp<Sample> sample(findSample_l(sampleID));"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0810",
        "func_name": "android/SoundPool::load",
        "description": "media/libmedia/SoundPool.cpp in mediaserver in Android 4.x before 4.4.4, 5.x before 5.1.1 LMY49G, and 6.x before 2016-02-01 mishandles locking requirements, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 25781119.",
        "git_url": "https://android.googlesource.com/platform%2Fframeworks%2Fav/+/19c47afbc402542720ddd280e1bbde3b2277b586",
        "commit_title": "DO NOT MERGE SoundPool: add lock for findSample access from SoundPoolThread",
        "commit_text": " Sample decoding still occurs in SoundPoolThread without holding the SoundPool lock.  Bug: 25781119 ",
        "func_before": "int SoundPool::load(const char* path, int priority __unused)\n{\n    ALOGV(\"load: path=%s, priority=%d\", path, priority);\n    Mutex::Autolock lock(&mLock);\n    sp<Sample> sample = new Sample(++mNextSampleID, path);\n    mSamples.add(sample->sampleID(), sample);\n    doLoad(sample);\n    return sample->sampleID();\n}",
        "func": "int SoundPool::load(const char* path, int priority __unused)\n{\n    ALOGV(\"load: path=%s, priority=%d\", path, priority);\n    int sampleID;\n    {\n        Mutex::Autolock lock(&mLock);\n        sampleID = ++mNextSampleID;\n        sp<Sample> sample = new Sample(sampleID, path);\n        mSamples.add(sampleID, sample);\n        sample->startLoad();\n    }\n    // mDecodeThread->loadSample() must be called outside of mLock.\n    // mDecodeThread->loadSample() may block on mDecodeThread message queue space;\n    // the message queue emptying may block on SoundPool::findSample().\n    //\n    // It theoretically possible that sample loads might decode out-of-order.\n    mDecodeThread->loadSample(sampleID);\n    return sampleID;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,9 +1,19 @@\n int SoundPool::load(const char* path, int priority __unused)\n {\n     ALOGV(\"load: path=%s, priority=%d\", path, priority);\n-    Mutex::Autolock lock(&mLock);\n-    sp<Sample> sample = new Sample(++mNextSampleID, path);\n-    mSamples.add(sample->sampleID(), sample);\n-    doLoad(sample);\n-    return sample->sampleID();\n+    int sampleID;\n+    {\n+        Mutex::Autolock lock(&mLock);\n+        sampleID = ++mNextSampleID;\n+        sp<Sample> sample = new Sample(sampleID, path);\n+        mSamples.add(sampleID, sample);\n+        sample->startLoad();\n+    }\n+    // mDecodeThread->loadSample() must be called outside of mLock.\n+    // mDecodeThread->loadSample() may block on mDecodeThread message queue space;\n+    // the message queue emptying may block on SoundPool::findSample().\n+    //\n+    // It theoretically possible that sample loads might decode out-of-order.\n+    mDecodeThread->loadSample(sampleID);\n+    return sampleID;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    Mutex::Autolock lock(&mLock);",
                "    sp<Sample> sample = new Sample(++mNextSampleID, path);",
                "    mSamples.add(sample->sampleID(), sample);",
                "    doLoad(sample);",
                "    return sample->sampleID();"
            ],
            "added_lines": [
                "    int sampleID;",
                "    {",
                "        Mutex::Autolock lock(&mLock);",
                "        sampleID = ++mNextSampleID;",
                "        sp<Sample> sample = new Sample(sampleID, path);",
                "        mSamples.add(sampleID, sample);",
                "        sample->startLoad();",
                "    }",
                "    // mDecodeThread->loadSample() must be called outside of mLock.",
                "    // mDecodeThread->loadSample() may block on mDecodeThread message queue space;",
                "    // the message queue emptying may block on SoundPool::findSample().",
                "    //",
                "    // It theoretically possible that sample loads might decode out-of-order.",
                "    mDecodeThread->loadSample(sampleID);",
                "    return sampleID;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-0810",
        "func_name": "android/SoundPool::load",
        "description": "media/libmedia/SoundPool.cpp in mediaserver in Android 4.x before 4.4.4, 5.x before 5.1.1 LMY49G, and 6.x before 2016-02-01 mishandles locking requirements, which allows attackers to gain privileges via a crafted application, as demonstrated by obtaining Signature or SignatureOrSystem access, aka internal bug 25781119.",
        "git_url": "https://android.googlesource.com/platform%2Fframeworks%2Fav/+/19c47afbc402542720ddd280e1bbde3b2277b586",
        "commit_title": "DO NOT MERGE SoundPool: add lock for findSample access from SoundPoolThread",
        "commit_text": " Sample decoding still occurs in SoundPoolThread without holding the SoundPool lock.  Bug: 25781119 ",
        "func_before": "int SoundPool::load(int fd, int64_t offset, int64_t length, int priority __unused)\n{\n    ALOGV(\"load: fd=%d, offset=%\" PRId64 \", length=%\" PRId64 \", priority=%d\",\n            fd, offset, length, priority);\n    Mutex::Autolock lock(&mLock);\n    sp<Sample> sample = new Sample(++mNextSampleID, fd, offset, length);\n    mSamples.add(sample->sampleID(), sample);\n    doLoad(sample);\n    return sample->sampleID();\n}",
        "func": "int SoundPool::load(int fd, int64_t offset, int64_t length, int priority __unused)\n{\n    ALOGV(\"load: fd=%d, offset=%\" PRId64 \", length=%\" PRId64 \", priority=%d\",\n            fd, offset, length, priority);\n    int sampleID;\n    {\n        Mutex::Autolock lock(&mLock);\n        sampleID = ++mNextSampleID;\n        sp<Sample> sample = new Sample(sampleID, fd, offset, length);\n        mSamples.add(sampleID, sample);\n        sample->startLoad();\n    }\n    // mDecodeThread->loadSample() must be called outside of mLock.\n    // mDecodeThread->loadSample() may block on mDecodeThread message queue space;\n    // the message queue emptying may block on SoundPool::findSample().\n    //\n    // It theoretically possible that sample loads might decode out-of-order.\n    mDecodeThread->loadSample(sampleID);\n    return sampleID;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,9 +2,19 @@\n {\n     ALOGV(\"load: fd=%d, offset=%\" PRId64 \", length=%\" PRId64 \", priority=%d\",\n             fd, offset, length, priority);\n-    Mutex::Autolock lock(&mLock);\n-    sp<Sample> sample = new Sample(++mNextSampleID, fd, offset, length);\n-    mSamples.add(sample->sampleID(), sample);\n-    doLoad(sample);\n-    return sample->sampleID();\n+    int sampleID;\n+    {\n+        Mutex::Autolock lock(&mLock);\n+        sampleID = ++mNextSampleID;\n+        sp<Sample> sample = new Sample(sampleID, fd, offset, length);\n+        mSamples.add(sampleID, sample);\n+        sample->startLoad();\n+    }\n+    // mDecodeThread->loadSample() must be called outside of mLock.\n+    // mDecodeThread->loadSample() may block on mDecodeThread message queue space;\n+    // the message queue emptying may block on SoundPool::findSample().\n+    //\n+    // It theoretically possible that sample loads might decode out-of-order.\n+    mDecodeThread->loadSample(sampleID);\n+    return sampleID;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    Mutex::Autolock lock(&mLock);",
                "    sp<Sample> sample = new Sample(++mNextSampleID, fd, offset, length);",
                "    mSamples.add(sample->sampleID(), sample);",
                "    doLoad(sample);",
                "    return sample->sampleID();"
            ],
            "added_lines": [
                "    int sampleID;",
                "    {",
                "        Mutex::Autolock lock(&mLock);",
                "        sampleID = ++mNextSampleID;",
                "        sp<Sample> sample = new Sample(sampleID, fd, offset, length);",
                "        mSamples.add(sampleID, sample);",
                "        sample->startLoad();",
                "    }",
                "    // mDecodeThread->loadSample() must be called outside of mLock.",
                "    // mDecodeThread->loadSample() may block on mDecodeThread message queue space;",
                "    // the message queue emptying may block on SoundPool::findSample().",
                "    //",
                "    // It theoretically possible that sample loads might decode out-of-order.",
                "    mDecodeThread->loadSample(sampleID);",
                "    return sampleID;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1623",
        "func_name": "chromium/~SubframeLoadingDisabler",
        "description": "The DOM implementation in Google Chrome before 48.0.2564.109 does not properly restrict frame-attach operations from occurring during or after frame-detach operations, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to FrameLoader.cpp, HTMLFrameOwnerElement.h, LocalFrame.cpp, and WebLocalFrameImpl.cpp.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/a4bcdcb1f8df4f7427e208201501a9d8e41e386b",
        "commit_title": "Disable sub frame loads more reliably in frame detach.",
        "commit_text": " Previously, guarding against attaching a new frame in frame detach was done by inspecting LoadEventProgress. There are certain operations, such as document.open(), that can cause LoadEventProgress to never advance, causing the guard to get skipped.    ",
        "func_before": "~SubframeLoadingDisabler()\n    {\n        disabledSubtreeRoots().remove(m_root);\n    }",
        "func": "~SubframeLoadingDisabler()\n    {\n        if (m_root)\n            disabledSubtreeRoots().remove(m_root);\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n ~SubframeLoadingDisabler()\n     {\n-        disabledSubtreeRoots().remove(m_root);\n+        if (m_root)\n+            disabledSubtreeRoots().remove(m_root);\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        disabledSubtreeRoots().remove(m_root);"
            ],
            "added_lines": [
                "        if (m_root)",
                "            disabledSubtreeRoots().remove(m_root);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1623",
        "func_name": "chromium/canLoadFrame",
        "description": "The DOM implementation in Google Chrome before 48.0.2564.109 does not properly restrict frame-attach operations from occurring during or after frame-detach operations, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to FrameLoader.cpp, HTMLFrameOwnerElement.h, LocalFrame.cpp, and WebLocalFrameImpl.cpp.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/a4bcdcb1f8df4f7427e208201501a9d8e41e386b",
        "commit_title": "Disable sub frame loads more reliably in frame detach.",
        "commit_text": " Previously, guarding against attaching a new frame in frame detach was done by inspecting LoadEventProgress. There are certain operations, such as document.open(), that can cause LoadEventProgress to never advance, causing the guard to get skipped.    ",
        "func_before": "static bool canLoadFrame(HTMLFrameOwnerElement& owner)\n    {\n        if (owner.document().unloadStarted())\n            return false;\n        for (Node* node = &owner; node; node = node->parentOrShadowHostNode()) {\n            if (disabledSubtreeRoots().contains(node))\n                return false;\n        }\n        return true;\n    }",
        "func": "static bool canLoadFrame(HTMLFrameOwnerElement& owner)\n    {\n        for (Node* node = &owner; node; node = node->parentOrShadowHostNode()) {\n            if (disabledSubtreeRoots().contains(node))\n                return false;\n        }\n        return true;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,5 @@\n static bool canLoadFrame(HTMLFrameOwnerElement& owner)\n     {\n-        if (owner.document().unloadStarted())\n-            return false;\n         for (Node* node = &owner; node; node = node->parentOrShadowHostNode()) {\n             if (disabledSubtreeRoots().contains(node))\n                 return false;",
        "diff_line_info": {
            "deleted_lines": [
                "        if (owner.document().unloadStarted())",
                "            return false;"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2016-1623",
        "func_name": "chromium/LocalFrame::detach",
        "description": "The DOM implementation in Google Chrome before 48.0.2564.109 does not properly restrict frame-attach operations from occurring during or after frame-detach operations, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to FrameLoader.cpp, HTMLFrameOwnerElement.h, LocalFrame.cpp, and WebLocalFrameImpl.cpp.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/a4bcdcb1f8df4f7427e208201501a9d8e41e386b",
        "commit_title": "Disable sub frame loads more reliably in frame detach.",
        "commit_text": " Previously, guarding against attaching a new frame in frame detach was done by inspecting LoadEventProgress. There are certain operations, such as document.open(), that can cause LoadEventProgress to never advance, causing the guard to get skipped.    ",
        "func_before": "void LocalFrame::detach(FrameDetachType type)\n{\n    PluginScriptForbiddenScope forbidPluginDestructorScripting;\n    // A lot of the following steps can result in the current frame being\n    // detached, so protect a reference to it.\n    RefPtrWillBeRawPtr<LocalFrame> protect(this);\n    m_loader.stopAllLoaders();\n    m_loader.dispatchUnloadEvent();\n    detachChildren();\n    m_frameScheduler.clear();\n\n    // All done if detaching the subframes brought about a detach of this frame also.\n    if (!client())\n        return;\n\n    // stopAllLoaders() needs to be called after detachChildren(), because detachChildren()\n    // will trigger the unload event handlers of any child frames, and those event\n    // handlers might start a new subresource load in this frame.\n    m_loader.stopAllLoaders();\n    m_loader.detach();\n    document()->detach();\n    // This is the earliest that scripting can be disabled:\n    // - FrameLoader::detach() can fire XHR abort events\n    // - Document::detach()'s deferred widget updates can run script.\n    ScriptForbiddenScope forbidScript;\n    m_loader.clear();\n    if (!client())\n        return;\n\n    client()->willBeDetached();\n    // Notify ScriptController that the frame is closing, since its cleanup ends up calling\n    // back to FrameLoaderClient via WindowProxy.\n    script().clearForClose();\n    setView(nullptr);\n    willDetachFrameHost();\n    InspectorInstrumentation::frameDetachedFromParent(this);\n    Frame::detach(type);\n\n    // Signal frame destruction here rather than in the destructor.\n    // Main motivation is to avoid being dependent on its exact timing (Oilpan.)\n    LocalFrameLifecycleNotifier::notifyContextDestroyed();\n    m_supplements.clear();\n    WeakIdentifierMap<LocalFrame>::notifyObjectDestroyed(this);\n}",
        "func": "void LocalFrame::detach(FrameDetachType type)\n{\n    PluginScriptForbiddenScope forbidPluginDestructorScripting;\n    // A lot of the following steps can result in the current frame being\n    // detached, so protect a reference to it.\n    RefPtrWillBeRawPtr<LocalFrame> protect(this);\n    m_loader.stopAllLoaders();\n    // Don't allow any new child frames to load in this frame: attaching a new\n    // child frame during or after detaching children results in an attached\n    // frame on a detached DOM tree, which is bad.\n    SubframeLoadingDisabler disabler(*document());\n    m_loader.dispatchUnloadEvent();\n    detachChildren();\n    m_frameScheduler.clear();\n\n    // All done if detaching the subframes brought about a detach of this frame also.\n    if (!client())\n        return;\n\n    // stopAllLoaders() needs to be called after detachChildren(), because detachChildren()\n    // will trigger the unload event handlers of any child frames, and those event\n    // handlers might start a new subresource load in this frame.\n    m_loader.stopAllLoaders();\n    m_loader.detach();\n    document()->detach();\n    // This is the earliest that scripting can be disabled:\n    // - FrameLoader::detach() can fire XHR abort events\n    // - Document::detach()'s deferred widget updates can run script.\n    ScriptForbiddenScope forbidScript;\n    m_loader.clear();\n    if (!client())\n        return;\n\n    client()->willBeDetached();\n    // Notify ScriptController that the frame is closing, since its cleanup ends up calling\n    // back to FrameLoaderClient via WindowProxy.\n    script().clearForClose();\n    setView(nullptr);\n    willDetachFrameHost();\n    InspectorInstrumentation::frameDetachedFromParent(this);\n    Frame::detach(type);\n\n    // Signal frame destruction here rather than in the destructor.\n    // Main motivation is to avoid being dependent on its exact timing (Oilpan.)\n    LocalFrameLifecycleNotifier::notifyContextDestroyed();\n    m_supplements.clear();\n    WeakIdentifierMap<LocalFrame>::notifyObjectDestroyed(this);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,10 @@\n     // detached, so protect a reference to it.\n     RefPtrWillBeRawPtr<LocalFrame> protect(this);\n     m_loader.stopAllLoaders();\n+    // Don't allow any new child frames to load in this frame: attaching a new\n+    // child frame during or after detaching children results in an attached\n+    // frame on a detached DOM tree, which is bad.\n+    SubframeLoadingDisabler disabler(*document());\n     m_loader.dispatchUnloadEvent();\n     detachChildren();\n     m_frameScheduler.clear();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // Don't allow any new child frames to load in this frame: attaching a new",
                "    // child frame during or after detaching children results in an attached",
                "    // frame on a detached DOM tree, which is bad.",
                "    SubframeLoadingDisabler disabler(*document());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1623",
        "func_name": "chromium/FrameLoader::replaceDocumentWhileExecutingJavaScriptURL",
        "description": "The DOM implementation in Google Chrome before 48.0.2564.109 does not properly restrict frame-attach operations from occurring during or after frame-detach operations, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to FrameLoader.cpp, HTMLFrameOwnerElement.h, LocalFrame.cpp, and WebLocalFrameImpl.cpp.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/a4bcdcb1f8df4f7427e208201501a9d8e41e386b",
        "commit_title": "Disable sub frame loads more reliably in frame detach.",
        "commit_text": " Previously, guarding against attaching a new frame in frame detach was done by inspecting LoadEventProgress. There are certain operations, such as document.open(), that can cause LoadEventProgress to never advance, causing the guard to get skipped.    ",
        "func_before": "void FrameLoader::replaceDocumentWhileExecutingJavaScriptURL(const String& source, Document* ownerDocument)\n{\n    if (!m_frame->document()->loader() || m_frame->document()->pageDismissalEventBeingDispatched() != Document::NoDismissal)\n        return;\n\n    // DocumentLoader::replaceDocumentWhileExecutingJavaScriptURL can cause the DocumentLoader to get deref'ed and possible destroyed,\n    // so protect it with a RefPtr.\n    RefPtrWillBeRawPtr<DocumentLoader> documentLoader(m_frame->document()->loader());\n\n    UseCounter::count(*m_frame->document(), UseCounter::ReplaceDocumentViaJavaScriptURL);\n\n    // Prepare a DocumentInit before clearing the frame, because it may need to\n    // inherit an aliased security context.\n    DocumentInit init(m_frame->document()->url(), m_frame);\n    init.withNewRegistrationContext();\n\n    stopAllLoaders();\n    m_frame->detachChildren();\n    m_frame->document()->detach();\n    clear();\n\n    // detachChildren() potentially detaches the frame from the document. The\n    // loading cannot continue in that case.\n    if (!m_frame->page())\n        return;\n\n    client()->transitionToCommittedForNewPage();\n    documentLoader->replaceDocumentWhileExecutingJavaScriptURL(init, source, ownerDocument);\n}",
        "func": "void FrameLoader::replaceDocumentWhileExecutingJavaScriptURL(const String& source, Document* ownerDocument)\n{\n    if (!m_frame->document()->loader() || m_frame->document()->pageDismissalEventBeingDispatched() != Document::NoDismissal)\n        return;\n\n    // DocumentLoader::replaceDocumentWhileExecutingJavaScriptURL can cause the DocumentLoader to get deref'ed and possible destroyed,\n    // so protect it with a RefPtr.\n    RefPtrWillBeRawPtr<DocumentLoader> documentLoader(m_frame->document()->loader());\n\n    UseCounter::count(*m_frame->document(), UseCounter::ReplaceDocumentViaJavaScriptURL);\n\n    // Prepare a DocumentInit before clearing the frame, because it may need to\n    // inherit an aliased security context.\n    DocumentInit init(m_frame->document()->url(), m_frame);\n    init.withNewRegistrationContext();\n\n    stopAllLoaders();\n    // Don't allow any new child frames to load in this frame: attaching a new\n    // child frame during or after detaching children results in an attached\n    // frame on a detached DOM tree, which is bad.\n    SubframeLoadingDisabler disabler(m_frame->document());\n    m_frame->detachChildren();\n    m_frame->document()->detach();\n    clear();\n\n    // detachChildren() potentially detaches the frame from the document. The\n    // loading cannot continue in that case.\n    if (!m_frame->page())\n        return;\n\n    client()->transitionToCommittedForNewPage();\n    documentLoader->replaceDocumentWhileExecutingJavaScriptURL(init, source, ownerDocument);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,10 @@\n     init.withNewRegistrationContext();\n \n     stopAllLoaders();\n+    // Don't allow any new child frames to load in this frame: attaching a new\n+    // child frame during or after detaching children results in an attached\n+    // frame on a detached DOM tree, which is bad.\n+    SubframeLoadingDisabler disabler(m_frame->document());\n     m_frame->detachChildren();\n     m_frame->document()->detach();\n     clear();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // Don't allow any new child frames to load in this frame: attaching a new",
                "    // child frame during or after detaching children results in an attached",
                "    // frame on a detached DOM tree, which is bad.",
                "    SubframeLoadingDisabler disabler(m_frame->document());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1623",
        "func_name": "chromium/FrameLoader::prepareForCommit",
        "description": "The DOM implementation in Google Chrome before 48.0.2564.109 does not properly restrict frame-attach operations from occurring during or after frame-detach operations, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to FrameLoader.cpp, HTMLFrameOwnerElement.h, LocalFrame.cpp, and WebLocalFrameImpl.cpp.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/a4bcdcb1f8df4f7427e208201501a9d8e41e386b",
        "commit_title": "Disable sub frame loads more reliably in frame detach.",
        "commit_text": " Previously, guarding against attaching a new frame in frame detach was done by inspecting LoadEventProgress. There are certain operations, such as document.open(), that can cause LoadEventProgress to never advance, causing the guard to get skipped.    ",
        "func_before": "bool FrameLoader::prepareForCommit()\n{\n    PluginScriptForbiddenScope forbidPluginDestructorScripting;\n    RefPtrWillBeRawPtr<DocumentLoader> pdl = m_provisionalDocumentLoader;\n\n    if (m_frame->document()) {\n        unsigned totalNodeCount = InstanceCounters::counterValue(InstanceCounters::NodeCounter);\n        int nodeCount = static_cast<int>(totalNodeCount);\n        for (Document* document : Document::liveDocumentSet()) {\n            if (document != m_frame->document())\n                nodeCount -= document->nodeCount();\n        }\n        ASSERT(nodeCount >= 0);\n        float ratio = static_cast<float>(nodeCount) / totalNodeCount;\n        ThreadState::current()->schedulePageNavigationGCIfNeeded(ratio);\n    }\n\n    if (m_documentLoader) {\n        client()->dispatchWillClose();\n        dispatchUnloadEvent();\n    }\n    m_frame->detachChildren();\n    // The previous calls to dispatchUnloadEvent() and detachChildren() can\n    // execute arbitrary script via things like unload events. If the executed\n    // script intiates a new load or causes the current frame to be detached,\n    // we need to abandon the current load.\n    if (pdl != m_provisionalDocumentLoader)\n        return false;\n    if (m_documentLoader) {\n        FrameNavigationDisabler navigationDisabler(*m_frame);\n        detachDocumentLoader(m_documentLoader);\n    }\n    // detachFromFrame() will abort XHRs that haven't completed, which can\n    // trigger event listeners for 'abort'. These event listeners might detach\n    // the frame.\n    // TODO(dcheng): Investigate if this can be moved above the check that\n    // m_provisionalDocumentLoader hasn't changed.\n    if (!m_frame->client())\n        return false;\n    // No more events will be dispatched so detach the Document.\n    // TODO(yoav): Should we also be nullifying domWindow's document (or domWindow) since the doc is now detached?\n    if (m_frame->document())\n        m_frame->document()->detach();\n    m_documentLoader = m_provisionalDocumentLoader.release();\n\n    return true;\n}",
        "func": "bool FrameLoader::prepareForCommit()\n{\n    PluginScriptForbiddenScope forbidPluginDestructorScripting;\n    RefPtrWillBeRawPtr<DocumentLoader> pdl = m_provisionalDocumentLoader;\n\n    if (m_frame->document()) {\n        unsigned totalNodeCount = InstanceCounters::counterValue(InstanceCounters::NodeCounter);\n        int nodeCount = static_cast<int>(totalNodeCount);\n        for (Document* document : Document::liveDocumentSet()) {\n            if (document != m_frame->document())\n                nodeCount -= document->nodeCount();\n        }\n        ASSERT(nodeCount >= 0);\n        float ratio = static_cast<float>(nodeCount) / totalNodeCount;\n        ThreadState::current()->schedulePageNavigationGCIfNeeded(ratio);\n    }\n\n    // Don't allow any new child frames to load in this frame: attaching a new\n    // child frame during or after detaching children results in an attached\n    // frame on a detached DOM tree, which is bad.\n    SubframeLoadingDisabler disabler(m_frame->document());\n    if (m_documentLoader) {\n        client()->dispatchWillClose();\n        dispatchUnloadEvent();\n    }\n    m_frame->detachChildren();\n    // The previous calls to dispatchUnloadEvent() and detachChildren() can\n    // execute arbitrary script via things like unload events. If the executed\n    // script intiates a new load or causes the current frame to be detached,\n    // we need to abandon the current load.\n    if (pdl != m_provisionalDocumentLoader)\n        return false;\n    if (m_documentLoader) {\n        FrameNavigationDisabler navigationDisabler(*m_frame);\n        detachDocumentLoader(m_documentLoader);\n    }\n    // detachFromFrame() will abort XHRs that haven't completed, which can\n    // trigger event listeners for 'abort'. These event listeners might detach\n    // the frame.\n    // TODO(dcheng): Investigate if this can be moved above the check that\n    // m_provisionalDocumentLoader hasn't changed.\n    if (!m_frame->client())\n        return false;\n    // No more events will be dispatched so detach the Document.\n    // TODO(yoav): Should we also be nullifying domWindow's document (or domWindow) since the doc is now detached?\n    if (m_frame->document())\n        m_frame->document()->detach();\n    m_documentLoader = m_provisionalDocumentLoader.release();\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,10 @@\n         ThreadState::current()->schedulePageNavigationGCIfNeeded(ratio);\n     }\n \n+    // Don't allow any new child frames to load in this frame: attaching a new\n+    // child frame during or after detaching children results in an attached\n+    // frame on a detached DOM tree, which is bad.\n+    SubframeLoadingDisabler disabler(m_frame->document());\n     if (m_documentLoader) {\n         client()->dispatchWillClose();\n         dispatchUnloadEvent();",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    // Don't allow any new child frames to load in this frame: attaching a new",
                "    // child frame during or after detaching children results in an attached",
                "    // frame on a detached DOM tree, which is bad.",
                "    SubframeLoadingDisabler disabler(m_frame->document());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1623",
        "func_name": "chromium/WebLocalFrameImpl::dispatchUnloadEvent",
        "description": "The DOM implementation in Google Chrome before 48.0.2564.109 does not properly restrict frame-attach operations from occurring during or after frame-detach operations, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to FrameLoader.cpp, HTMLFrameOwnerElement.h, LocalFrame.cpp, and WebLocalFrameImpl.cpp.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/a4bcdcb1f8df4f7427e208201501a9d8e41e386b",
        "commit_title": "Disable sub frame loads more reliably in frame detach.",
        "commit_text": " Previously, guarding against attaching a new frame in frame detach was done by inspecting LoadEventProgress. There are certain operations, such as document.open(), that can cause LoadEventProgress to never advance, causing the guard to get skipped.    ",
        "func_before": "void WebLocalFrameImpl::dispatchUnloadEvent()\n{\n    if (!frame())\n        return;\n    frame()->loader().dispatchUnloadEvent();\n}",
        "func": "void WebLocalFrameImpl::dispatchUnloadEvent()\n{\n    if (!frame())\n        return;\n    SubframeLoadingDisabler disabler(frame()->document());\n    frame()->loader().dispatchUnloadEvent();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,5 +2,6 @@\n {\n     if (!frame())\n         return;\n+    SubframeLoadingDisabler disabler(frame()->document());\n     frame()->loader().dispatchUnloadEvent();\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    SubframeLoadingDisabler disabler(frame()->document());"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1625",
        "func_name": "chromium/SearchTabHelper::NavigateToURL",
        "description": "The Chrome Instant feature in Google Chrome before 48.0.2564.109 does not ensure that a New Tab Page (NTP) navigation target is on the most-visited or suggestions list, which allows remote attackers to bypass intended restrictions via unspecified vectors, related to instant_service.cc and search_tab_helper.cc.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/d523a41aed4e321d4c8197b5cccb73be23c8dcc2",
        "commit_title": "NTP: don't allow navigateContentWindow to navigate where it pleases.",
        "commit_text": "   ",
        "func_before": "void SearchTabHelper::NavigateToURL(const GURL& url,\n                                    WindowOpenDisposition disposition,\n                                    bool is_most_visited_item_url) {\n  if (is_most_visited_item_url) {\n    content::RecordAction(\n        base::UserMetricsAction(\"InstantExtended.MostVisitedClicked\"));\n  }\n\n  if (delegate_)\n    delegate_->NavigateOnThumbnailClick(url, disposition, web_contents_);\n}",
        "func": "void SearchTabHelper::NavigateToURL(const GURL& url,\n                                    WindowOpenDisposition disposition,\n                                    bool is_most_visited_item_url) {\n  // Make sure the specified URL is actually on the most visited or suggested\n  // items list.\n  // TODO(treib): The |is_most_visited_item_url| is meaningless: the way it's\n  // currently set by the renderer means it can't be used to decide which list\n  // of items (most visited or suggestions) to use for the validation check. Can\n  // it be removed?\n  if (!instant_service_ || !instant_service_->IsValidURLForNavigation(url))\n    return;\n\n  if (is_most_visited_item_url) {\n    content::RecordAction(\n        base::UserMetricsAction(\"InstantExtended.MostVisitedClicked\"));\n  }\n\n  if (delegate_)\n    delegate_->NavigateOnThumbnailClick(url, disposition, web_contents_);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,15 @@\n void SearchTabHelper::NavigateToURL(const GURL& url,\n                                     WindowOpenDisposition disposition,\n                                     bool is_most_visited_item_url) {\n+  // Make sure the specified URL is actually on the most visited or suggested\n+  // items list.\n+  // TODO(treib): The |is_most_visited_item_url| is meaningless: the way it's\n+  // currently set by the renderer means it can't be used to decide which list\n+  // of items (most visited or suggestions) to use for the validation check. Can\n+  // it be removed?\n+  if (!instant_service_ || !instant_service_->IsValidURLForNavigation(url))\n+    return;\n+\n   if (is_most_visited_item_url) {\n     content::RecordAction(\n         base::UserMetricsAction(\"InstantExtended.MostVisitedClicked\"));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  // Make sure the specified URL is actually on the most visited or suggested",
                "  // items list.",
                "  // TODO(treib): The |is_most_visited_item_url| is meaningless: the way it's",
                "  // currently set by the renderer means it can't be used to decide which list",
                "  // of items (most visited or suggestions) to use for the validation check. Can",
                "  // it be removed?",
                "  if (!instant_service_ || !instant_service_->IsValidURLForNavigation(url))",
                "    return;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1625",
        "func_name": "chromium/SearchBoxExtensionWrapper::NavigateContentWindow",
        "description": "The Chrome Instant feature in Google Chrome before 48.0.2564.109 does not ensure that a New Tab Page (NTP) navigation target is on the most-visited or suggestions list, which allows remote attackers to bypass intended restrictions via unspecified vectors, related to instant_service.cc and search_tab_helper.cc.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/d523a41aed4e321d4c8197b5cccb73be23c8dcc2",
        "commit_title": "NTP: don't allow navigateContentWindow to navigate where it pleases.",
        "commit_text": "   ",
        "func_before": "void SearchBoxExtensionWrapper::NavigateContentWindow(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  content::RenderView* render_view = GetRenderView();\n  if (!render_view) return;\n\n  if (!args.Length()) {\n    ThrowInvalidParameters(args);\n    return;\n  }\n\n  GURL destination_url;\n  bool is_most_visited_item_url = false;\n  // Check if the url is a rid\n  if (args[0]->IsNumber()) {\n    InstantMostVisitedItem item;\n    if (SearchBox::Get(render_view)->GetMostVisitedItemWithID(\n            args[0]->IntegerValue(), &item)) {\n      destination_url = item.url;\n      is_most_visited_item_url = true;\n    }\n  } else {\n    // Resolve the URL\n    const base::string16& possibly_relative_url = V8ValueToUTF16(args[0]);\n  GURL current_url = GetCurrentURL(render_view);\n    destination_url = internal::ResolveURL(current_url, possibly_relative_url);\n  }\n\n  DVLOG(1) << render_view << \" NavigateContentWindow: \" << destination_url;\n\n  // Navigate the main frame.\n  if (destination_url.is_valid() &&\n      !destination_url.SchemeIs(url::kJavaScriptScheme)) {\n    WindowOpenDisposition disposition = CURRENT_TAB;\n    if (args[1]->IsNumber()) {\n      disposition = (WindowOpenDisposition) args[1]->Uint32Value();\n    }\n    SearchBox::Get(render_view)->NavigateToURL(destination_url, disposition,\n                                               is_most_visited_item_url);\n  }\n}",
        "func": "void SearchBoxExtensionWrapper::NavigateContentWindow(\n    const v8::FunctionCallbackInfo<v8::Value>& args) {\n  content::RenderView* render_view = GetRenderView();\n  if (!render_view) return;\n\n  if (!args.Length()) {\n    ThrowInvalidParameters(args);\n    return;\n  }\n\n  GURL destination_url;\n  bool is_most_visited_item_url = false;\n  // Check if the url is a rid\n  if (args[0]->IsNumber()) {\n    InstantMostVisitedItem item;\n    if (SearchBox::Get(render_view)->GetMostVisitedItemWithID(\n            args[0]->IntegerValue(), &item)) {\n      destination_url = item.url;\n      is_most_visited_item_url = true;\n    }\n  } else {\n    // Resolve the URL\n    const base::string16& possibly_relative_url = V8ValueToUTF16(args[0]);\n  GURL current_url = GetCurrentURL(render_view);\n    destination_url = internal::ResolveURL(current_url, possibly_relative_url);\n  }\n\n  DVLOG(1) << render_view << \" NavigateContentWindow: \" << destination_url;\n\n  // Navigate the main frame. Note that the security checks are enforced by the\n  // browser process in InstantService::IsValidURLForNavigation(), but some\n  // simple checks here are useful for avoiding unnecessary IPCs.\n  if (destination_url.is_valid() &&\n      !destination_url.SchemeIs(url::kJavaScriptScheme)) {\n    WindowOpenDisposition disposition = CURRENT_TAB;\n    if (args[1]->IsNumber()) {\n      disposition = (WindowOpenDisposition) args[1]->Uint32Value();\n    }\n    SearchBox::Get(render_view)->NavigateToURL(destination_url, disposition,\n                                               is_most_visited_item_url);\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,7 +27,9 @@\n \n   DVLOG(1) << render_view << \" NavigateContentWindow: \" << destination_url;\n \n-  // Navigate the main frame.\n+  // Navigate the main frame. Note that the security checks are enforced by the\n+  // browser process in InstantService::IsValidURLForNavigation(), but some\n+  // simple checks here are useful for avoiding unnecessary IPCs.\n   if (destination_url.is_valid() &&\n       !destination_url.SchemeIs(url::kJavaScriptScheme)) {\n     WindowOpenDisposition disposition = CURRENT_TAB;",
        "diff_line_info": {
            "deleted_lines": [
                "  // Navigate the main frame."
            ],
            "added_lines": [
                "  // Navigate the main frame. Note that the security checks are enforced by the",
                "  // browser process in InstantService::IsValidURLForNavigation(), but some",
                "  // simple checks here are useful for avoiding unnecessary IPCs."
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1627",
        "func_name": "chromium/DevToolsUIBindings::LoadNetworkResource",
        "description": "The Developer Tools (aka DevTools) subsystem in Google Chrome before 48.0.2564.109 does not validate URL schemes and ensure that the remoteBase parameter is associated with a chrome-devtools-frontend.appspot.com URL, which allows remote attackers to bypass intended access restrictions via a crafted URL, related to browser/devtools/devtools_ui_bindings.cc and WebKit/Source/devtools/front_end/Runtime.js.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/e8ecfb59d4f906e0ab40b6046406b8af1366cb10",
        "commit_title": "[DevTools] Whitelist remoteBase and loadNetworkResource schemes.",
        "commit_text": "   ",
        "func_before": "void DevToolsUIBindings::LoadNetworkResource(const DispatchCallback& callback,\n                                             const std::string& url,\n                                             const std::string& headers,\n                                             int stream_id) {\n  GURL gurl(url);\n  if (!gurl.is_valid()) {\n    base::DictionaryValue response;\n    response.SetInteger(\"statusCode\", 404);\n    callback.Run(&response);\n    return;\n  }\n\n  net::URLFetcher* fetcher =\n      net::URLFetcher::Create(gurl, net::URLFetcher::GET, this).release();\n  pending_requests_[fetcher] = callback;\n  fetcher->SetRequestContext(profile_->GetRequestContext());\n  fetcher->SetExtraRequestHeaders(headers);\n  fetcher->SaveResponseWithWriter(scoped_ptr<net::URLFetcherResponseWriter>(\n      new ResponseWriter(weak_factory_.GetWeakPtr(), stream_id)));\n  fetcher->Start();\n}",
        "func": "void DevToolsUIBindings::LoadNetworkResource(const DispatchCallback& callback,\n                                             const std::string& url,\n                                             const std::string& headers,\n                                             int stream_id) {\n  GURL gurl(url);\n  bool schemeIsAllowed = gurl.is_valid() &&\n      (gurl.SchemeIs(url::kHttpScheme) || gurl.SchemeIs(url::kHttpsScheme) ||\n       gurl.SchemeIs(url::kDataScheme) || gurl.SchemeIs(url::kFtpScheme));\n  if (!gurl.is_valid() || !schemeIsAllowed) {\n    base::DictionaryValue response;\n    response.SetInteger(\"statusCode\", 404);\n    callback.Run(&response);\n    return;\n  }\n\n  net::URLFetcher* fetcher =\n      net::URLFetcher::Create(gurl, net::URLFetcher::GET, this).release();\n  pending_requests_[fetcher] = callback;\n  fetcher->SetRequestContext(profile_->GetRequestContext());\n  fetcher->SetExtraRequestHeaders(headers);\n  fetcher->SaveResponseWithWriter(scoped_ptr<net::URLFetcherResponseWriter>(\n      new ResponseWriter(weak_factory_.GetWeakPtr(), stream_id)));\n  fetcher->Start();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,10 @@\n                                              const std::string& headers,\n                                              int stream_id) {\n   GURL gurl(url);\n-  if (!gurl.is_valid()) {\n+  bool schemeIsAllowed = gurl.is_valid() &&\n+      (gurl.SchemeIs(url::kHttpScheme) || gurl.SchemeIs(url::kHttpsScheme) ||\n+       gurl.SchemeIs(url::kDataScheme) || gurl.SchemeIs(url::kFtpScheme));\n+  if (!gurl.is_valid() || !schemeIsAllowed) {\n     base::DictionaryValue response;\n     response.SetInteger(\"statusCode\", 404);\n     callback.Run(&response);",
        "diff_line_info": {
            "deleted_lines": [
                "  if (!gurl.is_valid()) {"
            ],
            "added_lines": [
                "  bool schemeIsAllowed = gurl.is_valid() &&",
                "      (gurl.SchemeIs(url::kHttpScheme) || gurl.SchemeIs(url::kHttpsScheme) ||",
                "       gurl.SchemeIs(url::kDataScheme) || gurl.SchemeIs(url::kFtpScheme));",
                "  if (!gurl.is_valid() || !schemeIsAllowed) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8133",
        "func_name": "torvalds/linux/do_set_thread_area",
        "description": "arch/x86/kernel/tls.c in the Thread Local Storage (TLS) implementation in the Linux kernel through 3.18.1 allows local users to bypass the espfix protection mechanism, and consequently makes it easier for local users to bypass the ASLR protection mechanism, via a crafted application that makes a set_thread_area system call and later reads a 16-bit value.",
        "git_url": "https://github.com/torvalds/linux/commit/41bdc78544b8a93a9c6814b8bbbfef966272abbe",
        "commit_title": "x86/tls: Validate TLS entries to protect espfix",
        "commit_text": " Installing a 16-bit RW data segment into the GDT defeats espfix. AFAICT this will not affect glibc, Wine, or dosemu at all.  Cc: stable@vger.kernel.org Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com> Cc: Linus Torvalds <torvalds@linux-foundation.org> Cc: security@kernel.org <security@kernel.org> Cc: Willy Tarreau <w@1wt.eu>",
        "func_before": "int do_set_thread_area(struct task_struct *p, int idx,\n\t\t       struct user_desc __user *u_info,\n\t\t       int can_allocate)\n{\n\tstruct user_desc info;\n\n\tif (copy_from_user(&info, u_info, sizeof(info)))\n\t\treturn -EFAULT;\n\n\tif (idx == -1)\n\t\tidx = info.entry_number;\n\n\t/*\n\t * index -1 means the kernel should try to find and\n\t * allocate an empty descriptor:\n\t */\n\tif (idx == -1 && can_allocate) {\n\t\tidx = get_free_idx();\n\t\tif (idx < 0)\n\t\t\treturn idx;\n\t\tif (put_user(idx, &u_info->entry_number))\n\t\t\treturn -EFAULT;\n\t}\n\n\tif (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)\n\t\treturn -EINVAL;\n\n\tset_tls_desc(p, idx, &info, 1);\n\n\treturn 0;\n}",
        "func": "int do_set_thread_area(struct task_struct *p, int idx,\n\t\t       struct user_desc __user *u_info,\n\t\t       int can_allocate)\n{\n\tstruct user_desc info;\n\n\tif (copy_from_user(&info, u_info, sizeof(info)))\n\t\treturn -EFAULT;\n\n\tif (!tls_desc_okay(&info))\n\t\treturn -EINVAL;\n\n\tif (idx == -1)\n\t\tidx = info.entry_number;\n\n\t/*\n\t * index -1 means the kernel should try to find and\n\t * allocate an empty descriptor:\n\t */\n\tif (idx == -1 && can_allocate) {\n\t\tidx = get_free_idx();\n\t\tif (idx < 0)\n\t\t\treturn idx;\n\t\tif (put_user(idx, &u_info->entry_number))\n\t\t\treturn -EFAULT;\n\t}\n\n\tif (idx < GDT_ENTRY_TLS_MIN || idx > GDT_ENTRY_TLS_MAX)\n\t\treturn -EINVAL;\n\n\tset_tls_desc(p, idx, &info, 1);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,9 @@\n \n \tif (copy_from_user(&info, u_info, sizeof(info)))\n \t\treturn -EFAULT;\n+\n+\tif (!tls_desc_okay(&info))\n+\t\treturn -EINVAL;\n \n \tif (idx == -1)\n \t\tidx = info.entry_number;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!tls_desc_okay(&info))",
                "\t\treturn -EINVAL;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8133",
        "func_name": "torvalds/linux/regset_tls_set",
        "description": "arch/x86/kernel/tls.c in the Thread Local Storage (TLS) implementation in the Linux kernel through 3.18.1 allows local users to bypass the espfix protection mechanism, and consequently makes it easier for local users to bypass the ASLR protection mechanism, via a crafted application that makes a set_thread_area system call and later reads a 16-bit value.",
        "git_url": "https://github.com/torvalds/linux/commit/41bdc78544b8a93a9c6814b8bbbfef966272abbe",
        "commit_title": "x86/tls: Validate TLS entries to protect espfix",
        "commit_text": " Installing a 16-bit RW data segment into the GDT defeats espfix. AFAICT this will not affect glibc, Wine, or dosemu at all.  Cc: stable@vger.kernel.org Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com> Cc: Linus Torvalds <torvalds@linux-foundation.org> Cc: security@kernel.org <security@kernel.org> Cc: Willy Tarreau <w@1wt.eu>",
        "func_before": "int regset_tls_set(struct task_struct *target, const struct user_regset *regset,\n\t\t   unsigned int pos, unsigned int count,\n\t\t   const void *kbuf, const void __user *ubuf)\n{\n\tstruct user_desc infobuf[GDT_ENTRY_TLS_ENTRIES];\n\tconst struct user_desc *info;\n\n\tif (pos >= GDT_ENTRY_TLS_ENTRIES * sizeof(struct user_desc) ||\n\t    (pos % sizeof(struct user_desc)) != 0 ||\n\t    (count % sizeof(struct user_desc)) != 0)\n\t\treturn -EINVAL;\n\n\tif (kbuf)\n\t\tinfo = kbuf;\n\telse if (__copy_from_user(infobuf, ubuf, count))\n\t\treturn -EFAULT;\n\telse\n\t\tinfo = infobuf;\n\n\tset_tls_desc(target,\n\t\t     GDT_ENTRY_TLS_MIN + (pos / sizeof(struct user_desc)),\n\t\t     info, count / sizeof(struct user_desc));\n\n\treturn 0;\n}",
        "func": "int regset_tls_set(struct task_struct *target, const struct user_regset *regset,\n\t\t   unsigned int pos, unsigned int count,\n\t\t   const void *kbuf, const void __user *ubuf)\n{\n\tstruct user_desc infobuf[GDT_ENTRY_TLS_ENTRIES];\n\tconst struct user_desc *info;\n\tint i;\n\n\tif (pos >= GDT_ENTRY_TLS_ENTRIES * sizeof(struct user_desc) ||\n\t    (pos % sizeof(struct user_desc)) != 0 ||\n\t    (count % sizeof(struct user_desc)) != 0)\n\t\treturn -EINVAL;\n\n\tif (kbuf)\n\t\tinfo = kbuf;\n\telse if (__copy_from_user(infobuf, ubuf, count))\n\t\treturn -EFAULT;\n\telse\n\t\tinfo = infobuf;\n\n\tfor (i = 0; i < count / sizeof(struct user_desc); i++)\n\t\tif (!tls_desc_okay(info + i))\n\t\t\treturn -EINVAL;\n\n\tset_tls_desc(target,\n\t\t     GDT_ENTRY_TLS_MIN + (pos / sizeof(struct user_desc)),\n\t\t     info, count / sizeof(struct user_desc));\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,7 @@\n {\n \tstruct user_desc infobuf[GDT_ENTRY_TLS_ENTRIES];\n \tconst struct user_desc *info;\n+\tint i;\n \n \tif (pos >= GDT_ENTRY_TLS_ENTRIES * sizeof(struct user_desc) ||\n \t    (pos % sizeof(struct user_desc)) != 0 ||\n@@ -17,6 +18,10 @@\n \telse\n \t\tinfo = infobuf;\n \n+\tfor (i = 0; i < count / sizeof(struct user_desc); i++)\n+\t\tif (!tls_desc_okay(info + i))\n+\t\t\treturn -EINVAL;\n+\n \tset_tls_desc(target,\n \t\t     GDT_ENTRY_TLS_MIN + (pos / sizeof(struct user_desc)),\n \t\t     info, count / sizeof(struct user_desc));",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tint i;",
                "\tfor (i = 0; i < count / sizeof(struct user_desc); i++)",
                "\t\tif (!tls_desc_okay(info + i))",
                "\t\t\treturn -EINVAL;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2014-2209",
        "func_name": "facebook/hhvm/do_change_user",
        "description": "Facebook HipHop Virtual Machine (HHVM) before 3.1.0 does not drop supplemental group memberships within hphp/util/capability.cpp and hphp/util/light-process.cpp, which allows remote attackers to bypass intended access restrictions by leveraging group permissions for a file or directory.",
        "git_url": "https://github.com/facebook/hhvm/commit/851fff90a9b7461df2393af32239ba217bc25946",
        "commit_title": "Drop supplementary groups when changing to non-root",
        "commit_text": " Summary: When running HHVM as a non-root user, UID and GID are updated correctly but supplementary groups are not dropped properly. This runs initgroups inside main thread and lightprocess threads to reset groups to those of the specified non-root user.  Reviewed By: @markw65  Differential Revision: D1193229",
        "func_before": "static void do_change_user(FILE *fin, FILE *fout) {\n  std::string uname;\n  lwp_read(fin, uname);\n  if (uname.length() > 0) {\n    struct passwd *pw = getpwnam(uname.c_str());\n    if (pw) {\n      if (pw->pw_gid) {\n        setgid(pw->pw_gid);\n      }\n      if (pw->pw_uid) {\n        setuid(pw->pw_uid);\n      }\n    }\n  }\n}",
        "func": "static void do_change_user(FILE *fin, FILE *fout) {\n  std::string uname;\n  lwp_read(fin, uname);\n  if (uname.length() > 0) {\n    struct passwd *pw = getpwnam(uname.c_str());\n    if (pw) {\n      if (pw->pw_gid) {\n        initgroups(pw->pw_name, pw->pw_gid);\n        setgid(pw->pw_gid);\n      }\n      if (pw->pw_uid) {\n        setuid(pw->pw_uid);\n      }\n    }\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,6 +5,7 @@\n     struct passwd *pw = getpwnam(uname.c_str());\n     if (pw) {\n       if (pw->pw_gid) {\n+        initgroups(pw->pw_name, pw->pw_gid);\n         setgid(pw->pw_gid);\n       }\n       if (pw->pw_uid) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        initgroups(pw->pw_name, pw->pw_gid);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-2209",
        "func_name": "facebook/hhvm/Capability::ChangeUnixUser",
        "description": "Facebook HipHop Virtual Machine (HHVM) before 3.1.0 does not drop supplemental group memberships within hphp/util/capability.cpp and hphp/util/light-process.cpp, which allows remote attackers to bypass intended access restrictions by leveraging group permissions for a file or directory.",
        "git_url": "https://github.com/facebook/hhvm/commit/851fff90a9b7461df2393af32239ba217bc25946",
        "commit_title": "Drop supplementary groups when changing to non-root",
        "commit_text": " Summary: When running HHVM as a non-root user, UID and GID are updated correctly but supplementary groups are not dropped properly. This runs initgroups inside main thread and lightprocess threads to reset groups to those of the specified non-root user.  Reviewed By: @markw65  Differential Revision: D1193229",
        "func_before": "bool Capability::ChangeUnixUser(uid_t uid) {\n  if (setInitialCapabilities()) {\n    struct passwd *pw;\n\n    if ((pw = getpwuid(uid)) == nullptr) {\n      Logger::Error(\"unable to getpwuid(%d): %s\", uid,\n                    folly::errnoStr(errno).c_str());\n      return false;\n    }\n\n    if (pw->pw_gid == 0 || setgid(pw->pw_gid) < 0) {\n      Logger::Error(\"unable to drop gid privs: %s\",\n                    folly::errnoStr(errno).c_str());\n      return false;\n    }\n\n    if (uid == 0 || setuid(uid) < 0) {\n      Logger::Error(\"unable to drop uid privs: %s\",\n                    folly::errnoStr(errno).c_str());\n      return false;\n    }\n\n    if (!setMinimalCapabilities()) {\n      Logger::Error(\"unable to set minimal server capabiltiies\");\n      return false;\n    }\n    return true;\n  }\n  return false;\n}",
        "func": "bool Capability::ChangeUnixUser(uid_t uid) {\n  if (setInitialCapabilities()) {\n    struct passwd *pw;\n\n    if ((pw = getpwuid(uid)) == nullptr) {\n      Logger::Error(\"unable to getpwuid(%d): %s\", uid,\n                    folly::errnoStr(errno).c_str());\n      return false;\n    }\n\n    if (initgroups(pw->pw_name, pw->pw_gid) < 0) {\n      Logger::Error(\"unable to drop supplementary group privs: %s\",\n                    folly::errnoStr(errno).c_str());\n      return false;\n    }\n\n    if (pw->pw_gid == 0 || setgid(pw->pw_gid) < 0) {\n      Logger::Error(\"unable to drop gid privs: %s\",\n                    folly::errnoStr(errno).c_str());\n      return false;\n    }\n\n    if (uid == 0 || setuid(uid) < 0) {\n      Logger::Error(\"unable to drop uid privs: %s\",\n                    folly::errnoStr(errno).c_str());\n      return false;\n    }\n\n    if (!setMinimalCapabilities()) {\n      Logger::Error(\"unable to set minimal server capabiltiies\");\n      return false;\n    }\n    return true;\n  }\n  return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,12 @@\n \n     if ((pw = getpwuid(uid)) == nullptr) {\n       Logger::Error(\"unable to getpwuid(%d): %s\", uid,\n+                    folly::errnoStr(errno).c_str());\n+      return false;\n+    }\n+\n+    if (initgroups(pw->pw_name, pw->pw_gid) < 0) {\n+      Logger::Error(\"unable to drop supplementary group privs: %s\",\n                     folly::errnoStr(errno).c_str());\n       return false;\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "                    folly::errnoStr(errno).c_str());",
                "      return false;",
                "    }",
                "",
                "    if (initgroups(pw->pw_name, pw->pw_gid) < 0) {",
                "      Logger::Error(\"unable to drop supplementary group privs: %s\","
            ]
        }
    },
    {
        "cve_id": "CVE-2010-1641",
        "func_name": "torvalds/linux/do_gfs2_set_flags",
        "description": "The do_gfs2_set_flags function in fs/gfs2/file.c in the Linux kernel before 2.6.34-git10 does not verify the ownership of a file, which allows local users to bypass intended access restrictions via a SETFLAGS ioctl request.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7df0e0397b9a18358573274db9fdab991941062f",
        "commit_title": "We should be checking for the ownership of the file for which",
        "commit_text": "flags are being set, rather than just for write access.  ",
        "func_before": "static int do_gfs2_set_flags(struct file *filp, u32 reqflags, u32 mask)\n{\n\tstruct inode *inode = filp->f_path.dentry->d_inode;\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct buffer_head *bh;\n\tstruct gfs2_holder gh;\n\tint error;\n\tu32 new_flags, flags;\n\n\terror = mnt_want_write(filp->f_path.mnt);\n\tif (error)\n\t\treturn error;\n\n\terror = gfs2_glock_nq_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &gh);\n\tif (error)\n\t\tgoto out_drop_write;\n\n\tflags = ip->i_diskflags;\n\tnew_flags = (flags & ~mask) | (reqflags & mask);\n\tif ((new_flags ^ flags) == 0)\n\t\tgoto out;\n\n\terror = -EINVAL;\n\tif ((new_flags ^ flags) & ~GFS2_FLAGS_USER_SET)\n\t\tgoto out;\n\n\terror = -EPERM;\n\tif (IS_IMMUTABLE(inode) && (new_flags & GFS2_DIF_IMMUTABLE))\n\t\tgoto out;\n\tif (IS_APPEND(inode) && (new_flags & GFS2_DIF_APPENDONLY))\n\t\tgoto out;\n\tif (((new_flags ^ flags) & GFS2_DIF_IMMUTABLE) &&\n\t    !capable(CAP_LINUX_IMMUTABLE))\n\t\tgoto out;\n\tif (!IS_IMMUTABLE(inode)) {\n\t\terror = gfs2_permission(inode, MAY_WRITE);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\tif ((flags ^ new_flags) & GFS2_DIF_JDATA) {\n\t\tif (flags & GFS2_DIF_JDATA)\n\t\t\tgfs2_log_flush(sdp, ip->i_gl);\n\t\terror = filemap_fdatawrite(inode->i_mapping);\n\t\tif (error)\n\t\t\tgoto out;\n\t\terror = filemap_fdatawait(inode->i_mapping);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\terror = gfs2_trans_begin(sdp, RES_DINODE, 0);\n\tif (error)\n\t\tgoto out;\n\terror = gfs2_meta_inode_buffer(ip, &bh);\n\tif (error)\n\t\tgoto out_trans_end;\n\tgfs2_trans_add_bh(ip->i_gl, bh, 1);\n\tip->i_diskflags = new_flags;\n\tgfs2_dinode_out(ip, bh->b_data);\n\tbrelse(bh);\n\tgfs2_set_inode_flags(inode);\n\tgfs2_set_aops(inode);\nout_trans_end:\n\tgfs2_trans_end(sdp);\nout:\n\tgfs2_glock_dq_uninit(&gh);\nout_drop_write:\n\tmnt_drop_write(filp->f_path.mnt);\n\treturn error;\n}",
        "func": "static int do_gfs2_set_flags(struct file *filp, u32 reqflags, u32 mask)\n{\n\tstruct inode *inode = filp->f_path.dentry->d_inode;\n\tstruct gfs2_inode *ip = GFS2_I(inode);\n\tstruct gfs2_sbd *sdp = GFS2_SB(inode);\n\tstruct buffer_head *bh;\n\tstruct gfs2_holder gh;\n\tint error;\n\tu32 new_flags, flags;\n\n\terror = mnt_want_write(filp->f_path.mnt);\n\tif (error)\n\t\treturn error;\n\n\terror = gfs2_glock_nq_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &gh);\n\tif (error)\n\t\tgoto out_drop_write;\n\n\terror = -EACCES;\n\tif (!is_owner_or_cap(inode))\n\t\tgoto out;\n\n\terror = 0;\n\tflags = ip->i_diskflags;\n\tnew_flags = (flags & ~mask) | (reqflags & mask);\n\tif ((new_flags ^ flags) == 0)\n\t\tgoto out;\n\n\terror = -EINVAL;\n\tif ((new_flags ^ flags) & ~GFS2_FLAGS_USER_SET)\n\t\tgoto out;\n\n\terror = -EPERM;\n\tif (IS_IMMUTABLE(inode) && (new_flags & GFS2_DIF_IMMUTABLE))\n\t\tgoto out;\n\tif (IS_APPEND(inode) && (new_flags & GFS2_DIF_APPENDONLY))\n\t\tgoto out;\n\tif (((new_flags ^ flags) & GFS2_DIF_IMMUTABLE) &&\n\t    !capable(CAP_LINUX_IMMUTABLE))\n\t\tgoto out;\n\tif (!IS_IMMUTABLE(inode)) {\n\t\terror = gfs2_permission(inode, MAY_WRITE);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\tif ((flags ^ new_flags) & GFS2_DIF_JDATA) {\n\t\tif (flags & GFS2_DIF_JDATA)\n\t\t\tgfs2_log_flush(sdp, ip->i_gl);\n\t\terror = filemap_fdatawrite(inode->i_mapping);\n\t\tif (error)\n\t\t\tgoto out;\n\t\terror = filemap_fdatawait(inode->i_mapping);\n\t\tif (error)\n\t\t\tgoto out;\n\t}\n\terror = gfs2_trans_begin(sdp, RES_DINODE, 0);\n\tif (error)\n\t\tgoto out;\n\terror = gfs2_meta_inode_buffer(ip, &bh);\n\tif (error)\n\t\tgoto out_trans_end;\n\tgfs2_trans_add_bh(ip->i_gl, bh, 1);\n\tip->i_diskflags = new_flags;\n\tgfs2_dinode_out(ip, bh->b_data);\n\tbrelse(bh);\n\tgfs2_set_inode_flags(inode);\n\tgfs2_set_aops(inode);\nout_trans_end:\n\tgfs2_trans_end(sdp);\nout:\n\tgfs2_glock_dq_uninit(&gh);\nout_drop_write:\n\tmnt_drop_write(filp->f_path.mnt);\n\treturn error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,6 +16,11 @@\n \tif (error)\n \t\tgoto out_drop_write;\n \n+\terror = -EACCES;\n+\tif (!is_owner_or_cap(inode))\n+\t\tgoto out;\n+\n+\terror = 0;\n \tflags = ip->i_diskflags;\n \tnew_flags = (flags & ~mask) | (reqflags & mask);\n \tif ((new_flags ^ flags) == 0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\terror = -EACCES;",
                "\tif (!is_owner_or_cap(inode))",
                "\t\tgoto out;",
                "",
                "\terror = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-1641",
        "func_name": "torvalds/linux/gfs2_set_flags",
        "description": "The do_gfs2_set_flags function in fs/gfs2/file.c in the Linux kernel before 2.6.34-git10 does not verify the ownership of a file, which allows local users to bypass intended access restrictions via a SETFLAGS ioctl request.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7df0e0397b9a18358573274db9fdab991941062f",
        "commit_title": "We should be checking for the ownership of the file for which",
        "commit_text": "flags are being set, rather than just for write access.  ",
        "func_before": "static int gfs2_set_flags(struct file *filp, u32 __user *ptr)\n{\n\tstruct inode *inode = filp->f_path.dentry->d_inode;\n\tu32 fsflags, gfsflags;\n\tif (get_user(fsflags, ptr))\n\t\treturn -EFAULT;\n\tgfsflags = fsflags_cvt(fsflags_to_gfs2, fsflags);\n\tif (!S_ISDIR(inode->i_mode)) {\n\t\tif (gfsflags & GFS2_DIF_INHERIT_JDATA)\n\t\t\tgfsflags ^= (GFS2_DIF_JDATA | GFS2_DIF_INHERIT_JDATA);\n\t\treturn do_gfs2_set_flags(filp, gfsflags, ~0);\n\t}\n\treturn do_gfs2_set_flags(filp, gfsflags, ~GFS2_DIF_JDATA);\n}",
        "func": "static int gfs2_set_flags(struct file *filp, u32 __user *ptr)\n{\n\tstruct inode *inode = filp->f_path.dentry->d_inode;\n\tu32 fsflags, gfsflags;\n\n\tif (get_user(fsflags, ptr))\n\t\treturn -EFAULT;\n\n\tgfsflags = fsflags_cvt(fsflags_to_gfs2, fsflags);\n\tif (!S_ISDIR(inode->i_mode)) {\n\t\tif (gfsflags & GFS2_DIF_INHERIT_JDATA)\n\t\t\tgfsflags ^= (GFS2_DIF_JDATA | GFS2_DIF_INHERIT_JDATA);\n\t\treturn do_gfs2_set_flags(filp, gfsflags, ~0);\n\t}\n\treturn do_gfs2_set_flags(filp, gfsflags, ~GFS2_DIF_JDATA);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,8 +2,10 @@\n {\n \tstruct inode *inode = filp->f_path.dentry->d_inode;\n \tu32 fsflags, gfsflags;\n+\n \tif (get_user(fsflags, ptr))\n \t\treturn -EFAULT;\n+\n \tgfsflags = fsflags_cvt(fsflags_to_gfs2, fsflags);\n \tif (!S_ISDIR(inode->i_mode)) {\n \t\tif (gfsflags & GFS2_DIF_INHERIT_JDATA)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2010-2071",
        "func_name": "torvalds/linux/btrfs_xattr_acl_set",
        "description": "The btrfs_xattr_set_acl function in fs/btrfs/acl.c in btrfs in the Linux kernel 2.6.34 and earlier does not check file ownership before setting an ACL, which allows local users to bypass file permissions by setting arbitrary ACLs, as demonstrated using setfacl.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=2f26afba",
        "commit_title": "On btrfs, do the following",
        "commit_text": "------------------ # su user1 # cd btrfs-part/ # touch aaa # getfacl aaa   # file: aaa   # owner: user1   # group: user1   user::rw-   group::rw-   other::r-- # su user2 # cd btrfs-part/ # setfacl -m u::rwx aaa # getfacl aaa   # file: aaa   # owner: user1   # group: user1   user::rwx           <- successed to setfacl   group::rw-   other::r-- ------------------ but we should prohibit it that user2 changing user1's acl. In fact, on ext3 and other fs, a message occurs:   setfacl: aaa: Operation not permitted  This patch fixed it. ",
        "func_before": "static int btrfs_xattr_acl_set(struct dentry *dentry, const char *name,\n\t\tconst void *value, size_t size, int flags, int type)\n{\n\tint ret;\n\tstruct posix_acl *acl = NULL;\n\n\tif (value) {\n\t\tacl = posix_acl_from_xattr(value, size);\n\t\tif (acl == NULL) {\n\t\t\tvalue = NULL;\n\t\t\tsize = 0;\n\t\t} else if (IS_ERR(acl)) {\n\t\t\treturn PTR_ERR(acl);\n\t\t}\n\t}\n\n\tret = btrfs_set_acl(NULL, dentry->d_inode, acl, type);\n\n\tposix_acl_release(acl);\n\n\treturn ret;\n}",
        "func": "static int btrfs_xattr_acl_set(struct dentry *dentry, const char *name,\n\t\tconst void *value, size_t size, int flags, int type)\n{\n\tint ret;\n\tstruct posix_acl *acl = NULL;\n\n\tif (!is_owner_or_cap(dentry->d_inode))\n\t\treturn -EPERM;\n\n\tif (value) {\n\t\tacl = posix_acl_from_xattr(value, size);\n\t\tif (acl == NULL) {\n\t\t\tvalue = NULL;\n\t\t\tsize = 0;\n\t\t} else if (IS_ERR(acl)) {\n\t\t\treturn PTR_ERR(acl);\n\t\t}\n\t}\n\n\tret = btrfs_set_acl(NULL, dentry->d_inode, acl, type);\n\n\tposix_acl_release(acl);\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,9 @@\n {\n \tint ret;\n \tstruct posix_acl *acl = NULL;\n+\n+\tif (!is_owner_or_cap(dentry->d_inode))\n+\t\treturn -EPERM;\n \n \tif (value) {\n \t\tacl = posix_acl_from_xattr(value, size);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!is_owner_or_cap(dentry->d_inode))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-3448",
        "func_name": "torvalds/linux/ibm_init",
        "description": "drivers/platform/x86/thinkpad_acpi.c in the Linux kernel before 2.6.34 on ThinkPad devices, when the X.Org X server is used, does not properly restrict access to the video output control state, which allows local users to cause a denial of service (system hang) via a (1) read or (2) write operation.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=b525c06cdbd8a3963f0173ccd23f9147d4c384b5",
        "commit_title": "Given the right combination of ThinkPad and X.org, just reading the",
        "commit_text": "video output control state is enough to hard-crash X.org.  Until the day I somehow find out a model or BIOS cut date to not provide this feature to ThinkPads that can do video switching through X RandR, change permissions so that only processes with CAP_SYS_ADMIN can access any sort of video output control state.  This bug could be considered a local DoS I suppose, as it allows any non-privledged local user to cause some versions of X.org to hard-crash some ThinkPads.  Cc: stable@kernel.org ",
        "func_before": "static int __init ibm_init(struct ibm_init_struct *iibm)\n{\n\tint ret;\n\tstruct ibm_struct *ibm = iibm->data;\n\tstruct proc_dir_entry *entry;\n\n\tBUG_ON(ibm == NULL);\n\n\tINIT_LIST_HEAD(&ibm->all_drivers);\n\n\tif (ibm->flags.experimental && !experimental)\n\t\treturn 0;\n\n\tdbg_printk(TPACPI_DBG_INIT,\n\t\t\"probing for %s\\n\", ibm->name);\n\n\tif (iibm->init) {\n\t\tret = iibm->init(iibm);\n\t\tif (ret > 0)\n\t\t\treturn 0;\t/* probe failed */\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tibm->flags.init_called = 1;\n\t}\n\n\tif (ibm->acpi) {\n\t\tif (ibm->acpi->hid) {\n\t\t\tret = register_tpacpi_subdriver(ibm);\n\t\t\tif (ret)\n\t\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (ibm->acpi->notify) {\n\t\t\tret = setup_acpi_notify(ibm);\n\t\t\tif (ret == -ENODEV) {\n\t\t\t\tprintk(TPACPI_NOTICE \"disabling subdriver %s\\n\",\n\t\t\t\t\tibm->name);\n\t\t\t\tret = 0;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\tif (ret < 0)\n\t\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tdbg_printk(TPACPI_DBG_INIT,\n\t\t\"%s installed\\n\", ibm->name);\n\n\tif (ibm->read) {\n\t\tmode_t mode;\n\n\t\tmode = S_IRUGO;\n\t\tif (ibm->write)\n\t\t\tmode |= S_IWUSR;\n\t\tentry = proc_create_data(ibm->name, mode, proc_dir,\n\t\t\t\t\t &dispatch_proc_fops, ibm);\n\t\tif (!entry) {\n\t\t\tprintk(TPACPI_ERR \"unable to create proc entry %s\\n\",\n\t\t\t       ibm->name);\n\t\t\tret = -ENODEV;\n\t\t\tgoto err_out;\n\t\t}\n\t\tibm->flags.proc_created = 1;\n\t}\n\n\tlist_add_tail(&ibm->all_drivers, &tpacpi_all_drivers);\n\n\treturn 0;\n\nerr_out:\n\tdbg_printk(TPACPI_DBG_INIT,\n\t\t\"%s: at error exit path with result %d\\n\",\n\t\tibm->name, ret);\n\n\tibm_exit(ibm);\n\treturn (ret < 0)? ret : 0;\n}",
        "func": "static int __init ibm_init(struct ibm_init_struct *iibm)\n{\n\tint ret;\n\tstruct ibm_struct *ibm = iibm->data;\n\tstruct proc_dir_entry *entry;\n\n\tBUG_ON(ibm == NULL);\n\n\tINIT_LIST_HEAD(&ibm->all_drivers);\n\n\tif (ibm->flags.experimental && !experimental)\n\t\treturn 0;\n\n\tdbg_printk(TPACPI_DBG_INIT,\n\t\t\"probing for %s\\n\", ibm->name);\n\n\tif (iibm->init) {\n\t\tret = iibm->init(iibm);\n\t\tif (ret > 0)\n\t\t\treturn 0;\t/* probe failed */\n\t\tif (ret)\n\t\t\treturn ret;\n\n\t\tibm->flags.init_called = 1;\n\t}\n\n\tif (ibm->acpi) {\n\t\tif (ibm->acpi->hid) {\n\t\t\tret = register_tpacpi_subdriver(ibm);\n\t\t\tif (ret)\n\t\t\t\tgoto err_out;\n\t\t}\n\n\t\tif (ibm->acpi->notify) {\n\t\t\tret = setup_acpi_notify(ibm);\n\t\t\tif (ret == -ENODEV) {\n\t\t\t\tprintk(TPACPI_NOTICE \"disabling subdriver %s\\n\",\n\t\t\t\t\tibm->name);\n\t\t\t\tret = 0;\n\t\t\t\tgoto err_out;\n\t\t\t}\n\t\t\tif (ret < 0)\n\t\t\t\tgoto err_out;\n\t\t}\n\t}\n\n\tdbg_printk(TPACPI_DBG_INIT,\n\t\t\"%s installed\\n\", ibm->name);\n\n\tif (ibm->read) {\n\t\tmode_t mode = iibm->base_procfs_mode;\n\n\t\tif (!mode)\n\t\t\tmode = S_IRUGO;\n\t\tif (ibm->write)\n\t\t\tmode |= S_IWUSR;\n\t\tentry = proc_create_data(ibm->name, mode, proc_dir,\n\t\t\t\t\t &dispatch_proc_fops, ibm);\n\t\tif (!entry) {\n\t\t\tprintk(TPACPI_ERR \"unable to create proc entry %s\\n\",\n\t\t\t       ibm->name);\n\t\t\tret = -ENODEV;\n\t\t\tgoto err_out;\n\t\t}\n\t\tibm->flags.proc_created = 1;\n\t}\n\n\tlist_add_tail(&ibm->all_drivers, &tpacpi_all_drivers);\n\n\treturn 0;\n\nerr_out:\n\tdbg_printk(TPACPI_DBG_INIT,\n\t\t\"%s: at error exit path with result %d\\n\",\n\t\tibm->name, ret);\n\n\tibm_exit(ibm);\n\treturn (ret < 0)? ret : 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -48,9 +48,10 @@\n \t\t\"%s installed\\n\", ibm->name);\n \n \tif (ibm->read) {\n-\t\tmode_t mode;\n+\t\tmode_t mode = iibm->base_procfs_mode;\n \n-\t\tmode = S_IRUGO;\n+\t\tif (!mode)\n+\t\t\tmode = S_IRUGO;\n \t\tif (ibm->write)\n \t\t\tmode |= S_IWUSR;\n \t\tentry = proc_create_data(ibm->name, mode, proc_dir,",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tmode_t mode;",
                "\t\tmode = S_IRUGO;"
            ],
            "added_lines": [
                "\t\tmode_t mode = iibm->base_procfs_mode;",
                "\t\tif (!mode)",
                "\t\t\tmode = S_IRUGO;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-3448",
        "func_name": "torvalds/linux/video_write",
        "description": "drivers/platform/x86/thinkpad_acpi.c in the Linux kernel before 2.6.34 on ThinkPad devices, when the X.Org X server is used, does not properly restrict access to the video output control state, which allows local users to cause a denial of service (system hang) via a (1) read or (2) write operation.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=b525c06cdbd8a3963f0173ccd23f9147d4c384b5",
        "commit_title": "Given the right combination of ThinkPad and X.org, just reading the",
        "commit_text": "video output control state is enough to hard-crash X.org.  Until the day I somehow find out a model or BIOS cut date to not provide this feature to ThinkPads that can do video switching through X RandR, change permissions so that only processes with CAP_SYS_ADMIN can access any sort of video output control state.  This bug could be considered a local DoS I suppose, as it allows any non-privledged local user to cause some versions of X.org to hard-crash some ThinkPads.  Cc: stable@kernel.org ",
        "func_before": "static int video_write(char *buf)\n{\n\tchar *cmd;\n\tint enable, disable, status;\n\tint res;\n\n\tif (video_supported == TPACPI_VIDEO_NONE)\n\t\treturn -ENODEV;\n\n\tenable = 0;\n\tdisable = 0;\n\n\twhile ((cmd = next_cmd(&buf))) {\n\t\tif (strlencmp(cmd, \"lcd_enable\") == 0) {\n\t\t\tenable |= TP_ACPI_VIDEO_S_LCD;\n\t\t} else if (strlencmp(cmd, \"lcd_disable\") == 0) {\n\t\t\tdisable |= TP_ACPI_VIDEO_S_LCD;\n\t\t} else if (strlencmp(cmd, \"crt_enable\") == 0) {\n\t\t\tenable |= TP_ACPI_VIDEO_S_CRT;\n\t\t} else if (strlencmp(cmd, \"crt_disable\") == 0) {\n\t\t\tdisable |= TP_ACPI_VIDEO_S_CRT;\n\t\t} else if (video_supported == TPACPI_VIDEO_NEW &&\n\t\t\t   strlencmp(cmd, \"dvi_enable\") == 0) {\n\t\t\tenable |= TP_ACPI_VIDEO_S_DVI;\n\t\t} else if (video_supported == TPACPI_VIDEO_NEW &&\n\t\t\t   strlencmp(cmd, \"dvi_disable\") == 0) {\n\t\t\tdisable |= TP_ACPI_VIDEO_S_DVI;\n\t\t} else if (strlencmp(cmd, \"auto_enable\") == 0) {\n\t\t\tres = video_autosw_set(1);\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else if (strlencmp(cmd, \"auto_disable\") == 0) {\n\t\t\tres = video_autosw_set(0);\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else if (strlencmp(cmd, \"video_switch\") == 0) {\n\t\t\tres = video_outputsw_cycle();\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else if (strlencmp(cmd, \"expand_toggle\") == 0) {\n\t\t\tres = video_expand_toggle();\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (enable || disable) {\n\t\tstatus = video_outputsw_get();\n\t\tif (status < 0)\n\t\t\treturn status;\n\t\tres = video_outputsw_set((status & ~disable) | enable);\n\t\tif (res)\n\t\t\treturn res;\n\t}\n\n\treturn 0;\n}",
        "func": "static int video_write(char *buf)\n{\n\tchar *cmd;\n\tint enable, disable, status;\n\tint res;\n\n\tif (video_supported == TPACPI_VIDEO_NONE)\n\t\treturn -ENODEV;\n\n\t/* Even reads can crash X.org, let alone writes... */\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tenable = 0;\n\tdisable = 0;\n\n\twhile ((cmd = next_cmd(&buf))) {\n\t\tif (strlencmp(cmd, \"lcd_enable\") == 0) {\n\t\t\tenable |= TP_ACPI_VIDEO_S_LCD;\n\t\t} else if (strlencmp(cmd, \"lcd_disable\") == 0) {\n\t\t\tdisable |= TP_ACPI_VIDEO_S_LCD;\n\t\t} else if (strlencmp(cmd, \"crt_enable\") == 0) {\n\t\t\tenable |= TP_ACPI_VIDEO_S_CRT;\n\t\t} else if (strlencmp(cmd, \"crt_disable\") == 0) {\n\t\t\tdisable |= TP_ACPI_VIDEO_S_CRT;\n\t\t} else if (video_supported == TPACPI_VIDEO_NEW &&\n\t\t\t   strlencmp(cmd, \"dvi_enable\") == 0) {\n\t\t\tenable |= TP_ACPI_VIDEO_S_DVI;\n\t\t} else if (video_supported == TPACPI_VIDEO_NEW &&\n\t\t\t   strlencmp(cmd, \"dvi_disable\") == 0) {\n\t\t\tdisable |= TP_ACPI_VIDEO_S_DVI;\n\t\t} else if (strlencmp(cmd, \"auto_enable\") == 0) {\n\t\t\tres = video_autosw_set(1);\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else if (strlencmp(cmd, \"auto_disable\") == 0) {\n\t\t\tres = video_autosw_set(0);\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else if (strlencmp(cmd, \"video_switch\") == 0) {\n\t\t\tres = video_outputsw_cycle();\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else if (strlencmp(cmd, \"expand_toggle\") == 0) {\n\t\t\tres = video_expand_toggle();\n\t\t\tif (res)\n\t\t\t\treturn res;\n\t\t} else\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (enable || disable) {\n\t\tstatus = video_outputsw_get();\n\t\tif (status < 0)\n\t\t\treturn status;\n\t\tres = video_outputsw_set((status & ~disable) | enable);\n\t\tif (res)\n\t\t\treturn res;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,10 @@\n \n \tif (video_supported == TPACPI_VIDEO_NONE)\n \t\treturn -ENODEV;\n+\n+\t/* Even reads can crash X.org, let alone writes... */\n+\tif (!capable(CAP_SYS_ADMIN))\n+\t\treturn -EPERM;\n \n \tenable = 0;\n \tdisable = 0;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* Even reads can crash X.org, let alone writes... */",
                "\tif (!capable(CAP_SYS_ADMIN))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-3448",
        "func_name": "torvalds/linux/video_read",
        "description": "drivers/platform/x86/thinkpad_acpi.c in the Linux kernel before 2.6.34 on ThinkPad devices, when the X.Org X server is used, does not properly restrict access to the video output control state, which allows local users to cause a denial of service (system hang) via a (1) read or (2) write operation.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=b525c06cdbd8a3963f0173ccd23f9147d4c384b5",
        "commit_title": "Given the right combination of ThinkPad and X.org, just reading the",
        "commit_text": "video output control state is enough to hard-crash X.org.  Until the day I somehow find out a model or BIOS cut date to not provide this feature to ThinkPads that can do video switching through X RandR, change permissions so that only processes with CAP_SYS_ADMIN can access any sort of video output control state.  This bug could be considered a local DoS I suppose, as it allows any non-privledged local user to cause some versions of X.org to hard-crash some ThinkPads.  Cc: stable@kernel.org ",
        "func_before": "static int video_read(struct seq_file *m)\n{\n\tint status, autosw;\n\n\tif (video_supported == TPACPI_VIDEO_NONE) {\n\t\tseq_printf(m, \"status:\\t\\tnot supported\\n\");\n\t\treturn 0;\n\t}\n\n\tstatus = video_outputsw_get();\n\tif (status < 0)\n\t\treturn status;\n\n\tautosw = video_autosw_get();\n\tif (autosw < 0)\n\t\treturn autosw;\n\n\tseq_printf(m, \"status:\\t\\tsupported\\n\");\n\tseq_printf(m, \"lcd:\\t\\t%s\\n\", enabled(status, 0));\n\tseq_printf(m, \"crt:\\t\\t%s\\n\", enabled(status, 1));\n\tif (video_supported == TPACPI_VIDEO_NEW)\n\t\tseq_printf(m, \"dvi:\\t\\t%s\\n\", enabled(status, 3));\n\tseq_printf(m, \"auto:\\t\\t%s\\n\", enabled(autosw, 0));\n\tseq_printf(m, \"commands:\\tlcd_enable, lcd_disable\\n\");\n\tseq_printf(m, \"commands:\\tcrt_enable, crt_disable\\n\");\n\tif (video_supported == TPACPI_VIDEO_NEW)\n\t\tseq_printf(m, \"commands:\\tdvi_enable, dvi_disable\\n\");\n\tseq_printf(m, \"commands:\\tauto_enable, auto_disable\\n\");\n\tseq_printf(m, \"commands:\\tvideo_switch, expand_toggle\\n\");\n\n\treturn 0;\n}",
        "func": "static int video_read(struct seq_file *m)\n{\n\tint status, autosw;\n\n\tif (video_supported == TPACPI_VIDEO_NONE) {\n\t\tseq_printf(m, \"status:\\t\\tnot supported\\n\");\n\t\treturn 0;\n\t}\n\n\t/* Even reads can crash X.org, so... */\n\tif (!capable(CAP_SYS_ADMIN))\n\t\treturn -EPERM;\n\n\tstatus = video_outputsw_get();\n\tif (status < 0)\n\t\treturn status;\n\n\tautosw = video_autosw_get();\n\tif (autosw < 0)\n\t\treturn autosw;\n\n\tseq_printf(m, \"status:\\t\\tsupported\\n\");\n\tseq_printf(m, \"lcd:\\t\\t%s\\n\", enabled(status, 0));\n\tseq_printf(m, \"crt:\\t\\t%s\\n\", enabled(status, 1));\n\tif (video_supported == TPACPI_VIDEO_NEW)\n\t\tseq_printf(m, \"dvi:\\t\\t%s\\n\", enabled(status, 3));\n\tseq_printf(m, \"auto:\\t\\t%s\\n\", enabled(autosw, 0));\n\tseq_printf(m, \"commands:\\tlcd_enable, lcd_disable\\n\");\n\tseq_printf(m, \"commands:\\tcrt_enable, crt_disable\\n\");\n\tif (video_supported == TPACPI_VIDEO_NEW)\n\t\tseq_printf(m, \"commands:\\tdvi_enable, dvi_disable\\n\");\n\tseq_printf(m, \"commands:\\tauto_enable, auto_disable\\n\");\n\tseq_printf(m, \"commands:\\tvideo_switch, expand_toggle\\n\");\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,10 @@\n \t\tseq_printf(m, \"status:\\t\\tnot supported\\n\");\n \t\treturn 0;\n \t}\n+\n+\t/* Even reads can crash X.org, so... */\n+\tif (!capable(CAP_SYS_ADMIN))\n+\t\treturn -EPERM;\n \n \tstatus = video_outputsw_get();\n \tif (status < 0)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* Even reads can crash X.org, so... */",
                "\tif (!capable(CAP_SYS_ADMIN))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2011-0989",
        "func_name": "mono/ves_icall_System_Runtime_CompilerServices_RuntimeHelpers_InitializeArray",
        "description": "The RuntimeHelpers.InitializeArray method in metadata/icall.c in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, does not properly restrict data types, which allows remote attackers to modify internal read-only data structures, and cause a denial of service (plugin crash) or corrupt the internal state of the security manager, via a crafted media file, as demonstrated by modifying a C# struct.",
        "git_url": "https://github.com/mono/mono/commit/035c8587c0d8d307e45f1b7171a0d337bb451f1e",
        "commit_title": "Allow only primitive types/enums in RuntimeHelpers.InitializeArray ().",
        "commit_text": "",
        "func_before": "static void\nves_icall_System_Runtime_CompilerServices_RuntimeHelpers_InitializeArray (MonoArray *array, MonoClassField *field_handle)\n{\n\tMonoClass *klass = array->obj.vtable->klass;\n\tguint32 size = mono_array_element_size (klass);\n\tMonoType *type = mono_type_get_underlying_type (&klass->element_class->byval_arg);\n\tint align;\n\tconst char *field_data;\n\n\tif (MONO_TYPE_IS_REFERENCE (type) ||\n\t\t\t(type->type == MONO_TYPE_VALUETYPE &&\n\t\t\t\t(!mono_type_get_class (type) ||\n\t\t\t\tmono_type_get_class (type)->has_references))) {\n\t\tMonoException *exc = mono_get_exception_argument(\"array\",\n\t\t\t\"Cannot initialize array containing references\");\n\t\tmono_raise_exception (exc);\n\t}\n\n\tif (!(field_handle->type->attrs & FIELD_ATTRIBUTE_HAS_FIELD_RVA)) {\n\t\tMonoException *exc = mono_get_exception_argument(\"field_handle\",\n\t\t\t\"Field doesn't have an RVA\");\n\t\tmono_raise_exception (exc);\n\t}\n\n\tsize *= array->max_length;\n\tfield_data = mono_field_get_data (field_handle);\n\n\tif (size > mono_type_size (field_handle->type, &align)) {\n\t\tMonoException *exc = mono_get_exception_argument(\"field_handle\",\n\t\t\t\"Field not large enough to fill array\");\n\t\tmono_raise_exception (exc);\n\t}\n\n#if G_BYTE_ORDER != G_LITTLE_ENDIAN\n#define SWAP(n) {\\\n\tguint ## n *data = (guint ## n *) mono_array_addr (array, char, 0); \\\n\tguint ## n *src = (guint ## n *) field_data; \\\n\tguint ## n *end = (guint ## n *)((char*)src + size); \\\n\\\n\tfor (; src < end; data++, src++) { \\\n\t\t*data = read ## n (src); \\\n\t} \\\n}\n\n\t/* printf (\"Initialize array with elements of %s type\\n\", klass->element_class->name); */\n\n\tswitch (type->type) {\n\tcase MONO_TYPE_CHAR:\n\tcase MONO_TYPE_I2:\n\tcase MONO_TYPE_U2:\n\t\tSWAP (16);\n\t\tbreak;\n\tcase MONO_TYPE_I4:\n\tcase MONO_TYPE_U4:\n\tcase MONO_TYPE_R4:\n\t\tSWAP (32);\n\t\tbreak;\n\tcase MONO_TYPE_I8:\n\tcase MONO_TYPE_U8:\n\tcase MONO_TYPE_R8:\n\t\tSWAP (64);\n\t\tbreak;\n\tdefault:\n\t\tmemcpy (mono_array_addr (array, char, 0), field_data, size);\n\t\tbreak;\n\t}\n#else\n\tmemcpy (mono_array_addr (array, char, 0), field_data, size);\n#ifdef ARM_FPU_FPA\n\tif (klass->element_class->byval_arg.type == MONO_TYPE_R8) {\n\t\tgint i;\n\t\tdouble tmp;\n\t\tdouble *data = (double*)mono_array_addr (array, double, 0);\n\n\t\tfor (i = 0; i < size; i++, data++) {\n\t\t\treadr8 (data, &tmp);\n\t\t\t*data = tmp;\n\t\t}\n\t}\n#endif\n#endif\n}",
        "func": "static void\nves_icall_System_Runtime_CompilerServices_RuntimeHelpers_InitializeArray (MonoArray *array, MonoClassField *field_handle)\n{\n\tMonoClass *klass = array->obj.vtable->klass;\n\tguint32 size = mono_array_element_size (klass);\n\tMonoType *type = mono_type_get_underlying_type (&klass->element_class->byval_arg);\n\tint align;\n\tconst char *field_data;\n\n\tif (MONO_TYPE_IS_REFERENCE (type) || type->type == MONO_TYPE_VALUETYPE) {\n\t\tMonoException *exc = mono_get_exception_argument(\"array\",\n\t\t\t\"Cannot initialize array of non-primitive type.\");\n\t\tmono_raise_exception (exc);\n\t}\n\n\tif (!(field_handle->type->attrs & FIELD_ATTRIBUTE_HAS_FIELD_RVA)) {\n\t\tMonoException *exc = mono_get_exception_argument(\"field_handle\",\n\t\t\t\"Field doesn't have an RVA\");\n\t\tmono_raise_exception (exc);\n\t}\n\n\tsize *= array->max_length;\n\tfield_data = mono_field_get_data (field_handle);\n\n\tif (size > mono_type_size (field_handle->type, &align)) {\n\t\tMonoException *exc = mono_get_exception_argument(\"field_handle\",\n\t\t\t\"Field not large enough to fill array\");\n\t\tmono_raise_exception (exc);\n\t}\n\n#if G_BYTE_ORDER != G_LITTLE_ENDIAN\n#define SWAP(n) {\\\n\tguint ## n *data = (guint ## n *) mono_array_addr (array, char, 0); \\\n\tguint ## n *src = (guint ## n *) field_data; \\\n\tguint ## n *end = (guint ## n *)((char*)src + size); \\\n\\\n\tfor (; src < end; data++, src++) { \\\n\t\t*data = read ## n (src); \\\n\t} \\\n}\n\n\t/* printf (\"Initialize array with elements of %s type\\n\", klass->element_class->name); */\n\n\tswitch (type->type) {\n\tcase MONO_TYPE_CHAR:\n\tcase MONO_TYPE_I2:\n\tcase MONO_TYPE_U2:\n\t\tSWAP (16);\n\t\tbreak;\n\tcase MONO_TYPE_I4:\n\tcase MONO_TYPE_U4:\n\tcase MONO_TYPE_R4:\n\t\tSWAP (32);\n\t\tbreak;\n\tcase MONO_TYPE_I8:\n\tcase MONO_TYPE_U8:\n\tcase MONO_TYPE_R8:\n\t\tSWAP (64);\n\t\tbreak;\n\tdefault:\n\t\tmemcpy (mono_array_addr (array, char, 0), field_data, size);\n\t\tbreak;\n\t}\n#else\n\tmemcpy (mono_array_addr (array, char, 0), field_data, size);\n#ifdef ARM_FPU_FPA\n\tif (klass->element_class->byval_arg.type == MONO_TYPE_R8) {\n\t\tgint i;\n\t\tdouble tmp;\n\t\tdouble *data = (double*)mono_array_addr (array, double, 0);\n\n\t\tfor (i = 0; i < size; i++, data++) {\n\t\t\treadr8 (data, &tmp);\n\t\t\t*data = tmp;\n\t\t}\n\t}\n#endif\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,12 +7,9 @@\n \tint align;\n \tconst char *field_data;\n \n-\tif (MONO_TYPE_IS_REFERENCE (type) ||\n-\t\t\t(type->type == MONO_TYPE_VALUETYPE &&\n-\t\t\t\t(!mono_type_get_class (type) ||\n-\t\t\t\tmono_type_get_class (type)->has_references))) {\n+\tif (MONO_TYPE_IS_REFERENCE (type) || type->type == MONO_TYPE_VALUETYPE) {\n \t\tMonoException *exc = mono_get_exception_argument(\"array\",\n-\t\t\t\"Cannot initialize array containing references\");\n+\t\t\t\"Cannot initialize array of non-primitive type.\");\n \t\tmono_raise_exception (exc);\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (MONO_TYPE_IS_REFERENCE (type) ||",
                "\t\t\t(type->type == MONO_TYPE_VALUETYPE &&",
                "\t\t\t\t(!mono_type_get_class (type) ||",
                "\t\t\t\tmono_type_get_class (type)->has_references))) {",
                "\t\t\t\"Cannot initialize array containing references\");"
            ],
            "added_lines": [
                "\tif (MONO_TYPE_IS_REFERENCE (type) || type->type == MONO_TYPE_VALUETYPE) {",
                "\t\t\t\"Cannot initialize array of non-primitive type.\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10200",
        "func_name": "torvalds/linux/l2tp_ip6_bind",
        "description": "Race condition in the L2TPv3 IP Encapsulation feature in the Linux kernel before 4.8.14 allows local users to gain privileges or cause a denial of service (use-after-free) by making multiple bind system calls without properly ascertaining whether a socket has the SOCK_ZAPPED status, related to net/l2tp/l2tp_ip.c and net/l2tp/l2tp_ip6.c.",
        "git_url": "https://github.com/torvalds/linux/commit/32c231164b762dddefa13af5a0101032c70b50ef",
        "commit_title": "l2tp: fix racy SOCK_ZAPPED flag check in l2tp_ip{,6}_bind()",
        "commit_text": " Lock socket before checking the SOCK_ZAPPED flag in l2tp_ip6_bind(). Without lock, a concurrent call could modify the socket flags between the sock_flag(sk, SOCK_ZAPPED) test and the lock_sock() call. This way, a socket could be inserted twice in l2tp_ip6_bind_table. Releasing it would then leave a stale pointer there, generating use-after-free errors when walking through the list or modifying adjacent entries.  BUG: KASAN: use-after-free in l2tp_ip6_close+0x22e/0x290 at addr ffff8800081b0ed8 Write of size 8 by task syz-executor/10987 CPU: 0 PID: 10987 Comm: syz-executor Not tainted 4.8.0+ #39 Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.2-0-g33fbe13 by qemu-project.org 04/01/2014  ffff880031d97838 ffffffff829f835b ffff88001b5a1640 ffff8800081b0ec0  ffff8800081b15a0 ffff8800081b6d20 ffff880031d97860 ffffffff8174d3cc  ffff880031d978f0 ffff8800081b0e80 ffff88001b5a1640 ffff880031d978e0 Call Trace:  [<ffffffff829f835b>] dump_stack+0xb3/0x118 lib/dump_stack.c:15  [<ffffffff8174d3cc>] kasan_object_err+0x1c/0x70 mm/kasan/report.c:156  [<     inline     >] print_address_description mm/kasan/report.c:194  [<ffffffff8174d666>] kasan_report_error+0x1f6/0x4d0 mm/kasan/report.c:283  [<     inline     >] kasan_report mm/kasan/report.c:303  [<ffffffff8174db7e>] __asan_report_store8_noabort+0x3e/0x40 mm/kasan/report.c:329  [<     inline     >] __write_once_size ./include/linux/compiler.h:249  [<     inline     >] __hlist_del ./include/linux/list.h:622  [<     inline     >] hlist_del_init ./include/linux/list.h:637  [<ffffffff8579047e>] l2tp_ip6_close+0x22e/0x290 net/l2tp/l2tp_ip6.c:239  [<ffffffff850b2dfd>] inet_release+0xed/0x1c0 net/ipv4/af_inet.c:415  [<ffffffff851dc5a0>] inet6_release+0x50/0x70 net/ipv6/af_inet6.c:422  [<ffffffff84c4581d>] sock_release+0x8d/0x1d0 net/socket.c:570  [<ffffffff84c45976>] sock_close+0x16/0x20 net/socket.c:1017  [<ffffffff817a108c>] __fput+0x28c/0x780 fs/file_table.c:208  [<ffffffff817a1605>] ____fput+0x15/0x20 fs/file_table.c:244  [<ffffffff813774f9>] task_work_run+0xf9/0x170  [<ffffffff81324aae>] do_exit+0x85e/0x2a00  [<ffffffff81326dc8>] do_group_exit+0x108/0x330  [<ffffffff81348cf7>] get_signal+0x617/0x17a0 kernel/signal.c:2307  [<ffffffff811b49af>] do_signal+0x7f/0x18f0  [<ffffffff810039bf>] exit_to_usermode_loop+0xbf/0x150 arch/x86/entry/common.c:156  [<     inline     >] prepare_exit_to_usermode arch/x86/entry/common.c:190  [<ffffffff81006060>] syscall_return_slowpath+0x1a0/0x1e0 arch/x86/entry/common.c:259  [<ffffffff85e4d726>] entry_SYSCALL_64_fastpath+0xc4/0xc6 Object at ffff8800081b0ec0, in cache L2TP/IPv6 size: 1448 Allocated: PID = 10987  [ 1116.897025] [<ffffffff811ddcb6>] save_stack_trace+0x16/0x20  [ 1116.897025] [<ffffffff8174c736>] save_stack+0x46/0xd0  [ 1116.897025] [<ffffffff8174c9ad>] kasan_kmalloc+0xad/0xe0  [ 1116.897025] [<ffffffff8174cee2>] kasan_slab_alloc+0x12/0x20  [ 1116.897025] [<     inline     >] slab_post_alloc_hook mm/slab.h:417  [ 1116.897025] [<     inline     >] slab_alloc_node mm/slub.c:2708  [ 1116.897025] [<     inline     >] slab_alloc mm/slub.c:2716  [ 1116.897025] [<ffffffff817476a8>] kmem_cache_alloc+0xc8/0x2b0 mm/slub.c:2721  [ 1116.897025] [<ffffffff84c4f6a9>] sk_prot_alloc+0x69/0x2b0 net/core/sock.c:1326  [ 1116.897025] [<ffffffff84c58ac8>] sk_alloc+0x38/0xae0 net/core/sock.c:1388  [ 1116.897025] [<ffffffff851ddf67>] inet6_create+0x2d7/0x1000 net/ipv6/af_inet6.c:182  [ 1116.897025] [<ffffffff84c4af7b>] __sock_create+0x37b/0x640 net/socket.c:1153  [ 1116.897025] [<     inline     >] sock_create net/socket.c:1193  [ 1116.897025] [<     inline     >] SYSC_socket net/socket.c:1223  [ 1116.897025] [<ffffffff84c4b46f>] SyS_socket+0xef/0x1b0 net/socket.c:1203  [ 1116.897025] [<ffffffff85e4d685>] entry_SYSCALL_64_fastpath+0x23/0xc6 Freed: PID = 10987  [ 1116.897025] [<ffffffff811ddcb6>] save_stack_trace+0x16/0x20  [ 1116.897025] [<ffffffff8174c736>] save_stack+0x46/0xd0  [ 1116.897025] [<ffffffff8174cf61>] kasan_slab_free+0x71/0xb0  [ 1116.897025] [<     inline     >] slab_free_hook mm/slub.c:1352  [ 1116.897025] [<     inline     >] slab_free_freelist_hook mm/slub.c:1374  [ 1116.897025] [<     inline     >] slab_free mm/slub.c:2951  [ 1116.897025] [<ffffffff81748b28>] kmem_cache_free+0xc8/0x330 mm/slub.c:2973  [ 1116.897025] [<     inline     >] sk_prot_free net/core/sock.c:1369  [ 1116.897025] [<ffffffff84c541eb>] __sk_destruct+0x32b/0x4f0 net/core/sock.c:1444  [ 1116.897025] [<ffffffff84c5aca4>] sk_destruct+0x44/0x80 net/core/sock.c:1452  [ 1116.897025] [<ffffffff84c5ad33>] __sk_free+0x53/0x220 net/core/sock.c:1460  [ 1116.897025] [<ffffffff84c5af23>] sk_free+0x23/0x30 net/core/sock.c:1471  [ 1116.897025] [<ffffffff84c5cb6c>] sk_common_release+0x28c/0x3e0 ./include/net/sock.h:1589  [ 1116.897025] [<ffffffff8579044e>] l2tp_ip6_close+0x1fe/0x290 net/l2tp/l2tp_ip6.c:243  [ 1116.897025] [<ffffffff850b2dfd>] inet_release+0xed/0x1c0 net/ipv4/af_inet.c:415  [ 1116.897025] [<ffffffff851dc5a0>] inet6_release+0x50/0x70 net/ipv6/af_inet6.c:422  [ 1116.897025] [<ffffffff84c4581d>] sock_release+0x8d/0x1d0 net/socket.c:570  [ 1116.897025] [<ffffffff84c45976>] sock_close+0x16/0x20 net/socket.c:1017  [ 1116.897025] [<ffffffff817a108c>] __fput+0x28c/0x780 fs/file_table.c:208  [ 1116.897025] [<ffffffff817a1605>] ____fput+0x15/0x20 fs/file_table.c:244  [ 1116.897025] [<ffffffff813774f9>] task_work_run+0xf9/0x170  [ 1116.897025] [<ffffffff81324aae>] do_exit+0x85e/0x2a00  [ 1116.897025] [<ffffffff81326dc8>] do_group_exit+0x108/0x330  [ 1116.897025] [<ffffffff81348cf7>] get_signal+0x617/0x17a0 kernel/signal.c:2307  [ 1116.897025] [<ffffffff811b49af>] do_signal+0x7f/0x18f0  [ 1116.897025] [<ffffffff810039bf>] exit_to_usermode_loop+0xbf/0x150 arch/x86/entry/common.c:156  [ 1116.897025] [<     inline     >] prepare_exit_to_usermode arch/x86/entry/common.c:190  [ 1116.897025] [<ffffffff81006060>] syscall_return_slowpath+0x1a0/0x1e0 arch/x86/entry/common.c:259  [ 1116.897025] [<ffffffff85e4d726>] entry_SYSCALL_64_fastpath+0xc4/0xc6 Memory state around the buggy address:  ffff8800081b0d80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc  ffff8800081b0e00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc >ffff8800081b0e80: fc fc fc fc fc fc fc fc fb fb fb fb fb fb fb fb                                                     ^  ffff8800081b0f00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb  ffff8800081b0f80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb  ==================================================================  The same issue exists with l2tp_ip_bind() and l2tp_ip_bind_table. ",
        "func_before": "static int l2tp_ip6_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct sockaddr_l2tpip6 *addr = (struct sockaddr_l2tpip6 *) uaddr;\n\tstruct net *net = sock_net(sk);\n\t__be32 v4addr = 0;\n\tint addr_type;\n\tint err;\n\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\treturn -EINVAL;\n\tif (addr->l2tp_family != AF_INET6)\n\t\treturn -EINVAL;\n\tif (addr_len < sizeof(*addr))\n\t\treturn -EINVAL;\n\n\taddr_type = ipv6_addr_type(&addr->l2tp_addr);\n\n\t/* l2tp_ip6 sockets are IPv6 only */\n\tif (addr_type == IPV6_ADDR_MAPPED)\n\t\treturn -EADDRNOTAVAIL;\n\n\t/* L2TP is point-point, not multicast */\n\tif (addr_type & IPV6_ADDR_MULTICAST)\n\t\treturn -EADDRNOTAVAIL;\n\n\terr = -EADDRINUSE;\n\tread_lock_bh(&l2tp_ip6_lock);\n\tif (__l2tp_ip6_bind_lookup(net, &addr->l2tp_addr,\n\t\t\t\t   sk->sk_bound_dev_if, addr->l2tp_conn_id))\n\t\tgoto out_in_use;\n\tread_unlock_bh(&l2tp_ip6_lock);\n\n\tlock_sock(sk);\n\n\terr = -EINVAL;\n\tif (sk->sk_state != TCP_CLOSE)\n\t\tgoto out_unlock;\n\n\t/* Check if the address belongs to the host. */\n\trcu_read_lock();\n\tif (addr_type != IPV6_ADDR_ANY) {\n\t\tstruct net_device *dev = NULL;\n\n\t\tif (addr_type & IPV6_ADDR_LINKLOCAL) {\n\t\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t\t    addr->l2tp_scope_id) {\n\t\t\t\t/* Override any existing binding, if another\n\t\t\t\t * one is supplied by user.\n\t\t\t\t */\n\t\t\t\tsk->sk_bound_dev_if = addr->l2tp_scope_id;\n\t\t\t}\n\n\t\t\t/* Binding to link-local address requires an\n\t\t\t   interface */\n\t\t\tif (!sk->sk_bound_dev_if)\n\t\t\t\tgoto out_unlock_rcu;\n\n\t\t\terr = -ENODEV;\n\t\t\tdev = dev_get_by_index_rcu(sock_net(sk),\n\t\t\t\t\t\t   sk->sk_bound_dev_if);\n\t\t\tif (!dev)\n\t\t\t\tgoto out_unlock_rcu;\n\t\t}\n\n\t\t/* ipv4 addr of the socket is invalid.  Only the\n\t\t * unspecified and mapped address have a v4 equivalent.\n\t\t */\n\t\tv4addr = LOOPBACK4_IPV6;\n\t\terr = -EADDRNOTAVAIL;\n\t\tif (!ipv6_chk_addr(sock_net(sk), &addr->l2tp_addr, dev, 0))\n\t\t\tgoto out_unlock_rcu;\n\t}\n\trcu_read_unlock();\n\n\tinet->inet_rcv_saddr = inet->inet_saddr = v4addr;\n\tsk->sk_v6_rcv_saddr = addr->l2tp_addr;\n\tnp->saddr = addr->l2tp_addr;\n\n\tl2tp_ip6_sk(sk)->conn_id = addr->l2tp_conn_id;\n\n\twrite_lock_bh(&l2tp_ip6_lock);\n\tsk_add_bind_node(sk, &l2tp_ip6_bind_table);\n\tsk_del_node_init(sk);\n\twrite_unlock_bh(&l2tp_ip6_lock);\n\n\tsock_reset_flag(sk, SOCK_ZAPPED);\n\trelease_sock(sk);\n\treturn 0;\n\nout_unlock_rcu:\n\trcu_read_unlock();\nout_unlock:\n\trelease_sock(sk);\n\treturn err;\n\nout_in_use:\n\tread_unlock_bh(&l2tp_ip6_lock);\n\treturn err;\n}",
        "func": "static int l2tp_ip6_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct ipv6_pinfo *np = inet6_sk(sk);\n\tstruct sockaddr_l2tpip6 *addr = (struct sockaddr_l2tpip6 *) uaddr;\n\tstruct net *net = sock_net(sk);\n\t__be32 v4addr = 0;\n\tint addr_type;\n\tint err;\n\n\tif (addr->l2tp_family != AF_INET6)\n\t\treturn -EINVAL;\n\tif (addr_len < sizeof(*addr))\n\t\treturn -EINVAL;\n\n\taddr_type = ipv6_addr_type(&addr->l2tp_addr);\n\n\t/* l2tp_ip6 sockets are IPv6 only */\n\tif (addr_type == IPV6_ADDR_MAPPED)\n\t\treturn -EADDRNOTAVAIL;\n\n\t/* L2TP is point-point, not multicast */\n\tif (addr_type & IPV6_ADDR_MULTICAST)\n\t\treturn -EADDRNOTAVAIL;\n\n\terr = -EADDRINUSE;\n\tread_lock_bh(&l2tp_ip6_lock);\n\tif (__l2tp_ip6_bind_lookup(net, &addr->l2tp_addr,\n\t\t\t\t   sk->sk_bound_dev_if, addr->l2tp_conn_id))\n\t\tgoto out_in_use;\n\tread_unlock_bh(&l2tp_ip6_lock);\n\n\tlock_sock(sk);\n\n\terr = -EINVAL;\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\tgoto out_unlock;\n\n\tif (sk->sk_state != TCP_CLOSE)\n\t\tgoto out_unlock;\n\n\t/* Check if the address belongs to the host. */\n\trcu_read_lock();\n\tif (addr_type != IPV6_ADDR_ANY) {\n\t\tstruct net_device *dev = NULL;\n\n\t\tif (addr_type & IPV6_ADDR_LINKLOCAL) {\n\t\t\tif (addr_len >= sizeof(struct sockaddr_in6) &&\n\t\t\t    addr->l2tp_scope_id) {\n\t\t\t\t/* Override any existing binding, if another\n\t\t\t\t * one is supplied by user.\n\t\t\t\t */\n\t\t\t\tsk->sk_bound_dev_if = addr->l2tp_scope_id;\n\t\t\t}\n\n\t\t\t/* Binding to link-local address requires an\n\t\t\t   interface */\n\t\t\tif (!sk->sk_bound_dev_if)\n\t\t\t\tgoto out_unlock_rcu;\n\n\t\t\terr = -ENODEV;\n\t\t\tdev = dev_get_by_index_rcu(sock_net(sk),\n\t\t\t\t\t\t   sk->sk_bound_dev_if);\n\t\t\tif (!dev)\n\t\t\t\tgoto out_unlock_rcu;\n\t\t}\n\n\t\t/* ipv4 addr of the socket is invalid.  Only the\n\t\t * unspecified and mapped address have a v4 equivalent.\n\t\t */\n\t\tv4addr = LOOPBACK4_IPV6;\n\t\terr = -EADDRNOTAVAIL;\n\t\tif (!ipv6_chk_addr(sock_net(sk), &addr->l2tp_addr, dev, 0))\n\t\t\tgoto out_unlock_rcu;\n\t}\n\trcu_read_unlock();\n\n\tinet->inet_rcv_saddr = inet->inet_saddr = v4addr;\n\tsk->sk_v6_rcv_saddr = addr->l2tp_addr;\n\tnp->saddr = addr->l2tp_addr;\n\n\tl2tp_ip6_sk(sk)->conn_id = addr->l2tp_conn_id;\n\n\twrite_lock_bh(&l2tp_ip6_lock);\n\tsk_add_bind_node(sk, &l2tp_ip6_bind_table);\n\tsk_del_node_init(sk);\n\twrite_unlock_bh(&l2tp_ip6_lock);\n\n\tsock_reset_flag(sk, SOCK_ZAPPED);\n\trelease_sock(sk);\n\treturn 0;\n\nout_unlock_rcu:\n\trcu_read_unlock();\nout_unlock:\n\trelease_sock(sk);\n\treturn err;\n\nout_in_use:\n\tread_unlock_bh(&l2tp_ip6_lock);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,8 +8,6 @@\n \tint addr_type;\n \tint err;\n \n-\tif (!sock_flag(sk, SOCK_ZAPPED))\n-\t\treturn -EINVAL;\n \tif (addr->l2tp_family != AF_INET6)\n \t\treturn -EINVAL;\n \tif (addr_len < sizeof(*addr))\n@@ -35,6 +33,9 @@\n \tlock_sock(sk);\n \n \terr = -EINVAL;\n+\tif (!sock_flag(sk, SOCK_ZAPPED))\n+\t\tgoto out_unlock;\n+\n \tif (sk->sk_state != TCP_CLOSE)\n \t\tgoto out_unlock;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!sock_flag(sk, SOCK_ZAPPED))",
                "\t\treturn -EINVAL;"
            ],
            "added_lines": [
                "\tif (!sock_flag(sk, SOCK_ZAPPED))",
                "\t\tgoto out_unlock;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10200",
        "func_name": "torvalds/linux/l2tp_ip_bind",
        "description": "Race condition in the L2TPv3 IP Encapsulation feature in the Linux kernel before 4.8.14 allows local users to gain privileges or cause a denial of service (use-after-free) by making multiple bind system calls without properly ascertaining whether a socket has the SOCK_ZAPPED status, related to net/l2tp/l2tp_ip.c and net/l2tp/l2tp_ip6.c.",
        "git_url": "https://github.com/torvalds/linux/commit/32c231164b762dddefa13af5a0101032c70b50ef",
        "commit_title": "l2tp: fix racy SOCK_ZAPPED flag check in l2tp_ip{,6}_bind()",
        "commit_text": " Lock socket before checking the SOCK_ZAPPED flag in l2tp_ip6_bind(). Without lock, a concurrent call could modify the socket flags between the sock_flag(sk, SOCK_ZAPPED) test and the lock_sock() call. This way, a socket could be inserted twice in l2tp_ip6_bind_table. Releasing it would then leave a stale pointer there, generating use-after-free errors when walking through the list or modifying adjacent entries.  BUG: KASAN: use-after-free in l2tp_ip6_close+0x22e/0x290 at addr ffff8800081b0ed8 Write of size 8 by task syz-executor/10987 CPU: 0 PID: 10987 Comm: syz-executor Not tainted 4.8.0+ #39 Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.8.2-0-g33fbe13 by qemu-project.org 04/01/2014  ffff880031d97838 ffffffff829f835b ffff88001b5a1640 ffff8800081b0ec0  ffff8800081b15a0 ffff8800081b6d20 ffff880031d97860 ffffffff8174d3cc  ffff880031d978f0 ffff8800081b0e80 ffff88001b5a1640 ffff880031d978e0 Call Trace:  [<ffffffff829f835b>] dump_stack+0xb3/0x118 lib/dump_stack.c:15  [<ffffffff8174d3cc>] kasan_object_err+0x1c/0x70 mm/kasan/report.c:156  [<     inline     >] print_address_description mm/kasan/report.c:194  [<ffffffff8174d666>] kasan_report_error+0x1f6/0x4d0 mm/kasan/report.c:283  [<     inline     >] kasan_report mm/kasan/report.c:303  [<ffffffff8174db7e>] __asan_report_store8_noabort+0x3e/0x40 mm/kasan/report.c:329  [<     inline     >] __write_once_size ./include/linux/compiler.h:249  [<     inline     >] __hlist_del ./include/linux/list.h:622  [<     inline     >] hlist_del_init ./include/linux/list.h:637  [<ffffffff8579047e>] l2tp_ip6_close+0x22e/0x290 net/l2tp/l2tp_ip6.c:239  [<ffffffff850b2dfd>] inet_release+0xed/0x1c0 net/ipv4/af_inet.c:415  [<ffffffff851dc5a0>] inet6_release+0x50/0x70 net/ipv6/af_inet6.c:422  [<ffffffff84c4581d>] sock_release+0x8d/0x1d0 net/socket.c:570  [<ffffffff84c45976>] sock_close+0x16/0x20 net/socket.c:1017  [<ffffffff817a108c>] __fput+0x28c/0x780 fs/file_table.c:208  [<ffffffff817a1605>] ____fput+0x15/0x20 fs/file_table.c:244  [<ffffffff813774f9>] task_work_run+0xf9/0x170  [<ffffffff81324aae>] do_exit+0x85e/0x2a00  [<ffffffff81326dc8>] do_group_exit+0x108/0x330  [<ffffffff81348cf7>] get_signal+0x617/0x17a0 kernel/signal.c:2307  [<ffffffff811b49af>] do_signal+0x7f/0x18f0  [<ffffffff810039bf>] exit_to_usermode_loop+0xbf/0x150 arch/x86/entry/common.c:156  [<     inline     >] prepare_exit_to_usermode arch/x86/entry/common.c:190  [<ffffffff81006060>] syscall_return_slowpath+0x1a0/0x1e0 arch/x86/entry/common.c:259  [<ffffffff85e4d726>] entry_SYSCALL_64_fastpath+0xc4/0xc6 Object at ffff8800081b0ec0, in cache L2TP/IPv6 size: 1448 Allocated: PID = 10987  [ 1116.897025] [<ffffffff811ddcb6>] save_stack_trace+0x16/0x20  [ 1116.897025] [<ffffffff8174c736>] save_stack+0x46/0xd0  [ 1116.897025] [<ffffffff8174c9ad>] kasan_kmalloc+0xad/0xe0  [ 1116.897025] [<ffffffff8174cee2>] kasan_slab_alloc+0x12/0x20  [ 1116.897025] [<     inline     >] slab_post_alloc_hook mm/slab.h:417  [ 1116.897025] [<     inline     >] slab_alloc_node mm/slub.c:2708  [ 1116.897025] [<     inline     >] slab_alloc mm/slub.c:2716  [ 1116.897025] [<ffffffff817476a8>] kmem_cache_alloc+0xc8/0x2b0 mm/slub.c:2721  [ 1116.897025] [<ffffffff84c4f6a9>] sk_prot_alloc+0x69/0x2b0 net/core/sock.c:1326  [ 1116.897025] [<ffffffff84c58ac8>] sk_alloc+0x38/0xae0 net/core/sock.c:1388  [ 1116.897025] [<ffffffff851ddf67>] inet6_create+0x2d7/0x1000 net/ipv6/af_inet6.c:182  [ 1116.897025] [<ffffffff84c4af7b>] __sock_create+0x37b/0x640 net/socket.c:1153  [ 1116.897025] [<     inline     >] sock_create net/socket.c:1193  [ 1116.897025] [<     inline     >] SYSC_socket net/socket.c:1223  [ 1116.897025] [<ffffffff84c4b46f>] SyS_socket+0xef/0x1b0 net/socket.c:1203  [ 1116.897025] [<ffffffff85e4d685>] entry_SYSCALL_64_fastpath+0x23/0xc6 Freed: PID = 10987  [ 1116.897025] [<ffffffff811ddcb6>] save_stack_trace+0x16/0x20  [ 1116.897025] [<ffffffff8174c736>] save_stack+0x46/0xd0  [ 1116.897025] [<ffffffff8174cf61>] kasan_slab_free+0x71/0xb0  [ 1116.897025] [<     inline     >] slab_free_hook mm/slub.c:1352  [ 1116.897025] [<     inline     >] slab_free_freelist_hook mm/slub.c:1374  [ 1116.897025] [<     inline     >] slab_free mm/slub.c:2951  [ 1116.897025] [<ffffffff81748b28>] kmem_cache_free+0xc8/0x330 mm/slub.c:2973  [ 1116.897025] [<     inline     >] sk_prot_free net/core/sock.c:1369  [ 1116.897025] [<ffffffff84c541eb>] __sk_destruct+0x32b/0x4f0 net/core/sock.c:1444  [ 1116.897025] [<ffffffff84c5aca4>] sk_destruct+0x44/0x80 net/core/sock.c:1452  [ 1116.897025] [<ffffffff84c5ad33>] __sk_free+0x53/0x220 net/core/sock.c:1460  [ 1116.897025] [<ffffffff84c5af23>] sk_free+0x23/0x30 net/core/sock.c:1471  [ 1116.897025] [<ffffffff84c5cb6c>] sk_common_release+0x28c/0x3e0 ./include/net/sock.h:1589  [ 1116.897025] [<ffffffff8579044e>] l2tp_ip6_close+0x1fe/0x290 net/l2tp/l2tp_ip6.c:243  [ 1116.897025] [<ffffffff850b2dfd>] inet_release+0xed/0x1c0 net/ipv4/af_inet.c:415  [ 1116.897025] [<ffffffff851dc5a0>] inet6_release+0x50/0x70 net/ipv6/af_inet6.c:422  [ 1116.897025] [<ffffffff84c4581d>] sock_release+0x8d/0x1d0 net/socket.c:570  [ 1116.897025] [<ffffffff84c45976>] sock_close+0x16/0x20 net/socket.c:1017  [ 1116.897025] [<ffffffff817a108c>] __fput+0x28c/0x780 fs/file_table.c:208  [ 1116.897025] [<ffffffff817a1605>] ____fput+0x15/0x20 fs/file_table.c:244  [ 1116.897025] [<ffffffff813774f9>] task_work_run+0xf9/0x170  [ 1116.897025] [<ffffffff81324aae>] do_exit+0x85e/0x2a00  [ 1116.897025] [<ffffffff81326dc8>] do_group_exit+0x108/0x330  [ 1116.897025] [<ffffffff81348cf7>] get_signal+0x617/0x17a0 kernel/signal.c:2307  [ 1116.897025] [<ffffffff811b49af>] do_signal+0x7f/0x18f0  [ 1116.897025] [<ffffffff810039bf>] exit_to_usermode_loop+0xbf/0x150 arch/x86/entry/common.c:156  [ 1116.897025] [<     inline     >] prepare_exit_to_usermode arch/x86/entry/common.c:190  [ 1116.897025] [<ffffffff81006060>] syscall_return_slowpath+0x1a0/0x1e0 arch/x86/entry/common.c:259  [ 1116.897025] [<ffffffff85e4d726>] entry_SYSCALL_64_fastpath+0xc4/0xc6 Memory state around the buggy address:  ffff8800081b0d80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc  ffff8800081b0e00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc >ffff8800081b0e80: fc fc fc fc fc fc fc fc fb fb fb fb fb fb fb fb                                                     ^  ffff8800081b0f00: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb  ffff8800081b0f80: fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb fb  ==================================================================  The same issue exists with l2tp_ip_bind() and l2tp_ip_bind_table. ",
        "func_before": "static int l2tp_ip_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct sockaddr_l2tpip *addr = (struct sockaddr_l2tpip *) uaddr;\n\tstruct net *net = sock_net(sk);\n\tint ret;\n\tint chk_addr_ret;\n\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\treturn -EINVAL;\n\tif (addr_len < sizeof(struct sockaddr_l2tpip))\n\t\treturn -EINVAL;\n\tif (addr->l2tp_family != AF_INET)\n\t\treturn -EINVAL;\n\n\tret = -EADDRINUSE;\n\tread_lock_bh(&l2tp_ip_lock);\n\tif (__l2tp_ip_bind_lookup(net, addr->l2tp_addr.s_addr,\n\t\t\t\t  sk->sk_bound_dev_if, addr->l2tp_conn_id))\n\t\tgoto out_in_use;\n\n\tread_unlock_bh(&l2tp_ip_lock);\n\n\tlock_sock(sk);\n\tif (sk->sk_state != TCP_CLOSE || addr_len < sizeof(struct sockaddr_l2tpip))\n\t\tgoto out;\n\n\tchk_addr_ret = inet_addr_type(net, addr->l2tp_addr.s_addr);\n\tret = -EADDRNOTAVAIL;\n\tif (addr->l2tp_addr.s_addr && chk_addr_ret != RTN_LOCAL &&\n\t    chk_addr_ret != RTN_MULTICAST && chk_addr_ret != RTN_BROADCAST)\n\t\tgoto out;\n\n\tif (addr->l2tp_addr.s_addr)\n\t\tinet->inet_rcv_saddr = inet->inet_saddr = addr->l2tp_addr.s_addr;\n\tif (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)\n\t\tinet->inet_saddr = 0;  /* Use device */\n\tsk_dst_reset(sk);\n\n\tl2tp_ip_sk(sk)->conn_id = addr->l2tp_conn_id;\n\n\twrite_lock_bh(&l2tp_ip_lock);\n\tsk_add_bind_node(sk, &l2tp_ip_bind_table);\n\tsk_del_node_init(sk);\n\twrite_unlock_bh(&l2tp_ip_lock);\n\tret = 0;\n\tsock_reset_flag(sk, SOCK_ZAPPED);\n\nout:\n\trelease_sock(sk);\n\n\treturn ret;\n\nout_in_use:\n\tread_unlock_bh(&l2tp_ip_lock);\n\n\treturn ret;\n}",
        "func": "static int l2tp_ip_bind(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct sockaddr_l2tpip *addr = (struct sockaddr_l2tpip *) uaddr;\n\tstruct net *net = sock_net(sk);\n\tint ret;\n\tint chk_addr_ret;\n\n\tif (addr_len < sizeof(struct sockaddr_l2tpip))\n\t\treturn -EINVAL;\n\tif (addr->l2tp_family != AF_INET)\n\t\treturn -EINVAL;\n\n\tret = -EADDRINUSE;\n\tread_lock_bh(&l2tp_ip_lock);\n\tif (__l2tp_ip_bind_lookup(net, addr->l2tp_addr.s_addr,\n\t\t\t\t  sk->sk_bound_dev_if, addr->l2tp_conn_id))\n\t\tgoto out_in_use;\n\n\tread_unlock_bh(&l2tp_ip_lock);\n\n\tlock_sock(sk);\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\tgoto out;\n\n\tif (sk->sk_state != TCP_CLOSE || addr_len < sizeof(struct sockaddr_l2tpip))\n\t\tgoto out;\n\n\tchk_addr_ret = inet_addr_type(net, addr->l2tp_addr.s_addr);\n\tret = -EADDRNOTAVAIL;\n\tif (addr->l2tp_addr.s_addr && chk_addr_ret != RTN_LOCAL &&\n\t    chk_addr_ret != RTN_MULTICAST && chk_addr_ret != RTN_BROADCAST)\n\t\tgoto out;\n\n\tif (addr->l2tp_addr.s_addr)\n\t\tinet->inet_rcv_saddr = inet->inet_saddr = addr->l2tp_addr.s_addr;\n\tif (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)\n\t\tinet->inet_saddr = 0;  /* Use device */\n\tsk_dst_reset(sk);\n\n\tl2tp_ip_sk(sk)->conn_id = addr->l2tp_conn_id;\n\n\twrite_lock_bh(&l2tp_ip_lock);\n\tsk_add_bind_node(sk, &l2tp_ip_bind_table);\n\tsk_del_node_init(sk);\n\twrite_unlock_bh(&l2tp_ip_lock);\n\tret = 0;\n\tsock_reset_flag(sk, SOCK_ZAPPED);\n\nout:\n\trelease_sock(sk);\n\n\treturn ret;\n\nout_in_use:\n\tread_unlock_bh(&l2tp_ip_lock);\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,8 +6,6 @@\n \tint ret;\n \tint chk_addr_ret;\n \n-\tif (!sock_flag(sk, SOCK_ZAPPED))\n-\t\treturn -EINVAL;\n \tif (addr_len < sizeof(struct sockaddr_l2tpip))\n \t\treturn -EINVAL;\n \tif (addr->l2tp_family != AF_INET)\n@@ -22,6 +20,9 @@\n \tread_unlock_bh(&l2tp_ip_lock);\n \n \tlock_sock(sk);\n+\tif (!sock_flag(sk, SOCK_ZAPPED))\n+\t\tgoto out;\n+\n \tif (sk->sk_state != TCP_CLOSE || addr_len < sizeof(struct sockaddr_l2tpip))\n \t\tgoto out;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (!sock_flag(sk, SOCK_ZAPPED))",
                "\t\treturn -EINVAL;"
            ],
            "added_lines": [
                "\tif (!sock_flag(sk, SOCK_ZAPPED))",
                "\t\tgoto out;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10152",
        "func_name": "achernya/hesiod/read_config_file",
        "description": "The read_config_file function in lib/hesiod.c in Hesiod 3.2.1 falls back to the \".athena.mit.edu\" default domain when opening the configuration file fails, which allows remote attackers to gain root privileges by poisoning the DNS cache.",
        "git_url": "https://github.com/achernya/hesiod/commit/247e2ce1f2aff40040657acaae7f1a1d673d6618",
        "commit_title": "Remove hard-coded defaults for LHS and RHS",
        "commit_text": " Don't fall back to using a default LHS or RHS when the configuration file can't be read.  Instead, return an error. Original report from https://bugzilla.redhat.com/show_bug.cgi?id=1332493",
        "func_before": "static int read_config_file(struct hesiod_p *ctx, const char *filename)\n{\n  char *key, *data, *p, **which;\n  char buf[MAXDNAME + 7];\n  FILE *fp;\n\n  /* Try to open the configuration file. */\n  fp = fopen(filename, \"r\");\n  if (!fp)\n    {\n      /* Use compiled in default domain names. */\n      ctx->lhs = malloc(strlen(DEF_LHS) + 1);\n      ctx->rhs = malloc(strlen(DEF_RHS) + 1);\n      if (ctx->lhs && ctx->rhs)\n\t{\n\t  strcpy(ctx->lhs, DEF_LHS);\n\t  strcpy(ctx->rhs, DEF_RHS);\n\t  return 0;\n\t}\n      else\n\t{\n\t  errno = ENOMEM;\n\t  return -1;\n\t}\n    }\n\n  ctx->lhs = NULL;\n  ctx->rhs = NULL;\n  while (fgets(buf, sizeof(buf), fp) != NULL)\n    {\n      p = buf;\n      if (*p == '#' || *p == '\\n' || *p == '\\r')\n\tcontinue;\n      while(*p == ' ' || *p == '\\t')\n\tp++;\n      key = p;\n      while(*p != ' ' && *p != '\\t' && *p != '=')\n\tp++;\n      *p++ = 0;\n\t\t\n      while(isspace((unsigned char)*p) || *p == '=')\n\tp++;\n      data = p;\n      while(!isspace((unsigned char)*p))\n\tp++;\n      *p = 0;\n\n      if (cistrcmp(key, \"lhs\") == 0 || cistrcmp(key, \"rhs\") == 0)\n\t{\n\t  which = (cistrcmp(key, \"lhs\") == 0) ? &ctx->lhs : &ctx->rhs;\n\t  *which = malloc(strlen(data) + 1);\n\t  if (!*which)\n\t    {\n\t      errno = ENOMEM;\n\t      return -1;\n\t    }\n\t  strcpy(*which, data);\n\t}\n    }\n  fclose(fp);\n\n  /* Make sure that the rhs is set. */\n  if (!ctx->rhs)\n    {\n      errno = ENOEXEC;\n      return -1;\n    }\n\n  return 0;\n}",
        "func": "static int read_config_file(struct hesiod_p *ctx, const char *filename)\n{\n  char *key, *data, *p, **which;\n  char buf[MAXDNAME + 7];\n  FILE *fp;\n\n  /* Try to open the configuration file. */\n  fp = fopen(filename, \"r\");\n  if (!fp)\n    return -1;\n\n  ctx->lhs = NULL;\n  ctx->rhs = NULL;\n  while (fgets(buf, sizeof(buf), fp) != NULL)\n    {\n      p = buf;\n      if (*p == '#' || *p == '\\n' || *p == '\\r')\n\tcontinue;\n      while(*p == ' ' || *p == '\\t')\n\tp++;\n      key = p;\n      while(*p != ' ' && *p != '\\t' && *p != '=')\n\tp++;\n      *p++ = 0;\n\t\t\n      while(isspace((unsigned char)*p) || *p == '=')\n\tp++;\n      data = p;\n      while(!isspace((unsigned char)*p))\n\tp++;\n      *p = 0;\n\n      if (cistrcmp(key, \"lhs\") == 0 || cistrcmp(key, \"rhs\") == 0)\n\t{\n\t  which = (cistrcmp(key, \"lhs\") == 0) ? &ctx->lhs : &ctx->rhs;\n\t  *which = malloc(strlen(data) + 1);\n\t  if (!*which)\n\t    {\n\t      errno = ENOMEM;\n\t      return -1;\n\t    }\n\t  strcpy(*which, data);\n\t}\n    }\n  fclose(fp);\n\n  /* Make sure that the rhs is set. */\n  if (!ctx->rhs)\n    {\n      errno = ENOEXEC;\n      return -1;\n    }\n\n  return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,22 +7,7 @@\n   /* Try to open the configuration file. */\n   fp = fopen(filename, \"r\");\n   if (!fp)\n-    {\n-      /* Use compiled in default domain names. */\n-      ctx->lhs = malloc(strlen(DEF_LHS) + 1);\n-      ctx->rhs = malloc(strlen(DEF_RHS) + 1);\n-      if (ctx->lhs && ctx->rhs)\n-\t{\n-\t  strcpy(ctx->lhs, DEF_LHS);\n-\t  strcpy(ctx->rhs, DEF_RHS);\n-\t  return 0;\n-\t}\n-      else\n-\t{\n-\t  errno = ENOMEM;\n-\t  return -1;\n-\t}\n-    }\n+    return -1;\n \n   ctx->lhs = NULL;\n   ctx->rhs = NULL;",
        "diff_line_info": {
            "deleted_lines": [
                "    {",
                "      /* Use compiled in default domain names. */",
                "      ctx->lhs = malloc(strlen(DEF_LHS) + 1);",
                "      ctx->rhs = malloc(strlen(DEF_RHS) + 1);",
                "      if (ctx->lhs && ctx->rhs)",
                "\t{",
                "\t  strcpy(ctx->lhs, DEF_LHS);",
                "\t  strcpy(ctx->rhs, DEF_RHS);",
                "\t  return 0;",
                "\t}",
                "      else",
                "\t{",
                "\t  errno = ENOMEM;",
                "\t  return -1;",
                "\t}",
                "    }"
            ],
            "added_lines": [
                "    return -1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9922",
        "func_name": "torvalds/linux/ecryptfs_mount",
        "description": "The eCryptfs subsystem in the Linux kernel before 3.18 allows local users to gain privileges via a large filesystem stack that includes an overlayfs layer, related to fs/ecryptfs/main.c and fs/overlayfs/super.c.",
        "git_url": "https://github.com/torvalds/linux/commit/69c433ed2ecd2d3264efd7afec4439524b319121",
        "commit_title": "fs: limit filesystem stacking depth",
        "commit_text": " Add a simple read-only counter to super_block that indicates how deep this is in the stack of filesystems.  Previously ecryptfs was the only stackable filesystem and it explicitly disallowed multiple layers of itself.  Overlayfs, however, can be stacked recursively and also may be stacked on top of ecryptfs or vice versa.  To limit the kernel stack usage we must limit the depth of the filesystem stack.  Initially the limit is set to 2. ",
        "func_before": "static struct dentry *ecryptfs_mount(struct file_system_type *fs_type, int flags,\n\t\t\tconst char *dev_name, void *raw_data)\n{\n\tstruct super_block *s;\n\tstruct ecryptfs_sb_info *sbi;\n\tstruct ecryptfs_dentry_info *root_info;\n\tconst char *err = \"Getting sb failed\";\n\tstruct inode *inode;\n\tstruct path path;\n\tuid_t check_ruid;\n\tint rc;\n\n\tsbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);\n\tif (!sbi) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);\n\tif (rc) {\n\t\terr = \"Error parsing options\";\n\t\tgoto out;\n\t}\n\n\ts = sget(fs_type, NULL, set_anon_super, flags, NULL);\n\tif (IS_ERR(s)) {\n\t\trc = PTR_ERR(s);\n\t\tgoto out;\n\t}\n\n\trc = bdi_setup_and_register(&sbi->bdi, \"ecryptfs\", BDI_CAP_MAP_COPY);\n\tif (rc)\n\t\tgoto out1;\n\n\tecryptfs_set_superblock_private(s, sbi);\n\ts->s_bdi = &sbi->bdi;\n\n\t/* ->kill_sb() will take care of sbi after that point */\n\tsbi = NULL;\n\ts->s_op = &ecryptfs_sops;\n\ts->s_d_op = &ecryptfs_dops;\n\n\terr = \"Reading sb failed\";\n\trc = kern_path(dev_name, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &path);\n\tif (rc) {\n\t\tecryptfs_printk(KERN_WARNING, \"kern_path() failed\\n\");\n\t\tgoto out1;\n\t}\n\tif (path.dentry->d_sb->s_type == &ecryptfs_fs_type) {\n\t\trc = -EINVAL;\n\t\tprintk(KERN_ERR \"Mount on filesystem of type \"\n\t\t\t\"eCryptfs explicitly disallowed due to \"\n\t\t\t\"known incompatibilities\\n\");\n\t\tgoto out_free;\n\t}\n\n\tif (check_ruid && !uid_eq(path.dentry->d_inode->i_uid, current_uid())) {\n\t\trc = -EPERM;\n\t\tprintk(KERN_ERR \"Mount of device (uid: %d) not owned by \"\n\t\t       \"requested user (uid: %d)\\n\",\n\t\t\ti_uid_read(path.dentry->d_inode),\n\t\t\tfrom_kuid(&init_user_ns, current_uid()));\n\t\tgoto out_free;\n\t}\n\n\tecryptfs_set_superblock_lower(s, path.dentry->d_sb);\n\n\t/**\n\t * Set the POSIX ACL flag based on whether they're enabled in the lower\n\t * mount. Force a read-only eCryptfs mount if the lower mount is ro.\n\t * Allow a ro eCryptfs mount even when the lower mount is rw.\n\t */\n\ts->s_flags = flags & ~MS_POSIXACL;\n\ts->s_flags |= path.dentry->d_sb->s_flags & (MS_RDONLY | MS_POSIXACL);\n\n\ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n\ts->s_blocksize = path.dentry->d_sb->s_blocksize;\n\ts->s_magic = ECRYPTFS_SUPER_MAGIC;\n\n\tinode = ecryptfs_get_inode(path.dentry->d_inode, s);\n\trc = PTR_ERR(inode);\n\tif (IS_ERR(inode))\n\t\tgoto out_free;\n\n\ts->s_root = d_make_root(inode);\n\tif (!s->s_root) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\trc = -ENOMEM;\n\troot_info = kmem_cache_zalloc(ecryptfs_dentry_info_cache, GFP_KERNEL);\n\tif (!root_info)\n\t\tgoto out_free;\n\n\t/* ->kill_sb() will take care of root_info */\n\tecryptfs_set_dentry_private(s->s_root, root_info);\n\troot_info->lower_path = path;\n\n\ts->s_flags |= MS_ACTIVE;\n\treturn dget(s->s_root);\n\nout_free:\n\tpath_put(&path);\nout1:\n\tdeactivate_locked_super(s);\nout:\n\tif (sbi) {\n\t\tecryptfs_destroy_mount_crypt_stat(&sbi->mount_crypt_stat);\n\t\tkmem_cache_free(ecryptfs_sb_info_cache, sbi);\n\t}\n\tprintk(KERN_ERR \"%s; rc = [%d]\\n\", err, rc);\n\treturn ERR_PTR(rc);\n}",
        "func": "static struct dentry *ecryptfs_mount(struct file_system_type *fs_type, int flags,\n\t\t\tconst char *dev_name, void *raw_data)\n{\n\tstruct super_block *s;\n\tstruct ecryptfs_sb_info *sbi;\n\tstruct ecryptfs_dentry_info *root_info;\n\tconst char *err = \"Getting sb failed\";\n\tstruct inode *inode;\n\tstruct path path;\n\tuid_t check_ruid;\n\tint rc;\n\n\tsbi = kmem_cache_zalloc(ecryptfs_sb_info_cache, GFP_KERNEL);\n\tif (!sbi) {\n\t\trc = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trc = ecryptfs_parse_options(sbi, raw_data, &check_ruid);\n\tif (rc) {\n\t\terr = \"Error parsing options\";\n\t\tgoto out;\n\t}\n\n\ts = sget(fs_type, NULL, set_anon_super, flags, NULL);\n\tif (IS_ERR(s)) {\n\t\trc = PTR_ERR(s);\n\t\tgoto out;\n\t}\n\n\trc = bdi_setup_and_register(&sbi->bdi, \"ecryptfs\", BDI_CAP_MAP_COPY);\n\tif (rc)\n\t\tgoto out1;\n\n\tecryptfs_set_superblock_private(s, sbi);\n\ts->s_bdi = &sbi->bdi;\n\n\t/* ->kill_sb() will take care of sbi after that point */\n\tsbi = NULL;\n\ts->s_op = &ecryptfs_sops;\n\ts->s_d_op = &ecryptfs_dops;\n\n\terr = \"Reading sb failed\";\n\trc = kern_path(dev_name, LOOKUP_FOLLOW | LOOKUP_DIRECTORY, &path);\n\tif (rc) {\n\t\tecryptfs_printk(KERN_WARNING, \"kern_path() failed\\n\");\n\t\tgoto out1;\n\t}\n\tif (path.dentry->d_sb->s_type == &ecryptfs_fs_type) {\n\t\trc = -EINVAL;\n\t\tprintk(KERN_ERR \"Mount on filesystem of type \"\n\t\t\t\"eCryptfs explicitly disallowed due to \"\n\t\t\t\"known incompatibilities\\n\");\n\t\tgoto out_free;\n\t}\n\n\tif (check_ruid && !uid_eq(path.dentry->d_inode->i_uid, current_uid())) {\n\t\trc = -EPERM;\n\t\tprintk(KERN_ERR \"Mount of device (uid: %d) not owned by \"\n\t\t       \"requested user (uid: %d)\\n\",\n\t\t\ti_uid_read(path.dentry->d_inode),\n\t\t\tfrom_kuid(&init_user_ns, current_uid()));\n\t\tgoto out_free;\n\t}\n\n\tecryptfs_set_superblock_lower(s, path.dentry->d_sb);\n\n\t/**\n\t * Set the POSIX ACL flag based on whether they're enabled in the lower\n\t * mount. Force a read-only eCryptfs mount if the lower mount is ro.\n\t * Allow a ro eCryptfs mount even when the lower mount is rw.\n\t */\n\ts->s_flags = flags & ~MS_POSIXACL;\n\ts->s_flags |= path.dentry->d_sb->s_flags & (MS_RDONLY | MS_POSIXACL);\n\n\ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n\ts->s_blocksize = path.dentry->d_sb->s_blocksize;\n\ts->s_magic = ECRYPTFS_SUPER_MAGIC;\n\ts->s_stack_depth = path.dentry->d_sb->s_stack_depth + 1;\n\n\trc = -EINVAL;\n\tif (s->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n\t\tpr_err(\"eCryptfs: maximum fs stacking depth exceeded\\n\");\n\t\tgoto out_free;\n\t}\n\n\tinode = ecryptfs_get_inode(path.dentry->d_inode, s);\n\trc = PTR_ERR(inode);\n\tif (IS_ERR(inode))\n\t\tgoto out_free;\n\n\ts->s_root = d_make_root(inode);\n\tif (!s->s_root) {\n\t\trc = -ENOMEM;\n\t\tgoto out_free;\n\t}\n\n\trc = -ENOMEM;\n\troot_info = kmem_cache_zalloc(ecryptfs_dentry_info_cache, GFP_KERNEL);\n\tif (!root_info)\n\t\tgoto out_free;\n\n\t/* ->kill_sb() will take care of root_info */\n\tecryptfs_set_dentry_private(s->s_root, root_info);\n\troot_info->lower_path = path;\n\n\ts->s_flags |= MS_ACTIVE;\n\treturn dget(s->s_root);\n\nout_free:\n\tpath_put(&path);\nout1:\n\tdeactivate_locked_super(s);\nout:\n\tif (sbi) {\n\t\tecryptfs_destroy_mount_crypt_stat(&sbi->mount_crypt_stat);\n\t\tkmem_cache_free(ecryptfs_sb_info_cache, sbi);\n\t}\n\tprintk(KERN_ERR \"%s; rc = [%d]\\n\", err, rc);\n\treturn ERR_PTR(rc);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -76,6 +76,13 @@\n \ts->s_maxbytes = path.dentry->d_sb->s_maxbytes;\n \ts->s_blocksize = path.dentry->d_sb->s_blocksize;\n \ts->s_magic = ECRYPTFS_SUPER_MAGIC;\n+\ts->s_stack_depth = path.dentry->d_sb->s_stack_depth + 1;\n+\n+\trc = -EINVAL;\n+\tif (s->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n+\t\tpr_err(\"eCryptfs: maximum fs stacking depth exceeded\\n\");\n+\t\tgoto out_free;\n+\t}\n \n \tinode = ecryptfs_get_inode(path.dentry->d_inode, s);\n \trc = PTR_ERR(inode);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\ts->s_stack_depth = path.dentry->d_sb->s_stack_depth + 1;",
                "",
                "\trc = -EINVAL;",
                "\tif (s->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {",
                "\t\tpr_err(\"eCryptfs: maximum fs stacking depth exceeded\\n\");",
                "\t\tgoto out_free;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9922",
        "func_name": "torvalds/linux/ovl_fill_super",
        "description": "The eCryptfs subsystem in the Linux kernel before 3.18 allows local users to gain privileges via a large filesystem stack that includes an overlayfs layer, related to fs/ecryptfs/main.c and fs/overlayfs/super.c.",
        "git_url": "https://github.com/torvalds/linux/commit/69c433ed2ecd2d3264efd7afec4439524b319121",
        "commit_title": "fs: limit filesystem stacking depth",
        "commit_text": " Add a simple read-only counter to super_block that indicates how deep this is in the stack of filesystems.  Previously ecryptfs was the only stackable filesystem and it explicitly disallowed multiple layers of itself.  Overlayfs, however, can be stacked recursively and also may be stacked on top of ecryptfs or vice versa.  To limit the kernel stack usage we must limit the depth of the filesystem stack.  Initially the limit is set to 2. ",
        "func_before": "static int ovl_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct path lowerpath;\n\tstruct path upperpath;\n\tstruct path workpath;\n\tstruct inode *root_inode;\n\tstruct dentry *root_dentry;\n\tstruct ovl_entry *oe;\n\tstruct ovl_fs *ufs;\n\tstruct kstatfs statfs;\n\tint err;\n\n\terr = -ENOMEM;\n\tufs = kzalloc(sizeof(struct ovl_fs), GFP_KERNEL);\n\tif (!ufs)\n\t\tgoto out;\n\n\terr = ovl_parse_opt((char *) data, &ufs->config);\n\tif (err)\n\t\tgoto out_free_config;\n\n\t/* FIXME: workdir is not needed for a R/O mount */\n\terr = -EINVAL;\n\tif (!ufs->config.upperdir || !ufs->config.lowerdir ||\n\t    !ufs->config.workdir) {\n\t\tpr_err(\"overlayfs: missing upperdir or lowerdir or workdir\\n\");\n\t\tgoto out_free_config;\n\t}\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry();\n\tif (oe == NULL)\n\t\tgoto out_free_config;\n\n\terr = ovl_mount_dir(ufs->config.upperdir, &upperpath);\n\tif (err)\n\t\tgoto out_free_oe;\n\n\terr = ovl_mount_dir(ufs->config.lowerdir, &lowerpath);\n\tif (err)\n\t\tgoto out_put_upperpath;\n\n\terr = ovl_mount_dir(ufs->config.workdir, &workpath);\n\tif (err)\n\t\tgoto out_put_lowerpath;\n\n\terr = -EINVAL;\n\tif (!S_ISDIR(upperpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(lowerpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(workpath.dentry->d_inode->i_mode)) {\n\t\tpr_err(\"overlayfs: upperdir or lowerdir or workdir not a directory\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (upperpath.mnt != workpath.mnt) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must reside under the same mount\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tif (!ovl_workdir_ok(workpath.dentry, upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must be separate subtrees\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of upperdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(lowerpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of lowerdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\terr = vfs_statfs(&lowerpath, &statfs);\n\tif (err) {\n\t\tpr_err(\"overlayfs: statfs failed on lowerpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tufs->lower_namelen = statfs.f_namelen;\n\n\tufs->upper_mnt = clone_private_mount(&upperpath);\n\terr = PTR_ERR(ufs->upper_mnt);\n\tif (IS_ERR(ufs->upper_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone upperpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tufs->lower_mnt = clone_private_mount(&lowerpath);\n\terr = PTR_ERR(ufs->lower_mnt);\n\tif (IS_ERR(ufs->lower_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone lowerpath\\n\");\n\t\tgoto out_put_upper_mnt;\n\t}\n\n\tufs->workdir = ovl_workdir_create(ufs->upper_mnt, workpath.dentry);\n\terr = PTR_ERR(ufs->workdir);\n\tif (IS_ERR(ufs->workdir)) {\n\t\tpr_err(\"overlayfs: failed to create directory %s/%s\\n\",\n\t\t       ufs->config.workdir, OVL_WORKDIR_NAME);\n\t\tgoto out_put_lower_mnt;\n\t}\n\n\t/*\n\t * Make lower_mnt R/O.  That way fchmod/fchown on lower file\n\t * will fail instead of modifying lower fs.\n\t */\n\tufs->lower_mnt->mnt_flags |= MNT_READONLY;\n\n\t/* If the upper fs is r/o, we mark overlayfs r/o too */\n\tif (ufs->upper_mnt->mnt_sb->s_flags & MS_RDONLY)\n\t\tsb->s_flags |= MS_RDONLY;\n\n\tsb->s_d_op = &ovl_dentry_operations;\n\n\terr = -ENOMEM;\n\troot_inode = ovl_new_inode(sb, S_IFDIR, oe);\n\tif (!root_inode)\n\t\tgoto out_put_workdir;\n\n\troot_dentry = d_make_root(root_inode);\n\tif (!root_dentry)\n\t\tgoto out_put_workdir;\n\n\tmntput(upperpath.mnt);\n\tmntput(lowerpath.mnt);\n\tpath_put(&workpath);\n\n\toe->__upperdentry = upperpath.dentry;\n\toe->lowerdentry = lowerpath.dentry;\n\n\troot_dentry->d_fsdata = oe;\n\n\tsb->s_magic = OVERLAYFS_SUPER_MAGIC;\n\tsb->s_op = &ovl_super_operations;\n\tsb->s_root = root_dentry;\n\tsb->s_fs_info = ufs;\n\n\treturn 0;\n\nout_put_workdir:\n\tdput(ufs->workdir);\nout_put_lower_mnt:\n\tmntput(ufs->lower_mnt);\nout_put_upper_mnt:\n\tmntput(ufs->upper_mnt);\nout_put_workpath:\n\tpath_put(&workpath);\nout_put_lowerpath:\n\tpath_put(&lowerpath);\nout_put_upperpath:\n\tpath_put(&upperpath);\nout_free_oe:\n\tkfree(oe);\nout_free_config:\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\nout:\n\treturn err;\n}",
        "func": "static int ovl_fill_super(struct super_block *sb, void *data, int silent)\n{\n\tstruct path lowerpath;\n\tstruct path upperpath;\n\tstruct path workpath;\n\tstruct inode *root_inode;\n\tstruct dentry *root_dentry;\n\tstruct ovl_entry *oe;\n\tstruct ovl_fs *ufs;\n\tstruct kstatfs statfs;\n\tint err;\n\n\terr = -ENOMEM;\n\tufs = kzalloc(sizeof(struct ovl_fs), GFP_KERNEL);\n\tif (!ufs)\n\t\tgoto out;\n\n\terr = ovl_parse_opt((char *) data, &ufs->config);\n\tif (err)\n\t\tgoto out_free_config;\n\n\t/* FIXME: workdir is not needed for a R/O mount */\n\terr = -EINVAL;\n\tif (!ufs->config.upperdir || !ufs->config.lowerdir ||\n\t    !ufs->config.workdir) {\n\t\tpr_err(\"overlayfs: missing upperdir or lowerdir or workdir\\n\");\n\t\tgoto out_free_config;\n\t}\n\n\terr = -ENOMEM;\n\toe = ovl_alloc_entry();\n\tif (oe == NULL)\n\t\tgoto out_free_config;\n\n\terr = ovl_mount_dir(ufs->config.upperdir, &upperpath);\n\tif (err)\n\t\tgoto out_free_oe;\n\n\terr = ovl_mount_dir(ufs->config.lowerdir, &lowerpath);\n\tif (err)\n\t\tgoto out_put_upperpath;\n\n\terr = ovl_mount_dir(ufs->config.workdir, &workpath);\n\tif (err)\n\t\tgoto out_put_lowerpath;\n\n\terr = -EINVAL;\n\tif (!S_ISDIR(upperpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(lowerpath.dentry->d_inode->i_mode) ||\n\t    !S_ISDIR(workpath.dentry->d_inode->i_mode)) {\n\t\tpr_err(\"overlayfs: upperdir or lowerdir or workdir not a directory\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (upperpath.mnt != workpath.mnt) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must reside under the same mount\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tif (!ovl_workdir_ok(workpath.dentry, upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: workdir and upperdir must be separate subtrees\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(upperpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of upperdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tif (!ovl_is_allowed_fs_type(lowerpath.dentry)) {\n\t\tpr_err(\"overlayfs: filesystem of lowerdir is not supported\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\terr = vfs_statfs(&lowerpath, &statfs);\n\tif (err) {\n\t\tpr_err(\"overlayfs: statfs failed on lowerpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\tufs->lower_namelen = statfs.f_namelen;\n\n\tsb->s_stack_depth = max(upperpath.mnt->mnt_sb->s_stack_depth,\n\t\t\t\tlowerpath.mnt->mnt_sb->s_stack_depth) + 1;\n\n\terr = -EINVAL;\n\tif (sb->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n\t\tpr_err(\"overlayfs: maximum fs stacking depth exceeded\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tufs->upper_mnt = clone_private_mount(&upperpath);\n\terr = PTR_ERR(ufs->upper_mnt);\n\tif (IS_ERR(ufs->upper_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone upperpath\\n\");\n\t\tgoto out_put_workpath;\n\t}\n\n\tufs->lower_mnt = clone_private_mount(&lowerpath);\n\terr = PTR_ERR(ufs->lower_mnt);\n\tif (IS_ERR(ufs->lower_mnt)) {\n\t\tpr_err(\"overlayfs: failed to clone lowerpath\\n\");\n\t\tgoto out_put_upper_mnt;\n\t}\n\n\tufs->workdir = ovl_workdir_create(ufs->upper_mnt, workpath.dentry);\n\terr = PTR_ERR(ufs->workdir);\n\tif (IS_ERR(ufs->workdir)) {\n\t\tpr_err(\"overlayfs: failed to create directory %s/%s\\n\",\n\t\t       ufs->config.workdir, OVL_WORKDIR_NAME);\n\t\tgoto out_put_lower_mnt;\n\t}\n\n\t/*\n\t * Make lower_mnt R/O.  That way fchmod/fchown on lower file\n\t * will fail instead of modifying lower fs.\n\t */\n\tufs->lower_mnt->mnt_flags |= MNT_READONLY;\n\n\t/* If the upper fs is r/o, we mark overlayfs r/o too */\n\tif (ufs->upper_mnt->mnt_sb->s_flags & MS_RDONLY)\n\t\tsb->s_flags |= MS_RDONLY;\n\n\tsb->s_d_op = &ovl_dentry_operations;\n\n\terr = -ENOMEM;\n\troot_inode = ovl_new_inode(sb, S_IFDIR, oe);\n\tif (!root_inode)\n\t\tgoto out_put_workdir;\n\n\troot_dentry = d_make_root(root_inode);\n\tif (!root_dentry)\n\t\tgoto out_put_workdir;\n\n\tmntput(upperpath.mnt);\n\tmntput(lowerpath.mnt);\n\tpath_put(&workpath);\n\n\toe->__upperdentry = upperpath.dentry;\n\toe->lowerdentry = lowerpath.dentry;\n\n\troot_dentry->d_fsdata = oe;\n\n\tsb->s_magic = OVERLAYFS_SUPER_MAGIC;\n\tsb->s_op = &ovl_super_operations;\n\tsb->s_root = root_dentry;\n\tsb->s_fs_info = ufs;\n\n\treturn 0;\n\nout_put_workdir:\n\tdput(ufs->workdir);\nout_put_lower_mnt:\n\tmntput(ufs->lower_mnt);\nout_put_upper_mnt:\n\tmntput(ufs->upper_mnt);\nout_put_workpath:\n\tpath_put(&workpath);\nout_put_lowerpath:\n\tpath_put(&lowerpath);\nout_put_upperpath:\n\tpath_put(&upperpath);\nout_free_oe:\n\tkfree(oe);\nout_free_config:\n\tkfree(ufs->config.lowerdir);\n\tkfree(ufs->config.upperdir);\n\tkfree(ufs->config.workdir);\n\tkfree(ufs);\nout:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -77,6 +77,15 @@\n \t\tgoto out_put_workpath;\n \t}\n \tufs->lower_namelen = statfs.f_namelen;\n+\n+\tsb->s_stack_depth = max(upperpath.mnt->mnt_sb->s_stack_depth,\n+\t\t\t\tlowerpath.mnt->mnt_sb->s_stack_depth) + 1;\n+\n+\terr = -EINVAL;\n+\tif (sb->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {\n+\t\tpr_err(\"overlayfs: maximum fs stacking depth exceeded\\n\");\n+\t\tgoto out_put_workpath;\n+\t}\n \n \tufs->upper_mnt = clone_private_mount(&upperpath);\n \terr = PTR_ERR(ufs->upper_mnt);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tsb->s_stack_depth = max(upperpath.mnt->mnt_sb->s_stack_depth,",
                "\t\t\t\tlowerpath.mnt->mnt_sb->s_stack_depth) + 1;",
                "",
                "\terr = -EINVAL;",
                "\tif (sb->s_stack_depth > FILESYSTEM_MAX_STACK_DEPTH) {",
                "\t\tpr_err(\"overlayfs: maximum fs stacking depth exceeded\\n\");",
                "\t\tgoto out_put_workpath;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10318",
        "func_name": "torvalds/linux/fscrypt_process_policy",
        "description": "A missing authorization check in the fscrypt_process_policy function in fs/crypto/policy.c in the ext4 and f2fs filesystem encryption support in the Linux kernel before 4.7.4 allows a user to assign an encryption policy to a directory owned by a different user, potentially creating a denial of service.",
        "git_url": "https://github.com/torvalds/linux/commit/163ae1c6ad6299b19e22b4a35d5ab24a89791a98",
        "commit_title": "fscrypto: add authorization check for setting encryption policy",
        "commit_text": " On an ext4 or f2fs filesystem with file encryption supported, a user could set an encryption policy on any empty directory(*) to which they had readonly access.  This is obviously problematic, since such a directory might be owned by another user and the new encryption policy would prevent that other user from creating files in their own directory (for example).  Fix this by requiring inode_owner_or_capable() permission to set an encryption policy.  This means that either the caller must own the file, or the caller must have the capability CAP_FOWNER.  (*) Or also on any regular file, for f2fs v4.6 and later and ext4     v4.8-rc1 and later; a separate bug fix is coming for that.  Cc: stable@vger.kernel.org # 4.1+; check fs/{ext4,f2fs}",
        "func_before": "int fscrypt_process_policy(struct inode *inode,\n\t\t\t\tconst struct fscrypt_policy *policy)\n{\n\tif (policy->version != 0)\n\t\treturn -EINVAL;\n\n\tif (!inode_has_encryption_context(inode)) {\n\t\tif (!inode->i_sb->s_cop->empty_dir)\n\t\t\treturn -EOPNOTSUPP;\n\t\tif (!inode->i_sb->s_cop->empty_dir(inode))\n\t\t\treturn -ENOTEMPTY;\n\t\treturn create_encryption_context_from_policy(inode, policy);\n\t}\n\n\tif (is_encryption_context_consistent_with_policy(inode, policy))\n\t\treturn 0;\n\n\tprintk(KERN_WARNING \"%s: Policy inconsistent with encryption context\\n\",\n\t       __func__);\n\treturn -EINVAL;\n}",
        "func": "int fscrypt_process_policy(struct inode *inode,\n\t\t\t\tconst struct fscrypt_policy *policy)\n{\n\tif (!inode_owner_or_capable(inode))\n\t\treturn -EACCES;\n\n\tif (policy->version != 0)\n\t\treturn -EINVAL;\n\n\tif (!inode_has_encryption_context(inode)) {\n\t\tif (!inode->i_sb->s_cop->empty_dir)\n\t\t\treturn -EOPNOTSUPP;\n\t\tif (!inode->i_sb->s_cop->empty_dir(inode))\n\t\t\treturn -ENOTEMPTY;\n\t\treturn create_encryption_context_from_policy(inode, policy);\n\t}\n\n\tif (is_encryption_context_consistent_with_policy(inode, policy))\n\t\treturn 0;\n\n\tprintk(KERN_WARNING \"%s: Policy inconsistent with encryption context\\n\",\n\t       __func__);\n\treturn -EINVAL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,9 @@\n int fscrypt_process_policy(struct inode *inode,\n \t\t\t\tconst struct fscrypt_policy *policy)\n {\n+\tif (!inode_owner_or_capable(inode))\n+\t\treturn -EACCES;\n+\n \tif (policy->version != 0)\n \t\treturn -EINVAL;\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!inode_owner_or_capable(inode))",
                "\t\treturn -EACCES;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3067",
        "func_name": "newlib-cygwin/create_token",
        "description": "Cygwin before 2.5.0 does not properly handle updating permissions when changing users, which allows attackers to gain privileges.",
        "git_url": "https://sourceware.org/git/?p=newlib-cygwin.git;a=commit;h=205862ed08649df8f50b926a2c58c963f571b044",
        "commit_title": "",
        "commit_text": "setuid: Create token from scratch without credentials of caller  \t* sec_auth.cc (get_token_group_sidlist): Drop auth_luid and \tauth_pos parameter.  Remove code adding a logon SID. \t(get_initgroups_sidlist): Drop auth_luid and auth_pos parameter. \tDrop in call to get_token_group_sidlist. Accommodate in callers. \t(get_setgroups_sidlist): Ditto. \t(create_token): Explicitely set auth_luid to ANONYMOUS_LOGON_LUID \tor LOCALSERVICE_LUID depending on OS.  Explain why. \tRemove handling of logon SID since we don't generate one anymore. \t(lsaauth): Drop now unused local variable auth_luid and auth_pos. \t* wincap.h (wincaps::has_broken_whoami): New element. \t* wincap.cc: Implement above element throughout.  ",
        "func_before": "HANDLE\ncreate_token (cygsid &usersid, user_groups &new_groups)\n{\n  NTSTATUS status;\n  LSA_HANDLE lsa = NULL;\n\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n\n  SECURITY_QUALITY_OF_SERVICE sqos =\n    { sizeof sqos, SecurityImpersonation, SECURITY_STATIC_TRACKING, FALSE };\n  OBJECT_ATTRIBUTES oa = { sizeof oa, 0, 0, 0, 0, &sqos };\n  LUID auth_luid = SYSTEM_LUID;\n  LARGE_INTEGER exp = { QuadPart:INT64_MAX };\n\n  TOKEN_USER user;\n  PTOKEN_GROUPS new_tok_gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  TOKEN_OWNER owner;\n  TOKEN_PRIMARY_GROUP pgrp;\n  TOKEN_DEFAULT_DACL dacl = {};\n  TOKEN_SOURCE source;\n  TOKEN_STATISTICS stats;\n  memcpy (source.SourceName, \"Cygwin.1\", 8);\n  source.SourceIdentifier.HighPart = 0;\n  source.SourceIdentifier.LowPart = 0x0101;\n\n  HANDLE token = INVALID_HANDLE_VALUE;\n  HANDLE primary_token = INVALID_HANDLE_VALUE;\n\n  PTOKEN_GROUPS my_tok_gsids = NULL;\n  cygpsid mandatory_integrity_sid;\n  ULONG size;\n  size_t psize = 0;\n\n  /* SE_CREATE_TOKEN_NAME privilege needed to call NtCreateToken. */\n  push_self_privilege (SE_CREATE_TOKEN_PRIVILEGE, true);\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* User, owner, primary group. */\n  user.User.Sid = usersid;\n  user.User.Attributes = 0;\n  owner.Owner = usersid;\n\n  /* Retrieve authentication id and group list from own process. */\n  if (hProcToken)\n    {\n      /* Switching user context to SYSTEM doesn't inherit the authentication\n\t id of the user account running current process. */\n      if (usersid == well_known_system_sid)\n\t/* nothing to do */;\n      else\n\t{\n\t  status = NtQueryInformationToken (hProcToken, TokenStatistics,\n\t\t\t\t\t    &stats, sizeof stats, &size);\n\t  if (!NT_SUCCESS (status))\n\t    debug_printf (\"NtQueryInformationToken(hProcToken, \"\n\t\t\t  \"TokenStatistics), %y\", status);\n\t  else\n\t    auth_luid = stats.AuthenticationId;\n\t}\n\n      /* Retrieving current processes group list to be able to inherit\n\t some important well known group sids. */\n      status = NtQueryInformationToken (hProcToken, TokenGroups, NULL, 0,\n\t\t\t\t\t&size);\n      if (!NT_SUCCESS (status) && status != STATUS_BUFFER_TOO_SMALL)\n\tdebug_printf (\"NtQueryInformationToken(hProcToken, TokenGroups), %y\",\n\t\t      status);\n      else if (!(my_tok_gsids = (PTOKEN_GROUPS) malloc (size)))\n\tdebug_printf (\"malloc (my_tok_gsids) failed.\");\n      else\n\t{\n\t  status = NtQueryInformationToken (hProcToken, TokenGroups,\n\t\t\t\t\t    my_tok_gsids, size, &size);\n\t  if (!NT_SUCCESS (status))\n\t    {\n\t      debug_printf (\"NtQueryInformationToken(hProcToken, TokenGroups), \"\n\t\t\t    \"%y\", status);\n\t      free (my_tok_gsids);\n\t      my_tok_gsids = NULL;\n\t    }\n\t}\n    }\n\n  /* Create list of groups, the user is member in. */\n  int auth_pos;\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, my_tok_gsids, new_groups,\n\t\t\t   auth_luid, auth_pos);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    my_tok_gsids, auth_luid, auth_pos))\n    goto out;\n\n  /* Primary group. */\n  pgrp.PrimaryGroup = new_groups.pgsid;\n\n  /* Create a TOKEN_GROUPS list from the above retrieved list of sids. */\n  new_tok_gsids = (PTOKEN_GROUPS)\n\t\t  alloca (sizeof (DWORD) + (tmp_gsids.count () + 1)\n\t\t\t\t\t   * sizeof (SID_AND_ATTRIBUTES));\n  new_tok_gsids->GroupCount = tmp_gsids.count ();\n  for (DWORD i = 0; i < new_tok_gsids->GroupCount; ++i)\n    {\n      new_tok_gsids->Groups[i].Sid = tmp_gsids.sids[i];\n      new_tok_gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t\t    | SE_GROUP_ENABLED;\n    }\n  if (auth_pos >= 0)\n    new_tok_gsids->Groups[auth_pos].Attributes |= SE_GROUP_LOGON_ID;\n\n  /* Retrieve list of privileges of that user.  Based on the usersid and\n     the returned privileges, get_priv_list sets the mandatory_integrity_sid\n     pointer to the correct MIC SID for UAC. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize,\n\t\t\t       &mandatory_integrity_sid)))\n    goto out;\n\n  /* On systems supporting Mandatory Integrity Control, add the MIC SID. */\n  if (wincap.has_mandatory_integrity_control ())\n    {\n      new_tok_gsids->Groups[new_tok_gsids->GroupCount].Attributes =\n\tSE_GROUP_INTEGRITY | SE_GROUP_INTEGRITY_ENABLED;\n      new_tok_gsids->Groups[new_tok_gsids->GroupCount++].Sid\n\t= mandatory_integrity_sid;\n    }\n\n  /* Let's be heroic... */\n  status = NtCreateToken (&token, TOKEN_ALL_ACCESS, &oa, TokenImpersonation,\n\t\t\t  &auth_luid, &exp, &user, new_tok_gsids, privs, &owner,\n\t\t\t  &pgrp, &dacl, &source);\n  if (status)\n    __seterrno_from_nt_status (status);\n  else\n    {\n      /* Convert to primary token. */\n      if (!DuplicateTokenEx (token, MAXIMUM_ALLOWED, &sec_none,\n\t\t\t     SecurityImpersonation, TokenPrimary,\n\t\t\t     &primary_token))\n\t{\n\t  __seterrno ();\n\t  debug_printf (\"DuplicateTokenEx %E\");\n\t}\n    }\n\nout:\n  pop_self_privilege ();\n  if (token != INVALID_HANDLE_VALUE)\n    CloseHandle (token);\n  if (privs)\n    free (privs);\n  if (my_tok_gsids)\n    free (my_tok_gsids);\n  lsa_close_policy (lsa);\n\n  debug_printf (\"%p = create_token ()\", primary_token);\n  return primary_token;\n}",
        "func": "HANDLE\ncreate_token (cygsid &usersid, user_groups &new_groups)\n{\n  NTSTATUS status;\n  LSA_HANDLE lsa = NULL;\n\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n\n  SECURITY_QUALITY_OF_SERVICE sqos =\n    { sizeof sqos, SecurityImpersonation, SECURITY_STATIC_TRACKING, FALSE };\n  OBJECT_ATTRIBUTES oa = { sizeof oa, 0, 0, 0, 0, &sqos };\n  /* Up to Windows 7, when using a authwentication LUID other than \"Anonymous\",\n     Windows whoami prints the wrong username, the one from the login session,\n     not the one from the actual user token of the process.  This is apparently\n     fixed in Windows 8.  However, starting with Windows 8, access rights of\n     the anonymous logon session is further restricted.  Therefore we create\n     the new user token with the authentication id of the local service\n     account.  Hopefully that's sufficient. */\n  const LUID auth_luid_7 = ANONYMOUS_LOGON_LUID;\n  const LUID auth_luid_8 = LOCALSERVICE_LUID;\n  LUID auth_luid = wincap.has_broken_whoami () ? auth_luid_7 : auth_luid_8;\n  LARGE_INTEGER exp = { QuadPart:INT64_MAX };\n\n  TOKEN_USER user;\n  PTOKEN_GROUPS new_tok_gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  TOKEN_OWNER owner;\n  TOKEN_PRIMARY_GROUP pgrp;\n  TOKEN_DEFAULT_DACL dacl = {};\n  TOKEN_SOURCE source;\n  TOKEN_STATISTICS stats;\n  memcpy (source.SourceName, \"Cygwin.1\", 8);\n  source.SourceIdentifier.HighPart = 0;\n  source.SourceIdentifier.LowPart = 0x0101;\n\n  HANDLE token = INVALID_HANDLE_VALUE;\n  HANDLE primary_token = INVALID_HANDLE_VALUE;\n\n  PTOKEN_GROUPS my_tok_gsids = NULL;\n  cygpsid mandatory_integrity_sid;\n  ULONG size;\n  size_t psize = 0;\n\n  /* SE_CREATE_TOKEN_NAME privilege needed to call NtCreateToken. */\n  push_self_privilege (SE_CREATE_TOKEN_PRIVILEGE, true);\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* User, owner, primary group. */\n  user.User.Sid = usersid;\n  user.User.Attributes = 0;\n  owner.Owner = usersid;\n\n  /* Retrieve authentication id and group list from own process. */\n  if (hProcToken)\n    {\n      /* Switching user context to SYSTEM doesn't inherit the authentication\n\t id of the user account running current process. */\n      if (usersid == well_known_system_sid)\n\t/* nothing to do */;\n      else\n\t{\n\t  status = NtQueryInformationToken (hProcToken, TokenStatistics,\n\t\t\t\t\t    &stats, sizeof stats, &size);\n\t  if (!NT_SUCCESS (status))\n\t    debug_printf (\"NtQueryInformationToken(hProcToken, \"\n\t\t\t  \"TokenStatistics), %y\", status);\n\t}\n\n      /* Retrieving current processes group list to be able to inherit\n\t some important well known group sids. */\n      status = NtQueryInformationToken (hProcToken, TokenGroups, NULL, 0,\n\t\t\t\t\t&size);\n      if (!NT_SUCCESS (status) && status != STATUS_BUFFER_TOO_SMALL)\n\tdebug_printf (\"NtQueryInformationToken(hProcToken, TokenGroups), %y\",\n\t\t      status);\n      else if (!(my_tok_gsids = (PTOKEN_GROUPS) malloc (size)))\n\tdebug_printf (\"malloc (my_tok_gsids) failed.\");\n      else\n\t{\n\t  status = NtQueryInformationToken (hProcToken, TokenGroups,\n\t\t\t\t\t    my_tok_gsids, size, &size);\n\t  if (!NT_SUCCESS (status))\n\t    {\n\t      debug_printf (\"NtQueryInformationToken(hProcToken, TokenGroups), \"\n\t\t\t    \"%y\", status);\n\t      free (my_tok_gsids);\n\t      my_tok_gsids = NULL;\n\t    }\n\t}\n    }\n\n  /* Create list of groups, the user is member in. */\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, my_tok_gsids, new_groups);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    my_tok_gsids))\n    goto out;\n\n  /* Primary group. */\n  pgrp.PrimaryGroup = new_groups.pgsid;\n\n  /* Create a TOKEN_GROUPS list from the above retrieved list of sids. */\n  new_tok_gsids = (PTOKEN_GROUPS)\n\t\t  alloca (sizeof (DWORD) + (tmp_gsids.count () + 1)\n\t\t\t\t\t   * sizeof (SID_AND_ATTRIBUTES));\n  new_tok_gsids->GroupCount = tmp_gsids.count ();\n  for (DWORD i = 0; i < new_tok_gsids->GroupCount; ++i)\n    {\n      new_tok_gsids->Groups[i].Sid = tmp_gsids.sids[i];\n      new_tok_gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t\t    | SE_GROUP_ENABLED;\n    }\n\n  /* Retrieve list of privileges of that user.  Based on the usersid and\n     the returned privileges, get_priv_list sets the mandatory_integrity_sid\n     pointer to the correct MIC SID for UAC. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize,\n\t\t\t       &mandatory_integrity_sid)))\n    goto out;\n\n  /* On systems supporting Mandatory Integrity Control, add the MIC SID. */\n  if (wincap.has_mandatory_integrity_control ())\n    {\n      new_tok_gsids->Groups[new_tok_gsids->GroupCount].Attributes =\n\tSE_GROUP_INTEGRITY | SE_GROUP_INTEGRITY_ENABLED;\n      new_tok_gsids->Groups[new_tok_gsids->GroupCount++].Sid\n\t= mandatory_integrity_sid;\n    }\n\n  /* Let's be heroic... */\n  status = NtCreateToken (&token, TOKEN_ALL_ACCESS, &oa, TokenImpersonation,\n\t\t\t  &auth_luid, &exp, &user, new_tok_gsids, privs, &owner,\n\t\t\t  &pgrp, &dacl, &source);\n  if (status)\n    __seterrno_from_nt_status (status);\n  else\n    {\n      /* Convert to primary token. */\n      if (!DuplicateTokenEx (token, MAXIMUM_ALLOWED, &sec_none,\n\t\t\t     SecurityImpersonation, TokenPrimary,\n\t\t\t     &primary_token))\n\t{\n\t  __seterrno ();\n\t  debug_printf (\"DuplicateTokenEx %E\");\n\t}\n    }\n\nout:\n  pop_self_privilege ();\n  if (token != INVALID_HANDLE_VALUE)\n    CloseHandle (token);\n  if (privs)\n    free (privs);\n  if (my_tok_gsids)\n    free (my_tok_gsids);\n  lsa_close_policy (lsa);\n\n  debug_printf (\"%p = create_token ()\", primary_token);\n  return primary_token;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,7 +9,16 @@\n   SECURITY_QUALITY_OF_SERVICE sqos =\n     { sizeof sqos, SecurityImpersonation, SECURITY_STATIC_TRACKING, FALSE };\n   OBJECT_ATTRIBUTES oa = { sizeof oa, 0, 0, 0, 0, &sqos };\n-  LUID auth_luid = SYSTEM_LUID;\n+  /* Up to Windows 7, when using a authwentication LUID other than \"Anonymous\",\n+     Windows whoami prints the wrong username, the one from the login session,\n+     not the one from the actual user token of the process.  This is apparently\n+     fixed in Windows 8.  However, starting with Windows 8, access rights of\n+     the anonymous logon session is further restricted.  Therefore we create\n+     the new user token with the authentication id of the local service\n+     account.  Hopefully that's sufficient. */\n+  const LUID auth_luid_7 = ANONYMOUS_LOGON_LUID;\n+  const LUID auth_luid_8 = LOCALSERVICE_LUID;\n+  LUID auth_luid = wincap.has_broken_whoami () ? auth_luid_7 : auth_luid_8;\n   LARGE_INTEGER exp = { QuadPart:INT64_MAX };\n \n   TOKEN_USER user;\n@@ -58,8 +67,6 @@\n \t  if (!NT_SUCCESS (status))\n \t    debug_printf (\"NtQueryInformationToken(hProcToken, \"\n \t\t\t  \"TokenStatistics), %y\", status);\n-\t  else\n-\t    auth_luid = stats.AuthenticationId;\n \t}\n \n       /* Retrieving current processes group list to be able to inherit\n@@ -86,12 +93,10 @@\n     }\n \n   /* Create list of groups, the user is member in. */\n-  int auth_pos;\n   if (new_groups.issetgroups ())\n-    get_setgroups_sidlist (tmp_gsids, usersid, my_tok_gsids, new_groups,\n-\t\t\t   auth_luid, auth_pos);\n+    get_setgroups_sidlist (tmp_gsids, usersid, my_tok_gsids, new_groups);\n   else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n-\t\t\t\t    my_tok_gsids, auth_luid, auth_pos))\n+\t\t\t\t    my_tok_gsids))\n     goto out;\n \n   /* Primary group. */\n@@ -109,8 +114,6 @@\n \t\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n \t\t\t\t\t    | SE_GROUP_ENABLED;\n     }\n-  if (auth_pos >= 0)\n-    new_tok_gsids->Groups[auth_pos].Attributes |= SE_GROUP_LOGON_ID;\n \n   /* Retrieve list of privileges of that user.  Based on the usersid and\n      the returned privileges, get_priv_list sets the mandatory_integrity_sid",
        "diff_line_info": {
            "deleted_lines": [
                "  LUID auth_luid = SYSTEM_LUID;",
                "\t  else",
                "\t    auth_luid = stats.AuthenticationId;",
                "  int auth_pos;",
                "    get_setgroups_sidlist (tmp_gsids, usersid, my_tok_gsids, new_groups,",
                "\t\t\t   auth_luid, auth_pos);",
                "\t\t\t\t    my_tok_gsids, auth_luid, auth_pos))",
                "  if (auth_pos >= 0)",
                "    new_tok_gsids->Groups[auth_pos].Attributes |= SE_GROUP_LOGON_ID;"
            ],
            "added_lines": [
                "  /* Up to Windows 7, when using a authwentication LUID other than \"Anonymous\",",
                "     Windows whoami prints the wrong username, the one from the login session,",
                "     not the one from the actual user token of the process.  This is apparently",
                "     fixed in Windows 8.  However, starting with Windows 8, access rights of",
                "     the anonymous logon session is further restricted.  Therefore we create",
                "     the new user token with the authentication id of the local service",
                "     account.  Hopefully that's sufficient. */",
                "  const LUID auth_luid_7 = ANONYMOUS_LOGON_LUID;",
                "  const LUID auth_luid_8 = LOCALSERVICE_LUID;",
                "  LUID auth_luid = wincap.has_broken_whoami () ? auth_luid_7 : auth_luid_8;",
                "    get_setgroups_sidlist (tmp_gsids, usersid, my_tok_gsids, new_groups);",
                "\t\t\t\t    my_tok_gsids))"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3067",
        "func_name": "newlib-cygwin/get_token_group_sidlist",
        "description": "Cygwin before 2.5.0 does not properly handle updating permissions when changing users, which allows attackers to gain privileges.",
        "git_url": "https://sourceware.org/git/?p=newlib-cygwin.git;a=commit;h=205862ed08649df8f50b926a2c58c963f571b044",
        "commit_title": "",
        "commit_text": "setuid: Create token from scratch without credentials of caller  \t* sec_auth.cc (get_token_group_sidlist): Drop auth_luid and \tauth_pos parameter.  Remove code adding a logon SID. \t(get_initgroups_sidlist): Drop auth_luid and auth_pos parameter. \tDrop in call to get_token_group_sidlist. Accommodate in callers. \t(get_setgroups_sidlist): Ditto. \t(create_token): Explicitely set auth_luid to ANONYMOUS_LOGON_LUID \tor LOCALSERVICE_LUID depending on OS.  Explain why. \tRemove handling of logon SID since we don't generate one anymore. \t(lsaauth): Drop now unused local variable auth_luid and auth_pos. \t* wincap.h (wincaps::has_broken_whoami): New element. \t* wincap.cc: Implement above element throughout.  ",
        "func_before": "static void\nget_token_group_sidlist (cygsidlist &grp_list, PTOKEN_GROUPS my_grps,\n\t\t\t LUID auth_luid, int &auth_pos)\n{\n  auth_pos = -1;\n  if (my_grps)\n    {\n      grp_list += well_known_local_sid;\n      if (wincap.has_console_logon_sid ())\n\tgrp_list += well_known_console_logon_sid;\n      if (sid_in_token_groups (my_grps, well_known_dialup_sid))\n\tgrp_list *= well_known_dialup_sid;\n      if (sid_in_token_groups (my_grps, well_known_network_sid))\n\tgrp_list *= well_known_network_sid;\n      if (sid_in_token_groups (my_grps, well_known_batch_sid))\n\tgrp_list *= well_known_batch_sid;\n      grp_list *= well_known_interactive_sid;\n#if 0\n      /* Don't add the SERVICE group when switching the user context.\n\t That's much too dangerous, since the service group adds the\n\t SE_IMPERSONATE_NAME privilege to the user.  After all, the\n\t process started with this token is not the service process\n\t anymore anyway. */\n      if (sid_in_token_groups (my_grps, well_known_service_sid))\n\tgrp_list *= well_known_service_sid;\n#endif\n      if (sid_in_token_groups (my_grps, well_known_this_org_sid))\n\tgrp_list *= well_known_this_org_sid;\n      grp_list *= well_known_users_sid;\n    }\n  else\n    {\n      grp_list += well_known_local_sid;\n      grp_list *= well_known_interactive_sid;\n      grp_list *= well_known_users_sid;\n    }\n  if (get_ll (auth_luid) != 999LL) /* != SYSTEM_LUID */\n    {\n      for (DWORD i = 0; i < my_grps->GroupCount; ++i)\n\tif (my_grps->Groups[i].Attributes & SE_GROUP_LOGON_ID)\n\t  {\n\t    grp_list += my_grps->Groups[i].Sid;\n\t    auth_pos = grp_list.count () - 1;\n\t    break;\n\t  }\n    }\n}",
        "func": "static void\nget_token_group_sidlist (cygsidlist &grp_list, PTOKEN_GROUPS my_grps)\n{\n  if (my_grps)\n    {\n      grp_list += well_known_local_sid;\n      if (wincap.has_console_logon_sid ())\n\tgrp_list += well_known_console_logon_sid;\n      if (sid_in_token_groups (my_grps, well_known_dialup_sid))\n\tgrp_list *= well_known_dialup_sid;\n      if (sid_in_token_groups (my_grps, well_known_network_sid))\n\tgrp_list *= well_known_network_sid;\n      if (sid_in_token_groups (my_grps, well_known_batch_sid))\n\tgrp_list *= well_known_batch_sid;\n      grp_list *= well_known_interactive_sid;\n#if 0\n      /* Don't add the SERVICE group when switching the user context.\n\t That's much too dangerous, since the service group adds the\n\t SE_IMPERSONATE_NAME privilege to the user.  After all, the\n\t process started with this token is not the service process\n\t anymore anyway. */\n      if (sid_in_token_groups (my_grps, well_known_service_sid))\n\tgrp_list *= well_known_service_sid;\n#endif\n      if (sid_in_token_groups (my_grps, well_known_this_org_sid))\n\tgrp_list *= well_known_this_org_sid;\n      grp_list *= well_known_users_sid;\n    }\n  else\n    {\n      grp_list += well_known_local_sid;\n      grp_list *= well_known_interactive_sid;\n      grp_list *= well_known_users_sid;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,6 @@\n static void\n-get_token_group_sidlist (cygsidlist &grp_list, PTOKEN_GROUPS my_grps,\n-\t\t\t LUID auth_luid, int &auth_pos)\n+get_token_group_sidlist (cygsidlist &grp_list, PTOKEN_GROUPS my_grps)\n {\n-  auth_pos = -1;\n   if (my_grps)\n     {\n       grp_list += well_known_local_sid;\n@@ -34,14 +32,4 @@\n       grp_list *= well_known_interactive_sid;\n       grp_list *= well_known_users_sid;\n     }\n-  if (get_ll (auth_luid) != 999LL) /* != SYSTEM_LUID */\n-    {\n-      for (DWORD i = 0; i < my_grps->GroupCount; ++i)\n-\tif (my_grps->Groups[i].Attributes & SE_GROUP_LOGON_ID)\n-\t  {\n-\t    grp_list += my_grps->Groups[i].Sid;\n-\t    auth_pos = grp_list.count () - 1;\n-\t    break;\n-\t  }\n-    }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "get_token_group_sidlist (cygsidlist &grp_list, PTOKEN_GROUPS my_grps,",
                "\t\t\t LUID auth_luid, int &auth_pos)",
                "  auth_pos = -1;",
                "  if (get_ll (auth_luid) != 999LL) /* != SYSTEM_LUID */",
                "    {",
                "      for (DWORD i = 0; i < my_grps->GroupCount; ++i)",
                "\tif (my_grps->Groups[i].Attributes & SE_GROUP_LOGON_ID)",
                "\t  {",
                "\t    grp_list += my_grps->Groups[i].Sid;",
                "\t    auth_pos = grp_list.count () - 1;",
                "\t    break;",
                "\t  }",
                "    }"
            ],
            "added_lines": [
                "get_token_group_sidlist (cygsidlist &grp_list, PTOKEN_GROUPS my_grps)"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3067",
        "func_name": "newlib-cygwin/get_setgroups_sidlist",
        "description": "Cygwin before 2.5.0 does not properly handle updating permissions when changing users, which allows attackers to gain privileges.",
        "git_url": "https://sourceware.org/git/?p=newlib-cygwin.git;a=commit;h=205862ed08649df8f50b926a2c58c963f571b044",
        "commit_title": "",
        "commit_text": "setuid: Create token from scratch without credentials of caller  \t* sec_auth.cc (get_token_group_sidlist): Drop auth_luid and \tauth_pos parameter.  Remove code adding a logon SID. \t(get_initgroups_sidlist): Drop auth_luid and auth_pos parameter. \tDrop in call to get_token_group_sidlist. Accommodate in callers. \t(get_setgroups_sidlist): Ditto. \t(create_token): Explicitely set auth_luid to ANONYMOUS_LOGON_LUID \tor LOCALSERVICE_LUID depending on OS.  Explain why. \tRemove handling of logon SID since we don't generate one anymore. \t(lsaauth): Drop now unused local variable auth_luid and auth_pos. \t* wincap.h (wincaps::has_broken_whoami): New element. \t* wincap.cc: Implement above element throughout.  ",
        "func_before": "static void\nget_setgroups_sidlist (cygsidlist &tmp_list, PSID usersid,\n\t\t       PTOKEN_GROUPS my_grps, user_groups &groups,\n\t\t       LUID auth_luid, int &auth_pos)\n{\n  tmp_list *= well_known_world_sid;\n  tmp_list *= well_known_authenticated_users_sid;\n  get_token_group_sidlist (tmp_list, my_grps, auth_luid, auth_pos);\n  get_server_groups (tmp_list, usersid);\n  for (int gidx = 0; gidx < groups.sgsids.count (); gidx++)\n    tmp_list += groups.sgsids.sids[gidx];\n  tmp_list += groups.pgsid;\n}",
        "func": "static void\nget_setgroups_sidlist (cygsidlist &tmp_list, PSID usersid,\n\t\t       PTOKEN_GROUPS my_grps, user_groups &groups)\n{\n  tmp_list *= well_known_world_sid;\n  tmp_list *= well_known_authenticated_users_sid;\n  get_token_group_sidlist (tmp_list, my_grps);\n  get_server_groups (tmp_list, usersid);\n  for (int gidx = 0; gidx < groups.sgsids.count (); gidx++)\n    tmp_list += groups.sgsids.sids[gidx];\n  tmp_list += groups.pgsid;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,10 @@\n static void\n get_setgroups_sidlist (cygsidlist &tmp_list, PSID usersid,\n-\t\t       PTOKEN_GROUPS my_grps, user_groups &groups,\n-\t\t       LUID auth_luid, int &auth_pos)\n+\t\t       PTOKEN_GROUPS my_grps, user_groups &groups)\n {\n   tmp_list *= well_known_world_sid;\n   tmp_list *= well_known_authenticated_users_sid;\n-  get_token_group_sidlist (tmp_list, my_grps, auth_luid, auth_pos);\n+  get_token_group_sidlist (tmp_list, my_grps);\n   get_server_groups (tmp_list, usersid);\n   for (int gidx = 0; gidx < groups.sgsids.count (); gidx++)\n     tmp_list += groups.sgsids.sids[gidx];",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t       PTOKEN_GROUPS my_grps, user_groups &groups,",
                "\t\t       LUID auth_luid, int &auth_pos)",
                "  get_token_group_sidlist (tmp_list, my_grps, auth_luid, auth_pos);"
            ],
            "added_lines": [
                "\t\t       PTOKEN_GROUPS my_grps, user_groups &groups)",
                "  get_token_group_sidlist (tmp_list, my_grps);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3067",
        "func_name": "newlib-cygwin/get_initgroups_sidlist",
        "description": "Cygwin before 2.5.0 does not properly handle updating permissions when changing users, which allows attackers to gain privileges.",
        "git_url": "https://sourceware.org/git/?p=newlib-cygwin.git;a=commit;h=205862ed08649df8f50b926a2c58c963f571b044",
        "commit_title": "",
        "commit_text": "setuid: Create token from scratch without credentials of caller  \t* sec_auth.cc (get_token_group_sidlist): Drop auth_luid and \tauth_pos parameter.  Remove code adding a logon SID. \t(get_initgroups_sidlist): Drop auth_luid and auth_pos parameter. \tDrop in call to get_token_group_sidlist. Accommodate in callers. \t(get_setgroups_sidlist): Ditto. \t(create_token): Explicitely set auth_luid to ANONYMOUS_LOGON_LUID \tor LOCALSERVICE_LUID depending on OS.  Explain why. \tRemove handling of logon SID since we don't generate one anymore. \t(lsaauth): Drop now unused local variable auth_luid and auth_pos. \t* wincap.h (wincaps::has_broken_whoami): New element. \t* wincap.cc: Implement above element throughout.  ",
        "func_before": "static bool\nget_initgroups_sidlist (cygsidlist &grp_list, PSID usersid, PSID pgrpsid,\n\t\t\tPTOKEN_GROUPS my_grps, LUID auth_luid, int &auth_pos)\n{\n  grp_list *= well_known_world_sid;\n  grp_list *= well_known_authenticated_users_sid;\n  if (well_known_system_sid == usersid)\n    auth_pos = -1;\n  else\n    get_token_group_sidlist (grp_list, my_grps, auth_luid, auth_pos);\n  if (!get_server_groups (grp_list, usersid))\n    return false;\n\n  /* special_pgrp true if pgrpsid is not in normal groups */\n  grp_list += pgrpsid;\n  return true;\n}",
        "func": "static bool\nget_initgroups_sidlist (cygsidlist &grp_list, PSID usersid, PSID pgrpsid,\n\t\t\tPTOKEN_GROUPS my_grps)\n{\n  grp_list *= well_known_world_sid;\n  grp_list *= well_known_authenticated_users_sid;\n  if (well_known_system_sid != usersid)\n    get_token_group_sidlist (grp_list, my_grps);\n  if (!get_server_groups (grp_list, usersid))\n    return false;\n\n  /* special_pgrp true if pgrpsid is not in normal groups */\n  grp_list += pgrpsid;\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,13 +1,11 @@\n static bool\n get_initgroups_sidlist (cygsidlist &grp_list, PSID usersid, PSID pgrpsid,\n-\t\t\tPTOKEN_GROUPS my_grps, LUID auth_luid, int &auth_pos)\n+\t\t\tPTOKEN_GROUPS my_grps)\n {\n   grp_list *= well_known_world_sid;\n   grp_list *= well_known_authenticated_users_sid;\n-  if (well_known_system_sid == usersid)\n-    auth_pos = -1;\n-  else\n-    get_token_group_sidlist (grp_list, my_grps, auth_luid, auth_pos);\n+  if (well_known_system_sid != usersid)\n+    get_token_group_sidlist (grp_list, my_grps);\n   if (!get_server_groups (grp_list, usersid))\n     return false;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tPTOKEN_GROUPS my_grps, LUID auth_luid, int &auth_pos)",
                "  if (well_known_system_sid == usersid)",
                "    auth_pos = -1;",
                "  else",
                "    get_token_group_sidlist (grp_list, my_grps, auth_luid, auth_pos);"
            ],
            "added_lines": [
                "\t\t\tPTOKEN_GROUPS my_grps)",
                "  if (well_known_system_sid != usersid)",
                "    get_token_group_sidlist (grp_list, my_grps);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-3067",
        "func_name": "newlib-cygwin/lsaauth",
        "description": "Cygwin before 2.5.0 does not properly handle updating permissions when changing users, which allows attackers to gain privileges.",
        "git_url": "https://sourceware.org/git/?p=newlib-cygwin.git;a=commit;h=205862ed08649df8f50b926a2c58c963f571b044",
        "commit_title": "",
        "commit_text": "setuid: Create token from scratch without credentials of caller  \t* sec_auth.cc (get_token_group_sidlist): Drop auth_luid and \tauth_pos parameter.  Remove code adding a logon SID. \t(get_initgroups_sidlist): Drop auth_luid and auth_pos parameter. \tDrop in call to get_token_group_sidlist. Accommodate in callers. \t(get_setgroups_sidlist): Ditto. \t(create_token): Explicitely set auth_luid to ANONYMOUS_LOGON_LUID \tor LOCALSERVICE_LUID depending on OS.  Explain why. \tRemove handling of logon SID since we don't generate one anymore. \t(lsaauth): Drop now unused local variable auth_luid and auth_pos. \t* wincap.h (wincaps::has_broken_whoami): New element. \t* wincap.cc: Implement above element throughout.  ",
        "func_before": "HANDLE\nlsaauth (cygsid &usersid, user_groups &new_groups)\n{\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n  cygpsid pgrpsid;\n  LSA_STRING name;\n  HANDLE lsa_hdl = NULL, lsa = NULL;\n  LSA_OPERATIONAL_MODE sec_mode;\n  NTSTATUS status, sub_status;\n  ULONG package_id, size;\n  LUID auth_luid = SYSTEM_LUID;\n  struct {\n    LSA_STRING str;\n    CHAR buf[16];\n  } origin;\n  DWORD ulen = UNLEN + 1;\n  DWORD dlen = MAX_DOMAIN_NAME_LEN + 1;\n  SID_NAME_USE use;\n  cyglsa_t *authinf = NULL;\n  ULONG authinf_size;\n  TOKEN_SOURCE ts;\n  PCYG_TOKEN_GROUPS gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  PACL dacl = NULL;\n  PVOID profile = NULL;\n  LUID luid;\n  QUOTA_LIMITS quota;\n  size_t psize = 0, gsize = 0, dsize = 0;\n  OFFSET offset, sids_offset;\n  int tmpidx, non_well_known_cnt;\n\n  HANDLE user_token = NULL;\n\n  push_self_privilege (SE_TCB_PRIVILEGE, true);\n\n  /* Register as logon process. */\n  RtlInitAnsiString (&name, \"Cygwin\");\n  SetLastError (0);\n  status = LsaRegisterLogonProcess (&name, &lsa_hdl, &sec_mode);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaRegisterLogonProcess: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  else if (GetLastError () == ERROR_PROC_NOT_FOUND)\n    {\n      debug_printf (\"Couldn't load Secur32.dll\");\n      goto out;\n    }\n  /* Get handle to our own LSA package. */\n  RtlInitAnsiString (&name, CYG_LSA_PKGNAME);\n  status = LsaLookupAuthenticationPackage (lsa_hdl, &name, &package_id);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLookupAuthenticationPackage: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* Create origin. */\n  stpcpy (origin.buf, \"Cygwin\");\n  RtlInitAnsiString (&origin.str, origin.buf);\n  /* Create token source. */\n  memcpy (ts.SourceName, \"Cygwin.1\", 8);\n  ts.SourceIdentifier.HighPart = 0;\n  ts.SourceIdentifier.LowPart = 0x0103;\n\n  /* Create list of groups, the user is member in. */\n  int auth_pos;\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups, auth_luid,\n\t\t\t   auth_pos);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    NULL, auth_luid, auth_pos))\n    goto out;\n\n  tmp_gsids.debug_print (\"tmp_gsids\");\n\n  /* Evaluate size of TOKEN_GROUPS list */\n  non_well_known_cnt =  tmp_gsids.non_well_known_count ();\n  gsize = sizeof (DWORD) + non_well_known_cnt * sizeof (SID_AND_ATTRIBUTES);\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) >= 0)\n      gsize += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n\n  /* Retrieve list of privileges of that user.  The MIC SID is created by\n     the LSA here. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize, NULL)))\n    goto out;\n\n  /* Create DefaultDacl. */\n  dsize = sizeof (ACL) + 3 * sizeof (ACCESS_ALLOWED_ACE)\n\t  + RtlLengthSid (usersid)\n\t  + RtlLengthSid (well_known_admins_sid)\n\t  + RtlLengthSid (well_known_system_sid);\n  dacl = (PACL) alloca (dsize);\n  if (!NT_SUCCESS (RtlCreateAcl (dacl, dsize, ACL_REVISION)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   usersid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_admins_sid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_system_sid)))\n    goto out;\n\n  /* Evaluate authinf size and allocate authinf. */\n  authinf_size = (authinf->data - (PBYTE) authinf);\n  authinf_size += RtlLengthSid (usersid);\t    /* User SID */\n  authinf_size += gsize;\t\t\t    /* Groups + Group SIDs */\n  /* When trying to define the admins group as primary group on Vista,\n     LsaLogonUser fails with error STATUS_INVALID_OWNER.  As workaround\n     we define \"Local\" as primary group here.  Seteuid32 sets the primary\n     group to the group set in /etc/passwd anyway. */\n  if (new_groups.pgsid == well_known_admins_sid)\n    pgrpsid = well_known_local_sid;\n  else\n    pgrpsid = new_groups.pgsid;\n\n  authinf_size += RtlLengthSid (pgrpsid);\t    /* Primary Group SID */\n\n  authinf_size += psize;\t\t\t    /* Privileges */\n  authinf_size += 0;\t\t\t\t    /* Owner SID */\n  authinf_size += dsize;\t\t\t    /* Default DACL */\n\n  authinf = (cyglsa_t *) alloca (authinf_size);\n  authinf->inf_size = authinf_size - ((PBYTE) &authinf->inf - (PBYTE) authinf);\n\n  authinf->magic = CYG_LSA_MAGIC;\n\n  if (!LookupAccountSidW (NULL, usersid, authinf->username, &ulen,\n\t\t\t  authinf->domain, &dlen, &use))\n    {\n      __seterrno ();\n      goto out;\n    }\n\n  /* Store stuff in authinf with offset relative to start of \"inf\" member,\n     instead of using pointers. */\n  offset = authinf->data - (PBYTE) &authinf->inf;\n\n  authinf->inf.ExpirationTime.LowPart = 0xffffffffL;\n  authinf->inf.ExpirationTime.HighPart = 0x7fffffffL;\n  /* User SID */\n  authinf->inf.User.User.Sid = offset;\n  authinf->inf.User.User.Attributes = 0;\n  RtlCopySid (RtlLengthSid (usersid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      usersid);\n  offset += RtlLengthSid (usersid);\n  /* Groups */\n  authinf->inf.Groups = offset;\n  gsids = (PCYG_TOKEN_GROUPS) ((PBYTE) &authinf->inf + offset);\n  sids_offset = offset + sizeof (ULONG) + non_well_known_cnt\n\t\t\t\t\t  * sizeof (SID_AND_ATTRIBUTES);\n  gsids->GroupCount = non_well_known_cnt;\n  /* Group SIDs */\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    {\n      if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) < 0)\n\tbreak;\n      gsids->Groups[i].Sid = sids_offset;\n      gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t    | SE_GROUP_ENABLED;\n      RtlCopySid (RtlLengthSid (tmp_gsids.sids[tmpidx]),\n\t\t  (PSID) ((PBYTE) &authinf->inf + sids_offset),\n\t\t  tmp_gsids.sids[tmpidx]);\n      sids_offset += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n    }\n  offset += gsize;\n  /* Primary Group SID */\n  authinf->inf.PrimaryGroup.PrimaryGroup = offset;\n  RtlCopySid (RtlLengthSid (pgrpsid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      pgrpsid);\n  offset += RtlLengthSid (pgrpsid);\n  /* Privileges */\n  authinf->inf.Privileges = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, privs, psize);\n  offset += psize;\n  /* Owner */\n  authinf->inf.Owner.Owner = 0;\n  /* Default DACL */\n  authinf->inf.DefaultDacl.DefaultDacl = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, dacl, dsize);\n\n  authinf->checksum = CYG_LSA_MAGIC;\n  PDWORD csp;\n  PDWORD csp_end;\n  csp = (PDWORD) &authinf->username;\n  csp_end = (PDWORD) ((PBYTE) authinf + authinf_size);\n  while (csp < csp_end)\n    authinf->checksum += *csp++;\n\n  /* Try to logon... */\n  status = LsaLogonUser (lsa_hdl, (PLSA_STRING) &origin, Interactive,\n\t\t\t package_id, authinf, authinf_size, NULL, &ts,\n\t\t\t &profile, &size, &luid, &user_token, &quota,\n\t\t\t &sub_status);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLogonUser: %y (sub-status %y)\", status, sub_status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  if (profile)\n    {\n#ifdef JUST_ANOTHER_NONWORKING_SOLUTION\n      /* See ../lsaauth/cyglsa.c. */\n      cygprf_t *prf = (cygprf_t *) profile;\n      if (prf->magic_pre == MAGIC_PRE && prf->magic_post == MAGIC_POST\n\t  && prf->token)\n\t{\n\t  CloseHandle (user_token);\n\t  user_token = prf->token;\n\t  system_printf (\"Got token through profile: %p\", user_token);\n\t}\n#endif /* JUST_ANOTHER_NONWORKING_SOLUTION */\n      LsaFreeReturnBuffer (profile);\n    }\n  user_token = get_full_privileged_inheritable_token (user_token);\n\nout:\n  if (privs)\n    free (privs);\n  lsa_close_policy (lsa);\n  if (lsa_hdl)\n    LsaDeregisterLogonProcess (lsa_hdl);\n  pop_self_privilege ();\n\n  debug_printf (\"%p = lsaauth ()\", user_token);\n  return user_token;\n}",
        "func": "HANDLE\nlsaauth (cygsid &usersid, user_groups &new_groups)\n{\n  cygsidlist tmp_gsids (cygsidlist_auto, 12);\n  cygpsid pgrpsid;\n  LSA_STRING name;\n  HANDLE lsa_hdl = NULL, lsa = NULL;\n  LSA_OPERATIONAL_MODE sec_mode;\n  NTSTATUS status, sub_status;\n  ULONG package_id, size;\n  struct {\n    LSA_STRING str;\n    CHAR buf[16];\n  } origin;\n  DWORD ulen = UNLEN + 1;\n  DWORD dlen = MAX_DOMAIN_NAME_LEN + 1;\n  SID_NAME_USE use;\n  cyglsa_t *authinf = NULL;\n  ULONG authinf_size;\n  TOKEN_SOURCE ts;\n  PCYG_TOKEN_GROUPS gsids = NULL;\n  PTOKEN_PRIVILEGES privs = NULL;\n  PACL dacl = NULL;\n  PVOID profile = NULL;\n  LUID luid;\n  QUOTA_LIMITS quota;\n  size_t psize = 0, gsize = 0, dsize = 0;\n  OFFSET offset, sids_offset;\n  int tmpidx, non_well_known_cnt;\n\n  HANDLE user_token = NULL;\n\n  push_self_privilege (SE_TCB_PRIVILEGE, true);\n\n  /* Register as logon process. */\n  RtlInitAnsiString (&name, \"Cygwin\");\n  SetLastError (0);\n  status = LsaRegisterLogonProcess (&name, &lsa_hdl, &sec_mode);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaRegisterLogonProcess: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  else if (GetLastError () == ERROR_PROC_NOT_FOUND)\n    {\n      debug_printf (\"Couldn't load Secur32.dll\");\n      goto out;\n    }\n  /* Get handle to our own LSA package. */\n  RtlInitAnsiString (&name, CYG_LSA_PKGNAME);\n  status = LsaLookupAuthenticationPackage (lsa_hdl, &name, &package_id);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLookupAuthenticationPackage: %y\", status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n\n  /* Open policy object. */\n  if (!(lsa = lsa_open_policy (NULL, POLICY_EXECUTE)))\n    goto out;\n\n  /* Create origin. */\n  stpcpy (origin.buf, \"Cygwin\");\n  RtlInitAnsiString (&origin.str, origin.buf);\n  /* Create token source. */\n  memcpy (ts.SourceName, \"Cygwin.1\", 8);\n  ts.SourceIdentifier.HighPart = 0;\n  ts.SourceIdentifier.LowPart = 0x0103;\n\n  /* Create list of groups, the user is member in. */\n  if (new_groups.issetgroups ())\n    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups);\n  else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n\t\t\t\t    NULL))\n    goto out;\n\n  tmp_gsids.debug_print (\"tmp_gsids\");\n\n  /* Evaluate size of TOKEN_GROUPS list */\n  non_well_known_cnt =  tmp_gsids.non_well_known_count ();\n  gsize = sizeof (DWORD) + non_well_known_cnt * sizeof (SID_AND_ATTRIBUTES);\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) >= 0)\n      gsize += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n\n  /* Retrieve list of privileges of that user.  The MIC SID is created by\n     the LSA here. */\n  if (!(privs = get_priv_list (lsa, usersid, tmp_gsids, psize, NULL)))\n    goto out;\n\n  /* Create DefaultDacl. */\n  dsize = sizeof (ACL) + 3 * sizeof (ACCESS_ALLOWED_ACE)\n\t  + RtlLengthSid (usersid)\n\t  + RtlLengthSid (well_known_admins_sid)\n\t  + RtlLengthSid (well_known_system_sid);\n  dacl = (PACL) alloca (dsize);\n  if (!NT_SUCCESS (RtlCreateAcl (dacl, dsize, ACL_REVISION)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   usersid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_admins_sid)))\n    goto out;\n  if (!NT_SUCCESS (RtlAddAccessAllowedAce (dacl, ACL_REVISION, GENERIC_ALL,\n\t\t\t\t\t   well_known_system_sid)))\n    goto out;\n\n  /* Evaluate authinf size and allocate authinf. */\n  authinf_size = (authinf->data - (PBYTE) authinf);\n  authinf_size += RtlLengthSid (usersid);\t    /* User SID */\n  authinf_size += gsize;\t\t\t    /* Groups + Group SIDs */\n  /* When trying to define the admins group as primary group on Vista,\n     LsaLogonUser fails with error STATUS_INVALID_OWNER.  As workaround\n     we define \"Local\" as primary group here.  Seteuid32 sets the primary\n     group to the group set in /etc/passwd anyway. */\n  if (new_groups.pgsid == well_known_admins_sid)\n    pgrpsid = well_known_local_sid;\n  else\n    pgrpsid = new_groups.pgsid;\n\n  authinf_size += RtlLengthSid (pgrpsid);\t    /* Primary Group SID */\n\n  authinf_size += psize;\t\t\t    /* Privileges */\n  authinf_size += 0;\t\t\t\t    /* Owner SID */\n  authinf_size += dsize;\t\t\t    /* Default DACL */\n\n  authinf = (cyglsa_t *) alloca (authinf_size);\n  authinf->inf_size = authinf_size - ((PBYTE) &authinf->inf - (PBYTE) authinf);\n\n  authinf->magic = CYG_LSA_MAGIC;\n\n  if (!LookupAccountSidW (NULL, usersid, authinf->username, &ulen,\n\t\t\t  authinf->domain, &dlen, &use))\n    {\n      __seterrno ();\n      goto out;\n    }\n\n  /* Store stuff in authinf with offset relative to start of \"inf\" member,\n     instead of using pointers. */\n  offset = authinf->data - (PBYTE) &authinf->inf;\n\n  authinf->inf.ExpirationTime.LowPart = 0xffffffffL;\n  authinf->inf.ExpirationTime.HighPart = 0x7fffffffL;\n  /* User SID */\n  authinf->inf.User.User.Sid = offset;\n  authinf->inf.User.User.Attributes = 0;\n  RtlCopySid (RtlLengthSid (usersid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      usersid);\n  offset += RtlLengthSid (usersid);\n  /* Groups */\n  authinf->inf.Groups = offset;\n  gsids = (PCYG_TOKEN_GROUPS) ((PBYTE) &authinf->inf + offset);\n  sids_offset = offset + sizeof (ULONG) + non_well_known_cnt\n\t\t\t\t\t  * sizeof (SID_AND_ATTRIBUTES);\n  gsids->GroupCount = non_well_known_cnt;\n  /* Group SIDs */\n  tmpidx = -1;\n  for (int i = 0; i < non_well_known_cnt; ++i)\n    {\n      if ((tmpidx = tmp_gsids.next_non_well_known_sid (tmpidx)) < 0)\n\tbreak;\n      gsids->Groups[i].Sid = sids_offset;\n      gsids->Groups[i].Attributes = SE_GROUP_MANDATORY\n\t\t\t\t    | SE_GROUP_ENABLED_BY_DEFAULT\n\t\t\t\t    | SE_GROUP_ENABLED;\n      RtlCopySid (RtlLengthSid (tmp_gsids.sids[tmpidx]),\n\t\t  (PSID) ((PBYTE) &authinf->inf + sids_offset),\n\t\t  tmp_gsids.sids[tmpidx]);\n      sids_offset += RtlLengthSid (tmp_gsids.sids[tmpidx]);\n    }\n  offset += gsize;\n  /* Primary Group SID */\n  authinf->inf.PrimaryGroup.PrimaryGroup = offset;\n  RtlCopySid (RtlLengthSid (pgrpsid), (PSID) ((PBYTE) &authinf->inf + offset),\n\t      pgrpsid);\n  offset += RtlLengthSid (pgrpsid);\n  /* Privileges */\n  authinf->inf.Privileges = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, privs, psize);\n  offset += psize;\n  /* Owner */\n  authinf->inf.Owner.Owner = 0;\n  /* Default DACL */\n  authinf->inf.DefaultDacl.DefaultDacl = offset;\n  memcpy ((PBYTE) &authinf->inf + offset, dacl, dsize);\n\n  authinf->checksum = CYG_LSA_MAGIC;\n  PDWORD csp;\n  PDWORD csp_end;\n  csp = (PDWORD) &authinf->username;\n  csp_end = (PDWORD) ((PBYTE) authinf + authinf_size);\n  while (csp < csp_end)\n    authinf->checksum += *csp++;\n\n  /* Try to logon... */\n  status = LsaLogonUser (lsa_hdl, (PLSA_STRING) &origin, Interactive,\n\t\t\t package_id, authinf, authinf_size, NULL, &ts,\n\t\t\t &profile, &size, &luid, &user_token, &quota,\n\t\t\t &sub_status);\n  if (status != STATUS_SUCCESS)\n    {\n      debug_printf (\"LsaLogonUser: %y (sub-status %y)\", status, sub_status);\n      __seterrno_from_nt_status (status);\n      goto out;\n    }\n  if (profile)\n    {\n#ifdef JUST_ANOTHER_NONWORKING_SOLUTION\n      /* See ../lsaauth/cyglsa.c. */\n      cygprf_t *prf = (cygprf_t *) profile;\n      if (prf->magic_pre == MAGIC_PRE && prf->magic_post == MAGIC_POST\n\t  && prf->token)\n\t{\n\t  CloseHandle (user_token);\n\t  user_token = prf->token;\n\t  system_printf (\"Got token through profile: %p\", user_token);\n\t}\n#endif /* JUST_ANOTHER_NONWORKING_SOLUTION */\n      LsaFreeReturnBuffer (profile);\n    }\n  user_token = get_full_privileged_inheritable_token (user_token);\n\nout:\n  if (privs)\n    free (privs);\n  lsa_close_policy (lsa);\n  if (lsa_hdl)\n    LsaDeregisterLogonProcess (lsa_hdl);\n  pop_self_privilege ();\n\n  debug_printf (\"%p = lsaauth ()\", user_token);\n  return user_token;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,6 @@\n   LSA_OPERATIONAL_MODE sec_mode;\n   NTSTATUS status, sub_status;\n   ULONG package_id, size;\n-  LUID auth_luid = SYSTEM_LUID;\n   struct {\n     LSA_STRING str;\n     CHAR buf[16];\n@@ -71,12 +70,10 @@\n   ts.SourceIdentifier.LowPart = 0x0103;\n \n   /* Create list of groups, the user is member in. */\n-  int auth_pos;\n   if (new_groups.issetgroups ())\n-    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups, auth_luid,\n-\t\t\t   auth_pos);\n+    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups);\n   else if (!get_initgroups_sidlist (tmp_gsids, usersid, new_groups.pgsid,\n-\t\t\t\t    NULL, auth_luid, auth_pos))\n+\t\t\t\t    NULL))\n     goto out;\n \n   tmp_gsids.debug_print (\"tmp_gsids\");",
        "diff_line_info": {
            "deleted_lines": [
                "  LUID auth_luid = SYSTEM_LUID;",
                "  int auth_pos;",
                "    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups, auth_luid,",
                "\t\t\t   auth_pos);",
                "\t\t\t\t    NULL, auth_luid, auth_pos))"
            ],
            "added_lines": [
                "    get_setgroups_sidlist (tmp_gsids, usersid, NULL, new_groups);",
                "\t\t\t\t    NULL))"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-9004",
        "func_name": "torvalds/linux/perf_pmu_register",
        "description": "kernel/events/core.c in the Linux kernel before 3.19 mishandles counter grouping, which allows local users to gain privileges via a crafted application, related to the perf_pmu_register and perf_event_open functions.",
        "git_url": "https://github.com/torvalds/linux/commit/c3c87e770458aa004bd7ed3f29945ff436fd6511",
        "commit_title": "perf: Tighten (and fix) the grouping condition",
        "commit_text": " The fix from 9fc81d87420d (\"perf: Fix events installation during moving group\") was incomplete in that it failed to recognise that creating a group with events for different CPUs is semantically broken -- they cannot be co-scheduled.  Furthermore, it leads to real breakage where, when we create an event for CPU Y and then migrate it to form a group on CPU X, the code gets confused where the counter is programmed -- triggered in practice as well by me via the perf fuzzer.  Fix this by tightening the rules for creating groups. Only allow grouping of counters that can be co-scheduled in the same context. This means for the same task and/or the same cpu.  Cc: Arnaldo Carvalho de Melo <acme@kernel.org> Cc: Jiri Olsa <jolsa@redhat.com> Cc: Linus Torvalds <torvalds@linux-foundation.org> Link: http://lkml.kernel.org/r/20150123125834.090683288@infradead.org",
        "func_before": "int perf_pmu_register(struct pmu *pmu, const char *name, int type)\n{\n\tint cpu, ret;\n\n\tmutex_lock(&pmus_lock);\n\tret = -ENOMEM;\n\tpmu->pmu_disable_count = alloc_percpu(int);\n\tif (!pmu->pmu_disable_count)\n\t\tgoto unlock;\n\n\tpmu->type = -1;\n\tif (!name)\n\t\tgoto skip_type;\n\tpmu->name = name;\n\n\tif (type < 0) {\n\t\ttype = idr_alloc(&pmu_idr, pmu, PERF_TYPE_MAX, 0, GFP_KERNEL);\n\t\tif (type < 0) {\n\t\t\tret = type;\n\t\t\tgoto free_pdc;\n\t\t}\n\t}\n\tpmu->type = type;\n\n\tif (pmu_bus_running) {\n\t\tret = pmu_dev_alloc(pmu);\n\t\tif (ret)\n\t\t\tgoto free_idr;\n\t}\n\nskip_type:\n\tpmu->pmu_cpu_context = find_pmu_context(pmu->task_ctx_nr);\n\tif (pmu->pmu_cpu_context)\n\t\tgoto got_cpu_context;\n\n\tret = -ENOMEM;\n\tpmu->pmu_cpu_context = alloc_percpu(struct perf_cpu_context);\n\tif (!pmu->pmu_cpu_context)\n\t\tgoto free_dev;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct perf_cpu_context *cpuctx;\n\n\t\tcpuctx = per_cpu_ptr(pmu->pmu_cpu_context, cpu);\n\t\t__perf_event_init_context(&cpuctx->ctx);\n\t\tlockdep_set_class(&cpuctx->ctx.mutex, &cpuctx_mutex);\n\t\tlockdep_set_class(&cpuctx->ctx.lock, &cpuctx_lock);\n\t\tcpuctx->ctx.type = cpu_context;\n\t\tcpuctx->ctx.pmu = pmu;\n\n\t\t__perf_cpu_hrtimer_init(cpuctx, cpu);\n\n\t\tINIT_LIST_HEAD(&cpuctx->rotation_list);\n\t\tcpuctx->unique_pmu = pmu;\n\t}\n\ngot_cpu_context:\n\tif (!pmu->start_txn) {\n\t\tif (pmu->pmu_enable) {\n\t\t\t/*\n\t\t\t * If we have pmu_enable/pmu_disable calls, install\n\t\t\t * transaction stubs that use that to try and batch\n\t\t\t * hardware accesses.\n\t\t\t */\n\t\t\tpmu->start_txn  = perf_pmu_start_txn;\n\t\t\tpmu->commit_txn = perf_pmu_commit_txn;\n\t\t\tpmu->cancel_txn = perf_pmu_cancel_txn;\n\t\t} else {\n\t\t\tpmu->start_txn  = perf_pmu_nop_void;\n\t\t\tpmu->commit_txn = perf_pmu_nop_int;\n\t\t\tpmu->cancel_txn = perf_pmu_nop_void;\n\t\t}\n\t}\n\n\tif (!pmu->pmu_enable) {\n\t\tpmu->pmu_enable  = perf_pmu_nop_void;\n\t\tpmu->pmu_disable = perf_pmu_nop_void;\n\t}\n\n\tif (!pmu->event_idx)\n\t\tpmu->event_idx = perf_event_idx_default;\n\n\tlist_add_rcu(&pmu->entry, &pmus);\n\tret = 0;\nunlock:\n\tmutex_unlock(&pmus_lock);\n\n\treturn ret;\n\nfree_dev:\n\tdevice_del(pmu->dev);\n\tput_device(pmu->dev);\n\nfree_idr:\n\tif (pmu->type >= PERF_TYPE_MAX)\n\t\tidr_remove(&pmu_idr, pmu->type);\n\nfree_pdc:\n\tfree_percpu(pmu->pmu_disable_count);\n\tgoto unlock;\n}",
        "func": "int perf_pmu_register(struct pmu *pmu, const char *name, int type)\n{\n\tint cpu, ret;\n\n\tmutex_lock(&pmus_lock);\n\tret = -ENOMEM;\n\tpmu->pmu_disable_count = alloc_percpu(int);\n\tif (!pmu->pmu_disable_count)\n\t\tgoto unlock;\n\n\tpmu->type = -1;\n\tif (!name)\n\t\tgoto skip_type;\n\tpmu->name = name;\n\n\tif (type < 0) {\n\t\ttype = idr_alloc(&pmu_idr, pmu, PERF_TYPE_MAX, 0, GFP_KERNEL);\n\t\tif (type < 0) {\n\t\t\tret = type;\n\t\t\tgoto free_pdc;\n\t\t}\n\t}\n\tpmu->type = type;\n\n\tif (pmu_bus_running) {\n\t\tret = pmu_dev_alloc(pmu);\n\t\tif (ret)\n\t\t\tgoto free_idr;\n\t}\n\nskip_type:\n\tpmu->pmu_cpu_context = find_pmu_context(pmu->task_ctx_nr);\n\tif (pmu->pmu_cpu_context)\n\t\tgoto got_cpu_context;\n\n\tret = -ENOMEM;\n\tpmu->pmu_cpu_context = alloc_percpu(struct perf_cpu_context);\n\tif (!pmu->pmu_cpu_context)\n\t\tgoto free_dev;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tstruct perf_cpu_context *cpuctx;\n\n\t\tcpuctx = per_cpu_ptr(pmu->pmu_cpu_context, cpu);\n\t\t__perf_event_init_context(&cpuctx->ctx);\n\t\tlockdep_set_class(&cpuctx->ctx.mutex, &cpuctx_mutex);\n\t\tlockdep_set_class(&cpuctx->ctx.lock, &cpuctx_lock);\n\t\tcpuctx->ctx.pmu = pmu;\n\n\t\t__perf_cpu_hrtimer_init(cpuctx, cpu);\n\n\t\tINIT_LIST_HEAD(&cpuctx->rotation_list);\n\t\tcpuctx->unique_pmu = pmu;\n\t}\n\ngot_cpu_context:\n\tif (!pmu->start_txn) {\n\t\tif (pmu->pmu_enable) {\n\t\t\t/*\n\t\t\t * If we have pmu_enable/pmu_disable calls, install\n\t\t\t * transaction stubs that use that to try and batch\n\t\t\t * hardware accesses.\n\t\t\t */\n\t\t\tpmu->start_txn  = perf_pmu_start_txn;\n\t\t\tpmu->commit_txn = perf_pmu_commit_txn;\n\t\t\tpmu->cancel_txn = perf_pmu_cancel_txn;\n\t\t} else {\n\t\t\tpmu->start_txn  = perf_pmu_nop_void;\n\t\t\tpmu->commit_txn = perf_pmu_nop_int;\n\t\t\tpmu->cancel_txn = perf_pmu_nop_void;\n\t\t}\n\t}\n\n\tif (!pmu->pmu_enable) {\n\t\tpmu->pmu_enable  = perf_pmu_nop_void;\n\t\tpmu->pmu_disable = perf_pmu_nop_void;\n\t}\n\n\tif (!pmu->event_idx)\n\t\tpmu->event_idx = perf_event_idx_default;\n\n\tlist_add_rcu(&pmu->entry, &pmus);\n\tret = 0;\nunlock:\n\tmutex_unlock(&pmus_lock);\n\n\treturn ret;\n\nfree_dev:\n\tdevice_del(pmu->dev);\n\tput_device(pmu->dev);\n\nfree_idr:\n\tif (pmu->type >= PERF_TYPE_MAX)\n\t\tidr_remove(&pmu_idr, pmu->type);\n\nfree_pdc:\n\tfree_percpu(pmu->pmu_disable_count);\n\tgoto unlock;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -45,7 +45,6 @@\n \t\t__perf_event_init_context(&cpuctx->ctx);\n \t\tlockdep_set_class(&cpuctx->ctx.mutex, &cpuctx_mutex);\n \t\tlockdep_set_class(&cpuctx->ctx.lock, &cpuctx_lock);\n-\t\tcpuctx->ctx.type = cpu_context;\n \t\tcpuctx->ctx.pmu = pmu;\n \n \t\t__perf_cpu_hrtimer_init(cpuctx, cpu);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tcpuctx->ctx.type = cpu_context;"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-7272",
        "func_name": "sddm/UserSession::setupChildProcess",
        "description": "Simple Desktop Display Manager (SDDM) before 0.10.0 allows local users to gain root privileges because code running as root performs write operations within a user home directory, and this user may have created links in advance (exploitation requires the user to win a race condition in the ~/.Xauthority chown case, but not other cases).",
        "git_url": "https://github.com/sddm/sddm/commit/e92c466f5c324b429ce1a8aa1b40d208574c778a",
        "commit_title": "Move onAuthenticated XAUTHORITY generation to the helper",
        "commit_text": " This avoids it being created as root and then chown'd.",
        "func_before": "void UserSession::setupChildProcess() {\n        struct passwd *pw = getpwnam(qobject_cast<HelperApp*>(parent())->user().toLocal8Bit());\n        if (setgid(pw->pw_gid) != 0)\n            bail(2);\n        if (initgroups(pw->pw_name, pw->pw_gid) != 0)\n            bail(2);\n        if (setuid(pw->pw_uid) != 0)\n            bail(2);\n        chdir(pw->pw_dir);\n    }",
        "func": "void UserSession::setupChildProcess() {\n        struct passwd *pw = getpwnam(qobject_cast<HelperApp*>(parent())->user().toLocal8Bit());\n        if (setgid(pw->pw_gid) != 0)\n            bail(2);\n        if (initgroups(pw->pw_name, pw->pw_gid) != 0)\n            bail(2);\n        if (setuid(pw->pw_uid) != 0)\n            bail(2);\n        chdir(pw->pw_dir);\n        // redirect standard error to a file\n        setStandardErrorFile(QString(\"%1/.xsession-errors\").arg(pw->pw_dir));\n\n        QString cookie = qobject_cast<HelperApp*>(parent())->cookie();\n        if (!cookie.isEmpty()) {\n            QString file = processEnvironment().value(\"XAUTHORITY\");\n            QString display = processEnvironment().value(\"DISPLAY\");\n            qDebug() << \"Adding cookie to\" << file;\n\n            QFile file_handler(file);\n            file_handler.open(QIODevice::WriteOnly);\n            file_handler.close();\n\n            QString cmd = QString(\"%1 -f %2 -q\").arg(mainConfig.XDisplay.XauthPath.get()).arg(file);\n\n            // execute xauth\n            FILE *fp = popen(qPrintable(cmd), \"w\");\n\n            // check file\n            if (!fp)\n                return;\n            fprintf(fp, \"remove %s\\n\", qPrintable(display));\n            fprintf(fp, \"add %s . %s\\n\", qPrintable(display), qPrintable(cookie));\n            fprintf(fp, \"exit\\n\");\n\n            // close pipe\n            pclose(fp);\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,4 +7,32 @@\n         if (setuid(pw->pw_uid) != 0)\n             bail(2);\n         chdir(pw->pw_dir);\n+        // redirect standard error to a file\n+        setStandardErrorFile(QString(\"%1/.xsession-errors\").arg(pw->pw_dir));\n+\n+        QString cookie = qobject_cast<HelperApp*>(parent())->cookie();\n+        if (!cookie.isEmpty()) {\n+            QString file = processEnvironment().value(\"XAUTHORITY\");\n+            QString display = processEnvironment().value(\"DISPLAY\");\n+            qDebug() << \"Adding cookie to\" << file;\n+\n+            QFile file_handler(file);\n+            file_handler.open(QIODevice::WriteOnly);\n+            file_handler.close();\n+\n+            QString cmd = QString(\"%1 -f %2 -q\").arg(mainConfig.XDisplay.XauthPath.get()).arg(file);\n+\n+            // execute xauth\n+            FILE *fp = popen(qPrintable(cmd), \"w\");\n+\n+            // check file\n+            if (!fp)\n+                return;\n+            fprintf(fp, \"remove %s\\n\", qPrintable(display));\n+            fprintf(fp, \"add %s . %s\\n\", qPrintable(display), qPrintable(cookie));\n+            fprintf(fp, \"exit\\n\");\n+\n+            // close pipe\n+            pclose(fp);\n+        }\n     }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        // redirect standard error to a file",
                "        setStandardErrorFile(QString(\"%1/.xsession-errors\").arg(pw->pw_dir));",
                "",
                "        QString cookie = qobject_cast<HelperApp*>(parent())->cookie();",
                "        if (!cookie.isEmpty()) {",
                "            QString file = processEnvironment().value(\"XAUTHORITY\");",
                "            QString display = processEnvironment().value(\"DISPLAY\");",
                "            qDebug() << \"Adding cookie to\" << file;",
                "",
                "            QFile file_handler(file);",
                "            file_handler.open(QIODevice::WriteOnly);",
                "            file_handler.close();",
                "",
                "            QString cmd = QString(\"%1 -f %2 -q\").arg(mainConfig.XDisplay.XauthPath.get()).arg(file);",
                "",
                "            // execute xauth",
                "            FILE *fp = popen(qPrintable(cmd), \"w\");",
                "",
                "            // check file",
                "            if (!fp)",
                "                return;",
                "            fprintf(fp, \"remove %s\\n\", qPrintable(display));",
                "            fprintf(fp, \"add %s . %s\\n\", qPrintable(display), qPrintable(cookie));",
                "            fprintf(fp, \"exit\\n\");",
                "",
                "            // close pipe",
                "            pclose(fp);",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7272",
        "func_name": "sddm/Display::slotAuthenticationFinished",
        "description": "Simple Desktop Display Manager (SDDM) before 0.10.0 allows local users to gain root privileges because code running as root performs write operations within a user home directory, and this user may have created links in advance (exploitation requires the user to win a race condition in the ~/.Xauthority chown case, but not other cases).",
        "git_url": "https://github.com/sddm/sddm/commit/e92c466f5c324b429ce1a8aa1b40d208574c778a",
        "commit_title": "Move onAuthenticated XAUTHORITY generation to the helper",
        "commit_text": " This avoids it being created as root and then chown'd.",
        "func_before": "void Display::slotAuthenticationFinished(const QString &user, bool success) {\n        if (success) {\n            qDebug() << \"Authenticated successfully\";\n\n            struct passwd *pw = getpwnam(qPrintable(user));\n            if (pw) {\n                qobject_cast<XorgDisplayServer *>(m_displayServer)->addCookie(QString(\"%1/.Xauthority\").arg(pw->pw_dir));\n                chown(qPrintable(QString(\"%1/.Xauthority\").arg(pw->pw_dir)), pw->pw_uid, pw->pw_gid);\n            }\n\n            // save last user and last session\n            stateConfig.Last.User.set(m_auth->user());\n            stateConfig.Last.Session.set(m_sessionName);\n            stateConfig.save();\n\n            if (m_socket)\n                emit loginSucceeded(m_socket);\n        } else if (m_socket) {\n            qDebug() << \"Authentication failure\";\n            emit loginFailed(m_socket);\n        }\n        m_socket = nullptr;\n    }",
        "func": "void Display::slotAuthenticationFinished(const QString &user, bool success) {\n        if (success) {\n            qDebug() << \"Authenticated successfully\";\n\n            m_auth->setCookie(qobject_cast<XorgDisplayServer *>(m_displayServer)->cookie());\n\n            // save last user and last session\n            stateConfig.Last.User.set(m_auth->user());\n            stateConfig.Last.Session.set(m_sessionName);\n            stateConfig.save();\n\n            if (m_socket)\n                emit loginSucceeded(m_socket);\n        } else if (m_socket) {\n            qDebug() << \"Authentication failure\";\n            emit loginFailed(m_socket);\n        }\n        m_socket = nullptr;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,11 +2,7 @@\n         if (success) {\n             qDebug() << \"Authenticated successfully\";\n \n-            struct passwd *pw = getpwnam(qPrintable(user));\n-            if (pw) {\n-                qobject_cast<XorgDisplayServer *>(m_displayServer)->addCookie(QString(\"%1/.Xauthority\").arg(pw->pw_dir));\n-                chown(qPrintable(QString(\"%1/.Xauthority\").arg(pw->pw_dir)), pw->pw_uid, pw->pw_gid);\n-            }\n+            m_auth->setCookie(qobject_cast<XorgDisplayServer *>(m_displayServer)->cookie());\n \n             // save last user and last session\n             stateConfig.Last.User.set(m_auth->user());",
        "diff_line_info": {
            "deleted_lines": [
                "            struct passwd *pw = getpwnam(qPrintable(user));",
                "            if (pw) {",
                "                qobject_cast<XorgDisplayServer *>(m_displayServer)->addCookie(QString(\"%1/.Xauthority\").arg(pw->pw_dir));",
                "                chown(qPrintable(QString(\"%1/.Xauthority\").arg(pw->pw_dir)), pw->pw_uid, pw->pw_gid);",
                "            }"
            ],
            "added_lines": [
                "            m_auth->setCookie(qobject_cast<XorgDisplayServer *>(m_displayServer)->cookie());"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7272",
        "func_name": "sddm/Auth::Private::dataPending",
        "description": "Simple Desktop Display Manager (SDDM) before 0.10.0 allows local users to gain root privileges because code running as root performs write operations within a user home directory, and this user may have created links in advance (exploitation requires the user to win a race condition in the ~/.Xauthority chown case, but not other cases).",
        "git_url": "https://github.com/sddm/sddm/commit/e92c466f5c324b429ce1a8aa1b40d208574c778a",
        "commit_title": "Move onAuthenticated XAUTHORITY generation to the helper",
        "commit_text": " This avoids it being created as root and then chown'd.",
        "func_before": "void Auth::Private::dataPending() {\n        Auth *auth = qobject_cast<Auth*>(parent());\n        Msg m = MSG_UNKNOWN;\n        SafeDataStream str(socket);\n        str.receive();\n        str >> m;\n        switch (m) {\n            case ERROR: {\n                QString message;\n                Error type = ERROR_NONE;\n                str >> message >> type;\n                Q_EMIT auth->error(message, type);\n                break;\n            }\n            case INFO: {\n                QString message;\n                Info type = INFO_NONE;\n                str >> message >> type;\n                Q_EMIT auth->info(message, type);\n                break;\n            }\n            case REQUEST: {\n                Request r;\n                str >> r;\n                request->setRequest(&r);\n                break;\n            }\n            case AUTHENTICATED: {\n                QString user;\n                str >> user;\n                if (!user.isEmpty()) {\n                    auth->setUser(user);\n                    Q_EMIT auth->authentication(user, true);\n                    str.reset();\n                    str << AUTHENTICATED << environment;\n                    str.send();\n                }\n                else {\n                    Q_EMIT auth->authentication(user, false);\n                }\n                break;\n            }\n            case SESSION_STATUS: {\n                bool status;\n                str >> status;\n                Q_EMIT auth->session(status);\n                str.reset();\n                str << SESSION_STATUS;\n                str.send();\n                break;\n            }\n            default: {\n                Q_EMIT auth->error(QString(\"Auth: Unexpected value received: %1\").arg(m), ERROR_INTERNAL);\n            }\n        }\n    }",
        "func": "void Auth::Private::dataPending() {\n        Auth *auth = qobject_cast<Auth*>(parent());\n        Msg m = MSG_UNKNOWN;\n        SafeDataStream str(socket);\n        str.receive();\n        str >> m;\n        switch (m) {\n            case ERROR: {\n                QString message;\n                Error type = ERROR_NONE;\n                str >> message >> type;\n                Q_EMIT auth->error(message, type);\n                break;\n            }\n            case INFO: {\n                QString message;\n                Info type = INFO_NONE;\n                str >> message >> type;\n                Q_EMIT auth->info(message, type);\n                break;\n            }\n            case REQUEST: {\n                Request r;\n                str >> r;\n                request->setRequest(&r);\n                break;\n            }\n            case AUTHENTICATED: {\n                QString user;\n                str >> user;\n                if (!user.isEmpty()) {\n                    auth->setUser(user);\n                    Q_EMIT auth->authentication(user, true);\n                    str.reset();\n                    str << AUTHENTICATED << environment << cookie;\n                    str.send();\n                }\n                else {\n                    Q_EMIT auth->authentication(user, false);\n                }\n                break;\n            }\n            case SESSION_STATUS: {\n                bool status;\n                str >> status;\n                Q_EMIT auth->session(status);\n                str.reset();\n                str << SESSION_STATUS;\n                str.send();\n                break;\n            }\n            default: {\n                Q_EMIT auth->error(QString(\"Auth: Unexpected value received: %1\").arg(m), ERROR_INTERNAL);\n            }\n        }\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,7 +32,7 @@\n                     auth->setUser(user);\n                     Q_EMIT auth->authentication(user, true);\n                     str.reset();\n-                    str << AUTHENTICATED << environment;\n+                    str << AUTHENTICATED << environment << cookie;\n                     str.send();\n                 }\n                 else {",
        "diff_line_info": {
            "deleted_lines": [
                "                    str << AUTHENTICATED << environment;"
            ],
            "added_lines": [
                "                    str << AUTHENTICATED << environment << cookie;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7272",
        "func_name": "sddm/HelperApp::authenticated",
        "description": "Simple Desktop Display Manager (SDDM) before 0.10.0 allows local users to gain root privileges because code running as root performs write operations within a user home directory, and this user may have created links in advance (exploitation requires the user to win a race condition in the ~/.Xauthority chown case, but not other cases).",
        "git_url": "https://github.com/sddm/sddm/commit/e92c466f5c324b429ce1a8aa1b40d208574c778a",
        "commit_title": "Move onAuthenticated XAUTHORITY generation to the helper",
        "commit_text": " This avoids it being created as root and then chown'd.",
        "func_before": "QProcessEnvironment HelperApp::authenticated(const QString &user) {\n        Msg m = Msg::MSG_UNKNOWN;\n        QProcessEnvironment response;\n        SafeDataStream str(m_socket);\n        str << Msg::AUTHENTICATED << user;\n        str.send();\n        if (user.isEmpty())\n            return response;\n        str.receive();\n        str >> m >> response;\n        if (m != AUTHENTICATED) {\n            response = QProcessEnvironment();\n            qCritical() << \"Received a wrong opcode instead of AUTHENTICATED:\" << m;\n        }\n        return response;\n    }",
        "func": "QProcessEnvironment HelperApp::authenticated(const QString &user) {\n        Msg m = Msg::MSG_UNKNOWN;\n        QProcessEnvironment env;\n        SafeDataStream str(m_socket);\n        str << Msg::AUTHENTICATED << user;\n        str.send();\n        if (user.isEmpty())\n            return env;\n        str.receive();\n        str >> m >> env >> m_cookie;\n        if (m != AUTHENTICATED) {\n            env = QProcessEnvironment();\n            m_cookie = QString();\n            qCritical() << \"Received a wrong opcode instead of AUTHENTICATED:\" << m;\n        }\n        return env;\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,16 +1,17 @@\n QProcessEnvironment HelperApp::authenticated(const QString &user) {\n         Msg m = Msg::MSG_UNKNOWN;\n-        QProcessEnvironment response;\n+        QProcessEnvironment env;\n         SafeDataStream str(m_socket);\n         str << Msg::AUTHENTICATED << user;\n         str.send();\n         if (user.isEmpty())\n-            return response;\n+            return env;\n         str.receive();\n-        str >> m >> response;\n+        str >> m >> env >> m_cookie;\n         if (m != AUTHENTICATED) {\n-            response = QProcessEnvironment();\n+            env = QProcessEnvironment();\n+            m_cookie = QString();\n             qCritical() << \"Received a wrong opcode instead of AUTHENTICATED:\" << m;\n         }\n-        return response;\n+        return env;\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "        QProcessEnvironment response;",
                "            return response;",
                "        str >> m >> response;",
                "            response = QProcessEnvironment();",
                "        return response;"
            ],
            "added_lines": [
                "        QProcessEnvironment env;",
                "            return env;",
                "        str >> m >> env >> m_cookie;",
                "            env = QProcessEnvironment();",
                "            m_cookie = QString();",
                "        return env;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7272",
        "func_name": "sddm/Backend::openSession",
        "description": "Simple Desktop Display Manager (SDDM) before 0.10.0 allows local users to gain root privileges because code running as root performs write operations within a user home directory, and this user may have created links in advance (exploitation requires the user to win a race condition in the ~/.Xauthority chown case, but not other cases).",
        "git_url": "https://github.com/sddm/sddm/commit/e92c466f5c324b429ce1a8aa1b40d208574c778a",
        "commit_title": "Move onAuthenticated XAUTHORITY generation to the helper",
        "commit_text": " This avoids it being created as root and then chown'd.",
        "func_before": "bool Backend::openSession() {\n        struct passwd *pw;\n        pw = getpwnam(qPrintable(qobject_cast<HelperApp*>(parent())->user()));\n        if (pw) {\n            QProcessEnvironment env = m_app->session()->processEnvironment();\n            env.insert(\"HOME\", pw->pw_dir);\n            env.insert(\"PWD\", pw->pw_dir);\n            env.insert(\"SHELL\", pw->pw_shell);\n            env.insert(\"USER\", pw->pw_name);\n            env.insert(\"LOGNAME\", pw->pw_name);\n            if (env.contains(\"DISPLAY\") && !env.contains(\"XAUTHORITY\"))\n                env.insert(\"XAUTHORITY\", QString(\"%1/.Xauthority\").arg(pw->pw_dir));\n            // TODO: I'm fairly sure this shouldn't be done for PAM sessions, investigate!\n            m_app->session()->setProcessEnvironment(env);\n\n            // redirect standard error to a file\n            m_app->session()->setStandardErrorFile(QString(\"%1/.xsession-errors\").arg(pw->pw_dir));\n        }\n        return m_app->session()->start();\n    }",
        "func": "bool Backend::openSession() {\n        struct passwd *pw;\n        pw = getpwnam(qPrintable(qobject_cast<HelperApp*>(parent())->user()));\n        if (pw) {\n            QProcessEnvironment env = m_app->session()->processEnvironment();\n            env.insert(\"HOME\", pw->pw_dir);\n            env.insert(\"PWD\", pw->pw_dir);\n            env.insert(\"SHELL\", pw->pw_shell);\n            env.insert(\"USER\", pw->pw_name);\n            env.insert(\"LOGNAME\", pw->pw_name);\n            if (env.contains(\"DISPLAY\") && !env.contains(\"XAUTHORITY\"))\n                env.insert(\"XAUTHORITY\", QString(\"%1/.Xauthority\").arg(pw->pw_dir));\n            // TODO: I'm fairly sure this shouldn't be done for PAM sessions, investigate!\n            m_app->session()->setProcessEnvironment(env);\n        }\n        return m_app->session()->start();\n    }",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,9 +12,6 @@\n                 env.insert(\"XAUTHORITY\", QString(\"%1/.Xauthority\").arg(pw->pw_dir));\n             // TODO: I'm fairly sure this shouldn't be done for PAM sessions, investigate!\n             m_app->session()->setProcessEnvironment(env);\n-\n-            // redirect standard error to a file\n-            m_app->session()->setStandardErrorFile(QString(\"%1/.xsession-errors\").arg(pw->pw_dir));\n         }\n         return m_app->session()->start();\n     }",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "            // redirect standard error to a file",
                "            m_app->session()->setStandardErrorFile(QString(\"%1/.xsession-errors\").arg(pw->pw_dir));"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2016-10150",
        "func_name": "torvalds/linux/kvm_ioctl_create_device",
        "description": "Use-after-free vulnerability in the kvm_ioctl_create_device function in virt/kvm/kvm_main.c in the Linux kernel before 4.8.13 allows host OS users to cause a denial of service (host OS crash) or possibly gain privileges via crafted ioctl calls on the /dev/kvm device.",
        "git_url": "https://github.com/torvalds/linux/commit/a0f1d21c1ccb1da66629627a74059dd7f5ac9c61",
        "commit_title": "KVM: use after free in kvm_ioctl_create_device()",
        "commit_text": " We should move the ops->destroy(dev) after the list_del(&dev->vm_node) so that we don't use \"dev\" after freeing it. ",
        "func_before": "static int kvm_ioctl_create_device(struct kvm *kvm,\n\t\t\t\t   struct kvm_create_device *cd)\n{\n\tstruct kvm_device_ops *ops = NULL;\n\tstruct kvm_device *dev;\n\tbool test = cd->flags & KVM_CREATE_DEVICE_TEST;\n\tint ret;\n\n\tif (cd->type >= ARRAY_SIZE(kvm_device_ops_table))\n\t\treturn -ENODEV;\n\n\tops = kvm_device_ops_table[cd->type];\n\tif (ops == NULL)\n\t\treturn -ENODEV;\n\n\tif (test)\n\t\treturn 0;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tdev->ops = ops;\n\tdev->kvm = kvm;\n\n\tmutex_lock(&kvm->lock);\n\tret = ops->create(dev, cd->type);\n\tif (ret < 0) {\n\t\tmutex_unlock(&kvm->lock);\n\t\tkfree(dev);\n\t\treturn ret;\n\t}\n\tlist_add(&dev->vm_node, &kvm->devices);\n\tmutex_unlock(&kvm->lock);\n\n\tif (ops->init)\n\t\tops->init(dev);\n\n\tret = anon_inode_getfd(ops->name, &kvm_device_fops, dev, O_RDWR | O_CLOEXEC);\n\tif (ret < 0) {\n\t\tops->destroy(dev);\n\t\tmutex_lock(&kvm->lock);\n\t\tlist_del(&dev->vm_node);\n\t\tmutex_unlock(&kvm->lock);\n\t\treturn ret;\n\t}\n\n\tkvm_get_kvm(kvm);\n\tcd->fd = ret;\n\treturn 0;\n}",
        "func": "static int kvm_ioctl_create_device(struct kvm *kvm,\n\t\t\t\t   struct kvm_create_device *cd)\n{\n\tstruct kvm_device_ops *ops = NULL;\n\tstruct kvm_device *dev;\n\tbool test = cd->flags & KVM_CREATE_DEVICE_TEST;\n\tint ret;\n\n\tif (cd->type >= ARRAY_SIZE(kvm_device_ops_table))\n\t\treturn -ENODEV;\n\n\tops = kvm_device_ops_table[cd->type];\n\tif (ops == NULL)\n\t\treturn -ENODEV;\n\n\tif (test)\n\t\treturn 0;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tdev->ops = ops;\n\tdev->kvm = kvm;\n\n\tmutex_lock(&kvm->lock);\n\tret = ops->create(dev, cd->type);\n\tif (ret < 0) {\n\t\tmutex_unlock(&kvm->lock);\n\t\tkfree(dev);\n\t\treturn ret;\n\t}\n\tlist_add(&dev->vm_node, &kvm->devices);\n\tmutex_unlock(&kvm->lock);\n\n\tif (ops->init)\n\t\tops->init(dev);\n\n\tret = anon_inode_getfd(ops->name, &kvm_device_fops, dev, O_RDWR | O_CLOEXEC);\n\tif (ret < 0) {\n\t\tmutex_lock(&kvm->lock);\n\t\tlist_del(&dev->vm_node);\n\t\tmutex_unlock(&kvm->lock);\n\t\tops->destroy(dev);\n\t\treturn ret;\n\t}\n\n\tkvm_get_kvm(kvm);\n\tcd->fd = ret;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -38,10 +38,10 @@\n \n \tret = anon_inode_getfd(ops->name, &kvm_device_fops, dev, O_RDWR | O_CLOEXEC);\n \tif (ret < 0) {\n-\t\tops->destroy(dev);\n \t\tmutex_lock(&kvm->lock);\n \t\tlist_del(&dev->vm_node);\n \t\tmutex_unlock(&kvm->lock);\n+\t\tops->destroy(dev);\n \t\treturn ret;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tops->destroy(dev);"
            ],
            "added_lines": [
                "\t\tops->destroy(dev);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-10044",
        "func_name": "torvalds/linux/aio_mount",
        "description": "The aio_mount function in fs/aio.c in the Linux kernel before 4.7.7 does not properly restrict execute access, which makes it easier for local users to bypass intended SELinux W^X policy restrictions, and consequently gain privileges, via an io_setup system call.",
        "git_url": "https://github.com/torvalds/linux/commit/22f6b4d34fcf039c63a94e7670e0da24f8575a5a",
        "commit_title": "aio: mark AIO pseudo-fs noexec",
        "commit_text": " This ensures that do_mmap() won't implicitly make AIO memory mappings executable if the READ_IMPLIES_EXEC personality flag is set.  Such behavior is problematic because the security_mmap_file LSM hook doesn't catch this case, potentially permitting an attacker to bypass a W^X policy enforced by SELinux.  I have tested the patch on my machine.  To test the behavior, compile and run this:      #define _GNU_SOURCE     #include <unistd.h>     #include <sys/personality.h>     #include <linux/aio_abi.h>     #include <err.h>     #include <stdlib.h>     #include <stdio.h>     #include <sys/syscall.h>      int main(void) {         personality(READ_IMPLIES_EXEC);         aio_context_t ctx = 0;         if (syscall(__NR_io_setup, 1, &ctx))             err(1, \"io_setup\");          char cmd[1000];         sprintf(cmd, \"cat /proc/%d/maps | grep -F '/[aio]'\",             (int)getpid());         system(cmd);         return 0;     }  In the output, \"rw-s\" is good, \"rwxs\" is bad. ",
        "func_before": "static struct dentry *aio_mount(struct file_system_type *fs_type,\n\t\t\t\tint flags, const char *dev_name, void *data)\n{\n\tstatic const struct dentry_operations ops = {\n\t\t.d_dname\t= simple_dname,\n\t};\n\treturn mount_pseudo(fs_type, \"aio:\", NULL, &ops, AIO_RING_MAGIC);\n}",
        "func": "static struct dentry *aio_mount(struct file_system_type *fs_type,\n\t\t\t\tint flags, const char *dev_name, void *data)\n{\n\tstatic const struct dentry_operations ops = {\n\t\t.d_dname\t= simple_dname,\n\t};\n\tstruct dentry *root = mount_pseudo(fs_type, \"aio:\", NULL, &ops,\n\t\t\t\t\t   AIO_RING_MAGIC);\n\n\tif (!IS_ERR(root))\n\t\troot->d_sb->s_iflags |= SB_I_NOEXEC;\n\treturn root;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,5 +4,10 @@\n \tstatic const struct dentry_operations ops = {\n \t\t.d_dname\t= simple_dname,\n \t};\n-\treturn mount_pseudo(fs_type, \"aio:\", NULL, &ops, AIO_RING_MAGIC);\n+\tstruct dentry *root = mount_pseudo(fs_type, \"aio:\", NULL, &ops,\n+\t\t\t\t\t   AIO_RING_MAGIC);\n+\n+\tif (!IS_ERR(root))\n+\t\troot->d_sb->s_iflags |= SB_I_NOEXEC;\n+\treturn root;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\treturn mount_pseudo(fs_type, \"aio:\", NULL, &ops, AIO_RING_MAGIC);"
            ],
            "added_lines": [
                "\tstruct dentry *root = mount_pseudo(fs_type, \"aio:\", NULL, &ops,",
                "\t\t\t\t\t   AIO_RING_MAGIC);",
                "",
                "\tif (!IS_ERR(root))",
                "\t\troot->d_sb->s_iflags |= SB_I_NOEXEC;",
                "\treturn root;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-8659",
        "func_name": "containers/bubblewrap/privileged_op",
        "description": "Bubblewrap before 0.1.3 sets the PR_SET_DUMPABLE flag, which might allow local users to gain privileges by attaching to the process, as demonstrated by sending commands to a PrivSep socket.",
        "git_url": "https://github.com/containers/bubblewrap/commit/133dcb7cba65c56767b5ab7b5f60bfc590799b6f",
        "commit_title": "Don't allow setting hostname if not unsharing UTS namespace",
        "commit_text": " This is normally verified on argument validation, but it may happen if someone managed to send custom priv-sep operations via e.g. ptrace.  See https://github.com/projectatomic/bubblewrap/issues/107  Closes: #108 Approved by: alexlarsson",
        "func_before": "static void\nprivileged_op (int         privileged_op_socket,\n               uint32_t    op,\n               uint32_t    flags,\n               const char *arg1,\n               const char *arg2)\n{\n  if (privileged_op_socket != -1)\n    {\n      uint32_t buffer[2048];  /* 8k, but is int32 to guarantee nice alignment */\n      PrivSepOp *op_buffer = (PrivSepOp *) buffer;\n      size_t buffer_size = sizeof (PrivSepOp);\n      uint32_t arg1_offset = 0, arg2_offset = 0;\n      if (arg1 != NULL)\n        {\n          arg1_offset = buffer_size;\n          buffer_size += strlen (arg1) + 1;\n        }\n      if (arg2 != NULL)\n        {\n          arg2_offset = buffer_size;\n          buffer_size += strlen (arg2) + 1;\n        }\n\n      if (buffer_size >= sizeof (buffer))\n        die (\"privilege separation operation to large\");\n\n      op_buffer->op = op;\n      op_buffer->flags = flags;\n      op_buffer->arg1_offset = arg1_offset;\n      op_buffer->arg2_offset = arg2_offset;\n      if (arg1 != NULL)\n        strcpy ((char *) buffer + arg1_offset, arg1);\n      if (arg2 != NULL)\n        strcpy ((char *) buffer + arg2_offset, arg2);\n\n      if (write (privileged_op_socket, buffer, buffer_size) != buffer_size)\n        die (\"Can't write to privileged_op_socket\");\n\n      if (read (privileged_op_socket, buffer, 1) != 1)\n        die (\"Can't read from privileged_op_socket\");\n\n      return;\n    }\n\n  switch (op)\n    {\n    case PRIV_SEP_OP_DONE:\n      break;\n\n    case PRIV_SEP_OP_REMOUNT_RO_NO_RECURSIVE:\n      if (bind_mount (proc_fd, arg1, arg2, flags) != 0)\n        die_with_error (\"Can't bind mount %s on %s\", arg1, arg2);\n      break;\n\n    case PRIV_SEP_OP_BIND_MOUNT:\n      /* We always bind directories recursively, otherwise this would let us\n         access files that are otherwise covered on the host */\n      if (bind_mount (proc_fd, arg1, arg2, BIND_RECURSIVE | flags) != 0)\n        die_with_error (\"Can't bind mount %s on %s\", arg1, arg2);\n      break;\n\n    case PRIV_SEP_OP_PROC_MOUNT:\n      if (mount (\"proc\", arg1, \"proc\", MS_MGC_VAL | MS_NOSUID | MS_NOEXEC | MS_NODEV, NULL) != 0)\n        die_with_error (\"Can't mount proc on %s\", arg1);\n      break;\n\n    case PRIV_SEP_OP_TMPFS_MOUNT:\n      {\n        cleanup_free char *opt = label_mount (\"mode=0755\", opt_file_label);\n        if (mount (\"tmpfs\", arg1, \"tmpfs\", MS_MGC_VAL | MS_NOSUID | MS_NODEV, opt) != 0)\n          die_with_error (\"Can't mount tmpfs on %s\", arg1);\n        break;\n      }\n\n    case PRIV_SEP_OP_DEVPTS_MOUNT:\n      if (mount (\"devpts\", arg1, \"devpts\", MS_MGC_VAL | MS_NOSUID | MS_NOEXEC,\n                 \"newinstance,ptmxmode=0666,mode=620\") != 0)\n        die_with_error (\"Can't mount devpts on %s\", arg1);\n      break;\n\n    case PRIV_SEP_OP_MQUEUE_MOUNT:\n      if (mount (\"mqueue\", arg1, \"mqueue\", 0, NULL) != 0)\n        die_with_error (\"Can't mount mqueue on %s\", arg1);\n      break;\n\n    case PRIV_SEP_OP_SET_HOSTNAME:\n      if (sethostname (arg1, strlen(arg1)) != 0)\n        die_with_error (\"Can't set hostname to %s\", arg1);\n      break;\n\n    default:\n      die (\"Unexpected privileged op %d\", op);\n    }\n}",
        "func": "static void\nprivileged_op (int         privileged_op_socket,\n               uint32_t    op,\n               uint32_t    flags,\n               const char *arg1,\n               const char *arg2)\n{\n  if (privileged_op_socket != -1)\n    {\n      uint32_t buffer[2048];  /* 8k, but is int32 to guarantee nice alignment */\n      PrivSepOp *op_buffer = (PrivSepOp *) buffer;\n      size_t buffer_size = sizeof (PrivSepOp);\n      uint32_t arg1_offset = 0, arg2_offset = 0;\n      if (arg1 != NULL)\n        {\n          arg1_offset = buffer_size;\n          buffer_size += strlen (arg1) + 1;\n        }\n      if (arg2 != NULL)\n        {\n          arg2_offset = buffer_size;\n          buffer_size += strlen (arg2) + 1;\n        }\n\n      if (buffer_size >= sizeof (buffer))\n        die (\"privilege separation operation to large\");\n\n      op_buffer->op = op;\n      op_buffer->flags = flags;\n      op_buffer->arg1_offset = arg1_offset;\n      op_buffer->arg2_offset = arg2_offset;\n      if (arg1 != NULL)\n        strcpy ((char *) buffer + arg1_offset, arg1);\n      if (arg2 != NULL)\n        strcpy ((char *) buffer + arg2_offset, arg2);\n\n      if (write (privileged_op_socket, buffer, buffer_size) != buffer_size)\n        die (\"Can't write to privileged_op_socket\");\n\n      if (read (privileged_op_socket, buffer, 1) != 1)\n        die (\"Can't read from privileged_op_socket\");\n\n      return;\n    }\n\n  switch (op)\n    {\n    case PRIV_SEP_OP_DONE:\n      break;\n\n    case PRIV_SEP_OP_REMOUNT_RO_NO_RECURSIVE:\n      if (bind_mount (proc_fd, arg1, arg2, flags) != 0)\n        die_with_error (\"Can't bind mount %s on %s\", arg1, arg2);\n      break;\n\n    case PRIV_SEP_OP_BIND_MOUNT:\n      /* We always bind directories recursively, otherwise this would let us\n         access files that are otherwise covered on the host */\n      if (bind_mount (proc_fd, arg1, arg2, BIND_RECURSIVE | flags) != 0)\n        die_with_error (\"Can't bind mount %s on %s\", arg1, arg2);\n      break;\n\n    case PRIV_SEP_OP_PROC_MOUNT:\n      if (mount (\"proc\", arg1, \"proc\", MS_MGC_VAL | MS_NOSUID | MS_NOEXEC | MS_NODEV, NULL) != 0)\n        die_with_error (\"Can't mount proc on %s\", arg1);\n      break;\n\n    case PRIV_SEP_OP_TMPFS_MOUNT:\n      {\n        cleanup_free char *opt = label_mount (\"mode=0755\", opt_file_label);\n        if (mount (\"tmpfs\", arg1, \"tmpfs\", MS_MGC_VAL | MS_NOSUID | MS_NODEV, opt) != 0)\n          die_with_error (\"Can't mount tmpfs on %s\", arg1);\n        break;\n      }\n\n    case PRIV_SEP_OP_DEVPTS_MOUNT:\n      if (mount (\"devpts\", arg1, \"devpts\", MS_MGC_VAL | MS_NOSUID | MS_NOEXEC,\n                 \"newinstance,ptmxmode=0666,mode=620\") != 0)\n        die_with_error (\"Can't mount devpts on %s\", arg1);\n      break;\n\n    case PRIV_SEP_OP_MQUEUE_MOUNT:\n      if (mount (\"mqueue\", arg1, \"mqueue\", 0, NULL) != 0)\n        die_with_error (\"Can't mount mqueue on %s\", arg1);\n      break;\n\n    case PRIV_SEP_OP_SET_HOSTNAME:\n      /* This is checked at the start, but lets verify it here in case\n         something manages to send hacked priv-sep operation requests. */\n      if (!opt_unshare_uts)\n        die (\"Refusing to set hostname in original namespace\");\n      if (sethostname (arg1, strlen(arg1)) != 0)\n        die_with_error (\"Can't set hostname to %s\", arg1);\n      break;\n\n    default:\n      die (\"Unexpected privileged op %d\", op);\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -85,6 +85,10 @@\n       break;\n \n     case PRIV_SEP_OP_SET_HOSTNAME:\n+      /* This is checked at the start, but lets verify it here in case\n+         something manages to send hacked priv-sep operation requests. */\n+      if (!opt_unshare_uts)\n+        die (\"Refusing to set hostname in original namespace\");\n       if (sethostname (arg1, strlen(arg1)) != 0)\n         die_with_error (\"Can't set hostname to %s\", arg1);\n       break;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "      /* This is checked at the start, but lets verify it here in case",
                "         something manages to send hacked priv-sep operation requests. */",
                "      if (!opt_unshare_uts)",
                "        die (\"Refusing to set hostname in original namespace\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7809",
        "func_name": "twigphp/Twig/twig_add_method_to_class",
        "description": "The displayBlock function Template.php in Sensio Labs Twig before 1.20.0, when Sandbox mode is enabled, allows remote attackers to execute arbitrary code via the _self variable in a template.",
        "git_url": "https://github.com/twigphp/Twig/commit/22500609b69a9f17a64102d9376cb114f706ee2f",
        "commit_title": "Fix the accessibility of Twig_Template::getEnvironment method in the C ext",
        "commit_text": "",
        "func_before": "static int twig_add_method_to_class(void *pDest APPLY_TSRMLS_DC, int num_args, va_list args, zend_hash_key *hash_key)\n{\n\tzval *retval;\n\tchar *item;\n\tsize_t item_len;\n\tzend_function *mptr = (zend_function *) pDest;\n\tAPPLY_TSRMLS_FETCH();\n\n\tif (!(mptr->common.fn_flags & ZEND_ACC_PUBLIC)) {\n\t\treturn 0;\n\t}\n\n\tretval = va_arg(args, zval*);\n\n\titem_len = strlen(mptr->common.function_name);\n\titem = estrndup(mptr->common.function_name, item_len);\n\tphp_strtolower(item, item_len);\n\n\tadd_assoc_stringl_ex(retval, item, item_len+1, item, item_len, 0);\n\n\treturn 0;\n}",
        "func": "static int twig_add_method_to_class(void *pDest APPLY_TSRMLS_DC, int num_args, va_list args, zend_hash_key *hash_key)\n{\n\tzend_class_entry *ce;\n\tzval *retval;\n\tchar *item;\n\tsize_t item_len;\n\tzend_function *mptr = (zend_function *) pDest;\n\tAPPLY_TSRMLS_FETCH();\n\n\tif (!(mptr->common.fn_flags & ZEND_ACC_PUBLIC)) {\n\t\treturn 0;\n\t}\n\n\tce = *va_arg(args, zend_class_entry**);\n\tretval = va_arg(args, zval*);\n\n\titem_len = strlen(mptr->common.function_name);\n\titem = estrndup(mptr->common.function_name, item_len);\n\tphp_strtolower(item, item_len);\n\n\tif (strcmp(\"getenvironment\", item) == 0) {\n\t\tzend_class_entry **twig_template_ce;\n\t\tif (zend_lookup_class(\"Twig_Template\", strlen(\"Twig_Template\"), &twig_template_ce TSRMLS_CC) == FAILURE) {\n\t\t\treturn 0;\n\t\t}\n\t\tif (instanceof_function(ce, *twig_template_ce TSRMLS_CC)) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tadd_assoc_stringl_ex(retval, item, item_len+1, item, item_len, 0);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n static int twig_add_method_to_class(void *pDest APPLY_TSRMLS_DC, int num_args, va_list args, zend_hash_key *hash_key)\n {\n+\tzend_class_entry *ce;\n \tzval *retval;\n \tchar *item;\n \tsize_t item_len;\n@@ -10,12 +11,23 @@\n \t\treturn 0;\n \t}\n \n+\tce = *va_arg(args, zend_class_entry**);\n \tretval = va_arg(args, zval*);\n \n \titem_len = strlen(mptr->common.function_name);\n \titem = estrndup(mptr->common.function_name, item_len);\n \tphp_strtolower(item, item_len);\n \n+\tif (strcmp(\"getenvironment\", item) == 0) {\n+\t\tzend_class_entry **twig_template_ce;\n+\t\tif (zend_lookup_class(\"Twig_Template\", strlen(\"Twig_Template\"), &twig_template_ce TSRMLS_CC) == FAILURE) {\n+\t\t\treturn 0;\n+\t\t}\n+\t\tif (instanceof_function(ce, *twig_template_ce TSRMLS_CC)) {\n+\t\t\treturn 0;\n+\t\t}\n+\t}\n+\n \tadd_assoc_stringl_ex(retval, item, item_len+1, item, item_len, 0);\n \n \treturn 0;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tzend_class_entry *ce;",
                "\tce = *va_arg(args, zend_class_entry**);",
                "\tif (strcmp(\"getenvironment\", item) == 0) {",
                "\t\tzend_class_entry **twig_template_ce;",
                "\t\tif (zend_lookup_class(\"Twig_Template\", strlen(\"Twig_Template\"), &twig_template_ce TSRMLS_CC) == FAILURE) {",
                "\t\t\treturn 0;",
                "\t\t}",
                "\t\tif (instanceof_function(ce, *twig_template_ce TSRMLS_CC)) {",
                "\t\t\treturn 0;",
                "\t\t}",
                "\t}",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7809",
        "func_name": "twigphp/Twig/twig_add_class_to_cache",
        "description": "The displayBlock function Template.php in Sensio Labs Twig before 1.20.0, when Sandbox mode is enabled, allows remote attackers to execute arbitrary code via the _self variable in a template.",
        "git_url": "https://github.com/twigphp/Twig/commit/22500609b69a9f17a64102d9376cb114f706ee2f",
        "commit_title": "Fix the accessibility of Twig_Template::getEnvironment method in the C ext",
        "commit_text": "",
        "func_before": "static void twig_add_class_to_cache(zval *cache, zval *object, char *class_name TSRMLS_DC)\n{\n\tzval *class_info, *class_methods, *class_properties;\n\tzend_class_entry *class_ce;\n\n\tclass_ce = zend_get_class_entry(object TSRMLS_CC);\n\n\tALLOC_INIT_ZVAL(class_info);\n\tALLOC_INIT_ZVAL(class_methods);\n\tALLOC_INIT_ZVAL(class_properties);\n\tarray_init(class_info);\n\tarray_init(class_methods);\n\tarray_init(class_properties);\n\t// add all methods to self::cache[$class]['methods']\n\tzend_hash_apply_with_arguments(&class_ce->function_table APPLY_TSRMLS_CC, twig_add_method_to_class, 1, class_methods);\n\tzend_hash_apply_with_arguments(&class_ce->properties_info APPLY_TSRMLS_CC, twig_add_property_to_class, 2, &class_ce, class_properties);\n\n\tadd_assoc_zval(class_info, \"methods\", class_methods);\n\tadd_assoc_zval(class_info, \"properties\", class_properties);\n\tadd_assoc_zval(cache, class_name, class_info);\n}",
        "func": "static void twig_add_class_to_cache(zval *cache, zval *object, char *class_name TSRMLS_DC)\n{\n\tzval *class_info, *class_methods, *class_properties;\n\tzend_class_entry *class_ce;\n\n\tclass_ce = zend_get_class_entry(object TSRMLS_CC);\n\n\tALLOC_INIT_ZVAL(class_info);\n\tALLOC_INIT_ZVAL(class_methods);\n\tALLOC_INIT_ZVAL(class_properties);\n\tarray_init(class_info);\n\tarray_init(class_methods);\n\tarray_init(class_properties);\n\t// add all methods to self::cache[$class]['methods']\n\tzend_hash_apply_with_arguments(&class_ce->function_table APPLY_TSRMLS_CC, twig_add_method_to_class, 2, &class_ce, class_methods);\n\tzend_hash_apply_with_arguments(&class_ce->properties_info APPLY_TSRMLS_CC, twig_add_property_to_class, 2, &class_ce, class_properties);\n\n\tadd_assoc_zval(class_info, \"methods\", class_methods);\n\tadd_assoc_zval(class_info, \"properties\", class_properties);\n\tadd_assoc_zval(cache, class_name, class_info);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,7 @@\n \tarray_init(class_methods);\n \tarray_init(class_properties);\n \t// add all methods to self::cache[$class]['methods']\n-\tzend_hash_apply_with_arguments(&class_ce->function_table APPLY_TSRMLS_CC, twig_add_method_to_class, 1, class_methods);\n+\tzend_hash_apply_with_arguments(&class_ce->function_table APPLY_TSRMLS_CC, twig_add_method_to_class, 2, &class_ce, class_methods);\n \tzend_hash_apply_with_arguments(&class_ce->properties_info APPLY_TSRMLS_CC, twig_add_property_to_class, 2, &class_ce, class_properties);\n \n \tadd_assoc_zval(class_info, \"methods\", class_methods);",
        "diff_line_info": {
            "deleted_lines": [
                "\tzend_hash_apply_with_arguments(&class_ce->function_table APPLY_TSRMLS_CC, twig_add_method_to_class, 1, class_methods);"
            ],
            "added_lines": [
                "\tzend_hash_apply_with_arguments(&class_ce->function_table APPLY_TSRMLS_CC, twig_add_method_to_class, 2, &class_ce, class_methods);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3845",
        "func_name": "android/Parcel::appendFrom",
        "description": "The Parcel::appendFrom function in libs/binder/Parcel.cpp in Binder in Android before 5.1.1 LMY48M does not consider parcel boundaries during identification of binder objects in an append operation, which allows attackers to obtain a different application's privileges via a crafted application, aka internal bug 17312693.",
        "git_url": "https://android.googlesource.com/platform/frameworks/native/+/e68cbc3e9e66df4231e70efa3e9c41abc12aea20",
        "commit_title": "Disregard alleged binder entities beyond parcel bounds",
        "commit_text": " When appending one parcel's contents to another, ignore binder objects within the source Parcel that appear to lie beyond the formal bounds of that Parcel's data buffer.  Bug 17312693  (cherry picked from commit 27182be9f20f4f5b48316666429f09b9ecc1f22e) ",
        "func_before": "status_t Parcel::appendFrom(const Parcel *parcel, size_t offset, size_t len)\n{\n    const sp<ProcessState> proc(ProcessState::self());\n    status_t err;\n    const uint8_t *data = parcel->mData;\n    const binder_size_t *objects = parcel->mObjects;\n    size_t size = parcel->mObjectsSize;\n    int startPos = mDataPos;\n    int firstIndex = -1, lastIndex = -2;\n\n    if (len == 0) {\n        return NO_ERROR;\n    }\n\n    // range checks against the source parcel size\n    if ((offset > parcel->mDataSize)\n            || (len > parcel->mDataSize)\n            || (offset + len > parcel->mDataSize)) {\n        return BAD_VALUE;\n    }\n\n    // Count objects in range\n    for (int i = 0; i < (int) size; i++) {\n        size_t off = objects[i];\n        if ((off >= offset) && (off < offset + len)) {\n            if (firstIndex == -1) {\n                firstIndex = i;\n            }\n            lastIndex = i;\n        }\n    }\n    int numObjects = lastIndex - firstIndex + 1;\n\n    if ((mDataSize+len) > mDataCapacity) {\n        // grow data\n        err = growData(len);\n        if (err != NO_ERROR) {\n            return err;\n        }\n    }\n\n    // append data\n    memcpy(mData + mDataPos, data + offset, len);\n    mDataPos += len;\n    mDataSize += len;\n\n    err = NO_ERROR;\n\n    if (numObjects > 0) {\n        // grow objects\n        if (mObjectsCapacity < mObjectsSize + numObjects) {\n            int newSize = ((mObjectsSize + numObjects)*3)/2;\n            binder_size_t *objects =\n                (binder_size_t*)realloc(mObjects, newSize*sizeof(binder_size_t));\n            if (objects == (binder_size_t*)0) {\n                return NO_MEMORY;\n            }\n            mObjects = objects;\n            mObjectsCapacity = newSize;\n        }\n\n        // append and acquire objects\n        int idx = mObjectsSize;\n        for (int i = firstIndex; i <= lastIndex; i++) {\n            size_t off = objects[i] - offset + startPos;\n            mObjects[idx++] = off;\n            mObjectsSize++;\n\n            flat_binder_object* flat\n                = reinterpret_cast<flat_binder_object*>(mData + off);\n            acquire_object(proc, *flat, this);\n\n            if (flat->type == BINDER_TYPE_FD) {\n                // If this is a file descriptor, we need to dup it so the\n                // new Parcel now owns its own fd, and can declare that we\n                // officially know we have fds.\n                flat->handle = dup(flat->handle);\n                flat->cookie = 1;\n                mHasFds = mFdsKnown = true;\n                if (!mAllowFds) {\n                    err = FDS_NOT_ALLOWED;\n                }\n            }\n        }\n    }\n\n    return err;\n}",
        "func": "status_t Parcel::appendFrom(const Parcel *parcel, size_t offset, size_t len)\n{\n    const sp<ProcessState> proc(ProcessState::self());\n    status_t err;\n    const uint8_t *data = parcel->mData;\n    const binder_size_t *objects = parcel->mObjects;\n    size_t size = parcel->mObjectsSize;\n    int startPos = mDataPos;\n    int firstIndex = -1, lastIndex = -2;\n\n    if (len == 0) {\n        return NO_ERROR;\n    }\n\n    // range checks against the source parcel size\n    if ((offset > parcel->mDataSize)\n            || (len > parcel->mDataSize)\n            || (offset + len > parcel->mDataSize)) {\n        return BAD_VALUE;\n    }\n\n    // Count objects in range\n    for (int i = 0; i < (int) size; i++) {\n        size_t off = objects[i];\n        if ((off >= offset) && (off + sizeof(flat_binder_object) <= offset + len)) {\n            if (firstIndex == -1) {\n                firstIndex = i;\n            }\n            lastIndex = i;\n        }\n    }\n    int numObjects = lastIndex - firstIndex + 1;\n\n    if ((mDataSize+len) > mDataCapacity) {\n        // grow data\n        err = growData(len);\n        if (err != NO_ERROR) {\n            return err;\n        }\n    }\n\n    // append data\n    memcpy(mData + mDataPos, data + offset, len);\n    mDataPos += len;\n    mDataSize += len;\n\n    err = NO_ERROR;\n\n    if (numObjects > 0) {\n        // grow objects\n        if (mObjectsCapacity < mObjectsSize + numObjects) {\n            int newSize = ((mObjectsSize + numObjects)*3)/2;\n            binder_size_t *objects =\n                (binder_size_t*)realloc(mObjects, newSize*sizeof(binder_size_t));\n            if (objects == (binder_size_t*)0) {\n                return NO_MEMORY;\n            }\n            mObjects = objects;\n            mObjectsCapacity = newSize;\n        }\n\n        // append and acquire objects\n        int idx = mObjectsSize;\n        for (int i = firstIndex; i <= lastIndex; i++) {\n            size_t off = objects[i] - offset + startPos;\n            mObjects[idx++] = off;\n            mObjectsSize++;\n\n            flat_binder_object* flat\n                = reinterpret_cast<flat_binder_object*>(mData + off);\n            acquire_object(proc, *flat, this);\n\n            if (flat->type == BINDER_TYPE_FD) {\n                // If this is a file descriptor, we need to dup it so the\n                // new Parcel now owns its own fd, and can declare that we\n                // officially know we have fds.\n                flat->handle = dup(flat->handle);\n                flat->cookie = 1;\n                mHasFds = mFdsKnown = true;\n                if (!mAllowFds) {\n                    err = FDS_NOT_ALLOWED;\n                }\n            }\n        }\n    }\n\n    return err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,7 +22,7 @@\n     // Count objects in range\n     for (int i = 0; i < (int) size; i++) {\n         size_t off = objects[i];\n-        if ((off >= offset) && (off < offset + len)) {\n+        if ((off >= offset) && (off + sizeof(flat_binder_object) <= offset + len)) {\n             if (firstIndex == -1) {\n                 firstIndex = i;\n             }",
        "diff_line_info": {
            "deleted_lines": [
                "        if ((off >= offset) && (off < offset + len)) {"
            ],
            "added_lines": [
                "        if ((off >= offset) && (off + sizeof(flat_binder_object) <= offset + len)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3849",
        "func_name": "android/Region_createFromParcel",
        "description": "The Region_createFromParcel function in core/jni/android/graphics/Region.cpp in Region in Android before 5.1.1 LMY48M does not check the return values of certain read operations, which allows attackers to execute arbitrary code via an application that sends a crafted message to a service, aka internal bug 21585255.",
        "git_url": "https://android.googlesource.com/platform/frameworks/base/+/1e72dc7a3074cd0b44d89afbf39bbf5000ef7cc3",
        "commit_title": "DO NOT MERGE: Ensure that unparcelling Region only reads the expected number of bytes",
        "commit_text": " bug: 20883006 ",
        "func_before": "static jlong Region_createFromParcel(JNIEnv* env, jobject clazz, jobject parcel)\n{\n    if (parcel == NULL) {\n        return NULL;\n    }\n\n    android::Parcel* p = android::parcelForJavaObject(env, parcel);\n\n    const size_t size = p->readInt32();\n    const void* regionData = p->readInplace(size);\n    if (regionData == NULL) {\n        return NULL;\n    }\n    SkRegion* region = new SkRegion;\n    region->readFromMemory(regionData, size);\n\n    return reinterpret_cast<jlong>(region);\n}",
        "func": "static jlong Region_createFromParcel(JNIEnv* env, jobject clazz, jobject parcel)\n{\n    if (parcel == NULL) {\n        return NULL;\n    }\n\n    android::Parcel* p = android::parcelForJavaObject(env, parcel);\n\n    const size_t size = p->readInt32();\n    const void* regionData = p->readInplace(size);\n    if (regionData == NULL) {\n        return NULL;\n    }\n    SkRegion* region = new SkRegion;\n    size_t actualSize = region->readFromMemory(regionData, size);\n\n    if (size != actualSize) {\n        delete region;\n        return NULL;\n    }\n\n    return reinterpret_cast<jlong>(region);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,7 +12,12 @@\n         return NULL;\n     }\n     SkRegion* region = new SkRegion;\n-    region->readFromMemory(regionData, size);\n+    size_t actualSize = region->readFromMemory(regionData, size);\n+\n+    if (size != actualSize) {\n+        delete region;\n+        return NULL;\n+    }\n \n     return reinterpret_cast<jlong>(region);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    region->readFromMemory(regionData, size);"
            ],
            "added_lines": [
                "    size_t actualSize = region->readFromMemory(regionData, size);",
                "",
                "    if (size != actualSize) {",
                "        delete region;",
                "        return NULL;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3849",
        "func_name": "android/Region_createFromParcel",
        "description": "The Region_createFromParcel function in core/jni/android/graphics/Region.cpp in Region in Android before 5.1.1 LMY48M does not check the return values of certain read operations, which allows attackers to execute arbitrary code via an application that sends a crafted message to a service, aka internal bug 21585255.",
        "git_url": "https://android.googlesource.com/platform/frameworks/base/+/4cff1f49ff95d990d6c2614da5d5a23d02145885",
        "commit_title": "Check that the parcel contained the expected amount of region data. DO NOT MERGE",
        "commit_text": " bug:20883006 ",
        "func_before": "static jlong Region_createFromParcel(JNIEnv* env, jobject clazz, jobject parcel)\n{\n    if (parcel == NULL) {\n        return NULL;\n    }\n\n    android::Parcel* p = android::parcelForJavaObject(env, parcel);\n\n    SkRegion* region = new SkRegion;\n    size_t size = p->readInt32();\n    region->readFromMemory(p->readInplace(size), size);\n\n    return reinterpret_cast<jlong>(region);\n}",
        "func": "static jlong Region_createFromParcel(JNIEnv* env, jobject clazz, jobject parcel)\n{\n    if (parcel == NULL) {\n        return NULL;\n    }\n\n    android::Parcel* p = android::parcelForJavaObject(env, parcel);\n\n    const size_t size = p->readInt32();\n    const void* regionData = p->readInplace(size);\n    if (regionData == NULL) {\n        return NULL;\n    }\n    SkRegion* region = new SkRegion;\n    region->readFromMemory(regionData, size);\n\n    return reinterpret_cast<jlong>(region);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,9 +6,13 @@\n \n     android::Parcel* p = android::parcelForJavaObject(env, parcel);\n \n+    const size_t size = p->readInt32();\n+    const void* regionData = p->readInplace(size);\n+    if (regionData == NULL) {\n+        return NULL;\n+    }\n     SkRegion* region = new SkRegion;\n-    size_t size = p->readInt32();\n-    region->readFromMemory(p->readInplace(size), size);\n+    region->readFromMemory(regionData, size);\n \n     return reinterpret_cast<jlong>(region);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    size_t size = p->readInt32();",
                "    region->readFromMemory(p->readInplace(size), size);"
            ],
            "added_lines": [
                "    const size_t size = p->readInt32();",
                "    const void* regionData = p->readInplace(size);",
                "    if (regionData == NULL) {",
                "        return NULL;",
                "    }",
                "    region->readFromMemory(regionData, size);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6755",
        "func_name": "chromium/ContainerNode::parserInsertBefore",
        "description": "The ContainerNode::parserInsertBefore function in core/dom/ContainerNode.cpp in Blink, as used in Google Chrome before 46.0.2490.71, proceeds with a DOM tree insertion in certain cases where a parent node no longer contains a child node, which allows remote attackers to bypass the Same Origin Policy via crafted JavaScript code.",
        "git_url": "https://github.com/chromium/chromium/commit/c71a21e6dda9025c2bf823c5aab791c2ae8cdfc2",
        "commit_title": "parserInsertBefore: Bail out if the parent no longer contains the child.",
        "commit_text": " nextChild may be removed from the DOM tree during the |parserRemoveChild(*newChild)| call which triggers unload events of newChild's  descendant iframes. In order to maintain the integrity of the DOM tree, the insertion of newChild must be aborted in this case.  This patch adds a return statement that rectifies the behavior in this edge case.   ",
        "func_before": "void ContainerNode::parserInsertBefore(PassRefPtrWillBeRawPtr<Node> newChild, Node& nextChild)\n{\n    ASSERT(newChild);\n    ASSERT(nextChild.parentNode() == this);\n    ASSERT(!newChild->isDocumentFragment());\n    ASSERT(!isHTMLTemplateElement(this));\n\n    if (nextChild.previousSibling() == newChild || &nextChild == newChild) // nothing to do\n        return;\n\n    if (!checkParserAcceptChild(*newChild))\n        return;\n\n    RefPtrWillBeRawPtr<Node> protect(this);\n\n    // FIXME: parserRemoveChild can run script which could then insert the\n    // newChild back into the page. Loop until the child is actually removed.\n    // See: fast/parser/execute-script-during-adoption-agency-removal.html\n    while (RefPtrWillBeRawPtr<ContainerNode> parent = newChild->parentNode())\n        parent->parserRemoveChild(*newChild);\n\n    if (document() != newChild->document())\n        document().adoptNode(newChild.get(), ASSERT_NO_EXCEPTION);\n\n    {\n        EventDispatchForbiddenScope assertNoEventDispatch;\n        ScriptForbiddenScope forbidScript;\n\n        treeScope().adoptIfNeeded(*newChild);\n        insertBeforeCommon(nextChild, *newChild);\n        newChild->updateAncestorConnectedSubframeCountForInsertion();\n        ChildListMutationScope(*this).childAdded(*newChild);\n    }\n\n    notifyNodeInserted(*newChild, ChildrenChangeSourceParser);\n}",
        "func": "void ContainerNode::parserInsertBefore(PassRefPtrWillBeRawPtr<Node> newChild, Node& nextChild)\n{\n    ASSERT(newChild);\n    ASSERT(nextChild.parentNode() == this);\n    ASSERT(!newChild->isDocumentFragment());\n    ASSERT(!isHTMLTemplateElement(this));\n\n    if (nextChild.previousSibling() == newChild || &nextChild == newChild) // nothing to do\n        return;\n\n    if (!checkParserAcceptChild(*newChild))\n        return;\n\n    RefPtrWillBeRawPtr<Node> protect(this);\n\n    // FIXME: parserRemoveChild can run script which could then insert the\n    // newChild back into the page. Loop until the child is actually removed.\n    // See: fast/parser/execute-script-during-adoption-agency-removal.html\n    while (RefPtrWillBeRawPtr<ContainerNode> parent = newChild->parentNode())\n        parent->parserRemoveChild(*newChild);\n\n    if (nextChild.parentNode() != this)\n        return;\n\n    if (document() != newChild->document())\n        document().adoptNode(newChild.get(), ASSERT_NO_EXCEPTION);\n\n    {\n        EventDispatchForbiddenScope assertNoEventDispatch;\n        ScriptForbiddenScope forbidScript;\n\n        treeScope().adoptIfNeeded(*newChild);\n        insertBeforeCommon(nextChild, *newChild);\n        newChild->updateAncestorConnectedSubframeCountForInsertion();\n        ChildListMutationScope(*this).childAdded(*newChild);\n    }\n\n    notifyNodeInserted(*newChild, ChildrenChangeSourceParser);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -19,6 +19,9 @@\n     while (RefPtrWillBeRawPtr<ContainerNode> parent = newChild->parentNode())\n         parent->parserRemoveChild(*newChild);\n \n+    if (nextChild.parentNode() != this)\n+        return;\n+\n     if (document() != newChild->document())\n         document().adoptNode(newChild.get(), ASSERT_NO_EXCEPTION);\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (nextChild.parentNode() != this)",
                "        return;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7835",
        "func_name": "xen-project/xen/mod_l2_entry",
        "description": "The mod_l2_entry function in arch/x86/mm.c in Xen 3.4 through 4.6.x does not properly validate level 2 page table entries, which allows local PV guest administrators to gain privileges via a crafted superpage mapping.",
        "git_url": "https://github.com/xen-project/xen/commit/fe360c90ea13f309ef78810f1a2b92f2ae3b30b8",
        "commit_title": "x86: guard against undue super page PTE creation",
        "commit_text": " When optional super page support got added (commit bd1cd81d64 \"x86: PV support for hugepages\"), two adjustments were missed: mod_l2_entry() needs to consider the PSE and RW bits when deciding whether to use the fast path, and the PSE bit must not be removed from L2_DISALLOW_MASK unconditionally.  This is CVE-2015-7835 / XSA-148. ",
        "func_before": "static int mod_l2_entry(l2_pgentry_t *pl2e, \n                        l2_pgentry_t nl2e, \n                        unsigned long pfn,\n                        int preserve_ad,\n                        struct vcpu *vcpu)\n{\n    l2_pgentry_t ol2e;\n    struct domain *d = vcpu->domain;\n    struct page_info *l2pg = mfn_to_page(pfn);\n    unsigned long type = l2pg->u.inuse.type_info;\n    int rc = 0;\n\n    if ( unlikely(!is_guest_l2_slot(d, type, pgentry_ptr_to_slot(pl2e))) )\n    {\n        MEM_LOG(\"Illegal L2 update attempt in Xen-private area %p\", pl2e);\n        return -EPERM;\n    }\n\n    if ( unlikely(__copy_from_user(&ol2e, pl2e, sizeof(ol2e)) != 0) )\n        return -EFAULT;\n\n    if ( l2e_get_flags(nl2e) & _PAGE_PRESENT )\n    {\n        if ( unlikely(l2e_get_flags(nl2e) & L2_DISALLOW_MASK) )\n        {\n            MEM_LOG(\"Bad L2 flags %x\",\n                    l2e_get_flags(nl2e) & L2_DISALLOW_MASK);\n            return -EINVAL;\n        }\n\n        /* Fast path for identical mapping and presence. */\n        if ( !l2e_has_changed(ol2e, nl2e, _PAGE_PRESENT) )\n        {\n            adjust_guest_l2e(nl2e, d);\n            if ( UPDATE_ENTRY(l2, pl2e, ol2e, nl2e, pfn, vcpu, preserve_ad) )\n                return 0;\n            return -EBUSY;\n        }\n\n        if ( unlikely((rc = get_page_from_l2e(nl2e, pfn, d)) < 0) )\n            return rc;\n\n        adjust_guest_l2e(nl2e, d);\n        if ( unlikely(!UPDATE_ENTRY(l2, pl2e, ol2e, nl2e, pfn, vcpu,\n                                    preserve_ad)) )\n        {\n            ol2e = nl2e;\n            rc = -EBUSY;\n        }\n    }\n    else if ( unlikely(!UPDATE_ENTRY(l2, pl2e, ol2e, nl2e, pfn, vcpu,\n                                     preserve_ad)) )\n    {\n        return -EBUSY;\n    }\n\n    put_page_from_l2e(ol2e, pfn);\n    return rc;\n}",
        "func": "static int mod_l2_entry(l2_pgentry_t *pl2e, \n                        l2_pgentry_t nl2e, \n                        unsigned long pfn,\n                        int preserve_ad,\n                        struct vcpu *vcpu)\n{\n    l2_pgentry_t ol2e;\n    struct domain *d = vcpu->domain;\n    struct page_info *l2pg = mfn_to_page(pfn);\n    unsigned long type = l2pg->u.inuse.type_info;\n    int rc = 0;\n\n    if ( unlikely(!is_guest_l2_slot(d, type, pgentry_ptr_to_slot(pl2e))) )\n    {\n        MEM_LOG(\"Illegal L2 update attempt in Xen-private area %p\", pl2e);\n        return -EPERM;\n    }\n\n    if ( unlikely(__copy_from_user(&ol2e, pl2e, sizeof(ol2e)) != 0) )\n        return -EFAULT;\n\n    if ( l2e_get_flags(nl2e) & _PAGE_PRESENT )\n    {\n        if ( unlikely(l2e_get_flags(nl2e) & L2_DISALLOW_MASK) )\n        {\n            MEM_LOG(\"Bad L2 flags %x\",\n                    l2e_get_flags(nl2e) & L2_DISALLOW_MASK);\n            return -EINVAL;\n        }\n\n        /* Fast path for identical mapping and presence. */\n        if ( !l2e_has_changed(ol2e, nl2e,\n                              unlikely(opt_allow_superpage)\n                              ? _PAGE_PSE | _PAGE_RW | _PAGE_PRESENT\n                              : _PAGE_PRESENT) )\n        {\n            adjust_guest_l2e(nl2e, d);\n            if ( UPDATE_ENTRY(l2, pl2e, ol2e, nl2e, pfn, vcpu, preserve_ad) )\n                return 0;\n            return -EBUSY;\n        }\n\n        if ( unlikely((rc = get_page_from_l2e(nl2e, pfn, d)) < 0) )\n            return rc;\n\n        adjust_guest_l2e(nl2e, d);\n        if ( unlikely(!UPDATE_ENTRY(l2, pl2e, ol2e, nl2e, pfn, vcpu,\n                                    preserve_ad)) )\n        {\n            ol2e = nl2e;\n            rc = -EBUSY;\n        }\n    }\n    else if ( unlikely(!UPDATE_ENTRY(l2, pl2e, ol2e, nl2e, pfn, vcpu,\n                                     preserve_ad)) )\n    {\n        return -EBUSY;\n    }\n\n    put_page_from_l2e(ol2e, pfn);\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,7 +29,10 @@\n         }\n \n         /* Fast path for identical mapping and presence. */\n-        if ( !l2e_has_changed(ol2e, nl2e, _PAGE_PRESENT) )\n+        if ( !l2e_has_changed(ol2e, nl2e,\n+                              unlikely(opt_allow_superpage)\n+                              ? _PAGE_PSE | _PAGE_RW | _PAGE_PRESENT\n+                              : _PAGE_PRESENT) )\n         {\n             adjust_guest_l2e(nl2e, d);\n             if ( UPDATE_ENTRY(l2, pl2e, ol2e, nl2e, pfn, vcpu, preserve_ad) )",
        "diff_line_info": {
            "deleted_lines": [
                "        if ( !l2e_has_changed(ol2e, nl2e, _PAGE_PRESENT) )"
            ],
            "added_lines": [
                "        if ( !l2e_has_changed(ol2e, nl2e,",
                "                              unlikely(opt_allow_superpage)",
                "                              ? _PAGE_PSE | _PAGE_RW | _PAGE_PRESENT",
                "                              : _PAGE_PRESENT) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3196",
        "func_name": "chromium/SharedMemory::Create",
        "description": "base/memory/shared_memory_win.cc in Google Chrome before 38.0.2125.101 on Windows does not properly implement read-only restrictions on shared memory, which allows attackers to bypass a sandbox protection mechanism via unspecified vectors.",
        "git_url": "https://github.com/chromium/chromium/commit/6d6797eb60a6626fd48bd9fe92a6598de3a0ea8b",
        "commit_title": "Add DACL and fix test for anonymous read-only memory",
        "commit_text": " TBR=brettw@chromium.org  ",
        "func_before": "bool SharedMemory::Create(const SharedMemoryCreateOptions& options) {\n  // TODO(bsy,sehr): crbug.com/210609 NaCl forces us to round up 64k here,\n  // wasting 32k per mapping on average.\n  static const size_t kSectionMask = 65536 - 1;\n  DCHECK(!options.executable);\n  DCHECK(!mapped_file_);\n  if (options.size == 0)\n    return false;\n\n  // Check maximum accounting for overflow.\n  if (options.size >\n      static_cast<size_t>(std::numeric_limits<int>::max()) - kSectionMask)\n    return false;\n\n  size_t rounded_size = (options.size + kSectionMask) & ~kSectionMask;\n  name_ = ASCIIToWide(options.name_deprecated == NULL ? \"\" :\n                      *options.name_deprecated);\n  if (options.share_read_only && name_.empty()) {\n    // Windows ignores DACLs on certain unnamed objects (like shared sections).\n    // So, we generate a random name when we need to enforce read-only.\n    uint64_t rand_values[4];\n    base::RandBytes(&rand_values, sizeof(rand_values));\n    name_ = base::StringPrintf(L\"CrSharedMem_%016x%016x%016x%016x\",\n                               rand_values[0], rand_values[1],\n                               rand_values[2], rand_values[3]);\n  }\n  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, NULL,\n      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size), name_.c_str());\n  if (!mapped_file_)\n    return false;\n\n  requested_size_ = options.size;\n\n  // Check if the shared memory pre-exists.\n  if (GetLastError() == ERROR_ALREADY_EXISTS) {\n    // If the file already existed, set requested_size_ to 0 to show that\n    // we don't know the size.\n    requested_size_ = 0;\n    if (!options.open_existing_deprecated) {\n      Close();\n      return false;\n    }\n  }\n\n  return true;\n}",
        "func": "bool SharedMemory::Create(const SharedMemoryCreateOptions& options) {\n  // TODO(bsy,sehr): crbug.com/210609 NaCl forces us to round up 64k here,\n  // wasting 32k per mapping on average.\n  static const size_t kSectionMask = 65536 - 1;\n  DCHECK(!options.executable);\n  DCHECK(!mapped_file_);\n  if (options.size == 0)\n    return false;\n\n  // Check maximum accounting for overflow.\n  if (options.size >\n      static_cast<size_t>(std::numeric_limits<int>::max()) - kSectionMask)\n    return false;\n\n  size_t rounded_size = (options.size + kSectionMask) & ~kSectionMask;\n  name_ = ASCIIToWide(options.name_deprecated == NULL ? \"\" :\n                      *options.name_deprecated);\n  SECURITY_ATTRIBUTES sa = { sizeof(sa), NULL, FALSE };\n  SECURITY_DESCRIPTOR sd;\n  ACL dacl;\n\n  if (options.share_read_only && name_.empty()) {\n    // Add an empty DACL to enforce anonymous read-only sections.\n    sa.lpSecurityDescriptor = &sd;\n    if (!InitializeAcl(&dacl, sizeof(dacl), ACL_REVISION))\n      return false;\n    if (!InitializeSecurityDescriptor(&sd, SECURITY_DESCRIPTOR_REVISION))\n      return false;\n    if (!SetSecurityDescriptorDacl(&sd, TRUE, &dacl, FALSE))\n      return false;\n\n    // Windows ignores DACLs on certain unnamed objects (like shared sections).\n    // So, we generate a random name when we need to enforce read-only.\n    uint64_t rand_values[4];\n    base::RandBytes(&rand_values, sizeof(rand_values));\n    name_ = base::StringPrintf(L\"CrSharedMem_%016x%016x%016x%016x\",\n                               rand_values[0], rand_values[1],\n                               rand_values[2], rand_values[3]);\n  }\n  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, &sa,\n      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size), name_.c_str());\n  if (!mapped_file_)\n    return false;\n\n  requested_size_ = options.size;\n\n  // Check if the shared memory pre-exists.\n  if (GetLastError() == ERROR_ALREADY_EXISTS) {\n    // If the file already existed, set requested_size_ to 0 to show that\n    // we don't know the size.\n    requested_size_ = 0;\n    if (!options.open_existing_deprecated) {\n      Close();\n      return false;\n    }\n  }\n\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,20 @@\n   size_t rounded_size = (options.size + kSectionMask) & ~kSectionMask;\n   name_ = ASCIIToWide(options.name_deprecated == NULL ? \"\" :\n                       *options.name_deprecated);\n+  SECURITY_ATTRIBUTES sa = { sizeof(sa), NULL, FALSE };\n+  SECURITY_DESCRIPTOR sd;\n+  ACL dacl;\n+\n   if (options.share_read_only && name_.empty()) {\n+    // Add an empty DACL to enforce anonymous read-only sections.\n+    sa.lpSecurityDescriptor = &sd;\n+    if (!InitializeAcl(&dacl, sizeof(dacl), ACL_REVISION))\n+      return false;\n+    if (!InitializeSecurityDescriptor(&sd, SECURITY_DESCRIPTOR_REVISION))\n+      return false;\n+    if (!SetSecurityDescriptorDacl(&sd, TRUE, &dacl, FALSE))\n+      return false;\n+\n     // Windows ignores DACLs on certain unnamed objects (like shared sections).\n     // So, we generate a random name when we need to enforce read-only.\n     uint64_t rand_values[4];\n@@ -24,7 +37,7 @@\n                                rand_values[0], rand_values[1],\n                                rand_values[2], rand_values[3]);\n   }\n-  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, NULL,\n+  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, &sa,\n       PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size), name_.c_str());\n   if (!mapped_file_)\n     return false;",
        "diff_line_info": {
            "deleted_lines": [
                "  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, NULL,"
            ],
            "added_lines": [
                "  SECURITY_ATTRIBUTES sa = { sizeof(sa), NULL, FALSE };",
                "  SECURITY_DESCRIPTOR sd;",
                "  ACL dacl;",
                "",
                "    // Add an empty DACL to enforce anonymous read-only sections.",
                "    sa.lpSecurityDescriptor = &sd;",
                "    if (!InitializeAcl(&dacl, sizeof(dacl), ACL_REVISION))",
                "      return false;",
                "    if (!InitializeSecurityDescriptor(&sd, SECURITY_DESCRIPTOR_REVISION))",
                "      return false;",
                "    if (!SetSecurityDescriptorDacl(&sd, TRUE, &dacl, FALSE))",
                "      return false;",
                "",
                "  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, &sa,"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3196",
        "func_name": "chromium/SharedMemory::Create",
        "description": "base/memory/shared_memory_win.cc in Google Chrome before 38.0.2125.101 on Windows does not properly implement read-only restrictions on shared memory, which allows attackers to bypass a sandbox protection mechanism via unspecified vectors.",
        "git_url": "https://github.com/chromium/chromium/commit/dc84fcce71f37e6faeab9dce6ae2a65f1e12a5d2",
        "commit_title": "Add a random name to anonymous shared memory sections",
        "commit_text": " This prevents Windows from ignoring the DACL on unnamed sections.   ",
        "func_before": "bool SharedMemory::Create(const SharedMemoryCreateOptions& options) {\n  // TODO(bsy,sehr): crbug.com/210609 NaCl forces us to round up 64k here,\n  // wasting 32k per mapping on average.\n  static const size_t kSectionMask = 65536 - 1;\n  DCHECK(!options.executable);\n  DCHECK(!mapped_file_);\n  if (options.size == 0)\n    return false;\n\n  // Check maximum accounting for overflow.\n  if (options.size >\n      static_cast<size_t>(std::numeric_limits<int>::max()) - kSectionMask)\n    return false;\n\n  size_t rounded_size = (options.size + kSectionMask) & ~kSectionMask;\n  name_ = ASCIIToWide(options.name_deprecated == NULL ? \"\" :\n                          *options.name_deprecated);\n  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, NULL,\n      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size),\n      name_.empty() ? NULL : name_.c_str());\n  if (!mapped_file_)\n    return false;\n\n  requested_size_ = options.size;\n\n  // Check if the shared memory pre-exists.\n  if (GetLastError() == ERROR_ALREADY_EXISTS) {\n    // If the file already existed, set requested_size_ to 0 to show that\n    // we don't know the size.\n    requested_size_ = 0;\n    if (!options.open_existing_deprecated) {\n      Close();\n      return false;\n    }\n  }\n\n  return true;\n}",
        "func": "bool SharedMemory::Create(const SharedMemoryCreateOptions& options) {\n  // TODO(bsy,sehr): crbug.com/210609 NaCl forces us to round up 64k here,\n  // wasting 32k per mapping on average.\n  static const size_t kSectionMask = 65536 - 1;\n  DCHECK(!options.executable);\n  DCHECK(!mapped_file_);\n  if (options.size == 0)\n    return false;\n\n  // Check maximum accounting for overflow.\n  if (options.size >\n      static_cast<size_t>(std::numeric_limits<int>::max()) - kSectionMask)\n    return false;\n\n  size_t rounded_size = (options.size + kSectionMask) & ~kSectionMask;\n  name_ = ASCIIToWide(options.name_deprecated == NULL ? \"\" :\n                      *options.name_deprecated);\n  if (options.share_read_only && name_.empty()) {\n    // Windows ignores DACLs on certain unnamed objects (like shared sections).\n    // So, we generate a random name when we need to enforce read-only.\n    uint64_t rand_values[4];\n    base::RandBytes(&rand_values, sizeof(rand_values));\n    name_ = base::StringPrintf(L\"CrSharedMem_%016x%016x%016x%016x\",\n                               rand_values[0], rand_values[1],\n                               rand_values[2], rand_values[3]);\n  }\n  mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, NULL,\n      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size), name_.c_str());\n  if (!mapped_file_)\n    return false;\n\n  requested_size_ = options.size;\n\n  // Check if the shared memory pre-exists.\n  if (GetLastError() == ERROR_ALREADY_EXISTS) {\n    // If the file already existed, set requested_size_ to 0 to show that\n    // we don't know the size.\n    requested_size_ = 0;\n    if (!options.open_existing_deprecated) {\n      Close();\n      return false;\n    }\n  }\n\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,10 +14,18 @@\n \n   size_t rounded_size = (options.size + kSectionMask) & ~kSectionMask;\n   name_ = ASCIIToWide(options.name_deprecated == NULL ? \"\" :\n-                          *options.name_deprecated);\n+                      *options.name_deprecated);\n+  if (options.share_read_only && name_.empty()) {\n+    // Windows ignores DACLs on certain unnamed objects (like shared sections).\n+    // So, we generate a random name when we need to enforce read-only.\n+    uint64_t rand_values[4];\n+    base::RandBytes(&rand_values, sizeof(rand_values));\n+    name_ = base::StringPrintf(L\"CrSharedMem_%016x%016x%016x%016x\",\n+                               rand_values[0], rand_values[1],\n+                               rand_values[2], rand_values[3]);\n+  }\n   mapped_file_ = CreateFileMapping(INVALID_HANDLE_VALUE, NULL,\n-      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size),\n-      name_.empty() ? NULL : name_.c_str());\n+      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size), name_.c_str());\n   if (!mapped_file_)\n     return false;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "                          *options.name_deprecated);",
                "      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size),",
                "      name_.empty() ? NULL : name_.c_str());"
            ],
            "added_lines": [
                "                      *options.name_deprecated);",
                "  if (options.share_read_only && name_.empty()) {",
                "    // Windows ignores DACLs on certain unnamed objects (like shared sections).",
                "    // So, we generate a random name when we need to enforce read-only.",
                "    uint64_t rand_values[4];",
                "    base::RandBytes(&rand_values, sizeof(rand_values));",
                "    name_ = base::StringPrintf(L\"CrSharedMem_%016x%016x%016x%016x\",",
                "                               rand_values[0], rand_values[1],",
                "                               rand_values[2], rand_values[3]);",
                "  }",
                "      PAGE_READWRITE, 0, static_cast<DWORD>(rounded_size), name_.c_str());"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-3197",
        "func_name": "chromium/NavigationScheduler::schedulePageBlock",
        "description": "The NavigationScheduler::schedulePageBlock function in core/loader/NavigationScheduler.cpp in Blink, as used in Google Chrome before 38.0.2125.101, does not properly provide substitute data for pages blocked by the XSS auditor, which allows remote attackers to obtain sensitive information via a crafted web site.",
        "git_url": "https://github.com/chromium/chromium/commit/3008950ba5115eb45162e0788c39bc67e5196d5d",
        "commit_title": "Implement NavigationScheduler::schedulePageBlock() as a redirect to empty substitute data.",
        "commit_text": " This replaces the long-standing kludge of navigating to \"data:,\" so that we preserve the URL of the page that was blocked. Otherwise, cross-origin detection of the XSSAuditor is possible via a variety of techniques owing to the change in the URL.  We lose the benefit of the unique origin, however. I don't think actually provides any benefit, if only blank content is going into the replacement page. As a consequence, the parent frame will successfully see same-origin content in some of the tests. The cross-origin test remains unmodified,  showing that there aren't new leaks (full-block-script-tag-cross-domain).  The upside is I can remove a lot of logic that was introduced recently to preserve pages for view-source of the blocked page.  The window-open-block-mode test is such an example.  There will be more cleanup possible on the chrome side once this CL lands.   ",
        "func_before": "void NavigationScheduler::schedulePageBlock(Document* originDocument, const Referrer& referrer)\n{\n    ASSERT(m_frame->page());\n    schedule(adoptPtr(new ScheduledLocationChange(originDocument, SecurityOrigin::urlWithUniqueSecurityOrigin(), referrer, false)));\n}",
        "func": "void NavigationScheduler::schedulePageBlock(Document* originDocument, const Referrer& referrer)\n{\n    ASSERT(m_frame->page());\n    const KURL& url = m_frame->document()->url();\n    schedule(adoptPtr(new ScheduledPageBlock(originDocument, url, referrer)));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n void NavigationScheduler::schedulePageBlock(Document* originDocument, const Referrer& referrer)\n {\n     ASSERT(m_frame->page());\n-    schedule(adoptPtr(new ScheduledLocationChange(originDocument, SecurityOrigin::urlWithUniqueSecurityOrigin(), referrer, false)));\n+    const KURL& url = m_frame->document()->url();\n+    schedule(adoptPtr(new ScheduledPageBlock(originDocument, url, referrer)));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    schedule(adoptPtr(new ScheduledLocationChange(originDocument, SecurityOrigin::urlWithUniqueSecurityOrigin(), referrer, false)));"
            ],
            "added_lines": [
                "    const KURL& url = m_frame->document()->url();",
                "    schedule(adoptPtr(new ScheduledPageBlock(originDocument, url, referrer)));"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-2148",
        "func_name": "torvalds/linux/do_utimes",
        "description": "The utimensat system call (sys_utimensat) in Linux kernel 2.6.22 and other versions before 2.6.25.3 does not check file permissions when certain UTIME_NOW and UTIME_OMIT combinations are used, which allows local users to modify file times of arbitrary files, possibly leading to a denial of service.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=f9dfda1ad0637a89a64d001cf81478bd8d9b6306",
        "commit_title": "commit: 02c6be615f1fcd37ac5ed93a3ad6692ad8991cd9 upstream",
        "commit_text": " If utimensat() is called with both times set to UTIME_NOW or one of them to UTIME_NOW and the other to UTIME_OMIT, then it will update the file time without any permission checking.  I don't think this can be used for anything other than a local DoS, but could be quite bewildering at that (e.g.  \"Why was that large source tree rebuilt when I didn't modify anything???\")  This affects all kernels from 2.6.22, when the utimensat() syscall was introduced.  Fix by doing the same permission checking as for the \"times == NULL\" case.  Thanks to Michael Kerrisk, whose utimensat-non-conformances-and-fixes.patch in -mm also fixes this (and breaks other stuff), only he didn't realize the security implications of this bug.  Cc: Ulrich Drepper <drepper@redhat.com> Cc: Michael Kerrisk <mtk-manpages@gmx.net>  ",
        "func_before": "long do_utimes(int dfd, char __user *filename, struct timespec *times, int flags)\n{\n\tint error;\n\tstruct nameidata nd;\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tstruct iattr newattrs;\n\tstruct file *f = NULL;\n\n\terror = -EINVAL;\n\tif (times && (!nsec_valid(times[0].tv_nsec) ||\n\t\t      !nsec_valid(times[1].tv_nsec))) {\n\t\tgoto out;\n\t}\n\n\tif (flags & ~AT_SYMLINK_NOFOLLOW)\n\t\tgoto out;\n\n\tif (filename == NULL && dfd != AT_FDCWD) {\n\t\terror = -EINVAL;\n\t\tif (flags & AT_SYMLINK_NOFOLLOW)\n\t\t\tgoto out;\n\n\t\terror = -EBADF;\n\t\tf = fget(dfd);\n\t\tif (!f)\n\t\t\tgoto out;\n\t\tdentry = f->f_path.dentry;\n\t} else {\n\t\terror = __user_walk_fd(dfd, filename, (flags & AT_SYMLINK_NOFOLLOW) ? 0 : LOOKUP_FOLLOW, &nd);\n\t\tif (error)\n\t\t\tgoto out;\n\n\t\tdentry = nd.path.dentry;\n\t}\n\n\tinode = dentry->d_inode;\n\n\terror = -EROFS;\n\tif (IS_RDONLY(inode))\n\t\tgoto dput_and_out;\n\n\t/* Don't worry, the checks are done in inode_change_ok() */\n\tnewattrs.ia_valid = ATTR_CTIME | ATTR_MTIME | ATTR_ATIME;\n\tif (times) {\n\t\terror = -EPERM;\n                if (IS_APPEND(inode) || IS_IMMUTABLE(inode))\n                        goto dput_and_out;\n\n\t\tif (times[0].tv_nsec == UTIME_OMIT)\n\t\t\tnewattrs.ia_valid &= ~ATTR_ATIME;\n\t\telse if (times[0].tv_nsec != UTIME_NOW) {\n\t\t\tnewattrs.ia_atime.tv_sec = times[0].tv_sec;\n\t\t\tnewattrs.ia_atime.tv_nsec = times[0].tv_nsec;\n\t\t\tnewattrs.ia_valid |= ATTR_ATIME_SET;\n\t\t}\n\n\t\tif (times[1].tv_nsec == UTIME_OMIT)\n\t\t\tnewattrs.ia_valid &= ~ATTR_MTIME;\n\t\telse if (times[1].tv_nsec != UTIME_NOW) {\n\t\t\tnewattrs.ia_mtime.tv_sec = times[1].tv_sec;\n\t\t\tnewattrs.ia_mtime.tv_nsec = times[1].tv_nsec;\n\t\t\tnewattrs.ia_valid |= ATTR_MTIME_SET;\n\t\t}\n\t} else {\n\t\terror = -EACCES;\n                if (IS_IMMUTABLE(inode))\n                        goto dput_and_out;\n\n\t\tif (!is_owner_or_cap(inode)) {\n\t\t\tif (f) {\n\t\t\t\tif (!(f->f_mode & FMODE_WRITE))\n\t\t\t\t\tgoto dput_and_out;\n\t\t\t} else {\n\t\t\t\terror = vfs_permission(&nd, MAY_WRITE);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto dput_and_out;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_lock(&inode->i_mutex);\n\terror = notify_change(dentry, &newattrs);\n\tmutex_unlock(&inode->i_mutex);\ndput_and_out:\n\tif (f)\n\t\tfput(f);\n\telse\n\t\tpath_put(&nd.path);\nout:\n\treturn error;\n}",
        "func": "long do_utimes(int dfd, char __user *filename, struct timespec *times, int flags)\n{\n\tint error;\n\tstruct nameidata nd;\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tstruct iattr newattrs;\n\tstruct file *f = NULL;\n\n\terror = -EINVAL;\n\tif (times && (!nsec_valid(times[0].tv_nsec) ||\n\t\t      !nsec_valid(times[1].tv_nsec))) {\n\t\tgoto out;\n\t}\n\n\tif (flags & ~AT_SYMLINK_NOFOLLOW)\n\t\tgoto out;\n\n\tif (filename == NULL && dfd != AT_FDCWD) {\n\t\terror = -EINVAL;\n\t\tif (flags & AT_SYMLINK_NOFOLLOW)\n\t\t\tgoto out;\n\n\t\terror = -EBADF;\n\t\tf = fget(dfd);\n\t\tif (!f)\n\t\t\tgoto out;\n\t\tdentry = f->f_path.dentry;\n\t} else {\n\t\terror = __user_walk_fd(dfd, filename, (flags & AT_SYMLINK_NOFOLLOW) ? 0 : LOOKUP_FOLLOW, &nd);\n\t\tif (error)\n\t\t\tgoto out;\n\n\t\tdentry = nd.path.dentry;\n\t}\n\n\tinode = dentry->d_inode;\n\n\terror = -EROFS;\n\tif (IS_RDONLY(inode))\n\t\tgoto dput_and_out;\n\n\t/* Don't worry, the checks are done in inode_change_ok() */\n\tnewattrs.ia_valid = ATTR_CTIME | ATTR_MTIME | ATTR_ATIME;\n\tif (times) {\n\t\terror = -EPERM;\n                if (IS_APPEND(inode) || IS_IMMUTABLE(inode))\n                        goto dput_and_out;\n\n\t\tif (times[0].tv_nsec == UTIME_OMIT)\n\t\t\tnewattrs.ia_valid &= ~ATTR_ATIME;\n\t\telse if (times[0].tv_nsec != UTIME_NOW) {\n\t\t\tnewattrs.ia_atime.tv_sec = times[0].tv_sec;\n\t\t\tnewattrs.ia_atime.tv_nsec = times[0].tv_nsec;\n\t\t\tnewattrs.ia_valid |= ATTR_ATIME_SET;\n\t\t}\n\n\t\tif (times[1].tv_nsec == UTIME_OMIT)\n\t\t\tnewattrs.ia_valid &= ~ATTR_MTIME;\n\t\telse if (times[1].tv_nsec != UTIME_NOW) {\n\t\t\tnewattrs.ia_mtime.tv_sec = times[1].tv_sec;\n\t\t\tnewattrs.ia_mtime.tv_nsec = times[1].tv_nsec;\n\t\t\tnewattrs.ia_valid |= ATTR_MTIME_SET;\n\t\t}\n\t}\n\n\t/*\n\t * If times is NULL or both times are either UTIME_OMIT or\n\t * UTIME_NOW, then need to check permissions, because\n\t * inode_change_ok() won't do it.\n\t */\n\tif (!times || (nsec_special(times[0].tv_nsec) &&\n\t\t       nsec_special(times[1].tv_nsec))) {\n\t\terror = -EACCES;\n                if (IS_IMMUTABLE(inode))\n                        goto dput_and_out;\n\n\t\tif (!is_owner_or_cap(inode)) {\n\t\t\tif (f) {\n\t\t\t\tif (!(f->f_mode & FMODE_WRITE))\n\t\t\t\t\tgoto dput_and_out;\n\t\t\t} else {\n\t\t\t\terror = vfs_permission(&nd, MAY_WRITE);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto dput_and_out;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_lock(&inode->i_mutex);\n\terror = notify_change(dentry, &newattrs);\n\tmutex_unlock(&inode->i_mutex);\ndput_and_out:\n\tif (f)\n\t\tfput(f);\n\telse\n\t\tpath_put(&nd.path);\nout:\n\treturn error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -62,7 +62,15 @@\n \t\t\tnewattrs.ia_mtime.tv_nsec = times[1].tv_nsec;\n \t\t\tnewattrs.ia_valid |= ATTR_MTIME_SET;\n \t\t}\n-\t} else {\n+\t}\n+\n+\t/*\n+\t * If times is NULL or both times are either UTIME_OMIT or\n+\t * UTIME_NOW, then need to check permissions, because\n+\t * inode_change_ok() won't do it.\n+\t */\n+\tif (!times || (nsec_special(times[0].tv_nsec) &&\n+\t\t       nsec_special(times[1].tv_nsec))) {\n \t\terror = -EACCES;\n                 if (IS_IMMUTABLE(inode))\n                         goto dput_and_out;",
        "diff_line_info": {
            "deleted_lines": [
                "\t} else {"
            ],
            "added_lines": [
                "\t}",
                "",
                "\t/*",
                "\t * If times is NULL or both times are either UTIME_OMIT or",
                "\t * UTIME_NOW, then need to check permissions, because",
                "\t * inode_change_ok() won't do it.",
                "\t */",
                "\tif (!times || (nsec_special(times[0].tv_nsec) &&",
                "\t\t       nsec_special(times[1].tv_nsec))) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-2148",
        "func_name": "torvalds/linux/nsec_valid",
        "description": "The utimensat system call (sys_utimensat) in Linux kernel 2.6.22 and other versions before 2.6.25.3 does not check file permissions when certain UTIME_NOW and UTIME_OMIT combinations are used, which allows local users to modify file times of arbitrary files, possibly leading to a denial of service.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=f9dfda1ad0637a89a64d001cf81478bd8d9b6306",
        "commit_title": "commit: 02c6be615f1fcd37ac5ed93a3ad6692ad8991cd9 upstream",
        "commit_text": " If utimensat() is called with both times set to UTIME_NOW or one of them to UTIME_NOW and the other to UTIME_OMIT, then it will update the file time without any permission checking.  I don't think this can be used for anything other than a local DoS, but could be quite bewildering at that (e.g.  \"Why was that large source tree rebuilt when I didn't modify anything???\")  This affects all kernels from 2.6.22, when the utimensat() syscall was introduced.  Fix by doing the same permission checking as for the \"times == NULL\" case.  Thanks to Michael Kerrisk, whose utimensat-non-conformances-and-fixes.patch in -mm also fixes this (and breaks other stuff), only he didn't realize the security implications of this bug.  Cc: Ulrich Drepper <drepper@redhat.com> Cc: Michael Kerrisk <mtk-manpages@gmx.net>  ",
        "func_before": "static bool nsec_valid(long nsec)\n{\n\tif (nsec == UTIME_OMIT || nsec == UTIME_NOW)\n\t\treturn true;\n\n\treturn nsec >= 0 && nsec <= 999999999;\n}",
        "func": "static bool nsec_valid(long nsec)\n{\n\tif (nsec_special(nsec))\n\t\treturn true;\n\n\treturn nsec >= 0 && nsec <= 999999999;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n static bool nsec_valid(long nsec)\n {\n-\tif (nsec == UTIME_OMIT || nsec == UTIME_NOW)\n+\tif (nsec_special(nsec))\n \t\treturn true;\n \n \treturn nsec >= 0 && nsec <= 999999999;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (nsec == UTIME_OMIT || nsec == UTIME_NOW)"
            ],
            "added_lines": [
                "\tif (nsec_special(nsec))"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-3525",
        "func_name": "torvalds/linux/sbni_ioctl",
        "description": "The sbni_ioctl function in drivers/net/wan/sbni.c in the wan subsystem in the Linux kernel 2.6.26.3 does not check for the CAP_NET_ADMIN capability before processing a (1) SIOCDEVRESINSTATS, (2) SIOCDEVSHWSTATE, (3) SIOCDEVENSLAVE, or (4) SIOCDEVEMANSIPATE ioctl request, which allows local users to bypass intended capability restrictions.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=f2455eb176ac87081bbfc9a44b21c7cd2bc1967e",
        "commit_title": "There are missing capability checks in the following code:",
        "commit_text": " 1300 static int 1301 sbni_ioctl( struct net_device  *dev,  struct ifreq  *ifr,  int  cmd) 1302 { [...] 1319     case  SIOCDEVRESINSTATS : 1320         if( current->euid != 0 )    /* root only */ 1321             return  -EPERM; [...] 1336     case  SIOCDEVSHWSTATE : 1337         if( current->euid != 0 )    /* root only */ 1338             return  -EPERM; [...] 1357     case  SIOCDEVENSLAVE : 1358         if( current->euid != 0 )    /* root only */ 1359             return  -EPERM; [...] 1372     case  SIOCDEVEMANSIPATE : 1373         if( current->euid != 0 )    /* root only */ 1374             return  -EPERM;  Here's my proposed fix:  Missing capability checks.  ",
        "func_before": "static int\nsbni_ioctl( struct net_device  *dev,  struct ifreq  *ifr,  int  cmd )\n{\n\tstruct net_local  *nl = (struct net_local *) dev->priv; \n\tstruct sbni_flags  flags;\n\tint  error = 0;\n\n#ifdef CONFIG_SBNI_MULTILINE\n\tstruct net_device  *slave_dev;\n\tchar  slave_name[ 8 ];\n#endif\n  \n\tswitch( cmd ) {\n\tcase  SIOCDEVGETINSTATS :\n\t\tif (copy_to_user( ifr->ifr_data, &nl->in_stats,\n\t\t\t\t\tsizeof(struct sbni_in_stats) ))\n\t\t\terror = -EFAULT;\n\t\tbreak;\n\n\tcase  SIOCDEVRESINSTATS :\n\t\tif( current->euid != 0 )\t/* root only */\n\t\t\treturn  -EPERM;\n\t\tmemset( &nl->in_stats, 0, sizeof(struct sbni_in_stats) );\n\t\tbreak;\n\n\tcase  SIOCDEVGHWSTATE :\n\t\tflags.mac_addr\t= *(u32 *)(dev->dev_addr + 3);\n\t\tflags.rate\t= nl->csr1.rate;\n\t\tflags.slow_mode\t= (nl->state & FL_SLOW_MODE) != 0;\n\t\tflags.rxl\t= nl->cur_rxl_index;\n\t\tflags.fixed_rxl\t= nl->delta_rxl == 0;\n\n\t\tif (copy_to_user( ifr->ifr_data, &flags, sizeof flags ))\n\t\t\terror = -EFAULT;\n\t\tbreak;\n\n\tcase  SIOCDEVSHWSTATE :\n\t\tif( current->euid != 0 )\t/* root only */\n\t\t\treturn  -EPERM;\n\n\t\tspin_lock( &nl->lock );\n\t\tflags = *(struct sbni_flags*) &ifr->ifr_ifru;\n\t\tif( flags.fixed_rxl )\n\t\t\tnl->delta_rxl = 0,\n\t\t\tnl->cur_rxl_index = flags.rxl;\n\t\telse\n\t\t\tnl->delta_rxl = DEF_RXL_DELTA,\n\t\t\tnl->cur_rxl_index = DEF_RXL;\n\n\t\tnl->csr1.rxl = rxl_tab[ nl->cur_rxl_index ];\n\t\tnl->csr1.rate = flags.rate;\n\t\toutb( *(u8 *)&nl->csr1 | PR_RES, dev->base_addr + CSR1 );\n\t\tspin_unlock( &nl->lock );\n\t\tbreak;\n\n#ifdef CONFIG_SBNI_MULTILINE\n\n\tcase  SIOCDEVENSLAVE :\n\t\tif( current->euid != 0 )\t/* root only */\n\t\t\treturn  -EPERM;\n\n\t\tif (copy_from_user( slave_name, ifr->ifr_data, sizeof slave_name ))\n\t\t\treturn -EFAULT;\n\t\tslave_dev = dev_get_by_name(&init_net, slave_name );\n\t\tif( !slave_dev  ||  !(slave_dev->flags & IFF_UP) ) {\n\t\t\tprintk( KERN_ERR \"%s: trying to enslave non-active \"\n\t\t\t\t\"device %s\\n\", dev->name, slave_name );\n\t\t\treturn  -EPERM;\n\t\t}\n\n\t\treturn  enslave( dev, slave_dev );\n\n\tcase  SIOCDEVEMANSIPATE :\n\t\tif( current->euid != 0 )\t/* root only */\n\t\t\treturn  -EPERM;\n\n\t\treturn  emancipate( dev );\n\n#endif\t/* CONFIG_SBNI_MULTILINE */\n\n\tdefault :\n\t\treturn  -EOPNOTSUPP;\n\t}\n\n\treturn  error;\n}",
        "func": "static int\nsbni_ioctl( struct net_device  *dev,  struct ifreq  *ifr,  int  cmd )\n{\n\tstruct net_local  *nl = (struct net_local *) dev->priv; \n\tstruct sbni_flags  flags;\n\tint  error = 0;\n\n#ifdef CONFIG_SBNI_MULTILINE\n\tstruct net_device  *slave_dev;\n\tchar  slave_name[ 8 ];\n#endif\n  \n\tswitch( cmd ) {\n\tcase  SIOCDEVGETINSTATS :\n\t\tif (copy_to_user( ifr->ifr_data, &nl->in_stats,\n\t\t\t\t\tsizeof(struct sbni_in_stats) ))\n\t\t\terror = -EFAULT;\n\t\tbreak;\n\n\tcase  SIOCDEVRESINSTATS :\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn  -EPERM;\n\t\tmemset( &nl->in_stats, 0, sizeof(struct sbni_in_stats) );\n\t\tbreak;\n\n\tcase  SIOCDEVGHWSTATE :\n\t\tflags.mac_addr\t= *(u32 *)(dev->dev_addr + 3);\n\t\tflags.rate\t= nl->csr1.rate;\n\t\tflags.slow_mode\t= (nl->state & FL_SLOW_MODE) != 0;\n\t\tflags.rxl\t= nl->cur_rxl_index;\n\t\tflags.fixed_rxl\t= nl->delta_rxl == 0;\n\n\t\tif (copy_to_user( ifr->ifr_data, &flags, sizeof flags ))\n\t\t\terror = -EFAULT;\n\t\tbreak;\n\n\tcase  SIOCDEVSHWSTATE :\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn  -EPERM;\n\n\t\tspin_lock( &nl->lock );\n\t\tflags = *(struct sbni_flags*) &ifr->ifr_ifru;\n\t\tif( flags.fixed_rxl )\n\t\t\tnl->delta_rxl = 0,\n\t\t\tnl->cur_rxl_index = flags.rxl;\n\t\telse\n\t\t\tnl->delta_rxl = DEF_RXL_DELTA,\n\t\t\tnl->cur_rxl_index = DEF_RXL;\n\n\t\tnl->csr1.rxl = rxl_tab[ nl->cur_rxl_index ];\n\t\tnl->csr1.rate = flags.rate;\n\t\toutb( *(u8 *)&nl->csr1 | PR_RES, dev->base_addr + CSR1 );\n\t\tspin_unlock( &nl->lock );\n\t\tbreak;\n\n#ifdef CONFIG_SBNI_MULTILINE\n\n\tcase  SIOCDEVENSLAVE :\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn  -EPERM;\n\n\t\tif (copy_from_user( slave_name, ifr->ifr_data, sizeof slave_name ))\n\t\t\treturn -EFAULT;\n\t\tslave_dev = dev_get_by_name(&init_net, slave_name );\n\t\tif( !slave_dev  ||  !(slave_dev->flags & IFF_UP) ) {\n\t\t\tprintk( KERN_ERR \"%s: trying to enslave non-active \"\n\t\t\t\t\"device %s\\n\", dev->name, slave_name );\n\t\t\treturn  -EPERM;\n\t\t}\n\n\t\treturn  enslave( dev, slave_dev );\n\n\tcase  SIOCDEVEMANSIPATE :\n\t\tif (!capable(CAP_NET_ADMIN))\n\t\t\treturn  -EPERM;\n\n\t\treturn  emancipate( dev );\n\n#endif\t/* CONFIG_SBNI_MULTILINE */\n\n\tdefault :\n\t\treturn  -EOPNOTSUPP;\n\t}\n\n\treturn  error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,7 @@\n \t\tbreak;\n \n \tcase  SIOCDEVRESINSTATS :\n-\t\tif( current->euid != 0 )\t/* root only */\n+\t\tif (!capable(CAP_NET_ADMIN))\n \t\t\treturn  -EPERM;\n \t\tmemset( &nl->in_stats, 0, sizeof(struct sbni_in_stats) );\n \t\tbreak;\n@@ -35,7 +35,7 @@\n \t\tbreak;\n \n \tcase  SIOCDEVSHWSTATE :\n-\t\tif( current->euid != 0 )\t/* root only */\n+\t\tif (!capable(CAP_NET_ADMIN))\n \t\t\treturn  -EPERM;\n \n \t\tspin_lock( &nl->lock );\n@@ -56,7 +56,7 @@\n #ifdef CONFIG_SBNI_MULTILINE\n \n \tcase  SIOCDEVENSLAVE :\n-\t\tif( current->euid != 0 )\t/* root only */\n+\t\tif (!capable(CAP_NET_ADMIN))\n \t\t\treturn  -EPERM;\n \n \t\tif (copy_from_user( slave_name, ifr->ifr_data, sizeof slave_name ))\n@@ -71,7 +71,7 @@\n \t\treturn  enslave( dev, slave_dev );\n \n \tcase  SIOCDEVEMANSIPATE :\n-\t\tif( current->euid != 0 )\t/* root only */\n+\t\tif (!capable(CAP_NET_ADMIN))\n \t\t\treturn  -EPERM;\n \n \t\treturn  emancipate( dev );",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif( current->euid != 0 )\t/* root only */",
                "\t\tif( current->euid != 0 )\t/* root only */",
                "\t\tif( current->euid != 0 )\t/* root only */",
                "\t\tif( current->euid != 0 )\t/* root only */"
            ],
            "added_lines": [
                "\t\tif (!capable(CAP_NET_ADMIN))",
                "\t\tif (!capable(CAP_NET_ADMIN))",
                "\t\tif (!capable(CAP_NET_ADMIN))",
                "\t\tif (!capable(CAP_NET_ADMIN))"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-4210",
        "func_name": "torvalds/linux/do_truncate",
        "description": "fs/open.c in the Linux kernel before 2.6.22 does not properly strip setuid and setgid bits when there is a write to a file, which allows local users to gain the privileges of a different group, and obtain sensitive information or possibly have unspecified other impact, by creating an executable file in a setgid directory through the (1) truncate or (2) ftruncate function in conjunction with memory-mapped I/O.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=7b82dc0e64e93f430182f36b46b79fcee87d3532",
        "commit_title": ".. to match what we do on write().  This way, people who write to files",
        "commit_text": "by using [f]truncate + writable mmap have the same semantics as if they were using the write() family of system calls.  ",
        "func_before": "int do_truncate(struct dentry *dentry, loff_t length, unsigned int time_attrs,\n\tstruct file *filp)\n{\n\tint err;\n\tstruct iattr newattrs;\n\n\t/* Not pretty: \"inode->i_size\" shouldn't really be signed. But it is. */\n\tif (length < 0)\n\t\treturn -EINVAL;\n\n\tnewattrs.ia_size = length;\n\tnewattrs.ia_valid = ATTR_SIZE | time_attrs;\n\tif (filp) {\n\t\tnewattrs.ia_file = filp;\n\t\tnewattrs.ia_valid |= ATTR_FILE;\n\t}\n\n\tmutex_lock(&dentry->d_inode->i_mutex);\n\terr = notify_change(dentry, &newattrs);\n\tmutex_unlock(&dentry->d_inode->i_mutex);\n\treturn err;\n}",
        "func": "int do_truncate(struct dentry *dentry, loff_t length, unsigned int time_attrs,\n\tstruct file *filp)\n{\n\tint err;\n\tstruct iattr newattrs;\n\n\t/* Not pretty: \"inode->i_size\" shouldn't really be signed. But it is. */\n\tif (length < 0)\n\t\treturn -EINVAL;\n\n\tnewattrs.ia_size = length;\n\tnewattrs.ia_valid = ATTR_SIZE | time_attrs;\n\tif (filp) {\n\t\tnewattrs.ia_file = filp;\n\t\tnewattrs.ia_valid |= ATTR_FILE;\n\t}\n\n\t/* Remove suid/sgid on truncate too */\n\tnewattrs.ia_valid |= should_remove_suid(dentry);\n\n\tmutex_lock(&dentry->d_inode->i_mutex);\n\terr = notify_change(dentry, &newattrs);\n\tmutex_unlock(&dentry->d_inode->i_mutex);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,6 +15,9 @@\n \t\tnewattrs.ia_valid |= ATTR_FILE;\n \t}\n \n+\t/* Remove suid/sgid on truncate too */\n+\tnewattrs.ia_valid |= should_remove_suid(dentry);\n+\n \tmutex_lock(&dentry->d_inode->i_mutex);\n \terr = notify_change(dentry, &newattrs);\n \tmutex_unlock(&dentry->d_inode->i_mutex);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t/* Remove suid/sgid on truncate too */",
                "\tnewattrs.ia_valid |= should_remove_suid(dentry);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-3833",
        "func_name": "torvalds/linux/generic_file_splice_write_nolock",
        "description": "The generic_file_splice_write function in fs/splice.c in the Linux kernel before 2.6.19 does not properly strip setuid and setgid bits when there is a write to a file, which allows local users to gain the privileges of a different group, and obtain sensitive information or possibly have unspecified other impact, by splicing into an inode in order to create an executable file in a setgid directory, a different vulnerability than CVE-2008-4210.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=8c34e2d63231d4bf4852bac8521883944d770fe3",
        "commit_title": "Originally from Mark Fasheh <mark.fasheh@oracle.com>",
        "commit_text": " generic_file_splice_write() does not remove S_ISUID or S_ISGID. This is inconsistent with the way we generally write to files.  ",
        "func_before": "ssize_t\ngeneric_file_splice_write_nolock(struct pipe_inode_info *pipe, struct file *out,\n\t\t\t\t loff_t *ppos, size_t len, unsigned int flags)\n{\n\tstruct address_space *mapping = out->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tssize_t ret;\n\tint err;\n\n\tret = __splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n\tif (ret > 0) {\n\t\t*ppos += ret;\n\n\t\t/*\n\t\t * If file or inode is SYNC and we actually wrote some data,\n\t\t * sync it.\n\t\t */\n\t\tif (unlikely((out->f_flags & O_SYNC) || IS_SYNC(inode))) {\n\t\t\terr = generic_osync_inode(inode, mapping,\n\t\t\t\t\t\t  OSYNC_METADATA|OSYNC_DATA);\n\n\t\t\tif (err)\n\t\t\t\tret = err;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "func": "ssize_t\ngeneric_file_splice_write_nolock(struct pipe_inode_info *pipe, struct file *out,\n\t\t\t\t loff_t *ppos, size_t len, unsigned int flags)\n{\n\tstruct address_space *mapping = out->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tssize_t ret;\n\tint err;\n\n\terr = remove_suid(out->f_dentry);\n\tif (unlikely(err))\n\t\treturn err;\n\n\tret = __splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n\tif (ret > 0) {\n\t\t*ppos += ret;\n\n\t\t/*\n\t\t * If file or inode is SYNC and we actually wrote some data,\n\t\t * sync it.\n\t\t */\n\t\tif (unlikely((out->f_flags & O_SYNC) || IS_SYNC(inode))) {\n\t\t\terr = generic_osync_inode(inode, mapping,\n\t\t\t\t\t\t  OSYNC_METADATA|OSYNC_DATA);\n\n\t\t\tif (err)\n\t\t\t\tret = err;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,10 @@\n \tstruct inode *inode = mapping->host;\n \tssize_t ret;\n \tint err;\n+\n+\terr = remove_suid(out->f_dentry);\n+\tif (unlikely(err))\n+\t\treturn err;\n \n \tret = __splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n \tif (ret > 0) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\terr = remove_suid(out->f_dentry);",
                "\tif (unlikely(err))",
                "\t\treturn err;"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-3833",
        "func_name": "torvalds/linux/generic_file_splice_write",
        "description": "The generic_file_splice_write function in fs/splice.c in the Linux kernel before 2.6.19 does not properly strip setuid and setgid bits when there is a write to a file, which allows local users to gain the privileges of a different group, and obtain sensitive information or possibly have unspecified other impact, by splicing into an inode in order to create an executable file in a setgid directory, a different vulnerability than CVE-2008-4210.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=8c34e2d63231d4bf4852bac8521883944d770fe3",
        "commit_title": "Originally from Mark Fasheh <mark.fasheh@oracle.com>",
        "commit_text": " generic_file_splice_write() does not remove S_ISUID or S_ISGID. This is inconsistent with the way we generally write to files.  ",
        "func_before": "ssize_t\ngeneric_file_splice_write(struct pipe_inode_info *pipe, struct file *out,\n\t\t\t  loff_t *ppos, size_t len, unsigned int flags)\n{\n\tstruct address_space *mapping = out->f_mapping;\n\tssize_t ret;\n\n\tret = splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n\tif (ret > 0) {\n\t\tstruct inode *inode = mapping->host;\n\n\t\t*ppos += ret;\n\n\t\t/*\n\t\t * If file or inode is SYNC and we actually wrote some data,\n\t\t * sync it.\n\t\t */\n\t\tif (unlikely((out->f_flags & O_SYNC) || IS_SYNC(inode))) {\n\t\t\tint err;\n\n\t\t\tmutex_lock(&inode->i_mutex);\n\t\t\terr = generic_osync_inode(inode, mapping,\n\t\t\t\t\t\t  OSYNC_METADATA|OSYNC_DATA);\n\t\t\tmutex_unlock(&inode->i_mutex);\n\n\t\t\tif (err)\n\t\t\t\tret = err;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "func": "ssize_t\ngeneric_file_splice_write(struct pipe_inode_info *pipe, struct file *out,\n\t\t\t  loff_t *ppos, size_t len, unsigned int flags)\n{\n\tstruct address_space *mapping = out->f_mapping;\n\tstruct inode *inode = mapping->host;\n\tssize_t ret;\n\tint err;\n\n\terr = should_remove_suid(out->f_dentry);\n\tif (unlikely(err)) {\n\t\tmutex_lock(&inode->i_mutex);\n\t\terr = __remove_suid(out->f_dentry, err);\n\t\tmutex_unlock(&inode->i_mutex);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tret = splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n\tif (ret > 0) {\n\t\t*ppos += ret;\n\n\t\t/*\n\t\t * If file or inode is SYNC and we actually wrote some data,\n\t\t * sync it.\n\t\t */\n\t\tif (unlikely((out->f_flags & O_SYNC) || IS_SYNC(inode))) {\n\t\t\tmutex_lock(&inode->i_mutex);\n\t\t\terr = generic_osync_inode(inode, mapping,\n\t\t\t\t\t\t  OSYNC_METADATA|OSYNC_DATA);\n\t\t\tmutex_unlock(&inode->i_mutex);\n\n\t\t\tif (err)\n\t\t\t\tret = err;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,12 +3,21 @@\n \t\t\t  loff_t *ppos, size_t len, unsigned int flags)\n {\n \tstruct address_space *mapping = out->f_mapping;\n+\tstruct inode *inode = mapping->host;\n \tssize_t ret;\n+\tint err;\n+\n+\terr = should_remove_suid(out->f_dentry);\n+\tif (unlikely(err)) {\n+\t\tmutex_lock(&inode->i_mutex);\n+\t\terr = __remove_suid(out->f_dentry, err);\n+\t\tmutex_unlock(&inode->i_mutex);\n+\t\tif (err)\n+\t\t\treturn err;\n+\t}\n \n \tret = splice_from_pipe(pipe, out, ppos, len, flags, pipe_to_file);\n \tif (ret > 0) {\n-\t\tstruct inode *inode = mapping->host;\n-\n \t\t*ppos += ret;\n \n \t\t/*\n@@ -16,8 +25,6 @@\n \t\t * sync it.\n \t\t */\n \t\tif (unlikely((out->f_flags & O_SYNC) || IS_SYNC(inode))) {\n-\t\t\tint err;\n-\n \t\t\tmutex_lock(&inode->i_mutex);\n \t\t\terr = generic_osync_inode(inode, mapping,\n \t\t\t\t\t\t  OSYNC_METADATA|OSYNC_DATA);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tstruct inode *inode = mapping->host;",
                "",
                "\t\t\tint err;",
                ""
            ],
            "added_lines": [
                "\tstruct inode *inode = mapping->host;",
                "\tint err;",
                "",
                "\terr = should_remove_suid(out->f_dentry);",
                "\tif (unlikely(err)) {",
                "\t\tmutex_lock(&inode->i_mutex);",
                "\t\terr = __remove_suid(out->f_dentry, err);",
                "\t\tmutex_unlock(&inode->i_mutex);",
                "\t\tif (err)",
                "\t\t\treturn err;",
                "\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-4554",
        "func_name": "torvalds/linux/do_splice_from",
        "description": "The do_splice_from function in fs/splice.c in the Linux kernel before 2.6.27 does not reject file descriptors that have the O_APPEND flag set, which allows local users to bypass append mode and make arbitrary changes to other locations in the file.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=efc968d450e013049a662d22727cf132618dcb2f",
        "commit_title": "This is debatable, but while we're debating it, let's disallow the",
        "commit_text": "combination of splice and an O_APPEND destination.  It's not entirely clear what the semantics of O_APPEND should be, and POSIX apparently expects pwrite() to ignore O_APPEND, for example.  So we could make up any semantics we want, including the old ones.  But Miklos convinced me that we should at least give it some thought, and that accepting writes at arbitrary offsets is wrong at least for IS_APPEND() files (which always have O_APPEND set, even if the reverse isn't true: you can obviously have O_APPEND set on a regular file).  So disallow O_APPEND entirely for now.  I doubt anybody cares, and this way we have one less gray area to worry about.  Reported-and-argued-for-by: Miklos Szeredi <miklos@szeredi.hu> ",
        "func_before": "static long do_splice_from(struct pipe_inode_info *pipe, struct file *out,\n\t\t\t   loff_t *ppos, size_t len, unsigned int flags)\n{\n\tint ret;\n\n\tif (unlikely(!out->f_op || !out->f_op->splice_write))\n\t\treturn -EINVAL;\n\n\tif (unlikely(!(out->f_mode & FMODE_WRITE)))\n\t\treturn -EBADF;\n\n\tret = rw_verify_area(WRITE, out, ppos, len);\n\tif (unlikely(ret < 0))\n\t\treturn ret;\n\n\treturn out->f_op->splice_write(pipe, out, ppos, len, flags);\n}",
        "func": "static long do_splice_from(struct pipe_inode_info *pipe, struct file *out,\n\t\t\t   loff_t *ppos, size_t len, unsigned int flags)\n{\n\tint ret;\n\n\tif (unlikely(!out->f_op || !out->f_op->splice_write))\n\t\treturn -EINVAL;\n\n\tif (unlikely(!(out->f_mode & FMODE_WRITE)))\n\t\treturn -EBADF;\n\n\tif (unlikely(out->f_flags & O_APPEND))\n\t\treturn -EINVAL;\n\n\tret = rw_verify_area(WRITE, out, ppos, len);\n\tif (unlikely(ret < 0))\n\t\treturn ret;\n\n\treturn out->f_op->splice_write(pipe, out, ppos, len, flags);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,6 +9,9 @@\n \tif (unlikely(!(out->f_mode & FMODE_WRITE)))\n \t\treturn -EBADF;\n \n+\tif (unlikely(out->f_flags & O_APPEND))\n+\t\treturn -EINVAL;\n+\n \tret = rw_verify_area(WRITE, out, ppos, len);\n \tif (unlikely(ret < 0))\n \t\treturn ret;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (unlikely(out->f_flags & O_APPEND))",
                "\t\treturn -EINVAL;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2008-3527",
        "func_name": "torvalds/linux/arch_setup_additional_pages",
        "description": "arch/i386/kernel/sysenter.c in the Virtual Dynamic Shared Objects (vDSO) implementation in the Linux kernel before 2.6.21 does not properly check boundaries, which allows local users to gain privileges or cause a denial of service via unspecified vectors, related to the install_special_mapping, syscall, and syscall32_nopage functions.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7d91d531900bfa1165d445390b3b13a8013f98f7",
        "commit_title": "This patch uses install_special_mapping for the i386 vDSO setup, consolidating",
        "commit_text": "duplicated code.  Cc: Ingo Molnar <mingo@elte.hu> Cc: Paul Mackerras <paulus@samba.org> Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org> Cc: Andi Kleen <ak@suse.de> ",
        "func_before": "int arch_setup_additional_pages(struct linux_binprm *bprm, int exstack)\n{\n\tstruct vm_area_struct *vma;\n\tstruct mm_struct *mm = current->mm;\n\tunsigned long addr;\n\tint ret;\n\n\tdown_write(&mm->mmap_sem);\n\taddr = get_unmapped_area(NULL, 0, PAGE_SIZE, 0, 0);\n\tif (IS_ERR_VALUE(addr)) {\n\t\tret = addr;\n\t\tgoto up_fail;\n\t}\n\n\tvma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);\n\tif (!vma) {\n\t\tret = -ENOMEM;\n\t\tgoto up_fail;\n\t}\n\n\tvma->vm_start = addr;\n\tvma->vm_end = addr + PAGE_SIZE;\n\t/* MAYWRITE to allow gdb to COW and set breakpoints */\n\tvma->vm_flags = VM_READ|VM_EXEC|VM_MAYREAD|VM_MAYEXEC|VM_MAYWRITE;\n\t/*\n\t * Make sure the vDSO gets into every core dump.\n\t * Dumping its contents makes post-mortem fully interpretable later\n\t * without matching up the same kernel and hardware config to see\n\t * what PC values meant.\n\t */\n\tvma->vm_flags |= VM_ALWAYSDUMP;\n\tvma->vm_flags |= mm->def_flags;\n\tvma->vm_page_prot = protection_map[vma->vm_flags & 7];\n\tvma->vm_ops = &syscall_vm_ops;\n\tvma->vm_mm = mm;\n\n\tret = insert_vm_struct(mm, vma);\n\tif (unlikely(ret)) {\n\t\tkmem_cache_free(vm_area_cachep, vma);\n\t\tgoto up_fail;\n\t}\n\n\tcurrent->mm->context.vdso = (void *)addr;\n\tcurrent_thread_info()->sysenter_return =\n\t\t\t\t    (void *)VDSO_SYM(&SYSENTER_RETURN);\n\tmm->total_vm++;\nup_fail:\n\tup_write(&mm->mmap_sem);\n\treturn ret;\n}",
        "func": "int arch_setup_additional_pages(struct linux_binprm *bprm, int exstack)\n{\n\tstruct mm_struct *mm = current->mm;\n\tunsigned long addr;\n\tint ret;\n\n\tdown_write(&mm->mmap_sem);\n\taddr = get_unmapped_area(NULL, 0, PAGE_SIZE, 0, 0);\n\tif (IS_ERR_VALUE(addr)) {\n\t\tret = addr;\n\t\tgoto up_fail;\n\t}\n\n\t/*\n\t * MAYWRITE to allow gdb to COW and set breakpoints\n\t *\n\t * Make sure the vDSO gets into every core dump.\n\t * Dumping its contents makes post-mortem fully interpretable later\n\t * without matching up the same kernel and hardware config to see\n\t * what PC values meant.\n\t */\n\tret = install_special_mapping(mm, addr, PAGE_SIZE,\n\t\t\t\t      VM_READ|VM_EXEC|\n\t\t\t\t      VM_MAYREAD|VM_MAYWRITE|VM_MAYEXEC|\n\t\t\t\t      VM_ALWAYSDUMP,\n\t\t\t\t      syscall_pages);\n\tif (ret)\n\t\tgoto up_fail;\n\n\tcurrent->mm->context.vdso = (void *)addr;\n\tcurrent_thread_info()->sysenter_return =\n\t\t\t\t    (void *)VDSO_SYM(&SYSENTER_RETURN);\nup_fail:\n\tup_write(&mm->mmap_sem);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,5 @@\n int arch_setup_additional_pages(struct linux_binprm *bprm, int exstack)\n {\n-\tstruct vm_area_struct *vma;\n \tstruct mm_struct *mm = current->mm;\n \tunsigned long addr;\n \tint ret;\n@@ -12,38 +11,25 @@\n \t\tgoto up_fail;\n \t}\n \n-\tvma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);\n-\tif (!vma) {\n-\t\tret = -ENOMEM;\n-\t\tgoto up_fail;\n-\t}\n-\n-\tvma->vm_start = addr;\n-\tvma->vm_end = addr + PAGE_SIZE;\n-\t/* MAYWRITE to allow gdb to COW and set breakpoints */\n-\tvma->vm_flags = VM_READ|VM_EXEC|VM_MAYREAD|VM_MAYEXEC|VM_MAYWRITE;\n \t/*\n+\t * MAYWRITE to allow gdb to COW and set breakpoints\n+\t *\n \t * Make sure the vDSO gets into every core dump.\n \t * Dumping its contents makes post-mortem fully interpretable later\n \t * without matching up the same kernel and hardware config to see\n \t * what PC values meant.\n \t */\n-\tvma->vm_flags |= VM_ALWAYSDUMP;\n-\tvma->vm_flags |= mm->def_flags;\n-\tvma->vm_page_prot = protection_map[vma->vm_flags & 7];\n-\tvma->vm_ops = &syscall_vm_ops;\n-\tvma->vm_mm = mm;\n-\n-\tret = insert_vm_struct(mm, vma);\n-\tif (unlikely(ret)) {\n-\t\tkmem_cache_free(vm_area_cachep, vma);\n+\tret = install_special_mapping(mm, addr, PAGE_SIZE,\n+\t\t\t\t      VM_READ|VM_EXEC|\n+\t\t\t\t      VM_MAYREAD|VM_MAYWRITE|VM_MAYEXEC|\n+\t\t\t\t      VM_ALWAYSDUMP,\n+\t\t\t\t      syscall_pages);\n+\tif (ret)\n \t\tgoto up_fail;\n-\t}\n \n \tcurrent->mm->context.vdso = (void *)addr;\n \tcurrent_thread_info()->sysenter_return =\n \t\t\t\t    (void *)VDSO_SYM(&SYSENTER_RETURN);\n-\tmm->total_vm++;\n up_fail:\n \tup_write(&mm->mmap_sem);\n \treturn ret;",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct vm_area_struct *vma;",
                "\tvma = kmem_cache_zalloc(vm_area_cachep, GFP_KERNEL);",
                "\tif (!vma) {",
                "\t\tret = -ENOMEM;",
                "\t\tgoto up_fail;",
                "\t}",
                "",
                "\tvma->vm_start = addr;",
                "\tvma->vm_end = addr + PAGE_SIZE;",
                "\t/* MAYWRITE to allow gdb to COW and set breakpoints */",
                "\tvma->vm_flags = VM_READ|VM_EXEC|VM_MAYREAD|VM_MAYEXEC|VM_MAYWRITE;",
                "\tvma->vm_flags |= VM_ALWAYSDUMP;",
                "\tvma->vm_flags |= mm->def_flags;",
                "\tvma->vm_page_prot = protection_map[vma->vm_flags & 7];",
                "\tvma->vm_ops = &syscall_vm_ops;",
                "\tvma->vm_mm = mm;",
                "",
                "\tret = insert_vm_struct(mm, vma);",
                "\tif (unlikely(ret)) {",
                "\t\tkmem_cache_free(vm_area_cachep, vma);",
                "\t}",
                "\tmm->total_vm++;"
            ],
            "added_lines": [
                "\t * MAYWRITE to allow gdb to COW and set breakpoints",
                "\t *",
                "\tret = install_special_mapping(mm, addr, PAGE_SIZE,",
                "\t\t\t\t      VM_READ|VM_EXEC|",
                "\t\t\t\t      VM_MAYREAD|VM_MAYWRITE|VM_MAYEXEC|",
                "\t\t\t\t      VM_ALWAYSDUMP,",
                "\t\t\t\t      syscall_pages);",
                "\tif (ret)"
            ]
        }
    },
    {
        "cve_id": "CVE-2008-3527",
        "func_name": "torvalds/linux/sysenter_setup",
        "description": "arch/i386/kernel/sysenter.c in the Virtual Dynamic Shared Objects (vDSO) implementation in the Linux kernel before 2.6.21 does not properly check boundaries, which allows local users to gain privileges or cause a denial of service via unspecified vectors, related to the install_special_mapping, syscall, and syscall32_nopage functions.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=7d91d531900bfa1165d445390b3b13a8013f98f7",
        "commit_title": "This patch uses install_special_mapping for the i386 vDSO setup, consolidating",
        "commit_text": "duplicated code.  Cc: Ingo Molnar <mingo@elte.hu> Cc: Paul Mackerras <paulus@samba.org> Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org> Cc: Andi Kleen <ak@suse.de> ",
        "func_before": "int __init sysenter_setup(void)\n{\n\tsyscall_page = (void *)get_zeroed_page(GFP_ATOMIC);\n\n#ifdef CONFIG_COMPAT_VDSO\n\t__set_fixmap(FIX_VDSO, __pa(syscall_page), PAGE_READONLY);\n\tprintk(\"Compat vDSO mapped to %08lx.\\n\", __fix_to_virt(FIX_VDSO));\n#endif\n\n\tif (!boot_cpu_has(X86_FEATURE_SEP)) {\n\t\tmemcpy(syscall_page,\n\t\t       &vsyscall_int80_start,\n\t\t       &vsyscall_int80_end - &vsyscall_int80_start);\n\t\treturn 0;\n\t}\n\n\tmemcpy(syscall_page,\n\t       &vsyscall_sysenter_start,\n\t       &vsyscall_sysenter_end - &vsyscall_sysenter_start);\n\n\treturn 0;\n}",
        "func": "int __init sysenter_setup(void)\n{\n\tvoid *syscall_page = (void *)get_zeroed_page(GFP_ATOMIC);\n\tsyscall_pages[0] = virt_to_page(syscall_page);\n\n#ifdef CONFIG_COMPAT_VDSO\n\t__set_fixmap(FIX_VDSO, __pa(syscall_page), PAGE_READONLY);\n\tprintk(\"Compat vDSO mapped to %08lx.\\n\", __fix_to_virt(FIX_VDSO));\n#endif\n\n\tif (!boot_cpu_has(X86_FEATURE_SEP)) {\n\t\tmemcpy(syscall_page,\n\t\t       &vsyscall_int80_start,\n\t\t       &vsyscall_int80_end - &vsyscall_int80_start);\n\t\treturn 0;\n\t}\n\n\tmemcpy(syscall_page,\n\t       &vsyscall_sysenter_start,\n\t       &vsyscall_sysenter_end - &vsyscall_sysenter_start);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,7 @@\n int __init sysenter_setup(void)\n {\n-\tsyscall_page = (void *)get_zeroed_page(GFP_ATOMIC);\n+\tvoid *syscall_page = (void *)get_zeroed_page(GFP_ATOMIC);\n+\tsyscall_pages[0] = virt_to_page(syscall_page);\n \n #ifdef CONFIG_COMPAT_VDSO\n \t__set_fixmap(FIX_VDSO, __pa(syscall_page), PAGE_READONLY);",
        "diff_line_info": {
            "deleted_lines": [
                "\tsyscall_page = (void *)get_zeroed_page(GFP_ATOMIC);"
            ],
            "added_lines": [
                "\tvoid *syscall_page = (void *)get_zeroed_page(GFP_ATOMIC);",
                "\tsyscall_pages[0] = virt_to_page(syscall_page);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-0024",
        "func_name": "torvalds/linux/sys_remap_file_pages",
        "description": "The sys_remap_file_pages function in mm/fremap.c in the Linux kernel before 2.6.24.1 allows local users to cause a denial of service or gain privileges via unspecified vectors, related to the vm_file structure member, and the mmap_region and do_munmap functions.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/stable/linux.git;a=commit;h=8a459e44ad837018ea5c34a9efe8eb4ad27ded26",
        "commit_title": "Fix ->vm_file accounting, mmap_region() may do do_munmap().",
        "commit_text": " Cc: <stable@kernel.org> ",
        "func_before": "asmlinkage long sys_remap_file_pages(unsigned long start, unsigned long size,\n\tunsigned long prot, unsigned long pgoff, unsigned long flags)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct address_space *mapping;\n\tunsigned long end = start + size;\n\tstruct vm_area_struct *vma;\n\tint err = -EINVAL;\n\tint has_write_lock = 0;\n\n\tif (prot)\n\t\treturn err;\n\t/*\n\t * Sanitize the syscall parameters:\n\t */\n\tstart = start & PAGE_MASK;\n\tsize = size & PAGE_MASK;\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tif (start + size <= start)\n\t\treturn err;\n\n\t/* Can we represent this offset inside this architecture's pte's? */\n#if PTE_FILE_MAX_BITS < BITS_PER_LONG\n\tif (pgoff + (size >> PAGE_SHIFT) >= (1UL << PTE_FILE_MAX_BITS))\n\t\treturn err;\n#endif\n\n\t/* We need down_write() to change vma->vm_flags. */\n\tdown_read(&mm->mmap_sem);\n retry:\n\tvma = find_vma(mm, start);\n\n\t/*\n\t * Make sure the vma is shared, that it supports prefaulting,\n\t * and that the remapped range is valid and fully within\n\t * the single existing vma.  vm_private_data is used as a\n\t * swapout cursor in a VM_NONLINEAR vma.\n\t */\n\tif (!vma || !(vma->vm_flags & VM_SHARED))\n\t\tgoto out;\n\n\tif (vma->vm_private_data && !(vma->vm_flags & VM_NONLINEAR))\n\t\tgoto out;\n\n\tif (!(vma->vm_flags & VM_CAN_NONLINEAR))\n\t\tgoto out;\n\n\tif (end <= start || start < vma->vm_start || end > vma->vm_end)\n\t\tgoto out;\n\n\t/* Must set VM_NONLINEAR before any pages are populated. */\n\tif (!(vma->vm_flags & VM_NONLINEAR)) {\n\t\t/* Don't need a nonlinear mapping, exit success */\n\t\tif (pgoff == linear_page_index(vma, start)) {\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!has_write_lock) {\n\t\t\tup_read(&mm->mmap_sem);\n\t\t\tdown_write(&mm->mmap_sem);\n\t\t\thas_write_lock = 1;\n\t\t\tgoto retry;\n\t\t}\n\t\tmapping = vma->vm_file->f_mapping;\n\t\t/*\n\t\t * page_mkclean doesn't work on nonlinear vmas, so if\n\t\t * dirty pages need to be accounted, emulate with linear\n\t\t * vmas.\n\t\t */\n\t\tif (mapping_cap_account_dirty(mapping)) {\n\t\t\tunsigned long addr;\n\n\t\t\tflags &= MAP_NONBLOCK;\n\t\t\taddr = mmap_region(vma->vm_file, start, size,\n\t\t\t\t\tflags, vma->vm_flags, pgoff, 1);\n\t\t\tif (IS_ERR_VALUE(addr)) {\n\t\t\t\terr = addr;\n\t\t\t} else {\n\t\t\t\tBUG_ON(addr != start);\n\t\t\t\terr = 0;\n\t\t\t}\n\t\t\tgoto out;\n\t\t}\n\t\tspin_lock(&mapping->i_mmap_lock);\n\t\tflush_dcache_mmap_lock(mapping);\n\t\tvma->vm_flags |= VM_NONLINEAR;\n\t\tvma_prio_tree_remove(vma, &mapping->i_mmap);\n\t\tvma_nonlinear_insert(vma, &mapping->i_mmap_nonlinear);\n\t\tflush_dcache_mmap_unlock(mapping);\n\t\tspin_unlock(&mapping->i_mmap_lock);\n\t}\n\n\terr = populate_range(mm, vma, start, size, pgoff);\n\tif (!err && !(flags & MAP_NONBLOCK)) {\n\t\tif (unlikely(has_write_lock)) {\n\t\t\tdowngrade_write(&mm->mmap_sem);\n\t\t\thas_write_lock = 0;\n\t\t}\n\t\tmake_pages_present(start, start+size);\n\t}\n\n\t/*\n\t * We can't clear VM_NONLINEAR because we'd have to do\n\t * it after ->populate completes, and that would prevent\n\t * downgrading the lock.  (Locks can't be upgraded).\n\t */\n\nout:\n\tif (likely(!has_write_lock))\n\t\tup_read(&mm->mmap_sem);\n\telse\n\t\tup_write(&mm->mmap_sem);\n\n\treturn err;\n}",
        "func": "asmlinkage long sys_remap_file_pages(unsigned long start, unsigned long size,\n\tunsigned long prot, unsigned long pgoff, unsigned long flags)\n{\n\tstruct mm_struct *mm = current->mm;\n\tstruct address_space *mapping;\n\tunsigned long end = start + size;\n\tstruct vm_area_struct *vma;\n\tint err = -EINVAL;\n\tint has_write_lock = 0;\n\n\tif (prot)\n\t\treturn err;\n\t/*\n\t * Sanitize the syscall parameters:\n\t */\n\tstart = start & PAGE_MASK;\n\tsize = size & PAGE_MASK;\n\n\t/* Does the address range wrap, or is the span zero-sized? */\n\tif (start + size <= start)\n\t\treturn err;\n\n\t/* Can we represent this offset inside this architecture's pte's? */\n#if PTE_FILE_MAX_BITS < BITS_PER_LONG\n\tif (pgoff + (size >> PAGE_SHIFT) >= (1UL << PTE_FILE_MAX_BITS))\n\t\treturn err;\n#endif\n\n\t/* We need down_write() to change vma->vm_flags. */\n\tdown_read(&mm->mmap_sem);\n retry:\n\tvma = find_vma(mm, start);\n\n\t/*\n\t * Make sure the vma is shared, that it supports prefaulting,\n\t * and that the remapped range is valid and fully within\n\t * the single existing vma.  vm_private_data is used as a\n\t * swapout cursor in a VM_NONLINEAR vma.\n\t */\n\tif (!vma || !(vma->vm_flags & VM_SHARED))\n\t\tgoto out;\n\n\tif (vma->vm_private_data && !(vma->vm_flags & VM_NONLINEAR))\n\t\tgoto out;\n\n\tif (!(vma->vm_flags & VM_CAN_NONLINEAR))\n\t\tgoto out;\n\n\tif (end <= start || start < vma->vm_start || end > vma->vm_end)\n\t\tgoto out;\n\n\t/* Must set VM_NONLINEAR before any pages are populated. */\n\tif (!(vma->vm_flags & VM_NONLINEAR)) {\n\t\t/* Don't need a nonlinear mapping, exit success */\n\t\tif (pgoff == linear_page_index(vma, start)) {\n\t\t\terr = 0;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!has_write_lock) {\n\t\t\tup_read(&mm->mmap_sem);\n\t\t\tdown_write(&mm->mmap_sem);\n\t\t\thas_write_lock = 1;\n\t\t\tgoto retry;\n\t\t}\n\t\tmapping = vma->vm_file->f_mapping;\n\t\t/*\n\t\t * page_mkclean doesn't work on nonlinear vmas, so if\n\t\t * dirty pages need to be accounted, emulate with linear\n\t\t * vmas.\n\t\t */\n\t\tif (mapping_cap_account_dirty(mapping)) {\n\t\t\tunsigned long addr;\n\t\t\tstruct file *file = vma->vm_file;\n\n\t\t\tflags &= MAP_NONBLOCK;\n\t\t\tget_file(file);\n\t\t\taddr = mmap_region(file, start, size,\n\t\t\t\t\tflags, vma->vm_flags, pgoff, 1);\n\t\t\tfput(file);\n\t\t\tif (IS_ERR_VALUE(addr)) {\n\t\t\t\terr = addr;\n\t\t\t} else {\n\t\t\t\tBUG_ON(addr != start);\n\t\t\t\terr = 0;\n\t\t\t}\n\t\t\tgoto out;\n\t\t}\n\t\tspin_lock(&mapping->i_mmap_lock);\n\t\tflush_dcache_mmap_lock(mapping);\n\t\tvma->vm_flags |= VM_NONLINEAR;\n\t\tvma_prio_tree_remove(vma, &mapping->i_mmap);\n\t\tvma_nonlinear_insert(vma, &mapping->i_mmap_nonlinear);\n\t\tflush_dcache_mmap_unlock(mapping);\n\t\tspin_unlock(&mapping->i_mmap_lock);\n\t}\n\n\terr = populate_range(mm, vma, start, size, pgoff);\n\tif (!err && !(flags & MAP_NONBLOCK)) {\n\t\tif (unlikely(has_write_lock)) {\n\t\t\tdowngrade_write(&mm->mmap_sem);\n\t\t\thas_write_lock = 0;\n\t\t}\n\t\tmake_pages_present(start, start+size);\n\t}\n\n\t/*\n\t * We can't clear VM_NONLINEAR because we'd have to do\n\t * it after ->populate completes, and that would prevent\n\t * downgrading the lock.  (Locks can't be upgraded).\n\t */\n\nout:\n\tif (likely(!has_write_lock))\n\t\tup_read(&mm->mmap_sem);\n\telse\n\t\tup_write(&mm->mmap_sem);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -71,10 +71,13 @@\n \t\t */\n \t\tif (mapping_cap_account_dirty(mapping)) {\n \t\t\tunsigned long addr;\n+\t\t\tstruct file *file = vma->vm_file;\n \n \t\t\tflags &= MAP_NONBLOCK;\n-\t\t\taddr = mmap_region(vma->vm_file, start, size,\n+\t\t\tget_file(file);\n+\t\t\taddr = mmap_region(file, start, size,\n \t\t\t\t\tflags, vma->vm_flags, pgoff, 1);\n+\t\t\tfput(file);\n \t\t\tif (IS_ERR_VALUE(addr)) {\n \t\t\t\terr = addr;\n \t\t\t} else {",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\taddr = mmap_region(vma->vm_file, start, size,"
            ],
            "added_lines": [
                "\t\t\tstruct file *file = vma->vm_file;",
                "\t\t\tget_file(file);",
                "\t\t\taddr = mmap_region(file, start, size,",
                "\t\t\tfput(file);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-0675",
        "func_name": "torvalds/linux/skfp_ioctl",
        "description": "The skfp_ioctl function in drivers/net/skfp/skfddi.c in the Linux kernel before 2.6.28.6 permits SKFP_CLR_STATS requests only when the CAP_NET_ADMIN capability is absent, instead of when this capability is present, which allows local users to reset the driver statistics, related to an \"inverted logic\" issue.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=c25b9abbc2c2c0da88e180c3933d6e773245815a",
        "commit_title": "Fix inverted logic",
        "commit_text": " ",
        "func_before": "static int skfp_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tstruct s_smc *smc = netdev_priv(dev);\n\tskfddi_priv *lp = &smc->os;\n\tstruct s_skfp_ioctl ioc;\n\tint status = 0;\n\n\tif (copy_from_user(&ioc, rq->ifr_data, sizeof(struct s_skfp_ioctl)))\n\t\treturn -EFAULT;\n\n\tswitch (ioc.cmd) {\n\tcase SKFP_GET_STATS:\t/* Get the driver statistics */\n\t\tioc.len = sizeof(lp->MacStat);\n\t\tstatus = copy_to_user(ioc.data, skfp_ctl_get_stats(dev), ioc.len)\n\t\t\t\t? -EFAULT : 0;\n\t\tbreak;\n\tcase SKFP_CLR_STATS:\t/* Zero out the driver statistics */\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tmemset(&lp->MacStat, 0, sizeof(lp->MacStat));\n\t\t} else {\n\t\t\tstatus = -EPERM;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tprintk(\"ioctl for %s: unknow cmd: %04x\\n\", dev->name, ioc.cmd);\n\t\tstatus = -EOPNOTSUPP;\n\n\t}\t\t\t// switch\n\n\treturn status;\n}",
        "func": "static int skfp_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\n{\n\tstruct s_smc *smc = netdev_priv(dev);\n\tskfddi_priv *lp = &smc->os;\n\tstruct s_skfp_ioctl ioc;\n\tint status = 0;\n\n\tif (copy_from_user(&ioc, rq->ifr_data, sizeof(struct s_skfp_ioctl)))\n\t\treturn -EFAULT;\n\n\tswitch (ioc.cmd) {\n\tcase SKFP_GET_STATS:\t/* Get the driver statistics */\n\t\tioc.len = sizeof(lp->MacStat);\n\t\tstatus = copy_to_user(ioc.data, skfp_ctl_get_stats(dev), ioc.len)\n\t\t\t\t? -EFAULT : 0;\n\t\tbreak;\n\tcase SKFP_CLR_STATS:\t/* Zero out the driver statistics */\n\t\tif (!capable(CAP_NET_ADMIN)) {\n\t\t\tstatus = -EPERM;\n\t\t} else {\n\t\t\tmemset(&lp->MacStat, 0, sizeof(lp->MacStat));\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tprintk(\"ioctl for %s: unknow cmd: %04x\\n\", dev->name, ioc.cmd);\n\t\tstatus = -EOPNOTSUPP;\n\n\t}\t\t\t// switch\n\n\treturn status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,9 +16,9 @@\n \t\tbreak;\n \tcase SKFP_CLR_STATS:\t/* Zero out the driver statistics */\n \t\tif (!capable(CAP_NET_ADMIN)) {\n+\t\t\tstatus = -EPERM;\n+\t\t} else {\n \t\t\tmemset(&lp->MacStat, 0, sizeof(lp->MacStat));\n-\t\t} else {\n-\t\t\tstatus = -EPERM;\n \t\t}\n \t\tbreak;\n \tdefault:",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t} else {",
                "\t\t\tstatus = -EPERM;"
            ],
            "added_lines": [
                "\t\t\tstatus = -EPERM;",
                "\t\t} else {"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-0676",
        "func_name": "torvalds/linux/sock_getsockopt",
        "description": "The sock_getsockopt function in net/core/sock.c in the Linux kernel before 2.6.28.6 does not initialize a certain structure member, which allows local users to obtain potentially sensitive information from kernel memory via an SO_BSDCOMPAT getsockopt request.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=df0bca049d01c0ee94afb7cd5dfd959541e6c8da",
        "commit_title": "In function sock_getsockopt() located in net/core/sock.c, optval v.val",
        "commit_text": "is not correctly initialized and directly returned in userland in case we have SO_BSDCOMPAT option set.  This dummy code should trigger the bug:  int main(void) { \tunsigned char buf[4] = { 0, 0, 0, 0 }; \tint len; \tint sock; \tsock = socket(33, 2, 2); \tgetsockopt(sock, 1, SO_BSDCOMPAT, &buf, &len); \tprintf(\"%x%x%x%x\\n\", buf[0], buf[1], buf[2], buf[3]); \tclose(sock); }  Here is a patch that fix this bug by initalizing v.val just after its declaration.  ",
        "func_before": "int sock_getsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\n\tunion {\n\t\tint val;\n\t\tstruct linger ling;\n\t\tstruct timeval tm;\n\t} v;\n\n\tunsigned int lv = sizeof(int);\n\tint len;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\tswitch(optname) {\n\tcase SO_DEBUG:\n\t\tv.val = sock_flag(sk, SOCK_DBG);\n\t\tbreak;\n\n\tcase SO_DONTROUTE:\n\t\tv.val = sock_flag(sk, SOCK_LOCALROUTE);\n\t\tbreak;\n\n\tcase SO_BROADCAST:\n\t\tv.val = !!sock_flag(sk, SOCK_BROADCAST);\n\t\tbreak;\n\n\tcase SO_SNDBUF:\n\t\tv.val = sk->sk_sndbuf;\n\t\tbreak;\n\n\tcase SO_RCVBUF:\n\t\tv.val = sk->sk_rcvbuf;\n\t\tbreak;\n\n\tcase SO_REUSEADDR:\n\t\tv.val = sk->sk_reuse;\n\t\tbreak;\n\n\tcase SO_KEEPALIVE:\n\t\tv.val = !!sock_flag(sk, SOCK_KEEPOPEN);\n\t\tbreak;\n\n\tcase SO_TYPE:\n\t\tv.val = sk->sk_type;\n\t\tbreak;\n\n\tcase SO_ERROR:\n\t\tv.val = -sock_error(sk);\n\t\tif (v.val==0)\n\t\t\tv.val = xchg(&sk->sk_err_soft, 0);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tv.val = !!sock_flag(sk, SOCK_URGINLINE);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tv.val = sk->sk_no_check;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tv.val = sk->sk_priority;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tlv\t\t= sizeof(v.ling);\n\t\tv.ling.l_onoff\t= !!sock_flag(sk, SOCK_LINGER);\n\t\tv.ling.l_linger\t= sk->sk_lingertime / HZ;\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"getsockopt\");\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMP) &&\n\t\t\t\t!sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_TIMESTAMPNS:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tlv=sizeof(struct timeval);\n\t\tif (sk->sk_rcvtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_rcvtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_rcvtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tlv=sizeof(struct timeval);\n\t\tif (sk->sk_sndtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_sndtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_sndtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tv.val = sk->sk_rcvlowat;\n\t\tbreak;\n\n\tcase SO_SNDLOWAT:\n\t\tv.val=1;\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tv.val = test_bit(SOCK_PASSCRED, &sock->flags) ? 1 : 0;\n\t\tbreak;\n\n\tcase SO_PEERCRED:\n\t\tif (len > sizeof(sk->sk_peercred))\n\t\t\tlen = sizeof(sk->sk_peercred);\n\t\tif (copy_to_user(optval, &sk->sk_peercred, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\n\tcase SO_PEERNAME:\n\t{\n\t\tchar address[128];\n\n\t\tif (sock->ops->getname(sock, (struct sockaddr *)address, &lv, 2))\n\t\t\treturn -ENOTCONN;\n\t\tif (lv < len)\n\t\t\treturn -EINVAL;\n\t\tif (copy_to_user(optval, address, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\t}\n\n\t/* Dubious BSD thing... Probably nobody even uses it, but\n\t * the UNIX standard wants it for whatever reason... -DaveM\n\t */\n\tcase SO_ACCEPTCONN:\n\t\tv.val = sk->sk_state == TCP_LISTEN;\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tv.val = test_bit(SOCK_PASSSEC, &sock->flags) ? 1 : 0;\n\t\tbreak;\n\n\tcase SO_PEERSEC:\n\t\treturn security_socket_getpeersec_stream(sock, optval, optlen, len);\n\n\tcase SO_MARK:\n\t\tv.val = sk->sk_mark;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\tif (len > lv)\n\t\tlen = lv;\n\tif (copy_to_user(optval, &v, len))\n\t\treturn -EFAULT;\nlenout:\n\tif (put_user(len, optlen))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
        "func": "int sock_getsockopt(struct socket *sock, int level, int optname,\n\t\t    char __user *optval, int __user *optlen)\n{\n\tstruct sock *sk = sock->sk;\n\n\tunion {\n\t\tint val;\n\t\tstruct linger ling;\n\t\tstruct timeval tm;\n\t} v;\n\n\tunsigned int lv = sizeof(int);\n\tint len;\n\n\tif (get_user(len, optlen))\n\t\treturn -EFAULT;\n\tif (len < 0)\n\t\treturn -EINVAL;\n\n\tv.val = 0;\n\n\tswitch(optname) {\n\tcase SO_DEBUG:\n\t\tv.val = sock_flag(sk, SOCK_DBG);\n\t\tbreak;\n\n\tcase SO_DONTROUTE:\n\t\tv.val = sock_flag(sk, SOCK_LOCALROUTE);\n\t\tbreak;\n\n\tcase SO_BROADCAST:\n\t\tv.val = !!sock_flag(sk, SOCK_BROADCAST);\n\t\tbreak;\n\n\tcase SO_SNDBUF:\n\t\tv.val = sk->sk_sndbuf;\n\t\tbreak;\n\n\tcase SO_RCVBUF:\n\t\tv.val = sk->sk_rcvbuf;\n\t\tbreak;\n\n\tcase SO_REUSEADDR:\n\t\tv.val = sk->sk_reuse;\n\t\tbreak;\n\n\tcase SO_KEEPALIVE:\n\t\tv.val = !!sock_flag(sk, SOCK_KEEPOPEN);\n\t\tbreak;\n\n\tcase SO_TYPE:\n\t\tv.val = sk->sk_type;\n\t\tbreak;\n\n\tcase SO_ERROR:\n\t\tv.val = -sock_error(sk);\n\t\tif (v.val==0)\n\t\t\tv.val = xchg(&sk->sk_err_soft, 0);\n\t\tbreak;\n\n\tcase SO_OOBINLINE:\n\t\tv.val = !!sock_flag(sk, SOCK_URGINLINE);\n\t\tbreak;\n\n\tcase SO_NO_CHECK:\n\t\tv.val = sk->sk_no_check;\n\t\tbreak;\n\n\tcase SO_PRIORITY:\n\t\tv.val = sk->sk_priority;\n\t\tbreak;\n\n\tcase SO_LINGER:\n\t\tlv\t\t= sizeof(v.ling);\n\t\tv.ling.l_onoff\t= !!sock_flag(sk, SOCK_LINGER);\n\t\tv.ling.l_linger\t= sk->sk_lingertime / HZ;\n\t\tbreak;\n\n\tcase SO_BSDCOMPAT:\n\t\tsock_warn_obsolete_bsdism(\"getsockopt\");\n\t\tbreak;\n\n\tcase SO_TIMESTAMP:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMP) &&\n\t\t\t\t!sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_TIMESTAMPNS:\n\t\tv.val = sock_flag(sk, SOCK_RCVTSTAMPNS);\n\t\tbreak;\n\n\tcase SO_RCVTIMEO:\n\t\tlv=sizeof(struct timeval);\n\t\tif (sk->sk_rcvtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_rcvtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_rcvtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_SNDTIMEO:\n\t\tlv=sizeof(struct timeval);\n\t\tif (sk->sk_sndtimeo == MAX_SCHEDULE_TIMEOUT) {\n\t\t\tv.tm.tv_sec = 0;\n\t\t\tv.tm.tv_usec = 0;\n\t\t} else {\n\t\t\tv.tm.tv_sec = sk->sk_sndtimeo / HZ;\n\t\t\tv.tm.tv_usec = ((sk->sk_sndtimeo % HZ) * 1000000) / HZ;\n\t\t}\n\t\tbreak;\n\n\tcase SO_RCVLOWAT:\n\t\tv.val = sk->sk_rcvlowat;\n\t\tbreak;\n\n\tcase SO_SNDLOWAT:\n\t\tv.val=1;\n\t\tbreak;\n\n\tcase SO_PASSCRED:\n\t\tv.val = test_bit(SOCK_PASSCRED, &sock->flags) ? 1 : 0;\n\t\tbreak;\n\n\tcase SO_PEERCRED:\n\t\tif (len > sizeof(sk->sk_peercred))\n\t\t\tlen = sizeof(sk->sk_peercred);\n\t\tif (copy_to_user(optval, &sk->sk_peercred, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\n\tcase SO_PEERNAME:\n\t{\n\t\tchar address[128];\n\n\t\tif (sock->ops->getname(sock, (struct sockaddr *)address, &lv, 2))\n\t\t\treturn -ENOTCONN;\n\t\tif (lv < len)\n\t\t\treturn -EINVAL;\n\t\tif (copy_to_user(optval, address, len))\n\t\t\treturn -EFAULT;\n\t\tgoto lenout;\n\t}\n\n\t/* Dubious BSD thing... Probably nobody even uses it, but\n\t * the UNIX standard wants it for whatever reason... -DaveM\n\t */\n\tcase SO_ACCEPTCONN:\n\t\tv.val = sk->sk_state == TCP_LISTEN;\n\t\tbreak;\n\n\tcase SO_PASSSEC:\n\t\tv.val = test_bit(SOCK_PASSSEC, &sock->flags) ? 1 : 0;\n\t\tbreak;\n\n\tcase SO_PEERSEC:\n\t\treturn security_socket_getpeersec_stream(sock, optval, optlen, len);\n\n\tcase SO_MARK:\n\t\tv.val = sk->sk_mark;\n\t\tbreak;\n\n\tdefault:\n\t\treturn -ENOPROTOOPT;\n\t}\n\n\tif (len > lv)\n\t\tlen = lv;\n\tif (copy_to_user(optval, &v, len))\n\t\treturn -EFAULT;\nlenout:\n\tif (put_user(len, optlen))\n\t\treturn -EFAULT;\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -16,6 +16,8 @@\n \t\treturn -EFAULT;\n \tif (len < 0)\n \t\treturn -EINVAL;\n+\n+\tv.val = 0;\n \n \tswitch(optname) {\n \tcase SO_DEBUG:",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tv.val = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-1337",
        "func_name": "torvalds/linux/exit_notify",
        "description": "The exit_notify function in kernel/exit.c in the Linux kernel before 2.6.30-rc1 does not restrict exit signals when the CAP_KILL capability is held, which allows local users to send an arbitrary signal to a process by running a program that modifies the exit_signal field and then uses an exec system call to launch a setuid application.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=432870dab85a2f69dc417022646cb9a70acf7f94",
        "commit_title": "The CAP_KILL check in exit_notify() looks just wrong, kill it.",
        "commit_text": " Whatever logic we have to reset ->exit_signal, the malicious user can bypass it if it execs the setuid application before exiting.  ",
        "func_before": "static void exit_notify(struct task_struct *tsk, int group_dead)\n{\n\tint signal;\n\tvoid *cookie;\n\n\t/*\n\t * This does two things:\n\t *\n  \t * A.  Make init inherit all the child processes\n\t * B.  Check to see if any process groups have become orphaned\n\t *\tas a result of our exiting, and if they have any stopped\n\t *\tjobs, send them a SIGHUP and then a SIGCONT.  (POSIX 3.2.2.2)\n\t */\n\tforget_original_parent(tsk);\n\texit_task_namespaces(tsk);\n\n\twrite_lock_irq(&tasklist_lock);\n\tif (group_dead)\n\t\tkill_orphaned_pgrp(tsk->group_leader, NULL);\n\n\t/* Let father know we died\n\t *\n\t * Thread signals are configurable, but you aren't going to use\n\t * that to send signals to arbitary processes.\n\t * That stops right now.\n\t *\n\t * If the parent exec id doesn't match the exec id we saved\n\t * when we started then we know the parent has changed security\n\t * domain.\n\t *\n\t * If our self_exec id doesn't match our parent_exec_id then\n\t * we have changed execution domain as these two values started\n\t * the same after a fork.\n\t */\n\tif (tsk->exit_signal != SIGCHLD && !task_detached(tsk) &&\n\t    (tsk->parent_exec_id != tsk->real_parent->self_exec_id ||\n\t     tsk->self_exec_id != tsk->parent_exec_id) &&\n\t    !capable(CAP_KILL))\n\t\ttsk->exit_signal = SIGCHLD;\n\n\tsignal = tracehook_notify_death(tsk, &cookie, group_dead);\n\tif (signal >= 0)\n\t\tsignal = do_notify_parent(tsk, signal);\n\n\ttsk->exit_state = signal == DEATH_REAP ? EXIT_DEAD : EXIT_ZOMBIE;\n\n\t/* mt-exec, de_thread() is waiting for us */\n\tif (thread_group_leader(tsk) &&\n\t    tsk->signal->group_exit_task &&\n\t    tsk->signal->notify_count < 0)\n\t\twake_up_process(tsk->signal->group_exit_task);\n\n\twrite_unlock_irq(&tasklist_lock);\n\n\ttracehook_report_death(tsk, signal, cookie, group_dead);\n\n\t/* If the process is dead, release it - nobody will wait for it */\n\tif (signal == DEATH_REAP)\n\t\trelease_task(tsk);\n}",
        "func": "static void exit_notify(struct task_struct *tsk, int group_dead)\n{\n\tint signal;\n\tvoid *cookie;\n\n\t/*\n\t * This does two things:\n\t *\n  \t * A.  Make init inherit all the child processes\n\t * B.  Check to see if any process groups have become orphaned\n\t *\tas a result of our exiting, and if they have any stopped\n\t *\tjobs, send them a SIGHUP and then a SIGCONT.  (POSIX 3.2.2.2)\n\t */\n\tforget_original_parent(tsk);\n\texit_task_namespaces(tsk);\n\n\twrite_lock_irq(&tasklist_lock);\n\tif (group_dead)\n\t\tkill_orphaned_pgrp(tsk->group_leader, NULL);\n\n\t/* Let father know we died\n\t *\n\t * Thread signals are configurable, but you aren't going to use\n\t * that to send signals to arbitary processes.\n\t * That stops right now.\n\t *\n\t * If the parent exec id doesn't match the exec id we saved\n\t * when we started then we know the parent has changed security\n\t * domain.\n\t *\n\t * If our self_exec id doesn't match our parent_exec_id then\n\t * we have changed execution domain as these two values started\n\t * the same after a fork.\n\t */\n\tif (tsk->exit_signal != SIGCHLD && !task_detached(tsk) &&\n\t    (tsk->parent_exec_id != tsk->real_parent->self_exec_id ||\n\t     tsk->self_exec_id != tsk->parent_exec_id))\n\t\ttsk->exit_signal = SIGCHLD;\n\n\tsignal = tracehook_notify_death(tsk, &cookie, group_dead);\n\tif (signal >= 0)\n\t\tsignal = do_notify_parent(tsk, signal);\n\n\ttsk->exit_state = signal == DEATH_REAP ? EXIT_DEAD : EXIT_ZOMBIE;\n\n\t/* mt-exec, de_thread() is waiting for us */\n\tif (thread_group_leader(tsk) &&\n\t    tsk->signal->group_exit_task &&\n\t    tsk->signal->notify_count < 0)\n\t\twake_up_process(tsk->signal->group_exit_task);\n\n\twrite_unlock_irq(&tasklist_lock);\n\n\ttracehook_report_death(tsk, signal, cookie, group_dead);\n\n\t/* If the process is dead, release it - nobody will wait for it */\n\tif (signal == DEATH_REAP)\n\t\trelease_task(tsk);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -34,8 +34,7 @@\n \t */\n \tif (tsk->exit_signal != SIGCHLD && !task_detached(tsk) &&\n \t    (tsk->parent_exec_id != tsk->real_parent->self_exec_id ||\n-\t     tsk->self_exec_id != tsk->parent_exec_id) &&\n-\t    !capable(CAP_KILL))\n+\t     tsk->self_exec_id != tsk->parent_exec_id))\n \t\ttsk->exit_signal = SIGCHLD;\n \n \tsignal = tracehook_notify_death(tsk, &cookie, group_dead);",
        "diff_line_info": {
            "deleted_lines": [
                "\t     tsk->self_exec_id != tsk->parent_exec_id) &&",
                "\t    !capable(CAP_KILL))"
            ],
            "added_lines": [
                "\t     tsk->self_exec_id != tsk->parent_exec_id))"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-1338",
        "func_name": "torvalds/linux/kill_something_info",
        "description": "The kill_something_info function in kernel/signal.c in the Linux kernel before 2.6.28 does not consider PID namespaces when processing signals directed to PID -1, which allows local users to bypass the intended namespace isolation, and send arbitrary signals to all processes in all namespaces, via a kill command.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=d25141a818383b3c3b09f065698c544a7a0ec6e7",
        "commit_title": "Currently \"kill <sig> -1\" kills processes in all namespaces and breaks the",
        "commit_text": "isolation of namespaces.  Earlier attempt to fix this was discussed at:  \thttp://lkml.org/lkml/2008/7/23/148  As suggested by Oleg Nesterov in that thread, use \"task_pid_vnr() > 1\" check since task_pid_vnr() returns 0 if process is outside the caller's namespace.  ",
        "func_before": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\n\tint ret;\n\n\tif (pid > 0) {\n\t\trcu_read_lock();\n\t\tret = kill_pid_info(sig, info, find_vpid(pid));\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\n\tread_lock(&tasklist_lock);\n\tif (pid != -1) {\n\t\tret = __kill_pgrp_info(sig, info,\n\t\t\t\tpid ? find_vpid(-pid) : task_pgrp(current));\n\t} else {\n\t\tint retval = 0, count = 0;\n\t\tstruct task_struct * p;\n\n\t\tfor_each_process(p) {\n\t\t\tif (p->pid > 1 && !same_thread_group(p, current)) {\n\t\t\t\tint err = group_send_sig_info(sig, info, p);\n\t\t\t\t++count;\n\t\t\t\tif (err != -EPERM)\n\t\t\t\t\tretval = err;\n\t\t\t}\n\t\t}\n\t\tret = count ? retval : -ESRCH;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}",
        "func": "static int kill_something_info(int sig, struct siginfo *info, pid_t pid)\n{\n\tint ret;\n\n\tif (pid > 0) {\n\t\trcu_read_lock();\n\t\tret = kill_pid_info(sig, info, find_vpid(pid));\n\t\trcu_read_unlock();\n\t\treturn ret;\n\t}\n\n\tread_lock(&tasklist_lock);\n\tif (pid != -1) {\n\t\tret = __kill_pgrp_info(sig, info,\n\t\t\t\tpid ? find_vpid(-pid) : task_pgrp(current));\n\t} else {\n\t\tint retval = 0, count = 0;\n\t\tstruct task_struct * p;\n\n\t\tfor_each_process(p) {\n\t\t\tif (task_pid_vnr(p) > 1 &&\n\t\t\t\t\t!same_thread_group(p, current)) {\n\t\t\t\tint err = group_send_sig_info(sig, info, p);\n\t\t\t\t++count;\n\t\t\t\tif (err != -EPERM)\n\t\t\t\t\tretval = err;\n\t\t\t}\n\t\t}\n\t\tret = count ? retval : -ESRCH;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,8 @@\n \t\tstruct task_struct * p;\n \n \t\tfor_each_process(p) {\n-\t\t\tif (p->pid > 1 && !same_thread_group(p, current)) {\n+\t\t\tif (task_pid_vnr(p) > 1 &&\n+\t\t\t\t\t!same_thread_group(p, current)) {\n \t\t\t\tint err = group_send_sig_info(sig, info, p);\n \t\t\t\t++count;\n \t\t\t\tif (err != -EPERM)",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (p->pid > 1 && !same_thread_group(p, current)) {"
            ],
            "added_lines": [
                "\t\t\tif (task_pid_vnr(p) > 1 &&",
                "\t\t\t\t\t!same_thread_group(p, current)) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-2846",
        "func_name": "torvalds/linux/eisa_eeprom_read",
        "description": "The eisa_eeprom_read function in the parisc isa-eeprom component (drivers/parisc/eisa_eeprom.c) in the Linux kernel before 2.6.31-rc6 allows local users to access restricted memory via a negative ppos argument, which bypasses a check that assumes that ppos is positive and causes an out-of-bounds read in the readb function.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=6b4dbcd86a9d464057fcc7abe4d0574093071fcc",
        "commit_title": "loff_t is a signed type. If userspace passes a negative ppos, the \"count\"",
        "commit_text": "range check is weakened. \"count\"s bigger than HPEE_MAX_LENGTH will pass the check. Also, if ppos is negative, the readb(eisa_eeprom_addr + *ppos) will poke in random memory.  Cc: stable@kernel.org ",
        "func_before": "static ssize_t eisa_eeprom_read(struct file * file,\n\t\t\t      char __user *buf, size_t count, loff_t *ppos )\n{\n\tunsigned char *tmp;\n\tssize_t ret;\n\tint i;\n\t\n\tif (*ppos >= HPEE_MAX_LENGTH)\n\t\treturn 0;\n\t\n\tcount = *ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - *ppos;\n\ttmp = kmalloc(count, GFP_KERNEL);\n\tif (tmp) {\n\t\tfor (i = 0; i < count; i++)\n\t\t\ttmp[i] = readb(eisa_eeprom_addr+(*ppos)++);\n\n\t\tif (copy_to_user (buf, tmp, count))\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = count;\n\t\tkfree (tmp);\n\t} else\n\t\tret = -ENOMEM;\n\t\n\treturn ret;\n}",
        "func": "static ssize_t eisa_eeprom_read(struct file * file,\n\t\t\t      char __user *buf, size_t count, loff_t *ppos )\n{\n\tunsigned char *tmp;\n\tssize_t ret;\n\tint i;\n\t\n\tif (*ppos < 0 || *ppos >= HPEE_MAX_LENGTH)\n\t\treturn 0;\n\t\n\tcount = *ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - *ppos;\n\ttmp = kmalloc(count, GFP_KERNEL);\n\tif (tmp) {\n\t\tfor (i = 0; i < count; i++)\n\t\t\ttmp[i] = readb(eisa_eeprom_addr+(*ppos)++);\n\n\t\tif (copy_to_user (buf, tmp, count))\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = count;\n\t\tkfree (tmp);\n\t} else\n\t\tret = -ENOMEM;\n\t\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n \tssize_t ret;\n \tint i;\n \t\n-\tif (*ppos >= HPEE_MAX_LENGTH)\n+\tif (*ppos < 0 || *ppos >= HPEE_MAX_LENGTH)\n \t\treturn 0;\n \t\n \tcount = *ppos + count < HPEE_MAX_LENGTH ? count : HPEE_MAX_LENGTH - *ppos;",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (*ppos >= HPEE_MAX_LENGTH)"
            ],
            "added_lines": [
                "\tif (*ppos < 0 || *ppos >= HPEE_MAX_LENGTH)"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3286",
        "func_name": "torvalds/linux/do_open_lookup",
        "description": "NFSv4 in the Linux kernel 2.6.18, and possibly other versions, does not properly clean up an inode when an O_EXCL create fails, which causes files to be created with insecure settings such as setuid bits, and possibly allows local users to gain privileges, related to the execution of the do_open_permission function even when a create fails.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=81ac95c5",
        "commit_title": "In the case where an open creates the file, we shouldn't be rechecking",
        "commit_text": "permissions to open the file; the open succeeds regardless of what the new file's mode bits say.  This patch fixes the problem, but only by introducing yet another parameter to nfsd_create_v3.  This is ugly.  This will be fixed by later patches.  Cc: Jeff Garzik <jeff@garzik.org> ",
        "func_before": "static __be32\ndo_open_lookup(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_open *open)\n{\n\tstruct svc_fh resfh;\n\t__be32 status;\n\n\tfh_init(&resfh, NFS4_FHSIZE);\n\topen->op_truncate = 0;\n\n\tif (open->op_create) {\n\t\t/*\n\t\t * Note: create modes (UNCHECKED,GUARDED...) are the same\n\t\t * in NFSv4 as in v3.\n\t\t */\n\t\tstatus = nfsd_create_v3(rqstp, current_fh, open->op_fname.data,\n\t\t\t\t\topen->op_fname.len, &open->op_iattr,\n\t\t\t\t\t&resfh, open->op_createmode,\n\t\t\t\t\t(u32 *)open->op_verf.data, &open->op_truncate);\n\t} else {\n\t\tstatus = nfsd_lookup(rqstp, current_fh,\n\t\t\t\t     open->op_fname.data, open->op_fname.len, &resfh);\n\t\tfh_unlock(current_fh);\n\t}\n\tif (status)\n\t\tgoto out;\n\n\tset_change_info(&open->op_cinfo, current_fh);\n\n\t/* set reply cache */\n\tfh_dup2(current_fh, &resfh);\n\topen->op_stateowner->so_replay.rp_openfh_len = resfh.fh_handle.fh_size;\n\tmemcpy(open->op_stateowner->so_replay.rp_openfh,\n\t\t\t&resfh.fh_handle.fh_base, resfh.fh_handle.fh_size);\n\n\tstatus = do_open_permission(rqstp, current_fh, open, MAY_NOP);\n\nout:\n\tfh_put(&resfh);\n\treturn status;\n}",
        "func": "static __be32\ndo_open_lookup(struct svc_rqst *rqstp, struct svc_fh *current_fh, struct nfsd4_open *open)\n{\n\tstruct svc_fh resfh;\n\t__be32 status;\n\tint created = 0;\n\n\tfh_init(&resfh, NFS4_FHSIZE);\n\topen->op_truncate = 0;\n\n\tif (open->op_create) {\n\t\t/*\n\t\t * Note: create modes (UNCHECKED,GUARDED...) are the same\n\t\t * in NFSv4 as in v3.\n\t\t */\n\t\tstatus = nfsd_create_v3(rqstp, current_fh, open->op_fname.data,\n\t\t\t\t\topen->op_fname.len, &open->op_iattr,\n\t\t\t\t\t&resfh, open->op_createmode,\n\t\t\t\t\t(u32 *)open->op_verf.data, &open->op_truncate, &created);\n\t} else {\n\t\tstatus = nfsd_lookup(rqstp, current_fh,\n\t\t\t\t     open->op_fname.data, open->op_fname.len, &resfh);\n\t\tfh_unlock(current_fh);\n\t}\n\tif (status)\n\t\tgoto out;\n\n\tset_change_info(&open->op_cinfo, current_fh);\n\n\t/* set reply cache */\n\tfh_dup2(current_fh, &resfh);\n\topen->op_stateowner->so_replay.rp_openfh_len = resfh.fh_handle.fh_size;\n\tmemcpy(open->op_stateowner->so_replay.rp_openfh,\n\t\t\t&resfh.fh_handle.fh_base, resfh.fh_handle.fh_size);\n\n\tif (!created)\n\t\tstatus = do_open_permission(rqstp, current_fh, open, MAY_NOP);\n\nout:\n\tfh_put(&resfh);\n\treturn status;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,7 @@\n {\n \tstruct svc_fh resfh;\n \t__be32 status;\n+\tint created = 0;\n \n \tfh_init(&resfh, NFS4_FHSIZE);\n \topen->op_truncate = 0;\n@@ -15,7 +16,7 @@\n \t\tstatus = nfsd_create_v3(rqstp, current_fh, open->op_fname.data,\n \t\t\t\t\topen->op_fname.len, &open->op_iattr,\n \t\t\t\t\t&resfh, open->op_createmode,\n-\t\t\t\t\t(u32 *)open->op_verf.data, &open->op_truncate);\n+\t\t\t\t\t(u32 *)open->op_verf.data, &open->op_truncate, &created);\n \t} else {\n \t\tstatus = nfsd_lookup(rqstp, current_fh,\n \t\t\t\t     open->op_fname.data, open->op_fname.len, &resfh);\n@@ -32,7 +33,8 @@\n \tmemcpy(open->op_stateowner->so_replay.rp_openfh,\n \t\t\t&resfh.fh_handle.fh_base, resfh.fh_handle.fh_size);\n \n-\tstatus = do_open_permission(rqstp, current_fh, open, MAY_NOP);\n+\tif (!created)\n+\t\tstatus = do_open_permission(rqstp, current_fh, open, MAY_NOP);\n \n out:\n \tfh_put(&resfh);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\t(u32 *)open->op_verf.data, &open->op_truncate);",
                "\tstatus = do_open_permission(rqstp, current_fh, open, MAY_NOP);"
            ],
            "added_lines": [
                "\tint created = 0;",
                "\t\t\t\t\t(u32 *)open->op_verf.data, &open->op_truncate, &created);",
                "\tif (!created)",
                "\t\tstatus = do_open_permission(rqstp, current_fh, open, MAY_NOP);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3286",
        "func_name": "torvalds/linux/nfsd_create_v3",
        "description": "NFSv4 in the Linux kernel 2.6.18, and possibly other versions, does not properly clean up an inode when an O_EXCL create fails, which causes files to be created with insecure settings such as setuid bits, and possibly allows local users to gain privileges, related to the execution of the do_open_permission function even when a create fails.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=81ac95c5",
        "commit_title": "In the case where an open creates the file, we shouldn't be rechecking",
        "commit_text": "permissions to open the file; the open succeeds regardless of what the new file's mode bits say.  This patch fixes the problem, but only by introducing yet another parameter to nfsd_create_v3.  This is ugly.  This will be fixed by later patches.  Cc: Jeff Garzik <jeff@garzik.org> ",
        "func_before": "__be32\nnfsd_create_v3(struct svc_rqst *rqstp, struct svc_fh *fhp,\n\t\tchar *fname, int flen, struct iattr *iap,\n\t\tstruct svc_fh *resfhp, int createmode, u32 *verifier,\n\t        int *truncp)\n{\n\tstruct dentry\t*dentry, *dchild = NULL;\n\tstruct inode\t*dirp;\n\t__be32\t\terr;\n\tint\t\thost_err;\n\t__u32\t\tv_mtime=0, v_atime=0;\n\tint\t\tv_mode=0;\n\n\terr = nfserr_perm;\n\tif (!flen)\n\t\tgoto out;\n\terr = nfserr_exist;\n\tif (isdotent(fname, flen))\n\t\tgoto out;\n\tif (!(iap->ia_valid & ATTR_MODE))\n\t\tiap->ia_mode = 0;\n\terr = fh_verify(rqstp, fhp, S_IFDIR, MAY_CREATE);\n\tif (err)\n\t\tgoto out;\n\n\tdentry = fhp->fh_dentry;\n\tdirp = dentry->d_inode;\n\n\t/* Get all the sanity checks out of the way before\n\t * we lock the parent. */\n\terr = nfserr_notdir;\n\tif(!dirp->i_op || !dirp->i_op->lookup)\n\t\tgoto out;\n\tfh_lock_nested(fhp, I_MUTEX_PARENT);\n\n\t/*\n\t * Compose the response file handle.\n\t */\n\tdchild = lookup_one_len(fname, dentry, flen);\n\thost_err = PTR_ERR(dchild);\n\tif (IS_ERR(dchild))\n\t\tgoto out_nfserr;\n\n\terr = fh_compose(resfhp, fhp->fh_export, dchild, fhp);\n\tif (err)\n\t\tgoto out;\n\n\tif (createmode == NFS3_CREATE_EXCLUSIVE) {\n\t\t/* while the verifier would fit in mtime+atime,\n\t\t * solaris7 gets confused (bugid 4218508) if these have\n\t\t * the high bit set, so we use the mode as well\n\t\t */\n\t\tv_mtime = verifier[0]&0x7fffffff;\n\t\tv_atime = verifier[1]&0x7fffffff;\n\t\tv_mode  = S_IFREG\n\t\t\t| ((verifier[0]&0x80000000) >> (32-7)) /* u+x */\n\t\t\t| ((verifier[1]&0x80000000) >> (32-9)) /* u+r */\n\t\t\t;\n\t}\n\t\n\tif (dchild->d_inode) {\n\t\terr = 0;\n\n\t\tswitch (createmode) {\n\t\tcase NFS3_CREATE_UNCHECKED:\n\t\t\tif (! S_ISREG(dchild->d_inode->i_mode))\n\t\t\t\terr = nfserr_exist;\n\t\t\telse if (truncp) {\n\t\t\t\t/* in nfsv4, we need to treat this case a little\n\t\t\t\t * differently.  we don't want to truncate the\n\t\t\t\t * file now; this would be wrong if the OPEN\n\t\t\t\t * fails for some other reason.  furthermore,\n\t\t\t\t * if the size is nonzero, we should ignore it\n\t\t\t\t * according to spec!\n\t\t\t\t */\n\t\t\t\t*truncp = (iap->ia_valid & ATTR_SIZE) && !iap->ia_size;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tiap->ia_valid &= ATTR_SIZE;\n\t\t\t\tgoto set_attr;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NFS3_CREATE_EXCLUSIVE:\n\t\t\tif (   dchild->d_inode->i_mtime.tv_sec == v_mtime\n\t\t\t    && dchild->d_inode->i_atime.tv_sec == v_atime\n\t\t\t    && dchild->d_inode->i_mode  == v_mode\n\t\t\t    && dchild->d_inode->i_size  == 0 )\n\t\t\t\tbreak;\n\t\t\t /* fallthru */\n\t\tcase NFS3_CREATE_GUARDED:\n\t\t\terr = nfserr_exist;\n\t\t}\n\t\tgoto out;\n\t}\n\n\thost_err = vfs_create(dirp, dchild, iap->ia_mode, NULL);\n\tif (host_err < 0)\n\t\tgoto out_nfserr;\n\n\tif (EX_ISSYNC(fhp->fh_export)) {\n\t\terr = nfserrno(nfsd_sync_dir(dentry));\n\t\t/* setattr will sync the child (or not) */\n\t}\n\n\tif (createmode == NFS3_CREATE_EXCLUSIVE) {\n\t\t/* Cram the verifier into atime/mtime/mode */\n\t\tiap->ia_valid = ATTR_MTIME|ATTR_ATIME\n\t\t\t| ATTR_MTIME_SET|ATTR_ATIME_SET\n\t\t\t| ATTR_MODE;\n\t\t/* XXX someone who knows this better please fix it for nsec */ \n\t\tiap->ia_mtime.tv_sec = v_mtime;\n\t\tiap->ia_atime.tv_sec = v_atime;\n\t\tiap->ia_mtime.tv_nsec = 0;\n\t\tiap->ia_atime.tv_nsec = 0;\n\t\tiap->ia_mode  = v_mode;\n\t}\n\n\t/* Set file attributes.\n\t * Mode has already been set but we might need to reset it\n\t * for CREATE_EXCLUSIVE\n\t * Irix appears to send along the gid when it tries to\n\t * implement setgid directories via NFS. Clear out all that cruft.\n\t */\n set_attr:\n\tif ((iap->ia_valid &= ~(ATTR_UID|ATTR_GID)) != 0) {\n \t\t__be32 err2 = nfsd_setattr(rqstp, resfhp, iap, 0, (time_t)0);\n\t\tif (err2)\n\t\t\terr = err2;\n\t}\n\n\t/*\n\t * Update the filehandle to get the new inode info.\n\t */\n\tif (!err)\n\t\terr = fh_update(resfhp);\n\n out:\n\tfh_unlock(fhp);\n\tif (dchild && !IS_ERR(dchild))\n\t\tdput(dchild);\n \treturn err;\n \n out_nfserr:\n\terr = nfserrno(host_err);\n\tgoto out;\n}",
        "func": "__be32\nnfsd_create_v3(struct svc_rqst *rqstp, struct svc_fh *fhp,\n\t\tchar *fname, int flen, struct iattr *iap,\n\t\tstruct svc_fh *resfhp, int createmode, u32 *verifier,\n\t        int *truncp, int *created)\n{\n\tstruct dentry\t*dentry, *dchild = NULL;\n\tstruct inode\t*dirp;\n\t__be32\t\terr;\n\tint\t\thost_err;\n\t__u32\t\tv_mtime=0, v_atime=0;\n\tint\t\tv_mode=0;\n\n\terr = nfserr_perm;\n\tif (!flen)\n\t\tgoto out;\n\terr = nfserr_exist;\n\tif (isdotent(fname, flen))\n\t\tgoto out;\n\tif (!(iap->ia_valid & ATTR_MODE))\n\t\tiap->ia_mode = 0;\n\terr = fh_verify(rqstp, fhp, S_IFDIR, MAY_CREATE);\n\tif (err)\n\t\tgoto out;\n\n\tdentry = fhp->fh_dentry;\n\tdirp = dentry->d_inode;\n\n\t/* Get all the sanity checks out of the way before\n\t * we lock the parent. */\n\terr = nfserr_notdir;\n\tif(!dirp->i_op || !dirp->i_op->lookup)\n\t\tgoto out;\n\tfh_lock_nested(fhp, I_MUTEX_PARENT);\n\n\t/*\n\t * Compose the response file handle.\n\t */\n\tdchild = lookup_one_len(fname, dentry, flen);\n\thost_err = PTR_ERR(dchild);\n\tif (IS_ERR(dchild))\n\t\tgoto out_nfserr;\n\n\terr = fh_compose(resfhp, fhp->fh_export, dchild, fhp);\n\tif (err)\n\t\tgoto out;\n\n\tif (createmode == NFS3_CREATE_EXCLUSIVE) {\n\t\t/* while the verifier would fit in mtime+atime,\n\t\t * solaris7 gets confused (bugid 4218508) if these have\n\t\t * the high bit set, so we use the mode as well\n\t\t */\n\t\tv_mtime = verifier[0]&0x7fffffff;\n\t\tv_atime = verifier[1]&0x7fffffff;\n\t\tv_mode  = S_IFREG\n\t\t\t| ((verifier[0]&0x80000000) >> (32-7)) /* u+x */\n\t\t\t| ((verifier[1]&0x80000000) >> (32-9)) /* u+r */\n\t\t\t;\n\t}\n\t\n\tif (dchild->d_inode) {\n\t\terr = 0;\n\n\t\tswitch (createmode) {\n\t\tcase NFS3_CREATE_UNCHECKED:\n\t\t\tif (! S_ISREG(dchild->d_inode->i_mode))\n\t\t\t\terr = nfserr_exist;\n\t\t\telse if (truncp) {\n\t\t\t\t/* in nfsv4, we need to treat this case a little\n\t\t\t\t * differently.  we don't want to truncate the\n\t\t\t\t * file now; this would be wrong if the OPEN\n\t\t\t\t * fails for some other reason.  furthermore,\n\t\t\t\t * if the size is nonzero, we should ignore it\n\t\t\t\t * according to spec!\n\t\t\t\t */\n\t\t\t\t*truncp = (iap->ia_valid & ATTR_SIZE) && !iap->ia_size;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tiap->ia_valid &= ATTR_SIZE;\n\t\t\t\tgoto set_attr;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase NFS3_CREATE_EXCLUSIVE:\n\t\t\tif (   dchild->d_inode->i_mtime.tv_sec == v_mtime\n\t\t\t    && dchild->d_inode->i_atime.tv_sec == v_atime\n\t\t\t    && dchild->d_inode->i_mode  == v_mode\n\t\t\t    && dchild->d_inode->i_size  == 0 )\n\t\t\t\tbreak;\n\t\t\t /* fallthru */\n\t\tcase NFS3_CREATE_GUARDED:\n\t\t\terr = nfserr_exist;\n\t\t}\n\t\tgoto out;\n\t}\n\n\thost_err = vfs_create(dirp, dchild, iap->ia_mode, NULL);\n\tif (host_err < 0)\n\t\tgoto out_nfserr;\n\tif (created)\n\t\t*created = 1;\n\n\tif (EX_ISSYNC(fhp->fh_export)) {\n\t\terr = nfserrno(nfsd_sync_dir(dentry));\n\t\t/* setattr will sync the child (or not) */\n\t}\n\n\tif (createmode == NFS3_CREATE_EXCLUSIVE) {\n\t\t/* Cram the verifier into atime/mtime/mode */\n\t\tiap->ia_valid = ATTR_MTIME|ATTR_ATIME\n\t\t\t| ATTR_MTIME_SET|ATTR_ATIME_SET\n\t\t\t| ATTR_MODE;\n\t\t/* XXX someone who knows this better please fix it for nsec */ \n\t\tiap->ia_mtime.tv_sec = v_mtime;\n\t\tiap->ia_atime.tv_sec = v_atime;\n\t\tiap->ia_mtime.tv_nsec = 0;\n\t\tiap->ia_atime.tv_nsec = 0;\n\t\tiap->ia_mode  = v_mode;\n\t}\n\n\t/* Set file attributes.\n\t * Mode has already been set but we might need to reset it\n\t * for CREATE_EXCLUSIVE\n\t * Irix appears to send along the gid when it tries to\n\t * implement setgid directories via NFS. Clear out all that cruft.\n\t */\n set_attr:\n\tif ((iap->ia_valid &= ~(ATTR_UID|ATTR_GID)) != 0) {\n \t\t__be32 err2 = nfsd_setattr(rqstp, resfhp, iap, 0, (time_t)0);\n\t\tif (err2)\n\t\t\terr = err2;\n\t}\n\n\t/*\n\t * Update the filehandle to get the new inode info.\n\t */\n\tif (!err)\n\t\terr = fh_update(resfhp);\n\n out:\n\tfh_unlock(fhp);\n\tif (dchild && !IS_ERR(dchild))\n\t\tdput(dchild);\n \treturn err;\n \n out_nfserr:\n\terr = nfserrno(host_err);\n\tgoto out;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,7 @@\n nfsd_create_v3(struct svc_rqst *rqstp, struct svc_fh *fhp,\n \t\tchar *fname, int flen, struct iattr *iap,\n \t\tstruct svc_fh *resfhp, int createmode, u32 *verifier,\n-\t        int *truncp)\n+\t        int *truncp, int *created)\n {\n \tstruct dentry\t*dentry, *dchild = NULL;\n \tstruct inode\t*dirp;\n@@ -96,6 +96,8 @@\n \thost_err = vfs_create(dirp, dchild, iap->ia_mode, NULL);\n \tif (host_err < 0)\n \t\tgoto out_nfserr;\n+\tif (created)\n+\t\t*created = 1;\n \n \tif (EX_ISSYNC(fhp->fh_export)) {\n \t\terr = nfserrno(nfsd_sync_dir(dentry));",
        "diff_line_info": {
            "deleted_lines": [
                "\t        int *truncp)"
            ],
            "added_lines": [
                "\t        int *truncp, int *created)",
                "\tif (created)",
                "\t\t*created = 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3286",
        "func_name": "torvalds/linux/nfsd3_proc_create",
        "description": "NFSv4 in the Linux kernel 2.6.18, and possibly other versions, does not properly clean up an inode when an O_EXCL create fails, which causes files to be created with insecure settings such as setuid bits, and possibly allows local users to gain privileges, related to the execution of the do_open_permission function even when a create fails.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=81ac95c5",
        "commit_title": "In the case where an open creates the file, we shouldn't be rechecking",
        "commit_text": "permissions to open the file; the open succeeds regardless of what the new file's mode bits say.  This patch fixes the problem, but only by introducing yet another parameter to nfsd_create_v3.  This is ugly.  This will be fixed by later patches.  Cc: Jeff Garzik <jeff@garzik.org> ",
        "func_before": "static __be32\nnfsd3_proc_create(struct svc_rqst *rqstp, struct nfsd3_createargs *argp,\n\t\t\t\t\t  struct nfsd3_diropres   *resp)\n{\n\tsvc_fh\t\t*dirfhp, *newfhp = NULL;\n\tstruct iattr\t*attr;\n\t__be32\t\tnfserr;\n\n\tdprintk(\"nfsd: CREATE(3)   %s %.*s\\n\",\n\t\t\t\tSVCFH_fmt(&argp->fh),\n\t\t\t\targp->len,\n\t\t\t\targp->name);\n\n\tdirfhp = fh_copy(&resp->dirfh, &argp->fh);\n\tnewfhp = fh_init(&resp->fh, NFS3_FHSIZE);\n\tattr   = &argp->attrs;\n\n\t/* Get the directory inode */\n\tnfserr = fh_verify(rqstp, dirfhp, S_IFDIR, MAY_CREATE);\n\tif (nfserr)\n\t\tRETURN_STATUS(nfserr);\n\n\t/* Unfudge the mode bits */\n\tattr->ia_mode &= ~S_IFMT;\n\tif (!(attr->ia_valid & ATTR_MODE)) { \n\t\tattr->ia_valid |= ATTR_MODE;\n\t\tattr->ia_mode = S_IFREG;\n\t} else {\n\t\tattr->ia_mode = (attr->ia_mode & ~S_IFMT) | S_IFREG;\n\t}\n\n\t/* Now create the file and set attributes */\n\tnfserr = nfsd_create_v3(rqstp, dirfhp, argp->name, argp->len,\n\t\t\t\tattr, newfhp,\n\t\t\t\targp->createmode, argp->verf, NULL);\n\n\tRETURN_STATUS(nfserr);\n}",
        "func": "static __be32\nnfsd3_proc_create(struct svc_rqst *rqstp, struct nfsd3_createargs *argp,\n\t\t\t\t\t  struct nfsd3_diropres   *resp)\n{\n\tsvc_fh\t\t*dirfhp, *newfhp = NULL;\n\tstruct iattr\t*attr;\n\t__be32\t\tnfserr;\n\n\tdprintk(\"nfsd: CREATE(3)   %s %.*s\\n\",\n\t\t\t\tSVCFH_fmt(&argp->fh),\n\t\t\t\targp->len,\n\t\t\t\targp->name);\n\n\tdirfhp = fh_copy(&resp->dirfh, &argp->fh);\n\tnewfhp = fh_init(&resp->fh, NFS3_FHSIZE);\n\tattr   = &argp->attrs;\n\n\t/* Get the directory inode */\n\tnfserr = fh_verify(rqstp, dirfhp, S_IFDIR, MAY_CREATE);\n\tif (nfserr)\n\t\tRETURN_STATUS(nfserr);\n\n\t/* Unfudge the mode bits */\n\tattr->ia_mode &= ~S_IFMT;\n\tif (!(attr->ia_valid & ATTR_MODE)) { \n\t\tattr->ia_valid |= ATTR_MODE;\n\t\tattr->ia_mode = S_IFREG;\n\t} else {\n\t\tattr->ia_mode = (attr->ia_mode & ~S_IFMT) | S_IFREG;\n\t}\n\n\t/* Now create the file and set attributes */\n\tnfserr = nfsd_create_v3(rqstp, dirfhp, argp->name, argp->len,\n\t\t\t\tattr, newfhp,\n\t\t\t\targp->createmode, argp->verf, NULL, NULL);\n\n\tRETURN_STATUS(nfserr);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -32,7 +32,7 @@\n \t/* Now create the file and set attributes */\n \tnfserr = nfsd_create_v3(rqstp, dirfhp, argp->name, argp->len,\n \t\t\t\tattr, newfhp,\n-\t\t\t\targp->createmode, argp->verf, NULL);\n+\t\t\t\targp->createmode, argp->verf, NULL, NULL);\n \n \tRETURN_STATUS(nfserr);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\targp->createmode, argp->verf, NULL);"
            ],
            "added_lines": [
                "\t\t\t\targp->createmode, argp->verf, NULL, NULL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-3722",
        "func_name": "torvalds/linux/handle_dr",
        "description": "The handle_dr function in arch/x86/kvm/vmx.c in the KVM subsystem in the Linux kernel before 2.6.31.1 does not properly verify the Current Privilege Level (CPL) before accessing a debug register, which allows guest OS users to cause a denial of service (trap) on the host OS via a crafted application.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=0a79b009525b160081d75cef5dbf45817956acf2",
        "commit_title": "Debug registers may only be accessed from cpl 0.  Unfortunately, vmx will",
        "commit_text": "code to emulate the instruction even though it was issued from guest userspace, possibly leading to an unexpected trap later.  Cc: stable@kernel.org ",
        "func_before": "static int handle_dr(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run)\n{\n\tunsigned long exit_qualification;\n\tunsigned long val;\n\tint dr, reg;\n\n\tdr = vmcs_readl(GUEST_DR7);\n\tif (dr & DR7_GD) {\n\t\t/*\n\t\t * As the vm-exit takes precedence over the debug trap, we\n\t\t * need to emulate the latter, either for the host or the\n\t\t * guest debugging itself.\n\t\t */\n\t\tif (vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP) {\n\t\t\tkvm_run->debug.arch.dr6 = vcpu->arch.dr6;\n\t\t\tkvm_run->debug.arch.dr7 = dr;\n\t\t\tkvm_run->debug.arch.pc =\n\t\t\t\tvmcs_readl(GUEST_CS_BASE) +\n\t\t\t\tvmcs_readl(GUEST_RIP);\n\t\t\tkvm_run->debug.arch.exception = DB_VECTOR;\n\t\t\tkvm_run->exit_reason = KVM_EXIT_DEBUG;\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tvcpu->arch.dr7 &= ~DR7_GD;\n\t\t\tvcpu->arch.dr6 |= DR6_BD;\n\t\t\tvmcs_writel(GUEST_DR7, vcpu->arch.dr7);\n\t\t\tkvm_queue_exception(vcpu, DB_VECTOR);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\texit_qualification = vmcs_readl(EXIT_QUALIFICATION);\n\tdr = exit_qualification & DEBUG_REG_ACCESS_NUM;\n\treg = DEBUG_REG_ACCESS_REG(exit_qualification);\n\tif (exit_qualification & TYPE_MOV_FROM_DR) {\n\t\tswitch (dr) {\n\t\tcase 0 ... 3:\n\t\t\tval = vcpu->arch.db[dr];\n\t\t\tbreak;\n\t\tcase 6:\n\t\t\tval = vcpu->arch.dr6;\n\t\t\tbreak;\n\t\tcase 7:\n\t\t\tval = vcpu->arch.dr7;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tval = 0;\n\t\t}\n\t\tkvm_register_write(vcpu, reg, val);\n\t} else {\n\t\tval = vcpu->arch.regs[reg];\n\t\tswitch (dr) {\n\t\tcase 0 ... 3:\n\t\t\tvcpu->arch.db[dr] = val;\n\t\t\tif (!(vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP))\n\t\t\t\tvcpu->arch.eff_db[dr] = val;\n\t\t\tbreak;\n\t\tcase 4 ... 5:\n\t\t\tif (vcpu->arch.cr4 & X86_CR4_DE)\n\t\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\t\tbreak;\n\t\tcase 6:\n\t\t\tif (val & 0xffffffff00000000ULL) {\n\t\t\t\tkvm_queue_exception(vcpu, GP_VECTOR);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvcpu->arch.dr6 = (val & DR6_VOLATILE) | DR6_FIXED_1;\n\t\t\tbreak;\n\t\tcase 7:\n\t\t\tif (val & 0xffffffff00000000ULL) {\n\t\t\t\tkvm_queue_exception(vcpu, GP_VECTOR);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvcpu->arch.dr7 = (val & DR7_VOLATILE) | DR7_FIXED_1;\n\t\t\tif (!(vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP)) {\n\t\t\t\tvmcs_writel(GUEST_DR7, vcpu->arch.dr7);\n\t\t\t\tvcpu->arch.switch_db_regs =\n\t\t\t\t\t(val & DR7_BP_EN_MASK);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tskip_emulated_instruction(vcpu);\n\treturn 1;\n}",
        "func": "static int handle_dr(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run)\n{\n\tunsigned long exit_qualification;\n\tunsigned long val;\n\tint dr, reg;\n\n\tif (!kvm_require_cpl(vcpu, 0))\n\t\treturn 1;\n\tdr = vmcs_readl(GUEST_DR7);\n\tif (dr & DR7_GD) {\n\t\t/*\n\t\t * As the vm-exit takes precedence over the debug trap, we\n\t\t * need to emulate the latter, either for the host or the\n\t\t * guest debugging itself.\n\t\t */\n\t\tif (vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP) {\n\t\t\tkvm_run->debug.arch.dr6 = vcpu->arch.dr6;\n\t\t\tkvm_run->debug.arch.dr7 = dr;\n\t\t\tkvm_run->debug.arch.pc =\n\t\t\t\tvmcs_readl(GUEST_CS_BASE) +\n\t\t\t\tvmcs_readl(GUEST_RIP);\n\t\t\tkvm_run->debug.arch.exception = DB_VECTOR;\n\t\t\tkvm_run->exit_reason = KVM_EXIT_DEBUG;\n\t\t\treturn 0;\n\t\t} else {\n\t\t\tvcpu->arch.dr7 &= ~DR7_GD;\n\t\t\tvcpu->arch.dr6 |= DR6_BD;\n\t\t\tvmcs_writel(GUEST_DR7, vcpu->arch.dr7);\n\t\t\tkvm_queue_exception(vcpu, DB_VECTOR);\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\texit_qualification = vmcs_readl(EXIT_QUALIFICATION);\n\tdr = exit_qualification & DEBUG_REG_ACCESS_NUM;\n\treg = DEBUG_REG_ACCESS_REG(exit_qualification);\n\tif (exit_qualification & TYPE_MOV_FROM_DR) {\n\t\tswitch (dr) {\n\t\tcase 0 ... 3:\n\t\t\tval = vcpu->arch.db[dr];\n\t\t\tbreak;\n\t\tcase 6:\n\t\t\tval = vcpu->arch.dr6;\n\t\t\tbreak;\n\t\tcase 7:\n\t\t\tval = vcpu->arch.dr7;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tval = 0;\n\t\t}\n\t\tkvm_register_write(vcpu, reg, val);\n\t} else {\n\t\tval = vcpu->arch.regs[reg];\n\t\tswitch (dr) {\n\t\tcase 0 ... 3:\n\t\t\tvcpu->arch.db[dr] = val;\n\t\t\tif (!(vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP))\n\t\t\t\tvcpu->arch.eff_db[dr] = val;\n\t\t\tbreak;\n\t\tcase 4 ... 5:\n\t\t\tif (vcpu->arch.cr4 & X86_CR4_DE)\n\t\t\t\tkvm_queue_exception(vcpu, UD_VECTOR);\n\t\t\tbreak;\n\t\tcase 6:\n\t\t\tif (val & 0xffffffff00000000ULL) {\n\t\t\t\tkvm_queue_exception(vcpu, GP_VECTOR);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvcpu->arch.dr6 = (val & DR6_VOLATILE) | DR6_FIXED_1;\n\t\t\tbreak;\n\t\tcase 7:\n\t\t\tif (val & 0xffffffff00000000ULL) {\n\t\t\t\tkvm_queue_exception(vcpu, GP_VECTOR);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tvcpu->arch.dr7 = (val & DR7_VOLATILE) | DR7_FIXED_1;\n\t\t\tif (!(vcpu->guest_debug & KVM_GUESTDBG_USE_HW_BP)) {\n\t\t\t\tvmcs_writel(GUEST_DR7, vcpu->arch.dr7);\n\t\t\t\tvcpu->arch.switch_db_regs =\n\t\t\t\t\t(val & DR7_BP_EN_MASK);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tskip_emulated_instruction(vcpu);\n\treturn 1;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -4,6 +4,8 @@\n \tunsigned long val;\n \tint dr, reg;\n \n+\tif (!kvm_require_cpl(vcpu, 0))\n+\t\treturn 1;\n \tdr = vmcs_readl(GUEST_DR7);\n \tif (dr & DR7_GD) {\n \t\t/*",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (!kvm_require_cpl(vcpu, 0))",
                "\t\treturn 1;"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4131",
        "func_name": "kernel/git/tytso/ext4/ext4_ioctl",
        "description": "The EXT4_IOC_MOVE_EXT (aka move extents) ioctl implementation in the ext4 filesystem in the Linux kernel before 2.6.32-git6 allows local users to overwrite arbitrary files via a crafted request, related to insufficient checks for file permissions.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/tytso/ext4.git;a=commit;h=4a58579b9e4e2a35d57e6c9c8483e52f6f1b7fd6",
        "commit_title": "This patch fixes three problems in the handling of the",
        "commit_text": "EXT4_IOC_MOVE_EXT ioctl:  1. In current EXT4_IOC_MOVE_EXT, there are read access mode checks for original and donor files, but they allow the illegal write access to donor file, since donor file is overwritten by original file data.  To fix this problem, change access mode checks of original (r->r/w) and donor (r->w) files.  2.  Disallow the use of donor files that have a setuid or setgid bits.  3.  Call mnt_want_write() and mnt_drop_write() before and after ext4_move_extents() calling to get write access to a mount.  ",
        "func_before": "long ext4_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)\n{\n\tstruct inode *inode = filp->f_dentry->d_inode;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tunsigned int flags;\n\n\text4_debug(\"cmd = %u, arg = %lu\\n\", cmd, arg);\n\n\tswitch (cmd) {\n\tcase EXT4_IOC_GETFLAGS:\n\t\text4_get_inode_flags(ei);\n\t\tflags = ei->i_flags & EXT4_FL_USER_VISIBLE;\n\t\treturn put_user(flags, (int __user *) arg);\n\tcase EXT4_IOC_SETFLAGS: {\n\t\thandle_t *handle = NULL;\n\t\tint err, migrate = 0;\n\t\tstruct ext4_iloc iloc;\n\t\tunsigned int oldflags;\n\t\tunsigned int jflag;\n\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EACCES;\n\n\t\tif (get_user(flags, (int __user *) arg))\n\t\t\treturn -EFAULT;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tflags = ext4_mask_flags(inode->i_mode, flags);\n\n\t\terr = -EPERM;\n\t\tmutex_lock(&inode->i_mutex);\n\t\t/* Is it quota file? Do not allow user to mess with it */\n\t\tif (IS_NOQUOTA(inode))\n\t\t\tgoto flags_out;\n\n\t\toldflags = ei->i_flags;\n\n\t\t/* The JOURNAL_DATA flag is modifiable only by root */\n\t\tjflag = flags & EXT4_JOURNAL_DATA_FL;\n\n\t\t/*\n\t\t * The IMMUTABLE and APPEND_ONLY flags can only be changed by\n\t\t * the relevant capability.\n\t\t *\n\t\t * This test looks nicer. Thanks to Pauline Middelink\n\t\t */\n\t\tif ((flags ^ oldflags) & (EXT4_APPEND_FL | EXT4_IMMUTABLE_FL)) {\n\t\t\tif (!capable(CAP_LINUX_IMMUTABLE))\n\t\t\t\tgoto flags_out;\n\t\t}\n\n\t\t/*\n\t\t * The JOURNAL_DATA flag can only be changed by\n\t\t * the relevant capability.\n\t\t */\n\t\tif ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL)) {\n\t\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\t\tgoto flags_out;\n\t\t}\n\t\tif (oldflags & EXT4_EXTENTS_FL) {\n\t\t\t/* We don't support clearning extent flags */\n\t\t\tif (!(flags & EXT4_EXTENTS_FL)) {\n\t\t\t\terr = -EOPNOTSUPP;\n\t\t\t\tgoto flags_out;\n\t\t\t}\n\t\t} else if (flags & EXT4_EXTENTS_FL) {\n\t\t\t/* migrate the file */\n\t\t\tmigrate = 1;\n\t\t\tflags &= ~EXT4_EXTENTS_FL;\n\t\t}\n\n\t\thandle = ext4_journal_start(inode, 1);\n\t\tif (IS_ERR(handle)) {\n\t\t\terr = PTR_ERR(handle);\n\t\t\tgoto flags_out;\n\t\t}\n\t\tif (IS_SYNC(inode))\n\t\t\text4_handle_sync(handle);\n\t\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\t\tif (err)\n\t\t\tgoto flags_err;\n\n\t\tflags = flags & EXT4_FL_USER_MODIFIABLE;\n\t\tflags |= oldflags & ~EXT4_FL_USER_MODIFIABLE;\n\t\tei->i_flags = flags;\n\n\t\text4_set_inode_flags(inode);\n\t\tinode->i_ctime = ext4_current_time(inode);\n\n\t\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\nflags_err:\n\t\text4_journal_stop(handle);\n\t\tif (err)\n\t\t\tgoto flags_out;\n\n\t\tif ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL))\n\t\t\terr = ext4_change_inode_journal_flag(inode, jflag);\n\t\tif (err)\n\t\t\tgoto flags_out;\n\t\tif (migrate)\n\t\t\terr = ext4_ext_migrate(inode);\nflags_out:\n\t\tmutex_unlock(&inode->i_mutex);\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n\tcase EXT4_IOC_GETVERSION:\n\tcase EXT4_IOC_GETVERSION_OLD:\n\t\treturn put_user(inode->i_generation, (int __user *) arg);\n\tcase EXT4_IOC_SETVERSION:\n\tcase EXT4_IOC_SETVERSION_OLD: {\n\t\thandle_t *handle;\n\t\tstruct ext4_iloc iloc;\n\t\t__u32 generation;\n\t\tint err;\n\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EPERM;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (get_user(generation, (int __user *) arg)) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto setversion_out;\n\t\t}\n\n\t\thandle = ext4_journal_start(inode, 1);\n\t\tif (IS_ERR(handle)) {\n\t\t\terr = PTR_ERR(handle);\n\t\t\tgoto setversion_out;\n\t\t}\n\t\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\t\tif (err == 0) {\n\t\t\tinode->i_ctime = ext4_current_time(inode);\n\t\t\tinode->i_generation = generation;\n\t\t\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\t\t}\n\t\text4_journal_stop(handle);\nsetversion_out:\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n#ifdef CONFIG_JBD2_DEBUG\n\tcase EXT4_IOC_WAIT_FOR_READONLY:\n\t\t/*\n\t\t * This is racy - by the time we're woken up and running,\n\t\t * the superblock could be released.  And the module could\n\t\t * have been unloaded.  So sue me.\n\t\t *\n\t\t * Returns 1 if it slept, else zero.\n\t\t */\n\t\t{\n\t\t\tstruct super_block *sb = inode->i_sb;\n\t\t\tDECLARE_WAITQUEUE(wait, current);\n\t\t\tint ret = 0;\n\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\tadd_wait_queue(&EXT4_SB(sb)->ro_wait_queue, &wait);\n\t\t\tif (timer_pending(&EXT4_SB(sb)->turn_ro_timer)) {\n\t\t\t\tschedule();\n\t\t\t\tret = 1;\n\t\t\t}\n\t\t\tremove_wait_queue(&EXT4_SB(sb)->ro_wait_queue, &wait);\n\t\t\treturn ret;\n\t\t}\n#endif\n\tcase EXT4_IOC_GROUP_EXTEND: {\n\t\text4_fsblk_t n_blocks_count;\n\t\tstruct super_block *sb = inode->i_sb;\n\t\tint err, err2=0;\n\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (get_user(n_blocks_count, (__u32 __user *)arg))\n\t\t\treturn -EFAULT;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = ext4_group_extend(sb, EXT4_SB(sb)->s_es, n_blocks_count);\n\t\tif (EXT4_SB(sb)->s_journal) {\n\t\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\t\terr2 = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\t}\n\t\tif (err == 0)\n\t\t\terr = err2;\n\t\tmnt_drop_write(filp->f_path.mnt);\n\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_MOVE_EXT: {\n\t\tstruct move_extent me;\n\t\tstruct file *donor_filp;\n\t\tint err;\n\n\t\tif (copy_from_user(&me,\n\t\t\t(struct move_extent __user *)arg, sizeof(me)))\n\t\t\treturn -EFAULT;\n\n\t\tdonor_filp = fget(me.donor_fd);\n\t\tif (!donor_filp)\n\t\t\treturn -EBADF;\n\n\t\tif (!capable(CAP_DAC_OVERRIDE)) {\n\t\t\tif ((current->real_cred->fsuid != inode->i_uid) ||\n\t\t\t\t!(inode->i_mode & S_IRUSR) ||\n\t\t\t\t!(donor_filp->f_dentry->d_inode->i_mode &\n\t\t\t\tS_IRUSR)) {\n\t\t\t\tfput(donor_filp);\n\t\t\t\treturn -EACCES;\n\t\t\t}\n\t\t}\n\n\t\tme.moved_len = 0;\n\t\terr = ext4_move_extents(filp, donor_filp, me.orig_start,\n\t\t\t\t\tme.donor_start, me.len, &me.moved_len);\n\t\tfput(donor_filp);\n\n\t\tif (copy_to_user((struct move_extent *)arg, &me, sizeof(me)))\n\t\t\treturn -EFAULT;\n\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_GROUP_ADD: {\n\t\tstruct ext4_new_group_data input;\n\t\tstruct super_block *sb = inode->i_sb;\n\t\tint err, err2=0;\n\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&input, (struct ext4_new_group_input __user *)arg,\n\t\t\t\tsizeof(input)))\n\t\t\treturn -EFAULT;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = ext4_group_add(sb, &input);\n\t\tif (EXT4_SB(sb)->s_journal) {\n\t\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\t\terr2 = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\t}\n\t\tif (err == 0)\n\t\t\terr = err2;\n\t\tmnt_drop_write(filp->f_path.mnt);\n\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_MIGRATE:\n\t{\n\t\tint err;\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EACCES;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\t\t/*\n\t\t * inode_mutex prevent write and truncate on the file.\n\t\t * Read still goes through. We take i_data_sem in\n\t\t * ext4_ext_swap_inode_data before we switch the\n\t\t * inode format to prevent read.\n\t\t */\n\t\tmutex_lock(&(inode->i_mutex));\n\t\terr = ext4_ext_migrate(inode);\n\t\tmutex_unlock(&(inode->i_mutex));\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_ALLOC_DA_BLKS:\n\t{\n\t\tint err;\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EACCES;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = ext4_alloc_da_blocks(inode);\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n}",
        "func": "long ext4_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)\n{\n\tstruct inode *inode = filp->f_dentry->d_inode;\n\tstruct ext4_inode_info *ei = EXT4_I(inode);\n\tunsigned int flags;\n\n\text4_debug(\"cmd = %u, arg = %lu\\n\", cmd, arg);\n\n\tswitch (cmd) {\n\tcase EXT4_IOC_GETFLAGS:\n\t\text4_get_inode_flags(ei);\n\t\tflags = ei->i_flags & EXT4_FL_USER_VISIBLE;\n\t\treturn put_user(flags, (int __user *) arg);\n\tcase EXT4_IOC_SETFLAGS: {\n\t\thandle_t *handle = NULL;\n\t\tint err, migrate = 0;\n\t\tstruct ext4_iloc iloc;\n\t\tunsigned int oldflags;\n\t\tunsigned int jflag;\n\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EACCES;\n\n\t\tif (get_user(flags, (int __user *) arg))\n\t\t\treturn -EFAULT;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tflags = ext4_mask_flags(inode->i_mode, flags);\n\n\t\terr = -EPERM;\n\t\tmutex_lock(&inode->i_mutex);\n\t\t/* Is it quota file? Do not allow user to mess with it */\n\t\tif (IS_NOQUOTA(inode))\n\t\t\tgoto flags_out;\n\n\t\toldflags = ei->i_flags;\n\n\t\t/* The JOURNAL_DATA flag is modifiable only by root */\n\t\tjflag = flags & EXT4_JOURNAL_DATA_FL;\n\n\t\t/*\n\t\t * The IMMUTABLE and APPEND_ONLY flags can only be changed by\n\t\t * the relevant capability.\n\t\t *\n\t\t * This test looks nicer. Thanks to Pauline Middelink\n\t\t */\n\t\tif ((flags ^ oldflags) & (EXT4_APPEND_FL | EXT4_IMMUTABLE_FL)) {\n\t\t\tif (!capable(CAP_LINUX_IMMUTABLE))\n\t\t\t\tgoto flags_out;\n\t\t}\n\n\t\t/*\n\t\t * The JOURNAL_DATA flag can only be changed by\n\t\t * the relevant capability.\n\t\t */\n\t\tif ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL)) {\n\t\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\t\tgoto flags_out;\n\t\t}\n\t\tif (oldflags & EXT4_EXTENTS_FL) {\n\t\t\t/* We don't support clearning extent flags */\n\t\t\tif (!(flags & EXT4_EXTENTS_FL)) {\n\t\t\t\terr = -EOPNOTSUPP;\n\t\t\t\tgoto flags_out;\n\t\t\t}\n\t\t} else if (flags & EXT4_EXTENTS_FL) {\n\t\t\t/* migrate the file */\n\t\t\tmigrate = 1;\n\t\t\tflags &= ~EXT4_EXTENTS_FL;\n\t\t}\n\n\t\thandle = ext4_journal_start(inode, 1);\n\t\tif (IS_ERR(handle)) {\n\t\t\terr = PTR_ERR(handle);\n\t\t\tgoto flags_out;\n\t\t}\n\t\tif (IS_SYNC(inode))\n\t\t\text4_handle_sync(handle);\n\t\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\t\tif (err)\n\t\t\tgoto flags_err;\n\n\t\tflags = flags & EXT4_FL_USER_MODIFIABLE;\n\t\tflags |= oldflags & ~EXT4_FL_USER_MODIFIABLE;\n\t\tei->i_flags = flags;\n\n\t\text4_set_inode_flags(inode);\n\t\tinode->i_ctime = ext4_current_time(inode);\n\n\t\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\nflags_err:\n\t\text4_journal_stop(handle);\n\t\tif (err)\n\t\t\tgoto flags_out;\n\n\t\tif ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL))\n\t\t\terr = ext4_change_inode_journal_flag(inode, jflag);\n\t\tif (err)\n\t\t\tgoto flags_out;\n\t\tif (migrate)\n\t\t\terr = ext4_ext_migrate(inode);\nflags_out:\n\t\tmutex_unlock(&inode->i_mutex);\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n\tcase EXT4_IOC_GETVERSION:\n\tcase EXT4_IOC_GETVERSION_OLD:\n\t\treturn put_user(inode->i_generation, (int __user *) arg);\n\tcase EXT4_IOC_SETVERSION:\n\tcase EXT4_IOC_SETVERSION_OLD: {\n\t\thandle_t *handle;\n\t\tstruct ext4_iloc iloc;\n\t\t__u32 generation;\n\t\tint err;\n\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EPERM;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\t\tif (get_user(generation, (int __user *) arg)) {\n\t\t\terr = -EFAULT;\n\t\t\tgoto setversion_out;\n\t\t}\n\n\t\thandle = ext4_journal_start(inode, 1);\n\t\tif (IS_ERR(handle)) {\n\t\t\terr = PTR_ERR(handle);\n\t\t\tgoto setversion_out;\n\t\t}\n\t\terr = ext4_reserve_inode_write(handle, inode, &iloc);\n\t\tif (err == 0) {\n\t\t\tinode->i_ctime = ext4_current_time(inode);\n\t\t\tinode->i_generation = generation;\n\t\t\terr = ext4_mark_iloc_dirty(handle, inode, &iloc);\n\t\t}\n\t\text4_journal_stop(handle);\nsetversion_out:\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n#ifdef CONFIG_JBD2_DEBUG\n\tcase EXT4_IOC_WAIT_FOR_READONLY:\n\t\t/*\n\t\t * This is racy - by the time we're woken up and running,\n\t\t * the superblock could be released.  And the module could\n\t\t * have been unloaded.  So sue me.\n\t\t *\n\t\t * Returns 1 if it slept, else zero.\n\t\t */\n\t\t{\n\t\t\tstruct super_block *sb = inode->i_sb;\n\t\t\tDECLARE_WAITQUEUE(wait, current);\n\t\t\tint ret = 0;\n\n\t\t\tset_current_state(TASK_INTERRUPTIBLE);\n\t\t\tadd_wait_queue(&EXT4_SB(sb)->ro_wait_queue, &wait);\n\t\t\tif (timer_pending(&EXT4_SB(sb)->turn_ro_timer)) {\n\t\t\t\tschedule();\n\t\t\t\tret = 1;\n\t\t\t}\n\t\t\tremove_wait_queue(&EXT4_SB(sb)->ro_wait_queue, &wait);\n\t\t\treturn ret;\n\t\t}\n#endif\n\tcase EXT4_IOC_GROUP_EXTEND: {\n\t\text4_fsblk_t n_blocks_count;\n\t\tstruct super_block *sb = inode->i_sb;\n\t\tint err, err2=0;\n\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (get_user(n_blocks_count, (__u32 __user *)arg))\n\t\t\treturn -EFAULT;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = ext4_group_extend(sb, EXT4_SB(sb)->s_es, n_blocks_count);\n\t\tif (EXT4_SB(sb)->s_journal) {\n\t\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\t\terr2 = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\t}\n\t\tif (err == 0)\n\t\t\terr = err2;\n\t\tmnt_drop_write(filp->f_path.mnt);\n\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_MOVE_EXT: {\n\t\tstruct move_extent me;\n\t\tstruct file *donor_filp;\n\t\tint err;\n\n\t\tif (!(filp->f_mode & FMODE_READ) ||\n\t\t    !(filp->f_mode & FMODE_WRITE))\n\t\t\treturn -EBADF;\n\n\t\tif (copy_from_user(&me,\n\t\t\t(struct move_extent __user *)arg, sizeof(me)))\n\t\t\treturn -EFAULT;\n\t\tme.moved_len = 0;\n\n\t\tdonor_filp = fget(me.donor_fd);\n\t\tif (!donor_filp)\n\t\t\treturn -EBADF;\n\n\t\tif (!(donor_filp->f_mode & FMODE_WRITE)) {\n\t\t\terr = -EBADF;\n\t\t\tgoto mext_out;\n\t\t}\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\tgoto mext_out;\n\n\t\terr = ext4_move_extents(filp, donor_filp, me.orig_start,\n\t\t\t\t\tme.donor_start, me.len, &me.moved_len);\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\tif (me.moved_len > 0)\n\t\t\tfile_remove_suid(donor_filp);\n\n\t\tif (copy_to_user((struct move_extent *)arg, &me, sizeof(me)))\n\t\t\terr = -EFAULT;\nmext_out:\n\t\tfput(donor_filp);\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_GROUP_ADD: {\n\t\tstruct ext4_new_group_data input;\n\t\tstruct super_block *sb = inode->i_sb;\n\t\tint err, err2=0;\n\n\t\tif (!capable(CAP_SYS_RESOURCE))\n\t\t\treturn -EPERM;\n\n\t\tif (copy_from_user(&input, (struct ext4_new_group_input __user *)arg,\n\t\t\t\tsizeof(input)))\n\t\t\treturn -EFAULT;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\terr = ext4_group_add(sb, &input);\n\t\tif (EXT4_SB(sb)->s_journal) {\n\t\t\tjbd2_journal_lock_updates(EXT4_SB(sb)->s_journal);\n\t\t\terr2 = jbd2_journal_flush(EXT4_SB(sb)->s_journal);\n\t\t\tjbd2_journal_unlock_updates(EXT4_SB(sb)->s_journal);\n\t\t}\n\t\tif (err == 0)\n\t\t\terr = err2;\n\t\tmnt_drop_write(filp->f_path.mnt);\n\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_MIGRATE:\n\t{\n\t\tint err;\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EACCES;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\t\t/*\n\t\t * inode_mutex prevent write and truncate on the file.\n\t\t * Read still goes through. We take i_data_sem in\n\t\t * ext4_ext_swap_inode_data before we switch the\n\t\t * inode format to prevent read.\n\t\t */\n\t\tmutex_lock(&(inode->i_mutex));\n\t\terr = ext4_ext_migrate(inode);\n\t\tmutex_unlock(&(inode->i_mutex));\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n\n\tcase EXT4_IOC_ALLOC_DA_BLKS:\n\t{\n\t\tint err;\n\t\tif (!is_owner_or_cap(inode))\n\t\t\treturn -EACCES;\n\n\t\terr = mnt_want_write(filp->f_path.mnt);\n\t\tif (err)\n\t\t\treturn err;\n\t\terr = ext4_alloc_da_blocks(inode);\n\t\tmnt_drop_write(filp->f_path.mnt);\n\t\treturn err;\n\t}\n\n\tdefault:\n\t\treturn -ENOTTY;\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -201,32 +201,38 @@\n \t\tstruct file *donor_filp;\n \t\tint err;\n \n+\t\tif (!(filp->f_mode & FMODE_READ) ||\n+\t\t    !(filp->f_mode & FMODE_WRITE))\n+\t\t\treturn -EBADF;\n+\n \t\tif (copy_from_user(&me,\n \t\t\t(struct move_extent __user *)arg, sizeof(me)))\n \t\t\treturn -EFAULT;\n+\t\tme.moved_len = 0;\n \n \t\tdonor_filp = fget(me.donor_fd);\n \t\tif (!donor_filp)\n \t\t\treturn -EBADF;\n \n-\t\tif (!capable(CAP_DAC_OVERRIDE)) {\n-\t\t\tif ((current->real_cred->fsuid != inode->i_uid) ||\n-\t\t\t\t!(inode->i_mode & S_IRUSR) ||\n-\t\t\t\t!(donor_filp->f_dentry->d_inode->i_mode &\n-\t\t\t\tS_IRUSR)) {\n-\t\t\t\tfput(donor_filp);\n-\t\t\t\treturn -EACCES;\n-\t\t\t}\n-\t\t}\n-\n-\t\tme.moved_len = 0;\n+\t\tif (!(donor_filp->f_mode & FMODE_WRITE)) {\n+\t\t\terr = -EBADF;\n+\t\t\tgoto mext_out;\n+\t\t}\n+\n+\t\terr = mnt_want_write(filp->f_path.mnt);\n+\t\tif (err)\n+\t\t\tgoto mext_out;\n+\n \t\terr = ext4_move_extents(filp, donor_filp, me.orig_start,\n \t\t\t\t\tme.donor_start, me.len, &me.moved_len);\n+\t\tmnt_drop_write(filp->f_path.mnt);\n+\t\tif (me.moved_len > 0)\n+\t\t\tfile_remove_suid(donor_filp);\n+\n+\t\tif (copy_to_user((struct move_extent *)arg, &me, sizeof(me)))\n+\t\t\terr = -EFAULT;\n+mext_out:\n \t\tfput(donor_filp);\n-\n-\t\tif (copy_to_user((struct move_extent *)arg, &me, sizeof(me)))\n-\t\t\treturn -EFAULT;\n-\n \t\treturn err;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (!capable(CAP_DAC_OVERRIDE)) {",
                "\t\t\tif ((current->real_cred->fsuid != inode->i_uid) ||",
                "\t\t\t\t!(inode->i_mode & S_IRUSR) ||",
                "\t\t\t\t!(donor_filp->f_dentry->d_inode->i_mode &",
                "\t\t\t\tS_IRUSR)) {",
                "\t\t\t\tfput(donor_filp);",
                "\t\t\t\treturn -EACCES;",
                "\t\t\t}",
                "\t\t}",
                "",
                "\t\tme.moved_len = 0;",
                "",
                "\t\tif (copy_to_user((struct move_extent *)arg, &me, sizeof(me)))",
                "\t\t\treturn -EFAULT;",
                ""
            ],
            "added_lines": [
                "\t\tif (!(filp->f_mode & FMODE_READ) ||",
                "\t\t    !(filp->f_mode & FMODE_WRITE))",
                "\t\t\treturn -EBADF;",
                "",
                "\t\tme.moved_len = 0;",
                "\t\tif (!(donor_filp->f_mode & FMODE_WRITE)) {",
                "\t\t\terr = -EBADF;",
                "\t\t\tgoto mext_out;",
                "\t\t}",
                "",
                "\t\terr = mnt_want_write(filp->f_path.mnt);",
                "\t\tif (err)",
                "\t\t\tgoto mext_out;",
                "",
                "\t\tmnt_drop_write(filp->f_path.mnt);",
                "\t\tif (me.moved_len > 0)",
                "\t\t\tfile_remove_suid(donor_filp);",
                "",
                "\t\tif (copy_to_user((struct move_extent *)arg, &me, sizeof(me)))",
                "\t\t\terr = -EFAULT;",
                "mext_out:"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4131",
        "func_name": "kernel/git/tytso/ext4/mext_check_arguments",
        "description": "The EXT4_IOC_MOVE_EXT (aka move extents) ioctl implementation in the ext4 filesystem in the Linux kernel before 2.6.32-git6 allows local users to overwrite arbitrary files via a crafted request, related to insufficient checks for file permissions.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/tytso/ext4.git;a=commit;h=4a58579b9e4e2a35d57e6c9c8483e52f6f1b7fd6",
        "commit_title": "This patch fixes three problems in the handling of the",
        "commit_text": "EXT4_IOC_MOVE_EXT ioctl:  1. In current EXT4_IOC_MOVE_EXT, there are read access mode checks for original and donor files, but they allow the illegal write access to donor file, since donor file is overwritten by original file data.  To fix this problem, change access mode checks of original (r->r/w) and donor (r->w) files.  2.  Disallow the use of donor files that have a setuid or setgid bits.  3.  Call mnt_want_write() and mnt_drop_write() before and after ext4_move_extents() calling to get write access to a mount.  ",
        "func_before": "static int\nmext_check_arguments(struct inode *orig_inode,\n\t\t     struct inode *donor_inode, __u64 orig_start,\n\t\t     __u64 donor_start, __u64 *len)\n{\n\text4_lblk_t orig_blocks, donor_blocks;\n\tunsigned int blkbits = orig_inode->i_blkbits;\n\tunsigned int blocksize = 1 << blkbits;\n\n\t/* Regular file check */\n\tif (!S_ISREG(orig_inode->i_mode) || !S_ISREG(donor_inode->i_mode)) {\n\t\text4_debug(\"ext4 move extent: The argument files should be \"\n\t\t\t\"regular file [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ext4 move extent does not support swapfile */\n\tif (IS_SWAPFILE(orig_inode) || IS_SWAPFILE(donor_inode)) {\n\t\text4_debug(\"ext4 move extent: The argument files should \"\n\t\t\t\"not be swapfile [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Files should be in the same ext4 FS */\n\tif (orig_inode->i_sb != donor_inode->i_sb) {\n\t\text4_debug(\"ext4 move extent: The argument files \"\n\t\t\t\"should be in same FS [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ext4 move extent supports only extent based file */\n\tif (!(EXT4_I(orig_inode)->i_flags & EXT4_EXTENTS_FL)) {\n\t\text4_debug(\"ext4 move extent: orig file is not extents \"\n\t\t\t\"based file [ino:orig %lu]\\n\", orig_inode->i_ino);\n\t\treturn -EOPNOTSUPP;\n\t} else if (!(EXT4_I(donor_inode)->i_flags & EXT4_EXTENTS_FL)) {\n\t\text4_debug(\"ext4 move extent: donor file is not extents \"\n\t\t\t\"based file [ino:donor %lu]\\n\", donor_inode->i_ino);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif ((!orig_inode->i_size) || (!donor_inode->i_size)) {\n\t\text4_debug(\"ext4 move extent: File size is 0 byte\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Start offset should be same */\n\tif (orig_start != donor_start) {\n\t\text4_debug(\"ext4 move extent: orig and donor's start \"\n\t\t\t\"offset are not same [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\tif ((orig_start > EXT_MAX_BLOCK) ||\n\t    (donor_start > EXT_MAX_BLOCK) ||\n\t    (*len > EXT_MAX_BLOCK) ||\n\t    (orig_start + *len > EXT_MAX_BLOCK))  {\n\t\text4_debug(\"ext4 move extent: Can't handle over [%u] blocks \"\n\t\t\t\"[ino:orig %lu, donor %lu]\\n\", EXT_MAX_BLOCK,\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\tif (orig_inode->i_size > donor_inode->i_size) {\n\t\tdonor_blocks = (donor_inode->i_size + blocksize - 1) >> blkbits;\n\t\t/* TODO: eliminate this artificial restriction */\n\t\tif (orig_start >= donor_blocks) {\n\t\t\text4_debug(\"ext4 move extent: orig start offset \"\n\t\t\t\"[%llu] should be less than donor file blocks \"\n\t\t\t\"[%u] [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_start, donor_blocks,\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* TODO: eliminate this artificial restriction */\n\t\tif (orig_start + *len > donor_blocks) {\n\t\t\text4_debug(\"ext4 move extent: End offset [%llu] should \"\n\t\t\t\t\"be less than donor file blocks [%u].\"\n\t\t\t\t\"So adjust length from %llu to %llu \"\n\t\t\t\t\"[ino:orig %lu, donor %lu]\\n\",\n\t\t\t\torig_start + *len, donor_blocks,\n\t\t\t\t*len, donor_blocks - orig_start,\n\t\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\t*len = donor_blocks - orig_start;\n\t\t}\n\t} else {\n\t\torig_blocks = (orig_inode->i_size + blocksize - 1) >> blkbits;\n\t\tif (orig_start >= orig_blocks) {\n\t\t\text4_debug(\"ext4 move extent: start offset [%llu] \"\n\t\t\t\t\"should be less than original file blocks \"\n\t\t\t\t\"[%u] [ino:orig %lu, donor %lu]\\n\",\n\t\t\t\t orig_start, orig_blocks,\n\t\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (orig_start + *len > orig_blocks) {\n\t\t\text4_debug(\"ext4 move extent: Adjust length \"\n\t\t\t\t\"from %llu to %llu. Because it should be \"\n\t\t\t\t\"less than original file blocks \"\n\t\t\t\t\"[ino:orig %lu, donor %lu]\\n\",\n\t\t\t\t*len, orig_blocks - orig_start,\n\t\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\t*len = orig_blocks - orig_start;\n\t\t}\n\t}\n\n\tif (!*len) {\n\t\text4_debug(\"ext4 move extent: len should not be 0 \"\n\t\t\t\"[ino:orig %lu, donor %lu]\\n\", orig_inode->i_ino,\n\t\t\tdonor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}",
        "func": "static int\nmext_check_arguments(struct inode *orig_inode,\n\t\t     struct inode *donor_inode, __u64 orig_start,\n\t\t     __u64 donor_start, __u64 *len)\n{\n\text4_lblk_t orig_blocks, donor_blocks;\n\tunsigned int blkbits = orig_inode->i_blkbits;\n\tunsigned int blocksize = 1 << blkbits;\n\n\t/* Regular file check */\n\tif (!S_ISREG(orig_inode->i_mode) || !S_ISREG(donor_inode->i_mode)) {\n\t\text4_debug(\"ext4 move extent: The argument files should be \"\n\t\t\t\"regular file [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\tif (donor_inode->i_mode & (S_ISUID|S_ISGID)) {\n\t\text4_debug(\"ext4 move extent: suid or sgid is set\"\n\t\t\t   \" to donor file [ino:orig %lu, donor %lu]\\n\",\n\t\t\t   orig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ext4 move extent does not support swapfile */\n\tif (IS_SWAPFILE(orig_inode) || IS_SWAPFILE(donor_inode)) {\n\t\text4_debug(\"ext4 move extent: The argument files should \"\n\t\t\t\"not be swapfile [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Files should be in the same ext4 FS */\n\tif (orig_inode->i_sb != donor_inode->i_sb) {\n\t\text4_debug(\"ext4 move extent: The argument files \"\n\t\t\t\"should be in same FS [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Ext4 move extent supports only extent based file */\n\tif (!(EXT4_I(orig_inode)->i_flags & EXT4_EXTENTS_FL)) {\n\t\text4_debug(\"ext4 move extent: orig file is not extents \"\n\t\t\t\"based file [ino:orig %lu]\\n\", orig_inode->i_ino);\n\t\treturn -EOPNOTSUPP;\n\t} else if (!(EXT4_I(donor_inode)->i_flags & EXT4_EXTENTS_FL)) {\n\t\text4_debug(\"ext4 move extent: donor file is not extents \"\n\t\t\t\"based file [ino:donor %lu]\\n\", donor_inode->i_ino);\n\t\treturn -EOPNOTSUPP;\n\t}\n\n\tif ((!orig_inode->i_size) || (!donor_inode->i_size)) {\n\t\text4_debug(\"ext4 move extent: File size is 0 byte\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\t/* Start offset should be same */\n\tif (orig_start != donor_start) {\n\t\text4_debug(\"ext4 move extent: orig and donor's start \"\n\t\t\t\"offset are not same [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\tif ((orig_start > EXT_MAX_BLOCK) ||\n\t    (donor_start > EXT_MAX_BLOCK) ||\n\t    (*len > EXT_MAX_BLOCK) ||\n\t    (orig_start + *len > EXT_MAX_BLOCK))  {\n\t\text4_debug(\"ext4 move extent: Can't handle over [%u] blocks \"\n\t\t\t\"[ino:orig %lu, donor %lu]\\n\", EXT_MAX_BLOCK,\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\tif (orig_inode->i_size > donor_inode->i_size) {\n\t\tdonor_blocks = (donor_inode->i_size + blocksize - 1) >> blkbits;\n\t\t/* TODO: eliminate this artificial restriction */\n\t\tif (orig_start >= donor_blocks) {\n\t\t\text4_debug(\"ext4 move extent: orig start offset \"\n\t\t\t\"[%llu] should be less than donor file blocks \"\n\t\t\t\"[%u] [ino:orig %lu, donor %lu]\\n\",\n\t\t\torig_start, donor_blocks,\n\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\t/* TODO: eliminate this artificial restriction */\n\t\tif (orig_start + *len > donor_blocks) {\n\t\t\text4_debug(\"ext4 move extent: End offset [%llu] should \"\n\t\t\t\t\"be less than donor file blocks [%u].\"\n\t\t\t\t\"So adjust length from %llu to %llu \"\n\t\t\t\t\"[ino:orig %lu, donor %lu]\\n\",\n\t\t\t\torig_start + *len, donor_blocks,\n\t\t\t\t*len, donor_blocks - orig_start,\n\t\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\t*len = donor_blocks - orig_start;\n\t\t}\n\t} else {\n\t\torig_blocks = (orig_inode->i_size + blocksize - 1) >> blkbits;\n\t\tif (orig_start >= orig_blocks) {\n\t\t\text4_debug(\"ext4 move extent: start offset [%llu] \"\n\t\t\t\t\"should be less than original file blocks \"\n\t\t\t\t\"[%u] [ino:orig %lu, donor %lu]\\n\",\n\t\t\t\t orig_start, orig_blocks,\n\t\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (orig_start + *len > orig_blocks) {\n\t\t\text4_debug(\"ext4 move extent: Adjust length \"\n\t\t\t\t\"from %llu to %llu. Because it should be \"\n\t\t\t\t\"less than original file blocks \"\n\t\t\t\t\"[ino:orig %lu, donor %lu]\\n\",\n\t\t\t\t*len, orig_blocks - orig_start,\n\t\t\t\torig_inode->i_ino, donor_inode->i_ino);\n\t\t\t*len = orig_blocks - orig_start;\n\t\t}\n\t}\n\n\tif (!*len) {\n\t\text4_debug(\"ext4 move extent: len should not be 0 \"\n\t\t\t\"[ino:orig %lu, donor %lu]\\n\", orig_inode->i_ino,\n\t\t\tdonor_inode->i_ino);\n\t\treturn -EINVAL;\n\t}\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -12,6 +12,13 @@\n \t\text4_debug(\"ext4 move extent: The argument files should be \"\n \t\t\t\"regular file [ino:orig %lu, donor %lu]\\n\",\n \t\t\torig_inode->i_ino, donor_inode->i_ino);\n+\t\treturn -EINVAL;\n+\t}\n+\n+\tif (donor_inode->i_mode & (S_ISUID|S_ISGID)) {\n+\t\text4_debug(\"ext4 move extent: suid or sgid is set\"\n+\t\t\t   \" to donor file [ino:orig %lu, donor %lu]\\n\",\n+\t\t\t   orig_inode->i_ino, donor_inode->i_ino);\n \t\treturn -EINVAL;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\treturn -EINVAL;",
                "\t}",
                "",
                "\tif (donor_inode->i_mode & (S_ISUID|S_ISGID)) {",
                "\t\text4_debug(\"ext4 move extent: suid or sgid is set\"",
                "\t\t\t   \" to donor file [ino:orig %lu, donor %lu]\\n\",",
                "\t\t\t   orig_inode->i_ino, donor_inode->i_ino);"
            ]
        }
    },
    {
        "cve_id": "CVE-2009-4411",
        "func_name": "acl/main",
        "description": "The (1) setfacl and (2) getfacl commands in XFS acl 2.2.47, when running in recursive (-R) mode, follow symbolic links even when the --physical (aka -P) or -L option is specified, which might allow local users to modify the ACL for arbitrary files or directories via a symlink attack.",
        "git_url": "http://git.savannah.gnu.org/cgit/acl.git/commit/?id=63451a0",
        "commit_title": "This fixes http://oss.sgi.com/bugzilla/show_bug.cgi?id=790",
        "commit_text": "\"getfacl follows symlinks, even without -L\". ",
        "func_before": "int main(int argc, char *argv[])\n{\n\tint opt;\n\tchar *line;\n\n\tprogname = basename(argv[0]);\n\n#if POSIXLY_CORRECT\n\tcmd_line_options = POSIXLY_CMD_LINE_OPTIONS;\n#else\n\tif (getenv(POSIXLY_CORRECT_STR))\n\t\tposixly_correct = 1;\n\tif (!posixly_correct)\n\t\tcmd_line_options = CMD_LINE_OPTIONS;\n\telse\n\t\tcmd_line_options = POSIXLY_CMD_LINE_OPTIONS;\n#endif\n\n\tsetlocale(LC_CTYPE, \"\");\n\tsetlocale(LC_MESSAGES, \"\");\n\tbindtextdomain(PACKAGE, LOCALEDIR);\n\ttextdomain(PACKAGE);\n\n\t/* Align `#effective:' comments to column 40 for tty's */\n\tif (!posixly_correct && isatty(fileno(stdout)))\n\t\tprint_options |= TEXT_SMART_INDENT;\n\n\twhile ((opt = getopt_long(argc, argv, cmd_line_options,\n\t\t                 long_options, NULL)) != -1) {\n\t\tswitch (opt) {\n\t\t\tcase 'a':  /* acl only */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_print_acl = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'd':  /* default acl only */\n\t\t\t\topt_print_default_acl = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':  /* no comments */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_comments = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase 'e':  /* all #effective comments */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\tprint_options |= TEXT_ALL_EFFECTIVE;\n\t\t\t\tbreak;\n\n\t\t\tcase 'E':  /* no #effective comments */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\tprint_options &= ~(TEXT_SOME_EFFECTIVE |\n\t\t\t\t                   TEXT_ALL_EFFECTIVE);\n\t\t\t\tbreak;\n\n\t\t\tcase 'R':  /* recursive */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\twalk_flags |= WALK_TREE_RECURSIVE;\n\t\t\t\tbreak;\n\n\t\t\tcase 'L':  /* follow all symlinks */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\twalk_flags |= WALK_TREE_LOGICAL;\n\t\t\t\twalk_flags &= ~WALK_TREE_PHYSICAL;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':  /* skip all symlinks */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\twalk_flags |= WALK_TREE_PHYSICAL;\n\t\t\t\twalk_flags &= ~WALK_TREE_LOGICAL;\n\t\t\t\tbreak;\n\n\t\t\tcase 's':  /* skip files with only base entries */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_skip_base = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_strip_leading_slash = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_tabular = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'n':  /* numeric */\n\t\t\t\topt_numeric = 1;\n\t\t\t\tprint_options |= TEXT_NUMERIC_IDS;\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':  /* print version */\n\t\t\t\tprintf(\"%s \" VERSION \"\\n\", progname);\n\t\t\t\treturn 0;\n\n\t\t\tcase 'h':  /* help */\n\t\t\t\thelp();\n\t\t\t\treturn 0;\n\n\t\t\tcase ':':  /* option missing */\n\t\t\tcase '?':  /* unknown option */\n\t\t\tdefault:\n\t\t\t\tgoto synopsis;\n\t\t}\n\t}\n\n\tif (!(opt_print_acl || opt_print_default_acl)) {\n\t\topt_print_acl = 1;\n\t\tif (!posixly_correct)\n\t\t\topt_print_default_acl = 1;\n\t}\n\t\t\n\tif ((optind == argc) && !posixly_correct)\n\t\tgoto synopsis;\n\n\tdo {\n\t\tif (optind == argc ||\n\t\t    strcmp(argv[optind], \"-\") == 0) {\n\t\t\twhile ((line = next_line(stdin)) != NULL) {\n\t\t\t\tif (*line == '\\0')\n\t\t\t\t\tcontinue;\n\n\t\t\t\thad_errors += walk_tree(line, walk_flags, 0,\n\t\t\t\t\t\t\tdo_print, NULL);\n\t\t\t}\n\t\t\tif (!feof(stdin)) {\n\t\t\t\tfprintf(stderr, _(\"%s: Standard input: %s\\n\"),\n\t\t\t\t        progname, strerror(errno));\n\t\t\t\thad_errors++;\n\t\t\t}\n\t\t} else\n\t\t\thad_errors += walk_tree(argv[optind], walk_flags, 0,\n\t\t\t\t\t\tdo_print, NULL);\n\t\toptind++;\n\t} while (optind < argc);\n\n\treturn had_errors ? 1 : 0;\n\nsynopsis:\n\tfprintf(stderr, _(\"Usage: %s [-%s] file ...\\n\"),\n\t        progname, cmd_line_options);\n\tfprintf(stderr, _(\"Try `%s --help' for more information.\\n\"),\n\t\tprogname);\n\treturn 2;\n}",
        "func": "int main(int argc, char *argv[])\n{\n\tint opt;\n\tchar *line;\n\n\tprogname = basename(argv[0]);\n\n#if POSIXLY_CORRECT\n\tcmd_line_options = POSIXLY_CMD_LINE_OPTIONS;\n#else\n\tif (getenv(POSIXLY_CORRECT_STR))\n\t\tposixly_correct = 1;\n\tif (!posixly_correct)\n\t\tcmd_line_options = CMD_LINE_OPTIONS;\n\telse\n\t\tcmd_line_options = POSIXLY_CMD_LINE_OPTIONS;\n#endif\n\n\tsetlocale(LC_CTYPE, \"\");\n\tsetlocale(LC_MESSAGES, \"\");\n\tbindtextdomain(PACKAGE, LOCALEDIR);\n\ttextdomain(PACKAGE);\n\n\t/* Align `#effective:' comments to column 40 for tty's */\n\tif (!posixly_correct && isatty(fileno(stdout)))\n\t\tprint_options |= TEXT_SMART_INDENT;\n\n\twhile ((opt = getopt_long(argc, argv, cmd_line_options,\n\t\t                 long_options, NULL)) != -1) {\n\t\tswitch (opt) {\n\t\t\tcase 'a':  /* acl only */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_print_acl = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'd':  /* default acl only */\n\t\t\t\topt_print_default_acl = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'c':  /* no comments */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_comments = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase 'e':  /* all #effective comments */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\tprint_options |= TEXT_ALL_EFFECTIVE;\n\t\t\t\tbreak;\n\n\t\t\tcase 'E':  /* no #effective comments */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\tprint_options &= ~(TEXT_SOME_EFFECTIVE |\n\t\t\t\t                   TEXT_ALL_EFFECTIVE);\n\t\t\t\tbreak;\n\n\t\t\tcase 'R':  /* recursive */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\twalk_flags |= WALK_TREE_RECURSIVE;\n\t\t\t\tbreak;\n\n\t\t\tcase 'L':  /* follow all symlinks */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\twalk_flags |= WALK_TREE_LOGICAL | WALK_TREE_DEREFERENCE;\n\t\t\t\twalk_flags &= ~WALK_TREE_PHYSICAL;\n\t\t\t\tbreak;\n\n\t\t\tcase 'P':  /* skip all symlinks */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\twalk_flags |= WALK_TREE_PHYSICAL;\n\t\t\t\twalk_flags &= ~(WALK_TREE_LOGICAL | WALK_TREE_DEREFERENCE |\n\t\t\t\t\t\tWALK_TREE_DEREFERENCE_TOPLEVEL);\n\t\t\t\tbreak;\n\n\t\t\tcase 's':  /* skip files with only base entries */\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_skip_base = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'p':\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_strip_leading_slash = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase 't':\n\t\t\t\tif (posixly_correct)\n\t\t\t\t\tgoto synopsis;\n\t\t\t\topt_tabular = 1;\n\t\t\t\tbreak;\n\n\t\t\tcase 'n':  /* numeric */\n\t\t\t\topt_numeric = 1;\n\t\t\t\tprint_options |= TEXT_NUMERIC_IDS;\n\t\t\t\tbreak;\n\n\t\t\tcase 'v':  /* print version */\n\t\t\t\tprintf(\"%s \" VERSION \"\\n\", progname);\n\t\t\t\treturn 0;\n\n\t\t\tcase 'h':  /* help */\n\t\t\t\thelp();\n\t\t\t\treturn 0;\n\n\t\t\tcase ':':  /* option missing */\n\t\t\tcase '?':  /* unknown option */\n\t\t\tdefault:\n\t\t\t\tgoto synopsis;\n\t\t}\n\t}\n\n\tif (!(opt_print_acl || opt_print_default_acl)) {\n\t\topt_print_acl = 1;\n\t\tif (!posixly_correct)\n\t\t\topt_print_default_acl = 1;\n\t}\n\t\t\n\tif ((optind == argc) && !posixly_correct)\n\t\tgoto synopsis;\n\n\tdo {\n\t\tif (optind == argc ||\n\t\t    strcmp(argv[optind], \"-\") == 0) {\n\t\t\twhile ((line = next_line(stdin)) != NULL) {\n\t\t\t\tif (*line == '\\0')\n\t\t\t\t\tcontinue;\n\n\t\t\t\thad_errors += walk_tree(line, walk_flags, 0,\n\t\t\t\t\t\t\tdo_print, NULL);\n\t\t\t}\n\t\t\tif (!feof(stdin)) {\n\t\t\t\tfprintf(stderr, _(\"%s: Standard input: %s\\n\"),\n\t\t\t\t        progname, strerror(errno));\n\t\t\t\thad_errors++;\n\t\t\t}\n\t\t} else\n\t\t\thad_errors += walk_tree(argv[optind], walk_flags, 0,\n\t\t\t\t\t\tdo_print, NULL);\n\t\toptind++;\n\t} while (optind < argc);\n\n\treturn had_errors ? 1 : 0;\n\nsynopsis:\n\tfprintf(stderr, _(\"Usage: %s [-%s] file ...\\n\"),\n\t        progname, cmd_line_options);\n\tfprintf(stderr, _(\"Try `%s --help' for more information.\\n\"),\n\t\tprogname);\n\treturn 2;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -66,7 +66,7 @@\n \t\t\tcase 'L':  /* follow all symlinks */\n \t\t\t\tif (posixly_correct)\n \t\t\t\t\tgoto synopsis;\n-\t\t\t\twalk_flags |= WALK_TREE_LOGICAL;\n+\t\t\t\twalk_flags |= WALK_TREE_LOGICAL | WALK_TREE_DEREFERENCE;\n \t\t\t\twalk_flags &= ~WALK_TREE_PHYSICAL;\n \t\t\t\tbreak;\n \n@@ -74,7 +74,8 @@\n \t\t\t\tif (posixly_correct)\n \t\t\t\t\tgoto synopsis;\n \t\t\t\twalk_flags |= WALK_TREE_PHYSICAL;\n-\t\t\t\twalk_flags &= ~WALK_TREE_LOGICAL;\n+\t\t\t\twalk_flags &= ~(WALK_TREE_LOGICAL | WALK_TREE_DEREFERENCE |\n+\t\t\t\t\t\tWALK_TREE_DEREFERENCE_TOPLEVEL);\n \t\t\t\tbreak;\n \n \t\t\tcase 's':  /* skip files with only base entries */",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\twalk_flags |= WALK_TREE_LOGICAL;",
                "\t\t\t\twalk_flags &= ~WALK_TREE_LOGICAL;"
            ],
            "added_lines": [
                "\t\t\t\twalk_flags |= WALK_TREE_LOGICAL | WALK_TREE_DEREFERENCE;",
                "\t\t\t\twalk_flags &= ~(WALK_TREE_LOGICAL | WALK_TREE_DEREFERENCE |",
                "\t\t\t\t\t\tWALK_TREE_DEREFERENCE_TOPLEVEL);"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-0007",
        "func_name": "torvalds/linux/do_ebt_get_ctl",
        "description": "net/bridge/netfilter/ebtables.c in the ebtables module in the netfilter framework in the Linux kernel before 2.6.33-rc4 does not require the CAP_NET_ADMIN capability for setting or modifying rules, which allows local users to bypass intended access restrictions and configure arbitrary network-traffic filtering via a modified ebtables application.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=dce766af541f6605fa9889892c0280bab31c66ab",
        "commit_title": "normal users are currently allowed to set/modify ebtables rules.",
        "commit_text": "Restrict it to processes with CAP_NET_ADMIN.  Note that this cannot be reproduced with unmodified ebtables binary because it uses SOCK_RAW.  Cc: stable@kernel.org ",
        "func_before": "static int do_ebt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\tstruct ebt_replace tmp;\n\tstruct ebt_table *t;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tt = find_table_lock(sock_net(sk), tmp.name, &ret, &ebt_mutex);\n\tif (!t)\n\t\treturn ret;\n\n\tswitch(cmd) {\n\tcase EBT_SO_GET_INFO:\n\tcase EBT_SO_GET_INIT_INFO:\n\t\tif (*len != sizeof(struct ebt_replace)){\n\t\t\tret = -EINVAL;\n\t\t\tmutex_unlock(&ebt_mutex);\n\t\t\tbreak;\n\t\t}\n\t\tif (cmd == EBT_SO_GET_INFO) {\n\t\t\ttmp.nentries = t->private->nentries;\n\t\t\ttmp.entries_size = t->private->entries_size;\n\t\t\ttmp.valid_hooks = t->valid_hooks;\n\t\t} else {\n\t\t\ttmp.nentries = t->table->nentries;\n\t\t\ttmp.entries_size = t->table->entries_size;\n\t\t\ttmp.valid_hooks = t->table->valid_hooks;\n\t\t}\n\t\tmutex_unlock(&ebt_mutex);\n\t\tif (copy_to_user(user, &tmp, *len) != 0){\n\t\t\tBUGPRINT(\"c2u Didn't work\\n\");\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tret = 0;\n\t\tbreak;\n\n\tcase EBT_SO_GET_ENTRIES:\n\tcase EBT_SO_GET_INIT_ENTRIES:\n\t\tret = copy_everything_to_user(t, user, len, cmd);\n\t\tmutex_unlock(&ebt_mutex);\n\t\tbreak;\n\n\tdefault:\n\t\tmutex_unlock(&ebt_mutex);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}",
        "func": "static int do_ebt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\tstruct ebt_replace tmp;\n\tstruct ebt_table *t;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)))\n\t\treturn -EFAULT;\n\n\tt = find_table_lock(sock_net(sk), tmp.name, &ret, &ebt_mutex);\n\tif (!t)\n\t\treturn ret;\n\n\tswitch(cmd) {\n\tcase EBT_SO_GET_INFO:\n\tcase EBT_SO_GET_INIT_INFO:\n\t\tif (*len != sizeof(struct ebt_replace)){\n\t\t\tret = -EINVAL;\n\t\t\tmutex_unlock(&ebt_mutex);\n\t\t\tbreak;\n\t\t}\n\t\tif (cmd == EBT_SO_GET_INFO) {\n\t\t\ttmp.nentries = t->private->nentries;\n\t\t\ttmp.entries_size = t->private->entries_size;\n\t\t\ttmp.valid_hooks = t->valid_hooks;\n\t\t} else {\n\t\t\ttmp.nentries = t->table->nentries;\n\t\t\ttmp.entries_size = t->table->entries_size;\n\t\t\ttmp.valid_hooks = t->table->valid_hooks;\n\t\t}\n\t\tmutex_unlock(&ebt_mutex);\n\t\tif (copy_to_user(user, &tmp, *len) != 0){\n\t\t\tBUGPRINT(\"c2u Didn't work\\n\");\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tret = 0;\n\t\tbreak;\n\n\tcase EBT_SO_GET_ENTRIES:\n\tcase EBT_SO_GET_INIT_ENTRIES:\n\t\tret = copy_everything_to_user(t, user, len, cmd);\n\t\tmutex_unlock(&ebt_mutex);\n\t\tbreak;\n\n\tdefault:\n\t\tmutex_unlock(&ebt_mutex);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,6 +3,9 @@\n \tint ret;\n \tstruct ebt_replace tmp;\n \tstruct ebt_table *t;\n+\n+\tif (!capable(CAP_NET_ADMIN))\n+\t\treturn -EPERM;\n \n \tif (copy_from_user(&tmp, user, sizeof(tmp)))\n \t\treturn -EFAULT;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!capable(CAP_NET_ADMIN))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-0007",
        "func_name": "torvalds/linux/do_ebt_set_ctl",
        "description": "net/bridge/netfilter/ebtables.c in the ebtables module in the netfilter framework in the Linux kernel before 2.6.33-rc4 does not require the CAP_NET_ADMIN capability for setting or modifying rules, which allows local users to bypass intended access restrictions and configure arbitrary network-traffic filtering via a modified ebtables application.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commit;h=dce766af541f6605fa9889892c0280bab31c66ab",
        "commit_title": "normal users are currently allowed to set/modify ebtables rules.",
        "commit_text": "Restrict it to processes with CAP_NET_ADMIN.  Note that this cannot be reproduced with unmodified ebtables binary because it uses SOCK_RAW.  Cc: stable@kernel.org ",
        "func_before": "static int do_ebt_set_ctl(struct sock *sk,\n\tint cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tswitch(cmd) {\n\tcase EBT_SO_SET_ENTRIES:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\tcase EBT_SO_SET_COUNTERS:\n\t\tret = update_counters(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n  }\n\treturn ret;\n}",
        "func": "static int do_ebt_set_ctl(struct sock *sk,\n\tint cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tif (!capable(CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch(cmd) {\n\tcase EBT_SO_SET_ENTRIES:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\tcase EBT_SO_SET_COUNTERS:\n\t\tret = update_counters(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n  }\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,9 @@\n \tint cmd, void __user *user, unsigned int len)\n {\n \tint ret;\n+\n+\tif (!capable(CAP_NET_ADMIN))\n+\t\treturn -EPERM;\n \n \tswitch(cmd) {\n \tcase EBT_SO_SET_ENTRIES:",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (!capable(CAP_NET_ADMIN))",
                "\t\treturn -EPERM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2010-0011",
        "func_name": "uzbl/eval_js",
        "description": "The eval_js function in uzbl-core.c in Uzbl before 2010.01.05 exposes the run method of the Uzbl object, which allows remote attackers to execute arbitrary commands via JavaScript code.",
        "git_url": "https://github.com/uzbl/uzbl/commit/1958b52d41cba96956dc1995660de49525ed1047",
        "commit_title": "disable Uzbl javascript object because of security problem.",
        "commit_text": "",
        "func_before": "void\neval_js(WebKitWebView * web_view, gchar *script, GString *result) {\n    WebKitWebFrame *frame;\n    JSGlobalContextRef context;\n    JSObjectRef globalobject;\n    JSStringRef var_name;\n\n    JSStringRef js_script;\n    JSValueRef js_result;\n    JSStringRef js_result_string;\n    size_t js_result_size;\n\n    js_init();\n\n    frame = webkit_web_view_get_main_frame(WEBKIT_WEB_VIEW(web_view));\n    context = webkit_web_frame_get_global_context(frame);\n    globalobject = JSContextGetGlobalObject(context);\n\n    /* uzbl javascript namespace */\n    var_name = JSStringCreateWithUTF8CString(\"Uzbl\");\n    JSObjectSetProperty(context, globalobject, var_name,\n                        JSObjectMake(context, uzbl.js.classref, NULL),\n                        kJSClassAttributeNone, NULL);\n\n    /* evaluate the script and get return value*/\n    js_script = JSStringCreateWithUTF8CString(script);\n    js_result = JSEvaluateScript(context, js_script, globalobject, NULL, 0, NULL);\n    if (js_result && !JSValueIsUndefined(context, js_result)) {\n        js_result_string = JSValueToStringCopy(context, js_result, NULL);\n        js_result_size = JSStringGetMaximumUTF8CStringSize(js_result_string);\n\n        if (js_result_size) {\n            char js_result_utf8[js_result_size];\n            JSStringGetUTF8CString(js_result_string, js_result_utf8, js_result_size);\n            g_string_assign(result, js_result_utf8);\n        }\n\n        JSStringRelease(js_result_string);\n    }\n\n    /* cleanup */\n    JSObjectDeleteProperty(context, globalobject, var_name, NULL);\n\n    JSStringRelease(var_name);\n    JSStringRelease(js_script);\n}",
        "func": "void\neval_js(WebKitWebView * web_view, gchar *script, GString *result) {\n    WebKitWebFrame *frame;\n    JSGlobalContextRef context;\n    JSObjectRef globalobject;\n\n    JSStringRef js_script;\n    JSValueRef js_result;\n    JSStringRef js_result_string;\n    size_t js_result_size;\n\n    js_init();\n\n    frame = webkit_web_view_get_main_frame(WEBKIT_WEB_VIEW(web_view));\n    context = webkit_web_frame_get_global_context(frame);\n    globalobject = JSContextGetGlobalObject(context);\n\n    /* evaluate the script and get return value*/\n    js_script = JSStringCreateWithUTF8CString(script);\n    js_result = JSEvaluateScript(context, js_script, globalobject, NULL, 0, NULL);\n    if (js_result && !JSValueIsUndefined(context, js_result)) {\n        js_result_string = JSValueToStringCopy(context, js_result, NULL);\n        js_result_size = JSStringGetMaximumUTF8CStringSize(js_result_string);\n\n        if (js_result_size) {\n            char js_result_utf8[js_result_size];\n            JSStringGetUTF8CString(js_result_string, js_result_utf8, js_result_size);\n            g_string_assign(result, js_result_utf8);\n        }\n\n        JSStringRelease(js_result_string);\n    }\n\n    /* cleanup */\n    JSStringRelease(js_script);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,6 @@\n     WebKitWebFrame *frame;\n     JSGlobalContextRef context;\n     JSObjectRef globalobject;\n-    JSStringRef var_name;\n \n     JSStringRef js_script;\n     JSValueRef js_result;\n@@ -15,12 +14,6 @@\n     frame = webkit_web_view_get_main_frame(WEBKIT_WEB_VIEW(web_view));\n     context = webkit_web_frame_get_global_context(frame);\n     globalobject = JSContextGetGlobalObject(context);\n-\n-    /* uzbl javascript namespace */\n-    var_name = JSStringCreateWithUTF8CString(\"Uzbl\");\n-    JSObjectSetProperty(context, globalobject, var_name,\n-                        JSObjectMake(context, uzbl.js.classref, NULL),\n-                        kJSClassAttributeNone, NULL);\n \n     /* evaluate the script and get return value*/\n     js_script = JSStringCreateWithUTF8CString(script);\n@@ -39,8 +32,5 @@\n     }\n \n     /* cleanup */\n-    JSObjectDeleteProperty(context, globalobject, var_name, NULL);\n-\n-    JSStringRelease(var_name);\n     JSStringRelease(js_script);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    JSStringRef var_name;",
                "",
                "    /* uzbl javascript namespace */",
                "    var_name = JSStringCreateWithUTF8CString(\"Uzbl\");",
                "    JSObjectSetProperty(context, globalobject, var_name,",
                "                        JSObjectMake(context, uzbl.js.classref, NULL),",
                "                        kJSClassAttributeNone, NULL);",
                "    JSObjectDeleteProperty(context, globalobject, var_name, NULL);",
                "",
                "    JSStringRelease(var_name);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-9016",
        "func_name": "torvalds/linux/flush_end_io",
        "description": "In blk_mq_tag_to_rq in blk-mq.c in the upstream kernel, there is a possible use after free due to a race condition when a request has been previously freed by blk_mq_complete_request. This could lead to local escalation of privilege. Product: Android. Versions: Android kernel. Android ID: A-63083046.",
        "git_url": "https://github.com/torvalds/linux/commit/0048b4837affd153897ed1222283492070027aa9",
        "commit_title": "blk-mq: fix race between timeout and freeing request",
        "commit_text": " Inside timeout handler, blk_mq_tag_to_rq() is called to retrieve the request from one tag. This way is obviously wrong because the request can be freed any time and some fiedds of the request can't be trusted, then kernel oops might be triggered[1].  Currently wrt. blk_mq_tag_to_rq(), the only special case is that the flush request can share same tag with the request cloned from, and the two requests can't be active at the same time, so this patch fixes the above issue by updating tags->rqs[tag] with the active request(either flush rq or the request cloned from) of the tag.  Also blk_mq_tag_to_rq() gets much simplified with this patch.  Given blk_mq_tag_to_rq() is mainly for drivers and the caller must make sure the request can't be freed, so in bt_for_each() this helper is replaced with tags->rqs[tag].  [1] kernel oops log [  439.696220] BUG: unable to handle kernel NULL pointer dereference at 0000000000000158^M [  439.697162] IP: [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.700653] PGD 7ef765067 PUD 7ef764067 PMD 0 ^M [  439.700653] Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC ^M [  439.700653] Dumping ftrace buffer:^M [  439.700653]    (ftrace buffer empty)^M [  439.700653] Modules linked in: nbd ipv6 kvm_intel kvm serio_raw^M [  439.700653] CPU: 6 PID: 2779 Comm: stress-ng-sigfd Not tainted 4.2.0-rc5-next-20150805+ #265^M [  439.730500] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011^M [  439.730500] task: ffff880605308000 ti: ffff88060530c000 task.ti: ffff88060530c000^M [  439.730500] RIP: 0010:[<ffffffff812d89ba>]  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.730500] RSP: 0018:ffff880819203da0  EFLAGS: 00010283^M [  439.730500] RAX: ffff880811b0e000 RBX: ffff8800bb465f00 RCX: 0000000000000002^M [  439.730500] RDX: 0000000000000000 RSI: 0000000000000202 RDI: 0000000000000000^M [  439.730500] RBP: ffff880819203db0 R08: 0000000000000002 R09: 0000000000000000^M [  439.730500] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000202^M [  439.730500] R13: ffff880814104800 R14: 0000000000000002 R15: ffff880811a2ea00^M [  439.730500] FS:  00007f165b3f5740(0000) GS:ffff880819200000(0000) knlGS:0000000000000000^M [  439.730500] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b^M [  439.730500] CR2: 0000000000000158 CR3: 00000007ef766000 CR4: 00000000000006e0^M [  439.730500] Stack:^M [  439.730500]  0000000000000008 ffff8808114eed90 ffff880819203e00 ffffffff812dc104^M [  439.755663]  ffff880819203e40 ffffffff812d9f5e 0000020000000000 ffff8808114eed80^M [  439.755663] Call Trace:^M [  439.755663]  <IRQ> ^M [  439.755663]  [<ffffffff812dc104>] bt_for_each+0x6e/0xc8^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812dc1b3>] blk_mq_tag_busy_iter+0x55/0x5e^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff812d8911>] blk_mq_rq_timer+0x5d/0xd4^M [  439.755663]  [<ffffffff810a3e10>] call_timer_fn+0xf7/0x284^M [  439.755663]  [<ffffffff810a3d1e>] ? call_timer_fn+0x5/0x284^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff810a46d6>] run_timer_softirq+0x1ce/0x1f8^M [  439.755663]  [<ffffffff8104c367>] __do_softirq+0x181/0x3a4^M [  439.755663]  [<ffffffff8104c76e>] irq_exit+0x40/0x94^M [  439.755663]  [<ffffffff81031482>] smp_apic_timer_interrupt+0x33/0x3e^M [  439.755663]  [<ffffffff815559a4>] apic_timer_interrupt+0x84/0x90^M [  439.755663]  <EOI> ^M [  439.755663]  [<ffffffff81554350>] ? _raw_spin_unlock_irq+0x32/0x4a^M [  439.755663]  [<ffffffff8106a98b>] finish_task_switch+0xe0/0x163^M [  439.755663]  [<ffffffff8106a94d>] ? finish_task_switch+0xa2/0x163^M [  439.755663]  [<ffffffff81550066>] __schedule+0x469/0x6cd^M [  439.755663]  [<ffffffff8155039b>] schedule+0x82/0x9a^M [  439.789267]  [<ffffffff8119b28b>] signalfd_read+0x186/0x49a^M [  439.790911]  [<ffffffff8106d86a>] ? wake_up_q+0x47/0x47^M [  439.790911]  [<ffffffff811618c2>] __vfs_read+0x28/0x9f^M [  439.790911]  [<ffffffff8117a289>] ? __fget_light+0x4d/0x74^M [  439.790911]  [<ffffffff811620a7>] vfs_read+0x7a/0xc6^M [  439.790911]  [<ffffffff8116292b>] SyS_read+0x49/0x7f^M [  439.790911]  [<ffffffff81554c17>] entry_SYSCALL_64_fastpath+0x12/0x6f^M [  439.790911] Code: 48 89 e5 e8 a9 b8 e7 ff 5d c3 0f 1f 44 00 00 55 89 f2 48 89 e5 41 54 41 89 f4 53 48 8b 47 60 48 8b 1c d0 48 8b 7b 30 48 8b 53 38 <48> 8b 87 58 01 00 00 48 85 c0 75 09 48 8b 97 88 0c 00 00 eb 10 ^M [  439.790911] RIP  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.790911]  RSP <ffff880819203da0>^M [  439.790911] CR2: 0000000000000158^M [  439.790911] ---[ end trace d40af58949325661 ]---^M  Cc: <stable@vger.kernel.org>",
        "func_before": "static void flush_end_io(struct request *flush_rq, int error)\n{\n\tstruct request_queue *q = flush_rq->q;\n\tstruct list_head *running;\n\tbool queued = false;\n\tstruct request *rq, *n;\n\tunsigned long flags = 0;\n\tstruct blk_flush_queue *fq = blk_get_flush_queue(q, flush_rq->mq_ctx);\n\n\tif (q->mq_ops) {\n\t\tspin_lock_irqsave(&fq->mq_flush_lock, flags);\n\t\tflush_rq->tag = -1;\n\t}\n\n\trunning = &fq->flush_queue[fq->flush_running_idx];\n\tBUG_ON(fq->flush_pending_idx == fq->flush_running_idx);\n\n\t/* account completion of the flush request */\n\tfq->flush_running_idx ^= 1;\n\n\tif (!q->mq_ops)\n\t\telv_completed_request(q, flush_rq);\n\n\t/* and push the waiting requests to the next stage */\n\tlist_for_each_entry_safe(rq, n, running, flush.list) {\n\t\tunsigned int seq = blk_flush_cur_seq(rq);\n\n\t\tBUG_ON(seq != REQ_FSEQ_PREFLUSH && seq != REQ_FSEQ_POSTFLUSH);\n\t\tqueued |= blk_flush_complete_seq(rq, fq, seq, error);\n\t}\n\n\t/*\n\t * Kick the queue to avoid stall for two cases:\n\t * 1. Moving a request silently to empty queue_head may stall the\n\t * queue.\n\t * 2. When flush request is running in non-queueable queue, the\n\t * queue is hold. Restart the queue after flush request is finished\n\t * to avoid stall.\n\t * This function is called from request completion path and calling\n\t * directly into request_fn may confuse the driver.  Always use\n\t * kblockd.\n\t */\n\tif (queued || fq->flush_queue_delayed) {\n\t\tWARN_ON(q->mq_ops);\n\t\tblk_run_queue_async(q);\n\t}\n\tfq->flush_queue_delayed = 0;\n\tif (q->mq_ops)\n\t\tspin_unlock_irqrestore(&fq->mq_flush_lock, flags);\n}",
        "func": "static void flush_end_io(struct request *flush_rq, int error)\n{\n\tstruct request_queue *q = flush_rq->q;\n\tstruct list_head *running;\n\tbool queued = false;\n\tstruct request *rq, *n;\n\tunsigned long flags = 0;\n\tstruct blk_flush_queue *fq = blk_get_flush_queue(q, flush_rq->mq_ctx);\n\n\tif (q->mq_ops) {\n\t\tstruct blk_mq_hw_ctx *hctx;\n\n\t\t/* release the tag's ownership to the req cloned from */\n\t\tspin_lock_irqsave(&fq->mq_flush_lock, flags);\n\t\thctx = q->mq_ops->map_queue(q, flush_rq->mq_ctx->cpu);\n\t\tblk_mq_tag_set_rq(hctx, flush_rq->tag, fq->orig_rq);\n\t\tflush_rq->tag = -1;\n\t}\n\n\trunning = &fq->flush_queue[fq->flush_running_idx];\n\tBUG_ON(fq->flush_pending_idx == fq->flush_running_idx);\n\n\t/* account completion of the flush request */\n\tfq->flush_running_idx ^= 1;\n\n\tif (!q->mq_ops)\n\t\telv_completed_request(q, flush_rq);\n\n\t/* and push the waiting requests to the next stage */\n\tlist_for_each_entry_safe(rq, n, running, flush.list) {\n\t\tunsigned int seq = blk_flush_cur_seq(rq);\n\n\t\tBUG_ON(seq != REQ_FSEQ_PREFLUSH && seq != REQ_FSEQ_POSTFLUSH);\n\t\tqueued |= blk_flush_complete_seq(rq, fq, seq, error);\n\t}\n\n\t/*\n\t * Kick the queue to avoid stall for two cases:\n\t * 1. Moving a request silently to empty queue_head may stall the\n\t * queue.\n\t * 2. When flush request is running in non-queueable queue, the\n\t * queue is hold. Restart the queue after flush request is finished\n\t * to avoid stall.\n\t * This function is called from request completion path and calling\n\t * directly into request_fn may confuse the driver.  Always use\n\t * kblockd.\n\t */\n\tif (queued || fq->flush_queue_delayed) {\n\t\tWARN_ON(q->mq_ops);\n\t\tblk_run_queue_async(q);\n\t}\n\tfq->flush_queue_delayed = 0;\n\tif (q->mq_ops)\n\t\tspin_unlock_irqrestore(&fq->mq_flush_lock, flags);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,12 @@\n \tstruct blk_flush_queue *fq = blk_get_flush_queue(q, flush_rq->mq_ctx);\n \n \tif (q->mq_ops) {\n+\t\tstruct blk_mq_hw_ctx *hctx;\n+\n+\t\t/* release the tag's ownership to the req cloned from */\n \t\tspin_lock_irqsave(&fq->mq_flush_lock, flags);\n+\t\thctx = q->mq_ops->map_queue(q, flush_rq->mq_ctx->cpu);\n+\t\tblk_mq_tag_set_rq(hctx, flush_rq->tag, fq->orig_rq);\n \t\tflush_rq->tag = -1;\n \t}\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\tstruct blk_mq_hw_ctx *hctx;",
                "",
                "\t\t/* release the tag's ownership to the req cloned from */",
                "\t\thctx = q->mq_ops->map_queue(q, flush_rq->mq_ctx->cpu);",
                "\t\tblk_mq_tag_set_rq(hctx, flush_rq->tag, fq->orig_rq);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-9016",
        "func_name": "torvalds/linux/blk_kick_flush",
        "description": "In blk_mq_tag_to_rq in blk-mq.c in the upstream kernel, there is a possible use after free due to a race condition when a request has been previously freed by blk_mq_complete_request. This could lead to local escalation of privilege. Product: Android. Versions: Android kernel. Android ID: A-63083046.",
        "git_url": "https://github.com/torvalds/linux/commit/0048b4837affd153897ed1222283492070027aa9",
        "commit_title": "blk-mq: fix race between timeout and freeing request",
        "commit_text": " Inside timeout handler, blk_mq_tag_to_rq() is called to retrieve the request from one tag. This way is obviously wrong because the request can be freed any time and some fiedds of the request can't be trusted, then kernel oops might be triggered[1].  Currently wrt. blk_mq_tag_to_rq(), the only special case is that the flush request can share same tag with the request cloned from, and the two requests can't be active at the same time, so this patch fixes the above issue by updating tags->rqs[tag] with the active request(either flush rq or the request cloned from) of the tag.  Also blk_mq_tag_to_rq() gets much simplified with this patch.  Given blk_mq_tag_to_rq() is mainly for drivers and the caller must make sure the request can't be freed, so in bt_for_each() this helper is replaced with tags->rqs[tag].  [1] kernel oops log [  439.696220] BUG: unable to handle kernel NULL pointer dereference at 0000000000000158^M [  439.697162] IP: [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.700653] PGD 7ef765067 PUD 7ef764067 PMD 0 ^M [  439.700653] Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC ^M [  439.700653] Dumping ftrace buffer:^M [  439.700653]    (ftrace buffer empty)^M [  439.700653] Modules linked in: nbd ipv6 kvm_intel kvm serio_raw^M [  439.700653] CPU: 6 PID: 2779 Comm: stress-ng-sigfd Not tainted 4.2.0-rc5-next-20150805+ #265^M [  439.730500] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011^M [  439.730500] task: ffff880605308000 ti: ffff88060530c000 task.ti: ffff88060530c000^M [  439.730500] RIP: 0010:[<ffffffff812d89ba>]  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.730500] RSP: 0018:ffff880819203da0  EFLAGS: 00010283^M [  439.730500] RAX: ffff880811b0e000 RBX: ffff8800bb465f00 RCX: 0000000000000002^M [  439.730500] RDX: 0000000000000000 RSI: 0000000000000202 RDI: 0000000000000000^M [  439.730500] RBP: ffff880819203db0 R08: 0000000000000002 R09: 0000000000000000^M [  439.730500] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000202^M [  439.730500] R13: ffff880814104800 R14: 0000000000000002 R15: ffff880811a2ea00^M [  439.730500] FS:  00007f165b3f5740(0000) GS:ffff880819200000(0000) knlGS:0000000000000000^M [  439.730500] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b^M [  439.730500] CR2: 0000000000000158 CR3: 00000007ef766000 CR4: 00000000000006e0^M [  439.730500] Stack:^M [  439.730500]  0000000000000008 ffff8808114eed90 ffff880819203e00 ffffffff812dc104^M [  439.755663]  ffff880819203e40 ffffffff812d9f5e 0000020000000000 ffff8808114eed80^M [  439.755663] Call Trace:^M [  439.755663]  <IRQ> ^M [  439.755663]  [<ffffffff812dc104>] bt_for_each+0x6e/0xc8^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812dc1b3>] blk_mq_tag_busy_iter+0x55/0x5e^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff812d8911>] blk_mq_rq_timer+0x5d/0xd4^M [  439.755663]  [<ffffffff810a3e10>] call_timer_fn+0xf7/0x284^M [  439.755663]  [<ffffffff810a3d1e>] ? call_timer_fn+0x5/0x284^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff810a46d6>] run_timer_softirq+0x1ce/0x1f8^M [  439.755663]  [<ffffffff8104c367>] __do_softirq+0x181/0x3a4^M [  439.755663]  [<ffffffff8104c76e>] irq_exit+0x40/0x94^M [  439.755663]  [<ffffffff81031482>] smp_apic_timer_interrupt+0x33/0x3e^M [  439.755663]  [<ffffffff815559a4>] apic_timer_interrupt+0x84/0x90^M [  439.755663]  <EOI> ^M [  439.755663]  [<ffffffff81554350>] ? _raw_spin_unlock_irq+0x32/0x4a^M [  439.755663]  [<ffffffff8106a98b>] finish_task_switch+0xe0/0x163^M [  439.755663]  [<ffffffff8106a94d>] ? finish_task_switch+0xa2/0x163^M [  439.755663]  [<ffffffff81550066>] __schedule+0x469/0x6cd^M [  439.755663]  [<ffffffff8155039b>] schedule+0x82/0x9a^M [  439.789267]  [<ffffffff8119b28b>] signalfd_read+0x186/0x49a^M [  439.790911]  [<ffffffff8106d86a>] ? wake_up_q+0x47/0x47^M [  439.790911]  [<ffffffff811618c2>] __vfs_read+0x28/0x9f^M [  439.790911]  [<ffffffff8117a289>] ? __fget_light+0x4d/0x74^M [  439.790911]  [<ffffffff811620a7>] vfs_read+0x7a/0xc6^M [  439.790911]  [<ffffffff8116292b>] SyS_read+0x49/0x7f^M [  439.790911]  [<ffffffff81554c17>] entry_SYSCALL_64_fastpath+0x12/0x6f^M [  439.790911] Code: 48 89 e5 e8 a9 b8 e7 ff 5d c3 0f 1f 44 00 00 55 89 f2 48 89 e5 41 54 41 89 f4 53 48 8b 47 60 48 8b 1c d0 48 8b 7b 30 48 8b 53 38 <48> 8b 87 58 01 00 00 48 85 c0 75 09 48 8b 97 88 0c 00 00 eb 10 ^M [  439.790911] RIP  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.790911]  RSP <ffff880819203da0>^M [  439.790911] CR2: 0000000000000158^M [  439.790911] ---[ end trace d40af58949325661 ]---^M  Cc: <stable@vger.kernel.org>",
        "func_before": "static bool blk_kick_flush(struct request_queue *q, struct blk_flush_queue *fq)\n{\n\tstruct list_head *pending = &fq->flush_queue[fq->flush_pending_idx];\n\tstruct request *first_rq =\n\t\tlist_first_entry(pending, struct request, flush.list);\n\tstruct request *flush_rq = fq->flush_rq;\n\n\t/* C1 described at the top of this file */\n\tif (fq->flush_pending_idx != fq->flush_running_idx || list_empty(pending))\n\t\treturn false;\n\n\t/* C2 and C3 */\n\tif (!list_empty(&fq->flush_data_in_flight) &&\n\t    time_before(jiffies,\n\t\t\tfq->flush_pending_since + FLUSH_PENDING_TIMEOUT))\n\t\treturn false;\n\n\t/*\n\t * Issue flush and toggle pending_idx.  This makes pending_idx\n\t * different from running_idx, which means flush is in flight.\n\t */\n\tfq->flush_pending_idx ^= 1;\n\n\tblk_rq_init(q, flush_rq);\n\n\t/*\n\t * Borrow tag from the first request since they can't\n\t * be in flight at the same time.\n\t */\n\tif (q->mq_ops) {\n\t\tflush_rq->mq_ctx = first_rq->mq_ctx;\n\t\tflush_rq->tag = first_rq->tag;\n\t}\n\n\tflush_rq->cmd_type = REQ_TYPE_FS;\n\tflush_rq->cmd_flags = WRITE_FLUSH | REQ_FLUSH_SEQ;\n\tflush_rq->rq_disk = first_rq->rq_disk;\n\tflush_rq->end_io = flush_end_io;\n\n\treturn blk_flush_queue_rq(flush_rq, false);\n}",
        "func": "static bool blk_kick_flush(struct request_queue *q, struct blk_flush_queue *fq)\n{\n\tstruct list_head *pending = &fq->flush_queue[fq->flush_pending_idx];\n\tstruct request *first_rq =\n\t\tlist_first_entry(pending, struct request, flush.list);\n\tstruct request *flush_rq = fq->flush_rq;\n\n\t/* C1 described at the top of this file */\n\tif (fq->flush_pending_idx != fq->flush_running_idx || list_empty(pending))\n\t\treturn false;\n\n\t/* C2 and C3 */\n\tif (!list_empty(&fq->flush_data_in_flight) &&\n\t    time_before(jiffies,\n\t\t\tfq->flush_pending_since + FLUSH_PENDING_TIMEOUT))\n\t\treturn false;\n\n\t/*\n\t * Issue flush and toggle pending_idx.  This makes pending_idx\n\t * different from running_idx, which means flush is in flight.\n\t */\n\tfq->flush_pending_idx ^= 1;\n\n\tblk_rq_init(q, flush_rq);\n\n\t/*\n\t * Borrow tag from the first request since they can't\n\t * be in flight at the same time. And acquire the tag's\n\t * ownership for flush req.\n\t */\n\tif (q->mq_ops) {\n\t\tstruct blk_mq_hw_ctx *hctx;\n\n\t\tflush_rq->mq_ctx = first_rq->mq_ctx;\n\t\tflush_rq->tag = first_rq->tag;\n\t\tfq->orig_rq = first_rq;\n\n\t\thctx = q->mq_ops->map_queue(q, first_rq->mq_ctx->cpu);\n\t\tblk_mq_tag_set_rq(hctx, first_rq->tag, flush_rq);\n\t}\n\n\tflush_rq->cmd_type = REQ_TYPE_FS;\n\tflush_rq->cmd_flags = WRITE_FLUSH | REQ_FLUSH_SEQ;\n\tflush_rq->rq_disk = first_rq->rq_disk;\n\tflush_rq->end_io = flush_end_io;\n\n\treturn blk_flush_queue_rq(flush_rq, false);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,11 +25,18 @@\n \n \t/*\n \t * Borrow tag from the first request since they can't\n-\t * be in flight at the same time.\n+\t * be in flight at the same time. And acquire the tag's\n+\t * ownership for flush req.\n \t */\n \tif (q->mq_ops) {\n+\t\tstruct blk_mq_hw_ctx *hctx;\n+\n \t\tflush_rq->mq_ctx = first_rq->mq_ctx;\n \t\tflush_rq->tag = first_rq->tag;\n+\t\tfq->orig_rq = first_rq;\n+\n+\t\thctx = q->mq_ops->map_queue(q, first_rq->mq_ctx->cpu);\n+\t\tblk_mq_tag_set_rq(hctx, first_rq->tag, flush_rq);\n \t}\n \n \tflush_rq->cmd_type = REQ_TYPE_FS;",
        "diff_line_info": {
            "deleted_lines": [
                "\t * be in flight at the same time."
            ],
            "added_lines": [
                "\t * be in flight at the same time. And acquire the tag's",
                "\t * ownership for flush req.",
                "\t\tstruct blk_mq_hw_ctx *hctx;",
                "",
                "\t\tfq->orig_rq = first_rq;",
                "",
                "\t\thctx = q->mq_ops->map_queue(q, first_rq->mq_ctx->cpu);",
                "\t\tblk_mq_tag_set_rq(hctx, first_rq->tag, flush_rq);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-9016",
        "func_name": "torvalds/linux/blk_mq_tag_to_rq",
        "description": "In blk_mq_tag_to_rq in blk-mq.c in the upstream kernel, there is a possible use after free due to a race condition when a request has been previously freed by blk_mq_complete_request. This could lead to local escalation of privilege. Product: Android. Versions: Android kernel. Android ID: A-63083046.",
        "git_url": "https://github.com/torvalds/linux/commit/0048b4837affd153897ed1222283492070027aa9",
        "commit_title": "blk-mq: fix race between timeout and freeing request",
        "commit_text": " Inside timeout handler, blk_mq_tag_to_rq() is called to retrieve the request from one tag. This way is obviously wrong because the request can be freed any time and some fiedds of the request can't be trusted, then kernel oops might be triggered[1].  Currently wrt. blk_mq_tag_to_rq(), the only special case is that the flush request can share same tag with the request cloned from, and the two requests can't be active at the same time, so this patch fixes the above issue by updating tags->rqs[tag] with the active request(either flush rq or the request cloned from) of the tag.  Also blk_mq_tag_to_rq() gets much simplified with this patch.  Given blk_mq_tag_to_rq() is mainly for drivers and the caller must make sure the request can't be freed, so in bt_for_each() this helper is replaced with tags->rqs[tag].  [1] kernel oops log [  439.696220] BUG: unable to handle kernel NULL pointer dereference at 0000000000000158^M [  439.697162] IP: [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.700653] PGD 7ef765067 PUD 7ef764067 PMD 0 ^M [  439.700653] Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC ^M [  439.700653] Dumping ftrace buffer:^M [  439.700653]    (ftrace buffer empty)^M [  439.700653] Modules linked in: nbd ipv6 kvm_intel kvm serio_raw^M [  439.700653] CPU: 6 PID: 2779 Comm: stress-ng-sigfd Not tainted 4.2.0-rc5-next-20150805+ #265^M [  439.730500] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011^M [  439.730500] task: ffff880605308000 ti: ffff88060530c000 task.ti: ffff88060530c000^M [  439.730500] RIP: 0010:[<ffffffff812d89ba>]  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.730500] RSP: 0018:ffff880819203da0  EFLAGS: 00010283^M [  439.730500] RAX: ffff880811b0e000 RBX: ffff8800bb465f00 RCX: 0000000000000002^M [  439.730500] RDX: 0000000000000000 RSI: 0000000000000202 RDI: 0000000000000000^M [  439.730500] RBP: ffff880819203db0 R08: 0000000000000002 R09: 0000000000000000^M [  439.730500] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000202^M [  439.730500] R13: ffff880814104800 R14: 0000000000000002 R15: ffff880811a2ea00^M [  439.730500] FS:  00007f165b3f5740(0000) GS:ffff880819200000(0000) knlGS:0000000000000000^M [  439.730500] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b^M [  439.730500] CR2: 0000000000000158 CR3: 00000007ef766000 CR4: 00000000000006e0^M [  439.730500] Stack:^M [  439.730500]  0000000000000008 ffff8808114eed90 ffff880819203e00 ffffffff812dc104^M [  439.755663]  ffff880819203e40 ffffffff812d9f5e 0000020000000000 ffff8808114eed80^M [  439.755663] Call Trace:^M [  439.755663]  <IRQ> ^M [  439.755663]  [<ffffffff812dc104>] bt_for_each+0x6e/0xc8^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812dc1b3>] blk_mq_tag_busy_iter+0x55/0x5e^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff812d8911>] blk_mq_rq_timer+0x5d/0xd4^M [  439.755663]  [<ffffffff810a3e10>] call_timer_fn+0xf7/0x284^M [  439.755663]  [<ffffffff810a3d1e>] ? call_timer_fn+0x5/0x284^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff810a46d6>] run_timer_softirq+0x1ce/0x1f8^M [  439.755663]  [<ffffffff8104c367>] __do_softirq+0x181/0x3a4^M [  439.755663]  [<ffffffff8104c76e>] irq_exit+0x40/0x94^M [  439.755663]  [<ffffffff81031482>] smp_apic_timer_interrupt+0x33/0x3e^M [  439.755663]  [<ffffffff815559a4>] apic_timer_interrupt+0x84/0x90^M [  439.755663]  <EOI> ^M [  439.755663]  [<ffffffff81554350>] ? _raw_spin_unlock_irq+0x32/0x4a^M [  439.755663]  [<ffffffff8106a98b>] finish_task_switch+0xe0/0x163^M [  439.755663]  [<ffffffff8106a94d>] ? finish_task_switch+0xa2/0x163^M [  439.755663]  [<ffffffff81550066>] __schedule+0x469/0x6cd^M [  439.755663]  [<ffffffff8155039b>] schedule+0x82/0x9a^M [  439.789267]  [<ffffffff8119b28b>] signalfd_read+0x186/0x49a^M [  439.790911]  [<ffffffff8106d86a>] ? wake_up_q+0x47/0x47^M [  439.790911]  [<ffffffff811618c2>] __vfs_read+0x28/0x9f^M [  439.790911]  [<ffffffff8117a289>] ? __fget_light+0x4d/0x74^M [  439.790911]  [<ffffffff811620a7>] vfs_read+0x7a/0xc6^M [  439.790911]  [<ffffffff8116292b>] SyS_read+0x49/0x7f^M [  439.790911]  [<ffffffff81554c17>] entry_SYSCALL_64_fastpath+0x12/0x6f^M [  439.790911] Code: 48 89 e5 e8 a9 b8 e7 ff 5d c3 0f 1f 44 00 00 55 89 f2 48 89 e5 41 54 41 89 f4 53 48 8b 47 60 48 8b 1c d0 48 8b 7b 30 48 8b 53 38 <48> 8b 87 58 01 00 00 48 85 c0 75 09 48 8b 97 88 0c 00 00 eb 10 ^M [  439.790911] RIP  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.790911]  RSP <ffff880819203da0>^M [  439.790911] CR2: 0000000000000158^M [  439.790911] ---[ end trace d40af58949325661 ]---^M  Cc: <stable@vger.kernel.org>",
        "func_before": "struct request *blk_mq_tag_to_rq(struct blk_mq_tags *tags, unsigned int tag)\n{\n\tstruct request *rq = tags->rqs[tag];\n\t/* mq_ctx of flush rq is always cloned from the corresponding req */\n\tstruct blk_flush_queue *fq = blk_get_flush_queue(rq->q, rq->mq_ctx);\n\n\tif (!is_flush_request(rq, fq, tag))\n\t\treturn rq;\n\n\treturn fq->flush_rq;\n}",
        "func": "struct request *blk_mq_tag_to_rq(struct blk_mq_tags *tags, unsigned int tag)\n{\n\treturn tags->rqs[tag];\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,11 +1,4 @@\n struct request *blk_mq_tag_to_rq(struct blk_mq_tags *tags, unsigned int tag)\n {\n-\tstruct request *rq = tags->rqs[tag];\n-\t/* mq_ctx of flush rq is always cloned from the corresponding req */\n-\tstruct blk_flush_queue *fq = blk_get_flush_queue(rq->q, rq->mq_ctx);\n-\n-\tif (!is_flush_request(rq, fq, tag))\n-\t\treturn rq;\n-\n-\treturn fq->flush_rq;\n+\treturn tags->rqs[tag];\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct request *rq = tags->rqs[tag];",
                "\t/* mq_ctx of flush rq is always cloned from the corresponding req */",
                "\tstruct blk_flush_queue *fq = blk_get_flush_queue(rq->q, rq->mq_ctx);",
                "",
                "\tif (!is_flush_request(rq, fq, tag))",
                "\t\treturn rq;",
                "",
                "\treturn fq->flush_rq;"
            ],
            "added_lines": [
                "\treturn tags->rqs[tag];"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-9016",
        "func_name": "torvalds/linux/bt_for_each",
        "description": "In blk_mq_tag_to_rq in blk-mq.c in the upstream kernel, there is a possible use after free due to a race condition when a request has been previously freed by blk_mq_complete_request. This could lead to local escalation of privilege. Product: Android. Versions: Android kernel. Android ID: A-63083046.",
        "git_url": "https://github.com/torvalds/linux/commit/0048b4837affd153897ed1222283492070027aa9",
        "commit_title": "blk-mq: fix race between timeout and freeing request",
        "commit_text": " Inside timeout handler, blk_mq_tag_to_rq() is called to retrieve the request from one tag. This way is obviously wrong because the request can be freed any time and some fiedds of the request can't be trusted, then kernel oops might be triggered[1].  Currently wrt. blk_mq_tag_to_rq(), the only special case is that the flush request can share same tag with the request cloned from, and the two requests can't be active at the same time, so this patch fixes the above issue by updating tags->rqs[tag] with the active request(either flush rq or the request cloned from) of the tag.  Also blk_mq_tag_to_rq() gets much simplified with this patch.  Given blk_mq_tag_to_rq() is mainly for drivers and the caller must make sure the request can't be freed, so in bt_for_each() this helper is replaced with tags->rqs[tag].  [1] kernel oops log [  439.696220] BUG: unable to handle kernel NULL pointer dereference at 0000000000000158^M [  439.697162] IP: [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.700653] PGD 7ef765067 PUD 7ef764067 PMD 0 ^M [  439.700653] Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC ^M [  439.700653] Dumping ftrace buffer:^M [  439.700653]    (ftrace buffer empty)^M [  439.700653] Modules linked in: nbd ipv6 kvm_intel kvm serio_raw^M [  439.700653] CPU: 6 PID: 2779 Comm: stress-ng-sigfd Not tainted 4.2.0-rc5-next-20150805+ #265^M [  439.730500] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011^M [  439.730500] task: ffff880605308000 ti: ffff88060530c000 task.ti: ffff88060530c000^M [  439.730500] RIP: 0010:[<ffffffff812d89ba>]  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.730500] RSP: 0018:ffff880819203da0  EFLAGS: 00010283^M [  439.730500] RAX: ffff880811b0e000 RBX: ffff8800bb465f00 RCX: 0000000000000002^M [  439.730500] RDX: 0000000000000000 RSI: 0000000000000202 RDI: 0000000000000000^M [  439.730500] RBP: ffff880819203db0 R08: 0000000000000002 R09: 0000000000000000^M [  439.730500] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000202^M [  439.730500] R13: ffff880814104800 R14: 0000000000000002 R15: ffff880811a2ea00^M [  439.730500] FS:  00007f165b3f5740(0000) GS:ffff880819200000(0000) knlGS:0000000000000000^M [  439.730500] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b^M [  439.730500] CR2: 0000000000000158 CR3: 00000007ef766000 CR4: 00000000000006e0^M [  439.730500] Stack:^M [  439.730500]  0000000000000008 ffff8808114eed90 ffff880819203e00 ffffffff812dc104^M [  439.755663]  ffff880819203e40 ffffffff812d9f5e 0000020000000000 ffff8808114eed80^M [  439.755663] Call Trace:^M [  439.755663]  <IRQ> ^M [  439.755663]  [<ffffffff812dc104>] bt_for_each+0x6e/0xc8^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812dc1b3>] blk_mq_tag_busy_iter+0x55/0x5e^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff812d8911>] blk_mq_rq_timer+0x5d/0xd4^M [  439.755663]  [<ffffffff810a3e10>] call_timer_fn+0xf7/0x284^M [  439.755663]  [<ffffffff810a3d1e>] ? call_timer_fn+0x5/0x284^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff810a46d6>] run_timer_softirq+0x1ce/0x1f8^M [  439.755663]  [<ffffffff8104c367>] __do_softirq+0x181/0x3a4^M [  439.755663]  [<ffffffff8104c76e>] irq_exit+0x40/0x94^M [  439.755663]  [<ffffffff81031482>] smp_apic_timer_interrupt+0x33/0x3e^M [  439.755663]  [<ffffffff815559a4>] apic_timer_interrupt+0x84/0x90^M [  439.755663]  <EOI> ^M [  439.755663]  [<ffffffff81554350>] ? _raw_spin_unlock_irq+0x32/0x4a^M [  439.755663]  [<ffffffff8106a98b>] finish_task_switch+0xe0/0x163^M [  439.755663]  [<ffffffff8106a94d>] ? finish_task_switch+0xa2/0x163^M [  439.755663]  [<ffffffff81550066>] __schedule+0x469/0x6cd^M [  439.755663]  [<ffffffff8155039b>] schedule+0x82/0x9a^M [  439.789267]  [<ffffffff8119b28b>] signalfd_read+0x186/0x49a^M [  439.790911]  [<ffffffff8106d86a>] ? wake_up_q+0x47/0x47^M [  439.790911]  [<ffffffff811618c2>] __vfs_read+0x28/0x9f^M [  439.790911]  [<ffffffff8117a289>] ? __fget_light+0x4d/0x74^M [  439.790911]  [<ffffffff811620a7>] vfs_read+0x7a/0xc6^M [  439.790911]  [<ffffffff8116292b>] SyS_read+0x49/0x7f^M [  439.790911]  [<ffffffff81554c17>] entry_SYSCALL_64_fastpath+0x12/0x6f^M [  439.790911] Code: 48 89 e5 e8 a9 b8 e7 ff 5d c3 0f 1f 44 00 00 55 89 f2 48 89 e5 41 54 41 89 f4 53 48 8b 47 60 48 8b 1c d0 48 8b 7b 30 48 8b 53 38 <48> 8b 87 58 01 00 00 48 85 c0 75 09 48 8b 97 88 0c 00 00 eb 10 ^M [  439.790911] RIP  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.790911]  RSP <ffff880819203da0>^M [  439.790911] CR2: 0000000000000158^M [  439.790911] ---[ end trace d40af58949325661 ]---^M  Cc: <stable@vger.kernel.org>",
        "func_before": "static void bt_for_each(struct blk_mq_hw_ctx *hctx,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n\t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n\t\t     bit < bm->depth;\n\t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t     \trq = blk_mq_tag_to_rq(hctx->tags, off + bit);\n\t\t\tif (rq->q == hctx->queue)\n\t\t\t\tfn(hctx, rq, data, reserved);\n\t\t}\n\n\t\toff += (1 << bt->bits_per_word);\n\t}\n}",
        "func": "static void bt_for_each(struct blk_mq_hw_ctx *hctx,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n\t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n\t\t     bit < bm->depth;\n\t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t\trq = hctx->tags->rqs[off + bit];\n\t\t\tif (rq->q == hctx->queue)\n\t\t\t\tfn(hctx, rq, data, reserved);\n\t\t}\n\n\t\toff += (1 << bt->bits_per_word);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -11,7 +11,7 @@\n \t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n \t\t     bit < bm->depth;\n \t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n-\t\t     \trq = blk_mq_tag_to_rq(hctx->tags, off + bit);\n+\t\t\trq = hctx->tags->rqs[off + bit];\n \t\t\tif (rq->q == hctx->queue)\n \t\t\t\tfn(hctx, rq, data, reserved);\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t     \trq = blk_mq_tag_to_rq(hctx->tags, off + bit);"
            ],
            "added_lines": [
                "\t\t\trq = hctx->tags->rqs[off + bit];"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-9016",
        "func_name": "torvalds/linux/bt_tags_for_each",
        "description": "In blk_mq_tag_to_rq in blk-mq.c in the upstream kernel, there is a possible use after free due to a race condition when a request has been previously freed by blk_mq_complete_request. This could lead to local escalation of privilege. Product: Android. Versions: Android kernel. Android ID: A-63083046.",
        "git_url": "https://github.com/torvalds/linux/commit/0048b4837affd153897ed1222283492070027aa9",
        "commit_title": "blk-mq: fix race between timeout and freeing request",
        "commit_text": " Inside timeout handler, blk_mq_tag_to_rq() is called to retrieve the request from one tag. This way is obviously wrong because the request can be freed any time and some fiedds of the request can't be trusted, then kernel oops might be triggered[1].  Currently wrt. blk_mq_tag_to_rq(), the only special case is that the flush request can share same tag with the request cloned from, and the two requests can't be active at the same time, so this patch fixes the above issue by updating tags->rqs[tag] with the active request(either flush rq or the request cloned from) of the tag.  Also blk_mq_tag_to_rq() gets much simplified with this patch.  Given blk_mq_tag_to_rq() is mainly for drivers and the caller must make sure the request can't be freed, so in bt_for_each() this helper is replaced with tags->rqs[tag].  [1] kernel oops log [  439.696220] BUG: unable to handle kernel NULL pointer dereference at 0000000000000158^M [  439.697162] IP: [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.700653] PGD 7ef765067 PUD 7ef764067 PMD 0 ^M [  439.700653] Oops: 0000 [#1] PREEMPT SMP DEBUG_PAGEALLOC ^M [  439.700653] Dumping ftrace buffer:^M [  439.700653]    (ftrace buffer empty)^M [  439.700653] Modules linked in: nbd ipv6 kvm_intel kvm serio_raw^M [  439.700653] CPU: 6 PID: 2779 Comm: stress-ng-sigfd Not tainted 4.2.0-rc5-next-20150805+ #265^M [  439.730500] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Bochs 01/01/2011^M [  439.730500] task: ffff880605308000 ti: ffff88060530c000 task.ti: ffff88060530c000^M [  439.730500] RIP: 0010:[<ffffffff812d89ba>]  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.730500] RSP: 0018:ffff880819203da0  EFLAGS: 00010283^M [  439.730500] RAX: ffff880811b0e000 RBX: ffff8800bb465f00 RCX: 0000000000000002^M [  439.730500] RDX: 0000000000000000 RSI: 0000000000000202 RDI: 0000000000000000^M [  439.730500] RBP: ffff880819203db0 R08: 0000000000000002 R09: 0000000000000000^M [  439.730500] R10: 0000000000000000 R11: 0000000000000000 R12: 0000000000000202^M [  439.730500] R13: ffff880814104800 R14: 0000000000000002 R15: ffff880811a2ea00^M [  439.730500] FS:  00007f165b3f5740(0000) GS:ffff880819200000(0000) knlGS:0000000000000000^M [  439.730500] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b^M [  439.730500] CR2: 0000000000000158 CR3: 00000007ef766000 CR4: 00000000000006e0^M [  439.730500] Stack:^M [  439.730500]  0000000000000008 ffff8808114eed90 ffff880819203e00 ffffffff812dc104^M [  439.755663]  ffff880819203e40 ffffffff812d9f5e 0000020000000000 ffff8808114eed80^M [  439.755663] Call Trace:^M [  439.755663]  <IRQ> ^M [  439.755663]  [<ffffffff812dc104>] bt_for_each+0x6e/0xc8^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812d9f5e>] ? blk_mq_rq_timed_out+0x6a/0x6a^M [  439.755663]  [<ffffffff812dc1b3>] blk_mq_tag_busy_iter+0x55/0x5e^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff812d8911>] blk_mq_rq_timer+0x5d/0xd4^M [  439.755663]  [<ffffffff810a3e10>] call_timer_fn+0xf7/0x284^M [  439.755663]  [<ffffffff810a3d1e>] ? call_timer_fn+0x5/0x284^M [  439.755663]  [<ffffffff812d88b4>] ? blk_mq_bio_to_request+0x38/0x38^M [  439.755663]  [<ffffffff810a46d6>] run_timer_softirq+0x1ce/0x1f8^M [  439.755663]  [<ffffffff8104c367>] __do_softirq+0x181/0x3a4^M [  439.755663]  [<ffffffff8104c76e>] irq_exit+0x40/0x94^M [  439.755663]  [<ffffffff81031482>] smp_apic_timer_interrupt+0x33/0x3e^M [  439.755663]  [<ffffffff815559a4>] apic_timer_interrupt+0x84/0x90^M [  439.755663]  <EOI> ^M [  439.755663]  [<ffffffff81554350>] ? _raw_spin_unlock_irq+0x32/0x4a^M [  439.755663]  [<ffffffff8106a98b>] finish_task_switch+0xe0/0x163^M [  439.755663]  [<ffffffff8106a94d>] ? finish_task_switch+0xa2/0x163^M [  439.755663]  [<ffffffff81550066>] __schedule+0x469/0x6cd^M [  439.755663]  [<ffffffff8155039b>] schedule+0x82/0x9a^M [  439.789267]  [<ffffffff8119b28b>] signalfd_read+0x186/0x49a^M [  439.790911]  [<ffffffff8106d86a>] ? wake_up_q+0x47/0x47^M [  439.790911]  [<ffffffff811618c2>] __vfs_read+0x28/0x9f^M [  439.790911]  [<ffffffff8117a289>] ? __fget_light+0x4d/0x74^M [  439.790911]  [<ffffffff811620a7>] vfs_read+0x7a/0xc6^M [  439.790911]  [<ffffffff8116292b>] SyS_read+0x49/0x7f^M [  439.790911]  [<ffffffff81554c17>] entry_SYSCALL_64_fastpath+0x12/0x6f^M [  439.790911] Code: 48 89 e5 e8 a9 b8 e7 ff 5d c3 0f 1f 44 00 00 55 89 f2 48 89 e5 41 54 41 89 f4 53 48 8b 47 60 48 8b 1c d0 48 8b 7b 30 48 8b 53 38 <48> 8b 87 58 01 00 00 48 85 c0 75 09 48 8b 97 88 0c 00 00 eb 10 ^M [  439.790911] RIP  [<ffffffff812d89ba>] blk_mq_tag_to_rq+0x21/0x6e^M [  439.790911]  RSP <ffff880819203da0>^M [  439.790911] CR2: 0000000000000158^M [  439.790911] ---[ end trace d40af58949325661 ]---^M  Cc: <stable@vger.kernel.org>",
        "func_before": "static void bt_tags_for_each(struct blk_mq_tags *tags,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_tag_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tif (!tags->rqs)\n\t\treturn;\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n\t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n\t\t     bit < bm->depth;\n\t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t\trq = blk_mq_tag_to_rq(tags, off + bit);\n\t\t\tfn(rq, data, reserved);\n\t\t}\n\n\t\toff += (1 << bt->bits_per_word);\n\t}\n}",
        "func": "static void bt_tags_for_each(struct blk_mq_tags *tags,\n\t\tstruct blk_mq_bitmap_tags *bt, unsigned int off,\n\t\tbusy_tag_iter_fn *fn, void *data, bool reserved)\n{\n\tstruct request *rq;\n\tint bit, i;\n\n\tif (!tags->rqs)\n\t\treturn;\n\tfor (i = 0; i < bt->map_nr; i++) {\n\t\tstruct blk_align_bitmap *bm = &bt->map[i];\n\n\t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n\t\t     bit < bm->depth;\n\t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n\t\t\trq = tags->rqs[off + bit];\n\t\t\tfn(rq, data, reserved);\n\t\t}\n\n\t\toff += (1 << bt->bits_per_word);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,7 +13,7 @@\n \t\tfor (bit = find_first_bit(&bm->word, bm->depth);\n \t\t     bit < bm->depth;\n \t\t     bit = find_next_bit(&bm->word, bm->depth, bit + 1)) {\n-\t\t\trq = blk_mq_tag_to_rq(tags, off + bit);\n+\t\t\trq = tags->rqs[off + bit];\n \t\t\tfn(rq, data, reserved);\n \t\t}\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\trq = blk_mq_tag_to_rq(tags, off + bit);"
            ],
            "added_lines": [
                "\t\t\trq = tags->rqs[off + bit];"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0056",
        "func_name": "torvalds/linux/mem_write",
        "description": "The mem_write function in the Linux kernel before 3.2.2, when ASLR is disabled, does not properly check permissions when writing to /proc/<pid>/mem, which allows local users to gain privileges by modifying process memory, as demonstrated by Mempodipper.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=e268337dfe26dfc7efd422a804dbb27977a3cccc",
        "commit_title": "Jri Aedla reported that the /proc/<pid>/mem handling really isn't very",
        "commit_text": "robust, and it also doesn't match the permission checking of any of the other related files.  This changes it to do the permission checks at open time, and instead of tracking the process, it tracks the VM at the time of the open.  That simplifies the code a lot, but does mean that if you hold the file descriptor open over an execve(), you'll continue to read from the _old_ VM.  That is different from our previous behavior, but much simpler.  If somebody actually finds a load where this matters, we'll need to revert this commit.  I suspect that nobody will ever notice - because the process mapping addresses will also have changed as part of the execve.  So you cannot actually usefully access the fd across a VM change simply because all the offsets for IO would have changed too.  Cc: Al Viro <viro@zeniv.linux.org.uk> ",
        "func_before": "static ssize_t mem_write(struct file * file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\tint copied;\n\tchar *page;\n\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);\n\tunsigned long dst = *ppos;\n\tstruct mm_struct *mm;\n\n\tcopied = -ESRCH;\n\tif (!task)\n\t\tgoto out_no_task;\n\n\tcopied = -ENOMEM;\n\tpage = (char *)__get_free_page(GFP_TEMPORARY);\n\tif (!page)\n\t\tgoto out_task;\n\n\tmm = check_mem_permission(task);\n\tcopied = PTR_ERR(mm);\n\tif (IS_ERR(mm))\n\t\tgoto out_free;\n\n\tcopied = -EIO;\n\tif (file->private_data != (void *)((long)current->self_exec_id))\n\t\tgoto out_mm;\n\n\tcopied = 0;\n\twhile (count > 0) {\n\t\tint this_len, retval;\n\n\t\tthis_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;\n\t\tif (copy_from_user(page, buf, this_len)) {\n\t\t\tcopied = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tretval = access_remote_vm(mm, dst, page, this_len, 1);\n\t\tif (!retval) {\n\t\t\tif (!copied)\n\t\t\t\tcopied = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tcopied += retval;\n\t\tbuf += retval;\n\t\tdst += retval;\n\t\tcount -= retval;\t\t\t\n\t}\n\t*ppos = dst;\n\nout_mm:\n\tmmput(mm);\nout_free:\n\tfree_page((unsigned long) page);\nout_task:\n\tput_task_struct(task);\nout_no_task:\n\treturn copied;\n}",
        "func": "static ssize_t mem_write(struct file * file, const char __user *buf,\n\t\t\t size_t count, loff_t *ppos)\n{\n\tint copied;\n\tchar *page;\n\tunsigned long dst = *ppos;\n\tstruct mm_struct *mm = file->private_data;\n\n\tif (!mm)\n\t\treturn 0;\n\n\tpage = (char *)__get_free_page(GFP_TEMPORARY);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tcopied = 0;\n\twhile (count > 0) {\n\t\tint this_len, retval;\n\n\t\tthis_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;\n\t\tif (copy_from_user(page, buf, this_len)) {\n\t\t\tcopied = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tretval = access_remote_vm(mm, dst, page, this_len, 1);\n\t\tif (!retval) {\n\t\t\tif (!copied)\n\t\t\t\tcopied = -EIO;\n\t\t\tbreak;\n\t\t}\n\t\tcopied += retval;\n\t\tbuf += retval;\n\t\tdst += retval;\n\t\tcount -= retval;\t\t\t\n\t}\n\t*ppos = dst;\n\n\tfree_page((unsigned long) page);\n\treturn copied;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,27 +3,15 @@\n {\n \tint copied;\n \tchar *page;\n-\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);\n \tunsigned long dst = *ppos;\n-\tstruct mm_struct *mm;\n+\tstruct mm_struct *mm = file->private_data;\n \n-\tcopied = -ESRCH;\n-\tif (!task)\n-\t\tgoto out_no_task;\n+\tif (!mm)\n+\t\treturn 0;\n \n-\tcopied = -ENOMEM;\n \tpage = (char *)__get_free_page(GFP_TEMPORARY);\n \tif (!page)\n-\t\tgoto out_task;\n-\n-\tmm = check_mem_permission(task);\n-\tcopied = PTR_ERR(mm);\n-\tif (IS_ERR(mm))\n-\t\tgoto out_free;\n-\n-\tcopied = -EIO;\n-\tif (file->private_data != (void *)((long)current->self_exec_id))\n-\t\tgoto out_mm;\n+\t\treturn -ENOMEM;\n \n \tcopied = 0;\n \twhile (count > 0) {\n@@ -47,12 +35,6 @@\n \t}\n \t*ppos = dst;\n \n-out_mm:\n-\tmmput(mm);\n-out_free:\n \tfree_page((unsigned long) page);\n-out_task:\n-\tput_task_struct(task);\n-out_no_task:\n \treturn copied;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);",
                "\tstruct mm_struct *mm;",
                "\tcopied = -ESRCH;",
                "\tif (!task)",
                "\t\tgoto out_no_task;",
                "\tcopied = -ENOMEM;",
                "\t\tgoto out_task;",
                "",
                "\tmm = check_mem_permission(task);",
                "\tcopied = PTR_ERR(mm);",
                "\tif (IS_ERR(mm))",
                "\t\tgoto out_free;",
                "",
                "\tcopied = -EIO;",
                "\tif (file->private_data != (void *)((long)current->self_exec_id))",
                "\t\tgoto out_mm;",
                "out_mm:",
                "\tmmput(mm);",
                "out_free:",
                "out_task:",
                "\tput_task_struct(task);",
                "out_no_task:"
            ],
            "added_lines": [
                "\tstruct mm_struct *mm = file->private_data;",
                "\tif (!mm)",
                "\t\treturn 0;",
                "\t\treturn -ENOMEM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0056",
        "func_name": "torvalds/linux/mem_read",
        "description": "The mem_write function in the Linux kernel before 3.2.2, when ASLR is disabled, does not properly check permissions when writing to /proc/<pid>/mem, which allows local users to gain privileges by modifying process memory, as demonstrated by Mempodipper.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=e268337dfe26dfc7efd422a804dbb27977a3cccc",
        "commit_title": "Jri Aedla reported that the /proc/<pid>/mem handling really isn't very",
        "commit_text": "robust, and it also doesn't match the permission checking of any of the other related files.  This changes it to do the permission checks at open time, and instead of tracking the process, it tracks the VM at the time of the open.  That simplifies the code a lot, but does mean that if you hold the file descriptor open over an execve(), you'll continue to read from the _old_ VM.  That is different from our previous behavior, but much simpler.  If somebody actually finds a load where this matters, we'll need to revert this commit.  I suspect that nobody will ever notice - because the process mapping addresses will also have changed as part of the execve.  So you cannot actually usefully access the fd across a VM change simply because all the offsets for IO would have changed too.  Cc: Al Viro <viro@zeniv.linux.org.uk> ",
        "func_before": "static ssize_t mem_read(struct file * file, char __user * buf,\n\t\t\tsize_t count, loff_t *ppos)\n{\n\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);\n\tchar *page;\n\tunsigned long src = *ppos;\n\tint ret = -ESRCH;\n\tstruct mm_struct *mm;\n\n\tif (!task)\n\t\tgoto out_no_task;\n\n\tret = -ENOMEM;\n\tpage = (char *)__get_free_page(GFP_TEMPORARY);\n\tif (!page)\n\t\tgoto out;\n\n\tmm = check_mem_permission(task);\n\tret = PTR_ERR(mm);\n\tif (IS_ERR(mm))\n\t\tgoto out_free;\n\n\tret = -EIO;\n \n\tif (file->private_data != (void*)((long)current->self_exec_id))\n\t\tgoto out_put;\n\n\tret = 0;\n \n\twhile (count > 0) {\n\t\tint this_len, retval;\n\n\t\tthis_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;\n\t\tretval = access_remote_vm(mm, src, page, this_len, 0);\n\t\tif (!retval) {\n\t\t\tif (!ret)\n\t\t\t\tret = -EIO;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (copy_to_user(buf, page, retval)) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n \n\t\tret += retval;\n\t\tsrc += retval;\n\t\tbuf += retval;\n\t\tcount -= retval;\n\t}\n\t*ppos = src;\n\nout_put:\n\tmmput(mm);\nout_free:\n\tfree_page((unsigned long) page);\nout:\n\tput_task_struct(task);\nout_no_task:\n\treturn ret;\n}",
        "func": "static ssize_t mem_read(struct file * file, char __user * buf,\n\t\t\tsize_t count, loff_t *ppos)\n{\n\tint ret;\n\tchar *page;\n\tunsigned long src = *ppos;\n\tstruct mm_struct *mm = file->private_data;\n\n\tif (!mm)\n\t\treturn 0;\n\n\tpage = (char *)__get_free_page(GFP_TEMPORARY);\n\tif (!page)\n\t\treturn -ENOMEM;\n\n\tret = 0;\n \n\twhile (count > 0) {\n\t\tint this_len, retval;\n\n\t\tthis_len = (count > PAGE_SIZE) ? PAGE_SIZE : count;\n\t\tretval = access_remote_vm(mm, src, page, this_len, 0);\n\t\tif (!retval) {\n\t\t\tif (!ret)\n\t\t\t\tret = -EIO;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (copy_to_user(buf, page, retval)) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n \n\t\tret += retval;\n\t\tsrc += retval;\n\t\tbuf += retval;\n\t\tcount -= retval;\n\t}\n\t*ppos = src;\n\n\tfree_page((unsigned long) page);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,29 +1,17 @@\n static ssize_t mem_read(struct file * file, char __user * buf,\n \t\t\tsize_t count, loff_t *ppos)\n {\n-\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);\n+\tint ret;\n \tchar *page;\n \tunsigned long src = *ppos;\n-\tint ret = -ESRCH;\n-\tstruct mm_struct *mm;\n+\tstruct mm_struct *mm = file->private_data;\n \n-\tif (!task)\n-\t\tgoto out_no_task;\n+\tif (!mm)\n+\t\treturn 0;\n \n-\tret = -ENOMEM;\n \tpage = (char *)__get_free_page(GFP_TEMPORARY);\n \tif (!page)\n-\t\tgoto out;\n-\n-\tmm = check_mem_permission(task);\n-\tret = PTR_ERR(mm);\n-\tif (IS_ERR(mm))\n-\t\tgoto out_free;\n-\n-\tret = -EIO;\n- \n-\tif (file->private_data != (void*)((long)current->self_exec_id))\n-\t\tgoto out_put;\n+\t\treturn -ENOMEM;\n \n \tret = 0;\n  \n@@ -50,12 +38,6 @@\n \t}\n \t*ppos = src;\n \n-out_put:\n-\tmmput(mm);\n-out_free:\n \tfree_page((unsigned long) page);\n-out:\n-\tput_task_struct(task);\n-out_no_task:\n \treturn ret;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);",
                "\tint ret = -ESRCH;",
                "\tstruct mm_struct *mm;",
                "\tif (!task)",
                "\t\tgoto out_no_task;",
                "\tret = -ENOMEM;",
                "\t\tgoto out;",
                "",
                "\tmm = check_mem_permission(task);",
                "\tret = PTR_ERR(mm);",
                "\tif (IS_ERR(mm))",
                "\t\tgoto out_free;",
                "",
                "\tret = -EIO;",
                " ",
                "\tif (file->private_data != (void*)((long)current->self_exec_id))",
                "\t\tgoto out_put;",
                "out_put:",
                "\tmmput(mm);",
                "out_free:",
                "out:",
                "\tput_task_struct(task);",
                "out_no_task:"
            ],
            "added_lines": [
                "\tint ret;",
                "\tstruct mm_struct *mm = file->private_data;",
                "\tif (!mm)",
                "\t\treturn 0;",
                "\t\treturn -ENOMEM;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0056",
        "func_name": "torvalds/linux/mm_for_maps",
        "description": "The mem_write function in the Linux kernel before 3.2.2, when ASLR is disabled, does not properly check permissions when writing to /proc/<pid>/mem, which allows local users to gain privileges by modifying process memory, as demonstrated by Mempodipper.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=e268337dfe26dfc7efd422a804dbb27977a3cccc",
        "commit_title": "Jri Aedla reported that the /proc/<pid>/mem handling really isn't very",
        "commit_text": "robust, and it also doesn't match the permission checking of any of the other related files.  This changes it to do the permission checks at open time, and instead of tracking the process, it tracks the VM at the time of the open.  That simplifies the code a lot, but does mean that if you hold the file descriptor open over an execve(), you'll continue to read from the _old_ VM.  That is different from our previous behavior, but much simpler.  If somebody actually finds a load where this matters, we'll need to revert this commit.  I suspect that nobody will ever notice - because the process mapping addresses will also have changed as part of the execve.  So you cannot actually usefully access the fd across a VM change simply because all the offsets for IO would have changed too.  Cc: Al Viro <viro@zeniv.linux.org.uk> ",
        "func_before": "struct mm_struct *mm_for_maps(struct task_struct *task)\n{\n\tstruct mm_struct *mm;\n\tint err;\n\n\terr =  mutex_lock_killable(&task->signal->cred_guard_mutex);\n\tif (err)\n\t\treturn ERR_PTR(err);\n\n\tmm = get_task_mm(task);\n\tif (mm && mm != current->mm &&\n\t\t\t!ptrace_may_access(task, PTRACE_MODE_READ)) {\n\t\tmmput(mm);\n\t\tmm = ERR_PTR(-EACCES);\n\t}\n\tmutex_unlock(&task->signal->cred_guard_mutex);\n\n\treturn mm;\n}",
        "func": "struct mm_struct *mm_for_maps(struct task_struct *task)\n{\n\treturn mm_access(task, PTRACE_MODE_READ);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,19 +1,4 @@\n struct mm_struct *mm_for_maps(struct task_struct *task)\n {\n-\tstruct mm_struct *mm;\n-\tint err;\n-\n-\terr =  mutex_lock_killable(&task->signal->cred_guard_mutex);\n-\tif (err)\n-\t\treturn ERR_PTR(err);\n-\n-\tmm = get_task_mm(task);\n-\tif (mm && mm != current->mm &&\n-\t\t\t!ptrace_may_access(task, PTRACE_MODE_READ)) {\n-\t\tmmput(mm);\n-\t\tmm = ERR_PTR(-EACCES);\n-\t}\n-\tmutex_unlock(&task->signal->cred_guard_mutex);\n-\n-\treturn mm;\n+\treturn mm_access(task, PTRACE_MODE_READ);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tstruct mm_struct *mm;",
                "\tint err;",
                "",
                "\terr =  mutex_lock_killable(&task->signal->cred_guard_mutex);",
                "\tif (err)",
                "\t\treturn ERR_PTR(err);",
                "",
                "\tmm = get_task_mm(task);",
                "\tif (mm && mm != current->mm &&",
                "\t\t\t!ptrace_may_access(task, PTRACE_MODE_READ)) {",
                "\t\tmmput(mm);",
                "\t\tmm = ERR_PTR(-EACCES);",
                "\t}",
                "\tmutex_unlock(&task->signal->cred_guard_mutex);",
                "",
                "\treturn mm;"
            ],
            "added_lines": [
                "\treturn mm_access(task, PTRACE_MODE_READ);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-0056",
        "func_name": "torvalds/linux/mem_open",
        "description": "The mem_write function in the Linux kernel before 3.2.2, when ASLR is disabled, does not properly check permissions when writing to /proc/<pid>/mem, which allows local users to gain privileges by modifying process memory, as demonstrated by Mempodipper.",
        "git_url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux.git;a=commitdiff;h=e268337dfe26dfc7efd422a804dbb27977a3cccc",
        "commit_title": "Jri Aedla reported that the /proc/<pid>/mem handling really isn't very",
        "commit_text": "robust, and it also doesn't match the permission checking of any of the other related files.  This changes it to do the permission checks at open time, and instead of tracking the process, it tracks the VM at the time of the open.  That simplifies the code a lot, but does mean that if you hold the file descriptor open over an execve(), you'll continue to read from the _old_ VM.  That is different from our previous behavior, but much simpler.  If somebody actually finds a load where this matters, we'll need to revert this commit.  I suspect that nobody will ever notice - because the process mapping addresses will also have changed as part of the execve.  So you cannot actually usefully access the fd across a VM change simply because all the offsets for IO would have changed too.  Cc: Al Viro <viro@zeniv.linux.org.uk> ",
        "func_before": "static int mem_open(struct inode* inode, struct file* file)\n{\n\tfile->private_data = (void*)((long)current->self_exec_id);\n\t/* OK to pass negative loff_t, we can catch out-of-range */\n\tfile->f_mode |= FMODE_UNSIGNED_OFFSET;\n\treturn 0;\n}",
        "func": "static int mem_open(struct inode* inode, struct file* file)\n{\n\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);\n\tstruct mm_struct *mm;\n\n\tif (!task)\n\t\treturn -ESRCH;\n\n\tmm = mm_access(task, PTRACE_MODE_ATTACH);\n\tput_task_struct(task);\n\n\tif (IS_ERR(mm))\n\t\treturn PTR_ERR(mm);\n\n\t/* OK to pass negative loff_t, we can catch out-of-range */\n\tfile->f_mode |= FMODE_UNSIGNED_OFFSET;\n\tfile->private_data = mm;\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,20 @@\n static int mem_open(struct inode* inode, struct file* file)\n {\n-\tfile->private_data = (void*)((long)current->self_exec_id);\n+\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);\n+\tstruct mm_struct *mm;\n+\n+\tif (!task)\n+\t\treturn -ESRCH;\n+\n+\tmm = mm_access(task, PTRACE_MODE_ATTACH);\n+\tput_task_struct(task);\n+\n+\tif (IS_ERR(mm))\n+\t\treturn PTR_ERR(mm);\n+\n \t/* OK to pass negative loff_t, we can catch out-of-range */\n \tfile->f_mode |= FMODE_UNSIGNED_OFFSET;\n+\tfile->private_data = mm;\n+\n \treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tfile->private_data = (void*)((long)current->self_exec_id);"
            ],
            "added_lines": [
                "\tstruct task_struct *task = get_proc_task(file->f_path.dentry->d_inode);",
                "\tstruct mm_struct *mm;",
                "",
                "\tif (!task)",
                "\t\treturn -ESRCH;",
                "",
                "\tmm = mm_access(task, PTRACE_MODE_ATTACH);",
                "\tput_task_struct(task);",
                "",
                "\tif (IS_ERR(mm))",
                "\t\treturn PTR_ERR(mm);",
                "",
                "\tfile->private_data = mm;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/unuse_pmd_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static inline int unuse_pmd_range(struct vm_area_struct *vma, pud_t *pud,\n\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\tswp_entry_t entry, struct page *page)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\tint ret;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (unlikely(pmd_trans_huge(*pmd)))\n\t\t\tcontinue;\n\t\tif (pmd_none_or_clear_bad(pmd))\n\t\t\tcontinue;\n\t\tret = unuse_pte_range(vma, pmd, addr, next, entry, page);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} while (pmd++, addr = next, addr != end);\n\treturn 0;\n}",
        "func": "static inline int unuse_pmd_range(struct vm_area_struct *vma, pud_t *pud,\n\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\tswp_entry_t entry, struct page *page)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\tint ret;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n\t\t\tcontinue;\n\t\tret = unuse_pte_range(vma, pmd, addr, next, entry, page);\n\t\tif (ret)\n\t\t\treturn ret;\n\t} while (pmd++, addr = next, addr != end);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -9,9 +9,7 @@\n \tpmd = pmd_offset(pud, addr);\n \tdo {\n \t\tnext = pmd_addr_end(addr, end);\n-\t\tif (unlikely(pmd_trans_huge(*pmd)))\n-\t\t\tcontinue;\n-\t\tif (pmd_none_or_clear_bad(pmd))\n+\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n \t\t\tcontinue;\n \t\tret = unuse_pte_range(vma, pmd, addr, next, entry, page);\n \t\tif (ret)",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (unlikely(pmd_trans_huge(*pmd)))",
                "\t\t\tcontinue;",
                "\t\tif (pmd_none_or_clear_bad(pmd))"
            ],
            "added_lines": [
                "\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/mincore_pmd_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static void mincore_pmd_range(struct vm_area_struct *vma, pud_t *pud,\n\t\t\tunsigned long addr, unsigned long end,\n\t\t\tunsigned char *vec)\n{\n\tunsigned long next;\n\tpmd_t *pmd;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (pmd_trans_huge(*pmd)) {\n\t\t\tif (mincore_huge_pmd(vma, pmd, addr, next, vec)) {\n\t\t\t\tvec += (next - addr) >> PAGE_SHIFT;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* fall through */\n\t\t}\n\t\tif (pmd_none_or_clear_bad(pmd))\n\t\t\tmincore_unmapped_range(vma, addr, next, vec);\n\t\telse\n\t\t\tmincore_pte_range(vma, pmd, addr, next, vec);\n\t\tvec += (next - addr) >> PAGE_SHIFT;\n\t} while (pmd++, addr = next, addr != end);\n}",
        "func": "static void mincore_pmd_range(struct vm_area_struct *vma, pud_t *pud,\n\t\t\tunsigned long addr, unsigned long end,\n\t\t\tunsigned char *vec)\n{\n\tunsigned long next;\n\tpmd_t *pmd;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (pmd_trans_huge(*pmd)) {\n\t\t\tif (mincore_huge_pmd(vma, pmd, addr, next, vec)) {\n\t\t\t\tvec += (next - addr) >> PAGE_SHIFT;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* fall through */\n\t\t}\n\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n\t\t\tmincore_unmapped_range(vma, addr, next, vec);\n\t\telse\n\t\t\tmincore_pte_range(vma, pmd, addr, next, vec);\n\t\tvec += (next - addr) >> PAGE_SHIFT;\n\t} while (pmd++, addr = next, addr != end);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -15,7 +15,7 @@\n \t\t\t}\n \t\t\t/* fall through */\n \t\t}\n-\t\tif (pmd_none_or_clear_bad(pmd))\n+\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n \t\t\tmincore_unmapped_range(vma, addr, next, vec);\n \t\telse\n \t\t\tmincore_pte_range(vma, pmd, addr, next, vec);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (pmd_none_or_clear_bad(pmd))"
            ],
            "added_lines": [
                "\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/mark_screen_rdonly",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static void mark_screen_rdonly(struct mm_struct *mm)\n{\n\tpgd_t *pgd;\n\tpud_t *pud;\n\tpmd_t *pmd;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\tint i;\n\n\tpgd = pgd_offset(mm, 0xA0000);\n\tif (pgd_none_or_clear_bad(pgd))\n\t\tgoto out;\n\tpud = pud_offset(pgd, 0xA0000);\n\tif (pud_none_or_clear_bad(pud))\n\t\tgoto out;\n\tpmd = pmd_offset(pud, 0xA0000);\n\tsplit_huge_page_pmd(mm, pmd);\n\tif (pmd_none_or_clear_bad(pmd))\n\t\tgoto out;\n\tpte = pte_offset_map_lock(mm, pmd, 0xA0000, &ptl);\n\tfor (i = 0; i < 32; i++) {\n\t\tif (pte_present(*pte))\n\t\t\tset_pte(pte, pte_wrprotect(*pte));\n\t\tpte++;\n\t}\n\tpte_unmap_unlock(pte, ptl);\nout:\n\tflush_tlb();\n}",
        "func": "static void mark_screen_rdonly(struct mm_struct *mm)\n{\n\tpgd_t *pgd;\n\tpud_t *pud;\n\tpmd_t *pmd;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\tint i;\n\n\tdown_write(&mm->mmap_sem);\n\tpgd = pgd_offset(mm, 0xA0000);\n\tif (pgd_none_or_clear_bad(pgd))\n\t\tgoto out;\n\tpud = pud_offset(pgd, 0xA0000);\n\tif (pud_none_or_clear_bad(pud))\n\t\tgoto out;\n\tpmd = pmd_offset(pud, 0xA0000);\n\tsplit_huge_page_pmd(mm, pmd);\n\tif (pmd_none_or_clear_bad(pmd))\n\t\tgoto out;\n\tpte = pte_offset_map_lock(mm, pmd, 0xA0000, &ptl);\n\tfor (i = 0; i < 32; i++) {\n\t\tif (pte_present(*pte))\n\t\t\tset_pte(pte, pte_wrprotect(*pte));\n\t\tpte++;\n\t}\n\tpte_unmap_unlock(pte, ptl);\nout:\n\tup_write(&mm->mmap_sem);\n\tflush_tlb();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n \tspinlock_t *ptl;\n \tint i;\n \n+\tdown_write(&mm->mmap_sem);\n \tpgd = pgd_offset(mm, 0xA0000);\n \tif (pgd_none_or_clear_bad(pgd))\n \t\tgoto out;\n@@ -25,5 +26,6 @@\n \t}\n \tpte_unmap_unlock(pte, ptl);\n out:\n+\tup_write(&mm->mmap_sem);\n \tflush_tlb();\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tdown_write(&mm->mmap_sem);",
                "\tup_write(&mm->mmap_sem);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/mem_cgroup_move_charge_pte_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static int mem_cgroup_move_charge_pte_range(pmd_t *pmd,\n\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\tstruct mm_walk *walk)\n{\n\tint ret = 0;\n\tstruct vm_area_struct *vma = walk->private;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\nretry:\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; addr += PAGE_SIZE) {\n\t\tpte_t ptent = *(pte++);\n\t\tunion mc_target target;\n\t\tint type;\n\t\tstruct page *page;\n\t\tstruct page_cgroup *pc;\n\t\tswp_entry_t ent;\n\n\t\tif (!mc.precharge)\n\t\t\tbreak;\n\n\t\ttype = is_target_pte_for_mc(vma, addr, ptent, &target);\n\t\tswitch (type) {\n\t\tcase MC_TARGET_PAGE:\n\t\t\tpage = target.page;\n\t\t\tif (isolate_lru_page(page))\n\t\t\t\tgoto put;\n\t\t\tpc = lookup_page_cgroup(page);\n\t\t\tif (!mem_cgroup_move_account(page, 1, pc,\n\t\t\t\t\t\t     mc.from, mc.to, false)) {\n\t\t\t\tmc.precharge--;\n\t\t\t\t/* we uncharge from mc.from later. */\n\t\t\t\tmc.moved_charge++;\n\t\t\t}\n\t\t\tputback_lru_page(page);\nput:\t\t\t/* is_target_pte_for_mc() gets the page */\n\t\t\tput_page(page);\n\t\t\tbreak;\n\t\tcase MC_TARGET_SWAP:\n\t\t\tent = target.ent;\n\t\t\tif (!mem_cgroup_move_swap_account(ent,\n\t\t\t\t\t\tmc.from, mc.to, false)) {\n\t\t\t\tmc.precharge--;\n\t\t\t\t/* we fixup refcnts and charges later. */\n\t\t\t\tmc.moved_swap++;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\n\tif (addr != end) {\n\t\t/*\n\t\t * We have consumed all precharges we got in can_attach().\n\t\t * We try charge one by one, but don't do any additional\n\t\t * charges to mc.to if we have failed in charge once in attach()\n\t\t * phase.\n\t\t */\n\t\tret = mem_cgroup_do_precharge(1);\n\t\tif (!ret)\n\t\t\tgoto retry;\n\t}\n\n\treturn ret;\n}",
        "func": "static int mem_cgroup_move_charge_pte_range(pmd_t *pmd,\n\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\tstruct mm_walk *walk)\n{\n\tint ret = 0;\n\tstruct vm_area_struct *vma = walk->private;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\nretry:\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; addr += PAGE_SIZE) {\n\t\tpte_t ptent = *(pte++);\n\t\tunion mc_target target;\n\t\tint type;\n\t\tstruct page *page;\n\t\tstruct page_cgroup *pc;\n\t\tswp_entry_t ent;\n\n\t\tif (!mc.precharge)\n\t\t\tbreak;\n\n\t\ttype = is_target_pte_for_mc(vma, addr, ptent, &target);\n\t\tswitch (type) {\n\t\tcase MC_TARGET_PAGE:\n\t\t\tpage = target.page;\n\t\t\tif (isolate_lru_page(page))\n\t\t\t\tgoto put;\n\t\t\tpc = lookup_page_cgroup(page);\n\t\t\tif (!mem_cgroup_move_account(page, 1, pc,\n\t\t\t\t\t\t     mc.from, mc.to, false)) {\n\t\t\t\tmc.precharge--;\n\t\t\t\t/* we uncharge from mc.from later. */\n\t\t\t\tmc.moved_charge++;\n\t\t\t}\n\t\t\tputback_lru_page(page);\nput:\t\t\t/* is_target_pte_for_mc() gets the page */\n\t\t\tput_page(page);\n\t\t\tbreak;\n\t\tcase MC_TARGET_SWAP:\n\t\t\tent = target.ent;\n\t\t\tif (!mem_cgroup_move_swap_account(ent,\n\t\t\t\t\t\tmc.from, mc.to, false)) {\n\t\t\t\tmc.precharge--;\n\t\t\t\t/* we fixup refcnts and charges later. */\n\t\t\t\tmc.moved_swap++;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\n\tif (addr != end) {\n\t\t/*\n\t\t * We have consumed all precharges we got in can_attach().\n\t\t * We try charge one by one, but don't do any additional\n\t\t * charges to mc.to if we have failed in charge once in attach()\n\t\t * phase.\n\t\t */\n\t\tret = mem_cgroup_do_precharge(1);\n\t\tif (!ret)\n\t\t\tgoto retry;\n\t}\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,8 @@\n \tspinlock_t *ptl;\n \n \tsplit_huge_page_pmd(walk->mm, pmd);\n+\tif (pmd_trans_unstable(pmd))\n+\t\treturn 0;\n retry:\n \tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n \tfor (; addr != end; addr += PAGE_SIZE) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (pmd_trans_unstable(pmd))",
                "\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/mem_cgroup_count_precharge_pte_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static int mem_cgroup_count_precharge_pte_range(pmd_t *pmd,\n\t\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\t\tstruct mm_walk *walk)\n{\n\tstruct vm_area_struct *vma = walk->private;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\n\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; pte++, addr += PAGE_SIZE)\n\t\tif (is_target_pte_for_mc(vma, addr, *pte, NULL))\n\t\t\tmc.precharge++;\t/* increment precharge temporarily */\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\n\treturn 0;\n}",
        "func": "static int mem_cgroup_count_precharge_pte_range(pmd_t *pmd,\n\t\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\t\tstruct mm_walk *walk)\n{\n\tstruct vm_area_struct *vma = walk->private;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\n\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; pte++, addr += PAGE_SIZE)\n\t\tif (is_target_pte_for_mc(vma, addr, *pte, NULL))\n\t\t\tmc.precharge++;\t/* increment precharge temporarily */\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,8 @@\n \tspinlock_t *ptl;\n \n \tsplit_huge_page_pmd(walk->mm, pmd);\n+\tif (pmd_trans_unstable(pmd))\n+\t\treturn 0;\n \n \tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n \tfor (; addr != end; pte++, addr += PAGE_SIZE)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (pmd_trans_unstable(pmd))",
                "\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/check_pmd_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static inline int check_pmd_range(struct vm_area_struct *vma, pud_t *pud,\n\t\tunsigned long addr, unsigned long end,\n\t\tconst nodemask_t *nodes, unsigned long flags,\n\t\tvoid *private)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tsplit_huge_page_pmd(vma->vm_mm, pmd);\n\t\tif (pmd_none_or_clear_bad(pmd))\n\t\t\tcontinue;\n\t\tif (check_pte_range(vma, pmd, addr, next, nodes,\n\t\t\t\t    flags, private))\n\t\t\treturn -EIO;\n\t} while (pmd++, addr = next, addr != end);\n\treturn 0;\n}",
        "func": "static inline int check_pmd_range(struct vm_area_struct *vma, pud_t *pud,\n\t\tunsigned long addr, unsigned long end,\n\t\tconst nodemask_t *nodes, unsigned long flags,\n\t\tvoid *private)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tsplit_huge_page_pmd(vma->vm_mm, pmd);\n\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n\t\t\tcontinue;\n\t\tif (check_pte_range(vma, pmd, addr, next, nodes,\n\t\t\t\t    flags, private))\n\t\t\treturn -EIO;\n\t} while (pmd++, addr = next, addr != end);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,7 +10,7 @@\n \tdo {\n \t\tnext = pmd_addr_end(addr, end);\n \t\tsplit_huge_page_pmd(vma->vm_mm, pmd);\n-\t\tif (pmd_none_or_clear_bad(pmd))\n+\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n \t\t\tcontinue;\n \t\tif (check_pte_range(vma, pmd, addr, next, nodes,\n \t\t\t\t    flags, private))",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (pmd_none_or_clear_bad(pmd))"
            ],
            "added_lines": [
                "\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/zap_pmd_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static inline unsigned long zap_pmd_range(struct mmu_gather *tlb,\n\t\t\t\tstruct vm_area_struct *vma, pud_t *pud,\n\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\tstruct zap_details *details)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (pmd_trans_huge(*pmd)) {\n\t\t\tif (next-addr != HPAGE_PMD_SIZE) {\n\t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem));\n\t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd);\n\t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr))\n\t\t\t\tcontinue;\n\t\t\t/* fall through */\n\t\t}\n\t\tif (pmd_none_or_clear_bad(pmd))\n\t\t\tcontinue;\n\t\tnext = zap_pte_range(tlb, vma, pmd, addr, next, details);\n\t\tcond_resched();\n\t} while (pmd++, addr = next, addr != end);\n\n\treturn addr;\n}",
        "func": "static inline unsigned long zap_pmd_range(struct mmu_gather *tlb,\n\t\t\t\tstruct vm_area_struct *vma, pud_t *pud,\n\t\t\t\tunsigned long addr, unsigned long end,\n\t\t\t\tstruct zap_details *details)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (pmd_trans_huge(*pmd)) {\n\t\t\tif (next - addr != HPAGE_PMD_SIZE) {\n\t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem));\n\t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd);\n\t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr))\n\t\t\t\tgoto next;\n\t\t\t/* fall through */\n\t\t}\n\t\t/*\n\t\t * Here there can be other concurrent MADV_DONTNEED or\n\t\t * trans huge page faults running, and if the pmd is\n\t\t * none or trans huge it can change under us. This is\n\t\t * because MADV_DONTNEED holds the mmap_sem in read\n\t\t * mode.\n\t\t */\n\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n\t\t\tgoto next;\n\t\tnext = zap_pte_range(tlb, vma, pmd, addr, next, details);\nnext:\n\t\tcond_resched();\n\t} while (pmd++, addr = next, addr != end);\n\n\treturn addr;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,16 +10,24 @@\n \tdo {\n \t\tnext = pmd_addr_end(addr, end);\n \t\tif (pmd_trans_huge(*pmd)) {\n-\t\t\tif (next-addr != HPAGE_PMD_SIZE) {\n+\t\t\tif (next - addr != HPAGE_PMD_SIZE) {\n \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem));\n \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd);\n \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr))\n-\t\t\t\tcontinue;\n+\t\t\t\tgoto next;\n \t\t\t/* fall through */\n \t\t}\n-\t\tif (pmd_none_or_clear_bad(pmd))\n-\t\t\tcontinue;\n+\t\t/*\n+\t\t * Here there can be other concurrent MADV_DONTNEED or\n+\t\t * trans huge page faults running, and if the pmd is\n+\t\t * none or trans huge it can change under us. This is\n+\t\t * because MADV_DONTNEED holds the mmap_sem in read\n+\t\t * mode.\n+\t\t */\n+\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n+\t\t\tgoto next;\n \t\tnext = zap_pte_range(tlb, vma, pmd, addr, next, details);\n+next:\n \t\tcond_resched();\n \t} while (pmd++, addr = next, addr != end);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tif (next-addr != HPAGE_PMD_SIZE) {",
                "\t\t\t\tcontinue;",
                "\t\tif (pmd_none_or_clear_bad(pmd))",
                "\t\t\tcontinue;"
            ],
            "added_lines": [
                "\t\t\tif (next - addr != HPAGE_PMD_SIZE) {",
                "\t\t\t\tgoto next;",
                "\t\t/*",
                "\t\t * Here there can be other concurrent MADV_DONTNEED or",
                "\t\t * trans huge page faults running, and if the pmd is",
                "\t\t * none or trans huge it can change under us. This is",
                "\t\t * because MADV_DONTNEED holds the mmap_sem in read",
                "\t\t * mode.",
                "\t\t */",
                "\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))",
                "\t\t\tgoto next;",
                "next:"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/walk_pmd_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static int walk_pmd_range(pud_t *pud, unsigned long addr, unsigned long end,\n\t\t\t  struct mm_walk *walk)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\tint err = 0;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\nagain:\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (pmd_none(*pmd)) {\n\t\t\tif (walk->pte_hole)\n\t\t\t\terr = walk->pte_hole(addr, next, walk);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\t\t/*\n\t\t * This implies that each ->pmd_entry() handler\n\t\t * needs to know about pmd_trans_huge() pmds\n\t\t */\n\t\tif (walk->pmd_entry)\n\t\t\terr = walk->pmd_entry(pmd, addr, next, walk);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Check this here so we only break down trans_huge\n\t\t * pages when we _need_ to\n\t\t */\n\t\tif (!walk->pte_entry)\n\t\t\tcontinue;\n\n\t\tsplit_huge_page_pmd(walk->mm, pmd);\n\t\tif (pmd_none_or_clear_bad(pmd))\n\t\t\tgoto again;\n\t\terr = walk_pte_range(pmd, addr, next, walk);\n\t\tif (err)\n\t\t\tbreak;\n\t} while (pmd++, addr = next, addr != end);\n\n\treturn err;\n}",
        "func": "static int walk_pmd_range(pud_t *pud, unsigned long addr, unsigned long end,\n\t\t\t  struct mm_walk *walk)\n{\n\tpmd_t *pmd;\n\tunsigned long next;\n\tint err = 0;\n\n\tpmd = pmd_offset(pud, addr);\n\tdo {\nagain:\n\t\tnext = pmd_addr_end(addr, end);\n\t\tif (pmd_none(*pmd)) {\n\t\t\tif (walk->pte_hole)\n\t\t\t\terr = walk->pte_hole(addr, next, walk);\n\t\t\tif (err)\n\t\t\t\tbreak;\n\t\t\tcontinue;\n\t\t}\n\t\t/*\n\t\t * This implies that each ->pmd_entry() handler\n\t\t * needs to know about pmd_trans_huge() pmds\n\t\t */\n\t\tif (walk->pmd_entry)\n\t\t\terr = walk->pmd_entry(pmd, addr, next, walk);\n\t\tif (err)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Check this here so we only break down trans_huge\n\t\t * pages when we _need_ to\n\t\t */\n\t\tif (!walk->pte_entry)\n\t\t\tcontinue;\n\n\t\tsplit_huge_page_pmd(walk->mm, pmd);\n\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n\t\t\tgoto again;\n\t\terr = walk_pte_range(pmd, addr, next, walk);\n\t\tif (err)\n\t\t\tbreak;\n\t} while (pmd++, addr = next, addr != end);\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -33,7 +33,7 @@\n \t\t\tcontinue;\n \n \t\tsplit_huge_page_pmd(walk->mm, pmd);\n-\t\tif (pmd_none_or_clear_bad(pmd))\n+\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))\n \t\t\tgoto again;\n \t\terr = walk_pte_range(pmd, addr, next, walk);\n \t\tif (err)",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tif (pmd_none_or_clear_bad(pmd))"
            ],
            "added_lines": [
                "\t\tif (pmd_none_or_trans_huge_or_clear_bad(pmd))"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/pagemap_pte_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,\n\t\t\t     struct mm_walk *walk)\n{\n\tstruct vm_area_struct *vma;\n\tstruct pagemapread *pm = walk->private;\n\tpte_t *pte;\n\tint err = 0;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\n\n\t/* find the first VMA at or above 'addr' */\n\tvma = find_vma(walk->mm, addr);\n\tfor (; addr != end; addr += PAGE_SIZE) {\n\t\tu64 pfn = PM_NOT_PRESENT;\n\n\t\t/* check to see if we've left 'vma' behind\n\t\t * and need a new, higher one */\n\t\tif (vma && (addr >= vma->vm_end))\n\t\t\tvma = find_vma(walk->mm, addr);\n\n\t\t/* check that 'vma' actually covers this address,\n\t\t * and that it isn't a huge page vma */\n\t\tif (vma && (vma->vm_start <= addr) &&\n\t\t    !is_vm_hugetlb_page(vma)) {\n\t\t\tpte = pte_offset_map(pmd, addr);\n\t\t\tpfn = pte_to_pagemap_entry(*pte);\n\t\t\t/* unmap before userspace copy */\n\t\t\tpte_unmap(pte);\n\t\t}\n\t\terr = add_to_pagemap(addr, pfn, pm);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tcond_resched();\n\n\treturn err;\n}",
        "func": "static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,\n\t\t\t     struct mm_walk *walk)\n{\n\tstruct vm_area_struct *vma;\n\tstruct pagemapread *pm = walk->private;\n\tpte_t *pte;\n\tint err = 0;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\n\n\t/* find the first VMA at or above 'addr' */\n\tvma = find_vma(walk->mm, addr);\n\tfor (; addr != end; addr += PAGE_SIZE) {\n\t\tu64 pfn = PM_NOT_PRESENT;\n\n\t\t/* check to see if we've left 'vma' behind\n\t\t * and need a new, higher one */\n\t\tif (vma && (addr >= vma->vm_end))\n\t\t\tvma = find_vma(walk->mm, addr);\n\n\t\t/* check that 'vma' actually covers this address,\n\t\t * and that it isn't a huge page vma */\n\t\tif (vma && (vma->vm_start <= addr) &&\n\t\t    !is_vm_hugetlb_page(vma)) {\n\t\t\tpte = pte_offset_map(pmd, addr);\n\t\t\tpfn = pte_to_pagemap_entry(*pte);\n\t\t\t/* unmap before userspace copy */\n\t\t\tpte_unmap(pte);\n\t\t}\n\t\terr = add_to_pagemap(addr, pfn, pm);\n\t\tif (err)\n\t\t\treturn err;\n\t}\n\n\tcond_resched();\n\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,8 @@\n \tint err = 0;\n \n \tsplit_huge_page_pmd(walk->mm, pmd);\n+\tif (pmd_trans_unstable(pmd))\n+\t\treturn 0;\n \n \t/* find the first VMA at or above 'addr' */\n \tvma = find_vma(walk->mm, addr);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (pmd_trans_unstable(pmd))",
                "\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/clear_refs_pte_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static int clear_refs_pte_range(pmd_t *pmd, unsigned long addr,\n\t\t\t\tunsigned long end, struct mm_walk *walk)\n{\n\tstruct vm_area_struct *vma = walk->private;\n\tpte_t *pte, ptent;\n\tspinlock_t *ptl;\n\tstruct page *page;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\n\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; pte++, addr += PAGE_SIZE) {\n\t\tptent = *pte;\n\t\tif (!pte_present(ptent))\n\t\t\tcontinue;\n\n\t\tpage = vm_normal_page(vma, addr, ptent);\n\t\tif (!page)\n\t\t\tcontinue;\n\n\t\tif (PageReserved(page))\n\t\t\tcontinue;\n\n\t\t/* Clear accessed and referenced bits. */\n\t\tptep_test_and_clear_young(vma, addr, pte);\n\t\tClearPageReferenced(page);\n\t}\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\treturn 0;\n}",
        "func": "static int clear_refs_pte_range(pmd_t *pmd, unsigned long addr,\n\t\t\t\tunsigned long end, struct mm_walk *walk)\n{\n\tstruct vm_area_struct *vma = walk->private;\n\tpte_t *pte, ptent;\n\tspinlock_t *ptl;\n\tstruct page *page;\n\n\tsplit_huge_page_pmd(walk->mm, pmd);\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\n\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; pte++, addr += PAGE_SIZE) {\n\t\tptent = *pte;\n\t\tif (!pte_present(ptent))\n\t\t\tcontinue;\n\n\t\tpage = vm_normal_page(vma, addr, ptent);\n\t\tif (!page)\n\t\t\tcontinue;\n\n\t\tif (PageReserved(page))\n\t\t\tcontinue;\n\n\t\t/* Clear accessed and referenced bits. */\n\t\tptep_test_and_clear_young(vma, addr, pte);\n\t\tClearPageReferenced(page);\n\t}\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,8 @@\n \tstruct page *page;\n \n \tsplit_huge_page_pmd(walk->mm, pmd);\n+\tif (pmd_trans_unstable(pmd))\n+\t\treturn 0;\n \n \tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n \tfor (; addr != end; pte++, addr += PAGE_SIZE) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (pmd_trans_unstable(pmd))",
                "\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/smaps_pte_range",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static int smaps_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,\n\t\t\t   struct mm_walk *walk)\n{\n\tstruct mem_size_stats *mss = walk->private;\n\tstruct vm_area_struct *vma = mss->vma;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\n\tspin_lock(&walk->mm->page_table_lock);\n\tif (pmd_trans_huge(*pmd)) {\n\t\tif (pmd_trans_splitting(*pmd)) {\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\twait_split_huge_page(vma->anon_vma, pmd);\n\t\t} else {\n\t\t\tsmaps_pte_entry(*(pte_t *)pmd, addr,\n\t\t\t\t\tHPAGE_PMD_SIZE, walk);\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\tmss->anonymous_thp += HPAGE_PMD_SIZE;\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tspin_unlock(&walk->mm->page_table_lock);\n\t}\n\t/*\n\t * The mmap_sem held all the way back in m_start() is what\n\t * keeps khugepaged out of here and from collapsing things\n\t * in here.\n\t */\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; pte++, addr += PAGE_SIZE)\n\t\tsmaps_pte_entry(*pte, addr, PAGE_SIZE, walk);\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\treturn 0;\n}",
        "func": "static int smaps_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,\n\t\t\t   struct mm_walk *walk)\n{\n\tstruct mem_size_stats *mss = walk->private;\n\tstruct vm_area_struct *vma = mss->vma;\n\tpte_t *pte;\n\tspinlock_t *ptl;\n\n\tspin_lock(&walk->mm->page_table_lock);\n\tif (pmd_trans_huge(*pmd)) {\n\t\tif (pmd_trans_splitting(*pmd)) {\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\twait_split_huge_page(vma->anon_vma, pmd);\n\t\t} else {\n\t\t\tsmaps_pte_entry(*(pte_t *)pmd, addr,\n\t\t\t\t\tHPAGE_PMD_SIZE, walk);\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\tmss->anonymous_thp += HPAGE_PMD_SIZE;\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tspin_unlock(&walk->mm->page_table_lock);\n\t}\n\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\n\t/*\n\t * The mmap_sem held all the way back in m_start() is what\n\t * keeps khugepaged out of here and from collapsing things\n\t * in here.\n\t */\n\tpte = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\n\tfor (; addr != end; pte++, addr += PAGE_SIZE)\n\t\tsmaps_pte_entry(*pte, addr, PAGE_SIZE, walk);\n\tpte_unmap_unlock(pte - 1, ptl);\n\tcond_resched();\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -21,6 +21,9 @@\n \t} else {\n \t\tspin_unlock(&walk->mm->page_table_lock);\n \t}\n+\n+\tif (pmd_trans_unstable(pmd))\n+\t\treturn 0;\n \t/*\n \t * The mmap_sem held all the way back in m_start() is what\n \t * keeps khugepaged out of here and from collapsing things",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\tif (pmd_trans_unstable(pmd))",
                "\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-1179",
        "func_name": "torvalds/linux/gather_pte_stats",
        "description": "The Linux kernel before 3.3.1, when KVM is used, allows guest OS users to cause a denial of service (host OS crash) by leveraging administrative access to the guest OS, related to the pmd_none_or_clear_bad function and page faults for huge pages.",
        "git_url": "https://github.com/torvalds/linux/commit/4a1d704194a441bf83c636004a479e01360ec850",
        "commit_title": "mm: thp: fix pmd_bad() triggering in code paths holding mmap_sem read mode",
        "commit_text": " commit 1a5a9906d4e8d1976b701f889d8f35d54b928f25 upstream.  In some cases it may happen that pmd_none_or_clear_bad() is called with the mmap_sem hold in read mode.  In those cases the huge page faults can allocate hugepmds under pmd_none_or_clear_bad() and that can trigger a false positive from pmd_bad() that will not like to see a pmd materializing as trans huge.  It's not khugepaged causing the problem, khugepaged holds the mmap_sem in write mode (and all those sites must hold the mmap_sem in read mode to prevent pagetables to go away from under them, during code review it seems vm86 mode on 32bit kernels requires that too unless it's restricted to 1 thread per process or UP builds).  The race is only with the huge pagefaults that can convert a pmd_none() into a pmd_trans_huge().  Effectively all these pmd_none_or_clear_bad() sites running with mmap_sem in read mode are somewhat speculative with the page faults, and the result is always undefined when they run simultaneously.  This is probably why it wasn't common to run into this.  For example if the madvise(MADV_DONTNEED) runs zap_page_range() shortly before the page fault, the hugepage will not be zapped, if the page fault runs first it will be zapped.  Altering pmd_bad() not to error out if it finds hugepmds won't be enough to fix this, because zap_pmd_range would then proceed to call zap_pte_range (which would be incorrect if the pmd become a pmd_trans_huge()).  The simplest way to fix this is to read the pmd in the local stack (regardless of what we read, no need of actual CPU barriers, only compiler barrier needed), and be sure it is not changing under the code that computes its value.  Even if the real pmd is changing under the value we hold on the stack, we don't care.  If we actually end up in zap_pte_range it means the pmd was not none already and it was not huge, and it can't become huge from under us (khugepaged locking explained above).  All we need is to enforce that there is no way anymore that in a code path like below, pmd_trans_huge can be false, but pmd_none_or_clear_bad can run into a hugepmd.  The overhead of a barrier() is just a compiler tweak and should not be measurable (I only added it for THP builds).  I don't exclude different compiler versions may have prevented the race too by caching the value of *pmd on the stack (that hasn't been verified, but it wouldn't be impossible considering pmd_none_or_clear_bad, pmd_bad, pmd_trans_huge, pmd_none are all inlines and there's no external function called in between pmd_trans_huge and pmd_none_or_clear_bad).  \t\tif (pmd_trans_huge(*pmd)) { \t\t\tif (next-addr != HPAGE_PMD_SIZE) { \t\t\t\tVM_BUG_ON(!rwsem_is_locked(&tlb->mm->mmap_sem)); \t\t\t\tsplit_huge_page_pmd(vma->vm_mm, pmd); \t\t\t} else if (zap_huge_pmd(tlb, vma, pmd, addr)) \t\t\t\tcontinue; \t\t\t/* fall through */ \t\t} \t\tif (pmd_none_or_clear_bad(pmd))  Because this race condition could be exercised without special privileges this was reported in CVE-2012-1179.  The race was identified and fully explained by Ulrich who debugged it. I'm quoting his accurate explanation below, for reference.  ====== start quote =======       mapcount 0 page_mapcount 1       kernel BUG at mm/huge_memory.c:1384!      At some point prior to the panic, a \"bad pmd ...\" message similar to the     following is logged on the console:        mm/memory.c:145: bad pmd ffff8800376e1f98(80000000314000e7).      The \"bad pmd ...\" message is logged by pmd_clear_bad() before it clears     the page's PMD table entry.          143 void pmd_clear_bad(pmd_t *pmd)         144 {     ->  145         pmd_ERROR(*pmd);         146         pmd_clear(pmd);         147 }      After the PMD table entry has been cleared, there is an inconsistency     between the actual number of PMD table entries that are mapping the page     and the page's map count (_mapcount field in struct page). When the page     is subsequently reclaimed, __split_huge_page() detects this inconsistency.         1381         if (mapcount != page_mapcount(page))        1382                 printk(KERN_ERR \"mapcount %d page_mapcount %d\\n\",        1383                        mapcount, page_mapcount(page));     -> 1384         BUG_ON(mapcount != page_mapcount(page));      The root cause of the problem is a race of two threads in a multithreaded     process. Thread B incurs a page fault on a virtual address that has never     been accessed (PMD entry is zero) while Thread A is executing an madvise()     system call on a virtual address within the same 2 MB (huge page) range.                 virtual address space               .---------------------.               |                     |               |                     |             .-|---------------------|             | |                     |             | |                     |<-- B(fault)             | |                     |       2 MB  | |/////////////////////|-.       huge <  |/////////////////////|  > A(range)       page  | |/////////////////////|-'             | |                     |             | |                     |             '-|---------------------|               |                     |               |                     |               '---------------------'      - Thread A is executing an madvise(..., MADV_DONTNEED) system call       on the virtual address range \"A(range)\" shown in the picture.      sys_madvise       // Acquire the semaphore in shared mode.       down_read(&current->mm->mmap_sem)       ...       madvise_vma         switch (behavior)         case MADV_DONTNEED:              madvise_dontneed                zap_page_range                  unmap_vmas                    unmap_page_range                      zap_pud_range                        zap_pmd_range                          //                          // Assume that this huge page has never been accessed.                          // I.e. content of the PMD entry is zero (not mapped).                          //                          if (pmd_trans_huge(*pmd)) {                              // We don't get here due to the above assumption.                          }                          //                          // Assume that Thread B incurred a page fault and              .---------> // sneaks in here as shown below.              |           //              |           if (pmd_none_or_clear_bad(pmd))              |               {              |                 if (unlikely(pmd_bad(*pmd)))              |                     pmd_clear_bad              |                     {              |                       pmd_ERROR              |                         // Log \"bad pmd ...\" message here.              |                       pmd_clear              |                         // Clear the page's PMD entry.              |                         // Thread B incremented the map count              |                         // in page_add_new_anon_rmap(), but              |                         // now the page is no longer mapped              |                         // by a PMD entry (-> inconsistency).              |                     }              |               }              |              v     - Thread B is handling a page fault on virtual address \"B(fault)\" shown       in the picture.      ...     do_page_fault       __do_page_fault         // Acquire the semaphore in shared mode.         down_read_trylock(&mm->mmap_sem)         ...         handle_mm_fault           if (pmd_none(*pmd) && transparent_hugepage_enabled(vma))               // We get here due to the above assumption (PMD entry is zero).               do_huge_pmd_anonymous_page                 alloc_hugepage_vma                   // Allocate a new transparent huge page here.                 ...                 __do_huge_pmd_anonymous_page                   ...                   spin_lock(&mm->page_table_lock)                   ...                   page_add_new_anon_rmap                     // Here we increment the page's map count (starts at -1).                     atomic_set(&page->_mapcount, 0)                   set_pmd_at                     // Here we set the page's PMD entry which will be cleared                     // when Thread A calls pmd_clear_bad().                   ...                   spin_unlock(&mm->page_table_lock)      The mmap_sem does not prevent the race because both threads are acquiring     it in shared mode (down_read).  Thread B holds the page_table_lock while     the page's map count and PMD table entry are updated.  However, Thread A     does not synchronize on that lock.  ====== end quote =======  [akpm@linux-foundation.org: checkpatch fixes] Cc: Mel Gorman <mgorman@suse.de> Cc: Hugh Dickins <hughd@google.com> Cc: Dave Jones <davej@redhat.com> Cc: Mark Salter <msalter@redhat.com>",
        "func_before": "static int gather_pte_stats(pmd_t *pmd, unsigned long addr,\n\t\tunsigned long end, struct mm_walk *walk)\n{\n\tstruct numa_maps *md;\n\tspinlock_t *ptl;\n\tpte_t *orig_pte;\n\tpte_t *pte;\n\n\tmd = walk->private;\n\tspin_lock(&walk->mm->page_table_lock);\n\tif (pmd_trans_huge(*pmd)) {\n\t\tif (pmd_trans_splitting(*pmd)) {\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\twait_split_huge_page(md->vma->anon_vma, pmd);\n\t\t} else {\n\t\t\tpte_t huge_pte = *(pte_t *)pmd;\n\t\t\tstruct page *page;\n\n\t\t\tpage = can_gather_numa_stats(huge_pte, md->vma, addr);\n\t\t\tif (page)\n\t\t\t\tgather_stats(page, md, pte_dirty(huge_pte),\n\t\t\t\t\t\tHPAGE_PMD_SIZE/PAGE_SIZE);\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tspin_unlock(&walk->mm->page_table_lock);\n\t}\n\n\torig_pte = pte = pte_offset_map_lock(walk->mm, pmd, addr, &ptl);\n\tdo {\n\t\tstruct page *page = can_gather_numa_stats(*pte, md->vma, addr);\n\t\tif (!page)\n\t\t\tcontinue;\n\t\tgather_stats(page, md, pte_dirty(*pte), 1);\n\n\t} while (pte++, addr += PAGE_SIZE, addr != end);\n\tpte_unmap_unlock(orig_pte, ptl);\n\treturn 0;\n}",
        "func": "static int gather_pte_stats(pmd_t *pmd, unsigned long addr,\n\t\tunsigned long end, struct mm_walk *walk)\n{\n\tstruct numa_maps *md;\n\tspinlock_t *ptl;\n\tpte_t *orig_pte;\n\tpte_t *pte;\n\n\tmd = walk->private;\n\tspin_lock(&walk->mm->page_table_lock);\n\tif (pmd_trans_huge(*pmd)) {\n\t\tif (pmd_trans_splitting(*pmd)) {\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\twait_split_huge_page(md->vma->anon_vma, pmd);\n\t\t} else {\n\t\t\tpte_t huge_pte = *(pte_t *)pmd;\n\t\t\tstruct page *page;\n\n\t\t\tpage = can_gather_numa_stats(huge_pte, md->vma, addr);\n\t\t\tif (page)\n\t\t\t\tgather_stats(page, md, pte_dirty(huge_pte),\n\t\t\t\t\t\tHPAGE_PMD_SIZE/PAGE_SIZE);\n\t\t\tspin_unlock(&walk->mm->page_table_lock);\n\t\t\treturn 0;\n\t\t}\n\t} else {\n\t\tspin_unlock(&walk->mm->page_table_lock);\n\t}\n\n\tif (pmd_trans_unstable(pmd))\n\t\treturn 0;\n\torig_pte = pte = pte_offset_map_lock(walk->mm, pmd, addr, &ptl);\n\tdo {\n\t\tstruct page *page = can_gather_numa_stats(*pte, md->vma, addr);\n\t\tif (!page)\n\t\t\tcontinue;\n\t\tgather_stats(page, md, pte_dirty(*pte), 1);\n\n\t} while (pte++, addr += PAGE_SIZE, addr != end);\n\tpte_unmap_unlock(orig_pte, ptl);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,6 +27,8 @@\n \t\tspin_unlock(&walk->mm->page_table_lock);\n \t}\n \n+\tif (pmd_trans_unstable(pmd))\n+\t\treturn 0;\n \torig_pte = pte = pte_offset_map_lock(walk->mm, pmd, addr, &ptl);\n \tdo {\n \t\tstruct page *page = can_gather_numa_stats(*pte, md->vma, addr);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (pmd_trans_unstable(pmd))",
                "\t\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2121",
        "func_name": "torvalds/linux/__kvm_set_memory_region",
        "description": "The KVM implementation in the Linux kernel before 3.3.4 does not properly manage the relationships between memory slots and the iommu, which allows guest OS users to cause a denial of service (memory leak and host OS crash) by leveraging administrative access to the guest OS to conduct hotunplug and hotplug operations on devices.",
        "git_url": "https://github.com/torvalds/linux/commit/09ca8e1173bcb12e2a449698c9ae3b86a8a10195",
        "commit_title": "KVM: unmap pages from the iommu when slots are removed",
        "commit_text": " commit 32f6daad4651a748a58a3ab6da0611862175722f upstream.  We've been adding new mappings, but not destroying old mappings. This can lead to a page leak as pages are pinned using get_user_pages, but only unpinned with put_page if they still exist in the memslots list on vm shutdown.  A memslot that is destroyed while an iommu domain is enabled for the guest will therefore result in an elevated page reference count that is never cleared.  Additionally, without this fix, the iommu is only programmed with the first translation for a gpa.  This can result in peer-to-peer errors if a mapping is destroyed and replaced by a new mapping at the same gpa as the iommu will still be pointing to the original, pinned memory address. ",
        "func_before": "int __kvm_set_memory_region(struct kvm *kvm,\n\t\t\t    struct kvm_userspace_memory_region *mem,\n\t\t\t    int user_alloc)\n{\n\tint r;\n\tgfn_t base_gfn;\n\tunsigned long npages;\n\tunsigned long i;\n\tstruct kvm_memory_slot *memslot;\n\tstruct kvm_memory_slot old, new;\n\tstruct kvm_memslots *slots, *old_memslots;\n\n\tr = -EINVAL;\n\t/* General sanity checks */\n\tif (mem->memory_size & (PAGE_SIZE - 1))\n\t\tgoto out;\n\tif (mem->guest_phys_addr & (PAGE_SIZE - 1))\n\t\tgoto out;\n\t/* We can read the guest memory with __xxx_user() later on. */\n\tif (user_alloc &&\n\t    ((mem->userspace_addr & (PAGE_SIZE - 1)) ||\n\t     !access_ok(VERIFY_WRITE,\n\t\t\t(void __user *)(unsigned long)mem->userspace_addr,\n\t\t\tmem->memory_size)))\n\t\tgoto out;\n\tif (mem->slot >= KVM_MEM_SLOTS_NUM)\n\t\tgoto out;\n\tif (mem->guest_phys_addr + mem->memory_size < mem->guest_phys_addr)\n\t\tgoto out;\n\n\tmemslot = id_to_memslot(kvm->memslots, mem->slot);\n\tbase_gfn = mem->guest_phys_addr >> PAGE_SHIFT;\n\tnpages = mem->memory_size >> PAGE_SHIFT;\n\n\tr = -EINVAL;\n\tif (npages > KVM_MEM_MAX_NR_PAGES)\n\t\tgoto out;\n\n\tif (!npages)\n\t\tmem->flags &= ~KVM_MEM_LOG_DIRTY_PAGES;\n\n\tnew = old = *memslot;\n\n\tnew.id = mem->slot;\n\tnew.base_gfn = base_gfn;\n\tnew.npages = npages;\n\tnew.flags = mem->flags;\n\n\t/* Disallow changing a memory slot's size. */\n\tr = -EINVAL;\n\tif (npages && old.npages && npages != old.npages)\n\t\tgoto out_free;\n\n\t/* Check for overlaps */\n\tr = -EEXIST;\n\tfor (i = 0; i < KVM_MEMORY_SLOTS; ++i) {\n\t\tstruct kvm_memory_slot *s = &kvm->memslots->memslots[i];\n\n\t\tif (s == memslot || !s->npages)\n\t\t\tcontinue;\n\t\tif (!((base_gfn + npages <= s->base_gfn) ||\n\t\t      (base_gfn >= s->base_gfn + s->npages)))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Free page dirty bitmap if unneeded */\n\tif (!(new.flags & KVM_MEM_LOG_DIRTY_PAGES))\n\t\tnew.dirty_bitmap = NULL;\n\n\tr = -ENOMEM;\n\n\t/* Allocate if a slot is being created */\n#ifndef CONFIG_S390\n\tif (npages && !new.rmap) {\n\t\tnew.rmap = vzalloc(npages * sizeof(*new.rmap));\n\n\t\tif (!new.rmap)\n\t\t\tgoto out_free;\n\n\t\tnew.user_alloc = user_alloc;\n\t\tnew.userspace_addr = mem->userspace_addr;\n\t}\n\tif (!npages)\n\t\tgoto skip_lpage;\n\n\tfor (i = 0; i < KVM_NR_PAGE_SIZES - 1; ++i) {\n\t\tunsigned long ugfn;\n\t\tunsigned long j;\n\t\tint lpages;\n\t\tint level = i + 2;\n\n\t\t/* Avoid unused variable warning if no large pages */\n\t\t(void)level;\n\n\t\tif (new.lpage_info[i])\n\t\t\tcontinue;\n\n\t\tlpages = 1 + ((base_gfn + npages - 1)\n\t\t\t     >> KVM_HPAGE_GFN_SHIFT(level));\n\t\tlpages -= base_gfn >> KVM_HPAGE_GFN_SHIFT(level);\n\n\t\tnew.lpage_info[i] = vzalloc(lpages * sizeof(*new.lpage_info[i]));\n\n\t\tif (!new.lpage_info[i])\n\t\t\tgoto out_free;\n\n\t\tif (base_gfn & (KVM_PAGES_PER_HPAGE(level) - 1))\n\t\t\tnew.lpage_info[i][0].write_count = 1;\n\t\tif ((base_gfn+npages) & (KVM_PAGES_PER_HPAGE(level) - 1))\n\t\t\tnew.lpage_info[i][lpages - 1].write_count = 1;\n\t\tugfn = new.userspace_addr >> PAGE_SHIFT;\n\t\t/*\n\t\t * If the gfn and userspace address are not aligned wrt each\n\t\t * other, or if explicitly asked to, disable large page\n\t\t * support for this slot\n\t\t */\n\t\tif ((base_gfn ^ ugfn) & (KVM_PAGES_PER_HPAGE(level) - 1) ||\n\t\t    !largepages_enabled)\n\t\t\tfor (j = 0; j < lpages; ++j)\n\t\t\t\tnew.lpage_info[i][j].write_count = 1;\n\t}\n\nskip_lpage:\n\n\t/* Allocate page dirty bitmap if needed */\n\tif ((new.flags & KVM_MEM_LOG_DIRTY_PAGES) && !new.dirty_bitmap) {\n\t\tif (kvm_create_dirty_bitmap(&new) < 0)\n\t\t\tgoto out_free;\n\t\t/* destroy any largepage mappings for dirty tracking */\n\t}\n#else  /* not defined CONFIG_S390 */\n\tnew.user_alloc = user_alloc;\n\tif (user_alloc)\n\t\tnew.userspace_addr = mem->userspace_addr;\n#endif /* not defined CONFIG_S390 */\n\n\tif (!npages) {\n\t\tstruct kvm_memory_slot *slot;\n\n\t\tr = -ENOMEM;\n\t\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!slots)\n\t\t\tgoto out_free;\n\t\tslot = id_to_memslot(slots, mem->slot);\n\t\tslot->flags |= KVM_MEMSLOT_INVALID;\n\n\t\tupdate_memslots(slots, NULL);\n\n\t\told_memslots = kvm->memslots;\n\t\trcu_assign_pointer(kvm->memslots, slots);\n\t\tsynchronize_srcu_expedited(&kvm->srcu);\n\t\t/* From this point no new shadow pages pointing to a deleted\n\t\t * memslot will be created.\n\t\t *\n\t\t * validation of sp->gfn happens in:\n\t\t * \t- gfn_to_hva (kvm_read_guest, gfn_to_pfn)\n\t\t * \t- kvm_is_visible_gfn (mmu_check_roots)\n\t\t */\n\t\tkvm_arch_flush_shadow(kvm);\n\t\tkfree(old_memslots);\n\t}\n\n\tr = kvm_arch_prepare_memory_region(kvm, &new, old, mem, user_alloc);\n\tif (r)\n\t\tgoto out_free;\n\n\t/* map the pages in iommu page table */\n\tif (npages) {\n\t\tr = kvm_iommu_map_pages(kvm, &new);\n\t\tif (r)\n\t\t\tgoto out_free;\n\t}\n\n\tr = -ENOMEM;\n\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\tGFP_KERNEL);\n\tif (!slots)\n\t\tgoto out_free;\n\n\t/* actual memory is freed via old in kvm_free_physmem_slot below */\n\tif (!npages) {\n\t\tnew.rmap = NULL;\n\t\tnew.dirty_bitmap = NULL;\n\t\tfor (i = 0; i < KVM_NR_PAGE_SIZES - 1; ++i)\n\t\t\tnew.lpage_info[i] = NULL;\n\t}\n\n\tupdate_memslots(slots, &new);\n\told_memslots = kvm->memslots;\n\trcu_assign_pointer(kvm->memslots, slots);\n\tsynchronize_srcu_expedited(&kvm->srcu);\n\n\tkvm_arch_commit_memory_region(kvm, mem, old, user_alloc);\n\n\t/*\n\t * If the new memory slot is created, we need to clear all\n\t * mmio sptes.\n\t */\n\tif (npages && old.base_gfn != mem->guest_phys_addr >> PAGE_SHIFT)\n\t\tkvm_arch_flush_shadow(kvm);\n\n\tkvm_free_physmem_slot(&old, &new);\n\tkfree(old_memslots);\n\n\treturn 0;\n\nout_free:\n\tkvm_free_physmem_slot(&new, &old);\nout:\n\treturn r;\n\n}",
        "func": "int __kvm_set_memory_region(struct kvm *kvm,\n\t\t\t    struct kvm_userspace_memory_region *mem,\n\t\t\t    int user_alloc)\n{\n\tint r;\n\tgfn_t base_gfn;\n\tunsigned long npages;\n\tunsigned long i;\n\tstruct kvm_memory_slot *memslot;\n\tstruct kvm_memory_slot old, new;\n\tstruct kvm_memslots *slots, *old_memslots;\n\n\tr = -EINVAL;\n\t/* General sanity checks */\n\tif (mem->memory_size & (PAGE_SIZE - 1))\n\t\tgoto out;\n\tif (mem->guest_phys_addr & (PAGE_SIZE - 1))\n\t\tgoto out;\n\t/* We can read the guest memory with __xxx_user() later on. */\n\tif (user_alloc &&\n\t    ((mem->userspace_addr & (PAGE_SIZE - 1)) ||\n\t     !access_ok(VERIFY_WRITE,\n\t\t\t(void __user *)(unsigned long)mem->userspace_addr,\n\t\t\tmem->memory_size)))\n\t\tgoto out;\n\tif (mem->slot >= KVM_MEM_SLOTS_NUM)\n\t\tgoto out;\n\tif (mem->guest_phys_addr + mem->memory_size < mem->guest_phys_addr)\n\t\tgoto out;\n\n\tmemslot = id_to_memslot(kvm->memslots, mem->slot);\n\tbase_gfn = mem->guest_phys_addr >> PAGE_SHIFT;\n\tnpages = mem->memory_size >> PAGE_SHIFT;\n\n\tr = -EINVAL;\n\tif (npages > KVM_MEM_MAX_NR_PAGES)\n\t\tgoto out;\n\n\tif (!npages)\n\t\tmem->flags &= ~KVM_MEM_LOG_DIRTY_PAGES;\n\n\tnew = old = *memslot;\n\n\tnew.id = mem->slot;\n\tnew.base_gfn = base_gfn;\n\tnew.npages = npages;\n\tnew.flags = mem->flags;\n\n\t/* Disallow changing a memory slot's size. */\n\tr = -EINVAL;\n\tif (npages && old.npages && npages != old.npages)\n\t\tgoto out_free;\n\n\t/* Check for overlaps */\n\tr = -EEXIST;\n\tfor (i = 0; i < KVM_MEMORY_SLOTS; ++i) {\n\t\tstruct kvm_memory_slot *s = &kvm->memslots->memslots[i];\n\n\t\tif (s == memslot || !s->npages)\n\t\t\tcontinue;\n\t\tif (!((base_gfn + npages <= s->base_gfn) ||\n\t\t      (base_gfn >= s->base_gfn + s->npages)))\n\t\t\tgoto out_free;\n\t}\n\n\t/* Free page dirty bitmap if unneeded */\n\tif (!(new.flags & KVM_MEM_LOG_DIRTY_PAGES))\n\t\tnew.dirty_bitmap = NULL;\n\n\tr = -ENOMEM;\n\n\t/* Allocate if a slot is being created */\n#ifndef CONFIG_S390\n\tif (npages && !new.rmap) {\n\t\tnew.rmap = vzalloc(npages * sizeof(*new.rmap));\n\n\t\tif (!new.rmap)\n\t\t\tgoto out_free;\n\n\t\tnew.user_alloc = user_alloc;\n\t\tnew.userspace_addr = mem->userspace_addr;\n\t}\n\tif (!npages)\n\t\tgoto skip_lpage;\n\n\tfor (i = 0; i < KVM_NR_PAGE_SIZES - 1; ++i) {\n\t\tunsigned long ugfn;\n\t\tunsigned long j;\n\t\tint lpages;\n\t\tint level = i + 2;\n\n\t\t/* Avoid unused variable warning if no large pages */\n\t\t(void)level;\n\n\t\tif (new.lpage_info[i])\n\t\t\tcontinue;\n\n\t\tlpages = 1 + ((base_gfn + npages - 1)\n\t\t\t     >> KVM_HPAGE_GFN_SHIFT(level));\n\t\tlpages -= base_gfn >> KVM_HPAGE_GFN_SHIFT(level);\n\n\t\tnew.lpage_info[i] = vzalloc(lpages * sizeof(*new.lpage_info[i]));\n\n\t\tif (!new.lpage_info[i])\n\t\t\tgoto out_free;\n\n\t\tif (base_gfn & (KVM_PAGES_PER_HPAGE(level) - 1))\n\t\t\tnew.lpage_info[i][0].write_count = 1;\n\t\tif ((base_gfn+npages) & (KVM_PAGES_PER_HPAGE(level) - 1))\n\t\t\tnew.lpage_info[i][lpages - 1].write_count = 1;\n\t\tugfn = new.userspace_addr >> PAGE_SHIFT;\n\t\t/*\n\t\t * If the gfn and userspace address are not aligned wrt each\n\t\t * other, or if explicitly asked to, disable large page\n\t\t * support for this slot\n\t\t */\n\t\tif ((base_gfn ^ ugfn) & (KVM_PAGES_PER_HPAGE(level) - 1) ||\n\t\t    !largepages_enabled)\n\t\t\tfor (j = 0; j < lpages; ++j)\n\t\t\t\tnew.lpage_info[i][j].write_count = 1;\n\t}\n\nskip_lpage:\n\n\t/* Allocate page dirty bitmap if needed */\n\tif ((new.flags & KVM_MEM_LOG_DIRTY_PAGES) && !new.dirty_bitmap) {\n\t\tif (kvm_create_dirty_bitmap(&new) < 0)\n\t\t\tgoto out_free;\n\t\t/* destroy any largepage mappings for dirty tracking */\n\t}\n#else  /* not defined CONFIG_S390 */\n\tnew.user_alloc = user_alloc;\n\tif (user_alloc)\n\t\tnew.userspace_addr = mem->userspace_addr;\n#endif /* not defined CONFIG_S390 */\n\n\tif (!npages) {\n\t\tstruct kvm_memory_slot *slot;\n\n\t\tr = -ENOMEM;\n\t\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\t\tGFP_KERNEL);\n\t\tif (!slots)\n\t\t\tgoto out_free;\n\t\tslot = id_to_memslot(slots, mem->slot);\n\t\tslot->flags |= KVM_MEMSLOT_INVALID;\n\n\t\tupdate_memslots(slots, NULL);\n\n\t\told_memslots = kvm->memslots;\n\t\trcu_assign_pointer(kvm->memslots, slots);\n\t\tsynchronize_srcu_expedited(&kvm->srcu);\n\t\t/* From this point no new shadow pages pointing to a deleted\n\t\t * memslot will be created.\n\t\t *\n\t\t * validation of sp->gfn happens in:\n\t\t * \t- gfn_to_hva (kvm_read_guest, gfn_to_pfn)\n\t\t * \t- kvm_is_visible_gfn (mmu_check_roots)\n\t\t */\n\t\tkvm_arch_flush_shadow(kvm);\n\t\tkfree(old_memslots);\n\t}\n\n\tr = kvm_arch_prepare_memory_region(kvm, &new, old, mem, user_alloc);\n\tif (r)\n\t\tgoto out_free;\n\n\t/* map/unmap the pages in iommu page table */\n\tif (npages) {\n\t\tr = kvm_iommu_map_pages(kvm, &new);\n\t\tif (r)\n\t\t\tgoto out_free;\n\t} else\n\t\tkvm_iommu_unmap_pages(kvm, &old);\n\n\tr = -ENOMEM;\n\tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),\n\t\t\tGFP_KERNEL);\n\tif (!slots)\n\t\tgoto out_free;\n\n\t/* actual memory is freed via old in kvm_free_physmem_slot below */\n\tif (!npages) {\n\t\tnew.rmap = NULL;\n\t\tnew.dirty_bitmap = NULL;\n\t\tfor (i = 0; i < KVM_NR_PAGE_SIZES - 1; ++i)\n\t\t\tnew.lpage_info[i] = NULL;\n\t}\n\n\tupdate_memslots(slots, &new);\n\told_memslots = kvm->memslots;\n\trcu_assign_pointer(kvm->memslots, slots);\n\tsynchronize_srcu_expedited(&kvm->srcu);\n\n\tkvm_arch_commit_memory_region(kvm, mem, old, user_alloc);\n\n\t/*\n\t * If the new memory slot is created, we need to clear all\n\t * mmio sptes.\n\t */\n\tif (npages && old.base_gfn != mem->guest_phys_addr >> PAGE_SHIFT)\n\t\tkvm_arch_flush_shadow(kvm);\n\n\tkvm_free_physmem_slot(&old, &new);\n\tkfree(old_memslots);\n\n\treturn 0;\n\nout_free:\n\tkvm_free_physmem_slot(&new, &old);\nout:\n\treturn r;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -165,12 +165,13 @@\n \tif (r)\n \t\tgoto out_free;\n \n-\t/* map the pages in iommu page table */\n+\t/* map/unmap the pages in iommu page table */\n \tif (npages) {\n \t\tr = kvm_iommu_map_pages(kvm, &new);\n \t\tif (r)\n \t\t\tgoto out_free;\n-\t}\n+\t} else\n+\t\tkvm_iommu_unmap_pages(kvm, &old);\n \n \tr = -ENOMEM;\n \tslots = kmemdup(kvm->memslots, sizeof(struct kvm_memslots),",
        "diff_line_info": {
            "deleted_lines": [
                "\t/* map the pages in iommu page table */",
                "\t}"
            ],
            "added_lines": [
                "\t/* map/unmap the pages in iommu page table */",
                "\t} else",
                "\t\tkvm_iommu_unmap_pages(kvm, &old);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2121",
        "func_name": "torvalds/linux/kvm_iommu_unmap_memslots",
        "description": "The KVM implementation in the Linux kernel before 3.3.4 does not properly manage the relationships between memory slots and the iommu, which allows guest OS users to cause a denial of service (memory leak and host OS crash) by leveraging administrative access to the guest OS to conduct hotunplug and hotplug operations on devices.",
        "git_url": "https://github.com/torvalds/linux/commit/09ca8e1173bcb12e2a449698c9ae3b86a8a10195",
        "commit_title": "KVM: unmap pages from the iommu when slots are removed",
        "commit_text": " commit 32f6daad4651a748a58a3ab6da0611862175722f upstream.  We've been adding new mappings, but not destroying old mappings. This can lead to a page leak as pages are pinned using get_user_pages, but only unpinned with put_page if they still exist in the memslots list on vm shutdown.  A memslot that is destroyed while an iommu domain is enabled for the guest will therefore result in an elevated page reference count that is never cleared.  Additionally, without this fix, the iommu is only programmed with the first translation for a gpa.  This can result in peer-to-peer errors if a mapping is destroyed and replaced by a new mapping at the same gpa as the iommu will still be pointing to the original, pinned memory address. ",
        "func_before": "static int kvm_iommu_unmap_memslots(struct kvm *kvm)\n{\n\tint idx;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tslots = kvm_memslots(kvm);\n\n\tkvm_for_each_memslot(memslot, slots)\n\t\tkvm_iommu_put_pages(kvm, memslot->base_gfn, memslot->npages);\n\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\treturn 0;\n}",
        "func": "static int kvm_iommu_unmap_memslots(struct kvm *kvm)\n{\n\tint idx;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tslots = kvm_memslots(kvm);\n\n\tkvm_for_each_memslot(memslot, slots)\n\t\tkvm_iommu_unmap_pages(kvm, memslot);\n\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,7 +8,7 @@\n \tslots = kvm_memslots(kvm);\n \n \tkvm_for_each_memslot(memslot, slots)\n-\t\tkvm_iommu_put_pages(kvm, memslot->base_gfn, memslot->npages);\n+\t\tkvm_iommu_unmap_pages(kvm, memslot);\n \n \tsrcu_read_unlock(&kvm->srcu, idx);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tkvm_iommu_put_pages(kvm, memslot->base_gfn, memslot->npages);"
            ],
            "added_lines": [
                "\t\tkvm_iommu_unmap_pages(kvm, memslot);"
            ]
        }
    },
    {
        "cve_id": "CVE-2012-2123",
        "func_name": "torvalds/linux/cap_bprm_set_creds",
        "description": "The cap_bprm_set_creds function in security/commoncap.c in the Linux kernel before 3.3.3 does not properly handle the use of file system capabilities (aka fcaps) for implementing a privileged executable file, which allows local users to bypass intended personality restrictions via a crafted application, as demonstrated by an attack that uses a parent process to disable ASLR.",
        "git_url": "https://github.com/torvalds/linux/commit/d52fc5dde171f030170a6cb78034d166b13c9445",
        "commit_title": "fcaps: clear the same personality flags as suid when fcaps are used",
        "commit_text": " If a process increases permissions using fcaps all of the dangerous personality flags which are cleared for suid apps should also be cleared. Thus programs given priviledge with fcaps will continue to have address space randomization enabled even if the parent tried to disable it to make it easier to attack. ",
        "func_before": "int cap_bprm_set_creds(struct linux_binprm *bprm)\n{\n\tconst struct cred *old = current_cred();\n\tstruct cred *new = bprm->cred;\n\tbool effective, has_cap = false;\n\tint ret;\n\n\teffective = false;\n\tret = get_file_caps(bprm, &effective, &has_cap);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (!issecure(SECURE_NOROOT)) {\n\t\t/*\n\t\t * If the legacy file capability is set, then don't set privs\n\t\t * for a setuid root binary run by a non-root user.  Do set it\n\t\t * for a root user just to cause least surprise to an admin.\n\t\t */\n\t\tif (has_cap && new->uid != 0 && new->euid == 0) {\n\t\t\twarn_setuid_and_fcaps_mixed(bprm->filename);\n\t\t\tgoto skip;\n\t\t}\n\t\t/*\n\t\t * To support inheritance of root-permissions and suid-root\n\t\t * executables under compatibility mode, we override the\n\t\t * capability sets for the file.\n\t\t *\n\t\t * If only the real uid is 0, we do not set the effective bit.\n\t\t */\n\t\tif (new->euid == 0 || new->uid == 0) {\n\t\t\t/* pP' = (cap_bset & ~0) | (pI & ~0) */\n\t\t\tnew->cap_permitted = cap_combine(old->cap_bset,\n\t\t\t\t\t\t\t old->cap_inheritable);\n\t\t}\n\t\tif (new->euid == 0)\n\t\t\teffective = true;\n\t}\nskip:\n\n\t/* Don't let someone trace a set[ug]id/setpcap binary with the revised\n\t * credentials unless they have the appropriate permit\n\t */\n\tif ((new->euid != old->uid ||\n\t     new->egid != old->gid ||\n\t     !cap_issubset(new->cap_permitted, old->cap_permitted)) &&\n\t    bprm->unsafe & ~LSM_UNSAFE_PTRACE_CAP) {\n\t\t/* downgrade; they get no more than they had, and maybe less */\n\t\tif (!capable(CAP_SETUID)) {\n\t\t\tnew->euid = new->uid;\n\t\t\tnew->egid = new->gid;\n\t\t}\n\t\tnew->cap_permitted = cap_intersect(new->cap_permitted,\n\t\t\t\t\t\t   old->cap_permitted);\n\t}\n\n\tnew->suid = new->fsuid = new->euid;\n\tnew->sgid = new->fsgid = new->egid;\n\n\tif (effective)\n\t\tnew->cap_effective = new->cap_permitted;\n\telse\n\t\tcap_clear(new->cap_effective);\n\tbprm->cap_effective = effective;\n\n\t/*\n\t * Audit candidate if current->cap_effective is set\n\t *\n\t * We do not bother to audit if 3 things are true:\n\t *   1) cap_effective has all caps\n\t *   2) we are root\n\t *   3) root is supposed to have all caps (SECURE_NOROOT)\n\t * Since this is just a normal root execing a process.\n\t *\n\t * Number 1 above might fail if you don't have a full bset, but I think\n\t * that is interesting information to audit.\n\t */\n\tif (!cap_isclear(new->cap_effective)) {\n\t\tif (!cap_issubset(CAP_FULL_SET, new->cap_effective) ||\n\t\t    new->euid != 0 || new->uid != 0 ||\n\t\t    issecure(SECURE_NOROOT)) {\n\t\t\tret = audit_log_bprm_fcaps(bprm, new, old);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\tnew->securebits &= ~issecure_mask(SECURE_KEEP_CAPS);\n\treturn 0;\n}",
        "func": "int cap_bprm_set_creds(struct linux_binprm *bprm)\n{\n\tconst struct cred *old = current_cred();\n\tstruct cred *new = bprm->cred;\n\tbool effective, has_cap = false;\n\tint ret;\n\n\teffective = false;\n\tret = get_file_caps(bprm, &effective, &has_cap);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (!issecure(SECURE_NOROOT)) {\n\t\t/*\n\t\t * If the legacy file capability is set, then don't set privs\n\t\t * for a setuid root binary run by a non-root user.  Do set it\n\t\t * for a root user just to cause least surprise to an admin.\n\t\t */\n\t\tif (has_cap && new->uid != 0 && new->euid == 0) {\n\t\t\twarn_setuid_and_fcaps_mixed(bprm->filename);\n\t\t\tgoto skip;\n\t\t}\n\t\t/*\n\t\t * To support inheritance of root-permissions and suid-root\n\t\t * executables under compatibility mode, we override the\n\t\t * capability sets for the file.\n\t\t *\n\t\t * If only the real uid is 0, we do not set the effective bit.\n\t\t */\n\t\tif (new->euid == 0 || new->uid == 0) {\n\t\t\t/* pP' = (cap_bset & ~0) | (pI & ~0) */\n\t\t\tnew->cap_permitted = cap_combine(old->cap_bset,\n\t\t\t\t\t\t\t old->cap_inheritable);\n\t\t}\n\t\tif (new->euid == 0)\n\t\t\teffective = true;\n\t}\nskip:\n\n\t/* if we have fs caps, clear dangerous personality flags */\n\tif (!cap_issubset(new->cap_permitted, old->cap_permitted))\n\t\tbprm->per_clear |= PER_CLEAR_ON_SETID;\n\n\n\t/* Don't let someone trace a set[ug]id/setpcap binary with the revised\n\t * credentials unless they have the appropriate permit\n\t */\n\tif ((new->euid != old->uid ||\n\t     new->egid != old->gid ||\n\t     !cap_issubset(new->cap_permitted, old->cap_permitted)) &&\n\t    bprm->unsafe & ~LSM_UNSAFE_PTRACE_CAP) {\n\t\t/* downgrade; they get no more than they had, and maybe less */\n\t\tif (!capable(CAP_SETUID)) {\n\t\t\tnew->euid = new->uid;\n\t\t\tnew->egid = new->gid;\n\t\t}\n\t\tnew->cap_permitted = cap_intersect(new->cap_permitted,\n\t\t\t\t\t\t   old->cap_permitted);\n\t}\n\n\tnew->suid = new->fsuid = new->euid;\n\tnew->sgid = new->fsgid = new->egid;\n\n\tif (effective)\n\t\tnew->cap_effective = new->cap_permitted;\n\telse\n\t\tcap_clear(new->cap_effective);\n\tbprm->cap_effective = effective;\n\n\t/*\n\t * Audit candidate if current->cap_effective is set\n\t *\n\t * We do not bother to audit if 3 things are true:\n\t *   1) cap_effective has all caps\n\t *   2) we are root\n\t *   3) root is supposed to have all caps (SECURE_NOROOT)\n\t * Since this is just a normal root execing a process.\n\t *\n\t * Number 1 above might fail if you don't have a full bset, but I think\n\t * that is interesting information to audit.\n\t */\n\tif (!cap_isclear(new->cap_effective)) {\n\t\tif (!cap_issubset(CAP_FULL_SET, new->cap_effective) ||\n\t\t    new->euid != 0 || new->uid != 0 ||\n\t\t    issecure(SECURE_NOROOT)) {\n\t\t\tret = audit_log_bprm_fcaps(bprm, new, old);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\t\t}\n\t}\n\n\tnew->securebits &= ~issecure_mask(SECURE_KEEP_CAPS);\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -36,6 +36,11 @@\n \t\t\teffective = true;\n \t}\n skip:\n+\n+\t/* if we have fs caps, clear dangerous personality flags */\n+\tif (!cap_issubset(new->cap_permitted, old->cap_permitted))\n+\t\tbprm->per_clear |= PER_CLEAR_ON_SETID;\n+\n \n \t/* Don't let someone trace a set[ug]id/setpcap binary with the revised\n \t * credentials unless they have the appropriate permit",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "\t/* if we have fs caps, clear dangerous personality flags */",
                "\tif (!cap_issubset(new->cap_permitted, old->cap_permitted))",
                "\t\tbprm->per_clear |= PER_CLEAR_ON_SETID;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1292",
        "func_name": "chromium/LocalDOMWindow::navigator",
        "description": "The NavigatorServiceWorker::serviceWorker function in modules/serviceworkers/NavigatorServiceWorker.cpp in Blink, as used in Google Chrome before 45.0.2454.85, allows remote attackers to bypass the Same Origin Policy by accessing a Service Worker.",
        "git_url": "https://github.com/chromium/chromium/commit/c62d8db228d01f75d74b5a3420c6dec8f7d961fd",
        "commit_title": "DOMWindow::navigator should return a navigator w/o frame when detached.",
        "commit_text": " Currently DOMWindow::navigator returns a navigator associated with a frame even when the window is detached from the frame and another window is attached to it. That means calling frame()->document() may return an incorrect document, for example.  This CL makes LocalDOMWindow::navigator return a navigator with a null frame when the window is not associated to the frame.   ",
        "func_before": "Navigator* LocalDOMWindow::navigator() const\n{\n    if (!m_navigator)\n        m_navigator = Navigator::create(frame());\n    return m_navigator.get();\n}",
        "func": "Navigator* LocalDOMWindow::navigator() const\n{\n    if (!isCurrentlyDisplayedInFrame() && (!m_navigator || m_navigator->frame())) {\n        // We return a navigator with null frame instead of returning null\n        // pointer as other functions do, in order to allow users to access\n        // functions such as navigator.product.\n        m_navigator = Navigator::create(nullptr);\n    }\n    if (!m_navigator)\n        m_navigator = Navigator::create(frame());\n    // As described above, when not dispayed in the frame, the returning\n    // navigator should not be associated with the frame.\n    ASSERT(isCurrentlyDisplayedInFrame() || !m_navigator->frame());\n    return m_navigator.get();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,15 @@\n Navigator* LocalDOMWindow::navigator() const\n {\n+    if (!isCurrentlyDisplayedInFrame() && (!m_navigator || m_navigator->frame())) {\n+        // We return a navigator with null frame instead of returning null\n+        // pointer as other functions do, in order to allow users to access\n+        // functions such as navigator.product.\n+        m_navigator = Navigator::create(nullptr);\n+    }\n     if (!m_navigator)\n         m_navigator = Navigator::create(frame());\n+    // As described above, when not dispayed in the frame, the returning\n+    // navigator should not be associated with the frame.\n+    ASSERT(isCurrentlyDisplayedInFrame() || !m_navigator->frame());\n     return m_navigator.get();\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    if (!isCurrentlyDisplayedInFrame() && (!m_navigator || m_navigator->frame())) {",
                "        // We return a navigator with null frame instead of returning null",
                "        // pointer as other functions do, in order to allow users to access",
                "        // functions such as navigator.product.",
                "        m_navigator = Navigator::create(nullptr);",
                "    }",
                "    // As described above, when not dispayed in the frame, the returning",
                "    // navigator should not be associated with the frame.",
                "    ASSERT(isCurrentlyDisplayedInFrame() || !m_navigator->frame());"
            ]
        }
    }
]