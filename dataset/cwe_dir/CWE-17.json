[
    {
        "cve_id": "CVE-2016-1640",
        "func_name": "chromium/WebstoreInlineInstaller::WebstoreInlineInstaller",
        "description": "The Web Store inline-installer implementation in the Extensions UI in Google Chrome before 49.0.2623.75 does not block installations upon deletion of an installation frame, which makes it easier for remote attackers to trick a user into believing that an installation request originated from the user's next navigation target via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/2639e878336ccd138e0ab20a3daea375998c3a81",
        "commit_title": "Don't allow inline install if frame is deleted before user accepts",
        "commit_text": " If the frame that called the chrome.webstore.install method to begin an inline install gets deleted before the user accepts from the dialog, we don't want the install to continue because a navigation could make it look like the install request was coming from some unrelated site.  One downside of this approach is that the dialog stays around even after the frame is deleted, and hitting either accept or cancel buttons both just cancel the install. It would be better if the dialog is automatically cancelled, but doing that would involve a lot more refactoring. The approach in this CL was easier and is probably worth getting out, and we can improve on it in the future.    (cherry picked from commit bbe84115d3dc969bfcf6ca87bebd1f5608db6ecf)   ",
        "func_before": "WebstoreInlineInstaller::WebstoreInlineInstaller(\n    content::WebContents* web_contents,\n    const std::string& webstore_item_id,\n    const GURL& requestor_url,\n    const Callback& callback)\n    : WebstoreStandaloneInstaller(\n          webstore_item_id,\n          Profile::FromBrowserContext(web_contents->GetBrowserContext()),\n          callback),\n      content::WebContentsObserver(web_contents),\n      requestor_url_(requestor_url) {\n}",
        "func": "WebstoreInlineInstaller::WebstoreInlineInstaller(\n    content::WebContents* web_contents,\n    content::RenderFrameHost* host,\n    const std::string& webstore_item_id,\n    const GURL& requestor_url,\n    const Callback& callback)\n    : WebstoreStandaloneInstaller(\n          webstore_item_id,\n          Profile::FromBrowserContext(web_contents->GetBrowserContext()),\n          callback),\n      content::WebContentsObserver(web_contents),\n      host_(host),\n      requestor_url_(requestor_url) {}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,6 @@\n WebstoreInlineInstaller::WebstoreInlineInstaller(\n     content::WebContents* web_contents,\n+    content::RenderFrameHost* host,\n     const std::string& webstore_item_id,\n     const GURL& requestor_url,\n     const Callback& callback)\n@@ -8,5 +9,5 @@\n           Profile::FromBrowserContext(web_contents->GetBrowserContext()),\n           callback),\n       content::WebContentsObserver(web_contents),\n-      requestor_url_(requestor_url) {\n-}\n+      host_(host),\n+      requestor_url_(requestor_url) {}",
        "diff_line_info": {
            "deleted_lines": [
                "      requestor_url_(requestor_url) {",
                "}"
            ],
            "added_lines": [
                "    content::RenderFrameHost* host,",
                "      host_(host),",
                "      requestor_url_(requestor_url) {}"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1640",
        "func_name": "chromium/WebstoreInlineInstaller::CheckRequestorAlive",
        "description": "The Web Store inline-installer implementation in the Extensions UI in Google Chrome before 49.0.2623.75 does not block installations upon deletion of an installation frame, which makes it easier for remote attackers to trick a user into believing that an installation request originated from the user's next navigation target via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/2639e878336ccd138e0ab20a3daea375998c3a81",
        "commit_title": "Don't allow inline install if frame is deleted before user accepts",
        "commit_text": " If the frame that called the chrome.webstore.install method to begin an inline install gets deleted before the user accepts from the dialog, we don't want the install to continue because a navigation could make it look like the install request was coming from some unrelated site.  One downside of this approach is that the dialog stays around even after the frame is deleted, and hitting either accept or cancel buttons both just cancel the install. It would be better if the dialog is automatically cancelled, but doing that would involve a lot more refactoring. The approach in this CL was easier and is probably worth getting out, and we can improve on it in the future.    (cherry picked from commit bbe84115d3dc969bfcf6ca87bebd1f5608db6ecf)   ",
        "func_before": "bool WebstoreInlineInstaller::CheckRequestorAlive() const {\n  // The tab may have gone away - cancel installation in that case.\n  return web_contents() != NULL;\n}",
        "func": "bool WebstoreInlineInstaller::CheckRequestorAlive() const {\n  // The frame or tab may have gone away - cancel installation in that case.\n  return host_ != nullptr && web_contents() != nullptr;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n bool WebstoreInlineInstaller::CheckRequestorAlive() const {\n-  // The tab may have gone away - cancel installation in that case.\n-  return web_contents() != NULL;\n+  // The frame or tab may have gone away - cancel installation in that case.\n+  return host_ != nullptr && web_contents() != nullptr;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  // The tab may have gone away - cancel installation in that case.",
                "  return web_contents() != NULL;"
            ],
            "added_lines": [
                "  // The frame or tab may have gone away - cancel installation in that case.",
                "  return host_ != nullptr && web_contents() != nullptr;"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1640",
        "func_name": "chromium/WebstoreInlineInstallerFactory::CreateInstaller",
        "description": "The Web Store inline-installer implementation in the Extensions UI in Google Chrome before 49.0.2623.75 does not block installations upon deletion of an installation frame, which makes it easier for remote attackers to trick a user into believing that an installation request originated from the user's next navigation target via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/2639e878336ccd138e0ab20a3daea375998c3a81",
        "commit_title": "Don't allow inline install if frame is deleted before user accepts",
        "commit_text": " If the frame that called the chrome.webstore.install method to begin an inline install gets deleted before the user accepts from the dialog, we don't want the install to continue because a navigation could make it look like the install request was coming from some unrelated site.  One downside of this approach is that the dialog stays around even after the frame is deleted, and hitting either accept or cancel buttons both just cancel the install. It would be better if the dialog is automatically cancelled, but doing that would involve a lot more refactoring. The approach in this CL was easier and is probably worth getting out, and we can improve on it in the future.    (cherry picked from commit bbe84115d3dc969bfcf6ca87bebd1f5608db6ecf)   ",
        "func_before": "WebstoreInlineInstaller* WebstoreInlineInstallerFactory::CreateInstaller(\n      content::WebContents* contents,\n      const std::string& webstore_item_id,\n      const GURL& requestor_url,\n      const WebstoreStandaloneInstaller::Callback& callback) {\n  return new WebstoreInlineInstaller(\n      contents, webstore_item_id, requestor_url, callback);\n}",
        "func": "WebstoreInlineInstaller* WebstoreInlineInstallerFactory::CreateInstaller(\n    content::WebContents* contents,\n    content::RenderFrameHost* host,\n    const std::string& webstore_item_id,\n    const GURL& requestor_url,\n    const WebstoreStandaloneInstaller::Callback& callback) {\n  return new WebstoreInlineInstaller(contents, host, webstore_item_id,\n                                     requestor_url, callback);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,9 @@\n WebstoreInlineInstaller* WebstoreInlineInstallerFactory::CreateInstaller(\n-      content::WebContents* contents,\n-      const std::string& webstore_item_id,\n-      const GURL& requestor_url,\n-      const WebstoreStandaloneInstaller::Callback& callback) {\n-  return new WebstoreInlineInstaller(\n-      contents, webstore_item_id, requestor_url, callback);\n+    content::WebContents* contents,\n+    content::RenderFrameHost* host,\n+    const std::string& webstore_item_id,\n+    const GURL& requestor_url,\n+    const WebstoreStandaloneInstaller::Callback& callback) {\n+  return new WebstoreInlineInstaller(contents, host, webstore_item_id,\n+                                     requestor_url, callback);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "      content::WebContents* contents,",
                "      const std::string& webstore_item_id,",
                "      const GURL& requestor_url,",
                "      const WebstoreStandaloneInstaller::Callback& callback) {",
                "  return new WebstoreInlineInstaller(",
                "      contents, webstore_item_id, requestor_url, callback);"
            ],
            "added_lines": [
                "    content::WebContents* contents,",
                "    content::RenderFrameHost* host,",
                "    const std::string& webstore_item_id,",
                "    const GURL& requestor_url,",
                "    const WebstoreStandaloneInstaller::Callback& callback) {",
                "  return new WebstoreInlineInstaller(contents, host, webstore_item_id,",
                "                                     requestor_url, callback);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1640",
        "func_name": "chromium/TabHelper::OnInlineWebstoreInstall",
        "description": "The Web Store inline-installer implementation in the Extensions UI in Google Chrome before 49.0.2623.75 does not block installations upon deletion of an installation frame, which makes it easier for remote attackers to trick a user into believing that an installation request originated from the user's next navigation target via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/2639e878336ccd138e0ab20a3daea375998c3a81",
        "commit_title": "Don't allow inline install if frame is deleted before user accepts",
        "commit_text": " If the frame that called the chrome.webstore.install method to begin an inline install gets deleted before the user accepts from the dialog, we don't want the install to continue because a navigation could make it look like the install request was coming from some unrelated site.  One downside of this approach is that the dialog stays around even after the frame is deleted, and hitting either accept or cancel buttons both just cancel the install. It would be better if the dialog is automatically cancelled, but doing that would involve a lot more refactoring. The approach in this CL was easier and is probably worth getting out, and we can improve on it in the future.    (cherry picked from commit bbe84115d3dc969bfcf6ca87bebd1f5608db6ecf)   ",
        "func_before": "void TabHelper::OnInlineWebstoreInstall(content::RenderFrameHost* host,\n                                        int install_id,\n                                        int return_route_id,\n                                        const std::string& webstore_item_id,\n                                        const GURL& requestor_url,\n                                        int listeners_mask) {\n  // Check that the listener is reasonable. We should never get anything other\n  // than an install stage listener, a download listener, or both.\n  if ((listeners_mask & ~(api::webstore::INSTALL_STAGE_LISTENER |\n                          api::webstore::DOWNLOAD_PROGRESS_LISTENER)) != 0 ||\n      requestor_url.is_empty()) {\n    NOTREACHED();\n    return;\n  }\n  // Inform the Webstore API that an inline install is happening, in case the\n  // page requested status updates.\n  ExtensionRegistry* registry = ExtensionRegistry::Get(profile_);\n  if (registry->disabled_extensions().Contains(webstore_item_id) &&\n      (ExtensionPrefs::Get(profile_)->GetDisableReasons(webstore_item_id) &\n           Extension::DISABLE_PERMISSIONS_INCREASE) != 0) {\n      // The extension was disabled due to permissions increase. Prompt for\n      // re-enable.\n      // TODO(devlin): We should also prompt for re-enable for other reasons,\n      // like user-disabled.\n      // For clarity, explicitly end any prior reenable process.\n      extension_reenabler_.reset();\n      extension_reenabler_ = ExtensionReenabler::PromptForReenable(\n          registry->disabled_extensions().GetByID(webstore_item_id),\n          profile_,\n          web_contents(),\n          requestor_url,\n          base::Bind(&TabHelper::OnReenableComplete,\n                     weak_ptr_factory_.GetWeakPtr(),\n                     install_id,\n                     return_route_id));\n  } else {\n    // TODO(devlin): We should adddress the case of the extension already\n    // being installed and enabled.\n    WebstoreAPI::Get(profile_)->OnInlineInstallStart(\n        return_route_id, this, webstore_item_id, listeners_mask);\n\n    WebstoreStandaloneInstaller::Callback callback =\n        base::Bind(&TabHelper::OnInlineInstallComplete,\n                   base::Unretained(this),\n                   install_id,\n                   return_route_id);\n    scoped_refptr<WebstoreInlineInstaller> installer(\n        webstore_inline_installer_factory_->CreateInstaller(\n            web_contents(),\n            webstore_item_id,\n            requestor_url,\n            callback));\n    installer->BeginInstall();\n  }\n}",
        "func": "void TabHelper::OnInlineWebstoreInstall(content::RenderFrameHost* host,\n                                        int install_id,\n                                        int return_route_id,\n                                        const std::string& webstore_item_id,\n                                        const GURL& requestor_url,\n                                        int listeners_mask) {\n  // Check that the listener is reasonable. We should never get anything other\n  // than an install stage listener, a download listener, or both.\n  if ((listeners_mask & ~(api::webstore::INSTALL_STAGE_LISTENER |\n                          api::webstore::DOWNLOAD_PROGRESS_LISTENER)) != 0 ||\n      requestor_url.is_empty()) {\n    NOTREACHED();\n    return;\n  }\n  // Inform the Webstore API that an inline install is happening, in case the\n  // page requested status updates.\n  ExtensionRegistry* registry = ExtensionRegistry::Get(profile_);\n  if (registry->disabled_extensions().Contains(webstore_item_id) &&\n      (ExtensionPrefs::Get(profile_)->GetDisableReasons(webstore_item_id) &\n           Extension::DISABLE_PERMISSIONS_INCREASE) != 0) {\n      // The extension was disabled due to permissions increase. Prompt for\n      // re-enable.\n      // TODO(devlin): We should also prompt for re-enable for other reasons,\n      // like user-disabled.\n      // For clarity, explicitly end any prior reenable process.\n      extension_reenabler_.reset();\n      extension_reenabler_ = ExtensionReenabler::PromptForReenable(\n          registry->disabled_extensions().GetByID(webstore_item_id),\n          profile_,\n          web_contents(),\n          requestor_url,\n          base::Bind(&TabHelper::OnReenableComplete,\n                     weak_ptr_factory_.GetWeakPtr(),\n                     install_id,\n                     return_route_id));\n  } else {\n    // TODO(devlin): We should adddress the case of the extension already\n    // being installed and enabled.\n    WebstoreAPI::Get(profile_)->OnInlineInstallStart(\n        return_route_id, this, webstore_item_id, listeners_mask);\n\n    WebstoreStandaloneInstaller::Callback callback =\n        base::Bind(&TabHelper::OnInlineInstallComplete,\n                   base::Unretained(this),\n                   install_id,\n                   return_route_id);\n    scoped_refptr<WebstoreInlineInstaller> installer(\n        webstore_inline_installer_factory_->CreateInstaller(\n            web_contents(), host, webstore_item_id, requestor_url, callback));\n    installer->BeginInstall();\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -46,10 +46,7 @@\n                    return_route_id);\n     scoped_refptr<WebstoreInlineInstaller> installer(\n         webstore_inline_installer_factory_->CreateInstaller(\n-            web_contents(),\n-            webstore_item_id,\n-            requestor_url,\n-            callback));\n+            web_contents(), host, webstore_item_id, requestor_url, callback));\n     installer->BeginInstall();\n   }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "            web_contents(),",
                "            webstore_item_id,",
                "            requestor_url,",
                "            callback));"
            ],
            "added_lines": [
                "            web_contents(), host, webstore_item_id, requestor_url, callback));"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1640",
        "func_name": "chromium/ShowExtensionInstallDialogImpl",
        "description": "The Web Store inline-installer implementation in the Extensions UI in Google Chrome before 49.0.2623.75 does not block installations upon deletion of an installation frame, which makes it easier for remote attackers to trick a user into believing that an installation request originated from the user's next navigation target via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/0a1c15fecb1240ab909e1431b6127410c3b380e0",
        "commit_title": "Make the webstore inline install dialog be tab-modal",
        "commit_text": " Also clean up a few minor lint errors while I'm in here.    ",
        "func_before": "void ShowExtensionInstallDialogImpl(\n    ExtensionInstallPromptShowParams* show_params,\n    ExtensionInstallPrompt::Delegate* delegate,\n    scoped_refptr<ExtensionInstallPrompt::Prompt> prompt) {\n  DCHECK_CURRENTLY_ON(content::BrowserThread::UI);\n  ExtensionInstallDialogView* dialog =\n      new ExtensionInstallDialogView(show_params->profile(),\n                                     show_params->GetParentWebContents(),\n                                     delegate,\n                                     prompt);\n  constrained_window::CreateBrowserModalDialogViews(\n      dialog, show_params->GetParentWindow())->Show();\n}",
        "func": "void ShowExtensionInstallDialogImpl(\n    ExtensionInstallPromptShowParams* show_params,\n    ExtensionInstallPrompt::Delegate* delegate,\n    scoped_refptr<ExtensionInstallPrompt::Prompt> prompt) {\n  DCHECK_CURRENTLY_ON(content::BrowserThread::UI);\n  ExtensionInstallDialogView* dialog =\n      new ExtensionInstallDialogView(show_params->profile(),\n                                     show_params->GetParentWebContents(),\n                                     delegate,\n                                     prompt);\n  if (prompt->ShouldUseTabModalDialog()) {\n    content::WebContents* parent_web_contents =\n        show_params->GetParentWebContents();\n    if (parent_web_contents)\n      constrained_window::ShowWebModalDialogViews(dialog, parent_web_contents);\n  } else {\n    constrained_window::CreateBrowserModalDialogViews(\n        dialog, show_params->GetParentWindow())\n        ->Show();\n  }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,14 @@\n                                      show_params->GetParentWebContents(),\n                                      delegate,\n                                      prompt);\n-  constrained_window::CreateBrowserModalDialogViews(\n-      dialog, show_params->GetParentWindow())->Show();\n+  if (prompt->ShouldUseTabModalDialog()) {\n+    content::WebContents* parent_web_contents =\n+        show_params->GetParentWebContents();\n+    if (parent_web_contents)\n+      constrained_window::ShowWebModalDialogViews(dialog, parent_web_contents);\n+  } else {\n+    constrained_window::CreateBrowserModalDialogViews(\n+        dialog, show_params->GetParentWindow())\n+        ->Show();\n+  }\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  constrained_window::CreateBrowserModalDialogViews(",
                "      dialog, show_params->GetParentWindow())->Show();"
            ],
            "added_lines": [
                "  if (prompt->ShouldUseTabModalDialog()) {",
                "    content::WebContents* parent_web_contents =",
                "        show_params->GetParentWebContents();",
                "    if (parent_web_contents)",
                "      constrained_window::ShowWebModalDialogViews(dialog, parent_web_contents);",
                "  } else {",
                "    constrained_window::CreateBrowserModalDialogViews(",
                "        dialog, show_params->GetParentWindow())",
                "        ->Show();",
                "  }"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1640",
        "func_name": "chromium/ExtensionInstallDialogView::InitView",
        "description": "The Web Store inline-installer implementation in the Extensions UI in Google Chrome before 49.0.2623.75 does not block installations upon deletion of an installation frame, which makes it easier for remote attackers to trick a user into believing that an installation request originated from the user's next navigation target via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/0a1c15fecb1240ab909e1431b6127410c3b380e0",
        "commit_title": "Make the webstore inline install dialog be tab-modal",
        "commit_text": " Also clean up a few minor lint errors while I'm in here.    ",
        "func_before": "void ExtensionInstallDialogView::InitView() {\n  // Possible grid layouts:\n  // With webstore data (inline install, external install, repair)\n  //      w/ permissions           no permissions\n  // +--------------+------+  +--------------+------+\n  // | title        | icon |  | title        | icon |\n  // +--------------|      |  +--------------|      |\n  // | rating       |      |  | rating       |      |\n  // +--------------|      |  +--------------|      |\n  // | user_count   |      |  | user_count   |      |\n  // +--------------|      |  +--------------|      |\n  // | store_link   |      |  | store_link   |      |\n  // +--------------+------+  +--------------+------+\n  // |      separator      |  | scroll_view (empty) |\n  // +---------------------+  +---------------------+\n  // | scroll_view         |\n  // +---------------------+\n  //\n  // No webstore data (all other types)\n  // +--------------+------+\n  // | title        | icon |\n  // +--------------|      |\n  // | scroll_view  |      |\n  // +--------------+------+\n  // The scroll_view contains permissions (if there are any) and retained\n  // files/devices (if there are any; post-install-permissions prompt only).\n  int left_column_width =\n      (prompt_->ShouldShowPermissions() || prompt_->GetRetainedFileCount() > 0)\n          ? kPermissionsLeftColumnWidth\n          : kNoPermissionsLeftColumnWidth;\n  if (is_external_install())\n    left_column_width = kExternalInstallLeftColumnWidth;\n\n  int column_set_id = 0;\n  views::GridLayout* layout = CreateLayout(left_column_width, column_set_id);\n\n  ui::ResourceBundle& rb = ui::ResourceBundle::GetSharedInstance();\n\n  if (prompt_->has_webstore_data()) {\n    layout->StartRow(0, column_set_id);\n    views::View* rating = new views::View();\n    rating->SetLayoutManager(new views::BoxLayout(\n        views::BoxLayout::kHorizontal, 0, 0, 0));\n    layout->AddView(rating);\n    prompt_->AppendRatingStars(AddResourceIcon, rating);\n\n    const gfx::FontList& small_font_list =\n        rb.GetFontList(ui::ResourceBundle::SmallFont);\n    views::Label* rating_count =\n        new views::Label(prompt_->GetRatingCount(), small_font_list);\n    // Add some space between the stars and the rating count.\n    rating_count->SetBorder(views::Border::CreateEmptyBorder(0, 2, 0, 0));\n    rating->AddChildView(rating_count);\n\n    layout->StartRow(0, column_set_id);\n    views::Label* user_count =\n        new views::Label(prompt_->GetUserCount(), small_font_list);\n    user_count->SetAutoColorReadabilityEnabled(false);\n    user_count->SetEnabledColor(SK_ColorGRAY);\n    layout->AddView(user_count);\n\n    layout->StartRow(0, column_set_id);\n    views::Link* store_link = new views::Link(\n        l10n_util::GetStringUTF16(IDS_EXTENSION_PROMPT_STORE_LINK));\n    store_link->SetFontList(small_font_list);\n    store_link->set_listener(this);\n    layout->AddView(store_link);\n\n    if (prompt_->ShouldShowPermissions()) {\n      layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n      layout->StartRow(0, column_set_id);\n      layout->AddView(new views::Separator(views::Separator::HORIZONTAL),\n                      3,\n                      1,\n                      views::GridLayout::FILL,\n                      views::GridLayout::FILL);\n    }\n  }\n\n  int content_width = left_column_width + views::kPanelHorizMargin + kIconSize;\n\n  // Create the scrollable view which will contain the permissions and retained\n  // files/devices.\n  CustomScrollableView* scrollable = new CustomScrollableView();\n  views::GridLayout* scroll_layout = new views::GridLayout(scrollable);\n  scrollable->SetLayoutManager(scroll_layout);\n\n  views::ColumnSet* scrollable_column_set =\n      scroll_layout->AddColumnSet(column_set_id);\n  // If we have webstore data, there's a separator below it, so we can span the\n  // whole content width. Otherwise just use the width of the left column so\n  // that we don't overlap the icon.\n  int scrollable_width = prompt_->has_webstore_data() ? content_width\n                                                      : left_column_width;\n  scrollable_column_set->AddColumn(views::GridLayout::LEADING,\n                                   views::GridLayout::LEADING,\n                                   0,  // no resizing\n                                   views::GridLayout::USE_PREF,\n                                   scrollable_width,\n                                   scrollable_width);\n  // Pad to the very right of the dialog, so the scrollbar will be on the edge.\n  int padding_width =\n      content_width + views::kButtonHEdgeMarginNew - scrollable_width;\n  scrollable_column_set->AddPaddingColumn(0, padding_width);\n\n  layout->StartRow(0, column_set_id);\n  scroll_view_ = new views::ScrollView();\n  scroll_view_->set_hide_horizontal_scrollbar(true);\n  scroll_view_->SetContents(scrollable);\n  layout->AddView(scroll_view_, 4, 1);\n\n  if (is_bundle_install()) {\n    BundleInstaller::ItemList items = prompt_->bundle()->GetItemsWithState(\n        BundleInstaller::Item::STATE_PENDING);\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlSmallVerticalSpacing);\n    for (const BundleInstaller::Item& item : items) {\n      scroll_layout->StartRow(0, column_set_id);\n      views::Label* extension_label =\n          new views::Label(item.GetNameForDisplay());\n      extension_label->SetMultiLine(true);\n      extension_label->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n      extension_label->SizeToFit(\n          scrollable_width - kSmallIconSize - kSmallIconPadding);\n      gfx::ImageSkia image = gfx::ImageSkia::CreateFrom1xBitmap(item.icon);\n      scroll_layout->AddView(new IconedView(extension_label, image));\n    }\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n  }\n\n  if (prompt_->ShouldShowPermissions()) {\n    bool has_permissions =\n        prompt_->GetPermissionCount(\n            ExtensionInstallPrompt::PermissionsType::ALL_PERMISSIONS) > 0;\n    if (has_permissions) {\n      AddPermissions(\n          scroll_layout,\n          rb,\n          column_set_id,\n          scrollable_width,\n          ExtensionInstallPrompt::PermissionsType::REGULAR_PERMISSIONS);\n      AddPermissions(\n          scroll_layout,\n          rb,\n          column_set_id,\n          scrollable_width,\n          ExtensionInstallPrompt::PermissionsType::WITHHELD_PERMISSIONS);\n    } else {\n      scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n      scroll_layout->StartRow(0, column_set_id);\n      views::Label* permission_label = new views::Label(\n          l10n_util::GetStringUTF16(IDS_EXTENSION_NO_SPECIAL_PERMISSIONS));\n      permission_label->SetMultiLine(true);\n      permission_label->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n      permission_label->SizeToFit(scrollable_width);\n      scroll_layout->AddView(permission_label);\n    }\n  }\n\n  if (prompt_->GetRetainedFileCount()) {\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n\n    scroll_layout->StartRow(0, column_set_id);\n    views::Label* retained_files_header =\n        new views::Label(prompt_->GetRetainedFilesHeading());\n    retained_files_header->SetMultiLine(true);\n    retained_files_header->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n    retained_files_header->SizeToFit(scrollable_width);\n    scroll_layout->AddView(retained_files_header);\n\n    scroll_layout->StartRow(0, column_set_id);\n    PermissionDetails details;\n    for (size_t i = 0; i < prompt_->GetRetainedFileCount(); ++i) {\n      details.push_back(prompt_->GetRetainedFile(i));\n    }\n    ExpandableContainerView* issue_advice_view =\n        new ExpandableContainerView(this,\n                                    base::string16(),\n                                    details,\n                                    scrollable_width,\n                                    false);\n    scroll_layout->AddView(issue_advice_view);\n  }\n\n  if (prompt_->GetRetainedDeviceCount()) {\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n\n    scroll_layout->StartRow(0, column_set_id);\n    views::Label* retained_devices_header =\n        new views::Label(prompt_->GetRetainedDevicesHeading());\n    retained_devices_header->SetMultiLine(true);\n    retained_devices_header->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n    retained_devices_header->SizeToFit(scrollable_width);\n    scroll_layout->AddView(retained_devices_header);\n\n    scroll_layout->StartRow(0, column_set_id);\n    PermissionDetails details;\n    for (size_t i = 0; i < prompt_->GetRetainedDeviceCount(); ++i) {\n      details.push_back(prompt_->GetRetainedDeviceMessageString(i));\n    }\n    ExpandableContainerView* issue_advice_view =\n        new ExpandableContainerView(this,\n                                    base::string16(),\n                                    details,\n                                    scrollable_width,\n                                    false);\n    scroll_layout->AddView(issue_advice_view);\n  }\n\n  DCHECK(prompt_->type() >= 0);\n  UMA_HISTOGRAM_ENUMERATION(\"Extensions.InstallPrompt.Type\",\n                            prompt_->type(),\n                            ExtensionInstallPrompt::NUM_PROMPT_TYPES);\n\n  scroll_view_->ClipHeightTo(\n      0,\n      std::min(kScrollViewMaxHeight, scrollable->GetPreferredSize().height()));\n\n  dialog_size_ = gfx::Size(\n      content_width + 2 * views::kButtonHEdgeMarginNew,\n      container_->GetPreferredSize().height());\n\n  std::string event_name = ExperienceSamplingEvent::kExtensionInstallDialog;\n  event_name.append(\n      ExtensionInstallPrompt::PromptTypeToString(prompt_->type()));\n  sampling_event_ = ExperienceSamplingEvent::Create(event_name);\n}",
        "func": "void ExtensionInstallDialogView::InitView() {\n  // Possible grid layouts:\n  // With webstore data (inline install, external install, repair)\n  //      w/ permissions           no permissions\n  // +--------------+------+  +--------------+------+\n  // | title        | icon |  | title        | icon |\n  // +--------------|      |  +--------------|      |\n  // | rating       |      |  | rating       |      |\n  // +--------------|      |  +--------------|      |\n  // | user_count   |      |  | user_count   |      |\n  // +--------------|      |  +--------------|      |\n  // | store_link   |      |  | store_link   |      |\n  // +--------------+------+  +--------------+------+\n  // |      separator      |  | scroll_view (empty) |\n  // +---------------------+  +---------------------+\n  // | scroll_view         |\n  // +---------------------+\n  //\n  // No webstore data (all other types)\n  // +--------------+------+\n  // | title        | icon |\n  // +--------------|      |\n  // | scroll_view  |      |\n  // +--------------+------+\n  // The scroll_view contains permissions (if there are any) and retained\n  // files/devices (if there are any; post-install-permissions prompt only).\n  int left_column_width =\n      (prompt_->ShouldShowPermissions() || prompt_->GetRetainedFileCount() > 0)\n          ? kPermissionsLeftColumnWidth\n          : kNoPermissionsLeftColumnWidth;\n  if (is_external_install())\n    left_column_width = kExternalInstallLeftColumnWidth;\n\n  int column_set_id = 0;\n  views::GridLayout* layout = CreateLayout(left_column_width, column_set_id);\n\n  ui::ResourceBundle& rb = ui::ResourceBundle::GetSharedInstance();\n\n  if (prompt_->has_webstore_data()) {\n    layout->StartRow(0, column_set_id);\n    views::View* rating = new views::View();\n    rating->SetLayoutManager(new views::BoxLayout(\n        views::BoxLayout::kHorizontal, 0, 0, 0));\n    layout->AddView(rating);\n    prompt_->AppendRatingStars(AddResourceIcon, rating);\n\n    const gfx::FontList& small_font_list =\n        rb.GetFontList(ui::ResourceBundle::SmallFont);\n    views::Label* rating_count =\n        new views::Label(prompt_->GetRatingCount(), small_font_list);\n    // Add some space between the stars and the rating count.\n    rating_count->SetBorder(views::Border::CreateEmptyBorder(0, 2, 0, 0));\n    rating->AddChildView(rating_count);\n\n    layout->StartRow(0, column_set_id);\n    views::Label* user_count =\n        new views::Label(prompt_->GetUserCount(), small_font_list);\n    user_count->SetAutoColorReadabilityEnabled(false);\n    user_count->SetEnabledColor(SK_ColorGRAY);\n    layout->AddView(user_count);\n\n    layout->StartRow(0, column_set_id);\n    views::Link* store_link = new views::Link(\n        l10n_util::GetStringUTF16(IDS_EXTENSION_PROMPT_STORE_LINK));\n    store_link->SetFontList(small_font_list);\n    store_link->set_listener(this);\n    layout->AddView(store_link);\n\n    if (prompt_->ShouldShowPermissions()) {\n      layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n      layout->StartRow(0, column_set_id);\n      layout->AddView(new views::Separator(views::Separator::HORIZONTAL),\n                      3,\n                      1,\n                      views::GridLayout::FILL,\n                      views::GridLayout::FILL);\n    }\n  }\n\n  int content_width = left_column_width + views::kPanelHorizMargin + kIconSize;\n\n  // Create the scrollable view which will contain the permissions and retained\n  // files/devices.\n  CustomScrollableView* scrollable = new CustomScrollableView();\n  views::GridLayout* scroll_layout = new views::GridLayout(scrollable);\n  scrollable->SetLayoutManager(scroll_layout);\n\n  views::ColumnSet* scrollable_column_set =\n      scroll_layout->AddColumnSet(column_set_id);\n  // If we have webstore data, there's a separator below it, so we can span the\n  // whole content width. Otherwise just use the width of the left column so\n  // that we don't overlap the icon.\n  int scrollable_width = prompt_->has_webstore_data() ? content_width\n                                                      : left_column_width;\n  scrollable_column_set->AddColumn(views::GridLayout::LEADING,\n                                   views::GridLayout::LEADING,\n                                   0,  // no resizing\n                                   views::GridLayout::USE_PREF,\n                                   scrollable_width,\n                                   scrollable_width);\n  // Pad to the very right of the dialog, so the scrollbar will be on the edge.\n  int padding_width =\n      content_width + views::kButtonHEdgeMarginNew - scrollable_width;\n  scrollable_column_set->AddPaddingColumn(0, padding_width);\n\n  layout->StartRow(0, column_set_id);\n  scroll_view_ = new views::ScrollView();\n  scroll_view_->set_hide_horizontal_scrollbar(true);\n  scroll_view_->SetContents(scrollable);\n  layout->AddView(scroll_view_, 4, 1);\n\n  if (is_bundle_install()) {\n    BundleInstaller::ItemList items = prompt_->bundle()->GetItemsWithState(\n        BundleInstaller::Item::STATE_PENDING);\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlSmallVerticalSpacing);\n    for (const BundleInstaller::Item& item : items) {\n      scroll_layout->StartRow(0, column_set_id);\n      views::Label* extension_label =\n          new views::Label(item.GetNameForDisplay());\n      extension_label->SetMultiLine(true);\n      extension_label->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n      extension_label->SizeToFit(\n          scrollable_width - kSmallIconSize - kSmallIconPadding);\n      gfx::ImageSkia image = gfx::ImageSkia::CreateFrom1xBitmap(item.icon);\n      scroll_layout->AddView(new IconedView(extension_label, image));\n    }\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n  }\n\n  if (prompt_->ShouldShowPermissions()) {\n    bool has_permissions =\n        prompt_->GetPermissionCount(\n            ExtensionInstallPrompt::PermissionsType::ALL_PERMISSIONS) > 0;\n    if (has_permissions) {\n      AddPermissions(\n          scroll_layout,\n          rb,\n          column_set_id,\n          scrollable_width,\n          ExtensionInstallPrompt::PermissionsType::REGULAR_PERMISSIONS);\n      AddPermissions(\n          scroll_layout,\n          rb,\n          column_set_id,\n          scrollable_width,\n          ExtensionInstallPrompt::PermissionsType::WITHHELD_PERMISSIONS);\n    } else {\n      scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n      scroll_layout->StartRow(0, column_set_id);\n      views::Label* permission_label = new views::Label(\n          l10n_util::GetStringUTF16(IDS_EXTENSION_NO_SPECIAL_PERMISSIONS));\n      permission_label->SetMultiLine(true);\n      permission_label->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n      permission_label->SizeToFit(scrollable_width);\n      scroll_layout->AddView(permission_label);\n    }\n  }\n\n  if (prompt_->GetRetainedFileCount()) {\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n\n    scroll_layout->StartRow(0, column_set_id);\n    views::Label* retained_files_header =\n        new views::Label(prompt_->GetRetainedFilesHeading());\n    retained_files_header->SetMultiLine(true);\n    retained_files_header->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n    retained_files_header->SizeToFit(scrollable_width);\n    scroll_layout->AddView(retained_files_header);\n\n    scroll_layout->StartRow(0, column_set_id);\n    PermissionDetails details;\n    for (size_t i = 0; i < prompt_->GetRetainedFileCount(); ++i) {\n      details.push_back(prompt_->GetRetainedFile(i));\n    }\n    ExpandableContainerView* issue_advice_view =\n        new ExpandableContainerView(this,\n                                    base::string16(),\n                                    details,\n                                    scrollable_width,\n                                    false);\n    scroll_layout->AddView(issue_advice_view);\n  }\n\n  if (prompt_->GetRetainedDeviceCount()) {\n    scroll_layout->AddPaddingRow(0, views::kRelatedControlVerticalSpacing);\n\n    scroll_layout->StartRow(0, column_set_id);\n    views::Label* retained_devices_header =\n        new views::Label(prompt_->GetRetainedDevicesHeading());\n    retained_devices_header->SetMultiLine(true);\n    retained_devices_header->SetHorizontalAlignment(gfx::ALIGN_LEFT);\n    retained_devices_header->SizeToFit(scrollable_width);\n    scroll_layout->AddView(retained_devices_header);\n\n    scroll_layout->StartRow(0, column_set_id);\n    PermissionDetails details;\n    for (size_t i = 0; i < prompt_->GetRetainedDeviceCount(); ++i) {\n      details.push_back(prompt_->GetRetainedDeviceMessageString(i));\n    }\n    ExpandableContainerView* issue_advice_view =\n        new ExpandableContainerView(this,\n                                    base::string16(),\n                                    details,\n                                    scrollable_width,\n                                    false);\n    scroll_layout->AddView(issue_advice_view);\n  }\n\n  DCHECK_GE(prompt_->type(), 0);\n  UMA_HISTOGRAM_ENUMERATION(\"Extensions.InstallPrompt.Type\",\n                            prompt_->type(),\n                            ExtensionInstallPrompt::NUM_PROMPT_TYPES);\n\n  scroll_view_->ClipHeightTo(\n      0,\n      std::min(kScrollViewMaxHeight, scrollable->GetPreferredSize().height()));\n\n  dialog_size_ = gfx::Size(\n      content_width + 2 * views::kButtonHEdgeMarginNew,\n      container_->GetPreferredSize().height());\n\n  std::string event_name = ExperienceSamplingEvent::kExtensionInstallDialog;\n  event_name.append(\n      ExtensionInstallPrompt::PromptTypeToString(prompt_->type()));\n  sampling_event_ = ExperienceSamplingEvent::Create(event_name);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -206,7 +206,7 @@\n     scroll_layout->AddView(issue_advice_view);\n   }\n \n-  DCHECK(prompt_->type() >= 0);\n+  DCHECK_GE(prompt_->type(), 0);\n   UMA_HISTOGRAM_ENUMERATION(\"Extensions.InstallPrompt.Type\",\n                             prompt_->type(),\n                             ExtensionInstallPrompt::NUM_PROMPT_TYPES);",
        "diff_line_info": {
            "deleted_lines": [
                "  DCHECK(prompt_->type() >= 0);"
            ],
            "added_lines": [
                "  DCHECK_GE(prompt_->type(), 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1640",
        "func_name": "chromium/ExtensionInstallDialogView::GetModalType",
        "description": "The Web Store inline-installer implementation in the Extensions UI in Google Chrome before 49.0.2623.75 does not block installations upon deletion of an installation frame, which makes it easier for remote attackers to trick a user into believing that an installation request originated from the user's next navigation target via a crafted web site.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/0a1c15fecb1240ab909e1431b6127410c3b380e0",
        "commit_title": "Make the webstore inline install dialog be tab-modal",
        "commit_text": " Also clean up a few minor lint errors while I'm in here.    ",
        "func_before": "ui::ModalType ExtensionInstallDialogView::GetModalType() const {\n  return ui::MODAL_TYPE_WINDOW;\n}",
        "func": "ui::ModalType ExtensionInstallDialogView::GetModalType() const {\n  return prompt_->ShouldUseTabModalDialog() ? ui::MODAL_TYPE_CHILD\n                                            : ui::MODAL_TYPE_WINDOW;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,3 +1,4 @@\n ui::ModalType ExtensionInstallDialogView::GetModalType() const {\n-  return ui::MODAL_TYPE_WINDOW;\n+  return prompt_->ShouldUseTabModalDialog() ? ui::MODAL_TYPE_CHILD\n+                                            : ui::MODAL_TYPE_WINDOW;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  return ui::MODAL_TYPE_WINDOW;"
            ],
            "added_lines": [
                "  return prompt_->ShouldUseTabModalDialog() ? ui::MODAL_TYPE_CHILD",
                "                                            : ui::MODAL_TYPE_WINDOW;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7929",
        "func_name": "chromium/HTMLScriptElement::didMoveToNewDocument",
        "description": "Use-after-free vulnerability in the HTMLScriptElement::didMoveToNewDocument function in core/html/HTMLScriptElement.cpp in the DOM implementation in Blink, as used in Google Chrome before 40.0.2214.91, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors involving movement of a SCRIPT element across documents.",
        "git_url": "https://github.com/chromium/chromium/commit/6b51dbf1788c15785cb3e0febaab1593dc9fec5a",
        "commit_title": "Correctly move script element to a detached document.",
        "commit_text": " If a script element ends up being moved over to a new document's tree, its script loader is re-associated with that document's script runner if the load is still pending. That association of script runner and loader needs to reflect document association of the element itself, otherwise completion of script loading and any later movement of the element to another document will go wrong.   ",
        "func_before": "void HTMLScriptElement::didMoveToNewDocument(Document& oldDocument)\n{\n    if (RefPtrWillBeRawPtr<Document> contextDocument = document().contextDocument().get())\n        oldDocument.scriptRunner()->movePendingAsyncScript(contextDocument->scriptRunner(), m_loader.get());\n    HTMLElement::didMoveToNewDocument(oldDocument);\n}",
        "func": "void HTMLScriptElement::didMoveToNewDocument(Document& oldDocument)\n{\n    RefPtrWillBeRawPtr<Document> contextDocument = document().contextDocument().get();\n    if (!contextDocument) {\n        ASSERT(!document().frame());\n        // A frame-detached document is handled as having no context\n        // document - it would be the document if not detached. The\n        // newly moved script element needs to be the latter here as\n        // the script loader for the pending script must also move to\n        // reside with that document and its script runner.\n        contextDocument = &document();\n    }\n    oldDocument.scriptRunner()->movePendingAsyncScript(contextDocument->scriptRunner(), m_loader.get());\n    HTMLElement::didMoveToNewDocument(oldDocument);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,15 @@\n void HTMLScriptElement::didMoveToNewDocument(Document& oldDocument)\n {\n-    if (RefPtrWillBeRawPtr<Document> contextDocument = document().contextDocument().get())\n-        oldDocument.scriptRunner()->movePendingAsyncScript(contextDocument->scriptRunner(), m_loader.get());\n+    RefPtrWillBeRawPtr<Document> contextDocument = document().contextDocument().get();\n+    if (!contextDocument) {\n+        ASSERT(!document().frame());\n+        // A frame-detached document is handled as having no context\n+        // document - it would be the document if not detached. The\n+        // newly moved script element needs to be the latter here as\n+        // the script loader for the pending script must also move to\n+        // reside with that document and its script runner.\n+        contextDocument = &document();\n+    }\n+    oldDocument.scriptRunner()->movePendingAsyncScript(contextDocument->scriptRunner(), m_loader.get());\n     HTMLElement::didMoveToNewDocument(oldDocument);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    if (RefPtrWillBeRawPtr<Document> contextDocument = document().contextDocument().get())",
                "        oldDocument.scriptRunner()->movePendingAsyncScript(contextDocument->scriptRunner(), m_loader.get());"
            ],
            "added_lines": [
                "    RefPtrWillBeRawPtr<Document> contextDocument = document().contextDocument().get();",
                "    if (!contextDocument) {",
                "        ASSERT(!document().frame());",
                "        // A frame-detached document is handled as having no context",
                "        // document - it would be the document if not detached. The",
                "        // newly moved script element needs to be the latter here as",
                "        // the script loader for the pending script must also move to",
                "        // reside with that document and its script runner.",
                "        contextDocument = &document();",
                "    }",
                "    oldDocument.scriptRunner()->movePendingAsyncScript(contextDocument->scriptRunner(), m_loader.get());"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-7931",
        "func_name": "chromium/Factory::NewJSArrayStorage",
        "description": "factory.cc in Google V8, as used in Google Chrome before 40.0.2214.91, allows remote attackers to cause a denial of service (memory corruption) or possibly have unspecified other impact via crafted JavaScript code that triggers improper maintenance of backing-store pointers.",
        "git_url": "https://chromium.googlesource.com/v8/v8/+/377de64246b3c1449f4e2090622ae1e1691e51ae",
        "commit_title": "Make sure backing store pointer in handles get cleared after use in factory.",
        "commit_text": "   ",
        "func_before": "void Factory::NewJSArrayStorage(Handle<JSArray> array,\n                                int length,\n                                int capacity,\n                                ArrayStorageAllocationMode mode) {\n  DCHECK(capacity >= length);\n\n  if (capacity == 0) {\n    array->set_length(Smi::FromInt(0));\n    array->set_elements(*empty_fixed_array());\n    return;\n  }\n\n  Handle<FixedArrayBase> elms;\n  ElementsKind elements_kind = array->GetElementsKind();\n  if (IsFastDoubleElementsKind(elements_kind)) {\n    if (mode == DONT_INITIALIZE_ARRAY_ELEMENTS) {\n      elms = NewFixedDoubleArray(capacity);\n    } else {\n      DCHECK(mode == INITIALIZE_ARRAY_ELEMENTS_WITH_HOLE);\n      elms = NewFixedDoubleArrayWithHoles(capacity);\n    }\n  } else {\n    DCHECK(IsFastSmiOrObjectElementsKind(elements_kind));\n    if (mode == DONT_INITIALIZE_ARRAY_ELEMENTS) {\n      elms = NewUninitializedFixedArray(capacity);\n    } else {\n      DCHECK(mode == INITIALIZE_ARRAY_ELEMENTS_WITH_HOLE);\n      elms = NewFixedArrayWithHoles(capacity);\n    }\n  }\n\n  array->set_elements(*elms);\n  array->set_length(Smi::FromInt(length));\n}",
        "func": "void Factory::NewJSArrayStorage(Handle<JSArray> array,\n                                int length,\n                                int capacity,\n                                ArrayStorageAllocationMode mode) {\n  DCHECK(capacity >= length);\n\n  if (capacity == 0) {\n    array->set_length(Smi::FromInt(0));\n    array->set_elements(*empty_fixed_array());\n    return;\n  }\n\n  HandleScope inner_scope(isolate());\n  Handle<FixedArrayBase> elms;\n  ElementsKind elements_kind = array->GetElementsKind();\n  if (IsFastDoubleElementsKind(elements_kind)) {\n    if (mode == DONT_INITIALIZE_ARRAY_ELEMENTS) {\n      elms = NewFixedDoubleArray(capacity);\n    } else {\n      DCHECK(mode == INITIALIZE_ARRAY_ELEMENTS_WITH_HOLE);\n      elms = NewFixedDoubleArrayWithHoles(capacity);\n    }\n  } else {\n    DCHECK(IsFastSmiOrObjectElementsKind(elements_kind));\n    if (mode == DONT_INITIALIZE_ARRAY_ELEMENTS) {\n      elms = NewUninitializedFixedArray(capacity);\n    } else {\n      DCHECK(mode == INITIALIZE_ARRAY_ELEMENTS_WITH_HOLE);\n      elms = NewFixedArrayWithHoles(capacity);\n    }\n  }\n\n  array->set_elements(*elms);\n  array->set_length(Smi::FromInt(length));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,6 +10,7 @@\n     return;\n   }\n \n+  HandleScope inner_scope(isolate());\n   Handle<FixedArrayBase> elms;\n   ElementsKind elements_kind = array->GetElementsKind();\n   if (IsFastDoubleElementsKind(elements_kind)) {",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "  HandleScope inner_scope(isolate());"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1217",
        "func_name": "chromium/V8LazyEventListener::prepareListenerObject",
        "description": "The V8LazyEventListener::prepareListenerObject function in bindings/core/v8/V8LazyEventListener.cpp in the V8 bindings in Blink, as used in Google Chrome before 41.0.2272.76, does not properly compile listeners, which allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors that leverage \"type confusion.\"",
        "git_url": "https://github.com/chromium/chromium/commit/fc81fcf38edd250876cc384a6ed5567e1b2999e4",
        "commit_title": "Turn a bunch of ASSERTs into graceful failures when compiling listeners",
        "commit_text": "  ",
        "func_before": "void V8LazyEventListener::prepareListenerObject(ExecutionContext* executionContext)\n{\n    if (!executionContext)\n        return;\n\n    // A ScriptState used by the event listener needs to be calculated based on\n    // the ExecutionContext that fired the the event listener and the world\n    // that installed the event listener.\n    v8::HandleScope handleScope(toIsolate(executionContext));\n    v8::Local<v8::Context> v8Context = toV8Context(executionContext, world());\n    if (v8Context.IsEmpty())\n        return;\n    ScriptState* scriptState = ScriptState::from(v8Context);\n    if (!scriptState->contextIsValid())\n        return;\n\n    if (executionContext->isDocument() && !toDocument(executionContext)->allowInlineEventHandlers(m_node, this, m_sourceURL, m_position.m_line)) {\n        clearListenerObject();\n        return;\n    }\n\n    if (hasExistingListenerObject())\n        return;\n\n    ASSERT(executionContext->isDocument());\n\n    ScriptState::Scope scope(scriptState);\n    String listenerSource =  InspectorInstrumentation::preprocessEventListener(toDocument(executionContext)->frame(), m_code, m_sourceURL, m_functionName);\n\n    // FIXME: Remove the following 'with' hack.\n    //\n    // Nodes other than the document object, when executing inline event\n    // handlers push document, form owner, and the target node on the scope chain.\n    // We do this by using 'with' statement.\n    // See chrome/fast/forms/form-action.html\n    //     chrome/fast/forms/selected-index-value.html\n    //     base/fast/overflow/onscroll-layer-self-destruct.html\n    //\n    // Don't use new lines so that lines in the modified handler\n    // have the same numbers as in the original code.\n    // FIXME: V8 does not allow us to programmatically create object environments so\n    //        we have to do this hack! What if m_code escapes to run arbitrary script?\n    //\n    // Call with 4 arguments instead of 3, pass additional null as the last parameter.\n    // By calling the function with 4 arguments, we create a setter on arguments object\n    // which would shadow property \"3\" on the prototype.\n    String code = \"(function() {\"\n        \"with (this[2]) {\"\n        \"with (this[1]) {\"\n        \"with (this[0]) {\"\n            \"return function(\" + m_eventParameterName + \") {\" +\n                listenerSource + \"\\n\" // Insert '\\n' otherwise //-style comments could break the handler.\n            \"};\"\n        \"}}}})\";\n\n    v8::Handle<v8::String> codeExternalString = v8String(isolate(), code);\n\n    v8::Local<v8::Value> result = V8ScriptRunner::compileAndRunInternalScript(codeExternalString, isolate(), m_sourceURL, m_position);\n    if (result.IsEmpty())\n        return;\n\n    // Call the outer function to get the inner function.\n    ASSERT(result->IsFunction());\n    v8::Local<v8::Function> intermediateFunction = result.As<v8::Function>();\n\n    HTMLFormElement* formElement = 0;\n    if (m_node && m_node->isHTMLElement())\n        formElement = toHTMLElement(m_node)->formOwner();\n\n    v8::Handle<v8::Object> nodeWrapper = toObjectWrapper<Node>(m_node, scriptState);\n    v8::Handle<v8::Object> formWrapper = toObjectWrapper<HTMLFormElement>(formElement, scriptState);\n    v8::Handle<v8::Object> documentWrapper = toObjectWrapper<Document>(m_node ? m_node->ownerDocument() : 0, scriptState);\n\n    v8::Local<v8::Object> thisObject = v8::Object::New(isolate());\n    if (thisObject.IsEmpty())\n        return;\n    if (!thisObject->ForceSet(v8::Integer::New(isolate(), 0), nodeWrapper))\n        return;\n    if (!thisObject->ForceSet(v8::Integer::New(isolate(), 1), formWrapper))\n        return;\n    if (!thisObject->ForceSet(v8::Integer::New(isolate(), 2), documentWrapper))\n        return;\n\n    // FIXME: Remove this code when we stop doing the 'with' hack above.\n    v8::Local<v8::Value> innerValue = V8ScriptRunner::callInternalFunction(intermediateFunction, thisObject, 0, 0, isolate());\n    if (innerValue.IsEmpty() || !innerValue->IsFunction())\n        return;\n\n    v8::Local<v8::Function> wrappedFunction = innerValue.As<v8::Function>();\n\n    // Change the toString function on the wrapper function to avoid it\n    // returning the source for the actual wrapper function. Instead it\n    // returns source for a clean wrapper function with the event\n    // argument wrapping the event source code. The reason for this is\n    // that some web sites use toString on event functions and eval the\n    // source returned (sometimes a RegExp is applied as well) for some\n    // other use. That fails miserably if the actual wrapper source is\n    // returned.\n    v8::Local<v8::Function> toStringFunction = v8::Function::New(isolate(), V8LazyEventListenerToString);\n    ASSERT(!toStringFunction.IsEmpty());\n    String toStringString = \"function \" + m_functionName + \"(\" + m_eventParameterName + \") {\\n  \" + m_code + \"\\n}\";\n    V8HiddenValue::setHiddenValue(isolate(), wrappedFunction, V8HiddenValue::toStringString(isolate()), v8String(isolate(), toStringString));\n    wrappedFunction->Set(v8AtomicString(isolate(), \"toString\"), toStringFunction);\n    wrappedFunction->SetName(v8String(isolate(), m_functionName));\n\n    // FIXME: Remove the following comment-outs.\n    // See https://bugs.webkit.org/show_bug.cgi?id=85152 for more details.\n    //\n    // For the time being, we comment out the following code since the\n    // second parsing can happen.\n    // // Since we only parse once, there's no need to keep data used for parsing around anymore.\n    // m_functionName = String();\n    // m_code = String();\n    // m_eventParameterName = String();\n    // m_sourceURL = String();\n\n    setListenerObject(wrappedFunction);\n}",
        "func": "void V8LazyEventListener::prepareListenerObject(ExecutionContext* executionContext)\n{\n    if (!executionContext)\n        return;\n\n    // A ScriptState used by the event listener needs to be calculated based on\n    // the ExecutionContext that fired the the event listener and the world\n    // that installed the event listener.\n    v8::HandleScope handleScope(toIsolate(executionContext));\n    v8::Local<v8::Context> v8Context = toV8Context(executionContext, world());\n    if (v8Context.IsEmpty())\n        return;\n    ScriptState* scriptState = ScriptState::from(v8Context);\n    if (!scriptState->contextIsValid())\n        return;\n\n    if (!executionContext->isDocument())\n        return;\n\n    if (!toDocument(executionContext)->allowInlineEventHandlers(m_node, this, m_sourceURL, m_position.m_line)) {\n        clearListenerObject();\n        return;\n    }\n\n    if (hasExistingListenerObject())\n        return;\n\n    ScriptState::Scope scope(scriptState);\n    String listenerSource =  InspectorInstrumentation::preprocessEventListener(toDocument(executionContext)->frame(), m_code, m_sourceURL, m_functionName);\n\n    // FIXME: Remove the following 'with' hack.\n    //\n    // Nodes other than the document object, when executing inline event\n    // handlers push document, form owner, and the target node on the scope chain.\n    // We do this by using 'with' statement.\n    // See chrome/fast/forms/form-action.html\n    //     chrome/fast/forms/selected-index-value.html\n    //     base/fast/overflow/onscroll-layer-self-destruct.html\n    //\n    // Don't use new lines so that lines in the modified handler\n    // have the same numbers as in the original code.\n    // FIXME: V8 does not allow us to programmatically create object environments so\n    //        we have to do this hack! What if m_code escapes to run arbitrary script?\n    //\n    // Call with 4 arguments instead of 3, pass additional null as the last parameter.\n    // By calling the function with 4 arguments, we create a setter on arguments object\n    // which would shadow property \"3\" on the prototype.\n    String code = \"(function() {\"\n        \"with (this[2]) {\"\n        \"with (this[1]) {\"\n        \"with (this[0]) {\"\n            \"return function(\" + m_eventParameterName + \") {\" +\n                listenerSource + \"\\n\" // Insert '\\n' otherwise //-style comments could break the handler.\n            \"};\"\n        \"}}}})\";\n\n    v8::Handle<v8::String> codeExternalString = v8String(isolate(), code);\n\n    v8::Local<v8::Value> result = V8ScriptRunner::compileAndRunInternalScript(codeExternalString, isolate(), m_sourceURL, m_position);\n    if (result.IsEmpty())\n        return;\n\n    // Call the outer function to get the inner function.\n    if (!result->IsFunction())\n        return;\n    v8::Local<v8::Function> intermediateFunction = result.As<v8::Function>();\n\n    HTMLFormElement* formElement = 0;\n    if (m_node && m_node->isHTMLElement())\n        formElement = toHTMLElement(m_node)->formOwner();\n\n    v8::Handle<v8::Object> nodeWrapper = toObjectWrapper<Node>(m_node, scriptState);\n    v8::Handle<v8::Object> formWrapper = toObjectWrapper<HTMLFormElement>(formElement, scriptState);\n    v8::Handle<v8::Object> documentWrapper = toObjectWrapper<Document>(m_node ? m_node->ownerDocument() : 0, scriptState);\n\n    v8::Local<v8::Object> thisObject = v8::Object::New(isolate());\n    if (thisObject.IsEmpty())\n        return;\n    if (!thisObject->ForceSet(v8::Integer::New(isolate(), 0), nodeWrapper))\n        return;\n    if (!thisObject->ForceSet(v8::Integer::New(isolate(), 1), formWrapper))\n        return;\n    if (!thisObject->ForceSet(v8::Integer::New(isolate(), 2), documentWrapper))\n        return;\n\n    // FIXME: Remove this code when we stop doing the 'with' hack above.\n    v8::Local<v8::Value> innerValue = V8ScriptRunner::callInternalFunction(intermediateFunction, thisObject, 0, 0, isolate());\n    if (innerValue.IsEmpty() || !innerValue->IsFunction())\n        return;\n\n    v8::Local<v8::Function> wrappedFunction = innerValue.As<v8::Function>();\n\n    // Change the toString function on the wrapper function to avoid it\n    // returning the source for the actual wrapper function. Instead it\n    // returns source for a clean wrapper function with the event\n    // argument wrapping the event source code. The reason for this is\n    // that some web sites use toString on event functions and eval the\n    // source returned (sometimes a RegExp is applied as well) for some\n    // other use. That fails miserably if the actual wrapper source is\n    // returned.\n    v8::Local<v8::Function> toStringFunction = v8::Function::New(isolate(), V8LazyEventListenerToString);\n    ASSERT(!toStringFunction.IsEmpty());\n    String toStringString = \"function \" + m_functionName + \"(\" + m_eventParameterName + \") {\\n  \" + m_code + \"\\n}\";\n    V8HiddenValue::setHiddenValue(isolate(), wrappedFunction, V8HiddenValue::toStringString(isolate()), v8String(isolate(), toStringString));\n    wrappedFunction->Set(v8AtomicString(isolate(), \"toString\"), toStringFunction);\n    wrappedFunction->SetName(v8String(isolate(), m_functionName));\n\n    // FIXME: Remove the following comment-outs.\n    // See https://bugs.webkit.org/show_bug.cgi?id=85152 for more details.\n    //\n    // For the time being, we comment out the following code since the\n    // second parsing can happen.\n    // // Since we only parse once, there's no need to keep data used for parsing around anymore.\n    // m_functionName = String();\n    // m_code = String();\n    // m_eventParameterName = String();\n    // m_sourceURL = String();\n\n    setListenerObject(wrappedFunction);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -14,15 +14,16 @@\n     if (!scriptState->contextIsValid())\n         return;\n \n-    if (executionContext->isDocument() && !toDocument(executionContext)->allowInlineEventHandlers(m_node, this, m_sourceURL, m_position.m_line)) {\n+    if (!executionContext->isDocument())\n+        return;\n+\n+    if (!toDocument(executionContext)->allowInlineEventHandlers(m_node, this, m_sourceURL, m_position.m_line)) {\n         clearListenerObject();\n         return;\n     }\n \n     if (hasExistingListenerObject())\n         return;\n-\n-    ASSERT(executionContext->isDocument());\n \n     ScriptState::Scope scope(scriptState);\n     String listenerSource =  InspectorInstrumentation::preprocessEventListener(toDocument(executionContext)->frame(), m_code, m_sourceURL, m_functionName);\n@@ -60,7 +61,8 @@\n         return;\n \n     // Call the outer function to get the inner function.\n-    ASSERT(result->IsFunction());\n+    if (!result->IsFunction())\n+        return;\n     v8::Local<v8::Function> intermediateFunction = result.As<v8::Function>();\n \n     HTMLFormElement* formElement = 0;",
        "diff_line_info": {
            "deleted_lines": [
                "    if (executionContext->isDocument() && !toDocument(executionContext)->allowInlineEventHandlers(m_node, this, m_sourceURL, m_position.m_line)) {",
                "",
                "    ASSERT(executionContext->isDocument());",
                "    ASSERT(result->IsFunction());"
            ],
            "added_lines": [
                "    if (!executionContext->isDocument())",
                "        return;",
                "",
                "    if (!toDocument(executionContext)->allowInlineEventHandlers(m_node, this, m_sourceURL, m_position.m_line)) {",
                "    if (!result->IsFunction())",
                "        return;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1224",
        "func_name": "chromium/VpxVideoDecoder::VpxDecode",
        "description": "The VpxVideoDecoder::VpxDecode function in media/filters/vpx_video_decoder.cc in the vpxdecoder implementation in Google Chrome before 41.0.2272.76 does not ensure that alpha-plane dimensions are identical to image dimensions, which allows remote attackers to cause a denial of service (out-of-bounds read) via crafted VPx video data.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/c1a91a8a6a7132c47a174054f0fb56cc3dc8c069",
        "commit_title": "Reject vp8 video having alpha and image planes of different sizes.",
        "commit_text": " Previously we would accept malformed vp8 video files that had alpha and image planes with different dimensions. Now they result in a decode error. Also use the alpha image stride when copying the alpha plane, because it technically doesn't have to be the same as the image stride.    ",
        "func_before": "bool VpxVideoDecoder::VpxDecode(const scoped_refptr<DecoderBuffer>& buffer,\n                                scoped_refptr<VideoFrame>* video_frame) {\n  DCHECK(video_frame);\n  DCHECK(!buffer->end_of_stream());\n\n  // Pass |buffer| to libvpx.\n  int64 timestamp = buffer->timestamp().InMicroseconds();\n  void* user_priv = reinterpret_cast<void*>(&timestamp);\n\n  {\n    TRACE_EVENT1(\"video\", \"vpx_codec_decode\", \"timestamp\", timestamp);\n    vpx_codec_err_t status = vpx_codec_decode(vpx_codec_,\n                                              buffer->data(),\n                                              buffer->data_size(),\n                                              user_priv,\n                                              0);\n    if (status != VPX_CODEC_OK) {\n      LOG(ERROR) << \"vpx_codec_decode() failed, status=\" << status;\n      return false;\n    }\n  }\n\n  // Gets pointer to decoded data.\n  vpx_codec_iter_t iter = NULL;\n  const vpx_image_t* vpx_image = vpx_codec_get_frame(vpx_codec_, &iter);\n  if (!vpx_image) {\n    *video_frame = NULL;\n    return true;\n  }\n\n  if (vpx_image->user_priv != reinterpret_cast<void*>(&timestamp)) {\n    LOG(ERROR) << \"Invalid output timestamp.\";\n    return false;\n  }\n\n  const vpx_image_t* vpx_image_alpha = NULL;\n  if (vpx_codec_alpha_ && buffer->side_data_size() >= 8) {\n    // Pass alpha data to libvpx.\n    int64 timestamp_alpha = buffer->timestamp().InMicroseconds();\n    void* user_priv_alpha = reinterpret_cast<void*>(&timestamp_alpha);\n\n    // First 8 bytes of side data is side_data_id in big endian.\n    const uint64 side_data_id = base::NetToHost64(\n        *(reinterpret_cast<const uint64*>(buffer->side_data())));\n    if (side_data_id == 1) {\n      {\n        TRACE_EVENT1(\"video\", \"vpx_codec_decode_alpha\",\n                     \"timestamp_alpha\", timestamp_alpha);\n        vpx_codec_err_t status = vpx_codec_decode(vpx_codec_alpha_,\n                                                  buffer->side_data() + 8,\n                                                  buffer->side_data_size() - 8,\n                                                  user_priv_alpha,\n                                                  0);\n        if (status != VPX_CODEC_OK) {\n          LOG(ERROR) << \"vpx_codec_decode() failed on alpha, status=\" << status;\n          return false;\n        }\n      }\n\n      // Gets pointer to decoded data.\n      vpx_codec_iter_t iter_alpha = NULL;\n      vpx_image_alpha = vpx_codec_get_frame(vpx_codec_alpha_, &iter_alpha);\n      if (!vpx_image_alpha) {\n        *video_frame = NULL;\n        return true;\n      }\n\n      if (vpx_image_alpha->user_priv !=\n          reinterpret_cast<void*>(&timestamp_alpha)) {\n        LOG(ERROR) << \"Invalid output timestamp on alpha.\";\n        return false;\n      }\n    }\n  }\n\n  CopyVpxImageTo(vpx_image, vpx_image_alpha, video_frame);\n  (*video_frame)->set_timestamp(base::TimeDelta::FromMicroseconds(timestamp));\n  return true;\n}",
        "func": "bool VpxVideoDecoder::VpxDecode(const scoped_refptr<DecoderBuffer>& buffer,\n                                scoped_refptr<VideoFrame>* video_frame) {\n  DCHECK(video_frame);\n  DCHECK(!buffer->end_of_stream());\n\n  // Pass |buffer| to libvpx.\n  int64 timestamp = buffer->timestamp().InMicroseconds();\n  void* user_priv = reinterpret_cast<void*>(&timestamp);\n\n  {\n    TRACE_EVENT1(\"video\", \"vpx_codec_decode\", \"timestamp\", timestamp);\n    vpx_codec_err_t status = vpx_codec_decode(vpx_codec_,\n                                              buffer->data(),\n                                              buffer->data_size(),\n                                              user_priv,\n                                              0);\n    if (status != VPX_CODEC_OK) {\n      LOG(ERROR) << \"vpx_codec_decode() failed, status=\" << status;\n      return false;\n    }\n  }\n\n  // Gets pointer to decoded data.\n  vpx_codec_iter_t iter = NULL;\n  const vpx_image_t* vpx_image = vpx_codec_get_frame(vpx_codec_, &iter);\n  if (!vpx_image) {\n    *video_frame = NULL;\n    return true;\n  }\n\n  if (vpx_image->user_priv != reinterpret_cast<void*>(&timestamp)) {\n    LOG(ERROR) << \"Invalid output timestamp.\";\n    return false;\n  }\n\n  const vpx_image_t* vpx_image_alpha = NULL;\n  if (vpx_codec_alpha_ && buffer->side_data_size() >= 8) {\n    // Pass alpha data to libvpx.\n    int64 timestamp_alpha = buffer->timestamp().InMicroseconds();\n    void* user_priv_alpha = reinterpret_cast<void*>(&timestamp_alpha);\n\n    // First 8 bytes of side data is side_data_id in big endian.\n    const uint64 side_data_id = base::NetToHost64(\n        *(reinterpret_cast<const uint64*>(buffer->side_data())));\n    if (side_data_id == 1) {\n      {\n        TRACE_EVENT1(\"video\", \"vpx_codec_decode_alpha\",\n                     \"timestamp_alpha\", timestamp_alpha);\n        vpx_codec_err_t status = vpx_codec_decode(vpx_codec_alpha_,\n                                                  buffer->side_data() + 8,\n                                                  buffer->side_data_size() - 8,\n                                                  user_priv_alpha,\n                                                  0);\n        if (status != VPX_CODEC_OK) {\n          LOG(ERROR) << \"vpx_codec_decode() failed on alpha, status=\" << status;\n          return false;\n        }\n      }\n\n      // Gets pointer to decoded data.\n      vpx_codec_iter_t iter_alpha = NULL;\n      vpx_image_alpha = vpx_codec_get_frame(vpx_codec_alpha_, &iter_alpha);\n      if (!vpx_image_alpha) {\n        *video_frame = NULL;\n        return true;\n      }\n\n      if (vpx_image_alpha->user_priv !=\n          reinterpret_cast<void*>(&timestamp_alpha)) {\n        LOG(ERROR) << \"Invalid output timestamp on alpha.\";\n        return false;\n      }\n\n      if (vpx_image_alpha->d_h != vpx_image->d_h ||\n          vpx_image_alpha->d_w != vpx_image->d_w) {\n        LOG(ERROR) << \"The alpha plane dimensions are not the same as the \"\n                      \"image dimensions.\";\n        return false;\n      }\n    }\n  }\n\n  CopyVpxImageTo(vpx_image, vpx_image_alpha, video_frame);\n  (*video_frame)->set_timestamp(base::TimeDelta::FromMicroseconds(timestamp));\n  return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -70,6 +70,13 @@\n         LOG(ERROR) << \"Invalid output timestamp on alpha.\";\n         return false;\n       }\n+\n+      if (vpx_image_alpha->d_h != vpx_image->d_h ||\n+          vpx_image_alpha->d_w != vpx_image->d_w) {\n+        LOG(ERROR) << \"The alpha plane dimensions are not the same as the \"\n+                      \"image dimensions.\";\n+        return false;\n+      }\n     }\n   }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "      if (vpx_image_alpha->d_h != vpx_image->d_h ||",
                "          vpx_image_alpha->d_w != vpx_image->d_w) {",
                "        LOG(ERROR) << \"The alpha plane dimensions are not the same as the \"",
                "                      \"image dimensions.\";",
                "        return false;",
                "      }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1224",
        "func_name": "chromium/VpxVideoDecoder::CopyVpxImageTo",
        "description": "The VpxVideoDecoder::VpxDecode function in media/filters/vpx_video_decoder.cc in the vpxdecoder implementation in Google Chrome before 41.0.2272.76 does not ensure that alpha-plane dimensions are identical to image dimensions, which allows remote attackers to cause a denial of service (out-of-bounds read) via crafted VPx video data.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/c1a91a8a6a7132c47a174054f0fb56cc3dc8c069",
        "commit_title": "Reject vp8 video having alpha and image planes of different sizes.",
        "commit_text": " Previously we would accept malformed vp8 video files that had alpha and image planes with different dimensions. Now they result in a decode error. Also use the alpha image stride when copying the alpha plane, because it technically doesn't have to be the same as the image stride.    ",
        "func_before": "void VpxVideoDecoder::CopyVpxImageTo(const vpx_image* vpx_image,\n                                     const struct vpx_image* vpx_image_alpha,\n                                     scoped_refptr<VideoFrame>* video_frame) {\n  CHECK(vpx_image);\n  CHECK(vpx_image->fmt == VPX_IMG_FMT_I420 ||\n        vpx_image->fmt == VPX_IMG_FMT_YV12 ||\n        vpx_image->fmt == VPX_IMG_FMT_I444);\n\n  VideoFrame::Format codec_format = VideoFrame::YV12;\n  int uv_rows = (vpx_image->d_h + 1) / 2;\n\n  if (vpx_image->fmt == VPX_IMG_FMT_I444) {\n    CHECK(!vpx_codec_alpha_);\n    codec_format = VideoFrame::YV24;\n    uv_rows = vpx_image->d_h;\n  } else if (vpx_codec_alpha_) {\n    codec_format = VideoFrame::YV12A;\n  }\n\n  gfx::Size size(vpx_image->d_w, vpx_image->d_h);\n\n  if (!vpx_codec_alpha_ && memory_pool_.get()) {\n    *video_frame = VideoFrame::WrapExternalYuvData(\n        codec_format,\n        size, gfx::Rect(size), config_.natural_size(),\n        vpx_image->stride[VPX_PLANE_Y],\n        vpx_image->stride[VPX_PLANE_U],\n        vpx_image->stride[VPX_PLANE_V],\n        vpx_image->planes[VPX_PLANE_Y],\n        vpx_image->planes[VPX_PLANE_U],\n        vpx_image->planes[VPX_PLANE_V],\n        kNoTimestamp(),\n        memory_pool_->CreateFrameCallback(vpx_image->fb_priv));\n    return;\n  }\n\n  *video_frame = frame_pool_.CreateFrame(\n      codec_format,\n      size,\n      gfx::Rect(size),\n      config_.natural_size(),\n      kNoTimestamp());\n\n  CopyYPlane(vpx_image->planes[VPX_PLANE_Y],\n             vpx_image->stride[VPX_PLANE_Y],\n             vpx_image->d_h,\n             video_frame->get());\n  CopyUPlane(vpx_image->planes[VPX_PLANE_U],\n             vpx_image->stride[VPX_PLANE_U],\n             uv_rows,\n             video_frame->get());\n  CopyVPlane(vpx_image->planes[VPX_PLANE_V],\n             vpx_image->stride[VPX_PLANE_V],\n             uv_rows,\n             video_frame->get());\n  if (!vpx_codec_alpha_)\n    return;\n  if (!vpx_image_alpha) {\n    MakeOpaqueAPlane(\n        vpx_image->stride[VPX_PLANE_Y], vpx_image->d_h, video_frame->get());\n    return;\n  }\n  CopyAPlane(vpx_image_alpha->planes[VPX_PLANE_Y],\n             vpx_image->stride[VPX_PLANE_Y],\n             vpx_image->d_h,\n             video_frame->get());\n}",
        "func": "void VpxVideoDecoder::CopyVpxImageTo(const vpx_image* vpx_image,\n                                     const struct vpx_image* vpx_image_alpha,\n                                     scoped_refptr<VideoFrame>* video_frame) {\n  CHECK(vpx_image);\n  CHECK(vpx_image->fmt == VPX_IMG_FMT_I420 ||\n        vpx_image->fmt == VPX_IMG_FMT_YV12 ||\n        vpx_image->fmt == VPX_IMG_FMT_I444);\n\n  VideoFrame::Format codec_format = VideoFrame::YV12;\n  int uv_rows = (vpx_image->d_h + 1) / 2;\n\n  if (vpx_image->fmt == VPX_IMG_FMT_I444) {\n    CHECK(!vpx_codec_alpha_);\n    codec_format = VideoFrame::YV24;\n    uv_rows = vpx_image->d_h;\n  } else if (vpx_codec_alpha_) {\n    codec_format = VideoFrame::YV12A;\n  }\n\n  gfx::Size size(vpx_image->d_w, vpx_image->d_h);\n\n  if (!vpx_codec_alpha_ && memory_pool_.get()) {\n    *video_frame = VideoFrame::WrapExternalYuvData(\n        codec_format,\n        size, gfx::Rect(size), config_.natural_size(),\n        vpx_image->stride[VPX_PLANE_Y],\n        vpx_image->stride[VPX_PLANE_U],\n        vpx_image->stride[VPX_PLANE_V],\n        vpx_image->planes[VPX_PLANE_Y],\n        vpx_image->planes[VPX_PLANE_U],\n        vpx_image->planes[VPX_PLANE_V],\n        kNoTimestamp(),\n        memory_pool_->CreateFrameCallback(vpx_image->fb_priv));\n    return;\n  }\n\n  *video_frame = frame_pool_.CreateFrame(\n      codec_format,\n      size,\n      gfx::Rect(size),\n      config_.natural_size(),\n      kNoTimestamp());\n\n  CopyYPlane(vpx_image->planes[VPX_PLANE_Y],\n             vpx_image->stride[VPX_PLANE_Y],\n             vpx_image->d_h,\n             video_frame->get());\n  CopyUPlane(vpx_image->planes[VPX_PLANE_U],\n             vpx_image->stride[VPX_PLANE_U],\n             uv_rows,\n             video_frame->get());\n  CopyVPlane(vpx_image->planes[VPX_PLANE_V],\n             vpx_image->stride[VPX_PLANE_V],\n             uv_rows,\n             video_frame->get());\n  if (!vpx_codec_alpha_)\n    return;\n  if (!vpx_image_alpha) {\n    MakeOpaqueAPlane(\n        vpx_image->stride[VPX_PLANE_Y], vpx_image->d_h, video_frame->get());\n    return;\n  }\n  CopyAPlane(vpx_image_alpha->planes[VPX_PLANE_Y],\n             vpx_image_alpha->stride[VPX_PLANE_Y],\n             vpx_image_alpha->d_h,\n             video_frame->get());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -61,7 +61,7 @@\n     return;\n   }\n   CopyAPlane(vpx_image_alpha->planes[VPX_PLANE_Y],\n-             vpx_image->stride[VPX_PLANE_Y],\n-             vpx_image->d_h,\n+             vpx_image_alpha->stride[VPX_PLANE_Y],\n+             vpx_image_alpha->d_h,\n              video_frame->get());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "             vpx_image->stride[VPX_PLANE_Y],",
                "             vpx_image->d_h,"
            ],
            "added_lines": [
                "             vpx_image_alpha->stride[VPX_PLANE_Y],",
                "             vpx_image_alpha->d_h,"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/files_init",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "void __init files_init(unsigned long mempages)\n{ \n\tunsigned long n;\n\n\tfilp_cachep = kmem_cache_create(\"filp\", sizeof(struct file), 0,\n\t\t\tSLAB_HWCACHE_ALIGN | SLAB_PANIC, NULL);\n\n\t/*\n\t * One file with associated inode and dcache is very roughly 1K.\n\t * Per default don't use more than 10% of our memory for files. \n\t */ \n\n\tn = (mempages * (PAGE_SIZE / 1024)) / 10;\n\tfiles_stat.max_files = max_t(unsigned long, n, NR_FILE);\n\tfiles_defer_init();\n\tlg_lock_init(&files_lglock, \"files_lglock\");\n\tpercpu_counter_init(&nr_files, 0);\n}",
        "func": "void __init files_init(unsigned long mempages)\n{ \n\tunsigned long n;\n\n\tfilp_cachep = kmem_cache_create(\"filp\", sizeof(struct file), 0,\n\t\t\tSLAB_HWCACHE_ALIGN | SLAB_PANIC, NULL);\n\n\t/*\n\t * One file with associated inode and dcache is very roughly 1K.\n\t * Per default don't use more than 10% of our memory for files. \n\t */ \n\n\tn = (mempages * (PAGE_SIZE / 1024)) / 10;\n\tfiles_stat.max_files = max_t(unsigned long, n, NR_FILE);\n\tfiles_defer_init();\n\tpercpu_counter_init(&nr_files, 0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -13,6 +13,5 @@\n \tn = (mempages * (PAGE_SIZE / 1024)) / 10;\n \tfiles_stat.max_files = max_t(unsigned long, n, NR_FILE);\n \tfiles_defer_init();\n-\tlg_lock_init(&files_lglock, \"files_lglock\");\n \tpercpu_counter_init(&nr_files, 0);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tlg_lock_init(&files_lglock, \"files_lglock\");"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/__fput_sync",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "void __fput_sync(struct file *file)\n{\n\tif (atomic_long_dec_and_test(&file->f_count)) {\n\t\tstruct task_struct *task = current;\n\t\tfile_sb_list_del(file);\n\t\tBUG_ON(!(task->flags & PF_KTHREAD));\n\t\t__fput(file);\n\t}\n}",
        "func": "void __fput_sync(struct file *file)\n{\n\tif (atomic_long_dec_and_test(&file->f_count)) {\n\t\tstruct task_struct *task = current;\n\t\tBUG_ON(!(task->flags & PF_KTHREAD));\n\t\t__fput(file);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,6 @@\n {\n \tif (atomic_long_dec_and_test(&file->f_count)) {\n \t\tstruct task_struct *task = current;\n-\t\tfile_sb_list_del(file);\n \t\tBUG_ON(!(task->flags & PF_KTHREAD));\n \t\t__fput(file);\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tfile_sb_list_del(file);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/get_empty_filp",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "struct file *get_empty_filp(void)\n{\n\tconst struct cred *cred = current_cred();\n\tstatic long old_max;\n\tstruct file *f;\n\tint error;\n\n\t/*\n\t * Privileged users can go above max_files\n\t */\n\tif (get_nr_files() >= files_stat.max_files && !capable(CAP_SYS_ADMIN)) {\n\t\t/*\n\t\t * percpu_counters are inaccurate.  Do an expensive check before\n\t\t * we go and fail.\n\t\t */\n\t\tif (percpu_counter_sum_positive(&nr_files) >= files_stat.max_files)\n\t\t\tgoto over;\n\t}\n\n\tf = kmem_cache_zalloc(filp_cachep, GFP_KERNEL);\n\tif (unlikely(!f))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpercpu_counter_inc(&nr_files);\n\tf->f_cred = get_cred(cred);\n\terror = security_file_alloc(f);\n\tif (unlikely(error)) {\n\t\tfile_free(f);\n\t\treturn ERR_PTR(error);\n\t}\n\n\tINIT_LIST_HEAD(&f->f_u.fu_list);\n\tatomic_long_set(&f->f_count, 1);\n\trwlock_init(&f->f_owner.lock);\n\tspin_lock_init(&f->f_lock);\n\teventpoll_init_file(f);\n\t/* f->f_version: 0 */\n\treturn f;\n\nover:\n\t/* Ran out of filps - report that */\n\tif (get_nr_files() > old_max) {\n\t\tpr_info(\"VFS: file-max limit %lu reached\\n\", get_max_files());\n\t\told_max = get_nr_files();\n\t}\n\treturn ERR_PTR(-ENFILE);\n}",
        "func": "struct file *get_empty_filp(void)\n{\n\tconst struct cred *cred = current_cred();\n\tstatic long old_max;\n\tstruct file *f;\n\tint error;\n\n\t/*\n\t * Privileged users can go above max_files\n\t */\n\tif (get_nr_files() >= files_stat.max_files && !capable(CAP_SYS_ADMIN)) {\n\t\t/*\n\t\t * percpu_counters are inaccurate.  Do an expensive check before\n\t\t * we go and fail.\n\t\t */\n\t\tif (percpu_counter_sum_positive(&nr_files) >= files_stat.max_files)\n\t\t\tgoto over;\n\t}\n\n\tf = kmem_cache_zalloc(filp_cachep, GFP_KERNEL);\n\tif (unlikely(!f))\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tpercpu_counter_inc(&nr_files);\n\tf->f_cred = get_cred(cred);\n\terror = security_file_alloc(f);\n\tif (unlikely(error)) {\n\t\tfile_free(f);\n\t\treturn ERR_PTR(error);\n\t}\n\n\tatomic_long_set(&f->f_count, 1);\n\trwlock_init(&f->f_owner.lock);\n\tspin_lock_init(&f->f_lock);\n\teventpoll_init_file(f);\n\t/* f->f_version: 0 */\n\treturn f;\n\nover:\n\t/* Ran out of filps - report that */\n\tif (get_nr_files() > old_max) {\n\t\tpr_info(\"VFS: file-max limit %lu reached\\n\", get_max_files());\n\t\told_max = get_nr_files();\n\t}\n\treturn ERR_PTR(-ENFILE);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,7 +29,6 @@\n \t\treturn ERR_PTR(error);\n \t}\n \n-\tINIT_LIST_HEAD(&f->f_u.fu_list);\n \tatomic_long_set(&f->f_count, 1);\n \trwlock_init(&f->f_owner.lock);\n \tspin_lock_init(&f->f_lock);",
        "diff_line_info": {
            "deleted_lines": [
                "\tINIT_LIST_HEAD(&f->f_u.fu_list);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/fput",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "void fput(struct file *file)\n{\n\tif (atomic_long_dec_and_test(&file->f_count)) {\n\t\tstruct task_struct *task = current;\n\n\t\tfile_sb_list_del(file);\n\t\tif (likely(!in_interrupt() && !(task->flags & PF_KTHREAD))) {\n\t\t\tinit_task_work(&file->f_u.fu_rcuhead, ____fput);\n\t\t\tif (!task_work_add(task, &file->f_u.fu_rcuhead, true))\n\t\t\t\treturn;\n\t\t\t/*\n\t\t\t * After this task has run exit_task_work(),\n\t\t\t * task_work_add() will fail.  Fall through to delayed\n\t\t\t * fput to avoid leaking *file.\n\t\t\t */\n\t\t}\n\n\t\tif (llist_add(&file->f_u.fu_llist, &delayed_fput_list))\n\t\t\tschedule_work(&delayed_fput_work);\n\t}\n}",
        "func": "void fput(struct file *file)\n{\n\tif (atomic_long_dec_and_test(&file->f_count)) {\n\t\tstruct task_struct *task = current;\n\n\t\tif (likely(!in_interrupt() && !(task->flags & PF_KTHREAD))) {\n\t\t\tinit_task_work(&file->f_u.fu_rcuhead, ____fput);\n\t\t\tif (!task_work_add(task, &file->f_u.fu_rcuhead, true))\n\t\t\t\treturn;\n\t\t\t/*\n\t\t\t * After this task has run exit_task_work(),\n\t\t\t * task_work_add() will fail.  Fall through to delayed\n\t\t\t * fput to avoid leaking *file.\n\t\t\t */\n\t\t}\n\n\t\tif (llist_add(&file->f_u.fu_llist, &delayed_fput_list))\n\t\t\tschedule_work(&delayed_fput_work);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,6 @@\n \tif (atomic_long_dec_and_test(&file->f_count)) {\n \t\tstruct task_struct *task = current;\n \n-\t\tfile_sb_list_del(file);\n \t\tif (likely(!in_interrupt() && !(task->flags & PF_KTHREAD))) {\n \t\t\tinit_task_work(&file->f_u.fu_rcuhead, ____fput);\n \t\t\tif (!task_work_add(task, &file->f_u.fu_rcuhead, true))",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tfile_sb_list_del(file);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/put_filp",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "void put_filp(struct file *file)\n{\n\tif (atomic_long_dec_and_test(&file->f_count)) {\n\t\tsecurity_file_free(file);\n\t\tfile_sb_list_del(file);\n\t\tfile_free(file);\n\t}\n}",
        "func": "void put_filp(struct file *file)\n{\n\tif (atomic_long_dec_and_test(&file->f_count)) {\n\t\tsecurity_file_free(file);\n\t\tfile_free(file);\n\t}\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,7 +2,6 @@\n {\n \tif (atomic_long_dec_and_test(&file->f_count)) {\n \t\tsecurity_file_free(file);\n-\t\tfile_sb_list_del(file);\n \t\tfile_free(file);\n \t}\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tfile_sb_list_del(file);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/do_dentry_open",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "static int do_dentry_open(struct file *f,\n\t\t\t  int (*open)(struct inode *, struct file *),\n\t\t\t  const struct cred *cred)\n{\n\tstatic const struct file_operations empty_fops = {};\n\tstruct inode *inode;\n\tint error;\n\n\tf->f_mode = OPEN_FMODE(f->f_flags) | FMODE_LSEEK |\n\t\t\t\tFMODE_PREAD | FMODE_PWRITE;\n\n\tif (unlikely(f->f_flags & O_PATH))\n\t\tf->f_mode = FMODE_PATH;\n\n\tpath_get(&f->f_path);\n\tinode = f->f_inode = f->f_path.dentry->d_inode;\n\tif (f->f_mode & FMODE_WRITE) {\n\t\terror = __get_file_write_access(inode, f->f_path.mnt);\n\t\tif (error)\n\t\t\tgoto cleanup_file;\n\t\tif (!special_file(inode->i_mode))\n\t\t\tfile_take_write(f);\n\t}\n\n\tf->f_mapping = inode->i_mapping;\n\tfile_sb_list_add(f, inode->i_sb);\n\n\tif (unlikely(f->f_mode & FMODE_PATH)) {\n\t\tf->f_op = &empty_fops;\n\t\treturn 0;\n\t}\n\n\tf->f_op = fops_get(inode->i_fop);\n\tif (unlikely(WARN_ON(!f->f_op))) {\n\t\terror = -ENODEV;\n\t\tgoto cleanup_all;\n\t}\n\n\terror = security_file_open(f, cred);\n\tif (error)\n\t\tgoto cleanup_all;\n\n\terror = break_lease(inode, f->f_flags);\n\tif (error)\n\t\tgoto cleanup_all;\n\n\tif (!open)\n\t\topen = f->f_op->open;\n\tif (open) {\n\t\terror = open(inode, f);\n\t\tif (error)\n\t\t\tgoto cleanup_all;\n\t}\n\tif ((f->f_mode & (FMODE_READ | FMODE_WRITE)) == FMODE_READ)\n\t\ti_readcount_inc(inode);\n\n\tf->f_flags &= ~(O_CREAT | O_EXCL | O_NOCTTY | O_TRUNC);\n\n\tfile_ra_state_init(&f->f_ra, f->f_mapping->host->i_mapping);\n\n\treturn 0;\n\ncleanup_all:\n\tfops_put(f->f_op);\n\tfile_sb_list_del(f);\n\tif (f->f_mode & FMODE_WRITE) {\n\t\tput_write_access(inode);\n\t\tif (!special_file(inode->i_mode)) {\n\t\t\t/*\n\t\t\t * We don't consider this a real\n\t\t\t * mnt_want/drop_write() pair\n\t\t\t * because it all happenend right\n\t\t\t * here, so just reset the state.\n\t\t\t */\n\t\t\tfile_reset_write(f);\n\t\t\t__mnt_drop_write(f->f_path.mnt);\n\t\t}\n\t}\ncleanup_file:\n\tpath_put(&f->f_path);\n\tf->f_path.mnt = NULL;\n\tf->f_path.dentry = NULL;\n\tf->f_inode = NULL;\n\treturn error;\n}",
        "func": "static int do_dentry_open(struct file *f,\n\t\t\t  int (*open)(struct inode *, struct file *),\n\t\t\t  const struct cred *cred)\n{\n\tstatic const struct file_operations empty_fops = {};\n\tstruct inode *inode;\n\tint error;\n\n\tf->f_mode = OPEN_FMODE(f->f_flags) | FMODE_LSEEK |\n\t\t\t\tFMODE_PREAD | FMODE_PWRITE;\n\n\tif (unlikely(f->f_flags & O_PATH))\n\t\tf->f_mode = FMODE_PATH;\n\n\tpath_get(&f->f_path);\n\tinode = f->f_inode = f->f_path.dentry->d_inode;\n\tif (f->f_mode & FMODE_WRITE) {\n\t\terror = __get_file_write_access(inode, f->f_path.mnt);\n\t\tif (error)\n\t\t\tgoto cleanup_file;\n\t\tif (!special_file(inode->i_mode))\n\t\t\tfile_take_write(f);\n\t}\n\n\tf->f_mapping = inode->i_mapping;\n\n\tif (unlikely(f->f_mode & FMODE_PATH)) {\n\t\tf->f_op = &empty_fops;\n\t\treturn 0;\n\t}\n\n\tf->f_op = fops_get(inode->i_fop);\n\tif (unlikely(WARN_ON(!f->f_op))) {\n\t\terror = -ENODEV;\n\t\tgoto cleanup_all;\n\t}\n\n\terror = security_file_open(f, cred);\n\tif (error)\n\t\tgoto cleanup_all;\n\n\terror = break_lease(inode, f->f_flags);\n\tif (error)\n\t\tgoto cleanup_all;\n\n\tif (!open)\n\t\topen = f->f_op->open;\n\tif (open) {\n\t\terror = open(inode, f);\n\t\tif (error)\n\t\t\tgoto cleanup_all;\n\t}\n\tif ((f->f_mode & (FMODE_READ | FMODE_WRITE)) == FMODE_READ)\n\t\ti_readcount_inc(inode);\n\n\tf->f_flags &= ~(O_CREAT | O_EXCL | O_NOCTTY | O_TRUNC);\n\n\tfile_ra_state_init(&f->f_ra, f->f_mapping->host->i_mapping);\n\n\treturn 0;\n\ncleanup_all:\n\tfops_put(f->f_op);\n\tif (f->f_mode & FMODE_WRITE) {\n\t\tput_write_access(inode);\n\t\tif (!special_file(inode->i_mode)) {\n\t\t\t/*\n\t\t\t * We don't consider this a real\n\t\t\t * mnt_want/drop_write() pair\n\t\t\t * because it all happenend right\n\t\t\t * here, so just reset the state.\n\t\t\t */\n\t\t\tfile_reset_write(f);\n\t\t\t__mnt_drop_write(f->f_path.mnt);\n\t\t}\n\t}\ncleanup_file:\n\tpath_put(&f->f_path);\n\tf->f_path.mnt = NULL;\n\tf->f_path.dentry = NULL;\n\tf->f_inode = NULL;\n\treturn error;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -23,7 +23,6 @@\n \t}\n \n \tf->f_mapping = inode->i_mapping;\n-\tfile_sb_list_add(f, inode->i_sb);\n \n \tif (unlikely(f->f_mode & FMODE_PATH)) {\n \t\tf->f_op = &empty_fops;\n@@ -62,7 +61,6 @@\n \n cleanup_all:\n \tfops_put(f->f_op);\n-\tfile_sb_list_del(f);\n \tif (f->f_mode & FMODE_WRITE) {\n \t\tput_write_access(inode);\n \t\tif (!special_file(inode->i_mode)) {",
        "diff_line_info": {
            "deleted_lines": [
                "\tfile_sb_list_add(f, inode->i_sb);",
                "\tfile_sb_list_del(f);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/destroy_super",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "static void destroy_super(struct super_block *s)\n{\n\tint i;\n\tlist_lru_destroy(&s->s_dentry_lru);\n\tlist_lru_destroy(&s->s_inode_lru);\n#ifdef CONFIG_SMP\n\tfree_percpu(s->s_files);\n#endif\n\tfor (i = 0; i < SB_FREEZE_LEVELS; i++)\n\t\tpercpu_counter_destroy(&s->s_writers.counter[i]);\n\tsecurity_sb_free(s);\n\tWARN_ON(!list_empty(&s->s_mounts));\n\tkfree(s->s_subtype);\n\tkfree(s->s_options);\n\tkfree_rcu(s, rcu);\n}",
        "func": "static void destroy_super(struct super_block *s)\n{\n\tint i;\n\tlist_lru_destroy(&s->s_dentry_lru);\n\tlist_lru_destroy(&s->s_inode_lru);\n\tfor (i = 0; i < SB_FREEZE_LEVELS; i++)\n\t\tpercpu_counter_destroy(&s->s_writers.counter[i]);\n\tsecurity_sb_free(s);\n\tWARN_ON(!list_empty(&s->s_mounts));\n\tkfree(s->s_subtype);\n\tkfree(s->s_options);\n\tkfree_rcu(s, rcu);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,9 +3,6 @@\n \tint i;\n \tlist_lru_destroy(&s->s_dentry_lru);\n \tlist_lru_destroy(&s->s_inode_lru);\n-#ifdef CONFIG_SMP\n-\tfree_percpu(s->s_files);\n-#endif\n \tfor (i = 0; i < SB_FREEZE_LEVELS; i++)\n \t\tpercpu_counter_destroy(&s->s_writers.counter[i]);\n \tsecurity_sb_free(s);",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef CONFIG_SMP",
                "\tfree_percpu(s->s_files);",
                "#endif"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/do_remount_sb",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "int do_remount_sb(struct super_block *sb, int flags, void *data, int force)\n{\n\tint retval;\n\tint remount_ro;\n\n\tif (sb->s_writers.frozen != SB_UNFROZEN)\n\t\treturn -EBUSY;\n\n#ifdef CONFIG_BLOCK\n\tif (!(flags & MS_RDONLY) && bdev_read_only(sb->s_bdev))\n\t\treturn -EACCES;\n#endif\n\n\tif (flags & MS_RDONLY)\n\t\tacct_auto_close(sb);\n\tshrink_dcache_sb(sb);\n\tsync_filesystem(sb);\n\n\tremount_ro = (flags & MS_RDONLY) && !(sb->s_flags & MS_RDONLY);\n\n\t/* If we are remounting RDONLY and current sb is read/write,\n\t   make sure there are no rw files opened */\n\tif (remount_ro) {\n\t\tif (force) {\n\t\t\tmark_files_ro(sb);\n\t\t} else {\n\t\t\tretval = sb_prepare_remount_readonly(sb);\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t}\n\t}\n\n\tif (sb->s_op->remount_fs) {\n\t\tretval = sb->s_op->remount_fs(sb, &flags, data);\n\t\tif (retval) {\n\t\t\tif (!force)\n\t\t\t\tgoto cancel_readonly;\n\t\t\t/* If forced remount, go ahead despite any errors */\n\t\t\tWARN(1, \"forced remount of a %s fs returned %i\\n\",\n\t\t\t     sb->s_type->name, retval);\n\t\t}\n\t}\n\tsb->s_flags = (sb->s_flags & ~MS_RMT_MASK) | (flags & MS_RMT_MASK);\n\t/* Needs to be ordered wrt mnt_is_readonly() */\n\tsmp_wmb();\n\tsb->s_readonly_remount = 0;\n\n\t/*\n\t * Some filesystems modify their metadata via some other path than the\n\t * bdev buffer cache (eg. use a private mapping, or directories in\n\t * pagecache, etc). Also file data modifications go via their own\n\t * mappings. So If we try to mount readonly then copy the filesystem\n\t * from bdev, we could get stale data, so invalidate it to give a best\n\t * effort at coherency.\n\t */\n\tif (remount_ro && sb->s_bdev)\n\t\tinvalidate_bdev(sb->s_bdev);\n\treturn 0;\n\ncancel_readonly:\n\tsb->s_readonly_remount = 0;\n\treturn retval;\n}",
        "func": "int do_remount_sb(struct super_block *sb, int flags, void *data, int force)\n{\n\tint retval;\n\tint remount_ro;\n\n\tif (sb->s_writers.frozen != SB_UNFROZEN)\n\t\treturn -EBUSY;\n\n#ifdef CONFIG_BLOCK\n\tif (!(flags & MS_RDONLY) && bdev_read_only(sb->s_bdev))\n\t\treturn -EACCES;\n#endif\n\n\tif (flags & MS_RDONLY)\n\t\tacct_auto_close(sb);\n\tshrink_dcache_sb(sb);\n\tsync_filesystem(sb);\n\n\tremount_ro = (flags & MS_RDONLY) && !(sb->s_flags & MS_RDONLY);\n\n\t/* If we are remounting RDONLY and current sb is read/write,\n\t   make sure there are no rw files opened */\n\tif (remount_ro) {\n\t\tif (force) {\n\t\t\tsb->s_readonly_remount = 1;\n\t\t\tsmp_wmb();\n\t\t} else {\n\t\t\tretval = sb_prepare_remount_readonly(sb);\n\t\t\tif (retval)\n\t\t\t\treturn retval;\n\t\t}\n\t}\n\n\tif (sb->s_op->remount_fs) {\n\t\tretval = sb->s_op->remount_fs(sb, &flags, data);\n\t\tif (retval) {\n\t\t\tif (!force)\n\t\t\t\tgoto cancel_readonly;\n\t\t\t/* If forced remount, go ahead despite any errors */\n\t\t\tWARN(1, \"forced remount of a %s fs returned %i\\n\",\n\t\t\t     sb->s_type->name, retval);\n\t\t}\n\t}\n\tsb->s_flags = (sb->s_flags & ~MS_RMT_MASK) | (flags & MS_RMT_MASK);\n\t/* Needs to be ordered wrt mnt_is_readonly() */\n\tsmp_wmb();\n\tsb->s_readonly_remount = 0;\n\n\t/*\n\t * Some filesystems modify their metadata via some other path than the\n\t * bdev buffer cache (eg. use a private mapping, or directories in\n\t * pagecache, etc). Also file data modifications go via their own\n\t * mappings. So If we try to mount readonly then copy the filesystem\n\t * from bdev, we could get stale data, so invalidate it to give a best\n\t * effort at coherency.\n\t */\n\tif (remount_ro && sb->s_bdev)\n\t\tinvalidate_bdev(sb->s_bdev);\n\treturn 0;\n\ncancel_readonly:\n\tsb->s_readonly_remount = 0;\n\treturn retval;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -22,7 +22,8 @@\n \t   make sure there are no rw files opened */\n \tif (remount_ro) {\n \t\tif (force) {\n-\t\t\tmark_files_ro(sb);\n+\t\t\tsb->s_readonly_remount = 1;\n+\t\t\tsmp_wmb();\n \t\t} else {\n \t\t\tretval = sb_prepare_remount_readonly(sb);\n \t\t\tif (retval)",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tmark_files_ro(sb);"
            ],
            "added_lines": [
                "\t\t\tsb->s_readonly_remount = 1;",
                "\t\t\tsmp_wmb();"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8172",
        "func_name": "torvalds/linux/alloc_super",
        "description": "The filesystem implementation in the Linux kernel before 3.13 performs certain operations on lists of files with an inappropriate locking approach, which allows local users to cause a denial of service (soft lockup or system crash) via unspecified use of Asynchronous I/O (AIO) operations.",
        "git_url": "https://github.com/torvalds/linux/commit/eee5cc2702929fd41cce28058dc6d6717f723f87",
        "commit_title": "get rid of s_files and files_lock",
        "commit_text": " The only thing we need it for is alt-sysrq-r (emergency remount r/o) and these days we can do just as well without going through the list of files. ",
        "func_before": "static struct super_block *alloc_super(struct file_system_type *type, int flags)\n{\n\tstruct super_block *s = kzalloc(sizeof(struct super_block),  GFP_USER);\n\tstatic const struct super_operations default_op;\n\tint i;\n\n\tif (!s)\n\t\treturn NULL;\n\n\tif (security_sb_alloc(s))\n\t\tgoto fail;\n\n#ifdef CONFIG_SMP\n\ts->s_files = alloc_percpu(struct list_head);\n\tif (!s->s_files)\n\t\tgoto fail;\n\tfor_each_possible_cpu(i)\n\t\tINIT_LIST_HEAD(per_cpu_ptr(s->s_files, i));\n#else\n\tINIT_LIST_HEAD(&s->s_files);\n#endif\n\tfor (i = 0; i < SB_FREEZE_LEVELS; i++) {\n\t\tif (percpu_counter_init(&s->s_writers.counter[i], 0) < 0)\n\t\t\tgoto fail;\n\t\tlockdep_init_map(&s->s_writers.lock_map[i], sb_writers_name[i],\n\t\t\t\t &type->s_writers_key[i], 0);\n\t}\n\tinit_waitqueue_head(&s->s_writers.wait);\n\tinit_waitqueue_head(&s->s_writers.wait_unfrozen);\n\ts->s_flags = flags;\n\ts->s_bdi = &default_backing_dev_info;\n\tINIT_HLIST_NODE(&s->s_instances);\n\tINIT_HLIST_BL_HEAD(&s->s_anon);\n\tINIT_LIST_HEAD(&s->s_inodes);\n\n\tif (list_lru_init(&s->s_dentry_lru))\n\t\tgoto fail;\n\tif (list_lru_init(&s->s_inode_lru))\n\t\tgoto fail;\n\n\tINIT_LIST_HEAD(&s->s_mounts);\n\tinit_rwsem(&s->s_umount);\n\tlockdep_set_class(&s->s_umount, &type->s_umount_key);\n\t/*\n\t * sget() can have s_umount recursion.\n\t *\n\t * When it cannot find a suitable sb, it allocates a new\n\t * one (this one), and tries again to find a suitable old\n\t * one.\n\t *\n\t * In case that succeeds, it will acquire the s_umount\n\t * lock of the old one. Since these are clearly distrinct\n\t * locks, and this object isn't exposed yet, there's no\n\t * risk of deadlocks.\n\t *\n\t * Annotate this by putting this lock in a different\n\t * subclass.\n\t */\n\tdown_write_nested(&s->s_umount, SINGLE_DEPTH_NESTING);\n\ts->s_count = 1;\n\tatomic_set(&s->s_active, 1);\n\tmutex_init(&s->s_vfs_rename_mutex);\n\tlockdep_set_class(&s->s_vfs_rename_mutex, &type->s_vfs_rename_key);\n\tmutex_init(&s->s_dquot.dqio_mutex);\n\tmutex_init(&s->s_dquot.dqonoff_mutex);\n\tinit_rwsem(&s->s_dquot.dqptr_sem);\n\ts->s_maxbytes = MAX_NON_LFS;\n\ts->s_op = &default_op;\n\ts->s_time_gran = 1000000000;\n\ts->cleancache_poolid = -1;\n\n\ts->s_shrink.seeks = DEFAULT_SEEKS;\n\ts->s_shrink.scan_objects = super_cache_scan;\n\ts->s_shrink.count_objects = super_cache_count;\n\ts->s_shrink.batch = 1024;\n\ts->s_shrink.flags = SHRINKER_NUMA_AWARE;\n\treturn s;\n\nfail:\n\tdestroy_super(s);\n\treturn NULL;\n}",
        "func": "static struct super_block *alloc_super(struct file_system_type *type, int flags)\n{\n\tstruct super_block *s = kzalloc(sizeof(struct super_block),  GFP_USER);\n\tstatic const struct super_operations default_op;\n\tint i;\n\n\tif (!s)\n\t\treturn NULL;\n\n\tif (security_sb_alloc(s))\n\t\tgoto fail;\n\n\tfor (i = 0; i < SB_FREEZE_LEVELS; i++) {\n\t\tif (percpu_counter_init(&s->s_writers.counter[i], 0) < 0)\n\t\t\tgoto fail;\n\t\tlockdep_init_map(&s->s_writers.lock_map[i], sb_writers_name[i],\n\t\t\t\t &type->s_writers_key[i], 0);\n\t}\n\tinit_waitqueue_head(&s->s_writers.wait);\n\tinit_waitqueue_head(&s->s_writers.wait_unfrozen);\n\ts->s_flags = flags;\n\ts->s_bdi = &default_backing_dev_info;\n\tINIT_HLIST_NODE(&s->s_instances);\n\tINIT_HLIST_BL_HEAD(&s->s_anon);\n\tINIT_LIST_HEAD(&s->s_inodes);\n\n\tif (list_lru_init(&s->s_dentry_lru))\n\t\tgoto fail;\n\tif (list_lru_init(&s->s_inode_lru))\n\t\tgoto fail;\n\n\tINIT_LIST_HEAD(&s->s_mounts);\n\tinit_rwsem(&s->s_umount);\n\tlockdep_set_class(&s->s_umount, &type->s_umount_key);\n\t/*\n\t * sget() can have s_umount recursion.\n\t *\n\t * When it cannot find a suitable sb, it allocates a new\n\t * one (this one), and tries again to find a suitable old\n\t * one.\n\t *\n\t * In case that succeeds, it will acquire the s_umount\n\t * lock of the old one. Since these are clearly distrinct\n\t * locks, and this object isn't exposed yet, there's no\n\t * risk of deadlocks.\n\t *\n\t * Annotate this by putting this lock in a different\n\t * subclass.\n\t */\n\tdown_write_nested(&s->s_umount, SINGLE_DEPTH_NESTING);\n\ts->s_count = 1;\n\tatomic_set(&s->s_active, 1);\n\tmutex_init(&s->s_vfs_rename_mutex);\n\tlockdep_set_class(&s->s_vfs_rename_mutex, &type->s_vfs_rename_key);\n\tmutex_init(&s->s_dquot.dqio_mutex);\n\tmutex_init(&s->s_dquot.dqonoff_mutex);\n\tinit_rwsem(&s->s_dquot.dqptr_sem);\n\ts->s_maxbytes = MAX_NON_LFS;\n\ts->s_op = &default_op;\n\ts->s_time_gran = 1000000000;\n\ts->cleancache_poolid = -1;\n\n\ts->s_shrink.seeks = DEFAULT_SEEKS;\n\ts->s_shrink.scan_objects = super_cache_scan;\n\ts->s_shrink.count_objects = super_cache_count;\n\ts->s_shrink.batch = 1024;\n\ts->s_shrink.flags = SHRINKER_NUMA_AWARE;\n\treturn s;\n\nfail:\n\tdestroy_super(s);\n\treturn NULL;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -10,15 +10,6 @@\n \tif (security_sb_alloc(s))\n \t\tgoto fail;\n \n-#ifdef CONFIG_SMP\n-\ts->s_files = alloc_percpu(struct list_head);\n-\tif (!s->s_files)\n-\t\tgoto fail;\n-\tfor_each_possible_cpu(i)\n-\t\tINIT_LIST_HEAD(per_cpu_ptr(s->s_files, i));\n-#else\n-\tINIT_LIST_HEAD(&s->s_files);\n-#endif\n \tfor (i = 0; i < SB_FREEZE_LEVELS; i++) {\n \t\tif (percpu_counter_init(&s->s_writers.counter[i], 0) < 0)\n \t\t\tgoto fail;",
        "diff_line_info": {
            "deleted_lines": [
                "#ifdef CONFIG_SMP",
                "\ts->s_files = alloc_percpu(struct list_head);",
                "\tif (!s->s_files)",
                "\t\tgoto fail;",
                "\tfor_each_possible_cpu(i)",
                "\t\tINIT_LIST_HEAD(per_cpu_ptr(s->s_files, i));",
                "#else",
                "\tINIT_LIST_HEAD(&s->s_files);",
                "#endif"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-0286",
        "func_name": "openssl/ASN1_TYPE_cmp",
        "description": "The ASN1_TYPE_cmp function in crypto/asn1/a_type.c in OpenSSL before 0.9.8zf, 1.0.0 before 1.0.0r, 1.0.1 before 1.0.1m, and 1.0.2 before 1.0.2a does not properly perform boolean-type comparisons, which allows remote attackers to cause a denial of service (invalid read operation and application crash) via a crafted X.509 certificate to an endpoint that uses the certificate-verification feature.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=c3c7fb07dc975dc3c9de0eddb7d8fd79fc9c67c1",
        "commit_title": "",
        "commit_text": "Fix ASN1_TYPE_cmp  Fix segmentation violation when ASN1_TYPE_cmp is passed a boolean type. This can be triggered during certificate verification so could be a DoS attack against a client or a server enabling client authentication.  CVE-2015-0286  ",
        "func_before": "int ASN1_TYPE_cmp(const ASN1_TYPE *a, const ASN1_TYPE *b)\n{\n    int result = -1;\n\n    if (!a || !b || a->type != b->type)\n        return -1;\n\n    switch (a->type) {\n    case V_ASN1_OBJECT:\n        result = OBJ_cmp(a->value.object, b->value.object);\n        break;\n    case V_ASN1_NULL:\n        result = 0;             /* They do not have content. */\n        break;\n    case V_ASN1_INTEGER:\n    case V_ASN1_NEG_INTEGER:\n    case V_ASN1_ENUMERATED:\n    case V_ASN1_NEG_ENUMERATED:\n    case V_ASN1_BIT_STRING:\n    case V_ASN1_OCTET_STRING:\n    case V_ASN1_SEQUENCE:\n    case V_ASN1_SET:\n    case V_ASN1_NUMERICSTRING:\n    case V_ASN1_PRINTABLESTRING:\n    case V_ASN1_T61STRING:\n    case V_ASN1_VIDEOTEXSTRING:\n    case V_ASN1_IA5STRING:\n    case V_ASN1_UTCTIME:\n    case V_ASN1_GENERALIZEDTIME:\n    case V_ASN1_GRAPHICSTRING:\n    case V_ASN1_VISIBLESTRING:\n    case V_ASN1_GENERALSTRING:\n    case V_ASN1_UNIVERSALSTRING:\n    case V_ASN1_BMPSTRING:\n    case V_ASN1_UTF8STRING:\n    case V_ASN1_OTHER:\n    default:\n        result = ASN1_STRING_cmp((ASN1_STRING *)a->value.ptr,\n                                 (ASN1_STRING *)b->value.ptr);\n        break;\n    }\n\n    return result;\n}",
        "func": "int ASN1_TYPE_cmp(const ASN1_TYPE *a, const ASN1_TYPE *b)\n{\n    int result = -1;\n\n    if (!a || !b || a->type != b->type)\n        return -1;\n\n    switch (a->type) {\n    case V_ASN1_OBJECT:\n        result = OBJ_cmp(a->value.object, b->value.object);\n        break;\n    case V_ASN1_BOOLEAN:\n        result = a->value.boolean - b->value.boolean;\n        break;\n    case V_ASN1_NULL:\n        result = 0;             /* They do not have content. */\n        break;\n    case V_ASN1_INTEGER:\n    case V_ASN1_NEG_INTEGER:\n    case V_ASN1_ENUMERATED:\n    case V_ASN1_NEG_ENUMERATED:\n    case V_ASN1_BIT_STRING:\n    case V_ASN1_OCTET_STRING:\n    case V_ASN1_SEQUENCE:\n    case V_ASN1_SET:\n    case V_ASN1_NUMERICSTRING:\n    case V_ASN1_PRINTABLESTRING:\n    case V_ASN1_T61STRING:\n    case V_ASN1_VIDEOTEXSTRING:\n    case V_ASN1_IA5STRING:\n    case V_ASN1_UTCTIME:\n    case V_ASN1_GENERALIZEDTIME:\n    case V_ASN1_GRAPHICSTRING:\n    case V_ASN1_VISIBLESTRING:\n    case V_ASN1_GENERALSTRING:\n    case V_ASN1_UNIVERSALSTRING:\n    case V_ASN1_BMPSTRING:\n    case V_ASN1_UTF8STRING:\n    case V_ASN1_OTHER:\n    default:\n        result = ASN1_STRING_cmp((ASN1_STRING *)a->value.ptr,\n                                 (ASN1_STRING *)b->value.ptr);\n        break;\n    }\n\n    return result;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,6 +8,9 @@\n     switch (a->type) {\n     case V_ASN1_OBJECT:\n         result = OBJ_cmp(a->value.object, b->value.object);\n+        break;\n+    case V_ASN1_BOOLEAN:\n+        result = a->value.boolean - b->value.boolean;\n         break;\n     case V_ASN1_NULL:\n         result = 0;             /* They do not have content. */",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        break;",
                "    case V_ASN1_BOOLEAN:",
                "        result = a->value.boolean - b->value.boolean;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-0287",
        "func_name": "openssl/ASN1_item_ex_d2i",
        "description": "The ASN1_item_ex_d2i function in crypto/asn1/tasn_dec.c in OpenSSL before 0.9.8zf, 1.0.0 before 1.0.0r, 1.0.1 before 1.0.1m, and 1.0.2 before 1.0.2a does not reinitialize CHOICE and ADB data structures, which might allow attackers to cause a denial of service (invalid write operation and memory corruption) by leveraging an application that relies on ASN.1 structure reuse.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=b717b083073b6cacc0a5e2397b661678aff7ae7f",
        "commit_title": "",
        "commit_text": "Free up ADB and CHOICE if already initialised.  CVE-2015-0287  ",
        "func_before": "int ASN1_item_ex_d2i(ASN1_VALUE **pval, const unsigned char **in, long len,\n                     const ASN1_ITEM *it,\n                     int tag, int aclass, char opt, ASN1_TLC *ctx)\n{\n    const ASN1_TEMPLATE *tt, *errtt = NULL;\n    const ASN1_COMPAT_FUNCS *cf;\n    const ASN1_EXTERN_FUNCS *ef;\n    const ASN1_AUX *aux = it->funcs;\n    ASN1_aux_cb *asn1_cb;\n    const unsigned char *p = NULL, *q;\n    unsigned char *wp = NULL;   /* BIG FAT WARNING! BREAKS CONST WHERE USED */\n    unsigned char imphack = 0, oclass;\n    char seq_eoc, seq_nolen, cst, isopt;\n    long tmplen;\n    int i;\n    int otag;\n    int ret = 0;\n    ASN1_VALUE **pchptr, *ptmpval;\n    if (!pval)\n        return 0;\n    if (aux && aux->asn1_cb)\n        asn1_cb = aux->asn1_cb;\n    else\n        asn1_cb = 0;\n\n    switch (it->itype) {\n    case ASN1_ITYPE_PRIMITIVE:\n        if (it->templates) {\n            /*\n             * tagging or OPTIONAL is currently illegal on an item template\n             * because the flags can't get passed down. In practice this\n             * isn't a problem: we include the relevant flags from the item\n             * template in the template itself.\n             */\n            if ((tag != -1) || opt) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I,\n                        ASN1_R_ILLEGAL_OPTIONS_ON_ITEM_TEMPLATE);\n                goto err;\n            }\n            return asn1_template_ex_d2i(pval, in, len,\n                                        it->templates, opt, ctx);\n        }\n        return asn1_d2i_ex_primitive(pval, in, len, it,\n                                     tag, aclass, opt, ctx);\n        break;\n\n    case ASN1_ITYPE_MSTRING:\n        p = *in;\n        /* Just read in tag and class */\n        ret = asn1_check_tlen(NULL, &otag, &oclass, NULL, NULL,\n                              &p, len, -1, 0, 1, ctx);\n        if (!ret) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        /* Must be UNIVERSAL class */\n        if (oclass != V_ASN1_UNIVERSAL) {\n            /* If OPTIONAL, assume this is OK */\n            if (opt)\n                return -1;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MSTRING_NOT_UNIVERSAL);\n            goto err;\n        }\n        /* Check tag matches bit map */\n        if (!(ASN1_tag2bit(otag) & it->utype)) {\n            /* If OPTIONAL, assume this is OK */\n            if (opt)\n                return -1;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MSTRING_WRONG_TAG);\n            goto err;\n        }\n        return asn1_d2i_ex_primitive(pval, in, len, it, otag, 0, 0, ctx);\n\n    case ASN1_ITYPE_EXTERN:\n        /* Use new style d2i */\n        ef = it->funcs;\n        return ef->asn1_ex_d2i(pval, in, len, it, tag, aclass, opt, ctx);\n\n    case ASN1_ITYPE_COMPAT:\n        /* we must resort to old style evil hackery */\n        cf = it->funcs;\n\n        /* If OPTIONAL see if it is there */\n        if (opt) {\n            int exptag;\n            p = *in;\n            if (tag == -1)\n                exptag = it->utype;\n            else\n                exptag = tag;\n            /*\n             * Don't care about anything other than presence of expected tag\n             */\n\n            ret = asn1_check_tlen(NULL, NULL, NULL, NULL, NULL,\n                                  &p, len, exptag, aclass, 1, ctx);\n            if (!ret) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n                goto err;\n            }\n            if (ret == -1)\n                return -1;\n        }\n\n        /*\n         * This is the old style evil hack IMPLICIT handling: since the\n         * underlying code is expecting a tag and class other than the one\n         * present we change the buffer temporarily then change it back\n         * afterwards. This doesn't and never did work for tags > 30. Yes\n         * this is *horrible* but it is only needed for old style d2i which\n         * will hopefully not be around for much longer. FIXME: should copy\n         * the buffer then modify it so the input buffer can be const: we\n         * should *always* copy because the old style d2i might modify the\n         * buffer.\n         */\n\n        if (tag != -1) {\n            wp = *(unsigned char **)in;\n            imphack = *wp;\n            if (p == NULL) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n                goto err;\n            }\n            *wp = (unsigned char)((*p & V_ASN1_CONSTRUCTED)\n                                  | it->utype);\n        }\n\n        ptmpval = cf->asn1_d2i(pval, in, len);\n\n        if (tag != -1)\n            *wp = imphack;\n\n        if (ptmpval)\n            return 1;\n\n        ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n        goto err;\n\n    case ASN1_ITYPE_CHOICE:\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n            goto auxerr;\n\n        /* Allocate structure */\n        if (!*pval && !ASN1_item_ex_new(pval, it)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n        /* CHOICE type, try each possibility in turn */\n        p = *in;\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            pchptr = asn1_get_field_ptr(pval, tt);\n            /*\n             * We mark field as OPTIONAL so its absence can be recognised.\n             */\n            ret = asn1_template_ex_d2i(pchptr, &p, len, tt, 1, ctx);\n            /* If field not present, try the next one */\n            if (ret == -1)\n                continue;\n            /* If positive return, read OK, break loop */\n            if (ret > 0)\n                break;\n            /* Otherwise must be an ASN1 parsing error */\n            errtt = tt;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        /* Did we fall off the end without reading anything? */\n        if (i == it->tcount) {\n            /* If OPTIONAL, this is OK */\n            if (opt) {\n                /* Free and zero it */\n                ASN1_item_ex_free(pval, it);\n                return -1;\n            }\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_NO_MATCHING_CHOICE_TYPE);\n            goto err;\n        }\n\n        asn1_set_choice_selector(pval, i, it);\n        *in = p;\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_POST, pval, it, NULL))\n            goto auxerr;\n        return 1;\n\n    case ASN1_ITYPE_NDEF_SEQUENCE:\n    case ASN1_ITYPE_SEQUENCE:\n        p = *in;\n        tmplen = len;\n\n        /* If no IMPLICIT tagging set to SEQUENCE, UNIVERSAL */\n        if (tag == -1) {\n            tag = V_ASN1_SEQUENCE;\n            aclass = V_ASN1_UNIVERSAL;\n        }\n        /* Get SEQUENCE length and update len, p */\n        ret = asn1_check_tlen(&len, NULL, NULL, &seq_eoc, &cst,\n                              &p, len, tag, aclass, opt, ctx);\n        if (!ret) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        } else if (ret == -1)\n            return -1;\n        if (aux && (aux->flags & ASN1_AFLG_BROKEN)) {\n            len = tmplen - (p - *in);\n            seq_nolen = 1;\n        }\n        /* If indefinite we don't do a length check */\n        else\n            seq_nolen = seq_eoc;\n        if (!cst) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_SEQUENCE_NOT_CONSTRUCTED);\n            goto err;\n        }\n\n        if (!*pval && !ASN1_item_ex_new(pval, it)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n            goto auxerr;\n\n        /* Get each field entry */\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            const ASN1_TEMPLATE *seqtt;\n            ASN1_VALUE **pseqval;\n            seqtt = asn1_do_adb(pval, tt, 1);\n            if (!seqtt)\n                goto err;\n            pseqval = asn1_get_field_ptr(pval, seqtt);\n            /* Have we ran out of data? */\n            if (!len)\n                break;\n            q = p;\n            if (asn1_check_eoc(&p, len)) {\n                if (!seq_eoc) {\n                    ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_UNEXPECTED_EOC);\n                    goto err;\n                }\n                len -= p - q;\n                seq_eoc = 0;\n                q = p;\n                break;\n            }\n            /*\n             * This determines the OPTIONAL flag value. The field cannot be\n             * omitted if it is the last of a SEQUENCE and there is still\n             * data to be read. This isn't strictly necessary but it\n             * increases efficiency in some cases.\n             */\n            if (i == (it->tcount - 1))\n                isopt = 0;\n            else\n                isopt = (char)(seqtt->flags & ASN1_TFLG_OPTIONAL);\n            /*\n             * attempt to read in field, allowing each to be OPTIONAL\n             */\n\n            ret = asn1_template_ex_d2i(pseqval, &p, len, seqtt, isopt, ctx);\n            if (!ret) {\n                errtt = seqtt;\n                goto err;\n            } else if (ret == -1) {\n                /*\n                 * OPTIONAL component absent. Free and zero the field.\n                 */\n                ASN1_template_free(pseqval, seqtt);\n                continue;\n            }\n            /* Update length */\n            len -= p - q;\n        }\n\n        /* Check for EOC if expecting one */\n        if (seq_eoc && !asn1_check_eoc(&p, len)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MISSING_EOC);\n            goto err;\n        }\n        /* Check all data read */\n        if (!seq_nolen && len) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_SEQUENCE_LENGTH_MISMATCH);\n            goto err;\n        }\n\n        /*\n         * If we get here we've got no more data in the SEQUENCE, however we\n         * may not have read all fields so check all remaining are OPTIONAL\n         * and clear any that are.\n         */\n        for (; i < it->tcount; tt++, i++) {\n            const ASN1_TEMPLATE *seqtt;\n            seqtt = asn1_do_adb(pval, tt, 1);\n            if (!seqtt)\n                goto err;\n            if (seqtt->flags & ASN1_TFLG_OPTIONAL) {\n                ASN1_VALUE **pseqval;\n                pseqval = asn1_get_field_ptr(pval, seqtt);\n                ASN1_template_free(pseqval, seqtt);\n            } else {\n                errtt = seqtt;\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_FIELD_MISSING);\n                goto err;\n            }\n        }\n        /* Save encoding */\n        if (!asn1_enc_save(pval, *in, p - *in, it))\n            goto auxerr;\n        *in = p;\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_POST, pval, it, NULL))\n            goto auxerr;\n        return 1;\n\n    default:\n        return 0;\n    }\n auxerr:\n    ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_AUX_ERROR);\n err:\n    ASN1_item_ex_free(pval, it);\n    if (errtt)\n        ERR_add_error_data(4, \"Field=\", errtt->field_name,\n                           \", Type=\", it->sname);\n    else\n        ERR_add_error_data(2, \"Type=\", it->sname);\n    return 0;\n}",
        "func": "int ASN1_item_ex_d2i(ASN1_VALUE **pval, const unsigned char **in, long len,\n                     const ASN1_ITEM *it,\n                     int tag, int aclass, char opt, ASN1_TLC *ctx)\n{\n    const ASN1_TEMPLATE *tt, *errtt = NULL;\n    const ASN1_COMPAT_FUNCS *cf;\n    const ASN1_EXTERN_FUNCS *ef;\n    const ASN1_AUX *aux = it->funcs;\n    ASN1_aux_cb *asn1_cb;\n    const unsigned char *p = NULL, *q;\n    unsigned char *wp = NULL;   /* BIG FAT WARNING! BREAKS CONST WHERE USED */\n    unsigned char imphack = 0, oclass;\n    char seq_eoc, seq_nolen, cst, isopt;\n    long tmplen;\n    int i;\n    int otag;\n    int ret = 0;\n    ASN1_VALUE **pchptr, *ptmpval;\n    if (!pval)\n        return 0;\n    if (aux && aux->asn1_cb)\n        asn1_cb = aux->asn1_cb;\n    else\n        asn1_cb = 0;\n\n    switch (it->itype) {\n    case ASN1_ITYPE_PRIMITIVE:\n        if (it->templates) {\n            /*\n             * tagging or OPTIONAL is currently illegal on an item template\n             * because the flags can't get passed down. In practice this\n             * isn't a problem: we include the relevant flags from the item\n             * template in the template itself.\n             */\n            if ((tag != -1) || opt) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I,\n                        ASN1_R_ILLEGAL_OPTIONS_ON_ITEM_TEMPLATE);\n                goto err;\n            }\n            return asn1_template_ex_d2i(pval, in, len,\n                                        it->templates, opt, ctx);\n        }\n        return asn1_d2i_ex_primitive(pval, in, len, it,\n                                     tag, aclass, opt, ctx);\n        break;\n\n    case ASN1_ITYPE_MSTRING:\n        p = *in;\n        /* Just read in tag and class */\n        ret = asn1_check_tlen(NULL, &otag, &oclass, NULL, NULL,\n                              &p, len, -1, 0, 1, ctx);\n        if (!ret) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        /* Must be UNIVERSAL class */\n        if (oclass != V_ASN1_UNIVERSAL) {\n            /* If OPTIONAL, assume this is OK */\n            if (opt)\n                return -1;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MSTRING_NOT_UNIVERSAL);\n            goto err;\n        }\n        /* Check tag matches bit map */\n        if (!(ASN1_tag2bit(otag) & it->utype)) {\n            /* If OPTIONAL, assume this is OK */\n            if (opt)\n                return -1;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MSTRING_WRONG_TAG);\n            goto err;\n        }\n        return asn1_d2i_ex_primitive(pval, in, len, it, otag, 0, 0, ctx);\n\n    case ASN1_ITYPE_EXTERN:\n        /* Use new style d2i */\n        ef = it->funcs;\n        return ef->asn1_ex_d2i(pval, in, len, it, tag, aclass, opt, ctx);\n\n    case ASN1_ITYPE_COMPAT:\n        /* we must resort to old style evil hackery */\n        cf = it->funcs;\n\n        /* If OPTIONAL see if it is there */\n        if (opt) {\n            int exptag;\n            p = *in;\n            if (tag == -1)\n                exptag = it->utype;\n            else\n                exptag = tag;\n            /*\n             * Don't care about anything other than presence of expected tag\n             */\n\n            ret = asn1_check_tlen(NULL, NULL, NULL, NULL, NULL,\n                                  &p, len, exptag, aclass, 1, ctx);\n            if (!ret) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n                goto err;\n            }\n            if (ret == -1)\n                return -1;\n        }\n\n        /*\n         * This is the old style evil hack IMPLICIT handling: since the\n         * underlying code is expecting a tag and class other than the one\n         * present we change the buffer temporarily then change it back\n         * afterwards. This doesn't and never did work for tags > 30. Yes\n         * this is *horrible* but it is only needed for old style d2i which\n         * will hopefully not be around for much longer. FIXME: should copy\n         * the buffer then modify it so the input buffer can be const: we\n         * should *always* copy because the old style d2i might modify the\n         * buffer.\n         */\n\n        if (tag != -1) {\n            wp = *(unsigned char **)in;\n            imphack = *wp;\n            if (p == NULL) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n                goto err;\n            }\n            *wp = (unsigned char)((*p & V_ASN1_CONSTRUCTED)\n                                  | it->utype);\n        }\n\n        ptmpval = cf->asn1_d2i(pval, in, len);\n\n        if (tag != -1)\n            *wp = imphack;\n\n        if (ptmpval)\n            return 1;\n\n        ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n        goto err;\n\n    case ASN1_ITYPE_CHOICE:\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n            goto auxerr;\n        if (*pval) {\n            /* Free up and zero CHOICE value if initialised */\n            i = asn1_get_choice_selector(pval, it);\n            if ((i >= 0) && (i < it->tcount)) {\n                tt = it->templates + i;\n                pchptr = asn1_get_field_ptr(pval, tt);\n                ASN1_template_free(pchptr, tt);\n                asn1_set_choice_selector(pval, -1, it);\n            }\n        } else if (!ASN1_item_ex_new(pval, it)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n        /* CHOICE type, try each possibility in turn */\n        p = *in;\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            pchptr = asn1_get_field_ptr(pval, tt);\n            /*\n             * We mark field as OPTIONAL so its absence can be recognised.\n             */\n            ret = asn1_template_ex_d2i(pchptr, &p, len, tt, 1, ctx);\n            /* If field not present, try the next one */\n            if (ret == -1)\n                continue;\n            /* If positive return, read OK, break loop */\n            if (ret > 0)\n                break;\n            /* Otherwise must be an ASN1 parsing error */\n            errtt = tt;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        /* Did we fall off the end without reading anything? */\n        if (i == it->tcount) {\n            /* If OPTIONAL, this is OK */\n            if (opt) {\n                /* Free and zero it */\n                ASN1_item_ex_free(pval, it);\n                return -1;\n            }\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_NO_MATCHING_CHOICE_TYPE);\n            goto err;\n        }\n\n        asn1_set_choice_selector(pval, i, it);\n        *in = p;\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_POST, pval, it, NULL))\n            goto auxerr;\n        return 1;\n\n    case ASN1_ITYPE_NDEF_SEQUENCE:\n    case ASN1_ITYPE_SEQUENCE:\n        p = *in;\n        tmplen = len;\n\n        /* If no IMPLICIT tagging set to SEQUENCE, UNIVERSAL */\n        if (tag == -1) {\n            tag = V_ASN1_SEQUENCE;\n            aclass = V_ASN1_UNIVERSAL;\n        }\n        /* Get SEQUENCE length and update len, p */\n        ret = asn1_check_tlen(&len, NULL, NULL, &seq_eoc, &cst,\n                              &p, len, tag, aclass, opt, ctx);\n        if (!ret) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        } else if (ret == -1)\n            return -1;\n        if (aux && (aux->flags & ASN1_AFLG_BROKEN)) {\n            len = tmplen - (p - *in);\n            seq_nolen = 1;\n        }\n        /* If indefinite we don't do a length check */\n        else\n            seq_nolen = seq_eoc;\n        if (!cst) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_SEQUENCE_NOT_CONSTRUCTED);\n            goto err;\n        }\n\n        if (!*pval && !ASN1_item_ex_new(pval, it)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n            goto auxerr;\n\n        /* Free up and zero any ADB found */\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            if (tt->flags & ASN1_TFLG_ADB_MASK) {\n                const ASN1_TEMPLATE *seqtt;\n                ASN1_VALUE **pseqval;\n                seqtt = asn1_do_adb(pval, tt, 1);\n                pseqval = asn1_get_field_ptr(pval, seqtt);\n                ASN1_template_free(pseqval, seqtt);\n            }\n        }\n\n        /* Get each field entry */\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            const ASN1_TEMPLATE *seqtt;\n            ASN1_VALUE **pseqval;\n            seqtt = asn1_do_adb(pval, tt, 1);\n            if (!seqtt)\n                goto err;\n            pseqval = asn1_get_field_ptr(pval, seqtt);\n            /* Have we ran out of data? */\n            if (!len)\n                break;\n            q = p;\n            if (asn1_check_eoc(&p, len)) {\n                if (!seq_eoc) {\n                    ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_UNEXPECTED_EOC);\n                    goto err;\n                }\n                len -= p - q;\n                seq_eoc = 0;\n                q = p;\n                break;\n            }\n            /*\n             * This determines the OPTIONAL flag value. The field cannot be\n             * omitted if it is the last of a SEQUENCE and there is still\n             * data to be read. This isn't strictly necessary but it\n             * increases efficiency in some cases.\n             */\n            if (i == (it->tcount - 1))\n                isopt = 0;\n            else\n                isopt = (char)(seqtt->flags & ASN1_TFLG_OPTIONAL);\n            /*\n             * attempt to read in field, allowing each to be OPTIONAL\n             */\n\n            ret = asn1_template_ex_d2i(pseqval, &p, len, seqtt, isopt, ctx);\n            if (!ret) {\n                errtt = seqtt;\n                goto err;\n            } else if (ret == -1) {\n                /*\n                 * OPTIONAL component absent. Free and zero the field.\n                 */\n                ASN1_template_free(pseqval, seqtt);\n                continue;\n            }\n            /* Update length */\n            len -= p - q;\n        }\n\n        /* Check for EOC if expecting one */\n        if (seq_eoc && !asn1_check_eoc(&p, len)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MISSING_EOC);\n            goto err;\n        }\n        /* Check all data read */\n        if (!seq_nolen && len) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_SEQUENCE_LENGTH_MISMATCH);\n            goto err;\n        }\n\n        /*\n         * If we get here we've got no more data in the SEQUENCE, however we\n         * may not have read all fields so check all remaining are OPTIONAL\n         * and clear any that are.\n         */\n        for (; i < it->tcount; tt++, i++) {\n            const ASN1_TEMPLATE *seqtt;\n            seqtt = asn1_do_adb(pval, tt, 1);\n            if (!seqtt)\n                goto err;\n            if (seqtt->flags & ASN1_TFLG_OPTIONAL) {\n                ASN1_VALUE **pseqval;\n                pseqval = asn1_get_field_ptr(pval, seqtt);\n                ASN1_template_free(pseqval, seqtt);\n            } else {\n                errtt = seqtt;\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_FIELD_MISSING);\n                goto err;\n            }\n        }\n        /* Save encoding */\n        if (!asn1_enc_save(pval, *in, p - *in, it))\n            goto auxerr;\n        *in = p;\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_POST, pval, it, NULL))\n            goto auxerr;\n        return 1;\n\n    default:\n        return 0;\n    }\n auxerr:\n    ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_AUX_ERROR);\n err:\n    ASN1_item_ex_free(pval, it);\n    if (errtt)\n        ERR_add_error_data(4, \"Field=\", errtt->field_name,\n                           \", Type=\", it->sname);\n    else\n        ERR_add_error_data(2, \"Type=\", it->sname);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -140,9 +140,16 @@\n     case ASN1_ITYPE_CHOICE:\n         if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n             goto auxerr;\n-\n-        /* Allocate structure */\n-        if (!*pval && !ASN1_item_ex_new(pval, it)) {\n+        if (*pval) {\n+            /* Free up and zero CHOICE value if initialised */\n+            i = asn1_get_choice_selector(pval, it);\n+            if ((i >= 0) && (i < it->tcount)) {\n+                tt = it->templates + i;\n+                pchptr = asn1_get_field_ptr(pval, tt);\n+                ASN1_template_free(pchptr, tt);\n+                asn1_set_choice_selector(pval, -1, it);\n+            }\n+        } else if (!ASN1_item_ex_new(pval, it)) {\n             ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n             goto err;\n         }\n@@ -221,6 +228,17 @@\n \n         if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n             goto auxerr;\n+\n+        /* Free up and zero any ADB found */\n+        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n+            if (tt->flags & ASN1_TFLG_ADB_MASK) {\n+                const ASN1_TEMPLATE *seqtt;\n+                ASN1_VALUE **pseqval;\n+                seqtt = asn1_do_adb(pval, tt, 1);\n+                pseqval = asn1_get_field_ptr(pval, seqtt);\n+                ASN1_template_free(pseqval, seqtt);\n+            }\n+        }\n \n         /* Get each field entry */\n         for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {",
        "diff_line_info": {
            "deleted_lines": [
                "",
                "        /* Allocate structure */",
                "        if (!*pval && !ASN1_item_ex_new(pval, it)) {"
            ],
            "added_lines": [
                "        if (*pval) {",
                "            /* Free up and zero CHOICE value if initialised */",
                "            i = asn1_get_choice_selector(pval, it);",
                "            if ((i >= 0) && (i < it->tcount)) {",
                "                tt = it->templates + i;",
                "                pchptr = asn1_get_field_ptr(pval, tt);",
                "                ASN1_template_free(pchptr, tt);",
                "                asn1_set_choice_selector(pval, -1, it);",
                "            }",
                "        } else if (!ASN1_item_ex_new(pval, it)) {",
                "",
                "        /* Free up and zero any ADB found */",
                "        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {",
                "            if (tt->flags & ASN1_TFLG_ADB_MASK) {",
                "                const ASN1_TEMPLATE *seqtt;",
                "                ASN1_VALUE **pseqval;",
                "                seqtt = asn1_do_adb(pval, tt, 1);",
                "                pseqval = asn1_get_field_ptr(pval, seqtt);",
                "                ASN1_template_free(pseqval, seqtt);",
                "            }",
                "        }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-0290",
        "func_name": "openssl/ssl3_write_bytes",
        "description": "The multi-block feature in the ssl3_write_bytes function in s3_pkt.c in OpenSSL 1.0.2 before 1.0.2a on 64-bit x86 platforms with AES NI support does not properly handle certain non-blocking I/O cases, which allows remote attackers to cause a denial of service (pointer corruption and application crash) via unspecified vectors.",
        "git_url": "https://git.openssl.org/?p=openssl.git;a=commit;h=77c77f0a1b9f15b869ca3342186dfbedd1119d0e",
        "commit_title": "",
        "commit_text": "Multiblock corrupted pointer fix  OpenSSL 1.0.2 introduced the \"multiblock\" performance improvement. This feature only applies on 64 bit x86 architecture platforms that support AES NI instructions. A defect in the implementation of \"multiblock\" can cause OpenSSL's internal write buffer to become incorrectly set to NULL when using non-blocking IO. Typically, when the user application is using a socket BIO for writing, this will only result in a failed connection. However if some other BIO is used then it is likely that a segmentation fault will be triggered, thus enabling a potential DoS attack.  CVE-2015-0290  ",
        "func_before": "int ssl3_write_bytes(SSL *s, int type, const void *buf_, int len)\n{\n    const unsigned char *buf = buf_;\n    int tot;\n    unsigned int n, nw;\n#if !defined(OPENSSL_NO_MULTIBLOCK) && EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK\n    unsigned int max_send_fragment;\n#endif\n    SSL3_BUFFER *wb = &(s->s3->wbuf);\n    int i;\n\n    s->rwstate = SSL_NOTHING;\n    OPENSSL_assert(s->s3->wnum <= INT_MAX);\n    tot = s->s3->wnum;\n    s->s3->wnum = 0;\n\n    if (SSL_in_init(s) && !s->in_handshake) {\n        i = s->handshake_func(s);\n        if (i < 0)\n            return (i);\n        if (i == 0) {\n            SSLerr(SSL_F_SSL3_WRITE_BYTES, SSL_R_SSL_HANDSHAKE_FAILURE);\n            return -1;\n        }\n    }\n\n    /*\n     * ensure that if we end up with a smaller value of data to write out\n     * than the the original len from a write which didn't complete for\n     * non-blocking I/O and also somehow ended up avoiding the check for\n     * this in ssl3_write_pending/SSL_R_BAD_WRITE_RETRY as it must never be\n     * possible to end up with (len-tot) as a large number that will then\n     * promptly send beyond the end of the users buffer ... so we trap and\n     * report the error in a way the user will notice\n     */\n    if (len < tot) {\n        SSLerr(SSL_F_SSL3_WRITE_BYTES, SSL_R_BAD_LENGTH);\n        return (-1);\n    }\n\n    /*\n     * first check if there is a SSL3_BUFFER still being written out.  This\n     * will happen with non blocking IO\n     */\n    if (wb->left != 0) {\n        i = ssl3_write_pending(s, type, &buf[tot], s->s3->wpend_tot);\n        if (i <= 0) {\n            /* XXX should we ssl3_release_write_buffer if i<0? */\n            s->s3->wnum = tot;\n            return i;\n        }\n        tot += i;               /* this might be last fragment */\n    }\n#if !defined(OPENSSL_NO_MULTIBLOCK) && EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK\n    /*\n     * Depending on platform multi-block can deliver several *times*\n     * better performance. Downside is that it has to allocate\n     * jumbo buffer to accomodate up to 8 records, but the\n     * compromise is considered worthy.\n     */\n    if (type == SSL3_RT_APPLICATION_DATA &&\n        len >= 4 * (int)(max_send_fragment = s->max_send_fragment) &&\n        s->compress == NULL && s->msg_callback == NULL &&\n        SSL_USE_EXPLICIT_IV(s) &&\n        EVP_CIPHER_flags(s->enc_write_ctx->cipher) &\n        EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK) {\n        unsigned char aad[13];\n        EVP_CTRL_TLS1_1_MULTIBLOCK_PARAM mb_param;\n        int packlen;\n\n        /* minimize address aliasing conflicts */\n        if ((max_send_fragment & 0xfff) == 0)\n            max_send_fragment -= 512;\n\n        if (tot == 0 || wb->buf == NULL) { /* allocate jumbo buffer */\n            ssl3_release_write_buffer(s);\n\n            packlen = EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                          EVP_CTRL_TLS1_1_MULTIBLOCK_MAX_BUFSIZE,\n                                          max_send_fragment, NULL);\n\n            if (len >= 8 * (int)max_send_fragment)\n                packlen *= 8;\n            else\n                packlen *= 4;\n\n            wb->buf = OPENSSL_malloc(packlen);\n            if(!wb->buf) {\n                SSLerr(SSL_F_SSL3_WRITE_BYTES, ERR_R_MALLOC_FAILURE);\n                return -1;\n            }\n            wb->len = packlen;\n        } else if (tot == len) { /* done? */\n            OPENSSL_free(wb->buf); /* free jumbo buffer */\n            wb->buf = NULL;\n            return tot;\n        }\n\n        n = (len - tot);\n        for (;;) {\n            if (n < 4 * max_send_fragment) {\n                OPENSSL_free(wb->buf); /* free jumbo buffer */\n                wb->buf = NULL;\n                break;\n            }\n\n            if (s->s3->alert_dispatch) {\n                i = s->method->ssl_dispatch_alert(s);\n                if (i <= 0) {\n                    s->s3->wnum = tot;\n                    return i;\n                }\n            }\n\n            if (n >= 8 * max_send_fragment)\n                nw = max_send_fragment * (mb_param.interleave = 8);\n            else\n                nw = max_send_fragment * (mb_param.interleave = 4);\n\n            memcpy(aad, s->s3->write_sequence, 8);\n            aad[8] = type;\n            aad[9] = (unsigned char)(s->version >> 8);\n            aad[10] = (unsigned char)(s->version);\n            aad[11] = 0;\n            aad[12] = 0;\n            mb_param.out = NULL;\n            mb_param.inp = aad;\n            mb_param.len = nw;\n\n            packlen = EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                          EVP_CTRL_TLS1_1_MULTIBLOCK_AAD,\n                                          sizeof(mb_param), &mb_param);\n\n            if (packlen <= 0 || packlen > (int)wb->len) { /* never happens */\n                OPENSSL_free(wb->buf); /* free jumbo buffer */\n                wb->buf = NULL;\n                break;\n            }\n\n            mb_param.out = wb->buf;\n            mb_param.inp = &buf[tot];\n            mb_param.len = nw;\n\n            if (EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                    EVP_CTRL_TLS1_1_MULTIBLOCK_ENCRYPT,\n                                    sizeof(mb_param), &mb_param) <= 0)\n                return -1;\n\n            s->s3->write_sequence[7] += mb_param.interleave;\n            if (s->s3->write_sequence[7] < mb_param.interleave) {\n                int j = 6;\n                while (j >= 0 && (++s->s3->write_sequence[j--]) == 0) ;\n            }\n\n            wb->offset = 0;\n            wb->left = packlen;\n\n            s->s3->wpend_tot = nw;\n            s->s3->wpend_buf = &buf[tot];\n            s->s3->wpend_type = type;\n            s->s3->wpend_ret = nw;\n\n            i = ssl3_write_pending(s, type, &buf[tot], nw);\n            if (i <= 0) {\n                if (i < 0) {\n                    OPENSSL_free(wb->buf);\n                    wb->buf = NULL;\n                }\n                s->s3->wnum = tot;\n                return i;\n            }\n            if (i == (int)n) {\n                OPENSSL_free(wb->buf); /* free jumbo buffer */\n                wb->buf = NULL;\n                return tot + i;\n            }\n            n -= i;\n            tot += i;\n        }\n    } else\n#endif\n    if (tot == len) {           /* done? */\n        if (s->mode & SSL_MODE_RELEASE_BUFFERS && !SSL_IS_DTLS(s))\n            ssl3_release_write_buffer(s);\n\n        return tot;\n    }\n\n    n = (len - tot);\n    for (;;) {\n        if (n > s->max_send_fragment)\n            nw = s->max_send_fragment;\n        else\n            nw = n;\n\n        i = do_ssl3_write(s, type, &(buf[tot]), nw, 0);\n        if (i <= 0) {\n            /* XXX should we ssl3_release_write_buffer if i<0? */\n            s->s3->wnum = tot;\n            return i;\n        }\n\n        if ((i == (int)n) ||\n            (type == SSL3_RT_APPLICATION_DATA &&\n             (s->mode & SSL_MODE_ENABLE_PARTIAL_WRITE))) {\n            /*\n             * next chunk of data should get another prepended empty fragment\n             * in ciphersuites with known-IV weakness:\n             */\n            s->s3->empty_fragment_done = 0;\n\n            if ((i == (int)n) && s->mode & SSL_MODE_RELEASE_BUFFERS &&\n                !SSL_IS_DTLS(s))\n                ssl3_release_write_buffer(s);\n\n            return tot + i;\n        }\n\n        n -= i;\n        tot += i;\n    }\n}",
        "func": "int ssl3_write_bytes(SSL *s, int type, const void *buf_, int len)\n{\n    const unsigned char *buf = buf_;\n    int tot;\n    unsigned int n, nw;\n#if !defined(OPENSSL_NO_MULTIBLOCK) && EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK\n    unsigned int max_send_fragment;\n#endif\n    SSL3_BUFFER *wb = &(s->s3->wbuf);\n    int i;\n\n    s->rwstate = SSL_NOTHING;\n    OPENSSL_assert(s->s3->wnum <= INT_MAX);\n    tot = s->s3->wnum;\n    s->s3->wnum = 0;\n\n    if (SSL_in_init(s) && !s->in_handshake) {\n        i = s->handshake_func(s);\n        if (i < 0)\n            return (i);\n        if (i == 0) {\n            SSLerr(SSL_F_SSL3_WRITE_BYTES, SSL_R_SSL_HANDSHAKE_FAILURE);\n            return -1;\n        }\n    }\n\n    /*\n     * ensure that if we end up with a smaller value of data to write out\n     * than the the original len from a write which didn't complete for\n     * non-blocking I/O and also somehow ended up avoiding the check for\n     * this in ssl3_write_pending/SSL_R_BAD_WRITE_RETRY as it must never be\n     * possible to end up with (len-tot) as a large number that will then\n     * promptly send beyond the end of the users buffer ... so we trap and\n     * report the error in a way the user will notice\n     */\n    if (len < tot) {\n        SSLerr(SSL_F_SSL3_WRITE_BYTES, SSL_R_BAD_LENGTH);\n        return (-1);\n    }\n\n    /*\n     * first check if there is a SSL3_BUFFER still being written out.  This\n     * will happen with non blocking IO\n     */\n    if (wb->left != 0) {\n        i = ssl3_write_pending(s, type, &buf[tot], s->s3->wpend_tot);\n        if (i <= 0) {\n            /* XXX should we ssl3_release_write_buffer if i<0? */\n            s->s3->wnum = tot;\n            return i;\n        }\n        tot += i;               /* this might be last fragment */\n    }\n#if !defined(OPENSSL_NO_MULTIBLOCK) && EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK\n    /*\n     * Depending on platform multi-block can deliver several *times*\n     * better performance. Downside is that it has to allocate\n     * jumbo buffer to accomodate up to 8 records, but the\n     * compromise is considered worthy.\n     */\n    if (type == SSL3_RT_APPLICATION_DATA &&\n        len >= 4 * (int)(max_send_fragment = s->max_send_fragment) &&\n        s->compress == NULL && s->msg_callback == NULL &&\n        SSL_USE_EXPLICIT_IV(s) &&\n        EVP_CIPHER_flags(s->enc_write_ctx->cipher) &\n        EVP_CIPH_FLAG_TLS1_1_MULTIBLOCK) {\n        unsigned char aad[13];\n        EVP_CTRL_TLS1_1_MULTIBLOCK_PARAM mb_param;\n        int packlen;\n\n        /* minimize address aliasing conflicts */\n        if ((max_send_fragment & 0xfff) == 0)\n            max_send_fragment -= 512;\n\n        if (tot == 0 || wb->buf == NULL) { /* allocate jumbo buffer */\n            ssl3_release_write_buffer(s);\n\n            packlen = EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                          EVP_CTRL_TLS1_1_MULTIBLOCK_MAX_BUFSIZE,\n                                          max_send_fragment, NULL);\n\n            if (len >= 8 * (int)max_send_fragment)\n                packlen *= 8;\n            else\n                packlen *= 4;\n\n            wb->buf = OPENSSL_malloc(packlen);\n            if(!wb->buf) {\n                SSLerr(SSL_F_SSL3_WRITE_BYTES, ERR_R_MALLOC_FAILURE);\n                return -1;\n            }\n            wb->len = packlen;\n        } else if (tot == len) { /* done? */\n            OPENSSL_free(wb->buf); /* free jumbo buffer */\n            wb->buf = NULL;\n            return tot;\n        }\n\n        n = (len - tot);\n        for (;;) {\n            if (n < 4 * max_send_fragment) {\n                OPENSSL_free(wb->buf); /* free jumbo buffer */\n                wb->buf = NULL;\n                break;\n            }\n\n            if (s->s3->alert_dispatch) {\n                i = s->method->ssl_dispatch_alert(s);\n                if (i <= 0) {\n                    s->s3->wnum = tot;\n                    return i;\n                }\n            }\n\n            if (n >= 8 * max_send_fragment)\n                nw = max_send_fragment * (mb_param.interleave = 8);\n            else\n                nw = max_send_fragment * (mb_param.interleave = 4);\n\n            memcpy(aad, s->s3->write_sequence, 8);\n            aad[8] = type;\n            aad[9] = (unsigned char)(s->version >> 8);\n            aad[10] = (unsigned char)(s->version);\n            aad[11] = 0;\n            aad[12] = 0;\n            mb_param.out = NULL;\n            mb_param.inp = aad;\n            mb_param.len = nw;\n\n            packlen = EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                          EVP_CTRL_TLS1_1_MULTIBLOCK_AAD,\n                                          sizeof(mb_param), &mb_param);\n\n            if (packlen <= 0 || packlen > (int)wb->len) { /* never happens */\n                OPENSSL_free(wb->buf); /* free jumbo buffer */\n                wb->buf = NULL;\n                break;\n            }\n\n            mb_param.out = wb->buf;\n            mb_param.inp = &buf[tot];\n            mb_param.len = nw;\n\n            if (EVP_CIPHER_CTX_ctrl(s->enc_write_ctx,\n                                    EVP_CTRL_TLS1_1_MULTIBLOCK_ENCRYPT,\n                                    sizeof(mb_param), &mb_param) <= 0)\n                return -1;\n\n            s->s3->write_sequence[7] += mb_param.interleave;\n            if (s->s3->write_sequence[7] < mb_param.interleave) {\n                int j = 6;\n                while (j >= 0 && (++s->s3->write_sequence[j--]) == 0) ;\n            }\n\n            wb->offset = 0;\n            wb->left = packlen;\n\n            s->s3->wpend_tot = nw;\n            s->s3->wpend_buf = &buf[tot];\n            s->s3->wpend_type = type;\n            s->s3->wpend_ret = nw;\n\n            i = ssl3_write_pending(s, type, &buf[tot], nw);\n            if (i <= 0) {\n                if (i < 0 && (!s->wbio || !BIO_should_retry(s->wbio))) {\n                    OPENSSL_free(wb->buf);\n                    wb->buf = NULL;\n                }\n                s->s3->wnum = tot;\n                return i;\n            }\n            if (i == (int)n) {\n                OPENSSL_free(wb->buf); /* free jumbo buffer */\n                wb->buf = NULL;\n                return tot + i;\n            }\n            n -= i;\n            tot += i;\n        }\n    } else\n#endif\n    if (tot == len) {           /* done? */\n        if (s->mode & SSL_MODE_RELEASE_BUFFERS && !SSL_IS_DTLS(s))\n            ssl3_release_write_buffer(s);\n\n        return tot;\n    }\n\n    n = (len - tot);\n    for (;;) {\n        if (n > s->max_send_fragment)\n            nw = s->max_send_fragment;\n        else\n            nw = n;\n\n        i = do_ssl3_write(s, type, &(buf[tot]), nw, 0);\n        if (i <= 0) {\n            /* XXX should we ssl3_release_write_buffer if i<0? */\n            s->s3->wnum = tot;\n            return i;\n        }\n\n        if ((i == (int)n) ||\n            (type == SSL3_RT_APPLICATION_DATA &&\n             (s->mode & SSL_MODE_ENABLE_PARTIAL_WRITE))) {\n            /*\n             * next chunk of data should get another prepended empty fragment\n             * in ciphersuites with known-IV weakness:\n             */\n            s->s3->empty_fragment_done = 0;\n\n            if ((i == (int)n) && s->mode & SSL_MODE_RELEASE_BUFFERS &&\n                !SSL_IS_DTLS(s))\n                ssl3_release_write_buffer(s);\n\n            return tot + i;\n        }\n\n        n -= i;\n        tot += i;\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -162,7 +162,7 @@\n \n             i = ssl3_write_pending(s, type, &buf[tot], nw);\n             if (i <= 0) {\n-                if (i < 0) {\n+                if (i < 0 && (!s->wbio || !BIO_should_retry(s->wbio))) {\n                     OPENSSL_free(wb->buf);\n                     wb->buf = NULL;\n                 }",
        "diff_line_info": {
            "deleted_lines": [
                "                if (i < 0) {"
            ],
            "added_lines": [
                "                if (i < 0 && (!s->wbio || !BIO_should_retry(s->wbio))) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1465",
        "func_name": "torvalds/linux/ip_forward",
        "description": "The IPv4 implementation in the Linux kernel before 3.18.8 does not properly consider the length of the Read-Copy Update (RCU) grace period for redirecting lookups in the absence of caching, which allows remote attackers to cause a denial of service (memory consumption or system crash) via a flood of packets.",
        "git_url": "https://github.com/torvalds/linux/commit/df4d92549f23e1c037e83323aff58a21b3de7fe0",
        "commit_title": "ipv4: try to cache dst_entries which would cause a redirect",
        "commit_text": " Not caching dst_entries which cause redirects could be exploited by hosts on the same subnet, causing a severe DoS attack. This effect aggravated since commit f88649721268999 (\"ipv4: fix dst race in sk_dst_get()\").  Lookups causing redirects will be allocated with DST_NOCACHE set which will force dst_release to free them via RCU.  Unfortunately waiting for RCU grace period just takes too long, we can end up with >1M dst_entries waiting to be released and the system will run OOM. rcuos threads cannot catch up under high softirq load.  Attaching the flag to emit a redirect later on to the specific skb allows us to cache those dst_entries thus reducing the pressure on allocation and deallocation.  This issue was discovered by Marcelo Leitner.  Cc: Julian Anastasov <ja@ssi.bg>",
        "func_before": "int ip_forward(struct sk_buff *skb)\n{\n\tu32 mtu;\n\tstruct iphdr *iph;\t/* Our header */\n\tstruct rtable *rt;\t/* Route we use */\n\tstruct ip_options *opt\t= &(IPCB(skb)->opt);\n\n\t/* that should never happen */\n\tif (skb->pkt_type != PACKET_HOST)\n\t\tgoto drop;\n\n\tif (skb_warn_if_lro(skb))\n\t\tgoto drop;\n\n\tif (!xfrm4_policy_check(NULL, XFRM_POLICY_FWD, skb))\n\t\tgoto drop;\n\n\tif (IPCB(skb)->opt.router_alert && ip_call_ra_chain(skb))\n\t\treturn NET_RX_SUCCESS;\n\n\tskb_forward_csum(skb);\n\n\t/*\n\t *\tAccording to the RFC, we must first decrease the TTL field. If\n\t *\tthat reaches zero, we must reply an ICMP control message telling\n\t *\tthat the packet's lifetime expired.\n\t */\n\tif (ip_hdr(skb)->ttl <= 1)\n\t\tgoto too_many_hops;\n\n\tif (!xfrm4_route_forward(skb))\n\t\tgoto drop;\n\n\trt = skb_rtable(skb);\n\n\tif (opt->is_strictroute && rt->rt_uses_gateway)\n\t\tgoto sr_failed;\n\n\tIPCB(skb)->flags |= IPSKB_FORWARDED;\n\tmtu = ip_dst_mtu_maybe_forward(&rt->dst, true);\n\tif (!ip_may_fragment(skb) && ip_exceeds_mtu(skb, mtu)) {\n\t\tIP_INC_STATS(dev_net(rt->dst.dev), IPSTATS_MIB_FRAGFAILS);\n\t\ticmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,\n\t\t\t  htonl(mtu));\n\t\tgoto drop;\n\t}\n\n\t/* We are about to mangle packet. Copy it! */\n\tif (skb_cow(skb, LL_RESERVED_SPACE(rt->dst.dev)+rt->dst.header_len))\n\t\tgoto drop;\n\tiph = ip_hdr(skb);\n\n\t/* Decrease ttl after skb cow done */\n\tip_decrease_ttl(iph);\n\n\t/*\n\t *\tWe now generate an ICMP HOST REDIRECT giving the route\n\t *\twe calculated.\n\t */\n\tif (rt->rt_flags&RTCF_DOREDIRECT && !opt->srr && !skb_sec_path(skb))\n\t\tip_rt_send_redirect(skb);\n\n\tskb->priority = rt_tos2priority(iph->tos);\n\n\treturn NF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD, skb, skb->dev,\n\t\t       rt->dst.dev, ip_forward_finish);\n\nsr_failed:\n\t/*\n\t *\tStrict routing permits no gatewaying\n\t */\n\t icmp_send(skb, ICMP_DEST_UNREACH, ICMP_SR_FAILED, 0);\n\t goto drop;\n\ntoo_many_hops:\n\t/* Tell the sender its packet died... */\n\tIP_INC_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_INHDRERRORS);\n\ticmp_send(skb, ICMP_TIME_EXCEEDED, ICMP_EXC_TTL, 0);\ndrop:\n\tkfree_skb(skb);\n\treturn NET_RX_DROP;\n}",
        "func": "int ip_forward(struct sk_buff *skb)\n{\n\tu32 mtu;\n\tstruct iphdr *iph;\t/* Our header */\n\tstruct rtable *rt;\t/* Route we use */\n\tstruct ip_options *opt\t= &(IPCB(skb)->opt);\n\n\t/* that should never happen */\n\tif (skb->pkt_type != PACKET_HOST)\n\t\tgoto drop;\n\n\tif (skb_warn_if_lro(skb))\n\t\tgoto drop;\n\n\tif (!xfrm4_policy_check(NULL, XFRM_POLICY_FWD, skb))\n\t\tgoto drop;\n\n\tif (IPCB(skb)->opt.router_alert && ip_call_ra_chain(skb))\n\t\treturn NET_RX_SUCCESS;\n\n\tskb_forward_csum(skb);\n\n\t/*\n\t *\tAccording to the RFC, we must first decrease the TTL field. If\n\t *\tthat reaches zero, we must reply an ICMP control message telling\n\t *\tthat the packet's lifetime expired.\n\t */\n\tif (ip_hdr(skb)->ttl <= 1)\n\t\tgoto too_many_hops;\n\n\tif (!xfrm4_route_forward(skb))\n\t\tgoto drop;\n\n\trt = skb_rtable(skb);\n\n\tif (opt->is_strictroute && rt->rt_uses_gateway)\n\t\tgoto sr_failed;\n\n\tIPCB(skb)->flags |= IPSKB_FORWARDED;\n\tmtu = ip_dst_mtu_maybe_forward(&rt->dst, true);\n\tif (!ip_may_fragment(skb) && ip_exceeds_mtu(skb, mtu)) {\n\t\tIP_INC_STATS(dev_net(rt->dst.dev), IPSTATS_MIB_FRAGFAILS);\n\t\ticmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED,\n\t\t\t  htonl(mtu));\n\t\tgoto drop;\n\t}\n\n\t/* We are about to mangle packet. Copy it! */\n\tif (skb_cow(skb, LL_RESERVED_SPACE(rt->dst.dev)+rt->dst.header_len))\n\t\tgoto drop;\n\tiph = ip_hdr(skb);\n\n\t/* Decrease ttl after skb cow done */\n\tip_decrease_ttl(iph);\n\n\t/*\n\t *\tWe now generate an ICMP HOST REDIRECT giving the route\n\t *\twe calculated.\n\t */\n\tif (IPCB(skb)->flags & IPSKB_DOREDIRECT && !opt->srr &&\n\t    !skb_sec_path(skb))\n\t\tip_rt_send_redirect(skb);\n\n\tskb->priority = rt_tos2priority(iph->tos);\n\n\treturn NF_HOOK(NFPROTO_IPV4, NF_INET_FORWARD, skb, skb->dev,\n\t\t       rt->dst.dev, ip_forward_finish);\n\nsr_failed:\n\t/*\n\t *\tStrict routing permits no gatewaying\n\t */\n\t icmp_send(skb, ICMP_DEST_UNREACH, ICMP_SR_FAILED, 0);\n\t goto drop;\n\ntoo_many_hops:\n\t/* Tell the sender its packet died... */\n\tIP_INC_STATS_BH(dev_net(skb_dst(skb)->dev), IPSTATS_MIB_INHDRERRORS);\n\ticmp_send(skb, ICMP_TIME_EXCEEDED, ICMP_EXC_TTL, 0);\ndrop:\n\tkfree_skb(skb);\n\treturn NET_RX_DROP;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -57,7 +57,8 @@\n \t *\tWe now generate an ICMP HOST REDIRECT giving the route\n \t *\twe calculated.\n \t */\n-\tif (rt->rt_flags&RTCF_DOREDIRECT && !opt->srr && !skb_sec_path(skb))\n+\tif (IPCB(skb)->flags & IPSKB_DOREDIRECT && !opt->srr &&\n+\t    !skb_sec_path(skb))\n \t\tip_rt_send_redirect(skb);\n \n \tskb->priority = rt_tos2priority(iph->tos);",
        "diff_line_info": {
            "deleted_lines": [
                "\tif (rt->rt_flags&RTCF_DOREDIRECT && !opt->srr && !skb_sec_path(skb))"
            ],
            "added_lines": [
                "\tif (IPCB(skb)->flags & IPSKB_DOREDIRECT && !opt->srr &&",
                "\t    !skb_sec_path(skb))"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1465",
        "func_name": "torvalds/linux/rt_fill_info",
        "description": "The IPv4 implementation in the Linux kernel before 3.18.8 does not properly consider the length of the Read-Copy Update (RCU) grace period for redirecting lookups in the absence of caching, which allows remote attackers to cause a denial of service (memory consumption or system crash) via a flood of packets.",
        "git_url": "https://github.com/torvalds/linux/commit/df4d92549f23e1c037e83323aff58a21b3de7fe0",
        "commit_title": "ipv4: try to cache dst_entries which would cause a redirect",
        "commit_text": " Not caching dst_entries which cause redirects could be exploited by hosts on the same subnet, causing a severe DoS attack. This effect aggravated since commit f88649721268999 (\"ipv4: fix dst race in sk_dst_get()\").  Lookups causing redirects will be allocated with DST_NOCACHE set which will force dst_release to free them via RCU.  Unfortunately waiting for RCU grace period just takes too long, we can end up with >1M dst_entries waiting to be released and the system will run OOM. rcuos threads cannot catch up under high softirq load.  Attaching the flag to emit a redirect later on to the specific skb allows us to cache those dst_entries thus reducing the pressure on allocation and deallocation.  This issue was discovered by Marcelo Leitner.  Cc: Julian Anastasov <ja@ssi.bg>",
        "func_before": "static int rt_fill_info(struct net *net,  __be32 dst, __be32 src,\n\t\t\tstruct flowi4 *fl4, struct sk_buff *skb, u32 portid,\n\t\t\tu32 seq, int event, int nowait, unsigned int flags)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct rtmsg *r;\n\tstruct nlmsghdr *nlh;\n\tunsigned long expires = 0;\n\tu32 error;\n\tu32 metrics[RTAX_MAX];\n\n\tnlh = nlmsg_put(skb, portid, seq, event, sizeof(*r), flags);\n\tif (nlh == NULL)\n\t\treturn -EMSGSIZE;\n\n\tr = nlmsg_data(nlh);\n\tr->rtm_family\t = AF_INET;\n\tr->rtm_dst_len\t= 32;\n\tr->rtm_src_len\t= 0;\n\tr->rtm_tos\t= fl4->flowi4_tos;\n\tr->rtm_table\t= RT_TABLE_MAIN;\n\tif (nla_put_u32(skb, RTA_TABLE, RT_TABLE_MAIN))\n\t\tgoto nla_put_failure;\n\tr->rtm_type\t= rt->rt_type;\n\tr->rtm_scope\t= RT_SCOPE_UNIVERSE;\n\tr->rtm_protocol = RTPROT_UNSPEC;\n\tr->rtm_flags\t= (rt->rt_flags & ~0xFFFF) | RTM_F_CLONED;\n\tif (rt->rt_flags & RTCF_NOTIFY)\n\t\tr->rtm_flags |= RTM_F_NOTIFY;\n\n\tif (nla_put_be32(skb, RTA_DST, dst))\n\t\tgoto nla_put_failure;\n\tif (src) {\n\t\tr->rtm_src_len = 32;\n\t\tif (nla_put_be32(skb, RTA_SRC, src))\n\t\t\tgoto nla_put_failure;\n\t}\n\tif (rt->dst.dev &&\n\t    nla_put_u32(skb, RTA_OIF, rt->dst.dev->ifindex))\n\t\tgoto nla_put_failure;\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\tif (rt->dst.tclassid &&\n\t    nla_put_u32(skb, RTA_FLOW, rt->dst.tclassid))\n\t\tgoto nla_put_failure;\n#endif\n\tif (!rt_is_input_route(rt) &&\n\t    fl4->saddr != src) {\n\t\tif (nla_put_be32(skb, RTA_PREFSRC, fl4->saddr))\n\t\t\tgoto nla_put_failure;\n\t}\n\tif (rt->rt_uses_gateway &&\n\t    nla_put_be32(skb, RTA_GATEWAY, rt->rt_gateway))\n\t\tgoto nla_put_failure;\n\n\texpires = rt->dst.expires;\n\tif (expires) {\n\t\tunsigned long now = jiffies;\n\n\t\tif (time_before(now, expires))\n\t\t\texpires -= now;\n\t\telse\n\t\t\texpires = 0;\n\t}\n\n\tmemcpy(metrics, dst_metrics_ptr(&rt->dst), sizeof(metrics));\n\tif (rt->rt_pmtu && expires)\n\t\tmetrics[RTAX_MTU - 1] = rt->rt_pmtu;\n\tif (rtnetlink_put_metrics(skb, metrics) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (fl4->flowi4_mark &&\n\t    nla_put_u32(skb, RTA_MARK, fl4->flowi4_mark))\n\t\tgoto nla_put_failure;\n\n\terror = rt->dst.error;\n\n\tif (rt_is_input_route(rt)) {\n#ifdef CONFIG_IP_MROUTE\n\t\tif (ipv4_is_multicast(dst) && !ipv4_is_local_multicast(dst) &&\n\t\t    IPV4_DEVCONF_ALL(net, MC_FORWARDING)) {\n\t\t\tint err = ipmr_get_route(net, skb,\n\t\t\t\t\t\t fl4->saddr, fl4->daddr,\n\t\t\t\t\t\t r, nowait);\n\t\t\tif (err <= 0) {\n\t\t\t\tif (!nowait) {\n\t\t\t\t\tif (err == 0)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t} else {\n\t\t\t\t\tif (err == -EMSGSIZE)\n\t\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t\terror = err;\n\t\t\t\t}\n\t\t\t}\n\t\t} else\n#endif\n\t\t\tif (nla_put_u32(skb, RTA_IIF, skb->dev->ifindex))\n\t\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (rtnl_put_cacheinfo(skb, &rt->dst, 0, expires, error) < 0)\n\t\tgoto nla_put_failure;\n\n\treturn nlmsg_end(skb, nlh);\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "func": "static int rt_fill_info(struct net *net,  __be32 dst, __be32 src,\n\t\t\tstruct flowi4 *fl4, struct sk_buff *skb, u32 portid,\n\t\t\tu32 seq, int event, int nowait, unsigned int flags)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct rtmsg *r;\n\tstruct nlmsghdr *nlh;\n\tunsigned long expires = 0;\n\tu32 error;\n\tu32 metrics[RTAX_MAX];\n\n\tnlh = nlmsg_put(skb, portid, seq, event, sizeof(*r), flags);\n\tif (nlh == NULL)\n\t\treturn -EMSGSIZE;\n\n\tr = nlmsg_data(nlh);\n\tr->rtm_family\t = AF_INET;\n\tr->rtm_dst_len\t= 32;\n\tr->rtm_src_len\t= 0;\n\tr->rtm_tos\t= fl4->flowi4_tos;\n\tr->rtm_table\t= RT_TABLE_MAIN;\n\tif (nla_put_u32(skb, RTA_TABLE, RT_TABLE_MAIN))\n\t\tgoto nla_put_failure;\n\tr->rtm_type\t= rt->rt_type;\n\tr->rtm_scope\t= RT_SCOPE_UNIVERSE;\n\tr->rtm_protocol = RTPROT_UNSPEC;\n\tr->rtm_flags\t= (rt->rt_flags & ~0xFFFF) | RTM_F_CLONED;\n\tif (rt->rt_flags & RTCF_NOTIFY)\n\t\tr->rtm_flags |= RTM_F_NOTIFY;\n\tif (IPCB(skb)->flags & IPSKB_DOREDIRECT)\n\t\tr->rtm_flags |= RTCF_DOREDIRECT;\n\n\tif (nla_put_be32(skb, RTA_DST, dst))\n\t\tgoto nla_put_failure;\n\tif (src) {\n\t\tr->rtm_src_len = 32;\n\t\tif (nla_put_be32(skb, RTA_SRC, src))\n\t\t\tgoto nla_put_failure;\n\t}\n\tif (rt->dst.dev &&\n\t    nla_put_u32(skb, RTA_OIF, rt->dst.dev->ifindex))\n\t\tgoto nla_put_failure;\n#ifdef CONFIG_IP_ROUTE_CLASSID\n\tif (rt->dst.tclassid &&\n\t    nla_put_u32(skb, RTA_FLOW, rt->dst.tclassid))\n\t\tgoto nla_put_failure;\n#endif\n\tif (!rt_is_input_route(rt) &&\n\t    fl4->saddr != src) {\n\t\tif (nla_put_be32(skb, RTA_PREFSRC, fl4->saddr))\n\t\t\tgoto nla_put_failure;\n\t}\n\tif (rt->rt_uses_gateway &&\n\t    nla_put_be32(skb, RTA_GATEWAY, rt->rt_gateway))\n\t\tgoto nla_put_failure;\n\n\texpires = rt->dst.expires;\n\tif (expires) {\n\t\tunsigned long now = jiffies;\n\n\t\tif (time_before(now, expires))\n\t\t\texpires -= now;\n\t\telse\n\t\t\texpires = 0;\n\t}\n\n\tmemcpy(metrics, dst_metrics_ptr(&rt->dst), sizeof(metrics));\n\tif (rt->rt_pmtu && expires)\n\t\tmetrics[RTAX_MTU - 1] = rt->rt_pmtu;\n\tif (rtnetlink_put_metrics(skb, metrics) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (fl4->flowi4_mark &&\n\t    nla_put_u32(skb, RTA_MARK, fl4->flowi4_mark))\n\t\tgoto nla_put_failure;\n\n\terror = rt->dst.error;\n\n\tif (rt_is_input_route(rt)) {\n#ifdef CONFIG_IP_MROUTE\n\t\tif (ipv4_is_multicast(dst) && !ipv4_is_local_multicast(dst) &&\n\t\t    IPV4_DEVCONF_ALL(net, MC_FORWARDING)) {\n\t\t\tint err = ipmr_get_route(net, skb,\n\t\t\t\t\t\t fl4->saddr, fl4->daddr,\n\t\t\t\t\t\t r, nowait);\n\t\t\tif (err <= 0) {\n\t\t\t\tif (!nowait) {\n\t\t\t\t\tif (err == 0)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t} else {\n\t\t\t\t\tif (err == -EMSGSIZE)\n\t\t\t\t\t\tgoto nla_put_failure;\n\t\t\t\t\terror = err;\n\t\t\t\t}\n\t\t\t}\n\t\t} else\n#endif\n\t\t\tif (nla_put_u32(skb, RTA_IIF, skb->dev->ifindex))\n\t\t\t\tgoto nla_put_failure;\n\t}\n\n\tif (rtnl_put_cacheinfo(skb, &rt->dst, 0, expires, error) < 0)\n\t\tgoto nla_put_failure;\n\n\treturn nlmsg_end(skb, nlh);\n\nnla_put_failure:\n\tnlmsg_cancel(skb, nlh);\n\treturn -EMSGSIZE;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,6 +27,8 @@\n \tr->rtm_flags\t= (rt->rt_flags & ~0xFFFF) | RTM_F_CLONED;\n \tif (rt->rt_flags & RTCF_NOTIFY)\n \t\tr->rtm_flags |= RTM_F_NOTIFY;\n+\tif (IPCB(skb)->flags & IPSKB_DOREDIRECT)\n+\t\tr->rtm_flags |= RTCF_DOREDIRECT;\n \n \tif (nla_put_be32(skb, RTA_DST, dst))\n \t\tgoto nla_put_failure;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\tif (IPCB(skb)->flags & IPSKB_DOREDIRECT)",
                "\t\tr->rtm_flags |= RTCF_DOREDIRECT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1465",
        "func_name": "torvalds/linux/__mkroute_input",
        "description": "The IPv4 implementation in the Linux kernel before 3.18.8 does not properly consider the length of the Read-Copy Update (RCU) grace period for redirecting lookups in the absence of caching, which allows remote attackers to cause a denial of service (memory consumption or system crash) via a flood of packets.",
        "git_url": "https://github.com/torvalds/linux/commit/df4d92549f23e1c037e83323aff58a21b3de7fe0",
        "commit_title": "ipv4: try to cache dst_entries which would cause a redirect",
        "commit_text": " Not caching dst_entries which cause redirects could be exploited by hosts on the same subnet, causing a severe DoS attack. This effect aggravated since commit f88649721268999 (\"ipv4: fix dst race in sk_dst_get()\").  Lookups causing redirects will be allocated with DST_NOCACHE set which will force dst_release to free them via RCU.  Unfortunately waiting for RCU grace period just takes too long, we can end up with >1M dst_entries waiting to be released and the system will run OOM. rcuos threads cannot catch up under high softirq load.  Attaching the flag to emit a redirect later on to the specific skb allows us to cache those dst_entries thus reducing the pressure on allocation and deallocation.  This issue was discovered by Marcelo Leitner.  Cc: Julian Anastasov <ja@ssi.bg>",
        "func_before": "static int __mkroute_input(struct sk_buff *skb,\n\t\t\t   const struct fib_result *res,\n\t\t\t   struct in_device *in_dev,\n\t\t\t   __be32 daddr, __be32 saddr, u32 tos)\n{\n\tstruct fib_nh_exception *fnhe;\n\tstruct rtable *rth;\n\tint err;\n\tstruct in_device *out_dev;\n\tunsigned int flags = 0;\n\tbool do_cache;\n\tu32 itag = 0;\n\n\t/* get a working reference to the output device */\n\tout_dev = __in_dev_get_rcu(FIB_RES_DEV(*res));\n\tif (out_dev == NULL) {\n\t\tnet_crit_ratelimited(\"Bug in ip_route_input_slow(). Please report.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = fib_validate_source(skb, saddr, daddr, tos, FIB_RES_OIF(*res),\n\t\t\t\t  in_dev->dev, in_dev, &itag);\n\tif (err < 0) {\n\t\tip_handle_martian_source(in_dev->dev, in_dev, skb, daddr,\n\t\t\t\t\t saddr);\n\n\t\tgoto cleanup;\n\t}\n\n\tdo_cache = res->fi && !itag;\n\tif (out_dev == in_dev && err && IN_DEV_TX_REDIRECTS(out_dev) &&\n\t    (IN_DEV_SHARED_MEDIA(out_dev) ||\n\t     inet_addr_onlink(out_dev, saddr, FIB_RES_GW(*res)))) {\n\t\tflags |= RTCF_DOREDIRECT;\n\t\tdo_cache = false;\n\t}\n\n\tif (skb->protocol != htons(ETH_P_IP)) {\n\t\t/* Not IP (i.e. ARP). Do not create route, if it is\n\t\t * invalid for proxy arp. DNAT routes are always valid.\n\t\t *\n\t\t * Proxy arp feature have been extended to allow, ARP\n\t\t * replies back to the same interface, to support\n\t\t * Private VLAN switch technologies. See arp.c.\n\t\t */\n\t\tif (out_dev == in_dev &&\n\t\t    IN_DEV_PROXY_ARP_PVLAN(in_dev) == 0) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto cleanup;\n\t\t}\n\t}\n\n\tfnhe = find_exception(&FIB_RES_NH(*res), daddr);\n\tif (do_cache) {\n\t\tif (fnhe != NULL)\n\t\t\trth = rcu_dereference(fnhe->fnhe_rth_input);\n\t\telse\n\t\t\trth = rcu_dereference(FIB_RES_NH(*res).nh_rth_input);\n\n\t\tif (rt_cache_valid(rth)) {\n\t\t\tskb_dst_set_noref(skb, &rth->dst);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trth = rt_dst_alloc(out_dev->dev,\n\t\t\t   IN_DEV_CONF_GET(in_dev, NOPOLICY),\n\t\t\t   IN_DEV_CONF_GET(out_dev, NOXFRM), do_cache);\n\tif (!rth) {\n\t\terr = -ENOBUFS;\n\t\tgoto cleanup;\n\t}\n\n\trth->rt_genid = rt_genid_ipv4(dev_net(rth->dst.dev));\n\trth->rt_flags = flags;\n\trth->rt_type = res->type;\n\trth->rt_is_input = 1;\n\trth->rt_iif \t= 0;\n\trth->rt_pmtu\t= 0;\n\trth->rt_gateway\t= 0;\n\trth->rt_uses_gateway = 0;\n\tINIT_LIST_HEAD(&rth->rt_uncached);\n\tRT_CACHE_STAT_INC(in_slow_tot);\n\n\trth->dst.input = ip_forward;\n\trth->dst.output = ip_output;\n\n\trt_set_nexthop(rth, daddr, res, fnhe, res->fi, res->type, itag);\n\tskb_dst_set(skb, &rth->dst);\nout:\n\terr = 0;\n cleanup:\n\treturn err;\n}",
        "func": "static int __mkroute_input(struct sk_buff *skb,\n\t\t\t   const struct fib_result *res,\n\t\t\t   struct in_device *in_dev,\n\t\t\t   __be32 daddr, __be32 saddr, u32 tos)\n{\n\tstruct fib_nh_exception *fnhe;\n\tstruct rtable *rth;\n\tint err;\n\tstruct in_device *out_dev;\n\tunsigned int flags = 0;\n\tbool do_cache;\n\tu32 itag = 0;\n\n\t/* get a working reference to the output device */\n\tout_dev = __in_dev_get_rcu(FIB_RES_DEV(*res));\n\tif (out_dev == NULL) {\n\t\tnet_crit_ratelimited(\"Bug in ip_route_input_slow(). Please report.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\terr = fib_validate_source(skb, saddr, daddr, tos, FIB_RES_OIF(*res),\n\t\t\t\t  in_dev->dev, in_dev, &itag);\n\tif (err < 0) {\n\t\tip_handle_martian_source(in_dev->dev, in_dev, skb, daddr,\n\t\t\t\t\t saddr);\n\n\t\tgoto cleanup;\n\t}\n\n\tdo_cache = res->fi && !itag;\n\tif (out_dev == in_dev && err && IN_DEV_TX_REDIRECTS(out_dev) &&\n\t    skb->protocol == htons(ETH_P_IP) &&\n\t    (IN_DEV_SHARED_MEDIA(out_dev) ||\n\t     inet_addr_onlink(out_dev, saddr, FIB_RES_GW(*res))))\n\t\tIPCB(skb)->flags |= IPSKB_DOREDIRECT;\n\n\tif (skb->protocol != htons(ETH_P_IP)) {\n\t\t/* Not IP (i.e. ARP). Do not create route, if it is\n\t\t * invalid for proxy arp. DNAT routes are always valid.\n\t\t *\n\t\t * Proxy arp feature have been extended to allow, ARP\n\t\t * replies back to the same interface, to support\n\t\t * Private VLAN switch technologies. See arp.c.\n\t\t */\n\t\tif (out_dev == in_dev &&\n\t\t    IN_DEV_PROXY_ARP_PVLAN(in_dev) == 0) {\n\t\t\terr = -EINVAL;\n\t\t\tgoto cleanup;\n\t\t}\n\t}\n\n\tfnhe = find_exception(&FIB_RES_NH(*res), daddr);\n\tif (do_cache) {\n\t\tif (fnhe != NULL)\n\t\t\trth = rcu_dereference(fnhe->fnhe_rth_input);\n\t\telse\n\t\t\trth = rcu_dereference(FIB_RES_NH(*res).nh_rth_input);\n\n\t\tif (rt_cache_valid(rth)) {\n\t\t\tskb_dst_set_noref(skb, &rth->dst);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\trth = rt_dst_alloc(out_dev->dev,\n\t\t\t   IN_DEV_CONF_GET(in_dev, NOPOLICY),\n\t\t\t   IN_DEV_CONF_GET(out_dev, NOXFRM), do_cache);\n\tif (!rth) {\n\t\terr = -ENOBUFS;\n\t\tgoto cleanup;\n\t}\n\n\trth->rt_genid = rt_genid_ipv4(dev_net(rth->dst.dev));\n\trth->rt_flags = flags;\n\trth->rt_type = res->type;\n\trth->rt_is_input = 1;\n\trth->rt_iif \t= 0;\n\trth->rt_pmtu\t= 0;\n\trth->rt_gateway\t= 0;\n\trth->rt_uses_gateway = 0;\n\tINIT_LIST_HEAD(&rth->rt_uncached);\n\tRT_CACHE_STAT_INC(in_slow_tot);\n\n\trth->dst.input = ip_forward;\n\trth->dst.output = ip_output;\n\n\trt_set_nexthop(rth, daddr, res, fnhe, res->fi, res->type, itag);\n\tskb_dst_set(skb, &rth->dst);\nout:\n\terr = 0;\n cleanup:\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -29,11 +29,10 @@\n \n \tdo_cache = res->fi && !itag;\n \tif (out_dev == in_dev && err && IN_DEV_TX_REDIRECTS(out_dev) &&\n+\t    skb->protocol == htons(ETH_P_IP) &&\n \t    (IN_DEV_SHARED_MEDIA(out_dev) ||\n-\t     inet_addr_onlink(out_dev, saddr, FIB_RES_GW(*res)))) {\n-\t\tflags |= RTCF_DOREDIRECT;\n-\t\tdo_cache = false;\n-\t}\n+\t     inet_addr_onlink(out_dev, saddr, FIB_RES_GW(*res))))\n+\t\tIPCB(skb)->flags |= IPSKB_DOREDIRECT;\n \n \tif (skb->protocol != htons(ETH_P_IP)) {\n \t\t/* Not IP (i.e. ARP). Do not create route, if it is",
        "diff_line_info": {
            "deleted_lines": [
                "\t     inet_addr_onlink(out_dev, saddr, FIB_RES_GW(*res)))) {",
                "\t\tflags |= RTCF_DOREDIRECT;",
                "\t\tdo_cache = false;",
                "\t}"
            ],
            "added_lines": [
                "\t    skb->protocol == htons(ETH_P_IP) &&",
                "\t     inet_addr_onlink(out_dev, saddr, FIB_RES_GW(*res))))",
                "\t\tIPCB(skb)->flags |= IPSKB_DOREDIRECT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1262",
        "func_name": "chromium/HarfBuzzShaper::HarfBuzzShaper",
        "description": "platform/fonts/shaping/HarfBuzzShaper.cpp in Blink, as used in Google Chrome before 43.0.2357.65, does not initialize a certain width field, which allows remote attackers to cause a denial of service or possibly have unspecified other impact via crafted Unicode text.",
        "git_url": "https://github.com/chromium/chromium/commit/d8fccaec4e73a9120074293c1997f963f810c9dd",
        "commit_title": "Always initialize |m_totalWidth| in HarfBuzzShaper::shape.",
        "commit_text": "  ",
        "func_before": "HarfBuzzShaper::HarfBuzzShaper(const Font* font, const TextRun& run, const GlyphData* emphasisData,\n    HashSet<const SimpleFontData*>* fallbackFonts, FloatRect* bounds)\n    : Shaper(font, run, emphasisData, fallbackFonts, bounds)\n    , m_normalizedBufferLength(0)\n    , m_wordSpacingAdjustment(font->fontDescription().wordSpacing())\n    , m_letterSpacing(font->fontDescription().letterSpacing())\n    , m_expansionOpportunityCount(0)\n    , m_fromIndex(0)\n    , m_toIndex(m_run.length())\n{\n    m_normalizedBuffer = adoptArrayPtr(new UChar[m_run.length() + 1]);\n    normalizeCharacters(m_run, m_run.length(), m_normalizedBuffer.get(), &m_normalizedBufferLength);\n    setExpansion(m_run.expansion());\n    setFontFeatures();\n}",
        "func": "HarfBuzzShaper::HarfBuzzShaper(const Font* font, const TextRun& run, const GlyphData* emphasisData,\n    HashSet<const SimpleFontData*>* fallbackFonts, FloatRect* bounds)\n    : Shaper(font, run, emphasisData, fallbackFonts, bounds)\n    , m_normalizedBufferLength(0)\n    , m_wordSpacingAdjustment(font->fontDescription().wordSpacing())\n    , m_letterSpacing(font->fontDescription().letterSpacing())\n    , m_expansionOpportunityCount(0)\n    , m_fromIndex(0)\n    , m_toIndex(m_run.length())\n    , m_totalWidth(0)\n{\n    m_normalizedBuffer = adoptArrayPtr(new UChar[m_run.length() + 1]);\n    normalizeCharacters(m_run, m_run.length(), m_normalizedBuffer.get(), &m_normalizedBufferLength);\n    setExpansion(m_run.expansion());\n    setFontFeatures();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -7,6 +7,7 @@\n     , m_expansionOpportunityCount(0)\n     , m_fromIndex(0)\n     , m_toIndex(m_run.length())\n+    , m_totalWidth(0)\n {\n     m_normalizedBuffer = adoptArrayPtr(new UChar[m_run.length() + 1]);\n     normalizeCharacters(m_run, m_run.length(), m_normalizedBuffer.get(), &m_normalizedBufferLength);",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    , m_totalWidth(0)"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1262",
        "func_name": "chromium/HarfBuzzShaper::shape",
        "description": "platform/fonts/shaping/HarfBuzzShaper.cpp in Blink, as used in Google Chrome before 43.0.2357.65, does not initialize a certain width field, which allows remote attackers to cause a denial of service or possibly have unspecified other impact via crafted Unicode text.",
        "git_url": "https://github.com/chromium/chromium/commit/d8fccaec4e73a9120074293c1997f963f810c9dd",
        "commit_title": "Always initialize |m_totalWidth| in HarfBuzzShaper::shape.",
        "commit_text": "  ",
        "func_before": "bool HarfBuzzShaper::shape(GlyphBuffer* glyphBuffer)\n{\n    if (!createHarfBuzzRuns())\n        return false;\n\n    m_totalWidth = 0;\n    if (!shapeHarfBuzzRuns())\n        return false;\n\n    if (glyphBuffer && !fillGlyphBuffer(glyphBuffer))\n        return false;\n\n    return true;\n}",
        "func": "bool HarfBuzzShaper::shape(GlyphBuffer* glyphBuffer)\n{\n    if (!createHarfBuzzRuns())\n        return false;\n\n    if (!shapeHarfBuzzRuns())\n        return false;\n\n    if (glyphBuffer && !fillGlyphBuffer(glyphBuffer))\n        return false;\n\n    return true;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,7 +3,6 @@\n     if (!createHarfBuzzRuns())\n         return false;\n \n-    m_totalWidth = 0;\n     if (!shapeHarfBuzzRuns())\n         return false;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "    m_totalWidth = 0;"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-1263",
        "func_name": "chromium/SpellcheckHunspellDictionary::GetDictionaryURL",
        "description": "The Spellcheck API implementation in Google Chrome before 43.0.2357.65 does not use an HTTPS session for downloading a Hunspell dictionary, which allows man-in-the-middle attackers to deliver incorrect spelling suggestions or possibly have unspecified other impact via a crafted file.",
        "git_url": "https://chromium.googlesource.com/chromium/src/+/6703b5a51cedaa0ead73047d969f8c04362f51f1",
        "commit_title": "[Spellcheck] Switch to https download",
        "commit_text": " Download dictionaries via https instead of http, preventing MITM attacks against dicts. Plus, HTTPS 4 LYFE!    ",
        "func_before": "GURL SpellcheckHunspellDictionary::GetDictionaryURL() {\n  static const char kDownloadServerUrl[] =\n      \"http://cache.pack.google.com/edgedl/chrome/dict/\";\n  std::string bdict_file = dictionary_file_.path.BaseName().MaybeAsASCII();\n\n  DCHECK(!bdict_file.empty());\n\n  return GURL(std::string(kDownloadServerUrl) +\n              base::StringToLowerASCII(bdict_file));\n}",
        "func": "GURL SpellcheckHunspellDictionary::GetDictionaryURL() {\n  static const char kDownloadServerUrl[] =\n      \"https://redirector.gvt1.com/edgedl/chrome/dict/\";\n  std::string bdict_file = dictionary_file_.path.BaseName().MaybeAsASCII();\n\n  DCHECK(!bdict_file.empty());\n\n  return GURL(std::string(kDownloadServerUrl) +\n              base::StringToLowerASCII(bdict_file));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n GURL SpellcheckHunspellDictionary::GetDictionaryURL() {\n   static const char kDownloadServerUrl[] =\n-      \"http://cache.pack.google.com/edgedl/chrome/dict/\";\n+      \"https://redirector.gvt1.com/edgedl/chrome/dict/\";\n   std::string bdict_file = dictionary_file_.path.BaseName().MaybeAsASCII();\n \n   DCHECK(!bdict_file.empty());",
        "diff_line_info": {
            "deleted_lines": [
                "      \"http://cache.pack.google.com/edgedl/chrome/dict/\";"
            ],
            "added_lines": [
                "      \"https://redirector.gvt1.com/edgedl/chrome/dict/\";"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3811",
        "func_name": "wireshark/decompressed_entry",
        "description": "epan/dissectors/packet-wcp.c in the WCP dissector in Wireshark 1.10.x before 1.10.14 and 1.12.x before 1.12.5 improperly refers to previously processed bytes, which allows remote attackers to cause a denial of service (application crash) via a crafted packet, a different vulnerability than CVE-2015-2188.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a6fc6aa0b4efc1a1c3d7a2e3b5189e888fb6ccc2",
        "commit_title": "wcp: add validations to decompressed_entry",
        "commit_text": " Ensure that a reference to past bytes refers to bytes that actually exist.  Bug: 10978",
        "func_before": "static guint8 *\ndecompressed_entry(guint8 *dst, guint16 data_offset,\n    guint16 data_cnt, int *len, guint8 * buf_start, guint8 *buf_end)\n{\n\tconst guint8 *src;\n\n/* do the decompression for one field */\n\n\tsrc = (dst - 1 - data_offset);\n\tif ( src < buf_start)\n\t\tsrc += MAX_WIN_BUF_LEN;\n\n\n/*XXX could do some fancy memory moves, later if speed is problem */\n\n\twhile( data_cnt--){\n\t\t*dst = *src;\n\t\tif ( ++(*len) >MAX_WCP_BUF_LEN){\n\t\t\treturn NULL;\t/* end of buffer error */\n\t\t}\n\t\tif ( dst++ == buf_end)\n\t\t\tdst = buf_start;\n\t\tif ( src++ == buf_end)\n\t\t\tsrc = buf_start;\n\n\t}\n\treturn dst;\n}",
        "func": "static guint8 *\ndecompressed_entry(guint8 *dst, guint16 data_offset,\n    guint16 data_cnt, int *len, wcp_window_t *buf_ptr)\n{\n\tconst guint8 *src;\n\tguint8 *buf_start, *buf_end;\n\n\tbuf_start = buf_ptr->buffer;\n\tbuf_end = buf_ptr->buffer + MAX_WIN_BUF_LEN;\n\n/* do the decompression for one field */\n\n\tsrc = (dst - 1 - data_offset);\n\tif ( src < buf_start)\n\t\tsrc += MAX_WIN_BUF_LEN;\n\n\n/*XXX could do some fancy memory moves, later if speed is problem */\n\n\twhile( data_cnt--){\n\t\t*dst = *src;\n\t\tif ( buf_ptr->initialized < MAX_WIN_BUF_LEN)\n\t\t\tbuf_ptr->initialized++;\n\t\tif ( ++(*len) >MAX_WCP_BUF_LEN){\n\t\t\treturn NULL;\t/* end of buffer error */\n\t\t}\n\t\tif ( dst++ == buf_end)\n\t\t\tdst = buf_start;\n\t\tif ( src++ == buf_end)\n\t\t\tsrc = buf_start;\n\n\t}\n\treturn dst;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,12 @@\n static guint8 *\n decompressed_entry(guint8 *dst, guint16 data_offset,\n-    guint16 data_cnt, int *len, guint8 * buf_start, guint8 *buf_end)\n+    guint16 data_cnt, int *len, wcp_window_t *buf_ptr)\n {\n \tconst guint8 *src;\n+\tguint8 *buf_start, *buf_end;\n+\n+\tbuf_start = buf_ptr->buffer;\n+\tbuf_end = buf_ptr->buffer + MAX_WIN_BUF_LEN;\n \n /* do the decompression for one field */\n \n@@ -15,6 +19,8 @@\n \n \twhile( data_cnt--){\n \t\t*dst = *src;\n+\t\tif ( buf_ptr->initialized < MAX_WIN_BUF_LEN)\n+\t\t\tbuf_ptr->initialized++;\n \t\tif ( ++(*len) >MAX_WCP_BUF_LEN){\n \t\t\treturn NULL;\t/* end of buffer error */\n \t\t}",
        "diff_line_info": {
            "deleted_lines": [
                "    guint16 data_cnt, int *len, guint8 * buf_start, guint8 *buf_end)"
            ],
            "added_lines": [
                "    guint16 data_cnt, int *len, wcp_window_t *buf_ptr)",
                "\tguint8 *buf_start, *buf_end;",
                "",
                "\tbuf_start = buf_ptr->buffer;",
                "\tbuf_end = buf_ptr->buffer + MAX_WIN_BUF_LEN;",
                "\t\tif ( buf_ptr->initialized < MAX_WIN_BUF_LEN)",
                "\t\t\tbuf_ptr->initialized++;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3811",
        "func_name": "wireshark/get_wcp_window_ptr",
        "description": "epan/dissectors/packet-wcp.c in the WCP dissector in Wireshark 1.10.x before 1.10.14 and 1.12.x before 1.12.5 improperly refers to previously processed bytes, which allows remote attackers to cause a denial of service (application crash) via a crafted packet, a different vulnerability than CVE-2015-2188.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a6fc6aa0b4efc1a1c3d7a2e3b5189e888fb6ccc2",
        "commit_title": "wcp: add validations to decompressed_entry",
        "commit_text": " Ensure that a reference to past bytes refers to bytes that actually exist.  Bug: 10978",
        "func_before": "static\nwcp_window_t *get_wcp_window_ptr(packet_info *pinfo, circuit_type ctype, guint32 circuit_id){\n\n/* find the circuit for this DLCI, create one if needed */\n/* and return the wcp_window data structure pointer */\n/* for the direction of this packet */\n\n\tcircuit_t *circuit;\n\twcp_circuit_data_t *wcp_circuit_data;\n\n\tcircuit = find_circuit( ctype, circuit_id,\n\t\tpinfo->fd->num);\n\tif ( !circuit){\n\t\tcircuit = circuit_new( ctype, circuit_id,\n\t\t\tpinfo->fd->num);\n\t}\n\twcp_circuit_data = (wcp_circuit_data_t *)circuit_get_proto_data(circuit, proto_wcp);\n\tif ( !wcp_circuit_data){\n\t\twcp_circuit_data = wmem_new(wmem_file_scope(), wcp_circuit_data_t);\n\t\twcp_circuit_data->recv.buf_cur = wcp_circuit_data->recv.buffer;\n\t\twcp_circuit_data->send.buf_cur = wcp_circuit_data->send.buffer;\n\t\tcircuit_add_proto_data(circuit, proto_wcp, wcp_circuit_data);\n\t}\n\tif (pinfo->pseudo_header->x25.flags & FROM_DCE)\n\t\treturn &wcp_circuit_data->recv;\n\telse\n\t\treturn &wcp_circuit_data->send;\n}",
        "func": "static\nwcp_window_t *get_wcp_window_ptr(packet_info *pinfo, circuit_type ctype, guint32 circuit_id){\n\n/* find the circuit for this DLCI, create one if needed */\n/* and return the wcp_window data structure pointer */\n/* for the direction of this packet */\n\n\tcircuit_t *circuit;\n\twcp_circuit_data_t *wcp_circuit_data;\n\n\tcircuit = find_circuit( ctype, circuit_id,\n\t\tpinfo->fd->num);\n\tif ( !circuit){\n\t\tcircuit = circuit_new( ctype, circuit_id,\n\t\t\tpinfo->fd->num);\n\t}\n\twcp_circuit_data = (wcp_circuit_data_t *)circuit_get_proto_data(circuit, proto_wcp);\n\tif ( !wcp_circuit_data){\n\t\twcp_circuit_data = wmem_new(wmem_file_scope(), wcp_circuit_data_t);\n\t\twcp_circuit_data->recv.buf_cur = wcp_circuit_data->recv.buffer;\n\t\twcp_circuit_data->recv.initialized = 0;\n\t\twcp_circuit_data->send.buf_cur = wcp_circuit_data->send.buffer;\n\t\twcp_circuit_data->send.initialized = 0;\n\t\tcircuit_add_proto_data(circuit, proto_wcp, wcp_circuit_data);\n\t}\n\tif (pinfo->pseudo_header->x25.flags & FROM_DCE)\n\t\treturn &wcp_circuit_data->recv;\n\telse\n\t\treturn &wcp_circuit_data->send;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -18,7 +18,9 @@\n \tif ( !wcp_circuit_data){\n \t\twcp_circuit_data = wmem_new(wmem_file_scope(), wcp_circuit_data_t);\n \t\twcp_circuit_data->recv.buf_cur = wcp_circuit_data->recv.buffer;\n+\t\twcp_circuit_data->recv.initialized = 0;\n \t\twcp_circuit_data->send.buf_cur = wcp_circuit_data->send.buffer;\n+\t\twcp_circuit_data->send.initialized = 0;\n \t\tcircuit_add_proto_data(circuit, proto_wcp, wcp_circuit_data);\n \t}\n \tif (pinfo->pseudo_header->x25.flags & FROM_DCE)",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\twcp_circuit_data->recv.initialized = 0;",
                "\t\twcp_circuit_data->send.initialized = 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3811",
        "func_name": "wireshark/wcp_uncompress",
        "description": "epan/dissectors/packet-wcp.c in the WCP dissector in Wireshark 1.10.x before 1.10.14 and 1.12.x before 1.12.5 improperly refers to previously processed bytes, which allows remote attackers to cause a denial of service (application crash) via a crafted packet, a different vulnerability than CVE-2015-2188.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a6fc6aa0b4efc1a1c3d7a2e3b5189e888fb6ccc2",
        "commit_title": "wcp: add validations to decompressed_entry",
        "commit_text": " Ensure that a reference to past bytes refers to bytes that actually exist.  Bug: 10978",
        "func_before": "static tvbuff_t *wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree, circuit_type ctype, guint32 circuit_id) {\n\n/* do the packet data uncompression and load it into the dst buffer */\n\n\tproto_tree\t*cd_tree, *sub_tree;\n\tproto_item\t*cd_item, *ti;\n\n\tint len, i;\n\tint cnt = tvb_reported_length( src_tvb)-1;\t/* don't include check byte */\n\n\tguint8 *dst, *src, *buf_start, *buf_end, comp_flag_bits = 0;\n\tguint16 data_offset, data_cnt;\n\tguint8 src_buf[ MAX_WCP_BUF_LEN];\n\ttvbuff_t *tvb;\n\twcp_window_t *buf_ptr = 0;\n\twcp_pdata_t *pdata_ptr;\n\n\tbuf_ptr = get_wcp_window_ptr(pinfo, ctype, circuit_id);\n\n\tbuf_start = buf_ptr->buffer;\n\tbuf_end = buf_start + MAX_WIN_BUF_LEN;\n\n\tcd_item = proto_tree_add_item(tree, hf_wcp_compressed_data,\n\t    src_tvb, offset, cnt - offset, ENC_NA);\n\tcd_tree = proto_item_add_subtree(cd_item, ett_wcp_comp_data);\n\tif (cnt - offset > MAX_WCP_BUF_LEN) {\n\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_compressed_data_exceeds,\n\t\t\t\"Compressed data exceeds maximum buffer length (%d > %d)\",\n\t\t\tcnt - offset, MAX_WCP_BUF_LEN);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t * XXX - this will thow an exception if a snapshot length cut short\n\t * the data.  We may want to try to dissect the data in that case,\n\t * and we may even want to try to decompress it, *but* we will\n\t * want to mark the buffer of decompressed data as incomplete, so\n\t * that we don't try to use it for decompressing later packets.\n\t */\n\tsrc = (guint8 *)tvb_memcpy(src_tvb, src_buf, offset, cnt - offset);\n\tdst = buf_ptr->buf_cur;\n\tlen = 0;\n\ti = -1;\n\n\twhile( offset < cnt){\n\t\t/* There are i bytes left for this byte of flag bits */\n\t\tif ( --i >= 0){\n\t\t\t/*\n\t\t\t * There's still at least one more byte left for\n\t\t\t * the current set of compression flag bits; is\n\t\t\t * it compressed data or uncompressed data?\n\t\t\t */\n\t\t\tif ( comp_flag_bits & 0x80){\n\t\t\t\t/* This byte is compressed data */\n\t\t\t\tif (!(offset + 1 < cnt)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * The data offset runs past the\n\t\t\t\t\t * end of the data.\n\t\t\t\t\t */\n\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t}\n\t\t\t\tdata_offset = pntoh16(src) & WCP_OFFSET_MASK;\n\t\t\t\tif ((*src & 0xf0) == 0x10){\n\t\t\t\t\t/*\n\t\t\t\t\t * The count of bytes to copy from\n\t\t\t\t\t * the dictionary window is in the\n\t\t\t\t\t * byte following the data offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (!(offset + 2 < cnt)) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * The data count runs past the\n\t\t\t\t\t\t * end of the data.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t}\n\t\t\t\t\tdata_cnt = *(src + 2) + 1;\n\t\t\t\t\tif ( tree) {\n\t\t\t\t\t\tti = proto_tree_add_item( cd_tree, hf_wcp_long_run, src_tvb,\n\t\t\t\t\t\t\t offset, 3, ENC_NA);\n\t\t\t\t\t\tsub_tree = proto_item_add_subtree(ti, ett_wcp_field);\n\t\t\t\t\t\tproto_tree_add_uint(sub_tree, hf_wcp_offset, src_tvb,\n\t\t\t\t\t\t\t offset, 2, data_offset);\n\n\t\t\t\t\t\tproto_tree_add_item( sub_tree, hf_wcp_long_len, src_tvb,\n\t\t\t\t\t\t\t offset+2, 1, ENC_BIG_ENDIAN);\n\t\t\t\t\t}\n\t\t\t\t\tsrc += 3;\n\t\t\t\t\toffset += 3;\n\t\t\t\t}else{\n\t\t\t\t\t/*\n\t\t\t\t\t * The count of bytes to copy from\n\t\t\t\t\t * the dictionary window is in\n\t\t\t\t\t * the upper 4 bits of the next\n\t\t\t\t\t * byte.\n\t\t\t\t\t */\n\t\t\t\t\tdata_cnt = (*src >> 4) + 1;\n\t\t\t\t\tif ( tree) {\n\t\t\t\t\t\tti = proto_tree_add_item( cd_tree, hf_wcp_short_run, src_tvb,\n\t\t\t\t\t\t\t offset, 2, ENC_NA);\n\t\t\t\t\t\tsub_tree = proto_item_add_subtree(ti, ett_wcp_field);\n\t\t\t\t\t\tproto_tree_add_uint( sub_tree, hf_wcp_short_len, src_tvb,\n\t\t\t\t\t\t\t offset, 1, *src);\n\t\t\t\t\t\tproto_tree_add_uint(sub_tree, hf_wcp_offset, src_tvb,\n\t\t\t\t\t\t\t offset, 2, data_offset);\n\t\t\t\t\t}\n\t\t\t\t\tsrc += 2;\n\t\t\t\t\toffset += 2;\n\t\t\t\t}\n\t\t\t\tif ( !pinfo->fd->flags.visited){\t/* if first pass */\n\t\t\t\t\tdst = decompressed_entry(dst,\n\t\t\t\t\t    data_offset, data_cnt, &len,\n\t\t\t\t\t    buf_start, buf_end);\n\t\t\t\t\tif (dst == NULL){\n\t\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_uncompressed_data_exceeds,\n\t\t\t\t\t\t\t\"Uncompressed data exceeds maximum buffer length (%d > %d)\",\n\t\t\t\t\t\t\tlen, MAX_WCP_BUF_LEN);\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}else {\n\t\t\t\t/*\n\t\t\t\t * This byte is uncompressed data; is there\n\t\t\t\t * room for it in the buffer of uncompressed\n\t\t\t\t * data?\n\t\t\t\t */\n\t\t\t\tif ( ++len >MAX_WCP_BUF_LEN){\n\t\t\t\t\t/* No - report an error. */\n\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_uncompressed_data_exceeds,\n\t\t\t\t\t\t\"Uncompressed data exceeds maximum buffer length (%d > %d)\",\n\t\t\t\t\t\tlen, MAX_WCP_BUF_LEN);\n\t\t\t\t\treturn NULL;\n\t\t\t\t}\n\n\t\t\t\tif ( !pinfo->fd->flags.visited){\n\t\t\t\t\t/*\n\t\t\t\t\t * This is the first pass through\n\t\t\t\t\t * the packets, so copy it to the\n\t\t\t\t\t * buffer of unco,pressed data.\n\t\t\t\t\t */\n\t\t\t\t\t*dst = *src;\n\t\t\t\t\tif ( dst++ == buf_end)\n\t\t\t\t\t\tdst = buf_start;\n\t\t\t\t}\n\t\t\t\t++src;\n\t\t\t\t++offset;\n\t\t\t}\n\n\t\t\t/* Skip to the next compression flag bit */\n\t\t\tcomp_flag_bits <<= 1;\n\n\t\t}else {\n\t\t\t/*\n\t\t\t * There are no more bytes left for the current\n\t\t\t * set of compression flag bits, so this byte\n\t\t\t * is another byte of compression flag bits.\n\t\t\t */\n\t\t\tcomp_flag_bits = *src++;\n\t\t\tif (cd_tree)\n\t\t\t\tproto_tree_add_uint(cd_tree, hf_wcp_comp_bits,  src_tvb, offset, 1,\n\t\t\t\t\tcomp_flag_bits);\n\t\t\toffset++;\n\n\t\t\ti = 8;\n\t\t}\n\t}\n\n\tif ( pinfo->fd->flags.visited){\t/* if not first pass */\n\t\t\t\t\t/* get uncompressed data */\n\t\tpdata_ptr = (wcp_pdata_t *)p_get_proto_data(wmem_file_scope(), pinfo, proto_wcp, 0);\n\n\t\tif ( !pdata_ptr) {\t/* exit if no data */\n\t\t\tREPORT_DISSECTOR_BUG(\"Can't find uncompressed data\");\n\t\t\treturn NULL;\n\t\t}\n\t\tlen = pdata_ptr->len;\n\t} else {\n\n\t/* save the new data as per packet data */\n\t\tpdata_ptr = wmem_new(wmem_file_scope(), wcp_pdata_t);\n\t\tmemcpy( &pdata_ptr->buffer, buf_ptr->buf_cur,  len);\n\t\tpdata_ptr->len = len;\n\n\t\tp_add_proto_data(wmem_file_scope(), pinfo, proto_wcp, 0, (void*)pdata_ptr);\n\n\t\tbuf_ptr->buf_cur = dst;\n\t}\n\n\ttvb = tvb_new_child_real_data(src_tvb,  pdata_ptr->buffer, pdata_ptr->len, pdata_ptr->len);\n\n\t/* Add new data to the data source list */\n\tadd_new_data_source( pinfo, tvb, \"Uncompressed WCP\");\n\treturn tvb;\n\n}",
        "func": "static tvbuff_t *wcp_uncompress( tvbuff_t *src_tvb, int offset, packet_info *pinfo, proto_tree *tree, circuit_type ctype, guint32 circuit_id) {\n\n/* do the packet data uncompression and load it into the dst buffer */\n\n\tproto_tree\t*cd_tree, *sub_tree;\n\tproto_item\t*cd_item, *ti;\n\n\tint len, i;\n\tint cnt = tvb_reported_length( src_tvb)-1;\t/* don't include check byte */\n\n\tguint8 *dst, *src, *buf_start, *buf_end, comp_flag_bits = 0;\n\tguint16 data_offset, data_cnt;\n\tguint8 src_buf[ MAX_WCP_BUF_LEN];\n\ttvbuff_t *tvb;\n\twcp_window_t *buf_ptr = 0;\n\twcp_pdata_t *pdata_ptr;\n\n\tbuf_ptr = get_wcp_window_ptr(pinfo, ctype, circuit_id);\n\n\tbuf_start = buf_ptr->buffer;\n\tbuf_end = buf_start + MAX_WIN_BUF_LEN;\n\n\tcd_item = proto_tree_add_item(tree, hf_wcp_compressed_data,\n\t    src_tvb, offset, cnt - offset, ENC_NA);\n\tcd_tree = proto_item_add_subtree(cd_item, ett_wcp_comp_data);\n\tif (cnt - offset > MAX_WCP_BUF_LEN) {\n\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_compressed_data_exceeds,\n\t\t\t\"Compressed data exceeds maximum buffer length (%d > %d)\",\n\t\t\tcnt - offset, MAX_WCP_BUF_LEN);\n\t\treturn NULL;\n\t}\n\n\t/*\n\t * XXX - this will thow an exception if a snapshot length cut short\n\t * the data.  We may want to try to dissect the data in that case,\n\t * and we may even want to try to decompress it, *but* we will\n\t * want to mark the buffer of decompressed data as incomplete, so\n\t * that we don't try to use it for decompressing later packets.\n\t */\n\tsrc = (guint8 *)tvb_memcpy(src_tvb, src_buf, offset, cnt - offset);\n\tdst = buf_ptr->buf_cur;\n\tlen = 0;\n\ti = -1;\n\n\twhile( offset < cnt){\n\t\t/* There are i bytes left for this byte of flag bits */\n\t\tif ( --i >= 0){\n\t\t\t/*\n\t\t\t * There's still at least one more byte left for\n\t\t\t * the current set of compression flag bits; is\n\t\t\t * it compressed data or uncompressed data?\n\t\t\t */\n\t\t\tif ( comp_flag_bits & 0x80){\n\t\t\t\t/* This byte is compressed data */\n\t\t\t\tif (!(offset + 1 < cnt)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * The data offset runs past the\n\t\t\t\t\t * end of the data.\n\t\t\t\t\t */\n\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t}\n\t\t\t\tdata_offset = pntoh16(src) & WCP_OFFSET_MASK;\n\t\t\t\tif ((*src & 0xf0) == 0x10){\n\t\t\t\t\t/*\n\t\t\t\t\t * The count of bytes to copy from\n\t\t\t\t\t * the dictionary window is in the\n\t\t\t\t\t * byte following the data offset.\n\t\t\t\t\t */\n\t\t\t\t\tif (!(offset + 2 < cnt)) {\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * The data count runs past the\n\t\t\t\t\t\t * end of the data.\n\t\t\t\t\t\t */\n\t\t\t\t\t\tTHROW(ReportedBoundsError);\n\t\t\t\t\t}\n\t\t\t\t\tdata_cnt = *(src + 2) + 1;\n\t\t\t\t\tif ( tree) {\n\t\t\t\t\t\tti = proto_tree_add_item( cd_tree, hf_wcp_long_run, src_tvb,\n\t\t\t\t\t\t\t offset, 3, ENC_NA);\n\t\t\t\t\t\tsub_tree = proto_item_add_subtree(ti, ett_wcp_field);\n\t\t\t\t\t\tproto_tree_add_uint(sub_tree, hf_wcp_offset, src_tvb,\n\t\t\t\t\t\t\t offset, 2, data_offset);\n\n\t\t\t\t\t\tproto_tree_add_item( sub_tree, hf_wcp_long_len, src_tvb,\n\t\t\t\t\t\t\t offset+2, 1, ENC_BIG_ENDIAN);\n\t\t\t\t\t}\n\t\t\t\t\tsrc += 3;\n\t\t\t\t\toffset += 3;\n\t\t\t\t}else{\n\t\t\t\t\t/*\n\t\t\t\t\t * The count of bytes to copy from\n\t\t\t\t\t * the dictionary window is in\n\t\t\t\t\t * the upper 4 bits of the next\n\t\t\t\t\t * byte.\n\t\t\t\t\t */\n\t\t\t\t\tdata_cnt = (*src >> 4) + 1;\n\t\t\t\t\tif ( tree) {\n\t\t\t\t\t\tti = proto_tree_add_item( cd_tree, hf_wcp_short_run, src_tvb,\n\t\t\t\t\t\t\t offset, 2, ENC_NA);\n\t\t\t\t\t\tsub_tree = proto_item_add_subtree(ti, ett_wcp_field);\n\t\t\t\t\t\tproto_tree_add_uint( sub_tree, hf_wcp_short_len, src_tvb,\n\t\t\t\t\t\t\t offset, 1, *src);\n\t\t\t\t\t\tproto_tree_add_uint(sub_tree, hf_wcp_offset, src_tvb,\n\t\t\t\t\t\t\t offset, 2, data_offset);\n\t\t\t\t\t}\n\t\t\t\t\tsrc += 2;\n\t\t\t\t\toffset += 2;\n\t\t\t\t}\n\t\t\t\tif (data_offset + 1 > buf_ptr->initialized) {\n\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_invalid_window_offset,\n\t\t\t\t\t\t\t\"Data offset exceeds valid window size (%d > %d)\",\n\t\t\t\t\t\t\tdata_offset+1, buf_ptr->initialized);\n\t\t\t\t\treturn NULL;\n\t\t\t\t}\n\n\t\t\t\tif (data_offset + 1 < data_cnt) {\n\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_invalid_window_offset,\n\t\t\t\t\t\t\t\"Data count exceeds offset (%d > %d)\",\n\t\t\t\t\t\t\tdata_cnt, data_offset+1);\n\t\t\t\t\treturn NULL;\n\t\t\t\t}\n\t\t\t\tif ( !pinfo->fd->flags.visited){\t/* if first pass */\n\t\t\t\t\tdst = decompressed_entry(dst,\n\t\t\t\t\t    data_offset, data_cnt, &len,\n\t\t\t\t\t    buf_ptr);\n\t\t\t\t\tif (dst == NULL){\n\t\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_uncompressed_data_exceeds,\n\t\t\t\t\t\t\t\"Uncompressed data exceeds maximum buffer length (%d > %d)\",\n\t\t\t\t\t\t\tlen, MAX_WCP_BUF_LEN);\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}else {\n\t\t\t\t/*\n\t\t\t\t * This byte is uncompressed data; is there\n\t\t\t\t * room for it in the buffer of uncompressed\n\t\t\t\t * data?\n\t\t\t\t */\n\t\t\t\tif ( ++len >MAX_WCP_BUF_LEN){\n\t\t\t\t\t/* No - report an error. */\n\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_uncompressed_data_exceeds,\n\t\t\t\t\t\t\"Uncompressed data exceeds maximum buffer length (%d > %d)\",\n\t\t\t\t\t\tlen, MAX_WCP_BUF_LEN);\n\t\t\t\t\treturn NULL;\n\t\t\t\t}\n\n\t\t\t\tif ( !pinfo->fd->flags.visited){\n\t\t\t\t\t/*\n\t\t\t\t\t * This is the first pass through\n\t\t\t\t\t * the packets, so copy it to the\n\t\t\t\t\t * buffer of unco,pressed data.\n\t\t\t\t\t */\n\t\t\t\t\t*dst = *src;\n\t\t\t\t\tif ( dst++ == buf_end)\n\t\t\t\t\t\tdst = buf_start;\n\t\t\t\t\tif (buf_ptr->initialized < MAX_WIN_BUF_LEN)\n\t\t\t\t\t\tbuf_ptr->initialized++;\n\t\t\t\t}\n\t\t\t\t++src;\n\t\t\t\t++offset;\n\t\t\t}\n\n\t\t\t/* Skip to the next compression flag bit */\n\t\t\tcomp_flag_bits <<= 1;\n\n\t\t}else {\n\t\t\t/*\n\t\t\t * There are no more bytes left for the current\n\t\t\t * set of compression flag bits, so this byte\n\t\t\t * is another byte of compression flag bits.\n\t\t\t */\n\t\t\tcomp_flag_bits = *src++;\n\t\t\tif (cd_tree)\n\t\t\t\tproto_tree_add_uint(cd_tree, hf_wcp_comp_bits,  src_tvb, offset, 1,\n\t\t\t\t\tcomp_flag_bits);\n\t\t\toffset++;\n\n\t\t\ti = 8;\n\t\t}\n\t}\n\n\tif ( pinfo->fd->flags.visited){\t/* if not first pass */\n\t\t\t\t\t/* get uncompressed data */\n\t\tpdata_ptr = (wcp_pdata_t *)p_get_proto_data(wmem_file_scope(), pinfo, proto_wcp, 0);\n\n\t\tif ( !pdata_ptr) {\t/* exit if no data */\n\t\t\tREPORT_DISSECTOR_BUG(\"Can't find uncompressed data\");\n\t\t\treturn NULL;\n\t\t}\n\t\tlen = pdata_ptr->len;\n\t} else {\n\n\t/* save the new data as per packet data */\n\t\tpdata_ptr = wmem_new(wmem_file_scope(), wcp_pdata_t);\n\t\tmemcpy( &pdata_ptr->buffer, buf_ptr->buf_cur,  len);\n\t\tpdata_ptr->len = len;\n\n\t\tp_add_proto_data(wmem_file_scope(), pinfo, proto_wcp, 0, (void*)pdata_ptr);\n\n\t\tbuf_ptr->buf_cur = dst;\n\t}\n\n\ttvb = tvb_new_child_real_data(src_tvb,  pdata_ptr->buffer, pdata_ptr->len, pdata_ptr->len);\n\n\t/* Add new data to the data source list */\n\tadd_new_data_source( pinfo, tvb, \"Uncompressed WCP\");\n\treturn tvb;\n\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -106,10 +106,23 @@\n \t\t\t\t\tsrc += 2;\n \t\t\t\t\toffset += 2;\n \t\t\t\t}\n+\t\t\t\tif (data_offset + 1 > buf_ptr->initialized) {\n+\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_invalid_window_offset,\n+\t\t\t\t\t\t\t\"Data offset exceeds valid window size (%d > %d)\",\n+\t\t\t\t\t\t\tdata_offset+1, buf_ptr->initialized);\n+\t\t\t\t\treturn NULL;\n+\t\t\t\t}\n+\n+\t\t\t\tif (data_offset + 1 < data_cnt) {\n+\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_invalid_window_offset,\n+\t\t\t\t\t\t\t\"Data count exceeds offset (%d > %d)\",\n+\t\t\t\t\t\t\tdata_cnt, data_offset+1);\n+\t\t\t\t\treturn NULL;\n+\t\t\t\t}\n \t\t\t\tif ( !pinfo->fd->flags.visited){\t/* if first pass */\n \t\t\t\t\tdst = decompressed_entry(dst,\n \t\t\t\t\t    data_offset, data_cnt, &len,\n-\t\t\t\t\t    buf_start, buf_end);\n+\t\t\t\t\t    buf_ptr);\n \t\t\t\t\tif (dst == NULL){\n \t\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_uncompressed_data_exceeds,\n \t\t\t\t\t\t\t\"Uncompressed data exceeds maximum buffer length (%d > %d)\",\n@@ -140,6 +153,8 @@\n \t\t\t\t\t*dst = *src;\n \t\t\t\t\tif ( dst++ == buf_end)\n \t\t\t\t\t\tdst = buf_start;\n+\t\t\t\t\tif (buf_ptr->initialized < MAX_WIN_BUF_LEN)\n+\t\t\t\t\t\tbuf_ptr->initialized++;\n \t\t\t\t}\n \t\t\t\t++src;\n \t\t\t\t++offset;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\t    buf_start, buf_end);"
            ],
            "added_lines": [
                "\t\t\t\tif (data_offset + 1 > buf_ptr->initialized) {",
                "\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_invalid_window_offset,",
                "\t\t\t\t\t\t\t\"Data offset exceeds valid window size (%d > %d)\",",
                "\t\t\t\t\t\t\tdata_offset+1, buf_ptr->initialized);",
                "\t\t\t\t\treturn NULL;",
                "\t\t\t\t}",
                "",
                "\t\t\t\tif (data_offset + 1 < data_cnt) {",
                "\t\t\t\t\texpert_add_info_format(pinfo, cd_item, &ei_wcp_invalid_window_offset,",
                "\t\t\t\t\t\t\t\"Data count exceeds offset (%d > %d)\",",
                "\t\t\t\t\t\t\tdata_cnt, data_offset+1);",
                "\t\t\t\t\treturn NULL;",
                "\t\t\t\t}",
                "\t\t\t\t\t    buf_ptr);",
                "\t\t\t\t\tif (buf_ptr->initialized < MAX_WIN_BUF_LEN)",
                "\t\t\t\t\t\tbuf_ptr->initialized++;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-3811",
        "func_name": "wireshark/proto_register_wcp",
        "description": "epan/dissectors/packet-wcp.c in the WCP dissector in Wireshark 1.10.x before 1.10.14 and 1.12.x before 1.12.5 improperly refers to previously processed bytes, which allows remote attackers to cause a denial of service (application crash) via a crafted packet, a different vulnerability than CVE-2015-2188.",
        "git_url": "https://github.com/wireshark/wireshark/commit/a6fc6aa0b4efc1a1c3d7a2e3b5189e888fb6ccc2",
        "commit_title": "wcp: add validations to decompressed_entry",
        "commit_text": " Ensure that a reference to past bytes refers to bytes that actually exist.  Bug: 10978",
        "func_before": "void\nproto_register_wcp(void)\n{\n\tstatic hf_register_info hf[] = {\n\t\t{ &hf_wcp_cmd,\n\t\t  { \"Command\", \"wcp.cmd\", FT_UINT8, BASE_HEX, VALS(cmd_string), WCP_CMD,\n\t\t    \"Compression Command\", HFILL }},\n\t\t{ &hf_wcp_ext_cmd,\n\t\t  { \"Extended Command\", \"wcp.ext_cmd\", FT_UINT8, BASE_HEX, VALS(ext_cmd_string), WCP_EXT_CMD,\n\t\t    \"Extended Compression Command\", HFILL }},\n\t\t{ &hf_wcp_seq,\n\t\t  { \"SEQ\", \"wcp.seq\", FT_UINT16, BASE_HEX, NULL, WCP_SEQ,\n\t\t    \"Sequence Number\", HFILL }},\n\t\t{ &hf_wcp_chksum,\n\t\t  { \"Checksum\", \"wcp.checksum\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Packet Checksum\", HFILL }},\n\t\t{ &hf_wcp_tid,\n\t\t  { \"TID\", \"wcp.tid\", FT_UINT16, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_rev,\n\t\t  { \"Revision\", \"wcp.rev\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_init,\n\t\t  { \"Initiator\", \"wcp.init\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_seq_size,\n\t\t  { \"Seq Size\", \"wcp.seq_size\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Sequence Size\", HFILL }},\n\t\t{ &hf_wcp_alg_cnt,\n\t\t  { \"Alg Count\", \"wcp.alg_cnt\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm Count\", HFILL }},\n\t\t{ &hf_wcp_alg_a,\n\t\t  { \"Alg 1\", \"wcp.alg1\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #1\", HFILL }},\n\t\t{ &hf_wcp_alg_b,\n\t\t  { \"Alg 2\", \"wcp.alg2\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #2\", HFILL }},\n\t\t{ &hf_wcp_alg_c,\n\t\t  { \"Alg 3\", \"wcp.alg3\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #3\", HFILL }},\n\t\t{ &hf_wcp_alg_d,\n\t\t  { \"Alg 4\", \"wcp.alg4\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #4\", HFILL }},\n\t\t{ &hf_wcp_alg,\n\t\t  { \"Alg\", \"wcp.alg\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm\", HFILL }},\n#if 0\n\t\t{ &hf_wcp_rexmit,\n\t\t  { \"Rexmit\", \"wcp.rexmit\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Retransmit\", HFILL }},\n#endif\n\t\t{ &hf_wcp_hist_size,\n\t\t  { \"History\", \"wcp.hist\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"History Size\", HFILL }},\n\t\t{ &hf_wcp_ppc,\n\t\t  { \"PerPackComp\", \"wcp.ppc\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Per Packet Compression\", HFILL }},\n\t\t{ &hf_wcp_pib,\n\t\t  { \"PIB\", \"wcp.pib\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_compressed_data,\n\t\t  { \"Compressed Data\", \"wcp.compressed_data\", FT_NONE, BASE_NONE, NULL, 0,\n\t\t    \"Raw compressed data\", HFILL }},\n\t\t{ &hf_wcp_comp_bits,\n\t\t  { \"Compress Flag\", \"wcp.flag\", FT_UINT8, BASE_HEX, NULL, 0,\n\t\t    \"Compressed byte flag\", HFILL }},\n#if 0\n\t\t{ &hf_wcp_comp_marker,\n\t\t  { \"Compress Marker\", \"wcp.mark\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Compressed marker\", HFILL }},\n#endif\n\t\t{ &hf_wcp_offset,\n\t\t  { \"Source offset\", \"wcp.off\", FT_UINT16, BASE_HEX, NULL, WCP_OFFSET_MASK,\n\t\t    \"Data source offset\", HFILL }},\n\t\t{ &hf_wcp_short_len,\n\t\t  { \"Compress Length\", \"wcp.short_len\", FT_UINT8, BASE_HEX, NULL, 0xf0,\n\t\t    \"Compressed length\", HFILL }},\n\t\t{ &hf_wcp_long_len,\n\t\t  { \"Compress Length\", \"wcp.long_len\", FT_UINT8, BASE_HEX, NULL, 0,\n\t\t    \"Compressed length\", HFILL }},\n\t\t{ &hf_wcp_long_run,\n\t\t  { \"Long Compression\", \"wcp.long_comp\", FT_BYTES, BASE_NONE, NULL, 0,\n\t\t    \"Long Compression type\", HFILL }},\n\t\t{ &hf_wcp_short_run,\n\t\t  { \"Short Compression\", \"wcp.short_comp\", FT_BYTES, BASE_NONE, NULL, 0,\n\t\t    \"Short Compression type\", HFILL }},\n\n\t};\n\n\n\tstatic gint *ett[] = {\n\t\t&ett_wcp,\n\t\t&ett_wcp_comp_data,\n\t\t&ett_wcp_field,\n\t};\n\n\tstatic ei_register_info ei[] = {\n\t\t{ &ei_wcp_compressed_data_exceeds, { \"wcp.compressed_data.exceeds\", PI_MALFORMED, PI_ERROR, \"Compressed data exceeds maximum buffer length\", EXPFILL }},\n\t\t{ &ei_wcp_uncompressed_data_exceeds, { \"wcp.uncompressed_data.exceeds\", PI_MALFORMED, PI_ERROR, \"Uncompressed data exceeds maximum buffer length\", EXPFILL }},\n\t};\n\n\texpert_module_t* expert_wcp;\n\n\tproto_wcp = proto_register_protocol (\"Wellfleet Compression\", \"WCP\", \"wcp\");\n\tproto_register_field_array (proto_wcp, hf, array_length(hf));\n\tproto_register_subtree_array(ett, array_length(ett));\n\texpert_wcp = expert_register_protocol(proto_wcp);\n\texpert_register_field_array(expert_wcp, ei, array_length(ei));\n}",
        "func": "void\nproto_register_wcp(void)\n{\n\tstatic hf_register_info hf[] = {\n\t\t{ &hf_wcp_cmd,\n\t\t  { \"Command\", \"wcp.cmd\", FT_UINT8, BASE_HEX, VALS(cmd_string), WCP_CMD,\n\t\t    \"Compression Command\", HFILL }},\n\t\t{ &hf_wcp_ext_cmd,\n\t\t  { \"Extended Command\", \"wcp.ext_cmd\", FT_UINT8, BASE_HEX, VALS(ext_cmd_string), WCP_EXT_CMD,\n\t\t    \"Extended Compression Command\", HFILL }},\n\t\t{ &hf_wcp_seq,\n\t\t  { \"SEQ\", \"wcp.seq\", FT_UINT16, BASE_HEX, NULL, WCP_SEQ,\n\t\t    \"Sequence Number\", HFILL }},\n\t\t{ &hf_wcp_chksum,\n\t\t  { \"Checksum\", \"wcp.checksum\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Packet Checksum\", HFILL }},\n\t\t{ &hf_wcp_tid,\n\t\t  { \"TID\", \"wcp.tid\", FT_UINT16, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_rev,\n\t\t  { \"Revision\", \"wcp.rev\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_init,\n\t\t  { \"Initiator\", \"wcp.init\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_seq_size,\n\t\t  { \"Seq Size\", \"wcp.seq_size\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Sequence Size\", HFILL }},\n\t\t{ &hf_wcp_alg_cnt,\n\t\t  { \"Alg Count\", \"wcp.alg_cnt\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm Count\", HFILL }},\n\t\t{ &hf_wcp_alg_a,\n\t\t  { \"Alg 1\", \"wcp.alg1\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #1\", HFILL }},\n\t\t{ &hf_wcp_alg_b,\n\t\t  { \"Alg 2\", \"wcp.alg2\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #2\", HFILL }},\n\t\t{ &hf_wcp_alg_c,\n\t\t  { \"Alg 3\", \"wcp.alg3\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #3\", HFILL }},\n\t\t{ &hf_wcp_alg_d,\n\t\t  { \"Alg 4\", \"wcp.alg4\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm #4\", HFILL }},\n\t\t{ &hf_wcp_alg,\n\t\t  { \"Alg\", \"wcp.alg\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Algorithm\", HFILL }},\n#if 0\n\t\t{ &hf_wcp_rexmit,\n\t\t  { \"Rexmit\", \"wcp.rexmit\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Retransmit\", HFILL }},\n#endif\n\t\t{ &hf_wcp_hist_size,\n\t\t  { \"History\", \"wcp.hist\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"History Size\", HFILL }},\n\t\t{ &hf_wcp_ppc,\n\t\t  { \"PerPackComp\", \"wcp.ppc\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Per Packet Compression\", HFILL }},\n\t\t{ &hf_wcp_pib,\n\t\t  { \"PIB\", \"wcp.pib\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    NULL, HFILL }},\n\t\t{ &hf_wcp_compressed_data,\n\t\t  { \"Compressed Data\", \"wcp.compressed_data\", FT_NONE, BASE_NONE, NULL, 0,\n\t\t    \"Raw compressed data\", HFILL }},\n\t\t{ &hf_wcp_comp_bits,\n\t\t  { \"Compress Flag\", \"wcp.flag\", FT_UINT8, BASE_HEX, NULL, 0,\n\t\t    \"Compressed byte flag\", HFILL }},\n#if 0\n\t\t{ &hf_wcp_comp_marker,\n\t\t  { \"Compress Marker\", \"wcp.mark\", FT_UINT8, BASE_DEC, NULL, 0,\n\t\t    \"Compressed marker\", HFILL }},\n#endif\n\t\t{ &hf_wcp_offset,\n\t\t  { \"Source offset\", \"wcp.off\", FT_UINT16, BASE_HEX, NULL, WCP_OFFSET_MASK,\n\t\t    \"Data source offset\", HFILL }},\n\t\t{ &hf_wcp_short_len,\n\t\t  { \"Compress Length\", \"wcp.short_len\", FT_UINT8, BASE_HEX, NULL, 0xf0,\n\t\t    \"Compressed length\", HFILL }},\n\t\t{ &hf_wcp_long_len,\n\t\t  { \"Compress Length\", \"wcp.long_len\", FT_UINT8, BASE_HEX, NULL, 0,\n\t\t    \"Compressed length\", HFILL }},\n\t\t{ &hf_wcp_long_run,\n\t\t  { \"Long Compression\", \"wcp.long_comp\", FT_BYTES, BASE_NONE, NULL, 0,\n\t\t    \"Long Compression type\", HFILL }},\n\t\t{ &hf_wcp_short_run,\n\t\t  { \"Short Compression\", \"wcp.short_comp\", FT_BYTES, BASE_NONE, NULL, 0,\n\t\t    \"Short Compression type\", HFILL }},\n\n\t};\n\n\n\tstatic gint *ett[] = {\n\t\t&ett_wcp,\n\t\t&ett_wcp_comp_data,\n\t\t&ett_wcp_field,\n\t};\n\n\tstatic ei_register_info ei[] = {\n\t\t{ &ei_wcp_compressed_data_exceeds, { \"wcp.compressed_data.exceeds\", PI_MALFORMED, PI_ERROR, \"Compressed data exceeds maximum buffer length\", EXPFILL }},\n\t\t{ &ei_wcp_uncompressed_data_exceeds, { \"wcp.uncompressed_data.exceeds\", PI_MALFORMED, PI_ERROR, \"Uncompressed data exceeds maximum buffer length\", EXPFILL }},\n\t\t{ &ei_wcp_invalid_window_offset, { \"wcp.off.invalid\", PI_MALFORMED, PI_ERROR, \"Offset points outside of visible window\", EXPFILL }},\n\t\t{ &ei_wcp_invalid_match_length, { \"wcp.len.invalid\", PI_MALFORMED, PI_ERROR, \"Length greater than offset\", EXPFILL }},\n\t};\n\n\texpert_module_t* expert_wcp;\n\n\tproto_wcp = proto_register_protocol (\"Wellfleet Compression\", \"WCP\", \"wcp\");\n\tproto_register_field_array (proto_wcp, hf, array_length(hf));\n\tproto_register_subtree_array(ett, array_length(ett));\n\texpert_wcp = expert_register_protocol(proto_wcp);\n\texpert_register_field_array(expert_wcp, ei, array_length(ei));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -97,6 +97,8 @@\n \tstatic ei_register_info ei[] = {\n \t\t{ &ei_wcp_compressed_data_exceeds, { \"wcp.compressed_data.exceeds\", PI_MALFORMED, PI_ERROR, \"Compressed data exceeds maximum buffer length\", EXPFILL }},\n \t\t{ &ei_wcp_uncompressed_data_exceeds, { \"wcp.uncompressed_data.exceeds\", PI_MALFORMED, PI_ERROR, \"Uncompressed data exceeds maximum buffer length\", EXPFILL }},\n+\t\t{ &ei_wcp_invalid_window_offset, { \"wcp.off.invalid\", PI_MALFORMED, PI_ERROR, \"Offset points outside of visible window\", EXPFILL }},\n+\t\t{ &ei_wcp_invalid_match_length, { \"wcp.len.invalid\", PI_MALFORMED, PI_ERROR, \"Length greater than offset\", EXPFILL }},\n \t};\n \n \texpert_module_t* expert_wcp;",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "\t\t{ &ei_wcp_invalid_window_offset, { \"wcp.off.invalid\", PI_MALFORMED, PI_ERROR, \"Offset points outside of visible window\", EXPFILL }},",
                "\t\t{ &ei_wcp_invalid_match_length, { \"wcp.len.invalid\", PI_MALFORMED, PI_ERROR, \"Length greater than offset\", EXPFILL }},"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-2922",
        "func_name": "torvalds/linux/ndisc_router_discovery",
        "description": "The ndisc_router_discovery function in net/ipv6/ndisc.c in the Neighbor Discovery (ND) protocol implementation in the IPv6 stack in the Linux kernel before 3.19.6 allows remote attackers to reconfigure a hop-limit setting via a small hop_limit value in a Router Advertisement (RA) message.",
        "git_url": "https://github.com/torvalds/linux/commit/6fd99094de2b83d1d4c8457f2c83483b2828e75a",
        "commit_title": "ipv6: Don't reduce hop limit for an interface",
        "commit_text": " A local route may have a lower hop_limit set than global routes do.  RFC 3756, Section 4.2.7, \"Parameter Spoofing\"  >   1.  The attacker includes a Current Hop Limit of one or another small >       number which the attacker knows will cause legitimate packets to >       be dropped before they reach their destination.  >   As an example, one possible approach to mitigate this threat is to >   ignore very small hop limits.  The nodes could implement a >   configurable minimum hop limit, and ignore attempts to set it below >   said limit. ",
        "func_before": "static void ndisc_router_discovery(struct sk_buff *skb)\n{\n\tstruct ra_msg *ra_msg = (struct ra_msg *)skb_transport_header(skb);\n\tstruct neighbour *neigh = NULL;\n\tstruct inet6_dev *in6_dev;\n\tstruct rt6_info *rt = NULL;\n\tint lifetime;\n\tstruct ndisc_options ndopts;\n\tint optlen;\n\tunsigned int pref = 0;\n\n\t__u8 *opt = (__u8 *)(ra_msg + 1);\n\n\toptlen = (skb_tail_pointer(skb) - skb_transport_header(skb)) -\n\t\tsizeof(struct ra_msg);\n\n\tND_PRINTK(2, info,\n\t\t  \"RA: %s, dev: %s\\n\",\n\t\t  __func__, skb->dev->name);\n\tif (!(ipv6_addr_type(&ipv6_hdr(skb)->saddr) & IPV6_ADDR_LINKLOCAL)) {\n\t\tND_PRINTK(2, warn, \"RA: source address is not link-local\\n\");\n\t\treturn;\n\t}\n\tif (optlen < 0) {\n\t\tND_PRINTK(2, warn, \"RA: packet too short\\n\");\n\t\treturn;\n\t}\n\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\tif (skb->ndisc_nodetype == NDISC_NODETYPE_HOST) {\n\t\tND_PRINTK(2, warn, \"RA: from host or unauthorized router\\n\");\n\t\treturn;\n\t}\n#endif\n\n\t/*\n\t *\tset the RA_RECV flag in the interface\n\t */\n\n\tin6_dev = __in6_dev_get(skb->dev);\n\tif (in6_dev == NULL) {\n\t\tND_PRINTK(0, err, \"RA: can't find inet6 device for %s\\n\",\n\t\t\t  skb->dev->name);\n\t\treturn;\n\t}\n\n\tif (!ndisc_parse_options(opt, optlen, &ndopts)) {\n\t\tND_PRINTK(2, warn, \"RA: invalid ND options\\n\");\n\t\treturn;\n\t}\n\n\tif (!ipv6_accept_ra(in6_dev)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, did not accept ra for dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto skip_linkparms;\n\t}\n\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\t/* skip link-specific parameters from interior routers */\n\tif (skb->ndisc_nodetype == NDISC_NODETYPE_NODEFAULT) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, nodetype is NODEFAULT, dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto skip_linkparms;\n\t}\n#endif\n\n\tif (in6_dev->if_flags & IF_RS_SENT) {\n\t\t/*\n\t\t *\tflag that an RA was received after an RS was sent\n\t\t *\tout on this interface.\n\t\t */\n\t\tin6_dev->if_flags |= IF_RA_RCVD;\n\t}\n\n\t/*\n\t * Remember the managed/otherconf flags from most recently\n\t * received RA message (RFC 2462) -- yoshfuji\n\t */\n\tin6_dev->if_flags = (in6_dev->if_flags & ~(IF_RA_MANAGED |\n\t\t\t\tIF_RA_OTHERCONF)) |\n\t\t\t\t(ra_msg->icmph.icmp6_addrconf_managed ?\n\t\t\t\t\tIF_RA_MANAGED : 0) |\n\t\t\t\t(ra_msg->icmph.icmp6_addrconf_other ?\n\t\t\t\t\tIF_RA_OTHERCONF : 0);\n\n\tif (!in6_dev->cnf.accept_ra_defrtr) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, defrtr is false for dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto skip_defrtr;\n\t}\n\n\t/* Do not accept RA with source-addr found on local machine unless\n\t * accept_ra_from_local is set to true.\n\t */\n\tif (!in6_dev->cnf.accept_ra_from_local &&\n\t    ipv6_chk_addr(dev_net(in6_dev->dev), &ipv6_hdr(skb)->saddr,\n\t\t\t  NULL, 0)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA from local address detected on dev: %s: default router ignored\\n\",\n\t\t\t  skb->dev->name);\n\t\tgoto skip_defrtr;\n\t}\n\n\tlifetime = ntohs(ra_msg->icmph.icmp6_rt_lifetime);\n\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\tpref = ra_msg->icmph.icmp6_router_pref;\n\t/* 10b is handled as if it were 00b (medium) */\n\tif (pref == ICMPV6_ROUTER_PREF_INVALID ||\n\t    !in6_dev->cnf.accept_ra_rtr_pref)\n\t\tpref = ICMPV6_ROUTER_PREF_MEDIUM;\n#endif\n\n\trt = rt6_get_dflt_router(&ipv6_hdr(skb)->saddr, skb->dev);\n\n\tif (rt) {\n\t\tneigh = dst_neigh_lookup(&rt->dst, &ipv6_hdr(skb)->saddr);\n\t\tif (!neigh) {\n\t\t\tND_PRINTK(0, err,\n\t\t\t\t  \"RA: %s got default router without neighbour\\n\",\n\t\t\t\t  __func__);\n\t\t\tip6_rt_put(rt);\n\t\t\treturn;\n\t\t}\n\t}\n\tif (rt && lifetime == 0) {\n\t\tip6_del_rt(rt);\n\t\trt = NULL;\n\t}\n\n\tND_PRINTK(3, info, \"RA: rt: %p  lifetime: %d, for dev: %s\\n\",\n\t\t  rt, lifetime, skb->dev->name);\n\tif (rt == NULL && lifetime) {\n\t\tND_PRINTK(3, info, \"RA: adding default router\\n\");\n\n\t\trt = rt6_add_dflt_router(&ipv6_hdr(skb)->saddr, skb->dev, pref);\n\t\tif (rt == NULL) {\n\t\t\tND_PRINTK(0, err,\n\t\t\t\t  \"RA: %s failed to add default route\\n\",\n\t\t\t\t  __func__);\n\t\t\treturn;\n\t\t}\n\n\t\tneigh = dst_neigh_lookup(&rt->dst, &ipv6_hdr(skb)->saddr);\n\t\tif (neigh == NULL) {\n\t\t\tND_PRINTK(0, err,\n\t\t\t\t  \"RA: %s got default router without neighbour\\n\",\n\t\t\t\t  __func__);\n\t\t\tip6_rt_put(rt);\n\t\t\treturn;\n\t\t}\n\t\tneigh->flags |= NTF_ROUTER;\n\t} else if (rt) {\n\t\trt->rt6i_flags = (rt->rt6i_flags & ~RTF_PREF_MASK) | RTF_PREF(pref);\n\t}\n\n\tif (rt)\n\t\trt6_set_expires(rt, jiffies + (HZ * lifetime));\n\tif (ra_msg->icmph.icmp6_hop_limit) {\n\t\tin6_dev->cnf.hop_limit = ra_msg->icmph.icmp6_hop_limit;\n\t\tif (rt)\n\t\t\tdst_metric_set(&rt->dst, RTAX_HOPLIMIT,\n\t\t\t\t       ra_msg->icmph.icmp6_hop_limit);\n\t}\n\nskip_defrtr:\n\n\t/*\n\t *\tUpdate Reachable Time and Retrans Timer\n\t */\n\n\tif (in6_dev->nd_parms) {\n\t\tunsigned long rtime = ntohl(ra_msg->retrans_timer);\n\n\t\tif (rtime && rtime/1000 < MAX_SCHEDULE_TIMEOUT/HZ) {\n\t\t\trtime = (rtime*HZ)/1000;\n\t\t\tif (rtime < HZ/10)\n\t\t\t\trtime = HZ/10;\n\t\t\tNEIGH_VAR_SET(in6_dev->nd_parms, RETRANS_TIME, rtime);\n\t\t\tin6_dev->tstamp = jiffies;\n\t\t\tinet6_ifinfo_notify(RTM_NEWLINK, in6_dev);\n\t\t}\n\n\t\trtime = ntohl(ra_msg->reachable_time);\n\t\tif (rtime && rtime/1000 < MAX_SCHEDULE_TIMEOUT/(3*HZ)) {\n\t\t\trtime = (rtime*HZ)/1000;\n\n\t\t\tif (rtime < HZ/10)\n\t\t\t\trtime = HZ/10;\n\n\t\t\tif (rtime != NEIGH_VAR(in6_dev->nd_parms, BASE_REACHABLE_TIME)) {\n\t\t\t\tNEIGH_VAR_SET(in6_dev->nd_parms,\n\t\t\t\t\t      BASE_REACHABLE_TIME, rtime);\n\t\t\t\tNEIGH_VAR_SET(in6_dev->nd_parms,\n\t\t\t\t\t      GC_STALETIME, 3 * rtime);\n\t\t\t\tin6_dev->nd_parms->reachable_time = neigh_rand_reach_time(rtime);\n\t\t\t\tin6_dev->tstamp = jiffies;\n\t\t\t\tinet6_ifinfo_notify(RTM_NEWLINK, in6_dev);\n\t\t\t}\n\t\t}\n\t}\n\nskip_linkparms:\n\n\t/*\n\t *\tProcess options.\n\t */\n\n\tif (!neigh)\n\t\tneigh = __neigh_lookup(&nd_tbl, &ipv6_hdr(skb)->saddr,\n\t\t\t\t       skb->dev, 1);\n\tif (neigh) {\n\t\tu8 *lladdr = NULL;\n\t\tif (ndopts.nd_opts_src_lladdr) {\n\t\t\tlladdr = ndisc_opt_addr_data(ndopts.nd_opts_src_lladdr,\n\t\t\t\t\t\t     skb->dev);\n\t\t\tif (!lladdr) {\n\t\t\t\tND_PRINTK(2, warn,\n\t\t\t\t\t  \"RA: invalid link-layer address length\\n\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tneigh_update(neigh, lladdr, NUD_STALE,\n\t\t\t     NEIGH_UPDATE_F_WEAK_OVERRIDE|\n\t\t\t     NEIGH_UPDATE_F_OVERRIDE|\n\t\t\t     NEIGH_UPDATE_F_OVERRIDE_ISROUTER|\n\t\t\t     NEIGH_UPDATE_F_ISROUTER);\n\t}\n\n\tif (!ipv6_accept_ra(in6_dev)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, accept_ra is false for dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto out;\n\t}\n\n#ifdef CONFIG_IPV6_ROUTE_INFO\n\tif (!in6_dev->cnf.accept_ra_from_local &&\n\t    ipv6_chk_addr(dev_net(in6_dev->dev), &ipv6_hdr(skb)->saddr,\n\t\t\t  NULL, 0)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA from local address detected on dev: %s: router info ignored.\\n\",\n\t\t\t  skb->dev->name);\n\t\tgoto skip_routeinfo;\n\t}\n\n\tif (in6_dev->cnf.accept_ra_rtr_pref && ndopts.nd_opts_ri) {\n\t\tstruct nd_opt_hdr *p;\n\t\tfor (p = ndopts.nd_opts_ri;\n\t\t     p;\n\t\t     p = ndisc_next_option(p, ndopts.nd_opts_ri_end)) {\n\t\t\tstruct route_info *ri = (struct route_info *)p;\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\t\t\tif (skb->ndisc_nodetype == NDISC_NODETYPE_NODEFAULT &&\n\t\t\t    ri->prefix_len == 0)\n\t\t\t\tcontinue;\n#endif\n\t\t\tif (ri->prefix_len == 0 &&\n\t\t\t    !in6_dev->cnf.accept_ra_defrtr)\n\t\t\t\tcontinue;\n\t\t\tif (ri->prefix_len > in6_dev->cnf.accept_ra_rt_info_max_plen)\n\t\t\t\tcontinue;\n\t\t\trt6_route_rcv(skb->dev, (u8 *)p, (p->nd_opt_len) << 3,\n\t\t\t\t      &ipv6_hdr(skb)->saddr);\n\t\t}\n\t}\n\nskip_routeinfo:\n#endif\n\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\t/* skip link-specific ndopts from interior routers */\n\tif (skb->ndisc_nodetype == NDISC_NODETYPE_NODEFAULT) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, nodetype is NODEFAULT (interior routes), dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto out;\n\t}\n#endif\n\n\tif (in6_dev->cnf.accept_ra_pinfo && ndopts.nd_opts_pi) {\n\t\tstruct nd_opt_hdr *p;\n\t\tfor (p = ndopts.nd_opts_pi;\n\t\t     p;\n\t\t     p = ndisc_next_option(p, ndopts.nd_opts_pi_end)) {\n\t\t\taddrconf_prefix_rcv(skb->dev, (u8 *)p,\n\t\t\t\t\t    (p->nd_opt_len) << 3,\n\t\t\t\t\t    ndopts.nd_opts_src_lladdr != NULL);\n\t\t}\n\t}\n\n\tif (ndopts.nd_opts_mtu && in6_dev->cnf.accept_ra_mtu) {\n\t\t__be32 n;\n\t\tu32 mtu;\n\n\t\tmemcpy(&n, ((u8 *)(ndopts.nd_opts_mtu+1))+2, sizeof(mtu));\n\t\tmtu = ntohl(n);\n\n\t\tif (mtu < IPV6_MIN_MTU || mtu > skb->dev->mtu) {\n\t\t\tND_PRINTK(2, warn, \"RA: invalid mtu: %d\\n\", mtu);\n\t\t} else if (in6_dev->cnf.mtu6 != mtu) {\n\t\t\tin6_dev->cnf.mtu6 = mtu;\n\n\t\t\tif (rt)\n\t\t\t\tdst_metric_set(&rt->dst, RTAX_MTU, mtu);\n\n\t\t\trt6_mtu_change(skb->dev, mtu);\n\t\t}\n\t}\n\n\tif (ndopts.nd_useropts) {\n\t\tstruct nd_opt_hdr *p;\n\t\tfor (p = ndopts.nd_useropts;\n\t\t     p;\n\t\t     p = ndisc_next_useropt(p, ndopts.nd_useropts_end)) {\n\t\t\tndisc_ra_useropt(skb, p);\n\t\t}\n\t}\n\n\tif (ndopts.nd_opts_tgt_lladdr || ndopts.nd_opts_rh) {\n\t\tND_PRINTK(2, warn, \"RA: invalid RA options\\n\");\n\t}\nout:\n\tip6_rt_put(rt);\n\tif (neigh)\n\t\tneigh_release(neigh);\n}",
        "func": "static void ndisc_router_discovery(struct sk_buff *skb)\n{\n\tstruct ra_msg *ra_msg = (struct ra_msg *)skb_transport_header(skb);\n\tstruct neighbour *neigh = NULL;\n\tstruct inet6_dev *in6_dev;\n\tstruct rt6_info *rt = NULL;\n\tint lifetime;\n\tstruct ndisc_options ndopts;\n\tint optlen;\n\tunsigned int pref = 0;\n\n\t__u8 *opt = (__u8 *)(ra_msg + 1);\n\n\toptlen = (skb_tail_pointer(skb) - skb_transport_header(skb)) -\n\t\tsizeof(struct ra_msg);\n\n\tND_PRINTK(2, info,\n\t\t  \"RA: %s, dev: %s\\n\",\n\t\t  __func__, skb->dev->name);\n\tif (!(ipv6_addr_type(&ipv6_hdr(skb)->saddr) & IPV6_ADDR_LINKLOCAL)) {\n\t\tND_PRINTK(2, warn, \"RA: source address is not link-local\\n\");\n\t\treturn;\n\t}\n\tif (optlen < 0) {\n\t\tND_PRINTK(2, warn, \"RA: packet too short\\n\");\n\t\treturn;\n\t}\n\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\tif (skb->ndisc_nodetype == NDISC_NODETYPE_HOST) {\n\t\tND_PRINTK(2, warn, \"RA: from host or unauthorized router\\n\");\n\t\treturn;\n\t}\n#endif\n\n\t/*\n\t *\tset the RA_RECV flag in the interface\n\t */\n\n\tin6_dev = __in6_dev_get(skb->dev);\n\tif (in6_dev == NULL) {\n\t\tND_PRINTK(0, err, \"RA: can't find inet6 device for %s\\n\",\n\t\t\t  skb->dev->name);\n\t\treturn;\n\t}\n\n\tif (!ndisc_parse_options(opt, optlen, &ndopts)) {\n\t\tND_PRINTK(2, warn, \"RA: invalid ND options\\n\");\n\t\treturn;\n\t}\n\n\tif (!ipv6_accept_ra(in6_dev)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, did not accept ra for dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto skip_linkparms;\n\t}\n\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\t/* skip link-specific parameters from interior routers */\n\tif (skb->ndisc_nodetype == NDISC_NODETYPE_NODEFAULT) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, nodetype is NODEFAULT, dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto skip_linkparms;\n\t}\n#endif\n\n\tif (in6_dev->if_flags & IF_RS_SENT) {\n\t\t/*\n\t\t *\tflag that an RA was received after an RS was sent\n\t\t *\tout on this interface.\n\t\t */\n\t\tin6_dev->if_flags |= IF_RA_RCVD;\n\t}\n\n\t/*\n\t * Remember the managed/otherconf flags from most recently\n\t * received RA message (RFC 2462) -- yoshfuji\n\t */\n\tin6_dev->if_flags = (in6_dev->if_flags & ~(IF_RA_MANAGED |\n\t\t\t\tIF_RA_OTHERCONF)) |\n\t\t\t\t(ra_msg->icmph.icmp6_addrconf_managed ?\n\t\t\t\t\tIF_RA_MANAGED : 0) |\n\t\t\t\t(ra_msg->icmph.icmp6_addrconf_other ?\n\t\t\t\t\tIF_RA_OTHERCONF : 0);\n\n\tif (!in6_dev->cnf.accept_ra_defrtr) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, defrtr is false for dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto skip_defrtr;\n\t}\n\n\t/* Do not accept RA with source-addr found on local machine unless\n\t * accept_ra_from_local is set to true.\n\t */\n\tif (!in6_dev->cnf.accept_ra_from_local &&\n\t    ipv6_chk_addr(dev_net(in6_dev->dev), &ipv6_hdr(skb)->saddr,\n\t\t\t  NULL, 0)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA from local address detected on dev: %s: default router ignored\\n\",\n\t\t\t  skb->dev->name);\n\t\tgoto skip_defrtr;\n\t}\n\n\tlifetime = ntohs(ra_msg->icmph.icmp6_rt_lifetime);\n\n#ifdef CONFIG_IPV6_ROUTER_PREF\n\tpref = ra_msg->icmph.icmp6_router_pref;\n\t/* 10b is handled as if it were 00b (medium) */\n\tif (pref == ICMPV6_ROUTER_PREF_INVALID ||\n\t    !in6_dev->cnf.accept_ra_rtr_pref)\n\t\tpref = ICMPV6_ROUTER_PREF_MEDIUM;\n#endif\n\n\trt = rt6_get_dflt_router(&ipv6_hdr(skb)->saddr, skb->dev);\n\n\tif (rt) {\n\t\tneigh = dst_neigh_lookup(&rt->dst, &ipv6_hdr(skb)->saddr);\n\t\tif (!neigh) {\n\t\t\tND_PRINTK(0, err,\n\t\t\t\t  \"RA: %s got default router without neighbour\\n\",\n\t\t\t\t  __func__);\n\t\t\tip6_rt_put(rt);\n\t\t\treturn;\n\t\t}\n\t}\n\tif (rt && lifetime == 0) {\n\t\tip6_del_rt(rt);\n\t\trt = NULL;\n\t}\n\n\tND_PRINTK(3, info, \"RA: rt: %p  lifetime: %d, for dev: %s\\n\",\n\t\t  rt, lifetime, skb->dev->name);\n\tif (rt == NULL && lifetime) {\n\t\tND_PRINTK(3, info, \"RA: adding default router\\n\");\n\n\t\trt = rt6_add_dflt_router(&ipv6_hdr(skb)->saddr, skb->dev, pref);\n\t\tif (rt == NULL) {\n\t\t\tND_PRINTK(0, err,\n\t\t\t\t  \"RA: %s failed to add default route\\n\",\n\t\t\t\t  __func__);\n\t\t\treturn;\n\t\t}\n\n\t\tneigh = dst_neigh_lookup(&rt->dst, &ipv6_hdr(skb)->saddr);\n\t\tif (neigh == NULL) {\n\t\t\tND_PRINTK(0, err,\n\t\t\t\t  \"RA: %s got default router without neighbour\\n\",\n\t\t\t\t  __func__);\n\t\t\tip6_rt_put(rt);\n\t\t\treturn;\n\t\t}\n\t\tneigh->flags |= NTF_ROUTER;\n\t} else if (rt) {\n\t\trt->rt6i_flags = (rt->rt6i_flags & ~RTF_PREF_MASK) | RTF_PREF(pref);\n\t}\n\n\tif (rt)\n\t\trt6_set_expires(rt, jiffies + (HZ * lifetime));\n\tif (ra_msg->icmph.icmp6_hop_limit) {\n\t\t/* Only set hop_limit on the interface if it is higher than\n\t\t * the current hop_limit.\n\t\t */\n\t\tif (in6_dev->cnf.hop_limit < ra_msg->icmph.icmp6_hop_limit) {\n\t\t\tin6_dev->cnf.hop_limit = ra_msg->icmph.icmp6_hop_limit;\n\t\t} else {\n\t\t\tND_PRINTK(2, warn, \"RA: Got route advertisement with lower hop_limit than current\\n\");\n\t\t}\n\t\tif (rt)\n\t\t\tdst_metric_set(&rt->dst, RTAX_HOPLIMIT,\n\t\t\t\t       ra_msg->icmph.icmp6_hop_limit);\n\t}\n\nskip_defrtr:\n\n\t/*\n\t *\tUpdate Reachable Time and Retrans Timer\n\t */\n\n\tif (in6_dev->nd_parms) {\n\t\tunsigned long rtime = ntohl(ra_msg->retrans_timer);\n\n\t\tif (rtime && rtime/1000 < MAX_SCHEDULE_TIMEOUT/HZ) {\n\t\t\trtime = (rtime*HZ)/1000;\n\t\t\tif (rtime < HZ/10)\n\t\t\t\trtime = HZ/10;\n\t\t\tNEIGH_VAR_SET(in6_dev->nd_parms, RETRANS_TIME, rtime);\n\t\t\tin6_dev->tstamp = jiffies;\n\t\t\tinet6_ifinfo_notify(RTM_NEWLINK, in6_dev);\n\t\t}\n\n\t\trtime = ntohl(ra_msg->reachable_time);\n\t\tif (rtime && rtime/1000 < MAX_SCHEDULE_TIMEOUT/(3*HZ)) {\n\t\t\trtime = (rtime*HZ)/1000;\n\n\t\t\tif (rtime < HZ/10)\n\t\t\t\trtime = HZ/10;\n\n\t\t\tif (rtime != NEIGH_VAR(in6_dev->nd_parms, BASE_REACHABLE_TIME)) {\n\t\t\t\tNEIGH_VAR_SET(in6_dev->nd_parms,\n\t\t\t\t\t      BASE_REACHABLE_TIME, rtime);\n\t\t\t\tNEIGH_VAR_SET(in6_dev->nd_parms,\n\t\t\t\t\t      GC_STALETIME, 3 * rtime);\n\t\t\t\tin6_dev->nd_parms->reachable_time = neigh_rand_reach_time(rtime);\n\t\t\t\tin6_dev->tstamp = jiffies;\n\t\t\t\tinet6_ifinfo_notify(RTM_NEWLINK, in6_dev);\n\t\t\t}\n\t\t}\n\t}\n\nskip_linkparms:\n\n\t/*\n\t *\tProcess options.\n\t */\n\n\tif (!neigh)\n\t\tneigh = __neigh_lookup(&nd_tbl, &ipv6_hdr(skb)->saddr,\n\t\t\t\t       skb->dev, 1);\n\tif (neigh) {\n\t\tu8 *lladdr = NULL;\n\t\tif (ndopts.nd_opts_src_lladdr) {\n\t\t\tlladdr = ndisc_opt_addr_data(ndopts.nd_opts_src_lladdr,\n\t\t\t\t\t\t     skb->dev);\n\t\t\tif (!lladdr) {\n\t\t\t\tND_PRINTK(2, warn,\n\t\t\t\t\t  \"RA: invalid link-layer address length\\n\");\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t\tneigh_update(neigh, lladdr, NUD_STALE,\n\t\t\t     NEIGH_UPDATE_F_WEAK_OVERRIDE|\n\t\t\t     NEIGH_UPDATE_F_OVERRIDE|\n\t\t\t     NEIGH_UPDATE_F_OVERRIDE_ISROUTER|\n\t\t\t     NEIGH_UPDATE_F_ISROUTER);\n\t}\n\n\tif (!ipv6_accept_ra(in6_dev)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, accept_ra is false for dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto out;\n\t}\n\n#ifdef CONFIG_IPV6_ROUTE_INFO\n\tif (!in6_dev->cnf.accept_ra_from_local &&\n\t    ipv6_chk_addr(dev_net(in6_dev->dev), &ipv6_hdr(skb)->saddr,\n\t\t\t  NULL, 0)) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA from local address detected on dev: %s: router info ignored.\\n\",\n\t\t\t  skb->dev->name);\n\t\tgoto skip_routeinfo;\n\t}\n\n\tif (in6_dev->cnf.accept_ra_rtr_pref && ndopts.nd_opts_ri) {\n\t\tstruct nd_opt_hdr *p;\n\t\tfor (p = ndopts.nd_opts_ri;\n\t\t     p;\n\t\t     p = ndisc_next_option(p, ndopts.nd_opts_ri_end)) {\n\t\t\tstruct route_info *ri = (struct route_info *)p;\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\t\t\tif (skb->ndisc_nodetype == NDISC_NODETYPE_NODEFAULT &&\n\t\t\t    ri->prefix_len == 0)\n\t\t\t\tcontinue;\n#endif\n\t\t\tif (ri->prefix_len == 0 &&\n\t\t\t    !in6_dev->cnf.accept_ra_defrtr)\n\t\t\t\tcontinue;\n\t\t\tif (ri->prefix_len > in6_dev->cnf.accept_ra_rt_info_max_plen)\n\t\t\t\tcontinue;\n\t\t\trt6_route_rcv(skb->dev, (u8 *)p, (p->nd_opt_len) << 3,\n\t\t\t\t      &ipv6_hdr(skb)->saddr);\n\t\t}\n\t}\n\nskip_routeinfo:\n#endif\n\n#ifdef CONFIG_IPV6_NDISC_NODETYPE\n\t/* skip link-specific ndopts from interior routers */\n\tif (skb->ndisc_nodetype == NDISC_NODETYPE_NODEFAULT) {\n\t\tND_PRINTK(2, info,\n\t\t\t  \"RA: %s, nodetype is NODEFAULT (interior routes), dev: %s\\n\",\n\t\t\t  __func__, skb->dev->name);\n\t\tgoto out;\n\t}\n#endif\n\n\tif (in6_dev->cnf.accept_ra_pinfo && ndopts.nd_opts_pi) {\n\t\tstruct nd_opt_hdr *p;\n\t\tfor (p = ndopts.nd_opts_pi;\n\t\t     p;\n\t\t     p = ndisc_next_option(p, ndopts.nd_opts_pi_end)) {\n\t\t\taddrconf_prefix_rcv(skb->dev, (u8 *)p,\n\t\t\t\t\t    (p->nd_opt_len) << 3,\n\t\t\t\t\t    ndopts.nd_opts_src_lladdr != NULL);\n\t\t}\n\t}\n\n\tif (ndopts.nd_opts_mtu && in6_dev->cnf.accept_ra_mtu) {\n\t\t__be32 n;\n\t\tu32 mtu;\n\n\t\tmemcpy(&n, ((u8 *)(ndopts.nd_opts_mtu+1))+2, sizeof(mtu));\n\t\tmtu = ntohl(n);\n\n\t\tif (mtu < IPV6_MIN_MTU || mtu > skb->dev->mtu) {\n\t\t\tND_PRINTK(2, warn, \"RA: invalid mtu: %d\\n\", mtu);\n\t\t} else if (in6_dev->cnf.mtu6 != mtu) {\n\t\t\tin6_dev->cnf.mtu6 = mtu;\n\n\t\t\tif (rt)\n\t\t\t\tdst_metric_set(&rt->dst, RTAX_MTU, mtu);\n\n\t\t\trt6_mtu_change(skb->dev, mtu);\n\t\t}\n\t}\n\n\tif (ndopts.nd_useropts) {\n\t\tstruct nd_opt_hdr *p;\n\t\tfor (p = ndopts.nd_useropts;\n\t\t     p;\n\t\t     p = ndisc_next_useropt(p, ndopts.nd_useropts_end)) {\n\t\t\tndisc_ra_useropt(skb, p);\n\t\t}\n\t}\n\n\tif (ndopts.nd_opts_tgt_lladdr || ndopts.nd_opts_rh) {\n\t\tND_PRINTK(2, warn, \"RA: invalid RA options\\n\");\n\t}\nout:\n\tip6_rt_put(rt);\n\tif (neigh)\n\t\tneigh_release(neigh);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -160,7 +160,14 @@\n \tif (rt)\n \t\trt6_set_expires(rt, jiffies + (HZ * lifetime));\n \tif (ra_msg->icmph.icmp6_hop_limit) {\n-\t\tin6_dev->cnf.hop_limit = ra_msg->icmph.icmp6_hop_limit;\n+\t\t/* Only set hop_limit on the interface if it is higher than\n+\t\t * the current hop_limit.\n+\t\t */\n+\t\tif (in6_dev->cnf.hop_limit < ra_msg->icmph.icmp6_hop_limit) {\n+\t\t\tin6_dev->cnf.hop_limit = ra_msg->icmph.icmp6_hop_limit;\n+\t\t} else {\n+\t\t\tND_PRINTK(2, warn, \"RA: Got route advertisement with lower hop_limit than current\\n\");\n+\t\t}\n \t\tif (rt)\n \t\t\tdst_metric_set(&rt->dst, RTAX_HOPLIMIT,\n \t\t\t\t       ra_msg->icmph.icmp6_hop_limit);",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tin6_dev->cnf.hop_limit = ra_msg->icmph.icmp6_hop_limit;"
            ],
            "added_lines": [
                "\t\t/* Only set hop_limit on the interface if it is higher than",
                "\t\t * the current hop_limit.",
                "\t\t */",
                "\t\tif (in6_dev->cnf.hop_limit < ra_msg->icmph.icmp6_hop_limit) {",
                "\t\t\tin6_dev->cnf.hop_limit = ra_msg->icmph.icmp6_hop_limit;",
                "\t\t} else {",
                "\t\t\tND_PRINTK(2, warn, \"RA: Got route advertisement with lower hop_limit than current\\n\");",
                "\t\t}"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-4335",
        "func_name": "redis/f_parser",
        "description": "Redis before 2.8.21 and 3.x before 3.0.2 allows remote attackers to execute arbitrary Lua bytecode via the eval command.",
        "git_url": "https://github.com/redis/redis/commit/fdf9d455098f54f7666c702ae464e6ea21e25411",
        "commit_title": "disable loading lua bytecode",
        "commit_text": "",
        "func_before": "static void f_parser (lua_State *L, void *ud) {\n  int i;\n  Proto *tf;\n  Closure *cl;\n  struct SParser *p = cast(struct SParser *, ud);\n  int c = luaZ_lookahead(p->z);\n  luaC_checkGC(L);\n  tf = ((c == LUA_SIGNATURE[0]) ? luaU_undump : luaY_parser)(L, p->z,\n                                                             &p->buff, p->name);\n  cl = luaF_newLclosure(L, tf->nups, hvalue(gt(L)));\n  cl->l.p = tf;\n  for (i = 0; i < tf->nups; i++)  /* initialize eventual upvalues */\n    cl->l.upvals[i] = luaF_newupval(L);\n  setclvalue(L, L->top, cl);\n  incr_top(L);\n}",
        "func": "static void f_parser (lua_State *L, void *ud) {\n  int i;\n  Proto *tf;\n  Closure *cl;\n  struct SParser *p = cast(struct SParser *, ud);\n  int c = luaZ_lookahead(p->z);\n  luaC_checkGC(L);\n  tf = (luaY_parser)(L, p->z,\n                                                             &p->buff, p->name);\n  cl = luaF_newLclosure(L, tf->nups, hvalue(gt(L)));\n  cl->l.p = tf;\n  for (i = 0; i < tf->nups; i++)  /* initialize eventual upvalues */\n    cl->l.upvals[i] = luaF_newupval(L);\n  setclvalue(L, L->top, cl);\n  incr_top(L);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -5,7 +5,7 @@\n   struct SParser *p = cast(struct SParser *, ud);\n   int c = luaZ_lookahead(p->z);\n   luaC_checkGC(L);\n-  tf = ((c == LUA_SIGNATURE[0]) ? luaU_undump : luaY_parser)(L, p->z,\n+  tf = (luaY_parser)(L, p->z,\n                                                              &p->buff, p->name);\n   cl = luaF_newLclosure(L, tf->nups, hvalue(gt(L)));\n   cl->l.p = tf;",
        "diff_line_info": {
            "deleted_lines": [
                "  tf = ((c == LUA_SIGNATURE[0]) ? luaU_undump : luaY_parser)(L, p->z,"
            ],
            "added_lines": [
                "  tf = (luaY_parser)(L, p->z,"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1287",
        "func_name": "chromium/CSSStyleSheetResource::sheetText",
        "description": "Blink, as used in Google Chrome before 44.0.2403.89, enables a quirks-mode exception that limits the cases in which a Cascading Style Sheets (CSS) document is required to have the text/css content type, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to core/fetch/CSSStyleSheetResource.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/0522e0ad97fd5814fc17353f2e373534c4cfebb1",
        "commit_title": "CSS: Drop the quirks-mode exception for CSS MIME types.",
        "commit_text": " This matches Firefox's behavior (though it returns 'transparent' instead of 'rgba(0, 0, 0, 0)', which is a bit annoying).   ",
        "func_before": "const String CSSStyleSheetResource::sheetText(bool enforceMIMEType, bool* hasValidMIMEType) const\n{\n    ASSERT(!isPurgeable());\n\n    if (!m_data || m_data->isEmpty() || !canUseSheet(enforceMIMEType, hasValidMIMEType))\n        return String();\n\n    if (!m_decodedSheetText.isNull())\n        return m_decodedSheetText;\n\n    // Don't cache the decoded text, regenerating is cheap and it can use quite a bit of memory\n    return decodedText();\n}",
        "func": "const String CSSStyleSheetResource::sheetText(bool* hasValidMIMEType) const\n{\n    ASSERT(!isPurgeable());\n\n    if (!m_data || m_data->isEmpty() || !canUseSheet(hasValidMIMEType))\n        return String();\n\n    if (!m_decodedSheetText.isNull())\n        return m_decodedSheetText;\n\n    // Don't cache the decoded text, regenerating is cheap and it can use quite a bit of memory\n    return decodedText();\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,8 +1,8 @@\n-const String CSSStyleSheetResource::sheetText(bool enforceMIMEType, bool* hasValidMIMEType) const\n+const String CSSStyleSheetResource::sheetText(bool* hasValidMIMEType) const\n {\n     ASSERT(!isPurgeable());\n \n-    if (!m_data || m_data->isEmpty() || !canUseSheet(enforceMIMEType, hasValidMIMEType))\n+    if (!m_data || m_data->isEmpty() || !canUseSheet(hasValidMIMEType))\n         return String();\n \n     if (!m_decodedSheetText.isNull())",
        "diff_line_info": {
            "deleted_lines": [
                "const String CSSStyleSheetResource::sheetText(bool enforceMIMEType, bool* hasValidMIMEType) const",
                "    if (!m_data || m_data->isEmpty() || !canUseSheet(enforceMIMEType, hasValidMIMEType))"
            ],
            "added_lines": [
                "const String CSSStyleSheetResource::sheetText(bool* hasValidMIMEType) const",
                "    if (!m_data || m_data->isEmpty() || !canUseSheet(hasValidMIMEType))"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1287",
        "func_name": "chromium/CSSStyleSheetResource::canUseSheet",
        "description": "Blink, as used in Google Chrome before 44.0.2403.89, enables a quirks-mode exception that limits the cases in which a Cascading Style Sheets (CSS) document is required to have the text/css content type, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to core/fetch/CSSStyleSheetResource.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/0522e0ad97fd5814fc17353f2e373534c4cfebb1",
        "commit_title": "CSS: Drop the quirks-mode exception for CSS MIME types.",
        "commit_text": " This matches Firefox's behavior (though it returns 'transparent' instead of 'rgba(0, 0, 0, 0)', which is a bit annoying).   ",
        "func_before": "bool CSSStyleSheetResource::canUseSheet(bool enforceMIMEType, bool* hasValidMIMEType) const\n{\n    if (errorOccurred())\n        return false;\n\n    if (!enforceMIMEType && !hasValidMIMEType)\n        return true;\n\n    // This check exactly matches Firefox. Note that we grab the Content-Type\n    // header directly because we want to see what the value is BEFORE content\n    // sniffing. Firefox does this by setting a \"type hint\" on the channel.\n    // This implementation should be observationally equivalent.\n    //\n    // This code defaults to allowing the stylesheet for non-HTTP protocols so\n    // folks can use standards mode for local HTML documents.\n    bool typeOK = mimeType().isEmpty() || equalIgnoringCase(mimeType(), \"text/css\") || equalIgnoringCase(mimeType(), \"application/x-unknown-content-type\");\n    if (hasValidMIMEType)\n        *hasValidMIMEType = typeOK;\n    if (!enforceMIMEType)\n        return true;\n    return typeOK;\n}",
        "func": "bool CSSStyleSheetResource::canUseSheet(bool* hasValidMIMEType) const\n{\n    if (errorOccurred())\n        return false;\n\n    // This check exactly matches Firefox. Note that we grab the Content-Type\n    // header directly because we want to see what the value is BEFORE content\n    // sniffing. Firefox does this by setting a \"type hint\" on the channel.\n    // This implementation should be observationally equivalent.\n    //\n    // This code defaults to allowing the stylesheet for non-HTTP protocols so\n    // folks can use standards mode for local HTML documents.\n    bool typeOK = mimeType().isEmpty() || equalIgnoringCase(mimeType(), \"text/css\") || equalIgnoringCase(mimeType(), \"application/x-unknown-content-type\");\n    if (hasValidMIMEType)\n        *hasValidMIMEType = typeOK;\n    return typeOK;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,7 @@\n-bool CSSStyleSheetResource::canUseSheet(bool enforceMIMEType, bool* hasValidMIMEType) const\n+bool CSSStyleSheetResource::canUseSheet(bool* hasValidMIMEType) const\n {\n     if (errorOccurred())\n         return false;\n-\n-    if (!enforceMIMEType && !hasValidMIMEType)\n-        return true;\n \n     // This check exactly matches Firefox. Note that we grab the Content-Type\n     // header directly because we want to see what the value is BEFORE content\n@@ -16,7 +13,5 @@\n     bool typeOK = mimeType().isEmpty() || equalIgnoringCase(mimeType(), \"text/css\") || equalIgnoringCase(mimeType(), \"application/x-unknown-content-type\");\n     if (hasValidMIMEType)\n         *hasValidMIMEType = typeOK;\n-    if (!enforceMIMEType)\n-        return true;\n     return typeOK;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "bool CSSStyleSheetResource::canUseSheet(bool enforceMIMEType, bool* hasValidMIMEType) const",
                "",
                "    if (!enforceMIMEType && !hasValidMIMEType)",
                "        return true;",
                "    if (!enforceMIMEType)",
                "        return true;"
            ],
            "added_lines": [
                "bool CSSStyleSheetResource::canUseSheet(bool* hasValidMIMEType) const"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1287",
        "func_name": "chromium/ProcessingInstruction::setCSSStyleSheet",
        "description": "Blink, as used in Google Chrome before 44.0.2403.89, enables a quirks-mode exception that limits the cases in which a Cascading Style Sheets (CSS) document is required to have the text/css content type, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to core/fetch/CSSStyleSheetResource.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/0522e0ad97fd5814fc17353f2e373534c4cfebb1",
        "commit_title": "CSS: Drop the quirks-mode exception for CSS MIME types.",
        "commit_text": " This matches Firefox's behavior (though it returns 'transparent' instead of 'rgba(0, 0, 0, 0)', which is a bit annoying).   ",
        "func_before": "void ProcessingInstruction::setCSSStyleSheet(const String& href, const KURL& baseURL, const String& charset, const CSSStyleSheetResource* sheet)\n{\n    if (!inDocument()) {\n        ASSERT(!m_sheet);\n        return;\n    }\n\n    ASSERT(m_isCSS);\n    CSSParserContext parserContext(document(), 0, baseURL, charset);\n\n    RefPtrWillBeRawPtr<StyleSheetContents> newSheet = StyleSheetContents::create(href, parserContext);\n\n    RefPtrWillBeRawPtr<CSSStyleSheet> cssSheet = CSSStyleSheet::create(newSheet, this);\n    cssSheet->setDisabled(m_alternate);\n    cssSheet->setTitle(m_title);\n    cssSheet->setMediaQueries(MediaQuerySet::create(m_media));\n\n    m_sheet = cssSheet.release();\n\n    // We don't need the cross-origin security check here because we are\n    // getting the sheet text in \"strict\" mode. This enforces a valid CSS MIME\n    // type.\n    parseStyleSheet(sheet->sheetText(true));\n}",
        "func": "void ProcessingInstruction::setCSSStyleSheet(const String& href, const KURL& baseURL, const String& charset, const CSSStyleSheetResource* sheet)\n{\n    if (!inDocument()) {\n        ASSERT(!m_sheet);\n        return;\n    }\n\n    ASSERT(m_isCSS);\n    CSSParserContext parserContext(document(), 0, baseURL, charset);\n\n    RefPtrWillBeRawPtr<StyleSheetContents> newSheet = StyleSheetContents::create(href, parserContext);\n\n    RefPtrWillBeRawPtr<CSSStyleSheet> cssSheet = CSSStyleSheet::create(newSheet, this);\n    cssSheet->setDisabled(m_alternate);\n    cssSheet->setTitle(m_title);\n    cssSheet->setMediaQueries(MediaQuerySet::create(m_media));\n\n    m_sheet = cssSheet.release();\n\n    // We don't need the cross-origin security check here because we are\n    // getting the sheet text in \"strict\" mode. This enforces a valid CSS MIME\n    // type.\n    parseStyleSheet(sheet->sheetText());\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -20,5 +20,5 @@\n     // We don't need the cross-origin security check here because we are\n     // getting the sheet text in \"strict\" mode. This enforces a valid CSS MIME\n     // type.\n-    parseStyleSheet(sheet->sheetText(true));\n+    parseStyleSheet(sheet->sheetText());\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    parseStyleSheet(sheet->sheetText(true));"
            ],
            "added_lines": [
                "    parseStyleSheet(sheet->sheetText());"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1287",
        "func_name": "chromium/InspectorPageAgent::cachedResourceContent",
        "description": "Blink, as used in Google Chrome before 44.0.2403.89, enables a quirks-mode exception that limits the cases in which a Cascading Style Sheets (CSS) document is required to have the text/css content type, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to core/fetch/CSSStyleSheetResource.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/0522e0ad97fd5814fc17353f2e373534c4cfebb1",
        "commit_title": "CSS: Drop the quirks-mode exception for CSS MIME types.",
        "commit_text": " This matches Firefox's behavior (though it returns 'transparent' instead of 'rgba(0, 0, 0, 0)', which is a bit annoying).   ",
        "func_before": "bool InspectorPageAgent::cachedResourceContent(Resource* cachedResource, String* result, bool* base64Encoded)\n{\n    bool hasZeroSize;\n    bool prepared = prepareResourceBuffer(cachedResource, &hasZeroSize);\n    if (!prepared)\n        return false;\n\n    if (!hasTextContent(cachedResource))\n        return encodeCachedResourceContent(cachedResource, hasZeroSize, result, base64Encoded);\n    *base64Encoded = false;\n\n    if (hasZeroSize) {\n        *result = \"\";\n        return true;\n    }\n\n    if (cachedResource) {\n        switch (cachedResource->type()) {\n        case Resource::CSSStyleSheet:\n            *result = toCSSStyleSheetResource(cachedResource)->sheetText(false);\n            return true;\n        case Resource::Script:\n            *result = cachedResource->resourceBuffer() ? toScriptResource(cachedResource)->decodedText() : toScriptResource(cachedResource)->script();\n            return true;\n        case Resource::ImportResource: // Fall through.\n        case Resource::Raw: {\n            SharedBuffer* buffer = cachedResource->resourceBuffer();\n            if (!buffer)\n                return false;\n            OwnPtr<TextResourceDecoder> decoder = InspectorPageAgent::createResourceTextDecoder(cachedResource->response().mimeType(), cachedResource->response().textEncodingName());\n            if (!decoder)\n                return encodeCachedResourceContent(cachedResource, hasZeroSize, result, base64Encoded);\n            String content = decoder->decode(buffer->data(), buffer->size());\n            *result = content + decoder->flush();\n            return true;\n        }\n        default:\n            SharedBuffer* buffer = cachedResource->resourceBuffer();\n            return decodeBuffer(buffer ? buffer->data() : nullptr, buffer ? buffer->size() : 0, cachedResource->response().textEncodingName(), result);\n        }\n    }\n    return false;\n}",
        "func": "bool InspectorPageAgent::cachedResourceContent(Resource* cachedResource, String* result, bool* base64Encoded)\n{\n    bool hasZeroSize;\n    bool prepared = prepareResourceBuffer(cachedResource, &hasZeroSize);\n    if (!prepared)\n        return false;\n\n    if (!hasTextContent(cachedResource))\n        return encodeCachedResourceContent(cachedResource, hasZeroSize, result, base64Encoded);\n    *base64Encoded = false;\n\n    if (hasZeroSize) {\n        *result = \"\";\n        return true;\n    }\n\n    if (cachedResource) {\n        switch (cachedResource->type()) {\n        case Resource::CSSStyleSheet:\n            *result = toCSSStyleSheetResource(cachedResource)->sheetText();\n            return true;\n        case Resource::Script:\n            *result = cachedResource->resourceBuffer() ? toScriptResource(cachedResource)->decodedText() : toScriptResource(cachedResource)->script();\n            return true;\n        case Resource::ImportResource: // Fall through.\n        case Resource::Raw: {\n            SharedBuffer* buffer = cachedResource->resourceBuffer();\n            if (!buffer)\n                return false;\n            OwnPtr<TextResourceDecoder> decoder = InspectorPageAgent::createResourceTextDecoder(cachedResource->response().mimeType(), cachedResource->response().textEncodingName());\n            if (!decoder)\n                return encodeCachedResourceContent(cachedResource, hasZeroSize, result, base64Encoded);\n            String content = decoder->decode(buffer->data(), buffer->size());\n            *result = content + decoder->flush();\n            return true;\n        }\n        default:\n            SharedBuffer* buffer = cachedResource->resourceBuffer();\n            return decodeBuffer(buffer ? buffer->data() : nullptr, buffer ? buffer->size() : 0, cachedResource->response().textEncodingName(), result);\n        }\n    }\n    return false;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -17,7 +17,7 @@\n     if (cachedResource) {\n         switch (cachedResource->type()) {\n         case Resource::CSSStyleSheet:\n-            *result = toCSSStyleSheetResource(cachedResource)->sheetText(false);\n+            *result = toCSSStyleSheetResource(cachedResource)->sheetText();\n             return true;\n         case Resource::Script:\n             *result = cachedResource->resourceBuffer() ? toScriptResource(cachedResource)->decodedText() : toScriptResource(cachedResource)->script();",
        "diff_line_info": {
            "deleted_lines": [
                "            *result = toCSSStyleSheetResource(cachedResource)->sheetText(false);"
            ],
            "added_lines": [
                "            *result = toCSSStyleSheetResource(cachedResource)->sheetText();"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1287",
        "func_name": "chromium/StyleSheetContents::parseAuthorStyleSheet",
        "description": "Blink, as used in Google Chrome before 44.0.2403.89, enables a quirks-mode exception that limits the cases in which a Cascading Style Sheets (CSS) document is required to have the text/css content type, which allows remote attackers to bypass the Same Origin Policy via a crafted web site, related to core/fetch/CSSStyleSheetResource.cpp.",
        "git_url": "https://github.com/chromium/chromium/commit/0522e0ad97fd5814fc17353f2e373534c4cfebb1",
        "commit_title": "CSS: Drop the quirks-mode exception for CSS MIME types.",
        "commit_text": " This matches Firefox's behavior (though it returns 'transparent' instead of 'rgba(0, 0, 0, 0)', which is a bit annoying).   ",
        "func_before": "void StyleSheetContents::parseAuthorStyleSheet(const CSSStyleSheetResource* cachedStyleSheet, const SecurityOrigin* securityOrigin)\n{\n    TRACE_EVENT0(\"blink\", \"StyleSheetContents::parseAuthorStyleSheet\");\n    TRACE_EVENT1(TRACE_DISABLED_BY_DEFAULT(\"devtools.timeline\"), \"ParseAuthorStyleSheet\", \"data\", InspectorParseAuthorStyleSheetEvent::data(cachedStyleSheet));\n\n    bool quirksMode = isQuirksModeBehavior(m_parserContext.mode());\n\n    bool enforceMIMEType = !quirksMode;\n    bool hasValidMIMEType = false;\n    String sheetText = cachedStyleSheet->sheetText(enforceMIMEType, &hasValidMIMEType);\n\n    CSSParserContext context(parserContext(), UseCounter::getFrom(this));\n    CSSParser::parseSheet(context, this, sheetText, TextPosition::minimumPosition(), 0, true);\n\n    // If we're loading a stylesheet cross-origin, and the MIME type is not standard, require the CSS\n    // to at least start with a syntactically valid CSS rule.\n    // This prevents an attacker playing games by injecting CSS strings into HTML, XML, JSON, etc. etc.\n    if (!hasValidMIMEType && !hasSyntacticallyValidCSSHeader()) {\n        bool isCrossOriginCSS = !securityOrigin || !securityOrigin->canRequest(baseURL());\n        if (isCrossOriginCSS) {\n            clearRules();\n            return;\n        }\n    }\n}",
        "func": "void StyleSheetContents::parseAuthorStyleSheet(const CSSStyleSheetResource* cachedStyleSheet, const SecurityOrigin* securityOrigin)\n{\n    TRACE_EVENT0(\"blink\", \"StyleSheetContents::parseAuthorStyleSheet\");\n    TRACE_EVENT1(TRACE_DISABLED_BY_DEFAULT(\"devtools.timeline\"), \"ParseAuthorStyleSheet\", \"data\", InspectorParseAuthorStyleSheetEvent::data(cachedStyleSheet));\n\n    bool hasValidMIMEType = false;\n    String sheetText = cachedStyleSheet->sheetText(&hasValidMIMEType);\n\n    CSSParserContext context(parserContext(), UseCounter::getFrom(this));\n    CSSParser::parseSheet(context, this, sheetText, TextPosition::minimumPosition(), 0, true);\n\n    // If we're loading a stylesheet cross-origin, and the MIME type is not standard, require the CSS\n    // to at least start with a syntactically valid CSS rule.\n    // This prevents an attacker playing games by injecting CSS strings into HTML, XML, JSON, etc. etc.\n    if (!hasValidMIMEType && !hasSyntacticallyValidCSSHeader()) {\n        bool isCrossOriginCSS = !securityOrigin || !securityOrigin->canRequest(baseURL());\n        if (isCrossOriginCSS) {\n            clearRules();\n            return;\n        }\n    }\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -3,11 +3,8 @@\n     TRACE_EVENT0(\"blink\", \"StyleSheetContents::parseAuthorStyleSheet\");\n     TRACE_EVENT1(TRACE_DISABLED_BY_DEFAULT(\"devtools.timeline\"), \"ParseAuthorStyleSheet\", \"data\", InspectorParseAuthorStyleSheetEvent::data(cachedStyleSheet));\n \n-    bool quirksMode = isQuirksModeBehavior(m_parserContext.mode());\n-\n-    bool enforceMIMEType = !quirksMode;\n     bool hasValidMIMEType = false;\n-    String sheetText = cachedStyleSheet->sheetText(enforceMIMEType, &hasValidMIMEType);\n+    String sheetText = cachedStyleSheet->sheetText(&hasValidMIMEType);\n \n     CSSParserContext context(parserContext(), UseCounter::getFrom(this));\n     CSSParser::parseSheet(context, this, sheetText, TextPosition::minimumPosition(), 0, true);",
        "diff_line_info": {
            "deleted_lines": [
                "    bool quirksMode = isQuirksModeBehavior(m_parserContext.mode());",
                "",
                "    bool enforceMIMEType = !quirksMode;",
                "    String sheetText = cachedStyleSheet->sheetText(enforceMIMEType, &hasValidMIMEType);"
            ],
            "added_lines": [
                "    String sheetText = cachedStyleSheet->sheetText(&hasValidMIMEType);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1805",
        "func_name": "torvalds/linux/pipe_write",
        "description": "The (1) pipe_read and (2) pipe_write implementations in fs/pipe.c in the Linux kernel before 3.16 do not properly consider the side effects of failed __copy_to_user_inatomic and __copy_from_user_inatomic calls, which allows local users to cause a denial of service (system crash) or possibly gain privileges via a crafted application, aka an \"I/O vector array overrun.\"",
        "git_url": "https://github.com/torvalds/linux/commit/f0d1bec9d58d4c038d0ac958c9af82be6eb18045",
        "commit_title": "new helper: copy_page_from_iter()",
        "commit_text": " parallel to copy_page_to_iter().  pipe_write() switched to it (and became ->write_iter()). ",
        "func_before": "static ssize_t\npipe_write(struct kiocb *iocb, const struct iovec *_iov,\n\t    unsigned long nr_segs, loff_t ppos)\n{\n\tstruct file *filp = iocb->ki_filp;\n\tstruct pipe_inode_info *pipe = filp->private_data;\n\tssize_t ret;\n\tint do_wakeup;\n\tstruct iovec *iov = (struct iovec *)_iov;\n\tsize_t total_len;\n\tssize_t chars;\n\n\ttotal_len = iov_length(iov, nr_segs);\n\t/* Null write succeeds. */\n\tif (unlikely(total_len == 0))\n\t\treturn 0;\n\n\tdo_wakeup = 0;\n\tret = 0;\n\t__pipe_lock(pipe);\n\n\tif (!pipe->readers) {\n\t\tsend_sig(SIGPIPE, current, 0);\n\t\tret = -EPIPE;\n\t\tgoto out;\n\t}\n\n\t/* We try to merge small writes */\n\tchars = total_len & (PAGE_SIZE-1); /* size of the last buffer */\n\tif (pipe->nrbufs && chars != 0) {\n\t\tint lastbuf = (pipe->curbuf + pipe->nrbufs - 1) &\n\t\t\t\t\t\t\t(pipe->buffers - 1);\n\t\tstruct pipe_buffer *buf = pipe->bufs + lastbuf;\n\t\tconst struct pipe_buf_operations *ops = buf->ops;\n\t\tint offset = buf->offset + buf->len;\n\n\t\tif (ops->can_merge && offset + chars <= PAGE_SIZE) {\n\t\t\tint error, atomic = 1;\n\t\t\tvoid *addr;\n\n\t\t\terror = ops->confirm(pipe, buf);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n\n\t\t\tiov_fault_in_pages_read(iov, chars);\nredo1:\n\t\t\tif (atomic)\n\t\t\t\taddr = kmap_atomic(buf->page);\n\t\t\telse\n\t\t\t\taddr = kmap(buf->page);\n\t\t\terror = pipe_iov_copy_from_user(offset + addr, iov,\n\t\t\t\t\t\t\tchars, atomic);\n\t\t\tif (atomic)\n\t\t\t\tkunmap_atomic(addr);\n\t\t\telse\n\t\t\t\tkunmap(buf->page);\n\t\t\tret = error;\n\t\t\tdo_wakeup = 1;\n\t\t\tif (error) {\n\t\t\t\tif (atomic) {\n\t\t\t\t\tatomic = 0;\n\t\t\t\t\tgoto redo1;\n\t\t\t\t}\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbuf->len += chars;\n\t\t\ttotal_len -= chars;\n\t\t\tret = chars;\n\t\t\tif (!total_len)\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\n\tfor (;;) {\n\t\tint bufs;\n\n\t\tif (!pipe->readers) {\n\t\t\tsend_sig(SIGPIPE, current, 0);\n\t\t\tif (!ret)\n\t\t\t\tret = -EPIPE;\n\t\t\tbreak;\n\t\t}\n\t\tbufs = pipe->nrbufs;\n\t\tif (bufs < pipe->buffers) {\n\t\t\tint newbuf = (pipe->curbuf + bufs) & (pipe->buffers-1);\n\t\t\tstruct pipe_buffer *buf = pipe->bufs + newbuf;\n\t\t\tstruct page *page = pipe->tmp_page;\n\t\t\tchar *src;\n\t\t\tint error, atomic = 1;\n\n\t\t\tif (!page) {\n\t\t\t\tpage = alloc_page(GFP_HIGHUSER);\n\t\t\t\tif (unlikely(!page)) {\n\t\t\t\t\tret = ret ? : -ENOMEM;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tpipe->tmp_page = page;\n\t\t\t}\n\t\t\t/* Always wake up, even if the copy fails. Otherwise\n\t\t\t * we lock up (O_NONBLOCK-)readers that sleep due to\n\t\t\t * syscall merging.\n\t\t\t * FIXME! Is this really true?\n\t\t\t */\n\t\t\tdo_wakeup = 1;\n\t\t\tchars = PAGE_SIZE;\n\t\t\tif (chars > total_len)\n\t\t\t\tchars = total_len;\n\n\t\t\tiov_fault_in_pages_read(iov, chars);\nredo2:\n\t\t\tif (atomic)\n\t\t\t\tsrc = kmap_atomic(page);\n\t\t\telse\n\t\t\t\tsrc = kmap(page);\n\n\t\t\terror = pipe_iov_copy_from_user(src, iov, chars,\n\t\t\t\t\t\t\tatomic);\n\t\t\tif (atomic)\n\t\t\t\tkunmap_atomic(src);\n\t\t\telse\n\t\t\t\tkunmap(page);\n\n\t\t\tif (unlikely(error)) {\n\t\t\t\tif (atomic) {\n\t\t\t\t\tatomic = 0;\n\t\t\t\t\tgoto redo2;\n\t\t\t\t}\n\t\t\t\tif (!ret)\n\t\t\t\t\tret = error;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret += chars;\n\n\t\t\t/* Insert it into the buffer array */\n\t\t\tbuf->page = page;\n\t\t\tbuf->ops = &anon_pipe_buf_ops;\n\t\t\tbuf->offset = 0;\n\t\t\tbuf->len = chars;\n\t\t\tbuf->flags = 0;\n\t\t\tif (is_packetized(filp)) {\n\t\t\t\tbuf->ops = &packet_pipe_buf_ops;\n\t\t\t\tbuf->flags = PIPE_BUF_FLAG_PACKET;\n\t\t\t}\n\t\t\tpipe->nrbufs = ++bufs;\n\t\t\tpipe->tmp_page = NULL;\n\n\t\t\ttotal_len -= chars;\n\t\t\tif (!total_len)\n\t\t\t\tbreak;\n\t\t}\n\t\tif (bufs < pipe->buffers)\n\t\t\tcontinue;\n\t\tif (filp->f_flags & O_NONBLOCK) {\n\t\t\tif (!ret)\n\t\t\t\tret = -EAGAIN;\n\t\t\tbreak;\n\t\t}\n\t\tif (signal_pending(current)) {\n\t\t\tif (!ret)\n\t\t\t\tret = -ERESTARTSYS;\n\t\t\tbreak;\n\t\t}\n\t\tif (do_wakeup) {\n\t\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLIN | POLLRDNORM);\n\t\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);\n\t\t\tdo_wakeup = 0;\n\t\t}\n\t\tpipe->waiting_writers++;\n\t\tpipe_wait(pipe);\n\t\tpipe->waiting_writers--;\n\t}\nout:\n\t__pipe_unlock(pipe);\n\tif (do_wakeup) {\n\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLIN | POLLRDNORM);\n\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);\n\t}\n\tif (ret > 0 && sb_start_write_trylock(file_inode(filp)->i_sb)) {\n\t\tint err = file_update_time(filp);\n\t\tif (err)\n\t\t\tret = err;\n\t\tsb_end_write(file_inode(filp)->i_sb);\n\t}\n\treturn ret;\n}",
        "func": "static ssize_t\npipe_write(struct kiocb *iocb, struct iov_iter *from)\n{\n\tstruct file *filp = iocb->ki_filp;\n\tstruct pipe_inode_info *pipe = filp->private_data;\n\tssize_t ret = 0;\n\tint do_wakeup = 0;\n\tsize_t total_len = iov_iter_count(from);\n\tssize_t chars;\n\n\t/* Null write succeeds. */\n\tif (unlikely(total_len == 0))\n\t\treturn 0;\n\n\t__pipe_lock(pipe);\n\n\tif (!pipe->readers) {\n\t\tsend_sig(SIGPIPE, current, 0);\n\t\tret = -EPIPE;\n\t\tgoto out;\n\t}\n\n\t/* We try to merge small writes */\n\tchars = total_len & (PAGE_SIZE-1); /* size of the last buffer */\n\tif (pipe->nrbufs && chars != 0) {\n\t\tint lastbuf = (pipe->curbuf + pipe->nrbufs - 1) &\n\t\t\t\t\t\t\t(pipe->buffers - 1);\n\t\tstruct pipe_buffer *buf = pipe->bufs + lastbuf;\n\t\tconst struct pipe_buf_operations *ops = buf->ops;\n\t\tint offset = buf->offset + buf->len;\n\n\t\tif (ops->can_merge && offset + chars <= PAGE_SIZE) {\n\t\t\tint error = ops->confirm(pipe, buf);\n\t\t\tif (error)\n\t\t\t\tgoto out;\n\n\t\t\tret = copy_page_from_iter(buf->page, offset, chars, from);\n\t\t\tif (unlikely(ret < chars)) {\n\t\t\t\terror = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tdo_wakeup = 1;\n\t\t\tbuf->len += chars;\n\t\t\tret = chars;\n\t\t\tif (!iov_iter_count(from))\n\t\t\t\tgoto out;\n\t\t}\n\t}\n\n\tfor (;;) {\n\t\tint bufs;\n\n\t\tif (!pipe->readers) {\n\t\t\tsend_sig(SIGPIPE, current, 0);\n\t\t\tif (!ret)\n\t\t\t\tret = -EPIPE;\n\t\t\tbreak;\n\t\t}\n\t\tbufs = pipe->nrbufs;\n\t\tif (bufs < pipe->buffers) {\n\t\t\tint newbuf = (pipe->curbuf + bufs) & (pipe->buffers-1);\n\t\t\tstruct pipe_buffer *buf = pipe->bufs + newbuf;\n\t\t\tstruct page *page = pipe->tmp_page;\n\t\t\tint copied;\n\n\t\t\tif (!page) {\n\t\t\t\tpage = alloc_page(GFP_HIGHUSER);\n\t\t\t\tif (unlikely(!page)) {\n\t\t\t\t\tret = ret ? : -ENOMEM;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tpipe->tmp_page = page;\n\t\t\t}\n\t\t\t/* Always wake up, even if the copy fails. Otherwise\n\t\t\t * we lock up (O_NONBLOCK-)readers that sleep due to\n\t\t\t * syscall merging.\n\t\t\t * FIXME! Is this really true?\n\t\t\t */\n\t\t\tdo_wakeup = 1;\n\t\t\tcopied = copy_page_from_iter(page, 0, PAGE_SIZE, from);\n\t\t\tif (unlikely(copied < PAGE_SIZE && iov_iter_count(from))) {\n\t\t\t\tif (!ret)\n\t\t\t\t\tret = -EFAULT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret += copied;\n\n\t\t\t/* Insert it into the buffer array */\n\t\t\tbuf->page = page;\n\t\t\tbuf->ops = &anon_pipe_buf_ops;\n\t\t\tbuf->offset = 0;\n\t\t\tbuf->len = copied;\n\t\t\tbuf->flags = 0;\n\t\t\tif (is_packetized(filp)) {\n\t\t\t\tbuf->ops = &packet_pipe_buf_ops;\n\t\t\t\tbuf->flags = PIPE_BUF_FLAG_PACKET;\n\t\t\t}\n\t\t\tpipe->nrbufs = ++bufs;\n\t\t\tpipe->tmp_page = NULL;\n\n\t\t\tif (!iov_iter_count(from))\n\t\t\t\tbreak;\n\t\t}\n\t\tif (bufs < pipe->buffers)\n\t\t\tcontinue;\n\t\tif (filp->f_flags & O_NONBLOCK) {\n\t\t\tif (!ret)\n\t\t\t\tret = -EAGAIN;\n\t\t\tbreak;\n\t\t}\n\t\tif (signal_pending(current)) {\n\t\t\tif (!ret)\n\t\t\t\tret = -ERESTARTSYS;\n\t\t\tbreak;\n\t\t}\n\t\tif (do_wakeup) {\n\t\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLIN | POLLRDNORM);\n\t\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);\n\t\t\tdo_wakeup = 0;\n\t\t}\n\t\tpipe->waiting_writers++;\n\t\tpipe_wait(pipe);\n\t\tpipe->waiting_writers--;\n\t}\nout:\n\t__pipe_unlock(pipe);\n\tif (do_wakeup) {\n\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLIN | POLLRDNORM);\n\t\tkill_fasync(&pipe->fasync_readers, SIGIO, POLL_IN);\n\t}\n\tif (ret > 0 && sb_start_write_trylock(file_inode(filp)->i_sb)) {\n\t\tint err = file_update_time(filp);\n\t\tif (err)\n\t\t\tret = err;\n\t\tsb_end_write(file_inode(filp)->i_sb);\n\t}\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,22 +1,17 @@\n static ssize_t\n-pipe_write(struct kiocb *iocb, const struct iovec *_iov,\n-\t    unsigned long nr_segs, loff_t ppos)\n+pipe_write(struct kiocb *iocb, struct iov_iter *from)\n {\n \tstruct file *filp = iocb->ki_filp;\n \tstruct pipe_inode_info *pipe = filp->private_data;\n-\tssize_t ret;\n-\tint do_wakeup;\n-\tstruct iovec *iov = (struct iovec *)_iov;\n-\tsize_t total_len;\n+\tssize_t ret = 0;\n+\tint do_wakeup = 0;\n+\tsize_t total_len = iov_iter_count(from);\n \tssize_t chars;\n \n-\ttotal_len = iov_length(iov, nr_segs);\n \t/* Null write succeeds. */\n \tif (unlikely(total_len == 0))\n \t\treturn 0;\n \n-\tdo_wakeup = 0;\n-\tret = 0;\n \t__pipe_lock(pipe);\n \n \tif (!pipe->readers) {\n@@ -35,38 +30,19 @@\n \t\tint offset = buf->offset + buf->len;\n \n \t\tif (ops->can_merge && offset + chars <= PAGE_SIZE) {\n-\t\t\tint error, atomic = 1;\n-\t\t\tvoid *addr;\n-\n-\t\t\terror = ops->confirm(pipe, buf);\n+\t\t\tint error = ops->confirm(pipe, buf);\n \t\t\tif (error)\n \t\t\t\tgoto out;\n \n-\t\t\tiov_fault_in_pages_read(iov, chars);\n-redo1:\n-\t\t\tif (atomic)\n-\t\t\t\taddr = kmap_atomic(buf->page);\n-\t\t\telse\n-\t\t\t\taddr = kmap(buf->page);\n-\t\t\terror = pipe_iov_copy_from_user(offset + addr, iov,\n-\t\t\t\t\t\t\tchars, atomic);\n-\t\t\tif (atomic)\n-\t\t\t\tkunmap_atomic(addr);\n-\t\t\telse\n-\t\t\t\tkunmap(buf->page);\n-\t\t\tret = error;\n-\t\t\tdo_wakeup = 1;\n-\t\t\tif (error) {\n-\t\t\t\tif (atomic) {\n-\t\t\t\t\tatomic = 0;\n-\t\t\t\t\tgoto redo1;\n-\t\t\t\t}\n+\t\t\tret = copy_page_from_iter(buf->page, offset, chars, from);\n+\t\t\tif (unlikely(ret < chars)) {\n+\t\t\t\terror = -EFAULT;\n \t\t\t\tgoto out;\n \t\t\t}\n+\t\t\tdo_wakeup = 1;\n \t\t\tbuf->len += chars;\n-\t\t\ttotal_len -= chars;\n \t\t\tret = chars;\n-\t\t\tif (!total_len)\n+\t\t\tif (!iov_iter_count(from))\n \t\t\t\tgoto out;\n \t\t}\n \t}\n@@ -85,8 +61,7 @@\n \t\t\tint newbuf = (pipe->curbuf + bufs) & (pipe->buffers-1);\n \t\t\tstruct pipe_buffer *buf = pipe->bufs + newbuf;\n \t\t\tstruct page *page = pipe->tmp_page;\n-\t\t\tchar *src;\n-\t\t\tint error, atomic = 1;\n+\t\t\tint copied;\n \n \t\t\tif (!page) {\n \t\t\t\tpage = alloc_page(GFP_HIGHUSER);\n@@ -102,40 +77,19 @@\n \t\t\t * FIXME! Is this really true?\n \t\t\t */\n \t\t\tdo_wakeup = 1;\n-\t\t\tchars = PAGE_SIZE;\n-\t\t\tif (chars > total_len)\n-\t\t\t\tchars = total_len;\n-\n-\t\t\tiov_fault_in_pages_read(iov, chars);\n-redo2:\n-\t\t\tif (atomic)\n-\t\t\t\tsrc = kmap_atomic(page);\n-\t\t\telse\n-\t\t\t\tsrc = kmap(page);\n-\n-\t\t\terror = pipe_iov_copy_from_user(src, iov, chars,\n-\t\t\t\t\t\t\tatomic);\n-\t\t\tif (atomic)\n-\t\t\t\tkunmap_atomic(src);\n-\t\t\telse\n-\t\t\t\tkunmap(page);\n-\n-\t\t\tif (unlikely(error)) {\n-\t\t\t\tif (atomic) {\n-\t\t\t\t\tatomic = 0;\n-\t\t\t\t\tgoto redo2;\n-\t\t\t\t}\n+\t\t\tcopied = copy_page_from_iter(page, 0, PAGE_SIZE, from);\n+\t\t\tif (unlikely(copied < PAGE_SIZE && iov_iter_count(from))) {\n \t\t\t\tif (!ret)\n-\t\t\t\t\tret = error;\n+\t\t\t\t\tret = -EFAULT;\n \t\t\t\tbreak;\n \t\t\t}\n-\t\t\tret += chars;\n+\t\t\tret += copied;\n \n \t\t\t/* Insert it into the buffer array */\n \t\t\tbuf->page = page;\n \t\t\tbuf->ops = &anon_pipe_buf_ops;\n \t\t\tbuf->offset = 0;\n-\t\t\tbuf->len = chars;\n+\t\t\tbuf->len = copied;\n \t\t\tbuf->flags = 0;\n \t\t\tif (is_packetized(filp)) {\n \t\t\t\tbuf->ops = &packet_pipe_buf_ops;\n@@ -144,8 +98,7 @@\n \t\t\tpipe->nrbufs = ++bufs;\n \t\t\tpipe->tmp_page = NULL;\n \n-\t\t\ttotal_len -= chars;\n-\t\t\tif (!total_len)\n+\t\t\tif (!iov_iter_count(from))\n \t\t\t\tbreak;\n \t\t}\n \t\tif (bufs < pipe->buffers)",
        "diff_line_info": {
            "deleted_lines": [
                "pipe_write(struct kiocb *iocb, const struct iovec *_iov,",
                "\t    unsigned long nr_segs, loff_t ppos)",
                "\tssize_t ret;",
                "\tint do_wakeup;",
                "\tstruct iovec *iov = (struct iovec *)_iov;",
                "\tsize_t total_len;",
                "\ttotal_len = iov_length(iov, nr_segs);",
                "\tdo_wakeup = 0;",
                "\tret = 0;",
                "\t\t\tint error, atomic = 1;",
                "\t\t\tvoid *addr;",
                "",
                "\t\t\terror = ops->confirm(pipe, buf);",
                "\t\t\tiov_fault_in_pages_read(iov, chars);",
                "redo1:",
                "\t\t\tif (atomic)",
                "\t\t\t\taddr = kmap_atomic(buf->page);",
                "\t\t\telse",
                "\t\t\t\taddr = kmap(buf->page);",
                "\t\t\terror = pipe_iov_copy_from_user(offset + addr, iov,",
                "\t\t\t\t\t\t\tchars, atomic);",
                "\t\t\tif (atomic)",
                "\t\t\t\tkunmap_atomic(addr);",
                "\t\t\telse",
                "\t\t\t\tkunmap(buf->page);",
                "\t\t\tret = error;",
                "\t\t\tdo_wakeup = 1;",
                "\t\t\tif (error) {",
                "\t\t\t\tif (atomic) {",
                "\t\t\t\t\tatomic = 0;",
                "\t\t\t\t\tgoto redo1;",
                "\t\t\t\t}",
                "\t\t\ttotal_len -= chars;",
                "\t\t\tif (!total_len)",
                "\t\t\tchar *src;",
                "\t\t\tint error, atomic = 1;",
                "\t\t\tchars = PAGE_SIZE;",
                "\t\t\tif (chars > total_len)",
                "\t\t\t\tchars = total_len;",
                "",
                "\t\t\tiov_fault_in_pages_read(iov, chars);",
                "redo2:",
                "\t\t\tif (atomic)",
                "\t\t\t\tsrc = kmap_atomic(page);",
                "\t\t\telse",
                "\t\t\t\tsrc = kmap(page);",
                "",
                "\t\t\terror = pipe_iov_copy_from_user(src, iov, chars,",
                "\t\t\t\t\t\t\tatomic);",
                "\t\t\tif (atomic)",
                "\t\t\t\tkunmap_atomic(src);",
                "\t\t\telse",
                "\t\t\t\tkunmap(page);",
                "",
                "\t\t\tif (unlikely(error)) {",
                "\t\t\t\tif (atomic) {",
                "\t\t\t\t\tatomic = 0;",
                "\t\t\t\t\tgoto redo2;",
                "\t\t\t\t}",
                "\t\t\t\t\tret = error;",
                "\t\t\tret += chars;",
                "\t\t\tbuf->len = chars;",
                "\t\t\ttotal_len -= chars;",
                "\t\t\tif (!total_len)"
            ],
            "added_lines": [
                "pipe_write(struct kiocb *iocb, struct iov_iter *from)",
                "\tssize_t ret = 0;",
                "\tint do_wakeup = 0;",
                "\tsize_t total_len = iov_iter_count(from);",
                "\t\t\tint error = ops->confirm(pipe, buf);",
                "\t\t\tret = copy_page_from_iter(buf->page, offset, chars, from);",
                "\t\t\tif (unlikely(ret < chars)) {",
                "\t\t\t\terror = -EFAULT;",
                "\t\t\tdo_wakeup = 1;",
                "\t\t\tif (!iov_iter_count(from))",
                "\t\t\tint copied;",
                "\t\t\tcopied = copy_page_from_iter(page, 0, PAGE_SIZE, from);",
                "\t\t\tif (unlikely(copied < PAGE_SIZE && iov_iter_count(from))) {",
                "\t\t\t\t\tret = -EFAULT;",
                "\t\t\tret += copied;",
                "\t\t\tbuf->len = copied;",
                "\t\t\tif (!iov_iter_count(from))"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1805",
        "func_name": "torvalds/linux/pipe_read",
        "description": "The (1) pipe_read and (2) pipe_write implementations in fs/pipe.c in the Linux kernel before 3.16 do not properly consider the side effects of failed __copy_to_user_inatomic and __copy_from_user_inatomic calls, which allows local users to cause a denial of service (system crash) or possibly gain privileges via a crafted application, aka an \"I/O vector array overrun.\"",
        "git_url": "https://github.com/torvalds/linux/commit/637b58c2887e5e57850865839cc75f59184b23d1",
        "commit_title": "switch pipe_read() to copy_page_to_iter()",
        "commit_text": "",
        "func_before": "static ssize_t\npipe_read(struct kiocb *iocb, const struct iovec *_iov,\n\t   unsigned long nr_segs, loff_t pos)\n{\n\tstruct file *filp = iocb->ki_filp;\n\tstruct pipe_inode_info *pipe = filp->private_data;\n\tint do_wakeup;\n\tssize_t ret;\n\tstruct iovec *iov = (struct iovec *)_iov;\n\tsize_t total_len;\n\n\ttotal_len = iov_length(iov, nr_segs);\n\t/* Null read succeeds. */\n\tif (unlikely(total_len == 0))\n\t\treturn 0;\n\n\tdo_wakeup = 0;\n\tret = 0;\n\t__pipe_lock(pipe);\n\tfor (;;) {\n\t\tint bufs = pipe->nrbufs;\n\t\tif (bufs) {\n\t\t\tint curbuf = pipe->curbuf;\n\t\t\tstruct pipe_buffer *buf = pipe->bufs + curbuf;\n\t\t\tconst struct pipe_buf_operations *ops = buf->ops;\n\t\t\tvoid *addr;\n\t\t\tsize_t chars = buf->len;\n\t\t\tint error, atomic;\n\n\t\t\tif (chars > total_len)\n\t\t\t\tchars = total_len;\n\n\t\t\terror = ops->confirm(pipe, buf);\n\t\t\tif (error) {\n\t\t\t\tif (!ret)\n\t\t\t\t\tret = error;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tatomic = !iov_fault_in_pages_write(iov, chars);\nredo:\n\t\t\tif (atomic)\n\t\t\t\taddr = kmap_atomic(buf->page);\n\t\t\telse\n\t\t\t\taddr = kmap(buf->page);\n\t\t\terror = pipe_iov_copy_to_user(iov, addr + buf->offset, chars, atomic);\n\t\t\tif (atomic)\n\t\t\t\tkunmap_atomic(addr);\n\t\t\telse\n\t\t\t\tkunmap(buf->page);\n\t\t\tif (unlikely(error)) {\n\t\t\t\t/*\n\t\t\t\t * Just retry with the slow path if we failed.\n\t\t\t\t */\n\t\t\t\tif (atomic) {\n\t\t\t\t\tatomic = 0;\n\t\t\t\t\tgoto redo;\n\t\t\t\t}\n\t\t\t\tif (!ret)\n\t\t\t\t\tret = error;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret += chars;\n\t\t\tbuf->offset += chars;\n\t\t\tbuf->len -= chars;\n\n\t\t\t/* Was it a packet buffer? Clean up and exit */\n\t\t\tif (buf->flags & PIPE_BUF_FLAG_PACKET) {\n\t\t\t\ttotal_len = chars;\n\t\t\t\tbuf->len = 0;\n\t\t\t}\n\n\t\t\tif (!buf->len) {\n\t\t\t\tbuf->ops = NULL;\n\t\t\t\tops->release(pipe, buf);\n\t\t\t\tcurbuf = (curbuf + 1) & (pipe->buffers - 1);\n\t\t\t\tpipe->curbuf = curbuf;\n\t\t\t\tpipe->nrbufs = --bufs;\n\t\t\t\tdo_wakeup = 1;\n\t\t\t}\n\t\t\ttotal_len -= chars;\n\t\t\tif (!total_len)\n\t\t\t\tbreak;\t/* common path: read succeeded */\n\t\t}\n\t\tif (bufs)\t/* More to do? */\n\t\t\tcontinue;\n\t\tif (!pipe->writers)\n\t\t\tbreak;\n\t\tif (!pipe->waiting_writers) {\n\t\t\t/* syscall merging: Usually we must not sleep\n\t\t\t * if O_NONBLOCK is set, or if we got some data.\n\t\t\t * But if a writer sleeps in kernel space, then\n\t\t\t * we can wait for that data without violating POSIX.\n\t\t\t */\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t\tif (filp->f_flags & O_NONBLOCK) {\n\t\t\t\tret = -EAGAIN;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (signal_pending(current)) {\n\t\t\tif (!ret)\n\t\t\t\tret = -ERESTARTSYS;\n\t\t\tbreak;\n\t\t}\n\t\tif (do_wakeup) {\n\t\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLOUT | POLLWRNORM);\n \t\t\tkill_fasync(&pipe->fasync_writers, SIGIO, POLL_OUT);\n\t\t}\n\t\tpipe_wait(pipe);\n\t}\n\t__pipe_unlock(pipe);\n\n\t/* Signal writers asynchronously that there is more room. */\n\tif (do_wakeup) {\n\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLOUT | POLLWRNORM);\n\t\tkill_fasync(&pipe->fasync_writers, SIGIO, POLL_OUT);\n\t}\n\tif (ret > 0)\n\t\tfile_accessed(filp);\n\treturn ret;\n}",
        "func": "static ssize_t\npipe_read(struct kiocb *iocb, const struct iovec *_iov,\n\t   unsigned long nr_segs, loff_t pos)\n{\n\tstruct file *filp = iocb->ki_filp;\n\tstruct pipe_inode_info *pipe = filp->private_data;\n\tint do_wakeup;\n\tssize_t ret;\n\tstruct iovec *iov = (struct iovec *)_iov;\n\tsize_t total_len;\n\tstruct iov_iter iter;\n\n\ttotal_len = iov_length(iov, nr_segs);\n\t/* Null read succeeds. */\n\tif (unlikely(total_len == 0))\n\t\treturn 0;\n\n\tiov_iter_init(&iter, iov, nr_segs, total_len, 0);\n\n\tdo_wakeup = 0;\n\tret = 0;\n\t__pipe_lock(pipe);\n\tfor (;;) {\n\t\tint bufs = pipe->nrbufs;\n\t\tif (bufs) {\n\t\t\tint curbuf = pipe->curbuf;\n\t\t\tstruct pipe_buffer *buf = pipe->bufs + curbuf;\n\t\t\tconst struct pipe_buf_operations *ops = buf->ops;\n\t\t\tsize_t chars = buf->len;\n\t\t\tsize_t written;\n\t\t\tint error;\n\n\t\t\tif (chars > total_len)\n\t\t\t\tchars = total_len;\n\n\t\t\terror = ops->confirm(pipe, buf);\n\t\t\tif (error) {\n\t\t\t\tif (!ret)\n\t\t\t\t\tret = error;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\twritten = copy_page_to_iter(buf->page, buf->offset, chars, &iter);\n\t\t\tif (unlikely(written < chars)) {\n\t\t\t\tif (!ret)\n\t\t\t\t\tret = -EFAULT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret += chars;\n\t\t\tbuf->offset += chars;\n\t\t\tbuf->len -= chars;\n\n\t\t\t/* Was it a packet buffer? Clean up and exit */\n\t\t\tif (buf->flags & PIPE_BUF_FLAG_PACKET) {\n\t\t\t\ttotal_len = chars;\n\t\t\t\tbuf->len = 0;\n\t\t\t}\n\n\t\t\tif (!buf->len) {\n\t\t\t\tbuf->ops = NULL;\n\t\t\t\tops->release(pipe, buf);\n\t\t\t\tcurbuf = (curbuf + 1) & (pipe->buffers - 1);\n\t\t\t\tpipe->curbuf = curbuf;\n\t\t\t\tpipe->nrbufs = --bufs;\n\t\t\t\tdo_wakeup = 1;\n\t\t\t}\n\t\t\ttotal_len -= chars;\n\t\t\tif (!total_len)\n\t\t\t\tbreak;\t/* common path: read succeeded */\n\t\t}\n\t\tif (bufs)\t/* More to do? */\n\t\t\tcontinue;\n\t\tif (!pipe->writers)\n\t\t\tbreak;\n\t\tif (!pipe->waiting_writers) {\n\t\t\t/* syscall merging: Usually we must not sleep\n\t\t\t * if O_NONBLOCK is set, or if we got some data.\n\t\t\t * But if a writer sleeps in kernel space, then\n\t\t\t * we can wait for that data without violating POSIX.\n\t\t\t */\n\t\t\tif (ret)\n\t\t\t\tbreak;\n\t\t\tif (filp->f_flags & O_NONBLOCK) {\n\t\t\t\tret = -EAGAIN;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (signal_pending(current)) {\n\t\t\tif (!ret)\n\t\t\t\tret = -ERESTARTSYS;\n\t\t\tbreak;\n\t\t}\n\t\tif (do_wakeup) {\n\t\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLOUT | POLLWRNORM);\n \t\t\tkill_fasync(&pipe->fasync_writers, SIGIO, POLL_OUT);\n\t\t}\n\t\tpipe_wait(pipe);\n\t}\n\t__pipe_unlock(pipe);\n\n\t/* Signal writers asynchronously that there is more room. */\n\tif (do_wakeup) {\n\t\twake_up_interruptible_sync_poll(&pipe->wait, POLLOUT | POLLWRNORM);\n\t\tkill_fasync(&pipe->fasync_writers, SIGIO, POLL_OUT);\n\t}\n\tif (ret > 0)\n\t\tfile_accessed(filp);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,11 +8,14 @@\n \tssize_t ret;\n \tstruct iovec *iov = (struct iovec *)_iov;\n \tsize_t total_len;\n+\tstruct iov_iter iter;\n \n \ttotal_len = iov_length(iov, nr_segs);\n \t/* Null read succeeds. */\n \tif (unlikely(total_len == 0))\n \t\treturn 0;\n+\n+\tiov_iter_init(&iter, iov, nr_segs, total_len, 0);\n \n \tdo_wakeup = 0;\n \tret = 0;\n@@ -23,9 +26,9 @@\n \t\t\tint curbuf = pipe->curbuf;\n \t\t\tstruct pipe_buffer *buf = pipe->bufs + curbuf;\n \t\t\tconst struct pipe_buf_operations *ops = buf->ops;\n-\t\t\tvoid *addr;\n \t\t\tsize_t chars = buf->len;\n-\t\t\tint error, atomic;\n+\t\t\tsize_t written;\n+\t\t\tint error;\n \n \t\t\tif (chars > total_len)\n \t\t\t\tchars = total_len;\n@@ -37,27 +40,10 @@\n \t\t\t\tbreak;\n \t\t\t}\n \n-\t\t\tatomic = !iov_fault_in_pages_write(iov, chars);\n-redo:\n-\t\t\tif (atomic)\n-\t\t\t\taddr = kmap_atomic(buf->page);\n-\t\t\telse\n-\t\t\t\taddr = kmap(buf->page);\n-\t\t\terror = pipe_iov_copy_to_user(iov, addr + buf->offset, chars, atomic);\n-\t\t\tif (atomic)\n-\t\t\t\tkunmap_atomic(addr);\n-\t\t\telse\n-\t\t\t\tkunmap(buf->page);\n-\t\t\tif (unlikely(error)) {\n-\t\t\t\t/*\n-\t\t\t\t * Just retry with the slow path if we failed.\n-\t\t\t\t */\n-\t\t\t\tif (atomic) {\n-\t\t\t\t\tatomic = 0;\n-\t\t\t\t\tgoto redo;\n-\t\t\t\t}\n+\t\t\twritten = copy_page_to_iter(buf->page, buf->offset, chars, &iter);\n+\t\t\tif (unlikely(written < chars)) {\n \t\t\t\tif (!ret)\n-\t\t\t\t\tret = error;\n+\t\t\t\t\tret = -EFAULT;\n \t\t\t\tbreak;\n \t\t\t}\n \t\t\tret += chars;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\tvoid *addr;",
                "\t\t\tint error, atomic;",
                "\t\t\tatomic = !iov_fault_in_pages_write(iov, chars);",
                "redo:",
                "\t\t\tif (atomic)",
                "\t\t\t\taddr = kmap_atomic(buf->page);",
                "\t\t\telse",
                "\t\t\t\taddr = kmap(buf->page);",
                "\t\t\terror = pipe_iov_copy_to_user(iov, addr + buf->offset, chars, atomic);",
                "\t\t\tif (atomic)",
                "\t\t\t\tkunmap_atomic(addr);",
                "\t\t\telse",
                "\t\t\t\tkunmap(buf->page);",
                "\t\t\tif (unlikely(error)) {",
                "\t\t\t\t/*",
                "\t\t\t\t * Just retry with the slow path if we failed.",
                "\t\t\t\t */",
                "\t\t\t\tif (atomic) {",
                "\t\t\t\t\tatomic = 0;",
                "\t\t\t\t\tgoto redo;",
                "\t\t\t\t}",
                "\t\t\t\t\tret = error;"
            ],
            "added_lines": [
                "\tstruct iov_iter iter;",
                "",
                "\tiov_iter_init(&iter, iov, nr_segs, total_len, 0);",
                "\t\t\tsize_t written;",
                "\t\t\tint error;",
                "\t\t\twritten = copy_page_to_iter(buf->page, buf->offset, chars, &iter);",
                "\t\t\tif (unlikely(written < chars)) {",
                "\t\t\t\t\tret = -EFAULT;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1334",
        "func_name": "lxc/attach_child_main",
        "description": "attach.c in LXC 1.1.2 and earlier uses the proc filesystem in a container, which allows local container users to escape AppArmor or SELinux confinement by mounting a proc filesystem with a crafted (1) AppArmor profile or (2) SELinux label.",
        "git_url": "https://github.com/lxc/lxc/commit/5c3fcae78b63ac9dd56e36075903921bd9461f9e",
        "commit_title": "CVE-2015-1334: Don't use the container's /proc during attach",
        "commit_text": " A user could otherwise over-mount /proc and prevent the apparmor profile or selinux label from being written which combined with a modified /bin/sh or other commonly used binary would lead to unconfined code execution. ",
        "func_before": "static int attach_child_main(void* data)\n{\n\tstruct attach_clone_payload* payload = (struct attach_clone_payload*)data;\n\tint ipc_socket = payload->ipc_socket;\n\tlxc_attach_options_t* options = payload->options;\n\tstruct lxc_proc_context_info* init_ctx = payload->init_ctx;\n#if HAVE_SYS_PERSONALITY_H\n\tlong new_personality;\n#endif\n\tint ret;\n\tint status;\n\tint expected;\n\tlong flags;\n\tint fd;\n\tuid_t new_uid;\n\tgid_t new_gid;\n\n\t/* wait for the initial thread to signal us that it's ready\n\t * for us to start initializing\n\t */\n\texpected = 0;\n\tstatus = -1;\n\tret = lxc_read_nointr_expect(ipc_socket, &status, sizeof(status), &expected);\n\tif (ret <= 0) {\n\t\tERROR(\"error using IPC to receive notification from initial process (0)\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* A description of the purpose of this functionality is\n\t * provided in the lxc-attach(1) manual page. We have to\n\t * remount here and not in the parent process, otherwise\n\t * /proc may not properly reflect the new pid namespace.\n\t */\n\tif (!(options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_REMOUNT_PROC_SYS)) {\n\t\tret = lxc_attach_remount_sys_proc();\n\t\tif (ret < 0) {\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\t/* now perform additional attachments*/\n#if HAVE_SYS_PERSONALITY_H\n\tif (options->personality < 0)\n\t\tnew_personality = init_ctx->personality;\n\telse\n\t\tnew_personality = options->personality;\n\n\tif (options->attach_flags & LXC_ATTACH_SET_PERSONALITY) {\n\t\tret = personality(new_personality);\n\t\tif (ret < 0) {\n\t\t\tSYSERROR(\"could not ensure correct architecture\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n#endif\n\n\tif (options->attach_flags & LXC_ATTACH_DROP_CAPABILITIES) {\n\t\tret = lxc_attach_drop_privs(init_ctx);\n\t\tif (ret < 0) {\n\t\t\tERROR(\"could not drop privileges\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\t/* always set the environment (specify (LXC_ATTACH_KEEP_ENV, NULL, NULL) if you want this to be a no-op) */\n\tret = lxc_attach_set_environment(options->env_policy, options->extra_env_vars, options->extra_keep_env);\n\tif (ret < 0) {\n\t\tERROR(\"could not set initial environment for attached process\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* set user / group id */\n\tnew_uid = 0;\n\tnew_gid = 0;\n\t/* ignore errors, we will fall back to root in that case\n\t * (/proc was not mounted etc.)\n\t */\n\tif (options->namespaces & CLONE_NEWUSER)\n\t\tlxc_attach_get_init_uidgid(&new_uid, &new_gid);\n\n\tif (options->uid != (uid_t)-1)\n\t\tnew_uid = options->uid;\n\tif (options->gid != (gid_t)-1)\n\t\tnew_gid = options->gid;\n\n\t/* setup the control tty */\n\tif (options->stdin_fd && isatty(options->stdin_fd)) {\n\t\tif (setsid() < 0) {\n\t\t\tSYSERROR(\"unable to setsid\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\n\t\tif (ioctl(options->stdin_fd, TIOCSCTTY, (char *)NULL) < 0) {\n\t\t\tSYSERROR(\"unable to TIOCSTTY\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\t/* try to set the uid/gid combination */\n\tif ((new_gid != 0 || options->namespaces & CLONE_NEWUSER)) {\n\t\tif (setgid(new_gid) || setgroups(0, NULL)) {\n\t\t\tSYSERROR(\"switching to container gid\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\tif ((new_uid != 0 || options->namespaces & CLONE_NEWUSER) && setuid(new_uid)) {\n\t\tSYSERROR(\"switching to container uid\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* tell initial process it may now put us into the cgroups */\n\tstatus = 1;\n\tret = lxc_write_nointr(ipc_socket, &status, sizeof(status));\n\tif (ret != sizeof(status)) {\n\t\tERROR(\"error using IPC to notify initial process for initialization (1)\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* wait for the initial thread to signal us that it has done\n\t * everything for us when it comes to cgroups etc.\n\t */\n\texpected = 2;\n\tstatus = -1;\n\tret = lxc_read_nointr_expect(ipc_socket, &status, sizeof(status), &expected);\n\tif (ret <= 0) {\n\t\tERROR(\"error using IPC to receive final notification from initial process (2)\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\tshutdown(ipc_socket, SHUT_RDWR);\n\tclose(ipc_socket);\n\n\t/* set new apparmor profile/selinux context */\n\tif ((options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_LSM)) {\n\t\tint on_exec;\n\t\tint proc_mounted;\n\n\t\ton_exec = options->attach_flags & LXC_ATTACH_LSM_EXEC ? 1 : 0;\n\t\tproc_mounted = mount_proc_if_needed(\"/\");\n\t\tif (proc_mounted == -1) {\n\t\t\tERROR(\"Error mounting a sane /proc\");\n\t\t\trexit(-1);\n\t\t}\n\t\tret = lsm_process_label_set(init_ctx->lsm_label,\n\t\t\t\tinit_ctx->container->lxc_conf, 0, on_exec);\n\t\tif (proc_mounted)\n\t\t\tumount(\"/proc\");\n\t\tif (ret < 0) {\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\tif (init_ctx->container && init_ctx->container->lxc_conf &&\n\t\t\tlxc_seccomp_load(init_ctx->container->lxc_conf) != 0) {\n\t\tERROR(\"Loading seccomp policy\");\n\t\trexit(-1);\n\t}\n\n\tlxc_proc_put_context_info(init_ctx);\n\n\t/* The following is done after the communication socket is\n\t * shut down. That way, all errors that might (though\n\t * unlikely) occur up until this point will have their messages\n\t * printed to the original stderr (if logging is so configured)\n\t * and not the fd the user supplied, if any.\n\t */\n\n\t/* fd handling for stdin, stdout and stderr;\n\t * ignore errors here, user may want to make sure\n\t * the fds are closed, for example */\n\tif (options->stdin_fd >= 0 && options->stdin_fd != 0)\n\t\tdup2(options->stdin_fd, 0);\n\tif (options->stdout_fd >= 0 && options->stdout_fd != 1)\n\t\tdup2(options->stdout_fd, 1);\n\tif (options->stderr_fd >= 0 && options->stderr_fd != 2)\n\t\tdup2(options->stderr_fd, 2);\n\n\t/* close the old fds */\n\tif (options->stdin_fd > 2)\n\t\tclose(options->stdin_fd);\n\tif (options->stdout_fd > 2)\n\t\tclose(options->stdout_fd);\n\tif (options->stderr_fd > 2)\n\t\tclose(options->stderr_fd);\n\n\t/* try to remove CLOEXEC flag from stdin/stdout/stderr,\n\t * but also here, ignore errors */\n\tfor (fd = 0; fd <= 2; fd++) {\n\t\tflags = fcntl(fd, F_GETFL);\n\t\tif (flags < 0)\n\t\t\tcontinue;\n\t\tif (flags & FD_CLOEXEC) {\n\t\t\tif (fcntl(fd, F_SETFL, flags & ~FD_CLOEXEC) < 0) {\n\t\t\t\tSYSERROR(\"Unable to clear CLOEXEC from fd\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/* we're done, so we can now do whatever the user intended us to do */\n\trexit(payload->exec_function(payload->exec_payload));\n}",
        "func": "static int attach_child_main(void* data)\n{\n\tstruct attach_clone_payload* payload = (struct attach_clone_payload*)data;\n\tint ipc_socket = payload->ipc_socket;\n\tint procfd = payload->procfd;\n\tlxc_attach_options_t* options = payload->options;\n\tstruct lxc_proc_context_info* init_ctx = payload->init_ctx;\n#if HAVE_SYS_PERSONALITY_H\n\tlong new_personality;\n#endif\n\tint ret;\n\tint status;\n\tint expected;\n\tlong flags;\n\tint fd;\n\tuid_t new_uid;\n\tgid_t new_gid;\n\n\t/* wait for the initial thread to signal us that it's ready\n\t * for us to start initializing\n\t */\n\texpected = 0;\n\tstatus = -1;\n\tret = lxc_read_nointr_expect(ipc_socket, &status, sizeof(status), &expected);\n\tif (ret <= 0) {\n\t\tERROR(\"error using IPC to receive notification from initial process (0)\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* A description of the purpose of this functionality is\n\t * provided in the lxc-attach(1) manual page. We have to\n\t * remount here and not in the parent process, otherwise\n\t * /proc may not properly reflect the new pid namespace.\n\t */\n\tif (!(options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_REMOUNT_PROC_SYS)) {\n\t\tret = lxc_attach_remount_sys_proc();\n\t\tif (ret < 0) {\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\t/* now perform additional attachments*/\n#if HAVE_SYS_PERSONALITY_H\n\tif (options->personality < 0)\n\t\tnew_personality = init_ctx->personality;\n\telse\n\t\tnew_personality = options->personality;\n\n\tif (options->attach_flags & LXC_ATTACH_SET_PERSONALITY) {\n\t\tret = personality(new_personality);\n\t\tif (ret < 0) {\n\t\t\tSYSERROR(\"could not ensure correct architecture\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n#endif\n\n\tif (options->attach_flags & LXC_ATTACH_DROP_CAPABILITIES) {\n\t\tret = lxc_attach_drop_privs(init_ctx);\n\t\tif (ret < 0) {\n\t\t\tERROR(\"could not drop privileges\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\t/* always set the environment (specify (LXC_ATTACH_KEEP_ENV, NULL, NULL) if you want this to be a no-op) */\n\tret = lxc_attach_set_environment(options->env_policy, options->extra_env_vars, options->extra_keep_env);\n\tif (ret < 0) {\n\t\tERROR(\"could not set initial environment for attached process\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* set user / group id */\n\tnew_uid = 0;\n\tnew_gid = 0;\n\t/* ignore errors, we will fall back to root in that case\n\t * (/proc was not mounted etc.)\n\t */\n\tif (options->namespaces & CLONE_NEWUSER)\n\t\tlxc_attach_get_init_uidgid(&new_uid, &new_gid);\n\n\tif (options->uid != (uid_t)-1)\n\t\tnew_uid = options->uid;\n\tif (options->gid != (gid_t)-1)\n\t\tnew_gid = options->gid;\n\n\t/* setup the control tty */\n\tif (options->stdin_fd && isatty(options->stdin_fd)) {\n\t\tif (setsid() < 0) {\n\t\t\tSYSERROR(\"unable to setsid\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\n\t\tif (ioctl(options->stdin_fd, TIOCSCTTY, (char *)NULL) < 0) {\n\t\t\tSYSERROR(\"unable to TIOCSTTY\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\t/* try to set the uid/gid combination */\n\tif ((new_gid != 0 || options->namespaces & CLONE_NEWUSER)) {\n\t\tif (setgid(new_gid) || setgroups(0, NULL)) {\n\t\t\tSYSERROR(\"switching to container gid\");\n\t\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\t\trexit(-1);\n\t\t}\n\t}\n\tif ((new_uid != 0 || options->namespaces & CLONE_NEWUSER) && setuid(new_uid)) {\n\t\tSYSERROR(\"switching to container uid\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* tell initial process it may now put us into the cgroups */\n\tstatus = 1;\n\tret = lxc_write_nointr(ipc_socket, &status, sizeof(status));\n\tif (ret != sizeof(status)) {\n\t\tERROR(\"error using IPC to notify initial process for initialization (1)\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* wait for the initial thread to signal us that it has done\n\t * everything for us when it comes to cgroups etc.\n\t */\n\texpected = 2;\n\tstatus = -1;\n\tret = lxc_read_nointr_expect(ipc_socket, &status, sizeof(status), &expected);\n\tif (ret <= 0) {\n\t\tERROR(\"error using IPC to receive final notification from initial process (2)\");\n\t\tshutdown(ipc_socket, SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\tshutdown(ipc_socket, SHUT_RDWR);\n\tclose(ipc_socket);\n\n\t/* set new apparmor profile/selinux context */\n\tif ((options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_LSM) && init_ctx->lsm_label) {\n\t\tint on_exec;\n\n\t\ton_exec = options->attach_flags & LXC_ATTACH_LSM_EXEC ? 1 : 0;\n\t\tif (lsm_set_label_at(procfd, on_exec, init_ctx->lsm_label) < 0) {\n\t\t\trexit(-1);\n\t\t}\n\t}\n\n\tif (init_ctx->container && init_ctx->container->lxc_conf &&\n\t\t\tlxc_seccomp_load(init_ctx->container->lxc_conf) != 0) {\n\t\tERROR(\"Loading seccomp policy\");\n\t\trexit(-1);\n\t}\n\n\tlxc_proc_put_context_info(init_ctx);\n\n\t/* The following is done after the communication socket is\n\t * shut down. That way, all errors that might (though\n\t * unlikely) occur up until this point will have their messages\n\t * printed to the original stderr (if logging is so configured)\n\t * and not the fd the user supplied, if any.\n\t */\n\n\t/* fd handling for stdin, stdout and stderr;\n\t * ignore errors here, user may want to make sure\n\t * the fds are closed, for example */\n\tif (options->stdin_fd >= 0 && options->stdin_fd != 0)\n\t\tdup2(options->stdin_fd, 0);\n\tif (options->stdout_fd >= 0 && options->stdout_fd != 1)\n\t\tdup2(options->stdout_fd, 1);\n\tif (options->stderr_fd >= 0 && options->stderr_fd != 2)\n\t\tdup2(options->stderr_fd, 2);\n\n\t/* close the old fds */\n\tif (options->stdin_fd > 2)\n\t\tclose(options->stdin_fd);\n\tif (options->stdout_fd > 2)\n\t\tclose(options->stdout_fd);\n\tif (options->stderr_fd > 2)\n\t\tclose(options->stderr_fd);\n\n\t/* try to remove CLOEXEC flag from stdin/stdout/stderr,\n\t * but also here, ignore errors */\n\tfor (fd = 0; fd <= 2; fd++) {\n\t\tflags = fcntl(fd, F_GETFL);\n\t\tif (flags < 0)\n\t\t\tcontinue;\n\t\tif (flags & FD_CLOEXEC) {\n\t\t\tif (fcntl(fd, F_SETFL, flags & ~FD_CLOEXEC) < 0) {\n\t\t\t\tSYSERROR(\"Unable to clear CLOEXEC from fd\");\n\t\t\t}\n\t\t}\n\t}\n\n\t/* we don't need proc anymore */\n\tclose(procfd);\n\n\t/* we're done, so we can now do whatever the user intended us to do */\n\trexit(payload->exec_function(payload->exec_payload));\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,7 @@\n {\n \tstruct attach_clone_payload* payload = (struct attach_clone_payload*)data;\n \tint ipc_socket = payload->ipc_socket;\n+\tint procfd = payload->procfd;\n \tlxc_attach_options_t* options = payload->options;\n \tstruct lxc_proc_context_info* init_ctx = payload->init_ctx;\n #if HAVE_SYS_PERSONALITY_H\n@@ -142,21 +143,11 @@\n \tclose(ipc_socket);\n \n \t/* set new apparmor profile/selinux context */\n-\tif ((options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_LSM)) {\n+\tif ((options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_LSM) && init_ctx->lsm_label) {\n \t\tint on_exec;\n-\t\tint proc_mounted;\n \n \t\ton_exec = options->attach_flags & LXC_ATTACH_LSM_EXEC ? 1 : 0;\n-\t\tproc_mounted = mount_proc_if_needed(\"/\");\n-\t\tif (proc_mounted == -1) {\n-\t\t\tERROR(\"Error mounting a sane /proc\");\n-\t\t\trexit(-1);\n-\t\t}\n-\t\tret = lsm_process_label_set(init_ctx->lsm_label,\n-\t\t\t\tinit_ctx->container->lxc_conf, 0, on_exec);\n-\t\tif (proc_mounted)\n-\t\t\tumount(\"/proc\");\n-\t\tif (ret < 0) {\n+\t\tif (lsm_set_label_at(procfd, on_exec, init_ctx->lsm_label) < 0) {\n \t\t\trexit(-1);\n \t\t}\n \t}\n@@ -207,6 +198,9 @@\n \t\t}\n \t}\n \n+\t/* we don't need proc anymore */\n+\tclose(procfd);\n+\n \t/* we're done, so we can now do whatever the user intended us to do */\n \trexit(payload->exec_function(payload->exec_payload));\n }",
        "diff_line_info": {
            "deleted_lines": [
                "\tif ((options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_LSM)) {",
                "\t\tint proc_mounted;",
                "\t\tproc_mounted = mount_proc_if_needed(\"/\");",
                "\t\tif (proc_mounted == -1) {",
                "\t\t\tERROR(\"Error mounting a sane /proc\");",
                "\t\t\trexit(-1);",
                "\t\t}",
                "\t\tret = lsm_process_label_set(init_ctx->lsm_label,",
                "\t\t\t\tinit_ctx->container->lxc_conf, 0, on_exec);",
                "\t\tif (proc_mounted)",
                "\t\t\tumount(\"/proc\");",
                "\t\tif (ret < 0) {"
            ],
            "added_lines": [
                "\tint procfd = payload->procfd;",
                "\tif ((options->namespaces & CLONE_NEWNS) && (options->attach_flags & LXC_ATTACH_LSM) && init_ctx->lsm_label) {",
                "\t\tif (lsm_set_label_at(procfd, on_exec, init_ctx->lsm_label) < 0) {",
                "\t/* we don't need proc anymore */",
                "\tclose(procfd);",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-1334",
        "func_name": "lxc/lxc_attach",
        "description": "attach.c in LXC 1.1.2 and earlier uses the proc filesystem in a container, which allows local container users to escape AppArmor or SELinux confinement by mounting a proc filesystem with a crafted (1) AppArmor profile or (2) SELinux label.",
        "git_url": "https://github.com/lxc/lxc/commit/5c3fcae78b63ac9dd56e36075903921bd9461f9e",
        "commit_title": "CVE-2015-1334: Don't use the container's /proc during attach",
        "commit_text": " A user could otherwise over-mount /proc and prevent the apparmor profile or selinux label from being written which combined with a modified /bin/sh or other commonly used binary would lead to unconfined code execution. ",
        "func_before": "int lxc_attach(const char* name, const char* lxcpath, lxc_attach_exec_t exec_function, void* exec_payload, lxc_attach_options_t* options, pid_t* attached_process)\n{\n\tint ret, status;\n\tpid_t init_pid, pid, attached_pid, expected;\n\tstruct lxc_proc_context_info *init_ctx;\n\tchar* cwd;\n\tchar* new_cwd;\n\tint ipc_sockets[2];\n\tsigned long personality;\n\n\tif (!options)\n\t\toptions = &attach_static_default_options;\n\n\tinit_pid = lxc_cmd_get_init_pid(name, lxcpath);\n\tif (init_pid < 0) {\n\t\tERROR(\"failed to get the init pid\");\n\t\treturn -1;\n\t}\n\n\tinit_ctx = lxc_proc_get_context_info(init_pid);\n\tif (!init_ctx) {\n\t\tERROR(\"failed to get context of the init process, pid = %ld\", (long)init_pid);\n\t\treturn -1;\n\t}\n\n\tpersonality = get_personality(name, lxcpath);\n\tif (init_ctx->personality < 0) {\n\t\tERROR(\"Failed to get personality of the container\");\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\tinit_ctx->personality = personality;\n\n\tif (!fetch_seccomp(name, lxcpath, init_ctx, options))\n\t\tWARN(\"Failed to get seccomp policy\");\n\n\tcwd = getcwd(NULL, 0);\n\n\t/* determine which namespaces the container was created with\n\t * by asking lxc-start, if necessary\n\t */\n\tif (options->namespaces == -1) {\n\t\toptions->namespaces = lxc_cmd_get_clone_flags(name, lxcpath);\n\t\t/* call failed */\n\t\tif (options->namespaces == -1) {\n\t\t\tERROR(\"failed to automatically determine the \"\n\t\t\t      \"namespaces which the container unshared\");\n\t\t\tfree(cwd);\n\t\t\tlxc_proc_put_context_info(init_ctx);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t/* create a socket pair for IPC communication; set SOCK_CLOEXEC in order\n\t * to make sure we don't irritate other threads that want to fork+exec away\n\t *\n\t * IMPORTANT: if the initial process is multithreaded and another call\n\t * just fork()s away without exec'ing directly after, the socket fd will\n\t * exist in the forked process from the other thread and any close() in\n\t * our own child process will not really cause the socket to close properly,\n\t * potentiall causing the parent to hang.\n\t *\n\t * For this reason, while IPC is still active, we have to use shutdown()\n\t * if the child exits prematurely in order to signal that the socket\n\t * is closed and cannot assume that the child exiting will automatically\n\t * do that.\n\t *\n\t * IPC mechanism: (X is receiver)\n\t *   initial process        intermediate          attached\n\t *        X           <---  send pid of\n\t *                          attached proc,\n\t *                          then exit\n\t *    send 0 ------------------------------------>    X\n\t *                                              [do initialization]\n\t *        X  <------------------------------------  send 1\n\t *   [add to cgroup, ...]\n\t *    send 2 ------------------------------------>    X\n\t *   close socket                                 close socket\n\t *                                                run program\n\t */\n\tret = socketpair(PF_LOCAL, SOCK_STREAM | SOCK_CLOEXEC, 0, ipc_sockets);\n\tif (ret < 0) {\n\t\tSYSERROR(\"could not set up required IPC mechanism for attaching\");\n\t\tfree(cwd);\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\n\t/* create intermediate subprocess, three reasons:\n\t *       1. runs all pthread_atfork handlers and the\n\t *          child will no longer be threaded\n\t *          (we can't properly setns() in a threaded process)\n\t *       2. we can't setns() in the child itself, since\n\t *          we want to make sure we are properly attached to\n\t *          the pidns\n\t *       3. also, the initial thread has to put the attached\n\t *          process into the cgroup, which we can only do if\n\t *          we didn't already setns() (otherwise, user\n\t *          namespaces will hate us)\n\t */\n\tpid = fork();\n\n\tif (pid < 0) {\n\t\tSYSERROR(\"failed to create first subprocess\");\n\t\tfree(cwd);\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\n\tif (pid) {\n\t\tpid_t to_cleanup_pid = pid;\n\n\t\t/* initial thread, we close the socket that is for the\n\t\t * subprocesses\n\t\t */\n\t\tclose(ipc_sockets[1]);\n\t\tfree(cwd);\n\n\t\t/* attach to cgroup, if requested */\n\t\tif (options->attach_flags & LXC_ATTACH_MOVE_TO_CGROUP) {\n\t\t\tif (!cgroup_attach(name, lxcpath, pid))\n\t\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* Let the child process know to go ahead */\n\t\tstatus = 0;\n\t\tret = lxc_write_nointr(ipc_sockets[0], &status, sizeof(status));\n\t\tif (ret <= 0) {\n\t\t\tERROR(\"error using IPC to notify attached process for initialization (0)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* get pid from intermediate process */\n\t\tret = lxc_read_nointr_expect(ipc_sockets[0], &attached_pid, sizeof(attached_pid), NULL);\n\t\tif (ret <= 0) {\n\t\t\tif (ret != 0)\n\t\t\t\tERROR(\"error using IPC to receive pid of attached process\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* ignore SIGKILL (CTRL-C) and SIGQUIT (CTRL-\\) - issue #313 */\n\t\tif (options->stdin_fd == 0) {\n\t\t\tsignal(SIGINT, SIG_IGN);\n\t\t\tsignal(SIGQUIT, SIG_IGN);\n\t\t}\n\n\t\t/* reap intermediate process */\n\t\tret = wait_for_pid(pid);\n\t\tif (ret < 0)\n\t\t\tgoto cleanup_error;\n\n\t\t/* we will always have to reap the grandchild now */\n\t\tto_cleanup_pid = attached_pid;\n\n\t\t/* tell attached process it may start initializing */\n\t\tstatus = 0;\n\t\tret = lxc_write_nointr(ipc_sockets[0], &status, sizeof(status));\n\t\tif (ret <= 0) {\n\t\t\tERROR(\"error using IPC to notify attached process for initialization (0)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* wait for the attached process to finish initializing */\n\t\texpected = 1;\n\t\tret = lxc_read_nointr_expect(ipc_sockets[0], &status, sizeof(status), &expected);\n\t\tif (ret <= 0) {\n\t\t\tif (ret != 0)\n\t\t\t\tERROR(\"error using IPC to receive notification from attached process (1)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* tell attached process we're done */\n\t\tstatus = 2;\n\t\tret = lxc_write_nointr(ipc_sockets[0], &status, sizeof(status));\n\t\tif (ret <= 0) {\n\t\t\tERROR(\"error using IPC to notify attached process for initialization (2)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* now shut down communication with child, we're done */\n\t\tshutdown(ipc_sockets[0], SHUT_RDWR);\n\t\tclose(ipc_sockets[0]);\n\t\tlxc_proc_put_context_info(init_ctx);\n\n\t\t/* we're done, the child process should now execute whatever\n\t\t * it is that the user requested. The parent can now track it\n\t\t * with waitpid() or similar.\n\t\t */\n\n\t\t*attached_process = attached_pid;\n\t\treturn 0;\n\n\tcleanup_error:\n\t\t/* first shut down the socket, then wait for the pid,\n\t\t * otherwise the pid we're waiting for may never exit\n\t\t */\n\t\tshutdown(ipc_sockets[0], SHUT_RDWR);\n\t\tclose(ipc_sockets[0]);\n\t\tif (to_cleanup_pid)\n\t\t\t(void) wait_for_pid(to_cleanup_pid);\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\n\t/* first subprocess begins here, we close the socket that is for the\n\t * initial thread\n\t */\n\tclose(ipc_sockets[0]);\n\n\t/* Wait for the parent to have setup cgroups */\n\texpected = 0;\n\tstatus = -1;\n\tret = lxc_read_nointr_expect(ipc_sockets[1], &status, sizeof(status), &expected);\n\tif (ret <= 0) {\n\t\tERROR(\"error communicating with child process\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* attach now, create another subprocess later, since pid namespaces\n\t * only really affect the children of the current process\n\t */\n\tret = lxc_attach_to_ns(init_pid, options->namespaces);\n\tif (ret < 0) {\n\t\tERROR(\"failed to enter the namespace\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* attach succeeded, try to cwd */\n\tif (options->initial_cwd)\n\t\tnew_cwd = options->initial_cwd;\n\telse\n\t\tnew_cwd = cwd;\n\tret = chdir(new_cwd);\n\tif (ret < 0)\n\t\tWARN(\"could not change directory to '%s'\", new_cwd);\n\tfree(cwd);\n\n\t/* now create the real child process */\n\t{\n\t\tstruct attach_clone_payload payload = {\n\t\t\t.ipc_socket = ipc_sockets[1],\n\t\t\t.options = options,\n\t\t\t.init_ctx = init_ctx,\n\t\t\t.exec_function = exec_function,\n\t\t\t.exec_payload = exec_payload\n\t\t};\n\t\t/* We use clone_parent here to make this subprocess a direct child of\n\t\t * the initial process. Then this intermediate process can exit and\n\t\t * the parent can directly track the attached process.\n\t\t */\n\t\tpid = lxc_clone(attach_child_main, &payload, CLONE_PARENT);\n\t}\n\n\t/* shouldn't happen, clone() should always return positive pid */\n\tif (pid <= 0) {\n\t\tSYSERROR(\"failed to create subprocess\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* tell grandparent the pid of the pid of the newly created child */\n\tret = lxc_write_nointr(ipc_sockets[1], &pid, sizeof(pid));\n\tif (ret != sizeof(pid)) {\n\t\t/* if this really happens here, this is very unfortunate, since the\n\t\t * parent will not know the pid of the attached process and will\n\t\t * not be able to wait for it (and we won't either due to CLONE_PARENT)\n\t\t * so the parent won't be able to reap it and the attached process\n\t\t * will remain a zombie\n\t\t */\n\t\tERROR(\"error using IPC to notify main process of pid of the attached process\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* the rest is in the hands of the initial and the attached process */\n\trexit(0);\n}",
        "func": "int lxc_attach(const char* name, const char* lxcpath, lxc_attach_exec_t exec_function, void* exec_payload, lxc_attach_options_t* options, pid_t* attached_process)\n{\n\tint ret, status;\n\tpid_t init_pid, pid, attached_pid, expected;\n\tstruct lxc_proc_context_info *init_ctx;\n\tchar* cwd;\n\tchar* new_cwd;\n\tint ipc_sockets[2];\n\tint procfd;\n\tsigned long personality;\n\n\tif (!options)\n\t\toptions = &attach_static_default_options;\n\n\tinit_pid = lxc_cmd_get_init_pid(name, lxcpath);\n\tif (init_pid < 0) {\n\t\tERROR(\"failed to get the init pid\");\n\t\treturn -1;\n\t}\n\n\tinit_ctx = lxc_proc_get_context_info(init_pid);\n\tif (!init_ctx) {\n\t\tERROR(\"failed to get context of the init process, pid = %ld\", (long)init_pid);\n\t\treturn -1;\n\t}\n\n\tpersonality = get_personality(name, lxcpath);\n\tif (init_ctx->personality < 0) {\n\t\tERROR(\"Failed to get personality of the container\");\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\tinit_ctx->personality = personality;\n\n\tif (!fetch_seccomp(name, lxcpath, init_ctx, options))\n\t\tWARN(\"Failed to get seccomp policy\");\n\n\tcwd = getcwd(NULL, 0);\n\n\t/* determine which namespaces the container was created with\n\t * by asking lxc-start, if necessary\n\t */\n\tif (options->namespaces == -1) {\n\t\toptions->namespaces = lxc_cmd_get_clone_flags(name, lxcpath);\n\t\t/* call failed */\n\t\tif (options->namespaces == -1) {\n\t\t\tERROR(\"failed to automatically determine the \"\n\t\t\t      \"namespaces which the container unshared\");\n\t\t\tfree(cwd);\n\t\t\tlxc_proc_put_context_info(init_ctx);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t/* create a socket pair for IPC communication; set SOCK_CLOEXEC in order\n\t * to make sure we don't irritate other threads that want to fork+exec away\n\t *\n\t * IMPORTANT: if the initial process is multithreaded and another call\n\t * just fork()s away without exec'ing directly after, the socket fd will\n\t * exist in the forked process from the other thread and any close() in\n\t * our own child process will not really cause the socket to close properly,\n\t * potentiall causing the parent to hang.\n\t *\n\t * For this reason, while IPC is still active, we have to use shutdown()\n\t * if the child exits prematurely in order to signal that the socket\n\t * is closed and cannot assume that the child exiting will automatically\n\t * do that.\n\t *\n\t * IPC mechanism: (X is receiver)\n\t *   initial process        intermediate          attached\n\t *        X           <---  send pid of\n\t *                          attached proc,\n\t *                          then exit\n\t *    send 0 ------------------------------------>    X\n\t *                                              [do initialization]\n\t *        X  <------------------------------------  send 1\n\t *   [add to cgroup, ...]\n\t *    send 2 ------------------------------------>    X\n\t *   close socket                                 close socket\n\t *                                                run program\n\t */\n\tret = socketpair(PF_LOCAL, SOCK_STREAM | SOCK_CLOEXEC, 0, ipc_sockets);\n\tif (ret < 0) {\n\t\tSYSERROR(\"could not set up required IPC mechanism for attaching\");\n\t\tfree(cwd);\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\n\t/* create intermediate subprocess, three reasons:\n\t *       1. runs all pthread_atfork handlers and the\n\t *          child will no longer be threaded\n\t *          (we can't properly setns() in a threaded process)\n\t *       2. we can't setns() in the child itself, since\n\t *          we want to make sure we are properly attached to\n\t *          the pidns\n\t *       3. also, the initial thread has to put the attached\n\t *          process into the cgroup, which we can only do if\n\t *          we didn't already setns() (otherwise, user\n\t *          namespaces will hate us)\n\t */\n\tpid = fork();\n\n\tif (pid < 0) {\n\t\tSYSERROR(\"failed to create first subprocess\");\n\t\tfree(cwd);\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\n\tif (pid) {\n\t\tpid_t to_cleanup_pid = pid;\n\n\t\t/* initial thread, we close the socket that is for the\n\t\t * subprocesses\n\t\t */\n\t\tclose(ipc_sockets[1]);\n\t\tfree(cwd);\n\n\t\t/* attach to cgroup, if requested */\n\t\tif (options->attach_flags & LXC_ATTACH_MOVE_TO_CGROUP) {\n\t\t\tif (!cgroup_attach(name, lxcpath, pid))\n\t\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* Let the child process know to go ahead */\n\t\tstatus = 0;\n\t\tret = lxc_write_nointr(ipc_sockets[0], &status, sizeof(status));\n\t\tif (ret <= 0) {\n\t\t\tERROR(\"error using IPC to notify attached process for initialization (0)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* get pid from intermediate process */\n\t\tret = lxc_read_nointr_expect(ipc_sockets[0], &attached_pid, sizeof(attached_pid), NULL);\n\t\tif (ret <= 0) {\n\t\t\tif (ret != 0)\n\t\t\t\tERROR(\"error using IPC to receive pid of attached process\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* ignore SIGKILL (CTRL-C) and SIGQUIT (CTRL-\\) - issue #313 */\n\t\tif (options->stdin_fd == 0) {\n\t\t\tsignal(SIGINT, SIG_IGN);\n\t\t\tsignal(SIGQUIT, SIG_IGN);\n\t\t}\n\n\t\t/* reap intermediate process */\n\t\tret = wait_for_pid(pid);\n\t\tif (ret < 0)\n\t\t\tgoto cleanup_error;\n\n\t\t/* we will always have to reap the grandchild now */\n\t\tto_cleanup_pid = attached_pid;\n\n\t\t/* tell attached process it may start initializing */\n\t\tstatus = 0;\n\t\tret = lxc_write_nointr(ipc_sockets[0], &status, sizeof(status));\n\t\tif (ret <= 0) {\n\t\t\tERROR(\"error using IPC to notify attached process for initialization (0)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* wait for the attached process to finish initializing */\n\t\texpected = 1;\n\t\tret = lxc_read_nointr_expect(ipc_sockets[0], &status, sizeof(status), &expected);\n\t\tif (ret <= 0) {\n\t\t\tif (ret != 0)\n\t\t\t\tERROR(\"error using IPC to receive notification from attached process (1)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* tell attached process we're done */\n\t\tstatus = 2;\n\t\tret = lxc_write_nointr(ipc_sockets[0], &status, sizeof(status));\n\t\tif (ret <= 0) {\n\t\t\tERROR(\"error using IPC to notify attached process for initialization (2)\");\n\t\t\tgoto cleanup_error;\n\t\t}\n\n\t\t/* now shut down communication with child, we're done */\n\t\tshutdown(ipc_sockets[0], SHUT_RDWR);\n\t\tclose(ipc_sockets[0]);\n\t\tlxc_proc_put_context_info(init_ctx);\n\n\t\t/* we're done, the child process should now execute whatever\n\t\t * it is that the user requested. The parent can now track it\n\t\t * with waitpid() or similar.\n\t\t */\n\n\t\t*attached_process = attached_pid;\n\t\treturn 0;\n\n\tcleanup_error:\n\t\t/* first shut down the socket, then wait for the pid,\n\t\t * otherwise the pid we're waiting for may never exit\n\t\t */\n\t\tshutdown(ipc_sockets[0], SHUT_RDWR);\n\t\tclose(ipc_sockets[0]);\n\t\tif (to_cleanup_pid)\n\t\t\t(void) wait_for_pid(to_cleanup_pid);\n\t\tlxc_proc_put_context_info(init_ctx);\n\t\treturn -1;\n\t}\n\n\t/* first subprocess begins here, we close the socket that is for the\n\t * initial thread\n\t */\n\tclose(ipc_sockets[0]);\n\n\t/* Wait for the parent to have setup cgroups */\n\texpected = 0;\n\tstatus = -1;\n\tret = lxc_read_nointr_expect(ipc_sockets[1], &status, sizeof(status), &expected);\n\tif (ret <= 0) {\n\t\tERROR(\"error communicating with child process\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\tprocfd = open(\"/proc\", O_DIRECTORY | O_RDONLY);\n\tif (procfd < 0) {\n\t\tSYSERROR(\"Unable to open /proc\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* attach now, create another subprocess later, since pid namespaces\n\t * only really affect the children of the current process\n\t */\n\tret = lxc_attach_to_ns(init_pid, options->namespaces);\n\tif (ret < 0) {\n\t\tERROR(\"failed to enter the namespace\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* attach succeeded, try to cwd */\n\tif (options->initial_cwd)\n\t\tnew_cwd = options->initial_cwd;\n\telse\n\t\tnew_cwd = cwd;\n\tret = chdir(new_cwd);\n\tif (ret < 0)\n\t\tWARN(\"could not change directory to '%s'\", new_cwd);\n\tfree(cwd);\n\n\t/* now create the real child process */\n\t{\n\t\tstruct attach_clone_payload payload = {\n\t\t\t.ipc_socket = ipc_sockets[1],\n\t\t\t.options = options,\n\t\t\t.init_ctx = init_ctx,\n\t\t\t.exec_function = exec_function,\n\t\t\t.exec_payload = exec_payload,\n\t\t\t.procfd = procfd\n\t\t};\n\t\t/* We use clone_parent here to make this subprocess a direct child of\n\t\t * the initial process. Then this intermediate process can exit and\n\t\t * the parent can directly track the attached process.\n\t\t */\n\t\tpid = lxc_clone(attach_child_main, &payload, CLONE_PARENT);\n\t}\n\n\t/* shouldn't happen, clone() should always return positive pid */\n\tif (pid <= 0) {\n\t\tSYSERROR(\"failed to create subprocess\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* tell grandparent the pid of the pid of the newly created child */\n\tret = lxc_write_nointr(ipc_sockets[1], &pid, sizeof(pid));\n\tif (ret != sizeof(pid)) {\n\t\t/* if this really happens here, this is very unfortunate, since the\n\t\t * parent will not know the pid of the attached process and will\n\t\t * not be able to wait for it (and we won't either due to CLONE_PARENT)\n\t\t * so the parent won't be able to reap it and the attached process\n\t\t * will remain a zombie\n\t\t */\n\t\tERROR(\"error using IPC to notify main process of pid of the attached process\");\n\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n\t\trexit(-1);\n\t}\n\n\t/* the rest is in the hands of the initial and the attached process */\n\trexit(0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,7 @@\n \tchar* cwd;\n \tchar* new_cwd;\n \tint ipc_sockets[2];\n+\tint procfd;\n \tsigned long personality;\n \n \tif (!options)\n@@ -217,6 +218,13 @@\n \t\trexit(-1);\n \t}\n \n+\tprocfd = open(\"/proc\", O_DIRECTORY | O_RDONLY);\n+\tif (procfd < 0) {\n+\t\tSYSERROR(\"Unable to open /proc\");\n+\t\tshutdown(ipc_sockets[1], SHUT_RDWR);\n+\t\trexit(-1);\n+\t}\n+\n \t/* attach now, create another subprocess later, since pid namespaces\n \t * only really affect the children of the current process\n \t */\n@@ -244,7 +252,8 @@\n \t\t\t.options = options,\n \t\t\t.init_ctx = init_ctx,\n \t\t\t.exec_function = exec_function,\n-\t\t\t.exec_payload = exec_payload\n+\t\t\t.exec_payload = exec_payload,\n+\t\t\t.procfd = procfd\n \t\t};\n \t\t/* We use clone_parent here to make this subprocess a direct child of\n \t\t * the initial process. Then this intermediate process can exit and",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t.exec_payload = exec_payload"
            ],
            "added_lines": [
                "\tint procfd;",
                "\tprocfd = open(\"/proc\", O_DIRECTORY | O_RDONLY);",
                "\tif (procfd < 0) {",
                "\t\tSYSERROR(\"Unable to open /proc\");",
                "\t\tshutdown(ipc_sockets[1], SHUT_RDWR);",
                "\t\trexit(-1);",
                "\t}",
                "",
                "\t\t\t.exec_payload = exec_payload,",
                "\t\t\t.procfd = procfd"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9731",
        "func_name": "torvalds/linux/udf_find_entry",
        "description": "The UDF filesystem implementation in the Linux kernel before 3.18.2 does not ensure that space is available for storing a symlink target's name along with a trailing \\0 character, which allows local users to obtain sensitive information via a crafted filesystem image, related to fs/udf/symlink.c and fs/udf/unicode.c.",
        "git_url": "https://github.com/torvalds/linux/commit/0e5cc9a40ada6046e6bc3bdfcd0c0d7e4b706b14",
        "commit_title": "udf: Check path length when reading symlink",
        "commit_text": " Symlink reading code does not check whether the resulting path fits into the page provided by the generic code. This isn't as easy as just checking the symlink size because of various encoding conversions we perform on path. So we have to check whether there is still enough space in the buffer on the fly. ",
        "func_before": "static struct fileIdentDesc *udf_find_entry(struct inode *dir,\n\t\t\t\t\t    const struct qstr *child,\n\t\t\t\t\t    struct udf_fileident_bh *fibh,\n\t\t\t\t\t    struct fileIdentDesc *cfi)\n{\n\tstruct fileIdentDesc *fi = NULL;\n\tloff_t f_pos;\n\tint block, flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint8_t lfi;\n\tuint16_t liu;\n\tloff_t size;\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tstruct extent_position epos = {};\n\tstruct udf_inode_info *dinfo = UDF_I(dir);\n\tint isdotdot = child->len == 2 &&\n\t\tchild->name[0] == '.' && child->name[1] == '.';\n\n\tsize = udf_ext0_offset(dir) + dir->i_size;\n\tf_pos = udf_ext0_offset(dir);\n\n\tfibh->sbh = fibh->ebh = NULL;\n\tfibh->soffset = fibh->eoffset = f_pos & (dir->i_sb->s_blocksize - 1);\n\tif (dinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, f_pos >> dir->i_sb->s_blocksize_bits, &epos,\n\t\t    &eloc, &elen, &offset) != (EXT_RECORDED_ALLOCATED >> 30))\n\t\t\tgoto out_err;\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (dinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (dinfo->i_alloc_type == ICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else\n\t\t\toffset = 0;\n\n\t\tfibh->sbh = fibh->ebh = udf_tread(dir->i_sb, block);\n\t\tif (!fibh->sbh)\n\t\t\tgoto out_err;\n\t}\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname)\n\t\tgoto out_err;\n\n\twhile (f_pos < size) {\n\t\tfi = udf_fileident_read(dir, &f_pos, fibh, cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out_err;\n\n\t\tliu = le16_to_cpu(cfi->lengthOfImpUse);\n\t\tlfi = cfi->lengthFileIdent;\n\n\t\tif (fibh->sbh == fibh->ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh->soffset + sizeof(struct fileIdentDesc) +\n\t\t\t\t\tliu + lfi;\n\n\t\t\tif (poffset >= lfi)\n\t\t\t\tnameptr = (uint8_t *)(fibh->ebh->b_data +\n\t\t\t\t\t\t      poffset - lfi);\n\t\t\telse {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t\tlfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t\tfibh->ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_PARENT) &&\n\t\t    isdotdot)\n\t\t\tgoto out_ok;\n\n\t\tif (!lfi)\n\t\t\tcontinue;\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);\n\t\tif (flen && udf_match(flen, fname, child->len, child->name))\n\t\t\tgoto out_ok;\n\t}\n\nout_err:\n\tfi = NULL;\n\tif (fibh->sbh != fibh->ebh)\n\t\tbrelse(fibh->ebh);\n\tbrelse(fibh->sbh);\nout_ok:\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn fi;\n}",
        "func": "static struct fileIdentDesc *udf_find_entry(struct inode *dir,\n\t\t\t\t\t    const struct qstr *child,\n\t\t\t\t\t    struct udf_fileident_bh *fibh,\n\t\t\t\t\t    struct fileIdentDesc *cfi)\n{\n\tstruct fileIdentDesc *fi = NULL;\n\tloff_t f_pos;\n\tint block, flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint8_t lfi;\n\tuint16_t liu;\n\tloff_t size;\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tstruct extent_position epos = {};\n\tstruct udf_inode_info *dinfo = UDF_I(dir);\n\tint isdotdot = child->len == 2 &&\n\t\tchild->name[0] == '.' && child->name[1] == '.';\n\n\tsize = udf_ext0_offset(dir) + dir->i_size;\n\tf_pos = udf_ext0_offset(dir);\n\n\tfibh->sbh = fibh->ebh = NULL;\n\tfibh->soffset = fibh->eoffset = f_pos & (dir->i_sb->s_blocksize - 1);\n\tif (dinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, f_pos >> dir->i_sb->s_blocksize_bits, &epos,\n\t\t    &eloc, &elen, &offset) != (EXT_RECORDED_ALLOCATED >> 30))\n\t\t\tgoto out_err;\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (dinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (dinfo->i_alloc_type == ICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else\n\t\t\toffset = 0;\n\n\t\tfibh->sbh = fibh->ebh = udf_tread(dir->i_sb, block);\n\t\tif (!fibh->sbh)\n\t\t\tgoto out_err;\n\t}\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname)\n\t\tgoto out_err;\n\n\twhile (f_pos < size) {\n\t\tfi = udf_fileident_read(dir, &f_pos, fibh, cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out_err;\n\n\t\tliu = le16_to_cpu(cfi->lengthOfImpUse);\n\t\tlfi = cfi->lengthFileIdent;\n\n\t\tif (fibh->sbh == fibh->ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh->soffset + sizeof(struct fileIdentDesc) +\n\t\t\t\t\tliu + lfi;\n\n\t\t\tif (poffset >= lfi)\n\t\t\t\tnameptr = (uint8_t *)(fibh->ebh->b_data +\n\t\t\t\t\t\t      poffset - lfi);\n\t\t\telse {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t\tlfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t\tfibh->ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi->fileCharacteristics & FID_FILE_CHAR_PARENT) &&\n\t\t    isdotdot)\n\t\t\tgoto out_ok;\n\n\t\tif (!lfi)\n\t\t\tcontinue;\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,\n\t\t\t\t\tUDF_NAME_LEN);\n\t\tif (flen && udf_match(flen, fname, child->len, child->name))\n\t\t\tgoto out_ok;\n\t}\n\nout_err:\n\tfi = NULL;\n\tif (fibh->sbh != fibh->ebh)\n\t\tbrelse(fibh->ebh);\n\tbrelse(fibh->sbh);\nout_ok:\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn fi;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -92,7 +92,8 @@\n \t\tif (!lfi)\n \t\t\tcontinue;\n \n-\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);\n+\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,\n+\t\t\t\t\tUDF_NAME_LEN);\n \t\tif (flen && udf_match(flen, fname, child->len, child->name))\n \t\t\tgoto out_ok;\n \t}",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);"
            ],
            "added_lines": [
                "\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,",
                "\t\t\t\t\tUDF_NAME_LEN);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9731",
        "func_name": "torvalds/linux/udf_translate_to_linux",
        "description": "The UDF filesystem implementation in the Linux kernel before 3.18.2 does not ensure that space is available for storing a symlink target's name along with a trailing \\0 character, which allows local users to obtain sensitive information via a crafted filesystem image, related to fs/udf/symlink.c and fs/udf/unicode.c.",
        "git_url": "https://github.com/torvalds/linux/commit/0e5cc9a40ada6046e6bc3bdfcd0c0d7e4b706b14",
        "commit_title": "udf: Check path length when reading symlink",
        "commit_text": " Symlink reading code does not check whether the resulting path fits into the page provided by the generic code. This isn't as easy as just checking the symlink size because of various encoding conversions we perform on path. So we have to check whether there is still enough space in the buffer on the fly. ",
        "func_before": "static int udf_translate_to_linux(uint8_t *newName, uint8_t *udfName,\n\t\t\t\t  int udfLen, uint8_t *fidName,\n\t\t\t\t  int fidNameLen)\n{\n\tint index, newIndex = 0, needsCRC = 0;\n\tint extIndex = 0, newExtIndex = 0, hasExt = 0;\n\tunsigned short valueCRC;\n\tuint8_t curr;\n\n\tif (udfName[0] == '.' &&\n\t    (udfLen == 1 || (udfLen == 2 && udfName[1] == '.'))) {\n\t\tneedsCRC = 1;\n\t\tnewIndex = udfLen;\n\t\tmemcpy(newName, udfName, udfLen);\n\t} else {\n\t\tfor (index = 0; index < udfLen; index++) {\n\t\t\tcurr = udfName[index];\n\t\t\tif (curr == '/' || curr == 0) {\n\t\t\t\tneedsCRC = 1;\n\t\t\t\tcurr = ILLEGAL_CHAR_MARK;\n\t\t\t\twhile (index + 1 < udfLen &&\n\t\t\t\t\t\t(udfName[index + 1] == '/' ||\n\t\t\t\t\t\t udfName[index + 1] == 0))\n\t\t\t\t\tindex++;\n\t\t\t}\n\t\t\tif (curr == EXT_MARK &&\n\t\t\t\t\t(udfLen - index - 1) <= EXT_SIZE) {\n\t\t\t\tif (udfLen == index + 1)\n\t\t\t\t\thasExt = 0;\n\t\t\t\telse {\n\t\t\t\t\thasExt = 1;\n\t\t\t\t\textIndex = index;\n\t\t\t\t\tnewExtIndex = newIndex;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (newIndex < 256)\n\t\t\t\tnewName[newIndex++] = curr;\n\t\t\telse\n\t\t\t\tneedsCRC = 1;\n\t\t}\n\t}\n\tif (needsCRC) {\n\t\tuint8_t ext[EXT_SIZE];\n\t\tint localExtIndex = 0;\n\n\t\tif (hasExt) {\n\t\t\tint maxFilenameLen;\n\t\t\tfor (index = 0;\n\t\t\t     index < EXT_SIZE && extIndex + index + 1 < udfLen;\n\t\t\t     index++) {\n\t\t\t\tcurr = udfName[extIndex + index + 1];\n\n\t\t\t\tif (curr == '/' || curr == 0) {\n\t\t\t\t\tneedsCRC = 1;\n\t\t\t\t\tcurr = ILLEGAL_CHAR_MARK;\n\t\t\t\t\twhile (extIndex + index + 2 < udfLen &&\n\t\t\t\t\t      (index + 1 < EXT_SIZE &&\n\t\t\t\t\t\t(udfName[extIndex + index + 2] == '/' ||\n\t\t\t\t\t\t udfName[extIndex + index + 2] == 0)))\n\t\t\t\t\t\tindex++;\n\t\t\t\t}\n\t\t\t\text[localExtIndex++] = curr;\n\t\t\t}\n\t\t\tmaxFilenameLen = 250 - localExtIndex;\n\t\t\tif (newIndex > maxFilenameLen)\n\t\t\t\tnewIndex = maxFilenameLen;\n\t\t\telse\n\t\t\t\tnewIndex = newExtIndex;\n\t\t} else if (newIndex > 250)\n\t\t\tnewIndex = 250;\n\t\tnewName[newIndex++] = CRC_MARK;\n\t\tvalueCRC = crc_itu_t(0, fidName, fidNameLen);\n\t\tnewName[newIndex++] = hex_asc_upper_hi(valueCRC >> 8);\n\t\tnewName[newIndex++] = hex_asc_upper_lo(valueCRC >> 8);\n\t\tnewName[newIndex++] = hex_asc_upper_hi(valueCRC);\n\t\tnewName[newIndex++] = hex_asc_upper_lo(valueCRC);\n\n\t\tif (hasExt) {\n\t\t\tnewName[newIndex++] = EXT_MARK;\n\t\t\tfor (index = 0; index < localExtIndex; index++)\n\t\t\t\tnewName[newIndex++] = ext[index];\n\t\t}\n\t}\n\n\treturn newIndex;\n}",
        "func": "static int udf_translate_to_linux(uint8_t *newName, int newLen,\n\t\t\t\t  uint8_t *udfName, int udfLen,\n\t\t\t\t  uint8_t *fidName, int fidNameLen)\n{\n\tint index, newIndex = 0, needsCRC = 0;\n\tint extIndex = 0, newExtIndex = 0, hasExt = 0;\n\tunsigned short valueCRC;\n\tuint8_t curr;\n\n\tif (udfName[0] == '.' &&\n\t    (udfLen == 1 || (udfLen == 2 && udfName[1] == '.'))) {\n\t\tneedsCRC = 1;\n\t\tnewIndex = udfLen;\n\t\tmemcpy(newName, udfName, udfLen);\n\t} else {\n\t\tfor (index = 0; index < udfLen; index++) {\n\t\t\tcurr = udfName[index];\n\t\t\tif (curr == '/' || curr == 0) {\n\t\t\t\tneedsCRC = 1;\n\t\t\t\tcurr = ILLEGAL_CHAR_MARK;\n\t\t\t\twhile (index + 1 < udfLen &&\n\t\t\t\t\t\t(udfName[index + 1] == '/' ||\n\t\t\t\t\t\t udfName[index + 1] == 0))\n\t\t\t\t\tindex++;\n\t\t\t}\n\t\t\tif (curr == EXT_MARK &&\n\t\t\t\t\t(udfLen - index - 1) <= EXT_SIZE) {\n\t\t\t\tif (udfLen == index + 1)\n\t\t\t\t\thasExt = 0;\n\t\t\t\telse {\n\t\t\t\t\thasExt = 1;\n\t\t\t\t\textIndex = index;\n\t\t\t\t\tnewExtIndex = newIndex;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (newIndex < newLen)\n\t\t\t\tnewName[newIndex++] = curr;\n\t\t\telse\n\t\t\t\tneedsCRC = 1;\n\t\t}\n\t}\n\tif (needsCRC) {\n\t\tuint8_t ext[EXT_SIZE];\n\t\tint localExtIndex = 0;\n\n\t\tif (hasExt) {\n\t\t\tint maxFilenameLen;\n\t\t\tfor (index = 0;\n\t\t\t     index < EXT_SIZE && extIndex + index + 1 < udfLen;\n\t\t\t     index++) {\n\t\t\t\tcurr = udfName[extIndex + index + 1];\n\n\t\t\t\tif (curr == '/' || curr == 0) {\n\t\t\t\t\tneedsCRC = 1;\n\t\t\t\t\tcurr = ILLEGAL_CHAR_MARK;\n\t\t\t\t\twhile (extIndex + index + 2 < udfLen &&\n\t\t\t\t\t      (index + 1 < EXT_SIZE &&\n\t\t\t\t\t\t(udfName[extIndex + index + 2] == '/' ||\n\t\t\t\t\t\t udfName[extIndex + index + 2] == 0)))\n\t\t\t\t\t\tindex++;\n\t\t\t\t}\n\t\t\t\text[localExtIndex++] = curr;\n\t\t\t}\n\t\t\tmaxFilenameLen = newLen - CRC_LEN - localExtIndex;\n\t\t\tif (newIndex > maxFilenameLen)\n\t\t\t\tnewIndex = maxFilenameLen;\n\t\t\telse\n\t\t\t\tnewIndex = newExtIndex;\n\t\t} else if (newIndex > newLen - CRC_LEN)\n\t\t\tnewIndex = newLen - CRC_LEN;\n\t\tnewName[newIndex++] = CRC_MARK;\n\t\tvalueCRC = crc_itu_t(0, fidName, fidNameLen);\n\t\tnewName[newIndex++] = hex_asc_upper_hi(valueCRC >> 8);\n\t\tnewName[newIndex++] = hex_asc_upper_lo(valueCRC >> 8);\n\t\tnewName[newIndex++] = hex_asc_upper_hi(valueCRC);\n\t\tnewName[newIndex++] = hex_asc_upper_lo(valueCRC);\n\n\t\tif (hasExt) {\n\t\t\tnewName[newIndex++] = EXT_MARK;\n\t\t\tfor (index = 0; index < localExtIndex; index++)\n\t\t\t\tnewName[newIndex++] = ext[index];\n\t\t}\n\t}\n\n\treturn newIndex;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,6 +1,6 @@\n-static int udf_translate_to_linux(uint8_t *newName, uint8_t *udfName,\n-\t\t\t\t  int udfLen, uint8_t *fidName,\n-\t\t\t\t  int fidNameLen)\n+static int udf_translate_to_linux(uint8_t *newName, int newLen,\n+\t\t\t\t  uint8_t *udfName, int udfLen,\n+\t\t\t\t  uint8_t *fidName, int fidNameLen)\n {\n \tint index, newIndex = 0, needsCRC = 0;\n \tint extIndex = 0, newExtIndex = 0, hasExt = 0;\n@@ -33,7 +33,7 @@\n \t\t\t\t\tnewExtIndex = newIndex;\n \t\t\t\t}\n \t\t\t}\n-\t\t\tif (newIndex < 256)\n+\t\t\tif (newIndex < newLen)\n \t\t\t\tnewName[newIndex++] = curr;\n \t\t\telse\n \t\t\t\tneedsCRC = 1;\n@@ -61,13 +61,13 @@\n \t\t\t\t}\n \t\t\t\text[localExtIndex++] = curr;\n \t\t\t}\n-\t\t\tmaxFilenameLen = 250 - localExtIndex;\n+\t\t\tmaxFilenameLen = newLen - CRC_LEN - localExtIndex;\n \t\t\tif (newIndex > maxFilenameLen)\n \t\t\t\tnewIndex = maxFilenameLen;\n \t\t\telse\n \t\t\t\tnewIndex = newExtIndex;\n-\t\t} else if (newIndex > 250)\n-\t\t\tnewIndex = 250;\n+\t\t} else if (newIndex > newLen - CRC_LEN)\n+\t\t\tnewIndex = newLen - CRC_LEN;\n \t\tnewName[newIndex++] = CRC_MARK;\n \t\tvalueCRC = crc_itu_t(0, fidName, fidNameLen);\n \t\tnewName[newIndex++] = hex_asc_upper_hi(valueCRC >> 8);",
        "diff_line_info": {
            "deleted_lines": [
                "static int udf_translate_to_linux(uint8_t *newName, uint8_t *udfName,",
                "\t\t\t\t  int udfLen, uint8_t *fidName,",
                "\t\t\t\t  int fidNameLen)",
                "\t\t\tif (newIndex < 256)",
                "\t\t\tmaxFilenameLen = 250 - localExtIndex;",
                "\t\t} else if (newIndex > 250)",
                "\t\t\tnewIndex = 250;"
            ],
            "added_lines": [
                "static int udf_translate_to_linux(uint8_t *newName, int newLen,",
                "\t\t\t\t  uint8_t *udfName, int udfLen,",
                "\t\t\t\t  uint8_t *fidName, int fidNameLen)",
                "\t\t\tif (newIndex < newLen)",
                "\t\t\tmaxFilenameLen = newLen - CRC_LEN - localExtIndex;",
                "\t\t} else if (newIndex > newLen - CRC_LEN)",
                "\t\t\tnewIndex = newLen - CRC_LEN;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9731",
        "func_name": "torvalds/linux/udf_get_filename",
        "description": "The UDF filesystem implementation in the Linux kernel before 3.18.2 does not ensure that space is available for storing a symlink target's name along with a trailing \\0 character, which allows local users to obtain sensitive information via a crafted filesystem image, related to fs/udf/symlink.c and fs/udf/unicode.c.",
        "git_url": "https://github.com/torvalds/linux/commit/0e5cc9a40ada6046e6bc3bdfcd0c0d7e4b706b14",
        "commit_title": "udf: Check path length when reading symlink",
        "commit_text": " Symlink reading code does not check whether the resulting path fits into the page provided by the generic code. This isn't as easy as just checking the symlink size because of various encoding conversions we perform on path. So we have to check whether there is still enough space in the buffer on the fly. ",
        "func_before": "int udf_get_filename(struct super_block *sb, uint8_t *sname, uint8_t *dname,\n\t\t     int flen)\n{\n\tstruct ustr *filename, *unifilename;\n\tint len = 0;\n\n\tfilename = kmalloc(sizeof(struct ustr), GFP_NOFS);\n\tif (!filename)\n\t\treturn 0;\n\n\tunifilename = kmalloc(sizeof(struct ustr), GFP_NOFS);\n\tif (!unifilename)\n\t\tgoto out1;\n\n\tif (udf_build_ustr_exact(unifilename, sname, flen))\n\t\tgoto out2;\n\n\tif (UDF_QUERY_FLAG(sb, UDF_FLAG_UTF8)) {\n\t\tif (!udf_CS0toUTF8(filename, unifilename)) {\n\t\t\tudf_debug(\"Failed in udf_get_filename: sname = %s\\n\",\n\t\t\t\t  sname);\n\t\t\tgoto out2;\n\t\t}\n\t} else if (UDF_QUERY_FLAG(sb, UDF_FLAG_NLS_MAP)) {\n\t\tif (!udf_CS0toNLS(UDF_SB(sb)->s_nls_map, filename,\n\t\t\t\t  unifilename)) {\n\t\t\tudf_debug(\"Failed in udf_get_filename: sname = %s\\n\",\n\t\t\t\t  sname);\n\t\t\tgoto out2;\n\t\t}\n\t} else\n\t\tgoto out2;\n\n\tlen = udf_translate_to_linux(dname, filename->u_name, filename->u_len,\n\t\t\t\t     unifilename->u_name, unifilename->u_len);\nout2:\n\tkfree(unifilename);\nout1:\n\tkfree(filename);\n\treturn len;\n}",
        "func": "int udf_get_filename(struct super_block *sb, uint8_t *sname, int slen,\n\t\t     uint8_t *dname, int dlen)\n{\n\tstruct ustr *filename, *unifilename;\n\tint len = 0;\n\n\tfilename = kmalloc(sizeof(struct ustr), GFP_NOFS);\n\tif (!filename)\n\t\treturn 0;\n\n\tunifilename = kmalloc(sizeof(struct ustr), GFP_NOFS);\n\tif (!unifilename)\n\t\tgoto out1;\n\n\tif (udf_build_ustr_exact(unifilename, sname, slen))\n\t\tgoto out2;\n\n\tif (UDF_QUERY_FLAG(sb, UDF_FLAG_UTF8)) {\n\t\tif (!udf_CS0toUTF8(filename, unifilename)) {\n\t\t\tudf_debug(\"Failed in udf_get_filename: sname = %s\\n\",\n\t\t\t\t  sname);\n\t\t\tgoto out2;\n\t\t}\n\t} else if (UDF_QUERY_FLAG(sb, UDF_FLAG_NLS_MAP)) {\n\t\tif (!udf_CS0toNLS(UDF_SB(sb)->s_nls_map, filename,\n\t\t\t\t  unifilename)) {\n\t\t\tudf_debug(\"Failed in udf_get_filename: sname = %s\\n\",\n\t\t\t\t  sname);\n\t\t\tgoto out2;\n\t\t}\n\t} else\n\t\tgoto out2;\n\n\tlen = udf_translate_to_linux(dname, dlen,\n\t\t\t\t     filename->u_name, filename->u_len,\n\t\t\t\t     unifilename->u_name, unifilename->u_len);\nout2:\n\tkfree(unifilename);\nout1:\n\tkfree(filename);\n\treturn len;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,5 +1,5 @@\n-int udf_get_filename(struct super_block *sb, uint8_t *sname, uint8_t *dname,\n-\t\t     int flen)\n+int udf_get_filename(struct super_block *sb, uint8_t *sname, int slen,\n+\t\t     uint8_t *dname, int dlen)\n {\n \tstruct ustr *filename, *unifilename;\n \tint len = 0;\n@@ -12,7 +12,7 @@\n \tif (!unifilename)\n \t\tgoto out1;\n \n-\tif (udf_build_ustr_exact(unifilename, sname, flen))\n+\tif (udf_build_ustr_exact(unifilename, sname, slen))\n \t\tgoto out2;\n \n \tif (UDF_QUERY_FLAG(sb, UDF_FLAG_UTF8)) {\n@@ -31,7 +31,8 @@\n \t} else\n \t\tgoto out2;\n \n-\tlen = udf_translate_to_linux(dname, filename->u_name, filename->u_len,\n+\tlen = udf_translate_to_linux(dname, dlen,\n+\t\t\t\t     filename->u_name, filename->u_len,\n \t\t\t\t     unifilename->u_name, unifilename->u_len);\n out2:\n \tkfree(unifilename);",
        "diff_line_info": {
            "deleted_lines": [
                "int udf_get_filename(struct super_block *sb, uint8_t *sname, uint8_t *dname,",
                "\t\t     int flen)",
                "\tif (udf_build_ustr_exact(unifilename, sname, flen))",
                "\tlen = udf_translate_to_linux(dname, filename->u_name, filename->u_len,"
            ],
            "added_lines": [
                "int udf_get_filename(struct super_block *sb, uint8_t *sname, int slen,",
                "\t\t     uint8_t *dname, int dlen)",
                "\tif (udf_build_ustr_exact(unifilename, sname, slen))",
                "\tlen = udf_translate_to_linux(dname, dlen,",
                "\t\t\t\t     filename->u_name, filename->u_len,"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9731",
        "func_name": "torvalds/linux/udf_readdir",
        "description": "The UDF filesystem implementation in the Linux kernel before 3.18.2 does not ensure that space is available for storing a symlink target's name along with a trailing \\0 character, which allows local users to obtain sensitive information via a crafted filesystem image, related to fs/udf/symlink.c and fs/udf/unicode.c.",
        "git_url": "https://github.com/torvalds/linux/commit/0e5cc9a40ada6046e6bc3bdfcd0c0d7e4b706b14",
        "commit_title": "udf: Check path length when reading symlink",
        "commit_text": " Symlink reading code does not check whether the resulting path fits into the page provided by the generic code. This isn't as easy as just checking the symlink size because of various encoding conversions we perform on path. So we have to check whether there is still enough space in the buffer on the fly. ",
        "func_before": "static int udf_readdir(struct file *file, struct dir_context *ctx)\n{\n\tstruct inode *dir = file_inode(file);\n\tstruct udf_inode_info *iinfo = UDF_I(dir);\n\tstruct udf_fileident_bh fibh = { .sbh = NULL, .ebh = NULL};\n\tstruct fileIdentDesc *fi = NULL;\n\tstruct fileIdentDesc cfi;\n\tint block, iblock;\n\tloff_t nf_pos;\n\tint flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint16_t liu;\n\tuint8_t lfi;\n\tloff_t size = udf_ext0_offset(dir) + dir->i_size;\n\tstruct buffer_head *tmp, *bha[16];\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tint i, num, ret = 0;\n\tstruct extent_position epos = { NULL, 0, {0, 0} };\n\n\tif (ctx->pos == 0) {\n\t\tif (!dir_emit_dot(file, ctx))\n\t\t\treturn 0;\n\t\tctx->pos = 1;\n\t}\n\tnf_pos = (ctx->pos - 1) << 2;\n\tif (nf_pos >= size)\n\t\tgoto out;\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (nf_pos == 0)\n\t\tnf_pos = udf_ext0_offset(dir);\n\n\tfibh.soffset = fibh.eoffset = nf_pos & (dir->i_sb->s_blocksize - 1);\n\tif (iinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, nf_pos >> dir->i_sb->s_blocksize_bits,\n\t\t    &epos, &eloc, &elen, &offset)\n\t\t    != (EXT_RECORDED_ALLOCATED >> 30)) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (iinfo->i_alloc_type ==\n\t\t\t\t\tICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else {\n\t\t\toffset = 0;\n\t\t}\n\n\t\tif (!(fibh.sbh = fibh.ebh = udf_tread(dir->i_sb, block))) {\n\t\t\tret = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!(offset & ((16 >> (dir->i_sb->s_blocksize_bits - 9)) - 1))) {\n\t\t\ti = 16 >> (dir->i_sb->s_blocksize_bits - 9);\n\t\t\tif (i + offset > (elen >> dir->i_sb->s_blocksize_bits))\n\t\t\t\ti = (elen >> dir->i_sb->s_blocksize_bits) - offset;\n\t\t\tfor (num = 0; i > 0; i--) {\n\t\t\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset + i);\n\t\t\t\ttmp = udf_tgetblk(dir->i_sb, block);\n\t\t\t\tif (tmp && !buffer_uptodate(tmp) && !buffer_locked(tmp))\n\t\t\t\t\tbha[num++] = tmp;\n\t\t\t\telse\n\t\t\t\t\tbrelse(tmp);\n\t\t\t}\n\t\t\tif (num) {\n\t\t\t\tll_rw_block(READA, num, bha);\n\t\t\t\tfor (i = 0; i < num; i++)\n\t\t\t\t\tbrelse(bha[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\twhile (nf_pos < size) {\n\t\tstruct kernel_lb_addr tloc;\n\n\t\tctx->pos = (nf_pos >> 2) + 1;\n\n\t\tfi = udf_fileident_read(dir, &nf_pos, &fibh, &cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out;\n\n\t\tliu = le16_to_cpu(cfi.lengthOfImpUse);\n\t\tlfi = cfi.lengthFileIdent;\n\n\t\tif (fibh.sbh == fibh.ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh.soffset + sizeof(struct fileIdentDesc) + liu + lfi;\n\n\t\t\tif (poffset >= lfi) {\n\t\t\t\tnameptr = (char *)(fibh.ebh->b_data + poffset - lfi);\n\t\t\t} else {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t       lfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t       fibh.ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi.fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi.fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (cfi.fileCharacteristics & FID_FILE_CHAR_PARENT) {\n\t\t\tif (!dir_emit_dotdot(file, ctx))\n\t\t\t\tgoto out;\n\t\t\tcontinue;\n\t\t}\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);\n\t\tif (!flen)\n\t\t\tcontinue;\n\n\t\ttloc = lelb_to_cpu(cfi.icb.extLocation);\n\t\tiblock = udf_get_lb_pblock(dir->i_sb, &tloc, 0);\n\t\tif (!dir_emit(ctx, fname, flen, iblock, DT_UNKNOWN))\n\t\t\tgoto out;\n\t} /* end while */\n\n\tctx->pos = (nf_pos >> 2) + 1;\n\nout:\n\tif (fibh.sbh != fibh.ebh)\n\t\tbrelse(fibh.ebh);\n\tbrelse(fibh.sbh);\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn ret;\n}",
        "func": "static int udf_readdir(struct file *file, struct dir_context *ctx)\n{\n\tstruct inode *dir = file_inode(file);\n\tstruct udf_inode_info *iinfo = UDF_I(dir);\n\tstruct udf_fileident_bh fibh = { .sbh = NULL, .ebh = NULL};\n\tstruct fileIdentDesc *fi = NULL;\n\tstruct fileIdentDesc cfi;\n\tint block, iblock;\n\tloff_t nf_pos;\n\tint flen;\n\tunsigned char *fname = NULL;\n\tunsigned char *nameptr;\n\tuint16_t liu;\n\tuint8_t lfi;\n\tloff_t size = udf_ext0_offset(dir) + dir->i_size;\n\tstruct buffer_head *tmp, *bha[16];\n\tstruct kernel_lb_addr eloc;\n\tuint32_t elen;\n\tsector_t offset;\n\tint i, num, ret = 0;\n\tstruct extent_position epos = { NULL, 0, {0, 0} };\n\n\tif (ctx->pos == 0) {\n\t\tif (!dir_emit_dot(file, ctx))\n\t\t\treturn 0;\n\t\tctx->pos = 1;\n\t}\n\tnf_pos = (ctx->pos - 1) << 2;\n\tif (nf_pos >= size)\n\t\tgoto out;\n\n\tfname = kmalloc(UDF_NAME_LEN, GFP_NOFS);\n\tif (!fname) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tif (nf_pos == 0)\n\t\tnf_pos = udf_ext0_offset(dir);\n\n\tfibh.soffset = fibh.eoffset = nf_pos & (dir->i_sb->s_blocksize - 1);\n\tif (iinfo->i_alloc_type != ICBTAG_FLAG_AD_IN_ICB) {\n\t\tif (inode_bmap(dir, nf_pos >> dir->i_sb->s_blocksize_bits,\n\t\t    &epos, &eloc, &elen, &offset)\n\t\t    != (EXT_RECORDED_ALLOCATED >> 30)) {\n\t\t\tret = -ENOENT;\n\t\t\tgoto out;\n\t\t}\n\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset);\n\t\tif ((++offset << dir->i_sb->s_blocksize_bits) < elen) {\n\t\t\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_SHORT)\n\t\t\t\tepos.offset -= sizeof(struct short_ad);\n\t\t\telse if (iinfo->i_alloc_type ==\n\t\t\t\t\tICBTAG_FLAG_AD_LONG)\n\t\t\t\tepos.offset -= sizeof(struct long_ad);\n\t\t} else {\n\t\t\toffset = 0;\n\t\t}\n\n\t\tif (!(fibh.sbh = fibh.ebh = udf_tread(dir->i_sb, block))) {\n\t\t\tret = -EIO;\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!(offset & ((16 >> (dir->i_sb->s_blocksize_bits - 9)) - 1))) {\n\t\t\ti = 16 >> (dir->i_sb->s_blocksize_bits - 9);\n\t\t\tif (i + offset > (elen >> dir->i_sb->s_blocksize_bits))\n\t\t\t\ti = (elen >> dir->i_sb->s_blocksize_bits) - offset;\n\t\t\tfor (num = 0; i > 0; i--) {\n\t\t\t\tblock = udf_get_lb_pblock(dir->i_sb, &eloc, offset + i);\n\t\t\t\ttmp = udf_tgetblk(dir->i_sb, block);\n\t\t\t\tif (tmp && !buffer_uptodate(tmp) && !buffer_locked(tmp))\n\t\t\t\t\tbha[num++] = tmp;\n\t\t\t\telse\n\t\t\t\t\tbrelse(tmp);\n\t\t\t}\n\t\t\tif (num) {\n\t\t\t\tll_rw_block(READA, num, bha);\n\t\t\t\tfor (i = 0; i < num; i++)\n\t\t\t\t\tbrelse(bha[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\twhile (nf_pos < size) {\n\t\tstruct kernel_lb_addr tloc;\n\n\t\tctx->pos = (nf_pos >> 2) + 1;\n\n\t\tfi = udf_fileident_read(dir, &nf_pos, &fibh, &cfi, &epos, &eloc,\n\t\t\t\t\t&elen, &offset);\n\t\tif (!fi)\n\t\t\tgoto out;\n\n\t\tliu = le16_to_cpu(cfi.lengthOfImpUse);\n\t\tlfi = cfi.lengthFileIdent;\n\n\t\tif (fibh.sbh == fibh.ebh) {\n\t\t\tnameptr = fi->fileIdent + liu;\n\t\t} else {\n\t\t\tint poffset;\t/* Unpaded ending offset */\n\n\t\t\tpoffset = fibh.soffset + sizeof(struct fileIdentDesc) + liu + lfi;\n\n\t\t\tif (poffset >= lfi) {\n\t\t\t\tnameptr = (char *)(fibh.ebh->b_data + poffset - lfi);\n\t\t\t} else {\n\t\t\t\tnameptr = fname;\n\t\t\t\tmemcpy(nameptr, fi->fileIdent + liu,\n\t\t\t\t       lfi - poffset);\n\t\t\t\tmemcpy(nameptr + lfi - poffset,\n\t\t\t\t       fibh.ebh->b_data, poffset);\n\t\t\t}\n\t\t}\n\n\t\tif ((cfi.fileCharacteristics & FID_FILE_CHAR_DELETED) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNDELETE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif ((cfi.fileCharacteristics & FID_FILE_CHAR_HIDDEN) != 0) {\n\t\t\tif (!UDF_QUERY_FLAG(dir->i_sb, UDF_FLAG_UNHIDE))\n\t\t\t\tcontinue;\n\t\t}\n\n\t\tif (cfi.fileCharacteristics & FID_FILE_CHAR_PARENT) {\n\t\t\tif (!dir_emit_dotdot(file, ctx))\n\t\t\t\tgoto out;\n\t\t\tcontinue;\n\t\t}\n\n\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,\n\t\t\t\t\tUDF_NAME_LEN);\n\t\tif (!flen)\n\t\t\tcontinue;\n\n\t\ttloc = lelb_to_cpu(cfi.icb.extLocation);\n\t\tiblock = udf_get_lb_pblock(dir->i_sb, &tloc, 0);\n\t\tif (!dir_emit(ctx, fname, flen, iblock, DT_UNKNOWN))\n\t\t\tgoto out;\n\t} /* end while */\n\n\tctx->pos = (nf_pos >> 2) + 1;\n\nout:\n\tif (fibh.sbh != fibh.ebh)\n\t\tbrelse(fibh.ebh);\n\tbrelse(fibh.sbh);\n\tbrelse(epos.bh);\n\tkfree(fname);\n\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -129,7 +129,8 @@\n \t\t\tcontinue;\n \t\t}\n \n-\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);\n+\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,\n+\t\t\t\t\tUDF_NAME_LEN);\n \t\tif (!flen)\n \t\t\tcontinue;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "\t\tflen = udf_get_filename(dir->i_sb, nameptr, fname, lfi);"
            ],
            "added_lines": [
                "\t\tflen = udf_get_filename(dir->i_sb, nameptr, lfi, fname,",
                "\t\t\t\t\tUDF_NAME_LEN);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9731",
        "func_name": "torvalds/linux/udf_symlink_filler",
        "description": "The UDF filesystem implementation in the Linux kernel before 3.18.2 does not ensure that space is available for storing a symlink target's name along with a trailing \\0 character, which allows local users to obtain sensitive information via a crafted filesystem image, related to fs/udf/symlink.c and fs/udf/unicode.c.",
        "git_url": "https://github.com/torvalds/linux/commit/0e5cc9a40ada6046e6bc3bdfcd0c0d7e4b706b14",
        "commit_title": "udf: Check path length when reading symlink",
        "commit_text": " Symlink reading code does not check whether the resulting path fits into the page provided by the generic code. This isn't as easy as just checking the symlink size because of various encoding conversions we perform on path. So we have to check whether there is still enough space in the buffer on the fly. ",
        "func_before": "static int udf_symlink_filler(struct file *file, struct page *page)\n{\n\tstruct inode *inode = page->mapping->host;\n\tstruct buffer_head *bh = NULL;\n\tunsigned char *symlink;\n\tint err;\n\tunsigned char *p = kmap(page);\n\tstruct udf_inode_info *iinfo;\n\tuint32_t pos;\n\n\t/* We don't support symlinks longer than one block */\n\tif (inode->i_size > inode->i_sb->s_blocksize) {\n\t\terr = -ENAMETOOLONG;\n\t\tgoto out_unmap;\n\t}\n\n\tiinfo = UDF_I(inode);\n\tpos = udf_block_map(inode, 0);\n\n\tdown_read(&iinfo->i_data_sem);\n\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {\n\t\tsymlink = iinfo->i_ext.i_data + iinfo->i_lenEAttr;\n\t} else {\n\t\tbh = sb_bread(inode->i_sb, pos);\n\n\t\tif (!bh) {\n\t\t\terr = -EIO;\n\t\t\tgoto out_unlock_inode;\n\t\t}\n\n\t\tsymlink = bh->b_data;\n\t}\n\n\tudf_pc_to_char(inode->i_sb, symlink, inode->i_size, p);\n\tbrelse(bh);\n\n\tup_read(&iinfo->i_data_sem);\n\tSetPageUptodate(page);\n\tkunmap(page);\n\tunlock_page(page);\n\treturn 0;\n\nout_unlock_inode:\n\tup_read(&iinfo->i_data_sem);\n\tSetPageError(page);\nout_unmap:\n\tkunmap(page);\n\tunlock_page(page);\n\treturn err;\n}",
        "func": "static int udf_symlink_filler(struct file *file, struct page *page)\n{\n\tstruct inode *inode = page->mapping->host;\n\tstruct buffer_head *bh = NULL;\n\tunsigned char *symlink;\n\tint err;\n\tunsigned char *p = kmap(page);\n\tstruct udf_inode_info *iinfo;\n\tuint32_t pos;\n\n\t/* We don't support symlinks longer than one block */\n\tif (inode->i_size > inode->i_sb->s_blocksize) {\n\t\terr = -ENAMETOOLONG;\n\t\tgoto out_unmap;\n\t}\n\n\tiinfo = UDF_I(inode);\n\tpos = udf_block_map(inode, 0);\n\n\tdown_read(&iinfo->i_data_sem);\n\tif (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {\n\t\tsymlink = iinfo->i_ext.i_data + iinfo->i_lenEAttr;\n\t} else {\n\t\tbh = sb_bread(inode->i_sb, pos);\n\n\t\tif (!bh) {\n\t\t\terr = -EIO;\n\t\t\tgoto out_unlock_inode;\n\t\t}\n\n\t\tsymlink = bh->b_data;\n\t}\n\n\terr = udf_pc_to_char(inode->i_sb, symlink, inode->i_size, p, PAGE_SIZE);\n\tbrelse(bh);\n\tif (err)\n\t\tgoto out_unlock_inode;\n\n\tup_read(&iinfo->i_data_sem);\n\tSetPageUptodate(page);\n\tkunmap(page);\n\tunlock_page(page);\n\treturn 0;\n\nout_unlock_inode:\n\tup_read(&iinfo->i_data_sem);\n\tSetPageError(page);\nout_unmap:\n\tkunmap(page);\n\tunlock_page(page);\n\treturn err;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -31,8 +31,10 @@\n \t\tsymlink = bh->b_data;\n \t}\n \n-\tudf_pc_to_char(inode->i_sb, symlink, inode->i_size, p);\n+\terr = udf_pc_to_char(inode->i_sb, symlink, inode->i_size, p, PAGE_SIZE);\n \tbrelse(bh);\n+\tif (err)\n+\t\tgoto out_unlock_inode;\n \n \tup_read(&iinfo->i_data_sem);\n \tSetPageUptodate(page);",
        "diff_line_info": {
            "deleted_lines": [
                "\tudf_pc_to_char(inode->i_sb, symlink, inode->i_size, p);"
            ],
            "added_lines": [
                "\terr = udf_pc_to_char(inode->i_sb, symlink, inode->i_size, p, PAGE_SIZE);",
                "\tif (err)",
                "\t\tgoto out_unlock_inode;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9731",
        "func_name": "torvalds/linux/udf_pc_to_char",
        "description": "The UDF filesystem implementation in the Linux kernel before 3.18.2 does not ensure that space is available for storing a symlink target's name along with a trailing \\0 character, which allows local users to obtain sensitive information via a crafted filesystem image, related to fs/udf/symlink.c and fs/udf/unicode.c.",
        "git_url": "https://github.com/torvalds/linux/commit/0e5cc9a40ada6046e6bc3bdfcd0c0d7e4b706b14",
        "commit_title": "udf: Check path length when reading symlink",
        "commit_text": " Symlink reading code does not check whether the resulting path fits into the page provided by the generic code. This isn't as easy as just checking the symlink size because of various encoding conversions we perform on path. So we have to check whether there is still enough space in the buffer on the fly. ",
        "func_before": "static void udf_pc_to_char(struct super_block *sb, unsigned char *from,\n\t\t\t   int fromlen, unsigned char *to)\n{\n\tstruct pathComponent *pc;\n\tint elen = 0;\n\tunsigned char *p = to;\n\n\twhile (elen < fromlen) {\n\t\tpc = (struct pathComponent *)(from + elen);\n\t\tswitch (pc->componentType) {\n\t\tcase 1:\n\t\t\t/*\n\t\t\t * Symlink points to some place which should be agreed\n \t\t\t * upon between originator and receiver of the media. Ignore.\n\t\t\t */\n\t\t\tif (pc->lengthComponentIdent > 0)\n\t\t\t\tbreak;\n\t\t\t/* Fall through */\n\t\tcase 2:\n\t\t\tp = to;\n\t\t\t*p++ = '/';\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tmemcpy(p, \"../\", 3);\n\t\t\tp += 3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tmemcpy(p, \"./\", 2);\n\t\t\tp += 2;\n\t\t\t/* that would be . - just ignore */\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tp += udf_get_filename(sb, pc->componentIdent, p,\n\t\t\t\t\t      pc->lengthComponentIdent);\n\t\t\t*p++ = '/';\n\t\t\tbreak;\n\t\t}\n\t\telen += sizeof(struct pathComponent) + pc->lengthComponentIdent;\n\t}\n\tif (p > to + 1)\n\t\tp[-1] = '\\0';\n\telse\n\t\tp[0] = '\\0';\n}",
        "func": "static int udf_pc_to_char(struct super_block *sb, unsigned char *from,\n\t\t\t  int fromlen, unsigned char *to, int tolen)\n{\n\tstruct pathComponent *pc;\n\tint elen = 0;\n\tint comp_len;\n\tunsigned char *p = to;\n\n\t/* Reserve one byte for terminating \\0 */\n\ttolen--;\n\twhile (elen < fromlen) {\n\t\tpc = (struct pathComponent *)(from + elen);\n\t\tswitch (pc->componentType) {\n\t\tcase 1:\n\t\t\t/*\n\t\t\t * Symlink points to some place which should be agreed\n \t\t\t * upon between originator and receiver of the media. Ignore.\n\t\t\t */\n\t\t\tif (pc->lengthComponentIdent > 0)\n\t\t\t\tbreak;\n\t\t\t/* Fall through */\n\t\tcase 2:\n\t\t\tif (tolen == 0)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t\tp = to;\n\t\t\t*p++ = '/';\n\t\t\ttolen--;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tif (tolen < 3)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t\tmemcpy(p, \"../\", 3);\n\t\t\tp += 3;\n\t\t\ttolen -= 3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tif (tolen < 2)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t\tmemcpy(p, \"./\", 2);\n\t\t\tp += 2;\n\t\t\ttolen -= 2;\n\t\t\t/* that would be . - just ignore */\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tcomp_len = udf_get_filename(sb, pc->componentIdent,\n\t\t\t\t\t\t    pc->lengthComponentIdent,\n\t\t\t\t\t\t    p, tolen);\n\t\t\tp += comp_len;\n\t\t\ttolen -= comp_len;\n\t\t\tif (tolen == 0)\n\t\t\t\treturn -ENAMETOOLONG;\n\t\t\t*p++ = '/';\n\t\t\ttolen--;\n\t\t\tbreak;\n\t\t}\n\t\telen += sizeof(struct pathComponent) + pc->lengthComponentIdent;\n\t}\n\tif (p > to + 1)\n\t\tp[-1] = '\\0';\n\telse\n\t\tp[0] = '\\0';\n\treturn 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,10 +1,13 @@\n-static void udf_pc_to_char(struct super_block *sb, unsigned char *from,\n-\t\t\t   int fromlen, unsigned char *to)\n+static int udf_pc_to_char(struct super_block *sb, unsigned char *from,\n+\t\t\t  int fromlen, unsigned char *to, int tolen)\n {\n \tstruct pathComponent *pc;\n \tint elen = 0;\n+\tint comp_len;\n \tunsigned char *p = to;\n \n+\t/* Reserve one byte for terminating \\0 */\n+\ttolen--;\n \twhile (elen < fromlen) {\n \t\tpc = (struct pathComponent *)(from + elen);\n \t\tswitch (pc->componentType) {\n@@ -17,22 +20,37 @@\n \t\t\t\tbreak;\n \t\t\t/* Fall through */\n \t\tcase 2:\n+\t\t\tif (tolen == 0)\n+\t\t\t\treturn -ENAMETOOLONG;\n \t\t\tp = to;\n \t\t\t*p++ = '/';\n+\t\t\ttolen--;\n \t\t\tbreak;\n \t\tcase 3:\n+\t\t\tif (tolen < 3)\n+\t\t\t\treturn -ENAMETOOLONG;\n \t\t\tmemcpy(p, \"../\", 3);\n \t\t\tp += 3;\n+\t\t\ttolen -= 3;\n \t\t\tbreak;\n \t\tcase 4:\n+\t\t\tif (tolen < 2)\n+\t\t\t\treturn -ENAMETOOLONG;\n \t\t\tmemcpy(p, \"./\", 2);\n \t\t\tp += 2;\n+\t\t\ttolen -= 2;\n \t\t\t/* that would be . - just ignore */\n \t\t\tbreak;\n \t\tcase 5:\n-\t\t\tp += udf_get_filename(sb, pc->componentIdent, p,\n-\t\t\t\t\t      pc->lengthComponentIdent);\n+\t\t\tcomp_len = udf_get_filename(sb, pc->componentIdent,\n+\t\t\t\t\t\t    pc->lengthComponentIdent,\n+\t\t\t\t\t\t    p, tolen);\n+\t\t\tp += comp_len;\n+\t\t\ttolen -= comp_len;\n+\t\t\tif (tolen == 0)\n+\t\t\t\treturn -ENAMETOOLONG;\n \t\t\t*p++ = '/';\n+\t\t\ttolen--;\n \t\t\tbreak;\n \t\t}\n \t\telen += sizeof(struct pathComponent) + pc->lengthComponentIdent;\n@@ -41,4 +59,5 @@\n \t\tp[-1] = '\\0';\n \telse\n \t\tp[0] = '\\0';\n+\treturn 0;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "static void udf_pc_to_char(struct super_block *sb, unsigned char *from,",
                "\t\t\t   int fromlen, unsigned char *to)",
                "\t\t\tp += udf_get_filename(sb, pc->componentIdent, p,",
                "\t\t\t\t\t      pc->lengthComponentIdent);"
            ],
            "added_lines": [
                "static int udf_pc_to_char(struct super_block *sb, unsigned char *from,",
                "\t\t\t  int fromlen, unsigned char *to, int tolen)",
                "\tint comp_len;",
                "\t/* Reserve one byte for terminating \\0 */",
                "\ttolen--;",
                "\t\t\tif (tolen == 0)",
                "\t\t\t\treturn -ENAMETOOLONG;",
                "\t\t\ttolen--;",
                "\t\t\tif (tolen < 3)",
                "\t\t\t\treturn -ENAMETOOLONG;",
                "\t\t\ttolen -= 3;",
                "\t\t\tif (tolen < 2)",
                "\t\t\t\treturn -ENAMETOOLONG;",
                "\t\t\ttolen -= 2;",
                "\t\t\tcomp_len = udf_get_filename(sb, pc->componentIdent,",
                "\t\t\t\t\t\t    pc->lengthComponentIdent,",
                "\t\t\t\t\t\t    p, tolen);",
                "\t\t\tp += comp_len;",
                "\t\t\ttolen -= comp_len;",
                "\t\t\tif (tolen == 0)",
                "\t\t\t\treturn -ENAMETOOLONG;",
                "\t\t\ttolen--;",
                "\treturn 0;"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-4700",
        "func_name": "torvalds/linux/bpf_int_jit_compile",
        "description": "The bpf_int_jit_compile function in arch/x86/net/bpf_jit_comp.c in the Linux kernel before 4.0.6 allows local users to cause a denial of service (system crash) by creating a packet filter and then loading crafted BPF instructions that trigger late convergence by the JIT compiler.",
        "git_url": "https://github.com/torvalds/linux/commit/3f7352bf21f8fd7ba3e2fcef9488756f188e12be",
        "commit_title": "x86: bpf_jit: fix compilation of large bpf programs",
        "commit_text": " x86 has variable length encoding. x86 JIT compiler is trying to pick the shortest encoding for given bpf instruction. While doing so the jump targets are changing, so JIT is doing multiple passes over the program. Typical program needs 3 passes. Some very short programs converge with 2 passes. Large programs may need 4 or 5. But specially crafted bpf programs may hit the pass limit and if the program converges on the last iteration the JIT compiler will be producing an image full of 'int 3' insns. Fix this corner case by doing final iteration over bpf program. ",
        "func_before": "void bpf_int_jit_compile(struct bpf_prog *prog)\n{\n\tstruct bpf_binary_header *header = NULL;\n\tint proglen, oldproglen = 0;\n\tstruct jit_context ctx = {};\n\tu8 *image = NULL;\n\tint *addrs;\n\tint pass;\n\tint i;\n\n\tif (!bpf_jit_enable)\n\t\treturn;\n\n\tif (!prog || !prog->len)\n\t\treturn;\n\n\taddrs = kmalloc(prog->len * sizeof(*addrs), GFP_KERNEL);\n\tif (!addrs)\n\t\treturn;\n\n\t/* Before first pass, make a rough estimation of addrs[]\n\t * each bpf instruction is translated to less than 64 bytes\n\t */\n\tfor (proglen = 0, i = 0; i < prog->len; i++) {\n\t\tproglen += 64;\n\t\taddrs[i] = proglen;\n\t}\n\tctx.cleanup_addr = proglen;\n\n\tfor (pass = 0; pass < 10; pass++) {\n\t\tproglen = do_jit(prog, addrs, image, oldproglen, &ctx);\n\t\tif (proglen <= 0) {\n\t\t\timage = NULL;\n\t\t\tif (header)\n\t\t\t\tbpf_jit_binary_free(header);\n\t\t\tgoto out;\n\t\t}\n\t\tif (image) {\n\t\t\tif (proglen != oldproglen) {\n\t\t\t\tpr_err(\"bpf_jit: proglen=%d != oldproglen=%d\\n\",\n\t\t\t\t       proglen, oldproglen);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (proglen == oldproglen) {\n\t\t\theader = bpf_jit_binary_alloc(proglen, &image,\n\t\t\t\t\t\t      1, jit_fill_hole);\n\t\t\tif (!header)\n\t\t\t\tgoto out;\n\t\t}\n\t\toldproglen = proglen;\n\t}\n\n\tif (bpf_jit_enable > 1)\n\t\tbpf_jit_dump(prog->len, proglen, 0, image);\n\n\tif (image) {\n\t\tbpf_flush_icache(header, image + proglen);\n\t\tset_memory_ro((unsigned long)header, header->pages);\n\t\tprog->bpf_func = (void *)image;\n\t\tprog->jited = true;\n\t}\nout:\n\tkfree(addrs);\n}",
        "func": "void bpf_int_jit_compile(struct bpf_prog *prog)\n{\n\tstruct bpf_binary_header *header = NULL;\n\tint proglen, oldproglen = 0;\n\tstruct jit_context ctx = {};\n\tu8 *image = NULL;\n\tint *addrs;\n\tint pass;\n\tint i;\n\n\tif (!bpf_jit_enable)\n\t\treturn;\n\n\tif (!prog || !prog->len)\n\t\treturn;\n\n\taddrs = kmalloc(prog->len * sizeof(*addrs), GFP_KERNEL);\n\tif (!addrs)\n\t\treturn;\n\n\t/* Before first pass, make a rough estimation of addrs[]\n\t * each bpf instruction is translated to less than 64 bytes\n\t */\n\tfor (proglen = 0, i = 0; i < prog->len; i++) {\n\t\tproglen += 64;\n\t\taddrs[i] = proglen;\n\t}\n\tctx.cleanup_addr = proglen;\n\n\t/* JITed image shrinks with every pass and the loop iterates\n\t * until the image stops shrinking. Very large bpf programs\n\t * may converge on the last pass. In such case do one more\n\t * pass to emit the final image\n\t */\n\tfor (pass = 0; pass < 10 || image; pass++) {\n\t\tproglen = do_jit(prog, addrs, image, oldproglen, &ctx);\n\t\tif (proglen <= 0) {\n\t\t\timage = NULL;\n\t\t\tif (header)\n\t\t\t\tbpf_jit_binary_free(header);\n\t\t\tgoto out;\n\t\t}\n\t\tif (image) {\n\t\t\tif (proglen != oldproglen) {\n\t\t\t\tpr_err(\"bpf_jit: proglen=%d != oldproglen=%d\\n\",\n\t\t\t\t       proglen, oldproglen);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tif (proglen == oldproglen) {\n\t\t\theader = bpf_jit_binary_alloc(proglen, &image,\n\t\t\t\t\t\t      1, jit_fill_hole);\n\t\t\tif (!header)\n\t\t\t\tgoto out;\n\t\t}\n\t\toldproglen = proglen;\n\t}\n\n\tif (bpf_jit_enable > 1)\n\t\tbpf_jit_dump(prog->len, proglen, 0, image);\n\n\tif (image) {\n\t\tbpf_flush_icache(header, image + proglen);\n\t\tset_memory_ro((unsigned long)header, header->pages);\n\t\tprog->bpf_func = (void *)image;\n\t\tprog->jited = true;\n\t}\nout:\n\tkfree(addrs);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -27,7 +27,12 @@\n \t}\n \tctx.cleanup_addr = proglen;\n \n-\tfor (pass = 0; pass < 10; pass++) {\n+\t/* JITed image shrinks with every pass and the loop iterates\n+\t * until the image stops shrinking. Very large bpf programs\n+\t * may converge on the last pass. In such case do one more\n+\t * pass to emit the final image\n+\t */\n+\tfor (pass = 0; pass < 10 || image; pass++) {\n \t\tproglen = do_jit(prog, addrs, image, oldproglen, &ctx);\n \t\tif (proglen <= 0) {\n \t\t\timage = NULL;",
        "diff_line_info": {
            "deleted_lines": [
                "\tfor (pass = 0; pass < 10; pass++) {"
            ],
            "added_lines": [
                "\t/* JITed image shrinks with every pass and the loop iterates",
                "\t * until the image stops shrinking. Very large bpf programs",
                "\t * may converge on the last pass. In such case do one more",
                "\t * pass to emit the final image",
                "\t */",
                "\tfor (pass = 0; pass < 10 || image; pass++) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-8216",
        "func_name": "ffmpeg/ljpeg_decode_yuv_scan",
        "description": "The ljpeg_decode_yuv_scan function in libavcodec/mjpegdec.c in FFmpeg before 2.8.2 omits certain width and height checks, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via crafted MJPEG data.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=d24888ef19ba38b787b11d1ee091a3d94920c76a",
        "commit_title": "",
        "commit_text": "avcodec/mjpegdec: Check index in ljpeg_decode_yuv_scan() before using it  Fixes out of array access  ",
        "func_before": "static int ljpeg_decode_yuv_scan(MJpegDecodeContext *s, int predictor,\n                                 int point_transform, int nb_components)\n{\n    int i, mb_x, mb_y, mask;\n    int bits= (s->bits+7)&~7;\n    int resync_mb_y = 0;\n    int resync_mb_x = 0;\n\n    point_transform += bits - s->bits;\n    mask = ((1 << s->bits) - 1) << point_transform;\n\n    av_assert0(nb_components>=1 && nb_components<=4);\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n            if (s->restart_interval && !s->restart_count){\n                s->restart_count = s->restart_interval;\n                resync_mb_x = mb_x;\n                resync_mb_y = mb_y;\n            }\n\n            if(!mb_x || mb_y == resync_mb_y || mb_y == resync_mb_y+1 && mb_x < resync_mb_x || s->interlaced){\n                int toprow  = mb_y == resync_mb_y || mb_y == resync_mb_y+1 && mb_x < resync_mb_x;\n                int leftcol = !mb_x || mb_y == resync_mb_y && mb_x == resync_mb_x;\n                for (i = 0; i < nb_components; i++) {\n                    uint8_t *ptr;\n                    uint16_t *ptr16;\n                    int n, h, v, x, y, c, j, linesize;\n                    n = s->nb_blocks[i];\n                    c = s->comp_index[i];\n                    h = s->h_scount[i];\n                    v = s->v_scount[i];\n                    x = 0;\n                    y = 0;\n                    linesize= s->linesize[c];\n\n                    if(bits>8) linesize /= 2;\n\n                    for(j=0; j<n; j++) {\n                        int pred, dc;\n\n                        dc = mjpeg_decode_dc(s, s->dc_index[i]);\n                        if(dc == 0xFFFFF)\n                            return -1;\n                        if(bits<=8){\n                        ptr = s->picture_ptr->data[c] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n                        if(y==0 && toprow){\n                            if(x==0 && leftcol){\n                                pred= 1 << (bits - 1);\n                            }else{\n                                pred= ptr[-1];\n                            }\n                        }else{\n                            if(x==0 && leftcol){\n                                pred= ptr[-linesize];\n                            }else{\n                                PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n                            }\n                        }\n\n                        if (s->interlaced && s->bottom_field)\n                            ptr += linesize >> 1;\n                        pred &= mask;\n                        *ptr= pred + (dc << point_transform);\n                        }else{\n                            ptr16 = (uint16_t*)(s->picture_ptr->data[c] + 2*(linesize * (v * mb_y + y)) + 2*(h * mb_x + x)); //FIXME optimize this crap\n                            if(y==0 && toprow){\n                                if(x==0 && leftcol){\n                                    pred= 1 << (bits - 1);\n                                }else{\n                                    pred= ptr16[-1];\n                                }\n                            }else{\n                                if(x==0 && leftcol){\n                                    pred= ptr16[-linesize];\n                                }else{\n                                    PREDICT(pred, ptr16[-linesize-1], ptr16[-linesize], ptr16[-1], predictor);\n                                }\n                            }\n\n                            if (s->interlaced && s->bottom_field)\n                                ptr16 += linesize >> 1;\n                            pred &= mask;\n                            *ptr16= pred + (dc << point_transform);\n                        }\n                        if (++x == h) {\n                            x = 0;\n                            y++;\n                        }\n                    }\n                }\n            } else {\n                for (i = 0; i < nb_components; i++) {\n                    uint8_t *ptr;\n                    uint16_t *ptr16;\n                    int n, h, v, x, y, c, j, linesize, dc;\n                    n        = s->nb_blocks[i];\n                    c        = s->comp_index[i];\n                    h        = s->h_scount[i];\n                    v        = s->v_scount[i];\n                    x        = 0;\n                    y        = 0;\n                    linesize = s->linesize[c];\n\n                    if(bits>8) linesize /= 2;\n\n                    for (j = 0; j < n; j++) {\n                        int pred;\n\n                        dc = mjpeg_decode_dc(s, s->dc_index[i]);\n                        if(dc == 0xFFFFF)\n                            return -1;\n                        if(bits<=8){\n                            ptr = s->picture_ptr->data[c] +\n                              (linesize * (v * mb_y + y)) +\n                              (h * mb_x + x); //FIXME optimize this crap\n                            PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n                            pred &= mask;\n                            *ptr = pred + (dc << point_transform);\n                        }else{\n                            ptr16 = (uint16_t*)(s->picture_ptr->data[c] + 2*(linesize * (v * mb_y + y)) + 2*(h * mb_x + x)); //FIXME optimize this crap\n                            PREDICT(pred, ptr16[-linesize-1], ptr16[-linesize], ptr16[-1], predictor);\n\n                            pred &= mask;\n                            *ptr16= pred + (dc << point_transform);\n                        }\n\n                        if (++x == h) {\n                            x = 0;\n                            y++;\n                        }\n                    }\n                }\n            }\n            if (s->restart_interval && !--s->restart_count) {\n                align_get_bits(&s->gb);\n                skip_bits(&s->gb, 16); /* skip RSTn */\n            }\n        }\n    }\n    return 0;\n}",
        "func": "static int ljpeg_decode_yuv_scan(MJpegDecodeContext *s, int predictor,\n                                 int point_transform, int nb_components)\n{\n    int i, mb_x, mb_y, mask;\n    int bits= (s->bits+7)&~7;\n    int resync_mb_y = 0;\n    int resync_mb_x = 0;\n\n    point_transform += bits - s->bits;\n    mask = ((1 << s->bits) - 1) << point_transform;\n\n    av_assert0(nb_components>=1 && nb_components<=4);\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n            if (s->restart_interval && !s->restart_count){\n                s->restart_count = s->restart_interval;\n                resync_mb_x = mb_x;\n                resync_mb_y = mb_y;\n            }\n\n            if(!mb_x || mb_y == resync_mb_y || mb_y == resync_mb_y+1 && mb_x < resync_mb_x || s->interlaced){\n                int toprow  = mb_y == resync_mb_y || mb_y == resync_mb_y+1 && mb_x < resync_mb_x;\n                int leftcol = !mb_x || mb_y == resync_mb_y && mb_x == resync_mb_x;\n                for (i = 0; i < nb_components; i++) {\n                    uint8_t *ptr;\n                    uint16_t *ptr16;\n                    int n, h, v, x, y, c, j, linesize;\n                    n = s->nb_blocks[i];\n                    c = s->comp_index[i];\n                    h = s->h_scount[i];\n                    v = s->v_scount[i];\n                    x = 0;\n                    y = 0;\n                    linesize= s->linesize[c];\n\n                    if(bits>8) linesize /= 2;\n\n                    for(j=0; j<n; j++) {\n                        int pred, dc;\n\n                        dc = mjpeg_decode_dc(s, s->dc_index[i]);\n                        if(dc == 0xFFFFF)\n                            return -1;\n                        if (   h * mb_x + x >= s->width\n                            || v * mb_y + y >= s->height) {\n                            // Nothing to do\n                        } else if (bits<=8) {\n                        ptr = s->picture_ptr->data[c] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n                        if(y==0 && toprow){\n                            if(x==0 && leftcol){\n                                pred= 1 << (bits - 1);\n                            }else{\n                                pred= ptr[-1];\n                            }\n                        }else{\n                            if(x==0 && leftcol){\n                                pred= ptr[-linesize];\n                            }else{\n                                PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n                            }\n                        }\n\n                        if (s->interlaced && s->bottom_field)\n                            ptr += linesize >> 1;\n                        pred &= mask;\n                        *ptr= pred + (dc << point_transform);\n                        }else{\n                            ptr16 = (uint16_t*)(s->picture_ptr->data[c] + 2*(linesize * (v * mb_y + y)) + 2*(h * mb_x + x)); //FIXME optimize this crap\n                            if(y==0 && toprow){\n                                if(x==0 && leftcol){\n                                    pred= 1 << (bits - 1);\n                                }else{\n                                    pred= ptr16[-1];\n                                }\n                            }else{\n                                if(x==0 && leftcol){\n                                    pred= ptr16[-linesize];\n                                }else{\n                                    PREDICT(pred, ptr16[-linesize-1], ptr16[-linesize], ptr16[-1], predictor);\n                                }\n                            }\n\n                            if (s->interlaced && s->bottom_field)\n                                ptr16 += linesize >> 1;\n                            pred &= mask;\n                            *ptr16= pred + (dc << point_transform);\n                        }\n                        if (++x == h) {\n                            x = 0;\n                            y++;\n                        }\n                    }\n                }\n            } else {\n                for (i = 0; i < nb_components; i++) {\n                    uint8_t *ptr;\n                    uint16_t *ptr16;\n                    int n, h, v, x, y, c, j, linesize, dc;\n                    n        = s->nb_blocks[i];\n                    c        = s->comp_index[i];\n                    h        = s->h_scount[i];\n                    v        = s->v_scount[i];\n                    x        = 0;\n                    y        = 0;\n                    linesize = s->linesize[c];\n\n                    if(bits>8) linesize /= 2;\n\n                    for (j = 0; j < n; j++) {\n                        int pred;\n\n                        dc = mjpeg_decode_dc(s, s->dc_index[i]);\n                        if(dc == 0xFFFFF)\n                            return -1;\n                        if (   h * mb_x + x >= s->width\n                            || v * mb_y + y >= s->height) {\n                            // Nothing to do\n                        } else if (bits<=8) {\n                            ptr = s->picture_ptr->data[c] +\n                              (linesize * (v * mb_y + y)) +\n                              (h * mb_x + x); //FIXME optimize this crap\n                            PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n                            pred &= mask;\n                            *ptr = pred + (dc << point_transform);\n                        }else{\n                            ptr16 = (uint16_t*)(s->picture_ptr->data[c] + 2*(linesize * (v * mb_y + y)) + 2*(h * mb_x + x)); //FIXME optimize this crap\n                            PREDICT(pred, ptr16[-linesize-1], ptr16[-linesize], ptr16[-1], predictor);\n\n                            pred &= mask;\n                            *ptr16= pred + (dc << point_transform);\n                        }\n\n                        if (++x == h) {\n                            x = 0;\n                            y++;\n                        }\n                    }\n                }\n            }\n            if (s->restart_interval && !--s->restart_count) {\n                align_get_bits(&s->gb);\n                skip_bits(&s->gb, 16); /* skip RSTn */\n            }\n        }\n    }\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -42,7 +42,10 @@\n                         dc = mjpeg_decode_dc(s, s->dc_index[i]);\n                         if(dc == 0xFFFFF)\n                             return -1;\n-                        if(bits<=8){\n+                        if (   h * mb_x + x >= s->width\n+                            || v * mb_y + y >= s->height) {\n+                            // Nothing to do\n+                        } else if (bits<=8) {\n                         ptr = s->picture_ptr->data[c] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n                         if(y==0 && toprow){\n                             if(x==0 && leftcol){\n@@ -110,7 +113,10 @@\n                         dc = mjpeg_decode_dc(s, s->dc_index[i]);\n                         if(dc == 0xFFFFF)\n                             return -1;\n-                        if(bits<=8){\n+                        if (   h * mb_x + x >= s->width\n+                            || v * mb_y + y >= s->height) {\n+                            // Nothing to do\n+                        } else if (bits<=8) {\n                             ptr = s->picture_ptr->data[c] +\n                               (linesize * (v * mb_y + y)) +\n                               (h * mb_x + x); //FIXME optimize this crap",
        "diff_line_info": {
            "deleted_lines": [
                "                        if(bits<=8){",
                "                        if(bits<=8){"
            ],
            "added_lines": [
                "                        if (   h * mb_x + x >= s->width",
                "                            || v * mb_y + y >= s->height) {",
                "                            // Nothing to do",
                "                        } else if (bits<=8) {",
                "                        if (   h * mb_x + x >= s->width",
                "                            || v * mb_y + y >= s->height) {",
                "                            // Nothing to do",
                "                        } else if (bits<=8) {"
            ]
        }
    },
    {
        "cve_id": "CVE-2016-1571",
        "func_name": "xen-project/xen/paging_invlpg",
        "description": "The paging_invlpg function in include/asm-x86/paging.h in Xen 3.3.x through 4.6.x, when using shadow mode paging or nested virtualization is enabled, allows local HVM guest users to cause a denial of service (host crash) via a non-canonical guest address in an INVVPID instruction, which triggers a hypervisor bug check.",
        "git_url": "https://github.com/xen-project/xen/commit/bf05e88ed7342a91cceba050b6c622accb809842",
        "commit_title": "x86/VMX: prevent INVVPID failure due to non-canonical guest address",
        "commit_text": " While INVLPG (and on SVM INVLPGA) don't fault on non-canonical addresses, INVVPID fails (in the \"individual address\" case) when passed such an address.  Since such intercepted INVLPG are effectively no-ops anyway, don't fix this in vmx_invlpg_intercept(), but instead have paging_invlpg() never return true in such a case.  This is CVE-2016-1571 / XSA-168. ",
        "func_before": "static inline int paging_invlpg(struct vcpu *v, unsigned long va)\n{\n    return paging_get_hostmode(v)->invlpg(v, va);\n}",
        "func": "static inline int paging_invlpg(struct vcpu *v, unsigned long va)\n{\n    return is_canonical_address(va) && paging_get_hostmode(v)->invlpg(v, va);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,4 @@\n static inline int paging_invlpg(struct vcpu *v, unsigned long va)\n {\n-    return paging_get_hostmode(v)->invlpg(v, va);\n+    return is_canonical_address(va) && paging_get_hostmode(v)->invlpg(v, va);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    return paging_get_hostmode(v)->invlpg(v, va);"
            ],
            "added_lines": [
                "    return is_canonical_address(va) && paging_get_hostmode(v)->invlpg(v, va);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8595",
        "func_name": "xen-project/xen/protmode_load_seg",
        "description": "arch/x86/x86_emulate/x86_emulate.c in Xen 3.2.1 through 4.4.x does not properly check privileges, which allows local HVM guest users to gain privileges or cause a denial of service (crash) via a crafted (1) CALL, (2) JMP, (3) RETF, (4) LCALL, (5) LJMP, or (6) LRET far branch instruction.",
        "git_url": "https://github.com/xen-project/xen/commit/1d68c1a70e00ed95ef0889cfa005379dab27b37d",
        "commit_title": "x86emul: enforce privilege level restrictions when loading CS",
        "commit_text": " Privilege level checks were basically missing for the CS case, the only check that was done (RPL == DPL for nonconforming segments) was solely covering a single special case (return to non-conforming segment).  Additionally in long mode the L bit set requires the D bit to be clear, as was recently pointed out for KVM by Nadav Amit <namit@cs.technion.ac.il>.  Finally we also need to force the loaded selector's RPL to CPL (at least as long as lret/retf emulation doesn't support privilege level changes).  This is CVE-2014-8595 / XSA-110. ",
        "func_before": "static int\nprotmode_load_seg(\n    enum x86_segment seg,\n    uint16_t sel,\n    struct x86_emulate_ctxt *ctxt,\n    const struct x86_emulate_ops *ops)\n{\n    struct segment_register desctab, ss, segr;\n    struct { uint32_t a, b; } desc;\n    uint8_t dpl, rpl, cpl;\n    uint32_t new_desc_b, a_flag = 0x100;\n    int rc, fault_type = EXC_GP;\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        if ( (seg == x86_seg_cs) || (seg == x86_seg_ss) )\n            goto raise_exn;\n        memset(&segr, 0, sizeof(segr));\n        return ops->write_segment(seg, &segr, ctxt);\n    }\n\n    /* System segment descriptors must reside in the GDT. */\n    if ( !is_x86_user_segment(seg) && (sel & 4) )\n        goto raise_exn;\n\n    if ( (rc = ops->read_segment(x86_seg_ss, &ss, ctxt)) ||\n         (rc = ops->read_segment((sel & 4) ? x86_seg_ldtr : x86_seg_gdtr,\n                                 &desctab, ctxt)) )\n        return rc;\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto raise_exn;\n\n    if ( (rc = ops->read(x86_seg_none, desctab.base + (sel & 0xfff8),\n                         &desc, sizeof(desc), ctxt)) )\n        return rc;\n\n    /* Segment present in memory? */\n    if ( !(desc.b & (1u<<15)) )\n    {\n        fault_type = EXC_NP;\n        goto raise_exn;\n    }\n\n    if ( !is_x86_user_segment(seg) )\n    {\n        /* System segments must have S flag == 0. */\n        if ( desc.b & (1u << 12) )\n            goto raise_exn;\n        /* We do not support 64-bit descriptor types. */\n        if ( in_longmode(ctxt, ops) )\n            return X86EMUL_UNHANDLEABLE;\n    }\n    /* User segments must have S flag == 1. */\n    else if ( !(desc.b & (1u << 12)) )\n        goto raise_exn;\n\n    dpl = (desc.b >> 13) & 3;\n    rpl = sel & 3;\n    cpl = ss.attr.fields.dpl;\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        /* Code segment? */\n        if ( !(desc.b & (1u<<11)) )\n            goto raise_exn;\n        /* Non-conforming segment: check DPL against RPL. */\n        if ( ((desc.b & (6u<<9)) != (6u<<9)) && (dpl != rpl) )\n            goto raise_exn;\n        break;\n    case x86_seg_ss:\n        /* Writable data segment? */\n        if ( (desc.b & (5u<<9)) != (1u<<9) )\n            goto raise_exn;\n        if ( (dpl != cpl) || (dpl != rpl) )\n            goto raise_exn;\n        break;\n    case x86_seg_ldtr:\n        /* LDT system segment? */\n        if ( (desc.b & (15u<<8)) != (2u<<8) )\n            goto raise_exn;\n        goto skip_accessed_flag;\n    case x86_seg_tr:\n        /* Available TSS system segment? */\n        if ( (desc.b & (15u<<8)) != (9u<<8) )\n            goto raise_exn;\n        a_flag = 0x200; /* busy flag */\n        break;\n    default:\n        /* Readable code or data segment? */\n        if ( (desc.b & (5u<<9)) == (4u<<9) )\n            goto raise_exn;\n        /* Non-conforming segment: check DPL against RPL and CPL. */\n        if ( ((desc.b & (6u<<9)) != (6u<<9)) &&\n             ((dpl < cpl) || (dpl < rpl)) )\n            goto raise_exn;\n        break;\n    }\n\n    /* Ensure Accessed flag is set. */\n    new_desc_b = desc.b | a_flag;\n    if ( !(desc.b & a_flag) &&\n         ((rc = ops->cmpxchg(\n             x86_seg_none, desctab.base + (sel & 0xfff8) + 4,\n             &desc.b, &new_desc_b, 4, ctxt)) != 0) )\n        return rc;\n\n    /* Force the Accessed flag in our local copy. */\n    desc.b |= a_flag;\n\n skip_accessed_flag:\n    segr.base = (((desc.b <<  0) & 0xff000000u) |\n                 ((desc.b << 16) & 0x00ff0000u) |\n                 ((desc.a >> 16) & 0x0000ffffu));\n    segr.attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                       ((desc.b >> 12) & 0x0f00u));\n    segr.limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( segr.attr.fields.g )\n        segr.limit = (segr.limit << 12) | 0xfffu;\n    segr.sel = sel;\n    return ops->write_segment(seg, &segr, ctxt);\n\n raise_exn:\n    if ( ops->inject_hw_exception == NULL )\n        return X86EMUL_UNHANDLEABLE;\n    if ( (rc = ops->inject_hw_exception(fault_type, sel & 0xfffc, ctxt)) )\n        return rc;\n    return X86EMUL_EXCEPTION;\n}",
        "func": "static int\nprotmode_load_seg(\n    enum x86_segment seg,\n    uint16_t sel, bool_t is_ret,\n    struct x86_emulate_ctxt *ctxt,\n    const struct x86_emulate_ops *ops)\n{\n    struct segment_register desctab, ss, segr;\n    struct { uint32_t a, b; } desc;\n    uint8_t dpl, rpl, cpl;\n    uint32_t new_desc_b, a_flag = 0x100;\n    int rc, fault_type = EXC_GP;\n\n    /* NULL selector? */\n    if ( (sel & 0xfffc) == 0 )\n    {\n        if ( (seg == x86_seg_cs) || (seg == x86_seg_ss) )\n            goto raise_exn;\n        memset(&segr, 0, sizeof(segr));\n        return ops->write_segment(seg, &segr, ctxt);\n    }\n\n    /* System segment descriptors must reside in the GDT. */\n    if ( !is_x86_user_segment(seg) && (sel & 4) )\n        goto raise_exn;\n\n    if ( (rc = ops->read_segment(x86_seg_ss, &ss, ctxt)) ||\n         (rc = ops->read_segment((sel & 4) ? x86_seg_ldtr : x86_seg_gdtr,\n                                 &desctab, ctxt)) )\n        return rc;\n\n    /* Check against descriptor table limit. */\n    if ( ((sel & 0xfff8) + 7) > desctab.limit )\n        goto raise_exn;\n\n    if ( (rc = ops->read(x86_seg_none, desctab.base + (sel & 0xfff8),\n                         &desc, sizeof(desc), ctxt)) )\n        return rc;\n\n    /* Segment present in memory? */\n    if ( !(desc.b & (1u<<15)) )\n    {\n        fault_type = EXC_NP;\n        goto raise_exn;\n    }\n\n    if ( !is_x86_user_segment(seg) )\n    {\n        /* System segments must have S flag == 0. */\n        if ( desc.b & (1u << 12) )\n            goto raise_exn;\n        /* We do not support 64-bit descriptor types. */\n        if ( in_longmode(ctxt, ops) )\n            return X86EMUL_UNHANDLEABLE;\n    }\n    /* User segments must have S flag == 1. */\n    else if ( !(desc.b & (1u << 12)) )\n        goto raise_exn;\n\n    dpl = (desc.b >> 13) & 3;\n    rpl = sel & 3;\n    cpl = ss.attr.fields.dpl;\n\n    switch ( seg )\n    {\n    case x86_seg_cs:\n        /* Code segment? */\n        if ( !(desc.b & (1u<<11)) )\n            goto raise_exn;\n        if ( is_ret\n             ? /*\n                * Really rpl < cpl, but our sole caller doesn't handle\n                * privilege level changes.\n                */\n               rpl != cpl || (desc.b & (1 << 10) ? dpl > rpl : dpl != rpl)\n             : desc.b & (1 << 10)\n               /* Conforming segment: check DPL against CPL. */\n               ? dpl > cpl\n               /* Non-conforming segment: check RPL and DPL against CPL. */\n               : rpl > cpl || dpl != cpl )\n            goto raise_exn;\n        /* 64-bit code segments (L bit set) must have D bit clear. */\n        if ( in_longmode(ctxt, ops) &&\n             (desc.b & (1 << 21)) && (desc.b & (1 << 22)) )\n            goto raise_exn;\n        sel = (sel ^ rpl) | cpl;\n        break;\n    case x86_seg_ss:\n        /* Writable data segment? */\n        if ( (desc.b & (5u<<9)) != (1u<<9) )\n            goto raise_exn;\n        if ( (dpl != cpl) || (dpl != rpl) )\n            goto raise_exn;\n        break;\n    case x86_seg_ldtr:\n        /* LDT system segment? */\n        if ( (desc.b & (15u<<8)) != (2u<<8) )\n            goto raise_exn;\n        goto skip_accessed_flag;\n    case x86_seg_tr:\n        /* Available TSS system segment? */\n        if ( (desc.b & (15u<<8)) != (9u<<8) )\n            goto raise_exn;\n        a_flag = 0x200; /* busy flag */\n        break;\n    default:\n        /* Readable code or data segment? */\n        if ( (desc.b & (5u<<9)) == (4u<<9) )\n            goto raise_exn;\n        /* Non-conforming segment: check DPL against RPL and CPL. */\n        if ( ((desc.b & (6u<<9)) != (6u<<9)) &&\n             ((dpl < cpl) || (dpl < rpl)) )\n            goto raise_exn;\n        break;\n    }\n\n    /* Ensure Accessed flag is set. */\n    new_desc_b = desc.b | a_flag;\n    if ( !(desc.b & a_flag) &&\n         ((rc = ops->cmpxchg(\n             x86_seg_none, desctab.base + (sel & 0xfff8) + 4,\n             &desc.b, &new_desc_b, 4, ctxt)) != 0) )\n        return rc;\n\n    /* Force the Accessed flag in our local copy. */\n    desc.b |= a_flag;\n\n skip_accessed_flag:\n    segr.base = (((desc.b <<  0) & 0xff000000u) |\n                 ((desc.b << 16) & 0x00ff0000u) |\n                 ((desc.a >> 16) & 0x0000ffffu));\n    segr.attr.bytes = (((desc.b >>  8) & 0x00ffu) |\n                       ((desc.b >> 12) & 0x0f00u));\n    segr.limit = (desc.b & 0x000f0000u) | (desc.a & 0x0000ffffu);\n    if ( segr.attr.fields.g )\n        segr.limit = (segr.limit << 12) | 0xfffu;\n    segr.sel = sel;\n    return ops->write_segment(seg, &segr, ctxt);\n\n raise_exn:\n    if ( ops->inject_hw_exception == NULL )\n        return X86EMUL_UNHANDLEABLE;\n    if ( (rc = ops->inject_hw_exception(fault_type, sel & 0xfffc, ctxt)) )\n        return rc;\n    return X86EMUL_EXCEPTION;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static int\n protmode_load_seg(\n     enum x86_segment seg,\n-    uint16_t sel,\n+    uint16_t sel, bool_t is_ret,\n     struct x86_emulate_ctxt *ctxt,\n     const struct x86_emulate_ops *ops)\n {\n@@ -67,9 +67,23 @@\n         /* Code segment? */\n         if ( !(desc.b & (1u<<11)) )\n             goto raise_exn;\n-        /* Non-conforming segment: check DPL against RPL. */\n-        if ( ((desc.b & (6u<<9)) != (6u<<9)) && (dpl != rpl) )\n+        if ( is_ret\n+             ? /*\n+                * Really rpl < cpl, but our sole caller doesn't handle\n+                * privilege level changes.\n+                */\n+               rpl != cpl || (desc.b & (1 << 10) ? dpl > rpl : dpl != rpl)\n+             : desc.b & (1 << 10)\n+               /* Conforming segment: check DPL against CPL. */\n+               ? dpl > cpl\n+               /* Non-conforming segment: check RPL and DPL against CPL. */\n+               : rpl > cpl || dpl != cpl )\n             goto raise_exn;\n+        /* 64-bit code segments (L bit set) must have D bit clear. */\n+        if ( in_longmode(ctxt, ops) &&\n+             (desc.b & (1 << 21)) && (desc.b & (1 << 22)) )\n+            goto raise_exn;\n+        sel = (sel ^ rpl) | cpl;\n         break;\n     case x86_seg_ss:\n         /* Writable data segment? */",
        "diff_line_info": {
            "deleted_lines": [
                "    uint16_t sel,",
                "        /* Non-conforming segment: check DPL against RPL. */",
                "        if ( ((desc.b & (6u<<9)) != (6u<<9)) && (dpl != rpl) )"
            ],
            "added_lines": [
                "    uint16_t sel, bool_t is_ret,",
                "        if ( is_ret",
                "             ? /*",
                "                * Really rpl < cpl, but our sole caller doesn't handle",
                "                * privilege level changes.",
                "                */",
                "               rpl != cpl || (desc.b & (1 << 10) ? dpl > rpl : dpl != rpl)",
                "             : desc.b & (1 << 10)",
                "               /* Conforming segment: check DPL against CPL. */",
                "               ? dpl > cpl",
                "               /* Non-conforming segment: check RPL and DPL against CPL. */",
                "               : rpl > cpl || dpl != cpl )",
                "        /* 64-bit code segments (L bit set) must have D bit clear. */",
                "        if ( in_longmode(ctxt, ops) &&",
                "             (desc.b & (1 << 21)) && (desc.b & (1 << 22)) )",
                "            goto raise_exn;",
                "        sel = (sel ^ rpl) | cpl;"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8595",
        "func_name": "xen-project/xen/load_seg",
        "description": "arch/x86/x86_emulate/x86_emulate.c in Xen 3.2.1 through 4.4.x does not properly check privileges, which allows local HVM guest users to gain privileges or cause a denial of service (crash) via a crafted (1) CALL, (2) JMP, (3) RETF, (4) LCALL, (5) LJMP, or (6) LRET far branch instruction.",
        "git_url": "https://github.com/xen-project/xen/commit/1d68c1a70e00ed95ef0889cfa005379dab27b37d",
        "commit_title": "x86emul: enforce privilege level restrictions when loading CS",
        "commit_text": " Privilege level checks were basically missing for the CS case, the only check that was done (RPL == DPL for nonconforming segments) was solely covering a single special case (return to non-conforming segment).  Additionally in long mode the L bit set requires the D bit to be clear, as was recently pointed out for KVM by Nadav Amit <namit@cs.technion.ac.il>.  Finally we also need to force the loaded selector's RPL to CPL (at least as long as lret/retf emulation doesn't support privilege level changes).  This is CVE-2014-8595 / XSA-110. ",
        "func_before": "static int\nload_seg(\n    enum x86_segment seg,\n    uint16_t sel,\n    struct x86_emulate_ctxt *ctxt,\n    const struct x86_emulate_ops *ops)\n{\n    if ( (ops->read_segment == NULL) ||\n         (ops->write_segment == NULL) )\n        return X86EMUL_UNHANDLEABLE;\n\n    if ( in_protmode(ctxt, ops) )\n        return protmode_load_seg(seg, sel, ctxt, ops);\n\n    return realmode_load_seg(seg, sel, ctxt, ops);\n}",
        "func": "static int\nload_seg(\n    enum x86_segment seg,\n    uint16_t sel, bool_t is_ret,\n    struct x86_emulate_ctxt *ctxt,\n    const struct x86_emulate_ops *ops)\n{\n    if ( (ops->read_segment == NULL) ||\n         (ops->write_segment == NULL) )\n        return X86EMUL_UNHANDLEABLE;\n\n    if ( in_protmode(ctxt, ops) )\n        return protmode_load_seg(seg, sel, is_ret, ctxt, ops);\n\n    return realmode_load_seg(seg, sel, ctxt, ops);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,7 +1,7 @@\n static int\n load_seg(\n     enum x86_segment seg,\n-    uint16_t sel,\n+    uint16_t sel, bool_t is_ret,\n     struct x86_emulate_ctxt *ctxt,\n     const struct x86_emulate_ops *ops)\n {\n@@ -10,7 +10,7 @@\n         return X86EMUL_UNHANDLEABLE;\n \n     if ( in_protmode(ctxt, ops) )\n-        return protmode_load_seg(seg, sel, ctxt, ops);\n+        return protmode_load_seg(seg, sel, is_ret, ctxt, ops);\n \n     return realmode_load_seg(seg, sel, ctxt, ops);\n }",
        "diff_line_info": {
            "deleted_lines": [
                "    uint16_t sel,",
                "        return protmode_load_seg(seg, sel, ctxt, ops);"
            ],
            "added_lines": [
                "    uint16_t sel, bool_t is_ret,",
                "        return protmode_load_seg(seg, sel, is_ret, ctxt, ops);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9090",
        "func_name": "torvalds/linux/trap_init",
        "description": "The do_double_fault function in arch/x86/kernel/traps.c in the Linux kernel through 3.17.4 does not properly handle faults associated with the Stack Segment (SS) segment register, which allows local users to cause a denial of service (panic) via a modify_ldt system call, as demonstrated by sigreturn_32 in the linux-clock-tests test suite.",
        "git_url": "https://github.com/torvalds/linux/commit/6f442be2fb22be02cafa606f1769fa1e6f894441",
        "commit_title": "x86_64, traps: Stop using IST for #SS",
        "commit_text": " On a 32-bit kernel, this has no effect, since there are no IST stacks.  On a 64-bit kernel, #SS can only happen in user code, on a failed iret to user space, a canonical violation on access via RSP or RBP, or a genuine stack segment violation in 32-bit kernel code.  The first two cases don't need IST, and the latter two cases are unlikely fatal bugs, and promoting them to double faults would be fine.  This fixes a bug in which the espfix64 code mishandles a stack segment violation.  This saves 4k of memory per CPU and a tiny bit of code.  Cc: stable@vger.kernel.org",
        "func_before": "void __init trap_init(void)\n{\n\tint i;\n\n#ifdef CONFIG_EISA\n\tvoid __iomem *p = early_ioremap(0x0FFFD9, 4);\n\n\tif (readl(p) == 'E' + ('I'<<8) + ('S'<<16) + ('A'<<24))\n\t\tEISA_bus = 1;\n\tearly_iounmap(p, 4);\n#endif\n\n\tset_intr_gate(X86_TRAP_DE, divide_error);\n\tset_intr_gate_ist(X86_TRAP_NMI, &nmi, NMI_STACK);\n\t/* int4 can be called from all */\n\tset_system_intr_gate(X86_TRAP_OF, &overflow);\n\tset_intr_gate(X86_TRAP_BR, bounds);\n\tset_intr_gate(X86_TRAP_UD, invalid_op);\n\tset_intr_gate(X86_TRAP_NM, device_not_available);\n#ifdef CONFIG_X86_32\n\tset_task_gate(X86_TRAP_DF, GDT_ENTRY_DOUBLEFAULT_TSS);\n#else\n\tset_intr_gate_ist(X86_TRAP_DF, &double_fault, DOUBLEFAULT_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_OLD_MF, coprocessor_segment_overrun);\n\tset_intr_gate(X86_TRAP_TS, invalid_TSS);\n\tset_intr_gate(X86_TRAP_NP, segment_not_present);\n\tset_intr_gate_ist(X86_TRAP_SS, &stack_segment, STACKFAULT_STACK);\n\tset_intr_gate(X86_TRAP_GP, general_protection);\n\tset_intr_gate(X86_TRAP_SPURIOUS, spurious_interrupt_bug);\n\tset_intr_gate(X86_TRAP_MF, coprocessor_error);\n\tset_intr_gate(X86_TRAP_AC, alignment_check);\n#ifdef CONFIG_X86_MCE\n\tset_intr_gate_ist(X86_TRAP_MC, &machine_check, MCE_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_XF, simd_coprocessor_error);\n\n\t/* Reserve all the builtin and the syscall vector: */\n\tfor (i = 0; i < FIRST_EXTERNAL_VECTOR; i++)\n\t\tset_bit(i, used_vectors);\n\n#ifdef CONFIG_IA32_EMULATION\n\tset_system_intr_gate(IA32_SYSCALL_VECTOR, ia32_syscall);\n\tset_bit(IA32_SYSCALL_VECTOR, used_vectors);\n#endif\n\n#ifdef CONFIG_X86_32\n\tset_system_trap_gate(SYSCALL_VECTOR, &system_call);\n\tset_bit(SYSCALL_VECTOR, used_vectors);\n#endif\n\n\t/*\n\t * Set the IDT descriptor to a fixed read-only location, so that the\n\t * \"sidt\" instruction will not leak the location of the kernel, and\n\t * to defend the IDT against arbitrary memory write vulnerabilities.\n\t * It will be reloaded in cpu_init() */\n\t__set_fixmap(FIX_RO_IDT, __pa_symbol(idt_table), PAGE_KERNEL_RO);\n\tidt_descr.address = fix_to_virt(FIX_RO_IDT);\n\n\t/*\n\t * Should be a barrier for any external CPU state:\n\t */\n\tcpu_init();\n\n\tx86_init.irqs.trap_init();\n\n#ifdef CONFIG_X86_64\n\tmemcpy(&debug_idt_table, &idt_table, IDT_ENTRIES * 16);\n\tset_nmi_gate(X86_TRAP_DB, &debug);\n\tset_nmi_gate(X86_TRAP_BP, &int3);\n#endif\n}",
        "func": "void __init trap_init(void)\n{\n\tint i;\n\n#ifdef CONFIG_EISA\n\tvoid __iomem *p = early_ioremap(0x0FFFD9, 4);\n\n\tif (readl(p) == 'E' + ('I'<<8) + ('S'<<16) + ('A'<<24))\n\t\tEISA_bus = 1;\n\tearly_iounmap(p, 4);\n#endif\n\n\tset_intr_gate(X86_TRAP_DE, divide_error);\n\tset_intr_gate_ist(X86_TRAP_NMI, &nmi, NMI_STACK);\n\t/* int4 can be called from all */\n\tset_system_intr_gate(X86_TRAP_OF, &overflow);\n\tset_intr_gate(X86_TRAP_BR, bounds);\n\tset_intr_gate(X86_TRAP_UD, invalid_op);\n\tset_intr_gate(X86_TRAP_NM, device_not_available);\n#ifdef CONFIG_X86_32\n\tset_task_gate(X86_TRAP_DF, GDT_ENTRY_DOUBLEFAULT_TSS);\n#else\n\tset_intr_gate_ist(X86_TRAP_DF, &double_fault, DOUBLEFAULT_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_OLD_MF, coprocessor_segment_overrun);\n\tset_intr_gate(X86_TRAP_TS, invalid_TSS);\n\tset_intr_gate(X86_TRAP_NP, segment_not_present);\n\tset_intr_gate(X86_TRAP_SS, stack_segment);\n\tset_intr_gate(X86_TRAP_GP, general_protection);\n\tset_intr_gate(X86_TRAP_SPURIOUS, spurious_interrupt_bug);\n\tset_intr_gate(X86_TRAP_MF, coprocessor_error);\n\tset_intr_gate(X86_TRAP_AC, alignment_check);\n#ifdef CONFIG_X86_MCE\n\tset_intr_gate_ist(X86_TRAP_MC, &machine_check, MCE_STACK);\n#endif\n\tset_intr_gate(X86_TRAP_XF, simd_coprocessor_error);\n\n\t/* Reserve all the builtin and the syscall vector: */\n\tfor (i = 0; i < FIRST_EXTERNAL_VECTOR; i++)\n\t\tset_bit(i, used_vectors);\n\n#ifdef CONFIG_IA32_EMULATION\n\tset_system_intr_gate(IA32_SYSCALL_VECTOR, ia32_syscall);\n\tset_bit(IA32_SYSCALL_VECTOR, used_vectors);\n#endif\n\n#ifdef CONFIG_X86_32\n\tset_system_trap_gate(SYSCALL_VECTOR, &system_call);\n\tset_bit(SYSCALL_VECTOR, used_vectors);\n#endif\n\n\t/*\n\t * Set the IDT descriptor to a fixed read-only location, so that the\n\t * \"sidt\" instruction will not leak the location of the kernel, and\n\t * to defend the IDT against arbitrary memory write vulnerabilities.\n\t * It will be reloaded in cpu_init() */\n\t__set_fixmap(FIX_RO_IDT, __pa_symbol(idt_table), PAGE_KERNEL_RO);\n\tidt_descr.address = fix_to_virt(FIX_RO_IDT);\n\n\t/*\n\t * Should be a barrier for any external CPU state:\n\t */\n\tcpu_init();\n\n\tx86_init.irqs.trap_init();\n\n#ifdef CONFIG_X86_64\n\tmemcpy(&debug_idt_table, &idt_table, IDT_ENTRIES * 16);\n\tset_nmi_gate(X86_TRAP_DB, &debug);\n\tset_nmi_gate(X86_TRAP_BP, &int3);\n#endif\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -25,7 +25,7 @@\n \tset_intr_gate(X86_TRAP_OLD_MF, coprocessor_segment_overrun);\n \tset_intr_gate(X86_TRAP_TS, invalid_TSS);\n \tset_intr_gate(X86_TRAP_NP, segment_not_present);\n-\tset_intr_gate_ist(X86_TRAP_SS, &stack_segment, STACKFAULT_STACK);\n+\tset_intr_gate(X86_TRAP_SS, stack_segment);\n \tset_intr_gate(X86_TRAP_GP, general_protection);\n \tset_intr_gate(X86_TRAP_SPURIOUS, spurious_interrupt_bug);\n \tset_intr_gate(X86_TRAP_MF, coprocessor_error);",
        "diff_line_info": {
            "deleted_lines": [
                "\tset_intr_gate_ist(X86_TRAP_SS, &stack_segment, STACKFAULT_STACK);"
            ],
            "added_lines": [
                "\tset_intr_gate(X86_TRAP_SS, stack_segment);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8866",
        "func_name": "xen-project/xen/compat_mmuext_op",
        "description": "The compatibility mode hypercall argument translation in Xen 3.3.x through 4.4.x, when running on a 64-bit hypervisor, allows local 32-bit HVM guests to cause a denial of service (host crash) via vectors involving altering the high halves of registers while in 64-bit mode.",
        "git_url": "https://github.com/xen-project/xen/commit/0ad715304b04739fd2fc9517ce8671d3947c7621",
        "commit_title": "x86: limit checks in hypercall_xlat_continuation() to actual arguments",
        "commit_text": " HVM/PVH guests can otherwise trigger the final BUG_ON() in that function by entering 64-bit mode, setting the high halves of affected registers to non-zero values, leaving 64-bit mode, and issuing a hypercall that might get preempted and hence become subject to continuation argument translation (HYPERVISOR_memory_op being the only one possible for HVM, PVH also having the option of using HYPERVISOR_mmuext_op). This issue got introduced when HVM code was switched to use compat_memory_op() - neither that nor hypercall_xlat_continuation() were originally intended to be used by other than PV guests (which can't enter 64-bit mode and hence have no way to alter the high halves of 64-bit registers).  This is CVE-2014-8866 / XSA-111. ",
        "func_before": "int compat_mmuext_op(XEN_GUEST_HANDLE_PARAM(mmuext_op_compat_t) cmp_uops,\n                     unsigned int count,\n                     XEN_GUEST_HANDLE_PARAM(uint) pdone,\n                     unsigned int foreigndom)\n{\n    unsigned int i, preempt_mask;\n    int rc = 0;\n    XEN_GUEST_HANDLE_PARAM(mmuext_op_t) nat_ops;\n\n    if ( unlikely(count == MMU_UPDATE_PREEMPTED) &&\n         likely(guest_handle_is_null(cmp_uops)) )\n    {\n        set_xen_guest_handle(nat_ops, NULL);\n        return do_mmuext_op(nat_ops, count, pdone, foreigndom);\n    }\n\n    preempt_mask = count & MMU_UPDATE_PREEMPTED;\n    count ^= preempt_mask;\n\n    if ( unlikely(!guest_handle_okay(cmp_uops, count)) )\n        return -EFAULT;\n\n    set_xen_guest_handle(nat_ops, COMPAT_ARG_XLAT_VIRT_BASE);\n\n    for ( ; count; count -= i )\n    {\n        mmuext_op_t *nat_op = nat_ops.p;\n        unsigned int limit = COMPAT_ARG_XLAT_SIZE / sizeof(*nat_op);\n        int err;\n\n        for ( i = 0; i < min(limit, count); ++i )\n        {\n            mmuext_op_compat_t cmp_op;\n            enum XLAT_mmuext_op_arg1 arg1;\n            enum XLAT_mmuext_op_arg2 arg2;\n\n            if ( unlikely(__copy_from_guest(&cmp_op, cmp_uops, 1) != 0) )\n            {\n                rc = -EFAULT;\n                break;\n            }\n\n            switch ( cmp_op.cmd )\n            {\n            case MMUEXT_PIN_L1_TABLE:\n            case MMUEXT_PIN_L2_TABLE:\n            case MMUEXT_PIN_L3_TABLE:\n            case MMUEXT_PIN_L4_TABLE:\n            case MMUEXT_UNPIN_TABLE:\n            case MMUEXT_NEW_BASEPTR:\n            case MMUEXT_CLEAR_PAGE:\n            case MMUEXT_COPY_PAGE:\n                arg1 = XLAT_mmuext_op_arg1_mfn;\n                break;\n            default:\n                arg1 = XLAT_mmuext_op_arg1_linear_addr;\n                break;\n            case MMUEXT_NEW_USER_BASEPTR:\n                rc = -EINVAL;\n            case MMUEXT_TLB_FLUSH_LOCAL:\n            case MMUEXT_TLB_FLUSH_MULTI:\n            case MMUEXT_TLB_FLUSH_ALL:\n            case MMUEXT_FLUSH_CACHE:\n                arg1 = -1;\n                break;\n            }\n\n            if ( rc )\n                break;\n\n            switch ( cmp_op.cmd )\n            {\n            case MMUEXT_SET_LDT:\n                arg2 = XLAT_mmuext_op_arg2_nr_ents;\n                break;\n            case MMUEXT_TLB_FLUSH_MULTI:\n            case MMUEXT_INVLPG_MULTI:\n                arg2 = XLAT_mmuext_op_arg2_vcpumask;\n                break;\n            case MMUEXT_COPY_PAGE:\n                arg2 = XLAT_mmuext_op_arg2_src_mfn;\n                break;\n            default:\n                arg2 = -1;\n                break;\n            }\n\n#define XLAT_mmuext_op_HNDL_arg2_vcpumask(_d_, _s_) \\\n        guest_from_compat_handle((_d_)->arg2.vcpumask, (_s_)->arg2.vcpumask)\n            XLAT_mmuext_op(nat_op, &cmp_op);\n#undef XLAT_mmuext_op_HNDL_arg2_vcpumask\n\n            if ( rc || i >= limit )\n                break;\n\n            guest_handle_add_offset(cmp_uops, 1);\n            ++nat_op;\n        }\n\n        err = do_mmuext_op(nat_ops, i | preempt_mask, pdone, foreigndom);\n\n        if ( err )\n        {\n            BUILD_BUG_ON(__HYPERVISOR_mmuext_op <= 0);\n            if ( err == __HYPERVISOR_mmuext_op )\n            {\n                struct cpu_user_regs *regs = guest_cpu_user_regs();\n                struct mc_state *mcs = &current->mc_state;\n                unsigned int arg1 = !test_bit(_MCSF_in_multicall, &mcs->flags)\n                                    ? regs->ecx\n                                    : mcs->call.args[1];\n                unsigned int left = arg1 & ~MMU_UPDATE_PREEMPTED;\n\n                BUG_ON(left == arg1 && left != i);\n                BUG_ON(left > count);\n                guest_handle_add_offset(nat_ops, i - left);\n                guest_handle_subtract_offset(cmp_uops, left);\n                left = 1;\n                if ( arg1 != MMU_UPDATE_PREEMPTED )\n                {\n                    BUG_ON(!hypercall_xlat_continuation(&left, 0x01, nat_ops,\n                                                        cmp_uops));\n                    if ( !test_bit(_MCSF_in_multicall, &mcs->flags) )\n                        regs->_ecx += count - i;\n                    else\n                        mcs->compat_call.args[1] += count - i;\n                }\n                else\n                    BUG_ON(hypercall_xlat_continuation(&left, 0));\n                BUG_ON(left != arg1);\n            }\n            else\n                BUG_ON(err > 0);\n            rc = err;\n        }\n\n        if ( rc )\n            break;\n\n        /* Force do_mmuext_op() to not start counting from zero again. */\n        preempt_mask = MMU_UPDATE_PREEMPTED;\n    }\n\n    return rc;\n}",
        "func": "int compat_mmuext_op(XEN_GUEST_HANDLE_PARAM(mmuext_op_compat_t) cmp_uops,\n                     unsigned int count,\n                     XEN_GUEST_HANDLE_PARAM(uint) pdone,\n                     unsigned int foreigndom)\n{\n    unsigned int i, preempt_mask;\n    int rc = 0;\n    XEN_GUEST_HANDLE_PARAM(mmuext_op_t) nat_ops;\n\n    if ( unlikely(count == MMU_UPDATE_PREEMPTED) &&\n         likely(guest_handle_is_null(cmp_uops)) )\n    {\n        set_xen_guest_handle(nat_ops, NULL);\n        return do_mmuext_op(nat_ops, count, pdone, foreigndom);\n    }\n\n    preempt_mask = count & MMU_UPDATE_PREEMPTED;\n    count ^= preempt_mask;\n\n    if ( unlikely(!guest_handle_okay(cmp_uops, count)) )\n        return -EFAULT;\n\n    set_xen_guest_handle(nat_ops, COMPAT_ARG_XLAT_VIRT_BASE);\n\n    for ( ; count; count -= i )\n    {\n        mmuext_op_t *nat_op = nat_ops.p;\n        unsigned int limit = COMPAT_ARG_XLAT_SIZE / sizeof(*nat_op);\n        int err;\n\n        for ( i = 0; i < min(limit, count); ++i )\n        {\n            mmuext_op_compat_t cmp_op;\n            enum XLAT_mmuext_op_arg1 arg1;\n            enum XLAT_mmuext_op_arg2 arg2;\n\n            if ( unlikely(__copy_from_guest(&cmp_op, cmp_uops, 1) != 0) )\n            {\n                rc = -EFAULT;\n                break;\n            }\n\n            switch ( cmp_op.cmd )\n            {\n            case MMUEXT_PIN_L1_TABLE:\n            case MMUEXT_PIN_L2_TABLE:\n            case MMUEXT_PIN_L3_TABLE:\n            case MMUEXT_PIN_L4_TABLE:\n            case MMUEXT_UNPIN_TABLE:\n            case MMUEXT_NEW_BASEPTR:\n            case MMUEXT_CLEAR_PAGE:\n            case MMUEXT_COPY_PAGE:\n                arg1 = XLAT_mmuext_op_arg1_mfn;\n                break;\n            default:\n                arg1 = XLAT_mmuext_op_arg1_linear_addr;\n                break;\n            case MMUEXT_NEW_USER_BASEPTR:\n                rc = -EINVAL;\n            case MMUEXT_TLB_FLUSH_LOCAL:\n            case MMUEXT_TLB_FLUSH_MULTI:\n            case MMUEXT_TLB_FLUSH_ALL:\n            case MMUEXT_FLUSH_CACHE:\n                arg1 = -1;\n                break;\n            }\n\n            if ( rc )\n                break;\n\n            switch ( cmp_op.cmd )\n            {\n            case MMUEXT_SET_LDT:\n                arg2 = XLAT_mmuext_op_arg2_nr_ents;\n                break;\n            case MMUEXT_TLB_FLUSH_MULTI:\n            case MMUEXT_INVLPG_MULTI:\n                arg2 = XLAT_mmuext_op_arg2_vcpumask;\n                break;\n            case MMUEXT_COPY_PAGE:\n                arg2 = XLAT_mmuext_op_arg2_src_mfn;\n                break;\n            default:\n                arg2 = -1;\n                break;\n            }\n\n#define XLAT_mmuext_op_HNDL_arg2_vcpumask(_d_, _s_) \\\n        guest_from_compat_handle((_d_)->arg2.vcpumask, (_s_)->arg2.vcpumask)\n            XLAT_mmuext_op(nat_op, &cmp_op);\n#undef XLAT_mmuext_op_HNDL_arg2_vcpumask\n\n            if ( rc || i >= limit )\n                break;\n\n            guest_handle_add_offset(cmp_uops, 1);\n            ++nat_op;\n        }\n\n        err = do_mmuext_op(nat_ops, i | preempt_mask, pdone, foreigndom);\n\n        if ( err )\n        {\n            BUILD_BUG_ON(__HYPERVISOR_mmuext_op <= 0);\n            if ( err == __HYPERVISOR_mmuext_op )\n            {\n                struct cpu_user_regs *regs = guest_cpu_user_regs();\n                struct mc_state *mcs = &current->mc_state;\n                unsigned int arg1 = !test_bit(_MCSF_in_multicall, &mcs->flags)\n                                    ? regs->ecx\n                                    : mcs->call.args[1];\n                unsigned int left = arg1 & ~MMU_UPDATE_PREEMPTED;\n\n                BUG_ON(left == arg1 && left != i);\n                BUG_ON(left > count);\n                guest_handle_add_offset(nat_ops, i - left);\n                guest_handle_subtract_offset(cmp_uops, left);\n                left = 1;\n                if ( arg1 != MMU_UPDATE_PREEMPTED )\n                {\n                    BUG_ON(!hypercall_xlat_continuation(&left, 4, 0x01, nat_ops,\n                                                        cmp_uops));\n                    if ( !test_bit(_MCSF_in_multicall, &mcs->flags) )\n                        regs->_ecx += count - i;\n                    else\n                        mcs->compat_call.args[1] += count - i;\n                }\n                else\n                    BUG_ON(hypercall_xlat_continuation(&left, 4, 0));\n                BUG_ON(left != arg1);\n            }\n            else\n                BUG_ON(err > 0);\n            rc = err;\n        }\n\n        if ( rc )\n            break;\n\n        /* Force do_mmuext_op() to not start counting from zero again. */\n        preempt_mask = MMU_UPDATE_PREEMPTED;\n    }\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -118,7 +118,7 @@\n                 left = 1;\n                 if ( arg1 != MMU_UPDATE_PREEMPTED )\n                 {\n-                    BUG_ON(!hypercall_xlat_continuation(&left, 0x01, nat_ops,\n+                    BUG_ON(!hypercall_xlat_continuation(&left, 4, 0x01, nat_ops,\n                                                         cmp_uops));\n                     if ( !test_bit(_MCSF_in_multicall, &mcs->flags) )\n                         regs->_ecx += count - i;\n@@ -126,7 +126,7 @@\n                         mcs->compat_call.args[1] += count - i;\n                 }\n                 else\n-                    BUG_ON(hypercall_xlat_continuation(&left, 0));\n+                    BUG_ON(hypercall_xlat_continuation(&left, 4, 0));\n                 BUG_ON(left != arg1);\n             }\n             else",
        "diff_line_info": {
            "deleted_lines": [
                "                    BUG_ON(!hypercall_xlat_continuation(&left, 0x01, nat_ops,",
                "                    BUG_ON(hypercall_xlat_continuation(&left, 0));"
            ],
            "added_lines": [
                "                    BUG_ON(!hypercall_xlat_continuation(&left, 4, 0x01, nat_ops,",
                "                    BUG_ON(hypercall_xlat_continuation(&left, 4, 0));"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8866",
        "func_name": "xen-project/xen/compat_arch_memory_op",
        "description": "The compatibility mode hypercall argument translation in Xen 3.3.x through 4.4.x, when running on a 64-bit hypervisor, allows local 32-bit HVM guests to cause a denial of service (host crash) via vectors involving altering the high halves of registers while in 64-bit mode.",
        "git_url": "https://github.com/xen-project/xen/commit/0ad715304b04739fd2fc9517ce8671d3947c7621",
        "commit_title": "x86: limit checks in hypercall_xlat_continuation() to actual arguments",
        "commit_text": " HVM/PVH guests can otherwise trigger the final BUG_ON() in that function by entering 64-bit mode, setting the high halves of affected registers to non-zero values, leaving 64-bit mode, and issuing a hypercall that might get preempted and hence become subject to continuation argument translation (HYPERVISOR_memory_op being the only one possible for HVM, PVH also having the option of using HYPERVISOR_mmuext_op). This issue got introduced when HVM code was switched to use compat_memory_op() - neither that nor hypercall_xlat_continuation() were originally intended to be used by other than PV guests (which can't enter 64-bit mode and hence have no way to alter the high halves of 64-bit registers).  This is CVE-2014-8866 / XSA-111. ",
        "func_before": "int compat_arch_memory_op(unsigned long cmd, XEN_GUEST_HANDLE_PARAM(void) arg)\n{\n    struct compat_machphys_mfn_list xmml;\n    l2_pgentry_t l2e;\n    unsigned long v;\n    compat_pfn_t mfn;\n    unsigned int i;\n    int rc = 0;\n    int op = cmd & MEMOP_CMD_MASK;\n\n    switch ( op )\n    {\n    case XENMEM_set_memory_map:\n    {\n        struct compat_foreign_memory_map cmp;\n        struct xen_foreign_memory_map *nat = COMPAT_ARG_XLAT_VIRT_BASE;\n\n        if ( copy_from_guest(&cmp, arg, 1) )\n            return -EFAULT;\n\n#define XLAT_memory_map_HNDL_buffer(_d_, _s_) \\\n        guest_from_compat_handle((_d_)->buffer, (_s_)->buffer)\n        XLAT_foreign_memory_map(nat, &cmp);\n#undef XLAT_memory_map_HNDL_buffer\n\n        rc = arch_memory_op(cmd, guest_handle_from_ptr(nat, void));\n\n        break;\n    }\n\n    case XENMEM_memory_map:\n    case XENMEM_machine_memory_map:\n    {\n        struct compat_memory_map cmp;\n        struct xen_memory_map *nat = COMPAT_ARG_XLAT_VIRT_BASE;\n\n        if ( copy_from_guest(&cmp, arg, 1) )\n            return -EFAULT;\n\n#define XLAT_memory_map_HNDL_buffer(_d_, _s_) \\\n        guest_from_compat_handle((_d_)->buffer, (_s_)->buffer)\n        XLAT_memory_map(nat, &cmp);\n#undef XLAT_memory_map_HNDL_buffer\n\n        rc = arch_memory_op(cmd, guest_handle_from_ptr(nat, void));\n        if ( rc < 0 )\n            break;\n\n#define XLAT_memory_map_HNDL_buffer(_d_, _s_) ((void)0)\n        XLAT_memory_map(&cmp, nat);\n#undef XLAT_memory_map_HNDL_buffer\n        if ( __copy_to_guest(arg, &cmp, 1) )\n            rc = -EFAULT;\n\n        break;\n    }\n\n    case XENMEM_set_pod_target:\n    case XENMEM_get_pod_target:\n    {\n        struct compat_pod_target cmp;\n        struct xen_pod_target *nat = COMPAT_ARG_XLAT_VIRT_BASE;\n\n        if ( copy_from_guest(&cmp, arg, 1) )\n            return -EFAULT;\n\n        XLAT_pod_target(nat, &cmp);\n\n        rc = arch_memory_op(cmd, guest_handle_from_ptr(nat, void));\n        if ( rc < 0 )\n            break;\n\n        if ( rc == __HYPERVISOR_memory_op )\n            hypercall_xlat_continuation(NULL, 0x2, nat, arg);\n\n        XLAT_pod_target(&cmp, nat);\n\n        if ( __copy_to_guest(arg, &cmp, 1) )\n        {\n            if ( rc == __HYPERVISOR_memory_op )\n                hypercall_cancel_continuation();\n            rc = -EFAULT;\n        }\n\n        break;\n    }\n\n    case XENMEM_machphys_mapping:\n    {\n        struct domain *d = current->domain;\n        struct compat_machphys_mapping mapping = {\n            .v_start = MACH2PHYS_COMPAT_VIRT_START(d),\n            .v_end   = MACH2PHYS_COMPAT_VIRT_END,\n            .max_mfn = MACH2PHYS_COMPAT_NR_ENTRIES(d) - 1\n        };\n\n        if ( copy_to_guest(arg, &mapping, 1) )\n            rc = -EFAULT;\n\n        break;\n    }\n\n    case XENMEM_machphys_mfn_list:\n    case XENMEM_machphys_compat_mfn_list:\n    {\n        unsigned long limit;\n        compat_pfn_t last_mfn;\n\n        if ( copy_from_guest(&xmml, arg, 1) )\n            return -EFAULT;\n\n        limit = (unsigned long)(compat_machine_to_phys_mapping + max_page);\n        if ( limit > RDWR_COMPAT_MPT_VIRT_END )\n            limit = RDWR_COMPAT_MPT_VIRT_END;\n        for ( i = 0, v = RDWR_COMPAT_MPT_VIRT_START, last_mfn = 0;\n              (i != xmml.max_extents) && (v < limit);\n              i++, v += 1 << L2_PAGETABLE_SHIFT )\n        {\n            l2e = compat_idle_pg_table_l2[l2_table_offset(v)];\n            if ( l2e_get_flags(l2e) & _PAGE_PRESENT )\n                mfn = l2e_get_pfn(l2e);\n            else\n                mfn = last_mfn;\n            ASSERT(mfn);\n            if ( copy_to_compat_offset(xmml.extent_start, i, &mfn, 1) )\n                return -EFAULT;\n            last_mfn = mfn;\n        }\n\n        xmml.nr_extents = i;\n        if ( __copy_to_guest(arg, &xmml, 1) )\n            rc = -EFAULT;\n\n        break;\n    }\n\n    case XENMEM_get_sharing_freed_pages:\n        return mem_sharing_get_nr_saved_mfns();\n\n    case XENMEM_get_sharing_shared_pages:\n        return mem_sharing_get_nr_shared_mfns();\n\n    case XENMEM_paging_op:\n    {\n        xen_mem_event_op_t meo;\n        if ( copy_from_guest(&meo, arg, 1) )\n            return -EFAULT;\n        rc = do_mem_event_op(op, meo.domain, (void *) &meo);\n        if ( !rc && __copy_to_guest(arg, &meo, 1) )\n            return -EFAULT;\n        break;\n    }\n\n    case XENMEM_sharing_op:\n    {\n        xen_mem_sharing_op_t mso;\n        if ( copy_from_guest(&mso, arg, 1) )\n            return -EFAULT;\n        if ( mso.op == XENMEM_sharing_op_audit )\n            return mem_sharing_audit(); \n        rc = do_mem_event_op(op, mso.domain, (void *) &mso);\n        if ( !rc && __copy_to_guest(arg, &mso, 1) )\n            return -EFAULT;\n        break;\n    }\n\n    default:\n        rc = -ENOSYS;\n        break;\n    }\n\n    return rc;\n}",
        "func": "int compat_arch_memory_op(unsigned long cmd, XEN_GUEST_HANDLE_PARAM(void) arg)\n{\n    struct compat_machphys_mfn_list xmml;\n    l2_pgentry_t l2e;\n    unsigned long v;\n    compat_pfn_t mfn;\n    unsigned int i;\n    int rc = 0;\n    int op = cmd & MEMOP_CMD_MASK;\n\n    switch ( op )\n    {\n    case XENMEM_set_memory_map:\n    {\n        struct compat_foreign_memory_map cmp;\n        struct xen_foreign_memory_map *nat = COMPAT_ARG_XLAT_VIRT_BASE;\n\n        if ( copy_from_guest(&cmp, arg, 1) )\n            return -EFAULT;\n\n#define XLAT_memory_map_HNDL_buffer(_d_, _s_) \\\n        guest_from_compat_handle((_d_)->buffer, (_s_)->buffer)\n        XLAT_foreign_memory_map(nat, &cmp);\n#undef XLAT_memory_map_HNDL_buffer\n\n        rc = arch_memory_op(cmd, guest_handle_from_ptr(nat, void));\n\n        break;\n    }\n\n    case XENMEM_memory_map:\n    case XENMEM_machine_memory_map:\n    {\n        struct compat_memory_map cmp;\n        struct xen_memory_map *nat = COMPAT_ARG_XLAT_VIRT_BASE;\n\n        if ( copy_from_guest(&cmp, arg, 1) )\n            return -EFAULT;\n\n#define XLAT_memory_map_HNDL_buffer(_d_, _s_) \\\n        guest_from_compat_handle((_d_)->buffer, (_s_)->buffer)\n        XLAT_memory_map(nat, &cmp);\n#undef XLAT_memory_map_HNDL_buffer\n\n        rc = arch_memory_op(cmd, guest_handle_from_ptr(nat, void));\n        if ( rc < 0 )\n            break;\n\n#define XLAT_memory_map_HNDL_buffer(_d_, _s_) ((void)0)\n        XLAT_memory_map(&cmp, nat);\n#undef XLAT_memory_map_HNDL_buffer\n        if ( __copy_to_guest(arg, &cmp, 1) )\n            rc = -EFAULT;\n\n        break;\n    }\n\n    case XENMEM_set_pod_target:\n    case XENMEM_get_pod_target:\n    {\n        struct compat_pod_target cmp;\n        struct xen_pod_target *nat = COMPAT_ARG_XLAT_VIRT_BASE;\n\n        if ( copy_from_guest(&cmp, arg, 1) )\n            return -EFAULT;\n\n        XLAT_pod_target(nat, &cmp);\n\n        rc = arch_memory_op(cmd, guest_handle_from_ptr(nat, void));\n        if ( rc < 0 )\n            break;\n\n        if ( rc == __HYPERVISOR_memory_op )\n            hypercall_xlat_continuation(NULL, 2, 0x2, nat, arg);\n\n        XLAT_pod_target(&cmp, nat);\n\n        if ( __copy_to_guest(arg, &cmp, 1) )\n        {\n            if ( rc == __HYPERVISOR_memory_op )\n                hypercall_cancel_continuation();\n            rc = -EFAULT;\n        }\n\n        break;\n    }\n\n    case XENMEM_machphys_mapping:\n    {\n        struct domain *d = current->domain;\n        struct compat_machphys_mapping mapping = {\n            .v_start = MACH2PHYS_COMPAT_VIRT_START(d),\n            .v_end   = MACH2PHYS_COMPAT_VIRT_END,\n            .max_mfn = MACH2PHYS_COMPAT_NR_ENTRIES(d) - 1\n        };\n\n        if ( copy_to_guest(arg, &mapping, 1) )\n            rc = -EFAULT;\n\n        break;\n    }\n\n    case XENMEM_machphys_mfn_list:\n    case XENMEM_machphys_compat_mfn_list:\n    {\n        unsigned long limit;\n        compat_pfn_t last_mfn;\n\n        if ( copy_from_guest(&xmml, arg, 1) )\n            return -EFAULT;\n\n        limit = (unsigned long)(compat_machine_to_phys_mapping + max_page);\n        if ( limit > RDWR_COMPAT_MPT_VIRT_END )\n            limit = RDWR_COMPAT_MPT_VIRT_END;\n        for ( i = 0, v = RDWR_COMPAT_MPT_VIRT_START, last_mfn = 0;\n              (i != xmml.max_extents) && (v < limit);\n              i++, v += 1 << L2_PAGETABLE_SHIFT )\n        {\n            l2e = compat_idle_pg_table_l2[l2_table_offset(v)];\n            if ( l2e_get_flags(l2e) & _PAGE_PRESENT )\n                mfn = l2e_get_pfn(l2e);\n            else\n                mfn = last_mfn;\n            ASSERT(mfn);\n            if ( copy_to_compat_offset(xmml.extent_start, i, &mfn, 1) )\n                return -EFAULT;\n            last_mfn = mfn;\n        }\n\n        xmml.nr_extents = i;\n        if ( __copy_to_guest(arg, &xmml, 1) )\n            rc = -EFAULT;\n\n        break;\n    }\n\n    case XENMEM_get_sharing_freed_pages:\n        return mem_sharing_get_nr_saved_mfns();\n\n    case XENMEM_get_sharing_shared_pages:\n        return mem_sharing_get_nr_shared_mfns();\n\n    case XENMEM_paging_op:\n    {\n        xen_mem_event_op_t meo;\n        if ( copy_from_guest(&meo, arg, 1) )\n            return -EFAULT;\n        rc = do_mem_event_op(op, meo.domain, (void *) &meo);\n        if ( !rc && __copy_to_guest(arg, &meo, 1) )\n            return -EFAULT;\n        break;\n    }\n\n    case XENMEM_sharing_op:\n    {\n        xen_mem_sharing_op_t mso;\n        if ( copy_from_guest(&mso, arg, 1) )\n            return -EFAULT;\n        if ( mso.op == XENMEM_sharing_op_audit )\n            return mem_sharing_audit(); \n        rc = do_mem_event_op(op, mso.domain, (void *) &mso);\n        if ( !rc && __copy_to_guest(arg, &mso, 1) )\n            return -EFAULT;\n        break;\n    }\n\n    default:\n        rc = -ENOSYS;\n        break;\n    }\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -71,7 +71,7 @@\n             break;\n \n         if ( rc == __HYPERVISOR_memory_op )\n-            hypercall_xlat_continuation(NULL, 0x2, nat, arg);\n+            hypercall_xlat_continuation(NULL, 2, 0x2, nat, arg);\n \n         XLAT_pod_target(&cmp, nat);\n ",
        "diff_line_info": {
            "deleted_lines": [
                "            hypercall_xlat_continuation(NULL, 0x2, nat, arg);"
            ],
            "added_lines": [
                "            hypercall_xlat_continuation(NULL, 2, 0x2, nat, arg);"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8866",
        "func_name": "xen-project/xen/hypercall_xlat_continuation",
        "description": "The compatibility mode hypercall argument translation in Xen 3.3.x through 4.4.x, when running on a 64-bit hypervisor, allows local 32-bit HVM guests to cause a denial of service (host crash) via vectors involving altering the high halves of registers while in 64-bit mode.",
        "git_url": "https://github.com/xen-project/xen/commit/0ad715304b04739fd2fc9517ce8671d3947c7621",
        "commit_title": "x86: limit checks in hypercall_xlat_continuation() to actual arguments",
        "commit_text": " HVM/PVH guests can otherwise trigger the final BUG_ON() in that function by entering 64-bit mode, setting the high halves of affected registers to non-zero values, leaving 64-bit mode, and issuing a hypercall that might get preempted and hence become subject to continuation argument translation (HYPERVISOR_memory_op being the only one possible for HVM, PVH also having the option of using HYPERVISOR_mmuext_op). This issue got introduced when HVM code was switched to use compat_memory_op() - neither that nor hypercall_xlat_continuation() were originally intended to be used by other than PV guests (which can't enter 64-bit mode and hence have no way to alter the high halves of 64-bit registers).  This is CVE-2014-8866 / XSA-111. ",
        "func_before": "int hypercall_xlat_continuation(unsigned int *id, unsigned int mask, ...)\n{\n    int rc = 0;\n    struct mc_state *mcs = &current->mc_state;\n    struct cpu_user_regs *regs;\n    unsigned int i, cval = 0;\n    unsigned long nval = 0;\n    va_list args;\n\n    BUG_ON(id && *id > 5);\n    BUG_ON(id && (mask & (1U << *id)));\n\n    va_start(args, mask);\n\n    if ( test_bit(_MCSF_in_multicall, &mcs->flags) )\n    {\n        if ( !test_bit(_MCSF_call_preempted, &mcs->flags) )\n        {\n            va_end(args);\n            return 0;\n        }\n\n        for ( i = 0; i < 6; ++i, mask >>= 1 )\n        {\n            if ( mask & 1 )\n            {\n                nval = va_arg(args, unsigned long);\n                cval = va_arg(args, unsigned int);\n                if ( cval == nval )\n                    mask &= ~1U;\n                else\n                    BUG_ON(nval == (unsigned int)nval);\n            }\n            else if ( id && *id == i )\n            {\n                *id = mcs->call.args[i];\n                id = NULL;\n            }\n            if ( (mask & 1) && mcs->call.args[i] == nval )\n            {\n                mcs->call.args[i] = cval;\n                ++rc;\n            }\n            else\n                BUG_ON(mcs->call.args[i] != (unsigned int)mcs->call.args[i]);\n        }\n    }\n    else\n    {\n        regs = guest_cpu_user_regs();\n        for ( i = 0; i < 6; ++i, mask >>= 1 )\n        {\n            unsigned long *reg;\n\n            switch ( i )\n            {\n            case 0: reg = &regs->ebx; break;\n            case 1: reg = &regs->ecx; break;\n            case 2: reg = &regs->edx; break;\n            case 3: reg = &regs->esi; break;\n            case 4: reg = &regs->edi; break;\n            case 5: reg = &regs->ebp; break;\n            default: BUG(); reg = NULL; break;\n            }\n            if ( (mask & 1) )\n            {\n                nval = va_arg(args, unsigned long);\n                cval = va_arg(args, unsigned int);\n                if ( cval == nval )\n                    mask &= ~1U;\n                else\n                    BUG_ON(nval == (unsigned int)nval);\n            }\n            else if ( id && *id == i )\n            {\n                *id = *reg;\n                id = NULL;\n            }\n            if ( (mask & 1) && *reg == nval )\n            {\n                *reg = cval;\n                ++rc;\n            }\n            else\n                BUG_ON(*reg != (unsigned int)*reg);\n        }\n    }\n\n    va_end(args);\n\n    return rc;\n}",
        "func": "int hypercall_xlat_continuation(unsigned int *id, unsigned int nr,\n                                unsigned int mask, ...)\n{\n    int rc = 0;\n    struct mc_state *mcs = &current->mc_state;\n    struct cpu_user_regs *regs;\n    unsigned int i, cval = 0;\n    unsigned long nval = 0;\n    va_list args;\n\n    ASSERT(nr <= ARRAY_SIZE(mcs->call.args));\n    ASSERT(!(mask >> nr));\n\n    BUG_ON(id && *id >= nr);\n    BUG_ON(id && (mask & (1U << *id)));\n\n    va_start(args, mask);\n\n    if ( test_bit(_MCSF_in_multicall, &mcs->flags) )\n    {\n        if ( !test_bit(_MCSF_call_preempted, &mcs->flags) )\n        {\n            va_end(args);\n            return 0;\n        }\n\n        for ( i = 0; i < nr; ++i, mask >>= 1 )\n        {\n            if ( mask & 1 )\n            {\n                nval = va_arg(args, unsigned long);\n                cval = va_arg(args, unsigned int);\n                if ( cval == nval )\n                    mask &= ~1U;\n                else\n                    BUG_ON(nval == (unsigned int)nval);\n            }\n            else if ( id && *id == i )\n            {\n                *id = mcs->call.args[i];\n                id = NULL;\n            }\n            if ( (mask & 1) && mcs->call.args[i] == nval )\n            {\n                mcs->call.args[i] = cval;\n                ++rc;\n            }\n            else\n                BUG_ON(mcs->call.args[i] != (unsigned int)mcs->call.args[i]);\n        }\n    }\n    else\n    {\n        regs = guest_cpu_user_regs();\n        for ( i = 0; i < nr; ++i, mask >>= 1 )\n        {\n            unsigned long *reg;\n\n            switch ( i )\n            {\n            case 0: reg = &regs->ebx; break;\n            case 1: reg = &regs->ecx; break;\n            case 2: reg = &regs->edx; break;\n            case 3: reg = &regs->esi; break;\n            case 4: reg = &regs->edi; break;\n            case 5: reg = &regs->ebp; break;\n            default: BUG(); reg = NULL; break;\n            }\n            if ( (mask & 1) )\n            {\n                nval = va_arg(args, unsigned long);\n                cval = va_arg(args, unsigned int);\n                if ( cval == nval )\n                    mask &= ~1U;\n                else\n                    BUG_ON(nval == (unsigned int)nval);\n            }\n            else if ( id && *id == i )\n            {\n                *id = *reg;\n                id = NULL;\n            }\n            if ( (mask & 1) && *reg == nval )\n            {\n                *reg = cval;\n                ++rc;\n            }\n            else\n                BUG_ON(*reg != (unsigned int)*reg);\n        }\n    }\n\n    va_end(args);\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,4 +1,5 @@\n-int hypercall_xlat_continuation(unsigned int *id, unsigned int mask, ...)\n+int hypercall_xlat_continuation(unsigned int *id, unsigned int nr,\n+                                unsigned int mask, ...)\n {\n     int rc = 0;\n     struct mc_state *mcs = &current->mc_state;\n@@ -7,7 +8,10 @@\n     unsigned long nval = 0;\n     va_list args;\n \n-    BUG_ON(id && *id > 5);\n+    ASSERT(nr <= ARRAY_SIZE(mcs->call.args));\n+    ASSERT(!(mask >> nr));\n+\n+    BUG_ON(id && *id >= nr);\n     BUG_ON(id && (mask & (1U << *id)));\n \n     va_start(args, mask);\n@@ -20,7 +24,7 @@\n             return 0;\n         }\n \n-        for ( i = 0; i < 6; ++i, mask >>= 1 )\n+        for ( i = 0; i < nr; ++i, mask >>= 1 )\n         {\n             if ( mask & 1 )\n             {\n@@ -48,7 +52,7 @@\n     else\n     {\n         regs = guest_cpu_user_regs();\n-        for ( i = 0; i < 6; ++i, mask >>= 1 )\n+        for ( i = 0; i < nr; ++i, mask >>= 1 )\n         {\n             unsigned long *reg;\n ",
        "diff_line_info": {
            "deleted_lines": [
                "int hypercall_xlat_continuation(unsigned int *id, unsigned int mask, ...)",
                "    BUG_ON(id && *id > 5);",
                "        for ( i = 0; i < 6; ++i, mask >>= 1 )",
                "        for ( i = 0; i < 6; ++i, mask >>= 1 )"
            ],
            "added_lines": [
                "int hypercall_xlat_continuation(unsigned int *id, unsigned int nr,",
                "                                unsigned int mask, ...)",
                "    ASSERT(nr <= ARRAY_SIZE(mcs->call.args));",
                "    ASSERT(!(mask >> nr));",
                "",
                "    BUG_ON(id && *id >= nr);",
                "        for ( i = 0; i < nr; ++i, mask >>= 1 )",
                "        for ( i = 0; i < nr; ++i, mask >>= 1 )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-8866",
        "func_name": "xen-project/xen/compat_memory_op",
        "description": "The compatibility mode hypercall argument translation in Xen 3.3.x through 4.4.x, when running on a 64-bit hypervisor, allows local 32-bit HVM guests to cause a denial of service (host crash) via vectors involving altering the high halves of registers while in 64-bit mode.",
        "git_url": "https://github.com/xen-project/xen/commit/0ad715304b04739fd2fc9517ce8671d3947c7621",
        "commit_title": "x86: limit checks in hypercall_xlat_continuation() to actual arguments",
        "commit_text": " HVM/PVH guests can otherwise trigger the final BUG_ON() in that function by entering 64-bit mode, setting the high halves of affected registers to non-zero values, leaving 64-bit mode, and issuing a hypercall that might get preempted and hence become subject to continuation argument translation (HYPERVISOR_memory_op being the only one possible for HVM, PVH also having the option of using HYPERVISOR_mmuext_op). This issue got introduced when HVM code was switched to use compat_memory_op() - neither that nor hypercall_xlat_continuation() were originally intended to be used by other than PV guests (which can't enter 64-bit mode and hence have no way to alter the high halves of 64-bit registers).  This is CVE-2014-8866 / XSA-111. ",
        "func_before": "int compat_memory_op(unsigned int cmd, XEN_GUEST_HANDLE_PARAM(void) compat)\n{\n    int split, op = cmd & MEMOP_CMD_MASK;\n    long rc;\n    unsigned int start_extent = cmd >> MEMOP_EXTENT_SHIFT;\n\n    do\n    {\n        unsigned int i, end_extent = 0;\n        union {\n            XEN_GUEST_HANDLE_PARAM(void) hnd;\n            struct xen_memory_reservation *rsrv;\n            struct xen_memory_exchange *xchg;\n            struct xen_add_to_physmap *atp;\n            struct xen_add_to_physmap_batch *atpb;\n            struct xen_remove_from_physmap *xrfp;\n        } nat;\n        union {\n            struct compat_memory_reservation rsrv;\n            struct compat_memory_exchange xchg;\n            struct compat_add_to_physmap atp;\n            struct compat_add_to_physmap_batch atpb;\n        } cmp;\n\n        set_xen_guest_handle(nat.hnd, COMPAT_ARG_XLAT_VIRT_BASE);\n        split = 0;\n        switch ( op )\n        {\n            xen_pfn_t *space;\n\n        case XENMEM_increase_reservation:\n        case XENMEM_decrease_reservation:\n        case XENMEM_populate_physmap:\n            if ( copy_from_guest(&cmp.rsrv, compat, 1) )\n                return start_extent;\n\n            /* Is size too large for us to encode a continuation? */\n            if ( cmp.rsrv.nr_extents > (UINT_MAX >> MEMOP_EXTENT_SHIFT) )\n                return start_extent;\n\n            if ( !compat_handle_is_null(cmp.rsrv.extent_start) &&\n                 !compat_handle_okay(cmp.rsrv.extent_start, cmp.rsrv.nr_extents) )\n                return start_extent;\n\n            end_extent = start_extent + (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.rsrv)) /\n                                        sizeof(*space);\n            if ( end_extent > cmp.rsrv.nr_extents )\n                end_extent = cmp.rsrv.nr_extents;\n\n            space = (xen_pfn_t *)(nat.rsrv + 1);\n#define XLAT_memory_reservation_HNDL_extent_start(_d_, _s_) \\\n            do \\\n            { \\\n                if ( !compat_handle_is_null((_s_)->extent_start) ) \\\n                { \\\n                    set_xen_guest_handle((_d_)->extent_start, space - start_extent); \\\n                    if ( op != XENMEM_increase_reservation ) \\\n                    { \\\n                        for ( i = start_extent; i < end_extent; ++i ) \\\n                        { \\\n                            compat_pfn_t pfn; \\\n                            if ( __copy_from_compat_offset(&pfn, (_s_)->extent_start, i, 1) ) \\\n                            { \\\n                                end_extent = i; \\\n                                split = -1; \\\n                                break; \\\n                            } \\\n                            *space++ = pfn; \\\n                        } \\\n                    } \\\n                } \\\n                else \\\n                { \\\n                    set_xen_guest_handle((_d_)->extent_start, NULL); \\\n                    end_extent = cmp.rsrv.nr_extents; \\\n                } \\\n            } while (0)\n            XLAT_memory_reservation(nat.rsrv, &cmp.rsrv);\n#undef XLAT_memory_reservation_HNDL_extent_start\n\n            if ( end_extent < cmp.rsrv.nr_extents )\n            {\n                nat.rsrv->nr_extents = end_extent;\n                ++split;\n            }\n\n            break;\n\n        case XENMEM_exchange:\n        {\n            int order_delta;\n\n            if ( copy_from_guest(&cmp.xchg, compat, 1) )\n                return -EFAULT;\n\n            order_delta = cmp.xchg.out.extent_order - cmp.xchg.in.extent_order;\n            /* Various sanity checks. */\n            if ( (cmp.xchg.nr_exchanged > cmp.xchg.in.nr_extents) ||\n                 (order_delta > 0 && (cmp.xchg.nr_exchanged & ((1U << order_delta) - 1))) ||\n                 /* Sizes of input and output lists do not overflow an int? */\n                 ((~0U >> cmp.xchg.in.extent_order) < cmp.xchg.in.nr_extents) ||\n                 ((~0U >> cmp.xchg.out.extent_order) < cmp.xchg.out.nr_extents) ||\n                 /* Sizes of input and output lists match? */\n                 ((cmp.xchg.in.nr_extents << cmp.xchg.in.extent_order) !=\n                  (cmp.xchg.out.nr_extents << cmp.xchg.out.extent_order)) )\n                return -EINVAL;\n\n            if ( !compat_handle_okay(cmp.xchg.in.extent_start,\n                                     cmp.xchg.in.nr_extents) ||\n                 !compat_handle_okay(cmp.xchg.out.extent_start,\n                                     cmp.xchg.out.nr_extents) )\n                return -EFAULT;\n\n            start_extent = cmp.xchg.nr_exchanged;\n            end_extent = (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.xchg)) /\n                         (((1U << ABS(order_delta)) + 1) *\n                          sizeof(*space));\n            if ( end_extent == 0 )\n            {\n                printk(\"Cannot translate compatibility mode XENMEM_exchange extents (%u,%u)\\n\",\n                       cmp.xchg.in.extent_order, cmp.xchg.out.extent_order);\n                return -E2BIG;\n            }\n            if ( order_delta > 0 )\n                end_extent <<= order_delta;\n            end_extent += start_extent;\n            if ( end_extent > cmp.xchg.in.nr_extents )\n                end_extent = cmp.xchg.in.nr_extents;\n\n            space = (xen_pfn_t *)(nat.xchg + 1);\n            /* Code below depends upon .in preceding .out. */\n            BUILD_BUG_ON(offsetof(xen_memory_exchange_t, in) > offsetof(xen_memory_exchange_t, out));\n#define XLAT_memory_reservation_HNDL_extent_start(_d_, _s_) \\\n            do \\\n            { \\\n                set_xen_guest_handle((_d_)->extent_start, space - start_extent); \\\n                for ( i = start_extent; i < end_extent; ++i ) \\\n                { \\\n                    compat_pfn_t pfn; \\\n                    if ( __copy_from_compat_offset(&pfn, (_s_)->extent_start, i, 1) ) \\\n                        return -EFAULT; \\\n                    *space++ = pfn; \\\n                } \\\n                if ( order_delta > 0 ) \\\n                { \\\n                    start_extent >>= order_delta; \\\n                    end_extent >>= order_delta; \\\n                } \\\n                else \\\n                { \\\n                    start_extent <<= -order_delta; \\\n                    end_extent <<= -order_delta; \\\n                } \\\n                order_delta = -order_delta; \\\n            } while (0)\n            XLAT_memory_exchange(nat.xchg, &cmp.xchg);\n#undef XLAT_memory_reservation_HNDL_extent_start\n\n            if ( end_extent < cmp.xchg.in.nr_extents )\n            {\n                nat.xchg->in.nr_extents = end_extent;\n                if ( order_delta >= 0 )\n                    nat.xchg->out.nr_extents = end_extent >> order_delta;\n                else\n                    nat.xchg->out.nr_extents = end_extent << -order_delta;\n                ++split;\n            }\n\n            break;\n        }\n\n        case XENMEM_current_reservation:\n        case XENMEM_maximum_reservation:\n        case XENMEM_maximum_gpfn:\n        case XENMEM_maximum_ram_page:\n            nat.hnd = compat;\n            break;\n\n        case XENMEM_add_to_physmap:\n            BUILD_BUG_ON((typeof(cmp.atp.size))-1 >\n                         (UINT_MAX >> MEMOP_EXTENT_SHIFT));\n\n            if ( copy_from_guest(&cmp.atp, compat, 1) )\n                return -EFAULT;\n\n            XLAT_add_to_physmap(nat.atp, &cmp.atp);\n\n            break;\n\n        case XENMEM_add_to_physmap_batch:\n        {\n            unsigned int limit = (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.atpb))\n                                 / (sizeof(nat.atpb->idxs.p) + sizeof(nat.atpb->gpfns.p));\n            /* Use an intermediate variable to suppress warnings on old gcc: */\n            unsigned int size = cmp.atpb.size;\n            xen_ulong_t *idxs = (void *)(nat.atpb + 1);\n            xen_pfn_t *gpfns = (void *)(idxs + limit);\n\n            if ( copy_from_guest(&cmp.atpb, compat, 1) ||\n                 !compat_handle_okay(cmp.atpb.idxs, size) ||\n                 !compat_handle_okay(cmp.atpb.gpfns, size) ||\n                 !compat_handle_okay(cmp.atpb.errs, size) )\n                return -EFAULT;\n\n            end_extent = start_extent + limit;\n            if ( end_extent > size )\n                end_extent = size;\n\n            idxs -= start_extent;\n            gpfns -= start_extent;\n\n            for ( i = start_extent; i < end_extent; ++i )\n            {\n                compat_ulong_t idx;\n                compat_pfn_t gpfn;\n\n                if ( __copy_from_compat_offset(&idx, cmp.atpb.idxs, i, 1) ||\n                     __copy_from_compat_offset(&gpfn, cmp.atpb.gpfns, i, 1) )\n                    return -EFAULT;\n                idxs[i] = idx;\n                gpfns[i] = gpfn;\n            }\n\n#define XLAT_add_to_physmap_batch_HNDL_idxs(_d_, _s_) \\\n            set_xen_guest_handle((_d_)->idxs, idxs)\n#define XLAT_add_to_physmap_batch_HNDL_gpfns(_d_, _s_) \\\n            set_xen_guest_handle((_d_)->gpfns, gpfns)\n#define XLAT_add_to_physmap_batch_HNDL_errs(_d_, _s_) \\\n            guest_from_compat_handle((_d_)->errs, (_s_)->errs)\n\n            XLAT_add_to_physmap_batch(nat.atpb, &cmp.atpb);\n\n#undef XLAT_add_to_physmap_batch_HNDL_errs\n#undef XLAT_add_to_physmap_batch_HNDL_gpfns\n#undef XLAT_add_to_physmap_batch_HNDL_idxs\n\n            if ( end_extent < cmp.atpb.size )\n            {\n                nat.atpb->size = end_extent;\n                ++split;\n            }\n\n            break;\n        }\n\n        case XENMEM_remove_from_physmap:\n        {\n            struct compat_remove_from_physmap cmp;\n\n            if ( copy_from_guest(&cmp, compat, 1) )\n                return -EFAULT;\n\n            XLAT_remove_from_physmap(nat.xrfp, &cmp);\n\n            break;\n        }\n\n        default:\n            return compat_arch_memory_op(cmd, compat);\n        }\n\n        rc = do_memory_op(cmd, nat.hnd);\n        if ( rc < 0 )\n            break;\n\n        cmd = 0;\n        if ( hypercall_xlat_continuation(&cmd, 0x02, nat.hnd, compat) )\n        {\n            BUG_ON(rc != __HYPERVISOR_memory_op);\n            BUG_ON((cmd & MEMOP_CMD_MASK) != op);\n            split = -1;\n        }\n\n        switch ( op )\n        {\n        case XENMEM_increase_reservation:\n        case XENMEM_decrease_reservation:\n        case XENMEM_populate_physmap:\n            end_extent = split >= 0 ? rc : cmd >> MEMOP_EXTENT_SHIFT;\n            if ( (op != XENMEM_decrease_reservation) &&\n                 !guest_handle_is_null(nat.rsrv->extent_start) )\n            {\n                for ( ; start_extent < end_extent; ++start_extent )\n                {\n                    compat_pfn_t pfn = nat.rsrv->extent_start.p[start_extent];\n\n                    BUG_ON(pfn != nat.rsrv->extent_start.p[start_extent]);\n                    if ( __copy_to_compat_offset(cmp.rsrv.extent_start,\n                                                 start_extent, &pfn, 1) )\n                    {\n                        if ( split >= 0 )\n                        {\n                            rc = start_extent;\n                            split = 0;\n                        }\n                        else\n                            /*\n                             * Short of being able to cancel the continuation,\n                             * force it to restart here; eventually we shall\n                             * get out of this state.\n                             */\n                            rc = (start_extent << MEMOP_EXTENT_SHIFT) | op;\n                        break;\n                    }\n                }\n            }\n            else\n            {\n                start_extent = end_extent;\n            }\n            /* Bail if there was an error. */\n            if ( (split >= 0) && (end_extent != nat.rsrv->nr_extents) )\n                split = 0;\n            break;\n\n        case XENMEM_exchange:\n        {\n            DEFINE_XEN_GUEST_HANDLE(compat_memory_exchange_t);\n            int order_delta;\n\n            BUG_ON(split >= 0 && rc);\n            BUG_ON(end_extent < nat.xchg->nr_exchanged);\n            end_extent = nat.xchg->nr_exchanged;\n\n            order_delta = cmp.xchg.out.extent_order - cmp.xchg.in.extent_order;\n            if ( order_delta > 0 )\n            {\n                start_extent >>= order_delta;\n                BUG_ON(end_extent & ((1U << order_delta) - 1));\n                end_extent >>= order_delta;\n            }\n            else\n            {\n                start_extent <<= -order_delta;\n                end_extent <<= -order_delta;\n            }\n\n            for ( ; start_extent < end_extent; ++start_extent )\n            {\n                compat_pfn_t pfn = nat.xchg->out.extent_start.p[start_extent];\n\n                BUG_ON(pfn != nat.xchg->out.extent_start.p[start_extent]);\n                if ( __copy_to_compat_offset(cmp.xchg.out.extent_start,\n                                             start_extent, &pfn, 1) )\n                {\n                    rc = -EFAULT;\n                    break;\n                }\n            }\n\n            cmp.xchg.nr_exchanged = nat.xchg->nr_exchanged;\n            if ( __copy_field_to_guest(guest_handle_cast(compat,\n                                                         compat_memory_exchange_t),\n                                       &cmp.xchg, nr_exchanged) )\n                rc = -EFAULT;\n\n            if ( rc < 0 )\n            {\n                if ( split < 0 )\n                    /* Cannot cancel the continuation... */\n                    domain_crash(current->domain);\n                return rc;\n            }\n            break;\n        }\n\n        case XENMEM_access_op:\n            rc = mem_access_memop(cmd, guest_handle_cast(compat, xen_mem_access_op_t));\n            break;\n\n        case XENMEM_add_to_physmap_batch:\n            start_extent = end_extent;\n            break;\n\n        case XENMEM_maximum_ram_page:\n        case XENMEM_current_reservation:\n        case XENMEM_maximum_reservation:\n        case XENMEM_maximum_gpfn:\n        case XENMEM_add_to_physmap:\n        case XENMEM_remove_from_physmap:\n            break;\n\n        default:\n            domain_crash(current->domain);\n            split = 0;\n            break;\n        }\n\n        cmd = op | (start_extent << MEMOP_EXTENT_SHIFT);\n        if ( split > 0 && hypercall_preempt_check() )\n            return hypercall_create_continuation(\n                __HYPERVISOR_memory_op, \"ih\", cmd, compat);\n    } while ( split > 0 );\n\n    if ( unlikely(rc > INT_MAX) )\n        return INT_MAX;\n\n    if ( unlikely(rc < INT_MIN) )\n        return INT_MIN;\n\n    return rc;\n}",
        "func": "int compat_memory_op(unsigned int cmd, XEN_GUEST_HANDLE_PARAM(void) compat)\n{\n    int split, op = cmd & MEMOP_CMD_MASK;\n    long rc;\n    unsigned int start_extent = cmd >> MEMOP_EXTENT_SHIFT;\n\n    do\n    {\n        unsigned int i, end_extent = 0;\n        union {\n            XEN_GUEST_HANDLE_PARAM(void) hnd;\n            struct xen_memory_reservation *rsrv;\n            struct xen_memory_exchange *xchg;\n            struct xen_add_to_physmap *atp;\n            struct xen_add_to_physmap_batch *atpb;\n            struct xen_remove_from_physmap *xrfp;\n        } nat;\n        union {\n            struct compat_memory_reservation rsrv;\n            struct compat_memory_exchange xchg;\n            struct compat_add_to_physmap atp;\n            struct compat_add_to_physmap_batch atpb;\n        } cmp;\n\n        set_xen_guest_handle(nat.hnd, COMPAT_ARG_XLAT_VIRT_BASE);\n        split = 0;\n        switch ( op )\n        {\n            xen_pfn_t *space;\n\n        case XENMEM_increase_reservation:\n        case XENMEM_decrease_reservation:\n        case XENMEM_populate_physmap:\n            if ( copy_from_guest(&cmp.rsrv, compat, 1) )\n                return start_extent;\n\n            /* Is size too large for us to encode a continuation? */\n            if ( cmp.rsrv.nr_extents > (UINT_MAX >> MEMOP_EXTENT_SHIFT) )\n                return start_extent;\n\n            if ( !compat_handle_is_null(cmp.rsrv.extent_start) &&\n                 !compat_handle_okay(cmp.rsrv.extent_start, cmp.rsrv.nr_extents) )\n                return start_extent;\n\n            end_extent = start_extent + (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.rsrv)) /\n                                        sizeof(*space);\n            if ( end_extent > cmp.rsrv.nr_extents )\n                end_extent = cmp.rsrv.nr_extents;\n\n            space = (xen_pfn_t *)(nat.rsrv + 1);\n#define XLAT_memory_reservation_HNDL_extent_start(_d_, _s_) \\\n            do \\\n            { \\\n                if ( !compat_handle_is_null((_s_)->extent_start) ) \\\n                { \\\n                    set_xen_guest_handle((_d_)->extent_start, space - start_extent); \\\n                    if ( op != XENMEM_increase_reservation ) \\\n                    { \\\n                        for ( i = start_extent; i < end_extent; ++i ) \\\n                        { \\\n                            compat_pfn_t pfn; \\\n                            if ( __copy_from_compat_offset(&pfn, (_s_)->extent_start, i, 1) ) \\\n                            { \\\n                                end_extent = i; \\\n                                split = -1; \\\n                                break; \\\n                            } \\\n                            *space++ = pfn; \\\n                        } \\\n                    } \\\n                } \\\n                else \\\n                { \\\n                    set_xen_guest_handle((_d_)->extent_start, NULL); \\\n                    end_extent = cmp.rsrv.nr_extents; \\\n                } \\\n            } while (0)\n            XLAT_memory_reservation(nat.rsrv, &cmp.rsrv);\n#undef XLAT_memory_reservation_HNDL_extent_start\n\n            if ( end_extent < cmp.rsrv.nr_extents )\n            {\n                nat.rsrv->nr_extents = end_extent;\n                ++split;\n            }\n\n            break;\n\n        case XENMEM_exchange:\n        {\n            int order_delta;\n\n            if ( copy_from_guest(&cmp.xchg, compat, 1) )\n                return -EFAULT;\n\n            order_delta = cmp.xchg.out.extent_order - cmp.xchg.in.extent_order;\n            /* Various sanity checks. */\n            if ( (cmp.xchg.nr_exchanged > cmp.xchg.in.nr_extents) ||\n                 (order_delta > 0 && (cmp.xchg.nr_exchanged & ((1U << order_delta) - 1))) ||\n                 /* Sizes of input and output lists do not overflow an int? */\n                 ((~0U >> cmp.xchg.in.extent_order) < cmp.xchg.in.nr_extents) ||\n                 ((~0U >> cmp.xchg.out.extent_order) < cmp.xchg.out.nr_extents) ||\n                 /* Sizes of input and output lists match? */\n                 ((cmp.xchg.in.nr_extents << cmp.xchg.in.extent_order) !=\n                  (cmp.xchg.out.nr_extents << cmp.xchg.out.extent_order)) )\n                return -EINVAL;\n\n            if ( !compat_handle_okay(cmp.xchg.in.extent_start,\n                                     cmp.xchg.in.nr_extents) ||\n                 !compat_handle_okay(cmp.xchg.out.extent_start,\n                                     cmp.xchg.out.nr_extents) )\n                return -EFAULT;\n\n            start_extent = cmp.xchg.nr_exchanged;\n            end_extent = (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.xchg)) /\n                         (((1U << ABS(order_delta)) + 1) *\n                          sizeof(*space));\n            if ( end_extent == 0 )\n            {\n                printk(\"Cannot translate compatibility mode XENMEM_exchange extents (%u,%u)\\n\",\n                       cmp.xchg.in.extent_order, cmp.xchg.out.extent_order);\n                return -E2BIG;\n            }\n            if ( order_delta > 0 )\n                end_extent <<= order_delta;\n            end_extent += start_extent;\n            if ( end_extent > cmp.xchg.in.nr_extents )\n                end_extent = cmp.xchg.in.nr_extents;\n\n            space = (xen_pfn_t *)(nat.xchg + 1);\n            /* Code below depends upon .in preceding .out. */\n            BUILD_BUG_ON(offsetof(xen_memory_exchange_t, in) > offsetof(xen_memory_exchange_t, out));\n#define XLAT_memory_reservation_HNDL_extent_start(_d_, _s_) \\\n            do \\\n            { \\\n                set_xen_guest_handle((_d_)->extent_start, space - start_extent); \\\n                for ( i = start_extent; i < end_extent; ++i ) \\\n                { \\\n                    compat_pfn_t pfn; \\\n                    if ( __copy_from_compat_offset(&pfn, (_s_)->extent_start, i, 1) ) \\\n                        return -EFAULT; \\\n                    *space++ = pfn; \\\n                } \\\n                if ( order_delta > 0 ) \\\n                { \\\n                    start_extent >>= order_delta; \\\n                    end_extent >>= order_delta; \\\n                } \\\n                else \\\n                { \\\n                    start_extent <<= -order_delta; \\\n                    end_extent <<= -order_delta; \\\n                } \\\n                order_delta = -order_delta; \\\n            } while (0)\n            XLAT_memory_exchange(nat.xchg, &cmp.xchg);\n#undef XLAT_memory_reservation_HNDL_extent_start\n\n            if ( end_extent < cmp.xchg.in.nr_extents )\n            {\n                nat.xchg->in.nr_extents = end_extent;\n                if ( order_delta >= 0 )\n                    nat.xchg->out.nr_extents = end_extent >> order_delta;\n                else\n                    nat.xchg->out.nr_extents = end_extent << -order_delta;\n                ++split;\n            }\n\n            break;\n        }\n\n        case XENMEM_current_reservation:\n        case XENMEM_maximum_reservation:\n        case XENMEM_maximum_gpfn:\n        case XENMEM_maximum_ram_page:\n            nat.hnd = compat;\n            break;\n\n        case XENMEM_add_to_physmap:\n            BUILD_BUG_ON((typeof(cmp.atp.size))-1 >\n                         (UINT_MAX >> MEMOP_EXTENT_SHIFT));\n\n            if ( copy_from_guest(&cmp.atp, compat, 1) )\n                return -EFAULT;\n\n            XLAT_add_to_physmap(nat.atp, &cmp.atp);\n\n            break;\n\n        case XENMEM_add_to_physmap_batch:\n        {\n            unsigned int limit = (COMPAT_ARG_XLAT_SIZE - sizeof(*nat.atpb))\n                                 / (sizeof(nat.atpb->idxs.p) + sizeof(nat.atpb->gpfns.p));\n            /* Use an intermediate variable to suppress warnings on old gcc: */\n            unsigned int size = cmp.atpb.size;\n            xen_ulong_t *idxs = (void *)(nat.atpb + 1);\n            xen_pfn_t *gpfns = (void *)(idxs + limit);\n\n            if ( copy_from_guest(&cmp.atpb, compat, 1) ||\n                 !compat_handle_okay(cmp.atpb.idxs, size) ||\n                 !compat_handle_okay(cmp.atpb.gpfns, size) ||\n                 !compat_handle_okay(cmp.atpb.errs, size) )\n                return -EFAULT;\n\n            end_extent = start_extent + limit;\n            if ( end_extent > size )\n                end_extent = size;\n\n            idxs -= start_extent;\n            gpfns -= start_extent;\n\n            for ( i = start_extent; i < end_extent; ++i )\n            {\n                compat_ulong_t idx;\n                compat_pfn_t gpfn;\n\n                if ( __copy_from_compat_offset(&idx, cmp.atpb.idxs, i, 1) ||\n                     __copy_from_compat_offset(&gpfn, cmp.atpb.gpfns, i, 1) )\n                    return -EFAULT;\n                idxs[i] = idx;\n                gpfns[i] = gpfn;\n            }\n\n#define XLAT_add_to_physmap_batch_HNDL_idxs(_d_, _s_) \\\n            set_xen_guest_handle((_d_)->idxs, idxs)\n#define XLAT_add_to_physmap_batch_HNDL_gpfns(_d_, _s_) \\\n            set_xen_guest_handle((_d_)->gpfns, gpfns)\n#define XLAT_add_to_physmap_batch_HNDL_errs(_d_, _s_) \\\n            guest_from_compat_handle((_d_)->errs, (_s_)->errs)\n\n            XLAT_add_to_physmap_batch(nat.atpb, &cmp.atpb);\n\n#undef XLAT_add_to_physmap_batch_HNDL_errs\n#undef XLAT_add_to_physmap_batch_HNDL_gpfns\n#undef XLAT_add_to_physmap_batch_HNDL_idxs\n\n            if ( end_extent < cmp.atpb.size )\n            {\n                nat.atpb->size = end_extent;\n                ++split;\n            }\n\n            break;\n        }\n\n        case XENMEM_remove_from_physmap:\n        {\n            struct compat_remove_from_physmap cmp;\n\n            if ( copy_from_guest(&cmp, compat, 1) )\n                return -EFAULT;\n\n            XLAT_remove_from_physmap(nat.xrfp, &cmp);\n\n            break;\n        }\n\n        default:\n            return compat_arch_memory_op(cmd, compat);\n        }\n\n        rc = do_memory_op(cmd, nat.hnd);\n        if ( rc < 0 )\n            break;\n\n        cmd = 0;\n        if ( hypercall_xlat_continuation(&cmd, 2, 0x02, nat.hnd, compat) )\n        {\n            BUG_ON(rc != __HYPERVISOR_memory_op);\n            BUG_ON((cmd & MEMOP_CMD_MASK) != op);\n            split = -1;\n        }\n\n        switch ( op )\n        {\n        case XENMEM_increase_reservation:\n        case XENMEM_decrease_reservation:\n        case XENMEM_populate_physmap:\n            end_extent = split >= 0 ? rc : cmd >> MEMOP_EXTENT_SHIFT;\n            if ( (op != XENMEM_decrease_reservation) &&\n                 !guest_handle_is_null(nat.rsrv->extent_start) )\n            {\n                for ( ; start_extent < end_extent; ++start_extent )\n                {\n                    compat_pfn_t pfn = nat.rsrv->extent_start.p[start_extent];\n\n                    BUG_ON(pfn != nat.rsrv->extent_start.p[start_extent]);\n                    if ( __copy_to_compat_offset(cmp.rsrv.extent_start,\n                                                 start_extent, &pfn, 1) )\n                    {\n                        if ( split >= 0 )\n                        {\n                            rc = start_extent;\n                            split = 0;\n                        }\n                        else\n                            /*\n                             * Short of being able to cancel the continuation,\n                             * force it to restart here; eventually we shall\n                             * get out of this state.\n                             */\n                            rc = (start_extent << MEMOP_EXTENT_SHIFT) | op;\n                        break;\n                    }\n                }\n            }\n            else\n            {\n                start_extent = end_extent;\n            }\n            /* Bail if there was an error. */\n            if ( (split >= 0) && (end_extent != nat.rsrv->nr_extents) )\n                split = 0;\n            break;\n\n        case XENMEM_exchange:\n        {\n            DEFINE_XEN_GUEST_HANDLE(compat_memory_exchange_t);\n            int order_delta;\n\n            BUG_ON(split >= 0 && rc);\n            BUG_ON(end_extent < nat.xchg->nr_exchanged);\n            end_extent = nat.xchg->nr_exchanged;\n\n            order_delta = cmp.xchg.out.extent_order - cmp.xchg.in.extent_order;\n            if ( order_delta > 0 )\n            {\n                start_extent >>= order_delta;\n                BUG_ON(end_extent & ((1U << order_delta) - 1));\n                end_extent >>= order_delta;\n            }\n            else\n            {\n                start_extent <<= -order_delta;\n                end_extent <<= -order_delta;\n            }\n\n            for ( ; start_extent < end_extent; ++start_extent )\n            {\n                compat_pfn_t pfn = nat.xchg->out.extent_start.p[start_extent];\n\n                BUG_ON(pfn != nat.xchg->out.extent_start.p[start_extent]);\n                if ( __copy_to_compat_offset(cmp.xchg.out.extent_start,\n                                             start_extent, &pfn, 1) )\n                {\n                    rc = -EFAULT;\n                    break;\n                }\n            }\n\n            cmp.xchg.nr_exchanged = nat.xchg->nr_exchanged;\n            if ( __copy_field_to_guest(guest_handle_cast(compat,\n                                                         compat_memory_exchange_t),\n                                       &cmp.xchg, nr_exchanged) )\n                rc = -EFAULT;\n\n            if ( rc < 0 )\n            {\n                if ( split < 0 )\n                    /* Cannot cancel the continuation... */\n                    domain_crash(current->domain);\n                return rc;\n            }\n            break;\n        }\n\n        case XENMEM_access_op:\n            rc = mem_access_memop(cmd, guest_handle_cast(compat, xen_mem_access_op_t));\n            break;\n\n        case XENMEM_add_to_physmap_batch:\n            start_extent = end_extent;\n            break;\n\n        case XENMEM_maximum_ram_page:\n        case XENMEM_current_reservation:\n        case XENMEM_maximum_reservation:\n        case XENMEM_maximum_gpfn:\n        case XENMEM_add_to_physmap:\n        case XENMEM_remove_from_physmap:\n            break;\n\n        default:\n            domain_crash(current->domain);\n            split = 0;\n            break;\n        }\n\n        cmd = op | (start_extent << MEMOP_EXTENT_SHIFT);\n        if ( split > 0 && hypercall_preempt_check() )\n            return hypercall_create_continuation(\n                __HYPERVISOR_memory_op, \"ih\", cmd, compat);\n    } while ( split > 0 );\n\n    if ( unlikely(rc > INT_MAX) )\n        return INT_MAX;\n\n    if ( unlikely(rc < INT_MIN) )\n        return INT_MIN;\n\n    return rc;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -264,7 +264,7 @@\n             break;\n \n         cmd = 0;\n-        if ( hypercall_xlat_continuation(&cmd, 0x02, nat.hnd, compat) )\n+        if ( hypercall_xlat_continuation(&cmd, 2, 0x02, nat.hnd, compat) )\n         {\n             BUG_ON(rc != __HYPERVISOR_memory_op);\n             BUG_ON((cmd & MEMOP_CMD_MASK) != op);",
        "diff_line_info": {
            "deleted_lines": [
                "        if ( hypercall_xlat_continuation(&cmd, 0x02, nat.hnd, compat) )"
            ],
            "added_lines": [
                "        if ( hypercall_xlat_continuation(&cmd, 2, 0x02, nat.hnd, compat) )"
            ]
        }
    },
    {
        "cve_id": "CVE-2014-9426",
        "func_name": "php/php-src/apprentice_load",
        "description": "The apprentice_load function in libmagic/apprentice.c in the Fileinfo component in PHP through 5.6.4 attempts to perform a free operation on a stack-based character array, which allows remote attackers to cause a denial of service (memory corruption or application crash) or possibly have unspecified other impact via unknown vectors.  NOTE: this is disputed by the vendor because the standard erealloc behavior makes the free operation unreachable",
        "git_url": "https://github.com/php/php-src/commit/a72cd07f2983dc43a6bb35209dc4687852e53c09",
        "commit_title": "Fixed bug #68665 (Invalid free)",
        "commit_text": "",
        "func_before": "magic_map *\napprentice_load(struct magic_set *ms, const char *fn, int action)\n{\n\tint errs = 0;\n\tuint32_t i, j;\n\tsize_t files = 0, maxfiles = 0;\n\tchar **filearr = NULL;\n\tstruct stat st;\n\tstruct magic_map *map;\n\tstruct magic_entry_set mset[MAGIC_SETS];\n\tphp_stream *dir;\n\tphp_stream_dirent d;\n \n\tTSRMLS_FETCH();\n\n\tmemset(mset, 0, sizeof(mset));\n\tms->flags |= MAGIC_CHECK;\t/* Enable checks for parsed files */\n\n\n\tif ((map = CAST(struct magic_map *, ecalloc(1, sizeof(*map)))) == NULL)\n\t{\n\t\tfile_oomem(ms, sizeof(*map));\n\t\treturn NULL;\n\t}\n\n\t/* print silly verbose header for USG compat. */\n\tif (action == FILE_CHECK)\n\t\t(void)fprintf(stderr, \"%s\\n\", usg_hdr);\n\n\t/* load directory or file */\n\t/* FIXME: Read file names and sort them to prevent\n\t   non-determinism. See Debian bug #488562. */\n\tif (php_sys_stat(fn, &st) == 0 && S_ISDIR(st.st_mode)) {\n\t\tint mflen;\n\t\tchar mfn[MAXPATHLEN];\n\n\t\tdir = php_stream_opendir((char *)fn, REPORT_ERRORS, NULL);\n\t\tif (!dir) {\n\t\t\terrs++;\n\t\t\tgoto out;\n\t\t}\n\t\twhile (php_stream_readdir(dir, &d)) {\n\t\t\tif ((mflen = snprintf(mfn, sizeof(mfn), \"%s/%s\", fn, d.d_name)) < 0) {\n\t\t\t\tfile_oomem(ms,\n\t\t\t\tstrlen(fn) + strlen(d.d_name) + 2);\n\t\t\t\terrs++;\n\t\t\t\tphp_stream_closedir(dir);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (stat(mfn, &st) == -1 || !S_ISREG(st.st_mode)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (files >= maxfiles) {\n\t\t\t\tsize_t mlen;\n\t\t\t\tmaxfiles = (maxfiles + 1) * 2;\n\t\t\t\tmlen = maxfiles * sizeof(*filearr);\n\t\t\t\tif ((filearr = CAST(char **,\n\t\t\t\t    erealloc(filearr, mlen))) == NULL) {\n\t\t\t\t\tfile_oomem(ms, mlen);\n\t\t\t\t\tefree(mfn);\n\t\t\t\t\tphp_stream_closedir(dir);\n\t\t\t\t\terrs++;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfilearr[files++] = estrndup(mfn, (mflen > sizeof(mfn) - 1)? sizeof(mfn) - 1: mflen);\n\t\t}\n\t\tphp_stream_closedir(dir);\n\t\tqsort(filearr, files, sizeof(*filearr), cmpstrp);\n\t\tfor (i = 0; i < files; i++) {\n\t\t\tload_1(ms, action, filearr[i], &errs, mset);\n\t\t\tefree(filearr[i]);\n\t\t}\n\t\tefree(filearr);\n\t} else\n\t\tload_1(ms, action, fn, &errs, mset);\n\tif (errs)\n\t\tgoto out;\n\n\tfor (j = 0; j < MAGIC_SETS; j++) {\n\t\t/* Set types of tests */\n\t\tfor (i = 0; i < mset[j].count; ) {\n\t\t\tif (mset[j].me[i].mp->cont_level != 0) {\n\t\t\t\ti++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ti = set_text_binary(ms, mset[j].me, mset[j].count, i);\n\t\t}\n\t\tqsort(mset[j].me, mset[j].count, sizeof(*mset[j].me),\n\t\t    apprentice_sort);\n\n\t\t/*\n\t\t * Make sure that any level 0 \"default\" line is last\n\t\t * (if one exists).\n\t\t */\n\t\tset_last_default(ms, mset[j].me, mset[j].count);\n\n\t\t/* coalesce per file arrays into a single one */\n\t\tif (coalesce_entries(ms, mset[j].me, mset[j].count,\n\t\t    &map->magic[j], &map->nmagic[j]) == -1) {\n\t\t\terrs++;\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tfor (j = 0; j < MAGIC_SETS; j++)\n\t\tmagic_entry_free(mset[j].me, mset[j].count);\n\n\tif (errs) {\n\t\tfor (j = 0; j < MAGIC_SETS; j++) {\n\t\t\tif (map->magic[j])\n\t\t\t\tefree(map->magic[j]);\n\t\t}\n\t\tefree(map);\n\t\treturn NULL;\n\t}\n\treturn map;\n}",
        "func": "magic_map *\napprentice_load(struct magic_set *ms, const char *fn, int action)\n{\n\tint errs = 0;\n\tuint32_t i, j;\n\tsize_t files = 0, maxfiles = 0;\n\tchar **filearr = NULL;\n\tstruct stat st;\n\tstruct magic_map *map;\n\tstruct magic_entry_set mset[MAGIC_SETS];\n\tphp_stream *dir;\n\tphp_stream_dirent d;\n \n\tTSRMLS_FETCH();\n\n\tmemset(mset, 0, sizeof(mset));\n\tms->flags |= MAGIC_CHECK;\t/* Enable checks for parsed files */\n\n\n\tif ((map = CAST(struct magic_map *, ecalloc(1, sizeof(*map)))) == NULL)\n\t{\n\t\tfile_oomem(ms, sizeof(*map));\n\t\treturn NULL;\n\t}\n\n\t/* print silly verbose header for USG compat. */\n\tif (action == FILE_CHECK)\n\t\t(void)fprintf(stderr, \"%s\\n\", usg_hdr);\n\n\t/* load directory or file */\n\t/* FIXME: Read file names and sort them to prevent\n\t   non-determinism. See Debian bug #488562. */\n\tif (php_sys_stat(fn, &st) == 0 && S_ISDIR(st.st_mode)) {\n\t\tint mflen;\n\t\tchar mfn[MAXPATHLEN];\n\n\t\tdir = php_stream_opendir((char *)fn, REPORT_ERRORS, NULL);\n\t\tif (!dir) {\n\t\t\terrs++;\n\t\t\tgoto out;\n\t\t}\n\t\twhile (php_stream_readdir(dir, &d)) {\n\t\t\tif ((mflen = snprintf(mfn, sizeof(mfn), \"%s/%s\", fn, d.d_name)) < 0) {\n\t\t\t\tfile_oomem(ms,\n\t\t\t\tstrlen(fn) + strlen(d.d_name) + 2);\n\t\t\t\terrs++;\n\t\t\t\tphp_stream_closedir(dir);\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (stat(mfn, &st) == -1 || !S_ISREG(st.st_mode)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (files >= maxfiles) {\n\t\t\t\tsize_t mlen;\n\t\t\t\tmaxfiles = (maxfiles + 1) * 2;\n\t\t\t\tmlen = maxfiles * sizeof(*filearr);\n\t\t\t\tif ((filearr = CAST(char **,\n\t\t\t\t    erealloc(filearr, mlen))) == NULL) {\n\t\t\t\t\tfile_oomem(ms, mlen);\n\t\t\t\t\tphp_stream_closedir(dir);\n\t\t\t\t\terrs++;\n\t\t\t\t\tgoto out;\n\t\t\t\t}\n\t\t\t}\n\t\t\tfilearr[files++] = estrndup(mfn, (mflen > sizeof(mfn) - 1)? sizeof(mfn) - 1: mflen);\n\t\t}\n\t\tphp_stream_closedir(dir);\n\t\tqsort(filearr, files, sizeof(*filearr), cmpstrp);\n\t\tfor (i = 0; i < files; i++) {\n\t\t\tload_1(ms, action, filearr[i], &errs, mset);\n\t\t\tefree(filearr[i]);\n\t\t}\n\t\tefree(filearr);\n\t} else\n\t\tload_1(ms, action, fn, &errs, mset);\n\tif (errs)\n\t\tgoto out;\n\n\tfor (j = 0; j < MAGIC_SETS; j++) {\n\t\t/* Set types of tests */\n\t\tfor (i = 0; i < mset[j].count; ) {\n\t\t\tif (mset[j].me[i].mp->cont_level != 0) {\n\t\t\t\ti++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ti = set_text_binary(ms, mset[j].me, mset[j].count, i);\n\t\t}\n\t\tqsort(mset[j].me, mset[j].count, sizeof(*mset[j].me),\n\t\t    apprentice_sort);\n\n\t\t/*\n\t\t * Make sure that any level 0 \"default\" line is last\n\t\t * (if one exists).\n\t\t */\n\t\tset_last_default(ms, mset[j].me, mset[j].count);\n\n\t\t/* coalesce per file arrays into a single one */\n\t\tif (coalesce_entries(ms, mset[j].me, mset[j].count,\n\t\t    &map->magic[j], &map->nmagic[j]) == -1) {\n\t\t\terrs++;\n\t\t\tgoto out;\n\t\t}\n\t}\n\nout:\n\tfor (j = 0; j < MAGIC_SETS; j++)\n\t\tmagic_entry_free(mset[j].me, mset[j].count);\n\n\tif (errs) {\n\t\tfor (j = 0; j < MAGIC_SETS; j++) {\n\t\t\tif (map->magic[j])\n\t\t\t\tefree(map->magic[j]);\n\t\t}\n\t\tefree(map);\n\t\treturn NULL;\n\t}\n\treturn map;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -57,7 +57,6 @@\n \t\t\t\tif ((filearr = CAST(char **,\n \t\t\t\t    erealloc(filearr, mlen))) == NULL) {\n \t\t\t\t\tfile_oomem(ms, mlen);\n-\t\t\t\t\tefree(mfn);\n \t\t\t\t\tphp_stream_closedir(dir);\n \t\t\t\t\terrs++;\n \t\t\t\t\tgoto out;",
        "diff_line_info": {
            "deleted_lines": [
                "\t\t\t\t\tefree(mfn);"
            ],
            "added_lines": []
        }
    },
    {
        "cve_id": "CVE-2015-6818",
        "func_name": "ffmpeg/decode_ihdr_chunk",
        "description": "The decode_ihdr_chunk function in libavcodec/pngdec.c in FFmpeg before 2.7.2 does not enforce uniqueness of the IHDR (aka image header) chunk in a PNG image, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via a crafted image with two or more of these chunks.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=47f4e2d8960ca756ca153ab8e3e93d80449b8c91",
        "commit_title": "",
        "commit_text": "avcodec/pngdec: Only allow one IHDR chunk  Multiple IHDR chunks are forbidden in PNG Fixes inconsistency and out of array accesses   ",
        "func_before": "static int decode_ihdr_chunk(AVCodecContext *avctx, PNGDecContext *s,\n                             uint32_t length)\n{\n    if (length != 13)\n        return AVERROR_INVALIDDATA;\n\n    if (s->state & PNG_IDAT) {\n        av_log(avctx, AV_LOG_ERROR, \"IHDR after IDAT\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->width  = bytestream2_get_be32(&s->gb);\n    s->height = bytestream2_get_be32(&s->gb);\n    if (av_image_check_size(s->width, s->height, 0, avctx)) {\n        s->width = s->height = 0;\n        av_log(avctx, AV_LOG_ERROR, \"Invalid image size\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (s->cur_w == 0 && s->cur_h == 0) {\n        // Only set cur_w/h if update_thread_context() has not set it\n        s->cur_w = s->width;\n        s->cur_h = s->height;\n    }\n    s->bit_depth        = bytestream2_get_byte(&s->gb);\n    s->color_type       = bytestream2_get_byte(&s->gb);\n    s->compression_type = bytestream2_get_byte(&s->gb);\n    s->filter_type      = bytestream2_get_byte(&s->gb);\n    s->interlace_type   = bytestream2_get_byte(&s->gb);\n    bytestream2_skip(&s->gb, 4); /* crc */\n    s->state |= PNG_IHDR;\n    if (avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(avctx, AV_LOG_DEBUG, \"width=%d height=%d depth=%d color_type=%d \"\n                \"compression_type=%d filter_type=%d interlace_type=%d\\n\",\n                s->width, s->height, s->bit_depth, s->color_type,\n                s->compression_type, s->filter_type, s->interlace_type);\n\n    return 0;\n}",
        "func": "static int decode_ihdr_chunk(AVCodecContext *avctx, PNGDecContext *s,\n                             uint32_t length)\n{\n    if (length != 13)\n        return AVERROR_INVALIDDATA;\n\n    if (s->state & PNG_IDAT) {\n        av_log(avctx, AV_LOG_ERROR, \"IHDR after IDAT\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (s->state & PNG_IHDR) {\n        av_log(avctx, AV_LOG_ERROR, \"Multiple IHDR\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->width  = bytestream2_get_be32(&s->gb);\n    s->height = bytestream2_get_be32(&s->gb);\n    if (av_image_check_size(s->width, s->height, 0, avctx)) {\n        s->width = s->height = 0;\n        av_log(avctx, AV_LOG_ERROR, \"Invalid image size\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    if (s->cur_w == 0 && s->cur_h == 0) {\n        // Only set cur_w/h if update_thread_context() has not set it\n        s->cur_w = s->width;\n        s->cur_h = s->height;\n    }\n    s->bit_depth        = bytestream2_get_byte(&s->gb);\n    s->color_type       = bytestream2_get_byte(&s->gb);\n    s->compression_type = bytestream2_get_byte(&s->gb);\n    s->filter_type      = bytestream2_get_byte(&s->gb);\n    s->interlace_type   = bytestream2_get_byte(&s->gb);\n    bytestream2_skip(&s->gb, 4); /* crc */\n    s->state |= PNG_IHDR;\n    if (avctx->debug & FF_DEBUG_PICT_INFO)\n        av_log(avctx, AV_LOG_DEBUG, \"width=%d height=%d depth=%d color_type=%d \"\n                \"compression_type=%d filter_type=%d interlace_type=%d\\n\",\n                s->width, s->height, s->bit_depth, s->color_type,\n                s->compression_type, s->filter_type, s->interlace_type);\n\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -6,6 +6,11 @@\n \n     if (s->state & PNG_IDAT) {\n         av_log(avctx, AV_LOG_ERROR, \"IHDR after IDAT\\n\");\n+        return AVERROR_INVALIDDATA;\n+    }\n+\n+    if (s->state & PNG_IHDR) {\n+        av_log(avctx, AV_LOG_ERROR, \"Multiple IHDR\\n\");\n         return AVERROR_INVALIDDATA;\n     }\n ",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "        return AVERROR_INVALIDDATA;",
                "    }",
                "",
                "    if (s->state & PNG_IHDR) {",
                "        av_log(avctx, AV_LOG_ERROR, \"Multiple IHDR\\n\");"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6822",
        "func_name": "ffmpeg/destroy_buffers",
        "description": "The destroy_buffers function in libavcodec/sanm.c in FFmpeg before 2.7.2 does not properly maintain height and width values in the video context, which allows remote attackers to cause a denial of service (segmentation violation and application crash) or possibly have unspecified other impact via crafted LucasArts Smush video data.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=39bbdebb1ed8eb9c9b0cd6db85afde6ba89d86e4",
        "commit_title": "",
        "commit_text": "avcodec/sanm: Reset sizes in destroy_buffers()  Fixes crash in 1288a2fe8e9ae6b00ca40e089d08ca65_signal_sigsegv_7ffff71426a7_354_accident.san with allocation limit 65536  ",
        "func_before": "static void destroy_buffers(SANMVideoContext *ctx)\n{\n    av_freep(&ctx->frm0);\n    av_freep(&ctx->frm1);\n    av_freep(&ctx->frm2);\n    av_freep(&ctx->stored_frame);\n    av_freep(&ctx->rle_buf);\n    ctx->frm0_size =\n    ctx->frm1_size =\n    ctx->frm2_size = 0;\n}",
        "func": "static void destroy_buffers(SANMVideoContext *ctx)\n{\n    av_freep(&ctx->frm0);\n    av_freep(&ctx->frm1);\n    av_freep(&ctx->frm2);\n    av_freep(&ctx->stored_frame);\n    av_freep(&ctx->rle_buf);\n    ctx->frm0_size =\n    ctx->frm1_size =\n    ctx->frm2_size = 0;\n    init_sizes(ctx, 0, 0);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -8,4 +8,5 @@\n     ctx->frm0_size =\n     ctx->frm1_size =\n     ctx->frm2_size = 0;\n+    init_sizes(ctx, 0, 0);\n }",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "    init_sizes(ctx, 0, 0);"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6823",
        "func_name": "ffmpeg/allocate_buffers",
        "description": "The allocate_buffers function in libavcodec/alac.c in FFmpeg before 2.7.2 does not initialize certain context data, which allows remote attackers to cause a denial of service (segmentation violation) or possibly have unspecified other impact via crafted Apple Lossless Audio Codec (ALAC) data.",
        "git_url": "http://git.videolan.org/?p=ffmpeg.git;a=commit;h=f7068bf277a37479aecde2832208d820682b35e6",
        "commit_title": "",
        "commit_text": "avcodec/alac: Clear pointers in allocate_buffers()   ",
        "func_before": "static int allocate_buffers(ALACContext *alac)\n{\n    int ch;\n    int buf_size = alac->max_samples_per_frame * sizeof(int32_t);\n\n    for (ch = 0; ch < FFMIN(alac->channels, 2); ch++) {\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->predict_error_buffer[ch],\n                         buf_size, buf_alloc_fail);\n\n        alac->direct_output = alac->sample_size > 16 && av_sample_fmt_is_planar(alac->avctx->sample_fmt);\n        if (!alac->direct_output) {\n            FF_ALLOC_OR_GOTO(alac->avctx, alac->output_samples_buffer[ch],\n                             buf_size, buf_alloc_fail);\n        }\n\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->extra_bits_buffer[ch],\n                         buf_size, buf_alloc_fail);\n    }\n    return 0;\nbuf_alloc_fail:\n    alac_decode_close(alac->avctx);\n    return AVERROR(ENOMEM);\n}",
        "func": "static int allocate_buffers(ALACContext *alac)\n{\n    int ch;\n    int buf_size = alac->max_samples_per_frame * sizeof(int32_t);\n\n    for (ch = 0; ch < 2; ch++) {\n        alac->predict_error_buffer[ch]  = NULL;\n        alac->output_samples_buffer[ch] = NULL;\n        alac->extra_bits_buffer[ch]     = NULL;\n    }\n\n    for (ch = 0; ch < FFMIN(alac->channels, 2); ch++) {\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->predict_error_buffer[ch],\n                         buf_size, buf_alloc_fail);\n\n        alac->direct_output = alac->sample_size > 16 && av_sample_fmt_is_planar(alac->avctx->sample_fmt);\n        if (!alac->direct_output) {\n            FF_ALLOC_OR_GOTO(alac->avctx, alac->output_samples_buffer[ch],\n                             buf_size, buf_alloc_fail);\n        }\n\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->extra_bits_buffer[ch],\n                         buf_size, buf_alloc_fail);\n    }\n    return 0;\nbuf_alloc_fail:\n    alac_decode_close(alac->avctx);\n    return AVERROR(ENOMEM);\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -2,6 +2,12 @@\n {\n     int ch;\n     int buf_size = alac->max_samples_per_frame * sizeof(int32_t);\n+\n+    for (ch = 0; ch < 2; ch++) {\n+        alac->predict_error_buffer[ch]  = NULL;\n+        alac->output_samples_buffer[ch] = NULL;\n+        alac->extra_bits_buffer[ch]     = NULL;\n+    }\n \n     for (ch = 0; ch < FFMIN(alac->channels, 2); ch++) {\n         FF_ALLOC_OR_GOTO(alac->avctx, alac->predict_error_buffer[ch],",
        "diff_line_info": {
            "deleted_lines": [],
            "added_lines": [
                "",
                "    for (ch = 0; ch < 2; ch++) {",
                "        alac->predict_error_buffer[ch]  = NULL;",
                "        alac->output_samples_buffer[ch] = NULL;",
                "        alac->extra_bits_buffer[ch]     = NULL;",
                "    }"
            ]
        }
    },
    {
        "cve_id": "CVE-2015-7311",
        "func_name": "xen-project/xen/libxl__build_device_model_args_new",
        "description": "libxl in Xen 4.1.x through 4.6.x does not properly handle the readonly flag on disks when using the qemu-xen device model, which allows local guest users to write to a read-only disk image.",
        "git_url": "https://github.com/xen-project/xen/commit/fa30003c13577b7ae4bbb46252ec1cbabd65c645",
        "commit_title": "libxl: handle read-only drives with qemu-xen",
        "commit_text": " The current libxl code doesn't deal with read-only drives at all.  Upstream QEMU and qemu-xen only support read-only cdrom drives: make sure to specify \"readonly=on\" for cdrom drives and return error in case the user requested a non-cdrom read-only drive.  This is XSA-142, discovered by Lin Liu (https://bugzilla.redhat.com/show_bug.cgi?id=1257893). ",
        "func_before": "static int libxl__build_device_model_args_new(libxl__gc *gc,\n                                        const char *dm, int guest_domid,\n                                        const libxl_domain_config *guest_config,\n                                        char ***args, char ***envs,\n                                        const libxl__domain_build_state *state,\n                                        int *dm_state_fd)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    const libxl_domain_create_info *c_info = &guest_config->c_info;\n    const libxl_domain_build_info *b_info = &guest_config->b_info;\n    const libxl_device_disk *disks = guest_config->disks;\n    const libxl_device_nic *nics = guest_config->nics;\n    const int num_disks = guest_config->num_disks;\n    const int num_nics = guest_config->num_nics;\n    const libxl_vnc_info *vnc = libxl__dm_vnc(guest_config);\n    const libxl_sdl_info *sdl = dm_sdl(guest_config);\n    const char *keymap = dm_keymap(guest_config);\n    char *machinearg;\n    flexarray_t *dm_args, *dm_envs;\n    int i, connection, devid;\n    uint64_t ram_size;\n    const char *path, *chardev;\n\n    dm_args = flexarray_make(gc, 16, 1);\n    dm_envs = flexarray_make(gc, 16, 1);\n\n    flexarray_vappend(dm_args, dm,\n                      \"-xen-domid\",\n                      libxl__sprintf(gc, \"%d\", guest_domid), NULL);\n\n    flexarray_append(dm_args, \"-chardev\");\n    flexarray_append(dm_args,\n                     libxl__sprintf(gc, \"socket,id=libxl-cmd,\"\n                                    \"path=%s/qmp-libxl-%d,server,nowait\",\n                                    libxl__run_dir_path(), guest_domid));\n\n    flexarray_append(dm_args, \"-no-shutdown\");\n    flexarray_append(dm_args, \"-mon\");\n    flexarray_append(dm_args, \"chardev=libxl-cmd,mode=control\");\n\n    flexarray_append(dm_args, \"-chardev\");\n    flexarray_append(dm_args,\n                     libxl__sprintf(gc, \"socket,id=libxenstat-cmd,\"\n                                    \"path=%s/qmp-libxenstat-%d,server,nowait\",\n                                    libxl__run_dir_path(), guest_domid));\n\n    flexarray_append(dm_args, \"-mon\");\n    flexarray_append(dm_args, \"chardev=libxenstat-cmd,mode=control\");\n\n    for (i = 0; i < guest_config->num_channels; i++) {\n        connection = guest_config->channels[i].connection;\n        devid = guest_config->channels[i].devid;\n        switch (connection) {\n            case LIBXL_CHANNEL_CONNECTION_PTY:\n                chardev = GCSPRINTF(\"pty,id=libxl-channel%d\", devid);\n                break;\n            case LIBXL_CHANNEL_CONNECTION_SOCKET:\n                path = guest_config->channels[i].u.socket.path;\n                chardev = GCSPRINTF(\"socket,id=libxl-channel%d,path=%s,\"\n                                    \"server,nowait\", devid, path);\n                break;\n            default:\n                /* We've forgotten to add the clause */\n                LOG(ERROR, \"%s: unknown channel connection %d\",\n                    __func__, connection);\n                return ERROR_INVAL;\n        }\n        flexarray_append(dm_args, \"-chardev\");\n        flexarray_append(dm_args, (void*)chardev);\n    }\n\n    /*\n     * Remove default devices created by qemu. Qemu will create only devices\n     * defined by xen, since the devices not defined by xen are not usable.\n     */\n    flexarray_append(dm_args, \"-nodefaults\");\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_PV) {\n        flexarray_append(dm_args, \"-xen-attach\");\n    }\n\n    if (c_info->name) {\n        flexarray_vappend(dm_args, \"-name\", c_info->name, NULL);\n    }\n\n    if (vnc) {\n        char *vncarg = NULL;\n\n        flexarray_append(dm_args, \"-vnc\");\n\n        /*\n         * If vnc->listen is present and contains a :, and\n         *  - vnc->display is 0, use vnc->listen\n         *  - vnc->display is non-zero, be confused\n         * If vnc->listen is present but doesn't, use vnc->listen:vnc->display.\n         * If vnc->listen is not present, use 127.0.0.1:vnc->display\n         * (Remembering that vnc->display already defaults to 0.)\n         */\n        if (vnc->listen) {\n            if (strchr(vnc->listen, ':') != NULL) {\n                if (vnc->display) {\n                    LOG(ERROR, \"vncdisplay set, vnclisten contains display\");\n                    return ERROR_INVAL;\n                }\n                vncarg = vnc->listen;\n            } else {\n                vncarg = libxl__sprintf(gc, \"%s:%d\", vnc->listen,\n                                        vnc->display);\n            }\n        } else\n            vncarg = libxl__sprintf(gc, \"127.0.0.1:%d\", vnc->display);\n\n        if (vnc->passwd && vnc->passwd[0]) {\n            vncarg = libxl__sprintf(gc, \"%s,password\", vncarg);\n        }\n\n        if (libxl_defbool_val(vnc->findunused)) {\n            /* This option asks to QEMU to try this number of port before to\n             * give up.  So QEMU will try ports between $display and $display +\n             * 99.  This option needs to be the last one of the vnc options. */\n            vncarg = libxl__sprintf(gc, \"%s,to=99\", vncarg);\n        }\n\n        flexarray_append(dm_args, vncarg);\n    } else\n        /*\n         * Ensure that by default no vnc server is created.\n         */\n        flexarray_append_pair(dm_args, \"-vnc\", \"none\");\n\n    /*\n     * Ensure that by default no display backend is created. Further\n     * options given below might then enable more.\n     */\n    flexarray_append_pair(dm_args, \"-display\", \"none\");\n\n    if (sdl) {\n        flexarray_append(dm_args, \"-sdl\");\n        if (sdl->display)\n            flexarray_append_pair(dm_envs, \"DISPLAY\", sdl->display);\n        if (sdl->xauthority)\n            flexarray_append_pair(dm_envs, \"XAUTHORITY\", sdl->xauthority);\n    }\n\n    if (keymap) {\n        flexarray_vappend(dm_args, \"-k\", keymap, NULL);\n    }\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        int ioemu_nics = 0;\n\n        if (b_info->kernel)\n            flexarray_vappend(dm_args, \"-kernel\", b_info->kernel, NULL);\n\n        if (b_info->ramdisk)\n            flexarray_vappend(dm_args, \"-initrd\", b_info->ramdisk, NULL);\n\n        if (b_info->cmdline)\n            flexarray_vappend(dm_args, \"-append\", b_info->cmdline, NULL);\n\n        if (b_info->u.hvm.serial || b_info->u.hvm.serial_list) {\n            if ( b_info->u.hvm.serial && b_info->u.hvm.serial_list )\n            {\n                LOG(ERROR, \"Both serial and serial_list set\");\n                return ERROR_INVAL;\n            }\n            if (b_info->u.hvm.serial) {\n                flexarray_vappend(dm_args,\n                                  \"-serial\", b_info->u.hvm.serial, NULL);\n            } else if (b_info->u.hvm.serial_list) {\n                char **p;\n                for (p = b_info->u.hvm.serial_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-serial\",\n                                      *p, NULL);\n                }\n            }\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.nographic) && (!sdl && !vnc)) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.spice.enable)) {\n            const libxl_spice_info *spice = &b_info->u.hvm.spice;\n            char *spiceoptions = dm_spice_options(gc, spice);\n            if (!spiceoptions)\n                return ERROR_INVAL;\n\n            flexarray_append(dm_args, \"-spice\");\n            flexarray_append(dm_args, spiceoptions);\n            if (libxl_defbool_val(b_info->u.hvm.spice.vdagent)) {\n                flexarray_vappend(dm_args, \"-device\", \"virtio-serial\",\n                    \"-chardev\", \"spicevmc,id=vdagent,name=vdagent\", \"-device\",\n                    \"virtserialport,chardev=vdagent,name=com.redhat.spice.0\",\n                    NULL);\n            }\n        }\n\n        switch (b_info->u.hvm.vga.kind) {\n        case LIBXL_VGA_INTERFACE_TYPE_STD:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"VGA,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_CIRRUS:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"cirrus-vga,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_NONE:\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_QXL:\n            /* QXL have 2 ram regions, ram and vram */\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"qxl-vga,vram_size_mb=%\"PRIu64\",ram_size_mb=%\"PRIu64,\n                (b_info->video_memkb/2/1024), (b_info->video_memkb/2/1024) ) );\n            break;\n        }\n\n        if (b_info->u.hvm.boot) {\n            flexarray_vappend(dm_args, \"-boot\",\n                    libxl__sprintf(gc, \"order=%s\", b_info->u.hvm.boot), NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.usb)\n            || b_info->u.hvm.usbdevice\n            || b_info->u.hvm.usbdevice_list) {\n            if ( b_info->u.hvm.usbdevice && b_info->u.hvm.usbdevice_list )\n            {\n                LOG(ERROR, \"Both usbdevice and usbdevice_list set\");\n                return ERROR_INVAL;\n            }\n            flexarray_append(dm_args, \"-usb\");\n            if (b_info->u.hvm.usbdevice) {\n                flexarray_vappend(dm_args,\n                                  \"-usbdevice\", b_info->u.hvm.usbdevice, NULL);\n            } else if (b_info->u.hvm.usbdevice_list) {\n                char **p;\n                for (p = b_info->u.hvm.usbdevice_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-usbdevice\",\n                                      *p, NULL);\n                }\n            }\n        } else if (b_info->u.hvm.usbversion) {\n            switch (b_info->u.hvm.usbversion) {\n            case 1:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"piix3-usb-uhci,id=usb\", NULL);\n                break;\n            case 2:\n                flexarray_append_pair(dm_args, \"-device\",\n                    \"ich9-usb-ehci1,id=usb,addr=0x1d.0x7,multifunction=on\");\n                for (i = 1; i < 4; i++)\n                    flexarray_append_pair(dm_args, \"-device\",\n                        GCSPRINTF(\"ich9-usb-uhci%d,masterbus=usb.0,\"\n                        \"firstport=%d,addr=0x1d.%#x,multifunction=on\",\n                        i, 2*(i-1), i-1));\n                break;\n            case 3:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"nec-usb-xhci,id=usb\", NULL);\n                break;\n            default:\n                LOG(ERROR, \"usbversion parameter is invalid, \"\n                    \"must be between 1 and 3\");\n                return ERROR_INVAL;\n            }\n            if (b_info->u.hvm.spice.usbredirection >= 0 &&\n                b_info->u.hvm.spice.usbredirection < 5) {\n                for (i = 1; i <= b_info->u.hvm.spice.usbredirection; i++)\n                    flexarray_vappend(dm_args, \"-chardev\", libxl__sprintf(gc,\n                        \"spicevmc,name=usbredir,id=usbrc%d\", i), \"-device\",\n                        libxl__sprintf(gc, \"usb-redir,chardev=usbrc%d,\"\n                        \"id=usbrc%d\", i, i), NULL);\n            } else {\n                LOG(ERROR, \"usbredirection parameter is invalid, \"\n                    \"it must be between 1 and 4\");\n                return ERROR_INVAL;\n            }\n        }\n        if (b_info->u.hvm.soundhw) {\n            flexarray_vappend(dm_args, \"-soundhw\", b_info->u.hvm.soundhw, NULL);\n        }\n        if (!libxl_defbool_val(b_info->u.hvm.acpi)) {\n            flexarray_append(dm_args, \"-no-acpi\");\n        }\n        if (b_info->max_vcpus > 1) {\n            flexarray_append(dm_args, \"-smp\");\n            if (b_info->avail_vcpus.size) {\n                int nr_set_cpus = 0;\n                nr_set_cpus = libxl_bitmap_count_set(&b_info->avail_vcpus);\n\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d,maxcpus=%d\",\n                                                         nr_set_cpus,\n                                                         b_info->max_vcpus));\n            } else\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d\",\n                                                         b_info->max_vcpus));\n        }\n        for (i = 0; i < num_nics; i++) {\n            if (nics[i].nictype == LIBXL_NIC_TYPE_VIF_IOEMU) {\n                char *smac = libxl__sprintf(gc,\n                                LIBXL_MAC_FMT, LIBXL_MAC_BYTES(nics[i].mac));\n                const char *ifname = libxl__device_nic_devname(gc,\n                                                guest_domid, nics[i].devid,\n                                                LIBXL_NIC_TYPE_VIF_IOEMU);\n                flexarray_append(dm_args, \"-device\");\n                flexarray_append(dm_args,\n                   libxl__sprintf(gc, \"%s,id=nic%d,netdev=net%d,mac=%s\",\n                                                nics[i].model, nics[i].devid,\n                                                nics[i].devid, smac));\n                flexarray_append(dm_args, \"-netdev\");\n                flexarray_append(dm_args, GCSPRINTF(\n                                          \"type=tap,id=net%d,ifname=%s,\"\n                                          \"script=%s,downscript=%s\",\n                                          nics[i].devid, ifname,\n                                          libxl_tapif_script(gc),\n                                          libxl_tapif_script(gc)));\n                ioemu_nics++;\n            }\n        }\n        /* If we have no emulated nics, tell qemu not to create any */\n        if ( ioemu_nics == 0 ) {\n            flexarray_append(dm_args, \"-net\");\n            flexarray_append(dm_args, \"none\");\n        }\n        if (libxl_defbool_val(b_info->u.hvm.gfx_passthru)) {\n            flexarray_append(dm_args, \"-gfx_passthru\");\n        }\n    } else {\n        if (!sdl && !vnc) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n    }\n\n    if (state->saved_state) {\n        /* This file descriptor is meant to be used by QEMU */\n        *dm_state_fd = open(state->saved_state, O_RDONLY);\n        flexarray_append(dm_args, \"-incoming\");\n        flexarray_append(dm_args, GCSPRINTF(\"fd:%d\",*dm_state_fd));\n    }\n    for (i = 0; b_info->extra && b_info->extra[i] != NULL; i++)\n        flexarray_append(dm_args, b_info->extra[i]);\n\n    flexarray_append(dm_args, \"-machine\");\n    switch (b_info->type) {\n    case LIBXL_DOMAIN_TYPE_PV:\n        flexarray_append(dm_args, \"xenpv\");\n        for (i = 0; b_info->extra_pv && b_info->extra_pv[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_pv[i]);\n        break;\n    case LIBXL_DOMAIN_TYPE_HVM:\n        if (!libxl_defbool_val(b_info->u.hvm.xen_platform_pci)) {\n            /* Switching here to the machine \"pc\" which does not add\n             * the xen-platform device instead of the default \"xenfv\" machine.\n             */\n            machinearg = libxl__sprintf(gc, \"pc,accel=xen\");\n        } else {\n            machinearg = libxl__sprintf(gc, \"xenfv\");\n        }\n        if (b_info->u.hvm.mmio_hole_memkb) {\n            uint64_t max_ram_below_4g = (1ULL << 32) -\n                (b_info->u.hvm.mmio_hole_memkb << 10);\n\n            if (max_ram_below_4g > HVM_BELOW_4G_MMIO_START) {\n                LOG(WARN, \"mmio_hole_memkb=%\"PRIu64\n                    \" invalid ignored.\\n\",\n                    b_info->u.hvm.mmio_hole_memkb);\n            } else {\n                machinearg = libxl__sprintf(gc, \"%s,max-ram-below-4g=%\"PRIu64,\n                                            machinearg, max_ram_below_4g);\n            }\n        }\n        flexarray_append(dm_args, machinearg);\n        for (i = 0; b_info->extra_hvm && b_info->extra_hvm[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_hvm[i]);\n        break;\n    default:\n        abort();\n    }\n\n    ram_size = libxl__sizekb_to_mb(b_info->max_memkb - b_info->video_memkb);\n    flexarray_append(dm_args, \"-m\");\n    flexarray_append(dm_args, libxl__sprintf(gc, \"%\"PRId64, ram_size));\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        if (b_info->u.hvm.hdtype == LIBXL_HDTYPE_AHCI)\n            flexarray_append_pair(dm_args, \"-device\", \"ahci,id=ahci0\");\n        for (i = 0; i < num_disks; i++) {\n            int disk, part;\n            int dev_number =\n                libxl__device_disk_dev_number(disks[i].vdev, &disk, &part);\n            const char *format = qemu_disk_format_string(disks[i].format);\n            char *drive;\n            const char *pdev_path;\n\n            if (dev_number == -1) {\n                LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                           \" disk number for %s\", disks[i].vdev);\n                continue;\n            }\n\n            if (disks[i].is_cdrom) {\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY)\n                    drive = libxl__sprintf\n                        (gc, \"if=ide,index=%d,media=cdrom,cache=writeback,id=ide-%i\",\n                         disk, dev_number);\n                else\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,media=cdrom,format=%s,cache=writeback,id=ide-%i\",\n                         disks[i].pdev_path, disk, format, dev_number);\n            } else {\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"cannot support\"\n                               \" empty disk format for %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (format == NULL) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                               \" disk image format %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (disks[i].backend == LIBXL_DISK_BACKEND_TAP) {\n                    format = qemu_disk_format_string(LIBXL_DISK_FORMAT_RAW);\n                    pdev_path = libxl__blktap_devpath(gc, disks[i].pdev_path,\n                                                      disks[i].format);\n                } else {\n                    pdev_path = disks[i].pdev_path;\n                }\n\n                /*\n                 * Explicit sd disks are passed through as is.\n                 *\n                 * For other disks we translate devices 0..3 into\n                 * hd[a-d] and ignore the rest.\n                 */\n                if (strncmp(disks[i].vdev, \"sd\", 2) == 0)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=scsi,bus=0,unit=%d,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else if (disk < 6 && b_info->u.hvm.hdtype == LIBXL_HDTYPE_AHCI) {\n                    flexarray_vappend(dm_args, \"-drive\",\n                        GCSPRINTF(\"file=%s,if=none,id=ahcidisk-%d,format=%s,cache=writeback\",\n                        pdev_path, disk, format),\n                        \"-device\", GCSPRINTF(\"ide-hd,bus=ahci0.%d,unit=0,drive=ahcidisk-%d\",\n                        disk, disk), NULL);\n                    continue;\n                } else if (disk < 4)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,media=disk,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else\n                    continue; /* Do not emulate this disk */\n            }\n\n            flexarray_append(dm_args, \"-drive\");\n            flexarray_append(dm_args, drive);\n        }\n\n        switch (b_info->u.hvm.vendor_device) {\n        case LIBXL_VENDOR_DEVICE_XENSERVER:\n            flexarray_append(dm_args, \"-device\");\n            flexarray_append(dm_args, \"xen-pvdevice,device-id=0xc000\");\n            break;\n        default:\n            break;\n        }\n    }\n    flexarray_append(dm_args, NULL);\n    *args = (char **) flexarray_contents(dm_args);\n    flexarray_append(dm_envs, NULL);\n    if (envs)\n        *envs = (char **) flexarray_contents(dm_envs);\n    return 0;\n}",
        "func": "static int libxl__build_device_model_args_new(libxl__gc *gc,\n                                        const char *dm, int guest_domid,\n                                        const libxl_domain_config *guest_config,\n                                        char ***args, char ***envs,\n                                        const libxl__domain_build_state *state,\n                                        int *dm_state_fd)\n{\n    libxl_ctx *ctx = libxl__gc_owner(gc);\n    const libxl_domain_create_info *c_info = &guest_config->c_info;\n    const libxl_domain_build_info *b_info = &guest_config->b_info;\n    const libxl_device_disk *disks = guest_config->disks;\n    const libxl_device_nic *nics = guest_config->nics;\n    const int num_disks = guest_config->num_disks;\n    const int num_nics = guest_config->num_nics;\n    const libxl_vnc_info *vnc = libxl__dm_vnc(guest_config);\n    const libxl_sdl_info *sdl = dm_sdl(guest_config);\n    const char *keymap = dm_keymap(guest_config);\n    char *machinearg;\n    flexarray_t *dm_args, *dm_envs;\n    int i, connection, devid;\n    uint64_t ram_size;\n    const char *path, *chardev;\n\n    dm_args = flexarray_make(gc, 16, 1);\n    dm_envs = flexarray_make(gc, 16, 1);\n\n    flexarray_vappend(dm_args, dm,\n                      \"-xen-domid\",\n                      libxl__sprintf(gc, \"%d\", guest_domid), NULL);\n\n    flexarray_append(dm_args, \"-chardev\");\n    flexarray_append(dm_args,\n                     libxl__sprintf(gc, \"socket,id=libxl-cmd,\"\n                                    \"path=%s/qmp-libxl-%d,server,nowait\",\n                                    libxl__run_dir_path(), guest_domid));\n\n    flexarray_append(dm_args, \"-no-shutdown\");\n    flexarray_append(dm_args, \"-mon\");\n    flexarray_append(dm_args, \"chardev=libxl-cmd,mode=control\");\n\n    flexarray_append(dm_args, \"-chardev\");\n    flexarray_append(dm_args,\n                     libxl__sprintf(gc, \"socket,id=libxenstat-cmd,\"\n                                    \"path=%s/qmp-libxenstat-%d,server,nowait\",\n                                    libxl__run_dir_path(), guest_domid));\n\n    flexarray_append(dm_args, \"-mon\");\n    flexarray_append(dm_args, \"chardev=libxenstat-cmd,mode=control\");\n\n    for (i = 0; i < guest_config->num_channels; i++) {\n        connection = guest_config->channels[i].connection;\n        devid = guest_config->channels[i].devid;\n        switch (connection) {\n            case LIBXL_CHANNEL_CONNECTION_PTY:\n                chardev = GCSPRINTF(\"pty,id=libxl-channel%d\", devid);\n                break;\n            case LIBXL_CHANNEL_CONNECTION_SOCKET:\n                path = guest_config->channels[i].u.socket.path;\n                chardev = GCSPRINTF(\"socket,id=libxl-channel%d,path=%s,\"\n                                    \"server,nowait\", devid, path);\n                break;\n            default:\n                /* We've forgotten to add the clause */\n                LOG(ERROR, \"%s: unknown channel connection %d\",\n                    __func__, connection);\n                return ERROR_INVAL;\n        }\n        flexarray_append(dm_args, \"-chardev\");\n        flexarray_append(dm_args, (void*)chardev);\n    }\n\n    /*\n     * Remove default devices created by qemu. Qemu will create only devices\n     * defined by xen, since the devices not defined by xen are not usable.\n     */\n    flexarray_append(dm_args, \"-nodefaults\");\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_PV) {\n        flexarray_append(dm_args, \"-xen-attach\");\n    }\n\n    if (c_info->name) {\n        flexarray_vappend(dm_args, \"-name\", c_info->name, NULL);\n    }\n\n    if (vnc) {\n        char *vncarg = NULL;\n\n        flexarray_append(dm_args, \"-vnc\");\n\n        /*\n         * If vnc->listen is present and contains a :, and\n         *  - vnc->display is 0, use vnc->listen\n         *  - vnc->display is non-zero, be confused\n         * If vnc->listen is present but doesn't, use vnc->listen:vnc->display.\n         * If vnc->listen is not present, use 127.0.0.1:vnc->display\n         * (Remembering that vnc->display already defaults to 0.)\n         */\n        if (vnc->listen) {\n            if (strchr(vnc->listen, ':') != NULL) {\n                if (vnc->display) {\n                    LOG(ERROR, \"vncdisplay set, vnclisten contains display\");\n                    return ERROR_INVAL;\n                }\n                vncarg = vnc->listen;\n            } else {\n                vncarg = libxl__sprintf(gc, \"%s:%d\", vnc->listen,\n                                        vnc->display);\n            }\n        } else\n            vncarg = libxl__sprintf(gc, \"127.0.0.1:%d\", vnc->display);\n\n        if (vnc->passwd && vnc->passwd[0]) {\n            vncarg = libxl__sprintf(gc, \"%s,password\", vncarg);\n        }\n\n        if (libxl_defbool_val(vnc->findunused)) {\n            /* This option asks to QEMU to try this number of port before to\n             * give up.  So QEMU will try ports between $display and $display +\n             * 99.  This option needs to be the last one of the vnc options. */\n            vncarg = libxl__sprintf(gc, \"%s,to=99\", vncarg);\n        }\n\n        flexarray_append(dm_args, vncarg);\n    } else\n        /*\n         * Ensure that by default no vnc server is created.\n         */\n        flexarray_append_pair(dm_args, \"-vnc\", \"none\");\n\n    /*\n     * Ensure that by default no display backend is created. Further\n     * options given below might then enable more.\n     */\n    flexarray_append_pair(dm_args, \"-display\", \"none\");\n\n    if (sdl) {\n        flexarray_append(dm_args, \"-sdl\");\n        if (sdl->display)\n            flexarray_append_pair(dm_envs, \"DISPLAY\", sdl->display);\n        if (sdl->xauthority)\n            flexarray_append_pair(dm_envs, \"XAUTHORITY\", sdl->xauthority);\n    }\n\n    if (keymap) {\n        flexarray_vappend(dm_args, \"-k\", keymap, NULL);\n    }\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        int ioemu_nics = 0;\n\n        if (b_info->kernel)\n            flexarray_vappend(dm_args, \"-kernel\", b_info->kernel, NULL);\n\n        if (b_info->ramdisk)\n            flexarray_vappend(dm_args, \"-initrd\", b_info->ramdisk, NULL);\n\n        if (b_info->cmdline)\n            flexarray_vappend(dm_args, \"-append\", b_info->cmdline, NULL);\n\n        if (b_info->u.hvm.serial || b_info->u.hvm.serial_list) {\n            if ( b_info->u.hvm.serial && b_info->u.hvm.serial_list )\n            {\n                LOG(ERROR, \"Both serial and serial_list set\");\n                return ERROR_INVAL;\n            }\n            if (b_info->u.hvm.serial) {\n                flexarray_vappend(dm_args,\n                                  \"-serial\", b_info->u.hvm.serial, NULL);\n            } else if (b_info->u.hvm.serial_list) {\n                char **p;\n                for (p = b_info->u.hvm.serial_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-serial\",\n                                      *p, NULL);\n                }\n            }\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.nographic) && (!sdl && !vnc)) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n\n        if (libxl_defbool_val(b_info->u.hvm.spice.enable)) {\n            const libxl_spice_info *spice = &b_info->u.hvm.spice;\n            char *spiceoptions = dm_spice_options(gc, spice);\n            if (!spiceoptions)\n                return ERROR_INVAL;\n\n            flexarray_append(dm_args, \"-spice\");\n            flexarray_append(dm_args, spiceoptions);\n            if (libxl_defbool_val(b_info->u.hvm.spice.vdagent)) {\n                flexarray_vappend(dm_args, \"-device\", \"virtio-serial\",\n                    \"-chardev\", \"spicevmc,id=vdagent,name=vdagent\", \"-device\",\n                    \"virtserialport,chardev=vdagent,name=com.redhat.spice.0\",\n                    NULL);\n            }\n        }\n\n        switch (b_info->u.hvm.vga.kind) {\n        case LIBXL_VGA_INTERFACE_TYPE_STD:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"VGA,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_CIRRUS:\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"cirrus-vga,vgamem_mb=%d\",\n                libxl__sizekb_to_mb(b_info->video_memkb)));\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_NONE:\n            break;\n        case LIBXL_VGA_INTERFACE_TYPE_QXL:\n            /* QXL have 2 ram regions, ram and vram */\n            flexarray_append_pair(dm_args, \"-device\",\n                GCSPRINTF(\"qxl-vga,vram_size_mb=%\"PRIu64\",ram_size_mb=%\"PRIu64,\n                (b_info->video_memkb/2/1024), (b_info->video_memkb/2/1024) ) );\n            break;\n        }\n\n        if (b_info->u.hvm.boot) {\n            flexarray_vappend(dm_args, \"-boot\",\n                    libxl__sprintf(gc, \"order=%s\", b_info->u.hvm.boot), NULL);\n        }\n        if (libxl_defbool_val(b_info->u.hvm.usb)\n            || b_info->u.hvm.usbdevice\n            || b_info->u.hvm.usbdevice_list) {\n            if ( b_info->u.hvm.usbdevice && b_info->u.hvm.usbdevice_list )\n            {\n                LOG(ERROR, \"Both usbdevice and usbdevice_list set\");\n                return ERROR_INVAL;\n            }\n            flexarray_append(dm_args, \"-usb\");\n            if (b_info->u.hvm.usbdevice) {\n                flexarray_vappend(dm_args,\n                                  \"-usbdevice\", b_info->u.hvm.usbdevice, NULL);\n            } else if (b_info->u.hvm.usbdevice_list) {\n                char **p;\n                for (p = b_info->u.hvm.usbdevice_list;\n                     *p;\n                     p++) {\n                    flexarray_vappend(dm_args,\n                                      \"-usbdevice\",\n                                      *p, NULL);\n                }\n            }\n        } else if (b_info->u.hvm.usbversion) {\n            switch (b_info->u.hvm.usbversion) {\n            case 1:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"piix3-usb-uhci,id=usb\", NULL);\n                break;\n            case 2:\n                flexarray_append_pair(dm_args, \"-device\",\n                    \"ich9-usb-ehci1,id=usb,addr=0x1d.0x7,multifunction=on\");\n                for (i = 1; i < 4; i++)\n                    flexarray_append_pair(dm_args, \"-device\",\n                        GCSPRINTF(\"ich9-usb-uhci%d,masterbus=usb.0,\"\n                        \"firstport=%d,addr=0x1d.%#x,multifunction=on\",\n                        i, 2*(i-1), i-1));\n                break;\n            case 3:\n                flexarray_vappend(dm_args,\n                    \"-device\", \"nec-usb-xhci,id=usb\", NULL);\n                break;\n            default:\n                LOG(ERROR, \"usbversion parameter is invalid, \"\n                    \"must be between 1 and 3\");\n                return ERROR_INVAL;\n            }\n            if (b_info->u.hvm.spice.usbredirection >= 0 &&\n                b_info->u.hvm.spice.usbredirection < 5) {\n                for (i = 1; i <= b_info->u.hvm.spice.usbredirection; i++)\n                    flexarray_vappend(dm_args, \"-chardev\", libxl__sprintf(gc,\n                        \"spicevmc,name=usbredir,id=usbrc%d\", i), \"-device\",\n                        libxl__sprintf(gc, \"usb-redir,chardev=usbrc%d,\"\n                        \"id=usbrc%d\", i, i), NULL);\n            } else {\n                LOG(ERROR, \"usbredirection parameter is invalid, \"\n                    \"it must be between 1 and 4\");\n                return ERROR_INVAL;\n            }\n        }\n        if (b_info->u.hvm.soundhw) {\n            flexarray_vappend(dm_args, \"-soundhw\", b_info->u.hvm.soundhw, NULL);\n        }\n        if (!libxl_defbool_val(b_info->u.hvm.acpi)) {\n            flexarray_append(dm_args, \"-no-acpi\");\n        }\n        if (b_info->max_vcpus > 1) {\n            flexarray_append(dm_args, \"-smp\");\n            if (b_info->avail_vcpus.size) {\n                int nr_set_cpus = 0;\n                nr_set_cpus = libxl_bitmap_count_set(&b_info->avail_vcpus);\n\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d,maxcpus=%d\",\n                                                         nr_set_cpus,\n                                                         b_info->max_vcpus));\n            } else\n                flexarray_append(dm_args, libxl__sprintf(gc, \"%d\",\n                                                         b_info->max_vcpus));\n        }\n        for (i = 0; i < num_nics; i++) {\n            if (nics[i].nictype == LIBXL_NIC_TYPE_VIF_IOEMU) {\n                char *smac = libxl__sprintf(gc,\n                                LIBXL_MAC_FMT, LIBXL_MAC_BYTES(nics[i].mac));\n                const char *ifname = libxl__device_nic_devname(gc,\n                                                guest_domid, nics[i].devid,\n                                                LIBXL_NIC_TYPE_VIF_IOEMU);\n                flexarray_append(dm_args, \"-device\");\n                flexarray_append(dm_args,\n                   libxl__sprintf(gc, \"%s,id=nic%d,netdev=net%d,mac=%s\",\n                                                nics[i].model, nics[i].devid,\n                                                nics[i].devid, smac));\n                flexarray_append(dm_args, \"-netdev\");\n                flexarray_append(dm_args, GCSPRINTF(\n                                          \"type=tap,id=net%d,ifname=%s,\"\n                                          \"script=%s,downscript=%s\",\n                                          nics[i].devid, ifname,\n                                          libxl_tapif_script(gc),\n                                          libxl_tapif_script(gc)));\n                ioemu_nics++;\n            }\n        }\n        /* If we have no emulated nics, tell qemu not to create any */\n        if ( ioemu_nics == 0 ) {\n            flexarray_append(dm_args, \"-net\");\n            flexarray_append(dm_args, \"none\");\n        }\n        if (libxl_defbool_val(b_info->u.hvm.gfx_passthru)) {\n            flexarray_append(dm_args, \"-gfx_passthru\");\n        }\n    } else {\n        if (!sdl && !vnc) {\n            flexarray_append(dm_args, \"-nographic\");\n        }\n    }\n\n    if (state->saved_state) {\n        /* This file descriptor is meant to be used by QEMU */\n        *dm_state_fd = open(state->saved_state, O_RDONLY);\n        flexarray_append(dm_args, \"-incoming\");\n        flexarray_append(dm_args, GCSPRINTF(\"fd:%d\",*dm_state_fd));\n    }\n    for (i = 0; b_info->extra && b_info->extra[i] != NULL; i++)\n        flexarray_append(dm_args, b_info->extra[i]);\n\n    flexarray_append(dm_args, \"-machine\");\n    switch (b_info->type) {\n    case LIBXL_DOMAIN_TYPE_PV:\n        flexarray_append(dm_args, \"xenpv\");\n        for (i = 0; b_info->extra_pv && b_info->extra_pv[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_pv[i]);\n        break;\n    case LIBXL_DOMAIN_TYPE_HVM:\n        if (!libxl_defbool_val(b_info->u.hvm.xen_platform_pci)) {\n            /* Switching here to the machine \"pc\" which does not add\n             * the xen-platform device instead of the default \"xenfv\" machine.\n             */\n            machinearg = libxl__sprintf(gc, \"pc,accel=xen\");\n        } else {\n            machinearg = libxl__sprintf(gc, \"xenfv\");\n        }\n        if (b_info->u.hvm.mmio_hole_memkb) {\n            uint64_t max_ram_below_4g = (1ULL << 32) -\n                (b_info->u.hvm.mmio_hole_memkb << 10);\n\n            if (max_ram_below_4g > HVM_BELOW_4G_MMIO_START) {\n                LOG(WARN, \"mmio_hole_memkb=%\"PRIu64\n                    \" invalid ignored.\\n\",\n                    b_info->u.hvm.mmio_hole_memkb);\n            } else {\n                machinearg = libxl__sprintf(gc, \"%s,max-ram-below-4g=%\"PRIu64,\n                                            machinearg, max_ram_below_4g);\n            }\n        }\n        flexarray_append(dm_args, machinearg);\n        for (i = 0; b_info->extra_hvm && b_info->extra_hvm[i] != NULL; i++)\n            flexarray_append(dm_args, b_info->extra_hvm[i]);\n        break;\n    default:\n        abort();\n    }\n\n    ram_size = libxl__sizekb_to_mb(b_info->max_memkb - b_info->video_memkb);\n    flexarray_append(dm_args, \"-m\");\n    flexarray_append(dm_args, libxl__sprintf(gc, \"%\"PRId64, ram_size));\n\n    if (b_info->type == LIBXL_DOMAIN_TYPE_HVM) {\n        if (b_info->u.hvm.hdtype == LIBXL_HDTYPE_AHCI)\n            flexarray_append_pair(dm_args, \"-device\", \"ahci,id=ahci0\");\n        for (i = 0; i < num_disks; i++) {\n            int disk, part;\n            int dev_number =\n                libxl__device_disk_dev_number(disks[i].vdev, &disk, &part);\n            const char *format = qemu_disk_format_string(disks[i].format);\n            char *drive;\n            const char *pdev_path;\n\n            if (dev_number == -1) {\n                LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                           \" disk number for %s\", disks[i].vdev);\n                continue;\n            }\n\n            if (disks[i].is_cdrom) {\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY)\n                    drive = libxl__sprintf\n                        (gc, \"if=ide,index=%d,readonly=%s,media=cdrom,cache=writeback,id=ide-%i\",\n                         disk, disks[i].readwrite ? \"off\" : \"on\", dev_number);\n                else\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,readonly=%s,media=cdrom,format=%s,cache=writeback,id=ide-%i\",\n                         disks[i].pdev_path, disk, disks[i].readwrite ? \"off\" : \"on\", format, dev_number);\n            } else {\n                if (!disks[i].readwrite) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_ERROR, \"qemu-xen doesn't support read-only disk drivers\");\n                    return ERROR_INVAL;\n                }\n\n                if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"cannot support\"\n                               \" empty disk format for %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (format == NULL) {\n                    LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"unable to determine\"\n                               \" disk image format %s\", disks[i].vdev);\n                    continue;\n                }\n\n                if (disks[i].backend == LIBXL_DISK_BACKEND_TAP) {\n                    format = qemu_disk_format_string(LIBXL_DISK_FORMAT_RAW);\n                    pdev_path = libxl__blktap_devpath(gc, disks[i].pdev_path,\n                                                      disks[i].format);\n                } else {\n                    pdev_path = disks[i].pdev_path;\n                }\n\n                /*\n                 * Explicit sd disks are passed through as is.\n                 *\n                 * For other disks we translate devices 0..3 into\n                 * hd[a-d] and ignore the rest.\n                 */\n                if (strncmp(disks[i].vdev, \"sd\", 2) == 0)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=scsi,bus=0,unit=%d,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else if (disk < 6 && b_info->u.hvm.hdtype == LIBXL_HDTYPE_AHCI) {\n                    flexarray_vappend(dm_args, \"-drive\",\n                        GCSPRINTF(\"file=%s,if=none,id=ahcidisk-%d,format=%s,cache=writeback\",\n                        pdev_path, disk, format),\n                        \"-device\", GCSPRINTF(\"ide-hd,bus=ahci0.%d,unit=0,drive=ahcidisk-%d\",\n                        disk, disk), NULL);\n                    continue;\n                } else if (disk < 4)\n                    drive = libxl__sprintf\n                        (gc, \"file=%s,if=ide,index=%d,media=disk,format=%s,cache=writeback\",\n                         pdev_path, disk, format);\n                else\n                    continue; /* Do not emulate this disk */\n            }\n\n            flexarray_append(dm_args, \"-drive\");\n            flexarray_append(dm_args, drive);\n        }\n\n        switch (b_info->u.hvm.vendor_device) {\n        case LIBXL_VENDOR_DEVICE_XENSERVER:\n            flexarray_append(dm_args, \"-device\");\n            flexarray_append(dm_args, \"xen-pvdevice,device-id=0xc000\");\n            break;\n        default:\n            break;\n        }\n    }\n    flexarray_append(dm_args, NULL);\n    *args = (char **) flexarray_contents(dm_args);\n    flexarray_append(dm_envs, NULL);\n    if (envs)\n        *envs = (char **) flexarray_contents(dm_envs);\n    return 0;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -408,13 +408,18 @@\n             if (disks[i].is_cdrom) {\n                 if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY)\n                     drive = libxl__sprintf\n-                        (gc, \"if=ide,index=%d,media=cdrom,cache=writeback,id=ide-%i\",\n-                         disk, dev_number);\n+                        (gc, \"if=ide,index=%d,readonly=%s,media=cdrom,cache=writeback,id=ide-%i\",\n+                         disk, disks[i].readwrite ? \"off\" : \"on\", dev_number);\n                 else\n                     drive = libxl__sprintf\n-                        (gc, \"file=%s,if=ide,index=%d,media=cdrom,format=%s,cache=writeback,id=ide-%i\",\n-                         disks[i].pdev_path, disk, format, dev_number);\n+                        (gc, \"file=%s,if=ide,index=%d,readonly=%s,media=cdrom,format=%s,cache=writeback,id=ide-%i\",\n+                         disks[i].pdev_path, disk, disks[i].readwrite ? \"off\" : \"on\", format, dev_number);\n             } else {\n+                if (!disks[i].readwrite) {\n+                    LIBXL__LOG(ctx, LIBXL__LOG_ERROR, \"qemu-xen doesn't support read-only disk drivers\");\n+                    return ERROR_INVAL;\n+                }\n+\n                 if (disks[i].format == LIBXL_DISK_FORMAT_EMPTY) {\n                     LIBXL__LOG(ctx, LIBXL__LOG_WARNING, \"cannot support\"\n                                \" empty disk format for %s\", disks[i].vdev);",
        "diff_line_info": {
            "deleted_lines": [
                "                        (gc, \"if=ide,index=%d,media=cdrom,cache=writeback,id=ide-%i\",",
                "                         disk, dev_number);",
                "                        (gc, \"file=%s,if=ide,index=%d,media=cdrom,format=%s,cache=writeback,id=ide-%i\",",
                "                         disks[i].pdev_path, disk, format, dev_number);"
            ],
            "added_lines": [
                "                        (gc, \"if=ide,index=%d,readonly=%s,media=cdrom,cache=writeback,id=ide-%i\",",
                "                         disk, disks[i].readwrite ? \"off\" : \"on\", dev_number);",
                "                        (gc, \"file=%s,if=ide,index=%d,readonly=%s,media=cdrom,format=%s,cache=writeback,id=ide-%i\",",
                "                         disks[i].pdev_path, disk, disks[i].readwrite ? \"off\" : \"on\", format, dev_number);",
                "                if (!disks[i].readwrite) {",
                "                    LIBXL__LOG(ctx, LIBXL__LOG_ERROR, \"qemu-xen doesn't support read-only disk drivers\");",
                "                    return ERROR_INVAL;",
                "                }",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-6758",
        "func_name": "pdfium/CPDF_Document::GetPage",
        "description": "The CPDF_Document::GetPage function in fpdfapi/fpdf_parser/fpdf_parser_document.cpp in PDFium, as used in Google Chrome before 46.0.2490.71, does not properly perform a cast of a dictionary object, which allows remote attackers to cause a denial of service or possibly have unspecified other impact via a crafted PDF document.",
        "git_url": "https://pdfium.googlesource.com/pdfium/+/640c395fa9b76552383ccd0c5f4668ea698089f6",
        "commit_title": "Turn a failing assert into an actual check.",
        "commit_text": "  ",
        "func_before": "CPDF_Dictionary* CPDF_Document::GetPage(int iPage) {\n  if (iPage < 0 || iPage >= m_PageList.GetSize()) {\n    return NULL;\n  }\n  if (m_bLinearized && (iPage == (int)m_dwFirstPageNo)) {\n    CPDF_Object* pObj = GetIndirectObject(m_dwFirstPageObjNum);\n    if (pObj && pObj->GetType() == PDFOBJ_DICTIONARY) {\n      return (CPDF_Dictionary*)pObj;\n    }\n  }\n  int objnum = m_PageList.GetAt(iPage);\n  if (objnum) {\n    CPDF_Object* pObj = GetIndirectObject(objnum);\n    ASSERT(pObj->GetType() == PDFOBJ_DICTIONARY);\n    return (CPDF_Dictionary*)pObj;\n  }\n  CPDF_Dictionary* pRoot = GetRoot();\n  if (pRoot == NULL) {\n    return NULL;\n  }\n  CPDF_Dictionary* pPages = pRoot->GetDict(FX_BSTRC(\"Pages\"));\n  if (pPages == NULL) {\n    return NULL;\n  }\n  CPDF_Dictionary* pPage = _FindPDFPage(pPages, iPage, iPage, 0);\n  if (pPage == NULL) {\n    return NULL;\n  }\n  m_PageList.SetAt(iPage, pPage->GetObjNum());\n  return pPage;\n}",
        "func": "CPDF_Dictionary* CPDF_Document::GetPage(int iPage) {\n  if (iPage < 0 || iPage >= m_PageList.GetSize())\n    return nullptr;\n\n  if (m_bLinearized && (iPage == (int)m_dwFirstPageNo)) {\n    CPDF_Object* pObj = GetIndirectObject(m_dwFirstPageObjNum);\n    if (pObj && pObj->GetType() == PDFOBJ_DICTIONARY) {\n      return static_cast<CPDF_Dictionary*>(pObj);\n    }\n  }\n\n  int objnum = m_PageList.GetAt(iPage);\n  if (objnum) {\n    CPDF_Object* pObj = GetIndirectObject(objnum);\n    if (pObj && pObj->GetType() == PDFOBJ_DICTIONARY) {\n      return static_cast<CPDF_Dictionary*>(pObj);\n    }\n  }\n\n  CPDF_Dictionary* pRoot = GetRoot();\n  if (!pRoot)\n    return nullptr;\n\n  CPDF_Dictionary* pPages = pRoot->GetDict(FX_BSTRC(\"Pages\"));\n  if (!pPages)\n    return nullptr;\n\n  CPDF_Dictionary* pPage = _FindPDFPage(pPages, iPage, iPage, 0);\n  if (!pPage)\n    return nullptr;\n\n  m_PageList.SetAt(iPage, pPage->GetObjNum());\n  return pPage;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -1,31 +1,34 @@\n CPDF_Dictionary* CPDF_Document::GetPage(int iPage) {\n-  if (iPage < 0 || iPage >= m_PageList.GetSize()) {\n-    return NULL;\n-  }\n+  if (iPage < 0 || iPage >= m_PageList.GetSize())\n+    return nullptr;\n+\n   if (m_bLinearized && (iPage == (int)m_dwFirstPageNo)) {\n     CPDF_Object* pObj = GetIndirectObject(m_dwFirstPageObjNum);\n     if (pObj && pObj->GetType() == PDFOBJ_DICTIONARY) {\n-      return (CPDF_Dictionary*)pObj;\n+      return static_cast<CPDF_Dictionary*>(pObj);\n     }\n   }\n+\n   int objnum = m_PageList.GetAt(iPage);\n   if (objnum) {\n     CPDF_Object* pObj = GetIndirectObject(objnum);\n-    ASSERT(pObj->GetType() == PDFOBJ_DICTIONARY);\n-    return (CPDF_Dictionary*)pObj;\n+    if (pObj && pObj->GetType() == PDFOBJ_DICTIONARY) {\n+      return static_cast<CPDF_Dictionary*>(pObj);\n+    }\n   }\n+\n   CPDF_Dictionary* pRoot = GetRoot();\n-  if (pRoot == NULL) {\n-    return NULL;\n-  }\n+  if (!pRoot)\n+    return nullptr;\n+\n   CPDF_Dictionary* pPages = pRoot->GetDict(FX_BSTRC(\"Pages\"));\n-  if (pPages == NULL) {\n-    return NULL;\n-  }\n+  if (!pPages)\n+    return nullptr;\n+\n   CPDF_Dictionary* pPage = _FindPDFPage(pPages, iPage, iPage, 0);\n-  if (pPage == NULL) {\n-    return NULL;\n-  }\n+  if (!pPage)\n+    return nullptr;\n+\n   m_PageList.SetAt(iPage, pPage->GetObjNum());\n   return pPage;\n }",
        "diff_line_info": {
            "deleted_lines": [
                "  if (iPage < 0 || iPage >= m_PageList.GetSize()) {",
                "    return NULL;",
                "  }",
                "      return (CPDF_Dictionary*)pObj;",
                "    ASSERT(pObj->GetType() == PDFOBJ_DICTIONARY);",
                "    return (CPDF_Dictionary*)pObj;",
                "  if (pRoot == NULL) {",
                "    return NULL;",
                "  }",
                "  if (pPages == NULL) {",
                "    return NULL;",
                "  }",
                "  if (pPage == NULL) {",
                "    return NULL;",
                "  }"
            ],
            "added_lines": [
                "  if (iPage < 0 || iPage >= m_PageList.GetSize())",
                "    return nullptr;",
                "",
                "      return static_cast<CPDF_Dictionary*>(pObj);",
                "",
                "    if (pObj && pObj->GetType() == PDFOBJ_DICTIONARY) {",
                "      return static_cast<CPDF_Dictionary*>(pObj);",
                "    }",
                "",
                "  if (!pRoot)",
                "    return nullptr;",
                "",
                "  if (!pPages)",
                "    return nullptr;",
                "",
                "  if (!pPage)",
                "    return nullptr;",
                ""
            ]
        }
    },
    {
        "cve_id": "CVE-2015-0275",
        "func_name": "torvalds/linux/ext4_zero_range",
        "description": "The ext4_zero_range function in fs/ext4/extents.c in the Linux kernel before 4.1 allows local users to cause a denial of service (BUG) via a crafted fallocate zero-range request.",
        "git_url": "https://github.com/torvalds/linux/commit/0f2af21aae11972fa924374ddcf52e88347cf5a8",
        "commit_title": "ext4: allocate entire range in zero range",
        "commit_text": " Currently there is a bug in zero range code which causes zero range calls to only allocate block aligned portion of the range, while ignoring the rest in some cases.  In some cases, namely if the end of the range is past i_size, we do attempt to preallocate the last nonaligned block. However this might cause kernel to BUG() in some carefully designed zero range requests on setups where page size > block size.  Fix this problem by first preallocating the entire range, including the nonaligned edges and converting the written extents to unwritten in the next step. This approach will also give us the advantage of having the range to be as linearly contiguous as possible. ",
        "func_before": "static long ext4_zero_range(struct file *file, loff_t offset,\n\t\t\t    loff_t len, int mode)\n{\n\tstruct inode *inode = file_inode(file);\n\thandle_t *handle = NULL;\n\tunsigned int max_blocks;\n\tloff_t new_size = 0;\n\tint ret = 0;\n\tint flags;\n\tint credits;\n\tint partial_begin, partial_end;\n\tloff_t start, end;\n\text4_lblk_t lblk;\n\tstruct address_space *mapping = inode->i_mapping;\n\tunsigned int blkbits = inode->i_blkbits;\n\n\ttrace_ext4_zero_range(inode, offset, len, mode);\n\n\tif (!S_ISREG(inode->i_mode))\n\t\treturn -EINVAL;\n\n\t/* Call ext4_force_commit to flush all data in case of data=journal. */\n\tif (ext4_should_journal_data(inode)) {\n\t\tret = ext4_force_commit(inode->i_sb);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t/*\n\t * Write out all dirty pages to avoid race conditions\n\t * Then release them.\n\t */\n\tif (mapping->nrpages && mapping_tagged(mapping, PAGECACHE_TAG_DIRTY)) {\n\t\tret = filemap_write_and_wait_range(mapping, offset,\n\t\t\t\t\t\t   offset + len - 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t/*\n\t * Round up offset. This is not fallocate, we neet to zero out\n\t * blocks, so convert interior block aligned part of the range to\n\t * unwritten and possibly manually zero out unaligned parts of the\n\t * range.\n\t */\n\tstart = round_up(offset, 1 << blkbits);\n\tend = round_down((offset + len), 1 << blkbits);\n\n\tif (start < offset || end > offset + len)\n\t\treturn -EINVAL;\n\tpartial_begin = offset & ((1 << blkbits) - 1);\n\tpartial_end = (offset + len) & ((1 << blkbits) - 1);\n\n\tlblk = start >> blkbits;\n\tmax_blocks = (end >> blkbits);\n\tif (max_blocks < lblk)\n\t\tmax_blocks = 0;\n\telse\n\t\tmax_blocks -= lblk;\n\n\tflags = EXT4_GET_BLOCKS_CREATE_UNWRIT_EXT |\n\t\tEXT4_GET_BLOCKS_CONVERT_UNWRITTEN |\n\t\tEXT4_EX_NOCACHE;\n\tif (mode & FALLOC_FL_KEEP_SIZE)\n\t\tflags |= EXT4_GET_BLOCKS_KEEP_SIZE;\n\n\tmutex_lock(&inode->i_mutex);\n\n\t/*\n\t * Indirect files do not support unwritten extnets\n\t */\n\tif (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out_mutex;\n\t}\n\n\tif (!(mode & FALLOC_FL_KEEP_SIZE) &&\n\t     offset + len > i_size_read(inode)) {\n\t\tnew_size = offset + len;\n\t\tret = inode_newsize_ok(inode, new_size);\n\t\tif (ret)\n\t\t\tgoto out_mutex;\n\t\t/*\n\t\t * If we have a partial block after EOF we have to allocate\n\t\t * the entire block.\n\t\t */\n\t\tif (partial_end)\n\t\t\tmax_blocks += 1;\n\t}\n\n\tif (max_blocks > 0) {\n\n\t\t/* Now release the pages and zero block aligned part of pages*/\n\t\ttruncate_pagecache_range(inode, start, end - 1);\n\t\tinode->i_mtime = inode->i_ctime = ext4_current_time(inode);\n\n\t\t/* Wait all existing dio workers, newcomers will block on i_mutex */\n\t\text4_inode_block_unlocked_dio(inode);\n\t\tinode_dio_wait(inode);\n\n\t\tret = ext4_alloc_file_blocks(file, lblk, max_blocks, new_size,\n\t\t\t\t\t     flags, mode);\n\t\tif (ret)\n\t\t\tgoto out_dio;\n\t\t/*\n\t\t * Remove entire range from the extent status tree.\n\t\t *\n\t\t * ext4_es_remove_extent(inode, lblk, max_blocks) is\n\t\t * NOT sufficient.  I'm not sure why this is the case,\n\t\t * but let's be conservative and remove the extent\n\t\t * status tree for the entire inode.  There should be\n\t\t * no outstanding delalloc extents thanks to the\n\t\t * filemap_write_and_wait_range() call above.\n\t\t */\n\t\tret = ext4_es_remove_extent(inode, 0, EXT_MAX_BLOCKS);\n\t\tif (ret)\n\t\t\tgoto out_dio;\n\t}\n\tif (!partial_begin && !partial_end)\n\t\tgoto out_dio;\n\n\t/*\n\t * In worst case we have to writeout two nonadjacent unwritten\n\t * blocks and update the inode\n\t */\n\tcredits = (2 * ext4_ext_index_trans_blocks(inode, 2)) + 1;\n\tif (ext4_should_journal_data(inode))\n\t\tcredits += 2;\n\thandle = ext4_journal_start(inode, EXT4_HT_MISC, credits);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\text4_std_error(inode->i_sb, ret);\n\t\tgoto out_dio;\n\t}\n\n\tinode->i_mtime = inode->i_ctime = ext4_current_time(inode);\n\tif (new_size) {\n\t\text4_update_inode_size(inode, new_size);\n\t} else {\n\t\t/*\n\t\t* Mark that we allocate beyond EOF so the subsequent truncate\n\t\t* can proceed even if the new size is the same as i_size.\n\t\t*/\n\t\tif ((offset + len) > i_size_read(inode))\n\t\t\text4_set_inode_flag(inode, EXT4_INODE_EOFBLOCKS);\n\t}\n\text4_mark_inode_dirty(handle, inode);\n\n\t/* Zero out partial block at the edges of the range */\n\tret = ext4_zero_partial_blocks(handle, inode, offset, len);\n\n\tif (file->f_flags & O_SYNC)\n\t\text4_handle_sync(handle);\n\n\text4_journal_stop(handle);\nout_dio:\n\text4_inode_resume_unlocked_dio(inode);\nout_mutex:\n\tmutex_unlock(&inode->i_mutex);\n\treturn ret;\n}",
        "func": "static long ext4_zero_range(struct file *file, loff_t offset,\n\t\t\t    loff_t len, int mode)\n{\n\tstruct inode *inode = file_inode(file);\n\thandle_t *handle = NULL;\n\tunsigned int max_blocks;\n\tloff_t new_size = 0;\n\tint ret = 0;\n\tint flags;\n\tint credits;\n\tint partial_begin, partial_end;\n\tloff_t start, end;\n\text4_lblk_t lblk;\n\tstruct address_space *mapping = inode->i_mapping;\n\tunsigned int blkbits = inode->i_blkbits;\n\n\ttrace_ext4_zero_range(inode, offset, len, mode);\n\n\tif (!S_ISREG(inode->i_mode))\n\t\treturn -EINVAL;\n\n\t/* Call ext4_force_commit to flush all data in case of data=journal. */\n\tif (ext4_should_journal_data(inode)) {\n\t\tret = ext4_force_commit(inode->i_sb);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t/*\n\t * Write out all dirty pages to avoid race conditions\n\t * Then release them.\n\t */\n\tif (mapping->nrpages && mapping_tagged(mapping, PAGECACHE_TAG_DIRTY)) {\n\t\tret = filemap_write_and_wait_range(mapping, offset,\n\t\t\t\t\t\t   offset + len - 1);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\n\t/*\n\t * Round up offset. This is not fallocate, we neet to zero out\n\t * blocks, so convert interior block aligned part of the range to\n\t * unwritten and possibly manually zero out unaligned parts of the\n\t * range.\n\t */\n\tstart = round_up(offset, 1 << blkbits);\n\tend = round_down((offset + len), 1 << blkbits);\n\n\tif (start < offset || end > offset + len)\n\t\treturn -EINVAL;\n\tpartial_begin = offset & ((1 << blkbits) - 1);\n\tpartial_end = (offset + len) & ((1 << blkbits) - 1);\n\n\tlblk = start >> blkbits;\n\tmax_blocks = (end >> blkbits);\n\tif (max_blocks < lblk)\n\t\tmax_blocks = 0;\n\telse\n\t\tmax_blocks -= lblk;\n\n\tmutex_lock(&inode->i_mutex);\n\n\t/*\n\t * Indirect files do not support unwritten extnets\n\t */\n\tif (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out_mutex;\n\t}\n\n\tif (!(mode & FALLOC_FL_KEEP_SIZE) &&\n\t     offset + len > i_size_read(inode)) {\n\t\tnew_size = offset + len;\n\t\tret = inode_newsize_ok(inode, new_size);\n\t\tif (ret)\n\t\t\tgoto out_mutex;\n\t}\n\n\tflags = EXT4_GET_BLOCKS_CREATE_UNWRIT_EXT;\n\tif (mode & FALLOC_FL_KEEP_SIZE)\n\t\tflags |= EXT4_GET_BLOCKS_KEEP_SIZE;\n\n\t/* Preallocate the range including the unaligned edges */\n\tif (partial_begin || partial_end) {\n\t\tret = ext4_alloc_file_blocks(file,\n\t\t\t\tround_down(offset, 1 << blkbits) >> blkbits,\n\t\t\t\t(round_up((offset + len), 1 << blkbits) -\n\t\t\t\t round_down(offset, 1 << blkbits)) >> blkbits,\n\t\t\t\tnew_size, flags, mode);\n\t\tif (ret)\n\t\t\tgoto out_mutex;\n\n\t}\n\n\t/* Zero range excluding the unaligned edges */\n\tif (max_blocks > 0) {\n\t\tflags |= (EXT4_GET_BLOCKS_CONVERT_UNWRITTEN |\n\t\t\t  EXT4_EX_NOCACHE);\n\n\t\t/* Now release the pages and zero block aligned part of pages*/\n\t\ttruncate_pagecache_range(inode, start, end - 1);\n\t\tinode->i_mtime = inode->i_ctime = ext4_current_time(inode);\n\n\t\t/* Wait all existing dio workers, newcomers will block on i_mutex */\n\t\text4_inode_block_unlocked_dio(inode);\n\t\tinode_dio_wait(inode);\n\n\t\tret = ext4_alloc_file_blocks(file, lblk, max_blocks, new_size,\n\t\t\t\t\t     flags, mode);\n\t\tif (ret)\n\t\t\tgoto out_dio;\n\t\t/*\n\t\t * Remove entire range from the extent status tree.\n\t\t *\n\t\t * ext4_es_remove_extent(inode, lblk, max_blocks) is\n\t\t * NOT sufficient.  I'm not sure why this is the case,\n\t\t * but let's be conservative and remove the extent\n\t\t * status tree for the entire inode.  There should be\n\t\t * no outstanding delalloc extents thanks to the\n\t\t * filemap_write_and_wait_range() call above.\n\t\t */\n\t\tret = ext4_es_remove_extent(inode, 0, EXT_MAX_BLOCKS);\n\t\tif (ret)\n\t\t\tgoto out_dio;\n\t}\n\tif (!partial_begin && !partial_end)\n\t\tgoto out_dio;\n\n\t/*\n\t * In worst case we have to writeout two nonadjacent unwritten\n\t * blocks and update the inode\n\t */\n\tcredits = (2 * ext4_ext_index_trans_blocks(inode, 2)) + 1;\n\tif (ext4_should_journal_data(inode))\n\t\tcredits += 2;\n\thandle = ext4_journal_start(inode, EXT4_HT_MISC, credits);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\text4_std_error(inode->i_sb, ret);\n\t\tgoto out_dio;\n\t}\n\n\tinode->i_mtime = inode->i_ctime = ext4_current_time(inode);\n\tif (new_size) {\n\t\text4_update_inode_size(inode, new_size);\n\t} else {\n\t\t/*\n\t\t* Mark that we allocate beyond EOF so the subsequent truncate\n\t\t* can proceed even if the new size is the same as i_size.\n\t\t*/\n\t\tif ((offset + len) > i_size_read(inode))\n\t\t\text4_set_inode_flag(inode, EXT4_INODE_EOFBLOCKS);\n\t}\n\text4_mark_inode_dirty(handle, inode);\n\n\t/* Zero out partial block at the edges of the range */\n\tret = ext4_zero_partial_blocks(handle, inode, offset, len);\n\n\tif (file->f_flags & O_SYNC)\n\t\text4_handle_sync(handle);\n\n\text4_journal_stop(handle);\nout_dio:\n\text4_inode_resume_unlocked_dio(inode);\nout_mutex:\n\tmutex_unlock(&inode->i_mutex);\n\treturn ret;\n}",
        "diff_func": "--- func_before\n+++ func_after\n@@ -58,12 +58,6 @@\n \telse\n \t\tmax_blocks -= lblk;\n \n-\tflags = EXT4_GET_BLOCKS_CREATE_UNWRIT_EXT |\n-\t\tEXT4_GET_BLOCKS_CONVERT_UNWRITTEN |\n-\t\tEXT4_EX_NOCACHE;\n-\tif (mode & FALLOC_FL_KEEP_SIZE)\n-\t\tflags |= EXT4_GET_BLOCKS_KEEP_SIZE;\n-\n \tmutex_lock(&inode->i_mutex);\n \n \t/*\n@@ -80,15 +74,28 @@\n \t\tret = inode_newsize_ok(inode, new_size);\n \t\tif (ret)\n \t\t\tgoto out_mutex;\n-\t\t/*\n-\t\t * If we have a partial block after EOF we have to allocate\n-\t\t * the entire block.\n-\t\t */\n-\t\tif (partial_end)\n-\t\t\tmax_blocks += 1;\n \t}\n \n+\tflags = EXT4_GET_BLOCKS_CREATE_UNWRIT_EXT;\n+\tif (mode & FALLOC_FL_KEEP_SIZE)\n+\t\tflags |= EXT4_GET_BLOCKS_KEEP_SIZE;\n+\n+\t/* Preallocate the range including the unaligned edges */\n+\tif (partial_begin || partial_end) {\n+\t\tret = ext4_alloc_file_blocks(file,\n+\t\t\t\tround_down(offset, 1 << blkbits) >> blkbits,\n+\t\t\t\t(round_up((offset + len), 1 << blkbits) -\n+\t\t\t\t round_down(offset, 1 << blkbits)) >> blkbits,\n+\t\t\t\tnew_size, flags, mode);\n+\t\tif (ret)\n+\t\t\tgoto out_mutex;\n+\n+\t}\n+\n+\t/* Zero range excluding the unaligned edges */\n \tif (max_blocks > 0) {\n+\t\tflags |= (EXT4_GET_BLOCKS_CONVERT_UNWRITTEN |\n+\t\t\t  EXT4_EX_NOCACHE);\n \n \t\t/* Now release the pages and zero block aligned part of pages*/\n \t\ttruncate_pagecache_range(inode, start, end - 1);",
        "diff_line_info": {
            "deleted_lines": [
                "\tflags = EXT4_GET_BLOCKS_CREATE_UNWRIT_EXT |",
                "\t\tEXT4_GET_BLOCKS_CONVERT_UNWRITTEN |",
                "\t\tEXT4_EX_NOCACHE;",
                "\tif (mode & FALLOC_FL_KEEP_SIZE)",
                "\t\tflags |= EXT4_GET_BLOCKS_KEEP_SIZE;",
                "",
                "\t\t/*",
                "\t\t * If we have a partial block after EOF we have to allocate",
                "\t\t * the entire block.",
                "\t\t */",
                "\t\tif (partial_end)",
                "\t\t\tmax_blocks += 1;"
            ],
            "added_lines": [
                "\tflags = EXT4_GET_BLOCKS_CREATE_UNWRIT_EXT;",
                "\tif (mode & FALLOC_FL_KEEP_SIZE)",
                "\t\tflags |= EXT4_GET_BLOCKS_KEEP_SIZE;",
                "",
                "\t/* Preallocate the range including the unaligned edges */",
                "\tif (partial_begin || partial_end) {",
                "\t\tret = ext4_alloc_file_blocks(file,",
                "\t\t\t\tround_down(offset, 1 << blkbits) >> blkbits,",
                "\t\t\t\t(round_up((offset + len), 1 << blkbits) -",
                "\t\t\t\t round_down(offset, 1 << blkbits)) >> blkbits,",
                "\t\t\t\tnew_size, flags, mode);",
                "\t\tif (ret)",
                "\t\t\tgoto out_mutex;",
                "",
                "\t}",
                "",
                "\t/* Zero range excluding the unaligned edges */",
                "\t\tflags |= (EXT4_GET_BLOCKS_CONVERT_UNWRITTEN |",
                "\t\t\t  EXT4_EX_NOCACHE);"
            ]
        }
    }
]